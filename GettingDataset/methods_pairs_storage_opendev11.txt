169
#method_before
@Override
public List<Measurements> find(String tenantId, String name, Map<String, String> dimensions, DateTime startTime, @Nullable DateTime endTime, List<String> statistics, int period, String offset, int limit, Boolean mergeMetricsFlag, String groupBy) throws Exception {
    String q = buildQuery(tenantId, name, dimensions, startTime, endTime, statistics, period, offset, limit, mergeMetricsFlag, groupBy);
    String r = this.influxV9RepoReader.read(q);
    Series series = this.objectMapper.readValue(r, Series.class);
    List<Measurements> statisticsList = statisticslist(series, offset, limit);
    logger.debug("Found {} metric definitions matching query", statisticsList.size());
    return statisticsList;
}
#method_after
@Override
public List<Statistics> find(String tenantId, String name, Map<String, String> dimensions, DateTime startTime, @Nullable DateTime endTime, List<String> statistics, int period, String offset, int limit, Boolean mergeMetricsFlag, String groupBy) throws Exception {
    String q = buildQuery(tenantId, name, dimensions, startTime, endTime, statistics, period, offset, limit, mergeMetricsFlag, groupBy);
    String r = this.influxV9RepoReader.read(q);
    Series series = this.objectMapper.readValue(r, Series.class);
    List<Statistics> statisticsList = statisticslist(series, offset, limit);
    logger.debug("Found {} metric definitions matching query", statisticsList.size());
    return statisticsList;
}
#end_block

#method_before
private List<Measurements> statisticslist(Series series, String offsetStr, int limit) {
    int offsetId = 0;
    String offsetTimestamp = "1970-01-01T00:00:00.000Z";
    if (offsetStr != null) {
        List<String> offsets = influxV9Utils.parseMultiOffset(offsetStr);
        if (offsets.size() > 1) {
            offsetId = Integer.parseInt(offsets.get(0));
            offsetTimestamp = offsets.get(1);
        } else {
            offsetId = 0;
            offsetTimestamp = offsets.get(0);
        }
    }
    List<Measurements> statisticsList = new LinkedList<>();
    if (!series.isEmpty()) {
        int remaining_limit = limit;
        int index = 0;
        for (Serie serie : series.getSeries()) {
            if (index < offsetId || remaining_limit <= 0) {
                index++;
                continue;
            }
            Statistics statistics = new Statistics(serie.getName(), this.influxV9Utils.filterPrivateTags(serie.getTags()), Arrays.asList(translateNames(serie.getColumns())));
            statistics.setId(Integer.toString(index));
            for (Object[] valueObjects : serie.getValues()) {
                if (remaining_limit <= 0) {
                    break;
                }
                List<Object> values = buildValsList(valueObjects);
                if (((String) values.get(0)).compareTo(offsetTimestamp) > 0 || index > offsetId) {
                    statistics.addMeasurement(values);
                    remaining_limit--;
                }
            }
            if (statistics.getMeasurements().size() > 0) {
                statisticsList.add(statistics);
            }
            index++;
        }
    }
    return statisticsList;
}
#method_after
private List<Statistics> statisticslist(Series series, String offsetStr, int limit) {
    int offsetId = 0;
    String offsetTimestamp = "1970-01-01T00:00:00.000Z";
    if (offsetStr != null) {
        List<String> offsets = influxV9Utils.parseMultiOffset(offsetStr);
        if (offsets.size() > 1) {
            offsetId = Integer.parseInt(offsets.get(0));
            offsetTimestamp = offsets.get(1);
        } else {
            offsetId = 0;
            offsetTimestamp = offsets.get(0);
        }
    }
    List<Statistics> statisticsList = new LinkedList<>();
    if (!series.isEmpty()) {
        int remaining_limit = limit;
        int index = 0;
        for (Serie serie : series.getSeries()) {
            if (index < offsetId || remaining_limit <= 0) {
                index++;
                continue;
            }
            Statistics statistics = new Statistics(serie.getName(), this.influxV9Utils.filterPrivateTags(serie.getTags()), Arrays.asList(translateNames(serie.getColumns())));
            statistics.setId(Integer.toString(index));
            for (Object[] valueObjects : serie.getValues()) {
                if (remaining_limit <= 0) {
                    break;
                }
                List<Object> values = buildValsList(valueObjects);
                if (((String) values.get(0)).compareTo(offsetTimestamp) > 0 || index > offsetId) {
                    statistics.addMeasurement(values);
                    remaining_limit--;
                }
            }
            if (statistics.getMeasurements().size() > 0) {
                statisticsList.add(statistics);
            }
            index++;
        }
    }
    return statisticsList;
}
#end_block

#method_before
public static Object paginateMeasurements(int limit, List<Measurements> elements, UriInfo uriInfo) throws UnsupportedEncodingException {
    // Check for paging turned off. Happens if maxQueryLimit is not set or is set to zero.
    if (limit == 0) {
        Paged paged = new Paged();
        paged.elements = elements != null ? elements : new ArrayList<>();
        return paged;
    }
    Paged paged = new Paged();
    paged.links.add(getSelfLink(uriInfo));
    if (elements != null && !elements.isEmpty()) {
        int remaining_limit = limit;
        for (int i = 0; i < elements.size(); i++) {
            Measurements s = elements.get(i);
            if (s != null) {
                List<List<Object>> l = s.getMeasurements();
                if (l.size() >= remaining_limit) {
                    String offset = s.getId();
                    if (offset != null) {
                        offset += '_' + (String) l.get(remaining_limit - 1).get(0);
                    } else {
                        offset = (String) l.get(remaining_limit - 1).get(0);
                    }
                    paged.links.add(getNextLink(offset, uriInfo));
                    // Truncate the measurement list. Normally this will just truncate one extra element.
                    l = l.subList(0, remaining_limit);
                    s.setMeasurements(l);
                    // Truncate the elements list
                    elements = elements.subList(0, i + 1);
                } else {
                    remaining_limit -= l.size();
                }
                paged.elements = elements;
            } else {
                paged.elements = new ArrayList<>();
            }
        }
    } else {
        paged.elements = new ArrayList<>();
    }
    return paged;
}
#method_after
public static Object paginateMeasurements(int limit, List<? extends Measurements> elements, UriInfo uriInfo) throws UnsupportedEncodingException {
    // Check for paging turned off. Happens if maxQueryLimit is not set or is set to zero.
    if (limit == 0) {
        Paged paged = new Paged();
        paged.elements = elements != null ? elements : new ArrayList<>();
        return paged;
    }
    Paged paged = new Paged();
    paged.links.add(getSelfLink(uriInfo));
    if (elements != null && !elements.isEmpty()) {
        int remaining_limit = limit;
        for (int i = 0; i < elements.size(); i++) {
            Measurements s = elements.get(i);
            if (s != null) {
                List<List<Object>> l = s.getMeasurements();
                if (l.size() >= remaining_limit) {
                    String offset = s.getId();
                    if (offset != null) {
                        offset += '_' + (String) l.get(remaining_limit - 1).get(0);
                    } else {
                        offset = (String) l.get(remaining_limit - 1).get(0);
                    }
                    paged.links.add(getNextLink(offset, uriInfo));
                    // Truncate the measurement list. Normally this will just truncate one extra element.
                    l = l.subList(0, remaining_limit);
                    s.setMeasurements(l);
                    // Truncate the elements list
                    elements = elements.subList(0, i + 1);
                } else {
                    remaining_limit -= l.size();
                }
                paged.elements = elements;
            } else {
                paged.elements = new ArrayList<>();
            }
        }
    } else {
        paged.elements = new ArrayList<>();
    }
    return paged;
}
#end_block

#method_before
@Override
public List<Measurements> find(String tenantId, String name, Map<String, String> dimensions, DateTime startTime, DateTime endTime, List<String> statisticsCols, int period, String offset, int limit, Boolean mergeMetricsFlag, String groupBy) throws MultipleMetricsException {
    Map<String, Measurements> statisticsMap = new HashMap<>();
    // Sort the column names so that they match the order of the statistics in the results.
    List<String> statisticsColumns = createColumnsList(statisticsCols);
    try (Handle h = db.open()) {
        if (!"*".equals(groupBy) && !Boolean.TRUE.equals(mergeMetricsFlag)) {
            MetricQueries.checkForMultipleDefinitions(h, tenantId, name, dimensions);
        }
        String sql = createQuery(name, dimensions, period, startTime, endTime, offset, statisticsCols, mergeMetricsFlag);
        logger.debug("vertica sql: {}", sql);
        Query<Map<String, Object>> query = h.createQuery(sql).bind("tenantId", tenantId).bind("start_time", startTime).bind("end_time", endTime).bind("limit", limit + 1);
        if (name != null && !name.isEmpty()) {
            query.bind("name", name);
        }
        MetricQueries.bindDimensionsToQuery(query, dimensions);
        if (offset != null && !offset.isEmpty()) {
            logger.debug("binding offset: {}", offset);
            MetricQueries.bindOffsetToQuery(query, offset);
        }
        List<Map<String, Object>> rows = query.list();
        if (rows.size() == 0) {
            return new ArrayList<>();
        }
        if ("*".equals(groupBy)) {
            String currentDefId = null;
            for (Map<String, Object> row : rows) {
                List<Object> statisticsRow = parseRow(row);
                String defDimsId = (String) row.get("id");
                if (defDimsId != null && !defDimsId.equals(currentDefId)) {
                    Statistics newStats = new Statistics();
                    newStats.setColumns(statisticsColumns);
                    statisticsMap.put(defDimsId, newStats);
                    currentDefId = defDimsId;
                }
                statisticsMap.get(defDimsId).addMeasurement(statisticsRow);
            }
            MetricQueries.addDefsToResults(statisticsMap, h, this.dbHint);
        } else {
            Statistics statistics = new Statistics();
            statistics.setId("");
            statistics.setName(name);
            statistics.setColumns(statisticsColumns);
            String firstDefId = (String) rows.get(0).get("id");
            for (Map<String, Object> row : rows) {
                List<Object> statisticsRow = parseRow(row);
                statistics.addMeasurement(statisticsRow);
            }
            statisticsMap.put(firstDefId, statistics);
            if (!Boolean.TRUE.equals(mergeMetricsFlag)) {
                statistics.setId(firstDefId);
                MetricQueries.addDefsToResults(statisticsMap, h, this.dbHint);
            } else {
                if (dimensions == null) {
                    dimensions = new HashMap<>();
                }
                statistics.setDimensions(dimensions);
            }
        }
    }
    return new ArrayList<>(statisticsMap.values());
}
#method_after
@Override
public List<Statistics> find(String tenantId, String name, Map<String, String> dimensions, DateTime startTime, DateTime endTime, List<String> statisticsCols, int period, String offset, int limit, Boolean mergeMetricsFlag, String groupBy) throws MultipleMetricsException {
    Map<String, Statistics> statisticsMap = new HashMap<>();
    // Sort the column names so that they match the order of the statistics in the results.
    List<String> statisticsColumns = createColumnsList(statisticsCols);
    try (Handle h = db.open()) {
        if (!"*".equals(groupBy) && !Boolean.TRUE.equals(mergeMetricsFlag)) {
            MetricQueries.checkForMultipleDefinitions(h, tenantId, name, dimensions);
        }
        String sql = createQuery(name, dimensions, period, startTime, endTime, offset, statisticsCols, mergeMetricsFlag);
        logger.debug("vertica sql: {}", sql);
        Query<Map<String, Object>> query = h.createQuery(sql).bind("tenantId", tenantId).bind("start_time", startTime).bind("end_time", endTime).bind("limit", limit + 1);
        if (name != null && !name.isEmpty()) {
            query.bind("name", name);
        }
        MetricQueries.bindDimensionsToQuery(query, dimensions);
        if (offset != null && !offset.isEmpty()) {
            logger.debug("binding offset: {}", offset);
            MetricQueries.bindOffsetToQuery(query, offset);
        }
        List<Map<String, Object>> rows = query.list();
        if (rows.size() == 0) {
            return new ArrayList<>();
        }
        if ("*".equals(groupBy)) {
            String currentDefId = null;
            for (Map<String, Object> row : rows) {
                List<Object> statisticsRow = parseRow(row);
                String defDimsId = (String) row.get("id");
                if (defDimsId != null && !defDimsId.equals(currentDefId)) {
                    Statistics newStats = new Statistics();
                    newStats.setColumns(statisticsColumns);
                    statisticsMap.put(defDimsId, newStats);
                    currentDefId = defDimsId;
                }
                statisticsMap.get(defDimsId).addMeasurement(statisticsRow);
            }
            MetricQueries.addDefsToResults(statisticsMap, h, this.dbHint);
        } else {
            Statistics statistics = new Statistics();
            statistics.setId("");
            statistics.setName(name);
            statistics.setColumns(statisticsColumns);
            String firstDefId = (String) rows.get(0).get("id");
            for (Map<String, Object> row : rows) {
                List<Object> statisticsRow = parseRow(row);
                statistics.addMeasurement(statisticsRow);
            }
            statisticsMap.put(firstDefId, statistics);
            if (!Boolean.TRUE.equals(mergeMetricsFlag)) {
                statistics.setId(firstDefId);
                MetricQueries.addDefsToResults(statisticsMap, h, this.dbHint);
            } else {
                if (dimensions == null) {
                    dimensions = new HashMap<>();
                }
                statistics.setDimensions(dimensions);
            }
        }
    }
    return new ArrayList<>(statisticsMap.values());
}
#end_block

#method_before
static void addDefsToResults(Map<String, Measurements> results, Handle h, String dbHint) {
    StringBuilder sb = new StringBuilder();
    boolean first = true;
    for (String id : results.keySet()) {
        if (first) {
            sb.append("'").append(id).append("'");
            first = false;
        } else {
            sb.append(',').append("'").append(id).append("'");
        }
    }
    String defDimSql = String.format(MetricQueries.FIND_METRIC_DEFS_SQL, dbHint, sb.toString());
    Query<Map<String, Object>> query = h.createQuery(defDimSql);
    List<Map<String, Object>> rows = query.list();
    String currentDefDimId = null;
    Map<String, String> dims = null;
    for (Map<String, Object> row : rows) {
        String defDimId = (String) row.get("defDimsId");
        String defName = (String) row.get("name");
        String dimName = (String) row.get("dName");
        String dimValue = (String) row.get("dValue");
        if (defDimId != null && !defDimId.equals(currentDefDimId)) {
            currentDefDimId = defDimId;
            dims = new HashMap<>();
            if (dimName != null && dimValue != null)
                dims.put(dimName, dimValue);
            results.get(defDimId).setId(defDimId);
            results.get(defDimId).setName(defName);
            results.get(defDimId).setDimensions(dims);
        } else {
            if (dimName != null && dimValue != null)
                dims.put(dimName, dimValue);
        }
    }
}
#method_after
static void addDefsToResults(Map<String, ? extends Measurements> results, Handle h, String dbHint) {
    StringBuilder sb = new StringBuilder();
    boolean first = true;
    for (String id : results.keySet()) {
        if (first) {
            sb.append("'").append(id).append("'");
            first = false;
        } else {
            sb.append(',').append("'").append(id).append("'");
        }
    }
    String defDimSql = String.format(MetricQueries.FIND_METRIC_DEFS_SQL, dbHint, sb.toString());
    Query<Map<String, Object>> query = h.createQuery(defDimSql);
    List<Map<String, Object>> rows = query.list();
    String currentDefDimId = null;
    Map<String, String> dims = null;
    for (Map<String, Object> row : rows) {
        String defDimId = (String) row.get("defDimsId");
        String defName = (String) row.get("name");
        String dimName = (String) row.get("dName");
        String dimValue = (String) row.get("dValue");
        if (defDimId != null && !defDimId.equals(currentDefDimId)) {
            currentDefDimId = defDimId;
            dims = new HashMap<>();
            if (dimName != null && dimValue != null)
                dims.put(dimName, dimValue);
            results.get(defDimId).setId(defDimId);
            results.get(defDimId).setName(defName);
            results.get(defDimId).setDimensions(dims);
        } else {
            if (dimName != null && dimValue != null)
                dims.put(dimName, dimValue);
        }
    }
}
#end_block

#method_before
@Override
public boolean equals(Object obj) {
    if (this == obj)
        return true;
    if (obj == null)
        return false;
    if (getClass() != obj.getClass())
        return false;
    Measurements other = (Measurements) obj;
    if (dimensions == null) {
        if (other.dimensions != null)
            return false;
    } else if (!dimensions.equals(other.dimensions))
        return false;
    if (measurements == null) {
        if (other.measurements != null)
            return false;
    } else if (!measurements.equals(other.measurements))
        return false;
    if (name == null) {
        if (other.name != null)
            return false;
    } else if (!name.equals(other.name))
        return false;
    return true;
}
#method_after
@Override
public boolean equals(Object obj) {
    if (this == obj)
        return true;
    if (obj == null)
        return false;
    if (getClass() != obj.getClass())
        return false;
    Measurements other = (Measurements) obj;
    if (dimensions == null) {
        if (other.dimensions != null)
            return false;
    } else if (!dimensions.equals(other.dimensions))
        return false;
    if (measurements == null) {
        if (other.measurements != null)
            return false;
    } else if (!measurements.equals(other.measurements))
        return false;
    if (name == null) {
        if (other.name != null)
            return false;
    } else if (!name.equals(other.name))
        return false;
    if (columns == null) {
        if (other.columns != null)
            return false;
    } else if (!columns.equals(other.columns))
        return false;
    return true;
}
#end_block

#method_before
@Override
public int hashCode() {
    final int prime = 31;
    int result = 1;
    result = prime * result + ((dimensions == null) ? 0 : dimensions.hashCode());
    result = prime * result + ((measurements == null) ? 0 : measurements.hashCode());
    result = prime * result + ((name == null) ? 0 : name.hashCode());
    return result;
}
#method_after
@Override
public int hashCode() {
    final int prime = 31;
    int result = 1;
    result = prime * result + ((dimensions == null) ? 0 : dimensions.hashCode());
    result = prime * result + ((measurements == null) ? 0 : measurements.hashCode());
    result = prime * result + ((name == null) ? 0 : name.hashCode());
    result = prime * result + ((columns == null) ? 0 : columns.hashCode());
    return result;
}
#end_block

#method_before
void aggregateValues(MetricDefinitionAndTenantId metricDefinitionAndTenantId, Metric metric) {
    SubAlarmStatsRepository subAlarmStatsRepo = getOrCreateSubAlarmStatsRepo(metricDefinitionAndTenantId);
    if (subAlarmStatsRepo == null) {
        // This is probably the metric that will cause the creation of a new SubAlarm, save it until
        // the SubAlarm comes in
        savedMetrics.put(metricDefinitionAndTenantId, metric);
        return;
    }
    for (SubAlarmStats stats : subAlarmStatsRepo.get()) {
        long timestamp_secs = metric.timestamp / 1000;
        if (stats.getStats().addValue(metric.value, timestamp_secs)) {
            logger.trace("Aggregated value {} at {} for {}. Updated {}", metric.value, metric.timestamp, metricDefinitionAndTenantId, stats.getStats());
            if (stats.evaluateAndSlideWindow(timestamp_secs, config.alarmDelay)) {
                sendSubAlarmStateChange(stats);
            }
        } else {
            logger.warn("Metric is too old, age {} seconds: timestamp {} for {}, {}", currentTimeSeconds() - timestamp_secs, timestamp_secs, metricDefinitionAndTenantId, stats.getStats());
        }
    }
}
#method_after
void aggregateValues(MetricDefinitionAndTenantId metricDefinitionAndTenantId, Metric metric) {
    SubAlarmStatsRepository subAlarmStatsRepo = getOrCreateSubAlarmStatsRepo(metricDefinitionAndTenantId);
    if (subAlarmStatsRepo == null) {
        // This is probably the metric that will cause the creation of a new SubAlarm, save it until
        // the SubAlarm comes in
        savedMetrics.put(metricDefinitionAndTenantId, metric);
        return;
    }
    for (SubAlarmStats stats : subAlarmStatsRepo.get()) {
        final long timestamp_secs = metricTimestampInSeconds(metric);
        if (stats.getStats().addValue(metric.value, timestamp_secs)) {
            logger.trace("Aggregated value {} at {} for {}. Updated {}", metric.value, metric.timestamp, metricDefinitionAndTenantId, stats.getStats());
            if (stats.evaluateAndSlideWindow(timestamp_secs, config.alarmDelay)) {
                sendSubAlarmStateChange(stats);
            }
        } else {
            logger.warn("Metric is too old, age {} seconds: timestamp {} for {}, {}", currentTimeSeconds() - timestamp_secs, timestamp_secs, metricDefinitionAndTenantId, stats.getStats());
        }
    }
}
#end_block

#method_before
private void cleanSavedMetrics() {
    if (savedMetrics.isEmpty()) {
        return;
    }
    final List<MetricDefinitionAndTenantId> toRemove = new ArrayList<>();
    for (Map.Entry<MetricDefinitionAndTenantId, Metric> entry : savedMetrics.entrySet()) {
        long now = currentTimeSeconds();
        final long age = entry.getValue().getTimestamp() / 1000 - now;
        if (age > MAX_SAVED_METRIC_AGE) {
            toRemove.add(entry.getKey());
        }
    }
    for (MetricDefinitionAndTenantId mdtid : toRemove) {
        savedMetrics.remove(mdtid);
    }
}
#method_after
private void cleanSavedMetrics() {
    if (savedMetrics.isEmpty()) {
        return;
    }
    final List<MetricDefinitionAndTenantId> toRemove = new ArrayList<>();
    for (Map.Entry<MetricDefinitionAndTenantId, Metric> entry : savedMetrics.entrySet()) {
        if (savedMetricTooOld(entry.getValue())) {
            toRemove.add(entry.getKey());
        }
    }
    logger.debug("Removing {} too old saved metrics", toRemove.size());
    for (MetricDefinitionAndTenantId mdtid : toRemove) {
        savedMetrics.remove(mdtid);
    }
}
#end_block

#method_before
void handleAlarmCreated(MetricDefinitionAndTenantId metricDefinitionAndTenantId, SubAlarm subAlarm) {
    logger.info("Received AlarmCreatedEvent for {}", subAlarm);
    final SubAlarmStats newStats = addSubAlarm(metricDefinitionAndTenantId, subAlarm);
    // See if we have a saved metric for this SubAlarm. Add to the SubAlarm if we do.
    // Because the Metric comes directly from the MetricFilterinBolt but the
    // SubAlarm comes from the AlarmCreationBolt, it is very likely that the
    // Metric arrives first
    final Metric metric = savedMetrics.get(metricDefinitionAndTenantId);
    if (metric != null) {
        if (newStats.getStats().addValue(metric.value, metric.timestamp / 1000)) {
            logger.trace("Aggregated saved value {} at {} for {}. Updated {}", metric.value, metric.timestamp, metricDefinitionAndTenantId, newStats.getStats());
        // The metric is not deleted from savedMetrics because it is possible that
        // the metric fits into two different SubAlarms. Not likely, but possible
        }
    }
}
#method_after
void handleAlarmCreated(MetricDefinitionAndTenantId metricDefinitionAndTenantId, SubAlarm subAlarm) {
    logger.info("Received AlarmCreatedEvent for {}", subAlarm);
    final SubAlarmStats newStats = addSubAlarm(metricDefinitionAndTenantId, subAlarm);
    // See if we have a saved metric for this SubAlarm. Add to the SubAlarm if we do.
    // Because the Metric comes directly from the MetricFilterinBolt but the
    // SubAlarm comes from the AlarmCreationBolt, it is very likely that the
    // Metric arrives first
    final Metric metric = savedMetrics.get(metricDefinitionAndTenantId);
    if (metric != null && !savedMetricTooOld(metric)) {
        aggregateValues(metricDefinitionAndTenantId, metric);
        logger.trace("Aggregated saved value {} at {} for {}. Updated {}", metric.value, metric.timestamp, metricDefinitionAndTenantId, newStats.getStats());
    // The metric is not deleted from savedMetrics because it is possible that
    // the metric fits into two different SubAlarms. Not likely, but possible
    }
}
#end_block

#method_before
public void shouldEvaluateAlarms() {
    // Ensure subAlarm2 and subAlarm3 map to the same Metric Definition
    assertEquals(metricDef3, metricDef2);
    long t1 = 170000;
    bolt.setCurrentTime(t1);
    sendSubAlarmCreated(metricDef1, subAlarm1);
    sendSubAlarmCreated(metricDef2, subAlarm2);
    sendSubAlarmCreated(metricDef3, subAlarm3);
    sendSubAlarmCreated(metricDef4, subAlarm4);
    // Send metrics for subAlarm1
    bolt.execute(createMetricTuple(metricDef1, new Metric(metricDef1, t1, 100000, null)));
    bolt.execute(createMetricTuple(metricDef1, new Metric(metricDef1, t1 - 60000, 95, null)));
    bolt.execute(createMetricTuple(metricDef1, new Metric(metricDef1, t1 - 120000, 88, null)));
    t1 += 25000;
    bolt.setCurrentTime(t1);
    sendTickTuple();
    assertEquals(subAlarm1.getState(), AlarmState.OK);
    assertEquals(subAlarm2.getState(), AlarmState.UNDETERMINED);
    assertEquals(subAlarm3.getState(), AlarmState.UNDETERMINED);
    // deterministic
    assertEquals(subAlarm4.getState(), AlarmState.OK);
    verify(collector, times(1)).emit(new Values(subAlarm1.getAlarmId(), subAlarm1));
    // Have to reset the mock so it can tell the difference when subAlarm2 and subAlarm3 are emitted
    // again.
    reset(collector);
    // Drive subAlarm1 to ALARM
    bolt.execute(createMetricTuple(metricDef1, new Metric(metricDef1, t1, 99, null)));
    // Drive subAlarm2 to ALARM and subAlarm3 to OK since they use the same MetricDefinition
    t1 += 10000;
    bolt.execute(createMetricTuple(metricDef2, new Metric(metricDef2, t1, 94, null)));
    t1 += 50000;
    bolt.setCurrentTime(t1);
    sendTickTuple();
    assertEquals(subAlarm1.getState(), AlarmState.ALARM);
    assertEquals(subAlarm2.getState(), AlarmState.ALARM);
    assertEquals(subAlarm3.getState(), AlarmState.OK);
    assertEquals(subAlarm4.getState(), AlarmState.OK);
    verify(collector, times(1)).emit(new Values(subAlarm1.getAlarmId(), subAlarm1));
    verify(collector, times(1)).emit(new Values(subAlarm2.getAlarmId(), subAlarm2));
    verify(collector, times(1)).emit(new Values(subAlarm3.getAlarmId(), subAlarm3));
    verify(collector, times(1)).emit(new Values(subAlarm4.getAlarmId(), subAlarm4));
}
#method_after
public void shouldEvaluateAlarms() {
    // Ensure subAlarm2 and subAlarm3 map to the same Metric Definition
    assertEquals(metricDef3, metricDef2);
    long t1 = 170000;
    bolt.setCurrentTime(t1);
    sendSubAlarmCreated(metricDef1, subAlarm1);
    sendSubAlarmCreated(metricDef2, subAlarm2);
    sendSubAlarmCreated(metricDef3, subAlarm3);
    sendSubAlarmCreated(metricDef4, subAlarm4);
    // Send metrics for subAlarm1
    bolt.execute(createMetricTuple(metricDef1, new Metric(metricDef1, t1, 100000, null)));
    bolt.execute(createMetricTuple(metricDef1, new Metric(metricDef1, t1 - 60000, 95, null)));
    bolt.execute(createMetricTuple(metricDef1, new Metric(metricDef1, t1 - 120000, 88, null)));
    t1 += 25000;
    bolt.setCurrentTime(t1);
    sendTickTuple();
    assertEquals(subAlarm1.getState(), AlarmState.OK);
    assertEquals(subAlarm2.getState(), AlarmState.UNDETERMINED);
    assertEquals(subAlarm3.getState(), AlarmState.UNDETERMINED);
    // deterministic
    assertEquals(subAlarm4.getState(), AlarmState.OK);
    verify(collector, times(1)).emit(new Values(subAlarm1.getAlarmId(), subAlarm1));
    verify(collector, never()).emit(new Values(subAlarm2.getAlarmId(), subAlarm2));
    verify(collector, never()).emit(new Values(subAlarm3.getAlarmId(), subAlarm3));
    verify(collector, times(1)).emit(new Values(subAlarm4.getAlarmId(), subAlarm4));
    // Have to reset the mock so it can tell the difference when subAlarm2 and subAlarm3 are emitted
    reset(collector);
    // Drive subAlarm1 to ALARM
    bolt.execute(createMetricTuple(metricDef1, new Metric(metricDef1, t1, 99, null)));
    // Drive subAlarm2 to ALARM and subAlarm3 to OK since they use the same MetricDefinition
    t1 += 10000;
    bolt.execute(createMetricTuple(metricDef2, new Metric(metricDef2, t1, 94, null)));
    t1 += 50000;
    bolt.setCurrentTime(t1);
    sendTickTuple();
    assertEquals(subAlarm1.getState(), AlarmState.ALARM);
    assertEquals(subAlarm2.getState(), AlarmState.ALARM);
    assertEquals(subAlarm3.getState(), AlarmState.OK);
    assertEquals(subAlarm4.getState(), AlarmState.OK);
    verify(collector, times(1)).emit(new Values(subAlarm1.getAlarmId(), subAlarm1));
    verify(collector, times(1)).emit(new Values(subAlarm2.getAlarmId(), subAlarm2));
    verify(collector, times(1)).emit(new Values(subAlarm3.getAlarmId(), subAlarm3));
    verify(collector, never()).emit(new Values(subAlarm4.getAlarmId(), subAlarm4));
}
#end_block

#method_before
public void shouldImmediatelyEvaluateSubAlarm() {
    // Ensure subAlarm2 and subAlarm3 map to the same Metric Definition
    assertEquals(metricDef3, metricDef2);
    long t1 = 170000;
    bolt.setCurrentTime(t1);
    sendSubAlarmCreated(metricDef2, subAlarm2);
    sendSubAlarmCreated(metricDef3, subAlarm3);
    sendSubAlarmCreated(metricDef4, subAlarm4);
    // Send metric for subAlarm2 and subAlarm3
    bolt.execute(createMetricTuple(metricDef3, new Metric(metricDef3, t1 + 1000, 100000, null)));
    for (int i = 0; i < 5; i++) {
        bolt.execute(createMetricTuple(metricDef4, new Metric(metricDef4, t1 + 1000 + i, 1, null)));
    }
    // subAlarm2 is AVG so it can't be evaluated immediately like the MAX for subalarm3
    // or count for subAlarm4
    assertEquals(subAlarm2.getState(), AlarmState.UNDETERMINED);
    assertEquals(subAlarm3.getState(), AlarmState.ALARM);
    assertEquals(subAlarm4.getState(), AlarmState.ALARM);
    verify(collector, never()).emit(new Values(subAlarm2.getAlarmId(), subAlarm2));
    verify(collector, times(1)).emit(new Values(subAlarm3.getAlarmId(), subAlarm3));
    verify(collector, times(1)).emit(new Values(subAlarm4.getAlarmId(), subAlarm4));
    // Have to reset the mock so it can tell the difference when subAlarm2 and subAlarm3 are emitted
    // again.
    reset(collector);
    t1 = 195000;
    bolt.setCurrentTime(t1);
    sendTickTuple();
    assertEquals(subAlarm2.getState(), AlarmState.ALARM);
    assertEquals(subAlarm3.getState(), AlarmState.ALARM);
    assertEquals(subAlarm4.getState(), AlarmState.ALARM);
    verify(collector, times(1)).emit(new Values(subAlarm2.getAlarmId(), subAlarm2));
    verify(collector, never()).emit(new Values(subAlarm3.getAlarmId(), subAlarm3));
    verify(collector, never()).emit(new Values(subAlarm4.getAlarmId(), subAlarm4));
    // Have to reset the mock so it can tell the difference when subAlarm2 and subAlarm3 are emitted
    // again.
    reset(collector);
    // Now drive SubAlarms back to OK
    t1 = 235000;
    bolt.setCurrentTime(t1);
    bolt.execute(createMetricTuple(metricDef3, new Metric(metricDef3, t1 + 1000, 20, null)));
    t1 = 315000;
    bolt.setCurrentTime(t1);
    bolt.execute(createMetricTuple(metricDef3, new Metric(metricDef3, t1 + 1000, 20, null)));
    sendTickTuple();
    assertEquals(subAlarm2.getState(), AlarmState.OK);
    assertEquals(subAlarm3.getState(), AlarmState.OK);
    // still in alarm
    assertEquals(subAlarm4.getState(), AlarmState.ALARM);
    verify(collector, times(1)).emit(new Values(subAlarm2.getAlarmId(), subAlarm2));
    verify(collector, times(1)).emit(new Values(subAlarm3.getAlarmId(), subAlarm3));
    verify(collector, never()).emit(new Values(subAlarm4.getAlarmId(), subAlarm4));
    // Have to reset the mock so it can tell the difference when subAlarm2 and subAlarm3 are emitted
    // again.
    reset(collector);
    // Now send a metric that is after the window end time but within alarm delay
    t1 = 365000;
    bolt.setCurrentTime(t1);
    bolt.execute(createMetricTuple(metricDef3, new Metric(metricDef3, t1 + 1000, 100000, null)));
    // subAlarm2 is AVG so it can't be evaluated immediately like the MAX for subalarm3
    assertEquals(subAlarm2.getState(), AlarmState.OK);
    assertEquals(subAlarm3.getState(), AlarmState.ALARM);
    verify(collector, never()).emit(new Values(subAlarm2.getAlarmId(), subAlarm2));
    verify(collector, times(1)).emit(new Values(subAlarm3.getAlarmId(), subAlarm3));
    // Have to reset the mock so it can tell the difference when subAlarm2 and subAlarm3 are emitted
    // again.
    reset(collector);
    t1 = 375000;
    bolt.setCurrentTime(t1);
    sendTickTuple();
    // Ensure that subAlarm3 is still ALARM. subAlarm2 is still OK but because the metric
    // that triggered ALARM is in the future bucket
    // subAlarm4 gets back to OK due to missing metrics
    assertEquals(subAlarm2.getState(), AlarmState.OK);
    assertEquals(subAlarm3.getState(), AlarmState.ALARM);
    assertEquals(subAlarm4.getState(), AlarmState.OK);
    verify(collector, never()).emit(new Values(subAlarm2.getAlarmId(), subAlarm2));
    verify(collector, never()).emit(new Values(subAlarm3.getAlarmId(), subAlarm3));
    verify(collector, times(1)).emit(new Values(subAlarm4.getAlarmId(), subAlarm4));
}
#method_after
public void shouldImmediatelyEvaluateSubAlarm() {
    // Ensure subAlarm2 and subAlarm3 map to the same Metric Definition
    assertEquals(metricDef3, metricDef2);
    long t1 = 170000;
    bolt.setCurrentTime(t1);
    sendSubAlarmCreated(metricDef2, subAlarm2);
    sendSubAlarmCreated(metricDef3, subAlarm3);
    sendSubAlarmCreated(metricDef4, subAlarm4);
    // Send metric for subAlarm2 and subAlarm3
    bolt.execute(createMetricTuple(metricDef3, new Metric(metricDef3, t1 + 1000, 100000, null)));
    for (int i = 0; i < 5; i++) {
        bolt.execute(createMetricTuple(metricDef4, new Metric(metricDef4, t1 + 1000 + i, 1, null)));
    }
    // subAlarm2 is AVG so it can't be evaluated immediately like the MAX for subalarm3
    // or count for subAlarm4
    assertEquals(subAlarm2.getState(), AlarmState.UNDETERMINED);
    assertEquals(subAlarm3.getState(), AlarmState.ALARM);
    assertEquals(subAlarm4.getState(), AlarmState.ALARM);
    verify(collector, never()).emit(new Values(subAlarm2.getAlarmId(), subAlarm2));
    verify(collector, times(1)).emit(new Values(subAlarm3.getAlarmId(), subAlarm3));
    verify(collector, times(1)).emit(new Values(subAlarm4.getAlarmId(), subAlarm4));
    // Have to reset the mock so it can tell the difference when subAlarm2 and subAlarm3 are emitted
    // again.
    reset(collector);
    t1 = 195000;
    bolt.setCurrentTime(t1);
    sendTickTuple();
    assertEquals(subAlarm2.getState(), AlarmState.ALARM);
    assertEquals(subAlarm3.getState(), AlarmState.ALARM);
    assertEquals(subAlarm4.getState(), AlarmState.ALARM);
    verify(collector, times(1)).emit(new Values(subAlarm2.getAlarmId(), subAlarm2));
    verify(collector, never()).emit(new Values(subAlarm3.getAlarmId(), subAlarm3));
    verify(collector, never()).emit(new Values(subAlarm4.getAlarmId(), subAlarm4));
    // Have to reset the mock so it can tell the difference when subAlarm2 and subAlarm3 are emitted
    // again.
    reset(collector);
    // Now drive SubAlarms back to OK
    t1 = 235000;
    bolt.setCurrentTime(t1);
    bolt.execute(createMetricTuple(metricDef3, new Metric(metricDef3, t1 + 1000, 20, null)));
    t1 = 315000;
    bolt.setCurrentTime(t1);
    bolt.execute(createMetricTuple(metricDef3, new Metric(metricDef3, t1 + 1000, 20, null)));
    sendTickTuple();
    assertEquals(subAlarm2.getState(), AlarmState.OK);
    assertEquals(subAlarm3.getState(), AlarmState.OK);
    // subAlarm4 goes to OK because of missing metrics
    assertEquals(subAlarm4.getState(), AlarmState.OK);
    verify(collector, times(1)).emit(new Values(subAlarm2.getAlarmId(), subAlarm2));
    verify(collector, times(1)).emit(new Values(subAlarm3.getAlarmId(), subAlarm3));
    verify(collector, times(1)).emit(new Values(subAlarm4.getAlarmId(), subAlarm4));
    // Have to reset the mock so it can tell the difference when subAlarm2 and subAlarm3 are emitted
    // again.
    reset(collector);
    // Now send a metric that is after the window end time but within alarm delay
    t1 = 365000;
    bolt.setCurrentTime(t1);
    bolt.execute(createMetricTuple(metricDef3, new Metric(metricDef3, t1 + 1000, 100000, null)));
    // subAlarm2 is AVG so it can't be evaluated immediately like the MAX for subalarm3
    assertEquals(subAlarm2.getState(), AlarmState.OK);
    assertEquals(subAlarm3.getState(), AlarmState.ALARM);
    verify(collector, never()).emit(new Values(subAlarm2.getAlarmId(), subAlarm2));
    verify(collector, times(1)).emit(new Values(subAlarm3.getAlarmId(), subAlarm3));
    // Have to reset the mock so it can tell the difference when subAlarm2 and subAlarm3 are emitted
    // again.
    reset(collector);
    t1 = 375000;
    bolt.setCurrentTime(t1);
    sendTickTuple();
    // Ensure that subAlarm3 is still ALARM. subAlarm2 is still OK but because the metric
    // that triggered ALARM is in the future bucket
    // subAlarm4 is still OK due to missing metrics
    assertEquals(subAlarm2.getState(), AlarmState.OK);
    assertEquals(subAlarm3.getState(), AlarmState.ALARM);
    assertEquals(subAlarm4.getState(), AlarmState.OK);
    verify(collector, never()).emit(new Values(subAlarm2.getAlarmId(), subAlarm2));
    verify(collector, never()).emit(new Values(subAlarm3.getAlarmId(), subAlarm3));
    verify(collector, never()).emit(new Values(subAlarm4.getAlarmId(), subAlarm4));
}
#end_block

#method_before
protected void prepareData(final SessionFactory sessionFactory) {
    Session session = sessionFactory.openSession();
    session.beginTransaction();
    final AlarmDefinitionDb alarmDefinition123 = new AlarmDefinitionDb().setTenantId("bob").setName("90% CPU").setSeverity(AlarmSeverity.HIGH).setExpression("avg(hpcs.compute{flavor_id=777, image_id=888, metric_name=cpu, device=1}) > 10").setMatchBy("flavor_id,image_id").setActionsEnabled(true);
    session.save(alarmDefinition123.setId("123"));
    final SubAlarmDefinitionDb subAlarmDefinition111 = new SubAlarmDefinitionDb().setAlarmDefinition(alarmDefinition123).setFunction("avg").setMetricName("hpcs.compute").setOperator(AlarmOperator.GT).setThreshold(10d).setPeriod(60).setPeriods(1);
    session.save(subAlarmDefinition111.setId("111"));
    final SubAlarmDefinitionDimensionDb subAlarmDefinitionDimensionFlavor777 = new SubAlarmDefinitionDimensionDb().setDimensionName("flavor_id").setValue("777");
    final SubAlarmDefinitionDimensionDb subAlarmDefinitionDimensionImageId888 = new SubAlarmDefinitionDimensionDb().setDimensionName("image_id").setValue("888");
    final SubAlarmDefinitionDimensionDb subAlarmDefinitionDimensionFlavorMetricNameCpu = new SubAlarmDefinitionDimensionDb().setDimensionName("metric_name").setValue("cpu");
    final SubAlarmDefinitionDimensionDb subAlarmDefinitionDimensionDevice1 = new SubAlarmDefinitionDimensionDb().setDimensionName("device").setValue("1");
    session.save(subAlarmDefinitionDimensionFlavor777.setSubExpression(subAlarmDefinition111));
    session.save(subAlarmDefinitionDimensionImageId888.setSubExpression(subAlarmDefinition111));
    session.save(subAlarmDefinitionDimensionFlavorMetricNameCpu.setSubExpression(subAlarmDefinition111));
    session.save(subAlarmDefinitionDimensionDevice1.setSubExpression(subAlarmDefinition111));
    final AlarmActionDb alarmAction29387234 = new AlarmActionDb().setActionId("29387234").setAlarmDefinition(alarmDefinition123).setAlarmState(AlarmState.ALARM);
    final AlarmActionDb alarmAction77778687 = new AlarmActionDb().setActionId("77778687").setAlarmDefinition(alarmDefinition123).setAlarmState(AlarmState.ALARM);
    session.save(alarmAction29387234);
    session.save(alarmAction77778687);
    final AlarmDefinitionDb alarmDefinition234 = new AlarmDefinitionDb().setTenantId("bob").setName("50% CPU").setSeverity(AlarmSeverity.LOW).setExpression("avg(hpcs.compute{flavor_id=777, image_id=888, metric_name=mem}) > 20 and avg(hpcs.compute) < 100").setMatchBy("flavor_id,image_id").setActionsEnabled(true);
    session.save(alarmDefinition234.setId("234"));
    final SubAlarmDefinitionDb subAlarmDefinition222 = new SubAlarmDefinitionDb().setAlarmDefinition(alarmDefinition234).setFunction("avg").setMetricName("hpcs.compute").setOperator(AlarmOperator.GT).setThreshold(20d).setPeriod(60).setPeriods(1);
    final SubAlarmDefinitionDb subAlarmDefinition223 = new SubAlarmDefinitionDb().setAlarmDefinition(alarmDefinition234).setFunction("avg").setMetricName("hpcs.compute").setOperator(AlarmOperator.LT).setThreshold(100d).setPeriod(60).setPeriods(1);
    session.save(subAlarmDefinition222.setId("222"));
    session.save(subAlarmDefinition223.setId("223"));
    session.save(new SubAlarmDefinitionDimensionDb().setDimensionName("flavor_id").setValue("777").setSubExpression(subAlarmDefinition222));
    session.save(new SubAlarmDefinitionDimensionDb().setDimensionName("image_id").setValue("888").setSubExpression(subAlarmDefinition222));
    session.save(new SubAlarmDefinitionDimensionDb().setDimensionName("metric_name").setValue("mem").setSubExpression(subAlarmDefinition222));
    session.save(new AlarmActionDb().setAlarmDefinition(alarmDefinition234).setAlarmState(AlarmState.ALARM).setActionId("29387234"));
    session.save(new AlarmActionDb().setAlarmDefinition(alarmDefinition234).setAlarmState(AlarmState.ALARM).setActionId("77778687"));
    session.getTransaction().commit();
    session.close();
    alarmDef_123 = new AlarmDefinition("123", "90% CPU", null, "HIGH", "avg(hpcs.compute{flavor_id=777, image_id=888, metric_name=cpu, device=1}) > 10", Arrays.asList("flavor_id", "image_id"), true, Arrays.asList("29387234", "77778687"), Collections.<String>emptyList(), Collections.<String>emptyList());
    alarmDef_234 = new AlarmDefinition("234", "50% CPU", null, "LOW", "avg(hpcs.compute{flavor_id=777, image_id=888, metric_name=mem}) > 20 and avg(hpcs.compute) < 100", Arrays.asList("flavor_id", "image_id"), true, Arrays.asList("29387234", "77778687"), Collections.<String>emptyList(), Collections.<String>emptyList());
}
#method_after
protected void prepareData(final SessionFactory sessionFactory) {
    Session session = sessionFactory.openSession();
    session.beginTransaction();
    final AlarmDefinitionDb alarmDefinition123 = new AlarmDefinitionDb().setTenantId("bob").setName("90% CPU").setSeverity(AlarmSeverity.HIGH).setExpression("avg(hpcs.compute{flavor_id=777, image_id=888, metric_name=cpu, device=1}) > 10").setMatchBy("flavor_id,image_id").setActionsEnabled(true);
    session.save(alarmDefinition123.setId("123"));
    final SubAlarmDefinitionDb subAlarmDefinition111 = new SubAlarmDefinitionDb().setAlarmDefinition(alarmDefinition123).setFunction("avg").setMetricName("hpcs.compute").setOperator(AlarmOperator.GT).setThreshold(10d).setPeriod(60).setPeriods(1);
    session.save(subAlarmDefinition111.setId("111"));
    final SubAlarmDefinitionDimensionDb subAlarmDefinitionDimensionFlavor777 = new SubAlarmDefinitionDimensionDb().setDimensionName("flavor_id").setValue("777");
    final SubAlarmDefinitionDimensionDb subAlarmDefinitionDimensionImageId888 = new SubAlarmDefinitionDimensionDb().setDimensionName("image_id").setValue("888");
    final SubAlarmDefinitionDimensionDb subAlarmDefinitionDimensionFlavorMetricNameCpu = new SubAlarmDefinitionDimensionDb().setDimensionName("metric_name").setValue("cpu");
    final SubAlarmDefinitionDimensionDb subAlarmDefinitionDimensionDevice1 = new SubAlarmDefinitionDimensionDb().setDimensionName("device").setValue("1");
    session.save(subAlarmDefinitionDimensionFlavor777.setSubExpression(subAlarmDefinition111));
    session.save(subAlarmDefinitionDimensionImageId888.setSubExpression(subAlarmDefinition111));
    session.save(subAlarmDefinitionDimensionFlavorMetricNameCpu.setSubExpression(subAlarmDefinition111));
    session.save(subAlarmDefinitionDimensionDevice1.setSubExpression(subAlarmDefinition111));
    final NotificationMethodDb notificationMethodDb29387234 = new NotificationMethodDb().setAddress("root@localhost").setName("root2938723").setTenantId("bob").setType(AlarmNotificationMethodType.EMAIL).setPeriod(60);
    final NotificationMethodDb notificationMethodDb77778687 = new NotificationMethodDb().setAddress("root@localhost").setName("root77778687").setTenantId("bob").setType(AlarmNotificationMethodType.EMAIL).setPeriod(60);
    session.save(notificationMethodDb29387234.setId("29387234"));
    session.save(notificationMethodDb77778687.setId("77778687"));
    final AlarmActionDb alarmAction29387234 = new AlarmActionDb().setActionId("29387234").setAlarmDefinition(alarmDefinition123).setAlarmState(AlarmState.ALARM);
    final AlarmActionDb alarmAction77778687 = new AlarmActionDb().setActionId("77778687").setAlarmDefinition(alarmDefinition123).setAlarmState(AlarmState.ALARM);
    session.save(alarmAction29387234);
    session.save(alarmAction77778687);
    final AlarmDefinitionDb alarmDefinition234 = new AlarmDefinitionDb().setTenantId("bob").setName("50% CPU").setSeverity(AlarmSeverity.LOW).setExpression("avg(hpcs.compute{flavor_id=777, image_id=888, metric_name=mem}) > 20 and avg(hpcs.compute) < 100").setMatchBy("flavor_id,image_id").setActionsEnabled(true);
    session.save(alarmDefinition234.setId("234"));
    final SubAlarmDefinitionDb subAlarmDefinition222 = new SubAlarmDefinitionDb().setAlarmDefinition(alarmDefinition234).setFunction("avg").setMetricName("hpcs.compute").setOperator(AlarmOperator.GT).setThreshold(20d).setPeriod(60).setPeriods(1);
    final SubAlarmDefinitionDb subAlarmDefinition223 = new SubAlarmDefinitionDb().setAlarmDefinition(alarmDefinition234).setFunction("avg").setMetricName("hpcs.compute").setOperator(AlarmOperator.LT).setThreshold(100d).setPeriod(60).setPeriods(1);
    session.save(subAlarmDefinition222.setId("222"));
    session.save(subAlarmDefinition223.setId("223"));
    session.save(new SubAlarmDefinitionDimensionDb().setDimensionName("flavor_id").setValue("777").setSubExpression(subAlarmDefinition222));
    session.save(new SubAlarmDefinitionDimensionDb().setDimensionName("image_id").setValue("888").setSubExpression(subAlarmDefinition222));
    session.save(new SubAlarmDefinitionDimensionDb().setDimensionName("metric_name").setValue("mem").setSubExpression(subAlarmDefinition222));
    session.save(new AlarmActionDb().setAlarmDefinition(alarmDefinition234).setAlarmState(AlarmState.ALARM).setActionId("29387234"));
    session.save(new AlarmActionDb().setAlarmDefinition(alarmDefinition234).setAlarmState(AlarmState.ALARM).setActionId("77778687"));
    session.getTransaction().commit();
    session.close();
    alarmDef_123 = new AlarmDefinition("123", "90% CPU", null, "HIGH", "avg(hpcs.compute{flavor_id=777, image_id=888, metric_name=cpu, device=1}) > 10", Arrays.asList("flavor_id", "image_id"), true, Arrays.asList("29387234", "77778687"), Collections.<String>emptyList(), Collections.<String>emptyList());
    alarmDef_234 = new AlarmDefinition("234", "50% CPU", null, "LOW", "avg(hpcs.compute{flavor_id=777, image_id=888, metric_name=mem}) > 20 and avg(hpcs.compute) < 100", Arrays.asList("flavor_id", "image_id"), true, Arrays.asList("29387234", "77778687"), Collections.<String>emptyList(), Collections.<String>emptyList());
}
#end_block

#method_before
public void shouldFilterBySeverity() {
    final List<AlarmDefinition> alarmDefinitions = repo.find("bob", null, null, AlarmSeverity.HIGH, null, null, 1);
    final AlarmDefinition alarmDefinition;
    assertEquals(1, alarmDefinitions.size());
    alarmDefinition = alarmDefinitions.get(0);
    assertEquals(this.alarmDef_123, alarmDefinition);
}
#method_after
public void shouldFilterBySeverity() {
    checkList(repo.find("bob", null, null, Lists.newArrayList(AlarmSeverity.HIGH), null, null, 1), this.alarmDef_123);
    checkList(repo.find("bob", null, null, Lists.newArrayList(AlarmSeverity.LOW), null, null, 1), this.alarmDef_234);
    checkList(repo.find("bob", null, null, Lists.newArrayList(AlarmSeverity.HIGH, AlarmSeverity.LOW), null, null, 1), this.alarmDef_123, this.alarmDef_234);
}
#end_block

#method_before
@Override
@SuppressWarnings("unchecked")
public List<AlarmDefinition> find(String tenantId, String name, Map<String, String> dimensions, AlarmSeverity severity, List<String> sortBy, String offset, int limit) {
    logger.trace(ORM_LOG_MARKER, "find(...) entering...");
    if (sortBy != null && !sortBy.isEmpty()) {
        throw Exceptions.unprocessableEntity("Sort_by is not implemented for the hibernate database type");
    }
    Session session = null;
    List<AlarmDefinition> resultSet = Lists.newArrayList();
    // TODO introduce criteria here, will make code significantly better
    String query = "  SELECT t.id, t.tenant_id, t.name, t.description, t.expression, t.severity, t.match_by, " + "t.actions_enabled, aa.alarm_state AS states, aa.action_id AS notificationIds " + "FROM (SELECT distinct ad.id, ad.tenant_id, ad.name, ad.description, ad.expression, " + "ad.severity, ad.match_by, ad.actions_enabled, ad.created_at, ad.updated_at, ad.deleted_at " + "FROM alarm_definition AS ad LEFT OUTER JOIN sub_alarm_definition AS sad ON ad.id = sad.alarm_definition_id " + "LEFT OUTER JOIN sub_alarm_definition_dimension AS dim ON sad.id = dim.sub_alarm_definition_id %1$s " + "WHERE ad.tenant_id = :tenantId AND ad.deleted_at IS NULL %2$s ORDER BY ad.id %3$s) AS t " + "LEFT OUTER JOIN alarm_action AS aa ON t.id = aa.alarm_definition_id ORDER BY t.id, t.created_at";
    StringBuilder sbWhere = new StringBuilder();
    StringBuilder limitOffset = new StringBuilder();
    if (name != null) {
        sbWhere.append(" and ad.name = :name");
    }
    if (severity != null) {
        sbWhere.append(" and ad.severity = :severity");
    }
    if (limit > 0) {
        limitOffset.append(" limit :limit");
    }
    if (offset != null) {
        limitOffset.append(" offset ");
        limitOffset.append(offset);
        limitOffset.append(' ');
    }
    String sql = String.format(query, SubAlarmDefinitionQueries.buildJoinClauseFor(dimensions), sbWhere, limitOffset);
    try {
        session = sessionFactory.openSession();
        final Query qAlarmDefinition = session.createSQLQuery(sql).setString("tenantId", tenantId).setResultTransformer(ALARM_DEF_RESULT_TRANSFORMER);
        if (name != null) {
            qAlarmDefinition.setString("name", name);
        }
        if (severity != null) {
            qAlarmDefinition.setString("severity", severity.name());
        }
        if (limit > 0) {
            qAlarmDefinition.setInteger("limit", limit + 1);
        }
        this.bindDimensionsToQuery(qAlarmDefinition, dimensions);
        final List<Map<?, ?>> alarmDefinitionDbList = qAlarmDefinition.list();
        resultSet = CollectionUtils.isEmpty(alarmDefinitionDbList) ? Lists.<AlarmDefinition>newArrayList() : this.createAlarmDefinitions(alarmDefinitionDbList);
    } finally {
        if (session != null) {
            session.close();
        }
    }
    return resultSet;
}
#method_after
@Override
@SuppressWarnings("unchecked")
public List<AlarmDefinition> find(String tenantId, String name, Map<String, String> dimensions, List<AlarmSeverity> severities, List<String> sortBy, String offset, int limit) {
    logger.trace(ORM_LOG_MARKER, "find(...) entering...");
    if (sortBy != null && !sortBy.isEmpty()) {
        throw Exceptions.unprocessableEntity("Sort_by is not implemented for the hibernate database type");
    }
    Session session = null;
    List<AlarmDefinition> resultSet = Lists.newArrayList();
    // TODO introduce criteria here, will make code significantly better
    String query = "  SELECT t.id, t.tenant_id, t.name, t.description, t.expression, t.severity, t.match_by, " + "t.actions_enabled, aa.alarm_state AS states, aa.action_id AS notificationIds " + "FROM (SELECT distinct ad.id, ad.tenant_id, ad.name, ad.description, ad.expression, " + "ad.severity, ad.match_by, ad.actions_enabled, ad.created_at, ad.updated_at, ad.deleted_at " + "FROM alarm_definition AS ad LEFT OUTER JOIN sub_alarm_definition AS sad ON ad.id = sad.alarm_definition_id " + "LEFT OUTER JOIN sub_alarm_definition_dimension AS dim ON sad.id = dim.sub_alarm_definition_id %1$s " + "WHERE ad.tenant_id = :tenantId AND ad.deleted_at IS NULL %2$s ORDER BY ad.id %3$s) AS t " + "LEFT OUTER JOIN alarm_action AS aa ON t.id = aa.alarm_definition_id ORDER BY t.id, t.created_at";
    StringBuilder sbWhere = new StringBuilder();
    StringBuilder limitOffset = new StringBuilder();
    if (name != null) {
        sbWhere.append(" and ad.name = :name");
    }
    if (CollectionUtils.isNotEmpty(severities)) {
        if (severities.size() == 1) {
            sbWhere.append(" and ad.severity = :severity");
        } else {
            sbWhere.append(" and (");
            for (int i = 0; i < severities.size(); i++) {
                sbWhere.append("ad.severity = :severity_").append(i);
                if (i < severities.size() - 1) {
                    sbWhere.append(" or ");
                }
            }
            sbWhere.append(")");
        }
    }
    if (limit > 0) {
        limitOffset.append(" limit :limit");
    }
    if (offset != null) {
        limitOffset.append(" offset :offset ");
    }
    String sql = String.format(query, SubAlarmDefinitionQueries.buildJoinClauseFor(dimensions), sbWhere, limitOffset);
    try {
        session = sessionFactory.openSession();
        final Query qAlarmDefinition = session.createSQLQuery(sql).setString("tenantId", tenantId).setReadOnly(true).setResultTransformer(ALARM_DEF_RESULT_TRANSFORMER);
        if (name != null) {
            qAlarmDefinition.setString("name", name);
        }
        if (CollectionUtils.isNotEmpty(severities)) {
            if (severities.size() == 1) {
                qAlarmDefinition.setString("severity", severities.get(0).name());
            } else {
                for (int it = 0; it < severities.size(); it++) {
                    qAlarmDefinition.setString(String.format("severity_%d", it), severities.get(it).name());
                }
            }
        }
        if (limit > 0) {
            qAlarmDefinition.setInteger("limit", limit + 1);
        }
        if (offset != null) {
            qAlarmDefinition.setInteger("offset", Integer.parseInt(offset));
        }
        this.bindDimensionsToQuery(qAlarmDefinition, dimensions);
        final List<Map<?, ?>> alarmDefinitionDbList = qAlarmDefinition.list();
        resultSet = CollectionUtils.isEmpty(alarmDefinitionDbList) ? Lists.<AlarmDefinition>newArrayList() : this.createAlarmDefinitions(alarmDefinitionDbList);
    } finally {
        if (session != null) {
            session.close();
        }
    }
    return resultSet;
}
#end_block

#method_before
@Override
@SuppressWarnings("unchecked")
public Map<String, AlarmSubExpression> findSubExpressions(String alarmDefId) {
    logger.trace(ORM_LOG_MARKER, "findSubExpressions(...) entering...");
    Session session = null;
    Map<String, AlarmSubExpression> subExpressions = Maps.newHashMap();
    try {
        session = sessionFactory.openSession();
        List<SubAlarmDefinitionDb> subAlarmDefList = session.getNamedQuery(SubAlarmDefinitionDb.Queries.BY_ALARMDEFINITION_ID).setString("id", alarmDefId).list();
        Query querySybAlarmDefDimension = session.getNamedQuery(SubAlarmDefinitionDb.Queries.BY_ALARMDEFINITIONDIMENSION_SUBEXPRESSION_ID).setString("id", alarmDefId);
        List<SubAlarmDefinitionDimensionDb> subAlarmDefDimensionList = querySybAlarmDefDimension.list();
        Map<String, Map<String, String>> subAlarmDefDimensionMapExpression = mapAlarmDefDimensionExpression(subAlarmDefDimensionList);
        for (SubAlarmDefinitionDb subAlarmDef : subAlarmDefList) {
            String id = subAlarmDef.getId();
            AggregateFunction function = AggregateFunction.fromJson(subAlarmDef.getFunction());
            String metricName = subAlarmDef.getMetricName();
            AlarmOperator operator = AlarmOperator.fromJson(subAlarmDef.getOperator());
            double threshold = subAlarmDef.getThreshold();
            int period = subAlarmDef.getPeriod();
            int periods = subAlarmDef.getPeriods();
            Map<String, String> dimensions = Collections.emptyMap();
            if (subAlarmDefDimensionMapExpression.containsKey(id)) {
                dimensions = subAlarmDefDimensionMapExpression.get(id);
            }
            subExpressions.put(id, new AlarmSubExpression(function, new MetricDefinition(metricName, dimensions), operator, threshold, period, periods));
        }
        return subExpressions;
    } finally {
        if (session != null) {
            session.close();
        }
    }
}
#method_after
@Override
@SuppressWarnings("unchecked")
public Map<String, AlarmSubExpression> findSubExpressions(String alarmDefId) {
    logger.trace(ORM_LOG_MARKER, "findSubExpressions(...) entering...");
    Session session = null;
    Map<String, AlarmSubExpression> subExpressions = Maps.newHashMap();
    try {
        session = sessionFactory.openSession();
        List<SubAlarmDefinitionDb> subAlarmDefList = session.getNamedQuery(SubAlarmDefinitionDb.Queries.BY_ALARMDEFINITION_ID).setString("id", alarmDefId).list();
        Query querySybAlarmDefDimension = session.getNamedQuery(SubAlarmDefinitionDb.Queries.BY_ALARMDEFINITIONDIMENSION_SUBEXPRESSION_ID).setString("id", alarmDefId);
        List<SubAlarmDefinitionDimensionDb> subAlarmDefDimensionList = querySybAlarmDefDimension.list();
        Map<String, Map<String, String>> subAlarmDefDimensionMapExpression = mapAlarmDefDimensionExpression(subAlarmDefDimensionList);
        for (SubAlarmDefinitionDb subAlarmDef : subAlarmDefList) {
            String id = subAlarmDef.getId();
            AggregateFunction function = AggregateFunction.fromJson(subAlarmDef.getFunction());
            String metricName = subAlarmDef.getMetricName();
            AlarmOperator operator = AlarmOperator.fromJson(subAlarmDef.getOperator());
            double threshold = subAlarmDef.getThreshold();
            int period = subAlarmDef.getPeriod();
            int periods = subAlarmDef.getPeriods();
            boolean isDeterministic = subAlarmDef.isDeterministic();
            Map<String, String> dimensions = Collections.emptyMap();
            if (subAlarmDefDimensionMapExpression.containsKey(id)) {
                dimensions = subAlarmDefDimensionMapExpression.get(id);
            }
            subExpressions.put(id, new AlarmSubExpression(function, new MetricDefinition(metricName, dimensions), operator, threshold, period, periods, isDeterministic));
        }
        return subExpressions;
    } finally {
        if (session != null) {
            session.close();
        }
    }
}
#end_block

#method_before
private void updateChangedSubAlarms(final Map<String, AlarmSubExpression> changedSubAlarms, final Session session) {
    if (!MapUtils.isEmpty(changedSubAlarms))
        for (Map.Entry<String, AlarmSubExpression> entry : changedSubAlarms.entrySet()) {
            final AlarmSubExpression sa = entry.getValue();
            final String subAlarmDefinitionId = entry.getKey();
            SubAlarmDefinitionDb subAlarmDefinitionDb = session.get(SubAlarmDefinitionDb.class, subAlarmDefinitionId);
            subAlarmDefinitionDb.setOperator(sa.getOperator().name());
            subAlarmDefinitionDb.setThreshold(sa.getThreshold());
            subAlarmDefinitionDb.setUpdatedAt(this.getUTCNow());
            session.saveOrUpdate(subAlarmDefinitionDb);
        }
}
#method_after
private void updateChangedSubAlarms(final Map<String, AlarmSubExpression> changedSubAlarms, final Session session) {
    if (!MapUtils.isEmpty(changedSubAlarms))
        for (Map.Entry<String, AlarmSubExpression> entry : changedSubAlarms.entrySet()) {
            final AlarmSubExpression sa = entry.getValue();
            final String subAlarmDefinitionId = entry.getKey();
            SubAlarmDefinitionDb subAlarmDefinitionDb = session.get(SubAlarmDefinitionDb.class, subAlarmDefinitionId);
            subAlarmDefinitionDb.setOperator(sa.getOperator().name());
            subAlarmDefinitionDb.setThreshold(sa.getThreshold());
            subAlarmDefinitionDb.setUpdatedAt(this.getUTCNow());
            subAlarmDefinitionDb.setDeterministic(sa.isDeterministic());
            session.saveOrUpdate(subAlarmDefinitionDb);
        }
}
#end_block

#method_before
private AlarmDefinitionDb updateAlarmDefinition(final String tenantId, final String id, final String name, final String description, final String expression, final List<String> matchBy, final String severity, final boolean actionsEnabled, final Session session) {
    final AlarmDefinitionDb alarmDefinitionDb = (AlarmDefinitionDb) session.getNamedQuery(AlarmDefinitionDb.Queries.FIND_BY_TENANT_ID_AND_ID).setString("tenantId", tenantId).setString("id", id).uniqueResult();
    alarmDefinitionDb.setName(name);
    alarmDefinitionDb.setDescription(description);
    alarmDefinitionDb.setExpression(expression);
    alarmDefinitionDb.setMatchBy(matchBy == null || Iterables.isEmpty(matchBy) ? null : COMMA_JOINER.join(matchBy));
    alarmDefinitionDb.setSeverity(AlarmSeverity.valueOf(severity));
    alarmDefinitionDb.setActionsEnabled(actionsEnabled);
    session.saveOrUpdate(alarmDefinitionDb);
    return alarmDefinitionDb;
}
#method_after
private AlarmDefinitionDb updateAlarmDefinition(final String tenantId, final String id, final String name, final String description, final String expression, final List<String> matchBy, final String severity, final boolean actionsEnabled, final Session session) {
    final AlarmDefinitionDb alarmDefinitionDb = (AlarmDefinitionDb) session.getNamedQuery(AlarmDefinitionDb.Queries.FIND_BY_TENANT_ID_AND_ID).setString("tenantId", tenantId).setString("id", id).uniqueResult();
    alarmDefinitionDb.setName(name);
    alarmDefinitionDb.setDescription(description);
    alarmDefinitionDb.setExpression(expression);
    alarmDefinitionDb.setMatchBy(matchBy == null || Iterables.isEmpty(matchBy) ? null : COMMA_JOINER.join(matchBy));
    alarmDefinitionDb.setSeverity(AlarmSeverity.valueOf(severity));
    alarmDefinitionDb.setActionsEnabled(actionsEnabled);
    alarmDefinitionDb.setUpdatedAt(this.getUTCNow());
    session.saveOrUpdate(alarmDefinitionDb);
    return alarmDefinitionDb;
}
#end_block

#method_before
private void createSubExpressions(Session session, AlarmDefinitionDb alarmDefinition, Map<String, AlarmSubExpression> alarmSubExpressions) {
    if (alarmSubExpressions != null) {
        for (Map.Entry<String, AlarmSubExpression> subEntry : alarmSubExpressions.entrySet()) {
            String subAlarmId = subEntry.getKey();
            AlarmSubExpression subExpr = subEntry.getValue();
            MetricDefinition metricDef = subExpr.getMetricDefinition();
            // Persist sub-alarm
            final DateTime now = this.getUTCNow();
            SubAlarmDefinitionDb subAlarmDefinitionDb = new SubAlarmDefinitionDb(subAlarmId, alarmDefinition, subExpr.getFunction().name(), metricDef.name, subExpr.getOperator().name(), subExpr.getThreshold(), subExpr.getPeriod(), subExpr.getPeriods(), now, now);
            session.save(subAlarmDefinitionDb);
            // Persist sub-alarm dimensions
            if (!MapUtils.isEmpty(metricDef.dimensions)) {
                SubAlarmDefinitionDimensionDb definitionDimension;
                SubAlarmDefinitionDimensionId definitionDimensionId;
                for (Map.Entry<String, String> dimEntry : metricDef.dimensions.entrySet()) {
                    definitionDimensionId = new SubAlarmDefinitionDimensionId(subAlarmDefinitionDb, dimEntry.getKey());
                    definitionDimension = new SubAlarmDefinitionDimensionDb(definitionDimensionId, dimEntry.getValue());
                    session.save(definitionDimension);
                }
            }
        }
    }
}
#method_after
private void createSubExpressions(Session session, AlarmDefinitionDb alarmDefinition, Map<String, AlarmSubExpression> alarmSubExpressions) {
    if (alarmSubExpressions != null) {
        for (Map.Entry<String, AlarmSubExpression> subEntry : alarmSubExpressions.entrySet()) {
            String subAlarmId = subEntry.getKey();
            AlarmSubExpression subExpr = subEntry.getValue();
            MetricDefinition metricDef = subExpr.getMetricDefinition();
            // Persist sub-alarm
            final DateTime now = this.getUTCNow();
            final SubAlarmDefinitionDb subAlarmDefinitionDb = new SubAlarmDefinitionDb(subAlarmId, alarmDefinition, subExpr.getFunction().name(), metricDef.name, subExpr.getOperator().name(), subExpr.getThreshold(), subExpr.getPeriod(), subExpr.getPeriods(), now, now, subExpr.isDeterministic());
            session.save(subAlarmDefinitionDb);
            // Persist sub-alarm dimensions
            if (!MapUtils.isEmpty(metricDef.dimensions)) {
                SubAlarmDefinitionDimensionDb definitionDimension;
                SubAlarmDefinitionDimensionId definitionDimensionId;
                for (Map.Entry<String, String> dimEntry : metricDef.dimensions.entrySet()) {
                    definitionDimensionId = new SubAlarmDefinitionDimensionId(subAlarmDefinitionDb, dimEntry.getKey());
                    definitionDimension = new SubAlarmDefinitionDimensionDb(definitionDimensionId, dimEntry.getValue());
                    session.save(definitionDimension);
                }
            }
        }
    }
}
#end_block

#method_before
@GET
@Timed
@Path("/count")
@Produces(MediaType.APPLICATION_JSON)
public Object getCount(@Context UriInfo uriInfo, @HeaderParam("X-Tenant-Id") String tenantId, @PathParam("alarm_id") String alarmId, @QueryParam("alarm_definition_id") String alarmDefId, @QueryParam("metric_name") String metricName, @QueryParam("metric_dimensions") String metricDimensionsStr, @QueryParam("state") AlarmState state, @QueryParam("severity") AlarmSeverity severity, @QueryParam("lifecycle_state") String lifecycleState, @QueryParam("link") String link, @QueryParam("state_updated_start_time") String stateUpdatedStartStr, @QueryParam("group_by") String groupByStr, @QueryParam("offset") String offset, @QueryParam("limit") String limit) throws Exception {
    Map<String, String> metricDimensions = Strings.isNullOrEmpty(metricDimensionsStr) ? null : Validation.parseAndValidateDimensions(metricDimensionsStr);
    MetricNameValidation.validate(metricName, false);
    DateTime stateUpdatedStart = Validation.parseAndValidateDate(stateUpdatedStartStr, "state_updated_start_time", false);
    List<String> groupBy = (Strings.isNullOrEmpty(groupByStr)) ? null : parseAndValidateGroupBy(groupByStr);
    if (offset != null) {
        Validation.parseAndValidateNumber(offset, "offset");
    }
    final int paging_limit = this.persistUtils.getLimit(limit);
    final AlarmCount resource = repo.getAlarmsCount(tenantId, alarmDefId, metricName, metricDimensions, state, severity, lifecycleState, link, stateUpdatedStart, groupBy, offset, paging_limit);
    Links.paginateAlarmCount(resource, paging_limit, uriInfo);
    return resource;
}
#method_after
@GET
@Timed
@Path("/count")
@Produces(MediaType.APPLICATION_JSON)
public Object getCount(@Context UriInfo uriInfo, @HeaderParam("X-Tenant-Id") String tenantId, @PathParam("alarm_id") String alarmId, @QueryParam("alarm_definition_id") String alarmDefId, @QueryParam("metric_name") String metricName, @QueryParam("metric_dimensions") String metricDimensionsStr, @QueryParam("state") AlarmState state, @QueryParam("severity") String severity, @QueryParam("lifecycle_state") String lifecycleState, @QueryParam("link") String link, @QueryParam("state_updated_start_time") String stateUpdatedStartStr, @QueryParam("group_by") String groupByStr, @QueryParam("offset") String offset, @QueryParam("limit") String limit) throws Exception {
    Map<String, String> metricDimensions = Strings.isNullOrEmpty(metricDimensionsStr) ? null : Validation.parseAndValidateDimensions(metricDimensionsStr);
    MetricNameValidation.validate(metricName, false);
    DateTime stateUpdatedStart = Validation.parseAndValidateDate(stateUpdatedStartStr, "state_updated_start_time", false);
    List<AlarmSeverity> severityList = Validation.parseAndValidateSeverity(severity);
    List<String> groupBy = (Strings.isNullOrEmpty(groupByStr)) ? null : parseAndValidateGroupBy(groupByStr);
    if (offset != null) {
        Validation.parseAndValidateNumber(offset, "offset");
    }
    final int paging_limit = this.persistUtils.getLimit(limit);
    final AlarmCount resource = repo.getAlarmsCount(tenantId, alarmDefId, metricName, metricDimensions, state, severityList, lifecycleState, link, stateUpdatedStart, groupBy, offset, paging_limit);
    Links.paginateAlarmCount(resource, paging_limit, uriInfo);
    return resource;
}
#end_block

#method_before
@Override
public List<Alarm> find(String tenantId, String alarmDefId, String metricName, Map<String, String> metricDimensions, AlarmState state, List<AlarmSeverity> severity, String lifecycleState, String link, DateTime stateUpdatedStart, List<String> sortBy, String offset, int limit, boolean enforceLimit) {
    logger.trace(ORM_LOG_MARKER, "find(...) entering");
    if (sortBy != null && !sortBy.isEmpty()) {
        throw Exceptions.unprocessableEntity("Sort_by is not implemented for the hibernate database type");
    }
    if (severity != null) {
        throw Exceptions.unprocessableEntity("Severity filter is not implemented for the hibernate database type");
    }
    List<Alarm> alarms = this.findInternal(tenantId, alarmDefId, metricName, metricDimensions, state, lifecycleState, link, stateUpdatedStart, offset, (3 * limit / 2), enforceLimit);
    if (limit == 0 || !enforceLimit)
        return alarms;
    if (alarms.size() > limit) {
        for (int i = alarms.size() - 1; i > limit; i--) {
            alarms.remove(i);
        }
    } else if (alarms.size() > 0) {
        while (alarms.size() < limit) {
            List<Alarm> alarms2;
            int diff = limit - alarms.size();
            String offset2 = alarms.get(alarms.size() - 1).getId();
            alarms2 = this.findInternal(tenantId, alarmDefId, metricName, metricDimensions, state, lifecycleState, link, stateUpdatedStart, offset2, (2 * diff), enforceLimit);
            if (alarms2.size() == 0)
                break;
            for (int i = 0; i < alarms2.size() && i < diff; i++) alarms.add(alarms2.get(i));
        }
    }
    return alarms;
}
#method_after
@SuppressWarnings("unchecked")
@Override
public List<Alarm> find(final String tenantId, final String alarmDefId, final String metricName, final Map<String, String> metricDimensions, final AlarmState state, final List<AlarmSeverity> severities, final String lifecycleState, final String link, final DateTime stateUpdatedStart, final List<String> sortBy, final String offset, final int limit, final boolean enforceLimit) {
    logger.trace(ORM_LOG_MARKER, "find(...) entering");
    if (sortBy != null && !sortBy.isEmpty()) {
        throw Exceptions.unprocessableEntity("Sort_by is not implemented for the hibernate database type");
    }
    if (severities != null && !severities.isEmpty()) {
        throw Exceptions.unprocessableEntity("Severity filter is not implemented for the hibernate database type");
    }
    Preconditions.checkNotNull(tenantId, "TenantId is required");
    Session session = null;
    List<Alarm> alarms = new LinkedList<>();
    try {
        final Query query;
        final String sql = String.format(FIND_ALARMS_SQL, this.getFindAlarmsSubQuery(alarmDefId, metricName, metricDimensions, state, lifecycleState, link, stateUpdatedStart, offset, limit, enforceLimit));
        try {
            query = new Function<Session, Query>() {

                @Nullable
                @Override
                public Query apply(@Nullable final Session input) {
                    assert input != null;
                    final Query query = input.createSQLQuery(sql);
                    query.setString("tenantId", tenantId);
                    if (alarmDefId != null) {
                        query.setString("alarmDefId", alarmDefId);
                    }
                    if (metricName != null) {
                        query.setString("metricName", metricName);
                    }
                    if (state != null) {
                        query.setString("state", state.name());
                    }
                    if (link != null) {
                        query.setString("link", link);
                    }
                    if (lifecycleState != null) {
                        query.setString("lifecycleState", lifecycleState);
                    }
                    if (stateUpdatedStart != null) {
                        query.setDate("stateUpdatedStart", stateUpdatedStart.toDateTime(DateTimeZone.UTC).toDate());
                    }
                    if (enforceLimit && limit > 0) {
                        query.setInteger("limit", limit + 1);
                    }
                    bindDimensionsToQuery(query, metricDimensions);
                    return query;
                }
            }.apply((session = sessionFactory.openSession()));
        } catch (Exception e) {
            logger.error("Failed to bind query {}, error is {}", sql, e.getMessage());
            throw new RuntimeException("Failed to bind query", e);
        }
        List<Object[]> alarmList = (List<Object[]>) query.list();
        if (alarmList.isEmpty()) {
            return Collections.emptyList();
        }
        alarms = createAlarms(alarmList);
    } finally {
        if (session != null) {
            session.close();
        }
    }
    return alarms;
}
#end_block

#method_before
@Override
public AlarmCount getAlarmsCount(String tenantId, String alarmDefId, String metricName, Map<String, String> metricDimensions, AlarmState state, AlarmSeverity severity, String lifecycleState, String link, DateTime stateUpdatedStart, List<String> groupBy, String offset, int limit) {
    // Not Implemented
    return null;
}
#method_after
@Override
public AlarmCount getAlarmsCount(String tenantId, String alarmDefId, String metricName, Map<String, String> metricDimensions, AlarmState state, List<AlarmSeverity> severities, String lifecycleState, String link, DateTime stateUpdatedStart, List<String> groupBy, String offset, int limit) {
    // Not Implemented
    return null;
}
#end_block

#method_before
@Override
@SuppressWarnings("unchecked")
protected void setupResources() throws Exception {
    super.setupResources();
    expression = "avg(disk_read_ops{service=hpcs.compute, instance_id=937}) >= 90";
    List<String> matchBy = Arrays.asList("service", "instance_id");
    alarmItem = new AlarmDefinition("123", "Disk Exceeds 1k Operations", null, "LOW", expression, Arrays.asList("service", "instance_id"), true, null, null, null);
    alarmActions = new ArrayList<String>();
    alarmActions.add("29387234");
    alarmActions.add("77778687");
    alarm = new AlarmDefinition("123", "Disk Exceeds 1k Operations", null, "LOW", expression, matchBy, true, alarmActions, null, null);
    service = mock(AlarmDefinitionService.class);
    when(service.create(eq("abc"), eq("Disk Exceeds 1k Operations"), any(String.class), eq("LOW"), eq(expression), eq(AlarmExpression.of(expression)), eq(matchBy), any(List.class), any(List.class), any(List.class))).thenReturn(alarm);
    repo = mock(AlarmDefinitionRepo.class);
    when(repo.findById(eq("abc"), eq("123"))).thenReturn(alarm);
    when(repo.find(anyString(), anyString(), (Map<String, String>) anyMap(), anyListOf(AlarmSeverity.class), (List<String>) anyList(), anyString(), anyInt())).thenReturn(Arrays.asList(alarmItem));
    addResources(new AlarmDefinitionResource(service, repo, new PersistUtils()));
}
#method_after
@Override
@SuppressWarnings("unchecked")
protected void setupResources() throws Exception {
    super.setupResources();
    expression = "avg(disk_read_ops{service=hpcs.compute, instance_id=937}) >= 90";
    detExpression = "count(log.error{service=test,instance_id=2},deterministic) >= 10 times 10";
    List<String> matchBy = Arrays.asList("service", "instance_id");
    alarmItem = new AlarmDefinition("123", "Disk Exceeds 1k Operations", null, "LOW", expression, Arrays.asList("service", "instance_id"), true, null, null, null);
    alarmActions = new ArrayList<String>();
    alarmActions.add("29387234");
    alarmActions.add("77778687");
    alarm = new AlarmDefinition("123", "Disk Exceeds 1k Operations", null, "LOW", expression, matchBy, true, alarmActions, null, null);
    detAlarm = new AlarmDefinition("456", "log.error", null, "LOW", detExpression, matchBy, true, alarmActions, null, null);
    service = mock(AlarmDefinitionService.class);
    when(service.create(eq("abc"), eq("Disk Exceeds 1k Operations"), any(String.class), eq("LOW"), eq(expression), eq(AlarmExpression.of(expression)), eq(matchBy), any(List.class), any(List.class), any(List.class))).thenReturn(alarm);
    when(service.create(eq("abc"), eq("log.error"), any(String.class), eq("LOW"), eq(detExpression), eq(AlarmExpression.of(detExpression)), eq(matchBy), any(List.class), any(List.class), any(List.class))).thenReturn(detAlarm);
    repo = mock(AlarmDefinitionRepo.class);
    when(repo.findById(eq("abc"), eq("123"))).thenReturn(alarm);
    when(repo.findById(eq("abc"), eq("456"))).thenReturn(detAlarm);
    when(repo.find(anyString(), anyString(), (Map<String, String>) anyMap(), anyListOf(AlarmSeverity.class), (List<String>) anyList(), anyString(), anyInt())).thenReturn(Arrays.asList(alarmItem));
    addResources(new AlarmDefinitionResource(service, repo, new PersistUtils()));
}
#end_block

#method_before
@Override
public List<Alarm> find(String tenantId, String alarmDefId, String metricName, Map<String, String> metricDimensions, AlarmState state, List<AlarmSeverity> severity, String lifecycleState, String link, DateTime stateUpdatedStart, List<String> sortBy, String offset, int limit, boolean enforceLimit) {
    StringBuilder sbWhere = new StringBuilder("(select a.id " + "from alarm as a, alarm_definition as ad " + "where ad.id = a.alarm_definition_id " + "  and ad.deleted_at is null " + "  and ad.tenant_id = :tenantId ");
    if (alarmDefId != null) {
        sbWhere.append(" and ad.id = :alarmDefId ");
    }
    if (metricName != null) {
        sbWhere.append(" and a.id in (select distinct a.id from alarm as a " + "inner join alarm_metric as am on am.alarm_id = a.id " + "inner join metric_definition_dimensions as mdd " + "  on mdd.id = am.metric_definition_dimensions_id " + "inner join (select distinct id from metric_definition " + "            where name = :metricName) as md " + "  on md.id = mdd.metric_definition_id ");
        buildJoinClauseFor(metricDimensions, sbWhere);
        sbWhere.append(")");
    } else if (metricDimensions != null) {
        sbWhere.append(" and a.id in (select distinct a.id from alarm as a " + "inner join alarm_metric as am on am.alarm_id = a.id " + "inner join metric_definition_dimensions as mdd " + "  on mdd.id = am.metric_definition_dimensions_id ");
        buildJoinClauseFor(metricDimensions, sbWhere);
        sbWhere.append(")");
    }
    if (state != null) {
        sbWhere.append(" and a.state = :state");
    }
    if (severity != null && !severity.isEmpty()) {
        sbWhere.append(" and (");
        for (int i = 0; i < severity.size(); i++) {
            sbWhere.append("ad.severity = :severity").append(i);
            if (i < severity.size() - 1) {
                sbWhere.append(" or ");
            }
        }
        sbWhere.append(") ");
    }
    if (lifecycleState != null) {
        sbWhere.append(" and a.lifecycle_state = :lifecycleState");
    }
    if (link != null) {
        sbWhere.append(" and a.link = :link");
    }
    if (stateUpdatedStart != null) {
        sbWhere.append(" and a.state_updated_at >= :stateUpdatedStart");
    }
    StringBuilder orderClause = new StringBuilder();
    if (sortBy != null && !sortBy.isEmpty()) {
        // Convert friendly names to column names
        replaceFieldName(sortBy, "alarm_id", "a.id");
        replaceFieldName(sortBy, "alarm_definition_id", "ad.id");
        replaceFieldName(sortBy, "alarm_definition_name", "ad.name");
        replaceFieldName(sortBy, "created_timestamp", "a.created_at");
        replaceFieldName(sortBy, "updated_timestamp", "a.updated_at");
        replaceFieldName(sortBy, "state_updated_timestamp", "a.state_updated_at");
        replaceFieldName(sortBy, "state", "FIELD(state, \"OK\", \"UNDETERMINED\", \"ALARM\")");
        replaceFieldName(sortBy, "severity", "FIELD(severity, \"LOW\", \"MEDIUM\", \"HIGH\", \"CRITICAL\")");
        orderClause.append(" order by ");
        orderClause.append(COMMA_JOINER.join(sortBy));
        // if alarm_id is not in the list, add it
        if (orderClause.indexOf("a.id") == -1) {
            orderClause.append(",a.id ASC");
        }
        orderClause.append(' ');
    } else {
        orderClause.append(" order by a.id ASC ");
    }
    sbWhere.append(orderClause);
    if (enforceLimit && limit > 0) {
        sbWhere.append(" limit :limit");
    }
    if (offset != null) {
        sbWhere.append(" offset ");
        sbWhere.append(offset);
        sbWhere.append(' ');
    }
    sbWhere.append(")");
    String sql = String.format(FIND_ALARMS_SQL, sbWhere, orderClause);
    try (Handle h = db.open()) {
        final Query<Map<String, Object>> q = h.createQuery(sql).bind("tenantId", tenantId);
        if (alarmDefId != null) {
            q.bind("alarmDefId", alarmDefId);
        }
        if (metricName != null) {
            q.bind("metricName", metricName);
        }
        if (state != null) {
            q.bind("state", state.name());
        }
        if (severity != null && !severity.isEmpty()) {
            for (int i = 0; i < severity.size(); i++) {
                q.bind("severity" + String.valueOf(i), severity.get(i).name());
            }
        }
        if (lifecycleState != null) {
            q.bind("lifecycleState", lifecycleState);
        }
        if (link != null) {
            q.bind("link", link);
        }
        if (stateUpdatedStart != null) {
            q.bind("stateUpdatedStart", stateUpdatedStart.toString());
        }
        if (enforceLimit && limit > 0) {
            q.bind("limit", limit + 1);
        }
        DimensionQueries.bindDimensionsToQuery(q, metricDimensions);
        final List<Map<String, Object>> rows = q.list();
        return createAlarms(tenantId, rows);
    }
}
#method_after
@Override
public List<Alarm> find(String tenantId, String alarmDefId, String metricName, Map<String, String> metricDimensions, AlarmState state, List<AlarmSeverity> severities, String lifecycleState, String link, DateTime stateUpdatedStart, List<String> sortBy, String offset, int limit, boolean enforceLimit) {
    StringBuilder sbWhere = new StringBuilder("(select a.id " + "from alarm as a, alarm_definition as ad " + "where ad.id = a.alarm_definition_id " + "  and ad.deleted_at is null " + "  and ad.tenant_id = :tenantId ");
    if (alarmDefId != null) {
        sbWhere.append(" and ad.id = :alarmDefId ");
    }
    if (metricName != null) {
        sbWhere.append(" and a.id in (select distinct a.id from alarm as a " + "inner join alarm_metric as am on am.alarm_id = a.id " + "inner join metric_definition_dimensions as mdd " + "  on mdd.id = am.metric_definition_dimensions_id " + "inner join (select distinct id from metric_definition " + "            where name = :metricName) as md " + "  on md.id = mdd.metric_definition_id ");
        buildJoinClauseFor(metricDimensions, sbWhere);
        sbWhere.append(")");
    } else if (metricDimensions != null) {
        sbWhere.append(" and a.id in (select distinct a.id from alarm as a " + "inner join alarm_metric as am on am.alarm_id = a.id " + "inner join metric_definition_dimensions as mdd " + "  on mdd.id = am.metric_definition_dimensions_id ");
        buildJoinClauseFor(metricDimensions, sbWhere);
        sbWhere.append(")");
    }
    if (state != null) {
        sbWhere.append(" and a.state = :state");
    }
    sbWhere.append(MySQLUtils.buildSeverityAndClause(severities));
    if (lifecycleState != null) {
        sbWhere.append(" and a.lifecycle_state = :lifecycleState");
    }
    if (link != null) {
        sbWhere.append(" and a.link = :link");
    }
    if (stateUpdatedStart != null) {
        sbWhere.append(" and a.state_updated_at >= :stateUpdatedStart");
    }
    StringBuilder orderClause = new StringBuilder();
    if (sortBy != null && !sortBy.isEmpty()) {
        // Convert friendly names to column names
        replaceFieldName(sortBy, "alarm_id", "a.id");
        replaceFieldName(sortBy, "alarm_definition_id", "ad.id");
        replaceFieldName(sortBy, "alarm_definition_name", "ad.name");
        replaceFieldName(sortBy, "created_timestamp", "a.created_at");
        replaceFieldName(sortBy, "updated_timestamp", "a.updated_at");
        replaceFieldName(sortBy, "state_updated_timestamp", "a.state_updated_at");
        replaceFieldName(sortBy, "state", "FIELD(state, \"OK\", \"UNDETERMINED\", \"ALARM\")");
        replaceFieldName(sortBy, "severity", "FIELD(severity, \"LOW\", \"MEDIUM\", \"HIGH\", \"CRITICAL\")");
        orderClause.append(" order by ");
        orderClause.append(COMMA_JOINER.join(sortBy));
        // if alarm_id is not in the list, add it
        if (orderClause.indexOf("a.id") == -1) {
            orderClause.append(",a.id ASC");
        }
        orderClause.append(' ');
    } else {
        orderClause.append(" order by a.id ASC ");
    }
    sbWhere.append(orderClause);
    if (enforceLimit && limit > 0) {
        sbWhere.append(" limit :limit");
    }
    if (offset != null) {
        sbWhere.append(" offset ");
        sbWhere.append(offset);
        sbWhere.append(' ');
    }
    sbWhere.append(")");
    String sql = String.format(FIND_ALARMS_SQL, sbWhere, orderClause);
    try (Handle h = db.open()) {
        final Query<Map<String, Object>> q = h.createQuery(sql).bind("tenantId", tenantId);
        if (alarmDefId != null) {
            q.bind("alarmDefId", alarmDefId);
        }
        if (metricName != null) {
            q.bind("metricName", metricName);
        }
        if (state != null) {
            q.bind("state", state.name());
        }
        MySQLUtils.bindSeverityToQuery(q, severities);
        if (lifecycleState != null) {
            q.bind("lifecycleState", lifecycleState);
        }
        if (link != null) {
            q.bind("link", link);
        }
        if (stateUpdatedStart != null) {
            q.bind("stateUpdatedStart", stateUpdatedStart.toString());
        }
        if (enforceLimit && limit > 0) {
            q.bind("limit", limit + 1);
        }
        DimensionQueries.bindDimensionsToQuery(q, metricDimensions);
        final List<Map<String, Object>> rows = q.list();
        return createAlarms(tenantId, rows);
    }
}
#end_block

#method_before
@Override
public AlarmCount getAlarmsCount(String tenantId, String alarmDefId, String metricName, Map<String, String> metricDimensions, AlarmState state, AlarmSeverity severity, String lifecycleState, String link, DateTime stateUpdatedStart, List<String> groupBy, String offset, int limit) {
    final String SELECT_CLAUSE = "SELECT count(*) as count%1$s " + " FROM alarm AS a " + " INNER JOIN alarm_definition as ad on ad.id = a.alarm_definition_id ";
    StringBuilder queryBuilder = new StringBuilder();
    String groupByStr = "";
    String metricSelect;
    if (groupBy != null) {
        groupByStr = COMMA_JOINER.join(groupBy);
        queryBuilder.append(String.format(SELECT_CLAUSE, ',' + groupByStr));
        if (groupBy.contains("metric_name") || groupBy.contains("dimension_name") || groupBy.contains("dimension_value")) {
            metricSelect = " INNER JOIN (SELECT distinct am.alarm_id%1$s " + "FROM metric_definition AS md " + "JOIN metric_definition_dimensions AS mdd on md.id = mdd.metric_definition_id " + "JOIN metric_dimension AS mdim ON mdd.metric_dimension_set_id = mdim.dimension_set_id " + "JOIN alarm_metric AS am ON am.metric_definition_dimensions_id = mdd.id)" + "AS metrics ON a.id = metrics.alarm_id ";
            String subSelect = "";
            if (groupBy.contains("metric_name")) {
                subSelect = subSelect + ",md.name AS metric_name";
            }
            if (groupBy.contains("dimension_name")) {
                subSelect = subSelect + ",mdim.name AS dimension_name";
            }
            if (groupBy.contains("dimension_value")) {
                subSelect = subSelect + ",mdim.value AS dimension_value";
            }
            queryBuilder.append(String.format(metricSelect, subSelect));
        }
    } else {
        queryBuilder.append(String.format(SELECT_CLAUSE, groupByStr));
    }
    queryBuilder.append(" INNER JOIN (SELECT a.id " + "FROM alarm AS a, alarm_definition AS ad " + "WHERE ad.id = a.alarm_definition_id " + "  AND ad.deleted_at IS NULL " + "  AND ad.tenant_id = :tenantId ");
    if (alarmDefId != null) {
        queryBuilder.append(" AND ad.id = :alarmDefId ");
    }
    if (metricName != null) {
        queryBuilder.append(" AND a.id IN (SELECT distinct a.id FROM alarm AS a " + "INNER JOIN alarm_metric AS am ON am.alarm_id = a.id " + "INNER JOIN metric_definition_dimensions AS mdd " + "  ON mdd.id = am.metric_definition_dimensions_id " + "INNER JOIN (SELECT distinct id FROM metric_definition " + "            WHERE name = :metricName) AS md " + "  ON md.id = mdd.metric_definition_id ");
        buildJoinClauseFor(metricDimensions, queryBuilder);
        queryBuilder.append(")");
    } else if (metricDimensions != null) {
        queryBuilder.append(" AND a.id IN (SELECT distinct a.id FROM alarm AS a " + "INNER JOIN alarm_metric AS am ON am.alarm_id = a.id " + "INNER JOIN metric_definition_dimensions AS mdd " + "  ON mdd.id = am.metric_definition_dimensions_id ");
        buildJoinClauseFor(metricDimensions, queryBuilder);
        queryBuilder.append(")");
    }
    if (state != null) {
        queryBuilder.append(" AND a.state = :state");
    }
    if (severity != null) {
        queryBuilder.append(" AND ad.severity = :severity");
    }
    if (lifecycleState != null) {
        queryBuilder.append(" AND a.lifecycle_state = :lifecycleState");
    }
    if (link != null) {
        queryBuilder.append(" AND a.link = :link");
    }
    if (stateUpdatedStart != null) {
        queryBuilder.append(" AND a.state_updated_at >= :stateUpdatedStart");
    }
    queryBuilder.append(") AS alarm_id_list ON alarm_id_list.id = a.id ");
    if (groupBy != null) {
        queryBuilder.append(" GROUP BY ");
        queryBuilder.append(groupByStr);
    }
    queryBuilder.append(" ORDER BY ");
    if (!Strings.isNullOrEmpty(groupByStr)) {
        queryBuilder.append(groupByStr);
    } else {
        queryBuilder.append(" a.id ");
    }
    queryBuilder.append(" LIMIT :limit");
    if (offset != null) {
        queryBuilder.append(String.format(" OFFSET %1$s ", offset));
    }
    try (Handle h = db.open()) {
        final Query<Map<String, Object>> q = h.createQuery(queryBuilder.toString()).bind("tenantId", tenantId);
        if (alarmDefId != null) {
            q.bind("alarmDefId", alarmDefId);
        }
        if (metricName != null) {
            q.bind("metricName", metricName);
        }
        if (state != null) {
            q.bind("state", state.name());
        }
        if (severity != null) {
            q.bind("severity", severity.name());
        }
        if (lifecycleState != null) {
            q.bind("lifecycleState", lifecycleState);
        }
        if (link != null) {
            q.bind("link", link);
        }
        if (stateUpdatedStart != null) {
            q.bind("stateUpdatedStart", stateUpdatedStart.toString());
        }
        q.bind("limit", limit + 1);
        DimensionQueries.bindDimensionsToQuery(q, metricDimensions);
        final List<Map<String, Object>> rows = q.list();
        return createAlarmCounts(groupBy, rows);
    }
}
#method_after
@Override
public AlarmCount getAlarmsCount(String tenantId, String alarmDefId, String metricName, Map<String, String> metricDimensions, AlarmState state, List<AlarmSeverity> severities, String lifecycleState, String link, DateTime stateUpdatedStart, List<String> groupBy, String offset, int limit) {
    final String SELECT_CLAUSE = "SELECT count(*) as count%1$s " + " FROM alarm AS a " + " INNER JOIN alarm_definition as ad on ad.id = a.alarm_definition_id ";
    StringBuilder queryBuilder = new StringBuilder();
    String groupByStr = "";
    String metricSelect;
    if (groupBy != null) {
        groupByStr = COMMA_JOINER.join(groupBy);
        queryBuilder.append(String.format(SELECT_CLAUSE, ',' + groupByStr));
        if (groupBy.contains("metric_name") || groupBy.contains("dimension_name") || groupBy.contains("dimension_value")) {
            metricSelect = " INNER JOIN (SELECT distinct am.alarm_id%1$s " + "FROM metric_definition AS md " + "JOIN metric_definition_dimensions AS mdd on md.id = mdd.metric_definition_id " + "JOIN metric_dimension AS mdim ON mdd.metric_dimension_set_id = mdim.dimension_set_id " + "JOIN alarm_metric AS am ON am.metric_definition_dimensions_id = mdd.id)" + "AS metrics ON a.id = metrics.alarm_id ";
            String subSelect = "";
            if (groupBy.contains("metric_name")) {
                subSelect = subSelect + ",md.name AS metric_name";
            }
            if (groupBy.contains("dimension_name")) {
                subSelect = subSelect + ",mdim.name AS dimension_name";
            }
            if (groupBy.contains("dimension_value")) {
                subSelect = subSelect + ",mdim.value AS dimension_value";
            }
            queryBuilder.append(String.format(metricSelect, subSelect));
        }
    } else {
        queryBuilder.append(String.format(SELECT_CLAUSE, groupByStr));
    }
    queryBuilder.append(" INNER JOIN (SELECT a.id " + "FROM alarm AS a, alarm_definition AS ad " + "WHERE ad.id = a.alarm_definition_id " + "  AND ad.deleted_at IS NULL " + "  AND ad.tenant_id = :tenantId ");
    if (alarmDefId != null) {
        queryBuilder.append(" AND ad.id = :alarmDefId ");
    }
    if (metricName != null) {
        queryBuilder.append(" AND a.id IN (SELECT distinct a.id FROM alarm AS a " + "INNER JOIN alarm_metric AS am ON am.alarm_id = a.id " + "INNER JOIN metric_definition_dimensions AS mdd " + "  ON mdd.id = am.metric_definition_dimensions_id " + "INNER JOIN (SELECT distinct id FROM metric_definition " + "            WHERE name = :metricName) AS md " + "  ON md.id = mdd.metric_definition_id ");
        buildJoinClauseFor(metricDimensions, queryBuilder);
        queryBuilder.append(")");
    } else if (metricDimensions != null) {
        queryBuilder.append(" AND a.id IN (SELECT distinct a.id FROM alarm AS a " + "INNER JOIN alarm_metric AS am ON am.alarm_id = a.id " + "INNER JOIN metric_definition_dimensions AS mdd " + "  ON mdd.id = am.metric_definition_dimensions_id ");
        buildJoinClauseFor(metricDimensions, queryBuilder);
        queryBuilder.append(")");
    }
    if (state != null) {
        queryBuilder.append(" AND a.state = :state");
    }
    queryBuilder.append(MySQLUtils.buildSeverityAndClause(severities));
    if (lifecycleState != null) {
        queryBuilder.append(" AND a.lifecycle_state = :lifecycleState");
    }
    if (link != null) {
        queryBuilder.append(" AND a.link = :link");
    }
    if (stateUpdatedStart != null) {
        queryBuilder.append(" AND a.state_updated_at >= :stateUpdatedStart");
    }
    queryBuilder.append(") AS alarm_id_list ON alarm_id_list.id = a.id ");
    if (groupBy != null) {
        queryBuilder.append(" GROUP BY ");
        queryBuilder.append(groupByStr);
    }
    queryBuilder.append(" ORDER BY ");
    if (!Strings.isNullOrEmpty(groupByStr)) {
        queryBuilder.append(groupByStr);
    } else {
        queryBuilder.append(" a.id ");
    }
    queryBuilder.append(" LIMIT :limit");
    if (offset != null) {
        queryBuilder.append(String.format(" OFFSET %1$s ", offset));
    }
    try (Handle h = db.open()) {
        final Query<Map<String, Object>> q = h.createQuery(queryBuilder.toString()).bind("tenantId", tenantId);
        if (alarmDefId != null) {
            q.bind("alarmDefId", alarmDefId);
        }
        if (metricName != null) {
            q.bind("metricName", metricName);
        }
        if (state != null) {
            q.bind("state", state.name());
        }
        MySQLUtils.bindSeverityToQuery(q, severities);
        if (lifecycleState != null) {
            q.bind("lifecycleState", lifecycleState);
        }
        if (link != null) {
            q.bind("link", link);
        }
        if (stateUpdatedStart != null) {
            q.bind("stateUpdatedStart", stateUpdatedStart.toString());
        }
        q.bind("limit", limit + 1);
        DimensionQueries.bindDimensionsToQuery(q, metricDimensions);
        final List<Map<String, Object>> rows = q.list();
        return createAlarmCounts(groupBy, rows);
    }
}
#end_block

#method_before
@BeforeMethod
protected void beforeMethod() {
    handle.execute("SET foreign_key_checks = 0;");
    handle.execute("truncate table sub_alarm");
    handle.execute("truncate table sub_alarm_definition");
    handle.execute("truncate table alarm_action");
    handle.execute("truncate table sub_alarm_definition_dimension");
    handle.execute("truncate table alarm_definition");
    handle.execute("insert into alarm_definition (id, tenant_id, name, severity, expression, match_by, actions_enabled, created_at, updated_at, deleted_at) " + "values ('123', 'bob', '90% CPU', 'LOW', 'avg(hpcs.compute{flavor_id=777, image_id=888, metric_name=cpu, device=1}) > 10', 'flavor_id,image_id', 1, NOW(), NOW(), NULL)");
    handle.execute("insert into sub_alarm_definition (id, alarm_definition_id, function, metric_name, operator, threshold, period, periods, created_at, updated_at) " + "values ('111', '123', 'avg', 'hpcs.compute', 'GT', 10, 60, 1, NOW(), NOW())");
    handle.execute("insert into sub_alarm_definition_dimension values ('111', 'flavor_id', '777')");
    handle.execute("insert into sub_alarm_definition_dimension values ('111', 'image_id', '888')");
    handle.execute("insert into sub_alarm_definition_dimension values ('111', 'metric_name', 'cpu')");
    handle.execute("insert into sub_alarm_definition_dimension values ('111', 'device', '1')");
    handle.execute("insert into alarm_action values ('123', 'ALARM', '29387234')");
    handle.execute("insert into alarm_action values ('123', 'ALARM', '77778687')");
    handle.execute("insert into alarm_definition (id, tenant_id, name, severity, expression, match_by, actions_enabled, created_at, updated_at, deleted_at) " + "values ('234', 'bob', '50% CPU', 'HIGH', 'avg(hpcs.compute{flavor_id=777, image_id=888, metric_name=mem}) > 20 and avg(hpcs.compute) < 100', 'flavor_id,image_id', 1, NOW(), NOW(), NULL)");
    handle.execute("insert into sub_alarm_definition (id, alarm_definition_id, function, metric_name, operator, threshold, period, periods, created_at, updated_at) " + "values ('222', '234', 'avg', 'hpcs.compute', 'GT', 20, 60, 1, NOW(), NOW())");
    handle.execute("insert into sub_alarm_definition (id, alarm_definition_id, function, metric_name, operator, threshold, period, periods, created_at, updated_at) " + "values ('223', '234', 'avg', 'hpcs.compute', 'LT', 100, 60, 1, NOW(), NOW())");
    handle.execute("insert into sub_alarm_definition_dimension values ('222', 'flavor_id', '777')");
    handle.execute("insert into sub_alarm_definition_dimension values ('222', 'image_id', '888')");
    handle.execute("insert into sub_alarm_definition_dimension values ('222', 'metric_name', 'mem')");
    handle.execute("insert into alarm_action values ('234', 'ALARM', '29387234')");
    handle.execute("insert into alarm_action values ('234', 'ALARM', '77778687')");
    alarmDef_123 = new AlarmDefinition("123", "90% CPU", null, "LOW", "avg(hpcs.compute{flavor_id=777, image_id=888, metric_name=cpu, device=1}) > 10", Arrays.asList("flavor_id", "image_id"), true, Arrays.asList("29387234", "77778687"), Collections.<String>emptyList(), Collections.<String>emptyList());
    alarmDef_234 = new AlarmDefinition("234", "50% CPU", null, "HIGH", "avg(hpcs.compute{flavor_id=777, image_id=888, metric_name=mem}) > 20 and avg(hpcs.compute) < 100", Arrays.asList("flavor_id", "image_id"), true, Arrays.asList("29387234", "77778687"), Collections.<String>emptyList(), Collections.<String>emptyList());
}
#method_after
@BeforeMethod
protected void beforeMethod() {
    handle.execute("SET foreign_key_checks = 0;");
    handle.execute("truncate table sub_alarm");
    handle.execute("truncate table sub_alarm_definition");
    handle.execute("truncate table alarm_action");
    handle.execute("truncate table sub_alarm_definition_dimension");
    handle.execute("truncate table alarm_definition");
    handle.execute("insert into alarm_definition (id, tenant_id, name, severity, expression, match_by, actions_enabled, created_at, updated_at, deleted_at) " + "values ('123', 'bob', '90% CPU', 'LOW', 'avg(hpcs.compute{flavor_id=777, image_id=888, metric_name=cpu, device=1}) > 10', 'flavor_id,image_id', 1, NOW(), NOW(), NULL)");
    handle.execute("insert into sub_alarm_definition (id, alarm_definition_id, function, metric_name, operator, threshold, period, periods, created_at, updated_at) " + "values ('111', '123', 'avg', 'hpcs.compute', 'GT', 10, 60, 1, NOW(), NOW())");
    handle.execute("insert into sub_alarm_definition_dimension values ('111', 'flavor_id', '777')");
    handle.execute("insert into sub_alarm_definition_dimension values ('111', 'image_id', '888')");
    handle.execute("insert into sub_alarm_definition_dimension values ('111', 'metric_name', 'cpu')");
    handle.execute("insert into sub_alarm_definition_dimension values ('111', 'device', '1')");
    handle.execute("insert into alarm_action values ('123', 'ALARM', '29387234')");
    handle.execute("insert into alarm_action values ('123', 'ALARM', '77778687')");
    handle.execute("insert into alarm_definition (id, tenant_id, name, severity, expression, match_by, actions_enabled, created_at, updated_at, deleted_at) " + "values ('234', 'bob', '50% CPU', 'HIGH', 'avg(hpcs.compute{flavor_id=777, image_id=888, metric_name=mem}) > 20 and avg(hpcs.compute) < 100', 'flavor_id,image_id', 1, NOW(), NOW(), NULL)");
    handle.execute("insert into sub_alarm_definition (id, alarm_definition_id, function, metric_name, operator, threshold, period, periods, created_at, updated_at) " + "values ('222', '234', 'avg', 'hpcs.compute', 'GT', 20, 60, 1, NOW(), NOW())");
    handle.execute("insert into sub_alarm_definition (id, alarm_definition_id, function, metric_name, operator, threshold, period, periods, created_at, updated_at) " + "values ('223', '234', 'avg', 'hpcs.compute', 'LT', 100, 60, 1, NOW(), NOW())");
    handle.execute("insert into sub_alarm_definition_dimension values ('222', 'flavor_id', '777')");
    handle.execute("insert into sub_alarm_definition_dimension values ('222', 'image_id', '888')");
    handle.execute("insert into sub_alarm_definition_dimension values ('222', 'metric_name', 'mem')");
    handle.execute("insert into alarm_action values ('234', 'ALARM', '29387234')");
    handle.execute("insert into alarm_action values ('234', 'ALARM', '77778687')");
    handle.execute("insert into alarm_definition (id, tenant_id, name, severity, expression, match_by, actions_enabled, created_at, updated_at, deleted_at) " + "values ('345', 'bob', 'Testing Critical', 'CRITICAL', 'avg(test_metric{flavor_id=777, image_id=888, metric_name=mem}) > 20 and avg(test_metric) < 100', 'flavor_id,image_id', 1, NOW(), NOW(), NULL)");
    handle.execute("insert into sub_alarm_definition (id, alarm_definition_id, function, metric_name, operator, threshold, period, periods, created_at, updated_at) " + "values ('333', '345', 'avg', 'test_metric', 'GT', 20, 60, 1, NOW(), NOW())");
    handle.execute("insert into sub_alarm_definition (id, alarm_definition_id, function, metric_name, operator, threshold, period, periods, created_at, updated_at) " + "values ('334', '345', 'avg', 'test_metric', 'LT', 100, 60, 1, NOW(), NOW())");
    handle.execute("insert into sub_alarm_definition_dimension values ('333', 'flavor_id', '777')");
    handle.execute("insert into sub_alarm_definition_dimension values ('333', 'image_id', '888')");
    handle.execute("insert into sub_alarm_definition_dimension values ('333', 'metric_name', 'mem')");
    handle.execute("insert into alarm_action values ('345', 'ALARM', '29387234')");
    handle.execute("insert into alarm_action values ('345', 'ALARM', '77778687')");
    alarmDef_123 = new AlarmDefinition("123", "90% CPU", null, "LOW", "avg(hpcs.compute{flavor_id=777, image_id=888, metric_name=cpu, device=1}) > 10", Arrays.asList("flavor_id", "image_id"), true, Arrays.asList("29387234", "77778687"), Collections.<String>emptyList(), Collections.<String>emptyList());
    alarmDef_234 = new AlarmDefinition("234", "50% CPU", null, "HIGH", "avg(hpcs.compute{flavor_id=777, image_id=888, metric_name=mem}) > 20 and avg(hpcs.compute) < 100", Arrays.asList("flavor_id", "image_id"), true, Arrays.asList("29387234", "77778687"), Collections.<String>emptyList(), Collections.<String>emptyList());
    alarmDef_345 = new AlarmDefinition("345", "Testing Critical", null, "CRITICAL", "avg(test_metric{flavor_id=777, image_id=888, metric_name=mem}) > 20 and avg(test_metric) < 100", Arrays.asList("flavor_id", "image_id"), true, Arrays.asList("29387234", "77778687"), Collections.<String>emptyList(), Collections.<String>emptyList());
}
#end_block

#method_before
public void shouldFindBySeverity() {
    assertEquals(Arrays.asList(alarmDef_234), repo.find("bob", null, null, Lists.newArrayList(AlarmSeverity.HIGH), null, null, 1));
    assertEquals(0, repo.find("bob", null, null, Lists.newArrayList(AlarmSeverity.CRITICAL), null, null, 1).size());
}
#method_after
public void shouldFindBySeverity() {
    assertEquals(Arrays.asList(alarmDef_234), repo.find("bob", null, null, Lists.newArrayList(AlarmSeverity.HIGH), null, null, 1));
    assertEquals(0, repo.find("bob", null, null, Lists.newArrayList(AlarmSeverity.CRITICAL), null, null, 1).size());
    assertEquals(Arrays.asList(alarmDef_234, alarmDef_345), repo.find("bob", null, null, Lists.newArrayList(AlarmSeverity.HIGH, AlarmSeverity.CRITICAL), null, null, 2));
}
#end_block

#method_before
@Override
@SuppressWarnings("unchecked")
public List<AlarmDefinition> find(String tenantId, String name, Map<String, String> dimensions, List<AlarmSeverity> severity, List<String> sortBy, String offset, int limit) {
    logger.trace(ORM_LOG_MARKER, "find(...) entering...");
    if (sortBy != null && !sortBy.isEmpty()) {
        throw Exceptions.unprocessableEntity("Sort_by is not implemented for the hibernate database type");
    }
    if (severity != null) {
        throw Exceptions.unprocessableEntity("Severity is not implemented for the hibernate database type");
    }
    Session session = null;
    List<AlarmDefinition> resultSet = Lists.newArrayList();
    // TODO introduce criteria here, will make code significantly better
    String query = "  SELECT t.id, t.tenant_id, t.name, t.description, t.expression, t.severity, t.match_by, " + "t.actions_enabled, aa.alarm_state AS states, aa.action_id AS notificationIds " + "FROM (SELECT distinct ad.id, ad.tenant_id, ad.name, ad.description, ad.expression, " + "ad.severity, ad.match_by, ad.actions_enabled, ad.created_at, ad.updated_at, ad.deleted_at " + "FROM alarm_definition AS ad LEFT OUTER JOIN sub_alarm_definition AS sad ON ad.id = sad.alarm_definition_id " + "LEFT OUTER JOIN sub_alarm_definition_dimension AS dim ON sad.id = dim.sub_alarm_definition_id %1$s " + "WHERE ad.tenant_id = :tenantId AND ad.deleted_at IS NULL %2$s ORDER BY ad.id %3$s) AS t " + "LEFT OUTER JOIN alarm_action AS aa ON t.id = aa.alarm_definition_id ORDER BY t.id, t.created_at";
    StringBuilder sbWhere = new StringBuilder();
    if (name != null) {
        sbWhere.append(" and ad.name = :name");
    }
    if (offset != null && !offset.equals("0")) {
        sbWhere.append(" and ad.id > :offset");
    }
    String limitPart = "";
    if (limit > 0) {
        limitPart = " limit :limit";
    }
    String sql = String.format(query, SubAlarmDefinitionQueries.buildJoinClauseFor(dimensions), sbWhere, limitPart);
    try {
        session = sessionFactory.openSession();
        final Query qAlarmDefinition = session.createSQLQuery(sql).setString("tenantId", tenantId).setResultTransformer(ALARM_DEF_RESULT_TRANSFORMER);
        if (name != null) {
            qAlarmDefinition.setString("name", name);
        }
        if (offset != null && !offset.equals("0")) {
            qAlarmDefinition.setString("offset", offset);
        }
        if (limit > 0) {
            qAlarmDefinition.setInteger("limit", limit + 1);
        }
        this.bindDimensionsToQuery(qAlarmDefinition, dimensions);
        final List<Map<?, ?>> alarmDefinitionDbList = qAlarmDefinition.list();
        resultSet = CollectionUtils.isEmpty(alarmDefinitionDbList) ? Lists.<AlarmDefinition>newArrayList() : this.createAlarmDefinitions(alarmDefinitionDbList);
    } finally {
        if (session != null) {
            session.close();
        }
    }
    return resultSet;
}
#method_after
@Override
@SuppressWarnings("unchecked")
public List<AlarmDefinition> find(String tenantId, String name, Map<String, String> dimensions, List<AlarmSeverity> severities, List<String> sortBy, String offset, int limit) {
    logger.trace(ORM_LOG_MARKER, "find(...) entering...");
    if (sortBy != null && !sortBy.isEmpty()) {
        throw Exceptions.unprocessableEntity("Sort_by is not implemented for the hibernate database type");
    }
    if (severities != null && !severities.isEmpty()) {
        throw Exceptions.unprocessableEntity("Severity is not implemented for the hibernate database type");
    }
    Session session = null;
    List<AlarmDefinition> resultSet = Lists.newArrayList();
    // TODO introduce criteria here, will make code significantly better
    String query = "  SELECT t.id, t.tenant_id, t.name, t.description, t.expression, t.severity, t.match_by, " + "t.actions_enabled, aa.alarm_state AS states, aa.action_id AS notificationIds " + "FROM (SELECT distinct ad.id, ad.tenant_id, ad.name, ad.description, ad.expression, " + "ad.severity, ad.match_by, ad.actions_enabled, ad.created_at, ad.updated_at, ad.deleted_at " + "FROM alarm_definition AS ad LEFT OUTER JOIN sub_alarm_definition AS sad ON ad.id = sad.alarm_definition_id " + "LEFT OUTER JOIN sub_alarm_definition_dimension AS dim ON sad.id = dim.sub_alarm_definition_id %1$s " + "WHERE ad.tenant_id = :tenantId AND ad.deleted_at IS NULL %2$s ORDER BY ad.id %3$s) AS t " + "LEFT OUTER JOIN alarm_action AS aa ON t.id = aa.alarm_definition_id ORDER BY t.id, t.created_at";
    StringBuilder sbWhere = new StringBuilder();
    if (name != null) {
        sbWhere.append(" and ad.name = :name");
    }
    if (offset != null && !offset.equals("0")) {
        sbWhere.append(" and ad.id > :offset");
    }
    String limitPart = "";
    if (limit > 0) {
        limitPart = " limit :limit";
    }
    String sql = String.format(query, SubAlarmDefinitionQueries.buildJoinClauseFor(dimensions), sbWhere, limitPart);
    try {
        session = sessionFactory.openSession();
        final Query qAlarmDefinition = session.createSQLQuery(sql).setString("tenantId", tenantId).setResultTransformer(ALARM_DEF_RESULT_TRANSFORMER);
        if (name != null) {
            qAlarmDefinition.setString("name", name);
        }
        if (offset != null && !offset.equals("0")) {
            qAlarmDefinition.setString("offset", offset);
        }
        if (limit > 0) {
            qAlarmDefinition.setInteger("limit", limit + 1);
        }
        this.bindDimensionsToQuery(qAlarmDefinition, dimensions);
        final List<Map<?, ?>> alarmDefinitionDbList = qAlarmDefinition.list();
        resultSet = CollectionUtils.isEmpty(alarmDefinitionDbList) ? Lists.<AlarmDefinition>newArrayList() : this.createAlarmDefinitions(alarmDefinitionDbList);
    } finally {
        if (session != null) {
            session.close();
        }
    }
    return resultSet;
}
#end_block

#method_before
@Override
@SuppressWarnings("unchecked")
public Map<String, AlarmSubExpression> findSubExpressions(String alarmDefId) {
    logger.trace(ORM_LOG_MARKER, "findSubExpressions(...) entering...");
    Session session = null;
    Map<String, AlarmSubExpression> subExpressions = Maps.newHashMap();
    try {
        session = sessionFactory.openSession();
        List<SubAlarmDefinitionDb> subAlarmDefList = session.getNamedQuery(SubAlarmDefinitionDb.Queries.BY_ALARMDEFINITION_ID).setString("id", alarmDefId).list();
        Query querySybAlarmDefDimension = session.getNamedQuery(SubAlarmDefinitionDb.Queries.BY_ALARMDEFINITIONDIMENSION_SUBEXPRESSION_ID).setString("id", alarmDefId);
        List<SubAlarmDefinitionDimensionDb> subAlarmDefDimensionList = querySybAlarmDefDimension.list();
        Map<String, Map<String, String>> subAlarmDefDimensionMapExpression = mapAlarmDefDimensionExpression(subAlarmDefDimensionList);
        for (SubAlarmDefinitionDb subAlarmDef : subAlarmDefList) {
            String id = subAlarmDef.getId();
            AggregateFunction function = AggregateFunction.fromJson(subAlarmDef.getFunction());
            String metricName = subAlarmDef.getMetricName();
            AlarmOperator operator = AlarmOperator.fromJson(subAlarmDef.getOperator());
            double threshold = subAlarmDef.getThreshold();
            int period = subAlarmDef.getPeriod();
            int periods = subAlarmDef.getPeriods();
            Map<String, String> dimensions = Collections.emptyMap();
            if (subAlarmDefDimensionMapExpression.containsKey(id)) {
                dimensions = subAlarmDefDimensionMapExpression.get(id);
            }
            subExpressions.put(id, new AlarmSubExpression(function, new MetricDefinition(metricName, dimensions), operator, threshold, period, periods));
        }
        return subExpressions;
    } finally {
        if (session != null) {
            session.close();
        }
    }
}
#method_after
@Override
@SuppressWarnings("unchecked")
public Map<String, AlarmSubExpression> findSubExpressions(String alarmDefId) {
    logger.trace(ORM_LOG_MARKER, "findSubExpressions(...) entering...");
    Session session = null;
    Map<String, AlarmSubExpression> subExpressions = Maps.newHashMap();
    try {
        session = sessionFactory.openSession();
        List<SubAlarmDefinitionDb> subAlarmDefList = session.getNamedQuery(SubAlarmDefinitionDb.Queries.BY_ALARMDEFINITION_ID).setString("id", alarmDefId).list();
        Query querySybAlarmDefDimension = session.getNamedQuery(SubAlarmDefinitionDb.Queries.BY_ALARMDEFINITIONDIMENSION_SUBEXPRESSION_ID).setString("id", alarmDefId);
        List<SubAlarmDefinitionDimensionDb> subAlarmDefDimensionList = querySybAlarmDefDimension.list();
        Map<String, Map<String, String>> subAlarmDefDimensionMapExpression = mapAlarmDefDimensionExpression(subAlarmDefDimensionList);
        for (SubAlarmDefinitionDb subAlarmDef : subAlarmDefList) {
            String id = subAlarmDef.getId();
            AggregateFunction function = AggregateFunction.fromJson(subAlarmDef.getFunction());
            String metricName = subAlarmDef.getMetricName();
            AlarmOperator operator = AlarmOperator.fromJson(subAlarmDef.getOperator());
            double threshold = subAlarmDef.getThreshold();
            int period = subAlarmDef.getPeriod();
            int periods = subAlarmDef.getPeriods();
            boolean isDeterministic = subAlarmDef.isDeterministic();
            Map<String, String> dimensions = Collections.emptyMap();
            if (subAlarmDefDimensionMapExpression.containsKey(id)) {
                dimensions = subAlarmDefDimensionMapExpression.get(id);
            }
            subExpressions.put(id, new AlarmSubExpression(function, new MetricDefinition(metricName, dimensions), operator, threshold, period, periods, isDeterministic));
        }
        return subExpressions;
    } finally {
        if (session != null) {
            session.close();
        }
    }
}
#end_block

#method_before
private void updateChangedSubAlarms(final Map<String, AlarmSubExpression> changedSubAlarms, final Session session) {
    if (!MapUtils.isEmpty(changedSubAlarms))
        for (Map.Entry<String, AlarmSubExpression> entry : changedSubAlarms.entrySet()) {
            final AlarmSubExpression sa = entry.getValue();
            final String subAlarmDefinitionId = entry.getKey();
            SubAlarmDefinitionDb subAlarmDefinitionDb = session.get(SubAlarmDefinitionDb.class, subAlarmDefinitionId);
            subAlarmDefinitionDb.setOperator(sa.getOperator().name());
            subAlarmDefinitionDb.setThreshold(sa.getThreshold());
            subAlarmDefinitionDb.setUpdatedAt(this.getUTCNow());
            session.saveOrUpdate(subAlarmDefinitionDb);
        }
}
#method_after
private void updateChangedSubAlarms(final Map<String, AlarmSubExpression> changedSubAlarms, final Session session) {
    if (!MapUtils.isEmpty(changedSubAlarms))
        for (Map.Entry<String, AlarmSubExpression> entry : changedSubAlarms.entrySet()) {
            final AlarmSubExpression sa = entry.getValue();
            final String subAlarmDefinitionId = entry.getKey();
            SubAlarmDefinitionDb subAlarmDefinitionDb = session.get(SubAlarmDefinitionDb.class, subAlarmDefinitionId);
            subAlarmDefinitionDb.setOperator(sa.getOperator().name());
            subAlarmDefinitionDb.setThreshold(sa.getThreshold());
            subAlarmDefinitionDb.setUpdatedAt(this.getUTCNow());
            subAlarmDefinitionDb.setDeterministic(sa.isDeterministic());
            session.saveOrUpdate(subAlarmDefinitionDb);
        }
}
#end_block

#method_before
private AlarmDefinitionDb updateAlarmDefinition(final String tenantId, final String id, final String name, final String description, final String expression, final List<String> matchBy, final String severity, final boolean actionsEnabled, final Session session) {
    final AlarmDefinitionDb alarmDefinitionDb = (AlarmDefinitionDb) session.getNamedQuery(AlarmDefinitionDb.Queries.FIND_BY_TENANT_ID_AND_ID).setString("tenantId", tenantId).setString("id", id).uniqueResult();
    alarmDefinitionDb.setName(name);
    alarmDefinitionDb.setDescription(description);
    alarmDefinitionDb.setExpression(expression);
    alarmDefinitionDb.setMatchBy(matchBy == null || Iterables.isEmpty(matchBy) ? null : COMMA_JOINER.join(matchBy));
    alarmDefinitionDb.setSeverity(AlarmSeverity.valueOf(severity));
    alarmDefinitionDb.setActionsEnabled(actionsEnabled);
    session.saveOrUpdate(alarmDefinitionDb);
    return alarmDefinitionDb;
}
#method_after
private AlarmDefinitionDb updateAlarmDefinition(final String tenantId, final String id, final String name, final String description, final String expression, final List<String> matchBy, final String severity, final boolean actionsEnabled, final Session session) {
    final AlarmDefinitionDb alarmDefinitionDb = (AlarmDefinitionDb) session.getNamedQuery(AlarmDefinitionDb.Queries.FIND_BY_TENANT_ID_AND_ID).setString("tenantId", tenantId).setString("id", id).uniqueResult();
    alarmDefinitionDb.setName(name);
    alarmDefinitionDb.setDescription(description);
    alarmDefinitionDb.setExpression(expression);
    alarmDefinitionDb.setMatchBy(matchBy == null || Iterables.isEmpty(matchBy) ? null : COMMA_JOINER.join(matchBy));
    alarmDefinitionDb.setSeverity(AlarmSeverity.valueOf(severity));
    alarmDefinitionDb.setActionsEnabled(actionsEnabled);
    alarmDefinitionDb.setUpdatedAt(this.getUTCNow());
    session.saveOrUpdate(alarmDefinitionDb);
    return alarmDefinitionDb;
}
#end_block

#method_before
private void createSubExpressions(Session session, AlarmDefinitionDb alarmDefinition, Map<String, AlarmSubExpression> alarmSubExpressions) {
    if (alarmSubExpressions != null) {
        for (Map.Entry<String, AlarmSubExpression> subEntry : alarmSubExpressions.entrySet()) {
            String subAlarmId = subEntry.getKey();
            AlarmSubExpression subExpr = subEntry.getValue();
            MetricDefinition metricDef = subExpr.getMetricDefinition();
            // Persist sub-alarm
            final DateTime now = this.getUTCNow();
            SubAlarmDefinitionDb subAlarmDefinitionDb = new SubAlarmDefinitionDb(subAlarmId, alarmDefinition, subExpr.getFunction().name(), metricDef.name, subExpr.getOperator().name(), subExpr.getThreshold(), subExpr.getPeriod(), subExpr.getPeriods(), now, now);
            session.save(subAlarmDefinitionDb);
            // Persist sub-alarm dimensions
            if (!MapUtils.isEmpty(metricDef.dimensions)) {
                SubAlarmDefinitionDimensionDb definitionDimension;
                SubAlarmDefinitionDimensionId definitionDimensionId;
                for (Map.Entry<String, String> dimEntry : metricDef.dimensions.entrySet()) {
                    definitionDimensionId = new SubAlarmDefinitionDimensionId(subAlarmDefinitionDb, dimEntry.getKey());
                    definitionDimension = new SubAlarmDefinitionDimensionDb(definitionDimensionId, dimEntry.getValue());
                    session.save(definitionDimension);
                }
            }
        }
    }
}
#method_after
private void createSubExpressions(Session session, AlarmDefinitionDb alarmDefinition, Map<String, AlarmSubExpression> alarmSubExpressions) {
    if (alarmSubExpressions != null) {
        for (Map.Entry<String, AlarmSubExpression> subEntry : alarmSubExpressions.entrySet()) {
            String subAlarmId = subEntry.getKey();
            AlarmSubExpression subExpr = subEntry.getValue();
            MetricDefinition metricDef = subExpr.getMetricDefinition();
            // Persist sub-alarm
            final DateTime now = this.getUTCNow();
            final SubAlarmDefinitionDb subAlarmDefinitionDb = new SubAlarmDefinitionDb(subAlarmId, alarmDefinition, subExpr.getFunction().name(), metricDef.name, subExpr.getOperator().name(), subExpr.getThreshold(), subExpr.getPeriod(), subExpr.getPeriods(), now, now, subExpr.isDeterministic());
            session.save(subAlarmDefinitionDb);
            // Persist sub-alarm dimensions
            if (!MapUtils.isEmpty(metricDef.dimensions)) {
                SubAlarmDefinitionDimensionDb definitionDimension;
                SubAlarmDefinitionDimensionId definitionDimensionId;
                for (Map.Entry<String, String> dimEntry : metricDef.dimensions.entrySet()) {
                    definitionDimensionId = new SubAlarmDefinitionDimensionId(subAlarmDefinitionDb, dimEntry.getKey());
                    definitionDimension = new SubAlarmDefinitionDimensionDb(definitionDimensionId, dimEntry.getValue());
                    session.save(definitionDimension);
                }
            }
        }
    }
}
#end_block

#method_before
@SuppressWarnings("unchecked")
@Override
public List<AlarmDefinition> find(String tenantId, String name, Map<String, String> dimensions, List<AlarmSeverity> severity, List<String> sortBy, String offset, int limit) {
    try (Handle h = db.open()) {
        String query = "  SELECT t.id, t.tenant_id, t.name, t.description, t.expression, t.severity, t.match_by," + "     t.actions_enabled, t.created_at, t.updated_at, t.deleted_at, " + "     GROUP_CONCAT(aa.alarm_state) AS states, " + "     GROUP_CONCAT(aa.action_id) AS notificationIds " + "FROM (SELECT distinct ad.id, ad.tenant_id, ad.name, ad.description, ad.expression," + "        ad.severity, ad.match_by, ad.actions_enabled, ad.created_at, " + "        ad.updated_at, ad.deleted_at " + "      FROM alarm_definition AS ad " + "      LEFT OUTER JOIN sub_alarm_definition AS sad ON ad.id = sad.alarm_definition_id " + "      LEFT OUTER JOIN sub_alarm_definition_dimension AS dim ON sad.id = dim.sub_alarm_definition_id %1$s " + "      WHERE ad.tenant_id = :tenantId AND ad.deleted_at IS NULL %2$s) AS t " + "LEFT OUTER JOIN alarm_action AS aa ON t.id = aa.alarm_definition_id " + "GROUP BY t.id %3$s %4$s %5$s";
        StringBuilder sbWhere = new StringBuilder();
        if (name != null) {
            sbWhere.append(" and ad.name = :name");
        }
        if (severity != null && !severity.isEmpty()) {
            sbWhere.append(" AND (");
            for (int i = 0; i < severity.size(); i++) {
                sbWhere.append("ad.severity = :severity").append(i);
                if (i < severity.size() - 1) {
                    sbWhere.append(" OR ");
                }
            }
            sbWhere.append(") ");
        }
        String orderByPart = "";
        if (sortBy != null && !sortBy.isEmpty()) {
            orderByPart = " order by " + COMMA_JOINER.join(sortBy);
            if (!orderByPart.contains("id")) {
                orderByPart = orderByPart + ",id";
            }
        } else {
            orderByPart = " order by id ";
        }
        String limitPart = "";
        if (limit > 0) {
            limitPart = " limit :limit";
        }
        String offsetPart = "";
        if (offset != null) {
            offsetPart = " offset " + offset + ' ';
        }
        String sql = String.format(query, SubAlarmDefinitionQueries.buildJoinClauseFor(dimensions), sbWhere, orderByPart, limitPart, offsetPart);
        Query<?> q = h.createQuery(sql);
        q.bind("tenantId", tenantId);
        if (name != null) {
            q.bind("name", name);
        }
        if (severity != null && severity.size() > 0) {
            for (int i = 0; i < severity.size(); i++) {
                q.bind("severity" + String.valueOf(i), severity.get(i).name());
            }
        }
        if (limit > 0) {
            q.bind("limit", limit + 1);
        }
        q.registerMapper(new AlarmDefinitionMapper());
        q = q.mapTo(AlarmDefinition.class);
        SubAlarmDefinitionQueries.bindDimensionsToQuery(q, dimensions);
        List<AlarmDefinition> resultSet = (List<AlarmDefinition>) q.list();
        return resultSet;
    }
}
#method_after
@SuppressWarnings("unchecked")
@Override
public List<AlarmDefinition> find(String tenantId, String name, Map<String, String> dimensions, List<AlarmSeverity> severities, List<String> sortBy, String offset, int limit) {
    try (Handle h = db.open()) {
        String query = "  SELECT t.id, t.tenant_id, t.name, t.description, t.expression, t.severity, t.match_by," + "     t.actions_enabled, t.created_at, t.updated_at, t.deleted_at, " + "     GROUP_CONCAT(aa.alarm_state) AS states, " + "     GROUP_CONCAT(aa.action_id) AS notificationIds " + "FROM (SELECT distinct ad.id, ad.tenant_id, ad.name, ad.description, ad.expression," + "        ad.severity, ad.match_by, ad.actions_enabled, ad.created_at, " + "        ad.updated_at, ad.deleted_at " + "      FROM alarm_definition AS ad " + "      LEFT OUTER JOIN sub_alarm_definition AS sad ON ad.id = sad.alarm_definition_id " + "      LEFT OUTER JOIN sub_alarm_definition_dimension AS dim ON sad.id = dim.sub_alarm_definition_id %1$s " + "      WHERE ad.tenant_id = :tenantId AND ad.deleted_at IS NULL %2$s) AS t " + "LEFT OUTER JOIN alarm_action AS aa ON t.id = aa.alarm_definition_id " + "GROUP BY t.id %3$s %4$s %5$s";
        StringBuilder sbWhere = new StringBuilder();
        if (name != null) {
            sbWhere.append(" and ad.name = :name");
        }
        sbWhere.append(MySQLUtils.buildSeverityAndClause(severities));
        String orderByPart = "";
        if (sortBy != null && !sortBy.isEmpty()) {
            orderByPart = " order by " + COMMA_JOINER.join(sortBy);
            if (!orderByPart.contains("id")) {
                orderByPart = orderByPart + ",id";
            }
        } else {
            orderByPart = " order by id ";
        }
        String limitPart = "";
        if (limit > 0) {
            limitPart = " limit :limit";
        }
        String offsetPart = "";
        if (offset != null) {
            offsetPart = " offset " + offset + ' ';
        }
        String sql = String.format(query, SubAlarmDefinitionQueries.buildJoinClauseFor(dimensions), sbWhere, orderByPart, limitPart, offsetPart);
        Query<?> q = h.createQuery(sql);
        q.bind("tenantId", tenantId);
        if (name != null) {
            q.bind("name", name);
        }
        MySQLUtils.bindSeverityToQuery(q, severities);
        if (limit > 0) {
            q.bind("limit", limit + 1);
        }
        q.registerMapper(new AlarmDefinitionMapper());
        q = q.mapTo(AlarmDefinition.class);
        SubAlarmDefinitionQueries.bindDimensionsToQuery(q, dimensions);
        List<AlarmDefinition> resultSet = (List<AlarmDefinition>) q.list();
        return resultSet;
    }
}
#end_block

#method_before
@Override
public Map<String, AlarmSubExpression> findSubExpressions(String alarmDefId) {
    try (Handle h = db.open()) {
        List<Map<String, Object>> rows = h.createQuery(SUB_ALARM_SQL).bind("alarmDefId", alarmDefId).list();
        Map<String, AlarmSubExpression> subExpressions = new HashMap<>();
        for (Map<String, Object> row : rows) {
            String id = (String) row.get("id");
            AggregateFunction function = AggregateFunction.fromJson((String) row.get("function"));
            String metricName = (String) row.get("metric_name");
            AlarmOperator operator = AlarmOperator.fromJson((String) row.get("operator"));
            Double threshold = (Double) row.get("threshold");
            // MySQL connector returns an Integer, Drizzle returns a Long for period and periods.
            // Need to convert the results appropriately based on type.
            Integer period = Conversions.variantToInteger(row.get("period"));
            Integer periods = Conversions.variantToInteger(row.get("periods"));
            Map<String, String> dimensions = DimensionQueries.dimensionsFor((String) row.get("dimensions"));
            subExpressions.put(id, new AlarmSubExpression(function, new MetricDefinition(metricName, dimensions), operator, threshold, period, periods));
        }
        return subExpressions;
    }
}
#method_after
@Override
public Map<String, AlarmSubExpression> findSubExpressions(String alarmDefId) {
    try (Handle h = db.open()) {
        List<Map<String, Object>> rows = h.createQuery(SUB_ALARM_SQL).bind("alarmDefId", alarmDefId).list();
        Map<String, AlarmSubExpression> subExpressions = new HashMap<>();
        for (Map<String, Object> row : rows) {
            String id = (String) row.get("id");
            AggregateFunction function = AggregateFunction.fromJson((String) row.get("function"));
            String metricName = (String) row.get("metric_name");
            AlarmOperator operator = AlarmOperator.fromJson((String) row.get("operator"));
            Double threshold = (Double) row.get("threshold");
            // MySQL connector returns an Integer, Drizzle returns a Long for period and periods.
            // Need to convert the results appropriately based on type.
            Integer period = Conversions.variantToInteger(row.get("period"));
            Integer periods = Conversions.variantToInteger(row.get("periods"));
            Boolean isDeterministic = (Boolean) row.get("is_deterministic");
            Map<String, String> dimensions = DimensionQueries.dimensionsFor((String) row.get("dimensions"));
            subExpressions.put(id, new AlarmSubExpression(function, new MetricDefinition(metricName, dimensions), operator, threshold, period, periods, isDeterministic));
        }
        return subExpressions;
    }
}
#end_block

#method_before
@Override
public void update(String tenantId, String id, boolean patch, String name, String description, String expression, List<String> matchBy, String severity, boolean actionsEnabled, Collection<String> oldSubAlarmIds, Map<String, AlarmSubExpression> changedSubAlarms, Map<String, AlarmSubExpression> newSubAlarms, List<String> alarmActions, List<String> okActions, List<String> undeterminedActions) {
    Handle h = db.open();
    try {
        h.begin();
        h.insert("update alarm_definition set name = ?, description = ?, expression = ?, match_by = ?, severity = ?, actions_enabled = ?, updated_at = NOW() where tenant_id = ? and id = ?", name, description, expression, matchBy == null || Iterables.isEmpty(matchBy) ? null : COMMA_JOINER.join(matchBy), severity, actionsEnabled, tenantId, id);
        // Delete old sub-alarms
        if (oldSubAlarmIds != null)
            for (String oldSubAlarmId : oldSubAlarmIds) h.execute("delete from sub_alarm_definition where id = ?", oldSubAlarmId);
        // Update changed sub-alarms
        if (changedSubAlarms != null)
            for (Map.Entry<String, AlarmSubExpression> entry : changedSubAlarms.entrySet()) {
                AlarmSubExpression sa = entry.getValue();
                h.execute("update sub_alarm_definition set operator = ?, threshold = ?, updated_at = NOW() where id = ?", sa.getOperator().name(), sa.getThreshold(), entry.getKey());
            }
        // Insert new sub-alarms
        createSubExpressions(h, id, newSubAlarms);
        // Delete old actions
        if (patch) {
            deleteActions(h, id, AlarmState.ALARM, alarmActions);
            deleteActions(h, id, AlarmState.OK, okActions);
            deleteActions(h, id, AlarmState.UNDETERMINED, undeterminedActions);
        } else
            h.execute("delete from alarm_action where alarm_definition_id = ?", id);
        // Insert new actions
        persistActions(h, id, AlarmState.ALARM, alarmActions);
        persistActions(h, id, AlarmState.OK, okActions);
        persistActions(h, id, AlarmState.UNDETERMINED, undeterminedActions);
        h.commit();
    } catch (RuntimeException e) {
        h.rollback();
        throw e;
    } finally {
        h.close();
    }
}
#method_after
@Override
public void update(String tenantId, String id, boolean patch, String name, String description, String expression, List<String> matchBy, String severity, boolean actionsEnabled, Collection<String> oldSubAlarmIds, Map<String, AlarmSubExpression> changedSubAlarms, Map<String, AlarmSubExpression> newSubAlarms, List<String> alarmActions, List<String> okActions, List<String> undeterminedActions) {
    Handle h = db.open();
    try {
        h.begin();
        h.insert("update alarm_definition set name = ?, description = ?, expression = ?, match_by = ?, severity = ?, actions_enabled = ?, updated_at = NOW() where tenant_id = ? and id = ?", name, description, expression, matchBy == null || Iterables.isEmpty(matchBy) ? null : COMMA_JOINER.join(matchBy), severity, actionsEnabled, tenantId, id);
        // Delete old sub-alarms
        if (oldSubAlarmIds != null)
            for (String oldSubAlarmId : oldSubAlarmIds) h.execute("delete from sub_alarm_definition where id = ?", oldSubAlarmId);
        // Update changed sub-alarms
        if (changedSubAlarms != null)
            for (Map.Entry<String, AlarmSubExpression> entry : changedSubAlarms.entrySet()) {
                AlarmSubExpression sa = entry.getValue();
                h.execute(UPDATE_SUB_ALARM_DEF_SQL, sa.getOperator().name(), sa.getThreshold(), sa.isDeterministic(), entry.getKey());
            }
        // Insert new sub-alarms
        createSubExpressions(h, id, newSubAlarms);
        // Delete old actions
        if (patch) {
            deleteActions(h, id, AlarmState.ALARM, alarmActions);
            deleteActions(h, id, AlarmState.OK, okActions);
            deleteActions(h, id, AlarmState.UNDETERMINED, undeterminedActions);
        } else
            h.execute("delete from alarm_action where alarm_definition_id = ?", id);
        // Insert new actions
        persistActions(h, id, AlarmState.ALARM, alarmActions);
        persistActions(h, id, AlarmState.OK, okActions);
        persistActions(h, id, AlarmState.UNDETERMINED, undeterminedActions);
        h.commit();
    } catch (RuntimeException e) {
        h.rollback();
        throw e;
    } finally {
        h.close();
    }
}
#end_block

#method_before
private void createSubExpressions(Handle handle, String id, Map<String, AlarmSubExpression> alarmSubExpressions) {
    if (alarmSubExpressions != null) {
        for (Map.Entry<String, AlarmSubExpression> subEntry : alarmSubExpressions.entrySet()) {
            String subAlarmId = subEntry.getKey();
            AlarmSubExpression subExpr = subEntry.getValue();
            MetricDefinition metricDef = subExpr.getMetricDefinition();
            // Persist sub-alarm
            handle.insert("insert into sub_alarm_definition (id, alarm_definition_id, function, metric_name, operator, threshold, period, periods, created_at, updated_at) " + "values (?, ?, ?, ?, ?, ?, ?, ?, NOW(), NOW())", subAlarmId, id, subExpr.getFunction().name(), metricDef.name, subExpr.getOperator().name(), subExpr.getThreshold(), subExpr.getPeriod(), subExpr.getPeriods());
            // Persist sub-alarm dimensions
            if (metricDef.dimensions != null && !metricDef.dimensions.isEmpty())
                for (Map.Entry<String, String> dimEntry : metricDef.dimensions.entrySet()) handle.insert("insert into sub_alarm_definition_dimension values (?, ?, ?)", subAlarmId, dimEntry.getKey(), dimEntry.getValue());
        }
    }
}
#method_after
private void createSubExpressions(Handle handle, String id, Map<String, AlarmSubExpression> alarmSubExpressions) {
    if (alarmSubExpressions != null) {
        for (Map.Entry<String, AlarmSubExpression> subEntry : alarmSubExpressions.entrySet()) {
            String subAlarmId = subEntry.getKey();
            AlarmSubExpression subExpr = subEntry.getValue();
            MetricDefinition metricDef = subExpr.getMetricDefinition();
            // Persist sub-alarm
            handle.insert(CREATE_SUB_EXPRESSION_SQL, subAlarmId, id, subExpr.getFunction().name(), metricDef.name, subExpr.getOperator().name(), subExpr.getThreshold(), subExpr.getPeriod(), subExpr.getPeriods(), subExpr.isDeterministic());
            // Persist sub-alarm dimensions
            if (metricDef.dimensions != null && !metricDef.dimensions.isEmpty())
                for (Map.Entry<String, String> dimEntry : metricDef.dimensions.entrySet()) handle.insert("insert into sub_alarm_definition_dimension values (?, ?, ?)", subAlarmId, dimEntry.getKey(), dimEntry.getValue());
        }
    }
}
#end_block

#method_before
public static List<AlarmSeverity> parseAndValidateSeverity(String severityStr) {
    List<AlarmSeverity> severityList = null;
    if (severityStr != null && !severityStr.isEmpty()) {
        severityList = new ArrayList<>();
        List<String> severities = Lists.newArrayList(Splitter.on('|').omitEmptyStrings().trimResults().split(severityStr));
        for (String severity : severities) {
            AlarmSeverity s = AlarmSeverity.fromString(severity);
            if (s != null) {
                severityList.add(s);
            }
        }
    }
    return severityList;
}
#method_after
public static List<AlarmSeverity> parseAndValidateSeverity(String severityStr) {
    List<AlarmSeverity> severityList = null;
    if (severityStr != null && !severityStr.isEmpty()) {
        severityList = new ArrayList<>();
        List<String> severities = Lists.newArrayList(VERTICAL_BAR_SPLITTER.split(severityStr));
        for (String severity : severities) {
            AlarmSeverity s = AlarmSeverity.fromString(severity);
            if (s != null) {
                severityList.add(s);
            } else {
                throw Exceptions.unprocessableEntity(String.format("Invalid severity %s", severity));
            }
        }
    }
    return severityList;
}
#end_block

#method_before
public SubAlarm duplicate(final SubAlarm original) {
    final SubAlarm newSubAlarm = new SubAlarm(original.getId(), original.getAlarmId(), new SubExpression(original.getAlarmSubExpressionId(), original.getExpression()), original.getState());
    newSubAlarm.setNoState(original.isNoState());
    cloneCurrentValues(original, newSubAlarm);
    return newSubAlarm;
}
#method_after
public SubAlarm duplicate(final SubAlarm original) {
    final SubAlarm newSubAlarm = new SubAlarm(original.getId(), original.getAlarmId(), new SubExpression(original.getAlarmSubExpressionId(), original.getExpression()), original.getState());
    newSubAlarm.setNoState(original.isNoState());
    newSubAlarm.setCurrentValues(cloneCurrentValues(original));
    return newSubAlarm;
}
#end_block

#method_before
private void cloneCurrentValues(final SubAlarm original, final SubAlarm newSubAlarm) {
    final List<Double> originalCurrentValues = original.getCurrentValues();
    if (originalCurrentValues == null) {
        return;
    }
    newSubAlarm.setCurrentValues(new ArrayList<>(originalCurrentValues));
}
#method_after
private List<Double> cloneCurrentValues(final SubAlarm original) {
    final List<Double> originalCurrentValues = original.getCurrentValues();
    if (originalCurrentValues == null) {
        return null;
    }
    return new ArrayList<Double>(originalCurrentValues);
}
#end_block

#method_before
@BeforeMethod
public void befortMethod() throws Exception {
    // Fixtures
    final AlarmExpression expression = new AlarmExpression("max(cpu{id=5}) >= 3 or max(mem{id=5}) >= 5");
    cpuMetricDef = expression.getSubExpressions().get(0).getMetricDefinition();
    memMetricDef = expression.getSubExpressions().get(1).getMetricDefinition();
    extraMemMetricDefDimensions = new HashMap<>(memMetricDef.dimensions);
    extraMemMetricDefDimensions.put("Group", "group A");
    alarmDefinition = new AlarmDefinition(TEST_ALARM_TENANT_ID, TEST_ALARM_NAME, TEST_ALARM_DESCRIPTION, expression, "LOW", true, new ArrayList<String>());
    // Mocks
    alarmDAO = mock(AlarmDAO.class);
    alarmDefinitionDAO = mock(AlarmDefinitionDAO.class);
    // Bindings
    Injector.reset();
    Injector.registerModules(new AbstractModule() {

        protected void configure() {
            bind(AlarmDAO.class).toInstance(alarmDAO);
            bind(AlarmDefinitionDAO.class).toInstance(alarmDefinitionDAO);
        }
    });
    // Config
    ThresholdingConfiguration threshConfig = new ThresholdingConfiguration();
    threshConfig.alarmDelay = 1;
    threshConfig.sporadicMetricNamespaces = new HashSet<String>();
    Serialization.registerTarget(KafkaProducerConfiguration.class);
    threshConfig.kafkaProducerConfig = Serialization.fromJson("{\"KafkaProducerConfiguration\":{\"topic\":\"alarm-state-transitions\",\"metadataBrokerList\":\"192.168.10.10:9092\",\"requestRequiredAcks\":1,\"requestTimeoutMs\":10000,\"producerType\":\"sync\",\"serializerClass\":\"kafka.serializer.StringEncoder\",\"keySerializerClass\":\"\",\"partitionerClass\":\"\",\"compressionCodec\":\"none\",\"compressedTopics\":\"\",\"messageSendMaxRetries\":3,\"retryBackoffMs\":100,\"topicMetadataRefreshIntervalMs\":600000,\"queueBufferingMaxMs\":5000,\"queueBufferingMaxMessages\":10000,\"queueEnqueueTimeoutMs\":-1,\"batchNumMessages\":200,\"sendBufferBytes\":102400,\"clientId\":\"Threshold_Engine\"}}");
    Config stormConfig = new Config();
    stormConfig.setMaxTaskParallelism(1);
    metricSpout = new FeederSpout(new Fields(MetricSpout.FIELDS));
    eventSpout = new FeederSpout(new Fields("event"));
    alarmEventForwarder = mock(AlarmEventForwarder.class);
    Injector.registerModules(new TopologyModule(threshConfig, stormConfig, metricSpout, eventSpout));
    Injector.registerModules(new ProducerModule(alarmEventForwarder));
}
#method_after
@BeforeMethod
public void befortMethod() throws Exception {
    // Fixtures
    final AlarmExpression expression = new AlarmExpression("max(cpu{id=5}) >= 3 or max(mem{id=5}) >= 5");
    final AlarmExpression expression2 = AlarmExpression.of("count(log.error{id=5},deterministic) >= 1 OR count(log.warning{id=5},deterministic) >= 1");
    final AlarmExpression expression3 = AlarmExpression.of("max(cpu{id=5}) >= 3 AND count(log.warning{id=5},deterministic) >= 1");
    cpuMetricDef = expression.getSubExpressions().get(0).getMetricDefinition();
    memMetricDef = expression.getSubExpressions().get(1).getMetricDefinition();
    logErrorMetricDef = expression2.getSubExpressions().get(0).getMetricDefinition();
    logWarningMetricDef = expression2.getSubExpressions().get(1).getMetricDefinition();
    extraMemMetricDefDimensions = new HashMap<>(memMetricDef.dimensions);
    extraMemMetricDefDimensions.put("Group", "group A");
    alarmDefinition = new AlarmDefinition(TEST_ALARM_TENANT_ID, TEST_ALARM_NAME, TEST_ALARM_DESCRIPTION, expression, "LOW", true, new ArrayList<String>());
    this.deterministicAlarmDefinition = new AlarmDefinition(DET_TEST_ALARM_TENANT_ID, DET_TEST_ALARM_NAME, DET_TEST_ALARM_DESCRIPTION, expression2, "LOW", true, new ArrayList<String>());
    this.mixedAlarmDefinition = new AlarmDefinition(MIXED_TEST_ALARM_TENANT_ID, MIXED_TEST_ALARM_NAME, MIXED_TEST_ALARM_DESCRIPTION, expression3, "LOW", true, new ArrayList<String>());
    // Mocks
    alarmDAO = mock(AlarmDAO.class);
    alarmDefinitionDAO = mock(AlarmDefinitionDAO.class);
    // Bindings
    Injector.reset();
    Injector.registerModules(new AbstractModule() {

        protected void configure() {
            bind(AlarmDAO.class).toInstance(alarmDAO);
            bind(AlarmDefinitionDAO.class).toInstance(alarmDefinitionDAO);
        }
    });
    // Config
    ThresholdingConfiguration threshConfig = new ThresholdingConfiguration();
    threshConfig.alarmDelay = 1;
    threshConfig.sporadicMetricNamespaces = new HashSet<String>();
    Serialization.registerTarget(KafkaProducerConfiguration.class);
    threshConfig.kafkaProducerConfig = Serialization.fromJson("{\"KafkaProducerConfiguration\":{\"topic\":\"alarm-state-transitions\",\"metadataBrokerList\":\"192.168.10.10:9092\",\"requestRequiredAcks\":1,\"requestTimeoutMs\":10000,\"producerType\":\"sync\",\"serializerClass\":\"kafka.serializer.StringEncoder\",\"keySerializerClass\":\"\",\"partitionerClass\":\"\",\"compressionCodec\":\"none\",\"compressedTopics\":\"\",\"messageSendMaxRetries\":3,\"retryBackoffMs\":100,\"topicMetadataRefreshIntervalMs\":600000,\"queueBufferingMaxMs\":5000,\"queueBufferingMaxMessages\":10000,\"queueEnqueueTimeoutMs\":-1,\"batchNumMessages\":200,\"sendBufferBytes\":102400,\"clientId\":\"Threshold_Engine\"}}");
    Config stormConfig = new Config();
    stormConfig.setMaxTaskParallelism(1);
    metricSpout = new FeederSpout(new Fields(MetricSpout.FIELDS));
    eventSpout = new FeederSpout(new Fields("event"));
    alarmEventForwarder = mock(AlarmEventForwarder.class);
    Injector.registerModules(new TopologyModule(threshConfig, stormConfig, metricSpout, eventSpout));
    Injector.registerModules(new ProducerModule(alarmEventForwarder));
}
#end_block

#method_before
public void testWithAlarmDefinitionCreatedEvent() throws Exception {
    when(alarmDefinitionDAO.listAll()).thenReturn(new ArrayList<AlarmDefinition>());
    when(alarmDefinitionDAO.findById(alarmDefinition.getId())).thenReturn(alarmDefinition);
    final AlarmDefinitionCreatedEvent event = new AlarmDefinitionCreatedEvent(alarmDefinition.getTenantId(), alarmDefinition.getId(), alarmDefinition.getName(), alarmDefinition.getDescription(), alarmDefinition.getAlarmExpression().getExpression(), createSubExpressionMap(alarmDefinition.getAlarmExpression()), Arrays.asList("id"));
    eventSpout.feed(new Values(event));
    shouldThreshold(null, false);
}
#method_after
private void testWithAlarmDefinitionCreatedEvent(final AlarmDefinition alarmDefinition, final ThresholdSpec thresholdSpec) throws Exception {
    when(alarmDefinitionDAO.listAll()).thenReturn(new ArrayList<AlarmDefinition>());
    when(alarmDefinitionDAO.findById(alarmDefinition.getId())).thenReturn(alarmDefinition);
    final AlarmDefinitionCreatedEvent event = new AlarmDefinitionCreatedEvent(alarmDefinition.getTenantId(), alarmDefinition.getId(), alarmDefinition.getName(), alarmDefinition.getDescription(), alarmDefinition.getAlarmExpression().getExpression(), createSubExpressionMap(alarmDefinition.getAlarmExpression()), Arrays.asList("id"));
    eventSpout.feed(new Values(event));
    shouldThreshold(thresholdSpec);
}
#end_block

#method_before
public void testWithInitialAlarmDefinition() throws Exception {
    when(alarmDefinitionDAO.findById(alarmDefinition.getId())).thenReturn(alarmDefinition);
    when(alarmDefinitionDAO.listAll()).thenReturn(Arrays.asList(alarmDefinition));
    shouldThreshold(null, false);
}
#method_after
private void testWithInitialAlarmDefinition(final AlarmDefinition alarmDefinition, final ThresholdSpec thresholdSpec) throws Exception {
    when(alarmDefinitionDAO.findById(alarmDefinition.getId())).thenReturn(alarmDefinition);
    when(alarmDefinitionDAO.listAll()).thenReturn(Arrays.asList(alarmDefinition));
    shouldThreshold(thresholdSpec);
}
#end_block

#method_before
public void testWithInitialAlarm() throws Exception {
    when(alarmDefinitionDAO.findById(alarmDefinition.getId())).thenReturn(alarmDefinition);
    when(alarmDefinitionDAO.listAll()).thenReturn(Arrays.asList(alarmDefinition));
    final Alarm alarm = new Alarm(alarmDefinition, AlarmState.UNDETERMINED);
    alarm.addAlarmedMetric(new MetricDefinitionAndTenantId(cpuMetricDef, TEST_ALARM_TENANT_ID));
    alarm.addAlarmedMetric(new MetricDefinitionAndTenantId(memMetricDef, TEST_ALARM_TENANT_ID));
    when(alarmDAO.listAll()).thenReturn(Arrays.asList(alarm));
    when(alarmDAO.findById(alarm.getId())).thenReturn(alarm);
    when(alarmDAO.findForAlarmDefinitionId(alarmDefinition.getId())).thenReturn(Arrays.asList(alarm));
    shouldThreshold(alarm.getId(), true);
}
#method_after
private void testWithInitialAlarm(final AlarmDefinition alarmDefinition, final Alarm alarm, final ThresholdSpec thresholdSpec) throws Exception {
    when(alarmDefinitionDAO.findById(alarmDefinition.getId())).thenReturn(alarmDefinition);
    when(alarmDefinitionDAO.listAll()).thenReturn(Arrays.asList(alarmDefinition));
    when(alarmDAO.listAll()).thenReturn(Arrays.asList(alarm));
    when(alarmDAO.findById(alarm.getId())).thenReturn(alarm);
    when(alarmDAO.findForAlarmDefinitionId(alarmDefinition.getId())).thenReturn(Arrays.asList(alarm));
    shouldThreshold(thresholdSpec);
}
#end_block

#method_before
private void shouldThreshold(final String expectedAlarmId, final boolean hasExtraMetric) throws Exception {
    System.out.println("Starting topology");
    startTopology();
    previousState = AlarmState.UNDETERMINED;
    expectedState = AlarmState.ALARM;
    alarmsSent = 0;
    MetricFilteringBolt.clearMetricDefinitions();
    doAnswer(new Answer<Object>() {

        public Object answer(InvocationOnMock invocation) {
            final Object[] args = invocation.getArguments();
            AlarmStateTransitionedEvent event = Serialization.fromJson((String) args[0]);
            alarmsSent++;
            System.out.printf("Alarm transitioned from %s to %s%n", event.oldState, event.newState);
            assertEquals(event.alarmDefinitionId, alarmDefinition.getId());
            assertEquals(event.alarmName, TEST_ALARM_NAME);
            assertEquals(event.tenantId, TEST_ALARM_TENANT_ID);
            if (expectedAlarmId != null) {
                assertEquals(event.alarmId, expectedAlarmId);
            }
            assertEquals(event.oldState, previousState);
            assertEquals(event.newState, expectedState);
            assertEquals(event.metrics.size(), hasExtraMetric ? 3 : 2);
            for (MetricDefinition md : event.metrics) {
                if (md.name.equals(cpuMetricDef.name)) {
                    assertEquals(cpuMetricDef, md);
                } else if (md.name.equals(memMetricDef.name)) {
                    if (md.dimensions.size() == extraMemMetricDefDimensions.size()) {
                        assertEquals(extraMemMetricDefDimensions, md.dimensions);
                    } else if (hasExtraMetric) {
                        assertEquals(memMetricDef, md);
                    } else {
                        fail("Incorrect mem Alarmed Metric");
                    }
                } else {
                    fail(String.format("Unrecognized MetricDefinition %s", md));
                }
            }
            previousState = event.newState;
            return null;
        }
    }).when(alarmEventForwarder).send(anyString());
    doAnswer(new Answer<Object>() {

        public Object answer(InvocationOnMock invocation) {
            final Object[] args = invocation.getArguments();
            final Alarm alarm = (Alarm) args[0];
            when(alarmDAO.findById(alarm.getId())).thenReturn(alarm);
            System.out.printf("Alarm %s created\n", alarm.getId());
            return null;
        }
    }).when(alarmDAO).createAlarm((Alarm) any());
    int waitCount = 0;
    int feedCount = 5;
    int goodValueCount = 0;
    for (int i = 1; i < 40 && alarmsSent == 0; i++) {
        if (feedCount > 0) {
            System.out.println("Feeding metrics...");
            long time = System.currentTimeMillis();
            final MetricDefinitionAndTenantId cpuMtid = new MetricDefinitionAndTenantId(cpuMetricDef, TEST_ALARM_TENANT_ID);
            metricSpout.feed(new Values(new TenantIdAndMetricName(cpuMtid), time, new Metric(cpuMetricDef.name, cpuMetricDef.dimensions, time, (double) (++goodValueCount == 15 ? 1 : 555), null)));
            final MetricDefinitionAndTenantId memMtid = new MetricDefinitionAndTenantId(memMetricDef, TEST_ALARM_TENANT_ID);
            metricSpout.feed(new Values(new TenantIdAndMetricName(memMtid), time, new Metric(memMetricDef.name, extraMemMetricDefDimensions, time, (double) (goodValueCount == 15 ? 1 : 555), null)));
            if (--feedCount == 0) {
                waitCount = 3;
            }
            if (goodValueCount == 15) {
                goodValueCount = 0;
            }
        } else {
            System.out.println("Waiting...");
            if (--waitCount == 0) {
                feedCount = 5;
            }
        }
        try {
            Thread.sleep(1000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }
    // Give it some extra time if it needs it for the alarm to come out
    final int maxWait = 30;
    for (int i = 0; i < maxWait && alarmsSent == 0; i++) {
        if ((i % 5) == 0) {
            System.out.printf("Waiting %d more seconds for alarms to be sent\n", maxWait - i);
        }
        try {
            Thread.sleep(1000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }
    assertTrue(alarmsSent > 0, "Not enough alarms");
    System.out.println("All expected Alarms received");
}
#method_after
private void shouldThreshold(final ThresholdSpec thresholdSpec) throws Exception {
    System.out.println("Starting topology");
    startTopology();
    previousState = thresholdSpec.isDeterministic ? AlarmState.OK : AlarmState.UNDETERMINED;
    expectedState = AlarmState.ALARM;
    alarmsSent = 0;
    MetricFilteringBolt.clearMetricDefinitions();
    doAnswer(new Answer<Object>() {

        public Object answer(InvocationOnMock invocation) {
            final Object[] args = invocation.getArguments();
            AlarmStateTransitionedEvent event = Serialization.fromJson((String) args[0]);
            alarmsSent++;
            System.out.printf("Alarm transitioned from %s to %s%n", event.oldState, event.newState);
            assertEquals(event.alarmDefinitionId, thresholdSpec.alarmDefinitionId);
            assertEquals(event.alarmName, thresholdSpec.alarmName);
            assertEquals(event.tenantId, thresholdSpec.alarmTenantId);
            if (thresholdSpec.alarmId != null) {
                assertEquals(event.alarmId, thresholdSpec.alarmId);
            }
            assertEquals(event.oldState, previousState);
            assertEquals(event.newState, expectedState);
            assertEquals(event.metrics.size(), thresholdSpec.hasExtraMetric ? 3 : 2);
            for (MetricDefinition md : event.metrics) {
                if (md.name.equals(cpuMetricDef.name)) {
                    assertEquals(cpuMetricDef, md);
                } else if (md.name.equals(logErrorMetricDef.name)) {
                    assertEquals(logErrorMetricDef, md);
                } else if (md.name.equals(logWarningMetricDef.name)) {
                    assertEquals(logWarningMetricDef, md);
                } else if (md.name.equals(memMetricDef.name)) {
                    if (md.dimensions.size() == extraMemMetricDefDimensions.size()) {
                        assertEquals(extraMemMetricDefDimensions, md.dimensions);
                    } else if (thresholdSpec.hasExtraMetric) {
                        assertEquals(memMetricDef, md);
                    } else {
                        fail("Incorrect mem Alarmed Metric");
                    }
                } else {
                    fail(String.format("Unrecognized MetricDefinition %s", md));
                }
            }
            previousState = event.newState;
            return null;
        }
    }).when(alarmEventForwarder).send(anyString());
    doAnswer(new Answer<Object>() {

        public Object answer(InvocationOnMock invocation) {
            final Object[] args = invocation.getArguments();
            final Alarm alarm = (Alarm) args[0];
            when(alarmDAO.findById(alarm.getId())).thenReturn(alarm);
            System.out.printf("Alarm %s created\n", alarm.getId());
            return null;
        }
    }).when(alarmDAO).createAlarm((Alarm) any());
    int waitCount = 0;
    int feedCount = 5;
    int goodValueCount = 0;
    for (int i = 1; i < 40 && alarmsSent == 0; i++) {
        if (feedCount > 0) {
            System.out.println("Feeding metrics...");
            long time = System.currentTimeMillis();
            goodValueCount = this.feedMetrics(thresholdSpec, goodValueCount, time);
            if (--feedCount == 0) {
                waitCount = 3;
            }
            if (goodValueCount == 15) {
                goodValueCount = 0;
            }
        } else {
            System.out.println("Waiting...");
            if (--waitCount == 0) {
                feedCount = 5;
            }
        }
        try {
            Thread.sleep(1000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }
    // Give it some extra time if it needs it for the alarm to come out
    final int maxWait = 30;
    for (int i = 0; i < maxWait && alarmsSent == 0; i++) {
        if ((i % 5) == 0) {
            System.out.printf("Waiting %d more seconds for alarms to be sent\n", maxWait - i);
        }
        try {
            Thread.sleep(1000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }
    assertTrue(alarmsSent > 0, "Not enough alarms");
    System.out.println("All expected Alarms received");
}
#end_block

#method_before
public void testmetricFitsInAlarmDefinition() {
    final AlarmDefinition alarmDefinition = createAlarmDefinition("max(cpu{service=2}) > 90 and max(load_avg) > 10", "hostname");
    final MetricDefinitionAndTenantId goodCpu = new MetricDefinitionAndTenantId(build("cpu", "hostname", "eleanore", "service", "2", "other", "vivi"), TENANT_ID);
    assertTrue(bolt.validMetricDefinition(alarmDefinition, goodCpu));
    final MetricDefinitionAndTenantId goodLoad = new MetricDefinitionAndTenantId(build("load_avg", "hostname", "eleanore", "service", "2", "other", "vivi"), TENANT_ID);
    assertTrue(bolt.validMetricDefinition(alarmDefinition, goodLoad));
    final MetricDefinitionAndTenantId goodLoadNoDim = new MetricDefinitionAndTenantId(build("load_avg"), TENANT_ID);
    assertTrue(bolt.validMetricDefinition(alarmDefinition, goodLoadNoDim));
    final MetricDefinitionAndTenantId badCpuDim = new MetricDefinitionAndTenantId(build("cpu", "hostname", "eleanore", "service", "1", "other", "vivi"), TENANT_ID);
    assertFalse(bolt.validMetricDefinition(alarmDefinition, badCpuDim));
    final MetricDefinitionAndTenantId wrongMetricName = new MetricDefinitionAndTenantId(build("mem", "hostname", "eleanore", "service", "1", "other", "vivi"), TENANT_ID);
    assertFalse(bolt.validMetricDefinition(alarmDefinition, wrongMetricName));
    final MetricDefinitionAndTenantId badCpuNoDim = new MetricDefinitionAndTenantId(build("cpu"), TENANT_ID);
    assertFalse(bolt.validMetricDefinition(alarmDefinition, badCpuNoDim));
    final MetricDefinitionAndTenantId badCpuWrongTenant = new MetricDefinitionAndTenantId(build("cpu"), TENANT_ID + "2");
    assertFalse(bolt.validMetricDefinition(alarmDefinition, badCpuWrongTenant));
}
#method_after
public void testmetricFitsInAlarmDefinition() {
    final AlarmDefinition alarmDefinition = createAlarmDefinition("max(cpu{service=2}) > 90 and max(load_avg) > 10", "hostname");
    final MetricDefinitionAndTenantId goodCpu = new MetricDefinitionAndTenantId(build("cpu", "hostname", "eleanore", "service", "2", "other", "vivi"), TENANT_ID);
    assertTrue(bolt.validMetricDefinition(alarmDefinition, goodCpu));
    final MetricDefinitionAndTenantId goodLoad = new MetricDefinitionAndTenantId(build("load_avg", "hostname", "eleanore", "service", "2", "other", "vivi"), TENANT_ID);
    assertTrue(bolt.validMetricDefinition(alarmDefinition, goodLoad));
    final MetricDefinitionAndTenantId goodLoadNoDim = new MetricDefinitionAndTenantId(build("load_avg"), TENANT_ID);
    assertTrue(bolt.validMetricDefinition(alarmDefinition, goodLoadNoDim));
    final MetricDefinitionAndTenantId badCpuDim = new MetricDefinitionAndTenantId(build("cpu", "hostname", "eleanore", "service", "1", "other", "vivi"), TENANT_ID);
    assertFalse(bolt.validMetricDefinition(alarmDefinition, badCpuDim));
    final MetricDefinitionAndTenantId wrongMetricName = new MetricDefinitionAndTenantId(build("mem", "hostname", "eleanore", "service", "1", "other", "vivi"), TENANT_ID);
    assertFalse(bolt.validMetricDefinition(alarmDefinition, wrongMetricName));
    final MetricDefinitionAndTenantId badCpuNoDim = new MetricDefinitionAndTenantId(build("cpu"), TENANT_ID);
    assertFalse(bolt.validMetricDefinition(alarmDefinition, badCpuNoDim));
    final MetricDefinitionAndTenantId badCpuWrongTenant = new MetricDefinitionAndTenantId(build("cpu"), TENANT_ID + "2");
    assertFalse(bolt.validMetricDefinition(alarmDefinition, badCpuWrongTenant));
    // check deterministic
    final AlarmDefinition deterministicAlarmDefinition = createAlarmDefinition("count(log.error{},deterministic) > 2", "hostname");
    // deterministic, same tenant, with dimensions
    MetricDefinitionAndTenantId validLogError = new MetricDefinitionAndTenantId(build("log.error", "hostname", "eleanore", "path", "/var/log/test.log"), TENANT_ID);
    assertTrue(bolt.validMetricDefinition(deterministicAlarmDefinition, validLogError));
    // deterministic, same tenant, no dimensions
    MetricDefinitionAndTenantId invalidLogError = new MetricDefinitionAndTenantId(build("log.error"), TENANT_ID);
    assertTrue(bolt.validMetricDefinition(deterministicAlarmDefinition, invalidLogError));
    // deterministic, different tenant
    invalidLogError = new MetricDefinitionAndTenantId(build("log.error"), TENANT_ID + "234");
    assertFalse(bolt.validMetricDefinition(deterministicAlarmDefinition, invalidLogError));
}
#end_block

#method_before
public void testMetricFitsInAlarm() {
    final AlarmDefinition alarmDefinition = createAlarmDefinition("max(cpu{service=2}) > 90 and max(load_avg{service=2}) > 10", "hostname");
    final Alarm alarm = new Alarm(alarmDefinition, AlarmState.ALARM);
    final Iterator<SubAlarm> iterator = alarm.getSubAlarms().iterator();
    final SubAlarm cpu = iterator.next();
    final SubAlarm disk = iterator.next();
    final MetricDefinition alarmedMetric = build(cpu.getExpression().getMetricDefinition().name, "hostname", "eleanore", "service", "2");
    alarm.addAlarmedMetric(new MetricDefinitionAndTenantId(alarmedMetric, TENANT_ID));
    final MetricDefinition check = build(disk.getExpression().getMetricDefinition().name, "hostname", "eleanore", "service", "2", "other", "vivi");
    assertTrue(bolt.metricFitsInAlarm(alarm, alarmDefinition, new MetricDefinitionAndTenantId(check, TENANT_ID)));
    final MetricDefinition check2 = build(disk.getExpression().getMetricDefinition().name, "hostname", "vivi", "service", "2", "other", "eleanore");
    assertFalse(bolt.metricFitsInAlarm(alarm, alarmDefinition, new MetricDefinitionAndTenantId(check2, TENANT_ID)));
    final MetricDefinition check3 = build(disk.getExpression().getMetricDefinition().name, "service", "2", "other", "eleanore");
    assertFalse(bolt.metricFitsInAlarm(alarm, alarmDefinition, new MetricDefinitionAndTenantId(check3, TENANT_ID)));
    final MetricDefinition check4 = build(disk.getExpression().getMetricDefinition().name, "hostname", "eleanore", "service", "1", "other", "vivi");
    assertFalse(bolt.metricFitsInAlarm(alarm, alarmDefinition, new MetricDefinitionAndTenantId(check4, TENANT_ID)));
}
#method_after
public void testMetricFitsInAlarm() {
    final AlarmDefinition alarmDefinition = createAlarmDefinition("max(cpu{service=2}) > 90 and max(load_avg{service=2}) > 10", "hostname");
    final Alarm alarm = new Alarm(alarmDefinition);
    alarm.setState(AlarmState.ALARM);
    final Iterator<SubAlarm> iterator = alarm.getSubAlarms().iterator();
    final SubAlarm cpu = iterator.next();
    final SubAlarm disk = iterator.next();
    final MetricDefinition alarmedMetric = build(cpu.getExpression().getMetricDefinition().name, "hostname", "eleanore", "service", "2");
    alarm.addAlarmedMetric(new MetricDefinitionAndTenantId(alarmedMetric, TENANT_ID));
    final MetricDefinition check = build(disk.getExpression().getMetricDefinition().name, "hostname", "eleanore", "service", "2", "other", "vivi");
    assertTrue(bolt.metricFitsInAlarm(alarm, alarmDefinition, new MetricDefinitionAndTenantId(check, TENANT_ID)));
    final MetricDefinition check2 = build(disk.getExpression().getMetricDefinition().name, "hostname", "vivi", "service", "2", "other", "eleanore");
    assertFalse(bolt.metricFitsInAlarm(alarm, alarmDefinition, new MetricDefinitionAndTenantId(check2, TENANT_ID)));
    final MetricDefinition check3 = build(disk.getExpression().getMetricDefinition().name, "service", "2", "other", "eleanore");
    assertFalse(bolt.metricFitsInAlarm(alarm, alarmDefinition, new MetricDefinitionAndTenantId(check3, TENANT_ID)));
    final MetricDefinition check4 = build(disk.getExpression().getMetricDefinition().name, "hostname", "eleanore", "service", "1", "other", "vivi");
    assertFalse(bolt.metricFitsInAlarm(alarm, alarmDefinition, new MetricDefinitionAndTenantId(check4, TENANT_ID)));
}
#end_block

#method_before
public void testCreateSimpleAlarmWithMatchBy() {
    runCreateSimpleAlarm("hostname");
}
#method_after
public void testCreateSimpleAlarmWithMatchBy() {
    this.runCreateSimpleAlarm(false, "hostname");
}
#end_block

#method_before
public void testCreateSimpleAlarm() {
    runCreateSimpleAlarm();
}
#method_after
public void testCreateSimpleAlarm() {
    this.runCreateSimpleAlarm(false);
}
#end_block

#method_before
public void testCreateComplexAlarmWithMatchBy() {
    runCreateComplexAlarm("hostname");
}
#method_after
public void testCreateComplexAlarmWithMatchBy() {
    this.runCreateComplexAlarm(false, "hostname");
}
#end_block

#method_before
public void testCreateComplexAlarm() {
    runCreateComplexAlarm();
}
#method_after
public void testCreateComplexAlarm() {
    this.runCreateComplexAlarm(false);
}
#end_block

#method_before
public void testReuseMetricFromExistingAlarm() {
    final String expression = "max(cpu{service=vivi}) > 90";
    final String[] matchBy = new String[] { "hostname", "amplifier" };
    final AlarmDefinition alarmDefinition = createAlarmDefinition(expression, matchBy);
    final MetricDefinition metric = build("cpu", "hostname", "eleanore", "amplifier", "2", "service", "vivi");
    bolt.handleNewMetricDefinition(new MetricDefinitionAndTenantId(metric, TENANT_ID), alarmDefinition.getId());
    assertEquals(this.createdAlarms.size(), 1);
    verifyCreatedAlarm(this.createdAlarms.get(0), alarmDefinition, collector, new MetricDefinitionAndTenantId(metric, TENANT_ID));
    final MetricDefinition metric2 = build("cpu", "hostname", "eleanore", "service", "vivi");
    sendNewMetric(new MetricDefinitionAndTenantId(metric2, TENANT_ID), alarmDefinition.getId());
    assertEquals(this.createdAlarms.size(), 1, "A second alarm was created instead of the metric fitting into the first");
    verifyCreatedAlarm(this.createdAlarms.get(0), alarmDefinition, collector, new MetricDefinitionAndTenantId(metric, TENANT_ID), new MetricDefinitionAndTenantId(metric2, TENANT_ID));
    final MetricDefinition metric3 = build("cpu", "hostname", "eleanore", "amplifier", "3", "service", "vivi");
    bolt.handleNewMetricDefinition(new MetricDefinitionAndTenantId(metric3, TENANT_ID), alarmDefinition.getId());
    assertEquals(this.createdAlarms.size(), 2);
    verifyCreatedAlarm(this.createdAlarms.get(1), alarmDefinition, collector, new MetricDefinitionAndTenantId(metric3, TENANT_ID), new MetricDefinitionAndTenantId(metric2, TENANT_ID));
}
#method_after
public void testReuseMetricFromExistingAlarm() {
    final boolean deterministic = false;
    final String expression = "max(cpu{service=vivi}) > 90";
    final String[] matchBy = new String[] { "hostname", "amplifier" };
    final AlarmDefinition alarmDefinition = createAlarmDefinition(expression, matchBy);
    final MetricDefinition metric = build("cpu", "hostname", "eleanore", "amplifier", "2", "service", "vivi");
    bolt.handleNewMetricDefinition(new MetricDefinitionAndTenantId(metric, TENANT_ID), alarmDefinition.getId());
    assertEquals(this.createdAlarms.size(), 1);
    verifyCreatedAlarm(this.createdAlarms.get(0), alarmDefinition, deterministic, collector, new MetricDefinitionAndTenantId(metric, TENANT_ID));
    final MetricDefinition metric2 = build("cpu", "hostname", "eleanore", "service", "vivi");
    sendNewMetric(new MetricDefinitionAndTenantId(metric2, TENANT_ID), alarmDefinition.getId());
    assertEquals(this.createdAlarms.size(), 1, "A second alarm was created instead of the metric fitting into the first");
    verifyCreatedAlarm(this.createdAlarms.get(0), alarmDefinition, deterministic, collector, new MetricDefinitionAndTenantId(metric, TENANT_ID), new MetricDefinitionAndTenantId(metric2, TENANT_ID));
    final MetricDefinition metric3 = build("cpu", "hostname", "eleanore", "amplifier", "3", "service", "vivi");
    bolt.handleNewMetricDefinition(new MetricDefinitionAndTenantId(metric3, TENANT_ID), alarmDefinition.getId());
    assertEquals(this.createdAlarms.size(), 2);
    verifyCreatedAlarm(this.createdAlarms.get(1), alarmDefinition, deterministic, collector, new MetricDefinitionAndTenantId(metric3, TENANT_ID), new MetricDefinitionAndTenantId(metric2, TENANT_ID));
}
#end_block

#method_before
public void testUseMetricInExistingAlarm() {
    final String expression = "max(cpu{service=vivi}) > 90";
    final String[] matchBy = new String[] { "hostname", "amplifier" };
    final AlarmDefinition alarmDefinition = createAlarmDefinition(expression, matchBy);
    final MetricDefinition metric = build("cpu", "hostname", "eleanore", "amplifier", "2", "service", "vivi");
    bolt.handleNewMetricDefinition(new MetricDefinitionAndTenantId(metric, TENANT_ID), alarmDefinition.getId());
    assertEquals(this.createdAlarms.size(), 1);
    verifyCreatedAlarm(this.createdAlarms.get(0), alarmDefinition, collector, new MetricDefinitionAndTenantId(metric, TENANT_ID));
    final MetricDefinition metric3 = build("cpu", "hostname", "eleanore", "amplifier", "3", "service", "vivi");
    bolt.handleNewMetricDefinition(new MetricDefinitionAndTenantId(metric3, TENANT_ID), alarmDefinition.getId());
    assertEquals(this.createdAlarms.size(), 2);
    verifyCreatedAlarm(this.createdAlarms.get(1), alarmDefinition, collector, new MetricDefinitionAndTenantId(metric3, TENANT_ID));
    final MetricDefinition metric2 = build("cpu", "hostname", "eleanore", "service", "vivi");
    sendNewMetric(new MetricDefinitionAndTenantId(metric2, TENANT_ID), alarmDefinition.getId());
    assertEquals(this.createdAlarms.size(), 2, "A third alarm was created instead of the metric fitting into the first two");
    verifyCreatedAlarm(this.createdAlarms.get(0), alarmDefinition, collector, new MetricDefinitionAndTenantId(metric, TENANT_ID), new MetricDefinitionAndTenantId(metric2, TENANT_ID));
    verifyCreatedAlarm(this.createdAlarms.get(1), alarmDefinition, collector, new MetricDefinitionAndTenantId(metric3, TENANT_ID), new MetricDefinitionAndTenantId(metric2, TENANT_ID));
}
#method_after
public void testUseMetricInExistingAlarm() {
    final boolean deterministic = false;
    final String expression = "max(cpu{service=vivi}) > 90";
    final String[] matchBy = new String[] { "hostname", "amplifier" };
    final AlarmDefinition alarmDefinition = createAlarmDefinition(expression, matchBy);
    final MetricDefinition metric = build("cpu", "hostname", "eleanore", "amplifier", "2", "service", "vivi");
    bolt.handleNewMetricDefinition(new MetricDefinitionAndTenantId(metric, TENANT_ID), alarmDefinition.getId());
    assertEquals(this.createdAlarms.size(), 1);
    verifyCreatedAlarm(this.createdAlarms.get(0), alarmDefinition, deterministic, collector, new MetricDefinitionAndTenantId(metric, TENANT_ID));
    final MetricDefinition metric3 = build("cpu", "hostname", "eleanore", "amplifier", "3", "service", "vivi");
    bolt.handleNewMetricDefinition(new MetricDefinitionAndTenantId(metric3, TENANT_ID), alarmDefinition.getId());
    assertEquals(this.createdAlarms.size(), 2);
    verifyCreatedAlarm(this.createdAlarms.get(1), alarmDefinition, deterministic, collector, new MetricDefinitionAndTenantId(metric3, TENANT_ID));
    final MetricDefinition metric2 = build("cpu", "hostname", "eleanore", "service", "vivi");
    sendNewMetric(new MetricDefinitionAndTenantId(metric2, TENANT_ID), alarmDefinition.getId());
    assertEquals(this.createdAlarms.size(), 2, "A third alarm was created instead of the metric fitting into the first two");
    verifyCreatedAlarm(this.createdAlarms.get(0), alarmDefinition, deterministic, collector, new MetricDefinitionAndTenantId(metric, TENANT_ID), new MetricDefinitionAndTenantId(metric2, TENANT_ID));
    verifyCreatedAlarm(this.createdAlarms.get(1), alarmDefinition, deterministic, collector, new MetricDefinitionAndTenantId(metric3, TENANT_ID), new MetricDefinitionAndTenantId(metric2, TENANT_ID));
}
#end_block

#method_before
public void testDeletedAlarm() {
    final AlarmDefinition alarmDefinition = runCreateSimpleAlarm();
    assertEquals(this.createdAlarms.size(), 1);
    final Alarm alarmToDelete = this.createdAlarms.get(0);
    this.createdAlarms.clear();
    final Map<String, AlarmSubExpression> subAlarms = new HashMap<>();
    for (final SubAlarm subAlarm : alarmToDelete.getSubAlarms()) {
        subAlarms.put(subAlarm.getId(), subAlarm.getExpression());
    }
    final List<MetricDefinition> alarmedMetrics = new ArrayList<>();
    for (final MetricDefinitionAndTenantId mdtid : alarmToDelete.getAlarmedMetrics()) {
        alarmedMetrics.add(mdtid.metricDefinition);
    }
    final AlarmDeletedEvent event = new AlarmDeletedEvent(TENANT_ID, alarmToDelete.getId(), alarmedMetrics, alarmToDelete.getAlarmDefinitionId(), subAlarms);
    final MkTupleParam tupleParam = new MkTupleParam();
    tupleParam.setFields(EventProcessingBolt.ALARM_EVENT_STREAM_FIELDS);
    tupleParam.setStream(EventProcessingBolt.ALARM_EVENT_STREAM_ID);
    final Tuple tuple = Testing.testTuple(Arrays.asList(EventProcessingBolt.DELETED, alarmToDelete.getId(), event), tupleParam);
    bolt.execute(tuple);
    // Make sure the alarm gets created again
    createAlarms(alarmDefinition);
}
#method_after
public void testDeletedAlarm() {
    final AlarmDefinition alarmDefinition = runCreateSimpleAlarm(false);
    assertEquals(this.createdAlarms.size(), 1);
    final Alarm alarmToDelete = this.createdAlarms.get(0);
    this.createdAlarms.clear();
    final Map<String, AlarmSubExpression> subAlarms = new HashMap<>();
    for (final SubAlarm subAlarm : alarmToDelete.getSubAlarms()) {
        subAlarms.put(subAlarm.getId(), subAlarm.getExpression());
    }
    final List<MetricDefinition> alarmedMetrics = new ArrayList<>();
    for (final MetricDefinitionAndTenantId mdtid : alarmToDelete.getAlarmedMetrics()) {
        alarmedMetrics.add(mdtid.metricDefinition);
    }
    final AlarmDeletedEvent event = new AlarmDeletedEvent(TENANT_ID, alarmToDelete.getId(), alarmedMetrics, alarmToDelete.getAlarmDefinitionId(), subAlarms);
    final MkTupleParam tupleParam = new MkTupleParam();
    tupleParam.setFields(EventProcessingBolt.ALARM_EVENT_STREAM_FIELDS);
    tupleParam.setStream(EventProcessingBolt.ALARM_EVENT_STREAM_ID);
    final Tuple tuple = Testing.testTuple(Arrays.asList(EventProcessingBolt.DELETED, alarmToDelete.getId(), event), tupleParam);
    bolt.execute(tuple);
    // Make sure the alarm gets created again
    createAlarms(alarmDefinition, false);
}
#end_block

#method_before
private AlarmDefinition runCreateSimpleAlarm(final String... matchBy) {
    final String expression = "max(cpu{service=2}) > 90";
    final AlarmDefinition alarmDefinition = createAlarmDefinition(expression, matchBy);
    createAlarms(alarmDefinition, matchBy);
    return alarmDefinition;
}
#method_after
private AlarmDefinition runCreateSimpleAlarm(final Boolean deterministic, final String... matchBy) {
    final String expression = String.format("max(cpu{service=2}%s) > 90", (deterministic ? ",deterministic" : ""));
    final AlarmDefinition alarmDefinition = createAlarmDefinition(expression, matchBy);
    this.createAlarms(alarmDefinition, deterministic, matchBy);
    return alarmDefinition;
}
#end_block

#method_before
private void createAlarms(final AlarmDefinition alarmDefinition, final String... matchBy) {
    final MetricDefinition metric = build("cpu", "hostname", "eleanore", "service", "2", "other", "vivi");
    bolt.handleNewMetricDefinition(new MetricDefinitionAndTenantId(metric, TENANT_ID), alarmDefinition.getId());
    assertEquals(this.createdAlarms.size(), 1);
    verifyCreatedAlarm(this.createdAlarms.get(0), alarmDefinition, collector, new MetricDefinitionAndTenantId(metric, TENANT_ID));
    final MetricDefinition metric2 = build("cpu", "hostname", "vivi", "service", "2", "other", "eleanore");
    sendNewMetric(new MetricDefinitionAndTenantId(metric2, TENANT_ID), alarmDefinition.getId());
    if (matchBy.length == 0) {
        assertEquals(this.createdAlarms.size(), 1, "A second alarm was created instead of the metric fitting into the first");
    } else {
        assertEquals(this.createdAlarms.size(), 2, "The metric was fitted into the first alarm instead of creating a new alarm");
        verifyCreatedAlarm(this.createdAlarms.get(1), alarmDefinition, collector, new MetricDefinitionAndTenantId(metric2, TENANT_ID));
        // Now send a metric that must fit into the just created alarm to test that
        // code path
        final MetricDefinition metric3 = build("cpu", "hostname", "vivi", "service", "2", "other", "maddyie");
        sendNewMetric(new MetricDefinitionAndTenantId(metric3, TENANT_ID), alarmDefinition.getId());
        assertEquals(this.createdAlarms.size(), 2, "The metric created a new alarm instead of fitting into the second");
        verifyCreatedAlarm(this.createdAlarms.get(1), alarmDefinition, collector, new MetricDefinitionAndTenantId(metric2, TENANT_ID), new MetricDefinitionAndTenantId(metric3, TENANT_ID));
    }
}
#method_after
private void createAlarms(final AlarmDefinition alarmDefinition, final Boolean deterministic, final String... matchBy) {
    final MetricDefinition metric = build("cpu", "hostname", "eleanore", "service", "2", "other", "vivi");
    bolt.handleNewMetricDefinition(new MetricDefinitionAndTenantId(metric, TENANT_ID), alarmDefinition.getId());
    assertEquals(this.createdAlarms.size(), 1);
    this.verifyCreatedAlarm(this.createdAlarms.get(0), alarmDefinition, deterministic, collector, new MetricDefinitionAndTenantId(metric, TENANT_ID));
    final MetricDefinition metric2 = build("cpu", "hostname", "vivi", "service", "2", "other", "eleanore");
    sendNewMetric(new MetricDefinitionAndTenantId(metric2, TENANT_ID), alarmDefinition.getId());
    if (matchBy.length == 0) {
        assertEquals(this.createdAlarms.size(), 1, "A second alarm was created instead of the metric fitting into the first");
    } else {
        assertEquals(this.createdAlarms.size(), 2, "The metric was fitted into the first alarm instead of creating a new alarm");
        verifyCreatedAlarm(this.createdAlarms.get(1), alarmDefinition, deterministic, collector, new MetricDefinitionAndTenantId(metric2, TENANT_ID));
        // Now send a metric that must fit into the just created alarm to test that
        // code path
        final MetricDefinition metric3 = build("cpu", "hostname", "vivi", "service", "2", "other", "maddyie");
        sendNewMetric(new MetricDefinitionAndTenantId(metric3, TENANT_ID), alarmDefinition.getId());
        assertEquals(this.createdAlarms.size(), 2, "The metric created a new alarm instead of fitting into the second");
        verifyCreatedAlarm(this.createdAlarms.get(1), alarmDefinition, deterministic, collector, new MetricDefinitionAndTenantId(metric2, TENANT_ID), new MetricDefinitionAndTenantId(metric3, TENANT_ID));
    }
}
#end_block

#method_before
private void runCreateComplexAlarm(final String... matchBy) {
    final AlarmDefinition alarmDefinition = createAlarmDefinition("max(cpu{service=2}) > 90 or max(load.avg{service=2}) > 5", matchBy);
    final MetricDefinition cpuMetric = build("cpu", "hostname", "eleanore", "service", "2", "other", "vivi");
    MetricDefinitionAndTenantId cpuMtid = new MetricDefinitionAndTenantId(cpuMetric, TENANT_ID);
    bolt.handleNewMetricDefinition(cpuMtid, alarmDefinition.getId());
    // Send it again to ensure it handles case where the metric is sent twice.
    // Should not happen but make sure bolt handles it
    bolt.handleNewMetricDefinition(cpuMtid, alarmDefinition.getId());
    final MetricDefinition loadAvgMetric = build("load.avg", "hostname", "eleanore", "service", "2", "other", "vivi");
    MetricDefinitionAndTenantId loadAvgMtid = new MetricDefinitionAndTenantId(loadAvgMetric, TENANT_ID);
    bolt.handleNewMetricDefinition(loadAvgMtid, alarmDefinition.getId());
    assertEquals(this.createdAlarms.size(), 1);
    verifyCreatedAlarm(this.createdAlarms.get(0), alarmDefinition, collector, cpuMtid, loadAvgMtid);
    // Send it again to ensure it handles case where the metric is sent after
    // the alarm has been created.
    // Should not happen but make sure bolt handles it
    bolt.handleNewMetricDefinition(cpuMtid, alarmDefinition.getId());
    assertEquals(this.createdAlarms.size(), 1);
    // Make sure it did not get added to the existing alarm
    verifyCreatedAlarm(this.createdAlarms.get(0), alarmDefinition, collector, cpuMtid, loadAvgMtid);
}
#method_after
private void runCreateComplexAlarm(final Boolean deterministic, final String... matchBy) {
    final String rawExpression = "max(cpu{service=2}%s) > 90 or max(load.avg{service=2}%s) > 5";
    final String expression;
    final AlarmDefinition alarmDefinition;
    if (deterministic) {
        expression = String.format(rawExpression, ",deterministic", ",deterministic");
    } else {
        expression = String.format(rawExpression, "", "");
    }
    alarmDefinition = this.createAlarmDefinition(expression, matchBy);
    final MetricDefinition cpuMetric = build("cpu", "hostname", "eleanore", "service", "2", "other", "vivi");
    MetricDefinitionAndTenantId cpuMtid = new MetricDefinitionAndTenantId(cpuMetric, TENANT_ID);
    bolt.handleNewMetricDefinition(cpuMtid, alarmDefinition.getId());
    // Send it again to ensure it handles case where the metric is sent twice.
    // Should not happen but make sure bolt handles it
    bolt.handleNewMetricDefinition(cpuMtid, alarmDefinition.getId());
    final MetricDefinition loadAvgMetric = build("load.avg", "hostname", "eleanore", "service", "2", "other", "vivi");
    MetricDefinitionAndTenantId loadAvgMtid = new MetricDefinitionAndTenantId(loadAvgMetric, TENANT_ID);
    bolt.handleNewMetricDefinition(loadAvgMtid, alarmDefinition.getId());
    assertEquals(this.createdAlarms.size(), 1);
    verifyCreatedAlarm(this.createdAlarms.get(0), alarmDefinition, deterministic, collector, cpuMtid, loadAvgMtid);
    // Send it again to ensure it handles case where the metric is sent after
    // the alarm has been created.
    // Should not happen but make sure bolt handles it
    bolt.handleNewMetricDefinition(cpuMtid, alarmDefinition.getId());
    assertEquals(this.createdAlarms.size(), 1);
    // Make sure it did not get added to the existing alarm
    verifyCreatedAlarm(this.createdAlarms.get(0), alarmDefinition, deterministic, collector, cpuMtid, loadAvgMtid);
}
#end_block

#method_before
private void verifyCreatedAlarm(final Alarm newAlarm, final AlarmDefinition alarmDefinition, final OutputCollector collector, MetricDefinitionAndTenantId... mtids) {
    final String alarmId = newAlarm.getId();
    final Alarm expectedAlarm = new Alarm(alarmDefinition, AlarmState.UNDETERMINED);
    expectedAlarm.setId(alarmId);
    final List<SubAlarm> expectedSubAlarms = new LinkedList<>();
    for (final SubAlarm expectedSubAlarm : expectedAlarm.getSubAlarms()) {
        boolean found = false;
        for (final SubAlarm newSubAlarm : newAlarm.getSubAlarms()) {
            if (expectedSubAlarm.getExpression().equals(newSubAlarm.getExpression())) {
                found = true;
                expectedSubAlarms.add(new SubAlarm(newSubAlarm.getId(), alarmId, new SubExpression(expectedSubAlarm.getAlarmSubExpressionId(), expectedSubAlarm.getExpression())));
                break;
            }
        }
        assertTrue(found, "SubAlarms for created Alarm don't match the Alarm Definition");
    }
    expectedAlarm.setSubAlarms(expectedSubAlarms);
    assertEquals(newAlarm.getAlarmedMetrics().size(), mtids.length);
    for (final SubAlarm subAlarm : expectedAlarm.getSubAlarms()) {
        // Have to do it this way because order of sub alarms is not deterministic
        MetricDefinitionAndTenantId mtid = null;
        for (final MetricDefinitionAndTenantId check : mtids) {
            if (subAlarm.getExpression().getMetricDefinition().name.equals(check.metricDefinition.name)) {
                mtid = check;
                break;
            }
        }
        assertNotNull(mtid, String.format("Did not find metric for %s", subAlarm.getExpression().getMetricDefinition().name));
        verify(collector, times(1)).emit(AlarmCreationBolt.ALARM_CREATION_STREAM, new Values(EventProcessingBolt.CREATED, new TenantIdAndMetricName(mtid), mtid, alarmDefinition.getId(), subAlarm));
    }
}
#method_after
private void verifyCreatedAlarm(final Alarm newAlarm, final AlarmDefinition alarmDefinition, final Boolean deterministic, final OutputCollector collector, MetricDefinitionAndTenantId... mtids) {
    final AlarmState expectedState = deterministic ? AlarmState.OK : AlarmState.UNDETERMINED;
    assertEquals(newAlarm.getState(), expectedState);
    final String alarmId = newAlarm.getId();
    final Alarm expectedAlarm = new Alarm(alarmDefinition);
    expectedAlarm.setId(alarmId);
    final List<SubAlarm> expectedSubAlarms = new LinkedList<>();
    for (final SubAlarm expectedSubAlarm : expectedAlarm.getSubAlarms()) {
        boolean found = false;
        for (final SubAlarm newSubAlarm : newAlarm.getSubAlarms()) {
            if (expectedSubAlarm.getExpression().equals(newSubAlarm.getExpression())) {
                found = true;
                expectedSubAlarms.add(new SubAlarm(newSubAlarm.getId(), alarmId, new SubExpression(expectedSubAlarm.getAlarmSubExpressionId(), expectedSubAlarm.getExpression())));
                break;
            }
        }
        assertTrue(found, "SubAlarms for created Alarm don't match the Alarm Definition");
    }
    expectedAlarm.setSubAlarms(expectedSubAlarms);
    assertEquals(newAlarm.getAlarmedMetrics().size(), mtids.length);
    for (final SubAlarm subAlarm : expectedAlarm.getSubAlarms()) {
        // Have to do it this way because order of sub alarms is not deterministic
        MetricDefinitionAndTenantId mtid = null;
        for (final MetricDefinitionAndTenantId check : mtids) {
            if (subAlarm.getExpression().getMetricDefinition().name.equals(check.metricDefinition.name)) {
                mtid = check;
                break;
            }
        }
        assertNotNull(mtid, String.format("Did not find metric for %s", subAlarm.getExpression().getMetricDefinition().name));
        verify(collector, times(1)).emit(AlarmCreationBolt.ALARM_CREATION_STREAM, new Values(EventProcessingBolt.CREATED, new TenantIdAndMetricName(mtid), mtid, alarmDefinition.getId(), subAlarm));
    }
}
#end_block

#method_before
@BeforeClass
protected void beforeClass() {
    // Other tests set this and that can cause problems when the test is run from Maven
    System.clearProperty(MetricAggregationBolt.TICK_TUPLE_SECONDS_KEY);
    subExpr1 = new SubExpression("444", AlarmSubExpression.of("avg(hpcs.compute.cpu{id=5}, 60) >= 90 times 3"));
    subExpr2 = new SubExpression("555", AlarmSubExpression.of("avg(hpcs.compute.mem{id=5}, 60) >= 90"));
    subExpr3 = new SubExpression("666", AlarmSubExpression.of("max(hpcs.compute.mem{id=5}, 60) >= 96"));
    metricDef1 = subExpr1.getAlarmSubExpression().getMetricDefinition();
    metricDef2 = subExpr2.getAlarmSubExpression().getMetricDefinition();
    metricDef3 = subExpr3.getAlarmSubExpression().getMetricDefinition();
}
#method_after
@BeforeClass
protected void beforeClass() {
    // Other tests set this and that can cause problems when the test is run from Maven
    System.clearProperty(MetricAggregationBolt.TICK_TUPLE_SECONDS_KEY);
    subExpr1 = new SubExpression("444", AlarmSubExpression.of("avg(hpcs.compute.cpu{id=5}, 60) >= 90 times 3"));
    subExpr2 = new SubExpression("555", AlarmSubExpression.of("avg(hpcs.compute.mem{id=5}, 60) >= 90"));
    subExpr3 = new SubExpression("666", AlarmSubExpression.of("max(hpcs.compute.mem{id=5}, 60) >= 96"));
    subExpr4 = new SubExpression("777", AlarmSubExpression.of("count(log.error{id=5},deterministic,60) >= 5"));
    metricDef1 = subExpr1.getAlarmSubExpression().getMetricDefinition();
    metricDef2 = subExpr2.getAlarmSubExpression().getMetricDefinition();
    metricDef3 = subExpr3.getAlarmSubExpression().getMetricDefinition();
    metricDef4 = subExpr4.getAlarmSubExpression().getMetricDefinition();
}
#end_block

#method_before
@BeforeMethod
protected void beforeMethod() {
    // Fixtures
    subAlarm1 = new SubAlarm(ALARM_ID_1, "1", subExpr1, AlarmState.UNDETERMINED);
    subAlarm2 = new SubAlarm("456", "1", subExpr2, AlarmState.UNDETERMINED);
    subAlarm3 = new SubAlarm("789", "2", subExpr3, AlarmState.UNDETERMINED);
    subAlarms = new ArrayList<>();
    subAlarms.add(subAlarm1);
    subAlarms.add(subAlarm2);
    subAlarms.add(subAlarm3);
    final ThresholdingConfiguration config = new ThresholdingConfiguration();
    config.alarmDelay = 10;
    bolt = new MockMetricAggregationBolt(config);
    context = mock(TopologyContext.class);
    collector = mock(OutputCollector.class);
    bolt.prepare(null, context, collector);
}
#method_after
@BeforeMethod
protected void beforeMethod() {
    // Fixtures
    subAlarm1 = new SubAlarm(ALARM_ID_1, "1", subExpr1);
    subAlarm2 = new SubAlarm("456", "1", subExpr2);
    subAlarm3 = new SubAlarm("789", "2", subExpr3);
    subAlarm4 = new SubAlarm("666", "3", subExpr4);
    subAlarms = new ArrayList<>();
    subAlarms.add(subAlarm1);
    subAlarms.add(subAlarm2);
    subAlarms.add(subAlarm3);
    subAlarms.add(subAlarm4);
    final ThresholdingConfiguration config = new ThresholdingConfiguration();
    config.alarmDelay = 10;
    bolt = new MockMetricAggregationBolt(config);
    context = mock(TopologyContext.class);
    collector = mock(OutputCollector.class);
    bolt.prepare(null, context, collector);
}
#end_block

#method_before
public void shouldAggregateValues() {
    sendSubAlarmCreated(metricDef1, subAlarm1);
    sendSubAlarmCreated(metricDef2, subAlarm2);
    long t1 = System.currentTimeMillis();
    bolt.aggregateValues(new MetricDefinitionAndTenantId(metricDef1, TENANT_ID), new Metric(metricDef1.name, metricDef1.dimensions, t1, 100, null));
    bolt.aggregateValues(new MetricDefinitionAndTenantId(metricDef1, TENANT_ID), new Metric(metricDef1.name, metricDef1.dimensions, t1, 80, null));
    bolt.aggregateValues(new MetricDefinitionAndTenantId(metricDef2, TENANT_ID), new Metric(metricDef2.name, metricDef2.dimensions, t1, 50, null));
    bolt.aggregateValues(new MetricDefinitionAndTenantId(metricDef2, TENANT_ID), new Metric(metricDef2.name, metricDef2.dimensions, t1, 40, null));
    SubAlarmStatsRepository orCreateSubAlarmStatsRepo = bolt.getOrCreateSubAlarmStatsRepo(new MetricDefinitionAndTenantId(metricDef1, TENANT_ID));
    SubAlarmStats alarmData = orCreateSubAlarmStatsRepo.get(subAlarm1.getId());
    assertEquals(alarmData.getStats().getValue(t1 / 1000), 90.0);
    alarmData = bolt.getOrCreateSubAlarmStatsRepo(new MetricDefinitionAndTenantId(metricDef2, TENANT_ID)).get(subAlarm2.getId());
    assertEquals(alarmData.getStats().getValue(t1 / 1000), 45.0);
}
#method_after
public void shouldAggregateValues() {
    sendSubAlarmCreated(metricDef1, subAlarm1);
    sendSubAlarmCreated(metricDef2, subAlarm2);
    sendSubAlarmCreated(metricDef4, subAlarm4);
    long t1 = System.currentTimeMillis();
    bolt.aggregateValues(new MetricDefinitionAndTenantId(metricDef1, TENANT_ID), new Metric(metricDef1.name, metricDef1.dimensions, t1, 100, null));
    bolt.aggregateValues(new MetricDefinitionAndTenantId(metricDef1, TENANT_ID), new Metric(metricDef1.name, metricDef1.dimensions, t1, 80, null));
    bolt.aggregateValues(new MetricDefinitionAndTenantId(metricDef2, TENANT_ID), new Metric(metricDef2.name, metricDef2.dimensions, t1, 50, null));
    bolt.aggregateValues(new MetricDefinitionAndTenantId(metricDef2, TENANT_ID), new Metric(metricDef2.name, metricDef2.dimensions, t1, 40, null));
    bolt.aggregateValues(new MetricDefinitionAndTenantId(metricDef4, TENANT_ID), new Metric(metricDef4.name, metricDef4.dimensions, t1, 1, null));
    bolt.aggregateValues(new MetricDefinitionAndTenantId(metricDef4, TENANT_ID), new Metric(metricDef4.name, metricDef4.dimensions, t1, 1, null));
    SubAlarmStatsRepository orCreateSubAlarmStatsRepo = bolt.getOrCreateSubAlarmStatsRepo(new MetricDefinitionAndTenantId(metricDef1, TENANT_ID));
    SubAlarmStats alarmData = orCreateSubAlarmStatsRepo.get(subAlarm1.getId());
    assertEquals(alarmData.getStats().getValue(t1 / 1000), 90.0);
    alarmData = bolt.getOrCreateSubAlarmStatsRepo(new MetricDefinitionAndTenantId(metricDef2, TENANT_ID)).get(subAlarm2.getId());
    assertEquals(alarmData.getStats().getValue(t1 / 1000), 45.0);
    alarmData = bolt.getOrCreateSubAlarmStatsRepo(new MetricDefinitionAndTenantId(metricDef4, TENANT_ID)).get(subAlarm4.getId());
    assertEquals(alarmData.getStats().getValue(t1 / 1000), 2.0);
}
#end_block

#method_before
public void shouldEvaluateAlarms() {
    // Ensure subAlarm2 and subAlarm3 map to the same Metric Definition
    assertEquals(metricDef3, metricDef2);
    long t1 = 170000;
    bolt.setCurrentTime(t1);
    sendSubAlarmCreated(metricDef1, subAlarm1);
    sendSubAlarmCreated(metricDef2, subAlarm2);
    sendSubAlarmCreated(metricDef3, subAlarm3);
    // Send metrics for subAlarm1
    bolt.execute(createMetricTuple(metricDef1, new Metric(metricDef1, t1, 100000, null)));
    bolt.execute(createMetricTuple(metricDef1, new Metric(metricDef1, t1 - 60000, 95, null)));
    bolt.execute(createMetricTuple(metricDef1, new Metric(metricDef1, t1 - 120000, 88, null)));
    t1 += 25000;
    bolt.setCurrentTime(t1);
    sendTickTuple();
    assertEquals(subAlarm1.getState(), AlarmState.OK);
    assertEquals(subAlarm2.getState(), AlarmState.UNDETERMINED);
    assertEquals(subAlarm3.getState(), AlarmState.UNDETERMINED);
    verify(collector, times(1)).emit(new Values(subAlarm1.getAlarmId(), subAlarm1));
    // Have to reset the mock so it can tell the difference when subAlarm2 and subAlarm3 are emitted
    // again.
    reset(collector);
    // Drive subAlarm1 to ALARM
    bolt.execute(createMetricTuple(metricDef1, new Metric(metricDef1, t1, 99, null)));
    // Drive subAlarm2 to ALARM and subAlarm3 to OK since they use the same MetricDefinition
    t1 += 10000;
    bolt.execute(createMetricTuple(metricDef2, new Metric(metricDef2, t1, 94, null)));
    t1 += 50000;
    bolt.setCurrentTime(t1);
    sendTickTuple();
    assertEquals(subAlarm1.getState(), AlarmState.ALARM);
    assertEquals(subAlarm2.getState(), AlarmState.ALARM);
    assertEquals(subAlarm3.getState(), AlarmState.OK);
    verify(collector, times(1)).emit(new Values(subAlarm1.getAlarmId(), subAlarm1));
    verify(collector, times(1)).emit(new Values(subAlarm2.getAlarmId(), subAlarm2));
    verify(collector, times(1)).emit(new Values(subAlarm3.getAlarmId(), subAlarm3));
}
#method_after
public void shouldEvaluateAlarms() {
    // Ensure subAlarm2 and subAlarm3 map to the same Metric Definition
    assertEquals(metricDef3, metricDef2);
    long t1 = 170000;
    bolt.setCurrentTime(t1);
    sendSubAlarmCreated(metricDef1, subAlarm1);
    sendSubAlarmCreated(metricDef2, subAlarm2);
    sendSubAlarmCreated(metricDef3, subAlarm3);
    sendSubAlarmCreated(metricDef4, subAlarm4);
    // Send metrics for subAlarm1
    bolt.execute(createMetricTuple(metricDef1, new Metric(metricDef1, t1, 100000, null)));
    bolt.execute(createMetricTuple(metricDef1, new Metric(metricDef1, t1 - 60000, 95, null)));
    bolt.execute(createMetricTuple(metricDef1, new Metric(metricDef1, t1 - 120000, 88, null)));
    t1 += 25000;
    bolt.setCurrentTime(t1);
    sendTickTuple();
    assertEquals(subAlarm1.getState(), AlarmState.OK);
    assertEquals(subAlarm2.getState(), AlarmState.UNDETERMINED);
    assertEquals(subAlarm3.getState(), AlarmState.UNDETERMINED);
    // deterministic
    assertEquals(subAlarm4.getState(), AlarmState.OK);
    verify(collector, times(1)).emit(new Values(subAlarm1.getAlarmId(), subAlarm1));
    // Have to reset the mock so it can tell the difference when subAlarm2 and subAlarm3 are emitted
    // again.
    reset(collector);
    // Drive subAlarm1 to ALARM
    bolt.execute(createMetricTuple(metricDef1, new Metric(metricDef1, t1, 99, null)));
    // Drive subAlarm2 to ALARM and subAlarm3 to OK since they use the same MetricDefinition
    t1 += 10000;
    bolt.execute(createMetricTuple(metricDef2, new Metric(metricDef2, t1, 94, null)));
    t1 += 50000;
    bolt.setCurrentTime(t1);
    sendTickTuple();
    assertEquals(subAlarm1.getState(), AlarmState.ALARM);
    assertEquals(subAlarm2.getState(), AlarmState.ALARM);
    assertEquals(subAlarm3.getState(), AlarmState.OK);
    assertEquals(subAlarm4.getState(), AlarmState.OK);
    verify(collector, times(1)).emit(new Values(subAlarm1.getAlarmId(), subAlarm1));
    verify(collector, times(1)).emit(new Values(subAlarm2.getAlarmId(), subAlarm2));
    verify(collector, times(1)).emit(new Values(subAlarm3.getAlarmId(), subAlarm3));
    verify(collector, times(1)).emit(new Values(subAlarm4.getAlarmId(), subAlarm4));
}
#end_block

#method_before
public void shouldImmediatelyEvaluateSubAlarm() {
    // Ensure subAlarm2 and subAlarm3 map to the same Metric Definition
    assertEquals(metricDef3, metricDef2);
    long t1 = 170000;
    bolt.setCurrentTime(t1);
    sendSubAlarmCreated(metricDef2, subAlarm2);
    sendSubAlarmCreated(metricDef3, subAlarm3);
    // Send metric for subAlarm2 and subAlarm3
    bolt.execute(createMetricTuple(metricDef3, new Metric(metricDef3, t1 + 1000, 100000, null)));
    // subAlarm2 is AVG so it can't be evaluated immediately like the MAX for subalarm3
    assertEquals(subAlarm2.getState(), AlarmState.UNDETERMINED);
    assertEquals(subAlarm3.getState(), AlarmState.ALARM);
    verify(collector, never()).emit(new Values(subAlarm2.getAlarmId(), subAlarm2));
    verify(collector, times(1)).emit(new Values(subAlarm3.getAlarmId(), subAlarm3));
    // Have to reset the mock so it can tell the difference when subAlarm2 and subAlarm3 are emitted
    // again.
    reset(collector);
    t1 = 195000;
    bolt.setCurrentTime(t1);
    sendTickTuple();
    assertEquals(subAlarm2.getState(), AlarmState.ALARM);
    assertEquals(subAlarm3.getState(), AlarmState.ALARM);
    verify(collector, times(1)).emit(new Values(subAlarm2.getAlarmId(), subAlarm2));
    verify(collector, never()).emit(new Values(subAlarm3.getAlarmId(), subAlarm3));
    // Have to reset the mock so it can tell the difference when subAlarm2 and subAlarm3 are emitted
    // again.
    reset(collector);
    // Now drive SubAlarms back to OK
    t1 = 235000;
    bolt.setCurrentTime(t1);
    bolt.execute(createMetricTuple(metricDef3, new Metric(metricDef3, t1 + 1000, 20, null)));
    t1 = 315000;
    bolt.setCurrentTime(t1);
    bolt.execute(createMetricTuple(metricDef3, new Metric(metricDef3, t1 + 1000, 20, null)));
    sendTickTuple();
    assertEquals(subAlarm2.getState(), AlarmState.OK);
    assertEquals(subAlarm3.getState(), AlarmState.OK);
    verify(collector, times(1)).emit(new Values(subAlarm2.getAlarmId(), subAlarm2));
    verify(collector, times(1)).emit(new Values(subAlarm3.getAlarmId(), subAlarm3));
    // Have to reset the mock so it can tell the difference when subAlarm2 and subAlarm3 are emitted
    // again.
    reset(collector);
    // Now send a metric that is after the window end time but within alarm delay
    t1 = 365000;
    bolt.setCurrentTime(t1);
    bolt.execute(createMetricTuple(metricDef3, new Metric(metricDef3, t1 + 1000, 100000, null)));
    // subAlarm2 is AVG so it can't be evaluated immediately like the MAX for subalarm3
    assertEquals(subAlarm2.getState(), AlarmState.OK);
    assertEquals(subAlarm3.getState(), AlarmState.ALARM);
    verify(collector, never()).emit(new Values(subAlarm2.getAlarmId(), subAlarm2));
    verify(collector, times(1)).emit(new Values(subAlarm3.getAlarmId(), subAlarm3));
    // Have to reset the mock so it can tell the difference when subAlarm2 and subAlarm3 are emitted
    // again.
    reset(collector);
    t1 = 375000;
    bolt.setCurrentTime(t1);
    sendTickTuple();
    // Ensure that subAlarm3 is still ALARM. subAlarm2 is still OK but because the metric
    // that triggered ALARM is in the future bucket
    assertEquals(subAlarm2.getState(), AlarmState.OK);
    assertEquals(subAlarm3.getState(), AlarmState.ALARM);
    verify(collector, never()).emit(new Values(subAlarm2.getAlarmId(), subAlarm2));
    verify(collector, never()).emit(new Values(subAlarm3.getAlarmId(), subAlarm3));
}
#method_after
public void shouldImmediatelyEvaluateSubAlarm() {
    // Ensure subAlarm2 and subAlarm3 map to the same Metric Definition
    assertEquals(metricDef3, metricDef2);
    long t1 = 170000;
    bolt.setCurrentTime(t1);
    sendSubAlarmCreated(metricDef2, subAlarm2);
    sendSubAlarmCreated(metricDef3, subAlarm3);
    sendSubAlarmCreated(metricDef4, subAlarm4);
    // Send metric for subAlarm2 and subAlarm3
    bolt.execute(createMetricTuple(metricDef3, new Metric(metricDef3, t1 + 1000, 100000, null)));
    for (int i = 0; i < 5; i++) {
        bolt.execute(createMetricTuple(metricDef4, new Metric(metricDef4, t1 + 1000 + i, 1, null)));
    }
    // subAlarm2 is AVG so it can't be evaluated immediately like the MAX for subalarm3
    // or count for subAlarm4
    assertEquals(subAlarm2.getState(), AlarmState.UNDETERMINED);
    assertEquals(subAlarm3.getState(), AlarmState.ALARM);
    assertEquals(subAlarm4.getState(), AlarmState.ALARM);
    verify(collector, never()).emit(new Values(subAlarm2.getAlarmId(), subAlarm2));
    verify(collector, times(1)).emit(new Values(subAlarm3.getAlarmId(), subAlarm3));
    verify(collector, times(1)).emit(new Values(subAlarm4.getAlarmId(), subAlarm4));
    // Have to reset the mock so it can tell the difference when subAlarm2 and subAlarm3 are emitted
    // again.
    reset(collector);
    t1 = 195000;
    bolt.setCurrentTime(t1);
    sendTickTuple();
    assertEquals(subAlarm2.getState(), AlarmState.ALARM);
    assertEquals(subAlarm3.getState(), AlarmState.ALARM);
    assertEquals(subAlarm4.getState(), AlarmState.ALARM);
    verify(collector, times(1)).emit(new Values(subAlarm2.getAlarmId(), subAlarm2));
    verify(collector, never()).emit(new Values(subAlarm3.getAlarmId(), subAlarm3));
    verify(collector, never()).emit(new Values(subAlarm4.getAlarmId(), subAlarm4));
    // Have to reset the mock so it can tell the difference when subAlarm2 and subAlarm3 are emitted
    // again.
    reset(collector);
    // Now drive SubAlarms back to OK
    t1 = 235000;
    bolt.setCurrentTime(t1);
    bolt.execute(createMetricTuple(metricDef3, new Metric(metricDef3, t1 + 1000, 20, null)));
    t1 = 315000;
    bolt.setCurrentTime(t1);
    bolt.execute(createMetricTuple(metricDef3, new Metric(metricDef3, t1 + 1000, 20, null)));
    sendTickTuple();
    assertEquals(subAlarm2.getState(), AlarmState.OK);
    assertEquals(subAlarm3.getState(), AlarmState.OK);
    // still in alarm
    assertEquals(subAlarm4.getState(), AlarmState.ALARM);
    verify(collector, times(1)).emit(new Values(subAlarm2.getAlarmId(), subAlarm2));
    verify(collector, times(1)).emit(new Values(subAlarm3.getAlarmId(), subAlarm3));
    verify(collector, never()).emit(new Values(subAlarm4.getAlarmId(), subAlarm4));
    // Have to reset the mock so it can tell the difference when subAlarm2 and subAlarm3 are emitted
    // again.
    reset(collector);
    // Now send a metric that is after the window end time but within alarm delay
    t1 = 365000;
    bolt.setCurrentTime(t1);
    bolt.execute(createMetricTuple(metricDef3, new Metric(metricDef3, t1 + 1000, 100000, null)));
    // subAlarm2 is AVG so it can't be evaluated immediately like the MAX for subalarm3
    assertEquals(subAlarm2.getState(), AlarmState.OK);
    assertEquals(subAlarm3.getState(), AlarmState.ALARM);
    verify(collector, never()).emit(new Values(subAlarm2.getAlarmId(), subAlarm2));
    verify(collector, times(1)).emit(new Values(subAlarm3.getAlarmId(), subAlarm3));
    // Have to reset the mock so it can tell the difference when subAlarm2 and subAlarm3 are emitted
    // again.
    reset(collector);
    t1 = 375000;
    bolt.setCurrentTime(t1);
    sendTickTuple();
    // Ensure that subAlarm3 is still ALARM. subAlarm2 is still OK but because the metric
    // that triggered ALARM is in the future bucket
    // subAlarm4 gets back to OK due to missing metrics
    assertEquals(subAlarm2.getState(), AlarmState.OK);
    assertEquals(subAlarm3.getState(), AlarmState.ALARM);
    assertEquals(subAlarm4.getState(), AlarmState.OK);
    verify(collector, never()).emit(new Values(subAlarm2.getAlarmId(), subAlarm2));
    verify(collector, never()).emit(new Values(subAlarm3.getAlarmId(), subAlarm3));
    verify(collector, times(1)).emit(new Values(subAlarm4.getAlarmId(), subAlarm4));
}
#end_block

#method_before
public SubAlarm duplicate(final SubAlarm original) {
    final SubAlarm newSubAlarm = new SubAlarm(original.getId(), original.getAlarmId(), new SubExpression(original.getAlarmSubExpressionId(), original.getExpression()), original.getState());
    newSubAlarm.setNoState(original.isNoState());
    newSubAlarm.setSporadicMetric(original.isSporadicMetric());
    newSubAlarm.setCurrentValues(original.getCurrentValues());
    return newSubAlarm;
}
#method_after
public SubAlarm duplicate(final SubAlarm original) {
    final SubAlarm newSubAlarm = new SubAlarm(original.getId(), original.getAlarmId(), new SubExpression(original.getAlarmSubExpressionId(), original.getExpression()), original.getState());
    newSubAlarm.setNoState(original.isNoState());
    newSubAlarm.setCurrentValues(original.getCurrentValues());
    return newSubAlarm;
}
#end_block

#method_before
private List<Alarm> finishesAlarm(AlarmDefinition alarmDefinition, MetricDefinitionAndTenantId metricDefinitionAndTenantId, List<Alarm> existingAlarms) {
    final List<Alarm> waitingAlarms = findMatchingWaitingAlarms(getWaitingAlarmsForAlarmDefinition(alarmDefinition), alarmDefinition, metricDefinitionAndTenantId);
    final List<Alarm> result = new LinkedList<>();
    if (waitingAlarms.isEmpty()) {
        final Alarm newAlarm = new Alarm(alarmDefinition, AlarmState.UNDETERMINED);
        newAlarm.addAlarmedMetric(metricDefinitionAndTenantId);
        reuseExistingMetric(newAlarm, alarmDefinition, existingAlarms);
        if (alarmIsComplete(newAlarm)) {
            logger.debug("New alarm is complete. Saving");
            saveAlarm(newAlarm);
            result.add(newAlarm);
        } else {
            logger.debug("Adding new alarm to the waiting list");
            addToWaitingAlarms(newAlarm, alarmDefinition);
        }
    } else {
        for (final Alarm waiting : waitingAlarms) {
            waiting.addAlarmedMetric(metricDefinitionAndTenantId);
            if (alarmIsComplete(waiting)) {
                removeFromWaitingAlarms(waiting, alarmDefinition);
                saveAlarm(waiting);
                result.add(waiting);
            }
        }
    }
    return result;
}
#method_after
private List<Alarm> finishesAlarm(AlarmDefinition alarmDefinition, MetricDefinitionAndTenantId metricDefinitionAndTenantId, List<Alarm> existingAlarms) {
    final List<Alarm> waitingAlarms = findMatchingWaitingAlarms(getWaitingAlarmsForAlarmDefinition(alarmDefinition), alarmDefinition, metricDefinitionAndTenantId);
    final List<Alarm> result = new LinkedList<>();
    if (waitingAlarms.isEmpty()) {
        final Alarm newAlarm = new Alarm(alarmDefinition);
        newAlarm.addAlarmedMetric(metricDefinitionAndTenantId);
        reuseExistingMetric(newAlarm, alarmDefinition, existingAlarms);
        if (alarmIsComplete(newAlarm)) {
            logger.debug("New alarm is complete. Saving");
            saveAlarm(newAlarm);
            result.add(newAlarm);
        } else {
            logger.debug("Adding new alarm to the waiting list");
            addToWaitingAlarms(newAlarm, alarmDefinition);
        }
    } else {
        for (final Alarm waiting : waitingAlarms) {
            waiting.addAlarmedMetric(metricDefinitionAndTenantId);
            if (alarmIsComplete(waiting)) {
                removeFromWaitingAlarms(waiting, alarmDefinition);
                saveAlarm(waiting);
                result.add(waiting);
            }
        }
    }
    return result;
}
#end_block

#method_before
@Override
public boolean equals(Object obj) {
    if (this == obj)
        return true;
    if (!super.equals(obj))
        return false;
    if (getClass() != obj.getClass())
        return false;
    NotificationMethod other = (NotificationMethod) obj;
    if (address == null) {
        if (other.address != null)
            return false;
    } else if (!address.equals(other.address))
        return false;
    if (name == null) {
        if (other.name != null)
            return false;
    } else if (!name.equals(other.name))
        return false;
    if (periodicInterval != other.periodicInterval)
        return false;
    if (type != other.type)
        return false;
    return true;
}
#method_after
@Override
public boolean equals(Object obj) {
    if (this == obj)
        return true;
    if (!super.equals(obj))
        return false;
    if (getClass() != obj.getClass())
        return false;
    NotificationMethod other = (NotificationMethod) obj;
    if (address == null) {
        if (other.address != null)
            return false;
    } else if (!address.equals(other.address))
        return false;
    if (name == null) {
        if (other.name != null)
            return false;
    } else if (!name.equals(other.name))
        return false;
    if (period != other.period)
        return false;
    if (type != other.type)
        return false;
    return true;
}
#end_block

#method_before
@Override
public int hashCode() {
    final int prime = 31;
    int result = super.hashCode();
    result = prime * result + ((address == null) ? 0 : address.hashCode());
    result = prime * result + ((name == null) ? 0 : name.hashCode());
    result = prime * result + ((type == null) ? 0 : type.hashCode());
    result = prime * result + periodicInterval;
    return result;
}
#method_after
@Override
public int hashCode() {
    final int prime = 31;
    int result = super.hashCode();
    result = prime * result + ((address == null) ? 0 : address.hashCode());
    result = prime * result + ((name == null) ? 0 : name.hashCode());
    result = prime * result + ((type == null) ? 0 : type.hashCode());
    result = prime * result + period;
    return result;
}
#end_block

#method_before
@Override
public boolean equals(Object obj) {
    if (this == obj)
        return true;
    if (obj == null)
        return false;
    if (getClass() != obj.getClass())
        return false;
    UpdateNotificationMethodCommand other = (UpdateNotificationMethodCommand) obj;
    if (address == null) {
        if (other.address != null)
            return false;
    } else if (!address.equals(other.address))
        return false;
    if (name == null) {
        if (other.name != null)
            return false;
    } else if (!name.equals(other.name))
        return false;
    if (periodicInterval == null) {
        if (other.periodicInterval != null)
            return false;
    } else if (!periodicInterval.equals(other.periodicInterval))
        return false;
    if (type != other.type)
        return false;
    return true;
}
#method_after
@Override
public boolean equals(Object obj) {
    if (this == obj)
        return true;
    if (obj == null)
        return false;
    if (getClass() != obj.getClass())
        return false;
    UpdateNotificationMethodCommand other = (UpdateNotificationMethodCommand) obj;
    if (address == null) {
        if (other.address != null)
            return false;
    } else if (!address.equals(other.address))
        return false;
    if (name == null) {
        if (other.name != null)
            return false;
    } else if (!name.equals(other.name))
        return false;
    if (period == null) {
        if (other.period != null)
            return false;
    } else if (!period.equals(other.period))
        return false;
    if (type != other.type)
        return false;
    return true;
}
#end_block

#method_before
public void validate() {
    NotificationMethodValidation.validate(type, address, periodicInterval);
}
#method_after
public void validate(List<Integer> validPeriods) {
    NotificationMethodValidation.validate(type, address, period, validPeriods);
}
#end_block

#method_before
public static void validate(NotificationMethodType type, String address, String periodicInterval) {
    int convertedPeriodicInterval = Validation.parseAndValidateNumber(periodicInterval, "periodic_interval");
    switch(type) {
        case EMAIL:
            {
                if (!EmailValidator.getInstance(true).isValid(address))
                    throw Exceptions.unprocessableEntity("Address %s is not of correct format", address);
                if (convertedPeriodicInterval != 0)
                    throw Exceptions.unprocessableEntity("Periodic interval can only be set with webhooks");
            }
            break;
        case WEBHOOK:
            {
                String[] schemes = { "http", "https" };
                UrlValidator urlValidator = new UrlValidator(schemes, UrlValidator.ALLOW_LOCAL_URLS | UrlValidator.ALLOW_2_SLASHES);
                if (!urlValidator.isValid(address))
                    throw Exceptions.unprocessableEntity("Address %s is not of correct format", address);
            }
            break;
        case PAGERDUTY:
            {
                if (convertedPeriodicInterval != 0)
                    throw Exceptions.unprocessableEntity("Periodic interval can only be set with webhooks");
            }
            break;
    }
    if (!VALID_PERIODIC_INTERVALS.contains(convertedPeriodicInterval)) {
        throw Exceptions.unprocessableEntity("%d is not a valid periodic interval", convertedPeriodicInterval);
    }
}
#method_after
public static void validate(NotificationMethodType type, String address, String period, List<Integer> validPeriods) {
    int convertedPeriod = Validation.parseAndValidateNumber(period, "period");
    switch(type) {
        case EMAIL:
            {
                if (!EmailValidator.getInstance(true).isValid(address))
                    throw Exceptions.unprocessableEntity("Address %s is not of correct format", address);
                if (convertedPeriod != 0)
                    throw Exceptions.unprocessableEntity("Period can not be non zero for Email");
            }
            break;
        case WEBHOOK:
            {
                String[] schemes = { "http", "https" };
                UrlValidator urlValidator = new UrlValidator(schemes, UrlValidator.ALLOW_LOCAL_URLS | UrlValidator.ALLOW_2_SLASHES);
                if (!urlValidator.isValid(address))
                    throw Exceptions.unprocessableEntity("Address %s is not of correct format", address);
            }
            break;
        case PAGERDUTY:
            {
                if (convertedPeriod != 0)
                    throw Exceptions.unprocessableEntity("Period can not be non zero for Pagerduty");
            }
            break;
    }
    if (convertedPeriod != 0 && !validPeriods.contains(convertedPeriod)) {
        throw Exceptions.unprocessableEntity("%d is not a valid period", convertedPeriod);
    }
}
#end_block

#method_before
@Override
protected void setupResources() throws Exception {
    super.setupResources();
    Handle handle = db.open();
    handle.execute("truncate table notification_method");
    handle.execute("insert into notification_method (id, tenant_id, name, type, address, created_at, updated_at) values ('29387234', 'notification-method-test', 'MyEmaila', 'EMAIL', 'a@b', NOW(), NOW())");
    db.close(handle);
    repo = new NotificationMethodMySqlRepoImpl(db, new PersistUtils());
    addResources(new NotificationMethodResource(repo, new PersistUtils()));
}
#method_after
@Override
protected void setupResources() throws Exception {
    super.setupResources();
    Handle handle = db.open();
    handle.execute("truncate table notification_method");
    handle.execute("insert into notification_method (id, tenant_id, name, type, address, created_at, updated_at) values ('29387234', 'notification-method-test', 'MyEmaila', 'EMAIL', 'a@b', NOW(), NOW())");
    db.close(handle);
    repo = new NotificationMethodMySqlRepoImpl(db, new PersistUtils());
    addResources(new NotificationMethodResource(config, repo, new PersistUtils()));
}
#end_block

#method_before
@POST
@Timed
@Consumes(MediaType.APPLICATION_JSON)
@Produces(MediaType.APPLICATION_JSON)
public Response create(@Context UriInfo uriInfo, @HeaderParam("X-Tenant-Id") String tenantId, @Valid CreateNotificationMethodCommand command) {
    command.validate();
    int periodicInterval = Validation.parseAndValidateNumber(command.periodicInterval, "periodic_interval");
    NotificationMethod notificationMethod = Links.hydrate(repo.create(tenantId, command.name, command.type, command.address, periodicInterval), uriInfo, false);
    return Response.created(URI.create(notificationMethod.getId())).entity(notificationMethod).build();
}
#method_after
@POST
@Timed
@Consumes(MediaType.APPLICATION_JSON)
@Produces(MediaType.APPLICATION_JSON)
public Response create(@Context UriInfo uriInfo, @HeaderParam("X-Tenant-Id") String tenantId, @Valid CreateNotificationMethodCommand command) {
    command.validate(this.validPeriods);
    int period = Validation.parseAndValidateNumber(command.period, "period");
    NotificationMethod notificationMethod = Links.hydrate(repo.create(tenantId, command.name, command.type, command.address, period), uriInfo, false);
    return Response.created(URI.create(notificationMethod.getId())).entity(notificationMethod).build();
}
#end_block

#method_before
@PUT
@Timed
@Path("/{notification_method_id}")
@Consumes(MediaType.APPLICATION_JSON)
@Produces(MediaType.APPLICATION_JSON)
public NotificationMethod update(@Context UriInfo uriInfo, @HeaderParam("X-Tenant-Id") String tenantId, @PathParam("notification_method_id") String notificationMethodId, @Valid UpdateNotificationMethodCommand command) {
    command.validate();
    int periodicInterval = Validation.parseAndValidateNumber(command.periodicInterval, "periodic_interval");
    return Links.hydrate(repo.update(tenantId, notificationMethodId, command.name, command.type, command.address, periodicInterval), uriInfo, true);
}
#method_after
@PUT
@Timed
@Path("/{notification_method_id}")
@Consumes(MediaType.APPLICATION_JSON)
@Produces(MediaType.APPLICATION_JSON)
public NotificationMethod update(@Context UriInfo uriInfo, @HeaderParam("X-Tenant-Id") String tenantId, @PathParam("notification_method_id") String notificationMethodId, @Valid UpdateNotificationMethodCommand command) {
    command.validate(this.validPeriods);
    int period = Validation.parseAndValidateNumber(command.period, "period");
    return Links.hydrate(repo.update(tenantId, notificationMethodId, command.name, command.type, command.address, period), uriInfo, true);
}
#end_block

#method_before
public void testValidationForEmail() {
    CreateNotificationMethodCommand newNotificationMethod = new CreateNotificationMethodCommand("MyEmail", NotificationMethodType.EMAIL, "name@domain.com", "0");
    newNotificationMethod.validate();
}
#method_after
public void testValidationForEmail() {
    CreateNotificationMethodCommand newNotificationMethod = new CreateNotificationMethodCommand("MyEmail", NotificationMethodType.EMAIL, "name@domain.com", "0");
    newNotificationMethod.validate(validPeriods);
}
#end_block

#method_before
@Test(expectedExceptions = WebApplicationException.class)
public void testValidationExceptionForEmail() throws Exception {
    CreateNotificationMethodCommand newNotificationMethod = new CreateNotificationMethodCommand("MyEmail", NotificationMethodType.EMAIL, "name@domain.", "0");
    newNotificationMethod.validate();
}
#method_after
@Test(expectedExceptions = WebApplicationException.class)
public void testValidationExceptionForEmail() throws Exception {
    CreateNotificationMethodCommand newNotificationMethod = new CreateNotificationMethodCommand("MyEmail", NotificationMethodType.EMAIL, "name@domain.", "0");
    newNotificationMethod.validate(validPeriods);
}
#end_block

#method_before
public void testValidationForWebhook() {
    CreateNotificationMethodCommand newNotificationMethod = new CreateNotificationMethodCommand("MyWebhook", NotificationMethodType.WEBHOOK, "http://somedomain.com", "0");
    newNotificationMethod.validate();
}
#method_after
public void testValidationForWebhook() {
    CreateNotificationMethodCommand newNotificationMethod = new CreateNotificationMethodCommand("MyWebhook", NotificationMethodType.WEBHOOK, "http://somedomain.com", "0");
    newNotificationMethod.validate(validPeriods);
}
#end_block

#method_before
@Test(expectedExceptions = WebApplicationException.class)
public void testValidationExceptionForWebhook() throws Exception {
    CreateNotificationMethodCommand newNotificationMethod = new CreateNotificationMethodCommand("MyWebhook", NotificationMethodType.WEBHOOK, "ftp://localhost", "0");
    newNotificationMethod.validate();
}
#method_after
@Test(expectedExceptions = WebApplicationException.class)
public void testValidationExceptionForWebhook() throws Exception {
    CreateNotificationMethodCommand newNotificationMethod = new CreateNotificationMethodCommand("MyWebhook", NotificationMethodType.WEBHOOK, "ftp://localhost", "0");
    newNotificationMethod.validate(validPeriods);
}
#end_block

#method_before
public void testValidationForPagerduty() {
    CreateNotificationMethodCommand newNotificationMethod = new CreateNotificationMethodCommand("MyPagerduty", NotificationMethodType.PAGERDUTY, "nzH2LVRdMzun11HNC2oD", "0");
    newNotificationMethod.validate();
}
#method_after
public void testValidationForPagerduty() {
    CreateNotificationMethodCommand newNotificationMethod = new CreateNotificationMethodCommand("MyPagerduty", NotificationMethodType.PAGERDUTY, "nzH2LVRdMzun11HNC2oD", "0");
    newNotificationMethod.validate(validPeriods);
}
#end_block

#method_before
@Override
public NotificationMethod create(String tenantId, String name, NotificationMethodType type, String address, int periodicInterval) {
    Transaction tx = null;
    Session session = null;
    try {
        session = sessionFactory.openSession();
        tx = session.beginTransaction();
        if (byTenantIdAndName(session, tenantId, name) != null) {
            throw new EntityExistsException("Notification method %s \"%s\" already exists.", tenantId, name);
        }
        final String id = UUID.randomUUID().toString();
        final DateTime now = this.getUTCNow();
        final NotificationMethodDb db = new NotificationMethodDb(id, tenantId, name, AlarmNotificationMethodType.valueOf(type.name()), address, periodicInterval, now, now);
        session.save(db);
        LOG.debug("Creating notification method {} for {}", name, tenantId);
        tx.commit();
        tx = null;
        return this.convertToNotificationMethod(db);
    } catch (RuntimeException e) {
        this.rollbackIfNotNull(tx);
        throw e;
    } finally {
        if (session != null) {
            session.close();
        }
    }
}
#method_after
@Override
public NotificationMethod create(String tenantId, String name, NotificationMethodType type, String address, int period) {
    Transaction tx = null;
    Session session = null;
    try {
        session = sessionFactory.openSession();
        tx = session.beginTransaction();
        if (byTenantIdAndName(session, tenantId, name) != null) {
            throw new EntityExistsException("Notification method %s \"%s\" already exists.", tenantId, name);
        }
        final String id = UUID.randomUUID().toString();
        final DateTime now = this.getUTCNow();
        final NotificationMethodDb db = new NotificationMethodDb(id, tenantId, name, AlarmNotificationMethodType.valueOf(type.name()), address, period, now, now);
        session.save(db);
        LOG.debug("Creating notification method {} for {}", name, tenantId);
        tx.commit();
        tx = null;
        return this.convertToNotificationMethod(db);
    } catch (RuntimeException e) {
        this.rollbackIfNotNull(tx);
        throw e;
    } finally {
        if (session != null) {
            session.close();
        }
    }
}
#end_block

#method_before
@Override
public NotificationMethod update(String tenantId, String notificationMethodId, String name, NotificationMethodType type, String address, int periodicInterval) {
    Session session = null;
    Transaction tx = null;
    try {
        session = sessionFactory.openSession();
        final NotificationMethodDb result = this.byTenantIdAndName(session, tenantId, name);
        if (result != null && !result.getId().equalsIgnoreCase(notificationMethodId)) {
            throw new EntityExistsException("Notification method %s \"%s\" already exists.", tenantId, name);
        }
        tx = session.beginTransaction();
        NotificationMethodDb db;
        if ((db = session.get(NotificationMethodDb.class, notificationMethodId)) == null) {
            throw new EntityNotFoundException("No notification method exists for %s", notificationMethodId);
        }
        db.setName(name);
        db.setType(AlarmNotificationMethodType.valueOf(type.name()));
        db.setAddress(address);
        db.setPeriodicInterval(periodicInterval);
        db.setUpdatedAt(this.getUTCNow());
        session.save(db);
        tx.commit();
        tx = null;
        return this.convertToNotificationMethod(db);
    } catch (RuntimeException e) {
        this.rollbackIfNotNull(tx);
        throw e;
    } finally {
        if (session != null) {
            session.close();
        }
    }
}
#method_after
@Override
public NotificationMethod update(String tenantId, String notificationMethodId, String name, NotificationMethodType type, String address, int period) {
    Session session = null;
    Transaction tx = null;
    try {
        session = sessionFactory.openSession();
        final NotificationMethodDb result = this.byTenantIdAndName(session, tenantId, name);
        if (result != null && !result.getId().equalsIgnoreCase(notificationMethodId)) {
            throw new EntityExistsException("Notification method %s \"%s\" already exists.", tenantId, name);
        }
        tx = session.beginTransaction();
        NotificationMethodDb db;
        if ((db = session.get(NotificationMethodDb.class, notificationMethodId)) == null) {
            throw new EntityNotFoundException("No notification method exists for %s", notificationMethodId);
        }
        db.setName(name);
        db.setType(AlarmNotificationMethodType.valueOf(type.name()));
        db.setAddress(address);
        db.setPeriod(period);
        db.setUpdatedAt(this.getUTCNow());
        session.save(db);
        tx.commit();
        tx = null;
        return this.convertToNotificationMethod(db);
    } catch (RuntimeException e) {
        this.rollbackIfNotNull(tx);
        throw e;
    } finally {
        if (session != null) {
            session.close();
        }
    }
}
#end_block

#method_before
protected NotificationMethod convertToNotificationMethod(final NotificationMethodDb db) {
    return db == null ? null : new NotificationMethod(db.getId(), db.getName(), NotificationMethodType.valueOf(db.getType().name()), db.getAddress(), db.getPeriodicInterval());
}
#method_after
protected NotificationMethod convertToNotificationMethod(final NotificationMethodDb db) {
    return db == null ? null : new NotificationMethod(db.getId(), db.getName(), NotificationMethodType.valueOf(db.getType().name()), db.getAddress(), db.getPeriod());
}
#end_block

#method_before
@Override
public boolean equals(Object obj) {
    if (this == obj)
        return true;
    if (obj == null)
        return false;
    if (getClass() != obj.getClass())
        return false;
    CreateNotificationMethodCommand other = (CreateNotificationMethodCommand) obj;
    if (address == null) {
        if (other.address != null)
            return false;
    } else if (!address.equals(other.address))
        return false;
    if (name == null) {
        if (other.name != null)
            return false;
    } else if (!name.equals(other.name))
        return false;
    if (periodicInterval == null) {
        if (other.periodicInterval != null)
            return false;
    } else if (!periodicInterval.equals(other.periodicInterval))
        return false;
    if (type != other.type)
        return false;
    return true;
}
#method_after
@Override
public boolean equals(Object obj) {
    if (this == obj)
        return true;
    if (obj == null)
        return false;
    if (getClass() != obj.getClass())
        return false;
    CreateNotificationMethodCommand other = (CreateNotificationMethodCommand) obj;
    if (address == null) {
        if (other.address != null)
            return false;
    } else if (!address.equals(other.address))
        return false;
    if (name == null) {
        if (other.name != null)
            return false;
    } else if (!name.equals(other.name))
        return false;
    if (period == null) {
        if (other.period != null)
            return false;
    } else if (!period.equals(other.period))
        return false;
    if (type != other.type)
        return false;
    return true;
}
#end_block

#method_before
public void validate() {
    NotificationMethodValidation.validate(type, address, periodicInterval);
}
#method_after
public void validate(List<Integer> validPeriods) {
    NotificationMethodValidation.validate(type, address, period, validPeriods);
}
#end_block

#method_before
@Override
protected void setupResources() throws Exception {
    super.setupResources();
    notificationMethod = new NotificationMethod("123", "Joe's Email", NotificationMethodType.EMAIL, "a@b", 0);
    notificationMethodWebhook = new NotificationMethod("1234", "MyWh", NotificationMethodType.WEBHOOK, "http://localhost", 0);
    notificationMethodPagerduty = new NotificationMethod("12345", "MyPd", NotificationMethodType.PAGERDUTY, "nzH2LVRdMzun11HNC2oD", 0);
    repo = mock(NotificationMethodRepo.class);
    when(repo.create(eq("abc"), eq("MyEmail"), eq(NotificationMethodType.EMAIL), anyString(), eq(0))).thenReturn(notificationMethod);
    when(repo.create(eq("abc"), eq("MyWh"), eq(NotificationMethodType.WEBHOOK), anyString(), anyInt())).thenReturn(notificationMethodWebhook);
    when(repo.create(eq("abc"), eq("MyPd"), eq(NotificationMethodType.PAGERDUTY), anyString(), eq(0))).thenReturn(notificationMethodPagerduty);
    when(repo.findById(eq("abc"), eq("123"))).thenReturn(notificationMethod);
    when(repo.find(eq("abc"), (List<String>) anyList(), anyString(), anyInt())).thenReturn(Arrays.asList(notificationMethod));
    addResources(new NotificationMethodResource(repo, new PersistUtils()));
}
#method_after
@Override
protected void setupResources() throws Exception {
    super.setupResources();
    notificationMethod = new NotificationMethod("123", "Joe's Email", NotificationMethodType.EMAIL, "a@b", 0);
    notificationMethodWebhook = new NotificationMethod("1234", "MyWh", NotificationMethodType.WEBHOOK, "http://localhost", 60);
    notificationMethodPagerduty = new NotificationMethod("12345", "MyPd", NotificationMethodType.PAGERDUTY, "nzH2LVRdMzun11HNC2oD", 0);
    repo = mock(NotificationMethodRepo.class);
    when(repo.create(eq("abc"), eq("MyEmail"), eq(NotificationMethodType.EMAIL), anyString(), eq(0))).thenReturn(notificationMethod);
    when(repo.create(eq("abc"), eq("MyWh"), eq(NotificationMethodType.WEBHOOK), anyString(), anyInt())).thenReturn(notificationMethodWebhook);
    when(repo.create(eq("abc"), eq("MyPd"), eq(NotificationMethodType.PAGERDUTY), anyString(), eq(0))).thenReturn(notificationMethodPagerduty);
    when(repo.findById(eq("abc"), eq("123"))).thenReturn(notificationMethod);
    when(repo.find(eq("abc"), (List<String>) anyList(), anyString(), anyInt())).thenReturn(Arrays.asList(notificationMethod));
    config = mock(ApiConfig.class);
    config.validNotificationPeriods = Arrays.asList(0, 60);
    addResources(new NotificationMethodResource(config, repo, new PersistUtils()));
}
#end_block

#method_before
@Override
public NotificationMethod create(String tenantId, String name, NotificationMethodType type, String address, int periodicInterval) {
    try (Handle h = db.open()) {
        h.begin();
        if (getNotificationIdForTenantIdAndName(h, tenantId, name) != null)
            throw new EntityExistsException("Notification method %s \"%s\" already exists.", tenantId, name);
        String id = UUID.randomUUID().toString();
        h.insert("insert into notification_method (id, tenant_id, name, type, address, periodic_interval, created_at, updated_at) values (?, ?, ?, ?, ?, ?, NOW(), NOW())", id, tenantId, name, type.toString(), address, periodicInterval);
        LOG.debug("Creating notification method {} for {}", name, tenantId);
        h.commit();
        return new NotificationMethod(id, name, type, address, periodicInterval);
    }
}
#method_after
@Override
public NotificationMethod create(String tenantId, String name, NotificationMethodType type, String address, int period) {
    try (Handle h = db.open()) {
        h.begin();
        if (getNotificationIdForTenantIdAndName(h, tenantId, name) != null)
            throw new EntityExistsException("Notification method %s \"%s\" already exists.", tenantId, name);
        String id = UUID.randomUUID().toString();
        h.insert("insert into notification_method (id, tenant_id, name, type, address, period, created_at, updated_at) values (?, ?, ?, ?, ?, ?, NOW(), NOW())", id, tenantId, name, type.toString(), address, period);
        LOG.debug("Creating notification method {} for {}", name, tenantId);
        h.commit();
        return new NotificationMethod(id, name, type, address, period);
    }
}
#end_block

#method_before
@Override
public List<NotificationMethod> find(String tenantId, List<String> sortBy, String offset, int limit) {
    try (Handle h = db.open()) {
        String rawQuery = "  SELECT nm.id, nm.tenant_id, nm.name, nm.type, nm.address, nm.periodic_interval, nm.created_at, nm.updated_at " + "FROM notification_method as nm " + "WHERE tenant_id = :tenantId %1$s %2$s %3$s";
        String offsetPart = "";
        if (offset != null) {
            offsetPart = "and nm.id > :offset";
        }
        String orderByPart = "";
        if (sortBy != null && !sortBy.isEmpty()) {
            orderByPart = " order by " + COMMA_JOINER.join(sortBy);
            if (!orderByPart.contains("id")) {
                orderByPart = orderByPart + ",id";
            }
        } else {
            orderByPart = " order by id ";
        }
        String limitPart = "";
        if (limit > 0) {
            limitPart = " limit :limit";
        }
        String query = String.format(rawQuery, offsetPart, orderByPart, limitPart);
        Query<?> q = h.createQuery(query);
        q.bind("tenantId", tenantId);
        if (offset != null) {
            q.bind("offset", offset);
        }
        if (limit > 0) {
            q.bind("limit", limit + 1);
        }
        return q.map(new BeanMapper<>(NotificationMethod.class)).list();
    }
}
#method_after
@Override
public List<NotificationMethod> find(String tenantId, List<String> sortBy, String offset, int limit) {
    try (Handle h = db.open()) {
        String rawQuery = "  SELECT nm.id, nm.tenant_id, nm.name, nm.type, nm.address, nm.period, nm.created_at, nm.updated_at " + "FROM notification_method as nm " + "WHERE tenant_id = :tenantId %1$s %2$s %3$s";
        String offsetPart = "";
        if (offset != null) {
            offsetPart = "and nm.id > :offset";
        }
        String orderByPart = "";
        if (sortBy != null && !sortBy.isEmpty()) {
            orderByPart = " order by " + COMMA_JOINER.join(sortBy);
            if (!orderByPart.contains("id")) {
                orderByPart = orderByPart + ",id";
            }
        } else {
            orderByPart = " order by id ";
        }
        String limitPart = "";
        if (limit > 0) {
            limitPart = " limit :limit";
        }
        String query = String.format(rawQuery, offsetPart, orderByPart, limitPart);
        Query<?> q = h.createQuery(query);
        q.bind("tenantId", tenantId);
        if (offset != null) {
            q.bind("offset", offset);
        }
        if (limit > 0) {
            q.bind("limit", limit + 1);
        }
        return q.map(new BeanMapper<>(NotificationMethod.class)).list();
    }
}
#end_block

#method_before
@Override
public NotificationMethod update(String tenantId, String notificationMethodId, String name, NotificationMethodType type, String address, int periodicInterval) {
    try (Handle h = db.open()) {
        h.begin();
        String notificationID = getNotificationIdForTenantIdAndName(h, tenantId, name);
        if (notificationID != null && !notificationID.equalsIgnoreCase(notificationMethodId)) {
            throw new EntityExistsException("Notification method %s \"%s\" already exists.", tenantId, name);
        }
        if (h.update("update notification_method set name = ?, type = ?, address = ?, periodic_interval = ?, updated_at = NOW() " + "where tenant_id = ? and id = ?", name, type.name(), address, periodicInterval, tenantId, notificationMethodId) == 0)
            throw new EntityNotFoundException("No notification method exists for %s", notificationMethodId);
        h.commit();
        return new NotificationMethod(notificationMethodId, name, type, address, periodicInterval);
    }
}
#method_after
@Override
public NotificationMethod update(String tenantId, String notificationMethodId, String name, NotificationMethodType type, String address, int period) {
    try (Handle h = db.open()) {
        h.begin();
        String notificationID = getNotificationIdForTenantIdAndName(h, tenantId, name);
        if (notificationID != null && !notificationID.equalsIgnoreCase(notificationMethodId)) {
            throw new EntityExistsException("Notification method %s \"%s\" already exists.", tenantId, name);
        }
        if (h.update("update notification_method set name = ?, type = ?, address = ?, period = ?, updated_at = NOW() " + "where tenant_id = ? and id = ?", name, type.name(), address, period, tenantId, notificationMethodId) == 0)
            throw new EntityNotFoundException("No notification method exists for %s", notificationMethodId);
        h.commit();
        return new NotificationMethod(notificationMethodId, name, type, address, period);
    }
}
#end_block

#method_before
@Override
public List<Statistics> find(String tenantId, String name, Map<String, String> dimensions, DateTime startTime, DateTime endTime, List<String> statisticsCols, int period, String offset, int limit, Boolean mergeMetricsFlag) throws MultipleMetricsException {
    List<Statistics> statisticsList = new ArrayList<>();
    // Sort the column names so that they match the order of the statistics in the results.
    List<String> statisticsColumns = createColumnsList(statisticsCols);
    try (Handle h = db.open()) {
        Map<byte[], Statistics> byteMap = findDefIds(h, tenantId, name, dimensions);
        if (byteMap.isEmpty()) {
            return statisticsList;
        }
        if (!Boolean.TRUE.equals(mergeMetricsFlag) && byteMap.keySet().size() > 1) {
            throw new MultipleMetricsException(name, dimensions);
        }
        List<List<Object>> statisticsListList = new ArrayList<>();
        String sql = createQuery(byteMap.keySet(), period, startTime, endTime, offset, statisticsCols);
        logger.debug("vertica sql: {}", sql);
        Query<Map<String, Object>> query = h.createQuery(sql).bind("start_time", startTime).bind("end_time", endTime).bind("limit", limit + 1);
        if (offset != null && !offset.isEmpty()) {
            logger.debug("binding offset: {}", offset);
            query.bind("offset", new Timestamp(DateTime.parse(offset).getMillis()));
        }
        List<Map<String, Object>> rows = query.list();
        for (Map<String, Object> row : rows) {
            List<Object> statisticsRow = parseRow(row);
            statisticsListList.add(statisticsRow);
        }
        // Just use the first entry in the byteMap to get the def name and dimensions.
        Statistics statistics = byteMap.entrySet().iterator().next().getValue();
        statistics.setColumns(statisticsColumns);
        if (Boolean.TRUE.equals(mergeMetricsFlag) && byteMap.keySet().size() > 1) {
            // Wipe out the dimensions.
            statistics.setDimensions(new HashMap<String, String>());
        }
        statistics.setStatistics(statisticsListList);
        statisticsList.add(statistics);
    }
    return statisticsList;
}
#method_after
@Override
public List<Statistics> find(String tenantId, String name, Map<String, String> dimensions, DateTime startTime, DateTime endTime, List<String> statisticsCols, int period, String offset, int limit, Boolean mergeMetricsFlag, String groupBy) throws MultipleMetricsException {
    List<Statistics> statisticsList = new ArrayList<>();
    // Sort the column names so that they match the order of the statistics in the results.
    List<String> statisticsColumns = createColumnsList(statisticsCols);
    try (Handle h = db.open()) {
        Map<String, Statistics> byteMap = findDefIds(h, tenantId, name, dimensions);
        if (byteMap.isEmpty()) {
            return statisticsList;
        }
        if (!"*".equals(groupBy) && !Boolean.TRUE.equals(mergeMetricsFlag) && byteMap.keySet().size() > 1) {
            throw new MultipleMetricsException(name, dimensions);
        }
        List<List<Object>> statisticsListList = new ArrayList<>();
        String sql = createQuery(byteMap.keySet(), period, startTime, endTime, offset, statisticsCols, groupBy, mergeMetricsFlag);
        logger.debug("vertica sql: {}", sql);
        Query<Map<String, Object>> query = h.createQuery(sql).bind("start_time", startTime).bind("end_time", endTime).bind("limit", limit + 1);
        if (offset != null && !offset.isEmpty()) {
            logger.debug("binding offset: {}", offset);
            MetricQueries.bindOffsetToQuery(query, offset);
        }
        List<Map<String, Object>> rows = query.list();
        if ("*".equals(groupBy)) {
            for (Map<String, Object> row : rows) {
                List<Object> statisticsRow = parseRow(row);
                String defDimsId = (String) row.get("id");
                byteMap.get(defDimsId).addStatistics(statisticsRow);
            }
            for (Map.Entry<String, Statistics> entry : byteMap.entrySet()) {
                Statistics statistics = entry.getValue();
                statistics.setColumns(statisticsColumns);
                if (statistics.getStatistics().size() > 0) {
                    statisticsList.add(statistics);
                }
            }
        } else {
            for (Map<String, Object> row : rows) {
                List<Object> statisticsRow = parseRow(row);
                statisticsListList.add(statisticsRow);
            }
            // Just use the first entry in the byteMap to get the def name and dimensions.
            Statistics statistics = byteMap.entrySet().iterator().next().getValue();
            statistics.setColumns(statisticsColumns);
            if (Boolean.TRUE.equals(mergeMetricsFlag) && byteMap.keySet().size() > 1) {
                // Wipe out the dimensions.
                statistics.setDimensions(new HashMap<String, String>());
            }
            statistics.setStatistics(statisticsListList);
            statisticsList.add(statistics);
        }
    }
    return statisticsList;
}
#end_block

#method_before
private Map<byte[], Statistics> findDefIds(Handle h, String tenantId, String name, Map<String, String> dimensions) {
    List<byte[]> bytes = new ArrayList<>();
    StringBuilder sb = new StringBuilder();
    if (name != null && !name.isEmpty()) {
        sb.append(" and def.name = :name");
    }
    String sql = String.format(FIND_BY_METRIC_DEF_SQL, this.dbHint, sb, MetricQueries.buildDimensionAndClause(dimensions, TABLE_TO_JOIN_DIMENSIONS_ON, 0));
    Query<Map<String, Object>> query = h.createQuery(sql).bind("tenantId", tenantId);
    if (name != null && !name.isEmpty()) {
        logger.debug("binding name: {}", name);
        query.bind("name", name);
    }
    MetricQueries.bindDimensionsToQuery(query, dimensions);
    List<Map<String, Object>> rows = query.list();
    Map<byte[], Statistics> byteIdMap = new HashMap<>();
    byte[] currentDefDimId = null;
    Map<String, String> dims = null;
    for (Map<String, Object> row : rows) {
        byte[] defDimId = (byte[]) row.get("id");
        String defName = (String) row.get("name");
        String dimName = (String) row.get("dname");
        String dimValue = (String) row.get("dvalue");
        if (defDimId == null || !Arrays.equals(currentDefDimId, defDimId)) {
            currentDefDimId = defDimId;
            dims = new HashMap<>();
            dims.put(dimName, dimValue);
            Statistics statistics = new Statistics();
            statistics.setName(defName);
            statistics.setDimensions(dims);
            byteIdMap.put(currentDefDimId, statistics);
        } else {
            dims.put(dimName, dimValue);
        }
    }
    bytes.add(currentDefDimId);
    return byteIdMap;
}
#method_after
private Map<String, Statistics> findDefIds(Handle h, String tenantId, String name, Map<String, String> dimensions) {
    String sql = String.format(MetricQueries.FIND_METRIC_DEFS_SQL, this.dbHint, MetricQueries.buildMetricDefinitionSubSql(name, dimensions));
    Query<Map<String, Object>> query = h.createQuery(sql).bind("tenantId", tenantId);
    if (name != null && !name.isEmpty()) {
        logger.debug("binding name: {}", name);
        query.bind("name", name);
    }
    MetricQueries.bindDimensionsToQuery(query, dimensions);
    List<Map<String, Object>> rows = query.list();
    Map<String, Statistics> byteIdMap = new HashMap<>();
    String currentDefDimId = null;
    Map<String, String> dims = null;
    for (Map<String, Object> row : rows) {
        String defDimId = (String) row.get("defDimsId");
        String defName = (String) row.get("name");
        String dimName = (String) row.get("dName");
        String dimValue = (String) row.get("dValue");
        if (defDimId == null || !defDimId.equals(currentDefDimId)) {
            currentDefDimId = defDimId;
            dims = new HashMap<>();
            dims.put(dimName, dimValue);
            Statistics statistics = new Statistics();
            statistics.setId(defDimId);
            statistics.setName(defName);
            statistics.setDimensions(dims);
            byteIdMap.put(currentDefDimId, statistics);
        } else {
            dims.put(dimName, dimValue);
        }
    }
    return byteIdMap;
}
#end_block

#method_before
private String createQuery(Set<byte[]> defDimIdSet, int period, DateTime startTime, DateTime endTime, String offset, List<String> statistics) {
    StringBuilder sb = new StringBuilder();
    sb.append("SELECT " + this.dbHint + " " + createColumnsStr(statistics));
    if (period >= 1) {
        sb.append("Time_slice(time_stamp, " + period);
        sb.append(", 'SECOND', 'END') AS time_interval");
    }
    sb.append(" FROM MonMetrics.Measurements ");
    String inClause = MetricQueries.createDefDimIdInClause(defDimIdSet);
    sb.append("WHERE to_hex(definition_dimensions_id) " + inClause);
    sb.append(createWhereClause(startTime, endTime, offset));
    if (period >= 1) {
        sb.append("group by Time_slice(time_stamp, " + period);
        sb.append(", 'SECOND', 'END') order by time_interval");
    }
    sb.append(" limit :limit");
    return sb.toString();
}
#method_after
private String createQuery(Set<String> defDimIdSet, int period, DateTime startTime, DateTime endTime, String offset, List<String> statistics, String groupBy, Boolean mergeMetricsFlag) {
    StringBuilder sb = new StringBuilder();
    sb.append("SELECT " + this.dbHint + " ");
    if (groupBy != null && !groupBy.isEmpty()) {
        sb.append(" to_hex(definition_dimensions_id) AS id, ");
    }
    sb.append(createColumnsStr(statistics));
    if (period >= 1) {
        sb.append("Time_slice(time_stamp, ").append(period);
        sb.append(", 'SECOND', 'START') AS time_interval");
    }
    sb.append(" FROM MonMetrics.Measurements ");
    String inClause = MetricQueries.createDefDimIdInClause(defDimIdSet);
    sb.append("WHERE to_hex(definition_dimensions_id) ").append(inClause);
    sb.append(createWhereClause(startTime, endTime, offset, mergeMetricsFlag));
    if (period >= 1) {
        sb.append(" group by ");
        if (groupBy != null && !groupBy.isEmpty()) {
            sb.append("definition_dimensions_id,");
        }
        sb.append("time_interval ");
        sb.append(" order by ");
        if (groupBy != null && !groupBy.isEmpty()) {
            sb.append("to_hex(definition_dimensions_id),");
        }
        sb.append("time_interval ");
    }
    sb.append(" limit :limit");
    return sb.toString();
}
#end_block

#method_before
private String createWhereClause(DateTime startTime, DateTime endTime, String offset) {
    String s = "";
    if (startTime != null && endTime != null) {
        s = "AND time_stamp >= :start_time AND time_stamp <= :end_time ";
    } else if (startTime != null) {
        s = "AND time_stamp >= :start_time ";
    }
    if (offset != null && !offset.isEmpty()) {
        s += " and time_stamp > :offset ";
    }
    return s;
}
#method_after
private String createWhereClause(DateTime startTime, DateTime endTime, String offset, Boolean mergeMetricsFlag) {
    String s = "";
    if (startTime != null && endTime != null) {
        s = "AND time_stamp >= :start_time AND time_stamp <= :end_time ";
    } else if (startTime != null) {
        s = "AND time_stamp >= :start_time ";
    }
    if (offset != null && !offset.isEmpty()) {
        if (Boolean.FALSE.equals(mergeMetricsFlag)) {
            s += " AND (TO_HEX(definition_dimensions_id) > :offset_id " + "OR (TO_HEX(definition_dimensions_id) = :offset_id AND time_stamp > :offset_timestamp)) ";
        } else {
            s += " AND time_stamp > :offset_timestamp ";
        }
    }
    return s;
}
#end_block

#method_before
public void shouldFindWithoutDimensions() throws Exception {
    Collection<Measurements> measurements = repo.find("bob", "cpu_utilization", null, new DateTime(2014, 1, 1, 0, 0, 0), null, null, 1, false);
    assertEquals(measurements.size(), 3);
}
#method_after
public void shouldFindWithoutDimensions() throws Exception {
    Collection<Measurements> measurements = repo.find("bob", "cpu_utilization", null, new DateTime(2014, 1, 1, 0, 0, 0), null, null, 1, false, null);
    assertEquals(measurements.size(), 3);
}
#end_block

#method_before
public void shouldFindWithDimensions() throws Exception {
    Map<String, String> dims = new HashMap<>();
    dims.put("service", "compute");
    dims.put("instance_id", "123");
    Collection<Measurements> measurements = repo.find("bob", "cpu_utilization", dims, new DateTime(2014, 1, 1, 0, 0), null, null, 1, false);
    assertEquals(measurements.size(), 2);
    dims.put("flavor_id", "2");
    measurements = repo.find("bob", "cpu_utilization", dims, new DateTime(2014, 1, 1, 0, 0), null, null, 1, false);
    assertEquals(measurements.size(), 1);
}
#method_after
public void shouldFindWithDimensions() throws Exception {
    Map<String, String> dims = new HashMap<>();
    dims.put("service", "compute");
    dims.put("instance_id", "123");
    Collection<Measurements> measurements = repo.find("bob", "cpu_utilization", dims, new DateTime(2014, 1, 1, 0, 0), null, null, 1, false, null);
    assertEquals(measurements.size(), 2);
    dims.put("flavor_id", "2");
    measurements = repo.find("bob", "cpu_utilization", dims, new DateTime(2014, 1, 1, 0, 0), null, null, 1, false, null);
    assertEquals(measurements.size(), 1);
}
#end_block

#method_before
private List<Map<String, Object>> executeMetricNamesQuery(String tenantId, Map<String, String> dimensions, String offset, int limit) {
    String offsetPart = "";
    if (offset != null && !offset.isEmpty()) {
        offsetPart = " and defSub.id > :offset ";
    }
    // Can't bind limit in a nested sub query. So, just tack on as String.
    String limitPart = " limit " + Integer.toString(limit + 1);
    String defSubSelect = String.format(METRIC_NAMES_SUB_SELECT, offsetPart, MetricQueries.buildDimensionAndClause(dimensions, TABLE_TO_JOIN_DIMENSIONS_ON, // No limit on dim ids
    0), limitPart);
    String sql = String.format(FIND_METRIC_NAMES_SQL, defSubSelect);
    try (Handle h = db.open()) {
        Query<Map<String, Object>> query = h.createQuery(sql).bind("tenantId", tenantId);
        if (offset != null && !offset.isEmpty()) {
            logger.debug("binding offset: {}", offset);
            try {
                query.bind("offset", Hex.decodeHex(offset.toCharArray()));
            } catch (DecoderException e) {
                throw Exceptions.badRequest("failed to decode offset " + offset, e);
            }
        }
        MetricQueries.bindDimensionsToQuery(query, dimensions);
        return query.list();
    }
}
#method_after
private List<Map<String, Object>> executeMetricNamesQuery(String tenantId, Map<String, String> dimensions, String offset, int limit) {
    String offsetPart = "";
    if (offset != null && !offset.isEmpty()) {
        offsetPart = " and defSub.id > :offset ";
    }
    // Can't bind limit in a nested sub query. So, just tack on as String.
    String limitPart = " limit " + Integer.toString(limit + 1);
    String defSubSelect = String.format(METRIC_NAMES_SUB_SELECT, offsetPart, MetricQueries.buildDimensionAndClause(dimensions, TABLE_TO_JOIN_DIMENSIONS_ON), limitPart);
    String sql = String.format(FIND_METRIC_NAMES_SQL, defSubSelect);
    try (Handle h = db.open()) {
        Query<Map<String, Object>> query = h.createQuery(sql).bind("tenantId", tenantId);
        if (offset != null && !offset.isEmpty()) {
            logger.debug("binding offset: {}", offset);
            try {
                query.bind("offset", Hex.decodeHex(offset.toCharArray()));
            } catch (DecoderException e) {
                throw Exceptions.badRequest("failed to decode offset " + offset, e);
            }
        }
        MetricQueries.bindDimensionsToQuery(query, dimensions);
        return query.list();
    }
}
#end_block

#method_before
@Override
public List<MetricDefinition> find(String tenantId, String name, Map<String, String> dimensions, DateTime startTime, DateTime endTime, String offset, int limit) {
    List<Map<String, Object>> rows = executeMetricDefsQuery(tenantId, name, dimensions, startTime, endTime, offset, limit);
    List<MetricDefinition> metricDefs = new ArrayList<>(rows.size());
    byte[] currentDefDimId = null;
    Map<String, String> dims = null;
    for (Map<String, Object> row : rows) {
        byte[] defDimId = (byte[]) row.get("defdimsid");
        String metricName = (String) row.get("name");
        String dimName = (String) row.get("dname");
        String dimValue = (String) row.get("dvalue");
        if (defDimId == null || !Arrays.equals(currentDefDimId, defDimId)) {
            currentDefDimId = defDimId;
            dims = new HashMap<>();
            if (dimName != null && dimValue != null) {
                dims.put(dimName, dimValue);
            }
            MetricDefinition m = new MetricDefinition(metricName, dims);
            m.setId(Hex.encodeHexString(defDimId));
            metricDefs.add(m);
        } else {
            dims.put(dimName, dimValue);
        }
    }
    return metricDefs;
}
#method_after
@Override
public List<MetricDefinition> find(String tenantId, String name, Map<String, String> dimensions, DateTime startTime, DateTime endTime, String offset, int limit) {
    List<Map<String, Object>> rows = executeMetricDefsQuery(tenantId, name, dimensions, startTime, endTime, offset, limit);
    List<MetricDefinition> metricDefs = new ArrayList<>(rows.size());
    String currentDefDimId = null;
    Map<String, String> dims = null;
    for (Map<String, Object> row : rows) {
        String defDimId = (String) row.get("defDimsId");
        String metricName = (String) row.get("name");
        String dimName = (String) row.get("dName");
        String dimValue = (String) row.get("dValue");
        if (defDimId == null || !defDimId.equals(currentDefDimId)) {
            currentDefDimId = defDimId;
            dims = new HashMap<>();
            if (dimName != null && dimValue != null) {
                dims.put(dimName, dimValue);
            }
            MetricDefinition m = new MetricDefinition(metricName, dims);
            m.setId(defDimId);
            metricDefs.add(m);
        } else {
            dims.put(dimName, dimValue);
        }
    }
    return metricDefs;
}
#end_block

#method_before
private List<Map<String, Object>> executeMetricDefsQuery(String tenantId, String name, Map<String, String> dimensions, DateTime startTime, DateTime endTime, String offset, int limit) {
    String namePart = "";
    if (name != null && !name.isEmpty()) {
        namePart = " and def.name = :name ";
    }
    String offsetPart = "";
    if (offset != null && !offset.isEmpty()) {
        offsetPart = " and defDims.id > :offset ";
    }
    try (Handle h = db.open()) {
        // If startTime/endTime is specified, create the 'IN' select statement
        String timeInClause = createTimeInClause(h, startTime, endTime, tenantId, name, dimensions);
        String sql = String.format(FIND_METRIC_DEFS_SQL, this.dbHint, namePart, offsetPart, MetricQueries.buildDimensionAndClause(dimensions, "defDims", limit), timeInClause);
        Query<Map<String, Object>> query = h.createQuery(sql).bind("tenantId", tenantId);
        if (name != null && !name.isEmpty()) {
            logger.debug("binding name: {}", name);
            query.bind("name", name);
        }
        if (startTime != null) {
            query.bind("start_time", startTime);
        }
        if (endTime != null) {
            query.bind("end_time", endTime);
        }
        if (offset != null && !offset.isEmpty()) {
            logger.debug("binding offset: {}", offset);
            try {
                query.bind("offset", Hex.decodeHex(offset.toCharArray()));
            } catch (DecoderException e) {
                throw Exceptions.badRequest("failed to decode offset " + offset, e);
            }
        }
        MetricQueries.bindDimensionsToQuery(query, dimensions);
        return query.list();
    }
}
#method_after
private List<Map<String, Object>> executeMetricDefsQuery(String tenantId, String name, Map<String, String> dimensions, DateTime startTime, DateTime endTime, String offset, int limit) {
    String namePart = "";
    if (name != null && !name.isEmpty()) {
        namePart = " and defSub.name = :name ";
    }
    String offsetPart = "";
    if (offset != null && !offset.isEmpty()) {
        offsetPart = " and defDimsSub.id > :offset ";
    }
    String limitPart = "";
    if (limit > 0) {
        limitPart = "limit " + Integer.toString(limit + 1);
    }
    try (Handle h = db.open()) {
        // If startTime/endTime is specified, create the 'IN' select statement
        String timeInClause = createTimeInClause(h, startTime, endTime, tenantId, name, dimensions);
        String sql = String.format(MetricQueries.FIND_METRIC_DEFS_SQL, this.dbHint, String.format(METRIC_DEF_SUB_QUERY, namePart, offsetPart, MetricQueries.buildDimensionAndClause(dimensions, TABLE_TO_JOIN_DIMENSIONS_ON), timeInClause, limitPart));
        Query<Map<String, Object>> query = h.createQuery(sql).bind("tenantId", tenantId);
        if (name != null && !name.isEmpty()) {
            logger.debug("binding name: {}", name);
            query.bind("name", name);
        }
        if (startTime != null) {
            query.bind("start_time", startTime);
        }
        if (endTime != null) {
            query.bind("end_time", endTime);
        }
        if (offset != null && !offset.isEmpty()) {
            logger.debug("binding offset: {}", offset);
            try {
                query.bind("offset", Hex.decodeHex(offset.toCharArray()));
            } catch (DecoderException e) {
                throw Exceptions.badRequest("failed to decode offset " + offset, e);
            }
        }
        MetricQueries.bindDimensionsToQuery(query, dimensions);
        return query.list();
    }
}
#end_block

#method_before
private String createTimeInClause(Handle dbHandle, DateTime startTime, DateTime endTime, String tenantId, String metricName, Map<String, String> dimensions) {
    if (startTime == null) {
        return "";
    }
    Set<byte[]> defDimIdSet = new HashSet<>();
    String namePart = "";
    if (metricName != null && !metricName.isEmpty()) {
        namePart = "AND def.name = :name ";
    }
    String defDimSql = String.format(DEFDIM_IDS_SELECT, this.dbHint, namePart, MetricQueries.buildDimensionAndClause(dimensions, "defDims", 0));
    Query<Map<String, Object>> query = dbHandle.createQuery(defDimSql).bind("tenantId", tenantId);
    MetricQueries.bindDimensionsToQuery(query, dimensions);
    if (metricName != null && !metricName.isEmpty()) {
        query.bind("name", metricName);
    }
    List<Map<String, Object>> rows = query.list();
    for (Map<String, Object> row : rows) {
        byte[] defDimId = (byte[]) row.get("id");
        defDimIdSet.add(defDimId);
    }
    // 
    if (defDimIdSet.size() == 0) {
        return "";
    }
    String timeAndClause = "";
    if (endTime != null) {
        timeAndClause = "AND time_stamp >= :start_time AND time_stamp <= :end_time ";
    } else {
        timeAndClause = "AND time_stamp >= :start_time ";
    }
    String defDimInClause = MetricQueries.createDefDimIdInClause(defDimIdSet);
    return String.format(MEASUREMENT_AND_CLAUSE, defDimInClause, timeAndClause);
}
#method_after
private String createTimeInClause(Handle dbHandle, DateTime startTime, DateTime endTime, String tenantId, String metricName, Map<String, String> dimensions) {
    if (startTime == null) {
        return "";
    }
    Set<String> defDimIdSet = new HashSet<>();
    String namePart = "";
    if (metricName != null && !metricName.isEmpty()) {
        namePart = "AND def.name = :name ";
    }
    String defDimSql = String.format(DEFDIM_IDS_SELECT, this.dbHint, namePart, MetricQueries.buildDimensionAndClause(dimensions, "defDims"));
    Query<Map<String, Object>> query = dbHandle.createQuery(defDimSql).bind("tenantId", tenantId);
    MetricQueries.bindDimensionsToQuery(query, dimensions);
    if (metricName != null && !metricName.isEmpty()) {
        query.bind("name", metricName);
    }
    List<Map<String, Object>> rows = query.list();
    for (Map<String, Object> row : rows) {
        String defDimId = (String) row.get("id");
        defDimIdSet.add(defDimId);
    }
    // 
    if (defDimIdSet.size() == 0) {
        return "";
    }
    String timeAndClause = "";
    if (endTime != null) {
        timeAndClause = "AND time_stamp >= :start_time AND time_stamp <= :end_time ";
    } else {
        timeAndClause = "AND time_stamp >= :start_time ";
    }
    String defDimInClause = MetricQueries.createDefDimIdInClause(defDimIdSet);
    return String.format(MEASUREMENT_AND_CLAUSE, defDimInClause, timeAndClause);
}
#end_block

#method_before
@Override
public List<Measurements> find(String tenantId, String name, Map<String, String> dimensions, DateTime startTime, @Nullable DateTime endTime, @Nullable String offset, int limit, Boolean mergeMetricsFlag) throws MultipleMetricsException {
    try (Handle h = db.open()) {
        Map<ByteBuffer, Measurements> results = new LinkedHashMap<>();
        Set<byte[]> defDimIdSet = new HashSet<>();
        Set<byte[]> dimSetIdSet = new HashSet<>();
        String namePart = "";
        if (name != null && !name.isEmpty()) {
            namePart = "AND def.name = :name ";
        }
        String defDimSql = String.format(DEFDIM_IDS_SELECT, namePart, MetricQueries.buildDimensionAndClause(dimensions, "defDims", 0));
        Query<Map<String, Object>> query = h.createQuery(defDimSql).bind("tenantId", tenantId);
        MetricQueries.bindDimensionsToQuery(query, dimensions);
        if (name != null && !name.isEmpty()) {
            query.bind("name", name);
        }
        List<Map<String, Object>> rows = query.list();
        ByteBuffer defId = ByteBuffer.wrap(new byte[0]);
        for (Map<String, Object> row : rows) {
            byte[] defDimId = (byte[]) row.get("id");
            defDimIdSet.add(defDimId);
            byte[] dimSetIdBytes = (byte[]) row.get("dimension_set_id");
            dimSetIdSet.add(dimSetIdBytes);
            byte[] defIdBytes = (byte[]) row.get("definition_id");
            defId = ByteBuffer.wrap(defIdBytes);
        }
        if (!Boolean.TRUE.equals(mergeMetricsFlag) && (dimSetIdSet.size() > 1)) {
            throw new MultipleMetricsException(name, dimensions);
        }
        // 
        if (defDimIdSet.size() == 0) {
            return new ArrayList<>(results.values());
        }
        String defDimInClause = MetricQueries.createDefDimIdInClause(defDimIdSet);
        StringBuilder sb = new StringBuilder();
        if (endTime != null) {
            sb.append(" and time_stamp <= :endTime");
        }
        if (offset != null && !offset.isEmpty()) {
            sb.append(" and time_stamp > :offset");
        }
        String sql = String.format(FIND_BY_METRIC_DEF_SQL, this.dbHint, defDimInClause, sb);
        query = h.createQuery(sql).bind("startTime", new Timestamp(startTime.getMillis())).bind("limit", limit + 1);
        if (endTime != null) {
            logger.debug("binding endtime: {}", endTime);
            query.bind("endTime", new Timestamp(endTime.getMillis()));
        }
        if (offset != null && !offset.isEmpty()) {
            logger.debug("binding offset: {}", offset);
            query.bind("offset", new Timestamp(DateTime.parse(offset).getMillis()));
        }
        rows = query.list();
        for (Map<String, Object> row : rows) {
            String timestamp = DATETIME_FORMATTER.print(((Timestamp) row.get("time_stamp")).getTime());
            byte[] defdimsIdBytes = (byte[]) row.get("definition_dimensions_id");
            ByteBuffer defdimsId = ByteBuffer.wrap(defdimsIdBytes);
            double value = (double) row.get("value");
            String valueMetaString = (String) row.get("value_meta");
            Map<String, String> valueMetaMap = new HashMap<>();
            if (valueMetaString != null && !valueMetaString.isEmpty()) {
                try {
                    valueMetaMap = this.objectMapper.readValue(valueMetaString, VALUE_META_TYPE);
                } catch (IOException e) {
                    logger.error("failed to parse value metadata: {}", valueMetaString);
                }
            }
            Measurements measurements = (Boolean.TRUE.equals(mergeMetricsFlag)) ? results.get(defId) : results.get(defdimsId);
            if (measurements == null) {
                if (Boolean.TRUE.equals(mergeMetricsFlag)) {
                    measurements = new Measurements(name, new HashMap<String, String>(), new ArrayList<Object[]>());
                    results.put(defId, measurements);
                } else {
                    measurements = new Measurements(name, MetricQueries.dimensionsFor(h, (byte[]) dimSetIdSet.toArray()[0]), new ArrayList<Object[]>());
                    results.put(defdimsId, measurements);
                }
            }
            measurements.addMeasurement(new Object[] { timestamp, value, valueMetaMap });
        }
        return new ArrayList<>(results.values());
    }
}
#method_after
@Override
public List<Measurements> find(String tenantId, String name, Map<String, String> dimensions, DateTime startTime, @Nullable DateTime endTime, @Nullable String offset, int limit, Boolean mergeMetricsFlag, String groupBy) throws MultipleMetricsException {
    try (Handle h = db.open()) {
        Map<String, Measurements> results = findDefIds(h, tenantId, name, dimensions);
        Set<String> defDimsIdSet = results.keySet();
        if (!"*".equals(groupBy) && !Boolean.TRUE.equals(mergeMetricsFlag) && (defDimsIdSet.size() > 1)) {
            throw new MultipleMetricsException(name, dimensions);
        }
        // 
        if (defDimsIdSet.size() == 0) {
            return new ArrayList<>(results.values());
        }
        String defDimInClause = MetricQueries.createDefDimIdInClause(defDimsIdSet);
        StringBuilder sb = new StringBuilder();
        if (endTime != null) {
            sb.append(" and mes.time_stamp <= :endTime");
        }
        if (offset != null && !offset.isEmpty()) {
            if (Boolean.TRUE.equals(mergeMetricsFlag)) {
                sb.append(" and mes.time_stamp > :offset_timestamp ");
            } else {
                sb.append(" and (TO_HEX(mes.definition_dimensions_id) > :offset_id " + "or (TO_HEX(mes.definition_dimensions_id) = :offset_id and mes.time_stamp > :offset_timestamp)) ");
            }
        }
        String orderById = "";
        if (Boolean.FALSE.equals(mergeMetricsFlag)) {
            orderById = "mes.definition_dimensions_id,";
        }
        String sql = String.format(FIND_BY_METRIC_DEF_SQL, this.dbHint, defDimInClause, sb, orderById);
        Query<Map<String, Object>> query = h.createQuery(sql).bind("startTime", new Timestamp(startTime.getMillis())).bind("limit", limit + 1);
        if (endTime != null) {
            logger.debug("binding endtime: {}", endTime);
            query.bind("endTime", new Timestamp(endTime.getMillis()));
        }
        if (offset != null && !offset.isEmpty()) {
            logger.debug("binding offset: {}", offset);
            MetricQueries.bindOffsetToQuery(query, offset);
        }
        List<Map<String, Object>> rows = query.list();
        if (rows.size() == 0) {
            return new ArrayList<>();
        }
        if ("*".equals(groupBy)) {
            for (Map<String, Object> row : rows) {
                String defDimsId = (String) row.get("def_dims_id");
                Object[] measurement = parseRow(row);
                results.get(defDimsId).addMeasurement(measurement);
            }
        } else {
            String firstDefDimsId = (String) rows.get(0).get("def_dims_id");
            Measurements firstMeasurement = results.get(firstDefDimsId);
            // clear dimensions
            firstMeasurement.setDimensions(new HashMap<String, String>());
            results.clear();
            results.put(firstDefDimsId, firstMeasurement);
            for (Map<String, Object> row : rows) {
                Object[] measurement = parseRow(row);
                results.get(firstDefDimsId).addMeasurement(measurement);
            }
        }
        // clean up any empty measurements
        for (Map.Entry<String, Measurements> entry : results.entrySet()) {
            if (entry.getValue().getMeasurements().size() == 0) {
                results.remove(entry.getKey());
            }
        }
        return new ArrayList<>(results.values());
    }
}
#end_block

#method_before
void aggregateValues(MetricDefinitionAndTenantId metricDefinitionAndTenantId, Metric metric) {
    SubAlarmStatsRepository subAlarmStatsRepo = getOrCreateSubAlarmStatsRepo(metricDefinitionAndTenantId);
    if (subAlarmStatsRepo == null || metric == null) {
        logger.debug("Couldn't locate stats repo or metric was null [statsRepo={},metric={}]", subAlarmStatsRepo, metric);
        return;
    }
    // handle periodic metrics
    if (metric.isPeriodic()) {
        this.periodicMetricMap.put(metric.getName(), metric.getPeriod());
    } else if (this.periodicMetricMap.containsKey(metric.getName()) && !metric.isPeriodic()) {
        this.periodicMetricMap.remove(metric.getName());
    }
    for (SubAlarmStats stats : subAlarmStatsRepo.get()) {
        final long timestampSeconds = metric.timestamp / 1000;
        final SubAlarm subAlarm = stats.getSubAlarm();
        final SlidingWindowStats slidingWindowStats = stats.getStats();
        // if metric is sparse pass it on to associated sub alarm
        subAlarm.setSporadicMetric(metric.isSparse());
        if (slidingWindowStats.addValue(metric.value, timestampSeconds)) {
            logger.trace("Aggregated value {} at {} for {}. Updated {}", metric.value, metric.timestamp, metricDefinitionAndTenantId, slidingWindowStats);
            final long alarmDelay = this.getAlarmDelay(metric.getName(), metric.getPeriod());
            final boolean windowSlid = stats.evaluateAndSlideWindow(timestampSeconds, alarmDelay);
            if (windowSlid) {
                logger.trace("Window for metric {} has been slid", metric.getName());
                sendSubAlarmStateChange(stats);
            }
        } else {
            logger.warn("Metric is too old, age {} seconds: timestamp {} for {}, {}", currentTimeSeconds() - timestampSeconds, timestampSeconds, metricDefinitionAndTenantId, slidingWindowStats);
        }
    }
}
#method_after
void aggregateValues(MetricDefinitionAndTenantId metricDefinitionAndTenantId, Metric metric) {
    SubAlarmStatsRepository subAlarmStatsRepo = getOrCreateSubAlarmStatsRepo(metricDefinitionAndTenantId);
    if (subAlarmStatsRepo == null || metric == null) {
        return;
    }
    for (SubAlarmStats stats : subAlarmStatsRepo.get()) {
        long timestamp_secs = metric.timestamp / 1000;
        if (stats.getStats().addValue(metric.value, timestamp_secs)) {
            logger.trace("Aggregated value {} at {} for {}. Updated {}", metric.value, metric.timestamp, metricDefinitionAndTenantId, stats.getStats());
            if (stats.evaluateAndSlideWindow(timestamp_secs, config.alarmDelay)) {
                sendSubAlarmStateChange(stats);
            }
        } else {
            logger.warn("Metric is too old, age {} seconds: timestamp {} for {}, {}", currentTimeSeconds() - timestamp_secs, timestamp_secs, metricDefinitionAndTenantId, stats.getStats());
        }
    }
}
#end_block

#method_before
void evaluateAlarmsAndSlideWindows() {
    logger.debug("evaluateAlarmsAndSlideWindows called");
    long newWindowTimestamp = currentTimeSeconds();
    long alarmDelay = config.alarmDelay;
    for (SubAlarmStats subAlarmStats : subAlarmStatsSet) {
        // check if metric for subAlarmStats was saved in periodicMetricMap with custom delay
        final String metricName = subAlarmStats.getSubAlarm().getExpression().getMetricDefinition().name;
        if (this.periodicMetricMap.containsKey(metricName)) {
            alarmDelay = this.getAlarmDelay(metricName, this.periodicMetricMap.get(metricName));
        }
        if (upToDate) {
            logger.debug("Evaluating {}", subAlarmStats);
            if (subAlarmStats.evaluateAndSlideWindow(newWindowTimestamp, alarmDelay)) {
                sendSubAlarmStateChange(subAlarmStats);
            }
        } else {
            subAlarmStats.slideWindow(newWindowTimestamp, alarmDelay);
        }
    }
    if (!upToDate) {
        logger.info("Did not evaluate SubAlarms because Metrics are not up to date");
        upToDate = true;
    }
}
#method_after
void evaluateAlarmsAndSlideWindows() {
    logger.debug("evaluateAlarmsAndSlideWindows called");
    long newWindowTimestamp = currentTimeSeconds();
    for (SubAlarmStats subAlarmStats : subAlarmStatsSet) {
        if (upToDate) {
            logger.debug("Evaluating {}", subAlarmStats);
            if (subAlarmStats.evaluateAndSlideWindow(newWindowTimestamp, config.alarmDelay)) {
                sendSubAlarmStateChange(subAlarmStats);
            }
        } else {
            subAlarmStats.slideWindow(newWindowTimestamp, config.alarmDelay);
        }
    }
    if (!upToDate) {
        logger.info("Did not evaluate SubAlarms because Metrics are not up to date");
        upToDate = true;
    }
}
#end_block

#method_before
public SubAlarm duplicate(final SubAlarm original) {
    final SubAlarm newSubAlarm = new SubAlarm(original.getId(), original.getAlarmId(), new SubExpression(original.getAlarmSubExpressionId(), original.getExpression()), original.getState());
    newSubAlarm.setNoState(original.isNoState());
    newSubAlarm.setSporadicMetric(original.isSporadicMetric());
    newSubAlarm.setCurrentValues(original.getCurrentValues());
    return newSubAlarm;
}
#method_after
public SubAlarm duplicate(final SubAlarm original) {
    final SubAlarm newSubAlarm = new SubAlarm(original.getId(), original.getAlarmId(), new SubExpression(original.getAlarmSubExpressionId(), original.getExpression()), original.getState());
    newSubAlarm.setNoState(original.isNoState());
    newSubAlarm.setCurrentValues(original.getCurrentValues());
    return newSubAlarm;
}
#end_block

#method_before
@Override
public List<Measurements> find(String tenantId, String name, Map<String, String> dimensions, DateTime startTime, @Nullable DateTime endTime, @Nullable String offset, int limit, Boolean mergeMetricsFlag) throws MultipleMetricsException {
    try (Handle h = db.open()) {
        StringBuilder sb = new StringBuilder();
        if (name != null && !name.isEmpty()) {
            sb.append(" and def.name = :name");
        }
        if (endTime != null) {
            sb.append(" and mes.time_stamp <= :endTime");
        }
        if (offset != null && !offset.isEmpty()) {
            sb.append(" and time_stamp > :offset");
        }
        String sql = String.format(FIND_BY_METRIC_DEF_SQL, MetricQueries.buildJoinClauseFor(dimensions, TABLE_TO_JOIN_DIMENSIONS_ON), sb);
        Query<Map<String, Object>> query = h.createQuery(sql).bind("tenantId", tenantId).bind("startTime", new Timestamp(startTime.getMillis())).bind("limit", limit + 1);
        if (name != null && !name.isEmpty()) {
            logger.debug("binding name: {}", name);
            query.bind("name", name);
        }
        if (endTime != null) {
            logger.debug("binding endtime: {}", endTime);
            query.bind("endTime", new Timestamp(endTime.getMillis()));
        }
        if (offset != null && !offset.isEmpty()) {
            logger.debug("binding offset: {}", offset);
            query.bind("offset", new Timestamp(DateTime.parse(offset).getMillis()));
        }
        MetricQueries.bindDimensionsToQuery(query, dimensions);
        List<Map<String, Object>> rows = query.list();
        Map<ByteBuffer, Measurements> results = new LinkedHashMap<>();
        for (Map<String, Object> row : rows) {
            String metricName = (String) row.get("name");
            byte[] defIdBytes = (byte[]) row.get("definition_id");
            ByteBuffer defId = ByteBuffer.wrap(defIdBytes);
            byte[] defdimsIdBytes = (byte[]) row.get("definition_dimensions_id");
            byte[] dimSetIdBytes = (byte[]) row.get("dimension_set_id");
            ByteBuffer defdimsId = ByteBuffer.wrap(defdimsIdBytes);
            String timestamp = DATETIME_FORMATTER.print(((Timestamp) row.get("time_stamp")).getTime());
            double value = (double) row.get("value");
            String valueMetaString = (String) row.get("value_meta");
            Map<String, String> valueMetaMap = new HashMap<>();
            if (valueMetaString != null && !valueMetaString.isEmpty()) {
                try {
                    valueMetaMap = this.objectMapper.readValue(valueMetaString, VALUE_META_TYPE);
                } catch (IOException e) {
                    logger.error("failed to parse value metadata: {}", valueMetaString);
                }
            }
            Measurements measurements;
            if (Boolean.TRUE.equals(mergeMetricsFlag)) {
                measurements = results.get(defId);
            } else {
                measurements = results.get(defdimsId);
            }
            if (measurements == null) {
                if (Boolean.TRUE.equals(mergeMetricsFlag)) {
                    measurements = new Measurements(metricName, new HashMap<String, String>(), new ArrayList<Object[]>());
                    results.put(defId, measurements);
                } else {
                    measurements = new Measurements(metricName, MetricQueries.dimensionsFor(h, dimSetIdBytes), new ArrayList<Object[]>());
                    results.put(defdimsId, measurements);
                }
            }
            measurements.addMeasurement(new Object[] { timestamp, value, valueMetaMap });
        }
        return new ArrayList<>(results.values());
    }
}
#method_after
@Override
public List<Measurements> find(String tenantId, String name, Map<String, String> dimensions, DateTime startTime, @Nullable DateTime endTime, @Nullable String offset, int limit, Boolean mergeMetricsFlag, String groupBy) throws MultipleMetricsException {
    try (Handle h = db.open()) {
        Map<String, Measurements> results = findDefIds(h, tenantId, name, dimensions);
        Set<String> defDimsIdSet = results.keySet();
        if (!"*".equals(groupBy) && !Boolean.TRUE.equals(mergeMetricsFlag) && (defDimsIdSet.size() > 1)) {
            throw new MultipleMetricsException(name, dimensions);
        }
        // 
        if (defDimsIdSet.size() == 0) {
            return new ArrayList<>(results.values());
        }
        String defDimInClause = MetricQueries.createDefDimIdInClause(defDimsIdSet);
        StringBuilder sb = new StringBuilder();
        if (endTime != null) {
            sb.append(" and mes.time_stamp <= :endTime");
        }
        if (offset != null && !offset.isEmpty()) {
            if (Boolean.TRUE.equals(mergeMetricsFlag)) {
                sb.append(" and mes.time_stamp > :offset_timestamp ");
            } else {
                sb.append(" and (TO_HEX(mes.definition_dimensions_id) > :offset_id " + "or (TO_HEX(mes.definition_dimensions_id) = :offset_id and mes.time_stamp > :offset_timestamp)) ");
            }
        }
        String orderById = "";
        if (Boolean.FALSE.equals(mergeMetricsFlag)) {
            orderById = "mes.definition_dimensions_id,";
        }
        String sql = String.format(FIND_BY_METRIC_DEF_SQL, defDimInClause, sb, orderById);
        Query<Map<String, Object>> query = h.createQuery(sql).bind("startTime", new Timestamp(startTime.getMillis())).bind("limit", limit + 1);
        if (endTime != null) {
            logger.debug("binding endtime: {}", endTime);
            query.bind("endTime", new Timestamp(endTime.getMillis()));
        }
        if (offset != null && !offset.isEmpty()) {
            logger.debug("binding offset: {}", offset);
            MetricQueries.bindOffsetToQuery(query, offset);
        }
        List<Map<String, Object>> rows = query.list();
        if (rows.size() == 0) {
            return new ArrayList<>();
        }
        if ("*".equals(groupBy)) {
            for (Map<String, Object> row : rows) {
                String defDimsId = (String) row.get("def_dims_id");
                Object[] measurement = parseRow(row);
                results.get(defDimsId).addMeasurement(measurement);
            }
        } else {
            String firstDefDimsId = (String) rows.get(0).get("def_dims_id");
            Measurements firstMeasurement = results.get(firstDefDimsId);
            // clear dimensions
            firstMeasurement.setDimensions(new HashMap<String, String>());
            results.clear();
            results.put(firstDefDimsId, firstMeasurement);
            for (Map<String, Object> row : rows) {
                Object[] measurement = parseRow(row);
                results.get(firstDefDimsId).addMeasurement(measurement);
            }
        }
        // clean up any empty measurements
        for (Map.Entry<String, Measurements> entry : results.entrySet()) {
            if (entry.getValue().getMeasurements().size() == 0) {
                results.remove(entry.getKey());
            }
        }
        return new ArrayList<>(results.values());
    }
}
#end_block

#method_before
@Override
public List<Statistics> find(String tenantId, String name, Map<String, String> dimensions, DateTime startTime, DateTime endTime, List<String> statisticsCols, int period, String offset, int limit, Boolean mergeMetricsFlag) throws MultipleMetricsException {
    List<Statistics> statisticsList = new ArrayList<>();
    // Sort the column names so that they match the order of the statistics in the results.
    List<String> statisticsColumns = createColumnsList(statisticsCols);
    try (Handle h = db.open()) {
        Map<byte[], Statistics> byteMap = findDefIds(h, tenantId, name, dimensions);
        if (byteMap.isEmpty()) {
            return statisticsList;
        }
        List<List<Object>> statisticsListList = new ArrayList<>();
        String sql = createQuery(byteMap.keySet(), period, startTime, endTime, offset, statisticsCols);
        logger.debug("vertica sql: {}", sql);
        Query<Map<String, Object>> query = h.createQuery(sql).bind("start_time", startTime).bind("end_time", endTime).bind("limit", limit + 1);
        if (offset != null && !offset.isEmpty()) {
            logger.debug("binding offset: {}", offset);
            query.bind("offset", new Timestamp(DateTime.parse(offset).getMillis()));
        }
        List<Map<String, Object>> rows = query.list();
        for (Map<String, Object> row : rows) {
            List<Object> statisticsRow = parseRow(row);
            statisticsListList.add(statisticsRow);
        }
        for (Map.Entry<byte[], Statistics> entry : byteMap.entrySet()) {
            Statistics statistics = entry.getValue();
            statistics.setColumns(statisticsColumns);
            if (Boolean.TRUE.equals(mergeMetricsFlag) && byteMap.keySet().size() > 1) {
                // Wipe out the dimensions.
                statistics.setDimensions(new HashMap<String, String>());
            }
            statistics.setStatistics(statisticsListList);
            statisticsList.add(statistics);
        }
    }
    return statisticsList;
}
#method_after
@Override
public List<Statistics> find(String tenantId, String name, Map<String, String> dimensions, DateTime startTime, DateTime endTime, List<String> statisticsCols, int period, String offset, int limit, Boolean mergeMetricsFlag, String groupBy) throws MultipleMetricsException {
    List<Statistics> statisticsList = new ArrayList<>();
    // Sort the column names so that they match the order of the statistics in the results.
    List<String> statisticsColumns = createColumnsList(statisticsCols);
    try (Handle h = db.open()) {
        Map<String, Statistics> byteMap = findDefIds(h, tenantId, name, dimensions);
        if (byteMap.isEmpty()) {
            return statisticsList;
        }
        if (!"*".equals(groupBy) && !Boolean.TRUE.equals(mergeMetricsFlag) && byteMap.keySet().size() > 1) {
            throw new MultipleMetricsException(name, dimensions);
        }
        List<List<Object>> statisticsListList = new ArrayList<>();
        String sql = createQuery(byteMap.keySet(), period, startTime, endTime, offset, statisticsCols, groupBy, mergeMetricsFlag);
        logger.debug("vertica sql: {}", sql);
        Query<Map<String, Object>> query = h.createQuery(sql).bind("start_time", startTime).bind("end_time", endTime).bind("limit", limit + 1);
        if (offset != null && !offset.isEmpty()) {
            logger.debug("binding offset: {}", offset);
            MetricQueries.bindOffsetToQuery(query, offset);
        }
        List<Map<String, Object>> rows = query.list();
        if ("*".equals(groupBy)) {
            for (Map<String, Object> row : rows) {
                List<Object> statisticsRow = parseRow(row);
                String defDimsId = (String) row.get("id");
                byteMap.get(defDimsId).addStatistics(statisticsRow);
            }
            for (Map.Entry<String, Statistics> entry : byteMap.entrySet()) {
                Statistics statistics = entry.getValue();
                statistics.setColumns(statisticsColumns);
                if (statistics.getStatistics().size() > 0) {
                    statisticsList.add(statistics);
                }
            }
        } else {
            for (Map<String, Object> row : rows) {
                List<Object> statisticsRow = parseRow(row);
                statisticsListList.add(statisticsRow);
            }
            // Just use the first entry in the byteMap to get the def name and dimensions.
            Statistics statistics = byteMap.entrySet().iterator().next().getValue();
            statistics.setColumns(statisticsColumns);
            if (Boolean.TRUE.equals(mergeMetricsFlag) && byteMap.keySet().size() > 1) {
                // Wipe out the dimensions.
                statistics.setDimensions(new HashMap<String, String>());
            }
            statistics.setStatistics(statisticsListList);
            statisticsList.add(statistics);
        }
    }
    return statisticsList;
}
#end_block

#method_before
private Map<byte[], Statistics> findDefIds(Handle h, String tenantId, String name, Map<String, String> dimensions) {
    List<byte[]> bytes = new ArrayList<>();
    StringBuilder sb = new StringBuilder();
    if (name != null && !name.isEmpty()) {
        sb.append(" and def.name = :name");
    }
    String sql = String.format(FIND_BY_METRIC_DEF_SQL, MetricQueries.buildJoinClauseFor(dimensions, TABLE_TO_JOIN_DIMENSIONS_ON), sb);
    Query<Map<String, Object>> query = h.createQuery(sql).bind("tenantId", tenantId);
    if (name != null && !name.isEmpty()) {
        logger.debug("binding name: {}", name);
        query.bind("name", name);
    }
    MetricQueries.bindDimensionsToQuery(query, dimensions);
    List<Map<String, Object>> rows = query.list();
    Map<byte[], Statistics> byteIdMap = new HashMap<>();
    byte[] currentDefDimId = null;
    Map<String, String> dims = null;
    for (Map<String, Object> row : rows) {
        byte[] defDimId = (byte[]) row.get("id");
        String defName = (String) row.get("name");
        String dimName = (String) row.get("dname");
        String dimValue = (String) row.get("dvalue");
        if (defDimId == null || !Arrays.equals(currentDefDimId, defDimId)) {
            currentDefDimId = defDimId;
            dims = new HashMap<>();
            dims.put(dimName, dimValue);
            Statistics statistics = new Statistics();
            statistics.setName(defName);
            statistics.setDimensions(dims);
            byteIdMap.put(currentDefDimId, statistics);
        } else {
            dims.put(dimName, dimValue);
        }
    }
    bytes.add(currentDefDimId);
    return byteIdMap;
}
#method_after
private Map<String, Statistics> findDefIds(Handle h, String tenantId, String name, Map<String, String> dimensions) {
    String sql = String.format(MetricQueries.FIND_METRIC_DEFS_SQL, MetricQueries.buildMetricDefinitionSubSql(name, dimensions));
    Query<Map<String, Object>> query = h.createQuery(sql).bind("tenantId", tenantId);
    if (name != null && !name.isEmpty()) {
        logger.debug("binding name: {}", name);
        query.bind("name", name);
    }
    MetricQueries.bindDimensionsToQuery(query, dimensions);
    List<Map<String, Object>> rows = query.list();
    Map<String, Statistics> byteIdMap = new HashMap<>();
    String currentDefDimId = null;
    Map<String, String> dims = null;
    for (Map<String, Object> row : rows) {
        String defDimId = (String) row.get("defDimsId");
        String defName = (String) row.get("name");
        String dimName = (String) row.get("dName");
        String dimValue = (String) row.get("dValue");
        if (defDimId == null || !defDimId.equals(currentDefDimId)) {
            currentDefDimId = defDimId;
            dims = new HashMap<>();
            dims.put(dimName, dimValue);
            Statistics statistics = new Statistics();
            statistics.setId(defDimId);
            statistics.setName(defName);
            statistics.setDimensions(dims);
            byteIdMap.put(currentDefDimId, statistics);
        } else {
            dims.put(dimName, dimValue);
        }
    }
    return byteIdMap;
}
#end_block

#method_before
private String createQuery(Set<byte[]> defDimIdSet, int period, DateTime startTime, DateTime endTime, String offset, List<String> statistics) {
    StringBuilder sb = new StringBuilder();
    sb.append("SELECT " + createColumnsStr(statistics));
    if (period >= 1) {
        sb.append("Time_slice(time_stamp, " + period);
        sb.append(", 'SECOND', 'END') AS time_interval");
    }
    sb.append(" FROM MonMetrics.Measurements ");
    String inClause = MetricQueries.createDefDimIdInClause(defDimIdSet);
    sb.append("WHERE to_hex(definition_dimensions_id) " + inClause);
    sb.append(createWhereClause(startTime, endTime, offset));
    if (period >= 1) {
        sb.append("group by Time_slice(time_stamp, " + period);
        sb.append(", 'SECOND', 'END') order by time_interval");
    }
    sb.append(" limit :limit");
    return sb.toString();
}
#method_after
private String createQuery(Set<String> defDimIdSet, int period, DateTime startTime, DateTime endTime, String offset, List<String> statistics, String groupBy, Boolean mergeMetricsFlag) {
    StringBuilder sb = new StringBuilder();
    sb.append("SELECT ");
    if (groupBy != null && !groupBy.isEmpty()) {
        sb.append(" to_hex(definition_dimensions_id) AS id, ");
    }
    sb.append(createColumnsStr(statistics));
    if (period >= 1) {
        sb.append("Time_slice(time_stamp, ").append(period);
        sb.append(", 'SECOND', 'START') AS time_interval");
    }
    sb.append(" FROM MonMetrics.Measurements ");
    String inClause = MetricQueries.createDefDimIdInClause(defDimIdSet);
    sb.append("WHERE to_hex(definition_dimensions_id) ").append(inClause);
    sb.append(createWhereClause(startTime, endTime, offset, mergeMetricsFlag));
    if (period >= 1) {
        sb.append(" group by ");
        if (groupBy != null && !groupBy.isEmpty()) {
            sb.append("definition_dimensions_id,");
        }
        sb.append("time_interval ");
        sb.append(" order by ");
        if (groupBy != null && !groupBy.isEmpty()) {
            sb.append("to_hex(definition_dimensions_id),");
        }
        sb.append("time_interval ");
    }
    sb.append(" limit :limit");
    return sb.toString();
}
#end_block

#method_before
private String createWhereClause(DateTime startTime, DateTime endTime, String offset) {
    String s = "";
    if (startTime != null && endTime != null) {
        s = "AND time_stamp >= :start_time AND time_stamp <= :end_time ";
    } else if (startTime != null) {
        s = "AND time_stamp >= :start_time ";
    }
    if (offset != null && !offset.isEmpty()) {
        s += " and time_stamp > :offset ";
    }
    return s;
}
#method_after
private String createWhereClause(DateTime startTime, DateTime endTime, String offset, Boolean mergeMetricsFlag) {
    String s = "";
    if (startTime != null && endTime != null) {
        s = "AND time_stamp >= :start_time AND time_stamp <= :end_time ";
    } else if (startTime != null) {
        s = "AND time_stamp >= :start_time ";
    }
    if (offset != null && !offset.isEmpty()) {
        if (Boolean.FALSE.equals(mergeMetricsFlag)) {
            s += " AND (TO_HEX(definition_dimensions_id) > :offset_id " + "OR (TO_HEX(definition_dimensions_id) = :offset_id AND time_stamp > :offset_timestamp)) ";
        } else {
            s += " AND time_stamp > :offset_timestamp ";
        }
    }
    return s;
}
#end_block

#method_before
@Override
public List<Measurements> find(String tenantId, String name, Map<String, String> dimensions, DateTime startTime, @Nullable DateTime endTime, @Nullable String offset, int limit, Boolean mergeMetricsFlag) throws MultipleMetricsException {
    try (Handle h = db.open()) {
        Map<ByteBuffer, Measurements> results = new LinkedHashMap<>();
        Set<byte[]> defDimIdSet = new HashSet<>();
        Set<byte[]> dimSetIdSet = new HashSet<>();
        String namePart = "";
        if (name != null && !name.isEmpty()) {
            namePart = "AND def.name = :name ";
        }
        String defDimSql = String.format(DEFDIM_IDS_SELECT, namePart, MetricQueries.buildDimensionAndClause(dimensions, TABLE_TO_JOIN_DIMENSIONS_ON));
        Query<Map<String, Object>> query = h.createQuery(defDimSql).bind("tenantId", tenantId);
        MetricQueries.bindDimensionsToQuery(query, dimensions);
        if (name != null && !name.isEmpty()) {
            query.bind("name", name);
        }
        List<Map<String, Object>> rows = query.list();
        ByteBuffer defId = ByteBuffer.wrap(new byte[0]);
        for (Map<String, Object> row : rows) {
            byte[] defDimId = (byte[]) row.get("id");
            defDimIdSet.add(defDimId);
            byte[] dimSetIdBytes = (byte[]) row.get("dimension_set_id");
            dimSetIdSet.add(dimSetIdBytes);
            byte[] defIdBytes = (byte[]) row.get("definition_id");
            defId = ByteBuffer.wrap(defIdBytes);
        }
        if (!Boolean.TRUE.equals(mergeMetricsFlag) && (dimSetIdSet.size() > 1)) {
            throw new MultipleMetricsException(name, dimensions);
        }
        // 
        if (defDimIdSet.size() == 0) {
            return new ArrayList<>(results.values());
        }
        String defDimInClause = MetricQueries.createDefDimIdInClause(defDimIdSet);
        StringBuilder sb = new StringBuilder();
        if (endTime != null) {
            sb.append(" and time_stamp <= :endTime");
        }
        if (offset != null && !offset.isEmpty()) {
            sb.append(" and time_stamp > :offset");
        }
        String sql = String.format(FIND_BY_METRIC_DEF_SQL, defDimInClause, sb);
        query = h.createQuery(sql).bind("startTime", new Timestamp(startTime.getMillis())).bind("limit", limit + 1);
        if (endTime != null) {
            logger.debug("binding endtime: {}", endTime);
            query.bind("endTime", new Timestamp(endTime.getMillis()));
        }
        if (offset != null && !offset.isEmpty()) {
            logger.debug("binding offset: {}", offset);
            query.bind("offset", new Timestamp(DateTime.parse(offset).getMillis()));
        }
        rows = query.list();
        for (Map<String, Object> row : rows) {
            String timestamp = DATETIME_FORMATTER.print(((Timestamp) row.get("time_stamp")).getTime());
            byte[] defdimsIdBytes = (byte[]) row.get("definition_dimensions_id");
            ByteBuffer defdimsId = ByteBuffer.wrap(defdimsIdBytes);
            double value = (double) row.get("value");
            String valueMetaString = (String) row.get("value_meta");
            Map<String, String> valueMetaMap = new HashMap<>();
            if (valueMetaString != null && !valueMetaString.isEmpty()) {
                try {
                    valueMetaMap = this.objectMapper.readValue(valueMetaString, VALUE_META_TYPE);
                } catch (IOException e) {
                    logger.error("failed to parse value metadata: {}", valueMetaString);
                }
            }
            Measurements measurements = (Boolean.TRUE.equals(mergeMetricsFlag)) ? results.get(defId) : results.get(defdimsId);
            if (measurements == null) {
                if (Boolean.TRUE.equals(mergeMetricsFlag)) {
                    measurements = new Measurements(name, new HashMap<String, String>(), new ArrayList<Object[]>());
                    results.put(defId, measurements);
                } else {
                    measurements = new Measurements(name, MetricQueries.dimensionsFor(h, (byte[]) dimSetIdSet.toArray()[0]), new ArrayList<Object[]>());
                    results.put(defdimsId, measurements);
                }
            }
            measurements.addMeasurement(new Object[] { timestamp, value, valueMetaMap });
        }
        return new ArrayList<>(results.values());
    }
}
#method_after
@Override
public List<Measurements> find(String tenantId, String name, Map<String, String> dimensions, DateTime startTime, @Nullable DateTime endTime, @Nullable String offset, int limit, Boolean mergeMetricsFlag) throws MultipleMetricsException {
    try (Handle h = db.open()) {
        Map<ByteBuffer, Measurements> results = new LinkedHashMap<>();
        Set<byte[]> defDimIdSet = new HashSet<>();
        String defDimSql = String.format(DEFDIM_IDS_SELECT, MetricQueries.buildMetricDefinitionSubSql(name, dimensions));
        Query<Map<String, Object>> query = h.createQuery(defDimSql).bind("tenantId", tenantId);
        if (name != null && !name.isEmpty()) {
            query.bind("name", name);
        }
        MetricQueries.bindDimensionsToQuery(query, dimensions);
        List<Map<String, Object>> rows = query.list();
        for (Map<String, Object> row : rows) {
            byte[] defDimId = (byte[]) row.get("id");
            defDimIdSet.add(defDimId);
        }
        if (!Boolean.TRUE.equals(mergeMetricsFlag) && (defDimIdSet.size() > 1)) {
            throw new MultipleMetricsException(name, dimensions);
        }
        // 
        if (defDimIdSet.size() == 0) {
            return new ArrayList<>(results.values());
        }
        String defDimInClause = MetricQueries.createDefDimIdInClause(defDimIdSet);
        StringBuilder sb = new StringBuilder();
        if (endTime != null) {
            sb.append(" and time_stamp <= :endTime");
        }
        if (offset != null && !offset.isEmpty()) {
            sb.append(" and time_stamp > :offset");
        }
        String sql = String.format(FIND_BY_METRIC_DEF_SQL, defDimInClause, sb);
        query = h.createQuery(sql).bind("startTime", new Timestamp(startTime.getMillis())).bind("limit", limit + 1);
        if (endTime != null) {
            logger.debug("binding endtime: {}", endTime);
            query.bind("endTime", new Timestamp(endTime.getMillis()));
        }
        if (offset != null && !offset.isEmpty()) {
            logger.debug("binding offset: {}", offset);
            query.bind("offset", new Timestamp(DateTime.parse(offset).getMillis()));
        }
        rows = query.list();
        for (Map<String, Object> row : rows) {
            String timestamp = DATETIME_FORMATTER.print(((Timestamp) row.get("time_stamp")).getTime());
            byte[] defdimsIdBytes = (byte[]) row.get("definition_dimensions_id");
            ByteBuffer defdimsId = ByteBuffer.wrap(defdimsIdBytes);
            double value = (double) row.get("value");
            String valueMetaString = (String) row.get("value_meta");
            Map<String, String> valueMetaMap = new HashMap<>();
            if (valueMetaString != null && !valueMetaString.isEmpty()) {
                try {
                    valueMetaMap = this.objectMapper.readValue(valueMetaString, VALUE_META_TYPE);
                } catch (IOException e) {
                    logger.error("failed to parse value metadata: {}", valueMetaString);
                }
            }
            Measurements measurements = (Boolean.TRUE.equals(mergeMetricsFlag)) ? results.get(EMPTY_DEF_ID) : results.get(defdimsId);
            if (measurements == null) {
                if (Boolean.TRUE.equals(mergeMetricsFlag)) {
                    measurements = new Measurements(name, new HashMap<String, String>(), new ArrayList<Object[]>());
                    results.put(EMPTY_DEF_ID, measurements);
                } else {
                    measurements = new Measurements(name, MetricQueries.dimensionsFor(h, (byte[]) defDimIdSet.toArray()[0]), new ArrayList<Object[]>());
                    results.put(defdimsId, measurements);
                }
            }
            measurements.addMeasurement(new Object[] { timestamp, value, valueMetaMap });
        }
        return new ArrayList<>(results.values());
    }
}
#end_block

#method_before
private Map<byte[], Statistics> findDefIds(Handle h, String tenantId, String name, Map<String, String> dimensions) {
    List<byte[]> bytes = new ArrayList<>();
    StringBuilder sb = new StringBuilder();
    if (name != null && !name.isEmpty()) {
        sb.append(" and def.name = :name");
    }
    String sql = String.format(FIND_BY_METRIC_DEF_SQL, sb, MetricQueries.buildDimensionAndClause(dimensions, TABLE_TO_JOIN_DIMENSIONS_ON));
    Query<Map<String, Object>> query = h.createQuery(sql).bind("tenantId", tenantId);
    if (name != null && !name.isEmpty()) {
        logger.debug("binding name: {}", name);
        query.bind("name", name);
    }
    MetricQueries.bindDimensionsToQuery(query, dimensions);
    List<Map<String, Object>> rows = query.list();
    Map<byte[], Statistics> byteIdMap = new HashMap<>();
    byte[] currentDefDimId = null;
    Map<String, String> dims = null;
    for (Map<String, Object> row : rows) {
        byte[] defDimId = (byte[]) row.get("id");
        String defName = (String) row.get("name");
        String dimName = (String) row.get("dname");
        String dimValue = (String) row.get("dvalue");
        if (defDimId == null || !Arrays.equals(currentDefDimId, defDimId)) {
            currentDefDimId = defDimId;
            dims = new HashMap<>();
            dims.put(dimName, dimValue);
            Statistics statistics = new Statistics();
            statistics.setName(defName);
            statistics.setDimensions(dims);
            byteIdMap.put(currentDefDimId, statistics);
        } else {
            dims.put(dimName, dimValue);
        }
    }
    bytes.add(currentDefDimId);
    return byteIdMap;
}
#method_after
private Map<byte[], Statistics> findDefIds(Handle h, String tenantId, String name, Map<String, String> dimensions) {
    List<byte[]> bytes = new ArrayList<>();
    String sql = String.format(FIND_BY_METRIC_DEF_SQL, MetricQueries.buildMetricDefinitionSubSql(name, dimensions));
    Query<Map<String, Object>> query = h.createQuery(sql).bind("tenantId", tenantId);
    if (name != null && !name.isEmpty()) {
        logger.debug("binding name: {}", name);
        query.bind("name", name);
    }
    MetricQueries.bindDimensionsToQuery(query, dimensions);
    List<Map<String, Object>> rows = query.list();
    Map<byte[], Statistics> byteIdMap = new HashMap<>();
    byte[] currentDefDimId = null;
    Map<String, String> dims = null;
    for (Map<String, Object> row : rows) {
        byte[] defDimId = (byte[]) row.get("id");
        String defName = (String) row.get("name");
        String dimName = (String) row.get("dname");
        String dimValue = (String) row.get("dvalue");
        if (defDimId == null || !Arrays.equals(currentDefDimId, defDimId)) {
            currentDefDimId = defDimId;
            dims = new HashMap<>();
            dims.put(dimName, dimValue);
            Statistics statistics = new Statistics();
            statistics.setName(defName);
            statistics.setDimensions(dims);
            byteIdMap.put(currentDefDimId, statistics);
        } else {
            dims.put(dimName, dimValue);
        }
    }
    bytes.add(currentDefDimId);
    return byteIdMap;
}
#end_block

#method_before
static String buildDimensionAndClause(Map<String, String> dimensions, String tableToJoinName) {
    StringBuilder sb = null;
    if (dimensions != null && dimensions.size() > 0) {
        sb = new StringBuilder();
        sb.append(" and ( ");
        int i = 0;
        for (Iterator<Map.Entry<String, String>> it = dimensions.entrySet().iterator(); it.hasNext(); i++) {
            Map.Entry<String, String> entry = it.next();
            sb.append("(");
            sb.append(tableToJoinName).append(".name = :dname").append(i);
            String dim_value = entry.getValue();
            if (!Strings.isNullOrEmpty(dim_value)) {
                List<String> values = BAR_SPLITTER.splitToList(dim_value);
                if (values.size() > 1) {
                    sb.append(" and ( ");
                    for (int j = 0; j < values.size(); j++) {
                        sb.append(tableToJoinName).append(".value = :dvalue").append(i).append('_').append(j);
                        if (j < values.size() - 1) {
                            sb.append(" or ");
                        }
                    }
                    sb.append(")");
                } else {
                    sb.append(" and ").append(tableToJoinName).append(".value = :dvalue").append(i);
                }
            }
            sb.append(")");
            if (it.hasNext()) {
                sb.append(" or ");
            }
        }
        sb.append(")");
    }
    return sb == null ? "" : sb.toString();
}
#method_after
static String buildDimensionAndClause(Map<String, String> dimensions, String tableToJoinName) {
    if (dimensions == null || dimensions.isEmpty()) {
        return "";
    }
    StringBuilder sb = new StringBuilder();
    sb.append(" and ").append(tableToJoinName).append(".dimension_set_id in ( " + "SELECT dimension_set_id FROM MonMetrics.Dimensions WHERE (");
    int i = 0;
    for (Iterator<Map.Entry<String, String>> it = dimensions.entrySet().iterator(); it.hasNext(); i++) {
        Map.Entry<String, String> entry = it.next();
        sb.append("(name = :dname").append(i);
        String dim_value = entry.getValue();
        if (!Strings.isNullOrEmpty(dim_value)) {
            List<String> values = BAR_SPLITTER.splitToList(dim_value);
            if (values.size() > 1) {
                sb.append(" and ( ");
                for (int j = 0; j < values.size(); j++) {
                    sb.append("value = :dvalue").append(i).append('_').append(j);
                    if (j < values.size() - 1) {
                        sb.append(" or ");
                    }
                }
                sb.append(")");
            } else {
                sb.append(" and value = :dvalue").append(i);
            }
        }
        sb.append(")");
        if (it.hasNext()) {
            sb.append(" or ");
        }
    }
    sb.append(") GROUP BY dimension_set_id HAVING count(*) = ").append(dimensions.size()).append(") ");
    return sb.toString();
}
#end_block

#method_before
static Map<String, String> dimensionsFor(Handle handle, byte[] dimensionSetId) {
    return SqlQueries.keyValuesFor(handle, "select name, value from MonMetrics.Dimensions " + "where" + " dimension_set_id = ?", dimensionSetId);
}
#method_after
static Map<String, String> dimensionsFor(Handle handle, byte[] dimensionSetId) {
    return SqlQueries.keyValuesFor(handle, "select name, value from MonMetrics.Dimensions as d " + "join MonMetrics.DefinitionDimensions as dd " + "on d.dimension_set_id = dd.dimension_set_id " + "where" + " dd.id = ?", dimensionSetId);
}
#end_block

#method_before
public void metricQueriesBuildDimensionAndClauseTest1() {
    String expectedResult = " and ( (defdims.name = :dname0 and defdims.value = :dvalue0)" + " or (defdims.name = :dname1 and defdims.value = :dvalue1))";
    Map<String, String> dimsMap = new HashMap<>();
    dimsMap.put("foo", "bar");
    dimsMap.put("biz", "baz");
    String s = MetricQueries.buildDimensionAndClause(dimsMap, TABLE_TO_JOIN_DIMENSIONS_ON);
    assertEquals(expectedResult, s);
}
#method_after
public void metricQueriesBuildDimensionAndClauseTest1() {
    String expectedResult = " and defdims.dimension_set_id in ( SELECT dimension_set_id FROM MonMetrics.Dimensions WHERE" + " ((name = :dname0 and value = :dvalue0) or (name = :dname1 and value = :dvalue1))" + " GROUP BY dimension_set_id HAVING count(*) = 2) ";
    Map<String, String> dimsMap = new HashMap<>();
    dimsMap.put("foo", "bar");
    dimsMap.put("biz", "baz");
    String s = MetricQueries.buildDimensionAndClause(dimsMap, TABLE_TO_JOIN_DIMENSIONS_ON);
    assertEquals(expectedResult, s);
}
#end_block

#method_before
public void metricQueriesBuildDimensionAndClauseTest4() {
    String expectedResult = " and ( (defdims.name = :dname0 and ( defdims.value = :dvalue0_0 or defdims.value = :dvalue0_1)))";
    Map<String, String> dimsMap = new HashMap<>();
    dimsMap.put("foo", "bar|baz");
    String s = MetricQueries.buildDimensionAndClause(dimsMap, TABLE_TO_JOIN_DIMENSIONS_ON);
    assertEquals(expectedResult, s);
}
#method_after
public void metricQueriesBuildDimensionAndClauseTest4() {
    String expectedResult = " and defdims.dimension_set_id in ( SELECT dimension_set_id FROM MonMetrics.Dimensions WHERE" + " ((name = :dname0 and ( value = :dvalue0_0 or value = :dvalue0_1)))" + " GROUP BY dimension_set_id HAVING count(*) = 1) ";
    Map<String, String> dimsMap = new HashMap<>();
    dimsMap.put("foo", "bar|baz");
    String s = MetricQueries.buildDimensionAndClause(dimsMap, TABLE_TO_JOIN_DIMENSIONS_ON);
    assertEquals(expectedResult, s);
}
#end_block

#method_before
public void metricQueriesBuildDimensionAndClauseTest5() {
    String expectedResult = " and ( (defdims.name = :dname0 and ( defdims.value = :dvalue0_0 or defdims.value = :dvalue0_1))" + " or (defdims.name = :dname1 and ( defdims.value = :dvalue1_0 or defdims.value = :dvalue1_1)))";
    Map<String, String> dimsMap = new HashMap<>();
    dimsMap.put("foo", "bar|baz");
    dimsMap.put("biz", "baz|baf");
    String s = MetricQueries.buildDimensionAndClause(dimsMap, TABLE_TO_JOIN_DIMENSIONS_ON);
    assertEquals(expectedResult, s);
}
#method_after
public void metricQueriesBuildDimensionAndClauseTest5() {
    String expectedResult = " and defdims.dimension_set_id in ( SELECT dimension_set_id FROM MonMetrics.Dimensions WHERE" + " ((name = :dname0 and ( value = :dvalue0_0 or value = :dvalue0_1))" + " or (name = :dname1 and ( value = :dvalue1_0 or value = :dvalue1_1)))" + " GROUP BY dimension_set_id HAVING count(*) = 2) ";
    Map<String, String> dimsMap = new HashMap<>();
    dimsMap.put("foo", "bar|baz");
    dimsMap.put("biz", "baz|baf");
    String s = MetricQueries.buildDimensionAndClause(dimsMap, TABLE_TO_JOIN_DIMENSIONS_ON);
    assertEquals(expectedResult, s);
}
#end_block

#method_before
public NotificationMethodDb setPeriod(final int period) {
    this.period = period;
    return this;
}
#method_after
public NotificationMethodDb setPeriod(final Integer period) {
    this.period = period;
    return this;
}
#end_block

#method_before
public int getPeriod() {
    return this.period;
}
#method_after
public Integer getPeriod() {
    return this.period;
}
#end_block

#method_before
private void assertActionsExist(String tenantId, List<String> alarmActions, List<String> okActions, List<String> undeterminedActions) {
    Set<String> actions = new HashSet<>();
    if (alarmActions != null)
        actions.addAll(alarmActions);
    if (okActions != null)
        actions.addAll(okActions);
    if (undeterminedActions != null)
        actions.addAll(undeterminedActions);
    if (!actions.isEmpty())
        for (String action : actions) if (!notificationMethodRepo.exists(tenantId, action))
            throw monasca.api.resource.exception.Exceptions.unprocessableEntity("No notification method exists for action %s " + action);
}
#method_after
private void assertActionsExist(String tenantId, List<String> alarmActions, List<String> okActions, List<String> undeterminedActions) {
    Set<String> actions = new HashSet<>();
    if (alarmActions != null)
        actions.addAll(alarmActions);
    if (okActions != null)
        actions.addAll(okActions);
    if (undeterminedActions != null)
        actions.addAll(undeterminedActions);
    if (!actions.isEmpty())
        for (String action : actions) if (!notificationMethodRepo.exists(tenantId, action))
            throw monasca.api.resource.exception.Exceptions.unprocessableEntity("No notification method exists for action %s", action);
}
#end_block

#method_before
public static Map<String, String> parseAndValidateDimensions(String dimensionsStr) {
    Validation.validateNotNullOrEmpty(dimensionsStr, "dimensions");
    Map<String, String> dimensions = new HashMap<String, String>();
    for (String dimensionStr : COMMA_SPLITTER.split(dimensionsStr)) {
        String[] dimensionArr = Iterables.toArray(COLON_SPLITTER.split(dimensionStr), String.class);
        if (dimensionArr.length == 2) {
            DimensionValidation.validateKey(dimensionArr[0]);
            if (dimensionArr[1].contains("|")) {
                List<String> dimensionValueArr = Splitter.on('|').splitToList(dimensionArr[1]);
                for (String dimensionValue : dimensionValueArr) {
                    DimensionValidation.validateValue(dimensionValue);
                }
            } else {
                DimensionValidation.validateValue(dimensionArr[1]);
            }
            dimensions.put(dimensionArr[0], dimensionArr[1]);
        }
        if (dimensionArr.length == 1) {
            DimensionValidation.validateKey(dimensionArr[0]);
            dimensions.put(dimensionArr[0], "");
        }
    }
    // DimensionValidation.validate(dimensions);
    return dimensions;
}
#method_after
public static Map<String, String> parseAndValidateDimensions(String dimensionsStr) {
    Validation.validateNotNullOrEmpty(dimensionsStr, "dimensions");
    Map<String, String> dimensions = new HashMap<String, String>();
    for (String dimensionStr : COMMA_SPLITTER.split(dimensionsStr)) {
        String[] dimensionArr = Iterables.toArray(COLON_SPLITTER.split(dimensionStr), String.class);
        if (dimensionArr.length == 1) {
            DimensionValidation.validateName(dimensionArr[0]);
            dimensions.put(dimensionArr[0], "");
        } else if (dimensionArr.length > 1) {
            DimensionValidation.validateName(dimensionArr[0]);
            if (dimensionArr[1].contains("|")) {
                List<String> dimensionValueArr = VERTICAL_BAR_SPLITTER.splitToList(dimensionArr[1]);
                for (String dimensionValue : dimensionValueArr) {
                    DimensionValidation.validateValue(dimensionValue, dimensionArr[0]);
                }
            } else {
                DimensionValidation.validateValue(dimensionArr[1], dimensionArr[0]);
            }
            dimensions.put(dimensionArr[0], dimensionArr[1]);
        }
    }
    // DimensionValidation.validate(dimensions);
    return dimensions;
}
#end_block

#method_before
public static void validate(Map<String, String> dimensions) {
    // Validate dimension names and values
    for (Map.Entry<String, String> dimension : dimensions.entrySet()) {
        String name = dimension.getKey();
        String value = dimension.getValue();
        // General validations
        if (Strings.isNullOrEmpty(name))
            throw Exceptions.unprocessableEntity("Dimension name cannot be empty");
        if (Strings.isNullOrEmpty(value))
            throw Exceptions.unprocessableEntity("Dimension %s cannot have an empty value", name);
        if (name.length() > 255)
            throw Exceptions.unprocessableEntity("Dimension name %s must be 255 characters or less", name);
        if (value.length() > 255)
            throw Exceptions.unprocessableEntity("Dimension value %s must be 255 characters or less", value);
        // Dimension names that start with underscores are reserved for internal use only.
        if (name.startsWith("_")) {
            throw Exceptions.unprocessableEntity("Dimension name cannot start with underscore (_)", name);
        }
        if (!VALID_DIMENSION_NAME.matcher(name).matches())
            throw Exceptions.unprocessableEntity("Dimension name %s may not contain: %s", name, INVALID_CHAR_STRING);
        if (!VALID_DIMENSION_NAME.matcher(value).matches())
            throw Exceptions.unprocessableEntity("Dimension value %s may not contain: %s", value, INVALID_CHAR_STRING);
    }
}
#method_after
public static void validate(Map<String, String> dimensions) {
    // Validate dimension names and values
    for (Map.Entry<String, String> dimension : dimensions.entrySet()) {
        String name = dimension.getKey();
        String value = dimension.getValue();
        // General validations
        validateDimensionName(name);
        validateDimensionValue(value, name, false);
    }
}
#end_block

#method_before
/**
 * Validates a list of dimension names
 * @param names
 */
public static void validateNames(List<String> names) {
    if (names != null) {
        for (String name : names) {
            if (Strings.isNullOrEmpty(name)) {
                throw Exceptions.unprocessableEntity("Dimension name cannot be empty");
            }
            if (name.length() > 255) {
                throw Exceptions.unprocessableEntity("Dimension name '%s' must be 255 characters or less", name);
            }
            // Dimension names that start with underscores are reserved for internal use only.
            if (name.startsWith("_")) {
                throw Exceptions.unprocessableEntity("Dimension name '%s' cannot start with underscore (_)", name);
            }
            if (!VALID_DIMENSION_NAME.matcher(name).matches())
                throw Exceptions.unprocessableEntity("Dimension name '%s' may not contain: %s", name, INVALID_CHAR_STRING);
        }
    }
}
#method_after
public static void validateNames(List<String> names) {
    if (names != null) {
        for (String name : names) {
            validateDimensionName(name);
        }
    }
}
#end_block

#method_before
public static void validateValue(String value) {
    if (value != null) {
        if (Strings.isNullOrEmpty(value)) {
            throw Exceptions.unprocessableEntity("Dimension value cannot be empty");
        }
        if (value.length() > 255) {
            throw Exceptions.unprocessableEntity("Dimension value '%s' must be 255 characters or less", value);
        }
        if (!VALID_DIMENSION_NAME.matcher(value).matches()) {
            throw Exceptions.unprocessableEntity("Dimension value '%s' may not contain: %s", value, INVALID_CHAR_STRING);
        }
    }
}
#method_after
public static void validateValue(String value, String name) {
    validateDimensionValue(value, name, true);
}
#end_block

#method_before
public void shouldValidateKey() {
    DimensionValidation.validateKey("this.is_a.valid-key");
}
#method_after
public void shouldValidateKey() {
    DimensionValidation.validateName("this.is_a.valid-key");
}
#end_block

#method_before
@Test(expectedExceptions = WebApplicationException.class)
public void shouldErrorOnValidateKeyWithEmptyKey() {
    DimensionValidation.validateKey("");
}
#method_after
@Test(expectedExceptions = WebApplicationException.class)
public void shouldErrorOnValidateKeyWithEmptyKey() {
    DimensionValidation.validateName("");
}
#end_block

#method_before
@Test(expectedExceptions = WebApplicationException.class)
public void shouldErrorOnValidateKeyWithLongKey() {
    String key = StringUtils.repeat("A", 256);
    DimensionValidation.validateKey(key);
}
#method_after
@Test(expectedExceptions = WebApplicationException.class)
public void shouldErrorOnValidateKeyWithLongKey() {
    String key = StringUtils.repeat("A", 256);
    DimensionValidation.validateName(key);
}
#end_block

#method_before
@Test(expectedExceptions = WebApplicationException.class)
public void shouldErrorOnValidateKeyWithStartingUnderscore() {
    DimensionValidation.validateKey("_key");
}
#method_after
@Test(expectedExceptions = WebApplicationException.class)
public void shouldErrorOnValidateKeyWithStartingUnderscore() {
    DimensionValidation.validateName("_key");
}
#end_block

#method_before
@Test(expectedExceptions = WebApplicationException.class)
public void shouldErrorOnValidateKeyWithInvalidCharKey() {
    DimensionValidation.validateKey("this{}that");
}
#method_after
@Test(expectedExceptions = WebApplicationException.class)
public void shouldErrorOnValidateKeyWithInvalidCharKey() {
    DimensionValidation.validateName("this{}that");
}
#end_block

#method_before
public void shouldValidateValue() {
    DimensionValidation.validateValue("this.is_a.valid-value");
}
#method_after
public void shouldValidateValue() {
    DimensionValidation.validateValue("this.is_a.valid-value", "valid_name");
}
#end_block

#method_before
@Test(expectedExceptions = WebApplicationException.class)
public void shouldErrorOnValidateValueWithEmptyValue() {
    DimensionValidation.validateValue("");
}
#method_after
@Test(expectedExceptions = WebApplicationException.class)
public void shouldErrorOnValidateValueWithEmptyValue() {
    DimensionValidation.validateValue("", "valid_name");
}
#end_block

#method_before
@Test(expectedExceptions = WebApplicationException.class)
public void shouldErrorOnValidateValueWithLongValue() {
    String value = StringUtils.repeat("A", 256);
    DimensionValidation.validateValue(value);
}
#method_after
@Test(expectedExceptions = WebApplicationException.class)
public void shouldErrorOnValidateValueWithLongValue() {
    String value = StringUtils.repeat("A", 256);
    DimensionValidation.validateValue(value, "valid_name");
}
#end_block

#method_before
@Test(expectedExceptions = WebApplicationException.class)
public void shouldErrorOnValidateValueWithInvalidCharValue() {
    DimensionValidation.validateValue("this{}that");
}
#method_after
@Test(expectedExceptions = WebApplicationException.class)
public void shouldErrorOnValidateValueWithInvalidCharValue() {
    DimensionValidation.validateValue("this{}that", "valid_name");
}
#end_block

#method_before
static String buildDimensionAndClause(Map<String, String> dimensions, String tableToJoinName, int limit) {
    StringBuilder sb = null;
    if (dimensions != null && dimensions.size() > 0) {
        int numDims = dimensions.size();
        sb = new StringBuilder();
        sb.append(" and " + tableToJoinName + ".dimension_set_id in ").append("(select dimension_set_id from MonMetrics.Dimensions where ");
        int i = 0;
        for (String dimension_key : dimensions.keySet()) {
            sb.append("name = :dname").append(i);
            String dim_value = dimensions.get(dimension_key);
            if (!Strings.isNullOrEmpty(dim_value)) {
                List<String> values = Splitter.on('|').splitToList(dim_value);
                if (values.size() > 1) {
                    sb.append(" and ( ");
                    for (int j = 0; j < values.size(); j++) {
                        sb.append("value = :dvalue").append(i).append('_').append(j);
                        if (j < values.size() - 1) {
                            sb.append(" or ");
                        }
                    }
                    sb.append(" )");
                } else {
                    sb.append(" and value = :dvalue").append(i);
                }
            }
            i++;
            if (i < numDims) {
                sb.append(" or ");
            }
        }
        sb.append(" group by dimension_set_id").append(" having count(*) = " + numDims + " ");
        // 
        if (limit > 0) {
            sb.append("order by dimension_set_id ").append("limit " + Integer.toString(limit + 1));
        }
        sb.append(")");
    }
    return sb == null ? "" : sb.toString();
}
#method_after
static String buildDimensionAndClause(Map<String, String> dimensions, String tableToJoinName, int limit) {
    StringBuilder sb = null;
    if (dimensions != null && dimensions.size() > 0) {
        int numDims = dimensions.size();
        sb = new StringBuilder();
        sb.append(" and " + tableToJoinName + ".dimension_set_id in ").append("(select dimension_set_id from MonMetrics.Dimensions where ");
        int i = 0;
        for (Iterator<Map.Entry<String, String>> it = dimensions.entrySet().iterator(); it.hasNext(); i++) {
            Map.Entry<String, String> entry = it.next();
            sb.append("name = :dname").append(i);
            String dim_value = entry.getValue();
            if (!Strings.isNullOrEmpty(dim_value)) {
                List<String> values = Splitter.on('|').splitToList(dim_value);
                if (values.size() > 1) {
                    sb.append(" and ( ");
                    for (int j = 0; j < values.size(); j++) {
                        sb.append("value = :dvalue").append(i).append('_').append(j);
                        if (j < values.size() - 1) {
                            sb.append(" or ");
                        }
                    }
                    sb.append(" )");
                } else {
                    sb.append(" and value = :dvalue").append(i);
                }
            }
            if (it.hasNext()) {
                sb.append(" or ");
            }
        }
        sb.append(" group by dimension_set_id").append(" having count(*) = " + numDims + " ");
        // 
        if (limit > 0) {
            sb.append("order by dimension_set_id ").append("limit " + Integer.toString(limit + 1));
        }
        sb.append(")");
    }
    return sb == null ? "" : sb.toString();
}
#end_block

#method_before
@Override
public List<AlarmStateHistory> find(String tenantId, Map<String, String> dimensions, DateTime startTime, @Nullable DateTime endTime, @Nullable String offset, int limit) {
    List<String> alarmIds = this.utils.findAlarmIds(tenantId, dimensions);
    if (alarmIds == null || alarmIds.isEmpty()) {
        logger.debug("list of alarm ids is empty");
        return Collections.emptyList();
    }
    StringBuilder sb = new StringBuilder();
    sb.append(" and alarm_id in (");
    for (int i = 0; i < alarmIds.size(); i++) {
        if (i > 0) {
            sb.append(", ");
        }
        sb.append('\'').append(alarmIds.get(i)).append('\'');
    }
    sb.append(')');
    if (startTime != null) {
        sb.append(" and time_stamp > :startTime");
    }
    if (endTime != null) {
        sb.append(" and time_stamp < :endTime");
    }
    if (offset != null && !offset.isEmpty()) {
        sb.append(" and time_stamp > :offset");
    }
    String sql = String.format(FIND_BY_ALARM_IDS_SQL, sb);
    logger.debug("vertica sql: {}", sql);
    List<AlarmStateHistory> alarmStateHistoryList = new ArrayList<>();
    try (Handle h = vertica.open()) {
        Query<Map<String, Object>> verticaQuery = h.createQuery(sql).bind("tenantId", tenantId).bind("limit", limit + 1);
        if (startTime != null) {
            logger.debug("binding startime: {}", startTime);
            // Timestamp will not work in this query for some unknown reason.
            verticaQuery.bind("startTime", formatDateFromMillis(startTime.getMillis()));
        }
        if (endTime != null) {
            logger.debug("binding endtime: {}", endTime);
            // Timestamp will not work in this query for some unknown reason.
            verticaQuery.bind("endTime", formatDateFromMillis(endTime.getMillis()));
        }
        if (offset != null && !offset.isEmpty()) {
            logger.debug("binding offset: {}", offset);
            DateTime offset_dt = new DateTime(offset);
            verticaQuery.bind("offset", formatDateFromMillis(offset_dt.getMillis()));
        }
        DimensionQueries.bindDimensionsToQuery(verticaQuery, dimensions);
        for (Map<String, Object> row : verticaQuery.list()) {
            alarmStateHistoryList.add(getAlarmStateHistory(row));
        }
    }
    return alarmStateHistoryList;
}
#method_after
@Override
public List<AlarmStateHistory> find(String tenantId, Map<String, String> dimensions, DateTime startTime, @Nullable DateTime endTime, @Nullable String offset, int limit) {
    List<String> alarmIds = this.utils.findAlarmIds(tenantId, dimensions);
    if (alarmIds == null || alarmIds.isEmpty()) {
        logger.debug("list of alarm ids is empty");
        return Collections.emptyList();
    }
    StringBuilder sb = new StringBuilder();
    sb.append(" and alarm_id in (");
    for (int i = 0; i < alarmIds.size(); i++) {
        if (i > 0) {
            sb.append(", ");
        }
        sb.append('\'').append(alarmIds.get(i)).append('\'');
    }
    sb.append(')');
    if (startTime != null) {
        sb.append(" and time_stamp >= :startTime");
    }
    if (endTime != null) {
        sb.append(" and time_stamp <= :endTime");
    }
    if (offset != null && !offset.isEmpty()) {
        sb.append(" and time_stamp > :offset");
    }
    String sql = String.format(FIND_BY_ALARM_IDS_SQL, sb);
    logger.debug("vertica sql: {}", sql);
    List<AlarmStateHistory> alarmStateHistoryList = new ArrayList<>();
    try (Handle h = vertica.open()) {
        Query<Map<String, Object>> verticaQuery = h.createQuery(sql).bind("tenantId", tenantId).bind("limit", limit + 1);
        if (startTime != null) {
            logger.debug("binding startime: {}", startTime);
            // Timestamp will not work in this query for some unknown reason.
            verticaQuery.bind("startTime", formatDateFromMillis(startTime.getMillis()));
        }
        if (endTime != null) {
            logger.debug("binding endtime: {}", endTime);
            // Timestamp will not work in this query for some unknown reason.
            verticaQuery.bind("endTime", formatDateFromMillis(endTime.getMillis()));
        }
        if (offset != null && !offset.isEmpty()) {
            logger.debug("binding offset: {}", offset);
            DateTime offset_dt = new DateTime(offset);
            verticaQuery.bind("offset", formatDateFromMillis(offset_dt.getMillis()));
        }
        DimensionQueries.bindDimensionsToQuery(verticaQuery, dimensions);
        for (Map<String, Object> row : verticaQuery.list()) {
            alarmStateHistoryList.add(getAlarmStateHistory(row));
        }
    }
    return alarmStateHistoryList;
}
#end_block

#method_before
private List<Map<String, Object>> executeMetricDefsQuery(String tenantId, String name, Map<String, String> dimensions, DateTime startTime, DateTime endTime, String offset, int limit) {
    String namePart = "";
    if (name != null && !name.isEmpty()) {
        namePart = " and def.name = :name ";
    }
    String offsetPart = "";
    if (offset != null && !offset.isEmpty()) {
        offsetPart = " and defdimsSub.id > :offset ";
    }
    try (Handle h = db.open()) {
        // If startTime/endTime is specified, create the 'IN' select statement
        String timeInClause = createTimeInClause(h, startTime, endTime, tenantId, name, dimensions);
        String sql = String.format(FIND_METRIC_DEFS_SQL, namePart, offsetPart, MetricQueries.buildDimensionAndClause(dimensions, "defDims", limit), timeInClause);
        Query<Map<String, Object>> query = h.createQuery(sql).bind("tenantId", tenantId);
        if (name != null && !name.isEmpty()) {
            logger.debug("binding name: {}", name);
            query.bind("name", name);
        }
        if (startTime != null) {
            query.bind("start_time", startTime);
        }
        if (endTime != null) {
            query.bind("end_time", endTime);
        }
        if (offset != null && !offset.isEmpty()) {
            logger.debug("binding offset: {}", offset);
            try {
                query.bind("offset", Hex.decodeHex(offset.toCharArray()));
            } catch (DecoderException e) {
                throw Exceptions.badRequest("failed to decode offset " + offset, e);
            }
        }
        MetricQueries.bindDimensionsToQuery(query, dimensions);
        return query.list();
    }
}
#method_after
private List<Map<String, Object>> executeMetricDefsQuery(String tenantId, String name, Map<String, String> dimensions, DateTime startTime, DateTime endTime, String offset, int limit) {
    String namePart = "";
    if (name != null && !name.isEmpty()) {
        namePart = " and def.name = :name ";
    }
    String offsetPart = "";
    if (offset != null && !offset.isEmpty()) {
        offsetPart = " and defDims.id > :offset ";
    }
    try (Handle h = db.open()) {
        // If startTime/endTime is specified, create the 'IN' select statement
        String timeInClause = createTimeInClause(h, startTime, endTime, tenantId, name, dimensions);
        String sql = String.format(FIND_METRIC_DEFS_SQL, namePart, offsetPart, MetricQueries.buildDimensionAndClause(dimensions, "defDims", limit), timeInClause);
        Query<Map<String, Object>> query = h.createQuery(sql).bind("tenantId", tenantId);
        if (name != null && !name.isEmpty()) {
            logger.debug("binding name: {}", name);
            query.bind("name", name);
        }
        if (startTime != null) {
            query.bind("start_time", startTime);
        }
        if (endTime != null) {
            query.bind("end_time", endTime);
        }
        if (offset != null && !offset.isEmpty()) {
            logger.debug("binding offset: {}", offset);
            try {
                query.bind("offset", Hex.decodeHex(offset.toCharArray()));
            } catch (DecoderException e) {
                throw Exceptions.badRequest("failed to decode offset " + offset, e);
            }
        }
        MetricQueries.bindDimensionsToQuery(query, dimensions);
        return query.list();
    }
}
#end_block

#method_before
private String createTimeInClause(Handle dbHandle, DateTime startTime, DateTime endTime, String tenantId, String metricName, Map<String, String> dimensions) {
    if (startTime == null) {
        return "";
    }
    Set<byte[]> defDimIdSet = new HashSet<>();
    String namePart = "";
    if (metricName != null && !metricName.isEmpty()) {
        namePart = "AND def.name = :name ";
    }
    String defDimSql = String.format(DEFDIM_IDS_SELECT, namePart, MetricQueries.buildJoinClauseFor(dimensions, "defDims"));
    Query<Map<String, Object>> query = dbHandle.createQuery(defDimSql).bind("tenantId", tenantId);
    DimensionQueries.bindDimensionsToQuery(query, dimensions);
    if (metricName != null && !metricName.isEmpty()) {
        query.bind("name", metricName);
    }
    List<Map<String, Object>> rows = query.list();
    for (Map<String, Object> row : rows) {
        byte[] defDimId = (byte[]) row.get("id");
        defDimIdSet.add(defDimId);
    }
    // 
    if (defDimIdSet.size() == 0) {
        return "";
    }
    String timeAndClause = "";
    if (endTime != null) {
        timeAndClause = "AND time_stamp >= :start_time AND time_stamp <= :end_time ";
    } else {
        timeAndClause = "AND time_stamp >= :start_time ";
    }
    String defDimInClause = MetricQueries.createDefDimIdInClause(defDimIdSet);
    return String.format(MEASUREMENT_AND_CLAUSE, defDimInClause, timeAndClause);
}
#method_after
private String createTimeInClause(Handle dbHandle, DateTime startTime, DateTime endTime, String tenantId, String metricName, Map<String, String> dimensions) {
    if (startTime == null) {
        return "";
    }
    Set<byte[]> defDimIdSet = new HashSet<>();
    String namePart = "";
    if (metricName != null && !metricName.isEmpty()) {
        namePart = "AND def.name = :name ";
    }
    String defDimSql = String.format(DEFDIM_IDS_SELECT, MetricQueries.buildJoinClauseFor(dimensions, "defDims"), namePart);
    Query<Map<String, Object>> query = dbHandle.createQuery(defDimSql).bind("tenantId", tenantId);
    MetricQueries.bindDimensionsToQuery(query, dimensions);
    if (metricName != null && !metricName.isEmpty()) {
        query.bind("name", metricName);
    }
    List<Map<String, Object>> rows = query.list();
    for (Map<String, Object> row : rows) {
        byte[] defDimId = (byte[]) row.get("id");
        defDimIdSet.add(defDimId);
    }
    // 
    if (defDimIdSet.size() == 0) {
        return "";
    }
    String timeAndClause = "";
    if (endTime != null) {
        timeAndClause = "AND time_stamp >= :start_time AND time_stamp <= :end_time ";
    } else {
        timeAndClause = "AND time_stamp >= :start_time ";
    }
    String defDimInClause = MetricQueries.createDefDimIdInClause(defDimIdSet);
    return String.format(MEASUREMENT_AND_CLAUSE, defDimInClause, timeAndClause);
}
#end_block

#method_before
public void reconnect() {
    LOG.info("---- Worker " + this + " starting reconnect for " + session.toString());
    // In case we held the availability lock earlier, release it.
    availability.unlock(this);
    try {
        session.initSession(ioAvailable, this);
        if (id != null) {
            sendToAll(new GearmanPacketImpl(GearmanPacketMagic.REQ, GearmanPacketType.SET_CLIENT_ID, ByteUtils.toUTF8Bytes(id)));
        }
        // Reset events so that we don't process events from the old
        // connection.
        eventList = new ConcurrentLinkedQueue<GearmanSessionEvent>();
        // this will cause a grab-job event
        functionRegistry.setUpdated(true);
    } catch (IOException e) {
        try {
            Thread.sleep(2000);
        } catch (InterruptedException e1) {
            LOG.warn("---- Worker " + this + " interrupted while reconnecting", e);
            return;
        }
    }
    LOG.info("---- Worker " + this + " ending reconnect for " + session.toString());
}
#method_after
public void reconnect() {
    LOG.info("---- Worker " + this + " starting reconnect for " + session.toString());
    // In case we held the availability lock earlier, release it.
    availability.unlock(this);
    try {
        session.initSession(ioAvailable, this);
        if (id != null) {
            sendToAll(new GearmanPacketImpl(GearmanPacketMagic.REQ, GearmanPacketType.SET_CLIENT_ID, ByteUtils.toUTF8Bytes(id)));
        }
        // Reset events so that we don't process events from the old
        // connection.
        eventList = new ConcurrentLinkedQueue<GearmanSessionEvent>();
        // this will cause a grab-job event
        functionRegistry.setUpdated(true);
        // Make sure we reset the function list
        functionMap.clear();
    } catch (IOException e) {
        try {
            Thread.sleep(2000);
        } catch (InterruptedException e1) {
            LOG.warn("---- Worker " + this + " interrupted while reconnecting", e);
            return;
        }
    }
    LOG.info("---- Worker " + this + " ending reconnect for " + session.toString());
}
#end_block

#method_before
private void sendSubAlarmStateChange(SubAlarmStats subAlarmStats) {
    logger.debug("Alarm state changed for {}", subAlarmStats);
    collector.emit(new Values(subAlarmStats.getSubAlarm().getAlarmId(), subAlarmStats.getSubAlarm().clone()));
}
#method_after
private void sendSubAlarmStateChange(SubAlarmStats subAlarmStats) {
    logger.debug("Alarm state changed for {}", subAlarmStats);
    collector.emit(new Values(subAlarmStats.getSubAlarm().getAlarmId(), duplicate(subAlarmStats.getSubAlarm())));
}
#end_block

#method_before
@Test(groups = "database")
public void shouldFind() {
    checkList(repo.find("Not a tenant id", null, null, null, null, null, null, null, null, null, null, 1, false));
    checkList(repo.find(TENANT_ID, null, null, null, null, null, null, null, null, null, null, 1, false), alarm1, alarm2, alarm3, compoundAlarm);
    checkList(repo.find(TENANT_ID, compoundAlarm.getAlarmDefinition().getId(), null, null, null, null, null, null, null, null, null, 1, false), compoundAlarm);
    checkList(repo.find(TENANT_ID, null, "cpu.sys_mem", null, null, null, null, null, null, null, null, 1, false), compoundAlarm);
    checkList(repo.find(TENANT_ID, null, "cpu.idle_perc", null, null, null, null, null, null, null, null, 1, false), alarm1, alarm2, alarm3, compoundAlarm);
    checkList(repo.find(TENANT_ID, null, "cpu.idle_perc", ImmutableMap.<String, String>builder().put("flavor_id", "222").build(), null, null, null, null, null, null, null, 1, false), alarm1, alarm3);
    checkList(repo.find(TENANT_ID, null, "cpu.idle_perc", ImmutableMap.<String, String>builder().put("service", "monitoring").put("hostname", "roland").build(), null, null, null, null, null, null, null, 1, false), compoundAlarm);
    checkList(repo.find(TENANT_ID, null, null, null, AlarmState.UNDETERMINED, null, null, null, null, null, null, 1, false), alarm2, compoundAlarm);
    checkList(repo.find(TENANT_ID, alarm1.getAlarmDefinition().getId(), "cpu.idle_perc", ImmutableMap.<String, String>builder().put("service", "monitoring").build(), null, null, null, null, null, null, null, 1, false), alarm1, alarm2);
    checkList(repo.find(TENANT_ID, alarm1.getAlarmDefinition().getId(), "cpu.idle_perc", null, null, null, null, null, null, null, null, 1, false), alarm1, alarm2, alarm3);
    checkList(repo.find(TENANT_ID, compoundAlarm.getAlarmDefinition().getId(), null, null, AlarmState.UNDETERMINED, null, null, null, null, null, null, 1, false), compoundAlarm);
    checkList(repo.find(TENANT_ID, null, "cpu.sys_mem", null, AlarmState.UNDETERMINED, null, null, null, null, null, null, 1, false), compoundAlarm);
    checkList(repo.find(TENANT_ID, null, "cpu.idle_perc", ImmutableMap.<String, String>builder().put("service", "monitoring").build(), AlarmState.UNDETERMINED, null, null, null, null, null, null, 1, false), alarm2, compoundAlarm);
    checkList(repo.find(TENANT_ID, alarm1.getAlarmDefinition().getId(), "cpu.idle_perc", ImmutableMap.<String, String>builder().put("service", "monitoring").build(), AlarmState.UNDETERMINED, null, null, null, null, null, null, 1, false), alarm2);
    checkList(repo.find(TENANT_ID, null, null, null, null, null, null, null, DateTime.now(DateTimeZone.forID("UTC")), null, null, 0, false));
    checkList(repo.find(TENANT_ID, null, null, null, null, null, null, null, ISO_8601_FORMATTER.parseDateTime("2015-03-15T00:00:00Z"), null, null, 0, false), compoundAlarm);
    checkList(repo.find(TENANT_ID, null, null, null, null, null, null, null, ISO_8601_FORMATTER.parseDateTime("2015-03-14T00:00:00Z"), null, null, 1, false), alarm1, alarm2, alarm3, compoundAlarm);
    checkList(repo.find(TENANT_ID, null, null, null, null, null, null, null, null, Arrays.asList("state", "severity"), null, 1, false), alarm1, alarm2, compoundAlarm, alarm3);
    checkList(repo.find(TENANT_ID, null, null, null, null, null, null, null, null, Arrays.asList("state desc", "severity"), null, 1, false), compoundAlarm, alarm3, alarm2, alarm1);
}
#method_after
@Test(groups = "database")
public void shouldFind() {
    checkList(repo.find("Not a tenant id", null, null, null, null, null, null, null, null, null, null, 1, false));
    checkList(repo.find(TENANT_ID, null, null, null, null, null, null, null, null, null, null, 1, false), alarm1, alarm2, alarm3, compoundAlarm);
    checkList(repo.find(TENANT_ID, compoundAlarm.getAlarmDefinition().getId(), null, null, null, null, null, null, null, null, null, 1, false), compoundAlarm);
    checkList(repo.find(TENANT_ID, null, "cpu.sys_mem", null, null, null, null, null, null, null, null, 1, false), compoundAlarm);
    checkList(repo.find(TENANT_ID, null, "cpu.idle_perc", null, null, null, null, null, null, null, null, 1, false), alarm1, alarm2, alarm3, compoundAlarm);
    checkList(repo.find(TENANT_ID, null, "cpu.idle_perc", ImmutableMap.<String, String>builder().put("flavor_id", "222").build(), null, null, null, null, null, null, null, 1, false), alarm1, alarm3);
    checkList(repo.find(TENANT_ID, null, "cpu.idle_perc", ImmutableMap.<String, String>builder().put("service", "monitoring").put("hostname", "roland").build(), null, null, null, null, null, null, null, 1, false), compoundAlarm);
    checkList(repo.find(TENANT_ID, null, null, null, AlarmState.UNDETERMINED, null, null, null, null, null, null, 1, false), alarm2, compoundAlarm);
    checkList(repo.find(TENANT_ID, alarm1.getAlarmDefinition().getId(), "cpu.idle_perc", ImmutableMap.<String, String>builder().put("service", "monitoring").build(), null, null, null, null, null, null, null, 1, false), alarm1, alarm2);
    checkList(repo.find(TENANT_ID, alarm1.getAlarmDefinition().getId(), "cpu.idle_perc", null, null, null, null, null, null, null, null, 1, false), alarm1, alarm2, alarm3);
    checkList(repo.find(TENANT_ID, compoundAlarm.getAlarmDefinition().getId(), null, null, AlarmState.UNDETERMINED, null, null, null, null, null, null, 1, false), compoundAlarm);
    checkList(repo.find(TENANT_ID, null, "cpu.sys_mem", null, AlarmState.UNDETERMINED, null, null, null, null, null, null, 1, false), compoundAlarm);
    checkList(repo.find(TENANT_ID, null, "cpu.idle_perc", ImmutableMap.<String, String>builder().put("service", "monitoring").build(), AlarmState.UNDETERMINED, null, null, null, null, null, null, 1, false), alarm2, compoundAlarm);
    checkList(repo.find(TENANT_ID, alarm1.getAlarmDefinition().getId(), "cpu.idle_perc", ImmutableMap.<String, String>builder().put("service", "monitoring").build(), AlarmState.UNDETERMINED, null, null, null, null, null, null, 1, false), alarm2);
    checkList(repo.find(TENANT_ID, null, null, null, null, null, null, null, DateTime.now(DateTimeZone.forID("UTC")), null, null, 0, false));
    checkList(repo.find(TENANT_ID, null, null, null, null, null, null, null, ISO_8601_FORMATTER.parseDateTime("2015-03-15T00:00:00Z"), null, null, 0, false), compoundAlarm);
    checkList(repo.find(TENANT_ID, null, null, null, null, null, null, null, ISO_8601_FORMATTER.parseDateTime("2015-03-14T00:00:00Z"), null, null, 1, false), alarm1, alarm2, alarm3, compoundAlarm);
    checkList(repo.find(TENANT_ID, null, null, null, null, null, null, null, null, Arrays.asList("state", "severity"), null, 1, false), alarm1, alarm2, compoundAlarm, alarm3);
    checkList(repo.find(TENANT_ID, null, null, null, null, null, null, null, null, Arrays.asList("state desc", "severity"), null, 1, false), compoundAlarm, alarm3, alarm2, alarm1);
    checkList(repo.find(TENANT_ID, null, null, null, null, AlarmSeverity.HIGH, null, null, null, null, null, 1, false), compoundAlarm);
}
#end_block

#method_before
@SuppressWarnings("unchecked")
@Override
public List<AlarmDefinition> find(String tenantId, String name, Map<String, String> dimensions, AlarmSeverity severity, List<String> sortBy, String offset, int limit) {
    try (Handle h = db.open()) {
        String query = "  SELECT t.id, t.tenant_id, t.name, t.description, t.expression, t.severity, t.match_by," + "     t.actions_enabled, t.created_at, t.updated_at, t.deleted_at, " + "     GROUP_CONCAT(aa.alarm_state) AS states, " + "     GROUP_CONCAT(aa.action_id) AS notificationIds " + "FROM (SELECT distinct ad.id, ad.tenant_id, ad.name, ad.description, ad.expression," + "        ad.severity, ad.match_by, ad.actions_enabled, ad.created_at, " + "        ad.updated_at, ad.deleted_at " + "      FROM alarm_definition AS ad " + "      LEFT OUTER JOIN sub_alarm_definition AS sad ON ad.id = sad.alarm_definition_id " + "      LEFT OUTER JOIN sub_alarm_definition_dimension AS dim ON sad.id = dim.sub_alarm_definition_id %1$s " + "      WHERE ad.tenant_id = :tenantId AND ad.deleted_at IS NULL %2$s) AS t " + "LEFT OUTER JOIN alarm_action AS aa ON t.id = aa.alarm_definition_id " + "GROUP BY t.id %3$s %4$s %5$s";
        StringBuilder sbWhere = new StringBuilder();
        if (name != null) {
            sbWhere.append(" and ad.name = :name");
        }
        String orderByPart = "";
        if (sortBy != null && !sortBy.isEmpty()) {
            orderByPart = " order by " + COMMA_JOINER.join(sortBy);
            if (!orderByPart.contains("id")) {
                orderByPart = orderByPart + ",id";
            }
        } else {
            orderByPart = " order by id ";
        }
        String limitPart = "";
        if (limit > 0) {
            limitPart = " limit :limit";
        }
        String offsetPart = "";
        if (offset != null) {
            offsetPart = " offset " + offset + ' ';
        }
        String sql = String.format(query, SubAlarmDefinitionQueries.buildJoinClauseFor(dimensions), sbWhere, orderByPart, limitPart, offsetPart);
        Query<?> q = h.createQuery(sql);
        q.bind("tenantId", tenantId);
        if (name != null) {
            q.bind("name", name);
        }
        if (limit > 0) {
            q.bind("limit", limit + 1);
        }
        q.registerMapper(new AlarmDefinitionMapper());
        q = q.mapTo(AlarmDefinition.class);
        DimensionQueries.bindDimensionsToQuery(q, dimensions);
        List<AlarmDefinition> resultSet = (List<AlarmDefinition>) q.list();
        return resultSet;
    }
}
#method_after
@SuppressWarnings("unchecked")
@Override
public List<AlarmDefinition> find(String tenantId, String name, Map<String, String> dimensions, AlarmSeverity severity, List<String> sortBy, String offset, int limit) {
    try (Handle h = db.open()) {
        String query = "  SELECT t.id, t.tenant_id, t.name, t.description, t.expression, t.severity, t.match_by," + "     t.actions_enabled, t.created_at, t.updated_at, t.deleted_at, " + "     GROUP_CONCAT(aa.alarm_state) AS states, " + "     GROUP_CONCAT(aa.action_id) AS notificationIds " + "FROM (SELECT distinct ad.id, ad.tenant_id, ad.name, ad.description, ad.expression," + "        ad.severity, ad.match_by, ad.actions_enabled, ad.created_at, " + "        ad.updated_at, ad.deleted_at " + "      FROM alarm_definition AS ad " + "      LEFT OUTER JOIN sub_alarm_definition AS sad ON ad.id = sad.alarm_definition_id " + "      LEFT OUTER JOIN sub_alarm_definition_dimension AS dim ON sad.id = dim.sub_alarm_definition_id %1$s " + "      WHERE ad.tenant_id = :tenantId AND ad.deleted_at IS NULL %2$s) AS t " + "LEFT OUTER JOIN alarm_action AS aa ON t.id = aa.alarm_definition_id " + "GROUP BY t.id %3$s %4$s %5$s";
        StringBuilder sbWhere = new StringBuilder();
        if (name != null) {
            sbWhere.append(" and ad.name = :name");
        }
        if (severity != null) {
            sbWhere.append(" and ad.severity = :severity");
        }
        String orderByPart = "";
        if (sortBy != null && !sortBy.isEmpty()) {
            orderByPart = " order by " + COMMA_JOINER.join(sortBy);
            if (!orderByPart.contains("id")) {
                orderByPart = orderByPart + ",id";
            }
        } else {
            orderByPart = " order by id ";
        }
        String limitPart = "";
        if (limit > 0) {
            limitPart = " limit :limit";
        }
        String offsetPart = "";
        if (offset != null) {
            offsetPart = " offset " + offset + ' ';
        }
        String sql = String.format(query, SubAlarmDefinitionQueries.buildJoinClauseFor(dimensions), sbWhere, orderByPart, limitPart, offsetPart);
        Query<?> q = h.createQuery(sql);
        q.bind("tenantId", tenantId);
        if (name != null) {
            q.bind("name", name);
        }
        if (severity != null) {
            q.bind("severity", severity.name());
        }
        if (limit > 0) {
            q.bind("limit", limit + 1);
        }
        q.registerMapper(new AlarmDefinitionMapper());
        q = q.mapTo(AlarmDefinition.class);
        DimensionQueries.bindDimensionsToQuery(q, dimensions);
        List<AlarmDefinition> resultSet = (List<AlarmDefinition>) q.list();
        return resultSet;
    }
}
#end_block

#method_before
@Override
@SuppressWarnings("unchecked")
public List<AlarmDefinition> find(String tenantId, String name, Map<String, String> dimensions, AlarmSeverity severity, List<String> sortBy, String offset, int limit) {
    logger.trace(ORM_LOG_MARKER, "find(...) entering...");
    if (sortBy != null && !sortBy.isEmpty()) {
        throw Exceptions.unprocessableEntity("Sort_by is not implemented for the hibernate database type");
    }
    Session session = null;
    List<AlarmDefinition> resultSet = Lists.newArrayList();
    // TODO introduce criteria here, will make code significantly better
    String query = "  SELECT t.id, t.tenant_id, t.name, t.description, t.expression, t.severity, t.match_by, " + "t.actions_enabled, aa.alarm_state AS states, aa.action_id AS notificationIds " + "FROM (SELECT distinct ad.id, ad.tenant_id, ad.name, ad.description, ad.expression, " + "ad.severity, ad.match_by, ad.actions_enabled, ad.created_at, ad.updated_at, ad.deleted_at " + "FROM alarm_definition AS ad LEFT OUTER JOIN sub_alarm_definition AS sad ON ad.id = sad.alarm_definition_id " + "LEFT OUTER JOIN sub_alarm_definition_dimension AS dim ON sad.id = dim.sub_alarm_definition_id %1$s " + "WHERE ad.tenant_id = :tenantId AND ad.deleted_at IS NULL %2$s %3$s) AS t " + "LEFT OUTER JOIN alarm_action AS aa ON t.id = aa.alarm_definition_id ORDER BY t.id, t.created_at";
    StringBuilder sbWhere = new StringBuilder();
    if (name != null) {
        sbWhere.append(" and ad.name = :name");
    }
    if (offset != null) {
        sbWhere.append(" and ad.id > :offset");
    }
    String limitPart = "";
    if (limit > 0) {
        limitPart = " limit :limit";
    }
    String sql = String.format(query, SubAlarmDefinitionQueries.buildJoinClauseFor(dimensions), sbWhere, limitPart);
    try {
        session = sessionFactory.openSession();
        final Query qAlarmDefinition = session.createSQLQuery(sql).setString("tenantId", tenantId).setResultTransformer(ALARM_DEF_RESULT_TRANSFORMER);
        if (name != null) {
            qAlarmDefinition.setString("name", name);
        }
        if (offset != null) {
            qAlarmDefinition.setString("offset", offset);
        }
        if (limit > 0) {
            qAlarmDefinition.setInteger("limit", limit + 1);
        }
        this.bindDimensionsToQuery(qAlarmDefinition, dimensions);
        final List<Map<?, ?>> alarmDefinitionDbList = qAlarmDefinition.list();
        resultSet = CollectionUtils.isEmpty(alarmDefinitionDbList) ? Lists.<AlarmDefinition>newArrayList() : this.createAlarmDefinitions(alarmDefinitionDbList);
    } finally {
        if (session != null) {
            session.close();
        }
    }
    return resultSet;
}
#method_after
@Override
@SuppressWarnings("unchecked")
public List<AlarmDefinition> find(String tenantId, String name, Map<String, String> dimensions, AlarmSeverity severity, List<String> sortBy, String offset, int limit) {
    logger.trace(ORM_LOG_MARKER, "find(...) entering...");
    if (sortBy != null && !sortBy.isEmpty()) {
        throw Exceptions.unprocessableEntity("Sort_by is not implemented for the hibernate database type");
    }
    if (severity != null) {
        throw Exceptions.unprocessableEntity("Severity is not implemented for the hibernate database type");
    }
    Session session = null;
    List<AlarmDefinition> resultSet = Lists.newArrayList();
    // TODO introduce criteria here, will make code significantly better
    String query = "  SELECT t.id, t.tenant_id, t.name, t.description, t.expression, t.severity, t.match_by, " + "t.actions_enabled, aa.alarm_state AS states, aa.action_id AS notificationIds " + "FROM (SELECT distinct ad.id, ad.tenant_id, ad.name, ad.description, ad.expression, " + "ad.severity, ad.match_by, ad.actions_enabled, ad.created_at, ad.updated_at, ad.deleted_at " + "FROM alarm_definition AS ad LEFT OUTER JOIN sub_alarm_definition AS sad ON ad.id = sad.alarm_definition_id " + "LEFT OUTER JOIN sub_alarm_definition_dimension AS dim ON sad.id = dim.sub_alarm_definition_id %1$s " + "WHERE ad.tenant_id = :tenantId AND ad.deleted_at IS NULL %2$s %3$s) AS t " + "LEFT OUTER JOIN alarm_action AS aa ON t.id = aa.alarm_definition_id ORDER BY t.id, t.created_at";
    StringBuilder sbWhere = new StringBuilder();
    if (name != null) {
        sbWhere.append(" and ad.name = :name");
    }
    if (offset != null) {
        sbWhere.append(" and ad.id > :offset");
    }
    String limitPart = "";
    if (limit > 0) {
        limitPart = " limit :limit";
    }
    String sql = String.format(query, SubAlarmDefinitionQueries.buildJoinClauseFor(dimensions), sbWhere, limitPart);
    try {
        session = sessionFactory.openSession();
        final Query qAlarmDefinition = session.createSQLQuery(sql).setString("tenantId", tenantId).setResultTransformer(ALARM_DEF_RESULT_TRANSFORMER);
        if (name != null) {
            qAlarmDefinition.setString("name", name);
        }
        if (offset != null) {
            qAlarmDefinition.setString("offset", offset);
        }
        if (limit > 0) {
            qAlarmDefinition.setInteger("limit", limit + 1);
        }
        this.bindDimensionsToQuery(qAlarmDefinition, dimensions);
        final List<Map<?, ?>> alarmDefinitionDbList = qAlarmDefinition.list();
        resultSet = CollectionUtils.isEmpty(alarmDefinitionDbList) ? Lists.<AlarmDefinition>newArrayList() : this.createAlarmDefinitions(alarmDefinitionDbList);
    } finally {
        if (session != null) {
            session.close();
        }
    }
    return resultSet;
}
#end_block

#method_before
private void bindDimensionsToQuery(Query query, Map<String, String> dimensions) {
    if (dimensions != null) {
        int i = 0;
        for (Iterator<Map.Entry<String, String>> it = dimensions.entrySet().iterator(); it.hasNext(); i++) {
            Map.Entry<String, String> entry = it.next();
            query.bind("dname" + i, entry.getKey());
            query.bind("dvalue" + i, entry.getValue());
        }
    }
}
#method_after
private void bindDimensionsToQuery(Query query, Map<String, String> dimensions) {
    if (dimensions != null) {
        int i = 0;
        for (Map.Entry<String, String> entry : dimensions.entrySet()) {
            query.bind("dname" + i, entry.getKey());
            query.bind("dvalue" + i, entry.getValue());
            i++;
        }
    }
}
#end_block

#method_before
@Override
public List<Alarm> find(String tenantId, String alarmDefId, String metricName, Map<String, String> metricDimensions, AlarmState state, String lifecycleState, String link, DateTime stateUpdatedStart, List<String> sortBy, String offset, int limit, boolean enforceLimit) {
    StringBuilder sbWhere = new StringBuilder("(select a.id " + "from alarm as a, alarm_definition as ad " + "where ad.id = a.alarm_definition_id " + "  and ad.deleted_at is null " + "  and ad.tenant_id = :tenantId ");
    if (alarmDefId != null) {
        sbWhere.append(" and ad.id = :alarmDefId ");
    }
    if (metricName != null) {
        sbWhere.append(" and a.id in (select distinct a.id from alarm as a " + "inner join alarm_metric as am on am.alarm_id = a.id " + "inner join metric_definition_dimensions as mdd " + "  on mdd.id = am.metric_definition_dimensions_id " + "inner join (select distinct id from metric_definition " + "            where name = :metricName) as md " + "  on md.id = mdd.metric_definition_id ");
        buildJoinClauseFor(metricDimensions, sbWhere);
        sbWhere.append(")");
    } else if (metricDimensions != null) {
        sbWhere.append(" and a.id in (select distinct a.id from alarm as a " + "inner join alarm_metric as am on am.alarm_id = a.id " + "inner join metric_definition_dimensions as mdd " + "  on mdd.id = am.metric_definition_dimensions_id ");
        buildJoinClauseFor(metricDimensions, sbWhere);
        sbWhere.append(")");
    }
    if (state != null) {
        sbWhere.append(" and a.state = :state");
    }
    if (lifecycleState != null) {
        sbWhere.append(" and a.lifecycle_state = :lifecycleState");
    }
    if (link != null) {
        sbWhere.append(" and a.link = :link");
    }
    if (stateUpdatedStart != null) {
        sbWhere.append(" and a.state_updated_at >= :stateUpdatedStart");
    }
    sbWhere.append(")");
    StringBuilder orderLimitOffsetClause = new StringBuilder();
    if (sortBy != null && !sortBy.isEmpty()) {
        orderLimitOffsetClause.append(" order by ");
        orderLimitOffsetClause.append(COMMA_JOINER.join(sortBy));
        // if alarm_id is not in the list, add it
        if (orderLimitOffsetClause.indexOf("alarm_id") == -1) {
            orderLimitOffsetClause.append(",alarm_id ASC");
        }
        orderLimitOffsetClause.append(' ');
    } else {
        orderLimitOffsetClause.append(" order by alarm_id ASC ");
    }
    if (enforceLimit && limit > 0) {
        orderLimitOffsetClause.append(" limit :limit");
    }
    if (offset != null) {
        orderLimitOffsetClause.append(" offset ");
        orderLimitOffsetClause.append(offset);
        orderLimitOffsetClause.append(' ');
    }
    String sql = String.format(FIND_ALARMS_SQL, sbWhere, orderLimitOffsetClause);
    try (Handle h = db.open()) {
        final Query<Map<String, Object>> q = h.createQuery(sql).bind("tenantId", tenantId);
        if (alarmDefId != null) {
            q.bind("alarmDefId", alarmDefId);
        }
        if (metricName != null) {
            q.bind("metricName", metricName);
        }
        if (state != null) {
            q.bind("state", state.name());
        }
        if (lifecycleState != null) {
            q.bind("lifecycleState", lifecycleState);
        }
        if (link != null) {
            q.bind("link", link);
        }
        if (stateUpdatedStart != null) {
            q.bind("stateUpdatedStart", stateUpdatedStart.toString());
        }
        if (enforceLimit && limit > 0) {
            q.bind("limit", limit + 1);
        }
        DimensionQueries.bindDimensionsToQuery(q, metricDimensions);
        final List<Map<String, Object>> rows = q.list();
        return createAlarms(tenantId, rows);
    }
}
#method_after
@Override
public List<Alarm> find(String tenantId, String alarmDefId, String metricName, Map<String, String> metricDimensions, AlarmState state, String lifecycleState, String link, DateTime stateUpdatedStart, List<String> sortBy, String offset, int limit, boolean enforceLimit) {
    StringBuilder sbWhere = new StringBuilder("(select a.id " + "from alarm as a, alarm_definition as ad " + "where ad.id = a.alarm_definition_id " + "  and ad.deleted_at is null " + "  and ad.tenant_id = :tenantId ");
    if (alarmDefId != null) {
        sbWhere.append(" and ad.id = :alarmDefId ");
    }
    if (metricName != null) {
        sbWhere.append(" and a.id in (select distinct a.id from alarm as a " + "inner join alarm_metric as am on am.alarm_id = a.id " + "inner join metric_definition_dimensions as mdd " + "  on mdd.id = am.metric_definition_dimensions_id " + "inner join (select distinct id from metric_definition " + "            where name = :metricName) as md " + "  on md.id = mdd.metric_definition_id ");
        buildJoinClauseFor(metricDimensions, sbWhere);
        sbWhere.append(")");
    } else if (metricDimensions != null) {
        sbWhere.append(" and a.id in (select distinct a.id from alarm as a " + "inner join alarm_metric as am on am.alarm_id = a.id " + "inner join metric_definition_dimensions as mdd " + "  on mdd.id = am.metric_definition_dimensions_id ");
        buildJoinClauseFor(metricDimensions, sbWhere);
        sbWhere.append(")");
    }
    if (state != null) {
        sbWhere.append(" and a.state = :state");
    }
    if (lifecycleState != null) {
        sbWhere.append(" and a.lifecycle_state = :lifecycleState");
    }
    if (link != null) {
        sbWhere.append(" and a.link = :link");
    }
    if (stateUpdatedStart != null) {
        sbWhere.append(" and a.state_updated_at >= :stateUpdatedStart");
    }
    StringBuilder orderClause = new StringBuilder();
    if (sortBy != null && !sortBy.isEmpty()) {
        // Convert friendly names to column names
        replaceFieldName(sortBy, "alarm_id", "a.id");
        replaceFieldName(sortBy, "alarm_definition_id", "ad.id");
        replaceFieldName(sortBy, "alarm_definition_name", "ad.name");
        replaceFieldName(sortBy, "created_timestamp", "a.created_at");
        replaceFieldName(sortBy, "updated_timestamp", "a.updated_at");
        replaceFieldName(sortBy, "state_updated_timestamp", "a.state_updated_at");
        orderClause.append(" order by ");
        orderClause.append(COMMA_JOINER.join(sortBy));
        // if alarm_id is not in the list, add it
        if (orderClause.indexOf("a.id") == -1) {
            orderClause.append(",a.id ASC");
        }
        orderClause.append(' ');
    } else {
        orderClause.append(" order by a.id ASC ");
    }
    sbWhere.append(orderClause);
    if (enforceLimit && limit > 0) {
        sbWhere.append(" limit :limit");
    }
    if (offset != null) {
        sbWhere.append(" offset ");
        sbWhere.append(offset);
        sbWhere.append(' ');
    }
    sbWhere.append(")");
    String sql = String.format(FIND_ALARMS_SQL, sbWhere, orderClause);
    try (Handle h = db.open()) {
        final Query<Map<String, Object>> q = h.createQuery(sql).bind("tenantId", tenantId);
        if (alarmDefId != null) {
            q.bind("alarmDefId", alarmDefId);
        }
        if (metricName != null) {
            q.bind("metricName", metricName);
        }
        if (state != null) {
            q.bind("state", state.name());
        }
        if (lifecycleState != null) {
            q.bind("lifecycleState", lifecycleState);
        }
        if (link != null) {
            q.bind("link", link);
        }
        if (stateUpdatedStart != null) {
            q.bind("stateUpdatedStart", stateUpdatedStart.toString());
        }
        if (enforceLimit && limit > 0) {
            q.bind("limit", limit + 1);
        }
        DimensionQueries.bindDimensionsToQuery(q, metricDimensions);
        final List<Map<String, Object>> rows = q.list();
        return createAlarms(tenantId, rows);
    }
}
#end_block

#method_before
@Override
public void run() {
    try {
        storletLogger_.emitLog("About to invoke storlet");
        storlet_.invoke(inStreams_, outStreams_, executionParams_, storletLogger_);
        storletLogger_.emitLog("Storlet invocation done");
        synchronized (taskIdToTask_) {
            taskIdToTask_.remove(taskId_);
        }
    } catch (StorletException e) {
        storletLogger_.emitLog(e.getMessage());
    } finally {
        storletLogger_.Flush();
        storletLogger_.close();
    }
}
#method_after
@Override
public void run() {
    try {
        storletLogger_.emitLog("About to invoke storlet");
        storlet_.invoke(inStreams_, outStreams_, executionParams_, storletLogger_);
        storletLogger_.emitLog("Storlet invocation done");
        synchronized (taskIdToTask_) {
            taskIdToTask_.remove(taskId_);
        }
    } catch (StorletException e) {
        storletLogger_.emitLog(e.getMessage());
    } finally {
        storletLogger_.close();
        // We make sure all streams are closed
        closeStorletStreams();
    }
}
#end_block

#method_before
public void close() {
    try {
        stream.close();
    } catch (IOException e) {
    }
}
#method_after
public void close() {
    Flush();
    try {
        stream.close();
    } catch (IOException e) {
    }
}
#end_block

#method_before
@Override
public boolean equals(Object obj) {
    if (this == obj) {
        return true;
    }
    if (!super.equals(obj)) {
        return false;
    }
    if (getClass() != obj.getClass()) {
        return false;
    }
    Alarm other = (Alarm) obj;
    if (state != other.state) {
        return false;
    }
    if (!compareObjects(alarmDefinitionId, other.alarmDefinitionId)) {
        return false;
    }
    if (!compareObjects(subAlarms, other.subAlarms)) {
        return false;
    }
    if (!compareObjects(stateChangeReason, other.stateChangeReason)) {
        return false;
    }
    if (!compareObjects(alarmedMetrics, other.alarmedMetrics)) {
        return false;
    }
    return true;
}
#method_after
@Override
public boolean equals(Object obj) {
    if (this == obj) {
        return true;
    }
    if (!super.equals(obj)) {
        return false;
    }
    if (getClass() != obj.getClass()) {
        return false;
    }
    Alarm other = (Alarm) obj;
    if (state != other.state) {
        return false;
    }
    if (!compareObjects(link, other.link)) {
        return false;
    }
    if (!compareObjects(lifecycleState, other.lifecycleState)) {
        return false;
    }
    if (!compareObjects(alarmDefinitionId, other.alarmDefinitionId)) {
        return false;
    }
    if (!compareObjects(subAlarms, other.subAlarms)) {
        return false;
    }
    if (!compareObjects(stateChangeReason, other.stateChangeReason)) {
        return false;
    }
    if (!compareObjects(alarmedMetrics, other.alarmedMetrics)) {
        return false;
    }
    return true;
}
#end_block

#method_before
@Override
public int hashCode() {
    final int prime = 31;
    int result = super.hashCode();
    result = prime * result + ((state == null) ? 0 : state.hashCode());
    result = prime * result + ((subAlarms == null) ? 0 : subAlarms.hashCode());
    result = prime * result + ((alarmDefinitionId == null) ? 0 : alarmDefinitionId.hashCode());
    result = prime * result + ((stateChangeReason == null) ? 0 : stateChangeReason.hashCode());
    result = prime * result + ((alarmedMetrics == null) ? 0 : alarmedMetrics.hashCode());
    return result;
}
#method_after
@Override
public int hashCode() {
    final int prime = 31;
    int result = super.hashCode();
    result = prime * result + ((state == null) ? 0 : state.hashCode());
    result = prime * result + ((link == null) ? 0 : link.hashCode());
    result = prime * result + ((lifecycleState == null) ? 0 : lifecycleState.hashCode());
    result = prime * result + ((subAlarms == null) ? 0 : subAlarms.hashCode());
    result = prime * result + ((alarmDefinitionId == null) ? 0 : alarmDefinitionId.hashCode());
    result = prime * result + ((stateChangeReason == null) ? 0 : stateChangeReason.hashCode());
    result = prime * result + ((alarmedMetrics == null) ? 0 : alarmedMetrics.hashCode());
    return result;
}
#end_block

#method_before
@Override
public int hashCode() {
    final int prime = 31;
    int result = 1;
    result = prime * result + (actionsEnabled ? 1231 : 1237);
    result = prime * result + ((alarmDefinitionId == null) ? 0 : alarmDefinitionId.hashCode());
    result = prime * result + ((alarmDescription == null) ? 0 : alarmDescription.hashCode());
    result = prime * result + ((severity == null) ? 0 : severity.hashCode());
    result = prime * result + ((alarmId == null) ? 0 : alarmId.hashCode());
    result = prime * result + ((alarmName == null) ? 0 : alarmName.hashCode());
    result = prime * result + ((metrics == null) ? 0 : metrics.hashCode());
    result = prime * result + ((newState == null) ? 0 : newState.hashCode());
    result = prime * result + ((oldState == null) ? 0 : oldState.hashCode());
    result = prime * result + ((stateChangeReason == null) ? 0 : stateChangeReason.hashCode());
    result = prime * result + ((tenantId == null) ? 0 : tenantId.hashCode());
    result = prime * result + ((subAlarms == null) ? 0 : subAlarms.hashCode());
    result = prime * result + (int) (timestamp ^ (timestamp >>> 32));
    return result;
}
#method_after
@Override
public int hashCode() {
    final int prime = 31;
    int result = 1;
    result = prime * result + (actionsEnabled ? 1231 : 1237);
    result = prime * result + ((alarmDefinitionId == null) ? 0 : alarmDefinitionId.hashCode());
    result = prime * result + ((alarmDescription == null) ? 0 : alarmDescription.hashCode());
    result = prime * result + ((severity == null) ? 0 : severity.hashCode());
    result = prime * result + ((link == null) ? 0 : link.hashCode());
    result = prime * result + ((lifecycleState == null) ? 0 : lifecycleState.hashCode());
    result = prime * result + ((alarmId == null) ? 0 : alarmId.hashCode());
    result = prime * result + ((alarmName == null) ? 0 : alarmName.hashCode());
    result = prime * result + ((metrics == null) ? 0 : metrics.hashCode());
    result = prime * result + ((newState == null) ? 0 : newState.hashCode());
    result = prime * result + ((oldState == null) ? 0 : oldState.hashCode());
    result = prime * result + ((stateChangeReason == null) ? 0 : stateChangeReason.hashCode());
    result = prime * result + ((tenantId == null) ? 0 : tenantId.hashCode());
    result = prime * result + ((subAlarms == null) ? 0 : subAlarms.hashCode());
    result = prime * result + (int) (timestamp ^ (timestamp >>> 32));
    return result;
}
#end_block

#method_before
private void updateAlarmDefinition(final AlarmDefinitionUpdatedEvent event) {
    final AlarmDefinition alarmDefinition = alarmDefinitionCache.get(event.alarmDefinitionId);
    if (alarmDefinition != null) {
        logger.debug("Updating AlarmDefinition {}", event.alarmDefinitionId);
        alarmDefinition.setName(event.alarmName);
        alarmDefinition.setDescription(event.alarmDescription);
        alarmDefinition.setActionsEnabled(event.alarmActionsEnabled);
        alarmDefinition.setExpression(event.alarmExpression);
        alarmDefinition.setSeverity(event.severity);
        final List<String> newMatchBy;
        if (event.matchBy == null) {
            // The API can send NULL which means empty list
            newMatchBy = new ArrayList<>(0);
        } else {
            newMatchBy = event.matchBy;
        }
        if (!alarmDefinition.getMatchBy().equals(newMatchBy)) {
            logger.error("AlarmDefinition {}: match-by Er, was {} now {}", event.alarmDefinitionId, alarmDefinition.getMatchBy(), newMatchBy);
        }
        // Should never change
        alarmDefinition.setMatchBy(newMatchBy);
        for (Map.Entry<String, AlarmSubExpression> entry : event.changedSubExpressions.entrySet()) {
            if (!alarmDefinition.updateSubExpression(entry.getKey(), entry.getValue())) {
                logger.error("AlarmDefinition {}: Did not finding matching SubAlarmExpression id={} SubAlarmExpression{}", event.alarmDefinitionId, entry.getKey(), entry.getValue());
            }
        }
    }
}
#method_after
private void updateAlarmDefinition(final AlarmDefinitionUpdatedEvent event) {
    final AlarmDefinition alarmDefinition = alarmDefinitionCache.get(event.alarmDefinitionId);
    if (alarmDefinition != null) {
        logger.debug("Updating AlarmDefinition {}", event.alarmDefinitionId);
        alarmDefinition.setName(event.alarmName);
        alarmDefinition.setDescription(event.alarmDescription);
        alarmDefinition.setActionsEnabled(event.alarmActionsEnabled);
        alarmDefinition.setExpression(event.alarmExpression);
        alarmDefinition.setSeverity(event.severity);
        final List<String> newMatchBy;
        if (event.matchBy == null) {
            // The API can send NULL which means empty list
            newMatchBy = new ArrayList<>(0);
        } else {
            newMatchBy = event.matchBy;
        }
        if (!alarmDefinition.getMatchBy().equals(newMatchBy)) {
            logger.error("AlarmDefinition {}: match-by changed, was {} now {}", event.alarmDefinitionId, alarmDefinition.getMatchBy(), newMatchBy);
        }
        // Should never change
        alarmDefinition.setMatchBy(newMatchBy);
        for (Map.Entry<String, AlarmSubExpression> entry : event.changedSubExpressions.entrySet()) {
            if (!alarmDefinition.updateSubExpression(entry.getKey(), entry.getValue())) {
                logger.error("AlarmDefinition {}: Did not finding matching SubAlarmExpression id={} SubAlarmExpression{}", event.alarmDefinitionId, entry.getKey(), entry.getValue());
            }
        }
    }
}
#end_block

#method_before
@GET
@Timed
@Produces(MediaType.APPLICATION_JSON)
public Object list(@Context UriInfo uriInfo, @HeaderParam("X-Tenant-Id") String tenantId, @QueryParam("name") String name, @QueryParam("dimensions") String dimensionsStr, @QueryParam("sort_by") String sortByStr, @QueryParam("offset") String offset, @QueryParam("limit") String limit) throws UnsupportedEncodingException {
    Map<String, String> dimensions = Strings.isNullOrEmpty(dimensionsStr) ? null : Validation.parseAndValidateDimensions(dimensionsStr);
    List<String> sortByList = parseAndValidateSortBy(sortByStr);
    if (!Strings.isNullOrEmpty(offset)) {
        Validation.parseAndValidateNumber(offset, "offset");
    }
    final int paging_limit = this.persistUtils.getLimit(limit);
    final List<AlarmDefinition> resources = repo.find(tenantId, name, dimensions, sortByList, offset, paging_limit);
    return Links.paginateAlarming(paging_limit, Links.hydrate(resources, uriInfo), uriInfo);
}
#method_after
@GET
@Timed
@Produces(MediaType.APPLICATION_JSON)
public Object list(@Context UriInfo uriInfo, @HeaderParam("X-Tenant-Id") String tenantId, @QueryParam("name") String name, @QueryParam("dimensions") String dimensionsStr, @QueryParam("sort_by") String sortByStr, @QueryParam("offset") String offset, @QueryParam("limit") String limit) throws UnsupportedEncodingException {
    Map<String, String> dimensions = Strings.isNullOrEmpty(dimensionsStr) ? null : Validation.parseAndValidateDimensions(dimensionsStr);
    List<String> sortByList = Validation.parseAndValidateSortBy(sortByStr, ALLOWED_SORT_BY);
    if (!Strings.isNullOrEmpty(offset)) {
        Validation.parseAndValidateNumber(offset, "offset");
    }
    final int paging_limit = this.persistUtils.getLimit(limit);
    final List<AlarmDefinition> resources = repo.find(tenantId, name, dimensions, sortByList, offset, paging_limit);
    return Links.paginateAlarming(paging_limit, Links.hydrate(resources, uriInfo), uriInfo);
}
#end_block

#method_before
@Override
public List<Alarm> find(String tenantId, String alarmDefId, String metricName, Map<String, String> metricDimensions, AlarmState state, String lifecycleState, String link, DateTime stateUpdatedStart, List<String> sortBy, String offset, int limit, boolean enforceLimit) {
    StringBuilder sbWhere = new StringBuilder("(select a.id " + "from alarm as a, alarm_definition as ad " + "where ad.id = a.alarm_definition_id " + "  and ad.deleted_at is null " + "  and ad.tenant_id = :tenantId ");
    if (alarmDefId != null) {
        sbWhere.append(" and ad.id = :alarmDefId ");
    }
    if (metricName != null) {
        sbWhere.append(" and a.id in (select distinct a.id from alarm as a " + "inner join alarm_metric as am on am.alarm_id = a.id " + "inner join metric_definition_dimensions as mdd " + "  on mdd.id = am.metric_definition_dimensions_id " + "inner join (select distinct id from metric_definition " + "            where name = :metricName) as md " + "  on md.id = mdd.metric_definition_id ");
        buildJoinClauseFor(metricDimensions, sbWhere);
        sbWhere.append(")");
    } else if (metricDimensions != null) {
        sbWhere.append(" and a.id in (select distinct a.id from alarm as a " + "inner join alarm_metric as am on am.alarm_id = a.id " + "inner join metric_definition_dimensions as mdd " + "  on mdd.id = am.metric_definition_dimensions_id ");
        buildJoinClauseFor(metricDimensions, sbWhere);
        sbWhere.append(")");
    }
    if (state != null) {
        sbWhere.append(" and a.state = :state");
    }
    if (lifecycleState != null) {
        sbWhere.append(" and a.lifecycle_state = :lifecycleState");
    }
    if (link != null) {
        sbWhere.append(" and a.link = :link");
    }
    if (stateUpdatedStart != null) {
        sbWhere.append(" and a.state_updated_at >= :stateUpdatedStart");
    }
    StringBuilder sortByClause = new StringBuilder();
    if (sortBy != null && !sortBy.isEmpty()) {
        sortByClause.append(" order by ");
        sortByClause.append(COMMA_JOINER.join(sortBy));
        if (!sortBy.contains("alarm_id")) {
            sortByClause.append(",alarm_id ASC");
        }
        sortByClause.append(' ');
    } else {
        sortByClause.append(" order by alarm_id ASC ");
    }
    if (enforceLimit && limit > 0) {
        sbWhere.append(" limit :limit");
    }
    if (offset != null) {
        sbWhere.append(" offset ");
        sbWhere.append(offset);
        sbWhere.append(' ');
    }
    sbWhere.append(")");
    String sql = String.format(FIND_ALARMS_SQL, sbWhere, sortByClause);
    try (Handle h = db.open()) {
        final Query<Map<String, Object>> q = h.createQuery(sql).bind("tenantId", tenantId);
        if (alarmDefId != null) {
            q.bind("alarmDefId", alarmDefId);
        }
        if (metricName != null) {
            q.bind("metricName", metricName);
        }
        if (state != null) {
            q.bind("state", state.name());
        }
        if (lifecycleState != null) {
            q.bind("lifecycleState", lifecycleState);
        }
        if (link != null) {
            q.bind("link", link);
        }
        if (stateUpdatedStart != null) {
            q.bind("stateUpdatedStart", stateUpdatedStart.toString());
        }
        if (enforceLimit && limit > 0) {
            q.bind("limit", limit + 1);
        }
        DimensionQueries.bindDimensionsToQuery(q, metricDimensions);
        final List<Map<String, Object>> rows = q.list();
        return createAlarms(tenantId, rows);
    }
}
#method_after
@Override
public List<Alarm> find(String tenantId, String alarmDefId, String metricName, Map<String, String> metricDimensions, AlarmState state, String lifecycleState, String link, DateTime stateUpdatedStart, List<String> sortBy, String offset, int limit, boolean enforceLimit) {
    StringBuilder sbWhere = new StringBuilder("(select a.id " + "from alarm as a, alarm_definition as ad " + "where ad.id = a.alarm_definition_id " + "  and ad.deleted_at is null " + "  and ad.tenant_id = :tenantId ");
    if (alarmDefId != null) {
        sbWhere.append(" and ad.id = :alarmDefId ");
    }
    if (metricName != null) {
        sbWhere.append(" and a.id in (select distinct a.id from alarm as a " + "inner join alarm_metric as am on am.alarm_id = a.id " + "inner join metric_definition_dimensions as mdd " + "  on mdd.id = am.metric_definition_dimensions_id " + "inner join (select distinct id from metric_definition " + "            where name = :metricName) as md " + "  on md.id = mdd.metric_definition_id ");
        buildJoinClauseFor(metricDimensions, sbWhere);
        sbWhere.append(")");
    } else if (metricDimensions != null) {
        sbWhere.append(" and a.id in (select distinct a.id from alarm as a " + "inner join alarm_metric as am on am.alarm_id = a.id " + "inner join metric_definition_dimensions as mdd " + "  on mdd.id = am.metric_definition_dimensions_id ");
        buildJoinClauseFor(metricDimensions, sbWhere);
        sbWhere.append(")");
    }
    if (state != null) {
        sbWhere.append(" and a.state = :state");
    }
    if (lifecycleState != null) {
        sbWhere.append(" and a.lifecycle_state = :lifecycleState");
    }
    if (link != null) {
        sbWhere.append(" and a.link = :link");
    }
    if (stateUpdatedStart != null) {
        sbWhere.append(" and a.state_updated_at >= :stateUpdatedStart");
    }
    StringBuilder sortByClause = new StringBuilder();
    if (sortBy != null && !sortBy.isEmpty()) {
        sortByClause.append(" order by ");
        sortByClause.append(COMMA_JOINER.join(sortBy));
        // if alarm_id is not in the list, add it
        if (sortByClause.indexOf("alarm_id") == -1) {
            sortByClause.append(",alarm_id ASC");
        }
        sortByClause.append(' ');
    } else {
        sortByClause.append(" order by alarm_id ASC ");
    }
    if (enforceLimit && limit > 0) {
        sbWhere.append(" limit :limit");
    }
    if (offset != null) {
        sbWhere.append(" offset ");
        sbWhere.append(offset);
        sbWhere.append(' ');
    }
    sbWhere.append(")");
    String sql = String.format(FIND_ALARMS_SQL, sbWhere, sortByClause);
    try (Handle h = db.open()) {
        final Query<Map<String, Object>> q = h.createQuery(sql).bind("tenantId", tenantId);
        if (alarmDefId != null) {
            q.bind("alarmDefId", alarmDefId);
        }
        if (metricName != null) {
            q.bind("metricName", metricName);
        }
        if (state != null) {
            q.bind("state", state.name());
        }
        if (lifecycleState != null) {
            q.bind("lifecycleState", lifecycleState);
        }
        if (link != null) {
            q.bind("link", link);
        }
        if (stateUpdatedStart != null) {
            q.bind("stateUpdatedStart", stateUpdatedStart.toString());
        }
        if (enforceLimit && limit > 0) {
            q.bind("limit", limit + 1);
        }
        DimensionQueries.bindDimensionsToQuery(q, metricDimensions);
        final List<Map<String, Object>> rows = q.list();
        return createAlarms(tenantId, rows);
    }
}
#end_block

#method_before
@SuppressWarnings("unchecked")
@Override
public List<AlarmDefinition> find(String tenantId, String name, Map<String, String> dimensions, List<String> sortBy, String offset, int limit) {
    try (Handle h = db.open()) {
        String query = "  SELECT t.id, t.tenant_id, t.name, t.description, t.expression, t.severity, t.match_by," + "     t.actions_enabled, t.created_at, t.updated_at, t.deleted_at, " + "     GROUP_CONCAT(aa.alarm_state) AS states, " + "     GROUP_CONCAT(aa.action_id) AS notificationIds " + "FROM (SELECT distinct ad.id, ad.tenant_id, ad.name, ad.description, ad.expression," + "        ad.severity, ad.match_by, ad.actions_enabled, ad.created_at, " + "        ad.updated_at, ad.deleted_at " + "      FROM alarm_definition AS ad " + "      LEFT OUTER JOIN sub_alarm_definition AS sad ON ad.id = sad.alarm_definition_id " + "      LEFT OUTER JOIN sub_alarm_definition_dimension AS dim ON sad.id = dim.sub_alarm_definition_id %1$s " + "      WHERE ad.tenant_id = :tenantId AND ad.deleted_at IS NULL %2$s) AS t " + "LEFT OUTER JOIN alarm_action AS aa ON t.id = aa.alarm_definition_id " + "GROUP BY t.id %3$s %4$s %5$s";
        StringBuilder sbWhere = new StringBuilder();
        if (name != null) {
            sbWhere.append(" and ad.name = :name");
        }
        String orderByPart = "";
        if (sortBy != null && !sortBy.isEmpty()) {
            orderByPart = " order by " + COMMA_JOINER.join(sortBy);
            if (!sortBy.contains("id")) {
                orderByPart = orderByPart + ",id";
            }
        } else {
            orderByPart = " order by id ";
        }
        String limitPart = "";
        if (limit > 0) {
            limitPart = " limit :limit";
        }
        String offsetPart = "";
        if (offset != null) {
            offsetPart = " offset " + offset + ' ';
        }
        String sql = String.format(query, SubAlarmDefinitionQueries.buildJoinClauseFor(dimensions), sbWhere, orderByPart, limitPart, offsetPart);
        Query<?> q = h.createQuery(sql);
        q.bind("tenantId", tenantId);
        if (name != null) {
            q.bind("name", name);
        }
        if (limit > 0) {
            q.bind("limit", limit + 1);
        }
        q.registerMapper(new AlarmDefinitionMapper());
        q = q.mapTo(AlarmDefinition.class);
        DimensionQueries.bindDimensionsToQuery(q, dimensions);
        List<AlarmDefinition> resultSet = (List<AlarmDefinition>) q.list();
        return resultSet;
    }
}
#method_after
@SuppressWarnings("unchecked")
@Override
public List<AlarmDefinition> find(String tenantId, String name, Map<String, String> dimensions, List<String> sortBy, String offset, int limit) {
    try (Handle h = db.open()) {
        String query = "  SELECT t.id, t.tenant_id, t.name, t.description, t.expression, t.severity, t.match_by," + "     t.actions_enabled, t.created_at, t.updated_at, t.deleted_at, " + "     GROUP_CONCAT(aa.alarm_state) AS states, " + "     GROUP_CONCAT(aa.action_id) AS notificationIds " + "FROM (SELECT distinct ad.id, ad.tenant_id, ad.name, ad.description, ad.expression," + "        ad.severity, ad.match_by, ad.actions_enabled, ad.created_at, " + "        ad.updated_at, ad.deleted_at " + "      FROM alarm_definition AS ad " + "      LEFT OUTER JOIN sub_alarm_definition AS sad ON ad.id = sad.alarm_definition_id " + "      LEFT OUTER JOIN sub_alarm_definition_dimension AS dim ON sad.id = dim.sub_alarm_definition_id %1$s " + "      WHERE ad.tenant_id = :tenantId AND ad.deleted_at IS NULL %2$s) AS t " + "LEFT OUTER JOIN alarm_action AS aa ON t.id = aa.alarm_definition_id " + "GROUP BY t.id %3$s %4$s %5$s";
        StringBuilder sbWhere = new StringBuilder();
        if (name != null) {
            sbWhere.append(" and ad.name = :name");
        }
        String orderByPart = "";
        if (sortBy != null && !sortBy.isEmpty()) {
            orderByPart = " order by " + COMMA_JOINER.join(sortBy);
            if (!orderByPart.contains("id")) {
                orderByPart = orderByPart + ",id";
            }
        } else {
            orderByPart = " order by id ";
        }
        String limitPart = "";
        if (limit > 0) {
            limitPart = " limit :limit";
        }
        String offsetPart = "";
        if (offset != null) {
            offsetPart = " offset " + offset + ' ';
        }
        String sql = String.format(query, SubAlarmDefinitionQueries.buildJoinClauseFor(dimensions), sbWhere, orderByPart, limitPart, offsetPart);
        Query<?> q = h.createQuery(sql);
        q.bind("tenantId", tenantId);
        if (name != null) {
            q.bind("name", name);
        }
        if (limit > 0) {
            q.bind("limit", limit + 1);
        }
        q.registerMapper(new AlarmDefinitionMapper());
        q = q.mapTo(AlarmDefinition.class);
        DimensionQueries.bindDimensionsToQuery(q, dimensions);
        List<AlarmDefinition> resultSet = (List<AlarmDefinition>) q.list();
        return resultSet;
    }
}
#end_block

#method_before
@BeforeMethod
protected void beforeMethod() {
    handle.execute("SET foreign_key_checks = 0;");
    handle.execute("truncate table alarm");
    handle.execute("truncate table sub_alarm");
    handle.execute("truncate table alarm_action");
    handle.execute("truncate table alarm_definition");
    handle.execute("truncate table alarm_metric");
    handle.execute("truncate table metric_definition");
    handle.execute("truncate table metric_definition_dimensions");
    handle.execute("truncate table metric_dimension");
    DateTime timestamp1 = ISO_8601_FORMATTER.parseDateTime("2015-03-14T09:26:53").withZoneRetainFields(DateTimeZone.forID("UTC"));
    DateTime timestamp2 = ISO_8601_FORMATTER.parseDateTime("2015-03-14T09:26:54").withZoneRetainFields(DateTimeZone.forID("UTC"));
    DateTime timestamp3 = ISO_8601_FORMATTER.parseDateTime("2015-03-14T09:26:55").withZoneRetainFields(DateTimeZone.forID("UTC"));
    handle.execute("insert into alarm_definition (id, tenant_id, name, severity, expression, match_by, actions_enabled, created_at, updated_at, deleted_at) " + "values ('1', 'bob', '90% CPU', 'LOW', 'avg(cpu.idle_perc{flavor_id=777, image_id=888, device=1}) > 10', 'flavor_id,image_id', 1, NOW(), NOW(), NULL)");
    handle.execute("insert into alarm (id, alarm_definition_id, state, lifecycle_state, link, created_at, updated_at, state_updated_at) values ('1', '1', 'OK', 'OPEN', 'http://somesite.com/this-alarm-info', '" + timestamp1.toString().replace('Z', ' ') + "', '" + timestamp1.toString().replace('Z', ' ') + "', '" + timestamp1.toString().replace('Z', ' ') + "')");
    handle.execute("insert into alarm (id, alarm_definition_id, state, lifecycle_state, created_at, updated_at, state_updated_at) values ('2', '1', 'UNDETERMINED', 'OPEN', '" + timestamp2.toString().replace('Z', ' ') + "', '" + timestamp2.toString().replace('Z', ' ') + "', '" + timestamp2.toString().replace('Z', ' ') + "')");
    handle.execute("insert into alarm (id, alarm_definition_id, state, link, created_at, updated_at, state_updated_at) values ('3', '1', 'ALARM', 'http://somesite.com/this-alarm-info', '" + timestamp3.toString().replace('Z', ' ') + "', '" + timestamp3.toString().replace('Z', ' ') + "', '" + timestamp3.toString().replace('Z', ' ') + "')");
    long subAlarmId = 42;
    for (int alarmId = 1; alarmId <= 3; alarmId++) {
        handle.execute("insert into sub_alarm (id, alarm_id, expression, created_at, updated_at) values ('" + String.valueOf(subAlarmId++) + "', '" + alarmId + "', 'avg(cpu.idle_perc{flavor_id=777, image_id=888, device=1}) > 10', NOW(), NOW())");
    }
    handle.execute("insert into alarm_metric (alarm_id, metric_definition_dimensions_id) values ('1', 11)");
    handle.execute("insert into alarm_metric (alarm_id, metric_definition_dimensions_id) values ('1', 22)");
    handle.execute("insert into alarm_metric (alarm_id, metric_definition_dimensions_id) values ('2', 11)");
    handle.execute("insert into alarm_metric (alarm_id, metric_definition_dimensions_id) values ('3', 22)");
    handle.execute("insert into metric_definition (id, name, tenant_id, region) values (1, 'cpu.idle_perc', 'bob', 'west')");
    handle.execute("insert into metric_definition_dimensions (id, metric_definition_id, metric_dimension_set_id) values (11, 1, 1)");
    handle.execute("insert into metric_definition_dimensions (id, metric_definition_id, metric_dimension_set_id) values (22, 1, 2)");
    handle.execute("insert into metric_dimension (dimension_set_id, name, value) values (1, 'instance_id', '123')");
    handle.execute("insert into metric_dimension (dimension_set_id, name, value) values (1, 'service', 'monitoring')");
    handle.execute("insert into metric_dimension (dimension_set_id, name, value) values (2, 'flavor_id', '222')");
    alarm1 = new Alarm("1", "1", "90% CPU", "LOW", buildAlarmMetrics(buildMetricDefinition("cpu.idle_perc", "instance_id", "123", "service", "monitoring"), buildMetricDefinition("cpu.idle_perc", "flavor_id", "222")), AlarmState.OK, "OPEN", "http://somesite.com/this-alarm-info", timestamp1, timestamp1, timestamp1);
    alarm2 = new Alarm("2", "1", "90% CPU", "LOW", buildAlarmMetrics(buildMetricDefinition("cpu.idle_perc", "instance_id", "123", "service", "monitoring")), AlarmState.UNDETERMINED, "OPEN", null, timestamp2, timestamp2, timestamp2);
    alarm3 = new Alarm("3", "1", "90% CPU", "LOW", buildAlarmMetrics(buildMetricDefinition("cpu.idle_perc", "flavor_id", "222")), AlarmState.ALARM, null, "http://somesite.com/this-alarm-info", timestamp3, timestamp3, timestamp3);
    DateTime timestamp4 = ISO_8601_FORMATTER.parseDateTime("2015-03-15T09:26:53Z");
    handle.execute("insert into alarm_definition (id, tenant_id, name, severity, expression, match_by, actions_enabled, created_at, updated_at, deleted_at) " + "values ('234', 'bob', '50% CPU', 'LOW', 'avg(cpu.sys_mem{service=monitoring}) > 20 and avg(cpu.idle_perc{service=monitoring}) < 10', 'hostname,region', 1, NOW(), NOW(), NULL)");
    handle.execute("insert into alarm (id, alarm_definition_id, state, created_at, updated_at, state_updated_at) values ('234111', '234', 'UNDETERMINED', '" + timestamp4.toString().replace('Z', ' ') + "', '" + timestamp4.toString().replace('Z', ' ') + "', '" + timestamp4.toString().replace('Z', ' ') + "')");
    handle.execute("insert into sub_alarm (id, alarm_id, expression, created_at, updated_at) values ('4343', '234111', 'avg(cpu.sys_mem{service=monitoring}) > 20', NOW(), NOW())");
    handle.execute("insert into sub_alarm (id, alarm_id, expression, created_at, updated_at) values ('4242', '234111', 'avg(cpu.idle_perc{service=monitoring}) < 10', NOW(), NOW())");
    handle.execute("insert into alarm_metric (alarm_id, metric_definition_dimensions_id) values ('234111', 31)");
    handle.execute("insert into alarm_metric (alarm_id, metric_definition_dimensions_id) values ('234111', 32)");
    handle.execute("insert into metric_definition (id, name, tenant_id, region) values (111, 'cpu.sys_mem', 'bob', 'west')");
    handle.execute("insert into metric_definition (id, name, tenant_id, region) values (112, 'cpu.idle_perc', 'bob', 'west')");
    handle.execute("insert into metric_definition_dimensions (id, metric_definition_id, metric_dimension_set_id) values (31, 111, 21)");
    handle.execute("insert into metric_definition_dimensions (id, metric_definition_id, metric_dimension_set_id) values (32, 112, 22)");
    handle.execute("insert into metric_dimension (dimension_set_id, name, value) values (21, 'service', 'monitoring')");
    handle.execute("insert into metric_dimension (dimension_set_id, name, value) values (22, 'service', 'monitoring')");
    handle.execute("insert into metric_dimension (dimension_set_id, name, value) values (21, 'hostname', 'roland')");
    handle.execute("insert into metric_dimension (dimension_set_id, name, value) values (22, 'hostname', 'roland')");
    handle.execute("insert into metric_dimension (dimension_set_id, name, value) values (21, 'region', 'colorado')");
    handle.execute("insert into metric_dimension (dimension_set_id, name, value) values (22, 'region', 'colorado')");
    handle.execute("insert into metric_dimension (dimension_set_id, name, value) values (22, 'extra', 'vivi')");
    compoundAlarm = new Alarm("234111", "234", "50% CPU", "LOW", buildAlarmMetrics(buildMetricDefinition("cpu.sys_mem", "service", "monitoring", "hostname", "roland", "region", "colorado"), buildMetricDefinition("cpu.idle_perc", "service", "monitoring", "hostname", "roland", "region", "colorado", "extra", "vivi")), AlarmState.UNDETERMINED, null, null, timestamp4, timestamp4, timestamp4);
}
#method_after
@BeforeMethod
protected void beforeMethod() {
    handle.execute("SET foreign_key_checks = 0;");
    handle.execute("truncate table alarm");
    handle.execute("truncate table sub_alarm");
    handle.execute("truncate table alarm_action");
    handle.execute("truncate table alarm_definition");
    handle.execute("truncate table alarm_metric");
    handle.execute("truncate table metric_definition");
    handle.execute("truncate table metric_definition_dimensions");
    handle.execute("truncate table metric_dimension");
    DateTime timestamp1 = ISO_8601_FORMATTER.parseDateTime("2015-03-14T09:26:53").withZoneRetainFields(DateTimeZone.forID("UTC"));
    DateTime timestamp2 = ISO_8601_FORMATTER.parseDateTime("2015-03-14T09:26:54").withZoneRetainFields(DateTimeZone.forID("UTC"));
    DateTime timestamp3 = ISO_8601_FORMATTER.parseDateTime("2015-03-14T09:26:55").withZoneRetainFields(DateTimeZone.forID("UTC"));
    handle.execute("insert into alarm_definition (id, tenant_id, name, severity, expression, match_by, actions_enabled, created_at, updated_at, deleted_at) " + "values ('1', 'bob', '90% CPU', 'LOW', 'avg(cpu.idle_perc{flavor_id=777, image_id=888, device=1}) > 10', 'flavor_id,image_id', 1, NOW(), NOW(), NULL)");
    handle.execute("insert into alarm (id, alarm_definition_id, state, lifecycle_state, link, created_at, updated_at, state_updated_at) values ('1', '1', 'OK', 'OPEN', 'http://somesite.com/this-alarm-info', '" + timestamp1.toString().replace('Z', ' ') + "', '" + timestamp1.toString().replace('Z', ' ') + "', '" + timestamp1.toString().replace('Z', ' ') + "')");
    handle.execute("insert into alarm (id, alarm_definition_id, state, lifecycle_state, created_at, updated_at, state_updated_at) values ('2', '1', 'UNDETERMINED', 'OPEN', '" + timestamp2.toString().replace('Z', ' ') + "', '" + timestamp2.toString().replace('Z', ' ') + "', '" + timestamp2.toString().replace('Z', ' ') + "')");
    handle.execute("insert into alarm (id, alarm_definition_id, state, link, created_at, updated_at, state_updated_at) values ('3', '1', 'ALARM', 'http://somesite.com/this-alarm-info', '" + timestamp3.toString().replace('Z', ' ') + "', '" + timestamp3.toString().replace('Z', ' ') + "', '" + timestamp3.toString().replace('Z', ' ') + "')");
    long subAlarmId = 42;
    for (int alarmId = 1; alarmId <= 3; alarmId++) {
        handle.execute("insert into sub_alarm (id, alarm_id, expression, created_at, updated_at) values ('" + String.valueOf(subAlarmId++) + "', '" + alarmId + "', 'avg(cpu.idle_perc{flavor_id=777, image_id=888, device=1}) > 10', NOW(), NOW())");
    }
    handle.execute("insert into alarm_metric (alarm_id, metric_definition_dimensions_id) values ('1', 11)");
    handle.execute("insert into alarm_metric (alarm_id, metric_definition_dimensions_id) values ('1', 22)");
    handle.execute("insert into alarm_metric (alarm_id, metric_definition_dimensions_id) values ('2', 11)");
    handle.execute("insert into alarm_metric (alarm_id, metric_definition_dimensions_id) values ('3', 22)");
    handle.execute("insert into metric_definition (id, name, tenant_id, region) values (1, 'cpu.idle_perc', 'bob', 'west')");
    handle.execute("insert into metric_definition_dimensions (id, metric_definition_id, metric_dimension_set_id) values (11, 1, 1)");
    handle.execute("insert into metric_definition_dimensions (id, metric_definition_id, metric_dimension_set_id) values (22, 1, 2)");
    handle.execute("insert into metric_dimension (dimension_set_id, name, value) values (1, 'instance_id', '123')");
    handle.execute("insert into metric_dimension (dimension_set_id, name, value) values (1, 'service', 'monitoring')");
    handle.execute("insert into metric_dimension (dimension_set_id, name, value) values (2, 'flavor_id', '222')");
    alarm1 = new Alarm("1", "1", "90% CPU", "LOW", buildAlarmMetrics(buildMetricDefinition("cpu.idle_perc", "instance_id", "123", "service", "monitoring"), buildMetricDefinition("cpu.idle_perc", "flavor_id", "222")), AlarmState.OK, "OPEN", "http://somesite.com/this-alarm-info", timestamp1, timestamp1, timestamp1);
    alarm2 = new Alarm("2", "1", "90% CPU", "LOW", buildAlarmMetrics(buildMetricDefinition("cpu.idle_perc", "instance_id", "123", "service", "monitoring")), AlarmState.UNDETERMINED, "OPEN", null, timestamp2, timestamp2, timestamp2);
    alarm3 = new Alarm("3", "1", "90% CPU", "LOW", buildAlarmMetrics(buildMetricDefinition("cpu.idle_perc", "flavor_id", "222")), AlarmState.ALARM, null, "http://somesite.com/this-alarm-info", timestamp3, timestamp3, timestamp3);
    DateTime timestamp4 = ISO_8601_FORMATTER.parseDateTime("2015-03-15T09:26:53Z");
    handle.execute("insert into alarm_definition (id, tenant_id, name, severity, expression, match_by, actions_enabled, created_at, updated_at, deleted_at) " + "values ('234', 'bob', '50% CPU', 'HIGH', 'avg(cpu.sys_mem{service=monitoring}) > 20 and avg(cpu.idle_perc{service=monitoring}) < 10', 'hostname,region', 1, NOW(), NOW(), NULL)");
    handle.execute("insert into alarm (id, alarm_definition_id, state, created_at, updated_at, state_updated_at) values ('234111', '234', 'UNDETERMINED', '" + timestamp4.toString().replace('Z', ' ') + "', '" + timestamp4.toString().replace('Z', ' ') + "', '" + timestamp4.toString().replace('Z', ' ') + "')");
    handle.execute("insert into sub_alarm (id, alarm_id, expression, created_at, updated_at) values ('4343', '234111', 'avg(cpu.sys_mem{service=monitoring}) > 20', NOW(), NOW())");
    handle.execute("insert into sub_alarm (id, alarm_id, expression, created_at, updated_at) values ('4242', '234111', 'avg(cpu.idle_perc{service=monitoring}) < 10', NOW(), NOW())");
    handle.execute("insert into alarm_metric (alarm_id, metric_definition_dimensions_id) values ('234111', 31)");
    handle.execute("insert into alarm_metric (alarm_id, metric_definition_dimensions_id) values ('234111', 32)");
    handle.execute("insert into metric_definition (id, name, tenant_id, region) values (111, 'cpu.sys_mem', 'bob', 'west')");
    handle.execute("insert into metric_definition (id, name, tenant_id, region) values (112, 'cpu.idle_perc', 'bob', 'west')");
    handle.execute("insert into metric_definition_dimensions (id, metric_definition_id, metric_dimension_set_id) values (31, 111, 21)");
    handle.execute("insert into metric_definition_dimensions (id, metric_definition_id, metric_dimension_set_id) values (32, 112, 22)");
    handle.execute("insert into metric_dimension (dimension_set_id, name, value) values (21, 'service', 'monitoring')");
    handle.execute("insert into metric_dimension (dimension_set_id, name, value) values (22, 'service', 'monitoring')");
    handle.execute("insert into metric_dimension (dimension_set_id, name, value) values (21, 'hostname', 'roland')");
    handle.execute("insert into metric_dimension (dimension_set_id, name, value) values (22, 'hostname', 'roland')");
    handle.execute("insert into metric_dimension (dimension_set_id, name, value) values (21, 'region', 'colorado')");
    handle.execute("insert into metric_dimension (dimension_set_id, name, value) values (22, 'region', 'colorado')");
    handle.execute("insert into metric_dimension (dimension_set_id, name, value) values (22, 'extra', 'vivi')");
    compoundAlarm = new Alarm("234111", "234", "50% CPU", "HIGH", buildAlarmMetrics(buildMetricDefinition("cpu.sys_mem", "service", "monitoring", "hostname", "roland", "region", "colorado"), buildMetricDefinition("cpu.idle_perc", "service", "monitoring", "hostname", "roland", "region", "colorado", "extra", "vivi")), AlarmState.UNDETERMINED, null, null, timestamp4, timestamp4, timestamp4);
}
#end_block

#method_before
@Test(groups = "database")
public void shouldFind() {
    checkList(repo.find("Not a tenant id", null, null, null, null, null, null, null, null, null, 1, false));
    checkList(repo.find(TENANT_ID, null, null, null, null, null, null, null, null, null, 1, false), alarm1, alarm2, alarm3, compoundAlarm);
    checkList(repo.find(TENANT_ID, compoundAlarm.getAlarmDefinition().getId(), null, null, null, null, null, null, null, null, 1, false), compoundAlarm);
    checkList(repo.find(TENANT_ID, null, "cpu.sys_mem", null, null, null, null, null, null, null, 1, false), compoundAlarm);
    checkList(repo.find(TENANT_ID, null, "cpu.idle_perc", null, null, null, null, null, null, null, 1, false), alarm1, alarm2, alarm3, compoundAlarm);
    checkList(repo.find(TENANT_ID, null, "cpu.idle_perc", ImmutableMap.<String, String>builder().put("flavor_id", "222").build(), null, null, null, null, null, null, 1, false), alarm1, alarm3);
    checkList(repo.find(TENANT_ID, null, "cpu.idle_perc", ImmutableMap.<String, String>builder().put("service", "monitoring").put("hostname", "roland").build(), null, null, null, null, null, null, 1, false), compoundAlarm);
    checkList(repo.find(TENANT_ID, null, null, null, AlarmState.UNDETERMINED, null, null, null, null, null, 1, false), alarm2, compoundAlarm);
    checkList(repo.find(TENANT_ID, alarm1.getAlarmDefinition().getId(), "cpu.idle_perc", ImmutableMap.<String, String>builder().put("service", "monitoring").build(), null, null, null, null, null, null, 1, false), alarm1, alarm2);
    checkList(repo.find(TENANT_ID, alarm1.getAlarmDefinition().getId(), "cpu.idle_perc", null, null, null, null, null, null, null, 1, false), alarm1, alarm2, alarm3);
    checkList(repo.find(TENANT_ID, compoundAlarm.getAlarmDefinition().getId(), null, null, AlarmState.UNDETERMINED, null, null, null, null, null, 1, false), compoundAlarm);
    checkList(repo.find(TENANT_ID, null, "cpu.sys_mem", null, AlarmState.UNDETERMINED, null, null, null, null, null, 1, false), compoundAlarm);
    checkList(repo.find(TENANT_ID, null, "cpu.idle_perc", ImmutableMap.<String, String>builder().put("service", "monitoring").build(), AlarmState.UNDETERMINED, null, null, null, null, null, 1, false), alarm2, compoundAlarm);
    checkList(repo.find(TENANT_ID, alarm1.getAlarmDefinition().getId(), "cpu.idle_perc", ImmutableMap.<String, String>builder().put("service", "monitoring").build(), AlarmState.UNDETERMINED, null, null, null, null, null, 1, false), alarm2);
    checkList(repo.find(TENANT_ID, null, null, null, null, null, null, DateTime.now(DateTimeZone.forID("UTC")), null, null, 0, false));
    checkList(repo.find(TENANT_ID, null, null, null, null, null, null, ISO_8601_FORMATTER.parseDateTime("2015-03-15T00:00:00Z"), null, null, 0, false), compoundAlarm);
    checkList(repo.find(TENANT_ID, null, null, null, null, null, null, ISO_8601_FORMATTER.parseDateTime("2015-03-14T00:00:00Z"), null, null, 1, false), alarm1, alarm2, alarm3, compoundAlarm);
}
#method_after
@Test(groups = "database")
public void shouldFind() {
    checkList(repo.find("Not a tenant id", null, null, null, null, null, null, null, null, null, 1, false));
    checkList(repo.find(TENANT_ID, null, null, null, null, null, null, null, null, null, 1, false), alarm1, alarm2, alarm3, compoundAlarm);
    checkList(repo.find(TENANT_ID, compoundAlarm.getAlarmDefinition().getId(), null, null, null, null, null, null, null, null, 1, false), compoundAlarm);
    checkList(repo.find(TENANT_ID, null, "cpu.sys_mem", null, null, null, null, null, null, null, 1, false), compoundAlarm);
    checkList(repo.find(TENANT_ID, null, "cpu.idle_perc", null, null, null, null, null, null, null, 1, false), alarm1, alarm2, alarm3, compoundAlarm);
    checkList(repo.find(TENANT_ID, null, "cpu.idle_perc", ImmutableMap.<String, String>builder().put("flavor_id", "222").build(), null, null, null, null, null, null, 1, false), alarm1, alarm3);
    checkList(repo.find(TENANT_ID, null, "cpu.idle_perc", ImmutableMap.<String, String>builder().put("service", "monitoring").put("hostname", "roland").build(), null, null, null, null, null, null, 1, false), compoundAlarm);
    checkList(repo.find(TENANT_ID, null, null, null, AlarmState.UNDETERMINED, null, null, null, null, null, 1, false), alarm2, compoundAlarm);
    checkList(repo.find(TENANT_ID, alarm1.getAlarmDefinition().getId(), "cpu.idle_perc", ImmutableMap.<String, String>builder().put("service", "monitoring").build(), null, null, null, null, null, null, 1, false), alarm1, alarm2);
    checkList(repo.find(TENANT_ID, alarm1.getAlarmDefinition().getId(), "cpu.idle_perc", null, null, null, null, null, null, null, 1, false), alarm1, alarm2, alarm3);
    checkList(repo.find(TENANT_ID, compoundAlarm.getAlarmDefinition().getId(), null, null, AlarmState.UNDETERMINED, null, null, null, null, null, 1, false), compoundAlarm);
    checkList(repo.find(TENANT_ID, null, "cpu.sys_mem", null, AlarmState.UNDETERMINED, null, null, null, null, null, 1, false), compoundAlarm);
    checkList(repo.find(TENANT_ID, null, "cpu.idle_perc", ImmutableMap.<String, String>builder().put("service", "monitoring").build(), AlarmState.UNDETERMINED, null, null, null, null, null, 1, false), alarm2, compoundAlarm);
    checkList(repo.find(TENANT_ID, alarm1.getAlarmDefinition().getId(), "cpu.idle_perc", ImmutableMap.<String, String>builder().put("service", "monitoring").build(), AlarmState.UNDETERMINED, null, null, null, null, null, 1, false), alarm2);
    checkList(repo.find(TENANT_ID, null, null, null, null, null, null, DateTime.now(DateTimeZone.forID("UTC")), null, null, 0, false));
    checkList(repo.find(TENANT_ID, null, null, null, null, null, null, ISO_8601_FORMATTER.parseDateTime("2015-03-15T00:00:00Z"), null, null, 0, false), compoundAlarm);
    checkList(repo.find(TENANT_ID, null, null, null, null, null, null, ISO_8601_FORMATTER.parseDateTime("2015-03-14T00:00:00Z"), null, null, 1, false), alarm1, alarm2, alarm3, compoundAlarm);
    checkList(repo.find(TENANT_ID, null, null, null, null, null, null, null, Arrays.asList("state", "severity"), null, 1, false), alarm1, alarm2, compoundAlarm, alarm3);
    checkList(repo.find(TENANT_ID, null, null, null, null, null, null, null, Arrays.asList("state desc", "severity"), null, 1, false), compoundAlarm, alarm3, alarm2, alarm1);
}
#end_block

#method_before
@GET
@Timed
@Produces(MediaType.APPLICATION_JSON)
public Object list(@Context UriInfo uriInfo, @HeaderParam("X-Tenant-Id") String tenantId, @QueryParam("alarm_definition_id") String alarmDefId, @QueryParam("metric_name") String metricName, @QueryParam("metric_dimensions") String metricDimensionsStr, @QueryParam("state") AlarmState state, @QueryParam("lifecycle_state") String lifecycleState, @QueryParam("link") String link, @QueryParam("state_updated_start_time") String stateUpdatedStartStr, @QueryParam("sort_by") String sortBy, @QueryParam("offset") String offset, @QueryParam("limit") String limit) throws Exception {
    Map<String, String> metricDimensions = Strings.isNullOrEmpty(metricDimensionsStr) ? null : Validation.parseAndValidateDimensions(metricDimensionsStr);
    MetricNameValidation.validate(metricName, false);
    DateTime stateUpdatedStart = Validation.parseAndValidateDate(stateUpdatedStartStr, "state_updated_start_time", false);
    List<String> sortByList = parseAndValidateSortBy(sortBy);
    if (!Strings.isNullOrEmpty(offset)) {
        Validation.parseAndValidateNumber(offset, "offset");
    }
    final int paging_limit = this.persistUtils.getLimit(limit);
    final List<Alarm> alarms = repo.find(tenantId, alarmDefId, metricName, metricDimensions, state, lifecycleState, link, stateUpdatedStart, sortByList, offset, paging_limit, true);
    for (final Alarm alarm : alarms) {
        Links.hydrate(alarm.getAlarmDefinition(), uriInfo, AlarmDefinitionResource.ALARM_DEFINITIONS_PATH);
    }
    return Links.paginateAlarming(paging_limit, Links.hydrate(alarms, uriInfo), uriInfo);
}
#method_after
@GET
@Timed
@Produces(MediaType.APPLICATION_JSON)
public Object list(@Context UriInfo uriInfo, @HeaderParam("X-Tenant-Id") String tenantId, @QueryParam("alarm_definition_id") String alarmDefId, @QueryParam("metric_name") String metricName, @QueryParam("metric_dimensions") String metricDimensionsStr, @QueryParam("state") AlarmState state, @QueryParam("lifecycle_state") String lifecycleState, @QueryParam("link") String link, @QueryParam("state_updated_start_time") String stateUpdatedStartStr, @QueryParam("sort_by") String sortBy, @QueryParam("offset") String offset, @QueryParam("limit") String limit) throws Exception {
    Map<String, String> metricDimensions = Strings.isNullOrEmpty(metricDimensionsStr) ? null : Validation.parseAndValidateDimensions(metricDimensionsStr);
    MetricNameValidation.validate(metricName, false);
    DateTime stateUpdatedStart = Validation.parseAndValidateDate(stateUpdatedStartStr, "state_updated_start_time", false);
    List<String> sortByList = Validation.parseAndValidateSortBy(sortBy, ALLOWED_SORT_BY);
    if (!Strings.isNullOrEmpty(offset)) {
        Validation.parseAndValidateNumber(offset, "offset");
    }
    final int paging_limit = this.persistUtils.getLimit(limit);
    final List<Alarm> alarms = repo.find(tenantId, alarmDefId, metricName, metricDimensions, state, lifecycleState, link, stateUpdatedStart, sortByList, offset, paging_limit, true);
    for (final Alarm alarm : alarms) {
        Links.hydrate(alarm.getAlarmDefinition(), uriInfo, AlarmDefinitionResource.ALARM_DEFINITIONS_PATH);
    }
    return Links.paginateAlarming(paging_limit, Links.hydrate(alarms, uriInfo), uriInfo);
}
#end_block

#method_before
public void shouldFind() {
    assertEquals(Arrays.asList(alarmDef_123, alarmDef_234), repo.find("bob", null, null, null, null, 1));
    // Make sure it still finds AlarmDefinitions with no notifications
    handle.execute("delete from alarm_action");
    alarmDef_123.setAlarmActions(new ArrayList<String>(0));
    alarmDef_234.setAlarmActions(new ArrayList<String>(0));
    assertEquals(Arrays.asList(alarmDef_123, alarmDef_234), repo.find("bob", null, null, null, null, 1));
    assertEquals(0, repo.find("bill", null, null, null, null, 1).size());
}
#method_after
public void shouldFind() {
    assertEquals(Arrays.asList(alarmDef_123, alarmDef_234), repo.find("bob", null, null, null, null, 1));
    // Make sure it still finds AlarmDefinitions with no notifications
    handle.execute("delete from alarm_action");
    alarmDef_123.setAlarmActions(new ArrayList<String>(0));
    alarmDef_234.setAlarmActions(new ArrayList<String>(0));
    assertEquals(Arrays.asList(alarmDef_123, alarmDef_234), repo.find("bob", null, null, null, null, 1));
    assertEquals(0, repo.find("bill", null, null, null, null, 1).size());
    assertEquals(Arrays.asList(alarmDef_234, alarmDef_123), repo.find("bob", null, null, Arrays.asList("name"), null, 1));
    assertEquals(Arrays.asList(alarmDef_234, alarmDef_123), repo.find("bob", null, null, Arrays.asList("id desc"), null, 1));
}
#end_block

#method_before
public void setTimestamp(DateTime timestamp) {
    this.timestamp = timestamp;
    // Set the id in the AbstractEntity class.
    id = new DateTime(timestamp.getMillis()).toString();
}
#method_after
public void setTimestamp(DateTime timestamp) {
    this.timestamp = Conversions.variantToDateTime(timestamp);
    // Set the id in the AbstractEntity class.
    id = timestamp.toString();
}
#end_block

#method_before
@Test(groups = { "functional", "threeDigitMillisTimestamp" })
public void testThreeDigitMillisTimestamp_with_3digit() throws Exception {
    final String origTimestamp = "2016-01-11T16:10:34.472Z";
    assertEquals(this.instance.threeDigitMillisTimestamp(origTimestamp), origTimestamp);
}
#method_after
@Test(groups = { "threeDigitMillisTimestamp" })
public void testThreeDigitMillisTimestamp_with_3digit() throws Exception {
    final String origTimestamp = "2016-01-11T16:10:34.472Z";
    assertEquals(this.instance.threeDigitMillisTimestamp(origTimestamp), origTimestamp);
}
#end_block

#method_before
@Test(groups = { "functional", "threeDigitMillisTimestamp" })
public void testThreeDigitMillisTimestamp_with_2digit() throws Exception {
    final String origTimestamp_1 = "2016-01-11T16:10:34.47Z";
    assertEquals(this.instance.threeDigitMillisTimestamp(origTimestamp_1), "2016-01-11T16:10:34.047Z");
    final String origTimestamp_2 = "2016-01-11T16:10:34.40Z";
    assertEquals(this.instance.threeDigitMillisTimestamp(origTimestamp_2), "2016-01-11T16:10:34.040Z");
}
#method_after
@Test(groups = { "threeDigitMillisTimestamp" })
public void testThreeDigitMillisTimestamp_with_2digit() throws Exception {
    final String origTimestamp_1 = "2016-01-11T16:10:34.47Z";
    assertEquals(this.instance.threeDigitMillisTimestamp(origTimestamp_1), "2016-01-11T16:10:34.470Z");
    final String origTimestamp_2 = "2016-01-11T16:10:34.40Z";
    assertEquals(this.instance.threeDigitMillisTimestamp(origTimestamp_2), "2016-01-11T16:10:34.400Z");
}
#end_block

#method_before
@Test(groups = { "functional", "threeDigitMillisTimestamp" })
public void testThreeDigitMillisTimestamp_with_1digit() throws Exception {
    final String origTimestamp = "2016-01-11T16:10:34.4Z";
    assertEquals(this.instance.threeDigitMillisTimestamp(origTimestamp), "2016-01-11T16:10:34.004Z");
}
#method_after
@Test(groups = { "threeDigitMillisTimestamp" })
public void testThreeDigitMillisTimestamp_with_1digit() throws Exception {
    final String origTimestamp = "2016-01-11T16:10:34.4Z";
    assertEquals(this.instance.threeDigitMillisTimestamp(origTimestamp), "2016-01-11T16:10:34.400Z");
}
#end_block

#method_before
@Test(groups = { "functional", "threeDigitMillisTimestamp" })
public void testThreeDigitMillisTimestamp_with_0digit() throws Exception {
    final String origTimestamp = "2016-01-11T16:10:34Z";
    assertEquals(this.instance.threeDigitMillisTimestamp(origTimestamp), "2016-01-11T16:10:34.000Z");
}
#method_after
@Test(groups = { "threeDigitMillisTimestamp" })
public void testThreeDigitMillisTimestamp_with_0digit() throws Exception {
    final String origTimestamp = "2016-01-11T16:10:34Z";
    assertEquals(this.instance.threeDigitMillisTimestamp(origTimestamp), "2016-01-11T16:10:34.000Z");
}
#end_block

#method_before
public void testValidationForMaxNameAddress() {
    String name = "1aaaaaaaaa2bbbbbbbbb3ccccccccc4ddddddddd5eeeeeeeee6fffffffff7ggggggggg8hhhhhhhhh" + "9iiiiiiiii10jjjjjjjj11kkkkkkkk12llllllll13mmmmmmmm14nnnnnnnn15oooooooo16pppppppp" + "17qqqqqqqq18rrrrrrrr19ssssssss20tttttttt21uuuuuuuu22vvvvvvvv23wwwwwwww24xxxxxxxx" + "25yyyyyyyy";
    assertEquals(name.length(), 250);
    String address = "http://" + "1aaaaaaaaa2bbbbbbbbb3ccccccccc4ddddddddd5eeeeeeeee6fffffffff7ggggggggg8hhhhhhhhh" + "9iiiiiiiii10jjjjjjjj11kkkkkkkk12llllllll13mmmmmmmm14nnnnnnnn15oooooooo16pppppppp" + "17qqqqqqqq18rrrrrrrr19ssssssss20tttttttt21uuuuuuuu22vvvvvvvv23wwwwwwww24xxxxxxxx" + "25yyyyyyyy26zzzzzzzz27aaaaaaaa28bbbbbbbb29cccccccc30dddddddd31eeeeeeee32ffffffff" + "33gggggggg34hhhhhhhh35iiiiiiii36jjjjjjjj37kkkkkkkk38llllllll39mmmmmmmm40nnnnnnnn" + "41oooooooo42pppppppp42qqqqqqqq44rrrrrrrr45ssssssss46tttttttt47uuuuuuuu48vvvvvvvv" + "49wwwwwwww50xxxxxxxx" + "12" + ".io";
    assertEquals(address.length(), 512);
    CreateNotificationMethodCommand newNotificationMethod = new CreateNotificationMethodCommand(name, NotificationMethodType.WEBHOOK, address);
    Set<ConstraintViolation<CreateNotificationMethodCommand>> constraintViolations = validator.validate(newNotificationMethod);
    assertEquals(constraintViolations.size(), 0);
}
#method_after
public void testValidationForMaxNameAddress() {
    String name = StringUtils.repeat("A", 250);
    assertEquals(name.length(), 250);
    String address = "http://" + StringUtils.repeat("A", 502) + ".io";
    assertEquals(address.length(), 512);
    CreateNotificationMethodCommand newNotificationMethod = new CreateNotificationMethodCommand(name, NotificationMethodType.WEBHOOK, address);
    Set<ConstraintViolation<CreateNotificationMethodCommand>> constraintViolations = validator.validate(newNotificationMethod);
    assertEquals(constraintViolations.size(), 0);
}
#end_block

#method_before
public void testValidationExceptionForExceededNameLength() {
    String name = "1aaaaaaaaa2bbbbbbbbb3ccccccccc4ddddddddd5eeeeeeeee6fffffffff7ggggggggg8hhhhhhhhh" + "9iiiiiiiii10jjjjjjjj11kkkkkkkk12llllllll13mmmmmmmm14nnnnnnnn15oooooooo16pppppppp" + "17qqqqqqqq18rrrrrrrr19ssssssss20tttttttt21uuuuuuuu22vvvvvvvv23wwwwwwww24xxxxxxxx" + "25yyyyyyyy" + "1";
    assertEquals(name.length(), 251);
    CreateNotificationMethodCommand newNotificationMethod = new CreateNotificationMethodCommand(name, NotificationMethodType.WEBHOOK, "http://somedomain.com");
    Set<ConstraintViolation<CreateNotificationMethodCommand>> constraintViolations = validator.validate(newNotificationMethod);
    assertEquals(constraintViolations.size(), 1);
    assertEquals(constraintViolations.iterator().next().getMessage(), "size must be between 1 and 250");
}
#method_after
public void testValidationExceptionForExceededNameLength() {
    String name = StringUtils.repeat("A", 251);
    assertEquals(name.length(), 251);
    CreateNotificationMethodCommand newNotificationMethod = new CreateNotificationMethodCommand(name, NotificationMethodType.WEBHOOK, "http://somedomain.com");
    Set<ConstraintViolation<CreateNotificationMethodCommand>> constraintViolations = validator.validate(newNotificationMethod);
    assertEquals(constraintViolations.size(), 1);
    assertEquals(constraintViolations.iterator().next().getMessage(), "size must be between 1 and 250");
}
#end_block

#method_before
public void testValidationExceptionForExceededAddressLength() {
    String address = "http://" + "1aaaaaaaaa2bbbbbbbbb3ccccccccc4ddddddddd5eeeeeeeee6fffffffff7ggggggggg8hhhhhhhhh" + "9iiiiiiiii10jjjjjjjj11kkkkkkkk12llllllll13mmmmmmmm14nnnnnnnn15oooooooo16pppppppp" + "17qqqqqqqq18rrrrrrrr19ssssssss20tttttttt21uuuuuuuu22vvvvvvvv23wwwwwwww24xxxxxxxx" + "25yyyyyyyy26zzzzzzzz27aaaaaaaa28bbbbbbbb29cccccccc30dddddddd31eeeeeeee32ffffffff" + "33gggggggg34hhhhhhhh35iiiiiiii36jjjjjjjj37kkkkkkkk38llllllll39mmmmmmmm40nnnnnnnn" + "41oooooooo42pppppppp42qqqqqqqq44rrrrrrrr45ssssssss46tttttttt47uuuuuuuu48vvvvvvvv" + "49wwwwwwww50xxxxxxxx" + "123" + ".io";
    assertEquals(address.length(), 513);
    CreateNotificationMethodCommand newNotificationMethod = new CreateNotificationMethodCommand("MyWebhook", NotificationMethodType.WEBHOOK, address);
    Set<ConstraintViolation<CreateNotificationMethodCommand>> constraintViolations = validator.validate(newNotificationMethod);
    assertEquals(constraintViolations.size(), 1);
    assertEquals(constraintViolations.iterator().next().getMessage(), "size must be between 1 and 512");
}
#method_after
public void testValidationExceptionForExceededAddressLength() {
    String address = "http://" + StringUtils.repeat("A", 503) + ".io";
    assertEquals(address.length(), 513);
    CreateNotificationMethodCommand newNotificationMethod = new CreateNotificationMethodCommand("MyWebhook", NotificationMethodType.WEBHOOK, address);
    Set<ConstraintViolation<CreateNotificationMethodCommand>> constraintViolations = validator.validate(newNotificationMethod);
    assertEquals(constraintViolations.size(), 1);
    assertEquals(constraintViolations.iterator().next().getMessage(), "size must be between 1 and 512");
}
#end_block

#method_before
private boolean isAuthorized(HttpServletRequest request) {
    Object rolesFromKeystone = request.getAttribute(X_ROLES_ATTRIBUTE);
    if (rolesFromKeystone == null)
        return false;
    boolean agentUser = false;
    for (String role : rolesFromKeystone.toString().split(",")) {
        String lowerCaseRole = role.toLowerCase();
        if ((defaultAuthorizedRoles != null) && defaultAuthorizedRoles.contains(lowerCaseRole)) {
            return true;
        }
        if ((agentAuthorizedRoles != null) && agentAuthorizedRoles.contains(lowerCaseRole)) {
            agentUser = true;
        }
    }
    if (agentUser) {
        request.setAttribute(X_MONASCA_AGENT, true);
        return true;
    }
    return false;
}
#method_after
private boolean isAuthorized(HttpServletRequest request) {
    Object rolesFromKeystone = request.getAttribute(X_ROLES_ATTRIBUTE);
    if (rolesFromKeystone == null)
        return false;
    boolean agentUser = false;
    for (String role : rolesFromKeystone.toString().split(",")) {
        String lowerCaseRole = role.toLowerCase();
        if ((defaultAuthorizedRoles != null) && defaultAuthorizedRoles.contains(lowerCaseRole)) {
            return true;
        }
        if ((agentAuthorizedRoles != null) && agentAuthorizedRoles.contains(lowerCaseRole)) {
            agentUser = true;
        }
    }
    if (agentUser) {
        request.setAttribute(X_MONASCA_LOG_AGENT, true);
        return true;
    }
    return false;
}
#end_block

#method_before
private List<Map<String, Object>> executeMetricNamesQuery(String tenantId, Map<String, String> dimensions, String offset, int limit) {
    String offsetPart = "";
    if (offset != null && !offset.isEmpty()) {
        offsetPart = " and defSub.id > :offset ";
    }
    // Can't bind limit in a nested sub query. So, just tack on as String.
    String limitPart = " limit " + Integer.toString(limit + 1);
    String defSubSelect = String.format(METRIC_NAMES_SUB_SELECT, offsetPart, MetricQueries.buildDimensionAndClause(dimensions, TABLE_TO_JOIN_DIMENSIONS_ON), limitPart);
    String sql = String.format(FIND_METRIC_NAMES_SQL, defSubSelect);
    try (Handle h = db.open()) {
        Query<Map<String, Object>> query = h.createQuery(sql).bind("tenantId", tenantId);
        if (offset != null && !offset.isEmpty()) {
            logger.debug("binding offset: {}", offset);
            try {
                query.bind("offset", Hex.decodeHex(offset.toCharArray()));
            } catch (DecoderException e) {
                throw Exceptions.badRequest("failed to decode offset " + offset, e);
            }
        }
        DimensionQueries.bindDimensionsToQuery(query, dimensions);
        return query.list();
    }
}
#method_after
private List<Map<String, Object>> executeMetricNamesQuery(String tenantId, Map<String, String> dimensions, String offset, int limit) {
    String offsetPart = "";
    if (offset != null && !offset.isEmpty()) {
        offsetPart = " and defSub.id > :offset ";
    }
    // Can't bind limit in a nested sub query. So, just tack on as String.
    String limitPart = " limit " + Integer.toString(limit + 1);
    String defSubSelect = String.format(METRIC_NAMES_SUB_SELECT, offsetPart, MetricQueries.buildDimensionAndClause(dimensions, TABLE_TO_JOIN_DIMENSIONS_ON), limitPart);
    String sql = String.format(FIND_METRIC_NAMES_SQL, defSubSelect);
    Handle h = null;
    try {
        h = db.open();
        Query<Map<String, Object>> query = h.createQuery(sql).bind("tenantId", tenantId);
        if (offset != null && !offset.isEmpty()) {
            logger.debug("binding offset: {}", offset);
            try {
                query.bind("offset", Hex.decodeHex(offset.toCharArray()));
            } catch (DecoderException e) {
                throw Exceptions.badRequest("failed to decode offset " + offset, e);
            }
        }
        DimensionQueries.bindDimensionsToQuery(query, dimensions);
        return query.list();
    } finally {
        if (null != h) {
            h.close();
        }
    }
}
#end_block

#method_before
private List<Map<String, Object>> executeMetricDefsQuery(String tenantId, String name, Map<String, String> dimensions, DateTime startTime, DateTime endTime, String offset, int limit) {
    String namePart = "";
    if (name != null && !name.isEmpty()) {
        namePart = " and def.name = :name ";
    }
    String offsetPart = "";
    if (offset != null && !offset.isEmpty()) {
        offsetPart = " and defDims.id > :offset ";
    }
    // Can't bind limit in a nested sub query. So, just tack on as String.
    String limitPart = " limit " + Integer.toString(limit + 1);
    // If startTime/endTime is specified, create the 'IN' select statement
    String timeInClause = createTimeInClause(startTime, endTime, tenantId, name, dimensions);
    String sql = String.format(FIND_METRIC_DEFS_SQL, namePart, offsetPart, MetricQueries.buildDimensionAndClause(dimensions, "defDims"), timeInClause, limitPart);
    try (Handle h = db.open()) {
        Query<Map<String, Object>> query = h.createQuery(sql).bind("tenantId", tenantId);
        if (name != null && !name.isEmpty()) {
            logger.debug("binding name: {}", name);
            query.bind("name", name);
        }
        if (startTime != null && endTime != null) {
            query.bind("start_time", startTime).bind("end_time", endTime);
        } else if (startTime != null) {
            query.bind("start_time", startTime);
        }
        if (offset != null && !offset.isEmpty()) {
            logger.debug("binding offset: {}", offset);
            try {
                query.bind("offset", Hex.decodeHex(offset.toCharArray()));
            } catch (DecoderException e) {
                throw Exceptions.badRequest("failed to decode offset " + offset, e);
            }
        }
        DimensionQueries.bindDimensionsToQuery(query, dimensions);
        return query.list();
    }
}
#method_after
private List<Map<String, Object>> executeMetricDefsQuery(String tenantId, String name, Map<String, String> dimensions, DateTime startTime, DateTime endTime, String offset, int limit) {
    String namePart = "";
    if (name != null && !name.isEmpty()) {
        namePart = " and def.name = :name ";
    }
    String offsetPart = "";
    if (offset != null && !offset.isEmpty()) {
        offsetPart = " and defDims.id > :offset ";
    }
    // Can't bind limit in a nested sub query. So, just tack on as String.
    String limitPart = " limit " + Integer.toString(limit + 1);
    Handle h = null;
    try {
        h = db.open();
        // If startTime/endTime is specified, create the 'IN' select statement
        String timeInClause = createTimeInClause(h, startTime, endTime, tenantId, name, dimensions);
        String sql = String.format(FIND_METRIC_DEFS_SQL, namePart, offsetPart, MetricQueries.buildDimensionAndClause(dimensions, "defDims"), timeInClause, limitPart);
        Query<Map<String, Object>> query = h.createQuery(sql).bind("tenantId", tenantId);
        if (name != null && !name.isEmpty()) {
            logger.debug("binding name: {}", name);
            query.bind("name", name);
        }
        if (startTime != null) {
            query.bind("start_time", startTime);
        }
        if (endTime != null) {
            query.bind("end_time", endTime);
        }
        if (offset != null && !offset.isEmpty()) {
            logger.debug("binding offset: {}", offset);
            try {
                query.bind("offset", Hex.decodeHex(offset.toCharArray()));
            } catch (DecoderException e) {
                throw Exceptions.badRequest("failed to decode offset " + offset, e);
            }
        }
        DimensionQueries.bindDimensionsToQuery(query, dimensions);
        return query.list();
    } finally {
        if (null != h) {
            h.close();
        }
    }
}
#end_block

#method_before
private String createTimeInClause(DateTime startTime, DateTime endTime, String tenantId, String metricName, Map<String, String> dimensions) {
    if (startTime == null) {
        return "";
    }
    Set<byte[]> defDimIdSet = new HashSet<>();
    String defDimSql = String.format(DEFDIM_IDS_SELECT, MetricQueries.buildDimensionAndClause(dimensions, TABLE_TO_JOIN_DIMENSIONS_ON));
    try (Handle h = db.open()) {
        Query<Map<String, Object>> query = h.createQuery(defDimSql).bind("tenantId", tenantId);
        DimensionQueries.bindDimensionsToQuery(query, dimensions);
        if (metricName != null && !metricName.isEmpty()) {
            query.bind("name", metricName);
        }
        List<Map<String, Object>> rows = query.list();
        for (Map<String, Object> row : rows) {
            byte[] defDimId = (byte[]) row.get("id");
            defDimIdSet.add(defDimId);
        }
    }
    String timeAndClause = "";
    if (startTime != null && endTime != null) {
        timeAndClause = "AND time_stamp >= :start_time AND time_stamp <= :end_time ";
    } else if (startTime != null) {
        timeAndClause = "AND time_stamp >= :start_time ";
    }
    String defDimInClause = MetricQueries.createDefDimIdInClause(defDimIdSet);
    return String.format(MEASUREMENT_AND_CLAUSE, defDimInClause, timeAndClause);
}
#method_after
private String createTimeInClause(Handle dbHandle, DateTime startTime, DateTime endTime, String tenantId, String metricName, Map<String, String> dimensions) {
    if (startTime == null) {
        return "";
    }
    Set<byte[]> defDimIdSet = new HashSet<>();
    String namePart = "";
    if (metricName != null && !metricName.isEmpty()) {
        namePart = "AND def.name = :name ";
    }
    String defDimSql = String.format(DEFDIM_IDS_SELECT, namePart, MetricQueries.buildDimensionAndClause(dimensions, "defDims"));
    Query<Map<String, Object>> query = dbHandle.createQuery(defDimSql).bind("tenantId", tenantId);
    DimensionQueries.bindDimensionsToQuery(query, dimensions);
    if (metricName != null && !metricName.isEmpty()) {
        query.bind("name", metricName);
    }
    List<Map<String, Object>> rows = query.list();
    for (Map<String, Object> row : rows) {
        byte[] defDimId = (byte[]) row.get("id");
        defDimIdSet.add(defDimId);
    }
    // 
    if (defDimIdSet.size() == 0) {
        return "";
    }
    String timeAndClause = "";
    if (endTime != null) {
        timeAndClause = "AND time_stamp >= :start_time AND time_stamp <= :end_time ";
    } else {
        timeAndClause = "AND time_stamp >= :start_time ";
    }
    String defDimInClause = MetricQueries.createDefDimIdInClause(defDimIdSet);
    return String.format(MEASUREMENT_AND_CLAUSE, defDimInClause, timeAndClause);
}
#end_block

#method_before
@Override
public List<Statistics> find(String tenantId, String name, Map<String, String> dimensions, DateTime startTime, DateTime endTime, List<String> statisticsCols, int period, String offset, int limit, Boolean mergeMetricsFlag) throws MultipleMetricsException {
    List<Statistics> statisticsList = new ArrayList<>();
    // Sort the column names so that they match the order of the statistics in the results.
    List<String> statisticsColumns = createColumnsList(statisticsCols);
    try (Handle h = db.open()) {
        Map<byte[], Statistics> byteMap = findDefIds(h, tenantId, name, dimensions);
        if (byteMap.isEmpty()) {
            return statisticsList;
        }
        if (!Boolean.TRUE.equals(mergeMetricsFlag) && byteMap.keySet().size() > 1) {
            throw new MultipleMetricsException(name, dimensions);
        }
        List<List<Object>> statisticsListList = new ArrayList<>();
        String sql = createQuery(byteMap.keySet(), period, startTime, endTime, offset, statisticsCols);
        logger.debug("vertics sql: {}", sql);
        Query<Map<String, Object>> query = h.createQuery(sql).bind("start_time", startTime).bind("end_time", endTime).bind("limit", limit + 1);
        if (offset != null && !offset.isEmpty()) {
            logger.debug("binding offset: {}", offset);
            query.bind("offset", new Timestamp(DateTime.parse(offset).getMillis()));
        }
        List<Map<String, Object>> rows = query.list();
        for (Map<String, Object> row : rows) {
            List<Object> statisticsRow = parseRow(row);
            statisticsListList.add(statisticsRow);
        }
        // Just use the first entry in the byteMap to get the def name and dimensions.
        Statistics statistics = byteMap.entrySet().iterator().next().getValue();
        statistics.setColumns(statisticsColumns);
        if (Boolean.TRUE.equals(mergeMetricsFlag) && byteMap.keySet().size() > 1) {
            // Wipe out the dimensions.
            statistics.setDimensions(new HashMap<String, String>());
        }
        statistics.setStatistics(statisticsListList);
        statisticsList.add(statistics);
    }
    return statisticsList;
}
#method_after
@Override
public List<Statistics> find(String tenantId, String name, Map<String, String> dimensions, DateTime startTime, DateTime endTime, List<String> statisticsCols, int period, String offset, int limit, Boolean mergeMetricsFlag) throws MultipleMetricsException {
    List<Statistics> statisticsList = new ArrayList<>();
    // Sort the column names so that they match the order of the statistics in the results.
    List<String> statisticsColumns = createColumnsList(statisticsCols);
    Handle h = null;
    try {
        h = db.open();
        Map<byte[], Statistics> byteMap = findDefIds(h, tenantId, name, dimensions);
        if (byteMap.isEmpty()) {
            return statisticsList;
        }
        if (!Boolean.TRUE.equals(mergeMetricsFlag) && byteMap.keySet().size() > 1) {
            throw new MultipleMetricsException(name, dimensions);
        }
        List<List<Object>> statisticsListList = new ArrayList<>();
        String sql = createQuery(byteMap.keySet(), period, startTime, endTime, offset, statisticsCols);
        logger.debug("vertics sql: {}", sql);
        Query<Map<String, Object>> query = h.createQuery(sql).bind("start_time", startTime).bind("end_time", endTime).bind("limit", limit + 1);
        if (offset != null && !offset.isEmpty()) {
            logger.debug("binding offset: {}", offset);
            query.bind("offset", new Timestamp(DateTime.parse(offset).getMillis()));
        }
        List<Map<String, Object>> rows = query.list();
        for (Map<String, Object> row : rows) {
            List<Object> statisticsRow = parseRow(row);
            statisticsListList.add(statisticsRow);
        }
        // Just use the first entry in the byteMap to get the def name and dimensions.
        Statistics statistics = byteMap.entrySet().iterator().next().getValue();
        statistics.setColumns(statisticsColumns);
        if (Boolean.TRUE.equals(mergeMetricsFlag) && byteMap.keySet().size() > 1) {
            // Wipe out the dimensions.
            statistics.setDimensions(new HashMap<String, String>());
        }
        statistics.setStatistics(statisticsListList);
        statisticsList.add(statistics);
    } finally {
        if (null != h) {
            h.close();
        }
    }
    return statisticsList;
}
#end_block

#method_before
public static DateTime parseAndValidateDate(String date, String parameterName, boolean required) {
    if (Strings.isNullOrEmpty(date)) {
        if (required)
            throw Exceptions.unprocessableEntity("%s is required", parameterName);
        else
            return null;
    }
    try {
        return ISO_8601_FORMATTER.parseDateTime(date);
    } catch (Exception e) {
        throw Exceptions.unprocessableEntity("%s must be an ISO 8601 formatted time", parameterName);
    }
}
#method_after
public static DateTime parseAndValidateDate(String date, String parameterName, boolean required) {
    if (Strings.isNullOrEmpty(date)) {
        if (required)
            throw Exceptions.unprocessableEntity("%s is required", parameterName);
        else
            return null;
    }
    try {
        return ISO_8601_FORMATTER.parseDateTime(date);
    } catch (Exception e) {
        throw Exceptions.unprocessableEntity("%s (%s) must be an ISO 8601 formatted time", parameterName, date);
    }
}
#end_block

#method_before
public static int parseAndValidateNumber(String number, String parameterName) {
    try {
        return Integer.parseInt(number);
    } catch (NumberFormatException e) {
        throw Exceptions.unprocessableEntity("%s must be valid number", parameterName);
    }
}
#method_after
public static int parseAndValidateNumber(String number, String parameterName) {
    try {
        return Integer.parseInt(number);
    } catch (NumberFormatException e) {
        throw Exceptions.unprocessableEntity("%s (%s) must be valid number", parameterName, number);
    }
}
#end_block

#method_before
public static void validateTimes(DateTime startTime, DateTime endTime) {
    if (endTime != null && !startTime.isBefore(endTime))
        throw Exceptions.badRequest("start_time must be before end_time");
}
#method_after
public static void validateTimes(DateTime startTime, DateTime endTime) {
    if (endTime != null && !startTime.isBefore(endTime))
        throw Exceptions.badRequest("start_time (%s) must be before end_time (%s)", startTime, endTime);
}
#end_block

#method_before
String buildTimePart(final DateTime startTime, final DateTime endTime) {
    final StringBuilder sb = new StringBuilder();
    if (startTime != null) {
        sb.append(String.format(" and time > %1$ds", startTime.getMillis() / 1000));
    }
    if (endTime != null) {
        sb.append(String.format(" and time < %1$ds", endTime.getMillis() / 1000));
    }
    return sb.toString();
}
#method_after
String buildTimePart(final DateTime startTime, final DateTime endTime) {
    final StringBuilder sb = new StringBuilder();
    if (startTime != null) {
        sb.append(String.format(" and time > " + "'" + ISODateTimeFormat.dateTime().print(startTime) + "'"));
    }
    if (endTime != null) {
        sb.append(String.format(" and time < " + "'" + ISODateTimeFormat.dateTime().print(endTime) + "'"));
    }
    return sb.toString();
}
#end_block

