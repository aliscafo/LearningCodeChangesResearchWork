321
#method_before
@Override
public Set<SuggestedReviewer> suggestReviewers(Project.NameKey projectName, @Nullable Change.Id changeId, @Nullable String query, Set<Account.Id> candidates) {
    List<ReviewerFilterSection> sections = getSections(projectName);
    if (!sections.isEmpty()) {
        try (ReviewDb reviewDb = schemaFactory.open()) {
            ChangeData changeData = changeDataFactory.create(reviewDb, projectName, changeId);
            Set<String> reviewers = findReviewers(sections, changeData);
            if (!reviewers.isEmpty()) {
                return toAccounts(reviewDb, reviewers, projectName, null).stream().map(a -> suggestedReviewer(a)).collect(toSet());
            }
        } catch (OrmException | QueryParseException x) {
            log.error(x.getMessage(), x);
        }
    }
    return new HashSet<>();
}
#method_after
@Override
public Set<SuggestedReviewer> suggestReviewers(Project.NameKey projectName, @Nullable Change.Id changeId, @Nullable String query, Set<Account.Id> candidates) {
    List<ReviewerFilterSection> sections = getSections(projectName);
    if (sections.isEmpty()) {
        return ImmutableSet.of();
    }
    try (ReviewDb reviewDb = schemaFactory.open()) {
        ChangeData changeData = changeDataFactory.create(reviewDb, projectName, changeId);
        Set<String> reviewers = findReviewers(sections, changeData);
        if (!reviewers.isEmpty()) {
            return toAccounts(reviewDb, reviewers, projectName).stream().map(a -> suggestedReviewer(a)).collect(toSet());
        }
    } catch (OrmException | QueryParseException x) {
        log.error(x.getMessage(), x);
    }
    return ImmutableSet.of();
}
#end_block

#method_before
private Set<Account> toAccounts(ReviewDb reviewDb, Set<String> in, Project.NameKey p, AccountInfo uploader) {
    Set<Account> reviewers = Sets.newHashSetWithExpectedSize(in.size());
    GroupMembers groupMembers = null;
    for (String r : in) {
        try {
            Account account = accountResolver.find(reviewDb, r);
            if (account != null) {
                reviewers.add(account);
                continue;
            }
        } catch (OrmException e) {
            // If the account doesn't exist, find() will return null.  We only
            // get here if something went wrong accessing the database
            log.error("Failed to resolve account " + r, e);
            continue;
        }
        if (groupMembers == null && uploader != null) {
            // email is not unique to one account, try to locate the account using
            // "Full name <email>" to increase chance of finding only one.
            String uploaderNameEmail = String.format("%s <%s>", uploader.name, uploader.email);
            try {
                Account uploaderAccount = accountResolver.findByNameOrEmail(reviewDb, uploaderNameEmail);
                if (uploaderAccount != null) {
                    groupMembers = groupMembersFactory.create(identifiedUserFactory.create(uploaderAccount.getId()));
                }
            } catch (OrmException e) {
                log.warn(String.format("Failed to list accounts for group %s, cannot retrieve uploader account %s", r, uploaderNameEmail), e);
            }
            try {
                if (groupMembers != null) {
                    reviewers.addAll(groupMembers.listAccounts(groupsCollection.get().parse(r).getGroupUUID(), p));
                } else {
                    log.warn(String.format("Failed to list accounts for group %s; cannot retrieve uploader account for %s", r, uploader.email));
                }
            } catch (UnprocessableEntityException | NoSuchGroupException e) {
                log.warn(String.format("Reviewer %s is neither an account nor a group", r));
            } catch (NoSuchProjectException e) {
                log.warn(String.format("Failed to list accounts for group %s and project %s", r, p));
            } catch (IOException | OrmException e) {
                log.warn(String.format("Failed to list accounts for group %s", r), e);
            }
        }
    }
    return reviewers;
}
#method_after
private Set<Account> toAccounts(ReviewDb reviewDb, Set<String> in, Project.NameKey p) {
    return toAccounts(reviewDb, in, p, null);
}
#end_block

#method_before
private Set<Account> toAccounts(ReviewDb reviewDb, Set<String> in, Project.NameKey p, AccountInfo uploader) {
    Set<Account> reviewers = Sets.newHashSetWithExpectedSize(in.size());
    GroupMembers groupMembers = null;
    for (String r : in) {
        try {
            Account account = accountResolver.find(reviewDb, r);
            if (account != null) {
                reviewers.add(account);
                continue;
            }
        } catch (OrmException e) {
            // If the account doesn't exist, find() will return null.  We only
            // get here if something went wrong accessing the database
            log.error("Failed to resolve account " + r, e);
            continue;
        }
        if (groupMembers == null && uploader != null) {
            // email is not unique to one account, try to locate the account using
            // "Full name <email>" to increase chance of finding only one.
            String uploaderNameEmail = String.format("%s <%s>", uploader.name, uploader.email);
            try {
                Account uploaderAccount = accountResolver.findByNameOrEmail(reviewDb, uploaderNameEmail);
                if (uploaderAccount != null) {
                    groupMembers = groupMembersFactory.create(identifiedUserFactory.create(uploaderAccount.getId()));
                }
            } catch (OrmException e) {
                log.warn(String.format("Failed to list accounts for group %s, cannot retrieve uploader account %s", r, uploaderNameEmail), e);
            }
            try {
                if (groupMembers != null) {
                    reviewers.addAll(groupMembers.listAccounts(groupsCollection.get().parse(r).getGroupUUID(), p));
                } else {
                    log.warn(String.format("Failed to list accounts for group %s; cannot retrieve uploader account for %s", r, uploader.email));
                }
            } catch (UnprocessableEntityException | NoSuchGroupException e) {
                log.warn(String.format("Reviewer %s is neither an account nor a group", r));
            } catch (NoSuchProjectException e) {
                log.warn(String.format("Failed to list accounts for group %s and project %s", r, p));
            } catch (IOException | OrmException e) {
                log.warn(String.format("Failed to list accounts for group %s", r), e);
            }
        }
    }
    return reviewers;
}
#method_after
private Set<Account> toAccounts(ReviewDb reviewDb, Set<String> in, Project.NameKey p, @Nullable AccountInfo uploader) {
    Set<Account> reviewers = Sets.newHashSetWithExpectedSize(in.size());
    GroupMembers groupMembers = null;
    for (String r : in) {
        try {
            Account account = accountResolver.find(reviewDb, r);
            if (account != null) {
                reviewers.add(account);
                continue;
            }
        } catch (OrmException e) {
            // If the account doesn't exist, find() will return null.  We only
            // get here if something went wrong accessing the database
            log.error("Failed to resolve account " + r, e);
            continue;
        }
        if (groupMembers == null && uploader != null) {
            // email is not unique to one account, try to locate the account using
            // "Full name <email>" to increase chance of finding only one.
            String uploaderNameEmail = String.format("%s <%s>", uploader.name, uploader.email);
            try {
                Account uploaderAccount = accountResolver.findByNameOrEmail(reviewDb, uploaderNameEmail);
                if (uploaderAccount != null) {
                    groupMembers = groupMembersFactory.create(identifiedUserFactory.create(uploaderAccount.getId()));
                }
            } catch (OrmException e) {
                log.warn(String.format("Failed to list accounts for group %s, cannot retrieve uploader account %s", r, uploaderNameEmail), e);
            }
            try {
                if (groupMembers != null) {
                    reviewers.addAll(groupMembers.listAccounts(groupsCollection.get().parse(r).getGroupUUID(), p));
                } else {
                    log.warn(String.format("Failed to list accounts for group %s; cannot retrieve uploader account for %s", r, uploader.email));
                }
            } catch (UnprocessableEntityException | NoSuchGroupException e) {
                log.warn(String.format("Reviewer %s is neither an account nor a group", r));
            } catch (NoSuchProjectException e) {
                log.warn(String.format("Failed to list accounts for group %s and project %s", r, p));
            } catch (IOException | OrmException e) {
                log.warn(String.format("Failed to list accounts for group %s", r), e);
            }
        }
    }
    return reviewers;
}
#end_block

#method_before
@Override
public List<AccountInfo> apply(GroupResource resource) throws MethodNotAllowedException, OrmException {
    GroupDescription.Internal group = resource.asInternalGroup().orElseThrow(() -> new MethodNotAllowedException("not a Gerrit internal group"));
    if (recursive) {
        return getTransitiveMembers(group, resource.getControl());
    }
    return getDirectMembers(group, resource.getControl());
}
#method_after
@Override
public List<AccountInfo> apply(GroupResource resource) throws NotInternalGroupException, OrmException {
    GroupDescription.Internal group = resource.asInternalGroup().orElseThrow(NotInternalGroupException::new);
    if (recursive) {
        return getTransitiveMembers(group, resource.getControl());
    }
    return getDirectMembers(group, resource.getControl());
}
#end_block

#method_before
@Override
public Boolean callImpl(Provider<ReviewDb> db) throws Exception {
    try {
        if (stalenessChecker.isStale(id)) {
            index(newChangeData(db.get(), project, id));
            return true;
        }
    } catch (NoSuchChangeException nsce) {
        log.debug("Change {} was deleted, aborting reindexing the change.", id.get());
    } catch (Exception e) {
        if (!isCausedByRepositoryNotFoundException(e)) {
            throw e;
        }
        log.debug("Change {} belong to a deleted project, aborting reindexing the change.", id.get());
    }
    return false;
}
#method_after
@Override
public Boolean callImpl(Provider<ReviewDb> db) throws Exception {
    try {
        if (stalenessChecker.isStale(id)) {
            index(newChangeData(db.get(), project, id));
            return true;
        }
    } catch (NoSuchChangeException nsce) {
        log.debug("Change {} was deleted, aborting reindexing the change.", id.get());
    } catch (Exception e) {
        if (!isCausedByRepositoryNotFoundException(e)) {
            throw e;
        }
        log.debug("Change {} belongs to deleted project {}, aborting reindexing the change.", id.get(), project.get());
    }
    return false;
}
#end_block

#method_before
@Override
public Boolean callImpl(Provider<ReviewDb> db) throws Exception {
    try {
        if (stalenessChecker.isStale(id)) {
            index(newChangeData(db.get(), project, id));
            return true;
        }
    } catch (NoSuchChangeException e) {
        log.debug("Change was deleted, aborting reindexing the change");
    }
    return false;
}
#method_after
@Override
public Boolean callImpl(Provider<ReviewDb> db) throws Exception {
    try {
        if (stalenessChecker.isStale(id)) {
            index(newChangeData(db.get(), project, id));
            return true;
        }
    } catch (NoSuchChangeException e) {
        log.debug("Change {} was deleted, aborting reindexing the change.", id.get());
    }
    return false;
}
#end_block

#method_before
@Test
public void webLinkNoRefsMetaConfig() throws Exception {
    RegistrationHandle handle = fileHistoryWebLinkDynamicSet.add(new FileHistoryWebLink() {

        @Override
        public WebLinkInfo getFileHistoryWebLink(String projectName, String revision, String fileName) {
            WebLinkInfo info = new WebLinkInfo("name", "imageURL", "http://view/" + projectName + "/" + fileName);
            return info;
        }
    });
    try {
        ProjectAccessInfo info = pApi.access();
        assertThat(info.configWebLinks).hasSize(1);
        assertThat(info.configWebLinks.get(0).url).isEqualTo("http://view/" + newProjectName + "/project.config");
        try (Repository repo = repoManager.openRepository(new Project.NameKey(newProjectName))) {
            RefUpdate u = repo.updateRef(RefNames.REFS_CONFIG);
            u.setForceUpdate(true);
            assertThat(u.delete()).isEqualTo(Result.FORCED);
            // This should not crash.
            pApi.access();
        }
    } finally {
        handle.remove();
    }
}
#method_after
@Test
public void webLinkNoRefsMetaConfig() throws Exception {
    RegistrationHandle handle = fileHistoryWebLinkDynamicSet.add(new FileHistoryWebLink() {

        @Override
        public WebLinkInfo getFileHistoryWebLink(String projectName, String revision, String fileName) {
            return new WebLinkInfo("name", "imageURL", "http://view/" + projectName + "/" + fileName);
        }
    });
    try (Repository repo = repoManager.openRepository(new Project.NameKey(newProjectName))) {
        RefUpdate u = repo.updateRef(RefNames.REFS_CONFIG);
        u.setForceUpdate(true);
        assertThat(u.delete()).isEqualTo(Result.FORCED);
        // This should not crash.
        pApi.access();
    } finally {
        handle.remove();
    }
}
#end_block

#method_before
@Test
@GerritConfig(name = "change.disablePrivateChanges", value = "true")
public void createChangeWithPrivateByDefaultAndDisablePrivateChangesTrue() throws Exception {
    setPrivateByDefault(project2, InheritableBoolean.TRUE);
    ChangeInput input = new ChangeInput(project2.get(), "master", "empty change");
    exception.expect(BadRequestException.class);
    exception.expectMessage("private changes are not supported");
    gApi.changes().create(input);
}
#method_after
@Test
@GerritConfig(name = "change.disablePrivateChanges", value = "true")
public void createChangeWithPrivateByDefaultAndDisablePrivateChangesTrue() throws Exception {
    setPrivateByDefault(project2, InheritableBoolean.TRUE);
    ChangeInput input = new ChangeInput(project2.get(), "master", "empty change");
    exception.expect(MethodNotAllowedException.class);
    exception.expectMessage("private changes are disabled");
    gApi.changes().create(input);
}
#end_block

#method_before
private void parseMagicBranch(ReceiveCommand cmd) throws PermissionBackendException {
    // Permit exactly one new change request per push.
    if (magicBranch != null) {
        reject(cmd, "duplicate request");
        return;
    }
    logDebug("Found magic branch {}", cmd.getRefName());
    magicBranch = new MagicBranchInput(user, cmd, labelTypes, notesMigration);
    magicBranch.reviewer.addAll(extraReviewers.get(ReviewerStateInternal.REVIEWER));
    magicBranch.cc.addAll(extraReviewers.get(ReviewerStateInternal.CC));
    String ref;
    CmdLineParser clp = optionParserFactory.create(magicBranch);
    magicBranch.clp = clp;
    try {
        ref = magicBranch.parse(clp, repo, rp.getAdvertisedRefs().keySet(), pushOptions);
    } catch (CmdLineException e) {
        if (!clp.wasHelpRequestedByOption()) {
            logDebug("Invalid branch syntax");
            reject(cmd, e.getMessage());
            return;
        }
        // never happen
        ref = null;
    }
    if (magicBranch.topic != null && magicBranch.topic.length() > ChangeUtil.TOPIC_MAX_LENGTH) {
        reject(cmd, String.format("topic length exceeds the limit (%s)", ChangeUtil.TOPIC_MAX_LENGTH));
    }
    if (clp.wasHelpRequestedByOption()) {
        StringWriter w = new StringWriter();
        w.write("\nHelp for refs/for/branch:\n\n");
        clp.printUsage(w, null);
        addMessage(w.toString());
        reject(cmd, "see help");
        return;
    }
    if (projectState.isAllUsers() && RefNames.REFS_USERS_SELF.equals(ref)) {
        logDebug("Handling {}", RefNames.REFS_USERS_SELF);
        ref = RefNames.refsUsers(user.getAccountId());
    }
    if (!rp.getAdvertisedRefs().containsKey(ref) && !ref.equals(readHEAD(repo)) && !ref.equals(RefNames.REFS_CONFIG)) {
        logDebug("Ref {} not found", ref);
        if (ref.startsWith(Constants.R_HEADS)) {
            String n = ref.substring(Constants.R_HEADS.length());
            reject(cmd, "branch " + n + " not found");
        } else {
            reject(cmd, ref + " not found");
        }
        return;
    }
    magicBranch.dest = new Branch.NameKey(project.getNameKey(), ref);
    magicBranch.perm = permissions.ref(ref);
    if (!projectState.getProject().getState().permitsWrite()) {
        reject(cmd, "project state does not permit write");
        return;
    }
    try {
        magicBranch.perm.check(RefPermission.CREATE_CHANGE);
    } catch (AuthException denied) {
        errors.put(ReceiveError.CODE_REVIEW, ref);
        reject(cmd, denied.getMessage());
        return;
    }
    if (magicBranch.isPrivate && magicBranch.removePrivate) {
        reject(cmd, "the options 'private' and 'remove-private' are mutually exclusive");
        return;
    }
    boolean privateByDefault = projectCache.get(project.getNameKey()).is(BooleanProjectConfig.PRIVATE_BY_DEFAULT);
    setChangeAsPrivate = magicBranch.draft || magicBranch.isPrivate || (privateByDefault && !magicBranch.removePrivate);
    if (receiveConfig.disablePrivateChanges && setChangeAsPrivate) {
        reject(cmd, "private changes are not supported");
        return;
    }
    if (magicBranch.workInProgress && magicBranch.ready) {
        reject(cmd, "the options 'wip' and 'ready' are mutually exclusive");
        return;
    }
    if (magicBranch.publishComments && magicBranch.noPublishComments) {
        reject(cmd, "the options 'publish-comments' and 'no-publish-comments' are mutually exclusive");
        return;
    }
    if (magicBranch.submit) {
        try {
            permissions.ref(ref).check(RefPermission.UPDATE_BY_SUBMIT);
        } catch (AuthException e) {
            reject(cmd, e.getMessage());
            return;
        }
    }
    RevWalk walk = rp.getRevWalk();
    RevCommit tip;
    try {
        tip = walk.parseCommit(magicBranch.cmd.getNewId());
        logDebug("Tip of push: {}", tip.name());
    } catch (IOException ex) {
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", ex);
        return;
    }
    String destBranch = magicBranch.dest.get();
    try {
        if (magicBranch.merged) {
            if (magicBranch.base != null) {
                reject(cmd, "cannot use merged with base");
                return;
            }
            RevCommit branchTip = readBranchTip(cmd, magicBranch.dest);
            if (branchTip == null) {
                // readBranchTip already rejected cmd.
                return;
            }
            if (!walk.isMergedInto(tip, branchTip)) {
                reject(cmd, "not merged into branch");
                return;
            }
        }
        // if %base or %merged was specified, ignore newChangeForAllNotInTarget.
        if (tip.getParentCount() > 1 || magicBranch.base != null || magicBranch.merged || tip.getParentCount() == 0) {
            logDebug("Forcing newChangeForAllNotInTarget = false");
            newChangeForAllNotInTarget = false;
        }
        if (magicBranch.base != null) {
            logDebug("Handling %base: {}", magicBranch.base);
            magicBranch.baseCommit = Lists.newArrayListWithCapacity(magicBranch.base.size());
            for (ObjectId id : magicBranch.base) {
                try {
                    magicBranch.baseCommit.add(walk.parseCommit(id));
                } catch (IncorrectObjectTypeException notCommit) {
                    reject(cmd, "base must be a commit");
                    return;
                } catch (MissingObjectException e) {
                    reject(cmd, "base not found");
                    return;
                } catch (IOException e) {
                    logWarn(String.format("Project %s cannot read %s", project.getName(), id.name()), e);
                    reject(cmd, "internal server error");
                    return;
                }
            }
        } else if (newChangeForAllNotInTarget) {
            RevCommit branchTip = readBranchTip(cmd, magicBranch.dest);
            if (branchTip == null) {
                // readBranchTip already rejected cmd.
                return;
            }
            magicBranch.baseCommit = Collections.singletonList(branchTip);
            logDebug("Set baseCommit = {}", magicBranch.baseCommit.get(0).name());
        }
    } catch (IOException ex) {
        logWarn(String.format("Error walking to %s in project %s", destBranch, project.getName()), ex);
        reject(cmd, "internal server error");
        return;
    }
    // 
    try {
        Ref targetRef = rp.getAdvertisedRefs().get(magicBranch.dest.get());
        if (targetRef == null || targetRef.getObjectId() == null) {
            // The destination branch does not yet exist. Assume the
            // history being sent for review will start it and thus
            // is "connected" to the branch.
            logDebug("Branch is unborn");
            return;
        }
        RevCommit h = walk.parseCommit(targetRef.getObjectId());
        logDebug("Current branch tip: {}", h.name());
        RevFilter oldRevFilter = walk.getRevFilter();
        try {
            walk.reset();
            walk.setRevFilter(RevFilter.MERGE_BASE);
            walk.markStart(tip);
            walk.markStart(h);
            if (walk.next() == null) {
                reject(magicBranch.cmd, "no common ancestry");
            }
        } finally {
            walk.reset();
            walk.setRevFilter(oldRevFilter);
        }
    } catch (IOException e) {
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", e);
    }
}
#method_after
private void parseMagicBranch(ReceiveCommand cmd) throws PermissionBackendException {
    // Permit exactly one new change request per push.
    if (magicBranch != null) {
        reject(cmd, "duplicate request");
        return;
    }
    logDebug("Found magic branch {}", cmd.getRefName());
    magicBranch = new MagicBranchInput(user, cmd, labelTypes, notesMigration);
    magicBranch.reviewer.addAll(extraReviewers.get(ReviewerStateInternal.REVIEWER));
    magicBranch.cc.addAll(extraReviewers.get(ReviewerStateInternal.CC));
    String ref;
    CmdLineParser clp = optionParserFactory.create(magicBranch);
    magicBranch.clp = clp;
    try {
        ref = magicBranch.parse(clp, repo, rp.getAdvertisedRefs().keySet(), pushOptions);
    } catch (CmdLineException e) {
        if (!clp.wasHelpRequestedByOption()) {
            logDebug("Invalid branch syntax");
            reject(cmd, e.getMessage());
            return;
        }
        // never happen
        ref = null;
    }
    if (magicBranch.topic != null && magicBranch.topic.length() > ChangeUtil.TOPIC_MAX_LENGTH) {
        reject(cmd, String.format("topic length exceeds the limit (%s)", ChangeUtil.TOPIC_MAX_LENGTH));
    }
    if (clp.wasHelpRequestedByOption()) {
        StringWriter w = new StringWriter();
        w.write("\nHelp for refs/for/branch:\n\n");
        clp.printUsage(w, null);
        addMessage(w.toString());
        reject(cmd, "see help");
        return;
    }
    if (projectState.isAllUsers() && RefNames.REFS_USERS_SELF.equals(ref)) {
        logDebug("Handling {}", RefNames.REFS_USERS_SELF);
        ref = RefNames.refsUsers(user.getAccountId());
    }
    if (!rp.getAdvertisedRefs().containsKey(ref) && !ref.equals(readHEAD(repo)) && !ref.equals(RefNames.REFS_CONFIG)) {
        logDebug("Ref {} not found", ref);
        if (ref.startsWith(Constants.R_HEADS)) {
            String n = ref.substring(Constants.R_HEADS.length());
            reject(cmd, "branch " + n + " not found");
        } else {
            reject(cmd, ref + " not found");
        }
        return;
    }
    magicBranch.dest = new Branch.NameKey(project.getNameKey(), ref);
    magicBranch.perm = permissions.ref(ref);
    if (!projectState.getProject().getState().permitsWrite()) {
        reject(cmd, "project state does not permit write");
        return;
    }
    try {
        magicBranch.perm.check(RefPermission.CREATE_CHANGE);
    } catch (AuthException denied) {
        errors.put(ReceiveError.CODE_REVIEW, ref);
        reject(cmd, denied.getMessage());
        return;
    }
    if (magicBranch.isPrivate && magicBranch.removePrivate) {
        reject(cmd, "the options 'private' and 'remove-private' are mutually exclusive");
        return;
    }
    boolean privateByDefault = projectCache.get(project.getNameKey()).is(BooleanProjectConfig.PRIVATE_BY_DEFAULT);
    setChangeAsPrivate = magicBranch.draft || magicBranch.isPrivate || (privateByDefault && !magicBranch.removePrivate);
    if (receiveConfig.disablePrivateChanges && setChangeAsPrivate) {
        reject(cmd, "private changes are disabled");
        return;
    }
    if (magicBranch.workInProgress && magicBranch.ready) {
        reject(cmd, "the options 'wip' and 'ready' are mutually exclusive");
        return;
    }
    if (magicBranch.publishComments && magicBranch.noPublishComments) {
        reject(cmd, "the options 'publish-comments' and 'no-publish-comments' are mutually exclusive");
        return;
    }
    if (magicBranch.submit) {
        try {
            permissions.ref(ref).check(RefPermission.UPDATE_BY_SUBMIT);
        } catch (AuthException e) {
            reject(cmd, e.getMessage());
            return;
        }
    }
    RevWalk walk = rp.getRevWalk();
    RevCommit tip;
    try {
        tip = walk.parseCommit(magicBranch.cmd.getNewId());
        logDebug("Tip of push: {}", tip.name());
    } catch (IOException ex) {
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", ex);
        return;
    }
    String destBranch = magicBranch.dest.get();
    try {
        if (magicBranch.merged) {
            if (magicBranch.base != null) {
                reject(cmd, "cannot use merged with base");
                return;
            }
            RevCommit branchTip = readBranchTip(cmd, magicBranch.dest);
            if (branchTip == null) {
                // readBranchTip already rejected cmd.
                return;
            }
            if (!walk.isMergedInto(tip, branchTip)) {
                reject(cmd, "not merged into branch");
                return;
            }
        }
        // if %base or %merged was specified, ignore newChangeForAllNotInTarget.
        if (tip.getParentCount() > 1 || magicBranch.base != null || magicBranch.merged || tip.getParentCount() == 0) {
            logDebug("Forcing newChangeForAllNotInTarget = false");
            newChangeForAllNotInTarget = false;
        }
        if (magicBranch.base != null) {
            logDebug("Handling %base: {}", magicBranch.base);
            magicBranch.baseCommit = Lists.newArrayListWithCapacity(magicBranch.base.size());
            for (ObjectId id : magicBranch.base) {
                try {
                    magicBranch.baseCommit.add(walk.parseCommit(id));
                } catch (IncorrectObjectTypeException notCommit) {
                    reject(cmd, "base must be a commit");
                    return;
                } catch (MissingObjectException e) {
                    reject(cmd, "base not found");
                    return;
                } catch (IOException e) {
                    logWarn(String.format("Project %s cannot read %s", project.getName(), id.name()), e);
                    reject(cmd, "internal server error");
                    return;
                }
            }
        } else if (newChangeForAllNotInTarget) {
            RevCommit branchTip = readBranchTip(cmd, magicBranch.dest);
            if (branchTip == null) {
                // readBranchTip already rejected cmd.
                return;
            }
            magicBranch.baseCommit = Collections.singletonList(branchTip);
            logDebug("Set baseCommit = {}", magicBranch.baseCommit.get(0).name());
        }
    } catch (IOException ex) {
        logWarn(String.format("Error walking to %s in project %s", destBranch, project.getName()), ex);
        reject(cmd, "internal server error");
        return;
    }
    // 
    try {
        Ref targetRef = rp.getAdvertisedRefs().get(magicBranch.dest.get());
        if (targetRef == null || targetRef.getObjectId() == null) {
            // The destination branch does not yet exist. Assume the
            // history being sent for review will start it and thus
            // is "connected" to the branch.
            logDebug("Branch is unborn");
            return;
        }
        RevCommit h = walk.parseCommit(targetRef.getObjectId());
        logDebug("Current branch tip: {}", h.name());
        RevFilter oldRevFilter = walk.getRevFilter();
        try {
            walk.reset();
            walk.setRevFilter(RevFilter.MERGE_BASE);
            walk.markStart(tip);
            walk.markStart(h);
            if (walk.next() == null) {
                reject(magicBranch.cmd, "no common ancestry");
            }
        } finally {
            walk.reset();
            walk.setRevFilter(oldRevFilter);
        }
    } catch (IOException e) {
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", e);
    }
}
#end_block

#method_before
private void autoCloseChanges(ReceiveCommand cmd) {
    logDebug("Starting auto-closing of changes");
    String refName = cmd.getRefName();
    checkState(!MagicBranch.isMagicBranch(refName), "shouldn't be auto-closing changes on magic branch %s", refName);
    // insertChangesAndPatchSets.
    try (BatchUpdate bu = batchUpdateFactory.create(db, projectState.getNameKey(), user, TimeUtil.nowTs());
        ObjectInserter ins = repo.newObjectInserter();
        ObjectReader reader = ins.newReader();
        RevWalk rw = new RevWalk(reader)) {
        bu.setRepository(repo, rw, ins).updateChangesInParallel();
        bu.setRequestId(receiveId);
        // TODO(dborowitz): Teach BatchUpdate to ignore missing changes.
        RevCommit newTip = rw.parseCommit(cmd.getNewId());
        Branch.NameKey branch = new Branch.NameKey(project.getNameKey(), refName);
        rw.reset();
        rw.markStart(newTip);
        if (!ObjectId.zeroId().equals(cmd.getOldId())) {
            rw.markUninteresting(rw.parseCommit(cmd.getOldId()));
        }
        ListMultimap<ObjectId, Ref> byCommit = changeRefsById();
        Map<Change.Key, ChangeNotes> byKey = null;
        List<ReplaceRequest> replaceAndClose = new ArrayList<>();
        int existingPatchSets = 0;
        int newPatchSets = 0;
        COMMIT: for (RevCommit c; (c = rw.next()) != null; ) {
            rw.parseBody(c);
            for (Ref ref : byCommit.get(c.copy())) {
                PatchSet.Id psId = PatchSet.Id.fromRef(ref.getName());
                Optional<ChangeData> cd = byLegacyId(psId.getParentKey());
                if (cd.isPresent() && cd.get().change().getDest().equals(branch)) {
                    existingPatchSets++;
                    bu.addOp(psId.getParentKey(), mergedByPushOpFactory.create(requestScopePropagator, psId, refName));
                    continue COMMIT;
                }
            }
            for (String changeId : c.getFooterLines(CHANGE_ID)) {
                if (byKey == null) {
                    byKey = openChangesByKeyByBranch(branch);
                }
                ChangeNotes onto = byKey.get(new Change.Key(changeId.trim()));
                if (onto != null) {
                    newPatchSets++;
                    // Hold onto this until we're done with the walk, as the call to
                    // req.validate below calls isMergedInto which resets the walk.
                    ReplaceRequest req = new ReplaceRequest(onto.getChangeId(), c, cmd, false);
                    req.notes = onto;
                    replaceAndClose.add(req);
                    continue COMMIT;
                }
            }
        }
        for (ReplaceRequest req : replaceAndClose) {
            Change.Id id = req.notes.getChangeId();
            if (!req.validate(true)) {
                logDebug("Not closing {} because validation failed", id);
                continue;
            }
            req.addOps(bu, null);
            bu.addOp(id, mergedByPushOpFactory.create(requestScopePropagator, req.psId, refName).setPatchSetProvider(new Provider<PatchSet>() {

                @Override
                public PatchSet get() {
                    return req.replaceOp.getPatchSet();
                }
            }));
            bu.addOp(id, new ChangeProgressOp(closeProgress));
        }
        logDebug("Auto-closing {} changes with existing patch sets and {} with new patch sets", existingPatchSets, newPatchSets);
        bu.execute();
    } catch (RestApiException e) {
        logError("Can't insert patchset", e);
    } catch (IOException | OrmException | UpdateException | PermissionBackendException e) {
        logError("Can't scan for changes to close", e);
    }
}
#method_after
private void autoCloseChanges(ReceiveCommand cmd) {
    logDebug("Starting auto-closing of changes");
    String refName = cmd.getRefName();
    checkState(!MagicBranch.isMagicBranch(refName), "shouldn't be auto-closing changes on magic branch %s", refName);
    // insertChangesAndPatchSets.
    try {
        retryHelper.execute(updateFactory -> {
            try (BatchUpdate bu = updateFactory.create(db, projectState.getNameKey(), user, TimeUtil.nowTs());
                ObjectInserter ins = repo.newObjectInserter();
                ObjectReader reader = ins.newReader();
                RevWalk rw = new RevWalk(reader)) {
                bu.setRepository(repo, rw, ins).updateChangesInParallel();
                bu.setRequestId(receiveId);
                // TODO(dborowitz): Teach BatchUpdate to ignore missing changes.
                RevCommit newTip = rw.parseCommit(cmd.getNewId());
                Branch.NameKey branch = new Branch.NameKey(project.getNameKey(), refName);
                rw.reset();
                rw.markStart(newTip);
                if (!ObjectId.zeroId().equals(cmd.getOldId())) {
                    rw.markUninteresting(rw.parseCommit(cmd.getOldId()));
                }
                ListMultimap<ObjectId, Ref> byCommit = changeRefsById();
                Map<Change.Key, ChangeNotes> byKey = null;
                List<ReplaceRequest> replaceAndClose = new ArrayList<>();
                int existingPatchSets = 0;
                int newPatchSets = 0;
                COMMIT: for (RevCommit c; (c = rw.next()) != null; ) {
                    rw.parseBody(c);
                    for (Ref ref : byCommit.get(c.copy())) {
                        PatchSet.Id psId = PatchSet.Id.fromRef(ref.getName());
                        Optional<ChangeData> cd = retryHelper.execute(ActionType.CHANGE_QUERY, () -> byLegacyId(psId.getParentKey()), t -> t instanceof OrmException);
                        if (cd.isPresent() && cd.get().change().getDest().equals(branch)) {
                            existingPatchSets++;
                            bu.addOp(psId.getParentKey(), mergedByPushOpFactory.create(requestScopePropagator, psId, refName));
                            continue COMMIT;
                        }
                    }
                    for (String changeId : c.getFooterLines(CHANGE_ID)) {
                        if (byKey == null) {
                            byKey = retryHelper.execute(ActionType.CHANGE_QUERY, () -> openChangesByKeyByBranch(branch), t -> t instanceof OrmException);
                        }
                        ChangeNotes onto = byKey.get(new Change.Key(changeId.trim()));
                        if (onto != null) {
                            newPatchSets++;
                            // Hold onto this until we're done with the walk, as the call to
                            // req.validate below calls isMergedInto which resets the walk.
                            ReplaceRequest req = new ReplaceRequest(onto.getChangeId(), c, cmd, false);
                            req.notes = onto;
                            replaceAndClose.add(req);
                            continue COMMIT;
                        }
                    }
                }
                for (ReplaceRequest req : replaceAndClose) {
                    Change.Id id = req.notes.getChangeId();
                    if (!req.validate(true)) {
                        logDebug("Not closing {} because validation failed", id);
                        continue;
                    }
                    req.addOps(bu, null);
                    bu.addOp(id, mergedByPushOpFactory.create(requestScopePropagator, req.psId, refName).setPatchSetProvider(new Provider<PatchSet>() {

                        @Override
                        public PatchSet get() {
                            return req.replaceOp.getPatchSet();
                        }
                    }));
                    bu.addOp(id, new ChangeProgressOp(closeProgress));
                }
                logDebug("Auto-closing {} changes with existing patch sets and {} with new patch sets", existingPatchSets, newPatchSets);
                bu.execute();
            } catch (IOException | OrmException | PermissionBackendException e) {
                logError("Failed to auto-close changes", e);
            }
            return null;
        }, // eat up the whole timeout so that no time is left to retry this outer action.
        RetryHelper.options().timeout(retryHelper.getDefaultTimeout().multipliedBy(5)).build());
    } catch (RestApiException e) {
        logError("Can't insert patchset", e);
    } catch (UpdateException e) {
        logError("Failed to auto-close changes", e);
    }
}
#end_block

#method_before
private void updateAccountInfo() {
    if (setFullNameTo == null) {
        return;
    }
    logDebug("Updating full name of caller");
    try {
        Account account = accountsUpdate.create().update(user.getAccountId(), a -> {
            if (Strings.isNullOrEmpty(a.getFullName())) {
                a.setFullName(setFullNameTo);
            }
        });
        if (account != null) {
            user.getAccount().setFullName(account.getFullName());
        }
    } catch (IOException | ConfigInvalidException e) {
        logWarn("Failed to update full name of caller", e);
    }
}
#method_after
private void updateAccountInfo() {
    if (setFullNameTo == null) {
        return;
    }
    logDebug("Updating full name of caller");
    try {
        Account account = accountsUpdate.create().update("Set Full Name on Receive Commits", user.getAccountId(), (a, u) -> {
            if (Strings.isNullOrEmpty(a.getFullName())) {
                u.setFullName(setFullNameTo);
            }
        });
        if (account != null) {
            user.getAccount().setFullName(account.getFullName());
        }
    } catch (OrmException | IOException | ConfigInvalidException e) {
        logWarn("Failed to update full name of caller", e);
    }
}
#end_block

#method_before
private Map<Change.Key, ChangeNotes> openChangesByKeyByBranch(Branch.NameKey branch) throws OrmException {
    Map<Change.Key, ChangeNotes> r = new HashMap<>();
    for (ChangeData cd : queryProvider.get().byBranchOpen(branch)) {
        r.put(cd.change().getKey(), cd.notes());
    }
    return r;
}
#method_after
private Map<Change.Key, ChangeNotes> openChangesByKeyByBranch(Branch.NameKey branch) throws OrmException {
    Map<Change.Key, ChangeNotes> r = new HashMap<>();
    for (ChangeData cd : queryProvider.get().byBranchOpen(branch)) {
        try {
            r.put(cd.change().getKey(), cd.notes());
        } catch (NoSuchChangeException e) {
        // Ignore deleted change
        }
    }
    return r;
}
#end_block

#method_before
@Test
public void blockPushDrafts() {
    allow(parent, PUSH, REGISTERED_USERS, "refs/for/refs/*");
    block(parent, PUSH, ANONYMOUS_USERS, "refs/drafts/*");
    allow(local, PUSH, REGISTERED_USERS, "refs/drafts/*");
    ProjectControl u = user(local);
    assertCreateChange("refs/heads/master", u);
    assertThat(u.controlForRef("refs/drafst/master").canPerform(PUSH)).isFalse();
}
#method_after
@Test
public void blockPushDrafts() {
    allow(parent, PUSH, REGISTERED_USERS, "refs/for/refs/*");
    block(parent, PUSH, ANONYMOUS_USERS, "refs/drafts/*");
    allow(local, PUSH, REGISTERED_USERS, "refs/drafts/*");
    ProjectControl u = user(local);
    assertCreateChange("refs/heads/master", u);
    assertThat(u.controlForRef("refs/drafts/master").canPerform(PUSH)).isFalse();
}
#end_block

#method_before
public void testOwnerProject() {
    local.add(grant(OWN, admin, "refs/*", 1));
    ProjectControl uBlah = user(devs);
    ProjectControl uAdmin = user(devs, admin);
    assertFalse("not owner", uBlah.isOwner());
    assertTrue("is owner", uAdmin.isOwner());
}
#method_after
public void testOwnerProject() {
    grant(local, OWN, admin, "refs/*", 1);
    ProjectControl uBlah = user(devs);
    ProjectControl uAdmin = user(devs, admin);
    assertFalse("not owner", uBlah.isOwner());
    assertTrue("is owner", uAdmin.isOwner());
}
#end_block

#method_before
public void testBranchDelegation1() {
    local.add(grant(OWN, admin, "refs/*", 1));
    local.add(grant(OWN, devs, "refs/heads/x/*", 1));
    ProjectControl uDev = user(devs);
    assertFalse("not owner", uDev.isOwner());
    assertTrue("owns ref", uDev.isOwnerAnyRef());
    assertOwner("refs/heads/x/*", uDev);
    assertOwner("refs/heads/x/y", uDev);
    assertOwner("refs/heads/x/y/*", uDev);
    assertNotOwner("refs/*", uDev);
    assertNotOwner("refs/heads/master", uDev);
}
#method_after
public void testBranchDelegation1() {
    grant(local, OWN, admin, "refs/*", 1);
    grant(local, OWN, devs, "refs/heads/x/*", 1);
    ProjectControl uDev = user(devs);
    assertFalse("not owner", uDev.isOwner());
    assertTrue("owns ref", uDev.isOwnerAnyRef());
    assertOwner("refs/heads/x/*", uDev);
    assertOwner("refs/heads/x/y", uDev);
    assertOwner("refs/heads/x/y/*", uDev);
    assertNotOwner("refs/*", uDev);
    assertNotOwner("refs/heads/master", uDev);
}
#end_block

#method_before
public void testBranchDelegation2() {
    local.add(grant(OWN, admin, "refs/*", 1));
    local.add(grant(OWN, devs, "refs/heads/x/*", 1));
    local.add(grant(OWN, fixers, "-refs/heads/x/y/*", 1));
    ProjectControl uDev = user(devs);
    assertFalse("not owner", uDev.isOwner());
    assertTrue("owns ref", uDev.isOwnerAnyRef());
    assertOwner("refs/heads/x/*", uDev);
    assertOwner("refs/heads/x/y", uDev);
    assertOwner("refs/heads/x/y/*", uDev);
    assertNotOwner("refs/*", uDev);
    assertNotOwner("refs/heads/master", uDev);
    ProjectControl uFix = user(fixers);
    assertFalse("not owner", uFix.isOwner());
    assertTrue("owns ref", uFix.isOwnerAnyRef());
    assertOwner("refs/heads/x/y/*", uFix);
    assertOwner("refs/heads/x/y/bar", uFix);
    assertNotOwner("refs/heads/x/*", uFix);
    assertNotOwner("refs/heads/x/y", uFix);
    assertNotOwner("refs/*", uFix);
    assertNotOwner("refs/heads/master", uFix);
}
#method_after
public void testBranchDelegation2() {
    grant(local, OWN, admin, "refs/*", 1);
    grant(local, OWN, devs, "refs/heads/x/*", 1);
    grant(local, OWN, fixers, "-refs/heads/x/y/*", 1);
    ProjectControl uDev = user(devs);
    assertFalse("not owner", uDev.isOwner());
    assertTrue("owns ref", uDev.isOwnerAnyRef());
    assertOwner("refs/heads/x/*", uDev);
    assertOwner("refs/heads/x/y", uDev);
    assertOwner("refs/heads/x/y/*", uDev);
    assertNotOwner("refs/*", uDev);
    assertNotOwner("refs/heads/master", uDev);
    ProjectControl uFix = user(fixers);
    assertFalse("not owner", uFix.isOwner());
    assertTrue("owns ref", uFix.isOwnerAnyRef());
    assertOwner("refs/heads/x/y/*", uFix);
    assertOwner("refs/heads/x/y/bar", uFix);
    assertNotOwner("refs/heads/x/*", uFix);
    assertNotOwner("refs/heads/x/y", uFix);
    assertNotOwner("refs/*", uFix);
    assertNotOwner("refs/heads/master", uFix);
}
#end_block

#method_before
public void testInheritRead_SingleBranchDeniesUpload() {
    inherited.add(grant(READ, registered, "refs/*", 1, 2));
    local.add(grant(READ, registered, "-refs/heads/foobar", 1, 1));
    ProjectControl u = user();
    assertTrue("can upload", u.canPushToAtLeastOneRef());
    assertTrue(// 
    "can upload refs/heads/master", u.controlForRef("refs/heads/master").canUpload());
    assertFalse(// 
    "deny refs/heads/foobar", u.controlForRef("refs/heads/foobar").canUpload());
}
#method_after
public void testInheritRead_SingleBranchDeniesUpload() {
    grant(parent, READ, registered, "refs/*", 1, 2);
    grant(local, READ, registered, "-refs/heads/foobar", 1);
    ProjectControl u = user();
    assertTrue("can upload", u.canPushToAtLeastOneRef());
    assertTrue(// 
    "can upload refs/heads/master", u.controlForRef("refs/heads/master").canUpload());
    assertFalse(// 
    "deny refs/heads/foobar", u.controlForRef("refs/heads/foobar").canUpload());
}
#end_block

#method_before
public void testInheritRead_SingleBranchDoesNotOverrideInherited() {
    inherited.add(grant(READ, registered, "refs/*", 1, 2));
    local.add(grant(READ, registered, "refs/heads/foobar", 1, 1));
    ProjectControl u = user();
    assertTrue("can upload", u.canPushToAtLeastOneRef());
    assertTrue(// 
    "can upload refs/heads/master", u.controlForRef("refs/heads/master").canUpload());
    assertTrue(// 
    "can upload refs/heads/foobar", u.controlForRef("refs/heads/foobar").canUpload());
}
#method_after
public void testInheritRead_SingleBranchDoesNotOverrideInherited() {
    grant(parent, READ, registered, "refs/*", 1, 2);
    grant(local, READ, registered, "refs/heads/foobar", 1);
    ProjectControl u = user();
    assertTrue("can upload", u.canPushToAtLeastOneRef());
    assertTrue(// 
    "can upload refs/heads/master", u.controlForRef("refs/heads/master").canUpload());
    assertTrue(// 
    "can upload refs/heads/foobar", u.controlForRef("refs/heads/foobar").canUpload());
}
#end_block

#method_before
public void testInheritRead_OverrideWithDeny() {
    inherited.add(grant(READ, registered, "refs/*", 1, 1));
    local.add(grant(READ, registered, "refs/*", -1, -1));
    ProjectControl u = user();
    assertFalse("can't read", u.isVisible());
}
#method_after
public void testInheritRead_OverrideWithDeny() {
    grant(parent, READ, registered, "refs/*", 1);
    grant(local, READ, registered, "refs/*", 0);
    ProjectControl u = user();
    assertFalse("can't read", u.isVisible());
}
#end_block

#method_before
public void testInheritRead_OverridesAndDeniesOfRef() {
    inherited.add(grant(READ, registered, "refs/*", 1, 1));
    local.add(grant(READ, registered, "refs/*", -1, -1));
    local.add(grant(READ, registered, "refs/heads/*", -1, 1));
    ProjectControl u = user();
    assertTrue("can read", u.isVisible());
    assertFalse("can't read", u.controlForRef("refs/foobar").isVisible());
    assertTrue("can read", u.controlForRef("refs/heads/foobar").isVisible());
}
#method_after
public void testInheritRead_OverridesAndDeniesOfRef() {
    grant(parent, READ, registered, "refs/*", 1);
    grant(local, READ, registered, "refs/*", 0);
    grant(local, READ, registered, "refs/heads/*", -1, 1);
    ProjectControl u = user();
    assertTrue("can read", u.isVisible());
    assertFalse("can't read", u.controlForRef("refs/foobar").isVisible());
    assertFalse("can't read", u.controlForRef("refs/tags/foobar").isVisible());
    assertTrue("can read", u.controlForRef("refs/heads/foobar").isVisible());
}
#end_block

#method_before
public void testInheritSubmit_OverridesAndDeniesOfRef() {
    inherited.add(grant(SUBMIT, registered, "refs/*", 1, 1));
    local.add(grant(SUBMIT, registered, "refs/*", -1, -1));
    local.add(grant(SUBMIT, registered, "refs/heads/*", -1, 1));
    ProjectControl u = user();
    assertFalse("can't submit", u.controlForRef("refs/foobar").canSubmit());
    assertTrue("can submit", u.controlForRef("refs/heads/foobar").canSubmit());
}
#method_after
public void testInheritSubmit_OverridesAndDeniesOfRef() {
    grant(parent, SUBMIT, registered, "refs/*", 1);
    grant(local, SUBMIT, registered, "refs/*", 0);
    grant(local, SUBMIT, registered, "refs/heads/*", -1, 1);
    ProjectControl u = user();
    assertFalse("can't submit", u.controlForRef("refs/foobar").canSubmit());
    assertFalse("can't submit", u.controlForRef("refs/tags/foobar").canSubmit());
    assertTrue("can submit", u.controlForRef("refs/heads/foobar").canSubmit());
}
#end_block

#method_before
public void testCannotUploadToAnyRef() {
    inherited.add(grant(READ, registered, "refs/*", 1, 1));
    local.add(grant(READ, devs, "refs/heads/*", 1, 2));
    ProjectControl u = user();
    assertFalse("cannot upload", u.canPushToAtLeastOneRef());
    assertFalse(// 
    "cannot upload refs/heads/master", u.controlForRef("refs/heads/master").canUpload());
}
#method_after
public void testCannotUploadToAnyRef() {
    grant(parent, READ, registered, "refs/*", 1);
    grant(local, READ, devs, "refs/heads/*", 1, 2);
    ProjectControl u = user();
    assertFalse("cannot upload", u.canPushToAtLeastOneRef());
    assertFalse(// 
    "cannot upload refs/heads/master", u.controlForRef("refs/heads/master").canUpload());
}
#end_block

#method_before
@Override
protected void setUp() throws Exception {
    super.setUp();
    local = new ArrayList<RefRight>();
    inherited = new ArrayList<RefRight>();
}
#method_after
@Override
protected void setUp() throws Exception {
    super.setUp();
    localRights = new ArrayList<RefRight>();
    inheritedRights = new ArrayList<RefRight>();
}
#end_block

#method_before
private RefRight grant(ApprovalCategory.Id categoryId, AccountGroup.Id group, String ref, int minValue, int maxValue) {
    RefRight right = new RefRight(new RefRight.Key(projectNameKey, new RefPattern(ref), categoryId, group));
    right.setMinValue((short) minValue);
    right.setMaxValue((short) maxValue);
    return right;
}
#method_after
private void grant(Project.NameKey project, ApprovalCategory.Id categoryId, AccountGroup.Id group, String ref, int maxValue) {
    grant(project, categoryId, group, ref, maxValue, maxValue);
}
#end_block

#method_before
private ProjectState newProjectState() {
    ProjectCache projectCache = null;
    Project.NameKey wildProject = null;
    ProjectControl.AssistedFactory projectControlFactory = null;
    ProjectState ps = new ProjectState(anonymousUser, projectCache, wildProject, projectControlFactory, new Project(projectNameKey), local);
    ps.setInheritedRights(inherited);
    return ps;
}
#method_after
private ProjectState newProjectState() {
    ProjectCache projectCache = null;
    Project.NameKey wildProject = null;
    ProjectControl.AssistedFactory projectControlFactory = null;
    ProjectState ps = new ProjectState(anonymousUser, projectCache, wildProject, projectControlFactory, new Project(parent), localRights);
    ps.setInheritedRights(inheritedRights);
    return ps;
}
#end_block

#method_before
public Collection<RefRight> getAllRights(ApprovalCategory.Id action, boolean dropOverriden) {
    Collection<RefRight> rights = new LinkedList<RefRight>(getLocalRights(action));
    if (action.canInheritFromWildProject()) {
        rights.addAll(filter(getInheritedRights(), action));
    }
    if (dropOverriden) {
        Set<String> exist = new HashSet<String>();
        Iterator<RefRight> iter = rights.iterator();
        while (iter.hasNext()) {
            RefRight right = iter.next();
            String key = right.getProjectNameKey().get() + "#" + right.getApprovalCategoryId().get() + "#" + right.getAccountGroupId().get() + "#" + right.getRefPattern();
            if (exist.contains(key)) {
                iter.remove();
            } else {
                exist.add(key);
            }
        }
    }
    return Collections.unmodifiableCollection(rights);
}
#method_after
public Collection<RefRight> getAllRights(ApprovalCategory.Id action, boolean dropOverridden) {
    Collection<RefRight> rights = new LinkedList<RefRight>(getLocalRights(action));
    if (action.canInheritFromWildProject()) {
        rights.addAll(filter(getInheritedRights(), action));
    }
    if (dropOverridden) {
        Set<Grant> grants = new HashSet<Grant>();
        Iterator<RefRight> iter = rights.iterator();
        while (iter.hasNext()) {
            RefRight right = iter.next();
            Grant grant = new Grant(right.getAccountGroupId(), right.getRefPattern());
            if (grants.contains(grant)) {
                iter.remove();
            } else {
                grants.add(grant);
            }
        }
    }
    return Collections.unmodifiableCollection(rights);
}
#end_block

#method_before
String getBaseUrl() {
    return baseUrl;
}
#method_after
@VisibleForTesting
String getBaseUrl() {
    return baseUrl;
}
#end_block

#method_before
private HttpURLConnection prepHttpConnection(String spec, boolean isPostRequest) throws IOException {
    String urlWithSpec = baseUrl + spec;
    URL url = new URL(urlWithSpec);
    ProxySelector proxySelector = ProxySelector.getDefault();
    Proxy proxy = HttpSupport.proxyFor(proxySelector, url);
    HttpURLConnection conn = (HttpURLConnection) url.openConnection(proxy);
    conn.setRequestProperty("Authorization", "Basic " + auth);
    conn.setRequestProperty("Content-Type", "application/json");
    if (isPostRequest) {
        conn.setRequestMethod("POST");
        conn.setDoOutput(true);
    } else {
        conn.setRequestMethod("GET");
    }
    return conn;
}
#method_after
private HttpURLConnection prepHttpConnection(String spec, boolean isPostRequest) throws IOException {
    URL url = new URL(baseUrl + spec);
    ProxySelector proxySelector = ProxySelector.getDefault();
    Proxy proxy = HttpSupport.proxyFor(proxySelector, url);
    HttpURLConnection conn = (HttpURLConnection) url.openConnection(proxy);
    conn.setRequestProperty("Authorization", "Basic " + auth);
    conn.setRequestProperty("Content-Type", "application/json");
    if (isPostRequest) {
        conn.setRequestMethod("POST");
        conn.setDoOutput(true);
    } else {
        conn.setRequestMethod("GET");
    }
    return conn;
}
#end_block

#method_before
@Override
public void validateNewProject(CreateProjectArgs args) throws ValidationException {
    String name = args.getProjectName();
    log.debug("validating creation of {}", name);
    ProjectControl parentCtrl;
    try {
        parentCtrl = projectControlFactory.controlFor(args.newParent, self.get());
    } catch (NoSuchProjectException | IOException e) {
        log.error("Failed to create project " + name + "; Cannot retrieve info about parent project " + args.newParent.get() + ": " + e.getMessage(), e);
        throw new ValidationException(AN_ERROR_OCCURRED_MSG);
    }
    try {
        permissionBackend.user(self).check(GlobalPermission.ADMINISTRATE_SERVER);
        // Admins can bypass any rules to support creating projects that doesn't
        // comply with the new naming rules. New projects structures have to
        // comply but we need to be able to add new project to an existing non
        // compliant structure.
        log.debug("admin is creating project, bypassing all rules");
        return;
    } catch (AuthException | PermissionBackendException e) {
    // continuing
    }
    if (allProjectsName.get().equals(parentCtrl.getProject().getNameKey())) {
        validateRootProject(name, args.permissionsOnly);
    } else {
        validateProject(name, parentCtrl);
    }
    // user an owner if not already by inheritance.
    if (!parentCtrl.isOwner() && !configDisableGrantingOwnership(parentCtrl)) {
        args.ownerIds.add(createGroup(name + "-admins"));
    }
}
#method_after
@Override
public void validateNewProject(CreateProjectArgs args) throws ValidationException {
    String name = args.getProjectName();
    log.debug("validating creation of {}", name);
    ProjectControl parentCtrl;
    try {
        parentCtrl = projectControlFactory.controlFor(args.newParent, self.get());
    } catch (NoSuchProjectException | IOException e) {
        log.error("Failed to create project {}; Cannot retrieve info about parent project {}: {}", name, args.newParent.get(), e.getMessage(), e);
        throw new ValidationException(AN_ERROR_OCCURRED_MSG);
    }
    try {
        permissionBackend.user(self).check(GlobalPermission.ADMINISTRATE_SERVER);
        // Admins can bypass any rules to support creating projects that doesn't
        // comply with the new naming rules. New projects structures have to
        // comply but we need to be able to add new project to an existing non
        // compliant structure.
        log.debug("admin is creating project, bypassing all rules");
        return;
    } catch (AuthException | PermissionBackendException e) {
    // continuing
    }
    if (allProjectsName.get().equals(parentCtrl.getProject().getNameKey())) {
        validateRootProject(name, args.permissionsOnly);
    } else {
        validateProject(name, parentCtrl);
    }
    // user an owner if not already by inheritance.
    if (!parentCtrl.isOwner() && !configDisableGrantingOwnership(parentCtrl)) {
        args.ownerIds.add(createGroup(name + "-admins"));
    }
}
#end_block

#method_before
public Optional<T> deserialize(String input) {
    Optional<String> decrypted = cipher.decrypt(input);
    if (!decrypted.isPresent()) {
        return Optional.absent();
    }
    return createToken(Splitter.on(DELIMETER).splitToList(decrypted.get()));
}
#method_after
public Optional<T> deserialize(String input) {
    Optional<String> decrypted = cipher.decrypt(input);
    if (!decrypted.isPresent()) {
        return Optional.empty();
    }
    return createToken(Splitter.on(DELIMETER).splitToList(decrypted.get()));
}
#end_block

#method_before
static boolean onTime(String dateTime) {
    String now = LfsAuthToken.ISO.format(now());
    return now.compareTo(dateTime) <= 0;
}
#method_after
static boolean onTime(String dateTime) {
    return FORMAT.now().compareTo(dateTime) <= 0;
}
#end_block

#method_before
static String timeout(int expirationSeconds) {
    return LfsAuthToken.ISO.format(now().plusSeconds(expirationSeconds));
}
#method_after
static String timeout(int expirationSeconds) {
    return FORMAT.now(expirationSeconds);
}
#end_block

#method_before
@Test
public void testExpiredTime() throws Exception {
    // test that even 1ms expiration is enough
    assertThat(onTime(ISO.format(now().minusMillis(1)))).isFalse();
}
#method_after
@Test
public void testExpiredTime() throws Exception {
    // test that even 1ms expiration is enough
    assertThat(onTime(formatter.format(now().minusMillis(1)))).isFalse();
}
#end_block

#method_before
@Test
public void testOnTime() throws Exception {
    // if there is at least 1ms before there is no timeout
    assertThat(onTime(ISO.format(now().plusMillis(1)))).isTrue();
}
#method_after
@Test
public void testOnTime() throws Exception {
    // if there is at least 1ms before there is no timeout
    assertThat(onTime(formatter.format(now().plusMillis(1)))).isTrue();
}
#end_block

#method_before
void load() {
    if (!Files.exists(locksPath)) {
        return;
    }
    try {
        Files.list(locksPath).filter(Files::isRegularFile).forEach(path -> {
            if (!Files.isReadable(path)) {
                log.warn("Lock file [{}] in project {} is not readable", path, project);
                return;
            }
            try (Reader in = Files.newBufferedReader(path)) {
                LfsLock lock = gson.fromJson(in, LfsLock.class);
                locks.put(lock.id, lock);
            } catch (IOException e) {
                log.warn("Reading lock [{}] failed", path, e);
            }
        });
    } catch (IOException e) {
        log.warn("Reading locks in project {} failed", project, e);
    }
}
#method_after
void load() {
    if (!Files.exists(locksPath)) {
        return;
    }
    try (Stream<Path> stream = Files.list(locksPath)) {
        stream.filter(Files::isRegularFile).forEach(path -> {
            if (!Files.isReadable(path)) {
                log.warn("Lock file [{}] in project {} is not readable", path, project);
                return;
            }
            try (Reader in = Files.newBufferedReader(path)) {
                LfsLock lock = gson.fromJson(in, LfsLock.class);
                locks.put(lock.id, lock);
            } catch (IOException e) {
                log.warn("Reading lock [{}] failed", path, e);
            }
        });
    } catch (IOException e) {
        log.warn("Reading locks in project {} failed", project, e);
    }
}
#end_block

#method_before
LfsLock createLock(CurrentUser user, LfsCreateLockInput input) throws LfsException {
    log.debug("Create lock for {} in project {}", input.path, project);
    String lockId = toLockId.apply(input.path);
    LfsLock lock = locks.getIfPresent(lockId);
    if (lock != null) {
        throw new LfsLockExistsException(lock);
    }
    lock = new LfsLock(lockId, input.path, now(), new LfsLockOwner(user.getUserName()));
    LockFile fileLock = new LockFile(locksPath.resolve(lockId).toFile());
    try {
        if (!fileLock.lock()) {
            log.warn("Cannot lock path [{}] in project {}", input.path, project);
            throw new LfsLockExistsException(lock);
        }
    } catch (IOException e) {
        String error = String.format("Locking path [%s] in project %s failed with error %s", input.path, project, e.getMessage());
        log.warn(error);
        throw new LfsException(error);
    }
    try {
        try (OutputStreamWriter out = new OutputStreamWriter(fileLock.getOutputStream())) {
            gson.toJson(lock, out);
        } catch (IOException e) {
            String error = String.format("Locking path [%s] in project %s failed during write with error %s", input.path, project, e.getMessage());
            log.warn(error);
            throw new LfsException(error);
        }
        if (!fileLock.commit()) {
            String error = String.format("Committing lock to path [%s] in project %s failed", input.path, project);
            log.warn(error);
            throw new LfsException(error);
        }
        // put lock object to cache while file lock is being hold so that
        // there is no chance that other process performs lock operation
        // in the meantime (either cache returns with existing object or
        // LockFile.lock fails on locking attempt)
        locks.put(lockId, lock);
    } finally {
        fileLock.unlock();
    }
    return lock;
}
#method_after
LfsLock createLock(CurrentUser user, LfsCreateLockInput input) throws LfsException {
    log.debug("Create lock for {} in project {}", input.path, project);
    String lockId = toLockId.apply(input.path);
    LfsLock lock = locks.getIfPresent(lockId);
    if (lock != null) {
        throw new LfsLockExistsException(lock);
    }
    lock = new LfsLock(lockId, input.path, FORMAT.now(), new LfsLockOwner(user.getUserName().get()));
    LockFile fileLock = new LockFile(locksPath.resolve(lockId).toFile());
    try {
        if (!fileLock.lock()) {
            log.warn("Cannot lock path [{}] in project {}", input.path, project);
            throw new LfsLockExistsException(lock);
        }
    } catch (IOException e) {
        String error = String.format("Locking path [%s] in project %s failed with error %s", input.path, project, e.getMessage());
        log.warn(error);
        throw new LfsException(error);
    }
    try {
        try (OutputStreamWriter out = new OutputStreamWriter(fileLock.getOutputStream())) {
            gson.toJson(lock, out);
        } catch (IOException e) {
            String error = String.format("Locking path [%s] in project %s failed during write with error %s", input.path, project, e.getMessage());
            log.warn(error);
            throw new LfsException(error);
        }
        if (!fileLock.commit()) {
            String error = String.format("Committing lock to path [%s] in project %s failed", input.path, project);
            log.warn(error);
            throw new LfsException(error);
        }
        // put lock object to cache while file lock is being hold so that
        // there is no chance that other process performs lock operation
        // in the meantime (either cache returns with existing object or
        // LockFile.lock fails on locking attempt)
        locks.put(lockId, lock);
    } finally {
        fileLock.unlock();
    }
    return lock;
}
#end_block

#method_before
LfsLockResponse deleteLock(Project.NameKey project, CurrentUser user, String lockId, LfsDeleteLockInput input) throws LfsException {
    log.debug("Delete (-f {}) lock for {} in project {}", Boolean.TRUE.equals(input.force), lockId, project);
    LfsProjectLocks locks = projectLocks.getUnchecked(project);
    Optional<LfsLock> hasLock = locks.getLock(lockId);
    if (!hasLock.isPresent()) {
        throw new LfsException(String.format("there is no lock id %s in project %s", lockId, project));
    }
    LfsLock lock = hasLock.get();
    if (lock.owner.name.equals(user.getUserName())) {
        locks.deleteLock(lock);
        return new LfsLockResponse(lock);
    } else if (input.force) {
        locks.deleteLock(lock);
        return new LfsLockResponse(lock);
    }
    throw new LfsException(String.format("Lock %s is owned by different user %s", lockId, lock.owner.name));
}
#method_after
LfsLockResponse deleteLock(Project.NameKey project, CurrentUser user, String lockId, LfsDeleteLockInput input) throws LfsException {
    log.debug("Delete (-f {}) lock for {} in project {}", Boolean.TRUE.equals(input.force), lockId, project);
    LfsProjectLocks locks = projectLocks.getUnchecked(project);
    Optional<LfsLock> hasLock = locks.getLock(lockId);
    if (!hasLock.isPresent()) {
        throw new LfsException(String.format("there is no lock id %s in project %s", lockId, project));
    }
    LfsLock lock = hasLock.get();
    if (lock.owner.name.equals(user.getUserName().get())) {
        locks.deleteLock(lock);
        return new LfsLockResponse(lock);
    } else if (input.force) {
        locks.deleteLock(lock);
        return new LfsLockResponse(lock);
    }
    throw new LfsException(String.format("Lock %s is owned by different user %s", lockId, lock.owner.name));
}
#end_block

#method_before
LfsVerifyLocksResponse verifyLocks(Project.NameKey project, final CurrentUser user) {
    log.debug("Verify list of locks for {} project and user {}", project, user);
    LfsProjectLocks locks = projectLocks.getUnchecked(project);
    Function<LfsLock, Boolean> isOurs = new Function<LfsLock, Boolean>() {

        @Override
        public Boolean apply(LfsLock input) {
            return input.owner.name.equals(user.getUserName().get());
        }
    };
    Map<Boolean, List<LfsLock>> groupByOurs = locks.getLocks().stream().collect(Collectors.groupingBy(isOurs));
    return new LfsVerifyLocksResponse(groupByOurs.get(true), groupByOurs.get(false), null);
}
#method_after
LfsVerifyLocksResponse verifyLocks(Project.NameKey project, final CurrentUser user) {
    log.debug("Verify list of locks for {} project and user {}", project, user);
    LfsProjectLocks locks = projectLocks.getUnchecked(project);
    Map<Boolean, List<LfsLock>> groupByOurs = locks.getLocks().stream().collect(Collectors.groupingBy((in) -> {
        return in.owner.name.equals(user.getUserName().get());
    }));
    return new LfsVerifyLocksResponse(groupByOurs.get(true), groupByOurs.get(false), null);
}
#end_block

#method_before
SshAuthInfo generateAuthInfo(CurrentUser user, String project, String operation) {
    LfsSshAuthToken token = new LfsSshAuthToken(user.getUserName(), project, operation, expirationSeconds);
    return new SshAuthInfo(processor.serialize(token), token.expiresAt);
}
#method_after
SshAuthInfo generateAuthInfo(CurrentUser user, String project, String operation) {
    LfsSshAuthToken token = new LfsSshAuthToken(user.getUserName().get(), project, operation, expirationSeconds);
    return new SshAuthInfo(processor.serialize(token), token.expiresAt);
}
#end_block

#method_before
public CurrentUser getUser(String auth, String project, String operation) {
    if (!Strings.isNullOrEmpty(auth)) {
        if (auth.startsWith(BASIC_AUTH_PREFIX)) {
            return user.get();
        }
        if (auth.startsWith(SSH_AUTH_PREFIX)) {
            Optional<String> user = sshAuth.getUserFromValidToken(auth.substring(SSH_AUTH_PREFIX.length()), project, operation);
            if (user.isPresent()) {
                AccountState acc = accounts.getByUsername(user.get());
                if (acc != null) {
                    return userFactory.create(acc);
                }
            }
        }
    }
    return anonymous.get();
}
#method_after
public CurrentUser getUser(String auth, String project, String operation) {
    if (!Strings.isNullOrEmpty(auth)) {
        if (auth.startsWith(BASIC_AUTH_PREFIX)) {
            return user.get();
        }
        if (auth.startsWith(SSH_AUTH_PREFIX)) {
            Optional<String> user = sshAuth.getUserFromValidToken(auth.substring(SSH_AUTH_PREFIX.length()), project, operation);
            if (user.isPresent()) {
                Optional<AccountState> acc = accounts.getByUsername(user.get());
                if (acc.isPresent()) {
                    return userFactory.create(acc.get());
                }
            }
        }
    }
    return anonymous.get();
}
#end_block

#method_before
private JiraClient client() throws MalformedURLException {
    if (client == null) {
        log.debug("Connecting to jira at {}", jiraConfig.getUrl());
        client = new JiraClient(jiraConfig.getUrl(), jiraConfig.getUsername(), jiraConfig.getPassword());
        log.debug("Authenticating as User {}", jiraConfig.getUsername());
    }
    return client;
}
#method_after
private JiraClient client() throws MalformedURLException {
    if (client == null) {
        log.debug("Connecting to jira at {}", jiraConfig.getJiraUrl());
        client = new JiraClient(jiraConfig.getJiraUrl(), jiraConfig.getUsername(), jiraConfig.getPassword());
        log.debug("Authenticating as User {}", jiraConfig.getUsername());
    }
    return client;
}
#end_block

#method_before
@Override
protected void configure() {
    if (gerritConfig.getString(pluginName, null, "url") != null) {
        LOG.info("JIRA is configured as ITS");
        bind(JiraConfig.class);
        bind(ItsFacade.class).to(JiraItsFacade.class).asEagerSingleton();
        install(new ItsHookModule(pluginName, pluginCfgFactory));
    }
}
#method_after
@Override
protected void configure() {
    if (gerritConfig.getString(pluginName, null, "url") != null) {
        LOG.info("JIRA is configured as ITS");
        bind(ItsFacade.class).to(JiraItsFacade.class).asEagerSingleton();
        install(new ItsHookModule(pluginName, pluginCfgFactory));
    }
}
#end_block

#method_before
@Test
public void gerritConfigContainsSaneValues() throws Exception {
    when(cfg.getString(PLUGIN_NAME, null, GERRIT_CONFIG_URL)).thenReturn(URL);
    when(cfg.getString(PLUGIN_NAME, null, GERRIT_CONFIG_USERNAME)).thenReturn(USER);
    when(cfg.getString(PLUGIN_NAME, null, GERRIT_CONFIG_PASSWORD)).thenReturn(PASS);
    jiraConfig = new JiraConfig(cfg, PLUGIN_NAME);
    assertThat(jiraConfig.getUsername()).isEqualTo(USER);
    assertThat(jiraConfig.getPassword()).isEqualTo(PASS);
    assertThat(jiraConfig.getUrl()).isEqualTo(URL);
}
#method_after
@Test
public void gerritConfigContainsSaneValues() throws Exception {
    when(cfg.getString(PLUGIN_NAME, null, GERRIT_CONFIG_URL)).thenReturn(URL);
    when(cfg.getString(PLUGIN_NAME, null, GERRIT_CONFIG_USERNAME)).thenReturn(USER);
    when(cfg.getString(PLUGIN_NAME, null, GERRIT_CONFIG_PASSWORD)).thenReturn(PASS);
    jiraConfig = new JiraConfig(cfg, PLUGIN_NAME);
    assertThat(jiraConfig.getUsername()).isEqualTo(USER);
    assertThat(jiraConfig.getPassword()).isEqualTo(PASS);
    assertThat(jiraConfig.getJiraUrl()).isEqualTo(URL);
}
#end_block

#method_before
private Set<Account> getGroupMembers(InternalGroup group, @Nullable Project.NameKey project, Set<AccountGroup.UUID> seen) throws NoSuchProjectException, IOException {
    seen.add(group.getGroupUUID());
    GroupControl groupControl = groupControlFactory.controlFor(new InternalGroupDescription(group));
    Set<Account> directMembers = group.getMembers().stream().filter(groupControl::canSeeMember).map(accountCache::maybeGet).filter(Optional::isPresent).map(Optional::get).map(AccountState::getAccount).collect(toImmutableSet());
    Set<Account> indirectMembers = new HashSet<>();
    if (groupControl.canSeeGroup()) {
        for (AccountGroup.UUID subgroupUuid : group.getSubgroups()) {
            if (!seen.contains(subgroupUuid)) {
                indirectMembers.addAll(listAccounts(subgroupUuid, project, seen));
            }
        }
    }
    return Sets.union(directMembers, indirectMembers);
}
#method_after
private Set<Account> getGroupMembers(InternalGroup group, @Nullable Project.NameKey project, Set<AccountGroup.UUID> seen) throws NoSuchProjectException, IOException {
    seen.add(group.getGroupUUID());
    GroupControl groupControl = groupControlFactory.controlFor(new InternalGroupDescription(group));
    Set<Account> directMembers = group.getMembers().stream().filter(groupControl::canSeeMember).map(accountCache::maybeGet).flatMap(Streams::stream).map(AccountState::getAccount).collect(toImmutableSet());
    Set<Account> indirectMembers = new HashSet<>();
    if (groupControl.canSeeGroup()) {
        for (AccountGroup.UUID subgroupUuid : group.getSubgroups()) {
            if (!seen.contains(subgroupUuid)) {
                indirectMembers.addAll(listAccounts(subgroupUuid, project, seen));
            }
        }
    }
    return Sets.union(directMembers, indirectMembers);
}
#end_block

#method_before
private void parseCommands(Collection<ReceiveCommand> commands) throws PermissionBackendException, NoSuchProjectException, IOException {
    List<String> optionList = rp.getPushOptions();
    if (optionList != null) {
        for (String option : optionList) {
            int e = option.indexOf('=');
            if (e > 0) {
                pushOptions.put(option.substring(0, e), option.substring(e + 1));
            } else {
                pushOptions.put(option, "");
            }
        }
    }
    logDebug("Parsing {} commands", commands.size());
    for (ReceiveCommand cmd : commands) {
        if (cmd.getResult() != NOT_ATTEMPTED) {
            // Already rejected by the core receive process.
            logDebug("Already processed by core: {} {}", cmd.getResult(), cmd);
            continue;
        }
        if (!Repository.isValidRefName(cmd.getRefName()) || cmd.getRefName().contains("//")) {
            reject(cmd, "not valid ref");
            continue;
        }
        if (MagicBranch.isMagicBranch(cmd.getRefName())) {
            parseMagicBranch(cmd);
            continue;
        }
        if (projectState.isAllUsers() && RefNames.REFS_USERS_SELF.equals(cmd.getRefName())) {
            String newName = RefNames.refsUsers(user.getAccountId());
            logDebug("Swapping out command for {} to {}", RefNames.REFS_USERS_SELF, newName);
            final ReceiveCommand orgCmd = cmd;
            cmd = new ReceiveCommand(cmd.getOldId(), cmd.getNewId(), newName, cmd.getType()) {

                @Override
                public void setResult(Result s, String m) {
                    super.setResult(s, m);
                    orgCmd.setResult(s, m);
                }
            };
        }
        Matcher m = NEW_PATCHSET_PATTERN.matcher(cmd.getRefName());
        if (m.matches()) {
            if (cfg == null || cfg.getBoolean("receive", "allowPushToRefsChanges", false)) {
                // The referenced change must exist and must still be open.
                // 
                Change.Id changeId = Change.Id.parse(m.group(1));
                parseReplaceCommand(cmd, changeId);
            } else {
                reject(cmd, "upload to refs/changes not allowed");
            }
            continue;
        }
        switch(cmd.getType()) {
            case CREATE:
                parseCreate(cmd);
                break;
            case UPDATE:
                parseUpdate(cmd);
                break;
            case DELETE:
                parseDelete(cmd);
                break;
            case UPDATE_NONFASTFORWARD:
                parseRewind(cmd);
                break;
            default:
                reject(cmd, "prohibited by Gerrit: unknown command type " + cmd.getType());
                continue;
        }
        if (cmd.getResult() != NOT_ATTEMPTED) {
            continue;
        }
        if (isConfig(cmd)) {
            logDebug("Processing {} command", cmd.getRefName());
            try {
                permissions.check(ProjectPermission.WRITE_CONFIG);
            } catch (AuthException e) {
                reject(cmd, String.format("must be either project owner or have %s permission", ProjectPermission.WRITE_CONFIG.describeForException()));
                continue;
            }
            switch(cmd.getType()) {
                case CREATE:
                case UPDATE:
                case UPDATE_NONFASTFORWARD:
                    try {
                        ProjectConfig cfg = new ProjectConfig(project.getNameKey());
                        cfg.load(rp.getRevWalk(), cmd.getNewId());
                        if (!cfg.getValidationErrors().isEmpty()) {
                            addError("Invalid project configuration:");
                            for (ValidationError err : cfg.getValidationErrors()) {
                                addError("  " + err.getMessage());
                            }
                            reject(cmd, "invalid project configuration");
                            logError("User " + user.getUserName() + " tried to push invalid project configuration " + cmd.getNewId().name() + " for " + project.getName());
                            continue;
                        }
                        Project.NameKey newParent = cfg.getProject().getParent(allProjectsName);
                        Project.NameKey oldParent = project.getParent(allProjectsName);
                        if (oldParent == null) {
                            // update of the 'All-Projects' project
                            if (newParent != null) {
                                reject(cmd, "invalid project configuration: root project cannot have parent");
                                continue;
                            }
                        } else {
                            if (!oldParent.equals(newParent)) {
                                try {
                                    permissionBackend.user(user).check(GlobalPermission.ADMINISTRATE_SERVER);
                                } catch (AuthException e) {
                                    reject(cmd, "invalid project configuration: only Gerrit admin can set parent");
                                    continue;
                                }
                            }
                            if (projectCache.get(newParent) == null) {
                                reject(cmd, "invalid project configuration: parent does not exist");
                                continue;
                            }
                        }
                        for (Entry<ProjectConfigEntry> e : pluginConfigEntries) {
                            PluginConfig pluginCfg = cfg.getPluginConfig(e.getPluginName());
                            ProjectConfigEntry configEntry = e.getProvider().get();
                            String value = pluginCfg.getString(e.getExportName());
                            String oldValue = projectState.getConfig().getPluginConfig(e.getPluginName()).getString(e.getExportName());
                            if (configEntry.getType() == ProjectConfigEntryType.ARRAY) {
                                oldValue = Arrays.stream(projectState.getConfig().getPluginConfig(e.getPluginName()).getStringList(e.getExportName())).collect(joining("\n"));
                            }
                            if ((value == null ? oldValue != null : !value.equals(oldValue)) && !configEntry.isEditable(projectState)) {
                                reject(cmd, String.format("invalid project configuration: Not allowed to set parameter" + " '%s' of plugin '%s' on project '%s'.", e.getExportName(), e.getPluginName(), project.getName()));
                                continue;
                            }
                            if (ProjectConfigEntryType.LIST.equals(configEntry.getType()) && value != null && !configEntry.getPermittedValues().contains(value)) {
                                reject(cmd, String.format("invalid project configuration: The value '%s' is " + "not permitted for parameter '%s' of plugin '%s'.", value, e.getExportName(), e.getPluginName()));
                            }
                        }
                    } catch (Exception e) {
                        reject(cmd, "invalid project configuration");
                        logError("User " + user.getUserName() + " tried to push invalid project configuration " + cmd.getNewId().name() + " for " + project.getName(), e);
                        continue;
                    }
                    break;
                case DELETE:
                    break;
                default:
                    reject(cmd, "prohibited by Gerrit: don't know how to handle config update of type " + cmd.getType());
                    continue;
            }
        }
    }
}
#method_after
private void parseCommands(Collection<ReceiveCommand> commands) throws PermissionBackendException, NoSuchProjectException, IOException {
    List<String> optionList = rp.getPushOptions();
    if (optionList != null) {
        for (String option : optionList) {
            int e = option.indexOf('=');
            if (e > 0) {
                pushOptions.put(option.substring(0, e), option.substring(e + 1));
            } else {
                pushOptions.put(option, "");
            }
        }
    }
    logDebug("Parsing {} commands", commands.size());
    for (ReceiveCommand cmd : commands) {
        if (cmd.getResult() != NOT_ATTEMPTED) {
            // Already rejected by the core receive process.
            logDebug("Already processed by core: {} {}", cmd.getResult(), cmd);
            continue;
        }
        if (!Repository.isValidRefName(cmd.getRefName()) || cmd.getRefName().contains("//")) {
            reject(cmd, "not valid ref");
            continue;
        }
        if (MagicBranch.isMagicBranch(cmd.getRefName())) {
            parseMagicBranch(cmd);
            continue;
        }
        if (projectState.isAllUsers() && RefNames.REFS_USERS_SELF.equals(cmd.getRefName())) {
            String newName = RefNames.refsUsers(user.getAccountId());
            logDebug("Swapping out command for {} to {}", RefNames.REFS_USERS_SELF, newName);
            final ReceiveCommand orgCmd = cmd;
            cmd = new ReceiveCommand(cmd.getOldId(), cmd.getNewId(), newName, cmd.getType()) {

                @Override
                public void setResult(Result s, String m) {
                    super.setResult(s, m);
                    orgCmd.setResult(s, m);
                }
            };
        }
        Matcher m = NEW_PATCHSET_PATTERN.matcher(cmd.getRefName());
        if (m.matches()) {
            if (allowPushToRefsChanges) {
                // The referenced change must exist and must still be open.
                // 
                Change.Id changeId = Change.Id.parse(m.group(1));
                parseReplaceCommand(cmd, changeId);
            } else {
                reject(cmd, "upload to refs/changes not allowed");
            }
            continue;
        }
        switch(cmd.getType()) {
            case CREATE:
                parseCreate(cmd);
                break;
            case UPDATE:
                parseUpdate(cmd);
                break;
            case DELETE:
                parseDelete(cmd);
                break;
            case UPDATE_NONFASTFORWARD:
                parseRewind(cmd);
                break;
            default:
                reject(cmd, "prohibited by Gerrit: unknown command type " + cmd.getType());
                continue;
        }
        if (cmd.getResult() != NOT_ATTEMPTED) {
            continue;
        }
        if (isConfig(cmd)) {
            logDebug("Processing {} command", cmd.getRefName());
            try {
                permissions.check(ProjectPermission.WRITE_CONFIG);
            } catch (AuthException e) {
                reject(cmd, String.format("must be either project owner or have %s permission", ProjectPermission.WRITE_CONFIG.describeForException()));
                continue;
            }
            switch(cmd.getType()) {
                case CREATE:
                case UPDATE:
                case UPDATE_NONFASTFORWARD:
                    try {
                        ProjectConfig cfg = new ProjectConfig(project.getNameKey());
                        cfg.load(rp.getRevWalk(), cmd.getNewId());
                        if (!cfg.getValidationErrors().isEmpty()) {
                            addError("Invalid project configuration:");
                            for (ValidationError err : cfg.getValidationErrors()) {
                                addError("  " + err.getMessage());
                            }
                            reject(cmd, "invalid project configuration");
                            logError("User " + user.getLoggableName() + " tried to push invalid project configuration " + cmd.getNewId().name() + " for " + project.getName());
                            continue;
                        }
                        Project.NameKey newParent = cfg.getProject().getParent(allProjectsName);
                        Project.NameKey oldParent = project.getParent(allProjectsName);
                        if (oldParent == null) {
                            // update of the 'All-Projects' project
                            if (newParent != null) {
                                reject(cmd, "invalid project configuration: root project cannot have parent");
                                continue;
                            }
                        } else {
                            if (!oldParent.equals(newParent)) {
                                try {
                                    permissionBackend.user(user).check(GlobalPermission.ADMINISTRATE_SERVER);
                                } catch (AuthException e) {
                                    reject(cmd, "invalid project configuration: only Gerrit admin can set parent");
                                    continue;
                                }
                            }
                            if (projectCache.get(newParent) == null) {
                                reject(cmd, "invalid project configuration: parent does not exist");
                                continue;
                            }
                        }
                        for (Entry<ProjectConfigEntry> e : pluginConfigEntries) {
                            PluginConfig pluginCfg = cfg.getPluginConfig(e.getPluginName());
                            ProjectConfigEntry configEntry = e.getProvider().get();
                            String value = pluginCfg.getString(e.getExportName());
                            String oldValue = projectState.getConfig().getPluginConfig(e.getPluginName()).getString(e.getExportName());
                            if (configEntry.getType() == ProjectConfigEntryType.ARRAY) {
                                oldValue = Arrays.stream(projectState.getConfig().getPluginConfig(e.getPluginName()).getStringList(e.getExportName())).collect(joining("\n"));
                            }
                            if ((value == null ? oldValue != null : !value.equals(oldValue)) && !configEntry.isEditable(projectState)) {
                                reject(cmd, String.format("invalid project configuration: Not allowed to set parameter" + " '%s' of plugin '%s' on project '%s'.", e.getExportName(), e.getPluginName(), project.getName()));
                                continue;
                            }
                            if (ProjectConfigEntryType.LIST.equals(configEntry.getType()) && value != null && !configEntry.getPermittedValues().contains(value)) {
                                reject(cmd, String.format("invalid project configuration: The value '%s' is " + "not permitted for parameter '%s' of plugin '%s'.", value, e.getExportName(), e.getPluginName()));
                            }
                        }
                    } catch (Exception e) {
                        reject(cmd, "invalid project configuration");
                        logError("User " + user.getLoggableName() + " tried to push invalid project configuration " + cmd.getNewId().name() + " for " + project.getName(), e);
                        continue;
                    }
                    break;
                case DELETE:
                    break;
                default:
                    reject(cmd, "prohibited by Gerrit: don't know how to handle config update of type " + cmd.getType());
                    continue;
            }
        }
    }
}
#end_block

#method_before
boolean validate(boolean autoClose) throws IOException, OrmException, PermissionBackendException {
    if (!autoClose && inputCommand.getResult() != NOT_ATTEMPTED) {
        return false;
    } else if (notes == null) {
        reject(inputCommand, "change " + ontoChange + " not found");
        return false;
    }
    Change change = notes.getChange();
    priorPatchSet = change.currentPatchSetId();
    if (!revisions.containsValue(priorPatchSet)) {
        reject(inputCommand, "change " + ontoChange + " missing revisions");
        return false;
    }
    RevCommit newCommit = rp.getRevWalk().parseCommit(newCommitId);
    RevCommit priorCommit = revisions.inverse().get(priorPatchSet);
    try {
        permissions.change(notes).database(db).check(ChangePermission.ADD_PATCH_SET);
    } catch (AuthException no) {
        reject(inputCommand, "cannot add patch set to " + ontoChange + ".");
        return false;
    }
    if (!projectState.statePermitsWrite()) {
        reject(inputCommand, "cannot add patch set to " + ontoChange + ".");
        return false;
    }
    if (change.getStatus().isClosed()) {
        reject(inputCommand, "change " + ontoChange + " closed");
        return false;
    } else if (revisions.containsKey(newCommit)) {
        reject(inputCommand, "commit already exists (in the change)");
        return false;
    }
    for (Ref r : rp.getRepository().getRefDatabase().getRefs("refs/changes").values()) {
        if (r.getObjectId().equals(newCommit)) {
            reject(inputCommand, "commit already exists (in the project)");
            return false;
        }
    }
    for (RevCommit prior : revisions.keySet()) {
        // amending when trying to address review comments.
        if (rp.getRevWalk().isMergedInto(prior, newCommit)) {
            reject(inputCommand, SAME_CHANGE_ID_IN_MULTIPLE_CHANGES);
            return false;
        }
    }
    PermissionBackend.ForRef perm = permissions.ref(change.getDest().get());
    if (!validCommit(rp.getRevWalk(), perm, change.getDest(), inputCommand, newCommit, change)) {
        return false;
    }
    rp.getRevWalk().parseBody(priorCommit);
    // of the commit was modified.
    if (newCommit.getTree().equals(priorCommit.getTree())) {
        boolean messageEq = eq(newCommit.getFullMessage(), priorCommit.getFullMessage());
        boolean parentsEq = parentsEqual(newCommit, priorCommit);
        boolean authorEq = authorEqual(newCommit, priorCommit);
        ObjectReader reader = rp.getRevWalk().getObjectReader();
        if (messageEq && parentsEq && authorEq && !autoClose) {
            addMessage(String.format("(W) No changes between prior commit %s and new commit %s", reader.abbreviate(priorCommit).name(), reader.abbreviate(newCommit).name()));
        } else {
            StringBuilder msg = new StringBuilder();
            msg.append("(I) ");
            msg.append(reader.abbreviate(newCommit).name());
            msg.append(":");
            msg.append(" no files changed");
            if (!authorEq) {
                msg.append(", author changed");
            }
            if (!messageEq) {
                msg.append(", message updated");
            }
            if (!parentsEq) {
                msg.append(", was rebased");
            }
            addMessage(msg.toString());
        }
    }
    if (magicBranch != null && (magicBranch.workInProgress || magicBranch.ready) && magicBranch.workInProgress != change.isWorkInProgress() && !user.getAccountId().equals(change.getOwner())) {
        reject(inputCommand, ONLY_OWNER_CAN_MODIFY_WIP);
        return false;
    }
    if (magicBranch != null && (magicBranch.edit || magicBranch.draft)) {
        return newEdit();
    }
    newPatchSet();
    return true;
}
#method_after
boolean validate(boolean autoClose) throws IOException, OrmException, PermissionBackendException {
    if (!autoClose && inputCommand.getResult() != NOT_ATTEMPTED) {
        return false;
    } else if (notes == null) {
        reject(inputCommand, "change " + ontoChange + " not found");
        return false;
    }
    Change change = notes.getChange();
    priorPatchSet = change.currentPatchSetId();
    if (!revisions.containsValue(priorPatchSet)) {
        reject(inputCommand, "change " + ontoChange + " missing revisions");
        return false;
    }
    RevCommit newCommit = rp.getRevWalk().parseCommit(newCommitId);
    RevCommit priorCommit = revisions.inverse().get(priorPatchSet);
    try {
        permissions.change(notes).database(db).check(ChangePermission.ADD_PATCH_SET);
    } catch (AuthException no) {
        reject(inputCommand, "cannot add patch set to " + ontoChange + ".");
        return false;
    }
    if (!projectState.statePermitsWrite()) {
        reject(inputCommand, "cannot add patch set to " + ontoChange + ".");
        return false;
    }
    if (change.getStatus().isClosed()) {
        reject(inputCommand, "change " + ontoChange + " closed");
        return false;
    } else if (revisions.containsKey(newCommit)) {
        reject(inputCommand, "commit already exists (in the change)");
        return false;
    }
    for (Ref r : rp.getRepository().getRefDatabase().getRefs("refs/changes").values()) {
        if (r.getObjectId().equals(newCommit)) {
            reject(inputCommand, "commit already exists (in the project)");
            return false;
        }
    }
    for (RevCommit prior : revisions.keySet()) {
        // amending when trying to address review comments.
        if (rp.getRevWalk().isMergedInto(prior, newCommit)) {
            reject(inputCommand, SAME_CHANGE_ID_IN_MULTIPLE_CHANGES);
            return false;
        }
    }
    PermissionBackend.ForRef perm = permissions.ref(change.getDest().get());
    if (!validCommit(rp.getRevWalk(), perm, change.getDest(), inputCommand, newCommit, change)) {
        return false;
    }
    rp.getRevWalk().parseBody(priorCommit);
    // of the commit was modified.
    if (newCommit.getTree().equals(priorCommit.getTree())) {
        boolean messageEq = Objects.equals(newCommit.getFullMessage(), priorCommit.getFullMessage());
        boolean parentsEq = parentsEqual(newCommit, priorCommit);
        boolean authorEq = authorEqual(newCommit, priorCommit);
        ObjectReader reader = rp.getRevWalk().getObjectReader();
        if (messageEq && parentsEq && authorEq && !autoClose) {
            addMessage(String.format("(W) No changes between prior commit %s and new commit %s", reader.abbreviate(priorCommit).name(), reader.abbreviate(newCommit).name()));
        } else {
            StringBuilder msg = new StringBuilder();
            msg.append("(I) ");
            msg.append(reader.abbreviate(newCommit).name());
            msg.append(":");
            msg.append(" no files changed");
            if (!authorEq) {
                msg.append(", author changed");
            }
            if (!messageEq) {
                msg.append(", message updated");
            }
            if (!parentsEq) {
                msg.append(", was rebased");
            }
            addMessage(msg.toString());
        }
    }
    if (magicBranch != null && (magicBranch.workInProgress || magicBranch.ready) && magicBranch.workInProgress != change.isWorkInProgress() && !user.getAccountId().equals(change.getOwner())) {
        reject(inputCommand, ONLY_OWNER_CAN_MODIFY_WIP);
        return false;
    }
    if (magicBranch != null && (magicBranch.edit || magicBranch.draft)) {
        return newEdit();
    }
    newPatchSet();
    return true;
}
#end_block

#method_before
static boolean authorEqual(RevCommit a, RevCommit b) {
    PersonIdent aAuthor = a.getAuthorIdent();
    PersonIdent bAuthor = b.getAuthorIdent();
    if (aAuthor == null && bAuthor == null) {
        return true;
    } else if (aAuthor == null || bAuthor == null) {
        return false;
    }
    return eq(aAuthor.getName(), bAuthor.getName()) && eq(aAuthor.getEmailAddress(), bAuthor.getEmailAddress());
}
#method_after
static boolean authorEqual(RevCommit a, RevCommit b) {
    PersonIdent aAuthor = a.getAuthorIdent();
    PersonIdent bAuthor = b.getAuthorIdent();
    if (aAuthor == null && bAuthor == null) {
        return true;
    } else if (aAuthor == null || bAuthor == null) {
        return false;
    }
    return Objects.equals(aAuthor.getName(), bAuthor.getName()) && Objects.equals(aAuthor.getEmailAddress(), bAuthor.getEmailAddress());
}
#end_block

#method_before
private void validateNewCommits(Branch.NameKey branch, ReceiveCommand cmd) throws PermissionBackendException {
    PermissionBackend.ForRef perm = permissions.ref(branch.get());
    if (!RefNames.REFS_CONFIG.equals(cmd.getRefName()) && !(MagicBranch.isMagicBranch(cmd.getRefName()) || NEW_PATCHSET_PATTERN.matcher(cmd.getRefName()).matches()) && pushOptions.containsKey(PUSH_OPTION_SKIP_VALIDATION)) {
        try {
            perm.check(RefPermission.SKIP_VALIDATION);
            if (!Iterables.isEmpty(rejectCommits)) {
                throw new AuthException("reject-commits prevents " + PUSH_OPTION_SKIP_VALIDATION);
            }
            logDebug("Short-circuiting new commit validation");
        } catch (AuthException denied) {
            reject(cmd, denied.getMessage());
        }
        return;
    }
    boolean missingFullName = Strings.isNullOrEmpty(user.getAccount().getFullName());
    RevWalk walk = rp.getRevWalk();
    walk.reset();
    walk.sort(RevSort.NONE);
    try {
        RevObject parsedObject = walk.parseAny(cmd.getNewId());
        if (!(parsedObject instanceof RevCommit)) {
            return;
        }
        ListMultimap<ObjectId, Ref> existing = changeRefsById();
        walk.markStart((RevCommit) parsedObject);
        markHeadsAsUninteresting(walk, cmd.getRefName());
        int limit = receiveConfig.maxBatchCommits;
        int n = 0;
        for (RevCommit c; (c = walk.next()) != null; ) {
            if (++n > limit) {
                logDebug("Number of new commits exceeds limit of {}", limit);
                addMessage("Cannot push more than " + limit + " commits to " + branch.get() + " without " + PUSH_OPTION_SKIP_VALIDATION + " option");
                reject(cmd, "too many commits");
                return;
            }
            if (existing.keySet().contains(c)) {
                continue;
            } else if (!validCommit(walk, perm, branch, cmd, c, null)) {
                break;
            }
            if (missingFullName && user.hasEmailAddress(c.getCommitterIdent().getEmailAddress())) {
                logDebug("Will update full name of caller");
                setFullNameTo = c.getCommitterIdent().getName();
                missingFullName = false;
            }
        }
        logDebug("Validated {} new commits", n);
    } catch (IOException err) {
        cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", err);
    }
}
#method_after
private void validateNewCommits(Branch.NameKey branch, ReceiveCommand cmd) throws PermissionBackendException {
    PermissionBackend.ForRef perm = permissions.ref(branch.get());
    if (!RefNames.REFS_CONFIG.equals(cmd.getRefName()) && !(MagicBranch.isMagicBranch(cmd.getRefName()) || NEW_PATCHSET_PATTERN.matcher(cmd.getRefName()).matches()) && pushOptions.containsKey(PUSH_OPTION_SKIP_VALIDATION)) {
        try {
            perm.check(RefPermission.SKIP_VALIDATION);
            if (!Iterables.isEmpty(rejectCommits)) {
                throw new AuthException("reject-commits prevents " + PUSH_OPTION_SKIP_VALIDATION);
            }
            logDebug("Short-circuiting new commit validation");
        } catch (AuthException denied) {
            reject(cmd, denied.getMessage());
        }
        return;
    }
    boolean missingFullName = Strings.isNullOrEmpty(user.getAccount().getFullName());
    RevWalk walk = rp.getRevWalk();
    walk.reset();
    walk.sort(RevSort.NONE);
    try {
        RevObject parsedObject = walk.parseAny(cmd.getNewId());
        if (!(parsedObject instanceof RevCommit)) {
            return;
        }
        ListMultimap<ObjectId, Ref> existing = changeRefsById();
        walk.markStart((RevCommit) parsedObject);
        markHeadsAsUninteresting(walk, cmd.getRefName());
        int limit = receiveConfig.maxBatchCommits;
        int n = 0;
        for (RevCommit c; (c = walk.next()) != null; ) {
            if (++n > limit) {
                logDebug("Number of new commits exceeds limit of {}", limit);
                addMessage(String.format("Cannot push more than %d commits to %s without %s option " + "(see %sDocumentation/user-upload.html#skip_validation for details)", limit, branch.get(), PUSH_OPTION_SKIP_VALIDATION, canonicalWebUrl));
                reject(cmd, "too many commits");
                return;
            }
            if (existing.keySet().contains(c)) {
                continue;
            } else if (!validCommit(walk, perm, branch, cmd, c, null)) {
                break;
            }
            if (missingFullName && user.hasEmailAddress(c.getCommitterIdent().getEmailAddress())) {
                logDebug("Will update full name of caller");
                setFullNameTo = c.getCommitterIdent().getName();
                missingFullName = false;
            }
        }
        logDebug("Validated {} new commits", n);
    } catch (IOException err) {
        cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", err);
    }
}
#end_block

#method_before
private void autoCloseChanges(ReceiveCommand cmd) {
    logDebug("Starting auto-closing of changes");
    String refName = cmd.getRefName();
    checkState(!MagicBranch.isMagicBranch(refName), "shouldn't be auto-closing changes on magic branch %s", refName);
    // insertChangesAndPatchSets.
    try {
        retryHelper.execute(updateFactory -> {
            try (BatchUpdate bu = updateFactory.create(db, projectState.getNameKey(), user, TimeUtil.nowTs());
                ObjectInserter ins = repo.newObjectInserter();
                ObjectReader reader = ins.newReader();
                RevWalk rw = new RevWalk(reader)) {
                bu.setRepository(repo, rw, ins).updateChangesInParallel();
                bu.setRequestId(receiveId);
                // TODO(dborowitz): Teach BatchUpdate to ignore missing changes.
                RevCommit newTip = rw.parseCommit(cmd.getNewId());
                Branch.NameKey branch = new Branch.NameKey(project.getNameKey(), refName);
                rw.reset();
                rw.markStart(newTip);
                if (!ObjectId.zeroId().equals(cmd.getOldId())) {
                    rw.markUninteresting(rw.parseCommit(cmd.getOldId()));
                }
                ListMultimap<ObjectId, Ref> byCommit = changeRefsById();
                Map<Change.Key, ChangeNotes> byKey = null;
                List<ReplaceRequest> replaceAndClose = new ArrayList<>();
                int existingPatchSets = 0;
                int newPatchSets = 0;
                COMMIT: for (RevCommit c; (c = rw.next()) != null; ) {
                    rw.parseBody(c);
                    for (Ref ref : byCommit.get(c.copy())) {
                        PatchSet.Id psId = PatchSet.Id.fromRef(ref.getName());
                        Optional<ChangeData> cd = retryHelper.execute(ActionType.CHANGE_QUERY, () -> byLegacyId(psId.getParentKey()), t -> t instanceof OrmException);
                        if (cd.isPresent() && cd.get().change().getDest().equals(branch)) {
                            existingPatchSets++;
                            bu.addOp(psId.getParentKey(), mergedByPushOpFactory.create(requestScopePropagator, psId, refName));
                            continue COMMIT;
                        }
                    }
                    for (String changeId : c.getFooterLines(CHANGE_ID)) {
                        if (byKey == null) {
                            byKey = retryHelper.execute(ActionType.CHANGE_QUERY, () -> openChangesByKeyByBranch(branch), t -> t instanceof OrmException);
                        }
                        ChangeNotes onto = byKey.get(new Change.Key(changeId.trim()));
                        if (onto != null) {
                            newPatchSets++;
                            // Hold onto this until we're done with the walk, as the call to
                            // req.validate below calls isMergedInto which resets the walk.
                            ReplaceRequest req = new ReplaceRequest(onto.getChangeId(), c, cmd, false);
                            req.notes = onto;
                            replaceAndClose.add(req);
                            continue COMMIT;
                        }
                    }
                }
                for (ReplaceRequest req : replaceAndClose) {
                    Change.Id id = req.notes.getChangeId();
                    if (!req.validate(true)) {
                        logDebug("Not closing {} because validation failed", id);
                        continue;
                    }
                    req.addOps(bu, null);
                    bu.addOp(id, mergedByPushOpFactory.create(requestScopePropagator, req.psId, refName).setPatchSetProvider(new Provider<PatchSet>() {

                        @Override
                        public PatchSet get() {
                            return req.replaceOp.getPatchSet();
                        }
                    }));
                    bu.addOp(id, new ChangeProgressOp(closeProgress));
                }
                logDebug("Auto-closing {} changes with existing patch sets and {} with new patch sets", existingPatchSets, newPatchSets);
                bu.execute();
            } catch (IOException | OrmException | PermissionBackendException e) {
                logError("Failed to auto-close changes", e);
            }
            return null;
        }, // eat up the whole timeout so that no time is left to retry this outer action.
        RetryHelper.options().timeout(retryHelper.getDefaultTimeout().multipliedBy(5)).build());
    } catch (RestApiException e) {
        logError("Can't insert patchset", e);
    } catch (UpdateException e) {
        logError("Failed to auto-close changes", e);
    }
}
#method_after
private void autoCloseChanges(ReceiveCommand cmd) {
    logDebug("Starting auto-closing of changes");
    String refName = cmd.getRefName();
    checkState(!MagicBranch.isMagicBranch(refName), "shouldn't be auto-closing changes on magic branch %s", refName);
    // insertChangesAndPatchSets.
    try {
        retryHelper.execute(updateFactory -> {
            try (BatchUpdate bu = updateFactory.create(db, projectState.getNameKey(), user, TimeUtil.nowTs());
                ObjectInserter ins = repo.newObjectInserter();
                ObjectReader reader = ins.newReader();
                RevWalk rw = new RevWalk(reader)) {
                bu.setRepository(repo, rw, ins).updateChangesInParallel();
                bu.setRequestId(receiveId);
                // TODO(dborowitz): Teach BatchUpdate to ignore missing changes.
                RevCommit newTip = rw.parseCommit(cmd.getNewId());
                Branch.NameKey branch = new Branch.NameKey(project.getNameKey(), refName);
                rw.reset();
                rw.markStart(newTip);
                if (!ObjectId.zeroId().equals(cmd.getOldId())) {
                    rw.markUninteresting(rw.parseCommit(cmd.getOldId()));
                }
                ListMultimap<ObjectId, Ref> byCommit = changeRefsById();
                Map<Change.Key, ChangeNotes> byKey = null;
                List<ReplaceRequest> replaceAndClose = new ArrayList<>();
                int existingPatchSets = 0;
                int newPatchSets = 0;
                COMMIT: for (RevCommit c; (c = rw.next()) != null; ) {
                    rw.parseBody(c);
                    for (Ref ref : byCommit.get(c.copy())) {
                        PatchSet.Id psId = PatchSet.Id.fromRef(ref.getName());
                        Optional<ChangeData> cd = executeIndexQuery(() -> byLegacyId(psId.getParentKey()));
                        if (cd.isPresent() && cd.get().change().getDest().equals(branch)) {
                            existingPatchSets++;
                            bu.addOp(psId.getParentKey(), mergedByPushOpFactory.create(requestScopePropagator, psId, refName));
                            continue COMMIT;
                        }
                    }
                    for (String changeId : c.getFooterLines(CHANGE_ID)) {
                        if (byKey == null) {
                            byKey = executeIndexQuery(() -> openChangesByKeyByBranch(branch));
                        }
                        ChangeNotes onto = byKey.get(new Change.Key(changeId.trim()));
                        if (onto != null) {
                            newPatchSets++;
                            // Hold onto this until we're done with the walk, as the call to
                            // req.validate below calls isMergedInto which resets the walk.
                            ReplaceRequest req = new ReplaceRequest(onto.getChangeId(), c, cmd, false);
                            req.notes = onto;
                            replaceAndClose.add(req);
                            continue COMMIT;
                        }
                    }
                }
                for (ReplaceRequest req : replaceAndClose) {
                    Change.Id id = req.notes.getChangeId();
                    if (!executeRequestValidation(() -> req.validate(true))) {
                        logDebug("Not closing {} because validation failed", id);
                        continue;
                    }
                    req.addOps(bu, null);
                    bu.addOp(id, mergedByPushOpFactory.create(requestScopePropagator, req.psId, refName).setPatchSetProvider(new Provider<PatchSet>() {

                        @Override
                        public PatchSet get() {
                            return req.replaceOp.getPatchSet();
                        }
                    }));
                    bu.addOp(id, new ChangeProgressOp(closeProgress));
                }
                logDebug("Auto-closing {} changes with existing patch sets and {} with new patch sets", existingPatchSets, newPatchSets);
                bu.execute();
            } catch (IOException | OrmException | PermissionBackendException e) {
                logError("Failed to auto-close changes", e);
            }
            return null;
        }, // eat up the whole timeout so that no time is left to retry this outer action.
        RetryHelper.options().timeout(retryHelper.getDefaultTimeout(ActionType.CHANGE_UPDATE).multipliedBy(5)).build());
    } catch (RestApiException e) {
        logError("Can't insert patchset", e);
    } catch (UpdateException e) {
        logError("Failed to auto-close changes", e);
    }
}
#end_block

#method_before
private void updateAccountInfo() {
    if (setFullNameTo == null) {
        return;
    }
    logDebug("Updating full name of caller");
    try {
        Account account = accountsUpdate.create().update("Set Full Name on Receive Commits", user.getAccountId(), (a, u) -> {
            if (Strings.isNullOrEmpty(a.getFullName())) {
                u.setFullName(setFullNameTo);
            }
        });
        if (account != null) {
            user.getAccount().setFullName(account.getFullName());
        }
    } catch (OrmException | IOException | ConfigInvalidException e) {
        logWarn("Failed to update full name of caller", e);
    }
}
#method_after
private void updateAccountInfo() {
    if (setFullNameTo == null) {
        return;
    }
    logDebug("Updating full name of caller");
    try {
        Optional<AccountState> accountState = accountsUpdate.create().update("Set Full Name on Receive Commits", user.getAccountId(), (a, u) -> {
            if (Strings.isNullOrEmpty(a.getAccount().getFullName())) {
                u.setFullName(setFullNameTo);
            }
        });
        accountState.map(AccountState::getAccount).ifPresent(a -> user.getAccount().setFullName(a.getFullName()));
    } catch (OrmException | IOException | ConfigInvalidException e) {
        logWarn("Failed to update full name of caller", e);
    }
}
#end_block

#method_before
private void parseCommands(Collection<ReceiveCommand> commands) throws PermissionBackendException, NoSuchProjectException, IOException {
    List<String> optionList = rp.getPushOptions();
    if (optionList != null) {
        for (String option : optionList) {
            int e = option.indexOf('=');
            if (e > 0) {
                pushOptions.put(option.substring(0, e), option.substring(e + 1));
            } else {
                pushOptions.put(option, "");
            }
        }
    }
    logDebug("Parsing {} commands", commands.size());
    for (ReceiveCommand cmd : commands) {
        if (cmd.getResult() != NOT_ATTEMPTED) {
            // Already rejected by the core receive process.
            logDebug("Already processed by core: {} {}", cmd.getResult(), cmd);
            continue;
        }
        if (!Repository.isValidRefName(cmd.getRefName()) || cmd.getRefName().contains("//")) {
            reject(cmd, "not valid ref");
            continue;
        }
        if (MagicBranch.isMagicBranch(cmd.getRefName())) {
            parseMagicBranch(cmd);
            continue;
        }
        if (projectState.isAllUsers() && RefNames.REFS_USERS_SELF.equals(cmd.getRefName())) {
            String newName = RefNames.refsUsers(user.getAccountId());
            logDebug("Swapping out command for {} to {}", RefNames.REFS_USERS_SELF, newName);
            final ReceiveCommand orgCmd = cmd;
            cmd = new ReceiveCommand(cmd.getOldId(), cmd.getNewId(), newName, cmd.getType()) {

                @Override
                public void setResult(Result s, String m) {
                    super.setResult(s, m);
                    orgCmd.setResult(s, m);
                }
            };
        }
        Matcher m = NEW_PATCHSET_PATTERN.matcher(cmd.getRefName());
        if (m.matches()) {
            // The referenced change must exist and must still be open.
            // 
            Change.Id changeId = Change.Id.parse(m.group(1));
            parseReplaceCommand(cmd, changeId);
            continue;
        }
        switch(cmd.getType()) {
            case CREATE:
                parseCreate(cmd);
                break;
            case UPDATE:
                parseUpdate(cmd);
                break;
            case DELETE:
                parseDelete(cmd);
                break;
            case UPDATE_NONFASTFORWARD:
                parseRewind(cmd);
                break;
            default:
                reject(cmd, "prohibited by Gerrit: unknown command type " + cmd.getType());
                continue;
        }
        if (cmd.getResult() != NOT_ATTEMPTED) {
            continue;
        }
        if (isConfig(cmd)) {
            logDebug("Processing {} command", cmd.getRefName());
            try {
                permissions.check(ProjectPermission.WRITE_CONFIG);
            } catch (AuthException e) {
                reject(cmd, String.format("must be either project owner or have %s permission", ProjectPermission.WRITE_CONFIG.describeForException()));
                continue;
            }
            switch(cmd.getType()) {
                case CREATE:
                case UPDATE:
                case UPDATE_NONFASTFORWARD:
                    try {
                        ProjectConfig cfg = new ProjectConfig(project.getNameKey());
                        cfg.load(rp.getRevWalk(), cmd.getNewId());
                        if (!cfg.getValidationErrors().isEmpty()) {
                            addError("Invalid project configuration:");
                            for (ValidationError err : cfg.getValidationErrors()) {
                                addError("  " + err.getMessage());
                            }
                            reject(cmd, "invalid project configuration");
                            logError("User " + user.getUserName() + " tried to push invalid project configuration " + cmd.getNewId().name() + " for " + project.getName());
                            continue;
                        }
                        Project.NameKey newParent = cfg.getProject().getParent(allProjectsName);
                        Project.NameKey oldParent = project.getParent(allProjectsName);
                        if (oldParent == null) {
                            // update of the 'All-Projects' project
                            if (newParent != null) {
                                reject(cmd, "invalid project configuration: root project cannot have parent");
                                continue;
                            }
                        } else {
                            if (!oldParent.equals(newParent)) {
                                try {
                                    permissionBackend.user(user).check(GlobalPermission.ADMINISTRATE_SERVER);
                                } catch (AuthException e) {
                                    reject(cmd, "invalid project configuration: only Gerrit admin can set parent");
                                    continue;
                                }
                            }
                            if (projectCache.get(newParent) == null) {
                                reject(cmd, "invalid project configuration: parent does not exist");
                                continue;
                            }
                        }
                        for (Entry<ProjectConfigEntry> e : pluginConfigEntries) {
                            PluginConfig pluginCfg = cfg.getPluginConfig(e.getPluginName());
                            ProjectConfigEntry configEntry = e.getProvider().get();
                            String value = pluginCfg.getString(e.getExportName());
                            String oldValue = projectState.getConfig().getPluginConfig(e.getPluginName()).getString(e.getExportName());
                            if (configEntry.getType() == ProjectConfigEntryType.ARRAY) {
                                oldValue = Arrays.stream(projectState.getConfig().getPluginConfig(e.getPluginName()).getStringList(e.getExportName())).collect(joining("\n"));
                            }
                            if ((value == null ? oldValue != null : !value.equals(oldValue)) && !configEntry.isEditable(projectState)) {
                                reject(cmd, String.format("invalid project configuration: Not allowed to set parameter" + " '%s' of plugin '%s' on project '%s'.", e.getExportName(), e.getPluginName(), project.getName()));
                                continue;
                            }
                            if (ProjectConfigEntryType.LIST.equals(configEntry.getType()) && value != null && !configEntry.getPermittedValues().contains(value)) {
                                reject(cmd, String.format("invalid project configuration: The value '%s' is " + "not permitted for parameter '%s' of plugin '%s'.", value, e.getExportName(), e.getPluginName()));
                            }
                        }
                    } catch (Exception e) {
                        reject(cmd, "invalid project configuration");
                        logError("User " + user.getUserName() + " tried to push invalid project configuration " + cmd.getNewId().name() + " for " + project.getName(), e);
                        continue;
                    }
                    break;
                case DELETE:
                    break;
                default:
                    reject(cmd, "prohibited by Gerrit: don't know how to handle config update of type " + cmd.getType());
                    continue;
            }
        }
    }
}
#method_after
private void parseCommands(Collection<ReceiveCommand> commands) throws PermissionBackendException, NoSuchProjectException, IOException {
    List<String> optionList = rp.getPushOptions();
    if (optionList != null) {
        for (String option : optionList) {
            int e = option.indexOf('=');
            if (e > 0) {
                pushOptions.put(option.substring(0, e), option.substring(e + 1));
            } else {
                pushOptions.put(option, "");
            }
        }
    }
    logDebug("Parsing {} commands", commands.size());
    for (ReceiveCommand cmd : commands) {
        if (cmd.getResult() != NOT_ATTEMPTED) {
            // Already rejected by the core receive process.
            logDebug("Already processed by core: {} {}", cmd.getResult(), cmd);
            continue;
        }
        if (!Repository.isValidRefName(cmd.getRefName()) || cmd.getRefName().contains("//")) {
            reject(cmd, "not valid ref");
            continue;
        }
        if (MagicBranch.isMagicBranch(cmd.getRefName())) {
            parseMagicBranch(cmd);
            continue;
        }
        if (projectState.isAllUsers() && RefNames.REFS_USERS_SELF.equals(cmd.getRefName())) {
            String newName = RefNames.refsUsers(user.getAccountId());
            logDebug("Swapping out command for {} to {}", RefNames.REFS_USERS_SELF, newName);
            final ReceiveCommand orgCmd = cmd;
            cmd = new ReceiveCommand(cmd.getOldId(), cmd.getNewId(), newName, cmd.getType()) {

                @Override
                public void setResult(Result s, String m) {
                    super.setResult(s, m);
                    orgCmd.setResult(s, m);
                }
            };
        }
        Matcher m = NEW_PATCHSET_PATTERN.matcher(cmd.getRefName());
        if (m.matches()) {
            // The referenced change must exist and must still be open.
            // 
            Change.Id changeId = Change.Id.parse(m.group(1));
            parseReplaceCommand(cmd, changeId);
            continue;
        }
        switch(cmd.getType()) {
            case CREATE:
                parseCreate(cmd);
                break;
            case UPDATE:
                parseUpdate(cmd);
                break;
            case DELETE:
                parseDelete(cmd);
                break;
            case UPDATE_NONFASTFORWARD:
                parseRewind(cmd);
                break;
            default:
                reject(cmd, "prohibited by Gerrit: unknown command type " + cmd.getType());
                continue;
        }
        if (cmd.getResult() != NOT_ATTEMPTED) {
            continue;
        }
        if (isConfig(cmd)) {
            logDebug("Processing {} command", cmd.getRefName());
            try {
                permissions.check(ProjectPermission.WRITE_CONFIG);
            } catch (AuthException e) {
                reject(cmd, String.format("must be either project owner or have %s permission", ProjectPermission.WRITE_CONFIG.describeForException()));
                continue;
            }
            switch(cmd.getType()) {
                case CREATE:
                case UPDATE:
                case UPDATE_NONFASTFORWARD:
                    try {
                        ProjectConfig cfg = new ProjectConfig(project.getNameKey());
                        cfg.load(rp.getRevWalk(), cmd.getNewId());
                        if (!cfg.getValidationErrors().isEmpty()) {
                            addError("Invalid project configuration:");
                            for (ValidationError err : cfg.getValidationErrors()) {
                                addError("  " + err.getMessage());
                            }
                            reject(cmd, "invalid project configuration");
                            logError("User " + user.getLoggableName() + " tried to push invalid project configuration " + cmd.getNewId().name() + " for " + project.getName());
                            continue;
                        }
                        Project.NameKey newParent = cfg.getProject().getParent(allProjectsName);
                        Project.NameKey oldParent = project.getParent(allProjectsName);
                        if (oldParent == null) {
                            // update of the 'All-Projects' project
                            if (newParent != null) {
                                reject(cmd, "invalid project configuration: root project cannot have parent");
                                continue;
                            }
                        } else {
                            if (!oldParent.equals(newParent)) {
                                try {
                                    permissionBackend.user(user).check(GlobalPermission.ADMINISTRATE_SERVER);
                                } catch (AuthException e) {
                                    reject(cmd, "invalid project configuration: only Gerrit admin can set parent");
                                    continue;
                                }
                            }
                            if (projectCache.get(newParent) == null) {
                                reject(cmd, "invalid project configuration: parent does not exist");
                                continue;
                            }
                        }
                        for (Entry<ProjectConfigEntry> e : pluginConfigEntries) {
                            PluginConfig pluginCfg = cfg.getPluginConfig(e.getPluginName());
                            ProjectConfigEntry configEntry = e.getProvider().get();
                            String value = pluginCfg.getString(e.getExportName());
                            String oldValue = projectState.getConfig().getPluginConfig(e.getPluginName()).getString(e.getExportName());
                            if (configEntry.getType() == ProjectConfigEntryType.ARRAY) {
                                oldValue = Arrays.stream(projectState.getConfig().getPluginConfig(e.getPluginName()).getStringList(e.getExportName())).collect(joining("\n"));
                            }
                            if ((value == null ? oldValue != null : !value.equals(oldValue)) && !configEntry.isEditable(projectState)) {
                                reject(cmd, String.format("invalid project configuration: Not allowed to set parameter" + " '%s' of plugin '%s' on project '%s'.", e.getExportName(), e.getPluginName(), project.getName()));
                                continue;
                            }
                            if (ProjectConfigEntryType.LIST.equals(configEntry.getType()) && value != null && !configEntry.getPermittedValues().contains(value)) {
                                reject(cmd, String.format("invalid project configuration: The value '%s' is " + "not permitted for parameter '%s' of plugin '%s'.", value, e.getExportName(), e.getPluginName()));
                            }
                        }
                    } catch (Exception e) {
                        reject(cmd, "invalid project configuration");
                        logError("User " + user.getLoggableName() + " tried to push invalid project configuration " + cmd.getNewId().name() + " for " + project.getName(), e);
                        continue;
                    }
                    break;
                case DELETE:
                    break;
                default:
                    reject(cmd, "prohibited by Gerrit: don't know how to handle config update of type " + cmd.getType());
                    continue;
            }
        }
    }
}
#end_block

#method_before
private void validateNewCommits(Branch.NameKey branch, ReceiveCommand cmd) throws PermissionBackendException {
    PermissionBackend.ForRef perm = permissions.ref(branch.get());
    if (!RefNames.REFS_CONFIG.equals(cmd.getRefName()) && !(MagicBranch.isMagicBranch(cmd.getRefName()) || NEW_PATCHSET_PATTERN.matcher(cmd.getRefName()).matches()) && pushOptions.containsKey(PUSH_OPTION_SKIP_VALIDATION)) {
        try {
            perm.check(RefPermission.SKIP_VALIDATION);
            if (!Iterables.isEmpty(rejectCommits)) {
                throw new AuthException("reject-commits prevents " + PUSH_OPTION_SKIP_VALIDATION);
            }
            logDebug("Short-circuiting new commit validation");
        } catch (AuthException denied) {
            reject(cmd, denied.getMessage());
        }
        return;
    }
    boolean missingFullName = Strings.isNullOrEmpty(user.getAccount().getFullName());
    RevWalk walk = rp.getRevWalk();
    walk.reset();
    walk.sort(RevSort.NONE);
    try {
        RevObject parsedObject = walk.parseAny(cmd.getNewId());
        if (!(parsedObject instanceof RevCommit)) {
            return;
        }
        ListMultimap<ObjectId, Ref> existing = changeRefsById();
        walk.markStart((RevCommit) parsedObject);
        markHeadsAsUninteresting(walk, cmd.getRefName());
        int limit = receiveConfig.maxBatchCommits;
        int n = 0;
        for (RevCommit c; (c = walk.next()) != null; ) {
            if (++n > limit) {
                logDebug("Number of new commits exceeds limit of {}", limit);
                addMessage("Cannot push more than " + limit + " commits to " + branch.get() + " without " + PUSH_OPTION_SKIP_VALIDATION + " option (see https://gerrit-review.googlesource.com/Documentation/" + "user-upload.html#skip_validation details)");
                reject(cmd, "too many commits");
                return;
            }
            if (existing.keySet().contains(c)) {
                continue;
            } else if (!validCommit(walk, perm, branch, cmd, c, null)) {
                break;
            }
            if (missingFullName && user.hasEmailAddress(c.getCommitterIdent().getEmailAddress())) {
                logDebug("Will update full name of caller");
                setFullNameTo = c.getCommitterIdent().getName();
                missingFullName = false;
            }
        }
        logDebug("Validated {} new commits", n);
    } catch (IOException err) {
        cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", err);
    }
}
#method_after
private void validateNewCommits(Branch.NameKey branch, ReceiveCommand cmd) throws PermissionBackendException {
    PermissionBackend.ForRef perm = permissions.ref(branch.get());
    if (!RefNames.REFS_CONFIG.equals(cmd.getRefName()) && !(MagicBranch.isMagicBranch(cmd.getRefName()) || NEW_PATCHSET_PATTERN.matcher(cmd.getRefName()).matches()) && pushOptions.containsKey(PUSH_OPTION_SKIP_VALIDATION)) {
        try {
            perm.check(RefPermission.SKIP_VALIDATION);
            if (!Iterables.isEmpty(rejectCommits)) {
                throw new AuthException("reject-commits prevents " + PUSH_OPTION_SKIP_VALIDATION);
            }
            logDebug("Short-circuiting new commit validation");
        } catch (AuthException denied) {
            reject(cmd, denied.getMessage());
        }
        return;
    }
    boolean missingFullName = Strings.isNullOrEmpty(user.getAccount().getFullName());
    RevWalk walk = rp.getRevWalk();
    walk.reset();
    walk.sort(RevSort.NONE);
    try {
        RevObject parsedObject = walk.parseAny(cmd.getNewId());
        if (!(parsedObject instanceof RevCommit)) {
            return;
        }
        ListMultimap<ObjectId, Ref> existing = changeRefsById();
        walk.markStart((RevCommit) parsedObject);
        markHeadsAsUninteresting(walk, cmd.getRefName());
        int limit = receiveConfig.maxBatchCommits;
        int n = 0;
        for (RevCommit c; (c = walk.next()) != null; ) {
            if (++n > limit) {
                logDebug("Number of new commits exceeds limit of {}", limit);
                addMessage(String.format("Cannot push more than %d commits to %s without %s option " + "(see %sDocumentation/user-upload.html#skip_validation for details)", limit, branch.get(), PUSH_OPTION_SKIP_VALIDATION, canonicalWebUrl));
                reject(cmd, "too many commits");
                return;
            }
            if (existing.keySet().contains(c)) {
                continue;
            } else if (!validCommit(walk, perm, branch, cmd, c, null)) {
                break;
            }
            if (missingFullName && user.hasEmailAddress(c.getCommitterIdent().getEmailAddress())) {
                logDebug("Will update full name of caller");
                setFullNameTo = c.getCommitterIdent().getName();
                missingFullName = false;
            }
        }
        logDebug("Validated {} new commits", n);
    } catch (IOException err) {
        cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", err);
    }
}
#end_block

#method_before
private void autoCloseChanges(ReceiveCommand cmd) {
    logDebug("Starting auto-closing of changes");
    String refName = cmd.getRefName();
    checkState(!MagicBranch.isMagicBranch(refName), "shouldn't be auto-closing changes on magic branch %s", refName);
    // insertChangesAndPatchSets.
    try {
        retryHelper.execute(updateFactory -> {
            try (BatchUpdate bu = updateFactory.create(db, projectState.getNameKey(), user, TimeUtil.nowTs());
                ObjectInserter ins = repo.newObjectInserter();
                ObjectReader reader = ins.newReader();
                RevWalk rw = new RevWalk(reader)) {
                bu.setRepository(repo, rw, ins).updateChangesInParallel();
                bu.setRequestId(receiveId);
                // TODO(dborowitz): Teach BatchUpdate to ignore missing changes.
                RevCommit newTip = rw.parseCommit(cmd.getNewId());
                Branch.NameKey branch = new Branch.NameKey(project.getNameKey(), refName);
                rw.reset();
                rw.markStart(newTip);
                if (!ObjectId.zeroId().equals(cmd.getOldId())) {
                    rw.markUninteresting(rw.parseCommit(cmd.getOldId()));
                }
                ListMultimap<ObjectId, Ref> byCommit = changeRefsById();
                Map<Change.Key, ChangeNotes> byKey = null;
                List<ReplaceRequest> replaceAndClose = new ArrayList<>();
                int existingPatchSets = 0;
                int newPatchSets = 0;
                COMMIT: for (RevCommit c; (c = rw.next()) != null; ) {
                    rw.parseBody(c);
                    for (Ref ref : byCommit.get(c.copy())) {
                        PatchSet.Id psId = PatchSet.Id.fromRef(ref.getName());
                        Optional<ChangeData> cd = executeIndexQuery(() -> byLegacyId(psId.getParentKey()));
                        if (cd.isPresent() && cd.get().change().getDest().equals(branch)) {
                            existingPatchSets++;
                            bu.addOp(psId.getParentKey(), mergedByPushOpFactory.create(requestScopePropagator, psId, refName));
                            continue COMMIT;
                        }
                    }
                    for (String changeId : c.getFooterLines(CHANGE_ID)) {
                        if (byKey == null) {
                            byKey = executeIndexQuery(() -> openChangesByKeyByBranch(branch));
                        }
                        ChangeNotes onto = byKey.get(new Change.Key(changeId.trim()));
                        if (onto != null) {
                            newPatchSets++;
                            // Hold onto this until we're done with the walk, as the call to
                            // req.validate below calls isMergedInto which resets the walk.
                            ReplaceRequest req = new ReplaceRequest(onto.getChangeId(), c, cmd, false);
                            req.notes = onto;
                            replaceAndClose.add(req);
                            continue COMMIT;
                        }
                    }
                }
                for (ReplaceRequest req : replaceAndClose) {
                    Change.Id id = req.notes.getChangeId();
                    if (!executeRequestValidation(() -> req.validate(true))) {
                        logDebug("Not closing {} because validation failed", id);
                        continue;
                    }
                    req.addOps(bu, null);
                    bu.addOp(id, mergedByPushOpFactory.create(requestScopePropagator, req.psId, refName).setPatchSetProvider(new Provider<PatchSet>() {

                        @Override
                        public PatchSet get() {
                            return req.replaceOp.getPatchSet();
                        }
                    }));
                    bu.addOp(id, new ChangeProgressOp(closeProgress));
                }
                logDebug("Auto-closing {} changes with existing patch sets and {} with new patch sets", existingPatchSets, newPatchSets);
                bu.execute();
            } catch (IOException | OrmException | PermissionBackendException e) {
                logError("Failed to auto-close changes", e);
            }
            return null;
        }, // eat up the whole timeout so that no time is left to retry this outer action.
        RetryHelper.options().timeout(retryHelper.getDefaultTimeout().multipliedBy(5)).build());
    } catch (RestApiException e) {
        logError("Can't insert patchset", e);
    } catch (UpdateException e) {
        logError("Failed to auto-close changes", e);
    }
}
#method_after
private void autoCloseChanges(ReceiveCommand cmd) {
    logDebug("Starting auto-closing of changes");
    String refName = cmd.getRefName();
    checkState(!MagicBranch.isMagicBranch(refName), "shouldn't be auto-closing changes on magic branch %s", refName);
    // insertChangesAndPatchSets.
    try {
        retryHelper.execute(updateFactory -> {
            try (BatchUpdate bu = updateFactory.create(db, projectState.getNameKey(), user, TimeUtil.nowTs());
                ObjectInserter ins = repo.newObjectInserter();
                ObjectReader reader = ins.newReader();
                RevWalk rw = new RevWalk(reader)) {
                bu.setRepository(repo, rw, ins).updateChangesInParallel();
                bu.setRequestId(receiveId);
                // TODO(dborowitz): Teach BatchUpdate to ignore missing changes.
                RevCommit newTip = rw.parseCommit(cmd.getNewId());
                Branch.NameKey branch = new Branch.NameKey(project.getNameKey(), refName);
                rw.reset();
                rw.markStart(newTip);
                if (!ObjectId.zeroId().equals(cmd.getOldId())) {
                    rw.markUninteresting(rw.parseCommit(cmd.getOldId()));
                }
                ListMultimap<ObjectId, Ref> byCommit = changeRefsById();
                Map<Change.Key, ChangeNotes> byKey = null;
                List<ReplaceRequest> replaceAndClose = new ArrayList<>();
                int existingPatchSets = 0;
                int newPatchSets = 0;
                COMMIT: for (RevCommit c; (c = rw.next()) != null; ) {
                    rw.parseBody(c);
                    for (Ref ref : byCommit.get(c.copy())) {
                        PatchSet.Id psId = PatchSet.Id.fromRef(ref.getName());
                        Optional<ChangeData> cd = executeIndexQuery(() -> byLegacyId(psId.getParentKey()));
                        if (cd.isPresent() && cd.get().change().getDest().equals(branch)) {
                            existingPatchSets++;
                            bu.addOp(psId.getParentKey(), mergedByPushOpFactory.create(requestScopePropagator, psId, refName));
                            continue COMMIT;
                        }
                    }
                    for (String changeId : c.getFooterLines(CHANGE_ID)) {
                        if (byKey == null) {
                            byKey = executeIndexQuery(() -> openChangesByKeyByBranch(branch));
                        }
                        ChangeNotes onto = byKey.get(new Change.Key(changeId.trim()));
                        if (onto != null) {
                            newPatchSets++;
                            // Hold onto this until we're done with the walk, as the call to
                            // req.validate below calls isMergedInto which resets the walk.
                            ReplaceRequest req = new ReplaceRequest(onto.getChangeId(), c, cmd, false);
                            req.notes = onto;
                            replaceAndClose.add(req);
                            continue COMMIT;
                        }
                    }
                }
                for (ReplaceRequest req : replaceAndClose) {
                    Change.Id id = req.notes.getChangeId();
                    if (!executeRequestValidation(() -> req.validate(true))) {
                        logDebug("Not closing {} because validation failed", id);
                        continue;
                    }
                    req.addOps(bu, null);
                    bu.addOp(id, mergedByPushOpFactory.create(requestScopePropagator, req.psId, refName).setPatchSetProvider(new Provider<PatchSet>() {

                        @Override
                        public PatchSet get() {
                            return req.replaceOp.getPatchSet();
                        }
                    }));
                    bu.addOp(id, new ChangeProgressOp(closeProgress));
                }
                logDebug("Auto-closing {} changes with existing patch sets and {} with new patch sets", existingPatchSets, newPatchSets);
                bu.execute();
            } catch (IOException | OrmException | PermissionBackendException e) {
                logError("Failed to auto-close changes", e);
            }
            return null;
        }, // eat up the whole timeout so that no time is left to retry this outer action.
        RetryHelper.options().timeout(retryHelper.getDefaultTimeout(ActionType.CHANGE_UPDATE).multipliedBy(5)).build());
    } catch (RestApiException e) {
        logError("Can't insert patchset", e);
    } catch (UpdateException e) {
        logError("Failed to auto-close changes", e);
    }
}
#end_block

#method_before
@Override
public AccountResource parse(TopLevelResource root, IdString id) throws ResourceNotFoundException, AuthException, OrmException, IOException, ConfigInvalidException {
    IdentifiedUser user = parseId(id.get());
    if (user == null || !accountControlFactory.get().canSee(user.getAccount())) {
        throw new ResourceNotFoundException(String.format("'%s' doesn't represent an account or is ambiguous", id));
    }
    return new AccountResource(user);
}
#method_after
@Override
public AccountResource parse(TopLevelResource root, IdString id) throws ResourceNotFoundException, AuthException, OrmException, IOException, ConfigInvalidException {
    IdentifiedUser user = parseId(id.get());
    if (user == null || !accountControlFactory.get().canSee(user.getAccount())) {
        throw new ResourceNotFoundException(String.format("Account '%s' is not found or ambiguous", id));
    }
    return new AccountResource(user);
}
#end_block

#method_before
public IdentifiedUser parseOnBehalfOf(@Nullable CurrentUser caller, String id) throws AuthException, UnprocessableEntityException, OrmException, IOException, ConfigInvalidException {
    IdentifiedUser user = parseIdOnBehalfOf(caller, id);
    if (user == null || !accountControlFactory.get().canSee(user.getAccount())) {
        throw new UnprocessableEntityException(String.format("'%s' doesn't represent an account or is ambiguous", id));
    }
    return user;
}
#method_after
public IdentifiedUser parseOnBehalfOf(@Nullable CurrentUser caller, String id) throws AuthException, UnprocessableEntityException, OrmException, IOException, ConfigInvalidException {
    IdentifiedUser user = parseIdOnBehalfOf(caller, id);
    if (user == null || !accountControlFactory.get().canSee(user.getAccount())) {
        throw new UnprocessableEntityException(String.format("Account '%s' is not found or ambiguous", id));
    }
    return user;
}
#end_block

#method_before
@Override
public Response<ChangeInfo> apply(ProjectResource rsrc, ProjectAccessInput input) throws PermissionBackendException, PermissionDeniedException, IOException, ConfigInvalidException, OrmException, InvalidNameException, UpdateException, RestApiException {
    PermissionBackend.ForProject forProject = permissionBackend.user(rsrc.getUser()).project(rsrc.getNameKey());
    if (!check(forProject, ProjectPermission.READ_CONFIG)) {
        throw new PermissionDeniedException(RefNames.REFS_CONFIG + " not visible");
    }
    if (!check(forProject, ProjectPermission.WRITE_CONFIG)) {
        try {
            forProject.ref(RefNames.REFS_CONFIG).check(RefPermission.CREATE_CHANGE);
        } catch (AuthException denied) {
            throw new PermissionDeniedException("cannot create change for " + RefNames.REFS_CONFIG);
        }
    }
    projectCache.checkedGet(rsrc.getNameKey()).checkStatePermitsWrite();
    MetaDataUpdate.User metaDataUpdateUser = metaDataUpdateFactory.get();
    List<AccessSection> removals = setAccess.getAccessSections(input.remove);
    List<AccessSection> additions = setAccess.getAccessSections(input.add);
    Project.NameKey newParentProjectName = input.parent == null ? null : new Project.NameKey(input.parent);
    try (MetaDataUpdate md = metaDataUpdateUser.create(rsrc.getNameKey())) {
        ProjectConfig config = ProjectConfig.read(md);
        setAccess.validateChanges(config, removals, additions);
        setAccess.applyChanges(config, removals, additions);
        try {
            setAccess.setParentName(rsrc.getUser().asIdentifiedUser(), config, rsrc.getNameKey(), newParentProjectName, false);
        } catch (AuthException e) {
            throw new IllegalStateException(e);
        }
        md.setMessage("Review access change");
        md.setInsertChangeId(true);
        RevCommit newCommit = config.commit(md);
        if (config.getRevision().equals(newCommit)) {
            throw new BadRequestException("no change");
        }
        Change.Id changeId = new Change.Id(seq.nextChangeId());
        RevCommit commit = config.commitToNewRef(md, new PatchSet.Id(changeId, Change.INITIAL_PATCH_SET_ID).toRefName());
        try (ObjectInserter objInserter = md.getRepository().newObjectInserter();
            ObjectReader objReader = objInserter.newReader();
            RevWalk rw = new RevWalk(objReader);
            BatchUpdate bu = updateFactory.create(db.get(), rsrc.getNameKey(), rsrc.getUser(), TimeUtil.nowTs())) {
            bu.setRepository(md.getRepository(), rw, objInserter);
            ChangeInserter ins = newInserter(changeId, commit);
            bu.insertChange(ins);
            bu.execute();
            return Response.created(jsonFactory.noOptions().format(ins.getChange()));
        }
    }
}
#method_after
@Override
public Response<ChangeInfo> apply(ProjectResource rsrc, ProjectAccessInput input) throws PermissionBackendException, PermissionDeniedException, IOException, ConfigInvalidException, OrmException, InvalidNameException, UpdateException, RestApiException {
    PermissionBackend.ForProject forProject = permissionBackend.user(rsrc.getUser()).project(rsrc.getNameKey());
    if (!check(forProject, ProjectPermission.READ_CONFIG)) {
        throw new PermissionDeniedException(RefNames.REFS_CONFIG + " not visible");
    }
    if (!check(forProject, ProjectPermission.WRITE_CONFIG)) {
        try {
            forProject.ref(RefNames.REFS_CONFIG).check(RefPermission.CREATE_CHANGE);
        } catch (AuthException denied) {
            throw new PermissionDeniedException("cannot create change for " + RefNames.REFS_CONFIG);
        }
    }
    projectCache.checkedGet(rsrc.getNameKey()).checkStatePermitsWrite();
    MetaDataUpdate.User metaDataUpdateUser = metaDataUpdateFactory.get();
    List<AccessSection> removals = setAccess.getAccessSections(input.remove);
    List<AccessSection> additions = setAccess.getAccessSections(input.add);
    Project.NameKey newParentProjectName = input.parent == null ? null : new Project.NameKey(input.parent);
    try (MetaDataUpdate md = metaDataUpdateUser.create(rsrc.getNameKey())) {
        ProjectConfig config = ProjectConfig.read(md);
        ObjectId oldCommit = config.getRevision();
        setAccess.validateChanges(config, removals, additions);
        setAccess.applyChanges(config, removals, additions);
        try {
            setAccess.setParentName(rsrc.getUser().asIdentifiedUser(), config, rsrc.getNameKey(), newParentProjectName, false);
        } catch (AuthException e) {
            throw new IllegalStateException(e);
        }
        md.setMessage("Review access change");
        md.setInsertChangeId(true);
        Change.Id changeId = new Change.Id(seq.nextChangeId());
        RevCommit commit = config.commitToNewRef(md, new PatchSet.Id(changeId, Change.INITIAL_PATCH_SET_ID).toRefName());
        if (commit.name().equals(oldCommit.getName())) {
            throw new BadRequestException("no change");
        }
        try (ObjectInserter objInserter = md.getRepository().newObjectInserter();
            ObjectReader objReader = objInserter.newReader();
            RevWalk rw = new RevWalk(objReader);
            BatchUpdate bu = updateFactory.create(db.get(), rsrc.getNameKey(), rsrc.getUser(), TimeUtil.nowTs())) {
            bu.setRepository(md.getRepository(), rw, objInserter);
            ChangeInserter ins = newInserter(changeId, commit);
            bu.insertChange(ins);
            bu.execute();
            return Response.created(jsonFactory.noOptions().format(ins.getChange()));
        }
    }
}
#end_block

#method_before
@Override
public AccessCheckInfo apply(ProjectResource rsrc, AccessCheckInput input) throws OrmException, PermissionBackendException, RestApiException, IOException, ConfigInvalidException {
    permissionBackend.user(rsrc.getUser()).check(GlobalPermission.ADMINISTRATE_SERVER);
    if (input == null) {
        throw new BadRequestException("input is required");
    }
    if (Strings.isNullOrEmpty(input.account)) {
        throw new BadRequestException("input requires 'account'");
    }
    Account match = accountResolver.find(input.account);
    if (match == null) {
        throw new UnprocessableEntityException(String.format("cannot find account %s", input.account));
    }
    AccessCheckInfo info = new AccessCheckInfo();
    IdentifiedUser user = userFactory.create(match.getId());
    try {
        permissionBackend.user(user).project(rsrc.getNameKey()).check(ProjectPermission.ACCESS);
    } catch (AuthException | PermissionBackendException e) {
        info.message = String.format("user %s (%s) cannot see project %s", user.getNameEmail(), user.getAccount().getId(), rsrc.getName());
        info.status = HttpServletResponse.SC_FORBIDDEN;
        return info;
    }
    RefPermission refPerm = null;
    if (!Strings.isNullOrEmpty(input.permission)) {
        if (Strings.isNullOrEmpty(input.ref)) {
            throw new BadRequestException("must set 'ref' when specifying 'permission'");
        }
        if (!Permission.isPermission(input.permission)) {
            throw new BadRequestException(String.format("'%s' is not recognized as permission", input.permission));
        }
        for (RefPermission p : RefPermission.values()) {
            if (!p.permissionName().isPresent()) {
                continue;
            }
            if (p.permissionName().get().equals(input.permission)) {
                refPerm = p;
                break;
            }
        }
        if (refPerm == null) {
            throw new BadRequestException(String.format("'%s' is not a recognized as ref permission", input.permission));
        }
    } else {
        refPerm = RefPermission.READ;
    }
    if (!Strings.isNullOrEmpty(input.ref)) {
        try {
            permissionBackend.user(user).ref(new Branch.NameKey(rsrc.getNameKey(), input.ref)).check(refPerm);
        } catch (AuthException | PermissionBackendException e) {
            info.status = HttpServletResponse.SC_FORBIDDEN;
            info.message = String.format("user %s (%s) lacks permission %s for %s in project %s", user.getNameEmail(), user.getAccount().getId(), input.permission, input.ref, rsrc.getName());
            return info;
        }
    }
    info.status = HttpServletResponse.SC_OK;
    return info;
}
#method_after
@Override
public AccessCheckInfo apply(ProjectResource rsrc, AccessCheckInput input) throws OrmException, PermissionBackendException, RestApiException, IOException, ConfigInvalidException {
    permissionBackend.user(rsrc.getUser()).check(GlobalPermission.ADMINISTRATE_SERVER);
    rsrc.getProjectState().checkStatePermitsRead();
    if (input == null) {
        throw new BadRequestException("input is required");
    }
    if (Strings.isNullOrEmpty(input.account)) {
        throw new BadRequestException("input requires 'account'");
    }
    Account match = accountResolver.find(input.account);
    if (match == null) {
        throw new UnprocessableEntityException(String.format("cannot find account %s", input.account));
    }
    AccessCheckInfo info = new AccessCheckInfo();
    IdentifiedUser user = userFactory.create(match.getId());
    try {
        permissionBackend.user(user).project(rsrc.getNameKey()).check(ProjectPermission.ACCESS);
    } catch (AuthException | PermissionBackendException e) {
        info.message = String.format("user %s (%s) cannot see project %s", user.getNameEmail(), user.getAccount().getId(), rsrc.getName());
        info.status = HttpServletResponse.SC_FORBIDDEN;
        return info;
    }
    RefPermission refPerm = null;
    if (!Strings.isNullOrEmpty(input.permission)) {
        if (Strings.isNullOrEmpty(input.ref)) {
            throw new BadRequestException("must set 'ref' when specifying 'permission'");
        }
        Optional<RefPermission> rp = RefPermission.fromName(input.permission);
        if (!rp.isPresent()) {
            throw new BadRequestException(String.format("'%s' is not recognized as ref permission", input.permission));
        }
        refPerm = rp.get();
    } else {
        refPerm = RefPermission.READ;
    }
    if (!Strings.isNullOrEmpty(input.ref)) {
        try {
            permissionBackend.user(user).ref(new Branch.NameKey(rsrc.getNameKey(), input.ref)).check(refPerm);
        } catch (AuthException | PermissionBackendException e) {
            info.status = HttpServletResponse.SC_FORBIDDEN;
            info.message = String.format("user %s (%s) lacks permission %s for %s in project %s", user.getNameEmail(), user.getAccount().getId(), input.permission, input.ref, rsrc.getName());
            return info;
        }
    }
    info.status = HttpServletResponse.SC_OK;
    return info;
}
#end_block

#method_before
public void setGroupUpdate(InternalGroupUpdate groupUpdate, AuditLogFormatter auditLogFormatter) {
    this.groupUpdate = Optional.of(groupUpdate);
    this.auditLogFormatter = Optional.of(auditLogFormatter);
}
#method_after
public void setGroupUpdate(InternalGroupUpdate groupUpdate, AuditLogFormatter auditLogFormatter) {
    this.groupUpdate = Optional.of(groupUpdate);
    this.auditLogFormatter = auditLogFormatter;
}
#end_block

#method_before
private <E> void saveToFile(String filePath, ImmutableSet<E> elements, Function<E, String> toStringFunction) throws IOException {
    String fileContent = elements.stream().map(toStringFunction).collect(Collectors.joining("\n"));
    saveUTF8(filePath, fileContent);
}
#method_after
private <E> void saveToFile(String filePath, ImmutableSet<E> elements, Function<E, String> toStringFunction) throws IOException {
    String fileContent = elements.stream().map(toStringFunction).collect(joining("\n"));
    saveUTF8(filePath, fileContent);
}
#end_block

#method_before
private Stream<String> getCommitFootersForMemberModifications(ImmutableSet<Account.Id> oldMembers, ImmutableSet<Account.Id> newMembers) {
    AuditLogFormatter formatter = auditLogFormatter.orElseThrow(() -> new IllegalStateException("AuditLogFormatter is necessary but missing"));
    Stream<String> removedMembers = Sets.difference(oldMembers, newMembers).stream().map(formatter::getParsableAccount).map((FOOTER_REMOVE_MEMBER.getName() + ": ")::concat);
    Stream<String> addedMembers = Sets.difference(newMembers, oldMembers).stream().map(formatter::getParsableAccount).map((FOOTER_ADD_MEMBER.getName() + ": ")::concat);
    return Stream.concat(removedMembers, addedMembers);
}
#method_after
private Stream<String> getCommitFootersForMemberModifications(ImmutableSet<Account.Id> oldMembers, ImmutableSet<Account.Id> newMembers) {
    Stream<String> removedMembers = Sets.difference(oldMembers, newMembers).stream().map(auditLogFormatter::getParsableAccount).map((FOOTER_REMOVE_MEMBER.getName() + ": ")::concat);
    Stream<String> addedMembers = Sets.difference(newMembers, oldMembers).stream().map(auditLogFormatter::getParsableAccount).map((FOOTER_ADD_MEMBER.getName() + ": ")::concat);
    return Stream.concat(removedMembers, addedMembers);
}
#end_block

#method_before
private Stream<String> getCommitFootersForSubgroupModifications(ImmutableSet<AccountGroup.UUID> oldSubgroups, ImmutableSet<AccountGroup.UUID> newSubgroups) {
    AuditLogFormatter formatter = auditLogFormatter.orElseThrow(() -> new IllegalStateException("AuditLogFormatter is necessary but missing"));
    Stream<String> removedMembers = Sets.difference(oldSubgroups, newSubgroups).stream().map(formatter::getParsableGroup).map((FOOTER_REMOVE_GROUP.getName() + ": ")::concat);
    Stream<String> addedMembers = Sets.difference(newSubgroups, oldSubgroups).stream().map(formatter::getParsableGroup).map((FOOTER_ADD_GROUP.getName() + ": ")::concat);
    return Stream.concat(removedMembers, addedMembers);
}
#method_after
private Stream<String> getCommitFootersForSubgroupModifications(ImmutableSet<AccountGroup.UUID> oldSubgroups, ImmutableSet<AccountGroup.UUID> newSubgroups) {
    Stream<String> removedMembers = Sets.difference(oldSubgroups, newSubgroups).stream().map(auditLogFormatter::getParsableGroup).map((FOOTER_REMOVE_GROUP.getName() + ": ")::concat);
    Stream<String> addedMembers = Sets.difference(newSubgroups, oldSubgroups).stream().map(auditLogFormatter::getParsableGroup).map((FOOTER_ADD_GROUP.getName() + ": ")::concat);
    return Stream.concat(removedMembers, addedMembers);
}
#end_block

#method_before
public void setGroupUpdate(InternalGroupUpdate groupUpdate, AuditLogFormatter auditLogFormatter) {
    this.groupUpdate = Optional.of(groupUpdate);
    this.auditLogFormatter = Optional.of(auditLogFormatter);
}
#method_after
public void setGroupUpdate(InternalGroupUpdate groupUpdate, AuditLogFormatter auditLogFormatter) {
    this.groupUpdate = Optional.of(groupUpdate);
    this.auditLogFormatter = auditLogFormatter;
}
#end_block

#method_before
private <E> void saveToFile(String filePath, ImmutableSet<E> elements, Function<E, String> toStringFunction) throws IOException {
    String fileContent = elements.stream().map(toStringFunction).collect(Collectors.joining("\n"));
    saveUTF8(filePath, fileContent);
}
#method_after
private <E> void saveToFile(String filePath, ImmutableSet<E> elements, Function<E, String> toStringFunction) throws IOException {
    String fileContent = elements.stream().map(toStringFunction).collect(joining("\n"));
    saveUTF8(filePath, fileContent);
}
#end_block

#method_before
private Stream<String> getCommitFootersForMemberModifications(ImmutableSet<Account.Id> oldMembers, ImmutableSet<Account.Id> newMembers) {
    AuditLogFormatter formatter = auditLogFormatter.orElseThrow(() -> new IllegalStateException("AuditLogFormatter is necessary but missing"));
    Stream<String> removedMembers = Sets.difference(oldMembers, newMembers).stream().map(formatter::getParsableAccount).map((FOOTER_REMOVE_MEMBER.getName() + ": ")::concat);
    Stream<String> addedMembers = Sets.difference(newMembers, oldMembers).stream().map(formatter::getParsableAccount).map((FOOTER_ADD_MEMBER.getName() + ": ")::concat);
    return Stream.concat(removedMembers, addedMembers);
}
#method_after
private Stream<String> getCommitFootersForMemberModifications(ImmutableSet<Account.Id> oldMembers, ImmutableSet<Account.Id> newMembers) {
    Stream<String> removedMembers = Sets.difference(oldMembers, newMembers).stream().map(auditLogFormatter::getParsableAccount).map((FOOTER_REMOVE_MEMBER.getName() + ": ")::concat);
    Stream<String> addedMembers = Sets.difference(newMembers, oldMembers).stream().map(auditLogFormatter::getParsableAccount).map((FOOTER_ADD_MEMBER.getName() + ": ")::concat);
    return Stream.concat(removedMembers, addedMembers);
}
#end_block

#method_before
private Stream<String> getCommitFootersForSubgroupModifications(ImmutableSet<AccountGroup.UUID> oldSubgroups, ImmutableSet<AccountGroup.UUID> newSubgroups) {
    AuditLogFormatter formatter = auditLogFormatter.orElseThrow(() -> new IllegalStateException("AuditLogFormatter is necessary but missing"));
    Stream<String> removedMembers = Sets.difference(oldSubgroups, newSubgroups).stream().map(formatter::getParsableGroup).map((FOOTER_REMOVE_GROUP.getName() + ": ")::concat);
    Stream<String> addedMembers = Sets.difference(newSubgroups, oldSubgroups).stream().map(formatter::getParsableGroup).map((FOOTER_ADD_GROUP.getName() + ": ")::concat);
    return Stream.concat(removedMembers, addedMembers);
}
#method_after
private Stream<String> getCommitFootersForSubgroupModifications(ImmutableSet<AccountGroup.UUID> oldSubgroups, ImmutableSet<AccountGroup.UUID> newSubgroups) {
    Stream<String> removedMembers = Sets.difference(oldSubgroups, newSubgroups).stream().map(auditLogFormatter::getParsableGroup).map((FOOTER_REMOVE_GROUP.getName() + ": ")::concat);
    Stream<String> addedMembers = Sets.difference(newSubgroups, oldSubgroups).stream().map(auditLogFormatter::getParsableGroup).map((FOOTER_ADD_GROUP.getName() + ": ")::concat);
    return Stream.concat(removedMembers, addedMembers);
}
#end_block

#method_before
@Test
public void commitMessageOfNewGroupWithMembersContainsFooters() throws Exception {
    Account account13 = createAccount(new Account.Id(13), "John");
    Account account7 = createAccount(new Account.Id(7), "Jane");
    ImmutableSet<Account> accounts = ImmutableSet.of(account13, account7);
    AuditLogFormatter auditLogFormatter = createAuditLogFormatter(accounts, ImmutableSet.of(), "server-id");
    InternalGroupCreation groupCreation = getPrefilledGroupCreationBuilder().setGroupUUID(groupUuid).build();
    InternalGroupUpdate groupUpdate = InternalGroupUpdate.builder().setMemberModification(members -> ImmutableSet.of(account13.getId(), account7.getId())).build();
    GroupConfig groupConfig = GroupConfig.createForNewGroup(repository, groupCreation);
    groupConfig.setGroupUpdate(groupUpdate, auditLogFormatter);
    commit(groupConfig);
    RevCommit revCommit = getLatestCommitForGroup(groupUuid);
    assertThat(revCommit.getFullMessage()).isEqualTo("Create group\n\nAdd: John <13@server-id>\nAdd: Jane <7@server-id>");
}
#method_after
@Test
public void commitMessageOfNewGroupWithMembersContainsFooters() throws Exception {
    Account account13 = createAccount(new Account.Id(13), "John");
    Account account7 = createAccount(new Account.Id(7), "Jane");
    ImmutableSet<Account> accounts = ImmutableSet.of(account13, account7);
    AuditLogFormatter auditLogFormatter = AuditLogFormatter.createBackedBy(accounts, ImmutableSet.of(), "server-id");
    InternalGroupCreation groupCreation = getPrefilledGroupCreationBuilder().setGroupUUID(groupUuid).build();
    InternalGroupUpdate groupUpdate = InternalGroupUpdate.builder().setMemberModification(members -> ImmutableSet.of(account13.getId(), account7.getId())).build();
    GroupConfig groupConfig = GroupConfig.createForNewGroup(repository, groupCreation);
    groupConfig.setGroupUpdate(groupUpdate, auditLogFormatter);
    commit(groupConfig);
    RevCommit revCommit = getLatestCommitForGroup(groupUuid);
    assertThat(revCommit.getFullMessage()).isEqualTo("Create group\n\nAdd: John <13@server-id>\nAdd: Jane <7@server-id>");
}
#end_block

#method_before
@Test
public void commitMessageOfNewGroupWithSubgroupsContainsFooters() throws Exception {
    GroupDescription.Basic group1 = createGroup(new AccountGroup.UUID("129403"), "Bots");
    GroupDescription.Basic group2 = createGroup(new AccountGroup.UUID("8903493"), "Verifiers");
    ImmutableSet<GroupDescription.Basic> groups = ImmutableSet.of(group1, group2);
    AuditLogFormatter auditLogFormatter = createAuditLogFormatter(ImmutableSet.of(), groups, "serverId");
    InternalGroupCreation groupCreation = getPrefilledGroupCreationBuilder().setGroupUUID(groupUuid).build();
    InternalGroupUpdate groupUpdate = InternalGroupUpdate.builder().setSubgroupModification(subgroups -> ImmutableSet.of(group1.getGroupUUID(), group2.getGroupUUID())).build();
    GroupConfig groupConfig = GroupConfig.createForNewGroup(repository, groupCreation);
    groupConfig.setGroupUpdate(groupUpdate, auditLogFormatter);
    commit(groupConfig);
    RevCommit revCommit = getLatestCommitForGroup(groupUuid);
    assertThat(revCommit.getFullMessage()).isEqualTo("Create group\n\nAdd-group: Bots <129403>\nAdd-group: Verifiers <8903493>");
}
#method_after
@Test
public void commitMessageOfNewGroupWithSubgroupsContainsFooters() throws Exception {
    GroupDescription.Basic group1 = createGroup(new AccountGroup.UUID("129403"), "Bots");
    GroupDescription.Basic group2 = createGroup(new AccountGroup.UUID("8903493"), "Verifiers");
    ImmutableSet<GroupDescription.Basic> groups = ImmutableSet.of(group1, group2);
    AuditLogFormatter auditLogFormatter = AuditLogFormatter.createBackedBy(ImmutableSet.of(), groups, "serverId");
    InternalGroupCreation groupCreation = getPrefilledGroupCreationBuilder().setGroupUUID(groupUuid).build();
    InternalGroupUpdate groupUpdate = InternalGroupUpdate.builder().setSubgroupModification(subgroups -> ImmutableSet.of(group1.getGroupUUID(), group2.getGroupUUID())).build();
    GroupConfig groupConfig = GroupConfig.createForNewGroup(repository, groupCreation);
    groupConfig.setGroupUpdate(groupUpdate, auditLogFormatter);
    commit(groupConfig);
    RevCommit revCommit = getLatestCommitForGroup(groupUuid);
    assertThat(revCommit.getFullMessage()).isEqualTo("Create group\n\nAdd-group: Bots <129403>\nAdd-group: Verifiers <8903493>");
}
#end_block

#method_before
@Test
public void commitMessageOfMemberAdditionContainsFooters() throws Exception {
    Account account13 = createAccount(new Account.Id(13), "John");
    Account account7 = createAccount(new Account.Id(7), "Jane");
    ImmutableSet<Account> accounts = ImmutableSet.of(account13, account7);
    createArbitraryGroup(groupUuid);
    AuditLogFormatter auditLogFormatter = createAuditLogFormatter(accounts, ImmutableSet.of(), "GerritServer1");
    InternalGroupUpdate groupUpdate = InternalGroupUpdate.builder().setMemberModification(members -> ImmutableSet.of(account13.getId(), account7.getId())).build();
    updateGroup(groupUuid, groupUpdate, auditLogFormatter);
    RevCommit revCommit = getLatestCommitForGroup(groupUuid);
    assertThat(revCommit.getFullMessage()).isEqualTo("Update group\n\nAdd: John <13@GerritServer1>\nAdd: Jane <7@GerritServer1>");
}
#method_after
@Test
public void commitMessageOfMemberAdditionContainsFooters() throws Exception {
    Account account13 = createAccount(new Account.Id(13), "John");
    Account account7 = createAccount(new Account.Id(7), "Jane");
    ImmutableSet<Account> accounts = ImmutableSet.of(account13, account7);
    createArbitraryGroup(groupUuid);
    AuditLogFormatter auditLogFormatter = AuditLogFormatter.createBackedBy(accounts, ImmutableSet.of(), "GerritServer1");
    InternalGroupUpdate groupUpdate = InternalGroupUpdate.builder().setMemberModification(members -> ImmutableSet.of(account13.getId(), account7.getId())).build();
    updateGroup(groupUuid, groupUpdate, auditLogFormatter);
    RevCommit revCommit = getLatestCommitForGroup(groupUuid);
    assertThat(revCommit.getFullMessage()).isEqualTo("Update group\n\nAdd: John <13@GerritServer1>\nAdd: Jane <7@GerritServer1>");
}
#end_block

#method_before
@Test
public void commitMessageOfMemberRemovalContainsFooters() throws Exception {
    Account account13 = createAccount(new Account.Id(13), "John");
    Account account7 = createAccount(new Account.Id(7), "Jane");
    ImmutableSet<Account> accounts = ImmutableSet.of(account13, account7);
    createArbitraryGroup(groupUuid);
    AuditLogFormatter auditLogFormatter = createAuditLogFormatter(accounts, ImmutableSet.of(), "server-id");
    InternalGroupUpdate groupUpdate1 = InternalGroupUpdate.builder().setMemberModification(members -> ImmutableSet.of(account13.getId(), account7.getId())).build();
    updateGroup(groupUuid, groupUpdate1, auditLogFormatter);
    InternalGroupUpdate groupUpdate2 = InternalGroupUpdate.builder().setMemberModification(members -> ImmutableSet.of(account7.getId())).build();
    updateGroup(groupUuid, groupUpdate2, auditLogFormatter);
    RevCommit revCommit = getLatestCommitForGroup(groupUuid);
    assertThat(revCommit.getFullMessage()).isEqualTo("Update group\n\nRemove: John <13@server-id>");
}
#method_after
@Test
public void commitMessageOfMemberRemovalContainsFooters() throws Exception {
    Account account13 = createAccount(new Account.Id(13), "John");
    Account account7 = createAccount(new Account.Id(7), "Jane");
    ImmutableSet<Account> accounts = ImmutableSet.of(account13, account7);
    createArbitraryGroup(groupUuid);
    AuditLogFormatter auditLogFormatter = AuditLogFormatter.createBackedBy(accounts, ImmutableSet.of(), "server-id");
    InternalGroupUpdate groupUpdate1 = InternalGroupUpdate.builder().setMemberModification(members -> ImmutableSet.of(account13.getId(), account7.getId())).build();
    updateGroup(groupUuid, groupUpdate1, auditLogFormatter);
    InternalGroupUpdate groupUpdate2 = InternalGroupUpdate.builder().setMemberModification(members -> ImmutableSet.of(account7.getId())).build();
    updateGroup(groupUuid, groupUpdate2, auditLogFormatter);
    RevCommit revCommit = getLatestCommitForGroup(groupUuid);
    assertThat(revCommit.getFullMessage()).isEqualTo("Update group\n\nRemove: John <13@server-id>");
}
#end_block

#method_before
@Test
public void commitMessageOfSubgroupAdditionContainsFooters() throws Exception {
    GroupDescription.Basic group1 = createGroup(new AccountGroup.UUID("129403"), "Bots");
    GroupDescription.Basic group2 = createGroup(new AccountGroup.UUID("8903493"), "Verifiers");
    ImmutableSet<GroupDescription.Basic> groups = ImmutableSet.of(group1, group2);
    createArbitraryGroup(groupUuid);
    AuditLogFormatter auditLogFormatter = createAuditLogFormatter(ImmutableSet.of(), groups, "serverId");
    InternalGroupUpdate groupUpdate = InternalGroupUpdate.builder().setSubgroupModification(subgroups -> ImmutableSet.of(group1.getGroupUUID(), group2.getGroupUUID())).build();
    updateGroup(groupUuid, groupUpdate, auditLogFormatter);
    RevCommit revCommit = getLatestCommitForGroup(groupUuid);
    assertThat(revCommit.getFullMessage()).isEqualTo("Update group\n\nAdd-group: Bots <129403>\nAdd-group: Verifiers <8903493>");
}
#method_after
@Test
public void commitMessageOfSubgroupAdditionContainsFooters() throws Exception {
    GroupDescription.Basic group1 = createGroup(new AccountGroup.UUID("129403"), "Bots");
    GroupDescription.Basic group2 = createGroup(new AccountGroup.UUID("8903493"), "Verifiers");
    ImmutableSet<GroupDescription.Basic> groups = ImmutableSet.of(group1, group2);
    createArbitraryGroup(groupUuid);
    AuditLogFormatter auditLogFormatter = AuditLogFormatter.createBackedBy(ImmutableSet.of(), groups, "serverId");
    InternalGroupUpdate groupUpdate = InternalGroupUpdate.builder().setSubgroupModification(subgroups -> ImmutableSet.of(group1.getGroupUUID(), group2.getGroupUUID())).build();
    updateGroup(groupUuid, groupUpdate, auditLogFormatter);
    RevCommit revCommit = getLatestCommitForGroup(groupUuid);
    assertThat(revCommit.getFullMessage()).isEqualTo("Update group\n\nAdd-group: Bots <129403>\nAdd-group: Verifiers <8903493>");
}
#end_block

#method_before
@Test
public void commitMessageOfSubgroupRemovalContainsFooters() throws Exception {
    GroupDescription.Basic group1 = createGroup(new AccountGroup.UUID("129403"), "Bots");
    GroupDescription.Basic group2 = createGroup(new AccountGroup.UUID("8903493"), "Verifiers");
    ImmutableSet<GroupDescription.Basic> groups = ImmutableSet.of(group1, group2);
    createArbitraryGroup(groupUuid);
    AuditLogFormatter auditLogFormatter = createAuditLogFormatter(ImmutableSet.of(), groups, "serverId");
    InternalGroupUpdate groupUpdate1 = InternalGroupUpdate.builder().setSubgroupModification(subgroups -> ImmutableSet.of(group1.getGroupUUID(), group2.getGroupUUID())).build();
    updateGroup(groupUuid, groupUpdate1, auditLogFormatter);
    InternalGroupUpdate groupUpdate2 = InternalGroupUpdate.builder().setSubgroupModification(subgroups -> ImmutableSet.of(group1.getGroupUUID())).build();
    updateGroup(groupUuid, groupUpdate2, auditLogFormatter);
    RevCommit revCommit = getLatestCommitForGroup(groupUuid);
    assertThat(revCommit.getFullMessage()).isEqualTo("Update group\n\nRemove-group: Verifiers <8903493>");
}
#method_after
@Test
public void commitMessageOfSubgroupRemovalContainsFooters() throws Exception {
    GroupDescription.Basic group1 = createGroup(new AccountGroup.UUID("129403"), "Bots");
    GroupDescription.Basic group2 = createGroup(new AccountGroup.UUID("8903493"), "Verifiers");
    ImmutableSet<GroupDescription.Basic> groups = ImmutableSet.of(group1, group2);
    createArbitraryGroup(groupUuid);
    AuditLogFormatter auditLogFormatter = AuditLogFormatter.createBackedBy(ImmutableSet.of(), groups, "serverId");
    InternalGroupUpdate groupUpdate1 = InternalGroupUpdate.builder().setSubgroupModification(subgroups -> ImmutableSet.of(group1.getGroupUUID(), group2.getGroupUUID())).build();
    updateGroup(groupUuid, groupUpdate1, auditLogFormatter);
    InternalGroupUpdate groupUpdate2 = InternalGroupUpdate.builder().setSubgroupModification(subgroups -> ImmutableSet.of(group1.getGroupUUID())).build();
    updateGroup(groupUuid, groupUpdate2, auditLogFormatter);
    RevCommit revCommit = getLatestCommitForGroup(groupUuid);
    assertThat(revCommit.getFullMessage()).isEqualTo("Update group\n\nRemove-group: Verifiers <8903493>");
}
#end_block

#method_before
@Test
public void commitMessageFootersCanBeMixed() throws Exception {
    Account account13 = createAccount(new Account.Id(13), "John");
    Account account7 = createAccount(new Account.Id(7), "Jane");
    ImmutableSet<Account> accounts = ImmutableSet.of(account13, account7);
    GroupDescription.Basic group1 = createGroup(new AccountGroup.UUID("129403"), "Bots");
    GroupDescription.Basic group2 = createGroup(new AccountGroup.UUID("8903493"), "Verifiers");
    ImmutableSet<GroupDescription.Basic> groups = ImmutableSet.of(group1, group2);
    createArbitraryGroup(groupUuid);
    AuditLogFormatter auditLogFormatter = createAuditLogFormatter(accounts, groups, "serverId");
    InternalGroupUpdate groupUpdate1 = InternalGroupUpdate.builder().setName(new AccountGroup.NameKey("Old name")).setMemberModification(members -> ImmutableSet.of(account7.getId())).setSubgroupModification(subgroups -> ImmutableSet.of(group2.getGroupUUID())).build();
    updateGroup(groupUuid, groupUpdate1, auditLogFormatter);
    InternalGroupUpdate groupUpdate2 = InternalGroupUpdate.builder().setName(new AccountGroup.NameKey("New name")).setMemberModification(members -> ImmutableSet.of(account13.getId())).setSubgroupModification(subgroups -> ImmutableSet.of(group1.getGroupUUID())).build();
    updateGroup(groupUuid, groupUpdate2, auditLogFormatter);
    RevCommit revCommit = getLatestCommitForGroup(groupUuid);
    assertThat(revCommit.getFullMessage()).isEqualTo("Update group\n" + "\n" + "Rename from Old name to New name\n" + "Remove: Jane <7@serverId>\n" + "Add: John <13@serverId>\n" + "Remove-group: Verifiers <8903493>\n" + "Add-group: Bots <129403>");
}
#method_after
@Test
public void commitMessageFootersCanBeMixed() throws Exception {
    Account account13 = createAccount(new Account.Id(13), "John");
    Account account7 = createAccount(new Account.Id(7), "Jane");
    ImmutableSet<Account> accounts = ImmutableSet.of(account13, account7);
    GroupDescription.Basic group1 = createGroup(new AccountGroup.UUID("129403"), "Bots");
    GroupDescription.Basic group2 = createGroup(new AccountGroup.UUID("8903493"), "Verifiers");
    ImmutableSet<GroupDescription.Basic> groups = ImmutableSet.of(group1, group2);
    createArbitraryGroup(groupUuid);
    AuditLogFormatter auditLogFormatter = AuditLogFormatter.createBackedBy(accounts, groups, "serverId");
    InternalGroupUpdate groupUpdate1 = InternalGroupUpdate.builder().setName(new AccountGroup.NameKey("Old name")).setMemberModification(members -> ImmutableSet.of(account7.getId())).setSubgroupModification(subgroups -> ImmutableSet.of(group2.getGroupUUID())).build();
    updateGroup(groupUuid, groupUpdate1, auditLogFormatter);
    InternalGroupUpdate groupUpdate2 = InternalGroupUpdate.builder().setName(new AccountGroup.NameKey("New name")).setMemberModification(members -> ImmutableSet.of(account13.getId())).setSubgroupModification(subgroups -> ImmutableSet.of(group1.getGroupUUID())).build();
    updateGroup(groupUuid, groupUpdate2, auditLogFormatter);
    RevCommit revCommit = getLatestCommitForGroup(groupUuid);
    assertThat(revCommit.getFullMessage()).isEqualTo("Update group\n" + "\n" + "Rename from Old name to New name\n" + "Remove: Jane <7@serverId>\n" + "Add: John <13@serverId>\n" + "Remove-group: Verifiers <8903493>\n" + "Add-group: Bots <129403>");
}
#end_block

#method_before
@Test
public void fromName() {
    assertThat(RefPermission.fromName("doesnotexist")).isNull();
    assertThat(RefPermission.fromName("")).isNull();
    assertThat(RefPermission.fromName(Permission.VIEW_PRIVATE_CHANGES)).isEqualTo(RefPermission.READ_PRIVATE_CHANGES);
}
#method_after
@Test
public void fromName() {
    assertThat(RefPermission.fromName("doesnotexist")).isEmpty();
    assertThat(RefPermission.fromName("")).isEmpty();
    assertThat(RefPermission.fromName(Permission.VIEW_PRIVATE_CHANGES)).hasValue(RefPermission.READ_PRIVATE_CHANGES);
}
#end_block

#method_before
protected void removeUsersThatIgnoredTheChange() {
    for (Map.Entry<Account.Id, Collection<String>> e : stars.asMap().entrySet()) {
        if (e.getValue().contains(StarredChangesUtil.IGNORE_LABEL)) {
            args.accountCache.maybeGet(e.getKey()).map(AccountState::getAccount).ifPresent(a -> removeUser(a));
        }
    }
}
#method_after
protected void removeUsersThatIgnoredTheChange() {
    for (Map.Entry<Account.Id, Collection<String>> e : stars.asMap().entrySet()) {
        if (e.getValue().contains(StarredChangesUtil.IGNORE_LABEL)) {
            args.accountCache.maybeGet(e.getKey()).ifPresent(a -> removeUser(a.getAccount()));
        }
    }
}
#end_block

#method_before
public Account find(String nameOrEmail) throws OrmException, IOException, ConfigInvalidException {
    Set<Account.Id> r = findAll(nameOrEmail);
    if (r.size() == 1) {
        return byId.get(r.iterator().next()).getAccount();
    }
    Account match = null;
    for (Account.Id id : r) {
        Optional<Account> account = byId.maybeGet(id).map(AccountState::getAccount);
        if (!account.isPresent() || !account.get().isActive()) {
            continue;
        }
        if (match != null) {
            return null;
        }
        match = account.get();
    }
    return match;
}
#method_after
public Account find(String nameOrEmail) throws OrmException, IOException, ConfigInvalidException {
    Set<Account.Id> r = findAll(nameOrEmail);
    if (r.size() == 1) {
        return byId.get(r.iterator().next()).getAccount();
    }
    Account match = null;
    for (Account.Id id : r) {
        Optional<Account> account = byId.maybeGet(id).map(AccountState::getAccount);
        if (!account.map(Account::isActive).orElse(false)) {
            continue;
        }
        if (match != null) {
            return null;
        }
        match = account.get();
    }
    return match;
}
#end_block

#method_before
@Override
public EditPreferencesInfo apply(AccountResource rsrc, EditPreferencesInfo input) throws RestApiException, RepositoryNotFoundException, IOException, ConfigInvalidException, PermissionBackendException, OrmException {
    if (self.get() != rsrc.getUser()) {
        permissionBackend.user(self).check(GlobalPermission.MODIFY_ACCOUNT);
    }
    if (input == null) {
        throw new BadRequestException("input must be provided");
    }
    Account.Id id = rsrc.getUser().getAccountId();
    return accountsUpdate.create().update("Set Edit Preferences via API", id, u -> u.setEditPreferences(input)).map(AccountState::getEditPreferences).orElseThrow(ResourceNotFoundException::new);
}
#method_after
@Override
public EditPreferencesInfo apply(AccountResource rsrc, EditPreferencesInfo input) throws RestApiException, RepositoryNotFoundException, IOException, ConfigInvalidException, PermissionBackendException, OrmException {
    if (self.get() != rsrc.getUser()) {
        permissionBackend.user(self).check(GlobalPermission.MODIFY_ACCOUNT);
    }
    if (input == null) {
        throw new BadRequestException("input must be provided");
    }
    Account.Id id = rsrc.getUser().getAccountId();
    return accountsUpdate.create().update("Set Edit Preferences via API", id, u -> u.setEditPreferences(input)).map(AccountState::getEditPreferences).orElseThrow(() -> new ResourceNotFoundException(IdString.fromDecoded(id.toString())));
}
#end_block

#method_before
@Override
public GeneralPreferencesInfo apply(AccountResource rsrc, GeneralPreferencesInfo input) throws RestApiException, IOException, ConfigInvalidException, PermissionBackendException, OrmException {
    if (self.get() != rsrc.getUser()) {
        permissionBackend.user(self).check(GlobalPermission.MODIFY_ACCOUNT);
    }
    checkDownloadScheme(input.downloadScheme);
    Preferences.validateMy(input.my);
    Account.Id id = rsrc.getUser().getAccountId();
    return accountsUpdate.create().update("Set General Preferences via API", id, u -> u.setGeneralPreferences(input)).map(AccountState::getGeneralPreferences).orElseThrow(ResourceNotFoundException::new);
}
#method_after
@Override
public GeneralPreferencesInfo apply(AccountResource rsrc, GeneralPreferencesInfo input) throws RestApiException, IOException, ConfigInvalidException, PermissionBackendException, OrmException {
    if (self.get() != rsrc.getUser()) {
        permissionBackend.user(self).check(GlobalPermission.MODIFY_ACCOUNT);
    }
    checkDownloadScheme(input.downloadScheme);
    Preferences.validateMy(input.my);
    Account.Id id = rsrc.getUser().getAccountId();
    return accountsUpdate.create().update("Set General Preferences via API", id, u -> u.setGeneralPreferences(input)).map(AccountState::getGeneralPreferences).orElseThrow(() -> new ResourceNotFoundException(IdString.fromDecoded(id.toString())));
}
#end_block

#method_before
@Override
public DiffPreferencesInfo apply(AccountResource rsrc, DiffPreferencesInfo input) throws RestApiException, ConfigInvalidException, RepositoryNotFoundException, IOException, PermissionBackendException, OrmException {
    if (self.get() != rsrc.getUser()) {
        permissionBackend.user(self).check(GlobalPermission.MODIFY_ACCOUNT);
    }
    if (input == null) {
        throw new BadRequestException("input must be provided");
    }
    Account.Id id = rsrc.getUser().getAccountId();
    return accountsUpdate.create().update("Set Diff Preferences via API", id, u -> u.setDiffPreferences(input)).map(AccountState::getDiffPreferences).orElseThrow(ResourceNotFoundException::new);
}
#method_after
@Override
public DiffPreferencesInfo apply(AccountResource rsrc, DiffPreferencesInfo input) throws RestApiException, ConfigInvalidException, RepositoryNotFoundException, IOException, PermissionBackendException, OrmException {
    if (self.get() != rsrc.getUser()) {
        permissionBackend.user(self).check(GlobalPermission.MODIFY_ACCOUNT);
    }
    if (input == null) {
        throw new BadRequestException("input must be provided");
    }
    Account.Id id = rsrc.getUser().getAccountId();
    return accountsUpdate.create().update("Set Diff Preferences via API", id, u -> u.setDiffPreferences(input)).map(AccountState::getDiffPreferences).orElseThrow(() -> new ResourceNotFoundException(IdString.fromDecoded(id.toString())));
}
#end_block

#method_before
private void update(AuthRequest who, ExternalId extId) throws OrmException, IOException, ConfigInvalidException {
    IdentifiedUser user = userFactory.create(extId.accountId());
    List<Consumer<InternalAccountUpdate.Builder>> accountUpdates = new ArrayList<>();
    // If the email address was modified by the authentication provider,
    // update our records to match the changed email.
    // 
    String newEmail = who.getEmailAddress();
    String oldEmail = extId.email();
    if (newEmail != null && !newEmail.equals(oldEmail)) {
        if (oldEmail != null && oldEmail.equals(user.getAccount().getPreferredEmail())) {
            accountUpdates.add(u -> u.setPreferredEmail(newEmail));
        }
        accountUpdates.add(u -> u.replaceExternalId(extId, ExternalId.create(extId.key(), extId.accountId(), newEmail, extId.password())));
    }
    if (!realm.allowsEdit(AccountFieldName.FULL_NAME) && !Strings.isNullOrEmpty(who.getDisplayName()) && !Objects.equals(user.getAccount().getFullName(), who.getDisplayName())) {
        accountUpdates.add(u -> u.setFullName(who.getDisplayName()));
    }
    if (!realm.allowsEdit(AccountFieldName.USER_NAME) && !Strings.isNullOrEmpty(who.getUserName()) && !who.getUserName().equals(user.getUserName())) {
        if (user.getUserName() != null) {
            log.warn(String.format("Not changing already set username %s to %s", user.getUserName(), who.getUserName()));
        } else {
            log.warn(String.format("Not setting username to %s", who.getUserName()));
        }
    }
    if (!accountUpdates.isEmpty()) {
        accountsUpdateFactory.create().update("Update Account on Login", user.getAccountId(), AccountUpdater.joinConsumers(accountUpdates)).orElseThrow(() -> new OrmException("Account " + user.getAccountId() + " has been deleted"));
    }
}
#method_after
private void update(AuthRequest who, ExternalId extId) throws OrmException, IOException, ConfigInvalidException {
    IdentifiedUser user = userFactory.create(extId.accountId());
    List<Consumer<InternalAccountUpdate.Builder>> accountUpdates = new ArrayList<>();
    // If the email address was modified by the authentication provider,
    // update our records to match the changed email.
    // 
    String newEmail = who.getEmailAddress();
    String oldEmail = extId.email();
    if (newEmail != null && !newEmail.equals(oldEmail)) {
        if (oldEmail != null && oldEmail.equals(user.getAccount().getPreferredEmail())) {
            accountUpdates.add(u -> u.setPreferredEmail(newEmail));
        }
        accountUpdates.add(u -> u.replaceExternalId(extId, ExternalId.create(extId.key(), extId.accountId(), newEmail, extId.password())));
    }
    if (!realm.allowsEdit(AccountFieldName.FULL_NAME) && !Strings.isNullOrEmpty(who.getDisplayName()) && !Objects.equals(user.getAccount().getFullName(), who.getDisplayName())) {
        accountUpdates.add(u -> u.setFullName(who.getDisplayName()));
    }
    if (!realm.allowsEdit(AccountFieldName.USER_NAME) && !Strings.isNullOrEmpty(who.getUserName()) && !who.getUserName().equals(user.getUserName())) {
        if (user.getUserName() != null) {
            log.warn("Not changing already set username {} to {}", user.getUserName(), who.getUserName());
        } else {
            log.warn("Not setting username to {}", who.getUserName());
        }
    }
    if (!accountUpdates.isEmpty()) {
        accountsUpdateFactory.create().update("Update Account on Login", user.getAccountId(), AccountUpdater.joinConsumers(accountUpdates)).orElseThrow(() -> new OrmException("Account " + user.getAccountId() + " has been deleted"));
    }
}
#end_block

#method_before
public <T> T execute(ActionType actionType, Action<T> action, Options opts, Predicate<Throwable> exceptionPredicate) throws Exception {
    try {
        return executeWithAttemptCount(actionType, action, opts, exceptionPredicate);
    } catch (Throwable t) {
        Throwables.throwIfUnchecked(t);
        Throwables.throwIfInstanceOf(t, Exception.class);
        throw new IllegalStateException(t);
    }
}
#method_after
public <T> T execute(ActionType actionType, Action<T> action, Options opts, Predicate<Throwable> exceptionPredicate) throws Exception {
    try {
        return executeWithAttemptAndTimeoutCount(actionType, action, opts, exceptionPredicate);
    } catch (Throwable t) {
        Throwables.throwIfUnchecked(t);
        Throwables.throwIfInstanceOf(t, Exception.class);
        throw new IllegalStateException(t);
    }
}
#end_block

#method_before
public Optional<AccountState> update(String message, Account.Id accountId, Consumer<InternalAccountUpdate.Builder> update) throws OrmException, IOException, ConfigInvalidException {
    return update(message, accountId, AccountUpdater.fromConsumer(update));
}
#method_after
public Optional<AccountState> update(String message, Account.Id accountId, Consumer<InternalAccountUpdate.Builder> update) throws OrmException, LockFailureException, IOException, ConfigInvalidException {
    return update(message, accountId, AccountUpdater.fromConsumer(update));
}
#end_block

#method_before
public Optional<AccountState> update(String message, Account.Id accountId, AccountUpdater updater) throws OrmException, IOException, ConfigInvalidException {
    return updateAccount(r -> {
        AccountConfig accountConfig = read(r, accountId);
        Optional<AccountState> account = AccountState.fromAccountConfig(allUsersName, externalIds, accountConfig);
        if (!account.isPresent()) {
            return null;
        }
        InternalAccountUpdate.Builder updateBuilder = InternalAccountUpdate.builder();
        updater.update(account.get(), updateBuilder);
        InternalAccountUpdate update = updateBuilder.build();
        accountConfig.setAccountUpdate(update);
        ExternalIdNotes extIdNotes = createExternalIdNotes(r, accountConfig.getExternalIdsRev(), accountId, update);
        UpdatedAccount updatedAccounts = new UpdatedAccount(allUsersName, externalIds, message, accountConfig, extIdNotes);
        return updatedAccounts;
    });
}
#method_after
public Optional<AccountState> update(String message, Account.Id accountId, AccountUpdater updater) throws OrmException, LockFailureException, IOException, ConfigInvalidException {
    return updateAccount(r -> {
        AccountConfig accountConfig = read(r, accountId);
        Optional<AccountState> account = AccountState.fromAccountConfig(allUsersName, externalIds, accountConfig);
        if (!account.isPresent()) {
            return null;
        }
        InternalAccountUpdate.Builder updateBuilder = InternalAccountUpdate.builder();
        updater.update(account.get(), updateBuilder);
        InternalAccountUpdate update = updateBuilder.build();
        accountConfig.setAccountUpdate(update);
        ExternalIdNotes extIdNotes = createExternalIdNotes(r, accountConfig.getExternalIdsRev(), accountId, update);
        UpdatedAccount updatedAccounts = new UpdatedAccount(allUsersName, externalIds, message, accountConfig, extIdNotes);
        return updatedAccounts;
    });
}
#end_block

#method_before
@Test
@GerritConfig(name = "download.archive", values = { "txz" })
public void txzFormat() throws Exception {
    PushOneCommit.Result r = createChange();
    String abbreviated = r.getCommit().abbreviate(8).name();
    String c = command(r, "tar.xz", abbreviated);
    InputStream out = adminSshSession.exec2("git-upload-archive " + project.get(), argumentsToInputStream(c));
    // Wrap with PacketLineIn to read ACK bytes from output stream
    PacketLineIn in = new PacketLineIn(out);
    String tmp = in.readString();
    assertThat(tmp).isEqualTo("ACK");
    ByteBuffer buf = IO.readWholeStream(out, 1024);
    System.err.println(new String(buf.array()));
}
#method_after
@Test
public void txzFormat() throws Exception {
    PushOneCommit.Result r = createChange();
    String abbreviated = r.getCommit().abbreviate(8).name();
    String c = command(r, "tar.xz", abbreviated);
    try (InputStream out = adminSshSession.exec2("git-upload-archive " + project.get(), argumentsToInputStream(c))) {
        // Wrap with PacketLineIn to read ACK bytes from output stream
        PacketLineIn in = new PacketLineIn(out);
        String packet = in.readString();
        assertThat(packet).isEqualTo("ACK");
        // Discard first bit of data, which should be empty.
        packet = in.readString();
        assertThat(packet).isEmpty();
        // Make sure the next one is not on the error channel
        packet = in.readString();
        // 1 = DATA. It would be nicer to parse the OutputStream with SideBandInputStream from JGit, but
        // that is currently not public.
        char channel = packet.charAt(0);
        if (channel != 1) {
            fail("got packet on channel " + (int) channel, packet);
        }
    }
}
#end_block

#method_before
private String command(PushOneCommit.Result r, String format, String abbreviated) {
    String c = "-f=" + format + " " + "--prefix=" + abbreviated + "/ " + r.getCommit().name() + " " + PushOneCommit.FILE_NAME;
    return c;
}
#method_after
private String command(PushOneCommit.Result r, String format, String abbreviated) {
    String c = String.format("-f=%s --prefix=%s/ %s %s", format, abbreviated, r.getCommit().name(), PushOneCommit.FILE_NAME);
    return c;
}
#end_block

#method_before
private void assertArchiveNotPermitted() throws Exception {
    PushOneCommit.Result r = createChange();
    String abbreviated = r.getCommit().abbreviate(8).name();
    String c = command(r, "zip", abbreviated);
    InputStream out = adminSshSession.exec2("git-upload-archive " + project.get(), argumentsToInputStream(c));
    // Wrap with PacketLineIn to read ACK bytes from output stream
    PacketLineIn in = new PacketLineIn(out);
    String tmp = in.readString();
    assertThat(tmp).isEqualTo("ACK");
    tmp = in.readString();
    tmp = in.readString();
    tmp = tmp.substring(1);
    assertThat(tmp).isEqualTo("fatal: upload-archive not permitted");
}
#method_after
private void assertArchiveNotPermitted() throws Exception {
    PushOneCommit.Result r = createChange();
    String abbreviated = r.getCommit().abbreviate(8).name();
    String c = command(r, "zip", abbreviated);
    InputStream out = adminSshSession.exec2("git-upload-archive " + project.get(), argumentsToInputStream(c));
    // Wrap with PacketLineIn to read ACK bytes from output stream
    PacketLineIn in = new PacketLineIn(out);
    String tmp = in.readString();
    assertThat(tmp).isEqualTo("ACK");
    tmp = in.readString();
    tmp = in.readString();
    tmp = tmp.substring(1);
    assertThat(tmp).isEqualTo("fatal: upload-archive not permitted for format zip");
}
#end_block

#method_before
protected void readArguments() throws IOException, Failure {
    String argCmd = "argument ";
    List<String> args = new ArrayList<>();
    // Read arguments in Pkt-Line format
    PacketLineIn packetIn = new PacketLineIn(in);
    for (; ; ) {
        String s = packetIn.readString();
        if (s == PacketLineIn.END) {
            break;
        }
        if (!s.startsWith(argCmd)) {
            throw new Failure(1, "fatal: 'argument' token or flush expected");
        }
        String[] parts = s.substring(argCmd.length()).split("=", 2);
        for (String p : parts) {
            args.add(p);
        }
    }
    try {
        // Parse them into the 'options' field
        CmdLineParser parser = new CmdLineParser(options);
        parser.parseArgument(args);
        if (options.path == null || Arrays.asList(".").equals(options.path)) {
            options.path = Collections.emptyList();
        }
    } catch (CmdLineException e) {
        throw new Failure(2, "fatal: unable to parse arguments, " + e);
    }
}
#method_after
protected void readArguments() throws IOException, Failure {
    String argCmd = "argument ";
    List<String> args = new ArrayList<>();
    // Read arguments in Pkt-Line format
    PacketLineIn packetIn = new PacketLineIn(in);
    for (; ; ) {
        String s = packetIn.readString();
        if (s == PacketLineIn.END) {
            break;
        }
        if (!s.startsWith(argCmd)) {
            throw new Failure(1, "fatal: 'argument' token or flush expected, got " + s);
        }
        String[] parts = s.substring(argCmd.length()).split("=", 2);
        for (String p : parts) {
            args.add(p);
        }
    }
    try {
        // Parse them into the 'options' field
        CmdLineParser parser = new CmdLineParser(options);
        parser.parseArgument(args);
        if (options.path == null || Arrays.asList(".").equals(options.path)) {
            options.path = Collections.emptyList();
        }
    } catch (CmdLineException e) {
        throw new Failure(2, "fatal: unable to parse arguments, " + e);
    }
}
#end_block

#method_before
@Override
protected void runImpl() throws IOException, PermissionBackendException, Failure {
    PacketLineOut packetOut = new PacketLineOut(out);
    packetOut.setFlushOnEnd(true);
    packetOut.writeString("ACK");
    packetOut.end();
    try {
        // Parse Git arguments
        readArguments();
        ArchiveFormat f = allowedFormats.getExtensions().get("." + options.format);
        if (f == null) {
            throw new Failure(3, "fatal: upload-archive not permitted");
        }
        // Find out the object to get from the specified reference and paths
        ObjectId treeId = repo.resolve(options.treeIsh);
        if (treeId == null) {
            throw new Failure(4, "fatal: reference not found");
        }
        // Verify the user has permissions to read the specified tree.
        if (!canRead(treeId)) {
            throw new Failure(5, "fatal: cannot perform upload-archive operation");
        }
        // The archive is sent in DATA sideband channel
        try (SideBandOutputStream sidebandOut = new SideBandOutputStream(SideBandOutputStream.CH_DATA, SideBandOutputStream.MAX_BUF, out)) {
            new ArchiveCommand(repo).setFormat(f.name()).setFormatOptions(getFormatOptions(f)).setTree(treeId).setPaths(options.path.toArray(new String[0])).setPrefix(options.prefix).setOutputStream(sidebandOut).call();
            sidebandOut.flush();
        } catch (GitAPIException e) {
            System.err.println("API exception" + e);
            throw new Failure(7, "fatal: git api exception, " + e);
        }
    } catch (Failure f) {
        System.err.println("Failure: " + f);
        // Report the error in ERROR sideband channel
        try (SideBandOutputStream sidebandError = new SideBandOutputStream(SideBandOutputStream.CH_ERROR, SideBandOutputStream.MAX_BUF, out)) {
            sidebandError.write(f.getMessage().getBytes(UTF_8));
            sidebandError.flush();
        }
        throw f;
    } finally {
        // In any case, cleanly close the packetOut channel
        packetOut.end();
    }
}
#method_after
@Override
protected void runImpl() throws IOException, PermissionBackendException, Failure {
    PacketLineOut packetOut = new PacketLineOut(out);
    packetOut.setFlushOnEnd(true);
    packetOut.writeString("ACK");
    packetOut.end();
    try {
        // Parse Git arguments
        readArguments();
        ArchiveFormat f = allowedFormats.getExtensions().get("." + options.format);
        if (f == null) {
            throw new Failure(3, "fatal: upload-archive not permitted for format " + options.format);
        }
        // Find out the object to get from the specified reference and paths
        ObjectId treeId = repo.resolve(options.treeIsh);
        if (treeId == null) {
            throw new Failure(4, "fatal: reference not found: " + options.treeIsh);
        }
        // Verify the user has permissions to read the specified tree.
        if (!canRead(treeId)) {
            throw new Failure(5, "fatal: no permission to read tree" + options.treeIsh);
        }
        // The archive is sent in DATA sideband channel
        try (SideBandOutputStream sidebandOut = new SideBandOutputStream(SideBandOutputStream.CH_DATA, SideBandOutputStream.MAX_BUF, out)) {
            new ArchiveCommand(repo).setFormat(f.name()).setFormatOptions(getFormatOptions(f)).setTree(treeId).setPaths(options.path.toArray(new String[0])).setPrefix(options.prefix).setOutputStream(sidebandOut).call();
            sidebandOut.flush();
        } catch (GitAPIException e) {
            throw new Failure(7, "fatal: git api exception, " + e);
        }
    } catch (Throwable t) {
        // NoClassDefFound.
        try (SideBandOutputStream sidebandError = new SideBandOutputStream(SideBandOutputStream.CH_ERROR, SideBandOutputStream.MAX_BUF, out)) {
            sidebandError.write(t.getMessage().getBytes(UTF_8));
            sidebandError.flush();
        }
        throw t;
    } finally {
        // In any case, cleanly close the packetOut channel
        packetOut.end();
    }
}
#end_block

#method_before
public boolean isEnabled(Project.NameKey projectNK, String refName) {
    ProjectState projectState = projectCache.get(projectNK);
    if (projectState == null) {
        log.error("Failed to check if " + pluginName + " is enabled for project " + projectNK.get() + ": Project " + projectNK.get() + " not found");
        return false;
    }
    if (isEnforcedByAnyParentProject(refName, projectState)) {
        return true;
    }
    return !"false".equals(pluginCfgFactory.getFromProjectConfigWithInheritance(projectState, pluginName).getString("enabled", "false")) && isEnabledForBranch(projectState, refName);
}
#method_after
// Plugin enablement --------------------------------------------------------
public boolean isEnabled(RefEvent event) {
    if (event instanceof PatchSetCreatedEvent || event instanceof CommentAddedEvent || event instanceof ChangeMergedEvent || event instanceof ChangeAbandonedEvent || event instanceof ChangeRestoredEvent || event instanceof RefUpdatedEvent) {
        return isEnabled(event.getProjectNameKey(), event.getRefName());
    }
    log.debug("Event {} not recognised and ignored", event);
    return false;
}
#end_block

#method_before
public boolean isEnabled(Project.NameKey projectNK, String refName) {
    ProjectState projectState = projectCache.get(projectNK);
    if (projectState == null) {
        log.error("Failed to check if " + pluginName + " is enabled for project " + projectNK.get() + ": Project " + projectNK.get() + " not found");
        return false;
    }
    if (isEnforcedByAnyParentProject(refName, projectState)) {
        return true;
    }
    return !"false".equals(pluginCfgFactory.getFromProjectConfigWithInheritance(projectState, pluginName).getString("enabled", "false")) && isEnabledForBranch(projectState, refName);
}
#method_after
public boolean isEnabled(Project.NameKey projectNK, String refName) {
    ProjectState projectState = projectCache.get(projectNK);
    if (projectState == null) {
        log.error("Failed to check if {} is enabled for project {}: Project not found", pluginName, projectNK.get());
        return false;
    }
    if (isEnforcedByAnyParentProject(refName, projectState)) {
        return true;
    }
    return !"false".equals(pluginCfgFactory.getFromProjectConfigWithInheritance(projectState, pluginName).getString("enabled", "false")) && isEnabledForBranch(projectState, refName);
}
#end_block

#method_before
// Issue association --------------------------------------------------------
public String getCommentLinkName() {
    String ret;
    ret = getPluginConfigString("commentlink", null);
    if (ret == null) {
        ret = pluginName;
    }
    return ret;
}
#method_after
// Issue association --------------------------------------------------------
public String getCommentLinkName() {
    String ret;
    ret = getPluginConfigString("commentlink");
    if (ret == null) {
        ret = pluginName;
    }
    return ret;
}
#end_block

#method_before
public Pattern getIssuePattern() {
    Optional<String> match = FluentIterable.from(getCommentLinkInfo(getCommentLinkName())).filter(new Predicate<CommentLinkInfo>() {

        @Override
        public boolean apply(CommentLinkInfo input) {
            return input.match != null && !input.match.trim().isEmpty();
        }
    }).transform(new Function<CommentLinkInfo, String>() {

        @Override
        public String apply(CommentLinkInfo input) {
            return input.match;
        }
    }).last();
    String defPattern = gerritConfig.getString("commentlink", getCommentLinkName(), "match");
    if (!match.isPresent() && defPattern == null) {
        return null;
    }
    return Pattern.compile(match.or(defPattern));
}
#method_after
public Pattern getIssuePattern() {
    Optional<String> match = getCommentLinkInfo(getCommentLinkName()).stream().filter(input -> input.match != null && !input.match.trim().isEmpty()).map(input -> input.match).reduce((a, b) -> b);
    String defPattern = gerritConfig.getString("commentlink", getCommentLinkName(), "match");
    if (!match.isPresent() && defPattern == null) {
        return null;
    }
    return Pattern.compile(match.orElse(defPattern));
}
#end_block

#method_before
public Pattern getDummyIssuePattern() {
    return Pattern.compile(getPluginConfigString("dummyIssuePattern", "x^"));
}
#method_after
public Optional<Pattern> getDummyIssuePattern() {
    return Optional.ofNullable(getPluginConfigString("dummyIssuePattern")).map(Pattern::compile);
}
#end_block

#method_before
private String getPluginConfigString(String key, String defaultValue) {
    String val = getCurrentPluginConfig().getString(key, gerritConfig.getString(PLUGIN, pluginName, key));
    return val == null ? defaultValue : val;
}
#method_after
private String getPluginConfigString(String key) {
    return getCurrentPluginConfig().getString(key, gerritConfig.getString(PLUGIN, pluginName, key));
}
#end_block

#method_before
private List<CommentLinkInfo> getCommentLinkInfo(final String commentlinkName) {
    NameKey projectName = currentProjectName.get();
    if (projectName != null) {
        List<CommentLinkInfo> commentlinks = projectCache.get(projectName).getCommentLinks();
        return FluentIterable.from(commentlinks).filter(new Predicate<CommentLinkInfo>() {

            @Override
            public boolean apply(CommentLinkInfo input) {
                return input.name.equals(commentlinkName);
            }
        }).toList();
    }
    return Collections.emptyList();
}
#method_after
private List<CommentLinkInfo> getCommentLinkInfo(final String commentlinkName) {
    NameKey projectName = currentProjectName.get();
    if (projectName != null) {
        List<CommentLinkInfo> commentlinks = projectCache.get(projectName).getCommentLinks();
        return commentlinks.stream().filter(input -> input.name.equals(commentlinkName)).collect(toList());
    }
    return Collections.emptyList();
}
#end_block

#method_before
public void testSuggestedNonMatching() throws CommitValidationException {
    List<CommitValidationMessage> ret;
    ItsValidateComment ivc = injector.getInstance(ItsValidateComment.class);
    ReceiveCommand command = createMock(ReceiveCommand.class);
    RevCommit commit = createMock(RevCommit.class);
    CommitReceivedEvent event = newCommitReceivedEvent(command, project, null, commit, null);
    expect(itsConfig.getItsAssociationPolicy()).andReturn(ItsAssociationPolicy.SUGGESTED).atLeastOnce();
    expect(itsConfig.getDummyIssuePattern()).andReturn(Pattern.compile("x^")).atLeastOnce();
    expect(commit.getFullMessage()).andReturn("TestMessage").atLeastOnce();
    expect(commit.getId()).andReturn(commit).anyTimes();
    expect(commit.getName()).andReturn("TestCommit").anyTimes();
    expect(issueExtractor.getIssueIds("TestMessage")).andReturn(new String[] {}).atLeastOnce();
    replayMocks();
    ret = ivc.onCommitReceived(event);
    assertEquals("Size of returned CommitValidationMessages does not match", 1, ret.size());
    assertTrue("First CommitValidationMessages does not contain 'Missing " + "issue'", ret.get(0).getMessage().contains("Missing issue"));
}
#method_after
public void testSuggestedNonMatching() throws CommitValidationException {
    List<CommitValidationMessage> ret;
    ItsValidateComment ivc = injector.getInstance(ItsValidateComment.class);
    ReceiveCommand command = createMock(ReceiveCommand.class);
    RevCommit commit = createMock(RevCommit.class);
    CommitReceivedEvent event = newCommitReceivedEvent(command, project, null, commit, null);
    expect(itsConfig.getItsAssociationPolicy()).andReturn(ItsAssociationPolicy.SUGGESTED).atLeastOnce();
    expect(itsConfig.getDummyIssuePattern()).andReturn(Optional.empty()).atLeastOnce();
    expect(commit.getFullMessage()).andReturn("TestMessage").atLeastOnce();
    expect(commit.getId()).andReturn(commit).anyTimes();
    expect(commit.getName()).andReturn("TestCommit").anyTimes();
    expect(issueExtractor.getIssueIds("TestMessage")).andReturn(new String[] {}).atLeastOnce();
    replayMocks();
    ret = ivc.onCommitReceived(event);
    assertEquals("Size of returned CommitValidationMessages does not match", 1, ret.size());
    assertTrue("First CommitValidationMessages does not contain 'Missing " + "issue'", ret.get(0).getMessage().contains("Missing issue"));
}
#end_block

#method_before
public void testMandatoryNonMatching() {
    ItsValidateComment ivc = injector.getInstance(ItsValidateComment.class);
    ReceiveCommand command = createMock(ReceiveCommand.class);
    RevCommit commit = createMock(RevCommit.class);
    CommitReceivedEvent event = newCommitReceivedEvent(command, project, null, commit, null);
    expect(itsConfig.getItsAssociationPolicy()).andReturn(ItsAssociationPolicy.MANDATORY).atLeastOnce();
    expect(itsConfig.getDummyIssuePattern()).andReturn(Pattern.compile("x^")).atLeastOnce();
    expect(commit.getFullMessage()).andReturn("TestMessage").atLeastOnce();
    expect(commit.getId()).andReturn(commit).anyTimes();
    expect(commit.getName()).andReturn("TestCommit").anyTimes();
    expect(issueExtractor.getIssueIds("TestMessage")).andReturn(new String[] {}).atLeastOnce();
    replayMocks();
    try {
        ivc.onCommitReceived(event);
        fail("onCommitReceived did not throw any exception");
    } catch (CommitValidationException e) {
        assertTrue("Message of thrown CommitValidationException does not " + "contain 'Missing issue'", e.getMessage().contains("Missing issue"));
    }
}
#method_after
public void testMandatoryNonMatching() {
    ItsValidateComment ivc = injector.getInstance(ItsValidateComment.class);
    ReceiveCommand command = createMock(ReceiveCommand.class);
    RevCommit commit = createMock(RevCommit.class);
    CommitReceivedEvent event = newCommitReceivedEvent(command, project, null, commit, null);
    expect(itsConfig.getItsAssociationPolicy()).andReturn(ItsAssociationPolicy.MANDATORY).atLeastOnce();
    expect(itsConfig.getDummyIssuePattern()).andReturn(Optional.empty()).atLeastOnce();
    expect(commit.getFullMessage()).andReturn("TestMessage").atLeastOnce();
    expect(commit.getId()).andReturn(commit).anyTimes();
    expect(commit.getName()).andReturn("TestCommit").anyTimes();
    expect(issueExtractor.getIssueIds("TestMessage")).andReturn(new String[] {}).atLeastOnce();
    replayMocks();
    try {
        ivc.onCommitReceived(event);
        fail("onCommitReceived did not throw any exception");
    } catch (CommitValidationException e) {
        assertTrue("Message of thrown CommitValidationException does not " + "contain 'Missing issue'", e.getMessage().contains("Missing issue"));
    }
}
#end_block

#method_before
public void testOnlySkipMatching() throws CommitValidationException {
    List<CommitValidationMessage> ret;
    ItsValidateComment ivc = injector.getInstance(ItsValidateComment.class);
    ReceiveCommand command = createMock(ReceiveCommand.class);
    RevCommit commit = createMock(RevCommit.class);
    CommitReceivedEvent event = newCommitReceivedEvent(command, project, null, commit, null);
    expect(itsConfig.getItsAssociationPolicy()).andReturn(ItsAssociationPolicy.MANDATORY).atLeastOnce();
    expect(itsConfig.getDummyIssuePattern()).andReturn(Pattern.compile("SKIP")).atLeastOnce();
    expect(commit.getFullMessage()).andReturn("TestMessage SKIP").atLeastOnce();
    expect(commit.getId()).andReturn(commit).anyTimes();
    expect(commit.getName()).andReturn("TestCommit").anyTimes();
    expect(issueExtractor.getIssueIds("TestMessage SKIP")).andReturn(new String[] {}).atLeastOnce();
    replayMocks();
    ret = ivc.onCommitReceived(event);
    assertEmptyList(ret);
}
#method_after
public void testOnlySkipMatching() throws CommitValidationException {
    List<CommitValidationMessage> ret;
    ItsValidateComment ivc = injector.getInstance(ItsValidateComment.class);
    ReceiveCommand command = createMock(ReceiveCommand.class);
    RevCommit commit = createMock(RevCommit.class);
    CommitReceivedEvent event = newCommitReceivedEvent(command, project, null, commit, null);
    expect(itsConfig.getItsAssociationPolicy()).andReturn(ItsAssociationPolicy.MANDATORY).atLeastOnce();
    expect(itsConfig.getDummyIssuePattern()).andReturn(Optional.of(Pattern.compile("SKIP"))).atLeastOnce();
    expect(commit.getFullMessage()).andReturn("TestMessage SKIP").atLeastOnce();
    expect(commit.getId()).andReturn(commit).anyTimes();
    expect(commit.getName()).andReturn("TestCommit").anyTimes();
    expect(issueExtractor.getIssueIds("TestMessage SKIP")).andReturn(new String[] {}).atLeastOnce();
    replayMocks();
    ret = ivc.onCommitReceived(event);
    assertEmptyList(ret);
}
#end_block

#method_before
private List<CommitValidationMessage> validCommit(RevCommit commit) throws CommitValidationException {
    List<CommitValidationMessage> ret = Lists.newArrayList();
    ItsAssociationPolicy associationPolicy = itsConfig.getItsAssociationPolicy();
    switch(associationPolicy) {
        case MANDATORY:
        case SUGGESTED:
            String commitMessage = commit.getFullMessage();
            String[] issueIds = issueExtractor.getIssueIds(commitMessage);
            String synopsis = null;
            String details = null;
            if (issueIds.length > 0) {
                List<String> nonExistingIssueIds = Lists.newArrayList();
                for (String issueId : issueIds) {
                    boolean exists = false;
                    try {
                        exists = client.exists(issueId);
                    } catch (IOException e) {
                        synopsis = "Failed to check whether or not issue " + issueId + " exists";
                        log.warn(synopsis, e);
                        details = e.toString();
                        ret.add(commitValidationFailure(synopsis, details));
                    }
                    if (!exists) {
                        nonExistingIssueIds.add(issueId);
                    }
                }
                if (!nonExistingIssueIds.isEmpty()) {
                    synopsis = "Non-existing issue ids referenced in commit message";
                    StringBuilder sb = new StringBuilder();
                    sb.append("The issue-ids\n");
                    for (String issueId : nonExistingIssueIds) {
                        sb.append("    * ");
                        sb.append(issueId);
                        sb.append("\n");
                    }
                    sb.append("are referenced in the commit message of\n");
                    sb.append(commit.getId().getName());
                    sb.append(",\n");
                    sb.append("but do not exist in ");
                    sb.append(pluginName);
                    sb.append(" Issue-Tracker");
                    details = sb.toString();
                    ret.add(commitValidationFailure(synopsis, details));
                }
            } else if (!itsConfig.getDummyIssuePattern().matcher(commitMessage).find()) {
                synopsis = "Missing issue-id in commit message";
                StringBuilder sb = new StringBuilder();
                sb.append("Commit ");
                sb.append(commit.getId().getName());
                sb.append(" not associated to any issue\n");
                sb.append("\n");
                sb.append("Hint: insert one or more issue-id anywhere in the ");
                sb.append("commit message.\n");
                sb.append("      Issue-ids are strings matching ");
                sb.append(itsConfig.getIssuePattern().pattern());
                sb.append("\n");
                sb.append("      and are pointing to existing tickets on ");
                sb.append(pluginName);
                sb.append(" Issue-Tracker");
                details = sb.toString();
                ret.add(commitValidationFailure(synopsis, details));
            }
            break;
        case OPTIONAL:
        default:
            break;
    }
    return ret;
}
#method_after
private List<CommitValidationMessage> validCommit(RevCommit commit) throws CommitValidationException {
    List<CommitValidationMessage> ret = Lists.newArrayList();
    ItsAssociationPolicy associationPolicy = itsConfig.getItsAssociationPolicy();
    switch(associationPolicy) {
        case MANDATORY:
        case SUGGESTED:
            String commitMessage = commit.getFullMessage();
            String[] issueIds = issueExtractor.getIssueIds(commitMessage);
            String synopsis = null;
            String details = null;
            if (issueIds.length > 0) {
                List<String> nonExistingIssueIds = Lists.newArrayList();
                for (String issueId : issueIds) {
                    boolean exists = false;
                    try {
                        exists = client.exists(issueId);
                    } catch (IOException e) {
                        synopsis = "Failed to check whether or not issue " + issueId + " exists";
                        log.warn(synopsis, e);
                        details = e.toString();
                        ret.add(commitValidationFailure(synopsis, details));
                    }
                    if (!exists) {
                        nonExistingIssueIds.add(issueId);
                    }
                }
                if (!nonExistingIssueIds.isEmpty()) {
                    synopsis = "Non-existing issue ids referenced in commit message";
                    StringBuilder sb = new StringBuilder();
                    sb.append("The issue-ids\n");
                    for (String issueId : nonExistingIssueIds) {
                        sb.append("    * ");
                        sb.append(issueId);
                        sb.append("\n");
                    }
                    sb.append("are referenced in the commit message of\n");
                    sb.append(commit.getId().getName());
                    sb.append(",\n");
                    sb.append("but do not exist in ");
                    sb.append(pluginName);
                    sb.append(" Issue-Tracker");
                    details = sb.toString();
                    ret.add(commitValidationFailure(synopsis, details));
                }
            } else if (!itsConfig.getDummyIssuePattern().map(p -> p.matcher(commitMessage).find()).orElse(false)) {
                synopsis = "Missing issue-id in commit message";
                StringBuilder sb = new StringBuilder();
                sb.append("Commit ");
                sb.append(commit.getId().getName());
                sb.append(" not associated to any issue\n");
                sb.append("\n");
                sb.append("Hint: insert one or more issue-id anywhere in the ");
                sb.append("commit message.\n");
                sb.append("      Issue-ids are strings matching ");
                sb.append(itsConfig.getIssuePattern().pattern());
                sb.append("\n");
                sb.append("      and are pointing to existing tickets on ");
                sb.append(pluginName);
                sb.append(" Issue-Tracker");
                details = sb.toString();
                ret.add(commitValidationFailure(synopsis, details));
            }
            break;
        case OPTIONAL:
        default:
            break;
    }
    return ret;
}
#end_block

#method_before
public Collection<ExternalId> getExternalIds() {
    return externalIds;
}
#method_after
public ImmutableSet<ExternalId> getExternalIds() {
    return externalIds;
}
#end_block

#method_before
public Collection<ExternalId> getExternalIds(String scheme) {
    return externalIds.stream().filter(e -> e.key().isScheme(scheme)).collect(toSet());
}
#method_after
public ImmutableSet<ExternalId> getExternalIds(String scheme) {
    return externalIds.stream().filter(e -> e.key().isScheme(scheme)).collect(toImmutableSet());
}
#end_block

#method_before
public Map<ProjectWatchKey, Set<NotifyType>> getProjectWatches() {
    return projectWatches;
}
#method_after
public ImmutableMap<ProjectWatchKey, ImmutableSet<NotifyType>> getProjectWatches() {
    return projectWatches;
}
#end_block

#method_before
public AuthResult updateLink(Account.Id to, AuthRequest who) throws OrmException, AccountException, IOException, ConfigInvalidException {
    accountsUpdateFactory.create().update("Delete External IDs on Update Link", to, (a, u) -> {
        Collection<ExternalId> filteredExtIdsByScheme = a.getExternalIds(who.getExternalIdKey().scheme());
        if (!filteredExtIdsByScheme.isEmpty() && (filteredExtIdsByScheme.size() > 1 || !filteredExtIdsByScheme.stream().filter(e -> e.key().equals(who.getExternalIdKey())).findAny().isPresent())) {
            u.deleteExternalIds(filteredExtIdsByScheme);
        }
    });
    return link(to, who);
}
#method_after
public AuthResult updateLink(Account.Id to, AuthRequest who) throws OrmException, AccountException, IOException, ConfigInvalidException {
    accountsUpdateFactory.create().update("Delete External IDs on Update Link", to, (a, u) -> {
        Collection<ExternalId> filteredExtIdsByScheme = a.getExternalIds(who.getExternalIdKey().scheme());
        if (filteredExtIdsByScheme.isEmpty()) {
            return;
        }
        if (filteredExtIdsByScheme.size() > 1 || !filteredExtIdsByScheme.stream().anyMatch(e -> e.key().equals(who.getExternalIdKey()))) {
            u.deleteExternalIds(filteredExtIdsByScheme);
        }
    });
    return link(to, who);
}
#end_block

#method_before
@Override
public RestModifyView<ProjectResource, ?> create(ProjectResource parent, IdString id) throws RestApiException {
    parent.getProjectState().checkStatePermitsRead();
    if (isDefaultDashboard(id)) {
        return createDefault.get();
    }
    throw new ResourceNotFoundException(id);
}
#method_after
@Override
public RestModifyView<ProjectResource, ?> create(ProjectResource parent, IdString id) throws RestApiException {
    parent.getProjectState().checkStatePermitsWrite();
    if (isDefaultDashboard(id)) {
        return createDefault.get();
    }
    throw new ResourceNotFoundException(id);
}
#end_block

#method_before
public void checkRemoveReviewer(ChangeNotes notes, CurrentUser currentUser, PatchSetApproval approval) throws PermissionBackendException, AuthException, NoSuchProjectException, IOException {
    checkRemoveReviewer(notes, currentUser, approval.getAccountId(), approval.getValue());
}
#method_after
public void checkRemoveReviewer(ChangeNotes notes, CurrentUser currentUser, PatchSetApproval approval) throws PermissionBackendException, AuthException {
    checkRemoveReviewer(notes, currentUser, approval.getAccountId(), approval.getValue());
}
#end_block

#method_before
public void checkRemoveReviewer(ChangeNotes notes, CurrentUser currentUser, Account.Id reviewer) throws PermissionBackendException, AuthException, NoSuchProjectException, IOException {
    checkRemoveReviewer(notes, currentUser, reviewer, 0);
}
#method_after
public void checkRemoveReviewer(ChangeNotes notes, CurrentUser currentUser, Account.Id reviewer) throws PermissionBackendException, AuthException {
    checkRemoveReviewer(notes, currentUser, reviewer, 0);
}
#end_block

#method_before
public boolean testRemoveReviewer(ChangeData cd, CurrentUser currentUser, Account.Id reviewer, int value) throws PermissionBackendException, NoSuchProjectException, OrmException, IOException {
    if (canRemoveReviewerWithoutPermissionCheck(permissionBackend, cd.change(), currentUser, reviewer, value)) {
        return true;
    }
    return permissionBackend.user(currentUser).change(cd).database(dbProvider).test(ChangePermission.REMOVE_REVIEWER);
}
#method_after
public boolean testRemoveReviewer(ChangeData cd, CurrentUser currentUser, Account.Id reviewer, int value) throws PermissionBackendException, OrmException {
    if (canRemoveReviewerWithoutPermissionCheck(permissionBackend, cd.change(), currentUser, reviewer, value)) {
        return true;
    }
    return permissionBackend.user(currentUser).change(cd).database(dbProvider).test(ChangePermission.REMOVE_REVIEWER);
}
#end_block

#method_before
private void checkRemoveReviewer(ChangeNotes notes, CurrentUser currentUser, Account.Id reviewer, int val) throws PermissionBackendException, AuthException, NoSuchProjectException, IOException {
    if (canRemoveReviewerWithoutPermissionCheck(permissionBackend, notes.getChange(), currentUser, reviewer, val)) {
        return;
    }
    permissionBackend.user(currentUser).change(notes).database(dbProvider).check(ChangePermission.REMOVE_REVIEWER);
}
#method_after
private void checkRemoveReviewer(ChangeNotes notes, CurrentUser currentUser, Account.Id reviewer, int val) throws PermissionBackendException, AuthException {
    if (canRemoveReviewerWithoutPermissionCheck(permissionBackend, notes.getChange(), currentUser, reviewer, val)) {
        return;
    }
    permissionBackend.user(currentUser).change(notes).database(dbProvider).check(ChangePermission.REMOVE_REVIEWER);
}
#end_block

#method_before
private static boolean canRemoveReviewerWithoutPermissionCheck(PermissionBackend permissionBackend, Change change, CurrentUser currentUser, Account.Id reviewer, int value) throws NoSuchProjectException, IOException, PermissionBackendException {
    if (!change.getStatus().isOpen()) {
        return false;
    }
    if (currentUser.isIdentifiedUser()) {
        Account.Id aId = currentUser.getAccountId();
        if (aId.equals(reviewer)) {
            // A user can always remove themselves.
            return true;
        } else if (aId.equals(change.getOwner()) && 0 <= value) {
            // The change owner may remove any zero or positive score.
            return true;
        }
    }
    // Users with the remove reviewer permission, the branch owner, project
    // owner and site admin can remove anyone
    PermissionBackend.WithUser withUser = permissionBackend.user(currentUser);
    PermissionBackend.ForProject forProject = withUser.project(change.getProject());
    if (check(forProject.ref(change.getDest().get()), RefPermission.WRITE_CONFIG) || check(withUser, GlobalPermission.ADMINISTRATE_SERVER)) {
        return true;
    }
    return false;
}
#method_after
private static boolean canRemoveReviewerWithoutPermissionCheck(PermissionBackend permissionBackend, Change change, CurrentUser currentUser, Account.Id reviewer, int value) throws PermissionBackendException {
    if (!change.getStatus().isOpen()) {
        return false;
    }
    if (currentUser.isIdentifiedUser()) {
        Account.Id aId = currentUser.getAccountId();
        if (aId.equals(reviewer)) {
            // A user can always remove themselves.
            return true;
        } else if (aId.equals(change.getOwner()) && 0 <= value) {
            // The change owner may remove any zero or positive score.
            return true;
        }
    }
    // Users with the remove reviewer permission, the branch owner, project
    // owner and site admin can remove anyone
    PermissionBackend.WithUser withUser = permissionBackend.user(currentUser);
    PermissionBackend.ForProject forProject = withUser.project(change.getProject());
    if (check(forProject.ref(change.getDest().get()), RefPermission.WRITE_CONFIG) || check(withUser, GlobalPermission.ADMINISTRATE_SERVER)) {
        return true;
    }
    return false;
}
#end_block

#method_before
@Test
public void flushCache() throws Exception {
    InternalGroup group = groupCache.get(new AccountGroup.NameKey("Administrators")).orElse(null);
    assertWithMessage("Precondition: The group 'Administrators' was loaded by the group cache").that(group).isNotNull();
    RestResponse r = adminRestSession.get("/config/server/caches/groups_byname");
    CacheInfo result = newGson().fromJson(r.getReader(), CacheInfo.class);
    assertThat(result.entries.mem).isGreaterThan((long) 0);
    r = adminRestSession.post("/config/server/caches/groups_byname/flush");
    r.assertOK();
    r.consume();
    r = adminRestSession.get("/config/server/caches/groups_byname");
    result = newGson().fromJson(r.getReader(), CacheInfo.class);
    assertThat(result.entries.mem).isNull();
}
#method_after
@Test
public void flushCache() throws Exception {
    // access the admin group once so that it is loaded into the group cache
    adminGroup();
    RestResponse r = adminRestSession.get("/config/server/caches/groups_byname");
    CacheInfo result = newGson().fromJson(r.getReader(), CacheInfo.class);
    assertThat(result.entries.mem).isGreaterThan((long) 0);
    r = adminRestSession.post("/config/server/caches/groups_byname/flush");
    r.assertOK();
    r.consume();
    r = adminRestSession.get("/config/server/caches/groups_byname");
    result = newGson().fromJson(r.getReader(), CacheInfo.class);
    assertThat(result.entries.mem).isNull();
}
#end_block

#method_before
@Override
protected void configure() {
    bind(EmailExpander.class).toProvider(EmailExpanderProvider.class).in(SINGLETON);
    bind(IdGenerator.class);
    bind(RulesCache.class);
    bind(BlameCache.class).to(BlameCacheImpl.class);
    bind(Sequences.class);
    install(authModule);
    install(AccountCacheImpl.module());
    install(BatchUpdate.module());
    install(ChangeKindCacheImpl.module());
    install(ChangeFinder.module());
    install(ConflictsCacheImpl.module());
    install(GroupCacheImpl.module());
    install(GroupIncludeCacheImpl.module());
    install(MergeabilityCacheImpl.module());
    install(PatchListCacheImpl.module());
    install(ProjectCacheImpl.module());
    install(SectionSortCache.module());
    install(SubmitStrategy.module());
    install(TagCache.module());
    install(OAuthTokenCache.module());
    install(new AccessControlModule());
    install(new CmdLineParserModule());
    install(new EmailModule());
    install(new ExternalIdModule());
    install(new GitModule());
    install(new GroupModule());
    install(new NoteDbModule(cfg));
    install(new PrologModule());
    install(new ReceiveCommitsModule());
    install(new SshAddressesModule());
    install(ThreadLocalRequestContext.module());
    bind(AccountResolver.class);
    factory(AddReviewerSender.Factory.class);
    factory(DeleteReviewerSender.Factory.class);
    factory(AddKeySender.Factory.class);
    factory(CapabilityCollection.Factory.class);
    factory(ChangeData.AssistedFactory.class);
    factory(ChangeJson.AssistedFactory.class);
    factory(CreateChangeSender.Factory.class);
    factory(EmailMerge.Factory.class);
    factory(MergedSender.Factory.class);
    factory(MergeUtil.Factory.class);
    factory(PatchScriptFactory.Factory.class);
    factory(PluginUser.Factory.class);
    factory(ProjectNode.Factory.class);
    factory(ProjectState.Factory.class);
    factory(RegisterNewEmailSender.Factory.class);
    factory(ReplacePatchSetSender.Factory.class);
    factory(SetAssigneeSender.Factory.class);
    factory(VisibleRefFilter.Factory.class);
    bind(PermissionCollection.Factory.class);
    bind(AccountVisibility.class).toProvider(AccountVisibilityProvider.class).in(SINGLETON);
    factory(ProjectOwnerGroupsProvider.Factory.class);
    factory(SubmitRuleEvaluator.Factory.class);
    bind(AuthBackend.class).to(UniversalAuthBackend.class).in(SINGLETON);
    DynamicSet.setOf(binder(), AuthBackend.class);
    bind(GroupControl.Factory.class).in(SINGLETON);
    bind(GroupControl.GenericFactory.class).in(SINGLETON);
    bind(FileTypeRegistry.class).to(MimeUtilFileTypeRegistry.class);
    bind(ToolsCatalog.class);
    bind(EventFactory.class);
    bind(TransferConfig.class);
    bind(GcConfig.class);
    bind(ChangeCleanupConfig.class);
    bind(AccountDeactivator.class);
    bind(ApprovalsUtil.class);
    bind(SoyTofu.class).annotatedWith(MailTemplates.class).toProvider(MailSoyTofuProvider.class);
    bind(FromAddressGenerator.class).toProvider(FromAddressGeneratorProvider.class).in(SINGLETON);
    bind(Boolean.class).annotatedWith(DisableReverseDnsLookup.class).toProvider(DisableReverseDnsLookupProvider.class).in(SINGLETON);
    bind(PatchSetInfoFactory.class);
    bind(IdentifiedUser.GenericFactory.class).in(SINGLETON);
    bind(AccountControl.Factory.class);
    install(new AuditModule());
    bind(UiActions.class);
    install(new com.google.gerrit.server.access.Module());
    install(new com.google.gerrit.server.account.Module());
    install(new com.google.gerrit.server.change.Module());
    install(new com.google.gerrit.server.group.Module());
    install(new com.google.gerrit.server.project.Module());
    bind(GitReferenceUpdated.class);
    DynamicMap.mapOf(binder(), new TypeLiteral<Cache<?, ?>>() {
    });
    DynamicSet.setOf(binder(), CacheRemovalListener.class);
    DynamicMap.mapOf(binder(), CapabilityDefinition.class);
    DynamicSet.setOf(binder(), GitReferenceUpdatedListener.class);
    DynamicSet.setOf(binder(), AssigneeChangedListener.class);
    DynamicSet.setOf(binder(), ChangeAbandonedListener.class);
    DynamicSet.setOf(binder(), CommentAddedListener.class);
    DynamicSet.setOf(binder(), HashtagsEditedListener.class);
    DynamicSet.setOf(binder(), ChangeMergedListener.class);
    bind(ChangeMergedListener.class).annotatedWith(Exports.named("CreateGroupPermissionSyncer")).to(CreateGroupPermissionSyncer.class);
    DynamicSet.setOf(binder(), ChangeRestoredListener.class);
    DynamicSet.setOf(binder(), ChangeRevertedListener.class);
    DynamicSet.setOf(binder(), ReviewerAddedListener.class);
    DynamicSet.setOf(binder(), ReviewerDeletedListener.class);
    DynamicSet.setOf(binder(), VoteDeletedListener.class);
    DynamicSet.setOf(binder(), RevisionCreatedListener.class);
    DynamicSet.setOf(binder(), TopicEditedListener.class);
    DynamicSet.setOf(binder(), AgreementSignupListener.class);
    DynamicSet.setOf(binder(), PluginEventListener.class);
    DynamicSet.setOf(binder(), ReceivePackInitializer.class);
    DynamicSet.setOf(binder(), PostReceiveHook.class);
    DynamicSet.setOf(binder(), PreUploadHook.class);
    DynamicSet.setOf(binder(), PostUploadHook.class);
    DynamicSet.setOf(binder(), AccountIndexedListener.class);
    DynamicSet.setOf(binder(), ChangeIndexedListener.class);
    DynamicSet.setOf(binder(), GroupIndexedListener.class);
    DynamicSet.setOf(binder(), ProjectIndexedListener.class);
    DynamicSet.setOf(binder(), NewProjectCreatedListener.class);
    DynamicSet.setOf(binder(), ProjectDeletedListener.class);
    DynamicSet.setOf(binder(), GarbageCollectorListener.class);
    DynamicSet.setOf(binder(), HeadUpdatedListener.class);
    DynamicSet.setOf(binder(), UsageDataPublishedListener.class);
    DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(ReindexAfterRefUpdate.class);
    DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(ProjectConfigEntry.UpdateChecker.class);
    DynamicSet.setOf(binder(), EventListener.class);
    DynamicSet.bind(binder(), EventListener.class).to(EventsMetrics.class);
    DynamicSet.setOf(binder(), UserScopedEventListener.class);
    DynamicSet.setOf(binder(), CommitValidationListener.class);
    DynamicSet.setOf(binder(), ChangeMessageModifier.class);
    DynamicSet.setOf(binder(), RefOperationValidationListener.class);
    DynamicSet.setOf(binder(), OnSubmitValidationListener.class);
    DynamicSet.setOf(binder(), MergeValidationListener.class);
    DynamicSet.setOf(binder(), ProjectCreationValidationListener.class);
    DynamicSet.setOf(binder(), GroupCreationValidationListener.class);
    DynamicSet.setOf(binder(), HashtagValidationListener.class);
    DynamicSet.setOf(binder(), OutgoingEmailValidationListener.class);
    DynamicItem.itemOf(binder(), AvatarProvider.class);
    DynamicSet.setOf(binder(), LifecycleListener.class);
    DynamicSet.setOf(binder(), TopMenu.class);
    DynamicSet.setOf(binder(), MessageOfTheDay.class);
    DynamicMap.mapOf(binder(), DownloadScheme.class);
    DynamicMap.mapOf(binder(), DownloadCommand.class);
    DynamicMap.mapOf(binder(), CloneCommand.class);
    DynamicMap.mapOf(binder(), ReviewerSuggestion.class);
    DynamicSet.setOf(binder(), ExternalIncludedIn.class);
    DynamicMap.mapOf(binder(), ProjectConfigEntry.class);
    DynamicSet.setOf(binder(), PatchSetWebLink.class);
    DynamicSet.setOf(binder(), ParentWebLink.class);
    DynamicSet.setOf(binder(), FileWebLink.class);
    DynamicSet.setOf(binder(), FileHistoryWebLink.class);
    DynamicSet.setOf(binder(), DiffWebLink.class);
    DynamicSet.setOf(binder(), ProjectWebLink.class);
    DynamicSet.setOf(binder(), BranchWebLink.class);
    DynamicSet.setOf(binder(), TagWebLink.class);
    DynamicMap.mapOf(binder(), OAuthLoginProvider.class);
    DynamicItem.itemOf(binder(), OAuthTokenEncrypter.class);
    DynamicSet.setOf(binder(), AccountExternalIdCreator.class);
    DynamicSet.setOf(binder(), WebUiPlugin.class);
    DynamicItem.itemOf(binder(), AccountPatchReviewStore.class);
    DynamicSet.setOf(binder(), AssigneeValidationListener.class);
    DynamicSet.setOf(binder(), ActionVisitor.class);
    DynamicItem.itemOf(binder(), MergeSuperSetComputation.class);
    DynamicItem.itemOf(binder(), ProjectNameLockManager.class);
    DynamicMap.mapOf(binder(), MailFilter.class);
    bind(MailFilter.class).annotatedWith(Exports.named("ListMailFilter")).to(ListMailFilter.class);
    factory(UploadValidators.Factory.class);
    DynamicSet.setOf(binder(), UploadValidationListener.class);
    DynamicMap.mapOf(binder(), ChangeQueryBuilder.ChangeOperatorFactory.class);
    DynamicMap.mapOf(binder(), ChangeQueryBuilder.ChangeHasOperandFactory.class);
    DynamicMap.mapOf(binder(), ChangeQueryProcessor.ChangeAttributeFactory.class);
    install(new GitwebConfig.LegacyModule(cfg));
    bind(AnonymousUser.class);
    factory(AbandonOp.Factory.class);
    factory(AccountMergeValidator.Factory.class);
    factory(GroupMergeValidator.Factory.class);
    factory(RefOperationValidators.Factory.class);
    factory(OnSubmitValidators.Factory.class);
    factory(MergeValidators.Factory.class);
    factory(ProjectConfigValidator.Factory.class);
    factory(NotesBranchUtil.Factory.class);
    factory(MergedByPushOp.Factory.class);
    factory(GitModules.Factory.class);
    factory(VersionedAuthorizedKeys.Factory.class);
    bind(AccountManager.class);
    factory(ChangeUserName.Factory.class);
    bind(new TypeLiteral<List<CommentLinkInfo>>() {
    }).toProvider(CommentLinkProvider.class).in(SINGLETON);
    bind(ReloadPluginListener.class).annotatedWith(UniqueAnnotations.create()).to(PluginConfigFactory.class);
}
#method_after
@Override
protected void configure() {
    bind(EmailExpander.class).toProvider(EmailExpanderProvider.class).in(SINGLETON);
    bind(IdGenerator.class);
    bind(RulesCache.class);
    bind(BlameCache.class).to(BlameCacheImpl.class);
    bind(Sequences.class);
    install(authModule);
    install(AccountCacheImpl.module());
    install(BatchUpdate.module());
    install(ChangeKindCacheImpl.module());
    install(ChangeFinder.module());
    install(ConflictsCacheImpl.module());
    install(GroupCacheImpl.module());
    install(GroupIncludeCacheImpl.module());
    install(MergeabilityCacheImpl.module());
    install(PatchListCacheImpl.module());
    install(ProjectCacheImpl.module());
    install(SectionSortCache.module());
    install(SubmitStrategy.module());
    install(TagCache.module());
    install(OAuthTokenCache.module());
    install(new AccessControlModule());
    install(new CmdLineParserModule());
    install(new EmailModule());
    install(new ExternalIdModule());
    install(new GitModule());
    install(new GroupModule());
    install(new NoteDbModule(cfg));
    install(new PrologModule());
    install(new ReceiveCommitsModule());
    install(new SshAddressesModule());
    install(ThreadLocalRequestContext.module());
    bind(AccountResolver.class);
    factory(AddReviewerSender.Factory.class);
    factory(DeleteReviewerSender.Factory.class);
    factory(AddKeySender.Factory.class);
    factory(CapabilityCollection.Factory.class);
    factory(ChangeData.AssistedFactory.class);
    factory(ChangeJson.AssistedFactory.class);
    factory(CreateChangeSender.Factory.class);
    factory(EmailMerge.Factory.class);
    factory(MergedSender.Factory.class);
    factory(MergeUtil.Factory.class);
    factory(PatchScriptFactory.Factory.class);
    factory(PluginUser.Factory.class);
    factory(ProjectNode.Factory.class);
    factory(ProjectState.Factory.class);
    factory(RegisterNewEmailSender.Factory.class);
    factory(ReplacePatchSetSender.Factory.class);
    factory(SetAssigneeSender.Factory.class);
    factory(VisibleRefFilter.Factory.class);
    bind(PermissionCollection.Factory.class);
    bind(AccountVisibility.class).toProvider(AccountVisibilityProvider.class).in(SINGLETON);
    factory(ProjectOwnerGroupsProvider.Factory.class);
    factory(SubmitRuleEvaluator.Factory.class);
    bind(AuthBackend.class).to(UniversalAuthBackend.class).in(SINGLETON);
    DynamicSet.setOf(binder(), AuthBackend.class);
    bind(GroupControl.Factory.class).in(SINGLETON);
    bind(GroupControl.GenericFactory.class).in(SINGLETON);
    bind(FileTypeRegistry.class).to(MimeUtilFileTypeRegistry.class);
    bind(ToolsCatalog.class);
    bind(EventFactory.class);
    bind(TransferConfig.class);
    bind(GcConfig.class);
    bind(ChangeCleanupConfig.class);
    bind(AccountDeactivator.class);
    bind(ApprovalsUtil.class);
    bind(SoyTofu.class).annotatedWith(MailTemplates.class).toProvider(MailSoyTofuProvider.class);
    bind(FromAddressGenerator.class).toProvider(FromAddressGeneratorProvider.class).in(SINGLETON);
    bind(Boolean.class).annotatedWith(DisableReverseDnsLookup.class).toProvider(DisableReverseDnsLookupProvider.class).in(SINGLETON);
    bind(PatchSetInfoFactory.class);
    bind(IdentifiedUser.GenericFactory.class).in(SINGLETON);
    bind(AccountControl.Factory.class);
    install(new AuditModule());
    bind(UiActions.class);
    install(new com.google.gerrit.server.access.Module());
    install(new com.google.gerrit.server.account.Module());
    install(new com.google.gerrit.server.change.Module());
    install(new ConfigRestModule());
    install(new com.google.gerrit.server.group.Module(groupsMigration));
    install(new com.google.gerrit.server.project.Module());
    bind(GitReferenceUpdated.class);
    DynamicMap.mapOf(binder(), new TypeLiteral<Cache<?, ?>>() {
    });
    DynamicSet.setOf(binder(), CacheRemovalListener.class);
    DynamicMap.mapOf(binder(), CapabilityDefinition.class);
    DynamicSet.setOf(binder(), GitReferenceUpdatedListener.class);
    DynamicSet.setOf(binder(), AssigneeChangedListener.class);
    DynamicSet.setOf(binder(), ChangeAbandonedListener.class);
    DynamicSet.setOf(binder(), CommentAddedListener.class);
    DynamicSet.setOf(binder(), HashtagsEditedListener.class);
    DynamicSet.setOf(binder(), ChangeMergedListener.class);
    bind(ChangeMergedListener.class).annotatedWith(Exports.named("CreateGroupPermissionSyncer")).to(CreateGroupPermissionSyncer.class);
    DynamicSet.setOf(binder(), ChangeRestoredListener.class);
    DynamicSet.setOf(binder(), ChangeRevertedListener.class);
    DynamicSet.setOf(binder(), ReviewerAddedListener.class);
    DynamicSet.setOf(binder(), ReviewerDeletedListener.class);
    DynamicSet.setOf(binder(), VoteDeletedListener.class);
    DynamicSet.setOf(binder(), RevisionCreatedListener.class);
    DynamicSet.setOf(binder(), TopicEditedListener.class);
    DynamicSet.setOf(binder(), AgreementSignupListener.class);
    DynamicSet.setOf(binder(), PluginEventListener.class);
    DynamicSet.setOf(binder(), ReceivePackInitializer.class);
    DynamicSet.setOf(binder(), PostReceiveHook.class);
    DynamicSet.setOf(binder(), PreUploadHook.class);
    DynamicSet.setOf(binder(), PostUploadHook.class);
    DynamicSet.setOf(binder(), AccountIndexedListener.class);
    DynamicSet.setOf(binder(), ChangeIndexedListener.class);
    DynamicSet.setOf(binder(), GroupIndexedListener.class);
    DynamicSet.setOf(binder(), ProjectIndexedListener.class);
    DynamicSet.setOf(binder(), NewProjectCreatedListener.class);
    DynamicSet.setOf(binder(), ProjectDeletedListener.class);
    DynamicSet.setOf(binder(), GarbageCollectorListener.class);
    DynamicSet.setOf(binder(), HeadUpdatedListener.class);
    DynamicSet.setOf(binder(), UsageDataPublishedListener.class);
    DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(ReindexAfterRefUpdate.class);
    DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(ProjectConfigEntry.UpdateChecker.class);
    DynamicSet.setOf(binder(), EventListener.class);
    DynamicSet.bind(binder(), EventListener.class).to(EventsMetrics.class);
    DynamicSet.setOf(binder(), UserScopedEventListener.class);
    DynamicSet.setOf(binder(), CommitValidationListener.class);
    DynamicSet.setOf(binder(), ChangeMessageModifier.class);
    DynamicSet.setOf(binder(), RefOperationValidationListener.class);
    DynamicSet.setOf(binder(), OnSubmitValidationListener.class);
    DynamicSet.setOf(binder(), MergeValidationListener.class);
    DynamicSet.setOf(binder(), ProjectCreationValidationListener.class);
    DynamicSet.setOf(binder(), GroupCreationValidationListener.class);
    DynamicSet.setOf(binder(), HashtagValidationListener.class);
    DynamicSet.setOf(binder(), OutgoingEmailValidationListener.class);
    DynamicItem.itemOf(binder(), AvatarProvider.class);
    DynamicSet.setOf(binder(), LifecycleListener.class);
    DynamicSet.setOf(binder(), TopMenu.class);
    DynamicSet.setOf(binder(), MessageOfTheDay.class);
    DynamicMap.mapOf(binder(), DownloadScheme.class);
    DynamicMap.mapOf(binder(), DownloadCommand.class);
    DynamicMap.mapOf(binder(), CloneCommand.class);
    DynamicMap.mapOf(binder(), ReviewerSuggestion.class);
    DynamicSet.setOf(binder(), ExternalIncludedIn.class);
    DynamicMap.mapOf(binder(), ProjectConfigEntry.class);
    DynamicSet.setOf(binder(), PatchSetWebLink.class);
    DynamicSet.setOf(binder(), ParentWebLink.class);
    DynamicSet.setOf(binder(), FileWebLink.class);
    DynamicSet.setOf(binder(), FileHistoryWebLink.class);
    DynamicSet.setOf(binder(), DiffWebLink.class);
    DynamicSet.setOf(binder(), ProjectWebLink.class);
    DynamicSet.setOf(binder(), BranchWebLink.class);
    DynamicSet.setOf(binder(), TagWebLink.class);
    DynamicMap.mapOf(binder(), OAuthLoginProvider.class);
    DynamicItem.itemOf(binder(), OAuthTokenEncrypter.class);
    DynamicSet.setOf(binder(), AccountExternalIdCreator.class);
    DynamicSet.setOf(binder(), WebUiPlugin.class);
    DynamicItem.itemOf(binder(), AccountPatchReviewStore.class);
    DynamicSet.setOf(binder(), AssigneeValidationListener.class);
    DynamicSet.setOf(binder(), ActionVisitor.class);
    DynamicItem.itemOf(binder(), MergeSuperSetComputation.class);
    DynamicItem.itemOf(binder(), ProjectNameLockManager.class);
    DynamicMap.mapOf(binder(), MailFilter.class);
    bind(MailFilter.class).annotatedWith(Exports.named("ListMailFilter")).to(ListMailFilter.class);
    factory(UploadValidators.Factory.class);
    DynamicSet.setOf(binder(), UploadValidationListener.class);
    DynamicMap.mapOf(binder(), ChangeQueryBuilder.ChangeOperatorFactory.class);
    DynamicMap.mapOf(binder(), ChangeQueryBuilder.ChangeHasOperandFactory.class);
    DynamicMap.mapOf(binder(), ChangeQueryProcessor.ChangeAttributeFactory.class);
    install(new GitwebConfig.LegacyModule(cfg));
    bind(AnonymousUser.class);
    factory(AbandonOp.Factory.class);
    factory(AccountMergeValidator.Factory.class);
    factory(GroupMergeValidator.Factory.class);
    factory(RefOperationValidators.Factory.class);
    factory(OnSubmitValidators.Factory.class);
    factory(MergeValidators.Factory.class);
    factory(ProjectConfigValidator.Factory.class);
    factory(NotesBranchUtil.Factory.class);
    factory(MergedByPushOp.Factory.class);
    factory(GitModules.Factory.class);
    factory(VersionedAuthorizedKeys.Factory.class);
    bind(AccountManager.class);
    factory(ChangeUserName.Factory.class);
    bind(new TypeLiteral<List<CommentLinkInfo>>() {
    }).toProvider(CommentLinkProvider.class).in(SINGLETON);
    bind(ReloadPluginListener.class).annotatedWith(UniqueAnnotations.create()).to(PluginConfigFactory.class);
}
#end_block

#method_before
private Injector createSysInjector() {
    final List<Module> modules = new ArrayList<>();
    modules.add(SchemaVersionCheck.module());
    modules.add(new DropWizardMetricMaker.RestModule());
    modules.add(new LogFileCompressor.Module());
    // Plugin module needs to be inserted *before* the index module.
    // There is the concept of LifecycleModule, in Gerrit's own extension
    // to Guice, which has these:
    // listener().to(SomeClassImplementingLifecycleListener.class);
    // and the start() methods of each such listener are executed in the
    // order they are declared.
    // Makes sure that PluginLoader.start() is executed before the
    // LuceneIndexModule.start() so that plugins get loaded and the respective
    // Guice modules installed so that the on-line reindexing will happen
    // with the proper classes (e.g. group backends, custom Prolog
    // predicates) and the associated rules ready to be evaluated.
    modules.add(new PluginModule());
    // Index module shutdown must happen before work queue shutdown, otherwise
    // work queue can get stuck waiting on index futures that will never return.
    modules.add(createIndexModule());
    modules.add(new WorkQueue.Module());
    modules.add(new StreamEventsApiListener.Module());
    modules.add(new EventBroker.Module());
    modules.add(inMemoryTest ? new InMemoryAccountPatchReviewStore.Module() : new JdbcAccountPatchReviewStore.Module(config));
    modules.add(new ReceiveCommitsExecutorModule());
    modules.add(new DiffExecutorModule());
    modules.add(new MimeUtil2Module());
    modules.add(cfgInjector.getInstance(GerritGlobalModule.class));
    modules.add(new com.google.gerrit.server.api.Module());
    modules.add(new com.google.gerrit.server.config.endpoint.Module());
    modules.add(new SearchingChangeCacheImpl.Module(slave));
    modules.add(new InternalAccountDirectory.Module());
    modules.add(new DefaultPermissionBackendModule());
    modules.add(new DefaultCacheFactory.Module());
    modules.add(cfgInjector.getInstance(MailReceiver.Module.class));
    if (emailModule != null) {
        modules.add(emailModule);
    } else {
        modules.add(new SmtpEmailSender.Module());
    }
    modules.add(new SignedTokenEmailTokenVerifier.Module());
    modules.add(new PluginRestApiModule());
    modules.add(new RestCacheAdminModule());
    modules.add(new GpgModule(config));
    modules.add(new StartupChecks.Module());
    if (MoreObjects.firstNonNull(httpd, true)) {
        modules.add(new CanonicalWebUrlModule() {

            @Override
            protected Class<? extends Provider<String>> provider() {
                return HttpCanonicalWebUrlProvider.class;
            }
        });
    } else {
        modules.add(new CanonicalWebUrlModule() {

            @Override
            protected Class<? extends Provider<String>> provider() {
                return CanonicalWebUrlProvider.class;
            }
        });
    }
    if (sshd) {
        modules.add(SshKeyCacheImpl.module());
    } else {
        modules.add(NoSshKeyCache.module());
    }
    modules.add(new AbstractModule() {

        @Override
        protected void configure() {
            bind(GerritOptions.class).toInstance(new GerritOptions(config, headless, slave, polyGerritDev));
            if (inMemoryTest) {
                bind(String.class).annotatedWith(SecureStoreClassName.class).toInstance(DefaultSecureStore.class.getName());
                bind(SecureStore.class).toProvider(SecureStoreProvider.class);
            }
        }
    });
    modules.add(new GarbageCollectionModule());
    if (!slave) {
        modules.add(new AccountDeactivator.Module());
        modules.add(new ChangeCleanupRunner.Module());
    }
    modules.addAll(LibModuleLoader.loadModules(cfgInjector));
    if (migrateToNoteDb()) {
        modules.add(new OnlineNoteDbMigrator.Module(trial));
    }
    if (testSysModule != null) {
        modules.add(testSysModule);
    }
    modules.add(new LocalMergeSuperSetComputation.Module());
    modules.add(new DefaultProjectNameLockManager.Module());
    return cfgInjector.createChildInjector(modules);
}
#method_after
private Injector createSysInjector() {
    final List<Module> modules = new ArrayList<>();
    modules.add(SchemaVersionCheck.module());
    modules.add(new DropWizardMetricMaker.RestModule());
    modules.add(new LogFileCompressor.Module());
    // Plugin module needs to be inserted *before* the index module.
    // There is the concept of LifecycleModule, in Gerrit's own extension
    // to Guice, which has these:
    // listener().to(SomeClassImplementingLifecycleListener.class);
    // and the start() methods of each such listener are executed in the
    // order they are declared.
    // Makes sure that PluginLoader.start() is executed before the
    // LuceneIndexModule.start() so that plugins get loaded and the respective
    // Guice modules installed so that the on-line reindexing will happen
    // with the proper classes (e.g. group backends, custom Prolog
    // predicates) and the associated rules ready to be evaluated.
    modules.add(new PluginModule());
    // Index module shutdown must happen before work queue shutdown, otherwise
    // work queue can get stuck waiting on index futures that will never return.
    modules.add(createIndexModule());
    modules.add(new WorkQueue.Module());
    modules.add(new StreamEventsApiListener.Module());
    modules.add(new EventBroker.Module());
    modules.add(inMemoryTest ? new InMemoryAccountPatchReviewStore.Module() : new JdbcAccountPatchReviewStore.Module(config));
    modules.add(new ReceiveCommitsExecutorModule());
    modules.add(new DiffExecutorModule());
    modules.add(new MimeUtil2Module());
    modules.add(cfgInjector.getInstance(GerritGlobalModule.class));
    modules.add(new GerritApiModule());
    modules.add(new PluginApiModule());
    modules.add(new SearchingChangeCacheImpl.Module(slave));
    modules.add(new InternalAccountDirectory.Module());
    modules.add(new DefaultPermissionBackendModule());
    modules.add(new DefaultCacheFactory.Module());
    modules.add(cfgInjector.getInstance(MailReceiver.Module.class));
    if (emailModule != null) {
        modules.add(emailModule);
    } else {
        modules.add(new SmtpEmailSender.Module());
    }
    modules.add(new SignedTokenEmailTokenVerifier.Module());
    modules.add(new PluginRestApiModule());
    modules.add(new RestCacheAdminModule());
    modules.add(new GpgModule(config));
    modules.add(new StartupChecks.Module());
    if (MoreObjects.firstNonNull(httpd, true)) {
        modules.add(new CanonicalWebUrlModule() {

            @Override
            protected Class<? extends Provider<String>> provider() {
                return HttpCanonicalWebUrlProvider.class;
            }
        });
    } else {
        modules.add(new CanonicalWebUrlModule() {

            @Override
            protected Class<? extends Provider<String>> provider() {
                return CanonicalWebUrlProvider.class;
            }
        });
    }
    if (sshd) {
        modules.add(SshKeyCacheImpl.module());
    } else {
        modules.add(NoSshKeyCache.module());
    }
    modules.add(new AbstractModule() {

        @Override
        protected void configure() {
            bind(GerritOptions.class).toInstance(new GerritOptions(config, headless, slave, polyGerritDev));
            if (inMemoryTest) {
                bind(String.class).annotatedWith(SecureStoreClassName.class).toInstance(DefaultSecureStore.class.getName());
                bind(SecureStore.class).toProvider(SecureStoreProvider.class);
            }
        }
    });
    modules.add(new GarbageCollectionModule());
    if (!slave) {
        modules.add(new AccountDeactivator.Module());
        modules.add(new ChangeCleanupRunner.Module());
    }
    modules.addAll(LibModuleLoader.loadModules(cfgInjector));
    if (migrateToNoteDb()) {
        modules.add(new OnlineNoteDbMigrator.Module(trial));
    }
    if (testSysModule != null) {
        modules.add(testSysModule);
    }
    modules.add(new LocalMergeSuperSetComputation.Module());
    modules.add(new DefaultProjectNameLockManager.Module());
    return cfgInjector.createChildInjector(modules);
}
#end_block

#method_before
private Injector createDbInjector() {
    final List<Module> modules = new ArrayList<>();
    AbstractModule secureStore = createSecureStoreModule();
    modules.add(secureStore);
    if (sitePath != null) {
        Module sitePathModule = new AbstractModule() {

            @Override
            protected void configure() {
                bind(Path.class).annotatedWith(SitePath.class).toInstance(sitePath);
            }
        };
        modules.add(sitePathModule);
        Module configModule = new GerritServerConfigModule();
        modules.add(configModule);
        Injector cfgInjector = Guice.createInjector(sitePathModule, configModule, secureStore);
        Config cfg = cfgInjector.getInstance(Key.get(Config.class, GerritServerConfig.class));
        String dbType = cfg.getString("database", null, "type");
        final DataSourceType dst = Guice.createInjector(new DataSourceModule(), configModule, sitePathModule, secureStore).getInstance(Key.get(DataSourceType.class, Names.named(dbType.toLowerCase())));
        modules.add(new LifecycleModule() {

            @Override
            protected void configure() {
                bind(DataSourceType.class).toInstance(dst);
                bind(DataSourceProvider.Context.class).toInstance(DataSourceProvider.Context.MULTI_USER);
                bind(Key.get(DataSource.class, Names.named("ReviewDb"))).toProvider(DataSourceProvider.class).in(SINGLETON);
                listener().to(DataSourceProvider.class);
            }
        });
    } else {
        modules.add(new LifecycleModule() {

            @Override
            protected void configure() {
                bind(Key.get(DataSource.class, Names.named("ReviewDb"))).toProvider(ReviewDbDataSourceProvider.class).in(SINGLETON);
                listener().to(ReviewDbDataSourceProvider.class);
            }
        });
        // If we didn't get the site path from the system property
        // we need to get it from the database, as that's our old
        // method of locating the site path on disk.
        // 
        modules.add(new AbstractModule() {

            @Override
            protected void configure() {
                bind(Path.class).annotatedWith(SitePath.class).toProvider(SitePathFromSystemConfigProvider.class).in(SINGLETON);
            }
        });
        modules.add(new GerritServerConfigModule());
    }
    modules.add(new DatabaseModule());
    modules.add(new NotesMigration.Module());
    modules.add(new DropWizardMetricMaker.ApiModule());
    return Guice.createInjector(PRODUCTION, modules);
}
#method_after
private Injector createDbInjector() {
    final List<Module> modules = new ArrayList<>();
    AbstractModule secureStore = createSecureStoreModule();
    modules.add(secureStore);
    if (sitePath != null) {
        Module sitePathModule = new AbstractModule() {

            @Override
            protected void configure() {
                bind(Path.class).annotatedWith(SitePath.class).toInstance(sitePath);
            }
        };
        modules.add(sitePathModule);
        Module configModule = new GerritServerConfigModule();
        modules.add(configModule);
        Injector cfgInjector = Guice.createInjector(sitePathModule, configModule, secureStore);
        Config cfg = cfgInjector.getInstance(Key.get(Config.class, GerritServerConfig.class));
        String dbType = cfg.getString("database", null, "type");
        final DataSourceType dst = Guice.createInjector(new DataSourceModule(), configModule, sitePathModule, secureStore).getInstance(Key.get(DataSourceType.class, Names.named(dbType.toLowerCase())));
        modules.add(new LifecycleModule() {

            @Override
            protected void configure() {
                bind(DataSourceType.class).toInstance(dst);
                bind(DataSourceProvider.Context.class).toInstance(DataSourceProvider.Context.MULTI_USER);
                bind(Key.get(DataSource.class, Names.named("ReviewDb"))).toProvider(DataSourceProvider.class).in(SINGLETON);
                listener().to(DataSourceProvider.class);
            }
        });
    } else {
        modules.add(new LifecycleModule() {

            @Override
            protected void configure() {
                bind(Key.get(DataSource.class, Names.named("ReviewDb"))).toProvider(ReviewDbDataSourceProvider.class).in(SINGLETON);
                listener().to(ReviewDbDataSourceProvider.class);
            }
        });
        // If we didn't get the site path from the system property
        // we need to get it from the database, as that's our old
        // method of locating the site path on disk.
        // 
        modules.add(new AbstractModule() {

            @Override
            protected void configure() {
                bind(Path.class).annotatedWith(SitePath.class).toProvider(SitePathFromSystemConfigProvider.class).in(SINGLETON);
            }
        });
        modules.add(new GerritServerConfigModule());
    }
    modules.add(new DatabaseModule());
    modules.add(new NotesMigration.Module());
    modules.add(new GroupsMigration.Module());
    modules.add(new DropWizardMetricMaker.ApiModule());
    return Guice.createInjector(PRODUCTION, modules);
}
#end_block

#method_before
private Injector createSysInjector() {
    final List<Module> modules = new ArrayList<>();
    modules.add(new DropWizardMetricMaker.RestModule());
    modules.add(new LogFileCompressor.Module());
    modules.add(new EventBroker.Module());
    modules.add(new JdbcAccountPatchReviewStore.Module(config));
    modules.add(cfgInjector.getInstance(GitRepositoryManagerModule.class));
    modules.add(new StreamEventsApiListener.Module());
    modules.add(new ReceiveCommitsExecutorModule());
    modules.add(new DiffExecutorModule());
    modules.add(new MimeUtil2Module());
    modules.add(cfgInjector.getInstance(GerritGlobalModule.class));
    modules.add(new com.google.gerrit.server.api.Module());
    modules.add(new com.google.gerrit.server.config.endpoint.Module());
    modules.add(new SearchingChangeCacheImpl.Module());
    modules.add(new InternalAccountDirectory.Module());
    modules.add(new DefaultPermissionBackendModule());
    modules.add(new DefaultCacheFactory.Module());
    modules.add(cfgInjector.getInstance(MailReceiver.Module.class));
    modules.add(new SmtpEmailSender.Module());
    modules.add(new SignedTokenEmailTokenVerifier.Module());
    modules.add(new LocalMergeSuperSetComputation.Module());
    // Plugin module needs to be inserted *before* the index module.
    // There is the concept of LifecycleModule, in Gerrit's own extension
    // to Guice, which has these:
    // listener().to(SomeClassImplementingLifecycleListener.class);
    // and the start() methods of each such listener are executed in the
    // order they are declared.
    // Makes sure that PluginLoader.start() is executed before the
    // LuceneIndexModule.start() so that plugins get loaded and the respective
    // Guice modules installed so that the on-line reindexing will happen
    // with the proper classes (e.g. group backends, custom Prolog
    // predicates) and the associated rules ready to be evaluated.
    modules.add(new PluginModule());
    modules.add(new PluginRestApiModule());
    modules.add(new RestCacheAdminModule());
    modules.add(new GpgModule(config));
    modules.add(new StartupChecks.Module());
    // Index module shutdown must happen before work queue shutdown, otherwise
    // work queue can get stuck waiting on index futures that will never return.
    modules.add(createIndexModule());
    modules.add(new WorkQueue.Module());
    modules.add(new CanonicalWebUrlModule() {

        @Override
        protected Class<? extends Provider<String>> provider() {
            return HttpCanonicalWebUrlProvider.class;
        }
    });
    modules.add(SshKeyCacheImpl.module());
    modules.add(new AbstractModule() {

        @Override
        protected void configure() {
            bind(GerritOptions.class).toInstance(new GerritOptions(config, false, false, false));
        }
    });
    modules.add(new GarbageCollectionModule());
    modules.add(new ChangeCleanupRunner.Module());
    modules.add(new AccountDeactivator.Module());
    modules.addAll(LibModuleLoader.loadModules(cfgInjector));
    modules.add(new DefaultProjectNameLockManager.Module());
    return cfgInjector.createChildInjector(modules);
}
#method_after
private Injector createSysInjector() {
    final List<Module> modules = new ArrayList<>();
    modules.add(new DropWizardMetricMaker.RestModule());
    modules.add(new LogFileCompressor.Module());
    modules.add(new EventBroker.Module());
    modules.add(new JdbcAccountPatchReviewStore.Module(config));
    modules.add(cfgInjector.getInstance(GitRepositoryManagerModule.class));
    modules.add(new StreamEventsApiListener.Module());
    modules.add(new ReceiveCommitsExecutorModule());
    modules.add(new DiffExecutorModule());
    modules.add(new MimeUtil2Module());
    modules.add(cfgInjector.getInstance(GerritGlobalModule.class));
    modules.add(new GerritApiModule());
    modules.add(new SearchingChangeCacheImpl.Module());
    modules.add(new InternalAccountDirectory.Module());
    modules.add(new DefaultPermissionBackendModule());
    modules.add(new DefaultCacheFactory.Module());
    modules.add(cfgInjector.getInstance(MailReceiver.Module.class));
    modules.add(new SmtpEmailSender.Module());
    modules.add(new SignedTokenEmailTokenVerifier.Module());
    modules.add(new LocalMergeSuperSetComputation.Module());
    // Plugin module needs to be inserted *before* the index module.
    // There is the concept of LifecycleModule, in Gerrit's own extension
    // to Guice, which has these:
    // listener().to(SomeClassImplementingLifecycleListener.class);
    // and the start() methods of each such listener are executed in the
    // order they are declared.
    // Makes sure that PluginLoader.start() is executed before the
    // LuceneIndexModule.start() so that plugins get loaded and the respective
    // Guice modules installed so that the on-line reindexing will happen
    // with the proper classes (e.g. group backends, custom Prolog
    // predicates) and the associated rules ready to be evaluated.
    modules.add(new PluginModule());
    modules.add(new PluginRestApiModule());
    modules.add(new RestCacheAdminModule());
    modules.add(new GpgModule(config));
    modules.add(new StartupChecks.Module());
    // Index module shutdown must happen before work queue shutdown, otherwise
    // work queue can get stuck waiting on index futures that will never return.
    modules.add(createIndexModule());
    modules.add(new WorkQueue.Module());
    modules.add(new CanonicalWebUrlModule() {

        @Override
        protected Class<? extends Provider<String>> provider() {
            return HttpCanonicalWebUrlProvider.class;
        }
    });
    modules.add(SshKeyCacheImpl.module());
    modules.add(new AbstractModule() {

        @Override
        protected void configure() {
            bind(GerritOptions.class).toInstance(new GerritOptions(config, false, false, false));
        }
    });
    modules.add(new GarbageCollectionModule());
    modules.add(new ChangeCleanupRunner.Module());
    modules.add(new AccountDeactivator.Module());
    modules.addAll(LibModuleLoader.loadModules(cfgInjector));
    modules.add(new DefaultProjectNameLockManager.Module());
    return cfgInjector.createChildInjector(modules);
}
#end_block

#method_before
@Override
public int hashCode() {
    int h = 1000003;
    h ^= (this.message == null) ? 0 : this.message.hashCode();
    return h;
}
#method_after
@Override
public int hashCode() {
    return Objects.hashCode(message);
}
#end_block

#method_before
FilteredRepository create(Project.NameKey name) throws NoSuchProjectException, IOException, PermissionBackendException {
    ProjectState projectState = projectCache.checkedGet(name);
    try {
        if (!projectState.getProject().getState().permitsRead()) {
            throw new NoSuchProjectException(name);
        }
    } catch (Exception e) {
        throw new NoSuchProjectException(name);
    }
    return new FilteredRepository(projectState, userProvider.get(), repoManager.openRepository(name), visibleRefFilterFactory, permissionBackend);
}
#method_after
FilteredRepository create(Project.NameKey name) throws NoSuchProjectException, IOException, PermissionBackendException {
    ProjectState projectState = projectCache.checkedGet(name);
    if (projectState == null || !projectState.getProject().getState().permitsRead()) {
        throw new NoSuchProjectException(name);
    }
    return new FilteredRepository(projectState, userProvider.get(), repoManager.openRepository(name), visibleRefFilterFactory, permissionBackend);
}
#end_block

#method_before
private Config getGlobalConfig() throws IOException, ConfigInvalidException {
    File sitePath = new File(".").getAbsoluteFile();
    if (".".equals(sitePath.getName())) {
        sitePath = sitePath.getParentFile();
    }
    FileBasedConfig cfg = new FileBasedConfig(new File(sitePath, "etc/gitiles.config"), FS.DETECTED);
    if (cfg.getFile().exists()) {
        cfg.load();
    }
    return cfg;
}
#method_after
private Config getGlobalConfig() throws IOException {
    File cfgFile = site.etc_dir.resolve("gitiles.config").toFile();
    FileBasedConfig cfg = new FileBasedConfig(cfgFile, FS.DETECTED);
    try {
        if (cfg.getFile().exists()) {
            cfg.load();
        }
    } catch (ConfigInvalidException e) {
        throw new IOException(e);
    }
    return cfg;
}
#end_block

#method_before
@Override
public Config getConfig() throws IOException {
    // Try to get a gitiles.config file from the refs/meta/config branch
    // of the project. For non-project access, use All-Projects as project.
    // If none of the above exists, use global gitiles.config.
    Project.NameKey nameKey = Resolver.getNameKey(req);
    ProjectState state = projectCache.get(nameKey);
    if (state != null) {
        Config cfg = state.getConfig("gitiles.config").getWithInheritance();
        if (cfg != null && cfg.getSections().size() > 0) {
            return cfg;
        }
    } else {
        state = projectCache.getAllProjects();
        Config cfg = state.getConfig("gitiles.config").get();
        if (cfg != null && cfg.getSections().size() > 0) {
            return cfg;
        }
    }
    try {
        return getGlobalConfig();
    } catch (Exception e) {
    }
    return new Config();
}
#method_after
@Override
public Config getConfig() throws IOException {
    // Try to get a gitiles.config file from the refs/meta/config branch
    // of the project. For non-project access, use All-Projects as project.
    // If none of the above exists, use global gitiles.config.
    Project.NameKey nameKey = Resolver.getNameKey(req);
    ProjectState state = projectCache.get(nameKey);
    if (state != null) {
        Config cfg = state.getConfig("gitiles.config").getWithInheritance();
        if (cfg != null && cfg.getSections().size() > 0) {
            return cfg;
        }
    } else {
        state = projectCache.getAllProjects();
        Config cfg = state.getConfig("gitiles.config").get();
        if (cfg != null && cfg.getSections().size() > 0) {
            return cfg;
        }
    }
    return getGlobalConfig();
}
#end_block

#method_before
private void validate(RepoContext ctx) throws AuthException, ResourceConflictException, IOException, PermissionBackendException {
    if (checkAddPatchSetPermission) {
        permissionBackend.user(ctx.getUser()).database(ctx.getDb()).change(origNotes).check(ChangePermission.ADD_PATCH_SET);
    }
    if (!validate) {
        return;
    }
    PermissionBackend.ForRef perm = permissionBackend.user(ctx.getUser()).ref(origNotes.getChange().getDest());
    String refName = getPatchSetId().toRefName();
    try (CommitReceivedEvent event = new CommitReceivedEvent(new ReceiveCommand(ObjectId.zeroId(), commitId, refName.substring(0, refName.lastIndexOf('/') + 1) + "new"), projectCache.checkedGet(origNotes.getProjectName()).getProject(), origNotes.getChange().getDest().get(), ctx.getRevWalk().getObjectReader(), commitId, ctx.getIdentifiedUser())) {
        commitValidatorsFactory.forGerritCommits(perm, origNotes.getChange().getDest(), ctx.getIdentifiedUser(), new NoSshInfo(), ctx.getRevWalk(), origNotes.getChange()).validate(event);
    } catch (CommitValidationException e) {
        throw new ResourceConflictException(e.getFullMessage());
    }
}
#method_after
private void validate(RepoContext ctx) throws AuthException, ResourceConflictException, IOException, PermissionBackendException {
    if (checkAddPatchSetPermission) {
        permissionBackend.user(ctx.getUser()).database(ctx.getDb()).change(origNotes).check(ChangePermission.ADD_PATCH_SET);
    }
    projectCache.checkedGet(ctx.getProject()).checkStatePermitsWrite();
    if (!validate) {
        return;
    }
    PermissionBackend.ForRef perm = permissionBackend.user(ctx.getUser()).ref(origNotes.getChange().getDest());
    String refName = getPatchSetId().toRefName();
    try (CommitReceivedEvent event = new CommitReceivedEvent(new ReceiveCommand(ObjectId.zeroId(), commitId, refName.substring(0, refName.lastIndexOf('/') + 1) + "new"), projectCache.checkedGet(origNotes.getProjectName()).getProject(), origNotes.getChange().getDest().get(), ctx.getRevWalk().getObjectReader(), commitId, ctx.getIdentifiedUser())) {
        commitValidatorsFactory.forGerritCommits(perm, origNotes.getChange().getDest(), ctx.getIdentifiedUser(), new NoSshInfo(), ctx.getRevWalk(), origNotes.getChange()).validate(event);
    } catch (CommitValidationException e) {
        throw new ResourceConflictException(e.getFullMessage());
    }
}
#end_block

#method_before
private void parseCreate(ReceiveCommand cmd) throws PermissionBackendException, NoSuchProjectException, IOException {
    RevObject obj;
    try {
        obj = rp.getRevWalk().parseAny(cmd.getNewId());
    } catch (IOException err) {
        logError("Invalid object " + cmd.getNewId().name() + " for " + cmd.getRefName() + " creation", err);
        reject(cmd, "invalid object");
        return;
    }
    logDebug("Creating {}", cmd);
    if (isHead(cmd) && !isCommit(cmd)) {
        return;
    }
    Branch.NameKey branch = new Branch.NameKey(project.getName(), cmd.getRefName());
    try {
        // Must pass explicit user instead of injecting a provider into CreateRefControl, since
        // Provider<CurrentUser> within ReceiveCommits will always return anonymous.
        createRefControl.checkCreateRef(Providers.of(user), rp.getRepository(), branch, obj);
    } catch (AuthException denied) {
        reject(cmd, "prohibited by Gerrit: " + denied.getMessage());
        return;
    }
    if (!validRefOperation(cmd)) {
        // validRefOperation sets messages, so no need to provide more feedback.
        return;
    }
    validateNewCommits(new Branch.NameKey(project.getNameKey(), cmd.getRefName()), cmd);
    actualCommands.add(cmd);
}
#method_after
private void parseCreate(ReceiveCommand cmd) throws PermissionBackendException, NoSuchProjectException, IOException {
    RevObject obj;
    try {
        obj = rp.getRevWalk().parseAny(cmd.getNewId());
    } catch (IOException err) {
        logError("Invalid object " + cmd.getNewId().name() + " for " + cmd.getRefName() + " creation", err);
        reject(cmd, "invalid object");
        return;
    }
    logDebug("Creating {}", cmd);
    if (isHead(cmd) && !isCommit(cmd)) {
        return;
    }
    Branch.NameKey branch = new Branch.NameKey(project.getName(), cmd.getRefName());
    try {
        // Must pass explicit user instead of injecting a provider into CreateRefControl, since
        // Provider<CurrentUser> within ReceiveCommits will always return anonymous.
        createRefControl.checkCreateRef(Providers.of(user), rp.getRepository(), branch, obj);
    } catch (AuthException | ResourceConflictException denied) {
        reject(cmd, "prohibited by Gerrit: " + denied.getMessage());
        return;
    }
    if (!validRefOperation(cmd)) {
        // validRefOperation sets messages, so no need to provide more feedback.
        return;
    }
    validateNewCommits(new Branch.NameKey(project.getNameKey(), cmd.getRefName()), cmd);
    actualCommands.add(cmd);
}
#end_block

#method_before
private void parseUpdate(ReceiveCommand cmd) throws PermissionBackendException {
    logDebug("Updating {}", cmd);
    boolean ok;
    try {
        permissions.ref(cmd.getRefName()).check(RefPermission.UPDATE);
        ok = true;
    } catch (AuthException err) {
        ok = false;
    }
    if (ok) {
        if (isHead(cmd) && !isCommit(cmd)) {
            return;
        }
        if (!validRefOperation(cmd)) {
            return;
        }
        validateNewCommits(new Branch.NameKey(project.getNameKey(), cmd.getRefName()), cmd);
        actualCommands.add(cmd);
    } else {
        if (RefNames.REFS_CONFIG.equals(cmd.getRefName())) {
            errors.put(ReceiveError.CONFIG_UPDATE, RefNames.REFS_CONFIG);
        } else {
            errors.put(ReceiveError.UPDATE, cmd.getRefName());
        }
        reject(cmd, "prohibited by Gerrit: ref update access denied");
    }
}
#method_after
private void parseUpdate(ReceiveCommand cmd) throws PermissionBackendException {
    logDebug("Updating {}", cmd);
    boolean ok;
    try {
        permissions.ref(cmd.getRefName()).check(RefPermission.UPDATE);
        ok = true;
    } catch (AuthException err) {
        ok = false;
    }
    if (!projectState.statePermitsWrite()) {
        reject(cmd, "prohibited by Gerrit: project state does not permit write");
    }
    if (ok) {
        if (isHead(cmd) && !isCommit(cmd)) {
            return;
        }
        if (!validRefOperation(cmd)) {
            return;
        }
        validateNewCommits(new Branch.NameKey(project.getNameKey(), cmd.getRefName()), cmd);
        actualCommands.add(cmd);
    } else {
        if (RefNames.REFS_CONFIG.equals(cmd.getRefName())) {
            errors.put(ReceiveError.CONFIG_UPDATE, RefNames.REFS_CONFIG);
        } else {
            errors.put(ReceiveError.UPDATE, cmd.getRefName());
        }
        reject(cmd, "prohibited by Gerrit: ref update access denied");
    }
}
#end_block

#method_before
private boolean canDelete(ReceiveCommand cmd) throws PermissionBackendException {
    try {
        permissions.ref(cmd.getRefName()).check(RefPermission.DELETE);
        return true;
    } catch (AuthException e) {
        return false;
    }
}
#method_after
private boolean canDelete(ReceiveCommand cmd) throws PermissionBackendException {
    try {
        permissions.ref(cmd.getRefName()).check(RefPermission.DELETE);
        return projectState.statePermitsWrite();
    } catch (AuthException e) {
        return false;
    }
}
#end_block

#method_before
private void parseRewind(ReceiveCommand cmd) throws PermissionBackendException {
    RevCommit newObject;
    try {
        newObject = rp.getRevWalk().parseCommit(cmd.getNewId());
    } catch (IncorrectObjectTypeException notCommit) {
        newObject = null;
    } catch (IOException err) {
        logError("Invalid object " + cmd.getNewId().name() + " for " + cmd.getRefName() + " forced update", err);
        reject(cmd, "invalid object");
        return;
    }
    logDebug("Rewinding {}", cmd);
    if (newObject != null) {
        validateNewCommits(new Branch.NameKey(project.getNameKey(), cmd.getRefName()), cmd);
        if (cmd.getResult() != NOT_ATTEMPTED) {
            return;
        }
    }
    boolean ok;
    try {
        permissions.ref(cmd.getRefName()).check(RefPermission.FORCE_UPDATE);
        ok = true;
    } catch (AuthException err) {
        ok = false;
    }
    if (ok) {
        if (!validRefOperation(cmd)) {
            return;
        }
        actualCommands.add(cmd);
    } else {
        cmd.setResult(REJECTED_NONFASTFORWARD, " need '" + PermissionRule.FORCE_PUSH + "' privilege.");
    }
}
#method_after
private void parseRewind(ReceiveCommand cmd) throws PermissionBackendException {
    RevCommit newObject;
    try {
        newObject = rp.getRevWalk().parseCommit(cmd.getNewId());
    } catch (IncorrectObjectTypeException notCommit) {
        newObject = null;
    } catch (IOException err) {
        logError("Invalid object " + cmd.getNewId().name() + " for " + cmd.getRefName() + " forced update", err);
        reject(cmd, "invalid object");
        return;
    }
    logDebug("Rewinding {}", cmd);
    if (newObject != null) {
        validateNewCommits(new Branch.NameKey(project.getNameKey(), cmd.getRefName()), cmd);
        if (cmd.getResult() != NOT_ATTEMPTED) {
            return;
        }
    }
    boolean ok;
    try {
        permissions.ref(cmd.getRefName()).check(RefPermission.FORCE_UPDATE);
        ok = true;
    } catch (AuthException err) {
        ok = false;
    }
    if (ok) {
        if (!validRefOperation(cmd)) {
            return;
        }
        if (!projectState.statePermitsWrite()) {
            cmd.setResult(REJECTED_NONFASTFORWARD, " project state does not permit write.");
        }
        actualCommands.add(cmd);
    } else {
        cmd.setResult(REJECTED_NONFASTFORWARD, " need '" + PermissionRule.FORCE_PUSH + "' privilege.");
    }
}
#end_block

#method_before
private void parseMagicBranch(ReceiveCommand cmd) throws PermissionBackendException {
    // Permit exactly one new change request per push.
    if (magicBranch != null) {
        reject(cmd, "duplicate request");
        return;
    }
    logDebug("Found magic branch {}", cmd.getRefName());
    magicBranch = new MagicBranchInput(user, cmd, labelTypes, notesMigration);
    magicBranch.reviewer.addAll(extraReviewers.get(ReviewerStateInternal.REVIEWER));
    magicBranch.cc.addAll(extraReviewers.get(ReviewerStateInternal.CC));
    String ref;
    CmdLineParser clp = optionParserFactory.create(magicBranch);
    magicBranch.clp = clp;
    try {
        ref = magicBranch.parse(clp, repo, rp.getAdvertisedRefs().keySet(), pushOptions);
    } catch (CmdLineException e) {
        if (!clp.wasHelpRequestedByOption()) {
            logDebug("Invalid branch syntax");
            reject(cmd, e.getMessage());
            return;
        }
        // never happen
        ref = null;
    }
    if (magicBranch.topic != null && magicBranch.topic.length() > ChangeUtil.TOPIC_MAX_LENGTH) {
        reject(cmd, String.format("topic length exceeds the limit (%s)", ChangeUtil.TOPIC_MAX_LENGTH));
    }
    if (clp.wasHelpRequestedByOption()) {
        StringWriter w = new StringWriter();
        w.write("\nHelp for refs/for/branch:\n\n");
        clp.printUsage(w, null);
        addMessage(w.toString());
        reject(cmd, "see help");
        return;
    }
    if (projectState.isAllUsers() && RefNames.REFS_USERS_SELF.equals(ref)) {
        logDebug("Handling {}", RefNames.REFS_USERS_SELF);
        ref = RefNames.refsUsers(user.getAccountId());
    }
    if (!rp.getAdvertisedRefs().containsKey(ref) && !ref.equals(readHEAD(repo)) && !ref.equals(RefNames.REFS_CONFIG)) {
        logDebug("Ref {} not found", ref);
        if (ref.startsWith(Constants.R_HEADS)) {
            String n = ref.substring(Constants.R_HEADS.length());
            reject(cmd, "branch " + n + " not found");
        } else {
            reject(cmd, ref + " not found");
        }
        return;
    }
    magicBranch.dest = new Branch.NameKey(project.getNameKey(), ref);
    magicBranch.perm = permissions.ref(ref);
    if (!projectState.getProject().getState().permitsWrite()) {
        reject(cmd, "project state does not permit write");
        return;
    }
    try {
        magicBranch.perm.check(RefPermission.CREATE_CHANGE);
    } catch (AuthException denied) {
        errors.put(ReceiveError.CODE_REVIEW, ref);
        reject(cmd, denied.getMessage());
        return;
    }
    if (magicBranch.isPrivate && magicBranch.removePrivate) {
        reject(cmd, "the options 'private' and 'remove-private' are mutually exclusive");
        return;
    }
    if (magicBranch.workInProgress && magicBranch.ready) {
        reject(cmd, "the options 'wip' and 'ready' are mutually exclusive");
        return;
    }
    if (magicBranch.publishComments && magicBranch.noPublishComments) {
        reject(cmd, "the options 'publish-comments' and 'no-publish-comments' are mutually exclusive");
        return;
    }
    if (magicBranch.submit) {
        try {
            permissions.ref(ref).check(RefPermission.UPDATE_BY_SUBMIT);
        } catch (AuthException e) {
            reject(cmd, e.getMessage());
            return;
        }
    }
    RevWalk walk = rp.getRevWalk();
    RevCommit tip;
    try {
        tip = walk.parseCommit(magicBranch.cmd.getNewId());
        logDebug("Tip of push: {}", tip.name());
    } catch (IOException ex) {
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", ex);
        return;
    }
    String destBranch = magicBranch.dest.get();
    try {
        if (magicBranch.merged) {
            if (magicBranch.base != null) {
                reject(cmd, "cannot use merged with base");
                return;
            }
            RevCommit branchTip = readBranchTip(cmd, magicBranch.dest);
            if (branchTip == null) {
                // readBranchTip already rejected cmd.
                return;
            }
            if (!walk.isMergedInto(tip, branchTip)) {
                reject(cmd, "not merged into branch");
                return;
            }
        }
        // if %base or %merged was specified, ignore newChangeForAllNotInTarget.
        if (tip.getParentCount() > 1 || magicBranch.base != null || magicBranch.merged || tip.getParentCount() == 0) {
            logDebug("Forcing newChangeForAllNotInTarget = false");
            newChangeForAllNotInTarget = false;
        }
        if (magicBranch.base != null) {
            logDebug("Handling %base: {}", magicBranch.base);
            magicBranch.baseCommit = Lists.newArrayListWithCapacity(magicBranch.base.size());
            for (ObjectId id : magicBranch.base) {
                try {
                    magicBranch.baseCommit.add(walk.parseCommit(id));
                } catch (IncorrectObjectTypeException notCommit) {
                    reject(cmd, "base must be a commit");
                    return;
                } catch (MissingObjectException e) {
                    reject(cmd, "base not found");
                    return;
                } catch (IOException e) {
                    logWarn(String.format("Project %s cannot read %s", project.getName(), id.name()), e);
                    reject(cmd, "internal server error");
                    return;
                }
            }
        } else if (newChangeForAllNotInTarget) {
            RevCommit branchTip = readBranchTip(cmd, magicBranch.dest);
            if (branchTip == null) {
                // readBranchTip already rejected cmd.
                return;
            }
            magicBranch.baseCommit = Collections.singletonList(branchTip);
            logDebug("Set baseCommit = {}", magicBranch.baseCommit.get(0).name());
        }
    } catch (IOException ex) {
        logWarn(String.format("Error walking to %s in project %s", destBranch, project.getName()), ex);
        reject(cmd, "internal server error");
        return;
    }
    // 
    try {
        Ref targetRef = rp.getAdvertisedRefs().get(magicBranch.dest.get());
        if (targetRef == null || targetRef.getObjectId() == null) {
            // The destination branch does not yet exist. Assume the
            // history being sent for review will start it and thus
            // is "connected" to the branch.
            logDebug("Branch is unborn");
            return;
        }
        RevCommit h = walk.parseCommit(targetRef.getObjectId());
        logDebug("Current branch tip: {}", h.name());
        RevFilter oldRevFilter = walk.getRevFilter();
        try {
            walk.reset();
            walk.setRevFilter(RevFilter.MERGE_BASE);
            walk.markStart(tip);
            walk.markStart(h);
            if (walk.next() == null) {
                reject(magicBranch.cmd, "no common ancestry");
            }
        } finally {
            walk.reset();
            walk.setRevFilter(oldRevFilter);
        }
    } catch (IOException e) {
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", e);
    }
}
#method_after
private void parseMagicBranch(ReceiveCommand cmd) throws PermissionBackendException {
    // Permit exactly one new change request per push.
    if (magicBranch != null) {
        reject(cmd, "duplicate request");
        return;
    }
    logDebug("Found magic branch {}", cmd.getRefName());
    magicBranch = new MagicBranchInput(user, cmd, labelTypes, notesMigration);
    magicBranch.reviewer.addAll(extraReviewers.get(ReviewerStateInternal.REVIEWER));
    magicBranch.cc.addAll(extraReviewers.get(ReviewerStateInternal.CC));
    String ref;
    CmdLineParser clp = optionParserFactory.create(magicBranch);
    magicBranch.clp = clp;
    try {
        ref = magicBranch.parse(clp, repo, rp.getAdvertisedRefs().keySet(), pushOptions);
    } catch (CmdLineException e) {
        if (!clp.wasHelpRequestedByOption()) {
            logDebug("Invalid branch syntax");
            reject(cmd, e.getMessage());
            return;
        }
        // never happen
        ref = null;
    }
    if (magicBranch.topic != null && magicBranch.topic.length() > ChangeUtil.TOPIC_MAX_LENGTH) {
        reject(cmd, String.format("topic length exceeds the limit (%s)", ChangeUtil.TOPIC_MAX_LENGTH));
    }
    if (clp.wasHelpRequestedByOption()) {
        StringWriter w = new StringWriter();
        w.write("\nHelp for refs/for/branch:\n\n");
        clp.printUsage(w, null);
        addMessage(w.toString());
        reject(cmd, "see help");
        return;
    }
    if (projectState.isAllUsers() && RefNames.REFS_USERS_SELF.equals(ref)) {
        logDebug("Handling {}", RefNames.REFS_USERS_SELF);
        ref = RefNames.refsUsers(user.getAccountId());
    }
    if (!rp.getAdvertisedRefs().containsKey(ref) && !ref.equals(readHEAD(repo)) && !ref.equals(RefNames.REFS_CONFIG)) {
        logDebug("Ref {} not found", ref);
        if (ref.startsWith(Constants.R_HEADS)) {
            String n = ref.substring(Constants.R_HEADS.length());
            reject(cmd, "branch " + n + " not found");
        } else {
            reject(cmd, ref + " not found");
        }
        return;
    }
    magicBranch.dest = new Branch.NameKey(project.getNameKey(), ref);
    magicBranch.perm = permissions.ref(ref);
    if (!projectState.getProject().getState().permitsWrite()) {
        reject(cmd, "project state does not permit write");
        return;
    }
    try {
        magicBranch.perm.check(RefPermission.CREATE_CHANGE);
    } catch (AuthException denied) {
        errors.put(ReceiveError.CODE_REVIEW, ref);
        reject(cmd, denied.getMessage());
        return;
    }
    if (magicBranch.isPrivate && magicBranch.removePrivate) {
        reject(cmd, "the options 'private' and 'remove-private' are mutually exclusive");
        return;
    }
    boolean privateByDefault = projectCache.get(project.getNameKey()).is(BooleanProjectConfig.PRIVATE_BY_DEFAULT);
    setChangeAsPrivate = magicBranch.draft || magicBranch.isPrivate || (privateByDefault && !magicBranch.removePrivate);
    if (receiveConfig.disablePrivateChanges && setChangeAsPrivate) {
        reject(cmd, "private changes are disabled");
        return;
    }
    if (magicBranch.workInProgress && magicBranch.ready) {
        reject(cmd, "the options 'wip' and 'ready' are mutually exclusive");
        return;
    }
    if (magicBranch.publishComments && magicBranch.noPublishComments) {
        reject(cmd, "the options 'publish-comments' and 'no-publish-comments' are mutually exclusive");
        return;
    }
    if (magicBranch.submit) {
        try {
            permissions.ref(ref).check(RefPermission.UPDATE_BY_SUBMIT);
        } catch (AuthException e) {
            reject(cmd, e.getMessage());
            return;
        }
        if (!projectState.statePermitsWrite()) {
            reject(cmd, "project state does not permit write");
            return;
        }
    }
    RevWalk walk = rp.getRevWalk();
    RevCommit tip;
    try {
        tip = walk.parseCommit(magicBranch.cmd.getNewId());
        logDebug("Tip of push: {}", tip.name());
    } catch (IOException ex) {
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", ex);
        return;
    }
    String destBranch = magicBranch.dest.get();
    try {
        if (magicBranch.merged) {
            if (magicBranch.base != null) {
                reject(cmd, "cannot use merged with base");
                return;
            }
            RevCommit branchTip = readBranchTip(cmd, magicBranch.dest);
            if (branchTip == null) {
                // readBranchTip already rejected cmd.
                return;
            }
            if (!walk.isMergedInto(tip, branchTip)) {
                reject(cmd, "not merged into branch");
                return;
            }
        }
        // if %base or %merged was specified, ignore newChangeForAllNotInTarget.
        if (tip.getParentCount() > 1 || magicBranch.base != null || magicBranch.merged || tip.getParentCount() == 0) {
            logDebug("Forcing newChangeForAllNotInTarget = false");
            newChangeForAllNotInTarget = false;
        }
        if (magicBranch.base != null) {
            logDebug("Handling %base: {}", magicBranch.base);
            magicBranch.baseCommit = Lists.newArrayListWithCapacity(magicBranch.base.size());
            for (ObjectId id : magicBranch.base) {
                try {
                    magicBranch.baseCommit.add(walk.parseCommit(id));
                } catch (IncorrectObjectTypeException notCommit) {
                    reject(cmd, "base must be a commit");
                    return;
                } catch (MissingObjectException e) {
                    reject(cmd, "base not found");
                    return;
                } catch (IOException e) {
                    logWarn(String.format("Project %s cannot read %s", project.getName(), id.name()), e);
                    reject(cmd, "internal server error");
                    return;
                }
            }
        } else if (newChangeForAllNotInTarget) {
            RevCommit branchTip = readBranchTip(cmd, magicBranch.dest);
            if (branchTip == null) {
                // readBranchTip already rejected cmd.
                return;
            }
            magicBranch.baseCommit = Collections.singletonList(branchTip);
            logDebug("Set baseCommit = {}", magicBranch.baseCommit.get(0).name());
        }
    } catch (IOException ex) {
        logWarn(String.format("Error walking to %s in project %s", destBranch, project.getName()), ex);
        reject(cmd, "internal server error");
        return;
    }
    // 
    try {
        Ref targetRef = rp.getAdvertisedRefs().get(magicBranch.dest.get());
        if (targetRef == null || targetRef.getObjectId() == null) {
            // The destination branch does not yet exist. Assume the
            // history being sent for review will start it and thus
            // is "connected" to the branch.
            logDebug("Branch is unborn");
            return;
        }
        RevCommit h = walk.parseCommit(targetRef.getObjectId());
        logDebug("Current branch tip: {}", h.name());
        RevFilter oldRevFilter = walk.getRevFilter();
        try {
            walk.reset();
            walk.setRevFilter(RevFilter.MERGE_BASE);
            walk.markStart(tip);
            walk.markStart(h);
            if (walk.next() == null) {
                reject(magicBranch.cmd, "no common ancestry");
            }
        } finally {
            walk.reset();
            walk.setRevFilter(oldRevFilter);
        }
    } catch (IOException e) {
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", e);
    }
}
#end_block

#method_before
private void setChangeId(int id) {
    boolean privateByDefault = projectCache.get(project.getNameKey()).is(BooleanProjectConfig.PRIVATE_BY_DEFAULT);
    changeId = new Change.Id(id);
    ins = changeInserterFactory.create(changeId, commit, refName).setTopic(magicBranch.topic).setPrivate(magicBranch.draft || magicBranch.isPrivate || (privateByDefault && !magicBranch.removePrivate)).setWorkInProgress(magicBranch.workInProgress).setValidate(false);
    if (magicBranch.merged) {
        ins.setStatus(Change.Status.MERGED);
    }
    cmd = new ReceiveCommand(ObjectId.zeroId(), commit, ins.getPatchSetId().toRefName());
    if (rp.getPushCertificate() != null) {
        ins.setPushCertificate(rp.getPushCertificate().toTextWithSignature());
    }
}
#method_after
private void setChangeId(int id) {
    changeId = new Change.Id(id);
    ins = changeInserterFactory.create(changeId, commit, refName).setTopic(magicBranch.topic).setPrivate(setChangeAsPrivate).setWorkInProgress(magicBranch.workInProgress).setValidate(false);
    if (magicBranch.merged) {
        ins.setStatus(Change.Status.MERGED);
    }
    cmd = new ReceiveCommand(ObjectId.zeroId(), commit, ins.getPatchSetId().toRefName());
    if (rp.getPushCertificate() != null) {
        ins.setPushCertificate(rp.getPushCertificate().toTextWithSignature());
    }
}
#end_block

#method_before
boolean validate(boolean autoClose) throws IOException, OrmException, PermissionBackendException {
    if (!autoClose && inputCommand.getResult() != NOT_ATTEMPTED) {
        return false;
    } else if (notes == null) {
        reject(inputCommand, "change " + ontoChange + " not found");
        return false;
    }
    Change change = notes.getChange();
    priorPatchSet = change.currentPatchSetId();
    if (!revisions.containsValue(priorPatchSet)) {
        reject(inputCommand, "change " + ontoChange + " missing revisions");
        return false;
    }
    RevCommit newCommit = rp.getRevWalk().parseCommit(newCommitId);
    RevCommit priorCommit = revisions.inverse().get(priorPatchSet);
    try {
        permissions.change(notes).database(db).check(ChangePermission.ADD_PATCH_SET);
    } catch (AuthException no) {
        reject(inputCommand, "cannot add patch set to " + ontoChange + ".");
        return false;
    }
    if (change.getStatus().isClosed()) {
        reject(inputCommand, "change " + ontoChange + " closed");
        return false;
    } else if (revisions.containsKey(newCommit)) {
        reject(inputCommand, "commit already exists (in the change)");
        return false;
    }
    for (Ref r : rp.getRepository().getRefDatabase().getRefs("refs/changes").values()) {
        if (r.getObjectId().equals(newCommit)) {
            reject(inputCommand, "commit already exists (in the project)");
            return false;
        }
    }
    for (RevCommit prior : revisions.keySet()) {
        // amending when trying to address review comments.
        if (rp.getRevWalk().isMergedInto(prior, newCommit)) {
            reject(inputCommand, SAME_CHANGE_ID_IN_MULTIPLE_CHANGES);
            return false;
        }
    }
    PermissionBackend.ForRef perm = permissions.ref(change.getDest().get());
    if (!validCommit(rp.getRevWalk(), perm, change.getDest(), inputCommand, newCommit, change)) {
        return false;
    }
    rp.getRevWalk().parseBody(priorCommit);
    // of the commit was modified.
    if (newCommit.getTree().equals(priorCommit.getTree())) {
        boolean messageEq = eq(newCommit.getFullMessage(), priorCommit.getFullMessage());
        boolean parentsEq = parentsEqual(newCommit, priorCommit);
        boolean authorEq = authorEqual(newCommit, priorCommit);
        ObjectReader reader = rp.getRevWalk().getObjectReader();
        if (messageEq && parentsEq && authorEq && !autoClose) {
            addMessage(String.format("(W) No changes between prior commit %s and new commit %s", reader.abbreviate(priorCommit).name(), reader.abbreviate(newCommit).name()));
        } else {
            StringBuilder msg = new StringBuilder();
            msg.append("(I) ");
            msg.append(reader.abbreviate(newCommit).name());
            msg.append(":");
            msg.append(" no files changed");
            if (!authorEq) {
                msg.append(", author changed");
            }
            if (!messageEq) {
                msg.append(", message updated");
            }
            if (!parentsEq) {
                msg.append(", was rebased");
            }
            addMessage(msg.toString());
        }
    }
    if (magicBranch != null && (magicBranch.workInProgress || magicBranch.ready) && magicBranch.workInProgress != change.isWorkInProgress() && !user.getAccountId().equals(change.getOwner())) {
        reject(inputCommand, ONLY_OWNER_CAN_MODIFY_WIP);
        return false;
    }
    if (magicBranch != null && (magicBranch.edit || magicBranch.draft)) {
        return newEdit();
    }
    newPatchSet();
    return true;
}
#method_after
boolean validate(boolean autoClose) throws IOException, OrmException, PermissionBackendException {
    if (!autoClose && inputCommand.getResult() != NOT_ATTEMPTED) {
        return false;
    } else if (notes == null) {
        reject(inputCommand, "change " + ontoChange + " not found");
        return false;
    }
    Change change = notes.getChange();
    priorPatchSet = change.currentPatchSetId();
    if (!revisions.containsValue(priorPatchSet)) {
        reject(inputCommand, "change " + ontoChange + " missing revisions");
        return false;
    }
    RevCommit newCommit = rp.getRevWalk().parseCommit(newCommitId);
    RevCommit priorCommit = revisions.inverse().get(priorPatchSet);
    try {
        permissions.change(notes).database(db).check(ChangePermission.ADD_PATCH_SET);
    } catch (AuthException no) {
        reject(inputCommand, "cannot add patch set to " + ontoChange + ".");
        return false;
    }
    if (!projectState.statePermitsWrite()) {
        reject(inputCommand, "cannot add patch set to " + ontoChange + ".");
        return false;
    }
    if (change.getStatus().isClosed()) {
        reject(inputCommand, "change " + ontoChange + " closed");
        return false;
    } else if (revisions.containsKey(newCommit)) {
        reject(inputCommand, "commit already exists (in the change)");
        return false;
    }
    for (Ref r : rp.getRepository().getRefDatabase().getRefs("refs/changes").values()) {
        if (r.getObjectId().equals(newCommit)) {
            reject(inputCommand, "commit already exists (in the project)");
            return false;
        }
    }
    for (RevCommit prior : revisions.keySet()) {
        // amending when trying to address review comments.
        if (rp.getRevWalk().isMergedInto(prior, newCommit)) {
            reject(inputCommand, SAME_CHANGE_ID_IN_MULTIPLE_CHANGES);
            return false;
        }
    }
    PermissionBackend.ForRef perm = permissions.ref(change.getDest().get());
    if (!validCommit(rp.getRevWalk(), perm, change.getDest(), inputCommand, newCommit, change)) {
        return false;
    }
    rp.getRevWalk().parseBody(priorCommit);
    // of the commit was modified.
    if (newCommit.getTree().equals(priorCommit.getTree())) {
        boolean messageEq = eq(newCommit.getFullMessage(), priorCommit.getFullMessage());
        boolean parentsEq = parentsEqual(newCommit, priorCommit);
        boolean authorEq = authorEqual(newCommit, priorCommit);
        ObjectReader reader = rp.getRevWalk().getObjectReader();
        if (messageEq && parentsEq && authorEq && !autoClose) {
            addMessage(String.format("(W) No changes between prior commit %s and new commit %s", reader.abbreviate(priorCommit).name(), reader.abbreviate(newCommit).name()));
        } else {
            StringBuilder msg = new StringBuilder();
            msg.append("(I) ");
            msg.append(reader.abbreviate(newCommit).name());
            msg.append(":");
            msg.append(" no files changed");
            if (!authorEq) {
                msg.append(", author changed");
            }
            if (!messageEq) {
                msg.append(", message updated");
            }
            if (!parentsEq) {
                msg.append(", was rebased");
            }
            addMessage(msg.toString());
        }
    }
    if (magicBranch != null && (magicBranch.workInProgress || magicBranch.ready) && magicBranch.workInProgress != change.isWorkInProgress() && !user.getAccountId().equals(change.getOwner())) {
        reject(inputCommand, ONLY_OWNER_CAN_MODIFY_WIP);
        return false;
    }
    if (magicBranch != null && (magicBranch.edit || magicBranch.draft)) {
        return newEdit();
    }
    newPatchSet();
    return true;
}
#end_block

#method_before
private boolean validCommit(RevWalk rw, PermissionBackend.ForRef perm, Branch.NameKey branch, ReceiveCommand cmd, ObjectId id, @Nullable Change change) throws IOException {
    if (validCommits.contains(id)) {
        return true;
    }
    RevCommit c = rw.parseCommit(id);
    rw.parseBody(c);
    try (CommitReceivedEvent receiveEvent = new CommitReceivedEvent(cmd, project, branch.get(), rw.getObjectReader(), c, user)) {
        boolean isMerged = magicBranch != null && cmd.getRefName().equals(magicBranch.cmd.getRefName()) && magicBranch.merged;
        CommitValidators validators = isMerged ? commitValidatorsFactory.forMergedCommits(perm, user.asIdentifiedUser()) : commitValidatorsFactory.forReceiveCommits(perm, branch, user.asIdentifiedUser(), sshInfo, repo, rw, change);
        messages.addAll(validators.validate(receiveEvent));
    } catch (CommitValidationException e) {
        logDebug("Commit validation failed on {}", c.name());
        messages.addAll(e.getMessages());
        reject(cmd, e.getMessage());
        return false;
    }
    validCommits.add(c.copy());
    return true;
}
#method_after
private boolean validCommit(RevWalk rw, PermissionBackend.ForRef perm, Branch.NameKey branch, ReceiveCommand cmd, ObjectId id, @Nullable Change change) throws IOException {
    if (validCommits.contains(id)) {
        return true;
    }
    RevCommit c = rw.parseCommit(id);
    rw.parseBody(c);
    try (CommitReceivedEvent receiveEvent = new CommitReceivedEvent(cmd, project, branch.get(), rw.getObjectReader(), c, user)) {
        boolean isMerged = magicBranch != null && cmd.getRefName().equals(magicBranch.cmd.getRefName()) && magicBranch.merged;
        CommitValidators validators = isMerged ? commitValidatorsFactory.forMergedCommits(project.getNameKey(), perm, user.asIdentifiedUser()) : commitValidatorsFactory.forReceiveCommits(perm, branch, user.asIdentifiedUser(), sshInfo, repo, rw, change);
        messages.addAll(validators.validate(receiveEvent));
    } catch (CommitValidationException e) {
        logDebug("Commit validation failed on {}", c.name());
        messages.addAll(e.getMessages());
        reject(cmd, e.getMessage());
        return false;
    }
    validCommits.add(c.copy());
    return true;
}
#end_block

#method_before
private void autoCloseChanges(ReceiveCommand cmd) {
    logDebug("Starting auto-closing of changes");
    String refName = cmd.getRefName();
    checkState(!MagicBranch.isMagicBranch(refName), "shouldn't be auto-closing changes on magic branch %s", refName);
    // insertChangesAndPatchSets.
    try {
        retryHelper.execute(updateFactory -> {
            try (BatchUpdate bu = updateFactory.create(db, projectState.getNameKey(), user, TimeUtil.nowTs());
                ObjectInserter ins = repo.newObjectInserter();
                ObjectReader reader = ins.newReader();
                RevWalk rw = new RevWalk(reader)) {
                bu.setRepository(repo, rw, ins).updateChangesInParallel();
                bu.setRequestId(receiveId);
                // TODO(dborowitz): Teach BatchUpdate to ignore missing changes.
                RevCommit newTip = rw.parseCommit(cmd.getNewId());
                Branch.NameKey branch = new Branch.NameKey(project.getNameKey(), refName);
                rw.reset();
                rw.markStart(newTip);
                if (!ObjectId.zeroId().equals(cmd.getOldId())) {
                    rw.markUninteresting(rw.parseCommit(cmd.getOldId()));
                }
                ListMultimap<ObjectId, Ref> byCommit = changeRefsById();
                Map<Change.Key, ChangeNotes> byKey = null;
                List<ReplaceRequest> replaceAndClose = new ArrayList<>();
                int existingPatchSets = 0;
                int newPatchSets = 0;
                COMMIT: for (RevCommit c; (c = rw.next()) != null; ) {
                    rw.parseBody(c);
                    for (Ref ref : byCommit.get(c.copy())) {
                        PatchSet.Id psId = PatchSet.Id.fromRef(ref.getName());
                        Optional<ChangeData> cd = byLegacyId(psId.getParentKey());
                        if (cd.isPresent() && cd.get().change().getDest().equals(branch)) {
                            existingPatchSets++;
                            bu.addOp(psId.getParentKey(), mergedByPushOpFactory.create(requestScopePropagator, psId, refName));
                            continue COMMIT;
                        }
                    }
                    for (String changeId : c.getFooterLines(CHANGE_ID)) {
                        if (byKey == null) {
                            byKey = openChangesByKeyByBranch(branch);
                        }
                        ChangeNotes onto = byKey.get(new Change.Key(changeId.trim()));
                        if (onto != null) {
                            newPatchSets++;
                            // Hold onto this until we're done with the walk, as the call to
                            // req.validate below calls isMergedInto which resets the walk.
                            ReplaceRequest req = new ReplaceRequest(onto.getChangeId(), c, cmd, false);
                            req.notes = onto;
                            replaceAndClose.add(req);
                            continue COMMIT;
                        }
                    }
                }
                for (ReplaceRequest req : replaceAndClose) {
                    Change.Id id = req.notes.getChangeId();
                    if (!req.validate(true)) {
                        logDebug("Not closing {} because validation failed", id);
                        continue;
                    }
                    req.addOps(bu, null);
                    bu.addOp(id, mergedByPushOpFactory.create(requestScopePropagator, req.psId, refName).setPatchSetProvider(new Provider<PatchSet>() {

                        @Override
                        public PatchSet get() {
                            return req.replaceOp.getPatchSet();
                        }
                    }));
                    bu.addOp(id, new ChangeProgressOp(closeProgress));
                }
                logDebug("Auto-closing {} changes with existing patch sets and {} with new patch sets", existingPatchSets, newPatchSets);
                bu.execute();
            } catch (IOException | OrmException | PermissionBackendException e) {
                logError("Failed to auto-close changes", e);
            }
            return null;
        });
    } catch (RestApiException e) {
        logError("Can't insert patchset", e);
    } catch (UpdateException e) {
        logError("Failed to auto-close changes", e);
    }
}
#method_after
private void autoCloseChanges(ReceiveCommand cmd) {
    logDebug("Starting auto-closing of changes");
    String refName = cmd.getRefName();
    checkState(!MagicBranch.isMagicBranch(refName), "shouldn't be auto-closing changes on magic branch %s", refName);
    // insertChangesAndPatchSets.
    try {
        retryHelper.execute(updateFactory -> {
            try (BatchUpdate bu = updateFactory.create(db, projectState.getNameKey(), user, TimeUtil.nowTs());
                ObjectInserter ins = repo.newObjectInserter();
                ObjectReader reader = ins.newReader();
                RevWalk rw = new RevWalk(reader)) {
                bu.setRepository(repo, rw, ins).updateChangesInParallel();
                bu.setRequestId(receiveId);
                // TODO(dborowitz): Teach BatchUpdate to ignore missing changes.
                RevCommit newTip = rw.parseCommit(cmd.getNewId());
                Branch.NameKey branch = new Branch.NameKey(project.getNameKey(), refName);
                rw.reset();
                rw.markStart(newTip);
                if (!ObjectId.zeroId().equals(cmd.getOldId())) {
                    rw.markUninteresting(rw.parseCommit(cmd.getOldId()));
                }
                ListMultimap<ObjectId, Ref> byCommit = changeRefsById();
                Map<Change.Key, ChangeNotes> byKey = null;
                List<ReplaceRequest> replaceAndClose = new ArrayList<>();
                int existingPatchSets = 0;
                int newPatchSets = 0;
                COMMIT: for (RevCommit c; (c = rw.next()) != null; ) {
                    rw.parseBody(c);
                    for (Ref ref : byCommit.get(c.copy())) {
                        PatchSet.Id psId = PatchSet.Id.fromRef(ref.getName());
                        Optional<ChangeData> cd = retryHelper.execute(ActionType.CHANGE_QUERY, () -> byLegacyId(psId.getParentKey()), t -> t instanceof OrmException);
                        if (cd.isPresent() && cd.get().change().getDest().equals(branch)) {
                            existingPatchSets++;
                            bu.addOp(psId.getParentKey(), mergedByPushOpFactory.create(requestScopePropagator, psId, refName));
                            continue COMMIT;
                        }
                    }
                    for (String changeId : c.getFooterLines(CHANGE_ID)) {
                        if (byKey == null) {
                            byKey = retryHelper.execute(ActionType.CHANGE_QUERY, () -> openChangesByKeyByBranch(branch), t -> t instanceof OrmException);
                        }
                        ChangeNotes onto = byKey.get(new Change.Key(changeId.trim()));
                        if (onto != null) {
                            newPatchSets++;
                            // Hold onto this until we're done with the walk, as the call to
                            // req.validate below calls isMergedInto which resets the walk.
                            ReplaceRequest req = new ReplaceRequest(onto.getChangeId(), c, cmd, false);
                            req.notes = onto;
                            replaceAndClose.add(req);
                            continue COMMIT;
                        }
                    }
                }
                for (ReplaceRequest req : replaceAndClose) {
                    Change.Id id = req.notes.getChangeId();
                    if (!req.validate(true)) {
                        logDebug("Not closing {} because validation failed", id);
                        continue;
                    }
                    req.addOps(bu, null);
                    bu.addOp(id, mergedByPushOpFactory.create(requestScopePropagator, req.psId, refName).setPatchSetProvider(new Provider<PatchSet>() {

                        @Override
                        public PatchSet get() {
                            return req.replaceOp.getPatchSet();
                        }
                    }));
                    bu.addOp(id, new ChangeProgressOp(closeProgress));
                }
                logDebug("Auto-closing {} changes with existing patch sets and {} with new patch sets", existingPatchSets, newPatchSets);
                bu.execute();
            } catch (IOException | OrmException | PermissionBackendException e) {
                logError("Failed to auto-close changes", e);
            }
            return null;
        }, // eat up the whole timeout so that no time is left to retry this outer action.
        RetryHelper.options().timeout(retryHelper.getDefaultTimeout().multipliedBy(5)).build());
    } catch (RestApiException e) {
        logError("Can't insert patchset", e);
    } catch (UpdateException e) {
        logError("Failed to auto-close changes", e);
    }
}
#end_block

#method_before
public CommitValidators forReceiveCommits(PermissionBackend.ForRef perm, Branch.NameKey branch, IdentifiedUser user, SshInfo sshInfo, Repository repo, RevWalk rw, @Nullable Change change) throws IOException {
    NoteMap rejectCommits = BanCommit.loadRejectCommitsMap(repo, rw);
    ProjectState projectState = projectCache.checkedGet(branch.getParentKey());
    return new CommitValidators(ImmutableList.of(new UploadMergesPermissionValidator(perm), new AmendedGerritMergeCommitValidationListener(perm, gerritIdent), new AuthorUploaderValidator(user, perm, canonicalWebUrl), new CommitterUploaderValidator(user, perm, canonicalWebUrl), new SignedOffByValidator(user, perm, projectState), new ChangeIdValidator(projectState, user, canonicalWebUrl, installCommitMsgHookCommand, sshInfo, change), new ConfigValidator(branch, user, rw, allUsers, allProjects), new BannedCommitsValidator(rejectCommits), new PluginCommitValidationListener(pluginValidators), new ExternalIdUpdateListener(allUsers, externalIdsConsistencyChecker), new AccountCommitValidator(allUsers, accountValidator), new GroupCommitValidator(allUsers)));
}
#method_after
public CommitValidators forReceiveCommits(PermissionBackend.ForRef perm, Branch.NameKey branch, IdentifiedUser user, SshInfo sshInfo, Repository repo, RevWalk rw, @Nullable Change change) throws IOException {
    NoteMap rejectCommits = BanCommit.loadRejectCommitsMap(repo, rw);
    ProjectState projectState = projectCache.checkedGet(branch.getParentKey());
    return new CommitValidators(ImmutableList.of(new UploadMergesPermissionValidator(perm), new ProjectStateValidationListener(projectState), new AmendedGerritMergeCommitValidationListener(perm, gerritIdent), new AuthorUploaderValidator(user, perm, canonicalWebUrl), new CommitterUploaderValidator(user, perm, canonicalWebUrl), new SignedOffByValidator(user, perm, projectState), new ChangeIdValidator(projectState, user, canonicalWebUrl, installCommitMsgHookCommand, sshInfo, change), new ConfigValidator(branch, user, rw, allUsers, allProjects), new BannedCommitsValidator(rejectCommits), new PluginCommitValidationListener(pluginValidators), new ExternalIdUpdateListener(allUsers, externalIdsConsistencyChecker), new AccountCommitValidator(repoManager, allUsers, accountValidator), new GroupCommitValidator(allUsers)));
}
#end_block

#method_before
public CommitValidators forGerritCommits(ForRef perm, NameKey branch, IdentifiedUser user, SshInfo sshInfo, RevWalk rw, @Nullable Change change) throws IOException {
    return new CommitValidators(ImmutableList.of(new UploadMergesPermissionValidator(perm), new AmendedGerritMergeCommitValidationListener(perm, gerritIdent), new AuthorUploaderValidator(user, perm, canonicalWebUrl), new SignedOffByValidator(user, perm, projectCache.checkedGet(branch.getParentKey())), new ChangeIdValidator(projectCache.checkedGet(branch.getParentKey()), user, canonicalWebUrl, installCommitMsgHookCommand, sshInfo, change), new ConfigValidator(branch, user, rw, allUsers, allProjects), new PluginCommitValidationListener(pluginValidators), new ExternalIdUpdateListener(allUsers, externalIdsConsistencyChecker), new AccountCommitValidator(allUsers, accountValidator), new GroupCommitValidator(allUsers)));
}
#method_after
public CommitValidators forGerritCommits(ForRef perm, NameKey branch, IdentifiedUser user, SshInfo sshInfo, RevWalk rw, @Nullable Change change) throws IOException {
    ProjectState projectState = projectCache.checkedGet(branch.getParentKey());
    return new CommitValidators(ImmutableList.of(new UploadMergesPermissionValidator(perm), new ProjectStateValidationListener(projectState), new AmendedGerritMergeCommitValidationListener(perm, gerritIdent), new AuthorUploaderValidator(user, perm, canonicalWebUrl), new SignedOffByValidator(user, perm, projectCache.checkedGet(branch.getParentKey())), new ChangeIdValidator(projectState, user, canonicalWebUrl, installCommitMsgHookCommand, sshInfo, change), new ConfigValidator(branch, user, rw, allUsers, allProjects), new PluginCommitValidationListener(pluginValidators), new ExternalIdUpdateListener(allUsers, externalIdsConsistencyChecker), new AccountCommitValidator(repoManager, allUsers, accountValidator), new GroupCommitValidator(allUsers)));
}
#end_block

#method_before
public CommitValidators forMergedCommits(PermissionBackend.ForRef perm, IdentifiedUser user) {
    // formats, so we play it safe and exclude them.
    return new CommitValidators(ImmutableList.of(new UploadMergesPermissionValidator(perm), new AuthorUploaderValidator(user, perm, canonicalWebUrl), new CommitterUploaderValidator(user, perm, canonicalWebUrl)));
}
#method_after
public CommitValidators forMergedCommits(Project.NameKey project, PermissionBackend.ForRef perm, IdentifiedUser user) throws IOException {
    // formats, so we play it safe and exclude them.
    return new CommitValidators(ImmutableList.of(new UploadMergesPermissionValidator(perm), new ProjectStateValidationListener(projectCache.checkedGet(project)), new AuthorUploaderValidator(user, perm, canonicalWebUrl), new CommitterUploaderValidator(user, perm, canonicalWebUrl)));
}
#end_block

#method_before
@Override
public List<CommitValidationMessage> onCommitReceived(CommitReceivedEvent receiveEvent) throws CommitValidationException {
    if (!shouldValidateChangeId(receiveEvent)) {
        return Collections.emptyList();
    }
    RevCommit commit = receiveEvent.commit;
    List<CommitValidationMessage> messages = new ArrayList<>();
    List<String> idList = commit.getFooterLines(FooterConstants.CHANGE_ID);
    String sha1 = commit.abbreviate(RevId.ABBREV_LEN).name();
    if (idList.isEmpty()) {
        if (projectState.is(BooleanProjectConfig.REQUIRE_CHANGE_ID)) {
            String shortMsg = commit.getShortMessage();
            if (shortMsg.startsWith(CHANGE_ID_PREFIX) && CHANGE_ID.matcher(shortMsg.substring(CHANGE_ID_PREFIX.length()).trim()).matches()) {
                String errMsg = String.format(MISSING_SUBJECT_MSG, sha1);
                throw new CommitValidationException(errMsg);
            }
            String errMsg = String.format(MISSING_CHANGE_ID_MSG, sha1);
            messages.add(getMissingChangeIdErrorMsg(errMsg, commit));
            throw new CommitValidationException(errMsg, messages);
        }
    } else if (idList.size() > 1) {
        String errMsg = String.format(MULTIPLE_CHANGE_ID_MSG, sha1);
        throw new CommitValidationException(errMsg, messages);
    } else {
        String v = idList.get(idList.size() - 1).trim();
        // Egit (I0000000000000000000000000000000000000000).
        if (!CHANGE_ID.matcher(v).matches() || v.matches("^I00*$")) {
            String errMsg = String.format(INVALID_CHANGE_ID_MSG, sha1);
            messages.add(getMissingChangeIdErrorMsg(errMsg, receiveEvent.commit));
            throw new CommitValidationException(errMsg, messages);
        }
    }
    if (change != null && !idList.get(0).equals(change.getKey().get())) {
        String errMsg = String.format(CHANGE_ID_MIS_MATCH_MSG, sha1);
        throw new CommitValidationException(errMsg);
    }
    return Collections.emptyList();
}
#method_after
@Override
public List<CommitValidationMessage> onCommitReceived(CommitReceivedEvent receiveEvent) throws CommitValidationException {
    if (!shouldValidateChangeId(receiveEvent)) {
        return Collections.emptyList();
    }
    RevCommit commit = receiveEvent.commit;
    List<CommitValidationMessage> messages = new ArrayList<>();
    List<String> idList = commit.getFooterLines(FooterConstants.CHANGE_ID);
    String sha1 = commit.abbreviate(RevId.ABBREV_LEN).name();
    if (idList.isEmpty()) {
        if (projectState.is(BooleanProjectConfig.REQUIRE_CHANGE_ID)) {
            String shortMsg = commit.getShortMessage();
            if (shortMsg.startsWith(CHANGE_ID_PREFIX) && CHANGE_ID.matcher(shortMsg.substring(CHANGE_ID_PREFIX.length()).trim()).matches()) {
                String errMsg = String.format(MISSING_SUBJECT_MSG, sha1);
                throw new CommitValidationException(errMsg);
            }
            String errMsg = String.format(MISSING_CHANGE_ID_MSG, sha1);
            messages.add(getMissingChangeIdErrorMsg(errMsg, commit));
            throw new CommitValidationException(errMsg, messages);
        }
    } else if (idList.size() > 1) {
        String errMsg = String.format(MULTIPLE_CHANGE_ID_MSG, sha1);
        throw new CommitValidationException(errMsg, messages);
    } else {
        String v = idList.get(idList.size() - 1).trim();
        // Egit (I0000000000000000000000000000000000000000).
        if (!CHANGE_ID.matcher(v).matches() || v.matches("^I00*$")) {
            String errMsg = String.format(INVALID_CHANGE_ID_MSG, sha1);
            messages.add(getMissingChangeIdErrorMsg(errMsg, receiveEvent.commit));
            throw new CommitValidationException(errMsg, messages);
        }
        if (change != null && !v.equals(change.getKey().get())) {
            String errMsg = String.format(CHANGE_ID_MISMATCH_MSG, sha1);
            throw new CommitValidationException(errMsg);
        }
    }
    return Collections.emptyList();
}
#end_block

#method_before
@Override
public List<CommitValidationMessage> onCommitReceived(CommitReceivedEvent receiveEvent) throws CommitValidationException {
    if (REFS_CONFIG.equals(branch.get())) {
        List<CommitValidationMessage> messages = new ArrayList<>();
        try {
            ProjectConfig cfg = new ProjectConfig(receiveEvent.project.getNameKey());
            cfg.load(rw, receiveEvent.command.getNewId());
            if (!cfg.getValidationErrors().isEmpty()) {
                addError("Invalid project configuration:", messages);
                for (ValidationError err : cfg.getValidationErrors()) {
                    addError("  " + err.getMessage(), messages);
                }
                throw new ConfigInvalidException("invalid project configuration");
            }
            if (allUsers.equals(receiveEvent.project.getNameKey()) && !allProjects.equals(cfg.getProject().getParent(allProjects))) {
                addError("Invalid project configuration:", messages);
                addError(String.format("  %s must inherit from %s", allUsers.get(), allProjects.get()), messages);
                throw new ConfigInvalidException("invalid project configuration");
            }
        } catch (ConfigInvalidException | IOException e) {
            log.error("User " + user.getUserName() + " tried to push an invalid project configuration " + receiveEvent.command.getNewId().name() + " for project " + receiveEvent.project, e);
            throw new CommitValidationException("invalid project configuration", messages);
        }
    }
    if (allUsers.equals(branch.getParentKey()) && RefNames.isRefsUsers(branch.get())) {
        List<CommitValidationMessage> messages = new ArrayList<>();
        Account.Id accountId = Account.Id.fromRef(branch.get());
        if (accountId != null) {
            try {
                WatchConfig wc = new WatchConfig(accountId);
                wc.load(rw, receiveEvent.command.getNewId());
                if (!wc.getValidationErrors().isEmpty()) {
                    addError("Invalid project configuration:", messages);
                    for (ValidationError err : wc.getValidationErrors()) {
                        addError("  " + err.getMessage(), messages);
                    }
                    throw new ConfigInvalidException("invalid watch configuration");
                }
            } catch (IOException | ConfigInvalidException e) {
                log.error("User " + user.getUserName() + " tried to push an invalid watch configuration " + receiveEvent.command.getNewId().name() + " for account " + accountId.get(), e);
                throw new CommitValidationException("invalid watch configuration", messages);
            }
        }
    }
    return Collections.emptyList();
}
#method_after
@Override
public List<CommitValidationMessage> onCommitReceived(CommitReceivedEvent receiveEvent) throws CommitValidationException {
    if (REFS_CONFIG.equals(branch.get())) {
        List<CommitValidationMessage> messages = new ArrayList<>();
        try {
            ProjectConfig cfg = new ProjectConfig(receiveEvent.project.getNameKey());
            cfg.load(rw, receiveEvent.command.getNewId());
            if (!cfg.getValidationErrors().isEmpty()) {
                addError("Invalid project configuration:", messages);
                for (ValidationError err : cfg.getValidationErrors()) {
                    addError("  " + err.getMessage(), messages);
                }
                throw new ConfigInvalidException("invalid project configuration");
            }
            if (allUsers.equals(receiveEvent.project.getNameKey()) && !allProjects.equals(cfg.getProject().getParent(allProjects))) {
                addError("Invalid project configuration:", messages);
                addError(String.format("  %s must inherit from %s", allUsers.get(), allProjects.get()), messages);
                throw new ConfigInvalidException("invalid project configuration");
            }
        } catch (ConfigInvalidException | IOException e) {
            log.error("User " + user.getUserName() + " tried to push an invalid project configuration " + receiveEvent.command.getNewId().name() + " for project " + receiveEvent.project, e);
            throw new CommitValidationException("invalid project configuration", messages);
        }
    }
    return Collections.emptyList();
}
#end_block

#method_before
@Override
public List<CommitValidationMessage> onCommitReceived(CommitReceivedEvent receiveEvent) throws CommitValidationException {
    if (!allUsers.equals(receiveEvent.project.getNameKey())) {
        return Collections.emptyList();
    }
    if (receiveEvent.command.getRefName().startsWith(MagicBranch.NEW_CHANGE)) {
        // MergeValidators.AccountMergeValidator
        return Collections.emptyList();
    }
    Account.Id accountId = Account.Id.fromRef(receiveEvent.refName);
    if (accountId == null) {
        return Collections.emptyList();
    }
    try {
        List<String> errorMessages = accountValidator.validate(accountId, receiveEvent.revWalk, receiveEvent.command.getOldId(), receiveEvent.commit);
        if (!errorMessages.isEmpty()) {
            throw new CommitValidationException("invalid account configuration", errorMessages.stream().map(m -> new CommitValidationMessage(m, true)).collect(toList()));
        }
    } catch (IOException e) {
        String m = String.format("Validating update for account %s failed", accountId.get());
        log.error(m, e);
        throw new CommitValidationException(m, e);
    }
    return Collections.emptyList();
}
#method_after
@Override
public List<CommitValidationMessage> onCommitReceived(CommitReceivedEvent receiveEvent) throws CommitValidationException {
    if (!allUsers.equals(receiveEvent.project.getNameKey())) {
        return Collections.emptyList();
    }
    if (receiveEvent.command.getRefName().startsWith(MagicBranch.NEW_CHANGE)) {
        // MergeValidators.AccountMergeValidator
        return Collections.emptyList();
    }
    Account.Id accountId = Account.Id.fromRef(receiveEvent.refName);
    if (accountId == null) {
        return Collections.emptyList();
    }
    try (Repository repo = repoManager.openRepository(allUsers)) {
        List<String> errorMessages = accountValidator.validate(accountId, repo, receiveEvent.revWalk, receiveEvent.command.getOldId(), receiveEvent.commit);
        if (!errorMessages.isEmpty()) {
            throw new CommitValidationException("invalid account configuration", errorMessages.stream().map(m -> new CommitValidationMessage(m, true)).collect(toList()));
        }
    } catch (IOException e) {
        String m = String.format("Validating update for account %s failed", accountId.get());
        log.error(m, e);
        throw new CommitValidationException(m, e);
    }
    return Collections.emptyList();
}
#end_block

#method_before
@Override
public Output apply(RevisionResource rsrc, SubmitInput input) throws RestApiException, RepositoryNotFoundException, IOException, OrmException, PermissionBackendException, UpdateException, ConfigInvalidException {
    input.onBehalfOf = Strings.emptyToNull(input.onBehalfOf);
    IdentifiedUser submitter;
    if (input.onBehalfOf != null) {
        submitter = onBehalfOf(rsrc, input);
    } else {
        rsrc.permissions().check(ChangePermission.SUBMIT);
        submitter = rsrc.getUser().asIdentifiedUser();
    }
    projectCache.checkedGet(rsrc.getProject()).statePermitsWrite();
    return new Output(mergeChange(rsrc, submitter, input));
}
#method_after
@Override
public Output apply(RevisionResource rsrc, SubmitInput input) throws RestApiException, RepositoryNotFoundException, IOException, OrmException, PermissionBackendException, UpdateException, ConfigInvalidException {
    input.onBehalfOf = Strings.emptyToNull(input.onBehalfOf);
    IdentifiedUser submitter;
    if (input.onBehalfOf != null) {
        submitter = onBehalfOf(rsrc, input);
    } else {
        rsrc.permissions().check(ChangePermission.SUBMIT);
        submitter = rsrc.getUser().asIdentifiedUser();
    }
    projectCache.checkedGet(rsrc.getProject()).checkStatePermitsWrite();
    return new Output(mergeChange(rsrc, submitter, input));
}
#end_block

#method_before
@Override
protected void doPost(HttpServletRequest req, HttpServletResponse rsp) {
    this.healthy = true;
}
#method_after
@Override
protected void doPost(HttpServletRequest req, HttpServletResponse rsp) {
    this.healthy = true;
    rsp.setStatus(SC_NO_CONTENT);
}
#end_block

#method_before
@Override
protected void doDelete(HttpServletRequest req, HttpServletResponse rsp) {
    this.healthy = false;
}
#method_after
@Override
protected void doDelete(HttpServletRequest req, HttpServletResponse rsp) {
    this.healthy = false;
    rsp.setStatus(SC_NO_CONTENT);
}
#end_block

#method_before
@Override
protected void doGet(HttpServletRequest req, HttpServletResponse rsp) {
    if (healthy) {
        rsp.setStatus(SC_OK);
    } else {
        try {
            rsp.sendError(SC_INTERNAL_SERVER_ERROR);
        } catch (IOException e) {
            LOG.error("Failed to send error response", e);
        }
    }
}
#method_after
@Override
protected void doGet(HttpServletRequest req, HttpServletResponse rsp) {
    if (healthy) {
        rsp.setStatus(SC_NO_CONTENT);
    } else {
        try {
            rsp.sendError(SC_SERVICE_UNAVAILABLE);
        } catch (IOException e) {
            log.error("Failed to send error response", e);
        }
    }
}
#end_block

#method_before
public Collection<NotifyConfig> getNotifyConfigs() {
    return notify.values();
}
#method_after
public Collection<NotifyConfig> getNotifyConfigs() {
    return notifySections.values();
}
#end_block

#method_before
private void loadNotifySections(Config rc, Map<String, GroupReference> groupsByName) {
    notify = Maps.newHashMap();
    for (String sectionName : rc.getSubsections(NOTIFY)) {
        NotifyConfig n = new NotifyConfig();
        n.setFilter(rc.getString(NOTIFY, sectionName, KEY_FILTER));
        EnumSet<NotifyType> types = EnumSet.noneOf(NotifyType.class);
        types.addAll(ConfigUtil.getEnumList(rc, NOTIFY, sectionName, KEY_TYPE, NotifyType.ALL));
        n.setTypes(types);
        for (String dst : rc.getStringList(NOTIFY, sectionName, KEY_EMAIL)) {
            if (dst.startsWith("group ")) {
                String groupName = dst.substring(6).trim();
                GroupReference ref = groupsByName.get(groupName);
                if (ref == null) {
                    ref = new GroupReference(null, groupName);
                    groupsByName.put(ref.getName(), ref);
                }
                if (ref.getUUID() != null) {
                    n.addEmail(ref.getUUID());
                } else {
                    error(new ValidationError(PROJECT_CONFIG, "group \"" + ref.getName() + "\" not in " + GROUP_LIST));
                }
            } else if (dst.startsWith("user ")) {
                error(new ValidationError(PROJECT_CONFIG, dst + " not supported"));
            } else {
                try {
                    n.addEmail(Address.parse(dst));
                } catch (IllegalArgumentException err) {
                    error(new ValidationError(PROJECT_CONFIG, "notify section \"" + sectionName + "\" has invalid email \"" + dst + "\""));
                }
            }
        }
        notify.put(sectionName, n);
    }
}
#method_after
private void loadNotifySections(Config rc, Map<String, GroupReference> groupsByName) {
    notifySections = Maps.newHashMap();
    for (String sectionName : rc.getSubsections(NOTIFY)) {
        NotifyConfig n = new NotifyConfig();
        n.setName(sectionName);
        n.setFilter(rc.getString(NOTIFY, sectionName, KEY_FILTER));
        EnumSet<NotifyType> types = EnumSet.noneOf(NotifyType.class);
        types.addAll(ConfigUtil.getEnumList(rc, NOTIFY, sectionName, KEY_TYPE, NotifyType.ALL));
        n.setTypes(types);
        for (String dst : rc.getStringList(NOTIFY, sectionName, KEY_EMAIL)) {
            if (dst.startsWith("group ")) {
                String groupName = dst.substring(6).trim();
                GroupReference ref = groupsByName.get(groupName);
                if (ref == null) {
                    ref = new GroupReference(null, groupName);
                    groupsByName.put(ref.getName(), ref);
                }
                if (ref.getUUID() != null) {
                    n.addEmail(ref);
                } else {
                    error(new ValidationError(PROJECT_CONFIG, "group \"" + ref.getName() + "\" not in " + GROUP_LIST));
                }
            } else if (dst.startsWith("user ")) {
                error(new ValidationError(PROJECT_CONFIG, dst + " not supported"));
            } else {
                try {
                    n.addEmail(Address.parse(dst));
                } catch (IllegalArgumentException err) {
                    error(new ValidationError(PROJECT_CONFIG, "notify section \"" + sectionName + "\" has invalid email \"" + dst + "\""));
                }
            }
        }
        notifySections.put(sectionName, n);
    }
}
#end_block

#method_before
@Override
protected void onSave(CommitBuilder commit) throws IOException, ConfigInvalidException {
    if (commit.getMessage() == null || "".equals(commit.getMessage())) {
        commit.setMessage("Updated project configuration\n");
    }
    Config rc = readConfig(PROJECT_CONFIG);
    Project p = project;
    if (p.getDescription() != null && !p.getDescription().isEmpty()) {
        rc.setString(PROJECT, null, KEY_DESCRIPTION, p.getDescription());
    } else {
        rc.unset(PROJECT, null, KEY_DESCRIPTION);
    }
    set(rc, ACCESS, null, KEY_INHERIT_FROM, p.getParentName());
    set(rc, RECEIVE, null, KEY_REQUIRE_CONTRIBUTOR_AGREEMENT, p.isUseContributorAgreements());
    set(rc, RECEIVE, null, KEY_REQUIRE_SIGNED_OFF_BY, p.isUseSignedOffBy());
    set(rc, RECEIVE, null, KEY_REQUIRE_CHANGE_ID, p.isRequireChangeID());
    set(rc, SUBMIT, null, KEY_ACTION, p.getSubmitType(), defaultSubmitAction);
    set(rc, SUBMIT, null, KEY_MERGE_CONTENT, p.isUseContentMerge());
    set(rc, PROJECT, null, KEY_STATE, p.getState(), null);
    Set<AccountGroup.UUID> keepGroups = new HashSet<AccountGroup.UUID>();
    saveAccountsSection(rc, keepGroups);
    saveContributorAgreements(rc, keepGroups);
    saveAccessSections(rc, keepGroups);
    for (NotifyConfig n : notify.values()) {
        keepGroups.addAll(n.getGroups());
    }
    groupsByUUID.keySet().retainAll(keepGroups);
    saveConfig(PROJECT_CONFIG, rc);
    saveGroupList();
}
#method_after
@Override
protected void onSave(CommitBuilder commit) throws IOException, ConfigInvalidException {
    if (commit.getMessage() == null || "".equals(commit.getMessage())) {
        commit.setMessage("Updated project configuration\n");
    }
    Config rc = readConfig(PROJECT_CONFIG);
    Project p = project;
    if (p.getDescription() != null && !p.getDescription().isEmpty()) {
        rc.setString(PROJECT, null, KEY_DESCRIPTION, p.getDescription());
    } else {
        rc.unset(PROJECT, null, KEY_DESCRIPTION);
    }
    set(rc, ACCESS, null, KEY_INHERIT_FROM, p.getParentName());
    set(rc, RECEIVE, null, KEY_REQUIRE_CONTRIBUTOR_AGREEMENT, p.isUseContributorAgreements());
    set(rc, RECEIVE, null, KEY_REQUIRE_SIGNED_OFF_BY, p.isUseSignedOffBy());
    set(rc, RECEIVE, null, KEY_REQUIRE_CHANGE_ID, p.isRequireChangeID());
    set(rc, SUBMIT, null, KEY_ACTION, p.getSubmitType(), defaultSubmitAction);
    set(rc, SUBMIT, null, KEY_MERGE_CONTENT, p.isUseContentMerge());
    set(rc, PROJECT, null, KEY_STATE, p.getState(), null);
    Set<AccountGroup.UUID> keepGroups = new HashSet<AccountGroup.UUID>();
    saveAccountsSection(rc, keepGroups);
    saveContributorAgreements(rc, keepGroups);
    saveAccessSections(rc, keepGroups);
    saveNotifySections(rc, keepGroups);
    groupsByUUID.keySet().retainAll(keepGroups);
    saveConfig(PROJECT_CONFIG, rc);
    saveGroupList();
}
#end_block

#method_before
public String getChangeDetail() {
    StringBuilder detail = new StringBuilder();
    if (patchSetInfo != null) {
        detail.append(patchSetInfo.getMessage().trim() + "\n");
    } else {
        detail.append(change.getSubject().trim() + "\n");
    }
    if (patchSet != null) {
        detail.append("---\n");
        PatchList patchList = getPatchList();
        for (PatchListEntry p : patchList.getPatches()) {
            if (Patch.COMMIT_MSG.equals(p.getNewName())) {
                continue;
            }
            detail.append(p.getChangeType().getCode() + " " + p.getNewName() + "\n");
        }
        detail.append(MessageFormat.format(// 
        "" + // 
        "{0,choice,0#0 files|1#1 file|1<{0} files} changed, " + // 
        "{1,choice,0#0 insertions|1#1 insertion|1<{1} insertions}(+), " + // 
        "{2,choice,0#0 deletions|1#1 deletion|1<{2} deletions}(-)" + // 
        "\n", // 
        patchList.getPatches().size() - 1, // 
        patchList.getInsertions(), patchList.getDeletions()));
        detail.append("\n");
    }
    return detail.toString();
}
#method_after
public String getChangeDetail() {
    try {
        StringBuilder detail = new StringBuilder();
        if (patchSetInfo != null) {
            detail.append(patchSetInfo.getMessage().trim() + "\n");
        } else {
            detail.append(change.getSubject().trim() + "\n");
        }
        if (patchSet != null) {
            detail.append("---\n");
            PatchList patchList = getPatchList();
            for (PatchListEntry p : patchList.getPatches()) {
                if (Patch.COMMIT_MSG.equals(p.getNewName())) {
                    continue;
                }
                detail.append(p.getChangeType().getCode() + " " + p.getNewName() + "\n");
            }
            detail.append(MessageFormat.format(// 
            "" + // 
            "{0,choice,0#0 files|1#1 file|1<{0} files} changed, " + // 
            "{1,choice,0#0 insertions|1#1 insertion|1<{1} insertions}(+), " + // 
            "{2,choice,0#0 deletions|1#1 deletion|1<{2} deletions}(-)" + // 
            "\n", // 
            patchList.getPatches().size() - 1, // 
            patchList.getInsertions(), patchList.getDeletions()));
            detail.append("\n");
        }
        return detail.toString();
    } catch (Exception err) {
        log.warn("Cannot format change detail", err);
        return "";
    }
}
#end_block

#method_before
protected void bccStarredBy() {
    try {
        // 
        for (StarredChange w : args.db.get().starredChanges().byChange(change.getId())) {
            super.add(RecipientType.BCC, w.getAccountId());
        }
    } catch (OrmException err) {
    // Just don't BCC everyone. Better to send a partial message to those
    // we already have queued up then to fail deliver entirely to people
    // who have a lower interest in the change.
    }
}
#method_after
protected void bccStarredBy() {
    try {
        // 
        for (StarredChange w : args.db.get().starredChanges().byChange(change.getId())) {
            super.add(RecipientType.BCC, w.getAccountId());
        }
    } catch (OrmException err) {
        // Just don't BCC everyone. Better to send a partial message to those
        // we already have queued up then to fail deliver entirely to people
        // who have a lower interest in the change.
        log.warn("Cannot BCC users that starred updated change", err);
    }
}
#end_block

#method_before
protected void bccWatches(NotifyType type) {
    try {
        Watchers matching = getWatches(NotifyType.SUBMITTED_CHANGES);
        for (Account.Id user : matching.accounts) {
            add(RecipientType.BCC, user);
        }
        for (Address addr : matching.emails) {
            add(RecipientType.BCC, addr);
        }
    } catch (OrmException err) {
    // Just don't CC everyone. Better to send a partial message to those
    // we already have queued up then to fail deliver entirely to people
    // who have a lower interest in the change.
    }
}
#method_after
protected void bccWatches(NotifyType type) {
    try {
        Watchers matching = getWatches(type);
        for (Account.Id user : matching.accounts) {
            add(RecipientType.BCC, user);
        }
        for (Address addr : matching.emails) {
            add(RecipientType.BCC, addr);
        }
    } catch (OrmException err) {
        // Just don't CC everyone. Better to send a partial message to those
        // we already have queued up then to fail deliver entirely to people
        // who have a lower interest in the change.
        log.warn("Cannot BCC watchers for " + type, err);
    }
}
#end_block

#method_before
protected final Watchers getWatches(NotifyType type) throws OrmException {
    Watchers matching = new Watchers();
    if (changeData == null) {
        return matching;
    }
    Set<Account.Id> projectWatchers = new HashSet<Account.Id>();
    for (AccountProjectWatch w : args.db.get().accountProjectWatches().byProject(change.getProject())) {
        projectWatchers.add(w.getAccountId());
        if (w.isNotify(type)) {
            add(matching, w);
        }
    }
    for (AccountProjectWatch w : args.db.get().accountProjectWatches().byProject(args.allProjectsName)) {
        if (!projectWatchers.contains(w.getAccountId()) && w.isNotify(type)) {
            add(matching, w);
        }
    }
    ProjectState state = projectState;
    while (state != null) {
        for (NotifyConfig nc : state.getConfig().getNotifyConfigs()) {
            if (nc.isNotify(type)) {
                try {
                    add(matching, nc, state.getProject().getNameKey());
                } catch (QueryParseException e) {
                    log.warn(String.format("Project %s has invalid notify filter \"%s\": %s", state.getProject().getName(), nc.getFilter(), e.getMessage()));
                }
            }
        }
        state = state.getParentState();
    }
    return matching;
}
#method_after
protected final Watchers getWatches(NotifyType type) throws OrmException {
    Watchers matching = new Watchers();
    if (changeData == null) {
        return matching;
    }
    Set<Account.Id> projectWatchers = new HashSet<Account.Id>();
    for (AccountProjectWatch w : args.db.get().accountProjectWatches().byProject(change.getProject())) {
        projectWatchers.add(w.getAccountId());
        if (w.isNotify(type)) {
            add(matching, w);
        }
    }
    for (AccountProjectWatch w : args.db.get().accountProjectWatches().byProject(args.allProjectsName)) {
        if (!projectWatchers.contains(w.getAccountId()) && w.isNotify(type)) {
            add(matching, w);
        }
    }
    ProjectState state = projectState;
    while (state != null) {
        for (NotifyConfig nc : state.getConfig().getNotifyConfigs()) {
            if (nc.isNotify(type)) {
                try {
                    add(matching, nc, state.getProject().getNameKey());
                } catch (QueryParseException e) {
                    log.warn(String.format("Project %s has invalid notify %s filter \"%s\": %s", state.getProject().getName(), nc.getName(), nc.getFilter(), e.getMessage()));
                }
            }
        }
        state = state.getParentState();
    }
    return matching;
}
#end_block

#method_before
@SuppressWarnings("unchecked")
private void add(Watchers matching, NotifyConfig nc, Project.NameKey project) throws OrmException, QueryParseException {
    for (AccountGroup.UUID uuid : nc.getGroups()) {
        AccountGroup group = args.groupCache.get(uuid);
        if (group == null) {
            log.warn(String.format("Project %s has invalid group %s in notify section", project.get(), uuid.get()));
            continue;
        }
        if (group.getType() != AccountGroup.Type.INTERNAL) {
            log.warn(String.format("Project %s canont use group %s of type %s in notify section", project.get(), uuid.get(), group.getType()));
            continue;
        }
        ChangeQueryBuilder qb = args.queryBuilder.create(new SingleGroupUser(args.capabilityControlFactory, uuid));
        qb.setAllowFile(true);
        Predicate<ChangeData> p = qb.is_visible();
        if (nc.getFilter() != null) {
            p = Predicate.and(qb.parse(nc.getFilter()), p);
            p = args.queryRewriter.get().rewrite(p);
        }
        if (p.match(changeData)) {
            Set<AccountGroup.Id> seen = Sets.newHashSet();
            Queue<AccountGroup.Id> scan = Lists.newLinkedList();
            scan.add(group.getId());
            seen.add(group.getId());
            while (!scan.isEmpty()) {
                AccountGroup.Id next = scan.remove();
                for (AccountGroupMember m : args.db.get().accountGroupMembers().byGroup(next)) {
                    matching.accounts.add(m.getAccountId());
                }
                for (AccountGroupInclude m : args.db.get().accountGroupIncludes().byGroup(next)) {
                    if (seen.add(m.getIncludeId())) {
                        scan.add(m.getIncludeId());
                    }
                }
            }
        }
    }
    if (!nc.getAddresses().isEmpty()) {
        if (nc.getFilter() != null) {
            ChangeQueryBuilder qb = args.queryBuilder.create(args.anonymousUser);
            qb.setAllowFile(true);
            Predicate<ChangeData> p = qb.parse(nc.getFilter());
            p = args.queryRewriter.get().rewrite(p);
            if (p.match(changeData)) {
                matching.emails.addAll(nc.getAddresses());
            }
        } else {
            matching.emails.addAll(nc.getAddresses());
        }
    }
}
#method_after
@SuppressWarnings("unchecked")
private void add(Watchers matching, NotifyConfig nc, Project.NameKey project) throws OrmException, QueryParseException {
    for (GroupReference ref : nc.getGroups()) {
        AccountGroup group = args.groupCache.get(ref.getUUID());
        if (group == null) {
            log.warn(String.format("Project %s has invalid group %s in notify section %s", project.get(), ref.getName(), nc.getName()));
            continue;
        }
        if (group.getType() != AccountGroup.Type.INTERNAL) {
            log.warn(String.format("Project %s cannot use group %s of type %s in notify section %s", project.get(), ref.getName(), group.getType(), nc.getName()));
            continue;
        }
        ChangeQueryBuilder qb = args.queryBuilder.create(new SingleGroupUser(args.capabilityControlFactory, ref.getUUID()));
        qb.setAllowFile(true);
        Predicate<ChangeData> p = qb.is_visible();
        if (nc.getFilter() != null) {
            p = Predicate.and(qb.parse(nc.getFilter()), p);
            p = args.queryRewriter.get().rewrite(p);
        }
        if (p.match(changeData)) {
            recursivelyAddAllAccounts(matching, group);
        }
    }
    if (!nc.getAddresses().isEmpty()) {
        if (nc.getFilter() != null) {
            ChangeQueryBuilder qb = args.queryBuilder.create(args.anonymousUser);
            qb.setAllowFile(true);
            Predicate<ChangeData> p = qb.parse(nc.getFilter());
            p = args.queryRewriter.get().rewrite(p);
            if (p.match(changeData)) {
                matching.emails.addAll(nc.getAddresses());
            }
        } else {
            matching.emails.addAll(nc.getAddresses());
        }
    }
}
#end_block

#method_before
@Override
protected void init() throws EmailException {
    super.init();
    try {
        // BCC anyone who has interest in this project's changes
        // Try to mark interested owners with a TO and not a BCC line.
        // 
        Watchers matching = getWatches(NotifyType.NEW_CHANGES);
        for (Account.Id user : matching.accounts) {
            if (isOwnerOfProjectOrBranch(user)) {
                add(RecipientType.TO, user);
            } else {
                add(RecipientType.BCC, user);
            }
        }
        for (Address addr : matching.emails) {
            add(RecipientType.BCC, addr);
        }
    } catch (OrmException err) {
    // Just don't CC everyone. Better to send a partial message to those
    // we already have queued up then to fail deliver entirely to people
    // who have a lower interest in the change.
    }
}
#method_after
@Override
protected void init() throws EmailException {
    super.init();
    try {
        // BCC anyone who has interest in this project's changes
        // Try to mark interested owners with a TO and not a BCC line.
        // 
        Watchers matching = getWatches(NotifyType.NEW_CHANGES);
        for (Account.Id user : matching.accounts) {
            if (isOwnerOfProjectOrBranch(user)) {
                add(RecipientType.TO, user);
            } else {
                add(RecipientType.BCC, user);
            }
        }
        for (Address addr : matching.emails) {
            add(RecipientType.BCC, addr);
        }
    } catch (OrmException err) {
        // Just don't CC everyone. Better to send a partial message to those
        // we already have queued up then to fail deliver entirely to people
        // who have a lower interest in the change.
        log.warn("Cannot BCC watchers for new change", err);
    }
}
#end_block

#method_before
protected boolean shouldSendMessage() {
    if (body.length() == 0) {
        // 
        return false;
    }
    if (smtpRcptTo.isEmpty()) {
        // 
        return false;
    }
    if (rcptTo.size() == 1 && rcptTo.contains(fromId)) {
        // 
        return false;
    }
    return true;
}
#method_after
protected boolean shouldSendMessage() {
    if (body.length() == 0) {
        // 
        return false;
    }
    if (smtpRcptTo.isEmpty()) {
        // 
        return false;
    }
    if (smtpRcptTo.size() == 1 && rcptTo.size() == 1 && rcptTo.contains(fromId)) {
        // 
        return false;
    }
    return true;
}
#end_block

#method_before
public boolean isNotify(NotifyType type) {
    return types.contains(type);
}
#method_after
public boolean isNotify(NotifyType type) {
    return types.contains(type) || types.contains(NotifyType.ALL);
}
#end_block

#method_before
public Set<AccountGroup.UUID> getGroups() {
    return groups;
}
#method_after
public Set<GroupReference> getGroups() {
    return groups;
}
#end_block

#method_before
public void addEmail(Address address) {
    addresses.add(address);
}
#method_after
public void addEmail(GroupReference group) {
    groups.add(group);
}
#end_block

#method_before
private InMemoryRepository add(ProjectConfig pc) {
    PrologEnvironment.Factory envFactory = null;
    RulesCache rulesCache = null;
    SitePaths sitePaths = null;
    List<CommentLinkInfo> commentLinks = null;
    InMemoryRepository repo;
    try {
        repo = repoManager.createRepository(pc.getName());
        if (pc.getProject() == null) {
            pc.load(repo);
        }
    } catch (IOException | ConfigInvalidException e) {
        throw new RuntimeException(e);
    }
    all.put(pc.getName(), new ProjectState(sitePaths, projectCache, allProjectsName, allUsersName, null, envFactory, repoManager, rulesCache, commentLinks, capabilityCollectionFactory, pc));
    return repo;
}
#method_after
private InMemoryRepository add(ProjectConfig pc) {
    PrologEnvironment.Factory envFactory = null;
    RulesCache rulesCache = null;
    SitePaths sitePaths = null;
    List<CommentLinkInfo> commentLinks = null;
    InMemoryRepository repo;
    try {
        repo = repoManager.createRepository(pc.getName());
        if (pc.getProject() == null) {
            pc.load(repo);
        }
    } catch (IOException | ConfigInvalidException e) {
        throw new RuntimeException(e);
    }
    all.put(pc.getName(), new ProjectState(sitePaths, projectCache, allProjectsName, allUsersName, projectControlFactory, envFactory, repoManager, rulesCache, commentLinks, capabilityCollectionFactory, pc));
    return repo;
}
#end_block

#method_before
public Stream<T> search(List<T> list) {
    checkNotNull(list);
    int begin;
    int end;
    if (0 < prefixLen) {
        // Assumes many consecutive elements may have the same prefix, so the cost
        // of two binary searches is less than iterating to find the endpoints.
        begin = find(list, prefixBegin);
        end = find(list, prefixEnd);
    } else {
        begin = 0;
        end = list.size();
    }
    if (prefixOnly) {
        return (begin < end ? list.subList(begin, end) : ImmutableList.<T>of()).stream();
    }
    return list.subList(begin, end).stream().filter(x -> pattern.run(toStringFunc.apply(x)));
}
#method_after
public Stream<T> search(List<T> list) {
    checkNotNull(list);
    int begin;
    int end;
    if (0 < prefixLen) {
        // Assumes many consecutive elements may have the same prefix, so the cost of two binary
        // searches is less than iterating linearly and running the regexp find the endpoints.
        List<String> strings = Lists.transform(list, toStringFunc::apply);
        begin = find(strings, prefixBegin);
        end = find(strings, prefixEnd);
    } else {
        begin = 0;
        end = list.size();
    }
    if (begin >= end) {
        return Stream.empty();
    }
    Stream<T> result = list.subList(begin, end).stream();
    if (!prefixOnly) {
        result = result.filter(x -> pattern.run(toStringFunc.apply(x)));
    }
    return result;
}
#end_block

#method_before
private int find(List<T> list, String p) {
    int r = Collections.binarySearch(Lists.transform(list, toStringFunc), p);
    return r < 0 ? -(r + 1) : r;
}
#method_after
private static int find(List<String> list, String p) {
    int r = Collections.binarySearch(list, p);
    return r < 0 ? -(r + 1) : r;
}
#end_block

#method_before
@Override
public void remove(Project p) throws IOException {
    listLock.lock();
    try {
        list.put(ListKey.ALL, ImmutableSortedSet.copyOf(Sets.difference(list.get(ListKey.ALL), Collections.singleton(p.getNameKey()))));
    } catch (ExecutionException e) {
        log.warn("Cannot list available projects", e);
    } finally {
        listLock.unlock();
    }
    evict(p);
}
#method_after
@Override
public void remove(Project p) throws IOException {
    listLock.lock();
    try {
        list.put(ListKey.ALL, ImmutableSortedSet.copyOf(Sets.difference(list.get(ListKey.ALL), ImmutableSet.of(p.getNameKey()))));
    } catch (ExecutionException e) {
        log.warn("Cannot list available projects", e);
    } finally {
        listLock.unlock();
    }
    evict(p);
}
#end_block

#method_before
@Override
public void onCreateProject(Project.NameKey newProjectName) throws IOException {
    listLock.lock();
    try {
        list.put(ListKey.ALL, ImmutableSortedSet.copyOf(Sets.union(list.get(ListKey.ALL), Collections.singleton(newProjectName))));
    } catch (ExecutionException e) {
        log.warn("Cannot list available projects", e);
    } finally {
        listLock.unlock();
    }
    indexer.get().index(newProjectName);
}
#method_after
@Override
public void onCreateProject(Project.NameKey newProjectName) throws IOException {
    listLock.lock();
    try {
        list.put(ListKey.ALL, ImmutableSortedSet.copyOf(Sets.union(list.get(ListKey.ALL), ImmutableSet.of(newProjectName))));
    } catch (ExecutionException e) {
        log.warn("Cannot list available projects", e);
    } finally {
        listLock.unlock();
    }
    indexer.get().index(newProjectName);
}
#end_block

#method_before
@Test
public void configChangeCausesRefUpdate() throws Exception {
    RevCommit initialHead = getRemoteHead(project, RefNames.REFS_CONFIG);
    ConfigInfo info = gApi.projects().name(project.get()).config();
    assertThat(info.inheritedSubmitType.value).isEqualTo(SubmitType.MERGE_IF_NECESSARY);
    ConfigInput input = new ConfigInput();
    input.submitType = SubmitType.CHERRY_PICK;
    info = gApi.projects().name(project.get()).config(input);
    assertThat(info.inheritedSubmitType.value).isEqualTo(SubmitType.CHERRY_PICK);
    info = gApi.projects().name(project.get()).config();
    assertThat(info.inheritedSubmitType.value).isEqualTo(SubmitType.CHERRY_PICK);
    RevCommit updatedHead = getRemoteHead(project, RefNames.REFS_CONFIG);
    eventRecorder.assertRefUpdatedEvents(project.get(), RefNames.REFS_CONFIG, initialHead, updatedHead);
}
#method_after
@Test
public void configChangeCausesRefUpdate() throws Exception {
    RevCommit initialHead = getRemoteHead(project, RefNames.REFS_CONFIG);
    ConfigInfo info = gApi.projects().name(project.get()).config();
    assertThat(info.defaultSubmitType.value).isEqualTo(SubmitType.MERGE_IF_NECESSARY);
    ConfigInput input = new ConfigInput();
    input.submitType = SubmitType.CHERRY_PICK;
    info = gApi.projects().name(project.get()).config(input);
    assertThat(info.defaultSubmitType.value).isEqualTo(SubmitType.CHERRY_PICK);
    info = gApi.projects().name(project.get()).config();
    assertThat(info.defaultSubmitType.value).isEqualTo(SubmitType.CHERRY_PICK);
    RevCommit updatedHead = getRemoteHead(project, RefNames.REFS_CONFIG);
    eventRecorder.assertRefUpdatedEvents(project.get(), RefNames.REFS_CONFIG, initialHead, updatedHead);
}
#end_block

#method_before
@Test
@SuppressWarnings("deprecation")
public void setConfig() throws Exception {
    ConfigInput input = createTestConfigInput();
    ConfigInfo info = gApi.projects().name(project.get()).config(input);
    assertThat(info.description).isEqualTo(input.description);
    assertThat(info.useContributorAgreements.configuredValue).isEqualTo(input.useContributorAgreements);
    assertThat(info.useContentMerge.configuredValue).isEqualTo(input.useContentMerge);
    assertThat(info.useSignedOffBy.configuredValue).isEqualTo(input.useSignedOffBy);
    assertThat(info.createNewChangeForAllNotInTarget.configuredValue).isEqualTo(input.createNewChangeForAllNotInTarget);
    assertThat(info.requireChangeId.configuredValue).isEqualTo(input.requireChangeId);
    assertThat(info.rejectImplicitMerges.configuredValue).isEqualTo(input.rejectImplicitMerges);
    assertThat(info.enableReviewerByEmail.configuredValue).isEqualTo(input.enableReviewerByEmail);
    assertThat(info.createNewChangeForAllNotInTarget.configuredValue).isEqualTo(input.createNewChangeForAllNotInTarget);
    assertThat(info.maxObjectSizeLimit.configuredValue).isEqualTo(input.maxObjectSizeLimit);
    assertThat(info.submitType).isEqualTo(input.submitType);
    assertThat(info.inheritedSubmitType.value).isEqualTo(input.submitType);
    assertThat(info.inheritedSubmitType.inheritedValue).isEqualTo(SubmitType.MERGE_IF_NECESSARY);
    assertThat(info.inheritedSubmitType.configuredValue).isEqualTo(input.submitType);
    assertThat(info.state).isEqualTo(input.state);
}
#method_after
@Test
@SuppressWarnings("deprecation")
public void setConfig() throws Exception {
    ConfigInput input = createTestConfigInput();
    ConfigInfo info = gApi.projects().name(project.get()).config(input);
    assertThat(info.description).isEqualTo(input.description);
    assertThat(info.useContributorAgreements.configuredValue).isEqualTo(input.useContributorAgreements);
    assertThat(info.useContentMerge.configuredValue).isEqualTo(input.useContentMerge);
    assertThat(info.useSignedOffBy.configuredValue).isEqualTo(input.useSignedOffBy);
    assertThat(info.createNewChangeForAllNotInTarget.configuredValue).isEqualTo(input.createNewChangeForAllNotInTarget);
    assertThat(info.requireChangeId.configuredValue).isEqualTo(input.requireChangeId);
    assertThat(info.rejectImplicitMerges.configuredValue).isEqualTo(input.rejectImplicitMerges);
    assertThat(info.enableReviewerByEmail.configuredValue).isEqualTo(input.enableReviewerByEmail);
    assertThat(info.createNewChangeForAllNotInTarget.configuredValue).isEqualTo(input.createNewChangeForAllNotInTarget);
    assertThat(info.maxObjectSizeLimit.configuredValue).isEqualTo(input.maxObjectSizeLimit);
    assertThat(info.submitType).isEqualTo(input.submitType);
    assertThat(info.defaultSubmitType.value).isEqualTo(input.submitType);
    assertThat(info.defaultSubmitType.inheritedValue).isEqualTo(SubmitType.MERGE_IF_NECESSARY);
    assertThat(info.defaultSubmitType.configuredValue).isEqualTo(input.submitType);
    assertThat(info.state).isEqualTo(input.state);
}
#end_block

#method_before
@SuppressWarnings("deprecation")
@Test
public void setPartialConfig() throws Exception {
    ConfigInput input = createTestConfigInput();
    ConfigInfo info = gApi.projects().name(project.get()).config(input);
    ConfigInput partialInput = new ConfigInput();
    partialInput.useContributorAgreements = InheritableBoolean.FALSE;
    info = gApi.projects().name(project.get()).config(partialInput);
    assertThat(info.description).isNull();
    assertThat(info.useContributorAgreements.configuredValue).isEqualTo(partialInput.useContributorAgreements);
    assertThat(info.useContentMerge.configuredValue).isEqualTo(input.useContentMerge);
    assertThat(info.useSignedOffBy.configuredValue).isEqualTo(input.useSignedOffBy);
    assertThat(info.createNewChangeForAllNotInTarget.configuredValue).isEqualTo(input.createNewChangeForAllNotInTarget);
    assertThat(info.requireChangeId.configuredValue).isEqualTo(input.requireChangeId);
    assertThat(info.rejectImplicitMerges.configuredValue).isEqualTo(input.rejectImplicitMerges);
    assertThat(info.enableReviewerByEmail.configuredValue).isEqualTo(input.enableReviewerByEmail);
    assertThat(info.createNewChangeForAllNotInTarget.configuredValue).isEqualTo(input.createNewChangeForAllNotInTarget);
    assertThat(info.maxObjectSizeLimit.configuredValue).isEqualTo(input.maxObjectSizeLimit);
    assertThat(info.submitType).isEqualTo(input.submitType);
    assertThat(info.inheritedSubmitType.value).isEqualTo(input.submitType);
    assertThat(info.inheritedSubmitType.inheritedValue).isEqualTo(SubmitType.MERGE_IF_NECESSARY);
    assertThat(info.inheritedSubmitType.configuredValue).isEqualTo(input.submitType);
    assertThat(info.state).isEqualTo(input.state);
}
#method_after
@SuppressWarnings("deprecation")
@Test
public void setPartialConfig() throws Exception {
    ConfigInput input = createTestConfigInput();
    ConfigInfo info = gApi.projects().name(project.get()).config(input);
    ConfigInput partialInput = new ConfigInput();
    partialInput.useContributorAgreements = InheritableBoolean.FALSE;
    info = gApi.projects().name(project.get()).config(partialInput);
    assertThat(info.description).isNull();
    assertThat(info.useContributorAgreements.configuredValue).isEqualTo(partialInput.useContributorAgreements);
    assertThat(info.useContentMerge.configuredValue).isEqualTo(input.useContentMerge);
    assertThat(info.useSignedOffBy.configuredValue).isEqualTo(input.useSignedOffBy);
    assertThat(info.createNewChangeForAllNotInTarget.configuredValue).isEqualTo(input.createNewChangeForAllNotInTarget);
    assertThat(info.requireChangeId.configuredValue).isEqualTo(input.requireChangeId);
    assertThat(info.rejectImplicitMerges.configuredValue).isEqualTo(input.rejectImplicitMerges);
    assertThat(info.enableReviewerByEmail.configuredValue).isEqualTo(input.enableReviewerByEmail);
    assertThat(info.createNewChangeForAllNotInTarget.configuredValue).isEqualTo(input.createNewChangeForAllNotInTarget);
    assertThat(info.maxObjectSizeLimit.configuredValue).isEqualTo(input.maxObjectSizeLimit);
    assertThat(info.submitType).isEqualTo(input.submitType);
    assertThat(info.defaultSubmitType.value).isEqualTo(input.submitType);
    assertThat(info.defaultSubmitType.inheritedValue).isEqualTo(SubmitType.MERGE_IF_NECESSARY);
    assertThat(info.defaultSubmitType.configuredValue).isEqualTo(input.submitType);
    assertThat(info.state).isEqualTo(input.state);
}
#end_block

#method_before
void display(ConfigInfo result) {
    descTxt.setText(result.description());
    setBool(contributorAgreements, result.useContributorAgreements());
    setBool(signedOffBy, result.useSignedOffBy());
    setBool(contentMerge, result.useContentMerge());
    setBool(newChangeForAllNotInTarget, result.createNewChangeForAllNotInTarget());
    setBool(requireChangeID, result.requireChangeId());
    if (Gerrit.info().receive().enableSignedPush()) {
        setBool(enableSignedPush, result.enableSignedPush());
        setBool(requireSignedPush, result.requireSignedPush());
    }
    setBool(rejectImplicitMerges, result.rejectImplicitMerges());
    setBool(privateByDefault, result.privateByDefault());
    setBool(enableReviewerByEmail, result.enableReviewerByEmail());
    setBool(matchAuthorToCommitterDate, result.matchAuthorToCommitterDate());
    setSubmitType(result.inheritedSubmitType());
    setState(result.state());
    maxObjectSizeLimit.setText(result.maxObjectSizeLimit().configuredValue());
    if (result.maxObjectSizeLimit().inheritedValue() != null) {
        effectiveMaxObjectSizeLimit.setVisible(true);
        effectiveMaxObjectSizeLimit.setText(AdminMessages.I.effectiveMaxObjectSizeLimit(result.maxObjectSizeLimit().value()));
        effectiveMaxObjectSizeLimit.setTitle(AdminMessages.I.globalMaxObjectSizeLimit(result.maxObjectSizeLimit().inheritedValue()));
    } else {
        effectiveMaxObjectSizeLimit.setVisible(false);
    }
    saveProject.setEnabled(false);
    initPluginOptions(result);
    initProjectActions(result);
}
#method_after
void display(ConfigInfo result) {
    descTxt.setText(result.description());
    setBool(contributorAgreements, result.useContributorAgreements());
    setBool(signedOffBy, result.useSignedOffBy());
    setBool(contentMerge, result.useContentMerge());
    setBool(newChangeForAllNotInTarget, result.createNewChangeForAllNotInTarget());
    setBool(requireChangeID, result.requireChangeId());
    if (Gerrit.info().receive().enableSignedPush()) {
        setBool(enableSignedPush, result.enableSignedPush());
        setBool(requireSignedPush, result.requireSignedPush());
    }
    setBool(rejectImplicitMerges, result.rejectImplicitMerges());
    setBool(privateByDefault, result.privateByDefault());
    setBool(enableReviewerByEmail, result.enableReviewerByEmail());
    setBool(matchAuthorToCommitterDate, result.matchAuthorToCommitterDate());
    setSubmitType(result.defaultSubmitType());
    setState(result.state());
    maxObjectSizeLimit.setText(result.maxObjectSizeLimit().configuredValue());
    if (result.maxObjectSizeLimit().inheritedValue() != null) {
        effectiveMaxObjectSizeLimit.setVisible(true);
        effectiveMaxObjectSizeLimit.setText(AdminMessages.I.effectiveMaxObjectSizeLimit(result.maxObjectSizeLimit().value()));
        effectiveMaxObjectSizeLimit.setTitle(AdminMessages.I.globalMaxObjectSizeLimit(result.maxObjectSizeLimit().inheritedValue()));
    } else {
        effectiveMaxObjectSizeLimit.setVisible(false);
    }
    saveProject.setEnabled(false);
    initPluginOptions(result);
    initProjectActions(result);
}
#end_block

#method_before
@SuppressWarnings("deprecation")
@Test
public void createProjectWithDefaultInheritedSubmitType() throws Exception {
    String parent = name("parent");
    ProjectInput pin = new ProjectInput();
    pin.name = parent;
    ConfigInfo cfg = gApi.projects().create(pin).config();
    assertThat(cfg.submitType).isEqualTo(SubmitType.MERGE_IF_NECESSARY);
    assertThat(cfg.inheritedSubmitType.value).isEqualTo(SubmitType.MERGE_IF_NECESSARY);
    assertThat(cfg.inheritedSubmitType.configuredValue).isEqualTo(SubmitType.INHERIT);
    assertThat(cfg.inheritedSubmitType.inheritedValue).isEqualTo(SubmitType.MERGE_IF_NECESSARY);
    ConfigInput cin = new ConfigInput();
    cin.submitType = SubmitType.CHERRY_PICK;
    gApi.projects().name(parent).config(cin);
    cfg = gApi.projects().name(parent).config();
    assertThat(cfg.submitType).isEqualTo(SubmitType.CHERRY_PICK);
    assertThat(cfg.inheritedSubmitType.value).isEqualTo(SubmitType.CHERRY_PICK);
    assertThat(cfg.inheritedSubmitType.configuredValue).isEqualTo(SubmitType.CHERRY_PICK);
    assertThat(cfg.inheritedSubmitType.inheritedValue).isEqualTo(SubmitType.MERGE_IF_NECESSARY);
    String child = name("child");
    pin = new ProjectInput();
    pin.parent = parent;
    pin.name = child;
    cfg = gApi.projects().create(pin).config();
    assertThat(cfg.submitType).isEqualTo(SubmitType.CHERRY_PICK);
    assertThat(cfg.inheritedSubmitType.value).isEqualTo(SubmitType.CHERRY_PICK);
    assertThat(cfg.inheritedSubmitType.configuredValue).isEqualTo(SubmitType.INHERIT);
    assertThat(cfg.inheritedSubmitType.inheritedValue).isEqualTo(SubmitType.CHERRY_PICK);
    cin = new ConfigInput();
    cin.submitType = SubmitType.MERGE_IF_NECESSARY;
    gApi.projects().name(parent).config(cin);
    cfg = gApi.projects().name(parent).config();
    assertThat(cfg.submitType).isEqualTo(SubmitType.MERGE_IF_NECESSARY);
    assertThat(cfg.inheritedSubmitType.value).isEqualTo(SubmitType.MERGE_IF_NECESSARY);
    assertThat(cfg.inheritedSubmitType.configuredValue).isEqualTo(SubmitType.MERGE_IF_NECESSARY);
    assertThat(cfg.inheritedSubmitType.inheritedValue).isEqualTo(SubmitType.MERGE_IF_NECESSARY);
    cfg = gApi.projects().name(child).config();
    assertThat(cfg.submitType).isEqualTo(SubmitType.MERGE_IF_NECESSARY);
    assertThat(cfg.inheritedSubmitType.value).isEqualTo(SubmitType.MERGE_IF_NECESSARY);
    assertThat(cfg.inheritedSubmitType.configuredValue).isEqualTo(SubmitType.INHERIT);
    assertThat(cfg.inheritedSubmitType.inheritedValue).isEqualTo(SubmitType.MERGE_IF_NECESSARY);
}
#method_after
@SuppressWarnings("deprecation")
@Test
public void createProjectWithDefaultInheritedSubmitType() throws Exception {
    String parent = name("parent");
    ProjectInput pin = new ProjectInput();
    pin.name = parent;
    ConfigInfo cfg = gApi.projects().create(pin).config();
    assertThat(cfg.submitType).isEqualTo(SubmitType.MERGE_IF_NECESSARY);
    assertThat(cfg.defaultSubmitType.value).isEqualTo(SubmitType.MERGE_IF_NECESSARY);
    assertThat(cfg.defaultSubmitType.configuredValue).isEqualTo(SubmitType.MERGE_IF_NECESSARY);
    assertThat(cfg.defaultSubmitType.inheritedValue).isEqualTo(SubmitType.MERGE_IF_NECESSARY);
    ConfigInput cin = new ConfigInput();
    cin.submitType = SubmitType.CHERRY_PICK;
    gApi.projects().name(parent).config(cin);
    cfg = gApi.projects().name(parent).config();
    assertThat(cfg.submitType).isEqualTo(SubmitType.CHERRY_PICK);
    assertThat(cfg.defaultSubmitType.value).isEqualTo(SubmitType.CHERRY_PICK);
    assertThat(cfg.defaultSubmitType.configuredValue).isEqualTo(SubmitType.CHERRY_PICK);
    assertThat(cfg.defaultSubmitType.inheritedValue).isEqualTo(SubmitType.MERGE_IF_NECESSARY);
    String child = name("child");
    pin = new ProjectInput();
    pin.submitType = SubmitType.INHERIT;
    pin.parent = parent;
    pin.name = child;
    cfg = gApi.projects().create(pin).config();
    assertThat(cfg.submitType).isEqualTo(SubmitType.CHERRY_PICK);
    assertThat(cfg.defaultSubmitType.value).isEqualTo(SubmitType.CHERRY_PICK);
    assertThat(cfg.defaultSubmitType.configuredValue).isEqualTo(SubmitType.INHERIT);
    assertThat(cfg.defaultSubmitType.inheritedValue).isEqualTo(SubmitType.CHERRY_PICK);
    cin = new ConfigInput();
    cin.submitType = SubmitType.REBASE_IF_NECESSARY;
    gApi.projects().name(parent).config(cin);
    cfg = gApi.projects().name(parent).config();
    assertThat(cfg.submitType).isEqualTo(SubmitType.REBASE_IF_NECESSARY);
    assertThat(cfg.defaultSubmitType.value).isEqualTo(SubmitType.REBASE_IF_NECESSARY);
    assertThat(cfg.defaultSubmitType.configuredValue).isEqualTo(SubmitType.REBASE_IF_NECESSARY);
    assertThat(cfg.defaultSubmitType.inheritedValue).isEqualTo(SubmitType.MERGE_IF_NECESSARY);
    cfg = gApi.projects().name(child).config();
    assertThat(cfg.submitType).isEqualTo(SubmitType.REBASE_IF_NECESSARY);
    assertThat(cfg.defaultSubmitType.value).isEqualTo(SubmitType.REBASE_IF_NECESSARY);
    assertThat(cfg.defaultSubmitType.configuredValue).isEqualTo(SubmitType.INHERIT);
    assertThat(cfg.defaultSubmitType.inheritedValue).isEqualTo(SubmitType.REBASE_IF_NECESSARY);
}
#end_block

#method_before
@SuppressWarnings("deprecation")
@Test
@GerritConfig(name = "repository.testinheritedsubmittype/*.defaultSubmitType", value = "CHERRY_PICK")
public void repositoryConfigTakesPrecedenceOverInheritedSubmitType() throws Exception {
    // Can't use name() since we need to specify this project name in gerrit.config prior to
    // startup. Pick something reasonably unique instead.
    String parent = "testinheritedsubmittype";
    ProjectInput pin = new ProjectInput();
    pin.name = parent;
    pin.submitType = SubmitType.MERGE_ALWAYS;
    ConfigInfo cfg = gApi.projects().create(pin).config();
    assertThat(cfg.submitType).isEqualTo(SubmitType.MERGE_ALWAYS);
    assertThat(cfg.inheritedSubmitType.value).isEqualTo(SubmitType.MERGE_ALWAYS);
    assertThat(cfg.inheritedSubmitType.configuredValue).isEqualTo(SubmitType.MERGE_ALWAYS);
    assertThat(cfg.inheritedSubmitType.inheritedValue).isEqualTo(SubmitType.MERGE_IF_NECESSARY);
    String child = parent + "/child";
    pin = new ProjectInput();
    pin.parent = parent;
    pin.name = child;
    cfg = gApi.projects().create(pin).config();
    assertThat(cfg.submitType).isEqualTo(SubmitType.CHERRY_PICK);
    assertThat(cfg.inheritedSubmitType.value).isEqualTo(SubmitType.CHERRY_PICK);
    assertThat(cfg.inheritedSubmitType.configuredValue).isEqualTo(SubmitType.CHERRY_PICK);
    assertThat(cfg.inheritedSubmitType.inheritedValue).isEqualTo(SubmitType.MERGE_ALWAYS);
}
#method_after
@SuppressWarnings("deprecation")
@Test
@GerritConfig(name = "repository.testinheritedsubmittype/*.defaultSubmitType", value = "CHERRY_PICK")
public void repositoryConfigTakesPrecedenceOverInheritedSubmitType() throws Exception {
    // Can't use name() since we need to specify this project name in gerrit.config prior to
    // startup. Pick something reasonably unique instead.
    String parent = "testinheritedsubmittype";
    ProjectInput pin = new ProjectInput();
    pin.name = parent;
    pin.submitType = SubmitType.MERGE_ALWAYS;
    ConfigInfo cfg = gApi.projects().create(pin).config();
    assertThat(cfg.submitType).isEqualTo(SubmitType.MERGE_ALWAYS);
    assertThat(cfg.defaultSubmitType.value).isEqualTo(SubmitType.MERGE_ALWAYS);
    assertThat(cfg.defaultSubmitType.configuredValue).isEqualTo(SubmitType.MERGE_ALWAYS);
    assertThat(cfg.defaultSubmitType.inheritedValue).isEqualTo(SubmitType.MERGE_IF_NECESSARY);
    String child = parent + "/child";
    pin = new ProjectInput();
    pin.parent = parent;
    pin.name = child;
    cfg = gApi.projects().create(pin).config();
    assertThat(cfg.submitType).isEqualTo(SubmitType.CHERRY_PICK);
    assertThat(cfg.defaultSubmitType.value).isEqualTo(SubmitType.CHERRY_PICK);
    assertThat(cfg.defaultSubmitType.configuredValue).isEqualTo(SubmitType.CHERRY_PICK);
    assertThat(cfg.defaultSubmitType.inheritedValue).isEqualTo(SubmitType.MERGE_ALWAYS);
}
#end_block

#method_before
@Override
protected boolean onSave(CommitBuilder commit) throws IOException, ConfigInvalidException {
    if (commit.getMessage() == null || "".equals(commit.getMessage())) {
        commit.setMessage("Updated project configuration\n");
    }
    Config rc = readConfig(PROJECT_CONFIG);
    Project p = project;
    if (p.getDescription() != null && !p.getDescription().isEmpty()) {
        rc.setString(PROJECT, null, KEY_DESCRIPTION, p.getDescription());
    } else {
        rc.unset(PROJECT, null, KEY_DESCRIPTION);
    }
    set(rc, ACCESS, null, KEY_INHERIT_FROM, p.getParentName());
    for (BooleanProjectConfig config : BooleanProjectConfig.values()) {
        set(rc, config.getSection(), config.getSubSection(), config.getName(), p.getBooleanConfig(config), InheritableBoolean.INHERIT);
    }
    set(rc, RECEIVE, null, KEY_MAX_OBJECT_SIZE_LIMIT, validMaxObjectSizeLimit(p.getMaxObjectSizeLimit()));
    // Always set submit.action, even if it's the default.
    rc.setEnum(SUBMIT, null, KEY_ACTION, p.getConfiguredSubmitType());
    set(rc, PROJECT, null, KEY_STATE, p.getState(), DEFAULT_STATE_VALUE);
    set(rc, DASHBOARD, null, KEY_DEFAULT, p.getDefaultDashboard());
    set(rc, DASHBOARD, null, KEY_LOCAL_DEFAULT, p.getLocalDefaultDashboard());
    Set<AccountGroup.UUID> keepGroups = new HashSet<>();
    saveAccountsSection(rc, keepGroups);
    saveContributorAgreements(rc, keepGroups);
    saveAccessSections(rc, keepGroups);
    saveNotifySections(rc, keepGroups);
    savePluginSections(rc, keepGroups);
    groupList.retainUUIDs(keepGroups);
    saveLabelSections(rc);
    saveSubscribeSections(rc);
    saveConfig(PROJECT_CONFIG, rc);
    saveGroupList();
    return true;
}
#method_after
@Override
protected boolean onSave(CommitBuilder commit) throws IOException, ConfigInvalidException {
    if (commit.getMessage() == null || "".equals(commit.getMessage())) {
        commit.setMessage("Updated project configuration\n");
    }
    Config rc = readConfig(PROJECT_CONFIG);
    Project p = project;
    if (p.getDescription() != null && !p.getDescription().isEmpty()) {
        rc.setString(PROJECT, null, KEY_DESCRIPTION, p.getDescription());
    } else {
        rc.unset(PROJECT, null, KEY_DESCRIPTION);
    }
    set(rc, ACCESS, null, KEY_INHERIT_FROM, p.getParentName());
    for (BooleanProjectConfig config : BooleanProjectConfig.values()) {
        set(rc, config.getSection(), config.getSubSection(), config.getName(), p.getBooleanConfig(config), InheritableBoolean.INHERIT);
    }
    set(rc, RECEIVE, null, KEY_MAX_OBJECT_SIZE_LIMIT, validMaxObjectSizeLimit(p.getMaxObjectSizeLimit()));
    set(rc, SUBMIT, null, KEY_ACTION, p.getConfiguredSubmitType(), DEFAULT_SUBMIT_TYPE);
    set(rc, PROJECT, null, KEY_STATE, p.getState(), DEFAULT_STATE_VALUE);
    set(rc, DASHBOARD, null, KEY_DEFAULT, p.getDefaultDashboard());
    set(rc, DASHBOARD, null, KEY_LOCAL_DEFAULT, p.getLocalDefaultDashboard());
    Set<AccountGroup.UUID> keepGroups = new HashSet<>();
    saveAccountsSection(rc, keepGroups);
    saveContributorAgreements(rc, keepGroups);
    saveAccessSections(rc, keepGroups);
    saveNotifySections(rc, keepGroups);
    savePluginSections(rc, keepGroups);
    groupList.retainUUIDs(keepGroups);
    saveLabelSections(rc);
    saveSubscribeSections(rc);
    saveConfig(PROJECT_CONFIG, rc);
    saveGroupList();
    return true;
}
#end_block

#method_before
public static boolean isOff(String listenHostname) {
    return "off".equalsIgnoreCase(listenHostname) || "none".equalsIgnoreCase(listenHostname) || "no".equalsIgnoreCase(listenHostname);
}
#method_after
static boolean isOff(String listenHostname) {
    return "off".equalsIgnoreCase(listenHostname) || "none".equalsIgnoreCase(listenHostname) || "no".equalsIgnoreCase(listenHostname);
}
#end_block

#method_before
private List<ChangeAndCommit> getRelated(RevisionResource rsrc) throws OrmException, IOException, PermissionBackendException {
    Set<String> groups = getAllGroups(rsrc.getNotes());
    if (groups.isEmpty()) {
        return Collections.emptyList();
    }
    List<ChangeData> cds = InternalChangeQuery.byProjectGroups(queryProvider, indexConfig, rsrc.getChange().getProject(), groups);
    if (cds.isEmpty()) {
        return Collections.emptyList();
    }
    if (cds.size() == 1 && cds.get(0).getId().equals(rsrc.getChange().getId())) {
        return Collections.emptyList();
    }
    List<ChangeAndCommit> result = new ArrayList<>(cds.size());
    boolean isEdit = rsrc.getEdit().isPresent();
    PatchSet basePs = isEdit ? rsrc.getEdit().get().getBasePatchSet() : rsrc.getPatchSet();
    reloadChangeIfStale(cds, basePs);
    for (PatchSetData d : sorter.sort(cds, basePs, rsrc.getUser())) {
        PatchSet ps = d.patchSet();
        RevCommit commit;
        if (isEdit && ps.getId().equals(basePs.getId())) {
            // Replace base of an edit with the edit itself.
            ps = rsrc.getPatchSet();
            commit = rsrc.getEdit().get().getEditCommit();
        } else {
            commit = d.commit();
        }
        result.add(new ChangeAndCommit(rsrc.getProject(), d.data().change(), ps, commit));
    }
    if (result.size() == 1) {
        ChangeAndCommit r = result.get(0);
        if (r.commit != null && r.commit.commit.equals(rsrc.getPatchSet().getRevision().get())) {
            return Collections.emptyList();
        }
    }
    return result;
}
#method_after
private List<ChangeAndCommit> getRelated(RevisionResource rsrc) throws OrmException, IOException, PermissionBackendException {
    Set<String> groups = getAllGroups(rsrc.getNotes(), db.get(), psUtil);
    if (groups.isEmpty()) {
        return Collections.emptyList();
    }
    List<ChangeData> cds = InternalChangeQuery.byProjectGroups(queryProvider, indexConfig, rsrc.getChange().getProject(), groups);
    if (cds.isEmpty()) {
        return Collections.emptyList();
    }
    if (cds.size() == 1 && cds.get(0).getId().equals(rsrc.getChange().getId())) {
        return Collections.emptyList();
    }
    List<ChangeAndCommit> result = new ArrayList<>(cds.size());
    boolean isEdit = rsrc.getEdit().isPresent();
    PatchSet basePs = isEdit ? rsrc.getEdit().get().getBasePatchSet() : rsrc.getPatchSet();
    reloadChangeIfStale(cds, basePs);
    for (PatchSetData d : sorter.sort(cds, basePs, rsrc.getUser())) {
        PatchSet ps = d.patchSet();
        RevCommit commit;
        if (isEdit && ps.getId().equals(basePs.getId())) {
            // Replace base of an edit with the edit itself.
            ps = rsrc.getPatchSet();
            commit = rsrc.getEdit().get().getEditCommit();
        } else {
            commit = d.commit();
        }
        result.add(new ChangeAndCommit(rsrc.getProject(), d.data().change(), ps, commit));
    }
    if (result.size() == 1) {
        ChangeAndCommit r = result.get(0);
        if (r.commit != null && r.commit.commit.equals(rsrc.getPatchSet().getRevision().get())) {
            return Collections.emptyList();
        }
    }
    return result;
}
#end_block

#method_before
private void autoCloseChanges(ReceiveCommand cmd) {
    logDebug("Starting auto-closing of changes");
    String refName = cmd.getRefName();
    checkState(!MagicBranch.isMagicBranch(refName), "shouldn't be auto-closing changes on magic branch %s", refName);
    // insertChangesAndPatchSets.
    try {
        retryHelper.execute(updateFactory -> {
            try (BatchUpdate bu = updateFactory.create(db, projectState.getNameKey(), user, TimeUtil.nowTs());
                ObjectInserter ins = repo.newObjectInserter();
                ObjectReader reader = ins.newReader();
                RevWalk rw = new RevWalk(reader)) {
                bu.setRepository(repo, rw, ins).updateChangesInParallel();
                bu.setRequestId(receiveId);
                // TODO(dborowitz): Teach BatchUpdate to ignore missing changes.
                RevCommit newTip = rw.parseCommit(cmd.getNewId());
                Branch.NameKey branch = new Branch.NameKey(project.getNameKey(), refName);
                rw.reset();
                rw.markStart(newTip);
                if (!ObjectId.zeroId().equals(cmd.getOldId())) {
                    rw.markUninteresting(rw.parseCommit(cmd.getOldId()));
                }
                ListMultimap<ObjectId, Ref> byCommit = changeRefsById();
                Map<Change.Key, ChangeNotes> byKey = null;
                List<ReplaceRequest> replaceAndClose = new ArrayList<>();
                int existingPatchSets = 0;
                int newPatchSets = 0;
                COMMIT: for (RevCommit c; (c = rw.next()) != null; ) {
                    rw.parseBody(c);
                    for (Ref ref : byCommit.get(c.copy())) {
                        PatchSet.Id psId = PatchSet.Id.fromRef(ref.getName());
                        Optional<ChangeData> cd = retryHelper.execute(() -> byLegacyId(psId.getParentKey()), t -> t instanceof OrmException);
                        if (cd.isPresent() && cd.get().change().getDest().equals(branch)) {
                            existingPatchSets++;
                            bu.addOp(psId.getParentKey(), mergedByPushOpFactory.create(requestScopePropagator, psId, refName));
                            continue COMMIT;
                        }
                    }
                    for (String changeId : c.getFooterLines(CHANGE_ID)) {
                        if (byKey == null) {
                            byKey = retryHelper.execute(() -> openChangesByKeyByBranch(branch), t -> t instanceof OrmException);
                        }
                        ChangeNotes onto = byKey.get(new Change.Key(changeId.trim()));
                        if (onto != null) {
                            newPatchSets++;
                            // Hold onto this until we're done with the walk, as the call to
                            // req.validate below calls isMergedInto which resets the walk.
                            ReplaceRequest req = new ReplaceRequest(onto.getChangeId(), c, cmd, false);
                            req.notes = onto;
                            replaceAndClose.add(req);
                            continue COMMIT;
                        }
                    }
                }
                for (ReplaceRequest req : replaceAndClose) {
                    Change.Id id = req.notes.getChangeId();
                    if (!req.validate(true)) {
                        logDebug("Not closing {} because validation failed", id);
                        continue;
                    }
                    req.addOps(bu, null);
                    bu.addOp(id, mergedByPushOpFactory.create(requestScopePropagator, req.psId, refName).setPatchSetProvider(new Provider<PatchSet>() {

                        @Override
                        public PatchSet get() {
                            return req.replaceOp.getPatchSet();
                        }
                    }));
                    bu.addOp(id, new ChangeProgressOp(closeProgress));
                }
                logDebug("Auto-closing {} changes with existing patch sets and {} with new patch sets", existingPatchSets, newPatchSets);
                bu.execute();
            } catch (OrmException e) {
                logError("Can't scan for changes to close", e);
            } catch (IOException | PermissionBackendException e) {
                logError("Failed to auto-close changes", e);
            }
            return null;
        });
    } catch (RestApiException e) {
        logError("Can't insert patchset", e);
    } catch (UpdateException e) {
        logError("Failed to auto-close changes", e);
    }
}
#method_after
private void autoCloseChanges(ReceiveCommand cmd) {
    logDebug("Starting auto-closing of changes");
    String refName = cmd.getRefName();
    checkState(!MagicBranch.isMagicBranch(refName), "shouldn't be auto-closing changes on magic branch %s", refName);
    // insertChangesAndPatchSets.
    try {
        retryHelper.execute(updateFactory -> {
            try (BatchUpdate bu = updateFactory.create(db, projectState.getNameKey(), user, TimeUtil.nowTs());
                ObjectInserter ins = repo.newObjectInserter();
                ObjectReader reader = ins.newReader();
                RevWalk rw = new RevWalk(reader)) {
                bu.setRepository(repo, rw, ins).updateChangesInParallel();
                bu.setRequestId(receiveId);
                // TODO(dborowitz): Teach BatchUpdate to ignore missing changes.
                RevCommit newTip = rw.parseCommit(cmd.getNewId());
                Branch.NameKey branch = new Branch.NameKey(project.getNameKey(), refName);
                rw.reset();
                rw.markStart(newTip);
                if (!ObjectId.zeroId().equals(cmd.getOldId())) {
                    rw.markUninteresting(rw.parseCommit(cmd.getOldId()));
                }
                ListMultimap<ObjectId, Ref> byCommit = changeRefsById();
                Map<Change.Key, ChangeNotes> byKey = null;
                List<ReplaceRequest> replaceAndClose = new ArrayList<>();
                int existingPatchSets = 0;
                int newPatchSets = 0;
                COMMIT: for (RevCommit c; (c = rw.next()) != null; ) {
                    rw.parseBody(c);
                    for (Ref ref : byCommit.get(c.copy())) {
                        PatchSet.Id psId = PatchSet.Id.fromRef(ref.getName());
                        Optional<ChangeData> cd = retryHelper.execute(ActionType.CHANGE_QUERY, () -> byLegacyId(psId.getParentKey()), t -> t instanceof OrmException);
                        if (cd.isPresent() && cd.get().change().getDest().equals(branch)) {
                            existingPatchSets++;
                            bu.addOp(psId.getParentKey(), mergedByPushOpFactory.create(requestScopePropagator, psId, refName));
                            continue COMMIT;
                        }
                    }
                    for (String changeId : c.getFooterLines(CHANGE_ID)) {
                        if (byKey == null) {
                            byKey = retryHelper.execute(ActionType.CHANGE_QUERY, () -> openChangesByKeyByBranch(branch), t -> t instanceof OrmException);
                        }
                        ChangeNotes onto = byKey.get(new Change.Key(changeId.trim()));
                        if (onto != null) {
                            newPatchSets++;
                            // Hold onto this until we're done with the walk, as the call to
                            // req.validate below calls isMergedInto which resets the walk.
                            ReplaceRequest req = new ReplaceRequest(onto.getChangeId(), c, cmd, false);
                            req.notes = onto;
                            replaceAndClose.add(req);
                            continue COMMIT;
                        }
                    }
                }
                for (ReplaceRequest req : replaceAndClose) {
                    Change.Id id = req.notes.getChangeId();
                    if (!req.validate(true)) {
                        logDebug("Not closing {} because validation failed", id);
                        continue;
                    }
                    req.addOps(bu, null);
                    bu.addOp(id, mergedByPushOpFactory.create(requestScopePropagator, req.psId, refName).setPatchSetProvider(new Provider<PatchSet>() {

                        @Override
                        public PatchSet get() {
                            return req.replaceOp.getPatchSet();
                        }
                    }));
                    bu.addOp(id, new ChangeProgressOp(closeProgress));
                }
                logDebug("Auto-closing {} changes with existing patch sets and {} with new patch sets", existingPatchSets, newPatchSets);
                bu.execute();
            } catch (IOException | OrmException | PermissionBackendException e) {
                logError("Failed to auto-close changes", e);
            }
            return null;
        }, // eat up the whole timeout so that no time is left to retry this outer action.
        RetryHelper.options().timeout(retryHelper.getDefaultTimeout().multipliedBy(5)).build());
    } catch (RestApiException e) {
        logError("Can't insert patchset", e);
    } catch (UpdateException e) {
        logError("Failed to auto-close changes", e);
    }
}
#end_block

#method_before
private <T> T execute(ChangeAction<T> changeAction, Retryer<T> retryer) throws Throwable {
    try {
        return retryer.call(() -> changeAction.call(updateFactory));
    } catch (ExecutionException | RetryException e) {
        if (e instanceof RetryException) {
            metrics.timeoutCount.increment();
        }
        if (e.getCause() != null) {
            throw e.getCause();
        }
        throw e;
    }
}
#method_after
public <T> T execute(ActionType actionType, Action<T> action) throws IOException, ConfigInvalidException, OrmException {
    return execute(actionType, action, t -> t instanceof LockFailureException);
}
#end_block

#method_before
public <T> T execute(ChangeAction<T> changeAction, Options opts) throws RestApiException, UpdateException {
    try {
        if (!migration.disableChangeReviewDb()) {
            // don't do it automatically. Let the end user decide whether they want to retry.
            return execute(changeAction, RetryerBuilder.<T>newBuilder().build());
        }
        MetricListener listener = new MetricListener();
        try {
            RetryerBuilder<T> retryerBuilder = createRetryerBuilder(opts, t -> {
                if (t instanceof UpdateException) {
                    t = t.getCause();
                }
                return t instanceof LockFailureException;
            });
            retryerBuilder.withRetryListener(listener);
            return execute(changeAction, retryerBuilder.build());
        } finally {
            metrics.attemptCounts.record(listener.getAttemptCount());
        }
    } catch (Throwable t) {
        Throwables.throwIfUnchecked(t);
        Throwables.throwIfInstanceOf(t, UpdateException.class);
        Throwables.throwIfInstanceOf(t, RestApiException.class);
        throw new UpdateException(t);
    }
}
#method_after
public <T> T execute(ChangeAction<T> changeAction, Options opts) throws RestApiException, UpdateException {
    try {
        if (!migration.disableChangeReviewDb()) {
            // don't do it automatically. Let the end user decide whether they want to retry.
            return execute(ActionType.CHANGE_UPDATE, () -> changeAction.call(updateFactory), RetryerBuilder.<T>newBuilder().build());
        }
        return execute(ActionType.CHANGE_UPDATE, () -> changeAction.call(updateFactory), opts, t -> {
            if (t instanceof UpdateException) {
                t = t.getCause();
            }
            return t instanceof LockFailureException;
        });
    } catch (Throwable t) {
        Throwables.throwIfUnchecked(t);
        Throwables.throwIfInstanceOf(t, UpdateException.class);
        Throwables.throwIfInstanceOf(t, RestApiException.class);
        throw new UpdateException(t);
    }
}
#end_block

#method_before
public List<SuggestedReviewerInfo> suggestReviewers(ChangeNotes changeNotes, SuggestReviewers suggestReviewers, ProjectState projectState, VisibilityControl visibilityControl, boolean excludeGroups) throws IOException, OrmException, ConfigInvalidException {
    String query = suggestReviewers.getQuery();
    int limit = suggestReviewers.getLimit();
    if (!suggestReviewers.getSuggestAccounts()) {
        return Collections.emptyList();
    }
    List<Account.Id> candidateList = new ArrayList<>();
    if (!Strings.isNullOrEmpty(query)) {
        candidateList = suggestAccounts(suggestReviewers);
    }
    List<Account.Id> sortedRecommendations = recommendAccounts(changeNotes, suggestReviewers, projectState, candidateList);
    // Filter accounts by visibility and enforce limit
    List<Account.Id> filteredRecommendations = new ArrayList<>();
    try (Timer0.Context ctx = metrics.filterVisibility.start()) {
        for (Account.Id reviewer : sortedRecommendations) {
            if (filteredRecommendations.size() >= limit) {
                break;
            }
            if (visibilityControl.isVisibleTo(reviewer)) {
                filteredRecommendations.add(reviewer);
            }
        }
    }
    List<SuggestedReviewerInfo> suggestedReviewer = loadAccounts(filteredRecommendations);
    if (!excludeGroups && suggestedReviewer.size() < limit && !Strings.isNullOrEmpty(query)) {
        // Add groups at the end as individual accounts are usually more
        // important.
        suggestedReviewer.addAll(suggestAccountGroups(suggestReviewers, projectState, visibilityControl, limit - suggestedReviewer.size()));
    }
    if (suggestedReviewer.size() <= limit) {
        return suggestedReviewer;
    }
    return suggestedReviewer.subList(0, limit);
}
#method_after
public List<SuggestedReviewerInfo> suggestReviewers(ChangeNotes changeNotes, SuggestReviewers suggestReviewers, ProjectState projectState, VisibilityControl visibilityControl, boolean excludeGroups) throws IOException, OrmException, ConfigInvalidException {
    String query = suggestReviewers.getQuery();
    int limit = suggestReviewers.getLimit();
    if (!suggestReviewers.getSuggestAccounts()) {
        return Collections.emptyList();
    }
    List<Account.Id> candidateList = new ArrayList<>();
    if (!Strings.isNullOrEmpty(query)) {
        candidateList = suggestAccounts(suggestReviewers);
    }
    List<Account.Id> sortedRecommendations = recommendAccounts(changeNotes, suggestReviewers, projectState, candidateList);
    // Filter accounts by visibility and enforce limit
    List<Account.Id> filteredRecommendations = new ArrayList<>();
    try (Timer0.Context ctx = metrics.filterVisibility.start()) {
        for (Account.Id reviewer : sortedRecommendations) {
            if (filteredRecommendations.size() >= limit) {
                break;
            }
            // Check if change is visible to reviewer and if the current user can see reviewer
            if (visibilityControl.isVisibleTo(reviewer) && accountControlFactory.get().canSee(reviewer)) {
                filteredRecommendations.add(reviewer);
            }
        }
    }
    List<SuggestedReviewerInfo> suggestedReviewer = loadAccounts(filteredRecommendations);
    if (!excludeGroups && suggestedReviewer.size() < limit && !Strings.isNullOrEmpty(query)) {
        // Add groups at the end as individual accounts are usually more
        // important.
        suggestedReviewer.addAll(suggestAccountGroups(suggestReviewers, projectState, visibilityControl, limit - suggestedReviewer.size()));
    }
    if (suggestedReviewer.size() <= limit) {
        return suggestedReviewer;
    }
    return suggestedReviewer.subList(0, limit);
}
#end_block

#method_before
private List<Account.Id> suggestAccounts(SuggestReviewers suggestReviewers) throws OrmException {
    try (Timer0.Context ctx = metrics.queryAccountsLatency.start()) {
        try {
            QueryResult<AccountState> result = queryProvider.get().setRequestedFields(ImmutableSet.of(AccountField.ID.getName())).setUserProvidedLimit(suggestReviewers.getLimit() * CANDIDATE_LIST_MULTIPLIER).query(AccountPredicates.andActive(accountQueryBuilder.defaultQuery(suggestReviewers.getQuery())));
            return result.entities().stream().map(a -> a.getAccount().getId()).collect(toList());
        } catch (QueryParseException e) {
            return ImmutableList.of();
        }
    }
}
#method_after
private List<Account.Id> suggestAccounts(SuggestReviewers suggestReviewers) throws OrmException {
    try (Timer0.Context ctx = metrics.queryAccountsLatency.start()) {
        try {
            // For performance reasons we don't use AccountQueryProvider as it would always load the
            // complete account from the cache (or worse, from NoteDb) even though we only need the ID
            // which we can directly get from the returned results.
            ResultSet<FieldBundle> result = accountIndexes.getSearchIndex().getSource(Predicate.and(AccountPredicates.isActive(), accountQueryBuilder.defaultQuery(suggestReviewers.getQuery())), QueryOptions.create(indexConfig, 0, suggestReviewers.getLimit() * CANDIDATE_LIST_MULTIPLIER, ImmutableSet.of(AccountField.ID.getName()))).readRaw();
            return result.toList().stream().map(f -> new Account.Id(f.getValue(AccountField.ID).intValue())).collect(toList());
        } catch (QueryParseException e) {
            return ImmutableList.of();
        }
    }
}
#end_block

#method_before
public static ReviewDb unwrap(ReviewDb db) {
    // to bypass the write-only wrapper.
    if (db instanceof BatchUpdateReviewDb) {
        db = ((BatchUpdateReviewDb) db).unsafeGetDelegate();
    }
    return ReviewDbUtil.unwrapDb(db);
}
#method_after
public static ReviewDb unwrap(ReviewDb db) {
    if (db instanceof BatchUpdateReviewDb) {
        db = ((BatchUpdateReviewDb) db).unsafeGetDelegate();
    }
    return ReviewDbUtil.unwrapDb(db);
}
#end_block

#method_before
private void deleteChangeElementsFromDb(ChangeContext ctx, Change.Id id) throws OrmException {
    // Only delete from ReviewDb here; deletion from NoteDb is handled in
    // BatchUpdate.
    ReviewDb db = BatchUpdateReviewDb.unwrap(ctx.getDb());
    db.patchComments().delete(db.patchComments().byChange(id));
    db.patchSetApprovals().delete(db.patchSetApprovals().byChange(id));
    db.patchSets().delete(db.patchSets().byChange(id));
    db.changeMessages().delete(db.changeMessages().byChange(id));
}
#method_after
private void deleteChangeElementsFromDb(ChangeContext ctx, Change.Id id) throws OrmException {
    // Only delete from ReviewDb here; deletion from NoteDb is handled in
    // BatchUpdate.
    // 
    // This is special. We want to delete exactly the rows that are present in
    // the database, even when reading everything else from NoteDb, so we need
    // to bypass the write-only wrapper.
    ReviewDb db = BatchUpdateReviewDb.unwrap(ctx.getDb());
    db.patchComments().delete(db.patchComments().byChange(id));
    db.patchSetApprovals().delete(db.patchSetApprovals().byChange(id));
    db.patchSets().delete(db.patchSets().byChange(id));
    db.changeMessages().delete(db.changeMessages().byChange(id));
}
#end_block

#method_before
@Operator
public Predicate<ChangeData> label(String name) throws QueryParseException, OrmException, IOException, ConfigInvalidException {
    Set<Account.Id> accounts = null;
    AccountGroup.UUID group = null;
    // Parse for:
    // label:CodeReview=1,user=jsmith or
    // label:CodeReview=1,jsmith or
    // label:CodeReview=1,account=android_approvers or
    // label:CodeReview=1,android_approvers
    // user/groups without a label will first attempt to match user
    // Special case: votes by owners can be tracked with ",owner":
    // label:Code-Review+2,owner
    // label:Code-Review+2,user=owner
    String[] splitReviewer = name.split(",", 2);
    // remove all but the vote piece, e.g.'CodeReview=1'
    name = splitReviewer[0];
    if (splitReviewer.length == 2) {
        // process the user/account piece
        PredicateArgs lblArgs = new PredicateArgs(splitReviewer[1]);
        for (Map.Entry<String, String> pair : lblArgs.keyValue.entrySet()) {
            if (pair.getKey().equalsIgnoreCase(ARG_ID_USER)) {
                if (pair.getValue().equals(ARG_ID_OWNER)) {
                    accounts = Collections.singleton(OWNER_ACCOUNT_ID);
                } else {
                    accounts = parseAccount(pair.getValue());
                }
            } else if (pair.getKey().equalsIgnoreCase(ARG_ID_GROUP)) {
                group = parseGroup(pair.getValue()).getUUID();
            } else {
                throw new QueryParseException("Invalid argument identifier '" + pair.getKey() + "'");
            }
        }
        for (String value : lblArgs.positional) {
            if (accounts != null || group != null) {
                throw new QueryParseException("more than one user/account specified (" + value + ")");
            }
            try {
                if (value.equals(ARG_ID_OWNER)) {
                    accounts = Collections.singleton(OWNER_ACCOUNT_ID);
                } else {
                    accounts = parseAccount(value);
                }
            } catch (QueryParseException qpex) {
                // (accounts get precedence)
                try {
                    group = parseGroup(value).getUUID();
                } catch (QueryParseException e) {
                    throw error("Neither user nor account " + value + " found", e);
                }
            }
        }
    }
    // expand a account predicate into multiple user predicates
    if (group != null) {
        Set<Account.Id> allMembers = args.groupMembers.listAccounts(group).stream().map(a -> a.getId()).collect(toSet());
        int maxTerms = args.indexConfig.maxTerms();
        if (allMembers.size() > maxTerms) {
            // limit the number of query terms otherwise Gerrit will barf
            accounts = ImmutableSet.copyOf(Iterables.limit(allMembers, maxTerms));
        } else {
            accounts = allMembers;
        }
    }
    // If the vote piece looks like Code-Review=NEED with a valid non-numeric
    // submit record status, interpret as a submit record query.
    int eq = name.indexOf('=');
    if (args.getSchema().hasField(ChangeField.SUBMIT_RECORD) && eq > 0) {
        String statusName = name.substring(eq + 1).toUpperCase();
        if (!isInt(statusName)) {
            SubmitRecord.Label.Status status = Enums.getIfPresent(SubmitRecord.Label.Status.class, statusName).orNull();
            if (status == null) {
                throw error("Invalid label status " + statusName + " in " + name);
            }
            return SubmitRecordPredicate.create(name.substring(0, eq), status, accounts);
        }
    }
    return new LabelPredicate(args, name, accounts, group);
}
#method_after
@Operator
public Predicate<ChangeData> label(String name) throws QueryParseException, OrmException, IOException, ConfigInvalidException {
    Set<Account.Id> accounts = null;
    AccountGroup.UUID group = null;
    // Parse for:
    // label:CodeReview=1,user=jsmith or
    // label:CodeReview=1,jsmith or
    // label:CodeReview=1,group=android_approvers or
    // label:CodeReview=1,android_approvers
    // user/groups without a label will first attempt to match user
    // Special case: votes by owners can be tracked with ",owner":
    // label:Code-Review+2,owner
    // label:Code-Review+2,user=owner
    String[] splitReviewer = name.split(",", 2);
    // remove all but the vote piece, e.g.'CodeReview=1'
    name = splitReviewer[0];
    if (splitReviewer.length == 2) {
        // process the user/group piece
        PredicateArgs lblArgs = new PredicateArgs(splitReviewer[1]);
        for (Map.Entry<String, String> pair : lblArgs.keyValue.entrySet()) {
            if (pair.getKey().equalsIgnoreCase(ARG_ID_USER)) {
                if (pair.getValue().equals(ARG_ID_OWNER)) {
                    accounts = Collections.singleton(OWNER_ACCOUNT_ID);
                } else {
                    accounts = parseAccount(pair.getValue());
                }
            } else if (pair.getKey().equalsIgnoreCase(ARG_ID_GROUP)) {
                group = parseGroup(pair.getValue()).getUUID();
            } else {
                throw new QueryParseException("Invalid argument identifier '" + pair.getKey() + "'");
            }
        }
        for (String value : lblArgs.positional) {
            if (accounts != null || group != null) {
                throw new QueryParseException("more than one user/group specified (" + value + ")");
            }
            try {
                if (value.equals(ARG_ID_OWNER)) {
                    accounts = Collections.singleton(OWNER_ACCOUNT_ID);
                } else {
                    accounts = parseAccount(value);
                }
            } catch (QueryParseException qpex) {
                // (accounts get precedence)
                try {
                    group = parseGroup(value).getUUID();
                } catch (QueryParseException e) {
                    throw error("Neither user nor group " + value + " found", e);
                }
            }
        }
    }
    // expand a group predicate into multiple user predicates
    if (group != null) {
        Set<Account.Id> allMembers = args.groupMembers.listAccounts(group).stream().map(a -> a.getId()).collect(toSet());
        int maxTerms = args.indexConfig.maxTerms();
        if (allMembers.size() > maxTerms) {
            // limit the number of query terms otherwise Gerrit will barf
            accounts = ImmutableSet.copyOf(Iterables.limit(allMembers, maxTerms));
        } else {
            accounts = allMembers;
        }
    }
    // If the vote piece looks like Code-Review=NEED with a valid non-numeric
    // submit record status, interpret as a submit record query.
    int eq = name.indexOf('=');
    if (args.getSchema().hasField(ChangeField.SUBMIT_RECORD) && eq > 0) {
        String statusName = name.substring(eq + 1).toUpperCase();
        if (!isInt(statusName)) {
            SubmitRecord.Label.Status status = Enums.getIfPresent(SubmitRecord.Label.Status.class, statusName).orNull();
            if (status == null) {
                throw error("Invalid label status " + statusName + " in " + name);
            }
            return SubmitRecordPredicate.create(name.substring(0, eq), status, accounts);
        }
    }
    return new LabelPredicate(args, name, accounts, group);
}
#end_block

#method_before
@Operator
public Predicate<ChangeData> visibleto(String who) throws QueryParseException, OrmException, IOException, ConfigInvalidException {
    if (isSelf(who)) {
        return is_visible();
    }
    Set<Account.Id> m = args.accountResolver.findAll(who);
    if (!m.isEmpty()) {
        List<Predicate<ChangeData>> p = Lists.newArrayListWithCapacity(m.size());
        for (Account.Id id : m) {
            return visibleto(args.userFactory.create(id));
        }
        return Predicate.or(p);
    }
    // If its not an account, maybe its a account?
    // 
    Collection<GroupReference> suggestions = args.groupBackend.suggest(who, null);
    if (!suggestions.isEmpty()) {
        HashSet<AccountGroup.UUID> ids = new HashSet<>();
        for (GroupReference ref : suggestions) {
            ids.add(ref.getUUID());
        }
        return visibleto(new SingleGroupUser(ids));
    }
    throw error("No user or account matches \"" + who + "\".");
}
#method_after
@Operator
public Predicate<ChangeData> visibleto(String who) throws QueryParseException, OrmException, IOException, ConfigInvalidException {
    if (isSelf(who)) {
        return is_visible();
    }
    Set<Account.Id> m = args.accountResolver.findAll(who);
    if (!m.isEmpty()) {
        List<Predicate<ChangeData>> p = Lists.newArrayListWithCapacity(m.size());
        for (Account.Id id : m) {
            return visibleto(args.userFactory.create(id));
        }
        return Predicate.or(p);
    }
    // If its not an account, maybe its a group?
    Collection<GroupReference> suggestions = args.groupBackend.suggest(who, null);
    if (!suggestions.isEmpty()) {
        HashSet<AccountGroup.UUID> ids = new HashSet<>();
        for (GroupReference ref : suggestions) {
            ids.add(ref.getUUID());
        }
        return visibleto(new SingleGroupUser(ids));
    }
    throw error("No user or group matches \"" + who + "\".");
}
#end_block

#method_before
@Override
public List<ProjectInfo> apply(ProjectResource rsrc) throws PermissionBackendException {
    if (recursive) {
        return childProjectLister.recursiveChildProjects(rsrc.getNameKey());
    }
    return directChildProjects(rsrc.getNameKey());
}
#method_after
@Override
public List<ProjectInfo> apply(ProjectResource rsrc) throws PermissionBackendException {
    if (recursive) {
        return childProjects.list(rsrc.getNameKey());
    }
    return directChildProjects(rsrc.getNameKey());
}
#end_block

#method_before
Arguments asUser(CurrentUser otherUser) {
    return new Arguments(db, queryProvider, rewriter, opFactories, hasOperands, userFactory, Providers.of(otherUser), permissionBackend, notesFactory, changeDataFactory, commentsUtil, accountResolver, groupBackend, allProjectsName, allUsersName, patchListCache, repoManager, projectCache, childProjectLister, submitDryRun, conflictsCache, index, indexConfig, listMembers, starredChangesUtil, accountCache, allowsDrafts, notesMigration);
}
#method_after
Arguments asUser(CurrentUser otherUser) {
    return new Arguments(db, queryProvider, rewriter, opFactories, hasOperands, userFactory, Providers.of(otherUser), permissionBackend, notesFactory, changeDataFactory, commentsUtil, accountResolver, groupBackend, allProjectsName, allUsersName, patchListCache, repoManager, projectCache, childProjects, submitDryRun, conflictsCache, index, indexConfig, listMembers, starredChangesUtil, accountCache, allowsDrafts, notesMigration);
}
#end_block

#method_before
@Operator
public Predicate<ChangeData> parentproject(String name) {
    return new ParentProjectPredicate(args.projectCache, args.childProjectLister, args.self, name);
}
#method_after
@Operator
public Predicate<ChangeData> parentproject(String name) {
    return new ParentProjectPredicate(args.projectCache, args.childProjects, args.self, name);
}
#end_block

#method_before
private Predicate<ChangeData> getAuthorOrCommitterFullTextPredicate(String who, Function<String, Predicate<ChangeData>> fullPredicateFunc) throws QueryParseException {
    Set<String> parts = SchemaUtil.getNameParts(who);
    if (parts.isEmpty()) {
        throw error("invalid value");
    }
    List<Predicate<ChangeData>> predicates = parts.stream().map(fullPredicateFunc).collect(Collectors.toList());
    return Predicate.and(predicates);
}
#method_after
private Predicate<ChangeData> getAuthorOrCommitterFullTextPredicate(String who, Function<String, Predicate<ChangeData>> fullPredicateFunc) throws QueryParseException {
    Set<String> parts = SchemaUtil.getNameParts(who);
    if (parts.isEmpty()) {
        throw error("invalid value");
    }
    List<Predicate<ChangeData>> predicates = parts.stream().map(fullPredicateFunc).collect(toList());
    return Predicate.and(predicates);
}
#end_block

#method_before
protected static List<Predicate<ChangeData>> predicates(ProjectCache projectCache, ChildProjectLister childProjectLister, Provider<CurrentUser> self, String value) {
    ProjectState projectState = projectCache.get(new Project.NameKey(value));
    if (projectState == null) {
        return Collections.emptyList();
    }
    List<Predicate<ChangeData>> r = new ArrayList<>();
    r.add(new ProjectPredicate(projectState.getName()));
    try {
        for (ProjectInfo p : childProjectLister.recursiveChildProjects(projectState.getNameKey())) {
            r.add(new ProjectPredicate(p.name));
        }
    } catch (PermissionBackendException e) {
        log.warn("cannot check permissions to expand child projects", e);
    }
    return r;
}
#method_after
protected static List<Predicate<ChangeData>> predicates(ProjectCache projectCache, ChildProjects childProjects, Provider<CurrentUser> self, String value) {
    ProjectState projectState = projectCache.get(new Project.NameKey(value));
    if (projectState == null) {
        return Collections.emptyList();
    }
    List<Predicate<ChangeData>> r = new ArrayList<>();
    r.add(new ProjectPredicate(projectState.getName()));
    try {
        for (ProjectInfo p : childProjects.list(projectState.getNameKey())) {
            r.add(new ProjectPredicate(p.name));
        }
    } catch (PermissionBackendException e) {
        log.warn("cannot check permissions to expand child projects", e);
    }
    return r;
}
#end_block

#method_before
@Override
public ServerInfo apply(ConfigResource rsrc) throws MalformedURLException {
    ServerInfo info = new ServerInfo();
    info.auth = getAuthInfo(authConfig, realm);
    info.change = getChangeInfo(config);
    info.download = getDownloadInfo(downloadSchemes, downloadCommands, cloneCommands, archiveFormats);
    info.gerrit = getGerritInfo(config, allProjectsName, allUsersName);
    info.noteDbEnabled = toBoolean(isNoteDbEnabled());
    info.plugin = getPluginInfo();
    info.privateByDefault = config.getBoolean("change", "privateByDefault", false);
    if (Files.exists(sitePaths.site_theme)) {
        info.defaultTheme = "/static/" + SitePaths.THEME_FILENAME;
    }
    info.sshd = getSshdInfo(config);
    info.suggest = getSuggestInfo(config);
    Map<String, String> urlAliases = getUrlAliasesInfo(config);
    info.urlAliases = !urlAliases.isEmpty() ? urlAliases : null;
    info.user = getUserInfo(anonymousCowardName);
    info.receive = getReceiveInfo();
    return info;
}
#method_after
@Override
public ServerInfo apply(ConfigResource rsrc) throws MalformedURLException {
    ServerInfo info = new ServerInfo();
    info.auth = getAuthInfo(authConfig, realm);
    info.change = getChangeInfo(config);
    info.download = getDownloadInfo(downloadSchemes, downloadCommands, cloneCommands, archiveFormats);
    info.gerrit = getGerritInfo(config, allProjectsName, allUsersName);
    info.noteDbEnabled = toBoolean(isNoteDbEnabled());
    info.plugin = getPluginInfo();
    if (Files.exists(sitePaths.site_theme)) {
        info.defaultTheme = "/static/" + SitePaths.THEME_FILENAME;
    }
    info.sshd = getSshdInfo(config);
    info.suggest = getSuggestInfo(config);
    Map<String, String> urlAliases = getUrlAliasesInfo(config);
    info.urlAliases = !urlAliases.isEmpty() ? urlAliases : null;
    info.user = getUserInfo(anonymousCowardName);
    info.receive = getReceiveInfo();
    return info;
}
#end_block

#method_before
private ChangeConfigInfo getChangeInfo(Config cfg) {
    ChangeConfigInfo info = new ChangeConfigInfo();
    info.allowBlame = toBoolean(cfg.getBoolean("change", "allowBlame", true));
    info.allowDrafts = toBoolean(cfg.getBoolean("change", "allowDrafts", true));
    boolean hasAssigneeInIndex = indexes.getSearchIndex().getSchema().hasField(ChangeField.ASSIGNEE);
    info.showAssigneeInChangesTable = toBoolean(cfg.getBoolean("change", "showAssigneeInChangesTable", false) && hasAssigneeInIndex);
    info.largeChange = cfg.getInt("change", "largeChange", 500);
    info.replyTooltip = Optional.ofNullable(cfg.getString("change", null, "replyTooltip")).orElse("Reply and score") + " (Shortcut: a)";
    info.replyLabel = Optional.ofNullable(cfg.getString("change", null, "replyLabel")).orElse("Reply") + "\u2026";
    info.updateDelay = (int) ConfigUtil.getTimeUnit(cfg, "change", null, "updateDelay", 300, TimeUnit.SECONDS);
    info.submitWholeTopic = Submit.wholeTopicEnabled(cfg);
    return info;
}
#method_after
private ChangeConfigInfo getChangeInfo(Config cfg) {
    ChangeConfigInfo info = new ChangeConfigInfo();
    info.allowBlame = toBoolean(cfg.getBoolean("change", "allowBlame", true));
    info.allowDrafts = toBoolean(cfg.getBoolean("change", "allowDrafts", true));
    boolean hasAssigneeInIndex = indexes.getSearchIndex().getSchema().hasField(ChangeField.ASSIGNEE);
    info.showAssigneeInChangesTable = toBoolean(cfg.getBoolean("change", "showAssigneeInChangesTable", false) && hasAssigneeInIndex);
    info.largeChange = cfg.getInt("change", "largeChange", 500);
    info.privateByDefault = toBoolean(cfg.getBoolean("change", "privateByDefault", false));
    info.replyTooltip = Optional.ofNullable(cfg.getString("change", null, "replyTooltip")).orElse("Reply and score") + " (Shortcut: a)";
    info.replyLabel = Optional.ofNullable(cfg.getString("change", null, "replyLabel")).orElse("Reply") + "\u2026";
    info.updateDelay = (int) ConfigUtil.getTimeUnit(cfg, "change", null, "updateDelay", 300, TimeUnit.SECONDS);
    info.submitWholeTopic = Submit.wholeTopicEnabled(cfg);
    return info;
}
#end_block

#method_before
public boolean canRead(ProjectState state, Repository repo, RevCommit commit) {
    Project.NameKey project = state.getNameKey();
    // Look for changes associated with the commit.
    try {
        List<ChangeData> changes = queryProvider.get().enforceVisibility(true).byProjectCommit(project, commit);
        if (!changes.isEmpty()) {
            return true;
        }
    } catch (OrmException e) {
        log.error("Cannot look up change for commit " + commit.name() + " in " + project, e);
    }
    return reachable.isReachableFrom(state, repo, commit, repo.getAllRefs());
}
#method_after
public boolean canRead(ProjectState state, Repository repo, RevCommit commit) {
    Project.NameKey project = state.getNameKey();
    // Look for changes associated with the commit.
    try {
        List<ChangeData> changes = queryProvider.get().enforceVisibility(true).byProjectCommit(project, commit);
        if (!changes.isEmpty()) {
            return true;
        }
    } catch (OrmException e) {
        log.error("Cannot look up change for commit " + commit.name() + " in " + project, e);
    }
    return reachable.fromRefs(state, repo, commit, repo.getAllRefs());
}
#end_block

#method_before
boolean isReachableFromHeadsOrTags(Repository repo, RevCommit commit) {
    try {
        RefDatabase refdb = repo.getRefDatabase();
        Collection<Ref> heads = refdb.getRefs(Constants.R_HEADS).values();
        Collection<Ref> tags = refdb.getRefs(Constants.R_TAGS).values();
        Map<String, Ref> refs = Maps.newHashMapWithExpectedSize(heads.size() + tags.size());
        for (Ref r : Iterables.concat(heads, tags)) {
            refs.put(r.getName(), r);
        }
        return reachable.isReachableFrom(state, repo, commit, refs);
    } catch (IOException e) {
        log.error(String.format("Cannot verify permissions to commit object %s in repository %s", commit.name(), getProject().getNameKey()), e);
        return false;
    }
}
#method_after
boolean isReachableFromHeadsOrTags(Repository repo, RevCommit commit) {
    return reachable.fromHeadsOrTags(state, repo, commit);
}
#end_block

#method_before
public ChangeAttribute asChangeAttribute(ReviewDb db, Change change) {
    ChangeAttribute a = new ChangeAttribute();
    a.project = change.getProject().get();
    a.branch = change.getDest().getShortName();
    a.topic = change.getTopic();
    a.id = change.getKey().get();
    a.number = change.getId().get();
    a.subject = change.getSubject();
    try {
        a.commitMessage = changeDataFactory.create(db, change).commitMessage();
    } catch (Exception e) {
        log.error("Error while getting full commit message for change " + a.number);
    }
    a.url = getChangeUrl(change);
    a.owner = asAccountAttribute(change.getOwner());
    a.assignee = asAccountAttribute(change.getAssignee());
    a.status = change.getStatus();
    a.createdOn = change.getCreatedOn().getTime() / 1000L;
    a.isWip = change.isWorkInProgress() ? true : null;
    a.isPrivate = change.isPrivate() ? true : null;
    return a;
}
#method_after
public ChangeAttribute asChangeAttribute(ReviewDb db, Change change) {
    ChangeAttribute a = new ChangeAttribute();
    a.project = change.getProject().get();
    a.branch = change.getDest().getShortName();
    a.topic = change.getTopic();
    a.id = change.getKey().get();
    a.number = change.getId().get();
    a.subject = change.getSubject();
    try {
        a.commitMessage = changeDataFactory.create(db, change).commitMessage();
    } catch (Exception e) {
        log.error("Error while getting full commit message for change " + a.number);
    }
    a.url = getChangeUrl(change);
    a.owner = asAccountAttribute(change.getOwner());
    a.assignee = asAccountAttribute(change.getAssignee());
    a.status = change.getStatus();
    a.createdOn = change.getCreatedOn().getTime() / 1000L;
    a.wip = change.isWorkInProgress() ? true : null;
    a.isPrivate = change.isPrivate() ? true : null;
    return a;
}
#end_block

#method_before
@Override
protected void configure() {
    bind(EmailExpander.class).toProvider(EmailExpanderProvider.class).in(SINGLETON);
    bind(IdGenerator.class);
    bind(RulesCache.class);
    bind(BlameCache.class).to(BlameCacheImpl.class);
    bind(Sequences.class);
    install(authModule);
    install(AccountCacheImpl.module());
    install(BatchUpdate.module());
    install(ChangeKindCacheImpl.module());
    install(ChangeFinder.module());
    install(ConflictsCacheImpl.module());
    install(GroupCacheImpl.module());
    install(GroupIncludeCacheImpl.module());
    install(MergeabilityCacheImpl.module());
    install(PatchListCacheImpl.module());
    install(ProjectCacheImpl.module());
    install(SectionSortCache.module());
    install(SubmitStrategy.module());
    install(TagCache.module());
    install(OAuthTokenCache.module());
    install(new AccessControlModule());
    install(new CmdLineParserModule());
    install(new EmailModule());
    install(new ExternalIdModule());
    install(new GitModule());
    install(new GroupModule());
    install(new NoteDbModule(cfg));
    install(new PrologModule());
    install(new ReceiveCommitsModule());
    install(new SshAddressesModule());
    install(ThreadLocalRequestContext.module());
    bind(AccountResolver.class);
    factory(AddReviewerSender.Factory.class);
    factory(DeleteReviewerSender.Factory.class);
    factory(AddKeySender.Factory.class);
    factory(CapabilityCollection.Factory.class);
    factory(ChangeData.AssistedFactory.class);
    factory(ChangeJson.AssistedFactory.class);
    factory(CreateChangeSender.Factory.class);
    factory(GroupMembers.Factory.class);
    factory(EmailMerge.Factory.class);
    factory(MergedSender.Factory.class);
    factory(MergeUtil.Factory.class);
    factory(PatchScriptFactory.Factory.class);
    factory(PluginUser.Factory.class);
    factory(ProjectNode.Factory.class);
    factory(ProjectState.Factory.class);
    factory(RegisterNewEmailSender.Factory.class);
    factory(ReplacePatchSetSender.Factory.class);
    factory(SetAssigneeSender.Factory.class);
    factory(VisibleRefFilter.Factory.class);
    bind(PermissionCollection.Factory.class);
    bind(AccountVisibility.class).toProvider(AccountVisibilityProvider.class).in(SINGLETON);
    factory(ProjectOwnerGroupsProvider.Factory.class);
    factory(SubmitRuleEvaluator.Factory.class);
    bind(AuthBackend.class).to(UniversalAuthBackend.class).in(SINGLETON);
    DynamicSet.setOf(binder(), AuthBackend.class);
    bind(GroupControl.Factory.class).in(SINGLETON);
    bind(GroupControl.GenericFactory.class).in(SINGLETON);
    bind(FileTypeRegistry.class).to(MimeUtilFileTypeRegistry.class);
    bind(ToolsCatalog.class);
    bind(EventFactory.class);
    bind(TransferConfig.class);
    bind(GcConfig.class);
    bind(ChangeCleanupConfig.class);
    bind(AccountDeactivator.class);
    bind(ApprovalsUtil.class);
    bind(RuntimeInstance.class).toProvider(VelocityRuntimeProvider.class);
    bind(SoyTofu.class).annotatedWith(MailTemplates.class).toProvider(MailSoyTofuProvider.class);
    bind(FromAddressGenerator.class).toProvider(FromAddressGeneratorProvider.class).in(SINGLETON);
    bind(Boolean.class).annotatedWith(DisableReverseDnsLookup.class).toProvider(DisableReverseDnsLookupProvider.class).in(SINGLETON);
    bind(PatchSetInfoFactory.class);
    bind(IdentifiedUser.GenericFactory.class).in(SINGLETON);
    bind(AccountControl.Factory.class);
    install(new AuditModule());
    bind(UiActions.class);
    install(new com.google.gerrit.server.access.Module());
    install(new com.google.gerrit.server.account.Module());
    install(new com.google.gerrit.server.api.Module());
    install(new com.google.gerrit.server.change.Module());
    install(new com.google.gerrit.server.config.Module());
    install(new com.google.gerrit.server.group.Module());
    install(new com.google.gerrit.server.project.Module());
    bind(GitReferenceUpdated.class);
    DynamicMap.mapOf(binder(), new TypeLiteral<Cache<?, ?>>() {
    });
    DynamicSet.setOf(binder(), CacheRemovalListener.class);
    DynamicMap.mapOf(binder(), CapabilityDefinition.class);
    DynamicSet.setOf(binder(), GitReferenceUpdatedListener.class);
    DynamicSet.setOf(binder(), AssigneeChangedListener.class);
    DynamicSet.setOf(binder(), ChangeAbandonedListener.class);
    DynamicSet.setOf(binder(), CommentAddedListener.class);
    DynamicSet.setOf(binder(), HashtagsEditedListener.class);
    DynamicSet.setOf(binder(), ChangeMergedListener.class);
    DynamicSet.setOf(binder(), ChangeRestoredListener.class);
    DynamicSet.setOf(binder(), ChangeRevertedListener.class);
    DynamicSet.setOf(binder(), PrivateStateChangedListener.class);
    DynamicSet.setOf(binder(), ReviewerAddedListener.class);
    DynamicSet.setOf(binder(), ReviewerDeletedListener.class);
    DynamicSet.setOf(binder(), VoteDeletedListener.class);
    DynamicSet.setOf(binder(), RevisionCreatedListener.class);
    DynamicSet.setOf(binder(), TopicEditedListener.class);
    DynamicSet.setOf(binder(), AgreementSignupListener.class);
    DynamicSet.setOf(binder(), PluginEventListener.class);
    DynamicSet.setOf(binder(), ReceivePackInitializer.class);
    DynamicSet.setOf(binder(), PostReceiveHook.class);
    DynamicSet.setOf(binder(), PreUploadHook.class);
    DynamicSet.setOf(binder(), PostUploadHook.class);
    DynamicSet.setOf(binder(), AccountIndexedListener.class);
    DynamicSet.setOf(binder(), ChangeIndexedListener.class);
    DynamicSet.setOf(binder(), GroupIndexedListener.class);
    DynamicSet.setOf(binder(), NewProjectCreatedListener.class);
    DynamicSet.setOf(binder(), ProjectDeletedListener.class);
    DynamicSet.setOf(binder(), GarbageCollectorListener.class);
    DynamicSet.setOf(binder(), HeadUpdatedListener.class);
    DynamicSet.setOf(binder(), UsageDataPublishedListener.class);
    DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(ReindexAfterRefUpdate.class);
    DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(ProjectConfigEntry.UpdateChecker.class);
    DynamicSet.setOf(binder(), EventListener.class);
    DynamicSet.bind(binder(), EventListener.class).to(EventsMetrics.class);
    DynamicSet.setOf(binder(), UserScopedEventListener.class);
    DynamicSet.setOf(binder(), CommitValidationListener.class);
    DynamicSet.setOf(binder(), ChangeMessageModifier.class);
    DynamicSet.setOf(binder(), RefOperationValidationListener.class);
    DynamicSet.setOf(binder(), OnSubmitValidationListener.class);
    DynamicSet.setOf(binder(), MergeValidationListener.class);
    DynamicSet.setOf(binder(), ProjectCreationValidationListener.class);
    DynamicSet.setOf(binder(), GroupCreationValidationListener.class);
    DynamicSet.setOf(binder(), HashtagValidationListener.class);
    DynamicSet.setOf(binder(), OutgoingEmailValidationListener.class);
    DynamicItem.itemOf(binder(), AvatarProvider.class);
    DynamicSet.setOf(binder(), LifecycleListener.class);
    DynamicSet.setOf(binder(), TopMenu.class);
    DynamicSet.setOf(binder(), MessageOfTheDay.class);
    DynamicMap.mapOf(binder(), DownloadScheme.class);
    DynamicMap.mapOf(binder(), DownloadCommand.class);
    DynamicMap.mapOf(binder(), CloneCommand.class);
    DynamicMap.mapOf(binder(), ReviewerSuggestion.class);
    DynamicSet.setOf(binder(), ExternalIncludedIn.class);
    DynamicMap.mapOf(binder(), ProjectConfigEntry.class);
    DynamicSet.setOf(binder(), PatchSetWebLink.class);
    DynamicSet.setOf(binder(), ParentWebLink.class);
    DynamicSet.setOf(binder(), FileWebLink.class);
    DynamicSet.setOf(binder(), FileHistoryWebLink.class);
    DynamicSet.setOf(binder(), DiffWebLink.class);
    DynamicSet.setOf(binder(), ProjectWebLink.class);
    DynamicSet.setOf(binder(), BranchWebLink.class);
    DynamicSet.setOf(binder(), TagWebLink.class);
    DynamicMap.mapOf(binder(), OAuthLoginProvider.class);
    DynamicItem.itemOf(binder(), OAuthTokenEncrypter.class);
    DynamicSet.setOf(binder(), AccountExternalIdCreator.class);
    DynamicSet.setOf(binder(), WebUiPlugin.class);
    DynamicItem.itemOf(binder(), AccountPatchReviewStore.class);
    DynamicSet.setOf(binder(), AssigneeValidationListener.class);
    DynamicSet.setOf(binder(), ActionVisitor.class);
    DynamicMap.mapOf(binder(), MailFilter.class);
    bind(MailFilter.class).annotatedWith(Exports.named("ListMailFilter")).to(ListMailFilter.class);
    factory(UploadValidators.Factory.class);
    DynamicSet.setOf(binder(), UploadValidationListener.class);
    DynamicMap.mapOf(binder(), ChangeQueryBuilder.ChangeOperatorFactory.class);
    DynamicMap.mapOf(binder(), ChangeQueryBuilder.ChangeHasOperandFactory.class);
    DynamicMap.mapOf(binder(), ChangeQueryProcessor.ChangeAttributeFactory.class);
    install(new GitwebConfig.LegacyModule(cfg));
    bind(AnonymousUser.class);
    factory(AbandonOp.Factory.class);
    factory(AccountMergeValidator.Factory.class);
    factory(RefOperationValidators.Factory.class);
    factory(OnSubmitValidators.Factory.class);
    factory(MergeValidators.Factory.class);
    factory(ProjectConfigValidator.Factory.class);
    factory(NotesBranchUtil.Factory.class);
    factory(MergedByPushOp.Factory.class);
    factory(GitModules.Factory.class);
    factory(VersionedAuthorizedKeys.Factory.class);
    bind(AccountManager.class);
    factory(ChangeUserName.Factory.class);
    bind(new TypeLiteral<List<CommentLinkInfo>>() {
    }).toProvider(CommentLinkProvider.class).in(SINGLETON);
    bind(ReloadPluginListener.class).annotatedWith(UniqueAnnotations.create()).to(PluginConfigFactory.class);
}
#method_after
@Override
protected void configure() {
    bind(EmailExpander.class).toProvider(EmailExpanderProvider.class).in(SINGLETON);
    bind(IdGenerator.class);
    bind(RulesCache.class);
    bind(BlameCache.class).to(BlameCacheImpl.class);
    bind(Sequences.class);
    install(authModule);
    install(AccountCacheImpl.module());
    install(BatchUpdate.module());
    install(ChangeKindCacheImpl.module());
    install(ChangeFinder.module());
    install(ConflictsCacheImpl.module());
    install(GroupCacheImpl.module());
    install(GroupIncludeCacheImpl.module());
    install(MergeabilityCacheImpl.module());
    install(PatchListCacheImpl.module());
    install(ProjectCacheImpl.module());
    install(SectionSortCache.module());
    install(SubmitStrategy.module());
    install(TagCache.module());
    install(OAuthTokenCache.module());
    install(new AccessControlModule());
    install(new CmdLineParserModule());
    install(new EmailModule());
    install(new ExternalIdModule());
    install(new GitModule());
    install(new GroupModule());
    install(new NoteDbModule(cfg));
    install(new PrologModule());
    install(new ReceiveCommitsModule());
    install(new SshAddressesModule());
    install(ThreadLocalRequestContext.module());
    bind(AccountResolver.class);
    factory(AddReviewerSender.Factory.class);
    factory(DeleteReviewerSender.Factory.class);
    factory(AddKeySender.Factory.class);
    factory(CapabilityCollection.Factory.class);
    factory(ChangeData.AssistedFactory.class);
    factory(ChangeJson.AssistedFactory.class);
    factory(CreateChangeSender.Factory.class);
    factory(GroupMembers.Factory.class);
    factory(EmailMerge.Factory.class);
    factory(MergedSender.Factory.class);
    factory(MergeUtil.Factory.class);
    factory(PatchScriptFactory.Factory.class);
    factory(PluginUser.Factory.class);
    factory(ProjectNode.Factory.class);
    factory(ProjectState.Factory.class);
    factory(RegisterNewEmailSender.Factory.class);
    factory(ReplacePatchSetSender.Factory.class);
    factory(SetAssigneeSender.Factory.class);
    factory(VisibleRefFilter.Factory.class);
    bind(PermissionCollection.Factory.class);
    bind(AccountVisibility.class).toProvider(AccountVisibilityProvider.class).in(SINGLETON);
    factory(ProjectOwnerGroupsProvider.Factory.class);
    factory(SubmitRuleEvaluator.Factory.class);
    bind(AuthBackend.class).to(UniversalAuthBackend.class).in(SINGLETON);
    DynamicSet.setOf(binder(), AuthBackend.class);
    bind(GroupControl.Factory.class).in(SINGLETON);
    bind(GroupControl.GenericFactory.class).in(SINGLETON);
    bind(FileTypeRegistry.class).to(MimeUtilFileTypeRegistry.class);
    bind(ToolsCatalog.class);
    bind(EventFactory.class);
    bind(TransferConfig.class);
    bind(GcConfig.class);
    bind(ChangeCleanupConfig.class);
    bind(AccountDeactivator.class);
    bind(ApprovalsUtil.class);
    bind(RuntimeInstance.class).toProvider(VelocityRuntimeProvider.class);
    bind(SoyTofu.class).annotatedWith(MailTemplates.class).toProvider(MailSoyTofuProvider.class);
    bind(FromAddressGenerator.class).toProvider(FromAddressGeneratorProvider.class).in(SINGLETON);
    bind(Boolean.class).annotatedWith(DisableReverseDnsLookup.class).toProvider(DisableReverseDnsLookupProvider.class).in(SINGLETON);
    bind(PatchSetInfoFactory.class);
    bind(IdentifiedUser.GenericFactory.class).in(SINGLETON);
    bind(AccountControl.Factory.class);
    install(new AuditModule());
    bind(UiActions.class);
    install(new com.google.gerrit.server.access.Module());
    install(new com.google.gerrit.server.account.Module());
    install(new com.google.gerrit.server.api.Module());
    install(new com.google.gerrit.server.change.Module());
    install(new com.google.gerrit.server.config.Module());
    install(new com.google.gerrit.server.group.Module());
    install(new com.google.gerrit.server.project.Module());
    bind(GitReferenceUpdated.class);
    DynamicMap.mapOf(binder(), new TypeLiteral<Cache<?, ?>>() {
    });
    DynamicSet.setOf(binder(), CacheRemovalListener.class);
    DynamicMap.mapOf(binder(), CapabilityDefinition.class);
    DynamicSet.setOf(binder(), GitReferenceUpdatedListener.class);
    DynamicSet.setOf(binder(), AssigneeChangedListener.class);
    DynamicSet.setOf(binder(), ChangeAbandonedListener.class);
    DynamicSet.setOf(binder(), CommentAddedListener.class);
    DynamicSet.setOf(binder(), HashtagsEditedListener.class);
    DynamicSet.setOf(binder(), ChangeMergedListener.class);
    DynamicSet.setOf(binder(), ChangeRestoredListener.class);
    DynamicSet.setOf(binder(), ChangeRevertedListener.class);
    DynamicSet.setOf(binder(), PrivateStateChangedListener.class);
    DynamicSet.setOf(binder(), ReviewerAddedListener.class);
    DynamicSet.setOf(binder(), ReviewerDeletedListener.class);
    DynamicSet.setOf(binder(), VoteDeletedListener.class);
    DynamicSet.setOf(binder(), WorkInProgressStateChangedListener.class);
    DynamicSet.setOf(binder(), RevisionCreatedListener.class);
    DynamicSet.setOf(binder(), TopicEditedListener.class);
    DynamicSet.setOf(binder(), AgreementSignupListener.class);
    DynamicSet.setOf(binder(), PluginEventListener.class);
    DynamicSet.setOf(binder(), ReceivePackInitializer.class);
    DynamicSet.setOf(binder(), PostReceiveHook.class);
    DynamicSet.setOf(binder(), PreUploadHook.class);
    DynamicSet.setOf(binder(), PostUploadHook.class);
    DynamicSet.setOf(binder(), AccountIndexedListener.class);
    DynamicSet.setOf(binder(), ChangeIndexedListener.class);
    DynamicSet.setOf(binder(), GroupIndexedListener.class);
    DynamicSet.setOf(binder(), NewProjectCreatedListener.class);
    DynamicSet.setOf(binder(), ProjectDeletedListener.class);
    DynamicSet.setOf(binder(), GarbageCollectorListener.class);
    DynamicSet.setOf(binder(), HeadUpdatedListener.class);
    DynamicSet.setOf(binder(), UsageDataPublishedListener.class);
    DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(ReindexAfterRefUpdate.class);
    DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(ProjectConfigEntry.UpdateChecker.class);
    DynamicSet.setOf(binder(), EventListener.class);
    DynamicSet.bind(binder(), EventListener.class).to(EventsMetrics.class);
    DynamicSet.setOf(binder(), UserScopedEventListener.class);
    DynamicSet.setOf(binder(), CommitValidationListener.class);
    DynamicSet.setOf(binder(), ChangeMessageModifier.class);
    DynamicSet.setOf(binder(), RefOperationValidationListener.class);
    DynamicSet.setOf(binder(), OnSubmitValidationListener.class);
    DynamicSet.setOf(binder(), MergeValidationListener.class);
    DynamicSet.setOf(binder(), ProjectCreationValidationListener.class);
    DynamicSet.setOf(binder(), GroupCreationValidationListener.class);
    DynamicSet.setOf(binder(), HashtagValidationListener.class);
    DynamicSet.setOf(binder(), OutgoingEmailValidationListener.class);
    DynamicItem.itemOf(binder(), AvatarProvider.class);
    DynamicSet.setOf(binder(), LifecycleListener.class);
    DynamicSet.setOf(binder(), TopMenu.class);
    DynamicSet.setOf(binder(), MessageOfTheDay.class);
    DynamicMap.mapOf(binder(), DownloadScheme.class);
    DynamicMap.mapOf(binder(), DownloadCommand.class);
    DynamicMap.mapOf(binder(), CloneCommand.class);
    DynamicMap.mapOf(binder(), ReviewerSuggestion.class);
    DynamicSet.setOf(binder(), ExternalIncludedIn.class);
    DynamicMap.mapOf(binder(), ProjectConfigEntry.class);
    DynamicSet.setOf(binder(), PatchSetWebLink.class);
    DynamicSet.setOf(binder(), ParentWebLink.class);
    DynamicSet.setOf(binder(), FileWebLink.class);
    DynamicSet.setOf(binder(), FileHistoryWebLink.class);
    DynamicSet.setOf(binder(), DiffWebLink.class);
    DynamicSet.setOf(binder(), ProjectWebLink.class);
    DynamicSet.setOf(binder(), BranchWebLink.class);
    DynamicSet.setOf(binder(), TagWebLink.class);
    DynamicMap.mapOf(binder(), OAuthLoginProvider.class);
    DynamicItem.itemOf(binder(), OAuthTokenEncrypter.class);
    DynamicSet.setOf(binder(), AccountExternalIdCreator.class);
    DynamicSet.setOf(binder(), WebUiPlugin.class);
    DynamicItem.itemOf(binder(), AccountPatchReviewStore.class);
    DynamicSet.setOf(binder(), AssigneeValidationListener.class);
    DynamicSet.setOf(binder(), ActionVisitor.class);
    DynamicMap.mapOf(binder(), MailFilter.class);
    bind(MailFilter.class).annotatedWith(Exports.named("ListMailFilter")).to(ListMailFilter.class);
    factory(UploadValidators.Factory.class);
    DynamicSet.setOf(binder(), UploadValidationListener.class);
    DynamicMap.mapOf(binder(), ChangeQueryBuilder.ChangeOperatorFactory.class);
    DynamicMap.mapOf(binder(), ChangeQueryBuilder.ChangeHasOperandFactory.class);
    DynamicMap.mapOf(binder(), ChangeQueryProcessor.ChangeAttributeFactory.class);
    install(new GitwebConfig.LegacyModule(cfg));
    bind(AnonymousUser.class);
    factory(AbandonOp.Factory.class);
    factory(AccountMergeValidator.Factory.class);
    factory(RefOperationValidators.Factory.class);
    factory(OnSubmitValidators.Factory.class);
    factory(MergeValidators.Factory.class);
    factory(ProjectConfigValidator.Factory.class);
    factory(NotesBranchUtil.Factory.class);
    factory(MergedByPushOp.Factory.class);
    factory(GitModules.Factory.class);
    factory(VersionedAuthorizedKeys.Factory.class);
    bind(AccountManager.class);
    factory(ChangeUserName.Factory.class);
    bind(new TypeLiteral<List<CommentLinkInfo>>() {
    }).toProvider(CommentLinkProvider.class).in(SINGLETON);
    bind(ReloadPluginListener.class).annotatedWith(UniqueAnnotations.create()).to(PluginConfigFactory.class);
}
#end_block

#method_before
@Override
public void postUpdate(Context ctx) {
    privateStateChanged.fire(change, ctx.getAccount(), ctx.getWhen(), isPrivate);
}
#method_after
@Override
public void postUpdate(Context ctx) {
    privateStateChanged.fire(change, ctx.getAccount(), ctx.getWhen());
}
#end_block

#method_before
@Override
protected void configure() {
    DynamicSet.bind(binder(), AssigneeChangedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), ChangeAbandonedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), ChangeMergedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), ChangeRestoredListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), PrivateStateChangedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), CommentAddedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), HashtagsEditedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), NewProjectCreatedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), ReviewerAddedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), ReviewerDeletedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), RevisionCreatedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), TopicEditedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), VoteDeletedListener.class).to(StreamEventsApiListener.class);
}
#method_after
@Override
protected void configure() {
    DynamicSet.bind(binder(), AssigneeChangedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), ChangeAbandonedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), ChangeMergedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), ChangeRestoredListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), CommentAddedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), HashtagsEditedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), NewProjectCreatedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), PrivateStateChangedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), ReviewerAddedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), ReviewerDeletedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), RevisionCreatedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), TopicEditedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), VoteDeletedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), WorkInProgressStateChangedListener.class).to(StreamEventsApiListener.class);
}
#end_block

#method_before
@Override
public void onPrivateStateChanged(PrivateStateChangedListener.Event ev) {
    try {
        Change change = getChange(ev.getChange());
        PrivateStateChangedEvent event = new PrivateStateChangedEvent(change);
        event.change = changeAttributeSupplier(change);
        event.changer = accountAttributeSupplier(ev.getWho());
        event.isPrivate = ev.isPrivate();
        dispatcher.get().postEvent(change, event);
    } catch (OrmException | PermissionBackendException e) {
        log.error("Failed to dispatch event", e);
    }
}
#method_after
@Override
public void onPrivateStateChanged(PrivateStateChangedListener.Event ev) {
    try {
        Change change = getChange(ev.getChange());
        PrivateStateChangedEvent event = new PrivateStateChangedEvent(change);
        event.change = changeAttributeSupplier(change);
        event.changer = accountAttributeSupplier(ev.getWho());
        dispatcher.get().postEvent(change, event);
    } catch (OrmException | PermissionBackendException e) {
        log.error("Failed to dispatch event", e);
    }
}
#end_block

#method_before
public void fire(Change change, Account account, Timestamp when, boolean isPrivate) {
    if (!listeners.iterator().hasNext()) {
        return;
    }
    try {
        Event event = new Event(util.changeInfo(change), util.accountInfo(account), isPrivate, when);
        for (PrivateStateChangedListener l : listeners) {
            try {
                l.onPrivateStateChanged(event);
            } catch (Exception e) {
                util.logEventListenerError(event, l, e);
            }
        }
    } catch (OrmException e) {
        log.error("Couldn't fire event", e);
    }
}
#method_after
public void fire(Change change, Account account, Timestamp when) {
    if (!listeners.iterator().hasNext()) {
        return;
    }
    try {
        Event event = new Event(util.changeInfo(change), util.accountInfo(account), when);
        for (PrivateStateChangedListener l : listeners) {
            try {
                l.onPrivateStateChanged(event);
            } catch (Exception e) {
                util.logEventListenerError(event, l, e);
            }
        }
    } catch (OrmException e) {
        log.error("Couldn't fire event", e);
    }
}
#end_block

#method_before
@Override
public void postUpdate(Context ctx) {
    stateChanged.fire(change, ctx.getAccount(), ctx.getWhen(), workInProgress);
    if (workInProgress || notify.ordinal() < NotifyHandling.OWNER_REVIEWERS.ordinal()) {
        return;
    }
    email.create(notify, ImmutableListMultimap.of(), notes, ps, ctx.getIdentifiedUser(), cmsg, ImmutableList.of(), cmsg.getMessage(), ImmutableList.of()).sendAsync();
}
#method_after
@Override
public void postUpdate(Context ctx) {
    stateChanged.fire(change, ctx.getAccount(), ctx.getWhen());
    if (workInProgress || notify.ordinal() < NotifyHandling.OWNER_REVIEWERS.ordinal()) {
        return;
    }
    email.create(notify, ImmutableListMultimap.of(), notes, ps, ctx.getIdentifiedUser(), cmsg, ImmutableList.of(), cmsg.getMessage(), ImmutableList.of()).sendAsync();
}
#end_block

#method_before
public void fire(Change change, Account account, Timestamp when, boolean isWip) {
    if (!listeners.iterator().hasNext()) {
        return;
    }
    try {
        Event event = new Event(util.changeInfo(change), util.accountInfo(account), isWip, when);
        for (WorkInProgressStateChangedListener l : listeners) {
            try {
                l.onWorkInProgressStateChanged(event);
            } catch (Exception e) {
                util.logEventListenerError(event, l, e);
            }
        }
    } catch (OrmException e) {
        log.error("Couldn't fire event", e);
    }
}
#method_after
public void fire(Change change, Account account, Timestamp when) {
    if (!listeners.iterator().hasNext()) {
        return;
    }
    try {
        Event event = new Event(util.changeInfo(change), util.accountInfo(account), when);
        for (WorkInProgressStateChangedListener l : listeners) {
            try {
                l.onWorkInProgressStateChanged(event);
            } catch (Exception e) {
                util.logEventListenerError(event, l, e);
            }
        }
    } catch (OrmException e) {
        log.error("Couldn't fire event", e);
    }
}
#end_block

#method_before
@Override
protected void configure() {
    DynamicSet.bind(binder(), AssigneeChangedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), ChangeAbandonedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), ChangeMergedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), ChangeRestoredListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), WorkInProgressStateChangedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), CommentAddedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), HashtagsEditedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), NewProjectCreatedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), ReviewerAddedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), ReviewerDeletedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), RevisionCreatedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), TopicEditedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), VoteDeletedListener.class).to(StreamEventsApiListener.class);
}
#method_after
@Override
protected void configure() {
    DynamicSet.bind(binder(), AssigneeChangedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), ChangeAbandonedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), ChangeMergedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), ChangeRestoredListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), CommentAddedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), HashtagsEditedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), NewProjectCreatedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), ReviewerAddedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), ReviewerDeletedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), RevisionCreatedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), TopicEditedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), VoteDeletedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), WorkInProgressStateChangedListener.class).to(StreamEventsApiListener.class);
}
#end_block

#method_before
@Override
public void onWorkInProgressStateChanged(WorkInProgressStateChangedListener.Event ev) {
    try {
        Change change = getChange(ev.getChange());
        WorkInProgressStateChangedEvent event = new WorkInProgressStateChangedEvent(change);
        event.change = changeAttributeSupplier(change);
        event.changer = accountAttributeSupplier(ev.getWho());
        event.isWip = ev.isWip();
        dispatcher.get().postEvent(change, event);
    } catch (OrmException | PermissionBackendException e) {
        log.error("Failed to dispatch event", e);
    }
}
#method_after
@Override
public void onWorkInProgressStateChanged(WorkInProgressStateChangedListener.Event ev) {
    try {
        Change change = getChange(ev.getChange());
        WorkInProgressStateChangedEvent event = new WorkInProgressStateChangedEvent(change);
        event.change = changeAttributeSupplier(change);
        event.changer = accountAttributeSupplier(ev.getWho());
        dispatcher.get().postEvent(change, event);
    } catch (OrmException | PermissionBackendException e) {
        log.error("Failed to dispatch event", e);
    }
}
#end_block

#method_before
@Override
protected void configure() {
    bind(EmailExpander.class).toProvider(EmailExpanderProvider.class).in(SINGLETON);
    bind(IdGenerator.class);
    bind(RulesCache.class);
    bind(BlameCache.class).to(BlameCacheImpl.class);
    bind(Sequences.class);
    install(authModule);
    install(AccountCacheImpl.module());
    install(BatchUpdate.module());
    install(ChangeKindCacheImpl.module());
    install(ChangeFinder.module());
    install(ConflictsCacheImpl.module());
    install(GroupCacheImpl.module());
    install(GroupIncludeCacheImpl.module());
    install(MergeabilityCacheImpl.module());
    install(PatchListCacheImpl.module());
    install(ProjectCacheImpl.module());
    install(SectionSortCache.module());
    install(SubmitStrategy.module());
    install(TagCache.module());
    install(OAuthTokenCache.module());
    install(new AccessControlModule());
    install(new CmdLineParserModule());
    install(new EmailModule());
    install(new ExternalIdModule());
    install(new GitModule());
    install(new GroupModule());
    install(new NoteDbModule(cfg));
    install(new PrologModule());
    install(new ReceiveCommitsModule());
    install(new SshAddressesModule());
    install(ThreadLocalRequestContext.module());
    bind(AccountResolver.class);
    factory(AddReviewerSender.Factory.class);
    factory(DeleteReviewerSender.Factory.class);
    factory(AddKeySender.Factory.class);
    factory(CapabilityCollection.Factory.class);
    factory(ChangeData.AssistedFactory.class);
    factory(ChangeJson.AssistedFactory.class);
    factory(CreateChangeSender.Factory.class);
    factory(GroupMembers.Factory.class);
    factory(EmailMerge.Factory.class);
    factory(MergedSender.Factory.class);
    factory(MergeUtil.Factory.class);
    factory(PatchScriptFactory.Factory.class);
    factory(PluginUser.Factory.class);
    factory(ProjectNode.Factory.class);
    factory(ProjectState.Factory.class);
    factory(RegisterNewEmailSender.Factory.class);
    factory(ReplacePatchSetSender.Factory.class);
    factory(SetAssigneeSender.Factory.class);
    factory(VisibleRefFilter.Factory.class);
    bind(PermissionCollection.Factory.class);
    bind(AccountVisibility.class).toProvider(AccountVisibilityProvider.class).in(SINGLETON);
    factory(ProjectOwnerGroupsProvider.Factory.class);
    factory(SubmitRuleEvaluator.Factory.class);
    bind(AuthBackend.class).to(UniversalAuthBackend.class).in(SINGLETON);
    DynamicSet.setOf(binder(), AuthBackend.class);
    bind(GroupControl.Factory.class).in(SINGLETON);
    bind(GroupControl.GenericFactory.class).in(SINGLETON);
    bind(FileTypeRegistry.class).to(MimeUtilFileTypeRegistry.class);
    bind(ToolsCatalog.class);
    bind(EventFactory.class);
    bind(TransferConfig.class);
    bind(GcConfig.class);
    bind(ChangeCleanupConfig.class);
    bind(AccountDeactivator.class);
    bind(ApprovalsUtil.class);
    bind(RuntimeInstance.class).toProvider(VelocityRuntimeProvider.class);
    bind(SoyTofu.class).annotatedWith(MailTemplates.class).toProvider(MailSoyTofuProvider.class);
    bind(FromAddressGenerator.class).toProvider(FromAddressGeneratorProvider.class).in(SINGLETON);
    bind(Boolean.class).annotatedWith(DisableReverseDnsLookup.class).toProvider(DisableReverseDnsLookupProvider.class).in(SINGLETON);
    bind(PatchSetInfoFactory.class);
    bind(IdentifiedUser.GenericFactory.class).in(SINGLETON);
    bind(AccountControl.Factory.class);
    install(new AuditModule());
    bind(UiActions.class);
    install(new com.google.gerrit.server.access.Module());
    install(new com.google.gerrit.server.account.Module());
    install(new com.google.gerrit.server.api.Module());
    install(new com.google.gerrit.server.change.Module());
    install(new com.google.gerrit.server.config.Module());
    install(new com.google.gerrit.server.group.Module());
    install(new com.google.gerrit.server.project.Module());
    bind(GitReferenceUpdated.class);
    DynamicMap.mapOf(binder(), new TypeLiteral<Cache<?, ?>>() {
    });
    DynamicSet.setOf(binder(), CacheRemovalListener.class);
    DynamicMap.mapOf(binder(), CapabilityDefinition.class);
    DynamicSet.setOf(binder(), GitReferenceUpdatedListener.class);
    DynamicSet.setOf(binder(), AssigneeChangedListener.class);
    DynamicSet.setOf(binder(), ChangeAbandonedListener.class);
    DynamicSet.setOf(binder(), CommentAddedListener.class);
    DynamicSet.setOf(binder(), HashtagsEditedListener.class);
    DynamicSet.setOf(binder(), ChangeMergedListener.class);
    DynamicSet.setOf(binder(), ChangeRestoredListener.class);
    DynamicSet.setOf(binder(), ChangeRevertedListener.class);
    DynamicSet.setOf(binder(), WorkInProgressStateChangedListener.class);
    DynamicSet.setOf(binder(), ReviewerAddedListener.class);
    DynamicSet.setOf(binder(), ReviewerDeletedListener.class);
    DynamicSet.setOf(binder(), VoteDeletedListener.class);
    DynamicSet.setOf(binder(), RevisionCreatedListener.class);
    DynamicSet.setOf(binder(), TopicEditedListener.class);
    DynamicSet.setOf(binder(), AgreementSignupListener.class);
    DynamicSet.setOf(binder(), PluginEventListener.class);
    DynamicSet.setOf(binder(), ReceivePackInitializer.class);
    DynamicSet.setOf(binder(), PostReceiveHook.class);
    DynamicSet.setOf(binder(), PreUploadHook.class);
    DynamicSet.setOf(binder(), PostUploadHook.class);
    DynamicSet.setOf(binder(), AccountIndexedListener.class);
    DynamicSet.setOf(binder(), ChangeIndexedListener.class);
    DynamicSet.setOf(binder(), GroupIndexedListener.class);
    DynamicSet.setOf(binder(), NewProjectCreatedListener.class);
    DynamicSet.setOf(binder(), ProjectDeletedListener.class);
    DynamicSet.setOf(binder(), GarbageCollectorListener.class);
    DynamicSet.setOf(binder(), HeadUpdatedListener.class);
    DynamicSet.setOf(binder(), UsageDataPublishedListener.class);
    DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(ReindexAfterRefUpdate.class);
    DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(ProjectConfigEntry.UpdateChecker.class);
    DynamicSet.setOf(binder(), EventListener.class);
    DynamicSet.bind(binder(), EventListener.class).to(EventsMetrics.class);
    DynamicSet.setOf(binder(), UserScopedEventListener.class);
    DynamicSet.setOf(binder(), CommitValidationListener.class);
    DynamicSet.setOf(binder(), ChangeMessageModifier.class);
    DynamicSet.setOf(binder(), RefOperationValidationListener.class);
    DynamicSet.setOf(binder(), OnSubmitValidationListener.class);
    DynamicSet.setOf(binder(), MergeValidationListener.class);
    DynamicSet.setOf(binder(), ProjectCreationValidationListener.class);
    DynamicSet.setOf(binder(), GroupCreationValidationListener.class);
    DynamicSet.setOf(binder(), HashtagValidationListener.class);
    DynamicSet.setOf(binder(), OutgoingEmailValidationListener.class);
    DynamicItem.itemOf(binder(), AvatarProvider.class);
    DynamicSet.setOf(binder(), LifecycleListener.class);
    DynamicSet.setOf(binder(), TopMenu.class);
    DynamicSet.setOf(binder(), MessageOfTheDay.class);
    DynamicMap.mapOf(binder(), DownloadScheme.class);
    DynamicMap.mapOf(binder(), DownloadCommand.class);
    DynamicMap.mapOf(binder(), CloneCommand.class);
    DynamicMap.mapOf(binder(), ReviewerSuggestion.class);
    DynamicSet.setOf(binder(), ExternalIncludedIn.class);
    DynamicMap.mapOf(binder(), ProjectConfigEntry.class);
    DynamicSet.setOf(binder(), PatchSetWebLink.class);
    DynamicSet.setOf(binder(), ParentWebLink.class);
    DynamicSet.setOf(binder(), FileWebLink.class);
    DynamicSet.setOf(binder(), FileHistoryWebLink.class);
    DynamicSet.setOf(binder(), DiffWebLink.class);
    DynamicSet.setOf(binder(), ProjectWebLink.class);
    DynamicSet.setOf(binder(), BranchWebLink.class);
    DynamicSet.setOf(binder(), TagWebLink.class);
    DynamicMap.mapOf(binder(), OAuthLoginProvider.class);
    DynamicItem.itemOf(binder(), OAuthTokenEncrypter.class);
    DynamicSet.setOf(binder(), AccountExternalIdCreator.class);
    DynamicSet.setOf(binder(), WebUiPlugin.class);
    DynamicItem.itemOf(binder(), AccountPatchReviewStore.class);
    DynamicSet.setOf(binder(), AssigneeValidationListener.class);
    DynamicSet.setOf(binder(), ActionVisitor.class);
    DynamicMap.mapOf(binder(), MailFilter.class);
    bind(MailFilter.class).annotatedWith(Exports.named("ListMailFilter")).to(ListMailFilter.class);
    factory(UploadValidators.Factory.class);
    DynamicSet.setOf(binder(), UploadValidationListener.class);
    DynamicMap.mapOf(binder(), ChangeQueryBuilder.ChangeOperatorFactory.class);
    DynamicMap.mapOf(binder(), ChangeQueryBuilder.ChangeHasOperandFactory.class);
    DynamicMap.mapOf(binder(), ChangeQueryProcessor.ChangeAttributeFactory.class);
    install(new GitwebConfig.LegacyModule(cfg));
    bind(AnonymousUser.class);
    factory(AbandonOp.Factory.class);
    factory(AccountMergeValidator.Factory.class);
    factory(RefOperationValidators.Factory.class);
    factory(OnSubmitValidators.Factory.class);
    factory(MergeValidators.Factory.class);
    factory(ProjectConfigValidator.Factory.class);
    factory(NotesBranchUtil.Factory.class);
    factory(MergedByPushOp.Factory.class);
    factory(GitModules.Factory.class);
    factory(VersionedAuthorizedKeys.Factory.class);
    bind(AccountManager.class);
    factory(ChangeUserName.Factory.class);
    bind(new TypeLiteral<List<CommentLinkInfo>>() {
    }).toProvider(CommentLinkProvider.class).in(SINGLETON);
    bind(ReloadPluginListener.class).annotatedWith(UniqueAnnotations.create()).to(PluginConfigFactory.class);
}
#method_after
@Override
protected void configure() {
    bind(EmailExpander.class).toProvider(EmailExpanderProvider.class).in(SINGLETON);
    bind(IdGenerator.class);
    bind(RulesCache.class);
    bind(BlameCache.class).to(BlameCacheImpl.class);
    bind(Sequences.class);
    install(authModule);
    install(AccountCacheImpl.module());
    install(BatchUpdate.module());
    install(ChangeKindCacheImpl.module());
    install(ChangeFinder.module());
    install(ConflictsCacheImpl.module());
    install(GroupCacheImpl.module());
    install(GroupIncludeCacheImpl.module());
    install(MergeabilityCacheImpl.module());
    install(PatchListCacheImpl.module());
    install(ProjectCacheImpl.module());
    install(SectionSortCache.module());
    install(SubmitStrategy.module());
    install(TagCache.module());
    install(OAuthTokenCache.module());
    install(new AccessControlModule());
    install(new CmdLineParserModule());
    install(new EmailModule());
    install(new ExternalIdModule());
    install(new GitModule());
    install(new GroupModule());
    install(new NoteDbModule(cfg));
    install(new PrologModule());
    install(new ReceiveCommitsModule());
    install(new SshAddressesModule());
    install(ThreadLocalRequestContext.module());
    bind(AccountResolver.class);
    factory(AddReviewerSender.Factory.class);
    factory(DeleteReviewerSender.Factory.class);
    factory(AddKeySender.Factory.class);
    factory(CapabilityCollection.Factory.class);
    factory(ChangeData.AssistedFactory.class);
    factory(ChangeJson.AssistedFactory.class);
    factory(CreateChangeSender.Factory.class);
    factory(GroupMembers.Factory.class);
    factory(EmailMerge.Factory.class);
    factory(MergedSender.Factory.class);
    factory(MergeUtil.Factory.class);
    factory(PatchScriptFactory.Factory.class);
    factory(PluginUser.Factory.class);
    factory(ProjectNode.Factory.class);
    factory(ProjectState.Factory.class);
    factory(RegisterNewEmailSender.Factory.class);
    factory(ReplacePatchSetSender.Factory.class);
    factory(SetAssigneeSender.Factory.class);
    factory(VisibleRefFilter.Factory.class);
    bind(PermissionCollection.Factory.class);
    bind(AccountVisibility.class).toProvider(AccountVisibilityProvider.class).in(SINGLETON);
    factory(ProjectOwnerGroupsProvider.Factory.class);
    factory(SubmitRuleEvaluator.Factory.class);
    bind(AuthBackend.class).to(UniversalAuthBackend.class).in(SINGLETON);
    DynamicSet.setOf(binder(), AuthBackend.class);
    bind(GroupControl.Factory.class).in(SINGLETON);
    bind(GroupControl.GenericFactory.class).in(SINGLETON);
    bind(FileTypeRegistry.class).to(MimeUtilFileTypeRegistry.class);
    bind(ToolsCatalog.class);
    bind(EventFactory.class);
    bind(TransferConfig.class);
    bind(GcConfig.class);
    bind(ChangeCleanupConfig.class);
    bind(AccountDeactivator.class);
    bind(ApprovalsUtil.class);
    bind(RuntimeInstance.class).toProvider(VelocityRuntimeProvider.class);
    bind(SoyTofu.class).annotatedWith(MailTemplates.class).toProvider(MailSoyTofuProvider.class);
    bind(FromAddressGenerator.class).toProvider(FromAddressGeneratorProvider.class).in(SINGLETON);
    bind(Boolean.class).annotatedWith(DisableReverseDnsLookup.class).toProvider(DisableReverseDnsLookupProvider.class).in(SINGLETON);
    bind(PatchSetInfoFactory.class);
    bind(IdentifiedUser.GenericFactory.class).in(SINGLETON);
    bind(AccountControl.Factory.class);
    install(new AuditModule());
    bind(UiActions.class);
    install(new com.google.gerrit.server.access.Module());
    install(new com.google.gerrit.server.account.Module());
    install(new com.google.gerrit.server.api.Module());
    install(new com.google.gerrit.server.change.Module());
    install(new com.google.gerrit.server.config.Module());
    install(new com.google.gerrit.server.group.Module());
    install(new com.google.gerrit.server.project.Module());
    bind(GitReferenceUpdated.class);
    DynamicMap.mapOf(binder(), new TypeLiteral<Cache<?, ?>>() {
    });
    DynamicSet.setOf(binder(), CacheRemovalListener.class);
    DynamicMap.mapOf(binder(), CapabilityDefinition.class);
    DynamicSet.setOf(binder(), GitReferenceUpdatedListener.class);
    DynamicSet.setOf(binder(), AssigneeChangedListener.class);
    DynamicSet.setOf(binder(), ChangeAbandonedListener.class);
    DynamicSet.setOf(binder(), CommentAddedListener.class);
    DynamicSet.setOf(binder(), HashtagsEditedListener.class);
    DynamicSet.setOf(binder(), ChangeMergedListener.class);
    DynamicSet.setOf(binder(), ChangeRestoredListener.class);
    DynamicSet.setOf(binder(), ChangeRevertedListener.class);
    DynamicSet.setOf(binder(), ReviewerAddedListener.class);
    DynamicSet.setOf(binder(), ReviewerDeletedListener.class);
    DynamicSet.setOf(binder(), VoteDeletedListener.class);
    DynamicSet.setOf(binder(), WorkInProgressStateChangedListener.class);
    DynamicSet.setOf(binder(), RevisionCreatedListener.class);
    DynamicSet.setOf(binder(), TopicEditedListener.class);
    DynamicSet.setOf(binder(), AgreementSignupListener.class);
    DynamicSet.setOf(binder(), PluginEventListener.class);
    DynamicSet.setOf(binder(), ReceivePackInitializer.class);
    DynamicSet.setOf(binder(), PostReceiveHook.class);
    DynamicSet.setOf(binder(), PreUploadHook.class);
    DynamicSet.setOf(binder(), PostUploadHook.class);
    DynamicSet.setOf(binder(), AccountIndexedListener.class);
    DynamicSet.setOf(binder(), ChangeIndexedListener.class);
    DynamicSet.setOf(binder(), GroupIndexedListener.class);
    DynamicSet.setOf(binder(), NewProjectCreatedListener.class);
    DynamicSet.setOf(binder(), ProjectDeletedListener.class);
    DynamicSet.setOf(binder(), GarbageCollectorListener.class);
    DynamicSet.setOf(binder(), HeadUpdatedListener.class);
    DynamicSet.setOf(binder(), UsageDataPublishedListener.class);
    DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(ReindexAfterRefUpdate.class);
    DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(ProjectConfigEntry.UpdateChecker.class);
    DynamicSet.setOf(binder(), EventListener.class);
    DynamicSet.bind(binder(), EventListener.class).to(EventsMetrics.class);
    DynamicSet.setOf(binder(), UserScopedEventListener.class);
    DynamicSet.setOf(binder(), CommitValidationListener.class);
    DynamicSet.setOf(binder(), ChangeMessageModifier.class);
    DynamicSet.setOf(binder(), RefOperationValidationListener.class);
    DynamicSet.setOf(binder(), OnSubmitValidationListener.class);
    DynamicSet.setOf(binder(), MergeValidationListener.class);
    DynamicSet.setOf(binder(), ProjectCreationValidationListener.class);
    DynamicSet.setOf(binder(), GroupCreationValidationListener.class);
    DynamicSet.setOf(binder(), HashtagValidationListener.class);
    DynamicSet.setOf(binder(), OutgoingEmailValidationListener.class);
    DynamicItem.itemOf(binder(), AvatarProvider.class);
    DynamicSet.setOf(binder(), LifecycleListener.class);
    DynamicSet.setOf(binder(), TopMenu.class);
    DynamicSet.setOf(binder(), MessageOfTheDay.class);
    DynamicMap.mapOf(binder(), DownloadScheme.class);
    DynamicMap.mapOf(binder(), DownloadCommand.class);
    DynamicMap.mapOf(binder(), CloneCommand.class);
    DynamicMap.mapOf(binder(), ReviewerSuggestion.class);
    DynamicSet.setOf(binder(), ExternalIncludedIn.class);
    DynamicMap.mapOf(binder(), ProjectConfigEntry.class);
    DynamicSet.setOf(binder(), PatchSetWebLink.class);
    DynamicSet.setOf(binder(), ParentWebLink.class);
    DynamicSet.setOf(binder(), FileWebLink.class);
    DynamicSet.setOf(binder(), FileHistoryWebLink.class);
    DynamicSet.setOf(binder(), DiffWebLink.class);
    DynamicSet.setOf(binder(), ProjectWebLink.class);
    DynamicSet.setOf(binder(), BranchWebLink.class);
    DynamicSet.setOf(binder(), TagWebLink.class);
    DynamicMap.mapOf(binder(), OAuthLoginProvider.class);
    DynamicItem.itemOf(binder(), OAuthTokenEncrypter.class);
    DynamicSet.setOf(binder(), AccountExternalIdCreator.class);
    DynamicSet.setOf(binder(), WebUiPlugin.class);
    DynamicItem.itemOf(binder(), AccountPatchReviewStore.class);
    DynamicSet.setOf(binder(), AssigneeValidationListener.class);
    DynamicSet.setOf(binder(), ActionVisitor.class);
    DynamicMap.mapOf(binder(), MailFilter.class);
    bind(MailFilter.class).annotatedWith(Exports.named("ListMailFilter")).to(ListMailFilter.class);
    factory(UploadValidators.Factory.class);
    DynamicSet.setOf(binder(), UploadValidationListener.class);
    DynamicMap.mapOf(binder(), ChangeQueryBuilder.ChangeOperatorFactory.class);
    DynamicMap.mapOf(binder(), ChangeQueryBuilder.ChangeHasOperandFactory.class);
    DynamicMap.mapOf(binder(), ChangeQueryProcessor.ChangeAttributeFactory.class);
    install(new GitwebConfig.LegacyModule(cfg));
    bind(AnonymousUser.class);
    factory(AbandonOp.Factory.class);
    factory(AccountMergeValidator.Factory.class);
    factory(RefOperationValidators.Factory.class);
    factory(OnSubmitValidators.Factory.class);
    factory(MergeValidators.Factory.class);
    factory(ProjectConfigValidator.Factory.class);
    factory(NotesBranchUtil.Factory.class);
    factory(MergedByPushOp.Factory.class);
    factory(GitModules.Factory.class);
    factory(VersionedAuthorizedKeys.Factory.class);
    bind(AccountManager.class);
    factory(ChangeUserName.Factory.class);
    bind(new TypeLiteral<List<CommentLinkInfo>>() {
    }).toProvider(CommentLinkProvider.class).in(SINGLETON);
    bind(ReloadPluginListener.class).annotatedWith(UniqueAnnotations.create()).to(PluginConfigFactory.class);
}
#end_block

#method_before
private Set<Account> scanAccounts(ReviewDb db, ProgressMonitor pm) throws SQLException {
    Set<Map.Entry<String, AccountSetter>> fields = getFields(db);
    if (fields.isEmpty()) {
        return Collections.emptySet();
    }
    String query = fields.stream().map(f -> f.getKey()).collect(Collectors.joining(", ", "SELECT account_id, registered_on, ", String.format(" FROM %s", TABLE)));
    try (Statement stmt = newStatement(db);
        ResultSet rs = stmt.executeQuery(query)) {
        Set<Account> s = new HashSet<>();
        while (rs.next()) {
            Account a = new Account(new Account.Id(rs.getInt(1)), rs.getTimestamp(2));
            for (Map.Entry<String, AccountSetter> field : fields) {
                field.getValue().set(a, rs, field.getKey());
            }
            s.add(a);
            pm.update(1);
        }
        return s;
    }
}
#method_after
private Set<Account> scanAccounts(ReviewDb db, ProgressMonitor pm) throws SQLException {
    Map<String, AccountSetter> fields = getFields(db);
    if (fields.isEmpty()) {
        log.warn("Only account_id and registered_on fields are migrated for accounts");
    }
    List<String> queryFields = new ArrayList<>();
    queryFields.add("account_id");
    queryFields.add("registered_on");
    queryFields.addAll(fields.keySet());
    String query = "SELECT " + String.join(", ", queryFields) + String.format(" FROM %s", TABLE);
    try (Statement stmt = newStatement(db);
        ResultSet rs = stmt.executeQuery(query)) {
        Set<Account> s = new HashSet<>();
        while (rs.next()) {
            Account a = new Account(new Account.Id(rs.getInt(1)), rs.getTimestamp(2));
            for (Map.Entry<String, AccountSetter> field : fields.entrySet()) {
                field.getValue().set(a, rs, field.getKey());
            }
            s.add(a);
            pm.update(1);
        }
        return s;
    }
}
#end_block

#method_before
private Set<Map.Entry<String, AccountSetter>> getFields(ReviewDb db) throws SQLException {
    JdbcSchema schema = (JdbcSchema) db;
    Connection connection = schema.getConnection();
    Set<String> columns = schema.getDialect().listColumns(connection, TABLE);
    return ACCOUNT_FIELDS_MAP.entrySet().stream().filter(e -> columns.contains(e.getKey())).collect(Collectors.toSet());
}
#method_after
private Map<String, AccountSetter> getFields(ReviewDb db) throws SQLException {
    JdbcSchema schema = (JdbcSchema) db;
    Connection connection = schema.getConnection();
    Set<String> columns = schema.getDialect().listColumns(connection, TABLE);
    return ACCOUNT_FIELDS_MAP.entrySet().stream().filter(e -> columns.contains(e.getKey())).collect(toMap(Map.Entry::getKey, Map.Entry::getValue));
}
#end_block

#method_before
private void collectPluginCapabilities(Map<String, CapabilityInfo> output) {
    for (String pluginName : pluginCapabilities.plugins()) {
        if (!isPluginNameSane(pluginName)) {
            log.warn(String.format("Plugin name %s must match [A-Za-z0-9-]+ to use capabilities;" + " rename the plugin", pluginName));
            continue;
        }
        for (Map.Entry<String, Provider<CapabilityDefinition>> entry : pluginCapabilities.byPlugin(pluginName).entrySet()) {
            String id = String.format("%s-%s", pluginName, entry.getKey());
            output.put(id, new CapabilityInfo(id, entry.getValue().get().getDescription()));
        }
    }
}
#method_after
private void collectPluginCapabilities(Map<String, CapabilityInfo> output) {
    for (String pluginName : pluginCapabilities.plugins()) {
        if (!PLUGIN_NAME_PATTERN.matcher(pluginName).matches()) {
            log.warn("Plugin name '{}' must match '{}' to use capabilities; rename the plugin", pluginName, PLUGIN_NAME_PATTERN.pattern());
            continue;
        }
        for (Map.Entry<String, Provider<CapabilityDefinition>> entry : pluginCapabilities.byPlugin(pluginName).entrySet()) {
            String id = String.format("%s-%s", pluginName, entry.getKey());
            output.put(id, new CapabilityInfo(id, entry.getValue().get().getDescription()));
        }
    }
}
#end_block

#method_before
public ConfigInfo apply(ProjectState projectState, ConfigInput input) throws ResourceNotFoundException, BadRequestException, ResourceConflictException {
    Project.NameKey projectName = projectState.getNameKey();
    if (input == null) {
        throw new BadRequestException("config is required");
    }
    try (MetaDataUpdate md = metaDataUpdateFactory.get().create(projectName)) {
        ProjectConfig projectConfig = ProjectConfig.read(md);
        Project p = projectConfig.getProject();
        p.setDescription(Strings.emptyToNull(input.description));
        if (input.useContributorAgreements != null) {
            p.setUseContributorAgreements(input.useContributorAgreements);
        }
        if (input.useContentMerge != null) {
            p.setUseContentMerge(input.useContentMerge);
        }
        if (input.useSignedOffBy != null) {
            p.setUseSignedOffBy(input.useSignedOffBy);
        }
        if (input.createNewChangeForAllNotInTarget != null) {
            p.setCreateNewChangeForAllNotInTarget(input.createNewChangeForAllNotInTarget);
        }
        if (input.requireChangeId != null) {
            p.setRequireChangeID(input.requireChangeId);
        }
        if (serverEnableSignedPush) {
            if (input.enableSignedPush != null) {
                p.setEnableSignedPush(input.enableSignedPush);
            }
            if (input.requireSignedPush != null) {
                p.setRequireSignedPush(input.requireSignedPush);
            }
        }
        if (input.rejectImplicitMerges != null) {
            p.setRejectImplicitMerges(input.rejectImplicitMerges);
        }
        if (input.privateByDefault != null) {
            p.setPrivateByDefault(input.privateByDefault);
        }
        if (input.maxObjectSizeLimit != null) {
            p.setMaxObjectSizeLimit(input.maxObjectSizeLimit);
        }
        if (input.submitType != null) {
            p.setSubmitType(input.submitType);
        }
        if (input.state != null) {
            p.setState(input.state);
        }
        if (input.enableReviewerByEmail != null) {
            p.setEnableReviewerByEmail(input.enableReviewerByEmail);
        }
        if (input.matchAuthorToCommitterDate != null) {
            p.setMatchAuthorToCommitterDate(input.matchAuthorToCommitterDate);
        }
        if (input.pluginConfigValues != null) {
            setPluginConfigValues(projectState, projectConfig, input.pluginConfigValues);
        }
        md.setMessage("Modified project settings\n");
        try {
            projectConfig.commit(md);
            projectCache.evict(projectConfig.getProject());
            md.getRepository().setGitwebDescription(p.getDescription());
        } catch (IOException e) {
            if (e.getCause() instanceof ConfigInvalidException) {
                throw new ResourceConflictException("Cannot update " + projectName + ": " + e.getCause().getMessage());
            }
            log.warn(String.format("Failed to update config of project %s.", projectName), e);
            throw new ResourceConflictException("Cannot update " + projectName);
        }
        ProjectState state = projectStateFactory.create(projectConfig);
        return new ConfigInfoImpl(serverEnableSignedPush, state, user.get(), config, pluginConfigEntries, cfgFactory, allProjects, uiActions, views);
    } catch (RepositoryNotFoundException notFound) {
        throw new ResourceNotFoundException(projectName.get());
    } catch (ConfigInvalidException err) {
        throw new ResourceConflictException("Cannot read project " + projectName, err);
    } catch (IOException err) {
        throw new ResourceConflictException("Cannot update project " + projectName, err);
    }
}
#method_after
public ConfigInfo apply(ProjectState projectState, ConfigInput input) throws ResourceNotFoundException, BadRequestException, ResourceConflictException {
    Project.NameKey projectName = projectState.getNameKey();
    if (input == null) {
        throw new BadRequestException("config is required");
    }
    try (MetaDataUpdate md = metaDataUpdateFactory.get().create(projectName)) {
        ProjectConfig projectConfig = ProjectConfig.read(md);
        Project p = projectConfig.getProject();
        p.setDescription(Strings.emptyToNull(input.description));
        for (BooleanProjectConfig cfg : BooleanProjectConfig.values()) {
            InheritableBoolean val = BooleanProjectConfigTransformations.get(cfg, input);
            if (val != null) {
                p.setBooleanConfig(cfg, val);
            }
        }
        if (input.maxObjectSizeLimit != null) {
            p.setMaxObjectSizeLimit(input.maxObjectSizeLimit);
        }
        if (input.submitType != null) {
            p.setSubmitType(input.submitType);
        }
        if (input.state != null) {
            p.setState(input.state);
        }
        if (input.pluginConfigValues != null) {
            setPluginConfigValues(projectState, projectConfig, input.pluginConfigValues);
        }
        md.setMessage("Modified project settings\n");
        try {
            projectConfig.commit(md);
            projectCache.evict(projectConfig.getProject());
            md.getRepository().setGitwebDescription(p.getDescription());
        } catch (IOException e) {
            if (e.getCause() instanceof ConfigInvalidException) {
                throw new ResourceConflictException("Cannot update " + projectName + ": " + e.getCause().getMessage());
            }
            log.warn(String.format("Failed to update config of project %s.", projectName), e);
            throw new ResourceConflictException("Cannot update " + projectName);
        }
        ProjectState state = projectStateFactory.create(projectConfig);
        return new ConfigInfoImpl(serverEnableSignedPush, state, user.get(), config, pluginConfigEntries, cfgFactory, allProjects, uiActions, views);
    } catch (RepositoryNotFoundException notFound) {
        throw new ResourceNotFoundException(projectName.get());
    } catch (ConfigInvalidException err) {
        throw new ResourceConflictException("Cannot read project " + projectName, err);
    } catch (IOException err) {
        throw new ResourceConflictException("Cannot update project " + projectName, err);
    }
}
#end_block

#method_before
private void setPluginConfigValues(ProjectState projectState, ProjectConfig projectConfig, Map<String, Map<String, ConfigValue>> pluginConfigValues) throws BadRequestException {
    for (Entry<String, Map<String, ConfigValue>> e : pluginConfigValues.entrySet()) {
        String pluginName = e.getKey();
        PluginConfig cfg = projectConfig.getPluginConfig(pluginName);
        for (Entry<String, ConfigValue> v : e.getValue().entrySet()) {
            ProjectConfigEntry projectConfigEntry = pluginConfigEntries.get(pluginName, v.getKey());
            if (projectConfigEntry != null) {
                if (!isValidParameterName(v.getKey())) {
                    log.warn(String.format("Parameter name '%s' must match '^[a-zA-Z0-9]+[a-zA-Z0-9-]*$'", v.getKey()));
                    continue;
                }
                String oldValue = cfg.getString(v.getKey());
                String value = v.getValue().value;
                if (projectConfigEntry.getType() == ProjectConfigEntryType.ARRAY) {
                    List<String> l = Arrays.asList(cfg.getStringList(v.getKey()));
                    oldValue = Joiner.on("\n").join(l);
                    value = Joiner.on("\n").join(v.getValue().values);
                }
                if (Strings.emptyToNull(value) != null) {
                    if (!value.equals(oldValue)) {
                        validateProjectConfigEntryIsEditable(projectConfigEntry, projectState, v.getKey(), pluginName);
                        v.setValue(projectConfigEntry.preUpdate(v.getValue()));
                        value = v.getValue().value;
                        try {
                            switch(projectConfigEntry.getType()) {
                                case BOOLEAN:
                                    boolean newBooleanValue = Boolean.parseBoolean(value);
                                    cfg.setBoolean(v.getKey(), newBooleanValue);
                                    break;
                                case INT:
                                    int newIntValue = Integer.parseInt(value);
                                    cfg.setInt(v.getKey(), newIntValue);
                                    break;
                                case LONG:
                                    long newLongValue = Long.parseLong(value);
                                    cfg.setLong(v.getKey(), newLongValue);
                                    break;
                                case LIST:
                                    if (!projectConfigEntry.getPermittedValues().contains(value)) {
                                        throw new BadRequestException(String.format("The value '%s' is not permitted for parameter '%s' of plugin '" + pluginName + "'", value, v.getKey()));
                                    }
                                // $FALL-THROUGH$
                                case STRING:
                                    cfg.setString(v.getKey(), value);
                                    break;
                                case ARRAY:
                                    cfg.setStringList(v.getKey(), v.getValue().values);
                                    break;
                                default:
                                    log.warn(String.format("The type '%s' of parameter '%s' is not supported.", projectConfigEntry.getType().name(), v.getKey()));
                            }
                        } catch (NumberFormatException ex) {
                            throw new BadRequestException(String.format("The value '%s' of config parameter '%s' of plugin '%s' is invalid: %s", v.getValue(), v.getKey(), pluginName, ex.getMessage()));
                        }
                    }
                } else {
                    if (oldValue != null) {
                        validateProjectConfigEntryIsEditable(projectConfigEntry, projectState, v.getKey(), pluginName);
                        cfg.unset(v.getKey());
                    }
                }
            } else {
                throw new BadRequestException(String.format("The config parameter '%s' of plugin '%s' does not exist.", v.getKey(), pluginName));
            }
        }
    }
}
#method_after
private void setPluginConfigValues(ProjectState projectState, ProjectConfig projectConfig, Map<String, Map<String, ConfigValue>> pluginConfigValues) throws BadRequestException {
    for (Entry<String, Map<String, ConfigValue>> e : pluginConfigValues.entrySet()) {
        String pluginName = e.getKey();
        PluginConfig cfg = projectConfig.getPluginConfig(pluginName);
        for (Entry<String, ConfigValue> v : e.getValue().entrySet()) {
            ProjectConfigEntry projectConfigEntry = pluginConfigEntries.get(pluginName, v.getKey());
            if (projectConfigEntry != null) {
                if (!PARAMETER_NAME_PATTERN.matcher(v.getKey()).matches()) {
                    // TODO check why we have this restriction
                    log.warn("Parameter name '{}' must match '{}'", v.getKey(), PARAMETER_NAME_PATTERN.pattern());
                    continue;
                }
                String oldValue = cfg.getString(v.getKey());
                String value = v.getValue().value;
                if (projectConfigEntry.getType() == ProjectConfigEntryType.ARRAY) {
                    List<String> l = Arrays.asList(cfg.getStringList(v.getKey()));
                    oldValue = Joiner.on("\n").join(l);
                    value = Joiner.on("\n").join(v.getValue().values);
                }
                if (Strings.emptyToNull(value) != null) {
                    if (!value.equals(oldValue)) {
                        validateProjectConfigEntryIsEditable(projectConfigEntry, projectState, v.getKey(), pluginName);
                        v.setValue(projectConfigEntry.preUpdate(v.getValue()));
                        value = v.getValue().value;
                        try {
                            switch(projectConfigEntry.getType()) {
                                case BOOLEAN:
                                    boolean newBooleanValue = Boolean.parseBoolean(value);
                                    cfg.setBoolean(v.getKey(), newBooleanValue);
                                    break;
                                case INT:
                                    int newIntValue = Integer.parseInt(value);
                                    cfg.setInt(v.getKey(), newIntValue);
                                    break;
                                case LONG:
                                    long newLongValue = Long.parseLong(value);
                                    cfg.setLong(v.getKey(), newLongValue);
                                    break;
                                case LIST:
                                    if (!projectConfigEntry.getPermittedValues().contains(value)) {
                                        throw new BadRequestException(String.format("The value '%s' is not permitted for parameter '%s' of plugin '" + pluginName + "'", value, v.getKey()));
                                    }
                                // $FALL-THROUGH$
                                case STRING:
                                    cfg.setString(v.getKey(), value);
                                    break;
                                case ARRAY:
                                    cfg.setStringList(v.getKey(), v.getValue().values);
                                    break;
                                default:
                                    log.warn(String.format("The type '%s' of parameter '%s' is not supported.", projectConfigEntry.getType().name(), v.getKey()));
                            }
                        } catch (NumberFormatException ex) {
                            throw new BadRequestException(String.format("The value '%s' of config parameter '%s' of plugin '%s' is invalid: %s", v.getValue(), v.getKey(), pluginName, ex.getMessage()));
                        }
                    }
                } else {
                    if (oldValue != null) {
                        validateProjectConfigEntryIsEditable(projectConfigEntry, projectState, v.getKey(), pluginName);
                        cfg.unset(v.getKey());
                    }
                }
            } else {
                throw new BadRequestException(String.format("The config parameter '%s' of plugin '%s' does not exist.", v.getKey(), pluginName));
            }
        }
    }
}
#end_block

#method_before
private void autoCloseChanges(ReceiveCommand cmd) {
    logDebug("Starting auto-closing of changes");
    String refName = cmd.getRefName();
    checkState(!MagicBranch.isMagicBranch(refName), "shouldn't be auto-closing changes on magic branch %s", refName);
    // insertChangesAndPatchSets.
    try (BatchUpdate bu = batchUpdateFactory.create(db, projectState.getNameKey(), user, TimeUtil.nowTs());
        ObjectInserter ins = repo.newObjectInserter();
        ObjectReader reader = ins.newReader();
        RevWalk rw = new RevWalk(reader)) {
        bu.setRepository(repo, rw, ins).updateChangesInParallel();
        bu.setRequestId(receiveId);
        // TODO(dborowitz): Teach BatchUpdate to ignore missing changes.
        RevCommit newTip = rw.parseCommit(cmd.getNewId());
        Branch.NameKey branch = new Branch.NameKey(project.getNameKey(), refName);
        rw.reset();
        rw.markStart(newTip);
        if (!ObjectId.zeroId().equals(cmd.getOldId())) {
            rw.markUninteresting(rw.parseCommit(cmd.getOldId()));
        }
        ListMultimap<ObjectId, Ref> byCommit = changeRefsById();
        Map<Change.Key, ChangeNotes> byKey = null;
        List<ReplaceRequest> replaceAndClose = new ArrayList<>();
        int existingPatchSets = 0;
        int newPatchSets = 0;
        COMMIT: for (RevCommit c; (c = rw.next()) != null; ) {
            rw.parseBody(c);
            for (Ref ref : byCommit.get(c.copy())) {
                existingPatchSets++;
                PatchSet.Id psId = PatchSet.Id.fromRef(ref.getName());
                bu.addOp(psId.getParentKey(), mergedByPushOpFactory.create(requestScopePropagator, psId, refName));
                continue COMMIT;
            }
            for (String changeId : c.getFooterLines(CHANGE_ID)) {
                if (byKey == null) {
                    byKey = openChangesByBranch(branch);
                }
                ChangeNotes onto = byKey.get(new Change.Key(changeId.trim()));
                if (onto != null) {
                    newPatchSets++;
                    // Hold onto this until we're done with the walk, as the call to
                    // req.validate below calls isMergedInto which resets the walk.
                    ReplaceRequest req = new ReplaceRequest(onto.getChangeId(), c, cmd, false);
                    req.notes = onto;
                    replaceAndClose.add(req);
                    continue COMMIT;
                }
            }
        }
        for (ReplaceRequest req : replaceAndClose) {
            Change.Id id = req.notes.getChangeId();
            if (!req.validate(true)) {
                logDebug("Not closing {} because validation failed", id);
                continue;
            }
            req.addOps(bu, null);
            bu.addOp(id, mergedByPushOpFactory.create(requestScopePropagator, req.psId, refName).setPatchSetProvider(new Provider<PatchSet>() {

                @Override
                public PatchSet get() {
                    return req.replaceOp.getPatchSet();
                }
            }));
            bu.addOp(id, new ChangeProgressOp(closeProgress));
        }
        logDebug("Auto-closing {} changes with existing patch sets and {} with new patch sets", existingPatchSets, newPatchSets);
        bu.execute();
    } catch (RestApiException e) {
        logError("Can't insert patchset", e);
    } catch (IOException | OrmException | UpdateException | PermissionBackendException e) {
        logError("Can't scan for changes to close", e);
    }
}
#method_after
private void autoCloseChanges(ReceiveCommand cmd) {
    logDebug("Starting auto-closing of changes");
    String refName = cmd.getRefName();
    checkState(!MagicBranch.isMagicBranch(refName), "shouldn't be auto-closing changes on magic branch %s", refName);
    // insertChangesAndPatchSets.
    try (BatchUpdate bu = batchUpdateFactory.create(db, projectState.getNameKey(), user, TimeUtil.nowTs());
        ObjectInserter ins = repo.newObjectInserter();
        ObjectReader reader = ins.newReader();
        RevWalk rw = new RevWalk(reader)) {
        bu.setRepository(repo, rw, ins).updateChangesInParallel();
        bu.setRequestId(receiveId);
        // TODO(dborowitz): Teach BatchUpdate to ignore missing changes.
        RevCommit newTip = rw.parseCommit(cmd.getNewId());
        Branch.NameKey branch = new Branch.NameKey(project.getNameKey(), refName);
        rw.reset();
        rw.markStart(newTip);
        if (!ObjectId.zeroId().equals(cmd.getOldId())) {
            rw.markUninteresting(rw.parseCommit(cmd.getOldId()));
        }
        ListMultimap<ObjectId, Ref> byCommit = changeRefsById();
        Map<Change.Key, ChangeNotes> byKey = null;
        List<ReplaceRequest> replaceAndClose = new ArrayList<>();
        int existingPatchSets = 0;
        int newPatchSets = 0;
        COMMIT: for (RevCommit c; (c = rw.next()) != null; ) {
            rw.parseBody(c);
            for (Ref ref : byCommit.get(c.copy())) {
                PatchSet.Id psId = PatchSet.Id.fromRef(ref.getName());
                Optional<ChangeData> cd = byLegacyId(psId.getParentKey());
                if (cd.isPresent() && cd.get().change().getDest().equals(branch)) {
                    existingPatchSets++;
                    bu.addOp(psId.getParentKey(), mergedByPushOpFactory.create(requestScopePropagator, psId, refName));
                    continue COMMIT;
                }
            }
            for (String changeId : c.getFooterLines(CHANGE_ID)) {
                if (byKey == null) {
                    byKey = openChangesByKeyByBranch(branch);
                }
                ChangeNotes onto = byKey.get(new Change.Key(changeId.trim()));
                if (onto != null) {
                    newPatchSets++;
                    // Hold onto this until we're done with the walk, as the call to
                    // req.validate below calls isMergedInto which resets the walk.
                    ReplaceRequest req = new ReplaceRequest(onto.getChangeId(), c, cmd, false);
                    req.notes = onto;
                    replaceAndClose.add(req);
                    continue COMMIT;
                }
            }
        }
        for (ReplaceRequest req : replaceAndClose) {
            Change.Id id = req.notes.getChangeId();
            if (!req.validate(true)) {
                logDebug("Not closing {} because validation failed", id);
                continue;
            }
            req.addOps(bu, null);
            bu.addOp(id, mergedByPushOpFactory.create(requestScopePropagator, req.psId, refName).setPatchSetProvider(new Provider<PatchSet>() {

                @Override
                public PatchSet get() {
                    return req.replaceOp.getPatchSet();
                }
            }));
            bu.addOp(id, new ChangeProgressOp(closeProgress));
        }
        logDebug("Auto-closing {} changes with existing patch sets and {} with new patch sets", existingPatchSets, newPatchSets);
        bu.execute();
    } catch (RestApiException e) {
        logError("Can't insert patchset", e);
    } catch (IOException | OrmException | UpdateException | PermissionBackendException e) {
        logError("Can't scan for changes to close", e);
    }
}
#end_block

#method_before
public static void set(BooleanProjectConfig cfg, ConfigInfo info, InheritedBooleanInfo val) {
    TO_API.get(cfg).apply(info, val);
}
#method_after
public static void set(BooleanProjectConfig cfg, ConfigInfo info, InheritedBooleanInfo val) {
    MAPPER.get(cfg).set(info, val);
}
#end_block

#method_before
public static InheritableBoolean get(BooleanProjectConfig cfg, ConfigInput input) {
    return FROM_API.get(cfg).apply(input);
}
#method_after
public static InheritableBoolean get(BooleanProjectConfig cfg, ConfigInput input) {
    return MAPPER.get(cfg).get(input);
}
#end_block

#method_before
protected void fail(@Nullable String format, Object... args) throws Exception {
    assert_().fail(format, args);
}
#method_after
protected void fail(@Nullable String format, Object... args) {
    assert_().fail(format, args);
}
#end_block

#method_before
protected void fail() throws Exception {
    assert_().fail();
}
#method_after
protected void fail() {
    assert_().fail();
}
#end_block

#method_before
private String getProtocolStack(Config cfg, SitePaths site) {
    String location = cfg.getString(JGROUPS_SECTION, null, PROTOCOL_STACK_KEY);
    if (location == null) {
        return null;
    }
    Path p = Paths.get(location);
    if (p.isAbsolute()) {
        return location;
    }
    return site.etc_dir.resolve(location).toString();
}
#method_after
private Optional<Path> getProtocolStack(Config cfg, SitePaths site) {
    String location = cfg.getString(JGROUPS_SECTION, null, PROTOCOL_STACK_KEY);
    return location == null ? Optional.empty() : Optional.of(site.etc_dir.resolve(location));
}
#end_block

#method_before
public String protocolStack() {
    return protocolStack;
}
#method_after
public Optional<Path> protocolStack() {
    return protocolStack;
}
#end_block

#method_before
public void connect() {
    try {
        channel = getChannel();
        Optional<InetAddress> address = finder.findAddress();
        if (address.isPresent()) {
            log.debug("Protocol stack: " + channel.getProtocolStack());
            channel.getProtocolStack().getTransport().setBindAddress(address.get());
            log.debug("Channel bound to {}", address.get());
        } else {
            log.warn("Channel not bound: address not present");
        }
        channel.setReceiver(this);
        channel.setDiscardOwnMessages(true);
        channel.connect(jgroupsConfig.clusterName());
        log.info("Channel {} successfully joined jgroups cluster {}", channel.getName(), jgroupsConfig.clusterName());
    } catch (Exception e) {
        log.error("joining cluster {} for channel {} failed", jgroupsConfig.clusterName(), channel.getName(), e);
    }
}
#method_after
public void connect() {
    try {
        channel = getChannel();
        Optional<InetAddress> address = finder.findAddress();
        if (address.isPresent()) {
            log.debug("Protocol stack: " + channel.getProtocolStack());
            channel.getProtocolStack().getTransport().setBindAddress(address.get());
            log.debug("Channel bound to {}", address.get());
        } else {
            log.warn("Channel not bound: address not present");
        }
        channel.setReceiver(this);
        channel.setDiscardOwnMessages(true);
        channel.connect(jgroupsConfig.clusterName());
        log.info("Channel {} successfully joined jgroups cluster {}", channel.getName(), jgroupsConfig.clusterName());
    } catch (Exception e) {
        if (channel != null) {
            log.error("joining cluster {} (channel {}) failed", jgroupsConfig.clusterName(), channel.getName(), e);
        } else {
            log.error("joining cluster {} failed", jgroupsConfig.clusterName(), e);
        }
    }
}
#end_block

#method_before
private JChannel getChannel() {
    String protocolStack = "";
    try {
        protocolStack = jgroupsConfig.protocolStack();
        return protocolStack == null ? new JChannel() : new JChannel(protocolStack);
    } catch (Exception e) {
        log.error("Unable to create a new channel with {}", protocolStack, e);
        return null;
    }
}
#method_after
private JChannel getChannel() throws Exception {
    Optional<Path> protocolStack = jgroupsConfig.protocolStack();
    try {
        return protocolStack.isPresent() ? new JChannel(protocolStack.get().toString()) : new JChannel();
    } catch (Exception e) {
        log.error("Unable to create a channel with protocol stack: {}", protocolStack == null ? "default" : protocolStack, e);
        throw e;
    }
}
#end_block

#method_before
@Override
public void stop() {
    log.info("closing jgroups channel {} (cluster {})", channel.getName(), jgroupsConfig.clusterName());
    channel.close();
    peerInfo = Optional.empty();
    peerAddress = null;
}
#method_after
@Override
public void stop() {
    if (channel != null) {
        log.info("closing jgroups channel {} (cluster {})", channel.getName(), jgroupsConfig.clusterName());
        channel.close();
    }
    peerInfo = Optional.empty();
    peerAddress = null;
}
#end_block

#method_before
public List<ChangeNotes> find(String id) throws OrmException {
    if (id.isEmpty()) {
        return Collections.emptyList();
    }
    int z = id.lastIndexOf('~');
    int y = id.lastIndexOf('~', z - 1);
    if (y < 0 && z > 0) {
        // Try project~numericChangeId
        Integer n = Ints.tryParse(id.substring(z + 1));
        if (n != null) {
            changeIdCounter.increment(ChangeId.PROJECT_NUMERIC_ID);
            return fromProjectNumber(id.substring(0, z), n.intValue());
        }
    }
    if (y < 0 && z < 0) {
        // Try numeric changeId
        Integer n = Ints.tryParse(id);
        if (n != null) {
            changeIdCounter.increment(ChangeId.NUMERIC_ID);
            return find(new Change.Id(n));
        }
    }
    // Use the index to search for changes, but don't return any stored fields,
    // to force rereading in case the index is stale.
    InternalChangeQuery query = queryProvider.get().noFields();
    // Try commit hash
    if (id.matches("^([0-9a-fA-F]{" + RevId.ABBREV_LEN + "," + RevId.LEN + "})$")) {
        changeIdCounter.increment(ChangeId.COMMIT_HASH);
        return asChangeNotes(query.byCommit(id));
    }
    if (y > 0 && z > 0) {
        // Try change triplet (project~branch~Ihash...)
        Optional<ChangeTriplet> triplet = ChangeTriplet.parse(id, y, z);
        if (triplet.isPresent()) {
            ChangeTriplet t = triplet.get();
            changeIdCounter.increment(ChangeId.TRIPLET);
            return asChangeNotes(query.byBranchKey(t.branch(), t.id()));
        }
    }
    // Try isolated Ihash... format ("Change-Id: Ihash").
    List<ChangeNotes> notes = asChangeNotes(query.byKeyPrefix(id));
    if (!notes.isEmpty()) {
        changeIdCounter.increment(ChangeId.CHANGE_ID);
    }
    return notes;
}
#method_after
public List<ChangeNotes> find(String id) throws OrmException {
    if (id.isEmpty()) {
        return Collections.emptyList();
    }
    int z = id.lastIndexOf('~');
    int y = id.lastIndexOf('~', z - 1);
    if (y < 0 && z > 0) {
        // Try project~numericChangeId
        Integer n = Ints.tryParse(id.substring(z + 1));
        if (n != null) {
            changeIdCounter.increment(ChangeIdType.PROJECT_NUMERIC_ID);
            return fromProjectNumber(id.substring(0, z), n.intValue());
        }
    }
    if (y < 0 && z < 0) {
        // Try numeric changeId
        Integer n = Ints.tryParse(id);
        if (n != null) {
            changeIdCounter.increment(ChangeIdType.NUMERIC_ID);
            return find(new Change.Id(n));
        }
    }
    // Use the index to search for changes, but don't return any stored fields,
    // to force rereading in case the index is stale.
    InternalChangeQuery query = queryProvider.get().noFields();
    // Try commit hash
    if (id.matches("^([0-9a-fA-F]{" + RevId.ABBREV_LEN + "," + RevId.LEN + "})$")) {
        changeIdCounter.increment(ChangeIdType.COMMIT_HASH);
        return asChangeNotes(query.byCommit(id));
    }
    if (y > 0 && z > 0) {
        // Try change triplet (project~branch~Ihash...)
        Optional<ChangeTriplet> triplet = ChangeTriplet.parse(id, y, z);
        if (triplet.isPresent()) {
            ChangeTriplet t = triplet.get();
            changeIdCounter.increment(ChangeIdType.TRIPLET);
            return asChangeNotes(query.byBranchKey(t.branch(), t.id()));
        }
    }
    // Try isolated Ihash... format ("Change-Id: Ihash").
    List<ChangeNotes> notes = asChangeNotes(query.byKeyPrefix(id));
    if (!notes.isEmpty()) {
        changeIdCounter.increment(ChangeIdType.CHANGE_ID);
    }
    return notes;
}
#end_block

#method_before
private void setUp(Object target) throws Exception {
    injector = Guice.createInjector(new InMemoryModule());
    injector.injectMembers(this);
    lifecycle = new LifecycleManager();
    lifecycle.add(injector);
    lifecycle.start();
    try (ReviewDb underlyingDb = inMemoryDatabase.getDatabase().open()) {
        schemaCreator.create(underlyingDb);
    }
    db = schemaFactory.open();
    setApiUser(accountManager.authenticate(AuthRequest.forUser("user")).getAccountId());
    // Inject target members after setting API user, so it can @Inject a ReviewDb if it wants.
    injector.injectMembers(target);
}
#method_after
private void setUp(Object target) throws Exception {
    Injector injector = Guice.createInjector(new InMemoryModule());
    injector.injectMembers(this);
    lifecycle = new LifecycleManager();
    lifecycle.add(injector);
    lifecycle.start();
    try (ReviewDb underlyingDb = inMemoryDatabase.getDatabase().open()) {
        schemaCreator.create(underlyingDb);
    }
    db = schemaFactory.open();
    setApiUser(accountManager.authenticate(AuthRequest.forUser("user")).getAccountId());
    // Inject target members after setting API user, so it can @Inject a ReviewDb if it wants.
    injector.injectMembers(target);
}
#end_block

#method_before
@Override
public PureRevertInfo apply(ChangeResource rsrc) throws ResourceConflictException, IOException, BadRequestException, OrmException, AuthException {
    return calculatePureRevert.getPureRevert(rsrc.getNotes(), claimedOriginal);
}
#method_after
@Override
public PureRevertInfo apply(ChangeResource rsrc) throws ResourceConflictException, IOException, BadRequestException, OrmException, AuthException {
    return pureRevert.get(rsrc.getNotes(), claimedOriginal);
}
#end_block

#method_before
@Nullable
public Boolean isPureRevert() throws OrmException {
    if (change().getRevertOf() == null) {
        return null;
    }
    try {
        return pureRevert.getPureRevert(notes(), null).isPureRevert;
    } catch (IOException | BadRequestException | ResourceConflictException e) {
        throw new OrmException("could not compute pure revert", e);
    }
}
#method_after
@Nullable
public Boolean isPureRevert() throws OrmException {
    if (change().getRevertOf() == null) {
        return null;
    }
    try {
        return pureRevert.get(notes(), null).isPureRevert;
    } catch (IOException | BadRequestException | ResourceConflictException e) {
        throw new OrmException("could not compute pure revert", e);
    }
}
#end_block

#method_before
@Override
public PureRevertInfo pureRevert(@Nullable String claimedOriginal) throws RestApiException {
    try {
        return calculatePureRevert.getPureRevert(change.getNotes(), claimedOriginal);
    } catch (Exception e) {
        throw asRestApiException("Cannot compute pure revert", e);
    }
}
#method_after
@Override
public PureRevertInfo pureRevert(@Nullable String claimedOriginal) throws RestApiException {
    try {
        return pureRevert.get(change.getNotes(), claimedOriginal);
    } catch (Exception e) {
        throw asRestApiException("Cannot compute pure revert", e);
    }
}
#end_block

#method_before
private void autoCloseChanges(final ReceiveCommand cmd) {
    logDebug("Starting auto-closing of changes");
    String refName = cmd.getRefName();
    checkState(!MagicBranch.isMagicBranch(refName), "shouldn't be auto-closing changes on magic branch %s", refName);
    RevWalk rw = rp.getRevWalk();
    // insertChangesAndPatchSets.
    try (BatchUpdate bu = batchUpdateFactory.create(db, projectControl.getProject().getNameKey(), user, TimeUtil.nowTs());
        ObjectInserter ins = repo.newObjectInserter()) {
        bu.setRepository(repo, rp.getRevWalk(), ins).updateChangesInParallel();
        bu.setRequestId(receiveId);
        // TODO(dborowitz): Teach BatchUpdate to ignore missing changes.
        RevCommit newTip = rw.parseCommit(cmd.getNewId());
        Branch.NameKey branch = new Branch.NameKey(project.getNameKey(), refName);
        rw.reset();
        rw.markStart(newTip);
        if (!ObjectId.zeroId().equals(cmd.getOldId())) {
            rw.markUninteresting(rw.parseCommit(cmd.getOldId()));
        }
        ListMultimap<ObjectId, Ref> byCommit = changeRefsById();
        Map<Change.Key, ChangeNotes> byKey = null;
        List<ReplaceRequest> replaceAndClose = new ArrayList<>();
        int existingPatchSets = 0;
        int newPatchSets = 0;
        COMMIT: for (RevCommit c; (c = rw.next()) != null; ) {
            rw.parseBody(c);
            for (Ref ref : byCommit.get(c.copy())) {
                existingPatchSets++;
                PatchSet.Id psId = PatchSet.Id.fromRef(ref.getName());
                Optional<ChangeData> cd = byLegacyId(psId.getParentKey());
                if (cd.isPresent() && cd.get().change().getDest().equals(branch)) {
                    bu.addOp(psId.getParentKey(), mergedByPushOpFactory.create(requestScopePropagator, psId, refName));
                    continue COMMIT;
                }
            }
            for (String changeId : c.getFooterLines(CHANGE_ID)) {
                if (byKey == null) {
                    byKey = openChangesByKeyByBranch(branch);
                }
                ChangeNotes onto = byKey.get(new Change.Key(changeId.trim()));
                if (onto != null) {
                    newPatchSets++;
                    // Hold onto this until we're done with the walk, as the call to
                    // req.validate below calls isMergedInto which resets the walk.
                    ReplaceRequest req = new ReplaceRequest(onto.getChangeId(), c, cmd, false);
                    req.notes = onto;
                    replaceAndClose.add(req);
                    continue COMMIT;
                }
            }
        }
        for (final ReplaceRequest req : replaceAndClose) {
            Change.Id id = req.notes.getChangeId();
            if (!req.validate(true)) {
                logDebug("Not closing {} because validation failed", id);
                continue;
            }
            req.addOps(bu, null);
            bu.addOp(id, mergedByPushOpFactory.create(requestScopePropagator, req.psId, refName).setPatchSetProvider(new Provider<PatchSet>() {

                @Override
                public PatchSet get() {
                    return req.replaceOp.getPatchSet();
                }
            }));
            bu.addOp(id, new ChangeProgressOp(closeProgress));
        }
        logDebug("Auto-closing {} changes with existing patch sets and {} with new patch sets", existingPatchSets, newPatchSets);
        bu.execute();
    } catch (RestApiException e) {
        logError("Can't insert patchset", e);
    } catch (IOException | OrmException | UpdateException e) {
        logError("Can't scan for changes to close", e);
    }
}
#method_after
private void autoCloseChanges(final ReceiveCommand cmd) {
    logDebug("Starting auto-closing of changes");
    String refName = cmd.getRefName();
    checkState(!MagicBranch.isMagicBranch(refName), "shouldn't be auto-closing changes on magic branch %s", refName);
    RevWalk rw = rp.getRevWalk();
    // insertChangesAndPatchSets.
    try (BatchUpdate bu = batchUpdateFactory.create(db, projectControl.getProject().getNameKey(), user, TimeUtil.nowTs());
        ObjectInserter ins = repo.newObjectInserter()) {
        bu.setRepository(repo, rp.getRevWalk(), ins).updateChangesInParallel();
        bu.setRequestId(receiveId);
        // TODO(dborowitz): Teach BatchUpdate to ignore missing changes.
        RevCommit newTip = rw.parseCommit(cmd.getNewId());
        Branch.NameKey branch = new Branch.NameKey(project.getNameKey(), refName);
        rw.reset();
        rw.markStart(newTip);
        if (!ObjectId.zeroId().equals(cmd.getOldId())) {
            rw.markUninteresting(rw.parseCommit(cmd.getOldId()));
        }
        ListMultimap<ObjectId, Ref> byCommit = changeRefsById();
        Map<Change.Key, ChangeNotes> byKey = null;
        List<ReplaceRequest> replaceAndClose = new ArrayList<>();
        int existingPatchSets = 0;
        int newPatchSets = 0;
        COMMIT: for (RevCommit c; (c = rw.next()) != null; ) {
            rw.parseBody(c);
            for (Ref ref : byCommit.get(c.copy())) {
                PatchSet.Id psId = PatchSet.Id.fromRef(ref.getName());
                Optional<ChangeData> cd = byLegacyId(psId.getParentKey());
                if (cd.isPresent() && cd.get().change().getDest().equals(branch)) {
                    existingPatchSets++;
                    bu.addOp(psId.getParentKey(), mergedByPushOpFactory.create(requestScopePropagator, psId, refName));
                    continue COMMIT;
                }
            }
            for (String changeId : c.getFooterLines(CHANGE_ID)) {
                if (byKey == null) {
                    byKey = openChangesByKeyByBranch(branch);
                }
                ChangeNotes onto = byKey.get(new Change.Key(changeId.trim()));
                if (onto != null) {
                    newPatchSets++;
                    // Hold onto this until we're done with the walk, as the call to
                    // req.validate below calls isMergedInto which resets the walk.
                    ReplaceRequest req = new ReplaceRequest(onto.getChangeId(), c, cmd, false);
                    req.notes = onto;
                    replaceAndClose.add(req);
                    continue COMMIT;
                }
            }
        }
        for (final ReplaceRequest req : replaceAndClose) {
            Change.Id id = req.notes.getChangeId();
            if (!req.validate(true)) {
                logDebug("Not closing {} because validation failed", id);
                continue;
            }
            req.addOps(bu, null);
            bu.addOp(id, mergedByPushOpFactory.create(requestScopePropagator, req.psId, refName).setPatchSetProvider(new Provider<PatchSet>() {

                @Override
                public PatchSet get() {
                    return req.replaceOp.getPatchSet();
                }
            }));
            bu.addOp(id, new ChangeProgressOp(closeProgress));
        }
        logDebug("Auto-closing {} changes with existing patch sets and {} with new patch sets", existingPatchSets, newPatchSets);
        bu.execute();
    } catch (RestApiException e) {
        logError("Can't insert patchset", e);
    } catch (IOException | OrmException | UpdateException e) {
        logError("Can't scan for changes to close", e);
    }
}
#end_block

#method_before
@Nullable
public Optional<Account> getLoadedAccount() {
    checkLoaded();
    return loadedAccount;
}
#method_after
public Optional<Account> getLoadedAccount() {
    checkLoaded();
    return loadedAccount;
}
#end_block

#method_before
public void setAccount(Account account) {
    checkLoaded();
    this.loadedAccount = Optional.of(checkNotNull(account));
    this.registeredOn = account.getRegisteredOn();
}
#method_after
public void setAccount(Account account) {
    checkLoaded();
    this.loadedAccount = Optional.of(account);
    this.registeredOn = account.getRegisteredOn();
}
#end_block

#method_before
@Override
protected void onLoad() throws IOException, ConfigInvalidException {
    if (revision != null) {
        rw.reset();
        rw.markStart(revision);
        rw.sort(RevSort.REVERSE);
        registeredOn = new Timestamp(rw.next().getCommitTime() * 1000L);
        Config cfg = readConfig(ACCOUNT_CONFIG);
        loadedAccount = Optional.of(parse(cfg, revision.name()));
    }
    isLoaded = true;
}
#method_after
@Override
protected void onLoad() throws IOException, ConfigInvalidException {
    if (revision != null) {
        rw.reset();
        rw.markStart(revision);
        rw.sort(RevSort.REVERSE);
        registeredOn = new Timestamp(rw.next().getCommitTime() * 1000L);
        Config cfg = readConfig(ACCOUNT_CONFIG);
        loadedAccount = Optional.of(parse(cfg, revision.name()));
    } else {
        loadedAccount = Optional.empty();
    }
}
#end_block

#method_before
private void checkLoaded() {
    checkState(isLoaded, "Account %s not loaded yet", accountId.get());
}
#method_after
private void checkLoaded() {
    checkState(loadedAccount != null, "Account %s not loaded yet", accountId.get());
}
#end_block

#method_before
public static TagInfo createTagInfo(PermissionBackend.ForRef perm, Ref ref, RevWalk rw, Project.NameKey projectName, WebLinks links) throws MissingObjectException, IOException {
    RevObject object = rw.parseAny(ref.getObjectId());
    Boolean canDelete = perm.testOrFalse(RefPermission.DELETE) ? true : null;
    List<WebLinkInfo> webLinks = links.getTagLinks(projectName.get(), ref.getName());
    if (object instanceof RevTag) {
        // Annotated or signed tag
        RevTag tag = (RevTag) object;
        PersonIdent tagger = tag.getTaggerIdent();
        return new TagInfo(ref.getName(), tag.getName(), tag.getObject().getName(), tag.getFullMessage().trim(), tagger != null ? CommonConverters.toGitPerson(tagger) : null, canDelete, tagger != null ? new Timestamp(tagger.getWhen().getTime()) : null, webLinks.isEmpty() ? null : webLinks);
    }
    Timestamp timestamp = object instanceof RevCommit ? new Timestamp(((RevCommit) object).getCommitterIdent().getWhen().getTime()) : null;
    // Lightweight tag
    return new TagInfo(ref.getName(), ref.getObjectId().getName(), canDelete, timestamp, webLinks.isEmpty() ? null : webLinks);
}
#method_after
public static TagInfo createTagInfo(PermissionBackend.ForRef perm, Ref ref, RevWalk rw, Project.NameKey projectName, WebLinks links) throws MissingObjectException, IOException {
    RevObject object = rw.parseAny(ref.getObjectId());
    Boolean canDelete = perm.testOrFalse(RefPermission.DELETE) ? true : null;
    List<WebLinkInfo> webLinks = links.getTagLinks(projectName.get(), ref.getName());
    if (object instanceof RevTag) {
        // Annotated or signed tag
        RevTag tag = (RevTag) object;
        PersonIdent tagger = tag.getTaggerIdent();
        return new TagInfo(ref.getName(), tag.getName(), tag.getObject().getName(), tag.getFullMessage().trim(), tagger != null ? CommonConverters.toGitPerson(tagger) : null, canDelete, webLinks.isEmpty() ? null : webLinks, tagger != null ? new Timestamp(tagger.getWhen().getTime()) : null);
    }
    Timestamp timestamp = object instanceof RevCommit ? new Timestamp(((RevCommit) object).getCommitterIdent().getWhen().getTime()) : null;
    // Lightweight tag
    return new TagInfo(ref.getName(), ref.getObjectId().getName(), canDelete, webLinks.isEmpty() ? null : webLinks, timestamp);
}
#end_block

#method_before
private SiteIndexer.Result reindexGroups(GroupIndex index, List<AccountGroup.UUID> uuids, ProgressMonitor progress) {
    progress.beginTask("Reindexing groups", uuids.size());
    List<ListenableFuture<?>> futures = new ArrayList<>(uuids.size());
    AtomicBoolean ok = new AtomicBoolean(true);
    AtomicInteger done = new AtomicInteger();
    AtomicInteger failed = new AtomicInteger();
    Stopwatch sw = Stopwatch.createStarted();
    for (AccountGroup.UUID uuid : uuids) {
        String desc = "group " + uuid;
        ListenableFuture<?> future = executor.submit(() -> {
            try {
                Optional<InternalGroup> oldGroup = groupCache.get(uuid);
                if (oldGroup.isPresent()) {
                    InternalGroup group = oldGroup.get();
                    groupCache.evict(group.getGroupUUID(), group.getId(), group.getNameKey());
                } else {
                    // The UUID here is read from group name notes. If it fails to load from group
                    // cache, there exists an inconsistency.
                    GroupsNoteDbConsistencyChecker.logConsistencyProblemAsWarning("Group with UUID %s from group name notes is failed to load from group ref", uuid);
                }
                Optional<InternalGroup> internalGroup = groupCache.get(uuid);
                if (internalGroup.isPresent()) {
                    index.replace(internalGroup.get());
                } else {
                    index.delete(uuid);
                }
                verboseWriter.println("Reindexed " + desc);
                done.incrementAndGet();
            } catch (Exception e) {
                failed.incrementAndGet();
                throw e;
            }
            return null;
        });
        addErrorListener(future, desc, progress, ok);
        futures.add(future);
    }
    try {
        Futures.successfulAsList(futures).get();
    } catch (ExecutionException | InterruptedException e) {
        log.error("Error waiting on group futures", e);
        return new SiteIndexer.Result(sw, false, 0, 0);
    }
    progress.endTask();
    return new SiteIndexer.Result(sw, ok.get(), done.get(), failed.get());
}
#method_after
private SiteIndexer.Result reindexGroups(GroupIndex index, List<AccountGroup.UUID> uuids, ProgressMonitor progress) {
    progress.beginTask("Reindexing groups", uuids.size());
    List<ListenableFuture<?>> futures = new ArrayList<>(uuids.size());
    AtomicBoolean ok = new AtomicBoolean(true);
    AtomicInteger done = new AtomicInteger();
    AtomicInteger failed = new AtomicInteger();
    Stopwatch sw = Stopwatch.createStarted();
    for (AccountGroup.UUID uuid : uuids) {
        String desc = "group " + uuid;
        ListenableFuture<?> future = executor.submit(() -> {
            try {
                Optional<InternalGroup> oldGroup = groupCache.get(uuid);
                if (oldGroup.isPresent()) {
                    InternalGroup group = oldGroup.get();
                    groupCache.evict(group.getGroupUUID(), group.getId(), group.getNameKey());
                }
                Optional<InternalGroup> internalGroup = groupCache.get(uuid);
                if (internalGroup.isPresent()) {
                    index.replace(internalGroup.get());
                } else {
                    index.delete(uuid);
                    // The UUID here is read from group name notes. If it fails to load from group
                    // cache, there exists an inconsistency.
                    GroupsNoteDbConsistencyChecker.logFailToLoadFromGroupRefAsWarning(uuid);
                }
                verboseWriter.println("Reindexed " + desc);
                done.incrementAndGet();
            } catch (Exception e) {
                failed.incrementAndGet();
                throw e;
            }
            return null;
        });
        addErrorListener(future, desc, progress, ok);
        futures.add(future);
    }
    try {
        Futures.successfulAsList(futures).get();
    } catch (ExecutionException | InterruptedException e) {
        log.error("Error waiting on group futures", e);
        return new SiteIndexer.Result(sw, false, 0, 0);
    }
    progress.endTask();
    return new SiteIndexer.Result(sw, ok.get(), done.get(), failed.get());
}
#end_block

#method_before
public static List<ConsistencyProblemInfo> checkWithGroupNameNotes(Repository allUsersRepo, String name, AccountGroup.UUID uuid) {
    try {
        Ref ref = allUsersRepo.exactRef(RefNames.REFS_GROUPNAMES);
        if (ref == null) {
            return Arrays.asList(warning("ref %s does not exist", RefNames.REFS_GROUPNAMES));
        }
        try (RevWalk revWalk = new RevWalk(allUsersRepo);
            ObjectReader reader = revWalk.getObjectReader()) {
            RevCommit notesCommit = revWalk.parseCommit(ref.getObjectId());
            NoteMap noteMap = NoteMap.read(reader, notesCommit);
            ObjectId noteDataBlobId = noteMap.get(GroupNameNotes.getNoteKey(new AccountGroup.NameKey(name)));
            if (noteDataBlobId == null) {
                return Arrays.asList(warning("Group with name '%s' doesn't exist in the list of all names", name));
            }
            List<ConsistencyProblemInfo> problems = new ArrayList<>();
            GroupReference groupRef = getGroupReference(reader, noteDataBlobId);
            if (!Objects.equals(uuid, groupRef.getUUID())) {
                problems.add(warning("group with name '%s' has UUID '%s' in 'group.config' while '%s' in group name notes", name, uuid, groupRef.getUUID()));
            }
            if (!Objects.equals(name, groupRef.getName())) {
                problems.add(warning("group with UUID '%s' has name '%s' in 'group.config' while '%s' in group name notes", uuid, name, groupRef.getName()));
            }
            return problems;
        }
    } catch (IOException | ConfigInvalidException e) {
        return Arrays.asList(warning("fail to check consistency with group name notes"));
    }
}
#method_after
@VisibleForTesting
static List<ConsistencyProblemInfo> checkWithGroupNameNotes(Repository allUsersRepo, String groupName, AccountGroup.UUID groupUUID) throws IOException {
    try {
        Optional<GroupReference> groupRef = GroupNameNotes.loadOneGroupReference(allUsersRepo, groupName);
        if (!groupRef.isPresent()) {
            return ImmutableList.of(warning("Group with name '%s' doesn't exist in the list of all names", groupName));
        }
        AccountGroup.UUID uuid = groupRef.get().getUUID();
        String name = groupRef.get().getName();
        List<ConsistencyProblemInfo> problems = new ArrayList<>();
        if (!Objects.equals(groupUUID, uuid)) {
            problems.add(warning("group with name '%s' has UUID '%s' in 'group.config' but '%s' in group name notes", groupName, groupUUID, uuid));
        }
        if (!Objects.equals(groupName, name)) {
            problems.add(warning("group note of name '%s' claims to represent name of '%s'", groupName, name));
        }
        return problems;
    } catch (ConfigInvalidException e) {
        return ImmutableList.of(warning("fail to check consistency with group name notes: %s", e.getMessage()));
    }
}
#end_block

#method_before
public static void logConsistencyProblem(ConsistencyProblemInfo p) {
    if (p.status == ConsistencyProblemInfo.Status.WARNING) {
        log.warn(GROUP_CONSISTENCY_CHECK_LOG_PREFIX + p.message);
    } else {
        log.error(GROUP_CONSISTENCY_CHECK_LOG_PREFIX + p.message);
    }
}
#method_after
public static void logConsistencyProblem(ConsistencyProblemInfo p) {
    if (p.status == ConsistencyProblemInfo.Status.WARNING) {
        log.warn(p.message);
    } else {
        log.error(p.message);
    }
}
#end_block

#method_before
@Override
public int run() throws Exception {
    Injector dbInjector = createDbInjector(DataSourceProvider.Context.SINGLE_USER);
    SitePaths sitePaths = new SitePaths(getSitePath());
    ThreadSettingsConfig threadSettingsConfig = dbInjector.getInstance(ThreadSettingsConfig.class);
    Config fakeCfg = new Config();
    if (!Strings.isNullOrEmpty(sourceUrl)) {
        fakeCfg.setString("accountPatchReviewDb", null, "url", sourceUrl);
    }
    JdbcAccountPatchReviewStore sourceJdbcAccountPatchReviewStore = JdbcAccountPatchReviewStore.createAccountPatchReviewStore(fakeCfg, sitePaths, threadSettingsConfig);
    Config cfg = dbInjector.getInstance(Key.get(Config.class, GerritServerConfig.class));
    String targetUrl = cfg.getString("accountPatchReviewDb", null, "url");
    if (targetUrl == null) {
        System.err.println("accountPatchReviewDb.url is null in gerrit.config");
        return 1;
    }
    System.out.println("target Url: " + targetUrl);
    JdbcAccountPatchReviewStore targetJdbcAccountPatchReviewStore = JdbcAccountPatchReviewStore.createAccountPatchReviewStore(cfg, sitePaths, threadSettingsConfig);
    targetJdbcAccountPatchReviewStore.createTableIfNotExists();
    if (!isTargetTableEmpty(targetJdbcAccountPatchReviewStore)) {
        System.err.println("target table is not empty, cannot proceed");
        return 1;
    }
    try (Connection sourceCon = sourceJdbcAccountPatchReviewStore.getConnection();
        Connection targetCon = targetJdbcAccountPatchReviewStore.getConnection();
        PreparedStatement sourceStmt = sourceCon.prepareStatement("SELECT account_id, change_id, patch_set_id, file_name " + "FROM account_patch_reviews " + "LIMIT ? " + "OFFSET ?");
        PreparedStatement targetStmt = targetCon.prepareStatement("INSERT INTO account_patch_reviews " + "(account_id, change_id, patch_set_id, file_name) VALUES " + "(?, ?, ?, ?)")) {
        targetCon.setAutoCommit(false);
        long offset = 0;
        Stopwatch sw = Stopwatch.createStarted();
        List<Row> rows = selectRows(sourceStmt, offset);
        while (!rows.isEmpty()) {
            insertRows(targetCon, targetStmt, rows);
            offset += rows.size();
            System.out.printf("%8d rows migrated\n", offset);
            rows = selectRows(sourceStmt, offset);
        }
        double t = sw.elapsed(TimeUnit.MILLISECONDS) / 1000d;
        System.out.printf("Migrated %8d rows in %.01fs (%.01f/s)\n", offset, t, offset / t);
    }
    return 0;
}
#method_after
@Override
public int run() throws Exception {
    Injector dbInjector = createDbInjector(DataSourceProvider.Context.SINGLE_USER);
    SitePaths sitePaths = new SitePaths(getSitePath());
    ThreadSettingsConfig threadSettingsConfig = dbInjector.getInstance(ThreadSettingsConfig.class);
    Config fakeCfg = new Config();
    if (!Strings.isNullOrEmpty(sourceUrl)) {
        fakeCfg.setString("accountPatchReviewDb", null, "url", sourceUrl);
    }
    JdbcAccountPatchReviewStore sourceJdbcAccountPatchReviewStore = JdbcAccountPatchReviewStore.createAccountPatchReviewStore(fakeCfg, sitePaths, threadSettingsConfig);
    Config cfg = dbInjector.getInstance(Key.get(Config.class, GerritServerConfig.class));
    String targetUrl = cfg.getString("accountPatchReviewDb", null, "url");
    if (targetUrl == null) {
        System.err.println("accountPatchReviewDb.url is null in gerrit.config");
        return 1;
    }
    System.out.println("target Url: " + targetUrl);
    JdbcAccountPatchReviewStore targetJdbcAccountPatchReviewStore = JdbcAccountPatchReviewStore.createAccountPatchReviewStore(cfg, sitePaths, threadSettingsConfig);
    targetJdbcAccountPatchReviewStore.createTableIfNotExists();
    if (!isTargetTableEmpty(targetJdbcAccountPatchReviewStore)) {
        System.err.println("target table is not empty, cannot proceed");
        return 1;
    }
    try (Connection sourceCon = sourceJdbcAccountPatchReviewStore.getConnection();
        Connection targetCon = targetJdbcAccountPatchReviewStore.getConnection();
        PreparedStatement sourceStmt = sourceCon.prepareStatement("SELECT account_id, change_id, patch_set_id, file_name " + "FROM account_patch_reviews " + "LIMIT ? " + "OFFSET ?");
        PreparedStatement targetStmt = targetCon.prepareStatement("INSERT INTO account_patch_reviews " + "(account_id, change_id, patch_set_id, file_name) VALUES " + "(?, ?, ?, ?)")) {
        targetCon.setAutoCommit(false);
        long offset = 0;
        Stopwatch sw = Stopwatch.createStarted();
        List<Row> rows = selectRows(sourceStmt, offset);
        while (!rows.isEmpty()) {
            insertRows(targetCon, targetStmt, rows);
            offset += rows.size();
            System.out.printf("%8d rows migrated\n", offset);
            rows = selectRows(sourceStmt, offset);
        }
        double t = sw.elapsed(TimeUnit.MILLISECONDS) / 1000d;
        System.out.printf("Migrated %d rows in %.01fs (%.01f/s)\n", offset, t, offset / t);
    }
    return 0;
}
#end_block

#method_before
@Override
public int run() throws Exception {
    Injector dbInjector = createDbInjector(DataSourceProvider.Context.SINGLE_USER);
    SitePaths sitePaths = new SitePaths(getSitePath());
    ThreadSettingsConfig threadSettingsConfig = dbInjector.getInstance(ThreadSettingsConfig.class);
    Config fakeCfg = new Config();
    if (!Strings.isNullOrEmpty(sourceUrl)) {
        fakeCfg.setString("accountPatchReviewDb", null, "url", sourceUrl);
    }
    JdbcAccountPatchReviewStore sourceJdbcAccountPatchReviewStore = JdbcAccountPatchReviewStore.createAccountPatchReviewStore(fakeCfg, sitePaths, threadSettingsConfig);
    Config cfg = dbInjector.getInstance(Key.get(Config.class, GerritServerConfig.class));
    String targetUrl = cfg.getString("accountPatchReviewDb", null, "url");
    if (targetUrl == null) {
        System.err.println("accountPatchReviewDb.url is null in gerrit.config");
        return 1;
    }
    System.out.println("target Url: " + targetUrl);
    JdbcAccountPatchReviewStore targetJdbcAccountPatchReviewStore = JdbcAccountPatchReviewStore.createAccountPatchReviewStore(cfg, sitePaths, threadSettingsConfig);
    targetJdbcAccountPatchReviewStore.createTableIfNotExists();
    if (!isTargetTableEmpty(targetJdbcAccountPatchReviewStore)) {
        System.err.println("target table is not empty, cannot proceed");
        return 1;
    }
    try (Connection sourceCon = sourceJdbcAccountPatchReviewStore.getConnection();
        Connection targetCon = targetJdbcAccountPatchReviewStore.getConnection();
        PreparedStatement sourceStmt = sourceCon.prepareStatement("SELECT account_id, change_id, patch_set_id, file_name " + "FROM account_patch_reviews " + "LIMIT ? " + "OFFSET ?");
        PreparedStatement targetStmt = targetCon.prepareStatement("INSERT INTO account_patch_reviews " + "(account_id, change_id, patch_set_id, file_name_sha1, file_name) VALUES " + "(?, ?, ?, ?, ?)")) {
        targetCon.setAutoCommit(false);
        long offset = 0;
        List<Row> rows = selectRows(sourceStmt, offset);
        while (!rows.isEmpty()) {
            insertRows(targetCon, targetStmt, rows);
            offset += rows.size();
            System.out.printf("%8d rows migrated\n", offset);
            rows = selectRows(sourceStmt, offset);
        }
        System.out.println("Done");
    }
    return 0;
}
#method_after
@Override
public int run() throws Exception {
    Injector dbInjector = createDbInjector(DataSourceProvider.Context.SINGLE_USER);
    SitePaths sitePaths = new SitePaths(getSitePath());
    ThreadSettingsConfig threadSettingsConfig = dbInjector.getInstance(ThreadSettingsConfig.class);
    Config fakeCfg = new Config();
    if (!Strings.isNullOrEmpty(sourceUrl)) {
        fakeCfg.setString("accountPatchReviewDb", null, "url", sourceUrl);
    }
    JdbcAccountPatchReviewStore sourceJdbcAccountPatchReviewStore = JdbcAccountPatchReviewStore.createAccountPatchReviewStore(fakeCfg, sitePaths, threadSettingsConfig);
    Config cfg = dbInjector.getInstance(Key.get(Config.class, GerritServerConfig.class));
    String targetUrl = cfg.getString("accountPatchReviewDb", null, "url");
    if (targetUrl == null) {
        System.err.println("accountPatchReviewDb.url is null in gerrit.config");
        return 1;
    }
    System.out.println("target Url: " + targetUrl);
    JdbcAccountPatchReviewStore targetJdbcAccountPatchReviewStore = JdbcAccountPatchReviewStore.createAccountPatchReviewStore(cfg, sitePaths, threadSettingsConfig);
    targetJdbcAccountPatchReviewStore.createTableIfNotExists();
    if (!isTargetTableEmpty(targetJdbcAccountPatchReviewStore)) {
        System.err.println("target table is not empty, cannot proceed");
        return 1;
    }
    try (Connection sourceCon = sourceJdbcAccountPatchReviewStore.getConnection();
        Connection targetCon = targetJdbcAccountPatchReviewStore.getConnection();
        PreparedStatement sourceStmt = sourceCon.prepareStatement("SELECT account_id, change_id, patch_set_id, file_name " + "FROM account_patch_reviews " + "LIMIT ? " + "OFFSET ?");
        PreparedStatement targetStmt = targetCon.prepareStatement("INSERT INTO account_patch_reviews " + "(account_id, change_id, patch_set_id, file_name) VALUES " + "(?, ?, ?, ?)")) {
        targetCon.setAutoCommit(false);
        long offset = 0;
        List<Row> rows = selectRows(sourceStmt, offset);
        while (!rows.isEmpty()) {
            insertRows(targetCon, targetStmt, rows);
            offset += rows.size();
            System.out.printf("%8d rows migrated\n", offset);
            rows = selectRows(sourceStmt, offset);
        }
        System.out.println("Done");
    }
    return 0;
}
#end_block

#method_before
private static void insertRows(Connection con, PreparedStatement stmt, List<Row> rows) throws SQLException {
    for (Row r : rows) {
        stmt.setLong(1, r.accountId());
        stmt.setLong(2, r.changeId());
        stmt.setLong(3, r.patchSetId());
        stmt.setString(4, sha1(r.fileName()));
        stmt.setString(5, r.fileName());
        stmt.addBatch();
    }
    stmt.executeBatch();
    con.commit();
}
#method_after
private static void insertRows(Connection con, PreparedStatement stmt, List<Row> rows) throws SQLException {
    for (Row r : rows) {
        stmt.setLong(1, r.accountId());
        stmt.setLong(2, r.changeId());
        stmt.setLong(3, r.patchSetId());
        stmt.setString(4, r.fileName());
        stmt.addBatch();
    }
    stmt.executeBatch();
    con.commit();
}
#end_block

#method_before
private boolean shouldReplicate(Project.NameKey project, ReplicationState... states) {
    try {
        ProjectState projectState;
        try {
            projectState = projectCache.checkedGet(project);
        } catch (IOException e) {
            return false;
        }
        if (projectState == null) {
            throw new NoSuchProjectException(project);
        }
        return shouldReplicate(projectState, userProvider.get());
    } catch (NoSuchProjectException err) {
        stateLog.error(String.format("source project %s not available", project), err, states);
    } catch (Exception e) {
        Throwables.throwIfUnchecked(e);
        throw new RuntimeException(e);
    }
    return false;
}
#method_after
private boolean shouldReplicate(Project.NameKey project, ReplicationState... states) {
    try {
        return threadScoper.scope(new Callable<Boolean>() {

            @Override
            public Boolean call() throws NoSuchProjectException, PermissionBackendException {
                ProjectState projectState;
                try {
                    projectState = projectCache.checkedGet(project);
                } catch (IOException e) {
                    return false;
                }
                if (projectState == null) {
                    throw new NoSuchProjectException(project);
                }
                return shouldReplicate(projectState, userProvider.get());
            }
        }).call();
    } catch (NoSuchProjectException err) {
        stateLog.error(String.format("source project %s not available", project), err, states);
    } catch (Exception e) {
        Throwables.throwIfUnchecked(e);
        throw new RuntimeException(e);
    }
    return false;
}
#end_block

#method_before
private String getCommentChangeEvent(String action, String prefix, Map<String, String> map) {
    String ret = "";
    String changeNumber = Strings.nullToEmpty(map.get("changeNumber"));
    if (!changeNumber.isEmpty()) {
        changeNumber += " ";
    }
    ret += "Change " + changeNumber + action;
    String submitter = formatPerson(prefix, map);
    if (!submitter.isEmpty()) {
        ret += " by " + submitter;
    }
    String subject = Strings.nullToEmpty(map.get("subject"));
    if (!subject.isEmpty()) {
        ret += ":\n" + subject;
    }
    String reason = Strings.nullToEmpty(map.get("reason"));
    if (!reason.isEmpty()) {
        ret += "\n\nReason:\n" + reason;
    }
    String url = Strings.nullToEmpty(map.get("changeUrl"));
    if (!url.isEmpty()) {
        ret += "\n\n" + its.createLinkForWebui(url, url);
    }
    return ret;
}
#method_after
private String getCommentChangeEvent(String action, String prefix, Map<String, String> map) {
    String ret = "";
    String changeNumber = getValueFromMap(map, "", "change-number", "changeNumber");
    if (!changeNumber.isEmpty()) {
        changeNumber += " ";
    }
    ret += "Change " + changeNumber + action;
    String submitter = getValueFromMap(map, prefix, "-name", "Name", "-username", "Username");
    if (!submitter.isEmpty()) {
        ret += " by " + submitter;
    }
    String subject = Strings.nullToEmpty(map.get("subject"));
    if (!subject.isEmpty()) {
        ret += ":\n" + subject;
    }
    String reason = Strings.nullToEmpty(map.get("reason"));
    if (!reason.isEmpty()) {
        ret += "\n\nReason:\n" + reason;
    }
    String url = getValueFromMap(map, "", "change-url", "changeUrl");
    if (!url.isEmpty()) {
        ret += "\n\n" + its.createLinkForWebui(url, url);
    }
    return ret;
}
#end_block

#method_before
@Test
public void rebuild() throws Exception {
    assume().that(groupsMigration.writeToNoteDb()).isTrue();
    assume().that(groupsMigration.readFromNoteDb()).isFalse();
    GroupInfo g = gApi.groups().create(name("group")).get();
    AccountGroup.UUID uuid = new AccountGroup.UUID(g.id);
    String refName = RefNames.refsGroups(uuid);
    ObjectId oldId;
    GroupBundle oldBundle;
    try (Repository repo = repoManager.openRepository(allUsers)) {
        oldId = repo.exactRef(refName).getObjectId();
        oldBundle = bundleFactory.fromNoteDb(repo, uuid);
        new TestRepository<>(repo).delete(refName);
    }
    assertThat(adminRestSession.postOK("/groups/" + uuid + "/rebuild", "").getEntityContent()).isEqualTo("No differences between ReviewDb and NoteDb");
    try (Repository repo = repoManager.openRepository(allUsers)) {
        Ref ref = repo.exactRef(refName);
        assertThat(ref).isNotNull();
        // An artifact of the migration process makes the SHA-1 different, but it's actually ok
        // because the bundles are equal.
        assertThat(ref.getObjectId()).isNotEqualTo(oldId);
        // Comparing NoteDb to NoteDb, so compare fields instead of using static compare method.
        GroupBundle newBundle = bundleFactory.fromNoteDb(repo, uuid);
        assertThat(newBundle.group()).isEqualTo(oldBundle.group());
        assertThat(newBundle.members()).isEqualTo(oldBundle.members());
        assertThat(newBundle.memberAudit()).isEqualTo(oldBundle.memberAudit());
        assertThat(newBundle.byId()).isEqualTo(oldBundle.byId());
        assertThat(newBundle.byIdAudit()).isEqualTo(oldBundle.byIdAudit());
    }
}
#method_after
@Test
public void rebuild() throws Exception {
    assume().that(groupsMigration.writeToNoteDb()).isTrue();
    assume().that(groupsMigration.readFromNoteDb()).isFalse();
    GroupInfo g = gApi.groups().create(name("group")).get();
    AccountGroup.UUID uuid = new AccountGroup.UUID(g.id);
    String refName = RefNames.refsGroups(uuid);
    ObjectId oldId;
    GroupBundle oldBundle;
    try (Repository repo = repoManager.openRepository(allUsers)) {
        oldId = repo.exactRef(refName).getObjectId();
        oldBundle = bundleFactory.fromNoteDb(repo, uuid);
        new TestRepository<>(repo).delete(refName);
    }
    assertThat(adminRestSession.postOK("/groups/" + uuid + "/rebuild", input(null)).getEntityContent()).isEqualTo("No differences between ReviewDb and NoteDb");
    try (Repository repo = repoManager.openRepository(allUsers)) {
        Ref ref = repo.exactRef(refName);
        assertThat(ref).isNotNull();
        // An artifact of the migration process makes the SHA-1 different, but it's actually ok
        // because the bundles are equal.
        assertThat(ref.getObjectId()).isNotEqualTo(oldId);
        assertNoDifferences(oldBundle, bundleFactory.fromNoteDb(repo, uuid));
    }
}
#end_block

#method_before
@Override
public BinaryResult apply(GroupResource rsrc, Input input) throws RestApiException, ConfigInvalidException, OrmException, IOException {
    if (!migration.writeToNoteDb()) {
        throw new BadRequestException("NoteDb writes must be enabled");
    }
    if (!rsrc.isInternalGroup()) {
        throw new BadRequestException("not an internal group");
    }
    try (Repository repo = repoManager.openRepository(allUsers)) {
        GroupBundle reviewDbBundle = bundleFactory.fromReviewDb(db.get(), rsrc.asInternalGroup().get().getId());
        try {
            rebuilder.rebuild(repo, reviewDbBundle, null);
        } catch (LockFailureException e) {
            throw new ResourceConflictException("rebuild failed with lock failure");
        }
        repo.scanForRepoChanges();
        GroupBundle noteDbBundle = bundleFactory.fromNoteDb(repo, rsrc.getGroup().getGroupUUID());
        List<String> diffs = GroupBundle.compare(reviewDbBundle, noteDbBundle);
        if (diffs.isEmpty()) {
            return BinaryResult.create("No differences between ReviewDb and NoteDb");
        }
        return BinaryResult.create(diffs.stream().collect(joining("\n", "Differences between ReviewDb and NoteDb:\n", "\n")));
    }
}
#method_after
@Override
public BinaryResult apply(GroupResource rsrc, Input input) throws RestApiException, ConfigInvalidException, OrmException, IOException {
    boolean force = firstNonNull(input.force, false);
    if (!migration.writeToNoteDb()) {
        throw new MethodNotAllowedException("NoteDb writes must be enabled");
    }
    if (migration.readFromNoteDb() && force) {
        throw new MethodNotAllowedException("NoteDb reads must not be enabled when force=true");
    }
    if (!rsrc.isInternalGroup()) {
        throw new MethodNotAllowedException("Not an internal group");
    }
    AccountGroup.UUID uuid = rsrc.getGroup().getGroupUUID();
    try (Repository repo = repoManager.openRepository(allUsers)) {
        if (force) {
            RefUpdateUtil.deleteChecked(repo, RefNames.refsGroups(uuid));
        }
        GroupBundle reviewDbBundle = bundleFactory.fromReviewDb(db.get(), rsrc.asInternalGroup().get().getId());
        try {
            rebuilder.rebuild(repo, reviewDbBundle, null);
        } catch (OrmDuplicateKeyException e) {
            throw new ResourceConflictException("Group already exists in NoteDb");
        }
        GroupBundle noteDbBundle = bundleFactory.fromNoteDb(repo, uuid);
        List<String> diffs = GroupBundle.compare(reviewDbBundle, noteDbBundle);
        if (diffs.isEmpty()) {
            return BinaryResult.create("No differences between ReviewDb and NoteDb");
        }
        return BinaryResult.create(diffs.stream().collect(joining("\n", "Differences between ReviewDb and NoteDb:\n", "\n")));
    }
}
#end_block

#method_before
public String[] getIssueIds(String haystack) {
    Pattern pattern = itsConfig.getIssuePattern();
    if (pattern == null)
        return new String[] {};
    log.debug("Matching '" + haystack + "' against " + pattern.pattern());
    Set<String> issues = Sets.newHashSet();
    Matcher matcher = pattern.matcher(haystack);
    int groupIdx = itsConfig.getIssuePatternGroupIndex();
    while (matcher.find()) {
        String issueId = matcher.group(groupIdx);
        if (!Strings.isNullOrEmpty(issueId)) {
            issues.add(issueId);
        }
    }
    return issues.toArray(new String[issues.size()]);
}
#method_after
public String[] getIssueIds(String haystack) {
    Pattern pattern = itsConfig.getIssuePattern();
    if (pattern == null)
        return new String[] {};
    log.debug("Matching '{}' against {}", haystack, pattern.pattern());
    Set<String> issues = Sets.newHashSet();
    Matcher matcher = pattern.matcher(haystack);
    int groupIdx = itsConfig.getIssuePatternGroupIndex();
    while (matcher.find()) {
        String issueId = matcher.group(groupIdx);
        if (!Strings.isNullOrEmpty(issueId)) {
            issues.add(issueId);
        }
    }
    return issues.toArray(new String[issues.size()]);
}
#end_block

#method_before
public String[] getIssueIds(String haystack) {
    Pattern pattern = itsConfig.getIssuePattern();
    if (pattern == null)
        return new String[] {};
    log.debug("Matching '{}' against '", haystack, pattern.pattern());
    Set<String> issues = Sets.newHashSet();
    Matcher matcher = pattern.matcher(haystack);
    int groupIdx = itsConfig.getIssuePatternGroupIndex();
    while (matcher.find()) {
        String issueId = matcher.group(groupIdx);
        if (!Strings.isNullOrEmpty(issueId)) {
            issues.add(issueId);
        }
    }
    return issues.toArray(new String[issues.size()]);
}
#method_after
public String[] getIssueIds(String haystack) {
    Pattern pattern = itsConfig.getIssuePattern();
    if (pattern == null)
        return new String[] {};
    log.debug("Matching '{}' against {}", haystack, pattern.pattern());
    Set<String> issues = Sets.newHashSet();
    Matcher matcher = pattern.matcher(haystack);
    int groupIdx = itsConfig.getIssuePatternGroupIndex();
    while (matcher.find()) {
        String issueId = matcher.group(groupIdx);
        if (!Strings.isNullOrEmpty(issueId)) {
            issues.add(issueId);
        }
    }
    return issues.toArray(new String[issues.size()]);
}
#end_block

#method_before
private void addIssuesOccurrence(String text, String occurrence, Map<String, Set<String>> map) {
    for (String issue : getIssueIds(text)) {
        Set<String> occurrences = map.computeIfAbsent(issue, k -> Sets.newLinkedHashSet());
        occurrences.add(occurrence);
    }
}
#method_after
private void addIssuesOccurrence(String text, String occurrence, Map<String, Set<String>> map) {
    for (String issue : getIssueIds(text)) {
        Set<String> occurrences = map.get(issue);
        if (occurrences == null) {
            occurrences = Sets.newLinkedHashSet();
            map.put(issue, occurrences);
        }
        occurrences.add(occurrence);
    }
}
#end_block

#method_before
public boolean isEnabled(Project.NameKey projectNK, String refName) {
    ProjectState projectState = projectCache.get(projectNK);
    if (projectState == null) {
        log.error("Failed to check if {} is enabled for project {}: Project not found", pluginName, projectNK.get(), projectNK.get());
        return false;
    }
    if (isEnforcedByAnyParentProject(refName, projectState)) {
        return true;
    }
    return !"false".equals(pluginCfgFactory.getFromProjectConfigWithInheritance(projectState, pluginName).getString("enabled", "false")) && isEnabledForBranch(projectState, refName);
}
#method_after
public boolean isEnabled(Project.NameKey projectNK, String refName) {
    ProjectState projectState = projectCache.get(projectNK);
    if (projectState == null) {
        log.error("Failed to check if {} is enabled for project {}: Project not found", pluginName, projectNK.get());
        return false;
    }
    if (isEnforcedByAnyParentProject(refName, projectState)) {
        return true;
    }
    return !"false".equals(pluginCfgFactory.getFromProjectConfigWithInheritance(projectState, pluginName).getString("enabled", "false")) && isEnabledForBranch(projectState, refName);
}
#end_block

#method_before
private List<CommentLinkInfo> getCommentLinkInfo(final String commentlinkName) {
    NameKey projectName = currentProjectName.get();
    if (projectName != null) {
        List<CommentLinkInfo> commentlinks = projectCache.get(projectName).getCommentLinks();
        return commentlinks.stream().filter(input -> input.name.equals(commentlinkName)).collect(Collectors.toList());
    }
    return Collections.emptyList();
}
#method_after
private List<CommentLinkInfo> getCommentLinkInfo(final String commentlinkName) {
    NameKey projectName = currentProjectName.get();
    if (projectName != null) {
        List<CommentLinkInfo> commentlinks = projectCache.get(projectName).getCommentLinks();
        return commentlinks.stream().filter(input -> input.name.equals(commentlinkName)).collect(toList());
    }
    return Collections.emptyList();
}
#end_block

#method_before
private List<CommentLinkInfo> getCommentLinkInfo(final String commentlinkName) {
    NameKey projectName = currentProjectName.get();
    if (projectName != null) {
        List<CommentLinkInfo> commentlinks = projectCache.get(projectName).getCommentLinks();
        return commentlinks.stream().filter(input -> input.name.equals(commentlinkName)).collect(Collectors.toList());
    }
    return Collections.emptyList();
}
#method_after
private List<CommentLinkInfo> getCommentLinkInfo(final String commentlinkName) {
    NameKey projectName = currentProjectName.get();
    if (projectName != null) {
        List<CommentLinkInfo> commentlinks = projectCache.get(projectName).getCommentLinks();
        return commentlinks.stream().filter(input -> input.name.equals(commentlinkName)).collect(toList());
    }
    return Collections.emptyList();
}
#end_block

#method_before
@Test
@Sandboxed
public void putStatus() throws Exception {
    List<String> statuses = ImmutableList.of("OOO", "Busy");
    AccountInfo info;
    for (String status : statuses) {
        gApi.accounts().self().setStatus(status);
        info = gApi.accounts().self().get();
        assertUser(info, admin, status);
        accountIndexedCounter.assertReindexOf(admin);
    }
}
#method_after
@Test
public void putStatus() throws Exception {
    List<String> statuses = ImmutableList.of("OOO", "Busy");
    AccountInfo info;
    try {
        for (String status : statuses) {
            gApi.accounts().self().setStatus(status);
            info = gApi.accounts().self().get();
            assertUser(info, admin, status);
            accountIndexedCounter.assertReindexOf(admin);
        }
    } finally {
        gApi.accounts().self().setStatus(null);
        info = gApi.accounts().self().get();
        assertUser(info, admin);
        accountIndexedCounter.assertReindexOf(admin);
    }
}
#end_block

#method_before
public Multimap<String, AccountState> byPreferredEmail(String... emails) throws OrmException {
    List<String> emailList = Arrays.asList(emails);
    if (hasPreferredEmailExact()) {
        List<List<AccountState>> r = query(emailList.stream().map(e -> AccountPredicates.preferredEmailExact(e)).collect(toList()));
        Multimap<String, AccountState> accountsByEmail = ArrayListMultimap.create();
        for (int i = 0; i < emailList.size(); i++) {
            accountsByEmail.putAll(emailList.get(i), r.get(i));
        }
        return accountsByEmail;
    }
    if (hasPreferredEmail()) {
        List<List<AccountState>> r = query(emailList.stream().map(e -> AccountPredicates.preferredEmail(e)).collect(toList()));
        Multimap<String, AccountState> accountsByEmail = ArrayListMultimap.create();
        for (int i = 0; i < emailList.size(); i++) {
            String email = emailList.get(i);
            Set<AccountState> matchingAccounts = r.get(i).stream().filter(a -> a.getAccount().getPreferredEmail().equals(email)).collect(toSet());
            accountsByEmail.putAll(email, matchingAccounts);
        }
        return accountsByEmail;
    }
    return ImmutableListMultimap.of();
}
#method_after
public List<AccountState> byPreferredEmail(String email) throws OrmException {
    if (hasPreferredEmailExact()) {
        return query(AccountPredicates.preferredEmailExact(email));
    }
    if (!hasPreferredEmail()) {
        return ImmutableList.of();
    }
    return query(AccountPredicates.preferredEmail(email)).stream().filter(a -> a.getAccount().getPreferredEmail().equals(email)).collect(toList());
}
#end_block

#method_before
public Multimap<String, AccountState> byPreferredEmail(String... emails) throws OrmException {
    List<String> emailList = Arrays.asList(emails);
    if (hasPreferredEmailExact()) {
        List<List<AccountState>> r = query(emailList.stream().map(e -> AccountPredicates.preferredEmailExact(e)).collect(toList()));
        Multimap<String, AccountState> accountsByEmail = ArrayListMultimap.create();
        for (int i = 0; i < emailList.size(); i++) {
            accountsByEmail.putAll(emailList.get(i), r.get(i));
        }
        return accountsByEmail;
    }
    if (hasPreferredEmail()) {
        List<List<AccountState>> r = query(emailList.stream().map(e -> AccountPredicates.preferredEmail(e)).collect(toList()));
        Multimap<String, AccountState> accountsByEmail = ArrayListMultimap.create();
        for (int i = 0; i < emailList.size(); i++) {
            String email = emailList.get(i);
            Set<AccountState> matchingAccounts = r.get(i).stream().filter(a -> a.getAccount().getPreferredEmail().equals(email)).collect(toSet());
            accountsByEmail.putAll(email, matchingAccounts);
        }
        return accountsByEmail;
    }
    return ImmutableListMultimap.of();
}
#method_after
public Multimap<String, AccountState> byPreferredEmail(String... emails) throws OrmException {
    List<String> emailList = Arrays.asList(emails);
    if (hasPreferredEmailExact()) {
        List<List<AccountState>> r = query(emailList.stream().map(e -> AccountPredicates.preferredEmailExact(e)).collect(toList()));
        Multimap<String, AccountState> accountsByEmail = ArrayListMultimap.create();
        for (int i = 0; i < emailList.size(); i++) {
            accountsByEmail.putAll(emailList.get(i), r.get(i));
        }
        return accountsByEmail;
    }
    if (!hasPreferredEmail()) {
        return ImmutableListMultimap.of();
    }
    List<List<AccountState>> r = query(emailList.stream().map(e -> AccountPredicates.preferredEmail(e)).collect(toList()));
    Multimap<String, AccountState> accountsByEmail = ArrayListMultimap.create();
    for (int i = 0; i < emailList.size(); i++) {
        String email = emailList.get(i);
        Set<AccountState> matchingAccounts = r.get(i).stream().filter(a -> a.getAccount().getPreferredEmail().equals(email)).collect(toSet());
        accountsByEmail.putAll(email, matchingAccounts);
    }
    return accountsByEmail;
}
#end_block

#method_before
private boolean hasPreferredEmail() {
    Schema<AccountState> s = schema();
    return (s != null && s.hasField(AccountField.PREFERRED_EMAIL));
}
#method_after
private boolean hasPreferredEmail() {
    return hasField(AccountField.PREFERRED_EMAIL);
}
#end_block

#method_before
private boolean hasPreferredEmailExact() {
    Schema<AccountState> s = schema();
    return (s != null && s.hasField(AccountField.PREFERRED_EMAIL_EXACT));
}
#method_after
private boolean hasPreferredEmailExact() {
    return hasField(AccountField.PREFERRED_EMAIL_EXACT);
}
#end_block

#method_before
@Nullable
private Addition addWholeGroup(String reviewer, ChangeResource rsrc, ReviewerState state, NotifyHandling notify, ListMultimap<RecipientType, Account.Id> accountsToNotify, boolean confirmed, boolean allowGroup, boolean allowByEmail) throws OrmException, IOException, PermissionBackendException {
    if (!allowGroup) {
        return null;
    }
    GroupDescription.Basic group = null;
    try {
        group = groupsCollection.parseInternal(reviewer);
    } catch (UnprocessableEntityException e) {
        if (!allowByEmail) {
            return fail(reviewer, MessageFormat.format(ChangeMessages.get().reviewerNotFoundUserOrGroup, reviewer));
        }
        return null;
    }
    if (!isLegalReviewerGroup(group.getGroupUUID())) {
        return fail(reviewer, MessageFormat.format(ChangeMessages.get().groupIsNotAllowed, group.getName()));
    }
    Set<Account.Id> reviewers = new HashSet<>();
    Set<Account> members;
    try {
        members = groupMembers.listAccounts(group.getGroupUUID(), rsrc.getProject());
    } catch (NoSuchProjectException e) {
        return fail(reviewer, e.getMessage());
    }
    // if maxAllowed is set to 0, it is allowed to add any number of
    // reviewers
    int maxAllowed = cfg.getInt("addreviewer", "maxAllowed", DEFAULT_MAX_REVIEWERS);
    if (maxAllowed > 0 && members.size() > maxAllowed) {
        return fail(reviewer, MessageFormat.format(ChangeMessages.get().groupHasTooManyMembers, group.getName()));
    }
    // if maxWithoutCheck is set to 0, we never ask for confirmation
    int maxWithoutConfirmation = cfg.getInt("addreviewer", "maxWithoutConfirmation", DEFAULT_MAX_REVIEWERS_WITHOUT_CHECK);
    if (!confirmed && maxWithoutConfirmation > 0 && members.size() > maxWithoutConfirmation) {
        return fail(reviewer, true, MessageFormat.format(ChangeMessages.get().groupManyMembersConfirmation, group.getName(), members.size()));
    }
    PermissionBackend.ForRef perm = permissionBackend.user(rsrc.getUser()).ref(rsrc.getChange().getDest());
    for (Account member : members) {
        if (isValidReviewer(member, perm)) {
            reviewers.add(member.getId());
        }
    }
    return new Addition(reviewer, rsrc, reviewers, null, state, notify, accountsToNotify);
}
#method_after
@Nullable
private Addition addWholeGroup(String reviewer, ChangeResource rsrc, ReviewerState state, NotifyHandling notify, ListMultimap<RecipientType, Account.Id> accountsToNotify, boolean confirmed, boolean allowGroup, boolean allowByEmail) throws IOException, PermissionBackendException {
    if (!allowGroup) {
        return null;
    }
    GroupDescription.Basic group = null;
    try {
        group = groupsCollection.parseInternal(reviewer);
    } catch (UnprocessableEntityException e) {
        if (!allowByEmail) {
            return fail(reviewer, MessageFormat.format(ChangeMessages.get().reviewerNotFoundUserOrGroup, reviewer));
        }
        return null;
    }
    if (!isLegalReviewerGroup(group.getGroupUUID())) {
        return fail(reviewer, MessageFormat.format(ChangeMessages.get().groupIsNotAllowed, group.getName()));
    }
    Set<Account.Id> reviewers = new HashSet<>();
    Set<Account> members;
    try {
        members = groupMembers.listAccounts(group.getGroupUUID(), rsrc.getProject());
    } catch (NoSuchProjectException e) {
        return fail(reviewer, e.getMessage());
    }
    // if maxAllowed is set to 0, it is allowed to add any number of
    // reviewers
    int maxAllowed = cfg.getInt("addreviewer", "maxAllowed", DEFAULT_MAX_REVIEWERS);
    if (maxAllowed > 0 && members.size() > maxAllowed) {
        return fail(reviewer, MessageFormat.format(ChangeMessages.get().groupHasTooManyMembers, group.getName()));
    }
    // if maxWithoutCheck is set to 0, we never ask for confirmation
    int maxWithoutConfirmation = cfg.getInt("addreviewer", "maxWithoutConfirmation", DEFAULT_MAX_REVIEWERS_WITHOUT_CHECK);
    if (!confirmed && maxWithoutConfirmation > 0 && members.size() > maxWithoutConfirmation) {
        return fail(reviewer, true, MessageFormat.format(ChangeMessages.get().groupManyMembersConfirmation, group.getName(), members.size()));
    }
    PermissionBackend.ForRef perm = permissionBackend.user(rsrc.getUser()).ref(rsrc.getChange().getDest());
    for (Account member : members) {
        if (isValidReviewer(member, perm)) {
            reviewers.add(member.getId());
        }
    }
    return new Addition(reviewer, rsrc, reviewers, null, state, notify, accountsToNotify);
}
#end_block

#method_before
public List<ConsistencyProblemInfo> check() throws OrmException, IOException {
    try (Repository repo = repoManager.openRepository(allUsersName)) {
        Map<AccountGroup.UUID, InternalGroup> groups = new HashMap<>();
        List<ConsistencyProblemInfo> problems = globalChecker.check(repo, groups);
        if (!problems.isEmpty()) {
            return problems;
        }
        for (InternalGroup g : groups.values()) {
            problems.addAll(checkGroup(g, groups));
        }
        return problems;
    }
}
#method_after
public List<ConsistencyProblemInfo> check() throws IOException {
    if (!groupsMigration.writeToNoteDb()) {
        return new ArrayList<>();
    }
    try (Repository repo = repoManager.openRepository(allUsersName)) {
        GroupsNoteDbConsistencyChecker.Result result = globalChecker.check(repo);
        if (!result.problems.isEmpty()) {
            return result.problems;
        }
        for (InternalGroup g : result.uuidToGroupMap.values()) {
            result.problems.addAll(checkGroup(g, result.uuidToGroupMap));
        }
        return result.problems;
    }
}
#end_block

#method_before
public List<ConsistencyProblemInfo> check(Repository repo, Map<AccountGroup.UUID, InternalGroup> byUUID) throws OrmException, IOException {
    if (!groupsMigration.writeToNoteDb()) {
        return new ArrayList<>();
    }
    // Get all refs in an attempt to avoid seeing half committed group updates.
    Map<String, Ref> refs = repo.getAllRefs();
    List<ConsistencyProblemInfo> problems = new ArrayList<>();
    BiMap<AccountGroup.UUID, String> nameMap = HashBiMap.create();
    readGroups(repo, refs, problems, byUUID);
    readGroupNames(repo, refs, problems, nameMap);
    // No use continuing if we couldn't read the data.
    if (!problems.isEmpty()) {
        return problems;
    }
    return checkGlobalConsistency(byUUID, nameMap);
}
#method_after
@Nullable
public Result check(Repository repo) throws IOException {
    if (!groupsMigration.writeToNoteDb()) {
        return null;
    }
    Result r = doCheck(repo);
    if (!r.problems.isEmpty()) {
        r.uuidToGroupMap = null;
    }
    return r;
}
#end_block

#method_before
private void readGroups(Repository repo, Map<String, Ref> refs, List<ConsistencyProblemInfo> problems, Map<AccountGroup.UUID, InternalGroup> byUUID) throws IOException {
    for (Map.Entry<String, Ref> entry : refs.entrySet()) {
        if (!entry.getKey().startsWith(RefNames.REFS_GROUPS)) {
            continue;
        }
        AccountGroup.UUID uuid = AccountGroup.UUID.fromRef(entry.getKey());
        if (uuid == null) {
            problems.add(error("null UUID from %s", entry.getKey()));
            continue;
        }
        try {
            GroupConfig cfg = GroupConfig.loadForGroupSnapshot(repo, uuid, entry.getValue().getObjectId());
            byUUID.put(uuid, cfg.getLoadedGroup().get());
        } catch (ConfigInvalidException e) {
            problems.add(error("group %s does not parse: %s", uuid, e.getMessage()));
        }
    }
}
#method_after
private void readGroups(Repository repo, Map<String, Ref> refs, Result result) throws IOException {
    for (Map.Entry<String, Ref> entry : refs.entrySet()) {
        if (!entry.getKey().startsWith(RefNames.REFS_GROUPS)) {
            continue;
        }
        AccountGroup.UUID uuid = AccountGroup.UUID.fromRef(entry.getKey());
        if (uuid == null) {
            result.problems.add(error("null UUID from %s", entry.getKey()));
            continue;
        }
        try {
            GroupConfig cfg = GroupConfig.loadForGroupSnapshot(repo, uuid, entry.getValue().getObjectId());
            result.uuidToGroupMap.put(uuid, cfg.getLoadedGroup().get());
        } catch (ConfigInvalidException e) {
            result.problems.add(error("group %s does not parse: %s", uuid, e.getMessage()));
        }
    }
}
#end_block

#method_before
private void readGroupNames(Repository repo, Map<String, Ref> refs, List<ConsistencyProblemInfo> problems, BiMap<AccountGroup.UUID, String> result) throws IOException {
    Ref ref = refs.get(RefNames.REFS_GROUPNAMES);
    if (ref == null) {
        problems.add(new ConsistencyProblemInfo(groupsMigration.readFromNoteDb() ? ConsistencyProblemInfo.Status.ERROR : ConsistencyProblemInfo.Status.WARNING, String.format("ref %s does not exist", RefNames.REFS_GROUPNAMES)));
        return;
    }
    try (RevWalk rw = new RevWalk(repo)) {
        NoteMap nm = NoteMap.read(rw.getObjectReader(), rw.parseCommit(ref.getObjectId()));
        for (Note note : nm) {
            ObjectLoader ld = rw.getObjectReader().open(note.getData());
            byte[] data = ld.getCachedBytes();
            GroupReference gRef;
            try {
                gRef = GroupNameNotes.getFromNoteData(data);
            } catch (ConfigInvalidException e) {
                problems.add(error("notename entry %s: %s does not parse: %s", note, new String(data, StandardCharsets.UTF_8), e.getMessage()));
                continue;
            }
            ObjectId nameKey = GroupNameNotes.getNoteKey(new NameKey(gRef.getName()));
            if (!Objects.equals(nameKey, note)) {
                problems.add(error("notename entry %s does not match name %s", note, gRef.getName()));
            }
            // We trust SHA1 to have no collisions, so no need to check uniqueness of name.
            result.put(gRef.getUUID(), gRef.getName());
        }
    }
}
#method_after
private void readGroupNames(Repository repo, Map<String, Ref> refs, Result result, BiMap<AccountGroup.UUID, String> uuidNameBiMap) throws IOException {
    Ref ref = refs.get(RefNames.REFS_GROUPNAMES);
    if (ref == null) {
        String msg = String.format("ref %s does not exist", RefNames.REFS_GROUPNAMES);
        result.problems.add(groupsMigration.readFromNoteDb() ? error(msg) : warning(msg));
        return;
    }
    try (RevWalk rw = new RevWalk(repo)) {
        RevCommit c = rw.parseCommit(ref.getObjectId());
        NoteMap nm = NoteMap.read(rw.getObjectReader(), c);
        for (Note note : nm) {
            ObjectLoader ld = rw.getObjectReader().open(note.getData());
            byte[] data = ld.getCachedBytes();
            GroupReference gRef;
            try {
                gRef = GroupNameNotes.getFromNoteData(data);
            } catch (ConfigInvalidException e) {
                result.problems.add(error("notename entry %s: %s does not parse: %s", note, new String(data, StandardCharsets.UTF_8), e.getMessage()));
                continue;
            }
            ObjectId nameKey = GroupNameNotes.getNoteKey(new AccountGroup.NameKey(gRef.getName()));
            if (!Objects.equals(nameKey, note)) {
                result.problems.add(error("notename entry %s does not match name %s", note, gRef.getName()));
            }
            // We trust SHA1 to have no collisions, so no need to check uniqueness of name.
            uuidNameBiMap.put(gRef.getUUID(), gRef.getName());
        }
    }
}
#end_block

#method_before
private List<ConsistencyProblemInfo> checkGlobalConsistency(Map<AccountGroup.UUID, InternalGroup> byUUID, BiMap<AccountGroup.UUID, String> nameMap) {
    List<ConsistencyProblemInfo> problems = new ArrayList<>();
    // Check consistency between the data coming from different refs.
    for (AccountGroup.UUID uuid : byUUID.keySet()) {
        if (!nameMap.containsKey(uuid)) {
            problems.add(error("group %s has no entry in name map", uuid));
            continue;
        }
        String noteName = nameMap.get(uuid);
        String groupRefName = byUUID.get(uuid).getName();
        if (!Objects.equals(noteName, groupRefName)) {
            problems.add(error("inconsistent name for group %s (name map %s vs. group ref %s)", uuid, noteName, groupRefName));
        }
    }
    for (AccountGroup.UUID uuid : nameMap.keySet()) {
        if (!byUUID.containsKey(uuid)) {
            problems.add(error("name map has entry (%s, %s), entry missing as group ref", uuid, nameMap.get(uuid)));
        }
    }
    // No use delving further into inconsistent data.
    if (!problems.isEmpty()) {
        return problems;
    }
    // Check ids.
    Map<AccountGroup.Id, InternalGroup> groupById = new HashMap<>();
    for (InternalGroup g : byUUID.values()) {
        InternalGroup before = groupById.get(g.getId());
        if (before != null) {
            problems.add(error("shared group id %s for %s (%s) and %s (%s)", g.getId(), before.getName(), before.getGroupUUID(), g.getName(), g.getGroupUUID()));
        }
        groupById.put(g.getId(), g);
    }
    return problems;
}
#method_after
private List<ConsistencyProblemInfo> checkGlobalConsistency(Map<AccountGroup.UUID, InternalGroup> uuidToGroupMap, BiMap<AccountGroup.UUID, String> uuidNameBiMap) {
    List<ConsistencyProblemInfo> problems = new ArrayList<>();
    // Check consistency between the data coming from different refs.
    for (AccountGroup.UUID uuid : uuidToGroupMap.keySet()) {
        if (!uuidNameBiMap.containsKey(uuid)) {
            problems.add(error("group %s has no entry in name map", uuid));
            continue;
        }
        String noteName = uuidNameBiMap.get(uuid);
        String groupRefName = uuidToGroupMap.get(uuid).getName();
        if (!Objects.equals(noteName, groupRefName)) {
            problems.add(error("inconsistent name for group %s (name map %s vs. group ref %s)", uuid, noteName, groupRefName));
        }
    }
    for (AccountGroup.UUID uuid : uuidNameBiMap.keySet()) {
        if (!uuidToGroupMap.containsKey(uuid)) {
            problems.add(error("name map has entry (%s, %s), entry missing as group ref", uuid, uuidNameBiMap.get(uuid)));
        }
    }
    if (problems.isEmpty()) {
        // Check ids.
        Map<AccountGroup.Id, InternalGroup> groupById = new HashMap<>();
        for (InternalGroup g : uuidToGroupMap.values()) {
            InternalGroup before = groupById.get(g.getId());
            if (before != null) {
                problems.add(error("shared group id %s for %s (%s) and %s (%s)", g.getId(), before.getName(), before.getGroupUUID(), g.getName(), g.getGroupUUID()));
            }
            groupById.put(g.getId(), g);
        }
    }
    return problems;
}
#end_block

#method_before
public Response<EmailInfo> apply(IdentifiedUser user, EmailInput input) throws AuthException, BadRequestException, ResourceConflictException, ResourceNotFoundException, OrmException, EmailException, MethodNotAllowedException, IOException, ConfigInvalidException, PermissionBackendException {
    if (input == null) {
        input = new EmailInput();
    }
    if (input.email != null && !email.equals(input.email)) {
        throw new BadRequestException("email address must match URL");
    }
    String newEmail = email;
    if (newEmail != null) {
        newEmail = newEmail.trim();
    }
    if (!validator.isValid(newEmail)) {
        throw new BadRequestException("invalid email address");
    }
    EmailInfo info = new EmailInfo();
    info.email = newEmail;
    if (input.noConfirmation || isDevMode) {
        if (isDevMode) {
            log.warn("skipping email validation in developer mode");
        }
        try {
            accountManager.link(user.getAccountId(), AuthRequest.forEmail(newEmail));
        } catch (AccountException e) {
            throw new ResourceConflictException(e.getMessage());
        }
        if (input.preferred) {
            putPreferred.apply(new AccountResource.Email(user, newEmail), null);
            info.preferred = true;
        }
    } else {
        try {
            RegisterNewEmailSender sender = registerNewEmailFactory.create(newEmail);
            if (!sender.isAllowed()) {
                throw new MethodNotAllowedException("Not allowed to add email address " + newEmail);
            }
            sender.send();
            info.pendingConfirmation = true;
        } catch (EmailException | RuntimeException e) {
            log.error("Cannot send email verification message to " + newEmail, e);
            throw e;
        }
    }
    return Response.created(info);
}
#method_after
public Response<EmailInfo> apply(IdentifiedUser user, EmailInput input) throws AuthException, BadRequestException, ResourceConflictException, ResourceNotFoundException, OrmException, EmailException, MethodNotAllowedException, IOException, ConfigInvalidException, PermissionBackendException {
    if (input == null) {
        input = new EmailInput();
    }
    if (input.email != null && !email.equals(input.email)) {
        throw new BadRequestException("email address must match URL");
    }
    if (!validator.isValid(email)) {
        throw new BadRequestException("invalid email address");
    }
    EmailInfo info = new EmailInfo();
    info.email = email;
    if (input.noConfirmation || isDevMode) {
        if (isDevMode) {
            log.warn("skipping email validation in developer mode");
        }
        try {
            accountManager.link(user.getAccountId(), AuthRequest.forEmail(email));
        } catch (AccountException e) {
            throw new ResourceConflictException(e.getMessage());
        }
        if (input.preferred) {
            putPreferred.apply(new AccountResource.Email(user, email), null);
            info.preferred = true;
        }
    } else {
        try {
            RegisterNewEmailSender sender = registerNewEmailFactory.create(email);
            if (!sender.isAllowed()) {
                throw new MethodNotAllowedException("Not allowed to add email address " + email);
            }
            sender.send();
            info.pendingConfirmation = true;
        } catch (EmailException | RuntimeException e) {
            log.error("Cannot send email verification message to " + email, e);
            throw e;
        }
    }
    return Response.created(info);
}
#end_block

#method_before
private Change findChange(ChangeInfo c) throws OrmException {
    List<Change> changes = ChangeData.asChanges(queryProvider.get().byBranchKey(new Branch.NameKey(targetProject, fullName(c.branch)), new Change.Key(c.changeId)));
    if (changes.isEmpty()) {
        return null;
    }
    return db.changes().get(Iterators.getOnlyElement(changes.iterator()).getId());
}
#method_after
private Change findChange(ChangeInfo c) throws OrmException {
    List<Change> changes = ChangeData.asChanges(queryProvider.get().byBranchKey(new Branch.NameKey(targetProject, RefNames.fullName(c.branch)), new Change.Key(c.changeId)));
    if (changes.isEmpty()) {
        return null;
    }
    return db.changes().get(Iterators.getOnlyElement(changes.iterator()).getId());
}
#end_block

#method_before
private Change createChange(ChangeInfo c) throws OrmException, NoSuchAccountException, IOException, RestApiException, ConfigInvalidException {
    Change.Id changeId = new Change.Id(sequences.nextChangeId());
    Change change = new Change(new Change.Key(c.changeId), changeId, accountUtil.resolveUser(api, c.owner), new Branch.NameKey(targetProject, fullName(c.branch)), c.created);
    change.setStatus(Change.Status.forChangeStatus(c.status));
    change.setTopic(c.topic);
    change.setLastUpdatedOn(c.updated);
    return change;
}
#method_after
private Change createChange(ChangeInfo c) throws OrmException, NoSuchAccountException, IOException, RestApiException, ConfigInvalidException {
    Change.Id changeId = new Change.Id(sequences.nextChangeId());
    Change change = new Change(new Change.Key(c.changeId), changeId, accountUtil.resolveUser(api, c.owner), new Branch.NameKey(targetProject, RefNames.fullName(c.branch)), c.created);
    change.setStatus(Change.Status.forChangeStatus(c.status));
    change.setTopic(c.topic);
    change.setLastUpdatedOn(c.updated);
    return change;
}
#end_block

#method_before
@Test
public void redundantMemberAuditsAreIgnored() throws Exception {
    AccountGroup g = newGroup("a");
    Timestamp t1 = TimeUtil.nowTs();
    Timestamp t2 = TimeUtil.nowTs();
    Timestamp t3 = TimeUtil.nowTs();
    Timestamp t4 = TimeUtil.nowTs();
    Timestamp t5 = TimeUtil.nowTs();
    GroupBundle b = builder().group(g).members(member(g, 2)).memberAudit(addMember(g, 1, 8, t1), addMember(g, 1, 8, t1), addMember(g, 1, 8, t3), addMember(g, 1, 9, t4), addAndRemoveMember(g, 1, 8, t2, 9, t5), addAndLegacyRemoveMember(g, 2, 9, t3), addMember(g, 2, 8, t1), addMember(g, 2, 9, t4)).build();
    rebuilder.rebuild(repo, b, null);
    assertMigratedCleanly(reload(g), b);
    ImmutableList<CommitInfo> log = log(g);
    assertThat(log).hasSize(5);
    assertServerCommit(log.get(0), "Create group");
    assertCommit(log.get(1), "Update group\n\nAdd: Account 1 <1@server-id>\nAdd: Account 2 <2@server-id>", "Account 8", "8@server-id");
    assertCommit(log.get(2), "Update group\n\nRemove: Account 2 <2@server-id>", "Account 9", "9@server-id");
    assertCommit(log.get(3), "Update group\n\nAdd: Account 2 <2@server-id>", "Account 9", "9@server-id");
    assertCommit(log.get(4), "Update group\n\nRemove: Account 1 <1@server-id>", "Account 9", "9@server-id");
}
#method_after
@Test
public void redundantMemberAuditsAreIgnored() throws Exception {
    AccountGroup g = newGroup("a");
    Timestamp t1 = TimeUtil.nowTs();
    Timestamp t2 = TimeUtil.nowTs();
    Timestamp t3 = TimeUtil.nowTs();
    Timestamp t4 = TimeUtil.nowTs();
    Timestamp t5 = TimeUtil.nowTs();
    GroupBundle b = builder().group(g).members(member(g, 2)).memberAudit(addMember(g, 1, 8, t1), addMember(g, 1, 8, t1), addMember(g, 1, 8, t3), addMember(g, 1, 9, t4), addAndRemoveMember(g, 1, 8, t2, 9, t5), addAndLegacyRemoveMember(g, 2, 9, t3), addMember(g, 2, 8, t1), addMember(g, 2, 9, t4), addMember(g, 1, 8, t5)).build();
    rebuilder.rebuild(repo, b, null);
    assertMigratedCleanly(reload(g), b);
    ImmutableList<CommitInfo> log = log(g);
    assertThat(log).hasSize(5);
    assertServerCommit(log.get(0), "Create group");
    assertCommit(log.get(1), "Update group\n\nAdd: Account 1 <1@server-id>\nAdd: Account 2 <2@server-id>", "Account 8", "8@server-id");
    assertCommit(log.get(2), "Update group\n\nRemove: Account 2 <2@server-id>", "Account 9", "9@server-id");
    assertCommit(log.get(3), "Update group\n\nAdd: Account 2 <2@server-id>", "Account 9", "9@server-id");
    assertCommit(log.get(4), "Update group\n\nRemove: Account 1 <1@server-id>", "Account 9", "9@server-id");
}
#end_block

#method_before
public String getNameEmail(String anonymousCowardName) {
    String name = fullName != null ? fullName : anonymousCowardName;
    StringBuilder b = new StringBuilder();
    b.append(name);
    if (preferredEmail != null) {
        b.append(" <");
        b.append(preferredEmail);
        b.append(">");
    } else if (accountId != null) {
        b.append(" (");
        b.append(accountId.get());
        b.append(")");
    }
    return b.toString();
}
#method_after
public String getNameEmail(String anonymousCowardName) {
    String name = fullName != null ? fullName : anonymousCowardName;
    StringBuilder b = new StringBuilder();
    b.append(name);
    if (preferredEmail != null) {
        b.append(" <");
        b.append(preferredEmail);
        b.append(">");
    } else {
        b.append(" (");
        b.append(accountId.get());
        b.append(")");
    }
    return b.toString();
}
#end_block

#method_before
public void rebuild(Repository allUsersRepo, GroupBundle bundle, @Nullable BatchRefUpdate bru) throws IOException, ConfigInvalidException, OrmDuplicateKeyException {
    GroupConfig groupConfig = GroupConfig.loadForGroup(allUsersRepo, bundle.uuid());
    AccountGroup group = bundle.group();
    groupConfig.setGroupCreation(InternalGroupCreation.builder().setId(bundle.id()).setNameKey(group.getNameKey()).setGroupUUID(group.getGroupUUID()).setCreatedOn(group.getCreatedOn()).build());
    InternalGroupUpdate.Builder updateBuilder = InternalGroupUpdate.builder().setOwnerGroupUUID(group.getOwnerGroupUUID()).setVisibleToAll(group.isVisibleToAll());
    if (bundle.group().getDescription() != null) {
        updateBuilder.setDescription(group.getDescription());
    }
    groupConfig.setGroupUpdate(updateBuilder.build(), getAccountNameEmailFunc, getGroupNameFunc);
    Map<Key, Collection<Event>> events = toEvents(bundle).asMap();
    PersonIdent nowServerIdent = getServerIdent(events);
    MetaDataUpdate md = metaDataUpdateFactory.create(allUsers, allUsersRepo, bru);
    // Creation is done by the server (unlike later audit events).
    PersonIdent created = new PersonIdent(nowServerIdent, group.getCreatedOn());
    md.getCommitBuilder().setAuthor(created);
    md.getCommitBuilder().setCommitter(created);
    // Rebuild group ref.
    try (BatchMetaDataUpdate batch = groupConfig.openUpdate(md)) {
        batch.write(groupConfig, md.getCommitBuilder());
        for (Map.Entry<Key, Collection<Event>> e : events.entrySet()) {
            InternalGroupUpdate.Builder ub = InternalGroupUpdate.builder();
            e.getValue().forEach(event -> event.update().accept(ub));
            groupConfig.setGroupUpdate(ub.build(), getAccountNameEmailFunc, getGroupNameFunc);
            PersonIdent currServerIdent = new PersonIdent(nowServerIdent, e.getKey().when());
            CommitBuilder cb = new CommitBuilder();
            cb.setAuthor(e.getKey().accountId().map(id -> newPersonIdentFunc.apply(id, currServerIdent)).orElse(currServerIdent));
            cb.setCommitter(currServerIdent);
            batch.write(groupConfig, cb);
        }
        batch.createRef(groupConfig.getRefName());
    }
}
#method_after
public void rebuild(Repository allUsersRepo, GroupBundle bundle, @Nullable BatchRefUpdate bru) throws IOException, ConfigInvalidException, OrmDuplicateKeyException {
    GroupConfig groupConfig = GroupConfig.loadForGroup(allUsersRepo, bundle.uuid());
    AccountGroup group = bundle.group();
    groupConfig.setAllowSaveEmptyName();
    groupConfig.setGroupCreation(InternalGroupCreation.builder().setId(bundle.id()).setNameKey(group.getNameKey()).setGroupUUID(group.getGroupUUID()).setCreatedOn(group.getCreatedOn()).build());
    InternalGroupUpdate.Builder updateBuilder = InternalGroupUpdate.builder().setOwnerGroupUUID(group.getOwnerGroupUUID()).setVisibleToAll(group.isVisibleToAll());
    if (bundle.group().getDescription() != null) {
        updateBuilder.setDescription(group.getDescription());
    }
    groupConfig.setGroupUpdate(updateBuilder.build(), getAccountNameEmailFunc, getGroupNameFunc);
    Map<Key, Collection<Event>> events = toEvents(bundle).asMap();
    PersonIdent nowServerIdent = getServerIdent(events);
    MetaDataUpdate md = metaDataUpdateFactory.create(allUsers, allUsersRepo, bru);
    // Creation is done by the server (unlike later audit events).
    PersonIdent created = new PersonIdent(nowServerIdent, group.getCreatedOn());
    md.getCommitBuilder().setAuthor(created);
    md.getCommitBuilder().setCommitter(created);
    // Rebuild group ref.
    try (BatchMetaDataUpdate batch = groupConfig.openUpdate(md)) {
        batch.write(groupConfig, md.getCommitBuilder());
        for (Map.Entry<Key, Collection<Event>> e : events.entrySet()) {
            InternalGroupUpdate.Builder ub = InternalGroupUpdate.builder();
            e.getValue().forEach(event -> event.update().accept(ub));
            groupConfig.setGroupUpdate(ub.build(), getAccountNameEmailFunc, getGroupNameFunc);
            PersonIdent currServerIdent = new PersonIdent(nowServerIdent, e.getKey().when());
            CommitBuilder cb = new CommitBuilder();
            cb.setAuthor(e.getKey().accountId().map(id -> newPersonIdentFunc.apply(id, currServerIdent)).orElse(currServerIdent));
            cb.setCommitter(currServerIdent);
            batch.write(groupConfig, cb);
        }
        batch.createRef(groupConfig.getRefName());
    }
}
#end_block

#method_before
@Override
public AuthRequest authenticate(AuthRequest who) throws AccountException {
    if (config.getBoolean("ldap", "localUsernameToLowerCase", false)) {
        who.setLocalUser(who.getLocalUser().toLowerCase(Locale.US));
    }
    final String username = who.getLocalUser();
    try {
        final DirContext ctx;
        if (authConfig.getAuthType() == AuthType.LDAP_BIND) {
            ctx = helper.authenticate(username, who.getPassword());
        } else {
            ctx = helper.open();
        }
        try {
            final Helper.LdapSchema schema = helper.getSchema(ctx);
            LdapQuery.Result m;
            who.setAuthProvidesAccountActiveStatus(true);
            try {
                m = helper.findAccount(schema, ctx, username, fetchMemberOfEagerly);
                who.setActive(true);
            } catch (NoSuchUserException e) {
                who.setActive(false);
                return who;
            }
            if (authConfig.getAuthType() == AuthType.LDAP && !who.isSkipAuthentication()) {
                // We found the user account, but we need to verify
                // the password matches it before we can continue.
                // 
                helper.authenticate(m.getDN(), who.getPassword()).close();
            }
            who.setDisplayName(apply(schema.accountFullName, m));
            who.setUserName(apply(schema.accountSshUserName, m));
            if (schema.accountEmailAddress != null) {
                who.setEmailAddress(apply(schema.accountEmailAddress, m));
            } else if (emailExpander.canExpand(username)) {
                // If LDAP cannot give us a valid email address for this user
                // try expanding it through the older email expander code which
                // assumes a user name within a domain.
                // 
                who.setEmailAddress(emailExpander.expand(username));
            }
            // 
            if (fetchMemberOfEagerly || mandatoryGroup != null) {
                Set<AccountGroup.UUID> groups = helper.queryForGroups(ctx, username, m);
                if (mandatoryGroup != null) {
                    GroupReference mandatoryGroupRef = GroupBackends.findExactSuggestion(groupBackend, mandatoryGroup);
                    if (mandatoryGroupRef == null) {
                        throw new AccountException("Could not identify mandatory group: " + mandatoryGroup);
                    }
                    if (!groups.contains(mandatoryGroupRef.getUUID())) {
                        throw new AccountException("Not member of mandatory LDAP group: " + mandatoryGroupRef.getName());
                    }
                }
                // Regardless if we enabled fetchMemberOfEagerly, we already have the
                // groups and it would be a waste not to cache them.
                membershipCache.put(username, groups);
            }
            return who;
        } finally {
            try {
                ctx.close();
            } catch (NamingException e) {
                log.warn("Cannot close LDAP query handle", e);
            }
        }
    } catch (NamingException e) {
        log.error("Cannot query LDAP to authenticate user", e);
        throw new AuthenticationUnavailableException("Cannot query LDAP for account", e);
    } catch (LoginException e) {
        log.error("Cannot authenticate server via JAAS", e);
        throw new AuthenticationUnavailableException("Cannot query LDAP for account", e);
    }
}
#method_after
@Override
public AuthRequest authenticate(AuthRequest who) throws AccountException {
    if (config.getBoolean("ldap", "localUsernameToLowerCase", false)) {
        who.setLocalUser(who.getLocalUser().toLowerCase(Locale.US));
    }
    final String username = who.getLocalUser();
    try {
        final DirContext ctx;
        if (authConfig.getAuthType() == AuthType.LDAP_BIND) {
            ctx = helper.authenticate(username, who.getPassword());
        } else {
            ctx = helper.open();
        }
        try {
            final Helper.LdapSchema schema = helper.getSchema(ctx);
            LdapQuery.Result m;
            who.setAuthProvidesAccountActiveStatus(true);
            m = helper.findAccount(schema, ctx, username, fetchMemberOfEagerly);
            who.setActive(true);
            if (authConfig.getAuthType() == AuthType.LDAP && !who.isSkipAuthentication()) {
                // We found the user account, but we need to verify
                // the password matches it before we can continue.
                // 
                helper.authenticate(m.getDN(), who.getPassword()).close();
            }
            who.setDisplayName(apply(schema.accountFullName, m));
            who.setUserName(apply(schema.accountSshUserName, m));
            if (schema.accountEmailAddress != null) {
                who.setEmailAddress(apply(schema.accountEmailAddress, m));
            } else if (emailExpander.canExpand(username)) {
                // If LDAP cannot give us a valid email address for this user
                // try expanding it through the older email expander code which
                // assumes a user name within a domain.
                // 
                who.setEmailAddress(emailExpander.expand(username));
            }
            // 
            if (fetchMemberOfEagerly || mandatoryGroup != null) {
                Set<AccountGroup.UUID> groups = helper.queryForGroups(ctx, username, m);
                if (mandatoryGroup != null) {
                    GroupReference mandatoryGroupRef = GroupBackends.findExactSuggestion(groupBackend, mandatoryGroup);
                    if (mandatoryGroupRef == null) {
                        throw new AccountException("Could not identify mandatory group: " + mandatoryGroup);
                    }
                    if (!groups.contains(mandatoryGroupRef.getUUID())) {
                        throw new AccountException("Not member of mandatory LDAP group: " + mandatoryGroupRef.getName());
                    }
                }
                // Regardless if we enabled fetchMemberOfEagerly, we already have the
                // groups and it would be a waste not to cache them.
                membershipCache.put(username, groups);
            }
            return who;
        } finally {
            try {
                ctx.close();
            } catch (NamingException e) {
                log.warn("Cannot close LDAP query handle", e);
            }
        }
    } catch (NamingException e) {
        log.error("Cannot query LDAP to authenticate user", e);
        throw new AuthenticationUnavailableException("Cannot query LDAP for account", e);
    } catch (LoginException e) {
        log.error("Cannot authenticate server via JAAS", e);
        throw new AuthenticationUnavailableException("Cannot query LDAP for account", e);
    }
}
#end_block

#method_before
private boolean processAccount(AccountState account) {
    log.debug("processing account " + account.getUserName());
    try {
        if (account.getUserName() != null && !realm.isActive(account.getUserName())) {
            Collection<ExternalId> ids = externalIds.byAccount(account.getAccount().getId());
            if (realm.accBelongsToRealm(ids)) {
                sif.deactivate(account.getAccount().getId());
                log.info("deactivated account " + account.getUserName());
                return true;
            }
        }
    } catch (ResourceConflictException e) {
        log.info("Account {} already deactivated, continuing...", account.getUserName());
    } catch (Exception e) {
        log.error("Error deactivating account: {} ({}) {}", account.getUserName(), account.getAccount().getId(), e.getMessage(), e);
    }
    return false;
}
#method_after
private boolean processAccount(AccountState account) {
    log.debug("processing account " + account.getUserName());
    try {
        if (account.getUserName() != null && realm.accountBelongsToRealm(account.getExternalIds()) && !realm.isActive(account.getUserName())) {
            sif.deactivate(account.getAccount().getId());
            log.info("deactivated account " + account.getUserName());
            return true;
        }
    } catch (ResourceConflictException e) {
        log.info("Account {} already deactivated, continuing...", account.getUserName());
    } catch (Exception e) {
        log.error("Error deactivating account: {} ({}) {}", account.getUserName(), account.getAccount().getId(), e.getMessage(), e);
    }
    return false;
}
#end_block

#method_before
private static GroupReference getFromNoteData(byte[] noteData) throws ConfigInvalidException {
    Config config = new Config();
    config.fromText(new String(noteData, UTF_8));
    String uuid = config.getString(SECTION_NAME, null, UUID_PARAM);
    String name = Strings.nullToEmpty(config.getString(SECTION_NAME, null, NAME_PARAM));
    if (uuid == null) {
        throw new ConfigInvalidException(String.format("UUID for group '%s'", name));
    }
    return new GroupReference(new AccountGroup.UUID(uuid), name);
}
#method_after
private static GroupReference getFromNoteData(byte[] noteData) throws ConfigInvalidException {
    Config config = new Config();
    config.fromText(new String(noteData, UTF_8));
    String uuid = config.getString(SECTION_NAME, null, UUID_PARAM);
    String name = Strings.nullToEmpty(config.getString(SECTION_NAME, null, NAME_PARAM));
    if (uuid == null) {
        throw new ConfigInvalidException(String.format("UUID for group '%s' must be defined", name));
    }
    return new GroupReference(new AccountGroup.UUID(uuid), name);
}
#end_block

#method_before
@Override
public int hashCode() {
    return System.identityHashCode(this);
}
#method_after
@Override
public int hashCode() {
    throw new UnsupportedOperationException("hashCode is not supported because equals is not supported");
}
#end_block

#method_before
// This class just contains sanity checks that GroupBundle#compare correctly compares all parts of
// the bundle. Most other test coverage should come via the slightly more realistic
// GroupRebuilderTest.
@Test
public void compareNonEqual() throws Exception {
    GroupBundle reviewDbBundle = newBundle().source(Source.REVIEW_DB).build();
    AccountGroup g2 = new AccountGroup(reviewDbBundle.group());
    g2.setDescription("Hello!");
    GroupBundle noteDbBundle = GroupBundle.builder().source(Source.NOTE_DB).group(g2).build();
    assertThat(GroupBundle.compare(reviewDbBundle, noteDbBundle)).containsExactly("AccountGroups differ\n" + ("ReviewDb: AccountGroup{name=group, groupId=1, description=null," + " visibleToAll=false, groupUUID=group-1, ownerGroupUUID=group-1," + " createdOn=2009-09-30 17:00:00.0}\n") + ("NoteDb  : AccountGroup{name=group, groupId=1, description=Hello!," + " visibleToAll=false, groupUUID=group-1, ownerGroupUUID=group-1," + " createdOn=2009-09-30 17:00:00.0}"), "AccountGroupMembers differ\n" + "ReviewDb: [AccountGroupMember{key=1000,1}]\n" + "NoteDb  : []", "AccountGroupMemberAudits differ\n" + "ReviewDb: [AccountGroupMemberAudit{key=1000,1, addedBy=2000, removedBy=null, removedOn=null}]\n" + "NoteDb  : []", "AccountGroupByIds differ\n" + "ReviewDb: [AccountGroupById{key=1,subgroup}]\n" + "NoteDb  : []", "AccountGroupByIdAudits differ\n" + "ReviewDb: [AccountGroupByIdAud{key=1,subgroup, addedBy=3000, removedBy=null, removedOn=null}]\n" + "NoteDb  : []");
}
#method_after
@Test
public void compareNonEqual() throws Exception {
    GroupBundle reviewDbBundle = newBundle().source(Source.REVIEW_DB).build();
    AccountGroup g2 = new AccountGroup(reviewDbBundle.group());
    g2.setDescription("Hello!");
    GroupBundle noteDbBundle = GroupBundle.builder().source(Source.NOTE_DB).group(g2).build();
    assertThat(GroupBundle.compare(reviewDbBundle, noteDbBundle)).containsExactly("AccountGroups differ\n" + ("ReviewDb: AccountGroup{name=group, groupId=1, description=null," + " visibleToAll=false, groupUUID=group-1, ownerGroupUUID=group-1," + " createdOn=2009-09-30 17:00:00.0}\n") + ("NoteDb  : AccountGroup{name=group, groupId=1, description=Hello!," + " visibleToAll=false, groupUUID=group-1, ownerGroupUUID=group-1," + " createdOn=2009-09-30 17:00:00.0}"), "AccountGroupMembers differ\n" + "ReviewDb: [AccountGroupMember{key=1000,1}]\n" + "NoteDb  : []", "AccountGroupMemberAudits differ\n" + "ReviewDb: [AccountGroupMemberAudit{key=1000,1, addedBy=2000, removedBy=null, removedOn=null}]\n" + "NoteDb  : []", "AccountGroupByIds differ\n" + "ReviewDb: [AccountGroupById{key=1,subgroup}]\n" + "NoteDb  : []", "AccountGroupByIdAudits differ\n" + "ReviewDb: [AccountGroupByIdAud{key=1,subgroup, addedBy=3000, removedBy=null, removedOn=null}]\n" + "NoteDb  : []");
}
#end_block

#method_before
private GroupBundle.Builder newBundle() {
    Timestamp ts = new Timestamp(TestTimeUtil.START.toEpochMilli());
    AccountGroup group = new AccountGroup(new AccountGroup.NameKey("group"), new AccountGroup.Id(1), new AccountGroup.UUID("group-1"), ts);
    AccountGroupMember member = new AccountGroupMember(new AccountGroupMember.Key(new Account.Id(1000), group.getId()));
    AccountGroupMemberAudit memberAudit = new AccountGroupMemberAudit(member, new Account.Id(2000), ts);
    AccountGroupById byId = new AccountGroupById(new AccountGroupById.Key(group.getId(), new AccountGroup.UUID("subgroup")));
    AccountGroupByIdAud byIdAudit = new AccountGroupByIdAud(byId, new Account.Id(3000), ts);
    return GroupBundle.builder().group(group).members(member).memberAudit(memberAudit).byId(byId).byIdAudit(byIdAudit);
}
#method_after
private GroupBundle.Builder newBundle() {
    AccountGroup group = new AccountGroup(new AccountGroup.NameKey("group"), new AccountGroup.Id(1), new AccountGroup.UUID("group-1"), ts);
    AccountGroupMember member = new AccountGroupMember(new AccountGroupMember.Key(new Account.Id(1000), group.getId()));
    AccountGroupMemberAudit memberAudit = new AccountGroupMemberAudit(member, new Account.Id(2000), ts);
    AccountGroupById byId = new AccountGroupById(new AccountGroupById.Key(group.getId(), new AccountGroup.UUID("subgroup")));
    AccountGroupByIdAud byIdAudit = new AccountGroupByIdAud(byId, new Account.Id(3000), ts);
    return GroupBundle.builder().group(group).members(member).memberAudit(memberAudit).byId(byId).byIdAudit(byIdAudit);
}
#end_block

#method_before
@Override
public int hashCode() {
    return System.identityHashCode(this);
}
#method_after
@Override
public int hashCode() {
    throw new UnsupportedOperationException("hashCode is not supported because equals is not supported");
}
#end_block

#method_before
void setAllowSaveEmptyName(boolean allowSaveEmptyName) {
    this.allowSaveEmptyName = allowSaveEmptyName;
}
#method_after
void setAllowSaveEmptyName() {
    this.allowSaveEmptyName = true;
}
#end_block

#method_before
private Optional<String> getNewName() {
    if (groupUpdate.isPresent()) {
        return groupUpdate.get().getName().map(n -> Strings.nullToEmpty(n.get()));
    } else if (groupCreation.isPresent()) {
        return Optional.of(Strings.nullToEmpty(groupCreation.get().getNameKey().get()));
    }
    return Optional.empty();
}
#method_after
private Optional<String> getNewName() {
    if (groupUpdate.isPresent()) {
        return groupUpdate.get().getName().map(n -> Strings.nullToEmpty(n.get()));
    }
    if (groupCreation.isPresent()) {
        return Optional.of(Strings.nullToEmpty(groupCreation.get().getNameKey().get()));
    }
    return Optional.empty();
}
#end_block

#method_before
public void rebuild(Repository allUsersRepo, GroupBundle bundle, @Nullable BatchRefUpdate bru) throws IOException, ConfigInvalidException, OrmDuplicateKeyException {
    GroupConfig groupConfig = GroupConfig.loadForGroup(allUsersRepo, bundle.uuid());
    AccountGroup group = bundle.group();
    groupConfig.setAllowSaveEmptyName(true);
    groupConfig.setGroupCreation(InternalGroupCreation.builder().setId(bundle.id()).setNameKey(group.getNameKey()).setGroupUUID(group.getGroupUUID()).setCreatedOn(group.getCreatedOn()).build());
    InternalGroupUpdate.Builder updateBuilder = InternalGroupUpdate.builder().setOwnerGroupUUID(group.getOwnerGroupUUID()).setVisibleToAll(group.isVisibleToAll());
    if (bundle.group().getDescription() != null) {
        updateBuilder.setDescription(group.getDescription());
    }
    groupConfig.setGroupUpdate(updateBuilder.build(), getAccountNameEmailFunc, getGroupNameFunc);
    Map<Key, Collection<Event>> events = toEvents(bundle).asMap();
    PersonIdent nowServerIdent = getServerIdent(events);
    MetaDataUpdate md = metaDataUpdateFactory.create(allUsers, allUsersRepo, bru);
    // Creation is done by the server (unlike later audit events).
    PersonIdent created = new PersonIdent(nowServerIdent, group.getCreatedOn());
    md.getCommitBuilder().setAuthor(created);
    md.getCommitBuilder().setCommitter(created);
    // Rebuild group ref.
    try (BatchMetaDataUpdate batch = groupConfig.openUpdate(md)) {
        batch.write(groupConfig, md.getCommitBuilder());
        for (Map.Entry<Key, Collection<Event>> e : events.entrySet()) {
            InternalGroupUpdate.Builder ub = InternalGroupUpdate.builder();
            e.getValue().forEach(event -> event.update().accept(ub));
            groupConfig.setGroupUpdate(ub.build(), getAccountNameEmailFunc, getGroupNameFunc);
            PersonIdent currServerIdent = new PersonIdent(nowServerIdent, e.getKey().when());
            CommitBuilder cb = new CommitBuilder();
            cb.setAuthor(e.getKey().accountId().map(id -> newPersonIdentFunc.apply(id, currServerIdent)).orElse(currServerIdent));
            cb.setCommitter(currServerIdent);
            batch.write(groupConfig, cb);
        }
        batch.createRef(groupConfig.getRefName());
    }
}
#method_after
public void rebuild(Repository allUsersRepo, GroupBundle bundle, @Nullable BatchRefUpdate bru) throws IOException, ConfigInvalidException, OrmDuplicateKeyException {
    GroupConfig groupConfig = GroupConfig.loadForGroup(allUsersRepo, bundle.uuid());
    AccountGroup group = bundle.group();
    groupConfig.setAllowSaveEmptyName();
    groupConfig.setGroupCreation(InternalGroupCreation.builder().setId(bundle.id()).setNameKey(group.getNameKey()).setGroupUUID(group.getGroupUUID()).setCreatedOn(group.getCreatedOn()).build());
    InternalGroupUpdate.Builder updateBuilder = InternalGroupUpdate.builder().setOwnerGroupUUID(group.getOwnerGroupUUID()).setVisibleToAll(group.isVisibleToAll());
    if (bundle.group().getDescription() != null) {
        updateBuilder.setDescription(group.getDescription());
    }
    groupConfig.setGroupUpdate(updateBuilder.build(), getAccountNameEmailFunc, getGroupNameFunc);
    Map<Key, Collection<Event>> events = toEvents(bundle).asMap();
    PersonIdent nowServerIdent = getServerIdent(events);
    MetaDataUpdate md = metaDataUpdateFactory.create(allUsers, allUsersRepo, bru);
    // Creation is done by the server (unlike later audit events).
    PersonIdent created = new PersonIdent(nowServerIdent, group.getCreatedOn());
    md.getCommitBuilder().setAuthor(created);
    md.getCommitBuilder().setCommitter(created);
    // Rebuild group ref.
    try (BatchMetaDataUpdate batch = groupConfig.openUpdate(md)) {
        batch.write(groupConfig, md.getCommitBuilder());
        for (Map.Entry<Key, Collection<Event>> e : events.entrySet()) {
            InternalGroupUpdate.Builder ub = InternalGroupUpdate.builder();
            e.getValue().forEach(event -> event.update().accept(ub));
            groupConfig.setGroupUpdate(ub.build(), getAccountNameEmailFunc, getGroupNameFunc);
            PersonIdent currServerIdent = new PersonIdent(nowServerIdent, e.getKey().when());
            CommitBuilder cb = new CommitBuilder();
            cb.setAuthor(e.getKey().accountId().map(id -> newPersonIdentFunc.apply(id, currServerIdent)).orElse(currServerIdent));
            cb.setCommitter(currServerIdent);
            batch.write(groupConfig, cb);
        }
        batch.createRef(groupConfig.getRefName());
    }
}
#end_block

#method_before
@Override
public ConsistencyCheckInfo apply(ConfigResource resource, ConsistencyCheckInput input) throws RestApiException, IOException, OrmException, PermissionBackendException, ConfigInvalidException {
    permissionBackend.user(user).check(GlobalPermission.ACCESS_DATABASE);
    if (input == null || (input.checkAccounts == null && input.checkAccountExternalIds == null)) {
        throw new BadRequestException("input required");
    }
    ConsistencyCheckInfo consistencyCheckInfo = new ConsistencyCheckInfo();
    if (input.checkAccounts != null) {
        consistencyCheckInfo.checkAccountsResult = new CheckAccountsResultInfo(accountsConsistencyChecker.check());
    }
    if (input.checkAccountExternalIds != null) {
        consistencyCheckInfo.checkAccountExternalIdsResult = new CheckAccountExternalIdsResultInfo(externalIdsConsistencyChecker.check());
    }
    if (input.checkGroups != null) {
        consistencyCheckInfo.checkGroupsResult = new CheckGroupsResultInfo(groupsConsistencyChecker.check());
    }
    return consistencyCheckInfo;
}
#method_after
@Override
public ConsistencyCheckInfo apply(ConfigResource resource, ConsistencyCheckInput input) throws RestApiException, IOException, OrmException, PermissionBackendException, ConfigInvalidException {
    permissionBackend.user(user).check(GlobalPermission.ACCESS_DATABASE);
    if (input == null || (input.checkAccounts == null && input.checkAccountExternalIds == null && input.checkGroups == null)) {
        throw new BadRequestException("input required");
    }
    ConsistencyCheckInfo consistencyCheckInfo = new ConsistencyCheckInfo();
    if (input.checkAccounts != null) {
        consistencyCheckInfo.checkAccountsResult = new CheckAccountsResultInfo(accountsConsistencyChecker.check());
    }
    if (input.checkAccountExternalIds != null) {
        consistencyCheckInfo.checkAccountExternalIdsResult = new CheckAccountExternalIdsResultInfo(externalIdsConsistencyChecker.check());
    }
    if (input.checkGroups != null) {
        consistencyCheckInfo.checkGroupsResult = new CheckGroupsResultInfo(groupsConsistencyChecker.check());
    }
    return consistencyCheckInfo;
}
#end_block

#method_before
@Test
public void readConfigLabelDefaultValue() throws Exception {
    RevCommit rev = util.commit(// 
    util.tree(// 
    util.file("groups", util.blob(group(developers))), util.file("project.config", util.blob(// 
    "" + // 
    "[label \"CustomLabel\"]\n" + // 
    "  value = -1 Negative\n" + // 
    "  value = 0 No Score\n" + // 
    "  value =  1 Positive\n"))));
    ProjectConfig cfg = read(rev);
    Map<String, LabelType> labels = cfg.getLabelSections();
    Short dv = labels.entrySet().iterator().next().getValue().getDefaultValue();
    assertThat((int) dv).isEqualTo(0);
}
#method_after
@Test
public void readConfigLabelDefaultValue() throws Exception {
    RevCommit rev = util.commit(// 
    util.tree(// 
    util.file("groups", util.blob(group(developers))), util.file("project.config", util.blob(// 
    "" + // 
    "[label \"CustomLabel\"]\n" + // 
    "  value = -1 Negative\n" + // No leading space before 0.
    "  value = 0 No Score\n" + // 
    "  value =  1 Positive\n"))));
    ProjectConfig cfg = read(rev);
    Map<String, LabelType> labels = cfg.getLabelSections();
    Short dv = labels.entrySet().iterator().next().getValue().getDefaultValue();
    assertThat((int) dv).isEqualTo(0);
}
#end_block

#method_before
private String getStorageDir() {
    // default to old path for javamelody storage-directory if it exists
    final Path tmp = Paths.get(System.getProperty("java.io.tmpdir")).resolve(JAVAMELODY_PREFIX);
    if (Files.isDirectory(tmp)) {
        return tmp.toString();
    }
    // plugin config has the highest priority
    Path storageDir = Optional.ofNullable(cfg.getString(STORAGE_DIR)).map((path) -> {
        // put javamelody data in default plugin data dir
        if (path == null) {
            return defaultDataDir;
        }
        return Paths.get(path);
    }).get();
    if (!Files.isDirectory(storageDir)) {
        try {
            Files.createDirectories(storageDir);
        } catch (IOException e) {
            log.error("Creation of javamelody data dir [{}] failed.", storageDir, e);
            throw new RuntimeException(e);
        }
    }
    return storageDir.toString();
}
#method_after
private String getStorageDir() {
    // default to old path for javamelody storage-directory if it exists
    final Path tmp = Paths.get(System.getProperty("java.io.tmpdir")).resolve(JAVAMELODY_PREFIX);
    if (Files.isDirectory(tmp)) {
        log.warn("Javamelody data exists in 'tmp' [{}]. Configuration (if any) will be ignored.", tmp);
        return tmp.toString();
    }
    // plugin config has the highest priority
    Path storageDir = Optional.ofNullable(cfg.getString(STORAGE_DIR)).map(Paths::get).orElse(defaultDataDir);
    if (!Files.isDirectory(storageDir)) {
        try {
            Files.createDirectories(storageDir);
        } catch (IOException e) {
            log.error("Creation of javamelody data dir [{}] failed.", storageDir, e);
            throw new RuntimeException(e);
        }
    }
    return storageDir.toString();
}
#end_block

#method_before
public String getBasePath(Project.NameKey project) {
    return cfg.getString(SECTION_NAME, findSubSection(project.get()), BASE_PATH_NAME);
}
#method_after
public Path getBasePath(Project.NameKey project) {
    String basePath = cfg.getString(SECTION_NAME, findSubSection(project.get()), BASE_PATH_NAME);
    return basePath != null ? Paths.get(basePath) : null;
}
#end_block

#method_before
public String[] getAllBasePaths() {
    List<String> basePaths = new ArrayList<>();
    for (String subSection : cfg.getSubsections(SECTION_NAME)) {
        String basePath = cfg.getString(SECTION_NAME, subSection, BASE_PATH_NAME);
        if (basePath != null) {
            basePaths.add(basePath);
        }
    }
    return basePaths.toArray(new String[basePaths.size()]);
}
#method_after
public List<Path> getAllBasePaths() {
    List<Path> basePaths = new ArrayList<>();
    for (String subSection : cfg.getSubsections(SECTION_NAME)) {
        String basePath = cfg.getString(SECTION_NAME, subSection, BASE_PATH_NAME);
        if (basePath != null) {
            basePaths.add(Paths.get(basePath));
        }
    }
    return basePaths;
}
#end_block

#method_before
@Test
public void testBasePathWhenNotConfigured() {
    assertThat(repoCfg.getBasePath(new NameKey("someProject"))).isNull();
}
#method_after
@Test
public void testBasePathWhenNotConfigured() {
    assertThat((Object) repoCfg.getBasePath(new NameKey("someProject"))).isNull();
}
#end_block

#method_before
@Test
public void testBasePathForStarFilter() {
    String basePath = "/someAbsolutePath/someDirectory";
    configureBasePath("*", basePath);
    assertThat(repoCfg.getBasePath(new NameKey("someProject"))).isEqualTo(basePath);
}
#method_after
@Test
public void testBasePathForStarFilter() {
    String basePath = "/someAbsolutePath/someDirectory";
    configureBasePath("*", basePath);
    assertThat(repoCfg.getBasePath(new NameKey("someProject")).toString()).isEqualTo(basePath);
}
#end_block

#method_before
@Test
public void testBasePathForSpecificFilter() {
    String basePath = "/someAbsolutePath/someDirectory";
    configureBasePath("someProject", basePath);
    assertThat(repoCfg.getBasePath(new NameKey("someOtherProject"))).isNull();
    assertThat(repoCfg.getBasePath(new NameKey("someProject"))).isEqualTo(basePath);
}
#method_after
@Test
public void testBasePathForSpecificFilter() {
    String basePath = "/someAbsolutePath/someDirectory";
    configureBasePath("someProject", basePath);
    assertThat((Object) repoCfg.getBasePath(new NameKey("someOtherProject"))).isNull();
    assertThat(repoCfg.getBasePath(new NameKey("someProject")).toString()).isEqualTo(basePath);
}
#end_block

#method_before
@Test
public void testBasePathForStartWithFilter() {
    String basePath1 = "/someAbsolutePath1/someDirectory";
    String basePath2 = "someRelativeDirectory2";
    String basePath3 = "/someAbsolutePath3/someDirectory";
    configureBasePath("project/project/*", basePath1);
    configureBasePath("project/*", basePath2);
    configureBasePath("*", basePath3);
    assertThat(repoCfg.getBasePath(new NameKey("project/project/someProject"))).isEqualTo(basePath1);
    assertThat(repoCfg.getBasePath(new NameKey("project/someProject"))).isEqualTo(basePath2);
    assertThat(repoCfg.getBasePath(new NameKey("someProject"))).isEqualTo(basePath3);
}
#method_after
@Test
public void testBasePathForStartWithFilter() {
    String basePath1 = "/someAbsolutePath1/someDirectory";
    String basePath2 = "someRelativeDirectory2";
    String basePath3 = "/someAbsolutePath3/someDirectory";
    String basePath4 = "/someAbsolutePath4/someDirectory";
    configureBasePath("pro*", basePath1);
    configureBasePath("project/project/*", basePath2);
    configureBasePath("project/*", basePath3);
    configureBasePath("*", basePath4);
    assertThat(repoCfg.getBasePath(new NameKey("project1")).toString()).isEqualTo(basePath1);
    assertThat(repoCfg.getBasePath(new NameKey("project/project/someProject")).toString()).isEqualTo(basePath2);
    assertThat(repoCfg.getBasePath(new NameKey("project/someProject")).toString()).isEqualTo(basePath3);
    assertThat(repoCfg.getBasePath(new NameKey("someProject")).toString()).isEqualTo(basePath4);
}
#end_block

#method_before
@Test
public void testAllBasePath() {
    String[] allBasePaths = new String[] { "/someBasePath1", "/someBasePath2", "/someBasePath3" };
    configureBasePath("*", allBasePaths[0]);
    configureBasePath("project/*", allBasePaths[1]);
    configureBasePath("project/project/*", allBasePaths[2]);
    assertThat(repoCfg.getAllBasePaths()).isEqualTo(allBasePaths);
}
#method_after
@Test
public void testAllBasePath() {
    List<Path> allBasePaths = Arrays.asList(Paths.get("/someBasePath1"), Paths.get("/someBasePath2"), Paths.get("/someBasePath2"));
    configureBasePath("*", allBasePaths.get(0).toString());
    configureBasePath("project/*", allBasePaths.get(1).toString());
    configureBasePath("project/project/*", allBasePaths.get(2).toString());
    assertThat(repoCfg.getAllBasePaths()).isEqualTo(allBasePaths);
}
#end_block

#method_before
@Override
protected void configure() {
    bind(EmailExpander.class).toProvider(EmailExpanderProvider.class).in(SINGLETON);
    bind(IdGenerator.class);
    bind(RulesCache.class);
    install(authModule);
    install(AccountByEmailCacheImpl.module());
    install(AccountCacheImpl.module());
    install(ChangeCache.module());
    install(ChangeKindCacheImpl.module());
    install(ConflictsCacheImpl.module());
    install(GroupCacheImpl.module());
    install(GroupIncludeCacheImpl.module());
    install(MergeabilityCacheImpl.module());
    install(PatchListCacheImpl.module());
    install(ProjectCacheImpl.module());
    install(SectionSortCache.module());
    install(TagCache.module());
    install(new AccessControlModule());
    install(new CmdLineParserModule());
    install(new EmailModule());
    install(new GitModule());
    install(new GroupModule());
    install(new NoteDbModule());
    install(new PrologModule());
    install(new SshAddressesModule());
    install(ThreadLocalRequestContext.module());
    bind(AccountResolver.class);
    factory(AccountInfoCacheFactory.Factory.class);
    factory(AddReviewerSender.Factory.class);
    factory(CapabilityControl.Factory.class);
    factory(ChangeData.Factory.class);
    factory(ChangeQueryBuilder.Factory.class);
    factory(CreateChangeSender.Factory.class);
    factory(GroupDetailFactory.Factory.class);
    factory(GroupInfoCacheFactory.Factory.class);
    factory(GroupMembers.Factory.class);
    factory(MergedSender.Factory.class);
    factory(MergeFailSender.Factory.class);
    factory(MergeUtil.Factory.class);
    factory(PatchScriptFactory.Factory.class);
    factory(PerformCreateGroup.Factory.class);
    factory(PerformRenameGroup.Factory.class);
    factory(PluginUser.Factory.class);
    factory(ProjectNode.Factory.class);
    factory(ProjectState.Factory.class);
    factory(RegisterNewEmailSender.Factory.class);
    factory(ReplacePatchSetSender.Factory.class);
    factory(PerformCreateProject.Factory.class);
    factory(GarbageCollection.Factory.class);
    bind(PermissionCollection.Factory.class);
    bind(AccountVisibility.class).toProvider(AccountVisibilityProvider.class).in(SINGLETON);
    factory(ProjectOwnerGroupsProvider.Factory.class);
    bind(AuthBackend.class).to(UniversalAuthBackend.class).in(SINGLETON);
    DynamicSet.setOf(binder(), AuthBackend.class);
    bind(GroupControl.Factory.class).in(SINGLETON);
    bind(GroupControl.GenericFactory.class).in(SINGLETON);
    bind(FileTypeRegistry.class).to(MimeUtilFileTypeRegistry.class);
    bind(ToolsCatalog.class);
    bind(EventFactory.class);
    bind(TransferConfig.class);
    bind(GcConfig.class);
    bind(ApprovalsUtil.class);
    bind(ChangeMergeQueue.class).in(SINGLETON);
    bind(MergeQueue.class).to(ChangeMergeQueue.class).in(SINGLETON);
    bind(RuntimeInstance.class).toProvider(VelocityRuntimeProvider.class).in(SINGLETON);
    bind(FromAddressGenerator.class).toProvider(FromAddressGeneratorProvider.class).in(SINGLETON);
    bind(Boolean.class).annotatedWith(DisableReverseDnsLookup.class).toProvider(DisableReverseDnsLookupProvider.class).in(SINGLETON);
    bind(PatchSetInfoFactory.class);
    bind(IdentifiedUser.GenericFactory.class).in(SINGLETON);
    bind(ChangeControl.GenericFactory.class);
    bind(ProjectControl.GenericFactory.class);
    bind(AccountControl.Factory.class);
    install(new AuditModule());
    install(new com.google.gerrit.server.access.Module());
    install(new com.google.gerrit.server.account.Module());
    install(new com.google.gerrit.server.api.Module());
    install(new com.google.gerrit.server.change.Module());
    install(new com.google.gerrit.server.config.Module());
    install(new com.google.gerrit.server.group.Module());
    install(new com.google.gerrit.server.project.Module());
    bind(GitReferenceUpdated.class);
    DynamicMap.mapOf(binder(), new TypeLiteral<Cache<?, ?>>() {
    });
    DynamicSet.setOf(binder(), CacheRemovalListener.class);
    DynamicMap.mapOf(binder(), CapabilityDefinition.class);
    DynamicSet.setOf(binder(), GitReferenceUpdatedListener.class);
    DynamicSet.setOf(binder(), ReceivePackInitializer.class);
    DynamicSet.setOf(binder(), PostReceiveHook.class);
    DynamicSet.setOf(binder(), PreUploadHook.class);
    DynamicSet.setOf(binder(), NewProjectCreatedListener.class);
    DynamicSet.setOf(binder(), ProjectDeletedListener.class);
    DynamicSet.setOf(binder(), HeadUpdatedListener.class);
    DynamicSet.setOf(binder(), UsageDataPublishedListener.class);
    DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(ChangeCache.class);
    DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(ReindexAfterUpdate.class);
    DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(ProjectConfigEntry.UpdateChecker.class);
    DynamicSet.setOf(binder(), ChangeListener.class);
    DynamicSet.setOf(binder(), CommitValidationListener.class);
    DynamicSet.setOf(binder(), RefOperationValidationListener.class);
    DynamicSet.setOf(binder(), MergeValidationListener.class);
    DynamicSet.setOf(binder(), ProjectCreationValidationListener.class);
    DynamicSet.setOf(binder(), GroupCreationValidationListener.class);
    DynamicSet.setOf(binder(), HashtagValidationListener.class);
    DynamicItem.itemOf(binder(), AvatarProvider.class);
    DynamicSet.setOf(binder(), LifecycleListener.class);
    DynamicSet.setOf(binder(), TopMenu.class);
    DynamicSet.setOf(binder(), MessageOfTheDay.class);
    DynamicMap.mapOf(binder(), DownloadScheme.class);
    DynamicMap.mapOf(binder(), DownloadCommand.class);
    DynamicMap.mapOf(binder(), ProjectConfigEntry.class);
    DynamicSet.setOf(binder(), PatchSetWebLink.class);
    DynamicSet.setOf(binder(), FileWebLink.class);
    DynamicSet.setOf(binder(), ProjectWebLink.class);
    DynamicSet.setOf(binder(), BranchWebLink.class);
    factory(UploadValidators.Factory.class);
    DynamicSet.setOf(binder(), UploadValidationListener.class);
    bind(AnonymousUser.class);
    factory(CommitValidators.Factory.class);
    factory(RefOperationValidators.Factory.class);
    factory(MergeValidators.Factory.class);
    factory(ProjectConfigValidator.Factory.class);
    factory(NotesBranchUtil.Factory.class);
    bind(AccountManager.class);
    bind(ChangeUserName.CurrentUser.class);
    factory(ChangeUserName.Factory.class);
    bind(new TypeLiteral<List<CommentLinkInfo>>() {
    }).toProvider(CommentLinkProvider.class).in(SINGLETON);
    bind(ReloadPluginListener.class).annotatedWith(UniqueAnnotations.create()).to(PluginConfigFactory.class);
}
#method_after
@Override
protected void configure() {
    bind(EmailExpander.class).toProvider(EmailExpanderProvider.class).in(SINGLETON);
    bind(IdGenerator.class);
    bind(RulesCache.class);
    bind(Sequences.class);
    install(authModule);
    install(AccountByEmailCacheImpl.module());
    install(AccountCacheImpl.module());
    install(ChangeKindCacheImpl.module());
    install(ConflictsCacheImpl.module());
    install(GroupCacheImpl.module());
    install(GroupIncludeCacheImpl.module());
    install(MergeabilityCacheImpl.module());
    install(PatchListCacheImpl.module());
    install(ProjectCacheImpl.module());
    install(SectionSortCache.module());
    install(SubmitStrategy.module());
    install(TagCache.module());
    install(new AccessControlModule());
    install(new CmdLineParserModule());
    install(new EmailModule());
    install(new GitModule());
    install(new GroupModule());
    install(new NoteDbModule());
    install(new PrologModule());
    install(new SshAddressesModule());
    install(ThreadLocalRequestContext.module());
    bind(AccountResolver.class);
    factory(AccountInfoCacheFactory.Factory.class);
    factory(AddReviewerSender.Factory.class);
    factory(AddKeySender.Factory.class);
    factory(BatchUpdate.Factory.class);
    factory(CapabilityControl.Factory.class);
    factory(ChangeData.Factory.class);
    factory(ChangeJson.Factory.class);
    factory(CreateChangeSender.Factory.class);
    factory(GroupDetailFactory.Factory.class);
    factory(GroupInfoCacheFactory.Factory.class);
    factory(GroupMembers.Factory.class);
    factory(EmailMerge.Factory.class);
    factory(MergedSender.Factory.class);
    factory(MergeFailSender.Factory.class);
    factory(MergeUtil.Factory.class);
    factory(PatchScriptFactory.Factory.class);
    factory(PluginUser.Factory.class);
    factory(ProjectNode.Factory.class);
    factory(ProjectState.Factory.class);
    factory(RegisterNewEmailSender.Factory.class);
    factory(ReplacePatchSetSender.Factory.class);
    bind(PermissionCollection.Factory.class);
    bind(AccountVisibility.class).toProvider(AccountVisibilityProvider.class).in(SINGLETON);
    factory(ProjectOwnerGroupsProvider.Factory.class);
    bind(AuthBackend.class).to(UniversalAuthBackend.class).in(SINGLETON);
    DynamicSet.setOf(binder(), AuthBackend.class);
    bind(GroupControl.Factory.class).in(SINGLETON);
    bind(GroupControl.GenericFactory.class).in(SINGLETON);
    bind(FileTypeRegistry.class).to(MimeUtilFileTypeRegistry.class);
    bind(ToolsCatalog.class);
    bind(EventFactory.class);
    bind(TransferConfig.class);
    bind(GitwebConfig.class);
    bind(GcConfig.class);
    bind(ChangeCleanupConfig.class);
    bind(ApprovalsUtil.class);
    bind(RuntimeInstance.class).toProvider(VelocityRuntimeProvider.class).in(SINGLETON);
    bind(FromAddressGenerator.class).toProvider(FromAddressGeneratorProvider.class).in(SINGLETON);
    bind(Boolean.class).annotatedWith(DisableReverseDnsLookup.class).toProvider(DisableReverseDnsLookupProvider.class).in(SINGLETON);
    bind(PatchSetInfoFactory.class);
    bind(IdentifiedUser.GenericFactory.class).in(SINGLETON);
    bind(ChangeControl.GenericFactory.class);
    bind(ProjectControl.GenericFactory.class);
    bind(AccountControl.Factory.class);
    install(new AuditModule());
    install(new com.google.gerrit.server.access.Module());
    install(new com.google.gerrit.server.account.Module());
    install(new com.google.gerrit.server.api.Module());
    install(new com.google.gerrit.server.change.Module());
    install(new com.google.gerrit.server.config.Module());
    install(new com.google.gerrit.server.group.Module());
    install(new com.google.gerrit.server.project.Module());
    bind(GitReferenceUpdated.class);
    DynamicMap.mapOf(binder(), new TypeLiteral<Cache<?, ?>>() {
    });
    DynamicSet.setOf(binder(), CacheRemovalListener.class);
    DynamicMap.mapOf(binder(), CapabilityDefinition.class);
    DynamicSet.setOf(binder(), GitReferenceUpdatedListener.class);
    DynamicSet.setOf(binder(), ReceivePackInitializer.class);
    DynamicSet.setOf(binder(), PostReceiveHook.class);
    DynamicSet.setOf(binder(), PreUploadHook.class);
    DynamicSet.setOf(binder(), ChangeIndexedListener.class);
    DynamicSet.setOf(binder(), NewProjectCreatedListener.class);
    DynamicSet.setOf(binder(), ProjectDeletedListener.class);
    DynamicSet.setOf(binder(), GarbageCollectorListener.class);
    DynamicSet.setOf(binder(), HeadUpdatedListener.class);
    DynamicSet.setOf(binder(), UsageDataPublishedListener.class);
    DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(ReindexAfterUpdate.class);
    DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(ProjectConfigEntry.UpdateChecker.class);
    DynamicSet.setOf(binder(), EventListener.class);
    DynamicSet.bind(binder(), EventListener.class).to(EventsMetrics.class);
    DynamicSet.setOf(binder(), UserScopedEventListener.class);
    DynamicSet.setOf(binder(), CommitValidationListener.class);
    DynamicSet.setOf(binder(), RefOperationValidationListener.class);
    DynamicSet.setOf(binder(), MergeValidationListener.class);
    DynamicSet.setOf(binder(), ProjectCreationValidationListener.class);
    DynamicSet.setOf(binder(), GroupCreationValidationListener.class);
    DynamicSet.setOf(binder(), HashtagValidationListener.class);
    DynamicSet.setOf(binder(), OutgoingEmailValidationListener.class);
    DynamicItem.itemOf(binder(), AvatarProvider.class);
    DynamicSet.setOf(binder(), LifecycleListener.class);
    DynamicSet.setOf(binder(), TopMenu.class);
    DynamicSet.setOf(binder(), MessageOfTheDay.class);
    DynamicMap.mapOf(binder(), DownloadScheme.class);
    DynamicMap.mapOf(binder(), DownloadCommand.class);
    DynamicMap.mapOf(binder(), CloneCommand.class);
    DynamicMap.mapOf(binder(), ExternalIncludedIn.class);
    DynamicMap.mapOf(binder(), ProjectConfigEntry.class);
    DynamicSet.setOf(binder(), PatchSetWebLink.class);
    DynamicSet.setOf(binder(), FileWebLink.class);
    DynamicSet.setOf(binder(), FileHistoryWebLink.class);
    DynamicSet.setOf(binder(), DiffWebLink.class);
    DynamicSet.setOf(binder(), ProjectWebLink.class);
    DynamicSet.setOf(binder(), BranchWebLink.class);
    DynamicMap.mapOf(binder(), OAuthLoginProvider.class);
    DynamicSet.setOf(binder(), AccountExternalIdCreator.class);
    factory(UploadValidators.Factory.class);
    DynamicSet.setOf(binder(), UploadValidationListener.class);
    DynamicMap.mapOf(binder(), ChangeQueryBuilder.ChangeOperatorFactory.class);
    bind(AnonymousUser.class);
    factory(CommitValidators.Factory.class);
    factory(RefOperationValidators.Factory.class);
    factory(MergeValidators.Factory.class);
    factory(ProjectConfigValidator.Factory.class);
    factory(NotesBranchUtil.Factory.class);
    factory(SubmoduleSectionParser.Factory.class);
    factory(ReplaceOp.Factory.class);
    bind(AccountManager.class);
    factory(ChangeUserName.Factory.class);
    bind(new TypeLiteral<List<CommentLinkInfo>>() {
    }).toProvider(CommentLinkProvider.class).in(SINGLETON);
    bind(ReloadPluginListener.class).annotatedWith(UniqueAnnotations.create()).to(PluginConfigFactory.class);
}
#end_block

#method_before
@Test
public void includeExternalGroup() throws Exception {
    String g = createGroup("group");
    String subgroupUuid = SystemGroupBackend.REGISTERED_USERS.get();
    gApi.groups().id(g).addGroups(subgroupUuid);
    List<GroupInfo> subgroups = gApi.groups().id(g).includedGroups();
    assertThat(subgroups).hasSize(1);
    assertThat(subgroups.get(0).id).isEqualTo(subgroupUuid.replace(":", "%3A"));
    assertThat(subgroups.get(0).groupId).isNull();
    if (groupsMigration.writeToNoteDb()) {
        AccountGroup.UUID uuid = new AccountGroup.UUID(gApi.groups().id(g).get().id);
        try (Repository repo = repoManager.openRepository(allUsers)) {
            ImmutableList<CommitInfo> log = GroupTestUtil.log(repo, RefNames.refsGroups(uuid));
            assertThat(log).hasSize(2);
            assertThat(log.get(0)).message().isEqualTo("Create group");
            assertThat(log.get(1)).message().isEqualTo("Update group\n\nAdd-group: global:Registered-Users <global:Registered-Users>");
            List<AccountGroupByIdAud> audit = groups.getSubgroupsAudit(db, repo, uuid);
            assertThat(audit).hasSize(1);
            assertThat(audit.get(0).getIncludeUUID()).isEqualTo(SystemGroupBackend.REGISTERED_USERS);
        }
    }
}
#method_after
@Test
public void includeExternalGroup() throws Exception {
    String g = createGroup("group");
    String subgroupUuid = SystemGroupBackend.REGISTERED_USERS.get();
    gApi.groups().id(g).addGroups(subgroupUuid);
    List<GroupInfo> subgroups = gApi.groups().id(g).includedGroups();
    assertThat(subgroups).hasSize(1);
    assertThat(subgroups.get(0).id).isEqualTo(subgroupUuid.replace(":", "%3A"));
    assertThat(subgroups.get(0).name).isEqualTo("Registered Users");
    assertThat(subgroups.get(0).groupId).isNull();
    List<? extends GroupAuditEventInfo> auditEvents = gApi.groups().id(g).auditLog();
    assertThat(auditEvents).hasSize(1);
    assertAuditEvent(auditEvents.get(0), Type.ADD_GROUP, admin.id, "Registered Users");
}
#end_block

#method_before
@Test
public void logFormat() throws Exception {
    TestAccount user2 = accountCreator.user2();
    GroupInfo group1 = gApi.groups().create(name("group1")).get();
    GroupInfo group2 = gApi.groups().create(name("group2")).get();
    try (TempClockStep step = TestTimeUtil.freezeClock()) {
        gApi.groups().id(group1.id).addMembers(user.id.toString(), user2.id.toString());
    }
    TimeUtil.nowTs();
    try (TempClockStep step = TestTimeUtil.freezeClock()) {
        gApi.groups().id(group1.id).addGroups(group2.id, SystemGroupBackend.REGISTERED_USERS.get());
    }
    try (BlockReviewDbUpdatesForGroups ctx = new BlockReviewDbUpdatesForGroups()) {
        GroupBundle reviewDbBundle = bundleFactory.fromReviewDb(db, new AccountGroup.Id(group1.groupId));
        deleteGroupRefs(reviewDbBundle);
        GroupBundle noteDbBundle = rebuild(reviewDbBundle);
        assertThat(noteDbBundle).isEqualTo(reviewDbBundle.truncateToSecond());
        ImmutableList<CommitInfo> log = log(group1);
        assertThat(log).hasSize(4);
        assertThat(log.get(0)).message().isEqualTo("Create group");
        assertThat(log.get(0)).author().name().isEqualTo(serverIdent.get().getName());
        assertThat(log.get(0)).author().email().isEqualTo(serverIdent.get().getEmailAddress());
        assertThat(log.get(0)).author().date().isEqualTo(noteDbBundle.group().getCreatedOn());
        assertThat(log.get(0)).author().tz().isEqualTo(serverIdent.get().getTimeZoneOffset());
        assertThat(log.get(0)).committer().isEqualTo(log.get(0).author);
        assertThat(log.get(1)).message().isEqualTo("Update group\n\nAdd: Administrator <" + admin.id + "@" + serverId + ">");
        assertThat(log.get(1)).author().name().isEqualTo(admin.fullName);
        assertThat(log.get(1)).author().email().isEqualTo(admin.id + "@" + serverId);
        assertThat(log.get(1)).committer().hasSameDateAs(log.get(1).author);
        assertThat(log.get(2)).message().isEqualTo("Update group\n" + "\n" + ("Add: User <" + user.id + "@" + serverId + ">\n") + ("Add: User2 <" + user2.id + "@" + serverId + ">"));
        assertThat(log.get(2)).author().name().isEqualTo(admin.fullName);
        assertThat(log.get(2)).author().email().isEqualTo(admin.id + "@" + serverId);
        assertThat(log.get(2)).committer().hasSameDateAs(log.get(2).author);
        assertThat(log.get(3)).message().isEqualTo("Update group\n" + "\n" + ("Add-group: " + group2.name + " <" + group2.id + ">\n") + ("Add-group: global:Registered-Users <global:Registered-Users>"));
        assertThat(log.get(3)).author().name().isEqualTo(admin.fullName);
        assertThat(log.get(3)).author().email().isEqualTo(admin.id + "@" + serverId);
        assertThat(log.get(3)).committer().hasSameDateAs(log.get(3).author);
    }
}
#method_after
@Test
public void logFormat() throws Exception {
    TestAccount user2 = accountCreator.user2();
    GroupInfo group1 = gApi.groups().create(name("group1")).get();
    GroupInfo group2 = gApi.groups().create(name("group2")).get();
    try (TempClockStep step = TestTimeUtil.freezeClock()) {
        gApi.groups().id(group1.id).addMembers(user.id.toString(), user2.id.toString());
    }
    TimeUtil.nowTs();
    try (TempClockStep step = TestTimeUtil.freezeClock()) {
        gApi.groups().id(group1.id).addGroups(group2.id, SystemGroupBackend.REGISTERED_USERS.get());
    }
    try (BlockReviewDbUpdatesForGroups ctx = new BlockReviewDbUpdatesForGroups()) {
        GroupBundle reviewDbBundle = bundleFactory.fromReviewDb(db, new AccountGroup.Id(group1.groupId));
        deleteGroupRefs(reviewDbBundle);
        GroupBundle noteDbBundle = rebuild(reviewDbBundle);
        assertThat(noteDbBundle).isEqualTo(reviewDbBundle.truncateToSecond());
        ImmutableList<CommitInfo> log = log(group1);
        assertThat(log).hasSize(4);
        assertThat(log.get(0)).message().isEqualTo("Create group");
        assertThat(log.get(0)).author().name().isEqualTo(serverIdent.get().getName());
        assertThat(log.get(0)).author().email().isEqualTo(serverIdent.get().getEmailAddress());
        assertThat(log.get(0)).author().date().isEqualTo(noteDbBundle.group().getCreatedOn());
        assertThat(log.get(0)).author().tz().isEqualTo(serverIdent.get().getTimeZoneOffset());
        assertThat(log.get(0)).committer().isEqualTo(log.get(0).author);
        assertThat(log.get(1)).message().isEqualTo("Update group\n\nAdd: Administrator <" + admin.id + "@" + serverId + ">");
        assertThat(log.get(1)).author().name().isEqualTo(admin.fullName);
        assertThat(log.get(1)).author().email().isEqualTo(admin.id + "@" + serverId);
        assertThat(log.get(1)).committer().hasSameDateAs(log.get(1).author);
        assertThat(log.get(2)).message().isEqualTo("Update group\n" + "\n" + ("Add: User <" + user.id + "@" + serverId + ">\n") + ("Add: User2 <" + user2.id + "@" + serverId + ">"));
        assertThat(log.get(2)).author().name().isEqualTo(admin.fullName);
        assertThat(log.get(2)).author().email().isEqualTo(admin.id + "@" + serverId);
        assertThat(log.get(2)).committer().hasSameDateAs(log.get(2).author);
        assertThat(log.get(3)).message().isEqualTo("Update group\n" + "\n" + ("Add-group: " + group2.name + " <" + group2.id + ">\n") + ("Add-group: Registered Users <global:Registered-Users>"));
        assertThat(log.get(3)).author().name().isEqualTo(admin.fullName);
        assertThat(log.get(3)).author().email().isEqualTo(admin.id + "@" + serverId);
        assertThat(log.get(3)).committer().hasSameDateAs(log.get(3).author);
    }
}
#end_block

#method_before
private String getGroupName(AccountGroup.UUID groupUuid) {
    return getGroupName(groupCache, groupUuid);
}
#method_after
static String getGroupName(GroupBackend groupBackend, AccountGroup.UUID groupUuid) {
    String uuid = groupUuid.get();
    GroupDescription.Basic desc = groupBackend.get(groupUuid);
    String name = desc != null ? desc.getName() : uuid;
    return formatNameEmail(name, uuid);
}
#end_block

#method_before
private String getGroupName(AccountGroup.UUID groupUuid) {
    return getGroupName(groupCache, groupUuid);
}
#method_after
private String getGroupName(AccountGroup.UUID groupUuid) {
    return getGroupName(groupBackend, groupUuid);
}
#end_block

#method_before
@Test
public void defaultPermissionsOnUserBranches() throws Exception {
    String userRef = RefNames.REFS_USERS + "${" + RefPattern.USERID_SHARDED + "}";
    assertPermission(allUsers, groupRef(REGISTERED_USERS), userRef, true, Permission.READ, Permission.PUSH, Permission.SUBMIT);
    assertLabelPermission(allUsers, groupRef(REGISTERED_USERS), userRef, true, "Code-Review", -2, 2);
    assertPermission(allUsers, groupRef("Administrators"), RefNames.REFS_USERS_DEFAULT, true, Permission.READ, Permission.PUSH, Permission.CREATE);
}
#method_after
@Test
public void defaultPermissionsOnUserBranches() throws Exception {
    String userRef = RefNames.REFS_USERS + "${" + RefPattern.USERID_SHARDED + "}";
    assertPermissions(allUsers, groupRef(REGISTERED_USERS), userRef, true, Permission.READ, Permission.PUSH, Permission.SUBMIT);
    assertLabelPermission(allUsers, groupRef(REGISTERED_USERS), userRef, true, "Code-Review", -2, 2);
    assertPermissions(allUsers, groupRef("Administrators"), RefNames.REFS_USERS_DEFAULT, true, Permission.READ, Permission.PUSH, Permission.CREATE);
}
#end_block

#method_before
@ConfigSuite.Default
public static Config defaultConfig() {
    Config config = new Config();
    // This test is explicitly testing the migration from ReviewDb to NoteDb, and handles reading
    // from NoteDb manually. It should work regardless of the value of writeGroupsToNoteDb, however.
    config.setBoolean("user", null, "readGroupsFromNoteDb", false);
    return config;
}
#method_after
@ConfigSuite.Default
public static Config defaultConfig() {
    Config config = new Config();
    // This test is explicitly testing the migration from ReviewDb to NoteDb, and handles reading
    // from NoteDb manually. It should work regardless of the value of noteDb.groups.write, however.
    config.setBoolean(SECTION_NOTE_DB, GROUPS.key(), READ, false);
    return config;
}
#end_block

#method_before
private void blockReviewDbUpdates(boolean block) {
    cfg.setBoolean("user", null, "readGroupsFromNoteDb", block);
}
#method_after
private void blockReviewDbUpdates(boolean block) {
    cfg.setBoolean("user", null, "blockReviewDbGroupUpdates", block);
}
#end_block

#method_before
@Before
public void setUp() throws Exception {
    super.setUp();
    TestTimeUtil.resetWithClockStep(1, TimeUnit.SECONDS);
    idCounter = new AtomicInteger();
    repo = repoManager.createRepository(allUsersName);
    rebuilder = new GroupRebuilder(GroupRebuilderTest::newPersonIdent, allUsersName, (project, repo, batch) -> new MetaDataUpdate(GitReferenceUpdated.DISABLED, project, repo, batch), // values.
    AbstractGroupTest::newPersonIdent, AbstractGroupTest::getAccountNameEmail, AbstractGroupTest::getGroupName);
    bundleFactory = new GroupBundle.Factory(new AuditLogReader(SERVER_ID, repoManager, allUsersName));
}
#method_after
@Before
public void setUp() throws Exception {
    TestTimeUtil.resetWithClockStep(1, TimeUnit.SECONDS);
    idCounter = new AtomicInteger();
    repo = repoManager.createRepository(allUsersName);
    rebuilder = new GroupRebuilder(GroupRebuilderTest::newPersonIdent, allUsersName, (project, repo, batch) -> new MetaDataUpdate(GitReferenceUpdated.DISABLED, project, repo, batch), // values.
    AbstractGroupTest::newPersonIdent, AbstractGroupTest::getAccountNameEmail, AbstractGroupTest::getGroupName);
    bundleFactory = new GroupBundle.Factory(new AuditLogReader(SERVER_ID, repoManager, allUsersName));
}
#end_block

#method_before
private static PatchListEntry createPatchListEntry(RawTextComparator cmp, RevCommit aCommit, Text aText, Text bText, String fileName) {
    byte[] rawHdr = getRawHeader(aCommit != null, fileName);
    byte[] aContent = aText.getContent();
    byte[] bContent = bText.getContent();
    long size = bContent.length;
    long sizeDelta = size - (long) aContent.length;
    RawText aRawText = new RawText(aContent);
    RawText bRawText = new RawText(bContent);
    EditList edits = new HistogramDiff().diff(cmp, aRawText, bRawText);
    FileHeader fh = new FileHeader(rawHdr, edits, PatchType.UNIFIED);
    return new PatchListEntry(fh, edits, ImmutableSet.of(), size, sizeDelta);
}
#method_after
private static PatchListEntry createPatchListEntry(RawTextComparator cmp, RevCommit aCommit, Text aText, Text bText, String fileName) {
    byte[] rawHdr = getRawHeader(aCommit != null, fileName);
    byte[] aContent = aText.getContent();
    byte[] bContent = bText.getContent();
    long size = bContent.length;
    long sizeDelta = size - aContent.length;
    RawText aRawText = new RawText(aContent);
    RawText bRawText = new RawText(bContent);
    EditList edits = new HistogramDiff().diff(cmp, aRawText, bRawText);
    FileHeader fh = new FileHeader(rawHdr, edits, PatchType.UNIFIED);
    return new PatchListEntry(fh, edits, ImmutableSet.of(), size, sizeDelta);
}
#end_block

#method_before
@Before
public void setUp() {
    TestTimeUtil.resetWithClockStep(1, TimeUnit.SECONDS);
    idCounter = new AtomicInteger();
    allUsers = new AllUsersName(AllUsersNameProvider.DEFAULT);
    repo = new InMemoryRepository(new DfsRepositoryDescription(AllUsersNameProvider.DEFAULT));
    rebuilder = new GroupRebuilder(() -> new PersonIdent("Gerrit Server", "noreply@gerrit.com", TimeUtil.nowTs(), TZ), allUsers, (project, repo, batch) -> new MetaDataUpdate(GitReferenceUpdated.DISABLED, project, repo, batch), (id, ident) -> new PersonIdent("Account " + id, id + "@example.com", ident.getWhen(), ident.getTimeZone()), id -> String.format("Account %s <%s@example.com>", id, id), uuid -> "Group " + uuid);
}
#method_after
@Before
public void setUp() {
    TestTimeUtil.resetWithClockStep(1, TimeUnit.SECONDS);
    idCounter = new AtomicInteger();
    repo = new InMemoryRepository(new DfsRepositoryDescription(AllUsersNameProvider.DEFAULT));
    rebuilder = new GroupRebuilder(() -> new PersonIdent(SERVER_NAME, SERVER_EMAIL, TimeUtil.nowTs(), TZ), new AllUsersName(AllUsersNameProvider.DEFAULT), (project, repo, batch) -> new MetaDataUpdate(GitReferenceUpdated.DISABLED, project, repo, batch), // values.
    (id, ident) -> new PersonIdent("Account " + id, id + "@server-id", ident.getWhen(), ident.getTimeZone()), id -> String.format("Account %s <%s@server-id>", id, id), uuid -> "Group " + uuid);
}
#end_block

#method_before
@Test
public void minimalGroupFields() throws Exception {
    AccountGroup g = newGroup("a");
    GroupBundle b = builder().group(g).build();
    rebuilder.rebuild(repo, b);
    assertThat(reload(g)).isEqualTo(b.toInternalGroup());
    assertThat(log(g)).containsExactly("Create group");
    assertOwner(g, new GroupReference(g.getGroupUUID(), "Group a-1"));
}
#method_after
@Test
public void minimalGroupFields() throws Exception {
    AccountGroup g = newGroup("a");
    GroupBundle b = builder().group(g).build();
    rebuilder.rebuild(repo, b);
    assertThat(reload(g)).isEqualTo(b.toInternalGroup());
    ImmutableList<CommitInfo> log = log(g);
    assertThat(log).hasSize(1);
    assertCommit(log.get(0), "Create group", SERVER_NAME, SERVER_EMAIL);
}
#end_block

#method_before
@Test
public void allGroupFields() throws Exception {
    AccountGroup g = newGroup("a");
    g.setDescription("Description");
    g.setOwnerGroupUUID(new AccountGroup.UUID("owner"));
    g.setVisibleToAll(true);
    GroupBundle b = builder().group(g).build();
    rebuilder.rebuild(repo, b);
    assertThat(reload(g)).isEqualTo(b.toInternalGroup());
    assertThat(log(g)).containsExactly("Create group");
    assertOwner(g, new GroupReference(g.getOwnerGroupUUID(), "Group owner"));
}
#method_after
@Test
public void allGroupFields() throws Exception {
    AccountGroup g = newGroup("a");
    g.setDescription("Description");
    g.setOwnerGroupUUID(new AccountGroup.UUID("owner"));
    g.setVisibleToAll(true);
    GroupBundle b = builder().group(g).build();
    rebuilder.rebuild(repo, b);
    assertThat(reload(g)).isEqualTo(b.toInternalGroup());
    ImmutableList<CommitInfo> log = log(g);
    assertThat(log).hasSize(1);
    assertServerCommit(log.get(0), "Create group");
}
#end_block

#method_before
@Test
public void membersAndSubgroups() throws Exception {
    AccountGroup g = newGroup("a");
    GroupBundle b = builder().group(g).members(member(g, 1), member(g, 2)).byId(byId(g, "x"), byId(g, "y")).build();
    rebuilder.rebuild(repo, b);
    assertThat(reload(g)).isEqualTo(b.toInternalGroup());
    assertThat(log(g)).containsExactly("Create group", "Update group\n" + "\n" + "Add: Account 1 <1@example.com>\n" + "Add: Account 2 <2@example.com>\n" + "Add-group: Group x\n" + "Add-group: Group y").inOrder();
}
#method_after
@Test
public void membersAndSubgroups() throws Exception {
    AccountGroup g = newGroup("a");
    GroupBundle b = builder().group(g).members(member(g, 1), member(g, 2)).byId(byId(g, "x"), byId(g, "y")).build();
    rebuilder.rebuild(repo, b);
    assertThat(reload(g)).isEqualTo(b.toInternalGroup());
    ImmutableList<CommitInfo> log = log(g);
    assertThat(log).hasSize(2);
    assertServerCommit(log.get(0), "Create group");
    assertServerCommit(log.get(1), "Update group\n" + "\n" + "Add: Account 1 <1@server-id>\n" + "Add: Account 2 <2@server-id>\n" + "Add-group: Group x\n" + "Add-group: Group y");
}
#end_block

#method_before
@Test
public void memberAudit() throws Exception {
    AccountGroup g = newGroup("a");
    Timestamp t1 = TimeUtil.nowTs();
    Timestamp t2 = TimeUtil.nowTs();
    Timestamp t3 = TimeUtil.nowTs();
    GroupBundle b = builder().group(g).members(member(g, 1)).memberAudit(addMember(g, 1, 8, t2), addAndRemoveMember(g, 2, 8, t1, 9, t3)).build();
    rebuilder.rebuild(repo, b);
    assertThat(reload(g)).isEqualTo(b.toInternalGroup());
    assertThat(log(g)).containsExactly("Create group", "Update group\n\nAdd: Account 2 <2@example.com>", "Update group\n\nAdd: Account 1 <1@example.com>", "Update group\n\nRemove: Account 2 <2@example.com>").inOrder();
}
#method_after
@Test
public void memberAudit() throws Exception {
    AccountGroup g = newGroup("a");
    Timestamp t1 = TimeUtil.nowTs();
    Timestamp t2 = TimeUtil.nowTs();
    Timestamp t3 = TimeUtil.nowTs();
    GroupBundle b = builder().group(g).members(member(g, 1)).memberAudit(addMember(g, 1, 8, t2), addAndRemoveMember(g, 2, 8, t1, 9, t3)).build();
    rebuilder.rebuild(repo, b);
    assertThat(reload(g)).isEqualTo(b.toInternalGroup());
    ImmutableList<CommitInfo> log = log(g);
    assertThat(log).hasSize(4);
    assertServerCommit(log.get(0), "Create group");
    assertCommit(log.get(1), "Update group\n\nAdd: Account 2 <2@server-id>", "Account 8", "8@server-id");
    assertCommit(log.get(2), "Update group\n\nAdd: Account 1 <1@server-id>", "Account 8", "8@server-id");
    assertCommit(log.get(3), "Update group\n\nRemove: Account 2 <2@server-id>", "Account 9", "9@server-id");
}
#end_block

#method_before
@Test
public void memberAuditLegacyRemoved() throws Exception {
    AccountGroup g = newGroup("a");
    GroupBundle b = builder().group(g).members(member(g, 2)).memberAudit(addAndLegacyRemoveMember(g, 1, 8, TimeUtil.nowTs()), addMember(g, 2, 8, TimeUtil.nowTs())).build();
    rebuilder.rebuild(repo, b);
    assertThat(reload(g)).isEqualTo(b.toInternalGroup());
    assertThat(log(g)).containsExactly("Create group", "Update group\n\nAdd: Account 1 <1@example.com>", "Update group\n\nRemove: Account 1 <1@example.com>", "Update group\n\nAdd: Account 2 <2@example.com>").inOrder();
}
#method_after
@Test
public void memberAuditLegacyRemoved() throws Exception {
    AccountGroup g = newGroup("a");
    GroupBundle b = builder().group(g).members(member(g, 2)).memberAudit(addAndLegacyRemoveMember(g, 1, 8, TimeUtil.nowTs()), addMember(g, 2, 8, TimeUtil.nowTs())).build();
    rebuilder.rebuild(repo, b);
    assertThat(reload(g)).isEqualTo(b.toInternalGroup());
    ImmutableList<CommitInfo> log = log(g);
    assertThat(log).hasSize(4);
    assertServerCommit(log.get(0), "Create group");
    assertCommit(log.get(1), "Update group\n\nAdd: Account 1 <1@server-id>", "Account 8", "8@server-id");
    assertCommit(log.get(2), "Update group\n\nRemove: Account 1 <1@server-id>", "Account 8", "8@server-id");
    assertCommit(log.get(3), "Update group\n\nAdd: Account 2 <2@server-id>", "Account 8", "8@server-id");
}
#end_block

#method_before
@Test
public void unauditedMembershipsAddedAtEnd() throws Exception {
    AccountGroup g = newGroup("a");
    GroupBundle b = builder().group(g).members(member(g, 1), member(g, 2), member(g, 3)).memberAudit(addMember(g, 1, 8, TimeUtil.nowTs())).build();
    rebuilder.rebuild(repo, b);
    assertThat(reload(g)).isEqualTo(b.toInternalGroup());
    assertThat(log(g)).containsExactly("Create group", "Update group\n\nAdd: Account 1 <1@example.com>", "Update group\n\nAdd: Account 2 <2@example.com>\nAdd: Account 3 <3@example.com>").inOrder();
}
#method_after
@Test
public void unauditedMembershipsAddedAtEnd() throws Exception {
    AccountGroup g = newGroup("a");
    GroupBundle b = builder().group(g).members(member(g, 1), member(g, 2), member(g, 3)).memberAudit(addMember(g, 1, 8, TimeUtil.nowTs())).build();
    rebuilder.rebuild(repo, b);
    assertThat(reload(g)).isEqualTo(b.toInternalGroup());
    ImmutableList<CommitInfo> log = log(g);
    assertThat(log).hasSize(3);
    assertServerCommit(log.get(0), "Create group");
    assertCommit(log.get(1), "Update group\n\nAdd: Account 1 <1@server-id>", "Account 8", "8@server-id");
    assertServerCommit(log.get(2), "Update group\n\nAdd: Account 2 <2@server-id>\nAdd: Account 3 <3@server-id>");
}
#end_block

#method_before
@Test
public void byIdAudit() throws Exception {
    AccountGroup g = newGroup("a");
    Timestamp t1 = TimeUtil.nowTs();
    Timestamp t2 = TimeUtil.nowTs();
    Timestamp t3 = TimeUtil.nowTs();
    GroupBundle b = builder().group(g).byId(byId(g, "x")).byIdAudit(addById(g, "x", 8, t2), addAndRemoveById(g, "y", 8, t1, 9, t3)).build();
    rebuilder.rebuild(repo, b);
    assertThat(reload(g)).isEqualTo(b.toInternalGroup());
    assertThat(log(g)).containsExactly("Create group", "Update group\n\nAdd-group: Group y", "Update group\n\nAdd-group: Group x", "Update group\n\nRemove-group: Group y").inOrder();
}
#method_after
@Test
public void byIdAudit() throws Exception {
    AccountGroup g = newGroup("a");
    Timestamp t1 = TimeUtil.nowTs();
    Timestamp t2 = TimeUtil.nowTs();
    Timestamp t3 = TimeUtil.nowTs();
    GroupBundle b = builder().group(g).byId(byId(g, "x")).byIdAudit(addById(g, "x", 8, t2), addAndRemoveById(g, "y", 8, t1, 9, t3)).build();
    rebuilder.rebuild(repo, b);
    assertThat(reload(g)).isEqualTo(b.toInternalGroup());
    ImmutableList<CommitInfo> log = log(g);
    assertThat(log).hasSize(4);
    assertServerCommit(log.get(0), "Create group");
    assertCommit(log.get(1), "Update group\n\nAdd-group: Group y", "Account 8", "8@server-id");
    assertCommit(log.get(2), "Update group\n\nAdd-group: Group x", "Account 8", "8@server-id");
    assertCommit(log.get(3), "Update group\n\nRemove-group: Group y", "Account 9", "9@server-id");
}
#end_block

#method_before
@Test
public void unauditedByIdAddedAtEnd() throws Exception {
    AccountGroup g = newGroup("a");
    GroupBundle b = builder().group(g).byId(byId(g, "x"), byId(g, "y"), byId(g, "z")).byIdAudit(addById(g, "x", 8, TimeUtil.nowTs())).build();
    rebuilder.rebuild(repo, b);
    assertThat(reload(g)).isEqualTo(b.toInternalGroup());
    assertThat(log(g)).containsExactly("Create group", "Update group\n\nAdd-group: Group x", "Update group\n\nAdd-group: Group y\nAdd-group: Group z").inOrder();
}
#method_after
@Test
public void unauditedByIdAddedAtEnd() throws Exception {
    AccountGroup g = newGroup("a");
    GroupBundle b = builder().group(g).byId(byId(g, "x"), byId(g, "y"), byId(g, "z")).byIdAudit(addById(g, "x", 8, TimeUtil.nowTs())).build();
    rebuilder.rebuild(repo, b);
    assertThat(reload(g)).isEqualTo(b.toInternalGroup());
    ImmutableList<CommitInfo> log = log(g);
    assertThat(log).hasSize(3);
    assertServerCommit(log.get(0), "Create group");
    assertCommit(log.get(1), "Update group\n\nAdd-group: Group x", "Account 8", "8@server-id");
    assertServerCommit(log.get(2), "Update group\n\nAdd-group: Group y\nAdd-group: Group z");
}
#end_block

#method_before
private InternalGroup reload(AccountGroup g) throws Exception {
    return GroupConfig.loadForGroup(allUsers, repo, g.getGroupUUID(), project -> {
        throw new UnsupportedOperationException();
    }).getLoadedGroup().get();
}
#method_after
private InternalGroup reload(AccountGroup g) throws Exception {
    return GroupConfig.loadForGroup(repo, g.getGroupUUID()).getLoadedGroup().get();
}
#end_block

#method_before
private ImmutableList<String> log(AccountGroup g) throws Exception {
    try (RevWalk rw = new RevWalk(repo)) {
        Ref ref = repo.exactRef(RefNames.refsGroups(g.getGroupUUID()));
        if (ref == null) {
            return ImmutableList.of();
        }
        rw.sort(RevSort.REVERSE);
        rw.setRetainBody(true);
        rw.markStart(rw.parseCommit(ref.getObjectId()));
        return Streams.stream(rw).map(RevCommit::getFullMessage).collect(toImmutableList());
    }
}
#method_after
private ImmutableList<CommitInfo> log(AccountGroup g) throws Exception {
    ImmutableList<CommitInfo> result = ImmutableList.of();
    try (RevWalk rw = new RevWalk(repo)) {
        Ref ref = repo.exactRef(RefNames.refsGroups(g.getGroupUUID()));
        if (ref != null) {
            rw.sort(RevSort.REVERSE);
            rw.setRetainBody(true);
            rw.markStart(rw.parseCommit(ref.getObjectId()));
            result = Streams.stream(rw).map(CommitUtil::toCommitInfo).collect(toImmutableList());
        }
    }
    return result;
}
#end_block

#method_before
public void rebuild(Repository allUsersRepo, GroupBundle bundle) throws IOException, ConfigInvalidException, OrmDuplicateKeyException {
    GroupConfig groupConfig = GroupConfig.loadForGroupNoOwnerUpdate(allUsers, allUsersRepo, bundle.uuid());
    groupConfig.setGroupCreation(InternalGroupCreation.builder().setId(bundle.id()).setNameKey(bundle.group().getNameKey()).setGroupUUID(bundle.group().getGroupUUID()).setCreatedOn(bundle.group().getCreatedOn()).build());
    groupConfig.setUpdateOwnerPermissionsStrategy(UpdateOwnerPermissionsStrategy.SKIP);
    // Don't set owner in the InternalGroupUpdate; this triggers a non-atomic update of
    // refs/meta/config within GroupConfig#onSave. The owner update is handled specially in this
    // method using a single BatchRefUpdate.
    InternalGroupUpdate.Builder updateBuilder = InternalGroupUpdate.builder().setVisibleToAll(bundle.group().isVisibleToAll());
    if (bundle.group().getDescription() != null) {
        updateBuilder.setDescription(bundle.group().getDescription());
    }
    groupConfig.setGroupUpdate(updateBuilder.build(), getAccountNameEmailFunc, getGroupNameFunc);
    BatchRefUpdate bru = allUsersRepo.getRefDatabase().newBatchUpdate();
    MetaDataUpdate md = metaDataUpdateFactory.create(allUsers, allUsersRepo, bru);
    // Creation is done by the server (unlike later audit events).
    PersonIdent nowServerIdent = serverIdent.get();
    PersonIdent created = new PersonIdent(nowServerIdent, bundle.group().getCreatedOn());
    md.getCommitBuilder().setAuthor(created);
    md.getCommitBuilder().setCommitter(created);
    // Rebuild group ref.
    try (BatchMetaDataUpdate batch = groupConfig.openUpdate(md)) {
        batch.write(groupConfig, md.getCommitBuilder());
        for (Event e : toEvents(bundle, nowServerIdent)) {
            PersonIdent currServerIdent = new PersonIdent(nowServerIdent, e.when());
            groupConfig.setGroupUpdate(e.update(), getAccountNameEmailFunc, getGroupNameFunc);
            CommitBuilder cb = new CommitBuilder();
            cb.setAuthor(e.accountId().map(id -> newPersonIdentFunc.apply(id, currServerIdent)).orElse(currServerIdent));
            cb.setCommitter(currServerIdent);
            batch.write(groupConfig, cb);
        }
        batch.createRef(groupConfig.getRefName());
    }
    // Update refs/meta/config in same batch.
    GroupOwnerPermissions ownerPerm = new GroupOwnerPermissions(allUsers, allUsersRepo, project -> {
        checkArgument(project.equals(allUsers));
        MetaDataUpdate result = metaDataUpdateFactory.create(project, allUsersRepo, bru);
        result.getCommitBuilder().setAuthor(nowServerIdent);
        result.getCommitBuilder().setCommitter(nowServerIdent);
        return result;
    });
    AccountGroup.UUID ownerUuid = bundle.group().getOwnerGroupUUID();
    ownerPerm.updateOwnerPermissions(bundle.uuid(), null, new GroupReference(ownerUuid, getGroupNameFunc.apply(ownerUuid)));
    checkState(bru.getCommands().size() == 2, "expected 2 commands, got: %s", bru);
    try (RevWalk rw = new RevWalk(allUsersRepo)) {
        RefUpdateUtil.executeChecked(bru, rw);
    }
}
#method_after
public void rebuild(Repository allUsersRepo, GroupBundle bundle) throws IOException, ConfigInvalidException, OrmDuplicateKeyException {
    GroupConfig groupConfig = GroupConfig.loadForGroup(allUsersRepo, bundle.uuid());
    AccountGroup group = bundle.group();
    groupConfig.setGroupCreation(InternalGroupCreation.builder().setId(bundle.id()).setNameKey(group.getNameKey()).setGroupUUID(group.getGroupUUID()).setCreatedOn(group.getCreatedOn()).build());
    InternalGroupUpdate.Builder updateBuilder = InternalGroupUpdate.builder().setOwnerGroupUUID(group.getOwnerGroupUUID()).setVisibleToAll(group.isVisibleToAll());
    if (bundle.group().getDescription() != null) {
        updateBuilder.setDescription(group.getDescription());
    }
    groupConfig.setGroupUpdate(updateBuilder.build(), getAccountNameEmailFunc, getGroupNameFunc);
    MetaDataUpdate md = metaDataUpdateFactory.create(allUsers, allUsersRepo, null);
    // Creation is done by the server (unlike later audit events).
    PersonIdent nowServerIdent = serverIdent.get();
    PersonIdent created = new PersonIdent(nowServerIdent, group.getCreatedOn());
    md.getCommitBuilder().setAuthor(created);
    md.getCommitBuilder().setCommitter(created);
    // Rebuild group ref.
    try (BatchMetaDataUpdate batch = groupConfig.openUpdate(md)) {
        batch.write(groupConfig, md.getCommitBuilder());
        Map<Key, Collection<Event>> events = toEvents(bundle, nowServerIdent).asMap();
        for (Map.Entry<Key, Collection<Event>> e : events.entrySet()) {
            InternalGroupUpdate.Builder ub = InternalGroupUpdate.builder();
            e.getValue().forEach(event -> event.update().accept(ub));
            groupConfig.setGroupUpdate(ub.build(), getAccountNameEmailFunc, getGroupNameFunc);
            PersonIdent currServerIdent = new PersonIdent(nowServerIdent, e.getKey().when());
            CommitBuilder cb = new CommitBuilder();
            cb.setAuthor(e.getKey().accountId().map(id -> newPersonIdentFunc.apply(id, currServerIdent)).orElse(currServerIdent));
            cb.setCommitter(currServerIdent);
            batch.write(groupConfig, cb);
        }
        batch.createRef(groupConfig.getRefName());
    }
}
#end_block

#method_before
private ImmutableList<Event> toEvents(GroupBundle bundle, PersonIdent nowServerIdent) {
    List<Event> result = new ArrayList<>();
    for (AccountGroupMemberAudit a : bundle.memberAudit()) {
        checkArgument(a.getKey().getGroupId().equals(bundle.id()), "key %s does not match group %s", a.getKey(), bundle.id());
        Account.Id accountId = a.getKey().getParentKey();
        result.add(Event.create(a.getAddedBy(), a.getKey().getAddedOn(), addMember(accountId)));
        if (!a.isActive()) {
            result.add(Event.create(a.getRemovedBy(), a.getRemovedOn(), removeMember(accountId)));
        }
    }
    for (AccountGroupByIdAud a : bundle.byIdAudit()) {
        checkArgument(a.getKey().getParentKey().equals(bundle.id()), "key %s does not match group %s", a.getKey(), bundle.id());
        AccountGroup.UUID uuid = a.getKey().getIncludeUUID();
        result.add(Event.create(a.getAddedBy(), a.getKey().getAddedOn(), addGroup(uuid)));
        if (!a.isActive()) {
            result.add(Event.create(a.getRemovedBy(), a.getRemovedOn(), removeGroup(uuid)));
        }
    }
    result.add(Event.byServer(new Timestamp(nowServerIdent.getWhen().getTime()), setCurrentMembership(bundle)));
    // underlying database.
    return result.stream().sorted(comparing(Event::when)).collect(toImmutableList());
}
#method_after
private ListMultimap<Key, Event> toEvents(GroupBundle bundle, PersonIdent nowServerIdent) {
    ListMultimap<Key, Event> result = MultimapBuilder.treeKeys(Key.COMPARATOR).arrayListValues(1).build();
    Event e;
    for (AccountGroupMemberAudit a : bundle.memberAudit()) {
        checkArgument(a.getKey().getGroupId().equals(bundle.id()), "key %s does not match group %s", a.getKey(), bundle.id());
        Account.Id accountId = a.getKey().getParentKey();
        e = event(Type.ADD_MEMBER, a.getAddedBy(), a.getKey().getAddedOn(), addMember(accountId));
        result.put(e.key(), e);
        if (!a.isActive()) {
            e = event(Type.REMOVE_MEMBER, a.getRemovedBy(), a.getRemovedOn(), removeMember(accountId));
            result.put(e.key(), e);
        }
    }
    for (AccountGroupByIdAud a : bundle.byIdAudit()) {
        checkArgument(a.getKey().getParentKey().equals(bundle.id()), "key %s does not match group %s", a.getKey(), bundle.id());
        AccountGroup.UUID uuid = a.getKey().getIncludeUUID();
        e = event(Type.ADD_GROUP, a.getAddedBy(), a.getKey().getAddedOn(), addGroup(uuid));
        result.put(e.key(), e);
        if (!a.isActive()) {
            e = event(Type.REMOVE_GROUP, a.getRemovedBy(), a.getRemovedOn(), removeGroup(uuid));
            result.put(e.key(), e);
        }
    }
    Timestamp now = new Timestamp(nowServerIdent.getWhen().getTime());
    e = serverEvent(Type.FIXUP, now, setCurrentMembership(bundle));
    result.put(e.key(), e);
    return result;
}
#end_block

#method_before
private static InternalGroupUpdate.Builder addMember(Account.Id toAdd) {
    return InternalGroupUpdate.builder().setMemberModification(in -> Stream.concat(in.stream(), Stream.of(toAdd)).collect(toImmutableSet()));
}
#method_after
private static Consumer<InternalGroupUpdate.Builder> addMember(Account.Id toAdd) {
    return b -> {
        MemberModification prev = b.getMemberModification();
        b.setMemberModification(in -> Sets.union(prev.apply(in), ImmutableSet.of(toAdd)));
    };
}
#end_block

#method_before
private static InternalGroupUpdate.Builder removeMember(Account.Id toRemove) {
    return InternalGroupUpdate.builder().setMemberModification(in -> in.stream().filter(id -> !id.equals(toRemove)).collect(toImmutableSet()));
}
#method_after
private static Consumer<InternalGroupUpdate.Builder> removeMember(Account.Id toRemove) {
    return b -> {
        MemberModification prev = b.getMemberModification();
        b.setMemberModification(in -> Sets.difference(prev.apply(in), ImmutableSet.of(toRemove)));
    };
}
#end_block

#method_before
private static InternalGroupUpdate.Builder addGroup(AccountGroup.UUID toAdd) {
    return InternalGroupUpdate.builder().setSubgroupModification(in -> Stream.concat(in.stream(), Stream.of(toAdd)).collect(toImmutableSet()));
}
#method_after
private static Consumer<InternalGroupUpdate.Builder> addGroup(AccountGroup.UUID toAdd) {
    return b -> {
        SubgroupModification prev = b.getSubgroupModification();
        b.setSubgroupModification(in -> Sets.union(prev.apply(in), ImmutableSet.of(toAdd)));
    };
}
#end_block

#method_before
private static InternalGroupUpdate.Builder removeGroup(AccountGroup.UUID toRemove) {
    return InternalGroupUpdate.builder().setSubgroupModification(in -> in.stream().filter(id -> !id.equals(toRemove)).collect(toImmutableSet()));
}
#method_after
private static Consumer<InternalGroupUpdate.Builder> removeGroup(AccountGroup.UUID toRemove) {
    return b -> {
        SubgroupModification prev = b.getSubgroupModification();
        b.setSubgroupModification(in -> Sets.difference(prev.apply(in), ImmutableSet.of(toRemove)));
    };
}
#end_block

#method_before
private static InternalGroupUpdate.Builder setCurrentMembership(GroupBundle bundle) {
    // set differences to compute the appropriate delta.
    return InternalGroupUpdate.builder().setMemberModification(in -> bundle.members().stream().map(m -> m.getAccountId()).collect(toImmutableSet())).setSubgroupModification(in -> bundle.byId().stream().map(m -> m.getIncludeUUID()).collect(toImmutableSet()));
}
#method_after
private static Consumer<InternalGroupUpdate.Builder> setCurrentMembership(GroupBundle bundle) {
    // set differences to compute the appropriate delta, if any.
    return b -> b.setMemberModification(in -> bundle.members().stream().map(m -> m.getAccountId()).collect(toImmutableSet())).setSubgroupModification(in -> bundle.byId().stream().map(m -> m.getIncludeUUID()).collect(toImmutableSet()));
}
#end_block

#method_before
InternalGroup toInternalGroup() {
    return InternalGroup.create(group(), members().stream().map(AccountGroupMember::getAccountId).collect(toImmutableSet()), byId().stream().map(AccountGroupById::getIncludeUUID).collect(toImmutableSet()));
}
#method_after
public InternalGroup toInternalGroup() {
    return InternalGroup.create(group(), members().stream().map(AccountGroupMember::getAccountId).collect(toImmutableSet()), byId().stream().map(AccountGroupById::getIncludeUUID).collect(toImmutableSet()));
}
#end_block

#method_before
@ConfigSuite.Default
public static Config defaultConfig() {
    Config config = new Config();
    // This test is explicitly testing the migration from ReviewDb to NoteDb, and handles reading
    // from NoteDb manually.
    config.setBoolean("user", null, "readGroupsFromNoteDb", false);
    return config;
}
#method_after
@ConfigSuite.Default
public static Config defaultConfig() {
    Config config = new Config();
    // This test is explicitly testing the migration from ReviewDb to NoteDb, and handles reading
    // from NoteDb manually. It should work regardless of the value of writeGroupsToNoteDb, however.
    config.setBoolean("user", null, "readGroupsFromNoteDb", false);
    return config;
}
#end_block

#method_before
@Test
public void basicGroupProperties() throws Exception {
    InternalGroup group = groupsUpdate.get().createGroup(db, create(name("group")).build(), noUpdate());
    group = groups.getGroup(db, group.getGroupUUID()).get();
    deleteGroupRefs(group);
    assertThat(rebuild(group)).isEqualTo(roundToSecond(group));
}
#method_after
@Test
public void basicGroupProperties() throws Exception {
    GroupInfo createdGroup = gApi.groups().create(name("group")).get();
    InternalGroup reviewDbGroup = groups.getGroup(db, new AccountGroup.UUID(createdGroup.id)).get();
    deleteGroupRefs(reviewDbGroup);
    assertThat(rebuild(reviewDbGroup)).isEqualTo(roundToSecond(reviewDbGroup));
}
#end_block

#method_before
private InternalGroup rebuild(InternalGroup group) throws Exception {
    try (Repository repo = repoManager.openRepository(allUsers)) {
        rebuilder.rebuild(repo, GroupBundle.fromReviewDb(db, group.getId()));
        GroupConfig groupConfig = GroupConfig.loadForGroupNoOwnerUpdate(allUsers, repo, group.getGroupUUID());
        Optional<InternalGroup> result = groupConfig.getLoadedGroup();
        assertThat(result).isPresent();
        return result.get();
    }
}
#method_after
private InternalGroup rebuild(InternalGroup group) throws Exception {
    try (Repository repo = repoManager.openRepository(allUsers)) {
        rebuilder.rebuild(repo, GroupBundle.fromReviewDb(db, group.getId()));
        GroupConfig groupConfig = GroupConfig.loadForGroup(repo, group.getGroupUUID());
        Optional<InternalGroup> result = groupConfig.getLoadedGroup();
        assertThat(result).isPresent();
        return result.get();
    }
}
#end_block

#method_before
public static GroupConfig createForNewGroup(AllUsersName allUsersName, Repository repository, InternalGroupCreation groupCreation, MetaDataUpdateFactory metaDataUpdateFactory) throws IOException, ConfigInvalidException, OrmDuplicateKeyException {
    checkNotNull(metaDataUpdateFactory);
    GroupConfig groupConfig = new GroupConfig(new GroupOwnerPermissions(allUsersName, repository, metaDataUpdateFactory), groupCreation.getGroupUUID());
    groupConfig.load(repository);
    groupConfig.setGroupCreation(groupCreation);
    return groupConfig;
}
#method_after
public static GroupConfig createForNewGroup(Repository repository, InternalGroupCreation groupCreation) throws IOException, ConfigInvalidException, OrmDuplicateKeyException {
    GroupConfig groupConfig = new GroupConfig(groupCreation.getGroupUUID());
    groupConfig.load(repository);
    groupConfig.setGroupCreation(groupCreation);
    return groupConfig;
}
#end_block

#method_before
public static GroupConfig loadForGroup(AllUsersName allUsersName, Repository repository, AccountGroup.UUID groupUuid, MetaDataUpdateFactory metaDataUpdateFactory) throws IOException, ConfigInvalidException {
    checkNotNull(metaDataUpdateFactory);
    GroupConfig groupConfig = new GroupConfig(new GroupOwnerPermissions(allUsersName, repository, metaDataUpdateFactory), groupUuid);
    groupConfig.load(repository);
    return groupConfig;
}
#method_after
public static GroupConfig loadForGroup(Repository repository, AccountGroup.UUID groupUuid) throws IOException, ConfigInvalidException {
    GroupConfig groupConfig = new GroupConfig(groupUuid);
    groupConfig.load(repository);
    return groupConfig;
}
#end_block

#method_before
@Override
protected void onLoad() throws IOException, ConfigInvalidException {
    if (revision != null) {
        rw.reset();
        rw.markStart(revision);
        rw.sort(RevSort.REVERSE);
        RevCommit earliestCommit = rw.next();
        Timestamp createdOn = new Timestamp(earliestCommit.getCommitTime() * 1000L);
        Config config = readConfig(GROUP_CONFIG_FILE);
        ImmutableSet<Account.Id> members = readMembers();
        ImmutableSet<AccountGroup.UUID> subgroups = readSubgroups();
        AccountGroup.UUID ownerGroupUuid = groupOwnerPermissions.readOwnerGroup(groupUuid);
        if (ownerGroupUuid == null) {
            throw new ConfigInvalidException(String.format("Group owner for group %s not found.", groupUuid.get()));
        }
        loadedGroup = Optional.of(createFrom(groupUuid, ownerGroupUuid, config, members, subgroups, createdOn));
    }
    isLoaded = true;
}
#method_after
@Override
protected void onLoad() throws IOException, ConfigInvalidException {
    if (revision != null) {
        rw.reset();
        rw.markStart(revision);
        rw.sort(RevSort.REVERSE);
        RevCommit earliestCommit = rw.next();
        Timestamp createdOn = new Timestamp(earliestCommit.getCommitTime() * 1000L);
        Config config = readConfig(GROUP_CONFIG_FILE);
        ImmutableSet<Account.Id> members = readMembers();
        ImmutableSet<AccountGroup.UUID> subgroups = readSubgroups();
        loadedGroup = Optional.of(createFrom(groupUuid, config, members, subgroups, createdOn));
    }
    isLoaded = true;
}
#end_block

#method_before
private static InternalGroup createFrom(AccountGroup.UUID groupUuid, AccountGroup.UUID ownerGroupUuid, Config config, ImmutableSet<Account.Id> members, ImmutableSet<AccountGroup.UUID> subgroups, Timestamp createdOn) {
    InternalGroup.Builder group = InternalGroup.builder();
    group.setGroupUUID(groupUuid);
    group.setOwnerGroupUUID(ownerGroupUuid);
    Arrays.stream(GroupConfigEntry.values()).forEach(configEntry -> configEntry.readFromConfig(group, config));
    group.setMembers(members);
    group.setSubgroups(subgroups);
    group.setCreatedOn(createdOn);
    return group.build();
}
#method_after
private static InternalGroup createFrom(AccountGroup.UUID groupUuid, Config config, ImmutableSet<Account.Id> members, ImmutableSet<AccountGroup.UUID> subgroups, Timestamp createdOn) {
    InternalGroup.Builder group = InternalGroup.builder();
    group.setGroupUUID(groupUuid);
    Arrays.stream(GroupConfigEntry.values()).forEach(configEntry -> configEntry.readFromConfig(group, config));
    group.setMembers(members);
    group.setSubgroups(subgroups);
    group.setCreatedOn(createdOn);
    return group.build();
}
#end_block

#method_before
@Override
protected boolean onSave(CommitBuilder commit) throws IOException, ConfigInvalidException {
    checkLoaded();
    if (!groupCreation.isPresent() && !groupUpdate.isPresent()) {
        // Group was neither created nor changed. -> A new commit isn't necessary.
        return false;
    }
    Timestamp createdOn;
    if (groupCreation.isPresent()) {
        createdOn = groupCreation.get().getCreatedOn();
        commit.setAuthor(new PersonIdent(commit.getAuthor(), createdOn));
        commit.setCommitter(new PersonIdent(commit.getCommitter(), createdOn));
    } else {
        checkState(loadedGroup.isPresent(), String.format("Cannot update non-existent group %s", groupUuid.get()));
        createdOn = loadedGroup.get().getCreatedOn();
    }
    Config config = updateGroupProperties();
    AccountGroup.UUID groupOwnerUuid = updateOwnerPermissions();
    ImmutableSet<Account.Id> originalMembers = loadedGroup.map(InternalGroup::getMembers).orElseGet(ImmutableSet::of);
    Optional<ImmutableSet<Account.Id>> updatedMembers = updateMembers(originalMembers);
    ImmutableSet<AccountGroup.UUID> originalSubgroups = loadedGroup.map(InternalGroup::getSubgroups).orElseGet(ImmutableSet::of);
    Optional<ImmutableSet<AccountGroup.UUID>> updatedSubgroups = updateSubgroups(originalSubgroups);
    String commitMessage = createCommitMessage(originalMembers, updatedMembers, originalSubgroups, updatedSubgroups);
    commit.setMessage(commitMessage);
    loadedGroup = Optional.of(createFrom(groupUuid, groupOwnerUuid, config, updatedMembers.orElse(originalMembers), updatedSubgroups.orElse(originalSubgroups), createdOn));
    groupCreation = Optional.empty();
    updateOwnerPermissionsStrategy = UpdateOwnerPermissionsStrategy.UPDATE;
    return true;
}
#method_after
@Override
protected boolean onSave(CommitBuilder commit) throws IOException, ConfigInvalidException {
    checkLoaded();
    if (!groupCreation.isPresent() && !groupUpdate.isPresent()) {
        // Group was neither created nor changed. -> A new commit isn't necessary.
        return false;
    }
    Timestamp createdOn;
    if (groupCreation.isPresent()) {
        createdOn = groupCreation.get().getCreatedOn();
        commit.setAuthor(new PersonIdent(commit.getAuthor(), createdOn));
        commit.setCommitter(new PersonIdent(commit.getCommitter(), createdOn));
    } else {
        checkState(loadedGroup.isPresent(), "Cannot update non-existent group %s", groupUuid.get());
        createdOn = loadedGroup.get().getCreatedOn();
    }
    Config config = updateGroupProperties();
    ImmutableSet<Account.Id> originalMembers = loadedGroup.map(InternalGroup::getMembers).orElseGet(ImmutableSet::of);
    Optional<ImmutableSet<Account.Id>> updatedMembers = updateMembers(originalMembers);
    ImmutableSet<AccountGroup.UUID> originalSubgroups = loadedGroup.map(InternalGroup::getSubgroups).orElseGet(ImmutableSet::of);
    Optional<ImmutableSet<AccountGroup.UUID>> updatedSubgroups = updateSubgroups(originalSubgroups);
    String commitMessage = createCommitMessage(originalMembers, updatedMembers, originalSubgroups, updatedSubgroups);
    commit.setMessage(commitMessage);
    loadedGroup = Optional.of(createFrom(groupUuid, config, updatedMembers.orElse(originalMembers), updatedSubgroups.orElse(originalSubgroups), createdOn));
    groupCreation = Optional.empty();
    return true;
}
#end_block

#method_before
private void checkLoaded() {
    checkState(isLoaded, String.format("Group %s not loaded yet", groupUuid.get()));
}
#method_after
private void checkLoaded() {
    checkState(isLoaded, "Group %s not loaded yet", groupUuid.get());
}
#end_block

#method_before
private Optional<ImmutableSet<Account.Id>> updateMembers(ImmutableSet<Account.Id> originalMembers) throws IOException {
    Optional<ImmutableSet<Account.Id>> updatedMembers = groupUpdate.map(InternalGroupUpdate::getMemberModification).map(memberModification -> memberModification.apply(originalMembers)).map(ImmutableSet::copyOf);
    if (updatedMembers.isPresent() && !updatedMembers.get().equals(originalMembers)) {
        saveMembers(updatedMembers.get());
    }
    return updatedMembers;
}
#method_after
private Optional<ImmutableSet<Account.Id>> updateMembers(ImmutableSet<Account.Id> originalMembers) throws IOException {
    Optional<ImmutableSet<Account.Id>> updatedMembers = groupUpdate.map(InternalGroupUpdate::getMemberModification).map(memberModification -> memberModification.apply(originalMembers)).map(ImmutableSet::copyOf).filter(members -> !originalMembers.equals(members));
    if (updatedMembers.isPresent()) {
        saveMembers(updatedMembers.get());
    }
    return updatedMembers;
}
#end_block

#method_before
private Optional<ImmutableSet<AccountGroup.UUID>> updateSubgroups(ImmutableSet<AccountGroup.UUID> originalSubgroups) throws IOException {
    Optional<ImmutableSet<AccountGroup.UUID>> updatedSubgroups = groupUpdate.map(InternalGroupUpdate::getSubgroupModification).map(subgroupModification -> subgroupModification.apply(originalSubgroups)).map(ImmutableSet::copyOf);
    if (updatedSubgroups.isPresent() && !updatedSubgroups.get().equals(originalSubgroups)) {
        saveSubgroups(updatedSubgroups.get());
    }
    return updatedSubgroups;
}
#method_after
private Optional<ImmutableSet<AccountGroup.UUID>> updateSubgroups(ImmutableSet<AccountGroup.UUID> originalSubgroups) throws IOException {
    Optional<ImmutableSet<AccountGroup.UUID>> updatedSubgroups = groupUpdate.map(InternalGroupUpdate::getSubgroupModification).map(subgroupModification -> subgroupModification.apply(originalSubgroups)).map(ImmutableSet::copyOf).filter(subgroups -> !originalSubgroups.equals(subgroups));
    if (updatedSubgroups.isPresent()) {
        saveSubgroups(updatedSubgroups.get());
    }
    return updatedSubgroups;
}
#end_block

#method_before
// TODO(aliceks): Introduce a common class for MetaDataUpdate.User and MetaDataUpdate.Server which
// doesn't require this ugly code. In addition, allow to pass in the repository and to use another
private static MetaDataUpdateFactory getMetaDataUpdateFactory(MetaDataUpdate.User metaDataUpdateUserFactory, MetaDataUpdate.Server metaDataUpdateServerFactory, @Nullable IdentifiedUser currentUser, PersonIdent serverIdent, String serverId, String anonymousCowardName) {
    return currentUser != null ? projectName -> {
        MetaDataUpdate metaDataUpdate = metaDataUpdateUserFactory.create(projectName, currentUser);
        PersonIdent authorIdent = getAuditLogAuthorIdent(currentUser.getAccount(), serverIdent, serverId, anonymousCowardName);
        metaDataUpdate.getCommitBuilder().setAuthor(authorIdent);
        return metaDataUpdate;
    } : metaDataUpdateServerFactory::create;
}
#method_after
private static MetaDataUpdateFactory getMetaDataUpdateFactory(MetaDataUpdate.InternalFactory metaDataUpdateInternalFactory, @Nullable IdentifiedUser currentUser, PersonIdent serverIdent, String serverId, String anonymousCowardName) {
    return (projectName, repository, batchRefUpdate) -> {
        MetaDataUpdate metaDataUpdate = metaDataUpdateInternalFactory.create(projectName, repository, batchRefUpdate);
        metaDataUpdate.getCommitBuilder().setCommitter(serverIdent);
        PersonIdent authorIdent;
        if (currentUser != null) {
            metaDataUpdate.setAuthor(currentUser);
            authorIdent = getAuditLogAuthorIdent(currentUser.getAccount(), serverIdent, serverId, anonymousCowardName);
        } else {
            authorIdent = serverIdent;
        }
        metaDataUpdate.getCommitBuilder().setAuthor(authorIdent);
        return metaDataUpdate;
    };
}
#end_block

#method_before
public InternalGroup createGroup(ReviewDb db, InternalGroupCreation groupCreation, InternalGroupUpdate groupUpdate) throws OrmException, IOException, ConfigInvalidException {
    InternalGroup createdGroupInReviewDb = createGroupInReviewDb(db, groupCreation, groupUpdate);
    if (!writeGroupsToNoteDb) {
        updateCachesOnGroupCreation(createdGroupInReviewDb);
        return createdGroupInReviewDb;
    }
    InternalGroup createdGroup = createGroupInNoteDb(groupCreation, groupUpdate);
    updateCachesOnGroupCreation(createdGroup);
    return createdGroup;
}
#method_after
public InternalGroup createGroup(ReviewDb db, InternalGroupCreation groupCreation, InternalGroupUpdate groupUpdate) throws OrmException, IOException, ConfigInvalidException {
    InternalGroup createdGroupInReviewDb = createGroupInReviewDb(db, groupCreation, groupUpdate);
    if (!writeGroupsToNoteDb) {
        updateCachesOnGroupCreation(createdGroupInReviewDb);
        return createdGroupInReviewDb;
    }
    // TODO(aliceks): Add retry mechanism.
    InternalGroup createdGroup = createGroupInNoteDb(groupCreation, groupUpdate);
    updateCachesOnGroupCreation(createdGroup);
    return createdGroup;
}
#end_block

#method_before
@VisibleForTesting
public UpdateResult updateGroupInDb(ReviewDb db, AccountGroup.UUID groupUuid, InternalGroupUpdate groupUpdate) throws OrmException, NoSuchGroupException, IOException, ConfigInvalidException {
    AccountGroup group = getExistingGroupFromReviewDb(db, groupUuid);
    UpdateResult reviewDbUpdateResult = updateGroupInReviewDb(db, group, groupUpdate);
    if (!writeGroupsToNoteDb) {
        return reviewDbUpdateResult;
    }
    Optional<UpdateResult> noteDbUpdateResult = updateGroupInNoteDb(groupUuid, groupUpdate);
    return noteDbUpdateResult.orElse(reviewDbUpdateResult);
}
#method_after
@VisibleForTesting
public UpdateResult updateGroupInDb(ReviewDb db, AccountGroup.UUID groupUuid, InternalGroupUpdate groupUpdate) throws OrmException, NoSuchGroupException, IOException, ConfigInvalidException {
    AccountGroup group = getExistingGroupFromReviewDb(db, groupUuid);
    UpdateResult reviewDbUpdateResult = updateGroupInReviewDb(db, group, groupUpdate);
    if (!writeGroupsToNoteDb) {
        return reviewDbUpdateResult;
    }
    // TODO(aliceks): Add retry mechanism.
    Optional<UpdateResult> noteDbUpdateResult = updateGroupInNoteDb(groupUuid, groupUpdate);
    return noteDbUpdateResult.orElse(reviewDbUpdateResult);
}
#end_block

#method_before
private static void applyUpdate(AccountGroup group, InternalGroupUpdate groupUpdate) {
    groupUpdate.getName().ifPresent(group::setNameKey);
    groupUpdate.getDescription().ifPresent(d -> group.setDescription(Strings.emptyToNull(d)));
    groupUpdate.getOwnerGroupReference().ifPresent(r -> group.setOwnerGroupUUID(r.getUUID()));
    groupUpdate.getVisibleToAll().ifPresent(group::setVisibleToAll);
}
#method_after
private static void applyUpdate(AccountGroup group, InternalGroupUpdate groupUpdate) {
    groupUpdate.getName().ifPresent(group::setNameKey);
    groupUpdate.getDescription().ifPresent(d -> group.setDescription(Strings.emptyToNull(d)));
    groupUpdate.getOwnerGroupUUID().ifPresent(group::setOwnerGroupUUID);
    groupUpdate.getVisibleToAll().ifPresent(group::setVisibleToAll);
}
#end_block

#method_before
private InternalGroup createGroupInNoteDb(InternalGroupCreation groupCreation, InternalGroupUpdate groupUpdate) throws IOException, ConfigInvalidException, OrmException {
    GroupConfig groupConfig = createFor(groupCreation);
    updateGroupInNoteDb(groupConfig, groupUpdate);
    return groupConfig.getLoadedGroup().orElseThrow(() -> new IllegalStateException("Created group wasn't automatically loaded"));
}
#method_after
private InternalGroup createGroupInNoteDb(InternalGroupCreation groupCreation, InternalGroupUpdate groupUpdate) throws IOException, ConfigInvalidException, OrmException {
    try (Repository allUsersRepo = repoManager.openRepository(allUsersName)) {
        AccountGroup.NameKey groupName = groupUpdate.getName().orElseGet(groupCreation::getNameKey);
        GroupNameNotes groupNameNotes = GroupNameNotes.loadForNewGroup(allUsersRepo, groupCreation.getGroupUUID(), groupName);
        GroupConfig groupConfig = GroupConfig.createForNewGroup(allUsersRepo, groupCreation);
        groupConfig.setGroupUpdate(groupUpdate, this::getAccountNameEmail, this::getGroupName);
        commit(allUsersRepo, groupConfig, groupNameNotes);
        return groupConfig.getLoadedGroup().orElseThrow(() -> new IllegalStateException("Created group wasn't automatically loaded"));
    }
}
#end_block

#method_before
private Optional<UpdateResult> updateGroupInNoteDb(AccountGroup.UUID groupUuid, InternalGroupUpdate groupUpdate) throws IOException, ConfigInvalidException {
    GroupConfig groupConfig = loadFor(groupUuid);
    if (!groupConfig.getLoadedGroup().isPresent()) {
        // TODO(aliceks): Throw a NoSuchGroupException here when all groups are stored in NoteDb.
        return Optional.empty();
    }
    return updateGroupInNoteDb(groupConfig, groupUpdate);
}
#method_after
private Optional<UpdateResult> updateGroupInNoteDb(AccountGroup.UUID groupUuid, InternalGroupUpdate groupUpdate) throws IOException, ConfigInvalidException, OrmDuplicateKeyException {
    try (Repository allUsersRepo = repoManager.openRepository(allUsersName)) {
        GroupConfig groupConfig = GroupConfig.loadForGroup(allUsersRepo, groupUuid);
        groupConfig.setGroupUpdate(groupUpdate, this::getAccountNameEmail, this::getGroupName);
        if (!groupConfig.getLoadedGroup().isPresent()) {
            // TODO(aliceks): Throw a NoSuchGroupException here when all groups are stored in NoteDb.
            return Optional.empty();
        }
        InternalGroup originalGroup = groupConfig.getLoadedGroup().get();
        GroupNameNotes groupNameNotes = null;
        if (groupUpdate.getName().isPresent()) {
            AccountGroup.NameKey oldName = originalGroup.getNameKey();
            AccountGroup.NameKey newName = groupUpdate.getName().get();
            groupNameNotes = GroupNameNotes.loadForRename(allUsersRepo, groupUuid, oldName, newName);
        }
        commit(allUsersRepo, groupConfig, groupNameNotes);
        InternalGroup updatedGroup = groupConfig.getLoadedGroup().orElseThrow(() -> new IllegalStateException("Updated group wasn't automatically loaded"));
        return Optional.of(getUpdateResult(originalGroup, updatedGroup));
    }
}
#end_block

#method_before
static String getAccountNameEmail(AccountCache accountCache, String anonymousCowardName, Account.Id accountId, String serverId) {
    AccountState accountState = accountCache.getOrNull(accountId);
    String accountName = Optional.ofNullable(accountState).map(AccountState::getAccount).map(account -> account.getName(anonymousCowardName)).orElse(anonymousCowardName);
    return formatNameEmail(accountName, getEmailForAuditLog(accountId, serverId));
}
#method_after
static String getAccountNameEmail(AccountCache accountCache, String anonymousCowardName, Account.Id accountId, String serverId) {
    String accountName = getAccountName(accountCache, anonymousCowardName, accountId);
    return formatNameEmail(accountName, getEmailForAuditLog(accountId, serverId));
}
#end_block

#method_before
private static String getEmailForAuditLog(Account.Id accountId, String serverId) {
    return accountId.get() + "@" + serverId;
}
#method_after
static String getEmailForAuditLog(Account.Id accountId, String serverId) {
    return accountId.get() + "@" + serverId;
}
#end_block

#method_before
private void commit(GroupConfig groupConfig) throws IOException {
    try (MetaDataUpdate metaDataUpdate = metaDataUpdateFactory.create(allUsersName)) {
        groupConfig.commit(metaDataUpdate);
    }
}
#method_after
private void commit(Repository allUsersRepo, GroupConfig groupConfig, @Nullable GroupNameNotes groupNameNotes) throws IOException {
    BatchRefUpdate batchRefUpdate = allUsersRepo.getRefDatabase().newBatchUpdate();
    try (MetaDataUpdate metaDataUpdate = metaDataUpdateFactory.create(allUsersName, allUsersRepo, batchRefUpdate)) {
        groupConfig.commit(metaDataUpdate);
    }
    if (groupNameNotes != null) {
        // MetaDataUpdates unfortunately can't be reused. -> Create a new one.
        try (MetaDataUpdate metaDataUpdate = metaDataUpdateFactory.create(allUsersName, allUsersRepo, batchRefUpdate)) {
            groupNameNotes.commit(metaDataUpdate);
        }
    }
    try (RevWalk revWalk = new RevWalk(allUsersRepo)) {
        RefUpdateUtil.executeChecked(batchRefUpdate, revWalk);
    }
    gitRefUpdated.fire(allUsersName, batchRefUpdate, currentUser != null ? currentUser.getAccount() : null);
}
#end_block

