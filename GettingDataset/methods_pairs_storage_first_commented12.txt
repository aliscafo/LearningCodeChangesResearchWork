697
#method_before
public LazyArg<String> findCaller() {
    return lazy(() -> {
        for (Class<?> target : targets()) {
            // Skip one additional stack frame for this method.
            Optional<String> caller = findCallerOf(target, skip() + 1);
            if (caller.isPresent()) {
                return caller.get();
            }
        }
        return "n/a";
    });
}
#method_after
public LazyArg<String> findCaller() {
    return lazy(() -> targets().stream().map(t -> findCallerOf(t, skip() + 1)).filter(Optional::isPresent).findFirst().map(Optional::get).orElse("unknown"));
}
#end_block

#method_before
@Override
protected Response<?> applyImpl(BatchUpdate.Factory updateFactory, ChangeResource rsrc, Input input) throws RestApiException, UpdateException, PermissionBackendException {
    WorkInProgressOp.checkPermissions(permissionBackend, user.get(), rsrc.getChange(), true);
    Change change = rsrc.getChange();
    if (change.getStatus() != Status.NEW) {
        throw new ResourceConflictException("change is " + ChangeUtil.status(change));
    }
    if (change.isWorkInProgress()) {
        throw new ResourceConflictException("change is already work in progress");
    }
    try (BatchUpdate bu = updateFactory.create(db.get(), rsrc.getProject(), rsrc.getUser(), TimeUtil.nowTs())) {
        bu.addOp(rsrc.getChange().getId(), opFactory.create(true, input));
        bu.execute();
        return Response.ok("");
    }
}
#method_after
@Override
protected Response<?> applyImpl(BatchUpdate.Factory updateFactory, ChangeResource rsrc, Input input) throws RestApiException, UpdateException, PermissionBackendException {
    WorkInProgressOp.checkPermissions(permissionBackend, user.get(), rsrc.getChange());
    Change change = rsrc.getChange();
    if (change.getStatus() != Status.NEW) {
        throw new ResourceConflictException("change is " + ChangeUtil.status(change));
    }
    if (change.isWorkInProgress()) {
        throw new ResourceConflictException("change is already work in progress");
    }
    try (BatchUpdate bu = updateFactory.create(db.get(), rsrc.getProject(), rsrc.getUser(), TimeUtil.nowTs())) {
        bu.addOp(rsrc.getChange().getId(), opFactory.create(true, input));
        bu.execute();
        return Response.ok("");
    }
}
#end_block

#method_before
@Override
protected Response<?> applyImpl(BatchUpdate.Factory updateFactory, ChangeResource rsrc, Input input) throws RestApiException, UpdateException, PermissionBackendException {
    WorkInProgressOp.checkPermissions(permissionBackend, user.get(), rsrc.getChange(), false);
    Change change = rsrc.getChange();
    if (change.getStatus() != Status.NEW) {
        throw new ResourceConflictException("change is " + ChangeUtil.status(change));
    }
    if (!change.isWorkInProgress()) {
        throw new ResourceConflictException("change is not work in progress");
    }
    try (BatchUpdate bu = updateFactory.create(db.get(), rsrc.getProject(), rsrc.getUser(), TimeUtil.nowTs())) {
        bu.addOp(rsrc.getChange().getId(), opFactory.create(false, input));
        bu.execute();
        return Response.ok("");
    }
}
#method_after
@Override
protected Response<?> applyImpl(BatchUpdate.Factory updateFactory, ChangeResource rsrc, Input input) throws RestApiException, UpdateException, PermissionBackendException {
    WorkInProgressOp.checkPermissions(permissionBackend, user.get(), rsrc.getChange());
    Change change = rsrc.getChange();
    if (change.getStatus() != Status.NEW) {
        throw new ResourceConflictException("change is " + ChangeUtil.status(change));
    }
    if (!change.isWorkInProgress()) {
        throw new ResourceConflictException("change is not work in progress");
    }
    try (BatchUpdate bu = updateFactory.create(db.get(), rsrc.getProject(), rsrc.getUser(), TimeUtil.nowTs())) {
        bu.addOp(rsrc.getChange().getId(), opFactory.create(false, input));
        bu.execute();
        return Response.ok("");
    }
}
#end_block

#method_before
@Test
public void setWorkInProgressNotAllowedWithoutPermission() throws Exception {
    PushOneCommit.Result rwip = createChange();
    String changeId = rwip.getChangeId();
    setApiUser(user);
    exception.expect(AuthException.class);
    exception.expectMessage("not allowed to set work in progress");
    gApi.changes().id(changeId).setWorkInProgress();
}
#method_after
@Test
public void setWorkInProgressNotAllowedWithoutPermission() throws Exception {
    PushOneCommit.Result rwip = createChange();
    String changeId = rwip.getChangeId();
    setApiUser(user);
    exception.expect(AuthException.class);
    exception.expectMessage("not allowed to toggle work in progress");
    gApi.changes().id(changeId).setWorkInProgress();
}
#end_block

#method_before
@Test
public void setReadyForReviewNotAllowedWithoutPermission() throws Exception {
    PushOneCommit.Result rready = createChange();
    String changeId = rready.getChangeId();
    gApi.changes().id(changeId).setWorkInProgress();
    setApiUser(user);
    exception.expect(AuthException.class);
    exception.expectMessage("not allowed to set ready for review");
    gApi.changes().id(changeId).setReadyForReview();
}
#method_after
@Test
public void setReadyForReviewNotAllowedWithoutPermission() throws Exception {
    PushOneCommit.Result rready = createChange();
    String changeId = rready.getChangeId();
    gApi.changes().id(changeId).setWorkInProgress();
    setApiUser(user);
    exception.expect(AuthException.class);
    exception.expectMessage("not allowed to toggle work in progress");
    gApi.changes().id(changeId).setReadyForReview();
}
#end_block

#method_before
@Test
public void reviewWithWorkInProgressByNonOwnerReturnsError() throws Exception {
    PushOneCommit.Result r = createChange();
    ReviewInput in = ReviewInput.noScore().setWorkInProgress(true);
    setApiUser(user);
    exception.expect(AuthException.class);
    exception.expectMessage("not allowed to set work in progress");
    gApi.changes().id(r.getChangeId()).current().review(in);
}
#method_after
@Test
public void reviewWithWorkInProgressByNonOwnerReturnsError() throws Exception {
    PushOneCommit.Result r = createChange();
    ReviewInput in = ReviewInput.noScore().setWorkInProgress(true);
    setApiUser(user);
    exception.expect(AuthException.class);
    exception.expectMessage("not allowed to toggle work in progress");
    gApi.changes().id(r.getChangeId()).current().review(in);
}
#end_block

#method_before
@Test
public void reviewWithReadyByNonOwnerReturnsError() throws Exception {
    PushOneCommit.Result r = createChange();
    ReviewInput in = ReviewInput.noScore().setReady(true);
    setApiUser(user);
    exception.expect(AuthException.class);
    exception.expectMessage("not allowed to set ready");
    gApi.changes().id(r.getChangeId()).current().review(in);
}
#method_after
@Test
public void reviewWithReadyByNonOwnerReturnsError() throws Exception {
    PushOneCommit.Result r = createChange();
    ReviewInput in = ReviewInput.noScore().setReady(true);
    setApiUser(user);
    exception.expect(AuthException.class);
    exception.expectMessage("not allowed to toggle work in progress");
    gApi.changes().id(r.getChangeId()).current().review(in);
}
#end_block

#method_before
public Response<ReviewResult> apply(BatchUpdate.Factory updateFactory, RevisionResource revision, ReviewInput input, Timestamp ts) throws RestApiException, UpdateException, OrmException, IOException, PermissionBackendException, ConfigInvalidException, PatchListNotAvailableException {
    // Respect timestamp, but truncate at change created-on time.
    ts = Ordering.natural().max(ts, revision.getChange().getCreatedOn());
    if (revision.getEdit().isPresent()) {
        throw new ResourceConflictException("cannot post review on edit");
    }
    ProjectState projectState = projectCache.checkedGet(revision.getProject());
    LabelTypes labelTypes = projectState.getLabelTypes(revision.getNotes());
    input.drafts = firstNonNull(input.drafts, DraftHandling.KEEP);
    if (input.onBehalfOf != null) {
        revision = onBehalfOf(revision, labelTypes, input);
    }
    if (input.labels != null) {
        checkLabels(revision, labelTypes, input.labels);
    }
    if (input.comments != null) {
        cleanUpComments(input.comments);
        checkComments(revision, input.comments);
    }
    if (input.robotComments != null) {
        if (!migration.readChanges()) {
            throw new MethodNotAllowedException("robot comments not supported");
        }
        checkRobotComments(revision, input.robotComments);
    }
    NotifyHandling reviewerNotify = input.notify;
    if (input.notify == null) {
        input.notify = defaultNotify(revision.getChange(), input);
    }
    ListMultimap<RecipientType, Account.Id> accountsToNotify = notifyUtil.resolveAccounts(input.notifyDetails);
    Map<String, AddReviewerResult> reviewerJsonResults = null;
    List<PostReviewers.Addition> reviewerResults = Lists.newArrayList();
    boolean hasError = false;
    boolean confirm = false;
    if (input.reviewers != null) {
        reviewerJsonResults = Maps.newHashMap();
        for (AddReviewerInput reviewerInput : input.reviewers) {
            // Prevent notifications because setting reviewers is batched.
            reviewerInput.notify = NotifyHandling.NONE;
            PostReviewers.Addition result = postReviewers.prepareApplication(revision.getChangeResource(), reviewerInput, true);
            reviewerJsonResults.put(reviewerInput.reviewer, result.result);
            if (result.result.error != null) {
                hasError = true;
                continue;
            }
            if (result.result.confirm != null) {
                confirm = true;
                continue;
            }
            reviewerResults.add(result);
        }
    }
    ReviewResult output = new ReviewResult();
    output.reviewers = reviewerJsonResults;
    if (hasError || confirm) {
        output.error = ERROR_ADDING_REVIEWER;
        return Response.withStatusCode(SC_BAD_REQUEST, output);
    }
    output.labels = input.labels;
    try (BatchUpdate bu = updateFactory.create(db.get(), revision.getChange().getProject(), revision.getUser(), ts)) {
        Account.Id id = revision.getUser().getAccountId();
        boolean ccOrReviewer = false;
        if (input.labels != null && !input.labels.isEmpty()) {
            ccOrReviewer = input.labels.values().stream().filter(v -> v != 0).findFirst().isPresent();
        }
        if (!ccOrReviewer) {
            // Check if user was already CCed or reviewing prior to this review.
            ReviewerSet currentReviewers = approvalsUtil.getReviewers(db.get(), revision.getChangeResource().getNotes());
            ccOrReviewer = currentReviewers.all().contains(id);
        }
        // themselves as a reviewer or to the CC list.
        for (PostReviewers.Addition reviewerResult : reviewerResults) {
            bu.addOp(revision.getChange().getId(), reviewerResult.op);
            if (!ccOrReviewer && reviewerResult.result.reviewers != null) {
                for (ReviewerInfo reviewerInfo : reviewerResult.result.reviewers) {
                    if (Objects.equals(id.get(), reviewerInfo._accountId)) {
                        ccOrReviewer = true;
                        break;
                    }
                }
            }
            if (!ccOrReviewer && reviewerResult.result.ccs != null) {
                for (AccountInfo accountInfo : reviewerResult.result.ccs) {
                    if (Objects.equals(id.get(), accountInfo._accountId)) {
                        ccOrReviewer = true;
                        break;
                    }
                }
            }
        }
        if (!ccOrReviewer) {
            // User posting this review isn't currently in the reviewer or CC list,
            // isn't being explicitly added, and isn't voting on any label.
            // Automatically CC them on this change so they receive replies.
            PostReviewers.Addition selfAddition = postReviewers.ccCurrentUser(revision.getUser(), revision);
            bu.addOp(revision.getChange().getId(), selfAddition.op);
        }
        // Add WorkInProgressOp if requested.
        if (input.ready || input.workInProgress) {
            if (input.ready && input.workInProgress) {
                output.error = ERROR_WIP_READY_MUTUALLY_EXCLUSIVE;
                return Response.withStatusCode(SC_BAD_REQUEST, output);
            }
            WorkInProgressOp.checkPermissions(permissionBackend, revision.getUser(), revision.getChange(), input.workInProgress);
            if (input.ready) {
                output.ready = true;
            }
            // Suppress notifications in WorkInProgressOp, we'll take care of
            // them in this endpoint.
            WorkInProgressOp.Input wipIn = new WorkInProgressOp.Input();
            wipIn.notify = NotifyHandling.NONE;
            bu.addOp(revision.getChange().getId(), workInProgressOpFactory.create(input.workInProgress, wipIn));
        }
        // Add the review op.
        bu.addOp(revision.getChange().getId(), new Op(projectState, revision.getPatchSet().getId(), input, accountsToNotify));
        bu.execute();
        for (PostReviewers.Addition reviewerResult : reviewerResults) {
            reviewerResult.gatherResults();
        }
        boolean readyForReview = (output.ready != null && output.ready) || !revision.getChange().isWorkInProgress();
        emailReviewers(revision.getChange(), reviewerResults, reviewerNotify, accountsToNotify, readyForReview);
    }
    return Response.ok(output);
}
#method_after
public Response<ReviewResult> apply(BatchUpdate.Factory updateFactory, RevisionResource revision, ReviewInput input, Timestamp ts) throws RestApiException, UpdateException, OrmException, IOException, PermissionBackendException, ConfigInvalidException, PatchListNotAvailableException {
    // Respect timestamp, but truncate at change created-on time.
    ts = Ordering.natural().max(ts, revision.getChange().getCreatedOn());
    if (revision.getEdit().isPresent()) {
        throw new ResourceConflictException("cannot post review on edit");
    }
    ProjectState projectState = projectCache.checkedGet(revision.getProject());
    LabelTypes labelTypes = projectState.getLabelTypes(revision.getNotes());
    input.drafts = firstNonNull(input.drafts, DraftHandling.KEEP);
    if (input.onBehalfOf != null) {
        revision = onBehalfOf(revision, labelTypes, input);
    }
    if (input.labels != null) {
        checkLabels(revision, labelTypes, input.labels);
    }
    if (input.comments != null) {
        cleanUpComments(input.comments);
        checkComments(revision, input.comments);
    }
    if (input.robotComments != null) {
        if (!migration.readChanges()) {
            throw new MethodNotAllowedException("robot comments not supported");
        }
        checkRobotComments(revision, input.robotComments);
    }
    NotifyHandling reviewerNotify = input.notify;
    if (input.notify == null) {
        input.notify = defaultNotify(revision.getChange(), input);
    }
    ListMultimap<RecipientType, Account.Id> accountsToNotify = notifyUtil.resolveAccounts(input.notifyDetails);
    Map<String, AddReviewerResult> reviewerJsonResults = null;
    List<PostReviewers.Addition> reviewerResults = Lists.newArrayList();
    boolean hasError = false;
    boolean confirm = false;
    if (input.reviewers != null) {
        reviewerJsonResults = Maps.newHashMap();
        for (AddReviewerInput reviewerInput : input.reviewers) {
            // Prevent notifications because setting reviewers is batched.
            reviewerInput.notify = NotifyHandling.NONE;
            PostReviewers.Addition result = postReviewers.prepareApplication(revision.getChangeResource(), reviewerInput, true);
            reviewerJsonResults.put(reviewerInput.reviewer, result.result);
            if (result.result.error != null) {
                hasError = true;
                continue;
            }
            if (result.result.confirm != null) {
                confirm = true;
                continue;
            }
            reviewerResults.add(result);
        }
    }
    ReviewResult output = new ReviewResult();
    output.reviewers = reviewerJsonResults;
    if (hasError || confirm) {
        output.error = ERROR_ADDING_REVIEWER;
        return Response.withStatusCode(SC_BAD_REQUEST, output);
    }
    output.labels = input.labels;
    try (BatchUpdate bu = updateFactory.create(db.get(), revision.getChange().getProject(), revision.getUser(), ts)) {
        Account.Id id = revision.getUser().getAccountId();
        boolean ccOrReviewer = false;
        if (input.labels != null && !input.labels.isEmpty()) {
            ccOrReviewer = input.labels.values().stream().filter(v -> v != 0).findFirst().isPresent();
        }
        if (!ccOrReviewer) {
            // Check if user was already CCed or reviewing prior to this review.
            ReviewerSet currentReviewers = approvalsUtil.getReviewers(db.get(), revision.getChangeResource().getNotes());
            ccOrReviewer = currentReviewers.all().contains(id);
        }
        // themselves as a reviewer or to the CC list.
        for (PostReviewers.Addition reviewerResult : reviewerResults) {
            bu.addOp(revision.getChange().getId(), reviewerResult.op);
            if (!ccOrReviewer && reviewerResult.result.reviewers != null) {
                for (ReviewerInfo reviewerInfo : reviewerResult.result.reviewers) {
                    if (Objects.equals(id.get(), reviewerInfo._accountId)) {
                        ccOrReviewer = true;
                        break;
                    }
                }
            }
            if (!ccOrReviewer && reviewerResult.result.ccs != null) {
                for (AccountInfo accountInfo : reviewerResult.result.ccs) {
                    if (Objects.equals(id.get(), accountInfo._accountId)) {
                        ccOrReviewer = true;
                        break;
                    }
                }
            }
        }
        if (!ccOrReviewer) {
            // User posting this review isn't currently in the reviewer or CC list,
            // isn't being explicitly added, and isn't voting on any label.
            // Automatically CC them on this change so they receive replies.
            PostReviewers.Addition selfAddition = postReviewers.ccCurrentUser(revision.getUser(), revision);
            bu.addOp(revision.getChange().getId(), selfAddition.op);
        }
        // Add WorkInProgressOp if requested.
        if (input.ready || input.workInProgress) {
            if (input.ready && input.workInProgress) {
                output.error = ERROR_WIP_READY_MUTUALLY_EXCLUSIVE;
                return Response.withStatusCode(SC_BAD_REQUEST, output);
            }
            WorkInProgressOp.checkPermissions(permissionBackend, revision.getUser(), revision.getChange());
            if (input.ready) {
                output.ready = true;
            }
            // Suppress notifications in WorkInProgressOp, we'll take care of
            // them in this endpoint.
            WorkInProgressOp.Input wipIn = new WorkInProgressOp.Input();
            wipIn.notify = NotifyHandling.NONE;
            bu.addOp(revision.getChange().getId(), workInProgressOpFactory.create(input.workInProgress, wipIn));
        }
        // Add the review op.
        bu.addOp(revision.getChange().getId(), new Op(projectState, revision.getPatchSet().getId(), input, accountsToNotify));
        bu.execute();
        for (PostReviewers.Addition reviewerResult : reviewerResults) {
            reviewerResult.gatherResults();
        }
        boolean readyForReview = (output.ready != null && output.ready) || !revision.getChange().isWorkInProgress();
        emailReviewers(revision.getChange(), reviewerResults, reviewerNotify, accountsToNotify, readyForReview);
    }
    return Response.ok(output);
}
#end_block

#method_before
public static void checkPermissions(PermissionBackend permissionBackend, CurrentUser user, Change change, boolean workInProgress) throws PermissionBackendException, AuthException {
    if (!user.isIdentifiedUser()) {
        throw new AuthException("Authentication required");
    }
    if (change.getOwner().equals(user.asIdentifiedUser().getAccountId())) {
        return;
    }
    boolean hasAdministrateServerPermission = false;
    try {
        permissionBackend.currentUser().check(GlobalPermission.ADMINISTRATE_SERVER);
        hasAdministrateServerPermission = true;
    } catch (AuthException e) {
    // Skip.
    }
    if (!hasAdministrateServerPermission) {
        try {
            permissionBackend.user(user).project(change.getProject()).check(ProjectPermission.WRITE_CONFIG);
        } catch (AuthException exp) {
            if (workInProgress) {
                throw new AuthException("not allowed to set work in progress");
            }
            throw new AuthException("not allowed to set ready for review");
        }
    }
}
#method_after
public static void checkPermissions(PermissionBackend permissionBackend, CurrentUser user, Change change) throws PermissionBackendException, AuthException {
    if (!user.isIdentifiedUser()) {
        throw new AuthException("Authentication required");
    }
    if (change.getOwner().equals(user.asIdentifiedUser().getAccountId())) {
        return;
    }
    try {
        permissionBackend.currentUser().check(GlobalPermission.ADMINISTRATE_SERVER);
        return;
    } catch (AuthException e) {
    // Skip.
    }
    try {
        permissionBackend.user(user).project(change.getProject()).check(ProjectPermission.WRITE_CONFIG);
    } catch (AuthException exp) {
        throw new AuthException("not allowed to toggle work in progress");
    }
}
#end_block

#method_before
private String problemsForSubmittingChangeset(ChangeData cd, ChangeSet cs, CurrentUser user) {
    try {
        if (cs.furtherHiddenChanges()) {
            logger.atFine().log("Change %d cannot be submitted by user %s because it depends on hidden change: %s", cd.getId().get(), user.getLoggableName(), cs.nonVisibleChanges());
            return BLOCKED_HIDDEN_SUBMIT_TOOLTIP;
        }
        for (ChangeData c : cs.changes()) {
            if (cd.getId().equals(c.getId())) {
                // #apply and #getDescription methods.
                continue;
            }
            Set<ChangePermission> can = permissionBackend.user(user).database(dbProvider).change(c).test(EnumSet.of(ChangePermission.READ, ChangePermission.SUBMIT));
            if (!can.contains(ChangePermission.READ)) {
                logger.atFine().log("Change %d cannot be submitted by user %s because it depends on change %d which the user cannot read", cd.getId().get(), user.getLoggableName(), c.getId().get());
                return BLOCKED_HIDDEN_SUBMIT_TOOLTIP;
            }
            if (!can.contains(ChangePermission.SUBMIT)) {
                return "You don't have permission to submit change " + c.getId();
            }
            if (c.change().isWorkInProgress()) {
                return "Change " + c.getId() + " is marked work in progress";
            }
            try {
                MergeOp.checkSubmitRule(c, false);
            } catch (ResourceConflictException e) {
                return "Change " + c.getId() + " is not ready: " + e.getMessage();
            }
        }
        Collection<ChangeData> unmergeable = unmergeableChanges(cs);
        if (unmergeable == null) {
            return CLICK_FAILURE_TOOLTIP;
        } else if (!unmergeable.isEmpty()) {
            for (ChangeData c : unmergeable) {
                if (c.change().getKey().equals(cd.change().getKey())) {
                    return CHANGE_UNMERGEABLE;
                }
            }
            return "Problems with change(s): " + unmergeable.stream().map(c -> c.getId().toString()).collect(joining(", "));
        }
    } catch (PermissionBackendException | OrmException | IOException e) {
        logger.atSevere().withCause(e).log("Error checking if change is submittable");
        throw new OrmRuntimeException("Could not determine problems for the change", e);
    }
    return null;
}
#method_after
private String problemsForSubmittingChangeset(ChangeData cd, ChangeSet cs, CurrentUser user) {
    try {
        if (cs.furtherHiddenChanges()) {
            logger.atFine().log("Change %d cannot be submitted by user %s because it depends on hidden changes: %s", cd.getId().get(), user.getLoggableName(), cs.nonVisibleChanges());
            return BLOCKED_HIDDEN_SUBMIT_TOOLTIP;
        }
        for (ChangeData c : cs.changes()) {
            if (cd.getId().equals(c.getId())) {
                // #apply and #getDescription methods.
                continue;
            }
            Set<ChangePermission> can = permissionBackend.user(user).database(dbProvider).change(c).test(EnumSet.of(ChangePermission.READ, ChangePermission.SUBMIT));
            if (!can.contains(ChangePermission.READ)) {
                logger.atFine().log("Change %d cannot be submitted by user %s because it depends on change %d which the user cannot read", cd.getId().get(), user.getLoggableName(), c.getId().get());
                return BLOCKED_HIDDEN_SUBMIT_TOOLTIP;
            }
            if (!can.contains(ChangePermission.SUBMIT)) {
                return "You don't have permission to submit change " + c.getId();
            }
            if (c.change().isWorkInProgress()) {
                return "Change " + c.getId() + " is marked work in progress";
            }
            try {
                MergeOp.checkSubmitRule(c, false);
            } catch (ResourceConflictException e) {
                return "Change " + c.getId() + " is not ready: " + e.getMessage();
            }
        }
        Collection<ChangeData> unmergeable = unmergeableChanges(cs);
        if (unmergeable == null) {
            return CLICK_FAILURE_TOOLTIP;
        } else if (!unmergeable.isEmpty()) {
            for (ChangeData c : unmergeable) {
                if (c.change().getKey().equals(cd.change().getKey())) {
                    return CHANGE_UNMERGEABLE;
                }
            }
            return "Problems with change(s): " + unmergeable.stream().map(c -> c.getId().toString()).collect(joining(", "));
        }
    } catch (PermissionBackendException | OrmException | IOException e) {
        logger.atSevere().withCause(e).log("Error checking if change is submittable");
        throw new OrmRuntimeException("Could not determine problems for the change", e);
    }
    return null;
}
#end_block

#method_before
private Account.Id createAccountByLdapAndAddSshKeys(GerritApi api, AccountInfo acc) throws NoSuchAccountException, IOException, OrmException, RestApiException, ConfigInvalidException {
    if (!ExternalId.isValidUsername(acc.username)) {
        throw new NoSuchAccountException(String.format("User %s not found", acc.username));
    }
    try {
        AuthRequest req = AuthRequest.forUser(acc.username);
        req.setSkipAuthentication(true);
        Account.Id id = accountManager.authenticate(req).getAccountId();
        addSshKeys(api, acc);
        return id;
    } catch (AccountException e) {
        return createLocalUser(acc);
    }
}
#method_after
private Account.Id createAccountByLdapAndAddSshKeys(GerritApi api, AccountInfo acc) throws NoSuchAccountException, IOException, OrmException, RestApiException, ConfigInvalidException {
    if (!acc.username.matches(Account.USER_NAME_PATTERN)) {
        throw new NoSuchAccountException(String.format("User %s not found", acc.username));
    }
    try {
        AuthRequest req = AuthRequest.forUser(acc.username);
        req.setSkipAuthentication(true);
        Account.Id id = accountManager.authenticate(req).getAccountId();
        addSshKeys(api, acc);
        return id;
    } catch (AccountException e) {
        return createLocalUser(acc);
    }
}
#end_block

#method_before
public String getChangeUrl() {
    return args.browseUrls.reviewUrl(change.getProject(), change.getId(), null, null);
}
#method_after
@Nullable
public String getChangeUrl() {
    return args.urlFormatter.getChangeViewUrl(change.getProject(), change.getId()).orElse(null);
}
#end_block

#method_before
private String readAbandonMessage(Config cfg, String webUrl) {
    String abandonMessage = cfg.getString(SECTION, null, KEY_ABANDON_MESSAGE);
    if (Strings.isNullOrEmpty(abandonMessage)) {
        abandonMessage = DEFAULT_ABANDON_MESSAGE;
    }
    if (!Strings.isNullOrEmpty(webUrl)) {
        abandonMessage = abandonMessage.replaceAll("\\$\\{URL\\}", webUrl);
    }
    return abandonMessage;
}
#method_after
private String readAbandonMessage(Config cfg, UrlFormatter urlFormatter) {
    String abandonMessage = cfg.getString(SECTION, null, KEY_ABANDON_MESSAGE);
    if (Strings.isNullOrEmpty(abandonMessage)) {
        abandonMessage = DEFAULT_ABANDON_MESSAGE;
    }
    String docUrl = urlFormatter.getDocUrl("user-change-cleanup.html", "auto-abandon").orElse("");
    if (!docUrl.isEmpty()) {
        abandonMessage = abandonMessage.replaceAll("\\$\\{URL\\}", docUrl);
    }
    return abandonMessage;
}
#end_block

#method_before
@Override
protected void configure() {
    // Note that the CanonicalWebUrl itself must not be a singleton, but its
    // provider must be.
    // 
    // If the value was not configured in the system configuration data the
    // provider may try to guess it from the current HTTP request, if we are
    // running in an HTTP environment.
    // 
    final Class<? extends Provider<String>> provider = provider();
    bind(String.class).annotatedWith(CanonicalWebUrl.class).toProvider(provider);
    bind(BrowseUrls.class).to(DefaultBrowseUrls.class);
}
#method_after
@Override
protected void configure() {
    // Note that the CanonicalWebUrl itself must not be a singleton, but its
    // provider must be.
    // 
    // If the value was not configured in the system configuration data the
    // provider may try to guess it from the current HTTP request, if we are
    // running in an HTTP environment.
    // 
    final Class<? extends Provider<String>> provider = provider();
    bind(String.class).annotatedWith(CanonicalWebUrl.class).toProvider(provider);
    bind(UrlFormatter.class).to(DefaultBrowseUrls.class);
}
#end_block

#method_before
private String createDetailedCommitMessage(RevCommit n, ChangeNotes notes, PatchSet.Id psId) {
    Change c = notes.getChange();
    final List<FooterLine> footers = n.getFooterLines();
    final StringBuilder msgbuf = new StringBuilder();
    msgbuf.append(n.getFullMessage());
    if (msgbuf.length() == 0) {
        // WTF, an empty commit message?
        msgbuf.append("<no commit message provided>");
    }
    if (msgbuf.charAt(msgbuf.length() - 1) != '\n') {
        // Missing a trailing LF? Correct it (perhaps the editor was broken).
        msgbuf.append('\n');
    }
    if (footers.isEmpty()) {
        // Doesn't end in a "Signed-off-by: ..." style line? Add another line
        // break to start a new paragraph for the reviewed-by tag lines.
        // 
        msgbuf.append('\n');
    }
    if (!contains(footers, FooterConstants.CHANGE_ID, c.getKey().get())) {
        msgbuf.append(FooterConstants.CHANGE_ID.getName());
        msgbuf.append(": ");
        msgbuf.append(c.getKey().get());
        msgbuf.append('\n');
    }
    String url = browseUrls.reviewUrl(null, c.getId(), null, null);
    if (!contains(footers, FooterConstants.REVIEWED_ON, url)) {
        msgbuf.append(FooterConstants.REVIEWED_ON.getName());
        msgbuf.append(": ");
        msgbuf.append(url);
        msgbuf.append('\n');
    }
    PatchSetApproval submitAudit = null;
    for (PatchSetApproval a : safeGetApprovals(notes, psId)) {
        if (a.getValue() <= 0) {
            // Negative votes aren't counted.
            continue;
        }
        if (a.isLegacySubmit()) {
            // 
            if (submitAudit == null || a.getGranted().compareTo(submitAudit.getGranted()) > 0) {
                submitAudit = a;
            }
            continue;
        }
        final Account acc = identifiedUserFactory.create(a.getAccountId()).getAccount();
        final StringBuilder identbuf = new StringBuilder();
        if (acc.getFullName() != null && acc.getFullName().length() > 0) {
            if (identbuf.length() > 0) {
                identbuf.append(' ');
            }
            identbuf.append(acc.getFullName());
        }
        if (acc.getPreferredEmail() != null && acc.getPreferredEmail().length() > 0) {
            if (isSignedOffBy(footers, acc.getPreferredEmail())) {
                continue;
            }
            if (identbuf.length() > 0) {
                identbuf.append(' ');
            }
            identbuf.append('<');
            identbuf.append(acc.getPreferredEmail());
            identbuf.append('>');
        }
        if (identbuf.length() == 0) {
            // Nothing reasonable to describe them by? Ignore them.
            continue;
        }
        final String tag;
        if (isCodeReview(a.getLabelId())) {
            tag = "Reviewed-by";
        } else if (isVerified(a.getLabelId())) {
            tag = "Tested-by";
        } else {
            final LabelType lt = project.getLabelTypes().byLabel(a.getLabelId());
            if (lt == null) {
                continue;
            }
            tag = lt.getName();
        }
        if (!contains(footers, new FooterKey(tag), identbuf.toString())) {
            msgbuf.append(tag);
            msgbuf.append(": ");
            msgbuf.append(identbuf);
            msgbuf.append('\n');
        }
    }
    return msgbuf.toString();
}
#method_after
private String createDetailedCommitMessage(RevCommit n, ChangeNotes notes, PatchSet.Id psId) {
    Change c = notes.getChange();
    final List<FooterLine> footers = n.getFooterLines();
    final StringBuilder msgbuf = new StringBuilder();
    msgbuf.append(n.getFullMessage());
    if (msgbuf.length() == 0) {
        // WTF, an empty commit message?
        msgbuf.append("<no commit message provided>");
    }
    if (msgbuf.charAt(msgbuf.length() - 1) != '\n') {
        // Missing a trailing LF? Correct it (perhaps the editor was broken).
        msgbuf.append('\n');
    }
    if (footers.isEmpty()) {
        // Doesn't end in a "Signed-off-by: ..." style line? Add another line
        // break to start a new paragraph for the reviewed-by tag lines.
        // 
        msgbuf.append('\n');
    }
    if (!contains(footers, FooterConstants.CHANGE_ID, c.getKey().get())) {
        msgbuf.append(FooterConstants.CHANGE_ID.getName());
        msgbuf.append(": ");
        msgbuf.append(c.getKey().get());
        msgbuf.append('\n');
    }
    Optional<String> url = urlFormatter.getChangeViewUrl(null, c.getId());
    if (url.isPresent()) {
        if (!contains(footers, FooterConstants.REVIEWED_ON, url.get())) {
            msgbuf.append(FooterConstants.REVIEWED_ON.getName()).append(": ").append(url.get()).append('\n');
        }
    }
    PatchSetApproval submitAudit = null;
    for (PatchSetApproval a : safeGetApprovals(notes, psId)) {
        if (a.getValue() <= 0) {
            // Negative votes aren't counted.
            continue;
        }
        if (a.isLegacySubmit()) {
            // 
            if (submitAudit == null || a.getGranted().compareTo(submitAudit.getGranted()) > 0) {
                submitAudit = a;
            }
            continue;
        }
        final Account acc = identifiedUserFactory.create(a.getAccountId()).getAccount();
        final StringBuilder identbuf = new StringBuilder();
        if (acc.getFullName() != null && acc.getFullName().length() > 0) {
            if (identbuf.length() > 0) {
                identbuf.append(' ');
            }
            identbuf.append(acc.getFullName());
        }
        if (acc.getPreferredEmail() != null && acc.getPreferredEmail().length() > 0) {
            if (isSignedOffBy(footers, acc.getPreferredEmail())) {
                continue;
            }
            if (identbuf.length() > 0) {
                identbuf.append(' ');
            }
            identbuf.append('<');
            identbuf.append(acc.getPreferredEmail());
            identbuf.append('>');
        }
        if (identbuf.length() == 0) {
            // Nothing reasonable to describe them by? Ignore them.
            continue;
        }
        final String tag;
        if (isCodeReview(a.getLabelId())) {
            tag = "Reviewed-by";
        } else if (isVerified(a.getLabelId())) {
            tag = "Tested-by";
        } else {
            final LabelType lt = project.getLabelTypes().byLabel(a.getLabelId());
            if (lt == null) {
                continue;
            }
            tag = lt.getName();
        }
        if (!contains(footers, new FooterKey(tag), identbuf.toString())) {
            msgbuf.append(tag);
            msgbuf.append(": ");
            msgbuf.append(identbuf);
            msgbuf.append('\n');
        }
    }
    return msgbuf.toString();
}
#end_block

#method_before
@Before
public void setUpTestEnvironment() throws Exception {
    setTimeForTesting();
    serverIdent = new PersonIdent("Gerrit Server", "noreply@gerrit.com", TimeUtil.nowTs(), TZ);
    project = new Project.NameKey("test-project");
    repoManager = new InMemoryRepositoryManager();
    repo = repoManager.createRepository(project);
    tr = new TestRepository<>(repo);
    rw = tr.getRevWalk();
    accountCache = new FakeAccountCache();
    Account co = new Account(new Account.Id(1), TimeUtil.nowTs());
    co.setFullName("Change Owner");
    co.setPreferredEmail("change@owner.com");
    accountCache.put(co);
    Account ou = new Account(new Account.Id(2), TimeUtil.nowTs());
    ou.setFullName("Other Account");
    ou.setPreferredEmail("other@account.com");
    accountCache.put(ou);
    injector = Guice.createInjector(new FactoryModule() {

        @Override
        public void configure() {
            install(new GitModule());
            install(NoteDbModule.forTest(testConfig));
            bind(AllUsersName.class).toProvider(AllUsersNameProvider.class);
            bind(String.class).annotatedWith(GerritServerId.class).toInstance("gerrit");
            bind(GitRepositoryManager.class).toInstance(repoManager);
            bind(ProjectCache.class).toProvider(Providers.<ProjectCache>of(null));
            bind(Config.class).annotatedWith(GerritServerConfig.class).toInstance(testConfig);
            bind(String.class).annotatedWith(AnonymousCowardName.class).toProvider(AnonymousCowardNameProvider.class);
            bind(String.class).annotatedWith(CanonicalWebUrl.class).toInstance("http://localhost:8080/");
            bind(Boolean.class).annotatedWith(DisableReverseDnsLookup.class).toInstance(Boolean.FALSE);
            bind(Realm.class).to(FakeRealm.class);
            bind(GroupBackend.class).to(SystemGroupBackend.class).in(SINGLETON);
            bind(AccountCache.class).toInstance(accountCache);
            bind(PersonIdent.class).annotatedWith(GerritPersonIdent.class).toInstance(serverIdent);
            bind(GitReferenceUpdated.class).toInstance(GitReferenceUpdated.DISABLED);
            bind(MetricMaker.class).to(DisabledMetricMaker.class);
            bind(ReviewDb.class).toProvider(Providers.<ReviewDb>of(null));
            MutableNotesMigration migration = MutableNotesMigration.newDisabled();
            migration.setFrom(NotesMigrationState.FINAL);
            bind(MutableNotesMigration.class).toInstance(migration);
            bind(NotesMigration.class).to(MutableNotesMigration.class);
            bind(BrowseUrls.class).to(DefaultBrowseUrls.class);
            // Tests don't support ReviewDb at all, but bindings are required via NoteDbModule.
            bind(new TypeLiteral<SchemaFactory<ReviewDb>>() {
            }).toInstance(() -> {
                throw new UnsupportedOperationException();
            });
            bind(ChangeBundleReader.class).toInstance((db, id) -> {
                throw new UnsupportedOperationException();
            });
        }
    });
    injector.injectMembers(this);
    repoManager.createRepository(allUsers);
    changeOwner = userFactory.create(co.getId());
    otherUser = userFactory.create(ou.getId());
    otherUserId = otherUser.getAccountId();
    internalUser = new InternalUser();
}
#method_after
@Before
public void setUpTestEnvironment() throws Exception {
    setTimeForTesting();
    serverIdent = new PersonIdent("Gerrit Server", "noreply@gerrit.com", TimeUtil.nowTs(), TZ);
    project = new Project.NameKey("test-project");
    repoManager = new InMemoryRepositoryManager();
    repo = repoManager.createRepository(project);
    tr = new TestRepository<>(repo);
    rw = tr.getRevWalk();
    accountCache = new FakeAccountCache();
    Account co = new Account(new Account.Id(1), TimeUtil.nowTs());
    co.setFullName("Change Owner");
    co.setPreferredEmail("change@owner.com");
    accountCache.put(co);
    Account ou = new Account(new Account.Id(2), TimeUtil.nowTs());
    ou.setFullName("Other Account");
    ou.setPreferredEmail("other@account.com");
    accountCache.put(ou);
    injector = Guice.createInjector(new FactoryModule() {

        @Override
        public void configure() {
            install(new GitModule());
            install(NoteDbModule.forTest(testConfig));
            bind(AllUsersName.class).toProvider(AllUsersNameProvider.class);
            bind(String.class).annotatedWith(GerritServerId.class).toInstance("gerrit");
            bind(GitRepositoryManager.class).toInstance(repoManager);
            bind(ProjectCache.class).toProvider(Providers.<ProjectCache>of(null));
            bind(Config.class).annotatedWith(GerritServerConfig.class).toInstance(testConfig);
            bind(String.class).annotatedWith(AnonymousCowardName.class).toProvider(AnonymousCowardNameProvider.class);
            bind(String.class).annotatedWith(CanonicalWebUrl.class).toInstance("http://localhost:8080/");
            bind(Boolean.class).annotatedWith(DisableReverseDnsLookup.class).toInstance(Boolean.FALSE);
            bind(Realm.class).to(FakeRealm.class);
            bind(GroupBackend.class).to(SystemGroupBackend.class).in(SINGLETON);
            bind(AccountCache.class).toInstance(accountCache);
            bind(PersonIdent.class).annotatedWith(GerritPersonIdent.class).toInstance(serverIdent);
            bind(GitReferenceUpdated.class).toInstance(GitReferenceUpdated.DISABLED);
            bind(MetricMaker.class).to(DisabledMetricMaker.class);
            bind(ReviewDb.class).toProvider(Providers.<ReviewDb>of(null));
            MutableNotesMigration migration = MutableNotesMigration.newDisabled();
            migration.setFrom(NotesMigrationState.FINAL);
            bind(MutableNotesMigration.class).toInstance(migration);
            bind(NotesMigration.class).to(MutableNotesMigration.class);
            bind(UrlFormatter.class).to(DefaultBrowseUrls.class);
            // Tests don't support ReviewDb at all, but bindings are required via NoteDbModule.
            bind(new TypeLiteral<SchemaFactory<ReviewDb>>() {
            }).toInstance(() -> {
                throw new UnsupportedOperationException();
            });
            bind(ChangeBundleReader.class).toInstance((db, id) -> {
                throw new UnsupportedOperationException();
            });
        }
    });
    injector.injectMembers(this);
    repoManager.createRepository(allUsers);
    changeOwner = userFactory.create(co.getId());
    otherUser = userFactory.create(ou.getId());
    otherUserId = otherUser.getAccountId();
    internalUser = new InternalUser();
}
#end_block

#method_before
@Override
public String changeClosed(ChangeReportFormatter.Input input) {
    Change c = input.change();
    return String.format("change %s closed", browseUrls.reviewUrl(c.getProject(), c.getId(), null, null));
}
#method_after
@Override
public String changeClosed(ChangeReportFormatter.Input input) {
    Change c = input.change();
    return String.format("change %s closed", urlFormatter.getChangeViewUrl(c.getProject(), c.getId()).orElse(c.getId().toString()));
}
#end_block

#method_before
protected String formatChangeUrl(Input input) {
    Change c = input.change();
    StringBuilder m = new StringBuilder().append("  ").append(browseUrls.reviewUrl(c.getProject(), c.getId(), null, null)).append(" ").append(cropSubject(input.subject()));
    if (input.isEdit()) {
        m.append(" [EDIT]");
    }
    if (input.isPrivate()) {
        m.append(" [PRIVATE]");
    }
    if (input.isWorkInProgress()) {
        m.append(" [WIP]");
    }
    return m.toString();
}
#method_after
protected String formatChangeUrl(Input input) {
    Change c = input.change();
    Optional<String> changeUrl = urlFormatter.getChangeViewUrl(c.getProject(), c.getId());
    Preconditions.checkState(changeUrl.isPresent());
    StringBuilder m = new StringBuilder().append("  ").append(changeUrl.get()).append(" ").append(cropSubject(input.subject()));
    if (input.isEdit()) {
        m.append(" [EDIT]");
    }
    if (input.isPrivate()) {
        m.append(" [PRIVATE]");
    }
    if (input.isWorkInProgress()) {
        m.append(" [WIP]");
    }
    return m.toString();
}
#end_block

#method_before
public String getGerritUrl() {
    return args.browseUrls.webUrl();
}
#method_after
public String getGerritUrl() {
    return args.urlFormatter.getWebUrl().orElse(null);
}
#end_block

#method_before
@Override
public synchronized long tryDeleteDocument(IndexReader readerIn, int docID) throws IOException {
    long ret = super.tryDeleteDocument(readerIn, docID);
    if (ret > 0) {
        autoFlush();
    }
    return ret;
}
#method_after
@Override
public synchronized long tryDeleteDocument(IndexReader readerIn, int docID) throws IOException {
    long ret = super.tryDeleteDocument(readerIn, docID);
    if (ret != -1) {
        autoFlush();
    }
    return ret;
}
#end_block

#method_before
static Term intTerm(String name, int value) {
    return new Term(name, new IntPoint(name, value).binaryValue());
}
#method_after
static Term intTerm(String name, int value) {
    BytesRefBuilder builder = new BytesRefBuilder();
    LegacyNumericUtils.intToPrefixCoded(value, 0, builder);
    return new Term(name, builder.get());
}
#end_block

#method_before
private Query fieldQuery(IndexPredicate<V> p) throws QueryParseException {
    checkArgument(schema.hasField(p.getField()), "field not in schema v%s: %s", schema.getVersion(), p.getField().getName());
    if (p.getType() == FieldType.INTEGER) {
        return intQuery(p);
    } else if (p.getType() == FieldType.INTEGER_RANGE) {
        return intRangeQuery(p);
    } else if (p.getType() == FieldType.TIMESTAMP) {
        return timestampQuery(p);
    } else if (p.getType() == FieldType.EXACT) {
        return exactQuery(p);
    } else if (p.getType() == FieldType.PREFIX) {
        return prefixQuery(p);
    } else if (p.getType() == FieldType.FULL_TEXT) {
        return fullTextQuery(p);
    } else {
        throw FieldType.badFieldType(p.getType());
    }
}
#method_after
private Query fieldQuery(IndexPredicate<V> p) throws QueryParseException {
    checkArgument(schema.hasField(p.getField()), "field not in schema v%s: %s", schema.getVersion(), p.getField().getName());
    FieldType<?> type = p.getType();
    if (type == FieldType.INTEGER) {
        return intQuery(p);
    } else if (type == FieldType.INTEGER_RANGE) {
        return intRangeQuery(p);
    } else if (type == FieldType.TIMESTAMP) {
        return timestampQuery(p);
    } else if (type == FieldType.EXACT) {
        return exactQuery(p);
    } else if (type == FieldType.PREFIX) {
        return prefixQuery(p);
    } else if (type == FieldType.FULL_TEXT) {
        return fullTextQuery(p);
    } else {
        throw FieldType.badFieldType(type);
    }
}
#end_block

#method_before
private Query intQuery(IndexPredicate<V> p) throws QueryParseException {
    int value;
    try {
        // Can't use IntPredicate because it and IndexPredicate are different
        // subclasses of OperatorPredicate.
        value = Integer.parseInt(p.getValue());
    } catch (NumberFormatException e) {
        throw new QueryParseException("not an integer: " + p.getValue());
    }
    return intPoint(p.getField().getName(), value);
}
#method_after
private Query intQuery(IndexPredicate<V> p) throws QueryParseException {
    int value;
    try {
        // Can't use IntPredicate because it and IndexPredicate are different
        // subclasses of OperatorPredicate.
        value = Integer.parseInt(p.getValue());
    } catch (NumberFormatException e) {
        throw new QueryParseException("not an integer: " + p.getValue());
    }
    return new TermQuery(intTerm(p.getField().getName(), value));
}
#end_block

#method_before
private Query intRangeQuery(IndexPredicate<V> p) throws QueryParseException {
    if (p instanceof IntegerRangePredicate) {
        IntegerRangePredicate<V> r = (IntegerRangePredicate<V>) p;
        int minimum = r.getMinimumValue();
        int maximum = r.getMaximumValue();
        if (minimum == maximum) {
            // Just fall back to a standard integer query.
            return intPoint(p.getField().getName(), minimum);
        }
        return IntPoint.newRangeQuery(r.getField().getName(), minimum, maximum);
    }
    throw new QueryParseException("not an integer range: " + p);
}
#method_after
private Query intRangeQuery(IndexPredicate<V> p) throws QueryParseException {
    if (p instanceof IntegerRangePredicate) {
        IntegerRangePredicate<V> r = (IntegerRangePredicate<V>) p;
        int minimum = r.getMinimumValue();
        int maximum = r.getMaximumValue();
        if (minimum == maximum) {
            // Just fall back to a standard integer query.
            return new TermQuery(intTerm(p.getField().getName(), minimum));
        }
        return LegacyNumericRangeQuery.newIntRange(r.getField().getName(), minimum, maximum, true, true);
    }
    throw new QueryParseException("not an integer range: " + p);
}
#end_block

#method_before
private Query timestampQuery(IndexPredicate<V> p) throws QueryParseException {
    if (p instanceof TimestampRangePredicate) {
        TimestampRangePredicate<V> r = (TimestampRangePredicate<V>) p;
        return LongPoint.newRangeQuery(r.getField().getName(), r.getMinTimestamp().getTime(), r.getMaxTimestamp().getTime());
    }
    throw new QueryParseException("not a timestamp: " + p);
}
#method_after
private Query timestampQuery(IndexPredicate<V> p) throws QueryParseException {
    if (p instanceof TimestampRangePredicate) {
        TimestampRangePredicate<V> r = (TimestampRangePredicate<V>) p;
        return LegacyNumericRangeQuery.newLongRange(r.getField().getName(), r.getMinTimestamp().getTime(), r.getMaxTimestamp().getTime(), true, true);
    }
    throw new QueryParseException("not a timestamp: " + p);
}
#end_block

#method_before
private Query notTimestamp(TimestampRangePredicate<V> r) throws QueryParseException {
    if (r.getMinTimestamp().getTime() == 0) {
        return LongPoint.newRangeQuery(r.getField().getName(), r.getMaxTimestamp().getTime(), Long.MAX_VALUE);
    }
    throw new QueryParseException("cannot negate: " + r);
}
#method_after
private Query notTimestamp(TimestampRangePredicate<V> r) throws QueryParseException {
    if (r.getMinTimestamp().getTime() == 0) {
        return LegacyNumericRangeQuery.newLongRange(r.getField().getName(), r.getMaxTimestamp().getTime(), null, true, true);
    }
    throw new QueryParseException("cannot negate: " + r);
}
#end_block

#method_before
protected Directory readIndexDirectory() throws IOException {
    Directory dir = new RAMDirectory();
    byte[] buffer = new byte[4096];
    InputStream index = getClass().getResourceAsStream(Constants.INDEX_ZIP);
    if (index == null) {
        log.warn("No index available");
        return null;
    }
    try (ZipInputStream zip = new ZipInputStream(index)) {
        ZipEntry entry;
        while ((entry = zip.getNextEntry()) != null) {
            try (IndexOutput out = dir.createOutput(entry.getName(), null)) {
                int count;
                while ((count = zip.read(buffer)) != -1) {
                    out.writeBytes(buffer, count);
                }
            }
        }
    }
    // We must NOT call dir.close() here, as DirectoryReader.open() expects an opened directory.
    return dir;
}
#method_after
protected Directory readIndexDirectory() throws IOException {
    Directory dir = new RAMDirectory();
    byte[] buffer = new byte[4096];
    InputStream index = getClass().getResourceAsStream(Constants.INDEX_ZIP);
    if (index == null) {
        logger.atWarning().log("No index available");
        return null;
    }
    try (ZipInputStream zip = new ZipInputStream(index)) {
        ZipEntry entry;
        while ((entry = zip.getNextEntry()) != null) {
            try (IndexOutput out = dir.createOutput(entry.getName(), null)) {
                int count;
                while ((count = zip.read(buffer)) != -1) {
                    out.writeBytes(buffer, count);
                }
            }
        }
    }
    // We must NOT call dir.close() here, as DirectoryReader.open() expects an opened directory.
    return dir;
}
#end_block

#method_before
@Override
public void close() {
    if (autoCommitExecutor != null) {
        autoCommitExecutor.shutdown();
    }
    writerThread.shutdown();
    try {
        if (!writerThread.awaitTermination(5, TimeUnit.SECONDS)) {
            log.warn("shutting down " + name + " index with pending Lucene writes");
        }
    } catch (InterruptedException e) {
        log.warn("interrupted waiting for pending Lucene writes of " + name + " index", e);
    }
    reopenThread.close();
    // not have flushed.
    try {
        searcherManager.maybeRefreshBlocking();
    } catch (IOException e) {
        log.warn("error finishing pending Lucene writes", e);
    }
    try {
        writer.close();
    } catch (AlreadyClosedException e) {
    // Ignore.
    } catch (IOException e) {
        log.warn("error closing Lucene writer", e);
    }
    try {
        dir.close();
    } catch (IOException e) {
        log.warn("error closing Lucene directory", e);
    }
}
#method_after
@Override
public void close() {
    if (autoCommitExecutor != null) {
        autoCommitExecutor.shutdown();
    }
    writerThread.shutdown();
    try {
        if (!writerThread.awaitTermination(5, TimeUnit.SECONDS)) {
            logger.atWarning().log("shutting down %s index with pending Lucene writes", name);
        }
    } catch (InterruptedException e) {
        logger.atWarning().withCause(e).log("interrupted waiting for pending Lucene writes of %s index", name);
    }
    reopenThread.close();
    // not have flushed.
    try {
        searcherManager.maybeRefreshBlocking();
    } catch (IOException e) {
        logger.atWarning().withCause(e).log("error finishing pending Lucene writes");
    }
    try {
        writer.close();
    } catch (AlreadyClosedException e) {
    // Ignore.
    } catch (IOException e) {
        logger.atWarning().withCause(e).log("error closing Lucene writer");
    }
    try {
        dir.close();
    } catch (IOException e) {
        logger.atWarning().withCause(e).log("error closing Lucene directory");
    }
}
#end_block

#method_before
void add(Document doc, Values<V> values) {
    String name = values.getField().getName();
    FieldType<?> type = values.getField().getType();
    Store store = store(values.getField());
    if (type == FieldType.INTEGER || type == FieldType.INTEGER_RANGE) {
        for (Object value : values.getValues()) {
            Integer intValue = (Integer) value;
            doc.add(new IntPoint(name, intValue));
            if (store == Store.YES) {
                doc.add(new StoredField(name, intValue));
            }
        }
    } else if (type == FieldType.LONG) {
        for (Object value : values.getValues()) {
            Long longValue = (Long) value;
            doc.add(new LongPoint(name, longValue));
            if (store == Store.YES) {
                doc.add(new StoredField(name, longValue));
            }
        }
    } else if (type == FieldType.TIMESTAMP) {
        for (Object value : values.getValues()) {
            Long timeValue = ((Timestamp) value).getTime();
            doc.add(new LongPoint(name, timeValue));
            if (store == Store.YES) {
                doc.add(new StoredField(name, timeValue));
            }
        }
    } else if (type == FieldType.EXACT || type == FieldType.PREFIX) {
        for (Object value : values.getValues()) {
            doc.add(new StringField(name, (String) value, store));
        }
    } else if (type == FieldType.FULL_TEXT) {
        for (Object value : values.getValues()) {
            doc.add(new TextField(name, (String) value, store));
        }
    } else if (type == FieldType.STORED_ONLY) {
        for (Object value : values.getValues()) {
            doc.add(new StoredField(name, (byte[]) value));
        }
    } else {
        throw FieldType.badFieldType(type);
    }
}
#method_after
void add(Document doc, Values<V> values) {
    String name = values.getField().getName();
    FieldType<?> type = values.getField().getType();
    Store store = store(values.getField());
    if (type == FieldType.INTEGER || type == FieldType.INTEGER_RANGE) {
        for (Object value : values.getValues()) {
            doc.add(new LegacyIntField(name, (Integer) value, store));
        }
    } else if (type == FieldType.LONG) {
        for (Object value : values.getValues()) {
            doc.add(new LegacyLongField(name, (Long) value, store));
        }
    } else if (type == FieldType.TIMESTAMP) {
        for (Object value : values.getValues()) {
            doc.add(new LegacyLongField(name, ((Timestamp) value).getTime(), store));
        }
    } else if (type == FieldType.EXACT || type == FieldType.PREFIX) {
        for (Object value : values.getValues()) {
            doc.add(new StringField(name, (String) value, store));
        }
    } else if (type == FieldType.FULL_TEXT) {
        for (Object value : values.getValues()) {
            doc.add(new TextField(name, (String) value, store));
        }
    } else if (type == FieldType.STORED_ONLY) {
        for (Object value : values.getValues()) {
            doc.add(new StoredField(name, (byte[]) value));
        }
    } else {
        throw FieldType.badFieldType(type);
    }
}
#end_block

#method_before
private boolean isGenAvailableNowForCurrentSearcher() {
    try {
        return reopenThread.waitForGeneration(gen, 0);
    } catch (InterruptedException e) {
        log.warn("Interrupted waiting for searcher generation", e);
        return false;
    }
}
#method_after
private boolean isGenAvailableNowForCurrentSearcher() {
    try {
        return reopenThread.waitForGeneration(gen, 0);
    } catch (InterruptedException e) {
        logger.atWarning().withCause(e).log("Interrupted waiting for searcher generation");
        return false;
    }
}
#end_block

#method_before
private <T> ResultSet<T> readImpl(Function<Document, T> mapper) throws OrmException {
    IndexSearcher searcher = null;
    try {
        searcher = acquire();
        int realLimit = opts.start() + opts.limit();
        TopFieldDocs docs = searcher.search(query, realLimit, sort);
        List<T> result = new ArrayList<>(docs.scoreDocs.length);
        for (int i = opts.start(); i < docs.scoreDocs.length; i++) {
            ScoreDoc sd = docs.scoreDocs[i];
            Document doc = searcher.doc(sd.doc, opts.fields());
            T mapperResult = mapper.apply(doc);
            if (mapperResult != null) {
                result.add(mapperResult);
            }
        }
        final List<T> r = Collections.unmodifiableList(result);
        return new ResultSet<T>() {

            @Override
            public Iterator<T> iterator() {
                return r.iterator();
            }

            @Override
            public List<T> toList() {
                return r;
            }

            @Override
            public void close() {
            // Do nothing.
            }
        };
    } catch (IOException e) {
        throw new OrmException(e);
    } finally {
        if (searcher != null) {
            try {
                release(searcher);
            } catch (IOException e) {
                log.warn("cannot release Lucene searcher", e);
            }
        }
    }
}
#method_after
private <T> ResultSet<T> readImpl(Function<Document, T> mapper) throws OrmException {
    IndexSearcher searcher = null;
    try {
        searcher = acquire();
        int realLimit = opts.start() + opts.limit();
        TopFieldDocs docs = searcher.search(query, realLimit, sort);
        List<T> result = new ArrayList<>(docs.scoreDocs.length);
        for (int i = opts.start(); i < docs.scoreDocs.length; i++) {
            ScoreDoc sd = docs.scoreDocs[i];
            Document doc = searcher.doc(sd.doc, opts.fields());
            T mapperResult = mapper.apply(doc);
            if (mapperResult != null) {
                result.add(mapperResult);
            }
        }
        final List<T> r = Collections.unmodifiableList(result);
        return new ResultSet<T>() {

            @Override
            public Iterator<T> iterator() {
                return r.iterator();
            }

            @Override
            public List<T> toList() {
                return r;
            }

            @Override
            public void close() {
            // Do nothing.
            }
        };
    } catch (IOException e) {
        throw new OrmException(e);
    } finally {
        if (searcher != null) {
            try {
                release(searcher);
            } catch (IOException e) {
                logger.atWarning().withCause(e).log("cannot release Lucene searcher");
            }
        }
    }
}
#end_block

#method_before
private Comment parseComment(byte[] note, MutableInteger curr, String currentFileName, PatchSet.Id psId, RevId revId, boolean isForBase, Integer parentNumber) throws ConfigInvalidException {
    Change.Id changeId = psId.getParentKey();
    // Check if there is a new file.
    boolean newFile = (RawParseUtils.match(note, curr.value, FILE.getBytes(UTF_8))) != -1;
    if (newFile) {
        // If so, parse the new file name.
        currentFileName = parseFilename(note, curr, changeId);
    } else if (currentFileName == null) {
        throw parseException(changeId, "could not parse %s", FILE);
    }
    CommentRange range = parseCommentRange(note, curr);
    if (range == null) {
        throw parseException(changeId, "could not parse %s", COMMENT_RANGE);
    }
    Timestamp commentTime = parseTimestamp(note, curr, changeId);
    Account.Id aId = parseAuthor(note, curr, changeId, AUTHOR);
    boolean hasRealAuthor = (RawParseUtils.match(note, curr.value, REAL_AUTHOR.getBytes(UTF_8))) != -1;
    Account.Id raId = null;
    if (hasRealAuthor) {
        raId = parseAuthor(note, curr, changeId, REAL_AUTHOR);
    }
    boolean hasParent = (RawParseUtils.match(note, curr.value, PARENT.getBytes(UTF_8))) != -1;
    String parentUUID = null;
    if (hasParent) {
        parentUUID = parseStringField(note, curr, changeId, PARENT);
    }
    String uuid = parseStringField(note, curr, changeId, UUID);
    boolean hasTag = (RawParseUtils.match(note, curr.value, TAG.getBytes(UTF_8))) != -1;
    String tag = null;
    if (hasTag) {
        tag = parseStringField(note, curr, changeId, TAG);
    }
    int commentLength = parseCommentLength(note, curr, changeId);
    String message = RawParseUtils.decode(UTF_8, note, curr.value, curr.value + commentLength);
    checkResult(message, "message contents", changeId);
    Comment c = new Comment(new Comment.Key(uuid, currentFileName, psId.get()), aId, commentTime, isForBase ? (short) (parentNumber == null ? 0 : -parentNumber) : (short) 1, message, serverId);
    c.lineNbr = range.getEndLine();
    c.parentUuid = parentUUID;
    c.tag = tag;
    c.setRevId(revId);
    if (raId != null) {
        c.setRealAuthor(raId);
    }
    if (range.getStartCharacter() != -1) {
        c.setRange(range);
    }
    curr.value = RawParseUtils.nextLF(note, curr.value + commentLength);
    curr.value = RawParseUtils.nextLF(note, curr.value);
    return c;
}
#method_after
private Comment parseComment(byte[] note, MutableInteger curr, String currentFileName, PatchSet.Id psId, RevId revId, boolean isForBase, Integer parentNumber) throws ConfigInvalidException {
    Change.Id changeId = psId.getParentKey();
    // Check if there is a new file.
    boolean newFile = (RawParseUtils.match(note, curr.value, FILE.getBytes(UTF_8))) != -1;
    if (newFile) {
        // If so, parse the new file name.
        currentFileName = parseFilename(note, curr, changeId);
    } else if (currentFileName == null) {
        throw parseException(changeId, "could not parse %s", FILE);
    }
    CommentRange range = parseCommentRange(note, curr);
    if (range == null) {
        throw parseException(changeId, "could not parse %s", COMMENT_RANGE);
    }
    Timestamp commentTime = parseTimestamp(note, curr, changeId);
    Account.Id aId = parseAuthor(note, curr, changeId, AUTHOR);
    boolean hasRealAuthor = (RawParseUtils.match(note, curr.value, REAL_AUTHOR.getBytes(UTF_8))) != -1;
    Account.Id raId = null;
    if (hasRealAuthor) {
        raId = parseAuthor(note, curr, changeId, REAL_AUTHOR);
    }
    boolean hasParent = (RawParseUtils.match(note, curr.value, PARENT.getBytes(UTF_8))) != -1;
    String parentUUID = null;
    boolean unresolved = false;
    if (hasParent) {
        parentUUID = parseStringField(note, curr, changeId, PARENT);
    }
    boolean hasUnresolved = (RawParseUtils.match(note, curr.value, UNRESOLVED.getBytes(UTF_8))) != -1;
    if (hasUnresolved) {
        unresolved = parseBooleanField(note, curr, changeId, UNRESOLVED);
    }
    String uuid = parseStringField(note, curr, changeId, UUID);
    boolean hasTag = (RawParseUtils.match(note, curr.value, TAG.getBytes(UTF_8))) != -1;
    String tag = null;
    if (hasTag) {
        tag = parseStringField(note, curr, changeId, TAG);
    }
    int commentLength = parseCommentLength(note, curr, changeId);
    String message = RawParseUtils.decode(UTF_8, note, curr.value, curr.value + commentLength);
    checkResult(message, "message contents", changeId);
    Comment c = new Comment(new Comment.Key(uuid, currentFileName, psId.get()), aId, commentTime, isForBase ? (short) (parentNumber == null ? 0 : -parentNumber) : (short) 1, message, serverId, unresolved);
    c.lineNbr = range.getEndLine();
    c.parentUuid = parentUUID;
    c.tag = tag;
    c.setRevId(revId);
    if (raId != null) {
        c.setRealAuthor(raId);
    }
    if (range.getStartCharacter() != -1) {
        c.setRange(range);
    }
    curr.value = RawParseUtils.nextLF(note, curr.value + commentLength);
    curr.value = RawParseUtils.nextLF(note, curr.value);
    return c;
}
#end_block

#method_before
private void appendOneComment(PrintWriter writer, Comment c) {
    // The CommentRange field for a comment is allowed to be null. If it is
    // null, then in the first line, we simply use the line number field for a
    // comment instead. If it isn't null, we write the comment range itself.
    Comment.Range range = c.range;
    if (range != null) {
        writer.print(range.startLine);
        writer.print(':');
        writer.print(range.startChar);
        writer.print('-');
        writer.print(range.endLine);
        writer.print(':');
        writer.print(range.endChar);
    } else {
        writer.print(c.lineNbr);
    }
    writer.print("\n");
    writer.print(formatTime(serverIdent, c.writtenOn));
    writer.print("\n");
    appendIdent(writer, AUTHOR, c.author.getId(), c.writtenOn);
    if (!c.getRealAuthor().equals(c.author)) {
        appendIdent(writer, REAL_AUTHOR, c.getRealAuthor().getId(), c.writtenOn);
    }
    String parent = c.parentUuid;
    if (parent != null) {
        appendHeaderField(writer, PARENT, parent);
    }
    appendHeaderField(writer, UUID, c.key.uuid);
    if (c.tag != null) {
        appendHeaderField(writer, TAG, c.tag);
    }
    byte[] messageBytes = c.message.getBytes(UTF_8);
    appendHeaderField(writer, LENGTH, Integer.toString(messageBytes.length));
    writer.print(c.message);
    writer.print("\n\n");
}
#method_after
private void appendOneComment(PrintWriter writer, Comment c) {
    // The CommentRange field for a comment is allowed to be null. If it is
    // null, then in the first line, we simply use the line number field for a
    // comment instead. If it isn't null, we write the comment range itself.
    Comment.Range range = c.range;
    if (range != null) {
        writer.print(range.startLine);
        writer.print(':');
        writer.print(range.startChar);
        writer.print('-');
        writer.print(range.endLine);
        writer.print(':');
        writer.print(range.endChar);
    } else {
        writer.print(c.lineNbr);
    }
    writer.print("\n");
    writer.print(formatTime(serverIdent, c.writtenOn));
    writer.print("\n");
    appendIdent(writer, AUTHOR, c.author.getId(), c.writtenOn);
    if (!c.getRealAuthor().equals(c.author)) {
        appendIdent(writer, REAL_AUTHOR, c.getRealAuthor().getId(), c.writtenOn);
    }
    String parent = c.parentUuid;
    if (parent != null) {
        appendHeaderField(writer, PARENT, parent);
    }
    appendHeaderField(writer, UNRESOLVED, Boolean.toString(c.unresolved));
    appendHeaderField(writer, UUID, c.key.uuid);
    if (c.tag != null) {
        appendHeaderField(writer, TAG, c.tag);
    }
    byte[] messageBytes = c.message.getBytes(UTF_8);
    appendHeaderField(writer, LENGTH, Integer.toString(messageBytes.length));
    writer.print(c.message);
    writer.print("\n\n");
}
#end_block

#method_before
private static void diffPatchSets(List<String> diffs, ChangeBundle bundleA, ChangeBundle bundleB) {
    Map<PatchSet.Id, PatchSet> as = bundleA.filterPatchSets();
    Map<PatchSet.Id, PatchSet> bs = bundleB.filterPatchSets();
    for (PatchSet.Id id : diffKeySets(diffs, as, bs)) {
        PatchSet a = as.get(id);
        PatchSet b = bs.get(id);
        String desc = describe(id);
        String pushCertField = "pushCertificate";
        diffColumnsExcluding(diffs, PatchSet.class, desc, bundleA, a, bundleB, b, pushCertField);
        diffValues(diffs, desc, trimPushCert(a), trimPushCert(b), pushCertField);
    }
}
#method_after
private static void diffPatchSets(List<String> diffs, ChangeBundle bundleA, ChangeBundle bundleB) {
    Map<PatchSet.Id, PatchSet> as = bundleA.patchSets;
    Map<PatchSet.Id, PatchSet> bs = bundleB.patchSets;
    for (PatchSet.Id id : diffKeySets(diffs, as, bs)) {
        PatchSet a = as.get(id);
        PatchSet b = bs.get(id);
        String desc = describe(id);
        String pushCertField = "pushCertificate";
        diffColumnsExcluding(diffs, PatchSet.class, desc, bundleA, a, bundleB, b, pushCertField);
        diffValues(diffs, desc, trimPushCert(a), trimPushCert(b), pushCertField);
    }
}
#end_block

#method_before
@Test
public void tagInlineCommenrts() throws Exception {
    String tag = "jenkins";
    Change c = newChange();
    RevCommit commit = tr.commit().message("PS2").create();
    ChangeUpdate update = newUpdate(c, changeOwner);
    update.putComment(Status.PUBLISHED, newComment(c.currentPatchSetId(), "a.txt", "uuid1", new CommentRange(1, 2, 3, 4), 1, changeOwner, null, TimeUtil.nowTs(), "Comment", (short) 1, commit.name()));
    update.setTag(tag);
    update.commit();
    ChangeNotes notes = newNotes(c);
    ImmutableListMultimap<RevId, Comment> comments = notes.getComments();
    assertThat(comments).hasSize(1);
    assertThat(comments.entries().asList().get(0).getValue().tag).isEqualTo(tag);
}
#method_after
@Test
public void tagInlineCommenrts() throws Exception {
    String tag = "jenkins";
    Change c = newChange();
    RevCommit commit = tr.commit().message("PS2").create();
    ChangeUpdate update = newUpdate(c, changeOwner);
    update.putComment(Status.PUBLISHED, newComment(c.currentPatchSetId(), "a.txt", "uuid1", new CommentRange(1, 2, 3, 4), 1, changeOwner, null, TimeUtil.nowTs(), "Comment", (short) 1, commit.name(), false));
    update.setTag(tag);
    update.commit();
    ChangeNotes notes = newNotes(c);
    ImmutableListMultimap<RevId, Comment> comments = notes.getComments();
    assertThat(comments).hasSize(1);
    assertThat(comments.entries().asList().get(0).getValue().tag).isEqualTo(tag);
}
#end_block

#method_before
@Test
public void multipleTags() throws Exception {
    String ipTag = "ip";
    String coverageTag = "coverage";
    String integrationTag = "integration";
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, changeOwner);
    update.putApproval("Verified", (short) -1);
    update.setChangeMessage("integration verification");
    update.setTag(integrationTag);
    update.commit();
    RevCommit commit = tr.commit().message("PS2").create();
    update = newUpdate(c, changeOwner);
    update.putComment(Status.PUBLISHED, newComment(c.currentPatchSetId(), "a.txt", "uuid1", new CommentRange(1, 2, 3, 4), 1, changeOwner, null, TimeUtil.nowTs(), "Comment", (short) 1, commit.name()));
    update.setChangeMessage("coverage verification");
    update.setTag(coverageTag);
    update.commit();
    update = newUpdate(c, changeOwner);
    update.setChangeMessage("ip clear");
    update.setTag(ipTag);
    update.commit();
    ChangeNotes notes = newNotes(c);
    ImmutableListMultimap<PatchSet.Id, PatchSetApproval> approvals = notes.getApprovals();
    assertThat(approvals).hasSize(1);
    PatchSetApproval approval = approvals.entries().asList().get(0).getValue();
    assertThat(approval.getTag()).isEqualTo(integrationTag);
    assertThat(approval.getValue()).isEqualTo(-1);
    ImmutableListMultimap<RevId, Comment> comments = notes.getComments();
    assertThat(comments).hasSize(1);
    assertThat(comments.entries().asList().get(0).getValue().tag).isEqualTo(coverageTag);
    ImmutableList<ChangeMessage> messages = notes.getChangeMessages();
    assertThat(messages).hasSize(3);
    assertThat(messages.get(0).getTag()).isEqualTo(integrationTag);
    assertThat(messages.get(1).getTag()).isEqualTo(coverageTag);
    assertThat(messages.get(2).getTag()).isEqualTo(ipTag);
}
#method_after
@Test
public void multipleTags() throws Exception {
    String ipTag = "ip";
    String coverageTag = "coverage";
    String integrationTag = "integration";
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, changeOwner);
    update.putApproval("Verified", (short) -1);
    update.setChangeMessage("integration verification");
    update.setTag(integrationTag);
    update.commit();
    RevCommit commit = tr.commit().message("PS2").create();
    update = newUpdate(c, changeOwner);
    update.putComment(Status.PUBLISHED, newComment(c.currentPatchSetId(), "a.txt", "uuid1", new CommentRange(1, 2, 3, 4), 1, changeOwner, null, TimeUtil.nowTs(), "Comment", (short) 1, commit.name(), false));
    update.setChangeMessage("coverage verification");
    update.setTag(coverageTag);
    update.commit();
    update = newUpdate(c, changeOwner);
    update.setChangeMessage("ip clear");
    update.setTag(ipTag);
    update.commit();
    ChangeNotes notes = newNotes(c);
    ImmutableListMultimap<PatchSet.Id, PatchSetApproval> approvals = notes.getApprovals();
    assertThat(approvals).hasSize(1);
    PatchSetApproval approval = approvals.entries().asList().get(0).getValue();
    assertThat(approval.getTag()).isEqualTo(integrationTag);
    assertThat(approval.getValue()).isEqualTo(-1);
    ImmutableListMultimap<RevId, Comment> comments = notes.getComments();
    assertThat(comments).hasSize(1);
    assertThat(comments.entries().asList().get(0).getValue().tag).isEqualTo(coverageTag);
    ImmutableList<ChangeMessage> messages = notes.getChangeMessages();
    assertThat(messages).hasSize(3);
    assertThat(messages.get(0).getTag()).isEqualTo(integrationTag);
    assertThat(messages.get(1).getTag()).isEqualTo(coverageTag);
    assertThat(messages.get(2).getTag()).isEqualTo(ipTag);
}
#end_block

#method_before
@Test
public void patchSetStates() throws Exception {
    Change c = newChange();
    PatchSet.Id psId1 = c.currentPatchSetId();
    incrementCurrentPatchSetFieldOnly(c);
    PatchSet.Id psId2 = c.currentPatchSetId();
    RevCommit commit = tr.commit().message("PS2").create();
    ChangeUpdate update = newUpdate(c, changeOwner);
    update.setCommit(rw, commit);
    update.setPatchSetState(PatchSetState.DRAFT);
    update.putApproval("Code-Review", (short) 1);
    update.setChangeMessage("This is a message");
    update.putComment(Status.PUBLISHED, newComment(c.currentPatchSetId(), "a.txt", "uuid1", new CommentRange(1, 2, 3, 4), 1, changeOwner, null, TimeUtil.nowTs(), "Comment", (short) 1, commit.name()));
    update.commit();
    ChangeNotes notes = newNotes(c);
    assertThat(notes.getPatchSets().get(psId2).isDraft()).isTrue();
    assertThat(notes.getPatchSets().keySet()).containsExactly(psId1, psId2);
    assertThat(notes.getApprovals()).isNotEmpty();
    assertThat(notes.getChangeMessagesByPatchSet()).isNotEmpty();
    assertThat(notes.getChangeMessages()).isNotEmpty();
    assertThat(notes.getComments()).isNotEmpty();
    // publish ps2
    update = newUpdate(c, changeOwner);
    update.setPatchSetState(PatchSetState.PUBLISHED);
    update.commit();
    notes = newNotes(c);
    assertThat(notes.getPatchSets().get(psId2).isDraft()).isFalse();
    // delete ps2
    update = newUpdate(c, changeOwner);
    update.setPatchSetState(PatchSetState.DELETED);
    update.commit();
    notes = newNotes(c);
    assertThat(notes.getPatchSets().keySet()).containsExactly(psId1);
    assertThat(notes.getApprovals()).isEmpty();
    assertThat(notes.getChangeMessagesByPatchSet()).isEmpty();
    assertThat(notes.getChangeMessages()).isEmpty();
    assertThat(notes.getComments()).isEmpty();
}
#method_after
@Test
public void patchSetStates() throws Exception {
    Change c = newChange();
    PatchSet.Id psId1 = c.currentPatchSetId();
    incrementCurrentPatchSetFieldOnly(c);
    PatchSet.Id psId2 = c.currentPatchSetId();
    RevCommit commit = tr.commit().message("PS2").create();
    ChangeUpdate update = newUpdate(c, changeOwner);
    update.setCommit(rw, commit);
    update.setPatchSetState(PatchSetState.DRAFT);
    update.putApproval("Code-Review", (short) 1);
    update.setChangeMessage("This is a message");
    update.putComment(Status.PUBLISHED, newComment(c.currentPatchSetId(), "a.txt", "uuid1", new CommentRange(1, 2, 3, 4), 1, changeOwner, null, TimeUtil.nowTs(), "Comment", (short) 1, commit.name(), false));
    update.commit();
    ChangeNotes notes = newNotes(c);
    assertThat(notes.getPatchSets().get(psId2).isDraft()).isTrue();
    assertThat(notes.getPatchSets().keySet()).containsExactly(psId1, psId2);
    assertThat(notes.getApprovals()).isNotEmpty();
    assertThat(notes.getChangeMessagesByPatchSet()).isNotEmpty();
    assertThat(notes.getChangeMessages()).isNotEmpty();
    assertThat(notes.getComments()).isNotEmpty();
    // publish ps2
    update = newUpdate(c, changeOwner);
    update.setPatchSetState(PatchSetState.PUBLISHED);
    update.commit();
    notes = newNotes(c);
    assertThat(notes.getPatchSets().get(psId2).isDraft()).isFalse();
    // delete ps2
    update = newUpdate(c, changeOwner);
    update.setPatchSetState(PatchSetState.DELETED);
    update.commit();
    notes = newNotes(c);
    assertThat(notes.getPatchSets().keySet()).containsExactly(psId1);
    assertThat(notes.getApprovals()).isEmpty();
    assertThat(notes.getChangeMessagesByPatchSet()).isEmpty();
    assertThat(notes.getChangeMessages()).isEmpty();
    assertThat(notes.getComments()).isEmpty();
}
#end_block

#method_before
@Test
public void pushCertificate() throws Exception {
    String pushCert = "certificate version 0.1\n" + "pusher This is not a real push cert\n" + "-----BEGIN PGP SIGNATURE-----\n" + "Version: GnuPG v1\n" + "\n" + "Nor is this a real signature.\n" + "-----END PGP SIGNATURE-----\n";
    // ps2 with push cert
    Change c = newChange();
    PatchSet.Id psId1 = c.currentPatchSetId();
    incrementCurrentPatchSetFieldOnly(c);
    PatchSet.Id psId2 = c.currentPatchSetId();
    ChangeUpdate update = newUpdate(c, changeOwner);
    update.setPatchSetId(psId2);
    RevCommit commit = tr.commit().message("PS2").create();
    update.setCommit(rw, commit, pushCert);
    update.commit();
    ChangeNotes notes = newNotes(c);
    String note = readNote(notes, commit);
    if (!testJson()) {
        assertThat(note).isEqualTo(pushCert);
    }
    Map<PatchSet.Id, PatchSet> patchSets = notes.getPatchSets();
    assertThat(patchSets.get(psId1).getPushCertificate()).isNull();
    assertThat(patchSets.get(psId2).getPushCertificate()).isEqualTo(pushCert);
    assertThat(notes.getComments()).isEmpty();
    // comment on ps2
    update = newUpdate(c, changeOwner);
    update.setPatchSetId(psId2);
    Timestamp ts = TimeUtil.nowTs();
    update.putComment(Status.PUBLISHED, newComment(psId2, "a.txt", "uuid1", new CommentRange(1, 2, 3, 4), 1, changeOwner, null, ts, "Comment", (short) 1, commit.name()));
    update.commit();
    notes = newNotes(c);
    patchSets = notes.getPatchSets();
    assertThat(patchSets.get(psId1).getPushCertificate()).isNull();
    assertThat(patchSets.get(psId2).getPushCertificate()).isEqualTo(pushCert);
    assertThat(notes.getComments()).isNotEmpty();
    if (!testJson()) {
        assertThat(readNote(notes, commit)).isEqualTo(pushCert + "Revision: " + commit.name() + "\n" + "Patch-set: 2\n" + "File: a.txt\n" + "\n" + "1:2-3:4\n" + ChangeNoteUtil.formatTime(serverIdent, ts) + "\n" + "Author: Change Owner <1@gerrit>\n" + "UUID: uuid1\n" + "Bytes: 7\n" + "Comment\n" + "\n");
    }
}
#method_after
@Test
public void pushCertificate() throws Exception {
    String pushCert = "certificate version 0.1\n" + "pusher This is not a real push cert\n" + "-----BEGIN PGP SIGNATURE-----\n" + "Version: GnuPG v1\n" + "\n" + "Nor is this a real signature.\n" + "-----END PGP SIGNATURE-----\n";
    // ps2 with push cert
    Change c = newChange();
    PatchSet.Id psId1 = c.currentPatchSetId();
    incrementCurrentPatchSetFieldOnly(c);
    PatchSet.Id psId2 = c.currentPatchSetId();
    ChangeUpdate update = newUpdate(c, changeOwner);
    update.setPatchSetId(psId2);
    RevCommit commit = tr.commit().message("PS2").create();
    update.setCommit(rw, commit, pushCert);
    update.commit();
    ChangeNotes notes = newNotes(c);
    String note = readNote(notes, commit);
    if (!testJson()) {
        assertThat(note).isEqualTo(pushCert);
    }
    Map<PatchSet.Id, PatchSet> patchSets = notes.getPatchSets();
    assertThat(patchSets.get(psId1).getPushCertificate()).isNull();
    assertThat(patchSets.get(psId2).getPushCertificate()).isEqualTo(pushCert);
    assertThat(notes.getComments()).isEmpty();
    // comment on ps2
    update = newUpdate(c, changeOwner);
    update.setPatchSetId(psId2);
    Timestamp ts = TimeUtil.nowTs();
    update.putComment(Status.PUBLISHED, newComment(psId2, "a.txt", "uuid1", new CommentRange(1, 2, 3, 4), 1, changeOwner, null, ts, "Comment", (short) 1, commit.name(), false));
    update.commit();
    notes = newNotes(c);
    patchSets = notes.getPatchSets();
    assertThat(patchSets.get(psId1).getPushCertificate()).isNull();
    assertThat(patchSets.get(psId2).getPushCertificate()).isEqualTo(pushCert);
    assertThat(notes.getComments()).isNotEmpty();
    if (!testJson()) {
        assertThat(readNote(notes, commit)).isEqualTo(pushCert + "Revision: " + commit.name() + "\n" + "Patch-set: 2\n" + "File: a.txt\n" + "\n" + "1:2-3:4\n" + ChangeNoteUtil.formatTime(serverIdent, ts) + "\n" + "Author: Change Owner <1@gerrit>\n" + "Unresolved: false\n" + "UUID: uuid1\n" + "Bytes: 7\n" + "Comment\n" + "\n");
    }
}
#end_block

#method_before
@Test
public void multipleUpdatesIncludingComments() throws Exception {
    Change c = newChange();
    ChangeUpdate update1 = newUpdate(c, otherUser);
    String uuid1 = "uuid1";
    String message1 = "comment 1";
    CommentRange range1 = new CommentRange(1, 1, 2, 1);
    Timestamp time1 = TimeUtil.nowTs();
    PatchSet.Id psId = c.currentPatchSetId();
    RevCommit tipCommit;
    try (NoteDbUpdateManager updateManager = updateManagerFactory.create(project)) {
        Comment comment1 = newComment(psId, "file1", uuid1, range1, range1.getEndLine(), otherUser, null, time1, message1, (short) 0, "abcd1234abcd1234abcd1234abcd1234abcd1234");
        update1.setPatchSetId(psId);
        update1.putComment(Status.PUBLISHED, comment1);
        updateManager.add(update1);
        ChangeUpdate update2 = newUpdate(c, otherUser);
        update2.putApproval("Code-Review", (short) 2);
        updateManager.add(update2);
        updateManager.execute();
    }
    ChangeNotes notes = newNotes(c);
    ObjectId tip = notes.getRevision();
    tipCommit = rw.parseCommit(tip);
    RevCommit commitWithApprovals = tipCommit;
    assertThat(commitWithApprovals).isNotNull();
    RevCommit commitWithComments = commitWithApprovals.getParent(0);
    assertThat(commitWithComments).isNotNull();
    try (ChangeNotesRevWalk rw = ChangeNotesCommit.newRevWalk(repo)) {
        ChangeNotesParser notesWithComments = new ChangeNotesParser(c.getId(), commitWithComments.copy(), rw, noteUtil, args.metrics);
        ChangeNotesState state = notesWithComments.parseAll();
        assertThat(state.approvals()).isEmpty();
        assertThat(state.publishedComments()).hasSize(1);
    }
    try (ChangeNotesRevWalk rw = ChangeNotesCommit.newRevWalk(repo)) {
        ChangeNotesParser notesWithApprovals = new ChangeNotesParser(c.getId(), commitWithApprovals.copy(), rw, noteUtil, args.metrics);
        ChangeNotesState state = notesWithApprovals.parseAll();
        assertThat(state.approvals()).hasSize(1);
        assertThat(state.publishedComments()).hasSize(1);
    }
}
#method_after
@Test
public void multipleUpdatesIncludingComments() throws Exception {
    Change c = newChange();
    ChangeUpdate update1 = newUpdate(c, otherUser);
    String uuid1 = "uuid1";
    String message1 = "comment 1";
    CommentRange range1 = new CommentRange(1, 1, 2, 1);
    Timestamp time1 = TimeUtil.nowTs();
    PatchSet.Id psId = c.currentPatchSetId();
    RevCommit tipCommit;
    try (NoteDbUpdateManager updateManager = updateManagerFactory.create(project)) {
        Comment comment1 = newComment(psId, "file1", uuid1, range1, range1.getEndLine(), otherUser, null, time1, message1, (short) 0, "abcd1234abcd1234abcd1234abcd1234abcd1234", false);
        update1.setPatchSetId(psId);
        update1.putComment(Status.PUBLISHED, comment1);
        updateManager.add(update1);
        ChangeUpdate update2 = newUpdate(c, otherUser);
        update2.putApproval("Code-Review", (short) 2);
        updateManager.add(update2);
        updateManager.execute();
    }
    ChangeNotes notes = newNotes(c);
    ObjectId tip = notes.getRevision();
    tipCommit = rw.parseCommit(tip);
    RevCommit commitWithApprovals = tipCommit;
    assertThat(commitWithApprovals).isNotNull();
    RevCommit commitWithComments = commitWithApprovals.getParent(0);
    assertThat(commitWithComments).isNotNull();
    try (ChangeNotesRevWalk rw = ChangeNotesCommit.newRevWalk(repo)) {
        ChangeNotesParser notesWithComments = new ChangeNotesParser(c.getId(), commitWithComments.copy(), rw, noteUtil, args.metrics);
        ChangeNotesState state = notesWithComments.parseAll();
        assertThat(state.approvals()).isEmpty();
        assertThat(state.publishedComments()).hasSize(1);
    }
    try (ChangeNotesRevWalk rw = ChangeNotesCommit.newRevWalk(repo)) {
        ChangeNotesParser notesWithApprovals = new ChangeNotesParser(c.getId(), commitWithApprovals.copy(), rw, noteUtil, args.metrics);
        ChangeNotesState state = notesWithApprovals.parseAll();
        assertThat(state.approvals()).hasSize(1);
        assertThat(state.publishedComments()).hasSize(1);
    }
}
#end_block

#method_before
@Test
public void patchLineCommentsFileComment() throws Exception {
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, otherUser);
    PatchSet.Id psId = c.currentPatchSetId();
    RevId revId = new RevId("abcd1234abcd1234abcd1234abcd1234abcd1234");
    Comment comment = newComment(psId, "file1", "uuid", null, 0, otherUser, null, TimeUtil.nowTs(), "message", (short) 1, revId.get());
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, comment);
    update.commit();
    ChangeNotes notes = newNotes(c);
    assertThat(notes.getComments()).isEqualTo(ImmutableMultimap.of(revId, comment));
}
#method_after
@Test
public void patchLineCommentsFileComment() throws Exception {
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, otherUser);
    PatchSet.Id psId = c.currentPatchSetId();
    RevId revId = new RevId("abcd1234abcd1234abcd1234abcd1234abcd1234");
    Comment comment = newComment(psId, "file1", "uuid", null, 0, otherUser, null, TimeUtil.nowTs(), "message", (short) 1, revId.get(), false);
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, comment);
    update.commit();
    ChangeNotes notes = newNotes(c);
    assertThat(notes.getComments()).isEqualTo(ImmutableMultimap.of(revId, comment));
}
#end_block

#method_before
@Test
public void patchLineCommentsZeroColumns() throws Exception {
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, otherUser);
    PatchSet.Id psId = c.currentPatchSetId();
    RevId revId = new RevId("abcd1234abcd1234abcd1234abcd1234abcd1234");
    CommentRange range = new CommentRange(1, 0, 2, 0);
    Comment comment = newComment(psId, "file1", "uuid", range, range.getEndLine(), otherUser, null, TimeUtil.nowTs(), "message", (short) 1, revId.get());
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, comment);
    update.commit();
    ChangeNotes notes = newNotes(c);
    assertThat(notes.getComments()).isEqualTo(ImmutableMultimap.of(revId, comment));
}
#method_after
@Test
public void patchLineCommentsZeroColumns() throws Exception {
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, otherUser);
    PatchSet.Id psId = c.currentPatchSetId();
    RevId revId = new RevId("abcd1234abcd1234abcd1234abcd1234abcd1234");
    CommentRange range = new CommentRange(1, 0, 2, 0);
    Comment comment = newComment(psId, "file1", "uuid", range, range.getEndLine(), otherUser, null, TimeUtil.nowTs(), "message", (short) 1, revId.get(), false);
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, comment);
    update.commit();
    ChangeNotes notes = newNotes(c);
    assertThat(notes.getComments()).isEqualTo(ImmutableMultimap.of(revId, comment));
}
#end_block

#method_before
@Test
public void patchLineCommentZeroRange() throws Exception {
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, otherUser);
    PatchSet.Id psId = c.currentPatchSetId();
    RevId revId = new RevId("abcd1234abcd1234abcd1234abcd1234abcd1234");
    CommentRange range = new CommentRange(0, 0, 0, 0);
    Comment comment = newComment(psId, "file", "uuid", range, range.getEndLine(), otherUser, null, TimeUtil.nowTs(), "message", (short) 1, revId.get());
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, comment);
    update.commit();
    ChangeNotes notes = newNotes(c);
    assertThat(notes.getComments()).isEqualTo(ImmutableMultimap.of(revId, comment));
}
#method_after
@Test
public void patchLineCommentZeroRange() throws Exception {
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, otherUser);
    PatchSet.Id psId = c.currentPatchSetId();
    RevId revId = new RevId("abcd1234abcd1234abcd1234abcd1234abcd1234");
    CommentRange range = new CommentRange(0, 0, 0, 0);
    Comment comment = newComment(psId, "file", "uuid", range, range.getEndLine(), otherUser, null, TimeUtil.nowTs(), "message", (short) 1, revId.get(), false);
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, comment);
    update.commit();
    ChangeNotes notes = newNotes(c);
    assertThat(notes.getComments()).isEqualTo(ImmutableMultimap.of(revId, comment));
}
#end_block

#method_before
@Test
public void patchLineCommentEmptyFilename() throws Exception {
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, otherUser);
    PatchSet.Id psId = c.currentPatchSetId();
    RevId revId = new RevId("abcd1234abcd1234abcd1234abcd1234abcd1234");
    CommentRange range = new CommentRange(1, 2, 3, 4);
    Comment comment = newComment(psId, "", "uuid", range, range.getEndLine(), otherUser, null, TimeUtil.nowTs(), "message", (short) 1, revId.get());
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, comment);
    update.commit();
    ChangeNotes notes = newNotes(c);
    assertThat(notes.getComments()).isEqualTo(ImmutableMultimap.of(revId, comment));
}
#method_after
@Test
public void patchLineCommentEmptyFilename() throws Exception {
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, otherUser);
    PatchSet.Id psId = c.currentPatchSetId();
    RevId revId = new RevId("abcd1234abcd1234abcd1234abcd1234abcd1234");
    CommentRange range = new CommentRange(1, 2, 3, 4);
    Comment comment = newComment(psId, "", "uuid", range, range.getEndLine(), otherUser, null, TimeUtil.nowTs(), "message", (short) 1, revId.get(), false);
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, comment);
    update.commit();
    ChangeNotes notes = newNotes(c);
    assertThat(notes.getComments()).isEqualTo(ImmutableMultimap.of(revId, comment));
}
#end_block

#method_before
@Test
public void patchLineCommentNotesFormatSide1() throws Exception {
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, otherUser);
    String uuid1 = "uuid1";
    String uuid2 = "uuid2";
    String uuid3 = "uuid3";
    String message1 = "comment 1";
    String message2 = "comment 2";
    String message3 = "comment 3";
    CommentRange range1 = new CommentRange(1, 1, 2, 1);
    Timestamp time1 = TimeUtil.nowTs();
    Timestamp time2 = TimeUtil.nowTs();
    Timestamp time3 = TimeUtil.nowTs();
    PatchSet.Id psId = c.currentPatchSetId();
    Comment comment1 = newComment(psId, "file1", uuid1, range1, range1.getEndLine(), otherUser, null, time1, message1, (short) 1, "abcd1234abcd1234abcd1234abcd1234abcd1234");
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, comment1);
    update.commit();
    update = newUpdate(c, otherUser);
    CommentRange range2 = new CommentRange(2, 1, 3, 1);
    Comment comment2 = newComment(psId, "file1", uuid2, range2, range2.getEndLine(), otherUser, null, time2, message2, (short) 1, "abcd1234abcd1234abcd1234abcd1234abcd1234");
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, comment2);
    update.commit();
    update = newUpdate(c, otherUser);
    CommentRange range3 = new CommentRange(3, 0, 4, 1);
    Comment comment3 = newComment(psId, "file2", uuid3, range3, range3.getEndLine(), otherUser, null, time3, message3, (short) 1, "abcd1234abcd1234abcd1234abcd1234abcd1234");
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, comment3);
    update.commit();
    ChangeNotes notes = newNotes(c);
    try (RevWalk walk = new RevWalk(repo)) {
        ArrayList<Note> notesInTree = Lists.newArrayList(notes.revisionNoteMap.noteMap.iterator());
        Note note = Iterables.getOnlyElement(notesInTree);
        byte[] bytes = walk.getObjectReader().open(note.getData(), Constants.OBJ_BLOB).getBytes();
        String noteString = new String(bytes, UTF_8);
        if (!testJson()) {
            assertThat(noteString).isEqualTo("Revision: abcd1234abcd1234abcd1234abcd1234abcd1234\n" + "Patch-set: 1\n" + "File: file1\n" + "\n" + "1:1-2:1\n" + ChangeNoteUtil.formatTime(serverIdent, time1) + "\n" + "Author: Other Account <2@gerrit>\n" + "UUID: uuid1\n" + "Bytes: 9\n" + "comment 1\n" + "\n" + "2:1-3:1\n" + ChangeNoteUtil.formatTime(serverIdent, time2) + "\n" + "Author: Other Account <2@gerrit>\n" + "UUID: uuid2\n" + "Bytes: 9\n" + "comment 2\n" + "\n" + "File: file2\n" + "\n" + "3:0-4:1\n" + ChangeNoteUtil.formatTime(serverIdent, time3) + "\n" + "Author: Other Account <2@gerrit>\n" + "UUID: uuid3\n" + "Bytes: 9\n" + "comment 3\n" + "\n");
        }
    }
}
#method_after
@Test
public void patchLineCommentNotesFormatSide1() throws Exception {
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, otherUser);
    String uuid1 = "uuid1";
    String uuid2 = "uuid2";
    String uuid3 = "uuid3";
    String message1 = "comment 1";
    String message2 = "comment 2";
    String message3 = "comment 3";
    CommentRange range1 = new CommentRange(1, 1, 2, 1);
    Timestamp time1 = TimeUtil.nowTs();
    Timestamp time2 = TimeUtil.nowTs();
    Timestamp time3 = TimeUtil.nowTs();
    PatchSet.Id psId = c.currentPatchSetId();
    Comment comment1 = newComment(psId, "file1", uuid1, range1, range1.getEndLine(), otherUser, null, time1, message1, (short) 1, "abcd1234abcd1234abcd1234abcd1234abcd1234", false);
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, comment1);
    update.commit();
    update = newUpdate(c, otherUser);
    CommentRange range2 = new CommentRange(2, 1, 3, 1);
    Comment comment2 = newComment(psId, "file1", uuid2, range2, range2.getEndLine(), otherUser, null, time2, message2, (short) 1, "abcd1234abcd1234abcd1234abcd1234abcd1234", false);
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, comment2);
    update.commit();
    update = newUpdate(c, otherUser);
    CommentRange range3 = new CommentRange(3, 0, 4, 1);
    Comment comment3 = newComment(psId, "file2", uuid3, range3, range3.getEndLine(), otherUser, null, time3, message3, (short) 1, "abcd1234abcd1234abcd1234abcd1234abcd1234", false);
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, comment3);
    update.commit();
    ChangeNotes notes = newNotes(c);
    try (RevWalk walk = new RevWalk(repo)) {
        ArrayList<Note> notesInTree = Lists.newArrayList(notes.revisionNoteMap.noteMap.iterator());
        Note note = Iterables.getOnlyElement(notesInTree);
        byte[] bytes = walk.getObjectReader().open(note.getData(), Constants.OBJ_BLOB).getBytes();
        String noteString = new String(bytes, UTF_8);
        if (!testJson()) {
            assertThat(noteString).isEqualTo("Revision: abcd1234abcd1234abcd1234abcd1234abcd1234\n" + "Patch-set: 1\n" + "File: file1\n" + "\n" + "1:1-2:1\n" + ChangeNoteUtil.formatTime(serverIdent, time1) + "\n" + "Author: Other Account <2@gerrit>\n" + "Unresolved: false\n" + "UUID: uuid1\n" + "Bytes: 9\n" + "comment 1\n" + "\n" + "2:1-3:1\n" + ChangeNoteUtil.formatTime(serverIdent, time2) + "\n" + "Author: Other Account <2@gerrit>\n" + "Unresolved: false\n" + "UUID: uuid2\n" + "Bytes: 9\n" + "comment 2\n" + "\n" + "File: file2\n" + "\n" + "3:0-4:1\n" + ChangeNoteUtil.formatTime(serverIdent, time3) + "\n" + "Author: Other Account <2@gerrit>\n" + "Unresolved: false\n" + "UUID: uuid3\n" + "Bytes: 9\n" + "comment 3\n" + "\n");
        }
    }
}
#end_block

#method_before
@Test
public void patchLineCommentNotesFormatSide0() throws Exception {
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, otherUser);
    String uuid1 = "uuid1";
    String uuid2 = "uuid2";
    String message1 = "comment 1";
    String message2 = "comment 2";
    CommentRange range1 = new CommentRange(1, 1, 2, 1);
    Timestamp time1 = TimeUtil.nowTs();
    Timestamp time2 = TimeUtil.nowTs();
    PatchSet.Id psId = c.currentPatchSetId();
    Comment comment1 = newComment(psId, "file1", uuid1, range1, range1.getEndLine(), otherUser, null, time1, message1, (short) 0, "abcd1234abcd1234abcd1234abcd1234abcd1234");
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, comment1);
    update.commit();
    update = newUpdate(c, otherUser);
    CommentRange range2 = new CommentRange(2, 1, 3, 1);
    Comment comment2 = newComment(psId, "file1", uuid2, range2, range2.getEndLine(), otherUser, null, time2, message2, (short) 0, "abcd1234abcd1234abcd1234abcd1234abcd1234");
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, comment2);
    update.commit();
    ChangeNotes notes = newNotes(c);
    try (RevWalk walk = new RevWalk(repo)) {
        ArrayList<Note> notesInTree = Lists.newArrayList(notes.revisionNoteMap.noteMap.iterator());
        Note note = Iterables.getOnlyElement(notesInTree);
        byte[] bytes = walk.getObjectReader().open(note.getData(), Constants.OBJ_BLOB).getBytes();
        String noteString = new String(bytes, UTF_8);
        if (!testJson()) {
            assertThat(noteString).isEqualTo("Revision: abcd1234abcd1234abcd1234abcd1234abcd1234\n" + "Base-for-patch-set: 1\n" + "File: file1\n" + "\n" + "1:1-2:1\n" + ChangeNoteUtil.formatTime(serverIdent, time1) + "\n" + "Author: Other Account <2@gerrit>\n" + "UUID: uuid1\n" + "Bytes: 9\n" + "comment 1\n" + "\n" + "2:1-3:1\n" + ChangeNoteUtil.formatTime(serverIdent, time2) + "\n" + "Author: Other Account <2@gerrit>\n" + "UUID: uuid2\n" + "Bytes: 9\n" + "comment 2\n" + "\n");
        }
    }
}
#method_after
@Test
public void patchLineCommentNotesFormatSide0() throws Exception {
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, otherUser);
    String uuid1 = "uuid1";
    String uuid2 = "uuid2";
    String message1 = "comment 1";
    String message2 = "comment 2";
    CommentRange range1 = new CommentRange(1, 1, 2, 1);
    Timestamp time1 = TimeUtil.nowTs();
    Timestamp time2 = TimeUtil.nowTs();
    PatchSet.Id psId = c.currentPatchSetId();
    Comment comment1 = newComment(psId, "file1", uuid1, range1, range1.getEndLine(), otherUser, null, time1, message1, (short) 0, "abcd1234abcd1234abcd1234abcd1234abcd1234", false);
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, comment1);
    update.commit();
    update = newUpdate(c, otherUser);
    CommentRange range2 = new CommentRange(2, 1, 3, 1);
    Comment comment2 = newComment(psId, "file1", uuid2, range2, range2.getEndLine(), otherUser, null, time2, message2, (short) 0, "abcd1234abcd1234abcd1234abcd1234abcd1234", false);
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, comment2);
    update.commit();
    ChangeNotes notes = newNotes(c);
    try (RevWalk walk = new RevWalk(repo)) {
        ArrayList<Note> notesInTree = Lists.newArrayList(notes.revisionNoteMap.noteMap.iterator());
        Note note = Iterables.getOnlyElement(notesInTree);
        byte[] bytes = walk.getObjectReader().open(note.getData(), Constants.OBJ_BLOB).getBytes();
        String noteString = new String(bytes, UTF_8);
        if (!testJson()) {
            assertThat(noteString).isEqualTo("Revision: abcd1234abcd1234abcd1234abcd1234abcd1234\n" + "Base-for-patch-set: 1\n" + "File: file1\n" + "\n" + "1:1-2:1\n" + ChangeNoteUtil.formatTime(serverIdent, time1) + "\n" + "Author: Other Account <2@gerrit>\n" + "Unresolved: false\n" + "UUID: uuid1\n" + "Bytes: 9\n" + "comment 1\n" + "\n" + "2:1-3:1\n" + ChangeNoteUtil.formatTime(serverIdent, time2) + "\n" + "Author: Other Account <2@gerrit>\n" + "Unresolved: false\n" + "UUID: uuid2\n" + "Bytes: 9\n" + "comment 2\n" + "\n");
        }
    }
}
#end_block

#method_before
@Test
public void patchLineCommentNotesFormatMultiplePatchSetsSameRevId() throws Exception {
    Change c = newChange();
    PatchSet.Id psId1 = c.currentPatchSetId();
    incrementPatchSet(c);
    PatchSet.Id psId2 = c.currentPatchSetId();
    String uuid1 = "uuid1";
    String uuid2 = "uuid2";
    String uuid3 = "uuid3";
    String message1 = "comment 1";
    String message2 = "comment 2";
    String message3 = "comment 3";
    CommentRange range1 = new CommentRange(1, 1, 2, 1);
    CommentRange range2 = new CommentRange(2, 1, 3, 1);
    Timestamp time = TimeUtil.nowTs();
    RevId revId = new RevId("abcd1234abcd1234abcd1234abcd1234abcd1234");
    Comment comment1 = newComment(psId1, "file1", uuid1, range1, range1.getEndLine(), otherUser, null, time, message1, (short) 0, revId.get());
    Comment comment2 = newComment(psId1, "file1", uuid2, range2, range2.getEndLine(), otherUser, null, time, message2, (short) 0, revId.get());
    Comment comment3 = newComment(psId2, "file1", uuid3, range1, range1.getEndLine(), otherUser, null, time, message3, (short) 0, revId.get());
    ChangeUpdate update = newUpdate(c, otherUser);
    update.setPatchSetId(psId2);
    update.putComment(Status.PUBLISHED, comment3);
    update.putComment(Status.PUBLISHED, comment2);
    update.putComment(Status.PUBLISHED, comment1);
    update.commit();
    ChangeNotes notes = newNotes(c);
    try (RevWalk walk = new RevWalk(repo)) {
        ArrayList<Note> notesInTree = Lists.newArrayList(notes.revisionNoteMap.noteMap.iterator());
        Note note = Iterables.getOnlyElement(notesInTree);
        byte[] bytes = walk.getObjectReader().open(note.getData(), Constants.OBJ_BLOB).getBytes();
        String noteString = new String(bytes, UTF_8);
        String timeStr = ChangeNoteUtil.formatTime(serverIdent, time);
        if (!testJson()) {
            assertThat(noteString).isEqualTo("Revision: abcd1234abcd1234abcd1234abcd1234abcd1234\n" + "Base-for-patch-set: 1\n" + "File: file1\n" + "\n" + "1:1-2:1\n" + timeStr + "\n" + "Author: Other Account <2@gerrit>\n" + "UUID: uuid1\n" + "Bytes: 9\n" + "comment 1\n" + "\n" + "2:1-3:1\n" + timeStr + "\n" + "Author: Other Account <2@gerrit>\n" + "UUID: uuid2\n" + "Bytes: 9\n" + "comment 2\n" + "\n" + "Base-for-patch-set: 2\n" + "File: file1\n" + "\n" + "1:1-2:1\n" + timeStr + "\n" + "Author: Other Account <2@gerrit>\n" + "UUID: uuid3\n" + "Bytes: 9\n" + "comment 3\n" + "\n");
        }
    }
    assertThat(notes.getComments()).isEqualTo(ImmutableMultimap.of(revId, comment1, revId, comment2, revId, comment3));
}
#method_after
@Test
public void patchLineCommentNotesFormatMultiplePatchSetsSameRevId() throws Exception {
    Change c = newChange();
    PatchSet.Id psId1 = c.currentPatchSetId();
    incrementPatchSet(c);
    PatchSet.Id psId2 = c.currentPatchSetId();
    String uuid1 = "uuid1";
    String uuid2 = "uuid2";
    String uuid3 = "uuid3";
    String message1 = "comment 1";
    String message2 = "comment 2";
    String message3 = "comment 3";
    CommentRange range1 = new CommentRange(1, 1, 2, 1);
    CommentRange range2 = new CommentRange(2, 1, 3, 1);
    Timestamp time = TimeUtil.nowTs();
    RevId revId = new RevId("abcd1234abcd1234abcd1234abcd1234abcd1234");
    Comment comment1 = newComment(psId1, "file1", uuid1, range1, range1.getEndLine(), otherUser, null, time, message1, (short) 0, revId.get(), false);
    Comment comment2 = newComment(psId1, "file1", uuid2, range2, range2.getEndLine(), otherUser, null, time, message2, (short) 0, revId.get(), false);
    Comment comment3 = newComment(psId2, "file1", uuid3, range1, range1.getEndLine(), otherUser, null, time, message3, (short) 0, revId.get(), false);
    ChangeUpdate update = newUpdate(c, otherUser);
    update.setPatchSetId(psId2);
    update.putComment(Status.PUBLISHED, comment3);
    update.putComment(Status.PUBLISHED, comment2);
    update.putComment(Status.PUBLISHED, comment1);
    update.commit();
    ChangeNotes notes = newNotes(c);
    try (RevWalk walk = new RevWalk(repo)) {
        ArrayList<Note> notesInTree = Lists.newArrayList(notes.revisionNoteMap.noteMap.iterator());
        Note note = Iterables.getOnlyElement(notesInTree);
        byte[] bytes = walk.getObjectReader().open(note.getData(), Constants.OBJ_BLOB).getBytes();
        String noteString = new String(bytes, UTF_8);
        String timeStr = ChangeNoteUtil.formatTime(serverIdent, time);
        if (!testJson()) {
            assertThat(noteString).isEqualTo("Revision: abcd1234abcd1234abcd1234abcd1234abcd1234\n" + "Base-for-patch-set: 1\n" + "File: file1\n" + "\n" + "1:1-2:1\n" + timeStr + "\n" + "Author: Other Account <2@gerrit>\n" + "Unresolved: false\n" + "UUID: uuid1\n" + "Bytes: 9\n" + "comment 1\n" + "\n" + "2:1-3:1\n" + timeStr + "\n" + "Author: Other Account <2@gerrit>\n" + "Unresolved: false\n" + "UUID: uuid2\n" + "Bytes: 9\n" + "comment 2\n" + "\n" + "Base-for-patch-set: 2\n" + "File: file1\n" + "\n" + "1:1-2:1\n" + timeStr + "\n" + "Author: Other Account <2@gerrit>\n" + "Unresolved: false\n" + "UUID: uuid3\n" + "Bytes: 9\n" + "comment 3\n" + "\n");
        }
    }
    assertThat(notes.getComments()).isEqualTo(ImmutableMultimap.of(revId, comment1, revId, comment2, revId, comment3));
}
#end_block

#method_before
@Test
public void patchLineCommentNotesFormatRealAuthor() throws Exception {
    Change c = newChange();
    CurrentUser ownerAsOtherUser = userFactory.runAs(null, otherUserId, changeOwner);
    ChangeUpdate update = newUpdate(c, ownerAsOtherUser);
    String uuid = "uuid";
    String message = "comment";
    CommentRange range = new CommentRange(1, 1, 2, 1);
    Timestamp time = TimeUtil.nowTs();
    PatchSet.Id psId = c.currentPatchSetId();
    RevId revId = new RevId("abcd1234abcd1234abcd1234abcd1234abcd1234");
    Comment comment = newComment(psId, "file", uuid, range, range.getEndLine(), otherUser, null, time, message, (short) 1, revId.get());
    comment.setRealAuthor(changeOwner.getAccountId());
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, comment);
    update.commit();
    ChangeNotes notes = newNotes(c);
    try (RevWalk walk = new RevWalk(repo)) {
        ArrayList<Note> notesInTree = Lists.newArrayList(notes.revisionNoteMap.noteMap.iterator());
        Note note = Iterables.getOnlyElement(notesInTree);
        byte[] bytes = walk.getObjectReader().open(note.getData(), Constants.OBJ_BLOB).getBytes();
        String noteString = new String(bytes, UTF_8);
        if (!testJson()) {
            assertThat(noteString).isEqualTo("Revision: abcd1234abcd1234abcd1234abcd1234abcd1234\n" + "Patch-set: 1\n" + "File: file\n" + "\n" + "1:1-2:1\n" + ChangeNoteUtil.formatTime(serverIdent, time) + "\n" + "Author: Other Account <2@gerrit>\n" + "Real-author: Change Owner <1@gerrit>\n" + "UUID: uuid\n" + "Bytes: 7\n" + "comment\n" + "\n");
        }
    }
    assertThat(notes.getComments()).isEqualTo(ImmutableMultimap.of(revId, comment));
}
#method_after
@Test
public void patchLineCommentNotesFormatRealAuthor() throws Exception {
    Change c = newChange();
    CurrentUser ownerAsOtherUser = userFactory.runAs(null, otherUserId, changeOwner);
    ChangeUpdate update = newUpdate(c, ownerAsOtherUser);
    String uuid = "uuid";
    String message = "comment";
    CommentRange range = new CommentRange(1, 1, 2, 1);
    Timestamp time = TimeUtil.nowTs();
    PatchSet.Id psId = c.currentPatchSetId();
    RevId revId = new RevId("abcd1234abcd1234abcd1234abcd1234abcd1234");
    Comment comment = newComment(psId, "file", uuid, range, range.getEndLine(), otherUser, null, time, message, (short) 1, revId.get(), false);
    comment.setRealAuthor(changeOwner.getAccountId());
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, comment);
    update.commit();
    ChangeNotes notes = newNotes(c);
    try (RevWalk walk = new RevWalk(repo)) {
        ArrayList<Note> notesInTree = Lists.newArrayList(notes.revisionNoteMap.noteMap.iterator());
        Note note = Iterables.getOnlyElement(notesInTree);
        byte[] bytes = walk.getObjectReader().open(note.getData(), Constants.OBJ_BLOB).getBytes();
        String noteString = new String(bytes, UTF_8);
        if (!testJson()) {
            assertThat(noteString).isEqualTo("Revision: abcd1234abcd1234abcd1234abcd1234abcd1234\n" + "Patch-set: 1\n" + "File: file\n" + "\n" + "1:1-2:1\n" + ChangeNoteUtil.formatTime(serverIdent, time) + "\n" + "Author: Other Account <2@gerrit>\n" + "Real-author: Change Owner <1@gerrit>\n" + "Unresolved: false\n" + "UUID: uuid\n" + "Bytes: 7\n" + "comment\n" + "\n");
        }
    }
    assertThat(notes.getComments()).isEqualTo(ImmutableMultimap.of(revId, comment));
}
#end_block

#method_before
@Test
public void patchLineCommentNotesFormatWeirdUser() throws Exception {
    Account account = new Account(new Account.Id(3), TimeUtil.nowTs());
    account.setFullName("Weird\n\u0002<User>\n");
    account.setPreferredEmail(" we\r\nird@ex>ample<.com");
    accountCache.put(account);
    IdentifiedUser user = userFactory.create(account.getId());
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, user);
    String uuid = "uuid";
    CommentRange range = new CommentRange(1, 1, 2, 1);
    Timestamp time = TimeUtil.nowTs();
    PatchSet.Id psId = c.currentPatchSetId();
    Comment comment = newComment(psId, "file1", uuid, range, range.getEndLine(), user, null, time, "comment", (short) 1, "abcd1234abcd1234abcd1234abcd1234abcd1234");
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, comment);
    update.commit();
    ChangeNotes notes = newNotes(c);
    try (RevWalk walk = new RevWalk(repo)) {
        ArrayList<Note> notesInTree = Lists.newArrayList(notes.revisionNoteMap.noteMap.iterator());
        Note note = Iterables.getOnlyElement(notesInTree);
        byte[] bytes = walk.getObjectReader().open(note.getData(), Constants.OBJ_BLOB).getBytes();
        String noteString = new String(bytes, UTF_8);
        String timeStr = ChangeNoteUtil.formatTime(serverIdent, time);
        if (!testJson()) {
            assertThat(noteString).isEqualTo("Revision: abcd1234abcd1234abcd1234abcd1234abcd1234\n" + "Patch-set: 1\n" + "File: file1\n" + "\n" + "1:1-2:1\n" + timeStr + "\n" + "Author: Weird\u0002User <3@gerrit>\n" + "UUID: uuid\n" + "Bytes: 7\n" + "comment\n" + "\n");
        }
    }
    assertThat(notes.getComments()).isEqualTo(ImmutableMultimap.of(new RevId(comment.revId), comment));
}
#method_after
@Test
public void patchLineCommentNotesFormatWeirdUser() throws Exception {
    Account account = new Account(new Account.Id(3), TimeUtil.nowTs());
    account.setFullName("Weird\n\u0002<User>\n");
    account.setPreferredEmail(" we\r\nird@ex>ample<.com");
    accountCache.put(account);
    IdentifiedUser user = userFactory.create(account.getId());
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, user);
    String uuid = "uuid";
    CommentRange range = new CommentRange(1, 1, 2, 1);
    Timestamp time = TimeUtil.nowTs();
    PatchSet.Id psId = c.currentPatchSetId();
    Comment comment = newComment(psId, "file1", uuid, range, range.getEndLine(), user, null, time, "comment", (short) 1, "abcd1234abcd1234abcd1234abcd1234abcd1234", false);
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, comment);
    update.commit();
    ChangeNotes notes = newNotes(c);
    try (RevWalk walk = new RevWalk(repo)) {
        ArrayList<Note> notesInTree = Lists.newArrayList(notes.revisionNoteMap.noteMap.iterator());
        Note note = Iterables.getOnlyElement(notesInTree);
        byte[] bytes = walk.getObjectReader().open(note.getData(), Constants.OBJ_BLOB).getBytes();
        String noteString = new String(bytes, UTF_8);
        String timeStr = ChangeNoteUtil.formatTime(serverIdent, time);
        if (!testJson()) {
            assertThat(noteString).isEqualTo("Revision: abcd1234abcd1234abcd1234abcd1234abcd1234\n" + "Patch-set: 1\n" + "File: file1\n" + "\n" + "1:1-2:1\n" + timeStr + "\n" + "Author: Weird\u0002User <3@gerrit>\n" + "Unresolved: false\n" + "UUID: uuid\n" + "Bytes: 7\n" + "comment\n" + "\n");
        }
    }
    assertThat(notes.getComments()).isEqualTo(ImmutableMultimap.of(new RevId(comment.revId), comment));
}
#end_block

#method_before
@Test
public void patchLineCommentMultipleOnePatchsetOneFileBothSides() throws Exception {
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, otherUser);
    String uuid1 = "uuid1";
    String uuid2 = "uuid2";
    String rev1 = "abcd1234abcd1234abcd1234abcd1234abcd1234";
    String rev2 = "abcd4567abcd4567abcd4567abcd4567abcd4567";
    String messageForBase = "comment for base";
    String messageForPS = "comment for ps";
    CommentRange range = new CommentRange(1, 1, 2, 1);
    Timestamp now = TimeUtil.nowTs();
    PatchSet.Id psId = c.currentPatchSetId();
    Comment commentForBase = newComment(psId, "filename", uuid1, range, range.getEndLine(), otherUser, null, now, messageForBase, (short) 0, rev1);
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, commentForBase);
    update.commit();
    update = newUpdate(c, otherUser);
    Comment commentForPS = newComment(psId, "filename", uuid2, range, range.getEndLine(), otherUser, null, now, messageForPS, (short) 1, rev2);
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, commentForPS);
    update.commit();
    assertThat(newNotes(c).getComments()).containsExactlyEntriesIn(ImmutableMultimap.of(new RevId(rev1), commentForBase, new RevId(rev2), commentForPS));
}
#method_after
@Test
public void patchLineCommentMultipleOnePatchsetOneFileBothSides() throws Exception {
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, otherUser);
    String uuid1 = "uuid1";
    String uuid2 = "uuid2";
    String rev1 = "abcd1234abcd1234abcd1234abcd1234abcd1234";
    String rev2 = "abcd4567abcd4567abcd4567abcd4567abcd4567";
    String messageForBase = "comment for base";
    String messageForPS = "comment for ps";
    CommentRange range = new CommentRange(1, 1, 2, 1);
    Timestamp now = TimeUtil.nowTs();
    PatchSet.Id psId = c.currentPatchSetId();
    Comment commentForBase = newComment(psId, "filename", uuid1, range, range.getEndLine(), otherUser, null, now, messageForBase, (short) 0, rev1, false);
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, commentForBase);
    update.commit();
    update = newUpdate(c, otherUser);
    Comment commentForPS = newComment(psId, "filename", uuid2, range, range.getEndLine(), otherUser, null, now, messageForPS, (short) 1, rev2, false);
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, commentForPS);
    update.commit();
    assertThat(newNotes(c).getComments()).containsExactlyEntriesIn(ImmutableMultimap.of(new RevId(rev1), commentForBase, new RevId(rev2), commentForPS));
}
#end_block

#method_before
@Test
public void patchLineCommentMultipleOnePatchsetOneFile() throws Exception {
    Change c = newChange();
    String uuid1 = "uuid1";
    String uuid2 = "uuid2";
    String rev = "abcd1234abcd1234abcd1234abcd1234abcd1234";
    CommentRange range = new CommentRange(1, 1, 2, 1);
    PatchSet.Id psId = c.currentPatchSetId();
    String filename = "filename";
    short side = (short) 1;
    ChangeUpdate update = newUpdate(c, otherUser);
    Timestamp timeForComment1 = TimeUtil.nowTs();
    Timestamp timeForComment2 = TimeUtil.nowTs();
    Comment comment1 = newComment(psId, filename, uuid1, range, range.getEndLine(), otherUser, null, timeForComment1, "comment 1", side, rev);
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, comment1);
    update.commit();
    update = newUpdate(c, otherUser);
    Comment comment2 = newComment(psId, filename, uuid2, range, range.getEndLine(), otherUser, null, timeForComment2, "comment 2", side, rev);
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, comment2);
    update.commit();
    assertThat(newNotes(c).getComments()).containsExactlyEntriesIn(ImmutableMultimap.of(new RevId(rev), comment1, new RevId(rev), comment2)).inOrder();
}
#method_after
@Test
public void patchLineCommentMultipleOnePatchsetOneFile() throws Exception {
    Change c = newChange();
    String uuid1 = "uuid1";
    String uuid2 = "uuid2";
    String rev = "abcd1234abcd1234abcd1234abcd1234abcd1234";
    CommentRange range = new CommentRange(1, 1, 2, 1);
    PatchSet.Id psId = c.currentPatchSetId();
    String filename = "filename";
    short side = (short) 1;
    ChangeUpdate update = newUpdate(c, otherUser);
    Timestamp timeForComment1 = TimeUtil.nowTs();
    Timestamp timeForComment2 = TimeUtil.nowTs();
    Comment comment1 = newComment(psId, filename, uuid1, range, range.getEndLine(), otherUser, null, timeForComment1, "comment 1", side, rev, false);
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, comment1);
    update.commit();
    update = newUpdate(c, otherUser);
    Comment comment2 = newComment(psId, filename, uuid2, range, range.getEndLine(), otherUser, null, timeForComment2, "comment 2", side, rev, false);
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, comment2);
    update.commit();
    assertThat(newNotes(c).getComments()).containsExactlyEntriesIn(ImmutableMultimap.of(new RevId(rev), comment1, new RevId(rev), comment2)).inOrder();
}
#end_block

#method_before
@Test
public void patchLineCommentMultipleOnePatchsetMultipleFiles() throws Exception {
    Change c = newChange();
    String uuid = "uuid";
    String rev = "abcd1234abcd1234abcd1234abcd1234abcd1234";
    CommentRange range = new CommentRange(1, 1, 2, 1);
    PatchSet.Id psId = c.currentPatchSetId();
    String filename1 = "filename1";
    String filename2 = "filename2";
    short side = (short) 1;
    ChangeUpdate update = newUpdate(c, otherUser);
    Timestamp now = TimeUtil.nowTs();
    Comment comment1 = newComment(psId, filename1, uuid, range, range.getEndLine(), otherUser, null, now, "comment 1", side, rev);
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, comment1);
    update.commit();
    update = newUpdate(c, otherUser);
    Comment comment2 = newComment(psId, filename2, uuid, range, range.getEndLine(), otherUser, null, now, "comment 2", side, rev);
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, comment2);
    update.commit();
    assertThat(newNotes(c).getComments()).containsExactlyEntriesIn(ImmutableMultimap.of(new RevId(rev), comment1, new RevId(rev), comment2)).inOrder();
}
#method_after
@Test
public void patchLineCommentMultipleOnePatchsetMultipleFiles() throws Exception {
    Change c = newChange();
    String uuid = "uuid";
    String rev = "abcd1234abcd1234abcd1234abcd1234abcd1234";
    CommentRange range = new CommentRange(1, 1, 2, 1);
    PatchSet.Id psId = c.currentPatchSetId();
    String filename1 = "filename1";
    String filename2 = "filename2";
    short side = (short) 1;
    ChangeUpdate update = newUpdate(c, otherUser);
    Timestamp now = TimeUtil.nowTs();
    Comment comment1 = newComment(psId, filename1, uuid, range, range.getEndLine(), otherUser, null, now, "comment 1", side, rev, false);
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, comment1);
    update.commit();
    update = newUpdate(c, otherUser);
    Comment comment2 = newComment(psId, filename2, uuid, range, range.getEndLine(), otherUser, null, now, "comment 2", side, rev, false);
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, comment2);
    update.commit();
    assertThat(newNotes(c).getComments()).containsExactlyEntriesIn(ImmutableMultimap.of(new RevId(rev), comment1, new RevId(rev), comment2)).inOrder();
}
#end_block

#method_before
@Test
public void patchLineCommentMultiplePatchsets() throws Exception {
    Change c = newChange();
    String uuid = "uuid";
    String rev1 = "abcd1234abcd1234abcd1234abcd1234abcd1234";
    String rev2 = "abcd4567abcd4567abcd4567abcd4567abcd4567";
    CommentRange range = new CommentRange(1, 1, 2, 1);
    PatchSet.Id ps1 = c.currentPatchSetId();
    String filename = "filename1";
    short side = (short) 1;
    ChangeUpdate update = newUpdate(c, otherUser);
    Timestamp now = TimeUtil.nowTs();
    Comment comment1 = newComment(ps1, filename, uuid, range, range.getEndLine(), otherUser, null, now, "comment on ps1", side, rev1);
    update.setPatchSetId(ps1);
    update.putComment(Status.PUBLISHED, comment1);
    update.commit();
    incrementPatchSet(c);
    PatchSet.Id ps2 = c.currentPatchSetId();
    update = newUpdate(c, otherUser);
    now = TimeUtil.nowTs();
    Comment comment2 = newComment(ps2, filename, uuid, range, range.getEndLine(), otherUser, null, now, "comment on ps2", side, rev2);
    update.setPatchSetId(ps2);
    update.putComment(Status.PUBLISHED, comment2);
    update.commit();
    assertThat(newNotes(c).getComments()).containsExactlyEntriesIn(ImmutableMultimap.of(new RevId(rev1), comment1, new RevId(rev2), comment2));
}
#method_after
@Test
public void patchLineCommentMultiplePatchsets() throws Exception {
    Change c = newChange();
    String uuid = "uuid";
    String rev1 = "abcd1234abcd1234abcd1234abcd1234abcd1234";
    String rev2 = "abcd4567abcd4567abcd4567abcd4567abcd4567";
    CommentRange range = new CommentRange(1, 1, 2, 1);
    PatchSet.Id ps1 = c.currentPatchSetId();
    String filename = "filename1";
    short side = (short) 1;
    ChangeUpdate update = newUpdate(c, otherUser);
    Timestamp now = TimeUtil.nowTs();
    Comment comment1 = newComment(ps1, filename, uuid, range, range.getEndLine(), otherUser, null, now, "comment on ps1", side, rev1, false);
    update.setPatchSetId(ps1);
    update.putComment(Status.PUBLISHED, comment1);
    update.commit();
    incrementPatchSet(c);
    PatchSet.Id ps2 = c.currentPatchSetId();
    update = newUpdate(c, otherUser);
    now = TimeUtil.nowTs();
    Comment comment2 = newComment(ps2, filename, uuid, range, range.getEndLine(), otherUser, null, now, "comment on ps2", side, rev2, false);
    update.setPatchSetId(ps2);
    update.putComment(Status.PUBLISHED, comment2);
    update.commit();
    assertThat(newNotes(c).getComments()).containsExactlyEntriesIn(ImmutableMultimap.of(new RevId(rev1), comment1, new RevId(rev2), comment2));
}
#end_block

#method_before
@Test
public void patchLineCommentSingleDraftToPublished() throws Exception {
    Change c = newChange();
    String uuid = "uuid";
    String rev = "abcd4567abcd4567abcd4567abcd4567abcd4567";
    CommentRange range = new CommentRange(1, 1, 2, 1);
    PatchSet.Id ps1 = c.currentPatchSetId();
    String filename = "filename1";
    short side = (short) 1;
    ChangeUpdate update = newUpdate(c, otherUser);
    Timestamp now = TimeUtil.nowTs();
    Comment comment1 = newComment(ps1, filename, uuid, range, range.getEndLine(), otherUser, null, now, "comment on ps1", side, rev);
    update.setPatchSetId(ps1);
    update.putComment(Status.DRAFT, comment1);
    update.commit();
    ChangeNotes notes = newNotes(c);
    assertThat(notes.getDraftComments(otherUserId)).containsExactlyEntriesIn(ImmutableMultimap.of(new RevId(rev), comment1));
    assertThat(notes.getComments()).isEmpty();
    update = newUpdate(c, otherUser);
    update.setPatchSetId(ps1);
    update.putComment(Status.PUBLISHED, comment1);
    update.commit();
    notes = newNotes(c);
    assertThat(notes.getDraftComments(otherUserId)).isEmpty();
    assertThat(notes.getComments()).containsExactlyEntriesIn(ImmutableMultimap.of(new RevId(rev), comment1));
}
#method_after
@Test
public void patchLineCommentSingleDraftToPublished() throws Exception {
    Change c = newChange();
    String uuid = "uuid";
    String rev = "abcd4567abcd4567abcd4567abcd4567abcd4567";
    CommentRange range = new CommentRange(1, 1, 2, 1);
    PatchSet.Id ps1 = c.currentPatchSetId();
    String filename = "filename1";
    short side = (short) 1;
    ChangeUpdate update = newUpdate(c, otherUser);
    Timestamp now = TimeUtil.nowTs();
    Comment comment1 = newComment(ps1, filename, uuid, range, range.getEndLine(), otherUser, null, now, "comment on ps1", side, rev, false);
    update.setPatchSetId(ps1);
    update.putComment(Status.DRAFT, comment1);
    update.commit();
    ChangeNotes notes = newNotes(c);
    assertThat(notes.getDraftComments(otherUserId)).containsExactlyEntriesIn(ImmutableMultimap.of(new RevId(rev), comment1));
    assertThat(notes.getComments()).isEmpty();
    update = newUpdate(c, otherUser);
    update.setPatchSetId(ps1);
    update.putComment(Status.PUBLISHED, comment1);
    update.commit();
    notes = newNotes(c);
    assertThat(notes.getDraftComments(otherUserId)).isEmpty();
    assertThat(notes.getComments()).containsExactlyEntriesIn(ImmutableMultimap.of(new RevId(rev), comment1));
}
#end_block

#method_before
@Test
public void patchLineCommentMultipleDraftsSameSidePublishOne() throws Exception {
    Change c = newChange();
    String uuid1 = "uuid1";
    String uuid2 = "uuid2";
    String rev = "abcd4567abcd4567abcd4567abcd4567abcd4567";
    CommentRange range1 = new CommentRange(1, 1, 2, 2);
    CommentRange range2 = new CommentRange(2, 2, 3, 3);
    String filename = "filename1";
    short side = (short) 1;
    Timestamp now = TimeUtil.nowTs();
    PatchSet.Id psId = c.currentPatchSetId();
    // Write two drafts on the same side of one patch set.
    ChangeUpdate update = newUpdate(c, otherUser);
    update.setPatchSetId(psId);
    Comment comment1 = newComment(psId, filename, uuid1, range1, range1.getEndLine(), otherUser, null, now, "comment on ps1", side, rev);
    Comment comment2 = newComment(psId, filename, uuid2, range2, range2.getEndLine(), otherUser, null, now, "other on ps1", side, rev);
    update.putComment(Status.DRAFT, comment1);
    update.putComment(Status.DRAFT, comment2);
    update.commit();
    ChangeNotes notes = newNotes(c);
    assertThat(notes.getDraftComments(otherUserId)).containsExactlyEntriesIn(ImmutableMultimap.of(new RevId(rev), comment1, new RevId(rev), comment2)).inOrder();
    assertThat(notes.getComments()).isEmpty();
    // Publish first draft.
    update = newUpdate(c, otherUser);
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, comment1);
    update.commit();
    notes = newNotes(c);
    assertThat(notes.getDraftComments(otherUserId)).containsExactlyEntriesIn(ImmutableMultimap.of(new RevId(rev), comment2));
    assertThat(notes.getComments()).containsExactlyEntriesIn(ImmutableMultimap.of(new RevId(rev), comment1));
}
#method_after
@Test
public void patchLineCommentMultipleDraftsSameSidePublishOne() throws Exception {
    Change c = newChange();
    String uuid1 = "uuid1";
    String uuid2 = "uuid2";
    String rev = "abcd4567abcd4567abcd4567abcd4567abcd4567";
    CommentRange range1 = new CommentRange(1, 1, 2, 2);
    CommentRange range2 = new CommentRange(2, 2, 3, 3);
    String filename = "filename1";
    short side = (short) 1;
    Timestamp now = TimeUtil.nowTs();
    PatchSet.Id psId = c.currentPatchSetId();
    // Write two drafts on the same side of one patch set.
    ChangeUpdate update = newUpdate(c, otherUser);
    update.setPatchSetId(psId);
    Comment comment1 = newComment(psId, filename, uuid1, range1, range1.getEndLine(), otherUser, null, now, "comment on ps1", side, rev, false);
    Comment comment2 = newComment(psId, filename, uuid2, range2, range2.getEndLine(), otherUser, null, now, "other on ps1", side, rev, false);
    update.putComment(Status.DRAFT, comment1);
    update.putComment(Status.DRAFT, comment2);
    update.commit();
    ChangeNotes notes = newNotes(c);
    assertThat(notes.getDraftComments(otherUserId)).containsExactlyEntriesIn(ImmutableMultimap.of(new RevId(rev), comment1, new RevId(rev), comment2)).inOrder();
    assertThat(notes.getComments()).isEmpty();
    // Publish first draft.
    update = newUpdate(c, otherUser);
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, comment1);
    update.commit();
    notes = newNotes(c);
    assertThat(notes.getDraftComments(otherUserId)).containsExactlyEntriesIn(ImmutableMultimap.of(new RevId(rev), comment2));
    assertThat(notes.getComments()).containsExactlyEntriesIn(ImmutableMultimap.of(new RevId(rev), comment1));
}
#end_block

#method_before
@Test
public void patchLineCommentsMultipleDraftsBothSidesPublishAll() throws Exception {
    Change c = newChange();
    String uuid1 = "uuid1";
    String uuid2 = "uuid2";
    String rev1 = "abcd1234abcd1234abcd1234abcd1234abcd1234";
    String rev2 = "abcd4567abcd4567abcd4567abcd4567abcd4567";
    CommentRange range1 = new CommentRange(1, 1, 2, 2);
    CommentRange range2 = new CommentRange(2, 2, 3, 3);
    String filename = "filename1";
    Timestamp now = TimeUtil.nowTs();
    PatchSet.Id psId = c.currentPatchSetId();
    // Write two drafts, one on each side of the patchset.
    ChangeUpdate update = newUpdate(c, otherUser);
    update.setPatchSetId(psId);
    Comment baseComment = newComment(psId, filename, uuid1, range1, range1.getEndLine(), otherUser, null, now, "comment on base", (short) 0, rev1);
    Comment psComment = newComment(psId, filename, uuid2, range2, range2.getEndLine(), otherUser, null, now, "comment on ps", (short) 1, rev2);
    update.putComment(Status.DRAFT, baseComment);
    update.putComment(Status.DRAFT, psComment);
    update.commit();
    ChangeNotes notes = newNotes(c);
    assertThat(notes.getDraftComments(otherUserId)).containsExactlyEntriesIn(ImmutableMultimap.of(new RevId(rev1), baseComment, new RevId(rev2), psComment));
    assertThat(notes.getComments()).isEmpty();
    // Publish both comments.
    update = newUpdate(c, otherUser);
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, baseComment);
    update.putComment(Status.PUBLISHED, psComment);
    update.commit();
    notes = newNotes(c);
    assertThat(notes.getDraftComments(otherUserId)).isEmpty();
    assertThat(notes.getComments()).containsExactlyEntriesIn(ImmutableMultimap.of(new RevId(rev1), baseComment, new RevId(rev2), psComment));
}
#method_after
@Test
public void patchLineCommentsMultipleDraftsBothSidesPublishAll() throws Exception {
    Change c = newChange();
    String uuid1 = "uuid1";
    String uuid2 = "uuid2";
    String rev1 = "abcd1234abcd1234abcd1234abcd1234abcd1234";
    String rev2 = "abcd4567abcd4567abcd4567abcd4567abcd4567";
    CommentRange range1 = new CommentRange(1, 1, 2, 2);
    CommentRange range2 = new CommentRange(2, 2, 3, 3);
    String filename = "filename1";
    Timestamp now = TimeUtil.nowTs();
    PatchSet.Id psId = c.currentPatchSetId();
    // Write two drafts, one on each side of the patchset.
    ChangeUpdate update = newUpdate(c, otherUser);
    update.setPatchSetId(psId);
    Comment baseComment = newComment(psId, filename, uuid1, range1, range1.getEndLine(), otherUser, null, now, "comment on base", (short) 0, rev1, false);
    Comment psComment = newComment(psId, filename, uuid2, range2, range2.getEndLine(), otherUser, null, now, "comment on ps", (short) 1, rev2, false);
    update.putComment(Status.DRAFT, baseComment);
    update.putComment(Status.DRAFT, psComment);
    update.commit();
    ChangeNotes notes = newNotes(c);
    assertThat(notes.getDraftComments(otherUserId)).containsExactlyEntriesIn(ImmutableMultimap.of(new RevId(rev1), baseComment, new RevId(rev2), psComment));
    assertThat(notes.getComments()).isEmpty();
    // Publish both comments.
    update = newUpdate(c, otherUser);
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, baseComment);
    update.putComment(Status.PUBLISHED, psComment);
    update.commit();
    notes = newNotes(c);
    assertThat(notes.getDraftComments(otherUserId)).isEmpty();
    assertThat(notes.getComments()).containsExactlyEntriesIn(ImmutableMultimap.of(new RevId(rev1), baseComment, new RevId(rev2), psComment));
}
#end_block

#method_before
@Test
public void patchLineCommentsDeleteAllDrafts() throws Exception {
    Change c = newChange();
    String uuid = "uuid";
    String rev = "abcd1234abcd1234abcd1234abcd1234abcd1234";
    ObjectId objId = ObjectId.fromString(rev);
    CommentRange range = new CommentRange(1, 1, 2, 1);
    PatchSet.Id psId = c.currentPatchSetId();
    String filename = "filename";
    short side = (short) 1;
    ChangeUpdate update = newUpdate(c, otherUser);
    Timestamp now = TimeUtil.nowTs();
    Comment comment = newComment(psId, filename, uuid, range, range.getEndLine(), otherUser, null, now, "comment on ps1", side, rev);
    update.setPatchSetId(psId);
    update.putComment(Status.DRAFT, comment);
    update.commit();
    ChangeNotes notes = newNotes(c);
    assertThat(notes.getDraftComments(otherUserId)).hasSize(1);
    assertThat(notes.getDraftCommentNotes().getNoteMap().contains(objId)).isTrue();
    update = newUpdate(c, otherUser);
    now = TimeUtil.nowTs();
    update.setPatchSetId(psId);
    update.deleteComment(comment);
    update.commit();
    notes = newNotes(c);
    assertThat(notes.getDraftComments(otherUserId)).isEmpty();
    assertThat(notes.getDraftCommentNotes().getNoteMap()).isNull();
}
#method_after
@Test
public void patchLineCommentsDeleteAllDrafts() throws Exception {
    Change c = newChange();
    String uuid = "uuid";
    String rev = "abcd1234abcd1234abcd1234abcd1234abcd1234";
    ObjectId objId = ObjectId.fromString(rev);
    CommentRange range = new CommentRange(1, 1, 2, 1);
    PatchSet.Id psId = c.currentPatchSetId();
    String filename = "filename";
    short side = (short) 1;
    ChangeUpdate update = newUpdate(c, otherUser);
    Timestamp now = TimeUtil.nowTs();
    Comment comment = newComment(psId, filename, uuid, range, range.getEndLine(), otherUser, null, now, "comment on ps1", side, rev, false);
    update.setPatchSetId(psId);
    update.putComment(Status.DRAFT, comment);
    update.commit();
    ChangeNotes notes = newNotes(c);
    assertThat(notes.getDraftComments(otherUserId)).hasSize(1);
    assertThat(notes.getDraftCommentNotes().getNoteMap().contains(objId)).isTrue();
    update = newUpdate(c, otherUser);
    now = TimeUtil.nowTs();
    update.setPatchSetId(psId);
    update.deleteComment(comment);
    update.commit();
    notes = newNotes(c);
    assertThat(notes.getDraftComments(otherUserId)).isEmpty();
    assertThat(notes.getDraftCommentNotes().getNoteMap()).isNull();
}
#end_block

#method_before
@Test
public void patchLineCommentsDeleteAllDraftsForOneRevision() throws Exception {
    Change c = newChange();
    String uuid = "uuid";
    String rev1 = "abcd1234abcd1234abcd1234abcd1234abcd1234";
    String rev2 = "abcd4567abcd4567abcd4567abcd4567abcd4567";
    ObjectId objId1 = ObjectId.fromString(rev1);
    ObjectId objId2 = ObjectId.fromString(rev2);
    CommentRange range = new CommentRange(1, 1, 2, 1);
    PatchSet.Id ps1 = c.currentPatchSetId();
    String filename = "filename1";
    short side = (short) 1;
    ChangeUpdate update = newUpdate(c, otherUser);
    Timestamp now = TimeUtil.nowTs();
    Comment comment1 = newComment(ps1, filename, uuid, range, range.getEndLine(), otherUser, null, now, "comment on ps1", side, rev1);
    update.setPatchSetId(ps1);
    update.putComment(Status.DRAFT, comment1);
    update.commit();
    incrementPatchSet(c);
    PatchSet.Id ps2 = c.currentPatchSetId();
    update = newUpdate(c, otherUser);
    now = TimeUtil.nowTs();
    Comment comment2 = newComment(ps2, filename, uuid, range, range.getEndLine(), otherUser, null, now, "comment on ps2", side, rev2);
    update.setPatchSetId(ps2);
    update.putComment(Status.DRAFT, comment2);
    update.commit();
    ChangeNotes notes = newNotes(c);
    assertThat(notes.getDraftComments(otherUserId)).hasSize(2);
    update = newUpdate(c, otherUser);
    now = TimeUtil.nowTs();
    update.setPatchSetId(ps2);
    update.deleteComment(comment2);
    update.commit();
    notes = newNotes(c);
    assertThat(notes.getDraftComments(otherUserId)).hasSize(1);
    NoteMap noteMap = notes.getDraftCommentNotes().getNoteMap();
    assertThat(noteMap.contains(objId1)).isTrue();
    assertThat(noteMap.contains(objId2)).isFalse();
}
#method_after
@Test
public void patchLineCommentsDeleteAllDraftsForOneRevision() throws Exception {
    Change c = newChange();
    String uuid = "uuid";
    String rev1 = "abcd1234abcd1234abcd1234abcd1234abcd1234";
    String rev2 = "abcd4567abcd4567abcd4567abcd4567abcd4567";
    ObjectId objId1 = ObjectId.fromString(rev1);
    ObjectId objId2 = ObjectId.fromString(rev2);
    CommentRange range = new CommentRange(1, 1, 2, 1);
    PatchSet.Id ps1 = c.currentPatchSetId();
    String filename = "filename1";
    short side = (short) 1;
    ChangeUpdate update = newUpdate(c, otherUser);
    Timestamp now = TimeUtil.nowTs();
    Comment comment1 = newComment(ps1, filename, uuid, range, range.getEndLine(), otherUser, null, now, "comment on ps1", side, rev1, false);
    update.setPatchSetId(ps1);
    update.putComment(Status.DRAFT, comment1);
    update.commit();
    incrementPatchSet(c);
    PatchSet.Id ps2 = c.currentPatchSetId();
    update = newUpdate(c, otherUser);
    now = TimeUtil.nowTs();
    Comment comment2 = newComment(ps2, filename, uuid, range, range.getEndLine(), otherUser, null, now, "comment on ps2", side, rev2, false);
    update.setPatchSetId(ps2);
    update.putComment(Status.DRAFT, comment2);
    update.commit();
    ChangeNotes notes = newNotes(c);
    assertThat(notes.getDraftComments(otherUserId)).hasSize(2);
    update = newUpdate(c, otherUser);
    now = TimeUtil.nowTs();
    update.setPatchSetId(ps2);
    update.deleteComment(comment2);
    update.commit();
    notes = newNotes(c);
    assertThat(notes.getDraftComments(otherUserId)).hasSize(1);
    NoteMap noteMap = notes.getDraftCommentNotes().getNoteMap();
    assertThat(noteMap.contains(objId1)).isTrue();
    assertThat(noteMap.contains(objId2)).isFalse();
}
#end_block

#method_before
@Test
public void addingPublishedCommentDoesNotCreateNoOpCommitOnEmptyDraftRef() throws Exception {
    Change c = newChange();
    String uuid = "uuid";
    String rev = "abcd4567abcd4567abcd4567abcd4567abcd4567";
    CommentRange range = new CommentRange(1, 1, 2, 1);
    PatchSet.Id ps1 = c.currentPatchSetId();
    String filename = "filename1";
    short side = (short) 1;
    ChangeUpdate update = newUpdate(c, otherUser);
    Timestamp now = TimeUtil.nowTs();
    Comment comment = newComment(ps1, filename, uuid, range, range.getEndLine(), otherUser, null, now, "comment on ps1", side, rev);
    update.putComment(Status.PUBLISHED, comment);
    update.commit();
    assertThat(repo.exactRef(changeMetaRef(c.getId()))).isNotNull();
    String draftRef = refsDraftComments(c.getId(), otherUser.getAccountId());
    assertThat(exactRefAllUsers(draftRef)).isNull();
}
#method_after
@Test
public void addingPublishedCommentDoesNotCreateNoOpCommitOnEmptyDraftRef() throws Exception {
    Change c = newChange();
    String uuid = "uuid";
    String rev = "abcd4567abcd4567abcd4567abcd4567abcd4567";
    CommentRange range = new CommentRange(1, 1, 2, 1);
    PatchSet.Id ps1 = c.currentPatchSetId();
    String filename = "filename1";
    short side = (short) 1;
    ChangeUpdate update = newUpdate(c, otherUser);
    Timestamp now = TimeUtil.nowTs();
    Comment comment = newComment(ps1, filename, uuid, range, range.getEndLine(), otherUser, null, now, "comment on ps1", side, rev, false);
    update.putComment(Status.PUBLISHED, comment);
    update.commit();
    assertThat(repo.exactRef(changeMetaRef(c.getId()))).isNotNull();
    String draftRef = refsDraftComments(c.getId(), otherUser.getAccountId());
    assertThat(exactRefAllUsers(draftRef)).isNull();
}
#end_block

#method_before
@Test
public void addingPublishedCommentDoesNotCreateNoOpCommitOnNonEmptyDraftRef() throws Exception {
    Change c = newChange();
    String rev = "abcd4567abcd4567abcd4567abcd4567abcd4567";
    CommentRange range = new CommentRange(1, 1, 2, 1);
    PatchSet.Id ps1 = c.currentPatchSetId();
    String filename = "filename1";
    short side = (short) 1;
    ChangeUpdate update = newUpdate(c, otherUser);
    Timestamp now = TimeUtil.nowTs();
    Comment draft = newComment(ps1, filename, "uuid1", range, range.getEndLine(), otherUser, null, now, "draft comment on ps1", side, rev);
    update.putComment(Status.DRAFT, draft);
    update.commit();
    String draftRef = refsDraftComments(c.getId(), otherUser.getAccountId());
    ObjectId old = exactRefAllUsers(draftRef);
    assertThat(old).isNotNull();
    update = newUpdate(c, otherUser);
    Comment pub = newComment(ps1, filename, "uuid2", range, range.getEndLine(), otherUser, null, now, "comment on ps1", side, rev);
    update.putComment(Status.PUBLISHED, pub);
    update.commit();
    assertThat(exactRefAllUsers(draftRef)).isEqualTo(old);
}
#method_after
@Test
public void addingPublishedCommentDoesNotCreateNoOpCommitOnNonEmptyDraftRef() throws Exception {
    Change c = newChange();
    String rev = "abcd4567abcd4567abcd4567abcd4567abcd4567";
    CommentRange range = new CommentRange(1, 1, 2, 1);
    PatchSet.Id ps1 = c.currentPatchSetId();
    String filename = "filename1";
    short side = (short) 1;
    ChangeUpdate update = newUpdate(c, otherUser);
    Timestamp now = TimeUtil.nowTs();
    Comment draft = newComment(ps1, filename, "uuid1", range, range.getEndLine(), otherUser, null, now, "draft comment on ps1", side, rev, false);
    update.putComment(Status.DRAFT, draft);
    update.commit();
    String draftRef = refsDraftComments(c.getId(), otherUser.getAccountId());
    ObjectId old = exactRefAllUsers(draftRef);
    assertThat(old).isNotNull();
    update = newUpdate(c, otherUser);
    Comment pub = newComment(ps1, filename, "uuid2", range, range.getEndLine(), otherUser, null, now, "comment on ps1", side, rev, false);
    update.putComment(Status.PUBLISHED, pub);
    update.commit();
    assertThat(exactRefAllUsers(draftRef)).isEqualTo(old);
}
#end_block

#method_before
@Test
public void fileComment() throws Exception {
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, otherUser);
    String uuid = "uuid";
    String rev = "abcd1234abcd1234abcd1234abcd1234abcd1234";
    String messageForBase = "comment for base";
    Timestamp now = TimeUtil.nowTs();
    PatchSet.Id psId = c.currentPatchSetId();
    Comment comment = newComment(psId, "filename", uuid, null, 0, otherUser, null, now, messageForBase, (short) 0, rev);
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, comment);
    update.commit();
    assertThat(newNotes(c).getComments()).containsExactlyEntriesIn(ImmutableMultimap.of(new RevId(rev), comment));
}
#method_after
@Test
public void fileComment() throws Exception {
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, otherUser);
    String uuid = "uuid";
    String rev = "abcd1234abcd1234abcd1234abcd1234abcd1234";
    String messageForBase = "comment for base";
    Timestamp now = TimeUtil.nowTs();
    PatchSet.Id psId = c.currentPatchSetId();
    Comment comment = newComment(psId, "filename", uuid, null, 0, otherUser, null, now, messageForBase, (short) 0, rev, false);
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, comment);
    update.commit();
    assertThat(newNotes(c).getComments()).containsExactlyEntriesIn(ImmutableMultimap.of(new RevId(rev), comment));
}
#end_block

#method_before
@Test
public void patchLineCommentNoRange() throws Exception {
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, otherUser);
    String uuid = "uuid";
    String rev = "abcd1234abcd1234abcd1234abcd1234abcd1234";
    String messageForBase = "comment for base";
    Timestamp now = TimeUtil.nowTs();
    PatchSet.Id psId = c.currentPatchSetId();
    Comment comment = newComment(psId, "filename", uuid, null, 1, otherUser, null, now, messageForBase, (short) 0, rev);
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, comment);
    update.commit();
    assertThat(newNotes(c).getComments()).containsExactlyEntriesIn(ImmutableMultimap.of(new RevId(rev), comment));
}
#method_after
@Test
public void patchLineCommentNoRange() throws Exception {
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, otherUser);
    String uuid = "uuid";
    String rev = "abcd1234abcd1234abcd1234abcd1234abcd1234";
    String messageForBase = "comment for base";
    Timestamp now = TimeUtil.nowTs();
    PatchSet.Id psId = c.currentPatchSetId();
    Comment comment = newComment(psId, "filename", uuid, null, 1, otherUser, null, now, messageForBase, (short) 0, rev, false);
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, comment);
    update.commit();
    assertThat(newNotes(c).getComments()).containsExactlyEntriesIn(ImmutableMultimap.of(new RevId(rev), comment));
}
#end_block

#method_before
@Test
public void putCommentsForMultipleRevisions() throws Exception {
    Change c = newChange();
    String uuid = "uuid";
    String rev1 = "abcd1234abcd1234abcd1234abcd1234abcd1234";
    String rev2 = "abcd4567abcd4567abcd4567abcd4567abcd4567";
    CommentRange range = new CommentRange(1, 1, 2, 1);
    PatchSet.Id ps1 = c.currentPatchSetId();
    String filename = "filename1";
    short side = (short) 1;
    incrementPatchSet(c);
    PatchSet.Id ps2 = c.currentPatchSetId();
    ChangeUpdate update = newUpdate(c, otherUser);
    update.setPatchSetId(ps2);
    Timestamp now = TimeUtil.nowTs();
    Comment comment1 = newComment(ps1, filename, uuid, range, range.getEndLine(), otherUser, null, now, "comment on ps1", side, rev1);
    Comment comment2 = newComment(ps2, filename, uuid, range, range.getEndLine(), otherUser, null, now, "comment on ps2", side, rev2);
    update.putComment(Status.DRAFT, comment1);
    update.putComment(Status.DRAFT, comment2);
    update.commit();
    ChangeNotes notes = newNotes(c);
    assertThat(notes.getDraftComments(otherUserId)).hasSize(2);
    assertThat(notes.getComments()).isEmpty();
    update = newUpdate(c, otherUser);
    update.setPatchSetId(ps2);
    update.putComment(Status.PUBLISHED, comment1);
    update.putComment(Status.PUBLISHED, comment2);
    update.commit();
    notes = newNotes(c);
    assertThat(notes.getDraftComments(otherUserId)).isEmpty();
    assertThat(notes.getComments()).hasSize(2);
}
#method_after
@Test
public void putCommentsForMultipleRevisions() throws Exception {
    Change c = newChange();
    String uuid = "uuid";
    String rev1 = "abcd1234abcd1234abcd1234abcd1234abcd1234";
    String rev2 = "abcd4567abcd4567abcd4567abcd4567abcd4567";
    CommentRange range = new CommentRange(1, 1, 2, 1);
    PatchSet.Id ps1 = c.currentPatchSetId();
    String filename = "filename1";
    short side = (short) 1;
    incrementPatchSet(c);
    PatchSet.Id ps2 = c.currentPatchSetId();
    ChangeUpdate update = newUpdate(c, otherUser);
    update.setPatchSetId(ps2);
    Timestamp now = TimeUtil.nowTs();
    Comment comment1 = newComment(ps1, filename, uuid, range, range.getEndLine(), otherUser, null, now, "comment on ps1", side, rev1, false);
    Comment comment2 = newComment(ps2, filename, uuid, range, range.getEndLine(), otherUser, null, now, "comment on ps2", side, rev2, false);
    update.putComment(Status.DRAFT, comment1);
    update.putComment(Status.DRAFT, comment2);
    update.commit();
    ChangeNotes notes = newNotes(c);
    assertThat(notes.getDraftComments(otherUserId)).hasSize(2);
    assertThat(notes.getComments()).isEmpty();
    update = newUpdate(c, otherUser);
    update.setPatchSetId(ps2);
    update.putComment(Status.PUBLISHED, comment1);
    update.putComment(Status.PUBLISHED, comment2);
    update.commit();
    notes = newNotes(c);
    assertThat(notes.getDraftComments(otherUserId)).isEmpty();
    assertThat(notes.getComments()).hasSize(2);
}
#end_block

#method_before
@Test
public void publishSubsetOfCommentsOnRevision() throws Exception {
    Change c = newChange();
    RevId rev1 = new RevId("abcd1234abcd1234abcd1234abcd1234abcd1234");
    CommentRange range = new CommentRange(1, 1, 2, 1);
    PatchSet.Id ps1 = c.currentPatchSetId();
    short side = (short) 1;
    ChangeUpdate update = newUpdate(c, otherUser);
    update.setPatchSetId(ps1);
    Timestamp now = TimeUtil.nowTs();
    Comment comment1 = newComment(ps1, "file1", "uuid1", range, range.getEndLine(), otherUser, null, now, "comment1", side, rev1.get());
    Comment comment2 = newComment(ps1, "file2", "uuid2", range, range.getEndLine(), otherUser, null, now, "comment2", side, rev1.get());
    update.putComment(Status.DRAFT, comment1);
    update.putComment(Status.DRAFT, comment2);
    update.commit();
    ChangeNotes notes = newNotes(c);
    assertThat(notes.getDraftComments(otherUserId).get(rev1)).containsExactly(comment1, comment2);
    assertThat(notes.getComments()).isEmpty();
    update = newUpdate(c, otherUser);
    update.setPatchSetId(ps1);
    update.putComment(Status.PUBLISHED, comment2);
    update.commit();
    notes = newNotes(c);
    assertThat(notes.getDraftComments(otherUserId).get(rev1)).containsExactly(comment1);
    assertThat(notes.getComments().get(rev1)).containsExactly(comment2);
}
#method_after
@Test
public void publishSubsetOfCommentsOnRevision() throws Exception {
    Change c = newChange();
    RevId rev1 = new RevId("abcd1234abcd1234abcd1234abcd1234abcd1234");
    CommentRange range = new CommentRange(1, 1, 2, 1);
    PatchSet.Id ps1 = c.currentPatchSetId();
    short side = (short) 1;
    ChangeUpdate update = newUpdate(c, otherUser);
    update.setPatchSetId(ps1);
    Timestamp now = TimeUtil.nowTs();
    Comment comment1 = newComment(ps1, "file1", "uuid1", range, range.getEndLine(), otherUser, null, now, "comment1", side, rev1.get(), false);
    Comment comment2 = newComment(ps1, "file2", "uuid2", range, range.getEndLine(), otherUser, null, now, "comment2", side, rev1.get(), false);
    update.putComment(Status.DRAFT, comment1);
    update.putComment(Status.DRAFT, comment2);
    update.commit();
    ChangeNotes notes = newNotes(c);
    assertThat(notes.getDraftComments(otherUserId).get(rev1)).containsExactly(comment1, comment2);
    assertThat(notes.getComments()).isEmpty();
    update = newUpdate(c, otherUser);
    update.setPatchSetId(ps1);
    update.putComment(Status.PUBLISHED, comment2);
    update.commit();
    notes = newNotes(c);
    assertThat(notes.getDraftComments(otherUserId).get(rev1)).containsExactly(comment1);
    assertThat(notes.getComments().get(rev1)).containsExactly(comment2);
}
#end_block

#method_before
@Test
public void filterOutAndFixUpZombieDraftComments() throws Exception {
    Change c = newChange();
    RevId rev1 = new RevId("abcd1234abcd1234abcd1234abcd1234abcd1234");
    CommentRange range = new CommentRange(1, 1, 2, 1);
    PatchSet.Id ps1 = c.currentPatchSetId();
    short side = (short) 1;
    ChangeUpdate update = newUpdate(c, otherUser);
    Timestamp now = TimeUtil.nowTs();
    Comment comment1 = newComment(ps1, "file1", "uuid1", range, range.getEndLine(), otherUser, null, now, "comment on ps1", side, rev1.get());
    Comment comment2 = newComment(ps1, "file2", "uuid2", range, range.getEndLine(), otherUser, null, now, "another comment", side, rev1.get());
    update.putComment(Status.DRAFT, comment1);
    update.putComment(Status.DRAFT, comment2);
    update.commit();
    String refName = refsDraftComments(c.getId(), otherUserId);
    ObjectId oldDraftId = exactRefAllUsers(refName);
    update = newUpdate(c, otherUser);
    update.setPatchSetId(ps1);
    update.putComment(Status.PUBLISHED, comment2);
    update.commit();
    assertThat(exactRefAllUsers(refName)).isNotNull();
    assertThat(exactRefAllUsers(refName)).isNotEqualTo(oldDraftId);
    // Re-add draft version of comment2 back to draft ref without updating
    // change ref. Simulates the case where deleting the draft failed
    // non-atomically after adding the published comment succeeded.
    ChangeDraftUpdate draftUpdate = newUpdate(c, otherUser).createDraftUpdateIfNull();
    draftUpdate.putComment(comment2);
    try (NoteDbUpdateManager manager = updateManagerFactory.create(c.getProject())) {
        manager.add(draftUpdate);
        manager.execute();
    }
    // Looking at drafts directly shows the zombie comment.
    DraftCommentNotes draftNotes = draftNotesFactory.create(c, otherUserId);
    assertThat(draftNotes.load().getComments().get(rev1)).containsExactly(comment1, comment2);
    // Zombie comment is filtered out of drafts via ChangeNotes.
    ChangeNotes notes = newNotes(c);
    assertThat(notes.getDraftComments(otherUserId).get(rev1)).containsExactly(comment1);
    assertThat(notes.getComments().get(rev1)).containsExactly(comment2);
    update = newUpdate(c, otherUser);
    update.setPatchSetId(ps1);
    update.putComment(Status.PUBLISHED, comment1);
    update.commit();
    // Updating an unrelated comment causes the zombie comment to get fixed up.
    assertThat(exactRefAllUsers(refName)).isNull();
}
#method_after
@Test
public void filterOutAndFixUpZombieDraftComments() throws Exception {
    Change c = newChange();
    RevId rev1 = new RevId("abcd1234abcd1234abcd1234abcd1234abcd1234");
    CommentRange range = new CommentRange(1, 1, 2, 1);
    PatchSet.Id ps1 = c.currentPatchSetId();
    short side = (short) 1;
    ChangeUpdate update = newUpdate(c, otherUser);
    Timestamp now = TimeUtil.nowTs();
    Comment comment1 = newComment(ps1, "file1", "uuid1", range, range.getEndLine(), otherUser, null, now, "comment on ps1", side, rev1.get(), false);
    Comment comment2 = newComment(ps1, "file2", "uuid2", range, range.getEndLine(), otherUser, null, now, "another comment", side, rev1.get(), false);
    update.putComment(Status.DRAFT, comment1);
    update.putComment(Status.DRAFT, comment2);
    update.commit();
    String refName = refsDraftComments(c.getId(), otherUserId);
    ObjectId oldDraftId = exactRefAllUsers(refName);
    update = newUpdate(c, otherUser);
    update.setPatchSetId(ps1);
    update.putComment(Status.PUBLISHED, comment2);
    update.commit();
    assertThat(exactRefAllUsers(refName)).isNotNull();
    assertThat(exactRefAllUsers(refName)).isNotEqualTo(oldDraftId);
    // Re-add draft version of comment2 back to draft ref without updating
    // change ref. Simulates the case where deleting the draft failed
    // non-atomically after adding the published comment succeeded.
    ChangeDraftUpdate draftUpdate = newUpdate(c, otherUser).createDraftUpdateIfNull();
    draftUpdate.putComment(comment2);
    try (NoteDbUpdateManager manager = updateManagerFactory.create(c.getProject())) {
        manager.add(draftUpdate);
        manager.execute();
    }
    // Looking at drafts directly shows the zombie comment.
    DraftCommentNotes draftNotes = draftNotesFactory.create(c, otherUserId);
    assertThat(draftNotes.load().getComments().get(rev1)).containsExactly(comment1, comment2);
    // Zombie comment is filtered out of drafts via ChangeNotes.
    ChangeNotes notes = newNotes(c);
    assertThat(notes.getDraftComments(otherUserId).get(rev1)).containsExactly(comment1);
    assertThat(notes.getComments().get(rev1)).containsExactly(comment2);
    update = newUpdate(c, otherUser);
    update.setPatchSetId(ps1);
    update.putComment(Status.PUBLISHED, comment1);
    update.commit();
    // Updating an unrelated comment causes the zombie comment to get fixed up.
    assertThat(exactRefAllUsers(refName)).isNull();
}
#end_block

#method_before
@Test
public void updateCommentsInSequentialUpdates() throws Exception {
    Change c = newChange();
    CommentRange range = new CommentRange(1, 1, 2, 1);
    String rev = "abcd1234abcd1234abcd1234abcd1234abcd1234";
    ChangeUpdate update1 = newUpdate(c, otherUser);
    Comment comment1 = newComment(c.currentPatchSetId(), "filename", "uuid1", range, range.getEndLine(), otherUser, null, new Timestamp(update1.getWhen().getTime()), "comment 1", (short) 1, rev);
    update1.putComment(Status.PUBLISHED, comment1);
    ChangeUpdate update2 = newUpdate(c, otherUser);
    Comment comment2 = newComment(c.currentPatchSetId(), "filename", "uuid2", range, range.getEndLine(), otherUser, null, new Timestamp(update2.getWhen().getTime()), "comment 2", (short) 1, rev);
    update2.putComment(Status.PUBLISHED, comment2);
    try (NoteDbUpdateManager manager = updateManagerFactory.create(project)) {
        manager.add(update1);
        manager.add(update2);
        manager.execute();
    }
    ChangeNotes notes = newNotes(c);
    List<Comment> comments = notes.getComments().get(new RevId(rev));
    assertThat(comments).hasSize(2);
    assertThat(comments.get(0).message).isEqualTo("comment 1");
    assertThat(comments.get(1).message).isEqualTo("comment 2");
}
#method_after
@Test
public void updateCommentsInSequentialUpdates() throws Exception {
    Change c = newChange();
    CommentRange range = new CommentRange(1, 1, 2, 1);
    String rev = "abcd1234abcd1234abcd1234abcd1234abcd1234";
    ChangeUpdate update1 = newUpdate(c, otherUser);
    Comment comment1 = newComment(c.currentPatchSetId(), "filename", "uuid1", range, range.getEndLine(), otherUser, null, new Timestamp(update1.getWhen().getTime()), "comment 1", (short) 1, rev, false);
    update1.putComment(Status.PUBLISHED, comment1);
    ChangeUpdate update2 = newUpdate(c, otherUser);
    Comment comment2 = newComment(c.currentPatchSetId(), "filename", "uuid2", range, range.getEndLine(), otherUser, null, new Timestamp(update2.getWhen().getTime()), "comment 2", (short) 1, rev, false);
    update2.putComment(Status.PUBLISHED, comment2);
    try (NoteDbUpdateManager manager = updateManagerFactory.create(project)) {
        manager.add(update1);
        manager.add(update2);
        manager.execute();
    }
    ChangeNotes notes = newNotes(c);
    List<Comment> comments = notes.getComments().get(new RevId(rev));
    assertThat(comments).hasSize(2);
    assertThat(comments.get(0).message).isEqualTo("comment 1");
    assertThat(comments.get(1).message).isEqualTo("comment 2");
}
#end_block

#method_before
@Test
public void ignoreEntitiesBeyondCurrentPatchSet() throws Exception {
    Change c = newChange();
    ChangeNotes notes = newNotes(c);
    int numMessages = notes.getChangeMessages().size();
    int numPatchSets = notes.getPatchSets().size();
    int numApprovals = notes.getApprovals().size();
    int numComments = notes.getComments().size();
    ChangeUpdate update = newUpdate(c, changeOwner);
    update.setPatchSetId(new PatchSet.Id(c.getId(), c.currentPatchSetId().get() + 1));
    update.setChangeMessage("Should be ignored");
    update.putApproval("Code-Review", (short) 2);
    CommentRange range = new CommentRange(1, 1, 2, 1);
    Comment comment = newComment(update.getPatchSetId(), "filename", "uuid", range, range.getEndLine(), changeOwner, null, new Timestamp(update.getWhen().getTime()), "comment", (short) 1, "abcd1234abcd1234abcd1234abcd1234abcd1234");
    update.putComment(Status.PUBLISHED, comment);
    update.commit();
    notes = newNotes(c);
    assertThat(notes.getChangeMessages()).hasSize(numMessages);
    assertThat(notes.getPatchSets()).hasSize(numPatchSets);
    assertThat(notes.getApprovals()).hasSize(numApprovals);
    assertThat(notes.getComments()).hasSize(numComments);
}
#method_after
@Test
public void ignoreEntitiesBeyondCurrentPatchSet() throws Exception {
    Change c = newChange();
    ChangeNotes notes = newNotes(c);
    int numMessages = notes.getChangeMessages().size();
    int numPatchSets = notes.getPatchSets().size();
    int numApprovals = notes.getApprovals().size();
    int numComments = notes.getComments().size();
    ChangeUpdate update = newUpdate(c, changeOwner);
    update.setPatchSetId(new PatchSet.Id(c.getId(), c.currentPatchSetId().get() + 1));
    update.setChangeMessage("Should be ignored");
    update.putApproval("Code-Review", (short) 2);
    CommentRange range = new CommentRange(1, 1, 2, 1);
    Comment comment = newComment(update.getPatchSetId(), "filename", "uuid", range, range.getEndLine(), changeOwner, null, new Timestamp(update.getWhen().getTime()), "comment", (short) 1, "abcd1234abcd1234abcd1234abcd1234abcd1234", false);
    update.putComment(Status.PUBLISHED, comment);
    update.commit();
    notes = newNotes(c);
    assertThat(notes.getChangeMessages()).hasSize(numMessages);
    assertThat(notes.getPatchSets()).hasSize(numPatchSets);
    assertThat(notes.getApprovals()).hasSize(numApprovals);
    assertThat(notes.getComments()).hasSize(numComments);
}
#end_block

#method_before
@Before
public void setUp() throws Exception {
    group1 = group("users1");
    group2 = group("users2");
    group3 = group("users3");
    user1 = user("user1", "First1 Last1", group1);
    user2 = user("user2", "First2 Last2", group2);
    user3 = user("user3", "First3 Last3", group1, group2);
    user4 = user("jdoe", "John Doe", "JDOE");
    anonymousUsers = groups.parse("Anonymous Users").getGroupUUID();
    allow(allProjects, "read", anonymousUsers, "refs/*");
}
#method_after
@Before
public void setUp() throws Exception {
    group1 = group("users1");
    group2 = group("users2");
    group3 = group("users3");
    user1 = user("user1", "First1 Last1", group1);
    user2 = user("user2", "First2 Last2", group2);
    user3 = user("user3", "First3 Last3", group1, group2);
    user4 = user("jdoe", "John Doe", "JDOE");
}
#end_block

#method_before
@Test
public void suggestReviewsPrivateProjectVisibility() throws Exception {
    String changeId = createChange().getChangeId();
    List<SuggestedReviewerInfo> reviewers;
    setApiUser(user3);
    remove(allProjects, "read", anonymousUsers, "refs/*");
    allow(allProjects, "read", group1.getGroupUUID(), "refs/*");
    reviewers = suggestReviewers(changeId, user2.username, 2);
    assertThat(reviewers).isEmpty();
    remove(allProjects, "read", group1.getGroupUUID(), "refs/*");
}
#method_after
@Test
public void suggestReviewsPrivateProjectVisibility() throws Exception {
    String changeId = createChange().getChangeId();
    List<SuggestedReviewerInfo> reviewers;
    setApiUser(user3);
    block("read", ANONYMOUS_USERS, "refs/*");
    allow("read", group1.getGroupUUID(), "refs/*");
    reviewers = suggestReviewers(changeId, user2.username, 2);
    assertThat(reviewers).isEmpty();
}
#end_block

#method_before
@Test
public void suggestReviewersFullTextSearch() throws Exception {
    String changeId = createChange().getChangeId();
    List<SuggestedReviewerInfo> reviewers;
    reviewers = suggestReviewers(changeId, "first", 4);
    assertThat(reviewers).hasSize(4);
    reviewers = suggestReviewers(changeId, "first1", 2);
    assertThat(reviewers).hasSize(2);
    reviewers = suggestReviewers(changeId, "last", 4);
    assertThat(reviewers).hasSize(4);
    reviewers = suggestReviewers(changeId, "last1", 2);
    assertThat(reviewers).hasSize(2);
    reviewers = suggestReviewers(changeId, "fi la", 4);
    assertThat(reviewers).hasSize(4);
    reviewers = suggestReviewers(changeId, "la fi", 4);
    assertThat(reviewers).hasSize(4);
    reviewers = suggestReviewers(changeId, "first1 la", 2);
    assertThat(reviewers).hasSize(2);
    reviewers = suggestReviewers(changeId, "fi last1", 2);
    assertThat(reviewers).hasSize(2);
    reviewers = suggestReviewers(changeId, "first1 last2", 1);
    assertThat(reviewers).hasSize(0);
    reviewers = suggestReviewers(changeId, name("user"), 7);
    assertThat(reviewers).hasSize(6);
    reviewers = suggestReviewers(changeId, user1.username, 2);
    assertThat(reviewers).hasSize(1);
    reviewers = suggestReviewers(changeId, "example.com", 7);
    assertThat(reviewers).hasSize(7);
    reviewers = suggestReviewers(changeId, user1.email, 2);
    assertThat(reviewers).hasSize(1);
    reviewers = suggestReviewers(changeId, user1.username + " example", 2);
    assertThat(reviewers).hasSize(1);
    reviewers = suggestReviewers(changeId, user4.email.toLowerCase(), 2);
    assertThat(reviewers).hasSize(1);
    assertThat(reviewers.get(0).account.email).isEqualTo(user4.email);
}
#method_after
@Test
public void suggestReviewersFullTextSearch() throws Exception {
    String changeId = createChange().getChangeId();
    List<SuggestedReviewerInfo> reviewers;
    reviewers = suggestReviewers(changeId, "first");
    assertThat(reviewers).hasSize(3);
    reviewers = suggestReviewers(changeId, "first1");
    assertThat(reviewers).hasSize(1);
    reviewers = suggestReviewers(changeId, "last");
    assertThat(reviewers).hasSize(3);
    reviewers = suggestReviewers(changeId, "last1");
    assertThat(reviewers).hasSize(1);
    reviewers = suggestReviewers(changeId, "fi la");
    assertThat(reviewers).hasSize(3);
    reviewers = suggestReviewers(changeId, "la fi");
    assertThat(reviewers).hasSize(3);
    reviewers = suggestReviewers(changeId, "first1 la");
    assertThat(reviewers).hasSize(1);
    reviewers = suggestReviewers(changeId, "fi last1");
    assertThat(reviewers).hasSize(1);
    reviewers = suggestReviewers(changeId, "first1 last2");
    assertThat(reviewers).hasSize(0);
    reviewers = suggestReviewers(changeId, name("user"));
    assertThat(reviewers).hasSize(6);
    reviewers = suggestReviewers(changeId, user1.username);
    assertThat(reviewers).hasSize(1);
    reviewers = suggestReviewers(changeId, "example.com");
    assertThat(reviewers).hasSize(6);
    reviewers = suggestReviewers(changeId, user1.email);
    assertThat(reviewers).hasSize(1);
    reviewers = suggestReviewers(changeId, user1.username + " example");
    assertThat(reviewers).hasSize(1);
    reviewers = suggestReviewers(changeId, user4.email.toLowerCase());
    assertThat(reviewers).hasSize(1);
    assertThat(reviewers.get(0).account.email).isEqualTo(user4.email);
}
#end_block

#method_before
private List<SuggestedReviewerInfo> suggestReviewers(String changeId, String query, int n) throws Exception {
    return gApi.changes().id(changeId).suggestReviewers(query).withLimit(n).get();
}
#method_after
private List<SuggestedReviewerInfo> suggestReviewers(String changeId, String query) throws Exception {
    return gApi.changes().id(changeId).suggestReviewers(query).get();
}
#end_block

#method_before
@Before
public void setUpInjector() throws Exception {
    lifecycle = new LifecycleManager();
    Injector injector = createInjector();
    lifecycle.add(injector);
    injector.injectMembers(this);
    lifecycle.start();
    db = schemaFactory.open();
    schemaCreator.create(db);
    userId = accountManager.authenticate(AuthRequest.forUser("user")).getAccountId();
    Account userAccount = db.accounts().get(userId);
    userAccount.setPreferredEmail("user@example.com");
    db.accounts().update(ImmutableList.of(userAccount));
    user = userFactory.create(userId);
    requestContext.setContext(newRequestContext(userAccount.getId()));
}
#method_after
@Before
public void setUpInjector() throws Exception {
    lifecycle = new LifecycleManager();
    injector = createInjector();
    lifecycle.add(injector);
    injector.injectMembers(this);
    lifecycle.start();
    setUpDatabase();
}
#end_block

#method_before
@Override
protected String getRefName() {
    return RefNames.refsDraftComments(getChangeId(), author);
}
#method_after
@Override
protected String getRefName() {
    return refsDraftComments(getChangeId(), author);
}
#end_block

#method_before
private void executeNoteDbUpdates(List<ChangeTask> tasks) {
    // Aggregate together all NoteDb ref updates from the ops we executed,
    // possibly in parallel. Each task had its own NoteDbUpdateManager instance
    // with its own thread-local copy of the repo(s), but each of those was just
    // used for staging updates and was never executed.
    // 
    // Use a new BatchRefUpdate as the original batchRefUpdate field is intended
    // for use only by the updateRepo phase.
    // 
    // See the comments in NoteDbUpdateManager#execute() for why we execute the
    // updates on the change repo first.
    logDebug("Executing NoteDb updates for {} changes", tasks.size());
    try {
        BatchRefUpdate changeRefUpdate = getRepository().getRefDatabase().newBatchUpdate();
        boolean hasAllUsersCommands = false;
        try (ObjectInserter ins = getRepository().newObjectInserter()) {
            int objs = 0;
            for (ChangeTask task : tasks) {
                if (task.noteDbResult == null) {
                    logDebug("No-op update to {}", task.id);
                    continue;
                }
                for (ReceiveCommand cmd : task.noteDbResult.changeCommands()) {
                    changeRefUpdate.addCommand(cmd);
                }
                for (InsertedObject obj : task.noteDbResult.changeObjects()) {
                    objs++;
                    ins.insert(obj.type(), obj.data().toByteArray());
                }
                hasAllUsersCommands |= !task.noteDbResult.allUsersCommands().isEmpty();
            }
            logDebug("Collected {} objects and {} ref updates to change repo", objs, changeRefUpdate.getCommands().size());
            executeNoteDbUpdate(getRevWalk(), ins, changeRefUpdate);
        }
        if (hasAllUsersCommands) {
            try (Repository allUsersRepo = repoManager.openRepository(allUsers);
                RevWalk allUsersRw = new RevWalk(allUsersRepo);
                ObjectInserter allUsersIns = allUsersRepo.newObjectInserter()) {
                int objs = 0;
                BatchRefUpdate allUsersRefUpdate = allUsersRepo.getRefDatabase().newBatchUpdate();
                for (ChangeTask task : tasks) {
                    for (ReceiveCommand cmd : task.noteDbResult.allUsersCommands()) {
                        allUsersRefUpdate.addCommand(cmd);
                    }
                    for (InsertedObject obj : task.noteDbResult.allUsersObjects()) {
                        allUsersIns.insert(obj.type(), obj.data().toByteArray());
                    }
                }
                logDebug("Collected {} objects and {} ref updates to All-Users", objs, allUsersRefUpdate.getCommands().size());
                executeNoteDbUpdate(allUsersRw, allUsersIns, allUsersRefUpdate);
            }
        } else {
            logDebug("No All-Users updates");
        }
    } catch (IOException e) {
        // Ignore all errors trying to update NoteDb at this point. We've
        // already written the NoteDbChangeState to ReviewDb, which means
        // if the state is out of date it will be rebuilt the next time it
        // is needed.
        // Always log even without RequestId.
        log.debug("Ignoring NoteDb update error after ReviewDb write", e);
    }
}
#method_after
private void executeNoteDbUpdates(List<ChangeTask> tasks) throws IOException {
    // Aggregate together all NoteDb ref updates from the ops we executed,
    // possibly in parallel. Each task had its own NoteDbUpdateManager instance
    // with its own thread-local copy of the repo(s), but each of those was just
    // used for staging updates and was never executed.
    // 
    // Use a new BatchRefUpdate as the original batchRefUpdate field is intended
    // for use only by the updateRepo phase.
    // 
    // See the comments in NoteDbUpdateManager#execute() for why we execute the
    // updates on the change repo first.
    logDebug("Executing NoteDb updates for {} changes", tasks.size());
    try {
        BatchRefUpdate changeRefUpdate = getRepository().getRefDatabase().newBatchUpdate();
        boolean hasAllUsersCommands = false;
        try (ObjectInserter ins = getRepository().newObjectInserter()) {
            int objs = 0;
            for (ChangeTask task : tasks) {
                if (task.noteDbResult == null) {
                    logDebug("No-op update to {}", task.id);
                    continue;
                }
                for (ReceiveCommand cmd : task.noteDbResult.changeCommands()) {
                    changeRefUpdate.addCommand(cmd);
                }
                for (InsertedObject obj : task.noteDbResult.changeObjects()) {
                    objs++;
                    ins.insert(obj.type(), obj.data().toByteArray());
                }
                hasAllUsersCommands |= !task.noteDbResult.allUsersCommands().isEmpty();
            }
            logDebug("Collected {} objects and {} ref updates to change repo", objs, changeRefUpdate.getCommands().size());
            executeNoteDbUpdate(getRevWalk(), ins, changeRefUpdate);
        }
        if (hasAllUsersCommands) {
            try (Repository allUsersRepo = repoManager.openRepository(allUsers);
                RevWalk allUsersRw = new RevWalk(allUsersRepo);
                ObjectInserter allUsersIns = allUsersRepo.newObjectInserter()) {
                int objs = 0;
                BatchRefUpdate allUsersRefUpdate = allUsersRepo.getRefDatabase().newBatchUpdate();
                for (ChangeTask task : tasks) {
                    for (ReceiveCommand cmd : task.noteDbResult.allUsersCommands()) {
                        allUsersRefUpdate.addCommand(cmd);
                    }
                    for (InsertedObject obj : task.noteDbResult.allUsersObjects()) {
                        allUsersIns.insert(obj.type(), obj.data().toByteArray());
                    }
                }
                logDebug("Collected {} objects and {} ref updates to All-Users", objs, allUsersRefUpdate.getCommands().size());
                executeNoteDbUpdate(allUsersRw, allUsersIns, allUsersRefUpdate);
            }
        } else {
            logDebug("No All-Users updates");
        }
    } catch (IOException e) {
        if (tasks.stream().allMatch(t -> t.storage == PrimaryStorage.REVIEW_DB)) {
            // Ignore all errors trying to update NoteDb at this point. We've
            // already written the NoteDbChangeStates to ReviewDb, which means
            // if any state is out of date it will be rebuilt the next time it
            // is needed.
            // Always log even without RequestId.
            log.debug("Ignoring NoteDb update error after ReviewDb write", e);
        } else {
            // primary storage.
            throw e;
        }
    }
}
#end_block

#method_before
private void executeNoteDbUpdate(RevWalk rw, ObjectInserter ins, BatchRefUpdate bru) throws IOException {
    if (bru.getCommands().isEmpty()) {
        logDebug("No commands, skipping flush and ref update");
        return;
    }
    ins.flush();
    bru.setAllowNonFastForwards(true);
    bru.execute(rw, NullProgressMonitor.INSTANCE);
    for (ReceiveCommand cmd : bru.getCommands()) {
        if (cmd.getResult() != ReceiveCommand.Result.OK) {
            throw new IOException("Update failed: " + bru);
        }
    }
}
#method_after
private void executeNoteDbUpdate(RevWalk rw, ObjectInserter ins, BatchRefUpdate bru) throws IOException {
    if (bru.getCommands().isEmpty()) {
        logDebug("No commands, skipping flush and ref update");
        return;
    }
    ins.flush();
    bru.setAllowNonFastForwards(true);
    bru.execute(rw, NullProgressMonitor.INSTANCE);
    for (ReceiveCommand cmd : bru.getCommands()) {
        // TODO(dborowitz): LOCK_FAILURE for NoteDb primary should be retried.
        if (cmd.getResult() != ReceiveCommand.Result.OK) {
            throw new IOException("Update failed: " + bru);
        }
    }
}
#end_block

#method_before
private void call(ReviewDb db, Repository repo, RevWalk rw) throws Exception {
    // Not always opened.
    @SuppressWarnings("resource")
    NoteDbUpdateManager updateManager = null;
    try {
        PrimaryStorage storage;
        db.changes().beginTransaction(id);
        try {
            ChangeContext ctx = newChangeContext(db, repo, rw, id);
            NoteDbChangeState oldState = NoteDbChangeState.parse(ctx.getChange());
            NoteDbChangeState.checkNotReadOnly(oldState, skewMs);
            storage = PrimaryStorage.of(oldState);
            if (storage == PrimaryStorage.NOTE_DB && !notesMigration.readChanges()) {
                throw new OrmException("must have NoteDb enabled to update change " + id);
            }
            // Call updateChange on each op.
            logDebug("Calling updateChange on {} ops", changeOps.size());
            for (Op op : changeOps) {
                dirty |= op.updateChange(ctx);
            }
            if (!dirty) {
                logDebug("No ops reported dirty, short-circuiting");
                return;
            }
            deleted = ctx.deleted;
            if (deleted) {
                logDebug("Change was deleted");
            }
            // Stage the NoteDb update and store its state in the Change.
            if (notesMigration.commitChangeWrites()) {
                updateManager = stageNoteDbUpdate(ctx, deleted);
            }
            if (storage == PrimaryStorage.REVIEW_DB) {
                // If primary storage of this change is in ReviewDb, bump
                // lastUpdatedOn or rowVersion and commit. Otherwise, don't waste
                // time updating ReviewDb at all.
                Iterable<Change> cs = changesToUpdate(ctx);
                if (isNewChange(id)) {
                    // Insert rather than upsert in case of a race on change IDs.
                    logDebug("Inserting change");
                    db.changes().insert(cs);
                } else if (deleted) {
                    logDebug("Deleting change");
                    db.changes().delete(cs);
                } else {
                    logDebug("Updating change");
                    db.changes().update(cs);
                }
                if (!dryrun) {
                    db.commit();
                }
            } else {
                logDebug("Skipping ReviewDb write since primary storage is {}", storage);
            }
        } finally {
            db.rollback();
        }
        // flushed inserters as well.
        if (storage == PrimaryStorage.NOTE_DB) {
            // Should have failed above if NoteDb is disabled.
            checkState(notesMigration.commitChangeWrites());
            noteDbResult = updateManager.stage().get(id);
        } else if (notesMigration.commitChangeWrites()) {
            try {
                noteDbResult = updateManager.stage().get(id);
            } catch (IOException ex) {
                // Ignore all errors trying to update NoteDb at this point. We've
                // already written the NoteDbChangeState to ReviewDb, which means
                // if the state is out of date it will be rebuilt the next time it
                // is needed.
                log.debug("Ignoring NoteDb update error after ReviewDb write", ex);
            }
        }
    } catch (Exception e) {
        logDebug("Error updating change (should be rethrown)", e);
        Throwables.propagateIfPossible(e, RestApiException.class);
        throw new UpdateException(e);
    } finally {
        if (updateManager != null) {
            updateManager.close();
        }
    }
}
#method_after
private void call(ReviewDb db, Repository repo, RevWalk rw) throws Exception {
    // Not always opened.
    @SuppressWarnings("resource")
    NoteDbUpdateManager updateManager = null;
    try {
        db.changes().beginTransaction(id);
        try {
            ChangeContext ctx = newChangeContext(db, repo, rw, id);
            NoteDbChangeState oldState = NoteDbChangeState.parse(ctx.getChange());
            NoteDbChangeState.checkNotReadOnly(oldState, skewMs);
            storage = PrimaryStorage.of(oldState);
            if (storage == PrimaryStorage.NOTE_DB && !notesMigration.readChanges()) {
                throw new OrmException("must have NoteDb enabled to update change " + id);
            }
            // Call updateChange on each op.
            logDebug("Calling updateChange on {} ops", changeOps.size());
            for (Op op : changeOps) {
                dirty |= op.updateChange(ctx);
            }
            if (!dirty) {
                logDebug("No ops reported dirty, short-circuiting");
                return;
            }
            deleted = ctx.deleted;
            if (deleted) {
                logDebug("Change was deleted");
            }
            // Stage the NoteDb update and store its state in the Change.
            if (notesMigration.commitChangeWrites()) {
                updateManager = stageNoteDbUpdate(ctx, deleted);
            }
            if (storage == PrimaryStorage.REVIEW_DB) {
                // If primary storage of this change is in ReviewDb, bump
                // lastUpdatedOn or rowVersion and commit. Otherwise, don't waste
                // time updating ReviewDb at all.
                Iterable<Change> cs = changesToUpdate(ctx);
                if (isNewChange(id)) {
                    // Insert rather than upsert in case of a race on change IDs.
                    logDebug("Inserting change");
                    db.changes().insert(cs);
                } else if (deleted) {
                    logDebug("Deleting change");
                    db.changes().delete(cs);
                } else {
                    logDebug("Updating change");
                    db.changes().update(cs);
                }
                if (!dryrun) {
                    db.commit();
                }
            } else {
                logDebug("Skipping ReviewDb write since primary storage is {}", storage);
            }
        } finally {
            db.rollback();
        }
        // flushed inserters as well.
        if (storage == PrimaryStorage.NOTE_DB) {
            // Should have failed above if NoteDb is disabled.
            checkState(notesMigration.commitChangeWrites());
            noteDbResult = updateManager.stage().get(id);
        } else if (notesMigration.commitChangeWrites()) {
            try {
                noteDbResult = updateManager.stage().get(id);
            } catch (IOException ex) {
                // Ignore all errors trying to update NoteDb at this point. We've
                // already written the NoteDbChangeState to ReviewDb, which means
                // if the state is out of date it will be rebuilt the next time it
                // is needed.
                log.debug("Ignoring NoteDb update error after ReviewDb write", ex);
            }
        }
    } catch (Exception e) {
        logDebug("Error updating change (should be rethrown)", e);
        Throwables.propagateIfPossible(e, RestApiException.class);
        throw new UpdateException(e);
    } finally {
        if (updateManager != null) {
            updateManager.close();
        }
    }
}
#end_block

#method_before
private NoteDbUpdateManager stageNoteDbUpdate(ChangeContext ctx, boolean deleted) throws OrmException, IOException {
    logDebug("Staging NoteDb update");
    NoteDbUpdateManager updateManager = updateManagerFactory.create(ctx.getProject()).setChangeRepo(ctx.getRepository(), ctx.getRevWalk(), null, new ChainedReceiveCommands(repo));
    for (ChangeUpdate u : ctx.updates.values()) {
        updateManager.add(u);
    }
    Change c = ctx.getChange();
    if (deleted) {
        updateManager.deleteChange(c.getId());
    }
    try {
        updateManager.stageAndApplyDelta(c);
    } catch (MismatchedStateException ex) {
        // Refused to apply update because NoteDb was out of sync, which can
        // only happen if ReviewDb is the primary storage for this change.
        // 
        // Go ahead with this ReviewDb update; it's still out of sync, but this
        // is no worse than before, and it will eventually get rebuilt.
        logDebug("Ignoring MismatchedStateException while staging");
    }
    return updateManager;
}
#method_after
private NoteDbUpdateManager stageNoteDbUpdate(ChangeContext ctx, boolean deleted) throws OrmException, IOException {
    logDebug("Staging NoteDb update");
    NoteDbUpdateManager updateManager = updateManagerFactory.create(ctx.getProject()).setChangeRepo(ctx.getRepository(), ctx.getRevWalk(), null, new ChainedReceiveCommands(repo));
    if (ctx.getUser().isIdentifiedUser()) {
        updateManager.setRefLogIdent(ctx.getUser().asIdentifiedUser().newRefLogIdent(ctx.getWhen(), tz));
    }
    for (ChangeUpdate u : ctx.updates.values()) {
        updateManager.add(u);
    }
    Change c = ctx.getChange();
    if (deleted) {
        updateManager.deleteChange(c.getId());
    }
    try {
        updateManager.stageAndApplyDelta(c);
    } catch (MismatchedStateException ex) {
        // Refused to apply update because NoteDb was out of sync, which can
        // only happen if ReviewDb is the primary storage for this change.
        // 
        // Go ahead with this ReviewDb update; it's still out of sync, but this
        // is no worse than before, and it will eventually get rebuilt.
        logDebug("Ignoring MismatchedStateException while staging");
    }
    return updateManager;
}
#end_block

#method_before
static GerritServer start(Description desc, Config baseConfig) throws Exception {
    Config cfg = desc.buildConfig(baseConfig);
    Logger.getLogger("com.google.gerrit").setLevel(Level.DEBUG);
    final CyclicBarrier serverStarted = new CyclicBarrier(2);
    final Daemon daemon = new Daemon(new Runnable() {

        @Override
        public void run() {
            try {
                serverStarted.await();
            } catch (InterruptedException | BrokenBarrierException e) {
                throw new RuntimeException(e);
            }
        }
    }, Paths.get(baseConfig.getString("gerrit", null, "tempSiteDir")));
    daemon.setEmailModuleForTesting(new FakeEmailSender.Module());
    final File site;
    ExecutorService daemonService = null;
    if (desc.memory()) {
        site = null;
        mergeTestConfig(cfg);
        // Set the log4j configuration to an invalid one to prevent system logs
        // from getting configured and creating log files.
        System.setProperty(SystemLog.LOG4J_CONFIGURATION, "invalidConfiguration");
        cfg.setBoolean("httpd", null, "requestLog", false);
        cfg.setBoolean("sshd", null, "requestLog", false);
        cfg.setBoolean("index", "lucene", "testInmemory", true);
        cfg.setString("gitweb", null, "cgi", "");
        daemon.setEnableHttpd(desc.httpd());
        daemon.setLuceneModule(LuceneIndexModule.singleVersionAllLatest(0));
        daemon.setDatabaseForTesting(ImmutableList.<Module>of(new InMemoryTestingDatabaseModule(cfg)));
        daemon.start();
    } else {
        site = initSite(cfg);
        daemonService = Executors.newSingleThreadExecutor();
        daemonService.submit(new Callable<Void>() {

            @Override
            public Void call() throws Exception {
                int rc = daemon.main(new String[] { "-d", site.getPath(), "--headless", "--console-log", "--show-stack-trace" });
                if (rc != 0) {
                    System.err.println("Failed to start Gerrit daemon");
                    serverStarted.reset();
                }
                return null;
            }
        });
        serverStarted.await();
        System.out.println("Gerrit Server Started");
    }
    Injector i = createTestInjector(daemon);
    return new GerritServer(desc, i, daemon, daemonService);
}
#method_after
static GerritServer start(Description desc, Config baseConfig) throws Exception {
    Config cfg = desc.buildConfig(baseConfig);
    Logger.getLogger("com.google.gerrit").setLevel(Level.DEBUG);
    final CyclicBarrier serverStarted = new CyclicBarrier(2);
    final Daemon daemon = new Daemon(new Runnable() {

        @Override
        public void run() {
            try {
                serverStarted.await();
            } catch (InterruptedException | BrokenBarrierException e) {
                throw new RuntimeException(e);
            }
        }
    }, Paths.get(baseConfig.getString("gerrit", null, "tempSiteDir")));
    daemon.setEmailModuleForTesting(new FakeEmailSender.Module());
    daemon.setEnableSshd(SshMode.useSsh());
    final File site;
    ExecutorService daemonService = null;
    if (desc.memory()) {
        site = null;
        mergeTestConfig(cfg);
        // Set the log4j configuration to an invalid one to prevent system logs
        // from getting configured and creating log files.
        System.setProperty(SystemLog.LOG4J_CONFIGURATION, "invalidConfiguration");
        cfg.setBoolean("httpd", null, "requestLog", false);
        cfg.setBoolean("sshd", null, "requestLog", false);
        cfg.setBoolean("index", "lucene", "testInmemory", true);
        cfg.setString("gitweb", null, "cgi", "");
        daemon.setEnableHttpd(desc.httpd());
        daemon.setLuceneModule(LuceneIndexModule.singleVersionAllLatest(0));
        daemon.setDatabaseForTesting(ImmutableList.<Module>of(new InMemoryTestingDatabaseModule(cfg)));
        daemon.start();
    } else {
        site = initSite(cfg);
        daemonService = Executors.newSingleThreadExecutor();
        daemonService.submit(new Callable<Void>() {

            @Override
            public Void call() throws Exception {
                int rc = daemon.main(new String[] { "-d", site.getPath(), "--headless", "--console-log", "--show-stack-trace" });
                if (rc != 0) {
                    System.err.println("Failed to start Gerrit daemon");
                    serverStarted.reset();
                }
                return null;
            }
        });
        serverStarted.await();
        System.out.println("Gerrit Server Started");
    }
    Injector i = createTestInjector(daemon);
    return new GerritServer(desc, i, daemon, daemonService);
}
#end_block

#method_before
public ImmutableListMultimap<RevId, Comment> getDraftComments(Account.Id author) throws OrmException {
    loadDraftComments(author);
    final Multimap<RevId, Comment> published = state.publishedComments();
    // Filter out any draft comments that also exist in the published map, in
    // case the update to All-Users to delete them during the publish operation
    // failed.
    Multimap<RevId, Comment> filtered = Multimaps.filterEntries(draftCommentNotes.getComments(), (Map.Entry<RevId, Comment> e) -> {
        for (Comment c : published.get(e.getKey())) {
            if (c.key.equals(e.getValue().key)) {
                return false;
            }
        }
        return true;
    });
    return ImmutableListMultimap.copyOf(filtered);
}
#method_after
public ImmutableListMultimap<RevId, Comment> getDraftComments(Account.Id author) throws OrmException {
    return getDraftComments(author, null);
}
#end_block

#method_before
public ImmutableListMultimap<RevId, Comment> getDraftComments(Account.Id author) throws OrmException {
    loadDraftComments(author);
    final Multimap<RevId, Comment> published = state.publishedComments();
    // Filter out any draft comments that also exist in the published map, in
    // case the update to All-Users to delete them during the publish operation
    // failed.
    Multimap<RevId, Comment> filtered = Multimaps.filterEntries(draftCommentNotes.getComments(), (Map.Entry<RevId, Comment> e) -> {
        for (Comment c : published.get(e.getKey())) {
            if (c.key.equals(e.getValue().key)) {
                return false;
            }
        }
        return true;
    });
    return ImmutableListMultimap.copyOf(filtered);
}
#method_after
public ImmutableListMultimap<RevId, Comment> getDraftComments(Account.Id author, @Nullable Ref ref) throws OrmException {
    loadDraftComments(author, ref);
    // during the publish operation failed.
    return ImmutableListMultimap.copyOf(Multimaps.filterEntries(draftCommentNotes.getComments(), e -> !getCommentKeys().contains(e.getValue().key)));
}
#end_block

#method_before
private void loadDraftComments(Account.Id author) throws OrmException {
    if (draftCommentNotes == null || !author.equals(draftCommentNotes.getAuthor())) {
        draftCommentNotes = new DraftCommentNotes(args, change, author, autoRebuild, rebuildResult);
        draftCommentNotes.load();
    }
}
#method_after
private void loadDraftComments(Account.Id author, @Nullable Ref ref) throws OrmException {
    if (draftCommentNotes == null || !author.equals(draftCommentNotes.getAuthor()) || ref != null) {
        draftCommentNotes = new DraftCommentNotes(args, change, author, autoRebuild, rebuildResult, ref);
        draftCommentNotes.load();
    }
}
#end_block

#method_before
public boolean containsComment(Comment c) throws OrmException {
    if (containsCommentPublished(c)) {
        return true;
    }
    loadDraftComments(c.author.getId());
    return draftCommentNotes.containsComment(c);
}
#method_after
public boolean containsComment(Comment c) throws OrmException {
    if (containsCommentPublished(c)) {
        return true;
    }
    loadDraftComments(c.author.getId(), null);
    return draftCommentNotes.containsComment(c);
}
#end_block

#method_before
private LoadHandle rebuildAndOpen(Repository repo, ObjectId oldId) throws IOException {
    Timer1.Context timer = args.metrics.autoRebuildLatency.start(CHANGES);
    try {
        Change.Id cid = getChangeId();
        ReviewDb db = args.db.get();
        ChangeRebuilder rebuilder = args.rebuilder.get();
        NoteDbUpdateManager.Result r;
        try (NoteDbUpdateManager manager = rebuilder.stage(db, cid)) {
            if (manager == null) {
                // May be null in tests.
                return super.openHandle(repo, oldId);
            }
            r = manager.stageAndApplyDelta(change);
            try {
                rebuilder.execute(db, cid, manager);
                repo.scanForRepoChanges();
            } catch (OrmException | IOException e) {
                // Rebuilding failed. Most likely cause is contention on one or more
                // change refs; there are other types of errors that can happen during
                // rebuilding, but generally speaking they should happen during stage(),
                // not execute(). Assume that some other worker is going to successfully
                // store the rebuilt state, which is deterministic given an input
                // ChangeBundle.
                // 
                // Parse notes from the staged result so we can return something useful
                // to the caller instead of throwing.
                log.debug("Rebuilding change {} failed: {}", getChangeId(), e.getMessage());
                args.metrics.autoRebuildFailureCount.increment(CHANGES);
                rebuildResult = checkNotNull(r);
                checkNotNull(r.newState());
                checkNotNull(r.staged());
                return LoadHandle.create(ChangeNotesCommit.newStagedRevWalk(repo, r.staged().changeObjects()), r.newState().getChangeMetaId());
            }
        }
        return LoadHandle.create(ChangeNotesCommit.newRevWalk(repo), r.newState().getChangeMetaId());
    } catch (NoSuchChangeException e) {
        return super.openHandle(repo, oldId);
    } catch (OrmException e) {
        throw new IOException(e);
    } finally {
        log.debug("Rebuilt change {} in project {} in {} ms", getChangeId(), getProjectName(), TimeUnit.MILLISECONDS.convert(timer.stop(), TimeUnit.NANOSECONDS));
    }
}
#method_after
private LoadHandle rebuildAndOpen(Repository repo, ObjectId oldId) throws IOException {
    Timer1.Context timer = args.metrics.autoRebuildLatency.start(CHANGES);
    try {
        Change.Id cid = getChangeId();
        ReviewDb db = args.db.get();
        ChangeRebuilder rebuilder = args.rebuilder.get();
        NoteDbUpdateManager.Result r;
        try (NoteDbUpdateManager manager = rebuilder.stage(db, cid)) {
            if (manager == null) {
                // May be null in tests.
                return super.openHandle(repo, oldId);
            }
            manager.setRefLogMessage("Auto-rebuilding change");
            r = manager.stageAndApplyDelta(change);
            try {
                rebuilder.execute(db, cid, manager);
                repo.scanForRepoChanges();
            } catch (OrmException | IOException e) {
                // Rebuilding failed. Most likely cause is contention on one or more
                // change refs; there are other types of errors that can happen during
                // rebuilding, but generally speaking they should happen during stage(),
                // not execute(). Assume that some other worker is going to successfully
                // store the rebuilt state, which is deterministic given an input
                // ChangeBundle.
                // 
                // Parse notes from the staged result so we can return something useful
                // to the caller instead of throwing.
                log.debug("Rebuilding change {} failed: {}", getChangeId(), e.getMessage());
                args.metrics.autoRebuildFailureCount.increment(CHANGES);
                rebuildResult = checkNotNull(r);
                checkNotNull(r.newState());
                checkNotNull(r.staged());
                return LoadHandle.create(ChangeNotesCommit.newStagedRevWalk(repo, r.staged().changeObjects()), r.newState().getChangeMetaId());
            }
        }
        return LoadHandle.create(ChangeNotesCommit.newRevWalk(repo), r.newState().getChangeMetaId());
    } catch (NoSuchChangeException e) {
        return super.openHandle(repo, oldId);
    } catch (OrmException e) {
        throw new IOException(e);
    } finally {
        log.debug("Rebuilt change {} in project {} in {} ms", getChangeId(), getProjectName(), TimeUnit.MILLISECONDS.convert(timer.stop(), TimeUnit.NANOSECONDS));
    }
}
#end_block

#method_before
public List<SubmitRecord> evaluate() {
    initOptions();
    try {
        init();
    } catch (OrmException e) {
        return ruleError("Error looking up change " + cd.getId(), e);
    }
    if (!opts.allowClosed() && change.getStatus().isClosed()) {
        SubmitRecord rec = new SubmitRecord();
        rec.status = SubmitRecord.Status.CLOSED;
        return Collections.singletonList(rec);
    }
    List<Term> results;
    try {
        results = evaluateImpl("locate_submit_rule", "can_submit", "locate_submit_filter", "filter_submit_results");
    } catch (RuleEvalException e) {
        return ruleError(e.getMessage(), e);
    }
    if (results.isEmpty()) {
        // whether or not that is actually possible given the permissions.
        return ruleError(String.format("Submit rule '%s' for change %s of %s has no solution.", getSubmitRuleName(), cd.getId(), getProjectName()));
    }
    return resultsToSubmitRecord(getSubmitRule(), results);
}
#method_after
public List<SubmitRecord> evaluate() {
    initOptions();
    try {
        init();
    } catch (OrmException | NoSuchProjectException e) {
        return ruleError("Error looking up change " + cd.getId(), e);
    }
    if (!opts.allowClosed() && change.getStatus().isClosed()) {
        SubmitRecord rec = new SubmitRecord();
        rec.status = SubmitRecord.Status.CLOSED;
        return Collections.singletonList(rec);
    }
    List<Term> results;
    try {
        results = evaluateImpl("locate_submit_rule", "can_submit", "locate_submit_filter", "filter_submit_results");
    } catch (RuleEvalException e) {
        return ruleError(e.getMessage(), e);
    }
    if (results.isEmpty()) {
        // whether or not that is actually possible given the permissions.
        return ruleError(String.format("Submit rule '%s' for change %s of %s has no solution.", getSubmitRuleName(), cd.getId(), getProjectName()));
    }
    return resultsToSubmitRecord(getSubmitRule(), results);
}
#end_block

#method_before
public SubmitTypeRecord getSubmitType() {
    initOptions();
    try {
        init();
    } catch (OrmException e) {
        return typeError("Error looking up change " + cd.getId(), e);
    }
    List<Term> results;
    try {
        results = evaluateImpl("locate_submit_type", "get_submit_type", "locate_submit_type_filter", "filter_submit_type_results");
    } catch (RuleEvalException e) {
        return typeError(e.getMessage(), e);
    }
    if (results.isEmpty()) {
        // Should never occur for a well written rule
        return typeError("Submit rule '" + getSubmitRuleName() + "' for change " + cd.getId() + " of " + getProjectName() + " has no solution.");
    }
    Term typeTerm = results.get(0);
    if (!(typeTerm instanceof SymbolTerm)) {
        return typeError("Submit rule '" + getSubmitRuleName() + "' for change " + cd.getId() + " of " + getProjectName() + " did not return a symbol.");
    }
    String typeName = ((SymbolTerm) typeTerm).name();
    try {
        return SubmitTypeRecord.OK(SubmitType.valueOf(typeName.toUpperCase()));
    } catch (IllegalArgumentException e) {
        return typeError("Submit type rule " + getSubmitRule() + " for change " + cd.getId() + " of " + getProjectName() + " output invalid result: " + typeName);
    }
}
#method_after
public SubmitTypeRecord getSubmitType() {
    initOptions();
    try {
        init();
    } catch (OrmException | NoSuchProjectException e) {
        return typeError("Error looking up change " + cd.getId(), e);
    }
    List<Term> results;
    try {
        results = evaluateImpl("locate_submit_type", "get_submit_type", "locate_submit_type_filter", "filter_submit_type_results");
    } catch (RuleEvalException e) {
        return typeError(e.getMessage(), e);
    }
    if (results.isEmpty()) {
        // Should never occur for a well written rule
        return typeError("Submit rule '" + getSubmitRuleName() + "' for change " + cd.getId() + " of " + getProjectName() + " has no solution.");
    }
    Term typeTerm = results.get(0);
    if (!(typeTerm instanceof SymbolTerm)) {
        return typeError("Submit rule '" + getSubmitRuleName() + "' for change " + cd.getId() + " of " + getProjectName() + " did not return a symbol.");
    }
    String typeName = ((SymbolTerm) typeTerm).name();
    try {
        return SubmitTypeRecord.OK(SubmitType.valueOf(typeName.toUpperCase()));
    } catch (IllegalArgumentException e) {
        return typeError("Submit type rule " + getSubmitRule() + " for change " + cd.getId() + " of " + getProjectName() + " output invalid result: " + typeName);
    }
}
#end_block

#method_before
private void init() throws OrmException {
    if (change == null) {
        change = cd.change();
        if (change == null) {
            throw new OrmException("No change found");
        }
    }
    if (projectState == null) {
        try {
            projectState = projectCache.checkedGet(change.getProject());
        } catch (IOException e) {
            throw new OrmException("Can't load project state", e);
        }
    }
    if (patchSet == null) {
        patchSet = cd.currentPatchSet();
        if (patchSet == null) {
            throw new OrmException("No patch set found");
        }
    }
}
#method_after
private void init() throws OrmException, NoSuchProjectException {
    if (change == null) {
        change = cd.change();
        if (change == null) {
            throw new OrmException("No change found");
        }
    }
    if (projectState == null) {
        projectState = projectCache.get(change.getProject());
        if (projectState == null) {
            throw new NoSuchProjectException(change.getProject());
        }
    }
    if (patchSet == null) {
        patchSet = cd.currentPatchSet();
        if (patchSet == null) {
            throw new OrmException("No patch set found");
        }
    }
}
#end_block

#method_before
public Boolean isMergeable() throws OrmException {
    if (mergeable == null) {
        Change c = change();
        if (c == null) {
            return null;
        }
        if (c.getStatus() == Change.Status.MERGED) {
            mergeable = true;
        } else if (c.getStatus() == Change.Status.ABANDONED) {
            return null;
        } else if (c.isWorkInProgress()) {
            return null;
        } else {
            if (!lazyLoad) {
                return null;
            }
            PatchSet ps = currentPatchSet();
            if (ps == null) {
                return null;
            }
            try (Repository repo = repoManager.openRepository(project())) {
                Ref ref = repo.getRefDatabase().exactRef(c.getDest().get());
                SubmitTypeRecord str = submitTypeRecord();
                if (!str.isOk()) {
                    // No need to log, as SubmitRuleEvaluator already did it for us.
                    return false;
                }
                String mergeStrategy = mergeUtilFactory.create(projectCache.get(project())).mergeStrategyName();
                mergeable = mergeabilityCache.get(ObjectId.fromString(ps.getRevision().get()), ref, str.type, mergeStrategy, c.getDest(), repo);
            } catch (IOException e) {
                throw new OrmException(e);
            }
        }
    }
    return mergeable;
}
#method_after
@Nullable
public Boolean isMergeable() throws OrmException {
    if (mergeable == null) {
        Change c = change();
        if (c == null) {
            return null;
        }
        if (c.getStatus() == Change.Status.MERGED) {
            mergeable = true;
        } else if (c.getStatus() == Change.Status.ABANDONED) {
            return null;
        } else if (c.isWorkInProgress()) {
            return null;
        } else {
            if (!lazyLoad) {
                return null;
            }
            PatchSet ps = currentPatchSet();
            if (ps == null) {
                return null;
            }
            try (Repository repo = repoManager.openRepository(project())) {
                Ref ref = repo.getRefDatabase().exactRef(c.getDest().get());
                SubmitTypeRecord str = submitTypeRecord();
                if (!str.isOk()) {
                    // No need to log, as SubmitRuleEvaluator already did it for us.
                    return false;
                }
                String mergeStrategy = mergeUtilFactory.create(projectCache.get(project())).mergeStrategyName();
                mergeable = mergeabilityCache.get(ObjectId.fromString(ps.getRevision().get()), ref, str.type, mergeStrategy, c.getDest(), repo);
            } catch (IOException e) {
                throw new OrmException(e);
            }
        }
    }
    return mergeable;
}
#end_block

#method_before
public Map<Account.Id, Ref> editRefs() throws OrmException {
    if (editsByUser == null) {
        if (!lazyLoad) {
            return Collections.emptyMap();
        }
        Change c = change();
        if (c == null) {
            return Collections.emptyMap();
        }
        editsByUser = new HashMap<>();
        Change.Id id = checkNotNull(change.getId());
        try (Repository repo = repoManager.openRepository(project())) {
            for (Map.Entry<String, Ref> e : repo.getRefDatabase().getRefs(RefNames.REFS_USERS).entrySet()) {
                if (id.equals(Change.Id.fromEditRefPart(e.getKey()))) {
                    editsByUser.put(Account.Id.fromRefPart(e.getKey()), e.getValue());
                }
            }
        } catch (IOException e) {
            throw new OrmException(e);
        }
    }
    return editsByUser;
}
#method_after
public Map<Account.Id, Ref> editRefs() throws OrmException {
    if (editsByUser == null) {
        if (!lazyLoad) {
            return Collections.emptyMap();
        }
        Change c = change();
        if (c == null) {
            return Collections.emptyMap();
        }
        editsByUser = new HashMap<>();
        Change.Id id = checkNotNull(change.getId());
        try (Repository repo = repoManager.openRepository(project())) {
            for (Map.Entry<String, Ref> e : repo.getRefDatabase().getRefs(RefNames.REFS_USERS).entrySet()) {
                if (id.equals(Change.Id.fromEditRefPart(e.getKey()))) {
                    Account.Id accountId = Account.Id.fromRefPart(e.getKey());
                    if (accountId != null) {
                        editsByUser.put(accountId, e.getValue());
                    }
                }
            }
        } catch (IOException e) {
            throw new OrmException(e);
        }
    }
    return editsByUser;
}
#end_block

#method_before
@Nullable
public Boolean isPureRevert() throws OrmException {
    if (change().getRevertOf() == null) {
        return null;
    }
    try {
        return pureRevert.getPureRevert(notes()).isPureRevert;
    } catch (IOException | BadRequestException | ResourceConflictException e) {
        throw new OrmException("could not compute pure revert", e);
    }
}
#method_after
@Nullable
public Boolean isPureRevert() throws OrmException {
    if (change().getRevertOf() == null) {
        return null;
    }
    try {
        return pureRevert.get(notes(), null).isPureRevert;
    } catch (IOException | BadRequestException | ResourceConflictException e) {
        throw new OrmException("could not compute pure revert", e);
    }
}
#end_block

#method_before
@Override
public final boolean updateChange(ChangeContext ctx) throws Exception {
    logger.atFine().log("%s#updateChange for change %s", getClass().getSimpleName(), toMerge.change().getId());
    // Update change and notes from ctx.
    toMerge.setNotes(ctx.getNotes());
    PatchSet.Id oldPsId = checkNotNull(toMerge.getPatchsetId());
    PatchSet.Id newPsId;
    if (ctx.getChange().getStatus() == Change.Status.MERGED) {
        // repo failed with lock failure.
        if (alreadyMergedCommit == null) {
            logger.atFine().log("Change is already merged according to its status, but we were unable to find it" + " merged into the current tip (%s)", args.mergeTip.getCurrentTip().name());
        } else {
            logger.atFine().log("Change is already merged");
        }
        changeAlreadyMerged = true;
        return false;
    }
    if (alreadyMergedCommit != null) {
        alreadyMergedCommit.setNotes(ctx.getNotes());
        mergedPatchSet = getOrCreateAlreadyMergedPatchSet(ctx);
    } else {
        PatchSet newPatchSet = updateChangeImpl(ctx);
        newPsId = checkNotNull(ctx.getChange().currentPatchSetId());
        if (newPatchSet == null) {
            checkState(oldPsId.equals(newPsId), "patch set advanced from %s to %s but updateChangeImpl did not" + " return new patch set instance", oldPsId, newPsId);
            // Ok to use stale notes to get the old patch set, which didn't change
            // during the submit strategy.
            mergedPatchSet = checkNotNull(args.psUtil.get(ctx.getDb(), ctx.getNotes(), oldPsId), "missing old patch set %s", oldPsId);
        } else {
            PatchSet.Id n = newPatchSet.getId();
            checkState(!n.equals(oldPsId) && n.equals(newPsId), "current patch was %s and is now %s, but updateChangeImpl returned" + " new patch set instance at %s", oldPsId, newPsId, n);
            mergedPatchSet = newPatchSet;
        }
    }
    Change c = ctx.getChange();
    Change.Id id = c.getId();
    CodeReviewCommit commit = args.commitStatus.get(id);
    checkNotNull(commit, "missing commit for change " + id);
    CommitMergeStatus s = commit.getStatusCode();
    checkNotNull(s, "status not set for change " + id + " expected to previously fail fast");
    logger.atFine().log("Status of change %s (%s) on %s: %s", id, commit.name(), c.getDest(), s);
    setApproval(ctx, args.caller);
    mergeResultRev = alreadyMergedCommit == null ? args.mergeTip.getMergeResults().get(commit) : // ChangeMergedEvent in the fixup case, but we'll just live with that.
    alreadyMergedCommit;
    try {
        setMerged(ctx, message(ctx, commit, s));
    } catch (OrmException err) {
        String msg = "Error updating change status for " + id;
        logger.atSevere().withCause(err).log(msg);
        args.commitStatus.logProblem(id, msg);
    // It's possible this happened before updating anything in the db, but
    // it's hard to know for sure, so just return true below to be safe.
    }
    updatedChange = c;
    return true;
}
#method_after
@Override
public final boolean updateChange(ChangeContext ctx) throws Exception {
    logger.atFine().log("%s#updateChange for change %s", getClass().getSimpleName(), toMerge.change().getId());
    // Update change and notes from ctx.
    toMerge.setNotes(ctx.getNotes());
    if (ctx.getChange().getStatus() == Change.Status.MERGED) {
        // repo failed with lock failure.
        if (alreadyMergedCommit == null) {
            logger.atFine().log("Change is already merged according to its status, but we were unable to find it" + " merged into the current tip (%s)", args.mergeTip.getCurrentTip().name());
        } else {
            logger.atFine().log("Change is already merged");
        }
        changeAlreadyMerged = true;
        return false;
    }
    if (alreadyMergedCommit != null) {
        alreadyMergedCommit.setNotes(ctx.getNotes());
        mergedPatchSet = getOrCreateAlreadyMergedPatchSet(ctx);
    } else {
        PatchSet newPatchSet = updateChangeImpl(ctx);
        PatchSet.Id oldPsId = checkNotNull(toMerge.getPatchsetId());
        PatchSet.Id newPsId = checkNotNull(ctx.getChange().currentPatchSetId());
        if (newPatchSet == null) {
            checkState(oldPsId.equals(newPsId), "patch set advanced from %s to %s but updateChangeImpl did not" + " return new patch set instance", oldPsId, newPsId);
            // Ok to use stale notes to get the old patch set, which didn't change
            // during the submit strategy.
            mergedPatchSet = checkNotNull(args.psUtil.get(ctx.getDb(), ctx.getNotes(), oldPsId), "missing old patch set %s", oldPsId);
        } else {
            PatchSet.Id n = newPatchSet.getId();
            checkState(!n.equals(oldPsId) && n.equals(newPsId), "current patch was %s and is now %s, but updateChangeImpl returned" + " new patch set instance at %s", oldPsId, newPsId, n);
            mergedPatchSet = newPatchSet;
        }
    }
    Change c = ctx.getChange();
    Change.Id id = c.getId();
    CodeReviewCommit commit = args.commitStatus.get(id);
    checkNotNull(commit, "missing commit for change " + id);
    CommitMergeStatus s = commit.getStatusCode();
    checkNotNull(s, "status not set for change " + id + " expected to previously fail fast");
    logger.atFine().log("Status of change %s (%s) on %s: %s", id, commit.name(), c.getDest(), s);
    setApproval(ctx, args.caller);
    mergeResultRev = alreadyMergedCommit == null ? args.mergeTip.getMergeResults().get(commit) : // ChangeMergedEvent in the fixup case, but we'll just live with that.
    alreadyMergedCommit;
    try {
        setMerged(ctx, message(ctx, commit, s));
    } catch (OrmException err) {
        String msg = "Error updating change status for " + id;
        logger.atSevere().withCause(err).log(msg);
        args.commitStatus.logProblem(id, msg);
    // It's possible this happened before updating anything in the db, but
    // it's hard to know for sure, so just return true below to be safe.
    }
    updatedChange = c;
    return true;
}
#end_block

#method_before
public void fire(Change change, Account deleter, Timestamp when, NotifyHandling notifyHandling) {
    if (!listeners.iterator().hasNext()) {
        return;
    }
    try {
        Event event = new Event(util.changeInfo(change), util.accountInfo(deleter), when, notifyHandling);
        for (ChangeDeletedListener l : listeners) {
            try {
                l.onChangeDeleted(event);
            } catch (Exception e) {
                util.logEventListenerError(this, l, e);
            }
        }
    } catch (OrmException e) {
        log.error("Couldn't fire event", e);
    }
}
#method_after
public void fire(Change change, Account deleter, Timestamp when) {
    if (!listeners.iterator().hasNext()) {
        return;
    }
    try {
        Event event = new Event(util.changeInfo(change), util.accountInfo(deleter), when);
        for (ChangeDeletedListener l : listeners) {
            try {
                l.onChangeDeleted(event);
            } catch (Exception e) {
                util.logEventListenerError(this, l, e);
            }
        }
    } catch (OrmException e) {
        log.error("Couldn't fire event", e);
    }
}
#end_block

#method_before
@Override
public boolean updateChange(ChangeContext ctx) throws RestApiException, OrmException, IOException, NoSuchChangeException {
    checkState(ctx.getOrder() == Order.DB_BEFORE_REPO, "must use DeleteChangeOp with DB_BEFORE_REPO");
    checkState(id == null, "cannot reuse DeleteChangeOp");
    id = ctx.getChange().getId();
    Collection<PatchSet> patchSets = psUtil.byChange(ctx.getDb(), ctx.getNotes());
    ensureDeletable(ctx, id, patchSets);
    // Cleaning up is only possible as long as the change and its elements are
    // still part of the database.
    cleanUpReferences(ctx, id, patchSets);
    deleteChangeElementsFromDb(ctx, id);
    ctx.deleteChange();
    changeDeleted.fire(ctx.getChange(), ctx.getAccount(), ctx.getWhen(), NotifyHandling.ALL);
    return true;
}
#method_after
@Override
public boolean updateChange(ChangeContext ctx) throws RestApiException, OrmException, IOException, NoSuchChangeException {
    checkState(ctx.getOrder() == Order.DB_BEFORE_REPO, "must use DeleteChangeOp with DB_BEFORE_REPO");
    checkState(id == null, "cannot reuse DeleteChangeOp");
    id = ctx.getChange().getId();
    Collection<PatchSet> patchSets = psUtil.byChange(ctx.getDb(), ctx.getNotes());
    ensureDeletable(ctx, id, patchSets);
    // Cleaning up is only possible as long as the change and its elements are
    // still part of the database.
    cleanUpReferences(ctx, id, patchSets);
    deleteChangeElementsFromDb(ctx, id);
    ctx.deleteChange();
    changeDeleted.fire(ctx.getChange(), ctx.getAccount(), ctx.getWhen());
    return true;
}
#end_block

#method_before
public static Module module() {
    return new CacheModule() {

        @Override
        protected void configure() {
            persist(OAUTH_TOKENS, Account.Id.class, OAuthToken.class).version(1).keySerializer(CacheSerializers.newIntKeySerializer(Account.Id::new)).valueSerializer(new Serializer());
        }
    };
}
#method_after
public static Module module() {
    return new CacheModule() {

        @Override
        protected void configure() {
            persist(OAUTH_TOKENS, Account.Id.class, OAuthToken.class).version(1).keySerializer(new IntKeyCacheSerializer<>(Account.Id::new)).valueSerializer(new Serializer());
        }
    };
}
#end_block

#method_before
@Override
public byte[] serialize(OAuthToken object) throws IOException {
    return ProtoCacheSerializers.toByteArray(OAuthTokenProto.newBuilder().setToken(object.getToken()).setSecret(object.getSecret()).setRaw(object.getRaw()).setExpiresAt(object.getExpiresAt()).setProviderId(Strings.nullToEmpty(object.getProviderId())).build());
}
#method_after
@Override
public byte[] serialize(OAuthToken object) {
    return ProtoCacheSerializers.toByteArray(OAuthTokenProto.newBuilder().setToken(object.getToken()).setSecret(object.getSecret()).setRaw(object.getRaw()).setExpiresAt(object.getExpiresAt()).setProviderId(Strings.nullToEmpty(object.getProviderId())).build());
}
#end_block

#method_before
@Override
public OAuthToken deserialize(byte[] in) throws IOException {
    OAuthTokenProto proto = OAuthTokenProto.parseFrom(in);
    return new OAuthToken(proto.getToken(), proto.getSecret(), proto.getRaw(), proto.getExpiresAt(), Strings.emptyToNull(proto.getProviderId()));
}
#method_after
@Override
public OAuthToken deserialize(byte[] in) {
    OAuthTokenProto proto;
    try {
        proto = OAuthTokenProto.parseFrom(in);
    } catch (IOException e) {
        throw new IllegalArgumentException("failed to deserialize OAuthToken");
    }
    return new OAuthToken(proto.getToken(), proto.getSecret(), proto.getRaw(), proto.getExpiresAt(), Strings.emptyToNull(proto.getProviderId()));
}
#end_block

#method_before
private void deleteFromPatchSets(ReviewDb db, final ResultSet<PatchSet> patchSets) throws OrmException {
    for (PatchSet patchSet : patchSets) {
        accountPatchReviewStore.get().clearReviewed(patchSet.getId());
        db.patchSets().delete(Collections.singleton(patchSet));
    }
}
#method_after
private void deleteFromPatchSets(ReviewDb db, ResultSet<PatchSet> patchSets) throws OrmException {
    for (PatchSet patchSet : patchSets) {
        accountPatchReviewStore.get().clearReviewed(patchSet.getId());
        db.patchSets().delete(Collections.singleton(patchSet));
    }
}
#end_block

#method_before
void assertCanBeDeleted(ProjectResource rsrc, Input input) throws ResourceConflictException {
    try {
        protectedProjects.assertIsNotProtected(rsrc);
        assertHasNoChildProjects(rsrc);
        Project.NameKey projectNameKey = rsrc.getNameKey();
        assertIsNotSubmodule(projectNameKey);
        assertDeleteWithTags(projectNameKey, input == null || input.preserve);
        assertHasOpenChanges(projectNameKey, input == null || input.force);
    } catch (CannotDeleteProjectException e) {
        throw new ResourceConflictException(e.getMessage());
    }
}
#method_after
void assertCanBeDeleted(ProjectResource rsrc, Input input) throws ResourceConflictException {
    try {
        protectedProjects.assertIsNotProtected(rsrc);
        assertHasNoChildProjects(rsrc);
        Project.NameKey projectNameKey = rsrc.getNameKey();
        assertIsNotSubmodule(projectNameKey);
        assertDeleteWithTags(projectNameKey, input != null && input.preserve);
        assertHasOpenChanges(projectNameKey, input != null && input.force);
    } catch (CannotDeleteProjectException e) {
        throw new ResourceConflictException(e.getMessage());
    }
}
#end_block

#method_before
public void assertHasOpenChanges(Project.NameKey projectNameKey, boolean force) throws CannotDeleteProjectException {
    if (!force) {
        try {
            List<ChangeData> openChanges = queryProvider.get().byProjectOpen(projectNameKey);
            if (!openChanges.isEmpty()) {
                throw new CannotDeleteProjectException(String.format("Project '%s' has open changes.", projectNameKey.get()));
            }
        } catch (OrmException e) {
            throw new CannotDeleteProjectException(String.format("Unable to verify if %s has open changes.", projectNameKey.get()));
        }
    }
}
#method_after
public void assertHasOpenChanges(Project.NameKey projectNameKey, boolean force) throws CannotDeleteProjectException {
    if (!force) {
        try {
            List<ChangeData> openChanges = queryProvider.get().byProjectOpen(projectNameKey);
            if (!openChanges.isEmpty()) {
                throw new CannotDeleteProjectException(String.format("Project '%s' has open changes.", projectNameKey.get()));
            }
        } catch (OrmException e) {
            throw new CannotDeleteProjectException(String.format("Unable to verify if '%s' has open changes.", projectNameKey.get()));
        }
    }
}
#end_block

#method_before
private void assertHasNoChildProjects(ProjectResource rsrc) throws CannotDeleteProjectException {
    List<ProjectInfo> children = listChildProjectsProvider.get().apply(rsrc);
    if (!children.isEmpty()) {
        throw new CannotDeleteProjectException("Cannot delete project because it has children: " + String.join(", ", children.stream().map(info -> info.name).collect(Collectors.toList())));
    }
}
#method_after
private void assertHasNoChildProjects(ProjectResource rsrc) throws CannotDeleteProjectException {
    List<ProjectInfo> children = listChildProjectsProvider.get().apply(rsrc);
    if (!children.isEmpty()) {
        throw new CannotDeleteProjectException("Cannot delete project because it has children: " + children.stream().map(info -> info.name).collect(joining(",")));
    }
}
#end_block

#method_before
@Test(expected = AuthException.class)
public void testUserCannotDelete() throws AuthException {
    when(ctl.canAdministrateServer()).thenReturn(false);
    when(ctl.canPerform(DELETE_PROJECT_PERMISSION)).thenReturn(false);
    when(ctl.canPerform(DELETE_OWN_PROJECT_PERMISSION)).thenReturn(false);
    when(userProvider.get()).thenReturn(user);
    when(user.getCapabilities()).thenReturn(ctl);
    preConditions.assertDeletePermission(rsrc);
}
#method_after
@Test
public void testUserCannotDelete() throws Exception {
    when(ctl.canAdministrateServer()).thenReturn(false);
    when(ctl.canPerform(DELETE_PROJECT_PERMISSION)).thenReturn(false);
    when(ctl.canPerform(DELETE_OWN_PROJECT_PERMISSION)).thenReturn(false);
    when(userProvider.get()).thenReturn(user);
    when(user.getCapabilities()).thenReturn(ctl);
    expectedException.expect(AuthException.class);
    expectedException.expectMessage("not allowed to delete project");
    preConditions.assertDeletePermission(rsrc);
}
#end_block

#method_before
@Test(expected = CannotDeleteProjectException.class)
public void testAssertHasOpenChangesNoForceSet() throws Exception {
    InternalChangeQuery queryChange = mock(InternalChangeQuery.class);
    ChangeData cd = mock(ChangeData.class);
    when(queryChange.byProjectOpen(PROJECT_NAMEKEY)).thenReturn(ImmutableList.of(cd));
    when(queryProvider.get()).thenReturn(queryChange);
    preConditions.assertHasOpenChanges(PROJECT_NAMEKEY, false);
}
#method_after
@Test
public void testAssertHasOpenChangesNoForceSet() throws Exception {
    InternalChangeQuery queryChange = mock(InternalChangeQuery.class);
    ChangeData cd = mock(ChangeData.class);
    when(queryChange.byProjectOpen(PROJECT_NAMEKEY)).thenReturn(ImmutableList.of(cd));
    when(queryProvider.get()).thenReturn(queryChange);
    String expectedMessage = String.format("Project '%s' has open changes.", PROJECT_NAMEKEY.get());
    expectedException.expectMessage(expectedMessage);
    expectedException.expect(CannotDeleteProjectException.class);
    preConditions.assertHasOpenChanges(PROJECT_NAMEKEY, false);
}
#end_block

#method_before
@Test(expected = CannotDeleteProjectException.class)
public void testUnableToAssertOpenChanges() throws Exception {
    InternalChangeQuery queryChange = mock(InternalChangeQuery.class);
    doThrow(OrmException.class).when(queryChange).byProjectOpen(PROJECT_NAMEKEY);
    when(queryProvider.get()).thenReturn(queryChange);
    preConditions.assertHasOpenChanges(PROJECT_NAMEKEY, false);
}
#method_after
@Test
public void testUnableToAssertOpenChanges() throws Exception {
    InternalChangeQuery queryChange = mock(InternalChangeQuery.class);
    doThrow(OrmException.class).when(queryChange).byProjectOpen(PROJECT_NAMEKEY);
    when(queryProvider.get()).thenReturn(queryChange);
    String expectedMessage = String.format("Unable to verify if '%s' has open changes.", PROJECT_NAMEKEY.get());
    expectedException.expectMessage(expectedMessage);
    expectedException.expect(CannotDeleteProjectException.class);
    preConditions.assertHasOpenChanges(PROJECT_NAMEKEY, false);
}
#end_block

#method_before
@Override
protected void configure() {
    bind(EmailExpander.class).toProvider(EmailExpanderProvider.class).in(SINGLETON);
    bind(IdGenerator.class);
    bind(RulesCache.class);
    bind(BlameCache.class).to(BlameCacheImpl.class);
    bind(Sequences.class);
    install(authModule);
    install(AccountCacheImpl.module());
    install(BatchUpdate.module());
    install(ChangeKindCacheImpl.module());
    install(ChangeFinder.module());
    install(ConflictsCacheImpl.module());
    install(GroupCacheImpl.module());
    install(GroupIncludeCacheImpl.module());
    install(MergeabilityCacheImpl.module());
    install(PatchListCacheImpl.module());
    install(ProjectCacheImpl.module());
    install(SectionSortCache.module());
    install(SubmitStrategy.module());
    install(TagCache.module());
    install(OAuthTokenCache.module());
    install(new AccessControlModule());
    install(new CmdLineParserModule());
    install(new EmailModule());
    install(new ExternalIdModule());
    install(new GitModule());
    install(new GroupDbModule());
    install(new GroupModule());
    install(new NoteDbModule(cfg));
    install(new PrologModule());
    install(new DefaultSubmitRule.Module());
    install(new RequireNonAuthorApprovalRule.Module());
    install(new ReceiveCommitsModule());
    install(new SshAddressesModule());
    install(ThreadLocalRequestContext.module());
    bind(AccountResolver.class);
    factory(AddReviewerSender.Factory.class);
    factory(DeleteReviewerSender.Factory.class);
    factory(AddKeySender.Factory.class);
    factory(CapabilityCollection.Factory.class);
    factory(ChangeData.AssistedFactory.class);
    factory(ChangeJson.AssistedFactory.class);
    factory(CreateChangeSender.Factory.class);
    factory(MergedSender.Factory.class);
    factory(MergeUtil.Factory.class);
    factory(PatchScriptFactory.Factory.class);
    factory(ProjectState.Factory.class);
    factory(RegisterNewEmailSender.Factory.class);
    factory(ReplacePatchSetSender.Factory.class);
    factory(SetAssigneeSender.Factory.class);
    factory(InboundEmailRejectionSender.Factory.class);
    bind(PermissionCollection.Factory.class);
    bind(AccountVisibility.class).toProvider(AccountVisibilityProvider.class).in(SINGLETON);
    factory(ProjectOwnerGroupsProvider.Factory.class);
    factory(SubmitRuleEvaluator.Factory.class);
    bind(AuthBackend.class).to(UniversalAuthBackend.class).in(SINGLETON);
    DynamicSet.setOf(binder(), AuthBackend.class);
    bind(GroupControl.Factory.class).in(SINGLETON);
    bind(GroupControl.GenericFactory.class).in(SINGLETON);
    bind(FileTypeRegistry.class).to(MimeUtilFileTypeRegistry.class);
    bind(ToolsCatalog.class);
    bind(EventFactory.class);
    bind(TransferConfig.class);
    bind(GcConfig.class);
    DynamicSet.setOf(binder(), GerritConfigListener.class);
    bind(ChangeCleanupConfig.class);
    bind(AccountDeactivator.class);
    bind(ApprovalsUtil.class);
    bind(SoyTofu.class).annotatedWith(MailTemplates.class).toProvider(MailSoyTofuProvider.class);
    bind(FromAddressGenerator.class).toProvider(FromAddressGeneratorProvider.class).in(SINGLETON);
    bind(Boolean.class).annotatedWith(DisableReverseDnsLookup.class).toProvider(DisableReverseDnsLookupProvider.class).in(SINGLETON);
    bind(PatchSetInfoFactory.class);
    bind(IdentifiedUser.GenericFactory.class).in(SINGLETON);
    bind(AccountControl.Factory.class);
    bind(UiActions.class);
    bind(GitReferenceUpdated.class);
    DynamicMap.mapOf(binder(), new TypeLiteral<Cache<?, ?>>() {
    });
    DynamicSet.setOf(binder(), CacheRemovalListener.class);
    DynamicMap.mapOf(binder(), CapabilityDefinition.class);
    DynamicSet.setOf(binder(), GitReferenceUpdatedListener.class);
    DynamicSet.setOf(binder(), AssigneeChangedListener.class);
    DynamicSet.setOf(binder(), ChangeAbandonedListener.class);
    DynamicSet.setOf(binder(), CommentAddedListener.class);
    DynamicSet.setOf(binder(), HashtagsEditedListener.class);
    DynamicSet.setOf(binder(), ChangeMergedListener.class);
    bind(ChangeMergedListener.class).annotatedWith(Exports.named("CreateGroupPermissionSyncer")).to(CreateGroupPermissionSyncer.class);
    DynamicSet.setOf(binder(), ChangeRestoredListener.class);
    DynamicSet.setOf(binder(), ChangeRevertedListener.class);
    DynamicSet.setOf(binder(), PrivateStateChangedListener.class);
    DynamicSet.setOf(binder(), ReviewerAddedListener.class);
    DynamicSet.setOf(binder(), ReviewerDeletedListener.class);
    DynamicSet.setOf(binder(), VoteDeletedListener.class);
    DynamicSet.setOf(binder(), WorkInProgressStateChangedListener.class);
    DynamicSet.setOf(binder(), RevisionCreatedListener.class);
    DynamicSet.setOf(binder(), TopicEditedListener.class);
    DynamicSet.setOf(binder(), AgreementSignupListener.class);
    DynamicSet.setOf(binder(), PluginEventListener.class);
    DynamicSet.setOf(binder(), ReceivePackInitializer.class);
    DynamicSet.setOf(binder(), PostReceiveHook.class);
    DynamicSet.setOf(binder(), PreUploadHook.class);
    DynamicSet.setOf(binder(), PostUploadHook.class);
    DynamicSet.setOf(binder(), AccountIndexedListener.class);
    DynamicSet.setOf(binder(), ChangeIndexedListener.class);
    DynamicSet.setOf(binder(), GroupIndexedListener.class);
    DynamicSet.setOf(binder(), ProjectIndexedListener.class);
    DynamicSet.setOf(binder(), NewProjectCreatedListener.class);
    DynamicSet.setOf(binder(), ProjectDeletedListener.class);
    DynamicSet.setOf(binder(), GarbageCollectorListener.class);
    DynamicSet.setOf(binder(), HeadUpdatedListener.class);
    DynamicSet.setOf(binder(), UsageDataPublishedListener.class);
    DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(ReindexAfterRefUpdate.class);
    DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(ProjectConfigEntry.UpdateChecker.class);
    DynamicSet.setOf(binder(), EventListener.class);
    DynamicSet.bind(binder(), EventListener.class).to(EventsMetrics.class);
    DynamicSet.setOf(binder(), UserScopedEventListener.class);
    DynamicSet.setOf(binder(), CommitValidationListener.class);
    DynamicSet.setOf(binder(), ChangeMessageModifier.class);
    DynamicSet.setOf(binder(), RefOperationValidationListener.class);
    DynamicSet.setOf(binder(), OnSubmitValidationListener.class);
    DynamicSet.setOf(binder(), MergeValidationListener.class);
    DynamicSet.setOf(binder(), ProjectCreationValidationListener.class);
    DynamicSet.setOf(binder(), GroupCreationValidationListener.class);
    DynamicSet.setOf(binder(), HashtagValidationListener.class);
    DynamicSet.setOf(binder(), OutgoingEmailValidationListener.class);
    DynamicSet.setOf(binder(), AccountActivationValidationListener.class);
    DynamicItem.itemOf(binder(), AvatarProvider.class);
    DynamicSet.setOf(binder(), LifecycleListener.class);
    DynamicSet.setOf(binder(), TopMenu.class);
    DynamicSet.setOf(binder(), MessageOfTheDay.class);
    DynamicMap.mapOf(binder(), DownloadScheme.class);
    DynamicMap.mapOf(binder(), DownloadCommand.class);
    DynamicMap.mapOf(binder(), CloneCommand.class);
    DynamicMap.mapOf(binder(), ReviewerSuggestion.class);
    DynamicSet.bind(binder(), GerritConfigListener.class).toInstance(SuggestReviewers.configListener());
    DynamicSet.setOf(binder(), ExternalIncludedIn.class);
    DynamicMap.mapOf(binder(), ProjectConfigEntry.class);
    DynamicSet.setOf(binder(), PatchSetWebLink.class);
    DynamicSet.setOf(binder(), ParentWebLink.class);
    DynamicSet.setOf(binder(), FileWebLink.class);
    DynamicSet.setOf(binder(), FileHistoryWebLink.class);
    DynamicSet.setOf(binder(), DiffWebLink.class);
    DynamicSet.setOf(binder(), ProjectWebLink.class);
    DynamicSet.setOf(binder(), BranchWebLink.class);
    DynamicSet.setOf(binder(), TagWebLink.class);
    DynamicMap.mapOf(binder(), OAuthLoginProvider.class);
    DynamicItem.itemOf(binder(), OAuthTokenEncrypter.class);
    DynamicSet.setOf(binder(), AccountExternalIdCreator.class);
    DynamicSet.setOf(binder(), WebUiPlugin.class);
    DynamicItem.itemOf(binder(), AccountPatchReviewStore.class);
    DynamicSet.setOf(binder(), AssigneeValidationListener.class);
    DynamicSet.setOf(binder(), ActionVisitor.class);
    DynamicItem.itemOf(binder(), MergeSuperSetComputation.class);
    DynamicItem.itemOf(binder(), ProjectNameLockManager.class);
    DynamicSet.setOf(binder(), SubmitRule.class);
    DynamicMap.mapOf(binder(), MailFilter.class);
    bind(MailFilter.class).annotatedWith(Exports.named("ListMailFilter")).to(ListMailFilter.class);
    bind(AutoReplyMailFilter.class).annotatedWith(Exports.named("AutoReplyMailFilter")).to(AutoReplyMailFilter.class);
    factory(UploadValidators.Factory.class);
    DynamicSet.setOf(binder(), UploadValidationListener.class);
    DynamicMap.mapOf(binder(), ChangeQueryBuilder.ChangeOperatorFactory.class);
    DynamicMap.mapOf(binder(), ChangeQueryBuilder.ChangeHasOperandFactory.class);
    DynamicMap.mapOf(binder(), ChangeQueryProcessor.ChangeAttributeFactory.class);
    install(new GitwebConfig.LegacyModule(cfg));
    bind(AnonymousUser.class);
    factory(AbandonOp.Factory.class);
    factory(AccountMergeValidator.Factory.class);
    factory(GroupMergeValidator.Factory.class);
    factory(RefOperationValidators.Factory.class);
    factory(OnSubmitValidators.Factory.class);
    factory(MergeValidators.Factory.class);
    factory(ProjectConfigValidator.Factory.class);
    factory(NotesBranchUtil.Factory.class);
    factory(MergedByPushOp.Factory.class);
    factory(GitModules.Factory.class);
    factory(VersionedAuthorizedKeys.Factory.class);
    bind(AccountManager.class);
    bind(new TypeLiteral<List<CommentLinkInfo>>() {
    }).toProvider(CommentLinkProvider.class);
    DynamicSet.bind(binder(), GerritConfigListener.class).to(CommentLinkProvider.class);
    bind(ReloadPluginListener.class).annotatedWith(UniqueAnnotations.create()).to(PluginConfigFactory.class);
}
#method_after
@Override
protected void configure() {
    bind(EmailExpander.class).toProvider(EmailExpanderProvider.class).in(SINGLETON);
    bind(IdGenerator.class);
    bind(RulesCache.class);
    bind(BlameCache.class).to(BlameCacheImpl.class);
    bind(Sequences.class);
    install(authModule);
    install(AccountCacheImpl.module());
    install(BatchUpdate.module());
    install(ChangeKindCacheImpl.module());
    install(ChangeFinder.module());
    install(ConflictsCacheImpl.module());
    install(GroupCacheImpl.module());
    install(GroupIncludeCacheImpl.module());
    install(MergeabilityCacheImpl.module());
    install(PatchListCacheImpl.module());
    install(ProjectCacheImpl.module());
    install(SectionSortCache.module());
    install(SubmitStrategy.module());
    install(TagCache.module());
    install(OAuthTokenCache.module());
    install(new AccessControlModule());
    install(new CmdLineParserModule());
    install(new EmailModule());
    install(new ExternalIdModule());
    install(new GitModule());
    install(new GroupDbModule());
    install(new GroupModule());
    install(new NoteDbModule(cfg));
    install(new PrologModule());
    install(new DefaultSubmitRule.Module());
    install(new IgnoreSelfApprovalRule.Module());
    install(new ReceiveCommitsModule());
    install(new SshAddressesModule());
    install(ThreadLocalRequestContext.module());
    bind(AccountResolver.class);
    factory(AddReviewerSender.Factory.class);
    factory(DeleteReviewerSender.Factory.class);
    factory(AddKeySender.Factory.class);
    factory(CapabilityCollection.Factory.class);
    factory(ChangeData.AssistedFactory.class);
    factory(ChangeJson.AssistedFactory.class);
    factory(CreateChangeSender.Factory.class);
    factory(MergedSender.Factory.class);
    factory(MergeUtil.Factory.class);
    factory(PatchScriptFactory.Factory.class);
    factory(ProjectState.Factory.class);
    factory(RegisterNewEmailSender.Factory.class);
    factory(ReplacePatchSetSender.Factory.class);
    factory(SetAssigneeSender.Factory.class);
    factory(InboundEmailRejectionSender.Factory.class);
    bind(PermissionCollection.Factory.class);
    bind(AccountVisibility.class).toProvider(AccountVisibilityProvider.class).in(SINGLETON);
    factory(ProjectOwnerGroupsProvider.Factory.class);
    factory(SubmitRuleEvaluator.Factory.class);
    bind(AuthBackend.class).to(UniversalAuthBackend.class).in(SINGLETON);
    DynamicSet.setOf(binder(), AuthBackend.class);
    bind(GroupControl.Factory.class).in(SINGLETON);
    bind(GroupControl.GenericFactory.class).in(SINGLETON);
    bind(FileTypeRegistry.class).to(MimeUtilFileTypeRegistry.class);
    bind(ToolsCatalog.class);
    bind(EventFactory.class);
    bind(TransferConfig.class);
    bind(GcConfig.class);
    DynamicSet.setOf(binder(), GerritConfigListener.class);
    bind(ChangeCleanupConfig.class);
    bind(AccountDeactivator.class);
    bind(ApprovalsUtil.class);
    bind(SoyTofu.class).annotatedWith(MailTemplates.class).toProvider(MailSoyTofuProvider.class);
    bind(FromAddressGenerator.class).toProvider(FromAddressGeneratorProvider.class).in(SINGLETON);
    bind(Boolean.class).annotatedWith(DisableReverseDnsLookup.class).toProvider(DisableReverseDnsLookupProvider.class).in(SINGLETON);
    bind(PatchSetInfoFactory.class);
    bind(IdentifiedUser.GenericFactory.class).in(SINGLETON);
    bind(AccountControl.Factory.class);
    bind(UiActions.class);
    bind(GitReferenceUpdated.class);
    DynamicMap.mapOf(binder(), new TypeLiteral<Cache<?, ?>>() {
    });
    DynamicSet.setOf(binder(), CacheRemovalListener.class);
    DynamicMap.mapOf(binder(), CapabilityDefinition.class);
    DynamicSet.setOf(binder(), GitReferenceUpdatedListener.class);
    DynamicSet.setOf(binder(), AssigneeChangedListener.class);
    DynamicSet.setOf(binder(), ChangeAbandonedListener.class);
    DynamicSet.setOf(binder(), CommentAddedListener.class);
    DynamicSet.setOf(binder(), HashtagsEditedListener.class);
    DynamicSet.setOf(binder(), ChangeMergedListener.class);
    bind(ChangeMergedListener.class).annotatedWith(Exports.named("CreateGroupPermissionSyncer")).to(CreateGroupPermissionSyncer.class);
    DynamicSet.setOf(binder(), ChangeRestoredListener.class);
    DynamicSet.setOf(binder(), ChangeRevertedListener.class);
    DynamicSet.setOf(binder(), PrivateStateChangedListener.class);
    DynamicSet.setOf(binder(), ReviewerAddedListener.class);
    DynamicSet.setOf(binder(), ReviewerDeletedListener.class);
    DynamicSet.setOf(binder(), VoteDeletedListener.class);
    DynamicSet.setOf(binder(), WorkInProgressStateChangedListener.class);
    DynamicSet.setOf(binder(), RevisionCreatedListener.class);
    DynamicSet.setOf(binder(), TopicEditedListener.class);
    DynamicSet.setOf(binder(), AgreementSignupListener.class);
    DynamicSet.setOf(binder(), PluginEventListener.class);
    DynamicSet.setOf(binder(), ReceivePackInitializer.class);
    DynamicSet.setOf(binder(), PostReceiveHook.class);
    DynamicSet.setOf(binder(), PreUploadHook.class);
    DynamicSet.setOf(binder(), PostUploadHook.class);
    DynamicSet.setOf(binder(), AccountIndexedListener.class);
    DynamicSet.setOf(binder(), ChangeIndexedListener.class);
    DynamicSet.setOf(binder(), GroupIndexedListener.class);
    DynamicSet.setOf(binder(), ProjectIndexedListener.class);
    DynamicSet.setOf(binder(), NewProjectCreatedListener.class);
    DynamicSet.setOf(binder(), ProjectDeletedListener.class);
    DynamicSet.setOf(binder(), GarbageCollectorListener.class);
    DynamicSet.setOf(binder(), HeadUpdatedListener.class);
    DynamicSet.setOf(binder(), UsageDataPublishedListener.class);
    DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(ReindexAfterRefUpdate.class);
    DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(ProjectConfigEntry.UpdateChecker.class);
    DynamicSet.setOf(binder(), EventListener.class);
    DynamicSet.bind(binder(), EventListener.class).to(EventsMetrics.class);
    DynamicSet.setOf(binder(), UserScopedEventListener.class);
    DynamicSet.setOf(binder(), CommitValidationListener.class);
    DynamicSet.setOf(binder(), ChangeMessageModifier.class);
    DynamicSet.setOf(binder(), RefOperationValidationListener.class);
    DynamicSet.setOf(binder(), OnSubmitValidationListener.class);
    DynamicSet.setOf(binder(), MergeValidationListener.class);
    DynamicSet.setOf(binder(), ProjectCreationValidationListener.class);
    DynamicSet.setOf(binder(), GroupCreationValidationListener.class);
    DynamicSet.setOf(binder(), HashtagValidationListener.class);
    DynamicSet.setOf(binder(), OutgoingEmailValidationListener.class);
    DynamicSet.setOf(binder(), AccountActivationValidationListener.class);
    DynamicItem.itemOf(binder(), AvatarProvider.class);
    DynamicSet.setOf(binder(), LifecycleListener.class);
    DynamicSet.setOf(binder(), TopMenu.class);
    DynamicSet.setOf(binder(), MessageOfTheDay.class);
    DynamicMap.mapOf(binder(), DownloadScheme.class);
    DynamicMap.mapOf(binder(), DownloadCommand.class);
    DynamicMap.mapOf(binder(), CloneCommand.class);
    DynamicMap.mapOf(binder(), ReviewerSuggestion.class);
    DynamicSet.bind(binder(), GerritConfigListener.class).toInstance(SuggestReviewers.configListener());
    DynamicSet.setOf(binder(), ExternalIncludedIn.class);
    DynamicMap.mapOf(binder(), ProjectConfigEntry.class);
    DynamicSet.setOf(binder(), PatchSetWebLink.class);
    DynamicSet.setOf(binder(), ParentWebLink.class);
    DynamicSet.setOf(binder(), FileWebLink.class);
    DynamicSet.setOf(binder(), FileHistoryWebLink.class);
    DynamicSet.setOf(binder(), DiffWebLink.class);
    DynamicSet.setOf(binder(), ProjectWebLink.class);
    DynamicSet.setOf(binder(), BranchWebLink.class);
    DynamicSet.setOf(binder(), TagWebLink.class);
    DynamicMap.mapOf(binder(), OAuthLoginProvider.class);
    DynamicItem.itemOf(binder(), OAuthTokenEncrypter.class);
    DynamicSet.setOf(binder(), AccountExternalIdCreator.class);
    DynamicSet.setOf(binder(), WebUiPlugin.class);
    DynamicItem.itemOf(binder(), AccountPatchReviewStore.class);
    DynamicSet.setOf(binder(), AssigneeValidationListener.class);
    DynamicSet.setOf(binder(), ActionVisitor.class);
    DynamicItem.itemOf(binder(), MergeSuperSetComputation.class);
    DynamicItem.itemOf(binder(), ProjectNameLockManager.class);
    DynamicSet.setOf(binder(), SubmitRule.class);
    DynamicMap.mapOf(binder(), MailFilter.class);
    bind(MailFilter.class).annotatedWith(Exports.named("ListMailFilter")).to(ListMailFilter.class);
    bind(AutoReplyMailFilter.class).annotatedWith(Exports.named("AutoReplyMailFilter")).to(AutoReplyMailFilter.class);
    factory(UploadValidators.Factory.class);
    DynamicSet.setOf(binder(), UploadValidationListener.class);
    DynamicMap.mapOf(binder(), ChangeQueryBuilder.ChangeOperatorFactory.class);
    DynamicMap.mapOf(binder(), ChangeQueryBuilder.ChangeHasOperandFactory.class);
    DynamicMap.mapOf(binder(), ChangeQueryProcessor.ChangeAttributeFactory.class);
    install(new GitwebConfig.LegacyModule(cfg));
    bind(AnonymousUser.class);
    factory(AbandonOp.Factory.class);
    factory(AccountMergeValidator.Factory.class);
    factory(GroupMergeValidator.Factory.class);
    factory(RefOperationValidators.Factory.class);
    factory(OnSubmitValidators.Factory.class);
    factory(MergeValidators.Factory.class);
    factory(ProjectConfigValidator.Factory.class);
    factory(NotesBranchUtil.Factory.class);
    factory(MergedByPushOp.Factory.class);
    factory(GitModules.Factory.class);
    factory(VersionedAuthorizedKeys.Factory.class);
    bind(AccountManager.class);
    bind(new TypeLiteral<List<CommentLinkInfo>>() {
    }).toProvider(CommentLinkProvider.class);
    DynamicSet.bind(binder(), GerritConfigListener.class).to(CommentLinkProvider.class);
    bind(ReloadPluginListener.class).annotatedWith(UniqueAnnotations.create()).to(PluginConfigFactory.class);
}
#end_block

#method_before
private void loadLabelSections(Config rc) {
    Map<String, String> lowerNames = Maps.newHashMapWithExpectedSize(2);
    labelSections = new LinkedHashMap<>();
    for (String name : rc.getSubsections(LABEL)) {
        String lower = name.toLowerCase();
        if (lowerNames.containsKey(lower)) {
            error(new ValidationError(PROJECT_CONFIG, String.format("Label \"%s\" conflicts with \"%s\"", name, lowerNames.get(lower))));
        }
        lowerNames.put(lower, name);
        List<LabelValue> values = new ArrayList<>();
        for (String value : rc.getStringList(LABEL, name, KEY_VALUE)) {
            try {
                values.add(parseLabelValue(value));
            } catch (IllegalArgumentException notValue) {
                error(new ValidationError(PROJECT_CONFIG, String.format("Invalid %s \"%s\" for label \"%s\": %s", KEY_VALUE, value, name, notValue.getMessage())));
            }
        }
        LabelType label;
        try {
            label = new LabelType(name, values);
        } catch (IllegalArgumentException badName) {
            error(new ValidationError(PROJECT_CONFIG, String.format("Invalid label \"%s\"", name)));
            continue;
        }
        String functionName = rc.getString(LABEL, name, KEY_FUNCTION);
        Optional<LabelFunction> function = functionName != null ? LabelFunction.parse(functionName) : Optional.of(LabelFunction.MAX_WITH_BLOCK);
        if (!function.isPresent()) {
            error(new ValidationError(PROJECT_CONFIG, String.format("Invalid %s for label \"%s\". Valid names are: %s", KEY_FUNCTION, name, Joiner.on(", ").join(LabelFunction.ALL.keySet()))));
        }
        label.setFunction(function.orElse(null));
        if (!values.isEmpty()) {
            short dv = (short) rc.getInt(LABEL, name, KEY_DEFAULT_VALUE, 0);
            if (isInRange(dv, values)) {
                label.setDefaultValue(dv);
            } else {
                error(new ValidationError(PROJECT_CONFIG, String.format("Invalid %s \"%s\" for label \"%s\"", KEY_DEFAULT_VALUE, dv, name)));
            }
        }
        label.setAllowPostSubmit(rc.getBoolean(LABEL, name, KEY_ALLOW_POST_SUBMIT, LabelType.DEF_ALLOW_POST_SUBMIT));
        label.setIgnoreAuthorSelfApproval(rc.getBoolean(LABEL, name, KEY_IGNORE_AUTHOR_SELF_APPROVAL, LabelType.DEF_IGNORE_AUTHOR_SELF_APPROVAL));
        label.setCopyMinScore(rc.getBoolean(LABEL, name, KEY_COPY_MIN_SCORE, LabelType.DEF_COPY_MIN_SCORE));
        label.setCopyMaxScore(rc.getBoolean(LABEL, name, KEY_COPY_MAX_SCORE, LabelType.DEF_COPY_MAX_SCORE));
        label.setCopyAllScoresOnMergeFirstParentUpdate(rc.getBoolean(LABEL, name, KEY_COPY_ALL_SCORES_ON_MERGE_FIRST_PARENT_UPDATE, LabelType.DEF_COPY_ALL_SCORES_ON_MERGE_FIRST_PARENT_UPDATE));
        label.setCopyAllScoresOnTrivialRebase(rc.getBoolean(LABEL, name, KEY_COPY_ALL_SCORES_ON_TRIVIAL_REBASE, LabelType.DEF_COPY_ALL_SCORES_ON_TRIVIAL_REBASE));
        label.setCopyAllScoresIfNoCodeChange(rc.getBoolean(LABEL, name, KEY_COPY_ALL_SCORES_IF_NO_CODE_CHANGE, LabelType.DEF_COPY_ALL_SCORES_IF_NO_CODE_CHANGE));
        label.setCopyAllScoresIfNoChange(rc.getBoolean(LABEL, name, KEY_COPY_ALL_SCORES_IF_NO_CHANGE, LabelType.DEF_COPY_ALL_SCORES_IF_NO_CHANGE));
        label.setCanOverride(rc.getBoolean(LABEL, name, KEY_CAN_OVERRIDE, LabelType.DEF_CAN_OVERRIDE));
        label.setRefPatterns(getStringListOrNull(rc, LABEL, name, KEY_BRANCH));
        labelSections.put(name, label);
    }
}
#method_after
private void loadLabelSections(Config rc) {
    Map<String, String> lowerNames = Maps.newHashMapWithExpectedSize(2);
    labelSections = new LinkedHashMap<>();
    for (String name : rc.getSubsections(LABEL)) {
        String lower = name.toLowerCase();
        if (lowerNames.containsKey(lower)) {
            error(new ValidationError(PROJECT_CONFIG, String.format("Label \"%s\" conflicts with \"%s\"", name, lowerNames.get(lower))));
        }
        lowerNames.put(lower, name);
        List<LabelValue> values = new ArrayList<>();
        for (String value : rc.getStringList(LABEL, name, KEY_VALUE)) {
            try {
                values.add(parseLabelValue(value));
            } catch (IllegalArgumentException notValue) {
                error(new ValidationError(PROJECT_CONFIG, String.format("Invalid %s \"%s\" for label \"%s\": %s", KEY_VALUE, value, name, notValue.getMessage())));
            }
        }
        LabelType label;
        try {
            label = new LabelType(name, values);
        } catch (IllegalArgumentException badName) {
            error(new ValidationError(PROJECT_CONFIG, String.format("Invalid label \"%s\"", name)));
            continue;
        }
        String functionName = rc.getString(LABEL, name, KEY_FUNCTION);
        Optional<LabelFunction> function = functionName != null ? LabelFunction.parse(functionName) : Optional.of(LabelFunction.MAX_WITH_BLOCK);
        if (!function.isPresent()) {
            error(new ValidationError(PROJECT_CONFIG, String.format("Invalid %s for label \"%s\". Valid names are: %s", KEY_FUNCTION, name, Joiner.on(", ").join(LabelFunction.ALL.keySet()))));
        }
        label.setFunction(function.orElse(null));
        if (!values.isEmpty()) {
            short dv = (short) rc.getInt(LABEL, name, KEY_DEFAULT_VALUE, 0);
            if (isInRange(dv, values)) {
                label.setDefaultValue(dv);
            } else {
                error(new ValidationError(PROJECT_CONFIG, String.format("Invalid %s \"%s\" for label \"%s\"", KEY_DEFAULT_VALUE, dv, name)));
            }
        }
        label.setAllowPostSubmit(rc.getBoolean(LABEL, name, KEY_ALLOW_POST_SUBMIT, LabelType.DEF_ALLOW_POST_SUBMIT));
        label.setIgnoreSelfApproval(rc.getBoolean(LABEL, name, KEY_IGNORE_SELF_APPROVAL, LabelType.DEF_IGNORE_SELF_APPROVAL));
        label.setCopyMinScore(rc.getBoolean(LABEL, name, KEY_COPY_MIN_SCORE, LabelType.DEF_COPY_MIN_SCORE));
        label.setCopyMaxScore(rc.getBoolean(LABEL, name, KEY_COPY_MAX_SCORE, LabelType.DEF_COPY_MAX_SCORE));
        label.setCopyAllScoresOnMergeFirstParentUpdate(rc.getBoolean(LABEL, name, KEY_COPY_ALL_SCORES_ON_MERGE_FIRST_PARENT_UPDATE, LabelType.DEF_COPY_ALL_SCORES_ON_MERGE_FIRST_PARENT_UPDATE));
        label.setCopyAllScoresOnTrivialRebase(rc.getBoolean(LABEL, name, KEY_COPY_ALL_SCORES_ON_TRIVIAL_REBASE, LabelType.DEF_COPY_ALL_SCORES_ON_TRIVIAL_REBASE));
        label.setCopyAllScoresIfNoCodeChange(rc.getBoolean(LABEL, name, KEY_COPY_ALL_SCORES_IF_NO_CODE_CHANGE, LabelType.DEF_COPY_ALL_SCORES_IF_NO_CODE_CHANGE));
        label.setCopyAllScoresIfNoChange(rc.getBoolean(LABEL, name, KEY_COPY_ALL_SCORES_IF_NO_CHANGE, LabelType.DEF_COPY_ALL_SCORES_IF_NO_CHANGE));
        label.setCanOverride(rc.getBoolean(LABEL, name, KEY_CAN_OVERRIDE, LabelType.DEF_CAN_OVERRIDE));
        label.setRefPatterns(getStringListOrNull(rc, LABEL, name, KEY_BRANCH));
        labelSections.put(name, label);
    }
}
#end_block

#method_before
private void saveNotifySections(Config rc, Set<AccountGroup.UUID> keepGroups) {
    for (NotifyConfig nc : sort(notifySections.values())) {
        List<String> email = new ArrayList<>();
        for (GroupReference gr : nc.getGroups()) {
            if (gr.getUUID() != null) {
                keepGroups.add(gr.getUUID());
            }
            email.add(new PermissionRule(gr).asString(false));
        }
        Collections.sort(email);
        List<String> addrs = new ArrayList<>();
        for (Address addr : nc.getAddresses()) {
            addrs.add(addr.toString());
        }
        Collections.sort(addrs);
        email.addAll(addrs);
        set(rc, NOTIFY, nc.getName(), KEY_HEADER, nc.getHeader(), NotifyConfig.Header.BCC);
        if (email.isEmpty()) {
            rc.unset(NOTIFY, nc.getName(), KEY_EMAIL);
        } else {
            rc.setStringList(NOTIFY, nc.getName(), KEY_EMAIL, email);
        }
        if (nc.getNotify().equals(EnumSet.of(NotifyType.ALL))) {
            rc.unset(NOTIFY, nc.getName(), KEY_TYPE);
        } else {
            List<String> types = new ArrayList<>(4);
            for (NotifyType t : NotifyType.values()) {
                if (nc.isNotify(t)) {
                    types.add(t.name().toLowerCase(Locale.US));
                }
            }
            rc.setStringList(NOTIFY, nc.getName(), KEY_TYPE, types);
        }
        set(rc, NOTIFY, nc.getName(), KEY_FILTER, nc.getFilter());
    }
}
#method_after
private void saveNotifySections(Config rc, Set<AccountGroup.UUID> keepGroups) {
    for (NotifyConfig nc : sort(notifySections.values())) {
        nc.getGroups().stream().map(gr -> gr.getUUID()).filter(Objects::nonNull).forEach(keepGroups::add);
        List<String> email = nc.getGroups().stream().map(gr -> new PermissionRule(gr).asString(false)).sorted().collect(toList());
        // Separate stream operation so that emails list contains 2 sorted sub-lists.
        nc.getAddresses().stream().map(Address::toString).sorted().forEach(email::add);
        set(rc, NOTIFY, nc.getName(), KEY_HEADER, nc.getHeader(), NotifyConfig.Header.BCC);
        if (email.isEmpty()) {
            rc.unset(NOTIFY, nc.getName(), KEY_EMAIL);
        } else {
            rc.setStringList(NOTIFY, nc.getName(), KEY_EMAIL, email);
        }
        if (nc.getNotify().equals(EnumSet.of(NotifyType.ALL))) {
            rc.unset(NOTIFY, nc.getName(), KEY_TYPE);
        } else {
            List<String> types = new ArrayList<>(4);
            for (NotifyType t : NotifyType.values()) {
                if (nc.isNotify(t)) {
                    types.add(t.name().toLowerCase(Locale.US));
                }
            }
            rc.setStringList(NOTIFY, nc.getName(), KEY_TYPE, types);
        }
        set(rc, NOTIFY, nc.getName(), KEY_FILTER, nc.getFilter());
    }
}
#end_block

#method_before
private void saveLabelSections(Config rc) {
    List<String> existing = new ArrayList<>(rc.getSubsections(LABEL));
    if (!new ArrayList<>(labelSections.keySet()).equals(existing)) {
        // Order of sections changed, remove and rewrite them all.
        for (String name : existing) {
            rc.unsetSection(LABEL, name);
        }
    }
    Set<String> toUnset = new HashSet<>(existing);
    for (Map.Entry<String, LabelType> e : labelSections.entrySet()) {
        String name = e.getKey();
        LabelType label = e.getValue();
        toUnset.remove(name);
        rc.setString(LABEL, name, KEY_FUNCTION, label.getFunction().getFunctionName());
        rc.setInt(LABEL, name, KEY_DEFAULT_VALUE, label.getDefaultValue());
        setBooleanConfigKey(rc, LABEL, name, KEY_ALLOW_POST_SUBMIT, label.allowPostSubmit(), LabelType.DEF_ALLOW_POST_SUBMIT);
        setBooleanConfigKey(rc, LABEL, name, KEY_IGNORE_AUTHOR_SELF_APPROVAL, label.ignoreAuthorSelfApproval(), LabelType.DEF_IGNORE_AUTHOR_SELF_APPROVAL);
        setBooleanConfigKey(rc, LABEL, name, KEY_COPY_MIN_SCORE, label.isCopyMinScore(), LabelType.DEF_COPY_MIN_SCORE);
        setBooleanConfigKey(rc, LABEL, name, KEY_COPY_MAX_SCORE, label.isCopyMaxScore(), LabelType.DEF_COPY_MAX_SCORE);
        setBooleanConfigKey(rc, LABEL, name, KEY_COPY_ALL_SCORES_ON_TRIVIAL_REBASE, label.isCopyAllScoresOnTrivialRebase(), LabelType.DEF_COPY_ALL_SCORES_ON_TRIVIAL_REBASE);
        setBooleanConfigKey(rc, LABEL, name, KEY_COPY_ALL_SCORES_IF_NO_CODE_CHANGE, label.isCopyAllScoresIfNoCodeChange(), LabelType.DEF_COPY_ALL_SCORES_IF_NO_CODE_CHANGE);
        setBooleanConfigKey(rc, LABEL, name, KEY_COPY_ALL_SCORES_IF_NO_CHANGE, label.isCopyAllScoresIfNoChange(), LabelType.DEF_COPY_ALL_SCORES_IF_NO_CHANGE);
        setBooleanConfigKey(rc, LABEL, name, KEY_COPY_ALL_SCORES_ON_MERGE_FIRST_PARENT_UPDATE, label.isCopyAllScoresOnMergeFirstParentUpdate(), LabelType.DEF_COPY_ALL_SCORES_ON_MERGE_FIRST_PARENT_UPDATE);
        setBooleanConfigKey(rc, LABEL, name, KEY_CAN_OVERRIDE, label.canOverride(), LabelType.DEF_CAN_OVERRIDE);
        List<String> values = new ArrayList<>(label.getValues().size());
        for (LabelValue value : label.getValues()) {
            values.add(value.format().trim());
        }
        rc.setStringList(LABEL, name, KEY_VALUE, values);
        List<String> refPatterns = label.getRefPatterns();
        if (refPatterns != null && !refPatterns.isEmpty()) {
            rc.setStringList(LABEL, name, KEY_BRANCH, refPatterns);
        }
    }
    for (String name : toUnset) {
        rc.unsetSection(LABEL, name);
    }
}
#method_after
private void saveLabelSections(Config rc) {
    List<String> existing = new ArrayList<>(rc.getSubsections(LABEL));
    if (!new ArrayList<>(labelSections.keySet()).equals(existing)) {
        // Order of sections changed, remove and rewrite them all.
        for (String name : existing) {
            rc.unsetSection(LABEL, name);
        }
    }
    Set<String> toUnset = new HashSet<>(existing);
    for (Map.Entry<String, LabelType> e : labelSections.entrySet()) {
        String name = e.getKey();
        LabelType label = e.getValue();
        toUnset.remove(name);
        rc.setString(LABEL, name, KEY_FUNCTION, label.getFunction().getFunctionName());
        rc.setInt(LABEL, name, KEY_DEFAULT_VALUE, label.getDefaultValue());
        setBooleanConfigKey(rc, LABEL, name, KEY_ALLOW_POST_SUBMIT, label.allowPostSubmit(), LabelType.DEF_ALLOW_POST_SUBMIT);
        setBooleanConfigKey(rc, LABEL, name, KEY_IGNORE_SELF_APPROVAL, label.ignoreSelfApproval(), LabelType.DEF_IGNORE_SELF_APPROVAL);
        setBooleanConfigKey(rc, LABEL, name, KEY_COPY_MIN_SCORE, label.isCopyMinScore(), LabelType.DEF_COPY_MIN_SCORE);
        setBooleanConfigKey(rc, LABEL, name, KEY_COPY_MAX_SCORE, label.isCopyMaxScore(), LabelType.DEF_COPY_MAX_SCORE);
        setBooleanConfigKey(rc, LABEL, name, KEY_COPY_ALL_SCORES_ON_TRIVIAL_REBASE, label.isCopyAllScoresOnTrivialRebase(), LabelType.DEF_COPY_ALL_SCORES_ON_TRIVIAL_REBASE);
        setBooleanConfigKey(rc, LABEL, name, KEY_COPY_ALL_SCORES_IF_NO_CODE_CHANGE, label.isCopyAllScoresIfNoCodeChange(), LabelType.DEF_COPY_ALL_SCORES_IF_NO_CODE_CHANGE);
        setBooleanConfigKey(rc, LABEL, name, KEY_COPY_ALL_SCORES_IF_NO_CHANGE, label.isCopyAllScoresIfNoChange(), LabelType.DEF_COPY_ALL_SCORES_IF_NO_CHANGE);
        setBooleanConfigKey(rc, LABEL, name, KEY_COPY_ALL_SCORES_ON_MERGE_FIRST_PARENT_UPDATE, label.isCopyAllScoresOnMergeFirstParentUpdate(), LabelType.DEF_COPY_ALL_SCORES_ON_MERGE_FIRST_PARENT_UPDATE);
        setBooleanConfigKey(rc, LABEL, name, KEY_CAN_OVERRIDE, label.canOverride(), LabelType.DEF_CAN_OVERRIDE);
        List<String> values = new ArrayList<>(label.getValues().size());
        for (LabelValue value : label.getValues()) {
            values.add(value.format().trim());
        }
        rc.setStringList(LABEL, name, KEY_VALUE, values);
        List<String> refPatterns = label.getRefPatterns();
        if (refPatterns != null && !refPatterns.isEmpty()) {
            rc.setStringList(LABEL, name, KEY_BRANCH, refPatterns);
        }
    }
    for (String name : toUnset) {
        rc.unsetSection(LABEL, name);
    }
}
#end_block

#method_before
@SuppressWarnings("rawtypes")
@Override
protected void configure() {
    install(reviewDbModule);
    install(new DiffExecutorModule());
    install(new SysExecutorModule());
    install(BatchUpdate.module());
    install(PatchListCacheImpl.module());
    // There is the concept of LifecycleModule, in Gerrit's own extension to Guice, which has these:
    // listener().to(SomeClassImplementingLifecycleListener.class);
    // and the start() methods of each such listener are executed in the order they are declared.
    // Makes sure that PluginLoader.start() is executed before the LuceneIndexModule.start() so that
    // plugins get loaded and the respective Guice modules installed so that the on-line reindexing
    // will happen with the proper classes (e.g. group backends, custom Prolog predicates) and the
    // associated rules ready to be evaluated.
    install(new PluginModule());
    // We're just running through each change
    // once, so don't worry about cache removal.
    bind(new TypeLiteral<DynamicSet<CacheRemovalListener>>() {
    }).toInstance(DynamicSet.<CacheRemovalListener>emptySet());
    bind(new TypeLiteral<DynamicMap<Cache<?, ?>>>() {
    }).toInstance(DynamicMap.<Cache<?, ?>>emptyMap());
    bind(new TypeLiteral<List<CommentLinkInfo>>() {
    }).toProvider(CommentLinkProvider.class).in(SINGLETON);
    bind(new TypeLiteral<DynamicMap<ChangeQueryProcessor.ChangeAttributeFactory>>() {
    }).toInstance(DynamicMap.<ChangeQueryProcessor.ChangeAttributeFactory>emptyMap());
    bind(new TypeLiteral<DynamicMap<RestView<CommitResource>>>() {
    }).toInstance(DynamicMap.<RestView<CommitResource>>emptyMap());
    bind(String.class).annotatedWith(CanonicalWebUrl.class).toProvider(CanonicalWebUrlProvider.class);
    bind(Boolean.class).annotatedWith(DisableReverseDnsLookup.class).toProvider(DisableReverseDnsLookupProvider.class).in(SINGLETON);
    bind(Realm.class).to(FakeRealm.class);
    bind(IdentifiedUser.class).toProvider(Providers.<IdentifiedUser>of(null));
    bind(ReplacePatchSetSender.Factory.class).toProvider(Providers.<ReplacePatchSetSender.Factory>of(null));
    bind(CurrentUser.class).to(IdentifiedUser.class);
    factory(MergeUtil.Factory.class);
    factory(PatchSetInserter.Factory.class);
    factory(RebaseChangeOp.Factory.class);
    // As Reindex is a batch program, don't assume the index is available for
    // the change cache.
    bind(SearchingChangeCacheImpl.class).toProvider(Providers.<SearchingChangeCacheImpl>of(null));
    bind(new TypeLiteral<ImmutableSet<GroupReference>>() {
    }).annotatedWith(AdministrateServerGroups.class).toInstance(ImmutableSet.<GroupReference>of());
    bind(new TypeLiteral<Set<AccountGroup.UUID>>() {
    }).annotatedWith(GitUploadPackGroups.class).toInstance(Collections.<AccountGroup.UUID>emptySet());
    bind(new TypeLiteral<Set<AccountGroup.UUID>>() {
    }).annotatedWith(GitReceivePackGroups.class).toInstance(Collections.<AccountGroup.UUID>emptySet());
    install(new BatchGitModule());
    install(new DefaultPermissionBackendModule());
    install(new DefaultMemoryCacheModule());
    install(new H2CacheModule());
    install(new ExternalIdModule());
    install(new GroupModule());
    install(new NoteDbModule(cfg));
    install(AccountCacheImpl.module());
    install(GroupCacheImpl.module());
    install(GroupIncludeCacheImpl.module());
    install(ProjectCacheImpl.module());
    install(SectionSortCache.module());
    install(ChangeKindCacheImpl.module());
    install(MergeabilityCacheImpl.module());
    install(TagCache.module());
    factory(CapabilityCollection.Factory.class);
    factory(ChangeData.AssistedFactory.class);
    factory(ProjectState.Factory.class);
    // Submit rules
    DynamicSet.setOf(binder(), SubmitRule.class);
    factory(SubmitRuleEvaluator.Factory.class);
    install(new PrologModule());
    install(new DefaultSubmitRule.Module());
    install(new RequireNonAuthorApprovalRule.Module());
    bind(ChangeJson.Factory.class).toProvider(Providers.<ChangeJson.Factory>of(null));
    bind(EventUtil.class).toProvider(Providers.<EventUtil>of(null));
    bind(GitReferenceUpdated.class).toInstance(GitReferenceUpdated.DISABLED);
    bind(RevisionCreated.class).toInstance(RevisionCreated.DISABLED);
    bind(AccountVisibility.class).toProvider(AccountVisibilityProvider.class).in(SINGLETON);
}
#method_after
@SuppressWarnings("rawtypes")
@Override
protected void configure() {
    install(reviewDbModule);
    install(new DiffExecutorModule());
    install(new SysExecutorModule());
    install(BatchUpdate.module());
    install(PatchListCacheImpl.module());
    // There is the concept of LifecycleModule, in Gerrit's own extension to Guice, which has these:
    // listener().to(SomeClassImplementingLifecycleListener.class);
    // and the start() methods of each such listener are executed in the order they are declared.
    // Makes sure that PluginLoader.start() is executed before the LuceneIndexModule.start() so that
    // plugins get loaded and the respective Guice modules installed so that the on-line reindexing
    // will happen with the proper classes (e.g. group backends, custom Prolog predicates) and the
    // associated rules ready to be evaluated.
    install(new PluginModule());
    // We're just running through each change
    // once, so don't worry about cache removal.
    bind(new TypeLiteral<DynamicSet<CacheRemovalListener>>() {
    }).toInstance(DynamicSet.<CacheRemovalListener>emptySet());
    bind(new TypeLiteral<DynamicMap<Cache<?, ?>>>() {
    }).toInstance(DynamicMap.<Cache<?, ?>>emptyMap());
    bind(new TypeLiteral<List<CommentLinkInfo>>() {
    }).toProvider(CommentLinkProvider.class).in(SINGLETON);
    bind(new TypeLiteral<DynamicMap<ChangeQueryProcessor.ChangeAttributeFactory>>() {
    }).toInstance(DynamicMap.<ChangeQueryProcessor.ChangeAttributeFactory>emptyMap());
    bind(new TypeLiteral<DynamicMap<RestView<CommitResource>>>() {
    }).toInstance(DynamicMap.<RestView<CommitResource>>emptyMap());
    bind(String.class).annotatedWith(CanonicalWebUrl.class).toProvider(CanonicalWebUrlProvider.class);
    bind(Boolean.class).annotatedWith(DisableReverseDnsLookup.class).toProvider(DisableReverseDnsLookupProvider.class).in(SINGLETON);
    bind(Realm.class).to(FakeRealm.class);
    bind(IdentifiedUser.class).toProvider(Providers.<IdentifiedUser>of(null));
    bind(ReplacePatchSetSender.Factory.class).toProvider(Providers.<ReplacePatchSetSender.Factory>of(null));
    bind(CurrentUser.class).to(IdentifiedUser.class);
    factory(MergeUtil.Factory.class);
    factory(PatchSetInserter.Factory.class);
    factory(RebaseChangeOp.Factory.class);
    // As Reindex is a batch program, don't assume the index is available for
    // the change cache.
    bind(SearchingChangeCacheImpl.class).toProvider(Providers.<SearchingChangeCacheImpl>of(null));
    bind(new TypeLiteral<ImmutableSet<GroupReference>>() {
    }).annotatedWith(AdministrateServerGroups.class).toInstance(ImmutableSet.<GroupReference>of());
    bind(new TypeLiteral<Set<AccountGroup.UUID>>() {
    }).annotatedWith(GitUploadPackGroups.class).toInstance(Collections.<AccountGroup.UUID>emptySet());
    bind(new TypeLiteral<Set<AccountGroup.UUID>>() {
    }).annotatedWith(GitReceivePackGroups.class).toInstance(Collections.<AccountGroup.UUID>emptySet());
    install(new BatchGitModule());
    install(new DefaultPermissionBackendModule());
    install(new DefaultMemoryCacheModule());
    install(new H2CacheModule());
    install(new ExternalIdModule());
    install(new GroupModule());
    install(new NoteDbModule(cfg));
    install(AccountCacheImpl.module());
    install(GroupCacheImpl.module());
    install(GroupIncludeCacheImpl.module());
    install(ProjectCacheImpl.module());
    install(SectionSortCache.module());
    install(ChangeKindCacheImpl.module());
    install(MergeabilityCacheImpl.module());
    install(TagCache.module());
    factory(CapabilityCollection.Factory.class);
    factory(ChangeData.AssistedFactory.class);
    factory(ProjectState.Factory.class);
    // Submit rules
    DynamicSet.setOf(binder(), SubmitRule.class);
    factory(SubmitRuleEvaluator.Factory.class);
    install(new PrologModule());
    install(new DefaultSubmitRule.Module());
    install(new IgnoreSelfApprovalRule.Module());
    bind(ChangeJson.Factory.class).toProvider(Providers.<ChangeJson.Factory>of(null));
    bind(EventUtil.class).toProvider(Providers.<EventUtil>of(null));
    bind(GitReferenceUpdated.class).toInstance(GitReferenceUpdated.DISABLED);
    bind(RevisionCreated.class).toInstance(RevisionCreated.DISABLED);
    bind(AccountVisibility.class).toProvider(AccountVisibilityProvider.class).in(SINGLETON);
}
#end_block

#method_before
@Override
public Token getAccessToken(Token requestToken, Verifier verifier) {
    OAuthRequest request = new OAuthRequest(api.getAccessTokenVerb(), api.getAccessTokenEndpoint());
    request.addBodyParameter(OAuthConstants.CLIENT_ID, config.getApiKey());
    request.addBodyParameter(OAuthConstants.CLIENT_SECRET, config.getApiSecret());
    request.addBodyParameter(OAuthConstants.CODE, verifier.getValue());
    request.addBodyParameter(OAuthConstants.REDIRECT_URI, config.getCallback());
    if (config.hasScope()) {
        request.addBodyParameter(OAuthConstants.SCOPE, config.getScope());
    }
    request.addBodyParameter(GRANT_TYPE, GRANT_TYPE_VALUE);
    if (log.isDebugEnabled()) {
        log.error("Access token request: {}", request);
    }
    Response response = request.send();
    if (log.isDebugEnabled()) {
        log.error("Access token response: {}", response.getBody());
    }
    return api.getAccessTokenExtractor().extract(response.getBody());
}
#method_after
@Override
public Token getAccessToken(Token requestToken, Verifier verifier) {
    OAuthRequest request = new OAuthRequest(api.getAccessTokenVerb(), api.getAccessTokenEndpoint());
    request.addBodyParameter(OAuthConstants.CLIENT_ID, config.getApiKey());
    request.addBodyParameter(OAuthConstants.CLIENT_SECRET, config.getApiSecret());
    request.addBodyParameter(OAuthConstants.CODE, verifier.getValue());
    request.addBodyParameter(OAuthConstants.REDIRECT_URI, config.getCallback());
    if (config.hasScope()) {
        request.addBodyParameter(OAuthConstants.SCOPE, config.getScope());
    }
    request.addBodyParameter(GRANT_TYPE, GRANT_TYPE_VALUE);
    if (log.isDebugEnabled()) {
        log.debug("Access token request: {}", request);
    }
    Response response = request.send();
    if (log.isDebugEnabled()) {
        log.debug("Access token response: {}", response.getBody());
    }
    return api.getAccessTokenExtractor().extract(response.getBody());
}
#end_block

#method_before
@Override
public OAuthUserInfo getUserInfo(OAuthToken token) throws IOException {
    OAuthRequest request = new OAuthRequest(Verb.GET, PROTECTED_RESOURCE_URL);
    Token t = new Token(token.getToken(), token.getSecret(), token.getRaw());
    service.signRequest(t, request);
    Response response = request.send();
    if (response.getCode() != SC_OK) {
        throw new IOException(String.format("Status %s (%s) for request %s", response.getCode(), response.getBody(), request.getUrl()));
    }
    JsonElement userJson = JSON.newGson().fromJson(response.getBody(), JsonElement.class);
    if (log.isDebugEnabled()) {
        log.debug("User info response: {}", response.getBody());
    }
    if (userJson.isJsonObject()) {
        JsonObject jsonObject = userJson.getAsJsonObject();
        JsonElement id = jsonObject.get("uid");
        if (id == null || id.isJsonNull()) {
            throw new IOException(String.format("Response doesn't contain id field"));
        }
        JsonElement email = jsonObject.get("email");
        JsonElement name = jsonObject.get("name");
        return new OAuthUserInfo(AV_PROVIDER_PREFIX + id.getAsString(), null, email.getAsString(), name.getAsString(), id.getAsString());
    }
    throw new IOException(String.format("Invalid JSON '%s': not a JSON Object", userJson));
}
#method_after
@Override
public OAuthUserInfo getUserInfo(OAuthToken token) throws IOException {
    OAuthRequest request = new OAuthRequest(Verb.GET, PROTECTED_RESOURCE_URL);
    Token t = new Token(token.getToken(), token.getSecret(), token.getRaw());
    service.signRequest(t, request);
    Response response = request.send();
    if (response.getCode() != SC_OK) {
        throw new IOException(String.format("Status %s (%s) for request %s", response.getCode(), response.getBody(), request.getUrl()));
    }
    JsonElement userJson = JSON.newGson().fromJson(response.getBody(), JsonElement.class);
    if (log.isDebugEnabled()) {
        log.debug("User info response: {}", response.getBody());
    }
    if (userJson.isJsonObject()) {
        JsonObject jsonObject = userJson.getAsJsonObject();
        JsonElement id = jsonObject.get("uid");
        if (id == null || id.isJsonNull()) {
            throw new IOException("Response doesn't contain uid field");
        }
        JsonElement email = jsonObject.get("email");
        JsonElement name = jsonObject.get("name");
        return new OAuthUserInfo(AV_PROVIDER_PREFIX + id.getAsString(), null, email.getAsString(), name.getAsString(), id.getAsString());
    }
    throw new IOException(String.format("Invalid JSON '%s': not a JSON Object", userJson));
}
#end_block

#method_before
public static boolean isValidUsername(String username) {
    return USER_NAME_PATTERN_COMPILED.matcher(username).matches();
}
#method_after
public static boolean isValidUsername(String username) {
    return USER_NAME_PATTERN.matcher(username).matches();
}
#end_block

#method_before
@Test
public void supportedVersion() throws Exception {
    assertThat(ElasticVersion.forVersion("2.4.0")).isEqualTo(ElasticVersion.V2_4);
    assertThat(ElasticVersion.forVersion("2.4.6")).isEqualTo(ElasticVersion.V2_4);
    assertThat(ElasticVersion.forVersion("5.6.0")).isEqualTo(ElasticVersion.V5_6);
    assertThat(ElasticVersion.forVersion("5.6.9")).isEqualTo(ElasticVersion.V5_6);
    assertThat(ElasticVersion.forVersion("5.6.10")).isEqualTo(ElasticVersion.V5_6);
    assertThat(ElasticVersion.forVersion("6.2.0")).isEqualTo(ElasticVersion.V6_2);
    assertThat(ElasticVersion.forVersion("6.2.4")).isEqualTo(ElasticVersion.V6_2);
    assertThat(ElasticVersion.forVersion("6.3.0")).isEqualTo(ElasticVersion.V6_3);
    assertThat(ElasticVersion.forVersion("6.3.1")).isEqualTo(ElasticVersion.V6_3);
    assertThat(ElasticVersion.forVersion("6.4.0")).isEqualTo(ElasticVersion.V6_4);
    assertThat(ElasticVersion.forVersion("6.4.1")).isEqualTo(ElasticVersion.V6_4);
}
#method_after
@Test
public void supportedVersion() throws Exception {
    assertThat(ElasticVersion.forVersion("2.4.0")).isEqualTo(ElasticVersion.V2_4);
    assertThat(ElasticVersion.forVersion("2.4.6")).isEqualTo(ElasticVersion.V2_4);
    assertThat(ElasticVersion.forVersion("5.6.0")).isEqualTo(ElasticVersion.V5_6);
    assertThat(ElasticVersion.forVersion("5.6.11")).isEqualTo(ElasticVersion.V5_6);
    assertThat(ElasticVersion.forVersion("6.2.0")).isEqualTo(ElasticVersion.V6_2);
    assertThat(ElasticVersion.forVersion("6.2.4")).isEqualTo(ElasticVersion.V6_2);
    assertThat(ElasticVersion.forVersion("6.3.0")).isEqualTo(ElasticVersion.V6_3);
    assertThat(ElasticVersion.forVersion("6.3.2")).isEqualTo(ElasticVersion.V6_3);
    assertThat(ElasticVersion.forVersion("6.4.0")).isEqualTo(ElasticVersion.V6_4);
    assertThat(ElasticVersion.forVersion("6.4.1")).isEqualTo(ElasticVersion.V6_4);
}
#end_block

#method_before
@Test
public void version6() throws Exception {
    assertThat(ElasticVersion.V6_2.isV6()).isTrue();
    assertThat(ElasticVersion.V6_3.isV6()).isTrue();
    assertThat(ElasticVersion.V5_6.isV6()).isFalse();
}
#method_after
@Test
public void version6() throws Exception {
    assertThat(ElasticVersion.V6_2.isV6()).isTrue();
    assertThat(ElasticVersion.V6_3.isV6()).isTrue();
    assertThat(ElasticVersion.V6_4.isV6()).isTrue();
    assertThat(ElasticVersion.V5_6.isV6()).isFalse();
}
#end_block

#method_before
public Response<AccountInfo> apply(IdString id, AccountInput input) throws BadRequestException, ResourceConflictException, UnprocessableEntityException, OrmException, IOException, ConfigInvalidException, PermissionBackendException {
    String username = id.get();
    if (input.username != null && !username.equals(input.username)) {
        throw new BadRequestException("username must match URL");
    }
    if (!ExternalId.isValidUsername(username)) {
        throw new BadRequestException("Username '" + username + "' must comply with [" + USER_NAME_PATTERN + "] pattern.");
    }
    Set<AccountGroup.UUID> groups = parseGroups(input.groups);
    Account.Id accountId = new Account.Id(seq.nextAccountId());
    List<ExternalId> extIds = new ArrayList<>();
    if (input.email != null) {
        if (!validator.isValid(input.email)) {
            throw new BadRequestException("invalid email address");
        }
        extIds.add(ExternalId.createEmail(accountId, input.email));
    }
    extIds.add(ExternalId.createUsername(username, accountId, input.httpPassword));
    for (AccountExternalIdCreator c : externalIdCreators) {
        extIds.addAll(c.create(accountId, username, input.email));
    }
    try {
        accountsUpdateProvider.get().insert("Create Account via API", accountId, u -> u.setFullName(input.name).setPreferredEmail(input.email).addExternalIds(extIds));
    } catch (DuplicateExternalIdKeyException e) {
        if (e.getDuplicateKey().isScheme(SCHEME_USERNAME)) {
            throw new ResourceConflictException("username '" + e.getDuplicateKey().id() + "' already exists");
        } else if (e.getDuplicateKey().isScheme(SCHEME_MAILTO)) {
            throw new UnprocessableEntityException("email '" + e.getDuplicateKey().id() + "' already exists");
        } else {
            // AccountExternalIdCreator returned an external ID that already exists
            throw e;
        }
    }
    for (AccountGroup.UUID groupUuid : groups) {
        try {
            addGroupMember(groupUuid, accountId);
        } catch (NoSuchGroupException e) {
            throw new UnprocessableEntityException(String.format("Group %s not found", groupUuid));
        }
    }
    if (input.sshKey != null) {
        try {
            authorizedKeys.addKey(accountId, input.sshKey);
            sshKeyCache.evict(username);
        } catch (InvalidSshKeyException e) {
            throw new BadRequestException(e.getMessage());
        }
    }
    AccountLoader loader = infoLoader.create(true);
    AccountInfo info = loader.get(accountId);
    loader.fill();
    return Response.created(info);
}
#method_after
public Response<AccountInfo> apply(IdString id, AccountInput input) throws BadRequestException, ResourceConflictException, UnprocessableEntityException, OrmException, IOException, ConfigInvalidException, PermissionBackendException {
    String username = id.get();
    if (input.username != null && !username.equals(input.username)) {
        throw new BadRequestException("username must match URL");
    }
    if (!ExternalId.isValidUsername(username)) {
        throw new BadRequestException("Invalid username '" + username + "'");
    }
    Set<AccountGroup.UUID> groups = parseGroups(input.groups);
    Account.Id accountId = new Account.Id(seq.nextAccountId());
    List<ExternalId> extIds = new ArrayList<>();
    if (input.email != null) {
        if (!validator.isValid(input.email)) {
            throw new BadRequestException("invalid email address");
        }
        extIds.add(ExternalId.createEmail(accountId, input.email));
    }
    extIds.add(ExternalId.createUsername(username, accountId, input.httpPassword));
    for (AccountExternalIdCreator c : externalIdCreators) {
        extIds.addAll(c.create(accountId, username, input.email));
    }
    try {
        accountsUpdateProvider.get().insert("Create Account via API", accountId, u -> u.setFullName(input.name).setPreferredEmail(input.email).addExternalIds(extIds));
    } catch (DuplicateExternalIdKeyException e) {
        if (e.getDuplicateKey().isScheme(SCHEME_USERNAME)) {
            throw new ResourceConflictException("username '" + e.getDuplicateKey().id() + "' already exists");
        } else if (e.getDuplicateKey().isScheme(SCHEME_MAILTO)) {
            throw new UnprocessableEntityException("email '" + e.getDuplicateKey().id() + "' already exists");
        } else {
            // AccountExternalIdCreator returned an external ID that already exists
            throw e;
        }
    }
    for (AccountGroup.UUID groupUuid : groups) {
        try {
            addGroupMember(groupUuid, accountId);
        } catch (NoSuchGroupException e) {
            throw new UnprocessableEntityException(String.format("Group %s not found", groupUuid));
        }
    }
    if (input.sshKey != null) {
        try {
            authorizedKeys.addKey(accountId, input.sshKey);
            sshKeyCache.evict(username);
        } catch (InvalidSshKeyException e) {
            throw new BadRequestException(e.getMessage());
        }
    }
    AccountLoader loader = infoLoader.create(true);
    AccountInfo info = loader.get(accountId);
    loader.fill();
    return Response.created(info);
}
#end_block

#method_before
private void parseUpdate(ReceiveCommand cmd) throws PermissionBackendException, IOException {
    logger.atFine().log("Updating %s", cmd);
    Optional<AuthException> err = checkRefPermission(cmd, RefPermission.UPDATE);
    if (!err.isPresent()) {
        if (isHead(cmd) && !isCommit(cmd)) {
            reject(cmd, "head must point to commit");
            return;
        }
        if (validRefOperation(cmd)) {
            validateRegularPushCommits(new Branch.NameKey(project.getNameKey(), cmd.getRefName()), cmd);
        }
    } else {
        rejectProhibited(cmd, err.get());
    }
}
#method_after
private void parseUpdate(ReceiveCommand cmd) throws PermissionBackendException {
    logger.atFine().log("Updating %s", cmd);
    Optional<AuthException> err = checkRefPermission(cmd, RefPermission.UPDATE);
    if (!err.isPresent()) {
        if (isHead(cmd) && !isCommit(cmd)) {
            reject(cmd, "head must point to commit");
            return;
        }
        if (validRefOperation(cmd)) {
            validateRegularPushCommits(new Branch.NameKey(project.getNameKey(), cmd.getRefName()), cmd);
        }
    } else {
        rejectProhibited(cmd, err.get());
    }
}
#end_block

#method_before
private void parseRewind(ReceiveCommand cmd) throws PermissionBackendException, IOException {
    RevCommit newObject;
    try {
        newObject = receivePack.getRevWalk().parseCommit(cmd.getNewId());
    } catch (IncorrectObjectTypeException notCommit) {
        newObject = null;
    } catch (IOException err) {
        logger.atSevere().withCause(err).log("Invalid object %s for %s forced update", cmd.getNewId().name(), cmd.getRefName());
        reject(cmd, "invalid object");
        return;
    }
    logger.atFine().log("Rewinding %s", cmd);
    if (newObject != null) {
        validateRegularPushCommits(new Branch.NameKey(project.getNameKey(), cmd.getRefName()), cmd);
        if (cmd.getResult() != NOT_ATTEMPTED) {
            return;
        }
    }
    Optional<AuthException> err = checkRefPermission(cmd, RefPermission.FORCE_UPDATE);
    if (!err.isPresent()) {
        validRefOperation(cmd);
    } else {
        rejectProhibited(cmd, err.get());
    }
}
#method_after
private void parseRewind(ReceiveCommand cmd) throws PermissionBackendException {
    RevCommit newObject;
    try {
        newObject = receivePack.getRevWalk().parseCommit(cmd.getNewId());
    } catch (IncorrectObjectTypeException notCommit) {
        newObject = null;
    } catch (IOException err) {
        logger.atSevere().withCause(err).log("Invalid object %s for %s forced update", cmd.getNewId().name(), cmd.getRefName());
        reject(cmd, "invalid object");
        return;
    }
    logger.atFine().log("Rewinding %s", cmd);
    if (newObject != null) {
        validateRegularPushCommits(new Branch.NameKey(project.getNameKey(), cmd.getRefName()), cmd);
        if (cmd.getResult() != NOT_ATTEMPTED) {
            return;
        }
    }
    Optional<AuthException> err = checkRefPermission(cmd, RefPermission.FORCE_UPDATE);
    if (!err.isPresent()) {
        validRefOperation(cmd);
    } else {
        rejectProhibited(cmd, err.get());
    }
}
#end_block

#method_before
private void parseReplaceCommand(ReceiveCommand cmd, Change.Id changeId) {
    logger.atFine().log("Parsing replace command");
    if (cmd.getType() != ReceiveCommand.Type.CREATE) {
        reject(cmd, "invalid usage");
        return;
    }
    RevCommit newCommit;
    try {
        newCommit = receivePack.getRevWalk().parseCommit(cmd.getNewId());
        logger.atFine().log("Replacing with %s", newCommit);
    } catch (IOException e) {
        logger.atSevere().withCause(e).log("Cannot parse %s as commit", cmd.getNewId().name());
        reject(cmd, "invalid commit");
        return;
    }
    Change changeEnt;
    try {
        changeEnt = notesFactory.createChecked(db, project.getNameKey(), changeId).getChange();
    } catch (NoSuchChangeException e) {
        logger.atSevere().withCause(e).log("Change not found %s", changeId);
        reject(cmd, "change " + changeId + " not found");
        return;
    } catch (OrmException e) {
        logger.atSevere().withCause(e).log("Cannot lookup existing change %s", changeId);
        reject(cmd, "database error");
        return;
    }
    if (!project.getNameKey().equals(changeEnt.getProject())) {
        reject(cmd, "change " + changeId + " does not belong to project " + project.getName());
        return;
    }
    CommitValidatorCache validator = commitValidatorFactory.create(projectState, user);
    try {
        NoteMap rejectCommits = loadRejectCommits();
        if (validator.validCommit(receivePack.getRevWalk().getObjectReader(), changeEnt.getDest(), cmd, newCommit, false, messages, rejectCommits, changeEnt)) {
            logger.atFine().log("Replacing change %s", changeEnt.getId());
            requestReplace(cmd, true, changeEnt, newCommit);
        }
    } catch (IOException e) {
        reject(cmd, "I/O exception validating commit");
    }
}
#method_after
private void parseReplaceCommand(ReceiveCommand cmd, Change.Id changeId) {
    logger.atFine().log("Parsing replace command");
    if (cmd.getType() != ReceiveCommand.Type.CREATE) {
        reject(cmd, "invalid usage");
        return;
    }
    RevCommit newCommit;
    try {
        newCommit = receivePack.getRevWalk().parseCommit(cmd.getNewId());
        logger.atFine().log("Replacing with %s", newCommit);
    } catch (IOException e) {
        logger.atSevere().withCause(e).log("Cannot parse %s as commit", cmd.getNewId().name());
        reject(cmd, "invalid commit");
        return;
    }
    Change changeEnt;
    try {
        changeEnt = notesFactory.createChecked(db, project.getNameKey(), changeId).getChange();
    } catch (NoSuchChangeException e) {
        logger.atSevere().withCause(e).log("Change not found %s", changeId);
        reject(cmd, "change " + changeId + " not found");
        return;
    } catch (OrmException e) {
        logger.atSevere().withCause(e).log("Cannot lookup existing change %s", changeId);
        reject(cmd, "database error");
        return;
    }
    if (!project.getNameKey().equals(changeEnt.getProject())) {
        reject(cmd, "change " + changeId + " does not belong to project " + project.getName());
        return;
    }
    CommitValidatorCache validator = commitValidatorFactory.create(projectState, user);
    try {
        if (validator.validCommit(receivePack.getRevWalk().getObjectReader(), changeEnt.getDest(), cmd, newCommit, false, messages, rejectCommits, changeEnt)) {
            logger.atFine().log("Replacing change %s", changeEnt.getId());
            requestReplace(cmd, true, changeEnt, newCommit);
        }
    } catch (IOException e) {
        reject(cmd, "I/O exception validating commit");
    }
}
#end_block

#method_before
private List<CreateRequest> selectNewAndReplacedChangesFromMagicBranch(Task newProgress) {
    logger.atFine().log("Finding new and replaced changes");
    List<CreateRequest> newChanges = new ArrayList<>();
    ListMultimap<ObjectId, Ref> existing = changeRefsById();
    GroupCollector groupCollector = GroupCollector.create(changeRefsById(), db, psUtil, notesFactory, project.getNameKey());
    CommitValidatorCache validator = commitValidatorFactory.create(projectState, user);
    try {
        NoteMap rejectCommits = loadRejectCommits();
        RevCommit start = setUpWalkForSelectingChanges();
        if (start == null) {
            return Collections.emptyList();
        }
        LinkedHashMap<RevCommit, ChangeLookup> pending = new LinkedHashMap<>();
        Set<Change.Key> newChangeIds = new HashSet<>();
        int maxBatchChanges = receiveConfig.getEffectiveMaxBatchChangesLimit(user);
        int total = 0;
        int alreadyTracked = 0;
        boolean rejectImplicitMerges = start.getParentCount() == 1 && projectCache.get(project.getNameKey()).is(BooleanProjectConfig.REJECT_IMPLICIT_MERGES) && // late.
        !magicBranch.merged;
        Set<RevCommit> mergedParents;
        if (rejectImplicitMerges) {
            mergedParents = new HashSet<>();
        } else {
            mergedParents = null;
        }
        for (; ; ) {
            RevCommit c = receivePack.getRevWalk().next();
            if (c == null) {
                break;
            }
            total++;
            receivePack.getRevWalk().parseBody(c);
            String name = c.name();
            groupCollector.visit(c);
            Collection<Ref> existingRefs = existing.get(c);
            if (rejectImplicitMerges) {
                Collections.addAll(mergedParents, c.getParents());
                mergedParents.remove(c);
            }
            boolean commitAlreadyTracked = !existingRefs.isEmpty();
            if (commitAlreadyTracked) {
                alreadyTracked++;
                // different target branch.
                for (Ref ref : existingRefs) {
                    updateGroups.add(new UpdateGroupsRequest(ref, c));
                }
                if (!(newChangeForAllNotInTarget || magicBranch.base != null)) {
                    continue;
                }
            }
            List<String> idList = c.getFooterLines(CHANGE_ID);
            if (!idList.isEmpty()) {
                pending.put(c, lookupByChangeKey(c, new Change.Key(idList.get(idList.size() - 1).trim())));
            } else {
                pending.put(c, lookupByCommit(c));
            }
            int n = pending.size() + newChanges.size();
            if (maxBatchChanges != 0 && n > maxBatchChanges) {
                logger.atFine().log("%d changes exceeds limit of %d", n, maxBatchChanges);
                reject(magicBranch.cmd, "the number of pushed changes in a batch exceeds the max limit " + maxBatchChanges);
                return Collections.emptyList();
            }
            if (commitAlreadyTracked) {
                boolean changeExistsOnDestBranch = false;
                for (ChangeData cd : pending.get(c).destChanges) {
                    if (cd.change().getDest().equals(magicBranch.dest)) {
                        changeExistsOnDestBranch = true;
                        break;
                    }
                }
                if (changeExistsOnDestBranch) {
                    continue;
                }
                logger.atFine().log("Creating new change for %s even though it is already tracked", name);
            }
            if (!validator.validCommit(receivePack.getRevWalk().getObjectReader(), magicBranch.dest, magicBranch.cmd, c, magicBranch.merged, messages, rejectCommits, null)) {
                // Not a change the user can propose? Abort as early as possible.
                logger.atFine().log("Aborting early due to invalid commit");
                return Collections.emptyList();
            }
            // Don't allow merges to be uploaded in commit chain via all-not-in-target
            if (newChangeForAllNotInTarget && c.getParentCount() > 1) {
                reject(magicBranch.cmd, "Pushing merges in commit chains with 'all not in target' is not allowed,\n" + "to override please set the base manually");
                logger.atFine().log("Rejecting merge commit %s with newChangeForAllNotInTarget", name);
            // TODO(dborowitz): Should we early return here?
            }
            if (idList.isEmpty()) {
                newChanges.add(new CreateRequest(c, magicBranch.dest.get(), newProgress));
                continue;
            }
        }
        logger.atFine().log("Finished initial RevWalk with %d commits total: %d already" + " tracked, %d new changes with no Change-Id, and %d deferred" + " lookups", total, alreadyTracked, newChanges.size(), pending.size());
        if (rejectImplicitMerges) {
            rejectImplicitMerges(mergedParents);
        }
        for (Iterator<ChangeLookup> itr = pending.values().iterator(); itr.hasNext(); ) {
            ChangeLookup p = itr.next();
            if (p.changeKey == null) {
                continue;
            }
            if (newChangeIds.contains(p.changeKey)) {
                logger.atFine().log("Multiple commits with Change-Id %s", p.changeKey);
                reject(magicBranch.cmd, SAME_CHANGE_ID_IN_MULTIPLE_CHANGES);
                return Collections.emptyList();
            }
            List<ChangeData> changes = p.destChanges;
            if (changes.size() > 1) {
                logger.atFine().log("Multiple changes in branch %s with Change-Id %s: %s", magicBranch.dest, p.changeKey, changes.stream().map(cd -> cd.getId().toString()).collect(joining()));
                // WTF, multiple changes in this branch have the same key?
                // Since the commit is new, the user should recreate it with
                // a different Change-Id. In practice, we should never see
                // this error message as Change-Id should be unique per branch.
                // 
                reject(magicBranch.cmd, p.changeKey.get() + " has duplicates");
                return Collections.emptyList();
            }
            if (changes.size() == 1) {
                // Schedule as a replacement to this one matching change.
                // 
                RevId currentPs = changes.get(0).currentPatchSet().getRevision();
                // If Commit is already current PatchSet of target Change.
                if (p.commit.name().equals(currentPs.get())) {
                    if (pending.size() == 1) {
                        // There are no commits left to check, all commits in pending were already
                        // current PatchSet of the corresponding target changes.
                        reject(magicBranch.cmd, "commit(s) already exists (as current patchset)");
                    } else {
                        // Commit is already current PatchSet.
                        // Remove from pending and try next commit.
                        itr.remove();
                        continue;
                    }
                }
                if (requestReplace(magicBranch.cmd, false, changes.get(0).change(), p.commit)) {
                    continue;
                }
                return Collections.emptyList();
            }
            if (changes.size() == 0) {
                if (!isValidChangeId(p.changeKey.get())) {
                    reject(magicBranch.cmd, "invalid Change-Id");
                    return Collections.emptyList();
                }
                // double check against the existing refs
                if (foundInExistingRef(existing.get(p.commit))) {
                    if (pending.size() == 1) {
                        reject(magicBranch.cmd, "commit(s) already exists (as current patchset)");
                        return Collections.emptyList();
                    }
                    itr.remove();
                    continue;
                }
                newChangeIds.add(p.changeKey);
            }
            newChanges.add(new CreateRequest(p.commit, magicBranch.dest.get(), newProgress));
        }
        logger.atFine().log("Finished deferred lookups with %d updates and %d new changes", replaceByChange.size(), newChanges.size());
    } catch (IOException e) {
        // Should never happen, the core receive process would have
        // identified the missing object earlier before we got control.
        // 
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logger.atSevere().withCause(e).log("Invalid pack upload; one or more objects weren't sent");
        return Collections.emptyList();
    } catch (OrmException e) {
        logger.atSevere().withCause(e).log("Cannot query database to locate prior changes");
        reject(magicBranch.cmd, "database error");
        return Collections.emptyList();
    }
    if (newChanges.isEmpty() && replaceByChange.isEmpty()) {
        reject(magicBranch.cmd, "no new changes");
        return Collections.emptyList();
    }
    if (!newChanges.isEmpty() && magicBranch.edit) {
        reject(magicBranch.cmd, "edit is not supported for new changes");
        return newChanges;
    }
    try {
        SortedSetMultimap<ObjectId, String> groups = groupCollector.getGroups();
        List<Integer> newIds = seq.nextChangeIds(newChanges.size());
        for (int i = 0; i < newChanges.size(); i++) {
            CreateRequest create = newChanges.get(i);
            create.setChangeId(newIds.get(i));
            create.groups = ImmutableList.copyOf(groups.get(create.commit));
        }
        for (ReplaceRequest replace : replaceByChange.values()) {
            replace.groups = ImmutableList.copyOf(groups.get(replace.newCommitId));
        }
        for (UpdateGroupsRequest update : updateGroups) {
            update.groups = ImmutableList.copyOf((groups.get(update.commit)));
        }
        logger.atFine().log("Finished updating groups from GroupCollector");
    } catch (OrmException e) {
        logger.atSevere().withCause(e).log("Error collecting groups for changes");
        reject(magicBranch.cmd, "internal server error");
    }
    return newChanges;
}
#method_after
private List<CreateRequest> selectNewAndReplacedChangesFromMagicBranch(Task newProgress) {
    logger.atFine().log("Finding new and replaced changes");
    List<CreateRequest> newChanges = new ArrayList<>();
    ListMultimap<ObjectId, Ref> existing = changeRefsById();
    GroupCollector groupCollector = GroupCollector.create(changeRefsById(), db, psUtil, notesFactory, project.getNameKey());
    CommitValidatorCache validator = commitValidatorFactory.create(projectState, user);
    try {
        RevCommit start = setUpWalkForSelectingChanges();
        if (start == null) {
            return Collections.emptyList();
        }
        LinkedHashMap<RevCommit, ChangeLookup> pending = new LinkedHashMap<>();
        Set<Change.Key> newChangeIds = new HashSet<>();
        int maxBatchChanges = receiveConfig.getEffectiveMaxBatchChangesLimit(user);
        int total = 0;
        int alreadyTracked = 0;
        boolean rejectImplicitMerges = start.getParentCount() == 1 && projectCache.get(project.getNameKey()).is(BooleanProjectConfig.REJECT_IMPLICIT_MERGES) && // late.
        !magicBranch.merged;
        Set<RevCommit> mergedParents;
        if (rejectImplicitMerges) {
            mergedParents = new HashSet<>();
        } else {
            mergedParents = null;
        }
        for (; ; ) {
            RevCommit c = receivePack.getRevWalk().next();
            if (c == null) {
                break;
            }
            total++;
            receivePack.getRevWalk().parseBody(c);
            String name = c.name();
            groupCollector.visit(c);
            Collection<Ref> existingRefs = existing.get(c);
            if (rejectImplicitMerges) {
                Collections.addAll(mergedParents, c.getParents());
                mergedParents.remove(c);
            }
            boolean commitAlreadyTracked = !existingRefs.isEmpty();
            if (commitAlreadyTracked) {
                alreadyTracked++;
                // different target branch.
                for (Ref ref : existingRefs) {
                    updateGroups.add(new UpdateGroupsRequest(ref, c));
                }
                if (!(newChangeForAllNotInTarget || magicBranch.base != null)) {
                    continue;
                }
            }
            List<String> idList = c.getFooterLines(CHANGE_ID);
            if (!idList.isEmpty()) {
                pending.put(c, lookupByChangeKey(c, new Change.Key(idList.get(idList.size() - 1).trim())));
            } else {
                pending.put(c, lookupByCommit(c));
            }
            int n = pending.size() + newChanges.size();
            if (maxBatchChanges != 0 && n > maxBatchChanges) {
                logger.atFine().log("%d changes exceeds limit of %d", n, maxBatchChanges);
                reject(magicBranch.cmd, "the number of pushed changes in a batch exceeds the max limit " + maxBatchChanges);
                return Collections.emptyList();
            }
            if (commitAlreadyTracked) {
                boolean changeExistsOnDestBranch = false;
                for (ChangeData cd : pending.get(c).destChanges) {
                    if (cd.change().getDest().equals(magicBranch.dest)) {
                        changeExistsOnDestBranch = true;
                        break;
                    }
                }
                if (changeExistsOnDestBranch) {
                    continue;
                }
                logger.atFine().log("Creating new change for %s even though it is already tracked", name);
            }
            if (!validator.validCommit(receivePack.getRevWalk().getObjectReader(), magicBranch.dest, magicBranch.cmd, c, magicBranch.merged, messages, rejectCommits, null)) {
                // Not a change the user can propose? Abort as early as possible.
                logger.atFine().log("Aborting early due to invalid commit");
                return Collections.emptyList();
            }
            // Don't allow merges to be uploaded in commit chain via all-not-in-target
            if (newChangeForAllNotInTarget && c.getParentCount() > 1) {
                reject(magicBranch.cmd, "Pushing merges in commit chains with 'all not in target' is not allowed,\n" + "to override please set the base manually");
                logger.atFine().log("Rejecting merge commit %s with newChangeForAllNotInTarget", name);
            // TODO(dborowitz): Should we early return here?
            }
            if (idList.isEmpty()) {
                newChanges.add(new CreateRequest(c, magicBranch.dest.get(), newProgress));
                continue;
            }
        }
        logger.atFine().log("Finished initial RevWalk with %d commits total: %d already" + " tracked, %d new changes with no Change-Id, and %d deferred" + " lookups", total, alreadyTracked, newChanges.size(), pending.size());
        if (rejectImplicitMerges) {
            rejectImplicitMerges(mergedParents);
        }
        for (Iterator<ChangeLookup> itr = pending.values().iterator(); itr.hasNext(); ) {
            ChangeLookup p = itr.next();
            if (p.changeKey == null) {
                continue;
            }
            if (newChangeIds.contains(p.changeKey)) {
                logger.atFine().log("Multiple commits with Change-Id %s", p.changeKey);
                reject(magicBranch.cmd, SAME_CHANGE_ID_IN_MULTIPLE_CHANGES);
                return Collections.emptyList();
            }
            List<ChangeData> changes = p.destChanges;
            if (changes.size() > 1) {
                logger.atFine().log("Multiple changes in branch %s with Change-Id %s: %s", magicBranch.dest, p.changeKey, changes.stream().map(cd -> cd.getId().toString()).collect(joining()));
                // WTF, multiple changes in this branch have the same key?
                // Since the commit is new, the user should recreate it with
                // a different Change-Id. In practice, we should never see
                // this error message as Change-Id should be unique per branch.
                // 
                reject(magicBranch.cmd, p.changeKey.get() + " has duplicates");
                return Collections.emptyList();
            }
            if (changes.size() == 1) {
                // Schedule as a replacement to this one matching change.
                // 
                RevId currentPs = changes.get(0).currentPatchSet().getRevision();
                // If Commit is already current PatchSet of target Change.
                if (p.commit.name().equals(currentPs.get())) {
                    if (pending.size() == 1) {
                        // There are no commits left to check, all commits in pending were already
                        // current PatchSet of the corresponding target changes.
                        reject(magicBranch.cmd, "commit(s) already exists (as current patchset)");
                    } else {
                        // Commit is already current PatchSet.
                        // Remove from pending and try next commit.
                        itr.remove();
                        continue;
                    }
                }
                if (requestReplace(magicBranch.cmd, false, changes.get(0).change(), p.commit)) {
                    continue;
                }
                return Collections.emptyList();
            }
            if (changes.size() == 0) {
                if (!isValidChangeId(p.changeKey.get())) {
                    reject(magicBranch.cmd, "invalid Change-Id");
                    return Collections.emptyList();
                }
                // double check against the existing refs
                if (foundInExistingRef(existing.get(p.commit))) {
                    if (pending.size() == 1) {
                        reject(magicBranch.cmd, "commit(s) already exists (as current patchset)");
                        return Collections.emptyList();
                    }
                    itr.remove();
                    continue;
                }
                newChangeIds.add(p.changeKey);
            }
            newChanges.add(new CreateRequest(p.commit, magicBranch.dest.get(), newProgress));
        }
        logger.atFine().log("Finished deferred lookups with %d updates and %d new changes", replaceByChange.size(), newChanges.size());
    } catch (IOException e) {
        // Should never happen, the core receive process would have
        // identified the missing object earlier before we got control.
        // 
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logger.atSevere().withCause(e).log("Invalid pack upload; one or more objects weren't sent");
        return Collections.emptyList();
    } catch (OrmException e) {
        logger.atSevere().withCause(e).log("Cannot query database to locate prior changes");
        reject(magicBranch.cmd, "database error");
        return Collections.emptyList();
    }
    if (newChanges.isEmpty() && replaceByChange.isEmpty()) {
        reject(magicBranch.cmd, "no new changes");
        return Collections.emptyList();
    }
    if (!newChanges.isEmpty() && magicBranch.edit) {
        reject(magicBranch.cmd, "edit is not supported for new changes");
        return newChanges;
    }
    try {
        SortedSetMultimap<ObjectId, String> groups = groupCollector.getGroups();
        List<Integer> newIds = seq.nextChangeIds(newChanges.size());
        for (int i = 0; i < newChanges.size(); i++) {
            CreateRequest create = newChanges.get(i);
            create.setChangeId(newIds.get(i));
            create.groups = ImmutableList.copyOf(groups.get(create.commit));
        }
        for (ReplaceRequest replace : replaceByChange.values()) {
            replace.groups = ImmutableList.copyOf(groups.get(replace.newCommitId));
        }
        for (UpdateGroupsRequest update : updateGroups) {
            update.groups = ImmutableList.copyOf((groups.get(update.commit)));
        }
        logger.atFine().log("Finished updating groups from GroupCollector");
    } catch (OrmException e) {
        logger.atSevere().withCause(e).log("Error collecting groups for changes");
        reject(magicBranch.cmd, "internal server error");
    }
    return newChanges;
}
#end_block

#method_before
private void validateRegularPushCommits(Branch.NameKey branch, ReceiveCommand cmd) throws PermissionBackendException, IOException {
    NoteMap rejectCommits = loadRejectCommits();
    if (!RefNames.REFS_CONFIG.equals(cmd.getRefName()) && !(MagicBranch.isMagicBranch(cmd.getRefName()) || NEW_PATCHSET_PATTERN.matcher(cmd.getRefName()).matches()) && pushOptions.containsKey(PUSH_OPTION_SKIP_VALIDATION)) {
        if (projectState.is(BooleanProjectConfig.USE_SIGNED_OFF_BY)) {
            reject(cmd, "requireSignedOffBy prevents option " + PUSH_OPTION_SKIP_VALIDATION);
            return;
        }
        Optional<AuthException> err = checkRefPermission(permissions.ref(branch.get()), RefPermission.SKIP_VALIDATION);
        if (err.isPresent()) {
            rejectProhibited(cmd, err.get());
            return;
        }
        if (!Iterables.isEmpty(rejectCommits)) {
            reject(cmd, "reject-commits prevents " + PUSH_OPTION_SKIP_VALIDATION);
        }
        logger.atFine().log("Short-circuiting new commit validation");
        return;
    }
    CommitValidatorCache validator = commitValidatorFactory.create(projectState, user);
    boolean missingFullName = Strings.isNullOrEmpty(user.getAccount().getFullName());
    RevWalk walk = receivePack.getRevWalk();
    walk.reset();
    walk.sort(RevSort.NONE);
    try {
        RevObject parsedObject = walk.parseAny(cmd.getNewId());
        if (!(parsedObject instanceof RevCommit)) {
            return;
        }
        ListMultimap<ObjectId, Ref> existing = changeRefsById();
        walk.markStart((RevCommit) parsedObject);
        markHeadsAsUninteresting(walk, cmd.getRefName());
        int limit = receiveConfig.maxBatchCommits;
        int n = 0;
        for (RevCommit c; (c = walk.next()) != null; ) {
            if (++n > limit) {
                logger.atFine().log("Number of new commits exceeds limit of %d", limit);
                reject(cmd, String.format("more than %d commits, and %s not set", limit, PUSH_OPTION_SKIP_VALIDATION));
                return;
            }
            if (existing.keySet().contains(c)) {
                continue;
            }
            if (!validator.validCommit(walk.getObjectReader(), branch, cmd, c, false, messages, rejectCommits, null)) {
                break;
            }
            if (missingFullName && user.hasEmailAddress(c.getCommitterIdent().getEmailAddress())) {
                logger.atFine().log("Will update full name of caller");
                setFullNameTo = c.getCommitterIdent().getName();
                missingFullName = false;
            }
        }
        logger.atFine().log("Validated %d new commits", n);
    } catch (IOException err) {
        cmd.setResult(REJECTED_MISSING_OBJECT);
        logger.atSevere().withCause(err).log("Invalid pack upload; one or more objects weren't sent");
    }
}
#method_after
private void validateRegularPushCommits(Branch.NameKey branch, ReceiveCommand cmd) throws PermissionBackendException {
    if (!RefNames.REFS_CONFIG.equals(cmd.getRefName()) && !(MagicBranch.isMagicBranch(cmd.getRefName()) || NEW_PATCHSET_PATTERN.matcher(cmd.getRefName()).matches()) && pushOptions.containsKey(PUSH_OPTION_SKIP_VALIDATION)) {
        if (projectState.is(BooleanProjectConfig.USE_SIGNED_OFF_BY)) {
            reject(cmd, "requireSignedOffBy prevents option " + PUSH_OPTION_SKIP_VALIDATION);
            return;
        }
        Optional<AuthException> err = checkRefPermission(permissions.ref(branch.get()), RefPermission.SKIP_VALIDATION);
        if (err.isPresent()) {
            rejectProhibited(cmd, err.get());
            return;
        }
        if (!Iterables.isEmpty(rejectCommits)) {
            reject(cmd, "reject-commits prevents " + PUSH_OPTION_SKIP_VALIDATION);
        }
        logger.atFine().log("Short-circuiting new commit validation");
        return;
    }
    CommitValidatorCache validator = commitValidatorFactory.create(projectState, user);
    boolean missingFullName = Strings.isNullOrEmpty(user.getAccount().getFullName());
    RevWalk walk = receivePack.getRevWalk();
    walk.reset();
    walk.sort(RevSort.NONE);
    try {
        RevObject parsedObject = walk.parseAny(cmd.getNewId());
        if (!(parsedObject instanceof RevCommit)) {
            return;
        }
        ListMultimap<ObjectId, Ref> existing = changeRefsById();
        walk.markStart((RevCommit) parsedObject);
        markHeadsAsUninteresting(walk, cmd.getRefName());
        int limit = receiveConfig.maxBatchCommits;
        int n = 0;
        for (RevCommit c; (c = walk.next()) != null; ) {
            if (++n > limit) {
                logger.atFine().log("Number of new commits exceeds limit of %d", limit);
                reject(cmd, String.format("more than %d commits, and %s not set", limit, PUSH_OPTION_SKIP_VALIDATION));
                return;
            }
            if (existing.keySet().contains(c)) {
                continue;
            }
            if (!validator.validCommit(walk.getObjectReader(), branch, cmd, c, false, messages, rejectCommits, null)) {
                break;
            }
            if (missingFullName && user.hasEmailAddress(c.getCommitterIdent().getEmailAddress())) {
                logger.atFine().log("Will update full name of caller");
                setFullNameTo = c.getCommitterIdent().getName();
                missingFullName = false;
            }
        }
        logger.atFine().log("Validated %d new commits", n);
    } catch (IOException err) {
        cmd.setResult(REJECTED_MISSING_OBJECT);
        logger.atSevere().withCause(err).log("Invalid pack upload; one or more objects weren't sent");
    }
}
#end_block

#method_before
@Override
public int hashCode() {
    return Objects.hashCode(EvaluationTask.class, repositoryPath);
}
#method_after
@Override
public int hashCode() {
    return Objects.hashCode(repositoryPath);
}
#end_block

#method_before
private static GerritServer startInMemory(Description desc, Path site, Config baseConfig, Daemon daemon, @Nullable InMemoryRepositoryManager inMemoryRepoManager, @Nullable InMemoryDatabase.Instance inMemoryDatabaseInstance) throws Exception {
    Config cfg = desc.buildConfig(baseConfig);
    mergeTestConfig(cfg);
    // Set the log4j configuration to an invalid one to prevent system logs
    // from getting configured and creating log files.
    System.setProperty(SystemLog.LOG4J_CONFIGURATION, "invalidConfiguration");
    cfg.setBoolean("httpd", null, "requestLog", false);
    cfg.setBoolean("sshd", null, "requestLog", false);
    cfg.setBoolean("index", "lucene", "testInmemory", true);
    cfg.setString("gitweb", null, "cgi", "");
    daemon.setEnableHttpd(desc.httpd());
    daemon.setLuceneModule(LuceneIndexModule.singleVersionAllLatest(0, isSlave(baseConfig)));
    daemon.setDatabaseForTesting(ImmutableList.<Module>of(new InMemoryTestingDatabaseModule(cfg, site, inMemoryRepoManager, inMemoryDatabaseInstance)));
    daemon.start();
    return new GerritServer(desc, null, createTestInjector(daemon), daemon, null);
}
#method_after
private static GerritServer startInMemory(Description desc, Path site, Config baseConfig, Daemon daemon, @Nullable InMemoryRepositoryManager inMemoryRepoManager, @Nullable InMemoryDatabase.Instance inMemoryDatabaseInstance) throws Exception {
    Config cfg = desc.buildConfig(baseConfig);
    mergeTestConfig(cfg);
    // Set the log4j configuration to an invalid one to prevent system logs
    // from getting configured and creating log files.
    System.setProperty(SystemLog.LOG4J_CONFIGURATION, "invalidConfiguration");
    cfg.setBoolean("httpd", null, "requestLog", false);
    cfg.setBoolean("sshd", null, "requestLog", false);
    cfg.setBoolean("index", "lucene", "testInmemory", true);
    cfg.setString("gitweb", null, "cgi", "");
    daemon.setEnableHttpd(desc.httpd());
    daemon.setLuceneModule(LuceneIndexModule.singleVersionAllLatest(0, isSlave(baseConfig)));
    daemon.setDatabaseForTesting(ImmutableList.<Module>of(new InMemoryTestingDatabaseModule(cfg, site, inMemoryRepoManager, inMemoryDatabaseInstance), new AbstractModule() {

        @Override
        protected void configure() {
            bind(GerritRuntime.class).toInstance(GerritRuntime.DAEMON);
        }
    }));
    daemon.start();
    return new GerritServer(desc, null, createTestInjector(daemon), daemon, null);
}
#end_block

#method_before
@Override
public void init(FilterConfig config) throws ServletException {
    System.setProperty(JAVAMELODY_MONITORING_PATH_AUTHENTICATED, "/a" + Parameter.MONITORING_PATH.getValue());
    if (isPropertyInPluginConfig(Parameter.HTTP_TRANSFORM_PATTERN.getCode()) || isPropertyUndefined(config, Parameter.HTTP_TRANSFORM_PATTERN.getCode(), GLOBAL_HTTP_TRANSFORM_PATTERN)) {
        System.setProperty(GLOBAL_HTTP_TRANSFORM_PATTERN, getTransformPattern());
    }
    if (isPropertyInPluginConfig(Parameter.STORAGE_DIRECTORY.getCode()) || isPropertyUndefined(config, Parameter.STORAGE_DIRECTORY.getCode(), GLOBAL_STORAGE_DIR)) {
        System.setProperty(GLOBAL_STORAGE_DIR, getStorageDir());
    }
    super.init(config);
}
#method_after
@Override
public void init(FilterConfig config) throws ServletException {
    if (isPropertyInPluginConfig(HTTP_TRANSFORM_PATTERN) || isPropertyUndefined(config, HTTP_TRANSFORM_PATTERN, GLOBAL_HTTP_TRANSFORM_PATTERN)) {
        System.setProperty(GLOBAL_HTTP_TRANSFORM_PATTERN, getTransformPattern());
    }
    if (isPropertyInPluginConfig(STORAGE_DIR) || isPropertyUndefined(config, STORAGE_DIR, GLOBAL_STORAGE_DIR)) {
        System.setProperty(GLOBAL_STORAGE_DIR, getStorageDir());
    }
    super.init(config);
}
#end_block

#method_before
private String getTransformPattern() {
    return cfg.getString(Parameter.HTTP_TRANSFORM_PATTERN.getCode(), GERRIT_GROUPING);
}
#method_after
private String getTransformPattern() {
    return cfg.getString(HTTP_TRANSFORM_PATTERN, GERRIT_GROUPING);
}
#end_block

#method_before
private String getStorageDir() {
    // default to old path for javamelody storage-directory if it exists
    final Path tmp = Paths.get(System.getProperty("java.io.tmpdir")).resolve(JAVAMELODY_PREFIX);
    if (Files.isDirectory(tmp)) {
        log.warn("Javamelody data exists in 'tmp' [{}]. Configuration (if any) will be ignored.", tmp);
        return tmp.toString();
    }
    // plugin config has the highest priority
    Path storageDir = Optional.ofNullable(cfg.getString(Parameter.STORAGE_DIRECTORY.getCode())).map(Paths::get).orElse(defaultDataDir);
    if (!Files.isDirectory(storageDir)) {
        try {
            Files.createDirectories(storageDir);
        } catch (IOException e) {
            log.error("Creation of javamelody data dir [{}] failed.", storageDir, e);
            throw new RuntimeException(e);
        }
    }
    return storageDir.toString();
}
#method_after
private String getStorageDir() {
    // default to old path for javamelody storage-directory if it exists
    final Path tmp = Paths.get(System.getProperty("java.io.tmpdir")).resolve(JAVAMELODY_PREFIX);
    if (Files.isDirectory(tmp)) {
        log.warn("Javamelody data exists in 'tmp' [{}]. Configuration (if any) will be ignored.", tmp);
        return tmp.toString();
    }
    // plugin config has the highest priority
    Path storageDir = Optional.ofNullable(cfg.getString(STORAGE_DIR)).map(Paths::get).orElse(defaultDataDir);
    if (!Files.isDirectory(storageDir)) {
        try {
            Files.createDirectories(storageDir);
        } catch (IOException e) {
            log.error("Creation of javamelody data dir [{}] failed.", storageDir, e);
            throw new RuntimeException(e);
        }
    }
    return storageDir.toString();
}
#end_block

#method_before
boolean canMonitor(HttpServletRequest httpRequest) {
    if (httpRequest.getRequestURI().equals(getJavamelodyUrl(httpRequest))) {
        return capabilityChecker.canMonitor();
    }
    return true;
}
#method_after
boolean canMonitor(HttpServletRequest httpRequest) {
    if (httpRequest.getRequestURI().equals(getJavamelodyUrl(httpRequest))) {
        /* Exception when access to metrics for Prometheus using Bearer Token
         * without going through any Gerrit Authentication step.
         * Enable to access the Prometheus metrics ONLY and nothing else, skipping
         * any authentication and ACL check.
         */
        if (useBearerTokenForPrometheus && httpRequest.getHeader(AUTHORIZATION_HEADER) != null && FORMAT_PROMETHEUS.equals(HttpParameter.FORMAT.getParameterFrom(httpRequest))) {
            return canMonitorFromPrometheusUsingBearerToken(httpRequest);
        }
        return capabilityChecker.canMonitor();
    }
    return true;
}
#end_block

#method_before
private void parseReplaceCommand(ReceiveCommand cmd, Change.Id changeId) {
    logger.atFine().log("Parsing replace command");
    if (cmd.getType() != ReceiveCommand.Type.CREATE) {
        reject(cmd, "invalid usage");
        return;
    }
    RevCommit newCommit;
    try {
        newCommit = receivePack.getRevWalk().parseCommit(cmd.getNewId());
        logger.atFine().log("Replacing with %s", newCommit);
    } catch (IOException e) {
        logger.atSevere().withCause(e).log("Cannot parse %s as commit", cmd.getNewId().name());
        reject(cmd, "invalid commit");
        return;
    }
    Change changeEnt;
    try {
        changeEnt = notesFactory.createChecked(db, project.getNameKey(), changeId).getChange();
    } catch (NoSuchChangeException e) {
        logger.atSevere().withCause(e).log("Change not found %s", changeId);
        reject(cmd, "change " + changeId + " not found");
        return;
    } catch (OrmException e) {
        logger.atSevere().withCause(e).log("Cannot lookup existing change %s", changeId);
        reject(cmd, "database error");
        return;
    }
    if (!project.getNameKey().equals(changeEnt.getProject())) {
        reject(cmd, "change " + changeId + " does not belong to project " + project.getName());
        return;
    }
    try {
        if (validCommit(receivePack.getRevWalk().getObjectReader(), changeEnt.getDest(), cmd, newCommit, false, changeEnt)) {
            logger.atFine().log("Replacing change %s", changeEnt.getId());
            requestReplace(cmd, true, changeEnt, newCommit);
        }
    } catch (IOException e) {
        reject(cmd, "I/O exception validating commit");
    }
}
#method_after
private void parseReplaceCommand(ReceiveCommand cmd, Change.Id changeId) {
    logger.atFine().log("Parsing replace command");
    if (cmd.getType() != ReceiveCommand.Type.CREATE) {
        reject(cmd, "invalid usage");
        return;
    }
    RevCommit newCommit;
    try {
        newCommit = receivePack.getRevWalk().parseCommit(cmd.getNewId());
        logger.atFine().log("Replacing with %s", newCommit);
    } catch (IOException e) {
        logger.atSevere().withCause(e).log("Cannot parse %s as commit", cmd.getNewId().name());
        reject(cmd, "invalid commit");
        return;
    }
    Change changeEnt;
    try {
        changeEnt = notesFactory.createChecked(db, project.getNameKey(), changeId).getChange();
    } catch (NoSuchChangeException e) {
        logger.atSevere().withCause(e).log("Change not found %s", changeId);
        reject(cmd, "change " + changeId + " not found");
        return;
    } catch (OrmException e) {
        logger.atSevere().withCause(e).log("Cannot lookup existing change %s", changeId);
        reject(cmd, "database error");
        return;
    }
    if (!project.getNameKey().equals(changeEnt.getProject())) {
        reject(cmd, "change " + changeId + " does not belong to project " + project.getName());
        return;
    }
    try {
        NoteMap rejectCommits = BanCommit.loadRejectCommitsMap(repo, receivePack.getRevWalk());
        if (validCommit(receivePack.getRevWalk().getObjectReader(), changeEnt.getDest(), cmd, newCommit, false, changeEnt, rejectCommits)) {
            logger.atFine().log("Replacing change %s", changeEnt.getId());
            requestReplace(cmd, true, changeEnt, newCommit);
        }
    } catch (IOException e) {
        reject(cmd, "I/O exception validating commit");
    }
}
#end_block

#method_before
private List<CreateRequest> selectNewAndReplacedChangesFromMagicBranch(Task newProgress) {
    logger.atFine().log("Finding new and replaced changes");
    List<CreateRequest> newChanges = new ArrayList<>();
    ListMultimap<ObjectId, Ref> existing = changeRefsById();
    GroupCollector groupCollector = GroupCollector.create(changeRefsById(), db, psUtil, notesFactory, project.getNameKey());
    try {
        RevCommit start = setUpWalkForSelectingChanges();
        if (start == null) {
            return Collections.emptyList();
        }
        LinkedHashMap<RevCommit, ChangeLookup> pending = new LinkedHashMap<>();
        Set<Change.Key> newChangeIds = new HashSet<>();
        int maxBatchChanges = receiveConfig.getEffectiveMaxBatchChangesLimit(user);
        int total = 0;
        int alreadyTracked = 0;
        boolean rejectImplicitMerges = start.getParentCount() == 1 && projectCache.get(project.getNameKey()).is(BooleanProjectConfig.REJECT_IMPLICIT_MERGES) && // late.
        !magicBranch.merged;
        Set<RevCommit> mergedParents;
        if (rejectImplicitMerges) {
            mergedParents = new HashSet<>();
        } else {
            mergedParents = null;
        }
        for (; ; ) {
            RevCommit c = receivePack.getRevWalk().next();
            if (c == null) {
                break;
            }
            total++;
            receivePack.getRevWalk().parseBody(c);
            String name = c.name();
            groupCollector.visit(c);
            Collection<Ref> existingRefs = existing.get(c);
            if (rejectImplicitMerges) {
                Collections.addAll(mergedParents, c.getParents());
                mergedParents.remove(c);
            }
            boolean commitAlreadyTracked = !existingRefs.isEmpty();
            if (commitAlreadyTracked) {
                alreadyTracked++;
                // different target branch.
                for (Ref ref : existingRefs) {
                    updateGroups.add(new UpdateGroupsRequest(ref, c));
                }
                if (!(newChangeForAllNotInTarget || magicBranch.base != null)) {
                    continue;
                }
            }
            List<String> idList = c.getFooterLines(CHANGE_ID);
            if (!idList.isEmpty()) {
                pending.put(c, lookupByChangeKey(c, new Change.Key(idList.get(idList.size() - 1).trim())));
            } else {
                pending.put(c, lookupByCommit(c));
            }
            int n = pending.size() + newChanges.size();
            if (maxBatchChanges != 0 && n > maxBatchChanges) {
                logger.atFine().log("%d changes exceeds limit of %d", n, maxBatchChanges);
                reject(magicBranch.cmd, "the number of pushed changes in a batch exceeds the max limit " + maxBatchChanges);
                return Collections.emptyList();
            }
            if (commitAlreadyTracked) {
                boolean changeExistsOnDestBranch = false;
                for (ChangeData cd : pending.get(c).destChanges) {
                    if (cd.change().getDest().equals(magicBranch.dest)) {
                        changeExistsOnDestBranch = true;
                        break;
                    }
                }
                if (changeExistsOnDestBranch) {
                    continue;
                }
                logger.atFine().log("Creating new change for %s even though it is already tracked", name);
            }
            if (!validCommit(receivePack.getRevWalk().getObjectReader(), magicBranch.dest, magicBranch.cmd, c, magicBranch.merged, null)) {
                // Not a change the user can propose? Abort as early as possible.
                logger.atFine().log("Aborting early due to invalid commit");
                return Collections.emptyList();
            }
            // Don't allow merges to be uploaded in commit chain via all-not-in-target
            if (newChangeForAllNotInTarget && c.getParentCount() > 1) {
                reject(magicBranch.cmd, "Pushing merges in commit chains with 'all not in target' is not allowed,\n" + "to override please set the base manually");
                logger.atFine().log("Rejecting merge commit %s with newChangeForAllNotInTarget", name);
            // TODO(dborowitz): Should we early return here?
            }
            if (idList.isEmpty()) {
                newChanges.add(new CreateRequest(c, magicBranch.dest.get(), newProgress));
                continue;
            }
        }
        logger.atFine().log("Finished initial RevWalk with %d commits total: %d already" + " tracked, %d new changes with no Change-Id, and %d deferred" + " lookups", total, alreadyTracked, newChanges.size(), pending.size());
        if (rejectImplicitMerges) {
            rejectImplicitMerges(mergedParents);
        }
        for (Iterator<ChangeLookup> itr = pending.values().iterator(); itr.hasNext(); ) {
            ChangeLookup p = itr.next();
            if (p.changeKey == null) {
                continue;
            }
            if (newChangeIds.contains(p.changeKey)) {
                logger.atFine().log("Multiple commits with Change-Id %s", p.changeKey);
                reject(magicBranch.cmd, SAME_CHANGE_ID_IN_MULTIPLE_CHANGES);
                return Collections.emptyList();
            }
            List<ChangeData> changes = p.destChanges;
            if (changes.size() > 1) {
                logger.atFine().log("Multiple changes in branch %s with Change-Id %s: %s", magicBranch.dest, p.changeKey, changes.stream().map(cd -> cd.getId().toString()).collect(joining()));
                // WTF, multiple changes in this branch have the same key?
                // Since the commit is new, the user should recreate it with
                // a different Change-Id. In practice, we should never see
                // this error message as Change-Id should be unique per branch.
                // 
                reject(magicBranch.cmd, p.changeKey.get() + " has duplicates");
                return Collections.emptyList();
            }
            if (changes.size() == 1) {
                // Schedule as a replacement to this one matching change.
                // 
                RevId currentPs = changes.get(0).currentPatchSet().getRevision();
                // If Commit is already current PatchSet of target Change.
                if (p.commit.name().equals(currentPs.get())) {
                    if (pending.size() == 1) {
                        // There are no commits left to check, all commits in pending were already
                        // current PatchSet of the corresponding target changes.
                        reject(magicBranch.cmd, "commit(s) already exists (as current patchset)");
                    } else {
                        // Commit is already current PatchSet.
                        // Remove from pending and try next commit.
                        itr.remove();
                        continue;
                    }
                }
                if (requestReplace(magicBranch.cmd, false, changes.get(0).change(), p.commit)) {
                    continue;
                }
                return Collections.emptyList();
            }
            if (changes.size() == 0) {
                if (!isValidChangeId(p.changeKey.get())) {
                    reject(magicBranch.cmd, "invalid Change-Id");
                    return Collections.emptyList();
                }
                // double check against the existing refs
                if (foundInExistingRef(existing.get(p.commit))) {
                    if (pending.size() == 1) {
                        reject(magicBranch.cmd, "commit(s) already exists (as current patchset)");
                        return Collections.emptyList();
                    }
                    itr.remove();
                    continue;
                }
                newChangeIds.add(p.changeKey);
            }
            newChanges.add(new CreateRequest(p.commit, magicBranch.dest.get(), newProgress));
        }
        logger.atFine().log("Finished deferred lookups with %d updates and %d new changes", replaceByChange.size(), newChanges.size());
    } catch (IOException e) {
        // Should never happen, the core receive process would have
        // identified the missing object earlier before we got control.
        // 
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logger.atSevere().withCause(e).log("Invalid pack upload; one or more objects weren't sent");
        return Collections.emptyList();
    } catch (OrmException e) {
        logger.atSevere().withCause(e).log("Cannot query database to locate prior changes");
        reject(magicBranch.cmd, "database error");
        return Collections.emptyList();
    }
    if (newChanges.isEmpty() && replaceByChange.isEmpty()) {
        reject(magicBranch.cmd, "no new changes");
        return Collections.emptyList();
    }
    if (!newChanges.isEmpty() && magicBranch.edit) {
        reject(magicBranch.cmd, "edit is not supported for new changes");
        return newChanges;
    }
    try {
        SortedSetMultimap<ObjectId, String> groups = groupCollector.getGroups();
        List<Integer> newIds = seq.nextChangeIds(newChanges.size());
        for (int i = 0; i < newChanges.size(); i++) {
            CreateRequest create = newChanges.get(i);
            create.setChangeId(newIds.get(i));
            create.groups = ImmutableList.copyOf(groups.get(create.commit));
        }
        for (ReplaceRequest replace : replaceByChange.values()) {
            replace.groups = ImmutableList.copyOf(groups.get(replace.newCommitId));
        }
        for (UpdateGroupsRequest update : updateGroups) {
            update.groups = ImmutableList.copyOf((groups.get(update.commit)));
        }
        logger.atFine().log("Finished updating groups from GroupCollector");
    } catch (OrmException e) {
        logger.atSevere().withCause(e).log("Error collecting groups for changes");
        reject(magicBranch.cmd, "internal server error");
    }
    return newChanges;
}
#method_after
private List<CreateRequest> selectNewAndReplacedChangesFromMagicBranch(Task newProgress) {
    logger.atFine().log("Finding new and replaced changes");
    List<CreateRequest> newChanges = new ArrayList<>();
    ListMultimap<ObjectId, Ref> existing = changeRefsById();
    GroupCollector groupCollector = GroupCollector.create(changeRefsById(), db, psUtil, notesFactory, project.getNameKey());
    try {
        NoteMap rejectCommits = loadRejectCommits();
        RevCommit start = setUpWalkForSelectingChanges();
        if (start == null) {
            return Collections.emptyList();
        }
        LinkedHashMap<RevCommit, ChangeLookup> pending = new LinkedHashMap<>();
        Set<Change.Key> newChangeIds = new HashSet<>();
        int maxBatchChanges = receiveConfig.getEffectiveMaxBatchChangesLimit(user);
        int total = 0;
        int alreadyTracked = 0;
        boolean rejectImplicitMerges = start.getParentCount() == 1 && projectCache.get(project.getNameKey()).is(BooleanProjectConfig.REJECT_IMPLICIT_MERGES) && // late.
        !magicBranch.merged;
        Set<RevCommit> mergedParents;
        if (rejectImplicitMerges) {
            mergedParents = new HashSet<>();
        } else {
            mergedParents = null;
        }
        for (; ; ) {
            RevCommit c = receivePack.getRevWalk().next();
            if (c == null) {
                break;
            }
            total++;
            receivePack.getRevWalk().parseBody(c);
            String name = c.name();
            groupCollector.visit(c);
            Collection<Ref> existingRefs = existing.get(c);
            if (rejectImplicitMerges) {
                Collections.addAll(mergedParents, c.getParents());
                mergedParents.remove(c);
            }
            boolean commitAlreadyTracked = !existingRefs.isEmpty();
            if (commitAlreadyTracked) {
                alreadyTracked++;
                // different target branch.
                for (Ref ref : existingRefs) {
                    updateGroups.add(new UpdateGroupsRequest(ref, c));
                }
                if (!(newChangeForAllNotInTarget || magicBranch.base != null)) {
                    continue;
                }
            }
            List<String> idList = c.getFooterLines(CHANGE_ID);
            if (!idList.isEmpty()) {
                pending.put(c, lookupByChangeKey(c, new Change.Key(idList.get(idList.size() - 1).trim())));
            } else {
                pending.put(c, lookupByCommit(c));
            }
            int n = pending.size() + newChanges.size();
            if (maxBatchChanges != 0 && n > maxBatchChanges) {
                logger.atFine().log("%d changes exceeds limit of %d", n, maxBatchChanges);
                reject(magicBranch.cmd, "the number of pushed changes in a batch exceeds the max limit " + maxBatchChanges);
                return Collections.emptyList();
            }
            if (commitAlreadyTracked) {
                boolean changeExistsOnDestBranch = false;
                for (ChangeData cd : pending.get(c).destChanges) {
                    if (cd.change().getDest().equals(magicBranch.dest)) {
                        changeExistsOnDestBranch = true;
                        break;
                    }
                }
                if (changeExistsOnDestBranch) {
                    continue;
                }
                logger.atFine().log("Creating new change for %s even though it is already tracked", name);
            }
            if (!validCommit(receivePack.getRevWalk().getObjectReader(), magicBranch.dest, magicBranch.cmd, c, magicBranch.merged, null, loadRejectCommits())) {
                // Not a change the user can propose? Abort as early as possible.
                logger.atFine().log("Aborting early due to invalid commit");
                return Collections.emptyList();
            }
            // Don't allow merges to be uploaded in commit chain via all-not-in-target
            if (newChangeForAllNotInTarget && c.getParentCount() > 1) {
                reject(magicBranch.cmd, "Pushing merges in commit chains with 'all not in target' is not allowed,\n" + "to override please set the base manually");
                logger.atFine().log("Rejecting merge commit %s with newChangeForAllNotInTarget", name);
            // TODO(dborowitz): Should we early return here?
            }
            if (idList.isEmpty()) {
                newChanges.add(new CreateRequest(c, magicBranch.dest.get(), newProgress));
                continue;
            }
        }
        logger.atFine().log("Finished initial RevWalk with %d commits total: %d already" + " tracked, %d new changes with no Change-Id, and %d deferred" + " lookups", total, alreadyTracked, newChanges.size(), pending.size());
        if (rejectImplicitMerges) {
            rejectImplicitMerges(mergedParents);
        }
        for (Iterator<ChangeLookup> itr = pending.values().iterator(); itr.hasNext(); ) {
            ChangeLookup p = itr.next();
            if (p.changeKey == null) {
                continue;
            }
            if (newChangeIds.contains(p.changeKey)) {
                logger.atFine().log("Multiple commits with Change-Id %s", p.changeKey);
                reject(magicBranch.cmd, SAME_CHANGE_ID_IN_MULTIPLE_CHANGES);
                return Collections.emptyList();
            }
            List<ChangeData> changes = p.destChanges;
            if (changes.size() > 1) {
                logger.atFine().log("Multiple changes in branch %s with Change-Id %s: %s", magicBranch.dest, p.changeKey, changes.stream().map(cd -> cd.getId().toString()).collect(joining()));
                // WTF, multiple changes in this branch have the same key?
                // Since the commit is new, the user should recreate it with
                // a different Change-Id. In practice, we should never see
                // this error message as Change-Id should be unique per branch.
                // 
                reject(magicBranch.cmd, p.changeKey.get() + " has duplicates");
                return Collections.emptyList();
            }
            if (changes.size() == 1) {
                // Schedule as a replacement to this one matching change.
                // 
                RevId currentPs = changes.get(0).currentPatchSet().getRevision();
                // If Commit is already current PatchSet of target Change.
                if (p.commit.name().equals(currentPs.get())) {
                    if (pending.size() == 1) {
                        // There are no commits left to check, all commits in pending were already
                        // current PatchSet of the corresponding target changes.
                        reject(magicBranch.cmd, "commit(s) already exists (as current patchset)");
                    } else {
                        // Commit is already current PatchSet.
                        // Remove from pending and try next commit.
                        itr.remove();
                        continue;
                    }
                }
                if (requestReplace(magicBranch.cmd, false, changes.get(0).change(), p.commit)) {
                    continue;
                }
                return Collections.emptyList();
            }
            if (changes.size() == 0) {
                if (!isValidChangeId(p.changeKey.get())) {
                    reject(magicBranch.cmd, "invalid Change-Id");
                    return Collections.emptyList();
                }
                // double check against the existing refs
                if (foundInExistingRef(existing.get(p.commit))) {
                    if (pending.size() == 1) {
                        reject(magicBranch.cmd, "commit(s) already exists (as current patchset)");
                        return Collections.emptyList();
                    }
                    itr.remove();
                    continue;
                }
                newChangeIds.add(p.changeKey);
            }
            newChanges.add(new CreateRequest(p.commit, magicBranch.dest.get(), newProgress));
        }
        logger.atFine().log("Finished deferred lookups with %d updates and %d new changes", replaceByChange.size(), newChanges.size());
    } catch (IOException e) {
        // Should never happen, the core receive process would have
        // identified the missing object earlier before we got control.
        // 
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logger.atSevere().withCause(e).log("Invalid pack upload; one or more objects weren't sent");
        return Collections.emptyList();
    } catch (OrmException e) {
        logger.atSevere().withCause(e).log("Cannot query database to locate prior changes");
        reject(magicBranch.cmd, "database error");
        return Collections.emptyList();
    }
    if (newChanges.isEmpty() && replaceByChange.isEmpty()) {
        reject(magicBranch.cmd, "no new changes");
        return Collections.emptyList();
    }
    if (!newChanges.isEmpty() && magicBranch.edit) {
        reject(magicBranch.cmd, "edit is not supported for new changes");
        return newChanges;
    }
    try {
        SortedSetMultimap<ObjectId, String> groups = groupCollector.getGroups();
        List<Integer> newIds = seq.nextChangeIds(newChanges.size());
        for (int i = 0; i < newChanges.size(); i++) {
            CreateRequest create = newChanges.get(i);
            create.setChangeId(newIds.get(i));
            create.groups = ImmutableList.copyOf(groups.get(create.commit));
        }
        for (ReplaceRequest replace : replaceByChange.values()) {
            replace.groups = ImmutableList.copyOf(groups.get(replace.newCommitId));
        }
        for (UpdateGroupsRequest update : updateGroups) {
            update.groups = ImmutableList.copyOf((groups.get(update.commit)));
        }
        logger.atFine().log("Finished updating groups from GroupCollector");
    } catch (OrmException e) {
        logger.atSevere().withCause(e).log("Error collecting groups for changes");
        reject(magicBranch.cmd, "internal server error");
    }
    return newChanges;
}
#end_block

#method_before
private void validateRegularPushCommits(Branch.NameKey branch, ReceiveCommand cmd) throws PermissionBackendException {
    if (!RefNames.REFS_CONFIG.equals(cmd.getRefName()) && !(MagicBranch.isMagicBranch(cmd.getRefName()) || NEW_PATCHSET_PATTERN.matcher(cmd.getRefName()).matches()) && pushOptions.containsKey(PUSH_OPTION_SKIP_VALIDATION)) {
        if (projectState.is(BooleanProjectConfig.USE_SIGNED_OFF_BY)) {
            reject(cmd, "requireSignedOffBy prevents option " + PUSH_OPTION_SKIP_VALIDATION);
            return;
        }
        Optional<AuthException> err = checkRefPermission(permissions.ref(branch.get()), RefPermission.SKIP_VALIDATION);
        if (err.isPresent()) {
            rejectProhibited(cmd, err.get());
            return;
        }
        if (!Iterables.isEmpty(rejectCommits)) {
            reject(cmd, "reject-commits prevents " + PUSH_OPTION_SKIP_VALIDATION);
        }
        logger.atFine().log("Short-circuiting new commit validation");
        return;
    }
    boolean missingFullName = Strings.isNullOrEmpty(user.getAccount().getFullName());
    RevWalk walk = receivePack.getRevWalk();
    walk.reset();
    walk.sort(RevSort.NONE);
    try {
        RevObject parsedObject = walk.parseAny(cmd.getNewId());
        if (!(parsedObject instanceof RevCommit)) {
            return;
        }
        ListMultimap<ObjectId, Ref> existing = changeRefsById();
        walk.markStart((RevCommit) parsedObject);
        markHeadsAsUninteresting(walk, cmd.getRefName());
        int limit = receiveConfig.maxBatchCommits;
        int n = 0;
        for (RevCommit c; (c = walk.next()) != null; ) {
            if (++n > limit) {
                logger.atFine().log("Number of new commits exceeds limit of %d", limit);
                reject(cmd, String.format("more than %d commits, and %s not set", limit, PUSH_OPTION_SKIP_VALIDATION));
                return;
            }
            if (existing.keySet().contains(c)) {
                continue;
            }
            if (!validCommit(walk.getObjectReader(), branch, cmd, c, false, null)) {
                break;
            }
            if (missingFullName && user.hasEmailAddress(c.getCommitterIdent().getEmailAddress())) {
                logger.atFine().log("Will update full name of caller");
                setFullNameTo = c.getCommitterIdent().getName();
                missingFullName = false;
            }
        }
        logger.atFine().log("Validated %d new commits", n);
    } catch (IOException err) {
        cmd.setResult(REJECTED_MISSING_OBJECT);
        logger.atSevere().withCause(err).log("Invalid pack upload; one or more objects weren't sent");
    }
}
#method_after
private void validateRegularPushCommits(Branch.NameKey branch, ReceiveCommand cmd) throws PermissionBackendException {
    if (!RefNames.REFS_CONFIG.equals(cmd.getRefName()) && !(MagicBranch.isMagicBranch(cmd.getRefName()) || NEW_PATCHSET_PATTERN.matcher(cmd.getRefName()).matches()) && pushOptions.containsKey(PUSH_OPTION_SKIP_VALIDATION)) {
        if (projectState.is(BooleanProjectConfig.USE_SIGNED_OFF_BY)) {
            reject(cmd, "requireSignedOffBy prevents option " + PUSH_OPTION_SKIP_VALIDATION);
            return;
        }
        Optional<AuthException> err = checkRefPermission(permissions.ref(branch.get()), RefPermission.SKIP_VALIDATION);
        if (err.isPresent()) {
            rejectProhibited(cmd, err.get());
            return;
        }
        if (!Iterables.isEmpty(rejectCommits)) {
            reject(cmd, "reject-commits prevents " + PUSH_OPTION_SKIP_VALIDATION);
        }
        logger.atFine().log("Short-circuiting new commit validation");
        return;
    }
    boolean missingFullName = Strings.isNullOrEmpty(user.getAccount().getFullName());
    RevWalk walk = receivePack.getRevWalk();
    walk.reset();
    walk.sort(RevSort.NONE);
    try {
        NoteMap rejectCommits = loadRejectCommits();
        RevObject parsedObject = walk.parseAny(cmd.getNewId());
        if (!(parsedObject instanceof RevCommit)) {
            return;
        }
        ListMultimap<ObjectId, Ref> existing = changeRefsById();
        walk.markStart((RevCommit) parsedObject);
        markHeadsAsUninteresting(walk, cmd.getRefName());
        int limit = receiveConfig.maxBatchCommits;
        int n = 0;
        for (RevCommit c; (c = walk.next()) != null; ) {
            if (++n > limit) {
                logger.atFine().log("Number of new commits exceeds limit of %d", limit);
                reject(cmd, String.format("more than %d commits, and %s not set", limit, PUSH_OPTION_SKIP_VALIDATION));
                return;
            }
            if (existing.keySet().contains(c)) {
                continue;
            }
            if (!validCommit(walk.getObjectReader(), branch, cmd, c, false, null, rejectCommits)) {
                break;
            }
            if (missingFullName && user.hasEmailAddress(c.getCommitterIdent().getEmailAddress())) {
                logger.atFine().log("Will update full name of caller");
                setFullNameTo = c.getCommitterIdent().getName();
                missingFullName = false;
            }
        }
        logger.atFine().log("Validated %d new commits", n);
    } catch (IOException err) {
        cmd.setResult(REJECTED_MISSING_OBJECT);
        logger.atSevere().withCause(err).log("Invalid pack upload; one or more objects weren't sent");
    }
}
#end_block

#method_before
private boolean validCommit(ObjectReader objectReader, Branch.NameKey branch, ReceiveCommand cmd, RevCommit commit, boolean isMerged, @Nullable Change change) throws IOException {
    PermissionBackend.ForRef perm = permissions.ref(branch.get());
    ValidCommitKey key = new AutoValue_ReceiveCommits_ValidCommitKey(commit.copy(), branch);
    if (validCommits.contains(key)) {
        return true;
    }
    try (CommitReceivedEvent receiveEvent = new CommitReceivedEvent(cmd, project, branch.get(), objectReader, commit, user)) {
        CommitValidators validators;
        if (isMerged) {
            validators = commitValidatorsFactory.forMergedCommits(project.getNameKey(), perm, user.asIdentifiedUser());
        } else {
            NoteMap rejectCommits = BanCommit.loadRejectCommitsMap(repo, receiveEvent.revWalk);
            validators = commitValidatorsFactory.forReceiveCommits(perm, branch, user.asIdentifiedUser(), sshInfo, rejectCommits, receiveEvent.revWalk, change);
        }
        for (CommitValidationMessage m : validators.validate(receiveEvent)) {
            messages.add(new CommitValidationMessage(messageForCommit(commit, m.getMessage()), m.isError()));
        }
    } catch (CommitValidationException e) {
        logger.atFine().log("Commit validation failed on %s", commit.name());
        for (CommitValidationMessage m : e.getMessages()) {
            // TODO(hanwen): drop the non-error messages?
            messages.add(new CommitValidationMessage(messageForCommit(commit, m.getMessage()), m.isError()));
        }
        reject(cmd, messageForCommit(commit, e.getMessage()));
        return false;
    }
    validCommits.add(key);
    return true;
}
#method_after
private boolean validCommit(ObjectReader objectReader, Branch.NameKey branch, ReceiveCommand cmd, RevCommit commit, boolean isMerged, @Nullable Change change, NoteMap rejectCommits) throws IOException {
    PermissionBackend.ForRef perm = permissions.ref(branch.get());
    ValidCommitKey key = new AutoValue_ReceiveCommits_ValidCommitKey(commit.copy(), branch);
    if (validCommits.contains(key)) {
        return true;
    }
    try (CommitReceivedEvent receiveEvent = new CommitReceivedEvent(cmd, project, branch.get(), objectReader, commit, user)) {
        CommitValidators validators;
        if (isMerged) {
            validators = commitValidatorsFactory.forMergedCommits(project.getNameKey(), perm, user.asIdentifiedUser());
        } else {
            validators = commitValidatorsFactory.forReceiveCommits(perm, branch, user.asIdentifiedUser(), sshInfo, rejectCommits, receiveEvent.revWalk, change);
        }
        for (CommitValidationMessage m : validators.validate(receiveEvent)) {
            messages.add(new CommitValidationMessage(messageForCommit(commit, m.getMessage()), m.isError()));
        }
    } catch (CommitValidationException e) {
        logger.atFine().log("Commit validation failed on %s", commit.name());
        for (CommitValidationMessage m : e.getMessages()) {
            // TODO(hanwen): drop the non-error messages?
            messages.add(new CommitValidationMessage(messageForCommit(commit, m.getMessage()), m.isError()));
        }
        reject(cmd, messageForCommit(commit, e.getMessage()));
        return false;
    }
    validCommits.add(key);
    return true;
}
#end_block

#method_before
@Test
public void unsupportedVersion() throws Exception {
    exception.expect(ElasticVersion.InvalidVersion.class);
    exception.expectMessage("Invalid version: [4.0.0]. Supported versions: " + ElasticVersion.supportedVersions());
    ElasticVersion.forVersion("4.0.0");
}
#method_after
@Test
public void unsupportedVersion() throws Exception {
    exception.expect(ElasticVersion.UnsupportedVersion.class);
    exception.expectMessage("Unsupported version: [4.0.0]. Supported versions: " + ElasticVersion.supportedVersions());
    ElasticVersion.forVersion("4.0.0");
}
#end_block

#method_before
private void checkRequiresCapability(ViewData d) throws AuthException, PermissionBackendException {
    // Skip all checks for administrators
    if (globals.permissionBackend.user(globals.currentUser).testOrFalse(GlobalPermission.ADMINISTRATE_SERVER)) {
        return;
    }
    globals.permissionBackend.user(globals.currentUser).checkAny(GlobalPermission.fromAnnotation(d.pluginName, d.view.getClass()));
}
#method_after
private void checkRequiresCapability(ViewData d) throws AuthException, PermissionBackendException {
    try {
        globals.permissionBackend.user(globals.currentUser).check(GlobalPermission.ADMINISTRATE_SERVER);
    } catch (AuthException e) {
        // Skiping
        globals.permissionBackend.user(globals.currentUser).checkAny(GlobalPermission.fromAnnotation(d.pluginName, d.view.getClass()));
    }
}
#end_block

#method_before
@Override
public void init(FilterConfig config) throws ServletException {
    if (isPropertyInPluginConfig(Parameter.HTTP_TRANSFORM_PATTERN.getCode()) || isPropertyUndefined(config, Parameter.HTTP_TRANSFORM_PATTERN.getCode(), GLOBAL_HTTP_TRANSFORM_PATTERN)) {
        System.setProperty(GLOBAL_HTTP_TRANSFORM_PATTERN, getTransformPattern());
    }
    if (isPropertyInPluginConfig(Parameter.STORAGE_DIRECTORY.getCode()) || isPropertyUndefined(config, Parameter.STORAGE_DIRECTORY.getCode(), GLOBAL_STORAGE_DIR)) {
        System.setProperty(GLOBAL_STORAGE_DIR, getStorageDir());
    }
    super.init(config);
}
#method_after
@Override
public void init(FilterConfig config) throws ServletException {
    if (isPropertyInPluginConfig(HTTP_TRANSFORM_PATTERN) || isPropertyUndefined(config, HTTP_TRANSFORM_PATTERN, GLOBAL_HTTP_TRANSFORM_PATTERN)) {
        System.setProperty(GLOBAL_HTTP_TRANSFORM_PATTERN, getTransformPattern());
    }
    if (isPropertyInPluginConfig(STORAGE_DIR) || isPropertyUndefined(config, STORAGE_DIR, GLOBAL_STORAGE_DIR)) {
        System.setProperty(GLOBAL_STORAGE_DIR, getStorageDir());
    }
    super.init(config);
}
#end_block

#method_before
private String getTransformPattern() {
    return cfg.getString(Parameter.HTTP_TRANSFORM_PATTERN.getCode(), GERRIT_GROUPING);
}
#method_after
private String getTransformPattern() {
    return cfg.getString(HTTP_TRANSFORM_PATTERN, GERRIT_GROUPING);
}
#end_block

#method_before
private String getStorageDir() {
    // default to old path for javamelody storage-directory if it exists
    final Path tmp = Paths.get(System.getProperty("java.io.tmpdir")).resolve(JAVAMELODY_PREFIX);
    if (Files.isDirectory(tmp)) {
        log.warn("Javamelody data exists in 'tmp' [{}]. Configuration (if any) will be ignored.", tmp);
        return tmp.toString();
    }
    // plugin config has the highest priority
    Path storageDir = Optional.ofNullable(cfg.getString(Parameter.STORAGE_DIRECTORY.getCode())).map(Paths::get).orElse(defaultDataDir);
    if (!Files.isDirectory(storageDir)) {
        try {
            Files.createDirectories(storageDir);
        } catch (IOException e) {
            log.error("Creation of javamelody data dir [{}] failed.", storageDir, e);
            throw new RuntimeException(e);
        }
    }
    return storageDir.toString();
}
#method_after
private String getStorageDir() {
    // default to old path for javamelody storage-directory if it exists
    final Path tmp = Paths.get(System.getProperty("java.io.tmpdir")).resolve(JAVAMELODY_PREFIX);
    if (Files.isDirectory(tmp)) {
        log.warn("Javamelody data exists in 'tmp' [{}]. Configuration (if any) will be ignored.", tmp);
        return tmp.toString();
    }
    // plugin config has the highest priority
    Path storageDir = Optional.ofNullable(cfg.getString(STORAGE_DIR)).map(Paths::get).orElse(defaultDataDir);
    if (!Files.isDirectory(storageDir)) {
        try {
            Files.createDirectories(storageDir);
        } catch (IOException e) {
            log.error("Creation of javamelody data dir [{}] failed.", storageDir, e);
            throw new RuntimeException(e);
        }
    }
    return storageDir.toString();
}
#end_block

#method_before
boolean canMonitor(HttpServletRequest httpRequest) {
    if (httpRequest.getRequestURI().equals(getJavamelodyUrl(httpRequest))) {
        return capabilityChecker.canMonitor();
    }
    return true;
}
#method_after
boolean canMonitor(HttpServletRequest httpRequest) {
    if (httpRequest.getRequestURI().equals(getJavamelodyUrl(httpRequest))) {
        /* Exception when access to metrics for Prometheus using Bearer Token
         * without going through any Gerrit Authentication step.
         * Enable to access the Prometheus metrics ONLY and nothing else, skipping
         * any authentication and ACL check.
         */
        if (useBearerTokenForPrometheus && httpRequest.getHeader(AUTHORIZATION_HEADER) != null && FORMAT_PROMETHEUS.equals(HttpParameter.FORMAT.getParameterFrom(httpRequest))) {
            return canMonitorFromPrometheusUsingBearerToken(httpRequest);
        }
        return capabilityChecker.canMonitor();
    }
    return true;
}
#end_block

#method_before
private Optional<PluginInfo> getPluginArtifactInfo(String url) {
    Optional<SmartJson> buildExecution = tryGetJson(url + "/api/json");
    Optional<JsonArray> artifacts = buildExecution.map(json -> json.get("artifacts").get().getAsJsonArray());
    if (artifacts.orElse(new JsonArray()).size() == 0) {
        return Optional.empty();
    }
    Optional<SmartJson> artifactJson = artifacts.flatMap(a -> findArtifact(a, ".jar"));
    if (!artifactJson.isPresent()) {
        return Optional.empty();
    }
    String pluginPath = artifactJson.get().getString("relativePath");
    String[] pluginPathParts = pluginPath.split("/");
    String pluginName = isMavenBuild(pluginPathParts) ? fixPluginNameForMavenBuilds(pluginPathParts) : pluginNameOfJar(pluginPathParts);
    String pluginUrl = String.format("%s/artifact/%s", buildExecution.get().getString("url"), pluginPath);
    System.out.println(pluginUrl);
    Optional<String> pluginVersion = fetchArtifact(buildExecution.get(), artifacts.get(), ".jar-version");
    Optional<String> pluginDescription = fetchArtifactJson(buildExecution.get(), artifacts.get(), ".json").flatMap(json -> json.getOptionalString("description"));
    for (JsonElement elem : buildExecution.get().get("actions").get().getAsJsonArray()) {
        SmartJson elemJson = SmartJson.of(elem);
        Optional<SmartJson> lastBuildRevision = elemJson.getOptional("lastBuiltRevision");
        if (lastBuildRevision.isPresent()) {
            String sha1 = lastBuildRevision.get().getString("SHA1").substring(0, 8);
            return pluginVersion.map(version -> new PluginInfo(pluginName, pluginDescription.orElse(""), version, sha1, pluginUrl));
        }
    }
    return Optional.empty();
}
#method_after
private Optional<PluginInfo> getPluginArtifactInfo(String url) {
    Optional<SmartJson> buildExecution = tryGetJson(url + "/api/json");
    Optional<JsonArray> artifacts = buildExecution.map(json -> json.get("artifacts").get().getAsJsonArray());
    if (artifacts.orElse(new JsonArray()).size() == 0) {
        return Optional.empty();
    }
    Optional<SmartJson> artifactJson = artifacts.flatMap(a -> findArtifact(a, ".jar"));
    if (!artifactJson.isPresent()) {
        return Optional.empty();
    }
    String pluginPath = artifactJson.get().getString("relativePath");
    String[] pluginPathParts = pluginPath.split("/");
    String pluginName = isMavenBuild(pluginPathParts) ? fixPluginNameForMavenBuilds(pluginPathParts) : pluginNameOfJar(pluginPathParts);
    String pluginUrl = String.format("%s/artifact/%s", buildExecution.get().getString("url"), pluginPath);
    Optional<String> pluginVersion = fetchArtifact(buildExecution.get(), artifacts.get(), ".jar-version");
    Optional<String> pluginDescription = fetchArtifactJson(buildExecution.get(), artifacts.get(), ".json").flatMap(json -> json.getOptionalString("description"));
    for (JsonElement elem : buildExecution.get().get("actions").get().getAsJsonArray()) {
        SmartJson elemJson = SmartJson.of(elem);
        Optional<SmartJson> lastBuildRevision = elemJson.getOptional("lastBuiltRevision");
        if (lastBuildRevision.isPresent()) {
            String sha1 = lastBuildRevision.get().getString("SHA1").substring(0, 8);
            return pluginVersion.map(version -> new PluginInfo(pluginName, pluginDescription.orElse(""), version, sha1, pluginUrl));
        }
    }
    return Optional.empty();
}
#end_block

#method_before
private void renderPublished(DisplaySide forSide, JsArray<CommentInfo> in) {
    for (CommentInfo info : Natives.asList(in)) {
        DisplaySide side = displaySide(info, forSide);
        if (side != null) {
            CommentGroup group = group(side, info.line());
            PublishedBox box = new PublishedBox(group, commentLinkProcessor, getPatchSetIdFromSide(side), info);
            group.add(box);
            int start = Math.max(0, info.line() - 1);
            int end = info.range() != null ? Math.max(0, info.range().end_line() - 1) : start;
            box.setMark(host.diffTable.overview.comment(host.getCmFromSide(side), CodeMirror.pos(start), CodeMirror.pos(end)));
            published.put(info.id(), box);
        }
    }
}
#method_after
private void renderPublished(DisplaySide forSide, JsArray<CommentInfo> in) {
    for (CommentInfo info : Natives.asList(in)) {
        DisplaySide side = displaySide(info, forSide);
        if (side != null) {
            CommentGroup group = group(side, info.line());
            PublishedBox box = new PublishedBox(group, commentLinkProcessor, getPatchSetIdFromSide(side), info);
            group.add(box);
            box.setAnnotation(host.diffTable.scrollbar.comment(host.getCmFromSide(side), Math.max(0, info.line() - 1)));
            published.put(info.id(), box);
        }
    }
}
#end_block

#method_before
DraftBox addDraftBox(DisplaySide side, CommentInfo info) {
    CommentGroup group = group(side, info.line());
    DraftBox box = new DraftBox(group, commentLinkProcessor, getPatchSetIdFromSide(side), info, expandAll);
    if (info.in_reply_to() != null) {
        PublishedBox r = published.get(info.in_reply_to());
        if (r != null) {
            r.setReplyBox(box);
        }
    }
    group.add(box);
    int start = Math.max(0, info.line() - 1);
    int end = info.range() != null ? Math.max(0, info.range().end_line() - 1) : start;
    box.setMark(host.diffTable.overview.draft(host.getCmFromSide(side), CodeMirror.pos(start), CodeMirror.pos(end)));
    return box;
}
#method_after
DraftBox addDraftBox(DisplaySide side, CommentInfo info) {
    CommentGroup group = group(side, info.line());
    DraftBox box = new DraftBox(group, commentLinkProcessor, getPatchSetIdFromSide(side), info, expandAll);
    if (info.in_reply_to() != null) {
        PublishedBox r = published.get(info.in_reply_to());
        if (r != null) {
            r.setReplyBox(box);
        }
    }
    group.add(box);
    box.setAnnotation(host.diffTable.scrollbar.draft(host.getCmFromSide(side), Math.max(0, info.line() - 1)));
    return box;
}
#end_block

#method_before
private void addGutterTag(Region region, int startA, int startB) {
    if (region.a() == null) {
        sidePanel.insert(cmB, startB, region.b().length());
    } else if (region.b() == null) {
        sidePanel.delete(cmA, cmB, startA, region.a().length());
    } else {
        sidePanel.edit(cmB, startB, region.b().length());
    }
}
#method_after
private void addGutterTag(Region region, int startA, int startB) {
    if (region.a() == null) {
        scrollbar.insert(cmB, startB, region.b().length());
    } else if (region.b() == null) {
        scrollbar.delete(cmA, cmB, startA, region.a().length());
    } else {
        scrollbar.edit(cmB, startB, region.b().length());
    }
}
#end_block

#method_before
void at(LineCharacter from, LineCharacter to) {
    this.from = from;
    this.to = to;
}
#method_after
void at(int line) {
    at(CodeMirror.pos(line), CodeMirror.pos(line + 1));
}
#end_block

#method_before
private void display(final CommentsCollections comments) {
    setThemeStyles(prefs.theme().isDark());
    setShowTabs(prefs.showTabs());
    setShowIntraline(prefs.intralineDifference());
    if (prefs.showLineNumbers()) {
        diffTable.addStyleName(DiffTable.style.showLineNumbers());
    }
    cmA = newCM(diff.meta_a(), diff.text_a(), DisplaySide.A, diffTable.cmA);
    cmB = newCM(diff.meta_b(), diff.text_b(), DisplaySide.B, diffTable.cmB);
    chunkManager = new ChunkManager(this, cmA, cmB, diffTable.overview);
    skipManager = new SkipManager(this, commentManager);
    columnMarginA = DOM.createDiv();
    columnMarginB = DOM.createDiv();
    columnMarginA.setClassName(DiffTable.style.columnMargin());
    columnMarginB.setClassName(DiffTable.style.columnMargin());
    cmA.getMoverElement().appendChild(columnMarginA);
    cmB.getMoverElement().appendChild(columnMarginB);
    if (prefs.renderEntireFile() && !canEnableRenderEntireFile(prefs)) {
        // CodeMirror is too slow to layout an entire huge file.
        prefs.renderEntireFile(false);
    }
    operation(new Runnable() {

        @Override
        public void run() {
            // Estimate initial CM3 height, fixed up in onShowView.
            int height = Window.getClientHeight() - (Gerrit.getHeaderFooterHeight() + 18);
            cmA.setHeight(height);
            cmB.setHeight(height);
            render(diff);
            commentManager.render(comments, prefs.expandAllComments());
            skipManager.render(prefs.context(), diff);
        }
    });
    registerCmEvents(cmA);
    registerCmEvents(cmB);
    scrollSynchronizer = new ScrollSynchronizer(diffTable, cmA, cmB, chunkManager.getLineMapper());
    prefsAction = new PreferencesAction(this, prefs);
    header.init(prefsAction, getLinks(), diff.side_by_side_web_links());
    if (prefs.syntaxHighlighting() && fileSize.compareTo(FileSize.SMALL) > 0) {
        Scheduler.get().scheduleFixedDelay(new RepeatingCommand() {

            @Override
            public boolean execute() {
                if (prefs.syntaxHighlighting() && isAttached()) {
                    setSyntaxHighlighting(prefs.syntaxHighlighting());
                }
                return false;
            }
        }, 250);
    }
}
#method_after
private void display(final CommentsCollections comments) {
    setThemeStyles(prefs.theme().isDark());
    setShowTabs(prefs.showTabs());
    setShowIntraline(prefs.intralineDifference());
    if (prefs.showLineNumbers()) {
        diffTable.addStyleName(DiffTable.style.showLineNumbers());
    }
    cmA = newCM(diff.meta_a(), diff.text_a(), DisplaySide.A, diffTable.cmA);
    cmB = newCM(diff.meta_b(), diff.text_b(), DisplaySide.B, diffTable.cmB);
    chunkManager = new ChunkManager(this, cmA, cmB, diffTable.scrollbar);
    skipManager = new SkipManager(this, commentManager);
    columnMarginA = DOM.createDiv();
    columnMarginB = DOM.createDiv();
    columnMarginA.setClassName(DiffTable.style.columnMargin());
    columnMarginB.setClassName(DiffTable.style.columnMargin());
    cmA.getMoverElement().appendChild(columnMarginA);
    cmB.getMoverElement().appendChild(columnMarginB);
    if (prefs.renderEntireFile() && !canEnableRenderEntireFile(prefs)) {
        // CodeMirror is too slow to layout an entire huge file.
        prefs.renderEntireFile(false);
    }
    operation(new Runnable() {

        @Override
        public void run() {
            // Estimate initial CM3 height, fixed up in onShowView.
            int height = Window.getClientHeight() - (Gerrit.getHeaderFooterHeight() + 18);
            cmA.setHeight(height);
            cmB.setHeight(height);
            render(diff);
            commentManager.render(comments, prefs.expandAllComments());
            skipManager.render(prefs.context(), diff);
        }
    });
    registerCmEvents(cmA);
    registerCmEvents(cmB);
    scrollSynchronizer = new ScrollSynchronizer(diffTable, cmA, cmB, chunkManager.getLineMapper());
    prefsAction = new PreferencesAction(this, prefs);
    header.init(prefsAction, getLinks(), diff.side_by_side_web_links());
    if (prefs.syntaxHighlighting() && fileSize.compareTo(FileSize.SMALL) > 0) {
        Scheduler.get().scheduleFixedDelay(new RepeatingCommand() {

            @Override
            public boolean execute() {
                if (prefs.syntaxHighlighting() && isAttached()) {
                    setSyntaxHighlighting(prefs.syntaxHighlighting());
                }
                return false;
            }
        }, 250);
    }
}
#end_block

#method_before
void reloadDiffInfo() {
    final int id = ++reloadVersionId;
    DiffApi.diff(revision, path).base(base).wholeFile().intraline(prefs.intralineDifference()).ignoreWhitespace(prefs.ignoreWhitespace()).get(new GerritCallback<DiffInfo>() {

        @Override
        public void onSuccess(DiffInfo diffInfo) {
            if (id == reloadVersionId && isAttached()) {
                diff = diffInfo;
                operation(new Runnable() {

                    @Override
                    public void run() {
                        skipManager.removeAll();
                        chunkManager.reset();
                        diffTable.overview.clearDiffMarkers();
                        setShowIntraline(prefs.intralineDifference());
                        render(diff);
                        chunkManager.adjustPadding();
                        skipManager.render(prefs.context(), diff);
                    }
                });
            }
        }
    });
}
#method_after
void reloadDiffInfo() {
    final int id = ++reloadVersionId;
    DiffApi.diff(revision, path).base(base).wholeFile().intraline(prefs.intralineDifference()).ignoreWhitespace(prefs.ignoreWhitespace()).get(new GerritCallback<DiffInfo>() {

        @Override
        public void onSuccess(DiffInfo diffInfo) {
            if (id == reloadVersionId && isAttached()) {
                diff = diffInfo;
                operation(new Runnable() {

                    @Override
                    public void run() {
                        skipManager.removeAll();
                        chunkManager.reset();
                        diffTable.scrollbar.removeDiffAnnotations();
                        setShowIntraline(prefs.intralineDifference());
                        render(diff);
                        chunkManager.adjustPadding();
                        skipManager.render(prefs.context(), diff);
                    }
                });
            }
        }
    });
}
#end_block

#method_before
private void removeUI() {
    if (replyToBox != null) {
        replyToBox.unregisterReplyBox();
    }
    getCommentManager().setUnsaved(this, false);
    setRangeHighlight(false);
    clearRange();
    getMark().clear();
    getCommentGroup().remove(this);
    getCm().focus();
}
#method_after
private void removeUI() {
    if (replyToBox != null) {
        replyToBox.unregisterReplyBox();
    }
    getCommentManager().setUnsaved(this, false);
    setRangeHighlight(false);
    clearRange();
    getAnnotation().remove();
    getCommentGroup().remove(this);
    getCm().focus();
}
#end_block

#method_before
private void parseCommits(Collection<Ref> refs) throws IOException {
    if (commitToRef != null) {
        return;
    }
    commitToRef = LinkedListMultimap.create();
    for (Ref ref : refs) {
        final RevCommit commit;
        try {
            commit = rw.parseCommit(ref.getObjectId());
        } catch (IncorrectObjectTypeException notCommit) {
            // 
            continue;
        } catch (MissingObjectException notHere) {
            // Log the problem with this branch, but keep processing.
            // 
            logger.atWarning().log("Reference %s in %s points to dangling object %s", ref.getName(), repo.getDirectory(), ref.getObjectId());
            continue;
        }
        commitToRef.put(commit, ref.getName());
    }
    tipsByCommitTime = Lists.newArrayList(commitToRef.keySet());
    sortOlderFirst(tipsByCommitTime);
}
#method_after
private void parseCommits(Collection<Ref> refs) throws IOException {
    if (commitToRef != null) {
        return;
    }
    commitToRef = LinkedListMultimap.create();
    for (Ref ref : refs) {
        final RevCommit commit;
        try {
            commit = rw.parseCommit(ref.getObjectId());
        } catch (IncorrectObjectTypeException notCommit) {
            // 
            continue;
        } catch (MissingObjectException notHere) {
            // Log the problem with this branch, but keep processing.
            // 
            logger.atWarning().log("Reference %s in %s points to dangling object %s", ref.getName(), repo.getDirectory(), ref.getObjectId());
            continue;
        }
        commitToRef.put(commit, ref.getName());
    }
    tipsByCommitTime = commitToRef.keySet().stream().sorted(comparing(RevCommit::getCommitTime)).collect(toList());
}
#end_block

#method_before
@SuppressWarnings("unchecked")
private MimeType getMimeType(Set<MimeType> mimeTypes, String path) {
    try {
        mimeTypes.addAll(mimeUtil.getMimeTypes(path));
    } catch (MimeException e) {
        logger.atWarning().withCause(e).log("Unable to determine MIME type from path");
    }
    if (isUnknownType(mimeTypes)) {
        return MimeUtil2.UNKNOWN_MIME_TYPE;
    }
    return Collections.min(mimeTypes, comparing(this::getCorrectedMimeSpecificity).reversed());
}
#method_after
@SuppressWarnings("unchecked")
private MimeType getMimeType(Set<MimeType> mimeTypes, String path) {
    try {
        mimeTypes.addAll(mimeUtil.getMimeTypes(path));
    } catch (MimeException e) {
        logger.atWarning().withCause(e).log("Unable to determine MIME type from path");
    }
    if (isUnknownType(mimeTypes)) {
        return MimeUtil2.UNKNOWN_MIME_TYPE;
    }
    return Collections.max(mimeTypes, comparing(this::getCorrectedMimeSpecificity));
}
#end_block

#method_before
void insert(GroupInfo info) {
    Comparator<GroupInfo> c = new Comparator<GroupInfo>() {

        @Override
        public int compare(GroupInfo a, GroupInfo b) {
            int cmp = nullToEmpty(a.name()).compareTo(nullToEmpty(b.name()));
            if (cmp != 0) {
                return cmp;
            }
            return a.getGroupUUID().compareTo(b.getGroupUUID());
        }

        private String nullToEmpty(@Nullable String str) {
            return (str == null) ? "" : str;
        }
    };
    int insertPos = getInsertRow(c, info);
    if (insertPos >= 0) {
        table.insertRow(insertPos);
        applyDataRowStyle(insertPos);
        populate(insertPos, info);
    }
}
#method_after
void insert(GroupInfo info) {
    Comparator<GroupInfo> c = comparing((GroupInfo g) -> nullToEmpty(g.name())).thenComparing(GroupInfo::getGroupUUID);
    int insertPos = getInsertRow(c, info);
    if (insertPos >= 0) {
        table.insertRow(insertPos);
        applyDataRowStyle(insertPos);
        populate(insertPos, info);
    }
}
#end_block

#method_before
private ProcessBuilder newBuildProcess(Label label) throws IOException {
    Properties properties = GerritLauncher.loadBuildProperties(sourceRoot.resolve(".bazel_path"));
    String bazel = firstNonNull(properties.getProperty("bazel"), "bazel");
    List<String> cmd = new ArrayList<>();
    cmd.add(bazel);
    cmd.add("build");
    if (GerritLauncher.isJdk9OrLater()) {
        cmd.add("--host_java_toolchain=@bazel_tools//tools/jdk:toolchain_java9");
        cmd.add("--java_toolchain=@bazel_tools//tools/jdk:toolchain_java9");
    }
    cmd.add(label.fullName());
    ProcessBuilder proc = new ProcessBuilder(cmd);
    if (properties.containsKey("PATH")) {
        proc.environment().put("PATH", properties.getProperty("PATH"));
    }
    return proc;
}
#method_after
private ProcessBuilder newBuildProcess(Label label) throws IOException {
    Properties properties = GerritLauncher.loadBuildProperties(sourceRoot.resolve(".bazel_path"));
    String bazel = firstNonNull(properties.getProperty("bazel"), "bazel");
    List<String> cmd = new ArrayList<>();
    cmd.add(bazel);
    cmd.add("build");
    if (GerritLauncher.isJdk9OrLater()) {
        String v = GerritLauncher.getJdkVersionPostJdk8();
        cmd.add("--host_java_toolchain=@bazel_tools//tools/jdk:toolchain_java" + v);
        cmd.add("--java_toolchain=@bazel_tools//tools/jdk:toolchain_java" + v);
    }
    cmd.add(label.fullName());
    ProcessBuilder proc = new ProcessBuilder(cmd);
    if (properties.containsKey("PATH")) {
        proc.environment().put("PATH", properties.getProperty("PATH"));
    }
    return proc;
}
#end_block

#method_before
private static ClassLoader useDevClasspath() throws IOException {
    Path out = getDeveloperEclipseOut();
    List<URL> dirs = new ArrayList<>();
    dirs.add(out.resolve("classes").toUri().toURL());
    ClassLoader cl = GerritLauncher.class.getClassLoader();
    if (isJdk9OrLater()) {
        Path rootPath = resolveInSourceRoot(".");
        Properties properties = loadBuildProperties(rootPath.resolve(".bazel_path"));
        String outputBase = properties.getProperty("output_base");
        Path runtimeClasspath = rootPath.resolve("bazel-bin/tools/eclipse/main_classpath_collect.runtime_classpath");
        String prefix = rootPath.toString().substring(0, rootPath.toString().length() - 1);
        for (String f : Files.readAllLines(runtimeClasspath, UTF_8)) {
            URL url;
            if (f.startsWith("external")) {
                url = new URL("file:" + outputBase + "/" + f);
            } else {
                url = new URL("file:" + prefix + f);
            }
            if (includeJar(url)) {
                dirs.add(url);
            }
        }
    } else {
        for (URL u : ((URLClassLoader) cl).getURLs()) {
            if (includeJar(u)) {
                dirs.add(u);
            }
        }
    }
    return URLClassLoader.newInstance(dirs.toArray(new URL[dirs.size()]), ClassLoader.getSystemClassLoader().getParent());
}
#method_after
private static ClassLoader useDevClasspath() throws IOException {
    Path out = getDeveloperEclipseOut();
    List<URL> dirs = new ArrayList<>();
    dirs.add(out.resolve("classes").toUri().toURL());
    ClassLoader cl = GerritLauncher.class.getClassLoader();
    if (isJdk9OrLater()) {
        Path rootPath = resolveInSourceRoot(".").normalize();
        Properties properties = loadBuildProperties(rootPath.resolve(".bazel_path"));
        Path outputBase = Paths.get(properties.getProperty("output_base"));
        Path runtimeClasspath = rootPath.resolve("bazel-bin/tools/eclipse/main_classpath_collect.runtime_classpath");
        for (String f : Files.readAllLines(runtimeClasspath, UTF_8)) {
            URL url;
            if (f.startsWith("external")) {
                url = outputBase.resolve(f).toUri().toURL();
            } else {
                url = rootPath.resolve(f).toUri().toURL();
            }
            if (includeJar(url)) {
                dirs.add(url);
            }
        }
    } else {
        for (URL u : ((URLClassLoader) cl).getURLs()) {
            if (includeJar(u)) {
                dirs.add(u);
            }
        }
    }
    return URLClassLoader.newInstance(dirs.toArray(new URL[dirs.size()]), ClassLoader.getSystemClassLoader().getParent());
}
#end_block

#method_before
private static boolean includeJar(URL u) {
    String path = u.getPath();
    return path.endsWith(".jar") && !path.endsWith("-src.jar");
}
#method_after
private static boolean includeJar(URL u) {
    String path = u.getPath();
    return path.endsWith(".jar") && !path.endsWith("-src.jar") && !path.contains("/com/google/gerrit");
}
#end_block

#method_before
private void processCommandsUnsafe(Collection<ReceiveCommand> commands, MultiProgressMonitor progress) {
    parsePushOptions();
    try (TraceContext traceContext = TraceContext.open().addTag(RequestId.Type.RECEIVE_ID, RequestId.forProject(project.getNameKey()))) {
        if (tracePushOption.orElse(false)) {
            RequestId traceId = new RequestId();
            traceContext.forceLogging().addTag(RequestId.Type.TRACE_ID, traceId);
            addMessage(RequestId.Type.TRACE_ID.name() + ": " + traceId);
            logger.atFine().log("push options: %s", receivePack.getPushOptions());
        }
        try {
            if (!projectState.getProject().getState().permitsWrite()) {
                for (ReceiveCommand cmd : commands) {
                    reject(cmd, "prohibited by Gerrit: project state does not permit write");
                }
                return;
            }
            logger.atFine().log("Parsing %d commands", commands.size());
            List<ReceiveCommand> magicCommands = new ArrayList<>();
            List<ReceiveCommand> directPatchSetPushCommands = new ArrayList<>();
            List<ReceiveCommand> regularCommands = new ArrayList<>();
            for (ReceiveCommand cmd : commands) {
                if (MagicBranch.isMagicBranch(cmd.getRefName())) {
                    magicCommands.add(cmd);
                } else if (isDirectChangesPush(cmd.getRefName())) {
                    directPatchSetPushCommands.add(cmd);
                } else {
                    regularCommands.add(cmd);
                }
            }
            int commandTypes = (magicCommands.isEmpty() ? 0 : 1) + (directPatchSetPushCommands.isEmpty() ? 0 : 1) + (regularCommands.isEmpty() ? 0 : 1);
            if (commandTypes > 1) {
                for (ReceiveCommand cmd : commands) {
                    if (cmd.getResult() == NOT_ATTEMPTED) {
                        cmd.setResult(REJECTED_OTHER_REASON, "cannot combine normal pushes and magic pushes");
                    }
                }
                return;
            }
            if (!regularCommands.isEmpty()) {
                handleRegularCommands(regularCommands, progress);
                return;
            }
            for (ReceiveCommand cmd : directPatchSetPushCommands) {
                parseDirectChangesPush(cmd);
            }
            boolean first = true;
            for (ReceiveCommand cmd : magicCommands) {
                if (first) {
                    parseMagicBranch(cmd);
                    first = false;
                } else {
                    reject(cmd, "duplicate request");
                }
            }
        } catch (PermissionBackendException | NoSuchProjectException | IOException err) {
            logger.atSevere().withCause(err).log("Failed to process refs in %s", project.getName());
            return;
        }
        Task newProgress = progress.beginSubTask("new", UNKNOWN);
        Task replaceProgress = progress.beginSubTask("updated", UNKNOWN);
        List<CreateRequest> newChanges = Collections.emptyList();
        if (magicBranch != null && magicBranch.cmd.getResult() == NOT_ATTEMPTED) {
            newChanges = selectNewAndReplacedChangesFromMagicBranch(newProgress);
        }
        preparePatchSetsForReplace(newChanges);
        insertChangesAndPatchSets(newChanges, replaceProgress);
        newProgress.end();
        replaceProgress.end();
        queueSuccessMessages(newChanges);
        refsPublishDeprecationWarning();
    }
}
#method_after
private void processCommandsUnsafe(Collection<ReceiveCommand> commands, MultiProgressMonitor progress) {
    parsePushOptions();
    try (TraceContext traceContext = TraceContext.newTrace(tracePushOption.isPresent(), tracePushOption.orElse(null), (tagName, traceId) -> addMessage(tagName + ": " + traceId))) {
        traceContext.addTag(RequestId.Type.RECEIVE_ID, RequestId.forProject(project.getNameKey()));
        // Log the push options here, rather than in parsePushOptions(), so that they are included
        // into the trace if tracing is enabled.
        logger.atFine().log("push options: %s", receivePack.getPushOptions());
        try {
            if (!projectState.getProject().getState().permitsWrite()) {
                for (ReceiveCommand cmd : commands) {
                    reject(cmd, "prohibited by Gerrit: project state does not permit write");
                }
                return;
            }
            logger.atFine().log("Parsing %d commands", commands.size());
            List<ReceiveCommand> magicCommands = new ArrayList<>();
            List<ReceiveCommand> directPatchSetPushCommands = new ArrayList<>();
            List<ReceiveCommand> regularCommands = new ArrayList<>();
            for (ReceiveCommand cmd : commands) {
                if (MagicBranch.isMagicBranch(cmd.getRefName())) {
                    magicCommands.add(cmd);
                } else if (isDirectChangesPush(cmd.getRefName())) {
                    directPatchSetPushCommands.add(cmd);
                } else {
                    regularCommands.add(cmd);
                }
            }
            int commandTypes = (magicCommands.isEmpty() ? 0 : 1) + (directPatchSetPushCommands.isEmpty() ? 0 : 1) + (regularCommands.isEmpty() ? 0 : 1);
            if (commandTypes > 1) {
                for (ReceiveCommand cmd : commands) {
                    if (cmd.getResult() == NOT_ATTEMPTED) {
                        cmd.setResult(REJECTED_OTHER_REASON, "cannot combine normal pushes and magic pushes");
                    }
                }
                return;
            }
            if (!regularCommands.isEmpty()) {
                handleRegularCommands(regularCommands, progress);
                return;
            }
            for (ReceiveCommand cmd : directPatchSetPushCommands) {
                parseDirectChangesPush(cmd);
            }
            boolean first = true;
            for (ReceiveCommand cmd : magicCommands) {
                if (first) {
                    parseMagicBranch(cmd);
                    first = false;
                } else {
                    reject(cmd, "duplicate request");
                }
            }
        } catch (PermissionBackendException | NoSuchProjectException | IOException err) {
            logger.atSevere().withCause(err).log("Failed to process refs in %s", project.getName());
            return;
        }
        Task newProgress = progress.beginSubTask("new", UNKNOWN);
        Task replaceProgress = progress.beginSubTask("updated", UNKNOWN);
        List<CreateRequest> newChanges = Collections.emptyList();
        if (magicBranch != null && magicBranch.cmd.getResult() == NOT_ATTEMPTED) {
            newChanges = selectNewAndReplacedChangesFromMagicBranch(newProgress);
        }
        // Commit validation has already happened, so any changes without Change-Id are for the
        // deprecated feature.
        warnAboutMissingChangeId(newChanges);
        preparePatchSetsForReplace(newChanges);
        insertChangesAndPatchSets(newChanges, replaceProgress);
        newProgress.end();
        replaceProgress.end();
        queueSuccessMessages(newChanges);
        refsPublishDeprecationWarning();
    }
}
#end_block

#method_before
private void parsePushOptions() {
    List<String> optionList = receivePack.getPushOptions();
    if (optionList != null) {
        for (String option : optionList) {
            int e = option.indexOf('=');
            if (e > 0) {
                pushOptions.put(option.substring(0, e), option.substring(e + 1));
            } else {
                pushOptions.put(option, "");
            }
        }
    }
    List<String> noteDbValues = pushOptions.get("notedb");
    if (!noteDbValues.isEmpty()) {
        // These semantics for duplicates/errors are somewhat arbitrary and may not match e.g. the
        // CommandLineParser behavior used by MagicBranchInput.
        String value = noteDbValues.get(noteDbValues.size() - 1);
        noteDbPushOption = NoteDbPushOption.parse(value);
        if (!noteDbPushOption.isPresent()) {
            addError("Invalid value in -o " + NoteDbPushOption.OPTION_NAME + "=" + value);
        }
    } else {
        noteDbPushOption = Optional.of(NoteDbPushOption.DISALLOW);
    }
    List<String> traceValues = pushOptions.get("trace");
    if (!traceValues.isEmpty()) {
        String value = traceValues.get(traceValues.size() - 1);
        tracePushOption = Optional.of(value.isEmpty() || Boolean.parseBoolean(value));
    } else {
        tracePushOption = Optional.empty();
    }
}
#method_after
private void parsePushOptions() {
    List<String> optionList = receivePack.getPushOptions();
    if (optionList != null) {
        for (String option : optionList) {
            int e = option.indexOf('=');
            if (e > 0) {
                pushOptions.put(option.substring(0, e), option.substring(e + 1));
            } else {
                pushOptions.put(option, "");
            }
        }
    }
    List<String> noteDbValues = pushOptions.get("notedb");
    if (!noteDbValues.isEmpty()) {
        // These semantics for duplicates/errors are somewhat arbitrary and may not match e.g. the
        // CmdLineParser behavior used by MagicBranchInput.
        String value = noteDbValues.get(noteDbValues.size() - 1);
        noteDbPushOption = NoteDbPushOption.parse(value);
        if (!noteDbPushOption.isPresent()) {
            addError("Invalid value in -o " + NoteDbPushOption.OPTION_NAME + "=" + value);
        }
    } else {
        noteDbPushOption = Optional.of(NoteDbPushOption.DISALLOW);
    }
    List<String> traceValues = pushOptions.get("trace");
    if (!traceValues.isEmpty()) {
        String value = traceValues.get(traceValues.size() - 1);
        tracePushOption = Optional.of(value);
    } else {
        tracePushOption = Optional.empty();
    }
}
#end_block

#method_before
private void parseDirectChangesPush(ReceiveCommand cmd) {
    Matcher m = NEW_PATCHSET_PATTERN.matcher(cmd.getRefName());
    checkArgument(m.matches());
    if (allowPushToRefsChanges) {
        // The referenced change must exist and must still be open.
        Change.Id changeId = Change.Id.parse(m.group(1));
        parseReplaceCommand(cmd, changeId);
    } else {
        reject(cmd, "upload to refs/changes not allowed");
    }
}
#method_after
private void parseDirectChangesPush(ReceiveCommand cmd) {
    Matcher m = NEW_PATCHSET_PATTERN.matcher(cmd.getRefName());
    checkArgument(m.matches());
    if (allowPushToRefsChanges) {
        // The referenced change must exist and must still be open.
        Change.Id changeId = Change.Id.parse(m.group(1));
        parseReplaceCommand(cmd, changeId);
        messages.add(new ValidationMessage("warning: pushes to refs/changes are deprecated", false));
    } else {
        reject(cmd, "upload to refs/changes not allowed");
    }
}
#end_block

#method_before
private void parseRegularCommand(ReceiveCommand cmd) throws PermissionBackendException, NoSuchProjectException, IOException {
    if (cmd.getResult() != NOT_ATTEMPTED) {
        // Already rejected by the core receive process.
        logger.atFine().log("Already processed by core: %s %s", cmd.getResult(), cmd);
        return;
    }
    if (!Repository.isValidRefName(cmd.getRefName()) || cmd.getRefName().contains("//")) {
        reject(cmd, "not valid ref");
        return;
    }
    if (RefNames.isNoteDbMetaRef(cmd.getRefName())) {
        // Reject pushes to NoteDb refs without a special option and permission. Note that this
        // prohibition doesn't depend on NoteDb being enabled in any way, since all sites will
        // migrate to NoteDb eventually, and we don't want garbage data waiting there when the
        // migration finishes.
        logger.atFine().log("%s NoteDb ref %s with %s=%s", cmd.getType(), cmd.getRefName(), NoteDbPushOption.OPTION_NAME, noteDbPushOption);
        if (!Optional.of(NoteDbPushOption.ALLOW).equals(noteDbPushOption)) {
            // Only reject this command, not the whole push. This supports the use case of "git clone
            // --mirror" followed by "git push --mirror", when the user doesn't really intend to clone
            // or mirror the NoteDb data; there is no single refspec that describes all refs *except*
            // NoteDb refs.
            reject(cmd, "NoteDb update requires -o " + NoteDbPushOption.OPTION_NAME + "=" + NoteDbPushOption.ALLOW.value());
            return;
        }
        try {
            permissionBackend.user(user).check(GlobalPermission.ACCESS_DATABASE);
        } catch (AuthException e) {
            reject(cmd, "NoteDb update requires access database permission");
            return;
        }
    }
    switch(cmd.getType()) {
        case CREATE:
            parseCreate(cmd);
            break;
        case UPDATE:
            parseUpdate(cmd);
            break;
        case DELETE:
            parseDelete(cmd);
            break;
        case UPDATE_NONFASTFORWARD:
            parseRewind(cmd);
            break;
        default:
            reject(cmd, "prohibited by Gerrit: unknown command type " + cmd.getType());
            return;
    }
    if (cmd.getResult() != NOT_ATTEMPTED) {
        return;
    }
    if (isConfig(cmd)) {
        logger.atFine().log("Processing %s command", cmd.getRefName());
        try {
            permissions.check(ProjectPermission.WRITE_CONFIG);
        } catch (AuthException e) {
            reject(cmd, String.format("must be either project owner or have %s permission", ProjectPermission.WRITE_CONFIG.describeForException()));
            return;
        }
        switch(cmd.getType()) {
            case CREATE:
            case UPDATE:
            case UPDATE_NONFASTFORWARD:
                try {
                    ProjectConfig cfg = new ProjectConfig(project.getNameKey());
                    cfg.load(project.getNameKey(), receivePack.getRevWalk(), cmd.getNewId());
                    if (!cfg.getValidationErrors().isEmpty()) {
                        addError("Invalid project configuration:");
                        for (ValidationError err : cfg.getValidationErrors()) {
                            addError("  " + err.getMessage());
                        }
                        reject(cmd, "invalid project configuration");
                        logger.atSevere().log("User %s tried to push invalid project configuration %s for %s", user.getLoggableName(), cmd.getNewId().name(), project.getName());
                        return;
                    }
                    Project.NameKey newParent = cfg.getProject().getParent(allProjectsName);
                    Project.NameKey oldParent = project.getParent(allProjectsName);
                    if (oldParent == null) {
                        // update of the 'All-Projects' project
                        if (newParent != null) {
                            reject(cmd, "invalid project configuration: root project cannot have parent");
                            return;
                        }
                    } else {
                        if (!oldParent.equals(newParent)) {
                            try {
                                permissionBackend.user(user).check(GlobalPermission.ADMINISTRATE_SERVER);
                            } catch (AuthException e) {
                                reject(cmd, "invalid project configuration: only Gerrit admin can set parent");
                                return;
                            }
                        }
                        if (projectCache.get(newParent) == null) {
                            reject(cmd, "invalid project configuration: parent does not exist");
                            return;
                        }
                    }
                    for (Entry<ProjectConfigEntry> e : pluginConfigEntries) {
                        PluginConfig pluginCfg = cfg.getPluginConfig(e.getPluginName());
                        ProjectConfigEntry configEntry = e.getProvider().get();
                        String value = pluginCfg.getString(e.getExportName());
                        String oldValue = projectState.getConfig().getPluginConfig(e.getPluginName()).getString(e.getExportName());
                        if (configEntry.getType() == ProjectConfigEntryType.ARRAY) {
                            oldValue = Arrays.stream(projectState.getConfig().getPluginConfig(e.getPluginName()).getStringList(e.getExportName())).collect(joining("\n"));
                        }
                        if ((value == null ? oldValue != null : !value.equals(oldValue)) && !configEntry.isEditable(projectState)) {
                            reject(cmd, String.format("invalid project configuration: Not allowed to set parameter" + " '%s' of plugin '%s' on project '%s'.", e.getExportName(), e.getPluginName(), project.getName()));
                            continue;
                        }
                        if (ProjectConfigEntryType.LIST.equals(configEntry.getType()) && value != null && !configEntry.getPermittedValues().contains(value)) {
                            reject(cmd, String.format("invalid project configuration: The value '%s' is " + "not permitted for parameter '%s' of plugin '%s'.", value, e.getExportName(), e.getPluginName()));
                        }
                    }
                } catch (Exception e) {
                    reject(cmd, "invalid project configuration");
                    logger.atSevere().withCause(e).log("User %s tried to push invalid project configuration %s for %s", user.getLoggableName(), cmd.getNewId().name(), project.getName());
                    return;
                }
                break;
            case DELETE:
                break;
            default:
                reject(cmd, "prohibited by Gerrit: don't know how to handle config update of type " + cmd.getType());
        }
    }
}
#method_after
private void parseRegularCommand(ReceiveCommand cmd) throws PermissionBackendException, NoSuchProjectException, IOException {
    if (cmd.getResult() != NOT_ATTEMPTED) {
        // Already rejected by the core receive process.
        logger.atFine().log("Already processed by core: %s %s", cmd.getResult(), cmd);
        return;
    }
    if (!Repository.isValidRefName(cmd.getRefName()) || cmd.getRefName().contains("//")) {
        reject(cmd, "not valid ref");
        return;
    }
    if (RefNames.isNoteDbMetaRef(cmd.getRefName())) {
        // Reject pushes to NoteDb refs without a special option and permission. Note that this
        // prohibition doesn't depend on NoteDb being enabled in any way, since all sites will
        // migrate to NoteDb eventually, and we don't want garbage data waiting there when the
        // migration finishes.
        logger.atFine().log("%s NoteDb ref %s with %s=%s", cmd.getType(), cmd.getRefName(), NoteDbPushOption.OPTION_NAME, noteDbPushOption);
        if (!Optional.of(NoteDbPushOption.ALLOW).equals(noteDbPushOption)) {
            // Only reject this command, not the whole push. This supports the use case of "git clone
            // --mirror" followed by "git push --mirror", when the user doesn't really intend to clone
            // or mirror the NoteDb data; there is no single refspec that describes all refs *except*
            // NoteDb refs.
            reject(cmd, "NoteDb update requires -o " + NoteDbPushOption.OPTION_NAME + "=" + NoteDbPushOption.ALLOW.value());
            return;
        }
        try {
            permissionBackend.user(user).check(GlobalPermission.ACCESS_DATABASE);
        } catch (AuthException e) {
            reject(cmd, "NoteDb update requires access database permission");
            return;
        }
    }
    switch(cmd.getType()) {
        case CREATE:
            parseCreate(cmd);
            break;
        case UPDATE:
            parseUpdate(cmd);
            break;
        case DELETE:
            parseDelete(cmd);
            break;
        case UPDATE_NONFASTFORWARD:
            parseRewind(cmd);
            break;
        default:
            reject(cmd, "prohibited by Gerrit: unknown command type " + cmd.getType());
            return;
    }
    if (cmd.getResult() != NOT_ATTEMPTED) {
        return;
    }
    if (isConfig(cmd)) {
        logger.atFine().log("Processing %s command", cmd.getRefName());
        try {
            permissions.check(ProjectPermission.WRITE_CONFIG);
        } catch (AuthException e) {
            reject(cmd, String.format("must be either project owner or have %s permission", ProjectPermission.WRITE_CONFIG.describeForException()));
            return;
        }
        switch(cmd.getType()) {
            case CREATE:
            case UPDATE:
            case UPDATE_NONFASTFORWARD:
                try {
                    ProjectConfig cfg = new ProjectConfig(project.getNameKey());
                    cfg.load(project.getNameKey(), receivePack.getRevWalk(), cmd.getNewId());
                    if (!cfg.getValidationErrors().isEmpty()) {
                        addError("Invalid project configuration:");
                        for (ValidationError err : cfg.getValidationErrors()) {
                            addError("  " + err.getMessage());
                        }
                        reject(cmd, "invalid project configuration");
                        logger.atSevere().log("User %s tried to push invalid project configuration %s for %s", user.getLoggableName(), cmd.getNewId().name(), project.getName());
                        return;
                    }
                    Project.NameKey newParent = cfg.getProject().getParent(allProjectsName);
                    Project.NameKey oldParent = project.getParent(allProjectsName);
                    if (oldParent == null) {
                        // update of the 'All-Projects' project
                        if (newParent != null) {
                            reject(cmd, "invalid project configuration: root project cannot have parent");
                            return;
                        }
                    } else {
                        if (!oldParent.equals(newParent)) {
                            if (allowProjectOwnersToChangeParent) {
                                try {
                                    permissionBackend.user(user).project(project.getNameKey()).check(ProjectPermission.WRITE_CONFIG);
                                } catch (AuthException e) {
                                    reject(cmd, "invalid project configuration: only project owners can set parent");
                                    return;
                                }
                            } else {
                                try {
                                    permissionBackend.user(user).check(GlobalPermission.ADMINISTRATE_SERVER);
                                } catch (AuthException e) {
                                    reject(cmd, "invalid project configuration: only Gerrit admin can set parent");
                                    return;
                                }
                            }
                        }
                        if (projectCache.get(newParent) == null) {
                            reject(cmd, "invalid project configuration: parent does not exist");
                            return;
                        }
                    }
                    for (Entry<ProjectConfigEntry> e : pluginConfigEntries) {
                        PluginConfig pluginCfg = cfg.getPluginConfig(e.getPluginName());
                        ProjectConfigEntry configEntry = e.getProvider().get();
                        String value = pluginCfg.getString(e.getExportName());
                        String oldValue = projectState.getConfig().getPluginConfig(e.getPluginName()).getString(e.getExportName());
                        if (configEntry.getType() == ProjectConfigEntryType.ARRAY) {
                            oldValue = Arrays.stream(projectState.getConfig().getPluginConfig(e.getPluginName()).getStringList(e.getExportName())).collect(joining("\n"));
                        }
                        if ((value == null ? oldValue != null : !value.equals(oldValue)) && !configEntry.isEditable(projectState)) {
                            reject(cmd, String.format("invalid project configuration: Not allowed to set parameter" + " '%s' of plugin '%s' on project '%s'.", e.getExportName(), e.getPluginName(), project.getName()));
                            continue;
                        }
                        if (ProjectConfigEntryType.LIST.equals(configEntry.getType()) && value != null && !configEntry.getPermittedValues().contains(value)) {
                            reject(cmd, String.format("invalid project configuration: The value '%s' is " + "not permitted for parameter '%s' of plugin '%s'.", value, e.getExportName(), e.getPluginName()));
                        }
                    }
                } catch (Exception e) {
                    reject(cmd, "invalid project configuration");
                    logger.atSevere().withCause(e).log("User %s tried to push invalid project configuration %s for %s", user.getLoggableName(), cmd.getNewId().name(), project.getName());
                    return;
                }
                break;
            case DELETE:
                break;
            default:
                reject(cmd, "prohibited by Gerrit: don't know how to handle config update of type " + cmd.getType());
        }
    }
}
#end_block

#method_before
private boolean validCommit(ObjectReader objectReader, Branch.NameKey branch, ReceiveCommand cmd, RevCommit commit, boolean isMerged, @Nullable Change change) throws IOException {
    PermissionBackend.ForRef perm = permissions.ref(branch.get());
    ValidCommitKey key = new AutoValue_ReceiveCommits_ValidCommitKey(commit.copy(), branch);
    if (validCommits.contains(key)) {
        return true;
    }
    try (CommitReceivedEvent receiveEvent = new CommitReceivedEvent(cmd, project, branch.get(), objectReader, commit, user)) {
        CommitValidators validators = isMerged ? commitValidatorsFactory.forMergedCommits(project.getNameKey(), perm, user.asIdentifiedUser()) : commitValidatorsFactory.forReceiveCommits(perm, branch, user.asIdentifiedUser(), sshInfo, repo, receiveEvent.revWalk, change);
        messages.addAll(validators.validate(receiveEvent));
    } catch (CommitValidationException e) {
        logger.atFine().log("Commit validation failed on %s", commit.name());
        messages.addAll(e.getMessages());
        reject(cmd, e.getMessage());
        return false;
    }
    validCommits.add(key);
    return true;
}
#method_after
private boolean validCommit(ObjectReader objectReader, Branch.NameKey branch, ReceiveCommand cmd, RevCommit commit, boolean isMerged, @Nullable Change change) throws IOException {
    PermissionBackend.ForRef perm = permissions.ref(branch.get());
    ValidCommitKey key = new AutoValue_ReceiveCommits_ValidCommitKey(commit.copy(), branch);
    if (validCommits.contains(key)) {
        return true;
    }
    try (CommitReceivedEvent receiveEvent = new CommitReceivedEvent(cmd, project, branch.get(), objectReader, commit, user)) {
        CommitValidators validators = isMerged ? commitValidatorsFactory.forMergedCommits(project.getNameKey(), perm, user.asIdentifiedUser()) : commitValidatorsFactory.forReceiveCommits(perm, branch, user.asIdentifiedUser(), sshInfo, repo, receiveEvent.revWalk, change);
        for (CommitValidationMessage m : validators.validate(receiveEvent)) {
            messages.add(new CommitValidationMessage(messageForCommit(commit, m.getMessage()), m.isError()));
        }
    } catch (CommitValidationException e) {
        logger.atFine().log("Commit validation failed on %s", commit.name());
        for (CommitValidationMessage m : e.getMessages()) {
            // TODO(hanwen): drop the non-error messages?
            messages.add(new CommitValidationMessage(messageForCommit(commit, m.getMessage()), m.isError()));
        }
        reject(cmd, messageForCommit(commit, e.getMessage()));
        return false;
    }
    validCommits.add(key);
    return true;
}
#end_block

#method_before
@Override
public GroupMembership getEffectiveGroups() {
    if (effectiveGroups == null) {
        if (authConfig.isIdentityTrustable(state().getExternalIds())) {
            effectiveGroups = groupBackend.membershipsOf(this);
            logger.atFinest().log("Known groups of %s: %s", getLoggableName(), lazy(() -> effectiveGroups.getKnownGroups()));
        } else {
            effectiveGroups = registeredGroups;
            logger.atFinest().log("%s has a non-trusted identity, falling back to %s as known groups", getLoggableName(), lazy(() -> effectiveGroups.getKnownGroups()));
        }
    }
    return effectiveGroups;
}
#method_after
@Override
public GroupMembership getEffectiveGroups() {
    if (effectiveGroups == null) {
        if (authConfig.isIdentityTrustable(state().getExternalIds())) {
            effectiveGroups = groupBackend.membershipsOf(this);
            logger.atFinest().log("Known groups of %s: %s", getLoggableName(), lazy(effectiveGroups::getKnownGroups));
        } else {
            effectiveGroups = registeredGroups;
            logger.atFinest().log("%s has a non-trusted identity, falling back to %s as known groups", getLoggableName(), lazy(registeredGroups::getKnownGroups));
        }
    }
    return effectiveGroups;
}
#end_block

#method_before
@Test
public void shouldKeepCommonFolders() throws Exception {
    String repoToDeleteName = "a/b/c/d";
    Repository repoToDelete = createRepository(repoToDeleteName);
    String repoToKeepName = "a/b/e";
    Repository repoToKeep = createRepository(repoToKeepName);
    Project.NameKey nameKey = new Project.NameKey(repoToDeleteName);
    Project project = new Project(nameKey);
    when(repoManager.openRepository(nameKey)).thenReturn(repoToDelete);
    fsDeleteHandler = new FilesystemDeleteHandler(repoManager, deletedListener);
    fsDeleteHandler.delete(project, false);
    assertThat(repoToDelete.getDirectory().exists()).isFalse();
    assertThat(repoToKeep.getDirectory().exists()).isTrue();
    assertThat(repoToKeep.getDirectory().exists()).isTrue();
}
#method_after
@Test
public void shouldKeepCommonFolders() throws Exception {
    String repoToDeleteName = "a/b/c/d";
    Repository repoToDelete = createRepository(repoToDeleteName);
    String repoToKeepName = "a/b/e";
    Repository repoToKeep = createRepository(repoToKeepName);
    Project.NameKey nameKey = new Project.NameKey(repoToDeleteName);
    Project project = new Project(nameKey);
    when(repoManager.openRepository(nameKey)).thenReturn(repoToDelete);
    fsDeleteHandler = new FilesystemDeleteHandler(repoManager, deletedListener);
    fsDeleteHandler.delete(project, false);
    assertThat(repoToDelete.getDirectory().exists()).isFalse();
    assertThat(repoToKeep.getDirectory().exists()).isTrue();
}
#end_block

#method_before
private GroupBundle readGroupBundleFromNoteDb(AccountGroup.UUID groupUuid) throws Exception {
    try (Repository allUsersRepo = gitRepoManager.openRepository(allUsersName)) {
        return groupBundleFactory.fromNoteDb(allUsersRepo, groupUuid);
    }
}
#method_after
private GroupBundle readGroupBundleFromNoteDb(AccountGroup.UUID groupUuid) throws Exception {
    try (Repository allUsersRepo = gitRepoManager.openRepository(allUsersName)) {
        return groupBundleFactory.fromNoteDb(allUsersName, allUsersRepo, groupUuid);
    }
}
#end_block

#method_before
private Optional<InternalGroup> getGroupFromNoteDb(AccountGroup.UUID groupUuid) throws Exception {
    try (Repository allUsersRepo = gitRepoManager.openRepository(allUsersName)) {
        return GroupConfig.loadForGroup(allUsersRepo, groupUuid).getLoadedGroup();
    }
}
#method_after
private Optional<InternalGroup> getGroupFromNoteDb(AccountGroup.UUID groupUuid) throws Exception {
    try (Repository allUsersRepo = gitRepoManager.openRepository(allUsersName)) {
        return GroupConfig.loadForGroup(allUsersName, allUsersRepo, groupUuid).getLoadedGroup();
    }
}
#end_block

#method_before
@Test
public void restCallWithoutTrace() throws Exception {
    RestResponse response = adminRestSession.put("/projects/new1");
    assertThat(response.getStatusCode()).isEqualTo(SC_CREATED);
    assertThat(response.getHeader(RestApiServlet.X_GERRIT_TRACE)).isNull();
    assertThat(projectCreationListener.foundTraceId).isFalse();
}
#method_after
@Test
public void restCallWithoutTrace() throws Exception {
    RestResponse response = adminRestSession.put("/projects/new1");
    assertThat(response.getStatusCode()).isEqualTo(SC_CREATED);
    assertThat(response.getHeader(RestApiServlet.X_GERRIT_TRACE)).isNull();
    assertThat(projectCreationListener.foundTraceId).isFalse();
    assertThat(projectCreationListener.isLoggingForced).isFalse();
}
#end_block

#method_before
@Test
public void restCallWithTrace() throws Exception {
    RestResponse response = adminRestSession.put("/projects/new2?" + ParameterParser.TRACE_PARAMETER);
    assertThat(response.getStatusCode()).isEqualTo(SC_CREATED);
    assertThat(response.getHeader(RestApiServlet.X_GERRIT_TRACE)).isNotNull();
    assertThat(projectCreationListener.foundTraceId).isTrue();
}
#method_after
@Test
public void restCallWithTrace() throws Exception {
    RestResponse response = adminRestSession.put("/projects/new2?" + ParameterParser.TRACE_PARAMETER);
    assertThat(response.getStatusCode()).isEqualTo(SC_CREATED);
    assertThat(response.getHeader(RestApiServlet.X_GERRIT_TRACE)).isNotNull();
    assertThat(projectCreationListener.foundTraceId).isTrue();
    assertThat(projectCreationListener.isLoggingForced).isTrue();
}
#end_block

#method_before
@Test
public void restCallWithTraceTrue() throws Exception {
    RestResponse response = adminRestSession.put("/projects/new3?" + ParameterParser.TRACE_PARAMETER + "=true");
    assertThat(response.getStatusCode()).isEqualTo(SC_CREATED);
    assertThat(response.getHeader(RestApiServlet.X_GERRIT_TRACE)).isNotNull();
    assertThat(projectCreationListener.foundTraceId).isTrue();
}
#method_after
@Test
public void restCallWithTraceTrue() throws Exception {
    RestResponse response = adminRestSession.put("/projects/new3?" + ParameterParser.TRACE_PARAMETER + "=true");
    assertThat(response.getStatusCode()).isEqualTo(SC_CREATED);
    assertThat(response.getHeader(RestApiServlet.X_GERRIT_TRACE)).isNotNull();
    assertThat(projectCreationListener.foundTraceId).isTrue();
    assertThat(projectCreationListener.isLoggingForced).isTrue();
}
#end_block

#method_before
@Test
public void restCallWithTraceFalse() throws Exception {
    RestResponse response = adminRestSession.put("/projects/new4?" + ParameterParser.TRACE_PARAMETER + "=false");
    assertThat(response.getStatusCode()).isEqualTo(SC_CREATED);
    assertThat(response.getHeader(RestApiServlet.X_GERRIT_TRACE)).isNull();
    assertThat(projectCreationListener.foundTraceId).isFalse();
}
#method_after
@Test
public void restCallWithTraceFalse() throws Exception {
    RestResponse response = adminRestSession.put("/projects/new4?" + ParameterParser.TRACE_PARAMETER + "=false");
    assertThat(response.getStatusCode()).isEqualTo(SC_CREATED);
    assertThat(response.getHeader(RestApiServlet.X_GERRIT_TRACE)).isNull();
    assertThat(projectCreationListener.foundTraceId).isFalse();
    assertThat(projectCreationListener.isLoggingForced).isFalse();
}
#end_block

#method_before
@Test
public void pushWithoutTrace() throws Exception {
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo);
    PushOneCommit.Result r = push.to("refs/heads/master");
    r.assertOkStatus();
    assertThat(commitValidationListener.foundTraceId).isFalse();
}
#method_after
@Test
public void pushWithoutTrace() throws Exception {
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo);
    PushOneCommit.Result r = push.to("refs/heads/master");
    r.assertOkStatus();
    assertThat(commitValidationListener.foundTraceId).isFalse();
    assertThat(commitValidationListener.isLoggingForced).isFalse();
}
#end_block

#method_before
@Test
public void pushWithTrace() throws Exception {
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo);
    push.setPushOptions(ImmutableList.of("trace"));
    PushOneCommit.Result r = push.to("refs/heads/master");
    r.assertOkStatus();
    assertThat(commitValidationListener.foundTraceId).isTrue();
}
#method_after
@Test
public void pushWithTrace() throws Exception {
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo);
    push.setPushOptions(ImmutableList.of("trace"));
    PushOneCommit.Result r = push.to("refs/heads/master");
    r.assertOkStatus();
    assertThat(commitValidationListener.foundTraceId).isTrue();
    assertThat(commitValidationListener.isLoggingForced).isTrue();
}
#end_block

#method_before
@Test
public void pushWithTraceTrue() throws Exception {
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo);
    push.setPushOptions(ImmutableList.of("trace=true"));
    PushOneCommit.Result r = push.to("refs/heads/master");
    r.assertOkStatus();
    assertThat(commitValidationListener.foundTraceId).isTrue();
}
#method_after
@Test
public void pushWithTraceTrue() throws Exception {
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo);
    push.setPushOptions(ImmutableList.of("trace=true"));
    PushOneCommit.Result r = push.to("refs/heads/master");
    r.assertOkStatus();
    assertThat(commitValidationListener.foundTraceId).isTrue();
    assertThat(commitValidationListener.isLoggingForced).isTrue();
}
#end_block

#method_before
@Test
public void pushWithTraceFalse() throws Exception {
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo);
    push.setPushOptions(ImmutableList.of("trace=false"));
    PushOneCommit.Result r = push.to("refs/heads/master");
    r.assertOkStatus();
    assertThat(commitValidationListener.foundTraceId).isFalse();
}
#method_after
@Test
public void pushWithTraceFalse() throws Exception {
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo);
    push.setPushOptions(ImmutableList.of("trace=false"));
    PushOneCommit.Result r = push.to("refs/heads/master");
    r.assertOkStatus();
    assertThat(commitValidationListener.foundTraceId).isFalse();
    assertThat(commitValidationListener.isLoggingForced).isFalse();
}
#end_block

#method_before
@Test
public void pushForReviewWithoutTrace() throws Exception {
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo);
    PushOneCommit.Result r = push.to("refs/for/master");
    r.assertOkStatus();
    assertThat(commitValidationListener.foundTraceId).isFalse();
}
#method_after
@Test
public void pushForReviewWithoutTrace() throws Exception {
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo);
    PushOneCommit.Result r = push.to("refs/for/master");
    r.assertOkStatus();
    assertThat(commitValidationListener.foundTraceId).isFalse();
    assertThat(commitValidationListener.isLoggingForced).isFalse();
}
#end_block

#method_before
@Test
public void pushForReviewWithTrace() throws Exception {
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo);
    push.setPushOptions(ImmutableList.of("trace"));
    PushOneCommit.Result r = push.to("refs/for/master");
    r.assertOkStatus();
    assertThat(commitValidationListener.foundTraceId).isTrue();
}
#method_after
@Test
public void pushForReviewWithTrace() throws Exception {
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo);
    push.setPushOptions(ImmutableList.of("trace"));
    PushOneCommit.Result r = push.to("refs/for/master");
    r.assertOkStatus();
    assertThat(commitValidationListener.foundTraceId).isTrue();
    assertThat(commitValidationListener.isLoggingForced).isTrue();
}
#end_block

#method_before
@Test
public void pushForReviewWithTraceTrue() throws Exception {
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo);
    push.setPushOptions(ImmutableList.of("trace=true"));
    PushOneCommit.Result r = push.to("refs/for/master");
    r.assertOkStatus();
    assertThat(commitValidationListener.foundTraceId).isTrue();
}
#method_after
@Test
public void pushForReviewWithTraceTrue() throws Exception {
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo);
    push.setPushOptions(ImmutableList.of("trace=true"));
    PushOneCommit.Result r = push.to("refs/for/master");
    r.assertOkStatus();
    assertThat(commitValidationListener.foundTraceId).isTrue();
    assertThat(commitValidationListener.isLoggingForced).isTrue();
}
#end_block

#method_before
@Test
public void pushForReviewWithTraceFalse() throws Exception {
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo);
    push.setPushOptions(ImmutableList.of("trace=false"));
    PushOneCommit.Result r = push.to("refs/for/master");
    r.assertOkStatus();
    assertThat(commitValidationListener.foundTraceId).isFalse();
}
#method_after
@Test
public void pushForReviewWithTraceFalse() throws Exception {
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo);
    push.setPushOptions(ImmutableList.of("trace=false"));
    PushOneCommit.Result r = push.to("refs/for/master");
    r.assertOkStatus();
    assertThat(commitValidationListener.foundTraceId).isFalse();
    assertThat(commitValidationListener.isLoggingForced).isFalse();
}
#end_block

#method_before
@Override
public void validateNewProject(CreateProjectArgs args) throws ValidationException {
    this.foundTraceId = LoggingContext.getInstance().getTagsAsMap().containsKey("TRACE_ID");
}
#method_after
@Override
public void validateNewProject(CreateProjectArgs args) throws ValidationException {
    this.foundTraceId = LoggingContext.getInstance().getTagsAsMap().containsKey("TRACE_ID");
    this.isLoggingForced = LoggingContext.getInstance().shouldForceLogging(null, null, false);
}
#end_block

#method_before
@Override
public List<CommitValidationMessage> onCommitReceived(CommitReceivedEvent receiveEvent) throws CommitValidationException {
    this.foundTraceId = LoggingContext.getInstance().getTagsAsMap().containsKey("TRACE_ID");
    return ImmutableList.of();
}
#method_after
@Override
public List<CommitValidationMessage> onCommitReceived(CommitReceivedEvent receiveEvent) throws CommitValidationException {
    this.foundTraceId = LoggingContext.getInstance().getTagsAsMap().containsKey("TRACE_ID");
    this.isLoggingForced = LoggingContext.getInstance().shouldForceLogging(null, null, false);
    return ImmutableList.of();
}
#end_block

#method_before
public Iterator<Entry<T>> entryIterator() {
    final Iterator<AtomicReference<NamedProvider<T>>> itr = items.iterator();
    return new Iterator<Entry<T>>() {

        private Entry<T> next;

        @Override
        public boolean hasNext() {
            while (next == null && itr.hasNext()) {
                NamedProvider<T> p = itr.next().get();
                if (p != null) {
                    try {
                        next = new Entry<T>() {

                            @Override
                            public String getPluginName() {
                                return p.pluginName;
                            }

                            @Override
                            public Provider<T> getProvider() {
                                return p.impl;
                            }
                        };
                    } catch (RuntimeException e) {
                    // TODO Log failed member of DynamicSet.
                    }
                }
            }
            return next != null;
        }

        @Override
        public Entry<T> next() {
            if (hasNext()) {
                Entry<T> result = next;
                next = null;
                return result;
            }
            throw new NoSuchElementException();
        }

        @Override
        public void remove() {
            throw new UnsupportedOperationException();
        }
    };
}
#method_after
public Iterator<Entry<T>> entryIterator() {
    final Iterator<AtomicReference<NamedProvider<T>>> itr = items.iterator();
    return new Iterator<Entry<T>>() {

        private Entry<T> next;

        @Override
        public boolean hasNext() {
            while (next == null && itr.hasNext()) {
                NamedProvider<T> p = itr.next().get();
                if (p != null) {
                    try {
                        next = new Entry<>(p.pluginName, p.impl);
                    } catch (RuntimeException e) {
                    // TODO Log failed member of DynamicSet.
                    }
                }
            }
            return next != null;
        }

        @Override
        public Entry<T> next() {
            if (hasNext()) {
                Entry<T> result = next;
                next = null;
                return result;
            }
            throw new NoSuchElementException();
        }

        @Override
        public void remove() {
            throw new UnsupportedOperationException();
        }
    };
}
#end_block

#method_before
public SortedSet<String> plugins() {
    SortedSet<String> r = new TreeSet<>();
    for (AtomicReference<NamedProvider<T>> item : items) {
        r.add(item.get().pluginName);
    }
    return Collections.unmodifiableSortedSet(r);
}
#method_after
public ImmutableSortedSet<String> plugins() {
    return items.stream().map(i -> i.get().pluginName).collect(toImmutableSortedSet(naturalOrder()));
}
#end_block

#method_before
public Set<Provider<T>> byPlugin(String pluginName) {
    Set<Provider<T>> r = new HashSet<>();
    for (AtomicReference<NamedProvider<T>> item : items) {
        if (item.get().pluginName.equals(pluginName)) {
            r.add(item.get().impl);
        }
    }
    return Collections.unmodifiableSet(r);
}
#method_after
public ImmutableSet<Provider<T>> byPlugin(String pluginName) {
    return items.stream().filter(i -> i.get().pluginName.equals(pluginName)).map(i -> i.get().impl).collect(toImmutableSet());
}
#end_block

#method_before
@Test
public void sshCallWithoutTrace() throws Exception {
    adminSshSession.exec("gerrit create-project new1");
    adminSshSession.assertSuccess();
    assertThat(projectCreationListener.foundTraceId).isFalse();
}
#method_after
@Test
public void sshCallWithoutTrace() throws Exception {
    adminSshSession.exec("gerrit create-project new1");
    adminSshSession.assertSuccess();
    assertThat(projectCreationListener.foundTraceId).isFalse();
    assertThat(projectCreationListener.isLoggingForced).isFalse();
}
#end_block

#method_before
@Test
public void sshCallWithTrace() throws Exception {
    adminSshSession.exec("gerrit create-project --trace new2");
    // The trace ID is written to stderr.
    adminSshSession.assertFailure(RequestId.Type.TRACE_ID.name());
    assertThat(projectCreationListener.foundTraceId).isTrue();
}
#method_after
@Test
public void sshCallWithTrace() throws Exception {
    adminSshSession.exec("gerrit create-project --trace new2");
    // The trace ID is written to stderr.
    adminSshSession.assertFailure(RequestId.Type.TRACE_ID.name());
    assertThat(projectCreationListener.foundTraceId).isTrue();
    assertThat(projectCreationListener.isLoggingForced).isTrue();
}
#end_block

#method_before
@Override
public void validateNewProject(CreateProjectArgs args) throws ValidationException {
    this.foundTraceId = LoggingContext.getInstance().getTagsAsMap().containsKey("TRACE_ID");
}
#method_after
@Override
public void validateNewProject(CreateProjectArgs args) throws ValidationException {
    this.foundTraceId = LoggingContext.getInstance().getTagsAsMap().containsKey("TRACE_ID");
    this.isLoggingForced = LoggingContext.getInstance().shouldForceLogging(null, null, false);
}
#end_block

#method_before
@Test
public void stalenessChecker() throws Exception {
    // Newly created account is not stale.
    AccountInfo accountInfo = gApi.accounts().create(name("foo")).get();
    Account.Id accountId = new Account.Id(accountInfo._accountId);
    assertThat(stalenessChecker.isStale(accountId)).isFalse();
    // Manually updating the user ref makes the index document stale.
    String userRef = RefNames.refsUsers(accountId);
    try (Repository repo = repoManager.openRepository(allUsers);
        ObjectInserter oi = repo.newObjectInserter();
        RevWalk rw = new RevWalk(repo)) {
        RevCommit commit = rw.parseCommit(repo.exactRef(userRef).getObjectId());
        PersonIdent ident = new PersonIdent(serverIdent.get(), TimeUtil.nowTs());
        CommitBuilder cb = new CommitBuilder();
        cb.setTreeId(commit.getTree());
        cb.setCommitter(ident);
        cb.setAuthor(ident);
        cb.setMessage(commit.getFullMessage());
        ObjectId emptyCommit = oi.insert(cb);
        oi.flush();
        RefUpdate updateRef = repo.updateRef(userRef);
        updateRef.setExpectedOldObjectId(commit.toObjectId());
        updateRef.setNewObjectId(emptyCommit);
        assertThat(updateRef.forceUpdate()).isEqualTo(RefUpdate.Result.FORCED);
    }
    assertStaleAccountAndReindex(accountId);
    // stale.
    try (Repository repo = repoManager.openRepository(allUsers)) {
        ExternalIdNotes extIdNotes = ExternalIdNotes.loadNoCacheUpdate(repo);
        ExternalId.Key key = ExternalId.Key.create("foo", "foo");
        extIdNotes.insert(ExternalId.create(key, accountId));
        try (MetaDataUpdate update = metaDataUpdateFactory.create(allUsers)) {
            extIdNotes.commit(update);
        }
        assertStaleAccountAndReindex(accountId);
        extIdNotes.upsert(ExternalId.createWithEmail(key, accountId, "foo@example.com"));
        try (MetaDataUpdate update = metaDataUpdateFactory.create(allUsers)) {
            extIdNotes.commit(update);
        }
        assertStaleAccountAndReindex(accountId);
        extIdNotes.delete(accountId, key);
        try (MetaDataUpdate update = metaDataUpdateFactory.create(allUsers)) {
            extIdNotes.commit(update);
        }
        assertStaleAccountAndReindex(accountId);
    }
    // Manually delete account
    try (Repository repo = repoManager.openRepository(allUsers);
        RevWalk rw = new RevWalk(repo)) {
        RevCommit commit = rw.parseCommit(repo.exactRef(userRef).getObjectId());
        RefUpdate updateRef = repo.updateRef(userRef);
        updateRef.setExpectedOldObjectId(commit.toObjectId());
        updateRef.setNewObjectId(ObjectId.zeroId());
        updateRef.setForceUpdate(true);
        assertThat(updateRef.delete()).isEqualTo(RefUpdate.Result.FORCED);
    }
    assertStaleAccountAndReindex(accountId);
}
#method_after
@Test
public void stalenessChecker() throws Exception {
    // Newly created account is not stale.
    AccountInfo accountInfo = gApi.accounts().create(name("foo")).get();
    Account.Id accountId = new Account.Id(accountInfo._accountId);
    assertThat(stalenessChecker.isStale(accountId)).isFalse();
    // Manually updating the user ref makes the index document stale.
    String userRef = RefNames.refsUsers(accountId);
    try (Repository repo = repoManager.openRepository(allUsers);
        ObjectInserter oi = repo.newObjectInserter();
        RevWalk rw = new RevWalk(repo)) {
        RevCommit commit = rw.parseCommit(repo.exactRef(userRef).getObjectId());
        PersonIdent ident = new PersonIdent(serverIdent.get(), TimeUtil.nowTs());
        CommitBuilder cb = new CommitBuilder();
        cb.setTreeId(commit.getTree());
        cb.setCommitter(ident);
        cb.setAuthor(ident);
        cb.setMessage(commit.getFullMessage());
        ObjectId emptyCommit = oi.insert(cb);
        oi.flush();
        RefUpdate updateRef = repo.updateRef(userRef);
        updateRef.setExpectedOldObjectId(commit.toObjectId());
        updateRef.setNewObjectId(emptyCommit);
        assertThat(updateRef.forceUpdate()).isEqualTo(RefUpdate.Result.FORCED);
    }
    assertStaleAccountAndReindex(accountId);
    // stale.
    try (Repository repo = repoManager.openRepository(allUsers)) {
        ExternalIdNotes extIdNotes = ExternalIdNotes.loadNoCacheUpdate(allUsers, repo);
        ExternalId.Key key = ExternalId.Key.create("foo", "foo");
        extIdNotes.insert(ExternalId.create(key, accountId));
        try (MetaDataUpdate update = metaDataUpdateFactory.create(allUsers)) {
            extIdNotes.commit(update);
        }
        assertStaleAccountAndReindex(accountId);
        extIdNotes.upsert(ExternalId.createWithEmail(key, accountId, "foo@example.com"));
        try (MetaDataUpdate update = metaDataUpdateFactory.create(allUsers)) {
            extIdNotes.commit(update);
        }
        assertStaleAccountAndReindex(accountId);
        extIdNotes.delete(accountId, key);
        try (MetaDataUpdate update = metaDataUpdateFactory.create(allUsers)) {
            extIdNotes.commit(update);
        }
        assertStaleAccountAndReindex(accountId);
    }
    // Manually delete account
    try (Repository repo = repoManager.openRepository(allUsers);
        RevWalk rw = new RevWalk(repo)) {
        RevCommit commit = rw.parseCommit(repo.exactRef(userRef).getObjectId());
        RefUpdate updateRef = repo.updateRef(userRef);
        updateRef.setExpectedOldObjectId(commit.toObjectId());
        updateRef.setNewObjectId(ObjectId.zeroId());
        updateRef.setForceUpdate(true);
        assertThat(updateRef.delete()).isEqualTo(RefUpdate.Result.FORCED);
    }
    assertStaleAccountAndReindex(accountId);
}
#end_block

#method_before
private static <T> List<AtomicReference<NamedProvider<T>>> find(Injector src, TypeLiteral<T> type) {
    List<Binding<T>> bindings = src.findBindingsByType(type);
    int cnt = bindings != null ? bindings.size() : 0;
    if (cnt == 0) {
        return Collections.emptyList();
    }
    List<AtomicReference<NamedProvider<T>>> r = new ArrayList<>(cnt);
    for (Binding<T> b : bindings) {
        if (b.getKey().getAnnotation() != null) {
            r.add(new AtomicReference<>(new NamedProvider<>(b.getProvider(), "gerrit")));
        }
    }
    return r;
}
#method_after
private static <T> List<AtomicReference<NamedProvider<T>>> find(Injector src, TypeLiteral<T> type) {
    List<Binding<T>> bindings = src.findBindingsByType(type);
    int cnt = bindings != null ? bindings.size() : 0;
    if (cnt == 0) {
        return Collections.emptyList();
    }
    List<AtomicReference<NamedProvider<T>>> r = new ArrayList<>(cnt);
    for (Binding<T> b : bindings) {
        if (b.getKey().getAnnotation() != null) {
            r.add(new AtomicReference<>(new NamedProvider<>(b.getProvider(), PluginName.GERRIT)));
        }
    }
    return r;
}
#end_block

#method_before
public static LifecycleListener registerInParentInjectors() {
    return new LifecycleListener() {

        private List<RegistrationHandle> handles;

        @Inject
        private Injector self;

        @Override
        public void start() {
            handles = new ArrayList<>(4);
            Injector parent = self.getParent();
            while (parent != null) {
                handles.addAll(attachSets(self, "gerrit", dynamicSetsOf(parent)));
                handles.addAll(attachMaps(self, "gerrit", dynamicMapsOf(parent)));
                parent = parent.getParent();
            }
            if (handles.isEmpty()) {
                handles = null;
            }
        }

        @Override
        public void stop() {
            remove(handles);
            handles = null;
        }
    };
}
#method_after
public static LifecycleListener registerInParentInjectors() {
    return new LifecycleListener() {

        private List<RegistrationHandle> handles;

        @Inject
        private Injector self;

        @Override
        public void start() {
            handles = new ArrayList<>(4);
            Injector parent = self.getParent();
            while (parent != null) {
                handles.addAll(attachSets(self, PluginName.GERRIT, dynamicSetsOf(parent)));
                handles.addAll(attachMaps(self, PluginName.GERRIT, dynamicMapsOf(parent)));
                parent = parent.getParent();
            }
            if (handles.isEmpty()) {
                handles = null;
            }
        }

        @Override
        public void stop() {
            remove(handles);
            handles = null;
        }
    };
}
#end_block

#method_before
public T get() {
    NamedProvider<T> item = ref.get();
    return item != null ? item.impl.get() : null;
}
#method_after
@Nullable
public T get() {
    NamedProvider<T> item = ref.get();
    return item != null ? item.impl.get() : null;
}
#end_block

#method_before
public String getPluginName() {
    NamedProvider<T> item = ref.get();
    return item != null ? item.pluginName : null;
}
#method_after
@Nullable
public String getPluginName() {
    NamedProvider<T> item = ref.get();
    return item != null ? item.pluginName : null;
}
#end_block

#method_before
@Override
public ReloadableHandle replace(Key<T> newKey, Provider<T> newItem) {
    NamedProvider<T> n = new NamedProvider<>(newItem, item.pluginName);
    if (ref.compareAndSet(item, n)) {
        return new ReloadableHandle(newKey, n, defaultItem);
    }
    return null;
}
#method_after
@Override
@Nullable
public ReloadableHandle replace(Key<T> newKey, Provider<T> newItem) {
    NamedProvider<T> n = new NamedProvider<>(newItem, item.pluginName);
    if (ref.compareAndSet(item, n)) {
        return new ReloadableHandle(newKey, n, defaultItem);
    }
    return null;
}
#end_block

#method_before
private Collection<AccountInfo> removableReviewers(ChangeData cd, ChangeInfo out) throws PermissionBackendException, OrmException {
    // Although this is called removableReviewers, this method also determines
    // which CCs are removable.
    // 
    // For reviewers, we need to look at each approval, because the reviewer
    // should only be considered removable if *all* of their approvals can be
    // removed. First, add all reviewers with *any* removable approval to the
    // "removable" set. Along the way, if we encounter a non-removable approval,
    // add the reviewer to the "fixed" set. Before we return, remove all members
    // of "fixed" from "removable", because not all of their approvals can be
    // removed.
    Collection<LabelInfo> labels = out.labels.values();
    Set<Account.Id> fixed = Sets.newHashSetWithExpectedSize(labels.size());
    Set<Account.Id> removable = Sets.newHashSetWithExpectedSize(labels.size());
    // Check if the user has the permission to remove a reviewer. This means we can bypass the
    // testRemoveReviewer check for a specific reviewer in the loop saving potentially many
    // permission checks.
    boolean canRemoveAnyReviewer = permissionBackend.user(userProvider.get()).change(cd).database(db).test(ChangePermission.REMOVE_REVIEWER);
    for (LabelInfo label : labels) {
        if (label.all == null) {
            continue;
        }
        for (ApprovalInfo ai : label.all) {
            Account.Id id = new Account.Id(ai._accountId);
            if (canRemoveAnyReviewer || removeReviewerControl.testRemoveReviewer(cd, userProvider.get(), id, MoreObjects.firstNonNull(ai.value, 0))) {
                removable.add(id);
            } else {
                fixed.add(id);
            }
        }
    }
    // CCs are simpler than reviewers. They are removable if the ChangeControl
    // would permit a non-negative approval by that account to be removed, in
    // which case add them to removable. We don't need to add unremovable CCs to
    // "fixed" because we only visit each CC once here.
    Collection<AccountInfo> ccs = out.reviewers.get(ReviewerState.CC);
    if (ccs != null) {
        for (AccountInfo ai : ccs) {
            if (ai._accountId != null) {
                Account.Id id = new Account.Id(ai._accountId);
                if (removeReviewerControl.testRemoveReviewer(cd, userProvider.get(), id, 0)) {
                    removable.add(id);
                }
            }
        }
    }
    // Subtract any reviewers with non-removable approvals from the "removable"
    // set. This also subtracts any CCs that for some reason also hold
    // unremovable approvals.
    removable.removeAll(fixed);
    List<AccountInfo> result = Lists.newArrayListWithCapacity(removable.size());
    for (Account.Id id : removable) {
        result.add(accountLoader.get(id));
    }
    // Reviewers added by email are always removable
    for (Collection<AccountInfo> infos : out.reviewers.values()) {
        for (AccountInfo info : infos) {
            if (info._accountId == null) {
                result.add(info);
            }
        }
    }
    return result;
}
#method_after
private Collection<AccountInfo> removableReviewers(ChangeData cd, ChangeInfo out) throws PermissionBackendException, OrmException {
    // Although this is called removableReviewers, this method also determines
    // which CCs are removable.
    // 
    // For reviewers, we need to look at each approval, because the reviewer
    // should only be considered removable if *all* of their approvals can be
    // removed. First, add all reviewers with *any* removable approval to the
    // "removable" set. Along the way, if we encounter a non-removable approval,
    // add the reviewer to the "fixed" set. Before we return, remove all members
    // of "fixed" from "removable", because not all of their approvals can be
    // removed.
    Collection<LabelInfo> labels = out.labels.values();
    Set<Account.Id> fixed = Sets.newHashSetWithExpectedSize(labels.size());
    Set<Account.Id> removable = Sets.newHashSetWithExpectedSize(labels.size());
    // Check if the user has the permission to remove a reviewer. This means we can bypass the
    // testRemoveReviewer check for a specific reviewer in the loop saving potentially many
    // permission checks.
    boolean canRemoveAnyReviewer = permissionBackendForChange(userProvider.get(), cd).test(ChangePermission.REMOVE_REVIEWER);
    for (LabelInfo label : labels) {
        if (label.all == null) {
            continue;
        }
        for (ApprovalInfo ai : label.all) {
            Account.Id id = new Account.Id(ai._accountId);
            if (canRemoveAnyReviewer || removeReviewerControl.testRemoveReviewer(cd, userProvider.get(), id, MoreObjects.firstNonNull(ai.value, 0))) {
                removable.add(id);
            } else {
                fixed.add(id);
            }
        }
    }
    // CCs are simpler than reviewers. They are removable if the ChangeControl
    // would permit a non-negative approval by that account to be removed, in
    // which case add them to removable. We don't need to add unremovable CCs to
    // "fixed" because we only visit each CC once here.
    Collection<AccountInfo> ccs = out.reviewers.get(ReviewerState.CC);
    if (ccs != null) {
        for (AccountInfo ai : ccs) {
            if (ai._accountId != null) {
                Account.Id id = new Account.Id(ai._accountId);
                if (canRemoveAnyReviewer || removeReviewerControl.testRemoveReviewer(cd, userProvider.get(), id, 0)) {
                    removable.add(id);
                }
            }
        }
    }
    // Subtract any reviewers with non-removable approvals from the "removable"
    // set. This also subtracts any CCs that for some reason also hold
    // unremovable approvals.
    removable.removeAll(fixed);
    List<AccountInfo> result = Lists.newArrayListWithCapacity(removable.size());
    for (Account.Id id : removable) {
        result.add(accountLoader.get(id));
    }
    // Reviewers added by email are always removable
    for (Collection<AccountInfo> infos : out.reviewers.values()) {
        for (AccountInfo info : infos) {
            if (info._accountId == null) {
                result.add(info);
            }
        }
    }
    return result;
}
#end_block

#method_before
@Override
public List<CommitValidationMessage> onCommitReceived(CommitReceivedEvent receiveEvent) throws CommitValidationException {
    PersonIdent author = receiveEvent.commit.getAuthorIdent();
    if (user.hasEmailAddress(author.getEmailAddress())) {
        return Collections.emptyList();
    }
    try {
        perm.check(RefPermission.FORGE_AUTHOR);
        return Collections.emptyList();
    } catch (AuthException e) {
        throw new CommitValidationException("invalid author", invalidEmail(receiveEvent.commit, "author", author, user, canonicalWebUrl));
    } catch (PermissionBackendException e) {
        logger.atSevere().withCause(e).log("cannot check FORGE_AUTHOR");
        throw new CommitValidationException("internal auth error");
    }
}
#method_after
@Override
public List<CommitValidationMessage> onCommitReceived(CommitReceivedEvent receiveEvent) throws CommitValidationException {
    PersonIdent author = receiveEvent.commit.getAuthorIdent();
    if (user.hasEmailAddress(author.getEmailAddress())) {
        return Collections.emptyList();
    }
    try {
        perm.check(RefPermission.FORGE_AUTHOR);
        return Collections.emptyList();
    } catch (AuthException e) {
        throw new CommitValidationException("invalid author", invalidEmail("author", author, user, canonicalWebUrl));
    } catch (PermissionBackendException e) {
        logger.atSevere().withCause(e).log("cannot check FORGE_AUTHOR");
        throw new CommitValidationException("internal auth error");
    }
}
#end_block

#method_before
@Override
public List<CommitValidationMessage> onCommitReceived(CommitReceivedEvent receiveEvent) throws CommitValidationException {
    PersonIdent committer = receiveEvent.commit.getCommitterIdent();
    if (user.hasEmailAddress(committer.getEmailAddress())) {
        return Collections.emptyList();
    }
    try {
        perm.check(RefPermission.FORGE_COMMITTER);
        return Collections.emptyList();
    } catch (AuthException e) {
        throw new CommitValidationException("invalid committer", invalidEmail(receiveEvent.commit, "committer", committer, user, canonicalWebUrl));
    } catch (PermissionBackendException e) {
        logger.atSevere().withCause(e).log("cannot check FORGE_COMMITTER");
        throw new CommitValidationException("internal auth error");
    }
}
#method_after
@Override
public List<CommitValidationMessage> onCommitReceived(CommitReceivedEvent receiveEvent) throws CommitValidationException {
    PersonIdent committer = receiveEvent.commit.getCommitterIdent();
    if (user.hasEmailAddress(committer.getEmailAddress())) {
        return Collections.emptyList();
    }
    try {
        perm.check(RefPermission.FORGE_COMMITTER);
        return Collections.emptyList();
    } catch (AuthException e) {
        throw new CommitValidationException("invalid committer", invalidEmail("committer", committer, user, canonicalWebUrl));
    } catch (PermissionBackendException e) {
        logger.atSevere().withCause(e).log("cannot check FORGE_COMMITTER");
        throw new CommitValidationException("internal auth error");
    }
}
#end_block

#method_before
private static CommitValidationMessage invalidEmail(RevCommit c, String type, PersonIdent who, IdentifiedUser currentUser, String canonicalWebUrl) {
    StringBuilder sb = new StringBuilder();
    sb.append(" email address ").append(who.getEmailAddress()).append(" is not registered in your account, and you lack 'forge ").append(type).append("' permission.\n");
    if (currentUser.getEmailAddresses().isEmpty()) {
        sb.append("You have not registered any email addresses.\n");
    } else {
        sb.append("The following addresses are currently registered:\n");
        for (String address : currentUser.getEmailAddresses()) {
            sb.append("   ").append(address).append("\n");
        }
    }
    if (canonicalWebUrl != null) {
        sb.append("To register an email address, visit:\n");
        sb.append(canonicalWebUrl).append("#").append(PageLinks.SETTINGS_CONTACT).append("\n");
    }
    sb.append("\n");
    return new CommitValidationMessage(sb.toString(), true);
}
#method_after
private static CommitValidationMessage invalidEmail(String type, PersonIdent who, IdentifiedUser currentUser, String canonicalWebUrl) {
    StringBuilder sb = new StringBuilder();
    sb.append("email address ").append(who.getEmailAddress()).append(" is not registered in your account, and you lack 'forge ").append(type).append("' permission.\n");
    if (currentUser.getEmailAddresses().isEmpty()) {
        sb.append("You have not registered any email addresses.\n");
    } else {
        sb.append("The following addresses are currently registered:\n");
        for (String address : currentUser.getEmailAddresses()) {
            sb.append("   ").append(address).append("\n");
        }
    }
    if (canonicalWebUrl != null) {
        sb.append("To register an email address, visit:\n");
        sb.append(canonicalWebUrl).append("#").append(PageLinks.SETTINGS_CONTACT).append("\n");
    }
    sb.append("\n");
    return new CommitValidationMessage(sb.toString(), true);
}
#end_block

#method_before
private void assertHasNoChildProjects(ProjectResource rsrc) throws CannotDeleteProjectException {
    List<ProjectInfo> children = listChildProjectsProvider.get().apply(rsrc);
    if (!children.isEmpty()) {
        String childrenString = Joiner.on(", ").join(children.stream().map(info -> info.name).collect(Collectors.toList()));
        throw new CannotDeleteProjectException("Cannot delete project because it has children: " + childrenString);
    }
}
#method_after
private void assertHasNoChildProjects(ProjectResource rsrc) throws CannotDeleteProjectException {
    List<ProjectInfo> children = listChildProjectsProvider.get().apply(rsrc);
    if (!children.isEmpty()) {
        throw new CannotDeleteProjectException("Cannot delete project because it has children: " + children.stream().map(info -> info.name).collect(joining(",")));
    }
}
#end_block

#method_before
private void deleteFromPatchSets(ReviewDb db, final ResultSet<PatchSet> patchSets) throws OrmException {
    for (PatchSet patchSet : patchSets) {
        accountPatchReviewStore.get().clearReviewed(patchSet.getId());
        db.patchSets().delete(Collections.singleton(patchSet));
    }
}
#method_after
private void deleteFromPatchSets(ReviewDb db, ResultSet<PatchSet> patchSets) throws OrmException {
    for (PatchSet patchSet : patchSets) {
        accountPatchReviewStore.get().clearReviewed(patchSet.getId());
        db.patchSets().delete(Collections.singleton(patchSet));
    }
}
#end_block

#method_before
private void parsePushOptions() {
    List<String> optionList = receivePack.getPushOptions();
    if (optionList != null) {
        for (String option : optionList) {
            int e = option.indexOf('=');
            if (e > 0) {
                pushOptions.put(option.substring(0, e), option.substring(e + 1));
            } else {
                pushOptions.put(option, "");
            }
        }
    }
    List<String> noteDbValues = pushOptions.get("notedb");
    if (!noteDbValues.isEmpty()) {
        // These semantics for duplicates/errors are somewhat arbitrary and may not match e.g. the
        // CommandLineParser behavior used by MagicBranchInput.
        String value = noteDbValues.get(noteDbValues.size() - 1);
        noteDbPushOption = NoteDbPushOption.parse(value);
        if (!noteDbPushOption.isPresent()) {
            addError("Invalid value in -o " + NoteDbPushOption.OPTION_NAME + "=" + value);
        }
    } else {
        noteDbPushOption = Optional.of(NoteDbPushOption.DISALLOW);
    }
    List<String> traceValues = pushOptions.get("trace");
    if (!traceValues.isEmpty()) {
        String value = traceValues.get(traceValues.size() - 1);
        tracePushOption = Optional.of(value.isEmpty() || Boolean.parseBoolean(value));
    } else {
        tracePushOption = Optional.empty();
    }
}
#method_after
private void parsePushOptions() {
    List<String> optionList = receivePack.getPushOptions();
    if (optionList != null) {
        for (String option : optionList) {
            int e = option.indexOf('=');
            if (e > 0) {
                pushOptions.put(option.substring(0, e), option.substring(e + 1));
            } else {
                pushOptions.put(option, "");
            }
        }
    }
    List<String> noteDbValues = pushOptions.get("notedb");
    if (!noteDbValues.isEmpty()) {
        // These semantics for duplicates/errors are somewhat arbitrary and may not match e.g. the
        // CmdLineParser behavior used by MagicBranchInput.
        String value = noteDbValues.get(noteDbValues.size() - 1);
        noteDbPushOption = NoteDbPushOption.parse(value);
        if (!noteDbPushOption.isPresent()) {
            addError("Invalid value in -o " + NoteDbPushOption.OPTION_NAME + "=" + value);
        }
    } else {
        noteDbPushOption = Optional.of(NoteDbPushOption.DISALLOW);
    }
    List<String> traceValues = pushOptions.get("trace");
    if (!traceValues.isEmpty()) {
        String value = traceValues.get(traceValues.size() - 1);
        tracePushOption = Optional.of(value.isEmpty() || Boolean.parseBoolean(value));
    } else {
        tracePushOption = Optional.empty();
    }
}
#end_block

#method_before
private void parseRegularCommand(ReceiveCommand cmd) throws PermissionBackendException, NoSuchProjectException, IOException {
    if (cmd.getResult() != NOT_ATTEMPTED) {
        // Already rejected by the core receive process.
        logger.atFine().log("Already processed by core: %s %s", cmd.getResult(), cmd);
        return;
    }
    if (!Repository.isValidRefName(cmd.getRefName()) || cmd.getRefName().contains("//")) {
        reject(cmd, "not valid ref");
        return;
    }
    if (RefNames.isNoteDbMetaRef(cmd.getRefName())) {
        // Reject pushes to NoteDb refs without a special option and permission. Note that this
        // prohibition doesn't depend on NoteDb being enabled in any way, since all sites will
        // migrate to NoteDb eventually, and we don't want garbage data waiting there when the
        // migration finishes.
        logger.atFine().log("%s NoteDb ref %s with %s=%s", cmd.getType(), cmd.getRefName(), NoteDbPushOption.OPTION_NAME, noteDbPushOption);
        if (!Optional.of(NoteDbPushOption.ALLOW).equals(noteDbPushOption)) {
            // Only reject this command, not the whole push. This supports the use case of "git clone
            // --mirror" followed by "git push --mirror", when the user doesn't really intend to clone
            // or mirror the NoteDb data; there is no single refspec that describes all refs *except*
            // NoteDb refs.
            reject(cmd, "NoteDb update requires -o " + NoteDbPushOption.OPTION_NAME + "=" + NoteDbPushOption.ALLOW.value());
            return;
        }
        try {
            permissionBackend.user(user).check(GlobalPermission.ACCESS_DATABASE);
        } catch (AuthException e) {
            reject(cmd, "NoteDb update requires access database permission");
            return;
        }
    }
    switch(cmd.getType()) {
        case CREATE:
            parseCreate(cmd);
            break;
        case UPDATE:
            parseUpdate(cmd);
            break;
        case DELETE:
            parseDelete(cmd);
            break;
        case UPDATE_NONFASTFORWARD:
            parseRewind(cmd);
            break;
        default:
            reject(cmd, "prohibited by Gerrit: unknown command type " + cmd.getType());
            return;
    }
    if (cmd.getResult() != NOT_ATTEMPTED) {
        return;
    }
    if (isConfig(cmd)) {
        logger.atFine().log("Processing %s command", cmd.getRefName());
        try {
            permissions.check(ProjectPermission.WRITE_CONFIG);
        } catch (AuthException e) {
            reject(cmd, String.format("must be either project owner or have %s permission", ProjectPermission.WRITE_CONFIG.describeForException()));
            return;
        }
        switch(cmd.getType()) {
            case CREATE:
            case UPDATE:
            case UPDATE_NONFASTFORWARD:
                try {
                    ProjectConfig cfg = new ProjectConfig(project.getNameKey());
                    cfg.load(project.getNameKey(), receivePack.getRevWalk(), cmd.getNewId());
                    if (!cfg.getValidationErrors().isEmpty()) {
                        addError("Invalid project configuration:");
                        for (ValidationError err : cfg.getValidationErrors()) {
                            addError("  " + err.getMessage());
                        }
                        reject(cmd, "invalid project configuration");
                        logger.atSevere().log("User %s tried to push invalid project configuration %s for %s", user.getLoggableName(), cmd.getNewId().name(), project.getName());
                        return;
                    }
                    Project.NameKey newParent = cfg.getProject().getParent(allProjectsName);
                    Project.NameKey oldParent = project.getParent(allProjectsName);
                    if (oldParent == null) {
                        // update of the 'All-Projects' project
                        if (newParent != null) {
                            reject(cmd, "invalid project configuration: root project cannot have parent");
                            return;
                        }
                    } else {
                        if (!oldParent.equals(newParent)) {
                            try {
                                permissionBackend.user(user).check(GlobalPermission.ADMINISTRATE_SERVER);
                            } catch (AuthException e) {
                                reject(cmd, "invalid project configuration: only Gerrit admin can set parent");
                                return;
                            }
                        }
                        if (projectCache.get(newParent) == null) {
                            reject(cmd, "invalid project configuration: parent does not exist");
                            return;
                        }
                    }
                    for (Entry<ProjectConfigEntry> e : pluginConfigEntries) {
                        PluginConfig pluginCfg = cfg.getPluginConfig(e.getPluginName());
                        ProjectConfigEntry configEntry = e.getProvider().get();
                        String value = pluginCfg.getString(e.getExportName());
                        String oldValue = projectState.getConfig().getPluginConfig(e.getPluginName()).getString(e.getExportName());
                        if (configEntry.getType() == ProjectConfigEntryType.ARRAY) {
                            oldValue = Arrays.stream(projectState.getConfig().getPluginConfig(e.getPluginName()).getStringList(e.getExportName())).collect(joining("\n"));
                        }
                        if ((value == null ? oldValue != null : !value.equals(oldValue)) && !configEntry.isEditable(projectState)) {
                            reject(cmd, String.format("invalid project configuration: Not allowed to set parameter" + " '%s' of plugin '%s' on project '%s'.", e.getExportName(), e.getPluginName(), project.getName()));
                            continue;
                        }
                        if (ProjectConfigEntryType.LIST.equals(configEntry.getType()) && value != null && !configEntry.getPermittedValues().contains(value)) {
                            reject(cmd, String.format("invalid project configuration: The value '%s' is " + "not permitted for parameter '%s' of plugin '%s'.", value, e.getExportName(), e.getPluginName()));
                        }
                    }
                } catch (Exception e) {
                    reject(cmd, "invalid project configuration");
                    logger.atSevere().withCause(e).log("User %s tried to push invalid project configuration %s for %s", user.getLoggableName(), cmd.getNewId().name(), project.getName());
                    return;
                }
                break;
            case DELETE:
                break;
            default:
                reject(cmd, "prohibited by Gerrit: don't know how to handle config update of type " + cmd.getType());
        }
    }
}
#method_after
private void parseRegularCommand(ReceiveCommand cmd) throws PermissionBackendException, NoSuchProjectException, IOException {
    if (cmd.getResult() != NOT_ATTEMPTED) {
        // Already rejected by the core receive process.
        logger.atFine().log("Already processed by core: %s %s", cmd.getResult(), cmd);
        return;
    }
    if (!Repository.isValidRefName(cmd.getRefName()) || cmd.getRefName().contains("//")) {
        reject(cmd, "not valid ref");
        return;
    }
    if (RefNames.isNoteDbMetaRef(cmd.getRefName())) {
        // Reject pushes to NoteDb refs without a special option and permission. Note that this
        // prohibition doesn't depend on NoteDb being enabled in any way, since all sites will
        // migrate to NoteDb eventually, and we don't want garbage data waiting there when the
        // migration finishes.
        logger.atFine().log("%s NoteDb ref %s with %s=%s", cmd.getType(), cmd.getRefName(), NoteDbPushOption.OPTION_NAME, noteDbPushOption);
        if (!Optional.of(NoteDbPushOption.ALLOW).equals(noteDbPushOption)) {
            // Only reject this command, not the whole push. This supports the use case of "git clone
            // --mirror" followed by "git push --mirror", when the user doesn't really intend to clone
            // or mirror the NoteDb data; there is no single refspec that describes all refs *except*
            // NoteDb refs.
            reject(cmd, "NoteDb update requires -o " + NoteDbPushOption.OPTION_NAME + "=" + NoteDbPushOption.ALLOW.value());
            return;
        }
        try {
            permissionBackend.user(user).check(GlobalPermission.ACCESS_DATABASE);
        } catch (AuthException e) {
            reject(cmd, "NoteDb update requires access database permission");
            return;
        }
    }
    switch(cmd.getType()) {
        case CREATE:
            parseCreate(cmd);
            break;
        case UPDATE:
            parseUpdate(cmd);
            break;
        case DELETE:
            parseDelete(cmd);
            break;
        case UPDATE_NONFASTFORWARD:
            parseRewind(cmd);
            break;
        default:
            reject(cmd, "prohibited by Gerrit: unknown command type " + cmd.getType());
            return;
    }
    if (cmd.getResult() != NOT_ATTEMPTED) {
        return;
    }
    if (isConfig(cmd)) {
        logger.atFine().log("Processing %s command", cmd.getRefName());
        try {
            permissions.check(ProjectPermission.WRITE_CONFIG);
        } catch (AuthException e) {
            reject(cmd, String.format("must be either project owner or have %s permission", ProjectPermission.WRITE_CONFIG.describeForException()));
            return;
        }
        switch(cmd.getType()) {
            case CREATE:
            case UPDATE:
            case UPDATE_NONFASTFORWARD:
                try {
                    ProjectConfig cfg = new ProjectConfig(project.getNameKey());
                    cfg.load(project.getNameKey(), receivePack.getRevWalk(), cmd.getNewId());
                    if (!cfg.getValidationErrors().isEmpty()) {
                        addError("Invalid project configuration:");
                        for (ValidationError err : cfg.getValidationErrors()) {
                            addError("  " + err.getMessage());
                        }
                        reject(cmd, "invalid project configuration");
                        logger.atSevere().log("User %s tried to push invalid project configuration %s for %s", user.getLoggableName(), cmd.getNewId().name(), project.getName());
                        return;
                    }
                    Project.NameKey newParent = cfg.getProject().getParent(allProjectsName);
                    Project.NameKey oldParent = project.getParent(allProjectsName);
                    if (oldParent == null) {
                        // update of the 'All-Projects' project
                        if (newParent != null) {
                            reject(cmd, "invalid project configuration: root project cannot have parent");
                            return;
                        }
                    } else {
                        if (!oldParent.equals(newParent)) {
                            if (allowProjectOwnersToChangeParent) {
                                try {
                                    permissionBackend.user(user).project(project.getNameKey()).check(ProjectPermission.WRITE_CONFIG);
                                } catch (AuthException e) {
                                    reject(cmd, "invalid project configuration: only project owners can set parent");
                                    return;
                                }
                            } else {
                                try {
                                    permissionBackend.user(user).check(GlobalPermission.ADMINISTRATE_SERVER);
                                } catch (AuthException e) {
                                    reject(cmd, "invalid project configuration: only Gerrit admin can set parent");
                                    return;
                                }
                            }
                        }
                        if (projectCache.get(newParent) == null) {
                            reject(cmd, "invalid project configuration: parent does not exist");
                            return;
                        }
                    }
                    for (Entry<ProjectConfigEntry> e : pluginConfigEntries) {
                        PluginConfig pluginCfg = cfg.getPluginConfig(e.getPluginName());
                        ProjectConfigEntry configEntry = e.getProvider().get();
                        String value = pluginCfg.getString(e.getExportName());
                        String oldValue = projectState.getConfig().getPluginConfig(e.getPluginName()).getString(e.getExportName());
                        if (configEntry.getType() == ProjectConfigEntryType.ARRAY) {
                            oldValue = Arrays.stream(projectState.getConfig().getPluginConfig(e.getPluginName()).getStringList(e.getExportName())).collect(joining("\n"));
                        }
                        if ((value == null ? oldValue != null : !value.equals(oldValue)) && !configEntry.isEditable(projectState)) {
                            reject(cmd, String.format("invalid project configuration: Not allowed to set parameter" + " '%s' of plugin '%s' on project '%s'.", e.getExportName(), e.getPluginName(), project.getName()));
                            continue;
                        }
                        if (ProjectConfigEntryType.LIST.equals(configEntry.getType()) && value != null && !configEntry.getPermittedValues().contains(value)) {
                            reject(cmd, String.format("invalid project configuration: The value '%s' is " + "not permitted for parameter '%s' of plugin '%s'.", value, e.getExportName(), e.getPluginName()));
                        }
                    }
                } catch (Exception e) {
                    reject(cmd, "invalid project configuration");
                    logger.atSevere().withCause(e).log("User %s tried to push invalid project configuration %s for %s", user.getLoggableName(), cmd.getNewId().name(), project.getName());
                    return;
                }
                break;
            case DELETE:
                break;
            default:
                reject(cmd, "prohibited by Gerrit: don't know how to handle config update of type " + cmd.getType());
        }
    }
}
#end_block

#method_before
public void validateParentUpdate(Project.NameKey project, IdentifiedUser user, String newParent, boolean checkIfAdmin) throws AuthException, ResourceConflictException, UnprocessableEntityException, PermissionBackendException, BadRequestException {
    if (checkIfAdmin && !allowProjectOwnersToChangeParent) {
        permissionBackend.user(user).check(GlobalPermission.ADMINISTRATE_SERVER);
    }
    if (project.equals(allUsers) && !allProjects.get().equals(newParent)) {
        throw new BadRequestException(String.format("%s must inherit from %s", allUsers.get(), allProjects.get()));
    }
    if (project.equals(allProjects)) {
        throw new ResourceConflictException("cannot set parent of " + allProjects.get());
    }
    if (allUsers.get().equals(newParent)) {
        throw new ResourceConflictException(String.format("Cannot inherit from '%s' project", allUsers.get()));
    }
    newParent = Strings.emptyToNull(newParent);
    if (newParent != null) {
        ProjectState parent = cache.get(new Project.NameKey(newParent));
        if (parent == null) {
            throw new UnprocessableEntityException("parent project " + newParent + " not found");
        }
        if (parent.getName().equals(project.get())) {
            throw new ResourceConflictException("cannot set parent to self");
        }
        if (Iterables.tryFind(parent.tree(), p -> {
            return p.getNameKey().equals(project);
        }).isPresent()) {
            throw new ResourceConflictException("cycle exists between " + project.get() + " and " + parent.getName());
        }
    }
}
#method_after
public void validateParentUpdate(Project.NameKey project, IdentifiedUser user, String newParent, boolean checkIfAdmin) throws AuthException, ResourceConflictException, UnprocessableEntityException, PermissionBackendException, BadRequestException {
    if (checkIfAdmin) {
        if (allowProjectOwnersToChangeParent) {
            permissionBackend.user(user).project(project).check(ProjectPermission.WRITE_CONFIG);
        } else {
            permissionBackend.user(user).check(GlobalPermission.ADMINISTRATE_SERVER);
        }
    }
    if (project.equals(allUsers) && !allProjects.get().equals(newParent)) {
        throw new BadRequestException(String.format("%s must inherit from %s", allUsers.get(), allProjects.get()));
    }
    if (project.equals(allProjects)) {
        throw new ResourceConflictException("cannot set parent of " + allProjects.get());
    }
    if (allUsers.get().equals(newParent)) {
        throw new ResourceConflictException(String.format("Cannot inherit from '%s' project", allUsers.get()));
    }
    newParent = Strings.emptyToNull(newParent);
    if (newParent != null) {
        ProjectState parent = cache.get(new Project.NameKey(newParent));
        if (parent == null) {
            throw new UnprocessableEntityException("parent project " + newParent + " not found");
        }
        if (parent.getName().equals(project.get())) {
            throw new ResourceConflictException("cannot set parent to self");
        }
        if (Iterables.tryFind(parent.tree(), p -> {
            return p.getNameKey().equals(project);
        }).isPresent()) {
            throw new ResourceConflictException("cycle exists between " + project.get() + " and " + parent.getName());
        }
    }
}
#end_block

#method_before
@Override
public void onPreMerge(final Repository repo, final CodeReviewCommit commit, final ProjectState destProject, final Branch.NameKey destBranch, final PatchSet.Id patchSetId, IdentifiedUser caller) throws MergeValidationException {
    if (RefNames.REFS_CONFIG.equals(destBranch.get())) {
        final Project.NameKey newParent;
        try {
            ProjectConfig cfg = new ProjectConfig(destProject.getNameKey());
            cfg.load(repo, commit);
            newParent = cfg.getProject().getParent(allProjectsName);
            final Project.NameKey oldParent = destProject.getProject().getParent(allProjectsName);
            if (oldParent == null) {
                // update of the 'All-Projects' project
                if (newParent != null) {
                    throw new MergeValidationException(ROOT_NO_PARENT);
                }
            } else {
                if (!oldParent.equals(newParent)) {
                    if (!allowProjectOwnersToChangeParent) {
                        try {
                            permissionBackend.user(caller).check(GlobalPermission.ADMINISTRATE_SERVER);
                        } catch (AuthException e) {
                            throw new MergeValidationException(SET_BY_ADMIN);
                        } catch (PermissionBackendException e) {
                            logger.atWarning().withCause(e).log("Cannot check ADMINISTRATE_SERVER");
                            throw new MergeValidationException("validation unavailable");
                        }
                    }
                    if (allUsersName.equals(destProject.getNameKey()) && !allProjectsName.equals(newParent)) {
                        throw new MergeValidationException(String.format(" %s must inherit from %s", allUsersName.get(), allProjectsName.get()));
                    }
                    if (projectCache.get(newParent) == null) {
                        throw new MergeValidationException(PARENT_NOT_FOUND);
                    }
                }
            }
            for (Entry<ProjectConfigEntry> e : pluginConfigEntries) {
                PluginConfig pluginCfg = cfg.getPluginConfig(e.getPluginName());
                ProjectConfigEntry configEntry = e.getProvider().get();
                String value = pluginCfg.getString(e.getExportName());
                String oldValue = destProject.getConfig().getPluginConfig(e.getPluginName()).getString(e.getExportName());
                if ((value == null ? oldValue != null : !value.equals(oldValue)) && !configEntry.isEditable(destProject)) {
                    throw new MergeValidationException(PLUGIN_VALUE_NOT_EDITABLE);
                }
                if (ProjectConfigEntryType.LIST.equals(configEntry.getType()) && value != null && !configEntry.getPermittedValues().contains(value)) {
                    throw new MergeValidationException(PLUGIN_VALUE_NOT_PERMITTED);
                }
            }
        } catch (ConfigInvalidException | IOException e) {
            throw new MergeValidationException(INVALID_CONFIG);
        }
    }
}
#method_after
@Override
public void onPreMerge(final Repository repo, final CodeReviewCommit commit, final ProjectState destProject, final Branch.NameKey destBranch, final PatchSet.Id patchSetId, IdentifiedUser caller) throws MergeValidationException {
    if (RefNames.REFS_CONFIG.equals(destBranch.get())) {
        final Project.NameKey newParent;
        try {
            ProjectConfig cfg = new ProjectConfig(destProject.getNameKey());
            cfg.load(repo, commit);
            newParent = cfg.getProject().getParent(allProjectsName);
            final Project.NameKey oldParent = destProject.getProject().getParent(allProjectsName);
            if (oldParent == null) {
                // update of the 'All-Projects' project
                if (newParent != null) {
                    throw new MergeValidationException(ROOT_NO_PARENT);
                }
            } else {
                if (!oldParent.equals(newParent)) {
                    if (!allowProjectOwnersToChangeParent) {
                        try {
                            permissionBackend.user(caller).check(GlobalPermission.ADMINISTRATE_SERVER);
                        } catch (AuthException e) {
                            throw new MergeValidationException(SET_BY_ADMIN);
                        } catch (PermissionBackendException e) {
                            logger.atWarning().withCause(e).log("Cannot check ADMINISTRATE_SERVER");
                            throw new MergeValidationException("validation unavailable");
                        }
                    } else {
                        try {
                            permissionBackend.user(caller).project(destProject.getNameKey()).check(ProjectPermission.WRITE_CONFIG);
                        } catch (AuthException e) {
                            throw new MergeValidationException(SET_BY_OWNER);
                        } catch (PermissionBackendException e) {
                            logger.atWarning().withCause(e).log("Cannot check WRITE_CONFIG");
                            throw new MergeValidationException("validation unavailable");
                        }
                    }
                    if (allUsersName.equals(destProject.getNameKey()) && !allProjectsName.equals(newParent)) {
                        throw new MergeValidationException(String.format(" %s must inherit from %s", allUsersName.get(), allProjectsName.get()));
                    }
                    if (projectCache.get(newParent) == null) {
                        throw new MergeValidationException(PARENT_NOT_FOUND);
                    }
                }
            }
            for (Entry<ProjectConfigEntry> e : pluginConfigEntries) {
                PluginConfig pluginCfg = cfg.getPluginConfig(e.getPluginName());
                ProjectConfigEntry configEntry = e.getProvider().get();
                String value = pluginCfg.getString(e.getExportName());
                String oldValue = destProject.getConfig().getPluginConfig(e.getPluginName()).getString(e.getExportName());
                if ((value == null ? oldValue != null : !value.equals(oldValue)) && !configEntry.isEditable(destProject)) {
                    throw new MergeValidationException(PLUGIN_VALUE_NOT_EDITABLE);
                }
                if (ProjectConfigEntryType.LIST.equals(configEntry.getType()) && value != null && !configEntry.getPermittedValues().contains(value)) {
                    throw new MergeValidationException(PLUGIN_VALUE_NOT_PERMITTED);
                }
            }
        } catch (ConfigInvalidException | IOException e) {
            throw new MergeValidationException(INVALID_CONFIG);
        }
    }
}
#end_block

#method_before
void processCommands(Collection<ReceiveCommand> commands, MultiProgressMonitor progress) {
    Task commandProgress = progress.beginSubTask("refs", UNKNOWN);
    commands = commands.stream().map(c -> wrapReceiveCommand(c, commandProgress)).collect(toList());
    processCommandsUnsafe(commands, progress);
    for (ReceiveCommand cmd : commands) {
        if (cmd.getResult() == NOT_ATTEMPTED) {
            cmd.setResult(REJECTED_OTHER_REASON, "internal server error");
        }
    }
    // This has to be done before terminating progress, or the test framework will get confused.
    sendErrorMessages();
    commandProgress.end();
    progress.end();
    // Update account info with details discovered during commit walking. The account update happens
    // in a separate batch update, and failure doesn't cause the push itself to fail.
    updateAccountInfo();
}
#method_after
void processCommands(Collection<ReceiveCommand> commands, MultiProgressMonitor progress) {
    Task commandProgress = progress.beginSubTask("refs", UNKNOWN);
    commands = commands.stream().map(c -> wrapReceiveCommand(c, commandProgress)).collect(toList());
    processCommandsUnsafe(commands, progress);
    for (ReceiveCommand cmd : commands) {
        if (cmd.getResult() == NOT_ATTEMPTED) {
            cmd.setResult(REJECTED_OTHER_REASON, "internal server error");
        }
    }
    // This sends error messages before the 'done' string of the progress monitor is sent.
    // Currently, the test framework relies on this ordering to understand if pushes completed
    // successfully.
    sendErrorMessages();
    commandProgress.end();
    progress.end();
    // Update account info with details discovered during commit walking. The account update happens
    // in a separate batch update, and failure doesn't cause the push itself to fail.
    updateAccountInfo();
}
#end_block

#method_before
private void processCommandsUnsafe(Collection<ReceiveCommand> commands, MultiProgressMonitor progress) {
    parsePushOptions();
    try (TraceContext traceContext = TraceContext.open().addTag(RequestId.Type.RECEIVE_ID, RequestId.forProject(project.getNameKey()))) {
        if (tracePushOption.orElse(false)) {
            RequestId traceId = new RequestId();
            traceContext.addTag(RequestId.Type.TRACE_ID, traceId);
            addMessage(RequestId.Type.TRACE_ID.name() + ": " + traceId);
        }
        try {
            if (!projectState.getProject().getState().permitsWrite()) {
                for (ReceiveCommand cmd : commands) {
                    reject(cmd, "prohibited by Gerrit: project state does not permit write");
                }
                return;
            }
            logger.atFine().log("Parsing %d commands", commands.size());
            List<ReceiveCommand> magicCommands = new ArrayList<>();
            List<ReceiveCommand> directPatchSetPushCommands = new ArrayList<>();
            List<ReceiveCommand> regularCommands = new ArrayList<>();
            for (ReceiveCommand cmd : commands) {
                if (MagicBranch.isMagicBranch(cmd.getRefName())) {
                    magicCommands.add(cmd);
                } else if (isDirectChangesPush(cmd.getRefName())) {
                    directPatchSetPushCommands.add(cmd);
                } else {
                    regularCommands.add(cmd);
                }
            }
            int commandTypes = (magicCommands.isEmpty() ? 0 : 1) + (directPatchSetPushCommands.isEmpty() ? 0 : 1) + (regularCommands.isEmpty() ? 0 : 1);
            if (commandTypes > 1) {
                for (ReceiveCommand cmd : commands) {
                    if (cmd.getResult() == NOT_ATTEMPTED) {
                        cmd.setResult(REJECTED_OTHER_REASON, "cannot combine normal pushes and magic pushes");
                    }
                }
                return;
            }
            if (!regularCommands.isEmpty()) {
                handleRegularCommands(regularCommands, progress);
                return;
            }
            for (ReceiveCommand cmd : directPatchSetPushCommands) {
                parseDirectChangesPush(cmd);
            }
            boolean first = true;
            for (ReceiveCommand cmd : magicCommands) {
                if (first) {
                    parseMagicBranch(cmd);
                    first = false;
                } else {
                    reject(cmd, "duplicate request");
                }
            }
        } catch (PermissionBackendException | NoSuchProjectException | IOException err) {
            logger.atSevere().withCause(err).log("Failed to process refs in %s", project.getName());
            return;
        }
        Task newProgress = progress.beginSubTask("new", UNKNOWN);
        Task replaceProgress = progress.beginSubTask("updated", UNKNOWN);
        List<CreateRequest> newChanges = Collections.emptyList();
        if (magicBranch != null && magicBranch.cmd.getResult() == NOT_ATTEMPTED) {
            newChanges = selectNewAndReplacedChangesFromMagicBranch(newProgress);
        }
        preparePatchSetsForReplace(newChanges);
        insertChangesAndPatchSets(newChanges, replaceProgress);
        newProgress.end();
        replaceProgress.end();
        queueSuccessMessages(newChanges);
        refsPublishDeprecationWarning();
    }
}
#method_after
private void processCommandsUnsafe(Collection<ReceiveCommand> commands, MultiProgressMonitor progress) {
    parsePushOptions();
    try (TraceContext traceContext = TraceContext.open().addTag(RequestId.Type.RECEIVE_ID, RequestId.forProject(project.getNameKey()))) {
        if (tracePushOption.orElse(false)) {
            RequestId traceId = new RequestId();
            traceContext.forceLogging().addTag(RequestId.Type.TRACE_ID, traceId);
            addMessage(RequestId.Type.TRACE_ID.name() + ": " + traceId);
        }
        try {
            if (!projectState.getProject().getState().permitsWrite()) {
                for (ReceiveCommand cmd : commands) {
                    reject(cmd, "prohibited by Gerrit: project state does not permit write");
                }
                return;
            }
            logger.atFine().log("Parsing %d commands", commands.size());
            List<ReceiveCommand> magicCommands = new ArrayList<>();
            List<ReceiveCommand> directPatchSetPushCommands = new ArrayList<>();
            List<ReceiveCommand> regularCommands = new ArrayList<>();
            for (ReceiveCommand cmd : commands) {
                if (MagicBranch.isMagicBranch(cmd.getRefName())) {
                    magicCommands.add(cmd);
                } else if (isDirectChangesPush(cmd.getRefName())) {
                    directPatchSetPushCommands.add(cmd);
                } else {
                    regularCommands.add(cmd);
                }
            }
            int commandTypes = (magicCommands.isEmpty() ? 0 : 1) + (directPatchSetPushCommands.isEmpty() ? 0 : 1) + (regularCommands.isEmpty() ? 0 : 1);
            if (commandTypes > 1) {
                for (ReceiveCommand cmd : commands) {
                    if (cmd.getResult() == NOT_ATTEMPTED) {
                        cmd.setResult(REJECTED_OTHER_REASON, "cannot combine normal pushes and magic pushes");
                    }
                }
                return;
            }
            if (!regularCommands.isEmpty()) {
                handleRegularCommands(regularCommands, progress);
                return;
            }
            for (ReceiveCommand cmd : directPatchSetPushCommands) {
                parseDirectChangesPush(cmd);
            }
            boolean first = true;
            for (ReceiveCommand cmd : magicCommands) {
                if (first) {
                    parseMagicBranch(cmd);
                    first = false;
                } else {
                    reject(cmd, "duplicate request");
                }
            }
        } catch (PermissionBackendException | NoSuchProjectException | IOException err) {
            logger.atSevere().withCause(err).log("Failed to process refs in %s", project.getName());
            return;
        }
        Task newProgress = progress.beginSubTask("new", UNKNOWN);
        Task replaceProgress = progress.beginSubTask("updated", UNKNOWN);
        List<CreateRequest> newChanges = Collections.emptyList();
        if (magicBranch != null && magicBranch.cmd.getResult() == NOT_ATTEMPTED) {
            newChanges = selectNewAndReplacedChangesFromMagicBranch(newProgress);
        }
        preparePatchSetsForReplace(newChanges);
        insertChangesAndPatchSets(newChanges, replaceProgress);
        newProgress.end();
        replaceProgress.end();
        queueSuccessMessages(newChanges);
        refsPublishDeprecationWarning();
    }
}
#end_block

#method_before
private void parseRegularCommand(ReceiveCommand cmd) throws PermissionBackendException, NoSuchProjectException, IOException {
    if (cmd.getResult() != NOT_ATTEMPTED) {
        // Already rejected by the core receive process.
        logger.atFine().log("Already processed by core: %s %s", cmd.getResult(), cmd);
        return;
    }
    if (!Repository.isValidRefName(cmd.getRefName()) || cmd.getRefName().contains("//")) {
        reject(cmd, "not valid ref");
        return;
    }
    if (RefNames.isNoteDbMetaRef(cmd.getRefName())) {
        // Reject pushes to NoteDb refs without a special option and permission. Note that this
        // prohibition doesn't depend on NoteDb being enabled in any way, since all sites will
        // migrate to NoteDb eventually, and we don't want garbage data waiting there when the
        // migration finishes.
        logger.atFine().log("%s NoteDb ref %s with %s=%s", cmd.getType(), cmd.getRefName(), NoteDbPushOption.OPTION_NAME, noteDbPushOption);
        if (!Optional.of(NoteDbPushOption.ALLOW).equals(noteDbPushOption)) {
            // Only reject this command, not the whole push. This supports the use case of "git clone
            // --mirror" followed by "git push --mirror", when the user doesn't really intend to clone
            // or mirror the NoteDb data; there is no single refspec that describes all refs *except*
            // NoteDb refs.
            reject(cmd, "NoteDb update requires -o " + NoteDbPushOption.OPTION_NAME + "=" + NoteDbPushOption.ALLOW.value());
            return;
        }
        try {
            permissionBackend.user(user).check(GlobalPermission.ACCESS_DATABASE);
        } catch (AuthException e) {
            reject(cmd, "NoteDb update requires access database permission");
            return;
        }
    }
    switch(cmd.getType()) {
        case CREATE:
            parseCreate(cmd);
            break;
        case UPDATE:
            parseUpdate(cmd);
            break;
        case DELETE:
            parseDelete(cmd);
            break;
        case UPDATE_NONFASTFORWARD:
            parseRewind(cmd);
            break;
        default:
            reject(cmd, "prohibited by Gerrit: unknown command type " + cmd.getType());
            return;
    }
    if (cmd.getResult() != NOT_ATTEMPTED) {
        return;
    }
    if (isConfig(cmd)) {
        logger.atFine().log("Processing %s command", cmd.getRefName());
        try {
            permissions.check(ProjectPermission.WRITE_CONFIG);
        } catch (AuthException e) {
            reject(cmd, String.format("must be either project owner or have %s permission", ProjectPermission.WRITE_CONFIG.describeForException()));
            return;
        }
        switch(cmd.getType()) {
            case CREATE:
            case UPDATE:
            case UPDATE_NONFASTFORWARD:
                try {
                    ProjectConfig cfg = new ProjectConfig(project.getNameKey());
                    cfg.load(receivePack.getRevWalk(), cmd.getNewId());
                    if (!cfg.getValidationErrors().isEmpty()) {
                        addError("Invalid project configuration:");
                        for (ValidationError err : cfg.getValidationErrors()) {
                            addError("  " + err.getMessage());
                        }
                        reject(cmd, "invalid project configuration");
                        logger.atSevere().log("User %s tried to push invalid project configuration %s for %s", user.getLoggableName(), cmd.getNewId().name(), project.getName());
                        return;
                    }
                    Project.NameKey newParent = cfg.getProject().getParent(allProjectsName);
                    Project.NameKey oldParent = project.getParent(allProjectsName);
                    if (oldParent == null) {
                        // update of the 'All-Projects' project
                        if (newParent != null) {
                            reject(cmd, "invalid project configuration: root project cannot have parent");
                            return;
                        }
                    } else {
                        if (!oldParent.equals(newParent)) {
                            try {
                                permissionBackend.user(user).check(GlobalPermission.ADMINISTRATE_SERVER);
                            } catch (AuthException e) {
                                reject(cmd, "invalid project configuration: only Gerrit admin can set parent");
                                return;
                            }
                        }
                        if (projectCache.get(newParent) == null) {
                            reject(cmd, "invalid project configuration: parent does not exist");
                            return;
                        }
                    }
                    for (Entry<ProjectConfigEntry> e : pluginConfigEntries) {
                        PluginConfig pluginCfg = cfg.getPluginConfig(e.getPluginName());
                        ProjectConfigEntry configEntry = e.getProvider().get();
                        String value = pluginCfg.getString(e.getExportName());
                        String oldValue = projectState.getConfig().getPluginConfig(e.getPluginName()).getString(e.getExportName());
                        if (configEntry.getType() == ProjectConfigEntryType.ARRAY) {
                            oldValue = Arrays.stream(projectState.getConfig().getPluginConfig(e.getPluginName()).getStringList(e.getExportName())).collect(joining("\n"));
                        }
                        if ((value == null ? oldValue != null : !value.equals(oldValue)) && !configEntry.isEditable(projectState)) {
                            reject(cmd, String.format("invalid project configuration: Not allowed to set parameter" + " '%s' of plugin '%s' on project '%s'.", e.getExportName(), e.getPluginName(), project.getName()));
                            continue;
                        }
                        if (ProjectConfigEntryType.LIST.equals(configEntry.getType()) && value != null && !configEntry.getPermittedValues().contains(value)) {
                            reject(cmd, String.format("invalid project configuration: The value '%s' is " + "not permitted for parameter '%s' of plugin '%s'.", value, e.getExportName(), e.getPluginName()));
                        }
                    }
                } catch (Exception e) {
                    reject(cmd, "invalid project configuration");
                    logger.atSevere().withCause(e).log("User %s tried to push invalid project configuration %s for %s", user.getLoggableName(), cmd.getNewId().name(), project.getName());
                    return;
                }
                break;
            case DELETE:
                break;
            default:
                reject(cmd, "prohibited by Gerrit: don't know how to handle config update of type " + cmd.getType());
        }
    }
}
#method_after
private void parseRegularCommand(ReceiveCommand cmd) throws PermissionBackendException, NoSuchProjectException, IOException {
    if (cmd.getResult() != NOT_ATTEMPTED) {
        // Already rejected by the core receive process.
        logger.atFine().log("Already processed by core: %s %s", cmd.getResult(), cmd);
        return;
    }
    if (!Repository.isValidRefName(cmd.getRefName()) || cmd.getRefName().contains("//")) {
        reject(cmd, "not valid ref");
        return;
    }
    if (RefNames.isNoteDbMetaRef(cmd.getRefName())) {
        // Reject pushes to NoteDb refs without a special option and permission. Note that this
        // prohibition doesn't depend on NoteDb being enabled in any way, since all sites will
        // migrate to NoteDb eventually, and we don't want garbage data waiting there when the
        // migration finishes.
        logger.atFine().log("%s NoteDb ref %s with %s=%s", cmd.getType(), cmd.getRefName(), NoteDbPushOption.OPTION_NAME, noteDbPushOption);
        if (!Optional.of(NoteDbPushOption.ALLOW).equals(noteDbPushOption)) {
            // Only reject this command, not the whole push. This supports the use case of "git clone
            // --mirror" followed by "git push --mirror", when the user doesn't really intend to clone
            // or mirror the NoteDb data; there is no single refspec that describes all refs *except*
            // NoteDb refs.
            reject(cmd, "NoteDb update requires -o " + NoteDbPushOption.OPTION_NAME + "=" + NoteDbPushOption.ALLOW.value());
            return;
        }
        try {
            permissionBackend.user(user).check(GlobalPermission.ACCESS_DATABASE);
        } catch (AuthException e) {
            reject(cmd, "NoteDb update requires access database permission");
            return;
        }
    }
    switch(cmd.getType()) {
        case CREATE:
            parseCreate(cmd);
            break;
        case UPDATE:
            parseUpdate(cmd);
            break;
        case DELETE:
            parseDelete(cmd);
            break;
        case UPDATE_NONFASTFORWARD:
            parseRewind(cmd);
            break;
        default:
            reject(cmd, "prohibited by Gerrit: unknown command type " + cmd.getType());
            return;
    }
    if (cmd.getResult() != NOT_ATTEMPTED) {
        return;
    }
    if (isConfig(cmd)) {
        logger.atFine().log("Processing %s command", cmd.getRefName());
        try {
            permissions.check(ProjectPermission.WRITE_CONFIG);
        } catch (AuthException e) {
            reject(cmd, String.format("must be either project owner or have %s permission", ProjectPermission.WRITE_CONFIG.describeForException()));
            return;
        }
        switch(cmd.getType()) {
            case CREATE:
            case UPDATE:
            case UPDATE_NONFASTFORWARD:
                try {
                    ProjectConfig cfg = new ProjectConfig(project.getNameKey());
                    cfg.load(project.getNameKey(), receivePack.getRevWalk(), cmd.getNewId());
                    if (!cfg.getValidationErrors().isEmpty()) {
                        addError("Invalid project configuration:");
                        for (ValidationError err : cfg.getValidationErrors()) {
                            addError("  " + err.getMessage());
                        }
                        reject(cmd, "invalid project configuration");
                        logger.atSevere().log("User %s tried to push invalid project configuration %s for %s", user.getLoggableName(), cmd.getNewId().name(), project.getName());
                        return;
                    }
                    Project.NameKey newParent = cfg.getProject().getParent(allProjectsName);
                    Project.NameKey oldParent = project.getParent(allProjectsName);
                    if (oldParent == null) {
                        // update of the 'All-Projects' project
                        if (newParent != null) {
                            reject(cmd, "invalid project configuration: root project cannot have parent");
                            return;
                        }
                    } else {
                        if (!oldParent.equals(newParent)) {
                            try {
                                permissionBackend.user(user).check(GlobalPermission.ADMINISTRATE_SERVER);
                            } catch (AuthException e) {
                                reject(cmd, "invalid project configuration: only Gerrit admin can set parent");
                                return;
                            }
                        }
                        if (projectCache.get(newParent) == null) {
                            reject(cmd, "invalid project configuration: parent does not exist");
                            return;
                        }
                    }
                    for (Entry<ProjectConfigEntry> e : pluginConfigEntries) {
                        PluginConfig pluginCfg = cfg.getPluginConfig(e.getPluginName());
                        ProjectConfigEntry configEntry = e.getProvider().get();
                        String value = pluginCfg.getString(e.getExportName());
                        String oldValue = projectState.getConfig().getPluginConfig(e.getPluginName()).getString(e.getExportName());
                        if (configEntry.getType() == ProjectConfigEntryType.ARRAY) {
                            oldValue = Arrays.stream(projectState.getConfig().getPluginConfig(e.getPluginName()).getStringList(e.getExportName())).collect(joining("\n"));
                        }
                        if ((value == null ? oldValue != null : !value.equals(oldValue)) && !configEntry.isEditable(projectState)) {
                            reject(cmd, String.format("invalid project configuration: Not allowed to set parameter" + " '%s' of plugin '%s' on project '%s'.", e.getExportName(), e.getPluginName(), project.getName()));
                            continue;
                        }
                        if (ProjectConfigEntryType.LIST.equals(configEntry.getType()) && value != null && !configEntry.getPermittedValues().contains(value)) {
                            reject(cmd, String.format("invalid project configuration: The value '%s' is " + "not permitted for parameter '%s' of plugin '%s'.", value, e.getExportName(), e.getPluginName()));
                        }
                    }
                } catch (Exception e) {
                    reject(cmd, "invalid project configuration");
                    logger.atSevere().withCause(e).log("User %s tried to push invalid project configuration %s for %s", user.getLoggableName(), cmd.getNewId().name(), project.getName());
                    return;
                }
                break;
            case DELETE:
                break;
            default:
                reject(cmd, "prohibited by Gerrit: don't know how to handle config update of type " + cmd.getType());
        }
    }
}
#end_block

#method_before
void processCommands(Collection<ReceiveCommand> commands, MultiProgressMonitor progress) {
    Task commandProgress = progress.beginSubTask("refs", UNKNOWN);
    commands = commands.stream().map(c -> wrapReceiveCommand(c, commandProgress)).collect(toList());
    processCommandsUnsafe(commands, progress);
    for (ReceiveCommand cmd : commands) {
        if (cmd.getResult() == NOT_ATTEMPTED) {
            cmd.setResult(REJECTED_OTHER_REASON, "internal server error");
        }
    }
    // This has to be done before terminating progress, or the test framework will get confused.
    sendErrorMessages();
    commandProgress.end();
    progress.end();
    // Update account info with details discovered during commit walking. The account update happens
    // in a separate batch update, and failure doesn't cause the push itself to fail.
    updateAccountInfo();
}
#method_after
void processCommands(Collection<ReceiveCommand> commands, MultiProgressMonitor progress) {
    Task commandProgress = progress.beginSubTask("refs", UNKNOWN);
    commands = commands.stream().map(c -> wrapReceiveCommand(c, commandProgress)).collect(toList());
    processCommandsUnsafe(commands, progress);
    for (ReceiveCommand cmd : commands) {
        if (cmd.getResult() == NOT_ATTEMPTED) {
            cmd.setResult(REJECTED_OTHER_REASON, "internal server error");
        }
    }
    // This sends error messages before the 'done' string of the progress monitor is sent.
    // Currently, the test framework relies on this ordering to understand if pushes completed
    // successfully.
    sendErrorMessages();
    commandProgress.end();
    progress.end();
    // Update account info with details discovered during commit walking. The account update happens
    // in a separate batch update, and failure doesn't cause the push itself to fail.
    updateAccountInfo();
}
#end_block

#method_before
private void processCommandsUnsafe(Collection<ReceiveCommand> commands, MultiProgressMonitor progress) {
    parsePushOptions();
    try (TraceContext traceContext = TraceContext.open().addTag(RequestId.Type.RECEIVE_ID, RequestId.forProject(project.getNameKey()))) {
        if (tracePushOption.orElse(false)) {
            RequestId traceId = new RequestId();
            traceContext.addTag(RequestId.Type.TRACE_ID, traceId);
            addMessage(RequestId.Type.TRACE_ID.name() + ": " + traceId);
        }
        try {
            if (!projectState.getProject().getState().permitsWrite()) {
                for (ReceiveCommand cmd : commands) {
                    reject(cmd, "prohibited by Gerrit: project state does not permit write");
                }
                return;
            }
            logger.atFine().log("Parsing %d commands", commands.size());
            List<ReceiveCommand> magicCommands = new ArrayList<>();
            List<ReceiveCommand> directPatchSetPushCommands = new ArrayList<>();
            List<ReceiveCommand> regularCommands = new ArrayList<>();
            for (ReceiveCommand cmd : commands) {
                if (MagicBranch.isMagicBranch(cmd.getRefName())) {
                    magicCommands.add(cmd);
                } else if (isDirectChangesPush(cmd.getRefName())) {
                    directPatchSetPushCommands.add(cmd);
                } else {
                    regularCommands.add(cmd);
                }
            }
            int commandTypes = (magicCommands.isEmpty() ? 0 : 1) + (directPatchSetPushCommands.isEmpty() ? 0 : 1) + (regularCommands.isEmpty() ? 0 : 1);
            if (commandTypes > 1) {
                for (ReceiveCommand cmd : commands) {
                    if (cmd.getResult() == NOT_ATTEMPTED) {
                        cmd.setResult(REJECTED_OTHER_REASON, "cannot combine normal pushes and magic pushes");
                    }
                }
                return;
            }
            if (!regularCommands.isEmpty()) {
                handleRegularCommands(regularCommands, progress);
                return;
            }
            for (ReceiveCommand cmd : directPatchSetPushCommands) {
                parseDirectChangesPush(cmd);
            }
            boolean first = true;
            for (ReceiveCommand cmd : magicCommands) {
                if (first) {
                    parseMagicBranch(cmd);
                    first = false;
                } else {
                    reject(cmd, "duplicate request");
                }
            }
        } catch (PermissionBackendException | NoSuchProjectException | IOException err) {
            logger.atSevere().withCause(err).log("Failed to process refs in %s", project.getName());
            return;
        }
        Task newProgress = progress.beginSubTask("new", UNKNOWN);
        Task replaceProgress = progress.beginSubTask("updated", UNKNOWN);
        List<CreateRequest> newChanges = Collections.emptyList();
        if (magicBranch != null && magicBranch.cmd.getResult() == NOT_ATTEMPTED) {
            newChanges = selectNewAndReplacedChangesFromMagicBranch(newProgress);
        }
        preparePatchSetsForReplace(newChanges);
        insertChangesAndPatchSets(newChanges, replaceProgress);
        newProgress.end();
        replaceProgress.end();
        reportMessages(newChanges);
    }
}
#method_after
private void processCommandsUnsafe(Collection<ReceiveCommand> commands, MultiProgressMonitor progress) {
    parsePushOptions();
    try (TraceContext traceContext = TraceContext.open().addTag(RequestId.Type.RECEIVE_ID, RequestId.forProject(project.getNameKey()))) {
        if (tracePushOption.orElse(false)) {
            RequestId traceId = new RequestId();
            traceContext.forceLogging().addTag(RequestId.Type.TRACE_ID, traceId);
            addMessage(RequestId.Type.TRACE_ID.name() + ": " + traceId);
        }
        try {
            if (!projectState.getProject().getState().permitsWrite()) {
                for (ReceiveCommand cmd : commands) {
                    reject(cmd, "prohibited by Gerrit: project state does not permit write");
                }
                return;
            }
            logger.atFine().log("Parsing %d commands", commands.size());
            List<ReceiveCommand> magicCommands = new ArrayList<>();
            List<ReceiveCommand> directPatchSetPushCommands = new ArrayList<>();
            List<ReceiveCommand> regularCommands = new ArrayList<>();
            for (ReceiveCommand cmd : commands) {
                if (MagicBranch.isMagicBranch(cmd.getRefName())) {
                    magicCommands.add(cmd);
                } else if (isDirectChangesPush(cmd.getRefName())) {
                    directPatchSetPushCommands.add(cmd);
                } else {
                    regularCommands.add(cmd);
                }
            }
            int commandTypes = (magicCommands.isEmpty() ? 0 : 1) + (directPatchSetPushCommands.isEmpty() ? 0 : 1) + (regularCommands.isEmpty() ? 0 : 1);
            if (commandTypes > 1) {
                for (ReceiveCommand cmd : commands) {
                    if (cmd.getResult() == NOT_ATTEMPTED) {
                        cmd.setResult(REJECTED_OTHER_REASON, "cannot combine normal pushes and magic pushes");
                    }
                }
                return;
            }
            if (!regularCommands.isEmpty()) {
                handleRegularCommands(regularCommands, progress);
                return;
            }
            for (ReceiveCommand cmd : directPatchSetPushCommands) {
                parseDirectChangesPush(cmd);
            }
            boolean first = true;
            for (ReceiveCommand cmd : magicCommands) {
                if (first) {
                    parseMagicBranch(cmd);
                    first = false;
                } else {
                    reject(cmd, "duplicate request");
                }
            }
        } catch (PermissionBackendException | NoSuchProjectException | IOException err) {
            logger.atSevere().withCause(err).log("Failed to process refs in %s", project.getName());
            return;
        }
        Task newProgress = progress.beginSubTask("new", UNKNOWN);
        Task replaceProgress = progress.beginSubTask("updated", UNKNOWN);
        List<CreateRequest> newChanges = Collections.emptyList();
        if (magicBranch != null && magicBranch.cmd.getResult() == NOT_ATTEMPTED) {
            newChanges = selectNewAndReplacedChangesFromMagicBranch(newProgress);
        }
        preparePatchSetsForReplace(newChanges);
        insertChangesAndPatchSets(newChanges, replaceProgress);
        newProgress.end();
        replaceProgress.end();
        reportMessages(newChanges);
    }
}
#end_block

#method_before
private void parseRegularCommand(ReceiveCommand cmd) throws PermissionBackendException, NoSuchProjectException, IOException {
    if (cmd.getResult() != NOT_ATTEMPTED) {
        // Already rejected by the core receive process.
        logger.atFine().log("Already processed by core: %s %s", cmd.getResult(), cmd);
        return;
    }
    if (!Repository.isValidRefName(cmd.getRefName()) || cmd.getRefName().contains("//")) {
        reject(cmd, "not valid ref");
        return;
    }
    if (RefNames.isNoteDbMetaRef(cmd.getRefName())) {
        // Reject pushes to NoteDb refs without a special option and permission. Note that this
        // prohibition doesn't depend on NoteDb being enabled in any way, since all sites will
        // migrate to NoteDb eventually, and we don't want garbage data waiting there when the
        // migration finishes.
        logger.atFine().log("%s NoteDb ref %s with %s=%s", cmd.getType(), cmd.getRefName(), NoteDbPushOption.OPTION_NAME, noteDbPushOption);
        if (!Optional.of(NoteDbPushOption.ALLOW).equals(noteDbPushOption)) {
            // Only reject this command, not the whole push. This supports the use case of "git clone
            // --mirror" followed by "git push --mirror", when the user doesn't really intend to clone
            // or mirror the NoteDb data; there is no single refspec that describes all refs *except*
            // NoteDb refs.
            reject(cmd, "NoteDb update requires -o " + NoteDbPushOption.OPTION_NAME + "=" + NoteDbPushOption.ALLOW.value());
            return;
        }
        try {
            permissionBackend.user(user).check(GlobalPermission.ACCESS_DATABASE);
        } catch (AuthException e) {
            reject(cmd, "NoteDb update requires access database permission");
            return;
        }
    }
    switch(cmd.getType()) {
        case CREATE:
            parseCreate(cmd);
            break;
        case UPDATE:
            parseUpdate(cmd);
            break;
        case DELETE:
            parseDelete(cmd);
            break;
        case UPDATE_NONFASTFORWARD:
            parseRewind(cmd);
            break;
        default:
            reject(cmd, "prohibited by Gerrit: unknown command type " + cmd.getType());
            return;
    }
    if (cmd.getResult() != NOT_ATTEMPTED) {
        return;
    }
    if (isConfig(cmd)) {
        logger.atFine().log("Processing %s command", cmd.getRefName());
        try {
            permissions.check(ProjectPermission.WRITE_CONFIG);
        } catch (AuthException e) {
            reject(cmd, String.format("must be either project owner or have %s permission", ProjectPermission.WRITE_CONFIG.describeForException()));
            return;
        }
        switch(cmd.getType()) {
            case CREATE:
            case UPDATE:
            case UPDATE_NONFASTFORWARD:
                try {
                    ProjectConfig cfg = new ProjectConfig(project.getNameKey());
                    cfg.load(receivePack.getRevWalk(), cmd.getNewId());
                    if (!cfg.getValidationErrors().isEmpty()) {
                        addError("Invalid project configuration:");
                        for (ValidationError err : cfg.getValidationErrors()) {
                            addError("  " + err.getMessage());
                        }
                        reject(cmd, "invalid project configuration");
                        logger.atSevere().log("User %s tried to push invalid project configuration %s for %s", user.getLoggableName(), cmd.getNewId().name(), project.getName());
                        return;
                    }
                    Project.NameKey newParent = cfg.getProject().getParent(allProjectsName);
                    Project.NameKey oldParent = project.getParent(allProjectsName);
                    if (oldParent == null) {
                        // update of the 'All-Projects' project
                        if (newParent != null) {
                            reject(cmd, "invalid project configuration: root project cannot have parent");
                            return;
                        }
                    } else {
                        if (!oldParent.equals(newParent)) {
                            try {
                                permissionBackend.user(user).check(GlobalPermission.ADMINISTRATE_SERVER);
                            } catch (AuthException e) {
                                reject(cmd, "invalid project configuration: only Gerrit admin can set parent");
                                return;
                            }
                        }
                        if (projectCache.get(newParent) == null) {
                            reject(cmd, "invalid project configuration: parent does not exist");
                            return;
                        }
                    }
                    for (Entry<ProjectConfigEntry> e : pluginConfigEntries) {
                        PluginConfig pluginCfg = cfg.getPluginConfig(e.getPluginName());
                        ProjectConfigEntry configEntry = e.getProvider().get();
                        String value = pluginCfg.getString(e.getExportName());
                        String oldValue = projectState.getConfig().getPluginConfig(e.getPluginName()).getString(e.getExportName());
                        if (configEntry.getType() == ProjectConfigEntryType.ARRAY) {
                            oldValue = Arrays.stream(projectState.getConfig().getPluginConfig(e.getPluginName()).getStringList(e.getExportName())).collect(joining("\n"));
                        }
                        if ((value == null ? oldValue != null : !value.equals(oldValue)) && !configEntry.isEditable(projectState)) {
                            reject(cmd, String.format("invalid project configuration: Not allowed to set parameter" + " '%s' of plugin '%s' on project '%s'.", e.getExportName(), e.getPluginName(), project.getName()));
                            continue;
                        }
                        if (ProjectConfigEntryType.LIST.equals(configEntry.getType()) && value != null && !configEntry.getPermittedValues().contains(value)) {
                            reject(cmd, String.format("invalid project configuration: The value '%s' is " + "not permitted for parameter '%s' of plugin '%s'.", value, e.getExportName(), e.getPluginName()));
                        }
                    }
                } catch (Exception e) {
                    reject(cmd, "invalid project configuration");
                    logger.atSevere().withCause(e).log("User %s tried to push invalid project configuration %s for %s", user.getLoggableName(), cmd.getNewId().name(), project.getName());
                    return;
                }
                break;
            case DELETE:
                break;
            default:
                reject(cmd, "prohibited by Gerrit: don't know how to handle config update of type " + cmd.getType());
        }
    }
}
#method_after
private void parseRegularCommand(ReceiveCommand cmd) throws PermissionBackendException, NoSuchProjectException, IOException {
    if (cmd.getResult() != NOT_ATTEMPTED) {
        // Already rejected by the core receive process.
        logger.atFine().log("Already processed by core: %s %s", cmd.getResult(), cmd);
        return;
    }
    if (!Repository.isValidRefName(cmd.getRefName()) || cmd.getRefName().contains("//")) {
        reject(cmd, "not valid ref");
        return;
    }
    if (RefNames.isNoteDbMetaRef(cmd.getRefName())) {
        // Reject pushes to NoteDb refs without a special option and permission. Note that this
        // prohibition doesn't depend on NoteDb being enabled in any way, since all sites will
        // migrate to NoteDb eventually, and we don't want garbage data waiting there when the
        // migration finishes.
        logger.atFine().log("%s NoteDb ref %s with %s=%s", cmd.getType(), cmd.getRefName(), NoteDbPushOption.OPTION_NAME, noteDbPushOption);
        if (!Optional.of(NoteDbPushOption.ALLOW).equals(noteDbPushOption)) {
            // Only reject this command, not the whole push. This supports the use case of "git clone
            // --mirror" followed by "git push --mirror", when the user doesn't really intend to clone
            // or mirror the NoteDb data; there is no single refspec that describes all refs *except*
            // NoteDb refs.
            reject(cmd, "NoteDb update requires -o " + NoteDbPushOption.OPTION_NAME + "=" + NoteDbPushOption.ALLOW.value());
            return;
        }
        try {
            permissionBackend.user(user).check(GlobalPermission.ACCESS_DATABASE);
        } catch (AuthException e) {
            reject(cmd, "NoteDb update requires access database permission");
            return;
        }
    }
    switch(cmd.getType()) {
        case CREATE:
            parseCreate(cmd);
            break;
        case UPDATE:
            parseUpdate(cmd);
            break;
        case DELETE:
            parseDelete(cmd);
            break;
        case UPDATE_NONFASTFORWARD:
            parseRewind(cmd);
            break;
        default:
            reject(cmd, "prohibited by Gerrit: unknown command type " + cmd.getType());
            return;
    }
    if (cmd.getResult() != NOT_ATTEMPTED) {
        return;
    }
    if (isConfig(cmd)) {
        logger.atFine().log("Processing %s command", cmd.getRefName());
        try {
            permissions.check(ProjectPermission.WRITE_CONFIG);
        } catch (AuthException e) {
            reject(cmd, String.format("must be either project owner or have %s permission", ProjectPermission.WRITE_CONFIG.describeForException()));
            return;
        }
        switch(cmd.getType()) {
            case CREATE:
            case UPDATE:
            case UPDATE_NONFASTFORWARD:
                try {
                    ProjectConfig cfg = new ProjectConfig(project.getNameKey());
                    cfg.load(project.getNameKey(), receivePack.getRevWalk(), cmd.getNewId());
                    if (!cfg.getValidationErrors().isEmpty()) {
                        addError("Invalid project configuration:");
                        for (ValidationError err : cfg.getValidationErrors()) {
                            addError("  " + err.getMessage());
                        }
                        reject(cmd, "invalid project configuration");
                        logger.atSevere().log("User %s tried to push invalid project configuration %s for %s", user.getLoggableName(), cmd.getNewId().name(), project.getName());
                        return;
                    }
                    Project.NameKey newParent = cfg.getProject().getParent(allProjectsName);
                    Project.NameKey oldParent = project.getParent(allProjectsName);
                    if (oldParent == null) {
                        // update of the 'All-Projects' project
                        if (newParent != null) {
                            reject(cmd, "invalid project configuration: root project cannot have parent");
                            return;
                        }
                    } else {
                        if (!oldParent.equals(newParent)) {
                            try {
                                permissionBackend.user(user).check(GlobalPermission.ADMINISTRATE_SERVER);
                            } catch (AuthException e) {
                                reject(cmd, "invalid project configuration: only Gerrit admin can set parent");
                                return;
                            }
                        }
                        if (projectCache.get(newParent) == null) {
                            reject(cmd, "invalid project configuration: parent does not exist");
                            return;
                        }
                    }
                    for (Entry<ProjectConfigEntry> e : pluginConfigEntries) {
                        PluginConfig pluginCfg = cfg.getPluginConfig(e.getPluginName());
                        ProjectConfigEntry configEntry = e.getProvider().get();
                        String value = pluginCfg.getString(e.getExportName());
                        String oldValue = projectState.getConfig().getPluginConfig(e.getPluginName()).getString(e.getExportName());
                        if (configEntry.getType() == ProjectConfigEntryType.ARRAY) {
                            oldValue = Arrays.stream(projectState.getConfig().getPluginConfig(e.getPluginName()).getStringList(e.getExportName())).collect(joining("\n"));
                        }
                        if ((value == null ? oldValue != null : !value.equals(oldValue)) && !configEntry.isEditable(projectState)) {
                            reject(cmd, String.format("invalid project configuration: Not allowed to set parameter" + " '%s' of plugin '%s' on project '%s'.", e.getExportName(), e.getPluginName(), project.getName()));
                            continue;
                        }
                        if (ProjectConfigEntryType.LIST.equals(configEntry.getType()) && value != null && !configEntry.getPermittedValues().contains(value)) {
                            reject(cmd, String.format("invalid project configuration: The value '%s' is " + "not permitted for parameter '%s' of plugin '%s'.", value, e.getExportName(), e.getPluginName()));
                        }
                    }
                } catch (Exception e) {
                    reject(cmd, "invalid project configuration");
                    logger.atSevere().withCause(e).log("User %s tried to push invalid project configuration %s for %s", user.getLoggableName(), cmd.getNewId().name(), project.getName());
                    return;
                }
                break;
            case DELETE:
                break;
            default:
                reject(cmd, "prohibited by Gerrit: don't know how to handle config update of type " + cmd.getType());
        }
    }
}
#end_block

#method_before
void processCommands(Collection<ReceiveCommand> commands, MultiProgressMonitor progress) {
    Task commandProgress = progress.beginSubTask("refs", UNKNOWN);
    commands = commands.stream().map(c -> wrapReceiveCommand(c, commandProgress)).collect(toList());
    processCommandsUnsafe(commands, progress);
    for (ReceiveCommand cmd : commands) {
        if (cmd.getResult() == NOT_ATTEMPTED) {
            cmd.setResult(REJECTED_OTHER_REASON, "internal server error");
        }
    }
    commandProgress.end();
    progress.end();
    // Update account info with details discovered during commit walking. The account update happens
    // in a separate batch update, and failure doesn't cause the push itself to fail.
    updateAccountInfo();
}
#method_after
void processCommands(Collection<ReceiveCommand> commands, MultiProgressMonitor progress) {
    Task commandProgress = progress.beginSubTask("refs", UNKNOWN);
    commands = commands.stream().map(c -> wrapReceiveCommand(c, commandProgress)).collect(toList());
    processCommandsUnsafe(commands, progress);
    for (ReceiveCommand cmd : commands) {
        if (cmd.getResult() == NOT_ATTEMPTED) {
            cmd.setResult(REJECTED_OTHER_REASON, "internal server error");
        }
    }
    // This sends error messages before the 'done' string of the progress monitor is sent.
    // Currently, the test framework relies on this ordering to understand if pushes completed
    // successfully.
    sendErrorMessages();
    commandProgress.end();
    progress.end();
    // Update account info with details discovered during commit walking. The account update happens
    // in a separate batch update, and failure doesn't cause the push itself to fail.
    updateAccountInfo();
}
#end_block

#method_before
private void processCommandsUnsafe(Collection<ReceiveCommand> commands, MultiProgressMonitor progress) {
    parsePushOptions();
    try (TraceContext traceContext = TraceContext.open().addTag(RequestId.Type.RECEIVE_ID, RequestId.forProject(project.getNameKey()))) {
        if (tracePushOption.orElse(false)) {
            RequestId traceId = new RequestId();
            traceContext.addTag(RequestId.Type.TRACE_ID, traceId);
            addMessage(RequestId.Type.TRACE_ID.name() + ": " + traceId);
        }
        try {
            if (!projectState.getProject().getState().permitsWrite()) {
                for (ReceiveCommand cmd : commands) {
                    reject(cmd, "prohibited by Gerrit: project state does not permit write");
                }
                return;
            }
            logger.atFine().log("Parsing %d commands", commands.size());
            List<ReceiveCommand> magicCommands = new ArrayList<>();
            List<ReceiveCommand> directPatchSetPushCommands = new ArrayList<>();
            List<ReceiveCommand> regularCommands = new ArrayList<>();
            for (ReceiveCommand cmd : commands) {
                if (MagicBranch.isMagicBranch(cmd.getRefName())) {
                    magicCommands.add(cmd);
                } else if (isDirectChangesPush(cmd.getRefName())) {
                    directPatchSetPushCommands.add(cmd);
                } else {
                    regularCommands.add(cmd);
                }
            }
            int commandTypes = (magicCommands.isEmpty() ? 0 : 1) + (directPatchSetPushCommands.isEmpty() ? 0 : 1) + (regularCommands.isEmpty() ? 0 : 1);
            if (commandTypes > 1) {
                for (ReceiveCommand cmd : commands) {
                    if (cmd.getResult() == NOT_ATTEMPTED) {
                        cmd.setResult(REJECTED_OTHER_REASON, "cannot combine normal pushes and magic pushes");
                    }
                }
                return;
            }
            if (!regularCommands.isEmpty()) {
                handleRegularCommands(regularCommands, progress);
            }
            for (ReceiveCommand cmd : directPatchSetPushCommands) {
                parseDirectChangesPush(cmd);
            }
            boolean first = true;
            for (ReceiveCommand cmd : magicCommands) {
                if (first) {
                    parseMagicBranch(cmd);
                    first = false;
                } else {
                    reject(cmd, "duplicate request");
                }
            }
        } catch (PermissionBackendException | NoSuchProjectException | IOException err) {
            logger.atSevere().withCause(err).log("Failed to process refs in %s", project.getName());
            return;
        }
        Task newProgress = progress.beginSubTask("new", UNKNOWN);
        Task replaceProgress = progress.beginSubTask("updated", UNKNOWN);
        List<CreateRequest> newChanges = Collections.emptyList();
        if (magicBranch != null && magicBranch.cmd.getResult() == NOT_ATTEMPTED) {
            newChanges = selectNewAndReplacedChangesFromMagicBranch(newProgress);
        }
        preparePatchSetsForReplace(newChanges);
        insertChangesAndPatchSets(newChanges, replaceProgress);
        newProgress.end();
        replaceProgress.end();
        if (!errors.isEmpty()) {
            logger.atFine().log("Handling error conditions: %s", errors.keySet());
            for (String error : errors.keySet()) {
                receivePack.sendMessage("error: " + buildError(error, errors.get(error)));
            }
            receivePack.sendMessage(String.format("User: %s", user.getLoggableName()));
            receivePack.sendMessage(COMMAND_REJECTION_MESSAGE_FOOTER);
        }
        reportMessages(newChanges);
    }
}
#method_after
private void processCommandsUnsafe(Collection<ReceiveCommand> commands, MultiProgressMonitor progress) {
    parsePushOptions();
    try (TraceContext traceContext = TraceContext.open().addTag(RequestId.Type.RECEIVE_ID, RequestId.forProject(project.getNameKey()))) {
        if (tracePushOption.orElse(false)) {
            RequestId traceId = new RequestId();
            traceContext.forceLogging().addTag(RequestId.Type.TRACE_ID, traceId);
            addMessage(RequestId.Type.TRACE_ID.name() + ": " + traceId);
        }
        try {
            if (!projectState.getProject().getState().permitsWrite()) {
                for (ReceiveCommand cmd : commands) {
                    reject(cmd, "prohibited by Gerrit: project state does not permit write");
                }
                return;
            }
            logger.atFine().log("Parsing %d commands", commands.size());
            List<ReceiveCommand> magicCommands = new ArrayList<>();
            List<ReceiveCommand> directPatchSetPushCommands = new ArrayList<>();
            List<ReceiveCommand> regularCommands = new ArrayList<>();
            for (ReceiveCommand cmd : commands) {
                if (MagicBranch.isMagicBranch(cmd.getRefName())) {
                    magicCommands.add(cmd);
                } else if (isDirectChangesPush(cmd.getRefName())) {
                    directPatchSetPushCommands.add(cmd);
                } else {
                    regularCommands.add(cmd);
                }
            }
            int commandTypes = (magicCommands.isEmpty() ? 0 : 1) + (directPatchSetPushCommands.isEmpty() ? 0 : 1) + (regularCommands.isEmpty() ? 0 : 1);
            if (commandTypes > 1) {
                for (ReceiveCommand cmd : commands) {
                    if (cmd.getResult() == NOT_ATTEMPTED) {
                        cmd.setResult(REJECTED_OTHER_REASON, "cannot combine normal pushes and magic pushes");
                    }
                }
                return;
            }
            if (!regularCommands.isEmpty()) {
                handleRegularCommands(regularCommands, progress);
                return;
            }
            for (ReceiveCommand cmd : directPatchSetPushCommands) {
                parseDirectChangesPush(cmd);
            }
            boolean first = true;
            for (ReceiveCommand cmd : magicCommands) {
                if (first) {
                    parseMagicBranch(cmd);
                    first = false;
                } else {
                    reject(cmd, "duplicate request");
                }
            }
        } catch (PermissionBackendException | NoSuchProjectException | IOException err) {
            logger.atSevere().withCause(err).log("Failed to process refs in %s", project.getName());
            return;
        }
        Task newProgress = progress.beginSubTask("new", UNKNOWN);
        Task replaceProgress = progress.beginSubTask("updated", UNKNOWN);
        List<CreateRequest> newChanges = Collections.emptyList();
        if (magicBranch != null && magicBranch.cmd.getResult() == NOT_ATTEMPTED) {
            newChanges = selectNewAndReplacedChangesFromMagicBranch(newProgress);
        }
        preparePatchSetsForReplace(newChanges);
        insertChangesAndPatchSets(newChanges, replaceProgress);
        newProgress.end();
        replaceProgress.end();
        queueSuccessMessages(newChanges);
        refsPublishDeprecationWarning();
    }
}
#end_block

#method_before
private void parseRegularCommand(ReceiveCommand cmd) throws PermissionBackendException, NoSuchProjectException, IOException {
    if (cmd.getResult() != NOT_ATTEMPTED) {
        // Already rejected by the core receive process.
        logger.atFine().log("Already processed by core: %s %s", cmd.getResult(), cmd);
        return;
    }
    if (!Repository.isValidRefName(cmd.getRefName()) || cmd.getRefName().contains("//")) {
        reject(cmd, "not valid ref");
        return;
    }
    if (RefNames.isNoteDbMetaRef(cmd.getRefName())) {
        // Reject pushes to NoteDb refs without a special option and permission. Note that this
        // prohibition doesn't depend on NoteDb being enabled in any way, since all sites will
        // migrate to NoteDb eventually, and we don't want garbage data waiting there when the
        // migration finishes.
        logger.atFine().log("%s NoteDb ref %s with %s=%s", cmd.getType(), cmd.getRefName(), NoteDbPushOption.OPTION_NAME, noteDbPushOption);
        if (!Optional.of(NoteDbPushOption.ALLOW).equals(noteDbPushOption)) {
            // Only reject this command, not the whole push. This supports the use case of "git clone
            // --mirror" followed by "git push --mirror", when the user doesn't really intend to clone
            // or mirror the NoteDb data; there is no single refspec that describes all refs *except*
            // NoteDb refs.
            reject(cmd, "NoteDb update requires -o " + NoteDbPushOption.OPTION_NAME + "=" + NoteDbPushOption.ALLOW.value());
            return;
        }
        try {
            permissionBackend.user(user).check(GlobalPermission.ACCESS_DATABASE);
        } catch (AuthException e) {
            reject(cmd, "NoteDb update requires access database permission");
            return;
        }
    }
    switch(cmd.getType()) {
        case CREATE:
            parseCreate(cmd);
            break;
        case UPDATE:
            parseUpdate(cmd);
            break;
        case DELETE:
            parseDelete(cmd);
            break;
        case UPDATE_NONFASTFORWARD:
            parseRewind(cmd);
            break;
        default:
            reject(cmd, "prohibited by Gerrit: unknown command type " + cmd.getType());
            return;
    }
    if (cmd.getResult() != NOT_ATTEMPTED) {
        return;
    }
    if (isConfig(cmd)) {
        logger.atFine().log("Processing %s command", cmd.getRefName());
        try {
            permissions.check(ProjectPermission.WRITE_CONFIG);
        } catch (AuthException e) {
            reject(cmd, String.format("must be either project owner or have %s permission", ProjectPermission.WRITE_CONFIG.describeForException()));
            return;
        }
        switch(cmd.getType()) {
            case CREATE:
            case UPDATE:
            case UPDATE_NONFASTFORWARD:
                try {
                    ProjectConfig cfg = new ProjectConfig(project.getNameKey());
                    cfg.load(receivePack.getRevWalk(), cmd.getNewId());
                    if (!cfg.getValidationErrors().isEmpty()) {
                        addError("Invalid project configuration:");
                        for (ValidationError err : cfg.getValidationErrors()) {
                            addError("  " + err.getMessage());
                        }
                        reject(cmd, "invalid project configuration");
                        logger.atSevere().log("User %s tried to push invalid project configuration %s for %s", user.getLoggableName(), cmd.getNewId().name(), project.getName());
                        return;
                    }
                    Project.NameKey newParent = cfg.getProject().getParent(allProjectsName);
                    Project.NameKey oldParent = project.getParent(allProjectsName);
                    if (oldParent == null) {
                        // update of the 'All-Projects' project
                        if (newParent != null) {
                            reject(cmd, "invalid project configuration: root project cannot have parent");
                            return;
                        }
                    } else {
                        if (!oldParent.equals(newParent)) {
                            try {
                                permissionBackend.user(user).check(GlobalPermission.ADMINISTRATE_SERVER);
                            } catch (AuthException e) {
                                reject(cmd, "invalid project configuration: only Gerrit admin can set parent");
                                return;
                            }
                        }
                        if (projectCache.get(newParent) == null) {
                            reject(cmd, "invalid project configuration: parent does not exist");
                            return;
                        }
                    }
                    for (Entry<ProjectConfigEntry> e : pluginConfigEntries) {
                        PluginConfig pluginCfg = cfg.getPluginConfig(e.getPluginName());
                        ProjectConfigEntry configEntry = e.getProvider().get();
                        String value = pluginCfg.getString(e.getExportName());
                        String oldValue = projectState.getConfig().getPluginConfig(e.getPluginName()).getString(e.getExportName());
                        if (configEntry.getType() == ProjectConfigEntryType.ARRAY) {
                            oldValue = Arrays.stream(projectState.getConfig().getPluginConfig(e.getPluginName()).getStringList(e.getExportName())).collect(joining("\n"));
                        }
                        if ((value == null ? oldValue != null : !value.equals(oldValue)) && !configEntry.isEditable(projectState)) {
                            reject(cmd, String.format("invalid project configuration: Not allowed to set parameter" + " '%s' of plugin '%s' on project '%s'.", e.getExportName(), e.getPluginName(), project.getName()));
                            continue;
                        }
                        if (ProjectConfigEntryType.LIST.equals(configEntry.getType()) && value != null && !configEntry.getPermittedValues().contains(value)) {
                            reject(cmd, String.format("invalid project configuration: The value '%s' is " + "not permitted for parameter '%s' of plugin '%s'.", value, e.getExportName(), e.getPluginName()));
                        }
                    }
                } catch (Exception e) {
                    reject(cmd, "invalid project configuration");
                    logger.atSevere().withCause(e).log("User %s tried to push invalid project configuration %s for %s", user.getLoggableName(), cmd.getNewId().name(), project.getName());
                    return;
                }
                break;
            case DELETE:
                break;
            default:
                reject(cmd, "prohibited by Gerrit: don't know how to handle config update of type " + cmd.getType());
                return;
        }
    }
}
#method_after
private void parseRegularCommand(ReceiveCommand cmd) throws PermissionBackendException, NoSuchProjectException, IOException {
    if (cmd.getResult() != NOT_ATTEMPTED) {
        // Already rejected by the core receive process.
        logger.atFine().log("Already processed by core: %s %s", cmd.getResult(), cmd);
        return;
    }
    if (!Repository.isValidRefName(cmd.getRefName()) || cmd.getRefName().contains("//")) {
        reject(cmd, "not valid ref");
        return;
    }
    if (RefNames.isNoteDbMetaRef(cmd.getRefName())) {
        // Reject pushes to NoteDb refs without a special option and permission. Note that this
        // prohibition doesn't depend on NoteDb being enabled in any way, since all sites will
        // migrate to NoteDb eventually, and we don't want garbage data waiting there when the
        // migration finishes.
        logger.atFine().log("%s NoteDb ref %s with %s=%s", cmd.getType(), cmd.getRefName(), NoteDbPushOption.OPTION_NAME, noteDbPushOption);
        if (!Optional.of(NoteDbPushOption.ALLOW).equals(noteDbPushOption)) {
            // Only reject this command, not the whole push. This supports the use case of "git clone
            // --mirror" followed by "git push --mirror", when the user doesn't really intend to clone
            // or mirror the NoteDb data; there is no single refspec that describes all refs *except*
            // NoteDb refs.
            reject(cmd, "NoteDb update requires -o " + NoteDbPushOption.OPTION_NAME + "=" + NoteDbPushOption.ALLOW.value());
            return;
        }
        try {
            permissionBackend.user(user).check(GlobalPermission.ACCESS_DATABASE);
        } catch (AuthException e) {
            reject(cmd, "NoteDb update requires access database permission");
            return;
        }
    }
    switch(cmd.getType()) {
        case CREATE:
            parseCreate(cmd);
            break;
        case UPDATE:
            parseUpdate(cmd);
            break;
        case DELETE:
            parseDelete(cmd);
            break;
        case UPDATE_NONFASTFORWARD:
            parseRewind(cmd);
            break;
        default:
            reject(cmd, "prohibited by Gerrit: unknown command type " + cmd.getType());
            return;
    }
    if (cmd.getResult() != NOT_ATTEMPTED) {
        return;
    }
    if (isConfig(cmd)) {
        logger.atFine().log("Processing %s command", cmd.getRefName());
        try {
            permissions.check(ProjectPermission.WRITE_CONFIG);
        } catch (AuthException e) {
            reject(cmd, String.format("must be either project owner or have %s permission", ProjectPermission.WRITE_CONFIG.describeForException()));
            return;
        }
        switch(cmd.getType()) {
            case CREATE:
            case UPDATE:
            case UPDATE_NONFASTFORWARD:
                try {
                    ProjectConfig cfg = new ProjectConfig(project.getNameKey());
                    cfg.load(project.getNameKey(), receivePack.getRevWalk(), cmd.getNewId());
                    if (!cfg.getValidationErrors().isEmpty()) {
                        addError("Invalid project configuration:");
                        for (ValidationError err : cfg.getValidationErrors()) {
                            addError("  " + err.getMessage());
                        }
                        reject(cmd, "invalid project configuration");
                        logger.atSevere().log("User %s tried to push invalid project configuration %s for %s", user.getLoggableName(), cmd.getNewId().name(), project.getName());
                        return;
                    }
                    Project.NameKey newParent = cfg.getProject().getParent(allProjectsName);
                    Project.NameKey oldParent = project.getParent(allProjectsName);
                    if (oldParent == null) {
                        // update of the 'All-Projects' project
                        if (newParent != null) {
                            reject(cmd, "invalid project configuration: root project cannot have parent");
                            return;
                        }
                    } else {
                        if (!oldParent.equals(newParent)) {
                            try {
                                permissionBackend.user(user).check(GlobalPermission.ADMINISTRATE_SERVER);
                            } catch (AuthException e) {
                                reject(cmd, "invalid project configuration: only Gerrit admin can set parent");
                                return;
                            }
                        }
                        if (projectCache.get(newParent) == null) {
                            reject(cmd, "invalid project configuration: parent does not exist");
                            return;
                        }
                    }
                    for (Entry<ProjectConfigEntry> e : pluginConfigEntries) {
                        PluginConfig pluginCfg = cfg.getPluginConfig(e.getPluginName());
                        ProjectConfigEntry configEntry = e.getProvider().get();
                        String value = pluginCfg.getString(e.getExportName());
                        String oldValue = projectState.getConfig().getPluginConfig(e.getPluginName()).getString(e.getExportName());
                        if (configEntry.getType() == ProjectConfigEntryType.ARRAY) {
                            oldValue = Arrays.stream(projectState.getConfig().getPluginConfig(e.getPluginName()).getStringList(e.getExportName())).collect(joining("\n"));
                        }
                        if ((value == null ? oldValue != null : !value.equals(oldValue)) && !configEntry.isEditable(projectState)) {
                            reject(cmd, String.format("invalid project configuration: Not allowed to set parameter" + " '%s' of plugin '%s' on project '%s'.", e.getExportName(), e.getPluginName(), project.getName()));
                            continue;
                        }
                        if (ProjectConfigEntryType.LIST.equals(configEntry.getType()) && value != null && !configEntry.getPermittedValues().contains(value)) {
                            reject(cmd, String.format("invalid project configuration: The value '%s' is " + "not permitted for parameter '%s' of plugin '%s'.", value, e.getExportName(), e.getPluginName()));
                        }
                    }
                } catch (Exception e) {
                    reject(cmd, "invalid project configuration");
                    logger.atSevere().withCause(e).log("User %s tried to push invalid project configuration %s for %s", user.getLoggableName(), cmd.getNewId().name(), project.getName());
                    return;
                }
                break;
            case DELETE:
                break;
            default:
                reject(cmd, "prohibited by Gerrit: don't know how to handle config update of type " + cmd.getType());
        }
    }
}
#end_block

#method_before
private void parseCreate(ReceiveCommand cmd) throws PermissionBackendException, NoSuchProjectException, IOException {
    RevObject obj;
    try {
        obj = receivePack.getRevWalk().parseAny(cmd.getNewId());
    } catch (IOException err) {
        logger.atSevere().withCause(err).log("Invalid object %s for %s creation", cmd.getNewId().name(), cmd.getRefName());
        reject(cmd, "invalid object");
        return;
    }
    logger.atFine().log("Creating %s", cmd);
    if (isHead(cmd) && !isCommit(cmd)) {
        return;
    }
    Branch.NameKey branch = new Branch.NameKey(project.getName(), cmd.getRefName());
    try {
        // Must pass explicit user instead of injecting a provider into CreateRefControl, since
        // Provider<CurrentUser> within ReceiveCommits will always return anonymous.
        createRefControl.checkCreateRef(Providers.of(user), receivePack.getRepository(), branch, obj);
    } catch (AuthException denied) {
        rejectProhibited(cmd, denied);
        return;
    } catch (ResourceConflictException denied) {
        reject(cmd, "prohibited by Gerrit: " + denied.getMessage());
        return;
    }
    if (validRefOperation(cmd)) {
        validateNewCommits(new Branch.NameKey(project.getNameKey(), cmd.getRefName()), cmd);
    }
}
#method_after
private void parseCreate(ReceiveCommand cmd) throws PermissionBackendException, NoSuchProjectException, IOException {
    RevObject obj;
    try {
        obj = receivePack.getRevWalk().parseAny(cmd.getNewId());
    } catch (IOException err) {
        logger.atSevere().withCause(err).log("Invalid object %s for %s creation", cmd.getNewId().name(), cmd.getRefName());
        reject(cmd, "invalid object");
        return;
    }
    logger.atFine().log("Creating %s", cmd);
    if (isHead(cmd) && !isCommit(cmd)) {
        return;
    }
    Branch.NameKey branch = new Branch.NameKey(project.getName(), cmd.getRefName());
    try {
        // Must pass explicit user instead of injecting a provider into CreateRefControl, since
        // Provider<CurrentUser> within ReceiveCommits will always return anonymous.
        createRefControl.checkCreateRef(Providers.of(user), receivePack.getRepository(), branch, obj);
    } catch (AuthException denied) {
        rejectProhibited(cmd, denied);
        return;
    } catch (ResourceConflictException denied) {
        reject(cmd, "prohibited by Gerrit: " + denied.getMessage());
        return;
    }
    if (validRefOperation(cmd)) {
        validateRegularPushCommits(new Branch.NameKey(project.getNameKey(), cmd.getRefName()), cmd);
    }
}
#end_block

#method_before
private void parseUpdate(ReceiveCommand cmd) throws PermissionBackendException {
    logger.atFine().log("Updating %s", cmd);
    Optional<AuthException> err = checkRefPermission(cmd, RefPermission.UPDATE);
    if (!err.isPresent()) {
        if (isHead(cmd) && !isCommit(cmd)) {
            reject(cmd, "head must point to commit");
            return;
        }
        if (validRefOperation(cmd)) {
            validateNewCommits(new Branch.NameKey(project.getNameKey(), cmd.getRefName()), cmd);
        }
    } else {
        rejectProhibited(cmd, err.get());
    }
}
#method_after
private void parseUpdate(ReceiveCommand cmd) throws PermissionBackendException {
    logger.atFine().log("Updating %s", cmd);
    Optional<AuthException> err = checkRefPermission(cmd, RefPermission.UPDATE);
    if (!err.isPresent()) {
        if (isHead(cmd) && !isCommit(cmd)) {
            reject(cmd, "head must point to commit");
            return;
        }
        if (validRefOperation(cmd)) {
            validateRegularPushCommits(new Branch.NameKey(project.getNameKey(), cmd.getRefName()), cmd);
        }
    } else {
        rejectProhibited(cmd, err.get());
    }
}
#end_block

#method_before
private void parseRewind(ReceiveCommand cmd) throws PermissionBackendException {
    RevCommit newObject;
    try {
        newObject = receivePack.getRevWalk().parseCommit(cmd.getNewId());
    } catch (IncorrectObjectTypeException notCommit) {
        newObject = null;
    } catch (IOException err) {
        logger.atSevere().withCause(err).log("Invalid object %s for %s forced update", cmd.getNewId().name(), cmd.getRefName());
        reject(cmd, "invalid object");
        return;
    }
    logger.atFine().log("Rewinding %s", cmd);
    if (newObject != null) {
        validateNewCommits(new Branch.NameKey(project.getNameKey(), cmd.getRefName()), cmd);
        if (cmd.getResult() != NOT_ATTEMPTED) {
            return;
        }
    }
    Optional<AuthException> err = checkRefPermission(cmd, RefPermission.FORCE_UPDATE);
    if (!err.isPresent()) {
        validRefOperation(cmd);
    } else {
        rejectProhibited(cmd, err.get());
    }
}
#method_after
private void parseRewind(ReceiveCommand cmd) throws PermissionBackendException {
    RevCommit newObject;
    try {
        newObject = receivePack.getRevWalk().parseCommit(cmd.getNewId());
    } catch (IncorrectObjectTypeException notCommit) {
        newObject = null;
    } catch (IOException err) {
        logger.atSevere().withCause(err).log("Invalid object %s for %s forced update", cmd.getNewId().name(), cmd.getRefName());
        reject(cmd, "invalid object");
        return;
    }
    logger.atFine().log("Rewinding %s", cmd);
    if (newObject != null) {
        validateRegularPushCommits(new Branch.NameKey(project.getNameKey(), cmd.getRefName()), cmd);
        if (cmd.getResult() != NOT_ATTEMPTED) {
            return;
        }
    }
    Optional<AuthException> err = checkRefPermission(cmd, RefPermission.FORCE_UPDATE);
    if (!err.isPresent()) {
        validRefOperation(cmd);
    } else {
        rejectProhibited(cmd, err.get());
    }
}
#end_block

#method_before
private void parseReplaceCommand(ReceiveCommand cmd, Change.Id changeId) {
    logger.atFine().log("Parsing replace command");
    if (cmd.getType() != ReceiveCommand.Type.CREATE) {
        reject(cmd, "invalid usage");
        return;
    }
    RevCommit newCommit;
    try {
        newCommit = receivePack.getRevWalk().parseCommit(cmd.getNewId());
        logger.atFine().log("Replacing with %s", newCommit);
    } catch (IOException e) {
        logger.atSevere().withCause(e).log("Cannot parse %s as commit", cmd.getNewId().name());
        reject(cmd, "invalid commit");
        return;
    }
    Change changeEnt;
    try {
        changeEnt = notesFactory.createChecked(db, project.getNameKey(), changeId).getChange();
    } catch (NoSuchChangeException e) {
        logger.atSevere().withCause(e).log("Change not found %s", changeId);
        reject(cmd, "change " + changeId + " not found");
        return;
    } catch (OrmException e) {
        logger.atSevere().withCause(e).log("Cannot lookup existing change %s", changeId);
        reject(cmd, "database error");
        return;
    }
    if (!project.getNameKey().equals(changeEnt.getProject())) {
        reject(cmd, "change " + changeId + " does not belong to project " + project.getName());
        return;
    }
    logger.atFine().log("Replacing change %s", changeEnt.getId());
    requestReplace(cmd, true, changeEnt, newCommit);
}
#method_after
private void parseReplaceCommand(ReceiveCommand cmd, Change.Id changeId) {
    logger.atFine().log("Parsing replace command");
    if (cmd.getType() != ReceiveCommand.Type.CREATE) {
        reject(cmd, "invalid usage");
        return;
    }
    RevCommit newCommit;
    try {
        newCommit = receivePack.getRevWalk().parseCommit(cmd.getNewId());
        logger.atFine().log("Replacing with %s", newCommit);
    } catch (IOException e) {
        logger.atSevere().withCause(e).log("Cannot parse %s as commit", cmd.getNewId().name());
        reject(cmd, "invalid commit");
        return;
    }
    Change changeEnt;
    try {
        changeEnt = notesFactory.createChecked(db, project.getNameKey(), changeId).getChange();
    } catch (NoSuchChangeException e) {
        logger.atSevere().withCause(e).log("Change not found %s", changeId);
        reject(cmd, "change " + changeId + " not found");
        return;
    } catch (OrmException e) {
        logger.atSevere().withCause(e).log("Cannot lookup existing change %s", changeId);
        reject(cmd, "database error");
        return;
    }
    if (!project.getNameKey().equals(changeEnt.getProject())) {
        reject(cmd, "change " + changeId + " does not belong to project " + project.getName());
        return;
    }
    try {
        if (validCommit(receivePack.getRevWalk().getObjectReader(), changeEnt.getDest(), cmd, newCommit, false, changeEnt)) {
            logger.atFine().log("Replacing change %s", changeEnt.getId());
            requestReplace(cmd, true, changeEnt, newCommit);
        }
    } catch (IOException e) {
        reject(cmd, "I/O exception validating commit");
    }
}
#end_block

#method_before
private List<CreateRequest> selectNewAndReplacedChangesFromMagicBranch(Task newProgress) {
    logger.atFine().log("Finding new and replaced changes");
    List<CreateRequest> newChanges = new ArrayList<>();
    ListMultimap<ObjectId, Ref> existing = changeRefsById();
    GroupCollector groupCollector = GroupCollector.create(changeRefsById(), db, psUtil, notesFactory, project.getNameKey());
    try {
        RevCommit start = setUpWalkForSelectingChanges();
        if (start == null) {
            return Collections.emptyList();
        }
        LinkedHashMap<RevCommit, ChangeLookup> pending = new LinkedHashMap<>();
        Set<Change.Key> newChangeIds = new HashSet<>();
        int maxBatchChanges = receiveConfig.getEffectiveMaxBatchChangesLimit(user);
        int total = 0;
        int alreadyTracked = 0;
        boolean rejectImplicitMerges = start.getParentCount() == 1 && projectCache.get(project.getNameKey()).is(BooleanProjectConfig.REJECT_IMPLICIT_MERGES) && // late.
        !magicBranch.merged;
        Set<RevCommit> mergedParents;
        if (rejectImplicitMerges) {
            mergedParents = new HashSet<>();
        } else {
            mergedParents = null;
        }
        for (; ; ) {
            RevCommit c = receivePack.getRevWalk().next();
            if (c == null) {
                break;
            }
            total++;
            receivePack.getRevWalk().parseBody(c);
            String name = c.name();
            groupCollector.visit(c);
            Collection<Ref> existingRefs = existing.get(c);
            if (rejectImplicitMerges) {
                Collections.addAll(mergedParents, c.getParents());
                mergedParents.remove(c);
            }
            boolean commitAlreadyTracked = !existingRefs.isEmpty();
            if (commitAlreadyTracked) {
                alreadyTracked++;
                // different target branch.
                for (Ref ref : existingRefs) {
                    updateGroups.add(new UpdateGroupsRequest(ref, c));
                }
                if (!(newChangeForAllNotInTarget || magicBranch.base != null)) {
                    continue;
                }
            }
            List<String> idList = c.getFooterLines(CHANGE_ID);
            if (!idList.isEmpty()) {
                pending.put(c, lookupByChangeKey(c, new Change.Key(idList.get(idList.size() - 1).trim())));
            } else {
                pending.put(c, lookupByCommit(c));
            }
            int n = pending.size() + newChanges.size();
            if (maxBatchChanges != 0 && n > maxBatchChanges) {
                logger.atFine().log("%d changes exceeds limit of %d", n, maxBatchChanges);
                reject(magicBranch.cmd, "the number of pushed changes in a batch exceeds the max limit " + maxBatchChanges);
                return Collections.emptyList();
            }
            if (commitAlreadyTracked) {
                boolean changeExistsOnDestBranch = false;
                for (ChangeData cd : pending.get(c).destChanges) {
                    if (cd.change().getDest().equals(magicBranch.dest)) {
                        changeExistsOnDestBranch = true;
                        break;
                    }
                }
                if (changeExistsOnDestBranch) {
                    continue;
                }
                logger.atFine().log("Creating new change for %s even though it is already tracked", name);
            }
            if (!validCommit(receivePack.getRevWalk(), magicBranch.dest, magicBranch.cmd, c, null)) {
                // Not a change the user can propose? Abort as early as possible.
                logger.atFine().log("Aborting early due to invalid commit");
                return Collections.emptyList();
            }
            // Don't allow merges to be uploaded in commit chain via all-not-in-target
            if (newChangeForAllNotInTarget && c.getParentCount() > 1) {
                reject(magicBranch.cmd, "Pushing merges in commit chains with 'all not in target' is not allowed,\n" + "to override please set the base manually");
                logger.atFine().log("Rejecting merge commit %s with newChangeForAllNotInTarget", name);
            // TODO(dborowitz): Should we early return here?
            }
            if (idList.isEmpty()) {
                newChanges.add(new CreateRequest(c, magicBranch.dest.get(), newProgress));
                continue;
            }
        }
        logger.atFine().log("Finished initial RevWalk with %d commits total: %d already" + " tracked, %d new changes with no Change-Id, and %d deferred" + " lookups", total, alreadyTracked, newChanges.size(), pending.size());
        if (rejectImplicitMerges) {
            rejectImplicitMerges(mergedParents);
        }
        for (Iterator<ChangeLookup> itr = pending.values().iterator(); itr.hasNext(); ) {
            ChangeLookup p = itr.next();
            if (p.changeKey == null) {
                continue;
            }
            if (newChangeIds.contains(p.changeKey)) {
                logger.atFine().log("Multiple commits with Change-Id %s", p.changeKey);
                reject(magicBranch.cmd, SAME_CHANGE_ID_IN_MULTIPLE_CHANGES);
                return Collections.emptyList();
            }
            List<ChangeData> changes = p.destChanges;
            if (changes.size() > 1) {
                logger.atFine().log("Multiple changes in branch %s with Change-Id %s: %s", magicBranch.dest, p.changeKey, changes.stream().map(cd -> cd.getId().toString()).collect(joining()));
                // WTF, multiple changes in this branch have the same key?
                // Since the commit is new, the user should recreate it with
                // a different Change-Id. In practice, we should never see
                // this error message as Change-Id should be unique per branch.
                // 
                reject(magicBranch.cmd, p.changeKey.get() + " has duplicates");
                return Collections.emptyList();
            }
            if (changes.size() == 1) {
                // Schedule as a replacement to this one matching change.
                // 
                RevId currentPs = changes.get(0).currentPatchSet().getRevision();
                // If Commit is already current PatchSet of target Change.
                if (p.commit.name().equals(currentPs.get())) {
                    if (pending.size() == 1) {
                        // There are no commits left to check, all commits in pending were already
                        // current PatchSet of the corresponding target changes.
                        reject(magicBranch.cmd, "commit(s) already exists (as current patchset)");
                    } else {
                        // Commit is already current PatchSet.
                        // Remove from pending and try next commit.
                        itr.remove();
                        continue;
                    }
                }
                if (requestReplace(magicBranch.cmd, false, changes.get(0).change(), p.commit)) {
                    continue;
                }
                return Collections.emptyList();
            }
            if (changes.size() == 0) {
                if (!isValidChangeId(p.changeKey.get())) {
                    reject(magicBranch.cmd, "invalid Change-Id");
                    return Collections.emptyList();
                }
                // double check against the existing refs
                if (foundInExistingRef(existing.get(p.commit))) {
                    if (pending.size() == 1) {
                        reject(magicBranch.cmd, "commit(s) already exists (as current patchset)");
                        return Collections.emptyList();
                    }
                    itr.remove();
                    continue;
                }
                newChangeIds.add(p.changeKey);
            }
            newChanges.add(new CreateRequest(p.commit, magicBranch.dest.get(), newProgress));
        }
        logger.atFine().log("Finished deferred lookups with %d updates and %d new changes", replaceByChange.size(), newChanges.size());
    } catch (IOException e) {
        // Should never happen, the core receive process would have
        // identified the missing object earlier before we got control.
        // 
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logger.atSevere().withCause(e).log("Invalid pack upload; one or more objects weren't sent");
        return Collections.emptyList();
    } catch (OrmException e) {
        logger.atSevere().withCause(e).log("Cannot query database to locate prior changes");
        reject(magicBranch.cmd, "database error");
        return Collections.emptyList();
    }
    if (newChanges.isEmpty() && replaceByChange.isEmpty()) {
        reject(magicBranch.cmd, "no new changes");
        return Collections.emptyList();
    }
    if (!newChanges.isEmpty() && magicBranch.edit) {
        reject(magicBranch.cmd, "edit is not supported for new changes");
        return newChanges;
    }
    try {
        SortedSetMultimap<ObjectId, String> groups = groupCollector.getGroups();
        List<Integer> newIds = seq.nextChangeIds(newChanges.size());
        for (int i = 0; i < newChanges.size(); i++) {
            CreateRequest create = newChanges.get(i);
            create.setChangeId(newIds.get(i));
            create.groups = ImmutableList.copyOf(groups.get(create.commit));
        }
        for (ReplaceRequest replace : replaceByChange.values()) {
            replace.groups = ImmutableList.copyOf(groups.get(replace.newCommitId));
        }
        for (UpdateGroupsRequest update : updateGroups) {
            update.groups = ImmutableList.copyOf((groups.get(update.commit)));
        }
        logger.atFine().log("Finished updating groups from GroupCollector");
    } catch (OrmException e) {
        logger.atSevere().withCause(e).log("Error collecting groups for changes");
        reject(magicBranch.cmd, "internal server error");
    }
    return newChanges;
}
#method_after
private List<CreateRequest> selectNewAndReplacedChangesFromMagicBranch(Task newProgress) {
    logger.atFine().log("Finding new and replaced changes");
    List<CreateRequest> newChanges = new ArrayList<>();
    ListMultimap<ObjectId, Ref> existing = changeRefsById();
    GroupCollector groupCollector = GroupCollector.create(changeRefsById(), db, psUtil, notesFactory, project.getNameKey());
    try {
        RevCommit start = setUpWalkForSelectingChanges();
        if (start == null) {
            return Collections.emptyList();
        }
        LinkedHashMap<RevCommit, ChangeLookup> pending = new LinkedHashMap<>();
        Set<Change.Key> newChangeIds = new HashSet<>();
        int maxBatchChanges = receiveConfig.getEffectiveMaxBatchChangesLimit(user);
        int total = 0;
        int alreadyTracked = 0;
        boolean rejectImplicitMerges = start.getParentCount() == 1 && projectCache.get(project.getNameKey()).is(BooleanProjectConfig.REJECT_IMPLICIT_MERGES) && // late.
        !magicBranch.merged;
        Set<RevCommit> mergedParents;
        if (rejectImplicitMerges) {
            mergedParents = new HashSet<>();
        } else {
            mergedParents = null;
        }
        for (; ; ) {
            RevCommit c = receivePack.getRevWalk().next();
            if (c == null) {
                break;
            }
            total++;
            receivePack.getRevWalk().parseBody(c);
            String name = c.name();
            groupCollector.visit(c);
            Collection<Ref> existingRefs = existing.get(c);
            if (rejectImplicitMerges) {
                Collections.addAll(mergedParents, c.getParents());
                mergedParents.remove(c);
            }
            boolean commitAlreadyTracked = !existingRefs.isEmpty();
            if (commitAlreadyTracked) {
                alreadyTracked++;
                // different target branch.
                for (Ref ref : existingRefs) {
                    updateGroups.add(new UpdateGroupsRequest(ref, c));
                }
                if (!(newChangeForAllNotInTarget || magicBranch.base != null)) {
                    continue;
                }
            }
            List<String> idList = c.getFooterLines(CHANGE_ID);
            if (!idList.isEmpty()) {
                pending.put(c, lookupByChangeKey(c, new Change.Key(idList.get(idList.size() - 1).trim())));
            } else {
                pending.put(c, lookupByCommit(c));
            }
            int n = pending.size() + newChanges.size();
            if (maxBatchChanges != 0 && n > maxBatchChanges) {
                logger.atFine().log("%d changes exceeds limit of %d", n, maxBatchChanges);
                reject(magicBranch.cmd, "the number of pushed changes in a batch exceeds the max limit " + maxBatchChanges);
                return Collections.emptyList();
            }
            if (commitAlreadyTracked) {
                boolean changeExistsOnDestBranch = false;
                for (ChangeData cd : pending.get(c).destChanges) {
                    if (cd.change().getDest().equals(magicBranch.dest)) {
                        changeExistsOnDestBranch = true;
                        break;
                    }
                }
                if (changeExistsOnDestBranch) {
                    continue;
                }
                logger.atFine().log("Creating new change for %s even though it is already tracked", name);
            }
            if (!validCommit(receivePack.getRevWalk().getObjectReader(), magicBranch.dest, magicBranch.cmd, c, magicBranch.merged, null)) {
                // Not a change the user can propose? Abort as early as possible.
                logger.atFine().log("Aborting early due to invalid commit");
                return Collections.emptyList();
            }
            // Don't allow merges to be uploaded in commit chain via all-not-in-target
            if (newChangeForAllNotInTarget && c.getParentCount() > 1) {
                reject(magicBranch.cmd, "Pushing merges in commit chains with 'all not in target' is not allowed,\n" + "to override please set the base manually");
                logger.atFine().log("Rejecting merge commit %s with newChangeForAllNotInTarget", name);
            // TODO(dborowitz): Should we early return here?
            }
            if (idList.isEmpty()) {
                newChanges.add(new CreateRequest(c, magicBranch.dest.get(), newProgress));
                continue;
            }
        }
        logger.atFine().log("Finished initial RevWalk with %d commits total: %d already" + " tracked, %d new changes with no Change-Id, and %d deferred" + " lookups", total, alreadyTracked, newChanges.size(), pending.size());
        if (rejectImplicitMerges) {
            rejectImplicitMerges(mergedParents);
        }
        for (Iterator<ChangeLookup> itr = pending.values().iterator(); itr.hasNext(); ) {
            ChangeLookup p = itr.next();
            if (p.changeKey == null) {
                continue;
            }
            if (newChangeIds.contains(p.changeKey)) {
                logger.atFine().log("Multiple commits with Change-Id %s", p.changeKey);
                reject(magicBranch.cmd, SAME_CHANGE_ID_IN_MULTIPLE_CHANGES);
                return Collections.emptyList();
            }
            List<ChangeData> changes = p.destChanges;
            if (changes.size() > 1) {
                logger.atFine().log("Multiple changes in branch %s with Change-Id %s: %s", magicBranch.dest, p.changeKey, changes.stream().map(cd -> cd.getId().toString()).collect(joining()));
                // WTF, multiple changes in this branch have the same key?
                // Since the commit is new, the user should recreate it with
                // a different Change-Id. In practice, we should never see
                // this error message as Change-Id should be unique per branch.
                // 
                reject(magicBranch.cmd, p.changeKey.get() + " has duplicates");
                return Collections.emptyList();
            }
            if (changes.size() == 1) {
                // Schedule as a replacement to this one matching change.
                // 
                RevId currentPs = changes.get(0).currentPatchSet().getRevision();
                // If Commit is already current PatchSet of target Change.
                if (p.commit.name().equals(currentPs.get())) {
                    if (pending.size() == 1) {
                        // There are no commits left to check, all commits in pending were already
                        // current PatchSet of the corresponding target changes.
                        reject(magicBranch.cmd, "commit(s) already exists (as current patchset)");
                    } else {
                        // Commit is already current PatchSet.
                        // Remove from pending and try next commit.
                        itr.remove();
                        continue;
                    }
                }
                if (requestReplace(magicBranch.cmd, false, changes.get(0).change(), p.commit)) {
                    continue;
                }
                return Collections.emptyList();
            }
            if (changes.size() == 0) {
                if (!isValidChangeId(p.changeKey.get())) {
                    reject(magicBranch.cmd, "invalid Change-Id");
                    return Collections.emptyList();
                }
                // double check against the existing refs
                if (foundInExistingRef(existing.get(p.commit))) {
                    if (pending.size() == 1) {
                        reject(magicBranch.cmd, "commit(s) already exists (as current patchset)");
                        return Collections.emptyList();
                    }
                    itr.remove();
                    continue;
                }
                newChangeIds.add(p.changeKey);
            }
            newChanges.add(new CreateRequest(p.commit, magicBranch.dest.get(), newProgress));
        }
        logger.atFine().log("Finished deferred lookups with %d updates and %d new changes", replaceByChange.size(), newChanges.size());
    } catch (IOException e) {
        // Should never happen, the core receive process would have
        // identified the missing object earlier before we got control.
        // 
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logger.atSevere().withCause(e).log("Invalid pack upload; one or more objects weren't sent");
        return Collections.emptyList();
    } catch (OrmException e) {
        logger.atSevere().withCause(e).log("Cannot query database to locate prior changes");
        reject(magicBranch.cmd, "database error");
        return Collections.emptyList();
    }
    if (newChanges.isEmpty() && replaceByChange.isEmpty()) {
        reject(magicBranch.cmd, "no new changes");
        return Collections.emptyList();
    }
    if (!newChanges.isEmpty() && magicBranch.edit) {
        reject(magicBranch.cmd, "edit is not supported for new changes");
        return newChanges;
    }
    try {
        SortedSetMultimap<ObjectId, String> groups = groupCollector.getGroups();
        List<Integer> newIds = seq.nextChangeIds(newChanges.size());
        for (int i = 0; i < newChanges.size(); i++) {
            CreateRequest create = newChanges.get(i);
            create.setChangeId(newIds.get(i));
            create.groups = ImmutableList.copyOf(groups.get(create.commit));
        }
        for (ReplaceRequest replace : replaceByChange.values()) {
            replace.groups = ImmutableList.copyOf(groups.get(replace.newCommitId));
        }
        for (UpdateGroupsRequest update : updateGroups) {
            update.groups = ImmutableList.copyOf((groups.get(update.commit)));
        }
        logger.atFine().log("Finished updating groups from GroupCollector");
    } catch (OrmException e) {
        logger.atSevere().withCause(e).log("Error collecting groups for changes");
        reject(magicBranch.cmd, "internal server error");
    }
    return newChanges;
}
#end_block

#method_before
private void addOps(BatchUpdate bu) throws RestApiException {
    checkState(changeId != null, "must call setChangeId before addOps");
    try {
        RevWalk rw = receivePack.getRevWalk();
        rw.parseBody(commit);
        final PatchSet.Id psId = ins.setGroups(groups).getPatchSetId();
        Account.Id me = user.getAccountId();
        List<FooterLine> footerLines = commit.getFooterLines();
        MailRecipients recipients = new MailRecipients();
        Map<String, Short> approvals = new HashMap<>();
        checkNotNull(magicBranch);
        recipients.add(magicBranch.getMailRecipients());
        approvals = magicBranch.labels;
        recipients.add(getRecipientsFromFooters(accountResolver, footerLines));
        recipients.remove(me);
        StringBuilder msg = new StringBuilder(ApprovalsUtil.renderMessageWithApprovals(psId.get(), approvals, Collections.<String, PatchSetApproval>emptyMap()));
        msg.append('.');
        if (!Strings.isNullOrEmpty(magicBranch.message)) {
            msg.append("\n").append(magicBranch.message);
        }
        bu.insertChange(ins.setReviewers(recipients.getReviewers()).setExtraCC(recipients.getCcOnly()).setApprovals(approvals).setMessage(msg.toString()).setNotify(magicBranch.getNotify()).setAccountsToNotify(magicBranch.getAccountsToNotify()).setRequestScopePropagator(requestScopePropagator).setSendMail(true).setPatchSetDescription(magicBranch.message));
        if (!magicBranch.hashtags.isEmpty()) {
            // Any change owner is allowed to add hashtags when creating a change.
            bu.addOp(changeId, hashtagsFactory.create(new HashtagsInput(magicBranch.hashtags)).setFireEvent(false));
        }
        if (!Strings.isNullOrEmpty(magicBranch.topic)) {
            bu.addOp(changeId, new BatchUpdateOp() {

                @Override
                public boolean updateChange(ChangeContext ctx) {
                    ctx.getUpdate(psId).setTopic(magicBranch.topic);
                    return true;
                }
            });
        }
        bu.addOp(changeId, new BatchUpdateOp() {

            @Override
            public boolean updateChange(ChangeContext ctx) {
                change = ctx.getChange();
                return false;
            }
        });
        bu.addOp(changeId, new ChangeProgressOp(progress));
    } catch (Exception e) {
        throw INSERT_EXCEPTION.apply(e);
    }
}
#method_after
private void addOps(BatchUpdate bu) throws RestApiException {
    checkState(changeId != null, "must call setChangeId before addOps");
    try {
        RevWalk rw = receivePack.getRevWalk();
        rw.parseBody(commit);
        final PatchSet.Id psId = ins.setGroups(groups).getPatchSetId();
        Account.Id me = user.getAccountId();
        List<FooterLine> footerLines = commit.getFooterLines();
        MailRecipients recipients = new MailRecipients();
        checkNotNull(magicBranch);
        recipients.add(magicBranch.getMailRecipients());
        Map<String, Short> approvals = magicBranch.labels;
        recipients.add(getRecipientsFromFooters(accountResolver, footerLines));
        recipients.remove(me);
        StringBuilder msg = new StringBuilder(ApprovalsUtil.renderMessageWithApprovals(psId.get(), approvals, Collections.emptyMap()));
        msg.append('.');
        if (!Strings.isNullOrEmpty(magicBranch.message)) {
            msg.append("\n").append(magicBranch.message);
        }
        bu.insertChange(ins.setReviewers(recipients.getReviewers()).setExtraCC(recipients.getCcOnly()).setApprovals(approvals).setMessage(msg.toString()).setNotify(magicBranch.getNotify()).setAccountsToNotify(magicBranch.getAccountsToNotify()).setRequestScopePropagator(requestScopePropagator).setSendMail(true).setPatchSetDescription(magicBranch.message));
        if (!magicBranch.hashtags.isEmpty()) {
            // Any change owner is allowed to add hashtags when creating a change.
            bu.addOp(changeId, hashtagsFactory.create(new HashtagsInput(magicBranch.hashtags)).setFireEvent(false));
        }
        if (!Strings.isNullOrEmpty(magicBranch.topic)) {
            bu.addOp(changeId, new BatchUpdateOp() {

                @Override
                public boolean updateChange(ChangeContext ctx) {
                    ctx.getUpdate(psId).setTopic(magicBranch.topic);
                    return true;
                }
            });
        }
        bu.addOp(changeId, new BatchUpdateOp() {

            @Override
            public boolean updateChange(ChangeContext ctx) {
                change = ctx.getChange();
                return false;
            }
        });
        bu.addOp(changeId, new ChangeProgressOp(progress));
    } catch (Exception e) {
        throw INSERT_EXCEPTION.apply(e);
    }
}
#end_block

#method_before
boolean validateNewPatchSet() throws IOException, OrmException, PermissionBackendException {
    if (!validateNewPatchSetCommit()) {
        return false;
    }
    sameTreeWarning();
    if (magicBranch != null) {
        validateMagicBranchWipStatusChange();
        if (inputCommand.getResult() != NOT_ATTEMPTED) {
            return false;
        }
        if (magicBranch.edit || magicBranch.draft) {
            return newEdit();
        }
    }
    newPatchSet();
    return true;
}
#method_after
boolean validateNewPatchSet() throws IOException, OrmException, PermissionBackendException {
    if (!validateNewPatchSetNoteDb()) {
        return false;
    }
    sameTreeWarning();
    if (magicBranch != null) {
        validateMagicBranchWipStatusChange();
        if (inputCommand.getResult() != NOT_ATTEMPTED) {
            return false;
        }
        if (magicBranch.edit || magicBranch.draft) {
            return newEdit();
        }
    }
    newPatchSet();
    return true;
}
#end_block

#method_before
boolean validateNewPatchSetForAutoClose() throws IOException, OrmException, PermissionBackendException {
    if (!validateNewPatchSetCommit()) {
        return false;
    }
    newPatchSet();
    return true;
}
#method_after
boolean validateNewPatchSetForAutoClose() throws IOException, OrmException, PermissionBackendException {
    if (!validateNewPatchSetNoteDb()) {
        return false;
    }
    newPatchSet();
    return true;
}
#end_block

#method_before
private boolean newEdit() {
    psId = notes.getChange().currentPatchSetId();
    Optional<ChangeEdit> edit = null;
    try {
        edit = editUtil.byChange(notes, user);
    } catch (AuthException | IOException e) {
        logger.atSevere().withCause(e).log("Cannot retrieve edit");
        return false;
    }
    if (edit.isPresent()) {
        if (edit.get().getBasePatchSet().getId().equals(psId)) {
            // replace edit
            cmd = new ReceiveCommand(edit.get().getEditCommit(), newCommitId, edit.get().getRefName());
        } else {
            // delete old edit ref on rebase
            prev = new ReceiveCommand(edit.get().getEditCommit(), ObjectId.zeroId(), edit.get().getRefName());
            createEditCommand();
        }
    } else {
        createEditCommand();
    }
    return true;
}
#method_after
private boolean newEdit() {
    psId = notes.getChange().currentPatchSetId();
    Optional<ChangeEdit> edit;
    try {
        edit = editUtil.byChange(notes, user);
    } catch (AuthException | IOException e) {
        logger.atSevere().withCause(e).log("Cannot retrieve edit");
        return false;
    }
    if (edit.isPresent()) {
        if (edit.get().getBasePatchSet().getId().equals(psId)) {
            // replace edit
            cmd = new ReceiveCommand(edit.get().getEditCommit(), newCommitId, edit.get().getRefName());
        } else {
            // delete old edit ref on rebase
            prev = new ReceiveCommand(edit.get().getEditCommit(), ObjectId.zeroId(), edit.get().getRefName());
            createEditCommand();
        }
    } else {
        createEditCommand();
    }
    return true;
}
#end_block

#method_before
private boolean validCommit(RevWalk rw, Branch.NameKey branch, ReceiveCommand cmd, ObjectId id, @Nullable Change change) throws IOException {
    PermissionBackend.ForRef perm = permissions.ref(branch.get());
    ValidCommitKey key = new AutoValue_ReceiveCommits_ValidCommitKey(id.copy(), branch);
    if (validCommits.contains(key)) {
        return true;
    }
    RevCommit c = rw.parseCommit(id);
    rw.parseBody(c);
    try (CommitReceivedEvent receiveEvent = new CommitReceivedEvent(cmd, project, branch.get(), rw.getObjectReader(), c, user)) {
        boolean isMerged = magicBranch != null && cmd.getRefName().equals(magicBranch.cmd.getRefName()) && magicBranch.merged;
        CommitValidators validators = isMerged ? commitValidatorsFactory.forMergedCommits(project.getNameKey(), perm, user.asIdentifiedUser()) : commitValidatorsFactory.forReceiveCommits(perm, branch, user.asIdentifiedUser(), sshInfo, repo, rw, change);
        messages.addAll(validators.validate(receiveEvent));
    } catch (CommitValidationException e) {
        logger.atFine().log("Commit validation failed on %s", c.name());
        messages.addAll(e.getMessages());
        reject(cmd, e.getMessage());
        return false;
    }
    validCommits.add(key);
    return true;
}
#method_after
private boolean validCommit(ObjectReader objectReader, Branch.NameKey branch, ReceiveCommand cmd, RevCommit commit, boolean isMerged, @Nullable Change change) throws IOException {
    PermissionBackend.ForRef perm = permissions.ref(branch.get());
    ValidCommitKey key = new AutoValue_ReceiveCommits_ValidCommitKey(commit.copy(), branch);
    if (validCommits.contains(key)) {
        return true;
    }
    try (CommitReceivedEvent receiveEvent = new CommitReceivedEvent(cmd, project, branch.get(), objectReader, commit, user)) {
        CommitValidators validators = isMerged ? commitValidatorsFactory.forMergedCommits(project.getNameKey(), perm, user.asIdentifiedUser()) : commitValidatorsFactory.forReceiveCommits(perm, branch, user.asIdentifiedUser(), sshInfo, repo, receiveEvent.revWalk, change);
        messages.addAll(validators.validate(receiveEvent));
    } catch (CommitValidationException e) {
        logger.atFine().log("Commit validation failed on %s", commit.name());
        messages.addAll(e.getMessages());
        reject(cmd, e.getMessage());
        return false;
    }
    validCommits.add(key);
    return true;
}
#end_block

#method_before
private void reject(ReceiveCommand cmd, String why) {
    cmd.setResult(REJECTED_OTHER_REASON, why);
}
#method_after
private static void reject(ReceiveCommand cmd, String why) {
    cmd.setResult(REJECTED_OTHER_REASON, why);
}
#end_block

#method_before
static AllExternalIds create(Multimap<Id, ExternalId> byAccount) {
    SetMultimap<String, ExternalId> byEmailCopy = MultimapBuilder.hashKeys(byAccount.size()).hashSetValues(1).build();
    byAccount.values().stream().filter(e -> !Strings.isNullOrEmpty(e.email())).forEach(e -> byEmailCopy.put(e.email(), e));
    return new AutoValue_AllExternalIds(Multimaps.unmodifiableSetMultimap(MultimapBuilder.hashKeys(byAccount.size()).hashSetValues(5).build(byAccount)), Multimaps.unmodifiableSetMultimap(byEmailCopy));
}
#method_after
static AllExternalIds create(Multimap<Id, ExternalId> byAccount) {
    SetMultimap<String, ExternalId> byEmailCopy = MultimapBuilder.hashKeys(byAccount.size()).hashSetValues(1).build();
    byAccount.values().stream().filter(e -> !Strings.isNullOrEmpty(e.email())).forEach(e -> byEmailCopy.put(e.email(), e));
    return new AutoValue_AllExternalIds(ImmutableSetMultimap.copyOf(MultimapBuilder.hashKeys(byAccount.size()).hashSetValues(5).build(byAccount)), ImmutableSetMultimap.copyOf(byEmailCopy));
}
#end_block

#method_before
public T load() throws OrmException {
    if (loaded) {
        return self();
    }
    logger.atFinest().log("Load %s for change %s of project %s from %s (%s)", getClass().getSimpleName(), getChangeId(), getProjectName(), getRefName(), primaryStorage);
    boolean read = args.migration.readChanges();
    if (!read && primaryStorage == PrimaryStorage.NOTE_DB) {
        throw new OrmException("NoteDb is required to read change " + changeId);
    }
    boolean readOrWrite = read || args.migration.rawWriteChangesSetting();
    if (!readOrWrite) {
        // Don't even open the repo if we neither write to nor read from NoteDb. It's possible that
        // there is some garbage in the noteDbState field and/or the repo, but at this point NoteDb is
        // completely off so it's none of our business.
        loadDefaults();
        return self();
    }
    if (args.migration.failOnLoadForTest()) {
        throw new OrmException("Reading from NoteDb is disabled");
    }
    try (Timer1.Context timer = args.metrics.readLatency.start(CHANGES);
        Repository repo = args.repoManager.openRepository(getProjectName());
        // auto-rebuilding before this object may get passed to a ChangeUpdate.
        LoadHandle handle = openHandle(repo)) {
        if (read) {
            revision = handle.id();
            onLoad(handle);
        } else {
            loadDefaults();
        }
        loaded = true;
    } catch (ConfigInvalidException | IOException e) {
        throw new OrmException(e);
    }
    return self();
}
#method_after
public T load() throws OrmException {
    if (loaded) {
        return self();
    }
    boolean read = args.migration.readChanges();
    if (!read && primaryStorage == PrimaryStorage.NOTE_DB) {
        throw new OrmException("NoteDb is required to read change " + changeId);
    }
    boolean readOrWrite = read || args.migration.rawWriteChangesSetting();
    if (!readOrWrite) {
        // Don't even open the repo if we neither write to nor read from NoteDb. It's possible that
        // there is some garbage in the noteDbState field and/or the repo, but at this point NoteDb is
        // completely off so it's none of our business.
        loadDefaults();
        return self();
    }
    if (args.migration.failOnLoadForTest()) {
        throw new OrmException("Reading from NoteDb is disabled");
    }
    try (Timer1.Context timer = args.metrics.readLatency.start(CHANGES);
        Repository repo = args.repoManager.openRepository(getProjectName());
        // auto-rebuilding before this object may get passed to a ChangeUpdate.
        LoadHandle handle = openHandle(repo)) {
        if (read) {
            revision = handle.id();
            onLoad(handle);
        } else {
            loadDefaults();
        }
        loaded = true;
    } catch (ConfigInvalidException | IOException e) {
        throw new OrmException(e);
    }
    return self();
}
#end_block

#method_before
@Override
protected void onLoad() {
    super.onLoad();
    query = new Query(match).start(start).run();
    savedPanel = TAGS;
}
#method_after
@Override
protected void onLoad() {
    super.onLoad();
    addPanel.setVisible(false);
    AccessMap.get(getProjectKey(), new GerritCallback<ProjectAccessInfo>() {

        @Override
        public void onSuccess(ProjectAccessInfo result) {
            addPanel.setVisible(result.canAddRefs());
        }
    });
    query = new Query(match).start(start).run();
    savedPanel = TAGS;
}
#end_block

#method_before
@Override
protected void onInitUI() {
    super.onInitUI();
    initPageHeader();
    prev = PagingHyperlink.createPrev();
    prev.setVisible(false);
    next = PagingHyperlink.createNext();
    next.setVisible(false);
    addPanel = new FlowPanel();
    final Grid addGrid = new Grid(2, 2);
    addGrid.setStyleName(Gerrit.RESOURCES.css().addBranch());
    final int texBoxLength = 50;
    nameTxtBox = new HintTextBox();
    nameTxtBox.setVisibleLength(texBoxLength);
    nameTxtBox.setHintText(Util.C.defaultTagName());
    nameTxtBox.addKeyPressHandler(new KeyPressHandler() {

        @Override
        public void onKeyPress(KeyPressEvent event) {
            if (event.getNativeEvent().getKeyCode() == KeyCodes.KEY_ENTER) {
                doAddNewTag();
            }
        }
    });
    addGrid.setText(0, 0, Util.C.columnTagName() + ":");
    addGrid.setWidget(0, 1, nameTxtBox);
    irevTxtBox = new HintTextBox();
    irevTxtBox.setVisibleLength(texBoxLength);
    irevTxtBox.setHintText(Util.C.defaultRevisionSpec());
    irevTxtBox.addKeyPressHandler(new KeyPressHandler() {

        @Override
        public void onKeyPress(KeyPressEvent event) {
            if (event.getNativeEvent().getKeyCode() == KeyCodes.KEY_ENTER) {
                doAddNewTag();
            }
        }
    });
    addGrid.setText(1, 0, Util.C.initialRevision() + ":");
    addGrid.setWidget(1, 1, irevTxtBox);
    addTag = new Button(Util.C.buttonAddTag());
    addTag.addClickHandler(new ClickHandler() {

        @Override
        public void onClick(final ClickEvent event) {
            doAddNewTag();
        }
    });
    addPanel.add(addGrid);
    addPanel.add(addTag);
    tagTable = new TagsTable();
    HorizontalPanel buttons = new HorizontalPanel();
    buttons.setStyleName(Gerrit.RESOURCES.css().branchTablePrevNextLinks());
    buttons.add(prev);
    buttons.add(next);
    add(tagTable);
    add(buttons);
    add(addPanel);
}
#method_after
@Override
protected void onInitUI() {
    super.onInitUI();
    initPageHeader();
    prev = PagingHyperlink.createPrev();
    prev.setVisible(false);
    next = PagingHyperlink.createNext();
    next.setVisible(false);
    addPanel = new FlowPanel();
    Grid addGrid = new Grid(2, 2);
    addGrid.setStyleName(Gerrit.RESOURCES.css().addBranch());
    int texBoxLength = 50;
    nameTxtBox = new HintTextBox();
    nameTxtBox.setVisibleLength(texBoxLength);
    nameTxtBox.setHintText(AdminConstants.I.defaultTagName());
    nameTxtBox.addKeyPressHandler(new KeyPressHandler() {

        @Override
        public void onKeyPress(KeyPressEvent event) {
            if (event.getNativeEvent().getKeyCode() == KeyCodes.KEY_ENTER) {
                doAddNewTag();
            }
        }
    });
    addGrid.setText(0, 0, AdminConstants.I.columnTagName() + ":");
    addGrid.setWidget(0, 1, nameTxtBox);
    irevTxtBox = new HintTextBox();
    irevTxtBox.setVisibleLength(texBoxLength);
    irevTxtBox.setHintText(AdminConstants.I.defaultRevisionSpec());
    irevTxtBox.addKeyPressHandler(new KeyPressHandler() {

        @Override
        public void onKeyPress(KeyPressEvent event) {
            if (event.getNativeEvent().getKeyCode() == KeyCodes.KEY_ENTER) {
                doAddNewTag();
            }
        }
    });
    addGrid.setText(1, 0, AdminConstants.I.initialRevision() + ":");
    addGrid.setWidget(1, 1, irevTxtBox);
    addTag = new Button(AdminConstants.I.buttonAddTag());
    addTag.addClickHandler(new ClickHandler() {

        @Override
        public void onClick(ClickEvent event) {
            doAddNewTag();
        }
    });
    addPanel.add(addGrid);
    addPanel.add(addTag);
    tagTable = new TagsTable();
    HorizontalPanel buttons = new HorizontalPanel();
    buttons.setStyleName(Gerrit.RESOURCES.css().branchTablePrevNextLinks());
    buttons.add(prev);
    buttons.add(next);
    add(tagTable);
    add(buttons);
    add(addPanel);
}
#end_block

#method_before
private void initPageHeader() {
    parseToken();
    HorizontalPanel hp = new HorizontalPanel();
    hp.setStyleName(Gerrit.RESOURCES.css().projectFilterPanel());
    Label filterLabel = new Label(Util.C.projectFilter());
    filterLabel.setStyleName(Gerrit.RESOURCES.css().projectFilterLabel());
    hp.add(filterLabel);
    filterTxt = new NpTextBox();
    filterTxt.setValue(match);
    filterTxt.addKeyUpHandler(new KeyUpHandler() {

        @Override
        public void onKeyUp(KeyUpEvent event) {
            Query q = new Query(filterTxt.getValue());
            if (match.equals(q.qMatch)) {
                q.start(start);
            } else {
                if (query == null) {
                    q.run();
                }
                query = q;
            }
        }
    });
    hp.add(filterTxt);
    add(hp);
}
#method_after
private void initPageHeader() {
    parseToken();
    HorizontalPanel hp = new HorizontalPanel();
    hp.setStyleName(Gerrit.RESOURCES.css().projectFilterPanel());
    Label filterLabel = new Label(AdminConstants.I.projectFilter());
    filterLabel.setStyleName(Gerrit.RESOURCES.css().projectFilterLabel());
    hp.add(filterLabel);
    filterTxt = new NpTextBox();
    filterTxt.setValue(match);
    filterTxt.addKeyUpHandler(new KeyUpHandler() {

        @Override
        public void onKeyUp(KeyUpEvent event) {
            Query q = new Query(filterTxt.getValue());
            if (match.equals(q.qMatch)) {
                q.start(start);
            } else {
                if (query == null) {
                    q.run();
                }
                query = q;
            }
        }
    });
    hp.add(filterTxt);
    add(hp);
}
#end_block

#method_before
private void doAddNewTag() {
    final String tagName = nameTxtBox.getText().trim();
    if ("".equals(tagName)) {
        nameTxtBox.setFocus(true);
        return;
    }
    final String rev = irevTxtBox.getText().trim();
    if ("".equals(rev)) {
        irevTxtBox.setText("HEAD");
        Scheduler.get().scheduleDeferred(new ScheduledCommand() {

            @Override
            public void execute() {
                irevTxtBox.selectAll();
                irevTxtBox.setFocus(true);
            }
        });
        return;
    }
    addTag.setEnabled(false);
    ProjectApi.createTag(getProjectKey(), tagName, rev, new GerritCallback<TagInfo>() {

        @Override
        public void onSuccess(TagInfo tag) {
            showAddedTag(tag);
            nameTxtBox.setText("");
            irevTxtBox.setText("");
            query = new Query(match).start(start).run();
        }

        @Override
        public void onFailure(Throwable caught) {
            addTag.setEnabled(true);
            selectAllAndFocus(nameTxtBox);
            new ErrorDialog(caught.getMessage()).center();
        }
    });
}
#method_after
private void doAddNewTag() {
    String tagName = nameTxtBox.getText().trim();
    if (tagName.isEmpty()) {
        nameTxtBox.setFocus(true);
        return;
    }
    String rev = irevTxtBox.getText().trim();
    if (rev.isEmpty()) {
        irevTxtBox.setText("HEAD");
        Scheduler.get().scheduleDeferred(new ScheduledCommand() {

            @Override
            public void execute() {
                irevTxtBox.selectAll();
                irevTxtBox.setFocus(true);
            }
        });
        return;
    }
    addTag.setEnabled(false);
    ProjectApi.createTag(getProjectKey(), tagName, rev, new GerritCallback<TagInfo>() {

        @Override
        public void onSuccess(TagInfo tag) {
            showAddedTag(tag);
            nameTxtBox.setText("");
            irevTxtBox.setText("");
            query = new Query(match).start(start).run();
        }

        @Override
        public void onFailure(Throwable caught) {
            addTag.setEnabled(true);
            selectAllAndFocus(nameTxtBox);
            new ErrorDialog(caught.getMessage()).center();
        }
    });
}
#end_block

#method_before
Set<String> getCheckedRefs() {
    Set<String> refs = new HashSet<>();
    for (int row = 1; row < table.getRowCount(); row++) {
        final TagInfo k = getRowItem(row);
        if (k != null && table.getWidget(row, 1) instanceof CheckBox && ((CheckBox) table.getWidget(row, 1)).getValue()) {
            refs.add(k.ref());
        }
    }
    return refs;
}
#method_after
Set<String> getCheckedRefs() {
    Set<String> refs = new HashSet<>();
    for (int row = 1; row < table.getRowCount(); row++) {
        TagInfo k = getRowItem(row);
        if (k != null && table.getWidget(row, 1) instanceof CheckBox && ((CheckBox) table.getWidget(row, 1)).getValue()) {
            refs.add(k.ref());
        }
    }
    return refs;
}
#end_block

#method_before
void setChecked(Set<String> refs) {
    for (int row = 1; row < table.getRowCount(); row++) {
        final TagInfo k = getRowItem(row);
        if (k != null && refs.contains(k.ref()) && table.getWidget(row, 1) instanceof CheckBox) {
            ((CheckBox) table.getWidget(row, 1)).setValue(true);
        }
    }
}
#method_after
void setChecked(Set<String> refs) {
    for (int row = 1; row < table.getRowCount(); row++) {
        TagInfo k = getRowItem(row);
        if (k != null && refs.contains(k.ref()) && table.getWidget(row, 1) instanceof CheckBox) {
            ((CheckBox) table.getWidget(row, 1)).setValue(true);
        }
    }
}
#end_block

#method_before
void displaySubset(List<TagInfo> tags, int fromIndex, int toIndex) {
    canDelete = false;
    while (1 < table.getRowCount()) {
        table.removeRow(table.getRowCount() - 1);
    }
    for (TagInfo k : tags.subList(fromIndex, toIndex)) {
        final int row = table.getRowCount();
        table.insertRow(row);
        applyDataRowStyle(row);
        populate(row, k);
    }
}
#method_after
void displaySubset(List<TagInfo> tags, int fromIndex, int toIndex) {
    while (1 < table.getRowCount()) {
        table.removeRow(table.getRowCount() - 1);
    }
    for (TagInfo k : tags.subList(fromIndex, toIndex)) {
        int row = table.getRowCount();
        table.insertRow(row);
        applyDataRowStyle(row);
        populate(row, k);
    }
}
#end_block

#method_before
void populate(int row, TagInfo k) {
    table.setText(row, 1, "");
    table.setWidget(row, 2, new InlineHTML(highlight(k.getShortName(), match)));
    if (k.revision() != null) {
        if ("HEAD".equals(k.getShortName())) {
            setHeadRevision(row, 3, k.revision());
        } else {
            table.setText(row, 3, k.revision());
        }
    } else {
        table.setText(row, 3, "");
    }
    final FlexCellFormatter fmt = table.getFlexCellFormatter();
    String iconCellStyle = Gerrit.RESOURCES.css().iconCell();
    String dataCellStyle = Gerrit.RESOURCES.css().dataCell();
    if (RefNames.REFS_CONFIG.equals(k.getShortName()) || "HEAD".equals(k.getShortName())) {
        iconCellStyle = Gerrit.RESOURCES.css().specialBranchIconCell();
        dataCellStyle = Gerrit.RESOURCES.css().specialBranchDataCell();
        fmt.setStyleName(row, 0, iconCellStyle);
    }
    fmt.addStyleName(row, 1, iconCellStyle);
    fmt.addStyleName(row, 2, dataCellStyle);
    fmt.addStyleName(row, 3, dataCellStyle);
    fmt.addStyleName(row, 4, dataCellStyle);
    setRowItem(row, k);
}
#method_after
void populate(int row, TagInfo k) {
    table.setText(row, 1, "");
    table.setWidget(row, 2, new InlineHTML(highlight(k.getShortName(), match)));
    if (k.revision() != null) {
        table.setText(row, 3, k.revision());
    } else {
        table.setText(row, 3, "");
    }
    FlexCellFormatter fmt = table.getFlexCellFormatter();
    String iconCellStyle = Gerrit.RESOURCES.css().iconCell();
    String dataCellStyle = Gerrit.RESOURCES.css().dataCell();
    fmt.addStyleName(row, 1, iconCellStyle);
    fmt.addStyleName(row, 2, dataCellStyle);
    fmt.addStyleName(row, 3, dataCellStyle);
    setRowItem(row, k);
}
#end_block

#method_before
private static String readCSS() {
    if (defaultCss != null) {
        return defaultCss;
    }
    try {
        return readPegdownCss(new AtomicBoolean());
    } catch (IOException err) {
        log.warn("Cannot load pegdown.css", err);
        return "";
    }
}
#method_after
private static String readCSS() {
    if (defaultCss != null) {
        return defaultCss;
    }
    try {
        return readFlexMarkJavaCss(new AtomicBoolean());
    } catch (IOException err) {
        logger.atWarning().withCause(err).log("Cannot load flexmark-java.css");
        return "";
    }
}
#end_block

#method_before
private MutableDataHolder markDownOptions() {
    int options = ALL & ~(HARDWRAPS);
    if (suppressHtml) {
        options |= SUPPRESS_ALL_HTML;
    }
    MutableDataHolder optionsExt = PegdownOptionsAdapter.flexmarkOptions(options).toMutable();
    ArrayList<Extension> extensions = new ArrayList<Extension>();
    for (Extension extension : optionsExt.get(com.vladsch.flexmark.parser.Parser.EXTENSIONS)) {
        extensions.add(extension);
    }
    return optionsExt;
}
#method_after
private MutableDataHolder markDownOptions() {
    int options = ALL & ~(HARDWRAPS);
    if (suppressHtml) {
        options |= SUPPRESS_ALL_HTML;
    }
    MutableDataHolder optionsExt = PegdownOptionsAdapter.flexmarkOptions(options, MarkdownFormatterHeader.HeadingExtension.create()).toMutable();
    ArrayList<Extension> extensions = new ArrayList<>();
    for (Extension extension : optionsExt.get(com.vladsch.flexmark.parser.Parser.EXTENSIONS)) {
        extensions.add(extension);
    }
    return optionsExt;
}
#end_block

#method_before
private String findTitle(Node root) {
    if (root instanceof Heading) {
        Heading h = (Heading) root;
        if (h.getLevel() == 1 && h.getChildren() != null) {
            StringBuilder b = new StringBuilder();
            for (Node n : root.getChildren()) {
                TextCollectingVisitor collectingVisitor = new TextCollectingVisitor();
                String headingText = collectingVisitor.collectAndGetText(n);
                b.append(headingText);
            }
            return b.toString();
        }
    }
    for (Node n : root.getChildren()) {
        String title = findTitle(n);
        if (title != null) {
            return title;
        }
    }
    return null;
}
#method_after
private String findTitle(Node root) {
    if (root instanceof Heading) {
        Heading h = (Heading) root;
        if (h.getLevel() == 1 && h.hasChildren()) {
            TextCollectingVisitor collectingVisitor = new TextCollectingVisitor();
            return collectingVisitor.collectAndGetText(h);
        }
    }
    if (root instanceof Block && root.hasChildren()) {
        Node child = root.getFirstChild();
        while (child != null) {
            String title = findTitle(child);
            if (title != null) {
                return title;
            }
            child = child.getNext();
        }
    }
    return null;
}
#end_block

#method_before
@Test
public void guessRestApiInReflog() throws Exception {
    assume().that(notesMigration.disableChangeReviewDb()).isTrue();
    PushOneCommit.Result r = createChange();
    Change.Id id = r.getChange().getId();
    try (Repository repo = repoManager.openRepository(r.getChange().project())) {
        File log = new File(repo.getDirectory(), "logs/" + changeMetaRef(id));
        if (!log.exists()) {
            log.getParentFile().mkdirs();
            assertThat(log.createNewFile()).isTrue();
        }
        gApi.changes().id(id.get()).topic("foo");
        ReflogEntry last = repo.getReflogReader(changeMetaRef(id)).getLastEntry();
        assertThat(last).named("last RefLogEntry").isNotNull();
        assertThat(last.getComment()).isEqualTo("change.PutTopic");
    }
}
#method_after
@Test
@UseLocalDisk
public void guessRestApiInReflog() throws Exception {
    assume().that(notesMigration.disableChangeReviewDb()).isTrue();
    PushOneCommit.Result r = createChange();
    Change.Id id = r.getChange().getId();
    try (Repository repo = repoManager.openRepository(r.getChange().project())) {
        File log = new File(repo.getDirectory(), "logs/" + changeMetaRef(id));
        if (!log.exists()) {
            log.getParentFile().mkdirs();
            assertThat(log.createNewFile()).isTrue();
        }
        gApi.changes().id(id.get()).topic("foo");
        ReflogEntry last = repo.getReflogReader(changeMetaRef(id)).getLastEntry();
        assertThat(last).named("last RefLogEntry").isNotNull();
        assertThat(last.getComment()).isEqualTo("change.PutTopic");
    }
}
#end_block

#method_before
private Iterable<ChangeData> byCommitsOnBranchNotMergedFromDatabase(Repository repo, ReviewDb db, Branch.NameKey branch, Collection<String> hashes) throws OrmException, IOException {
    Set<Change.Id> changeIds = Sets.newHashSetWithExpectedSize(hashes.size());
    String lastPrefix = null;
    for (Ref ref : repo.getRefDatabase().getRefs(RefNames.REFS_CHANGES).values()) {
        String r = ref.getName();
        if ((lastPrefix != null && r.startsWith(lastPrefix)) || !hashes.contains(ref.getObjectId().name())) {
            continue;
        }
        Change.Id id = Change.Id.fromRef(r);
        if (id == null) {
            continue;
        }
        if (changeIds.add(id)) {
            lastPrefix = r.substring(0, r.lastIndexOf('/'));
        }
    }
    List<ChangeNotes> notes = notesFactory.create(db, branch.getParentKey(), changeIds, cn -> {
        Change c = cn.getChange();
        return c.getDest().equals(branch) && c.getStatus() != Change.Status.MERGED;
    });
    return Lists.transform(notes, n -> changeDataFactory.create(db, n));
}
#method_after
private Iterable<ChangeData> byCommitsOnBranchNotMergedFromDatabase(Repository repo, ReviewDb db, Branch.NameKey branch, Collection<String> hashes) throws OrmException, IOException {
    Set<Change.Id> changeIds = Sets.newHashSetWithExpectedSize(hashes.size());
    String lastPrefix = null;
    for (Ref ref : repo.getRefDatabase().getRefsByPrefix(RefNames.REFS_CHANGES)) {
        String r = ref.getName();
        if ((lastPrefix != null && r.startsWith(lastPrefix)) || !hashes.contains(ref.getObjectId().name())) {
            continue;
        }
        Change.Id id = Change.Id.fromRef(r);
        if (id == null) {
            continue;
        }
        if (changeIds.add(id)) {
            lastPrefix = r.substring(0, r.lastIndexOf('/'));
        }
    }
    List<ChangeNotes> notes = notesFactory.create(db, branch.getParentKey(), changeIds, cn -> {
        Change c = cn.getChange();
        return c.getDest().equals(branch) && c.getStatus() != Change.Status.MERGED;
    });
    return Lists.transform(notes, n -> changeDataFactory.create(db, n));
}
#end_block

#method_before
@Override
protected void configure() {
    bind(ProjectsCollection.class);
    bind(DashboardsCollection.class);
    DynamicMap.mapOf(binder(), PROJECT_KIND);
    DynamicMap.mapOf(binder(), CHILD_PROJECT_KIND);
    DynamicMap.mapOf(binder(), BRANCH_KIND);
    DynamicMap.mapOf(binder(), DASHBOARD_KIND);
    DynamicMap.mapOf(binder(), FILE_KIND);
    DynamicMap.mapOf(binder(), COMMIT_KIND);
    DynamicMap.mapOf(binder(), TAG_KIND);
    put(PROJECT_KIND).to(PutProject.class);
    get(PROJECT_KIND).to(GetProject.class);
    get(PROJECT_KIND, "description").to(GetDescription.class);
    put(PROJECT_KIND, "description").to(PutDescription.class);
    delete(PROJECT_KIND, "description").to(PutDescription.class);
    get(PROJECT_KIND, "access").to(GetAccess.class);
    post(PROJECT_KIND, "access").to(SetAccess.class);
    put(PROJECT_KIND, "access:review").to(CreateAccessChange.class);
    post(PROJECT_KIND, "check.access").to(CheckAccess.class);
    post(PROJECT_KIND, "check").to(Check.class);
    get(PROJECT_KIND, "parent").to(GetParent.class);
    put(PROJECT_KIND, "parent").to(SetParent.class);
    child(PROJECT_KIND, "children").to(ChildProjectsCollection.class);
    get(CHILD_PROJECT_KIND).to(GetChildProject.class);
    get(PROJECT_KIND, "HEAD").to(GetHead.class);
    put(PROJECT_KIND, "HEAD").to(SetHead.class);
    put(PROJECT_KIND, "ban").to(BanCommit.class);
    get(PROJECT_KIND, "statistics.git").to(GetStatistics.class);
    post(PROJECT_KIND, "gc").to(GarbageCollect.class);
    post(PROJECT_KIND, "index").to(Index.class);
    child(PROJECT_KIND, "branches").to(BranchesCollection.class);
    put(BRANCH_KIND).to(PutBranch.class);
    get(BRANCH_KIND).to(GetBranch.class);
    delete(BRANCH_KIND).to(DeleteBranch.class);
    post(PROJECT_KIND, "branches:delete").to(DeleteBranches.class);
    factory(CreateBranch.Factory.class);
    get(BRANCH_KIND, "mergeable").to(CheckMergeability.class);
    factory(RefValidationHelper.Factory.class);
    get(BRANCH_KIND, "reflog").to(GetReflog.class);
    child(BRANCH_KIND, "files").to(FilesCollection.class);
    get(FILE_KIND, "content").to(GetContent.class);
    child(PROJECT_KIND, "commits").to(CommitsCollection.class);
    get(COMMIT_KIND).to(GetCommit.class);
    get(COMMIT_KIND, "in").to(CommitIncludedIn.class);
    child(COMMIT_KIND, "files").to(FilesInCommitCollection.class);
    child(PROJECT_KIND, "tags").to(TagsCollection.class);
    get(TAG_KIND).to(GetTag.class);
    put(TAG_KIND).to(PutTag.class);
    delete(TAG_KIND).to(DeleteTag.class);
    post(PROJECT_KIND, "tags:delete").to(DeleteTags.class);
    factory(CreateTag.Factory.class);
    child(PROJECT_KIND, "dashboards").to(DashboardsCollection.class);
    get(DASHBOARD_KIND).to(GetDashboard.class);
    put(DASHBOARD_KIND).to(SetDashboard.class);
    delete(DASHBOARD_KIND).to(DeleteDashboard.class);
    factory(CreateProject.Factory.class);
    get(PROJECT_KIND, "config").to(GetConfig.class);
    put(PROJECT_KIND, "config").to(PutConfig.class);
    factory(DeleteRef.Factory.class);
    factory(ProjectNode.Factory.class);
}
#method_after
@Override
protected void configure() {
    bind(ProjectsCollection.class);
    bind(DashboardsCollection.class);
    DynamicMap.mapOf(binder(), PROJECT_KIND);
    DynamicMap.mapOf(binder(), CHILD_PROJECT_KIND);
    DynamicMap.mapOf(binder(), BRANCH_KIND);
    DynamicMap.mapOf(binder(), DASHBOARD_KIND);
    DynamicMap.mapOf(binder(), FILE_KIND);
    DynamicMap.mapOf(binder(), COMMIT_KIND);
    DynamicMap.mapOf(binder(), TAG_KIND);
    create(PROJECT_KIND).to(CreateProject.class);
    put(PROJECT_KIND).to(PutProject.class);
    get(PROJECT_KIND).to(GetProject.class);
    get(PROJECT_KIND, "description").to(GetDescription.class);
    put(PROJECT_KIND, "description").to(PutDescription.class);
    delete(PROJECT_KIND, "description").to(PutDescription.class);
    get(PROJECT_KIND, "access").to(GetAccess.class);
    post(PROJECT_KIND, "access").to(SetAccess.class);
    put(PROJECT_KIND, "access:review").to(CreateAccessChange.class);
    post(PROJECT_KIND, "check.access").to(CheckAccess.class);
    get(PROJECT_KIND, "check.access").to(CheckAccessReadView.class);
    post(PROJECT_KIND, "check").to(Check.class);
    get(PROJECT_KIND, "parent").to(GetParent.class);
    put(PROJECT_KIND, "parent").to(SetParent.class);
    child(PROJECT_KIND, "children").to(ChildProjectsCollection.class);
    get(CHILD_PROJECT_KIND).to(GetChildProject.class);
    get(PROJECT_KIND, "HEAD").to(GetHead.class);
    put(PROJECT_KIND, "HEAD").to(SetHead.class);
    put(PROJECT_KIND, "ban").to(BanCommit.class);
    get(PROJECT_KIND, "statistics.git").to(GetStatistics.class);
    post(PROJECT_KIND, "gc").to(GarbageCollect.class);
    post(PROJECT_KIND, "index").to(Index.class);
    post(PROJECT_KIND, "index.changes").to(IndexChanges.class);
    child(PROJECT_KIND, "branches").to(BranchesCollection.class);
    create(BRANCH_KIND).to(CreateBranch.class);
    put(BRANCH_KIND).to(PutBranch.class);
    get(BRANCH_KIND).to(GetBranch.class);
    delete(BRANCH_KIND).to(DeleteBranch.class);
    post(PROJECT_KIND, "branches:delete").to(DeleteBranches.class);
    get(BRANCH_KIND, "mergeable").to(CheckMergeability.class);
    factory(RefValidationHelper.Factory.class);
    get(BRANCH_KIND, "reflog").to(GetReflog.class);
    child(BRANCH_KIND, "files").to(FilesCollection.class);
    get(FILE_KIND, "content").to(GetContent.class);
    child(PROJECT_KIND, "commits").to(CommitsCollection.class);
    get(COMMIT_KIND).to(GetCommit.class);
    get(COMMIT_KIND, "in").to(CommitIncludedIn.class);
    child(COMMIT_KIND, "files").to(FilesInCommitCollection.class);
    child(PROJECT_KIND, "tags").to(TagsCollection.class);
    create(TAG_KIND).to(CreateTag.class);
    get(TAG_KIND).to(GetTag.class);
    put(TAG_KIND).to(PutTag.class);
    delete(TAG_KIND).to(DeleteTag.class);
    post(PROJECT_KIND, "tags:delete").to(DeleteTags.class);
    child(PROJECT_KIND, "dashboards").to(DashboardsCollection.class);
    create(DASHBOARD_KIND).to(CreateDashboard.class);
    get(DASHBOARD_KIND).to(GetDashboard.class);
    put(DASHBOARD_KIND).to(SetDashboard.class);
    delete(DASHBOARD_KIND).to(DeleteDashboard.class);
    get(PROJECT_KIND, "config").to(GetConfig.class);
    put(PROJECT_KIND, "config").to(PutConfig.class);
    post(COMMIT_KIND, "cherrypick").to(CherryPickCommit.class);
    factory(ProjectNode.Factory.class);
}
#end_block

#method_before
@Override
public ProjectApi create(ProjectInput in) throws RestApiException {
    try {
        if (name == null) {
            throw new ResourceConflictException("Project already exists");
        }
        if (in.name != null && !name.equals(in.name)) {
            throw new BadRequestException("name must match input.name");
        }
        CreateProject impl = createProjectFactory.create(name);
        permissionBackend.user(user).checkAny(GlobalPermission.fromAnnotation(impl.getClass()));
        impl.apply(TopLevelResource.INSTANCE, in);
        return projectApi.create(projects.parse(name));
    } catch (Exception e) {
        throw asRestApiException("Cannot create project: " + e.getMessage(), e);
    }
}
#method_after
@Override
public ProjectApi create(ProjectInput in) throws RestApiException {
    try {
        if (name == null) {
            throw new ResourceConflictException("Project already exists");
        }
        if (in.name != null && !name.equals(in.name)) {
            throw new BadRequestException("name must match input.name");
        }
        permissionBackend.currentUser().checkAny(GlobalPermission.fromAnnotation(createProject.getClass()));
        createProject.apply(TopLevelResource.INSTANCE, IdString.fromDecoded(name), in);
        return projectApi.create(projects.parse(name));
    } catch (Exception e) {
        throw asRestApiException("Cannot create project: " + e.getMessage(), e);
    }
}
#end_block

#method_before
public CheckProjectResultInfo check(Project.NameKey projectName, CheckProjectInput input) throws IOException, OrmException {
    CheckProjectResultInfo r = new CheckProjectResultInfo();
    if (input.autoClosableChangesCheck != null) {
        r.autoClosableChangesCheckResult = checkForAutoClosableChanges(projectName, input.autoClosableChangesCheck);
    }
    return r;
}
#method_after
public CheckProjectResultInfo check(Project.NameKey projectName, CheckProjectInput input) throws IOException, OrmException, RestApiException {
    CheckProjectResultInfo r = new CheckProjectResultInfo();
    if (input.autoCloseableChangesCheck != null) {
        r.autoCloseableChangesCheckResult = checkForAutoCloseableChanges(projectName, input.autoCloseableChangesCheck);
    }
    return r;
}
#end_block

#method_before
@Test
public void noProblem() throws Exception {
    PushOneCommit.Result r = createChange("refs/for/master");
    String branch = r.getChange().change().getDest().get();
    ChangeInfo info = gApi.changes().id(r.getChange().getId().get()).info();
    assertThat(info.status).isEqualTo(ChangeStatus.NEW);
    CheckProjectResultInfo checkResult = gApi.projects().name(project.get()).check(checkProjectInputForAutoClosableCheck(branch));
    assertThat(checkResult.autoClosableChangesCheckResult.autoClosableChanges).isEmpty();
    info = gApi.changes().id(r.getChange().getId().get()).info();
    assertThat(info.status).isEqualTo(ChangeStatus.NEW);
}
#method_after
@Test
public void noProblem() throws Exception {
    PushOneCommit.Result r = createChange("refs/for/master");
    String branch = r.getChange().change().getDest().get();
    ChangeInfo info = gApi.changes().id(r.getChange().getId().get()).info();
    assertThat(info.status).isEqualTo(ChangeStatus.NEW);
    CheckProjectResultInfo checkResult = gApi.projects().name(project.get()).check(checkProjectInputForAutoCloseableCheck(branch));
    assertThat(checkResult.autoCloseableChangesCheckResult.autoCloseableChanges).isEmpty();
    info = gApi.changes().id(r.getChange().getId().get()).info();
    assertThat(info.status).isEqualTo(ChangeStatus.NEW);
}
#end_block

#method_before
@Test
public void detectAutoCloseableChangeByCommit() throws Exception {
    PushOneCommit.Result r = createChange("refs/for/master");
    String branch = r.getChange().change().getDest().get();
    serverSideTestRepo.branch(branch).update(testRepo.getRevWalk().parseCommit(r.getCommit()));
    ChangeInfo info = gApi.changes().id(r.getChange().getId().get()).info();
    assertThat(info.status).isEqualTo(ChangeStatus.NEW);
    CheckProjectResultInfo checkResult = gApi.projects().name(project.get()).check(checkProjectInputForAutoClosableCheck(branch));
    assertThat(checkResult.autoClosableChangesCheckResult.autoClosableChanges.keySet()).containsExactly(branch);
    assertThat(checkResult.autoClosableChangesCheckResult.autoClosableChanges.get(branch).stream().map(i -> i._number).collect(toSet())).containsExactly(r.getChange().getId().get());
    info = gApi.changes().id(r.getChange().getId().get()).info();
    assertThat(info.status).isEqualTo(ChangeStatus.NEW);
}
#method_after
@Test
public void detectAutoCloseableChangeByCommit() throws Exception {
    RevCommit commit = pushCommitWithoutChangeIdForReview();
    ChangeInfo change = Iterables.getOnlyElement(gApi.changes().query("commit:" + commit.name()).get());
    String branch = "refs/heads/master";
    serverSideTestRepo.branch(branch).update(testRepo.getRevWalk().parseCommit(commit));
    ChangeInfo info = gApi.changes().id(change._number).info();
    assertThat(info.status).isEqualTo(ChangeStatus.NEW);
    CheckProjectResultInfo checkResult = gApi.projects().name(project.get()).check(checkProjectInputForAutoCloseableCheck(branch));
    assertThat(checkResult.autoCloseableChangesCheckResult.autoCloseableChanges.stream().map(i -> i._number).collect(toList())).containsExactly(change._number);
    info = gApi.changes().id(change._number).info();
    assertThat(info.status).isEqualTo(ChangeStatus.NEW);
}
#end_block

#method_before
@Test
public void fixAutoCloseableChangeByCommit() throws Exception {
    PushOneCommit.Result r = createChange("refs/for/master");
    String branch = r.getChange().change().getDest().get();
    serverSideTestRepo.branch(branch).update(testRepo.getRevWalk().parseCommit(r.getCommit()));
    ChangeInfo info = gApi.changes().id(r.getChange().getId().get()).info();
    assertThat(info.status).isEqualTo(ChangeStatus.NEW);
    CheckProjectInput input = checkProjectInputForAutoClosableCheck(branch);
    input.autoClosableChangesCheck.fix = true;
    CheckProjectResultInfo checkResult = gApi.projects().name(project.get()).check(input);
    assertThat(checkResult.autoClosableChangesCheckResult.autoClosableChanges.keySet()).containsExactly(branch);
    assertThat(checkResult.autoClosableChangesCheckResult.autoClosableChanges.get(branch).stream().map(i -> i._number).collect(toSet())).containsExactly(r.getChange().getId().get());
    info = gApi.changes().id(r.getChange().getId().get()).info();
    assertThat(info.status).isEqualTo(ChangeStatus.MERGED);
}
#method_after
@Test
public void fixAutoCloseableChangeByCommit() throws Exception {
    RevCommit commit = pushCommitWithoutChangeIdForReview();
    ChangeInfo change = Iterables.getOnlyElement(gApi.changes().query("commit:" + commit.name()).get());
    String branch = "refs/heads/master";
    serverSideTestRepo.branch(branch).update(commit);
    ChangeInfo info = gApi.changes().id(change._number).info();
    assertThat(info.status).isEqualTo(ChangeStatus.NEW);
    CheckProjectInput input = checkProjectInputForAutoCloseableCheck(branch);
    input.autoCloseableChangesCheck.fix = true;
    CheckProjectResultInfo checkResult = gApi.projects().name(project.get()).check(input);
    assertThat(checkResult.autoCloseableChangesCheckResult.autoCloseableChanges.stream().map(i -> i._number).collect(toSet())).containsExactly(change._number);
    info = gApi.changes().id(change._number).info();
    assertThat(info.status).isEqualTo(ChangeStatus.MERGED);
}
#end_block

#method_before
@Test
public void detectAutoCloseableChangeByChangeId() throws Exception {
    PushOneCommit.Result r = createChange("refs/for/master");
    String branch = r.getChange().change().getDest().get();
    RevCommit amendedCommit = serverSideTestRepo.amend(r.getCommit()).create();
    serverSideTestRepo.branch(branch).update(amendedCommit);
    ChangeInfo info = gApi.changes().id(r.getChange().getId().get()).info();
    assertThat(info.status).isEqualTo(ChangeStatus.NEW);
    CheckProjectResultInfo checkResult = gApi.projects().name(project.get()).check(checkProjectInputForAutoClosableCheck(branch));
    assertThat(checkResult.autoClosableChangesCheckResult.autoClosableChanges.keySet()).containsExactly(branch);
    assertThat(checkResult.autoClosableChangesCheckResult.autoClosableChanges.get(branch).stream().map(i -> i._number).collect(toSet())).containsExactly(r.getChange().getId().get());
    info = gApi.changes().id(r.getChange().getId().get()).info();
    assertThat(info.status).isEqualTo(ChangeStatus.NEW);
}
#method_after
@Test
public void detectAutoCloseableChangeByChangeId() throws Exception {
    PushOneCommit.Result r = createChange("refs/for/master");
    String branch = r.getChange().change().getDest().get();
    RevCommit amendedCommit = serverSideTestRepo.amend(r.getCommit()).create();
    serverSideTestRepo.branch(branch).update(amendedCommit);
    ChangeInfo info = gApi.changes().id(r.getChange().getId().get()).info();
    assertThat(info.status).isEqualTo(ChangeStatus.NEW);
    CheckProjectResultInfo checkResult = gApi.projects().name(project.get()).check(checkProjectInputForAutoCloseableCheck(branch));
    assertThat(checkResult.autoCloseableChangesCheckResult.autoCloseableChanges.stream().map(i -> i._number).collect(toSet())).containsExactly(r.getChange().getId().get());
    info = gApi.changes().id(r.getChange().getId().get()).info();
    assertThat(info.status).isEqualTo(ChangeStatus.NEW);
}
#end_block

#method_before
@Test
public void fixAutoCloseableChangeByChangeId() throws Exception {
    PushOneCommit.Result r = createChange("refs/for/master");
    String branch = r.getChange().change().getDest().get();
    RevCommit amendedCommit = serverSideTestRepo.amend(r.getCommit()).create();
    serverSideTestRepo.branch(branch).update(amendedCommit);
    ChangeInfo info = gApi.changes().id(r.getChange().getId().get()).info();
    assertThat(info.status).isEqualTo(ChangeStatus.NEW);
    CheckProjectInput input = checkProjectInputForAutoClosableCheck(branch);
    input.autoClosableChangesCheck.fix = true;
    CheckProjectResultInfo checkResult = gApi.projects().name(project.get()).check(input);
    assertThat(checkResult.autoClosableChangesCheckResult.autoClosableChanges.keySet()).containsExactly(branch);
    assertThat(checkResult.autoClosableChangesCheckResult.autoClosableChanges.get(branch).stream().map(i -> i._number).collect(toSet())).containsExactly(r.getChange().getId().get());
    info = gApi.changes().id(r.getChange().getId().get()).info();
    assertThat(info.status).isEqualTo(ChangeStatus.MERGED);
}
#method_after
@Test
public void fixAutoCloseableChangeByChangeId() throws Exception {
    PushOneCommit.Result r = createChange("refs/for/master");
    String branch = r.getChange().change().getDest().get();
    RevCommit amendedCommit = serverSideTestRepo.amend(r.getCommit()).create();
    serverSideTestRepo.branch(branch).update(amendedCommit);
    ChangeInfo info = gApi.changes().id(r.getChange().getId().get()).info();
    assertThat(info.status).isEqualTo(ChangeStatus.NEW);
    CheckProjectInput input = checkProjectInputForAutoCloseableCheck(branch);
    input.autoCloseableChangesCheck.fix = true;
    CheckProjectResultInfo checkResult = gApi.projects().name(project.get()).check(input);
    assertThat(checkResult.autoCloseableChangesCheckResult.autoCloseableChanges.stream().map(i -> i._number).collect(toSet())).containsExactly(r.getChange().getId().get());
    info = gApi.changes().id(r.getChange().getId().get()).info();
    assertThat(info.status).isEqualTo(ChangeStatus.MERGED);
}
#end_block

#method_before
void processCommands(Collection<ReceiveCommand> commands, MultiProgressMonitor progress) {
    newProgress = progress.beginSubTask("new", UNKNOWN);
    replaceProgress = progress.beginSubTask("updated", UNKNOWN);
    closeProgress = progress.beginSubTask("closed", UNKNOWN);
    commandProgress = progress.beginSubTask("refs", UNKNOWN);
    if (!projectState.getProject().getState().permitsWrite()) {
        for (ReceiveCommand cmd : commands) {
            reject(cmd, "prohibited by Gerrit: project state does not permit write");
        }
        return;
    }
    try {
        parsePushOptions();
        logDebug("Parsing %d commands", commands.size());
        List<ReceiveCommand> magicCommands = commands.stream().filter(c -> MagicBranch.isMagicBranch(c.getRefName())).collect(toList());
        List<ReceiveCommand> directChangePushCommands = commands.stream().filter(c -> isDirectChangesPush(c)).collect(toList());
        commands = commands.stream().filter(c -> !MagicBranch.isMagicBranch(c.getRefName()) && !isDirectChangesPush(c)).collect(toList());
        for (ReceiveCommand cmd : commands) {
            parseNonMagicCommand(cmd);
        }
        for (ReceiveCommand cmd : directChangePushCommands) {
            parseDirectChangesPush(cmd);
        }
        // Process the magicCommand last so we are sure magicBranch settings don't affect
        // the non-magic commands.
        boolean first = true;
        for (ReceiveCommand cmd : magicCommands) {
            if (first) {
                parseMagicBranch(cmd);
                first = false;
            } else {
                reject(cmd, "duplicate request");
            }
        }
    } catch (PermissionBackendException | NoSuchProjectException | IOException err) {
        for (ReceiveCommand cmd : actualCommands) {
            if (cmd.getResult() == NOT_ATTEMPTED) {
                cmd.setResult(REJECTED_OTHER_REASON, "internal server error");
            }
        }
        logError(String.format("Failed to process refs in %s", project.getName()), err);
    }
    List<CreateRequest> newChanges = Collections.emptyList();
    if (magicBranch != null && magicBranch.cmd.getResult() == NOT_ATTEMPTED) {
        newChanges = selectNewAndReplacedChangesFromMagicBranch();
    }
    preparePatchSetsForReplace(newChanges);
    insertChangesAndPatchSets(newChanges);
    newProgress.end();
    replaceProgress.end();
    if (!errors.isEmpty()) {
        logDebug("Handling error conditions: %s", errors.keySet());
        for (String error : errors.keySet()) {
            receivePack.sendMessage(buildError(error, errors.get(error)));
        }
        receivePack.sendMessage(String.format("User: %s", user.getLoggableName()));
        receivePack.sendMessage(COMMAND_REJECTION_MESSAGE_FOOTER);
    }
    Set<Branch.NameKey> branches = new HashSet<>();
    for (ReceiveCommand c : actualCommands) {
        // involve kicking off an additional BatchUpdate.
        if (c.getResult() != OK) {
            continue;
        }
        if (isHead(c) || isConfig(c)) {
            switch(c.getType()) {
                case CREATE:
                case UPDATE:
                case UPDATE_NONFASTFORWARD:
                    autoCloseChanges(c);
                    branches.add(new Branch.NameKey(project.getNameKey(), c.getRefName()));
                    break;
                case DELETE:
                    break;
            }
        }
    }
    // Update superproject gitlinks if required.
    if (!branches.isEmpty()) {
        try (MergeOpRepoManager orm = ormProvider.get()) {
            orm.setContext(db, TimeUtil.nowTs(), user, receiveId);
            SubmoduleOp op = subOpFactory.create(branches, orm);
            op.updateSuperProjects();
        } catch (SubmoduleException e) {
            logError("Can't update the superprojects", e);
        }
    }
    // Update account info with details discovered during commit walking.
    updateAccountInfo();
    closeProgress.end();
    commandProgress.end();
    progress.end();
    reportMessages(newChanges);
}
#method_after
void processCommands(Collection<ReceiveCommand> commands, MultiProgressMonitor progress) {
    newProgress = progress.beginSubTask("new", UNKNOWN);
    replaceProgress = progress.beginSubTask("updated", UNKNOWN);
    closeProgress = progress.beginSubTask("closed", UNKNOWN);
    commandProgress = progress.beginSubTask("refs", UNKNOWN);
    try (TraceContext traceContext = new TraceContext(RequestId.Type.RECEIVE_ID, RequestId.forProject(project.getNameKey()))) {
        try {
            if (!projectState.getProject().getState().permitsWrite()) {
                for (ReceiveCommand cmd : commands) {
                    reject(cmd, "prohibited by Gerrit: project state does not permit write");
                }
                return;
            }
            parsePushOptions();
            logger.atFine().log("Parsing %d commands", commands.size());
            List<ReceiveCommand> magicCommands = new ArrayList<>();
            List<ReceiveCommand> directPatchSetPushCommands = new ArrayList<>();
            List<ReceiveCommand> regularCommands = new ArrayList<>();
            for (ReceiveCommand cmd : commands) {
                if (MagicBranch.isMagicBranch(cmd.getRefName())) {
                    magicCommands.add(cmd);
                } else if (isDirectChangesPush(cmd.getRefName())) {
                    directPatchSetPushCommands.add(cmd);
                } else {
                    regularCommands.add(cmd);
                }
            }
            for (ReceiveCommand cmd : regularCommands) {
                parseRegularCommand(cmd);
            }
            for (ReceiveCommand cmd : directPatchSetPushCommands) {
                parseDirectChangesPush(cmd);
            }
            // Process the magicCommand last, so magicBranch settings can't interact with regular
            // commands.
            boolean first = true;
            for (ReceiveCommand cmd : magicCommands) {
                if (first) {
                    parseMagicBranch(cmd);
                    first = false;
                } else {
                    reject(cmd, "duplicate request");
                }
            }
        } catch (PermissionBackendException | NoSuchProjectException | IOException err) {
            for (ReceiveCommand cmd : actualCommands) {
                if (cmd.getResult() == NOT_ATTEMPTED) {
                    cmd.setResult(REJECTED_OTHER_REASON, "internal server error");
                }
                logger.atSevere().withCause(err).log("Failed to process refs in %s", project.getName());
            }
            return;
        }
        List<CreateRequest> newChanges = Collections.emptyList();
        if (magicBranch != null && magicBranch.cmd.getResult() == NOT_ATTEMPTED) {
            newChanges = selectNewAndReplacedChangesFromMagicBranch();
        }
        preparePatchSetsForReplace(newChanges);
        insertChangesAndPatchSets(newChanges);
        newProgress.end();
        replaceProgress.end();
        if (!errors.isEmpty()) {
            logger.atFine().log("Handling error conditions: %s", errors.keySet());
            for (String error : errors.keySet()) {
                receivePack.sendMessage(buildError(error, errors.get(error)));
            }
            receivePack.sendMessage(String.format("User: %s", user.getLoggableName()));
            receivePack.sendMessage(COMMAND_REJECTION_MESSAGE_FOOTER);
        }
        Set<Branch.NameKey> branches = new HashSet<>();
        for (ReceiveCommand c : actualCommands) {
            // they involve kicking off an additional BatchUpdate.
            if (c.getResult() != OK) {
                continue;
            }
            if (isHead(c) || isConfig(c)) {
                switch(c.getType()) {
                    case CREATE:
                    case UPDATE:
                    case UPDATE_NONFASTFORWARD:
                        autoCloseChanges(c);
                        branches.add(new Branch.NameKey(project.getNameKey(), c.getRefName()));
                        break;
                    case DELETE:
                        break;
                }
            }
        }
        // Update superproject gitlinks if required.
        if (!branches.isEmpty()) {
            try (MergeOpRepoManager orm = ormProvider.get()) {
                orm.setContext(db, TimeUtil.nowTs(), user);
                SubmoduleOp op = subOpFactory.create(branches, orm);
                op.updateSuperProjects();
            } catch (SubmoduleException e) {
                logger.atSevere().withCause(e).log("Can't update the superprojects");
            }
        }
        // Update account info with details discovered during commit walking.
        updateAccountInfo();
        closeProgress.end();
        commandProgress.end();
        progress.end();
        reportMessages(newChanges);
    }
}
#end_block

#method_before
private void reportMessages(List<CreateRequest> newChanges) {
    List<CreateRequest> created = newChanges.stream().filter(r -> r.change != null).collect(toList());
    if (!created.isEmpty()) {
        addMessage("");
        addMessage("New Changes:");
        for (CreateRequest c : created) {
            addMessage(changeFormatter.newChange(ChangeReportFormatter.Input.builder().setChange(c.change).build()));
        }
        addMessage("");
    }
    List<ReplaceRequest> updated = replaceByChange.values().stream().filter(r -> r.inputCommand.getResult() == OK).sorted(comparingInt(r -> r.notes.getChangeId().get())).collect(toList());
    if (!updated.isEmpty()) {
        addMessage("");
        addMessage("Updated Changes:");
        boolean edit = magicBranch != null && (magicBranch.edit || magicBranch.draft);
        Boolean isPrivate = null;
        Boolean wip = null;
        if (magicBranch != null) {
            if (magicBranch.isPrivate) {
                isPrivate = true;
            } else if (magicBranch.removePrivate) {
                isPrivate = false;
            }
            if (magicBranch.workInProgress) {
                wip = true;
            } else if (magicBranch.ready) {
                wip = false;
            }
        }
        for (ReplaceRequest u : updated) {
            String subject;
            if (edit) {
                try {
                    subject = receivePack.getRevWalk().parseCommit(u.newCommitId).getShortMessage();
                } catch (IOException e) {
                    // Log and fall back to original change subject
                    logWarn("failed to get subject for edit patch set", e);
                    subject = u.notes.getChange().getSubject();
                }
            } else {
                subject = u.info.getSubject();
            }
            if (isPrivate == null) {
                isPrivate = u.notes.getChange().isPrivate();
            }
            if (wip == null) {
                wip = u.notes.getChange().isWorkInProgress();
            }
            ChangeReportFormatter.Input input = ChangeReportFormatter.Input.builder().setChange(u.notes.getChange()).setSubject(subject).setIsEdit(edit).setIsPrivate(isPrivate).setIsWorkInProgress(wip).build();
            addMessage(changeFormatter.changeUpdated(input));
        }
        addMessage("");
    }
}
#method_after
private void reportMessages(List<CreateRequest> newChanges) {
    List<CreateRequest> created = newChanges.stream().filter(r -> r.change != null).collect(toList());
    if (!created.isEmpty()) {
        addMessage("");
        addMessage("New Changes:");
        for (CreateRequest c : created) {
            addMessage(changeFormatter.newChange(ChangeReportFormatter.Input.builder().setChange(c.change).build()));
        }
        addMessage("");
    }
    List<ReplaceRequest> updated = replaceByChange.values().stream().filter(r -> r.inputCommand.getResult() == OK).sorted(comparingInt(r -> r.notes.getChangeId().get())).collect(toList());
    if (!updated.isEmpty()) {
        addMessage("");
        addMessage("Updated Changes:");
        boolean edit = magicBranch != null && (magicBranch.edit || magicBranch.draft);
        Boolean isPrivate = null;
        Boolean wip = null;
        if (magicBranch != null) {
            if (magicBranch.isPrivate) {
                isPrivate = true;
            } else if (magicBranch.removePrivate) {
                isPrivate = false;
            }
            if (magicBranch.workInProgress) {
                wip = true;
            } else if (magicBranch.ready) {
                wip = false;
            }
        }
        for (ReplaceRequest u : updated) {
            String subject;
            if (edit) {
                try {
                    subject = receivePack.getRevWalk().parseCommit(u.newCommitId).getShortMessage();
                } catch (IOException e) {
                    // Log and fall back to original change subject
                    logger.atWarning().withCause(e).log("failed to get subject for edit patch set");
                    subject = u.notes.getChange().getSubject();
                }
            } else {
                subject = u.info.getSubject();
            }
            if (isPrivate == null) {
                isPrivate = u.notes.getChange().isPrivate();
            }
            if (wip == null) {
                wip = u.notes.getChange().isWorkInProgress();
            }
            ChangeReportFormatter.Input input = ChangeReportFormatter.Input.builder().setChange(u.notes.getChange()).setSubject(subject).setIsEdit(edit).setIsPrivate(isPrivate).setIsWorkInProgress(wip).build();
            addMessage(changeFormatter.changeUpdated(input));
        }
        addMessage("");
    }
    // TODO(xchangcheng): remove after migrating tools which are using this magic branch.
    if (magicBranch != null && magicBranch.publish) {
        addMessage("Pushing to refs/publish/* is deprecated, use refs/for/* instead.");
    }
}
#end_block

#method_before
private void insertChangesAndPatchSets(List<CreateRequest> newChanges) {
    ReceiveCommand magicBranchCmd = magicBranch != null ? magicBranch.cmd : null;
    if (magicBranchCmd != null && magicBranchCmd.getResult() != NOT_ATTEMPTED) {
        logWarn(String.format("Skipping change updates on %s because ref update failed: %s %s", project.getName(), magicBranchCmd.getResult(), Strings.nullToEmpty(magicBranchCmd.getMessage())));
        return;
    }
    try (BatchUpdate bu = batchUpdateFactory.create(db, project.getNameKey(), user.materializedCopy(), TimeUtil.nowTs());
        ObjectInserter ins = repo.newObjectInserter();
        ObjectReader reader = ins.newReader();
        RevWalk rw = new RevWalk(reader)) {
        bu.setRepository(repo, rw, ins).updateChangesInParallel();
        bu.setRequestId(receiveId);
        bu.setRefLogMessage("push");
        logDebug("Adding %d replace requests", newChanges.size());
        for (ReplaceRequest replace : replaceByChange.values()) {
            replace.addOps(bu, replaceProgress);
        }
        logDebug("Adding %d create requests", newChanges.size());
        for (CreateRequest create : newChanges) {
            create.addOps(bu);
        }
        logDebug("Adding %d group update requests", newChanges.size());
        updateGroups.forEach(r -> r.addOps(bu));
        logDebug("Adding %d additional ref updates", actualCommands.size());
        actualCommands.forEach(c -> bu.addRepoOnlyOp(new UpdateOneRefOp(c)));
        logDebug("Executing batch");
        try {
            bu.execute();
        } catch (UpdateException e) {
            throw INSERT_EXCEPTION.apply(e);
        }
        if (magicBranchCmd != null) {
            magicBranchCmd.setResult(OK);
        }
        for (ReplaceRequest replace : replaceByChange.values()) {
            String rejectMessage = replace.getRejectMessage();
            if (rejectMessage == null) {
                if (replace.inputCommand.getResult() == NOT_ATTEMPTED) {
                    // Not necessarily the magic branch, so need to set OK on the original value.
                    replace.inputCommand.setResult(OK);
                }
            } else {
                logDebug("Rejecting due to message from ReplaceOp");
                reject(replace.inputCommand, rejectMessage);
            }
        }
    } catch (ResourceConflictException e) {
        addMessage(e.getMessage());
        reject(magicBranchCmd, "conflict");
    } catch (RestApiException | IOException err) {
        logError("Can't insert change/patch set for " + project.getName(), err);
        reject(magicBranchCmd, "internal server error: " + err.getMessage());
    }
    if (magicBranch != null && magicBranch.submit) {
        try {
            submit(newChanges, replaceByChange.values());
        } catch (ResourceConflictException e) {
            addMessage(e.getMessage());
            reject(magicBranchCmd, "conflict");
        } catch (RestApiException | OrmException | UpdateException | IOException | ConfigInvalidException | PermissionBackendException e) {
            logError("Error submitting changes to " + project.getName(), e);
            reject(magicBranchCmd, "error during submit");
        }
    }
}
#method_after
private void insertChangesAndPatchSets(List<CreateRequest> newChanges) {
    ReceiveCommand magicBranchCmd = magicBranch != null ? magicBranch.cmd : null;
    if (magicBranchCmd != null && magicBranchCmd.getResult() != NOT_ATTEMPTED) {
        logger.atWarning().log("Skipping change updates on %s because ref update failed: %s %s", project.getName(), magicBranchCmd.getResult(), Strings.nullToEmpty(magicBranchCmd.getMessage()));
        return;
    }
    try (BatchUpdate bu = batchUpdateFactory.create(db, project.getNameKey(), user.materializedCopy(), TimeUtil.nowTs());
        ObjectInserter ins = repo.newObjectInserter();
        ObjectReader reader = ins.newReader();
        RevWalk rw = new RevWalk(reader)) {
        bu.setRepository(repo, rw, ins).updateChangesInParallel();
        bu.setRefLogMessage("push");
        logger.atFine().log("Adding %d replace requests", newChanges.size());
        for (ReplaceRequest replace : replaceByChange.values()) {
            replace.addOps(bu, replaceProgress);
        }
        logger.atFine().log("Adding %d create requests", newChanges.size());
        for (CreateRequest create : newChanges) {
            create.addOps(bu);
        }
        logger.atFine().log("Adding %d group update requests", newChanges.size());
        updateGroups.forEach(r -> r.addOps(bu));
        logger.atFine().log("Adding %d additional ref updates", actualCommands.size());
        actualCommands.forEach(c -> bu.addRepoOnlyOp(new UpdateOneRefOp(c)));
        logger.atFine().log("Executing batch");
        try {
            bu.execute();
        } catch (UpdateException e) {
            throw INSERT_EXCEPTION.apply(e);
        }
        if (magicBranchCmd != null) {
            magicBranchCmd.setResult(OK);
        }
        for (ReplaceRequest replace : replaceByChange.values()) {
            String rejectMessage = replace.getRejectMessage();
            if (rejectMessage == null) {
                if (replace.inputCommand.getResult() == NOT_ATTEMPTED) {
                    // Not necessarily the magic branch, so need to set OK on the original value.
                    replace.inputCommand.setResult(OK);
                }
            } else {
                logger.atFine().log("Rejecting due to message from ReplaceOp");
                reject(replace.inputCommand, rejectMessage);
            }
        }
    } catch (ResourceConflictException e) {
        addMessage(e.getMessage());
        reject(magicBranchCmd, "conflict");
    } catch (RestApiException | IOException err) {
        logger.atSevere().withCause(err).log("Can't insert change/patch set for %s", project.getName());
        reject(magicBranchCmd, "internal server error: " + err.getMessage());
    }
    if (magicBranch != null && magicBranch.submit) {
        try {
            submit(newChanges, replaceByChange.values());
        } catch (ResourceConflictException e) {
            addMessage(e.getMessage());
            reject(magicBranchCmd, "conflict");
        } catch (RestApiException | OrmException | UpdateException | IOException | ConfigInvalidException | PermissionBackendException e) {
            logger.atSevere().withCause(e).log("Error submitting changes to %s", project.getName());
            reject(magicBranchCmd, "error during submit");
        }
    }
}
#end_block

#method_before
private static boolean isDirectChangesPush(ReceiveCommand cmd) {
    Matcher m = NEW_PATCHSET_PATTERN.matcher(cmd.getRefName());
    return m.matches();
}
#method_after
private static boolean isDirectChangesPush(String refname) {
    Matcher m = NEW_PATCHSET_PATTERN.matcher(refname);
    return m.matches();
}
#end_block

#method_before
private void parseCreate(ReceiveCommand cmd) throws PermissionBackendException, NoSuchProjectException, IOException {
    RevObject obj;
    try {
        obj = receivePack.getRevWalk().parseAny(cmd.getNewId());
    } catch (IOException err) {
        logError("Invalid object " + cmd.getNewId().name() + " for " + cmd.getRefName() + " creation", err);
        reject(cmd, "invalid object");
        return;
    }
    logDebug("Creating %s", cmd);
    if (isHead(cmd) && !isCommit(cmd)) {
        return;
    }
    Branch.NameKey branch = new Branch.NameKey(project.getName(), cmd.getRefName());
    try {
        // Must pass explicit user instead of injecting a provider into CreateRefControl, since
        // Provider<CurrentUser> within ReceiveCommits will always return anonymous.
        createRefControl.checkCreateRef(Providers.of(user), receivePack.getRepository(), branch, obj);
    } catch (AuthException denied) {
        rejectProhibited(cmd, denied);
        return;
    } catch (ResourceConflictException denied) {
        reject(cmd, "prohibited by Gerrit: " + denied.getMessage());
        return;
    }
    if (!validRefOperation(cmd)) {
        // validRefOperation sets messages, so no need to provide more feedback.
        return;
    }
    validateNewCommits(new Branch.NameKey(project.getNameKey(), cmd.getRefName()), cmd);
    actualCommands.add(cmd);
}
#method_after
private void parseCreate(ReceiveCommand cmd) throws PermissionBackendException, NoSuchProjectException, IOException {
    RevObject obj;
    try {
        obj = receivePack.getRevWalk().parseAny(cmd.getNewId());
    } catch (IOException err) {
        logger.atSevere().withCause(err).log("Invalid object %s for %s creation", cmd.getNewId().name(), cmd.getRefName());
        reject(cmd, "invalid object");
        return;
    }
    logger.atFine().log("Creating %s", cmd);
    if (isHead(cmd) && !isCommit(cmd)) {
        return;
    }
    Branch.NameKey branch = new Branch.NameKey(project.getName(), cmd.getRefName());
    try {
        // Must pass explicit user instead of injecting a provider into CreateRefControl, since
        // Provider<CurrentUser> within ReceiveCommits will always return anonymous.
        createRefControl.checkCreateRef(Providers.of(user), receivePack.getRepository(), branch, obj);
    } catch (AuthException denied) {
        rejectProhibited(cmd, denied);
        return;
    } catch (ResourceConflictException denied) {
        reject(cmd, "prohibited by Gerrit: " + denied.getMessage());
        return;
    }
    if (!validRefOperation(cmd)) {
        // validRefOperation sets messages, so no need to provide more feedback.
        return;
    }
    validateNewCommits(new Branch.NameKey(project.getNameKey(), cmd.getRefName()), cmd);
    actualCommands.add(cmd);
}
#end_block

#method_before
private void parseUpdate(ReceiveCommand cmd) throws PermissionBackendException {
    logDebug("Updating %s", cmd);
    Optional<AuthException> err = checkRefPermission(cmd, RefPermission.UPDATE);
    if (!err.isPresent()) {
        if (isHead(cmd) && !isCommit(cmd)) {
            return;
        }
        if (!validRefOperation(cmd)) {
            return;
        }
        validateNewCommits(new Branch.NameKey(project.getNameKey(), cmd.getRefName()), cmd);
        actualCommands.add(cmd);
    } else {
        rejectProhibited(cmd, err.get());
    }
}
#method_after
private void parseUpdate(ReceiveCommand cmd) throws PermissionBackendException {
    logger.atFine().log("Updating %s", cmd);
    Optional<AuthException> err = checkRefPermission(cmd, RefPermission.UPDATE);
    if (!err.isPresent()) {
        if (isHead(cmd) && !isCommit(cmd)) {
            return;
        }
        if (!validRefOperation(cmd)) {
            return;
        }
        validateNewCommits(new Branch.NameKey(project.getNameKey(), cmd.getRefName()), cmd);
        actualCommands.add(cmd);
    } else {
        rejectProhibited(cmd, err.get());
    }
}
#end_block

#method_before
private boolean isCommit(ReceiveCommand cmd) {
    RevObject obj;
    try {
        obj = receivePack.getRevWalk().parseAny(cmd.getNewId());
    } catch (IOException err) {
        logError("Invalid object " + cmd.getNewId().name() + " for " + cmd.getRefName(), err);
        reject(cmd, "invalid object");
        return false;
    }
    if (obj instanceof RevCommit) {
        return true;
    }
    reject(cmd, "not a commit");
    return false;
}
#method_after
private boolean isCommit(ReceiveCommand cmd) {
    RevObject obj;
    try {
        obj = receivePack.getRevWalk().parseAny(cmd.getNewId());
    } catch (IOException err) {
        logger.atSevere().withCause(err).log("Invalid object %s for %s", cmd.getNewId().name(), cmd.getRefName());
        reject(cmd, "invalid object");
        return false;
    }
    if (obj instanceof RevCommit) {
        return true;
    }
    reject(cmd, "not a commit");
    return false;
}
#end_block

#method_before
private void parseDelete(ReceiveCommand cmd) throws PermissionBackendException {
    logDebug("Deleting %s", cmd);
    if (cmd.getRefName().startsWith(REFS_CHANGES)) {
        errors.put(CANNOT_DELETE_CHANGES, cmd.getRefName());
        reject(cmd, "cannot delete changes");
    } else if (isConfigRef(cmd.getRefName())) {
        errors.put(CANNOT_DELETE_CONFIG, cmd.getRefName());
        reject(cmd, "cannot delete project configuration");
    }
    Optional<AuthException> err = checkRefPermission(cmd, RefPermission.DELETE);
    if (!err.isPresent()) {
        if (!validRefOperation(cmd)) {
            return;
        }
        actualCommands.add(cmd);
    } else {
        rejectProhibited(cmd, err.get());
    }
}
#method_after
private void parseDelete(ReceiveCommand cmd) throws PermissionBackendException {
    logger.atFine().log("Deleting %s", cmd);
    if (cmd.getRefName().startsWith(REFS_CHANGES)) {
        errors.put(CANNOT_DELETE_CHANGES, cmd.getRefName());
        reject(cmd, "cannot delete changes");
    } else if (isConfigRef(cmd.getRefName())) {
        errors.put(CANNOT_DELETE_CONFIG, cmd.getRefName());
        reject(cmd, "cannot delete project configuration");
    }
    Optional<AuthException> err = checkRefPermission(cmd, RefPermission.DELETE);
    if (!err.isPresent()) {
        if (!validRefOperation(cmd)) {
            return;
        }
        actualCommands.add(cmd);
    } else {
        rejectProhibited(cmd, err.get());
    }
}
#end_block

#method_before
private void parseRewind(ReceiveCommand cmd) throws PermissionBackendException {
    RevCommit newObject;
    try {
        newObject = receivePack.getRevWalk().parseCommit(cmd.getNewId());
    } catch (IncorrectObjectTypeException notCommit) {
        newObject = null;
    } catch (IOException err) {
        logError("Invalid object " + cmd.getNewId().name() + " for " + cmd.getRefName() + " forced update", err);
        reject(cmd, "invalid object");
        return;
    }
    logDebug("Rewinding %s", cmd);
    if (newObject != null) {
        validateNewCommits(new Branch.NameKey(project.getNameKey(), cmd.getRefName()), cmd);
        if (cmd.getResult() != NOT_ATTEMPTED) {
            return;
        }
    }
    Optional<AuthException> err = checkRefPermission(cmd, RefPermission.FORCE_UPDATE);
    if (!err.isPresent()) {
        if (!validRefOperation(cmd)) {
            return;
        }
        actualCommands.add(cmd);
    } else {
        rejectProhibited(cmd, err.get());
    }
}
#method_after
private void parseRewind(ReceiveCommand cmd) throws PermissionBackendException {
    RevCommit newObject;
    try {
        newObject = receivePack.getRevWalk().parseCommit(cmd.getNewId());
    } catch (IncorrectObjectTypeException notCommit) {
        newObject = null;
    } catch (IOException err) {
        logger.atSevere().withCause(err).log("Invalid object %s for %s forced update", cmd.getNewId().name(), cmd.getRefName());
        reject(cmd, "invalid object");
        return;
    }
    logger.atFine().log("Rewinding %s", cmd);
    if (newObject != null) {
        validateNewCommits(new Branch.NameKey(project.getNameKey(), cmd.getRefName()), cmd);
        if (cmd.getResult() != NOT_ATTEMPTED) {
            return;
        }
    }
    Optional<AuthException> err = checkRefPermission(cmd, RefPermission.FORCE_UPDATE);
    if (!err.isPresent()) {
        if (!validRefOperation(cmd)) {
            return;
        }
        actualCommands.add(cmd);
    } else {
        rejectProhibited(cmd, err.get());
    }
}
#end_block

#method_before
private void parseMagicBranch(ReceiveCommand cmd) throws PermissionBackendException {
    logDebug("Found magic branch %s", cmd.getRefName());
    magicBranch = new MagicBranchInput(user, cmd, labelTypes, notesMigration);
    magicBranch.reviewer.addAll(extraReviewers.get(ReviewerStateInternal.REVIEWER));
    magicBranch.cc.addAll(extraReviewers.get(ReviewerStateInternal.CC));
    String ref;
    magicBranch.cmdLineParser = optionParserFactory.create(magicBranch);
    try {
        ref = magicBranch.parse(repo, receivePack.getAdvertisedRefs().keySet(), pushOptions);
    } catch (CmdLineException e) {
        if (!magicBranch.cmdLineParser.wasHelpRequestedByOption()) {
            logDebug("Invalid branch syntax");
            reject(cmd, e.getMessage());
            return;
        }
        // never happens
        ref = null;
    }
    if (magicBranch.topic != null && magicBranch.topic.length() > ChangeUtil.TOPIC_MAX_LENGTH) {
        reject(cmd, String.format("topic length exceeds the limit (%d)", ChangeUtil.TOPIC_MAX_LENGTH));
    }
    if (magicBranch.cmdLineParser.wasHelpRequestedByOption()) {
        StringWriter w = new StringWriter();
        w.write("\nHelp for refs/for/branch:\n\n");
        magicBranch.cmdLineParser.printUsage(w, null);
        addMessage(w.toString());
        reject(cmd, "see help");
        return;
    }
    if (projectState.isAllUsers() && RefNames.REFS_USERS_SELF.equals(ref)) {
        logDebug("Handling %s", RefNames.REFS_USERS_SELF);
        ref = RefNames.refsUsers(user.getAccountId());
    }
    if (!receivePack.getAdvertisedRefs().containsKey(ref) && !ref.equals(readHEAD(repo)) && !ref.equals(RefNames.REFS_CONFIG)) {
        logDebug("Ref %s not found", ref);
        if (ref.startsWith(Constants.R_HEADS)) {
            String n = ref.substring(Constants.R_HEADS.length());
            reject(cmd, "branch " + n + " not found");
        } else {
            reject(cmd, ref + " not found");
        }
        return;
    }
    magicBranch.dest = new Branch.NameKey(project.getNameKey(), ref);
    magicBranch.perm = permissions.ref(ref);
    Optional<AuthException> err = checkRefPermission(magicBranch.perm, RefPermission.CREATE_CHANGE);
    if (err.isPresent()) {
        rejectProhibited(cmd, err.get());
        return;
    }
    if (!projectState.statePermitsWrite()) {
        reject(cmd, "project state does not permit write");
        return;
    }
    // after repo-tool supports private and work-in-progress changes.
    if (magicBranch.draft && !receiveConfig.allowDrafts) {
        errors.put(ReceiveError.CODE_REVIEW.get(), ref);
        reject(cmd, "draft workflow is disabled");
        return;
    }
    if (magicBranch.isPrivate && magicBranch.removePrivate) {
        reject(cmd, "the options 'private' and 'remove-private' are mutually exclusive");
        return;
    }
    boolean privateByDefault = projectCache.get(project.getNameKey()).is(BooleanProjectConfig.PRIVATE_BY_DEFAULT);
    setChangeAsPrivate = magicBranch.draft || magicBranch.isPrivate || (privateByDefault && !magicBranch.removePrivate);
    if (receiveConfig.disablePrivateChanges && setChangeAsPrivate) {
        reject(cmd, "private changes are disabled");
        return;
    }
    if (magicBranch.workInProgress && magicBranch.ready) {
        reject(cmd, "the options 'wip' and 'ready' are mutually exclusive");
        return;
    }
    if (magicBranch.publishComments && magicBranch.noPublishComments) {
        reject(cmd, "the options 'publish-comments' and 'no-publish-comments' are mutually exclusive");
        return;
    }
    if (magicBranch.submit) {
        err = checkRefPermission(magicBranch.perm, RefPermission.UPDATE_BY_SUBMIT);
        if (err.isPresent()) {
            rejectProhibited(cmd, err.get());
            return;
        }
    }
    RevWalk walk = receivePack.getRevWalk();
    RevCommit tip;
    try {
        tip = walk.parseCommit(magicBranch.cmd.getNewId());
        logDebug("Tip of push: %s", tip.name());
    } catch (IOException ex) {
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", ex);
        return;
    }
    String destBranch = magicBranch.dest.get();
    try {
        if (magicBranch.merged) {
            if (magicBranch.base != null) {
                reject(cmd, "cannot use merged with base");
                return;
            }
            RevCommit branchTip = readBranchTip(cmd, magicBranch.dest);
            if (branchTip == null) {
                // readBranchTip already rejected cmd.
                return;
            }
            if (!walk.isMergedInto(tip, branchTip)) {
                reject(cmd, "not merged into branch");
                return;
            }
        }
        // if %base or %merged was specified, ignore newChangeForAllNotInTarget.
        if (tip.getParentCount() > 1 || magicBranch.base != null || magicBranch.merged || tip.getParentCount() == 0) {
            logDebug("Forcing newChangeForAllNotInTarget = false");
            newChangeForAllNotInTarget = false;
        }
        if (magicBranch.base != null) {
            logDebug("Handling %base: %s", magicBranch.base);
            magicBranch.baseCommit = Lists.newArrayListWithCapacity(magicBranch.base.size());
            for (ObjectId id : magicBranch.base) {
                try {
                    magicBranch.baseCommit.add(walk.parseCommit(id));
                } catch (IncorrectObjectTypeException notCommit) {
                    reject(cmd, "base must be a commit");
                    return;
                } catch (MissingObjectException e) {
                    reject(cmd, "base not found");
                    return;
                } catch (IOException e) {
                    logWarn(String.format("Project %s cannot read %s", project.getName(), id.name()), e);
                    reject(cmd, "internal server error");
                    return;
                }
            }
        } else if (newChangeForAllNotInTarget) {
            RevCommit branchTip = readBranchTip(cmd, magicBranch.dest);
            if (branchTip == null) {
                // readBranchTip already rejected cmd.
                return;
            }
            magicBranch.baseCommit = Collections.singletonList(branchTip);
            logDebug("Set baseCommit = %s", magicBranch.baseCommit.get(0).name());
        }
    } catch (IOException ex) {
        logWarn(String.format("Error walking to %s in project %s", destBranch, project.getName()), ex);
        reject(cmd, "internal server error");
        return;
    }
    // 
    try {
        Ref targetRef = receivePack.getAdvertisedRefs().get(magicBranch.dest.get());
        if (targetRef == null || targetRef.getObjectId() == null) {
            // The destination branch does not yet exist. Assume the
            // history being sent for review will start it and thus
            // is "connected" to the branch.
            logDebug("Branch is unborn");
            return;
        }
        RevCommit h = walk.parseCommit(targetRef.getObjectId());
        logDebug("Current branch tip: %s", h.name());
        RevFilter oldRevFilter = walk.getRevFilter();
        try {
            walk.reset();
            walk.setRevFilter(RevFilter.MERGE_BASE);
            walk.markStart(tip);
            walk.markStart(h);
            if (walk.next() == null) {
                reject(magicBranch.cmd, "no common ancestry");
            }
        } finally {
            walk.reset();
            walk.setRevFilter(oldRevFilter);
        }
    } catch (IOException e) {
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", e);
    }
}
#method_after
private void parseMagicBranch(ReceiveCommand cmd) throws PermissionBackendException {
    logger.atFine().log("Found magic branch %s", cmd.getRefName());
    magicBranch = new MagicBranchInput(user, cmd, labelTypes, notesMigration);
    magicBranch.reviewer.addAll(extraReviewers.get(ReviewerStateInternal.REVIEWER));
    magicBranch.cc.addAll(extraReviewers.get(ReviewerStateInternal.CC));
    String ref;
    magicBranch.cmdLineParser = optionParserFactory.create(magicBranch);
    try {
        ref = magicBranch.parse(repo, receivePack.getAdvertisedRefs().keySet(), pushOptions);
    } catch (CmdLineException e) {
        if (!magicBranch.cmdLineParser.wasHelpRequestedByOption()) {
            logger.atFine().log("Invalid branch syntax");
            reject(cmd, e.getMessage());
            return;
        }
        // never happens
        ref = null;
    }
    if (magicBranch.topic != null && magicBranch.topic.length() > ChangeUtil.TOPIC_MAX_LENGTH) {
        reject(cmd, String.format("topic length exceeds the limit (%d)", ChangeUtil.TOPIC_MAX_LENGTH));
    }
    if (magicBranch.cmdLineParser.wasHelpRequestedByOption()) {
        StringWriter w = new StringWriter();
        w.write("\nHelp for refs/for/branch:\n\n");
        magicBranch.cmdLineParser.printUsage(w, null);
        addMessage(w.toString());
        reject(cmd, "see help");
        return;
    }
    if (projectState.isAllUsers() && RefNames.REFS_USERS_SELF.equals(ref)) {
        logger.atFine().log("Handling %s", RefNames.REFS_USERS_SELF);
        ref = RefNames.refsUsers(user.getAccountId());
    }
    if (!receivePack.getAdvertisedRefs().containsKey(ref) && !ref.equals(readHEAD(repo)) && !ref.equals(RefNames.REFS_CONFIG)) {
        logger.atFine().log("Ref %s not found", ref);
        if (ref.startsWith(Constants.R_HEADS)) {
            String n = ref.substring(Constants.R_HEADS.length());
            reject(cmd, "branch " + n + " not found");
        } else {
            reject(cmd, ref + " not found");
        }
        return;
    }
    magicBranch.dest = new Branch.NameKey(project.getNameKey(), ref);
    magicBranch.perm = permissions.ref(ref);
    Optional<AuthException> err = checkRefPermission(magicBranch.perm, RefPermission.CREATE_CHANGE);
    if (err.isPresent()) {
        rejectProhibited(cmd, err.get());
        return;
    }
    if (!projectState.statePermitsWrite()) {
        reject(cmd, "project state does not permit write");
        return;
    }
    // after repo-tool supports private and work-in-progress changes.
    if (magicBranch.draft && !receiveConfig.allowDrafts) {
        errors.put(ReceiveError.CODE_REVIEW.get(), ref);
        reject(cmd, "draft workflow is disabled");
        return;
    }
    if (magicBranch.isPrivate && magicBranch.removePrivate) {
        reject(cmd, "the options 'private' and 'remove-private' are mutually exclusive");
        return;
    }
    boolean privateByDefault = projectCache.get(project.getNameKey()).is(BooleanProjectConfig.PRIVATE_BY_DEFAULT);
    setChangeAsPrivate = magicBranch.draft || magicBranch.isPrivate || (privateByDefault && !magicBranch.removePrivate);
    if (receiveConfig.disablePrivateChanges && setChangeAsPrivate) {
        reject(cmd, "private changes are disabled");
        return;
    }
    if (magicBranch.workInProgress && magicBranch.ready) {
        reject(cmd, "the options 'wip' and 'ready' are mutually exclusive");
        return;
    }
    if (magicBranch.publishComments && magicBranch.noPublishComments) {
        reject(cmd, "the options 'publish-comments' and 'no-publish-comments' are mutually exclusive");
        return;
    }
    if (magicBranch.submit) {
        err = checkRefPermission(magicBranch.perm, RefPermission.UPDATE_BY_SUBMIT);
        if (err.isPresent()) {
            rejectProhibited(cmd, err.get());
            return;
        }
    }
    RevWalk walk = receivePack.getRevWalk();
    RevCommit tip;
    try {
        tip = walk.parseCommit(magicBranch.cmd.getNewId());
        logger.atFine().log("Tip of push: %s", tip.name());
    } catch (IOException ex) {
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logger.atSevere().withCause(ex).log("Invalid pack upload; one or more objects weren't sent");
        return;
    }
    String destBranch = magicBranch.dest.get();
    try {
        if (magicBranch.merged) {
            if (magicBranch.base != null) {
                reject(cmd, "cannot use merged with base");
                return;
            }
            RevCommit branchTip = readBranchTip(cmd, magicBranch.dest);
            if (branchTip == null) {
                // readBranchTip already rejected cmd.
                return;
            }
            if (!walk.isMergedInto(tip, branchTip)) {
                reject(cmd, "not merged into branch");
                return;
            }
        }
        // if %base or %merged was specified, ignore newChangeForAllNotInTarget.
        if (tip.getParentCount() > 1 || magicBranch.base != null || magicBranch.merged || tip.getParentCount() == 0) {
            logger.atFine().log("Forcing newChangeForAllNotInTarget = false");
            newChangeForAllNotInTarget = false;
        }
        if (magicBranch.base != null) {
            logger.atFine().log("Handling %%base: %s", magicBranch.base);
            magicBranch.baseCommit = Lists.newArrayListWithCapacity(magicBranch.base.size());
            for (ObjectId id : magicBranch.base) {
                try {
                    magicBranch.baseCommit.add(walk.parseCommit(id));
                } catch (IncorrectObjectTypeException notCommit) {
                    reject(cmd, "base must be a commit");
                    return;
                } catch (MissingObjectException e) {
                    reject(cmd, "base not found");
                    return;
                } catch (IOException e) {
                    logger.atWarning().withCause(e).log("Project %s cannot read %s", project.getName(), id.name());
                    reject(cmd, "internal server error");
                    return;
                }
            }
        } else if (newChangeForAllNotInTarget) {
            RevCommit branchTip = readBranchTip(cmd, magicBranch.dest);
            if (branchTip == null) {
                // readBranchTip already rejected cmd.
                return;
            }
            magicBranch.baseCommit = Collections.singletonList(branchTip);
            logger.atFine().log("Set baseCommit = %s", magicBranch.baseCommit.get(0).name());
        }
    } catch (IOException ex) {
        logger.atWarning().withCause(ex).log("Error walking to %s in project %s", destBranch, project.getName());
        reject(cmd, "internal server error");
        return;
    }
    // 
    try {
        Ref targetRef = receivePack.getAdvertisedRefs().get(magicBranch.dest.get());
        if (targetRef == null || targetRef.getObjectId() == null) {
            // The destination branch does not yet exist. Assume the
            // history being sent for review will start it and thus
            // is "connected" to the branch.
            logger.atFine().log("Branch is unborn");
            return;
        }
        RevCommit h = walk.parseCommit(targetRef.getObjectId());
        logger.atFine().log("Current branch tip: %s", h.name());
        RevFilter oldRevFilter = walk.getRevFilter();
        try {
            walk.reset();
            walk.setRevFilter(RevFilter.MERGE_BASE);
            walk.markStart(tip);
            walk.markStart(h);
            if (walk.next() == null) {
                reject(magicBranch.cmd, "no common ancestry");
            }
        } finally {
            walk.reset();
            walk.setRevFilter(oldRevFilter);
        }
    } catch (IOException e) {
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logger.atSevere().withCause(e).log("Invalid pack upload; one or more objects weren't sent");
    }
}
#end_block

#method_before
private void parseReplaceCommand(ReceiveCommand cmd, Change.Id changeId) {
    logDebug("Parsing replace command");
    if (cmd.getType() != ReceiveCommand.Type.CREATE) {
        reject(cmd, "invalid usage");
        return;
    }
    RevCommit newCommit;
    try {
        newCommit = receivePack.getRevWalk().parseCommit(cmd.getNewId());
        logDebug("Replacing with %s", newCommit);
    } catch (IOException e) {
        logError("Cannot parse " + cmd.getNewId().name() + " as commit", e);
        reject(cmd, "invalid commit");
        return;
    }
    Change changeEnt;
    try {
        changeEnt = notesFactory.createChecked(db, project.getNameKey(), changeId).getChange();
    } catch (NoSuchChangeException e) {
        logError("Change not found " + changeId, e);
        reject(cmd, "change " + changeId + " not found");
        return;
    } catch (OrmException e) {
        logError("Cannot lookup existing change " + changeId, e);
        reject(cmd, "database error");
        return;
    }
    if (!project.getNameKey().equals(changeEnt.getProject())) {
        reject(cmd, "change " + changeId + " does not belong to project " + project.getName());
        return;
    }
    logDebug("Replacing change %s", changeEnt.getId());
    requestReplace(cmd, true, changeEnt, newCommit);
}
#method_after
private void parseReplaceCommand(ReceiveCommand cmd, Change.Id changeId) {
    logger.atFine().log("Parsing replace command");
    if (cmd.getType() != ReceiveCommand.Type.CREATE) {
        reject(cmd, "invalid usage");
        return;
    }
    RevCommit newCommit;
    try {
        newCommit = receivePack.getRevWalk().parseCommit(cmd.getNewId());
        logger.atFine().log("Replacing with %s", newCommit);
    } catch (IOException e) {
        logger.atSevere().withCause(e).log("Cannot parse %s as commit", cmd.getNewId().name());
        reject(cmd, "invalid commit");
        return;
    }
    Change changeEnt;
    try {
        changeEnt = notesFactory.createChecked(db, project.getNameKey(), changeId).getChange();
    } catch (NoSuchChangeException e) {
        logger.atSevere().withCause(e).log("Change not found %s", changeId);
        reject(cmd, "change " + changeId + " not found");
        return;
    } catch (OrmException e) {
        logger.atSevere().withCause(e).log("Cannot lookup existing change %s", changeId);
        reject(cmd, "database error");
        return;
    }
    if (!project.getNameKey().equals(changeEnt.getProject())) {
        reject(cmd, "change " + changeId + " does not belong to project " + project.getName());
        return;
    }
    logger.atFine().log("Replacing change %s", changeEnt.getId());
    requestReplace(cmd, true, changeEnt, newCommit);
}
#end_block

#method_before
private List<CreateRequest> selectNewAndReplacedChangesFromMagicBranch() {
    logDebug("Finding new and replaced changes");
    List<CreateRequest> newChanges = new ArrayList<>();
    ListMultimap<ObjectId, Ref> existing = changeRefsById();
    GroupCollector groupCollector = GroupCollector.create(changeRefsById(), db, psUtil, notesFactory, project.getNameKey());
    try {
        RevCommit start = setUpWalkForSelectingChanges();
        if (start == null) {
            return Collections.emptyList();
        }
        LinkedHashMap<RevCommit, ChangeLookup> pending = new LinkedHashMap<>();
        Set<Change.Key> newChangeIds = new HashSet<>();
        int maxBatchChanges = receiveConfig.getEffectiveMaxBatchChangesLimit(user);
        int total = 0;
        int alreadyTracked = 0;
        boolean rejectImplicitMerges = start.getParentCount() == 1 && projectCache.get(project.getNameKey()).is(BooleanProjectConfig.REJECT_IMPLICIT_MERGES) && // late.
        !magicBranch.merged;
        Set<RevCommit> mergedParents;
        if (rejectImplicitMerges) {
            mergedParents = new HashSet<>();
        } else {
            mergedParents = null;
        }
        for (; ; ) {
            RevCommit c = receivePack.getRevWalk().next();
            if (c == null) {
                break;
            }
            total++;
            receivePack.getRevWalk().parseBody(c);
            String name = c.name();
            groupCollector.visit(c);
            Collection<Ref> existingRefs = existing.get(c);
            if (rejectImplicitMerges) {
                Collections.addAll(mergedParents, c.getParents());
                mergedParents.remove(c);
            }
            boolean commitAlreadyTracked = !existingRefs.isEmpty();
            if (commitAlreadyTracked) {
                alreadyTracked++;
                // different target branch.
                for (Ref ref : existingRefs) {
                    updateGroups.add(new UpdateGroupsRequest(ref, c));
                }
                if (!(newChangeForAllNotInTarget || magicBranch.base != null)) {
                    continue;
                }
            }
            List<String> idList = c.getFooterLines(CHANGE_ID);
            if (!idList.isEmpty()) {
                pending.put(c, new ChangeLookup(c, new Change.Key(idList.get(idList.size() - 1).trim())));
            } else {
                pending.put(c, new ChangeLookup(c));
            }
            int n = pending.size() + newChanges.size();
            if (maxBatchChanges != 0 && n > maxBatchChanges) {
                logDebug("%d changes exceeds limit of %d", n, maxBatchChanges);
                reject(magicBranch.cmd, "the number of pushed changes in a batch exceeds the max limit " + maxBatchChanges);
                return Collections.emptyList();
            }
            if (commitAlreadyTracked) {
                boolean changeExistsOnDestBranch = false;
                for (ChangeData cd : pending.get(c).destChanges) {
                    if (cd.change().getDest().equals(magicBranch.dest)) {
                        changeExistsOnDestBranch = true;
                        break;
                    }
                }
                if (changeExistsOnDestBranch) {
                    continue;
                }
                logDebug("Creating new change for %s even though it is already tracked", name);
            }
            if (!validCommit(receivePack.getRevWalk(), magicBranch.dest, magicBranch.cmd, c, null)) {
                // Not a change the user can propose? Abort as early as possible.
                logDebug("Aborting early due to invalid commit");
                return Collections.emptyList();
            }
            // Don't allow merges to be uploaded in commit chain via all-not-in-target
            if (newChangeForAllNotInTarget && c.getParentCount() > 1) {
                reject(magicBranch.cmd, "Pushing merges in commit chains with 'all not in target' is not allowed,\n" + "to override please set the base manually");
                logDebug("Rejecting merge commit %s with newChangeForAllNotInTarget", name);
            // TODO(dborowitz): Should we early return here?
            }
            if (idList.isEmpty()) {
                newChanges.add(new CreateRequest(c, magicBranch.dest.get()));
                continue;
            }
        }
        logDebug("Finished initial RevWalk with %d commits total: %d already" + " tracked, %d new changes with no Change-Id, and %d deferred" + " lookups", total, alreadyTracked, newChanges.size(), pending.size());
        if (rejectImplicitMerges) {
            rejectImplicitMerges(mergedParents);
        }
        for (Iterator<ChangeLookup> itr = pending.values().iterator(); itr.hasNext(); ) {
            ChangeLookup p = itr.next();
            if (p.changeKey == null) {
                continue;
            }
            if (newChangeIds.contains(p.changeKey)) {
                logDebug("Multiple commits with Change-Id %s", p.changeKey);
                reject(magicBranch.cmd, SAME_CHANGE_ID_IN_MULTIPLE_CHANGES);
                return Collections.emptyList();
            }
            List<ChangeData> changes = p.destChanges;
            if (changes.size() > 1) {
                logDebug("Multiple changes in branch %s with Change-Id %s: %s", magicBranch.dest, p.changeKey, changes.stream().map(cd -> cd.getId().toString()).collect(joining()));
                // WTF, multiple changes in this branch have the same key?
                // Since the commit is new, the user should recreate it with
                // a different Change-Id. In practice, we should never see
                // this error message as Change-Id should be unique per branch.
                // 
                reject(magicBranch.cmd, p.changeKey.get() + " has duplicates");
                return Collections.emptyList();
            }
            if (changes.size() == 1) {
                // Schedule as a replacement to this one matching change.
                // 
                RevId currentPs = changes.get(0).currentPatchSet().getRevision();
                // If Commit is already current PatchSet of target Change.
                if (p.commit.name().equals(currentPs.get())) {
                    if (pending.size() == 1) {
                        // There are no commits left to check, all commits in pending were already
                        // current PatchSet of the corresponding target changes.
                        reject(magicBranch.cmd, "commit(s) already exists (as current patchset)");
                    } else {
                        // Commit is already current PatchSet.
                        // Remove from pending and try next commit.
                        itr.remove();
                        continue;
                    }
                }
                if (requestReplace(magicBranch.cmd, false, changes.get(0).change(), p.commit)) {
                    continue;
                }
                return Collections.emptyList();
            }
            if (changes.size() == 0) {
                if (!isValidChangeId(p.changeKey.get())) {
                    reject(magicBranch.cmd, "invalid Change-Id");
                    return Collections.emptyList();
                }
                // double check against the existing refs
                if (foundInExistingRef(existing.get(p.commit))) {
                    if (pending.size() == 1) {
                        reject(magicBranch.cmd, "commit(s) already exists (as current patchset)");
                        return Collections.emptyList();
                    }
                    itr.remove();
                    continue;
                }
                newChangeIds.add(p.changeKey);
            }
            newChanges.add(new CreateRequest(p.commit, magicBranch.dest.get()));
        }
        logDebug("Finished deferred lookups with %d updates and %d new changes", replaceByChange.size(), newChanges.size());
    } catch (IOException e) {
        // Should never happen, the core receive process would have
        // identified the missing object earlier before we got control.
        // 
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", e);
        return Collections.emptyList();
    } catch (OrmException e) {
        logError("Cannot query database to locate prior changes", e);
        reject(magicBranch.cmd, "database error");
        return Collections.emptyList();
    }
    if (newChanges.isEmpty() && replaceByChange.isEmpty()) {
        reject(magicBranch.cmd, "no new changes");
        return Collections.emptyList();
    }
    if (!newChanges.isEmpty() && magicBranch.edit) {
        reject(magicBranch.cmd, "edit is not supported for new changes");
        return newChanges;
    }
    try {
        SortedSetMultimap<ObjectId, String> groups = groupCollector.getGroups();
        List<Integer> newIds = seq.nextChangeIds(newChanges.size());
        for (int i = 0; i < newChanges.size(); i++) {
            CreateRequest create = newChanges.get(i);
            create.setChangeId(newIds.get(i));
            create.groups = ImmutableList.copyOf(groups.get(create.commit));
        }
        for (ReplaceRequest replace : replaceByChange.values()) {
            replace.groups = ImmutableList.copyOf(groups.get(replace.newCommitId));
        }
        for (UpdateGroupsRequest update : updateGroups) {
            update.groups = ImmutableList.copyOf((groups.get(update.commit)));
        }
        logDebug("Finished updating groups from GroupCollector");
    } catch (OrmException e) {
        logError("Error collecting groups for changes", e);
        reject(magicBranch.cmd, "internal server error");
    }
    return newChanges;
}
#method_after
private List<CreateRequest> selectNewAndReplacedChangesFromMagicBranch() {
    logger.atFine().log("Finding new and replaced changes");
    List<CreateRequest> newChanges = new ArrayList<>();
    ListMultimap<ObjectId, Ref> existing = changeRefsById();
    GroupCollector groupCollector = GroupCollector.create(changeRefsById(), db, psUtil, notesFactory, project.getNameKey());
    try {
        RevCommit start = setUpWalkForSelectingChanges();
        if (start == null) {
            return Collections.emptyList();
        }
        LinkedHashMap<RevCommit, ChangeLookup> pending = new LinkedHashMap<>();
        Set<Change.Key> newChangeIds = new HashSet<>();
        int maxBatchChanges = receiveConfig.getEffectiveMaxBatchChangesLimit(user);
        int total = 0;
        int alreadyTracked = 0;
        boolean rejectImplicitMerges = start.getParentCount() == 1 && projectCache.get(project.getNameKey()).is(BooleanProjectConfig.REJECT_IMPLICIT_MERGES) && // late.
        !magicBranch.merged;
        Set<RevCommit> mergedParents;
        if (rejectImplicitMerges) {
            mergedParents = new HashSet<>();
        } else {
            mergedParents = null;
        }
        for (; ; ) {
            RevCommit c = receivePack.getRevWalk().next();
            if (c == null) {
                break;
            }
            total++;
            receivePack.getRevWalk().parseBody(c);
            String name = c.name();
            groupCollector.visit(c);
            Collection<Ref> existingRefs = existing.get(c);
            if (rejectImplicitMerges) {
                Collections.addAll(mergedParents, c.getParents());
                mergedParents.remove(c);
            }
            boolean commitAlreadyTracked = !existingRefs.isEmpty();
            if (commitAlreadyTracked) {
                alreadyTracked++;
                // different target branch.
                for (Ref ref : existingRefs) {
                    updateGroups.add(new UpdateGroupsRequest(ref, c));
                }
                if (!(newChangeForAllNotInTarget || magicBranch.base != null)) {
                    continue;
                }
            }
            List<String> idList = c.getFooterLines(CHANGE_ID);
            if (!idList.isEmpty()) {
                pending.put(c, new ChangeLookup(c, new Change.Key(idList.get(idList.size() - 1).trim())));
            } else {
                pending.put(c, new ChangeLookup(c));
            }
            int n = pending.size() + newChanges.size();
            if (maxBatchChanges != 0 && n > maxBatchChanges) {
                logger.atFine().log("%d changes exceeds limit of %d", n, maxBatchChanges);
                reject(magicBranch.cmd, "the number of pushed changes in a batch exceeds the max limit " + maxBatchChanges);
                return Collections.emptyList();
            }
            if (commitAlreadyTracked) {
                boolean changeExistsOnDestBranch = false;
                for (ChangeData cd : pending.get(c).destChanges) {
                    if (cd.change().getDest().equals(magicBranch.dest)) {
                        changeExistsOnDestBranch = true;
                        break;
                    }
                }
                if (changeExistsOnDestBranch) {
                    continue;
                }
                logger.atFine().log("Creating new change for %s even though it is already tracked", name);
            }
            if (!validCommit(receivePack.getRevWalk(), magicBranch.dest, magicBranch.cmd, c, null)) {
                // Not a change the user can propose? Abort as early as possible.
                logger.atFine().log("Aborting early due to invalid commit");
                return Collections.emptyList();
            }
            // Don't allow merges to be uploaded in commit chain via all-not-in-target
            if (newChangeForAllNotInTarget && c.getParentCount() > 1) {
                reject(magicBranch.cmd, "Pushing merges in commit chains with 'all not in target' is not allowed,\n" + "to override please set the base manually");
                logger.atFine().log("Rejecting merge commit %s with newChangeForAllNotInTarget", name);
            // TODO(dborowitz): Should we early return here?
            }
            if (idList.isEmpty()) {
                newChanges.add(new CreateRequest(c, magicBranch.dest.get()));
                continue;
            }
        }
        logger.atFine().log("Finished initial RevWalk with %d commits total: %d already" + " tracked, %d new changes with no Change-Id, and %d deferred" + " lookups", total, alreadyTracked, newChanges.size(), pending.size());
        if (rejectImplicitMerges) {
            rejectImplicitMerges(mergedParents);
        }
        for (Iterator<ChangeLookup> itr = pending.values().iterator(); itr.hasNext(); ) {
            ChangeLookup p = itr.next();
            if (p.changeKey == null) {
                continue;
            }
            if (newChangeIds.contains(p.changeKey)) {
                logger.atFine().log("Multiple commits with Change-Id %s", p.changeKey);
                reject(magicBranch.cmd, SAME_CHANGE_ID_IN_MULTIPLE_CHANGES);
                return Collections.emptyList();
            }
            List<ChangeData> changes = p.destChanges;
            if (changes.size() > 1) {
                logger.atFine().log("Multiple changes in branch %s with Change-Id %s: %s", magicBranch.dest, p.changeKey, changes.stream().map(cd -> cd.getId().toString()).collect(joining()));
                // WTF, multiple changes in this branch have the same key?
                // Since the commit is new, the user should recreate it with
                // a different Change-Id. In practice, we should never see
                // this error message as Change-Id should be unique per branch.
                // 
                reject(magicBranch.cmd, p.changeKey.get() + " has duplicates");
                return Collections.emptyList();
            }
            if (changes.size() == 1) {
                // Schedule as a replacement to this one matching change.
                // 
                RevId currentPs = changes.get(0).currentPatchSet().getRevision();
                // If Commit is already current PatchSet of target Change.
                if (p.commit.name().equals(currentPs.get())) {
                    if (pending.size() == 1) {
                        // There are no commits left to check, all commits in pending were already
                        // current PatchSet of the corresponding target changes.
                        reject(magicBranch.cmd, "commit(s) already exists (as current patchset)");
                    } else {
                        // Commit is already current PatchSet.
                        // Remove from pending and try next commit.
                        itr.remove();
                        continue;
                    }
                }
                if (requestReplace(magicBranch.cmd, false, changes.get(0).change(), p.commit)) {
                    continue;
                }
                return Collections.emptyList();
            }
            if (changes.size() == 0) {
                if (!isValidChangeId(p.changeKey.get())) {
                    reject(magicBranch.cmd, "invalid Change-Id");
                    return Collections.emptyList();
                }
                // double check against the existing refs
                if (foundInExistingRef(existing.get(p.commit))) {
                    if (pending.size() == 1) {
                        reject(magicBranch.cmd, "commit(s) already exists (as current patchset)");
                        return Collections.emptyList();
                    }
                    itr.remove();
                    continue;
                }
                newChangeIds.add(p.changeKey);
            }
            newChanges.add(new CreateRequest(p.commit, magicBranch.dest.get()));
        }
        logger.atFine().log("Finished deferred lookups with %d updates and %d new changes", replaceByChange.size(), newChanges.size());
    } catch (IOException e) {
        // Should never happen, the core receive process would have
        // identified the missing object earlier before we got control.
        // 
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logger.atSevere().withCause(e).log("Invalid pack upload; one or more objects weren't sent");
        return Collections.emptyList();
    } catch (OrmException e) {
        logger.atSevere().withCause(e).log("Cannot query database to locate prior changes");
        reject(magicBranch.cmd, "database error");
        return Collections.emptyList();
    }
    if (newChanges.isEmpty() && replaceByChange.isEmpty()) {
        reject(magicBranch.cmd, "no new changes");
        return Collections.emptyList();
    }
    if (!newChanges.isEmpty() && magicBranch.edit) {
        reject(magicBranch.cmd, "edit is not supported for new changes");
        return newChanges;
    }
    try {
        SortedSetMultimap<ObjectId, String> groups = groupCollector.getGroups();
        List<Integer> newIds = seq.nextChangeIds(newChanges.size());
        for (int i = 0; i < newChanges.size(); i++) {
            CreateRequest create = newChanges.get(i);
            create.setChangeId(newIds.get(i));
            create.groups = ImmutableList.copyOf(groups.get(create.commit));
        }
        for (ReplaceRequest replace : replaceByChange.values()) {
            replace.groups = ImmutableList.copyOf(groups.get(replace.newCommitId));
        }
        for (UpdateGroupsRequest update : updateGroups) {
            update.groups = ImmutableList.copyOf((groups.get(update.commit)));
        }
        logger.atFine().log("Finished updating groups from GroupCollector");
    } catch (OrmException e) {
        logger.atSevere().withCause(e).log("Error collecting groups for changes");
        reject(magicBranch.cmd, "internal server error");
    }
    return newChanges;
}
#end_block

#method_before
private boolean foundInExistingRef(Collection<Ref> existingRefs) throws OrmException {
    for (Ref ref : existingRefs) {
        ChangeNotes notes = notesFactory.create(db, project.getNameKey(), Change.Id.fromRef(ref.getName()));
        Change change = notes.getChange();
        if (change.getDest().equals(magicBranch.dest)) {
            logDebug("Found change %s from existing refs.", change.getKey());
            // Reindex the change asynchronously, ignoring errors.
            @SuppressWarnings("unused")
            Future<?> possiblyIgnoredError = indexer.indexAsync(project.getNameKey(), change.getId());
            return true;
        }
    }
    return false;
}
#method_after
private boolean foundInExistingRef(Collection<Ref> existingRefs) throws OrmException {
    for (Ref ref : existingRefs) {
        ChangeNotes notes = notesFactory.create(db, project.getNameKey(), Change.Id.fromRef(ref.getName()));
        Change change = notes.getChange();
        if (change.getDest().equals(magicBranch.dest)) {
            logger.atFine().log("Found change %s from existing refs.", change.getKey());
            // Reindex the change asynchronously, ignoring errors.
            @SuppressWarnings("unused")
            Future<?> possiblyIgnoredError = indexer.indexAsync(project.getNameKey(), change.getId());
            return true;
        }
    }
    return false;
}
#end_block

#method_before
private RevCommit setUpWalkForSelectingChanges() throws IOException {
    RevWalk rw = receivePack.getRevWalk();
    RevCommit start = rw.parseCommit(magicBranch.cmd.getNewId());
    rw.reset();
    rw.sort(RevSort.TOPO);
    rw.sort(RevSort.REVERSE, true);
    receivePack.getRevWalk().markStart(start);
    if (magicBranch.baseCommit != null) {
        markExplicitBasesUninteresting();
    } else if (magicBranch.merged) {
        logDebug("Marking parents of merged commit %s uninteresting", start.name());
        for (RevCommit c : start.getParents()) {
            rw.markUninteresting(c);
        }
    } else {
        markHeadsAsUninteresting(rw, magicBranch.dest != null ? magicBranch.dest.get() : null);
    }
    return start;
}
#method_after
private RevCommit setUpWalkForSelectingChanges() throws IOException {
    RevWalk rw = receivePack.getRevWalk();
    RevCommit start = rw.parseCommit(magicBranch.cmd.getNewId());
    rw.reset();
    rw.sort(RevSort.TOPO);
    rw.sort(RevSort.REVERSE, true);
    receivePack.getRevWalk().markStart(start);
    if (magicBranch.baseCommit != null) {
        markExplicitBasesUninteresting();
    } else if (magicBranch.merged) {
        logger.atFine().log("Marking parents of merged commit %s uninteresting", start.name());
        for (RevCommit c : start.getParents()) {
            rw.markUninteresting(c);
        }
    } else {
        markHeadsAsUninteresting(rw, magicBranch.dest != null ? magicBranch.dest.get() : null);
    }
    return start;
}
#end_block

#method_before
private void markExplicitBasesUninteresting() throws IOException {
    logDebug("Marking %d base commits uninteresting", magicBranch.baseCommit.size());
    for (RevCommit c : magicBranch.baseCommit) {
        receivePack.getRevWalk().markUninteresting(c);
    }
    Ref targetRef = allRefs().get(magicBranch.dest.get());
    if (targetRef != null) {
        logDebug("Marking target ref %s (%s) uninteresting", magicBranch.dest.get(), targetRef.getObjectId().name());
        receivePack.getRevWalk().markUninteresting(receivePack.getRevWalk().parseCommit(targetRef.getObjectId()));
    }
}
#method_after
private void markExplicitBasesUninteresting() throws IOException {
    logger.atFine().log("Marking %d base commits uninteresting", magicBranch.baseCommit.size());
    for (RevCommit c : magicBranch.baseCommit) {
        receivePack.getRevWalk().markUninteresting(c);
    }
    Ref targetRef = allRefs().get(magicBranch.dest.get());
    if (targetRef != null) {
        logger.atFine().log("Marking target ref %s (%s) uninteresting", magicBranch.dest.get(), targetRef.getObjectId().name());
        receivePack.getRevWalk().markUninteresting(receivePack.getRevWalk().parseCommit(targetRef.getObjectId()));
    }
}
#end_block

#method_before
// Mark all branch tips as uninteresting in the given revwalk,
private void markHeadsAsUninteresting(RevWalk rw, @Nullable String forRef) {
    int i = 0;
    for (Ref ref : allRefs().values()) {
        if ((ref.getName().startsWith(R_HEADS) || ref.getName().equals(forRef)) && ref.getObjectId() != null) {
            try {
                rw.markUninteresting(rw.parseCommit(ref.getObjectId()));
                i++;
            } catch (IOException e) {
                logWarn(String.format("Invalid ref %s in %s", ref.getName(), project.getName()), e);
            }
        }
    }
    logDebug("Marked %d heads as uninteresting", i);
}
#method_after
// Mark all branch tips as uninteresting in the given revwalk,
private void markHeadsAsUninteresting(RevWalk rw, @Nullable String forRef) {
    int i = 0;
    for (Ref ref : allRefs().values()) {
        if ((ref.getName().startsWith(R_HEADS) || ref.getName().equals(forRef)) && ref.getObjectId() != null) {
            try {
                rw.markUninteresting(rw.parseCommit(ref.getObjectId()));
                i++;
            } catch (IOException e) {
                logger.atWarning().withCause(e).log("Invalid ref %s in %s", ref.getName(), project.getName());
            }
        }
    }
    logger.atFine().log("Marked %d heads as uninteresting", i);
}
#end_block

#method_before
private void submit(Collection<CreateRequest> create, Collection<ReplaceRequest> replace) throws OrmException, RestApiException, UpdateException, IOException, ConfigInvalidException, PermissionBackendException {
    Map<ObjectId, Change> bySha = Maps.newHashMapWithExpectedSize(create.size() + replace.size());
    for (CreateRequest r : create) {
        checkNotNull(r.change, "cannot submit new change %s; op may not have run", r.changeId);
        bySha.put(r.commit, r.change);
    }
    for (ReplaceRequest r : replace) {
        bySha.put(r.newCommitId, r.notes.getChange());
    }
    Change tipChange = bySha.get(magicBranch.cmd.getNewId());
    checkNotNull(tipChange, "tip of push does not correspond to a change; found these changes: %s", bySha);
    logDebug("Processing submit with tip change %s (%s)", tipChange.getId(), magicBranch.cmd.getNewId());
    try (MergeOp op = mergeOpProvider.get()) {
        op.merge(db, tipChange, user, false, new SubmitInput(), false);
    }
}
#method_after
private void submit(Collection<CreateRequest> create, Collection<ReplaceRequest> replace) throws OrmException, RestApiException, UpdateException, IOException, ConfigInvalidException, PermissionBackendException {
    Map<ObjectId, Change> bySha = Maps.newHashMapWithExpectedSize(create.size() + replace.size());
    for (CreateRequest r : create) {
        checkNotNull(r.change, "cannot submit new change %s; op may not have run", r.changeId);
        bySha.put(r.commit, r.change);
    }
    for (ReplaceRequest r : replace) {
        bySha.put(r.newCommitId, r.notes.getChange());
    }
    Change tipChange = bySha.get(magicBranch.cmd.getNewId());
    checkNotNull(tipChange, "tip of push does not correspond to a change; found these changes: %s", bySha);
    logger.atFine().log("Processing submit with tip change %s (%s)", tipChange.getId(), magicBranch.cmd.getNewId());
    try (MergeOp op = mergeOpProvider.get()) {
        op.merge(db, tipChange, user, false, new SubmitInput(), false);
    }
}
#end_block

#method_before
private void preparePatchSetsForReplace(List<CreateRequest> newChanges) {
    try {
        readChangesForReplace();
        for (Iterator<ReplaceRequest> itr = replaceByChange.values().iterator(); itr.hasNext(); ) {
            ReplaceRequest req = itr.next();
            if (req.inputCommand.getResult() == NOT_ATTEMPTED) {
                req.validate(false);
            }
        }
    } catch (OrmException err) {
        logError(String.format("Cannot read database before replacement for project %s", project.getName()), err);
        for (ReplaceRequest req : replaceByChange.values()) {
            if (req.inputCommand.getResult() == NOT_ATTEMPTED) {
                req.inputCommand.setResult(REJECTED_OTHER_REASON, "internal server error");
            }
        }
    } catch (IOException | PermissionBackendException err) {
        logError(String.format("Cannot read repository before replacement for project %s", project.getName()), err);
        for (ReplaceRequest req : replaceByChange.values()) {
            if (req.inputCommand.getResult() == NOT_ATTEMPTED) {
                req.inputCommand.setResult(REJECTED_OTHER_REASON, "internal server error");
            }
        }
    }
    logDebug("Read %d changes to replace", replaceByChange.size());
    if (magicBranch != null && magicBranch.cmd.getResult() != NOT_ATTEMPTED) {
        // Cancel creations tied to refs/for/ or refs/drafts/ command.
        for (ReplaceRequest req : replaceByChange.values()) {
            if (req.inputCommand == magicBranch.cmd && req.cmd != null) {
                req.cmd.setResult(Result.REJECTED_OTHER_REASON, "aborted");
            }
        }
        for (CreateRequest req : newChanges) {
            req.cmd.setResult(Result.REJECTED_OTHER_REASON, "aborted");
        }
    }
}
#method_after
private void preparePatchSetsForReplace(List<CreateRequest> newChanges) {
    try {
        readChangesForReplace();
        for (Iterator<ReplaceRequest> itr = replaceByChange.values().iterator(); itr.hasNext(); ) {
            ReplaceRequest req = itr.next();
            if (req.inputCommand.getResult() == NOT_ATTEMPTED) {
                req.validate(false);
            }
        }
    } catch (OrmException err) {
        logger.atSevere().withCause(err).log("Cannot read database before replacement for project %s", project.getName());
        for (ReplaceRequest req : replaceByChange.values()) {
            if (req.inputCommand.getResult() == NOT_ATTEMPTED) {
                req.inputCommand.setResult(REJECTED_OTHER_REASON, "internal server error");
            }
        }
    } catch (IOException | PermissionBackendException err) {
        logger.atSevere().withCause(err).log("Cannot read repository before replacement for project %s", project.getName());
        for (ReplaceRequest req : replaceByChange.values()) {
            if (req.inputCommand.getResult() == NOT_ATTEMPTED) {
                req.inputCommand.setResult(REJECTED_OTHER_REASON, "internal server error");
            }
        }
    }
    logger.atFine().log("Read %d changes to replace", replaceByChange.size());
    if (magicBranch != null && magicBranch.cmd.getResult() != NOT_ATTEMPTED) {
        // Cancel creations tied to refs/for/ or refs/drafts/ command.
        for (ReplaceRequest req : replaceByChange.values()) {
            if (req.inputCommand == magicBranch.cmd && req.cmd != null) {
                req.cmd.setResult(Result.REJECTED_OTHER_REASON, "aborted");
            }
        }
        for (CreateRequest req : newChanges) {
            req.cmd.setResult(Result.REJECTED_OTHER_REASON, "aborted");
        }
    }
}
#end_block

#method_before
private boolean newEdit() {
    psId = notes.getChange().currentPatchSetId();
    Optional<ChangeEdit> edit = null;
    try {
        edit = editUtil.byChange(notes, user);
    } catch (AuthException | IOException e) {
        logError("Cannot retrieve edit", e);
        return false;
    }
    if (edit.isPresent()) {
        if (edit.get().getBasePatchSet().getId().equals(psId)) {
            // replace edit
            cmd = new ReceiveCommand(edit.get().getEditCommit(), newCommitId, edit.get().getRefName());
        } else {
            // delete old edit ref on rebase
            prev = new ReceiveCommand(edit.get().getEditCommit(), ObjectId.zeroId(), edit.get().getRefName());
            createEditCommand();
        }
    } else {
        createEditCommand();
    }
    return true;
}
#method_after
private boolean newEdit() {
    psId = notes.getChange().currentPatchSetId();
    Optional<ChangeEdit> edit = null;
    try {
        edit = editUtil.byChange(notes, user);
    } catch (AuthException | IOException e) {
        logger.atSevere().withCause(e).log("Cannot retrieve edit");
        return false;
    }
    if (edit.isPresent()) {
        if (edit.get().getBasePatchSet().getId().equals(psId)) {
            // replace edit
            cmd = new ReceiveCommand(edit.get().getEditCommit(), newCommitId, edit.get().getRefName());
        } else {
            // delete old edit ref on rebase
            prev = new ReceiveCommand(edit.get().getEditCommit(), ObjectId.zeroId(), edit.get().getRefName());
            createEditCommand();
        }
    } else {
        createEditCommand();
    }
    return true;
}
#end_block

#method_before
@Override
public void postUpdate(Context ctx) {
    String refName = cmd.getRefName();
    if (cmd.getType() == ReceiveCommand.Type.UPDATE) {
        // aka fast-forward
        logDebug("Updating tag cache on fast-forward of %s", cmd.getRefName());
        tagCache.updateFastForward(project.getNameKey(), refName, cmd.getOldId(), cmd.getNewId());
    }
    if (isConfig(cmd)) {
        logDebug("Reloading project in cache");
        try {
            projectCache.evict(project);
        } catch (IOException e) {
            logger.atWarning().withCause(e).log("Cannot evict from project cache, name key: %s", project.getName());
        }
        ProjectState ps = projectCache.get(project.getNameKey());
        try {
            logDebug("Updating project description");
            repo.setGitwebDescription(ps.getProject().getDescription());
        } catch (IOException e) {
            logger.atWarning().withCause(e).log("cannot update description of %s", project.getName());
        }
        if (allProjectsName.equals(project.getNameKey())) {
            try {
                createGroupPermissionSyncer.syncIfNeeded();
            } catch (IOException | ConfigInvalidException e) {
                logger.atSevere().withCause(e).log("Can't sync create group permissions");
            }
        }
    }
}
#method_after
@Override
public void postUpdate(Context ctx) {
    String refName = cmd.getRefName();
    if (cmd.getType() == ReceiveCommand.Type.UPDATE) {
        // aka fast-forward
        logger.atFine().log("Updating tag cache on fast-forward of %s", cmd.getRefName());
        tagCache.updateFastForward(project.getNameKey(), refName, cmd.getOldId(), cmd.getNewId());
    }
    if (isConfig(cmd)) {
        logger.atFine().log("Reloading project in cache");
        try {
            projectCache.evict(project);
        } catch (IOException e) {
            logger.atWarning().withCause(e).log("Cannot evict from project cache, name key: %s", project.getName());
        }
        ProjectState ps = projectCache.get(project.getNameKey());
        try {
            logger.atFine().log("Updating project description");
            repo.setGitwebDescription(ps.getProject().getDescription());
        } catch (IOException e) {
            logger.atWarning().withCause(e).log("cannot update description of %s", project.getName());
        }
        if (allProjectsName.equals(project.getNameKey())) {
            try {
                createGroupPermissionSyncer.syncIfNeeded();
            } catch (IOException | ConfigInvalidException e) {
                logger.atSevere().withCause(e).log("Can't sync create group permissions");
            }
        }
    }
}
#end_block

#method_before
private void validateNewCommits(Branch.NameKey branch, ReceiveCommand cmd) throws PermissionBackendException {
    PermissionBackend.ForRef perm = permissions.ref(branch.get());
    if (!RefNames.REFS_CONFIG.equals(cmd.getRefName()) && !(MagicBranch.isMagicBranch(cmd.getRefName()) || NEW_PATCHSET_PATTERN.matcher(cmd.getRefName()).matches()) && pushOptions.containsKey(PUSH_OPTION_SKIP_VALIDATION)) {
        if (projectState.is(BooleanProjectConfig.USE_SIGNED_OFF_BY)) {
            reject(cmd, "requireSignedOffBy prevents option " + PUSH_OPTION_SKIP_VALIDATION);
            return;
        }
        Optional<AuthException> err = checkRefPermission(permissions.ref(branch.get()), RefPermission.SKIP_VALIDATION);
        if (err.isPresent()) {
            rejectProhibited(cmd, err.get());
            return;
        }
        if (!Iterables.isEmpty(rejectCommits)) {
            reject(cmd, "reject-commits prevents " + PUSH_OPTION_SKIP_VALIDATION);
            return;
        }
        logDebug("Short-circuiting new commit validation");
        return;
    }
    boolean missingFullName = Strings.isNullOrEmpty(user.getAccount().getFullName());
    RevWalk walk = receivePack.getRevWalk();
    walk.reset();
    walk.sort(RevSort.NONE);
    try {
        RevObject parsedObject = walk.parseAny(cmd.getNewId());
        if (!(parsedObject instanceof RevCommit)) {
            return;
        }
        ListMultimap<ObjectId, Ref> existing = changeRefsById();
        walk.markStart((RevCommit) parsedObject);
        markHeadsAsUninteresting(walk, cmd.getRefName());
        int limit = receiveConfig.maxBatchCommits;
        int n = 0;
        for (RevCommit c; (c = walk.next()) != null; ) {
            if (++n > limit) {
                logDebug("Number of new commits exceeds limit of %d", limit);
                reject(cmd, String.format("more than %d commits, and %s not set", limit, PUSH_OPTION_SKIP_VALIDATION));
                return;
            }
            if (existing.keySet().contains(c)) {
                continue;
            } else if (!validCommit(walk, branch, cmd, c, null)) {
                break;
            }
            if (missingFullName && user.hasEmailAddress(c.getCommitterIdent().getEmailAddress())) {
                logDebug("Will update full name of caller");
                setFullNameTo = c.getCommitterIdent().getName();
                missingFullName = false;
            }
        }
        logDebug("Validated %d new commits", n);
    } catch (IOException err) {
        cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", err);
    }
}
#method_after
private void validateNewCommits(Branch.NameKey branch, ReceiveCommand cmd) throws PermissionBackendException {
    PermissionBackend.ForRef perm = permissions.ref(branch.get());
    if (!RefNames.REFS_CONFIG.equals(cmd.getRefName()) && !(MagicBranch.isMagicBranch(cmd.getRefName()) || NEW_PATCHSET_PATTERN.matcher(cmd.getRefName()).matches()) && pushOptions.containsKey(PUSH_OPTION_SKIP_VALIDATION)) {
        if (projectState.is(BooleanProjectConfig.USE_SIGNED_OFF_BY)) {
            reject(cmd, "requireSignedOffBy prevents option " + PUSH_OPTION_SKIP_VALIDATION);
            return;
        }
        Optional<AuthException> err = checkRefPermission(permissions.ref(branch.get()), RefPermission.SKIP_VALIDATION);
        if (err.isPresent()) {
            rejectProhibited(cmd, err.get());
            return;
        }
        if (!Iterables.isEmpty(rejectCommits)) {
            reject(cmd, "reject-commits prevents " + PUSH_OPTION_SKIP_VALIDATION);
        }
        logger.atFine().log("Short-circuiting new commit validation");
        return;
    }
    boolean missingFullName = Strings.isNullOrEmpty(user.getAccount().getFullName());
    RevWalk walk = receivePack.getRevWalk();
    walk.reset();
    walk.sort(RevSort.NONE);
    try {
        RevObject parsedObject = walk.parseAny(cmd.getNewId());
        if (!(parsedObject instanceof RevCommit)) {
            return;
        }
        ListMultimap<ObjectId, Ref> existing = changeRefsById();
        walk.markStart((RevCommit) parsedObject);
        markHeadsAsUninteresting(walk, cmd.getRefName());
        int limit = receiveConfig.maxBatchCommits;
        int n = 0;
        for (RevCommit c; (c = walk.next()) != null; ) {
            if (++n > limit) {
                logger.atFine().log("Number of new commits exceeds limit of %d", limit);
                reject(cmd, String.format("more than %d commits, and %s not set", limit, PUSH_OPTION_SKIP_VALIDATION));
                return;
            }
            if (existing.keySet().contains(c)) {
                continue;
            } else if (!validCommit(walk, branch, cmd, c, null)) {
                break;
            }
            if (missingFullName && user.hasEmailAddress(c.getCommitterIdent().getEmailAddress())) {
                logger.atFine().log("Will update full name of caller");
                setFullNameTo = c.getCommitterIdent().getName();
                missingFullName = false;
            }
        }
        logger.atFine().log("Validated %d new commits", n);
    } catch (IOException err) {
        cmd.setResult(REJECTED_MISSING_OBJECT);
        logger.atSevere().withCause(err).log("Invalid pack upload; one or more objects weren't sent");
    }
}
#end_block

#method_before
private boolean validCommit(RevWalk rw, Branch.NameKey branch, ReceiveCommand cmd, ObjectId id, @Nullable Change change) throws IOException {
    PermissionBackend.ForRef perm = permissions.ref(branch.get());
    ValidCommitKey key = new AutoValue_ReceiveCommits_ValidCommitKey(id.copy(), branch);
    if (validCommits.contains(key)) {
        return true;
    }
    RevCommit c = rw.parseCommit(id);
    rw.parseBody(c);
    try (CommitReceivedEvent receiveEvent = new CommitReceivedEvent(cmd, project, branch.get(), rw.getObjectReader(), c, user)) {
        boolean isMerged = magicBranch != null && cmd.getRefName().equals(magicBranch.cmd.getRefName()) && magicBranch.merged;
        CommitValidators validators = isMerged ? commitValidatorsFactory.forMergedCommits(project.getNameKey(), perm, user.asIdentifiedUser()) : commitValidatorsFactory.forReceiveCommits(perm, branch, user.asIdentifiedUser(), sshInfo, repo, rw, change);
        messages.addAll(validators.validate(receiveEvent));
    } catch (CommitValidationException e) {
        logDebug("Commit validation failed on %s", c.name());
        messages.addAll(e.getMessages());
        reject(cmd, e.getMessage());
        return false;
    }
    validCommits.add(key);
    return true;
}
#method_after
private boolean validCommit(RevWalk rw, Branch.NameKey branch, ReceiveCommand cmd, ObjectId id, @Nullable Change change) throws IOException {
    PermissionBackend.ForRef perm = permissions.ref(branch.get());
    ValidCommitKey key = new AutoValue_ReceiveCommits_ValidCommitKey(id.copy(), branch);
    if (validCommits.contains(key)) {
        return true;
    }
    RevCommit c = rw.parseCommit(id);
    rw.parseBody(c);
    try (CommitReceivedEvent receiveEvent = new CommitReceivedEvent(cmd, project, branch.get(), rw.getObjectReader(), c, user)) {
        boolean isMerged = magicBranch != null && cmd.getRefName().equals(magicBranch.cmd.getRefName()) && magicBranch.merged;
        CommitValidators validators = isMerged ? commitValidatorsFactory.forMergedCommits(project.getNameKey(), perm, user.asIdentifiedUser()) : commitValidatorsFactory.forReceiveCommits(perm, branch, user.asIdentifiedUser(), sshInfo, repo, rw, change);
        messages.addAll(validators.validate(receiveEvent));
    } catch (CommitValidationException e) {
        logger.atFine().log("Commit validation failed on %s", c.name());
        messages.addAll(e.getMessages());
        reject(cmd, e.getMessage());
        return false;
    }
    validCommits.add(key);
    return true;
}
#end_block

#method_before
private void autoCloseChanges(ReceiveCommand cmd) {
    logDebug("Starting auto-closing of changes");
    String refName = cmd.getRefName();
    checkState(!MagicBranch.isMagicBranch(refName), "shouldn't be auto-closing changes on magic branch %s", refName);
    // insertChangesAndPatchSets.
    try {
        retryHelper.execute(updateFactory -> {
            try (BatchUpdate bu = updateFactory.create(db, projectState.getNameKey(), user, TimeUtil.nowTs());
                ObjectInserter ins = repo.newObjectInserter();
                ObjectReader reader = ins.newReader();
                RevWalk rw = new RevWalk(reader)) {
                bu.setRepository(repo, rw, ins).updateChangesInParallel();
                bu.setRequestId(receiveId);
                // TODO(dborowitz): Teach BatchUpdate to ignore missing changes.
                RevCommit newTip = rw.parseCommit(cmd.getNewId());
                Branch.NameKey branch = new Branch.NameKey(project.getNameKey(), refName);
                rw.reset();
                rw.markStart(newTip);
                if (!ObjectId.zeroId().equals(cmd.getOldId())) {
                    rw.markUninteresting(rw.parseCommit(cmd.getOldId()));
                }
                ListMultimap<ObjectId, Ref> byCommit = changeRefsById();
                Map<Change.Key, ChangeNotes> byKey = null;
                List<ReplaceRequest> replaceAndClose = new ArrayList<>();
                int existingPatchSets = 0;
                int newPatchSets = 0;
                COMMIT: for (RevCommit c; (c = rw.next()) != null; ) {
                    rw.parseBody(c);
                    for (Ref ref : byCommit.get(c.copy())) {
                        PatchSet.Id psId = PatchSet.Id.fromRef(ref.getName());
                        Optional<ChangeNotes> notes = getChangeNotes(psId.getParentKey());
                        if (notes.isPresent() && notes.get().getChange().getDest().equals(branch)) {
                            existingPatchSets++;
                            bu.addOp(psId.getParentKey(), mergedByPushOpFactory.create(requestScopePropagator, psId, refName));
                            continue COMMIT;
                        }
                    }
                    for (String changeId : c.getFooterLines(CHANGE_ID)) {
                        if (byKey == null) {
                            byKey = executeIndexQuery(() -> openChangesByKeyByBranch(branch));
                        }
                        ChangeNotes onto = byKey.get(new Change.Key(changeId.trim()));
                        if (onto != null) {
                            newPatchSets++;
                            // Hold onto this until we're done with the walk, as the call to
                            // req.validate below calls isMergedInto which resets the walk.
                            ReplaceRequest req = new ReplaceRequest(onto.getChangeId(), c, cmd, false);
                            req.notes = onto;
                            replaceAndClose.add(req);
                            continue COMMIT;
                        }
                    }
                }
                for (ReplaceRequest req : replaceAndClose) {
                    Change.Id id = req.notes.getChangeId();
                    if (!req.validate(true)) {
                        logDebug("Not closing %s because validation failed", id);
                        continue;
                    }
                    req.addOps(bu, null);
                    bu.addOp(id, mergedByPushOpFactory.create(requestScopePropagator, req.psId, refName).setPatchSetProvider(req.replaceOp::getPatchSet));
                    bu.addOp(id, new ChangeProgressOp(closeProgress));
                }
                logDebug("Auto-closing %s changes with existing patch sets and %s with new patch sets", existingPatchSets, newPatchSets);
                bu.execute();
            } catch (IOException | OrmException | PermissionBackendException e) {
                logError("Failed to auto-close changes", e);
            }
            return null;
        }, // eat up the whole timeout so that no time is left to retry this outer action.
        RetryHelper.options().timeout(retryHelper.getDefaultTimeout(ActionType.CHANGE_UPDATE).multipliedBy(5)).build());
    } catch (RestApiException e) {
        logError("Can't insert patchset", e);
    } catch (UpdateException e) {
        logError("Failed to auto-close changes", e);
    }
}
#method_after
private void autoCloseChanges(ReceiveCommand cmd) {
    logger.atFine().log("Starting auto-closing of changes");
    String refName = cmd.getRefName();
    checkState(!MagicBranch.isMagicBranch(refName), "shouldn't be auto-closing changes on magic branch %s", refName);
    // insertChangesAndPatchSets.
    try {
        retryHelper.execute(updateFactory -> {
            try (BatchUpdate bu = updateFactory.create(db, projectState.getNameKey(), user, TimeUtil.nowTs());
                ObjectInserter ins = repo.newObjectInserter();
                ObjectReader reader = ins.newReader();
                RevWalk rw = new RevWalk(reader)) {
                bu.setRepository(repo, rw, ins).updateChangesInParallel();
                // TODO(dborowitz): Teach BatchUpdate to ignore missing changes.
                RevCommit newTip = rw.parseCommit(cmd.getNewId());
                Branch.NameKey branch = new Branch.NameKey(project.getNameKey(), refName);
                rw.reset();
                rw.markStart(newTip);
                if (!ObjectId.zeroId().equals(cmd.getOldId())) {
                    rw.markUninteresting(rw.parseCommit(cmd.getOldId()));
                }
                ListMultimap<ObjectId, Ref> byCommit = changeRefsById();
                Map<Change.Key, ChangeNotes> byKey = null;
                List<ReplaceRequest> replaceAndClose = new ArrayList<>();
                int existingPatchSets = 0;
                int newPatchSets = 0;
                COMMIT: for (RevCommit c; (c = rw.next()) != null; ) {
                    rw.parseBody(c);
                    for (Ref ref : byCommit.get(c.copy())) {
                        PatchSet.Id psId = PatchSet.Id.fromRef(ref.getName());
                        Optional<ChangeNotes> notes = getChangeNotes(psId.getParentKey());
                        if (notes.isPresent() && notes.get().getChange().getDest().equals(branch)) {
                            existingPatchSets++;
                            bu.addOp(psId.getParentKey(), mergedByPushOpFactory.create(requestScopePropagator, psId, refName));
                            continue COMMIT;
                        }
                    }
                    for (String changeId : c.getFooterLines(CHANGE_ID)) {
                        if (byKey == null) {
                            byKey = executeIndexQuery(() -> openChangesByKeyByBranch(branch));
                        }
                        ChangeNotes onto = byKey.get(new Change.Key(changeId.trim()));
                        if (onto != null) {
                            newPatchSets++;
                            // Hold onto this until we're done with the walk, as the call to
                            // req.validate below calls isMergedInto which resets the walk.
                            ReplaceRequest req = new ReplaceRequest(onto.getChangeId(), c, cmd, false);
                            req.notes = onto;
                            replaceAndClose.add(req);
                            continue COMMIT;
                        }
                    }
                }
                for (ReplaceRequest req : replaceAndClose) {
                    Change.Id id = req.notes.getChangeId();
                    if (!req.validate(true)) {
                        logger.atFine().log("Not closing %s because validation failed", id);
                        continue;
                    }
                    req.addOps(bu, null);
                    bu.addOp(id, mergedByPushOpFactory.create(requestScopePropagator, req.psId, refName).setPatchSetProvider(req.replaceOp::getPatchSet));
                    bu.addOp(id, new ChangeProgressOp(closeProgress));
                }
                logger.atFine().log("Auto-closing %s changes with existing patch sets and %s with new patch sets", existingPatchSets, newPatchSets);
                bu.execute();
            } catch (IOException | OrmException | PermissionBackendException e) {
                logger.atSevere().withCause(e).log("Failed to auto-close changes");
            }
            return null;
        }, // eat up the whole timeout so that no time is left to retry this outer action.
        RetryHelper.options().timeout(retryHelper.getDefaultTimeout(ActionType.CHANGE_UPDATE).multipliedBy(5)).build());
    } catch (RestApiException e) {
        logger.atSevere().withCause(e).log("Can't insert patchset");
    } catch (UpdateException e) {
        logger.atSevere().withCause(e).log("Failed to auto-close changes");
    }
}
#end_block

#method_before
private void updateAccountInfo() {
    if (setFullNameTo == null) {
        return;
    }
    logDebug("Updating full name of caller");
    try {
        Optional<AccountState> accountState = accountsUpdateProvider.get().update("Set Full Name on Receive Commits", user.getAccountId(), (a, u) -> {
            if (Strings.isNullOrEmpty(a.getAccount().getFullName())) {
                u.setFullName(setFullNameTo);
            }
        });
        accountState.map(AccountState::getAccount).ifPresent(a -> user.getAccount().setFullName(a.getFullName()));
    } catch (OrmException | IOException | ConfigInvalidException e) {
        logWarn("Failed to update full name of caller", e);
    }
}
#method_after
private void updateAccountInfo() {
    if (setFullNameTo == null) {
        return;
    }
    logger.atFine().log("Updating full name of caller");
    try {
        Optional<AccountState> accountState = accountsUpdateProvider.get().update("Set Full Name on Receive Commits", user.getAccountId(), (a, u) -> {
            if (Strings.isNullOrEmpty(a.getAccount().getFullName())) {
                u.setFullName(setFullNameTo);
            }
        });
        accountState.map(AccountState::getAccount).ifPresent(a -> user.getAccount().setFullName(a.getFullName()));
    } catch (OrmException | IOException | ConfigInvalidException e) {
        logger.atWarning().withCause(e).log("Failed to update full name of caller");
    }
}
#end_block

#method_before
void processCommands(Collection<ReceiveCommand> commands, MultiProgressMonitor progress) {
    newProgress = progress.beginSubTask("new", UNKNOWN);
    replaceProgress = progress.beginSubTask("updated", UNKNOWN);
    closeProgress = progress.beginSubTask("closed", UNKNOWN);
    commandProgress = progress.beginSubTask("refs", UNKNOWN);
    if (!projectState.getProject().getState().permitsWrite()) {
        for (ReceiveCommand cmd : commands) {
            reject(cmd, "prohibited by Gerrit: project state does not permit write");
        }
        return;
    }
    try {
        parsePushOptions();
        logDebug("Parsing %d commands", commands.size());
        List<ReceiveCommand> magicCommands = commands.stream().filter(c -> MagicBranch.isMagicBranch(c.getRefName())).collect(toList());
        List<ReceiveCommand> directChangePushCommands = commands.stream().filter(c -> isDirectChangesPush(c)).collect(toList());
        commands = commands.stream().filter(c -> !MagicBranch.isMagicBranch(c.getRefName()) && !isDirectChangesPush(c)).collect(toList());
        for (ReceiveCommand cmd : commands) {
            parseNonMagicCommand(cmd);
        }
        for (ReceiveCommand cmd : directChangePushCommands) {
            parseDirectChangesPush(cmd);
        }
        // Process the magicCommand last so we are sure magicBranch settings don't affect
        // the non-magic commands.
        boolean first = true;
        for (ReceiveCommand cmd : magicCommands) {
            if (first) {
                parseMagicBranch(cmd);
                first = false;
            } else {
                reject(cmd, "duplicate request");
            }
        }
    } catch (PermissionBackendException | NoSuchProjectException | IOException err) {
        for (ReceiveCommand cmd : actualCommands) {
            if (cmd.getResult() == NOT_ATTEMPTED) {
                cmd.setResult(REJECTED_OTHER_REASON, "internal server error");
            }
        }
        logError(String.format("Failed to process refs in %s", project.getName()), err);
    }
    List<CreateRequest> newChanges = Collections.emptyList();
    if (magicBranch != null && magicBranch.cmd.getResult() == NOT_ATTEMPTED) {
        newChanges = selectNewAndReplacedChangesFromMagicBranch();
    }
    preparePatchSetsForReplace(newChanges);
    insertChangesAndPatchSets(newChanges);
    newProgress.end();
    replaceProgress.end();
    if (!errors.isEmpty()) {
        logDebug("Handling error conditions: %s", errors.keySet());
        for (String error : errors.keySet()) {
            receivePack.sendMessage(buildError(error, errors.get(error)));
        }
        receivePack.sendMessage(String.format("User: %s", user.getLoggableName()));
        receivePack.sendMessage(COMMAND_REJECTION_MESSAGE_FOOTER);
    }
    Set<Branch.NameKey> branches = new HashSet<>();
    for (ReceiveCommand c : actualCommands) {
        // involve kicking off an additional BatchUpdate.
        if (c.getResult() != OK) {
            continue;
        }
        if (isHead(c) || isConfig(c)) {
            switch(c.getType()) {
                case CREATE:
                case UPDATE:
                case UPDATE_NONFASTFORWARD:
                    autoCloseChanges(c);
                    branches.add(new Branch.NameKey(project.getNameKey(), c.getRefName()));
                    break;
                case DELETE:
                    break;
            }
        }
    }
    // Update superproject gitlinks if required.
    if (!branches.isEmpty()) {
        try (MergeOpRepoManager orm = ormProvider.get()) {
            orm.setContext(db, TimeUtil.nowTs(), user, receiveId);
            SubmoduleOp op = subOpFactory.create(branches, orm);
            op.updateSuperProjects();
        } catch (SubmoduleException e) {
            logError("Can't update the superprojects", e);
        }
    }
    // Update account info with details discovered during commit walking.
    updateAccountInfo();
    closeProgress.end();
    commandProgress.end();
    progress.end();
    reportMessages(newChanges);
}
#method_after
void processCommands(Collection<ReceiveCommand> commands, MultiProgressMonitor progress) {
    newProgress = progress.beginSubTask("new", UNKNOWN);
    replaceProgress = progress.beginSubTask("updated", UNKNOWN);
    closeProgress = progress.beginSubTask("closed", UNKNOWN);
    commandProgress = progress.beginSubTask("refs", UNKNOWN);
    try (TraceContext traceContext = new TraceContext(RequestId.Type.RECEIVE_ID, RequestId.forProject(project.getNameKey()))) {
        try {
            if (!projectState.getProject().getState().permitsWrite()) {
                for (ReceiveCommand cmd : commands) {
                    reject(cmd, "prohibited by Gerrit: project state does not permit write");
                }
                return;
            }
            parsePushOptions();
            logger.atFine().log("Parsing %d commands", commands.size());
            List<ReceiveCommand> magicCommands = new ArrayList<>();
            List<ReceiveCommand> directPatchSetPushCommands = new ArrayList<>();
            List<ReceiveCommand> regularCommands = new ArrayList<>();
            for (ReceiveCommand cmd : commands) {
                if (MagicBranch.isMagicBranch(cmd.getRefName())) {
                    magicCommands.add(cmd);
                } else if (isDirectChangesPush(cmd.getRefName())) {
                    directPatchSetPushCommands.add(cmd);
                } else {
                    regularCommands.add(cmd);
                }
            }
            for (ReceiveCommand cmd : regularCommands) {
                parseRegularCommand(cmd);
            }
            for (ReceiveCommand cmd : directPatchSetPushCommands) {
                parseDirectChangesPush(cmd);
            }
            // Process the magicCommand last, so magicBranch settings can't interact with regular
            // commands.
            boolean first = true;
            for (ReceiveCommand cmd : magicCommands) {
                if (first) {
                    parseMagicBranch(cmd);
                    first = false;
                } else {
                    reject(cmd, "duplicate request");
                }
            }
        } catch (PermissionBackendException | NoSuchProjectException | IOException err) {
            for (ReceiveCommand cmd : actualCommands) {
                if (cmd.getResult() == NOT_ATTEMPTED) {
                    cmd.setResult(REJECTED_OTHER_REASON, "internal server error");
                }
                logger.atSevere().withCause(err).log("Failed to process refs in %s", project.getName());
            }
            return;
        }
        List<CreateRequest> newChanges = Collections.emptyList();
        if (magicBranch != null && magicBranch.cmd.getResult() == NOT_ATTEMPTED) {
            newChanges = selectNewAndReplacedChangesFromMagicBranch();
        }
        preparePatchSetsForReplace(newChanges);
        insertChangesAndPatchSets(newChanges);
        newProgress.end();
        replaceProgress.end();
        if (!errors.isEmpty()) {
            logger.atFine().log("Handling error conditions: %s", errors.keySet());
            for (String error : errors.keySet()) {
                receivePack.sendMessage(buildError(error, errors.get(error)));
            }
            receivePack.sendMessage(String.format("User: %s", user.getLoggableName()));
            receivePack.sendMessage(COMMAND_REJECTION_MESSAGE_FOOTER);
        }
        Set<Branch.NameKey> branches = new HashSet<>();
        for (ReceiveCommand c : actualCommands) {
            // they involve kicking off an additional BatchUpdate.
            if (c.getResult() != OK) {
                continue;
            }
            if (isHead(c) || isConfig(c)) {
                switch(c.getType()) {
                    case CREATE:
                    case UPDATE:
                    case UPDATE_NONFASTFORWARD:
                        autoCloseChanges(c);
                        branches.add(new Branch.NameKey(project.getNameKey(), c.getRefName()));
                        break;
                    case DELETE:
                        break;
                }
            }
        }
        // Update superproject gitlinks if required.
        if (!branches.isEmpty()) {
            try (MergeOpRepoManager orm = ormProvider.get()) {
                orm.setContext(db, TimeUtil.nowTs(), user);
                SubmoduleOp op = subOpFactory.create(branches, orm);
                op.updateSuperProjects();
            } catch (SubmoduleException e) {
                logger.atSevere().withCause(e).log("Can't update the superprojects");
            }
        }
        // Update account info with details discovered during commit walking.
        updateAccountInfo();
        closeProgress.end();
        commandProgress.end();
        progress.end();
        reportMessages(newChanges);
    }
}
#end_block

#method_before
private void reportMessages(List<CreateRequest> newChanges) {
    List<CreateRequest> created = newChanges.stream().filter(r -> r.change != null).collect(toList());
    if (!created.isEmpty()) {
        addMessage("");
        addMessage("New Changes:");
        for (CreateRequest c : created) {
            addMessage(changeFormatter.newChange(ChangeReportFormatter.Input.builder().setChange(c.change).build()));
        }
        addMessage("");
    }
    List<ReplaceRequest> updated = replaceByChange.values().stream().filter(r -> r.inputCommand.getResult() == OK).sorted(comparingInt(r -> r.notes.getChangeId().get())).collect(toList());
    if (!updated.isEmpty()) {
        addMessage("");
        addMessage("Updated Changes:");
        boolean edit = magicBranch != null && (magicBranch.edit || magicBranch.draft);
        Boolean isPrivate = null;
        Boolean wip = null;
        if (magicBranch != null) {
            if (magicBranch.isPrivate) {
                isPrivate = true;
            } else if (magicBranch.removePrivate) {
                isPrivate = false;
            }
            if (magicBranch.workInProgress) {
                wip = true;
            } else if (magicBranch.ready) {
                wip = false;
            }
        }
        for (ReplaceRequest u : updated) {
            String subject;
            if (edit) {
                try {
                    subject = receivePack.getRevWalk().parseCommit(u.newCommitId).getShortMessage();
                } catch (IOException e) {
                    // Log and fall back to original change subject
                    logWarn("failed to get subject for edit patch set", e);
                    subject = u.notes.getChange().getSubject();
                }
            } else {
                subject = u.info.getSubject();
            }
            if (isPrivate == null) {
                isPrivate = u.notes.getChange().isPrivate();
            }
            if (wip == null) {
                wip = u.notes.getChange().isWorkInProgress();
            }
            ChangeReportFormatter.Input input = ChangeReportFormatter.Input.builder().setChange(u.notes.getChange()).setSubject(subject).setIsEdit(edit).setIsPrivate(isPrivate).setIsWorkInProgress(wip).build();
            addMessage(changeFormatter.changeUpdated(input));
        }
        addMessage("");
    }
}
#method_after
private void reportMessages(List<CreateRequest> newChanges) {
    List<CreateRequest> created = newChanges.stream().filter(r -> r.change != null).collect(toList());
    if (!created.isEmpty()) {
        addMessage("");
        addMessage("New Changes:");
        for (CreateRequest c : created) {
            addMessage(changeFormatter.newChange(ChangeReportFormatter.Input.builder().setChange(c.change).build()));
        }
        addMessage("");
    }
    List<ReplaceRequest> updated = replaceByChange.values().stream().filter(r -> r.inputCommand.getResult() == OK).sorted(comparingInt(r -> r.notes.getChangeId().get())).collect(toList());
    if (!updated.isEmpty()) {
        addMessage("");
        addMessage("Updated Changes:");
        boolean edit = magicBranch != null && (magicBranch.edit || magicBranch.draft);
        Boolean isPrivate = null;
        Boolean wip = null;
        if (magicBranch != null) {
            if (magicBranch.isPrivate) {
                isPrivate = true;
            } else if (magicBranch.removePrivate) {
                isPrivate = false;
            }
            if (magicBranch.workInProgress) {
                wip = true;
            } else if (magicBranch.ready) {
                wip = false;
            }
        }
        for (ReplaceRequest u : updated) {
            String subject;
            if (edit) {
                try {
                    subject = receivePack.getRevWalk().parseCommit(u.newCommitId).getShortMessage();
                } catch (IOException e) {
                    // Log and fall back to original change subject
                    logger.atWarning().withCause(e).log("failed to get subject for edit patch set");
                    subject = u.notes.getChange().getSubject();
                }
            } else {
                subject = u.info.getSubject();
            }
            if (isPrivate == null) {
                isPrivate = u.notes.getChange().isPrivate();
            }
            if (wip == null) {
                wip = u.notes.getChange().isWorkInProgress();
            }
            ChangeReportFormatter.Input input = ChangeReportFormatter.Input.builder().setChange(u.notes.getChange()).setSubject(subject).setIsEdit(edit).setIsPrivate(isPrivate).setIsWorkInProgress(wip).build();
            addMessage(changeFormatter.changeUpdated(input));
        }
        addMessage("");
    }
    // TODO(xchangcheng): remove after migrating tools which are using this magic branch.
    if (magicBranch != null && magicBranch.publish) {
        addMessage("Pushing to refs/publish/* is deprecated, use refs/for/* instead.");
    }
}
#end_block

#method_before
private void insertChangesAndPatchSets(List<CreateRequest> newChanges) {
    ReceiveCommand magicBranchCmd = magicBranch != null ? magicBranch.cmd : null;
    if (magicBranchCmd != null && magicBranchCmd.getResult() != NOT_ATTEMPTED) {
        logWarn(String.format("Skipping change updates on %s because ref update failed: %s %s", project.getName(), magicBranchCmd.getResult(), Strings.nullToEmpty(magicBranchCmd.getMessage())));
        return;
    }
    try (BatchUpdate bu = batchUpdateFactory.create(db, project.getNameKey(), user.materializedCopy(), TimeUtil.nowTs());
        ObjectInserter ins = repo.newObjectInserter();
        ObjectReader reader = ins.newReader();
        RevWalk rw = new RevWalk(reader)) {
        bu.setRepository(repo, rw, ins).updateChangesInParallel();
        bu.setRequestId(receiveId);
        bu.setRefLogMessage("push");
        logDebug("Adding %d replace requests", newChanges.size());
        for (ReplaceRequest replace : replaceByChange.values()) {
            replace.addOps(bu, replaceProgress);
        }
        logDebug("Adding %d create requests", newChanges.size());
        for (CreateRequest create : newChanges) {
            create.addOps(bu);
        }
        logDebug("Adding %d group update requests", newChanges.size());
        updateGroups.forEach(r -> r.addOps(bu));
        logDebug("Adding %d additional ref updates", actualCommands.size());
        actualCommands.forEach(c -> bu.addRepoOnlyOp(new UpdateOneRefOp(c)));
        logDebug("Executing batch");
        try {
            bu.execute();
        } catch (UpdateException e) {
            throw INSERT_EXCEPTION.apply(e);
        }
        if (magicBranchCmd != null) {
            magicBranchCmd.setResult(OK);
        }
        for (ReplaceRequest replace : replaceByChange.values()) {
            String rejectMessage = replace.getRejectMessage();
            if (rejectMessage == null) {
                if (replace.inputCommand.getResult() == NOT_ATTEMPTED) {
                    // Not necessarily the magic branch, so need to set OK on the original value.
                    replace.inputCommand.setResult(OK);
                }
            } else {
                logDebug("Rejecting due to message from ReplaceOp");
                reject(replace.inputCommand, rejectMessage);
            }
        }
    } catch (ResourceConflictException e) {
        addMessage(e.getMessage());
        reject(magicBranchCmd, "conflict");
    } catch (RestApiException | IOException err) {
        logError("Can't insert change/patch set for " + project.getName(), err);
        reject(magicBranchCmd, "internal server error: " + err.getMessage());
    }
    if (magicBranch != null && magicBranch.submit) {
        try {
            submit(newChanges, replaceByChange.values());
        } catch (ResourceConflictException e) {
            addMessage(e.getMessage());
            reject(magicBranchCmd, "conflict");
        } catch (RestApiException | OrmException | UpdateException | IOException | ConfigInvalidException | PermissionBackendException e) {
            logError("Error submitting changes to " + project.getName(), e);
            reject(magicBranchCmd, "error during submit");
        }
    }
}
#method_after
private void insertChangesAndPatchSets(List<CreateRequest> newChanges) {
    ReceiveCommand magicBranchCmd = magicBranch != null ? magicBranch.cmd : null;
    if (magicBranchCmd != null && magicBranchCmd.getResult() != NOT_ATTEMPTED) {
        logger.atWarning().log("Skipping change updates on %s because ref update failed: %s %s", project.getName(), magicBranchCmd.getResult(), Strings.nullToEmpty(magicBranchCmd.getMessage()));
        return;
    }
    try (BatchUpdate bu = batchUpdateFactory.create(db, project.getNameKey(), user.materializedCopy(), TimeUtil.nowTs());
        ObjectInserter ins = repo.newObjectInserter();
        ObjectReader reader = ins.newReader();
        RevWalk rw = new RevWalk(reader)) {
        bu.setRepository(repo, rw, ins).updateChangesInParallel();
        bu.setRefLogMessage("push");
        logger.atFine().log("Adding %d replace requests", newChanges.size());
        for (ReplaceRequest replace : replaceByChange.values()) {
            replace.addOps(bu, replaceProgress);
        }
        logger.atFine().log("Adding %d create requests", newChanges.size());
        for (CreateRequest create : newChanges) {
            create.addOps(bu);
        }
        logger.atFine().log("Adding %d group update requests", newChanges.size());
        updateGroups.forEach(r -> r.addOps(bu));
        logger.atFine().log("Adding %d additional ref updates", actualCommands.size());
        actualCommands.forEach(c -> bu.addRepoOnlyOp(new UpdateOneRefOp(c)));
        logger.atFine().log("Executing batch");
        try {
            bu.execute();
        } catch (UpdateException e) {
            throw INSERT_EXCEPTION.apply(e);
        }
        if (magicBranchCmd != null) {
            magicBranchCmd.setResult(OK);
        }
        for (ReplaceRequest replace : replaceByChange.values()) {
            String rejectMessage = replace.getRejectMessage();
            if (rejectMessage == null) {
                if (replace.inputCommand.getResult() == NOT_ATTEMPTED) {
                    // Not necessarily the magic branch, so need to set OK on the original value.
                    replace.inputCommand.setResult(OK);
                }
            } else {
                logger.atFine().log("Rejecting due to message from ReplaceOp");
                reject(replace.inputCommand, rejectMessage);
            }
        }
    } catch (ResourceConflictException e) {
        addMessage(e.getMessage());
        reject(magicBranchCmd, "conflict");
    } catch (RestApiException | IOException err) {
        logger.atSevere().withCause(err).log("Can't insert change/patch set for %s", project.getName());
        reject(magicBranchCmd, "internal server error: " + err.getMessage());
    }
    if (magicBranch != null && magicBranch.submit) {
        try {
            submit(newChanges, replaceByChange.values());
        } catch (ResourceConflictException e) {
            addMessage(e.getMessage());
            reject(magicBranchCmd, "conflict");
        } catch (RestApiException | OrmException | UpdateException | IOException | ConfigInvalidException | PermissionBackendException e) {
            logger.atSevere().withCause(e).log("Error submitting changes to %s", project.getName());
            reject(magicBranchCmd, "error during submit");
        }
    }
}
#end_block

#method_before
private static boolean isDirectChangesPush(ReceiveCommand cmd) {
    Matcher m = NEW_PATCHSET_PATTERN.matcher(cmd.getRefName());
    return m.matches();
}
#method_after
private static boolean isDirectChangesPush(String refname) {
    Matcher m = NEW_PATCHSET_PATTERN.matcher(refname);
    return m.matches();
}
#end_block

#method_before
private void parseCreate(ReceiveCommand cmd) throws PermissionBackendException, NoSuchProjectException, IOException {
    RevObject obj;
    try {
        obj = receivePack.getRevWalk().parseAny(cmd.getNewId());
    } catch (IOException err) {
        logError("Invalid object " + cmd.getNewId().name() + " for " + cmd.getRefName() + " creation", err);
        reject(cmd, "invalid object");
        return;
    }
    logDebug("Creating %s", cmd);
    if (isHead(cmd) && !isCommit(cmd)) {
        return;
    }
    Branch.NameKey branch = new Branch.NameKey(project.getName(), cmd.getRefName());
    try {
        // Must pass explicit user instead of injecting a provider into CreateRefControl, since
        // Provider<CurrentUser> within ReceiveCommits will always return anonymous.
        createRefControl.checkCreateRef(Providers.of(user), receivePack.getRepository(), branch, obj);
    } catch (AuthException denied) {
        rejectProhibited(cmd, denied);
        return;
    } catch (ResourceConflictException denied) {
        reject(cmd, "prohibited by Gerrit: " + denied.getMessage());
        return;
    }
    if (!validRefOperation(cmd)) {
        // validRefOperation sets messages, so no need to provide more feedback.
        return;
    }
    validateNewCommits(new Branch.NameKey(project.getNameKey(), cmd.getRefName()), cmd);
    actualCommands.add(cmd);
}
#method_after
private void parseCreate(ReceiveCommand cmd) throws PermissionBackendException, NoSuchProjectException, IOException {
    RevObject obj;
    try {
        obj = receivePack.getRevWalk().parseAny(cmd.getNewId());
    } catch (IOException err) {
        logger.atSevere().withCause(err).log("Invalid object %s for %s creation", cmd.getNewId().name(), cmd.getRefName());
        reject(cmd, "invalid object");
        return;
    }
    logger.atFine().log("Creating %s", cmd);
    if (isHead(cmd) && !isCommit(cmd)) {
        return;
    }
    Branch.NameKey branch = new Branch.NameKey(project.getName(), cmd.getRefName());
    try {
        // Must pass explicit user instead of injecting a provider into CreateRefControl, since
        // Provider<CurrentUser> within ReceiveCommits will always return anonymous.
        createRefControl.checkCreateRef(Providers.of(user), receivePack.getRepository(), branch, obj);
    } catch (AuthException denied) {
        rejectProhibited(cmd, denied);
        return;
    } catch (ResourceConflictException denied) {
        reject(cmd, "prohibited by Gerrit: " + denied.getMessage());
        return;
    }
    if (!validRefOperation(cmd)) {
        // validRefOperation sets messages, so no need to provide more feedback.
        return;
    }
    validateNewCommits(new Branch.NameKey(project.getNameKey(), cmd.getRefName()), cmd);
    actualCommands.add(cmd);
}
#end_block

#method_before
private void parseUpdate(ReceiveCommand cmd) throws PermissionBackendException {
    logDebug("Updating %s", cmd);
    Optional<AuthException> err = checkRefPermission(cmd, RefPermission.UPDATE);
    if (!err.isPresent()) {
        if (isHead(cmd) && !isCommit(cmd)) {
            return;
        }
        if (!validRefOperation(cmd)) {
            return;
        }
        validateNewCommits(new Branch.NameKey(project.getNameKey(), cmd.getRefName()), cmd);
        actualCommands.add(cmd);
    } else {
        rejectProhibited(cmd, err.get());
    }
}
#method_after
private void parseUpdate(ReceiveCommand cmd) throws PermissionBackendException {
    logger.atFine().log("Updating %s", cmd);
    Optional<AuthException> err = checkRefPermission(cmd, RefPermission.UPDATE);
    if (!err.isPresent()) {
        if (isHead(cmd) && !isCommit(cmd)) {
            return;
        }
        if (!validRefOperation(cmd)) {
            return;
        }
        validateNewCommits(new Branch.NameKey(project.getNameKey(), cmd.getRefName()), cmd);
        actualCommands.add(cmd);
    } else {
        rejectProhibited(cmd, err.get());
    }
}
#end_block

#method_before
private boolean isCommit(ReceiveCommand cmd) {
    RevObject obj;
    try {
        obj = receivePack.getRevWalk().parseAny(cmd.getNewId());
    } catch (IOException err) {
        logError("Invalid object " + cmd.getNewId().name() + " for " + cmd.getRefName(), err);
        reject(cmd, "invalid object");
        return false;
    }
    if (obj instanceof RevCommit) {
        return true;
    }
    reject(cmd, "not a commit");
    return false;
}
#method_after
private boolean isCommit(ReceiveCommand cmd) {
    RevObject obj;
    try {
        obj = receivePack.getRevWalk().parseAny(cmd.getNewId());
    } catch (IOException err) {
        logger.atSevere().withCause(err).log("Invalid object %s for %s", cmd.getNewId().name(), cmd.getRefName());
        reject(cmd, "invalid object");
        return false;
    }
    if (obj instanceof RevCommit) {
        return true;
    }
    reject(cmd, "not a commit");
    return false;
}
#end_block

#method_before
private void parseDelete(ReceiveCommand cmd) throws PermissionBackendException {
    logDebug("Deleting %s", cmd);
    if (cmd.getRefName().startsWith(REFS_CHANGES)) {
        errors.put(CANNOT_DELETE_CHANGES, cmd.getRefName());
        reject(cmd, "cannot delete changes");
    } else if (isConfigRef(cmd.getRefName())) {
        errors.put(CANNOT_DELETE_CONFIG, cmd.getRefName());
        reject(cmd, "cannot delete project configuration");
    }
    Optional<AuthException> err = checkRefPermission(cmd, RefPermission.DELETE);
    if (!err.isPresent()) {
        if (!validRefOperation(cmd)) {
            return;
        }
        actualCommands.add(cmd);
    } else {
        rejectProhibited(cmd, err.get());
    }
}
#method_after
private void parseDelete(ReceiveCommand cmd) throws PermissionBackendException {
    logger.atFine().log("Deleting %s", cmd);
    if (cmd.getRefName().startsWith(REFS_CHANGES)) {
        errors.put(CANNOT_DELETE_CHANGES, cmd.getRefName());
        reject(cmd, "cannot delete changes");
    } else if (isConfigRef(cmd.getRefName())) {
        errors.put(CANNOT_DELETE_CONFIG, cmd.getRefName());
        reject(cmd, "cannot delete project configuration");
    }
    Optional<AuthException> err = checkRefPermission(cmd, RefPermission.DELETE);
    if (!err.isPresent()) {
        if (!validRefOperation(cmd)) {
            return;
        }
        actualCommands.add(cmd);
    } else {
        rejectProhibited(cmd, err.get());
    }
}
#end_block

#method_before
private void parseRewind(ReceiveCommand cmd) throws PermissionBackendException {
    RevCommit newObject;
    try {
        newObject = receivePack.getRevWalk().parseCommit(cmd.getNewId());
    } catch (IncorrectObjectTypeException notCommit) {
        newObject = null;
    } catch (IOException err) {
        logError("Invalid object " + cmd.getNewId().name() + " for " + cmd.getRefName() + " forced update", err);
        reject(cmd, "invalid object");
        return;
    }
    logDebug("Rewinding %s", cmd);
    if (newObject != null) {
        validateNewCommits(new Branch.NameKey(project.getNameKey(), cmd.getRefName()), cmd);
        if (cmd.getResult() != NOT_ATTEMPTED) {
            return;
        }
    }
    Optional<AuthException> err = checkRefPermission(cmd, RefPermission.FORCE_UPDATE);
    if (!err.isPresent()) {
        if (!validRefOperation(cmd)) {
            return;
        }
        actualCommands.add(cmd);
    } else {
        rejectProhibited(cmd, err.get());
    }
}
#method_after
private void parseRewind(ReceiveCommand cmd) throws PermissionBackendException {
    RevCommit newObject;
    try {
        newObject = receivePack.getRevWalk().parseCommit(cmd.getNewId());
    } catch (IncorrectObjectTypeException notCommit) {
        newObject = null;
    } catch (IOException err) {
        logger.atSevere().withCause(err).log("Invalid object %s for %s forced update", cmd.getNewId().name(), cmd.getRefName());
        reject(cmd, "invalid object");
        return;
    }
    logger.atFine().log("Rewinding %s", cmd);
    if (newObject != null) {
        validateNewCommits(new Branch.NameKey(project.getNameKey(), cmd.getRefName()), cmd);
        if (cmd.getResult() != NOT_ATTEMPTED) {
            return;
        }
    }
    Optional<AuthException> err = checkRefPermission(cmd, RefPermission.FORCE_UPDATE);
    if (!err.isPresent()) {
        if (!validRefOperation(cmd)) {
            return;
        }
        actualCommands.add(cmd);
    } else {
        rejectProhibited(cmd, err.get());
    }
}
#end_block

#method_before
private void parseMagicBranch(ReceiveCommand cmd) throws PermissionBackendException {
    logDebug("Found magic branch %s", cmd.getRefName());
    magicBranch = new MagicBranchInput(user, cmd, labelTypes, notesMigration);
    magicBranch.reviewer.addAll(extraReviewers.get(ReviewerStateInternal.REVIEWER));
    magicBranch.cc.addAll(extraReviewers.get(ReviewerStateInternal.CC));
    String ref;
    magicBranch.cmdLineParser = optionParserFactory.create(magicBranch);
    try {
        ref = magicBranch.parse(repo, receivePack.getAdvertisedRefs().keySet(), pushOptions);
    } catch (CmdLineException e) {
        if (!magicBranch.cmdLineParser.wasHelpRequestedByOption()) {
            logDebug("Invalid branch syntax");
            reject(cmd, e.getMessage());
            return;
        }
        // never happens
        ref = null;
    }
    if (magicBranch.topic != null && magicBranch.topic.length() > ChangeUtil.TOPIC_MAX_LENGTH) {
        reject(cmd, String.format("topic length exceeds the limit (%d)", ChangeUtil.TOPIC_MAX_LENGTH));
    }
    if (magicBranch.cmdLineParser.wasHelpRequestedByOption()) {
        StringWriter w = new StringWriter();
        w.write("\nHelp for refs/for/branch:\n\n");
        magicBranch.cmdLineParser.printUsage(w, null);
        addMessage(w.toString());
        reject(cmd, "see help");
        return;
    }
    if (projectState.isAllUsers() && RefNames.REFS_USERS_SELF.equals(ref)) {
        logDebug("Handling %s", RefNames.REFS_USERS_SELF);
        ref = RefNames.refsUsers(user.getAccountId());
    }
    if (!receivePack.getAdvertisedRefs().containsKey(ref) && !ref.equals(readHEAD(repo)) && !ref.equals(RefNames.REFS_CONFIG)) {
        logDebug("Ref %s not found", ref);
        if (ref.startsWith(Constants.R_HEADS)) {
            String n = ref.substring(Constants.R_HEADS.length());
            reject(cmd, "branch " + n + " not found");
        } else {
            reject(cmd, ref + " not found");
        }
        return;
    }
    magicBranch.dest = new Branch.NameKey(project.getNameKey(), ref);
    magicBranch.perm = permissions.ref(ref);
    Optional<AuthException> err = checkRefPermission(magicBranch.perm, RefPermission.CREATE_CHANGE);
    if (err.isPresent()) {
        rejectProhibited(cmd, err.get());
        return;
    }
    if (!projectState.statePermitsWrite()) {
        reject(cmd, "project state does not permit write");
        return;
    }
    // after repo-tool supports private and work-in-progress changes.
    if (magicBranch.draft && !receiveConfig.allowDrafts) {
        errors.put(ReceiveError.CODE_REVIEW.get(), ref);
        reject(cmd, "draft workflow is disabled");
        return;
    }
    if (magicBranch.isPrivate && magicBranch.removePrivate) {
        reject(cmd, "the options 'private' and 'remove-private' are mutually exclusive");
        return;
    }
    boolean privateByDefault = projectCache.get(project.getNameKey()).is(BooleanProjectConfig.PRIVATE_BY_DEFAULT);
    setChangeAsPrivate = magicBranch.draft || magicBranch.isPrivate || (privateByDefault && !magicBranch.removePrivate);
    if (receiveConfig.disablePrivateChanges && setChangeAsPrivate) {
        reject(cmd, "private changes are disabled");
        return;
    }
    if (magicBranch.workInProgress && magicBranch.ready) {
        reject(cmd, "the options 'wip' and 'ready' are mutually exclusive");
        return;
    }
    if (magicBranch.publishComments && magicBranch.noPublishComments) {
        reject(cmd, "the options 'publish-comments' and 'no-publish-comments' are mutually exclusive");
        return;
    }
    if (magicBranch.submit) {
        err = checkRefPermission(magicBranch.perm, RefPermission.UPDATE_BY_SUBMIT);
        if (err.isPresent()) {
            rejectProhibited(cmd, err.get());
            return;
        }
    }
    RevWalk walk = receivePack.getRevWalk();
    RevCommit tip;
    try {
        tip = walk.parseCommit(magicBranch.cmd.getNewId());
        logDebug("Tip of push: %s", tip.name());
    } catch (IOException ex) {
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", ex);
        return;
    }
    String destBranch = magicBranch.dest.get();
    try {
        if (magicBranch.merged) {
            if (magicBranch.base != null) {
                reject(cmd, "cannot use merged with base");
                return;
            }
            RevCommit branchTip = readBranchTip(cmd, magicBranch.dest);
            if (branchTip == null) {
                // readBranchTip already rejected cmd.
                return;
            }
            if (!walk.isMergedInto(tip, branchTip)) {
                reject(cmd, "not merged into branch");
                return;
            }
        }
        // if %base or %merged was specified, ignore newChangeForAllNotInTarget.
        if (tip.getParentCount() > 1 || magicBranch.base != null || magicBranch.merged || tip.getParentCount() == 0) {
            logDebug("Forcing newChangeForAllNotInTarget = false");
            newChangeForAllNotInTarget = false;
        }
        if (magicBranch.base != null) {
            logDebug("Handling %base: %s", magicBranch.base);
            magicBranch.baseCommit = Lists.newArrayListWithCapacity(magicBranch.base.size());
            for (ObjectId id : magicBranch.base) {
                try {
                    magicBranch.baseCommit.add(walk.parseCommit(id));
                } catch (IncorrectObjectTypeException notCommit) {
                    reject(cmd, "base must be a commit");
                    return;
                } catch (MissingObjectException e) {
                    reject(cmd, "base not found");
                    return;
                } catch (IOException e) {
                    logWarn(String.format("Project %s cannot read %s", project.getName(), id.name()), e);
                    reject(cmd, "internal server error");
                    return;
                }
            }
        } else if (newChangeForAllNotInTarget) {
            RevCommit branchTip = readBranchTip(cmd, magicBranch.dest);
            if (branchTip == null) {
                // readBranchTip already rejected cmd.
                return;
            }
            magicBranch.baseCommit = Collections.singletonList(branchTip);
            logDebug("Set baseCommit = %s", magicBranch.baseCommit.get(0).name());
        }
    } catch (IOException ex) {
        logWarn(String.format("Error walking to %s in project %s", destBranch, project.getName()), ex);
        reject(cmd, "internal server error");
        return;
    }
    // 
    try {
        Ref targetRef = receivePack.getAdvertisedRefs().get(magicBranch.dest.get());
        if (targetRef == null || targetRef.getObjectId() == null) {
            // The destination branch does not yet exist. Assume the
            // history being sent for review will start it and thus
            // is "connected" to the branch.
            logDebug("Branch is unborn");
            return;
        }
        RevCommit h = walk.parseCommit(targetRef.getObjectId());
        logDebug("Current branch tip: %s", h.name());
        RevFilter oldRevFilter = walk.getRevFilter();
        try {
            walk.reset();
            walk.setRevFilter(RevFilter.MERGE_BASE);
            walk.markStart(tip);
            walk.markStart(h);
            if (walk.next() == null) {
                reject(magicBranch.cmd, "no common ancestry");
            }
        } finally {
            walk.reset();
            walk.setRevFilter(oldRevFilter);
        }
    } catch (IOException e) {
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", e);
    }
}
#method_after
private void parseMagicBranch(ReceiveCommand cmd) throws PermissionBackendException {
    logger.atFine().log("Found magic branch %s", cmd.getRefName());
    magicBranch = new MagicBranchInput(user, cmd, labelTypes, notesMigration);
    magicBranch.reviewer.addAll(extraReviewers.get(ReviewerStateInternal.REVIEWER));
    magicBranch.cc.addAll(extraReviewers.get(ReviewerStateInternal.CC));
    String ref;
    magicBranch.cmdLineParser = optionParserFactory.create(magicBranch);
    try {
        ref = magicBranch.parse(repo, receivePack.getAdvertisedRefs().keySet(), pushOptions);
    } catch (CmdLineException e) {
        if (!magicBranch.cmdLineParser.wasHelpRequestedByOption()) {
            logger.atFine().log("Invalid branch syntax");
            reject(cmd, e.getMessage());
            return;
        }
        // never happens
        ref = null;
    }
    if (magicBranch.topic != null && magicBranch.topic.length() > ChangeUtil.TOPIC_MAX_LENGTH) {
        reject(cmd, String.format("topic length exceeds the limit (%d)", ChangeUtil.TOPIC_MAX_LENGTH));
    }
    if (magicBranch.cmdLineParser.wasHelpRequestedByOption()) {
        StringWriter w = new StringWriter();
        w.write("\nHelp for refs/for/branch:\n\n");
        magicBranch.cmdLineParser.printUsage(w, null);
        addMessage(w.toString());
        reject(cmd, "see help");
        return;
    }
    if (projectState.isAllUsers() && RefNames.REFS_USERS_SELF.equals(ref)) {
        logger.atFine().log("Handling %s", RefNames.REFS_USERS_SELF);
        ref = RefNames.refsUsers(user.getAccountId());
    }
    if (!receivePack.getAdvertisedRefs().containsKey(ref) && !ref.equals(readHEAD(repo)) && !ref.equals(RefNames.REFS_CONFIG)) {
        logger.atFine().log("Ref %s not found", ref);
        if (ref.startsWith(Constants.R_HEADS)) {
            String n = ref.substring(Constants.R_HEADS.length());
            reject(cmd, "branch " + n + " not found");
        } else {
            reject(cmd, ref + " not found");
        }
        return;
    }
    magicBranch.dest = new Branch.NameKey(project.getNameKey(), ref);
    magicBranch.perm = permissions.ref(ref);
    Optional<AuthException> err = checkRefPermission(magicBranch.perm, RefPermission.CREATE_CHANGE);
    if (err.isPresent()) {
        rejectProhibited(cmd, err.get());
        return;
    }
    if (!projectState.statePermitsWrite()) {
        reject(cmd, "project state does not permit write");
        return;
    }
    // after repo-tool supports private and work-in-progress changes.
    if (magicBranch.draft && !receiveConfig.allowDrafts) {
        errors.put(ReceiveError.CODE_REVIEW.get(), ref);
        reject(cmd, "draft workflow is disabled");
        return;
    }
    if (magicBranch.isPrivate && magicBranch.removePrivate) {
        reject(cmd, "the options 'private' and 'remove-private' are mutually exclusive");
        return;
    }
    boolean privateByDefault = projectCache.get(project.getNameKey()).is(BooleanProjectConfig.PRIVATE_BY_DEFAULT);
    setChangeAsPrivate = magicBranch.draft || magicBranch.isPrivate || (privateByDefault && !magicBranch.removePrivate);
    if (receiveConfig.disablePrivateChanges && setChangeAsPrivate) {
        reject(cmd, "private changes are disabled");
        return;
    }
    if (magicBranch.workInProgress && magicBranch.ready) {
        reject(cmd, "the options 'wip' and 'ready' are mutually exclusive");
        return;
    }
    if (magicBranch.publishComments && magicBranch.noPublishComments) {
        reject(cmd, "the options 'publish-comments' and 'no-publish-comments' are mutually exclusive");
        return;
    }
    if (magicBranch.submit) {
        err = checkRefPermission(magicBranch.perm, RefPermission.UPDATE_BY_SUBMIT);
        if (err.isPresent()) {
            rejectProhibited(cmd, err.get());
            return;
        }
    }
    RevWalk walk = receivePack.getRevWalk();
    RevCommit tip;
    try {
        tip = walk.parseCommit(magicBranch.cmd.getNewId());
        logger.atFine().log("Tip of push: %s", tip.name());
    } catch (IOException ex) {
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logger.atSevere().withCause(ex).log("Invalid pack upload; one or more objects weren't sent");
        return;
    }
    String destBranch = magicBranch.dest.get();
    try {
        if (magicBranch.merged) {
            if (magicBranch.base != null) {
                reject(cmd, "cannot use merged with base");
                return;
            }
            RevCommit branchTip = readBranchTip(cmd, magicBranch.dest);
            if (branchTip == null) {
                // readBranchTip already rejected cmd.
                return;
            }
            if (!walk.isMergedInto(tip, branchTip)) {
                reject(cmd, "not merged into branch");
                return;
            }
        }
        // if %base or %merged was specified, ignore newChangeForAllNotInTarget.
        if (tip.getParentCount() > 1 || magicBranch.base != null || magicBranch.merged || tip.getParentCount() == 0) {
            logger.atFine().log("Forcing newChangeForAllNotInTarget = false");
            newChangeForAllNotInTarget = false;
        }
        if (magicBranch.base != null) {
            logger.atFine().log("Handling %%base: %s", magicBranch.base);
            magicBranch.baseCommit = Lists.newArrayListWithCapacity(magicBranch.base.size());
            for (ObjectId id : magicBranch.base) {
                try {
                    magicBranch.baseCommit.add(walk.parseCommit(id));
                } catch (IncorrectObjectTypeException notCommit) {
                    reject(cmd, "base must be a commit");
                    return;
                } catch (MissingObjectException e) {
                    reject(cmd, "base not found");
                    return;
                } catch (IOException e) {
                    logger.atWarning().withCause(e).log("Project %s cannot read %s", project.getName(), id.name());
                    reject(cmd, "internal server error");
                    return;
                }
            }
        } else if (newChangeForAllNotInTarget) {
            RevCommit branchTip = readBranchTip(cmd, magicBranch.dest);
            if (branchTip == null) {
                // readBranchTip already rejected cmd.
                return;
            }
            magicBranch.baseCommit = Collections.singletonList(branchTip);
            logger.atFine().log("Set baseCommit = %s", magicBranch.baseCommit.get(0).name());
        }
    } catch (IOException ex) {
        logger.atWarning().withCause(ex).log("Error walking to %s in project %s", destBranch, project.getName());
        reject(cmd, "internal server error");
        return;
    }
    // 
    try {
        Ref targetRef = receivePack.getAdvertisedRefs().get(magicBranch.dest.get());
        if (targetRef == null || targetRef.getObjectId() == null) {
            // The destination branch does not yet exist. Assume the
            // history being sent for review will start it and thus
            // is "connected" to the branch.
            logger.atFine().log("Branch is unborn");
            return;
        }
        RevCommit h = walk.parseCommit(targetRef.getObjectId());
        logger.atFine().log("Current branch tip: %s", h.name());
        RevFilter oldRevFilter = walk.getRevFilter();
        try {
            walk.reset();
            walk.setRevFilter(RevFilter.MERGE_BASE);
            walk.markStart(tip);
            walk.markStart(h);
            if (walk.next() == null) {
                reject(magicBranch.cmd, "no common ancestry");
            }
        } finally {
            walk.reset();
            walk.setRevFilter(oldRevFilter);
        }
    } catch (IOException e) {
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logger.atSevere().withCause(e).log("Invalid pack upload; one or more objects weren't sent");
    }
}
#end_block

#method_before
private void parseReplaceCommand(ReceiveCommand cmd, Change.Id changeId) {
    logDebug("Parsing replace command");
    if (cmd.getType() != ReceiveCommand.Type.CREATE) {
        reject(cmd, "invalid usage");
        return;
    }
    RevCommit newCommit;
    try {
        newCommit = receivePack.getRevWalk().parseCommit(cmd.getNewId());
        logDebug("Replacing with %s", newCommit);
    } catch (IOException e) {
        logError("Cannot parse " + cmd.getNewId().name() + " as commit", e);
        reject(cmd, "invalid commit");
        return;
    }
    Change changeEnt;
    try {
        changeEnt = notesFactory.createChecked(db, project.getNameKey(), changeId).getChange();
    } catch (NoSuchChangeException e) {
        logError("Change not found " + changeId, e);
        reject(cmd, "change " + changeId + " not found");
        return;
    } catch (OrmException e) {
        logError("Cannot lookup existing change " + changeId, e);
        reject(cmd, "database error");
        return;
    }
    if (!project.getNameKey().equals(changeEnt.getProject())) {
        reject(cmd, "change " + changeId + " does not belong to project " + project.getName());
        return;
    }
    logDebug("Replacing change %s", changeEnt.getId());
    requestReplace(cmd, true, changeEnt, newCommit);
}
#method_after
private void parseReplaceCommand(ReceiveCommand cmd, Change.Id changeId) {
    logger.atFine().log("Parsing replace command");
    if (cmd.getType() != ReceiveCommand.Type.CREATE) {
        reject(cmd, "invalid usage");
        return;
    }
    RevCommit newCommit;
    try {
        newCommit = receivePack.getRevWalk().parseCommit(cmd.getNewId());
        logger.atFine().log("Replacing with %s", newCommit);
    } catch (IOException e) {
        logger.atSevere().withCause(e).log("Cannot parse %s as commit", cmd.getNewId().name());
        reject(cmd, "invalid commit");
        return;
    }
    Change changeEnt;
    try {
        changeEnt = notesFactory.createChecked(db, project.getNameKey(), changeId).getChange();
    } catch (NoSuchChangeException e) {
        logger.atSevere().withCause(e).log("Change not found %s", changeId);
        reject(cmd, "change " + changeId + " not found");
        return;
    } catch (OrmException e) {
        logger.atSevere().withCause(e).log("Cannot lookup existing change %s", changeId);
        reject(cmd, "database error");
        return;
    }
    if (!project.getNameKey().equals(changeEnt.getProject())) {
        reject(cmd, "change " + changeId + " does not belong to project " + project.getName());
        return;
    }
    logger.atFine().log("Replacing change %s", changeEnt.getId());
    requestReplace(cmd, true, changeEnt, newCommit);
}
#end_block

#method_before
private List<CreateRequest> selectNewAndReplacedChangesFromMagicBranch() {
    logDebug("Finding new and replaced changes");
    List<CreateRequest> newChanges = new ArrayList<>();
    ListMultimap<ObjectId, Ref> existing = changeRefsById();
    GroupCollector groupCollector = GroupCollector.create(changeRefsById(), db, psUtil, notesFactory, project.getNameKey());
    try {
        RevCommit start = setUpWalkForSelectingChanges();
        if (start == null) {
            return Collections.emptyList();
        }
        LinkedHashMap<RevCommit, ChangeLookup> pending = new LinkedHashMap<>();
        Set<Change.Key> newChangeIds = new HashSet<>();
        int maxBatchChanges = receiveConfig.getEffectiveMaxBatchChangesLimit(user);
        int total = 0;
        int alreadyTracked = 0;
        boolean rejectImplicitMerges = start.getParentCount() == 1 && projectCache.get(project.getNameKey()).is(BooleanProjectConfig.REJECT_IMPLICIT_MERGES) && // late.
        !magicBranch.merged;
        Set<RevCommit> mergedParents;
        if (rejectImplicitMerges) {
            mergedParents = new HashSet<>();
        } else {
            mergedParents = null;
        }
        for (; ; ) {
            RevCommit c = receivePack.getRevWalk().next();
            if (c == null) {
                break;
            }
            total++;
            receivePack.getRevWalk().parseBody(c);
            String name = c.name();
            groupCollector.visit(c);
            Collection<Ref> existingRefs = existing.get(c);
            if (rejectImplicitMerges) {
                Collections.addAll(mergedParents, c.getParents());
                mergedParents.remove(c);
            }
            boolean commitAlreadyTracked = !existingRefs.isEmpty();
            if (commitAlreadyTracked) {
                alreadyTracked++;
                // different target branch.
                for (Ref ref : existingRefs) {
                    updateGroups.add(new UpdateGroupsRequest(ref, c));
                }
                if (!(newChangeForAllNotInTarget || magicBranch.base != null)) {
                    continue;
                }
            }
            List<String> idList = c.getFooterLines(CHANGE_ID);
            if (!idList.isEmpty()) {
                pending.put(c, new ChangeLookup(c, new Change.Key(idList.get(idList.size() - 1).trim())));
            } else {
                pending.put(c, new ChangeLookup(c));
            }
            int n = pending.size() + newChanges.size();
            if (maxBatchChanges != 0 && n > maxBatchChanges) {
                logDebug("%d changes exceeds limit of %d", n, maxBatchChanges);
                reject(magicBranch.cmd, "the number of pushed changes in a batch exceeds the max limit " + maxBatchChanges);
                return Collections.emptyList();
            }
            if (commitAlreadyTracked) {
                boolean changeExistsOnDestBranch = false;
                for (ChangeData cd : pending.get(c).destChanges) {
                    if (cd.change().getDest().equals(magicBranch.dest)) {
                        changeExistsOnDestBranch = true;
                        break;
                    }
                }
                if (changeExistsOnDestBranch) {
                    continue;
                }
                logDebug("Creating new change for %s even though it is already tracked", name);
            }
            if (!validCommit(receivePack.getRevWalk(), magicBranch.dest, magicBranch.cmd, c, null)) {
                // Not a change the user can propose? Abort as early as possible.
                logDebug("Aborting early due to invalid commit");
                return Collections.emptyList();
            }
            // Don't allow merges to be uploaded in commit chain via all-not-in-target
            if (newChangeForAllNotInTarget && c.getParentCount() > 1) {
                reject(magicBranch.cmd, "Pushing merges in commit chains with 'all not in target' is not allowed,\n" + "to override please set the base manually");
                logDebug("Rejecting merge commit %s with newChangeForAllNotInTarget", name);
            // TODO(dborowitz): Should we early return here?
            }
            if (idList.isEmpty()) {
                newChanges.add(new CreateRequest(c, magicBranch.dest.get()));
                continue;
            }
        }
        logDebug("Finished initial RevWalk with %d commits total: %d already" + " tracked, %d new changes with no Change-Id, and %d deferred" + " lookups", total, alreadyTracked, newChanges.size(), pending.size());
        if (rejectImplicitMerges) {
            rejectImplicitMerges(mergedParents);
        }
        for (Iterator<ChangeLookup> itr = pending.values().iterator(); itr.hasNext(); ) {
            ChangeLookup p = itr.next();
            if (p.changeKey == null) {
                continue;
            }
            if (newChangeIds.contains(p.changeKey)) {
                logDebug("Multiple commits with Change-Id %s", p.changeKey);
                reject(magicBranch.cmd, SAME_CHANGE_ID_IN_MULTIPLE_CHANGES);
                return Collections.emptyList();
            }
            List<ChangeData> changes = p.destChanges;
            if (changes.size() > 1) {
                logDebug("Multiple changes in branch %s with Change-Id %s: %s", magicBranch.dest, p.changeKey, changes.stream().map(cd -> cd.getId().toString()).collect(joining()));
                // WTF, multiple changes in this branch have the same key?
                // Since the commit is new, the user should recreate it with
                // a different Change-Id. In practice, we should never see
                // this error message as Change-Id should be unique per branch.
                // 
                reject(magicBranch.cmd, p.changeKey.get() + " has duplicates");
                return Collections.emptyList();
            }
            if (changes.size() == 1) {
                // Schedule as a replacement to this one matching change.
                // 
                RevId currentPs = changes.get(0).currentPatchSet().getRevision();
                // If Commit is already current PatchSet of target Change.
                if (p.commit.name().equals(currentPs.get())) {
                    if (pending.size() == 1) {
                        // There are no commits left to check, all commits in pending were already
                        // current PatchSet of the corresponding target changes.
                        reject(magicBranch.cmd, "commit(s) already exists (as current patchset)");
                    } else {
                        // Commit is already current PatchSet.
                        // Remove from pending and try next commit.
                        itr.remove();
                        continue;
                    }
                }
                if (requestReplace(magicBranch.cmd, false, changes.get(0).change(), p.commit)) {
                    continue;
                }
                return Collections.emptyList();
            }
            if (changes.size() == 0) {
                if (!isValidChangeId(p.changeKey.get())) {
                    reject(magicBranch.cmd, "invalid Change-Id");
                    return Collections.emptyList();
                }
                // double check against the existing refs
                if (foundInExistingRef(existing.get(p.commit))) {
                    if (pending.size() == 1) {
                        reject(magicBranch.cmd, "commit(s) already exists (as current patchset)");
                        return Collections.emptyList();
                    }
                    itr.remove();
                    continue;
                }
                newChangeIds.add(p.changeKey);
            }
            newChanges.add(new CreateRequest(p.commit, magicBranch.dest.get()));
        }
        logDebug("Finished deferred lookups with %d updates and %d new changes", replaceByChange.size(), newChanges.size());
    } catch (IOException e) {
        // Should never happen, the core receive process would have
        // identified the missing object earlier before we got control.
        // 
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", e);
        return Collections.emptyList();
    } catch (OrmException e) {
        logError("Cannot query database to locate prior changes", e);
        reject(magicBranch.cmd, "database error");
        return Collections.emptyList();
    }
    if (newChanges.isEmpty() && replaceByChange.isEmpty()) {
        reject(magicBranch.cmd, "no new changes");
        return Collections.emptyList();
    }
    if (!newChanges.isEmpty() && magicBranch.edit) {
        reject(magicBranch.cmd, "edit is not supported for new changes");
        return newChanges;
    }
    try {
        SortedSetMultimap<ObjectId, String> groups = groupCollector.getGroups();
        List<Integer> newIds = seq.nextChangeIds(newChanges.size());
        for (int i = 0; i < newChanges.size(); i++) {
            CreateRequest create = newChanges.get(i);
            create.setChangeId(newIds.get(i));
            create.groups = ImmutableList.copyOf(groups.get(create.commit));
        }
        for (ReplaceRequest replace : replaceByChange.values()) {
            replace.groups = ImmutableList.copyOf(groups.get(replace.newCommitId));
        }
        for (UpdateGroupsRequest update : updateGroups) {
            update.groups = ImmutableList.copyOf((groups.get(update.commit)));
        }
        logDebug("Finished updating groups from GroupCollector");
    } catch (OrmException e) {
        logError("Error collecting groups for changes", e);
        reject(magicBranch.cmd, "internal server error");
    }
    return newChanges;
}
#method_after
private List<CreateRequest> selectNewAndReplacedChangesFromMagicBranch() {
    logger.atFine().log("Finding new and replaced changes");
    List<CreateRequest> newChanges = new ArrayList<>();
    ListMultimap<ObjectId, Ref> existing = changeRefsById();
    GroupCollector groupCollector = GroupCollector.create(changeRefsById(), db, psUtil, notesFactory, project.getNameKey());
    try {
        RevCommit start = setUpWalkForSelectingChanges();
        if (start == null) {
            return Collections.emptyList();
        }
        LinkedHashMap<RevCommit, ChangeLookup> pending = new LinkedHashMap<>();
        Set<Change.Key> newChangeIds = new HashSet<>();
        int maxBatchChanges = receiveConfig.getEffectiveMaxBatchChangesLimit(user);
        int total = 0;
        int alreadyTracked = 0;
        boolean rejectImplicitMerges = start.getParentCount() == 1 && projectCache.get(project.getNameKey()).is(BooleanProjectConfig.REJECT_IMPLICIT_MERGES) && // late.
        !magicBranch.merged;
        Set<RevCommit> mergedParents;
        if (rejectImplicitMerges) {
            mergedParents = new HashSet<>();
        } else {
            mergedParents = null;
        }
        for (; ; ) {
            RevCommit c = receivePack.getRevWalk().next();
            if (c == null) {
                break;
            }
            total++;
            receivePack.getRevWalk().parseBody(c);
            String name = c.name();
            groupCollector.visit(c);
            Collection<Ref> existingRefs = existing.get(c);
            if (rejectImplicitMerges) {
                Collections.addAll(mergedParents, c.getParents());
                mergedParents.remove(c);
            }
            boolean commitAlreadyTracked = !existingRefs.isEmpty();
            if (commitAlreadyTracked) {
                alreadyTracked++;
                // different target branch.
                for (Ref ref : existingRefs) {
                    updateGroups.add(new UpdateGroupsRequest(ref, c));
                }
                if (!(newChangeForAllNotInTarget || magicBranch.base != null)) {
                    continue;
                }
            }
            List<String> idList = c.getFooterLines(CHANGE_ID);
            if (!idList.isEmpty()) {
                pending.put(c, new ChangeLookup(c, new Change.Key(idList.get(idList.size() - 1).trim())));
            } else {
                pending.put(c, new ChangeLookup(c));
            }
            int n = pending.size() + newChanges.size();
            if (maxBatchChanges != 0 && n > maxBatchChanges) {
                logger.atFine().log("%d changes exceeds limit of %d", n, maxBatchChanges);
                reject(magicBranch.cmd, "the number of pushed changes in a batch exceeds the max limit " + maxBatchChanges);
                return Collections.emptyList();
            }
            if (commitAlreadyTracked) {
                boolean changeExistsOnDestBranch = false;
                for (ChangeData cd : pending.get(c).destChanges) {
                    if (cd.change().getDest().equals(magicBranch.dest)) {
                        changeExistsOnDestBranch = true;
                        break;
                    }
                }
                if (changeExistsOnDestBranch) {
                    continue;
                }
                logger.atFine().log("Creating new change for %s even though it is already tracked", name);
            }
            if (!validCommit(receivePack.getRevWalk(), magicBranch.dest, magicBranch.cmd, c, null)) {
                // Not a change the user can propose? Abort as early as possible.
                logger.atFine().log("Aborting early due to invalid commit");
                return Collections.emptyList();
            }
            // Don't allow merges to be uploaded in commit chain via all-not-in-target
            if (newChangeForAllNotInTarget && c.getParentCount() > 1) {
                reject(magicBranch.cmd, "Pushing merges in commit chains with 'all not in target' is not allowed,\n" + "to override please set the base manually");
                logger.atFine().log("Rejecting merge commit %s with newChangeForAllNotInTarget", name);
            // TODO(dborowitz): Should we early return here?
            }
            if (idList.isEmpty()) {
                newChanges.add(new CreateRequest(c, magicBranch.dest.get()));
                continue;
            }
        }
        logger.atFine().log("Finished initial RevWalk with %d commits total: %d already" + " tracked, %d new changes with no Change-Id, and %d deferred" + " lookups", total, alreadyTracked, newChanges.size(), pending.size());
        if (rejectImplicitMerges) {
            rejectImplicitMerges(mergedParents);
        }
        for (Iterator<ChangeLookup> itr = pending.values().iterator(); itr.hasNext(); ) {
            ChangeLookup p = itr.next();
            if (p.changeKey == null) {
                continue;
            }
            if (newChangeIds.contains(p.changeKey)) {
                logger.atFine().log("Multiple commits with Change-Id %s", p.changeKey);
                reject(magicBranch.cmd, SAME_CHANGE_ID_IN_MULTIPLE_CHANGES);
                return Collections.emptyList();
            }
            List<ChangeData> changes = p.destChanges;
            if (changes.size() > 1) {
                logger.atFine().log("Multiple changes in branch %s with Change-Id %s: %s", magicBranch.dest, p.changeKey, changes.stream().map(cd -> cd.getId().toString()).collect(joining()));
                // WTF, multiple changes in this branch have the same key?
                // Since the commit is new, the user should recreate it with
                // a different Change-Id. In practice, we should never see
                // this error message as Change-Id should be unique per branch.
                // 
                reject(magicBranch.cmd, p.changeKey.get() + " has duplicates");
                return Collections.emptyList();
            }
            if (changes.size() == 1) {
                // Schedule as a replacement to this one matching change.
                // 
                RevId currentPs = changes.get(0).currentPatchSet().getRevision();
                // If Commit is already current PatchSet of target Change.
                if (p.commit.name().equals(currentPs.get())) {
                    if (pending.size() == 1) {
                        // There are no commits left to check, all commits in pending were already
                        // current PatchSet of the corresponding target changes.
                        reject(magicBranch.cmd, "commit(s) already exists (as current patchset)");
                    } else {
                        // Commit is already current PatchSet.
                        // Remove from pending and try next commit.
                        itr.remove();
                        continue;
                    }
                }
                if (requestReplace(magicBranch.cmd, false, changes.get(0).change(), p.commit)) {
                    continue;
                }
                return Collections.emptyList();
            }
            if (changes.size() == 0) {
                if (!isValidChangeId(p.changeKey.get())) {
                    reject(magicBranch.cmd, "invalid Change-Id");
                    return Collections.emptyList();
                }
                // double check against the existing refs
                if (foundInExistingRef(existing.get(p.commit))) {
                    if (pending.size() == 1) {
                        reject(magicBranch.cmd, "commit(s) already exists (as current patchset)");
                        return Collections.emptyList();
                    }
                    itr.remove();
                    continue;
                }
                newChangeIds.add(p.changeKey);
            }
            newChanges.add(new CreateRequest(p.commit, magicBranch.dest.get()));
        }
        logger.atFine().log("Finished deferred lookups with %d updates and %d new changes", replaceByChange.size(), newChanges.size());
    } catch (IOException e) {
        // Should never happen, the core receive process would have
        // identified the missing object earlier before we got control.
        // 
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logger.atSevere().withCause(e).log("Invalid pack upload; one or more objects weren't sent");
        return Collections.emptyList();
    } catch (OrmException e) {
        logger.atSevere().withCause(e).log("Cannot query database to locate prior changes");
        reject(magicBranch.cmd, "database error");
        return Collections.emptyList();
    }
    if (newChanges.isEmpty() && replaceByChange.isEmpty()) {
        reject(magicBranch.cmd, "no new changes");
        return Collections.emptyList();
    }
    if (!newChanges.isEmpty() && magicBranch.edit) {
        reject(magicBranch.cmd, "edit is not supported for new changes");
        return newChanges;
    }
    try {
        SortedSetMultimap<ObjectId, String> groups = groupCollector.getGroups();
        List<Integer> newIds = seq.nextChangeIds(newChanges.size());
        for (int i = 0; i < newChanges.size(); i++) {
            CreateRequest create = newChanges.get(i);
            create.setChangeId(newIds.get(i));
            create.groups = ImmutableList.copyOf(groups.get(create.commit));
        }
        for (ReplaceRequest replace : replaceByChange.values()) {
            replace.groups = ImmutableList.copyOf(groups.get(replace.newCommitId));
        }
        for (UpdateGroupsRequest update : updateGroups) {
            update.groups = ImmutableList.copyOf((groups.get(update.commit)));
        }
        logger.atFine().log("Finished updating groups from GroupCollector");
    } catch (OrmException e) {
        logger.atSevere().withCause(e).log("Error collecting groups for changes");
        reject(magicBranch.cmd, "internal server error");
    }
    return newChanges;
}
#end_block

#method_before
private boolean foundInExistingRef(Collection<Ref> existingRefs) throws OrmException {
    for (Ref ref : existingRefs) {
        ChangeNotes notes = notesFactory.create(db, project.getNameKey(), Change.Id.fromRef(ref.getName()));
        Change change = notes.getChange();
        if (change.getDest().equals(magicBranch.dest)) {
            logDebug("Found change %s from existing refs.", change.getKey());
            // Reindex the change asynchronously, ignoring errors.
            @SuppressWarnings("unused")
            Future<?> possiblyIgnoredError = indexer.indexAsync(project.getNameKey(), change.getId());
            return true;
        }
    }
    return false;
}
#method_after
private boolean foundInExistingRef(Collection<Ref> existingRefs) throws OrmException {
    for (Ref ref : existingRefs) {
        ChangeNotes notes = notesFactory.create(db, project.getNameKey(), Change.Id.fromRef(ref.getName()));
        Change change = notes.getChange();
        if (change.getDest().equals(magicBranch.dest)) {
            logger.atFine().log("Found change %s from existing refs.", change.getKey());
            // Reindex the change asynchronously, ignoring errors.
            @SuppressWarnings("unused")
            Future<?> possiblyIgnoredError = indexer.indexAsync(project.getNameKey(), change.getId());
            return true;
        }
    }
    return false;
}
#end_block

#method_before
private RevCommit setUpWalkForSelectingChanges() throws IOException {
    RevWalk rw = receivePack.getRevWalk();
    RevCommit start = rw.parseCommit(magicBranch.cmd.getNewId());
    rw.reset();
    rw.sort(RevSort.TOPO);
    rw.sort(RevSort.REVERSE, true);
    receivePack.getRevWalk().markStart(start);
    if (magicBranch.baseCommit != null) {
        markExplicitBasesUninteresting();
    } else if (magicBranch.merged) {
        logDebug("Marking parents of merged commit %s uninteresting", start.name());
        for (RevCommit c : start.getParents()) {
            rw.markUninteresting(c);
        }
    } else {
        markHeadsAsUninteresting(rw, magicBranch.dest != null ? magicBranch.dest.get() : null);
    }
    return start;
}
#method_after
private RevCommit setUpWalkForSelectingChanges() throws IOException {
    RevWalk rw = receivePack.getRevWalk();
    RevCommit start = rw.parseCommit(magicBranch.cmd.getNewId());
    rw.reset();
    rw.sort(RevSort.TOPO);
    rw.sort(RevSort.REVERSE, true);
    receivePack.getRevWalk().markStart(start);
    if (magicBranch.baseCommit != null) {
        markExplicitBasesUninteresting();
    } else if (magicBranch.merged) {
        logger.atFine().log("Marking parents of merged commit %s uninteresting", start.name());
        for (RevCommit c : start.getParents()) {
            rw.markUninteresting(c);
        }
    } else {
        markHeadsAsUninteresting(rw, magicBranch.dest != null ? magicBranch.dest.get() : null);
    }
    return start;
}
#end_block

#method_before
private void markExplicitBasesUninteresting() throws IOException {
    logDebug("Marking %d base commits uninteresting", magicBranch.baseCommit.size());
    for (RevCommit c : magicBranch.baseCommit) {
        receivePack.getRevWalk().markUninteresting(c);
    }
    Ref targetRef = allRefs().get(magicBranch.dest.get());
    if (targetRef != null) {
        logDebug("Marking target ref %s (%s) uninteresting", magicBranch.dest.get(), targetRef.getObjectId().name());
        receivePack.getRevWalk().markUninteresting(receivePack.getRevWalk().parseCommit(targetRef.getObjectId()));
    }
}
#method_after
private void markExplicitBasesUninteresting() throws IOException {
    logger.atFine().log("Marking %d base commits uninteresting", magicBranch.baseCommit.size());
    for (RevCommit c : magicBranch.baseCommit) {
        receivePack.getRevWalk().markUninteresting(c);
    }
    Ref targetRef = allRefs().get(magicBranch.dest.get());
    if (targetRef != null) {
        logger.atFine().log("Marking target ref %s (%s) uninteresting", magicBranch.dest.get(), targetRef.getObjectId().name());
        receivePack.getRevWalk().markUninteresting(receivePack.getRevWalk().parseCommit(targetRef.getObjectId()));
    }
}
#end_block

#method_before
// Mark all branch tips as uninteresting in the given revwalk,
private void markHeadsAsUninteresting(RevWalk rw, @Nullable String forRef) {
    int i = 0;
    for (Ref ref : allRefs().values()) {
        if ((ref.getName().startsWith(R_HEADS) || ref.getName().equals(forRef)) && ref.getObjectId() != null) {
            try {
                rw.markUninteresting(rw.parseCommit(ref.getObjectId()));
                i++;
            } catch (IOException e) {
                logWarn(String.format("Invalid ref %s in %s", ref.getName(), project.getName()), e);
            }
        }
    }
    logDebug("Marked %d heads as uninteresting", i);
}
#method_after
// Mark all branch tips as uninteresting in the given revwalk,
private void markHeadsAsUninteresting(RevWalk rw, @Nullable String forRef) {
    int i = 0;
    for (Ref ref : allRefs().values()) {
        if ((ref.getName().startsWith(R_HEADS) || ref.getName().equals(forRef)) && ref.getObjectId() != null) {
            try {
                rw.markUninteresting(rw.parseCommit(ref.getObjectId()));
                i++;
            } catch (IOException e) {
                logger.atWarning().withCause(e).log("Invalid ref %s in %s", ref.getName(), project.getName());
            }
        }
    }
    logger.atFine().log("Marked %d heads as uninteresting", i);
}
#end_block

#method_before
private void submit(Collection<CreateRequest> create, Collection<ReplaceRequest> replace) throws OrmException, RestApiException, UpdateException, IOException, ConfigInvalidException, PermissionBackendException {
    Map<ObjectId, Change> bySha = Maps.newHashMapWithExpectedSize(create.size() + replace.size());
    for (CreateRequest r : create) {
        checkNotNull(r.change, "cannot submit new change %s; op may not have run", r.changeId);
        bySha.put(r.commit, r.change);
    }
    for (ReplaceRequest r : replace) {
        bySha.put(r.newCommitId, r.notes.getChange());
    }
    Change tipChange = bySha.get(magicBranch.cmd.getNewId());
    checkNotNull(tipChange, "tip of push does not correspond to a change; found these changes: %s", bySha);
    logDebug("Processing submit with tip change %s (%s)", tipChange.getId(), magicBranch.cmd.getNewId());
    try (MergeOp op = mergeOpProvider.get()) {
        op.merge(db, tipChange, user, false, new SubmitInput(), false);
    }
}
#method_after
private void submit(Collection<CreateRequest> create, Collection<ReplaceRequest> replace) throws OrmException, RestApiException, UpdateException, IOException, ConfigInvalidException, PermissionBackendException {
    Map<ObjectId, Change> bySha = Maps.newHashMapWithExpectedSize(create.size() + replace.size());
    for (CreateRequest r : create) {
        checkNotNull(r.change, "cannot submit new change %s; op may not have run", r.changeId);
        bySha.put(r.commit, r.change);
    }
    for (ReplaceRequest r : replace) {
        bySha.put(r.newCommitId, r.notes.getChange());
    }
    Change tipChange = bySha.get(magicBranch.cmd.getNewId());
    checkNotNull(tipChange, "tip of push does not correspond to a change; found these changes: %s", bySha);
    logger.atFine().log("Processing submit with tip change %s (%s)", tipChange.getId(), magicBranch.cmd.getNewId());
    try (MergeOp op = mergeOpProvider.get()) {
        op.merge(db, tipChange, user, false, new SubmitInput(), false);
    }
}
#end_block

#method_before
private void preparePatchSetsForReplace(List<CreateRequest> newChanges) {
    try {
        readChangesForReplace();
        for (Iterator<ReplaceRequest> itr = replaceByChange.values().iterator(); itr.hasNext(); ) {
            ReplaceRequest req = itr.next();
            if (req.inputCommand.getResult() == NOT_ATTEMPTED) {
                req.validate(false);
            }
        }
    } catch (OrmException err) {
        logError(String.format("Cannot read database before replacement for project %s", project.getName()), err);
        for (ReplaceRequest req : replaceByChange.values()) {
            if (req.inputCommand.getResult() == NOT_ATTEMPTED) {
                req.inputCommand.setResult(REJECTED_OTHER_REASON, "internal server error");
            }
        }
    } catch (IOException | PermissionBackendException err) {
        logError(String.format("Cannot read repository before replacement for project %s", project.getName()), err);
        for (ReplaceRequest req : replaceByChange.values()) {
            if (req.inputCommand.getResult() == NOT_ATTEMPTED) {
                req.inputCommand.setResult(REJECTED_OTHER_REASON, "internal server error");
            }
        }
    }
    logDebug("Read %d changes to replace", replaceByChange.size());
    if (magicBranch != null && magicBranch.cmd.getResult() != NOT_ATTEMPTED) {
        // Cancel creations tied to refs/for/ or refs/drafts/ command.
        for (ReplaceRequest req : replaceByChange.values()) {
            if (req.inputCommand == magicBranch.cmd && req.cmd != null) {
                req.cmd.setResult(Result.REJECTED_OTHER_REASON, "aborted");
            }
        }
        for (CreateRequest req : newChanges) {
            req.cmd.setResult(Result.REJECTED_OTHER_REASON, "aborted");
        }
    }
}
#method_after
private void preparePatchSetsForReplace(List<CreateRequest> newChanges) {
    try {
        readChangesForReplace();
        for (Iterator<ReplaceRequest> itr = replaceByChange.values().iterator(); itr.hasNext(); ) {
            ReplaceRequest req = itr.next();
            if (req.inputCommand.getResult() == NOT_ATTEMPTED) {
                req.validate(false);
            }
        }
    } catch (OrmException err) {
        logger.atSevere().withCause(err).log("Cannot read database before replacement for project %s", project.getName());
        for (ReplaceRequest req : replaceByChange.values()) {
            if (req.inputCommand.getResult() == NOT_ATTEMPTED) {
                req.inputCommand.setResult(REJECTED_OTHER_REASON, "internal server error");
            }
        }
    } catch (IOException | PermissionBackendException err) {
        logger.atSevere().withCause(err).log("Cannot read repository before replacement for project %s", project.getName());
        for (ReplaceRequest req : replaceByChange.values()) {
            if (req.inputCommand.getResult() == NOT_ATTEMPTED) {
                req.inputCommand.setResult(REJECTED_OTHER_REASON, "internal server error");
            }
        }
    }
    logger.atFine().log("Read %d changes to replace", replaceByChange.size());
    if (magicBranch != null && magicBranch.cmd.getResult() != NOT_ATTEMPTED) {
        // Cancel creations tied to refs/for/ or refs/drafts/ command.
        for (ReplaceRequest req : replaceByChange.values()) {
            if (req.inputCommand == magicBranch.cmd && req.cmd != null) {
                req.cmd.setResult(Result.REJECTED_OTHER_REASON, "aborted");
            }
        }
        for (CreateRequest req : newChanges) {
            req.cmd.setResult(Result.REJECTED_OTHER_REASON, "aborted");
        }
    }
}
#end_block

#method_before
private boolean newEdit() {
    psId = notes.getChange().currentPatchSetId();
    Optional<ChangeEdit> edit = null;
    try {
        edit = editUtil.byChange(notes, user);
    } catch (AuthException | IOException e) {
        logError("Cannot retrieve edit", e);
        return false;
    }
    if (edit.isPresent()) {
        if (edit.get().getBasePatchSet().getId().equals(psId)) {
            // replace edit
            cmd = new ReceiveCommand(edit.get().getEditCommit(), newCommitId, edit.get().getRefName());
        } else {
            // delete old edit ref on rebase
            prev = new ReceiveCommand(edit.get().getEditCommit(), ObjectId.zeroId(), edit.get().getRefName());
            createEditCommand();
        }
    } else {
        createEditCommand();
    }
    return true;
}
#method_after
private boolean newEdit() {
    psId = notes.getChange().currentPatchSetId();
    Optional<ChangeEdit> edit = null;
    try {
        edit = editUtil.byChange(notes, user);
    } catch (AuthException | IOException e) {
        logger.atSevere().withCause(e).log("Cannot retrieve edit");
        return false;
    }
    if (edit.isPresent()) {
        if (edit.get().getBasePatchSet().getId().equals(psId)) {
            // replace edit
            cmd = new ReceiveCommand(edit.get().getEditCommit(), newCommitId, edit.get().getRefName());
        } else {
            // delete old edit ref on rebase
            prev = new ReceiveCommand(edit.get().getEditCommit(), ObjectId.zeroId(), edit.get().getRefName());
            createEditCommand();
        }
    } else {
        createEditCommand();
    }
    return true;
}
#end_block

#method_before
@Override
public void postUpdate(Context ctx) {
    String refName = cmd.getRefName();
    if (cmd.getType() == ReceiveCommand.Type.UPDATE) {
        // aka fast-forward
        logDebug("Updating tag cache on fast-forward of %s", cmd.getRefName());
        tagCache.updateFastForward(project.getNameKey(), refName, cmd.getOldId(), cmd.getNewId());
    }
    if (isConfig(cmd)) {
        logDebug("Reloading project in cache");
        try {
            projectCache.evict(project);
        } catch (IOException e) {
            logger.atWarning().withCause(e).log("Cannot evict from project cache, name key: %s", project.getName());
        }
        ProjectState ps = projectCache.get(project.getNameKey());
        try {
            logDebug("Updating project description");
            repo.setGitwebDescription(ps.getProject().getDescription());
        } catch (IOException e) {
            logger.atWarning().withCause(e).log("cannot update description of %s", project.getName());
        }
        if (allProjectsName.equals(project.getNameKey())) {
            try {
                createGroupPermissionSyncer.syncIfNeeded();
            } catch (IOException | ConfigInvalidException e) {
                logger.atSevere().withCause(e).log("Can't sync create group permissions");
            }
        }
    }
}
#method_after
@Override
public void postUpdate(Context ctx) {
    String refName = cmd.getRefName();
    if (cmd.getType() == ReceiveCommand.Type.UPDATE) {
        // aka fast-forward
        logger.atFine().log("Updating tag cache on fast-forward of %s", cmd.getRefName());
        tagCache.updateFastForward(project.getNameKey(), refName, cmd.getOldId(), cmd.getNewId());
    }
    if (isConfig(cmd)) {
        logger.atFine().log("Reloading project in cache");
        try {
            projectCache.evict(project);
        } catch (IOException e) {
            logger.atWarning().withCause(e).log("Cannot evict from project cache, name key: %s", project.getName());
        }
        ProjectState ps = projectCache.get(project.getNameKey());
        try {
            logger.atFine().log("Updating project description");
            repo.setGitwebDescription(ps.getProject().getDescription());
        } catch (IOException e) {
            logger.atWarning().withCause(e).log("cannot update description of %s", project.getName());
        }
        if (allProjectsName.equals(project.getNameKey())) {
            try {
                createGroupPermissionSyncer.syncIfNeeded();
            } catch (IOException | ConfigInvalidException e) {
                logger.atSevere().withCause(e).log("Can't sync create group permissions");
            }
        }
    }
}
#end_block

#method_before
private void validateNewCommits(Branch.NameKey branch, ReceiveCommand cmd) throws PermissionBackendException {
    PermissionBackend.ForRef perm = permissions.ref(branch.get());
    if (!RefNames.REFS_CONFIG.equals(cmd.getRefName()) && !(MagicBranch.isMagicBranch(cmd.getRefName()) || NEW_PATCHSET_PATTERN.matcher(cmd.getRefName()).matches()) && pushOptions.containsKey(PUSH_OPTION_SKIP_VALIDATION)) {
        if (projectState.is(BooleanProjectConfig.USE_SIGNED_OFF_BY)) {
            reject(cmd, "requireSignedOffBy prevents option " + PUSH_OPTION_SKIP_VALIDATION);
            return;
        }
        Optional<AuthException> err = checkRefPermission(permissions.ref(branch.get()), RefPermission.SKIP_VALIDATION);
        if (err.isPresent()) {
            rejectProhibited(cmd, err.get());
            return;
        }
        if (!Iterables.isEmpty(rejectCommits)) {
            reject(cmd, "reject-commits prevents " + PUSH_OPTION_SKIP_VALIDATION);
            return;
        }
        logDebug("Short-circuiting new commit validation");
        return;
    }
    boolean missingFullName = Strings.isNullOrEmpty(user.getAccount().getFullName());
    RevWalk walk = receivePack.getRevWalk();
    walk.reset();
    walk.sort(RevSort.NONE);
    try {
        RevObject parsedObject = walk.parseAny(cmd.getNewId());
        if (!(parsedObject instanceof RevCommit)) {
            return;
        }
        ListMultimap<ObjectId, Ref> existing = changeRefsById();
        walk.markStart((RevCommit) parsedObject);
        markHeadsAsUninteresting(walk, cmd.getRefName());
        int limit = receiveConfig.maxBatchCommits;
        int n = 0;
        for (RevCommit c; (c = walk.next()) != null; ) {
            if (++n > limit) {
                logDebug("Number of new commits exceeds limit of %d", limit);
                addMessage(String.format("Cannot push more than %d commits to %s without %s option " + "(see %sDocumentation/user-upload.html#skip_validation for details)", limit, branch.get(), PUSH_OPTION_SKIP_VALIDATION, canonicalWebUrl));
                reject(cmd, "too many commits");
                return;
            }
            if (existing.keySet().contains(c)) {
                continue;
            } else if (!validCommit(walk, branch, cmd, c, null)) {
                break;
            }
            if (missingFullName && user.hasEmailAddress(c.getCommitterIdent().getEmailAddress())) {
                logDebug("Will update full name of caller");
                setFullNameTo = c.getCommitterIdent().getName();
                missingFullName = false;
            }
        }
        logDebug("Validated %d new commits", n);
    } catch (IOException err) {
        cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", err);
    }
}
#method_after
private void validateNewCommits(Branch.NameKey branch, ReceiveCommand cmd) throws PermissionBackendException {
    PermissionBackend.ForRef perm = permissions.ref(branch.get());
    if (!RefNames.REFS_CONFIG.equals(cmd.getRefName()) && !(MagicBranch.isMagicBranch(cmd.getRefName()) || NEW_PATCHSET_PATTERN.matcher(cmd.getRefName()).matches()) && pushOptions.containsKey(PUSH_OPTION_SKIP_VALIDATION)) {
        if (projectState.is(BooleanProjectConfig.USE_SIGNED_OFF_BY)) {
            reject(cmd, "requireSignedOffBy prevents option " + PUSH_OPTION_SKIP_VALIDATION);
            return;
        }
        Optional<AuthException> err = checkRefPermission(permissions.ref(branch.get()), RefPermission.SKIP_VALIDATION);
        if (err.isPresent()) {
            rejectProhibited(cmd, err.get());
            return;
        }
        if (!Iterables.isEmpty(rejectCommits)) {
            reject(cmd, "reject-commits prevents " + PUSH_OPTION_SKIP_VALIDATION);
        }
        logger.atFine().log("Short-circuiting new commit validation");
        return;
    }
    boolean missingFullName = Strings.isNullOrEmpty(user.getAccount().getFullName());
    RevWalk walk = receivePack.getRevWalk();
    walk.reset();
    walk.sort(RevSort.NONE);
    try {
        RevObject parsedObject = walk.parseAny(cmd.getNewId());
        if (!(parsedObject instanceof RevCommit)) {
            return;
        }
        ListMultimap<ObjectId, Ref> existing = changeRefsById();
        walk.markStart((RevCommit) parsedObject);
        markHeadsAsUninteresting(walk, cmd.getRefName());
        int limit = receiveConfig.maxBatchCommits;
        int n = 0;
        for (RevCommit c; (c = walk.next()) != null; ) {
            if (++n > limit) {
                logger.atFine().log("Number of new commits exceeds limit of %d", limit);
                addMessage(String.format("Cannot push more than %d commits to %s without %s option " + "(see %sDocumentation/user-upload.html#skip_validation for details)", limit, branch.get(), PUSH_OPTION_SKIP_VALIDATION, canonicalWebUrl));
                reject(cmd, "too many commits");
                return;
            }
            if (existing.keySet().contains(c)) {
                continue;
            } else if (!validCommit(walk, branch, cmd, c, null)) {
                break;
            }
            if (missingFullName && user.hasEmailAddress(c.getCommitterIdent().getEmailAddress())) {
                logger.atFine().log("Will update full name of caller");
                setFullNameTo = c.getCommitterIdent().getName();
                missingFullName = false;
            }
        }
        logger.atFine().log("Validated %d new commits", n);
    } catch (IOException err) {
        cmd.setResult(REJECTED_MISSING_OBJECT);
        logger.atSevere().withCause(err).log("Invalid pack upload; one or more objects weren't sent");
    }
}
#end_block

#method_before
private boolean validCommit(RevWalk rw, Branch.NameKey branch, ReceiveCommand cmd, ObjectId id, @Nullable Change change) throws IOException {
    PermissionBackend.ForRef perm = permissions.ref(branch.get());
    ValidCommitKey key = new AutoValue_ReceiveCommits_ValidCommitKey(id.copy(), branch);
    if (validCommits.contains(key)) {
        return true;
    }
    RevCommit c = rw.parseCommit(id);
    rw.parseBody(c);
    try (CommitReceivedEvent receiveEvent = new CommitReceivedEvent(cmd, project, branch.get(), rw.getObjectReader(), c, user)) {
        boolean isMerged = magicBranch != null && cmd.getRefName().equals(magicBranch.cmd.getRefName()) && magicBranch.merged;
        CommitValidators validators = isMerged ? commitValidatorsFactory.forMergedCommits(project.getNameKey(), perm, user.asIdentifiedUser()) : commitValidatorsFactory.forReceiveCommits(perm, branch, user.asIdentifiedUser(), sshInfo, repo, rw, change);
        messages.addAll(validators.validate(receiveEvent));
    } catch (CommitValidationException e) {
        logDebug("Commit validation failed on %s", c.name());
        messages.addAll(e.getMessages());
        reject(cmd, e.getMessage());
        return false;
    }
    validCommits.add(key);
    return true;
}
#method_after
private boolean validCommit(RevWalk rw, Branch.NameKey branch, ReceiveCommand cmd, ObjectId id, @Nullable Change change) throws IOException {
    PermissionBackend.ForRef perm = permissions.ref(branch.get());
    ValidCommitKey key = new AutoValue_ReceiveCommits_ValidCommitKey(id.copy(), branch);
    if (validCommits.contains(key)) {
        return true;
    }
    RevCommit c = rw.parseCommit(id);
    rw.parseBody(c);
    try (CommitReceivedEvent receiveEvent = new CommitReceivedEvent(cmd, project, branch.get(), rw.getObjectReader(), c, user)) {
        boolean isMerged = magicBranch != null && cmd.getRefName().equals(magicBranch.cmd.getRefName()) && magicBranch.merged;
        CommitValidators validators = isMerged ? commitValidatorsFactory.forMergedCommits(project.getNameKey(), perm, user.asIdentifiedUser()) : commitValidatorsFactory.forReceiveCommits(perm, branch, user.asIdentifiedUser(), sshInfo, repo, rw, change);
        messages.addAll(validators.validate(receiveEvent));
    } catch (CommitValidationException e) {
        logger.atFine().log("Commit validation failed on %s", c.name());
        messages.addAll(e.getMessages());
        reject(cmd, e.getMessage());
        return false;
    }
    validCommits.add(key);
    return true;
}
#end_block

#method_before
private void autoCloseChanges(ReceiveCommand cmd) {
    logDebug("Starting auto-closing of changes");
    String refName = cmd.getRefName();
    checkState(!MagicBranch.isMagicBranch(refName), "shouldn't be auto-closing changes on magic branch %s", refName);
    // insertChangesAndPatchSets.
    try {
        retryHelper.execute(updateFactory -> {
            try (BatchUpdate bu = updateFactory.create(db, projectState.getNameKey(), user, TimeUtil.nowTs());
                ObjectInserter ins = repo.newObjectInserter();
                ObjectReader reader = ins.newReader();
                RevWalk rw = new RevWalk(reader)) {
                bu.setRepository(repo, rw, ins).updateChangesInParallel();
                bu.setRequestId(receiveId);
                // TODO(dborowitz): Teach BatchUpdate to ignore missing changes.
                RevCommit newTip = rw.parseCommit(cmd.getNewId());
                Branch.NameKey branch = new Branch.NameKey(project.getNameKey(), refName);
                rw.reset();
                rw.markStart(newTip);
                if (!ObjectId.zeroId().equals(cmd.getOldId())) {
                    rw.markUninteresting(rw.parseCommit(cmd.getOldId()));
                }
                ListMultimap<ObjectId, Ref> byCommit = changeRefsById();
                Map<Change.Key, ChangeNotes> byKey = null;
                List<ReplaceRequest> replaceAndClose = new ArrayList<>();
                int existingPatchSets = 0;
                int newPatchSets = 0;
                COMMIT: for (RevCommit c; (c = rw.next()) != null; ) {
                    rw.parseBody(c);
                    for (Ref ref : byCommit.get(c.copy())) {
                        PatchSet.Id psId = PatchSet.Id.fromRef(ref.getName());
                        Optional<ChangeNotes> notes = getChangeNotes(psId.getParentKey());
                        if (notes.isPresent() && notes.get().getChange().getDest().equals(branch)) {
                            existingPatchSets++;
                            bu.addOp(psId.getParentKey(), mergedByPushOpFactory.create(requestScopePropagator, psId, refName));
                            continue COMMIT;
                        }
                    }
                    for (String changeId : c.getFooterLines(CHANGE_ID)) {
                        if (byKey == null) {
                            byKey = executeIndexQuery(() -> openChangesByKeyByBranch(branch));
                        }
                        ChangeNotes onto = byKey.get(new Change.Key(changeId.trim()));
                        if (onto != null) {
                            newPatchSets++;
                            // Hold onto this until we're done with the walk, as the call to
                            // req.validate below calls isMergedInto which resets the walk.
                            ReplaceRequest req = new ReplaceRequest(onto.getChangeId(), c, cmd, false);
                            req.notes = onto;
                            replaceAndClose.add(req);
                            continue COMMIT;
                        }
                    }
                }
                for (ReplaceRequest req : replaceAndClose) {
                    Change.Id id = req.notes.getChangeId();
                    if (!req.validate(true)) {
                        logDebug("Not closing %s because validation failed", id);
                        continue;
                    }
                    req.addOps(bu, null);
                    bu.addOp(id, mergedByPushOpFactory.create(requestScopePropagator, req.psId, refName).setPatchSetProvider(req.replaceOp::getPatchSet));
                    bu.addOp(id, new ChangeProgressOp(closeProgress));
                }
                logDebug("Auto-closing %s changes with existing patch sets and %s with new patch sets", existingPatchSets, newPatchSets);
                bu.execute();
            } catch (IOException | OrmException | PermissionBackendException e) {
                logError("Failed to auto-close changes", e);
            }
            return null;
        }, // eat up the whole timeout so that no time is left to retry this outer action.
        RetryHelper.options().timeout(retryHelper.getDefaultTimeout(ActionType.CHANGE_UPDATE).multipliedBy(5)).build());
    } catch (RestApiException e) {
        logError("Can't insert patchset", e);
    } catch (UpdateException e) {
        logError("Failed to auto-close changes", e);
    }
}
#method_after
private void autoCloseChanges(ReceiveCommand cmd) {
    logger.atFine().log("Starting auto-closing of changes");
    String refName = cmd.getRefName();
    checkState(!MagicBranch.isMagicBranch(refName), "shouldn't be auto-closing changes on magic branch %s", refName);
    // insertChangesAndPatchSets.
    try {
        retryHelper.execute(updateFactory -> {
            try (BatchUpdate bu = updateFactory.create(db, projectState.getNameKey(), user, TimeUtil.nowTs());
                ObjectInserter ins = repo.newObjectInserter();
                ObjectReader reader = ins.newReader();
                RevWalk rw = new RevWalk(reader)) {
                bu.setRepository(repo, rw, ins).updateChangesInParallel();
                // TODO(dborowitz): Teach BatchUpdate to ignore missing changes.
                RevCommit newTip = rw.parseCommit(cmd.getNewId());
                Branch.NameKey branch = new Branch.NameKey(project.getNameKey(), refName);
                rw.reset();
                rw.markStart(newTip);
                if (!ObjectId.zeroId().equals(cmd.getOldId())) {
                    rw.markUninteresting(rw.parseCommit(cmd.getOldId()));
                }
                ListMultimap<ObjectId, Ref> byCommit = changeRefsById();
                Map<Change.Key, ChangeNotes> byKey = null;
                List<ReplaceRequest> replaceAndClose = new ArrayList<>();
                int existingPatchSets = 0;
                int newPatchSets = 0;
                COMMIT: for (RevCommit c; (c = rw.next()) != null; ) {
                    rw.parseBody(c);
                    for (Ref ref : byCommit.get(c.copy())) {
                        PatchSet.Id psId = PatchSet.Id.fromRef(ref.getName());
                        Optional<ChangeNotes> notes = getChangeNotes(psId.getParentKey());
                        if (notes.isPresent() && notes.get().getChange().getDest().equals(branch)) {
                            existingPatchSets++;
                            bu.addOp(psId.getParentKey(), mergedByPushOpFactory.create(requestScopePropagator, psId, refName));
                            continue COMMIT;
                        }
                    }
                    for (String changeId : c.getFooterLines(CHANGE_ID)) {
                        if (byKey == null) {
                            byKey = executeIndexQuery(() -> openChangesByKeyByBranch(branch));
                        }
                        ChangeNotes onto = byKey.get(new Change.Key(changeId.trim()));
                        if (onto != null) {
                            newPatchSets++;
                            // Hold onto this until we're done with the walk, as the call to
                            // req.validate below calls isMergedInto which resets the walk.
                            ReplaceRequest req = new ReplaceRequest(onto.getChangeId(), c, cmd, false);
                            req.notes = onto;
                            replaceAndClose.add(req);
                            continue COMMIT;
                        }
                    }
                }
                for (ReplaceRequest req : replaceAndClose) {
                    Change.Id id = req.notes.getChangeId();
                    if (!req.validate(true)) {
                        logger.atFine().log("Not closing %s because validation failed", id);
                        continue;
                    }
                    req.addOps(bu, null);
                    bu.addOp(id, mergedByPushOpFactory.create(requestScopePropagator, req.psId, refName).setPatchSetProvider(req.replaceOp::getPatchSet));
                    bu.addOp(id, new ChangeProgressOp(closeProgress));
                }
                logger.atFine().log("Auto-closing %s changes with existing patch sets and %s with new patch sets", existingPatchSets, newPatchSets);
                bu.execute();
            } catch (IOException | OrmException | PermissionBackendException e) {
                logger.atSevere().withCause(e).log("Failed to auto-close changes");
            }
            return null;
        }, // eat up the whole timeout so that no time is left to retry this outer action.
        RetryHelper.options().timeout(retryHelper.getDefaultTimeout(ActionType.CHANGE_UPDATE).multipliedBy(5)).build());
    } catch (RestApiException e) {
        logger.atSevere().withCause(e).log("Can't insert patchset");
    } catch (UpdateException e) {
        logger.atSevere().withCause(e).log("Failed to auto-close changes");
    }
}
#end_block

#method_before
private void updateAccountInfo() {
    if (setFullNameTo == null) {
        return;
    }
    logDebug("Updating full name of caller");
    try {
        Optional<AccountState> accountState = accountsUpdateProvider.get().update("Set Full Name on Receive Commits", user.getAccountId(), (a, u) -> {
            if (Strings.isNullOrEmpty(a.getAccount().getFullName())) {
                u.setFullName(setFullNameTo);
            }
        });
        accountState.map(AccountState::getAccount).ifPresent(a -> user.getAccount().setFullName(a.getFullName()));
    } catch (OrmException | IOException | ConfigInvalidException e) {
        logWarn("Failed to update full name of caller", e);
    }
}
#method_after
private void updateAccountInfo() {
    if (setFullNameTo == null) {
        return;
    }
    logger.atFine().log("Updating full name of caller");
    try {
        Optional<AccountState> accountState = accountsUpdateProvider.get().update("Set Full Name on Receive Commits", user.getAccountId(), (a, u) -> {
            if (Strings.isNullOrEmpty(a.getAccount().getFullName())) {
                u.setFullName(setFullNameTo);
            }
        });
        accountState.map(AccountState::getAccount).ifPresent(a -> user.getAccount().setFullName(a.getFullName()));
    } catch (OrmException | IOException | ConfigInvalidException e) {
        logger.atWarning().withCause(e).log("Failed to update full name of caller");
    }
}
#end_block

#method_before
@Override
protected void updateRepoImpl(RepoContext ctx) throws IntegrationException {
    if (args.project.is(BooleanProjectConfig.REJECT_EMPTY_COMMIT)) {
        ObjectId oldTreeId = toMerge.getParentCount() > 0 ? toMerge.getParent(0).getTree() : EMPTY_TREE;
        if (toMerge.getTree().equals(oldTreeId)) {
            toMerge.setStatusCode(EMPTY_COMMIT);
            return;
        }
    }
    args.mergeTip.moveTipTo(toMerge, toMerge);
}
#method_after
@Override
protected void updateRepoImpl(RepoContext ctx) throws IntegrationException {
    if (args.project.is(BooleanProjectConfig.REJECT_EMPTY_COMMIT) && toMerge.getParentCount() > 0 && toMerge.getTree().equals(toMerge.getParent(0).getTree())) {
        toMerge.setStatusCode(EMPTY_COMMIT);
        return;
    }
    args.mergeTip.moveTipTo(toMerge, toMerge);
}
#end_block

#method_before
/**
 * Calculate the internal maps used by the operation.
 *
 * <p>In addition to the return value, the following fields are populated as a side effect:
 *
 * <ul>
 *   <li>{@link #affectedBranches}
 *   <li>{@link #targets}
 *   <li>{@link #branchesByProject}
 * </ul>
 *
 * @return the ordered set to be stored in {@link #sortedBranches}.
 * @throws SubmoduleException if an error occurred walking projects.
 */
// TODO(dborowitz): This setup process is hard to follow, in large part due to the accumulation of
// mutable maps, which makes this whole class difficult to understand.
// 
// A cleaner architecture for this process might be:
// 1. Separate out the code to parse submodule subscriptions and build up an in-memory data
// structure representing the subscription graph, using a separate class with a properly-
// documented interface.
// 2. Walk the graph to produce a work plan. This would be a list of items indicating: create a
// commit in project X updating reading branch tips for submodules S1..Sn and updating
// gitlinks in X.
// 3. Execute the work plan, i.e. convert the items into BatchUpdate.Ops and add them to the
// relevant updates.
// 
// In addition to improving readability, this approach has the advantage of making (1) and (2)
private ImmutableSet<Branch.NameKey> calculateSubscriptionMaps() throws SubmoduleException {
    if (!enableSuperProjectSubscriptions) {
        logDebug("Updating superprojects disabled");
        return null;
    }
    logDebug("Calculating superprojects - submodules map");
    LinkedHashSet<Branch.NameKey> allVisited = new LinkedHashSet<>();
    for (Branch.NameKey updatedBranch : updatedBranches) {
        if (allVisited.contains(updatedBranch)) {
            continue;
        }
        searchForSuperprojects(updatedBranch, new LinkedHashSet<>(), allVisited);
    }
    // Since the searchForSuperprojects will add all branches (related or
    // unrelated) and ensure the superproject's branches get added first before
    // a submodule branch. Need remove all unrelated branches and reverse
    // the order.
    allVisited.retainAll(affectedBranches);
    reverse(allVisited);
    return ImmutableSet.copyOf(allVisited);
}
#method_after
/**
 * Calculate the internal maps used by the operation.
 *
 * <p>In addition to the return value, the following fields are populated as a side effect:
 *
 * <ul>
 *   <li>{@link #affectedBranches}
 *   <li>{@link #targets}
 *   <li>{@link #branchesByProject}
 * </ul>
 *
 * @return the ordered set to be stored in {@link #sortedBranches}.
 * @throws SubmoduleException if an error occurred walking projects.
 */
// TODO(dborowitz): This setup process is hard to follow, in large part due to the accumulation of
// mutable maps, which makes this whole class difficult to understand.
// 
// A cleaner architecture for this process might be:
// 1. Separate out the code to parse submodule subscriptions and build up an in-memory data
// structure representing the subscription graph, using a separate class with a properly-
// documented interface.
// 2. Walk the graph to produce a work plan. This would be a list of items indicating: create a
// commit in project X reading branch tips for submodules S1..Sn and updating gitlinks in X.
// 3. Execute the work plan, i.e. convert the items into BatchUpdate.Ops and add them to the
// relevant updates.
// 
// In addition to improving readability, this approach has the advantage of making (1) and (2)
private ImmutableSet<Branch.NameKey> calculateSubscriptionMaps() throws SubmoduleException {
    if (!enableSuperProjectSubscriptions) {
        logDebug("Updating superprojects disabled");
        return null;
    }
    logDebug("Calculating superprojects - submodules map");
    LinkedHashSet<Branch.NameKey> allVisited = new LinkedHashSet<>();
    for (Branch.NameKey updatedBranch : updatedBranches) {
        if (allVisited.contains(updatedBranch)) {
            continue;
        }
        searchForSuperprojects(updatedBranch, new LinkedHashSet<>(), allVisited);
    }
    // Since the searchForSuperprojects will add all branches (related or
    // unrelated) and ensure the superproject's branches get added first before
    // a submodule branch. Need remove all unrelated branches and reverse
    // the order.
    allVisited.retainAll(affectedBranches);
    reverse(allVisited);
    return ImmutableSet.copyOf(allVisited);
}
#end_block

#method_before
@Test
public void fastForwardUpdateDenied() throws Exception {
    testRepo.branch("HEAD").commit().create();
    PushResult r = push("HEAD:refs/heads/master");
    assertThat(r).onlyRef("refs/heads/master").isRejected("prohibited by Gerrit: not permitted: update");
    assertThat(r).hasMessages("Branch refs/heads/master:", "To push into this reference you need 'Push' rights.", "User: admin", "Contact an administrator to fix the permissions");
    assertThat(r).hasProcessed(ImmutableMap.of("refs", 1));
}
#method_after
@Test
public void fastForwardUpdateDenied() throws Exception {
    testRepo.branch("HEAD").commit().create();
    PushResult r = push("HEAD:refs/heads/master");
    assertThat(r).onlyRef("refs/heads/master").isRejected("prohibited by Gerrit: ref update access denied");
    assertThat(r).hasMessages("Branch refs/heads/master:", "You are not allowed to perform this operation.", "To push into this reference you need 'Push' rights.", "User: admin", "Contact an administrator to fix the permissions");
    assertThat(r).hasProcessed(ImmutableMap.of("refs", 1));
}
#end_block

#method_before
@Test
public void nonFastForwardUpdateDenied() throws Exception {
    ObjectId commit = testRepo.commit().create();
    PushResult r = push("+" + commit.name() + ":refs/heads/master");
    assertThat(r).onlyRef("refs/heads/master").isRejected("prohibited by Gerrit: not permitted: force update");
    assertThat(r).hasProcessed(ImmutableMap.of("refs", 1));
}
#method_after
@Test
public void nonFastForwardUpdateDenied() throws Exception {
    ObjectId commit = testRepo.commit().create();
    PushResult r = push("+" + commit.name() + ":refs/heads/master");
    assertThat(r).onlyRef("refs/heads/master").isRejected("need 'Force Push' privilege.");
    assertThat(r).hasNoMessages();
    // TODO(dborowitz): Why does this not mention refs?
    assertThat(r).hasProcessed(ImmutableMap.of());
}
#end_block

#method_before
@Test
public void deleteDenied() throws Exception {
    PushResult r = push(":refs/heads/master");
    assertThat(r).onlyRef("refs/heads/master").isRejected("prohibited by Gerrit: not permitted: delete");
    assertThat(r).hasMessages("Branch refs/heads/master:", "You need 'Delete Reference' rights or 'Push' rights with the ", "'Force Push' flag set to delete references.", "User: admin", "Contact an administrator to fix the permissions");
    assertThat(r).hasProcessed(ImmutableMap.of("refs", 1));
}
#method_after
@Test
public void deleteDenied() throws Exception {
    PushResult r = push(":refs/heads/master");
    assertThat(r).onlyRef("refs/heads/master").isRejected("cannot delete references");
    assertThat(r).hasMessages("Branch refs/heads/master:", "You need 'Delete Reference' rights or 'Push' rights with the ", "'Force Push' flag set to delete references.", "User: admin", "Contact an administrator to fix the permissions");
    assertThat(r).hasProcessed(ImmutableMap.of("refs", 1));
}
#end_block

#method_before
@Test
public void createDenied() throws Exception {
    testRepo.branch("HEAD").commit().create();
    PushResult r = push("HEAD:refs/heads/newbranch");
    assertThat(r).onlyRef("refs/heads/newbranch").isRejected("prohibited by Gerrit: not permitted: create");
    assertThat(r).containsMessages("You need 'Create' rights to create new references.");
    assertThat(r).hasProcessed(ImmutableMap.of("refs", 1));
}
#method_after
@Test
public void createDenied() throws Exception {
    testRepo.branch("HEAD").commit().create();
    PushResult r = push("HEAD:refs/heads/newbranch");
    assertThat(r).onlyRef("refs/heads/newbranch").isRejected("prohibited by Gerrit: create not permitted for refs/heads/newbranch");
    assertThat(r).hasNoMessages();
    assertThat(r).hasProcessed(ImmutableMap.of("refs", 1));
}
#end_block

#method_before
@Test
public void groupRefsByMessage() throws Exception {
    try (Repository repo = repoManager.openRepository(project)) {
        TestRepository<?> tr = new TestRepository<>(repo);
        tr.branch("foo").commit().create();
        tr.branch("bar").commit().create();
    }
    testRepo.branch("HEAD").commit().create();
    PushResult r = push(":refs/heads/foo", ":refs/heads/bar", "HEAD:refs/heads/master");
    assertThat(r).ref("refs/heads/foo").isRejected("prohibited by Gerrit: not permitted: delete");
    assertThat(r).ref("refs/heads/bar").isRejected("prohibited by Gerrit: not permitted: delete");
    assertThat(r).ref("refs/heads/master").isRejected("prohibited by Gerrit: not permitted: update");
    assertThat(r).hasMessages("Branches refs/heads/foo, refs/heads/bar:", "You need 'Delete Reference' rights or 'Push' rights with the ", "'Force Push' flag set to delete references.", "Branch refs/heads/master:", "To push into this reference you need 'Push' rights.", "User: admin", "Contact an administrator to fix the permissions");
}
#method_after
@Test
public void groupRefsByMessage() throws Exception {
    try (Repository repo = repoManager.openRepository(project)) {
        TestRepository<?> tr = new TestRepository<>(repo);
        tr.branch("foo").commit().create();
        tr.branch("bar").commit().create();
    }
    testRepo.branch("HEAD").commit().create();
    PushResult r = push(":refs/heads/foo", ":refs/heads/bar", "HEAD:refs/heads/master");
    assertThat(r).ref("refs/heads/foo").isRejected("cannot delete references");
    assertThat(r).ref("refs/heads/bar").isRejected("cannot delete references");
    assertThat(r).ref("refs/heads/master").isRejected("prohibited by Gerrit: ref update access denied");
    assertThat(r).hasMessages("Branches refs/heads/foo, refs/heads/bar:", "You need 'Delete Reference' rights or 'Push' rights with the ", "'Force Push' flag set to delete references.", "Branch refs/heads/master:", "You are not allowed to perform this operation.", "To push into this reference you need 'Push' rights.", "User: admin", "Contact an administrator to fix the permissions");
}
#end_block

#method_before
@Test
public void refsMetaConfigUpdateRequiresProjectOwner() throws Exception {
    grant(project, "refs/meta/config", Permission.PUSH, false, REGISTERED_USERS);
    forceFetch("refs/meta/config");
    ObjectId commit = testRepo.branch("refs/meta/config").commit().create();
    PushResult r = push(commit.name() + ":refs/meta/config");
    assertThat(r).onlyRef("refs/meta/config").isRejected("prohibited by Gerrit: not permitted: update");
    assertThat(r).hasMessages("Branch refs/meta/config:", "Configuration changes can only be pushed by project owners", "who also have 'Push' rights on refs/meta/config", "User: admin", "Contact an administrator to fix the permissions");
    assertThat(r).hasProcessed(ImmutableMap.of("refs", 1));
    grant(project, "refs/*", Permission.OWNER, false, REGISTERED_USERS);
    // Re-fetch refs/meta/config from the server because the grant changed it, and we want a
    // fast-forward.
    forceFetch("refs/meta/config");
    commit = testRepo.branch("refs/meta/config").commit().create();
    assertThat(push(commit.name() + ":refs/meta/config")).onlyRef("refs/meta/config").isOk();
}
#method_after
@Test
public void refsMetaConfigUpdateRequiresProjectOwner() throws Exception {
    grant(project, "refs/meta/config", Permission.PUSH, false, REGISTERED_USERS);
    forceFetch("refs/meta/config");
    ObjectId commit = testRepo.branch("refs/meta/config").commit().create();
    PushResult r = push(commit.name() + ":refs/meta/config");
    assertThat(r).onlyRef("refs/meta/config").isRejected("prohibited by Gerrit: ref update access denied");
    assertThat(r).hasMessages("Branch refs/meta/config:", "You are not allowed to perform this operation.", "Configuration changes can only be pushed by project owners", "who also have 'Push' rights on refs/meta/config", "User: admin", "Contact an administrator to fix the permissions");
    assertThat(r).hasProcessed(ImmutableMap.of("refs", 1));
    grant(project, "refs/*", Permission.OWNER, false, REGISTERED_USERS);
    // Re-fetch refs/meta/config from the server because the grant changed it, and we want a
    // fast-forward.
    forceFetch("refs/meta/config");
    commit = testRepo.branch("refs/meta/config").commit().create();
    assertThat(push(commit.name() + ":refs/meta/config")).onlyRef("refs/meta/config").isOk();
}
#end_block

#method_before
@Test
public void createChangeDenied() throws Exception {
    testRepo.branch("HEAD").commit().create();
    PushResult r = push("HEAD:refs/for/master");
    assertThat(r).onlyRef("refs/for/master").isRejected("prohibited by Gerrit: not permitted: create change on refs/heads/master");
    assertThat(r).containsMessages("Branch refs/for/master:", "You need 'Create Change' rights to upload code review requests.", "Verify that you are pushing to the right branch.");
    assertThat(r).hasProcessed(ImmutableMap.of("refs", 1));
}
#method_after
@Test
public void createChangeDenied() throws Exception {
    testRepo.branch("HEAD").commit().create();
    PushResult r = push("HEAD:refs/for/master");
    assertThat(r).onlyRef("refs/for/master").isRejected("create change not permitted for refs/heads/master");
    assertThat(r).hasMessages("Branch refs/heads/master:", "You need 'Push' rights to upload code review requests.", "Verify that you are pushing to the right branch.", "User: admin", "Contact an administrator to fix the permissions");
    assertThat(r).hasProcessed(ImmutableMap.of("refs", 1));
}
#end_block

#method_before
@Test
public void updateBySubmitDenied() throws Exception {
    grant(project, "refs/for/refs/heads/*", Permission.PUSH, false, REGISTERED_USERS);
    ObjectId commit = testRepo.branch("HEAD").commit().create();
    assertThat(push("HEAD:refs/for/master")).onlyRef("refs/for/master").isOk();
    gApi.changes().id(commit.name()).current().review(ReviewInput.approve());
    PushResult r = push("HEAD:refs/for/master%submit");
    assertThat(r).onlyRef("refs/for/master%submit").isRejected("prohibited by Gerrit: not permitted: update by submit on refs/heads/master");
    assertThat(r).containsMessages("You need 'Submit' rights on refs/for/ to submit changes during change upload.");
    assertThat(r).hasProcessed(ImmutableMap.of("refs", 1));
}
#method_after
@Test
public void updateBySubmitDenied() throws Exception {
    grant(project, "refs/for/refs/heads/*", Permission.PUSH, false, REGISTERED_USERS);
    ObjectId commit = testRepo.branch("HEAD").commit().create();
    assertThat(push("HEAD:refs/for/master")).onlyRef("refs/for/master").isOk();
    gApi.changes().id(commit.name()).current().review(ReviewInput.approve());
    PushResult r = push("HEAD:refs/for/master%submit");
    assertThat(r).onlyRef("refs/for/master%submit").isRejected("update by submit not permitted for refs/heads/master");
    assertThat(r).hasNoMessages();
    assertThat(r).hasProcessed(ImmutableMap.of("refs", 1));
}
#end_block

#method_before
@Test
public void skipValidationDenied() throws Exception {
    grant(project, "refs/heads/*", Permission.PUSH, false, REGISTERED_USERS);
    testRepo.branch("HEAD").commit().create();
    PushResult r = push(c -> c.setPushOptions(ImmutableList.of("skip-validation")), "HEAD:refs/heads/master");
    assertThat(r).onlyRef("refs/heads/master").isRejected("prohibited by Gerrit: not permitted: skip validation");
    assertThat(r).containsMessages("You need 'Forge Author', 'Forge Server', 'Forge Committer'", "and 'Push Merge' rights to skip validation.");
    assertThat(r).hasProcessed(ImmutableMap.of("refs", 1));
}
#method_after
@Test
public void skipValidationDenied() throws Exception {
    grant(project, "refs/heads/*", Permission.PUSH, false, REGISTERED_USERS);
    testRepo.branch("HEAD").commit().create();
    PushResult r = push(c -> c.setPushOptions(ImmutableList.of("skip-validation")), "HEAD:refs/heads/master");
    assertThat(r).onlyRef("refs/heads/master").isRejected("skip validation not permitted for refs/heads/master");
    assertThat(r).hasNoMessages();
    assertThat(r).hasProcessed(ImmutableMap.of("refs", 1));
}
#end_block

#method_before
public void removeProjectEventsAsync(String projectName) {
    pool.submit(() -> eventsDb.removeProjectEvents(projectName));
    pool.submit(() -> localEventsDb.removeProjectEvents(projectName));
}
#method_after
public void removeProjectEventsAsync(String projectName) {
    pool.submit(() -> eventsDb.removeProjectEvents(projectName));
}
#end_block

#method_before
public void scheduleCleaningWith(int maxAge, long initialDelay, long interval) {
    pool.scheduleAtFixedRate(() -> eventsDb.removeOldEvents(maxAge), initialDelay, interval, TimeUnit.MILLISECONDS);
    pool.scheduleAtFixedRate(() -> localEventsDb.removeOldEvents(maxAge), initialDelay, interval, TimeUnit.MILLISECONDS);
}
#method_after
public void scheduleCleaningWith(int maxAge) {
    pool.scheduleAtFixedRate(() -> eventsDb.removeOldEvents(maxAge), getInitialDelay(), INTERVAL, TimeUnit.SECONDS);
}
#end_block

#method_before
@Override
public void start() {
    setUp();
    if (isPeriodicCleaningEnabled()) {
        eventsLogCleaner.scheduleCleaningWith(maxAge, initialDelay, interval);
    }
}
#method_after
@Override
public void start() {
    setUp();
    eventsLogCleaner.scheduleCleaningWith(maxAge);
}
#end_block

#method_before
private void setUp() {
    try {
        getEventsDb().createDBIfNotCreated();
    } catch (SQLException e) {
        log.warn("Cannot start the database. Events will be stored locally" + " until database connection can be established", e);
        setOnline(false);
    }
    if (online) {
        restoreEventsFromLocal();
    }
    if (!isPeriodicCleaningEnabled()) {
        eventsLogCleaner.removeOldEventsAsync(maxAge);
    }
}
#method_after
private void setUp() {
    try {
        getEventsDb().createDBIfNotCreated();
    } catch (SQLException e) {
        log.warn("Cannot start the database. Events will be stored locally" + " until database connection can be established", e);
        setOnline(false);
    }
    if (online) {
        restoreEventsFromLocal();
    }
}
#end_block

#method_before
private void setUpClient() {
    config.setJdbcUrl(TEST_URL);
    eventsDb = new SQLClient(config);
    config.setJdbcUrl(TEST_LOCAL_URL);
    localEventsDb = new SQLClient(config);
    store = new SQLStore(pcFactoryMock, userProviderMock, cfgMock, eventsDb, localEventsDb, poolMock);
    store.start();
}
#method_after
private void setUpClient() {
    config.setJdbcUrl(TEST_URL);
    eventsDb = new SQLClient(config);
    config.setJdbcUrl(TEST_LOCAL_URL);
    localEventsDb = new SQLClient(config);
    store = new SQLStore(pcFactoryMock, userProviderMock, cfgMock, eventsDb, localEventsDb, poolMock, logCleanerMock);
    store.start();
}
#end_block

#method_before
@Test
public void notReturnEventOfNonExistingProject() throws Exception {
    MockEvent mockEvent = new MockEvent();
    Project.NameKey projectMock = mock(Project.NameKey.class);
    CurrentUser userMock = mock(CurrentUser.class);
    when(userProviderMock.get()).thenReturn(userMock);
    NameKey projectNameKey = mockEvent.getProjectNameKey();
    doThrow(new NoSuchProjectException(projectMock)).when(pcFactoryMock).controlFor(projectNameKey, userMock);
    setUpClient();
    store.storeEvent(mockEvent);
    List<String> events = store.queryChangeEvents(GENERIC_QUERY);
    assertThat(events).isEmpty();
    tearDown();
}
#method_after
@Test
public void notReturnEventOfNonExistingProject() throws Exception {
    MockEvent mockEvent = new MockEvent();
    Project.NameKey projectMock = mock(Project.NameKey.class);
    CurrentUser userMock = mock(CurrentUser.class);
    when(userProviderMock.get()).thenReturn(userMock);
    NameKey projectNameKey = mockEvent.getProjectNameKey();
    doThrow(new NoSuchProjectException(projectMock)).when(pcFactoryMock).controlFor(projectNameKey, userMock);
    setUpClient();
    store.storeEvent(mockEvent);
    List<String> events = store.queryChangeEvents(GENERIC_QUERY);
    assertThat(events).isEmpty();
    verify(logCleanerMock).removeProjectEventsAsync(mockEvent.project);
    tearDown();
}
#end_block

#method_before
@Test
public void retryOnConnectException() throws Exception {
    MockEvent mockEvent = new MockEvent();
    when(cfgMock.getMaxTries()).thenReturn(3);
    Throwable[] exceptions = new Throwable[3];
    Arrays.fill(exceptions, new SQLException(new ConnectException()));
    setUpClientMock();
    doThrow(exceptions).doNothing().when(eventsDb).storeEvent(mockEvent);
    doThrow(exceptions).doNothing().when(eventsDb).queryOne();
    store = new SQLStore(pcFactoryMock, userProviderMock, cfgMock, eventsDb, localEventsDb, poolMock);
    store.start();
    store.storeEvent(mockEvent);
    verify(eventsDb, times(3)).storeEvent(mockEvent);
    verify(localEventsDb).storeEvent(mockEvent);
}
#method_after
@Test
public void retryOnConnectException() throws Exception {
    MockEvent mockEvent = new MockEvent();
    when(cfgMock.getMaxTries()).thenReturn(3);
    Throwable[] exceptions = new Throwable[3];
    Arrays.fill(exceptions, new SQLException(new ConnectException()));
    setUpClientMock();
    doThrow(exceptions).doNothing().when(eventsDb).storeEvent(mockEvent);
    doThrow(exceptions).doNothing().when(eventsDb).queryOne();
    store = new SQLStore(pcFactoryMock, userProviderMock, cfgMock, eventsDb, localEventsDb, poolMock, logCleanerMock);
    store.start();
    store.storeEvent(mockEvent);
    verify(eventsDb, times(3)).storeEvent(mockEvent);
    verify(localEventsDb).storeEvent(mockEvent);
}
#end_block

#method_before
@Test
public void retryOnMessage() throws Exception {
    MockEvent mockEvent = new MockEvent();
    when(cfgMock.getMaxTries()).thenReturn(3);
    Throwable[] exceptions = new Throwable[3];
    Arrays.fill(exceptions, new SQLException(TERM_CONN_MSG));
    setUpClientMock();
    doThrow(exceptions).doNothing().when(eventsDb).storeEvent(mockEvent);
    doThrow(exceptions).doNothing().when(eventsDb).queryOne();
    store = new SQLStore(pcFactoryMock, userProviderMock, cfgMock, eventsDb, localEventsDb, poolMock);
    store.start();
    store.storeEvent(mockEvent);
    verify(eventsDb, times(3)).storeEvent(mockEvent);
    verify(localEventsDb).storeEvent(mockEvent);
}
#method_after
@Test
public void retryOnMessage() throws Exception {
    MockEvent mockEvent = new MockEvent();
    when(cfgMock.getMaxTries()).thenReturn(3);
    Throwable[] exceptions = new Throwable[3];
    Arrays.fill(exceptions, new SQLException(TERM_CONN_MSG));
    setUpClientMock();
    doThrow(exceptions).doNothing().when(eventsDb).storeEvent(mockEvent);
    doThrow(exceptions).doNothing().when(eventsDb).queryOne();
    store = new SQLStore(pcFactoryMock, userProviderMock, cfgMock, eventsDb, localEventsDb, poolMock, logCleanerMock);
    store.start();
    store.storeEvent(mockEvent);
    verify(eventsDb, times(3)).storeEvent(mockEvent);
    verify(localEventsDb).storeEvent(mockEvent);
}
#end_block

#method_before
@Test
public void noRetryOnMessage() throws Exception {
    MockEvent mockEvent = new MockEvent();
    when(cfgMock.getMaxTries()).thenReturn(3);
    setUpClientMock();
    doThrow(new SQLException(MSG)).when(eventsDb).storeEvent(mockEvent);
    store = new SQLStore(pcFactoryMock, userProviderMock, cfgMock, eventsDb, localEventsDb, poolMock);
    store.start();
    store.storeEvent(mockEvent);
    verify(eventsDb, times(1)).storeEvent(mockEvent);
}
#method_after
@Test
public void noRetryOnMessage() throws Exception {
    MockEvent mockEvent = new MockEvent();
    when(cfgMock.getMaxTries()).thenReturn(3);
    setUpClientMock();
    doThrow(new SQLException(MSG)).when(eventsDb).storeEvent(mockEvent);
    store = new SQLStore(pcFactoryMock, userProviderMock, cfgMock, eventsDb, localEventsDb, poolMock, logCleanerMock);
    store.start();
    store.storeEvent(mockEvent);
    verify(eventsDb, times(1)).storeEvent(mockEvent);
}
#end_block

#method_before
@Test
public void noRetryOnZeroMaxTries() throws Exception {
    MockEvent mockEvent = new MockEvent();
    when(cfgMock.getMaxTries()).thenReturn(0);
    Throwable[] exceptions = new Throwable[3];
    Arrays.fill(exceptions, new SQLException(new ConnectException()));
    setUpClientMock();
    doThrow(exceptions).doNothing().when(eventsDb).storeEvent(mockEvent);
    doThrow(exceptions).doNothing().when(eventsDb).queryOne();
    store = new SQLStore(pcFactoryMock, userProviderMock, cfgMock, eventsDb, localEventsDb, poolMock);
    store.start();
    store.storeEvent(mockEvent);
    verify(eventsDb, times(1)).storeEvent(mockEvent);
}
#method_after
@Test
public void noRetryOnZeroMaxTries() throws Exception {
    MockEvent mockEvent = new MockEvent();
    when(cfgMock.getMaxTries()).thenReturn(0);
    Throwable[] exceptions = new Throwable[3];
    Arrays.fill(exceptions, new SQLException(new ConnectException()));
    setUpClientMock();
    doThrow(exceptions).doNothing().when(eventsDb).storeEvent(mockEvent);
    doThrow(exceptions).doNothing().when(eventsDb).queryOne();
    store = new SQLStore(pcFactoryMock, userProviderMock, cfgMock, eventsDb, localEventsDb, poolMock, logCleanerMock);
    store.start();
    store.storeEvent(mockEvent);
    verify(eventsDb, times(1)).storeEvent(mockEvent);
}
#end_block

#method_before
@Test(expected = ServiceUnavailableException.class)
public void throwSQLExceptionIfNotOnline() throws Exception {
    MockEvent mockEvent = new MockEvent();
    setUpClientMock();
    doThrow(new SQLException(new ConnectException())).when(eventsDb).createDBIfNotCreated();
    doThrow(new SQLException()).when(eventsDb).queryOne();
    store = new SQLStore(pcFactoryMock, userProviderMock, cfgMock, eventsDb, localEventsDb, poolMock);
    store.start();
    store.storeEvent(mockEvent);
    store.queryChangeEvents(GENERIC_QUERY);
}
#method_after
@Test(expected = ServiceUnavailableException.class)
public void throwSQLExceptionIfNotOnline() throws Exception {
    MockEvent mockEvent = new MockEvent();
    setUpClientMock();
    doThrow(new SQLException(new ConnectException())).when(eventsDb).createDBIfNotCreated();
    doThrow(new SQLException()).when(eventsDb).queryOne();
    store = new SQLStore(pcFactoryMock, userProviderMock, cfgMock, eventsDb, localEventsDb, poolMock, logCleanerMock);
    store.start();
    store.storeEvent(mockEvent);
    store.queryChangeEvents(GENERIC_QUERY);
}
#end_block

#method_before
@Test
public void restoreFromLocalAndRemoveUnfoundProjectEvents() throws Exception {
    MockEvent mockEvent = new MockEvent();
    MockEvent mockEvent2 = new MockEvent("proj");
    MockEvent mockEvent3 = new MockEvent("unfound");
    ProjectControl pc = mock(ProjectControl.class);
    NoSuchProjectException e = mock(NoSuchProjectException.class);
    CurrentUser userMock = mock(CurrentUser.class);
    when(userProviderMock.get()).thenReturn(userMock);
    when(pcFactoryMock.controlFor((mockEvent.getProjectNameKey()), userMock)).thenReturn(pc);
    when(pcFactoryMock.controlFor((mockEvent2.getProjectNameKey()), userMock)).thenReturn(pc);
    when(pc.isVisible()).thenReturn(true);
    doThrow(e).when(pcFactoryMock).controlFor((mockEvent3.getProjectNameKey()), userMock);
    config.setJdbcUrl(TEST_URL);
    eventsDb = new SQLClient(config);
    config.setJdbcUrl(TEST_LOCAL_URL);
    localEventsDb = new SQLClient(config);
    store = new SQLStore(pcFactoryMock, userProviderMock, cfgMock, eventsDb, localEventsDb, poolMock);
    localEventsDb.createDBIfNotCreated();
    localEventsDb.storeEvent(mockEvent);
    localEventsDb.storeEvent(mockEvent2);
    localEventsDb.storeEvent(mockEvent3);
    store.start();
    List<String> events = store.queryChangeEvents(GENERIC_QUERY);
    Gson gson = new Gson();
    String json = gson.toJson(mockEvent);
    String json2 = gson.toJson(mockEvent2);
    assertThat(events).containsExactly(json, json2).inOrder();
    tearDown();
}
#method_after
@Test
public void restoreFromLocalAndRemoveUnfoundProjectEvents() throws Exception {
    MockEvent mockEvent = new MockEvent();
    MockEvent mockEvent2 = new MockEvent("proj");
    MockEvent mockEvent3 = new MockEvent("unfound");
    ProjectControl pc = mock(ProjectControl.class);
    NoSuchProjectException e = mock(NoSuchProjectException.class);
    CurrentUser userMock = mock(CurrentUser.class);
    when(userProviderMock.get()).thenReturn(userMock);
    when(pcFactoryMock.controlFor((mockEvent.getProjectNameKey()), userMock)).thenReturn(pc);
    when(pcFactoryMock.controlFor((mockEvent2.getProjectNameKey()), userMock)).thenReturn(pc);
    when(pc.isVisible()).thenReturn(true);
    doThrow(e).when(pcFactoryMock).controlFor((mockEvent3.getProjectNameKey()), userMock);
    config.setJdbcUrl(TEST_URL);
    eventsDb = new SQLClient(config);
    config.setJdbcUrl(TEST_LOCAL_URL);
    localEventsDb = new SQLClient(config);
    store = new SQLStore(pcFactoryMock, userProviderMock, cfgMock, eventsDb, localEventsDb, poolMock, logCleanerMock);
    localEventsDb.createDBIfNotCreated();
    localEventsDb.storeEvent(mockEvent);
    localEventsDb.storeEvent(mockEvent2);
    localEventsDb.storeEvent(mockEvent3);
    store.start();
    List<String> events = store.queryChangeEvents(GENERIC_QUERY);
    Gson gson = new Gson();
    String json = gson.toJson(mockEvent);
    String json2 = gson.toJson(mockEvent2);
    assertThat(events).containsExactly(json, json2).inOrder();
    tearDown();
}
#end_block

#method_before
@Test
public void offlineUponStart() throws Exception {
    setUpClientMock();
    doThrow(new SQLException(new ConnectException())).when(eventsDb).createDBIfNotCreated();
    doThrow(new SQLException()).when(eventsDb).queryOne();
    store = new SQLStore(pcFactoryMock, userProviderMock, cfgMock, eventsDb, localEventsDb, poolMock);
    store.start();
    verify(localEventsDb).createDBIfNotCreated();
}
#method_after
@Test
public void offlineUponStart() throws Exception {
    setUpClientMock();
    doThrow(new SQLException(new ConnectException())).when(eventsDb).createDBIfNotCreated();
    doThrow(new SQLException()).when(eventsDb).queryOne();
    store = new SQLStore(pcFactoryMock, userProviderMock, cfgMock, eventsDb, localEventsDb, poolMock, logCleanerMock);
    store.start();
    verify(localEventsDb).createDBIfNotCreated();
}
#end_block

#method_before
@Test
public void storeLocalOffline() throws Exception {
    MockEvent mockEvent = new MockEvent();
    setUpClientMock();
    doThrow(new SQLException(new ConnectException())).when(eventsDb).createDBIfNotCreated();
    doThrow(new SQLException()).when(eventsDb).queryOne();
    store = new SQLStore(pcFactoryMock, userProviderMock, cfgMock, eventsDb, localEventsDb, poolMock);
    store.start();
    store.storeEvent(mockEvent);
    verify(localEventsDb).storeEvent(mockEvent);
}
#method_after
@Test
public void storeLocalOffline() throws Exception {
    MockEvent mockEvent = new MockEvent();
    setUpClientMock();
    doThrow(new SQLException(new ConnectException())).when(eventsDb).createDBIfNotCreated();
    doThrow(new SQLException()).when(eventsDb).queryOne();
    store = new SQLStore(pcFactoryMock, userProviderMock, cfgMock, eventsDb, localEventsDb, poolMock, logCleanerMock);
    store.start();
    store.storeEvent(mockEvent);
    verify(localEventsDb).storeEvent(mockEvent);
}
#end_block

#method_before
@Test
public void storeLocalOfflineAfterNoRetry() throws Exception {
    MockEvent mockEvent = new MockEvent();
    setUpClientMock();
    when(cfgMock.getMaxTries()).thenReturn(0);
    doThrow(new SQLException(new ConnectException())).when(eventsDb).createDBIfNotCreated();
    doThrow(new SQLException()).when(eventsDb).queryOne();
    store = new SQLStore(pcFactoryMock, userProviderMock, cfgMock, eventsDb, localEventsDb, poolMock);
    store.start();
    store.storeEvent(mockEvent);
    verify(localEventsDb).storeEvent(mockEvent);
}
#method_after
@Test
public void storeLocalOfflineAfterNoRetry() throws Exception {
    MockEvent mockEvent = new MockEvent();
    setUpClientMock();
    when(cfgMock.getMaxTries()).thenReturn(0);
    doThrow(new SQLException(new ConnectException())).when(eventsDb).createDBIfNotCreated();
    doThrow(new SQLException()).when(eventsDb).queryOne();
    store = new SQLStore(pcFactoryMock, userProviderMock, cfgMock, eventsDb, localEventsDb, poolMock, logCleanerMock);
    store.start();
    store.storeEvent(mockEvent);
    verify(localEventsDb).storeEvent(mockEvent);
}
#end_block

#method_before
@Test
public void testConnectionTask() throws Exception {
    config.setJdbcUrl(TEST_URL);
    eventsDb = new SQLClient(config);
    localEventsDb = mock(SQLClient.class);
    when(localEventsDb.dbExists()).thenReturn(true);
    when(localEventsDb.getAll()).thenReturn(ImmutableList.of(mock(SQLEntry.class)));
    store = new SQLStore(pcFactoryMock, userProviderMock, cfgMock, eventsDb, localEventsDb, poolMock);
    store.start();
    poolMock.scheduleWithFixedDelay(store.new CheckConnectionTask(), 0, 0, TimeUnit.MILLISECONDS);
    verify(localEventsDb, times(2)).removeOldEvents(0);
}
#method_after
@Test
public void testConnectionTask() throws Exception {
    config.setJdbcUrl(TEST_URL);
    eventsDb = new SQLClient(config);
    localEventsDb = mock(SQLClient.class);
    when(localEventsDb.dbExists()).thenReturn(true);
    when(localEventsDb.getAll()).thenReturn(ImmutableList.of(mock(SQLEntry.class)));
    store = new SQLStore(pcFactoryMock, userProviderMock, cfgMock, eventsDb, localEventsDb, poolMock, logCleanerMock);
    store.start();
    poolMock.scheduleWithFixedDelay(store.new CheckConnectionTask(), 0, 0, TimeUnit.MILLISECONDS);
    verify(localEventsDb, times(2)).removeOldEvents(0);
}
#end_block

#method_before
private void checkConnectionAndRestore(boolean copy) throws Exception {
    MockEvent mockEvent = new MockEvent();
    eventsDb = mock(SQLClient.class);
    config.setJdbcUrl(TEST_LOCAL_URL);
    localEventsDb = new SQLClient(config);
    localEventsDb.createDBIfNotCreated();
    localEventsDb.storeEvent(mockEvent);
    doThrow(new SQLException(new ConnectException())).doNothing().when(eventsDb).createDBIfNotCreated();
    if (copy) {
        when(cfgMock.getCopyLocal()).thenReturn(true);
    }
    store = new SQLStore(pcFactoryMock, userProviderMock, cfgMock, eventsDb, localEventsDb, poolMock);
    store.start();
    verify(eventsDb).queryOne();
    verify(eventsDb).storeEvent(any(String.class), any(Timestamp.class), any(String.class));
    List<SQLEntry> entries = localEventsDb.getAll();
    assertThat(entries).isEmpty();
}
#method_after
private void checkConnectionAndRestore(boolean copy) throws Exception {
    MockEvent mockEvent = new MockEvent();
    eventsDb = mock(SQLClient.class);
    config.setJdbcUrl(TEST_LOCAL_URL);
    localEventsDb = new SQLClient(config);
    localEventsDb.createDBIfNotCreated();
    localEventsDb.storeEvent(mockEvent);
    doThrow(new SQLException(new ConnectException())).doNothing().when(eventsDb).createDBIfNotCreated();
    if (copy) {
        when(cfgMock.getCopyLocal()).thenReturn(true);
    }
    store = new SQLStore(pcFactoryMock, userProviderMock, cfgMock, eventsDb, localEventsDb, poolMock, logCleanerMock);
    store.start();
    verify(eventsDb).queryOne();
    verify(eventsDb).storeEvent(any(String.class), any(Timestamp.class), any(String.class));
    List<SQLEntry> entries = localEventsDb.getAll();
    assertThat(entries).isEmpty();
}
#end_block

#method_before
void removeOldEvents(int maxAge) {
    try {
        execute(format("DELETE FROM %s WHERE %s < '%s'", TABLE_NAME, DATE_ENTRY, new Timestamp(System.currentTimeMillis() - MILLISECONDS.convert(maxAge, DAYS))));
    } catch (SQLException e) {
        log.warn("Cannot remove old event entries from database", e);
    }
}
#method_after
void removeOldEvents(int maxAge) {
    try {
        execute(format("DELETE FROM %s WHERE %s < '%s'", TABLE_NAME, DATE_ENTRY, new Timestamp(System.currentTimeMillis() - MILLISECONDS.convert(maxAge, DAYS))));
        log.info("Events older than {} days were removed from database {}", maxAge, ds.getPoolName());
    } catch (SQLException e) {
        log.warn("Cannot remove old event entries from database {}", ds.getPoolName(), e);
    }
}
#end_block

#method_before
@Provides
@Singleton
@EventsDb
SQLClient provideSqlClient(EventsLogConfig cfg) {
    HikariConfig dsConfig = new HikariConfig();
    dsConfig.setJdbcUrl(cfg.getStoreUrl());
    dsConfig.setUsername(cfg.getStoreUsername());
    dsConfig.setPassword(cfg.getStorePassword());
    dsConfig.setPoolName("events-log EventsDb pool");
    dsConfig.setMaximumPoolSize(cfg.getMaxConnections());
    setDataSourceOptions(cfg, dsConfig);
    return new SQLClient(dsConfig);
}
#method_after
@Provides
@Singleton
@EventsDb
SQLClient provideSqlClient(EventsLogConfig cfg, @PluginName String pluginName) {
    HikariConfig dsConfig = new HikariConfig();
    dsConfig.setJdbcUrl(cfg.getStoreUrl());
    dsConfig.setUsername(cfg.getStoreUsername());
    dsConfig.setPassword(cfg.getStorePassword());
    dsConfig.setPoolName("[" + pluginName + "] EventsDb");
    dsConfig.setMaximumPoolSize(cfg.getMaxConnections());
    setDataSourceOptions(cfg, dsConfig);
    return new SQLClient(dsConfig);
}
#end_block

#method_before
@Provides
@Singleton
@LocalEventsDb
SQLClient provideLocalSqlClient(EventsLogConfig cfg) {
    HikariConfig dsConfig = new HikariConfig();
    dsConfig.setJdbcUrl(H2_DB_PREFIX + cfg.getLocalStorePath().resolve(SQLTable.TABLE_NAME));
    dsConfig.setPoolName("events-log LocalEventsDb pool");
    setDataSourceOptions(cfg, dsConfig);
    return new SQLClient(dsConfig);
}
#method_after
@Provides
@Singleton
@LocalEventsDb
SQLClient provideLocalSqlClient(EventsLogConfig cfg, @PluginName String pluginName) {
    HikariConfig dsConfig = new HikariConfig();
    dsConfig.setJdbcUrl(H2_DB_PREFIX + cfg.getLocalStorePath().resolve(SQLTable.TABLE_NAME));
    dsConfig.setPoolName("[" + pluginName + "] LocalEventsDb");
    setDataSourceOptions(cfg, dsConfig);
    return new SQLClient(dsConfig);
}
#end_block

#method_before
public void delete(Project project) throws OrmException {
    // TODO(davido): Why not to use 1.7 features?
    // http://docs.oracle.com/javase/specs/jls/se7/html/jls-14.html#jls-14.20.3.2
    Connection conn = ((JdbcSchema) getDb()).getConnection();
    try {
        conn.setAutoCommit(false);
        try {
            PreparedStatement changesForProject = conn.prepareStatement("SELECT change_id FROM changes WHERE dest_project_name = ?");
            changesForProject.setString(1, project.getName());
            java.sql.ResultSet resultSet = changesForProject.executeQuery();
            List<Change.Id> changeIds = new ArrayList<>();
            while (resultSet.next()) {
                changeIds.add(new Change.Id(resultSet.getInt(1)));
            }
            atomicDelete(project, changeIds);
            conn.commit();
        } finally {
            conn.setAutoCommit(true);
        }
    } catch (SQLException e) {
        try {
            conn.rollback();
        } catch (SQLException ex) {
            throw new OrmException(ex);
        }
        throw new OrmException(e);
    }
}
#method_after
public void delete(Project project) throws OrmException {
    // TODO(davido): Why not to use 1.7 features?
    // http://docs.oracle.com/javase/specs/jls/se7/html/jls-14.html#jls-14.20.3.2
    ReviewDb db = ReviewDbUtil.unwrapDb(dbProvider.get());
    Connection conn = ((JdbcSchema) db).getConnection();
    try {
        conn.setAutoCommit(false);
        try {
            PreparedStatement changesForProject = conn.prepareStatement("SELECT change_id FROM changes WHERE dest_project_name = ?");
            changesForProject.setString(1, project.getName());
            java.sql.ResultSet resultSet = changesForProject.executeQuery();
            List<Change.Id> changeIds = new ArrayList<>();
            while (resultSet.next()) {
                changeIds.add(new Change.Id(resultSet.getInt(1)));
            }
            atomicDelete(db, project, changeIds);
            conn.commit();
        } finally {
            conn.setAutoCommit(true);
        }
    } catch (SQLException e) {
        try {
            conn.rollback();
        } catch (SQLException ex) {
            throw new OrmException(ex);
        }
        throw new OrmException(e);
    }
}
#end_block

#method_before
private final void deleteChanges(Project.NameKey project, List<Change.Id> changeIds) throws OrmException {
    for (Change.Id id : changeIds) {
        try {
            starredChangesUtil.unstarAll(project, id);
        } catch (NoSuchChangeException e) {
        // we can ignore the exception during delete
        }
        ResultSet<PatchSet> patchSets = null;
        patchSets = getDb().patchSets().byChange(id);
        if (patchSets != null) {
            deleteFromPatchSets(patchSets);
        }
        // In the future, use schemaVersion to decide what to delete.
        getDb().patchComments().delete(getDb().patchComments().byChange(id));
        getDb().patchSetApprovals().delete(getDb().patchSetApprovals().byChange(id));
        getDb().changeMessages().delete(getDb().changeMessages().byChange(id));
        getDb().changes().deleteKeys(Collections.singleton(id));
        // Delete from the secondary index
        try {
            indexer.delete(id);
        } catch (IOException e) {
            log.error("Failed to delete change {} from index", id, e);
        }
    }
}
#method_after
private final void deleteChanges(ReviewDb db, Project.NameKey project, List<Change.Id> changeIds) throws OrmException {
    for (Change.Id id : changeIds) {
        try {
            starredChangesUtil.unstarAll(project, id);
        } catch (NoSuchChangeException e) {
        // we can ignore the exception during delete
        }
        ResultSet<PatchSet> patchSets = db.patchSets().byChange(id);
        if (patchSets != null) {
            deleteFromPatchSets(db, patchSets);
        }
        // In the future, use schemaVersion to decide what to delete.
        db.patchComments().delete(db.patchComments().byChange(id));
        db.patchSetApprovals().delete(db.patchSetApprovals().byChange(id));
        db.changeMessages().delete(db.changeMessages().byChange(id));
        db.changes().deleteKeys(Collections.singleton(id));
        // Delete from the secondary index
        try {
            indexer.delete(id);
        } catch (IOException e) {
            log.error("Failed to delete change {} from index", id, e);
        }
    }
}
#end_block

#method_before
private final void deleteFromPatchSets(final ResultSet<PatchSet> patchSets) throws OrmException {
    for (PatchSet patchSet : patchSets) {
        accountPatchReviewStore.get().clearReviewed(patchSet.getId());
        getDb().patchSets().delete(Collections.singleton(patchSet));
    }
}
#method_after
private final void deleteFromPatchSets(ReviewDb db, final ResultSet<PatchSet> patchSets) throws OrmException {
    for (PatchSet patchSet : patchSets) {
        accountPatchReviewStore.get().clearReviewed(patchSet.getId());
        db.patchSets().delete(Collections.singleton(patchSet));
    }
}
#end_block

#method_before
public void atomicDelete(Project project, List<Change.Id> changeIds) throws OrmException {
    deleteChanges(project.getNameKey(), changeIds);
    for (AccountState a : accountQueryProvider.get().byWatchedProject(project.getNameKey())) {
        Account.Id accountId = a.getAccount().getId();
        for (ProjectWatchKey watchKey : a.getProjectWatches().keySet()) {
            if (project.getNameKey().equals(watchKey.project())) {
                try {
                    watchConfig.get().deleteProjectWatches(accountId, singleton(watchKey));
                } catch (IOException | ConfigInvalidException e) {
                    log.error("Removing watch entry for user {} in project {} failed.", a.getUserName(), project.getName(), e);
                }
            }
        }
    }
}
#method_after
public void atomicDelete(ReviewDb db, Project project, List<Change.Id> changeIds) throws OrmException {
    deleteChanges(db, project.getNameKey(), changeIds);
    for (AccountState a : accountQueryProvider.get().byWatchedProject(project.getNameKey())) {
        Account.Id accountId = a.getAccount().getId();
        for (ProjectWatchKey watchKey : a.getProjectWatches().keySet()) {
            if (project.getNameKey().equals(watchKey.project())) {
                try {
                    watchConfig.get().deleteProjectWatches(accountId, singleton(watchKey));
                } catch (IOException | ConfigInvalidException e) {
                    log.error("Removing watch entry for user {} in project {} failed.", a.getUserName(), project.getName(), e);
                }
            }
        }
    }
}
#end_block

#method_before
@Override
public Object apply(CommitResource resource) throws PatchListNotAvailableException {
    RevCommit commit = resource.getCommit();
    PatchListKey key;
    if (parentNum > 0) {
        key = PatchListKey.againstParentNum(parentNum, commit, DiffPreferencesInfo.Whitespace.IGNORE_NONE);
    } else {
        key = PatchListKey.againstCommit(null, commit, DiffPreferencesInfo.Whitespace.IGNORE_NONE);
    }
    return Response.ok(fileInfoJson.toFileInfoMap(resource.getProjectState().getNameKey(), key));
}
#method_after
@Override
public Object apply(CommitResource resource) throws PatchListNotAvailableException {
    RevCommit commit = resource.getCommit();
    PatchListKey key;
    if (parentNum > 0) {
        key = PatchListKey.againstParentNum(parentNum, commit, DiffPreferencesInfo.Whitespace.IGNORE_NONE);
    } else {
        key = PatchListKey.againstCommit(null, commit, DiffPreferencesInfo.Whitespace.IGNORE_NONE);
    }
    return fileInfoJson.toFileInfoMap(resource.getProjectState().getNameKey(), key);
}
#end_block

#method_before
private boolean shouldBlock(HttpServletRequest request) {
    String method = request.getMethod();
    String servletPath = request.getServletPath();
    return !servletPath.endsWith(endpoint) && (("POST".equals(method) && !servletPath.equals(GIT_UPLOAD_PACK_PROTOCOL)) || "PUT".equals(method) || "DELETE".equals(method));
}
#method_after
private boolean shouldBlock(HttpServletRequest request) {
    String method = request.getMethod();
    String servletPath = request.getServletPath();
    return !servletPath.endsWith(endpoint) && (("POST".equals(method) && !servletPath.endsWith(GIT_UPLOAD_PACK_PROTOCOL)) || "PUT".equals(method) || "DELETE".equals(method));
}
#end_block

#method_before
@Override
protected void configureCommands() {
    DynamicItem.bind(binder(), SshCreateCommandInterceptor.class).to(DisableCommandInterceptor.class);
    command(DisableCommand.class);
    // Register "readonly" command
    command(PutReadOnlyCommand.class);
    // Add "on" alias for "readonly" command
    alias("on", PutReadOnlyCommand.class);
    // Register "ready" command
    command(PutReadyCommand.class);
    // Add "off" alias for "ready" command
    alias("off", PutReadyCommand.class);
    // Add "status" command
    command(GetStateCommand.class);
}
#method_after
@Override
protected void configureCommands() {
    DynamicItem.bind(binder(), SshCreateCommandInterceptor.class).to(DisableCommandInterceptor.class);
    command(DisableCommand.class);
    command(PutReadOnlyCommand.class);
    alias("on", PutReadOnlyCommand.class);
    command(DeleteReadOnlyCommand.class);
    alias("off", DeleteReadOnlyCommand.class);
    command(GetReadOnlyCommand.class);
    alias("status", GetReadOnlyCommand.class);
}
#end_block

#method_before
@Override
protected void run() throws IOException {
    putReadOnly.apply(null, null);
}
#method_after
@Override
protected void run() throws IOException {
    put.apply(null, null);
}
#end_block

#method_before
@Override
protected void configure() {
    DynamicSet.bind(binder(), CommitValidationListener.class).to(ReadOnly.class);
    install(new RestApiModule() {

        @Override
        protected void configure() {
            put(CONFIG_KIND, "readonly").to(PutReadOnly.class);
            put(CONFIG_KIND, "ready").to(PutReady.class);
            get(CONFIG_KIND, "state").to(GetState.class);
        }
    });
}
#method_after
@Override
protected void configure() {
    DynamicSet.bind(binder(), CommitValidationListener.class).to(ReadOnly.class);
    install(new RestApiModule() {

        @Override
        protected void configure() {
            put(CONFIG_KIND, "readonly").to(ReadOnlyEndpoint.Put.class);
            delete(CONFIG_KIND, "readonly").to(ReadOnlyEndpoint.Delete.class);
            get(CONFIG_KIND, "readonly").to(ReadOnlyEndpoint.Get.class);
        }
    });
}
#end_block

#method_before
@Test
public void maxObjectSizeIsNotSetByDefault() throws Exception {
    ConfigInfo info = getConfig();
    assertThat(info.maxObjectSizeLimit.configuredValue).isNull();
    assertThat(info.maxObjectSizeLimit.inheritedValue).isNull();
}
#method_after
@Test
public void maxObjectSizeIsNotSetByDefault() throws Exception {
    ConfigInfo info = getConfig();
    assertThat(info.maxObjectSizeLimit.value).isNull();
    assertThat(info.maxObjectSizeLimit.configuredValue).isNull();
    assertThat(info.maxObjectSizeLimit.inheritedValue).isNull();
}
#end_block

#method_before
@Test
public void maxObjectSizeCanBeSetAndCleared() throws Exception {
    // Set a value
    ConfigInput input = new ConfigInput();
    input.maxObjectSizeLimit = "100k";
    ConfigInfo info = setConfig(input);
    assertThat(info.maxObjectSizeLimit.configuredValue).isEqualTo("100k");
    assertThat(info.maxObjectSizeLimit.inheritedValue).isNull();
    // Clear the value
    input.maxObjectSizeLimit = "0";
    info = setConfig(input);
    assertThat(info.maxObjectSizeLimit.configuredValue).isEqualTo("0");
    assertThat(info.maxObjectSizeLimit.inheritedValue).isNull();
}
#method_after
@Test
public void maxObjectSizeCanBeSetAndCleared() throws Exception {
    // Set a value
    ConfigInput input = new ConfigInput();
    input.maxObjectSizeLimit = "100k";
    ConfigInfo info = setConfig(input);
    // TODO: Should be "100k"
    assertThat(info.maxObjectSizeLimit.value).isNull();
    assertThat(info.maxObjectSizeLimit.configuredValue).isEqualTo("100k");
    assertThat(info.maxObjectSizeLimit.inheritedValue).isNull();
    // Clear the value
    input.maxObjectSizeLimit = "0";
    info = setConfig(input);
    // TODO: Should be null
    assertThat(info.maxObjectSizeLimit.value).isEqualTo("0");
    // TODO: Should be null
    assertThat(info.maxObjectSizeLimit.configuredValue).isEqualTo("0");
    assertThat(info.maxObjectSizeLimit.inheritedValue).isNull();
}
#end_block

#method_before
@Test
public void deleteCannotBeAppliedWithoutAdministrateServerCapability() throws Exception {
    int changeNum = createOneChange();
    setApiUser(user);
    exception.expect(AuthException.class);
    exception.expectMessage("administrate server not permitted");
    deleteOneChangeMessage(changeNum, 0, user, "spam");
}
#method_after
@Test
public void deleteCannotBeAppliedWithoutAdministrateServerCapability() throws Exception {
    int changeNum = createOneChangeWithMultipleChangeMessagesInHistory();
    setApiUser(user);
    try {
        deleteOneChangeMessage(changeNum, 0, user, "spam");
        fail("expected AuthException");
    } catch (AuthException e) {
        assertThat(e.getMessage()).isEqualTo("administrate server not permitted");
    }
}
#end_block

#method_before
@Test
public void deleteCanBeAppliedWithAdministrateServerCapability() throws Exception {
    allowGlobalCapabilities(REGISTERED_USERS, GlobalCapability.ADMINISTRATE_SERVER);
    int changeNum = createOneChange();
    setApiUser(user);
    deleteOneChangeMessage(changeNum, 0, user, "spam");
}
#method_after
@Test
public void deleteCanBeAppliedWithAdministrateServerCapability() throws Exception {
    allowGlobalCapabilities(REGISTERED_USERS, GlobalCapability.ADMINISTRATE_SERVER);
    int changeNum = createOneChangeWithMultipleChangeMessagesInHistory();
    setApiUser(user);
    deleteOneChangeMessage(changeNum, 0, user, "spam");
}
#end_block

#method_before
@Test
public void deleteCannotBeAppliedWithEmptyChangeMessageUuid() throws Exception {
    String changeId = createChange().getChangeId();
    exception.expect(BadRequestException.class);
    exception.expectMessage("change message uuid is required");
    gApi.changes().id(changeId).deleteChangeMessage(new DeleteChangeMessageInput("", "spam"));
}
#method_after
@Test
public void deleteCannotBeAppliedWithEmptyChangeMessageUuid() throws Exception {
    String changeId = createChange().getChangeId();
    try {
        gApi.changes().id(changeId).message("").delete(new DeleteChangeMessageInput("spam"));
        fail("expected ResourceNotFoundException");
    } catch (ResourceNotFoundException e) {
        assertThat(e.getMessage()).isEqualTo("change message  not found");
    }
}
#end_block

#method_before
@Test
public void deleteCannotBeAppliedWithNonExistingChangeMessageUuid() throws Exception {
    String changeId = createChange().getChangeId();
    DeleteChangeMessageInput input = new DeleteChangeMessageInput();
    input.uuid = "8473b95934b5732ac55d26311a706c9c2bde9941";
    input.reason = "spam";
    exception.expect(ResourceNotFoundException.class);
    exception.expectMessage(String.format("change message %s not found", input.uuid));
    gApi.changes().id(changeId).deleteChangeMessage(input);
}
#method_after
@Test
public void deleteCannotBeAppliedWithNonExistingChangeMessageUuid() throws Exception {
    String changeId = createChange().getChangeId();
    DeleteChangeMessageInput input = new DeleteChangeMessageInput();
    String id = "8473b95934b5732ac55d26311a706c9c2bde9941";
    input.reason = "spam";
    try {
        gApi.changes().id(changeId).message(id).delete(input);
        fail("expected ResourceNotFoundException");
    } catch (ResourceNotFoundException e) {
        assertThat(e.getMessage()).isEqualTo(String.format("change message %s not found", id));
    }
}
#end_block

#method_before
@Test
public void deleteCanBeAppliedWithoutProvidingReason() throws Exception {
    int changeNum = createOneChange();
    deleteOneChangeMessage(changeNum, 2, admin, "");
}
#method_after
@Test
public void deleteCanBeAppliedWithoutProvidingReason() throws Exception {
    int changeNum = createOneChangeWithMultipleChangeMessagesInHistory();
    deleteOneChangeMessage(changeNum, 2, admin, "");
}
#end_block

#method_before
@Test
public void deleteOneChangeMessageTwice() throws Exception {
    int changeNum = createOneChange();
    // Deletes the second change message twice.
    deleteOneChangeMessage(changeNum, 1, admin, "reason 1");
    deleteOneChangeMessage(changeNum, 1, admin, "reason 2");
}
#method_after
@Test
public void deleteOneChangeMessageTwice() throws Exception {
    int changeNum = createOneChangeWithMultipleChangeMessagesInHistory();
    // Deletes the second change message twice.
    deleteOneChangeMessage(changeNum, 1, admin, "reason 1");
    deleteOneChangeMessage(changeNum, 1, admin, "reason 2");
}
#end_block

#method_before
@Test
public void deleteMultipleChangeMessages() throws Exception {
    int changeNum = createOneChange();
    for (int i = 0; i < 7; ++i) {
        deleteOneChangeMessage(changeNum, i, admin, "reason " + i);
    }
}
#method_after
@Test
public void deleteMultipleChangeMessages() throws Exception {
    int changeNum = createOneChangeWithMultipleChangeMessagesInHistory();
    for (int i = 0; i < 7; ++i) {
        deleteOneChangeMessage(changeNum, i, admin, "reason " + i);
    }
}
#end_block

#method_before
private void deleteOneChangeMessage(int changeNum, int deletedMessageIndex, TestAccount deletedBy, String reason) throws Exception {
    List<ChangeMessageInfo> messagesBefore = getAllChangeMessages(changeNum);
    List<CommentInfo> commentsBefore = getChangeSortedComments(changeNum);
    List<RevCommit> commitsBefore = new ArrayList<>();
    if (notesMigration.readChanges()) {
        commitsBefore = getCommits(new Change.Id(changeNum), RevSort.REVERSE);
    }
    DeleteChangeMessageInput input = new DeleteChangeMessageInput(messagesBefore.get(deletedMessageIndex).id, reason);
    gApi.changes().id(changeNum).deleteChangeMessage(input);
    assertMessagesAfterDeletion(changeNum, messagesBefore, deletedMessageIndex, deletedBy, reason);
    assertCommentsAfterDeletion(changeNum, commentsBefore);
    if (notesMigration.readChanges()) {
        // Verifies states of commits if NoteDb is on.
        assertMetaCommitsAfterDeletion(commitsBefore, changeNum, deletedMessageIndex, deletedBy, reason);
    }
}
#method_after
private void deleteOneChangeMessage(int changeNum, int deletedMessageIndex, TestAccount deletedBy, String reason) throws Exception {
    List<ChangeMessageInfo> messagesBeforeDeletion = gApi.changes().id(changeNum).messages();
    List<CommentInfo> commentsBefore = getChangeSortedComments(changeNum);
    List<RevCommit> commitsBefore = new ArrayList<>();
    if (notesMigration.readChanges()) {
        commitsBefore = getChangeMetaCommitsInReverseOrder(new Change.Id(changeNum));
    }
    String id = messagesBeforeDeletion.get(deletedMessageIndex).id;
    DeleteChangeMessageInput input = new DeleteChangeMessageInput(reason);
    ChangeMessageInfo info = gApi.changes().id(changeNum).message(id).delete(input);
    // Verify the return change message info is as expect.
    assertThat(info.message).isEqualTo(createNewChangeMessage(deletedBy.fullName, reason));
    List<ChangeMessageInfo> messagesAfterDeletion = gApi.changes().id(changeNum).messages();
    assertMessagesAfterDeletion(messagesBeforeDeletion, messagesAfterDeletion, deletedMessageIndex, deletedBy, reason);
    assertCommentsAfterDeletion(changeNum, commentsBefore);
    // Verify change index is updated after deletion.
    List<ChangeInfo> changes = gApi.changes().query("message removed").get();
    assertThat(changes.stream().map(c -> c._number).collect(toSet())).contains(changeNum);
    // Verifies states of commits if NoteDb is on.
    if (notesMigration.readChanges()) {
        assertMetaCommitsAfterDeletion(commitsBefore, changeNum, deletedMessageIndex, deletedBy, reason);
    }
}
#end_block

#method_before
private void assertMessagesAfterDeletion(int changeNum, List<ChangeMessageInfo> messagesBeforeDeletion, int deletedMessageIndex, TestAccount deletedBy, String deleteReason) throws Exception {
    List<ChangeMessageInfo> messagesAfterDeletion = getAllChangeMessages(changeNum);
    assertThat(messagesAfterDeletion).hasSize(messagesBeforeDeletion.size());
    for (int i = 0; i < messagesAfterDeletion.size(); ++i) {
        ChangeMessageInfo before = messagesBeforeDeletion.get(i);
        ChangeMessageInfo after = messagesAfterDeletion.get(i);
        if (i < deletedMessageIndex) {
            // The uuid of a commit message will be updated after rewriting.
            assertThat(after.id).isEqualTo(before.id);
        }
        assertThat(after.tag).isEqualTo(before.tag);
        assertThat(after.author).isEqualTo(before.author);
        assertThat(after.realAuthor).isEqualTo(before.realAuthor);
        assertThat(after._revisionNumber).isEqualTo(before._revisionNumber);
        if (i == deletedMessageIndex) {
            assertThat(after.message).isEqualTo(createNewChangeMessage(deletedBy.fullName, deleteReason));
        } else {
            assertThat(after.message).isEqualTo(before.message);
        }
    }
}
#method_after
private void assertMessagesAfterDeletion(List<ChangeMessageInfo> messagesBeforeDeletion, List<ChangeMessageInfo> messagesAfterDeletion, int deletedMessageIndex, TestAccount deletedBy, String deleteReason) {
    assertThat(messagesAfterDeletion).named("after: %s; before: %s", messagesAfterDeletion, messagesBeforeDeletion).hasSize(messagesBeforeDeletion.size());
    for (int i = 0; i < messagesAfterDeletion.size(); ++i) {
        ChangeMessageInfo before = messagesBeforeDeletion.get(i);
        ChangeMessageInfo after = messagesAfterDeletion.get(i);
        if (i < deletedMessageIndex) {
            // The uuid of a commit message will be updated after rewriting.
            assertThat(after.id).isEqualTo(before.id);
        }
        assertThat(after.tag).isEqualTo(before.tag);
        assertThat(after.author).isEqualTo(before.author);
        assertThat(after.realAuthor).isEqualTo(before.realAuthor);
        assertThat(after._revisionNumber).isEqualTo(before._revisionNumber);
        if (i == deletedMessageIndex) {
            assertThat(after.message).isEqualTo(createNewChangeMessage(deletedBy.fullName, deleteReason));
        } else {
            assertThat(after.message).isEqualTo(before.message);
        }
    }
}
#end_block

#method_before
private void assertMetaCommitsAfterDeletion(List<RevCommit> commitsBeforeDeletion, int changeNum, int deletedMessageIndex, TestAccount deletedBy, String deleteReason) throws Exception {
    List<RevCommit> commitsAfterDeletion = getCommits(new Change.Id(changeNum), RevSort.REVERSE);
    assertThat(commitsAfterDeletion).hasSize(commitsBeforeDeletion.size());
    for (int i = 0; i < commitsBeforeDeletion.size(); i++) {
        RevCommit commitBefore = commitsBeforeDeletion.get(i);
        RevCommit commitAfter = commitsAfterDeletion.get(i);
        if (i == deletedMessageIndex) {
            byte[] rawBefore = commitBefore.getRawBuffer();
            byte[] rawAfter = commitAfter.getRawBuffer();
            Charset encodingBefore = RawParseUtils.parseEncoding(rawBefore);
            Charset encodingAfter = RawParseUtils.parseEncoding(rawAfter);
            Optional<ChangeNotesParser.Range> rangeBefore = parseCommitMessageRange(commitBefore);
            Optional<ChangeNotesParser.Range> rangeAfter = parseCommitMessageRange(commitAfter);
            assertThat(rangeBefore.isPresent()).isTrue();
            assertThat(rangeAfter.isPresent()).isTrue();
            String subjectBefore = decode(encodingBefore, rawBefore, rangeBefore.get().subjectStart(), rangeBefore.get().subjectEnd());
            String subjectAfter = decode(encodingAfter, rawAfter, rangeAfter.get().subjectStart(), rangeAfter.get().subjectEnd());
            assertThat(subjectBefore).isEqualTo(subjectAfter);
            String footersBefore = decode(encodingBefore, rawBefore, rangeBefore.get().changeMessageEnd() + 1, rawBefore.length);
            String footersAfter = decode(encodingAfter, rawAfter, rangeAfter.get().changeMessageEnd() + 1, rawAfter.length);
            assertThat(footersBefore).isEqualTo(footersAfter);
            String message = decode(encodingAfter, rawAfter, rangeAfter.get().changeMessageStart(), rangeAfter.get().changeMessageEnd() + 1);
            assertThat(message).isEqualTo(createNewChangeMessage(deletedBy.fullName, deleteReason));
        } else {
            assertThat(commitAfter.getFullMessage()).isEqualTo(commitBefore.getFullMessage());
        }
        assertThat(commitAfter.getCommitterIdent().getName()).isEqualTo(commitBefore.getCommitterIdent().getName());
        assertThat(commitAfter.getAuthorIdent().getName()).isEqualTo(commitBefore.getAuthorIdent().getName());
        assertThat(commitAfter.getEncoding()).isEqualTo(commitBefore.getEncoding());
        assertThat(commitAfter.getEncodingName()).isEqualTo(commitBefore.getEncodingName());
    }
}
#method_after
private void assertMetaCommitsAfterDeletion(List<RevCommit> commitsBeforeDeletion, int changeNum, int deletedMessageIndex, TestAccount deletedBy, String deleteReason) throws Exception {
    List<RevCommit> commitsAfterDeletion = getChangeMetaCommitsInReverseOrder(new Change.Id(changeNum));
    assertThat(commitsAfterDeletion).hasSize(commitsBeforeDeletion.size());
    for (int i = 0; i < commitsBeforeDeletion.size(); i++) {
        RevCommit commitBefore = commitsBeforeDeletion.get(i);
        RevCommit commitAfter = commitsAfterDeletion.get(i);
        if (i == deletedMessageIndex) {
            byte[] rawBefore = commitBefore.getRawBuffer();
            byte[] rawAfter = commitAfter.getRawBuffer();
            Charset encodingBefore = RawParseUtils.parseEncoding(rawBefore);
            Charset encodingAfter = RawParseUtils.parseEncoding(rawAfter);
            Optional<ChangeNoteUtil.CommitMessageRange> rangeBefore = parseCommitMessageRange(commitBefore);
            Optional<ChangeNoteUtil.CommitMessageRange> rangeAfter = parseCommitMessageRange(commitAfter);
            assertThat(rangeBefore.isPresent()).isTrue();
            assertThat(rangeAfter.isPresent()).isTrue();
            String subjectBefore = decode(encodingBefore, rawBefore, rangeBefore.get().subjectStart(), rangeBefore.get().subjectEnd());
            String subjectAfter = decode(encodingAfter, rawAfter, rangeAfter.get().subjectStart(), rangeAfter.get().subjectEnd());
            assertThat(subjectBefore).isEqualTo(subjectAfter);
            String footersBefore = decode(encodingBefore, rawBefore, rangeBefore.get().changeMessageEnd() + 1, rawBefore.length);
            String footersAfter = decode(encodingAfter, rawAfter, rangeAfter.get().changeMessageEnd() + 1, rawAfter.length);
            assertThat(footersBefore).isEqualTo(footersAfter);
            String message = decode(encodingAfter, rawAfter, rangeAfter.get().changeMessageStart(), rangeAfter.get().changeMessageEnd() + 1);
            assertThat(message).isEqualTo(createNewChangeMessage(deletedBy.fullName, deleteReason));
        } else {
            assertThat(commitAfter.getFullMessage()).isEqualTo(commitBefore.getFullMessage());
        }
        assertThat(commitAfter.getCommitterIdent().getName()).isEqualTo(commitBefore.getCommitterIdent().getName());
        assertThat(commitAfter.getAuthorIdent().getName()).isEqualTo(commitBefore.getAuthorIdent().getName());
        assertThat(commitAfter.getEncoding()).isEqualTo(commitBefore.getEncoding());
        assertThat(commitAfter.getEncodingName()).isEqualTo(commitBefore.getEncodingName());
    }
}
#end_block

#method_before
@Override
public Response<ChangeInfo> applyImpl(BatchUpdate.Factory updateFactory, ChangeResource resource, DeleteChangeMessageInput input) throws Exception {
    CurrentUser user = userProvider.get();
    permissionBackend.user(user).check(GlobalPermission.ADMINISTRATE_SERVER);
    if (input == null || input.uuid == null || input.uuid.isEmpty()) {
        throw new BadRequestException("change message uuid is required");
    }
    checkChangeMessageExists(input.uuid, resource.getNotes());
    String newChangeMessage = createNewChangeMessage(user.asIdentifiedUser().getName(), input.reason);
    DeleteChangeMessageOp deleteChangeMessageOp = new DeleteChangeMessageOp(input.uuid, newChangeMessage);
    try (BatchUpdate batchUpdate = updateFactory.create(dbProvider.get(), resource.getProject(), user, TimeUtil.nowTs())) {
        batchUpdate.addOp(resource.getId(), deleteChangeMessageOp).execute();
    }
    ChangeJson json = jsonFactory.noOptions();
    return Response.created(json.format(resource.getChange()));
}
#method_after
@Override
public Response<ChangeMessageInfo> applyImpl(BatchUpdate.Factory updateFactory, ChangeMessageResource resource, DeleteChangeMessageInput input) throws RestApiException, PermissionBackendException, OrmException, UpdateException, IOException {
    CurrentUser user = userProvider.get();
    permissionBackend.user(user).check(GlobalPermission.ADMINISTRATE_SERVER);
    String newChangeMessage = createNewChangeMessage(user.asIdentifiedUser().getName(), input.reason);
    DeleteChangeMessageOp deleteChangeMessageOp = new DeleteChangeMessageOp(resource.getChangeMessageIndex(), newChangeMessage);
    try (BatchUpdate batchUpdate = updateFactory.create(dbProvider.get(), resource.getChangeResource().getProject(), user, TimeUtil.nowTs())) {
        batchUpdate.addOp(resource.getChangeId(), deleteChangeMessageOp).execute();
    }
    ChangeMessageInfo updatedMessageInfo = createUpdatedChangeMessageInfo(resource.getChangeId(), resource.getChangeMessageIndex());
    return Response.created(updatedMessageInfo);
}
#end_block

#method_before
@VisibleForTesting
public static String createNewChangeMessage(String deletedBy, String deletedReason) {
    if (Strings.isNullOrEmpty(deletedReason)) {
        return createNewChangeMessage(deletedBy);
    }
    return String.format("Change message removed by: %s; Reason: %s", deletedBy, deletedReason);
}
#method_after
@VisibleForTesting
public static String createNewChangeMessage(String deletedBy, @Nullable String deletedReason) {
    checkNotNull(deletedBy, "user name must not be null");
    if (Strings.isNullOrEmpty(deletedReason)) {
        return createNewChangeMessage(deletedBy);
    }
    return String.format("Change message removed by: %s\nReason: %s", deletedBy, deletedReason);
}
#end_block

#method_before
@VisibleForTesting
public static String createNewChangeMessage(String deletedBy) {
    return "Change message removed by: " + deletedBy;
}
#method_after
@VisibleForTesting
public static String createNewChangeMessage(String deletedBy) {
    checkNotNull(deletedBy, "user name must not be null");
    return "Change message removed by: " + deletedBy;
}
#end_block

#method_before
@Override
public boolean updateChange(ChangeContext ctx) throws OrmException {
    PatchSet.Id psId = ctx.getChange().currentPatchSetId();
    changeMessagesUtil.deleteChangeMessageByRewritingHistory(ctx.getDb(), ctx.getUpdate(psId), uuid, newMessage);
    return true;
}
#method_after
@Override
public boolean updateChange(ChangeContext ctx) throws OrmException {
    PatchSet.Id psId = ctx.getChange().currentPatchSetId();
    changeMessagesUtil.replaceChangeMessage(ctx.getDb(), ctx.getUpdate(psId), targetMessageIdx, newMessage);
    return true;
}
#end_block

#method_before
public void deleteChangeMessageByRewritingHistory(String uuid, String newMessage) {
    deleteChangeMessageRewriter = deleteChangeMessageRewriterFactory.create(getChange().getId(), uuid, newMessage);
}
#method_after
public void deleteChangeMessageByRewritingHistory(int targetMessageIdx, String newMessage) {
    deleteChangeMessageRewriter = new DeleteChangeMessageRewriter(getChange().getId(), targetMessageIdx, newMessage);
}
#end_block

#method_before
@VisibleForTesting
ChangeDraftUpdate createDraftUpdateIfNull() {
    if (draftUpdate == null) {
        ChangeNotes notes = getNotes();
        if (notes != null) {
            draftUpdate = draftUpdateFactory.create(notes, accountId, realAccountId, authorIdent, when);
        } else {
            draftUpdate = draftUpdateFactory.create(getChange(), accountId, realAccountId, authorIdent, when);
        }
    }
    return draftUpdate;
}
#method_after
@VisibleForTesting
ChangeDraftUpdate createDraftUpdateIfNull() {
    if (draftUpdate == null) {
        ChangeNotes notes = getNotes();
        if (notes != null) {
            draftUpdate = draftUpdateFactory.create(notes, accountId, realAccountId, authorIdent, when);
        } else {
            // tests will always take the notes != null path above.
            draftUpdate = draftUpdateFactory.create(getChange(), accountId, realAccountId, authorIdent, when);
        }
    }
    return draftUpdate;
}
#end_block

#method_before
private ObjectId storeRevisionNotes(RevWalk rw, ObjectInserter inserter, ObjectId curr) throws ConfigInvalidException, OrmException, IOException {
    if (comments.isEmpty() && pushCert == null) {
        return null;
    }
    RevisionNoteMap<ChangeRevisionNote> rnm = getRevisionNoteMap(rw, curr);
    RevisionNoteBuilder.Cache cache = new RevisionNoteBuilder.Cache(rnm);
    for (Comment c : comments) {
        c.tag = tag;
        cache.get(new RevId(c.revId)).putComment(c);
    }
    if (pushCert != null) {
        checkState(commit != null);
        cache.get(new RevId(commit)).setPushCertificate(pushCert);
    }
    Map<RevId, RevisionNoteBuilder> builders = cache.getBuilders();
    checkComments(rnm.revisionNotes, builders);
    for (Map.Entry<RevId, RevisionNoteBuilder> e : builders.entrySet()) {
        ObjectId data = inserter.insert(OBJ_BLOB, e.getValue().build(noteUtil, noteUtil.getWriteJson()));
        rnm.noteMap.set(ObjectId.fromString(e.getKey().get()), data);
    }
    return rnm.noteMap.writeTree(inserter);
}
#method_after
private ObjectId storeRevisionNotes(RevWalk rw, ObjectInserter inserter, ObjectId curr) throws ConfigInvalidException, OrmException, IOException {
    if (comments.isEmpty() && pushCert == null) {
        return null;
    }
    RevisionNoteMap<ChangeRevisionNote> rnm = getRevisionNoteMap(rw, curr);
    RevisionNoteBuilder.Cache cache = new RevisionNoteBuilder.Cache(rnm);
    for (Comment c : comments) {
        c.tag = tag;
        cache.get(new RevId(c.revId)).putComment(c);
    }
    if (pushCert != null) {
        checkState(commit != null);
        cache.get(new RevId(commit)).setPushCertificate(pushCert);
    }
    Map<RevId, RevisionNoteBuilder> builders = cache.getBuilders();
    checkComments(rnm.revisionNotes, builders);
    for (Map.Entry<RevId, RevisionNoteBuilder> e : builders.entrySet()) {
        ObjectId data = inserter.insert(OBJ_BLOB, e.getValue().build(noteUtil.getChangeNoteJson()));
        rnm.noteMap.set(ObjectId.fromString(e.getKey().get()), data);
    }
    return rnm.noteMap.writeTree(inserter);
}
#end_block

#method_before
private RevisionNoteMap<ChangeRevisionNote> getRevisionNoteMap(RevWalk rw, ObjectId curr) throws ConfigInvalidException, OrmException, IOException {
    if (curr.equals(ObjectId.zeroId())) {
        return RevisionNoteMap.emptyMap();
    }
    if (migration.readChanges()) {
        // If reading from changes is enabled, then the old ChangeNotes may have
        // already parsed the revision notes. We can reuse them as long as the ref
        // hasn't advanced.
        ChangeNotes notes = getNotes();
        if (notes != null && notes.revisionNoteMap != null) {
            ObjectId idFromNotes = firstNonNull(notes.load().getRevision(), ObjectId.zeroId());
            if (idFromNotes.equals(curr)) {
                return notes.revisionNoteMap;
            }
        }
    }
    NoteMap noteMap = NoteMap.read(rw.getObjectReader(), rw.parseCommit(curr));
    // parse any existing revision notes so we can merge them.
    return RevisionNoteMap.parse(noteUtil, getId(), rw.getObjectReader(), noteMap, PatchLineComment.Status.PUBLISHED);
}
#method_after
private RevisionNoteMap<ChangeRevisionNote> getRevisionNoteMap(RevWalk rw, ObjectId curr) throws ConfigInvalidException, OrmException, IOException {
    if (curr.equals(ObjectId.zeroId())) {
        return RevisionNoteMap.emptyMap();
    }
    if (migration.readChanges()) {
        // If reading from changes is enabled, then the old ChangeNotes may have
        // already parsed the revision notes. We can reuse them as long as the ref
        // hasn't advanced.
        ChangeNotes notes = getNotes();
        if (notes != null && notes.revisionNoteMap != null) {
            ObjectId idFromNotes = firstNonNull(notes.load().getRevision(), ObjectId.zeroId());
            if (idFromNotes.equals(curr)) {
                return notes.revisionNoteMap;
            }
        }
    }
    NoteMap noteMap = NoteMap.read(rw.getObjectReader(), rw.parseCommit(curr));
    // parse any existing revision notes so we can merge them.
    return RevisionNoteMap.parse(noteUtil.getChangeNoteJson(), noteUtil.getLegacyChangeNoteRead(), getId(), rw.getObjectReader(), noteMap, PatchLineComment.Status.PUBLISHED);
}
#end_block

#method_before
@Override
protected CommitBuilder applyImpl(RevWalk rw, ObjectInserter ins, ObjectId curr) throws OrmException, IOException {
    checkState(deleteCommentRewriter == null && deleteChangeMessageRewriter == null, "cannot update and rewrite ref in one BatchUpdate");
    CommitBuilder cb = new CommitBuilder();
    int ps = psId != null ? psId.get() : getChange().currentPatchSetId().get();
    StringBuilder msg = new StringBuilder();
    if (commitSubject != null) {
        msg.append(commitSubject);
    } else {
        msg.append("Update patch set ").append(ps);
    }
    msg.append("\n\n");
    if (changeMessage != null) {
        msg.append(changeMessage);
        msg.append("\n\n");
    }
    addPatchSetFooter(msg, ps);
    if (currentPatchSet) {
        addFooter(msg, FOOTER_CURRENT, Boolean.TRUE);
    }
    if (psDescription != null) {
        addFooter(msg, FOOTER_PATCH_SET_DESCRIPTION, psDescription);
    }
    if (changeId != null) {
        addFooter(msg, FOOTER_CHANGE_ID, changeId);
    }
    if (subject != null) {
        addFooter(msg, FOOTER_SUBJECT, subject);
    }
    if (branch != null) {
        addFooter(msg, FOOTER_BRANCH, branch);
    }
    if (status != null) {
        addFooter(msg, FOOTER_STATUS, status.name().toLowerCase());
    }
    if (topic != null) {
        addFooter(msg, FOOTER_TOPIC, topic);
    }
    if (commit != null) {
        addFooter(msg, FOOTER_COMMIT, commit);
    }
    if (assignee != null) {
        if (assignee.isPresent()) {
            addFooter(msg, FOOTER_ASSIGNEE);
            addIdent(msg, assignee.get()).append('\n');
        } else {
            addFooter(msg, FOOTER_ASSIGNEE).append('\n');
        }
    }
    Joiner comma = Joiner.on(',');
    if (hashtags != null) {
        addFooter(msg, FOOTER_HASHTAGS, comma.join(hashtags));
    }
    if (tag != null) {
        addFooter(msg, FOOTER_TAG, tag);
    }
    if (groups != null) {
        addFooter(msg, FOOTER_GROUPS, comma.join(groups));
    }
    for (Map.Entry<Account.Id, ReviewerStateInternal> e : reviewers.entrySet()) {
        addFooter(msg, e.getValue().getFooterKey());
        addIdent(msg, e.getKey()).append('\n');
    }
    for (Map.Entry<Address, ReviewerStateInternal> e : reviewersByEmail.entrySet()) {
        addFooter(msg, e.getValue().getByEmailFooterKey(), e.getKey().toString());
    }
    for (Table.Cell<String, Account.Id, Optional<Short>> c : approvals.cellSet()) {
        addFooter(msg, FOOTER_LABEL);
        // Label names/values are safe to append without sanitizing.
        if (!c.getValue().isPresent()) {
            msg.append('-').append(c.getRowKey());
        } else {
            msg.append(LabelVote.create(c.getRowKey(), c.getValue().get()).formatWithEquals());
        }
        Account.Id id = c.getColumnKey();
        if (!id.equals(getAccountId())) {
            addIdent(msg.append(' '), id);
        }
        msg.append('\n');
    }
    if (submissionId != null) {
        addFooter(msg, FOOTER_SUBMISSION_ID, submissionId);
    }
    if (submitRecords != null) {
        for (SubmitRecord rec : submitRecords) {
            addFooter(msg, FOOTER_SUBMITTED_WITH).append(rec.status);
            if (rec.errorMessage != null) {
                msg.append(' ').append(sanitizeFooter(rec.errorMessage));
            }
            msg.append('\n');
            if (rec.labels != null) {
                for (SubmitRecord.Label label : rec.labels) {
                    // Label names/values are safe to append without sanitizing.
                    addFooter(msg, FOOTER_SUBMITTED_WITH).append(label.status).append(": ").append(label.label);
                    if (label.appliedBy != null) {
                        msg.append(": ");
                        addIdent(msg, label.appliedBy);
                    }
                    msg.append('\n');
                }
            }
        // TODO(maximeg) We might want to list plugins that validated this submission.
        }
    }
    if (!Objects.equals(accountId, realAccountId)) {
        addFooter(msg, FOOTER_REAL_USER);
        addIdent(msg, realAccountId).append('\n');
    }
    if (readOnlyUntil != null) {
        addFooter(msg, FOOTER_READ_ONLY_UNTIL, ChangeNoteUtil.formatTime(serverIdent, readOnlyUntil));
    }
    if (isPrivate != null) {
        addFooter(msg, FOOTER_PRIVATE, isPrivate);
    }
    if (workInProgress != null) {
        addFooter(msg, FOOTER_WORK_IN_PROGRESS, workInProgress);
    }
    if (revertOf != null) {
        addFooter(msg, FOOTER_REVERT_OF, revertOf);
    }
    cb.setMessage(msg.toString());
    try {
        ObjectId treeId = storeRevisionNotes(rw, ins, curr);
        if (treeId != null) {
            cb.setTreeId(treeId);
        }
    } catch (ConfigInvalidException e) {
        throw new OrmException(e);
    }
    return cb;
}
#method_after
@Override
protected CommitBuilder applyImpl(RevWalk rw, ObjectInserter ins, ObjectId curr) throws OrmException, IOException {
    checkState(deleteCommentRewriter == null && deleteChangeMessageRewriter == null, "cannot update and rewrite ref in one BatchUpdate");
    CommitBuilder cb = new CommitBuilder();
    int ps = psId != null ? psId.get() : getChange().currentPatchSetId().get();
    StringBuilder msg = new StringBuilder();
    if (commitSubject != null) {
        msg.append(commitSubject);
    } else {
        msg.append("Update patch set ").append(ps);
    }
    msg.append("\n\n");
    if (changeMessage != null) {
        msg.append(changeMessage);
        msg.append("\n\n");
    }
    addPatchSetFooter(msg, ps);
    if (currentPatchSet) {
        addFooter(msg, FOOTER_CURRENT, Boolean.TRUE);
    }
    if (psDescription != null) {
        addFooter(msg, FOOTER_PATCH_SET_DESCRIPTION, psDescription);
    }
    if (changeId != null) {
        addFooter(msg, FOOTER_CHANGE_ID, changeId);
    }
    if (subject != null) {
        addFooter(msg, FOOTER_SUBJECT, subject);
    }
    if (branch != null) {
        addFooter(msg, FOOTER_BRANCH, branch);
    }
    if (status != null) {
        addFooter(msg, FOOTER_STATUS, status.name().toLowerCase());
    }
    if (topic != null) {
        addFooter(msg, FOOTER_TOPIC, topic);
    }
    if (commit != null) {
        addFooter(msg, FOOTER_COMMIT, commit);
    }
    if (assignee != null) {
        if (assignee.isPresent()) {
            addFooter(msg, FOOTER_ASSIGNEE);
            addIdent(msg, assignee.get()).append('\n');
        } else {
            addFooter(msg, FOOTER_ASSIGNEE).append('\n');
        }
    }
    Joiner comma = Joiner.on(',');
    if (hashtags != null) {
        addFooter(msg, FOOTER_HASHTAGS, comma.join(hashtags));
    }
    if (tag != null) {
        addFooter(msg, FOOTER_TAG, tag);
    }
    if (groups != null) {
        addFooter(msg, FOOTER_GROUPS, comma.join(groups));
    }
    for (Map.Entry<Account.Id, ReviewerStateInternal> e : reviewers.entrySet()) {
        addFooter(msg, e.getValue().getFooterKey());
        addIdent(msg, e.getKey()).append('\n');
    }
    for (Map.Entry<Address, ReviewerStateInternal> e : reviewersByEmail.entrySet()) {
        addFooter(msg, e.getValue().getByEmailFooterKey(), e.getKey().toString());
    }
    for (Table.Cell<String, Account.Id, Optional<Short>> c : approvals.cellSet()) {
        addFooter(msg, FOOTER_LABEL);
        // Label names/values are safe to append without sanitizing.
        if (!c.getValue().isPresent()) {
            msg.append('-').append(c.getRowKey());
        } else {
            msg.append(LabelVote.create(c.getRowKey(), c.getValue().get()).formatWithEquals());
        }
        Account.Id id = c.getColumnKey();
        if (!id.equals(getAccountId())) {
            addIdent(msg.append(' '), id);
        }
        msg.append('\n');
    }
    if (submissionId != null) {
        addFooter(msg, FOOTER_SUBMISSION_ID, submissionId);
    }
    if (submitRecords != null) {
        for (SubmitRecord rec : submitRecords) {
            addFooter(msg, FOOTER_SUBMITTED_WITH).append(rec.status);
            if (rec.errorMessage != null) {
                msg.append(' ').append(sanitizeFooter(rec.errorMessage));
            }
            msg.append('\n');
            if (rec.labels != null) {
                for (SubmitRecord.Label label : rec.labels) {
                    // Label names/values are safe to append without sanitizing.
                    addFooter(msg, FOOTER_SUBMITTED_WITH).append(label.status).append(": ").append(label.label);
                    if (label.appliedBy != null) {
                        msg.append(": ");
                        addIdent(msg, label.appliedBy);
                    }
                    msg.append('\n');
                }
            }
        // TODO(maximeg) We might want to list plugins that validated this submission.
        }
    }
    if (!Objects.equals(accountId, realAccountId)) {
        addFooter(msg, FOOTER_REAL_USER);
        addIdent(msg, realAccountId).append('\n');
    }
    if (readOnlyUntil != null) {
        addFooter(msg, FOOTER_READ_ONLY_UNTIL, NoteDbUtil.formatTime(serverIdent, readOnlyUntil));
    }
    if (isPrivate != null) {
        addFooter(msg, FOOTER_PRIVATE, isPrivate);
    }
    if (workInProgress != null) {
        addFooter(msg, FOOTER_WORK_IN_PROGRESS, workInProgress);
    }
    if (revertOf != null) {
        addFooter(msg, FOOTER_REVERT_OF, revertOf);
    }
    cb.setMessage(msg.toString());
    try {
        ObjectId treeId = storeRevisionNotes(rw, ins, curr);
        if (treeId != null) {
            cb.setTreeId(treeId);
        }
    } catch (ConfigInvalidException e) {
        throw new OrmException(e);
    }
    return cb;
}
#end_block

#method_before
public void add(ChangeUpdate update) {
    checkArgument(update.getProjectName().equals(projectName), "update for project %s cannot be added to manager for project %s", update.getProjectName(), projectName);
    checkState(staged == null, "cannot add new update after staging");
    checkArgument(!rewriters.containsKey(update.getRefName()), "cannot update & rewrite ref %s in one BatchUpdate", update.getRefName());
    ChangeDraftUpdate du = update.getDraftUpdate();
    if (du != null) {
        draftUpdates.put(du.getRefName(), du);
    }
    RobotCommentUpdate rcu = update.getRobotCommentUpdate();
    if (rcu != null) {
        robotCommentUpdates.put(rcu.getRefName(), rcu);
    }
    DeleteCommentRewriter deleteCommentRewriter = update.getDeleteCommentRewriter();
    if (deleteCommentRewriter != null) {
        // Checks whether there is any ChangeUpdate added earlier trying to update the same ref.
        checkArgument(!changeUpdates.containsKey(deleteCommentRewriter.getRefName()), "cannot update & rewrite ref %s in one BatchUpdate", deleteCommentRewriter.getRefName());
        rewriters.put(deleteCommentRewriter.getRefName(), deleteCommentRewriter);
    }
    DeleteChangeMessageRewriter deleteChangeMessageRewriter = update.getDeleteChangeMessageRewriter();
    if (deleteChangeMessageRewriter != null) {
        // Checks whether there is any ChangeUpdate added earlier trying to update the same ref.
        checkArgument(!changeUpdates.containsKey(deleteChangeMessageRewriter.getRefName()), "cannot update & rewrite ref %s in one BatchUpdate", deleteChangeMessageRewriter.getRefName());
        checkArgument(!rewriters.containsKey(deleteChangeMessageRewriter.getRefName()), "cannot rewrite the same ref %s in one BatchUpdate", deleteChangeMessageRewriter.getRefName());
        rewriters.put(deleteChangeMessageRewriter.getRefName(), deleteChangeMessageRewriter);
    }
    changeUpdates.put(update.getRefName(), update);
}
#method_after
public void add(ChangeUpdate update) {
    checkArgument(update.getProjectName().equals(projectName), "update for project %s cannot be added to manager for project %s", update.getProjectName(), projectName);
    checkState(staged == null, "cannot add new update after staging");
    checkArgument(!rewriters.containsKey(update.getRefName()), "cannot update & rewrite ref %s in one BatchUpdate", update.getRefName());
    ChangeDraftUpdate du = update.getDraftUpdate();
    if (du != null) {
        draftUpdates.put(du.getRefName(), du);
    }
    RobotCommentUpdate rcu = update.getRobotCommentUpdate();
    if (rcu != null) {
        robotCommentUpdates.put(rcu.getRefName(), rcu);
    }
    DeleteCommentRewriter deleteCommentRewriter = update.getDeleteCommentRewriter();
    if (deleteCommentRewriter != null) {
        // Checks whether there is any ChangeUpdate or rewriter added earlier for the same ref.
        checkArgument(!changeUpdates.containsKey(deleteCommentRewriter.getRefName()), "cannot update & rewrite ref %s in one BatchUpdate", deleteCommentRewriter.getRefName());
        checkArgument(!rewriters.containsKey(deleteCommentRewriter.getRefName()), "cannot rewrite the same ref %s in one BatchUpdate", deleteCommentRewriter.getRefName());
        rewriters.put(deleteCommentRewriter.getRefName(), deleteCommentRewriter);
    }
    DeleteChangeMessageRewriter deleteChangeMessageRewriter = update.getDeleteChangeMessageRewriter();
    if (deleteChangeMessageRewriter != null) {
        // Checks whether there is any ChangeUpdate or rewriter added earlier for the same ref.
        checkArgument(!changeUpdates.containsKey(deleteChangeMessageRewriter.getRefName()), "cannot update & rewrite ref %s in one BatchUpdate", deleteChangeMessageRewriter.getRefName());
        checkArgument(!rewriters.containsKey(deleteChangeMessageRewriter.getRefName()), "cannot rewrite the same ref %s in one BatchUpdate", deleteChangeMessageRewriter.getRefName());
        rewriters.put(deleteChangeMessageRewriter.getRefName(), deleteChangeMessageRewriter);
    }
    changeUpdates.put(update.getRefName(), update);
}
#end_block

#method_before
private void doDelete(Change.Id id) throws IOException {
    String metaRef = RefNames.changeMetaRef(id);
    Optional<ObjectId> old = changeRepo.cmds.get(metaRef);
    if (old.isPresent()) {
        changeRepo.cmds.add(new ReceiveCommand(old.get(), ObjectId.zeroId(), metaRef));
    }
    // Just scan repo for ref names, but get "old" values from cmds.
    for (Ref r : allUsersRepo.repo.getRefDatabase().getRefs(RefNames.refsDraftCommentsPrefix(id)).values()) {
        old = allUsersRepo.cmds.get(r.getName());
        if (old.isPresent()) {
            allUsersRepo.cmds.add(new ReceiveCommand(old.get(), ObjectId.zeroId(), r.getName()));
        }
    }
}
#method_after
private void doDelete(Change.Id id) throws IOException {
    String metaRef = RefNames.changeMetaRef(id);
    Optional<ObjectId> old = changeRepo.cmds.get(metaRef);
    if (old.isPresent()) {
        changeRepo.cmds.add(new ReceiveCommand(old.get(), ObjectId.zeroId(), metaRef));
    }
    // Just scan repo for ref names, but get "old" values from cmds.
    for (Ref r : allUsersRepo.repo.getRefDatabase().getRefsByPrefix(RefNames.refsDraftCommentsPrefix(id))) {
        old = allUsersRepo.cmds.get(r.getName());
        if (old.isPresent()) {
            allUsersRepo.cmds.add(new ReceiveCommand(old.get(), ObjectId.zeroId(), r.getName()));
        }
    }
}
#end_block

#method_before
@Override
public ObjectId rewriteCommitHistory(RevWalk revWalk, ObjectInserter inserter, ObjectId currTip) throws IOException {
    checkArgument(!currTip.equals(ObjectId.zeroId()));
    // Walk from the first commit of the branch.
    revWalk.reset();
    revWalk.markStart(revWalk.parseCommit(currTip));
    revWalk.sort(RevSort.REVERSE);
    ObjectId newTipId = null;
    boolean rewrite = false;
    boolean rewriteMessage = false;
    RevCommit originalCommit;
    while ((originalCommit = revWalk.next()) != null) {
        if (!rewrite && uuid.equals(originalCommit.getName())) {
            rewrite = true;
            rewriteMessage = true;
        }
        if (!rewrite) {
            newTipId = originalCommit;
            continue;
        }
        if (rewriteMessage) {
            String newCommitMessage = createNewCommitMessage(originalCommit);
            newTipId = rewriteOneCommit(originalCommit, newTipId, newCommitMessage, inserter);
            rewriteMessage = false;
        } else {
            newTipId = rewriteOneCommit(originalCommit, newTipId, originalCommit.getFullMessage(), inserter);
        }
    }
    return newTipId;
}
#method_after
@Override
public ObjectId rewriteCommitHistory(RevWalk revWalk, ObjectInserter inserter, ObjectId currTip) throws IOException {
    checkArgument(!currTip.equals(ObjectId.zeroId()));
    // Walk from the first commit of the branch.
    revWalk.reset();
    revWalk.markStart(revWalk.parseCommit(currTip));
    revWalk.sort(RevSort.TOPO);
    revWalk.sort(RevSort.REVERSE);
    ObjectId newTipId = null;
    RevCommit originalCommit;
    int idx = 0;
    while ((originalCommit = revWalk.next()) != null) {
        if (idx < targetMessageIdx) {
            newTipId = originalCommit;
            idx++;
            continue;
        }
        String newCommitMessage = (idx == targetMessageIdx) ? createNewCommitMessage(originalCommit) : originalCommit.getFullMessage();
        newTipId = rewriteOneCommit(originalCommit, newTipId, newCommitMessage, inserter);
        idx++;
    }
    return newTipId;
}
#end_block

#method_before
private String createNewCommitMessage(RevCommit commit) {
    byte[] raw = commit.getRawBuffer();
    Optional<ChangeNotesParser.Range> range = ChangeNotesParser.parseCommitMessageRange(commit);
    if (!range.isPresent()) {
        throw new IllegalStateException("fail to parse commit message");
    }
    Charset encoding = RawParseUtils.parseEncoding(raw);
    String prefix = decode(encoding, raw, range.get().subjectStart(), range.get().changeMessageStart());
    String postfix = decode(encoding, raw, range.get().changeMessageEnd() + 1, raw.length);
    return prefix + newChangeMessage + postfix;
}
#method_after
private String createNewCommitMessage(RevCommit commit) {
    byte[] raw = commit.getRawBuffer();
    Optional<ChangeNoteUtil.CommitMessageRange> range = parseCommitMessageRange(commit);
    checkState(range.isPresent(), "failed to parse commit message");
    // Only replace the commit message body, which is the user-provided message. The subject and
    // footers are NoteDb metadata.
    Charset encoding = RawParseUtils.parseEncoding(raw);
    String prefix = decode(encoding, raw, range.get().subjectStart(), range.get().changeMessageStart());
    String postfix = decode(encoding, raw, range.get().changeMessageEnd() + 1, raw.length);
    return prefix + newChangeMessage + postfix;
}
#end_block

#method_before
@Override
protected void configure() {
    bind(ChangesCollection.class);
    bind(Revisions.class);
    bind(Reviewers.class);
    bind(RevisionReviewers.class);
    bind(DraftComments.class);
    bind(Comments.class);
    bind(RobotComments.class);
    bind(Fixes.class);
    bind(Files.class);
    bind(Votes.class);
    DynamicMap.mapOf(binder(), CHANGE_KIND);
    DynamicMap.mapOf(binder(), COMMENT_KIND);
    DynamicMap.mapOf(binder(), ROBOT_COMMENT_KIND);
    DynamicMap.mapOf(binder(), FIX_KIND);
    DynamicMap.mapOf(binder(), DRAFT_COMMENT_KIND);
    DynamicMap.mapOf(binder(), FILE_KIND);
    DynamicMap.mapOf(binder(), REVIEWER_KIND);
    DynamicMap.mapOf(binder(), REVISION_KIND);
    DynamicMap.mapOf(binder(), CHANGE_EDIT_KIND);
    DynamicMap.mapOf(binder(), VOTE_KIND);
    get(CHANGE_KIND).to(GetChange.class);
    post(CHANGE_KIND, "merge").to(CreateMergePatchSet.class);
    get(CHANGE_KIND, "detail").to(GetDetail.class);
    get(CHANGE_KIND, "topic").to(GetTopic.class);
    get(CHANGE_KIND, "in").to(ChangeIncludedIn.class);
    get(CHANGE_KIND, "assignee").to(GetAssignee.class);
    get(CHANGE_KIND, "past_assignees").to(GetPastAssignees.class);
    put(CHANGE_KIND, "assignee").to(PutAssignee.class);
    delete(CHANGE_KIND, "assignee").to(DeleteAssignee.class);
    get(CHANGE_KIND, "hashtags").to(GetHashtags.class);
    get(CHANGE_KIND, "comments").to(ListChangeComments.class);
    get(CHANGE_KIND, "robotcomments").to(ListChangeRobotComments.class);
    get(CHANGE_KIND, "drafts").to(ListChangeDrafts.class);
    get(CHANGE_KIND, "check").to(Check.class);
    get(CHANGE_KIND, "pure_revert").to(GetPureRevert.class);
    post(CHANGE_KIND, "check").to(Check.class);
    put(CHANGE_KIND, "topic").to(PutTopic.class);
    delete(CHANGE_KIND, "topic").to(PutTopic.class);
    delete(CHANGE_KIND).to(DeleteChange.class);
    post(CHANGE_KIND, "abandon").to(Abandon.class);
    post(CHANGE_KIND, "hashtags").to(PostHashtags.class);
    post(CHANGE_KIND, "restore").to(Restore.class);
    post(CHANGE_KIND, "revert").to(Revert.class);
    post(CHANGE_KIND, "submit").to(Submit.CurrentRevision.class);
    get(CHANGE_KIND, "submitted_together").to(SubmittedTogether.class);
    post(CHANGE_KIND, "rebase").to(Rebase.CurrentRevision.class);
    post(CHANGE_KIND, "index").to(Index.class);
    post(CHANGE_KIND, "rebuild.notedb").to(Rebuild.class);
    post(CHANGE_KIND, "move").to(Move.class);
    post(CHANGE_KIND, "private").to(PostPrivate.class);
    post(CHANGE_KIND, "private.delete").to(DeletePrivateByPost.class);
    delete(CHANGE_KIND, "private").to(DeletePrivate.class);
    put(CHANGE_KIND, "ignore").to(Ignore.class);
    put(CHANGE_KIND, "unignore").to(Unignore.class);
    put(CHANGE_KIND, "reviewed").to(MarkAsReviewed.class);
    put(CHANGE_KIND, "unreviewed").to(MarkAsUnreviewed.class);
    post(CHANGE_KIND, "wip").to(SetWorkInProgress.class);
    post(CHANGE_KIND, "ready").to(SetReadyForReview.class);
    put(CHANGE_KIND, "message").to(PutMessage.class);
    delete(CHANGE_KIND, "change_message").to(DeleteChangeMessage.class);
    post(CHANGE_KIND, "change_message.delete").to(DeleteChangeMessage.class);
    post(CHANGE_KIND, "reviewers").to(PostReviewers.class);
    get(CHANGE_KIND, "suggest_reviewers").to(SuggestChangeReviewers.class);
    child(CHANGE_KIND, "reviewers").to(Reviewers.class);
    get(REVIEWER_KIND).to(GetReviewer.class);
    delete(REVIEWER_KIND).to(DeleteReviewer.class);
    post(REVIEWER_KIND, "delete").to(DeleteReviewer.class);
    child(REVIEWER_KIND, "votes").to(Votes.class);
    delete(VOTE_KIND).to(DeleteVote.class);
    post(VOTE_KIND, "delete").to(DeleteVote.class);
    child(CHANGE_KIND, "revisions").to(Revisions.class);
    get(REVISION_KIND, "actions").to(GetRevisionActions.class);
    post(REVISION_KIND, "cherrypick").to(CherryPick.class);
    get(REVISION_KIND, "commit").to(GetCommit.class);
    get(REVISION_KIND, "mergeable").to(Mergeable.class);
    get(REVISION_KIND, "related").to(GetRelated.class);
    get(REVISION_KIND, "review").to(GetReview.class);
    post(REVISION_KIND, "review").to(PostReview.class);
    get(REVISION_KIND, "preview_submit").to(PreviewSubmit.class);
    post(REVISION_KIND, "submit").to(Submit.class);
    post(REVISION_KIND, "rebase").to(Rebase.class);
    put(REVISION_KIND, "description").to(PutDescription.class);
    get(REVISION_KIND, "description").to(GetDescription.class);
    get(REVISION_KIND, "patch").to(GetPatch.class);
    get(REVISION_KIND, "submit_type").to(TestSubmitType.Get.class);
    post(REVISION_KIND, "test.submit_rule").to(TestSubmitRule.class);
    post(REVISION_KIND, "test.submit_type").to(TestSubmitType.class);
    get(REVISION_KIND, "archive").to(GetArchive.class);
    get(REVISION_KIND, "mergelist").to(GetMergeList.class);
    child(REVISION_KIND, "reviewers").to(RevisionReviewers.class);
    child(REVISION_KIND, "drafts").to(DraftComments.class);
    put(REVISION_KIND, "drafts").to(CreateDraftComment.class);
    get(DRAFT_COMMENT_KIND).to(GetDraftComment.class);
    put(DRAFT_COMMENT_KIND).to(PutDraftComment.class);
    delete(DRAFT_COMMENT_KIND).to(DeleteDraftComment.class);
    child(REVISION_KIND, "comments").to(Comments.class);
    get(COMMENT_KIND).to(GetComment.class);
    delete(COMMENT_KIND).to(DeleteComment.class);
    post(COMMENT_KIND, "delete").to(DeleteComment.class);
    child(REVISION_KIND, "robotcomments").to(RobotComments.class);
    get(ROBOT_COMMENT_KIND).to(GetRobotComment.class);
    child(REVISION_KIND, "fixes").to(Fixes.class);
    post(FIX_KIND, "apply").to(ApplyFix.class);
    child(REVISION_KIND, "files").to(Files.class);
    put(FILE_KIND, "reviewed").to(PutReviewed.class);
    delete(FILE_KIND, "reviewed").to(DeleteReviewed.class);
    get(FILE_KIND, "content").to(GetContent.class);
    get(FILE_KIND, "download").to(DownloadContent.class);
    get(FILE_KIND, "diff").to(GetDiff.class);
    get(FILE_KIND, "blame").to(GetBlame.class);
    child(CHANGE_KIND, "edit").to(ChangeEdits.class);
    delete(CHANGE_KIND, "edit").to(DeleteChangeEdit.class);
    child(CHANGE_KIND, "edit:publish").to(PublishChangeEdit.class);
    child(CHANGE_KIND, "edit:rebase").to(RebaseChangeEdit.class);
    put(CHANGE_KIND, "edit:message").to(ChangeEdits.EditMessage.class);
    get(CHANGE_KIND, "edit:message").to(ChangeEdits.GetMessage.class);
    put(CHANGE_EDIT_KIND, "/").to(ChangeEdits.Put.class);
    delete(CHANGE_EDIT_KIND).to(ChangeEdits.DeleteContent.class);
    get(CHANGE_EDIT_KIND, "/").to(ChangeEdits.Get.class);
    get(CHANGE_EDIT_KIND, "meta").to(ChangeEdits.GetMeta.class);
    post(COMMIT_KIND, "cherrypick").to(CherryPickCommit.class);
    factory(AccountLoader.Factory.class);
    factory(ChangeEdits.Create.Factory.class);
    factory(ChangeEdits.DeleteFile.Factory.class);
    factory(ChangeInserter.Factory.class);
    factory(ChangeResource.Factory.class);
    factory(DeleteReviewerByEmailOp.Factory.class);
    factory(DeleteReviewerOp.Factory.class);
    factory(EmailReviewComments.Factory.class);
    factory(PatchSetInserter.Factory.class);
    factory(PostReviewersOp.Factory.class);
    factory(RebaseChangeOp.Factory.class);
    factory(ReviewerResource.Factory.class);
    factory(SetAssigneeOp.Factory.class);
    factory(SetHashtagsOp.Factory.class);
    factory(SetPrivateOp.Factory.class);
    factory(WorkInProgressOp.Factory.class);
}
#method_after
@Override
protected void configure() {
    bind(ChangesCollection.class);
    bind(Revisions.class);
    bind(Reviewers.class);
    bind(RevisionReviewers.class);
    bind(DraftComments.class);
    bind(Comments.class);
    bind(RobotComments.class);
    bind(Fixes.class);
    bind(Files.class);
    bind(Votes.class);
    DynamicMap.mapOf(binder(), CHANGE_KIND);
    DynamicMap.mapOf(binder(), COMMENT_KIND);
    DynamicMap.mapOf(binder(), ROBOT_COMMENT_KIND);
    DynamicMap.mapOf(binder(), FIX_KIND);
    DynamicMap.mapOf(binder(), DRAFT_COMMENT_KIND);
    DynamicMap.mapOf(binder(), FILE_KIND);
    DynamicMap.mapOf(binder(), REVIEWER_KIND);
    DynamicMap.mapOf(binder(), REVISION_KIND);
    DynamicMap.mapOf(binder(), CHANGE_EDIT_KIND);
    DynamicMap.mapOf(binder(), VOTE_KIND);
    DynamicMap.mapOf(binder(), CHANGE_MESSAGE_KIND);
    postOnCollection(CHANGE_KIND).to(CreateChange.class);
    get(CHANGE_KIND).to(GetChange.class);
    post(CHANGE_KIND, "merge").to(CreateMergePatchSet.class);
    get(CHANGE_KIND, "detail").to(GetDetail.class);
    get(CHANGE_KIND, "topic").to(GetTopic.class);
    get(CHANGE_KIND, "in").to(ChangeIncludedIn.class);
    get(CHANGE_KIND, "assignee").to(GetAssignee.class);
    get(CHANGE_KIND, "past_assignees").to(GetPastAssignees.class);
    put(CHANGE_KIND, "assignee").to(PutAssignee.class);
    delete(CHANGE_KIND, "assignee").to(DeleteAssignee.class);
    get(CHANGE_KIND, "hashtags").to(GetHashtags.class);
    get(CHANGE_KIND, "comments").to(ListChangeComments.class);
    get(CHANGE_KIND, "robotcomments").to(ListChangeRobotComments.class);
    get(CHANGE_KIND, "drafts").to(ListChangeDrafts.class);
    get(CHANGE_KIND, "check").to(Check.class);
    get(CHANGE_KIND, "pure_revert").to(GetPureRevert.class);
    post(CHANGE_KIND, "check").to(Check.class);
    put(CHANGE_KIND, "topic").to(PutTopic.class);
    delete(CHANGE_KIND, "topic").to(PutTopic.class);
    delete(CHANGE_KIND).to(DeleteChange.class);
    post(CHANGE_KIND, "abandon").to(Abandon.class);
    post(CHANGE_KIND, "hashtags").to(PostHashtags.class);
    post(CHANGE_KIND, "restore").to(Restore.class);
    post(CHANGE_KIND, "revert").to(Revert.class);
    post(CHANGE_KIND, "submit").to(Submit.CurrentRevision.class);
    get(CHANGE_KIND, "submitted_together").to(SubmittedTogether.class);
    post(CHANGE_KIND, "rebase").to(Rebase.CurrentRevision.class);
    post(CHANGE_KIND, "index").to(Index.class);
    post(CHANGE_KIND, "rebuild.notedb").to(Rebuild.class);
    post(CHANGE_KIND, "move").to(Move.class);
    post(CHANGE_KIND, "private").to(PostPrivate.class);
    post(CHANGE_KIND, "private.delete").to(DeletePrivateByPost.class);
    delete(CHANGE_KIND, "private").to(DeletePrivate.class);
    put(CHANGE_KIND, "ignore").to(Ignore.class);
    put(CHANGE_KIND, "unignore").to(Unignore.class);
    put(CHANGE_KIND, "reviewed").to(MarkAsReviewed.class);
    put(CHANGE_KIND, "unreviewed").to(MarkAsUnreviewed.class);
    post(CHANGE_KIND, "wip").to(SetWorkInProgress.class);
    post(CHANGE_KIND, "ready").to(SetReadyForReview.class);
    put(CHANGE_KIND, "message").to(PutMessage.class);
    get(CHANGE_KIND, "suggest_reviewers").to(SuggestChangeReviewers.class);
    child(CHANGE_KIND, "reviewers").to(Reviewers.class);
    postOnCollection(REVIEWER_KIND).to(PostReviewers.class);
    get(REVIEWER_KIND).to(GetReviewer.class);
    delete(REVIEWER_KIND).to(DeleteReviewer.class);
    post(REVIEWER_KIND, "delete").to(DeleteReviewer.class);
    child(REVIEWER_KIND, "votes").to(Votes.class);
    delete(VOTE_KIND).to(DeleteVote.class);
    post(VOTE_KIND, "delete").to(DeleteVote.class);
    child(CHANGE_KIND, "revisions").to(Revisions.class);
    get(REVISION_KIND, "actions").to(GetRevisionActions.class);
    post(REVISION_KIND, "cherrypick").to(CherryPick.class);
    get(REVISION_KIND, "commit").to(GetCommit.class);
    get(REVISION_KIND, "mergeable").to(Mergeable.class);
    get(REVISION_KIND, "related").to(GetRelated.class);
    get(REVISION_KIND, "review").to(GetReview.class);
    post(REVISION_KIND, "review").to(PostReview.class);
    get(REVISION_KIND, "preview_submit").to(PreviewSubmit.class);
    post(REVISION_KIND, "submit").to(Submit.class);
    post(REVISION_KIND, "rebase").to(Rebase.class);
    put(REVISION_KIND, "description").to(PutDescription.class);
    get(REVISION_KIND, "description").to(GetDescription.class);
    get(REVISION_KIND, "patch").to(GetPatch.class);
    get(REVISION_KIND, "submit_type").to(TestSubmitType.Get.class);
    post(REVISION_KIND, "test.submit_rule").to(TestSubmitRule.class);
    post(REVISION_KIND, "test.submit_type").to(TestSubmitType.class);
    get(REVISION_KIND, "archive").to(GetArchive.class);
    get(REVISION_KIND, "mergelist").to(GetMergeList.class);
    child(REVISION_KIND, "reviewers").to(RevisionReviewers.class);
    child(REVISION_KIND, "drafts").to(DraftComments.class);
    put(REVISION_KIND, "drafts").to(CreateDraftComment.class);
    get(DRAFT_COMMENT_KIND).to(GetDraftComment.class);
    put(DRAFT_COMMENT_KIND).to(PutDraftComment.class);
    delete(DRAFT_COMMENT_KIND).to(DeleteDraftComment.class);
    child(REVISION_KIND, "comments").to(Comments.class);
    get(COMMENT_KIND).to(GetComment.class);
    delete(COMMENT_KIND).to(DeleteComment.class);
    post(COMMENT_KIND, "delete").to(DeleteComment.class);
    child(REVISION_KIND, "robotcomments").to(RobotComments.class);
    get(ROBOT_COMMENT_KIND).to(GetRobotComment.class);
    child(REVISION_KIND, "fixes").to(Fixes.class);
    post(FIX_KIND, "apply").to(ApplyFix.class);
    child(REVISION_KIND, "files").to(Files.class);
    put(FILE_KIND, "reviewed").to(PutReviewed.class);
    delete(FILE_KIND, "reviewed").to(DeleteReviewed.class);
    get(FILE_KIND, "content").to(GetContent.class);
    get(FILE_KIND, "download").to(DownloadContent.class);
    get(FILE_KIND, "diff").to(GetDiff.class);
    get(FILE_KIND, "blame").to(GetBlame.class);
    child(CHANGE_KIND, "edit").to(ChangeEdits.class);
    create(CHANGE_EDIT_KIND).to(ChangeEdits.Create.class);
    deleteMissing(CHANGE_EDIT_KIND).to(ChangeEdits.DeleteFile.class);
    postOnCollection(CHANGE_EDIT_KIND).to(ChangeEdits.Post.class);
    deleteOnCollection(CHANGE_EDIT_KIND).to(DeleteChangeEdit.class);
    post(CHANGE_KIND, "edit:publish").to(PublishChangeEdit.class);
    post(CHANGE_KIND, "edit:rebase").to(RebaseChangeEdit.class);
    put(CHANGE_KIND, "edit:message").to(ChangeEdits.EditMessage.class);
    get(CHANGE_KIND, "edit:message").to(ChangeEdits.GetMessage.class);
    put(CHANGE_EDIT_KIND, "/").to(ChangeEdits.Put.class);
    delete(CHANGE_EDIT_KIND).to(ChangeEdits.DeleteContent.class);
    get(CHANGE_EDIT_KIND, "/").to(ChangeEdits.Get.class);
    get(CHANGE_EDIT_KIND, "meta").to(ChangeEdits.GetMeta.class);
    post(COMMIT_KIND, "cherrypick").to(CherryPickCommit.class);
    child(CHANGE_KIND, "messages").to(ChangeMessages.class);
    get(CHANGE_MESSAGE_KIND).to(GetChangeMessage.class);
    delete(CHANGE_MESSAGE_KIND).to(DeleteChangeMessage.DefaultDeleteChangeMessage.class);
    post(CHANGE_MESSAGE_KIND, "delete").to(DeleteChangeMessage.class);
    factory(AccountLoader.Factory.class);
    factory(ChangeInserter.Factory.class);
    factory(ChangeResource.Factory.class);
    factory(DeleteReviewerByEmailOp.Factory.class);
    factory(DeleteReviewerOp.Factory.class);
    factory(EmailReviewComments.Factory.class);
    factory(PatchSetInserter.Factory.class);
    factory(PostReviewersOp.Factory.class);
    factory(RebaseChangeOp.Factory.class);
    factory(ReviewerResource.Factory.class);
    factory(SetAssigneeOp.Factory.class);
    factory(SetHashtagsOp.Factory.class);
    factory(SetPrivateOp.Factory.class);
    factory(WorkInProgressOp.Factory.class);
}
#end_block

#method_before
private ProjectResetter.Config defaultResetProjects() {
    return new ProjectResetter.Config().reset(allProjects, RefNames.REFS_CONFIG).reset(allUsers, RefNames.REFS_CONFIG, RefNames.REFS_USERS + "*", RefNames.REFS_EXTERNAL_IDS, RefNames.REFS_STARRED_CHANGES + "*", RefNames.REFS_DRAFT_COMMENTS + "*");
}
#method_after
private ProjectResetter.Config defaultResetProjects() {
    return new ProjectResetter.Config().reset(allProjects, RefNames.REFS_CONFIG).reset(allUsers, RefNames.REFS_CONFIG, RefNames.REFS_USERS + "*", RefNames.REFS_EXTERNAL_IDS, RefNames.REFS_GROUPNAMES, RefNames.REFS_GROUPS + "*", RefNames.REFS_STARRED_CHANGES + "*", RefNames.REFS_DRAFT_COMMENTS + "*");
}
#end_block

#method_before
protected void beforeTest(Description description) throws Exception {
    this.description = description;
    GerritServer.Description classDesc = GerritServer.Description.forTestClass(description, configName);
    GerritServer.Description methodDesc = GerritServer.Description.forTestMethod(description, configName);
    testRequiresSsh = classDesc.useSshAnnotation() || methodDesc.useSshAnnotation();
    if (!testRequiresSsh) {
        baseConfig.setString("sshd", null, "listenAddress", "off");
    }
    baseConfig.setInt("receive", null, "changeUpdateThreads", 4);
    Module module = createModule();
    if (classDesc.equals(methodDesc) && !classDesc.sandboxed() && !methodDesc.sandboxed()) {
        if (commonServer == null) {
            commonServer = GerritServer.initAndStart(classDesc, baseConfig, module);
        }
        server = commonServer;
    } else {
        server = GerritServer.initAndStart(methodDesc, baseConfig, module);
    }
    server.getTestInjector().injectMembers(this);
    Transport.register(inProcessProtocol);
    toClose = Collections.synchronizedList(new ArrayList<Repository>());
    db = reviewDbProvider.open();
    // All groups which were added during the server start (e.g. in SchemaCreator) aren't contained
    // in the instance of the group index which is available here and in tests. There are two
    // reasons:
    // 1) No group index is available in SchemaCreator when using an in-memory database. (This could
    // be fixed by using the IndexManagerOnInit in InMemoryDatabase similar as BaseInit uses it.)
    // 2) During the on-init part of the server start, we use another instance of the index than
    // later on. As test indexes are non-permanent, closing an instance and opening another one
    // removes all indexed data.
    // As a workaround, we simply reindex all available groups here.
    reindexAllGroups();
    admin = accountCreator.admin();
    user = accountCreator.user();
    // Evict and reindex accounts in case tests modify them.
    evictAndReindexAccount(admin.getId());
    evictAndReindexAccount(user.getId());
    adminRestSession = new RestSession(server, admin);
    userRestSession = new RestSession(server, user);
    initSsh();
    resourcePrefix = UNSAFE_PROJECT_NAME.matcher(description.getClassName() + "_" + description.getMethodName() + "_").replaceAll("");
    Context ctx = newRequestContext(admin);
    atrScope.set(ctx);
    project = createProject(projectInput(description));
    testRepo = cloneProject(project, getCloneAsAccount(description));
}
#method_after
protected void beforeTest(Description description) throws Exception {
    this.description = description;
    GerritServer.Description classDesc = GerritServer.Description.forTestClass(description, configName);
    GerritServer.Description methodDesc = GerritServer.Description.forTestMethod(description, configName);
    testRequiresSsh = classDesc.useSshAnnotation() || methodDesc.useSshAnnotation();
    if (!testRequiresSsh) {
        baseConfig.setString("sshd", null, "listenAddress", "off");
    }
    baseConfig.setInt("index", null, "batchThreads", -1);
    baseConfig.setInt("receive", null, "changeUpdateThreads", 4);
    Module module = createModule();
    if (classDesc.equals(methodDesc) && !classDesc.sandboxed() && !methodDesc.sandboxed()) {
        if (commonServer == null) {
            commonServer = GerritServer.initAndStart(classDesc, baseConfig, module);
        }
        server = commonServer;
    } else {
        server = GerritServer.initAndStart(methodDesc, baseConfig, module);
    }
    server.getTestInjector().injectMembers(this);
    Transport.register(inProcessProtocol);
    toClose = Collections.synchronizedList(new ArrayList<Repository>());
    db = reviewDbProvider.open();
    // All groups which were added during the server start (e.g. in SchemaCreator) aren't contained
    // in the instance of the group index which is available here and in tests. There are two
    // reasons:
    // 1) No group index is available in SchemaCreator when using an in-memory database. (This could
    // be fixed by using the IndexManagerOnInit in InMemoryDatabase similar as BaseInit uses it.)
    // 2) During the on-init part of the server start, we use another instance of the index than
    // later on. As test indexes are non-permanent, closing an instance and opening another one
    // removes all indexed data.
    // As a workaround, we simply reindex all available groups here.
    reindexAllGroups();
    admin = accountCreator.admin();
    user = accountCreator.user();
    // Evict and reindex accounts in case tests modify them.
    evictAndReindexAccount(admin.getId());
    evictAndReindexAccount(user.getId());
    adminRestSession = new RestSession(server, admin);
    userRestSession = new RestSession(server, user);
    initSsh();
    resourcePrefix = UNSAFE_PROJECT_NAME.matcher(description.getClassName() + "_" + description.getMethodName() + "_").replaceAll("");
    Context ctx = newRequestContext(admin);
    atrScope.set(ctx);
    ProjectInput in = projectInput(description);
    gApi.projects().create(in);
    project = new Project.NameKey(in.name);
    testRepo = cloneProject(project, getCloneAsAccount(description));
}
#end_block

#method_before
protected void initSsh() throws JSchException {
    if (testRequiresSsh && SshMode.useSsh() && (adminSshSession == null || userSshSession == null)) {
        // Create Ssh sessions
        GitUtil.initSsh(admin);
        Context ctx = newRequestContext(user);
        atrScope.set(ctx);
        userSshSession = ctx.getSession();
        userSshSession.open();
        ctx = newRequestContext(admin);
        atrScope.set(ctx);
        adminSshSession = ctx.getSession();
        adminSshSession.open();
    }
}
#method_after
protected void initSsh() throws Exception {
    if (testRequiresSsh && SshMode.useSsh() && (adminSshSession == null || userSshSession == null)) {
        // Create Ssh sessions
        KeyPair adminKeyPair = sshKeys.getKeyPair(admin);
        GitUtil.initSsh(adminKeyPair);
        Context ctx = newRequestContext(user);
        atrScope.set(ctx);
        userSshSession = ctx.getSession();
        userSshSession.open();
        ctx = newRequestContext(admin);
        atrScope.set(ctx);
        adminSshSession = ctx.getSession();
        adminSshSession.open();
    }
}
#end_block

#method_before
protected Project.NameKey createProject(String nameSuffix, Project.NameKey parent, boolean createEmptyCommit, SubmitType submitType) throws RestApiException {
    ProjectInput in = new ProjectInput();
    in.name = name(nameSuffix);
    in.parent = parent != null ? parent.get() : null;
    in.submitType = submitType;
    in.createEmptyCommit = createEmptyCommit;
    return createProject(in);
}
#method_after
protected Project.NameKey createProject(String nameSuffix, Project.NameKey parent, boolean createEmptyCommit, SubmitType submitType) throws RestApiException {
    ProjectInput in = new ProjectInput();
    in.name = name(nameSuffix);
    in.parent = parent != null ? parent.get() : null;
    in.submitType = submitType;
    in.createEmptyCommit = createEmptyCommit;
    gApi.projects().create(in);
    return new Project.NameKey(in.name);
}
#end_block

#method_before
protected PushOneCommit.Result amendChange(String changeId) throws Exception {
    return amendChange(changeId, "refs/for/master");
}
#method_after
protected PushOneCommit.Result amendChange(String changeId) throws Exception {
    return amendChange(changeId, "refs/for/master", admin, testRepo);
}
#end_block

#method_before
private Context newRequestContext(TestAccount account) {
    return atrScope.newContext(reviewDbProvider, new SshSession(server, account), identifiedUserFactory.create(account.getId()));
}
#method_after
private Context newRequestContext(TestAccount account) {
    return atrScope.newContext(reviewDbProvider, new SshSession(sshKeys, server, account), identifiedUserFactory.create(account.getId()));
}
#end_block

#method_before
protected void allow(Project.NameKey p, String ref, String permission, AccountGroup.UUID id) throws Exception {
    ProjectConfig cfg = projectCache.checkedGet(p).getConfig();
    Util.allow(cfg, permission, id, ref);
    saveProjectConfig(p, cfg);
}
#method_after
protected void allow(Project.NameKey p, String ref, String permission, AccountGroup.UUID id) throws Exception {
    try (ProjectConfigUpdate u = updateProject(p)) {
        Util.allow(u.getConfig(), permission, id, ref);
        u.save();
    }
}
#end_block

#method_before
protected void allowGlobalCapabilities(AccountGroup.UUID id, Iterable<String> capabilityNames) throws Exception {
    ProjectConfig cfg = projectCache.checkedGet(allProjects).getConfig();
    for (String capabilityName : capabilityNames) {
        Util.allow(cfg, capabilityName, id);
    }
    saveProjectConfig(allProjects, cfg);
}
#method_after
protected void allowGlobalCapabilities(AccountGroup.UUID id, Iterable<String> capabilityNames) throws Exception {
    try (ProjectConfigUpdate u = updateProject(allProjects)) {
        for (String capabilityName : capabilityNames) {
            Util.allow(u.getConfig(), capabilityName, id);
        }
        u.save();
    }
}
#end_block

#method_before
protected void removeGlobalCapabilities(AccountGroup.UUID id, Iterable<String> capabilityNames) throws Exception {
    ProjectConfig cfg = projectCache.checkedGet(allProjects).getConfig();
    for (String capabilityName : capabilityNames) {
        Util.remove(cfg, capabilityName, id);
    }
    saveProjectConfig(allProjects, cfg);
}
#method_after
protected void removeGlobalCapabilities(AccountGroup.UUID id, Iterable<String> capabilityNames) throws Exception {
    try (ProjectConfigUpdate u = updateProject(allProjects)) {
        for (String capabilityName : capabilityNames) {
            Util.remove(u.getConfig(), capabilityName, id);
        }
        u.save();
    }
}
#end_block

#method_before
protected void deny(Project.NameKey p, String ref, String permission, AccountGroup.UUID id) throws Exception {
    ProjectConfig cfg = projectCache.checkedGet(p).getConfig();
    Util.deny(cfg, permission, id, ref);
    saveProjectConfig(p, cfg);
}
#method_after
protected void deny(Project.NameKey p, String ref, String permission, AccountGroup.UUID id) throws Exception {
    try (ProjectConfigUpdate u = updateProject(p)) {
        Util.deny(u.getConfig(), permission, id, ref);
        u.save();
    }
}
#end_block

#method_before
protected PermissionRule block(Project.NameKey project, String ref, String permission, AccountGroup.UUID id) throws Exception {
    ProjectConfig cfg = projectCache.checkedGet(project).getConfig();
    PermissionRule rule = Util.block(cfg, permission, id, ref);
    saveProjectConfig(project, cfg);
    return rule;
}
#method_after
protected PermissionRule block(Project.NameKey project, String ref, String permission, AccountGroup.UUID id) throws Exception {
    try (ProjectConfigUpdate u = updateProject(project)) {
        PermissionRule rule = Util.block(u.getConfig(), permission, id, ref);
        u.save();
        return rule;
    }
}
#end_block

#method_before
protected void blockLabel(String label, int min, int max, AccountGroup.UUID id, String ref, Project.NameKey project) throws Exception {
    ProjectConfig cfg = projectCache.checkedGet(project).getConfig();
    Util.block(cfg, Permission.LABEL + label, min, max, id, ref);
    saveProjectConfig(project, cfg);
}
#method_after
protected void blockLabel(String label, int min, int max, AccountGroup.UUID id, String ref, Project.NameKey project) throws Exception {
    try (ProjectConfigUpdate u = updateProject(project)) {
        Util.block(u.getConfig(), Permission.LABEL + label, min, max, id, ref);
        u.save();
    }
}
#end_block

#method_before
protected void removePermission(Project.NameKey project, String ref, String permission) throws IOException, ConfigInvalidException {
    try (MetaDataUpdate md = metaDataUpdateFactory.create(project)) {
        md.setMessage(String.format("Remove %s on %s", permission, ref));
        ProjectConfig config = ProjectConfig.read(md);
        AccessSection s = config.getAccessSection(ref, true);
        Permission p = s.getPermission(permission, true);
        p.getRules().clear();
        config.commit(md);
        projectCache.evict(config.getProject());
    }
}
#method_after
protected void removePermission(Project.NameKey project, String ref, String permission) throws IOException, ConfigInvalidException {
    try (MetaDataUpdate md = metaDataUpdateFactory.create(project)) {
        md.setMessage(String.format("Remove %s on %s", permission, ref));
        ProjectConfig config = ProjectConfig.read(md);
        AccessSection s = config.getAccessSection(ref, true);
        Permission p = s.getPermission(permission, true);
        p.clearRules();
        config.commit(md);
        projectCache.evict(config.getProject());
    }
}
#end_block

#method_before
protected void assertSubmittedTogether(String chId, String... expected) throws Exception {
    List<ChangeInfo> actual = gApi.changes().id(chId).submittedTogether();
    SubmittedTogetherInfo info = gApi.changes().id(chId).submittedTogether(EnumSet.of(NON_VISIBLE_CHANGES));
    assertThat(info.nonVisibleChanges).isEqualTo(0);
    assertThat(changeIds(actual)).containsExactly((Object[]) expected).inOrder();
    assertThat(changeIds(info.changes)).containsExactly((Object[]) expected).inOrder();
}
#method_after
protected void assertSubmittedTogether(String chId, String... expected) throws Exception {
    List<ChangeInfo> actual = gApi.changes().id(chId).submittedTogether();
    SubmittedTogetherInfo info = gApi.changes().id(chId).submittedTogether(EnumSet.of(NON_VISIBLE_CHANGES));
    assertThat(info.nonVisibleChanges).isEqualTo(0);
    assertThat(Iterables.transform(actual, i1 -> i1.changeId)).containsExactly((Object[]) expected).inOrder();
    assertThat(Iterables.transform(info.changes, i -> i.changeId)).containsExactly((Object[]) expected).inOrder();
}
#end_block

#method_before
protected ContributorAgreement configureContributorAgreement(boolean autoVerify) throws Exception {
    ContributorAgreement ca;
    if (autoVerify) {
        String g = createGroup("cla-test-group");
        GroupApi groupApi = gApi.groups().id(g);
        groupApi.description("CLA test group");
        InternalGroup caGroup = group(new AccountGroup.UUID(groupApi.detail().id));
        GroupReference groupRef = new GroupReference(caGroup.getGroupUUID(), caGroup.getName());
        PermissionRule rule = new PermissionRule(groupRef);
        rule.setAction(PermissionRule.Action.ALLOW);
        ca = new ContributorAgreement("cla-test");
        ca.setAutoVerify(groupRef);
        ca.setAccepted(ImmutableList.of(rule));
    } else {
        ca = new ContributorAgreement("cla-test-no-auto-verify");
    }
    ca.setDescription("description");
    ca.setAgreementUrl("agreement-url");
    ProjectConfig cfg = projectCache.checkedGet(allProjects).getConfig();
    cfg.replace(ca);
    saveProjectConfig(allProjects, cfg);
    return ca;
}
#method_after
protected ContributorAgreement configureContributorAgreement(boolean autoVerify) throws Exception {
    ContributorAgreement ca;
    if (autoVerify) {
        String g = createGroup("cla-test-group");
        GroupApi groupApi = gApi.groups().id(g);
        groupApi.description("CLA test group");
        InternalGroup caGroup = group(new AccountGroup.UUID(groupApi.detail().id));
        GroupReference groupRef = new GroupReference(caGroup.getGroupUUID(), caGroup.getName());
        PermissionRule rule = new PermissionRule(groupRef);
        rule.setAction(PermissionRule.Action.ALLOW);
        ca = new ContributorAgreement("cla-test");
        ca.setAutoVerify(groupRef);
        ca.setAccepted(ImmutableList.of(rule));
    } else {
        ca = new ContributorAgreement("cla-test-no-auto-verify");
    }
    ca.setDescription("description");
    ca.setAgreementUrl("agreement-url");
    try (ProjectConfigUpdate u = updateProject(allProjects)) {
        u.getConfig().replace(ca);
        u.save();
        return ca;
    }
}
#end_block

#method_before
protected Map<Branch.NameKey, ObjectId> fetchFromSubmitPreview(String changeId) throws Exception {
    try (BinaryResult result = submitPreview(changeId)) {
        return fetchFromBundles(result);
    }
}
#method_after
protected Map<Branch.NameKey, ObjectId> fetchFromSubmitPreview(String changeId) throws Exception {
    try (BinaryResult result = gApi.changes().id(changeId).current().submitPreview()) {
        return fetchFromBundles(result);
    }
}
#end_block

#method_before
protected void assertDiffForNewFile(DiffInfo diff, RevCommit commit, String path, String expectedContentSideB) throws Exception {
    List<String> expectedLines = new ArrayList<>();
    for (String line : expectedContentSideB.split("\n")) {
        expectedLines.add(line);
    }
    assertThat(diff.binary).isNull();
    assertThat(diff.changeType).isEqualTo(ChangeType.ADDED);
    assertThat(diff.diffHeader).isNotNull();
    assertThat(diff.intralineStatus).isNull();
    assertThat(diff.webLinks).isNull();
    assertThat(diff.metaA).isNull();
    assertThat(diff.metaB).isNotNull();
    assertThat(diff.metaB.commitId).isEqualTo(commit.name());
    String expectedContentType = "text/plain";
    if (COMMIT_MSG.equals(path)) {
        expectedContentType = FileContentUtil.TEXT_X_GERRIT_COMMIT_MESSAGE;
    } else if (MERGE_LIST.equals(path)) {
        expectedContentType = FileContentUtil.TEXT_X_GERRIT_MERGE_LIST;
    }
    assertThat(diff.metaB.contentType).isEqualTo(expectedContentType);
    assertThat(diff.metaB.lines).isEqualTo(expectedLines.size());
    assertThat(diff.metaB.name).isEqualTo(path);
    assertThat(diff.metaB.webLinks).isNull();
    assertThat(diff.content).hasSize(1);
    DiffInfo.ContentEntry contentEntry = diff.content.get(0);
    assertThat(contentEntry.b).containsExactlyElementsIn(expectedLines).inOrder();
    assertThat(contentEntry.a).isNull();
    assertThat(contentEntry.ab).isNull();
    assertThat(contentEntry.common).isNull();
    assertThat(contentEntry.editA).isNull();
    assertThat(contentEntry.editB).isNull();
    assertThat(contentEntry.skip).isNull();
}
#method_after
protected void assertDiffForNewFile(DiffInfo diff, RevCommit commit, String path, String expectedContentSideB) throws Exception {
    List<String> expectedLines = ImmutableList.copyOf(expectedContentSideB.split("\n", -1));
    assertThat(diff.binary).isNull();
    assertThat(diff.changeType).isEqualTo(ChangeType.ADDED);
    assertThat(diff.diffHeader).isNotNull();
    assertThat(diff.intralineStatus).isNull();
    assertThat(diff.webLinks).isNull();
    assertThat(diff.metaA).isNull();
    assertThat(diff.metaB).isNotNull();
    assertThat(diff.metaB.commitId).isEqualTo(commit.name());
    String expectedContentType = "text/plain";
    if (COMMIT_MSG.equals(path)) {
        expectedContentType = FileContentUtil.TEXT_X_GERRIT_COMMIT_MESSAGE;
    } else if (MERGE_LIST.equals(path)) {
        expectedContentType = FileContentUtil.TEXT_X_GERRIT_MERGE_LIST;
    }
    assertThat(diff.metaB.contentType).isEqualTo(expectedContentType);
    assertThat(diff.metaB.lines).isEqualTo(expectedLines.size());
    assertThat(diff.metaB.name).isEqualTo(path);
    assertThat(diff.metaB.webLinks).isNull();
    assertThat(diff.content).hasSize(1);
    DiffInfo.ContentEntry contentEntry = diff.content.get(0);
    assertThat(contentEntry.b).containsExactlyElementsIn(expectedLines).inOrder();
    assertThat(contentEntry.a).isNull();
    assertThat(contentEntry.ab).isNull();
    assertThat(contentEntry.common).isNull();
    assertThat(contentEntry.editA).isNull();
    assertThat(contentEntry.editB).isNull();
    assertThat(contentEntry.skip).isNull();
}
#end_block

#method_before
private void assertPermission(Permission permission, String expectedName, boolean expectedExclusive, @Nullable String expectedLabelName) {
    assertThat(permission).isNotNull();
    assertThat(permission.getName()).isEqualTo(expectedName);
    assertThat(permission.getExclusiveGroup()).isEqualTo(expectedExclusive);
    assertThat(permission.getLabel()).isEqualTo(expectedLabelName);
}
#method_after
protected void assertPermission(Permission permission, String expectedName, boolean expectedExclusive, @Nullable String expectedLabelName) {
    assertThat(permission).isNotNull();
    assertThat(permission.getName()).isEqualTo(expectedName);
    assertThat(permission.getExclusiveGroup()).isEqualTo(expectedExclusive);
    assertThat(permission.getLabel()).isEqualTo(expectedLabelName);
}
#end_block

#method_before
private void assertPermissionRule(PermissionRule rule, GroupReference expectedGroupReference, Action expectedAction, boolean expectedForce, int expectedMin, int expectedMax) {
    assertThat(rule.getGroup()).isEqualTo(expectedGroupReference);
    assertThat(rule.getAction()).isEqualTo(expectedAction);
    assertThat(rule.getForce()).isEqualTo(expectedForce);
    assertThat(rule.getMin()).isEqualTo(expectedMin);
    assertThat(rule.getMax()).isEqualTo(expectedMax);
}
#method_after
protected void assertPermissionRule(PermissionRule rule, GroupReference expectedGroupReference, Action expectedAction, boolean expectedForce, int expectedMin, int expectedMax) {
    assertThat(rule.getGroup()).isEqualTo(expectedGroupReference);
    assertThat(rule.getAction()).isEqualTo(expectedAction);
    assertThat(rule.getForce()).isEqualTo(expectedForce);
    assertThat(rule.getMin()).isEqualTo(expectedMin);
    assertThat(rule.getMax()).isEqualTo(expectedMax);
}
#end_block

#method_before
protected void assertNotifyTo(TestAccount expected) {
    assertNotifyTo(expected.emailAddress);
}
#method_after
protected void assertNotifyTo(TestAccount expected) {
    assertNotifyTo(expected.email, expected.fullName);
}
#end_block

#method_before
protected void assertNotifyTo(Address expected) {
    assertThat(sender.getMessages()).hasSize(1);
    Message m = sender.getMessages().get(0);
    assertThat(m.rcpt()).containsExactly(expected);
    assertThat(((EmailHeader.AddressList) m.headers().get("To")).getAddressList()).containsExactly(expected);
    assertThat(m.headers().get("Cc").isEmpty()).isTrue();
}
#method_after
protected void assertNotifyTo(com.google.gerrit.acceptance.testsuite.account.TestAccount expected) {
    assertNotifyTo(expected.preferredEmail().orElse(null), expected.fullname().orElse(null));
}
#end_block

#method_before
protected void assertNotifyCc(Address expected) {
    assertThat(sender.getMessages()).hasSize(1);
    Message m = sender.getMessages().get(0);
    assertThat(m.rcpt()).containsExactly(expected);
    assertThat(m.headers().get("To").isEmpty()).isTrue();
    assertThat(((EmailHeader.AddressList) m.headers().get("Cc")).getAddressList()).containsExactly(expected);
}
#method_after
protected void assertNotifyCc(com.google.gerrit.acceptance.testsuite.account.TestAccount expected) {
    assertNotifyCc(expected.preferredEmail().orElse(null), expected.fullname().orElse(null));
}
#end_block

#method_before
protected void assertNotifyCc(Address expected) {
    assertThat(sender.getMessages()).hasSize(1);
    Message m = sender.getMessages().get(0);
    assertThat(m.rcpt()).containsExactly(expected);
    assertThat(m.headers().get("To").isEmpty()).isTrue();
    assertThat(((EmailHeader.AddressList) m.headers().get("Cc")).getAddressList()).containsExactly(expected);
}
#method_after
protected void assertNotifyCc(Address expectedAddress) {
    assertThat(sender.getMessages()).hasSize(1);
    Message m = sender.getMessages().get(0);
    assertThat(m.rcpt()).containsExactly(expectedAddress);
    assertThat(m.headers().get("To").isEmpty()).isTrue();
    assertThat(((EmailHeader.AddressList) m.headers().get("Cc")).getAddressList()).containsExactly(expectedAddress);
}
#end_block

#method_before
protected void assertNotifyBcc(TestAccount expected) {
    assertThat(sender.getMessages()).hasSize(1);
    Message m = sender.getMessages().get(0);
    assertThat(m.rcpt()).containsExactly(expected.emailAddress);
    assertThat(m.headers().get("To").isEmpty()).isTrue();
    assertThat(m.headers().get("Cc").isEmpty()).isTrue();
}
#method_after
protected void assertNotifyBcc(com.google.gerrit.acceptance.testsuite.account.TestAccount expected) {
    assertThat(sender.getMessages()).hasSize(1);
    Message m = sender.getMessages().get(0);
    assertThat(m.rcpt()).containsExactly(new Address(expected.fullname().orElse(null), expected.preferredEmail().orElse(null)));
    assertThat(m.headers().get("To").isEmpty()).isTrue();
    assertThat(m.headers().get("Cc").isEmpty()).isTrue();
}
#end_block

#method_before
protected void configLabel(String label, LabelFunction func) throws Exception {
    configLabel(project, label, func, value(1, "Passes"), value(0, "No score"), value(-1, "Failed"));
}
#method_after
protected void configLabel(String label, LabelFunction func) throws Exception {
    configLabel(label, func, ImmutableList.of());
}
#end_block

#method_before
protected void configLabel(Project.NameKey project, String label, LabelFunction func, LabelValue... value) throws Exception {
    ProjectConfig cfg = projectCache.checkedGet(project).getConfig();
    LabelType labelType = category(label, value);
    labelType.setFunction(func);
    cfg.getLabelSections().put(labelType.getName(), labelType);
    saveProjectConfig(project, cfg);
}
#method_after
protected void configLabel(String label, LabelFunction func, List<String> refPatterns) throws Exception {
    configLabel(project, label, func, refPatterns, value(1, "Passes"), value(0, "No score"), value(-1, "Failed"));
}
#end_block

#method_before
protected void configLabel(Project.NameKey project, String label, LabelFunction func, LabelValue... value) throws Exception {
    ProjectConfig cfg = projectCache.checkedGet(project).getConfig();
    LabelType labelType = category(label, value);
    labelType.setFunction(func);
    cfg.getLabelSections().put(labelType.getName(), labelType);
    saveProjectConfig(project, cfg);
}
#method_after
protected void configLabel(Project.NameKey project, String label, LabelFunction func, LabelValue... value) throws Exception {
    configLabel(project, label, func, ImmutableList.of(), value);
}
#end_block

#method_before
protected void enableCreateNewChangeForAllNotInTarget() throws Exception {
    ProjectConfig config = projectCache.checkedGet(project).getConfig();
    config.getProject().setBooleanConfig(BooleanProjectConfig.CREATE_NEW_CHANGE_FOR_ALL_NOT_IN_TARGET, InheritableBoolean.TRUE);
    saveProjectConfig(project, config);
}
#method_after
protected void enableCreateNewChangeForAllNotInTarget() throws Exception {
    try (ProjectConfigUpdate u = updateProject(project)) {
        u.getConfig().getProject().setBooleanConfig(BooleanProjectConfig.CREATE_NEW_CHANGE_FOR_ALL_NOT_IN_TARGET, InheritableBoolean.TRUE);
        u.save();
    }
}
#end_block

#method_before
@Test
public void publishCommentsAllRevisions() throws Exception {
    PushOneCommit.Result r1 = createChange();
    PushOneCommit.Result r2 = pushFactory.create(db, admin.getIdent(), testRepo, SUBJECT, FILE_NAME, "new\ncntent\n", r1.getChangeId()).to("refs/for/master");
    addDraft(r1.getChangeId(), r1.getCommit().getName(), newDraft(FILE_NAME, Side.REVISION, 1, "nit: trailing whitespace"));
    addDraft(r1.getChangeId(), r1.getCommit().getName(), newDraft(FILE_NAME, Side.PARENT, 2, "what happened to this?"));
    addDraft(r2.getChangeId(), r2.getCommit().getName(), newDraft(FILE_NAME, Side.REVISION, 1, "join lines"));
    addDraft(r2.getChangeId(), r2.getCommit().getName(), newDraft(FILE_NAME, Side.REVISION, 2, "typo: content"));
    addDraft(r2.getChangeId(), r2.getCommit().getName(), newDraft(FILE_NAME, Side.PARENT, 1, "comment 1 on base"));
    addDraft(r2.getChangeId(), r2.getCommit().getName(), newDraft(FILE_NAME, Side.PARENT, 2, "comment 2 on base"));
    PushOneCommit.Result other = createChange();
    // Drafts on other changes aren't returned.
    addDraft(other.getChangeId(), other.getCommit().getName(), newDraft(FILE_NAME, Side.REVISION, 1, "unrelated comment"));
    setApiUser(admin);
    // Drafts by other users aren't returned.
    addDraft(r2.getChangeId(), r2.getCommit().getName(), newDraft(FILE_NAME, Side.REVISION, 2, "oops"));
    setApiUser(user);
    ReviewInput reviewInput = new ReviewInput();
    reviewInput.drafts = DraftHandling.PUBLISH_ALL_REVISIONS;
    reviewInput.message = "comments";
    gApi.changes().id(r2.getChangeId()).current().review(reviewInput);
    assertThat(gApi.changes().id(r1.getChangeId()).revision(r1.getCommit().name()).drafts()).isEmpty();
    Map<String, List<CommentInfo>> ps1Map = gApi.changes().id(r1.getChangeId()).revision(r1.getCommit().name()).comments();
    assertThat(ps1Map.keySet()).containsExactly(FILE_NAME);
    List<CommentInfo> ps1List = ps1Map.get(FILE_NAME);
    assertThat(ps1List).hasSize(2);
    assertThat(ps1List.get(0).message).isEqualTo("what happened to this?");
    assertThat(ps1List.get(0).side).isEqualTo(Side.PARENT);
    assertThat(ps1List.get(1).message).isEqualTo("nit: trailing whitespace");
    assertThat(ps1List.get(1).side).isNull();
    assertThat(gApi.changes().id(r2.getChangeId()).revision(r2.getCommit().name()).drafts()).isEmpty();
    Map<String, List<CommentInfo>> ps2Map = gApi.changes().id(r2.getChangeId()).revision(r2.getCommit().name()).comments();
    assertThat(ps2Map.keySet()).containsExactly(FILE_NAME);
    List<CommentInfo> ps2List = ps2Map.get(FILE_NAME);
    assertThat(ps2List).hasSize(4);
    assertThat(ps2List.get(0).message).isEqualTo("comment 1 on base");
    assertThat(ps2List.get(1).message).isEqualTo("comment 2 on base");
    assertThat(ps2List.get(2).message).isEqualTo("join lines");
    assertThat(ps2List.get(3).message).isEqualTo("typo: content");
    List<Message> messages = email.getMessages(r2.getChangeId(), "comment");
    assertThat(messages).hasSize(1);
    String url = canonicalWebUrl.get();
    int c = r1.getChange().getId().get();
    assertThat(extractComments(messages.get(0).body())).isEqualTo("Patch Set 2:\n" + "\n" + "(6 comments)\n" + "\n" + "comments\n" + "\n" + url + "#/c/" + c + "/1/a.txt\n" + "File a.txt:\n" + "\n" + url + "#/c/" + c + "/1/a.txt@a2\n" + "PS1, Line 2: \n" + "what happened to this?\n" + "\n" + "\n" + url + "#/c/" + c + "/1/a.txt@1\n" + "PS1, Line 1: ew\n" + "nit: trailing whitespace\n" + "\n" + "\n" + url + "#/c/" + c + "/2/a.txt\n" + "File a.txt:\n" + "\n" + url + "#/c/" + c + "/2/a.txt@a1\n" + "PS2, Line 1: \n" + "comment 1 on base\n" + "\n" + "\n" + url + "#/c/" + c + "/2/a.txt@a2\n" + "PS2, Line 2: \n" + "comment 2 on base\n" + "\n" + "\n" + url + "#/c/" + c + "/2/a.txt@1\n" + "PS2, Line 1: ew\n" + "join lines\n" + "\n" + "\n" + url + "#/c/" + c + "/2/a.txt@2\n" + "PS2, Line 2: nten\n" + "typo: content\n" + "\n" + "\n");
}
#method_after
@Test
public void publishCommentsAllRevisions() throws Exception {
    PushOneCommit.Result r1 = createChange();
    PushOneCommit.Result r2 = pushFactory.create(db, admin.getIdent(), testRepo, SUBJECT, FILE_NAME, "new\ncntent\n", r1.getChangeId()).to("refs/for/master");
    addDraft(r1.getChangeId(), r1.getCommit().getName(), newDraft(FILE_NAME, Side.REVISION, 1, "nit: trailing whitespace"));
    addDraft(r1.getChangeId(), r1.getCommit().getName(), newDraft(FILE_NAME, Side.PARENT, 2, "what happened to this?"));
    addDraft(r2.getChangeId(), r2.getCommit().getName(), newDraft(FILE_NAME, Side.REVISION, 1, "join lines"));
    addDraft(r2.getChangeId(), r2.getCommit().getName(), newDraft(FILE_NAME, Side.REVISION, 2, "typo: content"));
    addDraft(r2.getChangeId(), r2.getCommit().getName(), newDraft(FILE_NAME, Side.PARENT, 1, "comment 1 on base"));
    addDraft(r2.getChangeId(), r2.getCommit().getName(), newDraft(FILE_NAME, Side.PARENT, 2, "comment 2 on base"));
    PushOneCommit.Result other = createChange();
    // Drafts on other changes aren't returned.
    addDraft(other.getChangeId(), other.getCommit().getName(), newDraft(FILE_NAME, Side.REVISION, 1, "unrelated comment"));
    setApiUser(admin);
    // Drafts by other users aren't returned.
    addDraft(r2.getChangeId(), r2.getCommit().getName(), newDraft(FILE_NAME, Side.REVISION, 2, "oops"));
    setApiUser(user);
    ReviewInput reviewInput = new ReviewInput();
    reviewInput.drafts = DraftHandling.PUBLISH_ALL_REVISIONS;
    reviewInput.message = "comments";
    gApi.changes().id(r2.getChangeId()).current().review(reviewInput);
    assertThat(gApi.changes().id(r1.getChangeId()).revision(r1.getCommit().name()).drafts()).isEmpty();
    Map<String, List<CommentInfo>> ps1Map = gApi.changes().id(r1.getChangeId()).revision(r1.getCommit().name()).comments();
    assertThat(ps1Map.keySet()).containsExactly(FILE_NAME);
    List<CommentInfo> ps1List = ps1Map.get(FILE_NAME);
    assertThat(ps1List).hasSize(2);
    assertThat(ps1List.get(0).message).isEqualTo("what happened to this?");
    assertThat(ps1List.get(0).side).isEqualTo(Side.PARENT);
    assertThat(ps1List.get(1).message).isEqualTo("nit: trailing whitespace");
    assertThat(ps1List.get(1).side).isNull();
    assertThat(gApi.changes().id(r2.getChangeId()).revision(r2.getCommit().name()).drafts()).isEmpty();
    Map<String, List<CommentInfo>> ps2Map = gApi.changes().id(r2.getChangeId()).revision(r2.getCommit().name()).comments();
    assertThat(ps2Map.keySet()).containsExactly(FILE_NAME);
    List<CommentInfo> ps2List = ps2Map.get(FILE_NAME);
    assertThat(ps2List).hasSize(4);
    assertThat(ps2List.get(0).message).isEqualTo("comment 1 on base");
    assertThat(ps2List.get(1).message).isEqualTo("comment 2 on base");
    assertThat(ps2List.get(2).message).isEqualTo("join lines");
    assertThat(ps2List.get(3).message).isEqualTo("typo: content");
    List<Message> messages = email.getMessages(r2.getChangeId(), "comment");
    assertThat(messages).hasSize(1);
    String url = canonicalWebUrl.get();
    int c = r1.getChange().getId().get();
    assertThat(extractComments(messages.get(0).body())).isEqualTo("Patch Set 2:\n" + "\n" + "(6 comments)\n" + "\n" + "comments\n" + "\n" + url + "#/c/" + c + "/1/a.txt \n" + "File a.txt:\n" + "\n" + url + "#/c/" + c + "/1/a.txt@a2 \n" + "PS1, Line 2: \n" + "what happened to this?\n" + "\n" + "\n" + url + "#/c/" + c + "/1/a.txt@1 \n" + "PS1, Line 1: ew\n" + "nit: trailing whitespace\n" + "\n" + "\n" + url + "#/c/" + c + "/2/a.txt \n" + "File a.txt:\n" + "\n" + url + "#/c/" + c + "/2/a.txt@a1 \n" + "PS2, Line 1: \n" + "comment 1 on base\n" + "\n" + "\n" + url + "#/c/" + c + "/2/a.txt@a2 \n" + "PS2, Line 2: \n" + "comment 2 on base\n" + "\n" + "\n" + url + "#/c/" + c + "/2/a.txt@1 \n" + "PS2, Line 1: ew\n" + "join lines\n" + "\n" + "\n" + url + "#/c/" + c + "/2/a.txt@2 \n" + "PS2, Line 2: nten\n" + "typo: content\n" + "\n" + "\n");
}
#end_block

#method_before
@Test
public void deleteCommentByRewritingCommitHistory() throws Exception {
    // Creates the following commit history on the meta branch of the test change. Then tries to
    // delete the comments one by one, which will rewrite most of the commits on the 'meta' branch.
    // Commits will be rewritten N times for N added comments. After each deletion, the meta branch
    // should keep its previous state except that the target comment's message should be updated.
    // 1st commit: Create PS1.
    PushOneCommit.Result result1 = createChange(SUBJECT, "a.txt", "a");
    Change.Id id = result1.getChange().getId();
    String changeId = result1.getChangeId();
    String ps1 = result1.getCommit().name();
    // 2nd commit: Add (c1) to PS1.
    CommentInput c1 = newComment("a.txt", "comment 1");
    addComments(changeId, ps1, c1);
    // 3rd commit: Add (c2, c3) to PS1.
    CommentInput c2 = newComment("a.txt", "comment 2");
    CommentInput c3 = newComment("a.txt", "comment 3");
    addComments(changeId, ps1, c2, c3);
    // 4th commit: Add (c4) to PS1.
    CommentInput c4 = newComment("a.txt", "comment 4");
    addComments(changeId, ps1, c4);
    // 5th commit: Create PS2.
    PushOneCommit.Result result2 = amendChange(changeId, "refs/for/master", "b.txt", "b");
    String ps2 = result2.getCommit().name();
    // 6th commit: Add (c5) to PS1.
    CommentInput c5 = newComment("a.txt", "comment 5");
    addComments(changeId, ps1, c5);
    // 7th commit: Add (c6) to PS2.
    CommentInput c6 = newComment("b.txt", "comment 6");
    addComments(changeId, ps2, c6);
    // 8th commit: Create PS3.
    PushOneCommit.Result result3 = amendChange(changeId);
    String ps3 = result3.getCommit().name();
    // 9th commit: Create PS4.
    PushOneCommit.Result result4 = amendChange(changeId, "refs/for/master", "c.txt", "c");
    String ps4 = result4.getCommit().name();
    // 10th commit: Add (c7, c8) to PS4.
    CommentInput c7 = newComment("c.txt", "comment 7");
    CommentInput c8 = newComment("b.txt", "comment 8");
    addComments(changeId, ps4, c7, c8);
    // 11th commit: Add (c9) to PS2.
    CommentInput c9 = newComment("b.txt", "comment 9");
    addComments(changeId, ps2, c9);
    List<CommentInfo> commentsBeforeDelete = getChangeSortedComments(id.get());
    assertThat(commentsBeforeDelete).hasSize(9);
    // PS1 has comments [c1, c2, c3, c4, c5].
    assertThat(getRevisionComments(changeId, ps1)).hasSize(5);
    // PS2 has comments [c6, c9].
    assertThat(getRevisionComments(changeId, ps2)).hasSize(2);
    // PS3 has no comment.
    assertThat(getRevisionComments(changeId, ps3)).hasSize(0);
    // PS4 has comments [c7, c8].
    assertThat(getRevisionComments(changeId, ps4)).hasSize(2);
    setApiUser(admin);
    for (int i = 0; i < commentsBeforeDelete.size(); i++) {
        List<RevCommit> commitsBeforeDelete = new ArrayList<>();
        if (notesMigration.commitChangeWrites()) {
            commitsBeforeDelete = getCommits(id);
        }
        CommentInfo comment = commentsBeforeDelete.get(i);
        String uuid = comment.id;
        int patchSet = comment.patchSet;
        // 'oldComment' has some fields unset compared with 'comment'.
        CommentInfo oldComment = gApi.changes().id(changeId).revision(patchSet).comment(uuid).get();
        DeleteCommentInput input = new DeleteCommentInput("delete comment " + uuid);
        CommentInfo updatedComment = gApi.changes().id(changeId).revision(patchSet).comment(uuid).delete(input);
        String expectedMsg = String.format("Comment removed by: %s; Reason: %s", admin.fullName, input.reason);
        assertThat(updatedComment.message).isEqualTo(expectedMsg);
        oldComment.message = expectedMsg;
        assertThat(updatedComment).isEqualTo(oldComment);
        // Check the NoteDb state after the deletion.
        if (notesMigration.commitChangeWrites()) {
            assertMetaBranchCommitsAfterRewriting(commitsBeforeDelete, id, uuid, expectedMsg);
        }
        comment.message = expectedMsg;
        commentsBeforeDelete.set(i, comment);
        List<CommentInfo> commentsAfterDelete = getChangeSortedComments(id.get());
        assertThat(commentsAfterDelete).isEqualTo(commentsBeforeDelete);
    }
    // Make sure that comments can still be added correctly.
    CommentInput c10 = newComment("a.txt", "comment 10");
    CommentInput c11 = newComment("b.txt", "comment 11");
    CommentInput c12 = newComment("a.txt", "comment 12");
    CommentInput c13 = newComment("c.txt", "comment 13");
    addComments(changeId, ps1, c10);
    addComments(changeId, ps2, c11);
    addComments(changeId, ps3, c12);
    addComments(changeId, ps4, c13);
    assertThat(getChangeSortedComments(id.get())).hasSize(13);
    assertThat(getRevisionComments(changeId, ps1)).hasSize(6);
    assertThat(getRevisionComments(changeId, ps2)).hasSize(3);
    assertThat(getRevisionComments(changeId, ps3)).hasSize(1);
    assertThat(getRevisionComments(changeId, ps4)).hasSize(3);
}
#method_after
@Test
public void deleteCommentByRewritingCommitHistory() throws Exception {
    // Creates the following commit history on the meta branch of the test change. Then tries to
    // delete the comments one by one, which will rewrite most of the commits on the 'meta' branch.
    // Commits will be rewritten N times for N added comments. After each deletion, the meta branch
    // should keep its previous state except that the target comment's message should be updated.
    // 1st commit: Create PS1.
    PushOneCommit.Result result1 = createChange(SUBJECT, "a.txt", "a");
    Change.Id id = result1.getChange().getId();
    String changeId = result1.getChangeId();
    String ps1 = result1.getCommit().name();
    // 2nd commit: Add (c1) to PS1.
    CommentInput c1 = newComment("a.txt", "comment 1");
    addComments(changeId, ps1, c1);
    // 3rd commit: Add (c2, c3) to PS1.
    CommentInput c2 = newComment("a.txt", "comment 2");
    CommentInput c3 = newComment("a.txt", "comment 3");
    addComments(changeId, ps1, c2, c3);
    // 4th commit: Add (c4) to PS1.
    CommentInput c4 = newComment("a.txt", "comment 4");
    addComments(changeId, ps1, c4);
    // 5th commit: Create PS2.
    PushOneCommit.Result result2 = amendChange(changeId, "refs/for/master", "b.txt", "b");
    String ps2 = result2.getCommit().name();
    // 6th commit: Add (c5) to PS1.
    CommentInput c5 = newComment("a.txt", "comment 5");
    addComments(changeId, ps1, c5);
    // 7th commit: Add (c6) to PS2.
    CommentInput c6 = newComment("b.txt", "comment 6");
    addComments(changeId, ps2, c6);
    // 8th commit: Create PS3.
    PushOneCommit.Result result3 = amendChange(changeId);
    String ps3 = result3.getCommit().name();
    // 9th commit: Create PS4.
    PushOneCommit.Result result4 = amendChange(changeId, "refs/for/master", "c.txt", "c");
    String ps4 = result4.getCommit().name();
    // 10th commit: Add (c7, c8) to PS4.
    CommentInput c7 = newComment("c.txt", "comment 7");
    CommentInput c8 = newComment("b.txt", "comment 8");
    addComments(changeId, ps4, c7, c8);
    // 11th commit: Add (c9) to PS2.
    CommentInput c9 = newComment("b.txt", "comment 9");
    addComments(changeId, ps2, c9);
    List<CommentInfo> commentsBeforeDelete = getChangeSortedComments(id.get());
    assertThat(commentsBeforeDelete).hasSize(9);
    // PS1 has comments [c1, c2, c3, c4, c5].
    assertThat(getRevisionComments(changeId, ps1)).hasSize(5);
    // PS2 has comments [c6, c9].
    assertThat(getRevisionComments(changeId, ps2)).hasSize(2);
    // PS3 has no comment.
    assertThat(getRevisionComments(changeId, ps3)).hasSize(0);
    // PS4 has comments [c7, c8].
    assertThat(getRevisionComments(changeId, ps4)).hasSize(2);
    setApiUser(admin);
    for (int i = 0; i < commentsBeforeDelete.size(); i++) {
        List<RevCommit> commitsBeforeDelete = new ArrayList<>();
        if (notesMigration.commitChangeWrites()) {
            commitsBeforeDelete = getChangeMetaCommitsInReverseOrder(id);
        }
        CommentInfo comment = commentsBeforeDelete.get(i);
        String uuid = comment.id;
        int patchSet = comment.patchSet;
        // 'oldComment' has some fields unset compared with 'comment'.
        CommentInfo oldComment = gApi.changes().id(changeId).revision(patchSet).comment(uuid).get();
        DeleteCommentInput input = new DeleteCommentInput("delete comment " + uuid);
        CommentInfo updatedComment = gApi.changes().id(changeId).revision(patchSet).comment(uuid).delete(input);
        String expectedMsg = String.format("Comment removed by: %s; Reason: %s", admin.fullName, input.reason);
        assertThat(updatedComment.message).isEqualTo(expectedMsg);
        oldComment.message = expectedMsg;
        assertThat(updatedComment).isEqualTo(oldComment);
        // Check the NoteDb state after the deletion.
        if (notesMigration.commitChangeWrites()) {
            assertMetaBranchCommitsAfterRewriting(commitsBeforeDelete, id, uuid, expectedMsg);
        }
        comment.message = expectedMsg;
        commentsBeforeDelete.set(i, comment);
        List<CommentInfo> commentsAfterDelete = getChangeSortedComments(id.get());
        assertThat(commentsAfterDelete).isEqualTo(commentsBeforeDelete);
    }
    // Make sure that comments can still be added correctly.
    CommentInput c10 = newComment("a.txt", "comment 10");
    CommentInput c11 = newComment("b.txt", "comment 11");
    CommentInput c12 = newComment("a.txt", "comment 12");
    CommentInput c13 = newComment("c.txt", "comment 13");
    addComments(changeId, ps1, c10);
    addComments(changeId, ps2, c11);
    addComments(changeId, ps3, c12);
    addComments(changeId, ps4, c13);
    assertThat(getChangeSortedComments(id.get())).hasSize(13);
    assertThat(getRevisionComments(changeId, ps1)).hasSize(6);
    assertThat(getRevisionComments(changeId, ps2)).hasSize(3);
    assertThat(getRevisionComments(changeId, ps3)).hasSize(1);
    assertThat(getRevisionComments(changeId, ps4)).hasSize(3);
}
#end_block

#method_before
@Test
public void deleteOneCommentMultipleTimes() throws Exception {
    PushOneCommit.Result result = createChange();
    Change.Id id = result.getChange().getId();
    String changeId = result.getChangeId();
    String ps1 = result.getCommit().name();
    CommentInput c1 = newComment(FILE_NAME, "comment 1");
    CommentInput c2 = newComment(FILE_NAME, "comment 2");
    CommentInput c3 = newComment(FILE_NAME, "comment 3");
    addComments(changeId, ps1, c1);
    addComments(changeId, ps1, c2);
    addComments(changeId, ps1, c3);
    List<CommentInfo> commentsBeforeDelete = getChangeSortedComments(id.get());
    assertThat(commentsBeforeDelete).hasSize(3);
    Optional<CommentInfo> targetComment = commentsBeforeDelete.stream().filter(c -> c.message.equals("comment 2")).findFirst();
    assertThat(targetComment).isPresent();
    String uuid = targetComment.get().id;
    CommentInfo oldComment = gApi.changes().id(changeId).revision(ps1).comment(uuid).get();
    List<RevCommit> commitsBeforeDelete = new ArrayList<>();
    if (notesMigration.commitChangeWrites()) {
        commitsBeforeDelete = getCommits(id);
    }
    setApiUser(admin);
    for (int i = 0; i < 3; i++) {
        DeleteCommentInput input = new DeleteCommentInput("delete comment 2, iteration: " + i);
        gApi.changes().id(changeId).revision(ps1).comment(uuid).delete(input);
    }
    CommentInfo updatedComment = gApi.changes().id(changeId).revision(ps1).comment(uuid).get();
    String expectedMsg = String.format("Comment removed by: %s; Reason: %s", admin.fullName, "delete comment 2, iteration: 2");
    assertThat(updatedComment.message).isEqualTo(expectedMsg);
    oldComment.message = expectedMsg;
    assertThat(updatedComment).isEqualTo(oldComment);
    if (notesMigration.commitChangeWrites()) {
        assertMetaBranchCommitsAfterRewriting(commitsBeforeDelete, id, uuid, expectedMsg);
    }
    assertThat(getChangeSortedComments(id.get())).hasSize(3);
}
#method_after
@Test
public void deleteOneCommentMultipleTimes() throws Exception {
    PushOneCommit.Result result = createChange();
    Change.Id id = result.getChange().getId();
    String changeId = result.getChangeId();
    String ps1 = result.getCommit().name();
    CommentInput c1 = newComment(FILE_NAME, "comment 1");
    CommentInput c2 = newComment(FILE_NAME, "comment 2");
    CommentInput c3 = newComment(FILE_NAME, "comment 3");
    addComments(changeId, ps1, c1);
    addComments(changeId, ps1, c2);
    addComments(changeId, ps1, c3);
    List<CommentInfo> commentsBeforeDelete = getChangeSortedComments(id.get());
    assertThat(commentsBeforeDelete).hasSize(3);
    Optional<CommentInfo> targetComment = commentsBeforeDelete.stream().filter(c -> c.message.equals("comment 2")).findFirst();
    assertThat(targetComment).isPresent();
    String uuid = targetComment.get().id;
    CommentInfo oldComment = gApi.changes().id(changeId).revision(ps1).comment(uuid).get();
    List<RevCommit> commitsBeforeDelete = new ArrayList<>();
    if (notesMigration.commitChangeWrites()) {
        commitsBeforeDelete = getChangeMetaCommitsInReverseOrder(id);
    }
    setApiUser(admin);
    for (int i = 0; i < 3; i++) {
        DeleteCommentInput input = new DeleteCommentInput("delete comment 2, iteration: " + i);
        gApi.changes().id(changeId).revision(ps1).comment(uuid).delete(input);
    }
    CommentInfo updatedComment = gApi.changes().id(changeId).revision(ps1).comment(uuid).get();
    String expectedMsg = String.format("Comment removed by: %s; Reason: %s", admin.fullName, "delete comment 2, iteration: 2");
    assertThat(updatedComment.message).isEqualTo(expectedMsg);
    oldComment.message = expectedMsg;
    assertThat(updatedComment).isEqualTo(oldComment);
    if (notesMigration.commitChangeWrites()) {
        assertMetaBranchCommitsAfterRewriting(commitsBeforeDelete, id, uuid, expectedMsg);
    }
    assertThat(getChangeSortedComments(id.get())).hasSize(3);
}
#end_block

#method_before
@Test
public void jsonCommentHasLegacyFormatFalse() throws Exception {
    assume().that(notesMigration.readChanges()).isTrue();
    assertThat(noteUtil.getWriteJson()).isTrue();
    PushOneCommit.Result result = createChange();
    Change.Id changeId = result.getChange().getId();
    addComment(result.getChangeId(), "comment");
    Collection<com.google.gerrit.reviewdb.client.Comment> comments = notesFactory.createChecked(db, project, changeId).getComments().values();
    assertThat(comments).hasSize(1);
    com.google.gerrit.reviewdb.client.Comment comment = comments.iterator().next();
    assertThat(comment.message).isEqualTo("comment");
    assertThat(comment.legacyFormat).isFalse();
}
#method_after
@Test
public void jsonCommentHasLegacyFormatFalse() throws Exception {
    assume().that(notesMigration.readChanges()).isTrue();
    PushOneCommit.Result result = createChange();
    Change.Id changeId = result.getChange().getId();
    addComment(result.getChangeId(), "comment");
    Collection<com.google.gerrit.reviewdb.client.Comment> comments = notesFactory.createChecked(db, project, changeId).getComments().values();
    assertThat(comments).hasSize(1);
    com.google.gerrit.reviewdb.client.Comment comment = comments.iterator().next();
    assertThat(comment.message).isEqualTo("comment");
    assertThat(comment.legacyFormat).isFalse();
}
#end_block

#method_before
private void assertMetaBranchCommitsAfterRewriting(List<RevCommit> beforeDelete, Change.Id changeId, String targetCommentUuid, String expectedMessage) throws Exception {
    List<RevCommit> afterDelete = getCommits(changeId);
    assertThat(afterDelete).hasSize(beforeDelete.size());
    try (Repository repo = repoManager.openRepository(project);
        ObjectReader reader = repo.newObjectReader()) {
        for (int i = 0; i < beforeDelete.size(); i++) {
            RevCommit commitBefore = beforeDelete.get(i);
            RevCommit commitAfter = afterDelete.get(i);
            Map<String, com.google.gerrit.reviewdb.client.Comment> commentMapBefore = DeleteCommentRewriter.getPublishedComments(noteUtil, changeId, reader, NoteMap.read(reader, commitBefore));
            Map<String, com.google.gerrit.reviewdb.client.Comment> commentMapAfter = DeleteCommentRewriter.getPublishedComments(noteUtil, changeId, reader, NoteMap.read(reader, commitAfter));
            if (commentMapBefore.containsKey(targetCommentUuid)) {
                assertThat(commentMapAfter).containsKey(targetCommentUuid);
                com.google.gerrit.reviewdb.client.Comment comment = commentMapAfter.get(targetCommentUuid);
                assertThat(comment.message).isEqualTo(expectedMessage);
                comment.message = commentMapBefore.get(targetCommentUuid).message;
                commentMapAfter.put(targetCommentUuid, comment);
                assertThat(commentMapAfter).isEqualTo(commentMapBefore);
            } else {
                assertThat(commentMapAfter).doesNotContainKey(targetCommentUuid);
            }
            // Other metas should be exactly the same.
            assertThat(commitAfter.getFullMessage()).isEqualTo(commitBefore.getFullMessage());
            assertThat(commitAfter.getCommitterIdent()).isEqualTo(commitBefore.getCommitterIdent());
            assertThat(commitAfter.getAuthorIdent()).isEqualTo(commitBefore.getAuthorIdent());
            assertThat(commitAfter.getEncoding()).isEqualTo(commitBefore.getEncoding());
            assertThat(commitAfter.getEncodingName()).isEqualTo(commitBefore.getEncodingName());
        }
    }
}
#method_after
private void assertMetaBranchCommitsAfterRewriting(List<RevCommit> beforeDelete, Change.Id changeId, String targetCommentUuid, String expectedMessage) throws Exception {
    List<RevCommit> afterDelete = getChangeMetaCommitsInReverseOrder(changeId);
    assertThat(afterDelete).hasSize(beforeDelete.size());
    try (Repository repo = repoManager.openRepository(project);
        ObjectReader reader = repo.newObjectReader()) {
        for (int i = 0; i < beforeDelete.size(); i++) {
            RevCommit commitBefore = beforeDelete.get(i);
            RevCommit commitAfter = afterDelete.get(i);
            Map<String, com.google.gerrit.reviewdb.client.Comment> commentMapBefore = DeleteCommentRewriter.getPublishedComments(noteUtil, changeId, reader, NoteMap.read(reader, commitBefore));
            Map<String, com.google.gerrit.reviewdb.client.Comment> commentMapAfter = DeleteCommentRewriter.getPublishedComments(noteUtil, changeId, reader, NoteMap.read(reader, commitAfter));
            if (commentMapBefore.containsKey(targetCommentUuid)) {
                assertThat(commentMapAfter).containsKey(targetCommentUuid);
                com.google.gerrit.reviewdb.client.Comment comment = commentMapAfter.get(targetCommentUuid);
                assertThat(comment.message).isEqualTo(expectedMessage);
                comment.message = commentMapBefore.get(targetCommentUuid).message;
                commentMapAfter.put(targetCommentUuid, comment);
                assertThat(commentMapAfter).isEqualTo(commentMapBefore);
            } else {
                assertThat(commentMapAfter).doesNotContainKey(targetCommentUuid);
            }
            // Other metas should be exactly the same.
            assertThat(commitAfter.getFullMessage()).isEqualTo(commitBefore.getFullMessage());
            assertThat(commitAfter.getCommitterIdent()).isEqualTo(commitBefore.getCommitterIdent());
            assertThat(commitAfter.getAuthorIdent()).isEqualTo(commitBefore.getAuthorIdent());
            assertThat(commitAfter.getEncoding()).isEqualTo(commitBefore.getEncoding());
            assertThat(commitAfter.getEncodingName()).isEqualTo(commitBefore.getEncodingName());
        }
    }
}
#end_block

#method_before
private String getCommitMessageHookInstallationHint() {
    if (installCommitMsgHookCommand != null) {
        return installCommitMsgHookCommand;
    }
    final List<HostKey> hostKeys = sshInfo.getHostKeys();
    // HTTP(S)
    if (hostKeys.isEmpty()) {
        return String.format("  f=$(git rev-parse --git-dir)/hooks/commit-msg; curl -o $f %stools/hooks/commit-msg ; chmod +x $f", canonicalWebUrl);
    }
    // SSH keys exist, so the hook can be installed with scp.
    String sshHost;
    int sshPort;
    String host = hostKeys.get(0).getHost();
    int c = host.lastIndexOf(':');
    if (0 <= c) {
        if (host.startsWith("*:")) {
            sshHost = getGerritHost(canonicalWebUrl);
        } else {
            sshHost = host.substring(0, c);
        }
        sshPort = Integer.parseInt(host.substring(c + 1));
    } else {
        sshHost = host;
        sshPort = 22;
    }
    return String.format("  gitdir=$(git rev-parse --git-dir); scp -p -P %d %s@%s:hooks/commit-msg ${gitdir}/hooks/", sshPort, user.getUserName().orElse("<USERNAME>"), sshHost);
}
#method_after
private String getCommitMessageHookInstallationHint() {
    if (installCommitMsgHookCommand != null) {
        return installCommitMsgHookCommand;
    }
    final List<HostKey> hostKeys = sshInfo.getHostKeys();
    // HTTP(S)
    if (hostKeys.isEmpty()) {
        return String.format("  f=\"$(git rev-parse --git-dir)/hooks/commit-msg\"; curl -o \"$f\" %stools/hooks/commit-msg ; chmod +x \"$f\"", canonicalWebUrl);
    }
    // SSH keys exist, so the hook can be installed with scp.
    String sshHost;
    int sshPort;
    String host = hostKeys.get(0).getHost();
    int c = host.lastIndexOf(':');
    if (0 <= c) {
        if (host.startsWith("*:")) {
            sshHost = getGerritHost(canonicalWebUrl);
        } else {
            sshHost = host.substring(0, c);
        }
        sshPort = Integer.parseInt(host.substring(c + 1));
    } else {
        sshHost = host;
        sshPort = 22;
    }
    return String.format("  gitdir=$(git rev-parse --git-dir); scp -p -P %d %s@%s:hooks/commit-msg ${gitdir}/hooks/", sshPort, user.getUserName().orElse("<USERNAME>"), sshHost);
}
#end_block

#method_before
@Override
public ProjectState checkedGet(Project.NameKey projectName) throws IOException {
    if (projectName == null) {
        return null;
    }
    try {
        return strictCheckedGet(projectName);
    } catch (Exception e) {
        if (e.getCause() != null && !(e.getCause() instanceof RepositoryNotFoundException)) {
            logger.atWarning().withCause(e).log("Cannot read project %s", projectName.get());
            Throwables.throwIfInstanceOf(e.getCause(), IOException.class);
            throw new IOException(e);
        }
        logger.atFine().withCause(e).log("Cannot find project %s", projectName.get());
        return null;
    }
}
#method_after
@Override
public ProjectState checkedGet(Project.NameKey projectName) throws IOException {
    if (projectName == null) {
        return null;
    }
    try {
        return strictCheckedGet(projectName);
    } catch (Exception e) {
        if (!(e.getCause() instanceof RepositoryNotFoundException)) {
            logger.atWarning().withCause(e).log("Cannot read project %s", projectName.get());
            if (e.getCause() != null) {
                Throwables.throwIfInstanceOf(e.getCause(), IOException.class);
            }
            throw new IOException(e);
        }
        logger.atFine().withCause(e).log("Cannot find project %s", projectName.get());
        return null;
    }
}
#end_block

#method_before
public FakeEmailSenderSubject notSent() {
    if (actual().peekMessage() != null) {
        failWithoutActual(fact("expected message to be", "sent"));
    }
    return this;
}
#method_after
public FakeEmailSenderSubject notSent() {
    if (actual().peekMessage() != null) {
        failWithoutActual(fact("expected message", "sent"));
    }
    return this;
}
#end_block

#method_before
public FakeEmailSenderSubject sent(String messageType, StagedUsers users) {
    message = actual().nextMessage();
    if (message == null) {
        failWithoutActual(fact("expected message not to be", "sent"));
    }
    recipients = new HashMap<>();
    recipients.put(TO, parseAddresses(message, "To"));
    recipients.put(CC, parseAddresses(message, "Cc"));
    recipients.put(BCC, message.rcpt().stream().map(Address::getEmail).filter(e -> !recipients.get(TO).contains(e) && !recipients.get(CC).contains(e)).collect(toList()));
    this.users = users;
    if (!message.headers().containsKey("X-Gerrit-MessageType")) {
        failWithoutActual(fact("expected to have message sent with", "X-Gerrit-MessageType header"));
    }
    EmailHeader header = message.headers().get("X-Gerrit-MessageType");
    if (!header.equals(new EmailHeader.String(messageType))) {
        failWithoutActual(fact("expected message of type", messageType));
    }
    // recipients.
    return named(recipientMapToString(recipients, users::emailToName));
}
#method_after
public FakeEmailSenderSubject sent(String messageType, StagedUsers users) {
    message = actual().nextMessage();
    if (message == null) {
        failWithoutActual(fact("expected message", "not sent"));
    }
    recipients = new HashMap<>();
    recipients.put(TO, parseAddresses(message, "To"));
    recipients.put(CC, parseAddresses(message, "Cc"));
    recipients.put(BCC, message.rcpt().stream().map(Address::getEmail).filter(e -> !recipients.get(TO).contains(e) && !recipients.get(CC).contains(e)).collect(toList()));
    this.users = users;
    if (!message.headers().containsKey("X-Gerrit-MessageType")) {
        failWithoutActual(fact("expected to have message sent with", "X-Gerrit-MessageType header"));
    }
    EmailHeader header = message.headers().get("X-Gerrit-MessageType");
    if (!header.equals(new EmailHeader.String(messageType))) {
        failWithoutActual(fact("expected message of type", messageType));
    }
    // recipients.
    return named(recipientMapToString(recipients, users::emailToName));
}
#end_block

#method_before
public void isValid() {
    isNotNull();
    if (!actual().isValid()) {
        failWithoutActual(fact("expected to be", "valid"));
    }
}
#method_after
public void isValid() {
    isNotNull();
    if (!actual().isValid()) {
        failWithoutActual(fact("expected", "valid"));
    }
}
#end_block

#method_before
public void isInvalid() {
    isNotNull();
    if (actual().isValid()) {
        failWithoutActual(fact("expected not to be", "valid"));
    }
}
#method_after
public void isInvalid() {
    isNotNull();
    if (actual().isValid()) {
        failWithoutActual(fact("expected", "not valid"));
    }
}
#end_block

#method_before
private ReplicationFileBasedConfig loadConfig() throws ConfigInvalidException, IOException {
    return new ReplicationFileBasedConfig(site, destinationFactory);
}
#method_after
private ReplicationFileBasedConfig loadConfig() throws ConfigInvalidException, IOException {
    return new ReplicationFileBasedConfig(site, destinationFactory, pluginDataDir);
}
#end_block

#method_before
@Override
public Path getEventsDirectory() {
    return site.resolve(config.getString("replication", null, "eventsDirectory"));
}
#method_after
@Override
public Path getEventsDirectory() {
    String eventsDirectory = config.getString("replication", null, "eventsDirectory");
    if (!Strings.isNullOrEmpty(eventsDirectory)) {
        return site.resolve(eventsDirectory);
    }
    return pluginDataDir;
}
#end_block

#method_before
@Override
public void onGitReferenceUpdated(GitReferenceUpdatedListener.Event event) {
    ReplicationState state = replicationStateFactory.create(new GitUpdateProcessing(dispatcher.get()));
    if (!running) {
        stateLog.warn("Replication plugin did not finish startup before event", state);
        return;
    }
    Project.NameKey project = new Project.NameKey(event.getProjectName());
    for (Destination cfg : config.getDestinations(FilterType.ALL)) {
        if (cfg.wouldPushProject(project) && cfg.wouldPushRef(event.getRefName())) {
            String eventKey = persist(event);
            state.setEventKey(eventKey);
            for (URIish uri : cfg.getURIs(project, null)) {
                cfg.schedule(project, event.getRefName(), uri, state);
            }
        }
    }
    state.markAllPushTasksScheduled();
}
#method_after
@Override
public void onGitReferenceUpdated(GitReferenceUpdatedListener.Event event) {
    onGitReferenceUpdated(event.getProjectName(), event.getRefName());
}
#end_block

#method_before
@Override
public void onGitReferenceUpdated(GitReferenceUpdatedListener.Event event) {
    ReplicationState state = replicationStateFactory.create(new GitUpdateProcessing(dispatcher.get()));
    if (!running) {
        stateLog.warn("Replication plugin did not finish startup before event", state);
        return;
    }
    Project.NameKey project = new Project.NameKey(event.getProjectName());
    for (Destination cfg : config.getDestinations(FilterType.ALL)) {
        if (cfg.wouldPushProject(project) && cfg.wouldPushRef(event.getRefName())) {
            String eventKey = persist(event);
            state.setEventKey(eventKey);
            for (URIish uri : cfg.getURIs(project, null)) {
                cfg.schedule(project, event.getRefName(), uri, state);
            }
        }
    }
    state.markAllPushTasksScheduled();
}
#method_after
private void onGitReferenceUpdated(String projectName, String refName) {
    ReplicationState state = replicationStateFactory.create(new GitUpdateProcessing(dispatcher.get()));
    if (!running) {
        stateLog.warn("Replication plugin did not finish startup before event", state);
        return;
    }
    Project.NameKey project = new Project.NameKey(projectName);
    for (Destination cfg : config.getDestinations(FilterType.ALL)) {
        if (cfg.wouldPushProject(project) && cfg.wouldPushRef(refName)) {
            String eventKey = eventsStorage.persist(projectName, refName);
            state.setEventKey(eventKey);
            for (URIish uri : cfg.getURIs(project, null)) {
                cfg.schedule(project, refName, uri, state);
            }
        }
    }
    state.markAllPushTasksScheduled();
}
#end_block

#method_before
private void firePendingEvents() {
    try (DirectoryStream<Path> events = Files.newDirectoryStream(config.getEventsDirectory())) {
        for (Path e : events) {
            if (Files.isRegularFile(e)) {
                repLog.info("Firing pending event {}", e);
                String eventJson = new String(Files.readAllBytes(e), UTF_8);
                GitReferenceUpdatedListener.Event event = GSON.fromJson(eventJson, GitReferenceUpdated.Event.class);
                onGitReferenceUpdated(event);
                Files.delete(e);
            }
        }
    } catch (IOException e) {
        repLog.error("Error when firing pending events", e);
    }
}
#method_after
private void firePendingEvents() {
    for (EventsStorage.ReplicateRefUpdate e : eventsStorage.list()) {
        repLog.info("Firing pending event {}", e);
        onGitReferenceUpdated(e.project, e.ref);
    }
}
#end_block

#method_before
private void deleteEvent() {
    if (eventKey != null) {
        try {
            Files.delete(config.getEventsDirectory().resolve(eventKey));
        } catch (IOException e) {
            repLog.error("Error while deleting event {}", eventKey);
        }
    }
}
#method_after
private void deleteEvent() {
    if (eventKey != null) {
        eventsStorage.delete(eventKey);
    }
}
#end_block

#method_before
@Test
public void updateExisting() throws Exception {
    TestKey key5 = validKeyWithSecondUserId();
    PGPPublicKeyRing keyRing = key5.getPublicKeyRing();
    PGPPublicKey key = keyRing.getPublicKey();
    PGPPublicKey subKey = keyRing.getPublicKey(-4251428363064727069L);
    store.add(keyRing);
    assertEquals(RefUpdate.Result.NEW, store.save(newCommitBuilder()));
    assertUserIds(store.get(key5.getKeyId()).iterator().next(), "Testuser Five <test5@example.com>", "foo:myId");
    keyRing = PGPPublicKeyRing.removePublicKey(keyRing, subKey);
    keyRing = PGPPublicKeyRing.removePublicKey(keyRing, key);
    key = PGPPublicKey.removeCertification(key, "foo:myId");
    keyRing = PGPPublicKeyRing.insertPublicKey(keyRing, key);
    keyRing = PGPPublicKeyRing.insertPublicKey(keyRing, subKey);
    store.add(keyRing);
    assertEquals(RefUpdate.Result.FAST_FORWARD, store.save(newCommitBuilder()));
    Iterator<PGPPublicKeyRing> keyRings = store.get(key.getKeyID()).iterator();
    keyRing = keyRings.next();
    assertFalse(keyRings.hasNext());
    assertUserIds(keyRing, "Testuser Five <test5@example.com>");
}
#method_after
@Test
public void updateExisting() throws Exception {
    TestKey key5 = validKeyWithSecondUserId();
    PGPPublicKeyRing keyRing = key5.getPublicKeyRing();
    PGPPublicKey key = keyRing.getPublicKey();
    PGPPublicKey subKey = keyRing.getPublicKey(Iterators.get(keyRing.getPublicKeys(), 1).getKeyID());
    store.add(keyRing);
    assertEquals(RefUpdate.Result.NEW, store.save(newCommitBuilder()));
    assertUserIds(store.get(key5.getKeyId()).iterator().next(), "Testuser Five <test5@example.com>", "foo:myId");
    keyRing = PGPPublicKeyRing.removePublicKey(keyRing, subKey);
    keyRing = PGPPublicKeyRing.removePublicKey(keyRing, key);
    key = PGPPublicKey.removeCertification(key, "foo:myId");
    keyRing = PGPPublicKeyRing.insertPublicKey(keyRing, key);
    keyRing = PGPPublicKeyRing.insertPublicKey(keyRing, subKey);
    store.add(keyRing);
    assertEquals(RefUpdate.Result.FAST_FORWARD, store.save(newCommitBuilder()));
    Iterator<PGPPublicKeyRing> keyRings = store.get(key.getKeyID()).iterator();
    keyRing = keyRings.next();
    assertFalse(keyRings.hasNext());
    assertUserIds(keyRing, "Testuser Five <test5@example.com>");
}
#end_block

#method_before
@Override
public boolean equals(Object o) {
    if (o instanceof PatchSetApproval) {
        PatchSetApproval p = (PatchSetApproval) o;
        return Objects.equals(key, p.key) && Objects.equals(value, p.value) && Objects.equals(granted, p.granted) && Objects.equals(tag, p.tag) && Objects.equals(realAccountId, p.realAccountId) && postSubmit == p.postSubmit && Objects.equals(originalPatchSetId, p.originalPatchSetId);
    }
    return false;
}
#method_after
@Override
public boolean equals(Object o) {
    if (o instanceof PatchSetApproval) {
        PatchSetApproval p = (PatchSetApproval) o;
        return Objects.equals(key, p.key) && Objects.equals(value, p.value) && Objects.equals(granted, p.granted) && Objects.equals(tag, p.tag) && Objects.equals(realAccountId, p.realAccountId) && postSubmit == p.postSubmit;
    }
    return false;
}
#end_block

#method_before
private void ensureCanEditCommitMessage(ChangeNotes changeNotes) throws AuthException, PermissionBackendException, IOException, ResourceConflictException, OrmException {
    if (!userProvider.get().isIdentifiedUser()) {
        throw new AuthException("Authentication required");
    }
    // Not allow to put message if the current patch set is locked.
    if (isPatchSetLocked(approvalsUtil, projectCache, db.get(), changeNotes, userProvider.get())) {
        throw new ResourceConflictException(String.format("The current patch set of change %s is locked", changeNotes.getChangeId()));
    }
    try {
        permissionBackend.user(userProvider.get()).database(db.get()).change(changeNotes).check(ChangePermission.ADD_PATCH_SET);
        projectCache.checkedGet(changeNotes.getProjectName()).checkStatePermitsWrite();
    } catch (AuthException denied) {
        throw new AuthException("modifying commit message not permitted", denied);
    }
}
#method_after
private void ensureCanEditCommitMessage(ChangeNotes changeNotes) throws AuthException, PermissionBackendException, IOException, ResourceConflictException, OrmException {
    if (!userProvider.get().isIdentifiedUser()) {
        throw new AuthException("Authentication required");
    }
    // Not allowed to put message if the current patch set is locked.
    psUtil.checkPatchSetNotLocked(changeNotes, userProvider.get());
    try {
        permissionBackend.user(userProvider.get()).database(db.get()).change(changeNotes).check(ChangePermission.ADD_PATCH_SET);
        projectCache.checkedGet(changeNotes.getProjectName()).checkStatePermitsWrite();
    } catch (AuthException denied) {
        throw new AuthException("modifying commit message not permitted", denied);
    }
}
#end_block

#method_before
@Override
protected ChangeInfo applyImpl(BatchUpdate.Factory updateFactory, RevisionResource rsrc, RebaseInput input) throws OrmException, UpdateException, RestApiException, IOException, PermissionBackendException {
    // Not allow to rebase if the current patch set is locked.
    if (isPatchSetLocked(approvalsUtil, projectCache, dbProvider.get(), rsrc.getNotes(), rsrc.getUser())) {
        throw new ResourceConflictException(String.format("The current patch set of change %s is locked", rsrc.getChange().getId()));
    }
    rsrc.permissions().database(dbProvider).check(ChangePermission.REBASE);
    projectCache.checkedGet(rsrc.getProject()).checkStatePermitsWrite();
    Change change = rsrc.getChange();
    try (Repository repo = repoManager.openRepository(change.getProject());
        ObjectInserter oi = repo.newObjectInserter();
        ObjectReader reader = oi.newReader();
        RevWalk rw = new RevWalk(reader);
        BatchUpdate bu = updateFactory.create(dbProvider.get(), change.getProject(), rsrc.getUser(), TimeUtil.nowTs())) {
        if (!change.getStatus().isOpen()) {
            throw new ResourceConflictException("change is " + ChangeUtil.status(change));
        } else if (!hasOneParent(rw, rsrc.getPatchSet())) {
            throw new ResourceConflictException("cannot rebase merge commits or commit with no ancestor");
        }
        bu.setRepository(repo, rw, oi);
        bu.addOp(change.getId(), rebaseFactory.create(rsrc.getNotes(), rsrc.getPatchSet(), findBaseRev(repo, rw, rsrc, input)).setForceContentMerge(true).setFireRevisionCreated(true));
        bu.execute();
    }
    return json.create(OPTIONS).format(change.getProject(), change.getId());
}
#method_after
@Override
protected ChangeInfo applyImpl(BatchUpdate.Factory updateFactory, RevisionResource rsrc, RebaseInput input) throws OrmException, UpdateException, RestApiException, IOException, PermissionBackendException {
    // Not allowed to rebase if the current patch set is locked.
    patchSetUtil.checkPatchSetNotLocked(rsrc.getNotes(), rsrc.getUser());
    rsrc.permissions().database(dbProvider).check(ChangePermission.REBASE);
    projectCache.checkedGet(rsrc.getProject()).checkStatePermitsWrite();
    Change change = rsrc.getChange();
    try (Repository repo = repoManager.openRepository(change.getProject());
        ObjectInserter oi = repo.newObjectInserter();
        ObjectReader reader = oi.newReader();
        RevWalk rw = new RevWalk(reader);
        BatchUpdate bu = updateFactory.create(dbProvider.get(), change.getProject(), rsrc.getUser(), TimeUtil.nowTs())) {
        if (!change.getStatus().isOpen()) {
            throw new ResourceConflictException("change is " + ChangeUtil.status(change));
        } else if (!hasOneParent(rw, rsrc.getPatchSet())) {
            throw new ResourceConflictException("cannot rebase merge commits or commit with no ancestor");
        }
        bu.setRepository(repo, rw, oi);
        bu.addOp(change.getId(), rebaseFactory.create(rsrc.getNotes(), rsrc.getPatchSet(), findBaseRev(repo, rw, rsrc, input)).setForceContentMerge(true).setFireRevisionCreated(true));
        bu.execute();
    }
    return json.create(OPTIONS).format(change.getProject(), change.getId());
}
#end_block

#method_before
@Override
public UiAction.Description getDescription(RevisionResource rsrc) {
    UiAction.Description description = new UiAction.Description().setLabel("Rebase").setTitle("Rebase onto tip of branch or parent change").setVisible(false);
    Change change = rsrc.getChange();
    if (!(change.getStatus().isOpen() && rsrc.isCurrent())) {
        return description;
    }
    try {
        if (!projectCache.checkedGet(rsrc.getProject()).statePermitsWrite()) {
            return description;
        }
    } catch (IOException e) {
        log.error("Failed to check if project state permits write: " + rsrc.getProject(), e);
        return description;
    }
    try {
        if (isPatchSetLocked(approvalsUtil, projectCache, dbProvider.get(), rsrc.getNotes(), rsrc.getUser())) {
            return description;
        }
    } catch (OrmException | IOException e) {
        log.error(String.format("Failed to check if the current patch set of change %s is locked", change.getId()), e);
        return description;
    }
    boolean enabled = false;
    try (Repository repo = repoManager.openRepository(change.getDest().getParentKey());
        RevWalk rw = new RevWalk(repo)) {
        if (hasOneParent(rw, rsrc.getPatchSet())) {
            enabled = rebaseUtil.canRebase(rsrc.getPatchSet(), change.getDest(), repo, rw);
        }
    } catch (IOException e) {
        log.error("Failed to check if patch set can be rebased: " + rsrc.getPatchSet(), e);
        return description;
    }
    if (rsrc.permissions().database(dbProvider).testOrFalse(ChangePermission.REBASE)) {
        return description.setVisible(true).setEnabled(enabled);
    }
    return description;
}
#method_after
@Override
public UiAction.Description getDescription(RevisionResource rsrc) {
    UiAction.Description description = new UiAction.Description().setLabel("Rebase").setTitle("Rebase onto tip of branch or parent change").setVisible(false);
    Change change = rsrc.getChange();
    if (!(change.getStatus().isOpen() && rsrc.isCurrent())) {
        return description;
    }
    try {
        if (!projectCache.checkedGet(rsrc.getProject()).statePermitsWrite()) {
            return description;
        }
    } catch (IOException e) {
        log.error("Failed to check if project state permits write: " + rsrc.getProject(), e);
        return description;
    }
    try {
        if (patchSetUtil.isPatchSetLocked(rsrc.getNotes(), rsrc.getUser())) {
            return description;
        }
    } catch (OrmException | IOException e) {
        log.error(String.format("Failed to check if the current patch set of change %s is locked", change.getId()), e);
        return description;
    }
    boolean enabled = false;
    try (Repository repo = repoManager.openRepository(change.getDest().getParentKey());
        RevWalk rw = new RevWalk(repo)) {
        if (hasOneParent(rw, rsrc.getPatchSet())) {
            enabled = rebaseUtil.canRebase(rsrc.getPatchSet(), change.getDest(), repo, rw);
        }
    } catch (IOException e) {
        log.error("Failed to check if patch set can be rebased: " + rsrc.getPatchSet(), e);
        return description;
    }
    if (rsrc.permissions().database(dbProvider).testOrFalse(ChangePermission.REBASE)) {
        return description.setVisible(true).setEnabled(enabled);
    }
    return description;
}
#end_block

#method_before
private void validate(RepoContext ctx) throws AuthException, ResourceConflictException, IOException, PermissionBackendException, OrmException {
    // Not allow to create a new patch set if the current patch set is locked.
    if (isPatchSetLocked(approvalsUtil, projectCache, ctx.getDb(), origNotes, ctx.getUser())) {
        throw new ResourceConflictException(String.format("The current patch set of change %s is locked", origNotes.getChangeId()));
    }
    if (checkAddPatchSetPermission) {
        permissionBackend.user(ctx.getUser()).database(ctx.getDb()).change(origNotes).check(ChangePermission.ADD_PATCH_SET);
    }
    projectCache.checkedGet(ctx.getProject()).checkStatePermitsWrite();
    if (!validate) {
        return;
    }
    PermissionBackend.ForRef perm = permissionBackend.user(ctx.getUser()).ref(origNotes.getChange().getDest());
    String refName = getPatchSetId().toRefName();
    try (CommitReceivedEvent event = new CommitReceivedEvent(new ReceiveCommand(ObjectId.zeroId(), commitId, refName.substring(0, refName.lastIndexOf('/') + 1) + "new"), projectCache.checkedGet(origNotes.getProjectName()).getProject(), origNotes.getChange().getDest().get(), ctx.getRevWalk().getObjectReader(), commitId, ctx.getIdentifiedUser())) {
        commitValidatorsFactory.forGerritCommits(perm, origNotes.getChange().getDest(), ctx.getIdentifiedUser(), new NoSshInfo(), ctx.getRevWalk(), origNotes.getChange()).validate(event);
    } catch (CommitValidationException e) {
        throw new ResourceConflictException(e.getFullMessage());
    }
}
#method_after
private void validate(RepoContext ctx) throws AuthException, ResourceConflictException, IOException, PermissionBackendException, OrmException {
    // Not allowed to create a new patch set if the current patch set is locked.
    psUtil.checkPatchSetNotLocked(origNotes, ctx.getUser());
    if (checkAddPatchSetPermission) {
        permissionBackend.user(ctx.getUser()).database(ctx.getDb()).change(origNotes).check(ChangePermission.ADD_PATCH_SET);
    }
    projectCache.checkedGet(ctx.getProject()).checkStatePermitsWrite();
    if (!validate) {
        return;
    }
    PermissionBackend.ForRef perm = permissionBackend.user(ctx.getUser()).ref(origNotes.getChange().getDest());
    String refName = getPatchSetId().toRefName();
    try (CommitReceivedEvent event = new CommitReceivedEvent(new ReceiveCommand(ObjectId.zeroId(), commitId, refName.substring(0, refName.lastIndexOf('/') + 1) + "new"), projectCache.checkedGet(origNotes.getProjectName()).getProject(), origNotes.getChange().getDest().get(), ctx.getRevWalk().getObjectReader(), commitId, ctx.getIdentifiedUser())) {
        commitValidatorsFactory.forGerritCommits(perm, origNotes.getChange().getDest(), ctx.getIdentifiedUser(), new NoSshInfo(), ctx.getRevWalk(), origNotes.getChange()).validate(event);
    } catch (CommitValidationException e) {
        throw new ResourceConflictException(e.getFullMessage());
    }
}
#end_block

#method_before
@Override
protected Response<ChangeInfo> applyImpl(BatchUpdate.Factory updateFactory, ChangeResource rsrc, MergePatchSetInput in) throws OrmException, IOException, RestApiException, UpdateException, PermissionBackendException {
    // Not allow to create a new patch set if the current patch set is locked.
    if (isPatchSetLocked(approvalsUtil, projectCache, db.get(), rsrc.getNotes(), rsrc.getUser())) {
        throw new ResourceConflictException(String.format("The current patch set of change %s is locked", rsrc.getId()));
    }
    rsrc.permissions().database(db).check(ChangePermission.ADD_PATCH_SET);
    ProjectState projectState = projectCache.checkedGet(rsrc.getProject());
    projectState.checkStatePermitsWrite();
    MergeInput merge = in.merge;
    if (merge == null || Strings.isNullOrEmpty(merge.source)) {
        throw new BadRequestException("merge.source must be non-empty");
    }
    in.baseChange = Strings.nullToEmpty(in.baseChange).trim();
    PatchSet ps = psUtil.current(db.get(), rsrc.getNotes());
    Change change = rsrc.getChange();
    Project.NameKey project = change.getProject();
    Branch.NameKey dest = change.getDest();
    try (Repository git = gitManager.openRepository(project);
        ObjectInserter oi = git.newObjectInserter();
        ObjectReader reader = oi.newReader();
        RevWalk rw = new RevWalk(reader)) {
        RevCommit sourceCommit = MergeUtil.resolveCommit(git, rw, merge.source);
        if (!commits.canRead(projectState, git, sourceCommit)) {
            throw new ResourceNotFoundException("cannot find source commit: " + merge.source + " to merge.");
        }
        RevCommit currentPsCommit;
        List<String> groups = null;
        if (!in.inheritParent && !in.baseChange.isEmpty()) {
            PatchSet basePS = findBasePatchSet(in.baseChange);
            currentPsCommit = rw.parseCommit(ObjectId.fromString(basePS.getRevision().get()));
            groups = basePS.getGroups();
        } else {
            currentPsCommit = rw.parseCommit(ObjectId.fromString(ps.getRevision().get()));
        }
        Timestamp now = TimeUtil.nowTs();
        IdentifiedUser me = user.get().asIdentifiedUser();
        PersonIdent author = me.newCommitterIdent(now, serverTimeZone);
        RevCommit newCommit = createMergeCommit(in, projectState, dest, git, oi, rw, currentPsCommit, sourceCommit, author, ObjectId.fromString(change.getKey().get().substring(1)));
        PatchSet.Id nextPsId = ChangeUtil.nextPatchSetId(ps.getId());
        PatchSetInserter psInserter = patchSetInserterFactory.create(rsrc.getNotes(), nextPsId, newCommit);
        try (BatchUpdate bu = updateFactory.create(db.get(), project, me, now)) {
            bu.setRepository(git, rw, oi);
            psInserter.setMessage("Uploaded patch set " + nextPsId.get() + ".").setNotify(NotifyHandling.NONE).setCheckAddPatchSetPermission(false).setNotify(NotifyHandling.NONE);
            if (groups != null) {
                psInserter.setGroups(groups);
            }
            bu.addOp(rsrc.getId(), psInserter);
            bu.execute();
        }
        ChangeJson json = jsonFactory.create(ListChangesOption.CURRENT_REVISION);
        return Response.ok(json.format(psInserter.getChange()));
    }
}
#method_after
@Override
protected Response<ChangeInfo> applyImpl(BatchUpdate.Factory updateFactory, ChangeResource rsrc, MergePatchSetInput in) throws OrmException, IOException, RestApiException, UpdateException, PermissionBackendException {
    // Not allowed to create a new patch set if the current patch set is locked.
    psUtil.checkPatchSetNotLocked(rsrc.getNotes(), rsrc.getUser());
    rsrc.permissions().database(db).check(ChangePermission.ADD_PATCH_SET);
    ProjectState projectState = projectCache.checkedGet(rsrc.getProject());
    projectState.checkStatePermitsWrite();
    MergeInput merge = in.merge;
    if (merge == null || Strings.isNullOrEmpty(merge.source)) {
        throw new BadRequestException("merge.source must be non-empty");
    }
    in.baseChange = Strings.nullToEmpty(in.baseChange).trim();
    PatchSet ps = psUtil.current(db.get(), rsrc.getNotes());
    Change change = rsrc.getChange();
    Project.NameKey project = change.getProject();
    Branch.NameKey dest = change.getDest();
    try (Repository git = gitManager.openRepository(project);
        ObjectInserter oi = git.newObjectInserter();
        ObjectReader reader = oi.newReader();
        RevWalk rw = new RevWalk(reader)) {
        RevCommit sourceCommit = MergeUtil.resolveCommit(git, rw, merge.source);
        if (!commits.canRead(projectState, git, sourceCommit)) {
            throw new ResourceNotFoundException("cannot find source commit: " + merge.source + " to merge.");
        }
        RevCommit currentPsCommit;
        List<String> groups = null;
        if (!in.inheritParent && !in.baseChange.isEmpty()) {
            PatchSet basePS = findBasePatchSet(in.baseChange);
            currentPsCommit = rw.parseCommit(ObjectId.fromString(basePS.getRevision().get()));
            groups = basePS.getGroups();
        } else {
            currentPsCommit = rw.parseCommit(ObjectId.fromString(ps.getRevision().get()));
        }
        Timestamp now = TimeUtil.nowTs();
        IdentifiedUser me = user.get().asIdentifiedUser();
        PersonIdent author = me.newCommitterIdent(now, serverTimeZone);
        RevCommit newCommit = createMergeCommit(in, projectState, dest, git, oi, rw, currentPsCommit, sourceCommit, author, ObjectId.fromString(change.getKey().get().substring(1)));
        PatchSet.Id nextPsId = ChangeUtil.nextPatchSetId(ps.getId());
        PatchSetInserter psInserter = patchSetInserterFactory.create(rsrc.getNotes(), nextPsId, newCommit);
        try (BatchUpdate bu = updateFactory.create(db.get(), project, me, now)) {
            bu.setRepository(git, rw, oi);
            psInserter.setMessage("Uploaded patch set " + nextPsId.get() + ".").setNotify(NotifyHandling.NONE).setCheckAddPatchSetPermission(false).setNotify(NotifyHandling.NONE);
            if (groups != null) {
                psInserter.setGroups(groups);
            }
            bu.addOp(rsrc.getId(), psInserter);
            bu.execute();
        }
        ChangeJson json = jsonFactory.create(ListChangesOption.CURRENT_REVISION);
        return Response.ok(json.format(psInserter.getChange()));
    }
}
#end_block

#method_before
private boolean can(ChangePermission perm) throws PermissionBackendException {
    try {
        switch(perm) {
            case READ:
                return isVisible(db(), changeData());
            case ABANDON:
                return canAbandon();
            case DELETE:
                return (isOwner() && refControl.canPerform(Permission.DELETE_OWN_CHANGES)) || getProjectControl().isAdmin();
            case ADD_PATCH_SET:
                return canAddPatchSet();
            case EDIT_ASSIGNEE:
                return canEditAssignee();
            case EDIT_DESCRIPTION:
                return canEditDescription();
            case EDIT_HASHTAGS:
                return canEditHashtags();
            case EDIT_TOPIC_NAME:
                return canEditTopicName();
            case REBASE:
                return canRebase();
            case RESTORE:
                return canRestore();
            case SUBMIT:
                return refControl.canSubmit(isOwner());
            case REMOVE_REVIEWER:
            case SUBMIT_AS:
                return refControl.canPerform(perm.permissionName().get());
        }
    } catch (OrmException e) {
        throw new PermissionBackendException("unavailable", e);
    }
    throw new PermissionBackendException(perm + " unsupported");
}
#method_after
private boolean can(ChangePermission perm) throws PermissionBackendException {
    try {
        switch(perm) {
            case READ:
                return isVisible(db(), changeData());
            case ABANDON:
                return canAbandon();
            case DELETE:
                return (isOwner() && refControl.canPerform(Permission.DELETE_OWN_CHANGES)) || getProjectControl().isAdmin();
            case ADD_PATCH_SET:
                return canAddPatchSet();
            case EDIT_ASSIGNEE:
                return canEditAssignee();
            case EDIT_DESCRIPTION:
                return canEditDescription();
            case EDIT_HASHTAGS:
                return canEditHashtags();
            case EDIT_TOPIC_NAME:
                return canEditTopicName();
            case REBASE:
                return canRebase();
            case RESTORE:
                return canRestore();
            case SUBMIT:
                return refControl.canSubmit(isOwner());
            case REMOVE_REVIEWER:
            case SUBMIT_AS:
                return refControl.canPerform(changePermissionName(perm));
        }
    } catch (OrmException e) {
        throw new PermissionBackendException("unavailable", e);
    }
    throw new PermissionBackendException(perm + " unsupported");
}
#end_block

#method_before
private boolean can(LabelPermission perm) {
    return !label(perm.permissionName().get()).isEmpty();
}
#method_after
private boolean can(LabelPermission perm) {
    return !label(labelPermissionName(perm)).isEmpty();
}
#end_block

#method_before
private boolean can(LabelPermission.WithValue perm) {
    PermissionRange r = label(perm.permissionName().get());
    if (perm.forUser() == ON_BEHALF_OF && r.isEmpty()) {
        return false;
    }
    return r.contains(perm.value());
}
#method_after
private boolean can(LabelPermission.WithValue perm) {
    PermissionRange r = label(labelPermissionName(perm));
    if (perm.forUser() == ON_BEHALF_OF && r.isEmpty()) {
        return false;
    }
    return r.contains(perm.value());
}
#end_block

#method_before
@Override
protected ChangeInfo applyImpl(BatchUpdate.Factory updateFactory, ChangeResource rsrc, RestoreInput input) throws RestApiException, UpdateException, OrmException, PermissionBackendException, IOException {
    // Not allow to restore if the current patch set is locked.
    if (isPatchSetLocked(approvalsUtil, projectCache, dbProvider.get(), rsrc.getNotes(), rsrc.getUser())) {
        throw new ResourceConflictException(String.format("The current patch set of change %s is locked", rsrc.getId()));
    }
    rsrc.permissions().database(dbProvider).check(ChangePermission.RESTORE);
    projectCache.checkedGet(rsrc.getProject()).checkStatePermitsWrite();
    Op op = new Op(input);
    try (BatchUpdate u = updateFactory.create(dbProvider.get(), rsrc.getChange().getProject(), rsrc.getUser(), TimeUtil.nowTs())) {
        u.addOp(rsrc.getId(), op).execute();
    }
    return json.noOptions().format(op.change);
}
#method_after
@Override
protected ChangeInfo applyImpl(BatchUpdate.Factory updateFactory, ChangeResource rsrc, RestoreInput input) throws RestApiException, UpdateException, OrmException, PermissionBackendException, IOException {
    // Not allowed to restore if the current patch set is locked.
    psUtil.checkPatchSetNotLocked(rsrc.getNotes(), rsrc.getUser());
    rsrc.permissions().database(dbProvider).check(ChangePermission.RESTORE);
    projectCache.checkedGet(rsrc.getProject()).checkStatePermitsWrite();
    Op op = new Op(input);
    try (BatchUpdate u = updateFactory.create(dbProvider.get(), rsrc.getChange().getProject(), rsrc.getUser(), TimeUtil.nowTs())) {
        u.addOp(rsrc.getId(), op).execute();
    }
    return json.noOptions().format(op.change);
}
#end_block

#method_before
@Override
public UiAction.Description getDescription(ChangeResource rsrc) {
    UiAction.Description description = new UiAction.Description().setLabel("Restore").setTitle("Restore the change").setVisible(false);
    Change change = rsrc.getChange();
    if (change.getStatus() != Status.ABANDONED) {
        return description;
    }
    try {
        if (!projectCache.checkedGet(rsrc.getProject()).statePermitsWrite()) {
            return description;
        }
    } catch (IOException e) {
        log.error("Failed to check if project state permits write: " + rsrc.getProject(), e);
        return description;
    }
    try {
        if (isPatchSetLocked(approvalsUtil, projectCache, dbProvider.get(), rsrc.getNotes(), rsrc.getUser())) {
            return description;
        }
    } catch (OrmException | IOException e) {
        log.error(String.format("Failed to check if the current patch set of change %s is locked", change.getId()), e);
        return description;
    }
    boolean visible = rsrc.permissions().database(dbProvider).testOrFalse(ChangePermission.RESTORE);
    return description.setVisible(visible);
}
#method_after
@Override
public UiAction.Description getDescription(ChangeResource rsrc) {
    UiAction.Description description = new UiAction.Description().setLabel("Restore").setTitle("Restore the change").setVisible(false);
    Change change = rsrc.getChange();
    if (change.getStatus() != Status.ABANDONED) {
        return description;
    }
    try {
        if (!projectCache.checkedGet(rsrc.getProject()).statePermitsWrite()) {
            return description;
        }
    } catch (IOException e) {
        log.error("Failed to check if project state permits write: " + rsrc.getProject(), e);
        return description;
    }
    try {
        if (psUtil.isPatchSetLocked(rsrc.getNotes(), rsrc.getUser())) {
            return description;
        }
    } catch (OrmException | IOException e) {
        log.error(String.format("Failed to check if the current patch set of change %s is locked", change.getId()), e);
        return description;
    }
    boolean visible = rsrc.permissions().database(dbProvider).testOrFalse(ChangePermission.RESTORE);
    return description.setVisible(visible);
}
#end_block

#method_before
private boolean canDelete(ReceiveCommand cmd) throws PermissionBackendException {
    try {
        permissions.ref(cmd.getRefName()).check(RefPermission.DELETE);
        return projectState.statePermitsWrite();
    } catch (AuthException e) {
        return false;
    }
}
#method_after
private boolean canDelete(ReceiveCommand cmd) throws PermissionBackendException {
    if (isConfigRef(cmd.getRefName())) {
        // Never allow to delete the meta config branch.
        return false;
    }
    try {
        permissions.ref(cmd.getRefName()).check(RefPermission.DELETE);
        return projectState.statePermitsWrite();
    } catch (AuthException e) {
        return false;
    }
}
#end_block

#method_before
private void parseRewind(ReceiveCommand cmd) throws PermissionBackendException {
    RevCommit newObject;
    try {
        newObject = rp.getRevWalk().parseCommit(cmd.getNewId());
    } catch (IncorrectObjectTypeException notCommit) {
        newObject = null;
    } catch (IOException err) {
        logError("Invalid object " + cmd.getNewId().name() + " for " + cmd.getRefName() + " forced update", err);
        reject(cmd, "invalid object");
        return;
    }
    logDebug("Rewinding {}", cmd);
    if (newObject != null) {
        validateNewCommits(new Branch.NameKey(project.getNameKey(), cmd.getRefName()), cmd);
        if (cmd.getResult() != NOT_ATTEMPTED) {
            return;
        }
    }
    boolean ok;
    try {
        permissions.ref(cmd.getRefName()).check(RefPermission.FORCE_UPDATE);
        ok = true;
    } catch (AuthException err) {
        ok = false;
    }
    if (ok) {
        if (!validRefOperation(cmd)) {
            return;
        }
        actualCommands.add(cmd);
    } else {
        cmd.setResult(REJECTED_NONFASTFORWARD, " need '" + PermissionRule.FORCE_PUSH + "' privilege.");
    }
}
#method_after
private void parseRewind(ReceiveCommand cmd) throws PermissionBackendException {
    RevCommit newObject;
    try {
        newObject = rp.getRevWalk().parseCommit(cmd.getNewId());
    } catch (IncorrectObjectTypeException notCommit) {
        newObject = null;
    } catch (IOException err) {
        logError("Invalid object " + cmd.getNewId().name() + " for " + cmd.getRefName() + " forced update", err);
        reject(cmd, "invalid object");
        return;
    }
    logDebug("Rewinding {}", cmd);
    if (newObject != null) {
        validateNewCommits(new Branch.NameKey(project.getNameKey(), cmd.getRefName()), cmd);
        if (cmd.getResult() != NOT_ATTEMPTED) {
            return;
        }
    }
    boolean ok;
    try {
        permissions.ref(cmd.getRefName()).check(RefPermission.FORCE_UPDATE);
        ok = true;
    } catch (AuthException err) {
        ok = false;
    }
    if (ok) {
        if (!validRefOperation(cmd)) {
            return;
        }
        actualCommands.add(cmd);
    } else {
        cmd.setResult(REJECTED_OTHER_REASON, "need '" + PermissionRule.FORCE_PUSH + "' privilege.");
    }
}
#end_block

#method_before
boolean validate(boolean autoClose) throws IOException, OrmException, PermissionBackendException {
    if (!autoClose && inputCommand.getResult() != NOT_ATTEMPTED) {
        return false;
    } else if (notes == null) {
        reject(inputCommand, "change " + ontoChange + " not found");
        return false;
    }
    Change change = notes.getChange();
    priorPatchSet = change.currentPatchSetId();
    if (!revisions.containsValue(priorPatchSet)) {
        reject(inputCommand, "change " + ontoChange + " missing revisions");
        return false;
    }
    RevCommit newCommit = rp.getRevWalk().parseCommit(newCommitId);
    RevCommit priorCommit = revisions.inverse().get(priorPatchSet);
    // Not allow to create a new patch set if the current patch set is locked.
    if (isPatchSetLocked(approvalsUtil, projectCache, db, notes, user)) {
        reject(inputCommand, "cannot add patch set to " + ontoChange + ".");
        return false;
    }
    try {
        permissions.change(notes).database(db).check(ChangePermission.ADD_PATCH_SET);
    } catch (AuthException no) {
        reject(inputCommand, "cannot add patch set to " + ontoChange + ".");
        return false;
    }
    if (!projectState.statePermitsWrite()) {
        reject(inputCommand, "cannot add patch set to " + ontoChange + ".");
        return false;
    }
    if (change.getStatus().isClosed()) {
        reject(inputCommand, "change " + ontoChange + " closed");
        return false;
    } else if (revisions.containsKey(newCommit)) {
        reject(inputCommand, "commit already exists (in the change)");
        return false;
    }
    for (Ref r : rp.getRepository().getRefDatabase().getRefs("refs/changes").values()) {
        if (r.getObjectId().equals(newCommit)) {
            reject(inputCommand, "commit already exists (in the project)");
            return false;
        }
    }
    for (RevCommit prior : revisions.keySet()) {
        // amending when trying to address review comments.
        if (rp.getRevWalk().isMergedInto(prior, newCommit)) {
            reject(inputCommand, SAME_CHANGE_ID_IN_MULTIPLE_CHANGES);
            return false;
        }
    }
    PermissionBackend.ForRef perm = permissions.ref(change.getDest().get());
    if (!validCommit(rp.getRevWalk(), perm, change.getDest(), inputCommand, newCommit, change)) {
        return false;
    }
    rp.getRevWalk().parseBody(priorCommit);
    // of the commit was modified.
    if (newCommit.getTree().equals(priorCommit.getTree())) {
        boolean messageEq = Objects.equals(newCommit.getFullMessage(), priorCommit.getFullMessage());
        boolean parentsEq = parentsEqual(newCommit, priorCommit);
        boolean authorEq = authorEqual(newCommit, priorCommit);
        ObjectReader reader = rp.getRevWalk().getObjectReader();
        if (messageEq && parentsEq && authorEq && !autoClose) {
            addMessage(String.format("(W) No changes between prior commit %s and new commit %s", reader.abbreviate(priorCommit).name(), reader.abbreviate(newCommit).name()));
        } else {
            StringBuilder msg = new StringBuilder();
            msg.append("(I) ");
            msg.append(reader.abbreviate(newCommit).name());
            msg.append(":");
            msg.append(" no files changed");
            if (!authorEq) {
                msg.append(", author changed");
            }
            if (!messageEq) {
                msg.append(", message updated");
            }
            if (!parentsEq) {
                msg.append(", was rebased");
            }
            addMessage(msg.toString());
        }
    }
    if (magicBranch != null && (magicBranch.workInProgress || magicBranch.ready) && magicBranch.workInProgress != change.isWorkInProgress() && !user.getAccountId().equals(change.getOwner())) {
        reject(inputCommand, ONLY_OWNER_CAN_MODIFY_WIP);
        return false;
    }
    if (magicBranch != null && (magicBranch.edit || magicBranch.draft)) {
        return newEdit();
    }
    newPatchSet();
    return true;
}
#method_after
boolean validate(boolean autoClose) throws IOException, OrmException, PermissionBackendException {
    if (!autoClose && inputCommand.getResult() != NOT_ATTEMPTED) {
        return false;
    } else if (notes == null) {
        reject(inputCommand, "change " + ontoChange + " not found");
        return false;
    }
    Change change = notes.getChange();
    priorPatchSet = change.currentPatchSetId();
    if (!revisions.containsValue(priorPatchSet)) {
        reject(inputCommand, "change " + ontoChange + " missing revisions");
        return false;
    }
    RevCommit newCommit = rp.getRevWalk().parseCommit(newCommitId);
    RevCommit priorCommit = revisions.inverse().get(priorPatchSet);
    // Not allowed to create a new patch set if the current patch set is locked.
    if (psUtil.isPatchSetLocked(notes, user)) {
        reject(inputCommand, "cannot add patch set to " + ontoChange + ".");
        return false;
    }
    try {
        permissions.change(notes).database(db).check(ChangePermission.ADD_PATCH_SET);
    } catch (AuthException no) {
        reject(inputCommand, "cannot add patch set to " + ontoChange + ".");
        return false;
    }
    if (!projectState.statePermitsWrite()) {
        reject(inputCommand, "cannot add patch set to " + ontoChange + ".");
        return false;
    }
    if (change.getStatus().isClosed()) {
        reject(inputCommand, "change " + ontoChange + " closed");
        return false;
    } else if (revisions.containsKey(newCommit)) {
        reject(inputCommand, "commit already exists (in the change)");
        return false;
    }
    for (Ref r : rp.getRepository().getRefDatabase().getRefs("refs/changes").values()) {
        if (r.getObjectId().equals(newCommit)) {
            reject(inputCommand, "commit already exists (in the project)");
            return false;
        }
    }
    for (RevCommit prior : revisions.keySet()) {
        // amending when trying to address review comments.
        if (rp.getRevWalk().isMergedInto(prior, newCommit)) {
            reject(inputCommand, SAME_CHANGE_ID_IN_MULTIPLE_CHANGES);
            return false;
        }
    }
    PermissionBackend.ForRef perm = permissions.ref(change.getDest().get());
    if (!validCommit(rp.getRevWalk(), perm, change.getDest(), inputCommand, newCommit, change)) {
        return false;
    }
    rp.getRevWalk().parseBody(priorCommit);
    // of the commit was modified.
    if (newCommit.getTree().equals(priorCommit.getTree())) {
        boolean messageEq = Objects.equals(newCommit.getFullMessage(), priorCommit.getFullMessage());
        boolean parentsEq = parentsEqual(newCommit, priorCommit);
        boolean authorEq = authorEqual(newCommit, priorCommit);
        ObjectReader reader = rp.getRevWalk().getObjectReader();
        if (messageEq && parentsEq && authorEq && !autoClose) {
            addMessage(String.format("(W) No changes between prior commit %s and new commit %s", reader.abbreviate(priorCommit).name(), reader.abbreviate(newCommit).name()));
        } else {
            StringBuilder msg = new StringBuilder();
            msg.append("(I) ");
            msg.append(reader.abbreviate(newCommit).name());
            msg.append(":");
            msg.append(" no files changed");
            if (!authorEq) {
                msg.append(", author changed");
            }
            if (!messageEq) {
                msg.append(", message updated");
            }
            if (!parentsEq) {
                msg.append(", was rebased");
            }
            addMessage(msg.toString());
        }
    }
    if (magicBranch != null && (magicBranch.workInProgress || magicBranch.ready) && magicBranch.workInProgress != change.isWorkInProgress() && !user.getAccountId().equals(change.getOwner())) {
        reject(inputCommand, ONLY_OWNER_CAN_MODIFY_WIP);
        return false;
    }
    if (magicBranch != null && (magicBranch.edit || magicBranch.draft)) {
        return newEdit();
    }
    newPatchSet();
    return true;
}
#end_block

#method_before
private void validateNewCommits(Branch.NameKey branch, ReceiveCommand cmd) throws PermissionBackendException {
    PermissionBackend.ForRef perm = permissions.ref(branch.get());
    if (!RefNames.REFS_CONFIG.equals(cmd.getRefName()) && !(MagicBranch.isMagicBranch(cmd.getRefName()) || NEW_PATCHSET_PATTERN.matcher(cmd.getRefName()).matches()) && pushOptions.containsKey(PUSH_OPTION_SKIP_VALIDATION)) {
        try {
            perm.check(RefPermission.SKIP_VALIDATION);
            if (!Iterables.isEmpty(rejectCommits)) {
                throw new AuthException("reject-commits prevents " + PUSH_OPTION_SKIP_VALIDATION);
            }
            logDebug("Short-circuiting new commit validation");
        } catch (AuthException denied) {
            reject(cmd, denied.getMessage());
        }
        return;
    }
    boolean missingFullName = Strings.isNullOrEmpty(user.getAccount().getFullName());
    RevWalk walk = rp.getRevWalk();
    walk.reset();
    walk.sort(RevSort.NONE);
    try {
        RevObject parsedObject = walk.parseAny(cmd.getNewId());
        if (!(parsedObject instanceof RevCommit)) {
            return;
        }
        ListMultimap<ObjectId, Ref> existing = changeRefsById();
        walk.markStart((RevCommit) parsedObject);
        markHeadsAsUninteresting(walk, cmd.getRefName());
        int limit = receiveConfig.maxBatchCommits;
        int n = 0;
        for (RevCommit c; (c = walk.next()) != null; ) {
            if (++n > limit) {
                logDebug("Number of new commits exceeds limit of {}", limit);
                addMessage(String.format("Cannot push more than %d commits to %s without %s option " + "(see %sDocumentation/user-upload.html#skip_validation for details)", limit, branch.get(), PUSH_OPTION_SKIP_VALIDATION, canonicalWebUrl));
                reject(cmd, "too many commits");
                return;
            }
            if (existing.keySet().contains(c)) {
                continue;
            } else if (!validCommit(walk, perm, branch, cmd, c, null)) {
                break;
            }
            if (missingFullName && user.hasEmailAddress(c.getCommitterIdent().getEmailAddress())) {
                logDebug("Will update full name of caller");
                setFullNameTo = c.getCommitterIdent().getName();
                missingFullName = false;
            }
        }
        logDebug("Validated {} new commits", n);
    } catch (IOException err) {
        cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", err);
    }
}
#method_after
private void validateNewCommits(Branch.NameKey branch, ReceiveCommand cmd) throws PermissionBackendException {
    PermissionBackend.ForRef perm = permissions.ref(branch.get());
    if (!RefNames.REFS_CONFIG.equals(cmd.getRefName()) && !(MagicBranch.isMagicBranch(cmd.getRefName()) || NEW_PATCHSET_PATTERN.matcher(cmd.getRefName()).matches()) && pushOptions.containsKey(PUSH_OPTION_SKIP_VALIDATION)) {
        try {
            if (projectState.is(BooleanProjectConfig.USE_SIGNED_OFF_BY)) {
                throw new AuthException("requireSignedOffBy prevents option " + PUSH_OPTION_SKIP_VALIDATION);
            }
            perm.check(RefPermission.SKIP_VALIDATION);
            if (!Iterables.isEmpty(rejectCommits)) {
                throw new AuthException("reject-commits prevents " + PUSH_OPTION_SKIP_VALIDATION);
            }
            logDebug("Short-circuiting new commit validation");
        } catch (AuthException denied) {
            reject(cmd, denied.getMessage());
        }
        return;
    }
    boolean missingFullName = Strings.isNullOrEmpty(user.getAccount().getFullName());
    RevWalk walk = rp.getRevWalk();
    walk.reset();
    walk.sort(RevSort.NONE);
    try {
        RevObject parsedObject = walk.parseAny(cmd.getNewId());
        if (!(parsedObject instanceof RevCommit)) {
            return;
        }
        ListMultimap<ObjectId, Ref> existing = changeRefsById();
        walk.markStart((RevCommit) parsedObject);
        markHeadsAsUninteresting(walk, cmd.getRefName());
        int limit = receiveConfig.maxBatchCommits;
        int n = 0;
        for (RevCommit c; (c = walk.next()) != null; ) {
            if (++n > limit) {
                logDebug("Number of new commits exceeds limit of {}", limit);
                addMessage(String.format("Cannot push more than %d commits to %s without %s option " + "(see %sDocumentation/user-upload.html#skip_validation for details)", limit, branch.get(), PUSH_OPTION_SKIP_VALIDATION, canonicalWebUrl));
                reject(cmd, "too many commits");
                return;
            }
            if (existing.keySet().contains(c)) {
                continue;
            } else if (!validCommit(walk, perm, branch, cmd, c, null)) {
                break;
            }
            if (missingFullName && user.hasEmailAddress(c.getCommitterIdent().getEmailAddress())) {
                logDebug("Will update full name of caller");
                setFullNameTo = c.getCommitterIdent().getName();
                missingFullName = false;
            }
        }
        logDebug("Validated {} new commits", n);
    } catch (IOException err) {
        cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", err);
    }
}
#end_block

#method_before
private void autoCloseChanges(ReceiveCommand cmd) {
    logDebug("Starting auto-closing of changes");
    String refName = cmd.getRefName();
    checkState(!MagicBranch.isMagicBranch(refName), "shouldn't be auto-closing changes on magic branch %s", refName);
    // insertChangesAndPatchSets.
    try {
        retryHelper.execute(updateFactory -> {
            try (BatchUpdate bu = updateFactory.create(db, projectState.getNameKey(), user, TimeUtil.nowTs());
                ObjectInserter ins = repo.newObjectInserter();
                ObjectReader reader = ins.newReader();
                RevWalk rw = new RevWalk(reader)) {
                bu.setRepository(repo, rw, ins).updateChangesInParallel();
                bu.setRequestId(receiveId);
                // TODO(dborowitz): Teach BatchUpdate to ignore missing changes.
                RevCommit newTip = rw.parseCommit(cmd.getNewId());
                Branch.NameKey branch = new Branch.NameKey(project.getNameKey(), refName);
                rw.reset();
                rw.markStart(newTip);
                if (!ObjectId.zeroId().equals(cmd.getOldId())) {
                    rw.markUninteresting(rw.parseCommit(cmd.getOldId()));
                }
                ListMultimap<ObjectId, Ref> byCommit = changeRefsById();
                Map<Change.Key, ChangeNotes> byKey = null;
                List<ReplaceRequest> replaceAndClose = new ArrayList<>();
                int existingPatchSets = 0;
                int newPatchSets = 0;
                COMMIT: for (RevCommit c; (c = rw.next()) != null; ) {
                    rw.parseBody(c);
                    for (Ref ref : byCommit.get(c.copy())) {
                        PatchSet.Id psId = PatchSet.Id.fromRef(ref.getName());
                        Optional<ChangeData> cd = executeIndexQuery(() -> byLegacyId(psId.getParentKey()));
                        if (cd.isPresent() && cd.get().change().getDest().equals(branch)) {
                            existingPatchSets++;
                            bu.addOp(psId.getParentKey(), mergedByPushOpFactory.create(requestScopePropagator, psId, refName));
                            continue COMMIT;
                        }
                    }
                    for (String changeId : c.getFooterLines(CHANGE_ID)) {
                        if (byKey == null) {
                            byKey = executeIndexQuery(() -> openChangesByKeyByBranch(branch));
                        }
                        ChangeNotes onto = byKey.get(new Change.Key(changeId.trim()));
                        if (onto != null) {
                            newPatchSets++;
                            // Hold onto this until we're done with the walk, as the call to
                            // req.validate below calls isMergedInto which resets the walk.
                            ReplaceRequest req = new ReplaceRequest(onto.getChangeId(), c, cmd, false);
                            req.notes = onto;
                            replaceAndClose.add(req);
                            continue COMMIT;
                        }
                    }
                }
                for (ReplaceRequest req : replaceAndClose) {
                    Change.Id id = req.notes.getChangeId();
                    if (!executeRequestValidation(() -> req.validate(true))) {
                        logDebug("Not closing {} because validation failed", id);
                        continue;
                    }
                    req.addOps(bu, null);
                    bu.addOp(id, mergedByPushOpFactory.create(requestScopePropagator, req.psId, refName).setPatchSetProvider(new Provider<PatchSet>() {

                        @Override
                        public PatchSet get() {
                            return req.replaceOp.getPatchSet();
                        }
                    }));
                    bu.addOp(id, new ChangeProgressOp(closeProgress));
                }
                logDebug("Auto-closing {} changes with existing patch sets and {} with new patch sets", existingPatchSets, newPatchSets);
                bu.execute();
            } catch (IOException | OrmException | PermissionBackendException e) {
                logError("Failed to auto-close changes", e);
            }
            return null;
        }, // eat up the whole timeout so that no time is left to retry this outer action.
        RetryHelper.options().timeout(retryHelper.getDefaultTimeout(ActionType.CHANGE_UPDATE).multipliedBy(5)).build());
    } catch (RestApiException e) {
        logError("Can't insert patchset", e);
    } catch (UpdateException e) {
        logError("Failed to auto-close changes", e);
    }
}
#method_after
private void autoCloseChanges(ReceiveCommand cmd) {
    logDebug("Starting auto-closing of changes");
    String refName = cmd.getRefName();
    checkState(!MagicBranch.isMagicBranch(refName), "shouldn't be auto-closing changes on magic branch %s", refName);
    // insertChangesAndPatchSets.
    try {
        retryHelper.execute(updateFactory -> {
            try (BatchUpdate bu = updateFactory.create(db, projectState.getNameKey(), user, TimeUtil.nowTs());
                ObjectInserter ins = repo.newObjectInserter();
                ObjectReader reader = ins.newReader();
                RevWalk rw = new RevWalk(reader)) {
                bu.setRepository(repo, rw, ins).updateChangesInParallel();
                bu.setRequestId(receiveId);
                // TODO(dborowitz): Teach BatchUpdate to ignore missing changes.
                RevCommit newTip = rw.parseCommit(cmd.getNewId());
                Branch.NameKey branch = new Branch.NameKey(project.getNameKey(), refName);
                rw.reset();
                rw.markStart(newTip);
                if (!ObjectId.zeroId().equals(cmd.getOldId())) {
                    rw.markUninteresting(rw.parseCommit(cmd.getOldId()));
                }
                ListMultimap<ObjectId, Ref> byCommit = changeRefsById();
                Map<Change.Key, ChangeNotes> byKey = null;
                List<ReplaceRequest> replaceAndClose = new ArrayList<>();
                int existingPatchSets = 0;
                int newPatchSets = 0;
                COMMIT: for (RevCommit c; (c = rw.next()) != null; ) {
                    rw.parseBody(c);
                    for (Ref ref : byCommit.get(c.copy())) {
                        PatchSet.Id psId = PatchSet.Id.fromRef(ref.getName());
                        Optional<ChangeData> cd = executeIndexQuery(() -> byLegacyId(psId.getParentKey()));
                        if (cd.isPresent() && cd.get().change().getDest().equals(branch)) {
                            existingPatchSets++;
                            bu.addOp(psId.getParentKey(), mergedByPushOpFactory.create(requestScopePropagator, psId, refName));
                            continue COMMIT;
                        }
                    }
                    for (String changeId : c.getFooterLines(CHANGE_ID)) {
                        if (byKey == null) {
                            byKey = executeIndexQuery(() -> openChangesByKeyByBranch(branch));
                        }
                        ChangeNotes onto = byKey.get(new Change.Key(changeId.trim()));
                        if (onto != null) {
                            newPatchSets++;
                            // Hold onto this until we're done with the walk, as the call to
                            // req.validate below calls isMergedInto which resets the walk.
                            ReplaceRequest req = new ReplaceRequest(onto.getChangeId(), c, cmd, false);
                            req.notes = onto;
                            replaceAndClose.add(req);
                            continue COMMIT;
                        }
                    }
                }
                for (ReplaceRequest req : replaceAndClose) {
                    Change.Id id = req.notes.getChangeId();
                    if (!executeRequestValidation(() -> req.validate(true))) {
                        logDebug("Not closing {} because validation failed", id);
                        continue;
                    }
                    req.addOps(bu, null);
                    bu.addOp(id, mergedByPushOpFactory.create(requestScopePropagator, req.psId, refName).setPatchSetProvider(req.replaceOp::getPatchSet));
                    bu.addOp(id, new ChangeProgressOp(closeProgress));
                }
                logDebug("Auto-closing {} changes with existing patch sets and {} with new patch sets", existingPatchSets, newPatchSets);
                bu.execute();
            } catch (IOException | OrmException | PermissionBackendException e) {
                logError("Failed to auto-close changes", e);
            }
            return null;
        }, // eat up the whole timeout so that no time is left to retry this outer action.
        RetryHelper.options().timeout(retryHelper.getDefaultTimeout(ActionType.CHANGE_UPDATE).multipliedBy(5)).build());
    } catch (RestApiException e) {
        logError("Can't insert patchset", e);
    } catch (UpdateException e) {
        logError("Failed to auto-close changes", e);
    }
}
#end_block

#method_before
private void assertCanEdit(ChangeNotes notes) throws AuthException, PermissionBackendException, IOException, ResourceConflictException, OrmException {
    if (!currentUser.get().isIdentifiedUser()) {
        throw new AuthException("Authentication required");
    }
    // Not allow to edit if the current patch set is locked.
    if (isPatchSetLocked(approvalsUtil, projectCache, reviewDb.get(), notes, currentUser.get())) {
        throw new ResourceConflictException(String.format("The current patch set of change %s is locked", notes.getChangeId()));
    }
    try {
        permissionBackend.currentUser().database(reviewDb).change(notes).check(ChangePermission.ADD_PATCH_SET);
        projectCache.checkedGet(notes.getProjectName()).checkStatePermitsWrite();
    } catch (AuthException denied) {
        throw new AuthException("edit not permitted", denied);
    }
}
#method_after
private void assertCanEdit(ChangeNotes notes) throws AuthException, PermissionBackendException, IOException, ResourceConflictException, OrmException {
    if (!currentUser.get().isIdentifiedUser()) {
        throw new AuthException("Authentication required");
    }
    Change c = notes.getChange();
    if (!c.getStatus().isOpen()) {
        throw new ResourceConflictException(String.format("change %s is %s", c.getChangeId(), c.getStatus().toString().toLowerCase()));
    }
    // Not allowed to edit if the current patch set is locked.
    patchSetUtil.checkPatchSetNotLocked(notes, currentUser.get());
    try {
        permissionBackend.currentUser().database(reviewDb).change(notes).check(ChangePermission.ADD_PATCH_SET);
        projectCache.checkedGet(notes.getProjectName()).checkStatePermitsWrite();
    } catch (AuthException denied) {
        throw new AuthException("edit not permitted", denied);
    }
}
#end_block

#method_before
@Override
protected ChangeInfo applyImpl(BatchUpdate.Factory updateFactory, ChangeResource rsrc, AbandonInput input) throws RestApiException, UpdateException, OrmException, PermissionBackendException, IOException, ConfigInvalidException {
    // Not allow to abandon if the current patch set is locked.
    if (isPatchSetLocked(approvalsUtil, projectCache, dbProvider.get(), rsrc.getNotes(), rsrc.getUser())) {
        throw new ResourceConflictException(String.format("The current patch set of change %s is locked", rsrc.getId()));
    }
    rsrc.permissions().database(dbProvider).check(ChangePermission.ABANDON);
    NotifyHandling notify = input.notify == null ? defaultNotify(rsrc.getChange()) : input.notify;
    Change change = abandon(updateFactory, rsrc.getNotes(), rsrc.getUser(), input.message, notify, notifyUtil.resolveAccounts(input.notifyDetails));
    return json.noOptions().format(change);
}
#method_after
@Override
protected ChangeInfo applyImpl(BatchUpdate.Factory updateFactory, ChangeResource rsrc, AbandonInput input) throws RestApiException, UpdateException, OrmException, PermissionBackendException, IOException, ConfigInvalidException {
    // Not allowed to abandon if the current patch set is locked.
    patchSetUtil.checkPatchSetNotLocked(rsrc.getNotes(), rsrc.getUser());
    rsrc.permissions().database(dbProvider).check(ChangePermission.ABANDON);
    NotifyHandling notify = input.notify == null ? defaultNotify(rsrc.getChange()) : input.notify;
    Change change = abandon(updateFactory, rsrc.getNotes(), rsrc.getUser(), input.message, notify, notifyUtil.resolveAccounts(input.notifyDetails));
    return json.noOptions().format(change);
}
#end_block

#method_before
@Override
public UiAction.Description getDescription(ChangeResource rsrc) {
    UiAction.Description description = new UiAction.Description().setLabel("Abandon").setTitle("Abandon the change").setVisible(false);
    Change change = rsrc.getChange();
    if (!change.getStatus().isOpen()) {
        return description;
    }
    try {
        if (isPatchSetLocked(approvalsUtil, projectCache, dbProvider.get(), rsrc.getNotes(), rsrc.getUser())) {
            return description;
        }
    } catch (OrmException | IOException e) {
        log.error(String.format("Failed to check if the current patch set of change %s is locked", change.getId()), e);
        return description;
    }
    return description.setVisible(rsrc.permissions().testOrFalse(ChangePermission.ABANDON));
}
#method_after
@Override
public UiAction.Description getDescription(ChangeResource rsrc) {
    UiAction.Description description = new UiAction.Description().setLabel("Abandon").setTitle("Abandon the change").setVisible(false);
    Change change = rsrc.getChange();
    if (!change.getStatus().isOpen()) {
        return description;
    }
    try {
        if (patchSetUtil.isPatchSetLocked(rsrc.getNotes(), rsrc.getUser())) {
            return description;
        }
    } catch (OrmException | IOException e) {
        log.error(String.format("Failed to check if the current patch set of change %s is locked", change.getId()), e);
        return description;
    }
    return description.setVisible(rsrc.permissions().testOrFalse(ChangePermission.ABANDON));
}
#end_block

#method_before
public static boolean isPatchSetLocked(ApprovalsUtil approvalsUtil, ProjectCache projectCache, ReviewDb db, ChangeNotes notes, CurrentUser user) throws OrmException, IOException {
    Change change = notes.getChange();
    if (change.getStatus() == Change.Status.MERGED) {
        return false;
    }
    ProjectState projectState = projectCache.checkedGet(notes.getProjectName());
    checkNotNull(projectState, "Failed to load project %s", notes.getProjectName());
    for (PatchSetApproval ap : approvalsUtil.byPatchSet(db, notes, user, change.currentPatchSetId(), null, null)) {
        LabelType type = projectState.getLabelTypes(notes, user).byLabel(ap.getLabel());
        if (type != null && ap.getValue() == 1 && type.getFunction() == LabelFunction.PATCH_SET_LOCK) {
            return true;
        }
    }
    return false;
}
#method_after
public boolean isPatchSetLocked(ChangeNotes notes, CurrentUser user) throws OrmException, IOException {
    Change change = notes.getChange();
    if (change.getStatus() == Change.Status.MERGED) {
        return false;
    }
    ProjectState projectState = projectCache.checkedGet(notes.getProjectName());
    checkNotNull(projectState, "Failed to load project %s", notes.getProjectName());
    ApprovalsUtil approvalsUtil = approvalsUtilProvider.get();
    for (PatchSetApproval ap : approvalsUtil.byPatchSet(dbProvider.get(), notes, user, change.currentPatchSetId(), null, null)) {
        LabelType type = projectState.getLabelTypes(notes, user).byLabel(ap.getLabel());
        if (type != null && ap.getValue() == 1 && type.getFunction() == LabelFunction.PATCH_SET_LOCK) {
            return true;
        }
    }
    return false;
}
#end_block

#method_before
@Test
public void moveChangeWithCurrentPatchSetLocked() throws Exception {
    // Move change that is locked
    PushOneCommit.Result r = createChange();
    Branch.NameKey newBranch = new Branch.NameKey(r.getChange().change().getProject(), "moveTest");
    createBranch(newBranch);
    ProjectConfig cfg = projectCache.checkedGet(project).getConfig();
    LabelType patchSetLock = Util.patchSetLock();
    cfg.getLabelSections().put(patchSetLock.getName(), patchSetLock);
    AccountGroup.UUID registeredUsers = systemGroupBackend.getGroup(REGISTERED_USERS).getUUID();
    Util.allow(cfg, Permission.forLabel(patchSetLock.getName()), 0, 1, registeredUsers, "refs/heads/*");
    saveProjectConfig(cfg);
    grant(project, "refs/heads/*", Permission.LABEL + "Patch-Set-Lock");
    revision(r).review(new ReviewInput().label("Patch-Set-Lock", 1));
    exception.expect(ResourceConflictException.class);
    exception.expectMessage(String.format("The current patch set of change %s is locked", r.getChange().getId()));
    move(r.getChangeId(), newBranch.get());
}
#method_after
@Test
public void moveChangeWithCurrentPatchSetLocked() throws Exception {
    // Move change that is locked
    PushOneCommit.Result r = createChange();
    Branch.NameKey newBranch = new Branch.NameKey(r.getChange().change().getProject(), "moveTest");
    createBranch(newBranch);
    try (ProjectConfigUpdate u = updateProject(project)) {
        LabelType patchSetLock = Util.patchSetLock();
        u.getConfig().getLabelSections().put(patchSetLock.getName(), patchSetLock);
        AccountGroup.UUID registeredUsers = systemGroupBackend.getGroup(REGISTERED_USERS).getUUID();
        Util.allow(u.getConfig(), Permission.forLabel(patchSetLock.getName()), 0, 1, registeredUsers, "refs/heads/*");
        u.save();
    }
    grant(project, "refs/heads/*", Permission.LABEL + "Patch-Set-Lock");
    revision(r).review(new ReviewInput().label("Patch-Set-Lock", 1));
    exception.expect(ResourceConflictException.class);
    exception.expectMessage(String.format("The current patch set of change %s is locked", r.getChange().getId()));
    move(r.getChangeId(), newBranch.get());
}
#end_block

#method_before
@Test
public void moveChangeOnlyKeepVetoVotes() throws Exception {
    // A vote for a label will be kept after moving if the label's function is *WithBlock and the
    // vote holds the minimum value.
    createBranch(new Branch.NameKey(project, "foo"));
    // 'Code-Review' uses 'MaxWithBlock' function.
    String codeReviewLabel = "Code-Review";
    String testLabelA = "Label-A";
    String testLabelB = "Label-B";
    String testLabelC = "Label-C";
    configLabel(testLabelA, LabelFunction.ANY_WITH_BLOCK);
    configLabel(testLabelB, LabelFunction.MAX_NO_BLOCK);
    configLabel(testLabelC, LabelFunction.NO_BLOCK);
    AccountGroup.UUID registered = SystemGroupBackend.REGISTERED_USERS;
    ProjectConfig cfg = projectCache.checkedGet(project).getConfig();
    Util.allow(cfg, Permission.forLabel(testLabelA), -1, +1, registered, "refs/heads/*");
    Util.allow(cfg, Permission.forLabel(testLabelB), -1, +1, registered, "refs/heads/*");
    Util.allow(cfg, Permission.forLabel(testLabelC), -1, +1, registered, "refs/heads/*");
    saveProjectConfig(cfg);
    String changeId = createChange().getChangeId();
    gApi.changes().id(changeId).current().review(ReviewInput.reject());
    amendChange(changeId);
    ReviewInput input = new ReviewInput();
    input.label(testLabelA, -1);
    input.label(testLabelB, -1);
    input.label(testLabelC, -1);
    gApi.changes().id(changeId).current().review(input);
    assertThat(gApi.changes().id(changeId).current().reviewer(admin.email).votes().keySet()).containsExactly(codeReviewLabel, testLabelA, testLabelB, testLabelC);
    assertThat(gApi.changes().id(changeId).current().reviewer(admin.email).votes().values()).containsExactly((short) -2, (short) -1, (short) -1, (short) -1);
    // Move the change to the 'foo' branch.
    assertThat(gApi.changes().id(changeId).get().branch).isEqualTo("master");
    move(changeId, "foo");
    assertThat(gApi.changes().id(changeId).get().branch).isEqualTo("foo");
    // 'Code-Review -2' and 'Label-A -1' will be kept.
    assertThat(gApi.changes().id(changeId).current().reviewer(admin.email).votes().values()).containsExactly((short) -2, (short) -1, (short) 0, (short) 0);
    // Move the change back to 'master'.
    move(changeId, "master");
    assertThat(gApi.changes().id(changeId).get().branch).isEqualTo("master");
    assertThat(gApi.changes().id(changeId).current().reviewer(admin.email).votes().values()).containsExactly((short) -2, (short) -1, (short) 0, (short) 0);
}
#method_after
@Test
public void moveChangeOnlyKeepVetoVotes() throws Exception {
    // A vote for a label will be kept after moving if the label's function is *WithBlock and the
    // vote holds the minimum value.
    createBranch(new Branch.NameKey(project, "foo"));
    // 'Code-Review' uses 'MaxWithBlock' function.
    String codeReviewLabel = "Code-Review";
    String testLabelA = "Label-A";
    String testLabelB = "Label-B";
    String testLabelC = "Label-C";
    configLabel(testLabelA, LabelFunction.ANY_WITH_BLOCK);
    configLabel(testLabelB, LabelFunction.MAX_NO_BLOCK);
    configLabel(testLabelC, LabelFunction.NO_BLOCK);
    AccountGroup.UUID registered = SystemGroupBackend.REGISTERED_USERS;
    try (ProjectConfigUpdate u = updateProject(project)) {
        Util.allow(u.getConfig(), Permission.forLabel(testLabelA), -1, +1, registered, "refs/heads/*");
        Util.allow(u.getConfig(), Permission.forLabel(testLabelB), -1, +1, registered, "refs/heads/*");
        Util.allow(u.getConfig(), Permission.forLabel(testLabelC), -1, +1, registered, "refs/heads/*");
        u.save();
    }
    String changeId = createChange().getChangeId();
    gApi.changes().id(changeId).current().review(ReviewInput.reject());
    amendChange(changeId);
    ReviewInput input = new ReviewInput();
    input.label(testLabelA, -1);
    input.label(testLabelB, -1);
    input.label(testLabelC, -1);
    gApi.changes().id(changeId).current().review(input);
    assertThat(gApi.changes().id(changeId).current().reviewer(admin.email).votes().keySet()).containsExactly(codeReviewLabel, testLabelA, testLabelB, testLabelC);
    assertThat(gApi.changes().id(changeId).current().reviewer(admin.email).votes().values()).containsExactly((short) -2, (short) -1, (short) -1, (short) -1);
    // Move the change to the 'foo' branch.
    assertThat(gApi.changes().id(changeId).get().branch).isEqualTo("master");
    move(changeId, "foo");
    assertThat(gApi.changes().id(changeId).get().branch).isEqualTo("foo");
    // 'Code-Review -2' and 'Label-A -1' will be kept.
    assertThat(gApi.changes().id(changeId).current().reviewer(admin.email).votes().values()).containsExactly((short) -2, (short) -1, (short) 0, (short) 0);
    // Move the change back to 'master'.
    move(changeId, "master");
    assertThat(gApi.changes().id(changeId).get().branch).isEqualTo("master");
    assertThat(gApi.changes().id(changeId).current().reviewer(admin.email).votes().values()).containsExactly((short) -2, (short) -1, (short) 0, (short) 0);
}
#end_block

#method_before
@Override
protected ChangeInfo applyImpl(BatchUpdate.Factory updateFactory, ChangeResource rsrc, MoveInput input) throws RestApiException, OrmException, UpdateException, PermissionBackendException, IOException {
    Change change = rsrc.getChange();
    Project.NameKey project = rsrc.getProject();
    IdentifiedUser caller = rsrc.getUser().asIdentifiedUser();
    input.destinationBranch = RefNames.fullName(input.destinationBranch);
    if (change.getStatus().isClosed()) {
        throw new ResourceConflictException("Change is " + ChangeUtil.status(change));
    }
    Branch.NameKey newDest = new Branch.NameKey(project, input.destinationBranch);
    if (change.getDest().equals(newDest)) {
        throw new ResourceConflictException("Change is already destined for the specified branch");
    }
    // Not allow to move if the current patch set is locked.
    if (isPatchSetLocked(approvalsUtil, projectCache, dbProvider.get(), rsrc.getNotes(), rsrc.getUser())) {
        throw new ResourceConflictException(String.format("The current patch set of change %s is locked", rsrc.getId()));
    }
    // Move requires abandoning this change, and creating a new change.
    try {
        rsrc.permissions().database(dbProvider).check(ABANDON);
        permissionBackend.user(caller).database(dbProvider).ref(newDest).check(CREATE_CHANGE);
    } catch (AuthException denied) {
        throw new AuthException("move not permitted", denied);
    }
    projectCache.checkedGet(project).checkStatePermitsWrite();
    try (BatchUpdate u = updateFactory.create(dbProvider.get(), project, caller, TimeUtil.nowTs())) {
        u.addOp(change.getId(), new Op(input));
        u.execute();
    }
    return json.noOptions().format(project, rsrc.getId());
}
#method_after
@Override
protected ChangeInfo applyImpl(BatchUpdate.Factory updateFactory, ChangeResource rsrc, MoveInput input) throws RestApiException, OrmException, UpdateException, PermissionBackendException, IOException {
    Change change = rsrc.getChange();
    Project.NameKey project = rsrc.getProject();
    IdentifiedUser caller = rsrc.getUser().asIdentifiedUser();
    input.destinationBranch = RefNames.fullName(input.destinationBranch);
    if (change.getStatus().isClosed()) {
        throw new ResourceConflictException("Change is " + ChangeUtil.status(change));
    }
    Branch.NameKey newDest = new Branch.NameKey(project, input.destinationBranch);
    if (change.getDest().equals(newDest)) {
        throw new ResourceConflictException("Change is already destined for the specified branch");
    }
    // Not allowed to move if the current patch set is locked.
    psUtil.checkPatchSetNotLocked(rsrc.getNotes(), rsrc.getUser());
    // Move requires abandoning this change, and creating a new change.
    try {
        rsrc.permissions().database(dbProvider).check(ABANDON);
        permissionBackend.user(caller).database(dbProvider).ref(newDest).check(CREATE_CHANGE);
    } catch (AuthException denied) {
        throw new AuthException("move not permitted", denied);
    }
    projectCache.checkedGet(project).checkStatePermitsWrite();
    try (BatchUpdate u = updateFactory.create(dbProvider.get(), project, caller, TimeUtil.nowTs())) {
        u.addOp(change.getId(), new Op(input));
        u.execute();
    }
    return json.noOptions().format(project, rsrc.getId());
}
#end_block

#method_before
@Override
public UiAction.Description getDescription(ChangeResource rsrc) {
    UiAction.Description description = new UiAction.Description().setLabel("Move Change").setTitle("Move change to a different branch").setVisible(false);
    Change change = rsrc.getChange();
    if (!change.getStatus().isOpen()) {
        return description;
    }
    try {
        if (!projectCache.checkedGet(rsrc.getProject()).statePermitsWrite()) {
            return description;
        }
    } catch (IOException e) {
        log.error("Failed to check if project state permits write: " + rsrc.getProject(), e);
        return description;
    }
    try {
        if (isPatchSetLocked(approvalsUtil, projectCache, dbProvider.get(), rsrc.getNotes(), rsrc.getUser())) {
            return description;
        }
    } catch (OrmException | IOException e) {
        log.error(String.format("Failed to check if the current patch set of change %s is locked", change.getId()), e);
        return description;
    }
    return description.setVisible(and(permissionBackend.user(rsrc.getUser()).ref(change.getDest()).testCond(CREATE_CHANGE), rsrc.permissions().database(dbProvider).testCond(ABANDON)));
}
#method_after
@Override
public UiAction.Description getDescription(ChangeResource rsrc) {
    UiAction.Description description = new UiAction.Description().setLabel("Move Change").setTitle("Move change to a different branch").setVisible(false);
    Change change = rsrc.getChange();
    if (!change.getStatus().isOpen()) {
        return description;
    }
    try {
        if (!projectCache.checkedGet(rsrc.getProject()).statePermitsWrite()) {
            return description;
        }
    } catch (IOException e) {
        log.error("Failed to check if project state permits write: " + rsrc.getProject(), e);
        return description;
    }
    try {
        if (psUtil.isPatchSetLocked(rsrc.getNotes(), rsrc.getUser())) {
            return description;
        }
    } catch (OrmException | IOException e) {
        log.error(String.format("Failed to check if the current patch set of change %s is locked", change.getId()), e);
        return description;
    }
    return description.setVisible(and(permissionBackend.user(rsrc.getUser()).ref(change.getDest()).testCond(CREATE_CHANGE), rsrc.permissions().database(dbProvider).testCond(ABANDON)));
}
#end_block

#method_before
public static <T> T checkNotNull(T reference) {
    if (reference == null) {
        throw new NullPointerException();
    }
    return reference;
}
#method_after
private static void checkNotNull(Object reference) {
    if (reference == null) {
        throw new NullPointerException();
    }
}
#end_block

#method_before
public AccountGroup.UUID getUUID() {
    return uuid != null ? new AccountGroup.UUID(uuid) : null;
}
#method_after
@Nullable
public AccountGroup.UUID getUUID() {
    return uuid != null ? new AccountGroup.UUID(uuid) : null;
}
#end_block

#method_before
@Test
public void testHashcode() {
    AccountGroup.UUID uuid1 = new AccountGroup.UUID("uuid1");
    AccountGroup.UUID uuid2 = new AccountGroup.UUID("uuid2");
    GroupReference groupReference1 = new GroupReference(uuid1, "foo");
    GroupReference groupReference2 = new GroupReference(uuid1, "bar");
    GroupReference groupReference3 = new GroupReference(uuid2, "foo");
    GroupReference groupReference4 = new GroupReference(null, "bar");
    assertThat(groupReference1.hashCode()).isEqualTo(groupReference2.hashCode());
    assertThat(groupReference1.hashCode()).isNotEqualTo(groupReference3.hashCode());
    assertThat(groupReference1.hashCode()).isNotEqualTo(groupReference4.hashCode());
}
#method_after
@Test
public void testHashcode() {
    AccountGroup.UUID uuid1 = new AccountGroup.UUID("uuid1");
    assertThat(new GroupReference(uuid1, "foo").hashCode()).isEqualTo(new GroupReference(uuid1, "bar").hashCode());
    // Check that the following calls don't fail with an exception.
    new GroupReference(null, "bar").hashCode();
    new GroupReference(new AccountGroup.UUID(null), "bar").hashCode();
}
#end_block

#method_before
@Test
public void numberOfLinesInDiffOfDeletedFileWithoutNewlineAtEndIsCorrect() throws Exception {
    String filePath = "a_new_file.txt";
    String fileContent = "Line 1\nLine 2\nLine 3";
    gApi.changes().id(changeId).edit().modifyFile(filePath, RawInputUtil.create(fileContent));
    gApi.changes().id(changeId).edit().publish();
    String previousPatchSetId = gApi.changes().id(changeId).get().currentRevision;
    gApi.changes().id(changeId).edit().deleteFile(filePath);
    gApi.changes().id(changeId).edit().publish();
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, filePath).withBase(previousPatchSetId).get();
    assertThat(diffInfo).metaA().lines().isEqualTo(3);
    assertThat(diffInfo).metaB().isNull();
}
#method_after
@Test
public void numberOfLinesInDiffOfDeletedFileWithoutNewlineAtEndIsCorrect() throws Exception {
    String filePath = "a_new_file.txt";
    String fileContent = "Line 1\nLine 2\nLine 3";
    gApi.changes().id(changeId).edit().modifyFile(filePath, RawInputUtil.create(fileContent));
    gApi.changes().id(changeId).edit().publish();
    String previousPatchSetId = gApi.changes().id(changeId).get().currentRevision;
    gApi.changes().id(changeId).edit().deleteFile(filePath);
    gApi.changes().id(changeId).edit().publish();
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, filePath).withBase(previousPatchSetId).get();
    assertThat(diffInfo).metaA().totalLineCount().isEqualTo(3);
    assertThat(diffInfo).metaB().isNull();
}
#end_block

#method_before
@Test
public void numberOfLinesInDiffOfDeletedFileWithNewlineAtEndIsCorrect() throws Exception {
    String filePath = "a_new_file.txt";
    String fileContent = "Line 1\nLine 2\nLine 3\n";
    gApi.changes().id(changeId).edit().modifyFile(filePath, RawInputUtil.create(fileContent));
    gApi.changes().id(changeId).edit().publish();
    String previousPatchSetId = gApi.changes().id(changeId).get().currentRevision;
    gApi.changes().id(changeId).edit().deleteFile(filePath);
    gApi.changes().id(changeId).edit().publish();
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, filePath).withBase(previousPatchSetId).get();
    assertThat(diffInfo).metaA().lines().isEqualTo(4);
    assertThat(diffInfo).metaB().isNull();
}
#method_after
@Test
public void numberOfLinesInDiffOfDeletedFileWithNewlineAtEndIsCorrect() throws Exception {
    String filePath = "a_new_file.txt";
    String fileContent = "Line 1\nLine 2\nLine 3\n";
    gApi.changes().id(changeId).edit().modifyFile(filePath, RawInputUtil.create(fileContent));
    gApi.changes().id(changeId).edit().publish();
    String previousPatchSetId = gApi.changes().id(changeId).get().currentRevision;
    gApi.changes().id(changeId).edit().deleteFile(filePath);
    gApi.changes().id(changeId).edit().publish();
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, filePath).withBase(previousPatchSetId).get();
    assertThat(diffInfo).metaA().totalLineCount().isEqualTo(4);
    assertThat(diffInfo).metaB().isNull();
}
#end_block

#method_before
@Test
public void numberOfLinesInDiffOfAddedFileWithoutNewlineAtEndIsCorrect() throws Exception {
    String filePath = "a_new_file.txt";
    String fileContent = "Line 1\nLine2\nLine 3";
    gApi.changes().id(changeId).edit().modifyFile(filePath, RawInputUtil.create(fileContent));
    gApi.changes().id(changeId).edit().publish();
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, filePath).withBase(initialPatchSetId).get();
    assertThat(diffInfo).metaA().isNull();
    assertThat(diffInfo).metaB().lines().isEqualTo(3);
}
#method_after
@Test
public void numberOfLinesInDiffOfAddedFileWithoutNewlineAtEndIsCorrect() throws Exception {
    String filePath = "a_new_file.txt";
    String fileContent = "Line 1\nLine2\nLine 3";
    gApi.changes().id(changeId).edit().modifyFile(filePath, RawInputUtil.create(fileContent));
    gApi.changes().id(changeId).edit().publish();
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, filePath).withBase(initialPatchSetId).get();
    assertThat(diffInfo).metaA().isNull();
    assertThat(diffInfo).metaB().totalLineCount().isEqualTo(3);
}
#end_block

#method_before
@Test
public void numberOfLinesInDiffOfAddedFileWithNewlineAtEndIsCorrect() throws Exception {
    String filePath = "a_new_file.txt";
    String fileContent = "Line 1\nLine2\nLine 3\n";
    gApi.changes().id(changeId).edit().modifyFile(filePath, RawInputUtil.create(fileContent));
    gApi.changes().id(changeId).edit().publish();
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, filePath).withBase(initialPatchSetId).get();
    assertThat(diffInfo).metaA().isNull();
    assertThat(diffInfo).metaB().lines().isEqualTo(4);
}
#method_after
@Test
public void numberOfLinesInDiffOfAddedFileWithNewlineAtEndIsCorrect() throws Exception {
    String filePath = "a_new_file.txt";
    String fileContent = "Line 1\nLine2\nLine 3\n";
    gApi.changes().id(changeId).edit().modifyFile(filePath, RawInputUtil.create(fileContent));
    gApi.changes().id(changeId).edit().publish();
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, filePath).withBase(initialPatchSetId).get();
    assertThat(diffInfo).metaA().isNull();
    assertThat(diffInfo).metaB().totalLineCount().isEqualTo(4);
}
#end_block

#method_before
@Test
public void diffOfUnmodifiedFileWithNewlineAtEndHasEmptyLineAtEnd() throws Exception {
    String filePath = "a_new_file.txt";
    String fileContent = "Line 1\nLine 2\nLine 3\n";
    gApi.changes().id(changeId).edit().modifyFile(filePath, RawInputUtil.create(fileContent));
    gApi.changes().id(changeId).edit().publish();
    String previousPatchSetId = gApi.changes().id(changeId).get().currentRevision;
    gApi.changes().id(changeId).edit().modifyCommitMessage("An unchanged patchset");
    gApi.changes().id(changeId).edit().publish();
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, filePath).withBase(previousPatchSetId).get();
    assertThat(diffInfo).content().onlyElement().commonLines().lastElement().isEqualTo("");
    assertThat(diffInfo).metaA().lines().isEqualTo(4);
    assertThat(diffInfo).metaB().lines().isEqualTo(4);
}
#method_after
@Test
public void diffOfUnmodifiedFileWithNewlineAtEndHasEmptyLineAtEnd() throws Exception {
    String filePath = "a_new_file.txt";
    String fileContent = "Line 1\nLine 2\nLine 3\n";
    gApi.changes().id(changeId).edit().modifyFile(filePath, RawInputUtil.create(fileContent));
    gApi.changes().id(changeId).edit().publish();
    String previousPatchSetId = gApi.changes().id(changeId).get().currentRevision;
    gApi.changes().id(changeId).edit().modifyCommitMessage("An unchanged patchset");
    gApi.changes().id(changeId).edit().publish();
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, filePath).withBase(previousPatchSetId).get();
    assertThat(diffInfo).content().onlyElement().commonLines().lastElement().isEqualTo("");
    assertThat(diffInfo).metaA().totalLineCount().isEqualTo(4);
    assertThat(diffInfo).metaB().totalLineCount().isEqualTo(4);
}
#end_block

#method_before
@Test
public void diffOfUnmodifiedFileWithoutNewlineAtEndEndsWithLastLineContent() throws Exception {
    String filePath = "a_new_file.txt";
    String fileContent = "Line 1\nLine 2\nLine 3";
    gApi.changes().id(changeId).edit().modifyFile(filePath, RawInputUtil.create(fileContent));
    gApi.changes().id(changeId).edit().publish();
    String previousPatchSetId = gApi.changes().id(changeId).get().currentRevision;
    gApi.changes().id(changeId).edit().modifyCommitMessage("An unchanged patchset");
    gApi.changes().id(changeId).edit().publish();
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, filePath).withBase(previousPatchSetId).get();
    assertThat(diffInfo).content().onlyElement().commonLines().lastElement().isEqualTo("Line 3");
    assertThat(diffInfo).metaA().lines().isEqualTo(3);
    assertThat(diffInfo).metaB().lines().isEqualTo(3);
}
#method_after
@Test
public void diffOfUnmodifiedFileWithoutNewlineAtEndEndsWithLastLineContent() throws Exception {
    String filePath = "a_new_file.txt";
    String fileContent = "Line 1\nLine 2\nLine 3";
    gApi.changes().id(changeId).edit().modifyFile(filePath, RawInputUtil.create(fileContent));
    gApi.changes().id(changeId).edit().publish();
    String previousPatchSetId = gApi.changes().id(changeId).get().currentRevision;
    gApi.changes().id(changeId).edit().modifyCommitMessage("An unchanged patchset");
    gApi.changes().id(changeId).edit().publish();
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, filePath).withBase(previousPatchSetId).get();
    assertThat(diffInfo).content().onlyElement().commonLines().lastElement().isEqualTo("Line 3");
    assertThat(diffInfo).metaA().totalLineCount().isEqualTo(3);
    assertThat(diffInfo).metaB().totalLineCount().isEqualTo(3);
}
#end_block

#method_before
@Test
public void diffOfModifiedFileWithNewlineAtEndHasEmptyLineAtEnd() throws Exception {
    String filePath = "a_new_file.txt";
    String fileContent = "Line 1\nLine 2\nLine 3\n";
    gApi.changes().id(changeId).edit().modifyFile(filePath, RawInputUtil.create(fileContent));
    gApi.changes().id(changeId).edit().publish();
    String previousPatchSetId = gApi.changes().id(changeId).get().currentRevision;
    addModifiedPatchSet(changeId, filePath, content -> content.replace("Line 1\n", "Line one\n"));
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, filePath).withBase(previousPatchSetId).get();
    assertThat(diffInfo).content().lastElement().commonLines().lastElement().isEqualTo("");
    assertThat(diffInfo).metaA().lines().isEqualTo(4);
    assertThat(diffInfo).metaB().lines().isEqualTo(4);
}
#method_after
@Test
public void diffOfModifiedFileWithNewlineAtEndHasEmptyLineAtEnd() throws Exception {
    String filePath = "a_new_file.txt";
    String fileContent = "Line 1\nLine 2\nLine 3\n";
    gApi.changes().id(changeId).edit().modifyFile(filePath, RawInputUtil.create(fileContent));
    gApi.changes().id(changeId).edit().publish();
    String previousPatchSetId = gApi.changes().id(changeId).get().currentRevision;
    addModifiedPatchSet(changeId, filePath, content -> content.replace("Line 1\n", "Line one\n"));
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, filePath).withBase(previousPatchSetId).get();
    assertThat(diffInfo).content().lastElement().commonLines().lastElement().isEqualTo("");
    assertThat(diffInfo).metaA().totalLineCount().isEqualTo(4);
    assertThat(diffInfo).metaB().totalLineCount().isEqualTo(4);
}
#end_block

#method_before
@Test
public void diffOfModifiedFileWithoutNewlineAtEndEndsWithLastLineContent() throws Exception {
    String filePath = "a_new_file.txt";
    String fileContent = "Line 1\nLine 2\nLine 3";
    gApi.changes().id(changeId).edit().modifyFile(filePath, RawInputUtil.create(fileContent));
    gApi.changes().id(changeId).edit().publish();
    String previousPatchSetId = gApi.changes().id(changeId).get().currentRevision;
    addModifiedPatchSet(changeId, filePath, content -> content.replace("Line 1\n", "Line one\n"));
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, filePath).withBase(previousPatchSetId).get();
    assertThat(diffInfo).content().lastElement().commonLines().lastElement().isEqualTo("Line 3");
    assertThat(diffInfo).metaA().lines().isEqualTo(3);
    assertThat(diffInfo).metaB().lines().isEqualTo(3);
}
#method_after
@Test
public void diffOfModifiedFileWithoutNewlineAtEndEndsWithLastLineContent() throws Exception {
    String filePath = "a_new_file.txt";
    String fileContent = "Line 1\nLine 2\nLine 3";
    gApi.changes().id(changeId).edit().modifyFile(filePath, RawInputUtil.create(fileContent));
    gApi.changes().id(changeId).edit().publish();
    String previousPatchSetId = gApi.changes().id(changeId).get().currentRevision;
    addModifiedPatchSet(changeId, filePath, content -> content.replace("Line 1\n", "Line one\n"));
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, filePath).withBase(previousPatchSetId).get();
    assertThat(diffInfo).content().lastElement().commonLines().lastElement().isEqualTo("Line 3");
    assertThat(diffInfo).metaA().totalLineCount().isEqualTo(3);
    assertThat(diffInfo).metaB().totalLineCount().isEqualTo(3);
}
#end_block

#method_before
@Test
public void diffOfModifiedLastLineWithNewlineAtEndHasEmptyLineAtEnd() throws Exception {
    String filePath = "a_new_file.txt";
    String fileContent = "Line 1\nLine 2\nLine 3\n";
    gApi.changes().id(changeId).edit().modifyFile(filePath, RawInputUtil.create(fileContent));
    gApi.changes().id(changeId).edit().publish();
    String previousPatchSetId = gApi.changes().id(changeId).get().currentRevision;
    addModifiedPatchSet(changeId, filePath, content -> content.replace("Line 3\n", "Line three\n"));
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, filePath).withBase(previousPatchSetId).get();
    assertThat(diffInfo).content().lastElement().commonLines().lastElement().isEqualTo("");
    assertThat(diffInfo).metaA().lines().isEqualTo(4);
    assertThat(diffInfo).metaB().lines().isEqualTo(4);
}
#method_after
@Test
public void diffOfModifiedLastLineWithNewlineAtEndHasEmptyLineAtEnd() throws Exception {
    String filePath = "a_new_file.txt";
    String fileContent = "Line 1\nLine 2\nLine 3\n";
    gApi.changes().id(changeId).edit().modifyFile(filePath, RawInputUtil.create(fileContent));
    gApi.changes().id(changeId).edit().publish();
    String previousPatchSetId = gApi.changes().id(changeId).get().currentRevision;
    addModifiedPatchSet(changeId, filePath, content -> content.replace("Line 3\n", "Line three\n"));
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, filePath).withBase(previousPatchSetId).get();
    assertThat(diffInfo).content().lastElement().commonLines().lastElement().isEqualTo("");
    assertThat(diffInfo).metaA().totalLineCount().isEqualTo(4);
    assertThat(diffInfo).metaB().totalLineCount().isEqualTo(4);
}
#end_block

#method_before
@Test
public void diffOfModifiedLastLineWithoutNewlineAtEndEndsWithLastLineContent() throws Exception {
    String filePath = "a_new_file.txt";
    String fileContent = "Line 1\nLine 2\nLine 3";
    gApi.changes().id(changeId).edit().modifyFile(filePath, RawInputUtil.create(fileContent));
    gApi.changes().id(changeId).edit().publish();
    String previousPatchSetId = gApi.changes().id(changeId).get().currentRevision;
    addModifiedPatchSet(changeId, filePath, content -> content.replace("Line 3", "Line three"));
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, filePath).withBase(previousPatchSetId).get();
    assertThat(diffInfo).content().lastElement().linesOfA().containsExactly("Line 3");
    assertThat(diffInfo).content().lastElement().linesOfB().containsExactly("Line three");
    assertThat(diffInfo).metaA().lines().isEqualTo(3);
    assertThat(diffInfo).metaB().lines().isEqualTo(3);
}
#method_after
@Test
public void diffOfModifiedLastLineWithoutNewlineAtEndEndsWithLastLineContent() throws Exception {
    String filePath = "a_new_file.txt";
    String fileContent = "Line 1\nLine 2\nLine 3";
    gApi.changes().id(changeId).edit().modifyFile(filePath, RawInputUtil.create(fileContent));
    gApi.changes().id(changeId).edit().publish();
    String previousPatchSetId = gApi.changes().id(changeId).get().currentRevision;
    addModifiedPatchSet(changeId, filePath, content -> content.replace("Line 3", "Line three"));
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, filePath).withBase(previousPatchSetId).get();
    assertThat(diffInfo).content().lastElement().linesOfA().containsExactly("Line 3");
    assertThat(diffInfo).content().lastElement().linesOfB().containsExactly("Line three");
    assertThat(diffInfo).metaA().totalLineCount().isEqualTo(3);
    assertThat(diffInfo).metaB().totalLineCount().isEqualTo(3);
}
#end_block

#method_before
@Test
public void addedNewlineAtEndOfFileIsMarkedInDiffWhenWhitespaceIsConsidered() throws Exception {
    addModifiedPatchSet(changeId, FILE_NAME, fileContent -> fileContent.concat("Line 101"));
    String previousPatchSetId = gApi.changes().id(changeId).get().currentRevision;
    addModifiedPatchSet(changeId, FILE_NAME, fileContent -> fileContent.concat("\n"));
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, FILE_NAME).withWhitespace(DiffPreferencesInfo.Whitespace.IGNORE_NONE).withBase(previousPatchSetId).get();
    assertThat(diffInfo).content().element(0).commonLines().isNotEmpty();
    assertThat(diffInfo).content().element(1).linesOfA().containsExactly("Line 101");
    assertThat(diffInfo).content().element(1).linesOfB().containsExactly("Line 101", "");
    assertThat(diffInfo).metaA().lines().isEqualTo(101);
    assertThat(diffInfo).metaB().lines().isEqualTo(102);
}
#method_after
@Test
public void addedNewlineAtEndOfFileIsMarkedInDiffWhenWhitespaceIsConsidered() throws Exception {
    addModifiedPatchSet(changeId, FILE_NAME, fileContent -> fileContent.concat("Line 101"));
    String previousPatchSetId = gApi.changes().id(changeId).get().currentRevision;
    addModifiedPatchSet(changeId, FILE_NAME, fileContent -> fileContent.concat("\n"));
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, FILE_NAME).withWhitespace(DiffPreferencesInfo.Whitespace.IGNORE_NONE).withBase(previousPatchSetId).get();
    assertThat(diffInfo).content().element(0).commonLines().isNotEmpty();
    assertThat(diffInfo).content().element(1).linesOfA().containsExactly("Line 101");
    assertThat(diffInfo).content().element(1).linesOfB().containsExactly("Line 101", "");
    assertThat(diffInfo).metaA().totalLineCount().isEqualTo(101);
    assertThat(diffInfo).metaB().totalLineCount().isEqualTo(102);
}
#end_block

#method_before
@Test
public void addedNewlineAtEndOfFileIsMarkedInDiffWhenWhitespaceIsIgnored() throws Exception {
    addModifiedPatchSet(changeId, FILE_NAME, fileContent -> fileContent.concat("Line 101"));
    String previousPatchSetId = gApi.changes().id(changeId).get().currentRevision;
    addModifiedPatchSet(changeId, FILE_NAME, fileContent -> fileContent.concat("\n"));
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, FILE_NAME).withWhitespace(DiffPreferencesInfo.Whitespace.IGNORE_ALL).withBase(previousPatchSetId).get();
    assertThat(diffInfo).content().element(0).commonLines().isNotEmpty();
    assertThat(diffInfo).content().element(1).linesOfA().isNull();
    assertThat(diffInfo).content().element(1).linesOfB().containsExactly("");
    assertThat(diffInfo).metaA().lines().isEqualTo(101);
    assertThat(diffInfo).metaB().lines().isEqualTo(102);
}
#method_after
@Test
public void addedNewlineAtEndOfFileIsMarkedInDiffWhenWhitespaceIsIgnored() throws Exception {
    addModifiedPatchSet(changeId, FILE_NAME, fileContent -> fileContent.concat("Line 101"));
    String previousPatchSetId = gApi.changes().id(changeId).get().currentRevision;
    addModifiedPatchSet(changeId, FILE_NAME, fileContent -> fileContent.concat("\n"));
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, FILE_NAME).withWhitespace(DiffPreferencesInfo.Whitespace.IGNORE_ALL).withBase(previousPatchSetId).get();
    assertThat(diffInfo).content().element(0).commonLines().isNotEmpty();
    assertThat(diffInfo).content().element(1).linesOfA().isNull();
    assertThat(diffInfo).content().element(1).linesOfB().containsExactly("");
    assertThat(diffInfo).metaA().totalLineCount().isEqualTo(101);
    assertThat(diffInfo).metaB().totalLineCount().isEqualTo(102);
}
#end_block

#method_before
@Test
public void addedLastLineWithoutNewlineBeforeAndAfterwardsIsMarkedInDiff() throws Exception {
    addModifiedPatchSet(changeId, FILE_NAME, fileContent -> fileContent.concat("Line 101"));
    String previousPatchSetId = gApi.changes().id(changeId).get().currentRevision;
    addModifiedPatchSet(changeId, FILE_NAME, fileContent -> fileContent.concat("\nLine 102"));
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, FILE_NAME).withWhitespace(DiffPreferencesInfo.Whitespace.IGNORE_NONE).withBase(previousPatchSetId).get();
    assertThat(diffInfo).content().element(0).commonLines().isNotEmpty();
    assertThat(diffInfo).content().element(1).linesOfA().containsExactly("Line 101");
    assertThat(diffInfo).content().element(1).linesOfB().containsExactly("Line 101", "Line 102");
    assertThat(diffInfo).metaA().lines().isEqualTo(101);
    assertThat(diffInfo).metaB().lines().isEqualTo(102);
}
#method_after
@Test
public void addedLastLineWithoutNewlineBeforeAndAfterwardsIsMarkedInDiff() throws Exception {
    addModifiedPatchSet(changeId, FILE_NAME, fileContent -> fileContent.concat("Line 101"));
    String previousPatchSetId = gApi.changes().id(changeId).get().currentRevision;
    addModifiedPatchSet(changeId, FILE_NAME, fileContent -> fileContent.concat("\nLine 102"));
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, FILE_NAME).withWhitespace(DiffPreferencesInfo.Whitespace.IGNORE_NONE).withBase(previousPatchSetId).get();
    assertThat(diffInfo).content().element(0).commonLines().isNotEmpty();
    assertThat(diffInfo).content().element(1).linesOfA().containsExactly("Line 101");
    assertThat(diffInfo).content().element(1).linesOfB().containsExactly("Line 101", "Line 102");
    assertThat(diffInfo).metaA().totalLineCount().isEqualTo(101);
    assertThat(diffInfo).metaB().totalLineCount().isEqualTo(102);
}
#end_block

#method_before
@Test
public void addedLastLineWithoutNewlineBeforeButWithOneAfterwardsIsMarkedInDiff() throws Exception {
    addModifiedPatchSet(changeId, FILE_NAME, fileContent -> fileContent.concat("Line 101"));
    String previousPatchSetId = gApi.changes().id(changeId).get().currentRevision;
    addModifiedPatchSet(changeId, FILE_NAME, fileContent -> fileContent.concat("\nLine 102\n"));
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, FILE_NAME).withWhitespace(DiffPreferencesInfo.Whitespace.IGNORE_NONE).withBase(previousPatchSetId).get();
    assertThat(diffInfo).content().element(0).commonLines().isNotEmpty();
    assertThat(diffInfo).content().element(1).linesOfA().containsExactly("Line 101");
    assertThat(diffInfo).content().element(1).linesOfB().containsExactly("Line 101", "Line 102", "");
    assertThat(diffInfo).metaA().lines().isEqualTo(101);
    assertThat(diffInfo).metaB().lines().isEqualTo(103);
}
#method_after
@Test
public void addedLastLineWithoutNewlineBeforeButWithOneAfterwardsIsMarkedInDiff() throws Exception {
    addModifiedPatchSet(changeId, FILE_NAME, fileContent -> fileContent.concat("Line 101"));
    String previousPatchSetId = gApi.changes().id(changeId).get().currentRevision;
    addModifiedPatchSet(changeId, FILE_NAME, fileContent -> fileContent.concat("\nLine 102\n"));
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, FILE_NAME).withWhitespace(DiffPreferencesInfo.Whitespace.IGNORE_NONE).withBase(previousPatchSetId).get();
    assertThat(diffInfo).content().element(0).commonLines().isNotEmpty();
    assertThat(diffInfo).content().element(1).linesOfA().containsExactly("Line 101");
    assertThat(diffInfo).content().element(1).linesOfB().containsExactly("Line 101", "Line 102", "");
    assertThat(diffInfo).metaA().totalLineCount().isEqualTo(101);
    assertThat(diffInfo).metaB().totalLineCount().isEqualTo(103);
}
#end_block

#method_before
@Test
public void addedLastLineWithNewlineBeforeAndAfterwardsIsMarkedInDiff() throws Exception {
    addModifiedPatchSet(changeId, FILE_NAME, fileContent -> fileContent.concat("Line 101\n"));
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, FILE_NAME).withBase(initialPatchSetId).get();
    assertThat(diffInfo).content().element(0).commonLines().isNotEmpty();
    assertThat(diffInfo).content().element(1).linesOfA().isNull();
    assertThat(diffInfo).content().element(1).linesOfB().containsExactly("Line 101");
    assertThat(diffInfo).content().element(2).commonLines().containsExactly("");
    assertThat(diffInfo).metaA().lines().isEqualTo(101);
    assertThat(diffInfo).metaB().lines().isEqualTo(102);
}
#method_after
@Test
public void addedLastLineWithNewlineBeforeAndAfterwardsIsMarkedInDiff() throws Exception {
    addModifiedPatchSet(changeId, FILE_NAME, fileContent -> fileContent.concat("Line 101\n"));
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, FILE_NAME).withBase(initialPatchSetId).get();
    assertThat(diffInfo).content().element(0).commonLines().isNotEmpty();
    assertThat(diffInfo).content().element(1).linesOfA().isNull();
    assertThat(diffInfo).content().element(1).linesOfB().containsExactly("Line 101");
    assertThat(diffInfo).content().element(2).commonLines().containsExactly("");
    assertThat(diffInfo).metaA().totalLineCount().isEqualTo(101);
    assertThat(diffInfo).metaB().totalLineCount().isEqualTo(102);
}
#end_block

#method_before
@Test
public void addedLastLineWithNewlineBeforeButWithoutOneAfterwardsIsMarkedInDiff() throws Exception {
    addModifiedPatchSet(changeId, FILE_NAME, fileContent -> fileContent.concat("Line 101"));
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, FILE_NAME).withBase(initialPatchSetId).get();
    assertThat(diffInfo).content().element(0).commonLines().isNotEmpty();
    assertThat(diffInfo).content().element(1).linesOfA().containsExactly("");
    assertThat(diffInfo).content().element(1).linesOfB().containsExactly("Line 101");
    assertThat(diffInfo).metaA().lines().isEqualTo(101);
    assertThat(diffInfo).metaB().lines().isEqualTo(101);
}
#method_after
@Test
public void addedLastLineWithNewlineBeforeButWithoutOneAfterwardsIsMarkedInDiff() throws Exception {
    addModifiedPatchSet(changeId, FILE_NAME, fileContent -> fileContent.concat("Line 101"));
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, FILE_NAME).withBase(initialPatchSetId).get();
    assertThat(diffInfo).content().element(0).commonLines().isNotEmpty();
    assertThat(diffInfo).content().element(1).linesOfA().containsExactly("");
    assertThat(diffInfo).content().element(1).linesOfB().containsExactly("Line 101");
    assertThat(diffInfo).metaA().totalLineCount().isEqualTo(101);
    assertThat(diffInfo).metaB().totalLineCount().isEqualTo(101);
}
#end_block

#method_before
@Test
public void deletedNewlineAtEndOfFileIsMarkedInDiffWhenWhitespaceIsConsidered() throws Exception {
    addModifiedPatchSet(changeId, FILE_NAME, fileContent -> fileContent.replace("Line 100\n", "Line 100"));
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, FILE_NAME).withBase(initialPatchSetId).withWhitespace(DiffPreferencesInfo.Whitespace.IGNORE_NONE).get();
    assertThat(diffInfo).content().element(0).commonLines().isNotEmpty();
    assertThat(diffInfo).content().element(1).linesOfA().containsExactly("Line 100", "");
    assertThat(diffInfo).content().element(1).linesOfB().containsExactly("Line 100");
    assertThat(diffInfo).metaA().lines().isEqualTo(101);
    assertThat(diffInfo).metaB().lines().isEqualTo(100);
}
#method_after
@Test
public void deletedNewlineAtEndOfFileIsMarkedInDiffWhenWhitespaceIsConsidered() throws Exception {
    addModifiedPatchSet(changeId, FILE_NAME, fileContent -> fileContent.replace("Line 100\n", "Line 100"));
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, FILE_NAME).withBase(initialPatchSetId).withWhitespace(DiffPreferencesInfo.Whitespace.IGNORE_NONE).get();
    assertThat(diffInfo).content().element(0).commonLines().isNotEmpty();
    assertThat(diffInfo).content().element(1).linesOfA().containsExactly("Line 100", "");
    assertThat(diffInfo).content().element(1).linesOfB().containsExactly("Line 100");
    assertThat(diffInfo).metaA().totalLineCount().isEqualTo(101);
    assertThat(diffInfo).metaB().totalLineCount().isEqualTo(100);
}
#end_block

#method_before
@Test
public void deletedNewlineAtEndOfFileIsMarkedInDiffWhenWhitespaceIsIgnored() throws Exception {
    addModifiedPatchSet(changeId, FILE_NAME, fileContent -> fileContent.replace("Line 100\n", "Line 100"));
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, FILE_NAME).withBase(initialPatchSetId).withWhitespace(DiffPreferencesInfo.Whitespace.IGNORE_ALL).get();
    assertThat(diffInfo).content().element(0).commonLines().isNotEmpty();
    assertThat(diffInfo).content().element(1).linesOfA().containsExactly("");
    assertThat(diffInfo).content().element(1).linesOfB().isNull();
    assertThat(diffInfo).metaA().lines().isEqualTo(101);
    assertThat(diffInfo).metaB().lines().isEqualTo(100);
}
#method_after
@Test
public void deletedNewlineAtEndOfFileIsMarkedInDiffWhenWhitespaceIsIgnored() throws Exception {
    addModifiedPatchSet(changeId, FILE_NAME, fileContent -> fileContent.replace("Line 100\n", "Line 100"));
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, FILE_NAME).withBase(initialPatchSetId).withWhitespace(DiffPreferencesInfo.Whitespace.IGNORE_ALL).get();
    assertThat(diffInfo).content().element(0).commonLines().isNotEmpty();
    assertThat(diffInfo).content().element(1).linesOfA().containsExactly("");
    assertThat(diffInfo).content().element(1).linesOfB().isNull();
    assertThat(diffInfo).metaA().totalLineCount().isEqualTo(101);
    assertThat(diffInfo).metaB().totalLineCount().isEqualTo(100);
}
#end_block

#method_before
@Test
public void deletedLastLineWithoutNewlineBeforeAndAfterwardsIsMarkedInDiff() throws Exception {
    addModifiedPatchSet(changeId, FILE_NAME, fileContent -> fileContent.replace("Line 100\n", "Line 100"));
    String previousPatchSetId = gApi.changes().id(changeId).get().currentRevision;
    addModifiedPatchSet(changeId, FILE_NAME, fileContent -> fileContent.replace("\nLine 100", ""));
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, FILE_NAME).withBase(previousPatchSetId).withWhitespace(DiffPreferencesInfo.Whitespace.IGNORE_NONE).get();
    assertThat(diffInfo).content().element(0).commonLines().isNotEmpty();
    assertThat(diffInfo).content().element(1).linesOfA().containsExactly("Line 99", "Line 100");
    assertThat(diffInfo).content().element(1).linesOfB().containsExactly("Line 99");
    assertThat(diffInfo).metaA().lines().isEqualTo(100);
    assertThat(diffInfo).metaB().lines().isEqualTo(99);
}
#method_after
@Test
public void deletedLastLineWithoutNewlineBeforeAndAfterwardsIsMarkedInDiff() throws Exception {
    addModifiedPatchSet(changeId, FILE_NAME, fileContent -> fileContent.replace("Line 100\n", "Line 100"));
    String previousPatchSetId = gApi.changes().id(changeId).get().currentRevision;
    addModifiedPatchSet(changeId, FILE_NAME, fileContent -> fileContent.replace("\nLine 100", ""));
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, FILE_NAME).withBase(previousPatchSetId).withWhitespace(DiffPreferencesInfo.Whitespace.IGNORE_NONE).get();
    assertThat(diffInfo).content().element(0).commonLines().isNotEmpty();
    assertThat(diffInfo).content().element(1).linesOfA().containsExactly("Line 99", "Line 100");
    assertThat(diffInfo).content().element(1).linesOfB().containsExactly("Line 99");
    assertThat(diffInfo).metaA().totalLineCount().isEqualTo(100);
    assertThat(diffInfo).metaB().totalLineCount().isEqualTo(99);
}
#end_block

#method_before
@Test
public void deletedLastLineWithoutNewlineBeforeButWithOneAfterwardsIsMarkedInDiff() throws Exception {
    addModifiedPatchSet(changeId, FILE_NAME, fileContent -> fileContent.replace("Line 100\n", "Line 100"));
    String previousPatchSetId = gApi.changes().id(changeId).get().currentRevision;
    addModifiedPatchSet(changeId, FILE_NAME, fileContent -> fileContent.replace("Line 100", ""));
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, FILE_NAME).withBase(previousPatchSetId).withWhitespace(DiffPreferencesInfo.Whitespace.IGNORE_NONE).get();
    assertThat(diffInfo).content().element(0).commonLines().isNotEmpty();
    assertThat(diffInfo).content().element(1).linesOfA().containsExactly("Line 100");
    assertThat(diffInfo).content().element(1).linesOfB().containsExactly("");
    assertThat(diffInfo).metaA().lines().isEqualTo(100);
    assertThat(diffInfo).metaB().lines().isEqualTo(100);
}
#method_after
@Test
public void deletedLastLineWithoutNewlineBeforeButWithOneAfterwardsIsMarkedInDiff() throws Exception {
    addModifiedPatchSet(changeId, FILE_NAME, fileContent -> fileContent.replace("Line 100\n", "Line 100"));
    String previousPatchSetId = gApi.changes().id(changeId).get().currentRevision;
    addModifiedPatchSet(changeId, FILE_NAME, fileContent -> fileContent.replace("Line 100", ""));
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, FILE_NAME).withBase(previousPatchSetId).withWhitespace(DiffPreferencesInfo.Whitespace.IGNORE_NONE).get();
    assertThat(diffInfo).content().element(0).commonLines().isNotEmpty();
    assertThat(diffInfo).content().element(1).linesOfA().containsExactly("Line 100");
    assertThat(diffInfo).content().element(1).linesOfB().containsExactly("");
    assertThat(diffInfo).metaA().totalLineCount().isEqualTo(100);
    assertThat(diffInfo).metaB().totalLineCount().isEqualTo(100);
}
#end_block

#method_before
@Test
public void deletedLastLineWithNewlineBeforeAndAfterwardsIsMarkedInDiff() throws Exception {
    addModifiedPatchSet(changeId, FILE_NAME, fileContent -> fileContent.replace("Line 100\n", ""));
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, FILE_NAME).withBase(initialPatchSetId).withWhitespace(DiffPreferencesInfo.Whitespace.IGNORE_NONE).get();
    assertThat(diffInfo).content().element(0).commonLines().isNotEmpty();
    assertThat(diffInfo).content().element(1).linesOfA().containsExactly("Line 100");
    assertThat(diffInfo).content().element(1).linesOfB().isNull();
    assertThat(diffInfo).content().element(2).commonLines().containsExactly("");
    assertThat(diffInfo).metaA().lines().isEqualTo(101);
    assertThat(diffInfo).metaB().lines().isEqualTo(100);
}
#method_after
@Test
public void deletedLastLineWithNewlineBeforeAndAfterwardsIsMarkedInDiff() throws Exception {
    addModifiedPatchSet(changeId, FILE_NAME, fileContent -> fileContent.replace("Line 100\n", ""));
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, FILE_NAME).withBase(initialPatchSetId).withWhitespace(DiffPreferencesInfo.Whitespace.IGNORE_NONE).get();
    assertThat(diffInfo).content().element(0).commonLines().isNotEmpty();
    assertThat(diffInfo).content().element(1).linesOfA().containsExactly("Line 100");
    assertThat(diffInfo).content().element(1).linesOfB().isNull();
    assertThat(diffInfo).content().element(2).commonLines().containsExactly("");
    assertThat(diffInfo).metaA().totalLineCount().isEqualTo(101);
    assertThat(diffInfo).metaB().totalLineCount().isEqualTo(100);
}
#end_block

#method_before
@Test
public void deletedLastLineWithNewlineBeforeButWithoutOneAfterwardsIsMarkedInDiff() throws Exception {
    addModifiedPatchSet(changeId, FILE_NAME, fileContent -> fileContent.replace("\nLine 100\n", ""));
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, FILE_NAME).withBase(initialPatchSetId).withWhitespace(DiffPreferencesInfo.Whitespace.IGNORE_NONE).get();
    assertThat(diffInfo).content().element(0).commonLines().isNotEmpty();
    assertThat(diffInfo).content().element(1).linesOfA().containsExactly("Line 99", "Line 100", "");
    assertThat(diffInfo).content().element(1).linesOfB().containsExactly("Line 99");
    assertThat(diffInfo).metaA().lines().isEqualTo(101);
    assertThat(diffInfo).metaB().lines().isEqualTo(99);
}
#method_after
@Test
public void deletedLastLineWithNewlineBeforeButWithoutOneAfterwardsIsMarkedInDiff() throws Exception {
    addModifiedPatchSet(changeId, FILE_NAME, fileContent -> fileContent.replace("\nLine 100\n", ""));
    DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, FILE_NAME).withBase(initialPatchSetId).withWhitespace(DiffPreferencesInfo.Whitespace.IGNORE_NONE).get();
    assertThat(diffInfo).content().element(0).commonLines().isNotEmpty();
    assertThat(diffInfo).content().element(1).linesOfA().containsExactly("Line 99", "Line 100", "");
    assertThat(diffInfo).content().element(1).linesOfB().containsExactly("Line 99");
    assertThat(diffInfo).metaA().totalLineCount().isEqualTo(101);
    assertThat(diffInfo).metaB().totalLineCount().isEqualTo(99);
}
#end_block

#method_before
protected void removePermission(Project.NameKey project, String ref, String permission) throws IOException, ConfigInvalidException {
    try (MetaDataUpdate md = metaDataUpdateFactory.create(project)) {
        md.setMessage(String.format("Remove %s on %s", permission, ref));
        ProjectConfig config = ProjectConfig.read(md);
        AccessSection s = config.getAccessSection(ref, true);
        Permission p = s.getPermission(permission, true);
        p.getRules().clear();
        config.commit(md);
        projectCache.evict(config.getProject());
    }
}
#method_after
protected void removePermission(Project.NameKey project, String ref, String permission) throws IOException, ConfigInvalidException {
    try (MetaDataUpdate md = metaDataUpdateFactory.create(project)) {
        md.setMessage(String.format("Remove %s on %s", permission, ref));
        ProjectConfig config = ProjectConfig.read(md);
        AccessSection s = config.getAccessSection(ref, true);
        Permission p = s.getPermission(permission, true);
        p.clearRules();
        config.commit(md);
        projectCache.evict(config.getProject());
    }
}
#end_block

#method_before
private PatchScript build(PatchListEntry content, CommentDetail comments, List<Patch> history) throws IOException {
    boolean intralineDifferenceIsPossible = true;
    boolean intralineFailure = false;
    boolean intralineTimeout = false;
    a.path = oldName(content);
    b.path = newName(content);
    a.resolve(null, aId);
    b.resolve(a, bId);
    edits = new ArrayList<>(content.getEdits());
    ImmutableSet<Edit> editsDueToRebase = content.getEditsDueToRebase();
    if (!isModify(content)) {
        intralineDifferenceIsPossible = false;
    } else if (diffPrefs.intralineDifference) {
        IntraLineDiff d = patchListCache.getIntraLineDiff(IntraLineDiffKey.create(a.id, b.id, diffPrefs.ignoreWhitespace), IntraLineDiffArgs.create(a.src, b.src, edits, editsDueToRebase, projectKey, bId, b.path));
        if (d != null) {
            switch(d.getStatus()) {
                case EDIT_LIST:
                    edits = new ArrayList<>(d.getEdits());
                    break;
                case DISABLED:
                    intralineDifferenceIsPossible = false;
                    break;
                case ERROR:
                    intralineDifferenceIsPossible = false;
                    intralineFailure = true;
                    break;
                case TIMEOUT:
                    intralineDifferenceIsPossible = false;
                    intralineTimeout = true;
                    break;
            }
        } else {
            intralineDifferenceIsPossible = false;
            intralineFailure = true;
        }
    }
    correctEditsRegardingNewlineAtEndDifferences();
    if (comments != null) {
        ensureCommentsVisible(comments);
    }
    boolean hugeFile = false;
    if (a.src == b.src && a.size() <= context && content.getEdits().isEmpty()) {
        // 
        for (int i = 0; i < a.size(); i++) {
            a.addLine(i);
        }
        edits = new ArrayList<>(1);
        edits.add(new Edit(a.size(), a.size()));
    } else {
        if (BIG_FILE < Math.max(a.size(), b.size())) {
            // IF the file is really large, we disable things to avoid choking
            // the browser client.
            // 
            hugeFile = true;
        }
        // In order to expand the skipped common lines or syntax highlight the
        // file properly we need to give the client the complete file contents.
        // So force our context temporarily to the complete file size.
        // 
        context = MAX_CONTEXT;
        packContent(diffPrefs.ignoreWhitespace != Whitespace.IGNORE_NONE);
    }
    return new PatchScript(change.getKey(), content.getChangeType(), content.getOldName(), content.getNewName(), a.fileMode, b.fileMode, content.getHeaderLines(), diffPrefs, a.dst, b.dst, edits, editsDueToRebase, a.displayMethod, b.displayMethod, a.mimeType.toString(), b.mimeType.toString(), comments, history, hugeFile, intralineDifferenceIsPossible, intralineFailure, intralineTimeout, content.getPatchType() == Patch.PatchType.BINARY, aId == null ? null : aId.getName(), bId == null ? null : bId.getName());
}
#method_after
private PatchScript build(PatchListEntry content, CommentDetail comments, List<Patch> history) throws IOException {
    boolean intralineDifferenceIsPossible = true;
    boolean intralineFailure = false;
    boolean intralineTimeout = false;
    a.path = oldName(content);
    b.path = newName(content);
    a.resolve(null, aId);
    b.resolve(a, bId);
    edits = new ArrayList<>(content.getEdits());
    ImmutableSet<Edit> editsDueToRebase = content.getEditsDueToRebase();
    if (!isModify(content)) {
        intralineDifferenceIsPossible = false;
    } else if (diffPrefs.intralineDifference) {
        IntraLineDiff d = patchListCache.getIntraLineDiff(IntraLineDiffKey.create(a.id, b.id, diffPrefs.ignoreWhitespace), IntraLineDiffArgs.create(a.src, b.src, edits, editsDueToRebase, projectKey, bId, b.path));
        if (d != null) {
            switch(d.getStatus()) {
                case EDIT_LIST:
                    edits = new ArrayList<>(d.getEdits());
                    break;
                case DISABLED:
                    intralineDifferenceIsPossible = false;
                    break;
                case ERROR:
                    intralineDifferenceIsPossible = false;
                    intralineFailure = true;
                    break;
                case TIMEOUT:
                    intralineDifferenceIsPossible = false;
                    intralineTimeout = true;
                    break;
            }
        } else {
            intralineDifferenceIsPossible = false;
            intralineFailure = true;
        }
    }
    correctForDifferencesInNewlineAtEnd();
    if (comments != null) {
        ensureCommentsVisible(comments);
    }
    boolean hugeFile = false;
    if (a.src == b.src && a.size() <= context && content.getEdits().isEmpty()) {
        // 
        for (int i = 0; i < a.size(); i++) {
            a.addLine(i);
        }
        edits = new ArrayList<>(1);
        edits.add(new Edit(a.size(), a.size()));
    } else {
        if (BIG_FILE < Math.max(a.size(), b.size())) {
            // IF the file is really large, we disable things to avoid choking
            // the browser client.
            // 
            hugeFile = true;
        }
        // In order to expand the skipped common lines or syntax highlight the
        // file properly we need to give the client the complete file contents.
        // So force our context temporarily to the complete file size.
        // 
        context = MAX_CONTEXT;
        packContent(diffPrefs.ignoreWhitespace != Whitespace.IGNORE_NONE);
    }
    return new PatchScript(change.getKey(), content.getChangeType(), content.getOldName(), content.getNewName(), a.fileMode, b.fileMode, content.getHeaderLines(), diffPrefs, a.dst, b.dst, edits, editsDueToRebase, a.displayMethod, b.displayMethod, a.mimeType.toString(), b.mimeType.toString(), comments, history, hugeFile, intralineDifferenceIsPossible, intralineFailure, intralineTimeout, content.getPatchType() == Patch.PatchType.BINARY, aId == null ? null : aId.getName(), bId == null ? null : bId.getName());
}
#end_block

#method_before
@Override
public AtomicLong load(Project.NameKey project) throws IOException, InterruptedException {
    try (Repository git = gitManager.openRepository(project)) {
        return new AtomicLong(getDiskUsage(git.getDirectory()));
    }
}
#method_after
@Override
public AtomicLong load(Project.NameKey project) throws IOException {
    try (Repository git = gitManager.openRepository(project)) {
        if (useGitObjectCount) {
            return new AtomicLong(getDiskUsageByGitObjectCount(git));
        }
        return new AtomicLong(getDiskUsage(git.getDirectory()));
    }
}
#end_block

#method_before
private long getDiskUsage(File dir) throws IOException, InterruptedException {
    final MutableLong size = new MutableLong();
    if (gitObjectCountCommand == null) {
        log.debug("enableGitObjectCount is false");
        Files.walkFileTree(dir.toPath(), new SimpleFileVisitor<Path>() {

            @Override
            public FileVisitResult visitFile(Path path, BasicFileAttributes attrs) throws IOException {
                if (attrs.isRegularFile()) {
                    size.add(attrs.size());
                }
                return FileVisitResult.CONTINUE;
            }
        });
    } else {
        log.debug("enableGitObjectCount is true");
        ProcessBuilder builder = new ProcessBuilder(gitObjectCountCommand);
        builder.directory(dir);
        builder.redirectErrorStream(true);
        Process process = builder.start();
        process.waitFor();
        try (InputStreamReader isr = new InputStreamReader(process.getInputStream())) {
            String gitCountObjectsRawOutput = CharStreams.toString(isr).trim();
            Map<String, String> gitCountObjectsOutput = Splitter.on(System.getProperty("line.separator")).trimResults().withKeyValueSeparator(':').split(gitCountObjectsRawOutput);
            String sizeOfLooseObjects = gitCountObjectsOutput.get("size").trim();
            String sizeOfPackedObjects = gitCountObjectsOutput.get("size-pack").trim();
            if (sizeOfLooseObjects == null || sizeOfPackedObjects == null) {
                log.error("No required size found for repo: " + dir.getAbsolutePath());
            } else {
                size.add(Long.parseLong(sizeOfLooseObjects) * K);
                size.add(Long.parseLong(sizeOfPackedObjects) * K);
            }
        }
    }
    return size.longValue();
}
#method_after
private static long getDiskUsage(File dir) throws IOException {
    final MutableLong size = new MutableLong();
    Files.walkFileTree(dir.toPath(), new SimpleFileVisitor<Path>() {

        @Override
        public FileVisitResult visitFile(Path path, BasicFileAttributes attrs) throws IOException {
            if (attrs.isRegularFile()) {
                size.add(attrs.size());
            }
            return FileVisitResult.CONTINUE;
        }
    });
    return size.longValue();
}
#end_block

#method_before
@Override
public List<String> queryChangeEvents(String query) throws EventsLogException {
    if (!online) {
        throw new ServiceUnavailableException();
    }
    List<SQLEntry> entries = new ArrayList<>();
    for (Entry<String, Collection<SQLEntry>> entry : eventsDb.getEvents(query).asMap().entrySet()) {
        String projectName = entry.getKey();
        try {
            if (projectControlFactory.controlFor(new Project.NameKey(projectName), userProvider.get()).isVisible()) {
                entries.addAll(entry.getValue());
            }
        } catch (NoSuchProjectException e) {
            log.warn("Database contains entries for a non-existing project, {}; removing project from database", projectName);
            eventsDb.removeProjectEvents(projectName);
        } catch (IOException e) {
            log.warn("Cannot get project visibility info for {} from cache", projectName, e);
        }
    }
    return entries.stream().sorted().map(SQLEntry::getEvent).collect(Collectors.toList());
}
#method_after
@Override
public List<String> queryChangeEvents(String query) throws EventsLogException {
    if (!online) {
        throw new ServiceUnavailableException();
    }
    List<SQLEntry> entries = new ArrayList<>();
    for (Entry<String, Collection<SQLEntry>> entry : eventsDb.getEvents(query).asMap().entrySet()) {
        String projectName = entry.getKey();
        try {
            if (projectControlFactory.controlFor(new Project.NameKey(projectName), userProvider.get()).isVisible()) {
                entries.addAll(entry.getValue());
            }
        } catch (NoSuchProjectException e) {
            log.warn("Database contains a non-existing project, {}; removing project from database", projectName);
            eventsDb.removeProjectEvents(projectName);
        } catch (IOException e) {
            log.warn("Cannot get project visibility info for {} from cache", projectName, e);
        }
    }
    return entries.stream().sorted().map(SQLEntry::getEvent).collect(toList());
}
#end_block

#method_before
void setMaxConnections(int maxConnections) {
    ds.setMaxActive(maxConnections);
    ds.setMinIdle(maxConnections / 4);
    ds.setMaxIdle(maxConnections / 2);
    ds.setInitialSize(ds.getMinIdle());
}
#method_after
void setMaxConnections(int maxConnections) {
    ds.setMaxActive(maxConnections);
    ds.setMinIdle(maxConnections / 4);
    int maxIdle = maxConnections / 2;
    if (maxIdle == 0) {
        maxIdle = maxConnections;
    }
    ds.setMaxIdle(maxIdle);
    ds.setInitialSize(ds.getMinIdle());
}
#end_block

#method_before
void removeProjectEvents(String project) {
    try {
        execute(format("DELETE FROM %s WHERE project = '%s'", TABLE_NAME, project));
    } catch (SQLException e) {
        log.warn("Cannot remove project " + project + " events from database", e);
    }
}
#method_after
void removeProjectEvents(String project) {
    try {
        execute(format("DELETE FROM %s WHERE project = '%s'", TABLE_NAME, project));
    } catch (SQLException e) {
        log.warn("Cannot remove project {} events from database", project, e);
    }
}
#end_block

#method_before
@Provides
@Singleton
@LocalEventsDb
SQLClient provideLocalSqlClient(EventsLogConfig cfg) {
    String path = cfg.getLocalStorePath().toString();
    path = path.endsWith("/") ? path : path + "/";
    SQLClient sqlClient = new SQLClient(cfg.getLocalStoreDriver(), H2_DB_PREFIX + path + SQLTable.TABLE_NAME, cfg.getUrlOptions());
    sqlClient.setEvictIdleTime(cfg.getEvictIdleTime());
    return sqlClient;
}
#method_after
@Provides
@Singleton
@LocalEventsDb
SQLClient provideLocalSqlClient(EventsLogConfig cfg) {
    SQLClient sqlClient = new SQLClient(cfg.getLocalStoreDriver(), H2_DB_PREFIX + cfg.getLocalStorePath().resolve(SQLTable.TABLE_NAME), cfg.getUrlOptions());
    sqlClient.setEvictIdleTime(cfg.getEvictIdleTime());
    return sqlClient;
}
#end_block

#method_before
@Override
public List<String> queryChangeEvents(String query) throws EventsLogException {
    if (!online) {
        throw new ServiceUnavailableException();
    }
    List<SQLEntry> entries = new ArrayList<>();
    for (Entry<String, Collection<SQLEntry>> entry : eventsDb.getEvents(query).asMap().entrySet()) {
        String projectName = entry.getKey();
        try {
            if (projectControlFactory.controlFor(new Project.NameKey(projectName), userProvider.get()).isVisible()) {
                entries.addAll(entry.getValue());
            }
        } catch (NoSuchProjectException e) {
            log.warn("Database contains entries for a non-existing project, {}; removing project from database", projectName);
            eventsDb.removeProjectEvents(projectName);
        } catch (IOException e) {
            log.warn("Cannot get project visibility info for {} from cache", projectName, e);
        }
    }
    return sortedEventsFromEntries(entries);
}
#method_after
@Override
public List<String> queryChangeEvents(String query) throws EventsLogException {
    if (!online) {
        throw new ServiceUnavailableException();
    }
    List<SQLEntry> entries = new ArrayList<>();
    for (Entry<String, Collection<SQLEntry>> entry : eventsDb.getEvents(query).asMap().entrySet()) {
        String projectName = entry.getKey();
        try {
            if (projectControlFactory.controlFor(new Project.NameKey(projectName), userProvider.get()).isVisible()) {
                entries.addAll(entry.getValue());
            }
        } catch (NoSuchProjectException e) {
            log.warn("Database contains a non-existing project, {}; removing project from database", projectName);
            eventsDb.removeProjectEvents(projectName);
        } catch (IOException e) {
            log.warn("Cannot get project visibility info for {} from cache", projectName, e);
        }
    }
    return sortedEventsFromEntries(entries);
}
#end_block

#method_before
@Test
public void noOpIfAllCommentsAreJson() throws Exception {
    Change c = newChange();
    incrementPatchSet(c);
    ChangeNotes notes = newNotes(c);
    ChangeUpdate update = newUpdate(c, changeOwner);
    Comment ps1Comment = newComment(notes, 1, "comment on ps1");
    update.putComment(Status.PUBLISHED, ps1Comment);
    update.commit();
    notes = newNotes(c);
    update = newUpdate(c, changeOwner);
    Comment ps2Comment = newComment(notes, 2, "comment on ps2");
    update.putComment(Status.PUBLISHED, ps2Comment);
    update.commit();
    notes = newNotes(c);
    assertThat(getToStringRepresentations(notes.getComments())).containsExactly(getRevId(notes, 1), ps1Comment.toString(), getRevId(notes, 2), ps2Comment.toString());
    ChangeNotes oldNotes = notes;
    migrate(project, 0);
    assertNoDifferences(notes, oldNotes);
    assertThat(notes.getMetaId()).isEqualTo(oldNotes.getMetaId());
}
#method_after
@Test
public void noOpIfAllCommentsAreJson() throws Exception {
    Change c = newChange();
    incrementPatchSet(c);
    ChangeNotes notes = newNotes(c);
    ChangeUpdate update = newUpdate(c, changeOwner);
    Comment ps1Comment = newComment(notes, 1, "comment on ps1");
    update.putComment(Status.PUBLISHED, ps1Comment);
    update.commit();
    notes = newNotes(c);
    update = newUpdate(c, changeOwner);
    Comment ps2Comment = newComment(notes, 2, "comment on ps2");
    update.putComment(Status.PUBLISHED, ps2Comment);
    update.commit();
    notes = newNotes(c);
    assertThat(getToStringRepresentations(notes.getComments())).containsExactly(getRevId(notes, 1), ps1Comment.toString(), getRevId(notes, 2), ps2Comment.toString());
    ChangeNotes oldNotes = notes;
    checkMigrate(project, ImmutableList.of());
    assertNoDifferences(notes, oldNotes);
    assertThat(notes.getMetaId()).isEqualTo(oldNotes.getMetaId());
}
#end_block

#method_before
@Test
public void migratePublishedComments() throws Exception {
    Change c = newChange();
    incrementPatchSet(c);
    ChangeNotes notes = newNotes(c);
    Comment ps1Comment1 = newComment(notes, 1, "first comment on ps1");
    Comment ps2Comment1 = newComment(notes, 2, "first comment on ps2");
    Comment ps1Comment2 = newComment(notes, 1, "second comment on ps1");
    // Construct legacy format 'by hand'.
    ByteArrayOutputStream out1 = new ByteArrayOutputStream(0);
    legacyChangeNoteWrite.buildNote(ImmutableListMultimap.<Integer, Comment>builder().put(1, ps1Comment1).build(), out1);
    ByteArrayOutputStream out2 = new ByteArrayOutputStream(0);
    legacyChangeNoteWrite.buildNote(ImmutableListMultimap.<Integer, Comment>builder().put(2, ps2Comment1).build(), out2);
    ByteArrayOutputStream out3 = new ByteArrayOutputStream(0);
    legacyChangeNoteWrite.buildNote(ImmutableListMultimap.<Integer, Comment>builder().put(1, ps1Comment2).put(1, ps1Comment1).build(), out3);
    TestRepository<Repository> testRepository = new TestRepository<>(repo, rw);
    String metaRefName = RefNames.changeMetaRef(c.getId());
    testRepository.branch(metaRefName).commit().message("Review ps 1\n\nPatch-set: 1").add(ps1Comment1.revId, out1.toString()).author(serverIdent).committer(serverIdent).create();
    testRepository.branch(metaRefName).commit().message("Review ps 2\n\nPatch-set: 2").add(ps2Comment1.revId, out2.toString()).add(ps1Comment1.revId, out3.toString()).author(serverIdent).committer(serverIdent).create();
    notes = newNotes(c);
    assertThat(getToStringRepresentations(notes.getComments())).containsExactly(getRevId(notes, 1), ps1Comment1.toString(), getRevId(notes, 1), ps1Comment2.toString(), getRevId(notes, 2), ps2Comment1.toString());
    // Comments at each commit all have legacy format.
    ImmutableList<RevCommit> oldLog = log(project, RefNames.changeMetaRef(c.getId()));
    assertThat(oldLog).hasSize(4);
    assertThat(getLegacyFormatMapForPublishedComments(notes, oldLog.get(0))).isEmpty();
    assertThat(getLegacyFormatMapForPublishedComments(notes, oldLog.get(1))).isEmpty();
    assertThat(getLegacyFormatMapForPublishedComments(notes, oldLog.get(2))).containsExactly(ps1Comment1.key, true);
    assertThat(getLegacyFormatMapForPublishedComments(notes, oldLog.get(3))).containsExactly(ps1Comment1.key, true, ps1Comment2.key, true, ps2Comment1.key, true);
    ChangeNotes oldNotes = notes;
    migrate(project, 1);
    // Comment content is the same.
    notes = newNotes(c);
    assertNoDifferences(notes, oldNotes);
    assertThat(getToStringRepresentations(notes.getComments())).containsExactly(getRevId(notes, 1), ps1Comment1.toString(), getRevId(notes, 1), ps1Comment2.toString(), getRevId(notes, 2), ps2Comment1.toString());
    // Comments at each commit all have JSON format.
    ImmutableList<RevCommit> newLog = log(project, RefNames.changeMetaRef(c.getId()));
    assertLogEqualExceptTrees(newLog, oldLog);
    assertThat(getLegacyFormatMapForPublishedComments(notes, newLog.get(0))).isEmpty();
    assertThat(getLegacyFormatMapForPublishedComments(notes, newLog.get(1))).isEmpty();
    assertThat(getLegacyFormatMapForPublishedComments(notes, newLog.get(2))).containsExactly(ps1Comment1.key, false);
    assertThat(getLegacyFormatMapForPublishedComments(notes, newLog.get(3))).containsExactly(ps1Comment1.key, false, ps1Comment2.key, false, ps2Comment1.key, false);
}
#method_after
@Test
public void migratePublishedComments() throws Exception {
    Change c = newChange();
    incrementPatchSet(c);
    ChangeNotes notes = newNotes(c);
    Comment ps1Comment1 = newComment(notes, 1, "first comment on ps1");
    Comment ps2Comment1 = newComment(notes, 2, "first comment on ps2");
    Comment ps1Comment2 = newComment(notes, 1, "second comment on ps1");
    // Construct legacy format 'by hand'.
    ByteArrayOutputStream out1 = new ByteArrayOutputStream(0);
    legacyChangeNoteWrite.buildNote(ImmutableListMultimap.<Integer, Comment>builder().put(1, ps1Comment1).build(), out1);
    ByteArrayOutputStream out2 = new ByteArrayOutputStream(0);
    legacyChangeNoteWrite.buildNote(ImmutableListMultimap.<Integer, Comment>builder().put(2, ps2Comment1).build(), out2);
    ByteArrayOutputStream out3 = new ByteArrayOutputStream(0);
    legacyChangeNoteWrite.buildNote(ImmutableListMultimap.<Integer, Comment>builder().put(1, ps1Comment2).put(1, ps1Comment1).build(), out3);
    TestRepository<Repository> testRepository = new TestRepository<>(repo, rw);
    String metaRefName = RefNames.changeMetaRef(c.getId());
    testRepository.branch(metaRefName).commit().message("Review ps 1\n\nPatch-set: 1").add(ps1Comment1.revId, out1.toString()).author(serverIdent).committer(serverIdent).create();
    testRepository.branch(metaRefName).commit().message("Review ps 2\n\nPatch-set: 2").add(ps2Comment1.revId, out2.toString()).add(ps1Comment1.revId, out3.toString()).author(serverIdent).committer(serverIdent).create();
    notes = newNotes(c);
    assertThat(getToStringRepresentations(notes.getComments())).containsExactly(getRevId(notes, 1), ps1Comment1.toString(), getRevId(notes, 1), ps1Comment2.toString(), getRevId(notes, 2), ps2Comment1.toString());
    // Comments at each commit all have legacy format.
    ImmutableList<RevCommit> oldLog = log(project, RefNames.changeMetaRef(c.getId()));
    assertThat(oldLog).hasSize(4);
    assertThat(getLegacyFormatMapForPublishedComments(notes, oldLog.get(0))).isEmpty();
    assertThat(getLegacyFormatMapForPublishedComments(notes, oldLog.get(1))).isEmpty();
    assertThat(getLegacyFormatMapForPublishedComments(notes, oldLog.get(2))).containsExactly(ps1Comment1.key, true);
    assertThat(getLegacyFormatMapForPublishedComments(notes, oldLog.get(3))).containsExactly(ps1Comment1.key, true, ps1Comment2.key, true, ps2Comment1.key, true);
    ChangeNotes oldNotes = notes;
    checkMigrate(project, ImmutableList.of(RefNames.changeMetaRef(c.getId())));
    // Comment content is the same.
    notes = newNotes(c);
    assertNoDifferences(notes, oldNotes);
    assertThat(getToStringRepresentations(notes.getComments())).containsExactly(getRevId(notes, 1), ps1Comment1.toString(), getRevId(notes, 1), ps1Comment2.toString(), getRevId(notes, 2), ps2Comment1.toString());
    // Comments at each commit all have JSON format.
    ImmutableList<RevCommit> newLog = log(project, RefNames.changeMetaRef(c.getId()));
    assertLogEqualExceptTrees(newLog, oldLog);
    assertThat(getLegacyFormatMapForPublishedComments(notes, newLog.get(0))).isEmpty();
    assertThat(getLegacyFormatMapForPublishedComments(notes, newLog.get(1))).isEmpty();
    assertThat(getLegacyFormatMapForPublishedComments(notes, newLog.get(2))).containsExactly(ps1Comment1.key, false);
    assertThat(getLegacyFormatMapForPublishedComments(notes, newLog.get(3))).containsExactly(ps1Comment1.key, false, ps1Comment2.key, false, ps2Comment1.key, false);
}
#end_block

#method_before
@Test
public void migrateDraftComments() throws Exception {
    Change c = newChange();
    incrementPatchSet(c);
    ChangeNotes notes = newNotes(c);
    ObjectId origMetaId = notes.getMetaId();
    Comment ownerCommentPs1 = newComment(notes, 1, "owner comment on ps1", changeOwner);
    Comment ownerCommentPs2 = newComment(notes, 2, "owner comment on ps2", changeOwner);
    Comment otherCommentPs1 = newComment(notes, 1, "other user comment on ps1", otherUser);
    ByteArrayOutputStream out1 = new ByteArrayOutputStream(0);
    legacyChangeNoteWrite.buildNote(ImmutableListMultimap.<Integer, Comment>builder().put(1, ownerCommentPs1).build(), out1);
    ByteArrayOutputStream out2 = new ByteArrayOutputStream(0);
    legacyChangeNoteWrite.buildNote(ImmutableListMultimap.<Integer, Comment>builder().put(2, ownerCommentPs2).build(), out2);
    ByteArrayOutputStream out3 = new ByteArrayOutputStream(0);
    legacyChangeNoteWrite.buildNote(ImmutableListMultimap.<Integer, Comment>builder().put(1, otherCommentPs1).build(), out3);
    try (Repository allUsersRepo = repoManager.openRepository(allUsers);
        RevWalk allUsersRw = new RevWalk(allUsersRepo)) {
        TestRepository<Repository> testRepository = new TestRepository<>(allUsersRepo, allUsersRw);
        testRepository.branch(RefNames.refsDraftComments(c.getId(), changeOwner.getAccountId())).commit().message("Review ps 1\n\nPatch-set: 1").add(ownerCommentPs1.revId, out1.toString()).author(serverIdent).committer(serverIdent).create();
        testRepository.branch(RefNames.refsDraftComments(c.getId(), changeOwner.getAccountId())).commit().message("Review ps 1\n\nPatch-set: 2").add(ownerCommentPs2.revId, out2.toString()).author(serverIdent).committer(serverIdent).create();
        testRepository.branch(RefNames.refsDraftComments(c.getId(), otherUser.getAccountId())).commit().message("Review ps 2\n\nPatch-set: 2").add(otherCommentPs1.revId, out3.toString()).author(serverIdent).committer(serverIdent).create();
    }
    notes = newNotes(c);
    assertThat(getToStringRepresentations(notes.getDraftComments(changeOwner.getAccountId()))).containsExactly(getRevId(notes, 1), ownerCommentPs1.toString(), getRevId(notes, 2), ownerCommentPs2.toString());
    assertThat(getToStringRepresentations(notes.getDraftComments(otherUser.getAccountId()))).containsExactly(getRevId(notes, 1), otherCommentPs1.toString());
    // Comments at each commit all have legacy format.
    ImmutableList<RevCommit> oldOwnerLog = log(allUsers, RefNames.refsDraftComments(c.getId(), changeOwner.getAccountId()));
    assertThat(oldOwnerLog).hasSize(2);
    assertThat(getLegacyFormatMapForDraftComments(notes, oldOwnerLog.get(0))).containsExactly(ownerCommentPs1.key, true);
    assertThat(getLegacyFormatMapForDraftComments(notes, oldOwnerLog.get(1))).containsExactly(ownerCommentPs1.key, true, ownerCommentPs2.key, true);
    ImmutableList<RevCommit> oldOtherLog = log(allUsers, RefNames.refsDraftComments(c.getId(), otherUser.getAccountId()));
    assertThat(oldOtherLog).hasSize(1);
    assertThat(getLegacyFormatMapForDraftComments(notes, oldOtherLog.get(0))).containsExactly(otherCommentPs1.key, true);
    ChangeNotes oldNotes = notes;
    migrate(allUsers, 2);
    assertNoDifferences(notes, oldNotes);
    // Migration doesn't touch change ref.
    assertThat(repo.exactRef(RefNames.changeMetaRef(c.getId())).getObjectId()).isEqualTo(origMetaId);
    // Comment content is the same.
    notes = newNotes(c);
    assertThat(getToStringRepresentations(notes.getDraftComments(changeOwner.getAccountId()))).containsExactly(getRevId(notes, 1), ownerCommentPs1.toString(), getRevId(notes, 2), ownerCommentPs2.toString());
    assertThat(getToStringRepresentations(notes.getDraftComments(otherUser.getAccountId()))).containsExactly(getRevId(notes, 1), otherCommentPs1.toString());
    // Comments at each commit all have JSON format.
    ImmutableList<RevCommit> newOwnerLog = log(allUsers, RefNames.refsDraftComments(c.getId(), changeOwner.getAccountId()));
    assertLogEqualExceptTrees(newOwnerLog, oldOwnerLog);
    assertThat(getLegacyFormatMapForDraftComments(notes, newOwnerLog.get(0))).containsExactly(ownerCommentPs1.key, false);
    assertThat(getLegacyFormatMapForDraftComments(notes, newOwnerLog.get(1))).containsExactly(ownerCommentPs1.key, false, ownerCommentPs2.key, false);
    ImmutableList<RevCommit> newOtherLog = log(allUsers, RefNames.refsDraftComments(c.getId(), otherUser.getAccountId()));
    assertLogEqualExceptTrees(newOtherLog, oldOtherLog);
    assertThat(getLegacyFormatMapForDraftComments(notes, newOtherLog.get(0))).containsExactly(otherCommentPs1.key, false);
}
#method_after
@Test
public void migrateDraftComments() throws Exception {
    Change c = newChange();
    incrementPatchSet(c);
    ChangeNotes notes = newNotes(c);
    ObjectId origMetaId = notes.getMetaId();
    Comment ownerCommentPs1 = newComment(notes, 1, "owner comment on ps1", changeOwner);
    Comment ownerCommentPs2 = newComment(notes, 2, "owner comment on ps2", changeOwner);
    Comment otherCommentPs1 = newComment(notes, 1, "other user comment on ps1", otherUser);
    ByteArrayOutputStream out1 = new ByteArrayOutputStream(0);
    legacyChangeNoteWrite.buildNote(ImmutableListMultimap.<Integer, Comment>builder().put(1, ownerCommentPs1).build(), out1);
    ByteArrayOutputStream out2 = new ByteArrayOutputStream(0);
    legacyChangeNoteWrite.buildNote(ImmutableListMultimap.<Integer, Comment>builder().put(2, ownerCommentPs2).build(), out2);
    ByteArrayOutputStream out3 = new ByteArrayOutputStream(0);
    legacyChangeNoteWrite.buildNote(ImmutableListMultimap.<Integer, Comment>builder().put(1, otherCommentPs1).build(), out3);
    try (Repository allUsersRepo = repoManager.openRepository(allUsers);
        RevWalk allUsersRw = new RevWalk(allUsersRepo)) {
        TestRepository<Repository> testRepository = new TestRepository<>(allUsersRepo, allUsersRw);
        testRepository.branch(RefNames.refsDraftComments(c.getId(), changeOwner.getAccountId())).commit().message("Review ps 1\n\nPatch-set: 1").add(ownerCommentPs1.revId, out1.toString()).author(serverIdent).committer(serverIdent).create();
        testRepository.branch(RefNames.refsDraftComments(c.getId(), changeOwner.getAccountId())).commit().message("Review ps 1\n\nPatch-set: 2").add(ownerCommentPs2.revId, out2.toString()).author(serverIdent).committer(serverIdent).create();
        testRepository.branch(RefNames.refsDraftComments(c.getId(), otherUser.getAccountId())).commit().message("Review ps 2\n\nPatch-set: 2").add(otherCommentPs1.revId, out3.toString()).author(serverIdent).committer(serverIdent).create();
    }
    notes = newNotes(c);
    assertThat(getToStringRepresentations(notes.getDraftComments(changeOwner.getAccountId()))).containsExactly(getRevId(notes, 1), ownerCommentPs1.toString(), getRevId(notes, 2), ownerCommentPs2.toString());
    assertThat(getToStringRepresentations(notes.getDraftComments(otherUser.getAccountId()))).containsExactly(getRevId(notes, 1), otherCommentPs1.toString());
    // Comments at each commit all have legacy format.
    ImmutableList<RevCommit> oldOwnerLog = log(allUsers, RefNames.refsDraftComments(c.getId(), changeOwner.getAccountId()));
    assertThat(oldOwnerLog).hasSize(2);
    assertThat(getLegacyFormatMapForDraftComments(notes, oldOwnerLog.get(0))).containsExactly(ownerCommentPs1.key, true);
    assertThat(getLegacyFormatMapForDraftComments(notes, oldOwnerLog.get(1))).containsExactly(ownerCommentPs1.key, true, ownerCommentPs2.key, true);
    ImmutableList<RevCommit> oldOtherLog = log(allUsers, RefNames.refsDraftComments(c.getId(), otherUser.getAccountId()));
    assertThat(oldOtherLog).hasSize(1);
    assertThat(getLegacyFormatMapForDraftComments(notes, oldOtherLog.get(0))).containsExactly(otherCommentPs1.key, true);
    ChangeNotes oldNotes = notes;
    checkMigrate(allUsers, ImmutableList.of(RefNames.refsDraftComments(c.getId(), changeOwner.getAccountId()), RefNames.refsDraftComments(c.getId(), otherUser.getAccountId())));
    assertNoDifferences(notes, oldNotes);
    // Migration doesn't touch change ref.
    assertThat(repo.exactRef(RefNames.changeMetaRef(c.getId())).getObjectId()).isEqualTo(origMetaId);
    // Comment content is the same.
    notes = newNotes(c);
    assertThat(getToStringRepresentations(notes.getDraftComments(changeOwner.getAccountId()))).containsExactly(getRevId(notes, 1), ownerCommentPs1.toString(), getRevId(notes, 2), ownerCommentPs2.toString());
    assertThat(getToStringRepresentations(notes.getDraftComments(otherUser.getAccountId()))).containsExactly(getRevId(notes, 1), otherCommentPs1.toString());
    // Comments at each commit all have JSON format.
    ImmutableList<RevCommit> newOwnerLog = log(allUsers, RefNames.refsDraftComments(c.getId(), changeOwner.getAccountId()));
    assertLogEqualExceptTrees(newOwnerLog, oldOwnerLog);
    assertThat(getLegacyFormatMapForDraftComments(notes, newOwnerLog.get(0))).containsExactly(ownerCommentPs1.key, false);
    assertThat(getLegacyFormatMapForDraftComments(notes, newOwnerLog.get(1))).containsExactly(ownerCommentPs1.key, false, ownerCommentPs2.key, false);
    ImmutableList<RevCommit> newOtherLog = log(allUsers, RefNames.refsDraftComments(c.getId(), otherUser.getAccountId()));
    assertLogEqualExceptTrees(newOtherLog, oldOtherLog);
    assertThat(getLegacyFormatMapForDraftComments(notes, newOtherLog.get(0))).containsExactly(otherCommentPs1.key, false);
}
#end_block

#method_before
@Test
public void migrateMixOfJsonAndLegacyComments() throws Exception {
    // 3 comments: legacy, JSON, legacy. Because adding a comment necessarily rewrites the entire
    // note, these comments need to be on separate patch sets.
    Change c = newChange();
    incrementPatchSet(c);
    incrementPatchSet(c);
    ChangeNotes notes = newNotes(c);
    Comment ps1Comment = newComment(notes, 1, "comment on ps1 (legacy)");
    ByteArrayOutputStream out1 = new ByteArrayOutputStream(0);
    legacyChangeNoteWrite.buildNote(ImmutableListMultimap.<Integer, Comment>builder().put(1, ps1Comment).build(), out1);
    TestRepository<Repository> testRepository = new TestRepository<>(repo, rw);
    String metaRefName = RefNames.changeMetaRef(c.getId());
    testRepository.branch(metaRefName).commit().message("Review ps 1\n\nPatch-set: 1").add(ps1Comment.revId, out1.toString()).author(serverIdent).committer(serverIdent).create();
    notes = newNotes(c);
    ChangeUpdate update = newUpdate(c, changeOwner);
    Comment ps2Comment = newComment(notes, 2, "comment on ps2 (JSON)");
    update.putComment(Status.PUBLISHED, ps2Comment);
    update.commit();
    Comment ps3Comment = newComment(notes, 3, "comment on ps3 (legacy)");
    ByteArrayOutputStream out3 = new ByteArrayOutputStream(0);
    legacyChangeNoteWrite.buildNote(ImmutableListMultimap.<Integer, Comment>builder().put(3, ps3Comment).build(), out3);
    testRepository.branch(metaRefName).commit().message("Review ps 3\n\nPatch-set: 3").add(ps3Comment.revId, out3.toString()).author(serverIdent).committer(serverIdent).create();
    notes = newNotes(c);
    assertThat(getToStringRepresentations(notes.getComments())).containsExactly(getRevId(notes, 1), ps1Comment.toString(), getRevId(notes, 2), ps2Comment.toString(), getRevId(notes, 3), ps3Comment.toString());
    // Comments at each commit match expected format.
    ImmutableList<RevCommit> oldLog = log(project, RefNames.changeMetaRef(c.getId()));
    assertThat(oldLog).hasSize(6);
    assertThat(getLegacyFormatMapForPublishedComments(notes, oldLog.get(0))).isEmpty();
    assertThat(getLegacyFormatMapForPublishedComments(notes, oldLog.get(1))).isEmpty();
    assertThat(getLegacyFormatMapForPublishedComments(notes, oldLog.get(2))).isEmpty();
    assertThat(getLegacyFormatMapForPublishedComments(notes, oldLog.get(3))).containsExactly(ps1Comment.key, true);
    assertThat(getLegacyFormatMapForPublishedComments(notes, oldLog.get(4))).containsExactly(ps1Comment.key, true, ps2Comment.key, false);
    assertThat(getLegacyFormatMapForPublishedComments(notes, oldLog.get(5))).containsExactly(ps1Comment.key, true, ps2Comment.key, false, ps3Comment.key, true);
    ChangeNotes oldNotes = notes;
    migrate(project, 1);
    assertNoDifferences(notes, oldNotes);
    // Comment content is the same.
    notes = newNotes(c);
    assertThat(getToStringRepresentations(notes.getComments())).containsExactly(getRevId(notes, 1), ps1Comment.toString(), getRevId(notes, 2), ps2Comment.toString(), getRevId(notes, 3), ps3Comment.toString());
    // Comments at each commit all have JSON format.
    ImmutableList<RevCommit> newLog = log(project, RefNames.changeMetaRef(c.getId()));
    assertLogEqualExceptTrees(newLog, oldLog);
    assertThat(getLegacyFormatMapForPublishedComments(notes, newLog.get(0))).isEmpty();
    assertThat(getLegacyFormatMapForPublishedComments(notes, newLog.get(1))).isEmpty();
    assertThat(getLegacyFormatMapForPublishedComments(notes, newLog.get(2))).isEmpty();
    assertThat(getLegacyFormatMapForPublishedComments(notes, newLog.get(3))).containsExactly(ps1Comment.key, false);
    assertThat(getLegacyFormatMapForPublishedComments(notes, newLog.get(4))).containsExactly(ps1Comment.key, false, ps2Comment.key, false);
    assertThat(getLegacyFormatMapForPublishedComments(notes, newLog.get(5))).containsExactly(ps1Comment.key, false, ps2Comment.key, false, ps3Comment.key, false);
}
#method_after
@Test
public void migrateMixOfJsonAndLegacyComments() throws Exception {
    // 3 comments: legacy, JSON, legacy. Because adding a comment necessarily rewrites the entire
    // note, these comments need to be on separate patch sets.
    Change c = newChange();
    incrementPatchSet(c);
    incrementPatchSet(c);
    ChangeNotes notes = newNotes(c);
    Comment ps1Comment = newComment(notes, 1, "comment on ps1 (legacy)");
    ByteArrayOutputStream out1 = new ByteArrayOutputStream(0);
    legacyChangeNoteWrite.buildNote(ImmutableListMultimap.<Integer, Comment>builder().put(1, ps1Comment).build(), out1);
    TestRepository<Repository> testRepository = new TestRepository<>(repo, rw);
    String metaRefName = RefNames.changeMetaRef(c.getId());
    testRepository.branch(metaRefName).commit().message("Review ps 1\n\nPatch-set: 1").add(ps1Comment.revId, out1.toString()).author(serverIdent).committer(serverIdent).create();
    notes = newNotes(c);
    ChangeUpdate update = newUpdate(c, changeOwner);
    Comment ps2Comment = newComment(notes, 2, "comment on ps2 (JSON)");
    update.putComment(Status.PUBLISHED, ps2Comment);
    update.commit();
    Comment ps3Comment = newComment(notes, 3, "comment on ps3 (legacy)");
    ByteArrayOutputStream out3 = new ByteArrayOutputStream(0);
    legacyChangeNoteWrite.buildNote(ImmutableListMultimap.<Integer, Comment>builder().put(3, ps3Comment).build(), out3);
    testRepository.branch(metaRefName).commit().message("Review ps 3\n\nPatch-set: 3").add(ps3Comment.revId, out3.toString()).author(serverIdent).committer(serverIdent).create();
    notes = newNotes(c);
    assertThat(getToStringRepresentations(notes.getComments())).containsExactly(getRevId(notes, 1), ps1Comment.toString(), getRevId(notes, 2), ps2Comment.toString(), getRevId(notes, 3), ps3Comment.toString());
    // Comments at each commit match expected format.
    ImmutableList<RevCommit> oldLog = log(project, RefNames.changeMetaRef(c.getId()));
    assertThat(oldLog).hasSize(6);
    assertThat(getLegacyFormatMapForPublishedComments(notes, oldLog.get(0))).isEmpty();
    assertThat(getLegacyFormatMapForPublishedComments(notes, oldLog.get(1))).isEmpty();
    assertThat(getLegacyFormatMapForPublishedComments(notes, oldLog.get(2))).isEmpty();
    assertThat(getLegacyFormatMapForPublishedComments(notes, oldLog.get(3))).containsExactly(ps1Comment.key, true);
    assertThat(getLegacyFormatMapForPublishedComments(notes, oldLog.get(4))).containsExactly(ps1Comment.key, true, ps2Comment.key, false);
    assertThat(getLegacyFormatMapForPublishedComments(notes, oldLog.get(5))).containsExactly(ps1Comment.key, true, ps2Comment.key, false, ps3Comment.key, true);
    ChangeNotes oldNotes = notes;
    checkMigrate(project, ImmutableList.of(RefNames.changeMetaRef(c.getId())));
    assertNoDifferences(notes, oldNotes);
    // Comment content is the same.
    notes = newNotes(c);
    assertThat(getToStringRepresentations(notes.getComments())).containsExactly(getRevId(notes, 1), ps1Comment.toString(), getRevId(notes, 2), ps2Comment.toString(), getRevId(notes, 3), ps3Comment.toString());
    // Comments at each commit all have JSON format.
    ImmutableList<RevCommit> newLog = log(project, RefNames.changeMetaRef(c.getId()));
    assertLogEqualExceptTrees(newLog, oldLog);
    assertThat(getLegacyFormatMapForPublishedComments(notes, newLog.get(0))).isEmpty();
    assertThat(getLegacyFormatMapForPublishedComments(notes, newLog.get(1))).isEmpty();
    assertThat(getLegacyFormatMapForPublishedComments(notes, newLog.get(2))).isEmpty();
    assertThat(getLegacyFormatMapForPublishedComments(notes, newLog.get(3))).containsExactly(ps1Comment.key, false);
    assertThat(getLegacyFormatMapForPublishedComments(notes, newLog.get(4))).containsExactly(ps1Comment.key, false, ps2Comment.key, false);
    assertThat(getLegacyFormatMapForPublishedComments(notes, newLog.get(5))).containsExactly(ps1Comment.key, false, ps2Comment.key, false, ps3Comment.key, false);
}
#end_block

#method_before
public ProjectMigrationResult migrateProject(Project.NameKey project, Repository repo, boolean dryRun) {
    ProjectMigrationResult progress = new ProjectMigrationResult();
    progress.ok = true;
    progress.refsUpdated = ImmutableList.of();
    try (RevWalk rw = new RevWalk(repo);
        ObjectInserter ins = newPackInserter(repo)) {
        BatchRefUpdate bru = repo.getRefDatabase().newBatchUpdate();
        bru.setAllowNonFastForwards(true);
        progress.ok &= migrateChanges(project, repo, rw, ins, bru);
        if (project.equals(allUsers)) {
            progress.ok &= migrateDrafts(allUsers, repo, rw, ins, bru);
        }
        progress.refsUpdated = bru.getCommands().stream().map(c -> c.getRefName()).collect(toList());
        if (!bru.getCommands().isEmpty()) {
            if (!dryRun) {
                ins.flush();
                RefUpdateUtil.executeChecked(bru, rw);
            }
        } else {
            progress.skipped++;
        }
    } catch (IOException e) {
        progress.ok = false;
    }
    return progress;
}
#method_after
public ProjectMigrationResult migrateProject(Project.NameKey project, Repository repo, boolean dryRun) {
    ProjectMigrationResult progress = new ProjectMigrationResult();
    progress.ok = true;
    progress.skipped = 0;
    progress.refsUpdated = ImmutableList.of();
    try (RevWalk rw = new RevWalk(repo);
        ObjectInserter ins = newPackInserter(repo)) {
        BatchRefUpdate bru = repo.getRefDatabase().newBatchUpdate();
        bru.setAllowNonFastForwards(true);
        progress.ok &= migrateChanges(project, repo, rw, ins, bru);
        if (project.equals(allUsers)) {
            progress.ok &= migrateDrafts(allUsers, repo, rw, ins, bru);
        }
        progress.refsUpdated = bru.getCommands().stream().map(c -> c.getRefName()).collect(toImmutableList());
        if (!bru.getCommands().isEmpty()) {
            if (!dryRun) {
                ins.flush();
                RefUpdateUtil.executeChecked(bru, rw);
            }
        } else {
            progress.skipped++;
        }
    } catch (IOException e) {
        progress.ok = false;
    }
    return progress;
}
#end_block

#method_before
@Test
public void getAndSetUuid() {
    AccountGroup.UUID uuid = new AccountGroup.UUID("uuid-foo");
    String name = "foo";
    GroupReference groupReference = new GroupReference(uuid, name);
    assertThat(groupReference.getUUID()).isEqualTo(uuid);
    AccountGroup.UUID uuid2 = new AccountGroup.UUID("uuid-bar");
    groupReference.setUUID(uuid2);
    assertThat(groupReference.getUUID()).isEqualTo(uuid2);
    exception.expect(NullPointerException.class);
    groupReference.setUUID(null);
}
#method_after
@Test
public void getAndSetUuid() {
    AccountGroup.UUID uuid = new AccountGroup.UUID("uuid-foo");
    String name = "foo";
    GroupReference groupReference = new GroupReference(uuid, name);
    assertThat(groupReference.getUUID()).isEqualTo(uuid);
    AccountGroup.UUID uuid2 = new AccountGroup.UUID("uuid-bar");
    groupReference.setUUID(uuid2);
    assertThat(groupReference.getUUID()).isEqualTo(uuid2);
    // GroupReferences where the UUID is null are used to represent groups from project.config that
    // cannot be resolved.
    groupReference.setUUID(null);
    assertThat(groupReference.getUUID()).isNull();
}
#end_block

#method_before
public AccountGroup.UUID getUUID() {
    return new AccountGroup.UUID(uuid);
}
#method_after
public AccountGroup.UUID getUUID() {
    return uuid != null ? new AccountGroup.UUID(uuid) : null;
}
#end_block

#method_before
public void setUUID(AccountGroup.UUID newUUID) {
    uuid = checkNotNull(newUUID).get();
}
#method_after
public void setUUID(AccountGroup.UUID newUUID) {
    uuid = newUUID != null ? newUUID.get() : null;
}
#end_block

#method_before
public void setName(String newName) {
    this.name = checkNotNull(newName);
}
#method_after
public void setName(String newName) {
    if (newName == null) {
        throw new NullPointerException();
    }
    this.name = newName;
}
#end_block

#method_before
public boolean isStale(Project.NameKey project) throws IOException {
    ProjectData projectData = projectCache.get(project).toProjectData();
    ProjectIndex i = indexes.getSearchIndex();
    if (i == null) {
        // No index; caller couldn't do anything if it is stale.
        return false;
    }
    Optional<FieldBundle> result = i.getRaw(project, QueryOptions.create(indexConfig, 0, 1, FIELDS));
    if (!result.isPresent()) {
        return true;
    }
    return isStale(projectData, RefState.parseStates(result.get().getValue(ProjectField.REF_STATE)));
}
#method_after
public boolean isStale(Project.NameKey project) throws IOException {
    ProjectData projectData = projectCache.get(project).toProjectData();
    ProjectIndex i = indexes.getSearchIndex();
    if (i == null) {
        // No index; caller couldn't do anything if it is stale.
        return false;
    }
    Optional<FieldBundle> result = i.getRaw(project, QueryOptions.create(indexConfig, 0, 1, FIELDS));
    if (!result.isPresent()) {
        return true;
    }
    SetMultimap<Project.NameKey, RefState> indexedRefStates = RefState.parseStates(result.get().getValue(ProjectField.REF_STATE));
    SetMultimap<Project.NameKey, RefState> currentRefStates = MultimapBuilder.hashKeys().hashSetValues().build();
    projectData.tree().stream().filter(p -> p.getProject().getConfigRefState() != null).forEach(p -> currentRefStates.put(p.getProject().getNameKey(), RefState.create(RefNames.REFS_CONFIG, p.getProject().getConfigRefState())));
    return !currentRefStates.equals(indexedRefStates);
}
#end_block

#method_before
@Test
public void stalenessChecker_hierarchyChange_isStale() throws Exception {
    updateProjectConfigWithoutIndexUpdate(allProjects, c -> c.getProject().setParentName(allUsers));
    assertThat(stalenessChecker.isStale(project)).isTrue();
}
#method_after
@Test
public void stalenessChecker_hierarchyChange_isStale() throws Exception {
    Project.NameKey p1 = createProject("p1", allProjects);
    Project.NameKey p2 = createProject("p2", allProjects);
    try (ProjectConfigUpdate u = updateProject(project)) {
        u.getConfig().getProject().setParentName(p1);
        u.save();
    }
    assertThat(stalenessChecker.isStale(project)).isFalse();
    updateProjectConfigWithoutIndexUpdate(p1, c -> c.getProject().setParentName(p2));
    assertThat(stalenessChecker.isStale(project)).isTrue();
}
#end_block

#method_before
protected void beforeTest(Description description) throws Exception {
    this.description = description;
    GerritServer.Description classDesc = GerritServer.Description.forTestClass(description, configName);
    GerritServer.Description methodDesc = GerritServer.Description.forTestMethod(description, configName);
    testRequiresSsh = classDesc.useSshAnnotation() || methodDesc.useSshAnnotation();
    if (!testRequiresSsh) {
        baseConfig.setString("sshd", null, "listenAddress", "off");
    }
    baseConfig.setInt("receive", null, "changeUpdateThreads", 4);
    Module module = createModule();
    if (classDesc.equals(methodDesc) && !classDesc.sandboxed() && !methodDesc.sandboxed()) {
        if (commonServer == null) {
            commonServer = GerritServer.initAndStart(classDesc, baseConfig, module);
        }
        server = commonServer;
    } else {
        server = GerritServer.initAndStart(methodDesc, baseConfig, module);
    }
    server.getTestInjector().injectMembers(this);
    Transport.register(inProcessProtocol);
    toClose = Collections.synchronizedList(new ArrayList<Repository>());
    db = reviewDbProvider.open();
    // All groups which were added during the server start (e.g. in SchemaCreator) aren't contained
    // in the instance of the group index which is available here and in tests. There are two
    // reasons:
    // 1) No group index is available in SchemaCreator when using an in-memory database. (This could
    // be fixed by using the IndexManagerOnInit in InMemoryDatabase similar as BaseInit uses it.)
    // 2) During the on-init part of the server start, we use another instance of the index than
    // later on. As test indexes are non-permanent, closing an instance and opening another one
    // removes all indexed data.
    // As a workaround, we simply reindex all available groups here.
    reindexAllGroups();
    admin = accountCreator.admin();
    user = accountCreator.user();
    // Evict and reindex accounts in case tests modify them.
    evictAndReindexAccount(admin.getId());
    evictAndReindexAccount(user.getId());
    adminRestSession = new RestSession(server, admin);
    userRestSession = new RestSession(server, user);
    initSsh();
    resourcePrefix = UNSAFE_PROJECT_NAME.matcher(description.getClassName() + "_" + description.getMethodName() + "_").replaceAll("");
    Context ctx = newRequestContext(admin);
    atrScope.set(ctx);
    ProjectInput in = projectInput(description);
    gApi.projects().create(in);
    project = new Project.NameKey(in.name);
    testRepo = cloneProject(project, getCloneAsAccount(description));
}
#method_after
protected void beforeTest(Description description) throws Exception {
    this.description = description;
    GerritServer.Description classDesc = GerritServer.Description.forTestClass(description, configName);
    GerritServer.Description methodDesc = GerritServer.Description.forTestMethod(description, configName);
    testRequiresSsh = classDesc.useSshAnnotation() || methodDesc.useSshAnnotation();
    if (!testRequiresSsh) {
        baseConfig.setString("sshd", null, "listenAddress", "off");
    }
    baseConfig.setInt("index", null, "batchThreads", -1);
    baseConfig.setInt("receive", null, "changeUpdateThreads", 4);
    Module module = createModule();
    if (classDesc.equals(methodDesc) && !classDesc.sandboxed() && !methodDesc.sandboxed()) {
        if (commonServer == null) {
            commonServer = GerritServer.initAndStart(classDesc, baseConfig, module);
        }
        server = commonServer;
    } else {
        server = GerritServer.initAndStart(methodDesc, baseConfig, module);
    }
    server.getTestInjector().injectMembers(this);
    Transport.register(inProcessProtocol);
    toClose = Collections.synchronizedList(new ArrayList<Repository>());
    db = reviewDbProvider.open();
    // All groups which were added during the server start (e.g. in SchemaCreator) aren't contained
    // in the instance of the group index which is available here and in tests. There are two
    // reasons:
    // 1) No group index is available in SchemaCreator when using an in-memory database. (This could
    // be fixed by using the IndexManagerOnInit in InMemoryDatabase similar as BaseInit uses it.)
    // 2) During the on-init part of the server start, we use another instance of the index than
    // later on. As test indexes are non-permanent, closing an instance and opening another one
    // removes all indexed data.
    // As a workaround, we simply reindex all available groups here.
    reindexAllGroups();
    admin = accountCreator.admin();
    user = accountCreator.user();
    // Evict and reindex accounts in case tests modify them.
    evictAndReindexAccount(admin.getId());
    evictAndReindexAccount(user.getId());
    adminRestSession = new RestSession(server, admin);
    userRestSession = new RestSession(server, user);
    initSsh();
    resourcePrefix = UNSAFE_PROJECT_NAME.matcher(description.getClassName() + "_" + description.getMethodName() + "_").replaceAll("");
    Context ctx = newRequestContext(admin);
    atrScope.set(ctx);
    ProjectInput in = projectInput(description);
    gApi.projects().create(in);
    project = new Project.NameKey(in.name);
    testRepo = cloneProject(project, getCloneAsAccount(description));
}
#end_block

#method_before
protected AutoCloseable disableProjectIndex() {
    ProjectIndex searchIndex = projectIndexes.getSearchIndex();
    if (!(searchIndex instanceof DisabledProjectIndex)) {
        projectIndexes.setSearchIndex(new DisabledProjectIndex(searchIndex), false);
        disableProjectIndexWrites();
    }
    return new AutoCloseable() {

        @Override
        public void close() {
            ProjectIndex searchIndex = projectIndexes.getSearchIndex();
            if (searchIndex instanceof DisabledProjectIndex) {
                projectIndexes.setSearchIndex(((DisabledProjectIndex) searchIndex).unwrap(), false);
                enableProjectIndexWrites();
            }
        }
    };
}
#method_after
protected AutoCloseable disableProjectIndex() {
    disableProjectIndexWrites();
    ProjectIndex searchIndex = projectIndexes.getSearchIndex();
    if (!(searchIndex instanceof DisabledProjectIndex)) {
        projectIndexes.setSearchIndex(new DisabledProjectIndex(searchIndex), false);
    }
    return new AutoCloseable() {

        @Override
        public void close() {
            enableProjectIndexWrites();
            ProjectIndex searchIndex = projectIndexes.getSearchIndex();
            if (searchIndex instanceof DisabledProjectIndex) {
                projectIndexes.setSearchIndex(((DisabledProjectIndex) searchIndex).unwrap(), false);
            }
        }
    };
}
#end_block

#method_before
protected void removePermission(Project.NameKey project, String ref, String permission) throws IOException, ConfigInvalidException {
    try (MetaDataUpdate md = metaDataUpdateFactory.create(project)) {
        md.setMessage(String.format("Remove %s on %s", permission, ref));
        ProjectConfig config = ProjectConfig.read(md);
        AccessSection s = config.getAccessSection(ref, true);
        Permission p = s.getPermission(permission, true);
        p.getRules().clear();
        config.commit(md);
        projectCache.evict(config.getProject());
    }
}
#method_after
protected void removePermission(Project.NameKey project, String ref, String permission) throws IOException, ConfigInvalidException {
    try (MetaDataUpdate md = metaDataUpdateFactory.create(project)) {
        md.setMessage(String.format("Remove %s on %s", permission, ref));
        ProjectConfig config = ProjectConfig.read(md);
        AccessSection s = config.getAccessSection(ref, true);
        Permission p = s.getPermission(permission, true);
        p.clearRules();
        config.commit(md);
        projectCache.evict(config.getProject());
    }
}
#end_block

#method_before
@Override
public synchronized void handleEmails(boolean async) throws MailTransferException, IOException {
    IMAPClient imap;
    if (mailSettings.encryption != Encryption.NONE) {
        imap = new IMAPSClient(mailSettings.encryption.name(), true);
    } else {
        imap = new IMAPClient();
    }
    if (mailSettings.port > 0) {
        imap.setDefaultPort(mailSettings.port);
    }
    // Set a 30s timeout for each operation
    imap.setDefaultTimeout(30 * 1000);
    imap.connect(mailSettings.host);
    try {
        if (!imap.login(mailSettings.username, mailSettings.password)) {
            throw new MailTransferException("Could not login to IMAP server");
        }
        try {
            if (!imap.select(INBOX_FOLDER)) {
                throw new MailTransferException("Could not select IMAP folder " + INBOX_FOLDER);
            }
            // should fetch.
            if (!imap.fetch("1:*", "(INTERNALDATE)")) {
                // false indicates that there are no messages to fetch
                log.info("Fetched 0 messages via IMAP");
                return;
            }
            // Format of reply is one line per email and one line to indicate
            // that the fetch was successful.
            // Example:
            // * 1 FETCH (INTERNALDATE "Mon, 24 Oct 2016 16:53:22 +0200 (CEST)")
            // * 2 FETCH (INTERNALDATE "Mon, 24 Oct 2016 16:53:22 +0200 (CEST)")
            // AAAC OK FETCH completed.
            int numMessages = imap.getReplyStrings().length - 1;
            log.info("Fetched " + numMessages + " messages via IMAP");
            // Fetch the full version of all emails
            List<MailMessage> mailMessages = new ArrayList<>(numMessages);
            for (int i = 1; i <= numMessages; i++) {
                if (imap.fetch(i + ":" + i, "(BODY.PEEK[])")) {
                    // Obtain full reply
                    String[] rawMessage = imap.getReplyStrings();
                    if (rawMessage.length < 2) {
                        continue;
                    }
                    // First and last line are IMAP status codes. We have already
                    // checked, that the fetch returned true (OK), so we safely ignore
                    // those two lines.
                    StringBuilder b = new StringBuilder(2 * (rawMessage.length - 2));
                    for (int j = 1; j < rawMessage.length - 1; j++) {
                        if (j > 1) {
                            b.append("\n");
                        }
                        b.append(rawMessage[j]);
                    }
                    try {
                        MailMessage mailMessage = RawMailParser.parse(b.toString());
                        if (pendingDeletion.contains(mailMessage.id())) {
                            // Mark message as deleted
                            if (imap.store(i + ":" + i, "+FLAGS", "(\\Deleted)")) {
                                pendingDeletion.remove(mailMessage.id());
                            } else {
                                log.error("Could not mark mail message as deleted: " + mailMessage.id());
                            }
                        } else {
                            mailMessages.add(mailMessage);
                        }
                    } catch (MailParsingException e) {
                        log.error("Exception while parsing email after IMAP fetch", e);
                    }
                } else {
                    log.error("IMAP fetch failed. Will retry in next fetch cycle.");
                }
            }
            // Permanently delete emails marked for deletion
            if (!imap.expunge()) {
                log.error("Could not expunge IMAP emails");
            }
            dispatchMailProcessor(mailMessages, async);
        } finally {
            imap.logout();
        }
    } finally {
        imap.disconnect();
    }
}
#method_after
@Override
public synchronized void handleEmails(boolean async) throws MailTransferException, IOException {
    IMAPClient imap;
    if (mailSettings.encryption != Encryption.NONE) {
        imap = new IMAPSClient(mailSettings.encryption.name(), true);
    } else {
        imap = new IMAPClient();
    }
    if (mailSettings.port > 0) {
        imap.setDefaultPort(mailSettings.port);
    }
    // Set a 30s timeout for each operation
    imap.setDefaultTimeout(30 * 1000);
    imap.connect(mailSettings.host);
    try {
        if (!imap.login(mailSettings.username, mailSettings.password)) {
            throw new MailTransferException("Could not login to IMAP server");
        }
        try {
            if (!imap.select(INBOX_FOLDER)) {
                throw new MailTransferException("Could not select IMAP folder " + INBOX_FOLDER);
            }
            // should fetch.
            if (!imap.fetch("1:*", "(INTERNALDATE)")) {
                // false indicates that there are no messages to fetch
                logger.atInfo().log("Fetched 0 messages via IMAP");
                return;
            }
            // Format of reply is one line per email and one line to indicate
            // that the fetch was successful.
            // Example:
            // * 1 FETCH (INTERNALDATE "Mon, 24 Oct 2016 16:53:22 +0200 (CEST)")
            // * 2 FETCH (INTERNALDATE "Mon, 24 Oct 2016 16:53:22 +0200 (CEST)")
            // AAAC OK FETCH completed.
            int numMessages = imap.getReplyStrings().length - 1;
            logger.atInfo().log("Fetched %d messages via IMAP", numMessages);
            // Fetch the full version of all emails
            List<MailMessage> mailMessages = new ArrayList<>(numMessages);
            for (int i = 1; i <= numMessages; i++) {
                if (imap.fetch(i + ":" + i, "(BODY.PEEK[])")) {
                    // Obtain full reply
                    String[] rawMessage = imap.getReplyStrings();
                    if (rawMessage.length < 2) {
                        continue;
                    }
                    // First and last line are IMAP status codes. We have already
                    // checked, that the fetch returned true (OK), so we safely ignore
                    // those two lines.
                    StringBuilder b = new StringBuilder(2 * (rawMessage.length - 2));
                    for (int j = 1; j < rawMessage.length - 1; j++) {
                        if (j > 1) {
                            b.append("\n");
                        }
                        b.append(rawMessage[j]);
                    }
                    try {
                        MailMessage mailMessage = RawMailParser.parse(b.toString());
                        if (pendingDeletion.contains(mailMessage.id())) {
                            // Mark message as deleted
                            if (imap.store(i + ":" + i, "+FLAGS", "(\\Deleted)")) {
                                pendingDeletion.remove(mailMessage.id());
                            } else {
                                logger.atSevere().log("Could not mark mail message as deleted: %s", mailMessage.id());
                            }
                        } else {
                            mailMessages.add(mailMessage);
                        }
                    } catch (MailParsingException e) {
                        logger.atSevere().withCause(e).log("Exception while parsing email after IMAP fetch");
                    }
                } else {
                    logger.atSevere().log("IMAP fetch failed. Will retry in next fetch cycle.");
                }
            }
            // Permanently delete emails marked for deletion
            if (!imap.expunge()) {
                logger.atSevere().log("Could not expunge IMAP emails");
            }
            dispatchMailProcessor(mailMessages, async);
        } finally {
            imap.logout();
        }
    } finally {
        imap.disconnect();
    }
}
#end_block

#method_before
private void processImpl(BatchUpdate.Factory buf, MailMessage message) throws OrmException, UpdateException, RestApiException, IOException {
    for (DynamicMap.Entry<MailFilter> filter : mailFilters) {
        if (!filter.getProvider().get().shouldProcessMessage(message)) {
            log.warn(String.format("Message %s filtered by plugin %s %s. Will delete message.", message.id(), filter.getPluginName(), filter.getExportName()));
            return;
        }
    }
    MailMetadata metadata = MetadataParser.parse(message);
    if (!metadata.hasRequiredFields()) {
        log.error(String.format("Message %s is missing required metadata, have %s. Will delete message.", message.id(), metadata));
        return;
    }
    Set<Account.Id> accountIds = emails.getAccountFor(metadata.author);
    if (accountIds.size() != 1) {
        log.error(String.format("Address %s could not be matched to a unique account. It was matched to %s. Will delete message.", metadata.author, accountIds));
        return;
    }
    Account.Id account = accountIds.iterator().next();
    if (!accountCache.get(account).getAccount().isActive()) {
        log.warn(String.format("Mail: Account %s is inactive. Will delete message.", account));
        return;
    }
    persistComments(buf, message, metadata, account);
}
#method_after
private void processImpl(BatchUpdate.Factory buf, MailMessage message) throws OrmException, UpdateException, RestApiException, IOException {
    for (DynamicMap.Entry<MailFilter> filter : mailFilters) {
        if (!filter.getProvider().get().shouldProcessMessage(message)) {
            logger.atWarning().log("Message %s filtered by plugin %s %s. Will delete message.", message.id(), filter.getPluginName(), filter.getExportName());
            return;
        }
    }
    MailMetadata metadata = MailHeaderParser.parse(message);
    if (!metadata.hasRequiredFields()) {
        logger.atSevere().log("Message %s is missing required metadata, have %s. Will delete message.", message.id(), metadata);
        sendRejectionEmail(message, InboundEmailRejectionSender.Error.PARSING_ERROR);
        return;
    }
    Set<Account.Id> accountIds = emails.getAccountFor(metadata.author);
    if (accountIds.size() != 1) {
        logger.atSevere().log("Address %s could not be matched to a unique account. It was matched to %s." + " Will delete message.", metadata.author, accountIds);
        // We don't want to send an email if no accounts are linked to it.
        if (accountIds.size() > 1) {
            sendRejectionEmail(message, InboundEmailRejectionSender.Error.UNKNOWN_ACCOUNT);
        }
        return;
    }
    Account.Id accountId = accountIds.iterator().next();
    Optional<AccountState> accountState = accountCache.get(accountId);
    if (!accountState.isPresent()) {
        logger.atWarning().log("Mail: Account %s doesn't exist. Will delete message.", accountId);
        return;
    }
    if (!accountState.get().getAccount().isActive()) {
        logger.atWarning().log("Mail: Account %s is inactive. Will delete message.", accountId);
        sendRejectionEmail(message, InboundEmailRejectionSender.Error.INACTIVE_ACCOUNT);
        return;
    }
    persistComments(buf, message, metadata, accountId);
}
#end_block

#method_before
private void persistComments(BatchUpdate.Factory buf, MailMessage message, MailMetadata metadata, Account.Id sender) throws OrmException, UpdateException, RestApiException {
    try (ManualRequestContext ctx = oneOffRequestContext.openAs(sender)) {
        List<ChangeData> changeDataList = queryProvider.get().byLegacyChangeId(new Change.Id(metadata.changeNumber));
        if (changeDataList.size() != 1) {
            log.error(String.format("Message %s references unique change %s, but there are %d matching changes in the index. Will delete message.", message.id(), metadata.changeNumber, changeDataList.size()));
            return;
        }
        ChangeData cd = changeDataList.get(0);
        if (existingMessageIds(cd).contains(message.id())) {
            log.info(String.format("Message %s was already processed. Will delete message.", message.id()));
            return;
        }
        // Get all comments; filter and sort them to get the original list of
        // comments from the outbound email.
        // TODO(hiesel) Also filter by original comment author.
        Collection<Comment> comments = cd.publishedComments().stream().filter(c -> (c.writtenOn.getTime() / 1000) == (metadata.timestamp.getTime() / 1000)).sorted(CommentsUtil.COMMENT_ORDER).collect(toList());
        Project.NameKey project = cd.project();
        String changeUrl = canonicalUrl.get() + "#/c/" + cd.getId().get();
        List<MailComment> parsedComments;
        if (useHtmlParser(message)) {
            parsedComments = HtmlParser.parse(message, comments, changeUrl);
        } else {
            parsedComments = TextParser.parse(message, comments, changeUrl);
        }
        if (parsedComments.isEmpty()) {
            log.warn(String.format("Could not parse any comments from %s. Will delete message.", message.id()));
            return;
        }
        Op o = new Op(new PatchSet.Id(cd.getId(), metadata.patchSet), parsedComments, message.id());
        BatchUpdate batchUpdate = buf.create(cd.db(), project, ctx.getUser(), TimeUtil.nowTs());
        batchUpdate.addOp(cd.getId(), o);
        batchUpdate.execute();
    }
}
#method_after
private void persistComments(BatchUpdate.Factory buf, MailMessage message, MailMetadata metadata, Account.Id sender) throws OrmException, UpdateException, RestApiException {
    try (ManualRequestContext ctx = oneOffRequestContext.openAs(sender)) {
        List<ChangeData> changeDataList = queryProvider.get().byLegacyChangeId(new Change.Id(metadata.changeNumber));
        if (changeDataList.size() != 1) {
            logger.atSevere().log("Message %s references unique change %s," + " but there are %d matching changes in the index." + " Will delete message.", message.id(), metadata.changeNumber, changeDataList.size());
            sendRejectionEmail(message, InboundEmailRejectionSender.Error.INTERNAL_EXCEPTION);
            return;
        }
        ChangeData cd = changeDataList.get(0);
        if (existingMessageIds(cd).contains(message.id())) {
            logger.atInfo().log("Message %s was already processed. Will delete message.", message.id());
            return;
        }
        // Get all comments; filter and sort them to get the original list of
        // comments from the outbound email.
        // TODO(hiesel) Also filter by original comment author.
        Collection<Comment> comments = cd.publishedComments().stream().filter(c -> (c.writtenOn.getTime() / 1000) == (metadata.timestamp.getTime() / 1000)).sorted(CommentsUtil.COMMENT_ORDER).collect(toList());
        Project.NameKey project = cd.project();
        String changeUrl = canonicalUrl.get() + "#/c/" + cd.getId().get();
        List<MailComment> parsedComments;
        if (useHtmlParser(message)) {
            parsedComments = HtmlParser.parse(message, comments, changeUrl);
        } else {
            parsedComments = TextParser.parse(message, comments, changeUrl);
        }
        if (parsedComments.isEmpty()) {
            logger.atWarning().log("Could not parse any comments from %s. Will delete message.", message.id());
            sendRejectionEmail(message, InboundEmailRejectionSender.Error.PARSING_ERROR);
            return;
        }
        Op o = new Op(new PatchSet.Id(cd.getId(), metadata.patchSet), parsedComments, message.id());
        BatchUpdate batchUpdate = buf.create(cd.db(), project, ctx.getUser(), TimeUtil.nowTs());
        batchUpdate.addOp(cd.getId(), o);
        batchUpdate.execute();
    }
}
#end_block

#method_before
@Override
public boolean updateChange(ChangeContext ctx) throws OrmException, UnprocessableEntityException {
    patchSet = psUtil.get(ctx.getDb(), ctx.getNotes(), psId);
    notes = ctx.getNotes();
    if (patchSet == null) {
        throw new OrmException("patch set not found: " + psId);
    }
    changeMessage = generateChangeMessage(ctx);
    changeMessagesUtil.addChangeMessage(ctx.getDb(), ctx.getUpdate(psId), changeMessage);
    comments = new ArrayList<>();
    for (MailComment c : parsedComments) {
        if (c.getType() == MailComment.CommentType.CHANGE_MESSAGE) {
            continue;
        }
        comments.add(persistentCommentFromMailComment(ctx, c, targetPatchSetForComment(ctx, c, patchSet)));
    }
    commentsUtil.putComments(ctx.getDb(), ctx.getUpdate(ctx.getChange().currentPatchSetId()), Status.PUBLISHED, comments);
    return true;
}
#method_after
@Override
public boolean updateChange(ChangeContext ctx) throws OrmException, UnprocessableEntityException, PatchListNotAvailableException {
    patchSet = psUtil.get(ctx.getDb(), ctx.getNotes(), psId);
    notes = ctx.getNotes();
    if (patchSet == null) {
        throw new OrmException("patch set not found: " + psId);
    }
    changeMessage = generateChangeMessage(ctx);
    changeMessagesUtil.addChangeMessage(ctx.getDb(), ctx.getUpdate(psId), changeMessage);
    comments = new ArrayList<>();
    for (MailComment c : parsedComments) {
        if (c.getType() == MailComment.CommentType.CHANGE_MESSAGE) {
            continue;
        }
        comments.add(persistentCommentFromMailComment(ctx, c, targetPatchSetForComment(ctx, c, patchSet)));
    }
    commentsUtil.putComments(ctx.getDb(), ctx.getUpdate(ctx.getChange().currentPatchSetId()), Status.PUBLISHED, comments);
    return true;
}
#end_block

#method_before
@Override
public void postUpdate(Context ctx) throws Exception {
    String patchSetComment = null;
    if (parsedComments.get(0).getType() == MailComment.CommentType.CHANGE_MESSAGE) {
        patchSetComment = parsedComments.get(0).getMessage();
    }
    // Send email notifications
    outgoingMailFactory.create(NotifyHandling.ALL, ArrayListMultimap.create(), notes, patchSet, ctx.getUser().asIdentifiedUser(), changeMessage, comments, patchSetComment, ImmutableList.of()).sendAsync();
    // Get previous approvals from this user
    Map<String, Short> approvals = new HashMap<>();
    approvalsUtil.byPatchSetUser(ctx.getDb(), notes, ctx.getUser(), psId, ctx.getAccountId(), ctx.getRevWalk(), ctx.getRepoView().getConfig()).forEach(a -> approvals.put(a.getLabel(), a.getValue()));
    // Fire Gerrit event. Note that approvals can't be granted via email, so old and new approvals
    // are always the same here.
    commentAdded.fire(notes.getChange(), patchSet, ctx.getAccount(), changeMessage.getMessage(), approvals, approvals, ctx.getWhen());
}
#method_after
@Override
public void postUpdate(Context ctx) throws Exception {
    String patchSetComment = null;
    if (parsedComments.get(0).getType() == MailComment.CommentType.CHANGE_MESSAGE) {
        patchSetComment = parsedComments.get(0).getMessage();
    }
    // Send email notifications
    outgoingMailFactory.create(NotifyHandling.ALL, ArrayListMultimap.create(), notes, patchSet, ctx.getUser().asIdentifiedUser(), changeMessage, comments, patchSetComment, ImmutableList.of()).sendAsync();
    // Get previous approvals from this user
    Map<String, Short> approvals = new HashMap<>();
    approvalsUtil.byPatchSetUser(ctx.getDb(), notes, psId, ctx.getAccountId(), ctx.getRevWalk(), ctx.getRepoView().getConfig()).forEach(a -> approvals.put(a.getLabel(), a.getValue()));
    // Fire Gerrit event. Note that approvals can't be granted via email, so old and new approvals
    // are always the same here.
    commentAdded.fire(notes.getChange(), patchSet, ctx.getAccount(), changeMessage.getMessage(), approvals, approvals, ctx.getWhen());
}
#end_block

#method_before
private Comment persistentCommentFromMailComment(ChangeContext ctx, MailComment mailComment, PatchSet patchSetForComment) throws OrmException, UnprocessableEntityException {
    String fileName;
    // The patch set that this comment is based on is different if this
    // comment was sent in reply to a comment on a previous patch set.
    Side side;
    if (mailComment.getInReplyTo() != null) {
        fileName = mailComment.getInReplyTo().key.filename;
        side = Side.fromShort(mailComment.getInReplyTo().side);
    } else {
        fileName = mailComment.getFileName();
        side = Side.REVISION;
    }
    Comment comment = commentsUtil.newComment(ctx, fileName, patchSetForComment.getId(), (short) side.ordinal(), mailComment.getMessage(), false, null);
    comment.tag = tag;
    if (mailComment.getInReplyTo() != null) {
        comment.parentUuid = mailComment.getInReplyTo().key.uuid;
        comment.lineNbr = mailComment.getInReplyTo().lineNbr;
        comment.range = mailComment.getInReplyTo().range;
        comment.unresolved = mailComment.getInReplyTo().unresolved;
    }
    CommentsUtil.setCommentRevId(comment, patchListCache, ctx.getChange(), patchSetForComment);
    return comment;
}
#method_after
private Comment persistentCommentFromMailComment(ChangeContext ctx, MailComment mailComment, PatchSet patchSetForComment) throws OrmException, UnprocessableEntityException, PatchListNotAvailableException {
    String fileName;
    // The patch set that this comment is based on is different if this
    // comment was sent in reply to a comment on a previous patch set.
    Side side;
    if (mailComment.getInReplyTo() != null) {
        fileName = mailComment.getInReplyTo().key.filename;
        side = Side.fromShort(mailComment.getInReplyTo().side);
    } else {
        fileName = mailComment.getFileName();
        side = Side.REVISION;
    }
    Comment comment = commentsUtil.newComment(ctx, fileName, patchSetForComment.getId(), (short) side.ordinal(), mailComment.getMessage(), false, null);
    comment.tag = tag;
    if (mailComment.getInReplyTo() != null) {
        comment.parentUuid = mailComment.getInReplyTo().key.uuid;
        comment.lineNbr = mailComment.getInReplyTo().lineNbr;
        comment.range = mailComment.getInReplyTo().range;
        comment.unresolved = mailComment.getInReplyTo().unresolved;
    }
    CommentsUtil.setCommentRevId(comment, patchListCache, ctx.getChange(), patchSetForComment);
    return comment;
}
#end_block

#method_before
@Override
public synchronized void handleEmails(boolean async) throws MailTransferException, IOException {
    POP3Client pop3;
    if (mailSettings.encryption != Encryption.NONE) {
        pop3 = new POP3SClient(mailSettings.encryption.name(), true);
    } else {
        pop3 = new POP3Client();
    }
    if (mailSettings.port > 0) {
        pop3.setDefaultPort(mailSettings.port);
    }
    pop3.connect(mailSettings.host);
    try {
        if (!pop3.login(mailSettings.username, mailSettings.password)) {
            throw new MailTransferException("Could not login to POP3 email server. Check username and password");
        }
        try {
            POP3MessageInfo[] messages = pop3.listMessages();
            if (messages == null) {
                throw new MailTransferException("Could not retrieve message list via POP3");
            }
            log.info("Received " + messages.length + " messages via POP3");
            // Fetch messages
            List<MailMessage> mailMessages = new ArrayList<>();
            for (POP3MessageInfo msginfo : messages) {
                if (msginfo == null) {
                    // Message was deleted
                    continue;
                }
                try (BufferedReader reader = (BufferedReader) pop3.retrieveMessage(msginfo.number)) {
                    if (reader == null) {
                        throw new MailTransferException("Could not retrieve POP3 message header for message " + msginfo.identifier);
                    }
                    int[] message = fetchMessage(reader);
                    MailMessage mailMessage = RawMailParser.parse(message);
                    // 822 and delete the message if deletion is pending.
                    if (pendingDeletion.contains(mailMessage.id())) {
                        if (pop3.deleteMessage(msginfo.number)) {
                            pendingDeletion.remove(mailMessage.id());
                        } else {
                            log.error("Could not delete message " + msginfo.number);
                        }
                    } else {
                        // Process message further
                        mailMessages.add(mailMessage);
                    }
                } catch (MailParsingException e) {
                    log.error("Could not parse message " + msginfo.number);
                }
            }
            dispatchMailProcessor(mailMessages, async);
        } finally {
            pop3.logout();
        }
    } finally {
        pop3.disconnect();
    }
}
#method_after
@Override
public synchronized void handleEmails(boolean async) throws MailTransferException, IOException {
    POP3Client pop3;
    if (mailSettings.encryption != Encryption.NONE) {
        pop3 = new POP3SClient(mailSettings.encryption.name(), true);
    } else {
        pop3 = new POP3Client();
    }
    if (mailSettings.port > 0) {
        pop3.setDefaultPort(mailSettings.port);
    }
    pop3.connect(mailSettings.host);
    try {
        if (!pop3.login(mailSettings.username, mailSettings.password)) {
            throw new MailTransferException("Could not login to POP3 email server. Check username and password");
        }
        try {
            POP3MessageInfo[] messages = pop3.listMessages();
            if (messages == null) {
                throw new MailTransferException("Could not retrieve message list via POP3");
            }
            logger.atInfo().log("Received %d messages via POP3", messages.length);
            // Fetch messages
            List<MailMessage> mailMessages = new ArrayList<>();
            for (POP3MessageInfo msginfo : messages) {
                if (msginfo == null) {
                    // Message was deleted
                    continue;
                }
                try (BufferedReader reader = (BufferedReader) pop3.retrieveMessage(msginfo.number)) {
                    if (reader == null) {
                        throw new MailTransferException("Could not retrieve POP3 message header for message " + msginfo.identifier);
                    }
                    int[] message = fetchMessage(reader);
                    MailMessage mailMessage = RawMailParser.parse(message);
                    // 822 and delete the message if deletion is pending.
                    if (pendingDeletion.contains(mailMessage.id())) {
                        if (pop3.deleteMessage(msginfo.number)) {
                            pendingDeletion.remove(mailMessage.id());
                        } else {
                            logger.atSevere().log("Could not delete message %d", msginfo.number);
                        }
                    } else {
                        // Process message further
                        mailMessages.add(mailMessage);
                    }
                } catch (MailParsingException e) {
                    logger.atSevere().log("Could not parse message %d", msginfo.number);
                }
            }
            dispatchMailProcessor(mailMessages, async);
        } finally {
            pop3.logout();
        }
    } finally {
        pop3.disconnect();
    }
}
#end_block

#method_before
protected void includeWatchers(NotifyType type, boolean includeWatchersFromNotifyConfig) {
    try {
        Watchers matching = getWatchers(type, includeWatchersFromNotifyConfig);
        add(RecipientType.TO, matching.to);
        add(RecipientType.CC, matching.cc);
        add(RecipientType.BCC, matching.bcc);
    } catch (OrmException err) {
        // Just don't CC everyone. Better to send a partial message to those
        // we already have queued up then to fail deliver entirely to people
        // who have a lower interest in the change.
        log.warn("Cannot BCC watchers for " + type, err);
    }
}
#method_after
protected void includeWatchers(NotifyType type, boolean includeWatchersFromNotifyConfig) {
    try {
        Watchers matching = getWatchers(type, includeWatchersFromNotifyConfig);
        add(RecipientType.TO, matching.to);
        add(RecipientType.CC, matching.cc);
        add(RecipientType.BCC, matching.bcc);
    } catch (OrmException err) {
        // Just don't CC everyone. Better to send a partial message to those
        // we already have queued up then to fail deliver entirely to people
        // who have a lower interest in the change.
        logger.atWarning().withCause(err).log("Cannot BCC watchers for %s", type);
    }
}
#end_block

#method_before
@Override
protected void setupSoyContext() {
    super.setupSoyContext();
    String projectName = branch.getParentKey().get();
    soyContext.put("projectName", projectName);
    // shortProjectName is the project name with the path abbreviated.
    soyContext.put("shortProjectName", projectName.replaceAll("/.*/", "..."));
    soyContextEmailData.put("sshHost", getSshHost());
    Map<String, String> branchData = new HashMap<>();
    branchData.put("shortName", branch.getShortName());
    soyContext.put("branch", branchData);
    footers.add("Gerrit-Project: " + branch.getParentKey().get());
    footers.add("Gerrit-Branch: " + branch.getShortName());
}
#method_after
@Override
protected void setupSoyContext() {
    super.setupSoyContext();
    String projectName = branch.getParentKey().get();
    soyContext.put("projectName", projectName);
    // shortProjectName is the project name with the path abbreviated.
    soyContext.put("shortProjectName", getShortProjectName(projectName));
    // instanceAndProjectName is the instance's name followed by the abbreviated project path
    soyContext.put("instanceAndProjectName", getInstanceAndProjectName(args.instanceNameProvider.get(), projectName));
    soyContext.put("addInstanceNameInSubject", args.addInstanceNameInSubject);
    soyContextEmailData.put("sshHost", getSshHost());
    Map<String, String> branchData = new HashMap<>();
    branchData.put("shortName", branch.getShortName());
    soyContext.put("branch", branchData);
    footers.add(MailHeader.PROJECT.withDelimiter() + branch.getParentKey().get());
    footers.add("Gerrit-Branch: " + branch.getShortName());
}
#end_block

#method_before
@Test
public void assigneeCommit() throws Exception {
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, changeOwner);
    update.setAssignee(otherUserId);
    ObjectId result = update.commit();
    assertThat(result).isNotNull();
    try (RevWalk rw = new RevWalk(repo)) {
        RevCommit commit = rw.parseCommit(update.getResult());
        rw.parseBody(commit);
        String strIdent = otherUser.getName() + " <" + otherUserId + "@" + serverId + ">";
        assertThat(commit.getFullMessage()).contains("Assignee: " + strIdent);
    }
}
#method_after
@Test
public void assigneeCommit() throws Exception {
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, changeOwner);
    update.setAssignee(otherUserId);
    ObjectId result = update.commit();
    assertThat(result).isNotNull();
    try (RevWalk rw = new RevWalk(repo)) {
        RevCommit commit = rw.parseCommit(update.getResult());
        rw.parseBody(commit);
        String strIdent = "Gerrit User " + otherUserId + " <" + otherUserId + "@" + serverId + ">";
        assertThat(commit.getFullMessage()).contains("Assignee: " + strIdent);
    }
}
#end_block

#method_before
@Test
public void commitChangeNotesUnique() throws Exception {
    // PatchSetId -> RevId must be a one to one mapping
    Change c = newChange();
    ChangeNotes notes = newNotes(c);
    PatchSet ps = notes.getCurrentPatchSet();
    assertThat(ps).isNotNull();
    // new revId for the same patch set, ps1
    ChangeUpdate update = newUpdate(c, changeOwner);
    RevCommit commit = tr.commit().message("PS1 again").create();
    update.setCommit(rw, commit);
    update.commit();
    try {
        notes = newNotes(c);
        fail("Expected IOException");
    } catch (OrmException e) {
        assertCause(e, ConfigInvalidException.class, "Multiple revisions parsed for patch set 1:" + " RevId{" + commit.name() + "} and " + ps.getRevision().get());
    }
}
#method_after
@Test
public void commitChangeNotesUnique() throws Exception {
    // PatchSetId -> RevId must be a one to one mapping
    Change c = newChange();
    ChangeNotes notes = newNotes(c);
    PatchSet ps = notes.getCurrentPatchSet();
    assertThat(ps).isNotNull();
    // new revId for the same patch set, ps1
    ChangeUpdate update = newUpdate(c, changeOwner);
    RevCommit commit = tr.commit().message("PS1 again").create();
    update.setCommit(rw, commit);
    update.commit();
    try {
        newNotes(c);
        fail("Expected IOException");
    } catch (OrmException e) {
        assertCause(e, ConfigInvalidException.class, "Multiple revisions parsed for patch set 1:" + " RevId{" + commit.name() + "} and " + ps.getRevision().get());
    }
}
#end_block

#method_before
@Test
public void patchSetStates() throws Exception {
    Change c = newChange();
    PatchSet.Id psId1 = c.currentPatchSetId();
    incrementCurrentPatchSetFieldOnly(c);
    PatchSet.Id psId2 = c.currentPatchSetId();
    RevCommit commit = tr.commit().message("PS2").create();
    ChangeUpdate update = newUpdate(c, changeOwner);
    update.setCommit(rw, commit);
    update.putApproval("Code-Review", (short) 1);
    update.setChangeMessage("This is a message");
    update.putComment(Status.PUBLISHED, newComment(c.currentPatchSetId(), "a.txt", "uuid1", new CommentRange(1, 2, 3, 4), 1, changeOwner, null, TimeUtil.nowTs(), "Comment", (short) 1, commit.name(), false));
    update.commit();
    ChangeNotes notes = newNotes(c);
    assertThat(notes.getPatchSets().keySet()).containsExactly(psId1, psId2);
    assertThat(notes.getApprovals()).isNotEmpty();
    assertThat(notes.getChangeMessagesByPatchSet()).isNotEmpty();
    assertThat(notes.getChangeMessages()).isNotEmpty();
    assertThat(notes.getComments()).isNotEmpty();
    // publish ps2
    update = newUpdate(c, changeOwner);
    update.setPatchSetState(PatchSetState.PUBLISHED);
    update.commit();
    // delete ps2
    update = newUpdate(c, changeOwner);
    update.setPatchSetState(PatchSetState.DELETED);
    update.commit();
    notes = newNotes(c);
    assertThat(notes.getPatchSets().keySet()).containsExactly(psId1);
    assertThat(notes.getApprovals()).isEmpty();
    assertThat(notes.getChangeMessagesByPatchSet()).isEmpty();
    assertThat(notes.getChangeMessages()).isEmpty();
    assertThat(notes.getComments()).isEmpty();
}
#method_after
@Test
public void patchSetStates() throws Exception {
    Change c = newChange();
    PatchSet.Id psId1 = c.currentPatchSetId();
    incrementCurrentPatchSetFieldOnly(c);
    PatchSet.Id psId2 = c.currentPatchSetId();
    RevCommit commit = tr.commit().message("PS2").create();
    ChangeUpdate update = newUpdate(c, changeOwner);
    update.setCommit(rw, commit);
    update.putApproval("Code-Review", (short) 1);
    update.setChangeMessage("This is a message");
    update.putComment(Status.PUBLISHED, newComment(c.currentPatchSetId(), "a.txt", "uuid1", new CommentRange(1, 2, 3, 4), 1, changeOwner, null, TimeUtil.nowTs(), "Comment", (short) 1, commit.name(), false));
    update.commit();
    ChangeNotes notes = newNotes(c);
    assertThat(notes.getPatchSets().keySet()).containsExactly(psId1, psId2);
    assertThat(notes.getApprovals()).isNotEmpty();
    assertThat(notes.getChangeMessages()).isNotEmpty();
    assertThat(notes.getComments()).isNotEmpty();
    // publish ps2
    update = newUpdate(c, changeOwner);
    update.setPatchSetState(PatchSetState.PUBLISHED);
    update.commit();
    // delete ps2
    update = newUpdate(c, changeOwner);
    update.setPatchSetState(PatchSetState.DELETED);
    update.commit();
    notes = newNotes(c);
    assertThat(notes.getPatchSets().keySet()).containsExactly(psId1);
    assertThat(notes.getApprovals()).isEmpty();
    assertThat(notes.getChangeMessages()).isEmpty();
    assertThat(notes.getComments()).isEmpty();
}
#end_block

#method_before
@Test
public void pushCertificate() throws Exception {
    String pushCert = "certificate version 0.1\n" + "pusher This is not a real push cert\n" + "-----BEGIN PGP SIGNATURE-----\n" + "Version: GnuPG v1\n" + "\n" + "Nor is this a real signature.\n" + "-----END PGP SIGNATURE-----\n";
    // ps2 with push cert
    Change c = newChange();
    PatchSet.Id psId1 = c.currentPatchSetId();
    incrementCurrentPatchSetFieldOnly(c);
    PatchSet.Id psId2 = c.currentPatchSetId();
    ChangeUpdate update = newUpdate(c, changeOwner);
    update.setPatchSetId(psId2);
    RevCommit commit = tr.commit().message("PS2").create();
    update.setCommit(rw, commit, pushCert);
    update.commit();
    ChangeNotes notes = newNotes(c);
    String note = readNote(notes, commit);
    if (!testJson()) {
        assertThat(note).isEqualTo(pushCert);
    }
    Map<PatchSet.Id, PatchSet> patchSets = notes.getPatchSets();
    assertThat(patchSets.get(psId1).getPushCertificate()).isNull();
    assertThat(patchSets.get(psId2).getPushCertificate()).isEqualTo(pushCert);
    assertThat(notes.getComments()).isEmpty();
    // comment on ps2
    update = newUpdate(c, changeOwner);
    update.setPatchSetId(psId2);
    Timestamp ts = TimeUtil.nowTs();
    update.putComment(Status.PUBLISHED, newComment(psId2, "a.txt", "uuid1", new CommentRange(1, 2, 3, 4), 1, changeOwner, null, ts, "Comment", (short) 1, commit.name(), false));
    update.commit();
    notes = newNotes(c);
    patchSets = notes.getPatchSets();
    assertThat(patchSets.get(psId1).getPushCertificate()).isNull();
    assertThat(patchSets.get(psId2).getPushCertificate()).isEqualTo(pushCert);
    assertThat(notes.getComments()).isNotEmpty();
    if (!testJson()) {
        assertThat(readNote(notes, commit)).isEqualTo(pushCert + "Revision: " + commit.name() + "\n" + "Patch-set: 2\n" + "File: a.txt\n" + "\n" + "1:2-3:4\n" + ChangeNoteUtil.formatTime(serverIdent, ts) + "\n" + "Author: Change Owner <1@gerrit>\n" + "Unresolved: false\n" + "UUID: uuid1\n" + "Bytes: 7\n" + "Comment\n" + "\n");
    }
}
#method_after
@Test
public void pushCertificate() throws Exception {
    String pushCert = "certificate version 0.1\n" + "pusher This is not a real push cert\n" + "-----BEGIN PGP SIGNATURE-----\n" + "Version: GnuPG v1\n" + "\n" + "Nor is this a real signature.\n" + "-----END PGP SIGNATURE-----\n";
    // ps2 with push cert
    Change c = newChange();
    PatchSet.Id psId1 = c.currentPatchSetId();
    incrementCurrentPatchSetFieldOnly(c);
    PatchSet.Id psId2 = c.currentPatchSetId();
    ChangeUpdate update = newUpdate(c, changeOwner);
    update.setPatchSetId(psId2);
    RevCommit commit = tr.commit().message("PS2").create();
    update.setCommit(rw, commit, pushCert);
    update.commit();
    ChangeNotes notes = newNotes(c);
    readNote(notes, commit);
    Map<PatchSet.Id, PatchSet> patchSets = notes.getPatchSets();
    assertThat(patchSets.get(psId1).getPushCertificate()).isNull();
    assertThat(patchSets.get(psId2).getPushCertificate()).isEqualTo(pushCert);
    assertThat(notes.getComments()).isEmpty();
    // comment on ps2
    update = newUpdate(c, changeOwner);
    update.setPatchSetId(psId2);
    Timestamp ts = TimeUtil.nowTs();
    update.putComment(Status.PUBLISHED, newComment(psId2, "a.txt", "uuid1", new CommentRange(1, 2, 3, 4), 1, changeOwner, null, ts, "Comment", (short) 1, commit.name(), false));
    update.commit();
    notes = newNotes(c);
    patchSets = notes.getPatchSets();
    assertThat(patchSets.get(psId1).getPushCertificate()).isNull();
    assertThat(patchSets.get(psId2).getPushCertificate()).isEqualTo(pushCert);
    assertThat(notes.getComments()).isNotEmpty();
}
#end_block

#method_before
@Test
public void multipleUpdatesIncludingComments() throws Exception {
    Change c = newChange();
    ChangeUpdate update1 = newUpdate(c, otherUser);
    String uuid1 = "uuid1";
    String message1 = "comment 1";
    CommentRange range1 = new CommentRange(1, 1, 2, 1);
    Timestamp time1 = TimeUtil.nowTs();
    PatchSet.Id psId = c.currentPatchSetId();
    RevCommit tipCommit;
    try (NoteDbUpdateManager updateManager = updateManagerFactory.create(project)) {
        Comment comment1 = newComment(psId, "file1", uuid1, range1, range1.getEndLine(), otherUser, null, time1, message1, (short) 0, "abcd1234abcd1234abcd1234abcd1234abcd1234", false);
        update1.setPatchSetId(psId);
        update1.putComment(Status.PUBLISHED, comment1);
        updateManager.add(update1);
        ChangeUpdate update2 = newUpdate(c, otherUser);
        update2.putApproval("Code-Review", (short) 2);
        updateManager.add(update2);
        updateManager.execute();
    }
    ChangeNotes notes = newNotes(c);
    ObjectId tip = notes.getRevision();
    tipCommit = rw.parseCommit(tip);
    RevCommit commitWithApprovals = tipCommit;
    assertThat(commitWithApprovals).isNotNull();
    RevCommit commitWithComments = commitWithApprovals.getParent(0);
    assertThat(commitWithComments).isNotNull();
    try (ChangeNotesRevWalk rw = ChangeNotesCommit.newRevWalk(repo)) {
        ChangeNotesParser notesWithComments = new ChangeNotesParser(c.getId(), commitWithComments.copy(), rw, noteUtil, args.metrics);
        ChangeNotesState state = notesWithComments.parseAll();
        assertThat(state.approvals()).isEmpty();
        assertThat(state.publishedComments()).hasSize(1);
    }
    try (ChangeNotesRevWalk rw = ChangeNotesCommit.newRevWalk(repo)) {
        ChangeNotesParser notesWithApprovals = new ChangeNotesParser(c.getId(), commitWithApprovals.copy(), rw, noteUtil, args.metrics);
        ChangeNotesState state = notesWithApprovals.parseAll();
        assertThat(state.approvals()).hasSize(1);
        assertThat(state.publishedComments()).hasSize(1);
    }
}
#method_after
@Test
public void multipleUpdatesIncludingComments() throws Exception {
    Change c = newChange();
    ChangeUpdate update1 = newUpdate(c, otherUser);
    String uuid1 = "uuid1";
    String message1 = "comment 1";
    CommentRange range1 = new CommentRange(1, 1, 2, 1);
    Timestamp time1 = TimeUtil.nowTs();
    PatchSet.Id psId = c.currentPatchSetId();
    RevCommit tipCommit;
    try (NoteDbUpdateManager updateManager = updateManagerFactory.create(project)) {
        Comment comment1 = newComment(psId, "file1", uuid1, range1, range1.getEndLine(), otherUser, null, time1, message1, (short) 0, "abcd1234abcd1234abcd1234abcd1234abcd1234", false);
        update1.setPatchSetId(psId);
        update1.putComment(Status.PUBLISHED, comment1);
        updateManager.add(update1);
        ChangeUpdate update2 = newUpdate(c, otherUser);
        update2.putApproval("Code-Review", (short) 2);
        updateManager.add(update2);
        updateManager.execute();
    }
    ChangeNotes notes = newNotes(c);
    ObjectId tip = notes.getRevision();
    tipCommit = rw.parseCommit(tip);
    RevCommit commitWithApprovals = tipCommit;
    assertThat(commitWithApprovals).isNotNull();
    RevCommit commitWithComments = commitWithApprovals.getParent(0);
    assertThat(commitWithComments).isNotNull();
    try (ChangeNotesRevWalk rw = ChangeNotesCommit.newRevWalk(repo)) {
        ChangeNotesParser notesWithComments = new ChangeNotesParser(c.getId(), commitWithComments.copy(), rw, changeNoteJson, legacyChangeNoteRead, args.metrics);
        ChangeNotesState state = notesWithComments.parseAll();
        assertThat(state.approvals()).isEmpty();
        assertThat(state.publishedComments()).hasSize(1);
    }
    try (ChangeNotesRevWalk rw = ChangeNotesCommit.newRevWalk(repo)) {
        ChangeNotesParser notesWithApprovals = new ChangeNotesParser(c.getId(), commitWithApprovals.copy(), rw, changeNoteJson, legacyChangeNoteRead, args.metrics);
        ChangeNotesState state = notesWithApprovals.parseAll();
        assertThat(state.approvals()).hasSize(1);
        assertThat(state.publishedComments()).hasSize(1);
    }
}
#end_block

#method_before
@Test
public void changeMessageOnePatchSet() throws Exception {
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, changeOwner);
    update.putReviewer(changeOwner.getAccount().getId(), REVIEWER);
    update.setChangeMessage("Just a little code change.\n");
    update.commit();
    PatchSet.Id ps1 = c.currentPatchSetId();
    ChangeNotes notes = newNotes(c);
    ListMultimap<PatchSet.Id, ChangeMessage> changeMessages = notes.getChangeMessagesByPatchSet();
    assertThat(changeMessages.keySet()).containsExactly(ps1);
    ChangeMessage cm = Iterables.getOnlyElement(changeMessages.get(ps1));
    assertThat(cm.getMessage()).isEqualTo("Just a little code change.\n");
    assertThat(cm.getAuthor()).isEqualTo(changeOwner.getAccount().getId());
    assertThat(cm.getPatchSetId()).isEqualTo(ps1);
}
#method_after
@Test
public void changeMessageOnePatchSet() throws Exception {
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, changeOwner);
    update.putReviewer(changeOwner.getAccount().getId(), REVIEWER);
    update.setChangeMessage("Just a little code change.\n");
    update.commit();
    ChangeNotes notes = newNotes(c);
    ChangeMessage cm = Iterables.getOnlyElement(notes.getChangeMessages());
    assertThat(cm.getMessage()).isEqualTo("Just a little code change.\n");
    assertThat(cm.getAuthor()).isEqualTo(changeOwner.getAccount().getId());
    assertThat(cm.getPatchSetId()).isEqualTo(c.currentPatchSetId());
}
#end_block

#method_before
@Test
public void changeMessageWithTrailingDoubleNewline() throws Exception {
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, changeOwner);
    update.setChangeMessage("Testing trailing double newline\n\n");
    update.commit();
    PatchSet.Id ps1 = c.currentPatchSetId();
    ChangeNotes notes = newNotes(c);
    ListMultimap<PatchSet.Id, ChangeMessage> changeMessages = notes.getChangeMessagesByPatchSet();
    assertThat(changeMessages).hasSize(1);
    ChangeMessage cm1 = Iterables.getOnlyElement(changeMessages.get(ps1));
    assertThat(cm1.getMessage()).isEqualTo("Testing trailing double newline\n\n");
    assertThat(cm1.getAuthor()).isEqualTo(changeOwner.getAccount().getId());
}
#method_after
@Test
public void changeMessageWithTrailingDoubleNewline() throws Exception {
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, changeOwner);
    update.setChangeMessage("Testing trailing double newline\n\n");
    update.commit();
    ChangeNotes notes = newNotes(c);
    ChangeMessage cm1 = Iterables.getOnlyElement(notes.getChangeMessages());
    assertThat(cm1.getMessage()).isEqualTo("Testing trailing double newline\n\n");
    assertThat(cm1.getAuthor()).isEqualTo(changeOwner.getAccount().getId());
}
#end_block

#method_before
@Test
public void changeMessageWithMultipleParagraphs() throws Exception {
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, changeOwner);
    update.setChangeMessage("Testing paragraph 1\n\nTesting paragraph 2\n\nTesting paragraph 3");
    update.commit();
    PatchSet.Id ps1 = c.currentPatchSetId();
    ChangeNotes notes = newNotes(c);
    ListMultimap<PatchSet.Id, ChangeMessage> changeMessages = notes.getChangeMessagesByPatchSet();
    assertThat(changeMessages).hasSize(1);
    ChangeMessage cm1 = Iterables.getOnlyElement(changeMessages.get(ps1));
    assertThat(cm1.getMessage()).isEqualTo("Testing paragraph 1\n" + "\n" + "Testing paragraph 2\n" + "\n" + "Testing paragraph 3");
    assertThat(cm1.getAuthor()).isEqualTo(changeOwner.getAccount().getId());
}
#method_after
@Test
public void changeMessageWithMultipleParagraphs() throws Exception {
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, changeOwner);
    update.setChangeMessage("Testing paragraph 1\n\nTesting paragraph 2\n\nTesting paragraph 3");
    update.commit();
    ChangeNotes notes = newNotes(c);
    ChangeMessage cm1 = Iterables.getOnlyElement(notes.getChangeMessages());
    assertThat(cm1.getMessage()).isEqualTo("Testing paragraph 1\n" + "\n" + "Testing paragraph 2\n" + "\n" + "Testing paragraph 3");
    assertThat(cm1.getAuthor()).isEqualTo(changeOwner.getAccount().getId());
}
#end_block

#method_before
@Test
public void changeMessagesMultiplePatchSets() throws Exception {
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, changeOwner);
    update.putReviewer(changeOwner.getAccount().getId(), REVIEWER);
    update.setChangeMessage("This is the change message for the first PS.");
    update.commit();
    PatchSet.Id ps1 = c.currentPatchSetId();
    incrementPatchSet(c);
    update = newUpdate(c, changeOwner);
    update.setChangeMessage("This is the change message for the second PS.");
    update.commit();
    PatchSet.Id ps2 = c.currentPatchSetId();
    ChangeNotes notes = newNotes(c);
    ListMultimap<PatchSet.Id, ChangeMessage> changeMessages = notes.getChangeMessagesByPatchSet();
    assertThat(changeMessages).hasSize(2);
    ChangeMessage cm1 = Iterables.getOnlyElement(changeMessages.get(ps1));
    assertThat(cm1.getMessage()).isEqualTo("This is the change message for the first PS.");
    assertThat(cm1.getAuthor()).isEqualTo(changeOwner.getAccount().getId());
    ChangeMessage cm2 = Iterables.getOnlyElement(changeMessages.get(ps2));
    assertThat(cm1.getPatchSetId()).isEqualTo(ps1);
    assertThat(cm2.getMessage()).isEqualTo("This is the change message for the second PS.");
    assertThat(cm2.getAuthor()).isEqualTo(changeOwner.getAccount().getId());
    assertThat(cm2.getPatchSetId()).isEqualTo(ps2);
}
#method_after
@Test
public void changeMessagesMultiplePatchSets() throws Exception {
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, changeOwner);
    update.putReviewer(changeOwner.getAccount().getId(), REVIEWER);
    update.setChangeMessage("This is the change message for the first PS.");
    update.commit();
    PatchSet.Id ps1 = c.currentPatchSetId();
    incrementPatchSet(c);
    update = newUpdate(c, changeOwner);
    update.setChangeMessage("This is the change message for the second PS.");
    update.commit();
    PatchSet.Id ps2 = c.currentPatchSetId();
    ChangeNotes notes = newNotes(c);
    assertThat(notes.getChangeMessages()).hasSize(2);
    ChangeMessage cm1 = notes.getChangeMessages().get(0);
    assertThat(cm1.getPatchSetId()).isEqualTo(ps1);
    assertThat(cm1.getMessage()).isEqualTo("This is the change message for the first PS.");
    assertThat(cm1.getAuthor()).isEqualTo(changeOwner.getAccount().getId());
    ChangeMessage cm2 = notes.getChangeMessages().get(1);
    assertThat(cm2.getPatchSetId()).isEqualTo(ps2);
    assertThat(cm2.getMessage()).isEqualTo("This is the change message for the second PS.");
    assertThat(cm2.getAuthor()).isEqualTo(changeOwner.getAccount().getId());
    assertThat(cm2.getPatchSetId()).isEqualTo(ps2);
}
#end_block

#method_before
@Test
public void changeMessageMultipleInOnePatchSet() throws Exception {
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, changeOwner);
    update.putReviewer(changeOwner.getAccount().getId(), REVIEWER);
    update.setChangeMessage("First change message.\n");
    update.commit();
    PatchSet.Id ps1 = c.currentPatchSetId();
    update = newUpdate(c, changeOwner);
    update.putReviewer(changeOwner.getAccount().getId(), REVIEWER);
    update.setChangeMessage("Second change message.\n");
    update.commit();
    ChangeNotes notes = newNotes(c);
    ListMultimap<PatchSet.Id, ChangeMessage> changeMessages = notes.getChangeMessagesByPatchSet();
    assertThat(changeMessages.keySet()).hasSize(1);
    List<ChangeMessage> cm = changeMessages.get(ps1);
    assertThat(cm).hasSize(2);
    assertThat(cm.get(0).getMessage()).isEqualTo("First change message.\n");
    assertThat(cm.get(0).getAuthor()).isEqualTo(changeOwner.getAccount().getId());
    assertThat(cm.get(0).getPatchSetId()).isEqualTo(ps1);
    assertThat(cm.get(1).getMessage()).isEqualTo("Second change message.\n");
    assertThat(cm.get(1).getAuthor()).isEqualTo(changeOwner.getAccount().getId());
    assertThat(cm.get(1).getPatchSetId()).isEqualTo(ps1);
}
#method_after
@Test
public void changeMessageMultipleInOnePatchSet() throws Exception {
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, changeOwner);
    update.putReviewer(changeOwner.getAccount().getId(), REVIEWER);
    update.setChangeMessage("First change message.\n");
    update.commit();
    PatchSet.Id ps1 = c.currentPatchSetId();
    update = newUpdate(c, changeOwner);
    update.putReviewer(changeOwner.getAccount().getId(), REVIEWER);
    update.setChangeMessage("Second change message.\n");
    update.commit();
    ChangeNotes notes = newNotes(c);
    List<ChangeMessage> cm = notes.getChangeMessages();
    assertThat(cm).hasSize(2);
    assertThat(cm.get(0).getMessage()).isEqualTo("First change message.\n");
    assertThat(cm.get(0).getAuthor()).isEqualTo(changeOwner.getAccount().getId());
    assertThat(cm.get(0).getPatchSetId()).isEqualTo(ps1);
    assertThat(cm.get(1).getMessage()).isEqualTo("Second change message.\n");
    assertThat(cm.get(1).getAuthor()).isEqualTo(changeOwner.getAccount().getId());
    assertThat(cm.get(1).getPatchSetId()).isEqualTo(ps1);
}
#end_block

#method_before
@Test
public void patchLineCommentNotesFormatMultiplePatchSetsSameRevId() throws Exception {
    Change c = newChange();
    PatchSet.Id psId1 = c.currentPatchSetId();
    incrementPatchSet(c);
    PatchSet.Id psId2 = c.currentPatchSetId();
    String uuid1 = "uuid1";
    String uuid2 = "uuid2";
    String uuid3 = "uuid3";
    String message1 = "comment 1";
    String message2 = "comment 2";
    String message3 = "comment 3";
    CommentRange range1 = new CommentRange(1, 1, 2, 1);
    CommentRange range2 = new CommentRange(2, 1, 3, 1);
    Timestamp time = TimeUtil.nowTs();
    RevId revId = new RevId("abcd1234abcd1234abcd1234abcd1234abcd1234");
    Comment comment1 = newComment(psId1, "file1", uuid1, range1, range1.getEndLine(), otherUser, null, time, message1, (short) 0, revId.get(), false);
    Comment comment2 = newComment(psId1, "file1", uuid2, range2, range2.getEndLine(), otherUser, null, time, message2, (short) 0, revId.get(), false);
    Comment comment3 = newComment(psId2, "file1", uuid3, range1, range1.getEndLine(), otherUser, null, time, message3, (short) 0, revId.get(), false);
    ChangeUpdate update = newUpdate(c, otherUser);
    update.setPatchSetId(psId2);
    update.putComment(Status.PUBLISHED, comment3);
    update.putComment(Status.PUBLISHED, comment2);
    update.putComment(Status.PUBLISHED, comment1);
    update.commit();
    ChangeNotes notes = newNotes(c);
    try (RevWalk walk = new RevWalk(repo)) {
        ArrayList<Note> notesInTree = Lists.newArrayList(notes.revisionNoteMap.noteMap.iterator());
        Note note = Iterables.getOnlyElement(notesInTree);
        byte[] bytes = walk.getObjectReader().open(note.getData(), Constants.OBJ_BLOB).getBytes();
        String noteString = new String(bytes, UTF_8);
        String timeStr = ChangeNoteUtil.formatTime(serverIdent, time);
        if (!testJson()) {
            assertThat(noteString).isEqualTo("Revision: abcd1234abcd1234abcd1234abcd1234abcd1234\n" + "Base-for-patch-set: 1\n" + "File: file1\n" + "\n" + "1:1-2:1\n" + timeStr + "\n" + "Author: Other Account <2@gerrit>\n" + "Unresolved: false\n" + "UUID: uuid1\n" + "Bytes: 9\n" + "comment 1\n" + "\n" + "2:1-3:1\n" + timeStr + "\n" + "Author: Other Account <2@gerrit>\n" + "Unresolved: false\n" + "UUID: uuid2\n" + "Bytes: 9\n" + "comment 2\n" + "\n" + "Base-for-patch-set: 2\n" + "File: file1\n" + "\n" + "1:1-2:1\n" + timeStr + "\n" + "Author: Other Account <2@gerrit>\n" + "Unresolved: false\n" + "UUID: uuid3\n" + "Bytes: 9\n" + "comment 3\n" + "\n");
        }
    }
    assertThat(notes.getComments()).isEqualTo(ImmutableListMultimap.of(revId, comment1, revId, comment2, revId, comment3));
}
#method_after
@Test
public void patchLineCommentNotesFormatMultiplePatchSetsSameRevId() throws Exception {
    Change c = newChange();
    PatchSet.Id psId1 = c.currentPatchSetId();
    incrementPatchSet(c);
    PatchSet.Id psId2 = c.currentPatchSetId();
    String uuid1 = "uuid1";
    String uuid2 = "uuid2";
    String uuid3 = "uuid3";
    String message1 = "comment 1";
    String message2 = "comment 2";
    String message3 = "comment 3";
    CommentRange range1 = new CommentRange(1, 1, 2, 1);
    CommentRange range2 = new CommentRange(2, 1, 3, 1);
    Timestamp time = TimeUtil.nowTs();
    RevId revId = new RevId("abcd1234abcd1234abcd1234abcd1234abcd1234");
    Comment comment1 = newComment(psId1, "file1", uuid1, range1, range1.getEndLine(), otherUser, null, time, message1, (short) 0, revId.get(), false);
    Comment comment2 = newComment(psId1, "file1", uuid2, range2, range2.getEndLine(), otherUser, null, time, message2, (short) 0, revId.get(), false);
    Comment comment3 = newComment(psId2, "file1", uuid3, range1, range1.getEndLine(), otherUser, null, time, message3, (short) 0, revId.get(), false);
    ChangeUpdate update = newUpdate(c, otherUser);
    update.setPatchSetId(psId2);
    update.putComment(Status.PUBLISHED, comment3);
    update.putComment(Status.PUBLISHED, comment2);
    update.putComment(Status.PUBLISHED, comment1);
    update.commit();
    ChangeNotes notes = newNotes(c);
    assertThat(notes.getComments()).isEqualTo(ImmutableListMultimap.of(revId, comment1, revId, comment2, revId, comment3));
}
#end_block

#method_before
@Test
public void patchLineCommentNotesFormatRealAuthor() throws Exception {
    Change c = newChange();
    CurrentUser ownerAsOtherUser = userFactory.runAs(null, otherUserId, changeOwner);
    ChangeUpdate update = newUpdate(c, ownerAsOtherUser);
    String uuid = "uuid";
    String message = "comment";
    CommentRange range = new CommentRange(1, 1, 2, 1);
    Timestamp time = TimeUtil.nowTs();
    PatchSet.Id psId = c.currentPatchSetId();
    RevId revId = new RevId("abcd1234abcd1234abcd1234abcd1234abcd1234");
    Comment comment = newComment(psId, "file", uuid, range, range.getEndLine(), otherUser, null, time, message, (short) 1, revId.get(), false);
    comment.setRealAuthor(changeOwner.getAccountId());
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, comment);
    update.commit();
    ChangeNotes notes = newNotes(c);
    try (RevWalk walk = new RevWalk(repo)) {
        ArrayList<Note> notesInTree = Lists.newArrayList(notes.revisionNoteMap.noteMap.iterator());
        Note note = Iterables.getOnlyElement(notesInTree);
        byte[] bytes = walk.getObjectReader().open(note.getData(), Constants.OBJ_BLOB).getBytes();
        String noteString = new String(bytes, UTF_8);
        if (!testJson()) {
            assertThat(noteString).isEqualTo("Revision: abcd1234abcd1234abcd1234abcd1234abcd1234\n" + "Patch-set: 1\n" + "File: file\n" + "\n" + "1:1-2:1\n" + ChangeNoteUtil.formatTime(serverIdent, time) + "\n" + "Author: Other Account <2@gerrit>\n" + "Real-author: Change Owner <1@gerrit>\n" + "Unresolved: false\n" + "UUID: uuid\n" + "Bytes: 7\n" + "comment\n" + "\n");
        }
    }
    assertThat(notes.getComments()).isEqualTo(ImmutableListMultimap.of(revId, comment));
}
#method_after
@Test
public void patchLineCommentNotesFormatRealAuthor() throws Exception {
    Change c = newChange();
    CurrentUser ownerAsOtherUser = userFactory.runAs(null, otherUserId, changeOwner);
    ChangeUpdate update = newUpdate(c, ownerAsOtherUser);
    String uuid = "uuid";
    String message = "comment";
    CommentRange range = new CommentRange(1, 1, 2, 1);
    Timestamp time = TimeUtil.nowTs();
    PatchSet.Id psId = c.currentPatchSetId();
    RevId revId = new RevId("abcd1234abcd1234abcd1234abcd1234abcd1234");
    Comment comment = newComment(psId, "file", uuid, range, range.getEndLine(), otherUser, null, time, message, (short) 1, revId.get(), false);
    comment.setRealAuthor(changeOwner.getAccountId());
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, comment);
    update.commit();
    ChangeNotes notes = newNotes(c);
    assertThat(notes.getComments()).isEqualTo(ImmutableListMultimap.of(revId, comment));
}
#end_block

#method_before
@Test
public void patchLineCommentNotesFormatWeirdUser() throws Exception {
    Account account = new Account(new Account.Id(3), TimeUtil.nowTs());
    account.setFullName("Weird\n\u0002<User>\n");
    account.setPreferredEmail(" we\r\nird@ex>ample<.com");
    accountCache.put(account);
    IdentifiedUser user = userFactory.create(account.getId());
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, user);
    String uuid = "uuid";
    CommentRange range = new CommentRange(1, 1, 2, 1);
    Timestamp time = TimeUtil.nowTs();
    PatchSet.Id psId = c.currentPatchSetId();
    Comment comment = newComment(psId, "file1", uuid, range, range.getEndLine(), user, null, time, "comment", (short) 1, "abcd1234abcd1234abcd1234abcd1234abcd1234", false);
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, comment);
    update.commit();
    ChangeNotes notes = newNotes(c);
    try (RevWalk walk = new RevWalk(repo)) {
        ArrayList<Note> notesInTree = Lists.newArrayList(notes.revisionNoteMap.noteMap.iterator());
        Note note = Iterables.getOnlyElement(notesInTree);
        byte[] bytes = walk.getObjectReader().open(note.getData(), Constants.OBJ_BLOB).getBytes();
        String noteString = new String(bytes, UTF_8);
        String timeStr = ChangeNoteUtil.formatTime(serverIdent, time);
        if (!testJson()) {
            assertThat(noteString).isEqualTo("Revision: abcd1234abcd1234abcd1234abcd1234abcd1234\n" + "Patch-set: 1\n" + "File: file1\n" + "\n" + "1:1-2:1\n" + timeStr + "\n" + "Author: Weird\u0002User <3@gerrit>\n" + "Unresolved: false\n" + "UUID: uuid\n" + "Bytes: 7\n" + "comment\n" + "\n");
        }
    }
    assertThat(notes.getComments()).isEqualTo(ImmutableListMultimap.of(new RevId(comment.revId), comment));
}
#method_after
@Test
public void patchLineCommentNotesFormatWeirdUser() throws Exception {
    Account account = new Account(new Account.Id(3), TimeUtil.nowTs());
    account.setFullName("Weird\n\u0002<User>\n");
    account.setPreferredEmail(" we\r\nird@ex>ample<.com");
    accountCache.put(account);
    IdentifiedUser user = userFactory.create(account.getId());
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, user);
    String uuid = "uuid";
    CommentRange range = new CommentRange(1, 1, 2, 1);
    Timestamp time = TimeUtil.nowTs();
    PatchSet.Id psId = c.currentPatchSetId();
    Comment comment = newComment(psId, "file1", uuid, range, range.getEndLine(), user, null, time, "comment", (short) 1, "abcd1234abcd1234abcd1234abcd1234abcd1234", false);
    update.setPatchSetId(psId);
    update.putComment(Status.PUBLISHED, comment);
    update.commit();
    ChangeNotes notes = newNotes(c);
    assertThat(notes.getComments()).isEqualTo(ImmutableListMultimap.of(new RevId(comment.revId), comment));
}
#end_block

#method_before
@Test
public void patchLineCommentsDeleteAllDrafts() throws Exception {
    Change c = newChange();
    String uuid = "uuid";
    String rev = "abcd1234abcd1234abcd1234abcd1234abcd1234";
    ObjectId objId = ObjectId.fromString(rev);
    CommentRange range = new CommentRange(1, 1, 2, 1);
    PatchSet.Id psId = c.currentPatchSetId();
    String filename = "filename";
    short side = (short) 1;
    ChangeUpdate update = newUpdate(c, otherUser);
    Timestamp now = TimeUtil.nowTs();
    Comment comment = newComment(psId, filename, uuid, range, range.getEndLine(), otherUser, null, now, "comment on ps1", side, rev, false);
    update.setPatchSetId(psId);
    update.putComment(Status.DRAFT, comment);
    update.commit();
    ChangeNotes notes = newNotes(c);
    assertThat(notes.getDraftComments(otherUserId)).hasSize(1);
    assertThat(notes.getDraftCommentNotes().getNoteMap().contains(objId)).isTrue();
    update = newUpdate(c, otherUser);
    now = TimeUtil.nowTs();
    update.setPatchSetId(psId);
    update.deleteComment(comment);
    update.commit();
    notes = newNotes(c);
    assertThat(notes.getDraftComments(otherUserId)).isEmpty();
    assertThat(notes.getDraftCommentNotes().getNoteMap()).isNull();
}
#method_after
@Test
public void patchLineCommentsDeleteAllDrafts() throws Exception {
    Change c = newChange();
    String uuid = "uuid";
    String rev = "abcd1234abcd1234abcd1234abcd1234abcd1234";
    ObjectId objId = ObjectId.fromString(rev);
    CommentRange range = new CommentRange(1, 1, 2, 1);
    PatchSet.Id psId = c.currentPatchSetId();
    String filename = "filename";
    short side = (short) 1;
    ChangeUpdate update = newUpdate(c, otherUser);
    Timestamp now = TimeUtil.nowTs();
    Comment comment = newComment(psId, filename, uuid, range, range.getEndLine(), otherUser, null, now, "comment on ps1", side, rev, false);
    update.setPatchSetId(psId);
    update.putComment(Status.DRAFT, comment);
    update.commit();
    ChangeNotes notes = newNotes(c);
    assertThat(notes.getDraftComments(otherUserId)).hasSize(1);
    assertThat(notes.getDraftCommentNotes().getNoteMap().contains(objId)).isTrue();
    update = newUpdate(c, otherUser);
    update.setPatchSetId(psId);
    update.deleteComment(comment);
    update.commit();
    notes = newNotes(c);
    assertThat(notes.getDraftComments(otherUserId)).isEmpty();
    assertThat(notes.getDraftCommentNotes().getNoteMap()).isNull();
}
#end_block

#method_before
@Test
public void patchLineCommentsDeleteAllDraftsForOneRevision() throws Exception {
    Change c = newChange();
    String uuid = "uuid";
    String rev1 = "abcd1234abcd1234abcd1234abcd1234abcd1234";
    String rev2 = "abcd4567abcd4567abcd4567abcd4567abcd4567";
    ObjectId objId1 = ObjectId.fromString(rev1);
    ObjectId objId2 = ObjectId.fromString(rev2);
    CommentRange range = new CommentRange(1, 1, 2, 1);
    PatchSet.Id ps1 = c.currentPatchSetId();
    String filename = "filename1";
    short side = (short) 1;
    ChangeUpdate update = newUpdate(c, otherUser);
    Timestamp now = TimeUtil.nowTs();
    Comment comment1 = newComment(ps1, filename, uuid, range, range.getEndLine(), otherUser, null, now, "comment on ps1", side, rev1, false);
    update.setPatchSetId(ps1);
    update.putComment(Status.DRAFT, comment1);
    update.commit();
    incrementPatchSet(c);
    PatchSet.Id ps2 = c.currentPatchSetId();
    update = newUpdate(c, otherUser);
    now = TimeUtil.nowTs();
    Comment comment2 = newComment(ps2, filename, uuid, range, range.getEndLine(), otherUser, null, now, "comment on ps2", side, rev2, false);
    update.setPatchSetId(ps2);
    update.putComment(Status.DRAFT, comment2);
    update.commit();
    ChangeNotes notes = newNotes(c);
    assertThat(notes.getDraftComments(otherUserId)).hasSize(2);
    update = newUpdate(c, otherUser);
    now = TimeUtil.nowTs();
    update.setPatchSetId(ps2);
    update.deleteComment(comment2);
    update.commit();
    notes = newNotes(c);
    assertThat(notes.getDraftComments(otherUserId)).hasSize(1);
    NoteMap noteMap = notes.getDraftCommentNotes().getNoteMap();
    assertThat(noteMap.contains(objId1)).isTrue();
    assertThat(noteMap.contains(objId2)).isFalse();
}
#method_after
@Test
public void patchLineCommentsDeleteAllDraftsForOneRevision() throws Exception {
    Change c = newChange();
    String uuid = "uuid";
    String rev1 = "abcd1234abcd1234abcd1234abcd1234abcd1234";
    String rev2 = "abcd4567abcd4567abcd4567abcd4567abcd4567";
    ObjectId objId1 = ObjectId.fromString(rev1);
    ObjectId objId2 = ObjectId.fromString(rev2);
    CommentRange range = new CommentRange(1, 1, 2, 1);
    PatchSet.Id ps1 = c.currentPatchSetId();
    String filename = "filename1";
    short side = (short) 1;
    ChangeUpdate update = newUpdate(c, otherUser);
    Timestamp now = TimeUtil.nowTs();
    Comment comment1 = newComment(ps1, filename, uuid, range, range.getEndLine(), otherUser, null, now, "comment on ps1", side, rev1, false);
    update.setPatchSetId(ps1);
    update.putComment(Status.DRAFT, comment1);
    update.commit();
    incrementPatchSet(c);
    PatchSet.Id ps2 = c.currentPatchSetId();
    update = newUpdate(c, otherUser);
    now = TimeUtil.nowTs();
    Comment comment2 = newComment(ps2, filename, uuid, range, range.getEndLine(), otherUser, null, now, "comment on ps2", side, rev2, false);
    update.setPatchSetId(ps2);
    update.putComment(Status.DRAFT, comment2);
    update.commit();
    ChangeNotes notes = newNotes(c);
    assertThat(notes.getDraftComments(otherUserId)).hasSize(2);
    update = newUpdate(c, otherUser);
    update.setPatchSetId(ps2);
    update.deleteComment(comment2);
    update.commit();
    notes = newNotes(c);
    assertThat(notes.getDraftComments(otherUserId)).hasSize(1);
    NoteMap noteMap = notes.getDraftCommentNotes().getNoteMap();
    assertThat(noteMap.contains(objId1)).isTrue();
    assertThat(noteMap.contains(objId2)).isFalse();
}
#end_block

#method_before
@Test
public void privateDefault() throws Exception {
    Change c = newChange();
    ChangeNotes notes = newNotes(c);
    assertThat(notes.isPrivate()).isFalse();
}
#method_after
@Test
public void privateDefault() throws Exception {
    Change c = newChange();
    ChangeNotes notes = newNotes(c);
    assertThat(notes.getChange().isPrivate()).isFalse();
}
#end_block

#method_before
@Test
public void privateSetPrivate() throws Exception {
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, changeOwner);
    update.setPrivate(true);
    update.commit();
    ChangeNotes notes = newNotes(c);
    assertThat(notes.isPrivate()).isTrue();
}
#method_after
@Test
public void privateSetPrivate() throws Exception {
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, changeOwner);
    update.setPrivate(true);
    update.commit();
    ChangeNotes notes = newNotes(c);
    assertThat(notes.getChange().isPrivate()).isTrue();
}
#end_block

#method_before
@Test
public void privateSetPrivateMultipleTimes() throws Exception {
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, changeOwner);
    update.setPrivate(true);
    update.commit();
    update = newUpdate(c, changeOwner);
    update.setPrivate(false);
    update.commit();
    ChangeNotes notes = newNotes(c);
    assertThat(notes.isPrivate()).isFalse();
}
#method_after
@Test
public void privateSetPrivateMultipleTimes() throws Exception {
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, changeOwner);
    update.setPrivate(true);
    update.commit();
    update = newUpdate(c, changeOwner);
    update.setPrivate(false);
    update.commit();
    ChangeNotes notes = newNotes(c);
    assertThat(notes.getChange().isPrivate()).isFalse();
}
#end_block

#method_before
@Test
public void hasReviewStarted() throws Exception {
    ChangeNotes notes = newNotes(newChange());
    assertThat(notes.hasReviewStarted()).isTrue();
    notes = newNotes(newWorkInProgressChange());
    assertThat(notes.hasReviewStarted()).isFalse();
    Change c = newWorkInProgressChange();
    ChangeUpdate update = newUpdate(c, changeOwner);
    update.commit();
    notes = newNotes(c);
    assertThat(notes.hasReviewStarted()).isFalse();
    update = newUpdate(c, changeOwner);
    update.setWorkInProgress(true);
    update.commit();
    notes = newNotes(c);
    assertThat(notes.hasReviewStarted()).isFalse();
    update = newUpdate(c, changeOwner);
    update.setWorkInProgress(false);
    update.commit();
    notes = newNotes(c);
    assertThat(notes.hasReviewStarted()).isTrue();
    // Once review is started, setting WIP should have no impact.
    c = newChange();
    notes = newNotes(c);
    assertThat(notes.hasReviewStarted()).isTrue();
    update = newUpdate(c, changeOwner);
    update.setWorkInProgress(true);
    update.commit();
    notes = newNotes(c);
    assertThat(notes.hasReviewStarted()).isTrue();
}
#method_after
@Test
public void hasReviewStarted() throws Exception {
    ChangeNotes notes = newNotes(newChange());
    assertThat(notes.getChange().hasReviewStarted()).isTrue();
    notes = newNotes(newWorkInProgressChange());
    assertThat(notes.getChange().hasReviewStarted()).isFalse();
    Change c = newWorkInProgressChange();
    ChangeUpdate update = newUpdate(c, changeOwner);
    update.commit();
    notes = newNotes(c);
    assertThat(notes.getChange().hasReviewStarted()).isFalse();
    update = newUpdate(c, changeOwner);
    update.setWorkInProgress(true);
    update.commit();
    notes = newNotes(c);
    assertThat(notes.getChange().hasReviewStarted()).isFalse();
    update = newUpdate(c, changeOwner);
    update.setWorkInProgress(false);
    update.commit();
    notes = newNotes(c);
    assertThat(notes.getChange().hasReviewStarted()).isTrue();
    // Once review is started, setting WIP should have no impact.
    c = newChange();
    notes = newNotes(c);
    assertThat(notes.getChange().hasReviewStarted()).isTrue();
    update = newUpdate(c, changeOwner);
    update.setWorkInProgress(true);
    update.commit();
    notes = newNotes(c);
    assertThat(notes.getChange().hasReviewStarted()).isTrue();
}
#end_block

#method_before
@Test
public void revertOfIsNullByDefault() throws Exception {
    Change c = newChange();
    ChangeNotes notes = newNotes(c);
    assertThat(notes.getRevertOf()).isNull();
}
#method_after
@Test
public void revertOfIsNullByDefault() throws Exception {
    Change c = newChange();
    ChangeNotes notes = newNotes(c);
    assertThat(notes.getChange().getRevertOf()).isNull();
}
#end_block

#method_before
@Test
public void setRevertOfPersistsValue() throws Exception {
    Change changeToRevert = newChange();
    Change c = TestChanges.newChange(project, changeOwner.getAccountId());
    ChangeUpdate update = newUpdate(c, changeOwner);
    update.setChangeId(c.getKey().get());
    update.setRevertOf(changeToRevert.getId().get());
    update.commit();
    assertThat(newNotes(c).getRevertOf()).isEqualTo(changeToRevert.getId());
}
#method_after
@Test
public void setRevertOfPersistsValue() throws Exception {
    Change changeToRevert = newChange();
    Change c = TestChanges.newChange(project, changeOwner.getAccountId());
    ChangeUpdate update = newUpdate(c, changeOwner);
    update.setChangeId(c.getKey().get());
    update.setRevertOf(changeToRevert.getId().get());
    update.commit();
    assertThat(newNotes(c).getChange().getRevertOf()).isEqualTo(changeToRevert.getId());
}
#end_block

#method_before
@Test
public void setRevertOfOnChildCommitFails() throws Exception {
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, changeOwner);
    exception.expect(OrmException.class);
    exception.expectMessage("Given ChangeUpdate is only allowed on initial commit");
    update.setRevertOf(newChange().getId().get());
    update.commit();
}
#method_after
@Test
public void setRevertOfOnChildCommitFails() throws Exception {
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, changeOwner);
    update.setRevertOf(newChange().getId().get());
    exception.expect(OrmException.class);
    exception.expectMessage("Given ChangeUpdate is only allowed on initial commit");
    update.commit();
}
#end_block

#method_before
private ChangeInfo format(ChangeData cd, Optional<PatchSet.Id> limitToPsId, boolean fillAccountLoader) throws OrmException {
    try {
        if (fillAccountLoader) {
            accountLoader = accountLoaderFactory.create(has(DETAILED_ACCOUNTS));
            ChangeInfo res = toChangeInfo(cd, limitToPsId);
            accountLoader.fill();
            return res;
        }
        return toChangeInfo(cd, limitToPsId);
    } catch (PatchListNotAvailableException | GpgException | OrmException | IOException | PermissionBackendException | NoSuchProjectException | RuntimeException e) {
        if (!has(CHECK)) {
            Throwables.throwIfInstanceOf(e, OrmException.class);
            throw new OrmException(e);
        }
        return checkOnly(cd);
    }
}
#method_after
private ChangeInfo format(ChangeData cd, Optional<PatchSet.Id> limitToPsId, boolean fillAccountLoader) throws OrmException {
    try {
        if (fillAccountLoader) {
            accountLoader = accountLoaderFactory.create(has(DETAILED_ACCOUNTS));
            ChangeInfo res = toChangeInfo(cd, limitToPsId);
            accountLoader.fill();
            return res;
        }
        return toChangeInfo(cd, limitToPsId);
    } catch (PatchListNotAvailableException | GpgException | OrmException | IOException | PermissionBackendException | RuntimeException e) {
        if (!has(CHECK)) {
            Throwables.throwIfInstanceOf(e, OrmException.class);
            throw new OrmException(e);
        }
        return checkOnly(cd);
    }
}
#end_block

#method_before
public List<List<ChangeInfo>> formatQueryResults(List<QueryResult<ChangeData>> in) throws OrmException {
    accountLoader = accountLoaderFactory.create(has(DETAILED_ACCOUNTS));
    ensureLoaded(FluentIterable.from(in).transformAndConcat(QueryResult::entities));
    List<List<ChangeInfo>> res = Lists.newArrayListWithCapacity(in.size());
    Map<Change.Id, ChangeInfo> out = new HashMap<>();
    for (QueryResult<ChangeData> r : in) {
        List<ChangeInfo> infos = toChangeInfo(out, r.entities());
        if (!infos.isEmpty() && r.more()) {
            infos.get(infos.size() - 1)._moreChanges = true;
        }
        res.add(infos);
    }
    accountLoader.fill();
    return res;
}
#method_after
public List<List<ChangeInfo>> formatQueryResults(List<QueryResult<ChangeData>> in) {
    try (Timer0.Context ignored = metrics.formatQueryResultsLatency.start()) {
        accountLoader = accountLoaderFactory.create(has(DETAILED_ACCOUNTS));
        List<List<ChangeInfo>> res = new ArrayList<>(in.size());
        Map<Change.Id, ChangeInfo> cache = Maps.newHashMapWithExpectedSize(in.size());
        for (QueryResult<ChangeData> r : in) {
            List<ChangeInfo> infos = toChangeInfos(r.entities(), cache);
            infos.forEach(c -> cache.put(new Change.Id(c._number), c));
            if (!infos.isEmpty() && r.more()) {
                infos.get(infos.size() - 1)._moreChanges = true;
            }
            res.add(infos);
        }
        accountLoader.fill();
        return res;
    }
}
#end_block

#method_before
public List<ChangeInfo> formatChangeDatas(Collection<ChangeData> in) throws OrmException {
    accountLoader = accountLoaderFactory.create(has(DETAILED_ACCOUNTS));
    ensureLoaded(in);
    List<ChangeInfo> out = new ArrayList<>(in.size());
    for (ChangeData cd : in) {
        out.add(format(cd));
    }
    accountLoader.fill();
    return out;
}
#method_after
public List<ChangeInfo> formatChangeDatas(Collection<ChangeData> in) throws OrmException {
    accountLoader = accountLoaderFactory.create(has(DETAILED_ACCOUNTS));
    ensureLoaded(in);
    List<ChangeInfo> out = new ArrayList<>(in.size());
    for (ChangeData cd : in) {
        out.add(format(cd, Optional.empty(), false));
    }
    accountLoader.fill();
    return out;
}
#end_block

#method_before
private ChangeInfo checkOnly(ChangeData cd) {
    ChangeNotes notes;
    try {
        notes = cd.notes();
    } catch (OrmException e) {
        String msg = "Error loading change";
        log.warn(msg + " " + cd.getId(), e);
        ChangeInfo info = new ChangeInfo();
        info._number = cd.getId().get();
        ProblemInfo p = new ProblemInfo();
        p.message = msg;
        info.problems = Lists.newArrayList(p);
        return info;
    }
    ConsistencyChecker.Result result = checkerProvider.get().check(notes, fix);
    ChangeInfo info;
    Change c = result.change();
    if (c != null) {
        info = new ChangeInfo();
        info.project = c.getProject().get();
        info.branch = c.getDest().getShortName();
        info.topic = c.getTopic();
        info.changeId = c.getKey().get();
        info.subject = c.getSubject();
        info.status = c.getStatus().asChangeStatus();
        info.owner = new AccountInfo(c.getOwner().get());
        info.created = c.getCreatedOn();
        info.updated = c.getLastUpdatedOn();
        info._number = c.getId().get();
        info.problems = result.problems();
        info.isPrivate = c.isPrivate() ? true : null;
        info.workInProgress = c.isWorkInProgress() ? true : null;
        info.hasReviewStarted = c.hasReviewStarted();
        finish(info);
    } else {
        info = new ChangeInfo();
        info._number = result.id().get();
        info.problems = result.problems();
    }
    return info;
}
#method_after
private ChangeInfo checkOnly(ChangeData cd) {
    ChangeNotes notes;
    try {
        notes = cd.notes();
    } catch (OrmException e) {
        String msg = "Error loading change";
        logger.atWarning().withCause(e).log(msg + " %s", cd.getId());
        ChangeInfo info = new ChangeInfo();
        info._number = cd.getId().get();
        ProblemInfo p = new ProblemInfo();
        p.message = msg;
        info.problems = Lists.newArrayList(p);
        return info;
    }
    ConsistencyChecker.Result result = checkerProvider.get().check(notes, fix);
    ChangeInfo info;
    Change c = result.change();
    if (c != null) {
        info = new ChangeInfo();
        info.project = c.getProject().get();
        info.branch = c.getDest().getShortName();
        info.topic = c.getTopic();
        info.changeId = c.getKey().get();
        info.subject = c.getSubject();
        info.status = c.getStatus().asChangeStatus();
        info.owner = new AccountInfo(c.getOwner().get());
        info.created = c.getCreatedOn();
        info.updated = c.getLastUpdatedOn();
        info._number = c.getId().get();
        info.problems = result.problems();
        info.isPrivate = c.isPrivate() ? true : null;
        info.workInProgress = c.isWorkInProgress() ? true : null;
        info.hasReviewStarted = c.hasReviewStarted();
        finish(info);
    } else {
        info = new ChangeInfo();
        info._number = result.id().get();
        info.problems = result.problems();
    }
    return info;
}
#end_block

#method_before
private ChangeInfo toChangeInfo(ChangeData cd, Optional<PatchSet.Id> limitToPsId) throws PatchListNotAvailableException, GpgException, OrmException, IOException, PermissionBackendException, NoSuchProjectException {
    ChangeInfo out = new ChangeInfo();
    CurrentUser user = userProvider.get();
    if (has(CHECK)) {
        out.problems = checkerProvider.get().check(cd.notes(), fix).problems();
        // If any problems were fixed, the ChangeData needs to be reloaded.
        for (ProblemInfo p : out.problems) {
            if (p.status == ProblemInfo.Status.FIXED) {
                cd = changeDataFactory.create(cd.db(), cd.project(), cd.getId());
                break;
            }
        }
    }
    PermissionBackend.ForChange perm = permissionBackendForChange(user, cd);
    Change in = cd.change();
    out.project = in.getProject().get();
    out.branch = in.getDest().getShortName();
    out.topic = in.getTopic();
    if (indexes.getSearchIndex().getSchema().hasField(ChangeField.ASSIGNEE)) {
        if (in.getAssignee() != null) {
            out.assignee = accountLoader.get(in.getAssignee());
        }
    }
    out.hashtags = cd.hashtags();
    out.changeId = in.getKey().get();
    if (in.getStatus().isOpen()) {
        SubmitTypeRecord str = cd.submitTypeRecord();
        if (str.isOk()) {
            out.submitType = str.type;
        }
        out.mergeable = cd.isMergeable();
        if (has(SUBMITTABLE)) {
            out.submittable = submittable(cd);
        }
    }
    Optional<ChangedLines> changedLines = cd.changedLines();
    if (changedLines.isPresent()) {
        out.insertions = changedLines.get().insertions;
        out.deletions = changedLines.get().deletions;
    }
    out.isPrivate = in.isPrivate() ? true : null;
    out.workInProgress = in.isWorkInProgress() ? true : null;
    out.hasReviewStarted = in.hasReviewStarted();
    out.subject = in.getSubject();
    out.status = in.getStatus().asChangeStatus();
    out.owner = accountLoader.get(in.getOwner());
    out.created = in.getCreatedOn();
    out.updated = in.getLastUpdatedOn();
    out._number = in.getId().get();
    out.unresolvedCommentCount = cd.unresolvedCommentCount();
    if (user.isIdentifiedUser()) {
        Collection<String> stars = cd.stars(user.getAccountId());
        out.starred = stars.contains(StarredChangesUtil.DEFAULT_LABEL) ? true : null;
        if (!stars.isEmpty()) {
            out.stars = stars;
        }
    }
    if (in.getStatus().isOpen() && has(REVIEWED) && user.isIdentifiedUser()) {
        out.reviewed = cd.isReviewedBy(user.getAccountId()) ? true : null;
    }
    out.labels = labelsFor(perm, cd, has(LABELS), has(DETAILED_LABELS));
    if (out.labels != null && has(DETAILED_LABELS)) {
        // list permitted labels, since users can't vote on those patch sets.
        if (user.isIdentifiedUser() && (!limitToPsId.isPresent() || limitToPsId.get().equals(in.currentPatchSetId()))) {
            out.permittedLabels = cd.change().getStatus() != Change.Status.ABANDONED ? permittedLabels(perm, cd) : ImmutableMap.of();
        }
        out.reviewers = reviewerMap(cd.reviewers(), cd.reviewersByEmail(), false);
        out.pendingReviewers = reviewerMap(cd.pendingReviewers(), cd.pendingReviewersByEmail(), true);
        out.removableReviewers = removableReviewers(cd, out);
    }
    setSubmitter(cd, out);
    out.plugins = pluginDefinedAttributesFactory != null ? pluginDefinedAttributesFactory.create(cd) : null;
    out.revertOf = cd.change().getRevertOf() != null ? cd.change().getRevertOf().get() : null;
    if (has(REVIEWER_UPDATES)) {
        out.reviewerUpdates = reviewerUpdates(cd);
    }
    boolean needMessages = has(MESSAGES);
    boolean needRevisions = has(ALL_REVISIONS) || has(CURRENT_REVISION) || limitToPsId.isPresent();
    Map<PatchSet.Id, PatchSet> src;
    if (needMessages || needRevisions) {
        src = loadPatchSets(cd, limitToPsId);
    } else {
        src = null;
    }
    if (needMessages) {
        out.messages = messages(cd);
    }
    finish(out);
    // it will be passed to ActionVisitors as-is.
    if (needRevisions) {
        out.revisions = revisions(cd, src, limitToPsId, out);
        if (out.revisions != null) {
            for (Map.Entry<String, RevisionInfo> entry : out.revisions.entrySet()) {
                if (entry.getValue().isCurrent) {
                    out.currentRevision = entry.getKey();
                    break;
                }
            }
        }
    }
    if (has(CURRENT_ACTIONS) || has(CHANGE_ACTIONS)) {
        actionJson.addChangeActions(out, cd.notes());
    }
    if (has(TRACKING_IDS)) {
        ListMultimap<String, String> set = trackingFooters.extract(cd.commitFooters());
        out.trackingIds = set.entries().stream().map(e -> new TrackingIdInfo(e.getKey(), e.getValue())).collect(toList());
    }
    return out;
}
#method_after
private ChangeInfo toChangeInfo(ChangeData cd, Optional<PatchSet.Id> limitToPsId) throws PatchListNotAvailableException, GpgException, OrmException, PermissionBackendException, IOException {
    try (Timer0.Context ignored = metrics.toChangeInfoLatency.start()) {
        return toChangeInfoImpl(cd, limitToPsId);
    }
}
#end_block

#method_before
private boolean submittable(ChangeData cd) throws OrmException {
    return SubmitRecord.findOkRecord(cd.submitRecords(SUBMIT_RULE_OPTIONS_STRICT)).isPresent();
}
#method_after
private boolean submittable(ChangeData cd) {
    return SubmitRecord.allRecordsOK(cd.submitRecords(SUBMIT_RULE_OPTIONS_STRICT));
}
#end_block

#method_before
private List<SubmitRecord> submitRecords(ChangeData cd) throws OrmException {
    return cd.submitRecords(SUBMIT_RULE_OPTIONS_LENIENT);
}
#method_after
private List<SubmitRecord> submitRecords(ChangeData cd) {
    return cd.submitRecords(SUBMIT_RULE_OPTIONS_LENIENT);
}
#end_block

#method_before
private Map<String, LabelInfo> labelsFor(PermissionBackend.ForChange perm, ChangeData cd, boolean standard, boolean detailed) throws OrmException, PermissionBackendException {
    if (!standard && !detailed) {
        return null;
    }
    LabelTypes labelTypes = cd.getLabelTypes();
    Map<String, LabelWithStatus> withStatus = cd.change().getStatus() == Change.Status.MERGED ? labelsForSubmittedChange(perm, cd, labelTypes, standard, detailed) : labelsForUnsubmittedChange(perm, cd, labelTypes, standard, detailed);
    return ImmutableMap.copyOf(Maps.transformValues(withStatus, LabelWithStatus::label));
}
#method_after
private Map<String, LabelInfo> labelsFor(ChangeData cd, boolean standard, boolean detailed) throws OrmException, PermissionBackendException {
    if (!standard && !detailed) {
        return null;
    }
    LabelTypes labelTypes = cd.getLabelTypes();
    Map<String, LabelWithStatus> withStatus = cd.change().getStatus() == Change.Status.MERGED ? labelsForSubmittedChange(cd, labelTypes, standard, detailed) : labelsForUnsubmittedChange(cd, labelTypes, standard, detailed);
    return ImmutableMap.copyOf(Maps.transformValues(withStatus, LabelWithStatus::label));
}
#end_block

#method_before
private Map<String, LabelWithStatus> labelsForUnsubmittedChange(PermissionBackend.ForChange perm, ChangeData cd, LabelTypes labelTypes, boolean standard, boolean detailed) throws OrmException, PermissionBackendException {
    Map<String, LabelWithStatus> labels = initLabels(cd, labelTypes, standard);
    if (detailed) {
        setAllApprovals(perm, cd, labels);
    }
    for (Map.Entry<String, LabelWithStatus> e : labels.entrySet()) {
        LabelType type = labelTypes.byLabel(e.getKey());
        if (type == null) {
            continue;
        }
        if (standard) {
            for (PatchSetApproval psa : cd.currentApprovals()) {
                if (type.matches(psa)) {
                    short val = psa.getValue();
                    Account.Id accountId = psa.getAccountId();
                    setLabelScores(type, e.getValue(), val, accountId);
                }
            }
        }
        if (detailed) {
            setLabelValues(type, e.getValue());
        }
    }
    return labels;
}
#method_after
private Map<String, LabelWithStatus> labelsForUnsubmittedChange(ChangeData cd, LabelTypes labelTypes, boolean standard, boolean detailed) throws OrmException, PermissionBackendException {
    Map<String, LabelWithStatus> labels = initLabels(cd, labelTypes, standard);
    if (detailed) {
        setAllApprovals(cd, labels);
    }
    for (Map.Entry<String, LabelWithStatus> e : labels.entrySet()) {
        LabelType type = labelTypes.byLabel(e.getKey());
        if (type == null) {
            continue;
        }
        if (standard) {
            for (PatchSetApproval psa : cd.currentApprovals()) {
                if (type.matches(psa)) {
                    short val = psa.getValue();
                    Account.Id accountId = psa.getAccountId();
                    setLabelScores(type, e.getValue(), val, accountId);
                }
            }
        }
        if (detailed) {
            setLabelValues(type, e.getValue());
        }
    }
    return labels;
}
#end_block

#method_before
private Map<String, LabelWithStatus> initLabels(ChangeData cd, LabelTypes labelTypes, boolean standard) throws OrmException {
    Map<String, LabelWithStatus> labels = new TreeMap<>(labelTypes.nameComparator());
    for (SubmitRecord rec : submitRecords(cd)) {
        if (rec.labels == null) {
            continue;
        }
        for (SubmitRecord.Label r : rec.labels) {
            LabelWithStatus p = labels.get(r.label);
            if (p == null || p.status().compareTo(r.status) < 0) {
                LabelInfo n = new LabelInfo();
                if (standard) {
                    switch(r.status) {
                        case OK:
                            n.approved = accountLoader.get(r.appliedBy);
                            break;
                        case REJECT:
                            n.rejected = accountLoader.get(r.appliedBy);
                            n.blocking = true;
                            break;
                        case IMPOSSIBLE:
                        case MAY:
                        case NEED:
                        default:
                            break;
                    }
                }
                n.optional = r.status == SubmitRecord.Label.Status.MAY ? true : null;
                labels.put(r.label, LabelWithStatus.create(n, r.status));
            }
        }
    }
    return labels;
}
#method_after
private Map<String, LabelWithStatus> initLabels(ChangeData cd, LabelTypes labelTypes, boolean standard) {
    Map<String, LabelWithStatus> labels = new TreeMap<>(labelTypes.nameComparator());
    for (SubmitRecord rec : submitRecords(cd)) {
        if (rec.labels == null) {
            continue;
        }
        for (SubmitRecord.Label r : rec.labels) {
            LabelWithStatus p = labels.get(r.label);
            if (p == null || p.status().compareTo(r.status) < 0) {
                LabelInfo n = new LabelInfo();
                if (standard) {
                    switch(r.status) {
                        case OK:
                            n.approved = accountLoader.get(r.appliedBy);
                            break;
                        case REJECT:
                            n.rejected = accountLoader.get(r.appliedBy);
                            n.blocking = true;
                            break;
                        case IMPOSSIBLE:
                        case MAY:
                        case NEED:
                        default:
                            break;
                    }
                }
                n.optional = r.status == SubmitRecord.Label.Status.MAY ? true : null;
                labels.put(r.label, LabelWithStatus.create(n, r.status));
            }
        }
    }
    return labels;
}
#end_block

#method_before
private void setAllApprovals(PermissionBackend.ForChange basePerm, ChangeData cd, Map<String, LabelWithStatus> labels) throws OrmException, PermissionBackendException {
    Change.Status status = cd.change().getStatus();
    checkState(status != Change.Status.MERGED, "should not call setAllApprovals on %s change", status);
    // Include a user in the output for this label if either:
    // - They are an explicit reviewer.
    // - They ever voted on this change.
    Set<Account.Id> allUsers = new HashSet<>();
    allUsers.addAll(cd.reviewers().byState(ReviewerStateInternal.REVIEWER));
    for (PatchSetApproval psa : cd.approvals().values()) {
        allUsers.add(psa.getAccountId());
    }
    Table<Account.Id, String, PatchSetApproval> current = HashBasedTable.create(allUsers.size(), cd.getLabelTypes().getLabelTypes().size());
    for (PatchSetApproval psa : cd.currentApprovals()) {
        current.put(psa.getAccountId(), psa.getLabel(), psa);
    }
    LabelTypes labelTypes = cd.getLabelTypes();
    for (Account.Id accountId : allUsers) {
        PermissionBackend.ForChange perm = basePerm.user(userFactory.create(accountId));
        Map<String, VotingRangeInfo> pvr = getPermittedVotingRanges(permittedLabels(perm, cd));
        for (Map.Entry<String, LabelWithStatus> e : labels.entrySet()) {
            LabelType lt = labelTypes.byLabel(e.getKey());
            if (lt == null) {
                // author didn't intend for the label to show up in the table.
                continue;
            }
            Integer value;
            VotingRangeInfo permittedVotingRange = pvr.getOrDefault(lt.getName(), null);
            String tag = null;
            Timestamp date = null;
            PatchSetApproval psa = current.get(accountId, lt.getName());
            if (psa != null) {
                value = Integer.valueOf(psa.getValue());
                if (value == 0) {
                    // This may be a dummy approval that was inserted when the reviewer
                    // was added. Explicitly check whether the user can vote on this
                    // label.
                    value = perm.test(new LabelPermission(lt)) ? 0 : null;
                }
                tag = psa.getTag();
                date = psa.getGranted();
                if (psa.isPostSubmit()) {
                    log.warn("unexpected post-submit approval on open change: {}", psa);
                }
            } else {
                // Either the user cannot vote on this label, or they were added as a
                // reviewer but have not responded yet. Explicitly check whether the
                // user can vote on this label.
                value = perm.test(new LabelPermission(lt)) ? 0 : null;
            }
            addApproval(e.getValue().label(), approvalInfo(accountId, value, permittedVotingRange, tag, date));
        }
    }
}
#method_after
private void setAllApprovals(ChangeData cd, Map<String, LabelWithStatus> labels) throws OrmException, PermissionBackendException {
    Change.Status status = cd.change().getStatus();
    checkState(status != Change.Status.MERGED, "should not call setAllApprovals on %s change", status);
    // Include a user in the output for this label if either:
    // - They are an explicit reviewer.
    // - They ever voted on this change.
    Set<Account.Id> allUsers = new HashSet<>();
    allUsers.addAll(cd.reviewers().byState(ReviewerStateInternal.REVIEWER));
    for (PatchSetApproval psa : cd.approvals().values()) {
        allUsers.add(psa.getAccountId());
    }
    Table<Account.Id, String, PatchSetApproval> current = HashBasedTable.create(allUsers.size(), cd.getLabelTypes().getLabelTypes().size());
    for (PatchSetApproval psa : cd.currentApprovals()) {
        current.put(psa.getAccountId(), psa.getLabel(), psa);
    }
    LabelTypes labelTypes = cd.getLabelTypes();
    for (Account.Id accountId : allUsers) {
        PermissionBackend.ForChange perm = permissionBackendForChange(accountId, cd);
        Map<String, VotingRangeInfo> pvr = getPermittedVotingRanges(permittedLabels(accountId, cd));
        for (Map.Entry<String, LabelWithStatus> e : labels.entrySet()) {
            LabelType lt = labelTypes.byLabel(e.getKey());
            if (lt == null) {
                // author didn't intend for the label to show up in the table.
                continue;
            }
            Integer value;
            VotingRangeInfo permittedVotingRange = pvr.getOrDefault(lt.getName(), null);
            String tag = null;
            Timestamp date = null;
            PatchSetApproval psa = current.get(accountId, lt.getName());
            if (psa != null) {
                value = Integer.valueOf(psa.getValue());
                if (value == 0) {
                    // This may be a dummy approval that was inserted when the reviewer
                    // was added. Explicitly check whether the user can vote on this
                    // label.
                    value = perm.test(new LabelPermission(lt)) ? 0 : null;
                }
                tag = psa.getTag();
                date = psa.getGranted();
                if (psa.isPostSubmit()) {
                    logger.atWarning().log("unexpected post-submit approval on open change: %s", psa);
                }
            } else {
                // Either the user cannot vote on this label, or they were added as a
                // reviewer but have not responded yet. Explicitly check whether the
                // user can vote on this label.
                value = perm.test(new LabelPermission(lt)) ? 0 : null;
            }
            addApproval(e.getValue().label(), approvalInfo(accountId, value, permittedVotingRange, tag, date));
        }
    }
}
#end_block

#method_before
private Map<String, LabelWithStatus> labelsForSubmittedChange(PermissionBackend.ForChange basePerm, ChangeData cd, LabelTypes labelTypes, boolean standard, boolean detailed) throws OrmException, PermissionBackendException {
    Set<Account.Id> allUsers = new HashSet<>();
    if (detailed) {
        // the latest patch set (in the next loop).
        for (PatchSetApproval psa : cd.approvals().values()) {
            allUsers.add(psa.getAccountId());
        }
    }
    Set<String> labelNames = new HashSet<>();
    SetMultimap<Account.Id, PatchSetApproval> current = MultimapBuilder.hashKeys().hashSetValues().build();
    for (PatchSetApproval a : cd.currentApprovals()) {
        allUsers.add(a.getAccountId());
        LabelType type = labelTypes.byLabel(a.getLabelId());
        if (type != null) {
            labelNames.add(type.getName());
            // Not worth the effort to distinguish between votable/non-votable for 0
            // values on closed changes, since they can't vote anyway.
            current.put(a.getAccountId(), a);
        }
    }
    // Since voting on merged changes is allowed all labels which apply to
    // the change must be returned. All applying labels can be retrieved from
    // the submit records, which is what initLabels does.
    // It's not possible to only compute the labels based on the approvals
    // since merged changes may not have approvals for all labels (e.g. if not
    // all labels are required for submit or if the change was auto-closed due
    // to direct push or if new labels were defined after the change was
    // merged).
    Map<String, LabelWithStatus> labels;
    labels = initLabels(cd, labelTypes, standard);
    // it wouldn't be included in the submit records.
    for (String name : labelNames) {
        if (!labels.containsKey(name)) {
            labels.put(name, LabelWithStatus.create(new LabelInfo(), null));
        }
    }
    if (detailed) {
        labels.entrySet().stream().filter(e -> labelTypes.byLabel(e.getKey()) != null).forEach(e -> setLabelValues(labelTypes.byLabel(e.getKey()), e.getValue()));
    }
    for (Account.Id accountId : allUsers) {
        Map<String, ApprovalInfo> byLabel = Maps.newHashMapWithExpectedSize(labels.size());
        Map<String, VotingRangeInfo> pvr = Collections.emptyMap();
        if (detailed) {
            PermissionBackend.ForChange perm = basePerm.user(userFactory.create(accountId));
            pvr = getPermittedVotingRanges(permittedLabels(perm, cd));
            for (Map.Entry<String, LabelWithStatus> entry : labels.entrySet()) {
                ApprovalInfo ai = approvalInfo(accountId, 0, null, null, null);
                byLabel.put(entry.getKey(), ai);
                addApproval(entry.getValue().label(), ai);
            }
        }
        for (PatchSetApproval psa : current.get(accountId)) {
            LabelType type = labelTypes.byLabel(psa.getLabelId());
            if (type == null) {
                continue;
            }
            short val = psa.getValue();
            ApprovalInfo info = byLabel.get(type.getName());
            if (info != null) {
                info.value = Integer.valueOf(val);
                info.permittedVotingRange = pvr.getOrDefault(type.getName(), null);
                info.date = psa.getGranted();
                info.tag = psa.getTag();
                if (psa.isPostSubmit()) {
                    info.postSubmit = true;
                }
            }
            if (!standard) {
                continue;
            }
            setLabelScores(type, labels.get(type.getName()), val, accountId);
        }
    }
    return labels;
}
#method_after
private Map<String, LabelWithStatus> labelsForSubmittedChange(ChangeData cd, LabelTypes labelTypes, boolean standard, boolean detailed) throws OrmException, PermissionBackendException {
    Set<Account.Id> allUsers = new HashSet<>();
    if (detailed) {
        // the latest patch set (in the next loop).
        for (PatchSetApproval psa : cd.approvals().values()) {
            allUsers.add(psa.getAccountId());
        }
    }
    Set<String> labelNames = new HashSet<>();
    SetMultimap<Account.Id, PatchSetApproval> current = MultimapBuilder.hashKeys().hashSetValues().build();
    for (PatchSetApproval a : cd.currentApprovals()) {
        allUsers.add(a.getAccountId());
        LabelType type = labelTypes.byLabel(a.getLabelId());
        if (type != null) {
            labelNames.add(type.getName());
            // Not worth the effort to distinguish between votable/non-votable for 0
            // values on closed changes, since they can't vote anyway.
            current.put(a.getAccountId(), a);
        }
    }
    // Since voting on merged changes is allowed all labels which apply to
    // the change must be returned. All applying labels can be retrieved from
    // the submit records, which is what initLabels does.
    // It's not possible to only compute the labels based on the approvals
    // since merged changes may not have approvals for all labels (e.g. if not
    // all labels are required for submit or if the change was auto-closed due
    // to direct push or if new labels were defined after the change was
    // merged).
    Map<String, LabelWithStatus> labels;
    labels = initLabels(cd, labelTypes, standard);
    // it wouldn't be included in the submit records.
    for (String name : labelNames) {
        if (!labels.containsKey(name)) {
            labels.put(name, LabelWithStatus.create(new LabelInfo(), null));
        }
    }
    if (detailed) {
        labels.entrySet().stream().filter(e -> labelTypes.byLabel(e.getKey()) != null).forEach(e -> setLabelValues(labelTypes.byLabel(e.getKey()), e.getValue()));
    }
    for (Account.Id accountId : allUsers) {
        Map<String, ApprovalInfo> byLabel = Maps.newHashMapWithExpectedSize(labels.size());
        Map<String, VotingRangeInfo> pvr = Collections.emptyMap();
        if (detailed) {
            pvr = getPermittedVotingRanges(permittedLabels(accountId, cd));
            for (Map.Entry<String, LabelWithStatus> entry : labels.entrySet()) {
                ApprovalInfo ai = approvalInfo(accountId, 0, null, null, null);
                byLabel.put(entry.getKey(), ai);
                addApproval(entry.getValue().label(), ai);
            }
        }
        for (PatchSetApproval psa : current.get(accountId)) {
            LabelType type = labelTypes.byLabel(psa.getLabelId());
            if (type == null) {
                continue;
            }
            short val = psa.getValue();
            ApprovalInfo info = byLabel.get(type.getName());
            if (info != null) {
                info.value = Integer.valueOf(val);
                info.permittedVotingRange = pvr.getOrDefault(type.getName(), null);
                info.date = psa.getGranted();
                info.tag = psa.getTag();
                if (psa.isPostSubmit()) {
                    info.postSubmit = true;
                }
            }
            if (!standard) {
                continue;
            }
            setLabelScores(type, labels.get(type.getName()), val, accountId);
        }
    }
    return labels;
}
#end_block

#method_before
private Map<String, Collection<String>> permittedLabels(PermissionBackend.ForChange perm, ChangeData cd) throws OrmException, PermissionBackendException {
    boolean isMerged = cd.change().getStatus() == Change.Status.MERGED;
    LabelTypes labelTypes = cd.getLabelTypes();
    Map<String, LabelType> toCheck = new HashMap<>();
    for (SubmitRecord rec : submitRecords(cd)) {
        if (rec.labels != null) {
            for (SubmitRecord.Label r : rec.labels) {
                LabelType type = labelTypes.byLabel(r.label);
                if (type != null && (!isMerged || type.allowPostSubmit())) {
                    toCheck.put(type.getName(), type);
                }
            }
        }
    }
    Map<String, Short> labels = null;
    Set<LabelPermission.WithValue> can = perm.testLabels(toCheck.values());
    SetMultimap<String, String> permitted = LinkedHashMultimap.create();
    for (SubmitRecord rec : submitRecords(cd)) {
        if (rec.labels == null) {
            continue;
        }
        for (SubmitRecord.Label r : rec.labels) {
            LabelType type = labelTypes.byLabel(r.label);
            if (type == null || (isMerged && !type.allowPostSubmit())) {
                continue;
            }
            for (LabelValue v : type.getValues()) {
                boolean ok = can.contains(new LabelPermission.WithValue(type, v));
                if (isMerged) {
                    if (labels == null) {
                        labels = currentLabels(perm, cd);
                    }
                    short prev = labels.getOrDefault(type.getName(), (short) 0);
                    ok &= v.getValue() >= prev;
                }
                if (ok) {
                    permitted.put(r.label, v.formatValue());
                }
            }
        }
    }
    List<String> toClear = Lists.newArrayListWithCapacity(permitted.keySet().size());
    for (Map.Entry<String, Collection<String>> e : permitted.asMap().entrySet()) {
        if (isOnlyZero(e.getValue())) {
            toClear.add(e.getKey());
        }
    }
    for (String label : toClear) {
        permitted.removeAll(label);
    }
    return permitted.asMap();
}
#method_after
private Map<String, Collection<String>> permittedLabels(Account.Id filterApprovalsBy, ChangeData cd) throws OrmException, PermissionBackendException {
    boolean isMerged = cd.change().getStatus() == Change.Status.MERGED;
    LabelTypes labelTypes = cd.getLabelTypes();
    Map<String, LabelType> toCheck = new HashMap<>();
    for (SubmitRecord rec : submitRecords(cd)) {
        if (rec.labels != null) {
            for (SubmitRecord.Label r : rec.labels) {
                LabelType type = labelTypes.byLabel(r.label);
                if (type != null && (!isMerged || type.allowPostSubmit())) {
                    toCheck.put(type.getName(), type);
                }
            }
        }
    }
    Map<String, Short> labels = null;
    Set<LabelPermission.WithValue> can = permissionBackendForChange(filterApprovalsBy, cd).testLabels(toCheck.values());
    SetMultimap<String, String> permitted = LinkedHashMultimap.create();
    for (SubmitRecord rec : submitRecords(cd)) {
        if (rec.labels == null) {
            continue;
        }
        for (SubmitRecord.Label r : rec.labels) {
            LabelType type = labelTypes.byLabel(r.label);
            if (type == null || (isMerged && !type.allowPostSubmit())) {
                continue;
            }
            for (LabelValue v : type.getValues()) {
                boolean ok = can.contains(new LabelPermission.WithValue(type, v));
                if (isMerged) {
                    if (labels == null) {
                        labels = currentLabels(filterApprovalsBy, cd);
                    }
                    short prev = labels.getOrDefault(type.getName(), (short) 0);
                    ok &= v.getValue() >= prev;
                }
                if (ok) {
                    permitted.put(r.label, v.formatValue());
                }
            }
        }
    }
    List<String> toClear = Lists.newArrayListWithCapacity(permitted.keySet().size());
    for (Map.Entry<String, Collection<String>> e : permitted.asMap().entrySet()) {
        if (isOnlyZero(e.getValue())) {
            toClear.add(e.getKey());
        }
    }
    for (String label : toClear) {
        permitted.removeAll(label);
    }
    return permitted.asMap();
}
#end_block

#method_before
private Map<String, Short> currentLabels(PermissionBackend.ForChange perm, ChangeData cd) throws OrmException {
    IdentifiedUser user = perm.user().asIdentifiedUser();
    Map<String, Short> result = new HashMap<>();
    for (PatchSetApproval psa : approvalsUtil.byPatchSetUser(db.get(), lazyLoad ? cd.notes() : notesFactory.createFromIndexedChange(cd.change()), user, cd.change().currentPatchSetId(), user.getAccountId(), null, null)) {
        result.put(psa.getLabel(), psa.getValue());
    }
    return result;
}
#method_after
private Map<String, Short> currentLabels(Account.Id accountId, ChangeData cd) throws OrmException {
    Map<String, Short> result = new HashMap<>();
    for (PatchSetApproval psa : approvalsUtil.byPatchSetUser(db.get(), lazyLoad ? cd.notes() : notesFactory.createFromIndexedChange(cd.change()), cd.change().currentPatchSetId(), accountId, null, null)) {
        result.put(psa.getLabel(), psa.getValue());
    }
    return result;
}
#end_block

#method_before
private Collection<ChangeMessageInfo> messages(ChangeData cd) throws OrmException {
    List<ChangeMessage> messages = cmUtil.byChange(db.get(), cd.notes());
    if (messages.isEmpty()) {
        return Collections.emptyList();
    }
    List<ChangeMessageInfo> result = Lists.newArrayListWithCapacity(messages.size());
    for (ChangeMessage message : messages) {
        PatchSet.Id patchNum = message.getPatchSetId();
        ChangeMessageInfo cmi = new ChangeMessageInfo();
        cmi.id = message.getKey().get();
        cmi.author = accountLoader.get(message.getAuthor());
        cmi.date = message.getWrittenOn();
        cmi.message = message.getMessage();
        cmi.tag = message.getTag();
        cmi._revisionNumber = patchNum != null ? patchNum.get() : null;
        Account.Id realAuthor = message.getRealAuthor();
        if (realAuthor != null) {
            cmi.realAuthor = accountLoader.get(realAuthor);
        }
        result.add(cmi);
    }
    return result;
}
#method_after
private Collection<ChangeMessageInfo> messages(ChangeData cd) throws OrmException {
    List<ChangeMessage> messages = cmUtil.byChange(db.get(), cd.notes());
    if (messages.isEmpty()) {
        return Collections.emptyList();
    }
    List<ChangeMessageInfo> result = Lists.newArrayListWithCapacity(messages.size());
    for (ChangeMessage message : messages) {
        result.add(createChangeMessageInfo(message, accountLoader));
    }
    return result;
}
#end_block

#method_before
private Collection<AccountInfo> removableReviewers(ChangeData cd, ChangeInfo out) throws PermissionBackendException, NoSuchProjectException, OrmException, IOException {
    // Although this is called removableReviewers, this method also determines
    // which CCs are removable.
    // 
    // For reviewers, we need to look at each approval, because the reviewer
    // should only be considered removable if *all* of their approvals can be
    // removed. First, add all reviewers with *any* removable approval to the
    // "removable" set. Along the way, if we encounter a non-removable approval,
    // add the reviewer to the "fixed" set. Before we return, remove all members
    // of "fixed" from "removable", because not all of their approvals can be
    // removed.
    Collection<LabelInfo> labels = out.labels.values();
    Set<Account.Id> fixed = Sets.newHashSetWithExpectedSize(labels.size());
    Set<Account.Id> removable = Sets.newHashSetWithExpectedSize(labels.size());
    for (LabelInfo label : labels) {
        if (label.all == null) {
            continue;
        }
        for (ApprovalInfo ai : label.all) {
            Account.Id id = new Account.Id(ai._accountId);
            if (removeReviewerControl.testRemoveReviewer(cd, userProvider.get(), id, MoreObjects.firstNonNull(ai.value, 0))) {
                removable.add(id);
            } else {
                fixed.add(id);
            }
        }
    }
    // CCs are simpler than reviewers. They are removable if the ChangeControl
    // would permit a non-negative approval by that account to be removed, in
    // which case add them to removable. We don't need to add unremovable CCs to
    // "fixed" because we only visit each CC once here.
    Collection<AccountInfo> ccs = out.reviewers.get(ReviewerState.CC);
    if (ccs != null) {
        for (AccountInfo ai : ccs) {
            if (ai._accountId != null) {
                Account.Id id = new Account.Id(ai._accountId);
                if (removeReviewerControl.testRemoveReviewer(cd, userProvider.get(), id, 0)) {
                    removable.add(id);
                }
            }
        }
    }
    // Subtract any reviewers with non-removable approvals from the "removable"
    // set. This also subtracts any CCs that for some reason also hold
    // unremovable approvals.
    removable.removeAll(fixed);
    List<AccountInfo> result = Lists.newArrayListWithCapacity(removable.size());
    for (Account.Id id : removable) {
        result.add(accountLoader.get(id));
    }
    // Reviewers added by email are always removable
    for (Collection<AccountInfo> infos : out.reviewers.values()) {
        for (AccountInfo info : infos) {
            if (info._accountId == null) {
                result.add(info);
            }
        }
    }
    return result;
}
#method_after
private Collection<AccountInfo> removableReviewers(ChangeData cd, ChangeInfo out) throws PermissionBackendException, OrmException {
    // Although this is called removableReviewers, this method also determines
    // which CCs are removable.
    // 
    // For reviewers, we need to look at each approval, because the reviewer
    // should only be considered removable if *all* of their approvals can be
    // removed. First, add all reviewers with *any* removable approval to the
    // "removable" set. Along the way, if we encounter a non-removable approval,
    // add the reviewer to the "fixed" set. Before we return, remove all members
    // of "fixed" from "removable", because not all of their approvals can be
    // removed.
    Collection<LabelInfo> labels = out.labels.values();
    Set<Account.Id> fixed = Sets.newHashSetWithExpectedSize(labels.size());
    Set<Account.Id> removable = Sets.newHashSetWithExpectedSize(labels.size());
    for (LabelInfo label : labels) {
        if (label.all == null) {
            continue;
        }
        for (ApprovalInfo ai : label.all) {
            Account.Id id = new Account.Id(ai._accountId);
            if (removeReviewerControl.testRemoveReviewer(cd, userProvider.get(), id, MoreObjects.firstNonNull(ai.value, 0))) {
                removable.add(id);
            } else {
                fixed.add(id);
            }
        }
    }
    // CCs are simpler than reviewers. They are removable if the ChangeControl
    // would permit a non-negative approval by that account to be removed, in
    // which case add them to removable. We don't need to add unremovable CCs to
    // "fixed" because we only visit each CC once here.
    Collection<AccountInfo> ccs = out.reviewers.get(ReviewerState.CC);
    if (ccs != null) {
        for (AccountInfo ai : ccs) {
            if (ai._accountId != null) {
                Account.Id id = new Account.Id(ai._accountId);
                if (removeReviewerControl.testRemoveReviewer(cd, userProvider.get(), id, 0)) {
                    removable.add(id);
                }
            }
        }
    }
    // Subtract any reviewers with non-removable approvals from the "removable"
    // set. This also subtracts any CCs that for some reason also hold
    // unremovable approvals.
    removable.removeAll(fixed);
    List<AccountInfo> result = Lists.newArrayListWithCapacity(removable.size());
    for (Account.Id id : removable) {
        result.add(accountLoader.get(id));
    }
    // Reviewers added by email are always removable
    for (Collection<AccountInfo> infos : out.reviewers.values()) {
        for (AccountInfo info : infos) {
            if (info._accountId == null) {
                result.add(info);
            }
        }
    }
    return result;
}
#end_block

#method_before
private Map<String, RevisionInfo> revisions(ChangeData cd, Map<PatchSet.Id, PatchSet> map, Optional<PatchSet.Id> limitToPsId, ChangeInfo changeInfo) throws PatchListNotAvailableException, GpgException, OrmException, IOException, PermissionBackendException {
    Map<String, RevisionInfo> res = new LinkedHashMap<>();
    Boolean isWorldReadable = null;
    try (Repository repo = openRepoIfNecessary(cd.project());
        RevWalk rw = newRevWalk(repo)) {
        for (PatchSet in : map.values()) {
            PatchSet.Id id = in.getId();
            boolean want = false;
            if (has(ALL_REVISIONS)) {
                want = true;
            } else if (limitToPsId.isPresent()) {
                want = id.equals(limitToPsId.get());
            } else {
                want = id.equals(cd.change().currentPatchSetId());
            }
            if (want) {
                if (isWorldReadable == null) {
                    isWorldReadable = isWorldReadable(cd);
                }
                res.put(in.getRevision().get(), toRevisionInfo(cd, in, repo, rw, false, changeInfo, isWorldReadable));
            }
        }
        return res;
    }
}
#method_after
private Map<String, RevisionInfo> revisions(ChangeData cd, Map<PatchSet.Id, PatchSet> map, Optional<PatchSet.Id> limitToPsId, ChangeInfo changeInfo) throws PatchListNotAvailableException, GpgException, OrmException, IOException, PermissionBackendException {
    Map<String, RevisionInfo> res = new LinkedHashMap<>();
    try (Repository repo = openRepoIfNecessary(cd.project());
        RevWalk rw = newRevWalk(repo)) {
        for (PatchSet in : map.values()) {
            PatchSet.Id id = in.getId();
            boolean want = false;
            if (has(ALL_REVISIONS)) {
                want = true;
            } else if (limitToPsId.isPresent()) {
                want = id.equals(limitToPsId.get());
            } else {
                want = id.equals(cd.change().currentPatchSetId());
            }
            if (want) {
                res.put(in.getRevision().get(), toRevisionInfo(cd, in, repo, rw, false, changeInfo));
            }
        }
        return res;
    }
}
#end_block

#method_before
public RevisionInfo getRevisionInfo(ChangeData cd, PatchSet in) throws PatchListNotAvailableException, GpgException, OrmException, IOException, PermissionBackendException {
    accountLoader = accountLoaderFactory.create(has(DETAILED_ACCOUNTS));
    try (Repository repo = openRepoIfNecessary(cd.project());
        RevWalk rw = newRevWalk(repo)) {
        RevisionInfo rev = toRevisionInfo(cd, in, repo, rw, true, null, isWorldReadable(cd));
        accountLoader.fill();
        return rev;
    }
}
#method_after
public RevisionInfo getRevisionInfo(ChangeData cd, PatchSet in) throws PatchListNotAvailableException, GpgException, OrmException, IOException, PermissionBackendException {
    accountLoader = accountLoaderFactory.create(has(DETAILED_ACCOUNTS));
    try (Repository repo = openRepoIfNecessary(cd.project());
        RevWalk rw = newRevWalk(repo)) {
        RevisionInfo rev = toRevisionInfo(cd, in, repo, rw, true, null);
        accountLoader.fill();
        return rev;
    }
}
#end_block

#method_before
private RevisionInfo toRevisionInfo(ChangeData cd, PatchSet in, @Nullable Repository repo, @Nullable RevWalk rw, boolean fillCommit, @Nullable ChangeInfo changeInfo, boolean isWorldReadable) throws PatchListNotAvailableException, GpgException, OrmException, IOException {
    Change c = cd.change();
    RevisionInfo out = new RevisionInfo();
    out.isCurrent = in.getId().equals(c.currentPatchSetId());
    out._number = in.getId().get();
    out.ref = in.getRefName();
    out.created = in.getCreatedOn();
    out.uploader = accountLoader.get(in.getUploader());
    out.fetch = makeFetchMap(cd, in, isWorldReadable);
    out.kind = changeKindCache.getChangeKind(rw, repo != null ? repo.getConfig() : null, cd, in);
    out.description = in.getDescription();
    boolean setCommit = has(ALL_COMMITS) || (out.isCurrent && has(CURRENT_COMMIT));
    boolean addFooters = out.isCurrent && has(COMMIT_FOOTERS);
    if (setCommit || addFooters) {
        checkState(rw != null);
        checkState(repo != null);
        Project.NameKey project = c.getProject();
        String rev = in.getRevision().get();
        RevCommit commit = rw.parseCommit(ObjectId.fromString(rev));
        rw.parseBody(commit);
        if (setCommit) {
            out.commit = toCommit(project, rw, commit, has(WEB_LINKS), fillCommit);
        }
        if (addFooters) {
            Ref ref = repo.exactRef(cd.change().getDest().get());
            RevCommit mergeTip = null;
            if (ref != null) {
                mergeTip = rw.parseCommit(ref.getObjectId());
                rw.parseBody(mergeTip);
            }
            out.commitWithFooters = mergeUtilFactory.create(projectCache.get(project)).createCommitMessageOnSubmit(commit, mergeTip, cd.notes(), userProvider.get(), in.getId());
        }
    }
    if (has(ALL_FILES) || (out.isCurrent && has(CURRENT_FILES))) {
        out.files = fileInfoJson.toFileInfoMap(c, in);
        out.files.remove(Patch.COMMIT_MSG);
        out.files.remove(Patch.MERGE_LIST);
    }
    if (out.isCurrent && has(CURRENT_ACTIONS) && userProvider.get().isIdentifiedUser()) {
        actionJson.addRevisionActions(changeInfo, out, new RevisionResource(changeResourceFactory.create(cd.notes(), userProvider.get()), in));
    }
    if (gpgApi.isEnabled() && has(PUSH_CERTIFICATES)) {
        if (in.getPushCertificate() != null) {
            out.pushCertificate = gpgApi.checkPushCertificate(in.getPushCertificate(), userFactory.create(in.getUploader()));
        } else {
            out.pushCertificate = new PushCertificateInfo();
        }
    }
    return out;
}
#method_after
private RevisionInfo toRevisionInfo(ChangeData cd, PatchSet in, @Nullable Repository repo, @Nullable RevWalk rw, boolean fillCommit, @Nullable ChangeInfo changeInfo) throws PatchListNotAvailableException, GpgException, OrmException, IOException, PermissionBackendException {
    Change c = cd.change();
    RevisionInfo out = new RevisionInfo();
    out.isCurrent = in.getId().equals(c.currentPatchSetId());
    out._number = in.getId().get();
    out.ref = in.getRefName();
    out.created = in.getCreatedOn();
    out.uploader = accountLoader.get(in.getUploader());
    out.fetch = makeFetchMap(cd, in);
    out.kind = changeKindCache.getChangeKind(rw, repo != null ? repo.getConfig() : null, cd, in);
    out.description = in.getDescription();
    boolean setCommit = has(ALL_COMMITS) || (out.isCurrent && has(CURRENT_COMMIT));
    boolean addFooters = out.isCurrent && has(COMMIT_FOOTERS);
    if (setCommit || addFooters) {
        checkState(rw != null);
        checkState(repo != null);
        Project.NameKey project = c.getProject();
        String rev = in.getRevision().get();
        RevCommit commit = rw.parseCommit(ObjectId.fromString(rev));
        rw.parseBody(commit);
        if (setCommit) {
            out.commit = toCommit(project, rw, commit, has(WEB_LINKS), fillCommit);
        }
        if (addFooters) {
            Ref ref = repo.exactRef(cd.change().getDest().get());
            RevCommit mergeTip = null;
            if (ref != null) {
                mergeTip = rw.parseCommit(ref.getObjectId());
                rw.parseBody(mergeTip);
            }
            out.commitWithFooters = mergeUtilFactory.create(projectCache.get(project)).createCommitMessageOnSubmit(commit, mergeTip, cd.notes(), userProvider.get(), in.getId());
        }
    }
    if (has(ALL_FILES) || (out.isCurrent && has(CURRENT_FILES))) {
        out.files = fileInfoJson.toFileInfoMap(c, in);
        out.files.remove(Patch.COMMIT_MSG);
        out.files.remove(Patch.MERGE_LIST);
    }
    if (out.isCurrent && has(CURRENT_ACTIONS) && userProvider.get().isIdentifiedUser()) {
        actionJson.addRevisionActions(changeInfo, out, new RevisionResource(changeResourceFactory.create(cd.notes(), userProvider.get()), in));
    }
    if (gpgApi.isEnabled() && has(PUSH_CERTIFICATES)) {
        if (in.getPushCertificate() != null) {
            out.pushCertificate = gpgApi.checkPushCertificate(in.getPushCertificate(), userFactory.create(in.getUploader()));
        } else {
            out.pushCertificate = new PushCertificateInfo();
        }
    }
    return out;
}
#end_block

#method_before
CommitInfo toCommit(Project.NameKey project, RevWalk rw, RevCommit commit, boolean addLinks, boolean fillCommit) throws IOException {
    CommitInfo info = new CommitInfo();
    if (fillCommit) {
        info.commit = commit.name();
    }
    info.parents = new ArrayList<>(commit.getParentCount());
    info.author = toGitPerson(commit.getAuthorIdent());
    info.committer = toGitPerson(commit.getCommitterIdent());
    info.subject = commit.getShortMessage();
    info.message = commit.getFullMessage();
    if (addLinks) {
        List<WebLinkInfo> links = webLinks.getPatchSetLinks(project, commit.name());
        info.webLinks = links.isEmpty() ? null : links;
    }
    for (RevCommit parent : commit.getParents()) {
        rw.parseBody(parent);
        CommitInfo i = new CommitInfo();
        i.commit = parent.name();
        i.subject = parent.getShortMessage();
        if (addLinks) {
            List<WebLinkInfo> parentLinks = webLinks.getParentLinks(project, parent.name());
            i.webLinks = parentLinks.isEmpty() ? null : parentLinks;
        }
        info.parents.add(i);
    }
    return info;
}
#method_after
public CommitInfo toCommit(Project.NameKey project, RevWalk rw, RevCommit commit, boolean addLinks, boolean fillCommit) throws IOException {
    CommitInfo info = new CommitInfo();
    if (fillCommit) {
        info.commit = commit.name();
    }
    info.parents = new ArrayList<>(commit.getParentCount());
    info.author = toGitPerson(commit.getAuthorIdent());
    info.committer = toGitPerson(commit.getCommitterIdent());
    info.subject = commit.getShortMessage();
    info.message = commit.getFullMessage();
    if (addLinks) {
        List<WebLinkInfo> links = webLinks.getPatchSetLinks(project, commit.name());
        info.webLinks = links.isEmpty() ? null : links;
    }
    for (RevCommit parent : commit.getParents()) {
        rw.parseBody(parent);
        CommitInfo i = new CommitInfo();
        i.commit = parent.name();
        i.subject = parent.getShortMessage();
        if (addLinks) {
            List<WebLinkInfo> parentLinks = webLinks.getParentLinks(project, parent.name());
            i.webLinks = parentLinks.isEmpty() ? null : parentLinks;
        }
        info.parents.add(i);
    }
    return info;
}
#end_block

#method_before
private Map<String, FetchInfo> makeFetchMap(ChangeData cd, PatchSet in, boolean isWorldReadable) {
    Map<String, FetchInfo> r = new LinkedHashMap<>();
    for (DynamicMap.Entry<DownloadScheme> e : downloadSchemes) {
        String schemeName = e.getExportName();
        DownloadScheme scheme = e.getProvider().get();
        if (!scheme.isEnabled() || (scheme.isAuthRequired() && !userProvider.get().isIdentifiedUser())) {
            continue;
        }
        if (!scheme.isAuthSupported() && !isWorldReadable) {
            continue;
        }
        String projectName = cd.project().get();
        String url = scheme.getUrl(projectName);
        String refName = in.getRefName();
        FetchInfo fetchInfo = new FetchInfo(url, refName);
        r.put(schemeName, fetchInfo);
        if (has(DOWNLOAD_COMMANDS)) {
            populateFetchMap(scheme, downloadCommands, projectName, refName, fetchInfo);
        }
    }
    return r;
}
#method_after
private Map<String, FetchInfo> makeFetchMap(ChangeData cd, PatchSet in) throws PermissionBackendException, OrmException, IOException {
    Map<String, FetchInfo> r = new LinkedHashMap<>();
    for (DynamicMap.Entry<DownloadScheme> e : downloadSchemes) {
        String schemeName = e.getExportName();
        DownloadScheme scheme = e.getProvider().get();
        if (!scheme.isEnabled() || (scheme.isAuthRequired() && !userProvider.get().isIdentifiedUser())) {
            continue;
        }
        if (!scheme.isAuthSupported() && !isWorldReadable(cd)) {
            continue;
        }
        String projectName = cd.project().get();
        String url = scheme.getUrl(projectName);
        String refName = in.getRefName();
        FetchInfo fetchInfo = new FetchInfo(url, refName);
        r.put(schemeName, fetchInfo);
        if (has(DOWNLOAD_COMMANDS)) {
            populateFetchMap(scheme, downloadCommands, projectName, refName, fetchInfo);
        }
    }
    return r;
}
#end_block

#method_before
private PermissionBackend.ForChange permissionBackendForChange(CurrentUser user, ChangeData cd) throws OrmException {
    PermissionBackend.WithUser withUser = permissionBackend.user(user).database(db);
    return lazyLoad ? withUser.change(cd) : withUser.indexedChange(cd, notesFactory.createFromIndexedChange(cd.change()));
}
#method_after
private PermissionBackend.ForChange permissionBackendForChange(CurrentUser user, ChangeData cd) throws OrmException {
    return permissionBackendForChange(permissionBackend.user(user).database(db), cd);
}
#end_block

#method_before
private PermissionBackend.ForChange permissionBackendForChange(CurrentUser user, ChangeData cd) throws OrmException {
    PermissionBackend.WithUser withUser = permissionBackend.user(user).database(db);
    return lazyLoad ? withUser.change(cd) : withUser.indexedChange(cd, notesFactory.createFromIndexedChange(cd.change()));
}
#method_after
private PermissionBackend.ForChange permissionBackendForChange(Account.Id user, ChangeData cd) throws OrmException {
    return permissionBackendForChange(permissionBackend.absentUser(user).database(db), cd);
}
#end_block

#method_before
private boolean isWorldReadable(ChangeData cd) throws OrmException, PermissionBackendException {
    try {
        permissionBackendForChange(anonymous, cd).check(ChangePermission.READ);
        return true;
    } catch (AuthException ae) {
        return false;
    }
}
#method_after
private boolean isWorldReadable(ChangeData cd) throws OrmException, PermissionBackendException, IOException {
    try {
        permissionBackendForChange(anonymous, cd).check(ChangePermission.READ);
    } catch (AuthException ae) {
        return false;
    }
    ProjectState projectState = projectCache.checkedGet(cd.project());
    if (projectState == null) {
        logger.atSevere().log("project state for project %s is null", cd.project());
        return false;
    }
    return projectState.statePermitsRead();
}
#end_block

#method_before
@Override
public void start() {
    if (timer == null) {
        timer = new Timer();
    } else {
        timer.cancel();
    }
    timer.scheduleAtFixedRate(new TimerTask() {

        @Override
        public void run() {
            try {
                MailReceiver.this.handleEmails(true);
            } catch (MailTransferException | IOException e) {
                log.error("Error while fetching emails", e);
            }
        }
    }, 0L, mailSettings.fetchInterval);
}
#method_after
@Override
public void start() {
    if (timer == null) {
        timer = new Timer();
    } else {
        timer.cancel();
    }
    timer.scheduleAtFixedRate(new TimerTask() {

        @Override
        public void run() {
            try {
                MailReceiver.this.handleEmails(true);
            } catch (MailTransferException | IOException e) {
                logger.atSevere().withCause(e).log("Error while fetching emails");
            }
        }
    }, 0L, mailSettings.fetchInterval);
}
#end_block

#method_before
protected void dispatchMailProcessor(List<MailMessage> messages, boolean async) {
    for (MailMessage m : messages) {
        if (async) {
            @SuppressWarnings("unused")
            Future<?> possiblyIgnoredError = workQueue.getDefaultQueue().submit(() -> {
                try {
                    mailProcessor.process(m);
                    requestDeletion(m.id());
                } catch (RestApiException | UpdateException e) {
                    log.error("Mail: Can't process message " + m.id() + " . Won't delete.", e);
                }
            });
        } else {
            // Synchronous processing is used only in tests.
            try {
                mailProcessor.process(m);
                requestDeletion(m.id());
            } catch (RestApiException | UpdateException e) {
                log.error("Mail: Can't process messages. Won't delete.", e);
            }
        }
    }
}
#method_after
protected void dispatchMailProcessor(List<MailMessage> messages, boolean async) {
    for (MailMessage m : messages) {
        if (async) {
            @SuppressWarnings("unused")
            Future<?> possiblyIgnoredError = workQueue.getDefaultQueue().submit(() -> {
                try {
                    mailProcessor.process(m);
                    requestDeletion(m.id());
                } catch (RestApiException | UpdateException e) {
                    logger.atSevere().withCause(e).log("Mail: Can't process message %s . Won't delete.", m.id());
                }
            });
        } else {
            // Synchronous processing is used only in tests.
            try {
                mailProcessor.process(m);
                requestDeletion(m.id());
            } catch (RestApiException | UpdateException e) {
                logger.atSevere().withCause(e).log("Mail: Can't process messages. Won't delete.");
            }
        }
    }
}
#end_block

#method_before
public FakeEmailSenderSubject sent(String messageType, StagedUsers users) {
    message = actual().nextMessage();
    if (message == null) {
        fail("a message was sent");
    }
    recipients = new HashMap<>();
    recipients.put(TO, parseAddresses(message, "To"));
    recipients.put(CC, parseAddresses(message, "CC"));
    recipients.put(BCC, message.rcpt().stream().map(Address::getEmail).filter(e -> !recipients.get(TO).contains(e) && !recipients.get(CC).contains(e)).collect(Collectors.toList()));
    this.users = users;
    if (!message.headers().containsKey("X-Gerrit-MessageType")) {
        fail("a message was sent with X-Gerrit-MessageType header");
    }
    EmailHeader header = message.headers().get("X-Gerrit-MessageType");
    if (!header.equals(new EmailHeader.String(messageType))) {
        fail("message of type " + messageType + " was sent; X-Gerrit-MessageType is " + header);
    }
    // recipients.
    return named(recipientMapToString(recipients, e -> users.emailToName(e)));
}
#method_after
public FakeEmailSenderSubject sent(String messageType, StagedUsers users) {
    message = actual().nextMessage();
    if (message == null) {
        fail("a message was sent");
    }
    recipients = new HashMap<>();
    recipients.put(TO, parseAddresses(message, "To"));
    recipients.put(CC, parseAddresses(message, "Cc"));
    recipients.put(BCC, message.rcpt().stream().map(Address::getEmail).filter(e -> !recipients.get(TO).contains(e) && !recipients.get(CC).contains(e)).collect(toList()));
    this.users = users;
    if (!message.headers().containsKey("X-Gerrit-MessageType")) {
        fail("a message was sent with X-Gerrit-MessageType header");
    }
    EmailHeader header = message.headers().get("X-Gerrit-MessageType");
    if (!header.equals(new EmailHeader.String(messageType))) {
        fail("message of type " + messageType + " was sent; X-Gerrit-MessageType is " + header);
    }
    // recipients.
    return named(recipientMapToString(recipients, users::emailToName));
}
#end_block

#method_before
List<String> parseAddresses(Message msg, String headerName) {
    EmailHeader header = msg.headers().get(headerName);
    if (header == null) {
        return ImmutableList.of();
    }
    Truth.assertThat(header).isInstanceOf(AddressList.class);
    AddressList addrList = (AddressList) header;
    return addrList.getAddressList().stream().map(Address::getEmail).collect(Collectors.toList());
}
#method_after
List<String> parseAddresses(Message msg, String headerName) {
    EmailHeader header = msg.headers().get(headerName);
    if (header == null) {
        return ImmutableList.of();
    }
    Truth.assertThat(header).isInstanceOf(AddressList.class);
    AddressList addrList = (AddressList) header;
    return addrList.getAddressList().stream().map(Address::getEmail).collect(toList());
}
#end_block

#method_before
private TestAccount evictAndCopy(TestAccount account) throws IOException {
    accountCache.evict(account.id);
    return account;
}
#method_after
private TestAccount evictAndCopy(TestAccount account) throws IOException {
    evictAndReindexAccount(account.id);
    return account;
}
#end_block

#method_before
@Override
public Address from(Account.Id fromId) {
    String senderName;
    if (fromId != null) {
        Account a = accountCache.get(fromId).getAccount();
        String fullName = a.getFullName();
        String userEmail = a.getPreferredEmail();
        if (canRelay(userEmail)) {
            return new Address(fullName, userEmail);
        }
        if (fullName == null || "".equals(fullName.trim())) {
            fullName = anonymousCowardName;
        }
        senderName = nameRewriteTmpl.replace("user", fullName).toString();
    } else {
        senderName = serverAddress.getName();
    }
    String senderEmail;
    ParameterizedString senderEmailPattern = new ParameterizedString(serverAddress.getEmail());
    if (senderEmailPattern.getParameterNames().isEmpty()) {
        senderEmail = senderEmailPattern.getRawPattern();
    } else {
        senderEmail = senderEmailPattern.replace("userHash", hashOf(senderName)).toString();
    }
    return new Address(senderName, senderEmail);
}
#method_after
@Override
public Address from(Account.Id fromId) {
    String senderName;
    if (fromId != null) {
        Optional<Account> a = accountCache.get(fromId).map(AccountState::getAccount);
        String fullName = a.map(Account::getFullName).orElse(null);
        String userEmail = a.map(Account::getPreferredEmail).orElse(null);
        if (canRelay(userEmail)) {
            return new Address(fullName, userEmail);
        }
        if (fullName == null || "".equals(fullName.trim())) {
            fullName = anonymousCowardName;
        }
        senderName = nameRewriteTmpl.replace("user", fullName).toString();
    } else {
        senderName = serverAddress.getName();
    }
    String senderEmail;
    ParameterizedString senderEmailPattern = new ParameterizedString(serverAddress.getEmail());
    if (senderEmailPattern.getParameterNames().isEmpty()) {
        senderEmail = senderEmailPattern.getRawPattern();
    } else {
        senderEmail = senderEmailPattern.replace("userHash", hashOf(senderName)).toString();
    }
    return new Address(senderName, senderEmail);
}
#end_block

#method_before
@Override
public Address from(Account.Id fromId) {
    final String senderName;
    if (fromId != null) {
        final Account account = accountCache.get(fromId).getAccount();
        String fullName = account.getFullName();
        if (fullName == null || "".equals(fullName)) {
            fullName = anonymousCowardName;
        }
        senderName = namePattern.replace("user", fullName).toString();
    } else {
        senderName = serverAddress.getName();
    }
    String senderEmail;
    if (senderEmailPattern.getParameterNames().isEmpty()) {
        senderEmail = senderEmailPattern.getRawPattern();
    } else {
        senderEmail = senderEmailPattern.replace("userHash", hashOf(senderName)).toString();
    }
    return new Address(senderName, senderEmail);
}
#method_after
@Override
public Address from(Account.Id fromId) {
    final String senderName;
    if (fromId != null) {
        String fullName = accountCache.get(fromId).map(a -> a.getAccount().getFullName()).orElse(null);
        if (fullName == null || "".equals(fullName)) {
            fullName = anonymousCowardName;
        }
        senderName = namePattern.replace("user", fullName).toString();
    } else {
        senderName = serverAddress.getName();
    }
    String senderEmail;
    if (senderEmailPattern.getParameterNames().isEmpty()) {
        senderEmail = senderEmailPattern.getRawPattern();
    } else {
        senderEmail = senderEmailPattern.replace("userHash", hashOf(senderName)).toString();
    }
    return new Address(senderName, senderEmail);
}
#end_block

#method_before
private ChangeNotesState buildState() {
    return ChangeNotesState.create(tip.copy(), id, new Change.Key(changeId), createdOn, lastUpdatedOn, ownerId, branch, buildCurrentPatchSetId(), subject, topic, originalSubject, submissionId, assignee != null ? assignee.orElse(null) : null, status, Sets.newLinkedHashSet(Lists.reverse(pastAssignees)), hashtags, patchSets, buildApprovals(), ReviewerSet.fromTable(Tables.transpose(reviewers)), ReviewerByEmailSet.fromTable(Tables.transpose(reviewersByEmail)), pendingReviewers, pendingReviewersByEmail, allPastReviewers, buildReviewerUpdates(), submitRecords, buildAllMessages(), buildMessagesByPatchSet(), comments, readOnlyUntil, isPrivate, workInProgress, hasReviewStarted, revertOf);
}
#method_after
private ChangeNotesState buildState() {
    return ChangeNotesState.create(tip.copy(), id, new Change.Key(changeId), createdOn, lastUpdatedOn, ownerId, branch, buildCurrentPatchSetId(), subject, topic, originalSubject, submissionId, assignee != null ? assignee.orElse(null) : null, status, Sets.newLinkedHashSet(Lists.reverse(pastAssignees)), firstNonNull(hashtags, ImmutableSet.of()), patchSets, buildApprovals(), ReviewerSet.fromTable(Tables.transpose(reviewers)), ReviewerByEmailSet.fromTable(Tables.transpose(reviewersByEmail)), pendingReviewers, pendingReviewersByEmail, allPastReviewers, buildReviewerUpdates(), submitRecords, buildAllMessages(), comments, readOnlyUntil, firstNonNull(isPrivate, false), firstNonNull(workInProgress, false), firstNonNull(hasReviewStarted, true), revertOf);
}
#end_block

#method_before
private Account.Id parseRealAccountId(ChangeNotesCommit commit, Account.Id effectiveAccountId) throws ConfigInvalidException {
    String realUser = parseOneFooter(commit, FOOTER_REAL_USER);
    if (realUser == null) {
        return effectiveAccountId;
    }
    PersonIdent ident = RawParseUtils.parsePersonIdent(realUser);
    return noteUtil.parseIdent(ident, id);
}
#method_after
private Account.Id parseRealAccountId(ChangeNotesCommit commit, Account.Id effectiveAccountId) throws ConfigInvalidException {
    String realUser = parseOneFooter(commit, FOOTER_REAL_USER);
    if (realUser == null) {
        return effectiveAccountId;
    }
    PersonIdent ident = RawParseUtils.parsePersonIdent(realUser);
    return legacyChangeNoteRead.parseIdent(ident, id);
}
#end_block

#method_before
private void parseAssignee(ChangeNotesCommit commit) throws ConfigInvalidException {
    if (pastAssignees == null) {
        pastAssignees = Lists.newArrayList();
    }
    String assigneeValue = parseOneFooter(commit, FOOTER_ASSIGNEE);
    if (assigneeValue != null) {
        Optional<Account.Id> parsedAssignee;
        if (assigneeValue.equals("")) {
            // Empty footer found, assignee deleted
            parsedAssignee = Optional.empty();
        } else {
            PersonIdent ident = RawParseUtils.parsePersonIdent(assigneeValue);
            parsedAssignee = Optional.ofNullable(noteUtil.parseIdent(ident, id));
        }
        if (assignee == null) {
            assignee = parsedAssignee;
        }
        if (parsedAssignee.isPresent()) {
            pastAssignees.add(parsedAssignee.get());
        }
    }
}
#method_after
private void parseAssignee(ChangeNotesCommit commit) throws ConfigInvalidException {
    if (pastAssignees == null) {
        pastAssignees = Lists.newArrayList();
    }
    String assigneeValue = parseOneFooter(commit, FOOTER_ASSIGNEE);
    if (assigneeValue != null) {
        Optional<Account.Id> parsedAssignee;
        if (assigneeValue.equals("")) {
            // Empty footer found, assignee deleted
            parsedAssignee = Optional.empty();
        } else {
            PersonIdent ident = RawParseUtils.parsePersonIdent(assigneeValue);
            parsedAssignee = Optional.ofNullable(legacyChangeNoteRead.parseIdent(ident, id));
        }
        if (assignee == null) {
            assignee = parsedAssignee;
        }
        if (parsedAssignee.isPresent()) {
            pastAssignees.add(parsedAssignee.get());
        }
    }
}
#end_block

#method_before
private void parseChangeMessage(PatchSet.Id psId, Account.Id accountId, Account.Id realAccountId, ChangeNotesCommit commit, Timestamp ts) {
    byte[] raw = commit.getRawBuffer();
    int size = raw.length;
    Charset enc = RawParseUtils.parseEncoding(raw);
    int subjectStart = RawParseUtils.commitMessage(raw, 0);
    if (subjectStart < 0 || subjectStart >= size) {
        return;
    }
    int subjectEnd = RawParseUtils.endOfParagraph(raw, subjectStart);
    if (subjectEnd == size) {
        return;
    }
    int changeMessageStart;
    if (raw[subjectEnd] == '\n') {
        // \n\n ends paragraph
        changeMessageStart = subjectEnd + 2;
    } else if (raw[subjectEnd] == '\r') {
        // \r\n\r\n ends paragraph
        changeMessageStart = subjectEnd + 4;
    } else {
        return;
    }
    int ptr = size - 1;
    int changeMessageEnd = -1;
    while (ptr > changeMessageStart) {
        ptr = RawParseUtils.prevLF(raw, ptr, '\r');
        if (ptr == -1) {
            break;
        }
        if (raw[ptr] == '\n') {
            changeMessageEnd = ptr - 1;
            break;
        } else if (raw[ptr] == '\r') {
            changeMessageEnd = ptr - 3;
            break;
        }
    }
    if (ptr <= changeMessageStart) {
        return;
    }
    String changeMsgString = RawParseUtils.decode(enc, raw, changeMessageStart, changeMessageEnd + 1);
    ChangeMessage changeMessage = new ChangeMessage(new ChangeMessage.Key(psId.getParentKey(), commit.name()), accountId, ts, psId);
    changeMessage.setMessage(changeMsgString);
    changeMessage.setTag(tag);
    changeMessage.setRealAuthor(realAccountId);
    changeMessagesByPatchSet.put(psId, changeMessage);
    allChangeMessages.add(changeMessage);
}
#method_after
private void parseChangeMessage(PatchSet.Id psId, Account.Id accountId, Account.Id realAccountId, ChangeNotesCommit commit, Timestamp ts) {
    byte[] raw = commit.getRawBuffer();
    int size = raw.length;
    Charset enc = RawParseUtils.parseEncoding(raw);
    int subjectStart = RawParseUtils.commitMessage(raw, 0);
    if (subjectStart < 0 || subjectStart >= size) {
        return;
    }
    int subjectEnd = RawParseUtils.endOfParagraph(raw, subjectStart);
    if (subjectEnd == size) {
        return;
    }
    int changeMessageStart;
    if (raw[subjectEnd] == '\n') {
        // \n\n ends paragraph
        changeMessageStart = subjectEnd + 2;
    } else if (raw[subjectEnd] == '\r') {
        // \r\n\r\n ends paragraph
        changeMessageStart = subjectEnd + 4;
    } else {
        return;
    }
    int ptr = size - 1;
    int changeMessageEnd = -1;
    while (ptr > changeMessageStart) {
        ptr = RawParseUtils.prevLF(raw, ptr, '\r');
        if (ptr == -1) {
            break;
        }
        if (raw[ptr] == '\n') {
            changeMessageEnd = ptr - 1;
            break;
        } else if (raw[ptr] == '\r') {
            changeMessageEnd = ptr - 3;
            break;
        }
    }
    if (ptr <= changeMessageStart) {
        return;
    }
    String changeMsgString = RawParseUtils.decode(enc, raw, changeMessageStart, changeMessageEnd + 1);
    ChangeMessage changeMessage = new ChangeMessage(new ChangeMessage.Key(psId.getParentKey(), commit.name()), accountId, ts, psId);
    changeMessage.setMessage(changeMsgString);
    changeMessage.setTag(tag);
    changeMessage.setRealAuthor(realAccountId);
    allChangeMessages.add(changeMessage);
}
#end_block

#method_before
private void parseNotes() throws IOException, ConfigInvalidException {
    ObjectReader reader = walk.getObjectReader();
    ChangeNotesCommit tipCommit = walk.parseCommit(tip);
    revisionNoteMap = RevisionNoteMap.parse(noteUtil, id, reader, NoteMap.read(reader, tipCommit), PatchLineComment.Status.PUBLISHED);
    Map<RevId, ChangeRevisionNote> rns = revisionNoteMap.revisionNotes;
    for (Map.Entry<RevId, ChangeRevisionNote> e : rns.entrySet()) {
        for (Comment c : e.getValue().getComments()) {
            comments.put(e.getKey(), c);
        }
    }
    for (PatchSet ps : patchSets.values()) {
        ChangeRevisionNote rn = rns.get(ps.getRevision());
        if (rn != null && rn.getPushCert() != null) {
            ps.setPushCertificate(rn.getPushCert());
        }
    }
}
#method_after
private void parseNotes() throws IOException, ConfigInvalidException {
    ObjectReader reader = walk.getObjectReader();
    ChangeNotesCommit tipCommit = walk.parseCommit(tip);
    revisionNoteMap = RevisionNoteMap.parse(changeNoteJson, legacyChangeNoteRead, id, reader, NoteMap.read(reader, tipCommit), PatchLineComment.Status.PUBLISHED);
    Map<RevId, ChangeRevisionNote> rns = revisionNoteMap.revisionNotes;
    for (Map.Entry<RevId, ChangeRevisionNote> e : rns.entrySet()) {
        for (Comment c : e.getValue().getComments()) {
            comments.put(e.getKey(), c);
        }
    }
    for (PatchSet ps : patchSets.values()) {
        ChangeRevisionNote rn = rns.get(ps.getRevision());
        if (rn != null && rn.getPushCert() != null) {
            ps.setPushCertificate(rn.getPushCert());
        }
    }
}
#end_block

#method_before
private PatchSetApproval parseAddApproval(PatchSet.Id psId, Account.Id committerId, Account.Id realAccountId, Timestamp ts, String line) throws ConfigInvalidException {
    // There are potentially 3 accounts involved here:
    // 1. The account from the commit, which is the effective IdentifiedUser
    // that produced the update.
    // 2. The account in the label footer itself, which is used during submit
    // to copy other users' labels to a new patch set.
    // 3. The account in the Real-user footer, indicating that the whole
    // update operation was executed by this user on behalf of the effective
    // user.
    Account.Id effectiveAccountId;
    String labelVoteStr;
    int s = line.indexOf(' ');
    if (s > 0) {
        // Account in the label line (2) becomes the effective ID of the
        // approval. If there is a real user (3) different from the commit user
        // (2), we actually don't store that anywhere in this case; it's more
        // important to record that the real user (3) actually initiated submit.
        labelVoteStr = line.substring(0, s);
        PersonIdent ident = RawParseUtils.parsePersonIdent(line.substring(s + 1));
        checkFooter(ident != null, FOOTER_LABEL, line);
        effectiveAccountId = noteUtil.parseIdent(ident, id);
    } else {
        labelVoteStr = line;
        effectiveAccountId = committerId;
    }
    LabelVote l;
    try {
        l = LabelVote.parseWithEquals(labelVoteStr);
    } catch (IllegalArgumentException e) {
        ConfigInvalidException pe = parseException("invalid %s: %s", FOOTER_LABEL, line);
        pe.initCause(e);
        throw pe;
    }
    PatchSetApproval psa = new PatchSetApproval(new PatchSetApproval.Key(psId, effectiveAccountId, new LabelId(l.label())), l.value(), ts);
    psa.setTag(tag);
    if (!Objects.equals(realAccountId, committerId)) {
        psa.setRealAccountId(realAccountId);
    }
    ApprovalKey k = ApprovalKey.create(psId, effectiveAccountId, l.label());
    if (!approvals.containsKey(k)) {
        approvals.put(k, psa);
    }
    return psa;
}
#method_after
private PatchSetApproval parseAddApproval(PatchSet.Id psId, Account.Id committerId, Account.Id realAccountId, Timestamp ts, String line) throws ConfigInvalidException {
    // There are potentially 3 accounts involved here:
    // 1. The account from the commit, which is the effective IdentifiedUser
    // that produced the update.
    // 2. The account in the label footer itself, which is used during submit
    // to copy other users' labels to a new patch set.
    // 3. The account in the Real-user footer, indicating that the whole
    // update operation was executed by this user on behalf of the effective
    // user.
    Account.Id effectiveAccountId;
    String labelVoteStr;
    int s = line.indexOf(' ');
    if (s > 0) {
        // Account in the label line (2) becomes the effective ID of the
        // approval. If there is a real user (3) different from the commit user
        // (2), we actually don't store that anywhere in this case; it's more
        // important to record that the real user (3) actually initiated submit.
        labelVoteStr = line.substring(0, s);
        PersonIdent ident = RawParseUtils.parsePersonIdent(line.substring(s + 1));
        checkFooter(ident != null, FOOTER_LABEL, line);
        effectiveAccountId = legacyChangeNoteRead.parseIdent(ident, id);
    } else {
        labelVoteStr = line;
        effectiveAccountId = committerId;
    }
    LabelVote l;
    try {
        l = LabelVote.parseWithEquals(labelVoteStr);
    } catch (IllegalArgumentException e) {
        ConfigInvalidException pe = parseException("invalid %s: %s", FOOTER_LABEL, line);
        pe.initCause(e);
        throw pe;
    }
    PatchSetApproval psa = new PatchSetApproval(new PatchSetApproval.Key(psId, effectiveAccountId, new LabelId(l.label())), l.value(), ts);
    psa.setTag(tag);
    if (!Objects.equals(realAccountId, committerId)) {
        psa.setRealAccountId(realAccountId);
    }
    ApprovalKey k = ApprovalKey.create(psId, effectiveAccountId, l.label());
    if (!approvals.containsKey(k)) {
        approvals.put(k, psa);
    }
    return psa;
}
#end_block

#method_before
private PatchSetApproval parseRemoveApproval(PatchSet.Id psId, Account.Id committerId, Account.Id realAccountId, Timestamp ts, String line) throws ConfigInvalidException {
    // See comments in parseAddApproval about the various users involved.
    Account.Id effectiveAccountId;
    String label;
    int s = line.indexOf(' ');
    if (s > 0) {
        label = line.substring(1, s);
        PersonIdent ident = RawParseUtils.parsePersonIdent(line.substring(s + 1));
        checkFooter(ident != null, FOOTER_LABEL, line);
        effectiveAccountId = noteUtil.parseIdent(ident, id);
    } else {
        label = line.substring(1);
        effectiveAccountId = committerId;
    }
    try {
        LabelType.checkNameInternal(label);
    } catch (IllegalArgumentException e) {
        ConfigInvalidException pe = parseException("invalid %s: %s", FOOTER_LABEL, line);
        pe.initCause(e);
        throw pe;
    }
    // Store an actual 0-vote approval in the map for a removed approval, for
    // several reasons:
    // - This is closer to the ReviewDb representation, which leads to less
    // confusion and special-casing of NoteDb.
    // - More importantly, ApprovalCopier needs an actual approval in order to
    // block copying an earlier approval over a later delete.
    PatchSetApproval remove = new PatchSetApproval(new PatchSetApproval.Key(psId, effectiveAccountId, new LabelId(label)), (short) 0, ts);
    if (!Objects.equals(realAccountId, committerId)) {
        remove.setRealAccountId(realAccountId);
    }
    ApprovalKey k = ApprovalKey.create(psId, effectiveAccountId, label);
    if (!approvals.containsKey(k)) {
        approvals.put(k, remove);
    }
    return remove;
}
#method_after
private PatchSetApproval parseRemoveApproval(PatchSet.Id psId, Account.Id committerId, Account.Id realAccountId, Timestamp ts, String line) throws ConfigInvalidException {
    // See comments in parseAddApproval about the various users involved.
    Account.Id effectiveAccountId;
    String label;
    int s = line.indexOf(' ');
    if (s > 0) {
        label = line.substring(1, s);
        PersonIdent ident = RawParseUtils.parsePersonIdent(line.substring(s + 1));
        checkFooter(ident != null, FOOTER_LABEL, line);
        effectiveAccountId = legacyChangeNoteRead.parseIdent(ident, id);
    } else {
        label = line.substring(1);
        effectiveAccountId = committerId;
    }
    try {
        LabelType.checkNameInternal(label);
    } catch (IllegalArgumentException e) {
        ConfigInvalidException pe = parseException("invalid %s: %s", FOOTER_LABEL, line);
        pe.initCause(e);
        throw pe;
    }
    // Store an actual 0-vote approval in the map for a removed approval, for
    // several reasons:
    // - This is closer to the ReviewDb representation, which leads to less
    // confusion and special-casing of NoteDb.
    // - More importantly, ApprovalCopier needs an actual approval in order to
    // block copying an earlier approval over a later delete.
    PatchSetApproval remove = new PatchSetApproval(new PatchSetApproval.Key(psId, effectiveAccountId, new LabelId(label)), (short) 0, ts);
    if (!Objects.equals(realAccountId, committerId)) {
        remove.setRealAccountId(realAccountId);
    }
    ApprovalKey k = ApprovalKey.create(psId, effectiveAccountId, label);
    if (!approvals.containsKey(k)) {
        approvals.put(k, remove);
    }
    return remove;
}
#end_block

#method_before
private void parseSubmitRecords(List<String> lines) throws ConfigInvalidException {
    SubmitRecord rec = null;
    for (String line : lines) {
        int c = line.indexOf(": ");
        if (c < 0) {
            rec = new SubmitRecord();
            submitRecords.add(rec);
            int s = line.indexOf(' ');
            String statusStr = s >= 0 ? line.substring(0, s) : line;
            rec.status = Enums.getIfPresent(SubmitRecord.Status.class, statusStr).orNull();
            checkFooter(rec.status != null, FOOTER_SUBMITTED_WITH, line);
            if (s >= 0) {
                rec.errorMessage = line.substring(s);
            }
        } else {
            checkFooter(rec != null, FOOTER_SUBMITTED_WITH, line);
            SubmitRecord.Label label = new SubmitRecord.Label();
            if (rec.labels == null) {
                rec.labels = new ArrayList<>();
            }
            rec.labels.add(label);
            label.status = Enums.getIfPresent(SubmitRecord.Label.Status.class, line.substring(0, c)).orNull();
            checkFooter(label.status != null, FOOTER_SUBMITTED_WITH, line);
            int c2 = line.indexOf(": ", c + 2);
            if (c2 >= 0) {
                label.label = line.substring(c + 2, c2);
                PersonIdent ident = RawParseUtils.parsePersonIdent(line.substring(c2 + 2));
                checkFooter(ident != null, FOOTER_SUBMITTED_WITH, line);
                label.appliedBy = noteUtil.parseIdent(ident, id);
            } else {
                label.label = line.substring(c + 2);
            }
        }
    }
}
#method_after
private void parseSubmitRecords(List<String> lines) throws ConfigInvalidException {
    SubmitRecord rec = null;
    for (String line : lines) {
        int c = line.indexOf(": ");
        if (c < 0) {
            rec = new SubmitRecord();
            submitRecords.add(rec);
            int s = line.indexOf(' ');
            String statusStr = s >= 0 ? line.substring(0, s) : line;
            rec.status = Enums.getIfPresent(SubmitRecord.Status.class, statusStr).orNull();
            checkFooter(rec.status != null, FOOTER_SUBMITTED_WITH, line);
            if (s >= 0) {
                rec.errorMessage = line.substring(s);
            }
        } else {
            checkFooter(rec != null, FOOTER_SUBMITTED_WITH, line);
            SubmitRecord.Label label = new SubmitRecord.Label();
            if (rec.labels == null) {
                rec.labels = new ArrayList<>();
            }
            rec.labels.add(label);
            label.status = Enums.getIfPresent(SubmitRecord.Label.Status.class, line.substring(0, c)).orNull();
            checkFooter(label.status != null, FOOTER_SUBMITTED_WITH, line);
            int c2 = line.indexOf(": ", c + 2);
            if (c2 >= 0) {
                label.label = line.substring(c + 2, c2);
                PersonIdent ident = RawParseUtils.parsePersonIdent(line.substring(c2 + 2));
                checkFooter(ident != null, FOOTER_SUBMITTED_WITH, line);
                label.appliedBy = legacyChangeNoteRead.parseIdent(ident, id);
            } else {
                label.label = line.substring(c + 2);
            }
        }
    }
}
#end_block

#method_before
private Account.Id parseIdent(ChangeNotesCommit commit) throws ConfigInvalidException {
    // Check if the author name/email is the same as the committer name/email,
    // i.e. was the server ident at the time this commit was made.
    PersonIdent a = commit.getAuthorIdent();
    PersonIdent c = commit.getCommitterIdent();
    if (a.getName().equals(c.getName()) && a.getEmailAddress().equals(c.getEmailAddress())) {
        return null;
    }
    return noteUtil.parseIdent(commit.getAuthorIdent(), id);
}
#method_after
private Account.Id parseIdent(ChangeNotesCommit commit) throws ConfigInvalidException {
    // Check if the author name/email is the same as the committer name/email,
    // i.e. was the server ident at the time this commit was made.
    PersonIdent a = commit.getAuthorIdent();
    PersonIdent c = commit.getCommitterIdent();
    if (a.getName().equals(c.getName()) && a.getEmailAddress().equals(c.getEmailAddress())) {
        return null;
    }
    return legacyChangeNoteRead.parseIdent(commit.getAuthorIdent(), id);
}
#end_block

#method_before
private void parseReviewer(Timestamp ts, ReviewerStateInternal state, String line) throws ConfigInvalidException {
    PersonIdent ident = RawParseUtils.parsePersonIdent(line);
    if (ident == null) {
        throw invalidFooter(state.getFooterKey(), line);
    }
    Account.Id accountId = noteUtil.parseIdent(ident, id);
    reviewerUpdates.add(ReviewerStatusUpdate.create(ts, ownerId, accountId, state));
    if (!reviewers.containsRow(accountId)) {
        reviewers.put(accountId, state, ts);
    }
}
#method_after
private void parseReviewer(Timestamp ts, ReviewerStateInternal state, String line) throws ConfigInvalidException {
    PersonIdent ident = RawParseUtils.parsePersonIdent(line);
    if (ident == null) {
        throw invalidFooter(state.getFooterKey(), line);
    }
    Account.Id accountId = legacyChangeNoteRead.parseIdent(ident, id);
    reviewerUpdates.add(ReviewerStatusUpdate.create(ts, ownerId, accountId, state));
    if (!reviewers.containsRow(accountId)) {
        reviewers.put(accountId, state, ts);
    }
}
#end_block

#method_before
private void updatePatchSetStates() {
    Set<PatchSet.Id> missing = new TreeSet<>(ReviewDbUtil.intKeyOrdering());
    for (Iterator<PatchSet> it = patchSets.values().iterator(); it.hasNext(); ) {
        PatchSet ps = it.next();
        if (ps.getRevision().equals(PARTIAL_PATCH_SET)) {
            missing.add(ps.getId());
            it.remove();
        }
    }
    for (Map.Entry<PatchSet.Id, PatchSetState> e : patchSetStates.entrySet()) {
        switch(e.getValue()) {
            case PUBLISHED:
            default:
                break;
            case DELETED:
                patchSets.remove(e.getKey());
                break;
        }
    }
    // Post-process other collections to remove items corresponding to deleted
    // (or otherwise missing) patch sets. This is safer than trying to prevent
    // insertion, as it will also filter out items racily added after the patch
    // set was deleted.
    changeMessagesByPatchSet.keys().retainAll(patchSets.keySet());
    int pruned = pruneEntitiesForMissingPatchSets(allChangeMessages, ChangeMessage::getPatchSetId, missing);
    pruned += pruneEntitiesForMissingPatchSets(comments.values(), c -> new PatchSet.Id(id, c.key.patchSetId), missing);
    pruned += pruneEntitiesForMissingPatchSets(approvals.values(), PatchSetApproval::getPatchSetId, missing);
    if (!missing.isEmpty()) {
        log.warn("ignoring {} additional entities due to missing patch sets: {}", pruned, missing);
    }
}
#method_after
private void updatePatchSetStates() {
    Set<PatchSet.Id> missing = new TreeSet<>(ReviewDbUtil.intKeyOrdering());
    for (Iterator<PatchSet> it = patchSets.values().iterator(); it.hasNext(); ) {
        PatchSet ps = it.next();
        if (ps.getRevision().equals(PARTIAL_PATCH_SET)) {
            missing.add(ps.getId());
            it.remove();
        }
    }
    for (Map.Entry<PatchSet.Id, PatchSetState> e : patchSetStates.entrySet()) {
        switch(e.getValue()) {
            case PUBLISHED:
            default:
                break;
            case DELETED:
                patchSets.remove(e.getKey());
                break;
        }
    }
    // Post-process other collections to remove items corresponding to deleted
    // (or otherwise missing) patch sets. This is safer than trying to prevent
    // insertion, as it will also filter out items racily added after the patch
    // set was deleted.
    int pruned = pruneEntitiesForMissingPatchSets(allChangeMessages, ChangeMessage::getPatchSetId, missing);
    pruned += pruneEntitiesForMissingPatchSets(comments.values(), c -> new PatchSet.Id(id, c.key.patchSetId), missing);
    pruned += pruneEntitiesForMissingPatchSets(approvals.values(), PatchSetApproval::getPatchSetId, missing);
    if (!missing.isEmpty()) {
        logger.atWarning().log("ignoring %s additional entities due to missing patch sets: %s", pruned, missing);
    }
}
#end_block

#method_before
public List<Message> getMessages(String changeId, String type) {
    final String idFooter = "\nGerrit-Change-Id: " + changeId + "\n";
    final String typeFooter = "\nGerrit-MessageType: " + type + "\n";
    return getMessages().stream().filter(in -> in.body().contains(idFooter) && in.body().contains(typeFooter)).collect(toList());
}
#method_after
public List<Message> getMessages(String changeId, String type) {
    final String idFooter = "\n" + MailHeader.CHANGE_ID.withDelimiter() + changeId + "\n";
    final String typeFooter = "\n" + MailHeader.MESSAGE_TYPE.withDelimiter() + type + "\n";
    return getMessages().stream().filter(in -> in.body().contains(idFooter) && in.body().contains(typeFooter)).collect(toList());
}
#end_block

#method_before
private void waitForEmails() {
    // default executor).
    for (WorkQueue.Task<?> task : workQueue.getTasks()) {
        if (task.toString().contains("send-email")) {
            try {
                task.get();
            } catch (ExecutionException | InterruptedException e) {
                log.warn("error finishing email task", e);
            }
        }
    }
}
#method_after
private void waitForEmails() {
    // default executor).
    for (WorkQueue.Task<?> task : workQueue.getTasks()) {
        if (task.toString().contains("send-email")) {
            try {
                task.get();
            } catch (ExecutionException | InterruptedException e) {
                logger.atWarning().withCause(e).log("error finishing email task");
            }
        }
    }
}
#end_block

#method_before
@Test
public void newPatchSetsNotifyConfig() throws Exception {
    Address addr = new Address("Watcher", "watcher@example.com");
    NotifyConfig nc = new NotifyConfig();
    nc.addEmail(addr);
    nc.setName("new-patch-set");
    nc.setHeader(NotifyConfig.Header.CC);
    nc.setTypes(EnumSet.of(NotifyType.NEW_PATCHSETS));
    nc.setFilter("message:sekret");
    ProjectConfig cfg = projectCache.checkedGet(project).getConfig();
    cfg.putNotifyConfig("watch", nc);
    saveProjectConfig(project, cfg);
    PushOneCommit.Result r = pushFactory.create(db, admin.getIdent(), testRepo, "original subject", "a", "a1").to("refs/for/master");
    r.assertOkStatus();
    r = pushFactory.create(db, admin.getIdent(), testRepo, "super sekret subject", "a", "a2", r.getChangeId()).to("refs/for/master");
    r.assertOkStatus();
    r = pushFactory.create(db, admin.getIdent(), testRepo, "back to original subject", "a", "a3").to("refs/for/master");
    r.assertOkStatus();
    List<Message> messages = sender.getMessages();
    assertThat(messages).hasSize(1);
    Message m = messages.get(0);
    assertThat(m.rcpt()).containsExactly(addr);
    assertThat(m.body()).contains("Change subject: super sekret subject\n");
    assertThat(m.body()).contains("Gerrit-PatchSet: 2\n");
}
#method_after
@Test
public void newPatchSetsNotifyConfig() throws Exception {
    Address addr = new Address("Watcher", "watcher@example.com");
    NotifyConfig nc = new NotifyConfig();
    nc.addEmail(addr);
    nc.setName("new-patch-set");
    nc.setHeader(NotifyConfig.Header.CC);
    nc.setTypes(EnumSet.of(NotifyType.NEW_PATCHSETS));
    nc.setFilter("message:sekret");
    try (ProjectConfigUpdate u = updateProject(project)) {
        u.getConfig().putNotifyConfig("watch", nc);
        u.save();
    }
    PushOneCommit.Result r = pushFactory.create(db, admin.getIdent(), testRepo, "original subject", "a", "a1").to("refs/for/master");
    r.assertOkStatus();
    r = pushFactory.create(db, admin.getIdent(), testRepo, "super sekret subject", "a", "a2", r.getChangeId()).to("refs/for/master");
    r.assertOkStatus();
    r = pushFactory.create(db, admin.getIdent(), testRepo, "back to original subject", "a", "a3").to("refs/for/master");
    r.assertOkStatus();
    List<Message> messages = sender.getMessages();
    assertThat(messages).hasSize(1);
    Message m = messages.get(0);
    assertThat(m.rcpt()).containsExactly(addr);
    assertThat(m.body()).contains("Change subject: super sekret subject\n");
    assertThat(m.body()).contains("Gerrit-PatchSet: 2\n");
}
#end_block

#method_before
@Test
public void noNotificationForPrivateChangesForWatchersInNotifyConfig() throws Exception {
    Address addr = new Address("Watcher", "watcher@example.com");
    NotifyConfig nc = new NotifyConfig();
    nc.addEmail(addr);
    nc.setName("team");
    nc.setHeader(NotifyConfig.Header.TO);
    nc.setTypes(EnumSet.of(NotifyType.NEW_CHANGES, NotifyType.ALL_COMMENTS));
    ProjectConfig cfg = projectCache.checkedGet(project).getConfig();
    cfg.putNotifyConfig("team", nc);
    saveProjectConfig(project, cfg);
    sender.clear();
    PushOneCommit.Result r = pushFactory.create(db, admin.getIdent(), testRepo, "private change", "a", "a1").to("refs/for/master%private");
    r.assertOkStatus();
    assertThat(sender.getMessages()).isEmpty();
    setApiUser(admin);
    ReviewInput in = new ReviewInput();
    in.message = "comment";
    gApi.changes().id(r.getChangeId()).current().review(in);
    assertThat(sender.getMessages()).isEmpty();
}
#method_after
@Test
public void noNotificationForPrivateChangesForWatchersInNotifyConfig() throws Exception {
    Address addr = new Address("Watcher", "watcher@example.com");
    NotifyConfig nc = new NotifyConfig();
    nc.addEmail(addr);
    nc.setName("team");
    nc.setHeader(NotifyConfig.Header.TO);
    nc.setTypes(EnumSet.of(NotifyType.NEW_CHANGES, NotifyType.ALL_COMMENTS));
    try (ProjectConfigUpdate u = updateProject(project)) {
        u.getConfig().putNotifyConfig("team", nc);
        u.save();
    }
    sender.clear();
    PushOneCommit.Result r = pushFactory.create(db, admin.getIdent(), testRepo, "private change", "a", "a1").to("refs/for/master%private");
    r.assertOkStatus();
    assertThat(sender.getMessages()).isEmpty();
    setApiUser(admin);
    ReviewInput in = new ReviewInput();
    in.message = "comment";
    gApi.changes().id(r.getChangeId()).current().review(in);
    assertThat(sender.getMessages()).isEmpty();
}
#end_block

#method_before
@Test
public void noNotificationForChangeThatIsTurnedPrivateForWatchersInNotifyConfig() throws Exception {
    Address addr = new Address("Watcher", "watcher@example.com");
    NotifyConfig nc = new NotifyConfig();
    nc.addEmail(addr);
    nc.setName("team");
    nc.setHeader(NotifyConfig.Header.TO);
    nc.setTypes(EnumSet.of(NotifyType.NEW_PATCHSETS));
    ProjectConfig cfg = projectCache.checkedGet(project).getConfig();
    cfg.putNotifyConfig("team", nc);
    saveProjectConfig(project, cfg);
    PushOneCommit.Result r = pushFactory.create(db, admin.getIdent(), testRepo, "subject", "a", "a1").to("refs/for/master");
    r.assertOkStatus();
    sender.clear();
    r = pushFactory.create(db, admin.getIdent(), testRepo, "subject", "a", "a2", r.getChangeId()).to("refs/for/master%private");
    r.assertOkStatus();
    assertThat(sender.getMessages()).isEmpty();
}
#method_after
@Test
public void noNotificationForChangeThatIsTurnedPrivateForWatchersInNotifyConfig() throws Exception {
    Address addr = new Address("Watcher", "watcher@example.com");
    NotifyConfig nc = new NotifyConfig();
    nc.addEmail(addr);
    nc.setName("team");
    nc.setHeader(NotifyConfig.Header.TO);
    nc.setTypes(EnumSet.of(NotifyType.NEW_PATCHSETS));
    try (ProjectConfigUpdate u = updateProject(project)) {
        u.getConfig().putNotifyConfig("team", nc);
        u.save();
    }
    PushOneCommit.Result r = pushFactory.create(db, admin.getIdent(), testRepo, "subject", "a", "a1").to("refs/for/master");
    r.assertOkStatus();
    sender.clear();
    r = pushFactory.create(db, admin.getIdent(), testRepo, "subject", "a", "a2", r.getChangeId()).to("refs/for/master%private");
    r.assertOkStatus();
    assertThat(sender.getMessages()).isEmpty();
}
#end_block

#method_before
@Test
public void noNotificationForWipChangesForWatchersInNotifyConfig() throws Exception {
    Address addr = new Address("Watcher", "watcher@example.com");
    NotifyConfig nc = new NotifyConfig();
    nc.addEmail(addr);
    nc.setName("team");
    nc.setHeader(NotifyConfig.Header.TO);
    nc.setTypes(EnumSet.of(NotifyType.NEW_CHANGES, NotifyType.ALL_COMMENTS));
    ProjectConfig cfg = projectCache.checkedGet(project).getConfig();
    cfg.putNotifyConfig("team", nc);
    saveProjectConfig(project, cfg);
    sender.clear();
    PushOneCommit.Result r = pushFactory.create(db, admin.getIdent(), testRepo, "wip change", "a", "a1").to("refs/for/master%wip");
    r.assertOkStatus();
    assertThat(sender.getMessages()).isEmpty();
    setApiUser(admin);
    ReviewInput in = new ReviewInput();
    in.message = "comment";
    gApi.changes().id(r.getChangeId()).current().review(in);
    assertThat(sender.getMessages()).isEmpty();
}
#method_after
@Test
public void noNotificationForWipChangesForWatchersInNotifyConfig() throws Exception {
    Address addr = new Address("Watcher", "watcher@example.com");
    NotifyConfig nc = new NotifyConfig();
    nc.addEmail(addr);
    nc.setName("team");
    nc.setHeader(NotifyConfig.Header.TO);
    nc.setTypes(EnumSet.of(NotifyType.NEW_CHANGES, NotifyType.ALL_COMMENTS));
    try (ProjectConfigUpdate u = updateProject(project)) {
        u.getConfig().putNotifyConfig("team", nc);
        u.save();
    }
    sender.clear();
    PushOneCommit.Result r = pushFactory.create(db, admin.getIdent(), testRepo, "wip change", "a", "a1").to("refs/for/master%wip");
    r.assertOkStatus();
    assertThat(sender.getMessages()).isEmpty();
    setApiUser(admin);
    ReviewInput in = new ReviewInput();
    in.message = "comment";
    gApi.changes().id(r.getChangeId()).current().review(in);
    assertThat(sender.getMessages()).isEmpty();
}
#end_block

#method_before
@Test
public void noNotificationForChangeThatIsTurnedWipForWatchersInNotifyConfig() throws Exception {
    Address addr = new Address("Watcher", "watcher@example.com");
    NotifyConfig nc = new NotifyConfig();
    nc.addEmail(addr);
    nc.setName("team");
    nc.setHeader(NotifyConfig.Header.TO);
    nc.setTypes(EnumSet.of(NotifyType.NEW_PATCHSETS));
    ProjectConfig cfg = projectCache.checkedGet(project).getConfig();
    cfg.putNotifyConfig("team", nc);
    saveProjectConfig(project, cfg);
    PushOneCommit.Result r = pushFactory.create(db, admin.getIdent(), testRepo, "subject", "a", "a1").to("refs/for/master");
    r.assertOkStatus();
    sender.clear();
    r = pushFactory.create(db, admin.getIdent(), testRepo, "subject", "a", "a2", r.getChangeId()).to("refs/for/master%wip");
    r.assertOkStatus();
    assertThat(sender.getMessages()).isEmpty();
}
#method_after
@Test
public void noNotificationForChangeThatIsTurnedWipForWatchersInNotifyConfig() throws Exception {
    Address addr = new Address("Watcher", "watcher@example.com");
    NotifyConfig nc = new NotifyConfig();
    nc.addEmail(addr);
    nc.setName("team");
    nc.setHeader(NotifyConfig.Header.TO);
    nc.setTypes(EnumSet.of(NotifyType.NEW_PATCHSETS));
    try (ProjectConfigUpdate u = updateProject(project)) {
        u.getConfig().putNotifyConfig("team", nc);
        u.save();
    }
    PushOneCommit.Result r = pushFactory.create(db, admin.getIdent(), testRepo, "subject", "a", "a1").to("refs/for/master");
    r.assertOkStatus();
    sender.clear();
    r = pushFactory.create(db, admin.getIdent(), testRepo, "subject", "a", "a2", r.getChangeId()).to("refs/for/master%wip");
    r.assertOkStatus();
    assertThat(sender.getMessages()).isEmpty();
}
#end_block

#method_before
Arguments asUser(CurrentUser otherUser) {
    return new Arguments(db, queryProvider, rewriter, opFactories, hasOperands, userFactory, Providers.of(otherUser), permissionBackend, notesFactory, changeDataFactory, commentsUtil, accountResolver, groupBackend, allProjectsName, allUsersName, patchListCache, repoManager, projectCache, listChildProjects, submitDryRun, conflictsCache, index, indexConfig, listMembers, starredChangesUtil, accountCache, allowsDrafts, notesMigration);
}
#method_after
Arguments asUser(CurrentUser otherUser) {
    return new Arguments(db, queryProvider, rewriter, opFactories, hasOperands, userFactory, Providers.of(otherUser), permissionBackend, notesFactory, changeDataFactory, commentsUtil, accountResolver, groupBackend, allProjectsName, allUsersName, patchListCache, repoManager, projectCache, childProjects, submitDryRun, conflictsCache, index, indexConfig, starredChangesUtil, accountCache, notesMigration, groupMembers, anonymousUserProvider);
}
#end_block

#method_before
@Operator
public Predicate<ChangeData> has(String value) throws QueryParseException {
    if ("star".equalsIgnoreCase(value)) {
        return starredby(self());
    }
    if ("stars".equalsIgnoreCase(value)) {
        return new HasStarsPredicate(self());
    }
    if ("draft".equalsIgnoreCase(value)) {
        return draftby(self());
    }
    if ("edit".equalsIgnoreCase(value)) {
        return new EditByPredicate(self());
    }
    if ("unresolved".equalsIgnoreCase(value)) {
        return new IsUnresolvedPredicate();
    }
    // for plugins the value will be operandName_pluginName
    String[] names = value.split("_");
    if (names.length == 2) {
        ChangeHasOperandFactory op = args.hasOperands.get(names[1], names[0]);
        if (op != null) {
            return op.create(this);
        }
    }
    throw new IllegalArgumentException();
}
#method_after
@Operator
public Predicate<ChangeData> has(String value) throws QueryParseException {
    if ("star".equalsIgnoreCase(value)) {
        return starredby(self());
    }
    if ("stars".equalsIgnoreCase(value)) {
        return new HasStarsPredicate(self());
    }
    if ("draft".equalsIgnoreCase(value)) {
        return draftby(self());
    }
    if ("edit".equalsIgnoreCase(value)) {
        return new EditByPredicate(self());
    }
    if ("unresolved".equalsIgnoreCase(value)) {
        return new IsUnresolvedPredicate();
    }
    // for plugins the value will be operandName_pluginName
    List<String> names = Lists.newArrayList(Splitter.on('_').split(value));
    if (names.size() == 2) {
        ChangeHasOperandFactory op = args.hasOperands.get(names.get(1), names.get(0));
        if (op != null) {
            return op.create(this);
        }
    }
    throw new IllegalArgumentException();
}
#end_block

#method_before
@Operator
public Predicate<ChangeData> parentproject(String name) {
    return new ParentProjectPredicate(args.projectCache, args.listChildProjects, args.self, name);
}
#method_after
@Operator
public Predicate<ChangeData> parentproject(String name) {
    return new ParentProjectPredicate(args.projectCache, args.childProjects, name);
}
#end_block

#method_before
@Operator
public Predicate<ChangeData> label(String name) throws QueryParseException, OrmException, IOException, ConfigInvalidException {
    Set<Account.Id> accounts = null;
    AccountGroup.UUID group = null;
    // Parse for:
    // label:CodeReview=1,user=jsmith or
    // label:CodeReview=1,jsmith or
    // label:CodeReview=1,group=android_approvers or
    // label:CodeReview=1,android_approvers
    // user/groups without a label will first attempt to match user
    // Special case: votes by owners can be tracked with ",owner":
    // label:Code-Review+2,owner
    // label:Code-Review+2,user=owner
    String[] splitReviewer = name.split(",", 2);
    // remove all but the vote piece, e.g.'CodeReview=1'
    name = splitReviewer[0];
    if (splitReviewer.length == 2) {
        // process the user/group piece
        PredicateArgs lblArgs = new PredicateArgs(splitReviewer[1]);
        for (Map.Entry<String, String> pair : lblArgs.keyValue.entrySet()) {
            if (pair.getKey().equalsIgnoreCase(ARG_ID_USER)) {
                if (pair.getValue().equals(ARG_ID_OWNER)) {
                    accounts = Collections.singleton(OWNER_ACCOUNT_ID);
                } else {
                    accounts = parseAccount(pair.getValue());
                }
            } else if (pair.getKey().equalsIgnoreCase(ARG_ID_GROUP)) {
                group = parseGroup(pair.getValue()).getUUID();
            } else {
                throw new QueryParseException("Invalid argument identifier '" + pair.getKey() + "'");
            }
        }
        for (String value : lblArgs.positional) {
            if (accounts != null || group != null) {
                throw new QueryParseException("more than one user/group specified (" + value + ")");
            }
            try {
                if (value.equals(ARG_ID_OWNER)) {
                    accounts = Collections.singleton(OWNER_ACCOUNT_ID);
                } else {
                    accounts = parseAccount(value);
                }
            } catch (QueryParseException qpex) {
                // (accounts get precedence)
                try {
                    group = parseGroup(value).getUUID();
                } catch (QueryParseException e) {
                    throw error("Neither user nor group " + value + " found", e);
                }
            }
        }
    }
    // expand a group predicate into multiple user predicates
    if (group != null) {
        Set<Account.Id> allMembers = args.listMembers.get().getTransitiveMembers(group).stream().map(a -> new Account.Id(a._accountId)).collect(toSet());
        int maxLimit = args.indexConfig.maxLimit();
        if (allMembers.size() > maxLimit) {
            // limit the number of query terms otherwise Gerrit will barf
            accounts = ImmutableSet.copyOf(Iterables.limit(allMembers, maxLimit));
        } else {
            accounts = allMembers;
        }
    }
    // If the vote piece looks like Code-Review=NEED with a valid non-numeric
    // submit record status, interpret as a submit record query.
    int eq = name.indexOf('=');
    if (args.getSchema().hasField(ChangeField.SUBMIT_RECORD) && eq > 0) {
        String statusName = name.substring(eq + 1).toUpperCase();
        if (!isInt(statusName)) {
            SubmitRecord.Label.Status status = Enums.getIfPresent(SubmitRecord.Label.Status.class, statusName).orNull();
            if (status == null) {
                throw error("Invalid label status " + statusName + " in " + name);
            }
            return SubmitRecordPredicate.create(name.substring(0, eq), status, accounts);
        }
    }
    return new LabelPredicate(args, name, accounts, group);
}
#method_after
@Operator
public Predicate<ChangeData> label(String name) throws QueryParseException, OrmException, IOException, ConfigInvalidException {
    Set<Account.Id> accounts = null;
    AccountGroup.UUID group = null;
    // Parse for:
    // label:CodeReview=1,user=jsmith or
    // label:CodeReview=1,jsmith or
    // label:CodeReview=1,group=android_approvers or
    // label:CodeReview=1,android_approvers
    // user/groups without a label will first attempt to match user
    // Special case: votes by owners can be tracked with ",owner":
    // label:Code-Review+2,owner
    // label:Code-Review+2,user=owner
    List<String> splitReviewer = Lists.newArrayList(Splitter.on(',').limit(2).split(name));
    // remove all but the vote piece, e.g.'CodeReview=1'
    name = splitReviewer.get(0);
    if (splitReviewer.size() == 2) {
        // process the user/group piece
        PredicateArgs lblArgs = new PredicateArgs(splitReviewer.get(1));
        for (Map.Entry<String, String> pair : lblArgs.keyValue.entrySet()) {
            if (pair.getKey().equalsIgnoreCase(ARG_ID_USER)) {
                if (pair.getValue().equals(ARG_ID_OWNER)) {
                    accounts = Collections.singleton(OWNER_ACCOUNT_ID);
                } else {
                    accounts = parseAccount(pair.getValue());
                }
            } else if (pair.getKey().equalsIgnoreCase(ARG_ID_GROUP)) {
                group = parseGroup(pair.getValue()).getUUID();
            } else {
                throw new QueryParseException("Invalid argument identifier '" + pair.getKey() + "'");
            }
        }
        for (String value : lblArgs.positional) {
            if (accounts != null || group != null) {
                throw new QueryParseException("more than one user/group specified (" + value + ")");
            }
            try {
                if (value.equals(ARG_ID_OWNER)) {
                    accounts = Collections.singleton(OWNER_ACCOUNT_ID);
                } else {
                    accounts = parseAccount(value);
                }
            } catch (QueryParseException qpex) {
                // (accounts get precedence)
                try {
                    group = parseGroup(value).getUUID();
                } catch (QueryParseException e) {
                    throw error("Neither user nor group " + value + " found", e);
                }
            }
        }
    }
    if (group != null) {
        accounts = getMembers(group);
    }
    // If the vote piece looks like Code-Review=NEED with a valid non-numeric
    // submit record status, interpret as a submit record query.
    int eq = name.indexOf('=');
    if (args.getSchema().hasField(ChangeField.SUBMIT_RECORD) && eq > 0) {
        String statusName = name.substring(eq + 1).toUpperCase();
        if (!isInt(statusName)) {
            SubmitRecord.Label.Status status = Enums.getIfPresent(SubmitRecord.Label.Status.class, statusName).orNull();
            if (status == null) {
                throw error("Invalid label status " + statusName + " in " + name);
            }
            return SubmitRecordPredicate.create(name.substring(0, eq), status, accounts);
        }
    }
    return new LabelPredicate(args, name, accounts, group);
}
#end_block

#method_before
@Operator
public Predicate<ChangeData> visibleto(String who) throws QueryParseException, OrmException, IOException, ConfigInvalidException {
    if (isSelf(who)) {
        return is_visible();
    }
    Set<Account.Id> m = args.accountResolver.findAll(who);
    if (!m.isEmpty()) {
        List<Predicate<ChangeData>> p = Lists.newArrayListWithCapacity(m.size());
        for (Account.Id id : m) {
            return visibleto(args.userFactory.create(id));
        }
        return Predicate.or(p);
    }
    // If its not an account, maybe its a group?
    // 
    Collection<GroupReference> suggestions = args.groupBackend.suggest(who, null);
    if (!suggestions.isEmpty()) {
        HashSet<AccountGroup.UUID> ids = new HashSet<>();
        for (GroupReference ref : suggestions) {
            ids.add(ref.getUUID());
        }
        return visibleto(new SingleGroupUser(ids));
    }
    throw error("No user or group matches \"" + who + "\".");
}
#method_after
@Operator
public Predicate<ChangeData> visibleto(String who) throws QueryParseException, OrmException, IOException, ConfigInvalidException {
    if (isSelf(who)) {
        return is_visible();
    }
    Set<Account.Id> m = args.accountResolver.findAll(who);
    if (!m.isEmpty()) {
        List<Predicate<ChangeData>> p = Lists.newArrayListWithCapacity(m.size());
        for (Account.Id id : m) {
            return visibleto(args.userFactory.create(id));
        }
        return Predicate.or(p);
    }
    // If its not an account, maybe its a group?
    Collection<GroupReference> suggestions = args.groupBackend.suggest(who, null);
    if (!suggestions.isEmpty()) {
        HashSet<AccountGroup.UUID> ids = new HashSet<>();
        for (GroupReference ref : suggestions) {
            ids.add(ref.getUUID());
        }
        return visibleto(new SingleGroupUser(ids));
    }
    throw error("No user or group matches \"" + who + "\".");
}
#end_block

#method_before
public Predicate<ChangeData> visibleto(CurrentUser user) {
    return new ChangeIsVisibleToPredicate(args.db, args.notesFactory, user, args.permissionBackend);
}
#method_after
public Predicate<ChangeData> visibleto(CurrentUser user) {
    return new ChangeIsVisibleToPredicate(args.db, args.notesFactory, user, args.permissionBackend, args.projectCache, args.anonymousUserProvider);
}
#end_block

#method_before
@Operator
public Predicate<ChangeData> ownerin(String group) throws QueryParseException {
    GroupReference g = GroupBackends.findBestSuggestion(args.groupBackend, group);
    if (g == null) {
        throw error("Group " + group + " not found");
    }
    return new OwnerinPredicate(args.userFactory, g.getUUID());
}
#method_after
@Operator
public Predicate<ChangeData> ownerin(String group) throws QueryParseException, IOException {
    GroupReference g = GroupBackends.findBestSuggestion(args.groupBackend, group);
    if (g == null) {
        throw error("Group " + group + " not found");
    }
    AccountGroup.UUID groupId = g.getUUID();
    GroupDescription.Basic groupDescription = args.groupBackend.get(groupId);
    if (!(groupDescription instanceof GroupDescription.Internal)) {
        return new OwnerinPredicate(args.userFactory, groupId);
    }
    Set<Account.Id> accounts = getMembers(groupId);
    List<OwnerPredicate> p = Lists.newArrayListWithCapacity(accounts.size());
    for (Account.Id id : accounts) {
        p.add(new OwnerPredicate(id));
    }
    return Predicate.or(p);
}
#end_block

#method_before
@Operator
public Predicate<ChangeData> destination(String name) throws QueryParseException {
    try (Repository git = args.repoManager.openRepository(args.allUsersName)) {
        VersionedAccountDestinations d = VersionedAccountDestinations.forUser(self());
        d.load(git);
        Set<Branch.NameKey> destinations = d.getDestinationList().getDestinations(name);
        if (destinations != null) {
            return new DestinationPredicate(destinations, name);
        }
    } catch (RepositoryNotFoundException e) {
        throw new QueryParseException("Unknown named destination (no " + args.allUsersName + " repo): " + name, e);
    } catch (IOException | ConfigInvalidException e) {
        throw new QueryParseException("Error parsing named destination: " + name, e);
    }
    throw new QueryParseException("Unknown named destination: " + name);
}
#method_after
@Operator
public Predicate<ChangeData> destination(String name) throws QueryParseException {
    try (Repository git = args.repoManager.openRepository(args.allUsersName)) {
        VersionedAccountDestinations d = VersionedAccountDestinations.forUser(self());
        d.load(git);
        Set<Branch.NameKey> destinations = d.getDestinationList().getDestinations(name);
        if (destinations != null && !destinations.isEmpty()) {
            return new DestinationPredicate(destinations, name);
        }
    } catch (RepositoryNotFoundException e) {
        throw new QueryParseException("Unknown named destination (no " + args.allUsersName + " repo): " + name, e);
    } catch (IOException | ConfigInvalidException e) {
        throw new QueryParseException("Error parsing named destination: " + name, e);
    }
    throw new QueryParseException("Unknown named destination: " + name);
}
#end_block

#method_before
private Predicate<ChangeData> getAuthorOrCommitterFullTextPredicate(String who, Function<String, Predicate<ChangeData>> fullPredicateFunc) throws QueryParseException {
    Set<String> parts = SchemaUtil.getNameParts(who);
    if (parts.isEmpty()) {
        throw error("invalid value");
    }
    List<Predicate<ChangeData>> predicates = parts.stream().map(fullPredicateFunc).collect(Collectors.toList());
    return Predicate.and(predicates);
}
#method_after
private Predicate<ChangeData> getAuthorOrCommitterFullTextPredicate(String who, Function<String, Predicate<ChangeData>> fullPredicateFunc) throws QueryParseException {
    Set<String> parts = SchemaUtil.getNameParts(who);
    if (parts.isEmpty()) {
        throw error("invalid value");
    }
    List<Predicate<ChangeData>> predicates = parts.stream().map(fullPredicateFunc).collect(toList());
    return Predicate.and(predicates);
}
#end_block

#method_before
@Override
public boolean shouldProcessMessage(MailMessage message) {
    if (mode == ListFilterMode.OFF) {
        return true;
    }
    boolean match = mailPattern.matcher(message.from().getEmail()).find();
    if (mode == ListFilterMode.WHITELIST && !match || mode == ListFilterMode.BLACKLIST && match) {
        log.info("Mail message from " + message.from() + " rejected by list filter");
        return false;
    }
    return true;
}
#method_after
@Override
public boolean shouldProcessMessage(MailMessage message) {
    if (mode == ListFilterMode.OFF) {
        return true;
    }
    boolean match = mailPattern.matcher(message.from().getEmail()).find();
    if (mode == ListFilterMode.WHITELIST && !match || mode == ListFilterMode.BLACKLIST && match) {
        logger.atInfo().log("Mail message from %s rejected by list filter", message.from());
        return false;
    }
    return true;
}
#end_block

#method_before
@ConfigSuite.Default
public static Config enableSignedPushConfig() {
    Config cfg = new Config();
    cfg.setBoolean("receive", null, "enableSignedPush", true);
    return cfg;
}
#method_after
@ConfigSuite.Default
public static Config enableSignedPushConfig() {
    Config cfg = new Config();
    cfg.setBoolean("receive", null, "enableSignedPush", true);
    // Disable the staleness checker so that tests that verify the number of expected index events
    // are stable.
    cfg.setBoolean("index", null, "autoReindexIfStale", false);
    return cfg;
}
#end_block

#method_before
@Test
public void create() throws Exception {
    // account creation + external ID creation
    Account.Id accountId = create(2);
    refUpdateCounter.assertRefUpdateFor(RefUpdateCounter.projectRef(allUsers, RefNames.refsUsers(accountId)), RefUpdateCounter.projectRef(allUsers, RefNames.REFS_EXTERNAL_IDS), RefUpdateCounter.projectRef(allUsers, RefNames.REFS_SEQUENCES + Sequences.NAME_ACCOUNTS));
}
#method_after
@Test
public void create() throws Exception {
    AccountInput input = new AccountInput();
    input.username = "foo";
    input.name = "Foo";
    input.email = "foo@example.com";
    AccountInfo accountInfo = gApi.accounts().create(input).get();
    assertThat(accountInfo._accountId).isNotNull();
    assertThat(accountInfo.username).isEqualTo(input.username);
    assertThat(accountInfo.name).isEqualTo(input.name);
    assertThat(accountInfo.email).isEqualTo(input.email);
    assertThat(accountInfo.status).isNull();
    Account.Id accountId = new Account.Id(accountInfo._accountId);
    // account creation + external ID creation
    accountIndexedCounter.assertReindexOf(accountId, 2);
    assertThat(externalIds.byAccount(accountId)).containsExactly(ExternalId.createUsername(input.username, accountId, null), ExternalId.createEmail(accountId, input.email));
}
#end_block

#method_before
@Test
public void updateNonExistingAccount() throws Exception {
    Account.Id nonExistingAccountId = new Account.Id(999999);
    AtomicBoolean consumerCalled = new AtomicBoolean();
    Account account = accountsUpdate.create().update(nonExistingAccountId, a -> consumerCalled.set(true));
    assertThat(account).isNull();
    assertThat(consumerCalled.get()).isFalse();
}
#method_after
@Test
public void updateNonExistingAccount() throws Exception {
    Account.Id nonExistingAccountId = new Account.Id(999999);
    AtomicBoolean consumerCalled = new AtomicBoolean();
    Optional<AccountState> accountState = accountsUpdateProvider.get().update("Update Non-Existing Account", nonExistingAccountId, a -> consumerCalled.set(true));
    assertThat(accountState).isEmpty();
    assertThat(consumerCalled.get()).isFalse();
}
#end_block

#method_before
@Test
public void updateAccountWithoutAccountConfigNoteDb() throws Exception {
    TestAccount anonymousCoward = accountCreator.create();
    assertUserBranchWithoutAccountConfig(anonymousCoward.getId());
    String status = "OOO";
    Account account = accountsUpdate.create().update(anonymousCoward.getId(), a -> a.setStatus(status));
    assertThat(account).isNotNull();
    assertThat(account.getFullName()).isNull();
    assertThat(account.getStatus()).isEqualTo(status);
    assertUserBranch(anonymousCoward.getId(), null, status);
}
#method_after
@Test
public void updateAccountWithoutAccountConfigNoteDb() throws Exception {
    TestAccount anonymousCoward = accountCreator.create();
    assertUserBranchWithoutAccountConfig(anonymousCoward.getId());
    String status = "OOO";
    Optional<AccountState> accountState = accountsUpdateProvider.get().update("Set status", anonymousCoward.getId(), u -> u.setStatus(status));
    assertThat(accountState).isPresent();
    Account account = accountState.get().getAccount();
    assertThat(account.getFullName()).isNull();
    assertThat(account.getStatus()).isEqualTo(status);
    assertUserBranch(anonymousCoward.getId(), null, status);
}
#end_block

#method_before
private void assertUserBranch(Account.Id accountId, @Nullable String name, @Nullable String status) throws Exception {
    try (Repository repo = repoManager.openRepository(allUsers);
        RevWalk rw = new RevWalk(repo);
        ObjectReader or = repo.newObjectReader()) {
        Ref ref = repo.exactRef(RefNames.refsUsers(accountId));
        assertThat(ref).isNotNull();
        RevCommit c = rw.parseCommit(ref.getObjectId());
        long timestampDiffMs = Math.abs(c.getCommitTime() * 1000L - accountCache.get(accountId).getAccount().getRegisteredOn().getTime());
        assertThat(timestampDiffMs).isAtMost(ChangeRebuilderImpl.MAX_WINDOW_MS);
        // Check the 'account.config' file.
        try (TreeWalk tw = TreeWalk.forPath(or, AccountConfig.ACCOUNT_CONFIG, c.getTree())) {
            if (name != null || status != null) {
                assertThat(tw).isNotNull();
                Config cfg = new Config();
                cfg.fromText(new String(or.open(tw.getObjectId(0), OBJ_BLOB).getBytes(), UTF_8));
                assertThat(cfg.getString(AccountConfig.ACCOUNT, null, AccountConfig.KEY_FULL_NAME)).isEqualTo(name);
                assertThat(cfg.getString(AccountConfig.ACCOUNT, null, AccountConfig.KEY_STATUS)).isEqualTo(status);
            } else {
                // No account properties were set, hence an 'account.config' file was not created.
                assertThat(tw).isNull();
            }
        }
    }
}
#method_after
private void assertUserBranch(Account.Id accountId, @Nullable String name, @Nullable String status) throws Exception {
    try (Repository repo = repoManager.openRepository(allUsers);
        RevWalk rw = new RevWalk(repo);
        ObjectReader or = repo.newObjectReader()) {
        Ref ref = repo.exactRef(RefNames.refsUsers(accountId));
        assertThat(ref).isNotNull();
        RevCommit c = rw.parseCommit(ref.getObjectId());
        long timestampDiffMs = Math.abs(c.getCommitTime() * 1000L - getAccount(accountId).getRegisteredOn().getTime());
        assertThat(timestampDiffMs).isAtMost(ChangeRebuilderImpl.MAX_WINDOW_MS);
        // Check the 'account.config' file.
        try (TreeWalk tw = TreeWalk.forPath(or, AccountProperties.ACCOUNT_CONFIG, c.getTree())) {
            if (name != null || status != null) {
                assertThat(tw).isNotNull();
                Config cfg = new Config();
                cfg.fromText(new String(or.open(tw.getObjectId(0), OBJ_BLOB).getBytes(), UTF_8));
                assertThat(cfg.getString(AccountProperties.ACCOUNT, null, AccountProperties.KEY_FULL_NAME)).isEqualTo(name);
                assertThat(cfg.getString(AccountProperties.ACCOUNT, null, AccountProperties.KEY_STATUS)).isEqualTo(status);
            } else {
                // No account properties were set, hence an 'account.config' file was not created.
                assertThat(tw).isNull();
            }
        }
    }
}
#end_block

#method_before
@Test
public void deleteEmailFromCustomExternalIdSchemes() throws Exception {
    String email = "foo.bar@example.com";
    String extId1 = "foo:bar";
    String extId2 = "foo:baz";
    List<ExternalId> extIds = ImmutableList.of(ExternalId.createWithEmail(ExternalId.Key.parse(extId1), admin.id, email), ExternalId.createWithEmail(ExternalId.Key.parse(extId2), admin.id, email));
    externalIdsUpdateFactory.create().insert(extIds);
    accountIndexedCounter.assertReindexOf(admin);
    assertThat(gApi.accounts().self().getExternalIds().stream().map(e -> e.identity).collect(toSet())).containsAllOf(extId1, extId2);
    resetCurrentApiUser();
    assertThat(getEmails()).contains(email);
    gApi.accounts().self().deleteEmail(email);
    accountIndexedCounter.assertReindexOf(admin);
    resetCurrentApiUser();
    assertThat(getEmails()).doesNotContain(email);
    assertThat(gApi.accounts().self().getExternalIds().stream().map(e -> e.identity).collect(toSet())).containsNoneOf(extId1, extId2);
}
#method_after
@Test
public void deleteEmailFromCustomExternalIdSchemes() throws Exception {
    String email = "foo.bar@example.com";
    String extId1 = "foo:bar";
    String extId2 = "foo:baz";
    accountsUpdateProvider.get().update("Add External IDs", admin.id, u -> u.addExternalId(ExternalId.createWithEmail(ExternalId.Key.parse(extId1), admin.id, email)).addExternalId(ExternalId.createWithEmail(ExternalId.Key.parse(extId2), admin.id, email)));
    accountIndexedCounter.assertReindexOf(admin);
    assertThat(gApi.accounts().self().getExternalIds().stream().map(e -> e.identity).collect(toSet())).containsAllOf(extId1, extId2);
    resetCurrentApiUser();
    assertThat(getEmails()).contains(email);
    gApi.accounts().self().deleteEmail(email);
    accountIndexedCounter.assertReindexOf(admin);
    resetCurrentApiUser();
    assertThat(getEmails()).doesNotContain(email);
    assertThat(gApi.accounts().self().getExternalIds().stream().map(e -> e.identity).collect(toSet())).containsNoneOf(extId1, extId2);
}
#end_block

#method_before
@Test
public void lookUpByEmail() throws Exception {
    // exact match with scheme "mailto:"
    assertEmail(emails.getAccountFor(admin.email), admin);
    // exact match with other scheme
    String email = "foo.bar@example.com";
    externalIdsUpdateFactory.create().insert(ExternalId.createWithEmail(ExternalId.Key.parse("foo:bar"), admin.id, email));
    assertEmail(emails.getAccountFor(email), admin);
    // wrong case doesn't match
    assertThat(emails.getAccountFor(admin.email.toUpperCase(Locale.US))).isEmpty();
    // prefix doesn't match
    assertThat(emails.getAccountFor(admin.email.substring(0, admin.email.indexOf('@')))).isEmpty();
    // non-existing doesn't match
    assertThat(emails.getAccountFor("non-existing@example.com")).isEmpty();
    // lookup several accounts by email at once
    ImmutableSetMultimap<String, Account.Id> byEmails = emails.getAccountsFor(admin.email, user.email);
    assertEmail(byEmails.get(admin.email), admin);
    assertEmail(byEmails.get(user.email), user);
}
#method_after
@Test
public void lookUpByEmail() throws Exception {
    // exact match with scheme "mailto:"
    assertEmail(emails.getAccountFor(admin.email), admin);
    // exact match with other scheme
    String email = "foo.bar@example.com";
    accountsUpdateProvider.get().update("Add Email", admin.id, u -> u.addExternalId(ExternalId.createWithEmail(ExternalId.Key.parse("foo:bar"), admin.id, email)));
    assertEmail(emails.getAccountFor(email), admin);
    // wrong case doesn't match
    assertThat(emails.getAccountFor(admin.email.toUpperCase(Locale.US))).isEmpty();
    // prefix doesn't match
    assertThat(emails.getAccountFor(admin.email.substring(0, admin.email.indexOf('@')))).isEmpty();
    // non-existing doesn't match
    assertThat(emails.getAccountFor("non-existing@example.com")).isEmpty();
    // lookup several accounts by email at once
    ImmutableSetMultimap<String, Account.Id> byEmails = emails.getAccountsFor(admin.email, user.email);
    assertEmail(byEmails.get(admin.email), admin);
    assertEmail(byEmails.get(user.email), user);
}
#end_block

#method_before
@Test
public void lookUpByPreferredEmail() throws Exception {
    // create an inconsistent account that has a preferred email without external ID
    String prefix = "foo.preferred";
    String prefEmail = prefix + "@example.com";
    TestAccount foo = accountCreator.create(name("foo"));
    accountsUpdate.create().update(foo.id, a -> a.setPreferredEmail(prefEmail));
    // verify that the account is still found when using the preferred email to lookup the account
    ImmutableSet<Account.Id> accountsByPrefEmail = emails.getAccountFor(prefEmail);
    assertThat(accountsByPrefEmail).hasSize(1);
    assertThat(Iterables.getOnlyElement(accountsByPrefEmail)).isEqualTo(foo.id);
    // look up by email prefix doesn't find the account
    accountsByPrefEmail = emails.getAccountFor(prefix);
    assertThat(accountsByPrefEmail).isEmpty();
    // look up by other case doesn't find the account
    accountsByPrefEmail = emails.getAccountFor(prefEmail.toUpperCase(Locale.US));
    assertThat(accountsByPrefEmail).isEmpty();
}
#method_after
@Test
public void lookUpByPreferredEmail() throws Exception {
    // create an inconsistent account that has a preferred email without external ID
    String prefix = "foo.preferred";
    String prefEmail = prefix + "@example.com";
    TestAccount foo = accountCreator.create(name("foo"));
    accountsUpdateProvider.get().update("Set Preferred Email", foo.id, u -> u.setPreferredEmail(prefEmail));
    // verify that the account is still found when using the preferred email to lookup the account
    ImmutableSet<Account.Id> accountsByPrefEmail = emails.getAccountFor(prefEmail);
    assertThat(accountsByPrefEmail).hasSize(1);
    assertThat(Iterables.getOnlyElement(accountsByPrefEmail)).isEqualTo(foo.id);
    // look up by email prefix doesn't find the account
    accountsByPrefEmail = emails.getAccountFor(prefix);
    assertThat(accountsByPrefEmail).isEmpty();
    // look up by other case doesn't find the account
    accountsByPrefEmail = emails.getAccountFor(prefEmail.toUpperCase(Locale.US));
    assertThat(accountsByPrefEmail).isEmpty();
}
#end_block

#method_before
@Test
public void putStatus() throws Exception {
    List<String> statuses = ImmutableList.of("OOO", "Busy");
    AccountInfo info;
    for (String status : statuses) {
        gApi.accounts().self().setStatus(status);
        admin.status = status;
        info = gApi.accounts().self().get();
        assertUser(info, admin);
        accountIndexedCounter.assertReindexOf(admin);
    }
}
#method_after
@Test
public void putStatus() throws Exception {
    List<String> statuses = ImmutableList.of("OOO", "Busy");
    AccountInfo info;
    for (String status : statuses) {
        gApi.accounts().self().setStatus(status);
        info = gApi.accounts().self().get();
        assertUser(info, admin, status);
        accountIndexedCounter.assertReindexOf(admin);
    }
    gApi.accounts().self().setStatus(null);
    info = gApi.accounts().self().get();
    assertUser(info, admin);
    accountIndexedCounter.assertReindexOf(admin);
}
#end_block

#method_before
@Test
@Sandboxed
public void fetchUserBranch() throws Exception {
    setApiUser(user);
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers, user);
    String userRefName = RefNames.refsUsers(user.id);
    // remove default READ permissions
    ProjectConfig cfg = projectCache.checkedGet(allUsers).getConfig();
    cfg.getAccessSection(RefNames.REFS_USERS + "${" + RefPattern.USERID_SHARDED + "}", true).remove(new Permission(Permission.READ));
    saveProjectConfig(allUsers, cfg);
    // deny READ permission that is inherited from All-Projects
    deny(allUsers, RefNames.REFS + "*", Permission.READ, ANONYMOUS_USERS);
    // fetching user branch without READ permission fails
    try {
        fetch(allUsersRepo, userRefName + ":userRef");
        fail("user branch is visible although no READ permission is granted");
    } catch (TransportException e) {
    // expected because no READ granted on user branch
    }
    // allow each user to read its own user branch
    grant(allUsers, RefNames.REFS_USERS + "${" + RefPattern.USERID_SHARDED + "}", Permission.READ, false, REGISTERED_USERS);
    // fetch user branch using refs/users/YY/XXXXXXX
    fetch(allUsersRepo, userRefName + ":userRef");
    Ref userRef = allUsersRepo.getRepository().exactRef("userRef");
    assertThat(userRef).isNotNull();
    // fetch user branch using refs/users/self
    fetch(allUsersRepo, RefNames.REFS_USERS_SELF + ":userSelfRef");
    Ref userSelfRef = allUsersRepo.getRepository().getRefDatabase().exactRef("userSelfRef");
    assertThat(userSelfRef).isNotNull();
    assertThat(userSelfRef.getObjectId()).isEqualTo(userRef.getObjectId());
    accountIndexedCounter.assertNoReindex();
    // fetching user branch of another user fails
    String otherUserRefName = RefNames.refsUsers(admin.id);
    exception.expect(TransportException.class);
    exception.expectMessage("Remote does not have " + otherUserRefName + " available for fetch.");
    fetch(allUsersRepo, otherUserRefName + ":otherUserRef");
}
#method_after
@Test
public void fetchUserBranch() throws Exception {
    setApiUser(user);
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers, user);
    String userRefName = RefNames.refsUsers(user.id);
    // remove default READ permissions
    try (ProjectConfigUpdate u = updateProject(allUsers)) {
        u.getConfig().getAccessSection(RefNames.REFS_USERS + "${" + RefPattern.USERID_SHARDED + "}", true).remove(new Permission(Permission.READ));
        u.save();
    }
    // deny READ permission that is inherited from All-Projects
    deny(allUsers, RefNames.REFS + "*", Permission.READ, ANONYMOUS_USERS);
    // fetching user branch without READ permission fails
    try {
        fetch(allUsersRepo, userRefName + ":userRef");
        fail("user branch is visible although no READ permission is granted");
    } catch (TransportException e) {
    // expected because no READ granted on user branch
    }
    // allow each user to read its own user branch
    grant(allUsers, RefNames.REFS_USERS + "${" + RefPattern.USERID_SHARDED + "}", Permission.READ, false, REGISTERED_USERS);
    // fetch user branch using refs/users/YY/XXXXXXX
    fetch(allUsersRepo, userRefName + ":userRef");
    Ref userRef = allUsersRepo.getRepository().exactRef("userRef");
    assertThat(userRef).isNotNull();
    // fetch user branch using refs/users/self
    fetch(allUsersRepo, RefNames.REFS_USERS_SELF + ":userSelfRef");
    Ref userSelfRef = allUsersRepo.getRepository().getRefDatabase().exactRef("userSelfRef");
    assertThat(userSelfRef).isNotNull();
    assertThat(userSelfRef.getObjectId()).isEqualTo(userRef.getObjectId());
    accountIndexedCounter.assertNoReindex();
    // fetching user branch of another user fails
    String otherUserRefName = RefNames.refsUsers(admin.id);
    exception.expect(TransportException.class);
    exception.expectMessage("Remote does not have " + otherUserRefName + " available for fetch.");
    fetch(allUsersRepo, otherUserRefName + ":otherUserRef");
}
#end_block

#method_before
@Test
public void pushAccountConfigToUserBranchForReviewAndSubmit() throws Exception {
    String userRef = RefNames.refsUsers(admin.id);
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers);
    fetch(allUsersRepo, userRef + ":userRef");
    allUsersRepo.reset("userRef");
    Config ac = getAccountConfig(allUsersRepo);
    ac.setString(AccountConfig.ACCOUNT, null, AccountConfig.KEY_STATUS, "out-of-office");
    PushOneCommit.Result r = pushFactory.create(db, admin.getIdent(), allUsersRepo, "Update account config", AccountConfig.ACCOUNT_CONFIG, ac.toText()).to(MagicBranch.NEW_CHANGE + userRef);
    r.assertOkStatus();
    accountIndexedCounter.assertNoReindex();
    assertThat(r.getChange().change().getDest().get()).isEqualTo(userRef);
    gApi.changes().id(r.getChangeId()).current().review(ReviewInput.approve());
    gApi.changes().id(r.getChangeId()).current().submit();
    accountIndexedCounter.assertReindexOf(admin);
    AccountInfo info = gApi.accounts().self().get();
    assertThat(info.email).isEqualTo(admin.email);
    assertThat(info.name).isEqualTo(admin.fullName);
    assertThat(info.status).isEqualTo("out-of-office");
}
#method_after
@Test
public void pushAccountConfigToUserBranchForReviewAndSubmit() throws Exception {
    String userRef = RefNames.refsUsers(admin.id);
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers);
    fetch(allUsersRepo, userRef + ":userRef");
    allUsersRepo.reset("userRef");
    Config ac = getAccountConfig(allUsersRepo);
    ac.setString(AccountProperties.ACCOUNT, null, AccountProperties.KEY_STATUS, "out-of-office");
    PushOneCommit.Result r = pushFactory.create(db, admin.getIdent(), allUsersRepo, "Update account config", AccountProperties.ACCOUNT_CONFIG, ac.toText()).to(MagicBranch.NEW_CHANGE + userRef);
    r.assertOkStatus();
    accountIndexedCounter.assertNoReindex();
    assertThat(r.getChange().change().getDest().get()).isEqualTo(userRef);
    gApi.changes().id(r.getChangeId()).current().review(ReviewInput.approve());
    gApi.changes().id(r.getChangeId()).current().submit();
    accountIndexedCounter.assertReindexOf(admin);
    AccountInfo info = gApi.accounts().self().get();
    assertThat(info.email).isEqualTo(admin.email);
    assertThat(info.name).isEqualTo(admin.fullName);
    assertThat(info.status).isEqualTo("out-of-office");
}
#end_block

#method_before
@Test
public void pushAccountConfigWithPrefEmailThatDoesNotExistAsExtIdToUserBranchForReviewAndSubmit() throws Exception {
    TestAccount foo = accountCreator.create(name("foo"));
    String userRef = RefNames.refsUsers(foo.id);
    accountIndexedCounter.clear();
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers);
    fetch(allUsersRepo, userRef + ":userRef");
    allUsersRepo.reset("userRef");
    String email = "some.email@example.com";
    Config ac = getAccountConfig(allUsersRepo);
    ac.setString(AccountConfig.ACCOUNT, null, AccountConfig.KEY_PREFERRED_EMAIL, email);
    PushOneCommit.Result r = pushFactory.create(db, admin.getIdent(), allUsersRepo, "Update account config", AccountConfig.ACCOUNT_CONFIG, ac.toText()).to(MagicBranch.NEW_CHANGE + userRef);
    r.assertOkStatus();
    accountIndexedCounter.assertNoReindex();
    assertThat(r.getChange().change().getDest().get()).isEqualTo(userRef);
    setApiUser(foo);
    gApi.changes().id(r.getChangeId()).current().review(ReviewInput.approve());
    gApi.changes().id(r.getChangeId()).current().submit();
    accountIndexedCounter.assertReindexOf(foo);
    AccountInfo info = gApi.accounts().self().get();
    assertThat(info.email).isEqualTo(email);
    assertThat(info.name).isEqualTo(foo.fullName);
}
#method_after
@Test
public void pushAccountConfigWithPrefEmailThatDoesNotExistAsExtIdToUserBranchForReviewAndSubmit() throws Exception {
    TestAccount foo = accountCreator.create(name("foo"), name("foo") + "@example.com", "Foo");
    String userRef = RefNames.refsUsers(foo.id);
    accountIndexedCounter.clear();
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers, foo);
    fetch(allUsersRepo, userRef + ":userRef");
    allUsersRepo.reset("userRef");
    String email = "some.email@example.com";
    Config ac = getAccountConfig(allUsersRepo);
    ac.setString(AccountProperties.ACCOUNT, null, AccountProperties.KEY_PREFERRED_EMAIL, email);
    PushOneCommit.Result r = pushFactory.create(db, foo.getIdent(), allUsersRepo, "Update account config", AccountProperties.ACCOUNT_CONFIG, ac.toText()).to(MagicBranch.NEW_CHANGE + userRef);
    r.assertOkStatus();
    accountIndexedCounter.assertNoReindex();
    assertThat(r.getChange().change().getDest().get()).isEqualTo(userRef);
    setApiUser(foo);
    gApi.changes().id(r.getChangeId()).current().review(ReviewInput.approve());
    gApi.changes().id(r.getChangeId()).current().submit();
    accountIndexedCounter.assertReindexOf(foo);
    AccountInfo info = gApi.accounts().self().get();
    assertThat(info.email).isEqualTo(email);
    assertThat(info.name).isEqualTo(foo.fullName);
}
#end_block

#method_before
@Test
public void pushAccountConfigToUserBranchForReviewIsRejectedOnSubmitIfConfigIsInvalid() throws Exception {
    String userRef = RefNames.refsUsers(admin.id);
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers);
    fetch(allUsersRepo, userRef + ":userRef");
    allUsersRepo.reset("userRef");
    PushOneCommit.Result r = pushFactory.create(db, admin.getIdent(), allUsersRepo, "Update account config", AccountConfig.ACCOUNT_CONFIG, "invalid config").to(MagicBranch.NEW_CHANGE + userRef);
    r.assertOkStatus();
    accountIndexedCounter.assertNoReindex();
    assertThat(r.getChange().change().getDest().get()).isEqualTo(userRef);
    gApi.changes().id(r.getChangeId()).current().review(ReviewInput.approve());
    exception.expect(ResourceConflictException.class);
    exception.expectMessage(String.format("invalid account configuration: commit '%s' has an invalid '%s' file for account '%s':" + " Invalid config file %s in commit %s", r.getCommit().name(), AccountConfig.ACCOUNT_CONFIG, admin.id, AccountConfig.ACCOUNT_CONFIG, r.getCommit().name()));
    gApi.changes().id(r.getChangeId()).current().submit();
}
#method_after
@Test
public void pushAccountConfigToUserBranchForReviewIsRejectedOnSubmitIfConfigIsInvalid() throws Exception {
    String userRef = RefNames.refsUsers(admin.id);
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers);
    fetch(allUsersRepo, userRef + ":userRef");
    allUsersRepo.reset("userRef");
    PushOneCommit.Result r = pushFactory.create(db, admin.getIdent(), allUsersRepo, "Update account config", AccountProperties.ACCOUNT_CONFIG, "invalid config").to(MagicBranch.NEW_CHANGE + userRef);
    r.assertOkStatus();
    accountIndexedCounter.assertNoReindex();
    assertThat(r.getChange().change().getDest().get()).isEqualTo(userRef);
    gApi.changes().id(r.getChangeId()).current().review(ReviewInput.approve());
    exception.expect(ResourceConflictException.class);
    exception.expectMessage(String.format("invalid account configuration: commit '%s' has an invalid '%s' file for account '%s':" + " Invalid config file %s in commit %s", r.getCommit().name(), AccountProperties.ACCOUNT_CONFIG, admin.id, AccountProperties.ACCOUNT_CONFIG, r.getCommit().name()));
    gApi.changes().id(r.getChangeId()).current().submit();
}
#end_block

#method_before
@Test
public void pushAccountConfigToUserBranchForReviewIsRejectedOnSubmitIfPreferredEmailIsInvalid() throws Exception {
    String userRef = RefNames.refsUsers(admin.id);
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers);
    fetch(allUsersRepo, userRef + ":userRef");
    allUsersRepo.reset("userRef");
    String noEmail = "no.email";
    Config ac = getAccountConfig(allUsersRepo);
    ac.setString(AccountConfig.ACCOUNT, null, AccountConfig.KEY_PREFERRED_EMAIL, noEmail);
    PushOneCommit.Result r = pushFactory.create(db, admin.getIdent(), allUsersRepo, "Update account config", AccountConfig.ACCOUNT_CONFIG, ac.toText()).to(MagicBranch.NEW_CHANGE + userRef);
    r.assertOkStatus();
    accountIndexedCounter.assertNoReindex();
    assertThat(r.getChange().change().getDest().get()).isEqualTo(userRef);
    gApi.changes().id(r.getChangeId()).current().review(ReviewInput.approve());
    exception.expect(ResourceConflictException.class);
    exception.expectMessage(String.format("invalid account configuration: invalid preferred email '%s' for account '%s'", noEmail, admin.id));
    gApi.changes().id(r.getChangeId()).current().submit();
}
#method_after
@Test
public void pushAccountConfigToUserBranchForReviewIsRejectedOnSubmitIfPreferredEmailIsInvalid() throws Exception {
    String userRef = RefNames.refsUsers(admin.id);
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers);
    fetch(allUsersRepo, userRef + ":userRef");
    allUsersRepo.reset("userRef");
    String noEmail = "no.email";
    Config ac = getAccountConfig(allUsersRepo);
    ac.setString(AccountProperties.ACCOUNT, null, AccountProperties.KEY_PREFERRED_EMAIL, noEmail);
    PushOneCommit.Result r = pushFactory.create(db, admin.getIdent(), allUsersRepo, "Update account config", AccountProperties.ACCOUNT_CONFIG, ac.toText()).to(MagicBranch.NEW_CHANGE + userRef);
    r.assertOkStatus();
    accountIndexedCounter.assertNoReindex();
    assertThat(r.getChange().change().getDest().get()).isEqualTo(userRef);
    gApi.changes().id(r.getChangeId()).current().review(ReviewInput.approve());
    exception.expect(ResourceConflictException.class);
    exception.expectMessage(String.format("invalid account configuration: invalid preferred email '%s' for account '%s'", noEmail, admin.id));
    gApi.changes().id(r.getChangeId()).current().submit();
}
#end_block

#method_before
@Test
public void pushAccountConfigToUserBranchForReviewIsRejectedOnSubmitIfOwnAccountIsDeactivated() throws Exception {
    String userRef = RefNames.refsUsers(admin.id);
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers);
    fetch(allUsersRepo, userRef + ":userRef");
    allUsersRepo.reset("userRef");
    Config ac = getAccountConfig(allUsersRepo);
    ac.setBoolean(AccountConfig.ACCOUNT, null, AccountConfig.KEY_ACTIVE, false);
    PushOneCommit.Result r = pushFactory.create(db, admin.getIdent(), allUsersRepo, "Update account config", AccountConfig.ACCOUNT_CONFIG, ac.toText()).to(MagicBranch.NEW_CHANGE + userRef);
    r.assertOkStatus();
    accountIndexedCounter.assertNoReindex();
    assertThat(r.getChange().change().getDest().get()).isEqualTo(userRef);
    gApi.changes().id(r.getChangeId()).current().review(ReviewInput.approve());
    exception.expect(ResourceConflictException.class);
    exception.expectMessage("invalid account configuration: cannot deactivate own account");
    gApi.changes().id(r.getChangeId()).current().submit();
}
#method_after
@Test
public void pushAccountConfigToUserBranchForReviewIsRejectedOnSubmitIfOwnAccountIsDeactivated() throws Exception {
    String userRef = RefNames.refsUsers(admin.id);
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers);
    fetch(allUsersRepo, userRef + ":userRef");
    allUsersRepo.reset("userRef");
    Config ac = getAccountConfig(allUsersRepo);
    ac.setBoolean(AccountProperties.ACCOUNT, null, AccountProperties.KEY_ACTIVE, false);
    PushOneCommit.Result r = pushFactory.create(db, admin.getIdent(), allUsersRepo, "Update account config", AccountProperties.ACCOUNT_CONFIG, ac.toText()).to(MagicBranch.NEW_CHANGE + userRef);
    r.assertOkStatus();
    accountIndexedCounter.assertNoReindex();
    assertThat(r.getChange().change().getDest().get()).isEqualTo(userRef);
    gApi.changes().id(r.getChangeId()).current().review(ReviewInput.approve());
    exception.expect(ResourceConflictException.class);
    exception.expectMessage("invalid account configuration: cannot deactivate own account");
    gApi.changes().id(r.getChangeId()).current().submit();
}
#end_block

#method_before
@Test
public void pushAccountConfigToUserBranchForReviewDeactivateOtherAccount() throws Exception {
    TestAccount foo = accountCreator.create(name("foo"));
    assertThat(gApi.accounts().id(foo.id.get()).getActive()).isTrue();
    String userRef = RefNames.refsUsers(foo.id);
    accountIndexedCounter.clear();
    InternalGroup adminGroup = groupCache.get(new AccountGroup.NameKey("Administrators")).orElse(null);
    grant(allUsers, userRef, Permission.PUSH, false, adminGroup.getGroupUUID());
    grantLabel("Code-Review", -2, 2, allUsers, userRef, false, adminGroup.getGroupUUID(), false);
    grant(allUsers, userRef, Permission.SUBMIT, false, adminGroup.getGroupUUID());
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers);
    fetch(allUsersRepo, userRef + ":userRef");
    allUsersRepo.reset("userRef");
    Config ac = getAccountConfig(allUsersRepo);
    ac.setBoolean(AccountConfig.ACCOUNT, null, AccountConfig.KEY_ACTIVE, false);
    PushOneCommit.Result r = pushFactory.create(db, admin.getIdent(), allUsersRepo, "Update account config", AccountConfig.ACCOUNT_CONFIG, ac.toText()).to(MagicBranch.NEW_CHANGE + userRef);
    r.assertOkStatus();
    accountIndexedCounter.assertNoReindex();
    assertThat(r.getChange().change().getDest().get()).isEqualTo(userRef);
    gApi.changes().id(r.getChangeId()).current().review(ReviewInput.approve());
    gApi.changes().id(r.getChangeId()).current().submit();
    accountIndexedCounter.assertReindexOf(foo);
    assertThat(gApi.accounts().id(foo.id.get()).getActive()).isFalse();
}
#method_after
@Test
public void pushAccountConfigToUserBranchForReviewDeactivateOtherAccount() throws Exception {
    allowGlobalCapabilities(REGISTERED_USERS, GlobalCapability.ACCESS_DATABASE);
    TestAccount foo = accountCreator.create(name("foo"));
    assertThat(gApi.accounts().id(foo.id.get()).getActive()).isTrue();
    String userRef = RefNames.refsUsers(foo.id);
    accountIndexedCounter.clear();
    grant(allUsers, userRef, Permission.PUSH, false, adminGroupUuid());
    grantLabel("Code-Review", -2, 2, allUsers, userRef, false, adminGroupUuid(), false);
    grant(allUsers, userRef, Permission.SUBMIT, false, adminGroupUuid());
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers);
    fetch(allUsersRepo, userRef + ":userRef");
    allUsersRepo.reset("userRef");
    Config ac = getAccountConfig(allUsersRepo);
    ac.setBoolean(AccountProperties.ACCOUNT, null, AccountProperties.KEY_ACTIVE, false);
    PushOneCommit.Result r = pushFactory.create(db, admin.getIdent(), allUsersRepo, "Update account config", AccountProperties.ACCOUNT_CONFIG, ac.toText()).to(MagicBranch.NEW_CHANGE + userRef);
    r.assertOkStatus();
    accountIndexedCounter.assertNoReindex();
    assertThat(r.getChange().change().getDest().get()).isEqualTo(userRef);
    gApi.changes().id(r.getChangeId()).current().review(ReviewInput.approve());
    gApi.changes().id(r.getChangeId()).current().submit();
    accountIndexedCounter.assertReindexOf(foo);
    assertThat(gApi.accounts().id(foo.id.get()).getActive()).isFalse();
}
#end_block

#method_before
@Test
public void pushWatchConfigToUserBranch() throws Exception {
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers);
    fetch(allUsersRepo, RefNames.refsUsers(admin.id) + ":userRef");
    allUsersRepo.reset("userRef");
    Config wc = new Config();
    wc.setString(WatchConfig.PROJECT, project.get(), WatchConfig.KEY_NOTIFY, WatchConfig.NotifyValue.create(null, EnumSet.of(NotifyType.ALL_COMMENTS)).toString());
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), allUsersRepo, "Add project watch", WatchConfig.WATCH_CONFIG, wc.toText());
    push.to(RefNames.REFS_USERS_SELF).assertOkStatus();
    accountIndexedCounter.assertReindexOf(admin);
    String invalidNotifyValue = "]invalid[";
    wc.setString(WatchConfig.PROJECT, project.get(), WatchConfig.KEY_NOTIFY, invalidNotifyValue);
    push = pushFactory.create(db, admin.getIdent(), allUsersRepo, "Add invalid project watch", WatchConfig.WATCH_CONFIG, wc.toText());
    PushOneCommit.Result r = push.to(RefNames.REFS_USERS_SELF);
    r.assertErrorStatus("invalid watch configuration");
    r.assertMessage(String.format("%s: Invalid project watch of account %d for project %s: %s", WatchConfig.WATCH_CONFIG, admin.getId().get(), project.get(), invalidNotifyValue));
}
#method_after
@Test
public void pushWatchConfigToUserBranch() throws Exception {
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers);
    fetch(allUsersRepo, RefNames.refsUsers(admin.id) + ":userRef");
    allUsersRepo.reset("userRef");
    Config wc = new Config();
    wc.setString(ProjectWatches.PROJECT, project.get(), ProjectWatches.KEY_NOTIFY, ProjectWatches.NotifyValue.create(null, EnumSet.of(NotifyType.ALL_COMMENTS)).toString());
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), allUsersRepo, "Add project watch", ProjectWatches.WATCH_CONFIG, wc.toText());
    push.to(RefNames.REFS_USERS_SELF).assertOkStatus();
    accountIndexedCounter.assertReindexOf(admin);
    String invalidNotifyValue = "]invalid[";
    wc.setString(ProjectWatches.PROJECT, project.get(), ProjectWatches.KEY_NOTIFY, invalidNotifyValue);
    push = pushFactory.create(db, admin.getIdent(), allUsersRepo, "Add invalid project watch", ProjectWatches.WATCH_CONFIG, wc.toText());
    PushOneCommit.Result r = push.to(RefNames.REFS_USERS_SELF);
    r.assertErrorStatus("invalid account configuration");
    r.assertMessage(String.format("%s: Invalid project watch of account %d for project %s: %s", ProjectWatches.WATCH_CONFIG, admin.getId().get(), project.get(), invalidNotifyValue));
}
#end_block

#method_before
@Test
public void pushAccountConfigToUserBranch() throws Exception {
    TestAccount oooUser = accountCreator.create("away", "away@mail.invalid", "Ambrose Way");
    setApiUser(oooUser);
    // Must clone as oooUser to ensure the push is allowed.
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers, oooUser);
    fetch(allUsersRepo, RefNames.refsUsers(oooUser.id) + ":userRef");
    allUsersRepo.reset("userRef");
    Config ac = getAccountConfig(allUsersRepo);
    ac.setString(AccountConfig.ACCOUNT, null, AccountConfig.KEY_STATUS, "out-of-office");
    accountIndexedCounter.clear();
    pushFactory.create(db, oooUser.getIdent(), allUsersRepo, "Update account config", AccountConfig.ACCOUNT_CONFIG, ac.toText()).to(RefNames.refsUsers(oooUser.id)).assertOkStatus();
    accountIndexedCounter.assertReindexOf(oooUser);
    AccountInfo info = gApi.accounts().self().get();
    assertThat(info.email).isEqualTo(oooUser.email);
    assertThat(info.name).isEqualTo(oooUser.fullName);
    assertThat(info.status).isEqualTo("out-of-office");
}
#method_after
@Test
public void pushAccountConfigToUserBranch() throws Exception {
    TestAccount oooUser = accountCreator.create("away", "away@mail.invalid", "Ambrose Way");
    setApiUser(oooUser);
    // Must clone as oooUser to ensure the push is allowed.
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers, oooUser);
    fetch(allUsersRepo, RefNames.refsUsers(oooUser.id) + ":userRef");
    allUsersRepo.reset("userRef");
    Config ac = getAccountConfig(allUsersRepo);
    ac.setString(AccountProperties.ACCOUNT, null, AccountProperties.KEY_STATUS, "out-of-office");
    accountIndexedCounter.clear();
    pushFactory.create(db, oooUser.getIdent(), allUsersRepo, "Update account config", AccountProperties.ACCOUNT_CONFIG, ac.toText()).to(RefNames.refsUsers(oooUser.id)).assertOkStatus();
    accountIndexedCounter.assertReindexOf(oooUser);
    AccountInfo info = gApi.accounts().self().get();
    assertThat(info.email).isEqualTo(oooUser.email);
    assertThat(info.name).isEqualTo(oooUser.fullName);
    assertThat(info.status).isEqualTo("out-of-office");
}
#end_block

#method_before
@Test
public void pushAccountConfigToUserBranchIsRejectedIfConfigIsInvalid() throws Exception {
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers);
    fetch(allUsersRepo, RefNames.refsUsers(admin.id) + ":userRef");
    allUsersRepo.reset("userRef");
    PushOneCommit.Result r = pushFactory.create(db, admin.getIdent(), allUsersRepo, "Update account config", AccountConfig.ACCOUNT_CONFIG, "invalid config").to(RefNames.REFS_USERS_SELF);
    r.assertErrorStatus("invalid account configuration");
    r.assertMessage(String.format("commit '%s' has an invalid '%s' file for account '%s':" + " Invalid config file %s in commit %s", r.getCommit().name(), AccountConfig.ACCOUNT_CONFIG, admin.id, AccountConfig.ACCOUNT_CONFIG, r.getCommit().name()));
    accountIndexedCounter.assertNoReindex();
}
#method_after
@Test
public void pushAccountConfigToUserBranchIsRejectedIfConfigIsInvalid() throws Exception {
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers);
    fetch(allUsersRepo, RefNames.refsUsers(admin.id) + ":userRef");
    allUsersRepo.reset("userRef");
    PushOneCommit.Result r = pushFactory.create(db, admin.getIdent(), allUsersRepo, "Update account config", AccountProperties.ACCOUNT_CONFIG, "invalid config").to(RefNames.REFS_USERS_SELF);
    r.assertErrorStatus("invalid account configuration");
    r.assertMessage(String.format("commit '%s' has an invalid '%s' file for account '%s':" + " Invalid config file %s in commit %s", r.getCommit().name(), AccountProperties.ACCOUNT_CONFIG, admin.id, AccountProperties.ACCOUNT_CONFIG, r.getCommit().name()));
    accountIndexedCounter.assertNoReindex();
}
#end_block

#method_before
@Test
public void pushAccountConfigToUserBranchIsRejectedIfPreferredEmailIsInvalid() throws Exception {
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers);
    fetch(allUsersRepo, RefNames.refsUsers(admin.id) + ":userRef");
    allUsersRepo.reset("userRef");
    String noEmail = "no.email";
    Config ac = getAccountConfig(allUsersRepo);
    ac.setString(AccountConfig.ACCOUNT, null, AccountConfig.KEY_PREFERRED_EMAIL, noEmail);
    PushOneCommit.Result r = pushFactory.create(db, admin.getIdent(), allUsersRepo, "Update account config", AccountConfig.ACCOUNT_CONFIG, ac.toText()).to(RefNames.REFS_USERS_SELF);
    r.assertErrorStatus("invalid account configuration");
    r.assertMessage(String.format("invalid preferred email '%s' for account '%s'", noEmail, admin.id));
    accountIndexedCounter.assertNoReindex();
}
#method_after
@Test
public void pushAccountConfigToUserBranchIsRejectedIfPreferredEmailIsInvalid() throws Exception {
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers);
    fetch(allUsersRepo, RefNames.refsUsers(admin.id) + ":userRef");
    allUsersRepo.reset("userRef");
    String noEmail = "no.email";
    Config ac = getAccountConfig(allUsersRepo);
    ac.setString(AccountProperties.ACCOUNT, null, AccountProperties.KEY_PREFERRED_EMAIL, noEmail);
    PushOneCommit.Result r = pushFactory.create(db, admin.getIdent(), allUsersRepo, "Update account config", AccountProperties.ACCOUNT_CONFIG, ac.toText()).to(RefNames.REFS_USERS_SELF);
    r.assertErrorStatus("invalid account configuration");
    r.assertMessage(String.format("invalid preferred email '%s' for account '%s'", noEmail, admin.id));
    accountIndexedCounter.assertNoReindex();
}
#end_block

#method_before
@Test
public void pushAccountConfigToUserBranchInvalidPreferredEmailButNotChanged() throws Exception {
    TestAccount foo = accountCreator.create(name("foo"));
    String userRef = RefNames.refsUsers(foo.id);
    String noEmail = "no.email";
    accountsUpdate.create().update(foo.id, a -> a.setPreferredEmail(noEmail));
    accountIndexedCounter.clear();
    InternalGroup adminGroup = groupCache.get(new AccountGroup.NameKey("Administrators")).orElse(null);
    grant(allUsers, userRef, Permission.PUSH, false, adminGroup.getGroupUUID());
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers);
    fetch(allUsersRepo, userRef + ":userRef");
    allUsersRepo.reset("userRef");
    String status = "in vacation";
    Config ac = getAccountConfig(allUsersRepo);
    ac.setString(AccountConfig.ACCOUNT, null, AccountConfig.KEY_STATUS, status);
    pushFactory.create(db, admin.getIdent(), allUsersRepo, "Update account config", AccountConfig.ACCOUNT_CONFIG, ac.toText()).to(userRef).assertOkStatus();
    accountIndexedCounter.assertReindexOf(foo);
    AccountInfo info = gApi.accounts().id(foo.id.get()).get();
    assertThat(info.email).isEqualTo(noEmail);
    assertThat(info.name).isEqualTo(foo.fullName);
    assertThat(info.status).isEqualTo(status);
}
#method_after
@Test
public void pushAccountConfigToUserBranchInvalidPreferredEmailButNotChanged() throws Exception {
    TestAccount foo = accountCreator.create(name("foo"), name("foo") + "@example.com", "Foo");
    String userRef = RefNames.refsUsers(foo.id);
    String noEmail = "no.email";
    accountsUpdateProvider.get().update("Set Preferred Email", foo.id, u -> u.setPreferredEmail(noEmail));
    accountIndexedCounter.clear();
    grant(allUsers, userRef, Permission.PUSH, false, REGISTERED_USERS);
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers, foo);
    fetch(allUsersRepo, userRef + ":userRef");
    allUsersRepo.reset("userRef");
    String status = "in vacation";
    Config ac = getAccountConfig(allUsersRepo);
    ac.setString(AccountProperties.ACCOUNT, null, AccountProperties.KEY_STATUS, status);
    pushFactory.create(db, foo.getIdent(), allUsersRepo, "Update account config", AccountProperties.ACCOUNT_CONFIG, ac.toText()).to(userRef).assertOkStatus();
    accountIndexedCounter.assertReindexOf(foo);
    AccountInfo info = gApi.accounts().id(foo.id.get()).get();
    assertThat(info.email).isEqualTo(noEmail);
    assertThat(info.name).isEqualTo(foo.fullName);
    assertThat(info.status).isEqualTo(status);
}
#end_block

#method_before
@Test
public void pushAccountConfigToUserBranchIfPreferredEmailDoesNotExistAsExtId() throws Exception {
    TestAccount foo = accountCreator.create(name("foo"));
    String userRef = RefNames.refsUsers(foo.id);
    accountIndexedCounter.clear();
    InternalGroup adminGroup = groupCache.get(new AccountGroup.NameKey("Administrators")).orElse(null);
    grant(allUsers, userRef, Permission.PUSH, false, adminGroup.getGroupUUID());
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers);
    fetch(allUsersRepo, userRef + ":userRef");
    allUsersRepo.reset("userRef");
    String email = "some.email@example.com";
    Config ac = getAccountConfig(allUsersRepo);
    ac.setString(AccountConfig.ACCOUNT, null, AccountConfig.KEY_PREFERRED_EMAIL, email);
    pushFactory.create(db, admin.getIdent(), allUsersRepo, "Update account config", AccountConfig.ACCOUNT_CONFIG, ac.toText()).to(userRef).assertOkStatus();
    accountIndexedCounter.assertReindexOf(foo);
    AccountInfo info = gApi.accounts().id(foo.id.get()).get();
    assertThat(info.email).isEqualTo(email);
    assertThat(info.name).isEqualTo(foo.fullName);
}
#method_after
@Test
public void pushAccountConfigToUserBranchIfPreferredEmailDoesNotExistAsExtId() throws Exception {
    TestAccount foo = accountCreator.create(name("foo"), name("foo") + "@example.com", "Foo");
    String userRef = RefNames.refsUsers(foo.id);
    accountIndexedCounter.clear();
    grant(allUsers, userRef, Permission.PUSH, false, adminGroupUuid());
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers, foo);
    fetch(allUsersRepo, userRef + ":userRef");
    allUsersRepo.reset("userRef");
    String email = "some.email@example.com";
    Config ac = getAccountConfig(allUsersRepo);
    ac.setString(AccountProperties.ACCOUNT, null, AccountProperties.KEY_PREFERRED_EMAIL, email);
    pushFactory.create(db, foo.getIdent(), allUsersRepo, "Update account config", AccountProperties.ACCOUNT_CONFIG, ac.toText()).to(userRef).assertOkStatus();
    accountIndexedCounter.assertReindexOf(foo);
    AccountInfo info = gApi.accounts().id(foo.id.get()).get();
    assertThat(info.email).isEqualTo(email);
    assertThat(info.name).isEqualTo(foo.fullName);
}
#end_block

#method_before
@Test
public void pushAccountConfigToUserBranchIsRejectedIfOwnAccountIsDeactivated() throws Exception {
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers);
    fetch(allUsersRepo, RefNames.refsUsers(admin.id) + ":userRef");
    allUsersRepo.reset("userRef");
    Config ac = getAccountConfig(allUsersRepo);
    ac.setBoolean(AccountConfig.ACCOUNT, null, AccountConfig.KEY_ACTIVE, false);
    PushOneCommit.Result r = pushFactory.create(db, admin.getIdent(), allUsersRepo, "Update account config", AccountConfig.ACCOUNT_CONFIG, ac.toText()).to(RefNames.REFS_USERS_SELF);
    r.assertErrorStatus("invalid account configuration");
    r.assertMessage("cannot deactivate own account");
    accountIndexedCounter.assertNoReindex();
}
#method_after
@Test
public void pushAccountConfigToUserBranchIsRejectedIfOwnAccountIsDeactivated() throws Exception {
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers);
    fetch(allUsersRepo, RefNames.refsUsers(admin.id) + ":userRef");
    allUsersRepo.reset("userRef");
    Config ac = getAccountConfig(allUsersRepo);
    ac.setBoolean(AccountProperties.ACCOUNT, null, AccountProperties.KEY_ACTIVE, false);
    PushOneCommit.Result r = pushFactory.create(db, admin.getIdent(), allUsersRepo, "Update account config", AccountProperties.ACCOUNT_CONFIG, ac.toText()).to(RefNames.REFS_USERS_SELF);
    r.assertErrorStatus("invalid account configuration");
    r.assertMessage("cannot deactivate own account");
    accountIndexedCounter.assertNoReindex();
}
#end_block

#method_before
@Test
public void pushAccountConfigToUserBranchDeactivateOtherAccount() throws Exception {
    TestAccount foo = accountCreator.create(name("foo"));
    assertThat(gApi.accounts().id(foo.id.get()).getActive()).isTrue();
    String userRef = RefNames.refsUsers(foo.id);
    accountIndexedCounter.clear();
    InternalGroup adminGroup = groupCache.get(new AccountGroup.NameKey("Administrators")).orElse(null);
    grant(allUsers, userRef, Permission.PUSH, false, adminGroup.getGroupUUID());
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers);
    fetch(allUsersRepo, userRef + ":userRef");
    allUsersRepo.reset("userRef");
    Config ac = getAccountConfig(allUsersRepo);
    ac.setBoolean(AccountConfig.ACCOUNT, null, AccountConfig.KEY_ACTIVE, false);
    pushFactory.create(db, admin.getIdent(), allUsersRepo, "Update account config", AccountConfig.ACCOUNT_CONFIG, ac.toText()).to(userRef).assertOkStatus();
    accountIndexedCounter.assertReindexOf(foo);
    assertThat(gApi.accounts().id(foo.id.get()).getActive()).isFalse();
}
#method_after
@Test
public void pushAccountConfigToUserBranchDeactivateOtherAccount() throws Exception {
    allowGlobalCapabilities(REGISTERED_USERS, GlobalCapability.ACCESS_DATABASE);
    TestAccount foo = accountCreator.create(name("foo"));
    assertThat(gApi.accounts().id(foo.id.get()).getActive()).isTrue();
    String userRef = RefNames.refsUsers(foo.id);
    accountIndexedCounter.clear();
    grant(allUsers, userRef, Permission.PUSH, false, adminGroupUuid());
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers);
    fetch(allUsersRepo, userRef + ":userRef");
    allUsersRepo.reset("userRef");
    Config ac = getAccountConfig(allUsersRepo);
    ac.setBoolean(AccountProperties.ACCOUNT, null, AccountProperties.KEY_ACTIVE, false);
    pushFactory.create(db, admin.getIdent(), allUsersRepo, "Update account config", AccountProperties.ACCOUNT_CONFIG, ac.toText()).to(userRef).assertOkStatus();
    accountIndexedCounter.assertReindexOf(foo);
    assertThat(gApi.accounts().id(foo.id.get()).getActive()).isFalse();
}
#end_block

#method_before
@Test
@Sandboxed
public void cannotCreateUserBranch() throws Exception {
    grant(allUsers, RefNames.REFS_USERS + "*", Permission.CREATE);
    grant(allUsers, RefNames.REFS_USERS + "*", Permission.PUSH);
    String userRef = RefNames.refsUsers(new Account.Id(seq.nextAccountId()));
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers);
    PushOneCommit.Result r = pushFactory.create(db, admin.getIdent(), allUsersRepo).to(userRef);
    r.assertErrorStatus();
    assertThat(r.getMessage()).contains("Not allowed to create user branch.");
    try (Repository repo = repoManager.openRepository(allUsers)) {
        assertThat(repo.exactRef(userRef)).isNull();
    }
}
#method_after
@Test
public void cannotCreateUserBranch() throws Exception {
    grant(allUsers, RefNames.REFS_USERS + "*", Permission.CREATE);
    grant(allUsers, RefNames.REFS_USERS + "*", Permission.PUSH);
    String userRef = RefNames.refsUsers(new Account.Id(seq.nextAccountId()));
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers);
    PushOneCommit.Result r = pushFactory.create(db, admin.getIdent(), allUsersRepo).to(userRef);
    r.assertErrorStatus();
    assertThat(r.getMessage()).contains("Not allowed to create user branch.");
    try (Repository repo = repoManager.openRepository(allUsers)) {
        assertThat(repo.exactRef(userRef)).isNull();
    }
}
#end_block

#method_before
@Test
@Sandboxed
public void createUserBranchWithAccessDatabaseCapability() throws Exception {
    allowGlobalCapabilities(REGISTERED_USERS, GlobalCapability.ACCESS_DATABASE);
    grant(allUsers, RefNames.REFS_USERS + "*", Permission.CREATE);
    grant(allUsers, RefNames.REFS_USERS + "*", Permission.PUSH);
    String userRef = RefNames.refsUsers(new Account.Id(seq.nextAccountId()));
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers);
    pushFactory.create(db, admin.getIdent(), allUsersRepo).to(userRef).assertOkStatus();
    try (Repository repo = repoManager.openRepository(allUsers)) {
        assertThat(repo.exactRef(userRef)).isNotNull();
    }
}
#method_after
@Test
public void createUserBranchWithAccessDatabaseCapability() throws Exception {
    allowGlobalCapabilities(REGISTERED_USERS, GlobalCapability.ACCESS_DATABASE);
    grant(allUsers, RefNames.REFS_USERS + "*", Permission.CREATE);
    grant(allUsers, RefNames.REFS_USERS + "*", Permission.PUSH);
    String userRef = RefNames.refsUsers(new Account.Id(seq.nextAccountId()));
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers);
    pushFactory.create(db, admin.getIdent(), allUsersRepo).to(userRef).assertOkStatus();
    try (Repository repo = repoManager.openRepository(allUsers)) {
        assertThat(repo.exactRef(userRef)).isNotNull();
    }
}
#end_block

#method_before
@Test
@Sandboxed
public void cannotCreateNonUserBranchUnderRefsUsersWithAccessDatabaseCapability() throws Exception {
    allowGlobalCapabilities(REGISTERED_USERS, GlobalCapability.ACCESS_DATABASE);
    grant(allUsers, RefNames.REFS_USERS + "*", Permission.CREATE);
    grant(allUsers, RefNames.REFS_USERS + "*", Permission.PUSH);
    String userRef = RefNames.REFS_USERS + "foo";
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers);
    PushOneCommit.Result r = pushFactory.create(db, admin.getIdent(), allUsersRepo).to(userRef);
    r.assertErrorStatus();
    assertThat(r.getMessage()).contains("Not allowed to create non-user branch under refs/users/.");
    try (Repository repo = repoManager.openRepository(allUsers)) {
        assertThat(repo.exactRef(userRef)).isNull();
    }
}
#method_after
@Test
public void cannotCreateNonUserBranchUnderRefsUsersWithAccessDatabaseCapability() throws Exception {
    allowGlobalCapabilities(REGISTERED_USERS, GlobalCapability.ACCESS_DATABASE);
    grant(allUsers, RefNames.REFS_USERS + "*", Permission.CREATE);
    grant(allUsers, RefNames.REFS_USERS + "*", Permission.PUSH);
    String userRef = RefNames.REFS_USERS + "foo";
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers);
    PushOneCommit.Result r = pushFactory.create(db, admin.getIdent(), allUsersRepo).to(userRef);
    r.assertErrorStatus();
    assertThat(r.getMessage()).contains("Not allowed to create non-user branch under refs/users/.");
    try (Repository repo = repoManager.openRepository(allUsers)) {
        assertThat(repo.exactRef(userRef)).isNull();
    }
}
#end_block

#method_before
@Test
@Sandboxed
public void createDefaultUserBranch() throws Exception {
    try (Repository repo = repoManager.openRepository(allUsers)) {
        assertThat(repo.exactRef(RefNames.REFS_USERS_DEFAULT)).isNull();
    }
    grant(allUsers, RefNames.REFS_USERS_DEFAULT, Permission.CREATE);
    grant(allUsers, RefNames.REFS_USERS_DEFAULT, Permission.PUSH);
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers);
    pushFactory.create(db, admin.getIdent(), allUsersRepo).to(RefNames.REFS_USERS_DEFAULT).assertOkStatus();
    try (Repository repo = repoManager.openRepository(allUsers)) {
        assertThat(repo.exactRef(RefNames.REFS_USERS_DEFAULT)).isNotNull();
    }
}
#method_after
@Test
public void createDefaultUserBranch() throws Exception {
    try (Repository repo = repoManager.openRepository(allUsers)) {
        assertThat(repo.exactRef(RefNames.REFS_USERS_DEFAULT)).isNull();
    }
    grant(allUsers, RefNames.REFS_USERS_DEFAULT, Permission.CREATE);
    grant(allUsers, RefNames.REFS_USERS_DEFAULT, Permission.PUSH);
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers);
    pushFactory.create(db, admin.getIdent(), allUsersRepo).to(RefNames.REFS_USERS_DEFAULT).assertOkStatus();
    try (Repository repo = repoManager.openRepository(allUsers)) {
        assertThat(repo.exactRef(RefNames.REFS_USERS_DEFAULT)).isNotNull();
    }
}
#end_block

#method_before
@Test
@Sandboxed
public void cannotDeleteUserBranch() throws Exception {
    grant(allUsers, RefNames.REFS_USERS + "${" + RefPattern.USERID_SHARDED + "}", Permission.DELETE, true, REGISTERED_USERS);
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers);
    String userRef = RefNames.refsUsers(admin.id);
    PushResult r = deleteRef(allUsersRepo, userRef);
    RemoteRefUpdate refUpdate = r.getRemoteUpdate(userRef);
    assertThat(refUpdate.getStatus()).isEqualTo(RemoteRefUpdate.Status.REJECTED_OTHER_REASON);
    assertThat(refUpdate.getMessage()).contains("Not allowed to delete user branch.");
    try (Repository repo = repoManager.openRepository(allUsers)) {
        assertThat(repo.exactRef(userRef)).isNotNull();
    }
}
#method_after
@Test
public void cannotDeleteUserBranch() throws Exception {
    grant(allUsers, RefNames.REFS_USERS + "${" + RefPattern.USERID_SHARDED + "}", Permission.DELETE, true, REGISTERED_USERS);
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers);
    String userRef = RefNames.refsUsers(admin.id);
    PushResult r = deleteRef(allUsersRepo, userRef);
    RemoteRefUpdate refUpdate = r.getRemoteUpdate(userRef);
    assertThat(refUpdate.getStatus()).isEqualTo(RemoteRefUpdate.Status.REJECTED_OTHER_REASON);
    assertThat(refUpdate.getMessage()).contains("Not allowed to delete user branch.");
    try (Repository repo = repoManager.openRepository(allUsers)) {
        assertThat(repo.exactRef(userRef)).isNotNull();
    }
}
#end_block

#method_before
@Test
@Sandboxed
public void deleteUserBranchWithAccessDatabaseCapability() throws Exception {
    allowGlobalCapabilities(REGISTERED_USERS, GlobalCapability.ACCESS_DATABASE);
    grant(allUsers, RefNames.REFS_USERS + "${" + RefPattern.USERID_SHARDED + "}", Permission.DELETE, true, REGISTERED_USERS);
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers);
    String userRef = RefNames.refsUsers(admin.id);
    PushResult r = deleteRef(allUsersRepo, userRef);
    RemoteRefUpdate refUpdate = r.getRemoteUpdate(userRef);
    assertThat(refUpdate.getStatus()).isEqualTo(RemoteRefUpdate.Status.OK);
    try (Repository repo = repoManager.openRepository(allUsers)) {
        assertThat(repo.exactRef(userRef)).isNull();
    }
    assertThat(accountCache.getOrNull(admin.id)).isNull();
    assertThat(accountQueryProvider.get().byDefault(admin.id.toString())).isEmpty();
}
#method_after
@Test
public void deleteUserBranchWithAccessDatabaseCapability() throws Exception {
    allowGlobalCapabilities(REGISTERED_USERS, GlobalCapability.ACCESS_DATABASE);
    grant(allUsers, RefNames.REFS_USERS + "${" + RefPattern.USERID_SHARDED + "}", Permission.DELETE, true, REGISTERED_USERS);
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers);
    String userRef = RefNames.refsUsers(admin.id);
    PushResult r = deleteRef(allUsersRepo, userRef);
    RemoteRefUpdate refUpdate = r.getRemoteUpdate(userRef);
    assertThat(refUpdate.getStatus()).isEqualTo(RemoteRefUpdate.Status.OK);
    try (Repository repo = repoManager.openRepository(allUsers)) {
        assertThat(repo.exactRef(userRef)).isNull();
    }
    assertThat(accountCache.get(admin.id)).isEmpty();
    assertThat(accountQueryProvider.get().byDefault(admin.id.toString())).isEmpty();
}
#end_block

#method_before
@Test
public void reAddExistingGpgKey() throws Exception {
    addExternalIdEmail(admin, "test5@example.com");
    TestKey key = validKeyWithSecondUserId();
    String id = key.getKeyIdString();
    PGPPublicKey pk = key.getPublicKey();
    GpgKeyInfo info = addGpgKey(armor(pk)).get(id);
    assertThat(info.userIds).hasSize(2);
    assertIteratorSize(2, getOnlyKeyFromStore(key).getUserIDs());
    pk = PGPPublicKey.removeCertification(pk, "foo:myId");
    info = addGpgKey(armor(pk)).get(id);
    assertThat(info.userIds).hasSize(1);
    assertIteratorSize(1, getOnlyKeyFromStore(key).getUserIDs());
}
#method_after
@Test
public void reAddExistingGpgKey() throws Exception {
    addExternalIdEmail(admin, "test5@example.com");
    TestKey key = validKeyWithSecondUserId();
    String id = key.getKeyIdString();
    PGPPublicKey pk = key.getPublicKey();
    GpgKeyInfo info = addGpgKey(armor(pk)).get(id);
    assertThat(info.userIds).hasSize(2);
    assertIteratorSize(2, getOnlyKeyFromStore(key).getUserIDs());
    pk = PGPPublicKey.removeCertification(pk, "foo:myId");
    info = addGpgKeyNoReindex(armor(pk)).get(id);
    assertThat(info.userIds).hasSize(1);
    assertIteratorSize(1, getOnlyKeyFromStore(key).getUserIDs());
}
#end_block

#method_before
@Test
public void addOtherUsersGpgKey_Conflict() throws Exception {
    // Both users have a matching external ID for this key.
    addExternalIdEmail(admin, "test5@example.com");
    externalIdsUpdate.insert(ExternalId.create("foo", "myId", user.getId()));
    accountIndexedCounter.assertReindexOf(user);
    TestKey key = validKeyWithSecondUserId();
    addGpgKey(key.getPublicKeyArmored());
    setApiUser(user);
    exception.expect(ResourceConflictException.class);
    exception.expectMessage("GPG key already associated with another account");
    addGpgKey(key.getPublicKeyArmored());
}
#method_after
@Test
public void addOtherUsersGpgKey_Conflict() throws Exception {
    // Both users have a matching external ID for this key.
    addExternalIdEmail(admin, "test5@example.com");
    accountsUpdateProvider.get().update("Add External ID", user.getId(), u -> u.addExternalId(ExternalId.create("foo", "myId", user.getId())));
    accountIndexedCounter.assertReindexOf(user);
    TestKey key = validKeyWithSecondUserId();
    addGpgKey(key.getPublicKeyArmored());
    setApiUser(user);
    exception.expect(ResourceConflictException.class);
    exception.expectMessage("GPG key already associated with another account");
    addGpgKey(key.getPublicKeyArmored());
}
#end_block

#method_before
@Test
@UseSsh
public void sshKeys() throws Exception {
    // 
    // The test account should initially have exactly one ssh key
    List<SshKeyInfo> info = gApi.accounts().self().listSshKeys();
    assertThat(info).hasSize(1);
    assertSequenceNumbers(info);
    SshKeyInfo key = info.get(0);
    String inital = AccountCreator.publicKey(admin.sshKey, admin.email);
    assertThat(key.sshPublicKey).isEqualTo(inital);
    accountIndexedCounter.assertNoReindex();
    // Add a new key
    String newKey = AccountCreator.publicKey(AccountCreator.genSshKey(), admin.email);
    gApi.accounts().self().addSshKey(newKey);
    info = gApi.accounts().self().listSshKeys();
    assertThat(info).hasSize(2);
    assertSequenceNumbers(info);
    accountIndexedCounter.assertReindexOf(admin);
    // Add an existing key (the request succeeds, but the key isn't added again)
    gApi.accounts().self().addSshKey(inital);
    info = gApi.accounts().self().listSshKeys();
    assertThat(info).hasSize(2);
    assertSequenceNumbers(info);
    accountIndexedCounter.assertNoReindex();
    // Add another new key
    String newKey2 = AccountCreator.publicKey(AccountCreator.genSshKey(), admin.email);
    gApi.accounts().self().addSshKey(newKey2);
    info = gApi.accounts().self().listSshKeys();
    assertThat(info).hasSize(3);
    assertSequenceNumbers(info);
    accountIndexedCounter.assertReindexOf(admin);
    // Delete second key
    gApi.accounts().self().deleteSshKey(2);
    info = gApi.accounts().self().listSshKeys();
    assertThat(info).hasSize(2);
    assertThat(info.get(0).seq).isEqualTo(1);
    assertThat(info.get(1).seq).isEqualTo(3);
    accountIndexedCounter.assertReindexOf(admin);
}
#method_after
@Test
@UseSsh
public void sshKeys() throws Exception {
    // The test account should initially have exactly one ssh key
    List<SshKeyInfo> info = gApi.accounts().self().listSshKeys();
    assertThat(info).hasSize(1);
    assertSequenceNumbers(info);
    SshKeyInfo key = info.get(0);
    KeyPair keyPair = sshKeys.getKeyPair(admin);
    String inital = TestSshKeys.publicKey(keyPair, admin.email);
    assertThat(key.sshPublicKey).isEqualTo(inital);
    accountIndexedCounter.assertNoReindex();
    // Add a new key
    String newKey = TestSshKeys.publicKey(TestSshKeys.genSshKey(), admin.email);
    gApi.accounts().self().addSshKey(newKey);
    info = gApi.accounts().self().listSshKeys();
    assertThat(info).hasSize(2);
    assertSequenceNumbers(info);
    accountIndexedCounter.assertReindexOf(admin);
    // Add an existing key (the request succeeds, but the key isn't added again)
    gApi.accounts().self().addSshKey(inital);
    info = gApi.accounts().self().listSshKeys();
    assertThat(info).hasSize(2);
    assertSequenceNumbers(info);
    accountIndexedCounter.assertNoReindex();
    // Add another new key
    String newKey2 = TestSshKeys.publicKey(TestSshKeys.genSshKey(), admin.email);
    gApi.accounts().self().addSshKey(newKey2);
    info = gApi.accounts().self().listSshKeys();
    assertThat(info).hasSize(3);
    assertSequenceNumbers(info);
    accountIndexedCounter.assertReindexOf(admin);
    // Delete second key
    gApi.accounts().self().deleteSshKey(2);
    info = gApi.accounts().self().listSshKeys();
    assertThat(info).hasSize(2);
    assertThat(info.get(0).seq).isEqualTo(1);
    assertThat(info.get(1).seq).isEqualTo(3);
    accountIndexedCounter.assertReindexOf(admin);
    // Mark first key as invalid
    assertThat(info.get(0).valid).isTrue();
    authorizedKeys.markKeyInvalid(admin.id, 1);
    info = gApi.accounts().self().listSshKeys();
    assertThat(info).hasSize(2);
    assertThat(info.get(0).seq).isEqualTo(1);
    assertThat(info.get(0).valid).isFalse();
    assertThat(info.get(1).seq).isEqualTo(3);
    accountIndexedCounter.assertReindexOf(admin);
}
#end_block

#method_before
@Test
@Sandboxed
public void checkConsistency() throws Exception {
    allowGlobalCapabilities(REGISTERED_USERS, GlobalCapability.ACCESS_DATABASE);
    resetCurrentApiUser();
    // Create an account with a preferred email.
    String username = name("foo");
    String email = username + "@example.com";
    TestAccount account = accountCreator.create(username, email, "Foo Bar");
    ConsistencyCheckInput input = new ConsistencyCheckInput();
    input.checkAccounts = new CheckAccountsInput();
    ConsistencyCheckInfo checkInfo = gApi.config().server().checkConsistency(input);
    assertThat(checkInfo.checkAccountsResult.problems).isEmpty();
    Set<ConsistencyProblemInfo> expectedProblems = new HashSet<>();
    // Delete the external ID for the preferred email. This makes the account inconsistent since it
    // now doesn't have an external ID for its preferred email.
    externalIdsUpdate.delete(ExternalId.createEmail(account.getId(), email));
    expectedProblems.add(new ConsistencyProblemInfo(ConsistencyProblemInfo.Status.ERROR, "Account '" + account.getId().get() + "' has no external ID for its preferred email '" + email + "'"));
    checkInfo = gApi.config().server().checkConsistency(input);
    assertThat(checkInfo.checkAccountsResult.problems).hasSize(expectedProblems.size());
    assertThat(checkInfo.checkAccountsResult.problems).containsExactlyElementsIn(expectedProblems);
}
#method_after
@Test
public void checkConsistency() throws Exception {
    allowGlobalCapabilities(REGISTERED_USERS, GlobalCapability.ACCESS_DATABASE);
    resetCurrentApiUser();
    // Create an account with a preferred email.
    String username = name("foo");
    String email = username + "@example.com";
    TestAccount account = accountCreator.create(username, email, "Foo Bar");
    ConsistencyCheckInput input = new ConsistencyCheckInput();
    input.checkAccounts = new CheckAccountsInput();
    ConsistencyCheckInfo checkInfo = gApi.config().server().checkConsistency(input);
    assertThat(checkInfo.checkAccountsResult.problems).isEmpty();
    Set<ConsistencyProblemInfo> expectedProblems = new HashSet<>();
    // Delete the external ID for the preferred email. This makes the account inconsistent since it
    // now doesn't have an external ID for its preferred email.
    accountsUpdateProvider.get().update("Delete External ID", account.getId(), u -> u.deleteExternalId(ExternalId.createEmail(account.getId(), email)));
    expectedProblems.add(new ConsistencyProblemInfo(ConsistencyProblemInfo.Status.ERROR, "Account '" + account.getId().get() + "' has no external ID for its preferred email '" + email + "'"));
    checkInfo = gApi.config().server().checkConsistency(input);
    assertThat(checkInfo.checkAccountsResult.problems).hasSize(expectedProblems.size());
    assertThat(checkInfo.checkAccountsResult.problems).containsExactlyElementsIn(expectedProblems);
}
#end_block

#method_before
@Test
public void checkMetaId() throws Exception {
    // metaId is set when account is loaded
    assertThat(accounts.get(admin.getId()).getMetaId()).isEqualTo(getMetaId(admin.getId()));
    // metaId is set when account is created
    AccountsUpdate au = accountsUpdate.create();
    Account.Id accountId = new Account.Id(seq.nextAccountId());
    Account account = au.insert(accountId, a -> {
    });
    assertThat(account.getMetaId()).isEqualTo(getMetaId(accountId));
    // metaId is set when account is updated
    Account updatedAccount = au.update(accountId, a -> a.setFullName("foo"));
    assertThat(account.getMetaId()).isNotEqualTo(updatedAccount.getMetaId());
    assertThat(updatedAccount.getMetaId()).isEqualTo(getMetaId(accountId));
    // metaId is set when account is replaced
    Account newAccount = new Account(accountId, TimeUtil.nowTs());
    au.replace(newAccount);
    assertThat(updatedAccount.getMetaId()).isNotEqualTo(newAccount.getMetaId());
    assertThat(newAccount.getMetaId()).isEqualTo(getMetaId(accountId));
}
#method_after
@Test
public void checkMetaId() throws Exception {
    // metaId is set when account is loaded
    assertThat(accounts.get(admin.getId()).get().getAccount().getMetaId()).isEqualTo(getMetaId(admin.getId()));
    // metaId is set when account is created
    AccountsUpdate au = accountsUpdateProvider.get();
    Account.Id accountId = new Account.Id(seq.nextAccountId());
    AccountState accountState = au.insert("Create Test Account", accountId, u -> {
    });
    assertThat(accountState.getAccount().getMetaId()).isEqualTo(getMetaId(accountId));
    // metaId is set when account is updated
    Optional<AccountState> updatedAccountState = au.update("Set Full Name", accountId, u -> u.setFullName("foo"));
    assertThat(updatedAccountState).isPresent();
    Account updatedAccount = updatedAccountState.get().getAccount();
    assertThat(accountState.getAccount().getMetaId()).isNotEqualTo(updatedAccount.getMetaId());
    assertThat(updatedAccount.getMetaId()).isEqualTo(getMetaId(accountId));
}
#end_block

#method_before
private void addExternalIdEmail(TestAccount account, String email) throws Exception {
    checkNotNull(email);
    externalIdsUpdate.insert(ExternalId.createWithEmail(name("test"), email, account.getId(), email));
    accountIndexedCounter.assertReindexOf(account);
    setApiUser(account);
}
#method_after
private void addExternalIdEmail(TestAccount account, String email) throws Exception {
    checkNotNull(email);
    accountsUpdateProvider.get().update("Add Email", account.getId(), u -> u.addExternalId(ExternalId.createWithEmail(name("test"), email, account.getId(), email)));
    accountIndexedCounter.assertReindexOf(account);
    setApiUser(account);
}
#end_block

#method_before
private void assertUser(AccountInfo info, TestAccount account) throws Exception {
    assertThat(info.name).isEqualTo(account.fullName);
    assertThat(info.email).isEqualTo(account.email);
    assertThat(info.username).isEqualTo(account.username);
    assertThat(info.status).isEqualTo(account.status);
}
#method_after
private void assertUser(AccountInfo info, TestAccount account) throws Exception {
    assertUser(info, account, null);
}
#end_block

#method_before
private void assertUser(AccountInfo info, TestAccount account) throws Exception {
    assertThat(info.name).isEqualTo(account.fullName);
    assertThat(info.email).isEqualTo(account.email);
    assertThat(info.username).isEqualTo(account.username);
    assertThat(info.status).isEqualTo(account.status);
}
#method_after
private void assertUser(AccountInfo info, TestAccount account, @Nullable String expectedStatus) throws Exception {
    assertThat(info.name).isEqualTo(account.fullName);
    assertThat(info.email).isEqualTo(account.email);
    assertThat(info.username).isEqualTo(account.username);
    assertThat(info.status).isEqualTo(expectedStatus);
}
#end_block

#method_before
private Config getAccountConfig(TestRepository<?> allUsersRepo) throws Exception {
    Config ac = new Config();
    try (TreeWalk tw = TreeWalk.forPath(allUsersRepo.getRepository(), AccountConfig.ACCOUNT_CONFIG, getHead(allUsersRepo.getRepository()).getTree())) {
        assertThat(tw).isNotNull();
        ac.fromText(new String(allUsersRepo.getRevWalk().getObjectReader().open(tw.getObjectId(0), OBJ_BLOB).getBytes(), UTF_8));
    }
    return ac;
}
#method_after
private Config getAccountConfig(TestRepository<?> allUsersRepo) throws Exception {
    Config ac = new Config();
    try (TreeWalk tw = TreeWalk.forPath(allUsersRepo.getRepository(), AccountProperties.ACCOUNT_CONFIG, getHead(allUsersRepo.getRepository()).getTree())) {
        assertThat(tw).isNotNull();
        ac.fromText(new String(allUsersRepo.getRevWalk().getObjectReader().open(tw.getObjectId(0), OBJ_BLOB).getBytes(), UTF_8));
    }
    return ac;
}
#end_block

#method_before
@Test
public void approvalsCommitFormatSimple() throws Exception {
    Change c = TestChanges.newChange(project, changeOwner.getAccountId(), 1);
    ChangeUpdate update = newUpdate(c, changeOwner);
    update.putApproval("Verified", (short) 1);
    update.putApproval("Code-Review", (short) -1);
    update.putReviewer(changeOwner.getAccount().getId(), REVIEWER);
    update.putReviewer(otherUser.getAccount().getId(), CC);
    update.commit();
    assertThat(update.getRefName()).isEqualTo("refs/changes/01/1/meta");
    RevCommit commit = parseCommit(update.getResult());
    assertBodyEquals("Update patch set 1\n" + "\n" + "Patch-set: 1\n" + "Change-id: " + c.getKey().get() + "\n" + "Subject: Change subject\n" + "Branch: refs/heads/master\n" + "Commit: " + update.getCommit().name() + "\n" + "Reviewer: Change Owner <1@gerrit>\n" + "CC: Other Account <2@gerrit>\n" + "Label: Code-Review=-1\n" + "Label: Verified=+1\n", commit);
    PersonIdent author = commit.getAuthorIdent();
    assertThat(author.getName()).isEqualTo("Change Owner");
    assertThat(author.getEmailAddress()).isEqualTo("1@gerrit");
    assertThat(author.getWhen()).isEqualTo(new Date(c.getCreatedOn().getTime() + 1000));
    assertThat(author.getTimeZone()).isEqualTo(TimeZone.getTimeZone("GMT-7:00"));
    PersonIdent committer = commit.getCommitterIdent();
    assertThat(committer.getName()).isEqualTo("Gerrit Server");
    assertThat(committer.getEmailAddress()).isEqualTo("noreply@gerrit.com");
    assertThat(committer.getWhen()).isEqualTo(author.getWhen());
    assertThat(committer.getTimeZone()).isEqualTo(author.getTimeZone());
}
#method_after
@Test
public void approvalsCommitFormatSimple() throws Exception {
    Change c = TestChanges.newChange(project, changeOwner.getAccountId(), 1);
    ChangeUpdate update = newUpdate(c, changeOwner);
    update.putApproval("Verified", (short) 1);
    update.putApproval("Code-Review", (short) -1);
    update.putReviewer(changeOwner.getAccount().getId(), REVIEWER);
    update.putReviewer(otherUser.getAccount().getId(), CC);
    update.commit();
    assertThat(update.getRefName()).isEqualTo("refs/changes/01/1/meta");
    RevCommit commit = parseCommit(update.getResult());
    assertBodyEquals("Update patch set 1\n" + "\n" + "Patch-set: 1\n" + "Change-id: " + c.getKey().get() + "\n" + "Subject: Change subject\n" + "Branch: refs/heads/master\n" + "Commit: " + update.getCommit().name() + "\n" + "Reviewer: Gerrit User 1 <1@gerrit>\n" + "CC: Gerrit User 2 <2@gerrit>\n" + "Label: Code-Review=-1\n" + "Label: Verified=+1\n", commit);
    PersonIdent author = commit.getAuthorIdent();
    assertThat(author.getName()).isEqualTo("Gerrit User 1");
    assertThat(author.getEmailAddress()).isEqualTo("1@gerrit");
    assertThat(author.getWhen()).isEqualTo(new Date(c.getCreatedOn().getTime() + 1000));
    assertThat(author.getTimeZone()).isEqualTo(TimeZone.getTimeZone("GMT-7:00"));
    PersonIdent committer = commit.getCommitterIdent();
    assertThat(committer.getName()).isEqualTo("Gerrit Server");
    assertThat(committer.getEmailAddress()).isEqualTo("noreply@gerrit.com");
    assertThat(committer.getWhen()).isEqualTo(author.getWhen());
    assertThat(committer.getTimeZone()).isEqualTo(author.getTimeZone());
}
#end_block

#method_before
@Test
public void submitCommitFormat() throws Exception {
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, changeOwner);
    update.setSubjectForCommit("Submit patch set 1");
    RequestId submissionId = RequestId.forChange(c);
    update.merge(submissionId, ImmutableList.of(submitRecord("NOT_READY", null, submitLabel("Verified", "OK", changeOwner.getAccountId()), submitLabel("Code-Review", "NEED", null)), submitRecord("NOT_READY", null, submitLabel("Verified", "OK", changeOwner.getAccountId()), submitLabel("Alternative-Code-Review", "NEED", null))));
    update.commit();
    RevCommit commit = parseCommit(update.getResult());
    assertBodyEquals("Submit patch set 1\n" + "\n" + "Patch-set: 1\n" + "Status: merged\n" + "Submission-id: " + submissionId.toStringForStorage() + "\n" + "Submitted-with: NOT_READY\n" + "Submitted-with: OK: Verified: Change Owner <1@gerrit>\n" + "Submitted-with: NEED: Code-Review\n" + "Submitted-with: NOT_READY\n" + "Submitted-with: OK: Verified: Change Owner <1@gerrit>\n" + "Submitted-with: NEED: Alternative-Code-Review\n", commit);
    PersonIdent author = commit.getAuthorIdent();
    assertThat(author.getName()).isEqualTo("Change Owner");
    assertThat(author.getEmailAddress()).isEqualTo("1@gerrit");
    assertThat(author.getWhen()).isEqualTo(new Date(c.getCreatedOn().getTime() + 2000));
    assertThat(author.getTimeZone()).isEqualTo(TimeZone.getTimeZone("GMT-7:00"));
    PersonIdent committer = commit.getCommitterIdent();
    assertThat(committer.getName()).isEqualTo("Gerrit Server");
    assertThat(committer.getEmailAddress()).isEqualTo("noreply@gerrit.com");
    assertThat(committer.getWhen()).isEqualTo(author.getWhen());
    assertThat(committer.getTimeZone()).isEqualTo(author.getTimeZone());
}
#method_after
@Test
public void submitCommitFormat() throws Exception {
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, changeOwner);
    update.setSubjectForCommit("Submit patch set 1");
    RequestId submissionId = RequestId.forChange(c);
    update.merge(submissionId, ImmutableList.of(submitRecord("NOT_READY", null, submitLabel("Verified", "OK", changeOwner.getAccountId()), submitLabel("Code-Review", "NEED", null)), submitRecord("NOT_READY", null, submitLabel("Verified", "OK", changeOwner.getAccountId()), submitLabel("Alternative-Code-Review", "NEED", null))));
    update.commit();
    RevCommit commit = parseCommit(update.getResult());
    assertBodyEquals("Submit patch set 1\n" + "\n" + "Patch-set: 1\n" + "Status: merged\n" + "Submission-id: " + submissionId.toStringForStorage() + "\n" + "Submitted-with: NOT_READY\n" + "Submitted-with: OK: Verified: Gerrit User 1 <1@gerrit>\n" + "Submitted-with: NEED: Code-Review\n" + "Submitted-with: NOT_READY\n" + "Submitted-with: OK: Verified: Gerrit User 1 <1@gerrit>\n" + "Submitted-with: NEED: Alternative-Code-Review\n", commit);
    PersonIdent author = commit.getAuthorIdent();
    assertThat(author.getName()).isEqualTo("Gerrit User 1");
    assertThat(author.getEmailAddress()).isEqualTo("1@gerrit");
    assertThat(author.getWhen()).isEqualTo(new Date(c.getCreatedOn().getTime() + 2000));
    assertThat(author.getTimeZone()).isEqualTo(TimeZone.getTimeZone("GMT-7:00"));
    PersonIdent committer = commit.getCommitterIdent();
    assertThat(committer.getName()).isEqualTo("Gerrit Server");
    assertThat(committer.getEmailAddress()).isEqualTo("noreply@gerrit.com");
    assertThat(committer.getWhen()).isEqualTo(author.getWhen());
    assertThat(committer.getTimeZone()).isEqualTo(author.getTimeZone());
}
#end_block

#method_before
@Test
public void anonymousUser() throws Exception {
    Account anon = new Account(new Account.Id(3), TimeUtil.nowTs());
    accountCache.put(anon);
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, userFactory.create(anon.getId()));
    update.setChangeMessage("Comment on the change.");
    update.commit();
    RevCommit commit = parseCommit(update.getResult());
    assertBodyEquals("Update patch set 1\n\nComment on the change.\n\nPatch-set: 1\n", commit);
    PersonIdent author = commit.getAuthorIdent();
    assertThat(author.getName()).isEqualTo("Anonymous Coward (3)");
    assertThat(author.getEmailAddress()).isEqualTo("3@gerrit");
}
#method_after
@Test
public void anonymousUser() throws Exception {
    Account anon = new Account(new Account.Id(3), TimeUtil.nowTs());
    accountCache.put(anon);
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, userFactory.create(anon.getId()));
    update.setChangeMessage("Comment on the change.");
    update.commit();
    RevCommit commit = parseCommit(update.getResult());
    assertBodyEquals("Update patch set 1\n\nComment on the change.\n\nPatch-set: 1\n", commit);
    PersonIdent author = commit.getAuthorIdent();
    assertThat(author.getName()).isEqualTo("Gerrit User 3");
    assertThat(author.getEmailAddress()).isEqualTo("3@gerrit");
}
#end_block

#method_before
@Test
public void noChangeMessage() throws Exception {
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, changeOwner);
    update.putReviewer(changeOwner.getAccount().getId(), REVIEWER);
    update.commit();
    assertBodyEquals("Update patch set 1\n\nPatch-set: 1\nReviewer: Change Owner <1@gerrit>\n", update.getResult());
}
#method_after
@Test
public void noChangeMessage() throws Exception {
    Change c = newChange();
    ChangeUpdate update = newUpdate(c, changeOwner);
    update.putReviewer(changeOwner.getAccount().getId(), REVIEWER);
    update.commit();
    assertBodyEquals("Update patch set 1\n\nPatch-set: 1\nReviewer: Gerrit User 1 <1@gerrit>\n", update.getResult());
}
#end_block

#method_before
@Test
public void realUser() throws Exception {
    Change c = newChange();
    CurrentUser ownerAsOtherUser = userFactory.runAs(null, otherUserId, changeOwner);
    ChangeUpdate update = newUpdate(c, ownerAsOtherUser);
    update.setChangeMessage("Message on behalf of other user");
    update.commit();
    RevCommit commit = parseCommit(update.getResult());
    PersonIdent author = commit.getAuthorIdent();
    assertThat(author.getName()).isEqualTo("Other Account");
    assertThat(author.getEmailAddress()).isEqualTo("2@gerrit");
    assertBodyEquals("Update patch set 1\n" + "\n" + "Message on behalf of other user\n" + "\n" + "Patch-set: 1\n" + "Real-user: Change Owner <1@gerrit>\n", commit);
}
#method_after
@Test
public void realUser() throws Exception {
    Change c = newChange();
    CurrentUser ownerAsOtherUser = userFactory.runAs(null, otherUserId, changeOwner);
    ChangeUpdate update = newUpdate(c, ownerAsOtherUser);
    update.setChangeMessage("Message on behalf of other user");
    update.commit();
    RevCommit commit = parseCommit(update.getResult());
    PersonIdent author = commit.getAuthorIdent();
    assertThat(author.getName()).isEqualTo("Gerrit User 2");
    assertThat(author.getEmailAddress()).isEqualTo("2@gerrit");
    assertBodyEquals("Update patch set 1\n" + "\n" + "Message on behalf of other user\n" + "\n" + "Patch-set: 1\n" + "Real-user: Gerrit User 1 <1@gerrit>\n", commit);
}
#end_block

#method_before
@Override
protected void init() throws EmailException {
    super.init();
    if (notify.compareTo(NotifyHandling.OWNER_REVIEWERS) >= 0) {
        ccAllApprovals();
    }
    if (notify.compareTo(NotifyHandling.ALL) >= 0) {
        bccStarredBy();
        includeWatchers(NotifyType.ALL_COMMENTS, !change.isWorkInProgress() && !change.isPrivate());
    }
    removeUsersThatIgnoredTheChange();
    // Add header that enables identifying comments on parsed email.
    // Grouping is currently done by timestamp.
    setHeader("X-Gerrit-Comment-Date", timestamp);
    if (incomingEmailEnabled) {
        if (replyToAddress == null) {
            // Remove Reply-To and use outbound SMTP (default) instead.
            removeHeader("Reply-To");
        } else {
            setHeader("Reply-To", replyToAddress);
        }
    }
}
#method_after
@Override
protected void init() throws EmailException {
    super.init();
    if (notify.compareTo(NotifyHandling.OWNER_REVIEWERS) >= 0) {
        ccAllApprovals();
    }
    if (notify.compareTo(NotifyHandling.ALL) >= 0) {
        bccStarredBy();
        includeWatchers(NotifyType.ALL_COMMENTS, !change.isWorkInProgress() && !change.isPrivate());
    }
    removeUsersThatIgnoredTheChange();
    // Add header that enables identifying comments on parsed email.
    // Grouping is currently done by timestamp.
    setHeader(MailHeader.COMMENT_DATE.fieldName(), timestamp);
    if (incomingEmailEnabled) {
        if (replyToAddress == null) {
            // Remove Reply-To and use outbound SMTP (default) instead.
            removeHeader(FieldName.REPLY_TO);
        } else {
            setHeader(FieldName.REPLY_TO, replyToAddress);
        }
    }
}
#end_block

#method_before
private List<CommentSender.FileCommentGroup> getGroupedInlineComments(Repository repo) {
    List<CommentSender.FileCommentGroup> groups = new ArrayList<>();
    // Get the patch list:
    PatchList patchList = null;
    if (repo != null) {
        try {
            patchList = getPatchList();
        } catch (PatchListObjectTooLargeException e) {
            log.warn("Failed to get patch list: " + e.getMessage());
        } catch (PatchListNotAvailableException e) {
            log.error("Failed to get patch list", e);
        }
    }
    // Loop over the comments and collect them into groups based on the file
    // location of the comment.
    FileCommentGroup currentGroup = null;
    for (Comment c : inlineComments) {
        // If it's a new group:
        if (currentGroup == null || !c.key.filename.equals(currentGroup.filename) || c.key.patchSetId != currentGroup.patchSetId) {
            currentGroup = new FileCommentGroup();
            currentGroup.filename = c.key.filename;
            currentGroup.patchSetId = c.key.patchSetId;
            groups.add(currentGroup);
            if (patchList != null) {
                try {
                    currentGroup.fileData = new PatchFile(repo, patchList, c.key.filename);
                } catch (IOException e) {
                    log.warn(String.format("Cannot load %s from %s in %s", c.key.filename, patchList.getNewId().name(), projectState.getName()), e);
                    currentGroup.fileData = null;
                }
            }
        }
        if (currentGroup.fileData != null) {
            currentGroup.comments.add(c);
        }
    }
    Collections.sort(groups, Comparator.comparing(g -> g.filename, FilenameComparator.INSTANCE));
    return groups;
}
#method_after
private List<CommentSender.FileCommentGroup> getGroupedInlineComments(Repository repo) {
    List<CommentSender.FileCommentGroup> groups = new ArrayList<>();
    // Get the patch list:
    PatchList patchList = null;
    if (repo != null) {
        try {
            patchList = getPatchList();
        } catch (PatchListObjectTooLargeException e) {
            logger.atWarning().log("Failed to get patch list: %s", e.getMessage());
        } catch (PatchListNotAvailableException e) {
            logger.atSevere().withCause(e).log("Failed to get patch list");
        }
    }
    // Loop over the comments and collect them into groups based on the file
    // location of the comment.
    FileCommentGroup currentGroup = null;
    for (Comment c : inlineComments) {
        // If it's a new group:
        if (currentGroup == null || !c.key.filename.equals(currentGroup.filename) || c.key.patchSetId != currentGroup.patchSetId) {
            currentGroup = new FileCommentGroup();
            currentGroup.filename = c.key.filename;
            currentGroup.patchSetId = c.key.patchSetId;
            groups.add(currentGroup);
            if (patchList != null) {
                try {
                    currentGroup.fileData = new PatchFile(repo, patchList, c.key.filename);
                } catch (IOException e) {
                    logger.atWarning().withCause(e).log("Cannot load %s from %s in %s", c.key.filename, patchList.getNewId().name(), projectState.getName());
                    currentGroup.fileData = null;
                }
            }
        }
        if (currentGroup.fileData != null) {
            currentGroup.comments.add(c);
        }
    }
    Collections.sort(groups, Comparator.comparing(g -> g.filename, FilenameComparator.INSTANCE));
    return groups;
}
#end_block

#method_before
private Optional<Comment> getParent(Comment child) {
    if (child.parentUuid == null) {
        return Optional.empty();
    }
    Comment.Key key = new Comment.Key(child.parentUuid, child.key.filename, child.key.patchSetId);
    try {
        return commentsUtil.getPublished(args.db.get(), changeData.notes(), key);
    } catch (OrmException e) {
        log.warn("Could not find the parent of this comment: " + child.toString());
        return Optional.empty();
    }
}
#method_after
private Optional<Comment> getParent(Comment child) {
    if (child.parentUuid == null) {
        return Optional.empty();
    }
    Comment.Key key = new Comment.Key(child.parentUuid, child.key.filename, child.key.patchSetId);
    try {
        return commentsUtil.getPublished(args.db.get(), changeData.notes(), key);
    } catch (OrmException e) {
        logger.atWarning().log("Could not find the parent of this comment: %s", child);
        return Optional.empty();
    }
}
#end_block

#method_before
@Override
protected void setupSoyContext() {
    super.setupSoyContext();
    boolean hasComments = false;
    try (Repository repo = getRepository()) {
        List<Map<String, Object>> files = getCommentGroupsTemplateData(repo);
        soyContext.put("commentFiles", files);
        hasComments = !files.isEmpty();
    }
    soyContext.put("patchSetCommentBlocks", commentBlocksToSoyData(CommentFormatter.parse(patchSetComment)));
    soyContext.put("labels", getLabelVoteSoyData(labels));
    soyContext.put("commentCount", inlineComments.size());
    soyContext.put("commentTimestamp", getCommentTimestamp());
    soyContext.put("coverLetterBlocks", commentBlocksToSoyData(CommentFormatter.parse(getCoverLetter())));
    footers.add("Gerrit-Comment-Date: " + getCommentTimestamp());
    footers.add("Gerrit-HasComments: " + (hasComments ? "Yes" : "No"));
    footers.add("Gerrit-HasLabels: " + (labels.isEmpty() ? "No" : "Yes"));
}
#method_after
@Override
protected void setupSoyContext() {
    super.setupSoyContext();
    boolean hasComments = false;
    try (Repository repo = getRepository()) {
        List<Map<String, Object>> files = getCommentGroupsTemplateData(repo);
        soyContext.put("commentFiles", files);
        hasComments = !files.isEmpty();
    }
    soyContext.put("patchSetCommentBlocks", commentBlocksToSoyData(CommentFormatter.parse(patchSetComment)));
    soyContext.put("labels", getLabelVoteSoyData(labels));
    soyContext.put("commentCount", inlineComments.size());
    soyContext.put("commentTimestamp", getCommentTimestamp());
    soyContext.put("coverLetterBlocks", commentBlocksToSoyData(CommentFormatter.parse(getCoverLetter())));
    footers.add(MailHeader.COMMENT_DATE.withDelimiter() + getCommentTimestamp());
    footers.add(MailHeader.HAS_COMMENTS.withDelimiter() + (hasComments ? "Yes" : "No"));
    footers.add(MailHeader.HAS_LABELS.withDelimiter() + (labels.isEmpty() ? "No" : "Yes"));
    for (Account.Id account : getReplyAccounts()) {
        footers.add(MailHeader.COMMENT_IN_REPLY_TO.withDelimiter() + getNameEmailFor(account));
    }
}
#end_block

#method_before
private String getLine(PatchFile fileInfo, short side, int lineNbr) {
    try {
        return fileInfo.getLine(side, lineNbr);
    } catch (IOException err) {
        // Default to the empty string if the file cannot be safely read.
        log.warn(String.format("Failed to read file on side %d", side), err);
        return "";
    } catch (IndexOutOfBoundsException err) {
        // Default to the empty string if the given line number does not appear
        // in the file.
        log.debug(String.format("Failed to get line number of file on side %d", side), err);
        return "";
    } catch (NoSuchEntityException err) {
        // Default to the empty string if the side cannot be found.
        log.warn(String.format("Side %d of file didn't exist", side), err);
        return "";
    }
}
#method_after
private String getLine(PatchFile fileInfo, short side, int lineNbr) {
    try {
        return fileInfo.getLine(side, lineNbr);
    } catch (IOException err) {
        // Default to the empty string if the file cannot be safely read.
        logger.atWarning().withCause(err).log("Failed to read file on side %d", side);
        return "";
    } catch (IndexOutOfBoundsException err) {
        // Default to the empty string if the given line number does not appear
        // in the file.
        logger.atFine().withCause(err).log("Failed to get line number of file on side %d", side);
        return "";
    } catch (NoSuchEntityException err) {
        // Default to the empty string if the side cannot be found.
        logger.atWarning().withCause(err).log("Side %d of file didn't exist", side);
        return "";
    }
}
#end_block

#method_before
private String getCommentTimestamp() {
    // Grouping is currently done by timestamp.
    return com.google.gerrit.server.mail.lib.MailUtil.rfcDateformatter.format(ZonedDateTime.ofInstant(timestamp.toInstant(), ZoneId.of("UTC")));
}
#method_after
private String getCommentTimestamp() {
    // Grouping is currently done by timestamp.
    return MailProcessingUtil.rfcDateformatter.format(ZonedDateTime.ofInstant(timestamp.toInstant(), ZoneId.of("UTC")));
}
#end_block

#method_before
private static <T> T readContentFromJson(RestResponse r, int expectedStatus, Class<T> clazz) throws Exception {
    r.assertStatus(expectedStatus);
    JsonReader jsonReader = new JsonReader(r.getReader());
    jsonReader.setLenient(true);
    return newGson().fromJson(jsonReader, clazz);
}
#method_after
private static <T> T readContentFromJson(RestResponse r, int expectedStatus, Class<T> clazz) throws Exception {
    r.assertStatus(expectedStatus);
    try (JsonReader jsonReader = new JsonReader(r.getReader())) {
        jsonReader.setLenient(true);
        return newGson().fromJson(jsonReader, clazz);
    }
}
#end_block

#method_before
private static void assertReviewers(ChangeInfo c, ReviewerState reviewerState, TestAccount... accounts) throws Exception {
    List<TestAccount> accountList = new ArrayList<>(accounts.length);
    for (TestAccount a : accounts) {
        accountList.add(a);
    }
    assertReviewers(c, reviewerState, accountList);
}
#method_after
private static void assertReviewers(ChangeInfo c, ReviewerState reviewerState, TestAccount... accounts) throws Exception {
    List<TestAccount> accountList = new ArrayList<>(accounts.length);
    Collections.addAll(accountList, accounts);
    assertReviewers(c, reviewerState, accountList);
}
#end_block

#method_before
@Test
public void output() throws Exception {
    String url = canonicalWebUrl.get() + "#/c/" + project.get() + "/+/";
    ObjectId initialHead = testRepo.getRepository().resolve("HEAD");
    PushOneCommit.Result r1 = pushTo("refs/for/master");
    Change.Id id1 = r1.getChange().getId();
    r1.assertOkStatus();
    r1.assertChange(Change.Status.NEW, null);
    r1.assertMessage("New changes:\n  " + url + id1 + " " + r1.getCommit().getShortMessage() + "\n");
    testRepo.reset(initialHead);
    String newMsg = r1.getCommit().getShortMessage() + " v2";
    testRepo.branch("HEAD").commit().message(newMsg).insertChangeId(r1.getChangeId().substring(1)).create();
    PushOneCommit.Result r2 = pushFactory.create(db, admin.getIdent(), testRepo, "another commit", "b.txt", "bbb").to("refs/for/master");
    Change.Id id2 = r2.getChange().getId();
    r2.assertOkStatus();
    r2.assertChange(Change.Status.NEW, null);
    r2.assertMessage("New changes:\n" + "  " + url + id2 + " another commit\n" + "\n" + "\n" + "Updated changes:\n" + "  " + url + id1 + " " + newMsg + "\n");
}
#method_after
@Test
public void output() throws Exception {
    String url = canonicalWebUrl.get() + "c/" + project.get() + "/+/";
    ObjectId initialHead = testRepo.getRepository().resolve("HEAD");
    PushOneCommit.Result r1 = pushTo("refs/for/master");
    Change.Id id1 = r1.getChange().getId();
    r1.assertOkStatus();
    r1.assertChange(Change.Status.NEW, null);
    r1.assertMessage("New changes:\n  " + url + id1 + " " + r1.getCommit().getShortMessage() + "\n");
    testRepo.reset(initialHead);
    String newMsg = r1.getCommit().getShortMessage() + " v2";
    testRepo.branch("HEAD").commit().message(newMsg).insertChangeId(r1.getChangeId().substring(1)).create();
    PushOneCommit.Result r2 = pushFactory.create(db, admin.getIdent(), testRepo, "another commit", "b.txt", "bbb").to("refs/for/master");
    Change.Id id2 = r2.getChange().getId();
    r2.assertOkStatus();
    r2.assertChange(Change.Status.NEW, null);
    r2.assertMessage("New changes:\n" + "  " + url + id2 + " another commit\n" + "\n" + "\n" + "Updated changes:\n" + "  " + url + id1 + " " + newMsg + "\n");
}
#end_block

#method_before
@Test
public void pushForMasterWithTopicInRefExceedLimitFails() throws Exception {
    String topic = Stream.generate(() -> "t").limit(2049).collect(Collectors.joining());
    PushOneCommit.Result r = pushTo("refs/for/master/" + topic);
    r.assertErrorStatus("topic length exceeds the limit (2048)");
}
#method_after
@Test
public void pushForMasterWithTopicInRefExceedLimitFails() throws Exception {
    String topic = Stream.generate(() -> "t").limit(2049).collect(joining());
    PushOneCommit.Result r = pushTo("refs/for/master/" + topic);
    r.assertErrorStatus("topic length exceeds the limit (2048)");
}
#end_block

#method_before
@Test
public void pushForMasterWithTopicAsOptionExceedLimitFails() throws Exception {
    String topic = Stream.generate(() -> "t").limit(2049).collect(Collectors.joining());
    PushOneCommit.Result r = pushTo("refs/for/master%topic=" + topic);
    r.assertErrorStatus("topic length exceeds the limit (2048)");
}
#method_after
@Test
public void pushForMasterWithTopicAsOptionExceedLimitFails() throws Exception {
    String topic = Stream.generate(() -> "t").limit(2049).collect(joining());
    PushOneCommit.Result r = pushTo("refs/for/master%topic=" + topic);
    r.assertErrorStatus("topic length exceeds the limit (2048)");
}
#end_block

#method_before
@Test
public void pushWorkInProgressChangeWhenNotOwner() throws Exception {
    TestRepository<?> userRepo = cloneProject(project, user);
    PushOneCommit.Result r = pushFactory.create(db, user.getIdent(), userRepo).to("refs/for/master%wip");
    r.assertOkStatus();
    assertThat(r.getChange().change().getOwner()).isEqualTo(user.id);
    assertThat(r.getChange().change().isWorkInProgress()).isTrue();
    // Other user trying to move from WIP to ready should fail.
    GitUtil.fetch(testRepo, r.getPatchSet().getRefName() + ":ps");
    testRepo.reset("ps");
    r = amendChange(r.getChangeId(), "refs/for/master%ready", admin, testRepo);
    r.assertErrorStatus(ReceiveConstants.ONLY_OWNER_CAN_MODIFY_WIP);
    // Other user trying to move from WIP to WIP should succeed.
    r = amendChange(r.getChangeId(), "refs/for/master%wip", admin, testRepo);
    r.assertOkStatus();
    assertThat(r.getChange().change().isWorkInProgress()).isTrue();
    // Push as change owner to move change from WIP to ready.
    r = pushFactory.create(db, user.getIdent(), userRepo).to("refs/for/master%ready");
    r.assertOkStatus();
    assertThat(r.getChange().change().isWorkInProgress()).isFalse();
    // Other user trying to move from ready to WIP should fail.
    GitUtil.fetch(testRepo, r.getPatchSet().getRefName() + ":ps");
    testRepo.reset("ps");
    r = amendChange(r.getChangeId(), "refs/for/master%wip", admin, testRepo);
    r.assertErrorStatus(ReceiveConstants.ONLY_OWNER_CAN_MODIFY_WIP);
    // Other user trying to move from ready to ready should succeed.
    r = amendChange(r.getChangeId(), "refs/for/master%ready", admin, testRepo);
    r.assertOkStatus();
}
#method_after
@Test
public void pushWorkInProgressChangeWhenNotOwner() throws Exception {
    TestRepository<?> userRepo = cloneProject(project, user);
    PushOneCommit.Result r = pushFactory.create(db, user.getIdent(), userRepo).to("refs/for/master%wip");
    r.assertOkStatus();
    assertThat(r.getChange().change().getOwner()).isEqualTo(user.id);
    assertThat(r.getChange().change().isWorkInProgress()).isTrue();
    // Admin user trying to move from WIP to ready should succeed.
    GitUtil.fetch(testRepo, r.getPatchSet().getRefName() + ":ps");
    testRepo.reset("ps");
    r = amendChange(r.getChangeId(), "refs/for/master%ready", user, testRepo);
    r.assertOkStatus();
    // Other user trying to move from WIP to WIP should succeed.
    r = amendChange(r.getChangeId(), "refs/for/master%wip", admin, testRepo);
    r.assertOkStatus();
    assertThat(r.getChange().change().isWorkInProgress()).isTrue();
    // Push as change owner to move change from WIP to ready.
    r = pushFactory.create(db, user.getIdent(), userRepo).to("refs/for/master%ready");
    r.assertOkStatus();
    assertThat(r.getChange().change().isWorkInProgress()).isFalse();
    // Admin user trying to move from ready to WIP should succeed.
    GitUtil.fetch(testRepo, r.getPatchSet().getRefName() + ":ps");
    testRepo.reset("ps");
    r = amendChange(r.getChangeId(), "refs/for/master%wip", admin, testRepo);
    r.assertOkStatus();
    // Other user trying to move from wip to wip should succeed.
    r = amendChange(r.getChangeId(), "refs/for/master%wip", admin, testRepo);
    r.assertOkStatus();
    // Non owner, non admin and non project owner cannot flip wip bit:
    TestAccount user2 = accountCreator.user2();
    grant(project, "refs/*", Permission.FORGE_COMMITTER, false, SystemGroupBackend.REGISTERED_USERS);
    TestRepository<?> user2Repo = cloneProject(project, user2);
    GitUtil.fetch(user2Repo, r.getPatchSet().getRefName() + ":ps");
    user2Repo.reset("ps");
    r = amendChange(r.getChangeId(), "refs/for/master%ready", user2, user2Repo);
    r.assertErrorStatus(ReceiveConstants.ONLY_CHANGE_OWNER_OR_PROJECT_OWNER_CAN_MODIFY_WIP);
    // Project owner trying to move from WIP to ready should succeed.
    allow("refs/*", Permission.OWNER, SystemGroupBackend.REGISTERED_USERS);
    r = amendChange(r.getChangeId(), "refs/for/master%ready", user2, user2Repo);
    r.assertOkStatus();
}
#end_block

#method_before
@Test
public void pushForMasterAsEdit() throws Exception {
    PushOneCommit.Result r = pushTo("refs/for/master");
    r.assertOkStatus();
    Optional<EditInfo> edit = getEdit(r.getChangeId());
    assertThat(edit).isAbsent();
    assertThat(query("has:edit")).isEmpty();
    // specify edit as option
    r = amendChange(r.getChangeId(), "refs/for/master%edit");
    r.assertOkStatus();
    edit = getEdit(r.getChangeId());
    assertThat(edit).isPresent();
    EditInfo editInfo = edit.get();
    r.assertMessage("Updated Changes:\n  " + canonicalWebUrl.get() + "#/c/" + project.get() + "/+/" + r.getChange().getId() + " " + editInfo.commit.subject + " [EDIT]\n");
    // verify that the re-indexing was triggered for the change
    assertThat(query("has:edit")).hasSize(1);
}
#method_after
@Test
public void pushForMasterAsEdit() throws Exception {
    PushOneCommit.Result r = pushTo("refs/for/master");
    r.assertOkStatus();
    Optional<EditInfo> edit = getEdit(r.getChangeId());
    assertThat(edit).isAbsent();
    assertThat(query("has:edit")).isEmpty();
    // specify edit as option
    r = amendChange(r.getChangeId(), "refs/for/master%edit");
    r.assertOkStatus();
    edit = getEdit(r.getChangeId());
    assertThat(edit).isPresent();
    EditInfo editInfo = edit.get();
    r.assertMessage("Updated Changes:\n  " + canonicalWebUrl.get() + "c/" + project.get() + "/+/" + r.getChange().getId() + " " + editInfo.commit.subject + " [EDIT]\n");
    // verify that the re-indexing was triggered for the change
    assertThat(query("has:edit")).hasSize(1);
}
#end_block

#method_before
@Test
public void pushWithMultipleApprovals() throws Exception {
    LabelType Q = category("Custom-Label", value(1, "Positive"), value(0, "No score"), value(-1, "Negative"));
    ProjectConfig config = projectCache.checkedGet(project).getConfig();
    AccountGroup.UUID anon = systemGroupBackend.getGroup(ANONYMOUS_USERS).getUUID();
    String heads = "refs/heads/*";
    Util.allow(config, Permission.forLabel("Custom-Label"), -1, 1, anon, heads);
    config.getLabelSections().put(Q.getName(), Q);
    saveProjectConfig(project, config);
    RevCommit c = commitBuilder().author(admin.getIdent()).committer(admin.getIdent()).add(PushOneCommit.FILE_NAME, PushOneCommit.FILE_CONTENT).message(PushOneCommit.SUBJECT).create();
    pushHead(testRepo, "refs/for/master/%l=Code-Review+1,l=Custom-Label-1", false);
    ChangeInfo ci = get(GitUtil.getChangeId(testRepo, c).get(), DETAILED_LABELS, DETAILED_ACCOUNTS);
    LabelInfo cr = ci.labels.get("Code-Review");
    assertThat(cr.all).hasSize(1);
    cr = ci.labels.get("Custom-Label");
    assertThat(cr.all).hasSize(1);
    // Check that the user who pushed the change was added as a reviewer since they added a vote
    assertThatUserIsOnlyReviewer(ci, admin);
}
#method_after
@Test
public void pushWithMultipleApprovals() throws Exception {
    LabelType Q = category("Custom-Label", value(1, "Positive"), value(0, "No score"), value(-1, "Negative"));
    AccountGroup.UUID anon = systemGroupBackend.getGroup(ANONYMOUS_USERS).getUUID();
    String heads = "refs/heads/*";
    try (ProjectConfigUpdate u = updateProject(project)) {
        Util.allow(u.getConfig(), Permission.forLabel("Custom-Label"), -1, 1, anon, heads);
        u.getConfig().getLabelSections().put(Q.getName(), Q);
        u.save();
    }
    RevCommit c = commitBuilder().author(admin.getIdent()).committer(admin.getIdent()).add(PushOneCommit.FILE_NAME, PushOneCommit.FILE_CONTENT).message(PushOneCommit.SUBJECT).create();
    pushHead(testRepo, "refs/for/master/%l=Code-Review+1,l=Custom-Label-1", false);
    ChangeInfo ci = get(GitUtil.getChangeId(testRepo, c).get(), DETAILED_LABELS, DETAILED_ACCOUNTS);
    LabelInfo cr = ci.labels.get("Code-Review");
    assertThat(cr.all).hasSize(1);
    cr = ci.labels.get("Custom-Label");
    assertThat(cr.all).hasSize(1);
    // Check that the user who pushed the change was added as a reviewer since they added a vote
    assertThatUserIsOnlyReviewer(ci, admin);
}
#end_block

#method_before
@Test
public void pushNewPatchsetToRefsChanges() throws Exception {
    PushOneCommit.Result r = pushTo("refs/for/master");
    r.assertOkStatus();
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo, PushOneCommit.SUBJECT, "b.txt", "anotherContent", r.getChangeId());
    r = push.to("refs/changes/" + r.getChange().change().getId().get());
    r.assertOkStatus();
}
#method_after
@Test
public void pushNewPatchsetToRefsChanges() throws Exception {
    PushOneCommit.Result r = pushOneCommitToRefsChanges();
    r.assertErrorStatus("upload to refs/changes not allowed");
}
#end_block

#method_before
@Test
public void pushCommitUsingSignedOffBy() throws Exception {
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo, PushOneCommit.SUBJECT, "b.txt", "anotherContent");
    PushOneCommit.Result r = push.to("refs/for/master");
    r.assertOkStatus();
    setUseSignedOffBy(InheritableBoolean.TRUE);
    blockForgeCommitter(project, "refs/heads/master");
    push = pushFactory.create(db, admin.getIdent(), testRepo, PushOneCommit.SUBJECT + String.format("\n\nSigned-off-by: %s <%s>", admin.fullName, admin.email), "b.txt", "anotherContent");
    r = push.to("refs/for/master");
    r.assertOkStatus();
    push = pushFactory.create(db, admin.getIdent(), testRepo, PushOneCommit.SUBJECT, "b.txt", "anotherContent");
    r = push.to("refs/for/master");
    r.assertErrorStatus("not Signed-off-by author/committer/uploader in commit message footer");
}
#method_after
@Test
public void pushCommitUsingSignedOffBy() throws Exception {
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo, PushOneCommit.SUBJECT, "b.txt", "anotherContent");
    PushOneCommit.Result r = push.to("refs/for/master");
    r.assertOkStatus();
    setUseSignedOffBy(InheritableBoolean.TRUE);
    block(project, "refs/heads/master", Permission.FORGE_COMMITTER, REGISTERED_USERS);
    push = pushFactory.create(db, admin.getIdent(), testRepo, PushOneCommit.SUBJECT + String.format("\n\nSigned-off-by: %s <%s>", admin.fullName, admin.email), "b.txt", "anotherContent");
    r = push.to("refs/for/master");
    r.assertOkStatus();
    push = pushFactory.create(db, admin.getIdent(), testRepo, PushOneCommit.SUBJECT, "b.txt", "anotherContent");
    r = push.to("refs/for/master");
    r.assertErrorStatus("not Signed-off-by author/committer/uploader in commit message footer");
}
#end_block

#method_before
@Test
public void pushSameCommitTwice() throws Exception {
    ProjectConfig config = projectCache.checkedGet(project).getConfig();
    config.getProject().setCreateNewChangeForAllNotInTarget(InheritableBoolean.TRUE);
    saveProjectConfig(project, config);
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo, PushOneCommit.SUBJECT, "a.txt", "content");
    PushOneCommit.Result r = push.to("refs/for/master");
    r.assertOkStatus();
    push = pushFactory.create(db, admin.getIdent(), testRepo, PushOneCommit.SUBJECT, "b.txt", "anotherContent");
    r = push.to("refs/for/master");
    r.assertOkStatus();
    assertPushRejected(pushHead(testRepo, "refs/for/master", false), "refs/for/master", "commit(s) already exists (as current patchset)");
}
#method_after
@Test
public void pushSameCommitTwice() throws Exception {
    try (ProjectConfigUpdate u = updateProject(project)) {
        u.getConfig().getProject().setBooleanConfig(BooleanProjectConfig.CREATE_NEW_CHANGE_FOR_ALL_NOT_IN_TARGET, InheritableBoolean.TRUE);
        u.save();
    }
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo, PushOneCommit.SUBJECT, "a.txt", "content");
    PushOneCommit.Result r = push.to("refs/for/master");
    r.assertOkStatus();
    push = pushFactory.create(db, admin.getIdent(), testRepo, PushOneCommit.SUBJECT, "b.txt", "anotherContent");
    r = push.to("refs/for/master");
    r.assertOkStatus();
    assertPushRejected(pushHead(testRepo, "refs/for/master", false), "refs/for/master", "commit(s) already exists (as current patchset)");
}
#end_block

#method_before
@Test
public void pushSameCommitTwiceWhenIndexFailed() throws Exception {
    ProjectConfig config = projectCache.checkedGet(project).getConfig();
    config.getProject().setCreateNewChangeForAllNotInTarget(InheritableBoolean.TRUE);
    saveProjectConfig(project, config);
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo, PushOneCommit.SUBJECT, "a.txt", "content");
    PushOneCommit.Result r = push.to("refs/for/master");
    r.assertOkStatus();
    push = pushFactory.create(db, admin.getIdent(), testRepo, PushOneCommit.SUBJECT, "b.txt", "anotherContent");
    r = push.to("refs/for/master");
    r.assertOkStatus();
    indexer.delete(r.getChange().getId());
    assertPushRejected(pushHead(testRepo, "refs/for/master", false), "refs/for/master", "commit(s) already exists (as current patchset)");
}
#method_after
@Test
public void pushSameCommitTwiceWhenIndexFailed() throws Exception {
    try (ProjectConfigUpdate u = updateProject(project)) {
        u.getConfig().getProject().setBooleanConfig(BooleanProjectConfig.CREATE_NEW_CHANGE_FOR_ALL_NOT_IN_TARGET, InheritableBoolean.TRUE);
        u.save();
    }
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo, PushOneCommit.SUBJECT, "a.txt", "content");
    PushOneCommit.Result r = push.to("refs/for/master");
    r.assertOkStatus();
    push = pushFactory.create(db, admin.getIdent(), testRepo, PushOneCommit.SUBJECT, "b.txt", "anotherContent");
    r = push.to("refs/for/master");
    r.assertOkStatus();
    indexer.delete(r.getChange().getId());
    assertPushRejected(pushHead(testRepo, "refs/for/master", false), "refs/for/master", "commit(s) already exists (as current patchset)");
}
#end_block

#method_before
private void testPushWithoutChangeId() throws Exception {
    RevCommit c = createCommit(testRepo, "Message without Change-Id");
    assertThat(GitUtil.getChangeId(testRepo, c)).isEmpty();
    pushForReviewRejected(testRepo, "missing Change-Id in commit message footer");
    ProjectConfig config = projectCache.checkedGet(project).getConfig();
    config.getProject().setRequireChangeID(InheritableBoolean.FALSE);
    saveProjectConfig(project, config);
    pushForReviewOk(testRepo);
}
#method_after
private void testPushWithoutChangeId() throws Exception {
    RevCommit c = createCommit(testRepo, "Message without Change-Id");
    assertThat(GitUtil.getChangeId(testRepo, c)).isEmpty();
    pushForReviewRejected(testRepo, "missing Change-Id in commit message footer");
    setRequireChangeId(InheritableBoolean.FALSE);
    pushForReviewOk(testRepo);
}
#end_block

#method_before
private void testPushWithMultipleChangeIds() throws Exception {
    createCommit(testRepo, "Message with multiple Change-Id\n" + "\n" + "Change-Id: I10f98c2ef76e52e23aa23be5afeb71e40b350e86\n" + "Change-Id: Ie9a132e107def33bdd513b7854b50de911edba0a\n");
    pushForReviewRejected(testRepo, "multiple Change-Id lines in commit message footer");
    ProjectConfig config = projectCache.checkedGet(project).getConfig();
    config.getProject().setRequireChangeID(InheritableBoolean.FALSE);
    saveProjectConfig(project, config);
    pushForReviewRejected(testRepo, "multiple Change-Id lines in commit message footer");
}
#method_after
private void testPushWithMultipleChangeIds() throws Exception {
    createCommit(testRepo, "Message with multiple Change-Id\n" + "\n" + "Change-Id: I10f98c2ef76e52e23aa23be5afeb71e40b350e86\n" + "Change-Id: Ie9a132e107def33bdd513b7854b50de911edba0a\n");
    pushForReviewRejected(testRepo, "multiple Change-Id lines in commit message footer");
    setRequireChangeId(InheritableBoolean.FALSE);
    pushForReviewRejected(testRepo, "multiple Change-Id lines in commit message footer");
}
#end_block

#method_before
private void testpushWithInvalidChangeId() throws Exception {
    createCommit(testRepo, "Message with invalid Change-Id\n\nChange-Id: X\n");
    pushForReviewRejected(testRepo, "invalid Change-Id line format in commit message footer");
    ProjectConfig config = projectCache.checkedGet(project).getConfig();
    config.getProject().setRequireChangeID(InheritableBoolean.FALSE);
    saveProjectConfig(project, config);
    pushForReviewRejected(testRepo, "invalid Change-Id line format in commit message footer");
}
#method_after
private void testpushWithInvalidChangeId() throws Exception {
    createCommit(testRepo, "Message with invalid Change-Id\n\nChange-Id: X\n");
    pushForReviewRejected(testRepo, "invalid Change-Id line format in commit message footer");
    setRequireChangeId(InheritableBoolean.FALSE);
    pushForReviewRejected(testRepo, "invalid Change-Id line format in commit message footer");
}
#end_block

#method_before
private void testPushWithInvalidChangeIdFromEgit() throws Exception {
    createCommit(testRepo, "Message with invalid Change-Id\n" + "\n" + "Change-Id: I0000000000000000000000000000000000000000\n");
    pushForReviewRejected(testRepo, "invalid Change-Id line format in commit message footer");
    ProjectConfig config = projectCache.checkedGet(project).getConfig();
    config.getProject().setRequireChangeID(InheritableBoolean.FALSE);
    saveProjectConfig(project, config);
    pushForReviewRejected(testRepo, "invalid Change-Id line format in commit message footer");
}
#method_after
private void testPushWithInvalidChangeIdFromEgit() throws Exception {
    createCommit(testRepo, "Message with invalid Change-Id\n" + "\n" + "Change-Id: I0000000000000000000000000000000000000000\n");
    pushForReviewRejected(testRepo, "invalid Change-Id line format in commit message footer");
    setRequireChangeId(InheritableBoolean.FALSE);
    pushForReviewRejected(testRepo, "invalid Change-Id line format in commit message footer");
}
#end_block

#method_before
@Test
public void pushCommitWithSameChangeIdAsPredecessorChange() throws Exception {
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo, PushOneCommit.SUBJECT, "a.txt", "content");
    PushOneCommit.Result r = push.to("refs/for/master");
    r.assertOkStatus();
    RevCommit commitChange1 = r.getCommit();
    createCommit(testRepo, commitChange1.getFullMessage());
    pushForReviewRejected(testRepo, "same Change-Id in multiple changes.\n" + "Squash the commits with the same Change-Id or ensure Change-Ids are unique for each" + " commit");
    ProjectConfig config = projectCache.checkedGet(project).getConfig();
    config.getProject().setRequireChangeID(InheritableBoolean.FALSE);
    saveProjectConfig(project, config);
    pushForReviewRejected(testRepo, "same Change-Id in multiple changes.\n" + "Squash the commits with the same Change-Id or ensure Change-Ids are unique for each" + " commit");
}
#method_after
@Test
public void pushCommitWithSameChangeIdAsPredecessorChange() throws Exception {
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo, PushOneCommit.SUBJECT, "a.txt", "content");
    PushOneCommit.Result r = push.to("refs/for/master");
    r.assertOkStatus();
    RevCommit commitChange1 = r.getCommit();
    createCommit(testRepo, commitChange1.getFullMessage());
    pushForReviewRejected(testRepo, "same Change-Id in multiple changes.\n" + "Squash the commits with the same Change-Id or ensure Change-Ids are unique for each" + " commit");
    try (ProjectConfigUpdate u = updateProject(project)) {
        u.getConfig().getProject().setBooleanConfig(BooleanProjectConfig.REQUIRE_CHANGE_ID, InheritableBoolean.FALSE);
        u.save();
    }
    pushForReviewRejected(testRepo, "same Change-Id in multiple changes.\n" + "Squash the commits with the same Change-Id or ensure Change-Ids are unique for each" + " commit");
}
#end_block

#method_before
@Test
public void pushTwoCommitWithSameChangeId() throws Exception {
    RevCommit commitChange1 = createCommitWithChangeId(testRepo, "some change");
    createCommit(testRepo, commitChange1.getFullMessage());
    pushForReviewRejected(testRepo, "same Change-Id in multiple changes.\n" + "Squash the commits with the same Change-Id or ensure Change-Ids are unique for each" + " commit");
    ProjectConfig config = projectCache.checkedGet(project).getConfig();
    config.getProject().setRequireChangeID(InheritableBoolean.FALSE);
    saveProjectConfig(project, config);
    pushForReviewRejected(testRepo, "same Change-Id in multiple changes.\n" + "Squash the commits with the same Change-Id or ensure Change-Ids are unique for each" + " commit");
}
#method_after
@Test
public void pushTwoCommitWithSameChangeId() throws Exception {
    RevCommit commitChange1 = createCommitWithChangeId(testRepo, "some change");
    createCommit(testRepo, commitChange1.getFullMessage());
    pushForReviewRejected(testRepo, "same Change-Id in multiple changes.\n" + "Squash the commits with the same Change-Id or ensure Change-Ids are unique for each" + " commit");
    try (ProjectConfigUpdate u = updateProject(project)) {
        u.getConfig().getProject().setBooleanConfig(BooleanProjectConfig.REQUIRE_CHANGE_ID, InheritableBoolean.FALSE);
        u.save();
    }
    pushForReviewRejected(testRepo, "same Change-Id in multiple changes.\n" + "Squash the commits with the same Change-Id or ensure Change-Ids are unique for each" + " commit");
}
#end_block

#method_before
@Test
public void accidentallyPushNewPatchSetDirectlyToBranchAndRecoverByPushingToRefsChanges() throws Exception {
    Change.Id id = accidentallyPushNewPatchSetDirectlyToBranch();
    ChangeData cd = byChangeId(id);
    String ps1Rev = Iterables.getOnlyElement(cd.patchSets()).getRevision().get();
    String r = "refs/changes/" + id;
    assertPushOk(pushHead(testRepo, r, false), r);
    // Added a new patch set and auto-closed the change.
    cd = byChangeId(id);
    assertThat(cd.change().getStatus()).isEqualTo(Change.Status.MERGED);
    assertThat(getPatchSetRevisions(cd)).containsExactlyEntriesIn(ImmutableMap.of(1, ps1Rev, 2, testRepo.getRepository().resolve("HEAD").name()));
}
#method_after
@Test
@GerritConfig(name = "receive.allowPushToRefsChanges", value = "true")
public void accidentallyPushNewPatchSetDirectlyToBranchAndRecoverByPushingToRefsChanges() throws Exception {
    Change.Id id = accidentallyPushNewPatchSetDirectlyToBranch();
    ChangeData cd = byChangeId(id);
    String ps1Rev = Iterables.getOnlyElement(cd.patchSets()).getRevision().get();
    String r = "refs/changes/" + id;
    assertPushOk(pushHead(testRepo, r, false), r);
    // Added a new patch set and auto-closed the change.
    cd = byChangeId(id);
    assertThat(cd.change().getStatus()).isEqualTo(Change.Status.MERGED);
    assertThat(getPatchSetRevisions(cd)).containsExactlyEntriesIn(ImmutableMap.of(1, ps1Rev, 2, testRepo.getRepository().resolve("HEAD").name()));
}
#end_block

#method_before
@Test
public void pushNewPatchsetOverridingStickyLabel() throws Exception {
    ProjectConfig cfg = projectCache.checkedGet(project).getConfig();
    LabelType codeReview = Util.codeReview();
    codeReview.setCopyMaxScore(true);
    cfg.getLabelSections().put(codeReview.getName(), codeReview);
    saveProjectConfig(cfg);
    PushOneCommit.Result r = pushTo("refs/for/master%l=Code-Review+2");
    r.assertOkStatus();
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo, PushOneCommit.SUBJECT, "b.txt", "anotherContent", r.getChangeId());
    r = push.to("refs/for/master%l=Code-Review+1");
    r.assertOkStatus();
}
#method_after
@Test
public void pushNewPatchsetOverridingStickyLabel() throws Exception {
    try (ProjectConfigUpdate u = updateProject(project)) {
        LabelType codeReview = Util.codeReview();
        codeReview.setCopyMaxScore(true);
        u.getConfig().getLabelSections().put(codeReview.getName(), codeReview);
        u.save();
    }
    PushOneCommit.Result r = pushTo("refs/for/master%l=Code-Review+2");
    r.assertOkStatus();
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo, PushOneCommit.SUBJECT, "b.txt", "anotherContent", r.getChangeId());
    r = push.to("refs/for/master%l=Code-Review+1");
    r.assertOkStatus();
}
#end_block

#method_before
@Test
public void publishCommentsOnPushPublishesDraftsOnAllRevisions() throws Exception {
    PushOneCommit.Result r = createChange();
    String rev1 = r.getCommit().name();
    CommentInfo c1 = addDraft(r.getChangeId(), rev1, newDraft(FILE_NAME, 1, "comment1"));
    CommentInfo c2 = addDraft(r.getChangeId(), rev1, newDraft(FILE_NAME, 1, "comment2"));
    r = amendChange(r.getChangeId());
    String rev2 = r.getCommit().name();
    CommentInfo c3 = addDraft(r.getChangeId(), rev2, newDraft(FILE_NAME, 1, "comment3"));
    assertThat(getPublishedComments(r.getChangeId())).isEmpty();
    gApi.changes().id(r.getChangeId()).addReviewer(user.email);
    sender.clear();
    amendChange(r.getChangeId(), "refs/for/master%publish-comments");
    Collection<CommentInfo> comments = getPublishedComments(r.getChangeId());
    assertThat(comments.stream().map(c -> c.id)).containsExactly(c1.id, c2.id, c3.id);
    assertThat(comments.stream().map(c -> c.message)).containsExactly("comment1", "comment2", "comment3");
    assertThat(getLastMessage(r.getChangeId())).isEqualTo("Uploaded patch set 3.\n\n(3 comments)");
    List<String> messages = sender.getMessages().stream().map(m -> m.body()).sorted(Comparator.comparingInt(m -> m.contains("reexamine") ? 0 : 1)).collect(toList());
    assertThat(messages).hasSize(2);
    assertThat(messages.get(0)).contains("Gerrit-MessageType: newpatchset");
    assertThat(messages.get(0)).contains("I'd like you to reexamine a change");
    assertThat(messages.get(0)).doesNotContain("Uploaded patch set 3");
    assertThat(messages.get(1)).contains("Gerrit-MessageType: comment");
    assertThat(messages.get(1)).containsMatch(Pattern.compile(// then, this test documents the current behavior.
    "Uploaded patch set 3\\.\n" + "\n" + "\\(3 comments\\)\\n.*" + "PS1, Line 1:.*" + "comment1\\n.*" + "PS1, Line 1:.*" + "comment2\\n.*" + "PS2, Line 1:.*" + "comment3\\n", Pattern.DOTALL));
}
#method_after
@Test
public void publishCommentsOnPushPublishesDraftsOnAllRevisions() throws Exception {
    PushOneCommit.Result r = createChange();
    String rev1 = r.getCommit().name();
    CommentInfo c1 = addDraft(r.getChangeId(), rev1, newDraft(FILE_NAME, 1, "comment1"));
    CommentInfo c2 = addDraft(r.getChangeId(), rev1, newDraft(FILE_NAME, 1, "comment2"));
    r = amendChange(r.getChangeId());
    String rev2 = r.getCommit().name();
    CommentInfo c3 = addDraft(r.getChangeId(), rev2, newDraft(FILE_NAME, 1, "comment3"));
    assertThat(getPublishedComments(r.getChangeId())).isEmpty();
    gApi.changes().id(r.getChangeId()).addReviewer(user.email);
    sender.clear();
    amendChange(r.getChangeId(), "refs/for/master%publish-comments");
    Collection<CommentInfo> comments = getPublishedComments(r.getChangeId());
    assertThat(comments.stream().map(c -> c.id)).containsExactly(c1.id, c2.id, c3.id);
    assertThat(comments.stream().map(c -> c.message)).containsExactly("comment1", "comment2", "comment3");
    assertThat(getLastMessage(r.getChangeId())).isEqualTo("Uploaded patch set 3.\n\n(3 comments)");
    List<String> messages = sender.getMessages().stream().map(Message::body).sorted(Comparator.comparingInt(m -> m.contains("reexamine") ? 0 : 1)).collect(toList());
    assertThat(messages).hasSize(2);
    assertThat(messages.get(0)).contains("Gerrit-MessageType: newpatchset");
    assertThat(messages.get(0)).contains("I'd like you to reexamine a change");
    assertThat(messages.get(0)).doesNotContain("Uploaded patch set 3");
    assertThat(messages.get(1)).contains("Gerrit-MessageType: comment");
    assertThat(messages.get(1)).containsMatch(Pattern.compile(// then, this test documents the current behavior.
    "Uploaded patch set 3\\.\n" + "\n" + "\\(3 comments\\)\\n.*" + "PS1, Line 1:.*" + "comment1\\n.*" + "PS1, Line 1:.*" + "comment2\\n.*" + "PS2, Line 1:.*" + "comment3\\n", Pattern.DOTALL));
}
#end_block

#method_before
@Test
public void pushDraftGetsPrivateChange() throws Exception {
    String changeId1 = createChange("refs/drafts/master").getChangeId();
    String changeId2 = createChange("refs/for/master%draft").getChangeId();
    ChangeInfo info1 = gApi.changes().id(changeId1).get();
    ChangeInfo info2 = gApi.changes().id(changeId2).get();
    assertThat(info1.status).isEqualTo(ChangeStatus.NEW);
    assertThat(info2.status).isEqualTo(ChangeStatus.NEW);
    assertThat(info1.isPrivate).isEqualTo(true);
    assertThat(info2.isPrivate).isEqualTo(true);
    assertThat(info1.revisions).hasSize(1);
    assertThat(info2.revisions).hasSize(1);
}
#method_after
@GerritConfig(name = "change.allowDrafts", value = "true")
@Test
public void pushDraftGetsPrivateChange() throws Exception {
    String changeId1 = createChange("refs/drafts/master").getChangeId();
    String changeId2 = createChange("refs/for/master%draft").getChangeId();
    ChangeInfo info1 = gApi.changes().id(changeId1).get();
    ChangeInfo info2 = gApi.changes().id(changeId2).get();
    assertThat(info1.status).isEqualTo(ChangeStatus.NEW);
    assertThat(info2.status).isEqualTo(ChangeStatus.NEW);
    assertThat(info1.isPrivate).isTrue();
    assertThat(info2.isPrivate).isTrue();
    assertThat(info1.revisions).hasSize(1);
    assertThat(info2.revisions).hasSize(1);
}
#end_block

#method_before
@Sandboxed
@Test
public void pushWithDraftOptionToExistingNewChangeGetsChangeEdit() throws Exception {
    String changeId = createChange().getChangeId();
    EditInfoSubject.assertThat(getEdit(changeId)).isAbsent();
    ChangeInfo changeInfo = gApi.changes().id(changeId).get();
    ChangeStatus originalChangeStatus = changeInfo.status;
    PushOneCommit.Result result = amendChange(changeId, "refs/drafts/master");
    result.assertOkStatus();
    changeInfo = gApi.changes().id(changeId).get();
    assertThat(changeInfo.status).isEqualTo(originalChangeStatus);
    assertThat(changeInfo.isPrivate).isNull();
    assertThat(changeInfo.revisions).hasSize(1);
    EditInfoSubject.assertThat(getEdit(changeId)).isPresent();
}
#method_after
@GerritConfig(name = "change.allowDrafts", value = "true")
@Sandboxed
@Test
public void pushWithDraftOptionToExistingNewChangeGetsChangeEdit() throws Exception {
    String changeId = createChange().getChangeId();
    EditInfoSubject.assertThat(getEdit(changeId)).isAbsent();
    ChangeInfo changeInfo = gApi.changes().id(changeId).get();
    ChangeStatus originalChangeStatus = changeInfo.status;
    PushOneCommit.Result result = amendChange(changeId, "refs/drafts/master");
    result.assertOkStatus();
    changeInfo = gApi.changes().id(changeId).get();
    assertThat(changeInfo.status).isEqualTo(originalChangeStatus);
    assertThat(changeInfo.isPrivate).isNull();
    assertThat(changeInfo.revisions).hasSize(1);
    EditInfoSubject.assertThat(getEdit(changeId)).isPresent();
}
#end_block

#method_before
private Collection<CommentInfo> getPublishedComments(String changeId) throws Exception {
    return gApi.changes().id(changeId).comments().values().stream().flatMap(cs -> cs.stream()).collect(toList());
}
#method_after
private Collection<CommentInfo> getPublishedComments(String changeId) throws Exception {
    return gApi.changes().id(changeId).comments().values().stream().flatMap(Collection::stream).collect(toList());
}
#end_block

#method_before
private void grantSkipValidation(Project.NameKey project, String ref, AccountGroup.UUID groupUuid) throws Exception {
    // See SKIP_VALIDATION implementation in default permission backend.
    ProjectConfig config = projectCache.checkedGet(project).getConfig();
    Util.allow(config, Permission.FORGE_AUTHOR, groupUuid, ref);
    Util.allow(config, Permission.FORGE_COMMITTER, groupUuid, ref);
    Util.allow(config, Permission.FORGE_SERVER, groupUuid, ref);
    Util.allow(config, Permission.PUSH_MERGE, groupUuid, "refs/for/" + ref);
    saveProjectConfig(project, config);
}
#method_after
private void grantSkipValidation(Project.NameKey project, String ref, AccountGroup.UUID groupUuid) throws Exception {
    // See SKIP_VALIDATION implementation in default permission backend.
    try (ProjectConfigUpdate u = updateProject(project)) {
        Util.allow(u.getConfig(), Permission.FORGE_AUTHOR, groupUuid, ref);
        Util.allow(u.getConfig(), Permission.FORGE_COMMITTER, groupUuid, ref);
        Util.allow(u.getConfig(), Permission.FORGE_SERVER, groupUuid, ref);
        Util.allow(u.getConfig(), Permission.PUSH_MERGE, groupUuid, "refs/for/" + ref);
        u.save();
    }
}
#end_block

#method_before
protected void beforeTest(Description description) throws Exception {
    this.description = description;
    GerritServer.Description classDesc = GerritServer.Description.forTestClass(description, configName);
    GerritServer.Description methodDesc = GerritServer.Description.forTestMethod(description, configName);
    baseConfig.setInt("receive", null, "changeUpdateThreads", 4);
    if (classDesc.equals(methodDesc) && !classDesc.sandboxed() && !methodDesc.sandboxed()) {
        if (commonServer == null) {
            commonServer = GerritServer.initAndStart(classDesc, baseConfig);
        }
        server = commonServer;
    } else {
        server = GerritServer.initAndStart(methodDesc, baseConfig);
    }
    server.getTestInjector().injectMembers(this);
    Transport.register(inProcessProtocol);
    toClose = Collections.synchronizedList(new ArrayList<Repository>());
    db = reviewDbProvider.open();
    // All groups which were added during the server start (e.g. in SchemaCreator) aren't contained
    // in the instance of the group index which is available here and in tests. There are two
    // reasons:
    // 1) No group index is available in SchemaCreator when using an in-memory database. (This could
    // be fixed by using the IndexManagerOnInit in InMemoryDatabase similar as BaseInit uses it.)
    // 2) During the on-init part of the server start, we use another instance of the index than
    // later on. As test indexes are non-permanent, closing an instance and opening another one
    // removes all indexed data.
    // As a workaround, we simply reindex all available groups here.
    Iterable<GroupReference> allGroups = groups.getAllGroupReferences(db)::iterator;
    for (GroupReference group : allGroups) {
        groupCache.onCreateGroup(group.getUUID());
    }
    admin = accountCreator.admin();
    user = accountCreator.user();
    // Evict cached user state in case tests modify it.
    accountCache.evict(admin.getId());
    accountCache.evict(user.getId());
    adminRestSession = new RestSession(server, admin);
    userRestSession = new RestSession(server, user);
    testRequiresSsh = classDesc.useSshAnnotation() || methodDesc.useSshAnnotation();
    if (testRequiresSsh && SshMode.useSsh() && (adminSshSession == null || userSshSession == null)) {
        // Create Ssh sessions
        initSsh(admin);
        Context ctx = newRequestContext(user);
        atrScope.set(ctx);
        userSshSession = ctx.getSession();
        userSshSession.open();
        ctx = newRequestContext(admin);
        atrScope.set(ctx);
        adminSshSession = ctx.getSession();
        adminSshSession.open();
    }
    resourcePrefix = UNSAFE_PROJECT_NAME.matcher(description.getClassName() + "_" + description.getMethodName() + "_").replaceAll("");
    Context ctx = newRequestContext(admin);
    atrScope.set(ctx);
    project = createProject(projectInput(description));
    testRepo = cloneProject(project, getCloneAsAccount(description));
}
#method_after
protected void beforeTest(Description description) throws Exception {
    this.description = description;
    GerritServer.Description classDesc = GerritServer.Description.forTestClass(description, configName);
    GerritServer.Description methodDesc = GerritServer.Description.forTestMethod(description, configName);
    testRequiresSsh = classDesc.useSshAnnotation() || methodDesc.useSshAnnotation();
    if (!testRequiresSsh) {
        baseConfig.setString("sshd", null, "listenAddress", "off");
    }
    baseConfig.setInt("index", null, "batchThreads", -1);
    baseConfig.setInt("receive", null, "changeUpdateThreads", 4);
    Module module = createModule();
    if (classDesc.equals(methodDesc) && !classDesc.sandboxed() && !methodDesc.sandboxed()) {
        if (commonServer == null) {
            commonServer = GerritServer.initAndStart(classDesc, baseConfig, module);
        }
        server = commonServer;
    } else {
        server = GerritServer.initAndStart(methodDesc, baseConfig, module);
    }
    server.getTestInjector().injectMembers(this);
    Transport.register(inProcessProtocol);
    toClose = Collections.synchronizedList(new ArrayList<Repository>());
    db = reviewDbProvider.open();
    // All groups which were added during the server start (e.g. in SchemaCreator) aren't contained
    // in the instance of the group index which is available here and in tests. There are two
    // reasons:
    // 1) No group index is available in SchemaCreator when using an in-memory database. (This could
    // be fixed by using the IndexManagerOnInit in InMemoryDatabase similar as BaseInit uses it.)
    // 2) During the on-init part of the server start, we use another instance of the index than
    // later on. As test indexes are non-permanent, closing an instance and opening another one
    // removes all indexed data.
    // As a workaround, we simply reindex all available groups here.
    reindexAllGroups();
    admin = accountCreator.admin();
    user = accountCreator.user();
    // Evict and reindex accounts in case tests modify them.
    evictAndReindexAccount(admin.getId());
    evictAndReindexAccount(user.getId());
    adminRestSession = new RestSession(server, admin);
    userRestSession = new RestSession(server, user);
    initSsh();
    resourcePrefix = UNSAFE_PROJECT_NAME.matcher(description.getClassName() + "_" + description.getMethodName() + "_").replaceAll("");
    Context ctx = newRequestContext(admin);
    atrScope.set(ctx);
    ProjectInput in = projectInput(description);
    gApi.projects().create(in);
    project = new Project.NameKey(in.name);
    testRepo = cloneProject(project, getCloneAsAccount(description));
}
#end_block

#method_before
private ProjectInput projectInput(Description description) {
    ProjectInput in = new ProjectInput();
    TestProjectInput ann = description.getAnnotation(TestProjectInput.class);
    in.name = name("project");
    if (ann != null) {
        in.parent = Strings.emptyToNull(ann.parent());
        in.description = Strings.emptyToNull(ann.description());
        in.createEmptyCommit = ann.createEmptyCommit();
        in.submitType = ann.submitType();
        in.useContentMerge = ann.useContributorAgreements();
        in.useSignedOffBy = ann.useSignedOffBy();
        in.useContentMerge = ann.useContentMerge();
    } else {
        // Defaults should match TestProjectConfig, omitting nullable values.
        in.createEmptyCommit = true;
    }
    updateProjectInput(in);
    return in;
}
#method_after
private ProjectInput projectInput(Description description) {
    ProjectInput in = new ProjectInput();
    TestProjectInput ann = description.getAnnotation(TestProjectInput.class);
    in.name = name("project");
    if (ann != null) {
        in.parent = Strings.emptyToNull(ann.parent());
        in.description = Strings.emptyToNull(ann.description());
        in.createEmptyCommit = ann.createEmptyCommit();
        in.submitType = ann.submitType();
        in.useContentMerge = ann.useContributorAgreements();
        in.useSignedOffBy = ann.useSignedOffBy();
        in.useContentMerge = ann.useContentMerge();
        in.rejectEmptyCommit = ann.rejectEmptyCommit();
    } else {
        // Defaults should match TestProjectConfig, omitting nullable values.
        in.createEmptyCommit = true;
    }
    updateProjectInput(in);
    return in;
}
#end_block

#method_before
protected Project.NameKey createProject(String nameSuffix, Project.NameKey parent, boolean createEmptyCommit, SubmitType submitType) throws RestApiException {
    ProjectInput in = new ProjectInput();
    in.name = name(nameSuffix);
    in.parent = parent != null ? parent.get() : null;
    in.submitType = submitType;
    in.createEmptyCommit = createEmptyCommit;
    return createProject(in);
}
#method_after
protected Project.NameKey createProject(String nameSuffix, Project.NameKey parent, boolean createEmptyCommit, SubmitType submitType) throws RestApiException {
    ProjectInput in = new ProjectInput();
    in.name = name(nameSuffix);
    in.parent = parent != null ? parent.get() : null;
    in.submitType = submitType;
    in.createEmptyCommit = createEmptyCommit;
    gApi.projects().create(in);
    return new Project.NameKey(in.name);
}
#end_block

#method_before
protected void afterTest() throws Exception {
    Transport.unregister(inProcessProtocol);
    for (Repository repo : toClose) {
        repo.close();
    }
    db.close();
    if (adminSshSession != null) {
        adminSshSession.close();
    }
    if (userSshSession != null) {
        userSshSession.close();
    }
    if (server != commonServer) {
        server.close();
        server = null;
    }
    NoteDbMode.resetFromEnv(notesMigration);
}
#method_after
protected void afterTest() throws Exception {
    Transport.unregister(inProcessProtocol);
    for (Repository repo : toClose) {
        repo.close();
    }
    db.close();
    closeSsh();
    if (server != commonServer) {
        server.close();
        server = null;
    }
    NoteDbMode.resetFromEnv(notesMigration);
}
#end_block

#method_before
protected PushOneCommit.Result amendChange(String changeId) throws Exception {
    return amendChange(changeId, "refs/for/master");
}
#method_after
protected PushOneCommit.Result amendChange(String changeId) throws Exception {
    return amendChange(changeId, "refs/for/master", admin, testRepo);
}
#end_block

#method_before
private Context newRequestContext(TestAccount account) {
    return atrScope.newContext(reviewDbProvider, new SshSession(server, account), identifiedUserFactory.create(account.getId()));
}
#method_after
private Context newRequestContext(TestAccount account) {
    return atrScope.newContext(reviewDbProvider, new SshSession(sshKeys, server, account), identifiedUserFactory.create(account.getId()));
}
#end_block

#method_before
protected void allow(Project.NameKey p, String ref, String permission, AccountGroup.UUID id) throws Exception {
    ProjectConfig cfg = projectCache.checkedGet(p).getConfig();
    Util.allow(cfg, permission, id, ref);
    saveProjectConfig(p, cfg);
}
#method_after
protected void allow(Project.NameKey p, String ref, String permission, AccountGroup.UUID id) throws Exception {
    try (ProjectConfigUpdate u = updateProject(p)) {
        Util.allow(u.getConfig(), permission, id, ref);
        u.save();
    }
}
#end_block

#method_before
protected void allowGlobalCapabilities(AccountGroup.UUID id, Iterable<String> capabilityNames) throws Exception {
    ProjectConfig cfg = projectCache.checkedGet(allProjects).getConfig();
    for (String capabilityName : capabilityNames) {
        Util.allow(cfg, capabilityName, id);
    }
    saveProjectConfig(allProjects, cfg);
}
#method_after
protected void allowGlobalCapabilities(AccountGroup.UUID id, Iterable<String> capabilityNames) throws Exception {
    try (ProjectConfigUpdate u = updateProject(allProjects)) {
        for (String capabilityName : capabilityNames) {
            Util.allow(u.getConfig(), capabilityName, id);
        }
        u.save();
    }
}
#end_block

#method_before
protected void removeGlobalCapabilities(AccountGroup.UUID id, Iterable<String> capabilityNames) throws Exception {
    ProjectConfig cfg = projectCache.checkedGet(allProjects).getConfig();
    for (String capabilityName : capabilityNames) {
        Util.remove(cfg, capabilityName, id);
    }
    saveProjectConfig(allProjects, cfg);
}
#method_after
protected void removeGlobalCapabilities(AccountGroup.UUID id, Iterable<String> capabilityNames) throws Exception {
    try (ProjectConfigUpdate u = updateProject(allProjects)) {
        for (String capabilityName : capabilityNames) {
            Util.remove(u.getConfig(), capabilityName, id);
        }
        u.save();
    }
}
#end_block

#method_before
protected void setUseContributorAgreements(InheritableBoolean value) throws Exception {
    try (MetaDataUpdate md = metaDataUpdateFactory.create(project)) {
        ProjectConfig config = ProjectConfig.read(md);
        config.getProject().setUseContributorAgreements(value);
        config.commit(md);
        projectCache.evict(config.getProject());
    }
}
#method_after
protected void setUseContributorAgreements(InheritableBoolean value) throws Exception {
    try (MetaDataUpdate md = metaDataUpdateFactory.create(project)) {
        ProjectConfig config = ProjectConfig.read(md);
        config.getProject().setBooleanConfig(BooleanProjectConfig.USE_CONTRIBUTOR_AGREEMENTS, value);
        config.commit(md);
        projectCache.evict(config.getProject());
    }
}
#end_block

#method_before
protected void setUseSignedOffBy(InheritableBoolean value) throws Exception {
    try (MetaDataUpdate md = metaDataUpdateFactory.create(project)) {
        ProjectConfig config = ProjectConfig.read(md);
        config.getProject().setUseSignedOffBy(value);
        config.commit(md);
        projectCache.evict(config.getProject());
    }
}
#method_after
protected void setUseSignedOffBy(InheritableBoolean value) throws Exception {
    try (MetaDataUpdate md = metaDataUpdateFactory.create(project)) {
        ProjectConfig config = ProjectConfig.read(md);
        config.getProject().setBooleanConfig(BooleanProjectConfig.USE_SIGNED_OFF_BY, value);
        config.commit(md);
        projectCache.evict(config.getProject());
    }
}
#end_block

#method_before
protected void deny(Project.NameKey p, String ref, String permission, AccountGroup.UUID id) throws Exception {
    ProjectConfig cfg = projectCache.checkedGet(p).getConfig();
    Util.deny(cfg, permission, id, ref);
    saveProjectConfig(p, cfg);
}
#method_after
protected void deny(Project.NameKey p, String ref, String permission, AccountGroup.UUID id) throws Exception {
    try (ProjectConfigUpdate u = updateProject(p)) {
        Util.deny(u.getConfig(), permission, id, ref);
        u.save();
    }
}
#end_block

#method_before
protected PermissionRule block(Project.NameKey project, String ref, String permission, AccountGroup.UUID id) throws Exception {
    ProjectConfig cfg = projectCache.checkedGet(project).getConfig();
    PermissionRule rule = Util.block(cfg, permission, id, ref);
    saveProjectConfig(project, cfg);
    return rule;
}
#method_after
protected PermissionRule block(Project.NameKey project, String ref, String permission, AccountGroup.UUID id) throws Exception {
    try (ProjectConfigUpdate u = updateProject(project)) {
        PermissionRule rule = Util.block(u.getConfig(), permission, id, ref);
        u.save();
        return rule;
    }
}
#end_block

#method_before
protected void blockLabel(String label, int min, int max, AccountGroup.UUID id, String ref, Project.NameKey project) throws Exception {
    ProjectConfig cfg = projectCache.checkedGet(project).getConfig();
    Util.block(cfg, Permission.LABEL + label, min, max, id, ref);
    saveProjectConfig(project, cfg);
}
#method_after
protected void blockLabel(String label, int min, int max, AccountGroup.UUID id, String ref, Project.NameKey project) throws Exception {
    try (ProjectConfigUpdate u = updateProject(project)) {
        Util.block(u.getConfig(), Permission.LABEL + label, min, max, id, ref);
        u.save();
    }
}
#end_block

#method_before
protected void grant(Project.NameKey project, String ref, String permission, boolean force) throws RepositoryNotFoundException, IOException, ConfigInvalidException {
    InternalGroup adminGroup = groupCache.get(new AccountGroup.NameKey("Administrators")).orElse(null);
    grant(project, ref, permission, force, adminGroup.getGroupUUID());
}
#method_after
protected void grant(Project.NameKey project, String ref, String permission, boolean force) throws RepositoryNotFoundException, IOException, ConfigInvalidException {
    grant(project, ref, permission, force, adminGroupUuid());
}
#end_block

#method_before
protected void removePermission(Project.NameKey project, String ref, String permission) throws IOException, ConfigInvalidException {
    try (MetaDataUpdate md = metaDataUpdateFactory.create(project)) {
        md.setMessage(String.format("Remove %s on %s", permission, ref));
        ProjectConfig config = ProjectConfig.read(md);
        AccessSection s = config.getAccessSection(ref, true);
        Permission p = s.getPermission(permission, true);
        p.getRules().clear();
        config.commit(md);
        projectCache.evict(config.getProject());
    }
}
#method_after
protected void removePermission(Project.NameKey project, String ref, String permission) throws IOException, ConfigInvalidException {
    try (MetaDataUpdate md = metaDataUpdateFactory.create(project)) {
        md.setMessage(String.format("Remove %s on %s", permission, ref));
        ProjectConfig config = ProjectConfig.read(md);
        AccessSection s = config.getAccessSection(ref, true);
        Permission p = s.getPermission(permission, true);
        p.clearRules();
        config.commit(md);
        projectCache.evict(config.getProject());
    }
}
#end_block

#method_before
protected void assertSubmittedTogether(String chId, String... expected) throws Exception {
    List<ChangeInfo> actual = gApi.changes().id(chId).submittedTogether();
    SubmittedTogetherInfo info = gApi.changes().id(chId).submittedTogether(EnumSet.of(NON_VISIBLE_CHANGES));
    assertThat(info.nonVisibleChanges).isEqualTo(0);
    assertThat(changeIds(actual)).containsExactly((Object[]) expected).inOrder();
    assertThat(changeIds(info.changes)).containsExactly((Object[]) expected).inOrder();
}
#method_after
protected void assertSubmittedTogether(String chId, String... expected) throws Exception {
    List<ChangeInfo> actual = gApi.changes().id(chId).submittedTogether();
    SubmittedTogetherInfo info = gApi.changes().id(chId).submittedTogether(EnumSet.of(NON_VISIBLE_CHANGES));
    assertThat(info.nonVisibleChanges).isEqualTo(0);
    assertThat(Iterables.transform(actual, i1 -> i1.changeId)).containsExactly((Object[]) expected).inOrder();
    assertThat(Iterables.transform(info.changes, i -> i.changeId)).containsExactly((Object[]) expected).inOrder();
}
#end_block

#method_before
protected ContributorAgreement configureContributorAgreement(boolean autoVerify) throws Exception {
    ContributorAgreement ca;
    if (autoVerify) {
        String g = createGroup("cla-test-group");
        GroupApi groupApi = gApi.groups().id(g);
        groupApi.description("CLA test group");
        InternalGroup caGroup = groupCache.get(new AccountGroup.UUID(groupApi.detail().id)).orElse(null);
        GroupReference groupRef = new GroupReference(caGroup.getGroupUUID(), caGroup.getName());
        PermissionRule rule = new PermissionRule(groupRef);
        rule.setAction(PermissionRule.Action.ALLOW);
        ca = new ContributorAgreement("cla-test");
        ca.setAutoVerify(groupRef);
        ca.setAccepted(ImmutableList.of(rule));
    } else {
        ca = new ContributorAgreement("cla-test-no-auto-verify");
    }
    ca.setDescription("description");
    ca.setAgreementUrl("agreement-url");
    ProjectConfig cfg = projectCache.checkedGet(allProjects).getConfig();
    cfg.replace(ca);
    saveProjectConfig(allProjects, cfg);
    return ca;
}
#method_after
protected ContributorAgreement configureContributorAgreement(boolean autoVerify) throws Exception {
    ContributorAgreement ca;
    if (autoVerify) {
        String g = createGroup("cla-test-group");
        GroupApi groupApi = gApi.groups().id(g);
        groupApi.description("CLA test group");
        InternalGroup caGroup = group(new AccountGroup.UUID(groupApi.detail().id));
        GroupReference groupRef = new GroupReference(caGroup.getGroupUUID(), caGroup.getName());
        PermissionRule rule = new PermissionRule(groupRef);
        rule.setAction(PermissionRule.Action.ALLOW);
        ca = new ContributorAgreement("cla-test");
        ca.setAutoVerify(groupRef);
        ca.setAccepted(ImmutableList.of(rule));
    } else {
        ca = new ContributorAgreement("cla-test-no-auto-verify");
    }
    ca.setDescription("description");
    ca.setAgreementUrl("agreement-url");
    try (ProjectConfigUpdate u = updateProject(allProjects)) {
        u.getConfig().replace(ca);
        u.save();
        return ca;
    }
}
#end_block

#method_before
protected Map<Branch.NameKey, ObjectId> fetchFromSubmitPreview(String changeId) throws Exception {
    try (BinaryResult result = submitPreview(changeId)) {
        return fetchFromBundles(result);
    }
}
#method_after
protected Map<Branch.NameKey, ObjectId> fetchFromSubmitPreview(String changeId) throws Exception {
    try (BinaryResult result = gApi.changes().id(changeId).current().submitPreview()) {
        return fetchFromBundles(result);
    }
}
#end_block

#method_before
protected void assertDiffForNewFile(DiffInfo diff, RevCommit commit, String path, String expectedContentSideB) throws Exception {
    List<String> expectedLines = new ArrayList<>();
    for (String line : expectedContentSideB.split("\n")) {
        expectedLines.add(line);
    }
    assertThat(diff.binary).isNull();
    assertThat(diff.changeType).isEqualTo(ChangeType.ADDED);
    assertThat(diff.diffHeader).isNotNull();
    assertThat(diff.intralineStatus).isNull();
    assertThat(diff.webLinks).isNull();
    assertThat(diff.metaA).isNull();
    assertThat(diff.metaB).isNotNull();
    assertThat(diff.metaB.commitId).isEqualTo(commit.name());
    String expectedContentType = "text/plain";
    if (COMMIT_MSG.equals(path)) {
        expectedContentType = FileContentUtil.TEXT_X_GERRIT_COMMIT_MESSAGE;
    } else if (MERGE_LIST.equals(path)) {
        expectedContentType = FileContentUtil.TEXT_X_GERRIT_MERGE_LIST;
    }
    assertThat(diff.metaB.contentType).isEqualTo(expectedContentType);
    assertThat(diff.metaB.lines).isEqualTo(expectedLines.size());
    assertThat(diff.metaB.name).isEqualTo(path);
    assertThat(diff.metaB.webLinks).isNull();
    assertThat(diff.content).hasSize(1);
    DiffInfo.ContentEntry contentEntry = diff.content.get(0);
    assertThat(contentEntry.b).containsExactlyElementsIn(expectedLines).inOrder();
    assertThat(contentEntry.a).isNull();
    assertThat(contentEntry.ab).isNull();
    assertThat(contentEntry.common).isNull();
    assertThat(contentEntry.editA).isNull();
    assertThat(contentEntry.editB).isNull();
    assertThat(contentEntry.skip).isNull();
}
#method_after
protected void assertDiffForNewFile(DiffInfo diff, RevCommit commit, String path, String expectedContentSideB) throws Exception {
    List<String> expectedLines = new ArrayList<>();
    Collections.addAll(expectedLines, expectedContentSideB.split("\n"));
    assertThat(diff.binary).isNull();
    assertThat(diff.changeType).isEqualTo(ChangeType.ADDED);
    assertThat(diff.diffHeader).isNotNull();
    assertThat(diff.intralineStatus).isNull();
    assertThat(diff.webLinks).isNull();
    assertThat(diff.metaA).isNull();
    assertThat(diff.metaB).isNotNull();
    assertThat(diff.metaB.commitId).isEqualTo(commit.name());
    String expectedContentType = "text/plain";
    if (COMMIT_MSG.equals(path)) {
        expectedContentType = FileContentUtil.TEXT_X_GERRIT_COMMIT_MESSAGE;
    } else if (MERGE_LIST.equals(path)) {
        expectedContentType = FileContentUtil.TEXT_X_GERRIT_MERGE_LIST;
    }
    assertThat(diff.metaB.contentType).isEqualTo(expectedContentType);
    assertThat(diff.metaB.lines).isEqualTo(expectedLines.size());
    assertThat(diff.metaB.name).isEqualTo(path);
    assertThat(diff.metaB.webLinks).isNull();
    assertThat(diff.content).hasSize(1);
    DiffInfo.ContentEntry contentEntry = diff.content.get(0);
    assertThat(contentEntry.b).containsExactlyElementsIn(expectedLines).inOrder();
    assertThat(contentEntry.a).isNull();
    assertThat(contentEntry.ab).isNull();
    assertThat(contentEntry.common).isNull();
    assertThat(contentEntry.editA).isNull();
    assertThat(contentEntry.editB).isNull();
    assertThat(contentEntry.skip).isNull();
}
#end_block

#method_before
protected void assertNotifyTo(TestAccount expected) {
    assertNotifyTo(expected.emailAddress);
}
#method_after
protected void assertNotifyTo(TestAccount expected) {
    assertNotifyTo(expected.email, expected.fullName);
}
#end_block

#method_before
protected void assertNotifyTo(Address expected) {
    assertThat(sender.getMessages()).hasSize(1);
    Message m = sender.getMessages().get(0);
    assertThat(m.rcpt()).containsExactly(expected);
    assertThat(((EmailHeader.AddressList) m.headers().get("To")).getAddressList()).containsExactly(expected);
    assertThat(m.headers().get("CC").isEmpty()).isTrue();
}
#method_after
protected void assertNotifyTo(com.google.gerrit.acceptance.testsuite.account.TestAccount expected) {
    assertNotifyTo(expected.preferredEmail().orElse(null), expected.fullname().orElse(null));
}
#end_block

#method_before
protected void assertNotifyCc(Address expected) {
    assertThat(sender.getMessages()).hasSize(1);
    Message m = sender.getMessages().get(0);
    assertThat(m.rcpt()).containsExactly(expected);
    assertThat(m.headers().get("To").isEmpty()).isTrue();
    assertThat(((EmailHeader.AddressList) m.headers().get("CC")).getAddressList()).containsExactly(expected);
}
#method_after
protected void assertNotifyCc(com.google.gerrit.acceptance.testsuite.account.TestAccount expected) {
    assertNotifyCc(expected.preferredEmail().orElse(null), expected.fullname().orElse(null));
}
#end_block

#method_before
protected void assertNotifyCc(Address expected) {
    assertThat(sender.getMessages()).hasSize(1);
    Message m = sender.getMessages().get(0);
    assertThat(m.rcpt()).containsExactly(expected);
    assertThat(m.headers().get("To").isEmpty()).isTrue();
    assertThat(((EmailHeader.AddressList) m.headers().get("CC")).getAddressList()).containsExactly(expected);
}
#method_after
protected void assertNotifyCc(Address expectedAddress) {
    assertThat(sender.getMessages()).hasSize(1);
    Message m = sender.getMessages().get(0);
    assertThat(m.rcpt()).containsExactly(expectedAddress);
    assertThat(m.headers().get("To").isEmpty()).isTrue();
    assertThat(((EmailHeader.AddressList) m.headers().get("Cc")).getAddressList()).containsExactly(expectedAddress);
}
#end_block

#method_before
protected void assertNotifyBcc(TestAccount expected) {
    assertThat(sender.getMessages()).hasSize(1);
    Message m = sender.getMessages().get(0);
    assertThat(m.rcpt()).containsExactly(expected.emailAddress);
    assertThat(m.headers().get("To").isEmpty()).isTrue();
    assertThat(m.headers().get("CC").isEmpty()).isTrue();
}
#method_after
protected void assertNotifyBcc(TestAccount expected) {
    assertThat(sender.getMessages()).hasSize(1);
    Message m = sender.getMessages().get(0);
    assertThat(m.rcpt()).containsExactly(expected.emailAddress);
    assertThat(m.headers().get("To").isEmpty()).isTrue();
    assertThat(m.headers().get("Cc").isEmpty()).isTrue();
}
#end_block

#method_before
protected void assertNotifyBcc(TestAccount expected) {
    assertThat(sender.getMessages()).hasSize(1);
    Message m = sender.getMessages().get(0);
    assertThat(m.rcpt()).containsExactly(expected.emailAddress);
    assertThat(m.headers().get("To").isEmpty()).isTrue();
    assertThat(m.headers().get("CC").isEmpty()).isTrue();
}
#method_after
protected void assertNotifyBcc(com.google.gerrit.acceptance.testsuite.account.TestAccount expected) {
    assertThat(sender.getMessages()).hasSize(1);
    Message m = sender.getMessages().get(0);
    assertThat(m.rcpt()).containsExactly(new Address(expected.fullname().orElse(null), expected.preferredEmail().orElse(null)));
    assertThat(m.headers().get("To").isEmpty()).isTrue();
    assertThat(m.headers().get("Cc").isEmpty()).isTrue();
}
#end_block

#method_before
protected RevCommit createNewCommitWithoutChangeId(String branch, String file, String content) throws Exception {
    try (Repository repo = repoManager.openRepository(project);
        RevWalk walk = new RevWalk(repo)) {
        Ref ref = repo.exactRef(branch);
        RevCommit tip = null;
        if (ref != null) {
            tip = walk.parseCommit(ref.getObjectId());
        }
        TestRepository<?> testSrcRepo = new TestRepository<>(repo);
        TestRepository<?>.BranchBuilder builder = testSrcRepo.branch(branch);
        RevCommit revCommit = tip == null ? builder.commit().message("commit 1").add(file, content).create() : builder.commit().parent(tip).message("commit 1").add(file, content).create();
        assertThat(GitUtil.getChangeId(testSrcRepo, revCommit).isPresent()).isFalse();
        return revCommit;
    }
}
#method_after
protected RevCommit createNewCommitWithoutChangeId(String branch, String file, String content) throws Exception {
    try (Repository repo = repoManager.openRepository(project);
        RevWalk walk = new RevWalk(repo)) {
        Ref ref = repo.exactRef(branch);
        RevCommit tip = null;
        if (ref != null) {
            tip = walk.parseCommit(ref.getObjectId());
        }
        TestRepository<?> testSrcRepo = new TestRepository<>(repo);
        TestRepository<?>.BranchBuilder builder = testSrcRepo.branch(branch);
        RevCommit revCommit = tip == null ? builder.commit().message("commit 1").add(file, content).create() : builder.commit().parent(tip).message("commit 1").add(file, content).create();
        assertThat(GitUtil.getChangeId(testSrcRepo, revCommit)).isEmpty();
        return revCommit;
    }
}
#end_block

#method_before
protected void configLabel(String label, LabelFunction func) throws Exception {
    configLabel(project, label, func, value(1, "Passes"), value(0, "No score"), value(-1, "Failed"));
}
#method_after
protected void configLabel(String label, LabelFunction func) throws Exception {
    configLabel(label, func, ImmutableList.of());
}
#end_block

#method_before
protected void configLabel(Project.NameKey project, String label, LabelFunction func, LabelValue... value) throws Exception {
    ProjectConfig cfg = projectCache.checkedGet(project).getConfig();
    LabelType labelType = category(label, value);
    labelType.setFunction(func);
    cfg.getLabelSections().put(labelType.getName(), labelType);
    saveProjectConfig(project, cfg);
}
#method_after
protected void configLabel(String label, LabelFunction func, List<String> refPatterns) throws Exception {
    configLabel(project, label, func, refPatterns, value(1, "Passes"), value(0, "No score"), value(-1, "Failed"));
}
#end_block

#method_before
protected void configLabel(Project.NameKey project, String label, LabelFunction func, LabelValue... value) throws Exception {
    ProjectConfig cfg = projectCache.checkedGet(project).getConfig();
    LabelType labelType = category(label, value);
    labelType.setFunction(func);
    cfg.getLabelSections().put(labelType.getName(), labelType);
    saveProjectConfig(project, cfg);
}
#method_after
protected void configLabel(Project.NameKey project, String label, LabelFunction func, LabelValue... value) throws Exception {
    configLabel(project, label, func, ImmutableList.of(), value);
}
#end_block

#method_before
protected void fail(@Nullable String format, Object... args) throws Exception {
    assert_().fail(format, args);
}
#method_after
protected void fail(@Nullable String format, Object... args) {
    assert_().fail(format, args);
}
#end_block

#method_before
public final Watchers getWatchers(NotifyType type, boolean includeWatchersFromNotifyConfig) throws OrmException {
    Watchers matching = new Watchers();
    Set<Account.Id> projectWatchers = new HashSet<>();
    for (AccountState a : args.accountQueryProvider.get().byWatchedProject(project)) {
        Account.Id accountId = a.getAccount().getId();
        for (Map.Entry<ProjectWatchKey, Set<NotifyType>> e : a.getProjectWatches().entrySet()) {
            if (project.equals(e.getKey().project()) && add(matching, accountId, e.getKey(), e.getValue(), type)) {
                // We only want to prevent matching All-Projects if this filter hits
                projectWatchers.add(accountId);
            }
        }
    }
    for (AccountState a : args.accountQueryProvider.get().byWatchedProject(args.allProjectsName)) {
        for (Map.Entry<ProjectWatchKey, Set<NotifyType>> e : a.getProjectWatches().entrySet()) {
            if (args.allProjectsName.equals(e.getKey().project())) {
                Account.Id accountId = a.getAccount().getId();
                if (!projectWatchers.contains(accountId)) {
                    add(matching, accountId, e.getKey(), e.getValue(), type);
                }
            }
        }
    }
    if (!includeWatchersFromNotifyConfig) {
        return matching;
    }
    for (ProjectState state : projectState.tree()) {
        for (NotifyConfig nc : state.getConfig().getNotifyConfigs()) {
            if (nc.isNotify(type)) {
                try {
                    add(matching, nc);
                } catch (QueryParseException e) {
                    log.warn("Project {} has invalid notify {} filter \"{}\": {}", state.getName(), nc.getName(), nc.getFilter(), e.getMessage());
                }
            }
        }
    }
    return matching;
}
#method_after
public final Watchers getWatchers(NotifyType type, boolean includeWatchersFromNotifyConfig) throws OrmException {
    Watchers matching = new Watchers();
    Set<Account.Id> projectWatchers = new HashSet<>();
    for (AccountState a : args.accountQueryProvider.get().byWatchedProject(project)) {
        Account.Id accountId = a.getAccount().getId();
        for (Map.Entry<ProjectWatchKey, ImmutableSet<NotifyType>> e : a.getProjectWatches().entrySet()) {
            if (project.equals(e.getKey().project()) && add(matching, accountId, e.getKey(), e.getValue(), type)) {
                // We only want to prevent matching All-Projects if this filter hits
                projectWatchers.add(accountId);
            }
        }
    }
    for (AccountState a : args.accountQueryProvider.get().byWatchedProject(args.allProjectsName)) {
        for (Map.Entry<ProjectWatchKey, ImmutableSet<NotifyType>> e : a.getProjectWatches().entrySet()) {
            if (args.allProjectsName.equals(e.getKey().project())) {
                Account.Id accountId = a.getAccount().getId();
                if (!projectWatchers.contains(accountId)) {
                    add(matching, accountId, e.getKey(), e.getValue(), type);
                }
            }
        }
    }
    if (!includeWatchersFromNotifyConfig) {
        return matching;
    }
    for (ProjectState state : projectState.tree()) {
        for (NotifyConfig nc : state.getConfig().getNotifyConfigs()) {
            if (nc.isNotify(type)) {
                try {
                    add(matching, nc);
                } catch (QueryParseException e) {
                    logger.atWarning().log("Project %s has invalid notify %s filter \"%s\": %s", state.getName(), nc.getName(), nc.getFilter(), e.getMessage());
                }
            }
        }
    }
    return matching;
}
#end_block

#method_before
private Account.Id user(String name, String email) {
    final AccountState s = makeUser(name, email);
    expect(accountCache.get(eq(s.getAccount().getId()))).andReturn(s);
    return s.getAccount().getId();
}
#method_after
private Account.Id user(String name, String email) {
    final AccountState s = makeUser(name, email);
    expect(accountCache.get(eq(s.getAccount().getId()))).andReturn(Optional.of(s));
    return s.getAccount().getId();
}
#end_block

#method_before
private AccountState makeUser(String name, String email) {
    final Account.Id userId = new Account.Id(42);
    final Account account = new Account(userId, TimeUtil.nowTs());
    account.setFullName(name);
    account.setPreferredEmail(email);
    return new AccountState(new AllUsersName(AllUsersNameProvider.DEFAULT), account, Collections.emptySet(), new HashMap<>());
}
#method_after
private AccountState makeUser(String name, String email) {
    final Account.Id userId = new Account.Id(42);
    final Account account = new Account(userId, TimeUtil.nowTs());
    account.setFullName(name);
    account.setPreferredEmail(email);
    return AccountState.forAccount(new AllUsersName(AllUsersNameProvider.DEFAULT), account);
}
#end_block

#method_before
public void send() throws EmailException {
    if (NotifyHandling.NONE.equals(notify) && accountsToNotify.isEmpty()) {
        return;
    }
    if (!args.emailSender.isEnabled()) {
        // 
        return;
    }
    init();
    if (useHtml()) {
        appendHtml(soyHtmlTemplate("HeaderHtml"));
    }
    format();
    appendText(textTemplate("Footer"));
    if (useHtml()) {
        appendHtml(soyHtmlTemplate("FooterHtml"));
    }
    Set<Address> smtpRcptToPlaintextOnly = new HashSet<>();
    if (shouldSendMessage()) {
        if (fromId != null) {
            final Account fromUser = args.accountCache.get(fromId).getAccount();
            GeneralPreferencesInfo senderPrefs = fromUser.getGeneralPreferencesInfo();
            if (senderPrefs != null && senderPrefs.getEmailStrategy() == CC_ON_OWN_COMMENTS) {
                // If we are impersonating a user, make sure they receive a CC of
                // this message so they can always review and audit what we sent
                // on their behalf to others.
                // 
                add(RecipientType.CC, fromId);
            } else if (!accountsToNotify.containsValue(fromId) && rcptTo.remove(fromId)) {
                // If they don't want a copy, but we queued one up anyway,
                // drop them from the recipient lists.
                // 
                removeUser(fromUser);
            }
        }
        // In addition, check if users only want to receive plaintext email.
        for (Account.Id id : rcptTo) {
            Account thisUser = args.accountCache.get(id).getAccount();
            GeneralPreferencesInfo prefs = thisUser.getGeneralPreferencesInfo();
            if (prefs == null || prefs.getEmailStrategy() == DISABLED) {
                removeUser(thisUser);
            } else if (useHtml() && prefs.getEmailFormat() == EmailFormat.PLAINTEXT) {
                removeUser(thisUser);
                smtpRcptToPlaintextOnly.add(new Address(thisUser.getFullName(), thisUser.getPreferredEmail()));
            }
            if (smtpRcptTo.isEmpty() && smtpRcptToPlaintextOnly.isEmpty()) {
                return;
            }
        }
        // inbound email replies.
        if (!headers.containsKey("Reply-To")) {
            StringJoiner j = new StringJoiner(", ");
            if (fromId != null) {
                Address address = toAddress(fromId);
                if (address != null) {
                    j.add(address.getEmail());
                }
            }
            smtpRcptTo.stream().forEach(a -> j.add(a.getEmail()));
            smtpRcptToPlaintextOnly.stream().forEach(a -> j.add(a.getEmail()));
            setHeader("Reply-To", j.toString());
        }
        String textPart = textBody.toString();
        OutgoingEmailValidationListener.Args va = new OutgoingEmailValidationListener.Args();
        va.messageClass = messageClass;
        va.smtpFromAddress = smtpFromAddress;
        va.smtpRcptTo = smtpRcptTo;
        va.headers = headers;
        va.body = textPart;
        if (useHtml()) {
            va.htmlBody = htmlBody.toString();
        } else {
            va.htmlBody = null;
        }
        for (OutgoingEmailValidationListener validator : args.outgoingEmailValidationListeners) {
            try {
                validator.validateOutgoingEmail(va);
            } catch (ValidationException e) {
                return;
            }
        }
        if (!smtpRcptTo.isEmpty()) {
            // Send multipart message
            args.emailSender.send(va.smtpFromAddress, va.smtpRcptTo, va.headers, va.body, va.htmlBody);
        }
        if (!smtpRcptToPlaintextOnly.isEmpty()) {
            // Send plaintext message
            Map<String, EmailHeader> shallowCopy = new HashMap<>();
            shallowCopy.putAll(headers);
            // Remove To and Cc
            shallowCopy.remove(HDR_TO);
            shallowCopy.remove(HDR_CC);
            for (Address a : smtpRcptToPlaintextOnly) {
                // Add new To
                EmailHeader.AddressList to = new EmailHeader.AddressList();
                to.add(a);
                shallowCopy.put(HDR_TO, to);
            }
            args.emailSender.send(va.smtpFromAddress, smtpRcptToPlaintextOnly, shallowCopy, va.body);
        }
    }
}
#method_after
public void send() throws EmailException {
    if (NotifyHandling.NONE.equals(notify) && accountsToNotify.isEmpty()) {
        return;
    }
    if (!args.emailSender.isEnabled()) {
        // 
        return;
    }
    init();
    if (useHtml()) {
        appendHtml(soyHtmlTemplate("HeaderHtml"));
    }
    format();
    appendText(textTemplate("Footer"));
    if (useHtml()) {
        appendHtml(soyHtmlTemplate("FooterHtml"));
    }
    Set<Address> smtpRcptToPlaintextOnly = new HashSet<>();
    if (shouldSendMessage()) {
        if (fromId != null) {
            Optional<AccountState> fromUser = args.accountCache.get(fromId);
            if (fromUser.isPresent()) {
                GeneralPreferencesInfo senderPrefs = fromUser.get().getGeneralPreferences();
                if (senderPrefs != null && senderPrefs.getEmailStrategy() == CC_ON_OWN_COMMENTS) {
                    // If we are impersonating a user, make sure they receive a CC of
                    // this message so they can always review and audit what we sent
                    // on their behalf to others.
                    // 
                    add(RecipientType.CC, fromId);
                } else if (!accountsToNotify.containsValue(fromId) && rcptTo.remove(fromId)) {
                    // If they don't want a copy, but we queued one up anyway,
                    // drop them from the recipient lists.
                    // 
                    removeUser(fromUser.get().getAccount());
                }
            }
        }
        // In addition, check if users only want to receive plaintext email.
        for (Account.Id id : rcptTo) {
            Optional<AccountState> thisUser = args.accountCache.get(id);
            if (thisUser.isPresent()) {
                Account thisUserAccount = thisUser.get().getAccount();
                GeneralPreferencesInfo prefs = thisUser.get().getGeneralPreferences();
                if (prefs == null || prefs.getEmailStrategy() == DISABLED) {
                    removeUser(thisUserAccount);
                } else if (useHtml() && prefs.getEmailFormat() == EmailFormat.PLAINTEXT) {
                    removeUser(thisUserAccount);
                    smtpRcptToPlaintextOnly.add(new Address(thisUserAccount.getFullName(), thisUserAccount.getPreferredEmail()));
                }
            }
            if (smtpRcptTo.isEmpty() && smtpRcptToPlaintextOnly.isEmpty()) {
                return;
            }
        }
        // inbound email replies.
        if (!headers.containsKey(FieldName.REPLY_TO)) {
            StringJoiner j = new StringJoiner(", ");
            if (fromId != null) {
                Address address = toAddress(fromId);
                if (address != null) {
                    j.add(address.getEmail());
                }
            }
            smtpRcptTo.stream().forEach(a -> j.add(a.getEmail()));
            smtpRcptToPlaintextOnly.stream().forEach(a -> j.add(a.getEmail()));
            setHeader(FieldName.REPLY_TO, j.toString());
        }
        String textPart = textBody.toString();
        OutgoingEmailValidationListener.Args va = new OutgoingEmailValidationListener.Args();
        va.messageClass = messageClass;
        va.smtpFromAddress = smtpFromAddress;
        va.smtpRcptTo = smtpRcptTo;
        va.headers = headers;
        va.body = textPart;
        if (useHtml()) {
            va.htmlBody = htmlBody.toString();
        } else {
            va.htmlBody = null;
        }
        for (OutgoingEmailValidationListener validator : args.outgoingEmailValidationListeners) {
            try {
                validator.validateOutgoingEmail(va);
            } catch (ValidationException e) {
                return;
            }
        }
        if (!smtpRcptTo.isEmpty()) {
            // Send multipart message
            args.emailSender.send(va.smtpFromAddress, va.smtpRcptTo, va.headers, va.body, va.htmlBody);
        }
        if (!smtpRcptToPlaintextOnly.isEmpty()) {
            // Send plaintext message
            Map<String, EmailHeader> shallowCopy = new HashMap<>();
            shallowCopy.putAll(headers);
            // Remove To and Cc
            shallowCopy.remove(FieldName.TO);
            shallowCopy.remove(FieldName.CC);
            for (Address a : smtpRcptToPlaintextOnly) {
                // Add new To
                EmailHeader.AddressList to = new EmailHeader.AddressList();
                to.add(a);
                shallowCopy.put(FieldName.TO, to);
            }
            args.emailSender.send(va.smtpFromAddress, smtpRcptToPlaintextOnly, shallowCopy, va.body);
        }
    }
}
#end_block

#method_before
protected void init() throws EmailException {
    setupSoyContext();
    smtpFromAddress = args.fromAddressGenerator.from(fromId);
    setHeader("Date", new Date());
    headers.put("From", new EmailHeader.AddressList(smtpFromAddress));
    headers.put(HDR_TO, new EmailHeader.AddressList());
    headers.put(HDR_CC, new EmailHeader.AddressList());
    setHeader("Message-ID", "");
    for (RecipientType recipientType : accountsToNotify.keySet()) {
        add(recipientType, accountsToNotify.get(recipientType));
    }
    setHeader("X-Gerrit-MessageType", messageClass);
    textBody = new StringBuilder();
    htmlBody = new StringBuilder();
    if (fromId != null && args.fromAddressGenerator.isGenericAddress(fromId)) {
        appendText(getFromLine());
    }
}
#method_after
protected void init() throws EmailException {
    setupSoyContext();
    smtpFromAddress = args.fromAddressGenerator.from(fromId);
    setHeader(FieldName.DATE, new Date());
    headers.put(FieldName.FROM, new EmailHeader.AddressList(smtpFromAddress));
    headers.put(FieldName.TO, new EmailHeader.AddressList());
    headers.put(FieldName.CC, new EmailHeader.AddressList());
    setHeader(FieldName.MESSAGE_ID, "");
    setHeader(MailHeader.AUTO_SUBMITTED.fieldName(), "auto-generated");
    for (RecipientType recipientType : accountsToNotify.keySet()) {
        add(recipientType, accountsToNotify.get(recipientType));
    }
    setHeader(MailHeader.MESSAGE_TYPE.fieldName(), messageClass);
    footers.add(MailHeader.MESSAGE_TYPE.withDelimiter() + messageClass);
    textBody = new StringBuilder();
    htmlBody = new StringBuilder();
    if (fromId != null && args.fromAddressGenerator.isGenericAddress(fromId)) {
        appendText(getFromLine());
    }
}
#end_block

#method_before
protected String getFromLine() {
    final Account account = args.accountCache.get(fromId).getAccount();
    final String name = account.getFullName();
    final String email = account.getPreferredEmail();
    StringBuilder f = new StringBuilder();
    if ((name != null && !name.isEmpty()) || (email != null && !email.isEmpty())) {
        f.append("From");
        if (name != null && !name.isEmpty()) {
            f.append(" ").append(name);
        }
        if (email != null && !email.isEmpty()) {
            f.append(" <").append(email).append(">");
        }
        f.append(":\n\n");
    }
    return f.toString();
}
#method_after
protected String getFromLine() {
    StringBuilder f = new StringBuilder();
    Optional<Account> account = args.accountCache.get(fromId).map(AccountState::getAccount);
    if (account.isPresent()) {
        String name = account.get().getFullName();
        String email = account.get().getPreferredEmail();
        if ((name != null && !name.isEmpty()) || (email != null && !email.isEmpty())) {
            f.append("From");
            if (name != null && !name.isEmpty()) {
                f.append(" ").append(name);
            }
            if (email != null && !email.isEmpty()) {
                f.append(" <").append(email).append(">");
            }
            f.append(":\n\n");
        }
    }
    return f.toString();
}
#end_block

#method_before
protected String getNameFor(Account.Id accountId) {
    if (accountId == null) {
        return args.gerritPersonIdent.getName();
    }
    final Account userAccount = args.accountCache.get(accountId).getAccount();
    String name = userAccount.getFullName();
    if (name == null) {
        name = userAccount.getPreferredEmail();
    }
    if (name == null) {
        name = args.anonymousCowardName + " #" + accountId;
    }
    return name;
}
#method_after
protected String getNameFor(Account.Id accountId) {
    if (accountId == null) {
        return args.gerritPersonIdent.getName();
    }
    Optional<Account> account = args.accountCache.get(accountId).map(AccountState::getAccount);
    String name = null;
    if (account.isPresent()) {
        name = account.get().getFullName();
        if (name == null) {
            name = account.get().getPreferredEmail();
        }
    }
    if (name == null) {
        name = args.anonymousCowardName + " #" + accountId;
    }
    return name;
}
#end_block

#method_before
public String getNameEmailFor(Account.Id accountId) {
    AccountState who = args.accountCache.get(accountId);
    String name = who.getAccount().getFullName();
    String email = who.getAccount().getPreferredEmail();
    if (name != null && email != null) {
        return name + " <" + email + ">";
    } else if (name != null) {
        return name;
    } else if (email != null) {
        return email;
    } else /* (name == null && email == null) */
    {
        return args.anonymousCowardName + " #" + accountId;
    }
}
#method_after
protected String getNameEmailFor(Account.Id accountId) {
    Optional<Account> account = args.accountCache.get(accountId).map(AccountState::getAccount);
    if (account.isPresent()) {
        String name = account.get().getFullName();
        String email = account.get().getPreferredEmail();
        if (name != null && email != null) {
            return name + " <" + email + ">";
        } else if (name != null) {
            return name;
        } else if (email != null) {
            return email;
        }
    }
    return args.anonymousCowardName + " #" + accountId;
}
#end_block

#method_before
public String getUserNameEmailFor(Account.Id accountId) {
    AccountState who = args.accountCache.get(accountId);
    String name = who.getAccount().getFullName();
    String email = who.getAccount().getPreferredEmail();
    if (name != null && email != null) {
        return name + " <" + email + ">";
    } else if (email != null) {
        return email;
    } else if (name != null) {
        return name;
    }
    String username = who.getUserName();
    if (username != null) {
        return username;
    }
    return null;
}
#method_after
protected String getUserNameEmailFor(Account.Id accountId) {
    Optional<AccountState> accountState = args.accountCache.get(accountId);
    if (!accountState.isPresent()) {
        return null;
    }
    Account account = accountState.get().getAccount();
    String name = account.getFullName();
    String email = account.getPreferredEmail();
    if (name != null && email != null) {
        return name + " <" + email + ">";
    } else if (email != null) {
        return email;
    } else if (name != null) {
        return name;
    }
    return accountState.get().getUserName().orElse(null);
}
#end_block

#method_before
protected void add(RecipientType rt, Account.Id to, boolean override) {
    try {
        if (!rcptTo.contains(to) && isVisibleTo(to)) {
            rcptTo.add(to);
            add(rt, toAddress(to), override);
        }
    } catch (OrmException | PermissionBackendException e) {
        log.error("Error reading database for account: " + to, e);
    }
}
#method_after
protected void add(RecipientType rt, Account.Id to, boolean override) {
    try {
        if (!rcptTo.contains(to) && isVisibleTo(to)) {
            rcptTo.add(to);
            add(rt, toAddress(to), override);
        }
    } catch (PermissionBackendException e) {
        logger.atSevere().withCause(e).log("Error reading database for account: %s", to);
    }
}
#end_block

#method_before
protected boolean isVisibleTo(Account.Id to) throws OrmException, PermissionBackendException {
    return true;
}
#method_after
protected boolean isVisibleTo(Account.Id to) throws PermissionBackendException {
    return true;
}
#end_block

#method_before
protected void add(RecipientType rt, Address addr, boolean override) {
    if (addr != null && addr.getEmail() != null && addr.getEmail().length() > 0) {
        if (!args.validator.isValid(addr.getEmail())) {
            log.warn("Not emailing " + addr.getEmail() + " (invalid email address)");
        } else if (!args.emailSender.canEmail(addr.getEmail())) {
            log.warn("Not emailing " + addr.getEmail() + " (prohibited by allowrcpt)");
        } else {
            if (!smtpRcptTo.add(addr)) {
                if (!override) {
                    return;
                }
                ((EmailHeader.AddressList) headers.get(HDR_TO)).remove(addr.getEmail());
                ((EmailHeader.AddressList) headers.get(HDR_CC)).remove(addr.getEmail());
            }
            switch(rt) {
                case TO:
                    ((EmailHeader.AddressList) headers.get(HDR_TO)).add(addr);
                    break;
                case CC:
                    ((EmailHeader.AddressList) headers.get(HDR_CC)).add(addr);
                    break;
                case BCC:
                    break;
            }
        }
    }
}
#method_after
protected void add(RecipientType rt, Address addr, boolean override) {
    if (addr != null && addr.getEmail() != null && addr.getEmail().length() > 0) {
        if (!args.validator.isValid(addr.getEmail())) {
            logger.atWarning().log("Not emailing %s (invalid email address)", addr.getEmail());
        } else if (!args.emailSender.canEmail(addr.getEmail())) {
            logger.atWarning().log("Not emailing %s (prohibited by allowrcpt)", addr.getEmail());
        } else {
            if (!smtpRcptTo.add(addr)) {
                if (!override) {
                    return;
                }
                ((EmailHeader.AddressList) headers.get(FieldName.TO)).remove(addr.getEmail());
                ((EmailHeader.AddressList) headers.get(FieldName.CC)).remove(addr.getEmail());
            }
            switch(rt) {
                case TO:
                    ((EmailHeader.AddressList) headers.get(FieldName.TO)).add(addr);
                    break;
                case CC:
                    ((EmailHeader.AddressList) headers.get(FieldName.CC)).add(addr);
                    break;
                case BCC:
                    break;
            }
        }
    }
}
#end_block

#method_before
private Address toAddress(Account.Id id) {
    final Account a = args.accountCache.get(id).getAccount();
    final String e = a.getPreferredEmail();
    if (!a.isActive() || e == null) {
        return null;
    }
    return new Address(a.getFullName(), e);
}
#method_after
private Address toAddress(Account.Id id) {
    Optional<Account> accountState = args.accountCache.get(id).map(AccountState::getAccount);
    if (!accountState.isPresent()) {
        return null;
    }
    Account account = accountState.get();
    String e = account.getPreferredEmail();
    if (!account.isActive() || e == null) {
        return null;
    }
    return new Address(account.getFullName(), e);
}
#end_block

#method_before
protected void setupSoyContext() {
    soyContext = new HashMap<>();
    footers = new ArrayList<>();
    soyContext.put("messageClass", messageClass);
    soyContext.put("footers", footers);
    soyContextEmailData = new HashMap<>();
    soyContextEmailData.put("settingsUrl", getSettingsUrl());
    soyContextEmailData.put("gerritHost", getGerritHost());
    soyContextEmailData.put("gerritUrl", getGerritUrl());
    soyContext.put("email", soyContextEmailData);
}
#method_after
protected void setupSoyContext() {
    soyContext = new HashMap<>();
    footers = new ArrayList<>();
    soyContext.put("messageClass", messageClass);
    soyContext.put("footers", footers);
    soyContextEmailData = new HashMap<>();
    soyContextEmailData.put("settingsUrl", getSettingsUrl());
    soyContextEmailData.put("instanceName", getInstanceName());
    soyContextEmailData.put("gerritHost", getGerritHost());
    soyContextEmailData.put("gerritUrl", getGerritUrl());
    soyContext.put("email", soyContextEmailData);
}
#end_block

#method_before
@Test
@GerritConfig(name = "receiveemail.filter.mode", value = "WHITELIST")
@GerritConfig(name = "receiveemail.filter.patterns", values = { ".+@gerritcodereview\\.com", "a@b\\.com" })
public void listFilterWhitelistFiltersNotListedUser() throws Exception {
    ChangeInfo changeInfo = createChangeAndReplyByEmail();
    // Check that the comments from the email have NOT been persisted
    Collection<ChangeMessageInfo> messages = gApi.changes().id(changeInfo.id).get().messages;
    assertThat(messages).hasSize(2);
}
#method_after
@Test
@GerritConfig(name = "receiveemail.filter.mode", value = "WHITELIST")
@GerritConfig(name = "receiveemail.filter.patterns", values = { ".+@gerritcodereview\\.com", "a@b\\.com" })
public void listFilterWhitelistFiltersNotListedUser() throws Exception {
    ChangeInfo changeInfo = createChangeAndReplyByEmail();
    // Check that the comments from the email have NOT been persisted
    Collection<ChangeMessageInfo> messages = gApi.changes().id(changeInfo.id).get().messages;
    assertThat(messages).hasSize(2);
    // Check that no emails were sent because of this error
    assertThat(sender.getMessages()).isEmpty();
}
#end_block

#method_before
private ChangeInfo createChangeAndReplyByEmail() throws Exception {
    String changeId = createChangeWithReview();
    ChangeInfo changeInfo = gApi.changes().id(changeId).get();
    List<CommentInfo> comments = gApi.changes().id(changeId).current().commentsAsList();
    String ts = com.google.gerrit.server.mail.lib.MailUtil.rfcDateformatter.format(ZonedDateTime.ofInstant(comments.get(0).updated.toInstant(), ZoneId.of("UTC")));
    // Build Message
    MailMessage.Builder b = messageBuilderWithDefaultFields();
    String txt = newPlaintextBody(canonicalWebUrl.get() + "#/c/" + changeInfo._number + "/1", "Test Message", null, null, null);
    b.textContent(txt + textFooterForChange(changeInfo._number, ts));
    mailProcessor.process(b.build());
    return changeInfo;
}
#method_after
private ChangeInfo createChangeAndReplyByEmail() throws Exception {
    String changeId = createChangeWithReview();
    ChangeInfo changeInfo = gApi.changes().id(changeId).get();
    List<CommentInfo> comments = gApi.changes().id(changeId).current().commentsAsList();
    String ts = MailProcessingUtil.rfcDateformatter.format(ZonedDateTime.ofInstant(comments.get(0).updated.toInstant(), ZoneId.of("UTC")));
    // Build Message
    MailMessage.Builder b = messageBuilderWithDefaultFields();
    String txt = newPlaintextBody(canonicalWebUrl.get() + "#/c/" + changeInfo._number + "/1", "Test Message", null, null, null);
    b.textContent(txt + textFooterForChange(changeInfo._number, ts));
    mailProcessor.process(b.build());
    return changeInfo;
}
#end_block

#method_before
public String getSshKey() {
    return (sshKey != null) ? sshKey.getSshPublicKey() + "\n" : null;
}
#method_after
public String getSshKey() {
    return (sshKey != null) ? sshKey.sshPublicKey() + "\n" : null;
}
#end_block

#method_before
@Test
public void parseAndPersistChangeMessage() throws Exception {
    String changeId = createChangeWithReview();
    ChangeInfo changeInfo = gApi.changes().id(changeId).get();
    List<CommentInfo> comments = gApi.changes().id(changeId).current().commentsAsList();
    String ts = com.google.gerrit.server.mail.lib.MailUtil.rfcDateformatter.format(ZonedDateTime.ofInstant(comments.get(0).updated.toInstant(), ZoneId.of("UTC")));
    // Build Message
    MailMessage.Builder b = messageBuilderWithDefaultFields();
    String txt = newPlaintextBody(canonicalWebUrl.get() + "#/c/" + changeInfo._number + "/1", "Test Message", null, null, null);
    b.textContent(txt + textFooterForChange(changeInfo._number, ts));
    mailProcessor.process(b.build());
    Collection<ChangeMessageInfo> messages = gApi.changes().id(changeId).get().messages;
    assertThat(messages).hasSize(3);
    assertThat(Iterables.getLast(messages).message).isEqualTo("Patch Set 1:\n\nTest Message");
    assertThat(Iterables.getLast(messages).tag).isEqualTo("mailMessageId=some id");
}
#method_after
@Test
public void parseAndPersistChangeMessage() throws Exception {
    String changeId = createChangeWithReview();
    ChangeInfo changeInfo = gApi.changes().id(changeId).get();
    List<CommentInfo> comments = gApi.changes().id(changeId).current().commentsAsList();
    String ts = MailProcessingUtil.rfcDateformatter.format(ZonedDateTime.ofInstant(comments.get(0).updated.toInstant(), ZoneId.of("UTC")));
    // Build Message
    MailMessage.Builder b = messageBuilderWithDefaultFields();
    String txt = newPlaintextBody(canonicalWebUrl.get() + "#/c/" + changeInfo._number + "/1", "Test Message", null, null, null);
    b.textContent(txt + textFooterForChange(changeInfo._number, ts));
    mailProcessor.process(b.build());
    Collection<ChangeMessageInfo> messages = gApi.changes().id(changeId).get().messages;
    assertThat(messages).hasSize(3);
    assertThat(Iterables.getLast(messages).message).isEqualTo("Patch Set 1:\n\nTest Message");
    assertThat(Iterables.getLast(messages).tag).isEqualTo("mailMessageId=some id");
}
#end_block

#method_before
@Test
public void parseAndPersistInlineComment() throws Exception {
    String changeId = createChangeWithReview();
    ChangeInfo changeInfo = gApi.changes().id(changeId).get();
    List<CommentInfo> comments = gApi.changes().id(changeId).current().commentsAsList();
    String ts = com.google.gerrit.server.mail.lib.MailUtil.rfcDateformatter.format(ZonedDateTime.ofInstant(comments.get(0).updated.toInstant(), ZoneId.of("UTC")));
    // Build Message
    MailMessage.Builder b = messageBuilderWithDefaultFields();
    String txt = newPlaintextBody(canonicalWebUrl.get() + "#/c/" + changeInfo._number + "/1", null, "Some Inline Comment", null, null);
    b.textContent(txt + textFooterForChange(changeInfo._number, ts));
    mailProcessor.process(b.build());
    // Assert messages
    Collection<ChangeMessageInfo> messages = gApi.changes().id(changeId).get().messages;
    assertThat(messages).hasSize(3);
    assertThat(Iterables.getLast(messages).message).isEqualTo("Patch Set 1:\n\n(1 comment)");
    assertThat(Iterables.getLast(messages).tag).isEqualTo("mailMessageId=some id");
    // Assert comment
    comments = gApi.changes().id(changeId).current().commentsAsList();
    assertThat(comments).hasSize(3);
    assertThat(comments.get(2).message).isEqualTo("Some Inline Comment");
    assertThat(comments.get(2).tag).isEqualTo("mailMessageId=some id");
    assertThat(comments.get(2).inReplyTo).isEqualTo(comments.get(1).id);
}
#method_after
@Test
public void parseAndPersistInlineComment() throws Exception {
    String changeId = createChangeWithReview();
    ChangeInfo changeInfo = gApi.changes().id(changeId).get();
    List<CommentInfo> comments = gApi.changes().id(changeId).current().commentsAsList();
    String ts = MailProcessingUtil.rfcDateformatter.format(ZonedDateTime.ofInstant(comments.get(0).updated.toInstant(), ZoneId.of("UTC")));
    // Build Message
    MailMessage.Builder b = messageBuilderWithDefaultFields();
    String txt = newPlaintextBody(canonicalWebUrl.get() + "#/c/" + changeInfo._number + "/1", null, "Some Inline Comment", null, null);
    b.textContent(txt + textFooterForChange(changeInfo._number, ts));
    mailProcessor.process(b.build());
    // Assert messages
    Collection<ChangeMessageInfo> messages = gApi.changes().id(changeId).get().messages;
    assertThat(messages).hasSize(3);
    assertThat(Iterables.getLast(messages).message).isEqualTo("Patch Set 1:\n\n(1 comment)");
    assertThat(Iterables.getLast(messages).tag).isEqualTo("mailMessageId=some id");
    // Assert comment
    comments = gApi.changes().id(changeId).current().commentsAsList();
    assertThat(comments).hasSize(3);
    assertThat(comments.get(2).message).isEqualTo("Some Inline Comment");
    assertThat(comments.get(2).tag).isEqualTo("mailMessageId=some id");
    assertThat(comments.get(2).inReplyTo).isEqualTo(comments.get(1).id);
}
#end_block

#method_before
@Test
public void parseAndPersistFileComment() throws Exception {
    String changeId = createChangeWithReview();
    ChangeInfo changeInfo = gApi.changes().id(changeId).get();
    List<CommentInfo> comments = gApi.changes().id(changeId).current().commentsAsList();
    String ts = com.google.gerrit.server.mail.lib.MailUtil.rfcDateformatter.format(ZonedDateTime.ofInstant(comments.get(0).updated.toInstant(), ZoneId.of("UTC")));
    // Build Message
    MailMessage.Builder b = messageBuilderWithDefaultFields();
    String txt = newPlaintextBody(canonicalWebUrl.get() + "#/c/" + changeInfo._number + "/1", null, null, "Some Comment on File 1", null);
    b.textContent(txt + textFooterForChange(changeInfo._number, ts));
    mailProcessor.process(b.build());
    // Assert messages
    Collection<ChangeMessageInfo> messages = gApi.changes().id(changeId).get().messages;
    assertThat(messages).hasSize(3);
    assertThat(Iterables.getLast(messages).message).isEqualTo("Patch Set 1:\n\n(1 comment)");
    assertThat(Iterables.getLast(messages).tag).isEqualTo("mailMessageId=some id");
    // Assert comment
    comments = gApi.changes().id(changeId).current().commentsAsList();
    assertThat(comments).hasSize(3);
    assertThat(comments.get(0).message).isEqualTo("Some Comment on File 1");
    assertThat(comments.get(0).inReplyTo).isNull();
    assertThat(comments.get(0).tag).isEqualTo("mailMessageId=some id");
    assertThat(comments.get(0).path).isEqualTo("gerrit-server/test.txt");
}
#method_after
@Test
public void parseAndPersistFileComment() throws Exception {
    String changeId = createChangeWithReview();
    ChangeInfo changeInfo = gApi.changes().id(changeId).get();
    List<CommentInfo> comments = gApi.changes().id(changeId).current().commentsAsList();
    String ts = MailProcessingUtil.rfcDateformatter.format(ZonedDateTime.ofInstant(comments.get(0).updated.toInstant(), ZoneId.of("UTC")));
    // Build Message
    MailMessage.Builder b = messageBuilderWithDefaultFields();
    String txt = newPlaintextBody(canonicalWebUrl.get() + "#/c/" + changeInfo._number + "/1", null, null, "Some Comment on File 1", null);
    b.textContent(txt + textFooterForChange(changeInfo._number, ts));
    mailProcessor.process(b.build());
    // Assert messages
    Collection<ChangeMessageInfo> messages = gApi.changes().id(changeId).get().messages;
    assertThat(messages).hasSize(3);
    assertThat(Iterables.getLast(messages).message).isEqualTo("Patch Set 1:\n\n(1 comment)");
    assertThat(Iterables.getLast(messages).tag).isEqualTo("mailMessageId=some id");
    // Assert comment
    comments = gApi.changes().id(changeId).current().commentsAsList();
    assertThat(comments).hasSize(3);
    assertThat(comments.get(0).message).isEqualTo("Some Comment on File 1");
    assertThat(comments.get(0).inReplyTo).isNull();
    assertThat(comments.get(0).tag).isEqualTo("mailMessageId=some id");
    assertThat(comments.get(0).path).isEqualTo("gerrit-server/test.txt");
}
#end_block

#method_before
@Test
public void parseAndPersistMessageTwice() throws Exception {
    String changeId = createChangeWithReview();
    ChangeInfo changeInfo = gApi.changes().id(changeId).get();
    List<CommentInfo> comments = gApi.changes().id(changeId).current().commentsAsList();
    String ts = com.google.gerrit.server.mail.lib.MailUtil.rfcDateformatter.format(ZonedDateTime.ofInstant(comments.get(0).updated.toInstant(), ZoneId.of("UTC")));
    // Build Message
    MailMessage.Builder b = messageBuilderWithDefaultFields();
    String txt = newPlaintextBody(canonicalWebUrl.get() + "#/c/" + changeInfo._number + "/1", null, "Some Inline Comment", null, null);
    b.textContent(txt + textFooterForChange(changeInfo._number, ts));
    mailProcessor.process(b.build());
    comments = gApi.changes().id(changeId).current().commentsAsList();
    assertThat(comments).hasSize(3);
    // Check that the comment has not been persisted a second time
    mailProcessor.process(b.build());
    comments = gApi.changes().id(changeId).current().commentsAsList();
    assertThat(comments).hasSize(3);
}
#method_after
@Test
public void parseAndPersistMessageTwice() throws Exception {
    String changeId = createChangeWithReview();
    ChangeInfo changeInfo = gApi.changes().id(changeId).get();
    List<CommentInfo> comments = gApi.changes().id(changeId).current().commentsAsList();
    String ts = MailProcessingUtil.rfcDateformatter.format(ZonedDateTime.ofInstant(comments.get(0).updated.toInstant(), ZoneId.of("UTC")));
    // Build Message
    MailMessage.Builder b = messageBuilderWithDefaultFields();
    String txt = newPlaintextBody(canonicalWebUrl.get() + "#/c/" + changeInfo._number + "/1", null, "Some Inline Comment", null, null);
    b.textContent(txt + textFooterForChange(changeInfo._number, ts));
    mailProcessor.process(b.build());
    comments = gApi.changes().id(changeId).current().commentsAsList();
    assertThat(comments).hasSize(3);
    // Check that the comment has not been persisted a second time
    mailProcessor.process(b.build());
    comments = gApi.changes().id(changeId).current().commentsAsList();
    assertThat(comments).hasSize(3);
}
#end_block

#method_before
@Test
public void parseAndPersistMessageFromInactiveAccount() throws Exception {
    String changeId = createChangeWithReview();
    ChangeInfo changeInfo = gApi.changes().id(changeId).get();
    List<CommentInfo> comments = gApi.changes().id(changeId).current().commentsAsList();
    String ts = com.google.gerrit.server.mail.lib.MailUtil.rfcDateformatter.format(ZonedDateTime.ofInstant(comments.get(0).updated.toInstant(), ZoneId.of("UTC")));
    assertThat(comments).hasSize(2);
    // Build Message
    MailMessage.Builder b = messageBuilderWithDefaultFields();
    String txt = newPlaintextBody(canonicalWebUrl.get() + "#/c/" + changeInfo._number + "/1", null, "Some Inline Comment", null, null);
    b.textContent(txt + textFooterForChange(changeInfo._number, ts));
    // Set account state to inactive
    gApi.accounts().id("user").setActive(false);
    mailProcessor.process(b.build());
    comments = gApi.changes().id(changeId).current().commentsAsList();
    // Check that comment size has not changed
    assertThat(comments).hasSize(2);
    // Reset
    gApi.accounts().id("user").setActive(true);
}
#method_after
@Test
public void parseAndPersistMessageFromInactiveAccount() throws Exception {
    String changeId = createChangeWithReview();
    ChangeInfo changeInfo = gApi.changes().id(changeId).get();
    List<CommentInfo> comments = gApi.changes().id(changeId).current().commentsAsList();
    String ts = MailProcessingUtil.rfcDateformatter.format(ZonedDateTime.ofInstant(comments.get(0).updated.toInstant(), ZoneId.of("UTC")));
    assertThat(comments).hasSize(2);
    // Build Message
    MailMessage.Builder b = messageBuilderWithDefaultFields();
    String txt = newPlaintextBody(canonicalWebUrl.get() + "#/c/" + changeInfo._number + "/1", null, "Some Inline Comment", null, null);
    b.textContent(txt + textFooterForChange(changeInfo._number, ts));
    // Set account state to inactive
    gApi.accounts().id("user").setActive(false);
    mailProcessor.process(b.build());
    comments = gApi.changes().id(changeId).current().commentsAsList();
    // Check that comment size has not changed
    assertThat(comments).hasSize(2);
    // Reset
    gApi.accounts().id("user").setActive(true);
}
#end_block

#method_before
@Test
public void sendNotificationAfterPersistingComments() throws Exception {
    String changeId = createChangeWithReview();
    ChangeInfo changeInfo = gApi.changes().id(changeId).get();
    List<CommentInfo> comments = gApi.changes().id(changeId).current().commentsAsList();
    assertThat(comments).hasSize(2);
    String ts = com.google.gerrit.server.mail.lib.MailUtil.rfcDateformatter.format(ZonedDateTime.ofInstant(comments.get(0).updated.toInstant(), ZoneId.of("UTC")));
    // Build Message
    String txt = newPlaintextBody(canonicalWebUrl.get() + "#/c/" + changeInfo._number + "/1", "Test Message", null, null, null);
    MailMessage.Builder b = messageBuilderWithDefaultFields().from(user.emailAddress).textContent(txt + textFooterForChange(changeInfo._number, ts));
    sender.clear();
    mailProcessor.process(b.build());
    assertNotifyTo(admin);
}
#method_after
@Test
public void sendNotificationAfterPersistingComments() throws Exception {
    String changeId = createChangeWithReview();
    ChangeInfo changeInfo = gApi.changes().id(changeId).get();
    List<CommentInfo> comments = gApi.changes().id(changeId).current().commentsAsList();
    assertThat(comments).hasSize(2);
    String ts = MailProcessingUtil.rfcDateformatter.format(ZonedDateTime.ofInstant(comments.get(0).updated.toInstant(), ZoneId.of("UTC")));
    // Build Message
    String txt = newPlaintextBody(canonicalWebUrl.get() + "#/c/" + changeInfo._number + "/1", "Test Message", null, null, null);
    MailMessage.Builder b = messageBuilderWithDefaultFields().from(user.emailAddress).textContent(txt + textFooterForChange(changeInfo._number, ts));
    sender.clear();
    mailProcessor.process(b.build());
    assertNotifyTo(admin);
}
#end_block

#method_before
public static ReviewerSet parseReviewerFieldValues(Iterable<String> values) {
    ImmutableTable.Builder<ReviewerStateInternal, Account.Id, Timestamp> b = ImmutableTable.builder();
    for (String v : values) {
        int f = v.indexOf(',');
        if (f < 0) {
            continue;
        }
        int l = v.lastIndexOf(',');
        if (l == f) {
            continue;
        }
        b.put(ReviewerStateInternal.valueOf(v.substring(0, f)), Account.Id.parse(v.substring(f + 1, l)), new Timestamp(Long.valueOf(v.substring(l + 1, v.length()))));
    }
    return ReviewerSet.fromTable(b.build());
}
#method_after
public static ReviewerSet parseReviewerFieldValues(Change.Id changeId, Iterable<String> values) {
    ImmutableTable.Builder<ReviewerStateInternal, Account.Id, Timestamp> b = ImmutableTable.builder();
    for (String v : values) {
        int i = v.indexOf(',');
        if (i < 0) {
            logger.atWarning().log("Invalid value for reviewer field from change %s: %s", changeId.get(), v);
            continue;
        }
        int i2 = v.lastIndexOf(',');
        if (i2 == i) {
            // value and the "<reviewer-type>,<account-id>" value is ignored here.
            continue;
        }
        com.google.common.base.Optional<ReviewerStateInternal> reviewerState = Enums.getIfPresent(ReviewerStateInternal.class, v.substring(0, i));
        if (!reviewerState.isPresent()) {
            logger.atWarning().log("Failed to parse reviewer state of reviewer field from change %s: %s", changeId.get(), v);
            continue;
        }
        Optional<Account.Id> accountId = Account.Id.tryParse(v.substring(i + 1, i2));
        if (!accountId.isPresent()) {
            logger.atWarning().log("Failed to parse account ID of reviewer field from change %s: %s", changeId.get(), v);
            continue;
        }
        Long l = Longs.tryParse(v.substring(i2 + 1, v.length()));
        if (l == null) {
            logger.atWarning().log("Failed to parse timestamp of reviewer field from change %s: %s", changeId.get(), v);
            continue;
        }
        Timestamp timestamp = new Timestamp(l);
        b.put(reviewerState.get(), accountId.get(), timestamp);
    }
    return ReviewerSet.fromTable(b.build());
}
#end_block

#method_before
public static ReviewerByEmailSet parseReviewerByEmailFieldValues(Iterable<String> values) {
    ImmutableTable.Builder<ReviewerStateInternal, Address, Timestamp> b = ImmutableTable.builder();
    for (String v : values) {
        int f = v.indexOf(',');
        if (f < 0) {
            continue;
        }
        int l = v.lastIndexOf(',');
        if (l == f) {
            continue;
        }
        b.put(ReviewerStateInternal.valueOf(v.substring(0, f)), Address.parse(v.substring(f + 1, l)), new Timestamp(Long.valueOf(v.substring(l + 1, v.length()))));
    }
    return ReviewerByEmailSet.fromTable(b.build());
}
#method_after
public static ReviewerByEmailSet parseReviewerByEmailFieldValues(Change.Id changeId, Iterable<String> values) {
    ImmutableTable.Builder<ReviewerStateInternal, Address, Timestamp> b = ImmutableTable.builder();
    for (String v : values) {
        int i = v.indexOf(',');
        if (i < 0) {
            logger.atWarning().log("Invalid value for reviewer by email field from change %s: %s", changeId.get(), v);
            continue;
        }
        int i2 = v.lastIndexOf(',');
        if (i2 == i) {
            // and the "<reviewer-type>,<email>" value is ignored here.
            continue;
        }
        com.google.common.base.Optional<ReviewerStateInternal> reviewerState = Enums.getIfPresent(ReviewerStateInternal.class, v.substring(0, i));
        if (!reviewerState.isPresent()) {
            logger.atWarning().log("Failed to parse reviewer state of reviewer by email field from change %s: %s", changeId.get(), v);
            continue;
        }
        Address address = Address.tryParse(v.substring(i + 1, i2));
        if (address == null) {
            logger.atWarning().log("Failed to parse address of reviewer by email field from change %s: %s", changeId.get(), v);
            continue;
        }
        Long l = Longs.tryParse(v.substring(i2 + 1, v.length()));
        if (l == null) {
            logger.atWarning().log("Failed to parse timestamp of reviewer by email field from change %s: %s", changeId.get(), v);
            continue;
        }
        Timestamp timestamp = new Timestamp(l);
        b.put(reviewerState.get(), address, timestamp);
    }
    return ReviewerByEmailSet.fromTable(b.build());
}
#end_block

#method_before
private SubmitRecord toSubmitRecord() {
    SubmitRecord rec = new SubmitRecord();
    rec.status = status;
    rec.errorMessage = errorMessage;
    if (labels != null) {
        rec.labels = new ArrayList<>(labels.size());
        for (StoredLabel label : labels) {
            SubmitRecord.Label srl = new SubmitRecord.Label();
            srl.label = label.label;
            srl.status = label.status;
            srl.appliedBy = label.appliedBy != null ? new Account.Id(label.appliedBy) : null;
            rec.labels.add(srl);
        }
    }
    return rec;
}
#method_after
public SubmitRecord toSubmitRecord() {
    SubmitRecord rec = new SubmitRecord();
    rec.status = status;
    rec.errorMessage = errorMessage;
    if (labels != null) {
        rec.labels = new ArrayList<>(labels.size());
        for (StoredLabel label : labels) {
            SubmitRecord.Label srl = new SubmitRecord.Label();
            srl.label = label.label;
            srl.status = label.status;
            srl.appliedBy = label.appliedBy != null ? new Account.Id(label.appliedBy) : null;
            rec.labels.add(srl);
        }
    }
    if (requirements != null) {
        rec.requirements = new ArrayList<>(requirements.size());
        for (StoredRequirement req : requirements) {
            SubmitRequirement sr = SubmitRequirement.builder().setType(req.type).setFallbackText(req.fallbackText).setData(req.data).build();
            rec.requirements.add(sr);
        }
    }
    return rec;
}
#end_block

#method_before
private static Iterable<byte[]> storedSubmitRecords(ChangeData cd, SubmitRuleOptions opts) throws OrmException {
    return storedSubmitRecords(cd.submitRecords(opts));
}
#method_after
private static Iterable<byte[]> storedSubmitRecords(ChangeData cd, SubmitRuleOptions opts) {
    return storedSubmitRecords(cd.submitRecords(opts));
}
#end_block

#method_before
@VisibleForTesting
ChangeDraftUpdate createDraftUpdateIfNull() {
    if (draftUpdate == null) {
        ChangeNotes notes = getNotes();
        if (notes != null) {
            draftUpdate = draftUpdateFactory.create(notes, accountId, realAccountId, authorIdent, when);
        } else {
            draftUpdate = draftUpdateFactory.create(getChange(), accountId, realAccountId, authorIdent, when);
        }
    }
    return draftUpdate;
}
#method_after
@VisibleForTesting
ChangeDraftUpdate createDraftUpdateIfNull() {
    if (draftUpdate == null) {
        ChangeNotes notes = getNotes();
        if (notes != null) {
            draftUpdate = draftUpdateFactory.create(notes, accountId, realAccountId, authorIdent, when);
        } else {
            // tests will always take the notes != null path above.
            draftUpdate = draftUpdateFactory.create(getChange(), accountId, realAccountId, authorIdent, when);
        }
    }
    return draftUpdate;
}
#end_block

#method_before
private ObjectId storeRevisionNotes(RevWalk rw, ObjectInserter inserter, ObjectId curr) throws ConfigInvalidException, OrmException, IOException {
    if (comments.isEmpty() && pushCert == null) {
        return null;
    }
    RevisionNoteMap<ChangeRevisionNote> rnm = getRevisionNoteMap(rw, curr);
    RevisionNoteBuilder.Cache cache = new RevisionNoteBuilder.Cache(rnm);
    for (Comment c : comments) {
        c.tag = tag;
        cache.get(new RevId(c.revId)).putComment(c);
    }
    if (pushCert != null) {
        checkState(commit != null);
        cache.get(new RevId(commit)).setPushCertificate(pushCert);
    }
    Map<RevId, RevisionNoteBuilder> builders = cache.getBuilders();
    checkComments(rnm.revisionNotes, builders);
    for (Map.Entry<RevId, RevisionNoteBuilder> e : builders.entrySet()) {
        ObjectId data = inserter.insert(OBJ_BLOB, e.getValue().build(noteUtil, noteUtil.getWriteJson()));
        rnm.noteMap.set(ObjectId.fromString(e.getKey().get()), data);
    }
    return rnm.noteMap.writeTree(inserter);
}
#method_after
private ObjectId storeRevisionNotes(RevWalk rw, ObjectInserter inserter, ObjectId curr) throws ConfigInvalidException, OrmException, IOException {
    if (comments.isEmpty() && pushCert == null) {
        return null;
    }
    RevisionNoteMap<ChangeRevisionNote> rnm = getRevisionNoteMap(rw, curr);
    RevisionNoteBuilder.Cache cache = new RevisionNoteBuilder.Cache(rnm);
    for (Comment c : comments) {
        c.tag = tag;
        cache.get(new RevId(c.revId)).putComment(c);
    }
    if (pushCert != null) {
        checkState(commit != null);
        cache.get(new RevId(commit)).setPushCertificate(pushCert);
    }
    Map<RevId, RevisionNoteBuilder> builders = cache.getBuilders();
    checkComments(rnm.revisionNotes, builders);
    for (Map.Entry<RevId, RevisionNoteBuilder> e : builders.entrySet()) {
        ObjectId data = inserter.insert(OBJ_BLOB, e.getValue().build(noteUtil.getChangeNoteJson()));
        rnm.noteMap.set(ObjectId.fromString(e.getKey().get()), data);
    }
    return rnm.noteMap.writeTree(inserter);
}
#end_block

#method_before
private RevisionNoteMap<ChangeRevisionNote> getRevisionNoteMap(RevWalk rw, ObjectId curr) throws ConfigInvalidException, OrmException, IOException {
    if (curr.equals(ObjectId.zeroId())) {
        return RevisionNoteMap.emptyMap();
    }
    if (migration.readChanges()) {
        // If reading from changes is enabled, then the old ChangeNotes may have
        // already parsed the revision notes. We can reuse them as long as the ref
        // hasn't advanced.
        ChangeNotes notes = getNotes();
        if (notes != null && notes.revisionNoteMap != null) {
            ObjectId idFromNotes = firstNonNull(notes.load().getRevision(), ObjectId.zeroId());
            if (idFromNotes.equals(curr)) {
                return notes.revisionNoteMap;
            }
        }
    }
    NoteMap noteMap = NoteMap.read(rw.getObjectReader(), rw.parseCommit(curr));
    // parse any existing revision notes so we can merge them.
    return RevisionNoteMap.parse(noteUtil, getId(), rw.getObjectReader(), noteMap, PatchLineComment.Status.PUBLISHED);
}
#method_after
private RevisionNoteMap<ChangeRevisionNote> getRevisionNoteMap(RevWalk rw, ObjectId curr) throws ConfigInvalidException, OrmException, IOException {
    if (curr.equals(ObjectId.zeroId())) {
        return RevisionNoteMap.emptyMap();
    }
    if (migration.readChanges()) {
        // If reading from changes is enabled, then the old ChangeNotes may have
        // already parsed the revision notes. We can reuse them as long as the ref
        // hasn't advanced.
        ChangeNotes notes = getNotes();
        if (notes != null && notes.revisionNoteMap != null) {
            ObjectId idFromNotes = firstNonNull(notes.load().getRevision(), ObjectId.zeroId());
            if (idFromNotes.equals(curr)) {
                return notes.revisionNoteMap;
            }
        }
    }
    NoteMap noteMap = NoteMap.read(rw.getObjectReader(), rw.parseCommit(curr));
    // parse any existing revision notes so we can merge them.
    return RevisionNoteMap.parse(noteUtil.getChangeNoteJson(), noteUtil.getLegacyChangeNoteRead(), getId(), rw.getObjectReader(), noteMap, PatchLineComment.Status.PUBLISHED);
}
#end_block

#method_before
@Override
protected CommitBuilder applyImpl(RevWalk rw, ObjectInserter ins, ObjectId curr) throws OrmException, IOException {
    checkState(deleteCommentRewriter == null, "cannot update and rewrite ref in one BatchUpdate");
    CommitBuilder cb = new CommitBuilder();
    int ps = psId != null ? psId.get() : getChange().currentPatchSetId().get();
    StringBuilder msg = new StringBuilder();
    if (commitSubject != null) {
        msg.append(commitSubject);
    } else {
        msg.append("Update patch set ").append(ps);
    }
    msg.append("\n\n");
    if (changeMessage != null) {
        msg.append(changeMessage);
        msg.append("\n\n");
    }
    addPatchSetFooter(msg, ps);
    if (currentPatchSet) {
        addFooter(msg, FOOTER_CURRENT, Boolean.TRUE);
    }
    if (psDescription != null) {
        addFooter(msg, FOOTER_PATCH_SET_DESCRIPTION, psDescription);
    }
    if (changeId != null) {
        addFooter(msg, FOOTER_CHANGE_ID, changeId);
    }
    if (subject != null) {
        addFooter(msg, FOOTER_SUBJECT, subject);
    }
    if (branch != null) {
        addFooter(msg, FOOTER_BRANCH, branch);
    }
    if (status != null) {
        addFooter(msg, FOOTER_STATUS, status.name().toLowerCase());
    }
    if (topic != null) {
        addFooter(msg, FOOTER_TOPIC, topic);
    }
    if (commit != null) {
        addFooter(msg, FOOTER_COMMIT, commit);
    }
    if (assignee != null) {
        if (assignee.isPresent()) {
            addFooter(msg, FOOTER_ASSIGNEE);
            addIdent(msg, assignee.get()).append('\n');
        } else {
            addFooter(msg, FOOTER_ASSIGNEE).append('\n');
        }
    }
    Joiner comma = Joiner.on(',');
    if (hashtags != null) {
        addFooter(msg, FOOTER_HASHTAGS, comma.join(hashtags));
    }
    if (tag != null) {
        addFooter(msg, FOOTER_TAG, tag);
    }
    if (groups != null) {
        addFooter(msg, FOOTER_GROUPS, comma.join(groups));
    }
    for (Map.Entry<Account.Id, ReviewerStateInternal> e : reviewers.entrySet()) {
        addFooter(msg, e.getValue().getFooterKey());
        addIdent(msg, e.getKey()).append('\n');
    }
    for (Map.Entry<Address, ReviewerStateInternal> e : reviewersByEmail.entrySet()) {
        addFooter(msg, e.getValue().getByEmailFooterKey(), e.getKey().toString());
    }
    for (Table.Cell<String, Account.Id, Optional<Short>> c : approvals.cellSet()) {
        addFooter(msg, FOOTER_LABEL);
        // Label names/values are safe to append without sanitizing.
        if (!c.getValue().isPresent()) {
            msg.append('-').append(c.getRowKey());
        } else {
            msg.append(LabelVote.create(c.getRowKey(), c.getValue().get()).formatWithEquals());
        }
        Account.Id id = c.getColumnKey();
        if (!id.equals(getAccountId())) {
            addIdent(msg.append(' '), id);
        }
        msg.append('\n');
    }
    if (submissionId != null) {
        addFooter(msg, FOOTER_SUBMISSION_ID, submissionId);
    }
    if (submitRecords != null) {
        for (SubmitRecord rec : submitRecords) {
            addFooter(msg, FOOTER_SUBMITTED_WITH).append(rec.status);
            if (rec.errorMessage != null) {
                msg.append(' ').append(sanitizeFooter(rec.errorMessage));
            }
            msg.append('\n');
            if (rec.labels != null) {
                for (SubmitRecord.Label label : rec.labels) {
                    // Label names/values are safe to append without sanitizing.
                    addFooter(msg, FOOTER_SUBMITTED_WITH).append(label.status).append(": ").append(label.label);
                    if (label.appliedBy != null) {
                        msg.append(": ");
                        addIdent(msg, label.appliedBy);
                    }
                    msg.append('\n');
                }
            }
        }
    }
    if (!Objects.equals(accountId, realAccountId)) {
        addFooter(msg, FOOTER_REAL_USER);
        addIdent(msg, realAccountId).append('\n');
    }
    if (readOnlyUntil != null) {
        addFooter(msg, FOOTER_READ_ONLY_UNTIL, ChangeNoteUtil.formatTime(serverIdent, readOnlyUntil));
    }
    if (isPrivate != null) {
        addFooter(msg, FOOTER_PRIVATE, isPrivate);
    }
    if (workInProgress != null) {
        addFooter(msg, FOOTER_WORK_IN_PROGRESS, workInProgress);
    }
    if (revertOf != null) {
        addFooter(msg, FOOTER_REVERT_OF, revertOf);
    }
    cb.setMessage(msg.toString());
    try {
        ObjectId treeId = storeRevisionNotes(rw, ins, curr);
        if (treeId != null) {
            cb.setTreeId(treeId);
        }
    } catch (ConfigInvalidException e) {
        throw new OrmException(e);
    }
    return cb;
}
#method_after
@Override
protected CommitBuilder applyImpl(RevWalk rw, ObjectInserter ins, ObjectId curr) throws OrmException, IOException {
    checkState(deleteCommentRewriter == null, "cannot update and rewrite ref in one BatchUpdate");
    CommitBuilder cb = new CommitBuilder();
    int ps = psId != null ? psId.get() : getChange().currentPatchSetId().get();
    StringBuilder msg = new StringBuilder();
    if (commitSubject != null) {
        msg.append(commitSubject);
    } else {
        msg.append("Update patch set ").append(ps);
    }
    msg.append("\n\n");
    if (changeMessage != null) {
        msg.append(changeMessage);
        msg.append("\n\n");
    }
    addPatchSetFooter(msg, ps);
    if (currentPatchSet) {
        addFooter(msg, FOOTER_CURRENT, Boolean.TRUE);
    }
    if (psDescription != null) {
        addFooter(msg, FOOTER_PATCH_SET_DESCRIPTION, psDescription);
    }
    if (changeId != null) {
        addFooter(msg, FOOTER_CHANGE_ID, changeId);
    }
    if (subject != null) {
        addFooter(msg, FOOTER_SUBJECT, subject);
    }
    if (branch != null) {
        addFooter(msg, FOOTER_BRANCH, branch);
    }
    if (status != null) {
        addFooter(msg, FOOTER_STATUS, status.name().toLowerCase());
    }
    if (topic != null) {
        addFooter(msg, FOOTER_TOPIC, topic);
    }
    if (commit != null) {
        addFooter(msg, FOOTER_COMMIT, commit);
    }
    if (assignee != null) {
        if (assignee.isPresent()) {
            addFooter(msg, FOOTER_ASSIGNEE);
            addIdent(msg, assignee.get()).append('\n');
        } else {
            addFooter(msg, FOOTER_ASSIGNEE).append('\n');
        }
    }
    Joiner comma = Joiner.on(',');
    if (hashtags != null) {
        addFooter(msg, FOOTER_HASHTAGS, comma.join(hashtags));
    }
    if (tag != null) {
        addFooter(msg, FOOTER_TAG, tag);
    }
    if (groups != null) {
        addFooter(msg, FOOTER_GROUPS, comma.join(groups));
    }
    for (Map.Entry<Account.Id, ReviewerStateInternal> e : reviewers.entrySet()) {
        addFooter(msg, e.getValue().getFooterKey());
        addIdent(msg, e.getKey()).append('\n');
    }
    for (Map.Entry<Address, ReviewerStateInternal> e : reviewersByEmail.entrySet()) {
        addFooter(msg, e.getValue().getByEmailFooterKey(), e.getKey().toString());
    }
    for (Table.Cell<String, Account.Id, Optional<Short>> c : approvals.cellSet()) {
        addFooter(msg, FOOTER_LABEL);
        // Label names/values are safe to append without sanitizing.
        if (!c.getValue().isPresent()) {
            msg.append('-').append(c.getRowKey());
        } else {
            msg.append(LabelVote.create(c.getRowKey(), c.getValue().get()).formatWithEquals());
        }
        Account.Id id = c.getColumnKey();
        if (!id.equals(getAccountId())) {
            addIdent(msg.append(' '), id);
        }
        msg.append('\n');
    }
    if (submissionId != null) {
        addFooter(msg, FOOTER_SUBMISSION_ID, submissionId);
    }
    if (submitRecords != null) {
        for (SubmitRecord rec : submitRecords) {
            addFooter(msg, FOOTER_SUBMITTED_WITH).append(rec.status);
            if (rec.errorMessage != null) {
                msg.append(' ').append(sanitizeFooter(rec.errorMessage));
            }
            msg.append('\n');
            if (rec.labels != null) {
                for (SubmitRecord.Label label : rec.labels) {
                    // Label names/values are safe to append without sanitizing.
                    addFooter(msg, FOOTER_SUBMITTED_WITH).append(label.status).append(": ").append(label.label);
                    if (label.appliedBy != null) {
                        msg.append(": ");
                        addIdent(msg, label.appliedBy);
                    }
                    msg.append('\n');
                }
            }
        // TODO(maximeg) We might want to list plugins that validated this submission.
        }
    }
    if (!Objects.equals(accountId, realAccountId)) {
        addFooter(msg, FOOTER_REAL_USER);
        addIdent(msg, realAccountId).append('\n');
    }
    if (readOnlyUntil != null) {
        addFooter(msg, FOOTER_READ_ONLY_UNTIL, NoteDbUtil.formatTime(serverIdent, readOnlyUntil));
    }
    if (isPrivate != null) {
        addFooter(msg, FOOTER_PRIVATE, isPrivate);
    }
    if (workInProgress != null) {
        addFooter(msg, FOOTER_WORK_IN_PROGRESS, workInProgress);
    }
    if (revertOf != null) {
        addFooter(msg, FOOTER_REVERT_OF, revertOf);
    }
    cb.setMessage(msg.toString());
    try {
        ObjectId treeId = storeRevisionNotes(rw, ins, curr);
        if (treeId != null) {
            cb.setTreeId(treeId);
        }
    } catch (ConfigInvalidException e) {
        throw new OrmException(e);
    }
    return cb;
}
#end_block

#method_before
private StringBuilder addIdent(StringBuilder sb, Account.Id accountId) {
    Account account = accountCache.get(accountId).getAccount();
    PersonIdent ident = newIdent(account, when);
    PersonIdent.appendSanitized(sb, ident.getName());
    sb.append(" <");
    PersonIdent.appendSanitized(sb, ident.getEmailAddress());
    sb.append('>');
    return sb;
}
#method_after
private StringBuilder addIdent(StringBuilder sb, Account.Id accountId) {
    PersonIdent ident = newIdent(accountId, when);
    PersonIdent.appendSanitized(sb, ident.getName());
    sb.append(" <");
    PersonIdent.appendSanitized(sb, ident.getEmailAddress());
    sb.append('>');
    return sb;
}
#end_block

#method_before
private static void assertTextFooter(String body, Map<String, Object> want) throws Exception {
    for (Map.Entry<String, Object> entry : want.entrySet()) {
        if (entry.getValue() instanceof String) {
            assertThat(body).contains(entry.getKey() + ": " + entry.getValue());
        } else if (entry.getValue() instanceof Timestamp) {
            assertThat(body).contains(entry.getKey() + ": " + com.google.gerrit.server.mail.lib.MailUtil.rfcDateformatter.format(ZonedDateTime.ofInstant(((Timestamp) entry.getValue()).toInstant(), ZoneId.of("UTC"))));
        } else {
            throw new Exception("Object has unsupported type: " + entry.getValue().getClass().getName() + " must be java.util.Date or java.lang.String for key " + entry.getKey());
        }
    }
}
#method_after
private static void assertTextFooter(String body, Map<String, Object> want) throws Exception {
    for (Map.Entry<String, Object> entry : want.entrySet()) {
        if (entry.getValue() instanceof String) {
            assertThat(body).contains(entry.getKey() + ": " + entry.getValue());
        } else if (entry.getValue() instanceof Timestamp) {
            assertThat(body).contains(entry.getKey() + ": " + MailProcessingUtil.rfcDateformatter.format(ZonedDateTime.ofInstant(((Timestamp) entry.getValue()).toInstant(), ZoneId.of("UTC"))));
        } else {
            throw new Exception("Object has unsupported type: " + entry.getValue().getClass().getName() + " must be java.util.Date or java.lang.String for key " + entry.getKey());
        }
    }
}
#end_block

#method_before
@Override
public void send(final Address from, Collection<Address> rcpt, final Map<String, EmailHeader> callerHeaders, String textBody, @Nullable String htmlBody) throws EmailException {
    if (!isEnabled()) {
        throw new EmailException("Sending email is disabled");
    }
    StringBuffer rejected = new StringBuffer();
    try {
        final SMTPClient client = open();
        try {
            if (!client.setSender(from.getEmail())) {
                throw new EmailException("Server " + smtpHost + " rejected from address " + from.getEmail());
            }
            /* Do not prevent the email from being sent to "good" users simply
         * because some users get rejected.  If not, a single rejected
         * project watcher could prevent email for most actions on a project
         * from being sent to any user!  Instead, queue up the errors, and
         * throw an exception after sending the email to get the rejected
         * error(s) logged.
         */
            for (Address addr : rcpt) {
                if (!client.addRecipient(addr.getEmail())) {
                    String error = client.getReplyString();
                    rejected.append("Server ").append(smtpHost).append(" rejected recipient ").append(addr).append(": ").append(error);
                }
            }
            Writer messageDataWriter = client.sendMessageData();
            if (messageDataWriter == null) {
                /* Include rejected recipient error messages here to not lose that
           * information. That piece of the puzzle is vital if zero recipients
           * are accepted and the server consequently rejects the DATA command.
           */
                throw new EmailException(rejected + "Server " + smtpHost + " rejected DATA command: " + client.getReplyString());
            }
            render(messageDataWriter, callerHeaders, textBody, htmlBody);
            if (!client.completePendingCommand()) {
                throw new EmailException("Server " + smtpHost + " rejected message body: " + client.getReplyString());
            }
            client.logout();
            if (rejected.length() > 0) {
                throw new EmailException(rejected.toString());
            }
        } finally {
            client.disconnect();
        }
    } catch (IOException e) {
        throw new EmailException("Cannot send outgoing email", e);
    }
}
#method_after
@Override
public void send(final Address from, Collection<Address> rcpt, final Map<String, EmailHeader> callerHeaders, String textBody, @Nullable String htmlBody) throws EmailException {
    if (!isEnabled()) {
        throw new EmailException("Sending email is disabled");
    }
    StringBuffer rejected = new StringBuffer();
    try {
        final SMTPClient client = open();
        try {
            if (!client.setSender(from.getEmail())) {
                throw new EmailException("Server " + smtpHost + " rejected from address " + from.getEmail());
            }
            /* Do not prevent the email from being sent to "good" users simply
         * because some users get rejected.  If not, a single rejected
         * project watcher could prevent email for most actions on a project
         * from being sent to any user!  Instead, queue up the errors, and
         * throw an exception after sending the email to get the rejected
         * error(s) logged.
         */
            for (Address addr : rcpt) {
                if (!client.addRecipient(addr.getEmail())) {
                    String error = client.getReplyString();
                    rejected.append("Server ").append(smtpHost).append(" rejected recipient ").append(addr).append(": ").append(error);
                }
            }
            try (Writer messageDataWriter = client.sendMessageData()) {
                if (messageDataWriter == null) {
                    /* Include rejected recipient error messages here to not lose that
             * information. That piece of the puzzle is vital if zero recipients
             * are accepted and the server consequently rejects the DATA command.
             */
                    throw new EmailException(rejected + "Server " + smtpHost + " rejected DATA command: " + client.getReplyString());
                }
                render(messageDataWriter, callerHeaders, textBody, htmlBody);
                if (!client.completePendingCommand()) {
                    throw new EmailException("Server " + smtpHost + " rejected message body: " + client.getReplyString());
                }
                client.logout();
                if (rejected.length() > 0) {
                    throw new EmailException(rejected.toString());
                }
            }
        } finally {
            client.disconnect();
        }
    } catch (IOException e) {
        throw new EmailException("Cannot send outgoing email", e);
    }
}
#end_block

