448
#method_before
@Override
protected void configure() {
    bind(ChangesCollection.class);
    bind(Revisions.class);
    bind(Reviewers.class);
    bind(DraftComments.class);
    bind(Comments.class);
    bind(Files.class);
    bind(Votes.class);
    DynamicMap.mapOf(binder(), CHANGE_KIND);
    DynamicMap.mapOf(binder(), COMMENT_KIND);
    DynamicMap.mapOf(binder(), DRAFT_COMMENT_KIND);
    DynamicMap.mapOf(binder(), FILE_KIND);
    DynamicMap.mapOf(binder(), REVIEWER_KIND);
    DynamicMap.mapOf(binder(), REVISION_KIND);
    DynamicMap.mapOf(binder(), CHANGE_EDIT_KIND);
    DynamicMap.mapOf(binder(), VOTE_KIND);
    get(CHANGE_KIND).to(GetChange.class);
    get(CHANGE_KIND, "detail").to(GetDetail.class);
    get(CHANGE_KIND, "topic").to(GetTopic.class);
    get(CHANGE_KIND, "in").to(IncludedIn.class);
    get(CHANGE_KIND, "hashtags").to(GetHashtags.class);
    get(CHANGE_KIND, "comments").to(ListChangeComments.class);
    get(CHANGE_KIND, "drafts").to(ListChangeDrafts.class);
    get(CHANGE_KIND, "check").to(Check.class);
    post(CHANGE_KIND, "check").to(Check.class);
    put(CHANGE_KIND, "topic").to(PutTopic.class);
    delete(CHANGE_KIND, "topic").to(PutTopic.class);
    delete(CHANGE_KIND).to(DeleteDraftChange.class);
    post(CHANGE_KIND, "abandon").to(Abandon.class);
    post(CHANGE_KIND, "hashtags").to(PostHashtags.class);
    post(CHANGE_KIND, "publish").to(PublishDraftPatchSet.CurrentRevision.class);
    post(CHANGE_KIND, "restore").to(Restore.class);
    post(CHANGE_KIND, "revert").to(Revert.class);
    post(CHANGE_KIND, "submit").to(Submit.CurrentRevision.class);
    get(CHANGE_KIND, "submitted_together").to(SubmittedTogether.class);
    post(CHANGE_KIND, "rebase").to(Rebase.CurrentRevision.class);
    post(CHANGE_KIND, "index").to(Index.class);
    post(CHANGE_KIND, "rebuild.notedb").to(Rebuild.class);
    post(CHANGE_KIND, "move").to(Move.class);
    post(CHANGE_KIND, "reviewers").to(PostReviewers.class);
    get(CHANGE_KIND, "suggest_reviewers").to(SuggestChangeReviewers.class);
    child(CHANGE_KIND, "reviewers").to(Reviewers.class);
    get(REVIEWER_KIND).to(GetReviewer.class);
    delete(REVIEWER_KIND).to(DeleteReviewer.class);
    child(REVIEWER_KIND, "votes").to(Votes.class);
    delete(VOTE_KIND).to(DeleteVote.class);
    post(VOTE_KIND, "delete").to(DeleteVote.class);
    child(CHANGE_KIND, "revisions").to(Revisions.class);
    get(REVISION_KIND, "actions").to(GetRevisionActions.class);
    post(REVISION_KIND, "cherrypick").to(CherryPick.class);
    get(REVISION_KIND, "commit").to(GetCommit.class);
    delete(REVISION_KIND).to(DeleteDraftPatchSet.class);
    get(REVISION_KIND, "mergeable").to(Mergeable.class);
    post(REVISION_KIND, "publish").to(PublishDraftPatchSet.class);
    get(REVISION_KIND, "related").to(GetRelated.class);
    get(REVISION_KIND, "review").to(GetReview.class);
    post(REVISION_KIND, "review").to(PostReview.class);
    post(REVISION_KIND, "submit").to(Submit.class);
    get(REVISION_KIND, "submit_prediction").to(SubmitPrediction.class);
    post(REVISION_KIND, "rebase").to(Rebase.class);
    get(REVISION_KIND, "patch").to(GetPatch.class);
    get(REVISION_KIND, "submit_type").to(TestSubmitType.Get.class);
    post(REVISION_KIND, "test.submit_rule").to(TestSubmitRule.class);
    post(REVISION_KIND, "test.submit_type").to(TestSubmitType.class);
    get(REVISION_KIND, "archive").to(GetArchive.class);
    child(REVISION_KIND, "drafts").to(DraftComments.class);
    put(REVISION_KIND, "drafts").to(CreateDraftComment.class);
    get(DRAFT_COMMENT_KIND).to(GetDraftComment.class);
    put(DRAFT_COMMENT_KIND).to(PutDraftComment.class);
    delete(DRAFT_COMMENT_KIND).to(DeleteDraftComment.class);
    child(REVISION_KIND, "comments").to(Comments.class);
    get(COMMENT_KIND).to(GetComment.class);
    child(REVISION_KIND, "files").to(Files.class);
    put(FILE_KIND, "reviewed").to(PutReviewed.class);
    delete(FILE_KIND, "reviewed").to(DeleteReviewed.class);
    get(FILE_KIND, "content").to(GetContent.class);
    get(FILE_KIND, "download").to(DownloadContent.class);
    get(FILE_KIND, "diff").to(GetDiff.class);
    get(FILE_KIND, "blame").to(GetBlame.class);
    child(CHANGE_KIND, "edit").to(ChangeEdits.class);
    delete(CHANGE_KIND, "edit").to(DeleteChangeEdit.class);
    child(CHANGE_KIND, "edit:publish").to(PublishChangeEdit.class);
    child(CHANGE_KIND, "edit:rebase").to(RebaseChangeEdit.class);
    put(CHANGE_KIND, "edit:message").to(ChangeEdits.EditMessage.class);
    get(CHANGE_KIND, "edit:message").to(ChangeEdits.GetMessage.class);
    put(CHANGE_EDIT_KIND, "/").to(ChangeEdits.Put.class);
    delete(CHANGE_EDIT_KIND).to(ChangeEdits.DeleteContent.class);
    get(CHANGE_EDIT_KIND, "/").to(ChangeEdits.Get.class);
    get(CHANGE_EDIT_KIND, "meta").to(ChangeEdits.GetMeta.class);
    factory(AccountLoader.Factory.class);
    factory(ChangeEdits.Create.Factory.class);
    factory(ChangeEdits.DeleteFile.Factory.class);
    factory(ChangeInserter.Factory.class);
    factory(EmailReviewComments.Factory.class);
    factory(PatchSetInserter.Factory.class);
    factory(RebaseChangeOp.Factory.class);
    factory(ReviewerResource.Factory.class);
    factory(SetHashtagsOp.Factory.class);
    factory(ChangeResource.Factory.class);
}
#method_after
@Override
protected void configure() {
    bind(ChangesCollection.class);
    bind(Revisions.class);
    bind(Reviewers.class);
    bind(DraftComments.class);
    bind(Comments.class);
    bind(Files.class);
    bind(Votes.class);
    DynamicMap.mapOf(binder(), CHANGE_KIND);
    DynamicMap.mapOf(binder(), COMMENT_KIND);
    DynamicMap.mapOf(binder(), DRAFT_COMMENT_KIND);
    DynamicMap.mapOf(binder(), FILE_KIND);
    DynamicMap.mapOf(binder(), REVIEWER_KIND);
    DynamicMap.mapOf(binder(), REVISION_KIND);
    DynamicMap.mapOf(binder(), CHANGE_EDIT_KIND);
    DynamicMap.mapOf(binder(), VOTE_KIND);
    get(CHANGE_KIND).to(GetChange.class);
    get(CHANGE_KIND, "detail").to(GetDetail.class);
    get(CHANGE_KIND, "topic").to(GetTopic.class);
    get(CHANGE_KIND, "in").to(IncludedIn.class);
    get(CHANGE_KIND, "hashtags").to(GetHashtags.class);
    get(CHANGE_KIND, "comments").to(ListChangeComments.class);
    get(CHANGE_KIND, "drafts").to(ListChangeDrafts.class);
    get(CHANGE_KIND, "check").to(Check.class);
    post(CHANGE_KIND, "check").to(Check.class);
    put(CHANGE_KIND, "topic").to(PutTopic.class);
    delete(CHANGE_KIND, "topic").to(PutTopic.class);
    delete(CHANGE_KIND).to(DeleteDraftChange.class);
    post(CHANGE_KIND, "abandon").to(Abandon.class);
    post(CHANGE_KIND, "hashtags").to(PostHashtags.class);
    post(CHANGE_KIND, "publish").to(PublishDraftPatchSet.CurrentRevision.class);
    post(CHANGE_KIND, "restore").to(Restore.class);
    post(CHANGE_KIND, "revert").to(Revert.class);
    post(CHANGE_KIND, "submit").to(Submit.CurrentRevision.class);
    get(CHANGE_KIND, "submitted_together").to(SubmittedTogether.class);
    post(CHANGE_KIND, "rebase").to(Rebase.CurrentRevision.class);
    post(CHANGE_KIND, "index").to(Index.class);
    post(CHANGE_KIND, "rebuild.notedb").to(Rebuild.class);
    post(CHANGE_KIND, "move").to(Move.class);
    post(CHANGE_KIND, "reviewers").to(PostReviewers.class);
    get(CHANGE_KIND, "suggest_reviewers").to(SuggestChangeReviewers.class);
    child(CHANGE_KIND, "reviewers").to(Reviewers.class);
    get(REVIEWER_KIND).to(GetReviewer.class);
    delete(REVIEWER_KIND).to(DeleteReviewer.class);
    post(REVIEWER_KIND, "delete").to(DeleteReviewer.class);
    child(REVIEWER_KIND, "votes").to(Votes.class);
    delete(VOTE_KIND).to(DeleteVote.class);
    post(VOTE_KIND, "delete").to(DeleteVote.class);
    child(CHANGE_KIND, "revisions").to(Revisions.class);
    get(REVISION_KIND, "actions").to(GetRevisionActions.class);
    post(REVISION_KIND, "cherrypick").to(CherryPick.class);
    get(REVISION_KIND, "commit").to(GetCommit.class);
    delete(REVISION_KIND).to(DeleteDraftPatchSet.class);
    get(REVISION_KIND, "mergeable").to(Mergeable.class);
    post(REVISION_KIND, "publish").to(PublishDraftPatchSet.class);
    get(REVISION_KIND, "related").to(GetRelated.class);
    get(REVISION_KIND, "review").to(GetReview.class);
    post(REVISION_KIND, "review").to(PostReview.class);
    get(REVISION_KIND, "preview_submit").to(PreviewSubmit.class);
    post(REVISION_KIND, "submit").to(Submit.class);
    post(REVISION_KIND, "rebase").to(Rebase.class);
    get(REVISION_KIND, "patch").to(GetPatch.class);
    get(REVISION_KIND, "submit_type").to(TestSubmitType.Get.class);
    post(REVISION_KIND, "test.submit_rule").to(TestSubmitRule.class);
    post(REVISION_KIND, "test.submit_type").to(TestSubmitType.class);
    get(REVISION_KIND, "archive").to(GetArchive.class);
    get(REVISION_KIND, "mergelist").to(GetMergeList.class);
    child(REVISION_KIND, "drafts").to(DraftComments.class);
    put(REVISION_KIND, "drafts").to(CreateDraftComment.class);
    get(DRAFT_COMMENT_KIND).to(GetDraftComment.class);
    put(DRAFT_COMMENT_KIND).to(PutDraftComment.class);
    delete(DRAFT_COMMENT_KIND).to(DeleteDraftComment.class);
    child(REVISION_KIND, "comments").to(Comments.class);
    get(COMMENT_KIND).to(GetComment.class);
    child(REVISION_KIND, "files").to(Files.class);
    put(FILE_KIND, "reviewed").to(PutReviewed.class);
    delete(FILE_KIND, "reviewed").to(DeleteReviewed.class);
    get(FILE_KIND, "content").to(GetContent.class);
    get(FILE_KIND, "download").to(DownloadContent.class);
    get(FILE_KIND, "diff").to(GetDiff.class);
    get(FILE_KIND, "blame").to(GetBlame.class);
    child(CHANGE_KIND, "edit").to(ChangeEdits.class);
    delete(CHANGE_KIND, "edit").to(DeleteChangeEdit.class);
    child(CHANGE_KIND, "edit:publish").to(PublishChangeEdit.class);
    child(CHANGE_KIND, "edit:rebase").to(RebaseChangeEdit.class);
    put(CHANGE_KIND, "edit:message").to(ChangeEdits.EditMessage.class);
    get(CHANGE_KIND, "edit:message").to(ChangeEdits.GetMessage.class);
    put(CHANGE_EDIT_KIND, "/").to(ChangeEdits.Put.class);
    delete(CHANGE_EDIT_KIND).to(ChangeEdits.DeleteContent.class);
    get(CHANGE_EDIT_KIND, "/").to(ChangeEdits.Get.class);
    get(CHANGE_EDIT_KIND, "meta").to(ChangeEdits.GetMeta.class);
    factory(AccountLoader.Factory.class);
    factory(ChangeEdits.Create.Factory.class);
    factory(ChangeEdits.DeleteFile.Factory.class);
    factory(ChangeInserter.Factory.class);
    factory(EmailReviewComments.Factory.class);
    factory(PatchSetInserter.Factory.class);
    factory(RebaseChangeOp.Factory.class);
    factory(ReviewerResource.Factory.class);
    factory(SetHashtagsOp.Factory.class);
    factory(ChangeResource.Factory.class);
}
#end_block

#method_before
BatchUpdate getUpdate() {
    checkState(db != null, "call setContext before getUpdate");
    if (update == null) {
        update = batchUpdateFactory.create(db, getProjectName(), caller, ts).setRepository(repo, rw, ins).setRequestId(submissionId);
    }
    return update;
}
#method_after
public BatchUpdate getUpdate() {
    checkState(db != null, "call setContext before getUpdate");
    if (update == null) {
        update = batchUpdateFactory.create(db, getProjectName(), caller, ts).setRepository(repo, rw, ins).setRequestId(submissionId);
    }
    return update;
}
#end_block

#method_before
public OpenRepo openRepo(Project.NameKey project, boolean abortIfOpen) throws NoSuchProjectException, IOException {
    if (abortIfOpen) {
        checkState(!openRepos.containsKey(project), "repo already opened: %s", project);
    }
    if (openRepos.containsKey(project)) {
        return openRepos.get(project);
    }
    ProjectState projectState = projectCache.get(project);
    if (projectState == null) {
        throw new NoSuchProjectException(project);
    }
    try {
        OpenRepo or = new OpenRepo(repoManager.openRepository(project), projectState);
        openRepos.put(project, or);
        return or;
    } catch (RepositoryNotFoundException e) {
        throw new NoSuchProjectException(project);
    }
}
#method_after
public OpenRepo openRepo(Project.NameKey project) throws NoSuchProjectException, IOException {
    if (openRepos.containsKey(project)) {
        return openRepos.get(project);
    }
    ProjectState projectState = projectCache.get(project);
    if (projectState == null) {
        throw new NoSuchProjectException(project);
    }
    try {
        OpenRepo or = new OpenRepo(repoManager.openRepository(project), projectState);
        openRepos.put(project, or);
        return or;
    } catch (RepositoryNotFoundException e) {
        throw new NoSuchProjectException(project);
    }
}
#end_block

#method_before
public void execute(Listener listener) throws UpdateException, RestApiException {
    execute(ImmutableList.of(this), listener, requestId);
}
#method_after
static void execute(Collection<BatchUpdate> updates, Listener listener, @Nullable RequestId requestId, boolean dryrun) throws UpdateException, RestApiException {
    if (updates.isEmpty()) {
        return;
    }
    if (requestId != null) {
        for (BatchUpdate u : updates) {
            checkArgument(u.requestId == null || u.requestId == requestId, "refusing to overwrite RequestId %s in update with %s", u.requestId, requestId);
            u.setRequestId(requestId);
        }
    }
    try {
        Order order = getOrder(updates);
        boolean updateChangesInParallel = getUpdateChangesInParallel(updates);
        switch(order) {
            case REPO_BEFORE_DB:
                for (BatchUpdate u : updates) {
                    u.executeUpdateRepo();
                }
                listener.afterUpdateRepos();
                for (BatchUpdate u : updates) {
                    u.executeRefUpdates(dryrun);
                }
                listener.afterRefUpdates();
                for (BatchUpdate u : updates) {
                    u.executeChangeOps(updateChangesInParallel, dryrun);
                }
                listener.afterUpdateChanges();
                break;
            case DB_BEFORE_REPO:
                for (BatchUpdate u : updates) {
                    u.executeChangeOps(updateChangesInParallel, dryrun);
                }
                listener.afterUpdateChanges();
                for (BatchUpdate u : updates) {
                    u.executeUpdateRepo();
                }
                listener.afterUpdateRepos();
                for (BatchUpdate u : updates) {
                    u.executeRefUpdates(dryrun);
                }
                listener.afterRefUpdates();
                break;
            default:
                throw new IllegalStateException("invalid execution order: " + order);
        }
        List<CheckedFuture<?, IOException>> indexFutures = new ArrayList<>();
        for (BatchUpdate u : updates) {
            indexFutures.addAll(u.indexFutures);
        }
        ChangeIndexer.allAsList(indexFutures).get();
        for (BatchUpdate u : updates) {
            if (u.batchRefUpdate != null) {
                // Fire ref update events only after all mutations are finished, since
                // callers may assume a patch set ref being created means the change
                // was created, or a branch advancing meaning some changes were
                // closed.
                u.gitRefUpdated.fire(u.project, u.batchRefUpdate, u.getUser().isIdentifiedUser() ? u.getUser().getAccountId() : null);
            }
        }
        if (!dryrun) {
            for (BatchUpdate u : updates) {
                u.executePostOps();
            }
        }
    } catch (UpdateException | RestApiException e) {
        // failure.
        throw e;
    // Convert other common non-REST exception types with user-visible
    // messages to corresponding REST exception types
    } catch (InvalidChangeOperationException e) {
        throw new ResourceConflictException(e.getMessage(), e);
    } catch (NoSuchChangeException | NoSuchRefException | NoSuchProjectException e) {
        throw new ResourceNotFoundException(e.getMessage(), e);
    } catch (Exception e) {
        Throwables.propagateIfPossible(e);
        throw new UpdateException(e);
    }
}
#end_block

#method_before
public Collection<ReceiveCommand> getRefUpdates() throws UpdateException, RestApiException {
    executeUpdateRepo();
    return commands.getCommands().values();
}
#method_after
public Collection<ReceiveCommand> getRefUpdates() {
    return commands.getCommands().values();
}
#end_block

#method_before
public void execute(Listener listener) throws UpdateException, RestApiException {
    execute(ImmutableList.of(this), listener, requestId);
}
#method_after
public void execute(Listener listener) throws UpdateException, RestApiException {
    execute(ImmutableList.of(this), listener, requestId, false);
}
#end_block

#method_before
private void executeUpdateRepo() throws UpdateException, RestApiException {
    try {
        logDebug("Executing updateRepo on {} ops", ops.size());
        RepoContext ctx = new RepoContext();
        for (Op op : ops.values()) {
            op.updateRepo(ctx);
        }
        if (!repoOnlyOps.isEmpty()) {
            logDebug("Executing updateRepo on {} RepoOnlyOps", ops.size());
            for (RepoOnlyOp op : repoOnlyOps) {
                op.updateRepo(ctx);
            }
        }
        if (inserter != null) {
            // todo should be optional
            logDebug("Flushing inserter");
            inserter.flush();
        } else {
            logDebug("No objects to flush");
        }
    } catch (Exception e) {
        Throwables.propagateIfPossible(e, RestApiException.class);
        throw new UpdateException(e);
    }
}
#method_after
private void executeUpdateRepo() throws UpdateException, RestApiException {
    try {
        logDebug("Executing updateRepo on {} ops", ops.size());
        RepoContext ctx = new RepoContext();
        for (Op op : ops.values()) {
            op.updateRepo(ctx);
        }
        if (!repoOnlyOps.isEmpty()) {
            logDebug("Executing updateRepo on {} RepoOnlyOps", ops.size());
            for (RepoOnlyOp op : repoOnlyOps) {
                op.updateRepo(ctx);
            }
        }
        if (inserter != null) {
            logDebug("Flushing inserter");
            inserter.flush();
        } else {
            logDebug("No objects to flush");
        }
    } catch (Exception e) {
        Throwables.propagateIfPossible(e, RestApiException.class);
        throw new UpdateException(e);
    }
}
#end_block

#method_before
private void executeRefUpdates() throws IOException, UpdateException {
    if (commands == null || commands.isEmpty()) {
        logDebug("No ref updates to execute");
        return;
    }
    // May not be opened if the caller added ref updates but no new objects.
    initRepository();
    batchRefUpdate = repo.getRefDatabase().newBatchUpdate();
    commands.addTo(batchRefUpdate);
    logDebug("Executing batch of {} ref updates", batchRefUpdate.getCommands().size());
    batchRefUpdate.execute(revWalk, NullProgressMonitor.INSTANCE);
    boolean ok = true;
    for (ReceiveCommand cmd : batchRefUpdate.getCommands()) {
        if (cmd.getResult() != ReceiveCommand.Result.OK) {
            ok = false;
            break;
        }
    }
    if (!ok) {
        throw new UpdateException("BatchRefUpdate failed: " + batchRefUpdate);
    }
}
#method_after
private void executeRefUpdates(boolean dryrun) throws IOException, UpdateException {
    if (commands == null || commands.isEmpty()) {
        logDebug("No ref updates to execute");
        return;
    }
    // May not be opened if the caller added ref updates but no new objects.
    initRepository();
    batchRefUpdate = repo.getRefDatabase().newBatchUpdate();
    commands.addTo(batchRefUpdate);
    logDebug("Executing batch of {} ref updates", batchRefUpdate.getCommands().size());
    if (dryrun) {
        return;
    }
    batchRefUpdate.execute(revWalk, NullProgressMonitor.INSTANCE);
    boolean ok = true;
    for (ReceiveCommand cmd : batchRefUpdate.getCommands()) {
        if (cmd.getResult() != ReceiveCommand.Result.OK) {
            ok = false;
            break;
        }
    }
    if (!ok) {
        throw new UpdateException("BatchRefUpdate failed: " + batchRefUpdate);
    }
}
#end_block

#method_before
private void executeChangeOps(boolean parallel) throws UpdateException, RestApiException {
    logDebug("Executing change ops (parallel? {})", parallel);
    ListeningExecutorService executor = parallel ? changeUpdateExector : MoreExecutors.newDirectExecutorService();
    List<ChangeTask> tasks = new ArrayList<>(ops.keySet().size());
    try {
        if (notesMigration.commitChangeWrites() && repo != null) {
            // A NoteDb change may have been rebuilt since the repo was originally
            // opened, so make sure we see that.
            logDebug("Preemptively scanning for repo changes");
            repo.scanForRepoChanges();
        }
        if (!ops.isEmpty() && notesMigration.failChangeWrites()) {
            // Fail fast before attempting any writes if changes are read-only, as
            // this is a programmer error.
            logDebug("Failing early due to read-only Changes table");
            throw new OrmException(NoteDbUpdateManager.CHANGES_READ_ONLY);
        }
        List<ListenableFuture<?>> futures = new ArrayList<>(ops.keySet().size());
        for (Map.Entry<Change.Id, Collection<Op>> e : ops.asMap().entrySet()) {
            ChangeTask task = new ChangeTask(e.getKey(), e.getValue(), Thread.currentThread());
            tasks.add(task);
            if (!parallel) {
                logDebug("Direct execution of task for ops: {}", ops);
            }
            futures.add(executor.submit(task));
        }
        if (parallel) {
            logDebug("Waiting on futures for {} ops spanning {} changes", ops.size(), ops.keySet().size());
        }
        // TODO(dborowitz): Timing is wrong for non-parallel updates.
        long startNanos = System.nanoTime();
        Futures.allAsList(futures).get();
        maybeLogSlowUpdate(startNanos, "change");
        if (notesMigration.commitChangeWrites()) {
            startNanos = System.nanoTime();
            executeNoteDbUpdates(tasks);
            maybeLogSlowUpdate(startNanos, "NoteDb");
        }
    } catch (ExecutionException | InterruptedException e) {
        Throwables.propagateIfInstanceOf(e.getCause(), UpdateException.class);
        Throwables.propagateIfInstanceOf(e.getCause(), RestApiException.class);
        throw new UpdateException(e);
    } catch (OrmException | IOException e) {
        throw new UpdateException(e);
    }
    // Reindex changes.
    for (ChangeTask task : tasks) {
        if (task.deleted) {
            indexFutures.add(indexer.deleteAsync(task.id));
        } else if (task.dirty) {
            indexFutures.add(indexer.indexAsync(project, task.id));
        }
    }
}
#method_after
private void executeChangeOps(boolean parallel, boolean dryrun) throws UpdateException, RestApiException {
    logDebug("Executing change ops (parallel? {})", parallel);
    ListeningExecutorService executor = parallel ? changeUpdateExector : MoreExecutors.newDirectExecutorService();
    List<ChangeTask> tasks = new ArrayList<>(ops.keySet().size());
    try {
        if (notesMigration.commitChangeWrites() && repo != null) {
            // A NoteDb change may have been rebuilt since the repo was originally
            // opened, so make sure we see that.
            logDebug("Preemptively scanning for repo changes");
            repo.scanForRepoChanges();
        }
        if (!ops.isEmpty() && notesMigration.failChangeWrites()) {
            // Fail fast before attempting any writes if changes are read-only, as
            // this is a programmer error.
            logDebug("Failing early due to read-only Changes table");
            throw new OrmException(NoteDbUpdateManager.CHANGES_READ_ONLY);
        }
        List<ListenableFuture<?>> futures = new ArrayList<>(ops.keySet().size());
        for (Map.Entry<Change.Id, Collection<Op>> e : ops.asMap().entrySet()) {
            ChangeTask task = new ChangeTask(e.getKey(), e.getValue(), Thread.currentThread(), dryrun);
            tasks.add(task);
            if (!parallel) {
                logDebug("Direct execution of task for ops: {}", ops);
            }
            futures.add(executor.submit(task));
        }
        if (parallel) {
            logDebug("Waiting on futures for {} ops spanning {} changes", ops.size(), ops.keySet().size());
        }
        // TODO(dborowitz): Timing is wrong for non-parallel updates.
        long startNanos = System.nanoTime();
        Futures.allAsList(futures).get();
        maybeLogSlowUpdate(startNanos, "change");
        if (notesMigration.commitChangeWrites()) {
            startNanos = System.nanoTime();
            if (!dryrun) {
                executeNoteDbUpdates(tasks);
            }
            maybeLogSlowUpdate(startNanos, "NoteDb");
        }
    } catch (ExecutionException | InterruptedException e) {
        Throwables.propagateIfInstanceOf(e.getCause(), UpdateException.class);
        Throwables.propagateIfInstanceOf(e.getCause(), RestApiException.class);
        throw new UpdateException(e);
    } catch (OrmException | IOException e) {
        throw new UpdateException(e);
    }
    // Reindex changes.
    for (ChangeTask task : tasks) {
        if (task.deleted) {
            indexFutures.add(indexer.deleteAsync(task.id));
        } else if (task.dirty) {
            indexFutures.add(indexer.indexAsync(project, task.id));
        }
    }
}
#end_block

#method_before
private void call(ReviewDb db, Repository repo, RevWalk rw) throws Exception {
    // Not always opened.
    @SuppressWarnings("resource")
    NoteDbUpdateManager updateManager = null;
    try {
        ChangeContext ctx;
        db.changes().beginTransaction(id);
        try {
            ctx = newChangeContext(db, repo, rw, id);
            // Call updateChange on each op.
            logDebug("Calling updateChange on {} ops", changeOps.size());
            for (Op op : changeOps) {
                dirty |= op.updateChange(ctx);
            }
            if (!dirty) {
                logDebug("No ops reported dirty, short-circuiting");
                return;
            }
            deleted = ctx.deleted;
            if (deleted) {
                logDebug("Change was deleted");
            }
            // Stage the NoteDb update and store its state in the Change.
            if (notesMigration.commitChangeWrites()) {
                updateManager = stageNoteDbUpdate(ctx, deleted);
            }
            // Bump lastUpdatedOn or rowVersion and commit.
            Iterable<Change> cs = changesToUpdate(ctx);
            if (newChanges.containsKey(id)) {
                // Insert rather than upsert in case of a race on change IDs.
                logDebug("Inserting change");
                db.changes().insert(cs);
            } else if (deleted) {
                logDebug("Deleting change");
                db.changes().delete(cs);
            } else {
                logDebug("Updating change");
                db.changes().update(cs);
            }
            db.commit();
        } finally {
            db.rollback();
        }
        if (notesMigration.commitChangeWrites()) {
            try {
                // Do not execute the NoteDbUpdateManager, as we don't want too much
                // contention on the underlying repo, and we would rather use a
                // single ObjectInserter/BatchRefUpdate later.
                // 
                // TODO(dborowitz): May or may not be worth trying to batch
                // together flushed inserters as well.
                noteDbResult = updateManager.stage().get(id);
            } catch (IOException ex) {
                // Ignore all errors trying to update NoteDb at this point. We've
                // already written the NoteDbChangeState to ReviewDb, which means
                // if the state is out of date it will be rebuilt the next time it
                // is needed.
                log.debug("Ignoring NoteDb update error after ReviewDb write", ex);
            }
        }
    } catch (Exception e) {
        logDebug("Error updating change (should be rethrown)", e);
        Throwables.propagateIfPossible(e, RestApiException.class);
        throw new UpdateException(e);
    } finally {
        if (updateManager != null) {
            updateManager.close();
        }
    }
}
#method_after
private void call(ReviewDb db, Repository repo, RevWalk rw) throws Exception {
    // Not always opened.
    @SuppressWarnings("resource")
    NoteDbUpdateManager updateManager = null;
    try {
        ChangeContext ctx;
        db.changes().beginTransaction(id);
        try {
            ctx = newChangeContext(db, repo, rw, id);
            // Call updateChange on each op.
            logDebug("Calling updateChange on {} ops", changeOps.size());
            for (Op op : changeOps) {
                dirty |= op.updateChange(ctx);
            }
            if (!dirty) {
                logDebug("No ops reported dirty, short-circuiting");
                return;
            }
            deleted = ctx.deleted;
            if (deleted) {
                logDebug("Change was deleted");
            }
            // Stage the NoteDb update and store its state in the Change.
            if (notesMigration.commitChangeWrites()) {
                updateManager = stageNoteDbUpdate(ctx, deleted);
            }
            // Bump lastUpdatedOn or rowVersion and commit.
            Iterable<Change> cs = changesToUpdate(ctx);
            if (newChanges.containsKey(id)) {
                // Insert rather than upsert in case of a race on change IDs.
                logDebug("Inserting change");
                db.changes().insert(cs);
            } else if (deleted) {
                logDebug("Deleting change");
                db.changes().delete(cs);
            } else {
                logDebug("Updating change");
                db.changes().update(cs);
            }
            if (!dryrun) {
                db.commit();
            }
        } finally {
            db.rollback();
        }
        if (notesMigration.commitChangeWrites()) {
            try {
                // Do not execute the NoteDbUpdateManager, as we don't want too much
                // contention on the underlying repo, and we would rather use a
                // single ObjectInserter/BatchRefUpdate later.
                // 
                // TODO(dborowitz): May or may not be worth trying to batch
                // together flushed inserters as well.
                noteDbResult = updateManager.stage().get(id);
            } catch (IOException ex) {
                // Ignore all errors trying to update NoteDb at this point. We've
                // already written the NoteDbChangeState to ReviewDb, which means
                // if the state is out of date it will be rebuilt the next time it
                // is needed.
                log.debug("Ignoring NoteDb update error after ReviewDb write", ex);
            }
        }
    } catch (Exception e) {
        logDebug("Error updating change (should be rethrown)", e);
        Throwables.propagateIfPossible(e, RestApiException.class);
        throw new UpdateException(e);
    } finally {
        if (updateManager != null) {
            updateManager.close();
        }
    }
}
#end_block

#method_before
void sendMessages() {
    for (CommitValidationMessage m : messages) {
        if (m.isError()) {
            messageSender.sendError(m.getMessage());
        } else {
            messageSender.sendMessage(m.getMessage());
        }
    }
}
#method_after
void sendMessages() {
    for (ValidationMessage m : messages) {
        if (m.isError()) {
            messageSender.sendError(m.getMessage());
        } else {
            messageSender.sendMessage(m.getMessage());
        }
    }
}
#end_block

#method_before
private void reportMessages() {
    Iterable<CreateRequest> created = Iterables.filter(newChanges, new Predicate<CreateRequest>() {

        @Override
        public boolean apply(CreateRequest input) {
            return input.change != null;
        }
    });
    if (!Iterables.isEmpty(created)) {
        addMessage("");
        addMessage("New Changes:");
        for (CreateRequest c : created) {
            addMessage(formatChangeUrl(canonicalWebUrl, c.change, c.change.getSubject(), false));
        }
        addMessage("");
    }
    List<ReplaceRequest> updated = FluentIterable.from(replaceByChange.values()).filter(new Predicate<ReplaceRequest>() {

        @Override
        public boolean apply(ReplaceRequest input) {
            return !input.skip && input.inputCommand.getResult() == OK;
        }
    }).toSortedList(Ordering.natural().onResultOf(new Function<ReplaceRequest, Integer>() {

        @Override
        public Integer apply(ReplaceRequest in) {
            return in.notes.getChangeId().get();
        }
    }));
    if (!updated.isEmpty()) {
        addMessage("");
        addMessage("Updated Changes:");
        boolean edit = magicBranch != null && magicBranch.edit;
        for (ReplaceRequest u : updated) {
            String subject;
            if (edit) {
                try {
                    subject = rp.getRevWalk().parseCommit(u.newCommitId).getShortMessage();
                } catch (IOException e) {
                    // Log and fall back to original change subject
                    logWarn("failed to get subject for edit patch set", e);
                    subject = u.notes.getChange().getSubject();
                }
            } else {
                subject = u.info.getSubject();
            }
            addMessage(formatChangeUrl(canonicalWebUrl, u.notes.getChange(), subject, edit));
        }
        addMessage("");
    }
}
#method_after
private void reportMessages() {
    Iterable<CreateRequest> created = Iterables.filter(newChanges, new Predicate<CreateRequest>() {

        @Override
        public boolean apply(CreateRequest input) {
            return input.change != null;
        }
    });
    if (!Iterables.isEmpty(created)) {
        addMessage("");
        addMessage("New Changes:");
        for (CreateRequest c : created) {
            addMessage(formatChangeUrl(canonicalWebUrl, c.change, c.change.getSubject(), c.change.getStatus() == Change.Status.DRAFT, false));
        }
        addMessage("");
    }
    List<ReplaceRequest> updated = FluentIterable.from(replaceByChange.values()).filter(new Predicate<ReplaceRequest>() {

        @Override
        public boolean apply(ReplaceRequest input) {
            return !input.skip && input.inputCommand.getResult() == OK;
        }
    }).toSortedList(Ordering.natural().onResultOf(new Function<ReplaceRequest, Integer>() {

        @Override
        public Integer apply(ReplaceRequest in) {
            return in.notes.getChangeId().get();
        }
    }));
    if (!updated.isEmpty()) {
        addMessage("");
        addMessage("Updated Changes:");
        boolean edit = magicBranch != null && magicBranch.edit;
        for (ReplaceRequest u : updated) {
            String subject;
            if (edit) {
                try {
                    subject = rp.getRevWalk().parseCommit(u.newCommitId).getShortMessage();
                } catch (IOException e) {
                    // Log and fall back to original change subject
                    logWarn("failed to get subject for edit patch set", e);
                    subject = u.notes.getChange().getSubject();
                }
            } else {
                subject = u.info.getSubject();
            }
            addMessage(formatChangeUrl(canonicalWebUrl, u.notes.getChange(), subject, u.replaceOp != null && u.replaceOp.getPatchSet().isDraft(), edit));
        }
        addMessage("");
    }
}
#end_block

#method_before
private static String formatChangeUrl(String url, Change change, String subject, boolean edit) {
    StringBuilder m = new StringBuilder().append("  ").append(url).append(change.getChangeId()).append(" ").append(ChangeUtil.cropSubject(subject));
    if (change.getStatus() == Change.Status.DRAFT) {
        m.append(" [DRAFT]");
    }
    if (edit) {
        m.append(" [EDIT]");
    }
    return m.toString();
}
#method_after
private static String formatChangeUrl(String url, Change change, String subject, boolean draft, boolean edit) {
    StringBuilder m = new StringBuilder().append("  ").append(url).append(change.getChangeId()).append(" ").append(ChangeUtil.cropSubject(subject));
    if (draft) {
        m.append(" [DRAFT]");
    }
    if (edit) {
        m.append(" [EDIT]");
    }
    return m.toString();
}
#end_block

#method_before
private void parseCommands(Collection<ReceiveCommand> commands) {
    logDebug("Parsing {} commands", commands.size());
    for (ReceiveCommand cmd : commands) {
        if (cmd.getResult() != NOT_ATTEMPTED) {
            // Already rejected by the core receive process.
            logDebug("Already processed by core: {} {}", cmd.getResult(), cmd);
            continue;
        }
        if (!Repository.isValidRefName(cmd.getRefName()) || cmd.getRefName().contains("//")) {
            reject(cmd, "not valid ref");
            continue;
        }
        if (MagicBranch.isMagicBranch(cmd.getRefName())) {
            parseMagicBranch(cmd);
            continue;
        }
        if (projectControl.getProjectState().isAllUsers() && RefNames.REFS_USERS_SELF.equals(cmd.getRefName())) {
            String newName = RefNames.refsUsers(user.getAccountId());
            logDebug("Swapping out command for {} to {}", RefNames.REFS_USERS_SELF, newName);
            final ReceiveCommand orgCmd = cmd;
            cmd = new ReceiveCommand(cmd.getOldId(), cmd.getNewId(), newName, cmd.getType()) {

                @Override
                public void setResult(Result s, String m) {
                    super.setResult(s, m);
                    orgCmd.setResult(s, m);
                }
            };
        }
        Matcher m = NEW_PATCHSET.matcher(cmd.getRefName());
        if (m.matches()) {
            // The referenced change must exist and must still be open.
            // 
            Change.Id changeId = Change.Id.parse(m.group(1));
            parseReplaceCommand(cmd, changeId);
            continue;
        }
        switch(cmd.getType()) {
            case CREATE:
                parseCreate(cmd);
                break;
            case UPDATE:
                parseUpdate(cmd);
                break;
            case DELETE:
                parseDelete(cmd);
                break;
            case UPDATE_NONFASTFORWARD:
                parseRewind(cmd);
                break;
            default:
                reject(cmd);
                continue;
        }
        if (cmd.getResult() != NOT_ATTEMPTED) {
            continue;
        }
        if (isConfig(cmd)) {
            logDebug("Processing {} command", cmd.getRefName());
            if (!projectControl.isOwner()) {
                reject(cmd, "not project owner");
                continue;
            }
            switch(cmd.getType()) {
                case CREATE:
                case UPDATE:
                case UPDATE_NONFASTFORWARD:
                    try {
                        ProjectConfig cfg = new ProjectConfig(project.getNameKey());
                        cfg.load(rp.getRevWalk(), cmd.getNewId());
                        if (!cfg.getValidationErrors().isEmpty()) {
                            addError("Invalid project configuration:");
                            for (ValidationError err : cfg.getValidationErrors()) {
                                addError("  " + err.getMessage());
                            }
                            reject(cmd, "invalid project configuration");
                            logError("User " + user.getUserName() + " tried to push invalid project configuration " + cmd.getNewId().name() + " for " + project.getName());
                            continue;
                        }
                        Project.NameKey newParent = cfg.getProject().getParent(allProjectsName);
                        Project.NameKey oldParent = project.getParent(allProjectsName);
                        if (oldParent == null) {
                            // update of the 'All-Projects' project
                            if (newParent != null) {
                                reject(cmd, "invalid project configuration: root project cannot have parent");
                                continue;
                            }
                        } else {
                            if (!oldParent.equals(newParent) && !user.getCapabilities().canAdministrateServer()) {
                                reject(cmd, "invalid project configuration: only Gerrit admin can set parent");
                                continue;
                            }
                            if (projectCache.get(newParent) == null) {
                                reject(cmd, "invalid project configuration: parent does not exist");
                                continue;
                            }
                        }
                        for (Entry<ProjectConfigEntry> e : pluginConfigEntries) {
                            PluginConfig pluginCfg = cfg.getPluginConfig(e.getPluginName());
                            ProjectConfigEntry configEntry = e.getProvider().get();
                            String value = pluginCfg.getString(e.getExportName());
                            String oldValue = projectControl.getProjectState().getConfig().getPluginConfig(e.getPluginName()).getString(e.getExportName());
                            if (configEntry.getType() == ProjectConfigEntryType.ARRAY) {
                                List<String> l = Arrays.asList(projectControl.getProjectState().getConfig().getPluginConfig(e.getPluginName()).getStringList(e.getExportName()));
                                oldValue = Joiner.on("\n").join(l);
                            }
                            if ((value == null ? oldValue != null : !value.equals(oldValue)) && !configEntry.isEditable(projectControl.getProjectState())) {
                                reject(cmd, String.format("invalid project configuration: Not allowed to set parameter" + " '%s' of plugin '%s' on project '%s'.", e.getExportName(), e.getPluginName(), project.getName()));
                                continue;
                            }
                            if (ProjectConfigEntryType.LIST.equals(configEntry.getType()) && value != null && !configEntry.getPermittedValues().contains(value)) {
                                reject(cmd, String.format("invalid project configuration: The value '%s' is " + "not permitted for parameter '%s' of plugin '%s'.", value, e.getExportName(), e.getPluginName()));
                            }
                        }
                    } catch (Exception e) {
                        reject(cmd, "invalid project configuration");
                        logError("User " + user.getUserName() + " tried to push invalid project configuration " + cmd.getNewId().name() + " for " + project.getName(), e);
                        continue;
                    }
                    break;
                case DELETE:
                    break;
                default:
                    reject(cmd);
                    continue;
            }
        }
    }
}
#method_after
private void parseCommands(Collection<ReceiveCommand> commands) {
    List<String> optionList = rp.getPushOptions();
    if (optionList != null) {
        for (String option : optionList) {
            int e = option.indexOf('=');
            if (e > 0) {
                pushOptions.put(option.substring(0, e), option.substring(e + 1));
            } else {
                pushOptions.put(option, "");
            }
        }
    }
    logDebug("Parsing {} commands", commands.size());
    for (ReceiveCommand cmd : commands) {
        if (cmd.getResult() != NOT_ATTEMPTED) {
            // Already rejected by the core receive process.
            logDebug("Already processed by core: {} {}", cmd.getResult(), cmd);
            continue;
        }
        if (!Repository.isValidRefName(cmd.getRefName()) || cmd.getRefName().contains("//")) {
            reject(cmd, "not valid ref");
            continue;
        }
        if (MagicBranch.isMagicBranch(cmd.getRefName())) {
            parseMagicBranch(cmd);
            continue;
        }
        if (projectControl.getProjectState().isAllUsers() && RefNames.REFS_USERS_SELF.equals(cmd.getRefName())) {
            String newName = RefNames.refsUsers(user.getAccountId());
            logDebug("Swapping out command for {} to {}", RefNames.REFS_USERS_SELF, newName);
            final ReceiveCommand orgCmd = cmd;
            cmd = new ReceiveCommand(cmd.getOldId(), cmd.getNewId(), newName, cmd.getType()) {

                @Override
                public void setResult(Result s, String m) {
                    super.setResult(s, m);
                    orgCmd.setResult(s, m);
                }
            };
        }
        Matcher m = NEW_PATCHSET.matcher(cmd.getRefName());
        if (m.matches()) {
            // The referenced change must exist and must still be open.
            // 
            Change.Id changeId = Change.Id.parse(m.group(1));
            parseReplaceCommand(cmd, changeId);
            continue;
        }
        switch(cmd.getType()) {
            case CREATE:
                parseCreate(cmd);
                break;
            case UPDATE:
                parseUpdate(cmd);
                break;
            case DELETE:
                parseDelete(cmd);
                break;
            case UPDATE_NONFASTFORWARD:
                parseRewind(cmd);
                break;
            default:
                reject(cmd);
                continue;
        }
        if (cmd.getResult() != NOT_ATTEMPTED) {
            continue;
        }
        if (isConfig(cmd)) {
            logDebug("Processing {} command", cmd.getRefName());
            if (!projectControl.isOwner()) {
                reject(cmd, "not project owner");
                continue;
            }
            switch(cmd.getType()) {
                case CREATE:
                case UPDATE:
                case UPDATE_NONFASTFORWARD:
                    try {
                        ProjectConfig cfg = new ProjectConfig(project.getNameKey());
                        cfg.load(rp.getRevWalk(), cmd.getNewId());
                        if (!cfg.getValidationErrors().isEmpty()) {
                            addError("Invalid project configuration:");
                            for (ValidationError err : cfg.getValidationErrors()) {
                                addError("  " + err.getMessage());
                            }
                            reject(cmd, "invalid project configuration");
                            logError("User " + user.getUserName() + " tried to push invalid project configuration " + cmd.getNewId().name() + " for " + project.getName());
                            continue;
                        }
                        Project.NameKey newParent = cfg.getProject().getParent(allProjectsName);
                        Project.NameKey oldParent = project.getParent(allProjectsName);
                        if (oldParent == null) {
                            // update of the 'All-Projects' project
                            if (newParent != null) {
                                reject(cmd, "invalid project configuration: root project cannot have parent");
                                continue;
                            }
                        } else {
                            if (!oldParent.equals(newParent) && !user.getCapabilities().canAdministrateServer()) {
                                reject(cmd, "invalid project configuration: only Gerrit admin can set parent");
                                continue;
                            }
                            if (projectCache.get(newParent) == null) {
                                reject(cmd, "invalid project configuration: parent does not exist");
                                continue;
                            }
                        }
                        for (Entry<ProjectConfigEntry> e : pluginConfigEntries) {
                            PluginConfig pluginCfg = cfg.getPluginConfig(e.getPluginName());
                            ProjectConfigEntry configEntry = e.getProvider().get();
                            String value = pluginCfg.getString(e.getExportName());
                            String oldValue = projectControl.getProjectState().getConfig().getPluginConfig(e.getPluginName()).getString(e.getExportName());
                            if (configEntry.getType() == ProjectConfigEntryType.ARRAY) {
                                List<String> l = Arrays.asList(projectControl.getProjectState().getConfig().getPluginConfig(e.getPluginName()).getStringList(e.getExportName()));
                                oldValue = Joiner.on("\n").join(l);
                            }
                            if ((value == null ? oldValue != null : !value.equals(oldValue)) && !configEntry.isEditable(projectControl.getProjectState())) {
                                reject(cmd, String.format("invalid project configuration: Not allowed to set parameter" + " '%s' of plugin '%s' on project '%s'.", e.getExportName(), e.getPluginName(), project.getName()));
                                continue;
                            }
                            if (ProjectConfigEntryType.LIST.equals(configEntry.getType()) && value != null && !configEntry.getPermittedValues().contains(value)) {
                                reject(cmd, String.format("invalid project configuration: The value '%s' is " + "not permitted for parameter '%s' of plugin '%s'.", value, e.getExportName(), e.getPluginName()));
                            }
                        }
                    } catch (Exception e) {
                        reject(cmd, "invalid project configuration");
                        logError("User " + user.getUserName() + " tried to push invalid project configuration " + cmd.getNewId().name() + " for " + project.getName(), e);
                        continue;
                    }
                    break;
                case DELETE:
                    break;
                default:
                    reject(cmd);
                    continue;
            }
        }
    }
}
#end_block

#method_before
private void parseCreate(ReceiveCommand cmd) {
    RevObject obj;
    try {
        obj = rp.getRevWalk().parseAny(cmd.getNewId());
    } catch (IOException err) {
        logError("Invalid object " + cmd.getNewId().name() + " for " + cmd.getRefName() + " creation", err);
        reject(cmd, "invalid object");
        return;
    }
    logDebug("Creating {}", cmd);
    if (isHead(cmd) && !isCommit(cmd)) {
        return;
    }
    RefControl ctl = projectControl.controlForRef(cmd.getRefName());
    if (ctl.canCreate(db, rp.getRepository(), obj)) {
        validateNewCommits(ctl, cmd);
        batch.addCommand(cmd);
    } else {
        reject(cmd);
    }
}
#method_after
private void parseCreate(ReceiveCommand cmd) {
    RevObject obj;
    try {
        obj = rp.getRevWalk().parseAny(cmd.getNewId());
    } catch (IOException err) {
        logError("Invalid object " + cmd.getNewId().name() + " for " + cmd.getRefName() + " creation", err);
        reject(cmd, "invalid object");
        return;
    }
    logDebug("Creating {}", cmd);
    if (isHead(cmd) && !isCommit(cmd)) {
        return;
    }
    RefControl ctl = projectControl.controlForRef(cmd.getRefName());
    if (ctl.canCreate(db, rp.getRepository(), obj)) {
        if (!validRefOperation(cmd)) {
            return;
        }
        validateNewCommits(ctl, cmd);
        batch.addCommand(cmd);
    } else {
        reject(cmd);
    }
}
#end_block

#method_before
private void parseUpdate(ReceiveCommand cmd) {
    logDebug("Updating {}", cmd);
    RefControl ctl = projectControl.controlForRef(cmd.getRefName());
    if (ctl.canUpdate()) {
        if (isHead(cmd) && !isCommit(cmd)) {
            return;
        }
        validateNewCommits(ctl, cmd);
        batch.addCommand(cmd);
    } else {
        if (RefNames.REFS_CONFIG.equals(ctl.getRefName())) {
            errors.put(Error.CONFIG_UPDATE, RefNames.REFS_CONFIG);
        } else {
            errors.put(Error.UPDATE, ctl.getRefName());
        }
        reject(cmd);
    }
}
#method_after
private void parseUpdate(ReceiveCommand cmd) {
    logDebug("Updating {}", cmd);
    RefControl ctl = projectControl.controlForRef(cmd.getRefName());
    if (ctl.canUpdate()) {
        if (isHead(cmd) && !isCommit(cmd)) {
            return;
        }
        if (!validRefOperation(cmd)) {
            return;
        }
        validateNewCommits(ctl, cmd);
        batch.addCommand(cmd);
    } else {
        if (RefNames.REFS_CONFIG.equals(ctl.getRefName())) {
            errors.put(Error.CONFIG_UPDATE, RefNames.REFS_CONFIG);
        } else {
            errors.put(Error.UPDATE, ctl.getRefName());
        }
        reject(cmd);
    }
}
#end_block

#method_before
private void parseDelete(ReceiveCommand cmd) {
    logDebug("Deleting {}", cmd);
    RefControl ctl = projectControl.controlForRef(cmd.getRefName());
    if (ctl.getRefName().startsWith(REFS_CHANGES)) {
        errors.put(Error.DELETE_CHANGES, ctl.getRefName());
        reject(cmd, "cannot delete changes");
    } else if (ctl.canDelete()) {
        batch.addCommand(cmd);
    } else {
        if (RefNames.REFS_CONFIG.equals(ctl.getRefName())) {
            reject(cmd, "cannot delete project configuration");
        } else {
            errors.put(Error.DELETE, ctl.getRefName());
            reject(cmd, "cannot delete references");
        }
    }
}
#method_after
private void parseDelete(ReceiveCommand cmd) {
    logDebug("Deleting {}", cmd);
    RefControl ctl = projectControl.controlForRef(cmd.getRefName());
    if (ctl.getRefName().startsWith(REFS_CHANGES)) {
        errors.put(Error.DELETE_CHANGES, ctl.getRefName());
        reject(cmd, "cannot delete changes");
    } else if (ctl.canDelete()) {
        if (!validRefOperation(cmd)) {
            return;
        }
        batch.addCommand(cmd);
    } else {
        if (RefNames.REFS_CONFIG.equals(ctl.getRefName())) {
            reject(cmd, "cannot delete project configuration");
        } else {
            errors.put(Error.DELETE, ctl.getRefName());
            reject(cmd, "cannot delete references");
        }
    }
}
#end_block

#method_before
private void parseRewind(ReceiveCommand cmd) {
    RevCommit newObject;
    try {
        newObject = rp.getRevWalk().parseCommit(cmd.getNewId());
    } catch (IncorrectObjectTypeException notCommit) {
        newObject = null;
    } catch (IOException err) {
        logError("Invalid object " + cmd.getNewId().name() + " for " + cmd.getRefName() + " forced update", err);
        reject(cmd, "invalid object");
        return;
    }
    logDebug("Rewinding {}", cmd);
    RefControl ctl = projectControl.controlForRef(cmd.getRefName());
    if (newObject != null) {
        validateNewCommits(ctl, cmd);
        if (cmd.getResult() != NOT_ATTEMPTED) {
            return;
        }
    }
    if (ctl.canForceUpdate()) {
        batch.setAllowNonFastForwards(true).addCommand(cmd);
    } else {
        cmd.setResult(REJECTED_NONFASTFORWARD, " need '" + PermissionRule.FORCE_PUSH + "' privilege.");
    }
}
#method_after
private void parseRewind(ReceiveCommand cmd) {
    RevCommit newObject;
    try {
        newObject = rp.getRevWalk().parseCommit(cmd.getNewId());
    } catch (IncorrectObjectTypeException notCommit) {
        newObject = null;
    } catch (IOException err) {
        logError("Invalid object " + cmd.getNewId().name() + " for " + cmd.getRefName() + " forced update", err);
        reject(cmd, "invalid object");
        return;
    }
    logDebug("Rewinding {}", cmd);
    RefControl ctl = projectControl.controlForRef(cmd.getRefName());
    if (newObject != null) {
        validateNewCommits(ctl, cmd);
        if (cmd.getResult() != NOT_ATTEMPTED) {
            return;
        }
    }
    if (ctl.canForceUpdate()) {
        if (!validRefOperation(cmd)) {
            return;
        }
        batch.setAllowNonFastForwards(true).addCommand(cmd);
    } else {
        cmd.setResult(REJECTED_NONFASTFORWARD, " need '" + PermissionRule.FORCE_PUSH + "' privilege.");
    }
}
#end_block

#method_before
String parse(CmdLineParser clp, Repository repo, Set<String> refs) throws CmdLineException {
    String ref = RefNames.fullName(MagicBranch.getDestBranchName(cmd.getRefName()));
    int optionStart = ref.indexOf('%');
    if (0 < optionStart) {
        ListMultimap<String, String> options = LinkedListMultimap.create();
        for (String s : COMMAS.split(ref.substring(optionStart + 1))) {
            int e = s.indexOf('=');
            if (0 < e) {
                options.put(s.substring(0, e), s.substring(e + 1));
            } else {
                options.put(s, "");
            }
        }
        clp.parseOptionMap(options);
        ref = ref.substring(0, optionStart);
    }
    // Split the destination branch by branch and topic. The topic
    // suffix is entirely optional, so it might not even exist.
    String head = readHEAD(repo);
    int split = ref.length();
    for (; ; ) {
        String name = ref.substring(0, split);
        if (refs.contains(name) || name.equals(head)) {
            break;
        }
        split = name.lastIndexOf('/', split - 1);
        if (split <= Constants.R_REFS.length()) {
            return ref;
        }
    }
    if (split < ref.length()) {
        topic = Strings.emptyToNull(ref.substring(split + 1));
    }
    return ref.substring(0, split);
}
#method_after
String parse(CmdLineParser clp, Repository repo, Set<String> refs, ListMultimap<String, String> pushOptions) throws CmdLineException {
    String ref = RefNames.fullName(MagicBranch.getDestBranchName(cmd.getRefName()));
    ListMultimap<String, String> options = LinkedListMultimap.create(pushOptions);
    int optionStart = ref.indexOf('%');
    if (0 < optionStart) {
        for (String s : COMMAS.split(ref.substring(optionStart + 1))) {
            int e = s.indexOf('=');
            if (0 < e) {
                options.put(s.substring(0, e), s.substring(e + 1));
            } else {
                options.put(s, "");
            }
        }
        ref = ref.substring(0, optionStart);
    }
    if (!options.isEmpty()) {
        clp.parseOptionMap(options);
    }
    // Split the destination branch by branch and topic. The topic
    // suffix is entirely optional, so it might not even exist.
    String head = readHEAD(repo);
    int split = ref.length();
    for (; ; ) {
        String name = ref.substring(0, split);
        if (refs.contains(name) || name.equals(head)) {
            break;
        }
        split = name.lastIndexOf('/', split - 1);
        if (split <= Constants.R_REFS.length()) {
            return ref;
        }
    }
    if (split < ref.length()) {
        topic = Strings.emptyToNull(ref.substring(split + 1));
    }
    return ref.substring(0, split);
}
#end_block

#method_before
private void parseMagicBranch(ReceiveCommand cmd) {
    // Permit exactly one new change request per push.
    if (magicBranch != null) {
        reject(cmd, "duplicate request");
        return;
    }
    logDebug("Found magic branch {}", cmd.getRefName());
    magicBranch = new MagicBranchInput(cmd, labelTypes, notesMigration);
    magicBranch.reviewer.addAll(reviewersFromCommandLine);
    magicBranch.cc.addAll(ccFromCommandLine);
    String ref;
    CmdLineParser clp = optionParserFactory.create(magicBranch);
    magicBranch.clp = clp;
    try {
        ref = magicBranch.parse(clp, repo, rp.getAdvertisedRefs().keySet());
    } catch (CmdLineException e) {
        if (!clp.wasHelpRequestedByOption()) {
            logDebug("Invalid branch syntax");
            reject(cmd, e.getMessage());
            return;
        }
        // never happen
        ref = null;
    }
    if (clp.wasHelpRequestedByOption()) {
        StringWriter w = new StringWriter();
        w.write("\nHelp for refs/for/branch:\n\n");
        clp.printUsage(w, null);
        addMessage(w.toString());
        reject(cmd, "see help");
        return;
    }
    if (projectControl.getProjectState().isAllUsers() && RefNames.REFS_USERS_SELF.equals(ref)) {
        logDebug("Handling {}", RefNames.REFS_USERS_SELF);
        ref = RefNames.refsUsers(user.getAccountId());
    }
    if (!rp.getAdvertisedRefs().containsKey(ref) && !ref.equals(readHEAD(repo))) {
        logDebug("Ref {} not found", ref);
        if (ref.startsWith(Constants.R_HEADS)) {
            String n = ref.substring(Constants.R_HEADS.length());
            reject(cmd, "branch " + n + " not found");
        } else {
            reject(cmd, ref + " not found");
        }
        return;
    }
    magicBranch.dest = new Branch.NameKey(project.getNameKey(), ref);
    magicBranch.ctl = projectControl.controlForRef(ref);
    if (!magicBranch.ctl.canWrite()) {
        reject(cmd, "project is read only");
        return;
    }
    if (magicBranch.draft) {
        if (!receiveConfig.allowDrafts) {
            errors.put(Error.CODE_REVIEW, ref);
            reject(cmd, "draft workflow is disabled");
            return;
        } else if (projectControl.controlForRef("refs/drafts/" + ref).isBlocked(Permission.PUSH)) {
            errors.put(Error.CODE_REVIEW, ref);
            reject(cmd, "cannot upload drafts");
            return;
        }
    }
    if (!magicBranch.ctl.canUpload()) {
        errors.put(Error.CODE_REVIEW, ref);
        reject(cmd, "cannot upload review");
        return;
    }
    if (magicBranch.draft && magicBranch.submit) {
        reject(cmd, "cannot submit draft");
        return;
    }
    if (magicBranch.submit && !projectControl.controlForRef(MagicBranch.NEW_CHANGE + ref).canSubmit()) {
        reject(cmd, "submit not allowed");
        return;
    }
    RevWalk walk = rp.getRevWalk();
    RevCommit tip;
    try {
        tip = walk.parseCommit(magicBranch.cmd.getNewId());
        logDebug("Tip of push: {}", tip.name());
    } catch (IOException ex) {
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", ex);
        return;
    }
    // if %base was specified, ignore newChangeForAllNotInTarget
    if (tip.getParentCount() > 1 || magicBranch.base != null || tip.getParentCount() == 0) {
        logDebug("Forcing newChangeForAllNotInTarget = false");
        newChangeForAllNotInTarget = false;
    }
    if (magicBranch.base != null) {
        logDebug("Handling %base: {}", magicBranch.base);
        magicBranch.baseCommit = Lists.newArrayListWithCapacity(magicBranch.base.size());
        for (ObjectId id : magicBranch.base) {
            try {
                magicBranch.baseCommit.add(walk.parseCommit(id));
            } catch (IncorrectObjectTypeException notCommit) {
                reject(cmd, "base must be a commit");
                return;
            } catch (MissingObjectException e) {
                reject(cmd, "base not found");
                return;
            } catch (IOException e) {
                logWarn(String.format("Project %s cannot read %s", project.getName(), id.name()), e);
                reject(cmd, "internal server error");
                return;
            }
        }
    } else if (newChangeForAllNotInTarget) {
        logDebug("Handling newChangeForAllNotInTarget");
        String destBranch = magicBranch.dest.get();
        try {
            Ref r = repo.getRefDatabase().exactRef(destBranch);
            if (r == null) {
                reject(cmd, destBranch + " not found");
                return;
            }
            ObjectId baseHead = r.getObjectId();
            magicBranch.baseCommit = Collections.singletonList(walk.parseCommit(baseHead));
            logDebug("Set baseCommit = {}", magicBranch.baseCommit.get(0).name());
        } catch (IOException ex) {
            logWarn(String.format("Project %s cannot read %s", project.getName(), destBranch), ex);
            reject(cmd, "internal server error");
            return;
        }
    }
    // 
    try {
        Ref targetRef = rp.getAdvertisedRefs().get(magicBranch.ctl.getRefName());
        if (targetRef == null || targetRef.getObjectId() == null) {
            // The destination branch does not yet exist. Assume the
            // history being sent for review will start it and thus
            // is "connected" to the branch.
            logDebug("Branch is unborn");
            return;
        }
        RevCommit h = walk.parseCommit(targetRef.getObjectId());
        logDebug("Current branch tip: {}", h.name());
        RevFilter oldRevFilter = walk.getRevFilter();
        try {
            walk.reset();
            walk.setRevFilter(RevFilter.MERGE_BASE);
            walk.markStart(tip);
            walk.markStart(h);
            if (walk.next() == null) {
                reject(magicBranch.cmd, "no common ancestry");
            }
        } finally {
            walk.reset();
            walk.setRevFilter(oldRevFilter);
        }
    } catch (IOException e) {
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", e);
    }
}
#method_after
private void parseMagicBranch(ReceiveCommand cmd) {
    // Permit exactly one new change request per push.
    if (magicBranch != null) {
        reject(cmd, "duplicate request");
        return;
    }
    logDebug("Found magic branch {}", cmd.getRefName());
    magicBranch = new MagicBranchInput(cmd, labelTypes, notesMigration);
    magicBranch.reviewer.addAll(reviewersFromCommandLine);
    magicBranch.cc.addAll(ccFromCommandLine);
    String ref;
    CmdLineParser clp = optionParserFactory.create(magicBranch);
    magicBranch.clp = clp;
    try {
        ref = magicBranch.parse(clp, repo, rp.getAdvertisedRefs().keySet(), pushOptions);
    } catch (CmdLineException e) {
        if (!clp.wasHelpRequestedByOption()) {
            logDebug("Invalid branch syntax");
            reject(cmd, e.getMessage());
            return;
        }
        // never happen
        ref = null;
    }
    if (clp.wasHelpRequestedByOption()) {
        StringWriter w = new StringWriter();
        w.write("\nHelp for refs/for/branch:\n\n");
        clp.printUsage(w, null);
        addMessage(w.toString());
        reject(cmd, "see help");
        return;
    }
    if (projectControl.getProjectState().isAllUsers() && RefNames.REFS_USERS_SELF.equals(ref)) {
        logDebug("Handling {}", RefNames.REFS_USERS_SELF);
        ref = RefNames.refsUsers(user.getAccountId());
    }
    if (!rp.getAdvertisedRefs().containsKey(ref) && !ref.equals(readHEAD(repo))) {
        logDebug("Ref {} not found", ref);
        if (ref.startsWith(Constants.R_HEADS)) {
            String n = ref.substring(Constants.R_HEADS.length());
            reject(cmd, "branch " + n + " not found");
        } else {
            reject(cmd, ref + " not found");
        }
        return;
    }
    magicBranch.dest = new Branch.NameKey(project.getNameKey(), ref);
    magicBranch.ctl = projectControl.controlForRef(ref);
    if (!magicBranch.ctl.canWrite()) {
        reject(cmd, "project is read only");
        return;
    }
    if (magicBranch.draft) {
        if (!receiveConfig.allowDrafts) {
            errors.put(Error.CODE_REVIEW, ref);
            reject(cmd, "draft workflow is disabled");
            return;
        } else if (projectControl.controlForRef("refs/drafts/" + ref).isBlocked(Permission.PUSH)) {
            errors.put(Error.CODE_REVIEW, ref);
            reject(cmd, "cannot upload drafts");
            return;
        }
    }
    if (!magicBranch.ctl.canUpload()) {
        errors.put(Error.CODE_REVIEW, ref);
        reject(cmd, "cannot upload review");
        return;
    }
    if (magicBranch.draft && magicBranch.submit) {
        reject(cmd, "cannot submit draft");
        return;
    }
    if (magicBranch.submit && !projectControl.controlForRef(MagicBranch.NEW_CHANGE + ref).canSubmit(true)) {
        reject(cmd, "submit not allowed");
        return;
    }
    RevWalk walk = rp.getRevWalk();
    RevCommit tip;
    try {
        tip = walk.parseCommit(magicBranch.cmd.getNewId());
        logDebug("Tip of push: {}", tip.name());
    } catch (IOException ex) {
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", ex);
        return;
    }
    String destBranch = magicBranch.dest.get();
    try {
        if (magicBranch.merged) {
            if (magicBranch.draft) {
                reject(cmd, "cannot be draft & merged");
                return;
            }
            if (magicBranch.base != null) {
                reject(cmd, "cannot use merged with base");
                return;
            }
            RevCommit branchTip = readBranchTip(cmd, magicBranch.dest);
            if (branchTip == null) {
                // readBranchTip already rejected cmd.
                return;
            }
            if (!walk.isMergedInto(tip, branchTip)) {
                reject(cmd, "not merged into branch");
                return;
            }
        }
        // if %base or %merged was specified, ignore newChangeForAllNotInTarget.
        if (tip.getParentCount() > 1 || magicBranch.base != null || magicBranch.merged || tip.getParentCount() == 0) {
            logDebug("Forcing newChangeForAllNotInTarget = false");
            newChangeForAllNotInTarget = false;
        }
        if (magicBranch.base != null) {
            logDebug("Handling %base: {}", magicBranch.base);
            magicBranch.baseCommit = Lists.newArrayListWithCapacity(magicBranch.base.size());
            for (ObjectId id : magicBranch.base) {
                try {
                    magicBranch.baseCommit.add(walk.parseCommit(id));
                } catch (IncorrectObjectTypeException notCommit) {
                    reject(cmd, "base must be a commit");
                    return;
                } catch (MissingObjectException e) {
                    reject(cmd, "base not found");
                    return;
                } catch (IOException e) {
                    logWarn(String.format("Project %s cannot read %s", project.getName(), id.name()), e);
                    reject(cmd, "internal server error");
                    return;
                }
            }
        } else if (newChangeForAllNotInTarget) {
            RevCommit branchTip = readBranchTip(cmd, magicBranch.dest);
            if (branchTip == null) {
                // readBranchTip already rejected cmd.
                return;
            }
            magicBranch.baseCommit = Collections.singletonList(branchTip);
            logDebug("Set baseCommit = {}", magicBranch.baseCommit.get(0).name());
        }
    } catch (IOException ex) {
        logWarn(String.format("Error walking to %s in project %s", destBranch, project.getName()), ex);
        reject(cmd, "internal server error");
        return;
    }
    // 
    try {
        Ref targetRef = rp.getAdvertisedRefs().get(magicBranch.ctl.getRefName());
        if (targetRef == null || targetRef.getObjectId() == null) {
            // The destination branch does not yet exist. Assume the
            // history being sent for review will start it and thus
            // is "connected" to the branch.
            logDebug("Branch is unborn");
            return;
        }
        RevCommit h = walk.parseCommit(targetRef.getObjectId());
        logDebug("Current branch tip: {}", h.name());
        RevFilter oldRevFilter = walk.getRevFilter();
        try {
            walk.reset();
            walk.setRevFilter(RevFilter.MERGE_BASE);
            walk.markStart(tip);
            walk.markStart(h);
            if (walk.next() == null) {
                reject(magicBranch.cmd, "no common ancestry");
            }
        } finally {
            walk.reset();
            walk.setRevFilter(oldRevFilter);
        }
    } catch (IOException e) {
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", e);
    }
}
#end_block

#method_before
private void selectNewAndReplacedChangesFromMagicBranch() {
    logDebug("Finding new and replaced changes");
    newChanges = new ArrayList<>();
    SetMultimap<ObjectId, Ref> existing = changeRefsById();
    GroupCollector groupCollector = GroupCollector.create(changeRefsById(), db, psUtil, notesFactory, project.getNameKey());
    rp.getRevWalk().reset();
    rp.getRevWalk().sort(RevSort.TOPO);
    rp.getRevWalk().sort(RevSort.REVERSE, true);
    try {
        rp.getRevWalk().markStart(rp.getRevWalk().parseCommit(magicBranch.cmd.getNewId()));
        if (magicBranch.baseCommit != null) {
            logDebug("Marking {} base commits uninteresting", magicBranch.baseCommit.size());
            for (RevCommit c : magicBranch.baseCommit) {
                rp.getRevWalk().markUninteresting(c);
            }
            Ref targetRef = allRefs.get(magicBranch.ctl.getRefName());
            if (targetRef != null) {
                logDebug("Marking target ref {} ({}) uninteresting", magicBranch.ctl.getRefName(), targetRef.getObjectId().name());
                rp.getRevWalk().markUninteresting(rp.getRevWalk().parseCommit(targetRef.getObjectId()));
            }
        } else {
            markHeadsAsUninteresting(rp.getRevWalk(), magicBranch.ctl != null ? magicBranch.ctl.getRefName() : null);
        }
        List<ChangeLookup> pending = new ArrayList<>();
        Set<Change.Key> newChangeIds = new HashSet<>();
        int maxBatchChanges = receiveConfig.getEffectiveMaxBatchChangesLimit(user);
        int total = 0;
        int alreadyTracked = 0;
        for (; ; ) {
            RevCommit c = rp.getRevWalk().next();
            if (c == null) {
                break;
            }
            total++;
            String name = c.name();
            groupCollector.visit(c);
            Collection<Ref> existingRefs = existing.get(c);
            if (!existingRefs.isEmpty()) {
                // Commit is already tracked.
                alreadyTracked++;
                // different target branch.
                for (Ref ref : existingRefs) {
                    updateGroups.add(new UpdateGroupsRequest(ref, c));
                }
                if (!(newChangeForAllNotInTarget || magicBranch.base != null)) {
                    continue;
                }
                logDebug("Creating new change for {} even though it is already tracked", name);
            }
            if (!validCommit(rp.getRevWalk(), magicBranch.ctl, magicBranch.cmd, c)) {
                // Not a change the user can propose? Abort as early as possible.
                newChanges = Collections.emptyList();
                logDebug("Aborting early due to invalid commit");
                return;
            }
            // Don't allow merges to be uploaded in commit chain via all-not-in-target
            if (newChangeForAllNotInTarget && c.getParentCount() > 1) {
                reject(magicBranch.cmd, "Pushing merges in commit chains with 'all not in target' is not allowed,\n" + "to override please set the base manually");
                logDebug("Rejecting merge commit {} with newChangeForAllNotInTarget", name);
            // TODO(dborowitz): Should we early return here?
            }
            List<String> idList = c.getFooterLines(CHANGE_ID);
            if (idList.isEmpty()) {
                newChanges.add(new CreateRequest(c, magicBranch.dest.get()));
                continue;
            }
            String idStr = idList.get(idList.size() - 1).trim();
            if (idStr.matches("^I00*$")) {
                // Reject this invalid line from EGit.
                reject(magicBranch.cmd, "invalid Change-Id");
                newChanges = Collections.emptyList();
                return;
            }
            pending.add(new ChangeLookup(c, new Change.Key(idStr)));
            int n = pending.size() + newChanges.size();
            if (maxBatchChanges != 0 && n > maxBatchChanges) {
                logDebug("{} changes exceeds limit of {}", n, maxBatchChanges);
                reject(magicBranch.cmd, "the number of pushed changes in a batch exceeds the max limit " + maxBatchChanges);
                newChanges = Collections.emptyList();
                return;
            }
        }
        logDebug("Finished initial RevWalk with {} commits total: {} already" + " tracked, {} new changes with no Change-Id, and {} deferred" + " lookups", total, alreadyTracked, newChanges.size(), pending.size());
        for (Iterator<ChangeLookup> itr = pending.iterator(); itr.hasNext(); ) {
            ChangeLookup p = itr.next();
            if (newChangeIds.contains(p.changeKey)) {
                logDebug("Multiple commits with Change-Id {}", p.changeKey);
                reject(magicBranch.cmd, SAME_CHANGE_ID_IN_MULTIPLE_CHANGES);
                newChanges = Collections.emptyList();
                return;
            }
            List<ChangeData> changes = p.destChanges;
            if (changes.size() > 1) {
                logDebug("Multiple changes in project with Change-Id {}: {}", p.changeKey, Lists.transform(changes, new Function<ChangeData, String>() {

                    @Override
                    public String apply(ChangeData in) {
                        return in.getId().toString();
                    }
                }));
                // WTF, multiple changes in this project have the same key?
                // Since the commit is new, the user should recreate it with
                // a different Change-Id. In practice, we should never see
                // this error message as Change-Id should be unique.
                // 
                reject(magicBranch.cmd, p.changeKey.get() + " has duplicates");
                newChanges = Collections.emptyList();
                return;
            }
            if (changes.size() == 1) {
                // Schedule as a replacement to this one matching change.
                // 
                RevId currentPs = changes.get(0).currentPatchSet().getRevision();
                // If Commit is already current PatchSet of target Change.
                if (p.commit.name().equals(currentPs.get())) {
                    if (pending.size() == 1) {
                        // There are no commits left to check, all commits in pending were already
                        // current PatchSet of the corresponding target changes.
                        reject(magicBranch.cmd, "commit(s) already exists (as current patchset)");
                    } else {
                        // Commit is already current PatchSet.
                        // Remove from pending and try next commit.
                        itr.remove();
                        continue;
                    }
                }
                if (requestReplace(magicBranch.cmd, false, changes.get(0).change(), p.commit)) {
                    continue;
                }
                newChanges = Collections.emptyList();
                return;
            }
            if (changes.size() == 0) {
                if (!isValidChangeId(p.changeKey.get())) {
                    reject(magicBranch.cmd, "invalid Change-Id");
                    newChanges = Collections.emptyList();
                    return;
                }
                newChangeIds.add(p.changeKey);
            }
            newChanges.add(new CreateRequest(p.commit, magicBranch.dest.get()));
        }
        logDebug("Finished deferred lookups with {} updates and {} new changes", replaceByChange.size(), newChanges.size());
    } catch (IOException e) {
        // Should never happen, the core receive process would have
        // identified the missing object earlier before we got control.
        // 
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", e);
        newChanges = Collections.emptyList();
        return;
    } catch (OrmException e) {
        logError("Cannot query database to locate prior changes", e);
        reject(magicBranch.cmd, "database error");
        newChanges = Collections.emptyList();
        return;
    }
    if (newChanges.isEmpty() && replaceByChange.isEmpty()) {
        reject(magicBranch.cmd, "no new changes");
        return;
    }
    if (!newChanges.isEmpty() && magicBranch.edit) {
        reject(magicBranch.cmd, "edit is not supported for new changes");
        return;
    }
    try {
        SortedSetMultimap<ObjectId, String> groups = groupCollector.getGroups();
        List<Integer> newIds = seq.nextChangeIds(newChanges.size());
        for (int i = 0; i < newChanges.size(); i++) {
            CreateRequest create = newChanges.get(i);
            create.setChangeId(newIds.get(i));
            batch.addCommand(create.cmd);
            create.groups = ImmutableList.copyOf(groups.get(create.commit));
        }
        for (ReplaceRequest replace : replaceByChange.values()) {
            replace.groups = ImmutableList.copyOf(groups.get(replace.newCommitId));
        }
        for (UpdateGroupsRequest update : updateGroups) {
            update.groups = ImmutableList.copyOf((groups.get(update.commit)));
        }
        logDebug("Finished updating groups from GroupCollector");
    } catch (OrmException | NoSuchChangeException e) {
        logError("Error collecting groups for changes", e);
        reject(magicBranch.cmd, "internal server error");
        return;
    }
}
#method_after
private void selectNewAndReplacedChangesFromMagicBranch() {
    logDebug("Finding new and replaced changes");
    newChanges = new ArrayList<>();
    SetMultimap<ObjectId, Ref> existing = changeRefsById();
    GroupCollector groupCollector = GroupCollector.create(changeRefsById(), db, psUtil, notesFactory, project.getNameKey());
    try {
        RevCommit start = setUpWalkForSelectingChanges();
        if (start == null) {
            return;
        }
        List<ChangeLookup> pending = new ArrayList<>();
        Set<Change.Key> newChangeIds = new HashSet<>();
        int maxBatchChanges = receiveConfig.getEffectiveMaxBatchChangesLimit(user);
        int total = 0;
        int alreadyTracked = 0;
        boolean rejectImplicitMerges = start.getParentCount() == 1 && projectCache.get(project.getNameKey()).isRejectImplicitMerges() && // late.
        !magicBranch.merged;
        Set<RevCommit> mergedParents;
        if (rejectImplicitMerges) {
            mergedParents = new HashSet<>();
        } else {
            mergedParents = null;
        }
        for (; ; ) {
            RevCommit c = rp.getRevWalk().next();
            if (c == null) {
                break;
            }
            total++;
            String name = c.name();
            groupCollector.visit(c);
            Collection<Ref> existingRefs = existing.get(c);
            if (rejectImplicitMerges) {
                Collections.addAll(mergedParents, c.getParents());
                mergedParents.remove(c);
            }
            if (!existingRefs.isEmpty()) {
                // Commit is already tracked.
                alreadyTracked++;
                // different target branch.
                for (Ref ref : existingRefs) {
                    updateGroups.add(new UpdateGroupsRequest(ref, c));
                }
                if (!(newChangeForAllNotInTarget || magicBranch.base != null)) {
                    continue;
                }
                logDebug("Creating new change for {} even though it is already tracked", name);
            }
            if (!validCommit(rp.getRevWalk(), magicBranch.ctl, magicBranch.cmd, c)) {
                // Not a change the user can propose? Abort as early as possible.
                newChanges = Collections.emptyList();
                logDebug("Aborting early due to invalid commit");
                return;
            }
            // Don't allow merges to be uploaded in commit chain via all-not-in-target
            if (newChangeForAllNotInTarget && c.getParentCount() > 1) {
                reject(magicBranch.cmd, "Pushing merges in commit chains with 'all not in target' is not allowed,\n" + "to override please set the base manually");
                logDebug("Rejecting merge commit {} with newChangeForAllNotInTarget", name);
            // TODO(dborowitz): Should we early return here?
            }
            List<String> idList = c.getFooterLines(CHANGE_ID);
            if (idList.isEmpty()) {
                newChanges.add(new CreateRequest(c, magicBranch.dest.get()));
                continue;
            }
            String idStr = idList.get(idList.size() - 1).trim();
            if (idStr.matches("^I00*$")) {
                // Reject this invalid line from EGit.
                reject(magicBranch.cmd, "invalid Change-Id");
                newChanges = Collections.emptyList();
                return;
            }
            pending.add(new ChangeLookup(c, new Change.Key(idStr)));
            int n = pending.size() + newChanges.size();
            if (maxBatchChanges != 0 && n > maxBatchChanges) {
                logDebug("{} changes exceeds limit of {}", n, maxBatchChanges);
                reject(magicBranch.cmd, "the number of pushed changes in a batch exceeds the max limit " + maxBatchChanges);
                newChanges = Collections.emptyList();
                return;
            }
        }
        logDebug("Finished initial RevWalk with {} commits total: {} already" + " tracked, {} new changes with no Change-Id, and {} deferred" + " lookups", total, alreadyTracked, newChanges.size(), pending.size());
        if (rejectImplicitMerges) {
            rejectImplicitMerges(mergedParents);
        }
        for (Iterator<ChangeLookup> itr = pending.iterator(); itr.hasNext(); ) {
            ChangeLookup p = itr.next();
            if (newChangeIds.contains(p.changeKey)) {
                logDebug("Multiple commits with Change-Id {}", p.changeKey);
                reject(magicBranch.cmd, SAME_CHANGE_ID_IN_MULTIPLE_CHANGES);
                newChanges = Collections.emptyList();
                return;
            }
            List<ChangeData> changes = p.destChanges;
            if (changes.size() > 1) {
                logDebug("Multiple changes in project with Change-Id {}: {}", p.changeKey, Lists.transform(changes, new Function<ChangeData, String>() {

                    @Override
                    public String apply(ChangeData in) {
                        return in.getId().toString();
                    }
                }));
                // WTF, multiple changes in this project have the same key?
                // Since the commit is new, the user should recreate it with
                // a different Change-Id. In practice, we should never see
                // this error message as Change-Id should be unique.
                // 
                reject(magicBranch.cmd, p.changeKey.get() + " has duplicates");
                newChanges = Collections.emptyList();
                return;
            }
            if (changes.size() == 1) {
                // Schedule as a replacement to this one matching change.
                // 
                RevId currentPs = changes.get(0).currentPatchSet().getRevision();
                // If Commit is already current PatchSet of target Change.
                if (p.commit.name().equals(currentPs.get())) {
                    if (pending.size() == 1) {
                        // There are no commits left to check, all commits in pending were already
                        // current PatchSet of the corresponding target changes.
                        reject(magicBranch.cmd, "commit(s) already exists (as current patchset)");
                    } else {
                        // Commit is already current PatchSet.
                        // Remove from pending and try next commit.
                        itr.remove();
                        continue;
                    }
                }
                if (requestReplace(magicBranch.cmd, false, changes.get(0).change(), p.commit)) {
                    continue;
                }
                newChanges = Collections.emptyList();
                return;
            }
            if (changes.size() == 0) {
                if (!isValidChangeId(p.changeKey.get())) {
                    reject(magicBranch.cmd, "invalid Change-Id");
                    newChanges = Collections.emptyList();
                    return;
                }
                newChangeIds.add(p.changeKey);
            }
            newChanges.add(new CreateRequest(p.commit, magicBranch.dest.get()));
        }
        logDebug("Finished deferred lookups with {} updates and {} new changes", replaceByChange.size(), newChanges.size());
    } catch (IOException e) {
        // Should never happen, the core receive process would have
        // identified the missing object earlier before we got control.
        // 
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", e);
        newChanges = Collections.emptyList();
        return;
    } catch (OrmException e) {
        logError("Cannot query database to locate prior changes", e);
        reject(magicBranch.cmd, "database error");
        newChanges = Collections.emptyList();
        return;
    }
    if (newChanges.isEmpty() && replaceByChange.isEmpty()) {
        reject(magicBranch.cmd, "no new changes");
        return;
    }
    if (!newChanges.isEmpty() && magicBranch.edit) {
        reject(magicBranch.cmd, "edit is not supported for new changes");
        return;
    }
    try {
        SortedSetMultimap<ObjectId, String> groups = groupCollector.getGroups();
        List<Integer> newIds = seq.nextChangeIds(newChanges.size());
        for (int i = 0; i < newChanges.size(); i++) {
            CreateRequest create = newChanges.get(i);
            create.setChangeId(newIds.get(i));
            batch.addCommand(create.cmd);
            create.groups = ImmutableList.copyOf(groups.get(create.commit));
        }
        for (ReplaceRequest replace : replaceByChange.values()) {
            replace.groups = ImmutableList.copyOf(groups.get(replace.newCommitId));
        }
        for (UpdateGroupsRequest update : updateGroups) {
            update.groups = ImmutableList.copyOf((groups.get(update.commit)));
        }
        logDebug("Finished updating groups from GroupCollector");
    } catch (OrmException | NoSuchChangeException e) {
        logError("Error collecting groups for changes", e);
        reject(magicBranch.cmd, "internal server error");
        return;
    }
}
#end_block

#method_before
private void setChangeId(int id) {
    changeId = new Change.Id(id);
    ins = changeInserterFactory.create(changeId, commit, refName).setDraft(magicBranch.draft).setTopic(magicBranch.topic).setValidatePolicy(CommitValidators.Policy.NONE);
    cmd = new ReceiveCommand(ObjectId.zeroId(), commit, ins.getPatchSetId().toRefName());
    ins.setUpdateRefCommand(cmd);
    if (rp.getPushCertificate() != null) {
        ins.setPushCertificate(rp.getPushCertificate().toTextWithSignature());
    }
}
#method_after
private void setChangeId(int id) {
    changeId = new Change.Id(id);
    ins = changeInserterFactory.create(changeId, commit, refName).setTopic(magicBranch.topic).setValidatePolicy(CommitValidators.Policy.NONE);
    if (magicBranch.draft) {
        ins.setDraft(magicBranch.draft);
    } else if (magicBranch.merged) {
        ins.setStatus(Change.Status.MERGED);
    }
    cmd = new ReceiveCommand(ObjectId.zeroId(), commit, ins.getPatchSetId().toRefName());
    ins.setUpdateRefCommand(cmd);
    if (rp.getPushCertificate() != null) {
        ins.setPushCertificate(rp.getPushCertificate().toTextWithSignature());
    }
}
#end_block

#method_before
private boolean validCommit(RevWalk rw, RefControl ctl, ReceiveCommand cmd, ObjectId id) throws IOException {
    if (validCommits.contains(id)) {
        return true;
    }
    RevCommit c = rw.parseCommit(id);
    rw.parseBody(c);
    CommitReceivedEvent receiveEvent = new CommitReceivedEvent(cmd, project, ctl.getRefName(), c, user);
    CommitValidators commitValidators = commitValidatorsFactory.create(ctl, sshInfo, repo);
    try {
        messages.addAll(commitValidators.validateForReceiveCommits(receiveEvent, rejectCommits));
    } catch (CommitValidationException e) {
        logDebug("Commit validation failed on {}", c.name());
        messages.addAll(e.getMessages());
        reject(cmd, e.getMessage());
        return false;
    }
    validCommits.add(c.copy());
    return true;
}
#method_after
private boolean validCommit(RevWalk rw, RefControl ctl, ReceiveCommand cmd, ObjectId id) throws IOException {
    if (validCommits.contains(id)) {
        return true;
    }
    RevCommit c = rw.parseCommit(id);
    rw.parseBody(c);
    CommitReceivedEvent receiveEvent = new CommitReceivedEvent(cmd, project, ctl.getRefName(), c, user);
    CommitValidators.Policy policy;
    if (magicBranch != null && cmd.getRefName().equals(magicBranch.cmd.getRefName()) && magicBranch.merged) {
        policy = CommitValidators.Policy.MERGED;
    } else {
        policy = CommitValidators.Policy.RECEIVE_COMMITS;
    }
    try {
        messages.addAll(commitValidatorsFactory.create(policy, ctl, sshInfo, repo).validate(receiveEvent));
    } catch (CommitValidationException e) {
        logDebug("Commit validation failed on {}", c.name());
        messages.addAll(e.getMessages());
        reject(cmd, e.getMessage());
        return false;
    }
    validCommits.add(c.copy());
    return true;
}
#end_block

#method_before
@Override
public UiAction.Description getDescription(RevisionResource resource) {
    PatchSet.Id current = resource.getChange().currentPatchSetId();
    String topic = resource.getChange().getTopic();
    boolean visible = !resource.getPatchSet().isDraft() && resource.getChange().getStatus().isOpen() && resource.getPatchSet().getId().equals(current) && resource.getControl().canSubmit();
    ReviewDb db = dbProvider.get();
    ChangeData cd = changeDataFactory.create(db, resource.getControl());
    try {
        MergeOp.checkSubmitRule(cd);
    } catch (ResourceConflictException e) {
        visible = false;
    } catch (OrmException e) {
        log.error("Error checking if change is submittable", e);
        throw new OrmRuntimeException("Could not determine problems for the change", e);
    }
    if (!visible) {
        return new UiAction.Description().setLabel("").setTitle("").setVisible(false);
    }
    ChangeSet cs;
    try {
        cs = mergeSuperSet.completeChangeSet(db, cd.change(), resource.getControl().getUser());
    } catch (OrmException | IOException e) {
        throw new OrmRuntimeException("Could not determine complete set of " + "changes to be submitted", e);
    }
    int topicSize = 0;
    if (!Strings.isNullOrEmpty(topic)) {
        topicSize = getChangesByTopic(topic).size();
    }
    boolean treatWithTopic = submitWholeTopic && !Strings.isNullOrEmpty(topic) && topicSize > 1;
    String submitProblems = problemsForSubmittingChangeset(cd, cs, resource.getUser());
    Boolean enabled;
    try {
        // Recheck mergeability rather than using value stored in the index,
        // which may be stale.
        // TODO(dborowitz): This is ugly; consider providing a way to not read
        // stored fields from the index in the first place.
        // cd.setMergeable(null);
        // That was done in unmergeableChanges which was called by
        // problemsForSubmittingChangeset, so now it is safe to read from
        // the cache, as it yields the same result.
        enabled = cd.isMergeable();
    } catch (OrmException e) {
        throw new OrmRuntimeException("Could not determine mergeability", e);
    }
    if (submitProblems != null) {
        return new UiAction.Description().setLabel(treatWithTopic ? submitTopicLabel : (cs.size() > 1) ? labelWithParents : label).setTitle(submitProblems).setVisible(true).setEnabled(false);
    }
    if (treatWithTopic) {
        Map<String, String> params = ImmutableMap.of("topicSize", String.valueOf(topicSize), "submitSize", String.valueOf(cs.size()));
        return new UiAction.Description().setLabel(submitTopicLabel).setTitle(Strings.emptyToNull(submitTopicTooltip.replace(params))).setVisible(true).setEnabled(Boolean.TRUE.equals(enabled));
    }
    RevId revId = resource.getPatchSet().getRevision();
    Map<String, String> params = ImmutableMap.of("patchSet", String.valueOf(resource.getPatchSet().getPatchSetId()), "branch", resource.getChange().getDest().getShortName(), "commit", ObjectId.fromString(revId.get()).abbreviate(7).name(), "submitSize", String.valueOf(cs.size()));
    ParameterizedString tp = cs.size() > 1 ? titlePatternWithAncestors : titlePattern;
    return new UiAction.Description().setLabel(cs.size() > 1 ? labelWithParents : label).setTitle(Strings.emptyToNull(tp.replace(params))).setVisible(true).setEnabled(Boolean.TRUE.equals(enabled));
}
#method_after
@Override
public UiAction.Description getDescription(RevisionResource resource) {
    PatchSet.Id current = resource.getChange().currentPatchSetId();
    String topic = resource.getChange().getTopic();
    boolean visible = !resource.getPatchSet().isDraft() && resource.getChange().getStatus().isOpen() && resource.getPatchSet().getId().equals(current) && resource.getControl().canSubmit();
    ReviewDb db = dbProvider.get();
    ChangeData cd = changeDataFactory.create(db, resource.getControl());
    try {
        MergeOp.checkSubmitRule(cd);
    } catch (ResourceConflictException e) {
        visible = false;
    } catch (OrmException e) {
        log.error("Error checking if change is submittable", e);
        throw new OrmRuntimeException("Could not determine problems for the change", e);
    }
    if (!visible) {
        return new UiAction.Description().setLabel("").setTitle("").setVisible(false);
    }
    ChangeSet cs;
    try {
        cs = mergeSuperSet.get().completeChangeSet(db, cd.change(), resource.getControl().getUser());
    } catch (OrmException | IOException e) {
        throw new OrmRuntimeException("Could not determine complete set of " + "changes to be submitted", e);
    }
    int topicSize = 0;
    if (!Strings.isNullOrEmpty(topic)) {
        topicSize = getChangesByTopic(topic).size();
    }
    boolean treatWithTopic = submitWholeTopic && !Strings.isNullOrEmpty(topic) && topicSize > 1;
    String submitProblems = problemsForSubmittingChangeset(cd, cs, resource.getUser());
    Boolean enabled;
    try {
        // Recheck mergeability rather than using value stored in the index,
        // which may be stale.
        // TODO(dborowitz): This is ugly; consider providing a way to not read
        // stored fields from the index in the first place.
        // cd.setMergeable(null);
        // That was done in unmergeableChanges which was called by
        // problemsForSubmittingChangeset, so now it is safe to read from
        // the cache, as it yields the same result.
        enabled = cd.isMergeable();
    } catch (OrmException e) {
        throw new OrmRuntimeException("Could not determine mergeability", e);
    }
    if (submitProblems != null) {
        return new UiAction.Description().setLabel(treatWithTopic ? submitTopicLabel : (cs.size() > 1) ? labelWithParents : label).setTitle(submitProblems).setVisible(true).setEnabled(false);
    }
    if (treatWithTopic) {
        Map<String, String> params = ImmutableMap.of("topicSize", String.valueOf(topicSize), "submitSize", String.valueOf(cs.size()));
        return new UiAction.Description().setLabel(submitTopicLabel).setTitle(Strings.emptyToNull(submitTopicTooltip.replace(params))).setVisible(true).setEnabled(Boolean.TRUE.equals(enabled));
    }
    RevId revId = resource.getPatchSet().getRevision();
    Map<String, String> params = ImmutableMap.of("patchSet", String.valueOf(resource.getPatchSet().getPatchSetId()), "branch", resource.getChange().getDest().getShortName(), "commit", ObjectId.fromString(revId.get()).abbreviate(7).name(), "submitSize", String.valueOf(cs.size()));
    ParameterizedString tp = cs.size() > 1 ? titlePatternWithAncestors : titlePattern;
    return new UiAction.Description().setLabel(cs.size() > 1 ? labelWithParents : label).setTitle(Strings.emptyToNull(tp.replace(params))).setVisible(true).setEnabled(Boolean.TRUE.equals(enabled));
}
#end_block

#method_before
public void merge(ReviewDb db, Change change, IdentifiedUser caller, boolean checkSubmitRules, SubmitInput submitInput, boolean dryrun) throws OrmException, RestApiException {
    this.submitInput = submitInput;
    this.caller = caller;
    this.ts = TimeUtil.nowTs();
    submissionId = RequestId.forChange(change);
    this.db = db;
    orm.setContext(db, ts, caller, submissionId);
    logDebug("Beginning integration of {}", change);
    try {
        ChangeSet cs = mergeSuperSet.completeChangeSet(db, change, caller);
        checkState(cs.ids().contains(change.getId()), "change %s missing from %s", change.getId(), cs);
        if (cs.furtherHiddenChanges()) {
            throw new AuthException("A change to be submitted with " + change.getId() + " is not visible");
        }
        this.commits = new CommitStatus(cs);
        MergeSuperSet.reloadChanges(cs);
        logDebug("Calculated to merge {}", cs);
        if (checkSubmitRules) {
            logDebug("Checking submit rules and state");
            checkSubmitRulesAndState(cs);
        } else {
            logDebug("Bypassing submit rules");
            bypassSubmitRules(cs);
        }
        try {
            integrateIntoHistory(cs, dryrun);
        } catch (IntegrationException e) {
            logError("Error from integrateIntoHistory", e);
            throw new ResourceConflictException(e.getMessage(), e);
        }
    } catch (IOException e) {
        // Anything before the merge attempt is an error
        throw new OrmException(e);
    }
}
#method_after
public void merge(ReviewDb db, Change change, IdentifiedUser caller, boolean checkSubmitRules, SubmitInput submitInput, boolean dryrun) throws OrmException, RestApiException {
    this.submitInput = submitInput;
    this.dryrun = dryrun;
    this.caller = caller;
    this.ts = TimeUtil.nowTs();
    submissionId = RequestId.forChange(change);
    this.db = db;
    orm.setContext(db, ts, caller, submissionId);
    logDebug("Beginning integration of {}", change);
    try {
        ChangeSet cs = mergeSuperSet.setMergeOpRepoManager(orm).completeChangeSet(db, change, caller);
        checkState(cs.ids().contains(change.getId()), "change %s missing from %s", change.getId(), cs);
        if (cs.furtherHiddenChanges()) {
            throw new AuthException("A change to be submitted with " + change.getId() + " is not visible");
        }
        this.commits = new CommitStatus(cs);
        MergeSuperSet.reloadChanges(cs);
        logDebug("Calculated to merge {}", cs);
        if (checkSubmitRules) {
            logDebug("Checking submit rules and state");
            checkSubmitRulesAndState(cs);
        } else {
            logDebug("Bypassing submit rules");
            bypassSubmitRules(cs);
        }
        try {
            integrateIntoHistory(cs);
        } catch (IntegrationException e) {
            logError("Error from integrateIntoHistory", e);
            throw new ResourceConflictException(e.getMessage(), e);
        }
    } catch (IOException e) {
        // Anything before the merge attempt is an error
        throw new OrmException(e);
    }
}
#end_block

#method_before
private void integrateIntoHistory(ChangeSet cs, boolean dryrun) throws IntegrationException, RestApiException {
    checkArgument(!cs.furtherHiddenChanges(), "cannot integrate hidden changes into history");
    logDebug("Beginning merge attempt on {}", cs);
    Map<Branch.NameKey, BranchBatch> toSubmit = new HashMap<>();
    logDebug("Perform the merges");
    Multimap<Project.NameKey, Branch.NameKey> br;
    Multimap<Branch.NameKey, ChangeData> cbb;
    try {
        br = cs.branchesByProject();
        cbb = cs.changesByBranch();
    } catch (OrmException e) {
        throw new IntegrationException("Error reading changes to submit", e);
    }
    Set<Project.NameKey> projects = br.keySet();
    Set<Branch.NameKey> branches = cbb.keySet();
    openRepos(projects);
    for (Branch.NameKey branch : branches) {
        OpenRepo or = orm.getRepo(branch.getParentKey());
        toSubmit.put(branch, validateChangeList(or, cbb.get(branch)));
    }
    // Done checks that don't involve running submit strategies.
    commits.maybeFailVerbose();
    SubmoduleOp submoduleOp = subOpFactory.create(branches, orm);
    try {
        List<SubmitStrategy> strategies = getSubmitStrategies(toSubmit, submoduleOp);
        Set<Project.NameKey> allProjects = submoduleOp.getProjectsInOrder();
        // in case superproject subscription is disabled, allProjects would be null
        if (allProjects == null) {
            allProjects = projects;
        }
        this.allProjects = allProjects;
        if (!dryrun) {
            BatchUpdate.execute(orm.batchUpdates(allProjects), new SubmitStrategyListener(submitInput, strategies, commits), submissionId);
        }
    } catch (UpdateException | SubmoduleException e) {
        // BatchUpdate may have inadvertently wrapped an IntegrationException
        // thrown by some legacy SubmitStrategyOp code that intended the error
        // message to be user-visible. Copy the message from the wrapped
        // exception.
        // 
        // If you happen across one of these, the correct fix is to convert the
        // inner IntegrationException to a ResourceConflictException.
        String msg;
        if (e.getCause() instanceof IntegrationException) {
            msg = e.getCause().getMessage();
        } else {
            msg = "Error submitting change" + (cs.size() != 1 ? "s" : "") + ": \n" + e.getMessage();
        }
        throw new IntegrationException(msg, e);
    }
}
#method_after
private void integrateIntoHistory(ChangeSet cs) throws IntegrationException, RestApiException {
    checkArgument(!cs.furtherHiddenChanges(), "cannot integrate hidden changes into history");
    logDebug("Beginning merge attempt on {}", cs);
    Map<Branch.NameKey, BranchBatch> toSubmit = new HashMap<>();
    logDebug("Perform the merges");
    Multimap<Project.NameKey, Branch.NameKey> br;
    Multimap<Branch.NameKey, ChangeData> cbb;
    try {
        br = cs.branchesByProject();
        cbb = cs.changesByBranch();
    } catch (OrmException e) {
        throw new IntegrationException("Error reading changes to submit", e);
    }
    Set<Project.NameKey> projects = br.keySet();
    Set<Branch.NameKey> branches = cbb.keySet();
    openRepos(projects);
    for (Branch.NameKey branch : branches) {
        OpenRepo or = orm.getRepo(branch.getParentKey());
        toSubmit.put(branch, validateChangeList(or, cbb.get(branch)));
    }
    // Done checks that don't involve running submit strategies.
    commits.maybeFailVerbose();
    SubmoduleOp submoduleOp = subOpFactory.create(branches, orm);
    try {
        List<SubmitStrategy> strategies = getSubmitStrategies(toSubmit, submoduleOp, dryrun);
        Set<Project.NameKey> allProjects = submoduleOp.getProjectsInOrder();
        // in case superproject subscription is disabled, allProjects would be null
        if (allProjects == null) {
            allProjects = projects;
        }
        this.allProjects = allProjects;
        BatchUpdate.execute(orm.batchUpdates(allProjects), new SubmitStrategyListener(submitInput, strategies, commits), submissionId, dryrun);
    } catch (UpdateException | SubmoduleException e) {
        // BatchUpdate may have inadvertently wrapped an IntegrationException
        // thrown by some legacy SubmitStrategyOp code that intended the error
        // message to be user-visible. Copy the message from the wrapped
        // exception.
        // 
        // If you happen across one of these, the correct fix is to convert the
        // inner IntegrationException to a ResourceConflictException.
        String msg;
        if (e.getCause() instanceof IntegrationException) {
            msg = e.getCause().getMessage();
        } else {
            msg = "Error submitting change" + (cs.size() != 1 ? "s" : "") + ": \n" + e.getMessage();
        }
        throw new IntegrationException(msg, e);
    }
}
#end_block

#method_before
private List<SubmitStrategy> getSubmitStrategies(Map<Branch.NameKey, BranchBatch> toSubmit, SubmoduleOp submoduleOp) throws IntegrationException {
    List<SubmitStrategy> strategies = new ArrayList<>();
    Set<Branch.NameKey> allBranches = submoduleOp.getBranchesInOrder();
    // in case superproject subscription is disabled, allBranches would be null
    if (allBranches == null) {
        allBranches = toSubmit.keySet();
    }
    for (Branch.NameKey branch : allBranches) {
        OpenRepo or = orm.getRepo(branch.getParentKey());
        if (toSubmit.containsKey(branch)) {
            BranchBatch submitting = toSubmit.get(branch);
            OpenBranch ob = or.getBranch(branch);
            checkNotNull(submitting.submitType(), "null submit type for %s; expected to previously fail fast", submitting);
            Set<CodeReviewCommit> commitsToSubmit = commits(submitting.changes());
            ob.mergeTip = new MergeTip(ob.oldTip, commitsToSubmit);
            SubmitStrategy strategy = createStrategy(or, ob.mergeTip, branch, submitting.submitType(), ob.oldTip, submoduleOp);
            strategies.add(strategy);
            strategy.addOps(or.getUpdate(), commitsToSubmit);
        } else {
            // no open change for this branch
            // add submodule triggered op into BatchUpdate
            submoduleOp.addOp(or.getUpdate(), branch);
        }
    }
    return strategies;
}
#method_after
private List<SubmitStrategy> getSubmitStrategies(Map<Branch.NameKey, BranchBatch> toSubmit, SubmoduleOp submoduleOp, boolean dryrun) throws IntegrationException {
    List<SubmitStrategy> strategies = new ArrayList<>();
    Set<Branch.NameKey> allBranches = submoduleOp.getBranchesInOrder();
    // in case superproject subscription is disabled, allBranches would be null
    if (allBranches == null) {
        allBranches = toSubmit.keySet();
    }
    for (Branch.NameKey branch : allBranches) {
        OpenRepo or = orm.getRepo(branch.getParentKey());
        if (toSubmit.containsKey(branch)) {
            BranchBatch submitting = toSubmit.get(branch);
            OpenBranch ob = or.getBranch(branch);
            checkNotNull(submitting.submitType(), "null submit type for %s; expected to previously fail fast", submitting);
            Set<CodeReviewCommit> commitsToSubmit = commits(submitting.changes());
            ob.mergeTip = new MergeTip(ob.oldTip, commitsToSubmit);
            SubmitStrategy strategy = createStrategy(or, ob.mergeTip, branch, submitting.submitType(), ob.oldTip, submoduleOp, dryrun);
            strategies.add(strategy);
            strategy.addOps(or.getUpdate(), commitsToSubmit);
        } else {
            // no open change for this branch
            // add submodule triggered op into BatchUpdate
            submoduleOp.addOp(or.getUpdate(), branch);
        }
    }
    return strategies;
}
#end_block

#method_before
private SubmitStrategy createStrategy(OpenRepo or, MergeTip mergeTip, Branch.NameKey destBranch, SubmitType submitType, CodeReviewCommit branchTip, SubmoduleOp submoduleOp) throws IntegrationException {
    return submitStrategyFactory.create(submitType, db, or.repo, or.rw, or.ins, or.canMergeFlag, getAlreadyAccepted(or, branchTip), destBranch, caller, mergeTip, commits, submissionId, submitInput.notify, submoduleOp);
}
#method_after
private SubmitStrategy createStrategy(OpenRepo or, MergeTip mergeTip, Branch.NameKey destBranch, SubmitType submitType, CodeReviewCommit branchTip, SubmoduleOp submoduleOp, boolean dryrun) throws IntegrationException {
    return submitStrategyFactory.create(submitType, db, or.repo, or.rw, or.ins, or.canMergeFlag, getAlreadyAccepted(or, branchTip), destBranch, caller, mergeTip, commits, submissionId, submitInput.notify, submoduleOp, dryrun);
}
#end_block

#method_before
private void openRepos(Collection<Project.NameKey> projects) throws IntegrationException {
    for (Project.NameKey project : projects) {
        try {
            orm.openRepo(project, true);
        } catch (NoSuchProjectException noProject) {
            logWarn("Project " + noProject.project() + " no longer exists, " + "abandoning open changes");
            abandonAllOpenChangeForDeletedProject(noProject.project());
        } catch (IOException e) {
            throw new IntegrationException("Error opening project " + project, e);
        }
    }
}
#method_after
private void openRepos(Collection<Project.NameKey> projects) throws IntegrationException {
    for (Project.NameKey project : projects) {
        try {
            orm.openRepo(project);
        } catch (NoSuchProjectException noProject) {
            logWarn("Project " + noProject.project() + " no longer exists, " + "abandoning open changes");
            abandonAllOpenChangeForDeletedProject(noProject.project());
        } catch (IOException e) {
            throw new IntegrationException("Error opening project " + project, e);
        }
    }
}
#end_block

#method_before
private void parseMagicBranch(ReceiveCommand cmd) {
    // Permit exactly one new change request per push.
    if (magicBranch != null) {
        reject(cmd, "duplicate request");
        return;
    }
    logDebug("Found magic branch {}", cmd.getRefName());
    magicBranch = new MagicBranchInput(cmd, labelTypes, notesMigration);
    magicBranch.reviewer.addAll(reviewersFromCommandLine);
    magicBranch.cc.addAll(ccFromCommandLine);
    String ref;
    CmdLineParser clp = optionParserFactory.create(magicBranch);
    magicBranch.clp = clp;
    try {
        ref = magicBranch.parse(clp, repo, rp.getAdvertisedRefs().keySet(), pushOptions);
    } catch (CmdLineException e) {
        if (!clp.wasHelpRequestedByOption()) {
            logDebug("Invalid branch syntax");
            reject(cmd, e.getMessage());
            return;
        }
        // never happen
        ref = null;
    }
    if (clp.wasHelpRequestedByOption()) {
        StringWriter w = new StringWriter();
        w.write("\nHelp for refs/for/branch:\n\n");
        clp.printUsage(w, null);
        addMessage(w.toString());
        reject(cmd, "see help");
        return;
    }
    if (projectControl.getProjectState().isAllUsers() && RefNames.REFS_USERS_SELF.equals(ref)) {
        logDebug("Handling {}", RefNames.REFS_USERS_SELF);
        ref = RefNames.refsUsers(user.getAccountId());
    }
    if (!rp.getAdvertisedRefs().containsKey(ref) && !ref.equals(readHEAD(repo))) {
        logDebug("Ref {} not found", ref);
        if (ref.startsWith(Constants.R_HEADS)) {
            String n = ref.substring(Constants.R_HEADS.length());
            reject(cmd, "branch " + n + " not found");
        } else {
            reject(cmd, ref + " not found");
        }
        return;
    }
    magicBranch.dest = new Branch.NameKey(project.getNameKey(), ref);
    magicBranch.ctl = projectControl.controlForRef(ref);
    if (!magicBranch.ctl.canWrite()) {
        reject(cmd, "project is read only");
        return;
    }
    if (magicBranch.draft) {
        if (!receiveConfig.allowDrafts) {
            errors.put(Error.CODE_REVIEW, ref);
            reject(cmd, "draft workflow is disabled");
            return;
        } else if (projectControl.controlForRef("refs/drafts/" + ref).isBlocked(Permission.PUSH)) {
            errors.put(Error.CODE_REVIEW, ref);
            reject(cmd, "cannot upload drafts");
            return;
        }
    }
    if (!magicBranch.ctl.canUpload()) {
        errors.put(Error.CODE_REVIEW, ref);
        reject(cmd, "cannot upload review");
        return;
    }
    if (magicBranch.draft && magicBranch.submit) {
        reject(cmd, "cannot submit draft");
        return;
    }
    if (magicBranch.submit && !projectControl.controlForRef(MagicBranch.NEW_CHANGE + ref).canSubmit(true)) {
        reject(cmd, "submit not allowed");
        return;
    }
    if (magicBranch.merged) {
        if (magicBranch.draft) {
            reject(cmd, "cannot be draft & merged");
            return;
        }
        if (magicBranch.base != null) {
            reject(cmd, "cannot use merged with base");
            return;
        }
    }
    RevWalk walk = rp.getRevWalk();
    RevCommit tip;
    try {
        tip = walk.parseCommit(magicBranch.cmd.getNewId());
        logDebug("Tip of push: {}", tip.name());
    } catch (IOException ex) {
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", ex);
        return;
    }
    // if %base or %merged was specified, ignore newChangeForAllNotInTarget.
    if (tip.getParentCount() > 1 || magicBranch.base != null || magicBranch.merged || tip.getParentCount() == 0) {
        logDebug("Forcing newChangeForAllNotInTarget = false");
        newChangeForAllNotInTarget = false;
    }
    if (magicBranch.base != null) {
        logDebug("Handling %base: {}", magicBranch.base);
        magicBranch.baseCommit = Lists.newArrayListWithCapacity(magicBranch.base.size());
        for (ObjectId id : magicBranch.base) {
            try {
                magicBranch.baseCommit.add(walk.parseCommit(id));
            } catch (IncorrectObjectTypeException notCommit) {
                reject(cmd, "base must be a commit");
                return;
            } catch (MissingObjectException e) {
                reject(cmd, "base not found");
                return;
            } catch (IOException e) {
                logWarn(String.format("Project %s cannot read %s", project.getName(), id.name()), e);
                reject(cmd, "internal server error");
                return;
            }
        }
    } else if (newChangeForAllNotInTarget) {
        logDebug("Handling newChangeForAllNotInTarget");
        String destBranch = magicBranch.dest.get();
        try {
            Ref r = repo.getRefDatabase().exactRef(destBranch);
            if (r == null) {
                reject(cmd, destBranch + " not found");
                return;
            }
            ObjectId baseHead = r.getObjectId();
            magicBranch.baseCommit = Collections.singletonList(walk.parseCommit(baseHead));
            logDebug("Set baseCommit = {}", magicBranch.baseCommit.get(0).name());
        } catch (IOException ex) {
            logWarn(String.format("Project %s cannot read %s", project.getName(), destBranch), ex);
            reject(cmd, "internal server error");
            return;
        }
    }
    // 
    try {
        Ref targetRef = rp.getAdvertisedRefs().get(magicBranch.ctl.getRefName());
        if (targetRef == null || targetRef.getObjectId() == null) {
            // The destination branch does not yet exist. Assume the
            // history being sent for review will start it and thus
            // is "connected" to the branch.
            logDebug("Branch is unborn");
            return;
        }
        RevCommit h = walk.parseCommit(targetRef.getObjectId());
        logDebug("Current branch tip: {}", h.name());
        RevFilter oldRevFilter = walk.getRevFilter();
        try {
            walk.reset();
            walk.setRevFilter(RevFilter.MERGE_BASE);
            walk.markStart(tip);
            walk.markStart(h);
            if (walk.next() == null) {
                reject(magicBranch.cmd, "no common ancestry");
            }
        } finally {
            walk.reset();
            walk.setRevFilter(oldRevFilter);
        }
    } catch (IOException e) {
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", e);
    }
}
#method_after
private void parseMagicBranch(ReceiveCommand cmd) {
    // Permit exactly one new change request per push.
    if (magicBranch != null) {
        reject(cmd, "duplicate request");
        return;
    }
    logDebug("Found magic branch {}", cmd.getRefName());
    magicBranch = new MagicBranchInput(cmd, labelTypes, notesMigration);
    magicBranch.reviewer.addAll(reviewersFromCommandLine);
    magicBranch.cc.addAll(ccFromCommandLine);
    String ref;
    CmdLineParser clp = optionParserFactory.create(magicBranch);
    magicBranch.clp = clp;
    try {
        ref = magicBranch.parse(clp, repo, rp.getAdvertisedRefs().keySet(), pushOptions);
    } catch (CmdLineException e) {
        if (!clp.wasHelpRequestedByOption()) {
            logDebug("Invalid branch syntax");
            reject(cmd, e.getMessage());
            return;
        }
        // never happen
        ref = null;
    }
    if (clp.wasHelpRequestedByOption()) {
        StringWriter w = new StringWriter();
        w.write("\nHelp for refs/for/branch:\n\n");
        clp.printUsage(w, null);
        addMessage(w.toString());
        reject(cmd, "see help");
        return;
    }
    if (projectControl.getProjectState().isAllUsers() && RefNames.REFS_USERS_SELF.equals(ref)) {
        logDebug("Handling {}", RefNames.REFS_USERS_SELF);
        ref = RefNames.refsUsers(user.getAccountId());
    }
    if (!rp.getAdvertisedRefs().containsKey(ref) && !ref.equals(readHEAD(repo))) {
        logDebug("Ref {} not found", ref);
        if (ref.startsWith(Constants.R_HEADS)) {
            String n = ref.substring(Constants.R_HEADS.length());
            reject(cmd, "branch " + n + " not found");
        } else {
            reject(cmd, ref + " not found");
        }
        return;
    }
    magicBranch.dest = new Branch.NameKey(project.getNameKey(), ref);
    magicBranch.ctl = projectControl.controlForRef(ref);
    if (!magicBranch.ctl.canWrite()) {
        reject(cmd, "project is read only");
        return;
    }
    if (magicBranch.draft) {
        if (!receiveConfig.allowDrafts) {
            errors.put(Error.CODE_REVIEW, ref);
            reject(cmd, "draft workflow is disabled");
            return;
        } else if (projectControl.controlForRef("refs/drafts/" + ref).isBlocked(Permission.PUSH)) {
            errors.put(Error.CODE_REVIEW, ref);
            reject(cmd, "cannot upload drafts");
            return;
        }
    }
    if (!magicBranch.ctl.canUpload()) {
        errors.put(Error.CODE_REVIEW, ref);
        reject(cmd, "cannot upload review");
        return;
    }
    if (magicBranch.draft && magicBranch.submit) {
        reject(cmd, "cannot submit draft");
        return;
    }
    if (magicBranch.submit && !projectControl.controlForRef(MagicBranch.NEW_CHANGE + ref).canSubmit(true)) {
        reject(cmd, "submit not allowed");
        return;
    }
    RevWalk walk = rp.getRevWalk();
    RevCommit tip;
    try {
        tip = walk.parseCommit(magicBranch.cmd.getNewId());
        logDebug("Tip of push: {}", tip.name());
    } catch (IOException ex) {
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", ex);
        return;
    }
    String destBranch = magicBranch.dest.get();
    try {
        if (magicBranch.merged) {
            if (magicBranch.draft) {
                reject(cmd, "cannot be draft & merged");
                return;
            }
            if (magicBranch.base != null) {
                reject(cmd, "cannot use merged with base");
                return;
            }
            RevCommit branchTip = readBranchTip(cmd, magicBranch.dest);
            if (branchTip == null) {
                // readBranchTip already rejected cmd.
                return;
            }
            if (!walk.isMergedInto(tip, branchTip)) {
                reject(cmd, "not merged into branch");
                return;
            }
        }
        // if %base or %merged was specified, ignore newChangeForAllNotInTarget.
        if (tip.getParentCount() > 1 || magicBranch.base != null || magicBranch.merged || tip.getParentCount() == 0) {
            logDebug("Forcing newChangeForAllNotInTarget = false");
            newChangeForAllNotInTarget = false;
        }
        if (magicBranch.base != null) {
            logDebug("Handling %base: {}", magicBranch.base);
            magicBranch.baseCommit = Lists.newArrayListWithCapacity(magicBranch.base.size());
            for (ObjectId id : magicBranch.base) {
                try {
                    magicBranch.baseCommit.add(walk.parseCommit(id));
                } catch (IncorrectObjectTypeException notCommit) {
                    reject(cmd, "base must be a commit");
                    return;
                } catch (MissingObjectException e) {
                    reject(cmd, "base not found");
                    return;
                } catch (IOException e) {
                    logWarn(String.format("Project %s cannot read %s", project.getName(), id.name()), e);
                    reject(cmd, "internal server error");
                    return;
                }
            }
        } else if (newChangeForAllNotInTarget) {
            RevCommit branchTip = readBranchTip(cmd, magicBranch.dest);
            if (branchTip == null) {
                // readBranchTip already rejected cmd.
                return;
            }
            magicBranch.baseCommit = Collections.singletonList(branchTip);
            logDebug("Set baseCommit = {}", magicBranch.baseCommit.get(0).name());
        }
    } catch (IOException ex) {
        logWarn(String.format("Error walking to %s in project %s", destBranch, project.getName()), ex);
        reject(cmd, "internal server error");
        return;
    }
    // 
    try {
        Ref targetRef = rp.getAdvertisedRefs().get(magicBranch.ctl.getRefName());
        if (targetRef == null || targetRef.getObjectId() == null) {
            // The destination branch does not yet exist. Assume the
            // history being sent for review will start it and thus
            // is "connected" to the branch.
            logDebug("Branch is unborn");
            return;
        }
        RevCommit h = walk.parseCommit(targetRef.getObjectId());
        logDebug("Current branch tip: {}", h.name());
        RevFilter oldRevFilter = walk.getRevFilter();
        try {
            walk.reset();
            walk.setRevFilter(RevFilter.MERGE_BASE);
            walk.markStart(tip);
            walk.markStart(h);
            if (walk.next() == null) {
                reject(magicBranch.cmd, "no common ancestry");
            }
        } finally {
            walk.reset();
            walk.setRevFilter(oldRevFilter);
        }
    } catch (IOException e) {
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", e);
    }
}
#end_block

#method_before
private void selectNewAndReplacedChangesFromMagicBranch() {
    logDebug("Finding new and replaced changes");
    newChanges = new ArrayList<>();
    SetMultimap<ObjectId, Ref> existing = changeRefsById();
    GroupCollector groupCollector = GroupCollector.create(changeRefsById(), db, psUtil, notesFactory, project.getNameKey());
    try {
        RevCommit start = setUpWalkForSelectingChanges();
        List<ChangeLookup> pending = new ArrayList<>();
        Set<Change.Key> newChangeIds = new HashSet<>();
        int maxBatchChanges = receiveConfig.getEffectiveMaxBatchChangesLimit(user);
        int total = 0;
        int alreadyTracked = 0;
        boolean rejectImplicitMerges = start.getParentCount() == 1 && projectCache.get(project.getNameKey()).isRejectImplicitMerges() && // late.
        !magicBranch.merged;
        Set<RevCommit> mergedParents;
        if (rejectImplicitMerges) {
            mergedParents = new HashSet<>();
        } else {
            mergedParents = null;
        }
        for (; ; ) {
            RevCommit c = rp.getRevWalk().next();
            if (c == null) {
                break;
            }
            total++;
            String name = c.name();
            groupCollector.visit(c);
            Collection<Ref> existingRefs = existing.get(c);
            if (rejectImplicitMerges) {
                Collections.addAll(mergedParents, c.getParents());
                mergedParents.remove(c);
            }
            if (!existingRefs.isEmpty()) {
                // Commit is already tracked.
                alreadyTracked++;
                // different target branch.
                for (Ref ref : existingRefs) {
                    updateGroups.add(new UpdateGroupsRequest(ref, c));
                }
                if (!(newChangeForAllNotInTarget || magicBranch.base != null)) {
                    continue;
                }
                logDebug("Creating new change for {} even though it is already tracked", name);
            }
            if (!validCommit(rp.getRevWalk(), magicBranch.ctl, magicBranch.cmd, c)) {
                // Not a change the user can propose? Abort as early as possible.
                newChanges = Collections.emptyList();
                logDebug("Aborting early due to invalid commit");
                return;
            }
            // Don't allow merges to be uploaded in commit chain via all-not-in-target
            if (newChangeForAllNotInTarget && c.getParentCount() > 1) {
                reject(magicBranch.cmd, "Pushing merges in commit chains with 'all not in target' is not allowed,\n" + "to override please set the base manually");
                logDebug("Rejecting merge commit {} with newChangeForAllNotInTarget", name);
            // TODO(dborowitz): Should we early return here?
            }
            List<String> idList = c.getFooterLines(CHANGE_ID);
            if (idList.isEmpty()) {
                newChanges.add(new CreateRequest(c, magicBranch.dest.get()));
                continue;
            }
            String idStr = idList.get(idList.size() - 1).trim();
            if (idStr.matches("^I00*$")) {
                // Reject this invalid line from EGit.
                reject(magicBranch.cmd, "invalid Change-Id");
                newChanges = Collections.emptyList();
                return;
            }
            pending.add(new ChangeLookup(c, new Change.Key(idStr)));
            int n = pending.size() + newChanges.size();
            if (maxBatchChanges != 0 && n > maxBatchChanges) {
                logDebug("{} changes exceeds limit of {}", n, maxBatchChanges);
                reject(magicBranch.cmd, "the number of pushed changes in a batch exceeds the max limit " + maxBatchChanges);
                newChanges = Collections.emptyList();
                return;
            }
        }
        logDebug("Finished initial RevWalk with {} commits total: {} already" + " tracked, {} new changes with no Change-Id, and {} deferred" + " lookups", total, alreadyTracked, newChanges.size(), pending.size());
        if (rejectImplicitMerges) {
            rejectImplicitMerges(mergedParents);
        }
        for (Iterator<ChangeLookup> itr = pending.iterator(); itr.hasNext(); ) {
            ChangeLookup p = itr.next();
            if (newChangeIds.contains(p.changeKey)) {
                logDebug("Multiple commits with Change-Id {}", p.changeKey);
                reject(magicBranch.cmd, SAME_CHANGE_ID_IN_MULTIPLE_CHANGES);
                newChanges = Collections.emptyList();
                return;
            }
            List<ChangeData> changes = p.destChanges;
            if (changes.size() > 1) {
                logDebug("Multiple changes in project with Change-Id {}: {}", p.changeKey, Lists.transform(changes, new Function<ChangeData, String>() {

                    @Override
                    public String apply(ChangeData in) {
                        return in.getId().toString();
                    }
                }));
                // WTF, multiple changes in this project have the same key?
                // Since the commit is new, the user should recreate it with
                // a different Change-Id. In practice, we should never see
                // this error message as Change-Id should be unique.
                // 
                reject(magicBranch.cmd, p.changeKey.get() + " has duplicates");
                newChanges = Collections.emptyList();
                return;
            }
            if (changes.size() == 1) {
                // Schedule as a replacement to this one matching change.
                // 
                RevId currentPs = changes.get(0).currentPatchSet().getRevision();
                // If Commit is already current PatchSet of target Change.
                if (p.commit.name().equals(currentPs.get())) {
                    if (pending.size() == 1) {
                        // There are no commits left to check, all commits in pending were already
                        // current PatchSet of the corresponding target changes.
                        reject(magicBranch.cmd, "commit(s) already exists (as current patchset)");
                    } else {
                        // Commit is already current PatchSet.
                        // Remove from pending and try next commit.
                        itr.remove();
                        continue;
                    }
                }
                if (requestReplace(magicBranch.cmd, false, changes.get(0).change(), p.commit)) {
                    continue;
                }
                newChanges = Collections.emptyList();
                return;
            }
            if (changes.size() == 0) {
                if (!isValidChangeId(p.changeKey.get())) {
                    reject(magicBranch.cmd, "invalid Change-Id");
                    newChanges = Collections.emptyList();
                    return;
                }
                newChangeIds.add(p.changeKey);
            }
            newChanges.add(new CreateRequest(p.commit, magicBranch.dest.get()));
        }
        logDebug("Finished deferred lookups with {} updates and {} new changes", replaceByChange.size(), newChanges.size());
    } catch (IOException e) {
        // Should never happen, the core receive process would have
        // identified the missing object earlier before we got control.
        // 
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", e);
        newChanges = Collections.emptyList();
        return;
    } catch (OrmException e) {
        logError("Cannot query database to locate prior changes", e);
        reject(magicBranch.cmd, "database error");
        newChanges = Collections.emptyList();
        return;
    }
    if (newChanges.isEmpty() && replaceByChange.isEmpty()) {
        reject(magicBranch.cmd, "no new changes");
        return;
    }
    if (!newChanges.isEmpty() && magicBranch.edit) {
        reject(magicBranch.cmd, "edit is not supported for new changes");
        return;
    }
    try {
        SortedSetMultimap<ObjectId, String> groups = groupCollector.getGroups();
        List<Integer> newIds = seq.nextChangeIds(newChanges.size());
        for (int i = 0; i < newChanges.size(); i++) {
            CreateRequest create = newChanges.get(i);
            create.setChangeId(newIds.get(i));
            batch.addCommand(create.cmd);
            create.groups = ImmutableList.copyOf(groups.get(create.commit));
        }
        for (ReplaceRequest replace : replaceByChange.values()) {
            replace.groups = ImmutableList.copyOf(groups.get(replace.newCommitId));
        }
        for (UpdateGroupsRequest update : updateGroups) {
            update.groups = ImmutableList.copyOf((groups.get(update.commit)));
        }
        logDebug("Finished updating groups from GroupCollector");
    } catch (OrmException | NoSuchChangeException e) {
        logError("Error collecting groups for changes", e);
        reject(magicBranch.cmd, "internal server error");
        return;
    }
}
#method_after
private void selectNewAndReplacedChangesFromMagicBranch() {
    logDebug("Finding new and replaced changes");
    newChanges = new ArrayList<>();
    SetMultimap<ObjectId, Ref> existing = changeRefsById();
    GroupCollector groupCollector = GroupCollector.create(changeRefsById(), db, psUtil, notesFactory, project.getNameKey());
    try {
        RevCommit start = setUpWalkForSelectingChanges();
        if (start == null) {
            return;
        }
        List<ChangeLookup> pending = new ArrayList<>();
        Set<Change.Key> newChangeIds = new HashSet<>();
        int maxBatchChanges = receiveConfig.getEffectiveMaxBatchChangesLimit(user);
        int total = 0;
        int alreadyTracked = 0;
        boolean rejectImplicitMerges = start.getParentCount() == 1 && projectCache.get(project.getNameKey()).isRejectImplicitMerges() && // late.
        !magicBranch.merged;
        Set<RevCommit> mergedParents;
        if (rejectImplicitMerges) {
            mergedParents = new HashSet<>();
        } else {
            mergedParents = null;
        }
        for (; ; ) {
            RevCommit c = rp.getRevWalk().next();
            if (c == null) {
                break;
            }
            total++;
            String name = c.name();
            groupCollector.visit(c);
            Collection<Ref> existingRefs = existing.get(c);
            if (rejectImplicitMerges) {
                Collections.addAll(mergedParents, c.getParents());
                mergedParents.remove(c);
            }
            if (!existingRefs.isEmpty()) {
                // Commit is already tracked.
                alreadyTracked++;
                // different target branch.
                for (Ref ref : existingRefs) {
                    updateGroups.add(new UpdateGroupsRequest(ref, c));
                }
                if (!(newChangeForAllNotInTarget || magicBranch.base != null)) {
                    continue;
                }
                logDebug("Creating new change for {} even though it is already tracked", name);
            }
            if (!validCommit(rp.getRevWalk(), magicBranch.ctl, magicBranch.cmd, c)) {
                // Not a change the user can propose? Abort as early as possible.
                newChanges = Collections.emptyList();
                logDebug("Aborting early due to invalid commit");
                return;
            }
            // Don't allow merges to be uploaded in commit chain via all-not-in-target
            if (newChangeForAllNotInTarget && c.getParentCount() > 1) {
                reject(magicBranch.cmd, "Pushing merges in commit chains with 'all not in target' is not allowed,\n" + "to override please set the base manually");
                logDebug("Rejecting merge commit {} with newChangeForAllNotInTarget", name);
            // TODO(dborowitz): Should we early return here?
            }
            List<String> idList = c.getFooterLines(CHANGE_ID);
            if (idList.isEmpty()) {
                newChanges.add(new CreateRequest(c, magicBranch.dest.get()));
                continue;
            }
            String idStr = idList.get(idList.size() - 1).trim();
            if (idStr.matches("^I00*$")) {
                // Reject this invalid line from EGit.
                reject(magicBranch.cmd, "invalid Change-Id");
                newChanges = Collections.emptyList();
                return;
            }
            pending.add(new ChangeLookup(c, new Change.Key(idStr)));
            int n = pending.size() + newChanges.size();
            if (maxBatchChanges != 0 && n > maxBatchChanges) {
                logDebug("{} changes exceeds limit of {}", n, maxBatchChanges);
                reject(magicBranch.cmd, "the number of pushed changes in a batch exceeds the max limit " + maxBatchChanges);
                newChanges = Collections.emptyList();
                return;
            }
        }
        logDebug("Finished initial RevWalk with {} commits total: {} already" + " tracked, {} new changes with no Change-Id, and {} deferred" + " lookups", total, alreadyTracked, newChanges.size(), pending.size());
        if (rejectImplicitMerges) {
            rejectImplicitMerges(mergedParents);
        }
        for (Iterator<ChangeLookup> itr = pending.iterator(); itr.hasNext(); ) {
            ChangeLookup p = itr.next();
            if (newChangeIds.contains(p.changeKey)) {
                logDebug("Multiple commits with Change-Id {}", p.changeKey);
                reject(magicBranch.cmd, SAME_CHANGE_ID_IN_MULTIPLE_CHANGES);
                newChanges = Collections.emptyList();
                return;
            }
            List<ChangeData> changes = p.destChanges;
            if (changes.size() > 1) {
                logDebug("Multiple changes in project with Change-Id {}: {}", p.changeKey, Lists.transform(changes, new Function<ChangeData, String>() {

                    @Override
                    public String apply(ChangeData in) {
                        return in.getId().toString();
                    }
                }));
                // WTF, multiple changes in this project have the same key?
                // Since the commit is new, the user should recreate it with
                // a different Change-Id. In practice, we should never see
                // this error message as Change-Id should be unique.
                // 
                reject(magicBranch.cmd, p.changeKey.get() + " has duplicates");
                newChanges = Collections.emptyList();
                return;
            }
            if (changes.size() == 1) {
                // Schedule as a replacement to this one matching change.
                // 
                RevId currentPs = changes.get(0).currentPatchSet().getRevision();
                // If Commit is already current PatchSet of target Change.
                if (p.commit.name().equals(currentPs.get())) {
                    if (pending.size() == 1) {
                        // There are no commits left to check, all commits in pending were already
                        // current PatchSet of the corresponding target changes.
                        reject(magicBranch.cmd, "commit(s) already exists (as current patchset)");
                    } else {
                        // Commit is already current PatchSet.
                        // Remove from pending and try next commit.
                        itr.remove();
                        continue;
                    }
                }
                if (requestReplace(magicBranch.cmd, false, changes.get(0).change(), p.commit)) {
                    continue;
                }
                newChanges = Collections.emptyList();
                return;
            }
            if (changes.size() == 0) {
                if (!isValidChangeId(p.changeKey.get())) {
                    reject(magicBranch.cmd, "invalid Change-Id");
                    newChanges = Collections.emptyList();
                    return;
                }
                newChangeIds.add(p.changeKey);
            }
            newChanges.add(new CreateRequest(p.commit, magicBranch.dest.get()));
        }
        logDebug("Finished deferred lookups with {} updates and {} new changes", replaceByChange.size(), newChanges.size());
    } catch (IOException e) {
        // Should never happen, the core receive process would have
        // identified the missing object earlier before we got control.
        // 
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", e);
        newChanges = Collections.emptyList();
        return;
    } catch (OrmException e) {
        logError("Cannot query database to locate prior changes", e);
        reject(magicBranch.cmd, "database error");
        newChanges = Collections.emptyList();
        return;
    }
    if (newChanges.isEmpty() && replaceByChange.isEmpty()) {
        reject(magicBranch.cmd, "no new changes");
        return;
    }
    if (!newChanges.isEmpty() && magicBranch.edit) {
        reject(magicBranch.cmd, "edit is not supported for new changes");
        return;
    }
    try {
        SortedSetMultimap<ObjectId, String> groups = groupCollector.getGroups();
        List<Integer> newIds = seq.nextChangeIds(newChanges.size());
        for (int i = 0; i < newChanges.size(); i++) {
            CreateRequest create = newChanges.get(i);
            create.setChangeId(newIds.get(i));
            batch.addCommand(create.cmd);
            create.groups = ImmutableList.copyOf(groups.get(create.commit));
        }
        for (ReplaceRequest replace : replaceByChange.values()) {
            replace.groups = ImmutableList.copyOf(groups.get(replace.newCommitId));
        }
        for (UpdateGroupsRequest update : updateGroups) {
            update.groups = ImmutableList.copyOf((groups.get(update.commit)));
        }
        logDebug("Finished updating groups from GroupCollector");
    } catch (OrmException | NoSuchChangeException e) {
        logError("Error collecting groups for changes", e);
        reject(magicBranch.cmd, "internal server error");
        return;
    }
}
#end_block

#method_before
private RevCommit setUpWalkForSelectingChanges() throws IOException {
    RevWalk rw = rp.getRevWalk();
    rw.reset();
    rw.sort(RevSort.TOPO);
    rw.sort(RevSort.REVERSE, true);
    RevCommit start = rw.parseCommit(magicBranch.cmd.getNewId());
    rp.getRevWalk().markStart(start);
    if (magicBranch.baseCommit != null) {
        markExplicitBasesUninteresting();
    } else if (magicBranch.merged) {
        logDebug("Marking parents of merged commit {} uninteresting", start.name());
        for (RevCommit c : start.getParents()) {
            rw.markUninteresting(c);
        }
    } else {
        markHeadsAsUninteresting(rw, magicBranch.ctl != null ? magicBranch.ctl.getRefName() : null);
    }
    return start;
}
#method_after
private RevCommit setUpWalkForSelectingChanges() throws IOException {
    RevWalk rw = rp.getRevWalk();
    RevCommit start = rw.parseCommit(magicBranch.cmd.getNewId());
    rw.reset();
    rw.sort(RevSort.TOPO);
    rw.sort(RevSort.REVERSE, true);
    rp.getRevWalk().markStart(start);
    if (magicBranch.baseCommit != null) {
        markExplicitBasesUninteresting();
    } else if (magicBranch.merged) {
        logDebug("Marking parents of merged commit {} uninteresting", start.name());
        for (RevCommit c : start.getParents()) {
            rw.markUninteresting(c);
        }
    } else {
        markHeadsAsUninteresting(rw, magicBranch.ctl != null ? magicBranch.ctl.getRefName() : null);
    }
    return start;
}
#end_block

#method_before
private boolean validCommit(RevWalk rw, RefControl ctl, ReceiveCommand cmd, ObjectId id) throws IOException {
    if (validCommits.contains(id)) {
        return true;
    }
    RevCommit c = rw.parseCommit(id);
    rw.parseBody(c);
    CommitReceivedEvent receiveEvent = new CommitReceivedEvent(cmd, project, ctl.getRefName(), c, user);
    CommitValidators commitValidators = commitValidatorsFactory.create(ctl, sshInfo, repo);
    if (magicBranch != null && cmd.getRefName().equals(magicBranch.cmd.getRefName()) && magicBranch.merged) {
        // When a commit is already merged, the user can't go back and add a
        // Change-Id line if missing. However, we still want perform the rest of
        // the validation for things like Forge Committer.
        // TODO(dborowitz): Do we want to use all other validation checks? If we
        // need some defined subset, then we probably need a new validateFor*
        // method on CommitValidators.
        commitValidators.setValidateChangeId(false);
    }
    try {
        messages.addAll(commitValidators.validateForReceiveCommits(receiveEvent, rejectCommits));
    } catch (CommitValidationException e) {
        logDebug("Commit validation failed on {}", c.name());
        messages.addAll(e.getMessages());
        reject(cmd, e.getMessage());
        return false;
    }
    validCommits.add(c.copy());
    return true;
}
#method_after
private boolean validCommit(RevWalk rw, RefControl ctl, ReceiveCommand cmd, ObjectId id) throws IOException {
    if (validCommits.contains(id)) {
        return true;
    }
    RevCommit c = rw.parseCommit(id);
    rw.parseBody(c);
    CommitReceivedEvent receiveEvent = new CommitReceivedEvent(cmd, project, ctl.getRefName(), c, user);
    CommitValidators.Policy policy;
    if (magicBranch != null && cmd.getRefName().equals(magicBranch.cmd.getRefName()) && magicBranch.merged) {
        policy = CommitValidators.Policy.MERGED;
    } else {
        policy = CommitValidators.Policy.RECEIVE_COMMITS;
    }
    try {
        messages.addAll(commitValidatorsFactory.create(policy, ctl, sshInfo, repo).validate(receiveEvent));
    } catch (CommitValidationException e) {
        logDebug("Commit validation failed on {}", c.name());
        messages.addAll(e.getMessages());
        reject(cmd, e.getMessage());
        return false;
    }
    validCommits.add(c.copy());
    return true;
}
#end_block

#method_before
@Test
public void createChangeForMergedCommit() throws Exception {
    String master = "refs/heads/master";
    grant(Permission.PUSH, project, master, true);
    // Update master with a direct push.
    RevCommit c1;
    RevCommit c2;
    String changeId;
    c1 = testRepo.commit().message("Non-change 1").create();
    c2 = testRepo.parseBody(testRepo.commit().parent(c1).message("Non-change 2").insertChangeId().create());
    changeId = Iterables.getOnlyElement(c2.getFooterLines(CHANGE_ID));
    testRepo.reset(c2);
    assertPushOk(pushHead(testRepo, master, false, true), master);
    String q = "commit:" + c1.name() + " OR commit:" + c2.name() + " OR change:" + changeId;
    assertThat(gApi.changes().query(q).get()).isEmpty();
    // Push c2 as a merged change.
    String r = "refs/for/master%merged";
    assertPushOk(pushHead(testRepo, r, false), r);
    EnumSet<ListChangesOption> opts = EnumSet.of(ListChangesOption.CURRENT_REVISION);
    ChangeInfo info = gApi.changes().id(changeId).get(opts);
    assertThat(info.currentRevision).isEqualTo(c2.name());
    assertThat(info.status).isEqualTo(ChangeStatus.MERGED);
    // Only c2 was created as a change.
    String q1 = "commit: " + c1.name();
    assertThat(gApi.changes().query(q1).get()).isEmpty();
    // Push c1 as a merged change.
    testRepo.reset(c1);
    assertPushOk(pushHead(testRepo, r, false), r);
    List<ChangeInfo> infos = gApi.changes().query(q1).withOptions(opts).get();
    assertThat(infos).hasSize(1);
    info = infos.get(0);
    assertThat(info.currentRevision).isEqualTo(c1.name());
    assertThat(info.status).isEqualTo(ChangeStatus.MERGED);
}
#method_after
@Test
public void createChangeForMergedCommit() throws Exception {
    String master = "refs/heads/master";
    grant(Permission.PUSH, project, master, true);
    // Update master with a direct push.
    RevCommit c1 = testRepo.commit().message("Non-change 1").create();
    RevCommit c2 = testRepo.parseBody(testRepo.commit().parent(c1).message("Non-change 2").insertChangeId().create());
    String changeId = Iterables.getOnlyElement(c2.getFooterLines(CHANGE_ID));
    testRepo.reset(c2);
    assertPushOk(pushHead(testRepo, master, false, true), master);
    String q = "commit:" + c1.name() + " OR commit:" + c2.name() + " OR change:" + changeId;
    assertThat(gApi.changes().query(q).get()).isEmpty();
    // Push c2 as a merged change.
    String r = "refs/for/master%merged";
    assertPushOk(pushHead(testRepo, r, false), r);
    EnumSet<ListChangesOption> opts = EnumSet.of(ListChangesOption.CURRENT_REVISION);
    ChangeInfo info = gApi.changes().id(changeId).get(opts);
    assertThat(info.currentRevision).isEqualTo(c2.name());
    assertThat(info.status).isEqualTo(ChangeStatus.MERGED);
    // Only c2 was created as a change.
    String q1 = "commit: " + c1.name();
    assertThat(gApi.changes().query(q1).get()).isEmpty();
    // Push c1 as a merged change.
    testRepo.reset(c1);
    assertPushOk(pushHead(testRepo, r, false), r);
    List<ChangeInfo> infos = gApi.changes().query(q1).withOptions(opts).get();
    assertThat(infos).hasSize(1);
    info = infos.get(0);
    assertThat(info.currentRevision).isEqualTo(c1.name());
    assertThat(info.status).isEqualTo(ChangeStatus.MERGED);
}
#end_block

#method_before
@Override
public List<CommitValidationMessage> onCommitReceived(CommitReceivedEvent receiveEvent) throws CommitValidationException {
    RevCommit commit = receiveEvent.commit;
    List<CommitValidationMessage> messages = new LinkedList<>();
    List<String> idList = commit.getFooterLines(FooterConstants.CHANGE_ID);
    String sha1 = commit.abbreviate(SHA1_LENGTH).name();
    if (idList.isEmpty()) {
        if (projectControl.getProjectState().isRequireChangeID()) {
            String shortMsg = commit.getShortMessage();
            if (shortMsg.startsWith(CHANGE_ID_PREFIX) && CHANGE_ID.matcher(shortMsg.substring(CHANGE_ID_PREFIX.length()).trim()).matches()) {
                String errMsg = String.format(MISSING_SUBJECT_MSG, sha1);
                throw new CommitValidationException(errMsg);
            }
            String errMsg = String.format(MISSING_CHANGE_ID_MSG, sha1);
            messages.add(getMissingChangeIdErrorMsg(errMsg, commit));
            throw new CommitValidationException(errMsg, messages);
        }
    } else if (idList.size() > 1) {
        String errMsg = String.format(MULTIPLE_CHANGE_ID_MSG, sha1);
        throw new CommitValidationException(errMsg, messages);
    } else {
        String v = idList.get(idList.size() - 1).trim();
        if (!CHANGE_ID.matcher(v).matches()) {
            String errMsg = String.format(INVALID_CHANGE_ID_MSG, sha1);
            messages.add(getMissingChangeIdErrorMsg(errMsg, receiveEvent.commit));
            throw new CommitValidationException(errMsg, messages);
        }
    }
    return Collections.emptyList();
}
#method_after
@Override
public List<CommitValidationMessage> onCommitReceived(CommitReceivedEvent receiveEvent) throws CommitValidationException {
    if (!shouldValidateChangeId(receiveEvent)) {
        return Collections.emptyList();
    }
    RevCommit commit = receiveEvent.commit;
    List<CommitValidationMessage> messages = new LinkedList<>();
    List<String> idList = commit.getFooterLines(FooterConstants.CHANGE_ID);
    String sha1 = commit.abbreviate(SHA1_LENGTH).name();
    if (idList.isEmpty()) {
        if (projectControl.getProjectState().isRequireChangeID()) {
            String shortMsg = commit.getShortMessage();
            if (shortMsg.startsWith(CHANGE_ID_PREFIX) && CHANGE_ID.matcher(shortMsg.substring(CHANGE_ID_PREFIX.length()).trim()).matches()) {
                String errMsg = String.format(MISSING_SUBJECT_MSG, sha1);
                throw new CommitValidationException(errMsg);
            }
            String errMsg = String.format(MISSING_CHANGE_ID_MSG, sha1);
            messages.add(getMissingChangeIdErrorMsg(errMsg, commit));
            throw new CommitValidationException(errMsg, messages);
        }
    } else if (idList.size() > 1) {
        String errMsg = String.format(MULTIPLE_CHANGE_ID_MSG, sha1);
        throw new CommitValidationException(errMsg, messages);
    } else {
        String v = idList.get(idList.size() - 1).trim();
        if (!CHANGE_ID.matcher(v).matches()) {
            String errMsg = String.format(INVALID_CHANGE_ID_MSG, sha1);
            messages.add(getMissingChangeIdErrorMsg(errMsg, receiveEvent.commit));
            throw new CommitValidationException(errMsg, messages);
        }
    }
    return Collections.emptyList();
}
#end_block

#method_before
public MergeSuperSet setMergeOpRepoManager(MergeOpRepoManager orm) {
    checkState(this.orm == null);
    this.orm = checkNotNull(orm);
    return this;
}
#method_after
public MergeSuperSet setMergeOpRepoManager(MergeOpRepoManager orm) {
    checkState(this.orm == null);
    this.orm = checkNotNull(orm);
    closeOrm = false;
    return this;
}
#end_block

#method_before
public ChangeSet completeChangeSet(ReviewDb db, Change change, CurrentUser user) throws IOException, OrmException {
    try {
        ChangeData cd = changeDataFactory.create(db, change.getProject(), change.getId());
        cd.changeControl(user);
        ChangeSet cs = new ChangeSet(cd, cd.changeControl().isVisible(db, cd));
        if (Submit.wholeTopicEnabled(cfg)) {
            return completeChangeSetIncludingTopics(db, cs, user);
        }
        return completeChangeSetWithoutTopic(db, cs, user);
    } finally {
        closeRepos();
    }
}
#method_after
public ChangeSet completeChangeSet(ReviewDb db, Change change, CurrentUser user) throws IOException, OrmException {
    try {
        ChangeData cd = changeDataFactory.create(db, change.getProject(), change.getId());
        cd.changeControl(user);
        ChangeSet cs = new ChangeSet(cd, cd.changeControl().isVisible(db, cd));
        if (Submit.wholeTopicEnabled(cfg)) {
            return completeChangeSetIncludingTopics(db, cs, user);
        }
        return completeChangeSetWithoutTopic(db, cs, user);
    } finally {
        if (closeOrm && orm != null) {
            orm.close();
            orm = null;
        }
    }
}
#end_block

#method_before
private ChangeSet completeChangeSetWithoutTopic(ReviewDb db, ChangeSet changes, CurrentUser user) throws IOException, OrmException {
    Collection<ChangeData> visibleChanges = new ArrayList<>();
    Collection<ChangeData> nonVisibleChanges = new ArrayList<>();
    // For each target branch we run a separate rev walk to find open changes
    // reachable from changes already in the merge super set.
    ImmutableListMultimap<Branch.NameKey, ChangeData> bc = byBranch(Iterables.concat(changes.changes(), changes.nonVisibleChanges()));
    for (Branch.NameKey b : bc.keySet()) {
        OpenRepo or = getRepo(b.getParentKey());
        List<RevCommit> visibleCommits = new ArrayList<>();
        List<RevCommit> nonVisibleCommits = new ArrayList<>();
        for (ChangeData cd : bc.get(b)) {
            checkState(cd.hasChangeControl(), "completeChangeSet forgot to set changeControl for current user" + " at ChangeData creation time");
            boolean visible = changes.ids().contains(cd.getId());
            if (visible && !cd.changeControl().isVisible(db, cd)) {
                // We thought the change was visible, but it isn't.
                // This can happen if the ACL changes during the
                // completeChangeSet computation, for example.
                visible = false;
            }
            Collection<ChangeData> dest = visible ? visibleChanges : nonVisibleChanges;
            Collection<RevCommit> toWalk = visible ? visibleCommits : nonVisibleCommits;
            // Pick a revision to use for traversal.  If any of the patch sets
            // is visible, we use the most recent one.  Otherwise, use the current
            // patch set.
            PatchSet ps = cd.currentPatchSet();
            boolean visiblePatchSet = visible;
            if (!cd.changeControl().isPatchVisible(ps, cd)) {
                Iterable<PatchSet> visiblePatchSets = cd.visiblePatchSets();
                if (Iterables.isEmpty(visiblePatchSets)) {
                    visiblePatchSet = false;
                } else {
                    ps = Iterables.getLast(visiblePatchSets);
                }
            }
            if (submitType(cd, ps, visiblePatchSet) == SubmitType.CHERRY_PICK) {
                dest.add(cd);
                continue;
            }
            // Get the underlying git commit object
            String objIdStr = ps.getRevision().get();
            RevCommit commit = or.rw.parseCommit(ObjectId.fromString(objIdStr));
            // Always include the input, even if merged. This allows
            // SubmitStrategyOp to correct the situation later, assuming it gets
            // returned by byCommitsOnBranchNotMerged below.
            toWalk.add(commit);
        }
        Ref ref = or.repo.getRefDatabase().getRef(b.get());
        Optional<RevCommit> head = ref != null ? Optional.<RevCommit>of(or.rw.parseCommit(ref.getObjectId())) : Optional.<RevCommit>absent();
        Set<String> visibleHashes = new HashSet<>();
        or.rw.reset();
        if (head.isPresent()) {
            or.rw.markUninteresting(head.get());
        }
        for (RevCommit c : visibleCommits) {
            visibleHashes.add(c.name());
            or.rw.markStart(c);
        }
        for (RevCommit c : or.rw) {
            visibleHashes.add(c.name());
        }
        Iterable<ChangeData> cds = query().byCommitsOnBranchNotMerged(or.repo, db, b, visibleHashes);
        for (ChangeData chd : cds) {
            chd.changeControl(user);
            visibleChanges.add(chd);
        }
        Set<String> nonVisibleHashes = new HashSet<>();
        or.rw.reset();
        if (head.isPresent()) {
            or.rw.markUninteresting(head.get());
        }
        for (RevCommit c : nonVisibleCommits) {
            if (visibleHashes.contains(c.name())) {
                continue;
            }
            nonVisibleHashes.add(c.name());
            or.rw.markStart(c);
        }
        for (RevCommit c : or.rw) {
            if (visibleHashes.contains(c.name())) {
                continue;
            }
            nonVisibleHashes.add(c.name());
        }
        Iterables.addAll(nonVisibleChanges, query().byCommitsOnBranchNotMerged(or.repo, db, b, nonVisibleHashes));
    }
    return new ChangeSet(visibleChanges, nonVisibleChanges);
}
#method_after
private ChangeSet completeChangeSetWithoutTopic(ReviewDb db, ChangeSet changes, CurrentUser user) throws IOException, OrmException {
    Collection<ChangeData> visibleChanges = new ArrayList<>();
    Collection<ChangeData> nonVisibleChanges = new ArrayList<>();
    // For each target branch we run a separate rev walk to find open changes
    // reachable from changes already in the merge super set.
    ImmutableListMultimap<Branch.NameKey, ChangeData> bc = byBranch(Iterables.concat(changes.changes(), changes.nonVisibleChanges()));
    for (Branch.NameKey b : bc.keySet()) {
        OpenRepo or = getRepo(b.getParentKey());
        List<RevCommit> visibleCommits = new ArrayList<>();
        List<RevCommit> nonVisibleCommits = new ArrayList<>();
        for (ChangeData cd : bc.get(b)) {
            checkState(cd.hasChangeControl(), "completeChangeSet forgot to set changeControl for current user" + " at ChangeData creation time");
            boolean visible = changes.ids().contains(cd.getId());
            if (visible && !cd.changeControl().isVisible(db, cd)) {
                // We thought the change was visible, but it isn't.
                // This can happen if the ACL changes during the
                // completeChangeSet computation, for example.
                visible = false;
            }
            Collection<RevCommit> toWalk = visible ? visibleCommits : nonVisibleCommits;
            // Pick a revision to use for traversal.  If any of the patch sets
            // is visible, we use the most recent one.  Otherwise, use the current
            // patch set.
            PatchSet ps = cd.currentPatchSet();
            boolean visiblePatchSet = visible;
            if (!cd.changeControl().isPatchVisible(ps, cd)) {
                Iterable<PatchSet> visiblePatchSets = cd.visiblePatchSets();
                if (Iterables.isEmpty(visiblePatchSets)) {
                    visiblePatchSet = false;
                } else {
                    ps = Iterables.getLast(visiblePatchSets);
                }
            }
            if (submitType(cd, ps, visiblePatchSet) == SubmitType.CHERRY_PICK) {
                if (visible) {
                    visibleChanges.add(cd);
                } else {
                    nonVisibleChanges.add(cd);
                }
                continue;
            }
            // Get the underlying git commit object
            String objIdStr = ps.getRevision().get();
            RevCommit commit = or.rw.parseCommit(ObjectId.fromString(objIdStr));
            // Always include the input, even if merged. This allows
            // SubmitStrategyOp to correct the situation later, assuming it gets
            // returned by byCommitsOnBranchNotMerged below.
            toWalk.add(commit);
        }
        Ref ref = or.repo.getRefDatabase().getRef(b.get());
        Optional<RevCommit> head = ref != null ? Optional.<RevCommit>of(or.rw.parseCommit(ref.getObjectId())) : Optional.<RevCommit>absent();
        Set<String> emptySet = Collections.emptySet();
        Set<String> visibleHashes = walkChangesByHashes(visibleCommits, emptySet, or, head);
        Iterable<ChangeData> cds = query().byCommitsOnBranchNotMerged(or.repo, db, b, visibleHashes);
        for (ChangeData chd : cds) {
            chd.changeControl(user);
            visibleChanges.add(chd);
        }
        Set<String> nonVisibleHashes = walkChangesByHashes(nonVisibleCommits, visibleHashes, or, head);
        Iterables.addAll(nonVisibleChanges, query().byCommitsOnBranchNotMerged(or.repo, db, b, nonVisibleHashes));
    }
    return new ChangeSet(visibleChanges, nonVisibleChanges);
}
#end_block

#method_before
private OpenRepo getRepo(Project.NameKey project) throws IOException {
    if (orm == null) {
        orm = repoManagerProvider.get();
    }
    try {
        OpenRepo or = orm.openRepo(project);
        checkState(or.rw.hasRevSort(RevSort.TOPO));
        return or;
    } catch (NoSuchProjectException e) {
        throw new IOException(e);
    }
}
#method_after
private OpenRepo getRepo(Project.NameKey project) throws IOException {
    if (orm == null) {
        orm = repoManagerProvider.get();
        closeOrm = true;
    }
    try {
        OpenRepo or = orm.openRepo(project);
        checkState(or.rw.hasRevSort(RevSort.TOPO));
        return or;
    } catch (NoSuchProjectException e) {
        throw new IOException(e);
    }
}
#end_block

#method_before
@Override
public ChangeDataSource getSource(Predicate<ChangeData> p, QueryOptions opts) throws QueryParseException {
    Set<Change.Status> statuses = IndexRewriter.getPossibleStatus(p);
    List<SubIndex> indexes = Lists.newArrayListWithCapacity(2);
    if (!Sets.intersection(statuses, OPEN_STATUSES).isEmpty()) {
        indexes.add(openIndex);
    }
    if (!Sets.intersection(statuses, CLOSED_STATUSES).isEmpty()) {
        indexes.add(closedIndex);
    }
    return new QuerySource(indexes, queryBuilder.toQuery(p), opts, getSort());
}
#method_after
@Override
public ChangeDataSource getSource(Predicate<ChangeData> p, QueryOptions opts) throws QueryParseException {
    Set<Change.Status> statuses = IndexRewriter.getPossibleStatus(p);
    List<SubIndex> indexes = Lists.newArrayListWithCapacity(2);
    if (!Sets.intersection(statuses, OPEN_STATUSES).isEmpty()) {
        indexes.add(openIndex);
    }
    if (!Sets.intersection(statuses, CLOSED_STATUSES).isEmpty()) {
        indexes.add(closedIndex);
    }
    return new QuerySource(indexes, p, opts, getSort());
}
#end_block

#method_before
@Override
public String toString() {
    return query.toString();
}
#method_after
@Override
public String toString() {
    return predicate.toString();
}
#end_block

#method_before
@Override
public ResultSet<ChangeData> read() throws OrmException {
    if (Thread.interrupted()) {
        Thread.currentThread().interrupt();
        throw new OrmException("interupted");
    }
    return new ChangeDataResults(executor.submit(new Callable<List<Document>>() {

        @Override
        public List<Document> call() throws OrmException {
            return doRead();
        }

        @Override
        public String toString() {
            return query.toString();
        }
    }));
}
#method_after
@Override
public ResultSet<ChangeData> read() throws OrmException {
    if (Thread.interrupted()) {
        Thread.currentThread().interrupt();
        throw new OrmException("interupted");
    }
    return new ChangeDataResults(executor.submit(new Callable<List<Document>>() {

        @Override
        public List<Document> call() throws OrmException {
            return doRead();
        }

        @Override
        public String toString() {
            return predicate.toString();
        }
    }));
}
#end_block

#method_before
@Test
@TestProjectInput(createEmptyCommit = false)
public void pushInitialCommitForMasterBranch() throws Exception {
    RevCommit c = testRepo.commit().message("Initial commit").insertChangeId().create();
    String id = GitUtil.getChangeId(testRepo, c).get();
    testRepo.reset(c);
    String r = "refs/for/master";
    PushResult pr = pushHead(testRepo, r, false);
    assertPushOk(pr, r);
    assertThat(gApi.changes().id(id).info().branch).isEqualTo("master");
    try (Repository repo = repoManager.openRepository(project)) {
        assertThat(repo.resolve("master")).isNull();
    }
}
#method_after
@Test
@TestProjectInput(createEmptyCommit = false)
public void pushInitialCommitForMasterBranch() throws Exception {
    RevCommit c = testRepo.commit().message("Initial commit").insertChangeId().create();
    String id = GitUtil.getChangeId(testRepo, c).get();
    testRepo.reset(c);
    String r = "refs/for/master";
    PushResult pr = pushHead(testRepo, r, false);
    assertPushOk(pr, r);
    ChangeInfo change = gApi.changes().id(id).info();
    assertThat(change.branch).isEqualTo("master");
    assertThat(change.status).isEqualTo(ChangeStatus.NEW);
    try (Repository repo = repoManager.openRepository(project)) {
        assertThat(repo.resolve("master")).isNull();
    }
}
#end_block

#method_before
public static void reloadChanges(ChangeSet cs) throws OrmException {
    // Clear exactly the fields requested by query() below.
    for (ChangeData cd : cs.changes()) {
        cd.reloadChange();
        cd.setPatchSets(null);
    }
}
#method_after
public static void reloadChanges(ChangeSet cs) throws OrmException {
    // Clear exactly the fields requested by query() below.
    for (ChangeData cd : cs.changes()) {
        cd.reloadChange();
        cd.setPatchSets(null);
        cd.setMergeable(null);
    }
}
#end_block

#method_before
private InternalChangeQuery query() {
    // Request fields required for completing the ChangeSet without having to
    // touch the database. This provides reasonable performance when loading the
    // change screen; callers that care about reading the latest value of these
    // fields should clear them explicitly using reloadChanges().
    Set<String> fields = ImmutableSet.of(ChangeField.CHANGE.getName(), ChangeField.PATCH_SET.getName(), ChangeField.MERGEABLE.getName());
    return queryProvider.get().setRequestedFields(fields);
}
#method_after
private InternalChangeQuery query() {
    // Request fields required for completing the ChangeSet and converting to
    // ChangeInfo without having to touch the database or opening the repository
    // more than necessary. This provides reasonable performance when loading
    // the change screen; callers that care about reading the latest value of
    // these fields should clear them explicitly using reloadChanges().
    Set<String> fields = ImmutableSet.of(ChangeField.CHANGE.getName(), ChangeField.PATCH_SET.getName(), ChangeField.MERGEABLE.getName());
    return queryProvider.get().setRequestedFields(fields);
}
#end_block

#method_before
public void send() throws EmailException {
    if (NotifyHandling.NONE.equals(notify)) {
        return;
    }
    if (!args.emailSender.isEnabled()) {
        // 
        return;
    }
    init();
    format();
    appendText(textTemplate("Footer"));
    if (useHtml()) {
        appendHtml(soyHtmlTemplate("FooterHtml"));
    }
    if (shouldSendMessage()) {
        if (fromId != null) {
            final Account fromUser = args.accountCache.get(fromId).getAccount();
            GeneralPreferencesInfo senderPrefs = fromUser.getGeneralPreferencesInfo();
            if (senderPrefs != null && senderPrefs.getEmailStrategy() == CC_ON_OWN_COMMENTS) {
                // If we are impersonating a user, make sure they receive a CC of
                // this message so they can always review and audit what we sent
                // on their behalf to others.
                // 
                add(RecipientType.CC, fromId);
            } else if (rcptTo.remove(fromId)) {
                // If they don't want a copy, but we queued one up anyway,
                // drop them from the recipient lists.
                // 
                removeUser(fromUser);
            }
            // his email notifications then drop him from recipients' list
            for (Account.Id id : rcptTo) {
                Account thisUser = args.accountCache.get(id).getAccount();
                GeneralPreferencesInfo prefs = thisUser.getGeneralPreferencesInfo();
                if (prefs == null || prefs.getEmailStrategy() == DISABLED) {
                    removeUser(thisUser);
                }
                if (smtpRcptTo.isEmpty()) {
                    return;
                }
            }
        }
        OutgoingEmailValidationListener.Args va = new OutgoingEmailValidationListener.Args();
        va.messageClass = messageClass;
        va.smtpFromAddress = smtpFromAddress;
        va.smtpRcptTo = smtpRcptTo;
        va.headers = headers;
        va.body = textBody.toString();
        va.htmlBody = htmlBody.toString();
        for (OutgoingEmailValidationListener validator : args.outgoingEmailValidationListeners) {
            try {
                validator.validateOutgoingEmail(va);
            } catch (ValidationException e) {
                return;
            }
        }
        args.emailSender.send(va.smtpFromAddress, va.smtpRcptTo, va.headers, va.body, useHtml() ? va.htmlBody : null);
    }
}
#method_after
public void send() throws EmailException {
    if (NotifyHandling.NONE.equals(notify)) {
        return;
    }
    if (!args.emailSender.isEnabled()) {
        // 
        return;
    }
    init();
    format();
    appendText(textTemplate("Footer"));
    if (useHtml()) {
        appendHtml(soyHtmlTemplate("FooterHtml"));
    }
    if (shouldSendMessage()) {
        if (fromId != null) {
            final Account fromUser = args.accountCache.get(fromId).getAccount();
            GeneralPreferencesInfo senderPrefs = fromUser.getGeneralPreferencesInfo();
            if (senderPrefs != null && senderPrefs.getEmailStrategy() == CC_ON_OWN_COMMENTS) {
                // If we are impersonating a user, make sure they receive a CC of
                // this message so they can always review and audit what we sent
                // on their behalf to others.
                // 
                add(RecipientType.CC, fromId);
            } else if (rcptTo.remove(fromId)) {
                // If they don't want a copy, but we queued one up anyway,
                // drop them from the recipient lists.
                // 
                removeUser(fromUser);
            }
            // his email notifications then drop him from recipients' list
            for (Account.Id id : rcptTo) {
                Account thisUser = args.accountCache.get(id).getAccount();
                GeneralPreferencesInfo prefs = thisUser.getGeneralPreferencesInfo();
                if (prefs == null || prefs.getEmailStrategy() == DISABLED) {
                    removeUser(thisUser);
                }
                if (smtpRcptTo.isEmpty()) {
                    return;
                }
            }
        }
        String textPart = textBody.toString();
        OutgoingEmailValidationListener.Args va = new OutgoingEmailValidationListener.Args();
        va.messageClass = messageClass;
        va.smtpFromAddress = smtpFromAddress;
        va.smtpRcptTo = smtpRcptTo;
        va.headers = headers;
        if (useHtml()) {
            String htmlPart = htmlBody.toString();
            String boundary = generateMultipartBoundary(textPart, htmlPart);
            va.body = buildMultipartBody(boundary, textPart, htmlPart);
            va.textBody = textPart;
            va.htmlBody = htmlPart;
            va.headers.put("Content-Type", new EmailHeader.String("multipart/alternative; " + "boundary=\"" + boundary + "\"; " + "charset=UTF-8"));
        } else {
            va.body = textPart;
            va.textBody = textPart;
        }
        for (OutgoingEmailValidationListener validator : args.outgoingEmailValidationListeners) {
            try {
                validator.validateOutgoingEmail(va);
            } catch (ValidationException e) {
                return;
            }
        }
        args.emailSender.send(va.smtpFromAddress, va.smtpRcptTo, va.headers, va.body);
    }
}
#end_block

#method_before
protected void appendHtml(final String html) {
    if (html != null) {
        htmlBody.append(html);
    }
}
#method_after
protected void appendHtml(String html) {
    if (html != null) {
        htmlBody.append(html);
    }
}
#end_block

#method_before
protected String soyTextTemplate(String name) {
    return args.soyTofu.newRenderer("com.google.gerrit.server.mail.template." + name).setContentKind(SanitizedContent.ContentKind.TEXT).setData(soyContext).render();
}
#method_after
protected String soyTextTemplate(String name) {
    return soyTemplate(name, SanitizedContent.ContentKind.TEXT);
}
#end_block

#method_before
protected String soyHtmlTemplate(String name) {
    return args.soyTofu.newRenderer("com.google.gerrit.server.mail.template." + name).setContentKind(SanitizedContent.ContentKind.HTML).setData(soyContext).render();
}
#method_after
protected String soyHtmlTemplate(String name) {
    return soyTemplate(name, SanitizedContent.ContentKind.HTML);
}
#end_block

#method_before
protected String textTemplate(String name) throws EmailException {
    String velocityName = name + ".vm";
    Path filePath = args.site.mail_dir.resolve(velocityName);
    if (Files.isRegularFile(filePath)) {
        return velocifyFile(velocityName);
    } else {
        return soyTextTemplate(name);
    }
}
#method_after
protected String textTemplate(String name) throws EmailException {
    String velocityName = name + ".vm";
    Path filePath = args.site.mail_dir.resolve(velocityName);
    if (Files.isRegularFile(filePath)) {
        return velocifyFile(velocityName);
    }
    return soyTextTemplate(name);
}
#end_block

#method_before
@Test
public void fastForward() throws Exception {
    for (TagType tagType : TagType.values()) {
        allowTagCreation(tagType);
        String tagName = pushTagForExistingCommit(tagType, Status.OK);
        fastForwardTagToExistingCommit(tagType, tagName, Status.REJECTED_OTHER_REASON);
        fastForwardTagToNewCommit(tagType, tagName, Status.REJECTED_OTHER_REASON);
        allowPushOnRefsTags();
        if (TagType.ANNOTATED.equals(tagType)) {
            fastForwardTagToExistingCommit(tagType, tagName, Status.REJECTED_OTHER_REASON);
            fastForwardTagToNewCommit(tagType, tagName, Status.REJECTED_OTHER_REASON);
        } else {
            fastForwardTagToExistingCommit(tagType, tagName, Status.OK);
            fastForwardTagToNewCommit(tagType, tagName, Status.OK);
        }
        allowForcePushOnRefsTags();
        fastForwardTagToExistingCommit(tagType, tagName, Status.OK);
        fastForwardTagToNewCommit(tagType, tagName, Status.OK);
        removePushFromRefsTags();
    }
}
#method_after
@Test
public void fastForward() throws Exception {
    for (TagType tagType : TagType.values()) {
        allowTagCreation(tagType);
        String tagName = pushTagForExistingCommit(tagType, Status.OK);
        fastForwardTagToExistingCommit(tagType, tagName, Status.REJECTED_OTHER_REASON);
        fastForwardTagToNewCommit(tagType, tagName, Status.REJECTED_OTHER_REASON);
        allowTagDeletion();
        fastForwardTagToExistingCommit(tagType, tagName, Status.REJECTED_OTHER_REASON);
        fastForwardTagToNewCommit(tagType, tagName, Status.REJECTED_OTHER_REASON);
        allowPushOnRefsTags();
        Status expectedStatus = tagType == ANNOTATED ? Status.REJECTED_OTHER_REASON : Status.OK;
        fastForwardTagToExistingCommit(tagType, tagName, expectedStatus);
        fastForwardTagToNewCommit(tagType, tagName, expectedStatus);
        allowForcePushOnRefsTags();
        fastForwardTagToExistingCommit(tagType, tagName, Status.OK);
        fastForwardTagToNewCommit(tagType, tagName, Status.OK);
        removePushFromRefsTags();
    }
}
#end_block

#method_before
@Test
public void forceUpdate() throws Exception {
    for (TagType tagType : TagType.values()) {
        allowTagCreation(tagType);
        String tagName = pushTagForExistingCommit(tagType, Status.OK);
        forceUpdateTagToExistingCommit(tagType, tagName, Status.REJECTED_OTHER_REASON);
        forceUpdateTagToNewCommit(tagType, tagName, Status.REJECTED_OTHER_REASON);
        allowPushOnRefsTags();
        forceUpdateTagToExistingCommit(tagType, tagName, Status.REJECTED_OTHER_REASON);
        forceUpdateTagToNewCommit(tagType, tagName, Status.REJECTED_OTHER_REASON);
        allowForcePushOnRefsTags();
        forceUpdateTagToExistingCommit(tagType, tagName, Status.OK);
        forceUpdateTagToNewCommit(tagType, tagName, Status.OK);
        removePushFromRefsTags();
    }
}
#method_after
@Test
public void forceUpdate() throws Exception {
    for (TagType tagType : TagType.values()) {
        allowTagCreation(tagType);
        String tagName = pushTagForExistingCommit(tagType, Status.OK);
        forceUpdateTagToExistingCommit(tagType, tagName, Status.REJECTED_OTHER_REASON);
        forceUpdateTagToNewCommit(tagType, tagName, Status.REJECTED_OTHER_REASON);
        allowPushOnRefsTags();
        forceUpdateTagToExistingCommit(tagType, tagName, Status.REJECTED_OTHER_REASON);
        forceUpdateTagToNewCommit(tagType, tagName, Status.REJECTED_OTHER_REASON);
        allowTagDeletion();
        forceUpdateTagToExistingCommit(tagType, tagName, Status.REJECTED_OTHER_REASON);
        forceUpdateTagToNewCommit(tagType, tagName, Status.REJECTED_OTHER_REASON);
        allowForcePushOnRefsTags();
        forceUpdateTagToExistingCommit(tagType, tagName, Status.OK);
        forceUpdateTagToNewCommit(tagType, tagName, Status.OK);
        removePushFromRefsTags();
    }
}
#end_block

#method_before
@Test
public void delete() throws Exception {
    for (TagType tagType : TagType.values()) {
        allowTagCreation(tagType);
        String tagName = pushTagForExistingCommit(tagType, Status.OK);
        pushTagDeletion(tagType, tagName, Status.REJECTED_OTHER_REASON);
        allowPushOnRefsTags();
        pushTagDeletion(tagType, tagName, Status.REJECTED_OTHER_REASON);
    }
    allowForcePushOnRefsTags();
    for (TagType tagType : TagType.values()) {
        String tagName = pushTagForExistingCommit(tagType, Status.OK);
        pushTagDeletion(tagType, tagName, Status.OK);
    }
}
#method_after
@Test
public void delete() throws Exception {
    for (TagType tagType : TagType.values()) {
        allowTagCreation(tagType);
        String tagName = pushTagForExistingCommit(tagType, Status.OK);
        pushTagDeletion(tagType, tagName, Status.REJECTED_OTHER_REASON);
        allowPushOnRefsTags();
        pushTagDeletion(tagType, tagName, Status.REJECTED_OTHER_REASON);
    }
    allowForcePushOnRefsTags();
    for (TagType tagType : TagType.values()) {
        String tagName = pushTagForExistingCommit(tagType, Status.OK);
        pushTagDeletion(tagType, tagName, Status.OK);
    }
    removePushFromRefsTags();
    allowTagDeletion();
    for (TagType tagType : TagType.values()) {
        String tagName = pushTagForExistingCommit(tagType, Status.OK);
        pushTagDeletion(tagType, tagName, Status.OK);
    }
}
#end_block

#method_before
private String pushTag(TagType tagType, String tagName, boolean newCommit, boolean force, Status expectedStatus) throws Exception {
    if (force) {
        testRepo.reset(initialHead);
    }
    commit(user.getIdent(), "subject");
    boolean createTag = tagName == null;
    tagName = MoreObjects.firstNonNull(tagName, "v1" + "_" + System.nanoTime());
    switch(tagType) {
        case LIGHTWEIGHT:
            break;
        case ANNOTATED:
            if (createTag) {
                createAnnotatedTag(testRepo, tagName, user.getIdent());
            } else {
                updateAnnotatedTag(testRepo, tagName, user.getIdent());
            }
            break;
        default:
            throw new IllegalStateException("unexpected tag type: " + tagType);
    }
    if (!newCommit) {
        grant(Permission.SUBMIT, project, "refs/for/refs/heads/master", false, REGISTERED_USERS);
        pushHead(testRepo, "refs/for/master%submit");
    }
    String tagRef = tagRef(tagName);
    PushResult r = tagType == TagType.LIGHTWEIGHT ? pushHead(testRepo, tagRef, false, force) : GitUtil.pushTag(testRepo, tagName, !createTag);
    RemoteRefUpdate refUpdate = r.getRemoteUpdate(tagRef);
    assertThat(refUpdate.getStatus()).named(tagType.name()).isEqualTo(expectedStatus);
    return tagName;
}
#method_after
private String pushTag(TagType tagType, String tagName, boolean newCommit, boolean force, Status expectedStatus) throws Exception {
    if (force) {
        testRepo.reset(initialHead);
    }
    commit(user.getIdent(), "subject");
    boolean createTag = tagName == null;
    tagName = MoreObjects.firstNonNull(tagName, "v1" + "_" + System.nanoTime());
    switch(tagType) {
        case LIGHTWEIGHT:
            break;
        case ANNOTATED:
            if (createTag) {
                createAnnotatedTag(testRepo, tagName, user.getIdent());
            } else {
                updateAnnotatedTag(testRepo, tagName, user.getIdent());
            }
            break;
        default:
            throw new IllegalStateException("unexpected tag type: " + tagType);
    }
    if (!newCommit) {
        grant(Permission.SUBMIT, project, "refs/for/refs/heads/master", false, REGISTERED_USERS);
        pushHead(testRepo, "refs/for/master%submit");
    }
    String tagRef = tagRef(tagName);
    PushResult r = tagType == LIGHTWEIGHT ? pushHead(testRepo, tagRef, false, force) : GitUtil.pushTag(testRepo, tagName, !createTag);
    RemoteRefUpdate refUpdate = r.getRemoteUpdate(tagRef);
    assertThat(refUpdate.getStatus()).named(tagType.name()).isEqualTo(expectedStatus);
    return tagName;
}
#end_block

#method_before
public boolean isOwner() {
    return isDeclaredOwner() || user.getCapabilities().canAdministrateServer();
}
#method_after
public boolean isOwner() {
    return (isDeclaredOwner() && !controlForRef("refs/*").isBlocked(Permission.OWNER)) || user.getCapabilities().canAdministrateServer();
}
#end_block

#method_before
public Capable canPushToAtLeastOneRef() {
    if (!canPerformOnAnyRef(Permission.PUSH)) {
        String pName = state.getProject().getName();
        return new Capable("Upload denied for project '" + pName + "'");
    }
    if (state.isUseContributorAgreements()) {
        return verifyActiveContributorAgreement();
    }
    return Capable.OK;
}
#method_after
public Capable canPushToAtLeastOneRef() {
    if (!canPerformOnAnyRef(Permission.PUSH) && !canPerformOnAnyRef(Permission.CREATE_TAG)) {
        String pName = state.getProject().getName();
        return new Capable("Upload denied for project '" + pName + "'");
    }
    if (state.isUseContributorAgreements()) {
        return verifyActiveContributorAgreement();
    }
    return Capable.OK;
}
#end_block

#method_before
private void loadLabelSections(Config rc) {
    Map<String, String> lowerNames = Maps.newHashMapWithExpectedSize(2);
    labelSections = new LinkedHashMap<>();
    for (String name : rc.getSubsections(LABEL)) {
        String lower = name.toLowerCase();
        if (lowerNames.containsKey(lower)) {
            error(new ValidationError(PROJECT_CONFIG, String.format("Label \"%s\" conflicts with \"%s\"", name, lowerNames.get(lower))));
        }
        lowerNames.put(lower, name);
        List<LabelValue> values = new ArrayList<>();
        for (String value : rc.getStringList(LABEL, name, KEY_VALUE)) {
            try {
                values.add(parseLabelValue(value));
            } catch (IllegalArgumentException notValue) {
                error(new ValidationError(PROJECT_CONFIG, String.format("Invalid %s \"%s\" for label \"%s\": %s", KEY_VALUE, value, name, notValue.getMessage())));
            }
        }
        LabelType label;
        try {
            label = new LabelType(name, values);
        } catch (IllegalArgumentException badName) {
            error(new ValidationError(PROJECT_CONFIG, String.format("Invalid label \"%s\"", name)));
            continue;
        }
        String functionName = MoreObjects.firstNonNull(rc.getString(LABEL, name, KEY_FUNCTION), "MaxWithBlock");
        if (LABEL_FUNCTIONS.contains(functionName)) {
            label.setFunctionName(functionName);
        } else {
            error(new ValidationError(PROJECT_CONFIG, String.format("Invalid %s for label \"%s\". Valid names are: %s", KEY_FUNCTION, name, Joiner.on(", ").join(LABEL_FUNCTIONS))));
            label.setFunctionName(null);
        }
        if (!values.isEmpty()) {
            short dv = (short) rc.getInt(LABEL, name, KEY_DEFAULT_VALUE, 0);
            if (isInRange(dv, values)) {
                label.setDefaultValue(dv);
            } else {
                error(new ValidationError(PROJECT_CONFIG, String.format("Invalid %s \"%s\" for label \"%s\"", KEY_DEFAULT_VALUE, dv, name)));
            }
        }
        label.setCopyMinScore(rc.getBoolean(LABEL, name, KEY_COPY_MIN_SCORE, LabelType.DEF_COPY_MIN_SCORE));
        label.setCopyMaxScore(rc.getBoolean(LABEL, name, KEY_COPY_MAX_SCORE, LabelType.DEF_COPY_MAX_SCORE));
        label.setCopyAllScoresOnMergeFirstParentUpdate(rc.getBoolean(LABEL, name, KEY_COPY_ALL_SCORES_ON_MERGE_FIRST_PARENT_UPDATE, LabelType.DEF_COPY_ALL_SCORES_ON_MERGE_FIRST_PARENT_UPDATE));
        label.setCopyAllScoresOnTrivialRebase(rc.getBoolean(LABEL, name, KEY_COPY_ALL_SCORES_ON_TRIVIAL_REBASE, LabelType.DEF_COPY_ALL_SCORES_ON_TRIVIAL_REBASE));
        label.setCopyAllScoresIfNoCodeChange(rc.getBoolean(LABEL, name, KEY_COPY_ALL_SCORES_IF_NO_CODE_CHANGE, LabelType.DEF_COPY_ALL_SCORES_IF_NO_CODE_CHANGE));
        label.setCopyAllScoresIfNoChange(rc.getBoolean(LABEL, name, KEY_COPY_ALL_SCORES_IF_NO_CHANGE, LabelType.DEF_COPY_ALL_SCORES_IF_NO_CHANGE));
        label.setCanOverride(rc.getBoolean(LABEL, name, KEY_CAN_OVERRIDE, LabelType.DEF_CAN_OVERRIDE));
        label.setRefPatterns(getStringListOrNull(rc, LABEL, name, KEY_Branch));
        labelSections.put(name, label);
    }
}
#method_after
private void loadLabelSections(Config rc) {
    Map<String, String> lowerNames = Maps.newHashMapWithExpectedSize(2);
    labelSections = new LinkedHashMap<>();
    for (String name : rc.getSubsections(LABEL)) {
        String lower = name.toLowerCase();
        if (lowerNames.containsKey(lower)) {
            error(new ValidationError(PROJECT_CONFIG, String.format("Label \"%s\" conflicts with \"%s\"", name, lowerNames.get(lower))));
        }
        lowerNames.put(lower, name);
        List<LabelValue> values = new ArrayList<>();
        for (String value : rc.getStringList(LABEL, name, KEY_VALUE)) {
            try {
                values.add(parseLabelValue(value));
            } catch (IllegalArgumentException notValue) {
                error(new ValidationError(PROJECT_CONFIG, String.format("Invalid %s \"%s\" for label \"%s\": %s", KEY_VALUE, value, name, notValue.getMessage())));
            }
        }
        LabelType label;
        try {
            label = new LabelType(name, values);
        } catch (IllegalArgumentException badName) {
            error(new ValidationError(PROJECT_CONFIG, String.format("Invalid label \"%s\"", name)));
            continue;
        }
        String functionName = MoreObjects.firstNonNull(rc.getString(LABEL, name, KEY_FUNCTION), "MaxWithBlock");
        if (LABEL_FUNCTIONS.contains(functionName)) {
            label.setFunctionName(functionName);
        } else {
            error(new ValidationError(PROJECT_CONFIG, String.format("Invalid %s for label \"%s\". Valid names are: %s", KEY_FUNCTION, name, Joiner.on(", ").join(LABEL_FUNCTIONS))));
            label.setFunctionName(null);
        }
        if (!values.isEmpty()) {
            short dv = (short) rc.getInt(LABEL, name, KEY_DEFAULT_VALUE, 0);
            if (isInRange(dv, values)) {
                label.setDefaultValue(dv);
            } else {
                error(new ValidationError(PROJECT_CONFIG, String.format("Invalid %s \"%s\" for label \"%s\"", KEY_DEFAULT_VALUE, dv, name)));
            }
        }
        label.setCopyMinScore(rc.getBoolean(LABEL, name, KEY_COPY_MIN_SCORE, LabelType.DEF_COPY_MIN_SCORE));
        label.setCopyMaxScore(rc.getBoolean(LABEL, name, KEY_COPY_MAX_SCORE, LabelType.DEF_COPY_MAX_SCORE));
        label.setCopyAllScoresOnMergeFirstParentUpdate(rc.getBoolean(LABEL, name, KEY_COPY_ALL_SCORES_ON_MERGE_FIRST_PARENT_UPDATE, LabelType.DEF_COPY_ALL_SCORES_ON_MERGE_FIRST_PARENT_UPDATE));
        label.setCopyAllScoresOnTrivialRebase(rc.getBoolean(LABEL, name, KEY_COPY_ALL_SCORES_ON_TRIVIAL_REBASE, LabelType.DEF_COPY_ALL_SCORES_ON_TRIVIAL_REBASE));
        label.setCopyAllScoresIfNoCodeChange(rc.getBoolean(LABEL, name, KEY_COPY_ALL_SCORES_IF_NO_CODE_CHANGE, LabelType.DEF_COPY_ALL_SCORES_IF_NO_CODE_CHANGE));
        label.setCopyAllScoresIfNoChange(rc.getBoolean(LABEL, name, KEY_COPY_ALL_SCORES_IF_NO_CHANGE, LabelType.DEF_COPY_ALL_SCORES_IF_NO_CHANGE));
        label.setCanOverride(rc.getBoolean(LABEL, name, KEY_CAN_OVERRIDE, LabelType.DEF_CAN_OVERRIDE));
        label.setRefPatterns(getStringListOrNull(rc, LABEL, name, KEY_BRANCH));
        labelSections.put(name, label);
    }
}
#end_block

#method_before
public boolean hasLegacyPermissions() {
    return hasLagacyPermissions;
}
#method_after
public boolean hasLegacyPermissions() {
    return hasLegacyPermissions;
}
#end_block

#method_before
private String convertLegacyPermission(String permissionName) {
    switch(permissionName) {
        case LEGACY_PERMISSION_PUSH_TAG:
            hasLagacyPermissions = true;
            return Permission.CREATE_TAG;
        case LEGACY_PERMISSION_PUSH_SIGNED_TAG:
            hasLagacyPermissions = true;
            return Permission.CREATE_SIGNED_TAG;
        default:
            return permissionName;
    }
}
#method_after
private String convertLegacyPermission(String permissionName) {
    switch(permissionName) {
        case LEGACY_PERMISSION_PUSH_TAG:
            hasLegacyPermissions = true;
            return Permission.CREATE_TAG;
        case LEGACY_PERMISSION_PUSH_SIGNED_TAG:
            hasLegacyPermissions = true;
            return Permission.CREATE_SIGNED_TAG;
        default:
            return permissionName;
    }
}
#end_block

#method_before
private void initAllProjects(Repository git) throws IOException, ConfigInvalidException {
    try (MetaDataUpdate md = new MetaDataUpdate(GitReferenceUpdated.DISABLED, allProjectsName, git)) {
        md.getCommitBuilder().setAuthor(serverUser);
        md.getCommitBuilder().setCommitter(serverUser);
        md.setMessage(MoreObjects.firstNonNull(Strings.emptyToNull(message), "Initialized Gerrit Code Review " + Version.getVersion()));
        ProjectConfig config = ProjectConfig.read(md);
        Project p = config.getProject();
        p.setDescription("Access inherited by all other projects.");
        p.setRequireChangeID(InheritableBoolean.TRUE);
        p.setUseContentMerge(InheritableBoolean.TRUE);
        p.setUseContributorAgreements(InheritableBoolean.FALSE);
        p.setUseSignedOffBy(InheritableBoolean.FALSE);
        p.setEnableSignedPush(InheritableBoolean.FALSE);
        AccessSection cap = config.getAccessSection(AccessSection.GLOBAL_CAPABILITIES, true);
        AccessSection all = config.getAccessSection(AccessSection.ALL, true);
        AccessSection heads = config.getAccessSection(AccessSection.HEADS, true);
        AccessSection tags = config.getAccessSection("refs/tags/*", true);
        AccessSection meta = config.getAccessSection(RefNames.REFS_CONFIG, true);
        AccessSection refsFor = config.getAccessSection("refs/for/*", true);
        AccessSection magic = config.getAccessSection("refs/for/" + AccessSection.ALL, true);
        grant(config, cap, GlobalCapability.ADMINISTRATE_SERVER, admin);
        grant(config, all, Permission.READ, admin, anonymous);
        grant(config, refsFor, Permission.ADD_PATCH_SET, registered);
        if (batch != null) {
            Permission priority = cap.getPermission(GlobalCapability.PRIORITY, true);
            PermissionRule r = rule(config, batch);
            r.setAction(Action.BATCH);
            priority.add(r);
            Permission stream = cap.getPermission(GlobalCapability.STREAM_EVENTS, true);
            stream.add(rule(config, batch));
        }
        LabelType cr = initCodeReviewLabel(config);
        grant(config, heads, cr, -1, 1, registered);
        grant(config, heads, cr, -2, 2, admin, owners);
        grant(config, heads, Permission.CREATE, admin, owners);
        grant(config, heads, Permission.PUSH, admin, owners);
        grant(config, heads, Permission.SUBMIT, admin, owners);
        grant(config, heads, Permission.FORGE_AUTHOR, registered);
        grant(config, heads, Permission.FORGE_COMMITTER, admin, owners);
        grant(config, heads, Permission.EDIT_TOPIC_NAME, true, admin, owners);
        grant(config, tags, Permission.CREATE_TAG, admin, owners);
        grant(config, tags, Permission.CREATE_SIGNED_TAG, admin, owners);
        grant(config, magic, Permission.PUSH, registered);
        grant(config, magic, Permission.PUSH_MERGE, registered);
        meta.getPermission(Permission.READ, true).setExclusiveGroup(true);
        grant(config, meta, Permission.READ, admin, owners);
        grant(config, meta, cr, -2, 2, admin, owners);
        grant(config, meta, Permission.PUSH, admin, owners);
        grant(config, meta, Permission.SUBMIT, admin, owners);
        config.commitToNewRef(md, RefNames.REFS_CONFIG);
    }
}
#method_after
private void initAllProjects(Repository git) throws IOException, ConfigInvalidException {
    try (MetaDataUpdate md = new MetaDataUpdate(GitReferenceUpdated.DISABLED, allProjectsName, git)) {
        md.getCommitBuilder().setAuthor(serverUser);
        md.getCommitBuilder().setCommitter(serverUser);
        md.setMessage(MoreObjects.firstNonNull(Strings.emptyToNull(message), "Initialized Gerrit Code Review " + Version.getVersion()));
        ProjectConfig config = ProjectConfig.read(md);
        Project p = config.getProject();
        p.setDescription("Access inherited by all other projects.");
        p.setRequireChangeID(InheritableBoolean.TRUE);
        p.setUseContentMerge(InheritableBoolean.TRUE);
        p.setUseContributorAgreements(InheritableBoolean.FALSE);
        p.setUseSignedOffBy(InheritableBoolean.FALSE);
        p.setEnableSignedPush(InheritableBoolean.FALSE);
        AccessSection cap = config.getAccessSection(AccessSection.GLOBAL_CAPABILITIES, true);
        AccessSection all = config.getAccessSection(AccessSection.ALL, true);
        AccessSection heads = config.getAccessSection(AccessSection.HEADS, true);
        AccessSection tags = config.getAccessSection("refs/tags/*", true);
        AccessSection meta = config.getAccessSection(RefNames.REFS_CONFIG, true);
        AccessSection refsFor = config.getAccessSection("refs/for/*", true);
        AccessSection magic = config.getAccessSection("refs/for/" + AccessSection.ALL, true);
        grant(config, cap, GlobalCapability.ADMINISTRATE_SERVER, admin);
        grant(config, all, Permission.READ, admin, anonymous);
        grant(config, refsFor, Permission.ADD_PATCH_SET, registered);
        if (batch != null) {
            Permission priority = cap.getPermission(GlobalCapability.PRIORITY, true);
            PermissionRule r = rule(config, batch);
            r.setAction(Action.BATCH);
            priority.add(r);
            Permission stream = cap.getPermission(GlobalCapability.STREAM_EVENTS, true);
            stream.add(rule(config, batch));
        }
        LabelType cr = initCodeReviewLabel(config);
        grant(config, heads, cr, -1, 1, registered);
        grant(config, heads, cr, -2, 2, admin, owners);
        grant(config, heads, Permission.CREATE, admin, owners);
        grant(config, heads, Permission.PUSH, admin, owners);
        grant(config, heads, Permission.SUBMIT, admin, owners);
        grant(config, heads, Permission.FORGE_AUTHOR, registered);
        grant(config, heads, Permission.FORGE_COMMITTER, admin, owners);
        grant(config, heads, Permission.EDIT_TOPIC_NAME, true, admin, owners);
        grant(config, tags, Permission.CREATE, admin, owners);
        grant(config, tags, Permission.CREATE_TAG, admin, owners);
        grant(config, tags, Permission.CREATE_SIGNED_TAG, admin, owners);
        grant(config, magic, Permission.PUSH, registered);
        grant(config, magic, Permission.PUSH_MERGE, registered);
        meta.getPermission(Permission.READ, true).setExclusiveGroup(true);
        grant(config, meta, Permission.READ, admin, owners);
        grant(config, meta, cr, -2, 2, admin, owners);
        grant(config, meta, Permission.PUSH, admin, owners);
        grant(config, meta, Permission.SUBMIT, admin, owners);
        config.commitToNewRef(md, RefNames.REFS_CONFIG);
    }
}
#end_block

#method_before
@Override
protected void migrateData(ReviewDb db, UpdateUI ui) throws OrmException {
    for (Project.NameKey projectName : repoManager.list()) {
        try (Repository git = repoManager.openRepository(projectName);
            MetaDataUpdate md = new MetaDataUpdate(GitReferenceUpdated.DISABLED, projectName, git)) {
            ProjectConfig config = ProjectConfig.read(md);
            boolean update = false;
            for (AccessSection accessSection : config.getAccessSections()) {
                Permission pushTagPermission = accessSection.getPermission("pushTag");
                if (pushTagPermission == null) {
                    continue;
                }
                for (PermissionRule rule : pushTagPermission.getRules()) {
                    if (rule.getForce()) {
                        rule.setForce(false);
                        update = true;
                    }
                }
            }
            if (!update) {
                continue;
            }
            md.getCommitBuilder().setAuthor(serverUser);
            md.getCommitBuilder().setCommitter(serverUser);
            md.setMessage(COMMIT_MSG);
            config.commit(md);
        } catch (ConfigInvalidException | IOException ex) {
            throw new OrmException(ex);
        }
    }
}
#method_after
@Override
protected void migrateData(ReviewDb db, UpdateUI ui) throws OrmException {
    for (Project.NameKey projectName : repoManager.list()) {
        try (Repository git = repoManager.openRepository(projectName);
            MetaDataUpdate md = new MetaDataUpdate(GitReferenceUpdated.DISABLED, projectName, git)) {
            ProjectConfigSchemaUpdate cfg = ProjectConfigSchemaUpdate.read(md);
            cfg.removeForceFromPermission("pushTag");
            cfg.save(serverUser, COMMIT_MSG);
        } catch (ConfigInvalidException | IOException ex) {
            throw new OrmException(ex);
        }
    }
}
#end_block

#method_before
@Test
public void createTagNotAllowed() throws Exception {
    TagInput input = new TagInput();
    input.ref = "test";
    exception.expect(AuthException.class);
    exception.expectMessage("Cannot create tag \"" + R_TAGS + "test\"");
    tag(input.ref).create(input);
}
#method_after
@Test
public void createTagNotAllowed() throws Exception {
    block(Permission.CREATE, REGISTERED_USERS, R_TAGS + "*");
    TagInput input = new TagInput();
    input.ref = "test";
    exception.expect(AuthException.class);
    exception.expectMessage("Cannot create tag \"" + R_TAGS + "test\"");
    tag(input.ref).create(input);
}
#end_block

#method_before
public boolean canForceUpdate() {
    return (canPushWithForce() || canDelete()) && canWrite();
}
#method_after
public boolean canForceUpdate() {
    if (!canWrite()) {
        return false;
    }
    if (canPushWithForce()) {
        return true;
    }
    switch(getUser().getAccessPath()) {
        case GIT:
            return false;
        case JSON_RPC:
        case REST_API:
        case SSH_COMMAND:
        case UNKNOWN:
        case WEB_BROWSER:
        default:
            return getUser().getCapabilities().canAdministrateServer() || (isOwner() && !isForceBlocked(Permission.PUSH));
    }
}
#end_block

#method_before
public boolean canCreate(ReviewDb db, Repository repo, RevObject object) {
    if (!canWrite()) {
        return false;
    }
    boolean owner;
    boolean admin;
    switch(getUser().getAccessPath()) {
        case REST_API:
        case JSON_RPC:
        case UNKNOWN:
            owner = isOwner();
            admin = getUser().getCapabilities().canAdministrateServer();
            break;
        case GIT:
        case SSH_COMMAND:
        case WEB_BROWSER:
        default:
            owner = false;
            admin = false;
    }
    if (object instanceof RevCommit) {
        if (admin || (owner && !isBlocked(Permission.CREATE))) {
            // Admin or project owner; bypass visibility check.
            return true;
        } else if (!canPerform(Permission.CREATE)) {
            // No create permissions.
            return false;
        }
        return canCreateCommit(db, repo, (RevCommit) object, admin, owner);
    } else if (object instanceof RevTag) {
        final RevTag tag = (RevTag) object;
        try (RevWalk rw = new RevWalk(repo)) {
            rw.parseBody(tag);
        } catch (IOException e) {
            return false;
        }
        // If tagger is present, require it matches the user's email.
        // 
        final PersonIdent tagger = tag.getTaggerIdent();
        if (tagger != null) {
            boolean valid;
            if (getUser().isIdentifiedUser()) {
                final String addr = tagger.getEmailAddress();
                valid = getUser().asIdentifiedUser().hasEmailAddress(addr);
            } else {
                valid = false;
            }
            if (!valid && !owner && !canForgeCommitter()) {
                return false;
            }
        }
        RevObject tagObject = tag.getObject();
        if (tagObject instanceof RevCommit) {
            if (!canCreateCommit(db, repo, (RevCommit) tagObject, admin, owner)) {
                return false;
            }
        } else {
            if (!canCreate(db, repo, tagObject)) {
                return false;
            }
        }
        // 
        if (tag.getFullMessage().contains("-----BEGIN PGP SIGNATURE-----\n")) {
            return owner || canPerform(Permission.CREATE_SIGNED_TAG);
        }
        return owner || canPerform(Permission.CREATE_TAG);
    } else {
        return false;
    }
}
#method_after
public boolean canCreate(ReviewDb db, Repository repo, RevObject object) {
    if (!canWrite()) {
        return false;
    }
    if (object instanceof RevCommit) {
        if (!canPerform(Permission.CREATE)) {
            // No create permissions.
            return false;
        }
        return canCreateCommit(db, repo, (RevCommit) object);
    } else if (object instanceof RevTag) {
        final RevTag tag = (RevTag) object;
        try (RevWalk rw = new RevWalk(repo)) {
            rw.parseBody(tag);
        } catch (IOException e) {
            return false;
        }
        // If tagger is present, require it matches the user's email.
        // 
        final PersonIdent tagger = tag.getTaggerIdent();
        if (tagger != null) {
            boolean valid;
            if (getUser().isIdentifiedUser()) {
                final String addr = tagger.getEmailAddress();
                valid = getUser().asIdentifiedUser().hasEmailAddress(addr);
            } else {
                valid = false;
            }
            if (!valid && !canForgeCommitter()) {
                return false;
            }
        }
        RevObject tagObject = tag.getObject();
        if (tagObject instanceof RevCommit) {
            if (!canCreateCommit(db, repo, (RevCommit) tagObject)) {
                return false;
            }
        } else {
            if (!canCreate(db, repo, tagObject)) {
                return false;
            }
        }
        // 
        if (tag.getFullMessage().contains("-----BEGIN PGP SIGNATURE-----\n")) {
            return canPerform(Permission.CREATE_SIGNED_TAG);
        }
        return canPerform(Permission.CREATE_TAG);
    } else {
        return false;
    }
}
#end_block

#method_before
private boolean canCreateCommit(ReviewDb db, Repository repo, RevCommit commit, boolean admin, boolean owner) {
    if (admin || (owner && !isBlocked(Permission.CREATE))) {
        // Admin or project owner; bypass visibility check.
        return true;
    } else if (canUpdate()) {
        // of whether they are pushing any new objects along with the create.
        return true;
    } else if (isMergedIntoBranchOrTag(db, repo, commit)) {
        // even if they don't have push permission.
        return true;
    }
    return false;
}
#method_after
private boolean canCreateCommit(ReviewDb db, Repository repo, RevCommit commit) {
    if (canUpdate()) {
        // of whether they are pushing any new objects along with the create.
        return true;
    } else if (isMergedIntoBranchOrTag(db, repo, commit)) {
        // even if they don't have push permission.
        return true;
    }
    return false;
}
#end_block

#method_before
public boolean canDelete() {
    if (!canWrite() || (RefNames.REFS_CONFIG.equals(refName))) {
        // should be removed first.
        return false;
    }
    switch(getUser().getAccessPath()) {
        case GIT:
            return canPushWithForce();
        case JSON_RPC:
        case REST_API:
        case SSH_COMMAND:
        case UNKNOWN:
        case WEB_BROWSER:
        default:
            return getUser().getCapabilities().canAdministrateServer() || (isOwner() && !isForceBlocked(Permission.PUSH)) || canPushWithForce();
    }
}
#method_after
public boolean canDelete() {
    if (!canWrite() || (RefNames.REFS_CONFIG.equals(refName))) {
        // should be removed first.
        return false;
    }
    switch(getUser().getAccessPath()) {
        case GIT:
            return canPushWithForce() || canPerform(Permission.DELETE);
        case JSON_RPC:
        case REST_API:
        case SSH_COMMAND:
        case UNKNOWN:
        case WEB_BROWSER:
        default:
            return getUser().getCapabilities().canAdministrateServer() || (isOwner() && !isForceBlocked(Permission.PUSH)) || canPushWithForce() || canPerform(Permission.DELETE);
    }
}
#end_block

#method_before
protected void enableChangeIndexWrites() {
    for (ChangeIndex i : changeIndexes.getWriteIndexes()) {
        if (i instanceof ReadOnlyChangeIndex)
            changeIndexes.addWriteIndex(((ReadOnlyChangeIndex) i).unwrap());
    }
}
#method_after
protected void enableChangeIndexWrites() {
    for (ChangeIndex i : changeIndexes.getWriteIndexes()) {
        if (i instanceof ReadOnlyChangeIndex) {
            changeIndexes.addWriteIndex(((ReadOnlyChangeIndex) i).unwrap());
        }
    }
}
#end_block

#method_before
@Test
public void fastForward() throws Exception {
    for (TagType tagType : TagType.values()) {
        allowTagCreation(tagType);
        String tagName = pushTagForExistingCommit(tagType, Status.OK);
        fastForwardTagToExistingCommit(tagType, tagName, Status.REJECTED_OTHER_REASON);
        fastForwardTagToNewCommit(tagType, tagName, Status.REJECTED_OTHER_REASON);
        allowPushOnRefsTags();
        if (TagType.ANNOTATED.equals(tagType)) {
            fastForwardTagToExistingCommit(tagType, tagName, Status.REJECTED_OTHER_REASON);
            fastForwardTagToNewCommit(tagType, tagName, Status.REJECTED_OTHER_REASON);
        } else {
            fastForwardTagToExistingCommit(tagType, tagName, Status.OK);
            fastForwardTagToNewCommit(tagType, tagName, Status.OK);
        }
        allowForcePushOnRefsTags();
        fastForwardTagToExistingCommit(tagType, tagName, Status.OK);
        fastForwardTagToNewCommit(tagType, tagName, Status.OK);
        removePushFromRefsTags();
    }
}
#method_after
@Test
public void fastForward() throws Exception {
    for (TagType tagType : TagType.values()) {
        allowTagCreation(tagType);
        String tagName = pushTagForExistingCommit(tagType, Status.OK);
        fastForwardTagToExistingCommit(tagType, tagName, Status.REJECTED_OTHER_REASON);
        fastForwardTagToNewCommit(tagType, tagName, Status.REJECTED_OTHER_REASON);
        allowPushOnRefsTags();
        Status expectedStatus = tagType == ANNOTATED ? Status.REJECTED_OTHER_REASON : Status.OK;
        fastForwardTagToExistingCommit(tagType, tagName, expectedStatus);
        fastForwardTagToNewCommit(tagType, tagName, expectedStatus);
        allowForcePushOnRefsTags();
        fastForwardTagToExistingCommit(tagType, tagName, Status.OK);
        fastForwardTagToNewCommit(tagType, tagName, Status.OK);
        removePushFromRefsTags();
    }
}
#end_block

#method_before
private String pushTag(TagType tagType, String tagName, boolean newCommit, boolean force, Status expectedStatus) throws Exception {
    if (force) {
        testRepo.reset(initialHead);
    }
    commit(user.getIdent(), "subject");
    boolean createTag = tagName == null;
    tagName = MoreObjects.firstNonNull(tagName, "v1" + "_" + System.nanoTime());
    switch(tagType) {
        case LIGHTWEIGHT:
            break;
        case ANNOTATED:
            if (createTag) {
                createAnnotatedTag(testRepo, tagName, user.getIdent());
            } else {
                updateAnnotatedTag(testRepo, tagName, user.getIdent());
            }
            break;
        default:
            throw new IllegalStateException("unexpected tag type: " + tagType);
    }
    if (!newCommit) {
        grant(Permission.SUBMIT, project, "refs/for/refs/heads/master", false, REGISTERED_USERS);
        pushHead(testRepo, "refs/for/master%submit");
    }
    String tagRef = tagRef(tagName);
    PushResult r = tagType == TagType.LIGHTWEIGHT ? pushHead(testRepo, tagRef, false, force) : GitUtil.pushTag(testRepo, tagName, !createTag);
    RemoteRefUpdate refUpdate = r.getRemoteUpdate(tagRef);
    assertThat(refUpdate.getStatus()).named(tagType.name()).isEqualTo(expectedStatus);
    return tagName;
}
#method_after
private String pushTag(TagType tagType, String tagName, boolean newCommit, boolean force, Status expectedStatus) throws Exception {
    if (force) {
        testRepo.reset(initialHead);
    }
    commit(user.getIdent(), "subject");
    boolean createTag = tagName == null;
    tagName = MoreObjects.firstNonNull(tagName, "v1" + "_" + System.nanoTime());
    switch(tagType) {
        case LIGHTWEIGHT:
            break;
        case ANNOTATED:
            if (createTag) {
                createAnnotatedTag(testRepo, tagName, user.getIdent());
            } else {
                updateAnnotatedTag(testRepo, tagName, user.getIdent());
            }
            break;
        default:
            throw new IllegalStateException("unexpected tag type: " + tagType);
    }
    if (!newCommit) {
        grant(Permission.SUBMIT, project, "refs/for/refs/heads/master", false, REGISTERED_USERS);
        pushHead(testRepo, "refs/for/master%submit");
    }
    String tagRef = tagRef(tagName);
    PushResult r = tagType == LIGHTWEIGHT ? pushHead(testRepo, tagRef, false, force) : GitUtil.pushTag(testRepo, tagName, !createTag);
    RemoteRefUpdate refUpdate = r.getRemoteUpdate(tagRef);
    assertThat(refUpdate.getStatus()).named(tagType.name()).isEqualTo(expectedStatus);
    return tagName;
}
#end_block

#method_before
@Test
public void fastForward() throws Exception {
    for (TagType tagType : TagType.values()) {
        allowTagCreation(tagType);
        String tagName = pushTagForExistingCommit(tagType, Status.OK);
        fastForwardTagToExistingCommit(tagType, tagName, Status.REJECTED_OTHER_REASON);
        fastForwardTagToNewCommit(tagType, tagName, Status.REJECTED_OTHER_REASON);
        allowPushOnRefsTags();
        if (TagType.ANNOTATED.equals(tagType)) {
            fastForwardTagToExistingCommit(tagType, tagName, Status.REJECTED_OTHER_REASON);
            fastForwardTagToNewCommit(tagType, tagName, Status.REJECTED_OTHER_REASON);
        } else {
            fastForwardTagToExistingCommit(tagType, tagName, Status.OK);
            fastForwardTagToNewCommit(tagType, tagName, Status.OK);
        }
        allowForcePushOnRefsTags();
        fastForwardTagToExistingCommit(tagType, tagName, Status.OK);
        fastForwardTagToNewCommit(tagType, tagName, Status.OK);
        removePushFromRefsTags();
    }
}
#method_after
@Test
public void fastForward() throws Exception {
    for (TagType tagType : TagType.values()) {
        allowTagCreation(tagType);
        String tagName = pushTagForExistingCommit(tagType, Status.OK);
        fastForwardTagToExistingCommit(tagType, tagName, Status.REJECTED_OTHER_REASON);
        fastForwardTagToNewCommit(tagType, tagName, Status.REJECTED_OTHER_REASON);
        allowPushOnRefsTags();
        Status expectedStatus = tagType == ANNOTATED ? Status.REJECTED_OTHER_REASON : Status.OK;
        fastForwardTagToExistingCommit(tagType, tagName, expectedStatus);
        fastForwardTagToNewCommit(tagType, tagName, expectedStatus);
        allowForcePushOnRefsTags();
        fastForwardTagToExistingCommit(tagType, tagName, Status.OK);
        fastForwardTagToNewCommit(tagType, tagName, Status.OK);
        removePushFromRefsTags();
    }
}
#end_block

#method_before
private String pushTag(TagType tagType, String tagName, boolean newCommit, Status expectedStatus) throws Exception {
    commit(user.getIdent(), "subject");
    boolean createTag = tagName == null;
    tagName = MoreObjects.firstNonNull(tagName, "v1" + "_" + System.nanoTime());
    switch(tagType) {
        case LIGHTWEIGHT:
            break;
        case ANNOTATED:
            if (createTag) {
                createAnnotatedTag(testRepo, tagName, user.getIdent());
            } else {
                updateAnnotatedTag(testRepo, tagName, user.getIdent());
            }
            break;
        default:
            throw new IllegalStateException("unexpected tag type: " + tagType);
    }
    if (!newCommit) {
        grant(Permission.SUBMIT, project, "refs/for/refs/heads/master", false, REGISTERED_USERS);
        pushHead(testRepo, "refs/for/master%submit");
    }
    String tagRef = tagRef(tagName);
    PushResult r = tagType == TagType.LIGHTWEIGHT ? pushHead(testRepo, tagRef) : GitUtil.pushTag(testRepo, tagName, !createTag);
    RemoteRefUpdate refUpdate = r.getRemoteUpdate(tagRef);
    assertThat(refUpdate.getStatus()).named(tagType.name()).isEqualTo(expectedStatus);
    return tagName;
}
#method_after
private String pushTag(TagType tagType, String tagName, boolean newCommit, Status expectedStatus) throws Exception {
    commit(user.getIdent(), "subject");
    boolean createTag = tagName == null;
    tagName = MoreObjects.firstNonNull(tagName, "v1" + "_" + System.nanoTime());
    switch(tagType) {
        case LIGHTWEIGHT:
            break;
        case ANNOTATED:
            if (createTag) {
                createAnnotatedTag(testRepo, tagName, user.getIdent());
            } else {
                updateAnnotatedTag(testRepo, tagName, user.getIdent());
            }
            break;
        default:
            throw new IllegalStateException("unexpected tag type: " + tagType);
    }
    if (!newCommit) {
        grant(Permission.SUBMIT, project, "refs/for/refs/heads/master", false, REGISTERED_USERS);
        pushHead(testRepo, "refs/for/master%submit");
    }
    String tagRef = tagRef(tagName);
    PushResult r = tagType == LIGHTWEIGHT ? pushHead(testRepo, tagRef) : GitUtil.pushTag(testRepo, tagName, !createTag);
    RemoteRefUpdate refUpdate = r.getRemoteUpdate(tagRef);
    assertThat(refUpdate.getStatus()).named(tagType.name()).isEqualTo(expectedStatus);
    return tagName;
}
#end_block

#method_before
private void pushTag(TagType tagType, boolean newCommit, Status expectedStatus) throws Exception {
    commit(user.getIdent(), "subject");
    String tagName = "v1" + "_" + System.nanoTime();
    switch(tagType) {
        case LIGHTWEIGHT:
            break;
        case ANNOTATED:
            createAnnotatedTag(testRepo, tagName, user.getIdent());
            break;
        default:
            throw new IllegalStateException("unexpected tag type: " + tagType);
    }
    if (!newCommit) {
        grant(Permission.SUBMIT, project, "refs/for/refs/heads/master", false, REGISTERED_USERS);
        pushHead(testRepo, "refs/for/master%submit");
    }
    PushResult r = tagType == TagType.LIGHTWEIGHT ? pushHead(testRepo, "refs/tags/" + tagName) : GitUtil.pushTag(testRepo, tagName);
    RemoteRefUpdate refUpdate = r.getRemoteUpdate("refs/tags/" + tagName);
    assertThat(refUpdate.getStatus()).named(tagType.name()).isEqualTo(expectedStatus);
}
#method_after
private void pushTag(TagType tagType, boolean newCommit, Status expectedStatus) throws Exception {
    commit(user.getIdent(), "subject");
    String tagName = "v1" + "_" + System.nanoTime();
    switch(tagType) {
        case LIGHTWEIGHT:
            break;
        case ANNOTATED:
            createAnnotatedTag(testRepo, tagName, user.getIdent());
            break;
        default:
            throw new IllegalStateException("unexpected tag type: " + tagType);
    }
    if (!newCommit) {
        grant(Permission.SUBMIT, project, "refs/for/refs/heads/master", false, REGISTERED_USERS);
        pushHead(testRepo, "refs/for/master%submit");
    }
    PushResult r = tagType == LIGHTWEIGHT ? pushHead(testRepo, "refs/tags/" + tagName) : GitUtil.pushTag(testRepo, tagName);
    RemoteRefUpdate refUpdate = r.getRemoteUpdate("refs/tags/" + tagName);
    assertThat(refUpdate.getStatus()).named(tagType.name()).isEqualTo(expectedStatus);
}
#end_block

#method_before
public void abandonInactiveOpenChanges() {
    if (cfg.getAbandonAfter() <= 0) {
        return;
    }
    try {
        String query = "status:new age:" + TimeUnit.MILLISECONDS.toMinutes(cfg.getAbandonAfter()) + "m";
        if (!cfg.getAbandonIfMergeable()) {
            query += " -is:mergeable";
        }
        List<ChangeData> changesToAbandon = queryProcessor.enforceVisibility(false).queryChanges(queryBuilder.parse(query)).changes();
        int count = 0;
        for (ChangeData cd : changesToAbandon) {
            try {
                if (noNeedToAbandon(cd, query)) {
                    log.debug("Change data \"{}\" does not satisfy the query \"{}\" any" + " more, and hence skip it in clean up", cd, query);
                    continue;
                }
                abandon.abandon(changeControl(cd), cfg.getAbandonMessage(), null);
                count++;
            } catch (ResourceConflictException e) {
            // Change was already merged or abandoned.
            } catch (Throwable e) {
                log.error(String.format("Failed to auto-abandon inactive open change %d.", cd.getId().get()), e);
            }
        }
        log.info(String.format("Auto-Abandoned %d of %d changes.", count, changesToAbandon.size()));
    } catch (QueryParseException | OrmException e) {
        log.error("Failed to query inactive open changes for auto-abandoning.", e);
    }
}
#method_after
public void abandonInactiveOpenChanges() {
    if (cfg.getAbandonAfter() <= 0) {
        return;
    }
    try {
        String query = "status:new age:" + TimeUnit.MILLISECONDS.toMinutes(cfg.getAbandonAfter()) + "m";
        if (!cfg.getAbandonIfMergeable()) {
            query += " -is:mergeable";
        }
        List<ChangeData> changesToAbandon = queryProcessor.enforceVisibility(false).queryChanges(queryBuilder.parse(query)).changes();
        int count = 0;
        for (ChangeData cd : changesToAbandon) {
            try {
                if (noNeedToAbandon(cd, query)) {
                    log.debug("Change data \"{}\" does not satisfy the query \"{}\" any" + " more, hence skipping it in clean up", cd, query);
                    continue;
                }
                abandon.abandon(changeControl(cd), cfg.getAbandonMessage(), null);
                count++;
            } catch (ResourceConflictException e) {
            // Change was already merged or abandoned.
            } catch (Throwable e) {
                log.error(String.format("Failed to auto-abandon inactive open change %d.", cd.getId().get()), e);
            }
        }
        log.info(String.format("Auto-Abandoned %d of %d changes.", count, changesToAbandon.size()));
    } catch (QueryParseException | OrmException e) {
        log.error("Failed to query inactive open changes for auto-abandoning.", e);
    }
}
#end_block

#method_before
private void loadConfigInfo(final ChangeInfo info, String base) {
    final RevisionInfo rev = info.revision(revision);
    RevisionInfo b = resolveRevisionOrPatchSetId(info, base, null);
    CallbackGroup group = new CallbackGroup();
    Timestamp lastReply = myLastReply(info);
    if (rev.isEdit()) {
        // Comments are filtered for the current revision. Use parent
        // patch set for edits, as edits themself can never have comments.
        RevisionInfo p = RevisionInfo.findEditParentRevision(info.revisions().values());
        List<NativeMap<JsArray<CommentInfo>>> comments = loadComments(p, group);
        loadFileList(b, rev, lastReply, group, comments, null);
    } else {
        loadDiff(b, rev, lastReply, group);
    }
    group.addListener(new AsyncCallback<Void>() {

        @Override
        public void onSuccess(Void result) {
            loadConfigInfo(info, rev);
        }

        @Override
        public void onFailure(Throwable caught) {
            loadConfigInfo(info, rev);
        }
    });
    group.done();
}
#method_after
private void loadConfigInfo(final ChangeInfo info, String base) {
    final RevisionInfo rev = info.revision(revision);
    RevisionInfo b = resolveRevisionOrPatchSetId(info, base, null);
    CallbackGroup group = new CallbackGroup();
    Timestamp lastReply = myLastReply(info);
    if (rev.isEdit()) {
        // Comments are filtered for the current revision. Use parent
        // patch set for edits, as edits themself can never have comments.
        RevisionInfo p = RevisionInfo.findEditParentRevision(info.revisions().values());
        List<NativeMap<JsArray<CommentInfo>>> comments = loadComments(p, group);
        loadFileList(b, rev, lastReply, group, comments, null);
    } else {
        loadDiff(b, rev, lastReply, group);
    }
    group.addListener(new AsyncCallback<Void>() {

        @Override
        public void onSuccess(Void result) {
            loadConfigInfo(info, rev);
        }

        @Override
        public void onFailure(Throwable caught) {
            logger.log(Level.SEVERE, "Loading file list and inline comments failed: " + caught.getMessage());
            loadConfigInfo(info, rev);
        }
    });
    group.done();
}
#end_block

#method_before
@Override
protected void formatChange() throws EmailException {
    appendText(textTemplate("Reverted.soy"));
}
#method_after
@Override
protected void formatChange() throws EmailException {
    appendText(textTemplate("Reverted"));
}
#end_block

#method_before
@Override
protected void formatChange() throws EmailException {
    appendText(textTemplate("Restored.soy"));
}
#method_after
@Override
protected void formatChange() throws EmailException {
    appendText(textTemplate("Restored"));
}
#end_block

#method_before
@Test
public void submitNoPermission() throws Exception {
    // create project where submit is blocked
    Project.NameKey p = createProject("p");
    ProjectConfig cfg = projectCache.checkedGet(p).getConfig();
    Util.block(cfg, Permission.SUBMIT, REGISTERED_USERS, "refs/*");
    saveProjectConfig(p, cfg);
    TestRepository<InMemoryRepository> repo = cloneProject(p, admin);
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), repo);
    PushOneCommit.Result result = push.to("refs/for/master");
    result.assertOkStatus();
    submit(result.getChangeId(), new SubmitInput(), AuthException.class, "submit not permitted");
}
#method_after
@Test
public void submitNoPermission() throws Exception {
    // create project where submit is blocked
    Project.NameKey p = createProject("p");
    block(Permission.SUBMIT, REGISTERED_USERS, "refs/*", p);
    TestRepository<InMemoryRepository> repo = cloneProject(p, admin);
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), repo);
    PushOneCommit.Result result = push.to("refs/for/master");
    result.assertOkStatus();
    submit(result.getChangeId(), new SubmitInput(), AuthException.class, "submit not permitted");
}
#end_block

#method_before
@Test
public void submitNoPermission() throws Exception {
    // create project where submit is blocked
    Project.NameKey p = createProject("p");
    ProjectConfig cfg = projectCache.checkedGet(p).getConfig();
    Util.block(cfg, Permission.SUBMIT, REGISTERED_USERS, "refs/*");
    saveProjectConfig(p, cfg);
    TestRepository<InMemoryRepository> repo = cloneProject(p, admin);
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), repo);
    PushOneCommit.Result result = push.to("refs/for/master");
    result.assertOkStatus();
    submit(result.getChangeId(), new SubmitInput(), AuthException.class, "submit not permitted");
}
#method_after
@Test
public void submitNoPermission() throws Exception {
    // create project where submit is blocked
    Project.NameKey p = createProject("p");
    block(Permission.SUBMIT, REGISTERED_USERS, "refs/*", p);
    TestRepository<InMemoryRepository> repo = cloneProject(p, admin);
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), repo);
    PushOneCommit.Result result = push.to("refs/for/master");
    result.assertOkStatus();
    submit(result.getChangeId(), new SubmitInput(), AuthException.class, "submit not permitted");
}
#end_block

#method_before
private void deleteGitRepository(final Project.NameKey project, final File repoFile) throws IOException {
    // Delete the repository from disk
    Path trash = moveToTrash(repoFile.toPath(), project);
    try {
        recursiveDelete(trash);
    } catch (IOException e) {
        // Only log if delete failed - repo already moved to trash.
        // Otherwise, listeners are never called.
        log.warn("Error trying to delete " + trash, e);
    }
    // Delete parent folders if they are (now) empty
    recursiveDeleteParent(repoFile.getParentFile(), gitDir.toFile());
    // Send an event that the repository was deleted
    ProjectDeletedListener.Event event = new ProjectDeletedListener.Event() {

        @Override
        public String getProjectName() {
            return project.get();
        }

        @Override
        public NotifyHandling getNotify() {
            return NotifyHandling.NONE;
        }
    };
    for (ProjectDeletedListener l : deletedListener) {
        try {
            l.onProjectDeleted(event);
        } catch (RuntimeException e) {
            log.warn("Failure in ProjectDeletedListener", e);
        }
    }
}
#method_after
private void deleteGitRepository(final Project.NameKey project, final File repoFile) throws IOException {
    // Delete the repository from disk
    Path trash = moveToTrash(repoFile.toPath(), project);
    boolean ok = false;
    try {
        recursiveDelete(trash);
        ok = true;
    } catch (IOException e) {
        // Only log if delete failed - repo already moved to trash.
        // Otherwise, listeners are never called.
        log.warn("Error trying to delete " + trash, e);
    }
    // Delete parent folders if they are (now) empty
    if (ok) {
        try {
            recursiveDeleteParent(repoFile.getParentFile(), gitDir.toFile());
        } catch (IOException e) {
            log.warn("Couldn't delete (empty) parents of " + repoFile, e);
        }
    }
    // Send an event that the repository was deleted
    ProjectDeletedListener.Event event = new ProjectDeletedListener.Event() {

        @Override
        public String getProjectName() {
            return project.get();
        }

        @Override
        public NotifyHandling getNotify() {
            return NotifyHandling.NONE;
        }
    };
    for (ProjectDeletedListener l : deletedListener) {
        try {
            l.onProjectDeleted(event);
        } catch (RuntimeException e) {
            log.warn("Failure in ProjectDeletedListener", e);
        }
    }
}
#end_block

#method_before
private void recursiveDeleteParent(File file, File until) {
    if (file.equals(until)) {
        return;
    }
    if (file.listFiles().length == 0) {
        File parent = file.getParentFile();
        if (file.delete()) {
            recursiveDeleteParent(parent, until);
        }
    }
}
#method_after
private void recursiveDeleteParent(File file, File until) throws IOException {
    if (file.equals(until)) {
        return;
    }
    if (file.listFiles().length == 0) {
        File parent = file.getParentFile();
        Files.delete(file.toPath());
        recursiveDeleteParent(parent, until);
    }
}
#end_block

#method_before
protected void onInitUI() {
    if (LocaleInfo.getCurrentLocale().isRTL()) {
        labelIdx = 1;
        fieldIdx = 0;
    } else {
        labelIdx = 0;
        fieldIdx = 1;
    }
    nameTxt = new NpTextBox();
    nameTxt.setVisibleLength(60);
    nameTxt.setReadOnly(!canEditFullName());
    emailPick = new ListBox();
    final Grid infoPlainText = new Grid(2, 2);
    infoPlainText.setStyleName(Gerrit.RESOURCES.css().infoBlock());
    infoPlainText.addStyleName(Gerrit.RESOURCES.css().accountInfoBlock());
    body.add(infoPlainText);
    registerNewEmail = new Button(Util.C.buttonOpenRegisterNewEmail());
    registerNewEmail.setEnabled(false);
    registerNewEmail.addClickHandler(new ClickHandler() {

        @Override
        public void onClick(final ClickEvent event) {
            doRegisterNewEmail();
        }
    });
    final FlowPanel emailLine = new FlowPanel();
    emailLine.add(emailPick);
    if (canRegisterNewEmail()) {
        emailLine.add(registerNewEmail);
    }
    int row = 0;
    if (!Gerrit.info().auth().canEdit(FieldName.USER_NAME) && Gerrit.info().auth().siteHasUsernames()) {
        infoPlainText.resizeRows(infoPlainText.getRowCount() + 1);
        row(infoPlainText, row++, Util.C.userName(), new UsernameField());
    }
    if (!canEditFullName()) {
        FlowPanel nameLine = new FlowPanel();
        nameLine.add(nameTxt);
        if (Gerrit.info().auth().editFullNameUrl() != null) {
            Button edit = new Button(Util.C.linkEditFullName());
            edit.addClickHandler(new ClickHandler() {

                @Override
                public void onClick(ClickEvent event) {
                    Window.open(Gerrit.info().auth().editFullNameUrl(), "_blank", null);
                }
            });
            nameLine.add(edit);
        }
        Button reload = new Button(Util.C.linkReloadContact());
        reload.addClickHandler(new ClickHandler() {

            @Override
            public void onClick(ClickEvent event) {
                Window.Location.replace(Gerrit.loginRedirect(PageLinks.SETTINGS_CONTACT));
            }
        });
        nameLine.add(reload);
        row(infoPlainText, row++, Util.C.contactFieldFullName(), nameLine);
    } else {
        row(infoPlainText, row++, Util.C.contactFieldFullName(), nameTxt);
    }
    row(infoPlainText, row++, Util.C.contactFieldEmail(), emailLine);
    infoPlainText.getCellFormatter().addStyleName(0, 0, Gerrit.RESOURCES.css().topmost());
    infoPlainText.getCellFormatter().addStyleName(0, 1, Gerrit.RESOURCES.css().topmost());
    infoPlainText.getCellFormatter().addStyleName(row - 1, 0, Gerrit.RESOURCES.css().bottomheader());
    save = new Button(Util.C.buttonSaveChanges());
    save.setEnabled(false);
    save.addClickHandler(new ClickHandler() {

        @Override
        public void onClick(final ClickEvent event) {
            doSave(null);
        }
    });
    emailPick.addChangeHandler(new ChangeHandler() {

        @Override
        public void onChange(final ChangeEvent event) {
            final int idx = emailPick.getSelectedIndex();
            final String v = 0 <= idx ? emailPick.getValue(idx) : null;
            if (Util.C.buttonOpenRegisterNewEmail().equals(v)) {
                for (int i = 0; i < emailPick.getItemCount(); i++) {
                    if (currentEmail.equals(emailPick.getValue(i))) {
                        emailPick.setSelectedIndex(i);
                        break;
                    }
                }
                doRegisterNewEmail();
            } else {
                save.setEnabled(true);
            }
        }
    });
}
#method_after
protected void onInitUI() {
    if (LocaleInfo.getCurrentLocale().isRTL()) {
        labelIdx = 1;
        fieldIdx = 0;
    } else {
        labelIdx = 0;
        fieldIdx = 1;
    }
    nameTxt = new NpTextBox();
    nameTxt.setVisibleLength(60);
    nameTxt.setReadOnly(!canEditFullName());
    emailPick = new ListBox();
    final Grid infoPlainText = new Grid(2, 2);
    infoPlainText.setStyleName(Gerrit.RESOURCES.css().infoBlock());
    infoPlainText.addStyleName(Gerrit.RESOURCES.css().accountInfoBlock());
    body.add(infoPlainText);
    registerNewEmail = new Button(Util.C.buttonOpenRegisterNewEmail());
    registerNewEmail.setEnabled(false);
    registerNewEmail.addClickHandler(new ClickHandler() {

        @Override
        public void onClick(final ClickEvent event) {
            doRegisterNewEmail();
        }
    });
    final FlowPanel emailLine = new FlowPanel();
    emailLine.add(emailPick);
    if (canRegisterNewEmail()) {
        emailLine.add(registerNewEmail);
    }
    int row = 0;
    if (!Gerrit.info().auth().canEdit(FieldName.USER_NAME) && Gerrit.info().auth().siteHasUsernames()) {
        infoPlainText.resizeRows(infoPlainText.getRowCount() + 1);
        row(infoPlainText, row++, Util.C.userName(), new UsernameField());
    }
    if (!canEditFullName()) {
        FlowPanel nameLine = new FlowPanel();
        nameLine.add(nameTxt);
        if (Gerrit.info().auth().editFullNameUrl() != null) {
            Button edit = new Button(Util.C.linkEditFullName());
            edit.addClickHandler(new ClickHandler() {

                @Override
                public void onClick(ClickEvent event) {
                    Window.open(Gerrit.info().auth().editFullNameUrl(), "_blank", null);
                }
            });
            nameLine.add(edit);
        }
        Button reload = new Button(Util.C.linkReloadContact());
        reload.addClickHandler(new ClickHandler() {

            @Override
            public void onClick(ClickEvent event) {
                Window.Location.replace(Gerrit.loginRedirect(PageLinks.SETTINGS_CONTACT));
            }
        });
        nameLine.add(reload);
        row(infoPlainText, row++, Util.C.contactFieldFullName(), nameLine);
    } else {
        row(infoPlainText, row++, Util.C.contactFieldFullName(), nameTxt);
    }
    row(infoPlainText, row++, Util.C.contactFieldEmail(), emailLine);
    infoPlainText.getCellFormatter().addStyleName(0, 0, Gerrit.RESOURCES.css().topmost());
    infoPlainText.getCellFormatter().addStyleName(0, 1, Gerrit.RESOURCES.css().topmost());
    infoPlainText.getCellFormatter().addStyleName(row - 1, 0, Gerrit.RESOURCES.css().bottomheader());
    save = new Button(Util.C.buttonSaveChanges());
    save.setEnabled(false);
    save.addClickHandler(new ClickHandler() {

        @Override
        public void onClick(final ClickEvent event) {
            doSave();
        }
    });
    emailPick.addChangeHandler(new ChangeHandler() {

        @Override
        public void onChange(final ChangeEvent event) {
            final int idx = emailPick.getSelectedIndex();
            final String v = 0 <= idx ? emailPick.getValue(idx) : null;
            if (Util.C.buttonOpenRegisterNewEmail().equals(v)) {
                for (int i = 0; i < emailPick.getItemCount(); i++) {
                    if (currentEmail.equals(emailPick.getValue(i))) {
                        emailPick.setSelectedIndex(i);
                        break;
                    }
                }
                doRegisterNewEmail();
            } else {
                save.setEnabled(true);
            }
        }
    });
    onEditEnabler = new OnEditEnabler(save, nameTxt);
}
#end_block

#method_before
private void postLoad() {
    if (haveAccount && haveEmails) {
        updateEmailList();
        registerNewEmail.setEnabled(true);
        save.setEnabled(false);
        new OnEditEnabler(save, nameTxt);
    }
    display();
}
#method_after
private void postLoad() {
    if (haveAccount && haveEmails) {
        updateEmailList();
        registerNewEmail.setEnabled(true);
        save.setEnabled(false);
        onEditEnabler.updateOriginalValue(nameTxt);
    }
    display();
}
#end_block

#method_before
protected void display(AccountInfo account) {
    currentEmail = account.email();
    nameTxt.setText(account.name());
    save.setEnabled(false);
    new OnEditEnabler(save, nameTxt);
}
#method_after
protected void display(AccountInfo account) {
    currentEmail = account.email();
    nameTxt.setText(account.name());
    save.setEnabled(false);
    onEditEnabler.updateOriginalValue(nameTxt);
}
#end_block

#method_before
void doSave(final AsyncCallback<Account> onSave) {
    String newName = canEditFullName() ? nameTxt.getText() : null;
    if (newName != null && newName.trim().isEmpty()) {
        newName = null;
    }
    final String newEmail;
    if (emailPick.isEnabled() && emailPick.getSelectedIndex() >= 0) {
        final String v = emailPick.getValue(emailPick.getSelectedIndex());
        if (Util.C.buttonOpenRegisterNewEmail().equals(v)) {
            newEmail = currentEmail;
        } else {
            newEmail = v;
        }
    } else {
        newEmail = currentEmail;
    }
    save.setEnabled(false);
    registerNewEmail.setEnabled(false);
    CallbackGroup group = new CallbackGroup();
    if (!newEmail.equals(currentEmail)) {
        AccountApi.setPreferredEmail("self", newEmail, group.add(new GerritCallback<NativeString>() {

            @Override
            public void onSuccess(NativeString result) {
            }
        }));
    }
    AccountApi.setName("self", newName, group.add(new GerritCallback<NativeString>() {

        @Override
        public void onSuccess(NativeString result) {
            registerNewEmail.setEnabled(true);
        // TODO update
        }

        @Override
        public void onFailure(Throwable caught) {
            save.setEnabled(true);
            registerNewEmail.setEnabled(true);
            super.onFailure(caught);
        }
    }));
}
#method_after
void doSave() {
    final String newName;
    String name = canEditFullName() ? nameTxt.getText() : null;
    if (name != null && name.trim().isEmpty()) {
        newName = null;
    } else {
        newName = name;
    }
    final String newEmail;
    if (emailPick.isEnabled() && emailPick.getSelectedIndex() >= 0) {
        final String v = emailPick.getValue(emailPick.getSelectedIndex());
        if (Util.C.buttonOpenRegisterNewEmail().equals(v)) {
            newEmail = currentEmail;
        } else {
            newEmail = v;
        }
    } else {
        newEmail = currentEmail;
    }
    save.setEnabled(false);
    registerNewEmail.setEnabled(false);
    CallbackGroup group = new CallbackGroup();
    if (!newEmail.equals(currentEmail)) {
        AccountApi.setPreferredEmail("self", newEmail, group.add(new GerritCallback<NativeString>() {

            @Override
            public void onSuccess(NativeString result) {
            }
        }));
    }
    AccountApi.setName("self", newName, group.add(new GerritCallback<NativeString>() {

        @Override
        public void onSuccess(NativeString result) {
        }

        @Override
        public void onFailure(Throwable caught) {
            save.setEnabled(true);
            registerNewEmail.setEnabled(true);
            super.onFailure(caught);
        }
    }));
    group.done();
    group.addListener(new GerritCallback<Void>() {

        @Override
        public void onSuccess(Void result) {
            currentEmail = newEmail;
            AccountInfo me = Gerrit.getUserAccount();
            me.email(currentEmail);
            me.name(newName);
            onSaveSuccess(me);
            registerNewEmail.setEnabled(true);
        }
    });
}
#end_block

#method_before
public static void putEditPreferences(EditPreferences in, AsyncCallback<VoidResult> cb) {
    self().view("preferences.edit").put(in, cb);
}
#method_after
public static void putEditPreferences(EditPreferences in, AsyncCallback<EditPreferences> cb) {
    self().view("preferences.edit").put(in, cb);
}
#end_block

#method_before
public static void suggest(String query, int limit, AsyncCallback<JsArray<AccountInfo>> cb) {
    new RestApi("/accounts/").addParameter("q", query).addParameter("n", limit).background().get(cb);
}
#method_after
public static void suggest(String query, int limit, AsyncCallback<JsArray<AccountInfo>> cb) {
    new RestApi("/accounts/").addParameterTrue("suggest").addParameter("q", query).addParameter("n", limit).background().get(cb);
}
#end_block

#method_before
protected void setupSoyContext() {
    soyContext = new LinkedHashMap<String, Object>();
    soyContext.put("messageClass", messageClass);
    soyContextEmailData = new LinkedHashMap<String, Object>();
    soyContextEmailData.put("settingsUrl", getSettingsUrl());
    soyContextEmailData.put("gerritHost", getGerritHost());
    soyContextEmailData.put("gerritUrl", getGerritUrl());
    soyContext.put("email", soyContextEmailData);
}
#method_after
protected void setupSoyContext() {
    soyContext = new HashMap<>();
    soyContext.put("messageClass", messageClass);
    soyContextEmailData = new HashMap<>();
    soyContextEmailData.put("settingsUrl", getSettingsUrl());
    soyContextEmailData.put("gerritHost", getGerritHost());
    soyContextEmailData.put("gerritUrl", getGerritUrl());
    soyContext.put("email", soyContextEmailData);
}
#end_block

#method_before
@Override
protected void setupSoyContext() {
    super.setupSoyContext();
    soyContext.put("changeId", change.getKey().get());
    soyContext.put("coverLetter", getCoverLetter());
    soyContext.put("fromName", getNameFor(fromId));
    soyContextEmailData.put("unifiedDiff", getUnifiedDiff());
    soyContextEmailData.put("changeDetail", getChangeDetail());
    soyContextEmailData.put("changeUrl", getChangeUrl());
    soyContextEmailData.put("includeDiff", getIncludeDiff());
    LinkedHashMap<String, String> changeData = new LinkedHashMap<String, String>();
    changeData.put("subject", change.getSubject());
    changeData.put("originalSubject", change.getOriginalSubject());
    changeData.put("ownerEmail", getNameEmailFor(change.getOwner()));
    soyContext.put("change", changeData);
    LinkedHashMap<String, Object> patchSetData = new LinkedHashMap<String, Object>();
    patchSetData.put("patchSetId", patchSet.getPatchSetId());
    patchSetData.put("refName", patchSet.getRefName());
    soyContext.put("patchSet", patchSetData);
// TODO(wyatta): patchSetInfo
}
#method_after
@Override
protected void setupSoyContext() {
    super.setupSoyContext();
    soyContext.put("changeId", change.getKey().get());
    soyContext.put("coverLetter", getCoverLetter());
    soyContext.put("fromName", getNameFor(fromId));
    soyContextEmailData.put("unifiedDiff", getUnifiedDiff());
    soyContextEmailData.put("changeDetail", getChangeDetail());
    soyContextEmailData.put("changeUrl", getChangeUrl());
    soyContextEmailData.put("includeDiff", getIncludeDiff());
    Map<String, String> changeData = new HashMap<>();
    changeData.put("subject", change.getSubject());
    changeData.put("originalSubject", change.getOriginalSubject());
    changeData.put("ownerEmail", getNameEmailFor(change.getOwner()));
    soyContext.put("change", changeData);
    Map<String, Object> patchSetData = new HashMap<>();
    patchSetData.put("patchSetId", patchSet.getPatchSetId());
    patchSetData.put("refName", patchSet.getRefName());
    soyContext.put("patchSet", patchSetData);
// TODO(wyatta): patchSetInfo
}
#end_block

#method_before
@Override
protected void setupSoyContext() {
    super.setupSoyContext();
    soyContext.put("projectName", branch.getParentKey().get());
    soyContextEmailData.put("sshHost", getSshHost());
    LinkedHashMap<String, String> branchData = new LinkedHashMap<String, String>();
    branchData.put("shortName", branch.getShortName());
    soyContext.put("branch", branchData);
}
#method_after
@Override
protected void setupSoyContext() {
    super.setupSoyContext();
    soyContext.put("projectName", branch.getParentKey().get());
    soyContextEmailData.put("sshHost", getSshHost());
    Map<String, String> branchData = new HashMap<>();
    branchData.put("shortName", branch.getShortName());
    soyContext.put("branch", branchData);
}
#end_block

#method_before
@Override
public ChangeDataSource getSource(Predicate<ChangeData> p, QueryOptions opts) throws QueryParseException {
    Set<Change.Status> statuses = IndexRewriter.getPossibleStatus(p);
    List<ChangeSubIndex> indexes = new ArrayList<>(2);
    if (!Sets.intersection(statuses, OPEN_STATUSES).isEmpty()) {
        indexes.add(openIndex);
    }
    if (!Sets.intersection(statuses, CLOSED_STATUSES).isEmpty()) {
        indexes.add(closedIndex);
    }
    return new QuerySource(indexes, queryBuilder.toQuery(p), opts, getSort());
}
#method_after
@Override
public ChangeDataSource getSource(Predicate<ChangeData> p, QueryOptions opts) throws QueryParseException {
    Set<Change.Status> statuses = ChangeIndexRewriter.getPossibleStatus(p);
    List<ChangeSubIndex> indexes = new ArrayList<>(2);
    if (!Sets.intersection(statuses, OPEN_STATUSES).isEmpty()) {
        indexes.add(openIndex);
    }
    if (!Sets.intersection(statuses, CLOSED_STATUSES).isEmpty()) {
        indexes.add(closedIndex);
    }
    return new QuerySource(indexes, queryBuilder.toQuery(p), opts, getSort());
}
#end_block

#method_before
@Override
public ResultSet<ChangeData> read() throws OrmException {
    if (Thread.interrupted()) {
        Thread.currentThread().interrupt();
        throw new OrmException("interrupted");
    }
    return new ChangeDataResults(executor.submit(new Callable<List<ChangeData>>() {

        @Override
        public List<ChangeData> call() throws IOException {
            return doRead();
        }
    }));
}
#method_after
@Override
public ResultSet<ChangeData> read() throws OrmException {
    if (Thread.interrupted()) {
        Thread.currentThread().interrupt();
        throw new OrmException("interrupted");
    }
    final Set<String> fields = fields(opts);
    return new ChangeDataResults(executor.submit(new Callable<List<Document>>() {

        @Override
        public List<Document> call() throws IOException {
            return doRead(fields);
        }
    }), fields);
}
#end_block

#method_before
private List<ChangeData> doRead() throws IOException {
    IndexSearcher[] searchers = new IndexSearcher[indexes.size()];
    try {
        int realLimit = opts.start() + opts.limit();
        TopFieldDocs[] hits = new TopFieldDocs[indexes.size()];
        for (int i = 0; i < indexes.size(); i++) {
            searchers[i] = indexes.get(i).acquire();
            hits[i] = searchers[i].search(query, realLimit, sort);
        }
        TopDocs docs = TopDocs.merge(sort, realLimit, hits);
        List<ChangeData> result = new ArrayList<>(docs.scoreDocs.length);
        Set<String> fields = fields(opts);
        String idFieldName = LEGACY_ID.getName();
        for (int i = opts.start(); i < docs.scoreDocs.length; i++) {
            ScoreDoc sd = docs.scoreDocs[i];
            Document doc = searchers[sd.shardIndex].doc(sd.doc, fields);
            result.add(toChangeData(fields(doc, fields), fields, idFieldName));
        }
        return result;
    } finally {
        for (int i = 0; i < indexes.size(); i++) {
            if (searchers[i] != null) {
                try {
                    indexes.get(i).release(searchers[i]);
                } catch (IOException e) {
                    log.warn("cannot release Lucene searcher", e);
                }
            }
        }
    }
}
#method_after
private List<Document> doRead(Set<String> fields) throws IOException {
    IndexSearcher[] searchers = new IndexSearcher[indexes.size()];
    try {
        int realLimit = opts.start() + opts.limit();
        TopFieldDocs[] hits = new TopFieldDocs[indexes.size()];
        for (int i = 0; i < indexes.size(); i++) {
            searchers[i] = indexes.get(i).acquire();
            hits[i] = searchers[i].search(query, realLimit, sort);
        }
        TopDocs docs = TopDocs.merge(sort, realLimit, hits);
        List<Document> result = new ArrayList<>(docs.scoreDocs.length);
        for (int i = opts.start(); i < docs.scoreDocs.length; i++) {
            ScoreDoc sd = docs.scoreDocs[i];
            result.add(searchers[sd.shardIndex].doc(sd.doc, fields));
        }
        return result;
    } finally {
        for (int i = 0; i < indexes.size(); i++) {
            if (searchers[i] != null) {
                try {
                    indexes.get(i).release(searchers[i]);
                } catch (IOException e) {
                    log.warn("cannot release Lucene searcher", e);
                }
            }
        }
    }
}
#end_block

#method_before
@Override
public List<ChangeData> toList() {
    try {
        return future.get();
    } catch (InterruptedException e) {
        close();
        throw new OrmRuntimeException(e);
    } catch (ExecutionException e) {
        Throwables.propagateIfPossible(e.getCause());
        throw new OrmRuntimeException(e.getCause());
    }
}
#method_after
@Override
public List<ChangeData> toList() {
    try {
        List<Document> docs = future.get();
        List<ChangeData> result = new ArrayList<>(docs.size());
        String idFieldName = LEGACY_ID.getName();
        for (Document doc : docs) {
            result.add(toChangeData(fields(doc, fields), fields, idFieldName));
        }
        return result;
    } catch (InterruptedException e) {
        close();
        throw new OrmRuntimeException(e);
    } catch (ExecutionException e) {
        Throwables.propagateIfPossible(e.getCause());
        throw new OrmRuntimeException(e.getCause());
    }
}
#end_block

#method_before
private void decodeChangedLines(Multimap<String, IndexableField> doc, ChangeData cd) {
    IndexableField added = Iterables.getFirst(doc.get(ADDED_FIELD), null);
    IndexableField deleted = Iterables.getFirst(doc.get(DELETED_FIELD), null);
    if (added != null && deleted != null) {
        cd.setChangedLines(added.numericValue().intValue(), deleted.numericValue().intValue());
    }
}
#method_after
private void decodeChangedLines(Multimap<String, IndexableField> doc, ChangeData cd) {
    IndexableField added = Iterables.getFirst(doc.get(ADDED_FIELD), null);
    IndexableField deleted = Iterables.getFirst(doc.get(DELETED_FIELD), null);
    if (added != null && deleted != null) {
        cd.setChangedLines(added.numericValue().intValue(), deleted.numericValue().intValue());
    } else {
        // No ChangedLines stored, likely due to failure during reindexing, for
        // example due to LargeObjectException. But we know the field was
        // requested, so update ChangeData to prevent callers from trying to
        // lazily load it, as that would probably also fail.
        cd.setNoChangedLines();
    }
}
#end_block

#method_before
private boolean isReviewer(ChangeContext ctx) throws OrmException {
    if (ctx.getAccountId().equals(ctx.getChange().getOwner())) {
        return true;
    }
    for (PostReviewers.Addition addition : reviewerResults) {
        if (addition.op.addedReviewers == null) {
            continue;
        }
        for (PatchSetApproval psa : addition.op.addedReviewers) {
            if (psa.getAccountId().equals(ctx.getAccountId())) {
                return true;
            }
        }
    }
    ChangeData cd = changeDataFactory.create(db.get(), ctx.getControl());
    ReviewerSet reviewers = cd.reviewers();
    if (reviewers != null && reviewers.byState(REVIEWER).contains(ctx.getAccountId())) {
        return true;
    }
    return false;
}
#method_after
private boolean isReviewer(ChangeContext ctx) throws OrmException {
    if (ctx.getAccountId().equals(ctx.getChange().getOwner())) {
        return true;
    }
    for (PostReviewers.Addition addition : reviewerResults) {
        if (addition.op.addedReviewers == null) {
            continue;
        }
        for (PatchSetApproval psa : addition.op.addedReviewers) {
            if (psa.getAccountId().equals(ctx.getAccountId())) {
                return true;
            }
        }
    }
    ChangeData cd = changeDataFactory.create(db.get(), ctx.getControl());
    ReviewerSet reviewers = cd.reviewers();
    if (reviewers.byState(REVIEWER).contains(ctx.getAccountId())) {
        return true;
    }
    return false;
}
#end_block

#method_before
private ChangeInfo format(ChangeData cd, Optional<PatchSet.Id> limitToPsId, boolean fillAccountLoader) throws OrmException {
    try {
        if (fillAccountLoader) {
            accountLoader = accountLoaderFactory.create(has(DETAILED_ACCOUNTS));
            ChangeInfo res = toChangeInfo(cd, limitToPsId);
            accountLoader.fill();
            return res;
        }
        return toChangeInfo(cd, limitToPsId);
    } catch (PatchListNotAvailableException | GpgException | OrmException | IOException | RuntimeException e) {
        if (!has(CHECK)) {
            Throwables.throwIfInstanceOf(e, OrmException.class);
            throw new OrmException(e);
        }
        return checkOnly(cd);
    }
}
#method_after
private ChangeInfo format(ChangeData cd, Optional<PatchSet.Id> limitToPsId, boolean fillAccountLoader) throws OrmException {
    try {
        if (fillAccountLoader) {
            accountLoader = accountLoaderFactory.create(has(DETAILED_ACCOUNTS));
            ChangeInfo res = toChangeInfo(cd, limitToPsId);
            accountLoader.fill();
            return res;
        }
        return toChangeInfo(cd, limitToPsId);
    } catch (PatchListNotAvailableException | GpgException | OrmException | IOException | RuntimeException e) {
        if (!has(CHECK)) {
            Throwables.propagateIfPossible(e, OrmException.class);
            throw new OrmException(e);
        }
        return checkOnly(cd);
    }
}
#end_block

#method_before
private void setAllApprovals(ChangeControl baseCtrl, ChangeData cd, Map<String, LabelWithStatus> labels) throws OrmException {
    // Include a user in the output for this label if either:
    // - They are an explicit reviewer.
    // - They ever voted on this change.
    Set<Account.Id> allUsers = new HashSet<>();
    if (notesMigration.readChanges()) {
        allUsers.addAll(cd.reviewers().byState(ReviewerStateInternal.REVIEWER));
    } else {
        allUsers.addAll(cd.reviewers().all());
    }
    for (PatchSetApproval psa : cd.approvals().values()) {
        allUsers.add(psa.getAccountId());
    }
    Table<Account.Id, String, PatchSetApproval> current = HashBasedTable.create(allUsers.size(), baseCtrl.getLabelTypes().getLabelTypes().size());
    for (PatchSetApproval psa : cd.currentApprovals()) {
        current.put(psa.getAccountId(), psa.getLabel(), psa);
    }
    for (Account.Id accountId : allUsers) {
        IdentifiedUser user = userFactory.create(accountId);
        ChangeControl ctl = baseCtrl.forUser(user);
        for (Map.Entry<String, LabelWithStatus> e : labels.entrySet()) {
            LabelType lt = ctl.getLabelTypes().byLabel(e.getKey());
            if (lt == null) {
                // author didn't intend for the label to show up in the table.
                continue;
            }
            Integer value;
            String tag = null;
            Timestamp date = null;
            PatchSetApproval psa = current.get(accountId, lt.getName());
            if (psa != null) {
                value = Integer.valueOf(psa.getValue());
                if (value == 0) {
                    // This may be a dummy approval that was inserted when the reviewer
                    // was added. Explicitly check whether the user can vote on this
                    // label.
                    value = labelNormalizer.canVote(ctl, lt, accountId) ? 0 : null;
                }
                tag = psa.getTag();
                date = psa.getGranted();
            } else {
                // Either the user cannot vote on this label, or they were added as a
                // reviewer but have not responded yet. Explicitly check whether the
                // user can vote on this label.
                value = labelNormalizer.canVote(ctl, lt, accountId) ? 0 : null;
            }
            addApproval(e.getValue().label(), approvalInfo(accountId, value, tag, date));
        }
    }
}
#method_after
private void setAllApprovals(ChangeControl baseCtrl, ChangeData cd, Map<String, LabelWithStatus> labels) throws OrmException {
    // Include a user in the output for this label if either:
    // - They are an explicit reviewer.
    // - They ever voted on this change.
    Set<Account.Id> allUsers = new HashSet<>();
    allUsers.addAll(cd.reviewers().byState(ReviewerStateInternal.REVIEWER));
    for (PatchSetApproval psa : cd.approvals().values()) {
        allUsers.add(psa.getAccountId());
    }
    Table<Account.Id, String, PatchSetApproval> current = HashBasedTable.create(allUsers.size(), baseCtrl.getLabelTypes().getLabelTypes().size());
    for (PatchSetApproval psa : cd.currentApprovals()) {
        current.put(psa.getAccountId(), psa.getLabel(), psa);
    }
    for (Account.Id accountId : allUsers) {
        IdentifiedUser user = userFactory.create(accountId);
        ChangeControl ctl = baseCtrl.forUser(user);
        for (Map.Entry<String, LabelWithStatus> e : labels.entrySet()) {
            LabelType lt = ctl.getLabelTypes().byLabel(e.getKey());
            if (lt == null) {
                // author didn't intend for the label to show up in the table.
                continue;
            }
            Integer value;
            String tag = null;
            Timestamp date = null;
            PatchSetApproval psa = current.get(accountId, lt.getName());
            if (psa != null) {
                value = Integer.valueOf(psa.getValue());
                if (value == 0) {
                    // This may be a dummy approval that was inserted when the reviewer
                    // was added. Explicitly check whether the user can vote on this
                    // label.
                    value = labelNormalizer.canVote(ctl, lt, accountId) ? 0 : null;
                }
                tag = psa.getTag();
                date = psa.getGranted();
            } else {
                // Either the user cannot vote on this label, or they were added as a
                // reviewer but have not responded yet. Explicitly check whether the
                // user can vote on this label.
                value = labelNormalizer.canVote(ctl, lt, accountId) ? 0 : null;
            }
            addApproval(e.getValue().label(), approvalInfo(accountId, value, tag, date));
        }
    }
}
#end_block

#method_before
void sendMessages() {
    for (CommitValidationMessage m : messages) {
        if (m.isError()) {
            messageSender.sendError(m.getMessage());
        } else {
            messageSender.sendMessage(m.getMessage());
        }
    }
}
#method_after
void sendMessages() {
    for (ValidationMessage m : messages) {
        if (m.isError()) {
            messageSender.sendError(m.getMessage());
        } else {
            messageSender.sendMessage(m.getMessage());
        }
    }
}
#end_block

#method_before
void processCommands(Collection<ReceiveCommand> commands, MultiProgressMonitor progress) {
    newProgress = progress.beginSubTask("new", UNKNOWN);
    replaceProgress = progress.beginSubTask("updated", UNKNOWN);
    closeProgress = progress.beginSubTask("closed", UNKNOWN);
    commandProgress = progress.beginSubTask("refs", UNKNOWN);
    batch = repo.getRefDatabase().newBatchUpdate();
    batch.setPushCertificate(rp.getPushCertificate());
    batch.setRefLogIdent(rp.getRefLogIdent());
    batch.setRefLogMessage("push", true);
    parseCommands(commands);
    if (magicBranch != null && magicBranch.cmd.getResult() == NOT_ATTEMPTED) {
        selectNewAndReplacedChangesFromMagicBranch();
    }
    preparePatchSetsForReplace();
    if (!batch.getCommands().isEmpty()) {
        try {
            if (!batch.isAllowNonFastForwards() && magicBranch != null && magicBranch.edit) {
                batch.setAllowNonFastForwards(true);
            }
            batch.execute(rp.getRevWalk(), commandProgress);
        } catch (IOException err) {
            int cnt = 0;
            for (ReceiveCommand cmd : batch.getCommands()) {
                if (cmd.getResult() == NOT_ATTEMPTED) {
                    cmd.setResult(REJECTED_OTHER_REASON, "internal server error");
                    cnt++;
                }
            }
            log.error(String.format("Failed to store %d refs in %s", cnt, project.getName()), err);
        }
    }
    insertChangesAndPatchSets();
    newProgress.end();
    replaceProgress.end();
    if (!errors.isEmpty()) {
        for (Error error : errors.keySet()) {
            rp.sendMessage(buildError(error, errors.get(error)));
        }
        rp.sendMessage(String.format("User: %s", displayName(user)));
        rp.sendMessage(COMMAND_REJECTION_MESSAGE_FOOTER);
    }
    Set<Branch.NameKey> branches = new HashSet<>();
    for (ReceiveCommand c : batch.getCommands()) {
        if (c.getResult() == OK) {
            String refName = c.getRefName();
            if (c.getType() == ReceiveCommand.Type.UPDATE) {
                // aka fast-forward
                tagCache.updateFastForward(project.getNameKey(), refName, c.getOldId(), c.getNewId());
            }
            if (isHead(c) || isConfig(c)) {
                switch(c.getType()) {
                    case CREATE:
                    case UPDATE:
                    case UPDATE_NONFASTFORWARD:
                        autoCloseChanges(c);
                        branches.add(new Branch.NameKey(project.getNameKey(), refName));
                        break;
                    case DELETE:
                        break;
                }
            }
            if (isConfig(c)) {
                projectCache.evict(project);
                ProjectState ps = projectCache.get(project.getNameKey());
                // 
                repoManager.setProjectDescription(// 
                project.getNameKey(), ps.getProject().getDescription());
            }
            if (!MagicBranch.isMagicBranch(refName) && !refName.startsWith(REFS_CHANGES)) {
                // We only fire gitRefUpdated for direct refs updates.
                // Events for change refs are fired when they are created.
                // 
                gitRefUpdated.fire(project.getNameKey(), c, user.getAccount());
            }
        }
    }
    // Update superproject gitlinks if required.
    try (MergeOpRepoManager orm = ormProvider.get()) {
        orm.setContext(db, TimeUtil.nowTs(), user, "receiveID");
        SubmoduleOp op = subOpFactory.create(branches, orm);
        op.updateSuperProjects();
    } catch (SubmoduleException e) {
        log.error("Can't update the superprojects", e);
    }
    closeProgress.end();
    commandProgress.end();
    progress.end();
    reportMessages();
}
#method_after
void processCommands(Collection<ReceiveCommand> commands, MultiProgressMonitor progress) {
    newProgress = progress.beginSubTask("new", UNKNOWN);
    replaceProgress = progress.beginSubTask("updated", UNKNOWN);
    closeProgress = progress.beginSubTask("closed", UNKNOWN);
    commandProgress = progress.beginSubTask("refs", UNKNOWN);
    batch = repo.getRefDatabase().newBatchUpdate();
    batch.setPushCertificate(rp.getPushCertificate());
    batch.setRefLogIdent(rp.getRefLogIdent());
    batch.setRefLogMessage("push", true);
    parseCommands(commands);
    if (magicBranch != null && magicBranch.cmd.getResult() == NOT_ATTEMPTED) {
        selectNewAndReplacedChangesFromMagicBranch();
    }
    preparePatchSetsForReplace();
    logDebug("Executing batch with {} commands", batch.getCommands().size());
    if (!batch.getCommands().isEmpty()) {
        try {
            if (!batch.isAllowNonFastForwards() && magicBranch != null && magicBranch.edit) {
                logDebug("Allowing non-fast-forward for edit ref");
                batch.setAllowNonFastForwards(true);
            }
            batch.execute(rp.getRevWalk(), commandProgress);
        } catch (IOException err) {
            int cnt = 0;
            for (ReceiveCommand cmd : batch.getCommands()) {
                if (cmd.getResult() == NOT_ATTEMPTED) {
                    cmd.setResult(REJECTED_OTHER_REASON, "internal server error");
                    cnt++;
                }
            }
            logError(String.format("Failed to store %d refs in %s", cnt, project.getName()), err);
        }
    }
    insertChangesAndPatchSets();
    newProgress.end();
    replaceProgress.end();
    if (!errors.isEmpty()) {
        logDebug("Handling error conditions: {}", errors.keySet());
        for (Error error : errors.keySet()) {
            rp.sendMessage(buildError(error, errors.get(error)));
        }
        rp.sendMessage(String.format("User: %s", displayName(user)));
        rp.sendMessage(COMMAND_REJECTION_MESSAGE_FOOTER);
    }
    Set<Branch.NameKey> branches = new HashSet<>();
    for (ReceiveCommand c : batch.getCommands()) {
        if (c.getResult() == OK) {
            String refName = c.getRefName();
            if (c.getType() == ReceiveCommand.Type.UPDATE) {
                // aka fast-forward
                logDebug("Updating tag cache on fast-forward of {}", c.getRefName());
                tagCache.updateFastForward(project.getNameKey(), refName, c.getOldId(), c.getNewId());
            }
            if (isHead(c) || isConfig(c)) {
                switch(c.getType()) {
                    case CREATE:
                    case UPDATE:
                    case UPDATE_NONFASTFORWARD:
                        autoCloseChanges(c);
                        branches.add(new Branch.NameKey(project.getNameKey(), refName));
                        break;
                    case DELETE:
                        break;
                }
            }
            if (isConfig(c)) {
                logDebug("Reloading project in cache");
                projectCache.evict(project);
                ProjectState ps = projectCache.get(project.getNameKey());
                // 
                repoManager.setProjectDescription(// 
                project.getNameKey(), ps.getProject().getDescription());
            }
            if (!MagicBranch.isMagicBranch(refName) && !refName.startsWith(REFS_CHANGES)) {
                logDebug("Firing ref update for {}", c.getRefName());
                // We only fire gitRefUpdated for direct refs updates.
                // Events for change refs are fired when they are created.
                // 
                gitRefUpdated.fire(project.getNameKey(), c, user.getAccount());
            } else {
                logDebug("Assuming ref update event for {} has fired", c.getRefName());
            }
        }
    }
    // Update superproject gitlinks if required.
    try (MergeOpRepoManager orm = ormProvider.get()) {
        orm.setContext(db, TimeUtil.nowTs(), user, receiveId);
        SubmoduleOp op = subOpFactory.create(branches, orm);
        op.updateSuperProjects();
    } catch (SubmoduleException e) {
        logError("Can't update the superprojects", e);
    }
    closeProgress.end();
    commandProgress.end();
    progress.end();
    reportMessages();
}
#end_block

#method_before
private void reportMessages() {
    Iterable<CreateRequest> created = Iterables.filter(newChanges, new Predicate<CreateRequest>() {

        @Override
        public boolean apply(CreateRequest input) {
            return input.change != null;
        }
    });
    if (!Iterables.isEmpty(created)) {
        addMessage("");
        addMessage("New Changes:");
        for (CreateRequest c : created) {
            addMessage(formatChangeUrl(canonicalWebUrl, c.change, c.change.getSubject(), false));
        }
        addMessage("");
    }
    List<ReplaceRequest> updated = FluentIterable.from(replaceByChange.values()).filter(new Predicate<ReplaceRequest>() {

        @Override
        public boolean apply(ReplaceRequest input) {
            return !input.skip && input.inputCommand.getResult() == OK;
        }
    }).toSortedList(Ordering.natural().onResultOf(new Function<ReplaceRequest, Integer>() {

        @Override
        public Integer apply(ReplaceRequest in) {
            return in.notes.getChangeId().get();
        }
    }));
    if (!updated.isEmpty()) {
        addMessage("");
        addMessage("Updated Changes:");
        boolean edit = magicBranch != null && magicBranch.edit;
        for (ReplaceRequest u : updated) {
            String subject;
            if (edit) {
                try {
                    subject = rp.getRevWalk().parseCommit(u.newCommitId).getShortMessage();
                } catch (IOException e) {
                    // Log and fall back to original change subject
                    log.warn("failed to get subject for edit patch set", e);
                    subject = u.notes.getChange().getSubject();
                }
            } else {
                subject = u.info.getSubject();
            }
            addMessage(formatChangeUrl(canonicalWebUrl, u.notes.getChange(), subject, edit));
        }
        addMessage("");
    }
}
#method_after
private void reportMessages() {
    Iterable<CreateRequest> created = Iterables.filter(newChanges, new Predicate<CreateRequest>() {

        @Override
        public boolean apply(CreateRequest input) {
            return input.change != null;
        }
    });
    if (!Iterables.isEmpty(created)) {
        addMessage("");
        addMessage("New Changes:");
        for (CreateRequest c : created) {
            addMessage(formatChangeUrl(canonicalWebUrl, c.change, c.change.getSubject(), c.change.getStatus() == Change.Status.DRAFT, false));
        }
        addMessage("");
    }
    List<ReplaceRequest> updated = FluentIterable.from(replaceByChange.values()).filter(new Predicate<ReplaceRequest>() {

        @Override
        public boolean apply(ReplaceRequest input) {
            return !input.skip && input.inputCommand.getResult() == OK;
        }
    }).toSortedList(Ordering.natural().onResultOf(new Function<ReplaceRequest, Integer>() {

        @Override
        public Integer apply(ReplaceRequest in) {
            return in.notes.getChangeId().get();
        }
    }));
    if (!updated.isEmpty()) {
        addMessage("");
        addMessage("Updated Changes:");
        boolean edit = magicBranch != null && magicBranch.edit;
        for (ReplaceRequest u : updated) {
            String subject;
            if (edit) {
                try {
                    subject = rp.getRevWalk().parseCommit(u.newCommitId).getShortMessage();
                } catch (IOException e) {
                    // Log and fall back to original change subject
                    logWarn("failed to get subject for edit patch set", e);
                    subject = u.notes.getChange().getSubject();
                }
            } else {
                subject = u.info.getSubject();
            }
            addMessage(formatChangeUrl(canonicalWebUrl, u.notes.getChange(), subject, u.replaceOp != null && u.replaceOp.getPatchSet().isDraft(), edit));
        }
        addMessage("");
    }
}
#end_block

#method_before
private static String formatChangeUrl(String url, Change change, String subject, boolean edit) {
    StringBuilder m = new StringBuilder().append("  ").append(url).append(change.getChangeId()).append(" ").append(ChangeUtil.cropSubject(subject));
    if (change.getStatus() == Change.Status.DRAFT) {
        m.append(" [DRAFT]");
    }
    if (edit) {
        m.append(" [EDIT]");
    }
    return m.toString();
}
#method_after
private static String formatChangeUrl(String url, Change change, String subject, boolean draft, boolean edit) {
    StringBuilder m = new StringBuilder().append("  ").append(url).append(change.getChangeId()).append(" ").append(ChangeUtil.cropSubject(subject));
    if (draft) {
        m.append(" [DRAFT]");
    }
    if (edit) {
        m.append(" [EDIT]");
    }
    return m.toString();
}
#end_block

#method_before
private void insertChangesAndPatchSets() {
    int replaceCount = 0;
    int okToInsert = 0;
    for (Map.Entry<Change.Id, ReplaceRequest> e : replaceByChange.entrySet()) {
        ReplaceRequest replace = e.getValue();
        if (magicBranch != null && replace.inputCommand == magicBranch.cmd) {
            replaceCount++;
            if (replace.cmd != null && replace.cmd.getResult() == OK) {
                okToInsert++;
            }
        } else if (replace.cmd != null && replace.cmd.getResult() == OK) {
            checkState(NEW_PATCHSET.matcher(replace.inputCommand.getRefName()).matches(), "expected a new patch set command as input when creating %s;" + " got %s", replace.cmd.getRefName(), replace.inputCommand.getRefName());
            try {
                replace.insertPatchSetWithoutBatchUpdate();
                replace.inputCommand.setResult(OK);
            } catch (IOException | UpdateException | RestApiException err) {
                reject(replace.inputCommand, "internal server error");
                log.error(String.format("Cannot add patch set to change %d in project %s", e.getKey().get(), project.getName()), err);
            }
        } else if (replace.inputCommand.getResult() == NOT_ATTEMPTED) {
            reject(replace.inputCommand, "internal server error");
            log.error(String.format("Replacement for project %s was not attempted", project.getName()));
        }
    }
    if (magicBranch == null || magicBranch.cmd.getResult() != NOT_ATTEMPTED) {
        // No need to continue.
        return;
    }
    List<String> lastCreateChangeErrors = new ArrayList<>();
    for (CreateRequest create : newChanges) {
        if (create.cmd.getResult() == OK) {
            okToInsert++;
        } else {
            String createChangeResult = String.format("%s %s", create.cmd.getResult(), Strings.nullToEmpty(create.cmd.getMessage())).trim();
            lastCreateChangeErrors.add(createChangeResult);
            log.error(String.format("Command %s on %s:%s not completed: %s", create.cmd.getType(), project.getName(), create.cmd.getRefName(), createChangeResult));
        }
    }
    if (okToInsert != replaceCount + newChanges.size()) {
        // One or more new references failed to create. Assume the
        // system isn't working correctly anymore and abort.
        reject(magicBranch.cmd, "Unable to create changes: " + Joiner.on(' ').join(lastCreateChangeErrors));
        log.error(String.format("Only %d of %d new change refs created in %s; aborting", okToInsert, replaceCount + newChanges.size(), project.getName()));
        return;
    }
    try (BatchUpdate bu = batchUpdateFactory.create(db, magicBranch.dest.getParentKey(), user, TimeUtil.nowTs());
        ObjectInserter ins = repo.newObjectInserter()) {
        bu.setRepository(repo, rp.getRevWalk(), ins).updateChangesInParallel();
        for (ReplaceRequest replace : replaceByChange.values()) {
            if (replace.inputCommand == magicBranch.cmd) {
                replace.addOps(bu, replaceProgress);
            }
        }
        for (CreateRequest create : newChanges) {
            create.addOps(bu);
        }
        for (UpdateGroupsRequest update : updateGroups) {
            update.addOps(bu);
        }
        try {
            bu.execute();
        } catch (UpdateException e) {
            throw INSERT_EXCEPTION.apply(e);
        }
        magicBranch.cmd.setResult(OK);
        for (ReplaceRequest replace : replaceByChange.values()) {
            String rejectMessage = replace.getRejectMessage();
            if (rejectMessage != null) {
                reject(replace.inputCommand, rejectMessage);
            }
        }
    } catch (ResourceConflictException e) {
        addMessage(e.getMessage());
        reject(magicBranch.cmd, "conflict");
    } catch (RestApiException | IOException err) {
        log.error("Can't insert change/patch set for " + project.getName(), err);
        reject(magicBranch.cmd, "internal server error: " + err.getMessage());
    }
    if (magicBranch != null && magicBranch.submit) {
        try {
            submit(newChanges, replaceByChange.values());
        } catch (ResourceConflictException e) {
            addMessage(e.getMessage());
            reject(magicBranch.cmd, "conflict");
        } catch (RestApiException | OrmException e) {
            log.error("Error submit changes to " + project.getName(), e);
            reject(magicBranch.cmd, "error during submit");
        }
    }
}
#method_after
private void insertChangesAndPatchSets() {
    int replaceCount = 0;
    int okToInsert = 0;
    for (Map.Entry<Change.Id, ReplaceRequest> e : replaceByChange.entrySet()) {
        ReplaceRequest replace = e.getValue();
        if (magicBranch != null && replace.inputCommand == magicBranch.cmd) {
            replaceCount++;
            if (replace.cmd != null && replace.cmd.getResult() == OK) {
                okToInsert++;
            }
        } else if (replace.cmd != null && replace.cmd.getResult() == OK) {
            String refName = replace.inputCommand.getRefName();
            checkState(NEW_PATCHSET.matcher(refName).matches(), "expected a new patch set command as input when creating %s;" + " got %s", replace.cmd.getRefName(), refName);
            try {
                logDebug("One-off insertion of patch set for {}", refName);
                replace.insertPatchSetWithoutBatchUpdate();
                replace.inputCommand.setResult(OK);
            } catch (IOException | UpdateException | RestApiException err) {
                reject(replace.inputCommand, "internal server error");
                logError(String.format("Cannot add patch set to change %d in project %s", e.getKey().get(), project.getName()), err);
            }
        } else if (replace.inputCommand.getResult() == NOT_ATTEMPTED) {
            reject(replace.inputCommand, "internal server error");
            logError(String.format("Replacement for project %s was not attempted", project.getName()));
        }
    }
    // No need to continue.
    if (magicBranch == null) {
        logDebug("No magic branch, nothing more to do");
        return;
    } else if (magicBranch.cmd.getResult() != NOT_ATTEMPTED) {
        logWarn(String.format("Skipping change updates on %s because ref update failed: %s %s", project.getName(), magicBranch.cmd.getResult(), Strings.nullToEmpty(magicBranch.cmd.getMessage())));
        return;
    }
    List<String> lastCreateChangeErrors = new ArrayList<>();
    for (CreateRequest create : newChanges) {
        if (create.cmd.getResult() == OK) {
            okToInsert++;
        } else {
            String createChangeResult = String.format("%s %s", create.cmd.getResult(), Strings.nullToEmpty(create.cmd.getMessage())).trim();
            lastCreateChangeErrors.add(createChangeResult);
            logError(String.format("Command %s on %s:%s not completed: %s", create.cmd.getType(), project.getName(), create.cmd.getRefName(), createChangeResult));
        }
    }
    logDebug("Counted {} ok to insert, out of {} to replace and {} new", okToInsert, replaceCount, newChanges.size());
    if (okToInsert != replaceCount + newChanges.size()) {
        // One or more new references failed to create. Assume the
        // system isn't working correctly anymore and abort.
        reject(magicBranch.cmd, "Unable to create changes: " + Joiner.on(' ').join(lastCreateChangeErrors));
        logError(String.format("Only %d of %d new change refs created in %s; aborting", okToInsert, replaceCount + newChanges.size(), project.getName()));
        return;
    }
    try (BatchUpdate bu = batchUpdateFactory.create(db, magicBranch.dest.getParentKey(), user, TimeUtil.nowTs());
        ObjectInserter ins = repo.newObjectInserter()) {
        bu.setRepository(repo, rp.getRevWalk(), ins).updateChangesInParallel();
        bu.setRequestId(receiveId);
        for (ReplaceRequest replace : replaceByChange.values()) {
            if (replace.inputCommand == magicBranch.cmd) {
                replace.addOps(bu, replaceProgress);
            }
        }
        for (CreateRequest create : newChanges) {
            create.addOps(bu);
        }
        for (UpdateGroupsRequest update : updateGroups) {
            update.addOps(bu);
        }
        logDebug("Executing batch");
        try {
            bu.execute();
        } catch (UpdateException e) {
            throw INSERT_EXCEPTION.apply(e);
        }
        magicBranch.cmd.setResult(OK);
        for (ReplaceRequest replace : replaceByChange.values()) {
            String rejectMessage = replace.getRejectMessage();
            if (rejectMessage != null) {
                logDebug("Rejecting due to message from ReplaceOp");
                reject(replace.inputCommand, rejectMessage);
            }
        }
    } catch (ResourceConflictException e) {
        addMessage(e.getMessage());
        reject(magicBranch.cmd, "conflict");
    } catch (RestApiException | IOException err) {
        logError("Can't insert change/patch set for " + project.getName(), err);
        reject(magicBranch.cmd, "internal server error: " + err.getMessage());
    }
    if (magicBranch != null && magicBranch.submit) {
        try {
            submit(newChanges, replaceByChange.values());
        } catch (ResourceConflictException e) {
            addMessage(e.getMessage());
            reject(magicBranch.cmd, "conflict");
        } catch (RestApiException | OrmException e) {
            logError("Error submitting changes to " + project.getName(), e);
            reject(magicBranch.cmd, "error during submit");
        }
    }
}
#end_block

#method_before
private void parseCommands(Collection<ReceiveCommand> commands) {
    for (ReceiveCommand cmd : commands) {
        if (cmd.getResult() != NOT_ATTEMPTED) {
            // 
            continue;
        }
        if (!Repository.isValidRefName(cmd.getRefName()) || cmd.getRefName().contains("//")) {
            reject(cmd, "not valid ref");
            continue;
        }
        if (MagicBranch.isMagicBranch(cmd.getRefName())) {
            parseMagicBranch(cmd);
            continue;
        }
        if (projectControl.getProjectState().isAllUsers() && RefNames.REFS_USERS_SELF.equals(cmd.getRefName())) {
            final ReceiveCommand orgCmd = cmd;
            cmd = new ReceiveCommand(cmd.getOldId(), cmd.getNewId(), RefNames.refsUsers(user.getAccountId()), cmd.getType()) {

                @Override
                public void setResult(Result s, String m) {
                    super.setResult(s, m);
                    orgCmd.setResult(s, m);
                }
            };
        }
        Matcher m = NEW_PATCHSET.matcher(cmd.getRefName());
        if (m.matches()) {
            // The referenced change must exist and must still be open.
            // 
            Change.Id changeId = Change.Id.parse(m.group(1));
            parseReplaceCommand(cmd, changeId);
            continue;
        }
        switch(cmd.getType()) {
            case CREATE:
                parseCreate(cmd);
                break;
            case UPDATE:
                parseUpdate(cmd);
                break;
            case DELETE:
                parseDelete(cmd);
                break;
            case UPDATE_NONFASTFORWARD:
                parseRewind(cmd);
                break;
            default:
                reject(cmd);
                continue;
        }
        if (cmd.getResult() != NOT_ATTEMPTED) {
            continue;
        }
        if (isConfig(cmd)) {
            if (!projectControl.isOwner()) {
                reject(cmd, "not project owner");
                continue;
            }
            switch(cmd.getType()) {
                case CREATE:
                case UPDATE:
                case UPDATE_NONFASTFORWARD:
                    try {
                        ProjectConfig cfg = new ProjectConfig(project.getNameKey());
                        cfg.load(rp.getRevWalk(), cmd.getNewId());
                        if (!cfg.getValidationErrors().isEmpty()) {
                            addError("Invalid project configuration:");
                            for (ValidationError err : cfg.getValidationErrors()) {
                                addError("  " + err.getMessage());
                            }
                            reject(cmd, "invalid project configuration");
                            log.error("User " + user.getUserName() + " tried to push invalid project configuration " + cmd.getNewId().name() + " for " + project.getName());
                            continue;
                        }
                        Project.NameKey newParent = cfg.getProject().getParent(allProjectsName);
                        Project.NameKey oldParent = project.getParent(allProjectsName);
                        if (oldParent == null) {
                            // update of the 'All-Projects' project
                            if (newParent != null) {
                                reject(cmd, "invalid project configuration: root project cannot have parent");
                                continue;
                            }
                        } else {
                            if (!oldParent.equals(newParent) && !user.getCapabilities().canAdministrateServer()) {
                                reject(cmd, "invalid project configuration: only Gerrit admin can set parent");
                                continue;
                            }
                            if (projectCache.get(newParent) == null) {
                                reject(cmd, "invalid project configuration: parent does not exist");
                                continue;
                            }
                        }
                        for (Entry<ProjectConfigEntry> e : pluginConfigEntries) {
                            PluginConfig pluginCfg = cfg.getPluginConfig(e.getPluginName());
                            ProjectConfigEntry configEntry = e.getProvider().get();
                            String value = pluginCfg.getString(e.getExportName());
                            String oldValue = projectControl.getProjectState().getConfig().getPluginConfig(e.getPluginName()).getString(e.getExportName());
                            if (configEntry.getType() == ProjectConfigEntryType.ARRAY) {
                                List<String> l = Arrays.asList(projectControl.getProjectState().getConfig().getPluginConfig(e.getPluginName()).getStringList(e.getExportName()));
                                oldValue = Joiner.on("\n").join(l);
                            }
                            if ((value == null ? oldValue != null : !value.equals(oldValue)) && !configEntry.isEditable(projectControl.getProjectState())) {
                                reject(cmd, String.format("invalid project configuration: Not allowed to set parameter" + " '%s' of plugin '%s' on project '%s'.", e.getExportName(), e.getPluginName(), project.getName()));
                                continue;
                            }
                            if (ProjectConfigEntryType.LIST.equals(configEntry.getType()) && value != null && !configEntry.getPermittedValues().contains(value)) {
                                reject(cmd, String.format("invalid project configuration: The value '%s' is " + "not permitted for parameter '%s' of plugin '%s'.", value, e.getExportName(), e.getPluginName()));
                            }
                        }
                    } catch (Exception e) {
                        reject(cmd, "invalid project configuration");
                        log.error("User " + user.getUserName() + " tried to push invalid project configuration " + cmd.getNewId().name() + " for " + project.getName(), e);
                        continue;
                    }
                    break;
                case DELETE:
                    break;
                default:
                    reject(cmd);
                    continue;
            }
        }
    }
}
#method_after
private void parseCommands(Collection<ReceiveCommand> commands) {
    List<String> optionList = rp.getPushOptions();
    if (optionList != null) {
        for (String option : optionList) {
            int e = option.indexOf('=');
            if (e > 0) {
                pushOptions.put(option.substring(0, e), option.substring(e + 1));
            } else {
                pushOptions.put(option, "");
            }
        }
    }
    logDebug("Parsing {} commands", commands.size());
    for (ReceiveCommand cmd : commands) {
        if (cmd.getResult() != NOT_ATTEMPTED) {
            // Already rejected by the core receive process.
            logDebug("Already processed by core: {} {}", cmd.getResult(), cmd);
            continue;
        }
        if (!Repository.isValidRefName(cmd.getRefName()) || cmd.getRefName().contains("//")) {
            reject(cmd, "not valid ref");
            continue;
        }
        if (MagicBranch.isMagicBranch(cmd.getRefName())) {
            parseMagicBranch(cmd);
            continue;
        }
        if (projectControl.getProjectState().isAllUsers() && RefNames.REFS_USERS_SELF.equals(cmd.getRefName())) {
            String newName = RefNames.refsUsers(user.getAccountId());
            logDebug("Swapping out command for {} to {}", RefNames.REFS_USERS_SELF, newName);
            final ReceiveCommand orgCmd = cmd;
            cmd = new ReceiveCommand(cmd.getOldId(), cmd.getNewId(), newName, cmd.getType()) {

                @Override
                public void setResult(Result s, String m) {
                    super.setResult(s, m);
                    orgCmd.setResult(s, m);
                }
            };
        }
        Matcher m = NEW_PATCHSET.matcher(cmd.getRefName());
        if (m.matches()) {
            // The referenced change must exist and must still be open.
            // 
            Change.Id changeId = Change.Id.parse(m.group(1));
            parseReplaceCommand(cmd, changeId);
            continue;
        }
        switch(cmd.getType()) {
            case CREATE:
                parseCreate(cmd);
                break;
            case UPDATE:
                parseUpdate(cmd);
                break;
            case DELETE:
                parseDelete(cmd);
                break;
            case UPDATE_NONFASTFORWARD:
                parseRewind(cmd);
                break;
            default:
                reject(cmd);
                continue;
        }
        if (cmd.getResult() != NOT_ATTEMPTED) {
            continue;
        }
        if (isConfig(cmd)) {
            logDebug("Processing {} command", cmd.getRefName());
            if (!projectControl.isOwner()) {
                reject(cmd, "not project owner");
                continue;
            }
            switch(cmd.getType()) {
                case CREATE:
                case UPDATE:
                case UPDATE_NONFASTFORWARD:
                    try {
                        ProjectConfig cfg = new ProjectConfig(project.getNameKey());
                        cfg.load(rp.getRevWalk(), cmd.getNewId());
                        if (!cfg.getValidationErrors().isEmpty()) {
                            addError("Invalid project configuration:");
                            for (ValidationError err : cfg.getValidationErrors()) {
                                addError("  " + err.getMessage());
                            }
                            reject(cmd, "invalid project configuration");
                            logError("User " + user.getUserName() + " tried to push invalid project configuration " + cmd.getNewId().name() + " for " + project.getName());
                            continue;
                        }
                        Project.NameKey newParent = cfg.getProject().getParent(allProjectsName);
                        Project.NameKey oldParent = project.getParent(allProjectsName);
                        if (oldParent == null) {
                            // update of the 'All-Projects' project
                            if (newParent != null) {
                                reject(cmd, "invalid project configuration: root project cannot have parent");
                                continue;
                            }
                        } else {
                            if (!oldParent.equals(newParent) && !user.getCapabilities().canAdministrateServer()) {
                                reject(cmd, "invalid project configuration: only Gerrit admin can set parent");
                                continue;
                            }
                            if (projectCache.get(newParent) == null) {
                                reject(cmd, "invalid project configuration: parent does not exist");
                                continue;
                            }
                        }
                        for (Entry<ProjectConfigEntry> e : pluginConfigEntries) {
                            PluginConfig pluginCfg = cfg.getPluginConfig(e.getPluginName());
                            ProjectConfigEntry configEntry = e.getProvider().get();
                            String value = pluginCfg.getString(e.getExportName());
                            String oldValue = projectControl.getProjectState().getConfig().getPluginConfig(e.getPluginName()).getString(e.getExportName());
                            if (configEntry.getType() == ProjectConfigEntryType.ARRAY) {
                                List<String> l = Arrays.asList(projectControl.getProjectState().getConfig().getPluginConfig(e.getPluginName()).getStringList(e.getExportName()));
                                oldValue = Joiner.on("\n").join(l);
                            }
                            if ((value == null ? oldValue != null : !value.equals(oldValue)) && !configEntry.isEditable(projectControl.getProjectState())) {
                                reject(cmd, String.format("invalid project configuration: Not allowed to set parameter" + " '%s' of plugin '%s' on project '%s'.", e.getExportName(), e.getPluginName(), project.getName()));
                                continue;
                            }
                            if (ProjectConfigEntryType.LIST.equals(configEntry.getType()) && value != null && !configEntry.getPermittedValues().contains(value)) {
                                reject(cmd, String.format("invalid project configuration: The value '%s' is " + "not permitted for parameter '%s' of plugin '%s'.", value, e.getExportName(), e.getPluginName()));
                            }
                        }
                    } catch (Exception e) {
                        reject(cmd, "invalid project configuration");
                        logError("User " + user.getUserName() + " tried to push invalid project configuration " + cmd.getNewId().name() + " for " + project.getName(), e);
                        continue;
                    }
                    break;
                case DELETE:
                    break;
                default:
                    reject(cmd);
                    continue;
            }
        }
    }
}
#end_block

#method_before
private void parseCreate(ReceiveCommand cmd) {
    RevObject obj;
    try {
        obj = rp.getRevWalk().parseAny(cmd.getNewId());
    } catch (IOException err) {
        log.error("Invalid object " + cmd.getNewId().name() + " for " + cmd.getRefName() + " creation", err);
        reject(cmd, "invalid object");
        return;
    }
    if (isHead(cmd) && !isCommit(cmd)) {
        return;
    }
    RefControl ctl = projectControl.controlForRef(cmd.getRefName());
    if (ctl.canCreate(db, rp.getRepository(), obj)) {
        validateNewCommits(ctl, cmd);
        batch.addCommand(cmd);
    } else {
        reject(cmd);
    }
}
#method_after
private void parseCreate(ReceiveCommand cmd) {
    RevObject obj;
    try {
        obj = rp.getRevWalk().parseAny(cmd.getNewId());
    } catch (IOException err) {
        logError("Invalid object " + cmd.getNewId().name() + " for " + cmd.getRefName() + " creation", err);
        reject(cmd, "invalid object");
        return;
    }
    logDebug("Creating {}", cmd);
    if (isHead(cmd) && !isCommit(cmd)) {
        return;
    }
    RefControl ctl = projectControl.controlForRef(cmd.getRefName());
    if (ctl.canCreate(db, rp.getRepository(), obj)) {
        if (!validRefOperation(cmd)) {
            return;
        }
        validateNewCommits(ctl, cmd);
        batch.addCommand(cmd);
    } else {
        reject(cmd);
    }
}
#end_block

#method_before
private void parseUpdate(ReceiveCommand cmd) {
    RefControl ctl = projectControl.controlForRef(cmd.getRefName());
    if (ctl.canUpdate()) {
        if (isHead(cmd) && !isCommit(cmd)) {
            return;
        }
        validateNewCommits(ctl, cmd);
        batch.addCommand(cmd);
    } else {
        if (RefNames.REFS_CONFIG.equals(ctl.getRefName())) {
            errors.put(Error.CONFIG_UPDATE, RefNames.REFS_CONFIG);
        } else {
            errors.put(Error.UPDATE, ctl.getRefName());
        }
        reject(cmd);
    }
}
#method_after
private void parseUpdate(ReceiveCommand cmd) {
    logDebug("Updating {}", cmd);
    RefControl ctl = projectControl.controlForRef(cmd.getRefName());
    if (ctl.canUpdate()) {
        if (isHead(cmd) && !isCommit(cmd)) {
            return;
        }
        if (!validRefOperation(cmd)) {
            return;
        }
        validateNewCommits(ctl, cmd);
        batch.addCommand(cmd);
    } else {
        if (RefNames.REFS_CONFIG.equals(ctl.getRefName())) {
            errors.put(Error.CONFIG_UPDATE, RefNames.REFS_CONFIG);
        } else {
            errors.put(Error.UPDATE, ctl.getRefName());
        }
        reject(cmd);
    }
}
#end_block

#method_before
private boolean isCommit(ReceiveCommand cmd) {
    RevObject obj;
    try {
        obj = rp.getRevWalk().parseAny(cmd.getNewId());
    } catch (IOException err) {
        log.error("Invalid object " + cmd.getNewId().name() + " for " + cmd.getRefName(), err);
        reject(cmd, "invalid object");
        return false;
    }
    if (obj instanceof RevCommit) {
        return true;
    }
    reject(cmd, "not a commit");
    return false;
}
#method_after
private boolean isCommit(ReceiveCommand cmd) {
    RevObject obj;
    try {
        obj = rp.getRevWalk().parseAny(cmd.getNewId());
    } catch (IOException err) {
        logError("Invalid object " + cmd.getNewId().name() + " for " + cmd.getRefName(), err);
        reject(cmd, "invalid object");
        return false;
    }
    if (obj instanceof RevCommit) {
        return true;
    }
    reject(cmd, "not a commit");
    return false;
}
#end_block

#method_before
private void parseDelete(ReceiveCommand cmd) {
    RefControl ctl = projectControl.controlForRef(cmd.getRefName());
    if (ctl.getRefName().startsWith(REFS_CHANGES)) {
        errors.put(Error.DELETE_CHANGES, ctl.getRefName());
        reject(cmd, "cannot delete changes");
    } else if (ctl.canDelete()) {
        batch.addCommand(cmd);
    } else {
        if (RefNames.REFS_CONFIG.equals(ctl.getRefName())) {
            reject(cmd, "cannot delete project configuration");
        } else {
            errors.put(Error.DELETE, ctl.getRefName());
            reject(cmd, "cannot delete references");
        }
    }
}
#method_after
private void parseDelete(ReceiveCommand cmd) {
    logDebug("Deleting {}", cmd);
    RefControl ctl = projectControl.controlForRef(cmd.getRefName());
    if (ctl.getRefName().startsWith(REFS_CHANGES)) {
        errors.put(Error.DELETE_CHANGES, ctl.getRefName());
        reject(cmd, "cannot delete changes");
    } else if (ctl.canDelete()) {
        if (!validRefOperation(cmd)) {
            return;
        }
        batch.addCommand(cmd);
    } else {
        if (RefNames.REFS_CONFIG.equals(ctl.getRefName())) {
            reject(cmd, "cannot delete project configuration");
        } else {
            errors.put(Error.DELETE, ctl.getRefName());
            reject(cmd, "cannot delete references");
        }
    }
}
#end_block

#method_before
private void parseRewind(ReceiveCommand cmd) {
    RevCommit newObject;
    try {
        newObject = rp.getRevWalk().parseCommit(cmd.getNewId());
    } catch (IncorrectObjectTypeException notCommit) {
        newObject = null;
    } catch (IOException err) {
        log.error("Invalid object " + cmd.getNewId().name() + " for " + cmd.getRefName() + " forced update", err);
        reject(cmd, "invalid object");
        return;
    }
    RefControl ctl = projectControl.controlForRef(cmd.getRefName());
    if (newObject != null) {
        validateNewCommits(ctl, cmd);
        if (cmd.getResult() != NOT_ATTEMPTED) {
            return;
        }
    }
    if (ctl.canForceUpdate()) {
        batch.setAllowNonFastForwards(true).addCommand(cmd);
    } else {
        cmd.setResult(REJECTED_NONFASTFORWARD, " need '" + PermissionRule.FORCE_PUSH + "' privilege.");
    }
}
#method_after
private void parseRewind(ReceiveCommand cmd) {
    RevCommit newObject;
    try {
        newObject = rp.getRevWalk().parseCommit(cmd.getNewId());
    } catch (IncorrectObjectTypeException notCommit) {
        newObject = null;
    } catch (IOException err) {
        logError("Invalid object " + cmd.getNewId().name() + " for " + cmd.getRefName() + " forced update", err);
        reject(cmd, "invalid object");
        return;
    }
    logDebug("Rewinding {}", cmd);
    RefControl ctl = projectControl.controlForRef(cmd.getRefName());
    if (newObject != null) {
        validateNewCommits(ctl, cmd);
        if (cmd.getResult() != NOT_ATTEMPTED) {
            return;
        }
    }
    if (ctl.canForceUpdate()) {
        if (!validRefOperation(cmd)) {
            return;
        }
        batch.setAllowNonFastForwards(true).addCommand(cmd);
    } else {
        cmd.setResult(REJECTED_NONFASTFORWARD, " need '" + PermissionRule.FORCE_PUSH + "' privilege.");
    }
}
#end_block

#method_before
String parse(CmdLineParser clp, Repository repo, Set<String> refs) throws CmdLineException {
    String ref = RefNames.fullName(MagicBranch.getDestBranchName(cmd.getRefName()));
    int optionStart = ref.indexOf('%');
    if (0 < optionStart) {
        ListMultimap<String, String> options = LinkedListMultimap.create();
        for (String s : COMMAS.split(ref.substring(optionStart + 1))) {
            int e = s.indexOf('=');
            if (0 < e) {
                options.put(s.substring(0, e), s.substring(e + 1));
            } else {
                options.put(s, "");
            }
        }
        clp.parseOptionMap(options);
        ref = ref.substring(0, optionStart);
    }
    // Split the destination branch by branch and topic. The topic
    // suffix is entirely optional, so it might not even exist.
    String head = readHEAD(repo);
    int split = ref.length();
    for (; ; ) {
        String name = ref.substring(0, split);
        if (refs.contains(name) || name.equals(head)) {
            break;
        }
        split = name.lastIndexOf('/', split - 1);
        if (split <= Constants.R_REFS.length()) {
            return ref;
        }
    }
    if (split < ref.length()) {
        topic = Strings.emptyToNull(ref.substring(split + 1));
    }
    return ref.substring(0, split);
}
#method_after
String parse(CmdLineParser clp, Repository repo, Set<String> refs, ListMultimap<String, String> pushOptions) throws CmdLineException {
    String ref = RefNames.fullName(MagicBranch.getDestBranchName(cmd.getRefName()));
    ListMultimap<String, String> options = LinkedListMultimap.create(pushOptions);
    int optionStart = ref.indexOf('%');
    if (0 < optionStart) {
        for (String s : COMMAS.split(ref.substring(optionStart + 1))) {
            int e = s.indexOf('=');
            if (0 < e) {
                options.put(s.substring(0, e), s.substring(e + 1));
            } else {
                options.put(s, "");
            }
        }
        ref = ref.substring(0, optionStart);
    }
    if (!options.isEmpty()) {
        clp.parseOptionMap(options);
    }
    // Split the destination branch by branch and topic. The topic
    // suffix is entirely optional, so it might not even exist.
    String head = readHEAD(repo);
    int split = ref.length();
    for (; ; ) {
        String name = ref.substring(0, split);
        if (refs.contains(name) || name.equals(head)) {
            break;
        }
        split = name.lastIndexOf('/', split - 1);
        if (split <= Constants.R_REFS.length()) {
            return ref;
        }
    }
    if (split < ref.length()) {
        topic = Strings.emptyToNull(ref.substring(split + 1));
    }
    return ref.substring(0, split);
}
#end_block

#method_before
private void parseMagicBranch(ReceiveCommand cmd) {
    // Permit exactly one new change request per push.
    if (magicBranch != null) {
        reject(cmd, "duplicate request");
        return;
    }
    magicBranch = new MagicBranchInput(cmd, labelTypes, notesMigration);
    magicBranch.reviewer.addAll(reviewersFromCommandLine);
    magicBranch.cc.addAll(ccFromCommandLine);
    String ref;
    CmdLineParser clp = optionParserFactory.create(magicBranch);
    magicBranch.clp = clp;
    try {
        ListMultimap<String, String> options = LinkedListMultimap.create();
        for (String pushOption : pushOptions) {
            int e = pushOption.indexOf('=');
            if (0 < e) {
                options.put(pushOption.substring(0, e), pushOption.substring(e + 1));
            } else {
                options.put(pushOption, "");
            }
        }
        clp.parseOptionMap(options);
        ref = magicBranch.parse(clp, repo, rp.getAdvertisedRefs().keySet());
    } catch (CmdLineException e) {
        if (!clp.wasHelpRequestedByOption()) {
            reject(cmd, e.getMessage());
            return;
        }
        // never happen
        ref = null;
    }
    if (clp.wasHelpRequestedByOption()) {
        StringWriter w = new StringWriter();
        w.write("\nHelp for refs/for/branch:\n\n");
        clp.printUsage(w, null);
        addMessage(w.toString());
        reject(cmd, "see help");
        return;
    }
    if (projectControl.getProjectState().isAllUsers() && RefNames.REFS_USERS_SELF.equals(ref)) {
        ref = RefNames.refsUsers(user.getAccountId());
    }
    if (!rp.getAdvertisedRefs().containsKey(ref) && !ref.equals(readHEAD(repo))) {
        if (ref.startsWith(Constants.R_HEADS)) {
            String n = ref.substring(Constants.R_HEADS.length());
            reject(cmd, "branch " + n + " not found");
        } else {
            reject(cmd, ref + " not found");
        }
        return;
    }
    magicBranch.dest = new Branch.NameKey(project.getNameKey(), ref);
    magicBranch.ctl = projectControl.controlForRef(ref);
    if (!magicBranch.ctl.canWrite()) {
        reject(cmd, "project is read only");
        return;
    }
    if (magicBranch.draft) {
        if (!receiveConfig.allowDrafts) {
            errors.put(Error.CODE_REVIEW, ref);
            reject(cmd, "draft workflow is disabled");
            return;
        } else if (projectControl.controlForRef("refs/drafts/" + ref).isBlocked(Permission.PUSH)) {
            errors.put(Error.CODE_REVIEW, ref);
            reject(cmd, "cannot upload drafts");
            return;
        }
    }
    if (!magicBranch.ctl.canUpload()) {
        errors.put(Error.CODE_REVIEW, ref);
        reject(cmd, "cannot upload review");
        return;
    }
    if (magicBranch.draft && magicBranch.submit) {
        reject(cmd, "cannot submit draft");
        return;
    }
    if (magicBranch.submit && !projectControl.controlForRef(MagicBranch.NEW_CHANGE + ref).canSubmit()) {
        reject(cmd, "submit not allowed");
        return;
    }
    RevWalk walk = rp.getRevWalk();
    RevCommit tip;
    try {
        tip = walk.parseCommit(magicBranch.cmd.getNewId());
    } catch (IOException ex) {
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        log.error("Invalid pack upload; one or more objects weren't sent", ex);
        return;
    }
    // if %base was specified, ignore newChangeForAllNotInTarget
    if (tip.getParentCount() > 1 || magicBranch.base != null || tip.getParentCount() == 0) {
        newChangeForAllNotInTarget = false;
    }
    if (magicBranch.base != null) {
        magicBranch.baseCommit = Lists.newArrayListWithCapacity(magicBranch.base.size());
        for (ObjectId id : magicBranch.base) {
            try {
                magicBranch.baseCommit.add(walk.parseCommit(id));
            } catch (IncorrectObjectTypeException notCommit) {
                reject(cmd, "base must be a commit");
                return;
            } catch (MissingObjectException e) {
                reject(cmd, "base not found");
                return;
            } catch (IOException e) {
                log.warn(String.format("Project %s cannot read %s", project.getName(), id.name()), e);
                reject(cmd, "internal server error");
                return;
            }
        }
    } else if (newChangeForAllNotInTarget) {
        String destBranch = magicBranch.dest.get();
        try {
            Ref r = repo.getRefDatabase().exactRef(destBranch);
            if (r == null) {
                reject(cmd, destBranch + " not found");
                return;
            }
            ObjectId baseHead = r.getObjectId();
            magicBranch.baseCommit = Collections.singletonList(walk.parseCommit(baseHead));
        } catch (IOException ex) {
            log.warn(String.format("Project %s cannot read %s", project.getName(), destBranch), ex);
            reject(cmd, "internal server error");
            return;
        }
    }
    // 
    try {
        Ref targetRef = rp.getAdvertisedRefs().get(magicBranch.ctl.getRefName());
        if (targetRef == null || targetRef.getObjectId() == null) {
            // is "connected" to the branch.
            return;
        }
        RevCommit h = walk.parseCommit(targetRef.getObjectId());
        RevFilter oldRevFilter = walk.getRevFilter();
        try {
            walk.reset();
            walk.setRevFilter(RevFilter.MERGE_BASE);
            walk.markStart(tip);
            walk.markStart(h);
            if (walk.next() == null) {
                reject(magicBranch.cmd, "no common ancestry");
            }
        } finally {
            walk.reset();
            walk.setRevFilter(oldRevFilter);
        }
    } catch (IOException e) {
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        log.error("Invalid pack upload; one or more objects weren't sent", e);
    }
}
#method_after
private void parseMagicBranch(ReceiveCommand cmd) {
    // Permit exactly one new change request per push.
    if (magicBranch != null) {
        reject(cmd, "duplicate request");
        return;
    }
    logDebug("Found magic branch {}", cmd.getRefName());
    magicBranch = new MagicBranchInput(cmd, labelTypes, notesMigration);
    magicBranch.reviewer.addAll(reviewersFromCommandLine);
    magicBranch.cc.addAll(ccFromCommandLine);
    String ref;
    CmdLineParser clp = optionParserFactory.create(magicBranch);
    magicBranch.clp = clp;
    try {
        ref = magicBranch.parse(clp, repo, rp.getAdvertisedRefs().keySet(), pushOptions);
    } catch (CmdLineException e) {
        if (!clp.wasHelpRequestedByOption()) {
            logDebug("Invalid branch syntax");
            reject(cmd, e.getMessage());
            return;
        }
        // never happen
        ref = null;
    }
    if (clp.wasHelpRequestedByOption()) {
        StringWriter w = new StringWriter();
        w.write("\nHelp for refs/for/branch:\n\n");
        clp.printUsage(w, null);
        addMessage(w.toString());
        reject(cmd, "see help");
        return;
    }
    if (projectControl.getProjectState().isAllUsers() && RefNames.REFS_USERS_SELF.equals(ref)) {
        logDebug("Handling {}", RefNames.REFS_USERS_SELF);
        ref = RefNames.refsUsers(user.getAccountId());
    }
    if (!rp.getAdvertisedRefs().containsKey(ref) && !ref.equals(readHEAD(repo))) {
        logDebug("Ref {} not found", ref);
        if (ref.startsWith(Constants.R_HEADS)) {
            String n = ref.substring(Constants.R_HEADS.length());
            reject(cmd, "branch " + n + " not found");
        } else {
            reject(cmd, ref + " not found");
        }
        return;
    }
    magicBranch.dest = new Branch.NameKey(project.getNameKey(), ref);
    magicBranch.ctl = projectControl.controlForRef(ref);
    if (!magicBranch.ctl.canWrite()) {
        reject(cmd, "project is read only");
        return;
    }
    if (magicBranch.draft) {
        if (!receiveConfig.allowDrafts) {
            errors.put(Error.CODE_REVIEW, ref);
            reject(cmd, "draft workflow is disabled");
            return;
        } else if (projectControl.controlForRef("refs/drafts/" + ref).isBlocked(Permission.PUSH)) {
            errors.put(Error.CODE_REVIEW, ref);
            reject(cmd, "cannot upload drafts");
            return;
        }
    }
    if (!magicBranch.ctl.canUpload()) {
        errors.put(Error.CODE_REVIEW, ref);
        reject(cmd, "cannot upload review");
        return;
    }
    if (magicBranch.draft && magicBranch.submit) {
        reject(cmd, "cannot submit draft");
        return;
    }
    if (magicBranch.submit && !projectControl.controlForRef(MagicBranch.NEW_CHANGE + ref).canSubmit()) {
        reject(cmd, "submit not allowed");
        return;
    }
    RevWalk walk = rp.getRevWalk();
    RevCommit tip;
    try {
        tip = walk.parseCommit(magicBranch.cmd.getNewId());
        logDebug("Tip of push: {}", tip.name());
    } catch (IOException ex) {
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", ex);
        return;
    }
    // if %base was specified, ignore newChangeForAllNotInTarget
    if (tip.getParentCount() > 1 || magicBranch.base != null || tip.getParentCount() == 0) {
        logDebug("Forcing newChangeForAllNotInTarget = false");
        newChangeForAllNotInTarget = false;
    }
    if (magicBranch.base != null) {
        logDebug("Handling %base: {}", magicBranch.base);
        magicBranch.baseCommit = Lists.newArrayListWithCapacity(magicBranch.base.size());
        for (ObjectId id : magicBranch.base) {
            try {
                magicBranch.baseCommit.add(walk.parseCommit(id));
            } catch (IncorrectObjectTypeException notCommit) {
                reject(cmd, "base must be a commit");
                return;
            } catch (MissingObjectException e) {
                reject(cmd, "base not found");
                return;
            } catch (IOException e) {
                logWarn(String.format("Project %s cannot read %s", project.getName(), id.name()), e);
                reject(cmd, "internal server error");
                return;
            }
        }
    } else if (newChangeForAllNotInTarget) {
        logDebug("Handling newChangeForAllNotInTarget");
        String destBranch = magicBranch.dest.get();
        try {
            Ref r = repo.getRefDatabase().exactRef(destBranch);
            if (r == null) {
                reject(cmd, destBranch + " not found");
                return;
            }
            ObjectId baseHead = r.getObjectId();
            magicBranch.baseCommit = Collections.singletonList(walk.parseCommit(baseHead));
            logDebug("Set baseCommit = {}", magicBranch.baseCommit.get(0).name());
        } catch (IOException ex) {
            logWarn(String.format("Project %s cannot read %s", project.getName(), destBranch), ex);
            reject(cmd, "internal server error");
            return;
        }
    }
    // 
    try {
        Ref targetRef = rp.getAdvertisedRefs().get(magicBranch.ctl.getRefName());
        if (targetRef == null || targetRef.getObjectId() == null) {
            // The destination branch does not yet exist. Assume the
            // history being sent for review will start it and thus
            // is "connected" to the branch.
            logDebug("Branch is unborn");
            return;
        }
        RevCommit h = walk.parseCommit(targetRef.getObjectId());
        logDebug("Current branch tip: {}", h.name());
        RevFilter oldRevFilter = walk.getRevFilter();
        try {
            walk.reset();
            walk.setRevFilter(RevFilter.MERGE_BASE);
            walk.markStart(tip);
            walk.markStart(h);
            if (walk.next() == null) {
                reject(magicBranch.cmd, "no common ancestry");
            }
        } finally {
            walk.reset();
            walk.setRevFilter(oldRevFilter);
        }
    } catch (IOException e) {
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", e);
    }
}
#end_block

#method_before
private void parseReplaceCommand(ReceiveCommand cmd, Change.Id changeId) {
    if (cmd.getType() != ReceiveCommand.Type.CREATE) {
        reject(cmd, "invalid usage");
        return;
    }
    RevCommit newCommit;
    try {
        newCommit = rp.getRevWalk().parseCommit(cmd.getNewId());
    } catch (IOException e) {
        log.error("Cannot parse " + cmd.getNewId().name() + " as commit", e);
        reject(cmd, "invalid commit");
        return;
    }
    Change changeEnt;
    try {
        changeEnt = notesFactory.createChecked(db, project.getNameKey(), changeId).getChange();
    } catch (OrmException e) {
        log.error("Cannot lookup existing change " + changeId, e);
        reject(cmd, "database error");
        return;
    } catch (NoSuchChangeException e) {
        log.error("Change not found " + changeId, e);
        reject(cmd, "change " + changeId + " not found");
        return;
    }
    if (!project.getNameKey().equals(changeEnt.getProject())) {
        reject(cmd, "change " + changeId + " does not belong to project " + project.getName());
        return;
    }
    requestReplace(cmd, true, changeEnt, newCommit);
}
#method_after
private void parseReplaceCommand(ReceiveCommand cmd, Change.Id changeId) {
    logDebug("Parsing replace command");
    if (cmd.getType() != ReceiveCommand.Type.CREATE) {
        reject(cmd, "invalid usage");
        return;
    }
    RevCommit newCommit;
    try {
        newCommit = rp.getRevWalk().parseCommit(cmd.getNewId());
        logDebug("Replacing with {}", newCommit);
    } catch (IOException e) {
        logError("Cannot parse " + cmd.getNewId().name() + " as commit", e);
        reject(cmd, "invalid commit");
        return;
    }
    Change changeEnt;
    try {
        changeEnt = notesFactory.createChecked(db, project.getNameKey(), changeId).getChange();
    } catch (OrmException e) {
        logError("Cannot lookup existing change " + changeId, e);
        reject(cmd, "database error");
        return;
    } catch (NoSuchChangeException e) {
        logError("Change not found " + changeId, e);
        reject(cmd, "change " + changeId + " not found");
        return;
    }
    if (!project.getNameKey().equals(changeEnt.getProject())) {
        reject(cmd, "change " + changeId + " does not belong to project " + project.getName());
        return;
    }
    logDebug("Replacing change {}", changeEnt.getId());
    requestReplace(cmd, true, changeEnt, newCommit);
}
#end_block

#method_before
private void selectNewAndReplacedChangesFromMagicBranch() {
    newChanges = new ArrayList<>();
    SetMultimap<ObjectId, Ref> existing = changeRefsById();
    GroupCollector groupCollector = GroupCollector.create(changeRefsById(), db, psUtil, notesFactory, project.getNameKey());
    rp.getRevWalk().reset();
    rp.getRevWalk().sort(RevSort.TOPO);
    rp.getRevWalk().sort(RevSort.REVERSE, true);
    try {
        rp.getRevWalk().markStart(rp.getRevWalk().parseCommit(magicBranch.cmd.getNewId()));
        if (magicBranch.baseCommit != null) {
            for (RevCommit c : magicBranch.baseCommit) {
                rp.getRevWalk().markUninteresting(c);
            }
            Ref targetRef = allRefs.get(magicBranch.ctl.getRefName());
            if (targetRef != null) {
                rp.getRevWalk().markUninteresting(rp.getRevWalk().parseCommit(targetRef.getObjectId()));
            }
        } else {
            markHeadsAsUninteresting(rp.getRevWalk(), magicBranch.ctl != null ? magicBranch.ctl.getRefName() : null);
        }
        List<ChangeLookup> pending = new ArrayList<>();
        Set<Change.Key> newChangeIds = new HashSet<>();
        int maxBatchChanges = receiveConfig.getEffectiveMaxBatchChangesLimit(user);
        for (; ; ) {
            RevCommit c = rp.getRevWalk().next();
            if (c == null) {
                break;
            }
            groupCollector.visit(c);
            Collection<Ref> existingRefs = existing.get(c);
            if (!existingRefs.isEmpty()) {
                // different target branch.
                for (Ref ref : existingRefs) {
                    updateGroups.add(new UpdateGroupsRequest(ref, c));
                }
                if (!(newChangeForAllNotInTarget || magicBranch.base != null)) {
                    continue;
                }
            }
            if (!validCommit(rp.getRevWalk(), magicBranch.ctl, magicBranch.cmd, c)) {
                // Not a change the user can propose? Abort as early as possible.
                newChanges = Collections.emptyList();
                return;
            }
            // Don't allow merges to be uploaded in commit chain via all-not-in-target
            if (newChangeForAllNotInTarget && c.getParentCount() > 1) {
                reject(magicBranch.cmd, "Pushing merges in commit chains with 'all not in target' is not allowed,\n" + "to override please set the base manually");
            }
            List<String> idList = c.getFooterLines(CHANGE_ID);
            if (idList.isEmpty()) {
                newChanges.add(new CreateRequest(c, magicBranch.dest.get()));
                continue;
            }
            String idStr = idList.get(idList.size() - 1).trim();
            if (idStr.matches("^I00*$")) {
                // Reject this invalid line from EGit.
                reject(magicBranch.cmd, "invalid Change-Id");
                newChanges = Collections.emptyList();
                return;
            }
            pending.add(new ChangeLookup(c, new Change.Key(idStr)));
            if (maxBatchChanges != 0 && pending.size() + newChanges.size() > maxBatchChanges) {
                reject(magicBranch.cmd, "the number of pushed changes in a batch exceeds the max limit " + maxBatchChanges);
                newChanges = Collections.emptyList();
                return;
            }
        }
        for (Iterator<ChangeLookup> itr = pending.iterator(); itr.hasNext(); ) {
            ChangeLookup p = itr.next();
            if (newChangeIds.contains(p.changeKey)) {
                reject(magicBranch.cmd, SAME_CHANGE_ID_IN_MULTIPLE_CHANGES);
                newChanges = Collections.emptyList();
                return;
            }
            List<ChangeData> changes = p.destChanges;
            if (changes.size() > 1) {
                // WTF, multiple changes in this project have the same key?
                // Since the commit is new, the user should recreate it with
                // a different Change-Id. In practice, we should never see
                // this error message as Change-Id should be unique.
                // 
                reject(magicBranch.cmd, p.changeKey.get() + " has duplicates");
                newChanges = Collections.emptyList();
                return;
            }
            if (changes.size() == 1) {
                // Schedule as a replacement to this one matching change.
                // 
                RevId currentPs = changes.get(0).currentPatchSet().getRevision();
                // If Commit is already current PatchSet of target Change.
                if (p.commit.name().equals(currentPs.get())) {
                    if (pending.size() == 1) {
                        // There are no commits left to check, all commits in pending were already
                        // current PatchSet of the corresponding target changes.
                        reject(magicBranch.cmd, "commit(s) already exists (as current patchset)");
                    } else {
                        // Commit is already current PatchSet.
                        // Remove from pending and try next commit.
                        itr.remove();
                        continue;
                    }
                }
                if (requestReplace(magicBranch.cmd, false, changes.get(0).change(), p.commit)) {
                    continue;
                }
                newChanges = Collections.emptyList();
                return;
            }
            if (changes.size() == 0) {
                if (!isValidChangeId(p.changeKey.get())) {
                    reject(magicBranch.cmd, "invalid Change-Id");
                    newChanges = Collections.emptyList();
                    return;
                }
                newChangeIds.add(p.changeKey);
            }
            newChanges.add(new CreateRequest(p.commit, magicBranch.dest.get()));
        }
    } catch (IOException e) {
        // Should never happen, the core receive process would have
        // identified the missing object earlier before we got control.
        // 
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        log.error("Invalid pack upload; one or more objects weren't sent", e);
        newChanges = Collections.emptyList();
        return;
    } catch (OrmException e) {
        log.error("Cannot query database to locate prior changes", e);
        reject(magicBranch.cmd, "database error");
        newChanges = Collections.emptyList();
        return;
    }
    if (newChanges.isEmpty() && replaceByChange.isEmpty()) {
        reject(magicBranch.cmd, "no new changes");
        return;
    }
    if (!newChanges.isEmpty() && magicBranch.edit) {
        reject(magicBranch.cmd, "edit is not supported for new changes");
        return;
    }
    try {
        SortedSetMultimap<ObjectId, String> groups = groupCollector.getGroups();
        List<Integer> newIds = seq.nextChangeIds(newChanges.size());
        for (int i = 0; i < newChanges.size(); i++) {
            CreateRequest create = newChanges.get(i);
            create.setChangeId(newIds.get(i));
            batch.addCommand(create.cmd);
            create.groups = ImmutableList.copyOf(groups.get(create.commit));
        }
        for (ReplaceRequest replace : replaceByChange.values()) {
            replace.groups = ImmutableList.copyOf(groups.get(replace.newCommitId));
        }
        for (UpdateGroupsRequest update : updateGroups) {
            update.groups = ImmutableList.copyOf((groups.get(update.commit)));
        }
    } catch (OrmException | NoSuchChangeException e) {
        log.error("Error collecting groups for changes", e);
        reject(magicBranch.cmd, "internal server error");
        return;
    }
}
#method_after
private void selectNewAndReplacedChangesFromMagicBranch() {
    logDebug("Finding new and replaced changes");
    newChanges = new ArrayList<>();
    SetMultimap<ObjectId, Ref> existing = changeRefsById();
    GroupCollector groupCollector = GroupCollector.create(changeRefsById(), db, psUtil, notesFactory, project.getNameKey());
    rp.getRevWalk().reset();
    rp.getRevWalk().sort(RevSort.TOPO);
    rp.getRevWalk().sort(RevSort.REVERSE, true);
    try {
        rp.getRevWalk().markStart(rp.getRevWalk().parseCommit(magicBranch.cmd.getNewId()));
        if (magicBranch.baseCommit != null) {
            logDebug("Marking {} base commits uninteresting", magicBranch.baseCommit.size());
            for (RevCommit c : magicBranch.baseCommit) {
                rp.getRevWalk().markUninteresting(c);
            }
            Ref targetRef = allRefs.get(magicBranch.ctl.getRefName());
            if (targetRef != null) {
                logDebug("Marking target ref {} ({}) uninteresting", magicBranch.ctl.getRefName(), targetRef.getObjectId().name());
                rp.getRevWalk().markUninteresting(rp.getRevWalk().parseCommit(targetRef.getObjectId()));
            }
        } else {
            markHeadsAsUninteresting(rp.getRevWalk(), magicBranch.ctl != null ? magicBranch.ctl.getRefName() : null);
        }
        List<ChangeLookup> pending = new ArrayList<>();
        Set<Change.Key> newChangeIds = new HashSet<>();
        int maxBatchChanges = receiveConfig.getEffectiveMaxBatchChangesLimit(user);
        int total = 0;
        int alreadyTracked = 0;
        for (; ; ) {
            RevCommit c = rp.getRevWalk().next();
            if (c == null) {
                break;
            }
            total++;
            String name = c.name();
            groupCollector.visit(c);
            Collection<Ref> existingRefs = existing.get(c);
            if (!existingRefs.isEmpty()) {
                // Commit is already tracked.
                alreadyTracked++;
                // different target branch.
                for (Ref ref : existingRefs) {
                    updateGroups.add(new UpdateGroupsRequest(ref, c));
                }
                if (!(newChangeForAllNotInTarget || magicBranch.base != null)) {
                    continue;
                }
                logDebug("Creating new change for {} even though it is already tracked", name);
            }
            if (!validCommit(rp.getRevWalk(), magicBranch.ctl, magicBranch.cmd, c)) {
                // Not a change the user can propose? Abort as early as possible.
                newChanges = Collections.emptyList();
                logDebug("Aborting early due to invalid commit");
                return;
            }
            // Don't allow merges to be uploaded in commit chain via all-not-in-target
            if (newChangeForAllNotInTarget && c.getParentCount() > 1) {
                reject(magicBranch.cmd, "Pushing merges in commit chains with 'all not in target' is not allowed,\n" + "to override please set the base manually");
                logDebug("Rejecting merge commit {} with newChangeForAllNotInTarget", name);
            // TODO(dborowitz): Should we early return here?
            }
            List<String> idList = c.getFooterLines(CHANGE_ID);
            if (idList.isEmpty()) {
                newChanges.add(new CreateRequest(c, magicBranch.dest.get()));
                continue;
            }
            String idStr = idList.get(idList.size() - 1).trim();
            if (idStr.matches("^I00*$")) {
                // Reject this invalid line from EGit.
                reject(magicBranch.cmd, "invalid Change-Id");
                newChanges = Collections.emptyList();
                return;
            }
            pending.add(new ChangeLookup(c, new Change.Key(idStr)));
            int n = pending.size() + newChanges.size();
            if (maxBatchChanges != 0 && n > maxBatchChanges) {
                logDebug("{} changes exceeds limit of {}", n, maxBatchChanges);
                reject(magicBranch.cmd, "the number of pushed changes in a batch exceeds the max limit " + maxBatchChanges);
                newChanges = Collections.emptyList();
                return;
            }
        }
        logDebug("Finished initial RevWalk with {} commits total: {} already" + " tracked, {} new changes with no Change-Id, and {} deferred" + " lookups", total, alreadyTracked, newChanges.size(), pending.size());
        for (Iterator<ChangeLookup> itr = pending.iterator(); itr.hasNext(); ) {
            ChangeLookup p = itr.next();
            if (newChangeIds.contains(p.changeKey)) {
                logDebug("Multiple commits with Change-Id {}", p.changeKey);
                reject(magicBranch.cmd, SAME_CHANGE_ID_IN_MULTIPLE_CHANGES);
                newChanges = Collections.emptyList();
                return;
            }
            List<ChangeData> changes = p.destChanges;
            if (changes.size() > 1) {
                logDebug("Multiple changes in project with Change-Id {}: {}", p.changeKey, Lists.transform(changes, new Function<ChangeData, String>() {

                    @Override
                    public String apply(ChangeData in) {
                        return in.getId().toString();
                    }
                }));
                // WTF, multiple changes in this project have the same key?
                // Since the commit is new, the user should recreate it with
                // a different Change-Id. In practice, we should never see
                // this error message as Change-Id should be unique.
                // 
                reject(magicBranch.cmd, p.changeKey.get() + " has duplicates");
                newChanges = Collections.emptyList();
                return;
            }
            if (changes.size() == 1) {
                // Schedule as a replacement to this one matching change.
                // 
                RevId currentPs = changes.get(0).currentPatchSet().getRevision();
                // If Commit is already current PatchSet of target Change.
                if (p.commit.name().equals(currentPs.get())) {
                    if (pending.size() == 1) {
                        // There are no commits left to check, all commits in pending were already
                        // current PatchSet of the corresponding target changes.
                        reject(magicBranch.cmd, "commit(s) already exists (as current patchset)");
                    } else {
                        // Commit is already current PatchSet.
                        // Remove from pending and try next commit.
                        itr.remove();
                        continue;
                    }
                }
                if (requestReplace(magicBranch.cmd, false, changes.get(0).change(), p.commit)) {
                    continue;
                }
                newChanges = Collections.emptyList();
                return;
            }
            if (changes.size() == 0) {
                if (!isValidChangeId(p.changeKey.get())) {
                    reject(magicBranch.cmd, "invalid Change-Id");
                    newChanges = Collections.emptyList();
                    return;
                }
                newChangeIds.add(p.changeKey);
            }
            newChanges.add(new CreateRequest(p.commit, magicBranch.dest.get()));
        }
        logDebug("Finished deferred lookups with {} updates and {} new changes", replaceByChange.size(), newChanges.size());
    } catch (IOException e) {
        // Should never happen, the core receive process would have
        // identified the missing object earlier before we got control.
        // 
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", e);
        newChanges = Collections.emptyList();
        return;
    } catch (OrmException e) {
        logError("Cannot query database to locate prior changes", e);
        reject(magicBranch.cmd, "database error");
        newChanges = Collections.emptyList();
        return;
    }
    if (newChanges.isEmpty() && replaceByChange.isEmpty()) {
        reject(magicBranch.cmd, "no new changes");
        return;
    }
    if (!newChanges.isEmpty() && magicBranch.edit) {
        reject(magicBranch.cmd, "edit is not supported for new changes");
        return;
    }
    try {
        SortedSetMultimap<ObjectId, String> groups = groupCollector.getGroups();
        List<Integer> newIds = seq.nextChangeIds(newChanges.size());
        for (int i = 0; i < newChanges.size(); i++) {
            CreateRequest create = newChanges.get(i);
            create.setChangeId(newIds.get(i));
            batch.addCommand(create.cmd);
            create.groups = ImmutableList.copyOf(groups.get(create.commit));
        }
        for (ReplaceRequest replace : replaceByChange.values()) {
            replace.groups = ImmutableList.copyOf(groups.get(replace.newCommitId));
        }
        for (UpdateGroupsRequest update : updateGroups) {
            update.groups = ImmutableList.copyOf((groups.get(update.commit)));
        }
        logDebug("Finished updating groups from GroupCollector");
    } catch (OrmException | NoSuchChangeException e) {
        logError("Error collecting groups for changes", e);
        reject(magicBranch.cmd, "internal server error");
        return;
    }
}
#end_block

#method_before
private void markHeadsAsUninteresting(RevWalk rw, @Nullable String forRef) {
    for (Ref ref : allRefs.values()) {
        if ((ref.getName().startsWith(R_HEADS) || ref.getName().equals(forRef)) && ref.getObjectId() != null) {
            try {
                rw.markUninteresting(rw.parseCommit(ref.getObjectId()));
            } catch (IOException e) {
                log.warn(String.format("Invalid ref %s in %s", ref.getName(), project.getName()), e);
            }
        }
    }
}
#method_after
private void markHeadsAsUninteresting(RevWalk rw, @Nullable String forRef) {
    int i = 0;
    for (Ref ref : allRefs.values()) {
        if ((ref.getName().startsWith(R_HEADS) || ref.getName().equals(forRef)) && ref.getObjectId() != null) {
            try {
                rw.markUninteresting(rw.parseCommit(ref.getObjectId()));
                i++;
            } catch (IOException e) {
                logWarn(String.format("Invalid ref %s in %s", ref.getName(), project.getName()), e);
            }
        }
    }
    logDebug("Marked {} heads as uninteresting", i);
}
#end_block

#method_before
private void addOps(BatchUpdate bu) throws RestApiException {
    checkState(changeId != null, "must call setChangeId before addOps");
    try {
        RevWalk rw = rp.getRevWalk();
        rw.parseBody(commit);
        final PatchSet.Id psId = ins.setGroups(groups).getPatchSetId();
        Account.Id me = user.getAccountId();
        List<FooterLine> footerLines = commit.getFooterLines();
        MailRecipients recipients = new MailRecipients();
        Map<String, Short> approvals = new HashMap<>();
        checkNotNull(magicBranch);
        recipients.add(magicBranch.getMailRecipients());
        approvals = magicBranch.labels;
        recipients.add(getRecipientsFromFooters(accountResolver, magicBranch.draft, footerLines));
        recipients.remove(me);
        StringBuilder msg = new StringBuilder(ApprovalsUtil.renderMessageWithApprovals(psId.get(), approvals, Collections.<String, PatchSetApproval>emptyMap()));
        msg.append('.');
        if (!Strings.isNullOrEmpty(magicBranch.message)) {
            msg.append("\n").append(magicBranch.message);
        }
        bu.insertChange(ins.setReviewers(recipients.getReviewers()).setExtraCC(recipients.getCcOnly()).setApprovals(approvals).setMessage(msg.toString()).setNotify(magicBranch.notify).setRequestScopePropagator(requestScopePropagator).setSendMail(true).setUpdateRef(true));
        if (!magicBranch.hashtags.isEmpty()) {
            bu.addOp(changeId, hashtagsFactory.create(new HashtagsInput(magicBranch.hashtags)).setFireEvent(false));
        }
        if (!Strings.isNullOrEmpty(magicBranch.topic)) {
            bu.addOp(changeId, new BatchUpdate.Op() {

                @Override
                public boolean updateChange(ChangeContext ctx) {
                    ctx.getUpdate(psId).setTopic(magicBranch.topic);
                    return true;
                }
            });
        }
        bu.addOp(changeId, new BatchUpdate.Op() {

            @Override
            public boolean updateChange(ChangeContext ctx) {
                change = ctx.getChange();
                return false;
            }
        });
        bu.addOp(changeId, new ChangeProgressOp(newProgress));
    } catch (Exception e) {
        throw INSERT_EXCEPTION.apply(e);
    }
}
#method_after
private void addOps(BatchUpdate bu) throws RestApiException {
    checkState(changeId != null, "must call setChangeId before addOps");
    try {
        RevWalk rw = rp.getRevWalk();
        rw.parseBody(commit);
        final PatchSet.Id psId = ins.setGroups(groups).getPatchSetId();
        Account.Id me = user.getAccountId();
        List<FooterLine> footerLines = commit.getFooterLines();
        MailRecipients recipients = new MailRecipients();
        Map<String, Short> approvals = new HashMap<>();
        checkNotNull(magicBranch);
        recipients.add(magicBranch.getMailRecipients());
        approvals = magicBranch.labels;
        recipients.add(getRecipientsFromFooters(db, accountResolver, magicBranch.draft, footerLines));
        recipients.remove(me);
        StringBuilder msg = new StringBuilder(ApprovalsUtil.renderMessageWithApprovals(psId.get(), approvals, Collections.<String, PatchSetApproval>emptyMap()));
        msg.append('.');
        if (!Strings.isNullOrEmpty(magicBranch.message)) {
            msg.append("\n").append(magicBranch.message);
        }
        bu.insertChange(ins.setReviewers(recipients.getReviewers()).setExtraCC(recipients.getCcOnly()).setApprovals(approvals).setMessage(msg.toString()).setNotify(magicBranch.notify).setRequestScopePropagator(requestScopePropagator).setSendMail(true).setUpdateRef(true));
        if (!magicBranch.hashtags.isEmpty()) {
            bu.addOp(changeId, hashtagsFactory.create(new HashtagsInput(magicBranch.hashtags)).setFireEvent(false));
        }
        if (!Strings.isNullOrEmpty(magicBranch.topic)) {
            bu.addOp(changeId, new BatchUpdate.Op() {

                @Override
                public boolean updateChange(ChangeContext ctx) {
                    ctx.getUpdate(psId).setTopic(magicBranch.topic);
                    return true;
                }
            });
        }
        bu.addOp(changeId, new BatchUpdate.Op() {

            @Override
            public boolean updateChange(ChangeContext ctx) {
                change = ctx.getChange();
                return false;
            }
        });
        bu.addOp(changeId, new ChangeProgressOp(newProgress));
    } catch (Exception e) {
        throw INSERT_EXCEPTION.apply(e);
    }
}
#end_block

#method_before
private void submit(Collection<CreateRequest> create, Collection<ReplaceRequest> replace) throws OrmException, RestApiException {
    Map<ObjectId, Change> bySha = Maps.newHashMapWithExpectedSize(create.size() + replace.size());
    for (CreateRequest r : create) {
        checkNotNull(r.change, "cannot submit new change %s; op may not have run", r.changeId);
        bySha.put(r.commit, r.change);
    }
    for (ReplaceRequest r : replace) {
        bySha.put(r.newCommitId, r.notes.getChange());
    }
    Change tipChange = bySha.get(magicBranch.cmd.getNewId());
    checkNotNull(tipChange, "tip of push does not correspond to a change; found these changes: %s", bySha);
    try (MergeOp op = mergeOpProvider.get()) {
        op.merge(db, tipChange, user, false, new SubmitInput());
    }
}
#method_after
private void submit(Collection<CreateRequest> create, Collection<ReplaceRequest> replace) throws OrmException, RestApiException {
    Map<ObjectId, Change> bySha = Maps.newHashMapWithExpectedSize(create.size() + replace.size());
    for (CreateRequest r : create) {
        checkNotNull(r.change, "cannot submit new change %s; op may not have run", r.changeId);
        bySha.put(r.commit, r.change);
    }
    for (ReplaceRequest r : replace) {
        bySha.put(r.newCommitId, r.notes.getChange());
    }
    Change tipChange = bySha.get(magicBranch.cmd.getNewId());
    checkNotNull(tipChange, "tip of push does not correspond to a change; found these changes: %s", bySha);
    logDebug("Processing submit with tip change {} ({})", tipChange.getId(), magicBranch.cmd.getNewId());
    try (MergeOp op = mergeOpProvider.get()) {
        op.merge(db, tipChange, user, false, new SubmitInput());
    }
}
#end_block

#method_before
private void preparePatchSetsForReplace() {
    try {
        readChangesForReplace();
        for (Iterator<ReplaceRequest> itr = replaceByChange.values().iterator(); itr.hasNext(); ) {
            ReplaceRequest req = itr.next();
            if (req.inputCommand.getResult() == NOT_ATTEMPTED) {
                req.validate(false);
                if (req.skip && req.cmd == null) {
                    itr.remove();
                }
            }
        }
    } catch (OrmException err) {
        log.error(String.format("Cannot read database before replacement for project %s", project.getName()), err);
        for (ReplaceRequest req : replaceByChange.values()) {
            if (req.inputCommand.getResult() == NOT_ATTEMPTED) {
                req.inputCommand.setResult(REJECTED_OTHER_REASON, "internal server error");
            }
        }
    } catch (IOException err) {
        log.error(String.format("Cannot read repository before replacement for project %s", project.getName()), err);
        for (ReplaceRequest req : replaceByChange.values()) {
            if (req.inputCommand.getResult() == NOT_ATTEMPTED) {
                req.inputCommand.setResult(REJECTED_OTHER_REASON, "internal server error");
            }
        }
    }
    for (ReplaceRequest req : replaceByChange.values()) {
        if (req.inputCommand.getResult() == NOT_ATTEMPTED && req.cmd != null) {
            if (req.prev != null) {
                batch.addCommand(req.prev);
            }
            batch.addCommand(req.cmd);
        }
    }
    if (magicBranch != null && magicBranch.cmd.getResult() != NOT_ATTEMPTED) {
        // Cancel creations tied to refs/for/ or refs/drafts/ command.
        for (ReplaceRequest req : replaceByChange.values()) {
            if (req.inputCommand == magicBranch.cmd && req.cmd != null) {
                req.cmd.setResult(Result.REJECTED_OTHER_REASON, "aborted");
            }
        }
        for (CreateRequest req : newChanges) {
            req.cmd.setResult(Result.REJECTED_OTHER_REASON, "aborted");
        }
    }
}
#method_after
private void preparePatchSetsForReplace() {
    try {
        readChangesForReplace();
        for (Iterator<ReplaceRequest> itr = replaceByChange.values().iterator(); itr.hasNext(); ) {
            ReplaceRequest req = itr.next();
            if (req.inputCommand.getResult() == NOT_ATTEMPTED) {
                req.validate(false);
                if (req.skip && req.cmd == null) {
                    itr.remove();
                }
            }
        }
    } catch (OrmException err) {
        logError(String.format("Cannot read database before replacement for project %s", project.getName()), err);
        for (ReplaceRequest req : replaceByChange.values()) {
            if (req.inputCommand.getResult() == NOT_ATTEMPTED) {
                req.inputCommand.setResult(REJECTED_OTHER_REASON, "internal server error");
            }
        }
    } catch (IOException err) {
        logError(String.format("Cannot read repository before replacement for project %s", project.getName()), err);
        for (ReplaceRequest req : replaceByChange.values()) {
            if (req.inputCommand.getResult() == NOT_ATTEMPTED) {
                req.inputCommand.setResult(REJECTED_OTHER_REASON, "internal server error");
            }
        }
    }
    logDebug("Read {} changes to replace", replaceByChange.size());
    for (ReplaceRequest req : replaceByChange.values()) {
        if (req.inputCommand.getResult() == NOT_ATTEMPTED && req.cmd != null) {
            if (req.prev != null) {
                batch.addCommand(req.prev);
            }
            batch.addCommand(req.cmd);
        }
    }
    if (magicBranch != null && magicBranch.cmd.getResult() != NOT_ATTEMPTED) {
        // Cancel creations tied to refs/for/ or refs/drafts/ command.
        for (ReplaceRequest req : replaceByChange.values()) {
            if (req.inputCommand == magicBranch.cmd && req.cmd != null) {
                req.cmd.setResult(Result.REJECTED_OTHER_REASON, "aborted");
            }
        }
        for (CreateRequest req : newChanges) {
            req.cmd.setResult(Result.REJECTED_OTHER_REASON, "aborted");
        }
    }
}
#end_block

#method_before
private boolean newEdit() {
    psId = notes.getChange().currentPatchSetId();
    Optional<ChangeEdit> edit = null;
    try {
        edit = editUtil.byChange(changeCtl);
    } catch (AuthException | IOException e) {
        log.error("Cannot retrieve edit", e);
        return false;
    }
    if (edit.isPresent()) {
        if (edit.get().getBasePatchSet().getId().equals(psId)) {
            // replace edit
            cmd = new ReceiveCommand(edit.get().getRef().getObjectId(), newCommitId, edit.get().getRefName());
        } else {
            // delete old edit ref on rebase
            prev = new ReceiveCommand(edit.get().getRef().getObjectId(), ObjectId.zeroId(), edit.get().getRefName());
            createEditCommand();
        }
    } else {
        createEditCommand();
    }
    return true;
}
#method_after
private boolean newEdit() {
    psId = notes.getChange().currentPatchSetId();
    Optional<ChangeEdit> edit = null;
    try {
        edit = editUtil.byChange(changeCtl);
    } catch (AuthException | IOException e) {
        logError("Cannot retrieve edit", e);
        return false;
    }
    if (edit.isPresent()) {
        if (edit.get().getBasePatchSet().getId().equals(psId)) {
            // replace edit
            cmd = new ReceiveCommand(edit.get().getRef().getObjectId(), newCommitId, edit.get().getRefName());
        } else {
            // delete old edit ref on rebase
            prev = new ReceiveCommand(edit.get().getRef().getObjectId(), ObjectId.zeroId(), edit.get().getRefName());
            createEditCommand();
        }
    } else {
        createEditCommand();
    }
    return true;
}
#end_block

#method_before
void insertPatchSetWithoutBatchUpdate() throws IOException, UpdateException, RestApiException {
    try (BatchUpdate bu = batchUpdateFactory.create(db, projectControl.getProject().getNameKey(), user, TimeUtil.nowTs());
        ObjectInserter ins = repo.newObjectInserter()) {
        bu.setRepository(repo, rp.getRevWalk(), ins);
        addOps(bu, replaceProgress);
        bu.execute();
    }
}
#method_after
void insertPatchSetWithoutBatchUpdate() throws IOException, UpdateException, RestApiException {
    try (BatchUpdate bu = batchUpdateFactory.create(db, projectControl.getProject().getNameKey(), user, TimeUtil.nowTs());
        ObjectInserter ins = repo.newObjectInserter()) {
        bu.setRepository(repo, rp.getRevWalk(), ins);
        bu.setRequestId(receiveId);
        addOps(bu, replaceProgress);
        bu.execute();
    }
}
#end_block

#method_before
static boolean parentsEqual(RevCommit a, RevCommit b) {
    if (a.getParentCount() != b.getParentCount()) {
        return false;
    }
    for (int i = 0; i < a.getParentCount(); i++) {
        if (a.getParent(i) != b.getParent(i)) {
            return false;
        }
    }
    return true;
}
#method_after
static boolean parentsEqual(RevCommit a, RevCommit b) {
    if (a.getParentCount() != b.getParentCount()) {
        return false;
    }
    for (int i = 0; i < a.getParentCount(); i++) {
        if (!a.getParent(i).equals(b.getParent(i))) {
            return false;
        }
    }
    return true;
}
#end_block

#method_before
private void validateNewCommits(RefControl ctl, ReceiveCommand cmd) {
    if (ctl.canForgeAuthor() && ctl.canForgeCommitter() && ctl.canForgeGerritServerIdentity() && ctl.canUploadMerges() && !projectControl.getProjectState().isUseSignedOffBy() && Iterables.isEmpty(rejectCommits) && !RefNames.REFS_CONFIG.equals(ctl.getRefName()) && !(MagicBranch.isMagicBranch(cmd.getRefName()) || NEW_PATCHSET.matcher(cmd.getRefName()).matches())) {
        return;
    }
    boolean defaultName = Strings.isNullOrEmpty(user.getAccount().getFullName());
    RevWalk walk = rp.getRevWalk();
    walk.reset();
    walk.sort(RevSort.NONE);
    try {
        RevObject parsedObject = walk.parseAny(cmd.getNewId());
        if (!(parsedObject instanceof RevCommit)) {
            return;
        }
        SetMultimap<ObjectId, Ref> existing = changeRefsById();
        walk.markStart((RevCommit) parsedObject);
        markHeadsAsUninteresting(walk, cmd.getRefName());
        for (RevCommit c; (c = walk.next()) != null; ) {
            if (existing.keySet().contains(c)) {
                continue;
            } else if (!validCommit(walk, ctl, cmd, c)) {
                break;
            }
            if (defaultName && user.hasEmailAddress(c.getCommitterIdent().getEmailAddress())) {
                try {
                    Account a = db.accounts().get(user.getAccountId());
                    if (a != null && Strings.isNullOrEmpty(a.getFullName())) {
                        a.setFullName(c.getCommitterIdent().getName());
                        db.accounts().update(Collections.singleton(a));
                        user.getAccount().setFullName(a.getFullName());
                        accountCache.evict(a.getId());
                    }
                } catch (OrmException e) {
                    log.warn("Cannot default full_name", e);
                } finally {
                    defaultName = false;
                }
            }
        }
    } catch (IOException err) {
        cmd.setResult(REJECTED_MISSING_OBJECT);
        log.error("Invalid pack upload; one or more objects weren't sent", err);
    }
}
#method_after
private void validateNewCommits(RefControl ctl, ReceiveCommand cmd) {
    if (ctl.canForgeAuthor() && ctl.canForgeCommitter() && ctl.canForgeGerritServerIdentity() && ctl.canUploadMerges() && !projectControl.getProjectState().isUseSignedOffBy() && Iterables.isEmpty(rejectCommits) && !RefNames.REFS_CONFIG.equals(ctl.getRefName()) && !(MagicBranch.isMagicBranch(cmd.getRefName()) || NEW_PATCHSET.matcher(cmd.getRefName()).matches())) {
        logDebug("Short-circuiting new commit validation");
        return;
    }
    boolean defaultName = Strings.isNullOrEmpty(user.getAccount().getFullName());
    RevWalk walk = rp.getRevWalk();
    walk.reset();
    walk.sort(RevSort.NONE);
    try {
        RevObject parsedObject = walk.parseAny(cmd.getNewId());
        if (!(parsedObject instanceof RevCommit)) {
            return;
        }
        SetMultimap<ObjectId, Ref> existing = changeRefsById();
        walk.markStart((RevCommit) parsedObject);
        markHeadsAsUninteresting(walk, cmd.getRefName());
        int i = 0;
        for (RevCommit c; (c = walk.next()) != null; ) {
            i++;
            if (existing.keySet().contains(c)) {
                continue;
            } else if (!validCommit(walk, ctl, cmd, c)) {
                break;
            }
            if (defaultName && user.hasEmailAddress(c.getCommitterIdent().getEmailAddress())) {
                try {
                    Account a = db.accounts().get(user.getAccountId());
                    if (a != null && Strings.isNullOrEmpty(a.getFullName())) {
                        a.setFullName(c.getCommitterIdent().getName());
                        db.accounts().update(Collections.singleton(a));
                        user.getAccount().setFullName(a.getFullName());
                        accountCache.evict(a.getId());
                    }
                } catch (OrmException e) {
                    logWarn("Cannot default full_name", e);
                } finally {
                    defaultName = false;
                }
            }
        }
        logDebug("Validated {} new commits", i);
    } catch (IOException err) {
        cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", err);
    }
}
#end_block

#method_before
private boolean validCommit(RevWalk rw, RefControl ctl, ReceiveCommand cmd, ObjectId id) throws IOException {
    if (validCommits.contains(id)) {
        return true;
    }
    RevCommit c = rw.parseCommit(id);
    rw.parseBody(c);
    CommitReceivedEvent receiveEvent = new CommitReceivedEvent(cmd, project, ctl.getRefName(), c, user);
    CommitValidators commitValidators = commitValidatorsFactory.create(ctl, sshInfo, repo);
    try {
        messages.addAll(commitValidators.validateForReceiveCommits(receiveEvent, rejectCommits));
    } catch (CommitValidationException e) {
        messages.addAll(e.getMessages());
        reject(cmd, e.getMessage());
        return false;
    }
    validCommits.add(c.copy());
    return true;
}
#method_after
private boolean validCommit(RevWalk rw, RefControl ctl, ReceiveCommand cmd, ObjectId id) throws IOException {
    if (validCommits.contains(id)) {
        return true;
    }
    RevCommit c = rw.parseCommit(id);
    rw.parseBody(c);
    CommitReceivedEvent receiveEvent = new CommitReceivedEvent(cmd, project, ctl.getRefName(), c, user);
    CommitValidators commitValidators = commitValidatorsFactory.create(ctl, sshInfo, repo);
    try {
        messages.addAll(commitValidators.validateForReceiveCommits(receiveEvent, rejectCommits));
    } catch (CommitValidationException e) {
        logDebug("Commit validation failed on {}", c.name());
        messages.addAll(e.getMessages());
        reject(cmd, e.getMessage());
        return false;
    }
    validCommits.add(c.copy());
    return true;
}
#end_block

#method_before
private void autoCloseChanges(final ReceiveCommand cmd) {
    String refName = cmd.getRefName();
    checkState(!MagicBranch.isMagicBranch(refName), "shouldn't be auto-closing changes on magic branch %s", refName);
    RevWalk rw = rp.getRevWalk();
    // insertChangesAndPatchSets.
    try (BatchUpdate bu = batchUpdateFactory.create(db, projectControl.getProject().getNameKey(), user, TimeUtil.nowTs());
        ObjectInserter ins = repo.newObjectInserter()) {
        bu.setRepository(repo, rp.getRevWalk(), ins).updateChangesInParallel();
        // TODO(dborowitz): Teach BatchUpdate to ignore missing changes.
        RevCommit newTip = rw.parseCommit(cmd.getNewId());
        Branch.NameKey branch = new Branch.NameKey(project.getNameKey(), refName);
        rw.reset();
        rw.markStart(newTip);
        if (!ObjectId.zeroId().equals(cmd.getOldId())) {
            rw.markUninteresting(rw.parseCommit(cmd.getOldId()));
        }
        SetMultimap<ObjectId, Ref> byCommit = changeRefsById();
        Map<Change.Key, ChangeNotes> byKey = null;
        List<ReplaceRequest> replaceAndClose = new ArrayList<>();
        COMMIT: for (RevCommit c; (c = rw.next()) != null; ) {
            rw.parseBody(c);
            for (Ref ref : byCommit.get(c.copy())) {
                PatchSet.Id psId = PatchSet.Id.fromRef(ref.getName());
                bu.addOp(psId.getParentKey(), mergedByPushOpFactory.create(requestScopePropagator, psId, refName));
                continue COMMIT;
            }
            for (String changeId : c.getFooterLines(CHANGE_ID)) {
                if (byKey == null) {
                    byKey = openChangesByBranch(branch);
                }
                ChangeNotes onto = byKey.get(new Change.Key(changeId.trim()));
                if (onto != null) {
                    // Hold onto this until we're done with the walk, as the call to
                    // req.validate below calls isMergedInto which resets the walk.
                    ReplaceRequest req = new ReplaceRequest(onto.getChangeId(), c, cmd, false);
                    req.notes = onto;
                    replaceAndClose.add(req);
                    continue COMMIT;
                }
            }
        }
        for (final ReplaceRequest req : replaceAndClose) {
            Change.Id id = req.notes.getChangeId();
            if (!req.validate(true)) {
                continue;
            }
            req.addOps(bu, null);
            bu.addOp(id, mergedByPushOpFactory.create(requestScopePropagator, req.psId, refName).setPatchSetProvider(new Provider<PatchSet>() {

                @Override
                public PatchSet get() {
                    return req.replaceOp.getPatchSet();
                }
            }));
            bu.addOp(id, new ChangeProgressOp(closeProgress));
        }
        bu.execute();
    } catch (RestApiException e) {
        log.error("Can't insert patchset", e);
    } catch (IOException | OrmException | UpdateException e) {
        log.error("Can't scan for changes to close", e);
    }
}
#method_after
private void autoCloseChanges(final ReceiveCommand cmd) {
    logDebug("Starting auto-closing of changes");
    String refName = cmd.getRefName();
    checkState(!MagicBranch.isMagicBranch(refName), "shouldn't be auto-closing changes on magic branch %s", refName);
    RevWalk rw = rp.getRevWalk();
    // insertChangesAndPatchSets.
    try (BatchUpdate bu = batchUpdateFactory.create(db, projectControl.getProject().getNameKey(), user, TimeUtil.nowTs());
        ObjectInserter ins = repo.newObjectInserter()) {
        bu.setRepository(repo, rp.getRevWalk(), ins).updateChangesInParallel();
        bu.setRequestId(receiveId);
        // TODO(dborowitz): Teach BatchUpdate to ignore missing changes.
        RevCommit newTip = rw.parseCommit(cmd.getNewId());
        Branch.NameKey branch = new Branch.NameKey(project.getNameKey(), refName);
        rw.reset();
        rw.markStart(newTip);
        if (!ObjectId.zeroId().equals(cmd.getOldId())) {
            rw.markUninteresting(rw.parseCommit(cmd.getOldId()));
        }
        SetMultimap<ObjectId, Ref> byCommit = changeRefsById();
        Map<Change.Key, ChangeNotes> byKey = null;
        List<ReplaceRequest> replaceAndClose = new ArrayList<>();
        int existingPatchSets = 0;
        int newPatchSets = 0;
        COMMIT: for (RevCommit c; (c = rw.next()) != null; ) {
            rw.parseBody(c);
            for (Ref ref : byCommit.get(c.copy())) {
                existingPatchSets++;
                PatchSet.Id psId = PatchSet.Id.fromRef(ref.getName());
                bu.addOp(psId.getParentKey(), mergedByPushOpFactory.create(requestScopePropagator, psId, refName));
                continue COMMIT;
            }
            for (String changeId : c.getFooterLines(CHANGE_ID)) {
                if (byKey == null) {
                    byKey = openChangesByBranch(branch);
                }
                ChangeNotes onto = byKey.get(new Change.Key(changeId.trim()));
                if (onto != null) {
                    newPatchSets++;
                    // Hold onto this until we're done with the walk, as the call to
                    // req.validate below calls isMergedInto which resets the walk.
                    ReplaceRequest req = new ReplaceRequest(onto.getChangeId(), c, cmd, false);
                    req.notes = onto;
                    replaceAndClose.add(req);
                    continue COMMIT;
                }
            }
        }
        for (final ReplaceRequest req : replaceAndClose) {
            Change.Id id = req.notes.getChangeId();
            if (!req.validate(true)) {
                logDebug("Not closing {} because validation failed", id);
                continue;
            }
            req.addOps(bu, null);
            bu.addOp(id, mergedByPushOpFactory.create(requestScopePropagator, req.psId, refName).setPatchSetProvider(new Provider<PatchSet>() {

                @Override
                public PatchSet get() {
                    return req.replaceOp.getPatchSet();
                }
            }));
            bu.addOp(id, new ChangeProgressOp(closeProgress));
        }
        logDebug("Auto-closing {} changes with existing patch sets and {} with" + " new patch sets", existingPatchSets, newPatchSets);
        bu.execute();
    } catch (RestApiException e) {
        logError("Can't insert patchset", e);
    } catch (IOException | OrmException | UpdateException e) {
        logError("Can't scan for changes to close", e);
    }
}
#end_block

#method_before
@Override
public IncludedInInfo apply(ChangeResource rsrc) throws BadRequestException, ResourceConflictException, OrmException, IOException {
    ChangeControl ctl = rsrc.getControl();
    PatchSet ps = psUtil.current(db.get(), rsrc.getNotes());
    Project.NameKey project = ctl.getProject().getNameKey();
    try (Repository r = repoManager.openRepository(project);
        RevWalk rw = new RevWalk(r)) {
        rw.setRetainBody(false);
        RevCommit rev;
        try {
            rev = rw.parseCommit(ObjectId.fromString(ps.getRevision().get()));
        } catch (IncorrectObjectTypeException err) {
            throw new BadRequestException(err.getMessage());
        } catch (MissingObjectException err) {
            throw new ResourceConflictException(err.getMessage());
        }
        IncludedInResolver.Result d = IncludedInResolver.resolve(r, rw, rev);
        Map<String, Collection<String>> external = new HashMap<>();
        for (ExternalIncludedIn ext : includedIn) {
            Multimap<String, String> m = ext.getIncludedIn(project.get(), rev.name(), d.getTags(), d.getBranches());
            for (Map.Entry<String, Collection<String>> e : m.asMap().entrySet()) {
                external.put(e.getKey(), e.getValue());
            }
        }
        return new IncludedInInfo(d, (!external.isEmpty() ? external : null));
    }
}
#method_after
@Override
public IncludedInInfo apply(ChangeResource rsrc) throws BadRequestException, ResourceConflictException, OrmException, IOException {
    ChangeControl ctl = rsrc.getControl();
    PatchSet ps = psUtil.current(db.get(), rsrc.getNotes());
    Project.NameKey project = ctl.getProject().getNameKey();
    try (Repository r = repoManager.openRepository(project);
        RevWalk rw = new RevWalk(r)) {
        rw.setRetainBody(false);
        RevCommit rev;
        try {
            rev = rw.parseCommit(ObjectId.fromString(ps.getRevision().get()));
        } catch (IncorrectObjectTypeException err) {
            throw new BadRequestException(err.getMessage());
        } catch (MissingObjectException err) {
            throw new ResourceConflictException(err.getMessage());
        }
        IncludedInResolver.Result d = IncludedInResolver.resolve(r, rw, rev);
        Multimap<String, String> external = ArrayListMultimap.create();
        for (ExternalIncludedIn ext : includedIn) {
            external.putAll(ext.getIncludedIn(project.get(), rev.name(), d.getTags(), d.getBranches()));
        }
        return new IncludedInInfo(d, (!external.isEmpty() ? external.asMap() : null));
    }
}
#end_block

#method_before
public Change abandon(ChangeControl control, String msgTxt, NotifyHandling notifyHandling) throws RestApiException, UpdateException {
    Op op = new Op(control, msgTxt, notifyHandling);
    try (BatchUpdate u = batchUpdateFactory.create(dbProvider.get(), op.getProject(), op.getUser(), TimeUtil.nowTs())) {
        u.addOp(control.getId(), op).execute();
    }
    return op.change;
}
#method_after
public Change abandon(ChangeControl control) throws RestApiException, UpdateException {
    return abandon(control, "", NotifyHandling.ALL);
}
#end_block

#method_before
public Change abandon(ChangeControl control, String msgTxt, NotifyHandling notifyHandling) throws RestApiException, UpdateException {
    Op op = new Op(control, msgTxt, notifyHandling);
    try (BatchUpdate u = batchUpdateFactory.create(dbProvider.get(), op.getProject(), op.getUser(), TimeUtil.nowTs())) {
        u.addOp(control.getId(), op).execute();
    }
    return op.change;
}
#method_after
public Change abandon(ChangeControl control, String msgTxt, NotifyHandling notifyHandling) throws RestApiException, UpdateException {
    Op op = new Op(control, msgTxt, notifyHandling);
    try (BatchUpdate u = batchUpdateFactory.create(dbProvider.get(), control.getProject().getNameKey(), control.getUser(), TimeUtil.nowTs())) {
        u.addOp(control.getId(), op).execute();
    }
    return op.change;
}
#end_block

#method_before
@Override
public ChangeInfo apply(ChangeResource req, RevertInput input) throws IOException, OrmException, RestApiException, UpdateException, NoSuchChangeException {
    RefControl refControl = req.getControl().getRefControl();
    ProjectControl projectControl = req.getControl().getProjectControl();
    Change change = req.getChange();
    Capable capable = projectControl.canPushToAtLeastOneRef();
    if (capable != Capable.OK) {
        throw new AuthException(capable.getMessage());
    }
    if (!refControl.canUpload()) {
        throw new AuthException("revert not permitted");
    } else if (change.getStatus() != Status.MERGED) {
        throw new ResourceConflictException("change is " + status(change));
    }
    Change.Id revertedChangeId = revert(req.getControl(), Strings.emptyToNull(input.message));
    return json.create(ChangeJson.NO_OPTIONS).format(req.getProject(), revertedChangeId);
}
#method_after
@Override
public ChangeInfo apply(ChangeResource req, RevertInput input) throws IOException, OrmException, RestApiException, UpdateException, NoSuchChangeException {
    RefControl refControl = req.getControl().getRefControl();
    ProjectControl projectControl = req.getControl().getProjectControl();
    Capable capable = projectControl.canPushToAtLeastOneRef();
    if (capable != Capable.OK) {
        throw new AuthException(capable.getMessage());
    }
    Change change = req.getChange();
    if (!refControl.canUpload()) {
        throw new AuthException("revert not permitted");
    } else if (change.getStatus() != Status.MERGED) {
        throw new ResourceConflictException("change is " + status(change));
    }
    Change.Id revertedChangeId = revert(req.getControl(), Strings.emptyToNull(input.message));
    return json.create(ChangeJson.NO_OPTIONS).format(req.getProject(), revertedChangeId);
}
#end_block

#method_before
@Override
protected LargeFileRepository getLargeFileRepository(LfsRequest request, String path) throws LfsException {
    String pathInfo = path.startsWith("/") ? path : "/" + path;
    Matcher matcher = URL_PATTERN.matcher(pathInfo);
    if (!matcher.matches()) {
        return null;
    }
    Project.NameKey project = Project.NameKey.parse(ProjectUtil.stripGitSuffix(matcher.group(1)));
    ProjectState state = projectCache.get(project);
    if (state == null || state.getProject().getState() == HIDDEN) {
        throw new LfsRepositoryNotFound(project.get());
    }
    if (request.getOperation().equals("upload") && state.getProject().getState() == READ_ONLY) {
        throw new LfsRepositoryReadOnly(project.get());
    }
    Config config = pluginConfigFactory.getProjectPluginConfigWithInheritance(state, pluginName);
    // Only accept requests for projects where LFS is enabled
    if (!config.getBoolean("lfs", "enabled", false)) {
        return null;
    }
    if (request.getOperation().equals("upload")) {
        // Check object sizes against limit, if configured
        long maxObjectSize = config.getLong("lfs", "maxObjectSize", 0);
        if (maxObjectSize > 0) {
            for (LfsObject object : request.getObjects()) {
                if (object.getSize() > maxObjectSize) {
                    throw new LfsValidationError("size of object " + object.getOid() + " exceeds limit");
                }
            }
        }
    }
    return getRepository();
}
#method_after
@Override
protected LargeFileRepository getLargeFileRepository(LfsRequest request, String path) throws LfsException {
    String pathInfo = path.startsWith("/") ? path : "/" + path;
    Matcher matcher = URL_PATTERN.matcher(pathInfo);
    if (!matcher.matches()) {
        return null;
    }
    Project.NameKey project = Project.NameKey.parse(ProjectUtil.stripGitSuffix(matcher.group(1)));
    ProjectState state = projectCache.get(project);
    if (state == null || state.getProject().getState() == HIDDEN) {
        throw new LfsRepositoryNotFound(project.get());
    }
    if (request.getOperation().equals("upload") && state.getProject().getState() == READ_ONLY) {
        throw new LfsRepositoryReadOnly(project.get());
    }
    Config config = pluginConfigFactory.getProjectPluginConfigWithInheritance(state, pluginName);
    // Only accept requests for projects where LFS is enabled
    if (!config.getBoolean("lfs", "enabled", false)) {
        return null;
    }
    if (request.getOperation().equals("upload")) {
        // Check object sizes against limit, if configured
        long maxObjectSize = config.getLong("lfs", "maxObjectSize", 0);
        if (maxObjectSize > 0) {
            for (LfsObject object : request.getObjects()) {
                if (object.getSize() > maxObjectSize) {
                    throw new LfsValidationError(String.format("size of object %s (%d bytes) exceeds limit (%d bytes)", object.getOid(), object.getSize(), maxObjectSize));
                }
            }
        }
    }
    return getRepository();
}
#end_block

#method_before
@Override
public synchronized void start() {
    if (daemonAcceptor == null && !listen.isEmpty()) {
        checkConfig();
        if (sessionFactory == null) {
            sessionFactory = createSessionFactory();
        }
        sessionFactory.setServer(this);
        daemonAcceptor = createAcceptor();
        try {
            String listenAddress = cfg.getString("sshd", null, "listenAddress");
            boolean rewrite = !Strings.isNullOrEmpty(listenAddress) && listenAddress.endsWith(":0");
            daemonAcceptor.bind(listen);
            if (rewrite) {
                SocketAddress bound = Iterables.getOnlyElement(daemonAcceptor.getBoundAddresses());
                cfg.setString("sshd", null, "listenAddress", format((InetSocketAddress) bound));
            }
        } catch (IOException e) {
            throw new IllegalStateException("Cannot bind to " + addressList(), e);
        }
        log.info(String.format("Started Gerrit %s on %s", version, addressList()));
    }
}
#method_after
@Override
public synchronized void start() {
    if (daemonAcceptor == null && !listen.isEmpty()) {
        checkConfig();
        if (getSessionFactory() == null) {
            setSessionFactory(createSessionFactory());
        }
        daemonAcceptor = createAcceptor();
        try {
            String listenAddress = cfg.getString("sshd", null, "listenAddress");
            boolean rewrite = !Strings.isNullOrEmpty(listenAddress) && listenAddress.endsWith(":0");
            daemonAcceptor.bind(listen);
            if (rewrite) {
                SocketAddress bound = Iterables.getOnlyElement(daemonAcceptor.getBoundAddresses());
                cfg.setString("sshd", null, "listenAddress", format((InetSocketAddress) bound));
            }
        } catch (IOException e) {
            throw new IllegalStateException("Cannot bind to " + addressList(), e);
        }
        sshDaemonLog.info(String.format("Started Gerrit %s on %s", getVersion(), addressList()));
    }
}
#end_block

#method_before
@Override
public synchronized void stop() {
    if (daemonAcceptor != null) {
        try {
            daemonAcceptor.close(true).await();
            log.info("Stopped Gerrit SSHD");
        } catch (InterruptedException e) {
            log.warn("Exception caught while closing", e);
        } finally {
            daemonAcceptor = null;
        }
    }
}
#method_after
@Override
public synchronized void stop() {
    if (daemonAcceptor != null) {
        try {
            daemonAcceptor.close(true).await();
            sshDaemonLog.info("Stopped Gerrit SSHD");
        } catch (IOException e) {
            sshDaemonLog.warn("Exception caught while closing", e);
        } finally {
            daemonAcceptor = null;
        }
    }
}
#end_block

#method_before
private List<HostKey> computeHostKeys() {
    if (listen.isEmpty()) {
        return Collections.emptyList();
    }
    final List<PublicKey> keys = myHostKeys();
    final List<HostKey> r = new ArrayList<>();
    for (final PublicKey pub : keys) {
        final Buffer buf = new Buffer();
        buf.putRawPublicKey(pub);
        final byte[] keyBin = buf.getCompactData();
        for (final String addr : advertised) {
            try {
                r.add(new HostKey(addr, keyBin));
            } catch (JSchException e) {
                log.warn("Cannot format SSHD host key", e);
            }
        }
    }
    return Collections.unmodifiableList(r);
}
#method_after
private List<HostKey> computeHostKeys() {
    if (listen.isEmpty()) {
        return Collections.emptyList();
    }
    final List<PublicKey> keys = myHostKeys();
    final List<HostKey> r = new ArrayList<>();
    for (final PublicKey pub : keys) {
        final Buffer buf = new ByteArrayBuffer();
        buf.putRawPublicKey(pub);
        final byte[] keyBin = buf.getCompactData();
        for (final String addr : advertised) {
            try {
                r.add(new HostKey(addr, keyBin));
            } catch (JSchException e) {
                sshDaemonLog.warn("Cannot format SSHD host key", e);
            }
        }
    }
    return Collections.unmodifiableList(r);
}
#end_block

#method_before
private void initProviderBouncyCastle(Config cfg) {
    setKeyExchangeFactories(filter(cfg, "kex", new DHG14.Factory(), new DHG1.Factory(), new DHGEX.Factory(), new DHGEX256.Factory(), new ECDHP256.Factory(), new ECDHP384.Factory(), new ECDHP521.Factory()));
    NamedFactory<Random> factory;
    if (cfg.getBoolean("sshd", null, "testUseInsecureRandom", false)) {
        factory = new InsecureBouncyCastleRandom.Factory();
    } else {
        factory = new BouncyCastleRandom.Factory();
    }
    setRandomFactory(new SingletonRandomFactory(factory));
}
#method_after
private void initProviderBouncyCastle(Config cfg) {
    NamedFactory<Random> factory;
    if (cfg.getBoolean("sshd", null, "testUseInsecureRandom", false)) {
        factory = new InsecureBouncyCastleRandom.Factory();
    } else {
        factory = SecurityUtils.getRandomFactory();
    }
    setRandomFactory(new SingletonRandomFactory(factory));
}
#end_block

#method_before
@Override
public void fill(byte[] bytes, int start, int len) {
    random.nextBytes(bytes, start, len);
}
#method_after
@Override
public void fill(byte[] bytes) {
    random.nextBytes(bytes);
}
#end_block

#method_before
private void initProviderJce() {
    setKeyExchangeFactories(Arrays.<NamedFactory<KeyExchange>>asList(new DHG1.Factory()));
    setRandomFactory(new SingletonRandomFactory(new JceRandom.Factory()));
}
#method_after
private void initProviderJce() {
    setRandomFactory(new SingletonRandomFactory(JceRandomFactory.INSTANCE));
}
#end_block

#method_before
@SuppressWarnings("unchecked")
private void initCiphers(final Config cfg) {
    final List<NamedFactory<Cipher>> a = new LinkedList<>();
    a.add(new AES128CBC.Factory());
    a.add(new TripleDESCBC.Factory());
    a.add(new BlowfishCBC.Factory());
    a.add(new AES192CBC.Factory());
    a.add(new AES256CBC.Factory());
    a.add(new AES128CTR.Factory());
    a.add(new AES256CTR.Factory());
    a.add(new ARCFOUR256.Factory());
    a.add(new ARCFOUR128.Factory());
    for (Iterator<NamedFactory<Cipher>> i = a.iterator(); i.hasNext(); ) {
        final NamedFactory<Cipher> f = i.next();
        try {
            final Cipher c = f.create();
            final byte[] key = new byte[c.getBlockSize()];
            final byte[] iv = new byte[c.getIVSize()];
            c.init(Cipher.Mode.Encrypt, key, iv);
        } catch (InvalidKeyException e) {
            log.warn("Disabling cipher " + f.getName() + ": " + e.getMessage() + "; try installing unlimited cryptography extension");
            i.remove();
        } catch (Exception e) {
            log.warn("Disabling cipher " + f.getName() + ": " + e.getMessage());
            i.remove();
        }
    }
    a.add(null);
    a.add(new CipherNone.Factory());
    setCipherFactories(filter(cfg, "cipher", (NamedFactory<Cipher>[]) a.toArray(new NamedFactory[a.size()])));
}
#method_after
@SuppressWarnings("unchecked")
private void initCiphers(final Config cfg) {
    final List<NamedFactory<Cipher>> a = BaseBuilder.setUpDefaultCiphers(true);
    for (Iterator<NamedFactory<Cipher>> i = a.iterator(); i.hasNext(); ) {
        final NamedFactory<Cipher> f = i.next();
        try {
            final Cipher c = f.create();
            final byte[] key = new byte[c.getBlockSize()];
            final byte[] iv = new byte[c.getIVSize()];
            c.init(Cipher.Mode.Encrypt, key, iv);
        } catch (InvalidKeyException e) {
            sshDaemonLog.warn("Disabling cipher " + f.getName() + ": " + e.getMessage() + "; try installing unlimited cryptography extension");
            i.remove();
        } catch (Exception e) {
            sshDaemonLog.warn("Disabling cipher " + f.getName() + ": " + e.getMessage());
            i.remove();
        }
    }
    a.add(null);
    setCipherFactories(filter(cfg, "cipher", (NamedFactory<Cipher>[]) a.toArray(new NamedFactory[a.size()])));
}
#end_block

#method_before
private void initMacs(final Config cfg) {
    setMacFactories(filter(cfg, "mac", new HMACMD5.Factory(), new HMACSHA1.Factory(), new HMACMD596.Factory(), new HMACSHA196.Factory()));
}
#method_after
@SuppressWarnings("unchecked")
private void initMacs(Config cfg) {
    List<NamedFactory<Mac>> m = BaseBuilder.setUpDefaultMacs(true);
    setMacFactories(filter(cfg, "mac", (NamedFactory<Mac>[]) m.toArray(new NamedFactory[m.size()])));
}
#end_block

#method_before
@SafeVarargs
private static <T> List<NamedFactory<T>> filter(final Config cfg, final String key, final NamedFactory<T>... avail) {
    final ArrayList<NamedFactory<T>> def = new ArrayList<>();
    for (final NamedFactory<T> n : avail) {
        if (n == null) {
            break;
        }
        def.add(n);
    }
    final String[] want = cfg.getStringList("sshd", null, key);
    if (want == null || want.length == 0) {
        return def;
    }
    boolean didClear = false;
    for (final String setting : want) {
        String name = setting.trim();
        boolean add = true;
        if (name.startsWith("-")) {
            add = false;
            name = name.substring(1).trim();
        } else if (name.startsWith("+")) {
            name = name.substring(1).trim();
        } else if (!didClear) {
            didClear = true;
            def.clear();
        }
        final NamedFactory<T> n = find(name, avail);
        if (n == null) {
            final StringBuilder msg = new StringBuilder();
            msg.append("sshd.").append(key).append(" = ").append(name).append(" unsupported; only ");
            for (int i = 0; i < avail.length; i++) {
                if (avail[i] == null) {
                    continue;
                }
                if (i > 0) {
                    msg.append(", ");
                }
                msg.append(avail[i].getName());
            }
            msg.append(" is supported");
            log.error(msg.toString());
        } else if (add) {
            if (!def.contains(n)) {
                def.add(n);
            }
        } else {
            def.remove(n);
        }
    }
    return def;
}
#method_after
@SafeVarargs
private static <T> List<NamedFactory<T>> filter(final Config cfg, final String key, final NamedFactory<T>... avail) {
    final ArrayList<NamedFactory<T>> def = new ArrayList<>();
    for (final NamedFactory<T> n : avail) {
        if (n == null) {
            break;
        }
        def.add(n);
    }
    final String[] want = cfg.getStringList("sshd", null, key);
    if (want == null || want.length == 0) {
        return def;
    }
    boolean didClear = false;
    for (final String setting : want) {
        String name = setting.trim();
        boolean add = true;
        if (name.startsWith("-")) {
            add = false;
            name = name.substring(1).trim();
        } else if (name.startsWith("+")) {
            name = name.substring(1).trim();
        } else if (!didClear) {
            didClear = true;
            def.clear();
        }
        final NamedFactory<T> n = find(name, avail);
        if (n == null) {
            final StringBuilder msg = new StringBuilder();
            msg.append("sshd.").append(key).append(" = ").append(name).append(" unsupported; only ");
            for (int i = 0; i < avail.length; i++) {
                if (avail[i] == null) {
                    continue;
                }
                if (i > 0) {
                    msg.append(", ");
                }
                msg.append(avail[i].getName());
            }
            msg.append(" is supported");
            sshDaemonLog.error(msg.toString());
        } else if (add) {
            if (!def.contains(n)) {
                def.add(n);
            }
        } else {
            def.remove(n);
        }
    }
    return def;
}
#end_block

#method_before
private void initSignatures() {
    setSignatureFactories(Arrays.<NamedFactory<Signature>>asList(new SignatureDSA.Factory(), new SignatureRSA.Factory(), new SignatureECDSA.NISTP256Factory(), new SignatureECDSA.NISTP384Factory(), new SignatureECDSA.NISTP521Factory()));
}
#method_after
private void initSignatures() {
    setSignatureFactories(BaseBuilder.setUpDefaultSignatures(true));
}
#end_block

#method_before
private void initCompression(boolean enableCompression) {
    List<NamedFactory<Compression>> compressionFactories = Lists.newArrayList();
    // Always support no compression over SSHD.
    compressionFactories.add(new CompressionNone.Factory());
    if (enableCompression) {
        compressionFactories.add(new CompressionZlib.Factory());
    }
    setCompressionFactories(compressionFactories);
}
#method_after
private void initCompression(boolean enableCompression) {
    List<NamedFactory<Compression>> compressionFactories = new ArrayList<>();
    // Always support no compression over SSHD.
    compressionFactories.add(BuiltinCompressions.none);
    if (enableCompression) {
        compressionFactories.add(BuiltinCompressions.zlib);
    }
    setCompressionFactories(compressionFactories);
}
#end_block

#method_before
private void initChannels() {
    setChannelFactories(Arrays.<NamedFactory<Channel>>asList(// 
    new ChannelSession.Factory(), // 
    new TcpipServerChannel.DirectTcpipFactory()));
}
#method_after
private void initChannels() {
    setChannelFactories(ServerBuilder.DEFAULT_CHANNEL_FACTORIES);
}
#end_block

#method_before
private void initUserAuth(final PublickeyAuthenticator pubkey, final GSSAuthenticator kerberosAuthenticator, String kerberosKeytab, String kerberosPrincipal) {
    List<NamedFactory<UserAuth>> authFactories = Lists.newArrayList();
    if (kerberosKeytab != null) {
        authFactories.add(new UserAuthGSS.Factory());
        log.info("Enabling kerberos with keytab " + kerberosKeytab);
        if (!new File(kerberosKeytab).canRead()) {
            log.error("Keytab " + kerberosKeytab + " does not exist or is not readable; further errors are possible");
        }
        kerberosAuthenticator.setKeytabFile(kerberosKeytab);
        if (kerberosPrincipal == null) {
            try {
                kerberosPrincipal = "host/" + InetAddress.getLocalHost().getCanonicalHostName();
            } catch (UnknownHostException e) {
                kerberosPrincipal = "host/localhost";
            }
        }
        log.info("Using kerberos principal " + kerberosPrincipal);
        if (!kerberosPrincipal.startsWith("host/")) {
            log.warn("Host principal does not start with host/ " + "which most SSH clients will supply automatically");
        }
        kerberosAuthenticator.setServicePrincipalName(kerberosPrincipal);
        setGSSAuthenticator(kerberosAuthenticator);
    }
    authFactories.add(new UserAuthPublicKey.Factory());
    setUserAuthFactories(authFactories);
    setPublickeyAuthenticator(pubkey);
}
#method_after
private void initUserAuth(final PublickeyAuthenticator pubkey, final GSSAuthenticator kerberosAuthenticator, String kerberosKeytab, String kerberosPrincipal) {
    List<NamedFactory<UserAuth>> authFactories = new ArrayList<>();
    if (kerberosKeytab != null) {
        authFactories.add(UserAuthGSSFactory.INSTANCE);
        log.info("Enabling kerberos with keytab " + kerberosKeytab);
        if (!new File(kerberosKeytab).canRead()) {
            sshDaemonLog.error("Keytab " + kerberosKeytab + " does not exist or is not readable; further errors are possible");
        }
        kerberosAuthenticator.setKeytabFile(kerberosKeytab);
        if (kerberosPrincipal == null) {
            try {
                kerberosPrincipal = "host/" + InetAddress.getLocalHost().getCanonicalHostName();
            } catch (UnknownHostException e) {
                kerberosPrincipal = "host/localhost";
            }
        }
        sshDaemonLog.info("Using kerberos principal " + kerberosPrincipal);
        if (!kerberosPrincipal.startsWith("host/")) {
            sshDaemonLog.warn("Host principal does not start with host/ " + "which most SSH clients will supply automatically");
        }
        kerberosAuthenticator.setServicePrincipalName(kerberosPrincipal);
        setGSSAuthenticator(kerberosAuthenticator);
    }
    authFactories.add(UserAuthPublicKeyFactory.INSTANCE);
    setUserAuthFactories(authFactories);
    setPublickeyAuthenticator(pubkey);
}
#end_block

#method_before
private void initForwarding() {
    setTcpipForwardingFilter(new ForwardingFilter() {

        @Override
        public boolean canForwardAgent(Session session) {
            return false;
        }

        @Override
        public boolean canForwardX11(Session session) {
            return false;
        }

        @Override
        public boolean canListen(SshdSocketAddress address, Session session) {
            return false;
        }

        @Override
        public boolean canConnect(SshdSocketAddress address, Session session) {
            return false;
        }
    });
    setTcpipForwarderFactory(new DefaultTcpipForwarderFactory());
}
#method_after
private void initForwarding() {
    setTcpipForwardingFilter(new ForwardingFilter() {

        @Override
        public boolean canForwardAgent(Session session) {
            return false;
        }

        @Override
        public boolean canForwardX11(Session session) {
            return false;
        }

        @Override
        public boolean canListen(SshdSocketAddress address, Session session) {
            return false;
        }

        @Override
        public boolean canConnect(Type type, SshdSocketAddress address, Session session) {
            return false;
        }
    });
    setTcpipForwarderFactory(new DefaultTcpipForwarderFactory());
}
#end_block

#method_before
private void initFileSystemFactory() {
    setFileSystemFactory(new FileSystemFactory() {

        @Override
        public FileSystemView createFileSystemView(Session session) throws IOException {
            return new FileSystemView() {

                @Override
                public SshFile getFile(SshFile baseDir, String file) {
                    return null;
                }

                @Override
                public SshFile getFile(String file) {
                    return null;
                }

                @Override
                public FileSystemView getNormalizedView() {
                    return this;
                }
            };
        }
    });
}
#method_after
private void initFileSystemFactory() {
    setFileSystemFactory(new FileSystemFactory() {

        @Override
        public FileSystem createFileSystem(Session session) throws IOException {
            return new FileSystem() {

                @Override
                public void close() throws IOException {
                }

                @Override
                public Iterable<FileStore> getFileStores() {
                    return null;
                }

                @Override
                public Path getPath(String arg0, String... arg1) {
                    return null;
                }

                @Override
                public PathMatcher getPathMatcher(String arg0) {
                    return null;
                }

                @Override
                public Iterable<Path> getRootDirectories() {
                    return null;
                }

                @Override
                public String getSeparator() {
                    return null;
                }

                @Override
                public UserPrincipalLookupService getUserPrincipalLookupService() {
                    return null;
                }

                @Override
                public boolean isOpen() {
                    return false;
                }

                @Override
                public boolean isReadOnly() {
                    return false;
                }

                @Override
                public WatchService newWatchService() throws IOException {
                    return null;
                }

                @Override
                public FileSystemProvider provider() {
                    return null;
                }

                @Override
                public Set<String> supportedFileAttributeViews() {
                    return null;
                }
            };
        }
    });
}
#end_block

#method_before
@Test
@GerritConfig(name = "auth.contributorAgreements", value = "true")
public void anonymousAccess() throws Exception {
    configureContributorAgreement();
    setApiUserAnonymous();
    gApi.config().server().getInfo();
}
#method_after
@Test
@GerritConfig(name = "auth.contributorAgreements", value = "true")
public void anonymousAccess() throws Exception {
    configureContributorAgreement(true);
    setApiUserAnonymous();
    gApi.config().server().getInfo();
}
#end_block

#method_before
protected void setApiHeaders(HttpServletRequest req, HttpServletResponse res, String contentType) throws IOException {
    if (!Strings.isNullOrEmpty(contentType)) {
        res.setContentType(contentType);
    }
    res.setCharacterEncoding(UTF_8.name());
    res.setHeader(HttpHeaders.CONTENT_DISPOSITION, "attachment");
    GitilesAccess access = getAccess(req);
    String[] allowOrigin = access.getConfig().getStringList("gitiles", null, "allowOriginRegex");
    if (allowOrigin.length > 0) {
        String origin = req.getHeader(HttpHeaders.ORIGIN);
        Pattern allowOriginPattern = Pattern.compile(Joiner.on("|").skipNulls().join(allowOrigin));
        if (!(origin == null || origin.isEmpty()) && allowOriginPattern.matcher(origin).matches()) {
            res.setHeader(HttpHeaders.ACCESS_CONTROL_ALLOW_ORIGIN, origin);
        }
    } else {
        res.setHeader(HttpHeaders.ACCESS_CONTROL_ALLOW_ORIGIN, "*");
    }
    setCacheHeaders(res);
}
#method_after
protected void setApiHeaders(HttpServletRequest req, HttpServletResponse res, String contentType) throws IOException {
    if (!Strings.isNullOrEmpty(contentType)) {
        res.setContentType(contentType);
    }
    res.setCharacterEncoding(UTF_8.name());
    res.setHeader(HttpHeaders.CONTENT_DISPOSITION, "attachment");
    GitilesAccess access = getAccess(req);
    String[] allowOrigin = access.getConfig().getStringList("gitiles", null, "allowOriginRegex");
    if (allowOrigin.length > 0) {
        String origin = req.getHeader(HttpHeaders.ORIGIN);
        Pattern allowOriginPattern = Pattern.compile(Joiner.on("|").join(allowOrigin));
        if (!Strings.isNullOrEmpty(origin) && allowOriginPattern.matcher(origin).matches()) {
            res.setHeader(HttpHeaders.ACCESS_CONTROL_ALLOW_ORIGIN, origin);
        }
    } else {
        res.setHeader(HttpHeaders.ACCESS_CONTROL_ALLOW_ORIGIN, "*");
    }
    setCacheHeaders(res);
}
#end_block

#method_before
protected FakeHttpServletResponse buildResponse(String path, String queryString, int expectedStatus) throws Exception {
    FakeHttpServletRequest req = FakeHttpServletRequest.newRequest();
    req.setHeader(HttpHeaders.ORIGIN, "http://localhost");
    req.setPathInfo(path);
    if (queryString != null) {
        req.setQueryString(queryString);
    }
    FakeHttpServletResponse res = new FakeHttpServletResponse();
    servlet.service(req, res);
    assertThat(res.getStatus()).isEqualTo(expectedStatus);
    return res;
}
#method_after
protected FakeHttpServletResponse buildResponse(String path, String queryString, int expectedStatus, String origin) throws Exception {
    FakeHttpServletRequest req = FakeHttpServletRequest.newRequest();
    req.setHeader(HttpHeaders.ORIGIN, origin);
    req.setPathInfo(path);
    if (queryString != null) {
        req.setQueryString(queryString);
    }
    FakeHttpServletResponse res = new FakeHttpServletResponse();
    servlet.service(req, res);
    assertThat(res.getStatus()).isEqualTo(expectedStatus);
    return res;
}
#end_block

#method_before
protected FakeHttpServletResponse buildResponse(String path, String queryString, int expectedStatus) throws Exception {
    FakeHttpServletRequest req = FakeHttpServletRequest.newRequest();
    req.setHeader(HttpHeaders.ORIGIN, "http://localhost");
    req.setPathInfo(path);
    if (queryString != null) {
        req.setQueryString(queryString);
    }
    FakeHttpServletResponse res = new FakeHttpServletResponse();
    servlet.service(req, res);
    assertThat(res.getStatus()).isEqualTo(expectedStatus);
    return res;
}
#method_after
protected FakeHttpServletResponse buildResponse(String path, String queryString, int expectedStatus) throws Exception {
    return buildResponse(path, queryString, expectedStatus, "http://localhost");
}
#end_block

#method_before
@Override
protected void configure() {
    bind(EmailExpander.class).toProvider(EmailExpanderProvider.class).in(SINGLETON);
    bind(IdGenerator.class);
    bind(RulesCache.class);
    bind(BlameCache.class).to(BlameCacheImpl.class);
    bind(Sequences.class);
    install(authModule);
    install(AccountByEmailCacheImpl.module());
    install(AccountCacheImpl.module());
    install(ChangeKindCacheImpl.module());
    install(ConflictsCacheImpl.module());
    install(GroupCacheImpl.module());
    install(GroupIncludeCacheImpl.module());
    install(MergeabilityCacheImpl.module());
    install(PatchListCacheImpl.module());
    install(ProjectCacheImpl.module());
    install(SectionSortCache.module());
    install(SubmitStrategy.module());
    install(TagCache.module());
    install(OAuthTokenCache.module());
    install(new AccessControlModule());
    install(new CmdLineParserModule());
    install(new EmailModule());
    install(new GitModule());
    install(new GroupModule());
    install(new NoteDbModule(cfg));
    install(new PrologModule());
    install(new SshAddressesModule());
    install(ThreadLocalRequestContext.module());
    bind(AccountResolver.class);
    factory(AccountInfoCacheFactory.Factory.class);
    factory(AddReviewerSender.Factory.class);
    factory(DeleteReviewerSender.Factory.class);
    factory(AddKeySender.Factory.class);
    factory(BatchUpdate.Factory.class);
    factory(CapabilityCollection.Factory.class);
    factory(CapabilityControl.Factory.class);
    factory(ChangeData.Factory.class);
    factory(ChangeJson.Factory.class);
    factory(CreateChangeSender.Factory.class);
    factory(GroupDetailFactory.Factory.class);
    factory(GroupInfoCache.Factory.class);
    factory(GroupMembers.Factory.class);
    factory(EmailMerge.Factory.class);
    factory(MergedSender.Factory.class);
    factory(MergeUtil.Factory.class);
    factory(PatchScriptFactory.Factory.class);
    factory(PluginUser.Factory.class);
    factory(ProjectNode.Factory.class);
    factory(ProjectState.Factory.class);
    factory(RegisterNewEmailSender.Factory.class);
    factory(ReplacePatchSetSender.Factory.class);
    bind(PermissionCollection.Factory.class);
    bind(AccountVisibility.class).toProvider(AccountVisibilityProvider.class).in(SINGLETON);
    factory(ProjectOwnerGroupsProvider.Factory.class);
    bind(AuthBackend.class).to(UniversalAuthBackend.class).in(SINGLETON);
    DynamicSet.setOf(binder(), AuthBackend.class);
    bind(GroupControl.Factory.class).in(SINGLETON);
    bind(GroupControl.GenericFactory.class).in(SINGLETON);
    bind(FileTypeRegistry.class).to(MimeUtilFileTypeRegistry.class);
    bind(ToolsCatalog.class);
    bind(EventFactory.class);
    bind(TransferConfig.class);
    bind(GcConfig.class);
    bind(ChangeCleanupConfig.class);
    bind(ApprovalsUtil.class);
    bind(RuntimeInstance.class).toProvider(VelocityRuntimeProvider.class);
    bind(SoyTofu.class).toProvider(SoyTofuProvider.class);
    bind(FromAddressGenerator.class).toProvider(FromAddressGeneratorProvider.class).in(SINGLETON);
    bind(Boolean.class).annotatedWith(DisableReverseDnsLookup.class).toProvider(DisableReverseDnsLookupProvider.class).in(SINGLETON);
    bind(PatchSetInfoFactory.class);
    bind(IdentifiedUser.GenericFactory.class).in(SINGLETON);
    bind(ChangeControl.GenericFactory.class);
    bind(ProjectControl.GenericFactory.class);
    bind(AccountControl.Factory.class);
    install(new AuditModule());
    install(new com.google.gerrit.server.access.Module());
    install(new com.google.gerrit.server.account.Module());
    install(new com.google.gerrit.server.api.Module());
    install(new com.google.gerrit.server.change.Module());
    install(new com.google.gerrit.server.config.Module());
    install(new com.google.gerrit.server.group.Module());
    install(new com.google.gerrit.server.project.Module());
    bind(GitReferenceUpdated.class);
    DynamicMap.mapOf(binder(), new TypeLiteral<Cache<?, ?>>() {
    });
    DynamicSet.setOf(binder(), CacheRemovalListener.class);
    DynamicMap.mapOf(binder(), CapabilityDefinition.class);
    DynamicSet.setOf(binder(), GitReferenceUpdatedListener.class);
    DynamicSet.setOf(binder(), ChangeAbandonedListener.class);
    DynamicSet.setOf(binder(), CommentAddedListener.class);
    DynamicSet.setOf(binder(), DraftPublishedListener.class);
    DynamicSet.setOf(binder(), HashtagsEditedListener.class);
    DynamicSet.setOf(binder(), ChangeMergedListener.class);
    DynamicSet.setOf(binder(), ChangeRestoredListener.class);
    DynamicSet.setOf(binder(), ChangeRevertedListener.class);
    DynamicSet.setOf(binder(), ReviewerAddedListener.class);
    DynamicSet.setOf(binder(), ReviewerDeletedListener.class);
    DynamicSet.setOf(binder(), VoteDeletedListener.class);
    DynamicSet.setOf(binder(), RevisionCreatedListener.class);
    DynamicSet.setOf(binder(), TopicEditedListener.class);
    DynamicSet.setOf(binder(), AgreementSignupListener.class);
    DynamicSet.setOf(binder(), PluginEventListener.class);
    DynamicSet.setOf(binder(), ReceivePackInitializer.class);
    DynamicSet.setOf(binder(), PostReceiveHook.class);
    DynamicSet.setOf(binder(), PreUploadHook.class);
    DynamicSet.setOf(binder(), PostUploadHook.class);
    DynamicSet.setOf(binder(), ChangeIndexedListener.class);
    DynamicSet.setOf(binder(), NewProjectCreatedListener.class);
    DynamicSet.setOf(binder(), ProjectDeletedListener.class);
    DynamicSet.setOf(binder(), GarbageCollectorListener.class);
    DynamicSet.setOf(binder(), HeadUpdatedListener.class);
    DynamicSet.setOf(binder(), UsageDataPublishedListener.class);
    DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(ReindexAfterUpdate.class);
    DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(ProjectConfigEntry.UpdateChecker.class);
    DynamicSet.setOf(binder(), EventListener.class);
    DynamicSet.bind(binder(), EventListener.class).to(EventsMetrics.class);
    DynamicSet.setOf(binder(), UserScopedEventListener.class);
    DynamicSet.setOf(binder(), CommitValidationListener.class);
    DynamicSet.setOf(binder(), RefOperationValidationListener.class);
    DynamicSet.setOf(binder(), MergeValidationListener.class);
    DynamicSet.setOf(binder(), ProjectCreationValidationListener.class);
    DynamicSet.setOf(binder(), GroupCreationValidationListener.class);
    DynamicSet.setOf(binder(), HashtagValidationListener.class);
    DynamicSet.setOf(binder(), OutgoingEmailValidationListener.class);
    DynamicItem.itemOf(binder(), AvatarProvider.class);
    DynamicSet.setOf(binder(), LifecycleListener.class);
    DynamicSet.setOf(binder(), TopMenu.class);
    DynamicSet.setOf(binder(), MessageOfTheDay.class);
    DynamicMap.mapOf(binder(), DownloadScheme.class);
    DynamicMap.mapOf(binder(), DownloadCommand.class);
    DynamicMap.mapOf(binder(), CloneCommand.class);
    DynamicSet.setOf(binder(), ExternalIncludedIn.class);
    DynamicMap.mapOf(binder(), ProjectConfigEntry.class);
    DynamicSet.setOf(binder(), PatchSetWebLink.class);
    DynamicSet.setOf(binder(), FileWebLink.class);
    DynamicSet.setOf(binder(), FileHistoryWebLink.class);
    DynamicSet.setOf(binder(), DiffWebLink.class);
    DynamicSet.setOf(binder(), ProjectWebLink.class);
    DynamicSet.setOf(binder(), BranchWebLink.class);
    DynamicMap.mapOf(binder(), OAuthLoginProvider.class);
    DynamicItem.itemOf(binder(), OAuthTokenEncrypter.class);
    DynamicSet.setOf(binder(), AccountExternalIdCreator.class);
    DynamicSet.setOf(binder(), WebUiPlugin.class);
    DynamicItem.itemOf(binder(), AccountPatchReviewStore.class);
    factory(UploadValidators.Factory.class);
    DynamicSet.setOf(binder(), UploadValidationListener.class);
    DynamicMap.mapOf(binder(), ChangeQueryBuilder.ChangeOperatorFactory.class);
    install(new GitwebConfig.LegacyModule(cfg));
    bind(AnonymousUser.class);
    factory(CommitValidators.Factory.class);
    factory(RefOperationValidators.Factory.class);
    factory(MergeValidators.Factory.class);
    factory(ProjectConfigValidator.Factory.class);
    factory(NotesBranchUtil.Factory.class);
    factory(ReplaceOp.Factory.class);
    factory(MergedByPushOp.Factory.class);
    factory(GitModules.Factory.class);
    factory(VersionedAuthorizedKeys.Factory.class);
    factory(SubmoduleOp.Factory.class);
    bind(AccountManager.class);
    factory(ChangeUserName.Factory.class);
    bind(new TypeLiteral<List<CommentLinkInfo>>() {
    }).toProvider(CommentLinkProvider.class).in(SINGLETON);
    bind(ReloadPluginListener.class).annotatedWith(UniqueAnnotations.create()).to(PluginConfigFactory.class);
}
#method_after
@Override
protected void configure() {
    bind(EmailExpander.class).toProvider(EmailExpanderProvider.class).in(SINGLETON);
    bind(IdGenerator.class);
    bind(RulesCache.class);
    bind(BlameCache.class).to(BlameCacheImpl.class);
    bind(Sequences.class);
    install(authModule);
    install(AccountByEmailCacheImpl.module());
    install(AccountCacheImpl.module());
    install(ChangeKindCacheImpl.module());
    install(ConflictsCacheImpl.module());
    install(GroupCacheImpl.module());
    install(GroupIncludeCacheImpl.module());
    install(MergeabilityCacheImpl.module());
    install(PatchListCacheImpl.module());
    install(ProjectCacheImpl.module());
    install(SectionSortCache.module());
    install(SubmitStrategy.module());
    install(TagCache.module());
    install(OAuthTokenCache.module());
    install(new AccessControlModule());
    install(new CmdLineParserModule());
    install(new EmailModule());
    install(new GitModule());
    install(new GroupModule());
    install(new NoteDbModule(cfg));
    install(new PrologModule());
    install(new SshAddressesModule());
    install(ThreadLocalRequestContext.module());
    bind(AccountResolver.class);
    factory(AccountInfoCacheFactory.Factory.class);
    factory(AddReviewerSender.Factory.class);
    factory(DeleteReviewerSender.Factory.class);
    factory(AddKeySender.Factory.class);
    factory(BatchUpdate.Factory.class);
    factory(CapabilityCollection.Factory.class);
    factory(CapabilityControl.Factory.class);
    factory(ChangeData.Factory.class);
    factory(ChangeJson.Factory.class);
    factory(CreateChangeSender.Factory.class);
    factory(GroupDetailFactory.Factory.class);
    factory(GroupInfoCache.Factory.class);
    factory(GroupMembers.Factory.class);
    factory(EmailMerge.Factory.class);
    factory(MergedSender.Factory.class);
    factory(MergeUtil.Factory.class);
    factory(PatchScriptFactory.Factory.class);
    factory(PluginUser.Factory.class);
    factory(ProjectNode.Factory.class);
    factory(ProjectState.Factory.class);
    factory(RegisterNewEmailSender.Factory.class);
    factory(ReplacePatchSetSender.Factory.class);
    bind(PermissionCollection.Factory.class);
    bind(AccountVisibility.class).toProvider(AccountVisibilityProvider.class).in(SINGLETON);
    factory(ProjectOwnerGroupsProvider.Factory.class);
    bind(AuthBackend.class).to(UniversalAuthBackend.class).in(SINGLETON);
    DynamicSet.setOf(binder(), AuthBackend.class);
    bind(GroupControl.Factory.class).in(SINGLETON);
    bind(GroupControl.GenericFactory.class).in(SINGLETON);
    bind(FileTypeRegistry.class).to(MimeUtilFileTypeRegistry.class);
    bind(ToolsCatalog.class);
    bind(EventFactory.class);
    bind(TransferConfig.class);
    bind(GcConfig.class);
    bind(ChangeCleanupConfig.class);
    bind(ApprovalsUtil.class);
    bind(RuntimeInstance.class).toProvider(VelocityRuntimeProvider.class);
    bind(SoyTofu.class).annotatedWith(MailTemplates.class).toProvider(MailSoyTofuProvider.class);
    bind(FromAddressGenerator.class).toProvider(FromAddressGeneratorProvider.class).in(SINGLETON);
    bind(Boolean.class).annotatedWith(DisableReverseDnsLookup.class).toProvider(DisableReverseDnsLookupProvider.class).in(SINGLETON);
    bind(PatchSetInfoFactory.class);
    bind(IdentifiedUser.GenericFactory.class).in(SINGLETON);
    bind(ChangeControl.GenericFactory.class);
    bind(ProjectControl.GenericFactory.class);
    bind(AccountControl.Factory.class);
    install(new AuditModule());
    install(new com.google.gerrit.server.access.Module());
    install(new com.google.gerrit.server.account.Module());
    install(new com.google.gerrit.server.api.Module());
    install(new com.google.gerrit.server.change.Module());
    install(new com.google.gerrit.server.config.Module());
    install(new com.google.gerrit.server.group.Module());
    install(new com.google.gerrit.server.project.Module());
    bind(GitReferenceUpdated.class);
    DynamicMap.mapOf(binder(), new TypeLiteral<Cache<?, ?>>() {
    });
    DynamicSet.setOf(binder(), CacheRemovalListener.class);
    DynamicMap.mapOf(binder(), CapabilityDefinition.class);
    DynamicSet.setOf(binder(), GitReferenceUpdatedListener.class);
    DynamicSet.setOf(binder(), ChangeAbandonedListener.class);
    DynamicSet.setOf(binder(), CommentAddedListener.class);
    DynamicSet.setOf(binder(), DraftPublishedListener.class);
    DynamicSet.setOf(binder(), HashtagsEditedListener.class);
    DynamicSet.setOf(binder(), ChangeMergedListener.class);
    DynamicSet.setOf(binder(), ChangeRestoredListener.class);
    DynamicSet.setOf(binder(), ChangeRevertedListener.class);
    DynamicSet.setOf(binder(), ReviewerAddedListener.class);
    DynamicSet.setOf(binder(), ReviewerDeletedListener.class);
    DynamicSet.setOf(binder(), VoteDeletedListener.class);
    DynamicSet.setOf(binder(), RevisionCreatedListener.class);
    DynamicSet.setOf(binder(), TopicEditedListener.class);
    DynamicSet.setOf(binder(), AgreementSignupListener.class);
    DynamicSet.setOf(binder(), PluginEventListener.class);
    DynamicSet.setOf(binder(), ReceivePackInitializer.class);
    DynamicSet.setOf(binder(), PostReceiveHook.class);
    DynamicSet.setOf(binder(), PreUploadHook.class);
    DynamicSet.setOf(binder(), PostUploadHook.class);
    DynamicSet.setOf(binder(), ChangeIndexedListener.class);
    DynamicSet.setOf(binder(), NewProjectCreatedListener.class);
    DynamicSet.setOf(binder(), ProjectDeletedListener.class);
    DynamicSet.setOf(binder(), GarbageCollectorListener.class);
    DynamicSet.setOf(binder(), HeadUpdatedListener.class);
    DynamicSet.setOf(binder(), UsageDataPublishedListener.class);
    DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(ReindexAfterUpdate.class);
    DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(ProjectConfigEntry.UpdateChecker.class);
    DynamicSet.setOf(binder(), EventListener.class);
    DynamicSet.bind(binder(), EventListener.class).to(EventsMetrics.class);
    DynamicSet.setOf(binder(), UserScopedEventListener.class);
    DynamicSet.setOf(binder(), CommitValidationListener.class);
    DynamicSet.setOf(binder(), RefOperationValidationListener.class);
    DynamicSet.setOf(binder(), MergeValidationListener.class);
    DynamicSet.setOf(binder(), ProjectCreationValidationListener.class);
    DynamicSet.setOf(binder(), GroupCreationValidationListener.class);
    DynamicSet.setOf(binder(), HashtagValidationListener.class);
    DynamicSet.setOf(binder(), OutgoingEmailValidationListener.class);
    DynamicItem.itemOf(binder(), AvatarProvider.class);
    DynamicSet.setOf(binder(), LifecycleListener.class);
    DynamicSet.setOf(binder(), TopMenu.class);
    DynamicSet.setOf(binder(), MessageOfTheDay.class);
    DynamicMap.mapOf(binder(), DownloadScheme.class);
    DynamicMap.mapOf(binder(), DownloadCommand.class);
    DynamicMap.mapOf(binder(), CloneCommand.class);
    DynamicSet.setOf(binder(), ExternalIncludedIn.class);
    DynamicMap.mapOf(binder(), ProjectConfigEntry.class);
    DynamicSet.setOf(binder(), PatchSetWebLink.class);
    DynamicSet.setOf(binder(), FileWebLink.class);
    DynamicSet.setOf(binder(), FileHistoryWebLink.class);
    DynamicSet.setOf(binder(), DiffWebLink.class);
    DynamicSet.setOf(binder(), ProjectWebLink.class);
    DynamicSet.setOf(binder(), BranchWebLink.class);
    DynamicMap.mapOf(binder(), OAuthLoginProvider.class);
    DynamicItem.itemOf(binder(), OAuthTokenEncrypter.class);
    DynamicSet.setOf(binder(), AccountExternalIdCreator.class);
    DynamicSet.setOf(binder(), WebUiPlugin.class);
    DynamicItem.itemOf(binder(), AccountPatchReviewStore.class);
    factory(UploadValidators.Factory.class);
    DynamicSet.setOf(binder(), UploadValidationListener.class);
    DynamicMap.mapOf(binder(), ChangeQueryBuilder.ChangeOperatorFactory.class);
    install(new GitwebConfig.LegacyModule(cfg));
    bind(AnonymousUser.class);
    factory(CommitValidators.Factory.class);
    factory(RefOperationValidators.Factory.class);
    factory(MergeValidators.Factory.class);
    factory(ProjectConfigValidator.Factory.class);
    factory(NotesBranchUtil.Factory.class);
    factory(ReplaceOp.Factory.class);
    factory(MergedByPushOp.Factory.class);
    factory(GitModules.Factory.class);
    factory(VersionedAuthorizedKeys.Factory.class);
    factory(SubmoduleOp.Factory.class);
    bind(AccountManager.class);
    factory(ChangeUserName.Factory.class);
    bind(new TypeLiteral<List<CommentLinkInfo>>() {
    }).toProvider(CommentLinkProvider.class).in(SINGLETON);
    bind(ReloadPluginListener.class).annotatedWith(UniqueAnnotations.create()).to(PluginConfigFactory.class);
}
#end_block

#method_before
@Override
protected void onLoad() {
    super.onLoad();
    AccountApi.getAgreements("self", new GerritCallback<JsArray<AgreementInfo>>() {

        @Override
        public void onSuccess(JsArray<AgreementInfo> result) {
            if (isAttached()) {
                mySigned = new HashSet<>();
                for (AgreementInfo info : Natives.asList(result)) {
                    mySigned.add(info.name());
                }
                postRPC();
            }
        }
    });
    ConfigServerApi.serverInfo(new GerritCallback<ServerInfo>() {

        @Override
        public void onSuccess(ServerInfo result) {
            if (isAttached()) {
                available = result.auth().contributorAgrements();
                postRPC();
            }
        }
    });
}
#method_after
@Override
protected void onLoad() {
    super.onLoad();
    AccountApi.getAgreements("self", new GerritCallback<JsArray<AgreementInfo>>() {

        @Override
        public void onSuccess(JsArray<AgreementInfo> result) {
            if (isAttached()) {
                mySigned = new HashSet<>();
                for (AgreementInfo info : Natives.asList(result)) {
                    mySigned.add(info.name());
                }
                postRPC();
            }
        }
    });
    available = Gerrit.info().auth().contributorAgreements();
    postRPC();
}
#end_block

#method_before
@Override
protected void configureServlets() {
    filter("/*").through(Key.get(CacheControlFilter.class));
    bind(Key.get(CacheControlFilter.class)).in(SINGLETON);
    if (options.enableDefaultUi()) {
        filter("/").through(XsrfCookieFilter.class);
        serve("/").with(HostPageServlet.class);
        serve("/Gerrit").with(LegacyGerritServlet.class);
        serve("/Gerrit/*").with(legacyGerritScreen());
        // Forward PolyGerrit URLs to their respective GWT equivalents.
        serveRegex("^/(c|q|x|admin|dashboard|settings)/(.*)").with(gerritUrl());
    }
    serve("/cat/*").with(CatServlet.class);
    if (authConfig.getAuthType() != AuthType.OAUTH && authConfig.getAuthType() != AuthType.OPENID) {
        serve("/logout").with(HttpLogoutServlet.class);
        serve("/signout").with(HttpLogoutServlet.class);
    }
    serve("/ssh_info").with(SshInfoServlet.class);
    serve("/Main.class").with(notFound());
    serve("/com/google/gerrit/launcher/*").with(notFound());
    serve("/servlet/*").with(notFound());
    serve("/all").with(query("status:merged"));
    serve("/mine").with(screen(PageLinks.MINE));
    serve("/open").with(query("status:open"));
    serve("/watched").with(query("is:watched status:open"));
    serve("/starred").with(query("is:starred"));
    serveRegex("^/settings/?$").with(screen(PageLinks.SETTINGS));
    serveRegex("^/register/?$").with(screen(PageLinks.REGISTER + "/"));
    serveRegex("^/([1-9][0-9]*)/?$").with(directChangeById());
    serveRegex("^/p/(.*)$").with(queryProjectNew());
    serveRegex("^/r/(.+)/?$").with(DirectChangeByCommit.class);
    filter("/a/*").through(RequireIdentifiedUserFilter.class);
    serveRegex("^/(?:a/)?tools/(.*)$").with(ToolServlet.class);
    serveRegex("^/(?:a/)?access/(.*)$").with(AccessRestApiServlet.class);
    serveRegex("^/(?:a/)?accounts/(.*)$").with(AccountsRestApiServlet.class);
    serveRegex("^/(?:a/)?changes/(.*)$").with(ChangesRestApiServlet.class);
    serveRegex("^/(?:a/)?config/(.*)$").with(ConfigRestApiServlet.class);
    serveRegex("^/(?:a/)?groups/(.*)?$").with(GroupsRestApiServlet.class);
    serveRegex("^/(?:a/)?projects/(.*)?$").with(ProjectsRestApiServlet.class);
    filter("/Documentation/").through(QueryDocumentationFilter.class);
}
#method_after
@Override
protected void configureServlets() {
    filter("/*").through(Key.get(CacheControlFilter.class));
    bind(Key.get(CacheControlFilter.class)).in(SINGLETON);
    if (options.enableDefaultUi()) {
        filter("/").through(XsrfCookieFilter.class);
        filter("/accounts/self/detail").through(XsrfCookieFilter.class);
        serve("/").with(HostPageServlet.class);
        serve("/Gerrit").with(LegacyGerritServlet.class);
        serve("/Gerrit/*").with(legacyGerritScreen());
        // Forward PolyGerrit URLs to their respective GWT equivalents.
        serveRegex("^/(c|q|x|admin|dashboard|settings)/(.*)").with(gerritUrl());
    }
    serve("/cat/*").with(CatServlet.class);
    if (authConfig.getAuthType() != AuthType.OAUTH && authConfig.getAuthType() != AuthType.OPENID) {
        serve("/logout").with(HttpLogoutServlet.class);
        serve("/signout").with(HttpLogoutServlet.class);
    }
    serve("/ssh_info").with(SshInfoServlet.class);
    serve("/Main.class").with(notFound());
    serve("/com/google/gerrit/launcher/*").with(notFound());
    serve("/servlet/*").with(notFound());
    serve("/all").with(query("status:merged"));
    serve("/mine").with(screen(PageLinks.MINE));
    serve("/open").with(query("status:open"));
    serve("/watched").with(query("is:watched status:open"));
    serve("/starred").with(query("is:starred"));
    serveRegex("^/settings/?$").with(screen(PageLinks.SETTINGS));
    serveRegex("^/register/?$").with(screen(PageLinks.REGISTER + "/"));
    serveRegex("^/([1-9][0-9]*)/?$").with(directChangeById());
    serveRegex("^/p/(.*)$").with(queryProjectNew());
    serveRegex("^/r/(.+)/?$").with(DirectChangeByCommit.class);
    filter("/a/*").through(RequireIdentifiedUserFilter.class);
    serveRegex("^/(?:a/)?tools/(.*)$").with(ToolServlet.class);
    serveRegex("^/(?:a/)?access/(.*)$").with(AccessRestApiServlet.class);
    serveRegex("^/(?:a/)?accounts/(.*)$").with(AccountsRestApiServlet.class);
    serveRegex("^/(?:a/)?changes/(.*)$").with(ChangesRestApiServlet.class);
    serveRegex("^/(?:a/)?config/(.*)$").with(ConfigRestApiServlet.class);
    serveRegex("^/(?:a/)?groups/(.*)?$").with(GroupsRestApiServlet.class);
    serveRegex("^/(?:a/)?projects/(.*)?$").with(ProjectsRestApiServlet.class);
    filter("/Documentation/").through(QueryDocumentationFilter.class);
}
#end_block

#method_before
private AuthInfo getAuthInfo(AuthConfig cfg, Realm realm) {
    AuthInfo info = new AuthInfo();
    info.authType = cfg.getAuthType();
    info.useContributorAgreements = toBoolean(cfg.isUseContributorAgreements());
    info.editableAccountFields = new ArrayList<>(realm.getEditableFields());
    info.switchAccountUrl = cfg.getSwitchAccountUrl();
    info.isGitBasicAuth = toBoolean(cfg.isGitBasicAuth());
    if (info.useContributorAgreements) {
        Collection<ContributorAgreement> agreements = projectCache.getAllProjects().getConfig().getContributorAgreements();
        if (!agreements.isEmpty()) {
            info.contributorAgreements = Lists.newArrayListWithCapacity(agreements.size());
            AgreementInfo agreementInfo = new AgreementInfo();
            for (ContributorAgreement agreement : agreements) {
                agreementInfo.name = agreement.getName();
                agreementInfo.description = agreement.getDescription();
                agreementInfo.url = agreement.getAgreementUrl();
                info.contributorAgreements.add(agreementInfo);
            }
        }
    }
    switch(info.authType) {
        case LDAP:
        case LDAP_BIND:
            info.registerUrl = cfg.getRegisterUrl();
            info.registerText = cfg.getRegisterText();
            info.editFullNameUrl = cfg.getEditFullNameUrl();
            break;
        case CUSTOM_EXTENSION:
            info.registerUrl = cfg.getRegisterUrl();
            info.registerText = cfg.getRegisterText();
            info.editFullNameUrl = cfg.getEditFullNameUrl();
            info.httpPasswordUrl = cfg.getHttpPasswordUrl();
            break;
        case HTTP:
        case HTTP_LDAP:
            info.loginUrl = cfg.getLoginUrl();
            info.loginText = cfg.getLoginText();
            break;
        case CLIENT_SSL_CERT_LDAP:
        case DEVELOPMENT_BECOME_ANY_ACCOUNT:
        case OAUTH:
        case OPENID:
        case OPENID_SSO:
            break;
    }
    return info;
}
#method_after
private AuthInfo getAuthInfo(AuthConfig cfg, Realm realm) {
    AuthInfo info = new AuthInfo();
    info.authType = cfg.getAuthType();
    info.useContributorAgreements = toBoolean(cfg.isUseContributorAgreements());
    info.editableAccountFields = new ArrayList<>(realm.getEditableFields());
    info.switchAccountUrl = cfg.getSwitchAccountUrl();
    info.isGitBasicAuth = toBoolean(cfg.isGitBasicAuth());
    switch(info.authType) {
        case LDAP:
        case LDAP_BIND:
            info.registerUrl = cfg.getRegisterUrl();
            info.registerText = cfg.getRegisterText();
            info.editFullNameUrl = cfg.getEditFullNameUrl();
            break;
        case CUSTOM_EXTENSION:
            info.registerUrl = cfg.getRegisterUrl();
            info.registerText = cfg.getRegisterText();
            info.editFullNameUrl = cfg.getEditFullNameUrl();
            info.httpPasswordUrl = cfg.getHttpPasswordUrl();
            break;
        case HTTP:
        case HTTP_LDAP:
            info.loginUrl = cfg.getLoginUrl();
            info.loginText = cfg.getLoginText();
            break;
        case CLIENT_SSL_CERT_LDAP:
        case DEVELOPMENT_BECOME_ANY_ACCOUNT:
        case OAUTH:
        case OPENID:
        case OPENID_SSO:
            break;
    }
    return info;
}
#end_block

#method_before
@Override
protected void onLoad() {
    super.onLoad();
    AccountApi.getAgreements("self", new GerritCallback<JsArray<AgreementInfo>>() {

        @Override
        public void onSuccess(JsArray<AgreementInfo> result) {
            mySigned = new HashSet<>();
            for (AgreementInfo info : Natives.asList(result)) {
                mySigned.add(info.name());
            }
            postRPC();
        }
    });
    Gerrit.SYSTEM_SVC.contributorAgreements(new GerritCallback<List<ContributorAgreement>>() {

        @Override
        public void onSuccess(final List<ContributorAgreement> result) {
            if (isAttached()) {
                available = result;
                postRPC();
            }
        }
    });
}
#method_after
@Override
protected void onLoad() {
    super.onLoad();
    AccountApi.getAgreements("self", new GerritCallback<JsArray<AgreementInfo>>() {

        @Override
        public void onSuccess(JsArray<AgreementInfo> result) {
            if (isAttached()) {
                mySigned = new HashSet<>();
                for (AgreementInfo info : Natives.asList(result)) {
                    mySigned.add(info.name());
                }
                postRPC();
            }
        }
    });
    Gerrit.SYSTEM_SVC.contributorAgreements(new GerritCallback<List<ContributorAgreement>>() {

        @Override
        public void onSuccess(final List<ContributorAgreement> result) {
            if (isAttached()) {
                available = result;
                postRPC();
            }
        }
    });
}
#end_block

#method_before
@Override
protected void onLoad() {
    super.onLoad();
    AccountApi.getAgreements("self", new GerritCallback<JsArray<AgreementInfo>>() {

        @Override
        public void onSuccess(JsArray<AgreementInfo> result) {
            agreements.display(Natives.asList(result));
        }
    });
    display();
}
#method_after
@Override
protected void onLoad() {
    super.onLoad();
    AccountApi.getAgreements("self", new ScreenLoadCallback<JsArray<AgreementInfo>>(this) {

        @Override
        public void preDisplay(JsArray<AgreementInfo> result) {
            agreements.display(Natives.asList(result));
        }
    });
}
#end_block

#method_before
void addOne(AgreementInfo info) {
    int row = table.getRowCount();
    table.insertRow(row);
    applyDataRowStyle(row);
    String url = info.url();
    if (url != null && url.length() > 0) {
        Anchor a = new Anchor(info.name(), url);
        a.setTarget("_blank");
        table.setWidget(row, 1, a);
    } else {
        table.setText(row, 1, info.name());
    }
    table.setText(row, 2, info.description());
    FlexCellFormatter fmt = table.getFlexCellFormatter();
    for (int c = 1; c < 2; c++) {
        fmt.addStyleName(row, c, Gerrit.RESOURCES.css().dataCell());
    }
}
#method_after
void addOne(AgreementInfo info) {
    int row = table.getRowCount();
    table.insertRow(row);
    applyDataRowStyle(row);
    String url = info.url();
    if (url != null && url.length() > 0) {
        Anchor a = new Anchor(info.name(), url);
        a.setTarget("_blank");
        table.setWidget(row, 1, a);
    } else {
        table.setText(row, 1, info.name());
    }
    table.setText(row, 2, info.description());
    FlexCellFormatter fmt = table.getFlexCellFormatter();
    for (int c = 1; c < 3; c++) {
        fmt.addStyleName(row, c, Gerrit.RESOURCES.css().dataCell());
    }
}
#end_block

#method_before
public static void suggest(String query, int limit, AsyncCallback<JsArray<AccountInfo>> cb) {
    new RestApi("/accounts/").addParameter("q", query).addParameter("n", limit).background().get(cb);
}
#method_after
public static void suggest(String query, int limit, AsyncCallback<JsArray<AccountInfo>> cb) {
    new RestApi("/accounts/").addParameterTrue("suggest").addParameter("q", query).addParameter("n", limit).background().get(cb);
}
#end_block

#method_before
@Override
public BranchInfo apply(ProjectResource rsrc, Input input) throws BadRequestException, AuthException, ResourceConflictException, IOException {
    if (input == null) {
        input = new Input();
    }
    if (input.ref != null && !ref.equals(input.ref)) {
        throw new BadRequestException("ref must match URL");
    }
    if (input.revision == null) {
        input.revision = Constants.HEAD;
    }
    while (ref.startsWith("/")) {
        ref = ref.substring(1);
    }
    if (!ref.startsWith(Constants.R_REFS)) {
        ref = Constants.R_HEADS + ref;
    }
    if (!Repository.isValidRefName(ref)) {
        throw new BadRequestException("invalid branch name \"" + ref + "\"");
    }
    if (MagicBranch.isMagicBranch(ref)) {
        throw new BadRequestException("not allowed to create branches under \"" + MagicBranch.getMagicRefNamePrefix(ref) + "\"");
    }
    final Branch.NameKey name = new Branch.NameKey(rsrc.getNameKey(), ref);
    final RefControl refControl = rsrc.getControl().controlForRef(name);
    final Repository repo = repoManager.openRepository(rsrc.getNameKey());
    try {
        final ObjectId revid = parseBaseRevision(repo, rsrc.getNameKey(), input.revision);
        final RevWalk rw = verifyConnected(repo, revid);
        RevObject object = rw.parseAny(revid);
        if (ref.startsWith(Constants.R_HEADS)) {
            // 
            try {
                object = rw.parseCommit(object);
            } catch (IncorrectObjectTypeException notCommit) {
                throw new BadRequestException("\"" + input.revision + "\" not a commit");
            }
        }
        rw.reset();
        if (!refControl.canCreate(db.get(), rw, object)) {
            throw new AuthException("Cannot create \"" + ref + "\"");
        }
        try {
            final RefUpdate u = repo.updateRef(ref);
            u.setExpectedOldObjectId(ObjectId.zeroId());
            u.setNewObjectId(object.copy());
            u.setRefLogIdent(identifiedUser.get().newRefLogIdent());
            u.setRefLogMessage("created via REST from " + input.revision, false);
            Optional<String> notValid = validateRefCreation(rsrc, u);
            if (notValid.isPresent()) {
                throw new ResourceConflictException(notValid.get());
            }
            final RefUpdate.Result result = u.update(rw);
            switch(result) {
                case FAST_FORWARD:
                case NEW:
                case NO_CHANGE:
                    referenceUpdated.fire(name.getParentKey(), u);
                    hooks.doRefUpdatedHook(name, u, identifiedUser.get().getAccount());
                    break;
                case LOCK_FAILURE:
                    if (repo.getRef(ref) != null) {
                        throw new ResourceConflictException("branch \"" + ref + "\" already exists");
                    }
                    String refPrefix = getRefPrefix(ref);
                    while (!Constants.R_HEADS.equals(refPrefix)) {
                        if (repo.getRef(refPrefix) != null) {
                            throw new ResourceConflictException("Cannot create branch \"" + ref + "\" since it conflicts with branch \"" + refPrefix + "\".");
                        }
                        refPrefix = getRefPrefix(refPrefix);
                    }
                default:
                    {
                        throw new IOException(result.name());
                    }
            }
            return new BranchInfo(ref, revid.getName(), refControl.canDelete());
        } catch (IOException err) {
            log.error("Cannot create branch \"" + name + "\"", err);
            throw err;
        }
    } catch (InvalidRevisionException e) {
        throw new BadRequestException("invalid revision \"" + input.revision + "\"");
    } finally {
        repo.close();
    }
}
#method_after
@Override
public BranchInfo apply(ProjectResource rsrc, BranchInput input) throws BadRequestException, AuthException, ResourceConflictException, IOException {
    if (input == null) {
        input = new BranchInput();
    }
    if (input.ref != null && !ref.equals(input.ref)) {
        throw new BadRequestException("ref must match URL");
    }
    if (input.revision == null) {
        input.revision = Constants.HEAD;
    }
    while (ref.startsWith("/")) {
        ref = ref.substring(1);
    }
    ref = RefNames.fullName(ref);
    if (!Repository.isValidRefName(ref)) {
        throw new BadRequestException("invalid branch name \"" + ref + "\"");
    }
    if (MagicBranch.isMagicBranch(ref)) {
        throw new BadRequestException("not allowed to create branches under \"" + MagicBranch.getMagicRefNamePrefix(ref) + "\"");
    }
    final Branch.NameKey name = new Branch.NameKey(rsrc.getNameKey(), ref);
    final RefControl refControl = rsrc.getControl().controlForRef(name);
    try (Repository repo = repoManager.openRepository(rsrc.getNameKey())) {
        ObjectId revid = RefUtil.parseBaseRevision(repo, rsrc.getNameKey(), input.revision);
        RevWalk rw = RefUtil.verifyConnected(repo, revid);
        RevObject object = rw.parseAny(revid);
        if (ref.startsWith(Constants.R_HEADS)) {
            // 
            try {
                object = rw.parseCommit(object);
            } catch (IncorrectObjectTypeException notCommit) {
                throw new BadRequestException("\"" + input.revision + "\" not a commit");
            }
        }
        if (!refControl.canCreate(db.get(), repo, object)) {
            throw new AuthException("Cannot create \"" + ref + "\"");
        }
        try {
            final RefUpdate u = repo.updateRef(ref);
            u.setExpectedOldObjectId(ObjectId.zeroId());
            u.setNewObjectId(object.copy());
            u.setRefLogIdent(identifiedUser.get().newRefLogIdent());
            u.setRefLogMessage("created via REST from " + input.revision, false);
            refCreationValidator.validateRefOperation(rsrc.getName(), identifiedUser.get(), u);
            final RefUpdate.Result result = u.update(rw);
            switch(result) {
                case FAST_FORWARD:
                case NEW:
                case NO_CHANGE:
                    referenceUpdated.fire(name.getParentKey(), u, ReceiveCommand.Type.CREATE, identifiedUser.get().getAccount());
                    break;
                case LOCK_FAILURE:
                    if (repo.getRefDatabase().exactRef(ref) != null) {
                        throw new ResourceConflictException("branch \"" + ref + "\" already exists");
                    }
                    String refPrefix = RefUtil.getRefPrefix(ref);
                    while (!Constants.R_HEADS.equals(refPrefix)) {
                        if (repo.getRefDatabase().exactRef(refPrefix) != null) {
                            throw new ResourceConflictException("Cannot create branch \"" + ref + "\" since it conflicts with branch \"" + refPrefix + "\".");
                        }
                        refPrefix = RefUtil.getRefPrefix(refPrefix);
                    }
                // $FALL-THROUGH$
                case FORCED:
                case IO_FAILURE:
                case NOT_ATTEMPTED:
                case REJECTED:
                case REJECTED_CURRENT_BRANCH:
                case RENAMED:
                default:
                    {
                        throw new IOException(result.name());
                    }
            }
            BranchInfo info = new BranchInfo();
            info.ref = ref;
            info.revision = revid.getName();
            info.canDelete = refControl.canDelete() ? true : null;
            return info;
        } catch (IOException err) {
            log.error("Cannot create branch \"" + name + "\"", err);
            throw err;
        }
    } catch (RefUtil.InvalidRevisionException e) {
        throw new BadRequestException("invalid revision \"" + input.revision + "\"");
    }
}
#end_block

#method_before
@Override
public Response<?> apply(BranchResource rsrc, Input input) throws AuthException, ResourceConflictException, OrmException, IOException {
    if (!rsrc.getControl().controlForRef(rsrc.getBranchKey()).canDelete()) {
        throw new AuthException("Cannot delete branch");
    }
    if (dbProvider.get().changes().byBranchOpenAll(rsrc.getBranchKey()).iterator().hasNext()) {
        throw new ResourceConflictException("branch " + rsrc.getBranchKey() + " has open changes");
    }
    Repository r = repoManager.openRepository(rsrc.getNameKey());
    try {
        RefUpdate.Result result;
        RefUpdate u;
        try {
            u = r.updateRef(rsrc.getRef());
            u.setForceUpdate(true);
            Optional<String> notValid = validateRefDeletion(rsrc, u);
            if (notValid.isPresent()) {
                throw new ResourceConflictException(notValid.get());
            }
            result = u.delete();
        } catch (IOException e) {
            log.error("Cannot delete " + rsrc.getBranchKey(), e);
            throw e;
        }
        switch(result) {
            case NEW:
            case NO_CHANGE:
            case FAST_FORWARD:
            case FORCED:
                referenceUpdated.fire(rsrc.getNameKey(), u);
                hooks.doRefUpdatedHook(rsrc.getBranchKey(), u, identifiedUser.get().getAccount());
                break;
            case REJECTED_CURRENT_BRANCH:
                log.warn("Cannot delete " + rsrc.getBranchKey() + ": " + result.name());
                throw new ResourceConflictException("cannot delete current branch");
            default:
                log.error("Cannot delete " + rsrc.getBranchKey() + ": " + result.name());
                throw new ResourceConflictException("cannot delete branch: " + result.name());
        }
    } finally {
        r.close();
    }
    return Response.none();
}
#method_after
@Override
public Response<?> apply(BranchResource rsrc, Input input) throws AuthException, ResourceConflictException, OrmException, IOException {
    if (!rsrc.getControl().controlForRef(rsrc.getBranchKey()).canDelete()) {
        throw new AuthException("Cannot delete branch");
    }
    if (!queryProvider.get().setLimit(1).byBranchOpen(rsrc.getBranchKey()).isEmpty()) {
        throw new ResourceConflictException("branch " + rsrc.getBranchKey() + " has open changes");
    }
    try (Repository r = repoManager.openRepository(rsrc.getNameKey())) {
        RefUpdate.Result result;
        RefUpdate u = r.updateRef(rsrc.getRef());
        u.setForceUpdate(true);
        refDeletionValidator.validateRefOperation(rsrc.getName(), identifiedUser.get(), u);
        int remainingLockFailureCalls = MAX_LOCK_FAILURE_CALLS;
        for (; ; ) {
            try {
                result = u.delete();
            } catch (LockFailedException e) {
                result = RefUpdate.Result.LOCK_FAILURE;
            } catch (IOException e) {
                log.error("Cannot delete " + rsrc.getBranchKey(), e);
                throw e;
            }
            if (result == RefUpdate.Result.LOCK_FAILURE && --remainingLockFailureCalls > 0) {
                try {
                    Thread.sleep(SLEEP_ON_LOCK_FAILURE_MS);
                } catch (InterruptedException ie) {
                // ignore
                }
            } else {
                break;
            }
        }
        switch(result) {
            case NEW:
            case NO_CHANGE:
            case FAST_FORWARD:
            case FORCED:
                referenceUpdated.fire(rsrc.getNameKey(), u, ReceiveCommand.Type.DELETE, identifiedUser.get().getAccount());
                break;
            case REJECTED_CURRENT_BRANCH:
                log.error("Cannot delete " + rsrc.getBranchKey() + ": " + result.name());
                throw new ResourceConflictException("cannot delete current branch");
            case IO_FAILURE:
            case LOCK_FAILURE:
            case NOT_ATTEMPTED:
            case REJECTED:
            case RENAMED:
            default:
                log.error("Cannot delete " + rsrc.getBranchKey() + ": " + result.name());
                throw new ResourceConflictException("cannot delete branch: " + result.name());
        }
    }
    return Response.none();
}
#end_block

#method_before
public void setMessageSender(final MessageSender ms) {
    messageSender = ms != null ? ms : new ReceivePackMessageSender();
}
#method_after
public void setMessageSender(MessageSender ms) {
    messageSender = ms != null ? ms : new ReceivePackMessageSender();
}
#end_block

#method_before
void processCommands(final Collection<ReceiveCommand> commands, final MultiProgressMonitor progress) {
    newProgress = progress.beginSubTask("new", UNKNOWN);
    replaceProgress = progress.beginSubTask("updated", UNKNOWN);
    closeProgress = progress.beginSubTask("closed", UNKNOWN);
    commandProgress = progress.beginSubTask("refs", UNKNOWN);
    batch = repo.getRefDatabase().newBatchUpdate();
    batch.setRefLogIdent(rp.getRefLogIdent());
    batch.setRefLogMessage("push", true);
    parseCommands(commands);
    if (magicBranch != null && magicBranch.cmd.getResult() == NOT_ATTEMPTED) {
        newChanges = selectNewChanges();
    }
    preparePatchSetsForReplace();
    if (!batch.getCommands().isEmpty()) {
        try {
            batch.execute(rp.getRevWalk(), commandProgress);
        } catch (IOException err) {
            int cnt = 0;
            for (ReceiveCommand cmd : batch.getCommands()) {
                if (cmd.getResult() == NOT_ATTEMPTED) {
                    cmd.setResult(REJECTED_OTHER_REASON, "internal server error");
                    cnt++;
                }
            }
            log.error(String.format("Failed to store %d refs in %s", cnt, project.getName()), err);
        }
    }
    insertChangesAndPatchSets();
    newProgress.end();
    replaceProgress.end();
    if (!errors.isEmpty()) {
        for (Error error : errors.keySet()) {
            rp.sendMessage(buildError(error, errors.get(error)));
        }
        rp.sendMessage(String.format("User: %s", displayName(currentUser)));
        rp.sendMessage(COMMAND_REJECTION_MESSAGE_FOOTER);
    }
    for (final ReceiveCommand c : commands) {
        if (c.getResult() == OK) {
            try {
                switch(c.getType()) {
                    case CREATE:
                        if (isHead(c) || isConfig(c)) {
                            autoCloseChanges(c);
                        }
                        break;
                    case // otherwise known as a fast-forward
                    UPDATE:
                        tagCache.updateFastForward(project.getNameKey(), c.getRefName(), c.getOldId(), c.getNewId());
                        if (isHead(c) || isConfig(c)) {
                            autoCloseChanges(c);
                        }
                        break;
                    case UPDATE_NONFASTFORWARD:
                        if (isHead(c) || isConfig(c)) {
                            autoCloseChanges(c);
                        }
                        break;
                    case DELETE:
                        break;
                }
                if (isConfig(c)) {
                    projectCache.evict(project);
                    ProjectState ps = projectCache.get(project.getNameKey());
                    // 
                    repoManager.setProjectDescription(// 
                    project.getNameKey(), ps.getProject().getDescription());
                }
                if (!MagicBranch.isMagicBranch(c.getRefName())) {
                    // We only fire gitRefUpdated for direct refs updates.
                    // Events for change refs are fired when they are created.
                    // 
                    gitRefUpdated.fire(project.getNameKey(), c.getRefName(), c.getOldId(), c.getNewId());
                    hooks.doRefUpdatedHook(new Branch.NameKey(project.getNameKey(), c.getRefName()), c.getOldId(), c.getNewId(), currentUser.getAccount());
                }
            } catch (NoSuchChangeException e) {
                c.setResult(REJECTED_OTHER_REASON, "No such change: " + e.getMessage());
            }
        }
    }
    closeProgress.end();
    commandProgress.end();
    progress.end();
    reportMessages();
}
#method_after
void processCommands(Collection<ReceiveCommand> commands, MultiProgressMonitor progress) {
    newProgress = progress.beginSubTask("new", UNKNOWN);
    replaceProgress = progress.beginSubTask("updated", UNKNOWN);
    closeProgress = progress.beginSubTask("closed", UNKNOWN);
    commandProgress = progress.beginSubTask("refs", UNKNOWN);
    batch = repo.getRefDatabase().newBatchUpdate();
    batch.setPushCertificate(rp.getPushCertificate());
    batch.setRefLogIdent(rp.getRefLogIdent());
    batch.setRefLogMessage("push", true);
    parseCommands(commands);
    if (magicBranch != null && magicBranch.cmd.getResult() == NOT_ATTEMPTED) {
        selectNewAndReplacedChangesFromMagicBranch();
    }
    preparePatchSetsForReplace();
    logDebug("Executing batch with {} commands", batch.getCommands().size());
    if (!batch.getCommands().isEmpty()) {
        try {
            if (!batch.isAllowNonFastForwards() && magicBranch != null && magicBranch.edit) {
                logDebug("Allowing non-fast-forward for edit ref");
                batch.setAllowNonFastForwards(true);
            }
            batch.execute(rp.getRevWalk(), commandProgress);
        } catch (IOException err) {
            int cnt = 0;
            for (ReceiveCommand cmd : batch.getCommands()) {
                if (cmd.getResult() == NOT_ATTEMPTED) {
                    cmd.setResult(REJECTED_OTHER_REASON, "internal server error");
                    cnt++;
                }
            }
            logError(String.format("Failed to store %d refs in %s", cnt, project.getName()), err);
        }
    }
    insertChangesAndPatchSets();
    newProgress.end();
    replaceProgress.end();
    if (!errors.isEmpty()) {
        logDebug("Handling error conditions: {}", errors.keySet());
        for (Error error : errors.keySet()) {
            rp.sendMessage(buildError(error, errors.get(error)));
        }
        rp.sendMessage(String.format("User: %s", displayName(user)));
        rp.sendMessage(COMMAND_REJECTION_MESSAGE_FOOTER);
    }
    Set<Branch.NameKey> branches = new HashSet<>();
    for (ReceiveCommand c : batch.getCommands()) {
        if (c.getResult() == OK) {
            String refName = c.getRefName();
            if (c.getType() == ReceiveCommand.Type.UPDATE) {
                // aka fast-forward
                logDebug("Updating tag cache on fast-forward of {}", c.getRefName());
                tagCache.updateFastForward(project.getNameKey(), refName, c.getOldId(), c.getNewId());
            }
            if (isHead(c) || isConfig(c)) {
                switch(c.getType()) {
                    case CREATE:
                    case UPDATE:
                    case UPDATE_NONFASTFORWARD:
                        autoCloseChanges(c);
                        branches.add(new Branch.NameKey(project.getNameKey(), refName));
                        break;
                    case DELETE:
                        break;
                }
            }
            if (isConfig(c)) {
                logDebug("Reloading project in cache");
                projectCache.evict(project);
                ProjectState ps = projectCache.get(project.getNameKey());
                // 
                repoManager.setProjectDescription(// 
                project.getNameKey(), ps.getProject().getDescription());
            }
            if (!MagicBranch.isMagicBranch(refName) && !refName.startsWith(REFS_CHANGES)) {
                logDebug("Firing ref update for {}", c.getRefName());
                // We only fire gitRefUpdated for direct refs updates.
                // Events for change refs are fired when they are created.
                // 
                gitRefUpdated.fire(project.getNameKey(), c, user.getAccount());
            } else {
                logDebug("Assuming ref update event for {} has fired", c.getRefName());
            }
        }
    }
    // Update superproject gitlinks if required.
    try (MergeOpRepoManager orm = ormProvider.get()) {
        orm.setContext(db, TimeUtil.nowTs(), user, receiveId);
        SubmoduleOp op = subOpFactory.create(branches, orm);
        op.updateSuperProjects();
    } catch (SubmoduleException e) {
        logError("Can't update the superprojects", e);
    }
    closeProgress.end();
    commandProgress.end();
    progress.end();
    reportMessages();
}
#end_block

#method_before
private void reportMessages() {
    Iterable<CreateRequest> created = Iterables.filter(newChanges, new Predicate<CreateRequest>() {

        @Override
        public boolean apply(CreateRequest input) {
            return input.created;
        }
    });
    if (!Iterables.isEmpty(created)) {
        addMessage("");
        addMessage("New Changes:");
        for (CreateRequest c : created) {
            addMessage(formatChangeUrl(canonicalWebUrl, c.change));
        }
        addMessage("");
    }
    List<ReplaceRequest> updated = FluentIterable.from(replaceByChange.values()).filter(new Predicate<ReplaceRequest>() {

        @Override
        public boolean apply(ReplaceRequest input) {
            return !input.skip && input.inputCommand.getResult() == OK;
        }
    }).toSortedList(Ordering.natural().onResultOf(new Function<ReplaceRequest, Integer>() {

        @Override
        public Integer apply(ReplaceRequest in) {
            return in.change.getId().get();
        }
    }));
    if (!updated.isEmpty()) {
        addMessage("");
        addMessage("Updated Changes:");
        for (ReplaceRequest u : updated) {
            addMessage(formatChangeUrl(canonicalWebUrl, u.change));
        }
        addMessage("");
    }
}
#method_after
private void reportMessages() {
    Iterable<CreateRequest> created = Iterables.filter(newChanges, new Predicate<CreateRequest>() {

        @Override
        public boolean apply(CreateRequest input) {
            return input.change != null;
        }
    });
    if (!Iterables.isEmpty(created)) {
        addMessage("");
        addMessage("New Changes:");
        for (CreateRequest c : created) {
            addMessage(formatChangeUrl(canonicalWebUrl, c.change, c.change.getSubject(), c.change.getStatus() == Change.Status.DRAFT, false));
        }
        addMessage("");
    }
    List<ReplaceRequest> updated = FluentIterable.from(replaceByChange.values()).filter(new Predicate<ReplaceRequest>() {

        @Override
        public boolean apply(ReplaceRequest input) {
            return !input.skip && input.inputCommand.getResult() == OK;
        }
    }).toSortedList(Ordering.natural().onResultOf(new Function<ReplaceRequest, Integer>() {

        @Override
        public Integer apply(ReplaceRequest in) {
            return in.notes.getChangeId().get();
        }
    }));
    if (!updated.isEmpty()) {
        addMessage("");
        addMessage("Updated Changes:");
        boolean edit = magicBranch != null && magicBranch.edit;
        for (ReplaceRequest u : updated) {
            String subject;
            if (edit) {
                try {
                    subject = rp.getRevWalk().parseCommit(u.newCommitId).getShortMessage();
                } catch (IOException e) {
                    // Log and fall back to original change subject
                    logWarn("failed to get subject for edit patch set", e);
                    subject = u.notes.getChange().getSubject();
                }
            } else {
                subject = u.info.getSubject();
            }
            addMessage(formatChangeUrl(canonicalWebUrl, u.notes.getChange(), subject, u.replaceOp != null && u.replaceOp.getPatchSet().isDraft(), edit));
        }
        addMessage("");
    }
}
#end_block

#method_before
private static String formatChangeUrl(String url, Change change) {
    StringBuilder m = new StringBuilder().append("  ").append(url).append(change.getChangeId()).append(" ").append(ChangeUtil.cropSubject(change.getSubject()));
    if (change.getStatus() == Change.Status.DRAFT) {
        m.append(" [DRAFT]");
    }
    return m.toString();
}
#method_after
private static String formatChangeUrl(String url, Change change, String subject, boolean draft, boolean edit) {
    StringBuilder m = new StringBuilder().append("  ").append(url).append(change.getChangeId()).append(" ").append(ChangeUtil.cropSubject(subject));
    if (draft) {
        m.append(" [DRAFT]");
    }
    if (edit) {
        m.append(" [EDIT]");
    }
    return m.toString();
}
#end_block

#method_before
private void insertChangesAndPatchSets() {
    int replaceCount = 0;
    int okToInsert = 0;
    for (Map.Entry<Change.Id, ReplaceRequest> e : replaceByChange.entrySet()) {
        ReplaceRequest replace = e.getValue();
        if (magicBranch != null && replace.inputCommand == magicBranch.cmd) {
            replaceCount++;
            if (replace.cmd != null && replace.cmd.getResult() == OK) {
                okToInsert++;
            }
        } else if (replace.cmd != null && replace.cmd.getResult() == OK) {
            try {
                if (replace.insertPatchSet().checkedGet() != null) {
                    replace.inputCommand.setResult(OK);
                }
            } catch (IOException err) {
                reject(replace.inputCommand, "internal server error");
                log.error(String.format("Cannot add patch set to %d of %s", e.getKey().get(), project.getName()), err);
            } catch (InsertException err) {
                reject(replace.inputCommand, "internal server error");
                log.error(String.format("Cannot add patch set to %d of %s", e.getKey().get(), project.getName()), err);
            }
        } else if (replace.inputCommand.getResult() == NOT_ATTEMPTED) {
            reject(replace.inputCommand, "internal server error");
            log.error(String.format("Replacement for project %s was not attempted", project.getName()));
        }
    }
    if (magicBranch == null || magicBranch.cmd.getResult() != NOT_ATTEMPTED) {
        // No need to continue.
        return;
    }
    List<String> lastCreateChangeErrors = Lists.newArrayList();
    for (CreateRequest create : newChanges) {
        if (create.cmd.getResult() == OK) {
            okToInsert++;
        } else {
            String createChangeResult = String.format("%s %s", create.cmd.getResult(), Strings.nullToEmpty(create.cmd.getMessage())).trim();
            lastCreateChangeErrors.add(createChangeResult);
            log.error(String.format("Command %s on %s:%s not completed: %s", create.cmd.getType(), project.getName(), create.cmd.getRefName(), createChangeResult));
        }
    }
    if (okToInsert != replaceCount + newChanges.size()) {
        // One or more new references failed to create. Assume the
        // system isn't working correctly anymore and abort.
        reject(magicBranch.cmd, "Unable to create changes: " + Joiner.on(' ').join(lastCreateChangeErrors));
        log.error(String.format("Only %d of %d new change refs created in %s; aborting", okToInsert, replaceCount + newChanges.size(), project.getName()));
        return;
    }
    try {
        List<CheckedFuture<?, InsertException>> futures = Lists.newArrayList();
        for (ReplaceRequest replace : replaceByChange.values()) {
            if (magicBranch != null && replace.inputCommand == magicBranch.cmd) {
                futures.add(replace.insertPatchSet());
            }
        }
        for (CreateRequest create : newChanges) {
            futures.add(create.insertChange());
        }
        for (CheckedFuture<?, InsertException> f : futures) {
            f.checkedGet();
        }
        magicBranch.cmd.setResult(OK);
    } catch (InsertException err) {
        log.error("Can't insert change/patchset for " + project.getName(), err);
        reject(magicBranch.cmd, "internal server error");
    } catch (IOException err) {
        log.error("Can't read commits for " + project.getName(), err);
        reject(magicBranch.cmd, "internal server error");
    }
}
#method_after
private void insertChangesAndPatchSets() {
    int replaceCount = 0;
    int okToInsert = 0;
    for (Map.Entry<Change.Id, ReplaceRequest> e : replaceByChange.entrySet()) {
        ReplaceRequest replace = e.getValue();
        if (magicBranch != null && replace.inputCommand == magicBranch.cmd) {
            replaceCount++;
            if (replace.cmd != null && replace.cmd.getResult() == OK) {
                okToInsert++;
            }
        } else if (replace.cmd != null && replace.cmd.getResult() == OK) {
            String refName = replace.inputCommand.getRefName();
            checkState(NEW_PATCHSET.matcher(refName).matches(), "expected a new patch set command as input when creating %s;" + " got %s", replace.cmd.getRefName(), refName);
            try {
                logDebug("One-off insertion of patch set for {}", refName);
                replace.insertPatchSetWithoutBatchUpdate();
                replace.inputCommand.setResult(OK);
            } catch (IOException | UpdateException | RestApiException err) {
                reject(replace.inputCommand, "internal server error");
                logError(String.format("Cannot add patch set to change %d in project %s", e.getKey().get(), project.getName()), err);
            }
        } else if (replace.inputCommand.getResult() == NOT_ATTEMPTED) {
            reject(replace.inputCommand, "internal server error");
            logError(String.format("Replacement for project %s was not attempted", project.getName()));
        }
    }
    // No need to continue.
    if (magicBranch == null) {
        logDebug("No magic branch, nothing more to do");
        return;
    } else if (magicBranch.cmd.getResult() != NOT_ATTEMPTED) {
        logWarn(String.format("Skipping change updates on %s because ref update failed: %s %s", project.getName(), magicBranch.cmd.getResult(), Strings.nullToEmpty(magicBranch.cmd.getMessage())));
        return;
    }
    List<String> lastCreateChangeErrors = new ArrayList<>();
    for (CreateRequest create : newChanges) {
        if (create.cmd.getResult() == OK) {
            okToInsert++;
        } else {
            String createChangeResult = String.format("%s %s", create.cmd.getResult(), Strings.nullToEmpty(create.cmd.getMessage())).trim();
            lastCreateChangeErrors.add(createChangeResult);
            logError(String.format("Command %s on %s:%s not completed: %s", create.cmd.getType(), project.getName(), create.cmd.getRefName(), createChangeResult));
        }
    }
    logDebug("Counted {} ok to insert, out of {} to replace and {} new", okToInsert, replaceCount, newChanges.size());
    if (okToInsert != replaceCount + newChanges.size()) {
        // One or more new references failed to create. Assume the
        // system isn't working correctly anymore and abort.
        reject(magicBranch.cmd, "Unable to create changes: " + Joiner.on(' ').join(lastCreateChangeErrors));
        logError(String.format("Only %d of %d new change refs created in %s; aborting", okToInsert, replaceCount + newChanges.size(), project.getName()));
        return;
    }
    try (BatchUpdate bu = batchUpdateFactory.create(db, magicBranch.dest.getParentKey(), user, TimeUtil.nowTs());
        ObjectInserter ins = repo.newObjectInserter()) {
        bu.setRepository(repo, rp.getRevWalk(), ins).updateChangesInParallel();
        bu.setRequestId(receiveId);
        for (ReplaceRequest replace : replaceByChange.values()) {
            if (replace.inputCommand == magicBranch.cmd) {
                replace.addOps(bu, replaceProgress);
            }
        }
        for (CreateRequest create : newChanges) {
            create.addOps(bu);
        }
        for (UpdateGroupsRequest update : updateGroups) {
            update.addOps(bu);
        }
        logDebug("Executing batch");
        try {
            bu.execute();
        } catch (UpdateException e) {
            throw INSERT_EXCEPTION.apply(e);
        }
        magicBranch.cmd.setResult(OK);
        for (ReplaceRequest replace : replaceByChange.values()) {
            String rejectMessage = replace.getRejectMessage();
            if (rejectMessage != null) {
                logDebug("Rejecting due to message from ReplaceOp");
                reject(replace.inputCommand, rejectMessage);
            }
        }
    } catch (ResourceConflictException e) {
        addMessage(e.getMessage());
        reject(magicBranch.cmd, "conflict");
    } catch (RestApiException | IOException err) {
        logError("Can't insert change/patch set for " + project.getName(), err);
        reject(magicBranch.cmd, "internal server error: " + err.getMessage());
    }
    if (magicBranch != null && magicBranch.submit) {
        try {
            submit(newChanges, replaceByChange.values());
        } catch (ResourceConflictException e) {
            addMessage(e.getMessage());
            reject(magicBranch.cmd, "conflict");
        } catch (RestApiException | OrmException e) {
            logError("Error submitting changes to " + project.getName(), e);
            reject(magicBranch.cmd, "error during submit");
        }
    }
}
#end_block

#method_before
private void parseCommands(final Collection<ReceiveCommand> commands) {
    for (final ReceiveCommand cmd : commands) {
        if (cmd.getResult() != NOT_ATTEMPTED) {
            // 
            continue;
        }
        if (!Repository.isValidRefName(cmd.getRefName()) || cmd.getRefName().contains("//")) {
            reject(cmd, "not valid ref");
            continue;
        }
        HookResult result = hooks.doRefUpdateHook(project, cmd.getRefName(), currentUser.getAccount(), cmd.getOldId(), cmd.getNewId());
        if (result != null) {
            final String message = result.toString().trim();
            if (result.getExitValue() != 0) {
                reject(cmd, message);
                continue;
            }
            rp.sendMessage(message);
        }
        if (MagicBranch.isMagicBranch(cmd.getRefName())) {
            parseMagicBranch(cmd);
            continue;
        }
        final Matcher m = NEW_PATCHSET.matcher(cmd.getRefName());
        if (m.matches()) {
            // The referenced change must exist and must still be open.
            // 
            final Change.Id changeId = Change.Id.parse(m.group(1));
            parseReplaceCommand(cmd, changeId);
            continue;
        }
        switch(cmd.getType()) {
            case CREATE:
                parseCreate(cmd);
                break;
            case UPDATE:
                parseUpdate(cmd);
                break;
            case DELETE:
                parseDelete(cmd);
                break;
            case UPDATE_NONFASTFORWARD:
                parseRewind(cmd);
                break;
            default:
                reject(cmd);
                continue;
        }
        if (cmd.getResult() != NOT_ATTEMPTED) {
            continue;
        }
        if (isConfig(cmd)) {
            if (!projectControl.isOwner()) {
                reject(cmd, "not project owner");
                continue;
            }
            switch(cmd.getType()) {
                case CREATE:
                case UPDATE:
                case UPDATE_NONFASTFORWARD:
                    try {
                        ProjectConfig cfg = new ProjectConfig(project.getNameKey());
                        cfg.load(repo, cmd.getNewId());
                        if (!cfg.getValidationErrors().isEmpty()) {
                            addError("Invalid project configuration:");
                            for (ValidationError err : cfg.getValidationErrors()) {
                                addError("  " + err.getMessage());
                            }
                            reject(cmd, "invalid project configuration");
                            log.error("User " + currentUser.getUserName() + " tried to push invalid project configuration " + cmd.getNewId().name() + " for " + project.getName());
                            continue;
                        }
                        Project.NameKey newParent = cfg.getProject().getParent(allProjectsName);
                        Project.NameKey oldParent = project.getParent(allProjectsName);
                        if (oldParent == null) {
                            // update of the 'All-Projects' project
                            if (newParent != null) {
                                reject(cmd, "invalid project configuration: root project cannot have parent");
                                continue;
                            }
                        } else {
                            if (!oldParent.equals(newParent) && !currentUser.getCapabilities().canAdministrateServer()) {
                                reject(cmd, "invalid project configuration: only Gerrit admin can set parent");
                                continue;
                            }
                            if (projectCache.get(newParent) == null) {
                                reject(cmd, "invalid project configuration: parent does not exist");
                                continue;
                            }
                        }
                        for (Entry<ProjectConfigEntry> e : pluginConfigEntries) {
                            PluginConfig pluginCfg = cfg.getPluginConfig(e.getPluginName());
                            ProjectConfigEntry configEntry = e.getProvider().get();
                            String value = pluginCfg.getString(e.getExportName());
                            String oldValue = projectControl.getProjectState().getConfig().getPluginConfig(e.getPluginName()).getString(e.getExportName());
                            if (configEntry.getType() == ProjectConfigEntry.Type.ARRAY) {
                                List<String> l = Arrays.asList(projectControl.getProjectState().getConfig().getPluginConfig(e.getPluginName()).getStringList(e.getExportName()));
                                oldValue = Joiner.on("\n").join(l);
                            }
                            if ((value == null ? oldValue != null : !value.equals(oldValue)) && !configEntry.isEditable(projectControl.getProjectState())) {
                                reject(cmd, String.format("invalid project configuration: Not allowed to set parameter" + " '%s' of plugin '%s' on project '%s'.", e.getExportName(), e.getPluginName(), project.getName()));
                                continue;
                            }
                            if (ProjectConfigEntry.Type.LIST.equals(configEntry.getType()) && value != null && !configEntry.getPermittedValues().contains(value)) {
                                reject(cmd, String.format("invalid project configuration: The value '%s' is " + "not permitted for parameter '%s' of plugin '%s'.", value, e.getExportName(), e.getPluginName()));
                            }
                        }
                    } catch (Exception e) {
                        reject(cmd, "invalid project configuration");
                        log.error("User " + currentUser.getUserName() + " tried to push invalid project configuration " + cmd.getNewId().name() + " for " + project.getName(), e);
                        continue;
                    }
                    break;
                case DELETE:
                    break;
                default:
                    reject(cmd);
                    continue;
            }
        }
    }
}
#method_after
private void parseCommands(Collection<ReceiveCommand> commands) {
    logDebug("Parsing {} commands", commands.size());
    for (ReceiveCommand cmd : commands) {
        if (cmd.getResult() != NOT_ATTEMPTED) {
            // Already rejected by the core receive process.
            logDebug("Already processed by core: {} {}", cmd.getResult(), cmd);
            continue;
        }
        if (!Repository.isValidRefName(cmd.getRefName()) || cmd.getRefName().contains("//")) {
            reject(cmd, "not valid ref");
            continue;
        }
        if (MagicBranch.isMagicBranch(cmd.getRefName())) {
            parseMagicBranch(cmd);
            continue;
        }
        if (projectControl.getProjectState().isAllUsers() && RefNames.REFS_USERS_SELF.equals(cmd.getRefName())) {
            String newName = RefNames.refsUsers(user.getAccountId());
            logDebug("Swapping out command for {} to {}", RefNames.REFS_USERS_SELF, newName);
            final ReceiveCommand orgCmd = cmd;
            cmd = new ReceiveCommand(cmd.getOldId(), cmd.getNewId(), newName, cmd.getType()) {

                @Override
                public void setResult(Result s, String m) {
                    super.setResult(s, m);
                    orgCmd.setResult(s, m);
                }
            };
        }
        Matcher m = NEW_PATCHSET.matcher(cmd.getRefName());
        if (m.matches()) {
            // The referenced change must exist and must still be open.
            // 
            Change.Id changeId = Change.Id.parse(m.group(1));
            parseReplaceCommand(cmd, changeId);
            continue;
        }
        switch(cmd.getType()) {
            case CREATE:
                parseCreate(cmd);
                break;
            case UPDATE:
                parseUpdate(cmd);
                break;
            case DELETE:
                parseDelete(cmd);
                break;
            case UPDATE_NONFASTFORWARD:
                parseRewind(cmd);
                break;
            default:
                reject(cmd);
                continue;
        }
        if (cmd.getResult() != NOT_ATTEMPTED) {
            continue;
        }
        if (isConfig(cmd)) {
            logDebug("Processing {} command", cmd.getRefName());
            if (!projectControl.isOwner()) {
                reject(cmd, "not project owner");
                continue;
            }
            switch(cmd.getType()) {
                case CREATE:
                case UPDATE:
                case UPDATE_NONFASTFORWARD:
                    try {
                        ProjectConfig cfg = new ProjectConfig(project.getNameKey());
                        cfg.load(rp.getRevWalk(), cmd.getNewId());
                        if (!cfg.getValidationErrors().isEmpty()) {
                            addError("Invalid project configuration:");
                            for (ValidationError err : cfg.getValidationErrors()) {
                                addError("  " + err.getMessage());
                            }
                            reject(cmd, "invalid project configuration");
                            logError("User " + user.getUserName() + " tried to push invalid project configuration " + cmd.getNewId().name() + " for " + project.getName());
                            continue;
                        }
                        Project.NameKey newParent = cfg.getProject().getParent(allProjectsName);
                        Project.NameKey oldParent = project.getParent(allProjectsName);
                        if (oldParent == null) {
                            // update of the 'All-Projects' project
                            if (newParent != null) {
                                reject(cmd, "invalid project configuration: root project cannot have parent");
                                continue;
                            }
                        } else {
                            if (!oldParent.equals(newParent) && !user.getCapabilities().canAdministrateServer()) {
                                reject(cmd, "invalid project configuration: only Gerrit admin can set parent");
                                continue;
                            }
                            if (projectCache.get(newParent) == null) {
                                reject(cmd, "invalid project configuration: parent does not exist");
                                continue;
                            }
                        }
                        for (Entry<ProjectConfigEntry> e : pluginConfigEntries) {
                            PluginConfig pluginCfg = cfg.getPluginConfig(e.getPluginName());
                            ProjectConfigEntry configEntry = e.getProvider().get();
                            String value = pluginCfg.getString(e.getExportName());
                            String oldValue = projectControl.getProjectState().getConfig().getPluginConfig(e.getPluginName()).getString(e.getExportName());
                            if (configEntry.getType() == ProjectConfigEntryType.ARRAY) {
                                List<String> l = Arrays.asList(projectControl.getProjectState().getConfig().getPluginConfig(e.getPluginName()).getStringList(e.getExportName()));
                                oldValue = Joiner.on("\n").join(l);
                            }
                            if ((value == null ? oldValue != null : !value.equals(oldValue)) && !configEntry.isEditable(projectControl.getProjectState())) {
                                reject(cmd, String.format("invalid project configuration: Not allowed to set parameter" + " '%s' of plugin '%s' on project '%s'.", e.getExportName(), e.getPluginName(), project.getName()));
                                continue;
                            }
                            if (ProjectConfigEntryType.LIST.equals(configEntry.getType()) && value != null && !configEntry.getPermittedValues().contains(value)) {
                                reject(cmd, String.format("invalid project configuration: The value '%s' is " + "not permitted for parameter '%s' of plugin '%s'.", value, e.getExportName(), e.getPluginName()));
                            }
                        }
                    } catch (Exception e) {
                        reject(cmd, "invalid project configuration");
                        logError("User " + user.getUserName() + " tried to push invalid project configuration " + cmd.getNewId().name() + " for " + project.getName(), e);
                        continue;
                    }
                    break;
                case DELETE:
                    break;
                default:
                    reject(cmd);
                    continue;
            }
        }
    }
}
#end_block

#method_before
private void parseCreate(final ReceiveCommand cmd) {
    RevObject obj;
    try {
        obj = rp.getRevWalk().parseAny(cmd.getNewId());
    } catch (IOException err) {
        log.error("Invalid object " + cmd.getNewId().name() + " for " + cmd.getRefName() + " creation", err);
        reject(cmd, "invalid object");
        return;
    }
    if (isHead(cmd) && !isCommit(cmd)) {
        return;
    }
    RefControl ctl = projectControl.controlForRef(cmd.getRefName());
    rp.getRevWalk().reset();
    if (ctl.canCreate(db, rp.getRevWalk(), obj)) {
        if (!validRefOperation(cmd)) {
            return;
        }
        validateNewCommits(ctl, cmd);
        batch.addCommand(cmd);
    } else {
        reject(cmd);
    }
}
#method_after
private void parseCreate(ReceiveCommand cmd) {
    RevObject obj;
    try {
        obj = rp.getRevWalk().parseAny(cmd.getNewId());
    } catch (IOException err) {
        logError("Invalid object " + cmd.getNewId().name() + " for " + cmd.getRefName() + " creation", err);
        reject(cmd, "invalid object");
        return;
    }
    logDebug("Creating {}", cmd);
    if (isHead(cmd) && !isCommit(cmd)) {
        return;
    }
    RefControl ctl = projectControl.controlForRef(cmd.getRefName());
    if (ctl.canCreate(db, rp.getRepository(), obj)) {
        if (!validRefOperation(cmd)) {
            return;
        }
        validateNewCommits(ctl, cmd);
        batch.addCommand(cmd);
    } else {
        reject(cmd);
    }
}
#end_block

#method_before
private void parseUpdate(final ReceiveCommand cmd) {
    RefControl ctl = projectControl.controlForRef(cmd.getRefName());
    if (ctl.canUpdate()) {
        if (isHead(cmd) && !isCommit(cmd)) {
            return;
        }
        if (!validRefOperation(cmd)) {
            return;
        }
        validateNewCommits(ctl, cmd);
        batch.addCommand(cmd);
    } else {
        if (RefNames.REFS_CONFIG.equals(ctl.getRefName())) {
            errors.put(Error.CONFIG_UPDATE, RefNames.REFS_CONFIG);
        } else {
            errors.put(Error.UPDATE, ctl.getRefName());
        }
        reject(cmd);
    }
}
#method_after
private void parseUpdate(ReceiveCommand cmd) {
    logDebug("Updating {}", cmd);
    RefControl ctl = projectControl.controlForRef(cmd.getRefName());
    if (ctl.canUpdate()) {
        if (isHead(cmd) && !isCommit(cmd)) {
            return;
        }
        if (!validRefOperation(cmd)) {
            return;
        }
        validateNewCommits(ctl, cmd);
        batch.addCommand(cmd);
    } else {
        if (RefNames.REFS_CONFIG.equals(ctl.getRefName())) {
            errors.put(Error.CONFIG_UPDATE, RefNames.REFS_CONFIG);
        } else {
            errors.put(Error.UPDATE, ctl.getRefName());
        }
        reject(cmd);
    }
}
#end_block

#method_before
private boolean isCommit(final ReceiveCommand cmd) {
    RevObject obj;
    try {
        obj = rp.getRevWalk().parseAny(cmd.getNewId());
    } catch (IOException err) {
        log.error("Invalid object " + cmd.getNewId().name() + " for " + cmd.getRefName(), err);
        reject(cmd, "invalid object");
        return false;
    }
    if (obj instanceof RevCommit) {
        return true;
    } else {
        reject(cmd, "not a commit");
        return false;
    }
}
#method_after
private boolean isCommit(ReceiveCommand cmd) {
    RevObject obj;
    try {
        obj = rp.getRevWalk().parseAny(cmd.getNewId());
    } catch (IOException err) {
        logError("Invalid object " + cmd.getNewId().name() + " for " + cmd.getRefName(), err);
        reject(cmd, "invalid object");
        return false;
    }
    if (obj instanceof RevCommit) {
        return true;
    }
    reject(cmd, "not a commit");
    return false;
}
#end_block

#method_before
private void parseDelete(final ReceiveCommand cmd) {
    RefControl ctl = projectControl.controlForRef(cmd.getRefName());
    if (ctl.getRefName().startsWith(REFS_CHANGES)) {
        errors.put(Error.DELETE_CHANGES, ctl.getRefName());
        reject(cmd, "cannot delete changes");
    } else if (ctl.canDelete()) {
        if (!validRefOperation(cmd)) {
            return;
        }
        batch.addCommand(cmd);
    } else {
        if (RefNames.REFS_CONFIG.equals(ctl.getRefName())) {
            reject(cmd, "cannot delete project configuration");
        } else {
            errors.put(Error.DELETE, ctl.getRefName());
            reject(cmd, "cannot delete references");
        }
    }
}
#method_after
private void parseDelete(ReceiveCommand cmd) {
    logDebug("Deleting {}", cmd);
    RefControl ctl = projectControl.controlForRef(cmd.getRefName());
    if (ctl.getRefName().startsWith(REFS_CHANGES)) {
        errors.put(Error.DELETE_CHANGES, ctl.getRefName());
        reject(cmd, "cannot delete changes");
    } else if (ctl.canDelete()) {
        if (!validRefOperation(cmd)) {
            return;
        }
        batch.addCommand(cmd);
    } else {
        if (RefNames.REFS_CONFIG.equals(ctl.getRefName())) {
            reject(cmd, "cannot delete project configuration");
        } else {
            errors.put(Error.DELETE, ctl.getRefName());
            reject(cmd, "cannot delete references");
        }
    }
}
#end_block

#method_before
private void parseRewind(final ReceiveCommand cmd) {
    RevCommit newObject;
    try {
        newObject = rp.getRevWalk().parseCommit(cmd.getNewId());
    } catch (IncorrectObjectTypeException notCommit) {
        newObject = null;
    } catch (IOException err) {
        log.error("Invalid object " + cmd.getNewId().name() + " for " + cmd.getRefName() + " forced update", err);
        reject(cmd, "invalid object");
        return;
    }
    RefControl ctl = projectControl.controlForRef(cmd.getRefName());
    if (newObject != null) {
        validateNewCommits(ctl, cmd);
        if (cmd.getResult() != NOT_ATTEMPTED) {
            return;
        }
    }
    if (ctl.canForceUpdate()) {
        if (!validRefOperation(cmd)) {
            return;
        }
        batch.setAllowNonFastForwards(true).addCommand(cmd);
    } else {
        cmd.setResult(REJECTED_NONFASTFORWARD, " need '" + PermissionRule.FORCE_PUSH + "' privilege.");
    }
}
#method_after
private void parseRewind(ReceiveCommand cmd) {
    RevCommit newObject;
    try {
        newObject = rp.getRevWalk().parseCommit(cmd.getNewId());
    } catch (IncorrectObjectTypeException notCommit) {
        newObject = null;
    } catch (IOException err) {
        logError("Invalid object " + cmd.getNewId().name() + " for " + cmd.getRefName() + " forced update", err);
        reject(cmd, "invalid object");
        return;
    }
    logDebug("Rewinding {}", cmd);
    RefControl ctl = projectControl.controlForRef(cmd.getRefName());
    if (newObject != null) {
        validateNewCommits(ctl, cmd);
        if (cmd.getResult() != NOT_ATTEMPTED) {
            return;
        }
    }
    if (ctl.canForceUpdate()) {
        if (!validRefOperation(cmd)) {
            return;
        }
        batch.setAllowNonFastForwards(true).addCommand(cmd);
    } else {
        cmd.setResult(REJECTED_NONFASTFORWARD, " need '" + PermissionRule.FORCE_PUSH + "' privilege.");
    }
}
#end_block

#method_before
@Option(name = "-r", metaVar = "EMAIL", usage = "add reviewer to changes")
void reviewer(Account.Id id) {
    reviewer.add(id);
}
#method_after
@Option(name = "--reviewer", aliases = { "-r" }, metaVar = "EMAIL", usage = "add reviewer to changes")
void reviewer(Account.Id id) {
    reviewer.add(id);
}
#end_block

#method_before
@Option(name = "-l", metaVar = "LABEL+VALUE", usage = "label(s) to assign (defaults to +1 if no value provided")
void addLabel(final String token) throws CmdLineException {
    LabelVote v = LabelVote.parse(token);
    try {
        LabelType.checkName(v.getLabel());
        ApprovalsUtil.checkLabel(labelTypes, v.getLabel(), v.getValue());
    } catch (IllegalArgumentException e) {
        throw clp.reject(e.getMessage());
    }
    labels.put(v.getLabel(), v.getValue());
}
#method_after
@Option(name = "--label", aliases = { "-l" }, metaVar = "LABEL+VALUE", usage = "label(s) to assign (defaults to +1 if no value provided")
void addLabel(String token) throws CmdLineException {
    LabelVote v = LabelVote.parse(token);
    try {
        LabelType.checkName(v.label());
        ApprovalsUtil.checkLabel(labelTypes, v.label(), v.value());
    } catch (IllegalArgumentException e) {
        throw clp.reject(e.getMessage());
    }
    labels.put(v.label(), v.value());
}
#end_block

#method_before
String parse(CmdLineParser clp, Repository repo, Set<String> refs) throws CmdLineException {
    String ref = MagicBranch.getDestBranchName(cmd.getRefName());
    if (!ref.startsWith(Constants.R_REFS)) {
        ref = Constants.R_HEADS + ref;
    }
    int optionStart = ref.indexOf('%');
    if (0 < optionStart) {
        ListMultimap<String, String> options = LinkedListMultimap.create();
        for (String s : COMMAS.split(ref.substring(optionStart + 1))) {
            int e = s.indexOf('=');
            if (0 < e) {
                options.put(s.substring(0, e), s.substring(e + 1));
            } else {
                options.put(s, "");
            }
        }
        clp.parseOptionMap(options);
        ref = ref.substring(0, optionStart);
    }
    // Split the destination branch by branch and topic. The topic
    // suffix is entirely optional, so it might not even exist.
    String head = readHEAD(repo);
    int split = ref.length();
    for (; ; ) {
        String name = ref.substring(0, split);
        if (refs.contains(name) || name.equals(head)) {
            break;
        }
        split = name.lastIndexOf('/', split - 1);
        if (split <= Constants.R_REFS.length()) {
            return ref;
        }
    }
    if (split < ref.length()) {
        topic = Strings.emptyToNull(ref.substring(split + 1));
    }
    return ref.substring(0, split);
}
#method_after
String parse(CmdLineParser clp, Repository repo, Set<String> refs) throws CmdLineException {
    String ref = RefNames.fullName(MagicBranch.getDestBranchName(cmd.getRefName()));
    int optionStart = ref.indexOf('%');
    if (0 < optionStart) {
        ListMultimap<String, String> options = LinkedListMultimap.create();
        for (String s : COMMAS.split(ref.substring(optionStart + 1))) {
            int e = s.indexOf('=');
            if (0 < e) {
                options.put(s.substring(0, e), s.substring(e + 1));
            } else {
                options.put(s, "");
            }
        }
        clp.parseOptionMap(options);
        ref = ref.substring(0, optionStart);
    }
    // Split the destination branch by branch and topic. The topic
    // suffix is entirely optional, so it might not even exist.
    String head = readHEAD(repo);
    int split = ref.length();
    for (; ; ) {
        String name = ref.substring(0, split);
        if (refs.contains(name) || name.equals(head)) {
            break;
        }
        split = name.lastIndexOf('/', split - 1);
        if (split <= Constants.R_REFS.length()) {
            return ref;
        }
    }
    if (split < ref.length()) {
        topic = Strings.emptyToNull(ref.substring(split + 1));
    }
    return ref.substring(0, split);
}
#end_block

#method_before
private void parseMagicBranch(final ReceiveCommand cmd) {
    // Permit exactly one new change request per push.
    if (magicBranch != null) {
        reject(cmd, "duplicate request");
        return;
    }
    magicBranch = new MagicBranchInput(cmd, labelTypes);
    magicBranch.reviewer.addAll(reviewersFromCommandLine);
    magicBranch.cc.addAll(ccFromCommandLine);
    String ref;
    CmdLineParser clp = optionParserFactory.create(magicBranch);
    magicBranch.setCmdLineParser(clp);
    try {
        ref = magicBranch.parse(clp, repo, rp.getAdvertisedRefs().keySet());
    } catch (CmdLineException e) {
        if (!clp.wasHelpRequestedByOption()) {
            reject(cmd, e.getMessage());
            return;
        }
        // never happen
        ref = null;
    }
    if (clp.wasHelpRequestedByOption()) {
        StringWriter w = new StringWriter();
        w.write("\nHelp for refs/for/branch:\n\n");
        clp.printUsage(w, null);
        addMessage(w.toString());
        reject(cmd, "see help");
        return;
    }
    if (!rp.getAdvertisedRefs().containsKey(ref) && !ref.equals(readHEAD(repo))) {
        if (ref.startsWith(Constants.R_HEADS)) {
            String n = ref.substring(Constants.R_HEADS.length());
            reject(cmd, "branch " + n + " not found");
        } else {
            reject(cmd, ref + " not found");
        }
        return;
    }
    magicBranch.dest = new Branch.NameKey(project.getNameKey(), ref);
    magicBranch.ctl = projectControl.controlForRef(ref);
    if (!magicBranch.ctl.canWrite()) {
        reject(cmd, "project is read only");
        return;
    }
    if (magicBranch.isDraft() && (!receiveConfig.allowDrafts || projectControl.controlForRef("refs/drafts/" + ref).isBlocked(Permission.PUSH))) {
        errors.put(Error.CODE_REVIEW, ref);
        reject(cmd, "cannot upload drafts");
        return;
    }
    if (!magicBranch.ctl.canUpload()) {
        errors.put(Error.CODE_REVIEW, ref);
        reject(cmd, "cannot upload review");
        return;
    }
    if (magicBranch.isDraft() && magicBranch.isSubmit()) {
        reject(cmd, "cannot submit draft");
        return;
    }
    if (magicBranch.isSubmit() && !projectControl.controlForRef(MagicBranch.NEW_CHANGE + ref).canSubmit()) {
        reject(cmd, "submit not allowed");
    }
    RevWalk walk = rp.getRevWalk();
    if (magicBranch.base != null) {
        magicBranch.baseCommit = Lists.newArrayListWithCapacity(magicBranch.base.size());
        for (ObjectId id : magicBranch.base) {
            try {
                magicBranch.baseCommit.add(walk.parseCommit(id));
            } catch (IncorrectObjectTypeException notCommit) {
                reject(cmd, "base must be a commit");
                return;
            } catch (MissingObjectException e) {
                reject(cmd, "base not found");
                return;
            } catch (IOException e) {
                log.warn(String.format("Project %s cannot read %s", project.getName(), id.name()), e);
                reject(cmd, "internal server error");
                return;
            }
        }
    }
    // 
    try {
        final RevCommit tip = walk.parseCommit(magicBranch.cmd.getNewId());
        Ref targetRef = rp.getAdvertisedRefs().get(magicBranch.ctl.getRefName());
        if (targetRef == null || targetRef.getObjectId() == null) {
            // is "connected" to the branch.
            return;
        }
        final RevCommit h = walk.parseCommit(targetRef.getObjectId());
        final RevFilter oldRevFilter = walk.getRevFilter();
        try {
            walk.reset();
            walk.setRevFilter(RevFilter.MERGE_BASE);
            walk.markStart(tip);
            walk.markStart(h);
            if (walk.next() == null) {
                reject(magicBranch.cmd, "no common ancestry");
            }
        } finally {
            walk.reset();
            walk.setRevFilter(oldRevFilter);
        }
    } catch (IOException e) {
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        log.error("Invalid pack upload; one or more objects weren't sent", e);
    }
}
#method_after
private void parseMagicBranch(ReceiveCommand cmd) {
    // Permit exactly one new change request per push.
    if (magicBranch != null) {
        reject(cmd, "duplicate request");
        return;
    }
    logDebug("Found magic branch {}", cmd.getRefName());
    magicBranch = new MagicBranchInput(cmd, labelTypes, notesMigration);
    magicBranch.reviewer.addAll(reviewersFromCommandLine);
    magicBranch.cc.addAll(ccFromCommandLine);
    String ref;
    CmdLineParser clp = optionParserFactory.create(magicBranch);
    magicBranch.clp = clp;
    try {
        ref = magicBranch.parse(clp, repo, rp.getAdvertisedRefs().keySet());
    } catch (CmdLineException e) {
        if (!clp.wasHelpRequestedByOption()) {
            logDebug("Invalid branch syntax");
            reject(cmd, e.getMessage());
            return;
        }
        // never happen
        ref = null;
    }
    if (clp.wasHelpRequestedByOption()) {
        StringWriter w = new StringWriter();
        w.write("\nHelp for refs/for/branch:\n\n");
        clp.printUsage(w, null);
        addMessage(w.toString());
        reject(cmd, "see help");
        return;
    }
    if (projectControl.getProjectState().isAllUsers() && RefNames.REFS_USERS_SELF.equals(ref)) {
        logDebug("Handling {}", RefNames.REFS_USERS_SELF);
        ref = RefNames.refsUsers(user.getAccountId());
    }
    if (!rp.getAdvertisedRefs().containsKey(ref) && !ref.equals(readHEAD(repo))) {
        logDebug("Ref {} not found", ref);
        if (ref.startsWith(Constants.R_HEADS)) {
            String n = ref.substring(Constants.R_HEADS.length());
            reject(cmd, "branch " + n + " not found");
        } else {
            reject(cmd, ref + " not found");
        }
        return;
    }
    magicBranch.dest = new Branch.NameKey(project.getNameKey(), ref);
    magicBranch.ctl = projectControl.controlForRef(ref);
    if (!magicBranch.ctl.canWrite()) {
        reject(cmd, "project is read only");
        return;
    }
    if (magicBranch.draft) {
        if (!receiveConfig.allowDrafts) {
            errors.put(Error.CODE_REVIEW, ref);
            reject(cmd, "draft workflow is disabled");
            return;
        } else if (projectControl.controlForRef("refs/drafts/" + ref).isBlocked(Permission.PUSH)) {
            errors.put(Error.CODE_REVIEW, ref);
            reject(cmd, "cannot upload drafts");
            return;
        }
    }
    if (!magicBranch.ctl.canUpload()) {
        errors.put(Error.CODE_REVIEW, ref);
        reject(cmd, "cannot upload review");
        return;
    }
    if (magicBranch.draft && magicBranch.submit) {
        reject(cmd, "cannot submit draft");
        return;
    }
    if (magicBranch.submit && !projectControl.controlForRef(MagicBranch.NEW_CHANGE + ref).canSubmit()) {
        reject(cmd, "submit not allowed");
        return;
    }
    RevWalk walk = rp.getRevWalk();
    RevCommit tip;
    try {
        tip = walk.parseCommit(magicBranch.cmd.getNewId());
        logDebug("Tip of push: {}", tip.name());
    } catch (IOException ex) {
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", ex);
        return;
    }
    // if %base was specified, ignore newChangeForAllNotInTarget
    if (tip.getParentCount() > 1 || magicBranch.base != null || tip.getParentCount() == 0) {
        logDebug("Forcing newChangeForAllNotInTarget = false");
        newChangeForAllNotInTarget = false;
    }
    if (magicBranch.base != null) {
        logDebug("Handling %base: {}", magicBranch.base);
        magicBranch.baseCommit = Lists.newArrayListWithCapacity(magicBranch.base.size());
        for (ObjectId id : magicBranch.base) {
            try {
                magicBranch.baseCommit.add(walk.parseCommit(id));
            } catch (IncorrectObjectTypeException notCommit) {
                reject(cmd, "base must be a commit");
                return;
            } catch (MissingObjectException e) {
                reject(cmd, "base not found");
                return;
            } catch (IOException e) {
                logWarn(String.format("Project %s cannot read %s", project.getName(), id.name()), e);
                reject(cmd, "internal server error");
                return;
            }
        }
    } else if (newChangeForAllNotInTarget) {
        logDebug("Handling newChangeForAllNotInTarget");
        String destBranch = magicBranch.dest.get();
        try {
            Ref r = repo.getRefDatabase().exactRef(destBranch);
            if (r == null) {
                reject(cmd, destBranch + " not found");
                return;
            }
            ObjectId baseHead = r.getObjectId();
            magicBranch.baseCommit = Collections.singletonList(walk.parseCommit(baseHead));
            logDebug("Set baseCommit = {}", magicBranch.baseCommit.get(0).name());
        } catch (IOException ex) {
            logWarn(String.format("Project %s cannot read %s", project.getName(), destBranch), ex);
            reject(cmd, "internal server error");
            return;
        }
    }
    // 
    try {
        Ref targetRef = rp.getAdvertisedRefs().get(magicBranch.ctl.getRefName());
        if (targetRef == null || targetRef.getObjectId() == null) {
            // The destination branch does not yet exist. Assume the
            // history being sent for review will start it and thus
            // is "connected" to the branch.
            logDebug("Branch is unborn");
            return;
        }
        RevCommit h = walk.parseCommit(targetRef.getObjectId());
        logDebug("Current branch tip: {}", h.name());
        RevFilter oldRevFilter = walk.getRevFilter();
        try {
            walk.reset();
            walk.setRevFilter(RevFilter.MERGE_BASE);
            walk.markStart(tip);
            walk.markStart(h);
            if (walk.next() == null) {
                reject(magicBranch.cmd, "no common ancestry");
            }
        } finally {
            walk.reset();
            walk.setRevFilter(oldRevFilter);
        }
    } catch (IOException e) {
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", e);
    }
}
#end_block

#method_before
private void parseReplaceCommand(final ReceiveCommand cmd, final Change.Id changeId) {
    if (cmd.getType() != ReceiveCommand.Type.CREATE) {
        reject(cmd, "invalid usage");
        return;
    }
    final RevCommit newCommit;
    try {
        newCommit = rp.getRevWalk().parseCommit(cmd.getNewId());
    } catch (IOException e) {
        log.error("Cannot parse " + cmd.getNewId().name() + " as commit", e);
        reject(cmd, "invalid commit");
        return;
    }
    final Change changeEnt;
    try {
        changeEnt = db.changes().get(changeId);
    } catch (OrmException e) {
        log.error("Cannot lookup existing change " + changeId, e);
        reject(cmd, "database error");
        return;
    }
    if (changeEnt == null) {
        reject(cmd, "change " + changeId + " not found");
        return;
    }
    if (!project.getNameKey().equals(changeEnt.getProject())) {
        reject(cmd, "change " + changeId + " does not belong to project " + project.getName());
        return;
    }
    requestReplace(cmd, true, changeEnt, newCommit);
}
#method_after
private void parseReplaceCommand(ReceiveCommand cmd, Change.Id changeId) {
    logDebug("Parsing replace command");
    if (cmd.getType() != ReceiveCommand.Type.CREATE) {
        reject(cmd, "invalid usage");
        return;
    }
    RevCommit newCommit;
    try {
        newCommit = rp.getRevWalk().parseCommit(cmd.getNewId());
        logDebug("Replacing with {}", newCommit);
    } catch (IOException e) {
        logError("Cannot parse " + cmd.getNewId().name() + " as commit", e);
        reject(cmd, "invalid commit");
        return;
    }
    Change changeEnt;
    try {
        changeEnt = notesFactory.createChecked(db, project.getNameKey(), changeId).getChange();
    } catch (OrmException e) {
        logError("Cannot lookup existing change " + changeId, e);
        reject(cmd, "database error");
        return;
    } catch (NoSuchChangeException e) {
        logError("Change not found " + changeId, e);
        reject(cmd, "change " + changeId + " not found");
        return;
    }
    if (!project.getNameKey().equals(changeEnt.getProject())) {
        reject(cmd, "change " + changeId + " does not belong to project " + project.getName());
        return;
    }
    logDebug("Replacing change {}", changeEnt.getId());
    requestReplace(cmd, true, changeEnt, newCommit);
}
#end_block

#method_before
private boolean requestReplace(final ReceiveCommand cmd, final boolean checkMergedInto, final Change change, final RevCommit newCommit) {
    if (change.getStatus().isClosed()) {
        reject(cmd, "change " + change.getId() + " closed");
        return false;
    }
    final ReplaceRequest req = new ReplaceRequest(change.getId(), newCommit, cmd, checkMergedInto);
    if (replaceByChange.containsKey(req.ontoChange)) {
        reject(cmd, "duplicate request");
        return false;
    }
    if (replaceByCommit.containsKey(req.newCommit)) {
        reject(cmd, "duplicate request");
        return false;
    }
    replaceByChange.put(req.ontoChange, req);
    replaceByCommit.put(req.newCommit, req);
    return true;
}
#method_after
private boolean requestReplace(ReceiveCommand cmd, boolean checkMergedInto, Change change, RevCommit newCommit) {
    if (change.getStatus().isClosed()) {
        reject(cmd, "change " + canonicalWebUrl + change.getId() + " closed");
        return false;
    }
    ReplaceRequest req = new ReplaceRequest(change.getId(), newCommit, cmd, checkMergedInto);
    if (replaceByChange.containsKey(req.ontoChange)) {
        reject(cmd, "duplicate request");
        return false;
    }
    replaceByChange.put(req.ontoChange, req);
    return true;
}
#end_block

#method_before
private void markHeadsAsUninteresting(final RevWalk walk, Set<ObjectId> existing, @Nullable String forRef) {
    for (Ref ref : allRefs.values()) {
        if (ref.getObjectId() == null) {
            continue;
        } else if (ref.getName().startsWith(REFS_CHANGES)) {
            existing.add(ref.getObjectId());
        } else if (ref.getName().startsWith(R_HEADS) || (forRef != null && forRef.equals(ref.getName()))) {
            try {
                walk.markUninteresting(walk.parseCommit(ref.getObjectId()));
            } catch (IOException e) {
                log.warn(String.format("Invalid ref %s in %s", ref.getName(), project.getName()), e);
                continue;
            }
        }
    }
}
#method_after
private void markHeadsAsUninteresting(RevWalk rw, @Nullable String forRef) {
    int i = 0;
    for (Ref ref : allRefs.values()) {
        if ((ref.getName().startsWith(R_HEADS) || ref.getName().equals(forRef)) && ref.getObjectId() != null) {
            try {
                rw.markUninteresting(rw.parseCommit(ref.getObjectId()));
                i++;
            } catch (IOException e) {
                logWarn(String.format("Invalid ref %s in %s", ref.getName(), project.getName()), e);
            }
        }
    }
    logDebug("Marked {} heads as uninteresting", i);
}
#end_block

#method_before
private void submit(ChangeControl changeCtl, PatchSet ps) throws OrmException, IOException {
    Submit submit = submitProvider.get();
    RevisionResource rsrc = new RevisionResource(changes.parse(changeCtl), ps);
    Change c;
    try {
        // Force submit even if submit rule evaluation fails.
        c = submit.submit(rsrc, currentUser, true);
    } catch (ResourceConflictException e) {
        throw new IOException(e);
    }
    if (c == null) {
        addError("Submitting change " + changeCtl.getChange().getChangeId() + " failed.");
    } else {
        addMessage("");
        mergeQueue.merge(c.getDest());
        c = db.changes().get(c.getId());
        switch(c.getStatus()) {
            case SUBMITTED:
                addMessage("Change " + c.getChangeId() + " submitted.");
                break;
            case MERGED:
                addMessage("Change " + c.getChangeId() + " merged.");
                break;
            case NEW:
                ChangeMessage msg = submit.getConflictMessage(rsrc);
                if (msg != null) {
                    addMessage("Change " + c.getChangeId() + ": " + msg.getMessage());
                    break;
                }
            default:
                addMessage("change " + c.getChangeId() + " is " + c.getStatus().name().toLowerCase());
        }
    }
}
#method_after
private void submit(Collection<CreateRequest> create, Collection<ReplaceRequest> replace) throws OrmException, RestApiException {
    Map<ObjectId, Change> bySha = Maps.newHashMapWithExpectedSize(create.size() + replace.size());
    for (CreateRequest r : create) {
        checkNotNull(r.change, "cannot submit new change %s; op may not have run", r.changeId);
        bySha.put(r.commit, r.change);
    }
    for (ReplaceRequest r : replace) {
        bySha.put(r.newCommitId, r.notes.getChange());
    }
    Change tipChange = bySha.get(magicBranch.cmd.getNewId());
    checkNotNull(tipChange, "tip of push does not correspond to a change; found these changes: %s", bySha);
    logDebug("Processing submit with tip change {} ({})", tipChange.getId(), magicBranch.cmd.getNewId());
    try (MergeOp op = mergeOpProvider.get()) {
        op.merge(db, tipChange, user, false, new SubmitInput());
    }
}
#end_block

#method_before
private void preparePatchSetsForReplace() {
    try {
        readChangesForReplace();
        for (Iterator<ReplaceRequest> itr = replaceByChange.values().iterator(); itr.hasNext(); ) {
            ReplaceRequest req = itr.next();
            if (req.inputCommand.getResult() == NOT_ATTEMPTED) {
                req.validate(false);
                if (req.skip && req.cmd == null) {
                    itr.remove();
                    replaceByCommit.remove(req.newCommit);
                }
            }
        }
    } catch (OrmException err) {
        log.error(String.format("Cannot read database before replacement for project %s", project.getName()), err);
        for (ReplaceRequest req : replaceByChange.values()) {
            if (req.inputCommand.getResult() == NOT_ATTEMPTED) {
                req.inputCommand.setResult(REJECTED_OTHER_REASON, "internal server error");
            }
        }
    } catch (IOException err) {
        log.error(String.format("Cannot read repository before replacement for project %s", project.getName()), err);
        for (ReplaceRequest req : replaceByChange.values()) {
            if (req.inputCommand.getResult() == NOT_ATTEMPTED) {
                req.inputCommand.setResult(REJECTED_OTHER_REASON, "internal server error");
            }
        }
    }
    for (ReplaceRequest req : replaceByChange.values()) {
        if (req.inputCommand.getResult() == NOT_ATTEMPTED && req.cmd != null) {
            batch.addCommand(req.cmd);
        }
    }
    if (magicBranch != null && magicBranch.cmd.getResult() != NOT_ATTEMPTED) {
        // Cancel creations tied to refs/for/ or refs/drafts/ command.
        for (ReplaceRequest req : replaceByChange.values()) {
            if (req.inputCommand == magicBranch.cmd && req.cmd != null) {
                req.cmd.setResult(Result.REJECTED_OTHER_REASON, "aborted");
            }
        }
        for (CreateRequest req : newChanges) {
            req.cmd.setResult(Result.REJECTED_OTHER_REASON, "aborted");
        }
    }
}
#method_after
private void preparePatchSetsForReplace() {
    try {
        readChangesForReplace();
        for (Iterator<ReplaceRequest> itr = replaceByChange.values().iterator(); itr.hasNext(); ) {
            ReplaceRequest req = itr.next();
            if (req.inputCommand.getResult() == NOT_ATTEMPTED) {
                req.validate(false);
                if (req.skip && req.cmd == null) {
                    itr.remove();
                }
            }
        }
    } catch (OrmException err) {
        logError(String.format("Cannot read database before replacement for project %s", project.getName()), err);
        for (ReplaceRequest req : replaceByChange.values()) {
            if (req.inputCommand.getResult() == NOT_ATTEMPTED) {
                req.inputCommand.setResult(REJECTED_OTHER_REASON, "internal server error");
            }
        }
    } catch (IOException err) {
        logError(String.format("Cannot read repository before replacement for project %s", project.getName()), err);
        for (ReplaceRequest req : replaceByChange.values()) {
            if (req.inputCommand.getResult() == NOT_ATTEMPTED) {
                req.inputCommand.setResult(REJECTED_OTHER_REASON, "internal server error");
            }
        }
    }
    logDebug("Read {} changes to replace", replaceByChange.size());
    for (ReplaceRequest req : replaceByChange.values()) {
        if (req.inputCommand.getResult() == NOT_ATTEMPTED && req.cmd != null) {
            if (req.prev != null) {
                batch.addCommand(req.prev);
            }
            batch.addCommand(req.cmd);
        }
    }
    if (magicBranch != null && magicBranch.cmd.getResult() != NOT_ATTEMPTED) {
        // Cancel creations tied to refs/for/ or refs/drafts/ command.
        for (ReplaceRequest req : replaceByChange.values()) {
            if (req.inputCommand == magicBranch.cmd && req.cmd != null) {
                req.cmd.setResult(Result.REJECTED_OTHER_REASON, "aborted");
            }
        }
        for (CreateRequest req : newChanges) {
            req.cmd.setResult(Result.REJECTED_OTHER_REASON, "aborted");
        }
    }
}
#end_block

#method_before
private void readChangesForReplace() throws OrmException {
    List<CheckedFuture<Change, OrmException>> futures = Lists.newArrayListWithCapacity(replaceByChange.size());
    for (ReplaceRequest request : replaceByChange.values()) {
        futures.add(db.changes().getAsync(request.ontoChange));
    }
    for (CheckedFuture<Change, OrmException> f : futures) {
        Change c = f.checkedGet();
        if (c != null) {
            replaceByChange.get(c.getId()).change = c;
        }
    }
}
#method_after
private void readChangesForReplace() throws OrmException {
    Collection<ChangeNotes> allNotes = notesFactory.create(db, Collections2.transform(replaceByChange.values(), new Function<ReplaceRequest, Change.Id>() {

        @Override
        public Change.Id apply(ReplaceRequest in) {
            return in.ontoChange;
        }
    }));
    for (ChangeNotes notes : allNotes) {
        replaceByChange.get(notes.getChangeId()).notes = notes;
    }
}
#end_block

#method_before
boolean validate(boolean autoClose) throws IOException {
    if (!autoClose && inputCommand.getResult() != NOT_ATTEMPTED) {
        return false;
    } else if (change == null) {
        reject(inputCommand, "change " + ontoChange + " not found");
        return false;
    }
    priorPatchSet = change.currentPatchSetId();
    if (!revisions.containsValue(priorPatchSet)) {
        reject(inputCommand, "change " + ontoChange + " missing revisions");
        return false;
    }
    RevCommit priorCommit = revisions.inverse().get(priorPatchSet);
    if (newCommit == priorCommit) {
        // Ignore requests to make the change its current state.
        skip = true;
        reject(inputCommand, "commit already exists (as current patchset)");
        return false;
    }
    changeCtl = projectControl.controlFor(change);
    if (!changeCtl.canAddPatchSet()) {
        reject(inputCommand, "cannot replace " + ontoChange);
        return false;
    } else if (change.getStatus().isClosed()) {
        reject(inputCommand, "change " + ontoChange + " closed");
        return false;
    } else if (revisions.containsKey(newCommit)) {
        reject(inputCommand, "commit already exists (in the change)");
        return false;
    }
    for (final Ref r : rp.getRepository().getRefDatabase().getRefs("refs/changes").values()) {
        if (r.getObjectId().equals(newCommit)) {
            reject(inputCommand, "commit already exists (in the project)");
            return false;
        }
    }
    for (RevCommit prior : revisions.keySet()) {
        // amending when trying to address review comments.
        if (rp.getRevWalk().isMergedInto(prior, newCommit)) {
            reject(inputCommand, "squash commits first");
            return false;
        }
    }
    rp.getRevWalk().parseBody(newCommit);
    if (!validCommit(changeCtl.getRefControl(), inputCommand, newCommit)) {
        return false;
    }
    rp.getRevWalk().parseBody(priorCommit);
    // of the commit was modified.
    if (newCommit.getTree() == priorCommit.getTree()) {
        final boolean messageEq = eq(newCommit.getFullMessage(), priorCommit.getFullMessage());
        final boolean parentsEq = parentsEqual(newCommit, priorCommit);
        final boolean authorEq = authorEqual(newCommit, priorCommit);
        final ObjectReader reader = rp.getRevWalk().getObjectReader();
        if (messageEq && parentsEq && authorEq && !autoClose) {
            addMessage(String.format("(W) No changes between prior commit %s and new commit %s", reader.abbreviate(priorCommit).name(), reader.abbreviate(newCommit).name()));
            reject(inputCommand, "no changes made");
            return false;
        } else {
            StringBuilder msg = new StringBuilder();
            msg.append("(W) ");
            msg.append(reader.abbreviate(newCommit).name());
            msg.append(":");
            msg.append(" no files changed");
            if (!authorEq) {
                msg.append(", author changed");
            }
            if (!messageEq) {
                msg.append(", message updated");
            }
            if (!parentsEq) {
                msg.append(", was rebased");
            }
            addMessage(msg.toString());
        }
    }
    PatchSet.Id id = ChangeUtil.nextPatchSetId(allRefs, change.currentPatchSetId());
    newPatchSet = new PatchSet(id);
    newPatchSet.setCreatedOn(TimeUtil.nowTs());
    newPatchSet.setUploader(currentUser.getAccountId());
    newPatchSet.setRevision(toRevId(newCommit));
    if (magicBranch != null && magicBranch.isDraft()) {
        newPatchSet.setDraft(true);
    }
    info = patchSetInfoFactory.get(newCommit, newPatchSet.getId());
    cmd = new ReceiveCommand(ObjectId.zeroId(), newCommit, newPatchSet.getRefName());
    return true;
}
#method_after
boolean validate(boolean autoClose) throws IOException, OrmException {
    if (!autoClose && inputCommand.getResult() != NOT_ATTEMPTED) {
        return false;
    } else if (notes == null) {
        reject(inputCommand, "change " + ontoChange + " not found");
        return false;
    }
    priorPatchSet = notes.getChange().currentPatchSetId();
    if (!revisions.containsValue(priorPatchSet)) {
        reject(inputCommand, "change " + ontoChange + " missing revisions");
        return false;
    }
    RevCommit newCommit = rp.getRevWalk().parseCommit(newCommitId);
    RevCommit priorCommit = revisions.inverse().get(priorPatchSet);
    changeCtl = projectControl.controlFor(notes);
    if (!changeCtl.canAddPatchSet(db)) {
        String locked = ".";
        if (changeCtl.isPatchSetLocked(db)) {
            locked = ". Change is patch set locked.";
        }
        reject(inputCommand, "cannot add patch set to " + ontoChange + locked);
        return false;
    } else if (notes.getChange().getStatus().isClosed()) {
        reject(inputCommand, "change " + ontoChange + " closed");
        return false;
    } else if (revisions.containsKey(newCommit)) {
        reject(inputCommand, "commit already exists (in the change)");
        return false;
    }
    for (Ref r : rp.getRepository().getRefDatabase().getRefs("refs/changes").values()) {
        if (r.getObjectId().equals(newCommit)) {
            reject(inputCommand, "commit already exists (in the project)");
            return false;
        }
    }
    for (RevCommit prior : revisions.keySet()) {
        // amending when trying to address review comments.
        if (rp.getRevWalk().isMergedInto(prior, newCommit)) {
            reject(inputCommand, SAME_CHANGE_ID_IN_MULTIPLE_CHANGES);
            return false;
        }
    }
    if (!validCommit(rp.getRevWalk(), changeCtl.getRefControl(), inputCommand, newCommit)) {
        return false;
    }
    rp.getRevWalk().parseBody(priorCommit);
    // of the commit was modified.
    if (newCommit.getTree().equals(priorCommit.getTree())) {
        boolean messageEq = eq(newCommit.getFullMessage(), priorCommit.getFullMessage());
        boolean parentsEq = parentsEqual(newCommit, priorCommit);
        boolean authorEq = authorEqual(newCommit, priorCommit);
        ObjectReader reader = rp.getRevWalk().getObjectReader();
        if (messageEq && parentsEq && authorEq && !autoClose) {
            addMessage(String.format("(W) No changes between prior commit %s and new commit %s", reader.abbreviate(priorCommit).name(), reader.abbreviate(newCommit).name()));
        } else {
            StringBuilder msg = new StringBuilder();
            msg.append("(I) ");
            msg.append(reader.abbreviate(newCommit).name());
            msg.append(":");
            msg.append(" no files changed");
            if (!authorEq) {
                msg.append(", author changed");
            }
            if (!messageEq) {
                msg.append(", message updated");
            }
            if (!parentsEq) {
                msg.append(", was rebased");
            }
            addMessage(msg.toString());
        }
    }
    if (magicBranch != null && magicBranch.edit) {
        return newEdit();
    }
    newPatchSet();
    return true;
}
#end_block

#method_before
private List<Ref> refs(Change.Id changeId) {
    if (refsByChange == null) {
        int estRefsPerChange = 4;
        refsByChange = ArrayListMultimap.create(allRefs.size() / estRefsPerChange, estRefsPerChange);
        for (Ref ref : allRefs.values()) {
            if (ref.getObjectId() != null) {
                PatchSet.Id psId = PatchSet.Id.fromRef(ref.getName());
                if (psId != null) {
                    refsByChange.put(psId.getParentKey(), ref);
                }
            }
        }
    }
    return refsByChange.get(changeId);
}
#method_after
private List<Ref> refs(Change.Id changeId) {
    return refsByChange().get(changeId);
}
#end_block

#method_before
private SetMultimap<ObjectId, Ref> changeRefsById() throws IOException {
    if (refsById == null) {
        refsById = HashMultimap.create();
        for (Ref r : repo.getRefDatabase().getRefs(REFS_CHANGES).values()) {
            if (PatchSet.isRef(r.getName())) {
                refsById.put(r.getObjectId(), r);
            }
        }
    }
    return refsById;
}
#method_after
private SetMultimap<ObjectId, Ref> changeRefsById() {
    initChangeRefMaps();
    return refsById;
}
#end_block

#method_before
static boolean parentsEqual(RevCommit a, RevCommit b) {
    if (a.getParentCount() != b.getParentCount()) {
        return false;
    }
    for (int i = 0; i < a.getParentCount(); i++) {
        if (a.getParent(i) != b.getParent(i)) {
            return false;
        }
    }
    return true;
}
#method_after
static boolean parentsEqual(RevCommit a, RevCommit b) {
    if (a.getParentCount() != b.getParentCount()) {
        return false;
    }
    for (int i = 0; i < a.getParentCount(); i++) {
        if (!a.getParent(i).equals(b.getParent(i))) {
            return false;
        }
    }
    return true;
}
#end_block

#method_before
private boolean validRefOperation(final ReceiveCommand cmd) {
    RefOperationValidators refValidators = refValidatorsFactory.create(getProject(), currentUser, cmd);
    try {
        messages.addAll(refValidators.validateForRefOperation());
    } catch (RefOperationValidationException e) {
        messages.addAll(Lists.newArrayList(e.getMessages()));
        reject(cmd, e.getMessage());
        return false;
    }
    return true;
}
#method_after
private boolean validRefOperation(ReceiveCommand cmd) {
    RefOperationValidators refValidators = refValidatorsFactory.create(getProject(), user, cmd);
    try {
        messages.addAll(refValidators.validateForRefOperation());
    } catch (RefOperationValidationException e) {
        messages.addAll(Lists.newArrayList(e.getMessages()));
        reject(cmd, e.getMessage());
        return false;
    }
    return true;
}
#end_block

#method_before
private void validateNewCommits(RefControl ctl, ReceiveCommand cmd) {
    if (ctl.canForgeAuthor() && ctl.canForgeCommitter() && ctl.canForgeGerritServerIdentity() && ctl.canUploadMerges() && !projectControl.getProjectState().isUseSignedOffBy() && Iterables.isEmpty(rejectCommits) && !RefNames.REFS_CONFIG.equals(ctl.getRefName()) && !(MagicBranch.isMagicBranch(cmd.getRefName()) || NEW_PATCHSET.matcher(cmd.getRefName()).matches())) {
        return;
    }
    boolean defaultName = Strings.isNullOrEmpty(currentUser.getAccount().getFullName());
    final RevWalk walk = rp.getRevWalk();
    walk.reset();
    walk.sort(RevSort.NONE);
    try {
        Set<ObjectId> existing = Sets.newHashSet();
        walk.markStart(walk.parseCommit(cmd.getNewId()));
        markHeadsAsUninteresting(walk, existing, cmd.getRefName());
        RevCommit c;
        while ((c = walk.next()) != null) {
            if (existing.contains(c)) {
                continue;
            } else if (!validCommit(ctl, cmd, c)) {
                break;
            }
            if (defaultName && currentUser.getEmailAddresses().contains(c.getCommitterIdent().getEmailAddress())) {
                try {
                    Account a = db.accounts().get(currentUser.getAccountId());
                    if (a != null && Strings.isNullOrEmpty(a.getFullName())) {
                        a.setFullName(c.getCommitterIdent().getName());
                        db.accounts().update(Collections.singleton(a));
                        currentUser.getAccount().setFullName(a.getFullName());
                        accountCache.evict(a.getId());
                    }
                } catch (OrmException e) {
                    log.warn("Cannot default full_name", e);
                } finally {
                    defaultName = false;
                }
            }
        }
    } catch (IOException err) {
        cmd.setResult(REJECTED_MISSING_OBJECT);
        log.error("Invalid pack upload; one or more objects weren't sent", err);
    }
}
#method_after
private void validateNewCommits(RefControl ctl, ReceiveCommand cmd) {
    if (ctl.canForgeAuthor() && ctl.canForgeCommitter() && ctl.canForgeGerritServerIdentity() && ctl.canUploadMerges() && !projectControl.getProjectState().isUseSignedOffBy() && Iterables.isEmpty(rejectCommits) && !RefNames.REFS_CONFIG.equals(ctl.getRefName()) && !(MagicBranch.isMagicBranch(cmd.getRefName()) || NEW_PATCHSET.matcher(cmd.getRefName()).matches())) {
        logDebug("Short-circuiting new commit validation");
        return;
    }
    boolean defaultName = Strings.isNullOrEmpty(user.getAccount().getFullName());
    RevWalk walk = rp.getRevWalk();
    walk.reset();
    walk.sort(RevSort.NONE);
    try {
        RevObject parsedObject = walk.parseAny(cmd.getNewId());
        if (!(parsedObject instanceof RevCommit)) {
            return;
        }
        SetMultimap<ObjectId, Ref> existing = changeRefsById();
        walk.markStart((RevCommit) parsedObject);
        markHeadsAsUninteresting(walk, cmd.getRefName());
        int i = 0;
        for (RevCommit c; (c = walk.next()) != null; ) {
            i++;
            if (existing.keySet().contains(c)) {
                continue;
            } else if (!validCommit(walk, ctl, cmd, c)) {
                break;
            }
            if (defaultName && user.hasEmailAddress(c.getCommitterIdent().getEmailAddress())) {
                try {
                    Account a = db.accounts().get(user.getAccountId());
                    if (a != null && Strings.isNullOrEmpty(a.getFullName())) {
                        a.setFullName(c.getCommitterIdent().getName());
                        db.accounts().update(Collections.singleton(a));
                        user.getAccount().setFullName(a.getFullName());
                        accountCache.evict(a.getId());
                    }
                } catch (OrmException e) {
                    logWarn("Cannot default full_name", e);
                } finally {
                    defaultName = false;
                }
            }
        }
        logDebug("Validated {} new commits", i);
    } catch (IOException err) {
        cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", err);
    }
}
#end_block

#method_before
private boolean validCommit(final RefControl ctl, final ReceiveCommand cmd, final RevCommit c) throws MissingObjectException, IOException {
    if (validCommits.contains(c)) {
        return true;
    }
    CommitReceivedEvent receiveEvent = new CommitReceivedEvent(cmd, project, ctl.getRefName(), c, currentUser);
    CommitValidators commitValidators = commitValidatorsFactory.create(ctl, sshInfo, repo);
    try {
        messages.addAll(commitValidators.validateForReceiveCommits(receiveEvent, rejectCommits));
    } catch (CommitValidationException e) {
        messages.addAll(e.getMessages());
        reject(cmd, e.getMessage());
        return false;
    }
    validCommits.add(c);
    return true;
}
#method_after
private boolean validCommit(RevWalk rw, RefControl ctl, ReceiveCommand cmd, ObjectId id) throws IOException {
    if (validCommits.contains(id)) {
        return true;
    }
    RevCommit c = rw.parseCommit(id);
    rw.parseBody(c);
    CommitReceivedEvent receiveEvent = new CommitReceivedEvent(cmd, project, ctl.getRefName(), c, user);
    CommitValidators commitValidators = commitValidatorsFactory.create(ctl, sshInfo, repo);
    try {
        messages.addAll(commitValidators.validateForReceiveCommits(receiveEvent, rejectCommits));
    } catch (CommitValidationException e) {
        logDebug("Commit validation failed on {}", c.name());
        messages.addAll(e.getMessages());
        reject(cmd, e.getMessage());
        return false;
    }
    validCommits.add(c.copy());
    return true;
}
#end_block

#method_before
private void autoCloseChanges(final ReceiveCommand cmd) throws NoSuchChangeException {
    final RevWalk rw = rp.getRevWalk();
    try {
        rw.reset();
        rw.markStart(rw.parseCommit(cmd.getNewId()));
        if (!ObjectId.zeroId().equals(cmd.getOldId())) {
            rw.markUninteresting(rw.parseCommit(cmd.getOldId()));
        }
        final SetMultimap<ObjectId, Ref> byCommit = changeRefsById();
        final Map<Change.Key, Change.Id> byKey = openChangesByKey(new Branch.NameKey(project.getNameKey(), cmd.getRefName()));
        final List<ReplaceRequest> toClose = new ArrayList<>();
        RevCommit c;
        while ((c = rw.next()) != null) {
            final Set<Ref> refs = byCommit.get(c.copy());
            for (Ref ref : refs) {
                if (ref != null) {
                    rw.parseBody(c);
                    Change.Key closedChange = closeChange(cmd, PatchSet.Id.fromRef(ref.getName()), c);
                    closeProgress.update(1);
                    if (closedChange != null) {
                        byKey.remove(closedChange);
                    }
                }
            }
            rw.parseBody(c);
            for (final String changeId : c.getFooterLines(CHANGE_ID)) {
                final Change.Id onto = byKey.get(new Change.Key(changeId.trim()));
                if (onto != null) {
                    final ReplaceRequest req = new ReplaceRequest(onto, c, cmd, false);
                    req.change = db.changes().get(onto);
                    toClose.add(req);
                    break;
                }
            }
        }
        for (final ReplaceRequest req : toClose) {
            final PatchSet.Id psi = req.validate(true) ? req.insertPatchSet().checkedGet() : null;
            if (psi != null) {
                closeChange(req.inputCommand, psi, req.newCommit);
                closeProgress.update(1);
            }
        }
        // It handles gitlinks if required.
        rw.reset();
        final RevCommit codeReviewCommit = rw.parseCommit(cmd.getNewId());
        final SubmoduleOp subOp = subOpFactory.create(new Branch.NameKey(project.getNameKey(), cmd.getRefName()), codeReviewCommit, rw, repo, project, new ArrayList<Change>(), new HashMap<Change.Id, CodeReviewCommit>(), currentUser.getAccount());
        subOp.update();
    } catch (InsertException e) {
        log.error("Can't insert patchset", e);
    } catch (IOException e) {
        log.error("Can't scan for changes to close", e);
    } catch (OrmException e) {
        log.error("Can't scan for changes to close", e);
    } catch (SubmoduleException e) {
        log.error("Can't complete git links check", e);
    }
}
#method_after
private void autoCloseChanges(final ReceiveCommand cmd) {
    logDebug("Starting auto-closing of changes");
    String refName = cmd.getRefName();
    checkState(!MagicBranch.isMagicBranch(refName), "shouldn't be auto-closing changes on magic branch %s", refName);
    RevWalk rw = rp.getRevWalk();
    // insertChangesAndPatchSets.
    try (BatchUpdate bu = batchUpdateFactory.create(db, projectControl.getProject().getNameKey(), user, TimeUtil.nowTs());
        ObjectInserter ins = repo.newObjectInserter()) {
        bu.setRepository(repo, rp.getRevWalk(), ins).updateChangesInParallel();
        bu.setRequestId(receiveId);
        // TODO(dborowitz): Teach BatchUpdate to ignore missing changes.
        RevCommit newTip = rw.parseCommit(cmd.getNewId());
        Branch.NameKey branch = new Branch.NameKey(project.getNameKey(), refName);
        rw.reset();
        rw.markStart(newTip);
        if (!ObjectId.zeroId().equals(cmd.getOldId())) {
            rw.markUninteresting(rw.parseCommit(cmd.getOldId()));
        }
        SetMultimap<ObjectId, Ref> byCommit = changeRefsById();
        Map<Change.Key, ChangeNotes> byKey = null;
        List<ReplaceRequest> replaceAndClose = new ArrayList<>();
        int existingPatchSets = 0;
        int newPatchSets = 0;
        COMMIT: for (RevCommit c; (c = rw.next()) != null; ) {
            rw.parseBody(c);
            for (Ref ref : byCommit.get(c.copy())) {
                existingPatchSets++;
                PatchSet.Id psId = PatchSet.Id.fromRef(ref.getName());
                bu.addOp(psId.getParentKey(), mergedByPushOpFactory.create(requestScopePropagator, psId, refName));
                continue COMMIT;
            }
            for (String changeId : c.getFooterLines(CHANGE_ID)) {
                if (byKey == null) {
                    byKey = openChangesByBranch(branch);
                }
                ChangeNotes onto = byKey.get(new Change.Key(changeId.trim()));
                if (onto != null) {
                    newPatchSets++;
                    // Hold onto this until we're done with the walk, as the call to
                    // req.validate below calls isMergedInto which resets the walk.
                    ReplaceRequest req = new ReplaceRequest(onto.getChangeId(), c, cmd, false);
                    req.notes = onto;
                    replaceAndClose.add(req);
                    continue COMMIT;
                }
            }
        }
        for (final ReplaceRequest req : replaceAndClose) {
            Change.Id id = req.notes.getChangeId();
            if (!req.validate(true)) {
                logDebug("Not closing {} because validation failed", id);
                continue;
            }
            req.addOps(bu, null);
            bu.addOp(id, mergedByPushOpFactory.create(requestScopePropagator, req.psId, refName).setPatchSetProvider(new Provider<PatchSet>() {

                @Override
                public PatchSet get() {
                    return req.replaceOp.getPatchSet();
                }
            }));
            bu.addOp(id, new ChangeProgressOp(closeProgress));
        }
        logDebug("Auto-closing {} changes with existing patch sets and {} with" + " new patch sets", existingPatchSets, newPatchSets);
        bu.execute();
    } catch (RestApiException e) {
        logError("Can't insert patchset", e);
    } catch (IOException | OrmException | UpdateException e) {
        logError("Can't scan for changes to close", e);
    }
}
#end_block

#method_before
private void reject(final ReceiveCommand cmd) {
    reject(cmd, "prohibited by Gerrit");
}
#method_after
private void reject(ReceiveCommand cmd) {
    reject(cmd, "prohibited by Gerrit");
}
#end_block

#method_before
private void reject(final ReceiveCommand cmd, final String why) {
    cmd.setResult(REJECTED_OTHER_REASON, why);
    commandProgress.update(1);
}
#method_after
private void reject(ReceiveCommand cmd, String why) {
    cmd.setResult(REJECTED_OTHER_REASON, why);
    commandProgress.update(1);
}
#end_block

#method_before
private static boolean isHead(final ReceiveCommand cmd) {
    return cmd.getRefName().startsWith(Constants.R_HEADS);
}
#method_after
private static boolean isHead(ReceiveCommand cmd) {
    return cmd.getRefName().startsWith(Constants.R_HEADS);
}
#end_block

#method_before
private static boolean isConfig(final ReceiveCommand cmd) {
    return cmd.getRefName().equals(RefNames.REFS_CONFIG);
}
#method_after
private static boolean isConfig(ReceiveCommand cmd) {
    return cmd.getRefName().equals(RefNames.REFS_CONFIG);
}
#end_block

#method_before
@Test
public void testUSER_NoPreferredEmailUser() {
    setFrom("USER");
    final String name = "A U. Thor";
    final Account.Id user = user(name, null);
    replay(accountCache);
    final Address r = create().from(user);
    assertThat(r).isNotNull();
    assertThat(r.name).isEqualTo(name);
    assertThat(r.email).isEqualTo(ident.getEmailAddress());
    verify(accountCache);
}
#method_after
@Test
public void testUSER_NoPreferredEmailUser() {
    setFrom("USER");
    final String name = "A U. Thor";
    final Account.Id user = user(name, null);
    replay(accountCache);
    final Address r = create().from(user);
    assertThat(r).isNotNull();
    assertThat(r.name).isEqualTo(name + " (Code Review)");
    assertThat(r.email).isEqualTo(ident.getEmailAddress());
    verify(accountCache);
}
#end_block

#method_before
@Test
public void testUSERAllowDomain() {
    setFrom("USER");
    setDomain(Arrays.asList("*.example.com"));
    final String name = "A U. Thor";
    final String email = "a.u.thor@test.example.com";
    final Account.Id user = user(name, email);
    replay(accountCache);
    final Address r = create().from(user);
    assertThat(r).isNotNull();
    assertThat(r.name).isEqualTo(name);
    assertThat(r.email).isEqualTo(email);
    verify(accountCache);
}
#method_after
@Test
public void testUSERAllowDomain() {
    setFrom("USER");
    setDomains(Arrays.asList("*.example.com"));
    final String name = "A U. Thor";
    final String email = "a.u.thor@test.example.com";
    final Account.Id user = user(name, email);
    replay(accountCache);
    final Address r = create().from(user);
    assertThat(r).isNotNull();
    assertThat(r.name).isEqualTo(name);
    assertThat(r.email).isEqualTo(email);
    verify(accountCache);
}
#end_block

#method_before
@Test
public void testUSERNoAllowDomain() {
    setFrom("USER");
    setDomain(Arrays.asList("example.com"));
    final String name = "A U. Thor";
    final String email = "a.u.thor@test.com";
    final Account.Id user = user(name, email);
    replay(accountCache);
    final Address r = create().from(user);
    assertThat(r).isNotNull();
    assertThat(r.name).isEqualTo(name);
    assertThat(r.email).isEqualTo(ident.getEmailAddress());
    verify(accountCache);
}
#method_after
@Test
public void testUSERNoAllowDomain() {
    setFrom("USER");
    setDomains(Arrays.asList("example.com"));
    final String name = "A U. Thor";
    final String email = "a.u.thor@test.com";
    final Account.Id user = user(name, email);
    replay(accountCache);
    final Address r = create().from(user);
    assertThat(r).isNotNull();
    assertThat(r.name).isEqualTo(name + " (Code Review)");
    assertThat(r.email).isEqualTo(ident.getEmailAddress());
    verify(accountCache);
}
#end_block

#method_before
@Override
public Address from(final Account.Id fromId) {
    if (fromId != null) {
        Account a = accountCache.get(fromId).getAccount();
        String userEmail = a.getPreferredEmail();
        return new Address(a.getFullName(), canRelay(domains, userEmail) ? userEmail : srvAddr.getEmail());
    }
    return srvAddr;
}
#method_after
@Override
public Address from(final Account.Id fromId) {
    String senderName;
    if (fromId != null) {
        Account a = accountCache.get(fromId).getAccount();
        String fullName = a.getFullName();
        String userEmail = a.getPreferredEmail();
        if (canRelay(userEmail)) {
            return new Address(fullName, userEmail);
        }
        if (fullName == null || "".equals(fullName.trim())) {
            fullName = anonymousCowardName;
        }
        senderName = nameRewriteTmpl.replace("user", fullName).toString();
    } else {
        senderName = serverAddress.name;
    }
    String senderEmail;
    ParameterizedString senderEmailPattern = new ParameterizedString(serverAddress.email);
    if (senderEmailPattern.getParameterNames().isEmpty()) {
        senderEmail = senderEmailPattern.getRawPattern();
    } else {
        senderEmail = senderEmailPattern.replace("userHash", hashOf(senderName)).toString();
    }
    return new Address(senderName, senderEmail);
}
#end_block

#method_before
private boolean canRelay(String[] domains, String userEmail) {
    if (userEmail == null) {
        return false;
    }
    int index = userEmail.indexOf("@");
    if (index == -1) {
        return false;
    }
    String userDomain = userEmail.substring(index + 1);
    for (String domain : domains) {
        // Support wildcard
        domain = Pattern.quote(domain).replace("*", "\\E.*\\Q");
        if (userDomain.matches(domain)) {
            return true;
        }
    }
    return false;
}
#method_after
private boolean canRelay(String userEmail) {
    if (userEmail != null) {
        int index = userEmail.indexOf('@');
        if (index > 0 && index < userEmail.length() - 1) {
            return domainPattern.matcher(userEmail.substring(index + 1)).matches();
        }
    }
    return false;
}
#end_block

#method_before
public void addApprovals(ReviewDb db, ChangeUpdate update, LabelTypes labelTypes, PatchSet ps, ChangeControl changeCtl, Map<String, Short> approvals) throws OrmException {
    Iterable<PatchSetApproval> cells = makeApprovals(update, labelTypes, ps, changeCtl, approvals);
    db.patchSetApprovals().insert(cells);
}
#method_after
public Iterable<PatchSetApproval> addApprovals(ReviewDb db, ChangeUpdate update, LabelTypes labelTypes, PatchSet ps, ChangeControl changeCtl, Map<String, Short> approvals) throws OrmException {
    if (approvals.isEmpty()) {
        return Collections.emptyList();
    }
    checkApprovals(approvals, changeCtl);
    List<PatchSetApproval> cells = new ArrayList<>(approvals.size());
    Date ts = update.getWhen();
    for (Map.Entry<String, Short> vote : approvals.entrySet()) {
        LabelType lt = labelTypes.byLabel(vote.getKey());
        cells.add(new PatchSetApproval(new PatchSetApproval.Key(ps.getId(), ps.getUploader(), lt.getLabelId()), vote.getValue(), ts));
    }
    for (PatchSetApproval psa : cells) {
        update.putApproval(psa.getLabel(), psa.getValue());
    }
    db.patchSetApprovals().insert(cells);
    return cells;
}
#end_block

#method_before
@Override
public boolean updateChange(ChangeContext ctx) throws OrmException, IOException {
    change = ctx.getChange();
    if (change == null || change.getStatus().isClosed()) {
        rejectMessage = CHANGE_IS_CLOSED;
        return false;
    }
    if (groups.isEmpty()) {
        PatchSet prevPs = psUtil.current(ctx.getDb(), ctx.getNotes());
        groups = prevPs != null ? prevPs.getGroups() : ImmutableList.<String>of();
    }
    ChangeUpdate update = ctx.getUpdate(patchSetId);
    update.setSubjectForCommit("Create patch set " + patchSetId.get());
    String reviewMessage = null;
    if (magicBranch != null) {
        recipients.add(magicBranch.getMailRecipients());
        reviewMessage = magicBranch.message;
        approvals.putAll(magicBranch.labels);
        Set<String> hashtags = magicBranch.hashtags;
        if (hashtags != null && !hashtags.isEmpty()) {
            hashtags.addAll(ctx.getNotes().getHashtags());
            update.setHashtags(hashtags);
        }
        if (magicBranch.topic != null && !magicBranch.topic.equals(ctx.getChange().getTopic())) {
            update.setTopic(magicBranch.topic);
        }
    }
    boolean draft = magicBranch != null && magicBranch.draft;
    if (change.getStatus() == Change.Status.DRAFT && !draft) {
        update.setStatus(Change.Status.NEW);
    }
    newPatchSet = psUtil.insert(ctx.getDb(), ctx.getRevWalk(), update, patchSetId, commit, draft, groups, pushCertificate != null ? pushCertificate.toTextWithSignature() : null);
    recipients.add(getRecipientsFromFooters(ctx.getDb(), accountResolver, draft, commit.getFooterLines()));
    recipients.remove(ctx.getAccountId());
    ChangeData cd = changeDataFactory.create(ctx.getDb(), ctx.getControl());
    MailRecipients oldRecipients = getRecipientsFromReviewers(cd.reviewers());
    Iterable<PatchSetApproval> incomingApprovals = approvalsUtil.makeApprovals(update, projectControl.getLabelTypes(), newPatchSet, ctx.getControl(), approvals);
    approvalCopier.copy(ctx.getDb(), ctx.getControl(), newPatchSet, incomingApprovals);
    approvalsUtil.addReviewers(ctx.getDb(), update, projectControl.getLabelTypes(), change, newPatchSet, info, recipients.getReviewers(), oldRecipients.getAll());
    ctx.getDb().patchSetApprovals().insert(incomingApprovals);
    recipients.add(oldRecipients);
    String approvalMessage = ApprovalsUtil.renderMessageWithApprovals(patchSetId.get(), approvals, scanLabels(ctx, approvals));
    String kindMessage = changeKindMessage(changeKind);
    StringBuilder message = new StringBuilder(approvalMessage);
    if (!Strings.isNullOrEmpty(kindMessage)) {
        message.append(kindMessage);
    } else {
        message.append('.');
    }
    if (!Strings.isNullOrEmpty(reviewMessage)) {
        message.append("\n").append(reviewMessage);
    }
    msg = new ChangeMessage(new ChangeMessage.Key(change.getId(), ChangeUtil.messageUUID(ctx.getDb())), ctx.getAccountId(), ctx.getWhen(), patchSetId);
    msg.setMessage(message.toString());
    cmUtil.addChangeMessage(ctx.getDb(), update, msg);
    if (mergedByPushOp == null) {
        resetChange(ctx, msg);
    } else {
        mergedByPushOp.setPatchSetProvider(Providers.of(newPatchSet)).updateChange(ctx);
    }
    return true;
}
#method_after
@Override
public boolean updateChange(ChangeContext ctx) throws OrmException, IOException {
    change = ctx.getChange();
    if (change == null || change.getStatus().isClosed()) {
        rejectMessage = CHANGE_IS_CLOSED;
        return false;
    }
    if (groups.isEmpty()) {
        PatchSet prevPs = psUtil.current(ctx.getDb(), ctx.getNotes());
        groups = prevPs != null ? prevPs.getGroups() : ImmutableList.<String>of();
    }
    ChangeUpdate update = ctx.getUpdate(patchSetId);
    update.setSubjectForCommit("Create patch set " + patchSetId.get());
    String reviewMessage = null;
    if (magicBranch != null) {
        recipients.add(magicBranch.getMailRecipients());
        reviewMessage = magicBranch.message;
        approvals.putAll(magicBranch.labels);
        Set<String> hashtags = magicBranch.hashtags;
        if (hashtags != null && !hashtags.isEmpty()) {
            hashtags.addAll(ctx.getNotes().getHashtags());
            update.setHashtags(hashtags);
        }
        if (magicBranch.topic != null && !magicBranch.topic.equals(ctx.getChange().getTopic())) {
            update.setTopic(magicBranch.topic);
        }
    }
    boolean draft = magicBranch != null && magicBranch.draft;
    if (change.getStatus() == Change.Status.DRAFT && !draft) {
        update.setStatus(Change.Status.NEW);
    }
    newPatchSet = psUtil.insert(ctx.getDb(), ctx.getRevWalk(), update, patchSetId, commit, draft, groups, pushCertificate != null ? pushCertificate.toTextWithSignature() : null);
    recipients.add(getRecipientsFromFooters(ctx.getDb(), accountResolver, draft, commit.getFooterLines()));
    recipients.remove(ctx.getAccountId());
    ChangeData cd = changeDataFactory.create(ctx.getDb(), ctx.getControl());
    MailRecipients oldRecipients = getRecipientsFromReviewers(cd.reviewers());
    Iterable<PatchSetApproval> newApprovals = approvalsUtil.addApprovals(ctx.getDb(), update, projectControl.getLabelTypes(), newPatchSet, ctx.getControl(), approvals);
    approvalCopier.copy(ctx.getDb(), ctx.getControl(), newPatchSet, newApprovals);
    approvalsUtil.addReviewers(ctx.getDb(), update, projectControl.getLabelTypes(), change, newPatchSet, info, recipients.getReviewers(), oldRecipients.getAll());
    recipients.add(oldRecipients);
    String approvalMessage = ApprovalsUtil.renderMessageWithApprovals(patchSetId.get(), approvals, scanLabels(ctx, approvals));
    String kindMessage = changeKindMessage(changeKind);
    StringBuilder message = new StringBuilder(approvalMessage);
    if (!Strings.isNullOrEmpty(kindMessage)) {
        message.append(kindMessage);
    } else {
        message.append('.');
    }
    if (!Strings.isNullOrEmpty(reviewMessage)) {
        message.append("\n").append(reviewMessage);
    }
    msg = new ChangeMessage(new ChangeMessage.Key(change.getId(), ChangeUtil.messageUUID(ctx.getDb())), ctx.getAccountId(), ctx.getWhen(), patchSetId);
    msg.setMessage(message.toString());
    cmUtil.addChangeMessage(ctx.getDb(), update, msg);
    if (mergedByPushOp == null) {
        resetChange(ctx, msg);
    } else {
        mergedByPushOp.setPatchSetProvider(Providers.of(newPatchSet)).updateChange(ctx);
    }
    return true;
}
#end_block

#method_before
@Test
public void pushNewPatchsetOverridingStickyLabel() throws Exception {
    ProjectConfig cfg = projectCache.checkedGet(project).getConfig();
    LabelType codeReview = Util.codeReview();
    codeReview.setCopyMaxScore(true);
    cfg.getLabelSections().put(codeReview.getName(), codeReview);
    PushOneCommit.Result r = pushTo("refs/for/master%l=Code-Review+2");
    r.assertOkStatus();
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo, PushOneCommit.SUBJECT, "b.txt", "anotherContent", r.getChangeId());
    r = push.to("refs/for/master%l=Code-Review+1");
    r.assertOkStatus();
}
#method_after
@Test
public void pushNewPatchsetOverridingStickyLabel() throws Exception {
    ProjectConfig cfg = projectCache.checkedGet(project).getConfig();
    LabelType codeReview = Util.codeReview();
    codeReview.setCopyMaxScore(true);
    cfg.getLabelSections().put(codeReview.getName(), codeReview);
    saveProjectConfig(cfg);
    PushOneCommit.Result r = pushTo("refs/for/master%l=Code-Review+2");
    r.assertOkStatus();
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo, PushOneCommit.SUBJECT, "b.txt", "anotherContent", r.getChangeId());
    r = push.to("refs/for/master%l=Code-Review+1");
    r.assertOkStatus();
}
#end_block

#method_before
public void copy(ReviewDb db, ChangeControl ctl, PatchSet ps) throws OrmException {
    Iterable<PatchSetApproval> incomingApprovals = Collections.emptyList();
    copy(db, ctl, ps, incomingApprovals);
}
#method_after
public void copy(ReviewDb db, ChangeControl ctl, PatchSet ps) throws OrmException {
    copy(db, ctl, ps, Collections.<PatchSetApproval>emptyList());
}
#end_block

#method_before
public void copy(ReviewDb db, ChangeControl ctl, PatchSet ps, Iterable<PatchSetApproval> incomingApprovals) throws OrmException {
    db.patchSetApprovals().insert(getForPatchSet(db, ctl, ps, incomingApprovals));
}
#method_after
public void copy(ReviewDb db, ChangeControl ctl, PatchSet ps, Iterable<PatchSetApproval> dontCopy) throws OrmException {
    db.patchSetApprovals().insert(getForPatchSet(db, ctl, ps, dontCopy));
}
#end_block

#method_before
Iterable<PatchSetApproval> getForPatchSet(ReviewDb db, ChangeControl ctl, PatchSet.Id psId) throws OrmException {
    Iterable<PatchSetApproval> incomingApprovals = Collections.emptyList();
    return getForPatchSet(db, ctl, psId, incomingApprovals);
}
#method_after
Iterable<PatchSetApproval> getForPatchSet(ReviewDb db, ChangeControl ctl, PatchSet.Id psId) throws OrmException {
    return getForPatchSet(db, ctl, psId, Collections.<PatchSetApproval>emptyList());
}
#end_block

#method_before
Iterable<PatchSetApproval> getForPatchSet(ReviewDb db, ChangeControl ctl, PatchSet.Id psId, Iterable<PatchSetApproval> incomingApprovals) throws OrmException {
    PatchSet ps = psUtil.get(db, ctl.getNotes(), psId);
    if (ps == null) {
        return Collections.emptyList();
    }
    return getForPatchSet(db, ctl, ps, incomingApprovals);
}
#method_after
Iterable<PatchSetApproval> getForPatchSet(ReviewDb db, ChangeControl ctl, PatchSet.Id psId, Iterable<PatchSetApproval> dontCopy) throws OrmException {
    PatchSet ps = psUtil.get(db, ctl.getNotes(), psId);
    if (ps == null) {
        return Collections.emptyList();
    }
    return getForPatchSet(db, ctl, ps, dontCopy);
}
#end_block

#method_before
private Iterable<PatchSetApproval> getForPatchSet(ReviewDb db, ChangeControl ctl, PatchSet ps, Iterable<PatchSetApproval> incomingApprovals) throws OrmException {
    checkNotNull(ps, "ps should not be null");
    ChangeData cd = changeDataFactory.create(db, ctl);
    try {
        ProjectState project = projectCache.checkedGet(cd.change().getDest().getParentKey());
        ListMultimap<PatchSet.Id, PatchSetApproval> all = cd.approvals();
        checkNotNull(all, "all should not be null");
        Table<String, Account.Id, PatchSetApproval> wontCopy = HashBasedTable.create();
        for (PatchSetApproval psa : incomingApprovals) {
            wontCopy.put(psa.getLabel(), psa.getAccountId(), psa);
        }
        Table<String, Account.Id, PatchSetApproval> byUser = HashBasedTable.create();
        for (PatchSetApproval psa : all.get(ps.getId())) {
            byUser.put(psa.getLabel(), psa.getAccountId(), psa);
        }
        TreeMap<Integer, PatchSet> patchSets = getPatchSets(cd);
        try (Repository repo = repoManager.openRepository(project.getProject().getNameKey())) {
            // Walk patch sets strictly less than current in descending order.
            Collection<PatchSet> allPrior = patchSets.descendingMap().tailMap(ps.getId().get(), false).values();
            for (PatchSet priorPs : allPrior) {
                List<PatchSetApproval> priorApprovals = all.get(priorPs.getId());
                if (priorApprovals.isEmpty()) {
                    continue;
                }
                ChangeKind kind = changeKindCache.getChangeKind(project, repo, ObjectId.fromString(priorPs.getRevision().get()), ObjectId.fromString(ps.getRevision().get()));
                for (PatchSetApproval psa : priorApprovals) {
                    if (wontCopy.contains(psa.getLabel(), psa.getAccountId())) {
                        continue;
                    }
                    if (byUser.contains(psa.getLabel(), psa.getAccountId())) {
                        continue;
                    }
                    if (!canCopy(project, psa, ps.getId(), kind)) {
                        wontCopy.put(psa.getLabel(), psa.getAccountId(), psa);
                        continue;
                    }
                    byUser.put(psa.getLabel(), psa.getAccountId(), copy(psa, ps.getId()));
                }
            }
            return labelNormalizer.normalize(ctl, byUser.values()).getNormalized();
        }
    } catch (IOException e) {
        throw new OrmException(e);
    }
}
#method_after
private Iterable<PatchSetApproval> getForPatchSet(ReviewDb db, ChangeControl ctl, PatchSet ps, Iterable<PatchSetApproval> dontCopy) throws OrmException {
    checkNotNull(ps, "ps should not be null");
    ChangeData cd = changeDataFactory.create(db, ctl);
    try {
        ProjectState project = projectCache.checkedGet(cd.change().getDest().getParentKey());
        ListMultimap<PatchSet.Id, PatchSetApproval> all = cd.approvals();
        checkNotNull(all, "all should not be null");
        Table<String, Account.Id, PatchSetApproval> wontCopy = HashBasedTable.create();
        for (PatchSetApproval psa : dontCopy) {
            wontCopy.put(psa.getLabel(), psa.getAccountId(), psa);
        }
        Table<String, Account.Id, PatchSetApproval> byUser = HashBasedTable.create();
        for (PatchSetApproval psa : all.get(ps.getId())) {
            if (!wontCopy.contains(psa.getLabel(), psa.getAccountId())) {
                byUser.put(psa.getLabel(), psa.getAccountId(), psa);
            }
        }
        TreeMap<Integer, PatchSet> patchSets = getPatchSets(cd);
        try (Repository repo = repoManager.openRepository(project.getProject().getNameKey())) {
            // Walk patch sets strictly less than current in descending order.
            Collection<PatchSet> allPrior = patchSets.descendingMap().tailMap(ps.getId().get(), false).values();
            for (PatchSet priorPs : allPrior) {
                List<PatchSetApproval> priorApprovals = all.get(priorPs.getId());
                if (priorApprovals.isEmpty()) {
                    continue;
                }
                ChangeKind kind = changeKindCache.getChangeKind(project, repo, ObjectId.fromString(priorPs.getRevision().get()), ObjectId.fromString(ps.getRevision().get()));
                for (PatchSetApproval psa : priorApprovals) {
                    if (wontCopy.contains(psa.getLabel(), psa.getAccountId())) {
                        continue;
                    }
                    if (byUser.contains(psa.getLabel(), psa.getAccountId())) {
                        continue;
                    }
                    if (!canCopy(project, psa, ps.getId(), kind)) {
                        wontCopy.put(psa.getLabel(), psa.getAccountId(), psa);
                        continue;
                    }
                    byUser.put(psa.getLabel(), psa.getAccountId(), copy(psa, ps.getId()));
                }
            }
            return labelNormalizer.normalize(ctl, byUser.values()).getNormalized();
        }
    } catch (IOException e) {
        throw new OrmException(e);
    }
}
#end_block

#method_before
@Override
public boolean updateChange(ChangeContext ctx) throws AuthException, ResourceNotFoundException, OrmException {
    Account.Id reviewerId = reviewer.getId();
    currChange = ctx.getChange();
    currPs = psUtil.current(dbProvider.get(), ctx.getNotes());
    LabelTypes labelTypes = ctx.getControl().getLabelTypes();
    // removing a reviewer will remove all her votes
    for (LabelType lt : labelTypes.getLabelTypes()) {
        newApprovals.put(lt.getName(), (short) 0);
    }
    StringBuilder msg = new StringBuilder();
    for (PatchSetApproval a : approvals(ctx, reviewerId)) {
        if (ctx.getControl().canRemoveReviewer(a)) {
            del.add(a);
            if (a.getPatchSetId().equals(currPs.getId()) && a.getValue() != 0) {
                oldApprovals.put(a.getLabel(), a.getValue());
                if (msg.length() == 0) {
                    msg.append("Removed the following votes:\n\n");
                }
                msg.append("* ").append(a.getLabel()).append(formatLabelValue(a.getValue())).append(" by ").append(userFactory.create(a.getAccountId()).getNameEmail()).append("\n");
            }
        } else {
            throw new AuthException("delete not permitted");
        }
    }
    if (del.isEmpty()) {
        throw new ResourceNotFoundException();
    }
    msg.insert(0, "Removed the following reviewer: " + reviewer.getFullName() + "\n");
    ctx.getDb().patchSetApprovals().delete(del);
    ChangeUpdate update = ctx.getUpdate(currPs.getId());
    update.removeReviewer(reviewerId);
    changeMessage = new ChangeMessage(new ChangeMessage.Key(currChange.getId(), ChangeUtil.messageUUID(ctx.getDb())), ctx.getUser().getAccountId(), ctx.getWhen(), currPs.getId());
    changeMessage.setMessage(msg.toString());
    cmUtil.addChangeMessage(ctx.getDb(), update, changeMessage);
    return true;
}
#method_after
@Override
public boolean updateChange(ChangeContext ctx) throws AuthException, ResourceNotFoundException, OrmException {
    Account.Id reviewerId = reviewer.getId();
    if (!approvalsUtil.getReviewers(ctx.getDb(), ctx.getNotes()).all().contains(reviewerId)) {
        throw new ResourceNotFoundException();
    }
    currChange = ctx.getChange();
    currPs = psUtil.current(ctx.getDb(), ctx.getNotes());
    LabelTypes labelTypes = ctx.getControl().getLabelTypes();
    // removing a reviewer will remove all her votes
    for (LabelType lt : labelTypes.getLabelTypes()) {
        newApprovals.put(lt.getName(), (short) 0);
    }
    StringBuilder msg = new StringBuilder();
    msg.append("Removed reviewer " + reviewer.getFullName());
    StringBuilder removedVotesMsg = new StringBuilder();
    removedVotesMsg.append(" with the following votes:\n\n");
    boolean votesRemoved = false;
    for (PatchSetApproval a : approvals(ctx, reviewerId)) {
        if (ctx.getControl().canRemoveReviewer(a)) {
            del.add(a);
            if (a.getPatchSetId().equals(currPs.getId()) && a.getValue() != 0) {
                oldApprovals.put(a.getLabel(), a.getValue());
                removedVotesMsg.append("* ").append(a.getLabel()).append(formatLabelValue(a.getValue())).append(" by ").append(userFactory.create(a.getAccountId()).getNameEmail()).append("\n");
                votesRemoved = true;
            }
        } else {
            throw new AuthException("delete reviewer not permitted");
        }
    }
    if (votesRemoved) {
        msg.append(removedVotesMsg);
    } else {
        msg.append(".");
    }
    ctx.getDb().patchSetApprovals().delete(del);
    ChangeUpdate update = ctx.getUpdate(currPs.getId());
    update.removeReviewer(reviewerId);
    changeMessage = new ChangeMessage(new ChangeMessage.Key(currChange.getId(), ChangeUtil.messageUUID(ctx.getDb())), ctx.getAccountId(), ctx.getWhen(), currPs.getId());
    changeMessage.setMessage(msg.toString());
    cmUtil.addChangeMessage(ctx.getDb(), update, changeMessage);
    return true;
}
#end_block

#method_before
@Override
public void postUpdate(Context ctx) {
    emailReviewers(ctx.getProject(), currChange, del, changeMessage);
    try {
        hooks.doReviewerDeletedHook(currChange, reviewer, currPs, changeMessage.getMessage(), newApprovals, oldApprovals, dbProvider.get());
    } catch (OrmException e) {
        log.warn("ChangeHook.doCommentAddedHook delivery failed", e);
    }
}
#method_after
@Override
public void postUpdate(Context ctx) {
    emailReviewers(ctx.getProject(), currChange, del, changeMessage);
    reviewerDeleted.fire(currChange, currPs, reviewer, ctx.getAccount(), changeMessage.getMessage(), newApprovals, oldApprovals, ctx.getWhen());
}
#end_block

#method_before
private Iterable<PatchSetApproval> approvals(ChangeContext ctx, final Account.Id accountId) throws OrmException {
    return Iterables.filter(approvalsUtil.byChange(ctx.getDb(), ctx.getNotes()).values(), new Predicate<PatchSetApproval>() {

        @Override
        public boolean apply(PatchSetApproval input) {
            return accountId.equals(input.getAccountId());
        }
    });
}
#method_after
private Iterable<PatchSetApproval> approvals(ChangeContext ctx, final Account.Id accountId) throws OrmException {
    Change.Id changeId = ctx.getNotes().getChangeId();
    Iterable<PatchSetApproval> approvals;
    if (migration.readChanges()) {
        // Because NoteDb and ReviewDb have different semantics for zero-value
        // approvals, we must fall back to ReviewDb as the source of truth here.
        ReviewDb db = ctx.getDb();
        if (db instanceof BatchUpdateReviewDb) {
            db = ((BatchUpdateReviewDb) db).unsafeGetDelegate();
        }
        db = ReviewDbUtil.unwrapDb(db);
        approvals = db.patchSetApprovals().byChange(changeId);
    } else {
        approvals = approvalsUtil.byChange(ctx.getDb(), ctx.getNotes()).values();
    }
    return Iterables.filter(approvals, new Predicate<PatchSetApproval>() {

        @Override
        public boolean apply(PatchSetApproval input) {
            return accountId.equals(input.getAccountId());
        }
    });
}
#end_block

#method_before
private String formatLabelValue(short value) {
    if (value > 0) {
        return "+" + value;
    } else {
        return Short.toString(value);
    }
}
#method_after
private String formatLabelValue(short value) {
    if (value > 0) {
        return "+" + value;
    }
    return Short.toString(value);
}
#end_block

#method_before
private void emailReviewers(Project.NameKey projectName, Change change, List<PatchSetApproval> dels, ChangeMessage changeMessage) {
    // The user knows they removed themselves, don't bother emailing them.
    List<Account.Id> toMail = Lists.newArrayListWithCapacity(dels.size());
    Account.Id userId = user.get().getAccountId();
    for (PatchSetApproval psa : dels) {
        if (!psa.getAccountId().equals(userId)) {
            toMail.add(psa.getAccountId());
        }
    }
    if (!toMail.isEmpty()) {
        try {
            DeleteReviewerSender cm = deleteReviewerSenderFactory.create(projectName, change.getId());
            cm.setFrom(userId);
            cm.addReviewers(toMail);
            cm.setChangeMessage(changeMessage);
            cm.send();
        } catch (Exception err) {
            log.error("Cannot email update for change " + change.getId(), err);
        }
    }
}
#method_after
private void emailReviewers(Project.NameKey projectName, Change change, List<PatchSetApproval> dels, ChangeMessage changeMessage) {
    // The user knows they removed themselves, don't bother emailing them.
    List<Account.Id> toMail = Lists.newArrayListWithCapacity(dels.size());
    Account.Id userId = user.get().getAccountId();
    for (PatchSetApproval psa : dels) {
        if (!psa.getAccountId().equals(userId)) {
            toMail.add(psa.getAccountId());
        }
    }
    if (!toMail.isEmpty()) {
        try {
            DeleteReviewerSender cm = deleteReviewerSenderFactory.create(projectName, change.getId());
            cm.setFrom(userId);
            cm.addReviewers(toMail);
            cm.setChangeMessage(changeMessage.getMessage(), changeMessage.getWrittenOn());
            cm.send();
        } catch (Exception err) {
            log.error("Cannot email update for change " + change.getId(), err);
        }
    }
}
#end_block

#method_before
@Override
public List<ValidationMessage> onRefOperation(RefOperationReceivedEvent event) throws ValidationException {
    ArrayList<ValidationMessage> messages = Lists.newArrayList();
    if (event.command.getRefName().startsWith("invalidate-")) {
        throw new ValidationException(String.format("Invalid ref's %s %s operation in project was performed!", event.command.getRefName(), event.command.getType(), event.project.getName()));
    }
    return messages;
}
#method_after
@Override
public List<ValidationMessage> onRefOperation(RefReceivedEvent event) throws ValidationException {
    ArrayList<ValidationMessage> messages = Lists.newArrayList();
    if (event.command.getRefName().startsWith(RefNames.REFS_HEADS + "protected-") && !event.user.getCapabilities().canAdministrateServer()) {
        throw new ValidationException(String.format("Operation %s on %s branch in project %s is not valid!", event.command.getType(), event.command.getRefName(), event.project.getName()));
    }
    return messages;
}
#end_block

#method_before
@Override
protected void configure() {
    DynamicSet.bind(binder(), TopMenu.class).to(HelloTopMenu.class);
    DynamicSet.bind(binder(), PatchSetWebLink.class).to(HelloWeblink.class);
    DynamicSet.bind(binder(), ProjectWebLink.class).to(HelloWeblink.class);
    DynamicSet.bind(binder(), ServerPluginProvider.class).to(HelloSshPluginProvider.class);
    DynamicSet.bind(binder(), UsageDataPublishedListener.class).to(UsageDataLogger.class);
    install(new RestApiModule() {

        @Override
        protected void configure() {
            post(REVISION_KIND, "hello-revision").to(HelloRevisionAction.class);
            post(PROJECT_KIND, "hello-project").to(HelloProjectAction.class);
            get(REVISION_KIND, "greetings").to(Greetings.class);
        }
    });
    DynamicSet.bind(binder(), UploadValidationListener.class).to(DenyUploadExample.class);
    DynamicSet.bind(binder(), RefOperationValidationListener.class).to(RefOperationValidationExample.class);
    configurePluginParameters();
}
#method_after
@Override
protected void configure() {
    DynamicSet.bind(binder(), TopMenu.class).to(HelloTopMenu.class);
    DynamicSet.bind(binder(), PatchSetWebLink.class).to(HelloWeblink.class);
    DynamicSet.bind(binder(), ProjectWebLink.class).to(HelloWeblink.class);
    DynamicSet.bind(binder(), BranchWebLink.class).to(HelloWeblink.class);
    DynamicSet.bind(binder(), FileHistoryWebLink.class).to(HelloWeblink.class);
    DynamicSet.bind(binder(), ServerPluginProvider.class).to(HelloSshPluginProvider.class);
    DynamicSet.bind(binder(), UsageDataPublishedListener.class).to(UsageDataLogger.class);
    DynamicSet.bind(binder(), LifecycleListener.class).to(ConsoleMetricReporter.class);
    install(new RestApiModule() {

        @Override
        protected void configure() {
            post(REVISION_KIND, "hello-revision").to(HelloRevisionAction.class);
            post(PROJECT_KIND, "hello-project").to(HelloProjectAction.class);
            get(REVISION_KIND, "greetings").to(Greetings.class);
        }
    });
    DynamicSet.bind(binder(), UploadValidationListener.class).to(DenyUploadExample.class);
    DynamicSet.bind(binder(), MergeValidationListener.class).to(MergeUserValidator.class);
    DynamicSet.bind(binder(), HashtagValidationListener.class).to(HashtagValidator.class);
    DynamicSet.bind(binder(), CommitValidationListener.class).to(CommitValidator.class);
    DynamicSet.bind(binder(), NewProjectCreatedListener.class).to(ProjectCreatedListener.class);
    DynamicSet.bind(binder(), RefOperationValidationListener.class).to(RefOperationValidationExample.class);
    configurePluginParameters();
    DynamicSet.bind(binder(), ExternalIncludedIn.class).to(DeployedOnIncludedInExtension.class);
    bind(ChangeOperatorFactory.class).annotatedWith(Exports.named("sample")).to(SampleOperator.class);
    DynamicSet.bind(binder(), WebUiPlugin.class).toInstance(new JavaScriptPlugin("greetings.js"));
    DynamicSet.bind(binder(), WebUiPlugin.class).toInstance(new JavaScriptPlugin("hello-change.js"));
    DynamicSet.bind(binder(), WebUiPlugin.class).toInstance(new JavaScriptPlugin("hello-project.js"));
    DynamicSet.bind(binder(), WebUiPlugin.class).toInstance(new JavaScriptPlugin("hello-revision.js"));
    DynamicSet.bind(binder(), WebUiPlugin.class).toInstance(new GwtPlugin("cookbook"));
}
#end_block

#method_before
private void configurePluginParameters() {
    bind(ProjectConfigEntry.class).annotatedWith(Exports.named("enable-hello")).toInstance(new ProjectConfigEntry("Enable Greeting", true));
    bind(ProjectConfigEntry.class).annotatedWith(Exports.named("enable-goodbye")).toInstance(new ProjectConfigEntry("Enable Say Goodbye", InheritableBoolean.TRUE, InheritableBoolean.class, true));
    bind(ProjectConfigEntry.class).annotatedWith(Exports.named("default-greeting")).toInstance(new ProjectConfigEntry("Default Greeting", "Hey dude, how are you?", true));
    bind(ProjectConfigEntry.class).annotatedWith(Exports.named("language")).toInstance(new ProjectConfigEntry("Preferred Language", "en", ImmutableList.of("en", "de", "fr"), true));
    bind(ProjectConfigEntry.class).annotatedWith(Exports.named("greet-number-per-week")).toInstance(new ProjectConfigEntry("Greets Per Week", 42, true));
    bind(ProjectConfigEntry.class).annotatedWith(Exports.named("greet-number-per-year")).toInstance(new ProjectConfigEntry("Greets Per Year", 4711L, true));
    bind(ProjectConfigEntry.class).annotatedWith(Exports.named("reviewers")).toInstance(new ProjectConfigEntry("Reviewers", null, ProjectConfigEntry.Type.ARRAY, null, false, "Users or groups can be provided as reviewers"));
}
#method_after
private void configurePluginParameters() {
    bind(ProjectConfigEntry.class).annotatedWith(Exports.named("enable-hello")).toInstance(new ProjectConfigEntry("Enable Greeting", true));
    bind(ProjectConfigEntry.class).annotatedWith(Exports.named("enable-goodbye")).toInstance(new ProjectConfigEntry("Enable Say Goodbye", InheritableBoolean.TRUE, InheritableBoolean.class, true));
    bind(ProjectConfigEntry.class).annotatedWith(Exports.named("default-greeting")).toInstance(new ProjectConfigEntry("Default Greeting", "Hey dude, how are you?", true));
    bind(ProjectConfigEntry.class).annotatedWith(Exports.named("language")).toInstance(new ProjectConfigEntry("Preferred Language", "en", ImmutableList.of("en", "de", "fr"), true));
    bind(ProjectConfigEntry.class).annotatedWith(Exports.named("greet-number-per-week")).toInstance(new ProjectConfigEntry("Greets Per Week", 42, true));
    bind(ProjectConfigEntry.class).annotatedWith(Exports.named("greet-number-per-year")).toInstance(new ProjectConfigEntry("Greets Per Year", 4711L, true));
    bind(ProjectConfigEntry.class).annotatedWith(Exports.named("reviewers")).toInstance(new ProjectConfigEntry("Reviewers", null, ProjectConfigEntryType.ARRAY, null, false, "Users or groups can be provided as reviewers"));
}
#end_block

#method_before
private void setUserIdentified(final Account.Id id) {
    WebSession ws = session.get();
    ws.setUserAccountId(id);
    ws.setAccessPathOk(AccessPath.GIT, true);
    ws.setAccessPathOk(AccessPath.REST_API, true);
}
#method_after
private void setUserIdentified(Account.Id id) {
    WebSession ws = session.get();
    ws.setUserAccountId(id);
    ws.setAccessPathOk(AccessPath.GIT, true);
    ws.setAccessPathOk(AccessPath.REST_API, true);
}
#end_block

#method_before
ServiceUserInfo getAsServiceUser(PersonIdent committerIdent) throws OrmException {
    StringBuilder committer = new StringBuilder();
    committer.append(committerIdent.getName());
    committer.append(" <");
    committer.append(committerIdent.getEmailAddress());
    committer.append("> ");
    try (final ReviewDb db = schema.open()) {
        Account account = resolver.find(db, committer.toString());
        if (account == null) {
            return null;
        }
        try {
            return getServiceUser.get().apply(new ServiceUserResource(genericUserFactory.create(account.getId())));
        } catch (ResourceNotFoundException e) {
            return null;
        }
    }
}
#method_after
ServiceUserInfo getAsServiceUser(PersonIdent committerIdent) throws OrmException {
    StringBuilder committer = new StringBuilder();
    committer.append(committerIdent.getName());
    committer.append(" <");
    committer.append(committerIdent.getEmailAddress());
    committer.append("> ");
    try (ReviewDb db = schema.open()) {
        Account account = resolver.find(db, committer.toString());
        if (account == null) {
            return null;
        }
        try {
            return getServiceUser.get().apply(new ServiceUserResource(genericUserFactory.create(account.getId())));
        } catch (ResourceNotFoundException e) {
            return null;
        }
    }
}
#end_block

#method_before
@Test
public void basicTextFormattingWorks() throws IOException {
    String raw = "*italic* **bold** `monospace`";
    String formatted = PROLOG + "<em>italic</em> <strong>bold</strong> <code>monospace</code>" + EPILOG;
    assertEquals(formatter.format("MarkdownFormatterTest", null, null, null, cfg, raw), formatted);
}
#method_after
@Test
public void basicTextFormattingWorks() throws IOException {
    String raw = "*italic* **bold** `monospace`";
    String formatted = PROLOG + "<em>italic</em> <strong>bold</strong> <code>monospace</code>" + EPILOG;
    assertEquals(formatter.format(null, null, null, null, cfg, raw), formatted);
}
#end_block

#method_before
private void validateReviewer(String reviewer) throws RestApiException {
    try (ReviewDb reviewDb = schemaFactory.open()) {
        Account account = accountResolver.find(reviewDb, reviewer);
        if (account == null) {
            try {
                groupsCollection.get().parse(reviewer);
            } catch (UnprocessableEntityException e) {
                throw new ResourceNotFoundException("Account or group " + reviewer + " not found");
            }
        }
    } catch (OrmException e) {
        log.error("Failed to resolve account " + reviewer);
    }
}
#method_after
private void validateReviewer(String reviewer) throws RestApiException {
    try {
        Account account = accountResolver.find(reviewDbProvider.get(), reviewer);
        if (account == null) {
            try {
                groupsCollection.get().parse(reviewer);
            } catch (UnprocessableEntityException e) {
                throw new ResourceNotFoundException("Account or group " + reviewer + " not found");
            }
        }
    } catch (OrmException e) {
        log.error("Failed to resolve account " + reviewer);
    }
}
#end_block

#method_before
@Override
public GroupInfo apply(TopLevelResource resource, GroupInput input) throws BadRequestException, UnprocessableEntityException, ResourceConflictException, OrmException, IOException {
    return create(input, Collections.singleton(self.get().getAccountId()));
}
#method_after
@Override
public GroupInfo apply(TopLevelResource resource, GroupInput input) throws AuthException, BadRequestException, UnprocessableEntityException, ResourceConflictException, OrmException, IOException {
    if (input == null) {
        input = new GroupInput();
    }
    if (input.name != null && !name.equals(input.name)) {
        throw new BadRequestException("name must match URL");
    }
    AccountGroup.Id ownerId = owner(input);
    CreateGroupArgs args = new CreateGroupArgs();
    args.setGroupName(name);
    args.groupDescription = Strings.emptyToNull(input.description);
    args.visibleToAll = MoreObjects.firstNonNull(input.visibleToAll, defaultVisibleToAll);
    args.ownerGroupId = ownerId;
    if (input.members != null && !input.members.isEmpty()) {
        List<Account.Id> members = new ArrayList<>();
        for (String nameOrEmailOrId : input.members) {
            Account a = addMembers.findAccount(nameOrEmailOrId);
            if (!a.isActive()) {
                throw new UnprocessableEntityException(String.format("Account Inactive: %s", nameOrEmailOrId));
            }
            members.add(a.getId());
        }
        args.initialMembers = members;
    } else {
        args.initialMembers = ownerId == null ? Collections.singleton(self.get().getAccountId()) : Collections.<Account.Id>emptySet();
    }
    for (GroupCreationValidationListener l : groupCreationValidationListeners) {
        try {
            l.validateNewGroup(args);
        } catch (ValidationException e) {
            throw new ResourceConflictException(e.getMessage(), e);
        }
    }
    return json.format(GroupDescriptions.forAccountGroup(createGroup(args)));
}
#end_block

#method_before
@Provides
@Singleton
@Named(POLYGERRIT_INDEX_SERVLET)
HttpServlet getPolyGerritUiIndexServlet(@Named(CACHE) Cache<Path, Resource> cache) {
    return new SingleFileServlet(cache, polyGerritBasePath().resolve("index.html"), true, true);
}
#method_after
@Provides
@Singleton
@Named(POLYGERRIT_INDEX_SERVLET)
HttpServlet getPolyGerritUiIndexServlet(@Named(CACHE) Cache<Path, Resource> cache) {
    return new SingleFileServlet(cache, polyGerritBasePath().resolve("index.html"), getPaths().isDev(), false);
}
#end_block

#method_before
@Override
protected void doGet(HttpServletRequest req, HttpServletResponse rsp) throws IOException {
    String name;
    if (req.getPathInfo() == null) {
        name = "/";
    } else {
        name = CharMatcher.is('/').trimFrom(req.getPathInfo());
    }
    if (isUnreasonableName(name)) {
        notFound(rsp);
        return;
    }
    Path p = getResourcePath(name);
    if (p == null) {
        notFound(rsp);
        return;
    }
    Resource r = cache.getIfPresent(p);
    try {
        if (r == null) {
            if (maybeStream(p, req, rsp)) {
                // Bypass cache for large resource.
                return;
            }
            r = cache.get(p, newLoader(p));
        }
        if (noClientCache) {
            CacheHeaders.setNotCacheable(rsp);
        }
        if (refresh && r.isStale(p, this)) {
            cache.invalidate(p);
            r = cache.get(p, newLoader(p));
        }
    } catch (ExecutionException e) {
        log.warn("Cannot load static resource " + req.getPathInfo(), e);
        CacheHeaders.setNotCacheable(rsp);
        rsp.setStatus(SC_INTERNAL_SERVER_ERROR);
        return;
    }
    if (r == Resource.NOT_FOUND) {
        // Cached not found response.
        notFound(rsp);
        return;
    }
    String e = req.getParameter("e");
    if (e != null && !r.etag.equals(e)) {
        CacheHeaders.setNotCacheable(rsp);
        rsp.setStatus(SC_NOT_FOUND);
        return;
    } else if (r.etag.equals(req.getHeader(IF_NONE_MATCH))) {
        rsp.setStatus(SC_NOT_MODIFIED);
        return;
    }
    byte[] tosend = r.raw;
    if (!r.contentType.equals(JS) && RPCServletUtils.acceptsGzipEncoding(req)) {
        byte[] gz = HtmlDomUtil.compress(tosend);
        if ((gz.length + 24) < tosend.length) {
            rsp.setHeader(CONTENT_ENCODING, "gzip");
            tosend = gz;
        }
    }
    if (!CacheHeaders.hasCacheHeader(rsp)) {
        if (e != null && r.etag.equals(e)) {
            CacheHeaders.setCacheable(req, rsp, 360, DAYS, false);
        } else {
            CacheHeaders.setCacheable(req, rsp, 15, MINUTES, refresh);
        }
    }
    if (!noClientCache) {
        rsp.setHeader(ETAG, r.etag);
    }
    rsp.setContentType(r.contentType);
    rsp.setContentLength(tosend.length);
    try (OutputStream out = rsp.getOutputStream()) {
        out.write(tosend);
    }
}
#method_after
@Override
protected void doGet(HttpServletRequest req, HttpServletResponse rsp) throws IOException {
    String name;
    if (req.getPathInfo() == null) {
        name = "/";
    } else {
        name = CharMatcher.is('/').trimFrom(req.getPathInfo());
    }
    if (isUnreasonableName(name)) {
        notFound(rsp);
        return;
    }
    Path p = getResourcePath(name);
    if (p == null) {
        notFound(rsp);
        return;
    }
    Resource r = cache.getIfPresent(p);
    try {
        if (r == null) {
            if (maybeStream(p, req, rsp)) {
                // Bypass cache for large resource.
                return;
            }
            r = cache.get(p, newLoader(p));
        }
        if (refresh && r.isStale(p, this)) {
            cache.invalidate(p);
            r = cache.get(p, newLoader(p));
        }
    } catch (ExecutionException e) {
        log.warn("Cannot load static resource " + req.getPathInfo(), e);
        CacheHeaders.setNotCacheable(rsp);
        rsp.setStatus(SC_INTERNAL_SERVER_ERROR);
        return;
    }
    if (r == Resource.NOT_FOUND) {
        // Cached not found response.
        notFound(rsp);
        return;
    }
    String e = req.getParameter("e");
    if (e != null && !r.etag.equals(e)) {
        CacheHeaders.setNotCacheable(rsp);
        rsp.setStatus(SC_NOT_FOUND);
        return;
    } else if (cacheOnClient && r.etag.equals(req.getHeader(IF_NONE_MATCH))) {
        rsp.setStatus(SC_NOT_MODIFIED);
        return;
    }
    byte[] tosend = r.raw;
    if (!r.contentType.equals(JS) && RPCServletUtils.acceptsGzipEncoding(req)) {
        byte[] gz = HtmlDomUtil.compress(tosend);
        if ((gz.length + 24) < tosend.length) {
            rsp.setHeader(CONTENT_ENCODING, "gzip");
            tosend = gz;
        }
    }
    if (cacheOnClient) {
        rsp.setHeader(ETAG, r.etag);
    } else {
        CacheHeaders.setNotCacheable(rsp);
    }
    if (!CacheHeaders.hasCacheHeader(rsp)) {
        if (e != null && r.etag.equals(e)) {
            CacheHeaders.setCacheable(req, rsp, 360, DAYS, false);
        } else {
            CacheHeaders.setCacheable(req, rsp, 15, MINUTES, refresh);
        }
    }
    rsp.setContentType(r.contentType);
    rsp.setContentLength(tosend.length);
    try (OutputStream out = rsp.getOutputStream()) {
        out.write(tosend);
    }
}
#end_block

#method_before
@Test
public void checkAlreadyMergedCommit() throws Exception {
    ObjectId c0 = testRepo.branch("HEAD").commit().insertChangeId().message("first commit").add("a.txt", "a contents ").create();
    testRepo.git().push().setRemote("origin").setRefSpecs(new RefSpec("HEAD:refs/heads/master")).call();
    testRepo.branch("HEAD").commit().insertChangeId().message("second commit").add("b.txt", "b contents ").create();
    testRepo.git().push().setRemote("origin").setRefSpecs(new RefSpec("HEAD:refs/heads/master")).call();
    assertAlreadyMerged("master", c0.getName(), "");
}
#method_after
@Test
public void checkAlreadyMergedCommit() throws Exception {
    ObjectId c0 = testRepo.branch("HEAD").commit().insertChangeId().message("first commit").add("a.txt", "a contents ").create();
    testRepo.git().push().setRemote("origin").setRefSpecs(new RefSpec("HEAD:refs/heads/master")).call();
    testRepo.branch("HEAD").commit().insertChangeId().message("second commit").add("b.txt", "b contents ").create();
    testRepo.git().push().setRemote("origin").setRefSpecs(new RefSpec("HEAD:refs/heads/master")).call();
    assertCommitMerged("master", c0.getName(), "");
}
#end_block

#method_before
@Test
@TestProjectInput(submitType = SubmitType.CHERRY_PICK)
public void checkContentMergedCommit() throws Exception {
    testRepo.branch("HEAD").commit().insertChangeId().message("first commit").add("a.txt", "a contents ").create();
    testRepo.git().push().setRemote("origin").setRefSpecs(new RefSpec("HEAD:refs/heads/master")).call();
    // create a change, and cherrypick into master
    PushOneCommit.Result cId = createChange();
    approve(cId.getChangeId());
    RevCommit commitId = cId.getCommit();
    gApi.changes().id(cId.getChangeId()).current().submit();
    ObjectId remoteId = getRemoteHead();
    assertThat(remoteId).isNotEqualTo(commitId);
    assertMergeable("master", commitId.getName(), "recursive");
}
#method_after
@Test
public void checkContentMergedCommit() throws Exception {
    testRepo.branch("HEAD").commit().insertChangeId().message("first commit").add("a.txt", "a contents ").create();
    testRepo.git().push().setRemote("origin").setRefSpecs(new RefSpec("HEAD:refs/heads/master")).call();
    // create a change, and cherrypick into master
    PushOneCommit.Result cId = createChange();
    RevCommit commitId = cId.getCommit();
    CherryPickInput cpi = new CherryPickInput();
    cpi.destination = "master";
    cpi.message = "cherry pick the commit";
    ChangeApi orig = gApi.changes().id(cId.getChangeId());
    ChangeApi cherry = orig.current().cherryPick(cpi);
    cherry.current().review(ReviewInput.approve());
    cherry.current().submit();
    ObjectId remoteId = getRemoteHead();
    assertThat(remoteId).isNotEqualTo(commitId);
    assertContentMerged("master", commitId.getName(), "recursive");
}
#end_block

#method_before
@Test
public void checkInvalidSource() throws Exception {
    testRepo.branch("HEAD").commit().insertChangeId().message("first commit").add("a.txt", "a contents ").create();
    testRepo.git().push().setRemote("origin").setRefSpecs(new RefSpec("HEAD:refs/heads/master")).call();
    assertBadRequest("master", "fdsafsdf", "recursive", "Cannot resolve 'fdsafsdf' into a commit");
}
#method_after
@Test
public void checkInvalidSource() throws Exception {
    testRepo.branch("HEAD").commit().insertChangeId().message("first commit").add("a.txt", "a contents ").create();
    testRepo.git().push().setRemote("origin").setRefSpecs(new RefSpec("HEAD:refs/heads/master")).call();
    assertBadRequest("master", "fdsafsdf", "recursive", "Cannot resolve 'fdsafsdf' to a commit");
}
#end_block

#method_before
private void assertUnMergeable(String targetBranch, String source, String strategy, String... conflicts) throws Exception {
    MergeableInfo mergeableInfo = getMergeableInfo(targetBranch, source, strategy);
    assertThat(mergeableInfo.mergeable).isFalse();
    assertThat(mergeableInfo.conflicts).containsExactly(conflicts);
}
#method_after
private void assertUnMergeable(String targetBranch, String source, String strategy, String... conflicts) throws Exception {
    MergeableInfo mergeableInfo = getMergeableInfo(targetBranch, source, strategy);
    assertThat(mergeableInfo.mergeable).isFalse();
    assertThat(mergeableInfo.conflicts).containsExactly((Object[]) conflicts);
}
#end_block

#method_before
public static RevCommit createMergeCommit(Repository repo, ObjectInserter inserter, RevCommit mergeTip, RevCommit originalCommit, String mergeStrategy, PersonIdent committerIndent, String commitMsg, RevWalk rw) throws IOException, MergeIdenticalTreeException, MergeConflictException {
    if (rw.isMergedInto(originalCommit, mergeTip)) {
        throw new ChangeAlreadyMergedException("'" + originalCommit.getName() + "' has already been merged!");
    }
    Merger m = newMerger(repo, inserter, mergeStrategy);
    if (m.merge(false, mergeTip, originalCommit)) {
        ObjectId tree = m.getResultTreeId();
        CommitBuilder mergeCommit = new CommitBuilder();
        mergeCommit.setTreeId(tree);
        mergeCommit.setParentIds(mergeTip, originalCommit);
        mergeCommit.setAuthor(committerIndent);
        mergeCommit.setCommitter(committerIndent);
        mergeCommit.setMessage(commitMsg);
        return rw.parseCommit(inserter.insert(mergeCommit));
    }
    List<String> conflicts = ImmutableList.of();
    if (m instanceof ResolveMerger) {
        conflicts = ((ResolveMerger) m).getUnmergedPaths();
    }
    throw new MergeConflictException(createConflictMessage(conflicts));
}
#method_after
public static RevCommit createMergeCommit(Repository repo, ObjectInserter inserter, RevCommit mergeTip, RevCommit originalCommit, String mergeStrategy, PersonIdent committerIndent, String commitMsg, RevWalk rw) throws IOException, MergeIdenticalTreeException, MergeConflictException {
    if (rw.isMergedInto(originalCommit, mergeTip)) {
        throw new ChangeAlreadyMergedException("'" + originalCommit.getName() + "' has already been merged");
    }
    Merger m = newMerger(repo, inserter, mergeStrategy);
    if (m.merge(false, mergeTip, originalCommit)) {
        ObjectId tree = m.getResultTreeId();
        CommitBuilder mergeCommit = new CommitBuilder();
        mergeCommit.setTreeId(tree);
        mergeCommit.setParentIds(mergeTip, originalCommit);
        mergeCommit.setAuthor(committerIndent);
        mergeCommit.setCommitter(committerIndent);
        mergeCommit.setMessage(commitMsg);
        return rw.parseCommit(inserter.insert(mergeCommit));
    }
    List<String> conflicts = ImmutableList.of();
    if (m instanceof ResolveMerger) {
        conflicts = ((ResolveMerger) m).getUnmergedPaths();
    }
    throw new MergeConflictException(createConflictMessage(conflicts));
}
#end_block

#method_before
public static RevCommit resolveCommit(Repository repo, RevWalk rw, String str) throws BadRequestException, ResourceNotFoundException, IOException {
    try {
        ObjectId commitId = repo.resolve(str);
        if (commitId == null) {
            throw new BadRequestException("Cannot resolve '" + str + "' into a commit");
        }
        return rw.parseCommit(commitId);
    } catch (AmbiguousObjectException | IncorrectObjectTypeException | RevisionSyntaxException e) {
        throw new BadRequestException(e.getMessage());
    } catch (MissingObjectException e) {
        throw new ResourceNotFoundException(e.getMessage());
    }
}
#method_after
public static RevCommit resolveCommit(Repository repo, RevWalk rw, String str) throws BadRequestException, ResourceNotFoundException, IOException {
    try {
        ObjectId commitId = repo.resolve(str);
        if (commitId == null) {
            throw new BadRequestException("Cannot resolve '" + str + "' to a commit");
        }
        return rw.parseCommit(commitId);
    } catch (AmbiguousObjectException | IncorrectObjectTypeException | RevisionSyntaxException e) {
        throw new BadRequestException(e.getMessage());
    } catch (MissingObjectException e) {
        throw new ResourceNotFoundException(e.getMessage());
    }
}
#end_block

#method_before
@Test
public void invalidSource() throws Exception {
    changeInTwoBranches("branchA", "a.txt", "branchB", "b.txt");
    ChangeInput in = newMergeChangeInput("branchA", "invalid", "");
    assertCreateFails(in, BadRequestException.class, "Cannot resolve 'invalid' into a commit");
}
#method_after
@Test
public void invalidSource() throws Exception {
    changeInTwoBranches("branchA", "a.txt", "branchB", "b.txt");
    ChangeInput in = newMergeChangeInput("branchA", "invalid", "");
    assertCreateFails(in, BadRequestException.class, "Cannot resolve 'invalid' to a commit");
}
#end_block

#method_before
@Test
public void alreadyMerged() throws Exception {
    ObjectId c0 = testRepo.branch("HEAD").commit().insertChangeId().message("first commit").add("a.txt", "a contents ").create();
    testRepo.git().push().setRemote("origin").setRefSpecs(new RefSpec("HEAD:refs/heads/master")).call();
    testRepo.branch("HEAD").commit().insertChangeId().message("second commit").add("b.txt", "b contents ").create();
    testRepo.git().push().setRemote("origin").setRefSpecs(new RefSpec("HEAD:refs/heads/master")).call();
    ChangeInput in = newMergeChangeInput("master", c0.getName(), "");
    assertCreateFails(in, BadRequestException.class, "'" + c0.getName() + "' has already been merged!");
}
#method_after
@Test
public void alreadyMerged() throws Exception {
    ObjectId c0 = testRepo.branch("HEAD").commit().insertChangeId().message("first commit").add("a.txt", "a contents ").create();
    testRepo.git().push().setRemote("origin").setRefSpecs(new RefSpec("HEAD:refs/heads/master")).call();
    testRepo.branch("HEAD").commit().insertChangeId().message("second commit").add("b.txt", "b contents ").create();
    testRepo.git().push().setRemote("origin").setRefSpecs(new RefSpec("HEAD:refs/heads/master")).call();
    ChangeInput in = newMergeChangeInput("master", c0.getName(), "");
    assertCreateFails(in, ChangeAlreadyMergedException.class, "'" + c0.getName() + "' has already been merged");
}
#end_block

#method_before
@Test
@TestProjectInput(submitType = SubmitType.CHERRY_PICK)
public void onlyContentMerged() throws Exception {
    testRepo.branch("HEAD").commit().insertChangeId().message("first commit").add("a.txt", "a contents ").create();
    testRepo.git().push().setRemote("origin").setRefSpecs(new RefSpec("HEAD:refs/heads/master")).call();
    // create a change, and cherrypick into master
    PushOneCommit.Result cId = createChange();
    approve(cId.getChangeId());
    RevCommit commitId = cId.getCommit();
    gApi.changes().id(cId.getChangeId()).current().submit();
    ObjectId remoteId = getRemoteHead();
    assertThat(remoteId).isNotEqualTo(commitId);
    ChangeInput in = newMergeChangeInput("master", commitId.getName(), "");
    assertCreateSucceeds(in);
}
#method_after
@Test
public void onlyContentMerged() throws Exception {
    testRepo.branch("HEAD").commit().insertChangeId().message("first commit").add("a.txt", "a contents ").create();
    testRepo.git().push().setRemote("origin").setRefSpecs(new RefSpec("HEAD:refs/heads/master")).call();
    // create a change, and cherrypick into master
    PushOneCommit.Result cId = createChange();
    RevCommit commitId = cId.getCommit();
    CherryPickInput cpi = new CherryPickInput();
    cpi.destination = "master";
    cpi.message = "cherry pick the commit";
    ChangeApi orig = gApi.changes().id(cId.getChangeId());
    ChangeApi cherry = orig.current().cherryPick(cpi);
    cherry.current().review(ReviewInput.approve());
    cherry.current().submit();
    ObjectId remoteId = getRemoteHead();
    assertThat(remoteId).isNotEqualTo(commitId);
    ChangeInput in = newMergeChangeInput("master", commitId.getName(), "");
    assertCreateSucceeds(in);
}
#end_block

#method_before
private void changeInTwoBranches(String branchA, String fileA, String branchB, String fileB) throws Exception {
    // create a initial commit in master
    Result initialCommit = pushFactory.create(db, user.getIdent(), testRepo, "initial commit", "readme.txt", "initial commit").to("refs/heads/master");
    initialCommit.assertOkStatus();
    // create a new branch branchA
    createBranch(new Branch.NameKey(project, branchA));
    createBranch(new Branch.NameKey(project, branchB));
    // create a commit in branchA
    Result changeA = pushFactory.create(db, user.getIdent(), testRepo, "change A", fileA, "A content").to("refs/heads/" + branchA);
    changeA.assertOkStatus();
    // create a commit in branchB
    PushOneCommit commitB = pushFactory.create(db, user.getIdent(), testRepo, "change B", fileB, "B content");
    commitB.setParent(initialCommit.getCommit());
    Result changeB = commitB.to("refs/heads/" + branchB);
    changeB.assertOkStatus();
}
#method_after
private void changeInTwoBranches(String branchA, String fileA, String branchB, String fileB) throws Exception {
    // create a initial commit in master
    Result initialCommit = pushFactory.create(db, user.getIdent(), testRepo, "initial commit", "readme.txt", "initial commit").to("refs/heads/master");
    initialCommit.assertOkStatus();
    // create two new branches
    createBranch(new Branch.NameKey(project, branchA));
    createBranch(new Branch.NameKey(project, branchB));
    // create a commit in branchA
    Result changeA = pushFactory.create(db, user.getIdent(), testRepo, "change A", fileA, "A content").to("refs/heads/" + branchA);
    changeA.assertOkStatus();
    // create a commit in branchB
    PushOneCommit commitB = pushFactory.create(db, user.getIdent(), testRepo, "change B", fileB, "B content");
    commitB.setParent(initialCommit.getCommit());
    Result changeB = commitB.to("refs/heads/" + branchB);
    changeB.assertOkStatus();
}
#end_block

#method_before
@Override
public MergeableInfo apply(BranchResource resource) throws IOException, BadRequestException, ResourceNotFoundException {
    MergeableInfo result = new MergeableInfo();
    result.strategy = strategy;
    try (Repository git = gitManager.openRepository(resource.getNameKey());
        RevWalk rw = new RevWalk(git);
        ObjectInserter inserter = new InMemoryInserter(git)) {
        Merger m = MergeUtil.newMerger(git, inserter, strategy);
        Ref destRef = git.getRefDatabase().exactRef(resource.getRef());
        if (destRef == null) {
            throw new ResourceNotFoundException(resource.getRef());
        }
        RevCommit targetCommit = rw.parseCommit(destRef.getObjectId());
        RevCommit sourceCommit = MergeUtil.resolveCommit(git, rw, source);
        if (!resource.getControl().canReadCommit(db.get(), git, sourceCommit)) {
            throw new BadRequestException("Do not have read permission for: " + source);
        }
        if (rw.isMergedInto(sourceCommit, targetCommit)) {
            throw new ChangeAlreadyMergedException("'" + source + "' has already been merged!");
        }
        result.mergeable = m.merge(false, targetCommit, sourceCommit);
        if (m instanceof ResolveMerger) {
            result.conflicts = ((ResolveMerger) m).getUnmergedPaths();
        }
    } catch (IllegalArgumentException e) {
        throw new BadRequestException(e.getMessage());
    }
    return result;
}
#method_after
@Override
public MergeableInfo apply(BranchResource resource) throws IOException, BadRequestException, ResourceNotFoundException {
    if (!(submitType.equals(SubmitType.MERGE_ALWAYS) || submitType.equals(SubmitType.MERGE_IF_NECESSARY))) {
        throw new BadRequestException("Submit type: " + submitType + " is not supported");
    }
    MergeableInfo result = new MergeableInfo();
    result.submitType = submitType;
    result.strategy = strategy;
    try (Repository git = gitManager.openRepository(resource.getNameKey());
        RevWalk rw = new RevWalk(git);
        ObjectInserter inserter = new InMemoryInserter(git)) {
        Merger m = MergeUtil.newMerger(git, inserter, strategy);
        Ref destRef = git.getRefDatabase().exactRef(resource.getRef());
        if (destRef == null) {
            throw new ResourceNotFoundException(resource.getRef());
        }
        RevCommit targetCommit = rw.parseCommit(destRef.getObjectId());
        RevCommit sourceCommit = MergeUtil.resolveCommit(git, rw, source);
        if (!resource.getControl().canReadCommit(db.get(), git, sourceCommit)) {
            throw new BadRequestException("do not have read permission for: " + source);
        }
        if (rw.isMergedInto(sourceCommit, targetCommit)) {
            result.mergeable = true;
            result.commitMerged = true;
            result.contentMerged = true;
            return result;
        }
        if (m.merge(false, targetCommit, sourceCommit)) {
            result.mergeable = true;
            result.commitMerged = false;
            result.contentMerged = m.getResultTreeId().equals(targetCommit.getTree());
        } else {
            result.mergeable = false;
            if (m instanceof ResolveMerger) {
                result.conflicts = ((ResolveMerger) m).getUnmergedPaths();
            }
        }
    } catch (IllegalArgumentException e) {
        throw new BadRequestException(e.getMessage());
    }
    return result;
}
#end_block

#method_before
@Override
public Response<ChangeInfo> apply(TopLevelResource parent, ChangeInput input) throws OrmException, IOException, InvalidChangeOperationException, RestApiException, UpdateException {
    if (Strings.isNullOrEmpty(input.project)) {
        throw new BadRequestException("project must be non-empty");
    }
    if (Strings.isNullOrEmpty(input.branch)) {
        throw new BadRequestException("branch must be non-empty");
    }
    if (Strings.isNullOrEmpty(input.subject)) {
        throw new BadRequestException("commit message must be non-empty");
    }
    if (input.status != null) {
        if (input.status != ChangeStatus.NEW && input.status != ChangeStatus.DRAFT) {
            throw new BadRequestException("unsupported change status");
        }
        if (!allowDrafts && input.status == ChangeStatus.DRAFT) {
            throw new MethodNotAllowedException("draft workflow is disabled");
        }
    }
    String refName = RefNames.fullName(input.branch);
    ProjectResource rsrc = projectsCollection.parse(input.project);
    Capable r = rsrc.getControl().canPushToAtLeastOneRef();
    if (r != Capable.OK) {
        throw new AuthException(r.getMessage());
    }
    RefControl refControl = rsrc.getControl().controlForRef(refName);
    if (!refControl.canUpload() || !refControl.canRead()) {
        throw new AuthException("cannot upload review");
    }
    Project.NameKey project = rsrc.getNameKey();
    try (Repository git = gitManager.openRepository(project);
        ObjectInserter oi = git.newObjectInserter();
        RevWalk rw = new RevWalk(oi.newReader())) {
        ObjectId parentCommit;
        List<String> groups;
        if (input.baseChange != null) {
            List<ChangeControl> ctls = changeFinder.find(input.baseChange, rsrc.getControl().getUser());
            if (ctls.size() != 1) {
                throw new InvalidChangeOperationException("Base change not found: " + input.baseChange);
            }
            ChangeControl ctl = Iterables.getOnlyElement(ctls);
            if (!ctl.isVisible(db.get())) {
                throw new InvalidChangeOperationException("Base change not found: " + input.baseChange);
            }
            PatchSet ps = psUtil.current(db.get(), ctl.getNotes());
            parentCommit = ObjectId.fromString(ps.getRevision().get());
            groups = ps.getGroups();
        } else {
            Ref destRef = git.getRefDatabase().exactRef(refName);
            if (destRef != null) {
                if (Boolean.TRUE.equals(input.newBranch)) {
                    throw new ResourceConflictException(String.format("Branch %s already exists.", refName));
                }
                parentCommit = destRef.getObjectId();
            } else {
                if (Boolean.TRUE.equals(input.newBranch)) {
                    parentCommit = null;
                } else {
                    throw new UnprocessableEntityException(String.format("Branch %s does not exist.", refName));
                }
            }
            groups = Collections.emptyList();
        }
        RevCommit mergeTip = parentCommit == null ? null : rw.parseCommit(parentCommit);
        Timestamp now = TimeUtil.nowTs();
        IdentifiedUser me = user.get().asIdentifiedUser();
        PersonIdent author = me.newCommitterIdent(now, serverTimeZone);
        AccountState account = accountCache.get(me.getAccountId());
        GeneralPreferencesInfo info = account.getAccount().getGeneralPreferencesInfo();
        ObjectId treeId = mergeTip == null ? emptyTreeId(oi) : mergeTip.getTree();
        ObjectId id = ChangeIdUtil.computeChangeId(treeId, mergeTip, author, author, input.subject);
        String commitMessage = ChangeIdUtil.insertId(input.subject, id);
        if (Boolean.TRUE.equals(info.signedOffBy)) {
            commitMessage += String.format("%s%s", SIGNED_OFF_BY_TAG, account.getAccount().getNameEmail(anonymousCowardName));
        }
        RevCommit c;
        if (input.merge != null) {
            // create a merge commit
            c = newMergeCommit(git, oi, rw, rsrc.getControl(), mergeTip, input.merge, author, commitMessage);
        } else {
            // create an empty commit
            c = newCommit(oi, rw, author, mergeTip, commitMessage);
        }
        Change.Id changeId = new Change.Id(seq.nextChangeId());
        ChangeInserter ins = changeInserterFactory.create(changeId, c, refName).setValidatePolicy(CommitValidators.Policy.GERRIT);
        ins.setMessage(String.format("Uploaded patch set %s.", ins.getPatchSetId().get()));
        String topic = input.topic;
        if (topic != null) {
            topic = Strings.emptyToNull(topic.trim());
        }
        ins.setTopic(topic);
        ins.setDraft(input.status == ChangeStatus.DRAFT);
        ins.setGroups(groups);
        try (BatchUpdate bu = updateFactory.create(db.get(), project, me, now)) {
            bu.setRepository(git, rw, oi);
            bu.insertChange(ins);
            bu.execute();
        }
        ChangeJson json = jsonFactory.create(ChangeJson.NO_OPTIONS);
        return Response.created(json.format(ins.getChange()));
    } catch (IllegalArgumentException e) {
        throw new BadRequestException(e.getMessage());
    }
}
#method_after
@Override
public Response<ChangeInfo> apply(TopLevelResource parent, ChangeInput input) throws OrmException, IOException, InvalidChangeOperationException, RestApiException, UpdateException {
    if (Strings.isNullOrEmpty(input.project)) {
        throw new BadRequestException("project must be non-empty");
    }
    if (Strings.isNullOrEmpty(input.branch)) {
        throw new BadRequestException("branch must be non-empty");
    }
    if (Strings.isNullOrEmpty(input.subject)) {
        throw new BadRequestException("commit message must be non-empty");
    }
    if (input.status != null) {
        if (input.status != ChangeStatus.NEW && input.status != ChangeStatus.DRAFT) {
            throw new BadRequestException("unsupported change status");
        }
        if (!allowDrafts && input.status == ChangeStatus.DRAFT) {
            throw new MethodNotAllowedException("draft workflow is disabled");
        }
    }
    String refName = RefNames.fullName(input.branch);
    ProjectResource rsrc = projectsCollection.parse(input.project);
    Capable r = rsrc.getControl().canPushToAtLeastOneRef();
    if (r != Capable.OK) {
        throw new AuthException(r.getMessage());
    }
    RefControl refControl = rsrc.getControl().controlForRef(refName);
    if (!refControl.canUpload() || !refControl.canRead()) {
        throw new AuthException("cannot upload review");
    }
    Project.NameKey project = rsrc.getNameKey();
    try (Repository git = gitManager.openRepository(project);
        ObjectInserter oi = git.newObjectInserter();
        RevWalk rw = new RevWalk(oi.newReader())) {
        ObjectId parentCommit;
        List<String> groups;
        if (input.baseChange != null) {
            List<ChangeControl> ctls = changeFinder.find(input.baseChange, rsrc.getControl().getUser());
            if (ctls.size() != 1) {
                throw new InvalidChangeOperationException("Base change not found: " + input.baseChange);
            }
            ChangeControl ctl = Iterables.getOnlyElement(ctls);
            if (!ctl.isVisible(db.get())) {
                throw new InvalidChangeOperationException("Base change not found: " + input.baseChange);
            }
            PatchSet ps = psUtil.current(db.get(), ctl.getNotes());
            parentCommit = ObjectId.fromString(ps.getRevision().get());
            groups = ps.getGroups();
        } else {
            Ref destRef = git.getRefDatabase().exactRef(refName);
            if (destRef != null) {
                if (Boolean.TRUE.equals(input.newBranch)) {
                    throw new ResourceConflictException(String.format("Branch %s already exists.", refName));
                }
                parentCommit = destRef.getObjectId();
            } else {
                if (Boolean.TRUE.equals(input.newBranch)) {
                    parentCommit = null;
                } else {
                    throw new UnprocessableEntityException(String.format("Branch %s does not exist.", refName));
                }
            }
            groups = Collections.emptyList();
        }
        RevCommit mergeTip = parentCommit == null ? null : rw.parseCommit(parentCommit);
        Timestamp now = TimeUtil.nowTs();
        IdentifiedUser me = user.get().asIdentifiedUser();
        PersonIdent author = me.newCommitterIdent(now, serverTimeZone);
        AccountState account = accountCache.get(me.getAccountId());
        GeneralPreferencesInfo info = account.getAccount().getGeneralPreferencesInfo();
        ObjectId treeId = mergeTip == null ? emptyTreeId(oi) : mergeTip.getTree();
        ObjectId id = ChangeIdUtil.computeChangeId(treeId, mergeTip, author, author, input.subject);
        String commitMessage = ChangeIdUtil.insertId(input.subject, id);
        if (Boolean.TRUE.equals(info.signedOffBy)) {
            commitMessage += String.format("%s%s", SIGNED_OFF_BY_TAG, account.getAccount().getNameEmail(anonymousCowardName));
        }
        RevCommit c;
        if (input.merge != null) {
            // create a merge commit
            if (!(submitType.equals(SubmitType.MERGE_ALWAYS) || submitType.equals(SubmitType.MERGE_IF_NECESSARY))) {
                throw new BadRequestException("Submit type: " + submitType + " is not supported");
            }
            c = newMergeCommit(git, oi, rw, rsrc.getControl(), mergeTip, input.merge, author, commitMessage);
        } else {
            // create an empty commit
            c = newCommit(oi, rw, author, mergeTip, commitMessage);
        }
        Change.Id changeId = new Change.Id(seq.nextChangeId());
        ChangeInserter ins = changeInserterFactory.create(changeId, c, refName).setValidatePolicy(CommitValidators.Policy.GERRIT);
        ins.setMessage(String.format("Uploaded patch set %s.", ins.getPatchSetId().get()));
        String topic = input.topic;
        if (topic != null) {
            topic = Strings.emptyToNull(topic.trim());
        }
        ins.setTopic(topic);
        ins.setDraft(input.status == ChangeStatus.DRAFT);
        ins.setGroups(groups);
        try (BatchUpdate bu = updateFactory.create(db.get(), project, me, now)) {
            bu.setRepository(git, rw, oi);
            bu.insertChange(ins);
            bu.execute();
        }
        ChangeJson json = jsonFactory.create(ChangeJson.NO_OPTIONS);
        return Response.created(json.format(ins.getChange()));
    } catch (IllegalArgumentException e) {
        throw new BadRequestException(e.getMessage());
    }
}
#end_block

#method_before
int shutdown() {
    int cnt = 0;
    if (pool != null) {
        cnt = pool.shutdownNow().size();
        pool.unregisterWorkQueue();
        pool = null;
    }
    return cnt;
}
#method_after
int shutdown() {
    int cnt = 0;
    if (pool != null) {
        for (Runnable r : pool.getQueue()) {
            repLog.warn(String.format("Cancelling replication event %s", r));
        }
        cnt = pool.shutdownNow().size();
        pool.unregisterWorkQueue();
        pool = null;
    }
    return cnt;
}
#end_block

#method_before
@Override
public void run() throws IOException {
    ui.header("Index");
    IndexType type = index.select("Type", "type", IndexType.LUCENE);
    if ((site.isNew || isEmptySite()) && type == IndexType.LUCENE) {
        for (SchemaDefinitions<?> def : IndexModule.ALL_SCHEMA_DEFS) {
            AbstractLuceneIndex.setReady(site, def.getName(), def.getLatest().getVersion(), true);
        }
    } else {
        final String message = String.format("\nThe index must be %sbuilt before starting Gerrit:\n" + "  java -jar gerrit.war reindex -d site_path\n", site.isNew ? "" : "re");
        ui.message(message);
        initFlags.autoStart = false;
    }
}
#method_after
@Override
public void run() throws IOException {
    IndexType type = IndexType.LUCENE;
    if (IndexType.values().length > 1) {
        ui.header("Index");
        type = index.select("Type", "type", type);
    }
    if ((site.isNew || isEmptySite()) && type == IndexType.LUCENE) {
        for (SchemaDefinitions<?> def : IndexModule.ALL_SCHEMA_DEFS) {
            AbstractLuceneIndex.setReady(site, def.getName(), def.getLatest().getVersion(), true);
        }
    } else {
        if (IndexType.values().length <= 1) {
            ui.header("Index");
        }
        String message = String.format("\nThe index must be %sbuilt before starting Gerrit:\n" + "  java -jar gerrit.war reindex -d site_path\n", site.isNew ? "" : "re");
        ui.message(message);
        initFlags.autoStart = false;
    }
}
#end_block

#method_before
private void json(final Object data, final StringWriter w) {
    JsonServlet.defaultGsonBuilder().create().toJson(data, w);
}
#method_after
private void json(Object data, StringWriter w) {
    JsonServlet.defaultGsonBuilder().create().toJson(data, w);
}
#end_block

#method_before
private Page get() {
    Page p = page;
    if (refreshHeaderFooter && p.isStale()) {
        final Page newPage;
        try {
            newPage = new Page();
        } catch (IOException e) {
            log.error("Cannot refresh site header/footer", e);
            return p;
        }
        p = newPage;
        page = p;
    }
    return p;
}
#method_after
private Page get() {
    Page p = page;
    try {
        if (refreshHeaderFooter && p.isStale()) {
            p = new Page();
            page = p;
        }
    } catch (IOException e) {
        log.error("Cannot refresh site header/footer", e);
    }
    return p;
}
#end_block

#method_before
@Override
protected void doGet(final HttpServletRequest req, final HttpServletResponse rsp) throws IOException {
    final Page.Content page = select(req);
    final StringWriter w = new StringWriter();
    final CurrentUser user = currentUser.get();
    if (user.isIdentifiedUser()) {
        w.write(HPD_ID + ".account=");
        json(((IdentifiedUser) user).getAccount(), w);
        w.write(";");
        w.write(HPD_ID + ".xGerritAuth=");
        json(session.get().getXGerritAuth(), w);
        w.write(";");
        w.write(HPD_ID + ".accountDiffPref=");
        json(((IdentifiedUser) user).getAccountDiffPreference(), w);
        w.write(";");
        w.write(HPD_ID + ".theme=");
        json(signedInTheme, w);
        w.write(";");
    } else {
        w.write(HPD_ID + ".theme=");
        json(signedOutTheme, w);
        w.write(";");
    }
    plugins(w);
    messages(w);
    final byte[] hpd = w.toString().getBytes("UTF-8");
    final byte[] raw = Bytes.concat(page.part1, hpd, page.part2);
    final byte[] tosend;
    if (RPCServletUtils.acceptsGzipEncoding(req)) {
        rsp.setHeader("Content-Encoding", "gzip");
        tosend = HtmlDomUtil.compress(raw);
    } else {
        tosend = raw;
    }
    CacheHeaders.setNotCacheable(rsp);
    rsp.setContentType("text/html");
    rsp.setCharacterEncoding(HtmlDomUtil.ENC);
    rsp.setContentLength(tosend.length);
    final OutputStream out = rsp.getOutputStream();
    try {
        out.write(tosend);
    } finally {
        out.close();
    }
}
#method_after
@Override
protected void doGet(HttpServletRequest req, HttpServletResponse rsp) throws IOException {
    Page.Content page = select(req);
    StringWriter w = new StringWriter();
    CurrentUser user = currentUser.get();
    if (user.isIdentifiedUser()) {
        w.write(HPD_ID + ".accountDiffPref=");
        json(getDiffPreferences(user.asIdentifiedUser()), w);
        w.write(";");
        w.write(HPD_ID + ".theme=");
        json(signedInTheme, w);
        w.write(";");
    } else {
        w.write(HPD_ID + ".theme=");
        json(signedOutTheme, w);
        w.write(";");
    }
    plugins(w);
    messages(w);
    byte[] hpd = w.toString().getBytes(UTF_8);
    byte[] raw = Bytes.concat(page.part1, hpd, page.part2);
    byte[] tosend;
    if (RPCServletUtils.acceptsGzipEncoding(req)) {
        rsp.setHeader("Content-Encoding", "gzip");
        tosend = HtmlDomUtil.compress(raw);
    } else {
        tosend = raw;
    }
    CacheHeaders.setNotCacheable(rsp);
    rsp.setContentType("text/html");
    rsp.setCharacterEncoding(HtmlDomUtil.ENC.name());
    rsp.setContentLength(tosend.length);
    try (OutputStream out = rsp.getOutputStream()) {
        out.write(tosend);
    }
}
#end_block

#method_before
private void plugins(StringWriter w) {
    List<String> urls = Lists.newArrayList();
    for (WebUiPlugin u : plugins) {
        urls.add(String.format("plugins/%s/%s", u.getPluginName(), u.getJavaScriptResourcePath()));
    }
    if (!urls.isEmpty()) {
        w.write(HPD_ID + ".plugins=");
        json(urls, w);
        w.write(";");
    }
}
#method_after
private void plugins(StringWriter w) {
    List<String> urls = new ArrayList<>();
    for (WebUiPlugin u : plugins) {
        urls.add(String.format("plugins/%s/%s", u.getPluginName(), u.getJavaScriptResourcePath()));
    }
    if (!urls.isEmpty()) {
        w.write(HPD_ID + ".plugins=");
        json(urls, w);
        w.write(";");
    }
}
#end_block

#method_before
private void insertETags(Element e) {
    if ("img".equalsIgnoreCase(e.getTagName()) || "script".equalsIgnoreCase(e.getTagName())) {
        String src = e.getAttribute("src");
        if (src != null && src.startsWith("static/")) {
            String name = src.substring("static/".length());
            StaticServlet.Resource r = staticServlet.getResource(name);
            if (r != null) {
                e.setAttribute("src", src + "?e=" + r.etag);
            }
        }
    }
    for (Node n = e.getFirstChild(); n != null; n = n.getNextSibling()) {
        if (n instanceof Element) {
            insertETags((Element) n);
        }
    }
}
#method_after
private void insertETags(Element e) {
    if ("img".equalsIgnoreCase(e.getTagName()) || "script".equalsIgnoreCase(e.getTagName())) {
        String src = e.getAttribute("src");
        if (src != null && src.startsWith("static/")) {
            String name = src.substring("static/".length());
            ResourceServlet.Resource r = staticServlet.getResource(name);
            if (r != null) {
                e.setAttribute("src", src + "?e=" + r.etag);
            }
        }
    }
    for (Node n = e.getFirstChild(); n != null; n = n.getNextSibling()) {
        if (n instanceof Element) {
            insertETags((Element) n);
        }
    }
}
#end_block

#method_before
boolean isStale() {
    return time != path.lastModified();
}
#method_after
boolean isStale() {
    return time != lastModified(path);
}
#end_block

#method_before
private void asScript(final Element scriptNode) {
    scriptNode.setAttribute("type", "text/javascript");
    scriptNode.setAttribute("language", "javascript");
}
#method_after
private void asScript(Element scriptNode) {
    scriptNode.setAttribute("type", "text/javascript");
    scriptNode.setAttribute("language", "javascript");
}
#end_block

#method_before
private FileInfo injectCssFile(final Document hostDoc, final String id, final File src) throws IOException {
    final FileInfo info = new FileInfo(src);
    final Element banner = HtmlDomUtil.find(hostDoc, id);
    if (banner == null) {
        return info;
    }
    while (banner.getFirstChild() != null) {
        banner.removeChild(banner.getFirstChild());
    }
    String css = HtmlDomUtil.readFile(src.getParentFile(), src.getName());
    if (css == null) {
        return info;
    }
    banner.appendChild(hostDoc.createCDATASection("\n" + css + "\n"));
    return info;
}
#method_after
private FileInfo injectCssFile(Document hostDoc, String id, Path src) throws IOException {
    FileInfo info = new FileInfo(src);
    Element banner = HtmlDomUtil.find(hostDoc, id);
    if (banner == null) {
        return info;
    }
    while (banner.getFirstChild() != null) {
        banner.removeChild(banner.getFirstChild());
    }
    String css = HtmlDomUtil.readFile(src.getParent(), src.getFileName().toString());
    if (css == null) {
        return info;
    }
    banner.appendChild(hostDoc.createCDATASection("\n" + css + "\n"));
    return info;
}
#end_block

#method_before
private FileInfo injectXmlFile(final Document hostDoc, final String id, final File src) throws IOException {
    final FileInfo info = new FileInfo(src);
    final Element banner = HtmlDomUtil.find(hostDoc, id);
    if (banner == null) {
        return info;
    }
    while (banner.getFirstChild() != null) {
        banner.removeChild(banner.getFirstChild());
    }
    Document html = HtmlDomUtil.parseFile(src);
    if (html == null) {
        return info;
    }
    Element content = html.getDocumentElement();
    insertETags(content);
    banner.appendChild(hostDoc.importNode(content, true));
    return info;
}
#method_after
private FileInfo injectXmlFile(Document hostDoc, String id, Path src) throws IOException {
    FileInfo info = new FileInfo(src);
    Element banner = HtmlDomUtil.find(hostDoc, id);
    if (banner == null) {
        return info;
    }
    while (banner.getFirstChild() != null) {
        banner.removeChild(banner.getFirstChild());
    }
    Document html = HtmlDomUtil.parseFile(src);
    if (html == null) {
        return info;
    }
    Element content = html.getDocumentElement();
    insertETags(content);
    banner.appendChild(hostDoc.importNode(content, true));
    return info;
}
#end_block

#method_before
public static void display(final String token, final Screen view) {
    if (view.isRequiresSignIn() && !isSignedIn()) {
        doSignIn(token);
    } else {
        view.setToken(token);
        body.setView(view);
    }
}
#method_after
public static void display(final String token, final Screen view) {
    if (view.isRequiresSignIn() && !isSignedIn()) {
        doSignIn(token);
    } else {
        view.setToken(token);
        if (isSignedIn()) {
            LocalComments.saveInlineComments();
        }
        body.setView(view);
    }
}
#end_block

#method_before
public static void setHeaderVisible(boolean visible) {
    topMenu.setVisible(visible);
    siteHeader.setVisible(visible && (myAccount != null ? myAccount.getGeneralPreferences().isShowSiteHeader() : true));
}
#method_after
public static void setHeaderVisible(boolean visible) {
    topMenu.setVisible(visible);
    siteHeader.setVisible(visible && getUserPreferences().showSiteHeader());
}
#end_block

#method_before
public static Account getUserAccount() {
    return myAccount;
}
#method_after
public static AccountInfo getUserAccount() {
    return myAccount;
}
#end_block

#method_before
public static boolean isSignedIn() {
    return getUserAccount() != null;
}
#method_after
public static boolean isSignedIn() {
    return xGerritAuth != null;
}
#end_block

#method_before
public static String loginRedirect(String token) {
    if (token == null) {
        token = "";
    } else if (token.startsWith("/")) {
        token = token.substring(1);
    }
    return selfRedirect("/login/" + token);
}
#method_after
public static String loginRedirect(String token) {
    if (token == null) {
        token = "";
    } else if (token.startsWith("/")) {
        token = token.substring(1);
    }
    return selfRedirect("login/") + URL.encodePathSegment("#/" + token);
}
#end_block

#method_before
static void deleteSessionCookie() {
    myAccount = null;
    myAccountDiffPref = null;
    xGerritAuth = null;
    refreshMenuBar();
    // If the cookie was HttpOnly, this request to delete it will
    // most likely not be successful.  We can try anyway though.
    // 
    Cookies.removeCookie("GerritAccount");
}
#method_after
static void deleteSessionCookie() {
    myAccount = AccountInfo.create(0, null, null, null);
    myAccountDiffPref = null;
    editPrefs = null;
    myPrefs = GeneralPreferences.createDefault();
    urlAliasMatcher.clearUserAliases();
    xGerritAuth = null;
    refreshMenuBar();
    // If the cookie was HttpOnly, this request to delete it will
    // most likely not be successful.  We can try anyway though.
    // 
    Cookies.removeCookie("GerritAccount");
}
#end_block

#method_before
@Override
public void onModuleLoad() {
    if (canLoadInIFrame(GWT.getModuleBaseURL() + GWT.getModuleName())) {
        UserAgent.assertNotInIFrame();
    }
    KeyUtil.setEncoderImpl(new KeyUtil.Encoder() {

        @Override
        public String encode(String e) {
            e = URL.encodeQueryString(e);
            e = fixPathImpl(e);
            e = fixColonImpl(e);
            e = fixDoubleQuote(e);
            return e;
        }

        @Override
        public String decode(final String e) {
            return URL.decodeQueryString(e);
        }

        private native String fixPathImpl(String path);

        private native String fixColonImpl(String path);

        private native String fixDoubleQuote(String path);
    });
    initHostname();
    Window.setTitle(M.windowTitle1(myHost));
    final HostPageDataService hpd = GWT.create(HostPageDataService.class);
    hpd.load(new GerritCallback<HostPageData>() {

        @Override
        public void onSuccess(final HostPageData result) {
            Document.get().getElementById("gerrit_hostpagedata").removeFromParent();
            myConfig = result.config;
            myTheme = result.theme;
            if (result.account != null) {
                myAccount = result.account;
                xGerritAuth = result.xGerritAuth;
            }
            if (result.accountDiffPref != null) {
                myAccountDiffPref = result.accountDiffPref;
                applyUserPreferences();
            }
            onModuleLoad2(result);
        }
    });
}
#method_after
@Override
public void onModuleLoad() {
    if (!canLoadInIFrame()) {
        UserAgent.assertNotInIFrame();
    }
    setXsrfToken();
    KeyUtil.setEncoderImpl(new KeyUtil.Encoder() {

        @Override
        public String encode(String e) {
            e = URL.encodeQueryString(e);
            e = fixPathImpl(e);
            e = fixColonImpl(e);
            e = fixDoubleQuote(e);
            return e;
        }

        @Override
        public String decode(final String e) {
            return URL.decodeQueryString(e);
        }

        private native String fixPathImpl(String path);

        private native String fixColonImpl(String path);

        private native String fixDoubleQuote(String path);
    });
    initHostname();
    Window.setTitle(M.windowTitle1(myHost));
    RpcStatus.INSTANCE = new RpcStatus();
    CallbackGroup cbg = new CallbackGroup();
    getDocIndex(cbg.add(new GerritCallback<DocInfo>() {

        @Override
        public void onSuccess(DocInfo indexInfo) {
            hasDocumentation = indexInfo != null;
            docUrl = selfRedirect("/Documentation/");
        }
    }));
    ConfigServerApi.serverInfo(cbg.add(new GerritCallback<ServerInfo>() {

        @Override
        public void onSuccess(ServerInfo info) {
            myServerInfo = info;
            urlAliasMatcher = new UrlAliasMatcher(info.urlAliases());
            String du = info.gerrit().docUrl();
            if (du != null && !du.isEmpty()) {
                hasDocumentation = true;
                docUrl = du;
            }
            docSearch = info.gerrit().docSearch();
        }
    }));
    HostPageDataService hpd = GWT.create(HostPageDataService.class);
    hpd.load(cbg.addFinal(new GerritCallback<HostPageData>() {

        @Override
        public void onSuccess(final HostPageData result) {
            Document.get().getElementById("gerrit_hostpagedata").removeFromParent();
            myTheme = result.theme;
            isNoteDbEnabled = result.isNoteDbEnabled;
            if (result.accountDiffPref != null) {
                myAccountDiffPref = result.accountDiffPref;
            }
            if (result.accountDiffPref != null) {
                // TODO: Support options on the GetDetail REST endpoint so that it can
                // also return the preferences. Then we can fetch everything with a
                // single request and we don't need the callback group anymore.
                CallbackGroup cbg = new CallbackGroup();
                AccountApi.self().view("detail").get(cbg.add(new GerritCallback<AccountInfo>() {

                    @Override
                    public void onSuccess(AccountInfo result) {
                        myAccount = result;
                    }
                }));
                AccountApi.self().view("preferences").get(cbg.add(new GerritCallback<GeneralPreferences>() {

                    @Override
                    public void onSuccess(GeneralPreferences prefs) {
                        myPrefs = prefs;
                        onModuleLoad2(result);
                    }
                }));
                AccountApi.getEditPreferences(cbg.addFinal(new GerritCallback<EditPreferences>() {

                    @Override
                    public void onSuccess(EditPreferences prefs) {
                        EditPreferencesInfo prefsInfo = new EditPreferencesInfo();
                        prefs.copyTo(prefsInfo);
                        editPrefs = prefsInfo;
                    }
                }));
            } else {
                myAccount = AccountInfo.create(0, null, null, null);
                myPrefs = GeneralPreferences.createDefault();
                editPrefs = null;
                onModuleLoad2(result);
            }
        }
    }));
}
#end_block

#method_before
private static void populateBottomMenu(RootPanel btmmenu, HostPageData hpd) {
    String vs = hpd.version;
    if (vs == null || vs.isEmpty()) {
        vs = "dev";
    }
    btmmenu.add(new InlineLabel(C.keyHelp()));
    btmmenu.add(new InlineLabel(" | "));
    btmmenu.add(new InlineHTML(M.poweredBy(vs)));
    final String reportBugText = getConfig().getReportBugText();
    Anchor a = new Anchor(reportBugText == null ? C.reportBug() : reportBugText, getConfig().getReportBugUrl());
    a.setTarget("_blank");
    a.setStyleName("");
    btmmenu.add(new InlineLabel(" | "));
    btmmenu.add(a);
}
#method_after
private static void populateBottomMenu(RootPanel btmmenu, HostPageData hpd) {
    String vs = hpd.version;
    if (vs == null || vs.isEmpty()) {
        vs = "dev";
    }
    btmmenu.add(new InlineHTML(M.poweredBy(vs)));
    String reportBugUrl = info().gerrit().reportBugUrl();
    if (reportBugUrl != null) {
        String reportBugText = info().gerrit().reportBugText();
        Anchor a = new Anchor(reportBugText == null ? C.reportBug() : reportBugText, reportBugUrl);
        a.setTarget("_blank");
        a.setStyleName("");
        btmmenu.add(new InlineLabel(" | "));
        btmmenu.add(a);
    }
    btmmenu.add(new InlineLabel(" | "));
    btmmenu.add(new InlineLabel(C.keyHelp()));
}
#end_block

#method_before
private void onModuleLoad2(HostPageData hpd) {
    RESOURCES.gwt_override().ensureInjected();
    RESOURCES.css().ensureInjected();
    topMenu = RootPanel.get("gerrit_topmenu");
    final RootPanel gStarting = RootPanel.get("gerrit_startinggerrit");
    final RootPanel gBody = RootPanel.get("gerrit_body");
    bottomMenu = RootPanel.get("gerrit_btmmenu");
    topMenu.setStyleName(RESOURCES.css().gerritTopMenu());
    gBody.setStyleName(RESOURCES.css().gerritBody());
    final Grid menuLine = new Grid(1, 3);
    menuLeft = new MorphingTabPanel();
    menuRight = new LinkMenuBar();
    searchPanel = new SearchPanel();
    menuLeft.setStyleName(RESOURCES.css().topmenuMenuLeft());
    menuLine.setStyleName(RESOURCES.css().topmenu());
    topMenu.add(menuLine);
    final FlowPanel menuRightPanel = new FlowPanel();
    menuRightPanel.setStyleName(RESOURCES.css().topmenuMenuRight());
    menuRightPanel.add(searchPanel);
    menuRightPanel.add(menuRight);
    menuLine.setWidget(0, 0, menuLeft);
    menuLine.setWidget(0, 1, new FlowPanel());
    menuLine.setWidget(0, 2, menuRightPanel);
    final CellFormatter fmt = menuLine.getCellFormatter();
    fmt.setStyleName(0, 0, RESOURCES.css().topmenuTDmenu());
    fmt.setStyleName(0, 1, RESOURCES.css().topmenuTDglue());
    fmt.setStyleName(0, 2, RESOURCES.css().topmenuTDmenu());
    siteHeader = RootPanel.get("gerrit_header");
    siteFooter = RootPanel.get("gerrit_footer");
    body = new ViewSite<Screen>() {

        @Override
        protected void onShowView(Screen view) {
            String token = view.getToken();
            History.newItem(token, false);
            dispatchHistoryHooks(token);
            if (view instanceof ChangeListScreen) {
                lastChangeListToken = token;
            }
            super.onShowView(view);
            view.onShowView();
            lastViewToken = token;
        }
    };
    gBody.add(body);
    RpcStatus.INSTANCE = new RpcStatus();
    JsonUtil.addRpcStartHandler(RpcStatus.INSTANCE);
    JsonUtil.addRpcCompleteHandler(RpcStatus.INSTANCE);
    JsonUtil.setDefaultXsrfManager(new XsrfManager() {

        @Override
        public String getToken(JsonDefTarget proxy) {
            return xGerritAuth;
        }

        @Override
        public void setToken(JsonDefTarget proxy, String token) {
        // Ignore the request, we always rely upon the cookie.
        }
    });
    gStarting.getElement().getParentElement().removeChild(gStarting.getElement());
    RootPanel.detachNow(gStarting);
    ApiGlue.init();
    applyUserPreferences();
    populateBottomMenu(bottomMenu, hpd);
    refreshMenuBar();
    History.addValueChangeHandler(new ValueChangeHandler<String>() {

        @Override
        public void onValueChange(ValueChangeEvent<String> event) {
            display(event.getValue());
        }
    });
    JumpKeys.register(body);
    String token = History.getToken();
    if (token.isEmpty()) {
        token = isSignedIn() ? PageLinks.MINE : PageLinks.toChangeQuery("status:open");
    }
    saveDefaultTheme();
    if (hpd.messages != null) {
        new MessageOfTheDayBar(hpd.messages).show();
    }
    PluginLoader.load(hpd.plugins, token);
}
#method_after
private void onModuleLoad2(HostPageData hpd) {
    RESOURCES.gwt_override().ensureInjected();
    RESOURCES.css().ensureInjected();
    topMenu = RootPanel.get("gerrit_topmenu");
    final RootPanel gStarting = RootPanel.get("gerrit_startinggerrit");
    final RootPanel gBody = RootPanel.get("gerrit_body");
    bottomMenu = RootPanel.get("gerrit_btmmenu");
    topMenu.setStyleName(RESOURCES.css().gerritTopMenu());
    gBody.setStyleName(RESOURCES.css().gerritBody());
    final Grid menuLine = new Grid(1, 3);
    menuLeft = new MorphingTabPanel();
    menuRight = new LinkMenuBar();
    searchPanel = new SearchPanel();
    menuLeft.setStyleName(RESOURCES.css().topmenuMenuLeft());
    menuLine.setStyleName(RESOURCES.css().topmenu());
    topMenu.add(menuLine);
    final FlowPanel menuRightPanel = new FlowPanel();
    menuRightPanel.setStyleName(RESOURCES.css().topmenuMenuRight());
    menuRightPanel.add(searchPanel);
    menuRightPanel.add(menuRight);
    menuLine.setWidget(0, 0, menuLeft);
    menuLine.setWidget(0, 1, new FlowPanel());
    menuLine.setWidget(0, 2, menuRightPanel);
    final CellFormatter fmt = menuLine.getCellFormatter();
    fmt.setStyleName(0, 0, RESOURCES.css().topmenuTDmenu());
    fmt.setStyleName(0, 1, RESOURCES.css().topmenuTDglue());
    fmt.setStyleName(0, 2, RESOURCES.css().topmenuTDmenu());
    siteHeader = RootPanel.get("gerrit_header");
    siteFooter = RootPanel.get("gerrit_footer");
    body = new ViewSite<Screen>() {

        @Override
        protected void onShowView(Screen view) {
            String token = view.getToken();
            History.newItem(token, false);
            dispatchHistoryHooks(token);
            if (view instanceof ChangeListScreen) {
                lastChangeListToken = token;
            }
            super.onShowView(view);
            view.onShowView();
            lastViewToken = token;
        }
    };
    gBody.add(body);
    JsonUtil.addRpcStartHandler(RpcStatus.INSTANCE);
    JsonUtil.addRpcCompleteHandler(RpcStatus.INSTANCE);
    gStarting.getElement().getParentElement().removeChild(gStarting.getElement());
    RootPanel.detachNow(gStarting);
    ApiGlue.init();
    applyUserPreferences();
    populateBottomMenu(bottomMenu, hpd);
    refreshMenuBar();
    History.addValueChangeHandler(new ValueChangeHandler<String>() {

        @Override
        public void onValueChange(ValueChangeEvent<String> event) {
            display(event.getValue());
        }
    });
    JumpKeys.register(body);
    saveDefaultTheme();
    if (hpd.messages != null) {
        new MessageOfTheDayBar(hpd.messages).show();
    }
    PluginLoader.load(hpd.plugins, hpd.pluginsLoadTimeout, new GerritCallback<VoidResult>() {

        @Override
        public void onSuccess(VoidResult result) {
            String token = History.getToken();
            if (token.isEmpty()) {
                token = isSignedIn() ? PageLinks.MINE : PageLinks.toChangeQuery("status:open");
            }
            display(token);
        }
    });
}
#end_block

#method_before
public static void refreshMenuBar() {
    menuLeft.clear();
    menuRight.clear();
    menuBars = new HashMap<>();
    final boolean signedIn = isSignedIn();
    final GerritConfig cfg = getConfig();
    LinkMenuBar m;
    m = new LinkMenuBar();
    menuBars.put(GerritTopMenu.ALL.menuName, m);
    addLink(m, C.menuAllOpen(), PageLinks.toChangeQuery("status:open"));
    addLink(m, C.menuAllMerged(), PageLinks.toChangeQuery("status:merged"));
    addLink(m, C.menuAllAbandoned(), PageLinks.toChangeQuery("status:abandoned"));
    menuLeft.add(m, C.menuAll());
    if (signedIn) {
        final LinkMenuBar myBar = new LinkMenuBar();
        menuBars.put(GerritTopMenu.MY.menuName, m);
        AccountApi.self().view("preferences").get(new AsyncCallback<Preferences>() {

            @Override
            public void onSuccess(Preferences prefs) {
                for (TopMenuItem item : Natives.asList(prefs.my())) {
                    addExtensionLink(myBar, item);
                }
            }

            @Override
            public void onFailure(Throwable caught) {
            }
        });
        menuLeft.add(myBar, C.menuMine());
        menuLeft.selectTab(1);
    } else {
        menuLeft.selectTab(0);
    }
    patchScreen = null;
    LinkMenuBar diffBar = new LinkMenuBar();
    menuBars.put(GerritTopMenu.DIFFERENCES.menuName, diffBar);
    menuLeft.addInvisible(diffBar, C.menuDiff());
    addDiffLink(diffBar, CC.patchTableDiffSideBySide(), PatchScreen.Type.SIDE_BY_SIDE);
    addDiffLink(diffBar, CC.patchTableDiffUnified(), PatchScreen.Type.UNIFIED);
    addDiffLink(diffBar, C.menuDiffCommit(), PatchScreen.TopView.COMMIT);
    addDiffLink(diffBar, C.menuDiffPreferences(), PatchScreen.TopView.PREFERENCES);
    addDiffLink(diffBar, C.menuDiffPatchSets(), PatchScreen.TopView.PATCH_SETS);
    addDiffLink(diffBar, C.menuDiffFiles(), PatchScreen.TopView.FILES);
    final LinkMenuBar projectsBar = new LinkMenuBar() {

        @Override
        public void onScreenLoad(ScreenLoadEvent event) {
            if (event.getScreen() instanceof ProjectScreen) {
                menuLeft.selectTab(menuLeft.getWidgetIndex(this));
            }
        }
    };
    menuBars.put(GerritTopMenu.PROJECTS.menuName, projectsBar);
    addLink(projectsBar, C.menuProjectsList(), PageLinks.ADMIN_PROJECTS);
    addProjectLink(projectsBar, C.menuProjectsInfo(), ProjectScreen.INFO);
    addProjectLink(projectsBar, C.menuProjectsBranches(), ProjectScreen.BRANCH);
    addProjectLink(projectsBar, C.menuProjectsAccess(), ProjectScreen.ACCESS);
    final LinkMenuItem dashboardsMenuItem = addProjectLink(projectsBar, C.menuProjectsDashboards(), ProjectScreen.DASHBOARDS);
    menuLeft.add(projectsBar, C.menuProjects());
    if (signedIn) {
        final LinkMenuBar peopleBar = new LinkMenuBar();
        menuBars.put(GerritTopMenu.PEOPLE.menuName, peopleBar);
        final LinkMenuItem groupsListMenuItem = addLink(peopleBar, C.menuPeopleGroupsList(), PageLinks.ADMIN_GROUPS);
        menuLeft.add(peopleBar, C.menuPeople());
        final LinkMenuBar pluginsBar = new LinkMenuBar();
        menuBars.put(GerritTopMenu.PLUGINS.menuName, pluginsBar);
        AccountCapabilities.all(new GerritCallback<AccountCapabilities>() {

            @Override
            public void onSuccess(AccountCapabilities result) {
                if (result.canPerform(CREATE_PROJECT)) {
                    insertLink(projectsBar, C.menuProjectsCreate(), PageLinks.ADMIN_CREATE_PROJECT, projectsBar.getWidgetIndex(dashboardsMenuItem) + 1);
                }
                if (result.canPerform(CREATE_GROUP)) {
                    insertLink(peopleBar, C.menuPeopleGroupsCreate(), PageLinks.ADMIN_CREATE_GROUP, peopleBar.getWidgetIndex(groupsListMenuItem) + 1);
                }
                if (result.canPerform(ADMINISTRATE_SERVER)) {
                    insertLink(pluginsBar, C.menuPluginsInstalled(), PageLinks.ADMIN_PLUGINS, 0);
                    menuLeft.insert(pluginsBar, C.menuPlugins(), menuLeft.getWidgetIndex(peopleBar) + 1);
                }
            }
        }, CREATE_PROJECT, CREATE_GROUP, ADMINISTRATE_SERVER);
    }
    if (getConfig().isDocumentationAvailable()) {
        m = new LinkMenuBar();
        menuBars.put(GerritTopMenu.DOCUMENTATION.menuName, m);
        addDocLink(m, C.menuDocumentationTOC(), "index.html");
        addDocLink(m, C.menuDocumentationSearch(), "user-search.html");
        addDocLink(m, C.menuDocumentationUpload(), "user-upload.html");
        addDocLink(m, C.menuDocumentationAccess(), "access-control.html");
        addDocLink(m, C.menuDocumentationAPI(), "rest-api.html");
        menuLeft.add(m, C.menuDocumentation());
    }
    if (signedIn) {
        whoAmI(cfg.getAuthType() != AuthType.CLIENT_SSL_CERT_LDAP);
    } else {
        switch(cfg.getAuthType()) {
            case CLIENT_SSL_CERT_LDAP:
                break;
            case OPENID:
                menuRight.addItem(C.menuRegister(), new Command() {

                    public void execute() {
                        String t = History.getToken();
                        if (t == null) {
                            t = "";
                        }
                        doSignIn(PageLinks.REGISTER + t);
                    }
                });
                menuRight.addItem(C.menuSignIn(), new Command() {

                    public void execute() {
                        doSignIn(History.getToken());
                    }
                });
                break;
            case OPENID_SSO:
                menuRight.addItem(C.menuSignIn(), new Command() {

                    public void execute() {
                        doSignIn(History.getToken());
                    }
                });
                break;
            case HTTP:
            case HTTP_LDAP:
                if (cfg.getLoginUrl() != null) {
                    final String signinText = cfg.getLoginText() == null ? C.menuSignIn() : cfg.getLoginText();
                    menuRight.add(anchor(signinText, cfg.getLoginUrl()));
                }
                break;
            case LDAP:
            case LDAP_BIND:
            case CUSTOM_EXTENSION:
                if (cfg.getRegisterUrl() != null) {
                    final String registerText = cfg.getRegisterText() == null ? C.menuRegister() : cfg.getRegisterText();
                    menuRight.add(anchor(registerText, cfg.getRegisterUrl()));
                }
                menuRight.addItem(C.menuSignIn(), new Command() {

                    public void execute() {
                        doSignIn(History.getToken());
                    }
                });
                break;
            case DEVELOPMENT_BECOME_ANY_ACCOUNT:
                menuRight.add(anchor("Become", loginRedirect("")));
                break;
        }
    }
    ConfigServerApi.topMenus(new GerritCallback<TopMenuList>() {

        public void onSuccess(TopMenuList result) {
            List<TopMenu> topMenuExtensions = Natives.asList(result);
            for (TopMenu menu : topMenuExtensions) {
                LinkMenuBar existingBar = menuBars.get(menu.getName());
                LinkMenuBar bar = existingBar != null ? existingBar : new LinkMenuBar();
                for (TopMenuItem item : Natives.asList(menu.getItems())) {
                    addExtensionLink(bar, item);
                }
                if (existingBar == null) {
                    menuBars.put(menu.getName(), bar);
                    menuLeft.add(bar, menu.getName());
                }
            }
        }
    });
}
#method_after
public static void refreshMenuBar() {
    menuLeft.clear();
    menuRight.clear();
    menuBars = new HashMap<>();
    boolean signedIn = isSignedIn();
    AuthInfo authInfo = info().auth();
    LinkMenuBar m;
    m = new LinkMenuBar();
    menuBars.put(GerritTopMenu.ALL.menuName, m);
    addLink(m, C.menuAllOpen(), PageLinks.toChangeQuery("status:open"));
    addLink(m, C.menuAllMerged(), PageLinks.toChangeQuery("status:merged"));
    addLink(m, C.menuAllAbandoned(), PageLinks.toChangeQuery("status:abandoned"));
    menuLeft.add(m, C.menuAll());
    if (signedIn) {
        LinkMenuBar myBar = new LinkMenuBar();
        menuBars.put(GerritTopMenu.MY.menuName, myBar);
        if (myPrefs.my() != null) {
            myBar.clear();
            String url = null;
            List<TopMenuItem> myMenuItems = Natives.asList(myPrefs.my());
            if (!myMenuItems.isEmpty()) {
                if (myMenuItems.get(0).getUrl().startsWith("#")) {
                    url = myMenuItems.get(0).getUrl().substring(1);
                }
                for (TopMenuItem item : myMenuItems) {
                    addExtensionLink(myBar, item);
                }
            }
            defaultScreenToken = url;
        }
        menuLeft.add(myBar, C.menuMine());
        menuLeft.selectTab(1);
    } else {
        menuLeft.selectTab(0);
    }
    final LinkMenuBar projectsBar = new LinkMenuBar();
    menuBars.put(GerritTopMenu.PROJECTS.menuName, projectsBar);
    addLink(projectsBar, C.menuProjectsList(), PageLinks.ADMIN_PROJECTS);
    projectsBar.addItem(new ProjectLinkMenuItem(C.menuProjectsInfo(), ProjectScreen.INFO));
    projectsBar.addItem(new ProjectLinkMenuItem(C.menuProjectsBranches(), ProjectScreen.BRANCHES));
    projectsBar.addItem(new ProjectLinkMenuItem(C.menuProjectsTags(), ProjectScreen.TAGS));
    projectsBar.addItem(new ProjectLinkMenuItem(C.menuProjectsAccess(), ProjectScreen.ACCESS));
    final LinkMenuItem dashboardsMenuItem = new ProjectLinkMenuItem(C.menuProjectsDashboards(), ProjectScreen.DASHBOARDS) {

        @Override
        protected boolean match(String token) {
            return super.match(token) || (!getTargetHistoryToken().isEmpty() && ("/admin" + token).startsWith(getTargetHistoryToken()));
        }
    };
    projectsBar.addItem(dashboardsMenuItem);
    menuLeft.add(projectsBar, C.menuProjects());
    if (signedIn) {
        final LinkMenuBar peopleBar = new LinkMenuBar();
        menuBars.put(GerritTopMenu.PEOPLE.menuName, peopleBar);
        final LinkMenuItem groupsListMenuItem = addLink(peopleBar, C.menuPeopleGroupsList(), PageLinks.ADMIN_GROUPS);
        menuLeft.add(peopleBar, C.menuPeople());
        final LinkMenuBar pluginsBar = new LinkMenuBar();
        menuBars.put(GerritTopMenu.PLUGINS.menuName, pluginsBar);
        AccountCapabilities.all(new GerritCallback<AccountCapabilities>() {

            @Override
            public void onSuccess(AccountCapabilities result) {
                if (result.canPerform(CREATE_PROJECT)) {
                    insertLink(projectsBar, C.menuProjectsCreate(), PageLinks.ADMIN_CREATE_PROJECT, projectsBar.getWidgetIndex(dashboardsMenuItem) + 1);
                }
                if (result.canPerform(CREATE_GROUP)) {
                    insertLink(peopleBar, C.menuPeopleGroupsCreate(), PageLinks.ADMIN_CREATE_GROUP, peopleBar.getWidgetIndex(groupsListMenuItem) + 1);
                }
                if (result.canPerform(VIEW_PLUGINS)) {
                    insertLink(pluginsBar, C.menuPluginsInstalled(), PageLinks.ADMIN_PLUGINS, 0);
                    menuLeft.insert(pluginsBar, C.menuPlugins(), menuLeft.getWidgetIndex(peopleBar) + 1);
                }
            }
        }, CREATE_PROJECT, CREATE_GROUP, VIEW_PLUGINS);
    }
    if (hasDocumentation) {
        m = new LinkMenuBar();
        menuBars.put(GerritTopMenu.DOCUMENTATION.menuName, m);
        addDocLink(m, C.menuDocumentationTOC(), "index.html");
        addDocLink(m, C.menuDocumentationSearch(), "user-search.html");
        addDocLink(m, C.menuDocumentationUpload(), "user-upload.html");
        addDocLink(m, C.menuDocumentationAccess(), "access-control.html");
        addDocLink(m, C.menuDocumentationAPI(), "rest-api.html");
        addDocLink(m, C.menuDocumentationProjectOwnerGuide(), "intro-project-owner.html");
        menuLeft.add(m, C.menuDocumentation());
    }
    if (signedIn) {
        whoAmI(!authInfo.isClientSslCertLdap());
    } else {
        switch(authInfo.authType()) {
            case CLIENT_SSL_CERT_LDAP:
                break;
            case OPENID:
                menuRight.addItem(C.menuRegister(), new Command() {

                    @Override
                    public void execute() {
                        String t = History.getToken();
                        if (t == null) {
                            t = "";
                        }
                        doSignIn(PageLinks.REGISTER + t);
                    }
                });
                menuRight.addItem(C.menuSignIn(), new Command() {

                    @Override
                    public void execute() {
                        doSignIn(History.getToken());
                    }
                });
                break;
            case OAUTH:
                menuRight.addItem(C.menuSignIn(), new Command() {

                    @Override
                    public void execute() {
                        doSignIn(History.getToken());
                    }
                });
                break;
            case OPENID_SSO:
                menuRight.addItem(C.menuSignIn(), new Command() {

                    @Override
                    public void execute() {
                        doSignIn(History.getToken());
                    }
                });
                break;
            case HTTP:
            case HTTP_LDAP:
                if (authInfo.loginUrl() != null) {
                    String signinText = authInfo.loginText() == null ? C.menuSignIn() : authInfo.loginText();
                    menuRight.add(anchor(signinText, authInfo.loginUrl()));
                }
                break;
            case LDAP:
            case LDAP_BIND:
            case CUSTOM_EXTENSION:
                if (authInfo.registerUrl() != null) {
                    String registerText = authInfo.registerText() == null ? C.menuRegister() : authInfo.registerText();
                    menuRight.add(anchor(registerText, authInfo.registerUrl()));
                }
                menuRight.addItem(C.menuSignIn(), new Command() {

                    @Override
                    public void execute() {
                        doSignIn(History.getToken());
                    }
                });
                break;
            case DEVELOPMENT_BECOME_ANY_ACCOUNT:
                menuRight.add(anchor("Become", loginRedirect("")));
                break;
        }
    }
    ConfigServerApi.topMenus(new GerritCallback<TopMenuList>() {

        @Override
        public void onSuccess(TopMenuList result) {
            List<TopMenu> topMenuExtensions = Natives.asList(result);
            for (TopMenu menu : topMenuExtensions) {
                String name = menu.getName();
                LinkMenuBar existingBar = menuBars.get(name);
                LinkMenuBar bar = existingBar != null ? existingBar : new LinkMenuBar();
                for (TopMenuItem item : Natives.asList(menu.getItems())) {
                    addMenuLink(bar, item);
                }
                if (existingBar == null) {
                    menuBars.put(name, bar);
                    menuLeft.add(bar, name);
                }
            }
        }
    });
}
#end_block

#method_before
public static void applyUserPreferences() {
    if (myAccount != null) {
        final AccountGeneralPreferences p = myAccount.getGeneralPreferences();
        CopyableLabel.setFlashEnabled(p.isUseFlashClipboard());
        if (siteHeader != null) {
            siteHeader.setVisible(p.isShowSiteHeader());
        }
        if (siteFooter != null) {
            siteFooter.setVisible(p.isShowSiteHeader());
        }
        FormatUtil.setPreferences(myAccount.getGeneralPreferences());
    }
}
#method_after
private static void applyUserPreferences() {
    CopyableLabel.setFlashEnabled(myPrefs.useFlashClipboard());
    if (siteHeader != null) {
        siteHeader.setVisible(myPrefs.showSiteHeader());
    }
    if (siteFooter != null) {
        siteFooter.setVisible(myPrefs.showSiteHeader());
    }
    FormatUtil.setPreferences(myPrefs);
    urlAliasMatcher.updateUserAliases(myPrefs.urlAliases());
}
#end_block

#method_before
private static void whoAmI(boolean canLogOut) {
    AccountInfo account = getUserAccountInfo();
    final UserPopupPanel userPopup = new UserPopupPanel(account, canLogOut, true);
    final FlowPanel userSummaryPanel = new FlowPanel();
    class PopupHandler implements KeyDownHandler, ClickHandler {

        private void showHidePopup() {
            if (userPopup.isShowing() && userPopup.isVisible()) {
                userPopup.hide();
            } else {
                userPopup.showRelativeTo(userSummaryPanel);
            }
        }

        @Override
        public void onClick(ClickEvent event) {
            showHidePopup();
        }

        @Override
        public void onKeyDown(KeyDownEvent event) {
            if (event.getNativeKeyCode() == KeyCodes.KEY_ENTER) {
                showHidePopup();
                event.preventDefault();
            }
        }
    }
    final PopupHandler popupHandler = new PopupHandler();
    final InlineLabel l = new InlineLabel(FormatUtil.name(account));
    l.setStyleName(RESOURCES.css().menuBarUserName());
    final AvatarImage avatar = new AvatarImage(account, 26, false);
    avatar.setStyleName(RESOURCES.css().menuBarUserNameAvatar());
    userSummaryPanel.setStyleName(RESOURCES.css().menuBarUserNamePanel());
    userSummaryPanel.add(l);
    userSummaryPanel.add(avatar);
    // "BLACK DOWN-POINTING SMALL TRIANGLE"
    userSummaryPanel.add(new InlineLabel(" \u25be"));
    userPopup.addAutoHidePartner(userSummaryPanel.getElement());
    FocusPanel fp = new FocusPanel(userSummaryPanel);
    fp.setStyleName(RESOURCES.css().menuBarUserNameFocusPanel());
    fp.addKeyDownHandler(popupHandler);
    fp.addClickHandler(popupHandler);
    menuRight.add(fp);
}
#method_after
private static void whoAmI(boolean canLogOut) {
    AccountInfo account = getUserAccount();
    final UserPopupPanel userPopup = new UserPopupPanel(account, canLogOut, true);
    final FlowPanel userSummaryPanel = new FlowPanel();
    class PopupHandler implements KeyDownHandler, ClickHandler {

        private void showHidePopup() {
            if (userPopup.isShowing() && userPopup.isVisible()) {
                userPopup.hide();
            } else {
                userPopup.showRelativeTo(userSummaryPanel);
            }
        }

        @Override
        public void onClick(ClickEvent event) {
            showHidePopup();
        }

        @Override
        public void onKeyDown(KeyDownEvent event) {
            if (event.getNativeKeyCode() == KeyCodes.KEY_ENTER) {
                showHidePopup();
                event.preventDefault();
            }
        }
    }
    final PopupHandler popupHandler = new PopupHandler();
    final InlineLabel l = new InlineLabel(FormatUtil.name(account));
    l.setStyleName(RESOURCES.css().menuBarUserName());
    final AvatarImage avatar = new AvatarImage(account, 26, false);
    avatar.setStyleName(RESOURCES.css().menuBarUserNameAvatar());
    userSummaryPanel.setStyleName(RESOURCES.css().menuBarUserNamePanel());
    userSummaryPanel.add(l);
    userSummaryPanel.add(avatar);
    // "BLACK DOWN-POINTING SMALL TRIANGLE"
    userSummaryPanel.add(new InlineLabel(" \u25be"));
    userPopup.addAutoHidePartner(userSummaryPanel.getElement());
    FocusPanel fp = new FocusPanel(userSummaryPanel);
    fp.setStyleName(RESOURCES.css().menuBarUserNameFocusPanel());
    fp.addKeyDownHandler(popupHandler);
    fp.addClickHandler(popupHandler);
    menuRight.add(fp);
}
#end_block

#method_before
private static LinkMenuItem addProjectLink(final LinkMenuBar m, final String text, final String panel) {
    LinkMenuItem i = new LinkMenuItem(text, "") {

        @Override
        public void onScreenLoad(ScreenLoadEvent event) {
            Screen screen = event.getScreen();
            Project.NameKey projectKey;
            if (screen instanceof ProjectScreen) {
                projectKey = ((ProjectScreen) screen).getProjectKey();
            } else {
                projectKey = ProjectScreen.getSavedKey();
            }
            if (projectKey != null) {
                setVisible(true);
                setTargetHistoryToken(Dispatcher.toProjectAdmin(projectKey, panel));
            } else {
                setVisible(false);
            }
            super.onScreenLoad(event);
        }
    };
    m.addItem(i);
    return i;
}
#method_after
private static LinkMenuItem addProjectLink(LinkMenuBar m, TopMenuItem item) {
    LinkMenuItem i = new ProjectLinkMenuItem(item.getName(), item.getUrl()) {

        @Override
        protected void onScreenLoad(Project.NameKey project) {
            String p = panel.replace(PROJECT_NAME_MENU_VAR, URL.encodeQueryString(project.get()));
            if (!panel.startsWith("/x/") && !isAbsolute(panel)) {
                UrlBuilder builder = new UrlBuilder();
                builder.setProtocol(Location.getProtocol());
                builder.setHost(Location.getHost());
                String port = Location.getPort();
                if (port != null && !port.isEmpty()) {
                    builder.setPort(Integer.parseInt(port));
                }
                builder.setPath(Location.getPath());
                p = builder.buildString() + p;
            }
            getElement().setPropertyString("href", p);
        }

        @Override
        public void go() {
            String href = getElement().getPropertyString("href");
            if (href.startsWith("#")) {
                super.go();
            } else {
                Window.open(href, getElement().getPropertyString("target"), "");
            }
        }
    };
    if (item.getTarget() != null && !item.getTarget().isEmpty()) {
        i.getElement().setAttribute("target", item.getTarget());
    }
    if (item.getId() != null) {
        i.getElement().setAttribute("id", item.getId());
    }
    m.addItem(i);
    return i;
}
#end_block

#method_before
private static void addDocLink(final LinkMenuBar m, final String text, final String href) {
    final Anchor atag = anchor(text, selfRedirect("/Documentation/" + href));
    atag.setTarget("_blank");
    m.add(atag);
}
#method_after
private static void addDocLink(final LinkMenuBar m, final String text, final String href) {
    final Anchor atag = anchor(text, docUrl + href);
    atag.setTarget("_blank");
    m.add(atag);
}
#end_block

#method_before
private static void addExtensionLink(LinkMenuBar m, TopMenuItem item) {
    if (item.getUrl().startsWith("#") && (item.getTarget() == null || item.getTarget().isEmpty())) {
        LinkMenuItem a = new LinkMenuItem(item.getName(), item.getUrl().substring(1));
        if (item.getId() != null) {
            a.getElement().setAttribute("id", item.getId());
        }
        m.add(a);
    } else {
        Anchor atag = anchor(item.getName(), isAbsolute(item.getUrl()) ? item.getUrl() : selfRedirect(item.getUrl()));
        if (item.getTarget() != null && !item.getTarget().isEmpty()) {
            atag.setTarget(item.getTarget());
        }
        if (item.getId() != null) {
            atag.getElement().setAttribute("id", item.getId());
        }
        m.add(atag);
    }
}
#method_after
private static void addExtensionLink(LinkMenuBar m, TopMenuItem item) {
    if (item.getUrl().startsWith("#") && (item.getTarget() == null || item.getTarget().isEmpty())) {
        LinkMenuItem a = new LinkMenuItem(item.getName(), item.getUrl().substring(1));
        if (item.getId() != null) {
            a.getElement().setAttribute("id", item.getId());
        }
        m.addItem(a);
    } else {
        Anchor atag = anchor(item.getName(), isAbsolute(item.getUrl()) ? item.getUrl() : selfRedirect(item.getUrl()));
        if (item.getTarget() != null && !item.getTarget().isEmpty()) {
            atag.setTarget(item.getTarget());
        }
        if (item.getId() != null) {
            atag.getElement().setAttribute("id", item.getId());
        }
        m.add(atag);
    }
}
#end_block

#method_before
@Test
public void stickyAcrossMultiplePatchSets() throws Exception {
    ProjectConfig cfg = projectCache.checkedGet(project).getConfig();
    cfg.getLabelSections().get("Code-Review").setCopyMaxScore(true);
    cfg.getLabelSections().get("Verified").setCopyAllScoresIfNoCodeChange(true);
    saveProjectConfig(project, cfg);
    String changeId = createChange(REWORK);
    vote(admin, changeId, 2, 1);
    for (int i = 0; i < 5; i++) {
        updateChange(changeId, NO_CODE_CHANGE);
        ChangeInfo c = detailedChange(changeId);
        assertVotes(c, admin, 2, 1, NO_CODE_CHANGE);
    }
    updateChange(changeId, REWORK);
    ChangeInfo c = detailedChange(changeId);
    assertVotes(c, admin, 2, 0, NO_CODE_CHANGE);
}
#method_after
@Test
public void stickyAcrossMultiplePatchSets() throws Exception {
    ProjectConfig cfg = projectCache.checkedGet(project).getConfig();
    cfg.getLabelSections().get("Code-Review").setCopyMaxScore(true);
    cfg.getLabelSections().get("Verified").setCopyAllScoresIfNoCodeChange(true);
    saveProjectConfig(project, cfg);
    String changeId = createChange(REWORK);
    vote(admin, changeId, 2, 1);
    for (int i = 0; i < 5; i++) {
        updateChange(changeId, NO_CODE_CHANGE);
        ChangeInfo c = detailedChange(changeId);
        assertVotes(c, admin, 2, 1, NO_CODE_CHANGE);
    }
    updateChange(changeId, REWORK);
    ChangeInfo c = detailedChange(changeId);
    assertVotes(c, admin, 2, 0, REWORK);
}
#end_block

#method_before
private Iterable<PatchSetApproval> getForPatchSet(ReviewDb db, ChangeControl ctl, PatchSet ps) throws OrmException {
    checkNotNull(ps, "ps should not be null");
    ChangeData cd = changeDataFactory.create(db, ctl);
    try {
        ProjectState project = projectCache.checkedGet(cd.change().getDest().getParentKey());
        ListMultimap<PatchSet.Id, PatchSetApproval> all = cd.approvals();
        checkNotNull(all, "all should not be null");
        Table<String, Account.Id, PatchSetApproval> byUser = HashBasedTable.create();
        for (PatchSetApproval psa : all.get(ps.getId())) {
            byUser.put(psa.getLabel(), psa.getAccountId(), psa);
        }
        TreeMap<Integer, PatchSet> patchSets = getPatchSets(cd);
        try (Repository repo = repoManager.openRepository(project.getProject().getNameKey())) {
            // Walk patch sets strictly less than current in descending order.
            Collection<PatchSet> allPrior = patchSets.descendingMap().tailMap(ps.getId().get(), false).values();
            for (PatchSet priorPs : allPrior) {
                List<PatchSetApproval> priorApprovals = all.get(priorPs.getId());
                if (priorApprovals.isEmpty()) {
                    continue;
                }
                ChangeKind kind = changeKindCache.getChangeKind(project, repo, ObjectId.fromString(priorPs.getRevision().get()), ObjectId.fromString(ps.getRevision().get()));
                for (PatchSetApproval psa : priorApprovals) {
                    if (!byUser.contains(psa.getLabel(), psa.getAccountId()) && canCopy(project, psa, ps.getId(), kind)) {
                        byUser.put(psa.getLabel(), psa.getAccountId(), copy(psa, ps.getId()));
                    }
                }
            }
            return labelNormalizer.normalize(ctl, byUser.values()).getNormalized();
        }
    } catch (IOException e) {
        throw new OrmException(e);
    }
}
#method_after
private Iterable<PatchSetApproval> getForPatchSet(ReviewDb db, ChangeControl ctl, PatchSet ps) throws OrmException {
    checkNotNull(ps, "ps should not be null");
    ChangeData cd = changeDataFactory.create(db, ctl);
    try {
        ProjectState project = projectCache.checkedGet(cd.change().getDest().getParentKey());
        ListMultimap<PatchSet.Id, PatchSetApproval> all = cd.approvals();
        checkNotNull(all, "all should not be null");
        Table<String, Account.Id, PatchSetApproval> wontCopy = HashBasedTable.create();
        Table<String, Account.Id, PatchSetApproval> byUser = HashBasedTable.create();
        for (PatchSetApproval psa : all.get(ps.getId())) {
            byUser.put(psa.getLabel(), psa.getAccountId(), psa);
        }
        TreeMap<Integer, PatchSet> patchSets = getPatchSets(cd);
        try (Repository repo = repoManager.openRepository(project.getProject().getNameKey())) {
            // Walk patch sets strictly less than current in descending order.
            Collection<PatchSet> allPrior = patchSets.descendingMap().tailMap(ps.getId().get(), false).values();
            for (PatchSet priorPs : allPrior) {
                List<PatchSetApproval> priorApprovals = all.get(priorPs.getId());
                if (priorApprovals.isEmpty()) {
                    continue;
                }
                ChangeKind kind = changeKindCache.getChangeKind(project, repo, ObjectId.fromString(priorPs.getRevision().get()), ObjectId.fromString(ps.getRevision().get()));
                for (PatchSetApproval psa : priorApprovals) {
                    if (wontCopy.contains(psa.getLabel(), psa.getAccountId())) {
                        continue;
                    }
                    if (byUser.contains(psa.getLabel(), psa.getAccountId())) {
                        continue;
                    }
                    if (!canCopy(project, psa, ps.getId(), kind)) {
                        wontCopy.put(psa.getLabel(), psa.getAccountId(), psa);
                        continue;
                    }
                    byUser.put(psa.getLabel(), psa.getAccountId(), copy(psa, ps.getId()));
                }
            }
            return labelNormalizer.normalize(ctl, byUser.values()).getNormalized();
        }
    } catch (IOException e) {
        throw new OrmException(e);
    }
}
#end_block

#method_before
private <K, V, I extends Index<K, V>> void initIndex(IndexDefinition<K, V, I> def, GerritIndexStatus cfg) {
    TreeMap<Integer, Version<V>> versions = scanVersions(def, cfg);
    // Search from the most recent ready version.
    // Write to the most recent ready version and the most recent version.
    Version<V> search = null;
    List<Version<V>> write = Lists.newArrayListWithCapacity(2);
    for (Version<V> v : versions.descendingMap().values()) {
        if (v.schema == null) {
            continue;
        }
        if (write.isEmpty() && onlineUpgrade) {
            write.add(v);
        }
        if (v.ready) {
            search = v;
            if (!write.contains(v)) {
                write.add(v);
            }
            break;
        }
    }
    if (search == null) {
        throw new ProvisionException(runReindexMsg);
    }
    IndexFactory<K, V, I> factory = def.getIndexFactory();
    I searchIndex = factory.create(search.schema);
    IndexCollection<K, V, I> indexes = def.getIndexCollection();
    indexes.setSearchIndex(searchIndex);
    for (Version<V> v : write) {
        if (v.schema != null) {
            if (v.version != search.version) {
                indexes.addWriteIndex(factory.create(v.schema));
            } else {
                indexes.addWriteIndex(searchIndex);
            }
        }
    }
    markNotReady(cfg, def.getName(), versions.values(), write);
    int latest = write.get(0).version;
    if (onlineUpgrade && latest != search.version) {
        OnlineReindexer<K, V, I> reindexer = new OnlineReindexer<>(def, latest);
        synchronized (this) {
            if (!reindexers.containsKey(def.getName())) {
                reindexers.put(def.getName(), reindexer);
                reindexer.start();
            }
        }
    }
}
#method_after
private <K, V, I extends Index<K, V>> void initIndex(IndexDefinition<K, V, I> def, GerritIndexStatus cfg) {
    TreeMap<Integer, Version<V>> versions = scanVersions(def, cfg);
    // Search from the most recent ready version.
    // Write to the most recent ready version and the most recent version.
    Version<V> search = null;
    List<Version<V>> write = Lists.newArrayListWithCapacity(2);
    for (Version<V> v : versions.descendingMap().values()) {
        if (v.schema == null) {
            continue;
        }
        if (write.isEmpty() && onlineUpgrade) {
            write.add(v);
        }
        if (v.ready) {
            search = v;
            if (!write.contains(v)) {
                write.add(v);
            }
            break;
        }
    }
    if (search == null) {
        throw new ProvisionException(runReindexMsg);
    }
    IndexFactory<K, V, I> factory = def.getIndexFactory();
    I searchIndex = factory.create(search.schema);
    IndexCollection<K, V, I> indexes = def.getIndexCollection();
    indexes.setSearchIndex(searchIndex);
    for (Version<V> v : write) {
        if (v.schema != null) {
            if (v.version != search.version) {
                indexes.addWriteIndex(factory.create(v.schema));
            } else {
                indexes.addWriteIndex(searchIndex);
            }
        }
    }
    markNotReady(cfg, def.getName(), versions.values(), write);
    int latest = write.get(0).version;
    OnlineReindexer<K, V, I> reindexer = new OnlineReindexer<>(def, latest);
    reindexers.put(def.getName(), reindexer);
    if (onlineUpgrade && latest != search.version) {
        synchronized (this) {
            if (!reindexers.containsKey(def.getName())) {
                reindexer.start();
            }
        }
    }
}
#end_block

#method_before
@Override
protected void run() throws UnloggedFailure {
    try {
        if (luceneVersionManager.startReindexer(name, force)) {
            stdout.println("Reindexer started");
        } else {
            stdout.println("Nothing to reindex, index is already the latest version");
        }
    } catch (ReindexerAlreadyRunningException e) {
        throw new UnloggedFailure("Failed to start reindexer: " + e.getMessage());
    }
}
#method_after
@Override
protected void run() throws UnloggedFailure {
    try {
        if (luceneVersionManager.startReindexer(name, force)) {
            stdout.println("Reindexer started");
        } else {
            stdout.println("Nothing to reindex, index is already the latest version");
        }
    } catch (ReindexerAlreadyRunningException e) {
        throw die("Failed to start reindexer: " + e.getMessage());
    }
}
#end_block

#method_before
public boolean appliesTo(Branch.NameKey branch) {
    for (RefSpec r : refSpecs) {
        if (r.matchSource(branch.get())) {
            return true;
        }
    }
    return false;
}
#method_after
public boolean appliesTo(Branch.NameKey branch) {
    for (RefSpec r : matchingRefSpecs) {
        if (r.matchSource(branch.get())) {
            return true;
        }
    }
    for (RefSpec r : multiMatchRefSpecs) {
        if (r.matchSource(branch.get())) {
            return true;
        }
    }
    return false;
}
#end_block

#method_before
@Override
public String toString() {
    StringBuilder ret = new StringBuilder();
    ret.append("[SubscribeSection, project=");
    ret.append(project);
    ret.append(", refs=[");
    for (RefSpec r : refSpecs) {
        ret.append(r.toString());
        ret.append(", ");
    }
    ret.append("]");
    return ret.toString();
}
#method_after
@Override
public String toString() {
    StringBuilder ret = new StringBuilder();
    ret.append("[SubscribeSection, project=");
    ret.append(project);
    if (!matchingRefSpecs.isEmpty()) {
        ret.append(", matching=[");
        for (RefSpec r : matchingRefSpecs) {
            ret.append(r.toString());
            ret.append(", ");
        }
    }
    if (!multiMatchRefSpecs.isEmpty()) {
        ret.append(", all=[");
        for (RefSpec r : multiMatchRefSpecs) {
            ret.append(r.toString());
            ret.append(", ");
        }
    }
    ret.append("]");
    return ret.toString();
}
#end_block

#method_before
@Test
@GerritConfig(name = "submodule.enableSuperProjectSubscriptions", value = "false")
public void testSubscriptionWithoutGlobalServerSetting() throws Exception {
    TestRepository<?> superRepo = createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project");
    allowSubmoduleSubscription("subscribed-to-project", "refs/heads/master", "super-project", "refs/heads/master");
    createSubmoduleSubscription(superRepo, "master", "subscribed-to-project", "master");
    pushChangeTo(subRepo, "master");
    assertThat(hasSubmodule(superRepo, "master", "subscribed-to-project")).isFalse();
}
#method_after
@Test
@GerritConfig(name = "submodule.enableSuperProjectSubscriptions", value = "false")
public void testSubscriptionWithoutGlobalServerSetting() throws Exception {
    TestRepository<?> superRepo = createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project");
    allowMatchingSubmoduleSubscription("subscribed-to-project", "refs/heads/master", "super-project", "refs/heads/master");
    createSubmoduleSubscription(superRepo, "master", "subscribed-to-project", "master");
    pushChangeTo(subRepo, "master");
    assertThat(hasSubmodule(superRepo, "master", "subscribed-to-project")).isFalse();
}
#end_block

#method_before
@Test
public void testSubscriptionToEmptyRepo() throws Exception {
    TestRepository<?> superRepo = createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project");
    allowSubmoduleSubscription("subscribed-to-project", "refs/heads/master", "super-project", "refs/heads/master");
    createSubmoduleSubscription(superRepo, "master", "subscribed-to-project", "master");
    pushChangeTo(subRepo, "master");
    ObjectId subHEAD = pushChangeTo(subRepo, "master");
    assertThat(hasSubmodule(superRepo, "master", "subscribed-to-project")).isTrue();
    expectToHaveSubmoduleState(superRepo, "master", "subscribed-to-project", subHEAD);
}
#method_after
@Test
public void testSubscriptionToEmptyRepo() throws Exception {
    TestRepository<?> superRepo = createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project");
    allowMatchingSubmoduleSubscription("subscribed-to-project", "refs/heads/master", "super-project", "refs/heads/master");
    createSubmoduleSubscription(superRepo, "master", "subscribed-to-project", "master");
    pushChangeTo(subRepo, "master");
    ObjectId subHEAD = pushChangeTo(subRepo, "master");
    assertThat(hasSubmodule(superRepo, "master", "subscribed-to-project")).isTrue();
    expectToHaveSubmoduleState(superRepo, "master", "subscribed-to-project", subHEAD);
}
#end_block

#method_before
@Test
public void testSubscriptionToExistingRepo() throws Exception {
    TestRepository<?> superRepo = createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project");
    allowSubmoduleSubscription("subscribed-to-project", "refs/heads/master", "super-project", "refs/heads/master");
    pushChangeTo(subRepo, "master");
    createSubmoduleSubscription(superRepo, "master", "subscribed-to-project", "master");
    ObjectId subHEAD = pushChangeTo(subRepo, "master");
    assertThat(hasSubmodule(superRepo, "master", "subscribed-to-project")).isTrue();
    expectToHaveSubmoduleState(superRepo, "master", "subscribed-to-project", subHEAD);
}
#method_after
@Test
public void testSubscriptionToExistingRepo() throws Exception {
    TestRepository<?> superRepo = createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project");
    allowMatchingSubmoduleSubscription("subscribed-to-project", "refs/heads/master", "super-project", "refs/heads/master");
    pushChangeTo(subRepo, "master");
    createSubmoduleSubscription(superRepo, "master", "subscribed-to-project", "master");
    ObjectId subHEAD = pushChangeTo(subRepo, "master");
    assertThat(hasSubmodule(superRepo, "master", "subscribed-to-project")).isTrue();
    expectToHaveSubmoduleState(superRepo, "master", "subscribed-to-project", subHEAD);
}
#end_block

#method_before
@Test
public void testSubscriptionWildcardACLForSingleBranch() throws Exception {
    TestRepository<?> superRepo = createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project");
    // master is allowed to be subscribed to any superprojects branch:
    allowSubmoduleSubscription("subscribed-to-project", "refs/heads/master", "super-project", null);
    // create 'branch':
    pushChangeTo(superRepo, "branch");
    pushChangeTo(subRepo, "master");
    createSubmoduleSubscription(superRepo, "master", "subscribed-to-project", "master");
    createSubmoduleSubscription(superRepo, "branch", "subscribed-to-project", "master");
    ObjectId subHEAD = pushChangeTo(subRepo, "master");
    expectToHaveSubmoduleState(superRepo, "master", "subscribed-to-project", subHEAD);
    expectToHaveSubmoduleState(superRepo, "branch", "subscribed-to-project", subHEAD);
}
#method_after
@Test
public void testSubscriptionWildcardACLForSingleBranch() throws Exception {
    TestRepository<?> superRepo = createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project");
    // master is allowed to be subscribed to master branch only:
    allowMatchingSubmoduleSubscription("subscribed-to-project", "refs/heads/master", "super-project", null);
    // create 'branch':
    pushChangeTo(superRepo, "branch");
    pushChangeTo(subRepo, "master");
    createSubmoduleSubscription(superRepo, "master", "subscribed-to-project", "master");
    createSubmoduleSubscription(superRepo, "branch", "subscribed-to-project", "master");
    ObjectId subHEAD = pushChangeTo(subRepo, "master");
    expectToHaveSubmoduleState(superRepo, "master", "subscribed-to-project", subHEAD);
    assertThat(hasSubmodule(superRepo, "branch", "subscribed-to-project")).isFalse();
}
#end_block

#method_before
@Test
public void testSubscriptionWildcardACLForMissingProject() throws Exception {
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project");
    allowSubmoduleSubscription("subscribed-to-project", "refs/heads/*", "not-existing-super-project", "refs/heads/*");
    pushChangeTo(subRepo, "master");
}
#method_after
@Test
public void testSubscriptionWildcardACLForMissingProject() throws Exception {
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project");
    allowMatchingSubmoduleSubscription("subscribed-to-project", "refs/heads/*", "not-existing-super-project", "refs/heads/*");
    pushChangeTo(subRepo, "master");
}
#end_block

#method_before
@Test
public void testSubscriptionWildcardACLForMissingBranch() throws Exception {
    createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project");
    allowSubmoduleSubscription("subscribed-to-project", "refs/heads/*", "super-project", "refs/heads/*");
    pushChangeTo(subRepo, "foo");
}
#method_after
@Test
public void testSubscriptionWildcardACLForMissingBranch() throws Exception {
    createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project");
    allowMatchingSubmoduleSubscription("subscribed-to-project", "refs/heads/*", "super-project", "refs/heads/*");
    pushChangeTo(subRepo, "foo");
}
#end_block

#method_before
@Test
public void testSubscriptionWildcardACLForMissingGitmodules() throws Exception {
    TestRepository<?> superRepo = createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project");
    allowSubmoduleSubscription("subscribed-to-project", "refs/heads/*", "super-project", "refs/heads/*");
    pushChangeTo(superRepo, "master");
    pushChangeTo(subRepo, "master");
}
#method_after
@Test
public void testSubscriptionWildcardACLForMissingGitmodules() throws Exception {
    TestRepository<?> superRepo = createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project");
    allowMatchingSubmoduleSubscription("subscribed-to-project", "refs/heads/*", "super-project", "refs/heads/*");
    pushChangeTo(superRepo, "master");
    pushChangeTo(subRepo, "master");
}
#end_block

#method_before
@Test
public void testSubscriptionWildcardACLOneOnOneMapping() throws Exception {
    TestRepository<?> superRepo = createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project");
    // any branch is allowed to be subscribed to the same superprojects branch:
    allowSubmoduleSubscription("subscribed-to-project", "refs/heads/*", "super-project", "refs/heads/*");
    // create 'branch' in both repos:
    pushChangeTo(superRepo, "branch");
    pushChangeTo(subRepo, "branch");
    pushChangeTo(subRepo, "master");
    createSubmoduleSubscription(superRepo, "master", "subscribed-to-project", "master");
    createSubmoduleSubscription(superRepo, "branch", "subscribed-to-project", "branch");
    ObjectId subHEAD1 = pushChangeTo(subRepo, "master");
    ObjectId subHEAD2 = pushChangeTo(subRepo, "branch");
    expectToHaveSubmoduleState(superRepo, "master", "subscribed-to-project", subHEAD1);
    expectToHaveSubmoduleState(superRepo, "branch", "subscribed-to-project", subHEAD2);
    // Now test that cross subscriptions do not work:
    createSubmoduleSubscription(superRepo, "master", "subscribed-to-project", "branch");
    ObjectId subHEAD3 = pushChangeTo(subRepo, "branch");
    expectToHaveSubmoduleState(superRepo, "master", "subscribed-to-project", subHEAD1);
    expectToHaveSubmoduleState(superRepo, "branch", "subscribed-to-project", subHEAD3);
}
#method_after
@Test
public void testSubscriptionWildcardACLOneOnOneMapping() throws Exception {
    TestRepository<?> superRepo = createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project");
    // any branch is allowed to be subscribed to the same superprojects branch:
    allowMatchingSubmoduleSubscription("subscribed-to-project", "refs/heads/*", "super-project", "refs/heads/*");
    // create 'branch' in both repos:
    pushChangeTo(superRepo, "branch");
    pushChangeTo(subRepo, "branch");
    pushChangeTo(subRepo, "master");
    createSubmoduleSubscription(superRepo, "master", "subscribed-to-project", "master");
    createSubmoduleSubscription(superRepo, "branch", "subscribed-to-project", "branch");
    ObjectId subHEAD1 = pushChangeTo(subRepo, "master");
    ObjectId subHEAD2 = pushChangeTo(subRepo, "branch");
    expectToHaveSubmoduleState(superRepo, "master", "subscribed-to-project", subHEAD1);
    expectToHaveSubmoduleState(superRepo, "branch", "subscribed-to-project", subHEAD2);
    // Now test that cross subscriptions do not work:
    createSubmoduleSubscription(superRepo, "master", "subscribed-to-project", "branch");
    ObjectId subHEAD3 = pushChangeTo(subRepo, "branch");
    expectToHaveSubmoduleState(superRepo, "master", "subscribed-to-project", subHEAD1);
    expectToHaveSubmoduleState(superRepo, "branch", "subscribed-to-project", subHEAD3);
}
#end_block

#method_before
@Test
public void testSubscriptionWildcardACLForManyBranches() throws Exception {
    createProjectWithPush("inherit-from");
    Project.NameKey inherit = new Project.NameKey(name("inherit-from"));
    TestRepository<?> superRepo = createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project", inherit);
    TestRepository<?> subRepo2 = createProjectWithPush("subscribed-to-project2", inherit);
    // Any branch is allowed to be subscribed to any superproject branch:
    allowSubmoduleSubscription("inherit-from", "refs/heads/*", "super-project", null);
    // create 'branch' in both repos:
    pushChangeTo(superRepo, "branch");
    pushChangeTo(subRepo, "branch");
    pushChangeTo(subRepo2, "branch2");
    pushChangeTo(subRepo, "master");
    createSubmoduleSubscription(superRepo, "master", "subscribed-to-project", "master");
    createSubmoduleSubscription(superRepo, "master", "subscribed-to-project2", "master");
    createSubmoduleSubscription(superRepo, "branch", "subscribed-to-project", "branch");
    createSubmoduleSubscription(superRepo, "branch", "subscribed-to-project2", "branch2");
    ObjectId subHEAD1m = pushChangeTo(subRepo, "master");
    ObjectId subHEAD1b = pushChangeTo(subRepo, "branch");
    ObjectId subHEAD2m = pushChangeTo(subRepo, "master");
    ObjectId subHEAD2b = pushChangeTo(subRepo, "branch2");
    expectToHaveSubmoduleState(superRepo, "master", "subscribed-to-project", subHEAD1m);
    expectToHaveSubmoduleState(superRepo, "master", "subscribed-to-project2", subHEAD2m);
    expectToHaveSubmoduleState(superRepo, "branch", "subscribed-to-project", subHEAD1b);
    expectToHaveSubmoduleState(superRepo, "branch", "subscribed-to-project2", subHEAD2b);
}
#method_after
@Test
public void testSubscriptionWildcardACLForManyBranches() throws Exception {
    TestRepository<?> superRepo = createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project");
    // Any branch is allowed to be subscribed to any superproject branch:
    allowSubmoduleSubscription("subscribed-to-project", "refs/heads/*", "super-project", null, false);
    pushChangeTo(superRepo, "branch");
    pushChangeTo(subRepo, "another-branch");
    createSubmoduleSubscription(superRepo, "branch", "subscribed-to-project", "another-branch");
    ObjectId subHEAD = pushChangeTo(subRepo, "another-branch");
    expectToHaveSubmoduleState(superRepo, "branch", "subscribed-to-project", subHEAD);
}
#end_block

#method_before
@Test
@GerritConfig(name = "submodule.verboseSuperprojectUpdate", value = "false")
public void testSubmoduleShortCommitMessage() throws Exception {
    TestRepository<?> superRepo = createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project");
    allowSubmoduleSubscription("subscribed-to-project", "refs/heads/master", "super-project", "refs/heads/master");
    pushChangeTo(subRepo, "master");
    createSubmoduleSubscription(superRepo, "master", "subscribed-to-project", "master");
    // The first update doesn't include any commit messages
    ObjectId subRepoId = pushChangeTo(subRepo, "master");
    expectToHaveSubmoduleState(superRepo, "master", "subscribed-to-project", subRepoId);
    expectToHaveCommitMessage(superRepo, "master", "Update git submodules\n\n");
    // Any following update also has a short message
    subRepoId = pushChangeTo(subRepo, "master");
    expectToHaveSubmoduleState(superRepo, "master", "subscribed-to-project", subRepoId);
    expectToHaveCommitMessage(superRepo, "master", "Update git submodules\n\n");
}
#method_after
@Test
@GerritConfig(name = "submodule.verboseSuperprojectUpdate", value = "false")
public void testSubmoduleShortCommitMessage() throws Exception {
    TestRepository<?> superRepo = createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project");
    allowMatchingSubmoduleSubscription("subscribed-to-project", "refs/heads/master", "super-project", "refs/heads/master");
    pushChangeTo(subRepo, "master");
    createSubmoduleSubscription(superRepo, "master", "subscribed-to-project", "master");
    // The first update doesn't include any commit messages
    ObjectId subRepoId = pushChangeTo(subRepo, "master");
    expectToHaveSubmoduleState(superRepo, "master", "subscribed-to-project", subRepoId);
    expectToHaveCommitMessage(superRepo, "master", "Update git submodules\n\n");
    // Any following update also has a short message
    subRepoId = pushChangeTo(subRepo, "master");
    expectToHaveSubmoduleState(superRepo, "master", "subscribed-to-project", subRepoId);
    expectToHaveCommitMessage(superRepo, "master", "Update git submodules\n\n");
}
#end_block

#method_before
@Test
public void testSubmoduleCommitMessage() throws Exception {
    TestRepository<?> superRepo = createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project");
    allowSubmoduleSubscription("subscribed-to-project", "refs/heads/master", "super-project", "refs/heads/master");
    pushChangeTo(subRepo, "master");
    createSubmoduleSubscription(superRepo, "master", "subscribed-to-project", "master");
    ObjectId subHEAD = pushChangeTo(subRepo, "master");
    // The first update doesn't include the rev log
    RevWalk rw = subRepo.getRevWalk();
    expectToHaveCommitMessage(superRepo, "master", "Update git submodules\n\n" + "* Update " + name("subscribed-to-project") + " from branch 'master'");
    // The next commit should generate only its commit message,
    // omitting previous commit logs
    subHEAD = pushChangeTo(subRepo, "master");
    RevCommit subCommitMsg = rw.parseCommit(subHEAD);
    expectToHaveCommitMessage(superRepo, "master", "Update git submodules\n\n" + "* Update " + name("subscribed-to-project") + " from branch 'master'" + "\n  - " + subCommitMsg.getFullMessage().replace("\n", "\n    "));
}
#method_after
@Test
public void testSubmoduleCommitMessage() throws Exception {
    TestRepository<?> superRepo = createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project");
    allowMatchingSubmoduleSubscription("subscribed-to-project", "refs/heads/master", "super-project", "refs/heads/master");
    pushChangeTo(subRepo, "master");
    createSubmoduleSubscription(superRepo, "master", "subscribed-to-project", "master");
    ObjectId subHEAD = pushChangeTo(subRepo, "master");
    // The first update doesn't include the rev log
    RevWalk rw = subRepo.getRevWalk();
    expectToHaveCommitMessage(superRepo, "master", "Update git submodules\n\n" + "* Update " + name("subscribed-to-project") + " from branch 'master'");
    // The next commit should generate only its commit message,
    // omitting previous commit logs
    subHEAD = pushChangeTo(subRepo, "master");
    RevCommit subCommitMsg = rw.parseCommit(subHEAD);
    expectToHaveCommitMessage(superRepo, "master", "Update git submodules\n\n" + "* Update " + name("subscribed-to-project") + " from branch 'master'" + "\n  - " + subCommitMsg.getFullMessage().replace("\n", "\n    "));
}
#end_block

#method_before
@Test
public void testSubscriptionUnsubscribe() throws Exception {
    TestRepository<?> superRepo = createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project");
    allowSubmoduleSubscription("subscribed-to-project", "refs/heads/master", "super-project", "refs/heads/master");
    pushChangeTo(subRepo, "master");
    createSubmoduleSubscription(superRepo, "master", "subscribed-to-project", "master");
    pushChangeTo(subRepo, "master");
    ObjectId subHEADbeforeUnsubscribing = pushChangeTo(subRepo, "master");
    deleteAllSubscriptions(superRepo, "master");
    expectToHaveSubmoduleState(superRepo, "master", "subscribed-to-project", subHEADbeforeUnsubscribing);
    pushChangeTo(superRepo, "refs/heads/master", "commit after unsubscribe", "");
    pushChangeTo(subRepo, "refs/heads/master", "commit after unsubscribe", "");
    expectToHaveSubmoduleState(superRepo, "master", "subscribed-to-project", subHEADbeforeUnsubscribing);
}
#method_after
@Test
public void testSubscriptionUnsubscribe() throws Exception {
    TestRepository<?> superRepo = createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project");
    allowMatchingSubmoduleSubscription("subscribed-to-project", "refs/heads/master", "super-project", "refs/heads/master");
    pushChangeTo(subRepo, "master");
    createSubmoduleSubscription(superRepo, "master", "subscribed-to-project", "master");
    pushChangeTo(subRepo, "master");
    ObjectId subHEADbeforeUnsubscribing = pushChangeTo(subRepo, "master");
    deleteAllSubscriptions(superRepo, "master");
    expectToHaveSubmoduleState(superRepo, "master", "subscribed-to-project", subHEADbeforeUnsubscribing);
    pushChangeTo(superRepo, "refs/heads/master", "commit after unsubscribe", "");
    pushChangeTo(subRepo, "refs/heads/master", "commit after unsubscribe", "");
    expectToHaveSubmoduleState(superRepo, "master", "subscribed-to-project", subHEADbeforeUnsubscribing);
}
#end_block

#method_before
@Test
public void testSubscriptionUnsubscribeByDeletingGitModules() throws Exception {
    TestRepository<?> superRepo = createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project");
    allowSubmoduleSubscription("subscribed-to-project", "refs/heads/master", "super-project", "refs/heads/master");
    pushChangeTo(subRepo, "master");
    createSubmoduleSubscription(superRepo, "master", "subscribed-to-project", "master");
    pushChangeTo(subRepo, "master");
    ObjectId subHEADbeforeUnsubscribing = pushChangeTo(subRepo, "master");
    deleteGitModulesFile(superRepo, "master");
    expectToHaveSubmoduleState(superRepo, "master", "subscribed-to-project", subHEADbeforeUnsubscribing);
    pushChangeTo(superRepo, "refs/heads/master", "commit after unsubscribe", "");
    pushChangeTo(subRepo, "refs/heads/master", "commit after unsubscribe", "");
    expectToHaveSubmoduleState(superRepo, "master", "subscribed-to-project", subHEADbeforeUnsubscribing);
}
#method_after
@Test
public void testSubscriptionUnsubscribeByDeletingGitModules() throws Exception {
    TestRepository<?> superRepo = createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project");
    allowMatchingSubmoduleSubscription("subscribed-to-project", "refs/heads/master", "super-project", "refs/heads/master");
    pushChangeTo(subRepo, "master");
    createSubmoduleSubscription(superRepo, "master", "subscribed-to-project", "master");
    pushChangeTo(subRepo, "master");
    ObjectId subHEADbeforeUnsubscribing = pushChangeTo(subRepo, "master");
    deleteGitModulesFile(superRepo, "master");
    expectToHaveSubmoduleState(superRepo, "master", "subscribed-to-project", subHEADbeforeUnsubscribing);
    pushChangeTo(superRepo, "refs/heads/master", "commit after unsubscribe", "");
    pushChangeTo(subRepo, "refs/heads/master", "commit after unsubscribe", "");
    expectToHaveSubmoduleState(superRepo, "master", "subscribed-to-project", subHEADbeforeUnsubscribing);
}
#end_block

#method_before
@Test
public void testSubscriptionToDifferentBranches() throws Exception {
    TestRepository<?> superRepo = createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project");
    allowSubmoduleSubscription("subscribed-to-project", "refs/heads/foo", "super-project", "refs/heads/master");
    createSubmoduleSubscription(superRepo, "master", "subscribed-to-project", "foo");
    ObjectId subFoo = pushChangeTo(subRepo, "foo");
    pushChangeTo(subRepo, "master");
    expectToHaveSubmoduleState(superRepo, "master", "subscribed-to-project", subFoo);
}
#method_after
@Test
public void testSubscriptionToDifferentBranches() throws Exception {
    TestRepository<?> superRepo = createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project");
    allowMatchingSubmoduleSubscription("subscribed-to-project", "refs/heads/foo", "super-project", "refs/heads/master");
    createSubmoduleSubscription(superRepo, "master", "subscribed-to-project", "foo");
    ObjectId subFoo = pushChangeTo(subRepo, "foo");
    pushChangeTo(subRepo, "master");
    expectToHaveSubmoduleState(superRepo, "master", "subscribed-to-project", subFoo);
}
#end_block

#method_before
@Test
public void testBranchCircularSubscription() throws Exception {
    TestRepository<?> superRepo = createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project");
    allowSubmoduleSubscription("subscribed-to-project", "refs/heads/master", "super-project", "refs/heads/master");
    allowSubmoduleSubscription("super-project", "refs/heads/master", "subscribed-to-project", "refs/heads/master");
    pushChangeTo(subRepo, "master");
    pushChangeTo(superRepo, "master");
    createSubmoduleSubscription(superRepo, "master", "subscribed-to-project", "master");
    createSubmoduleSubscription(subRepo, "master", "super-project", "master");
    pushChangeTo(subRepo, "master");
    pushChangeTo(superRepo, "master");
    assertThat(hasSubmodule(subRepo, "master", "super-project")).isFalse();
    assertThat(hasSubmodule(superRepo, "master", "subscribed-to-project")).isFalse();
}
#method_after
@Test
public void testBranchCircularSubscription() throws Exception {
    TestRepository<?> superRepo = createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project");
    allowMatchingSubmoduleSubscription("subscribed-to-project", "refs/heads/master", "super-project", "refs/heads/master");
    allowMatchingSubmoduleSubscription("super-project", "refs/heads/master", "subscribed-to-project", "refs/heads/master");
    pushChangeTo(subRepo, "master");
    pushChangeTo(superRepo, "master");
    createSubmoduleSubscription(superRepo, "master", "subscribed-to-project", "master");
    createSubmoduleSubscription(subRepo, "master", "super-project", "master");
    pushChangeTo(subRepo, "master");
    pushChangeTo(superRepo, "master");
    assertThat(hasSubmodule(subRepo, "master", "super-project")).isFalse();
    assertThat(hasSubmodule(superRepo, "master", "subscribed-to-project")).isFalse();
}
#end_block

#method_before
@Test
public void testProjectCircularSubscription() throws Exception {
    TestRepository<?> superRepo = createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project");
    allowSubmoduleSubscription("subscribed-to-project", "refs/heads/master", "super-project", "refs/heads/master");
    allowSubmoduleSubscription("super-project", "refs/heads/dev", "subscribed-to-project", "refs/heads/dev");
    pushChangeTo(subRepo, "master");
    pushChangeTo(superRepo, "master");
    pushChangeTo(subRepo, "dev");
    pushChangeTo(superRepo, "dev");
    createSubmoduleSubscription(superRepo, "master", "subscribed-to-project", "master");
    createSubmoduleSubscription(subRepo, "dev", "super-project", "dev");
    ObjectId subMasterHead = pushChangeTo(subRepo, "master");
    ObjectId superDevHead = pushChangeTo(superRepo, "dev");
    assertThat(hasSubmodule(superRepo, "master", "subscribed-to-project")).isTrue();
    assertThat(hasSubmodule(subRepo, "dev", "super-project")).isTrue();
    expectToHaveSubmoduleState(superRepo, "master", "subscribed-to-project", subMasterHead);
    expectToHaveSubmoduleState(subRepo, "dev", "super-project", superDevHead);
}
#method_after
@Test
public void testProjectCircularSubscription() throws Exception {
    TestRepository<?> superRepo = createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project");
    allowMatchingSubmoduleSubscription("subscribed-to-project", "refs/heads/master", "super-project", "refs/heads/master");
    allowMatchingSubmoduleSubscription("super-project", "refs/heads/dev", "subscribed-to-project", "refs/heads/dev");
    pushChangeTo(subRepo, "master");
    pushChangeTo(superRepo, "master");
    pushChangeTo(subRepo, "dev");
    pushChangeTo(superRepo, "dev");
    createSubmoduleSubscription(superRepo, "master", "subscribed-to-project", "master");
    createSubmoduleSubscription(subRepo, "dev", "super-project", "dev");
    ObjectId subMasterHead = pushChangeTo(subRepo, "master");
    ObjectId superDevHead = pushChangeTo(superRepo, "dev");
    assertThat(hasSubmodule(superRepo, "master", "subscribed-to-project")).isTrue();
    assertThat(hasSubmodule(subRepo, "dev", "super-project")).isTrue();
    expectToHaveSubmoduleState(superRepo, "master", "subscribed-to-project", subMasterHead);
    expectToHaveSubmoduleState(subRepo, "dev", "super-project", superDevHead);
}
#end_block

#method_before
@Test
public void testSubscriptionFailOnWrongProjectACL() throws Exception {
    TestRepository<?> superRepo = createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project");
    allowSubmoduleSubscription("subscribed-to-project", "refs/heads/master", "wrong-super-project", "refs/heads/master");
    pushChangeTo(subRepo, "master");
    createSubmoduleSubscription(superRepo, "master", "subscribed-to-project", "master");
    pushChangeTo(subRepo, "master");
    assertThat(hasSubmodule(superRepo, "master", "subscribed-to-project")).isFalse();
}
#method_after
@Test
public void testSubscriptionFailOnWrongProjectACL() throws Exception {
    TestRepository<?> superRepo = createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project");
    allowMatchingSubmoduleSubscription("subscribed-to-project", "refs/heads/master", "wrong-super-project", "refs/heads/master");
    pushChangeTo(subRepo, "master");
    createSubmoduleSubscription(superRepo, "master", "subscribed-to-project", "master");
    pushChangeTo(subRepo, "master");
    assertThat(hasSubmodule(superRepo, "master", "subscribed-to-project")).isFalse();
}
#end_block

#method_before
@Test
public void testSubscriptionFailOnWrongBranchACL() throws Exception {
    TestRepository<?> superRepo = createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project");
    allowSubmoduleSubscription("subscribed-to-project", "refs/heads/master", "super-project", "refs/heads/wrong-branch");
    pushChangeTo(subRepo, "master");
    createSubmoduleSubscription(superRepo, "master", "subscribed-to-project", "master");
    pushChangeTo(subRepo, "master");
    assertThat(hasSubmodule(superRepo, "master", "subscribed-to-project")).isFalse();
}
#method_after
@Test
public void testSubscriptionFailOnWrongBranchACL() throws Exception {
    TestRepository<?> superRepo = createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project");
    allowMatchingSubmoduleSubscription("subscribed-to-project", "refs/heads/master", "super-project", "refs/heads/wrong-branch");
    pushChangeTo(subRepo, "master");
    createSubmoduleSubscription(superRepo, "master", "subscribed-to-project", "master");
    pushChangeTo(subRepo, "master");
    assertThat(hasSubmodule(superRepo, "master", "subscribed-to-project")).isFalse();
}
#end_block

#method_before
@Test
public void testSubscriptionInheritACL() throws Exception {
    createProjectWithPush("config-repo");
    createProjectWithPush("config-repo2", new Project.NameKey(name("config-repo")));
    TestRepository<?> superRepo = createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project", new Project.NameKey(name("config-repo2")));
    allowSubmoduleSubscription("config-repo", "refs/heads/*", "super-project", "refs/heads/*");
    pushChangeTo(subRepo, "master");
    createSubmoduleSubscription(superRepo, "master", "subscribed-to-project", "master");
    ObjectId subHEAD = pushChangeTo(subRepo, "master");
    expectToHaveSubmoduleState(superRepo, "master", "subscribed-to-project", subHEAD);
}
#method_after
@Test
public void testSubscriptionInheritACL() throws Exception {
    createProjectWithPush("config-repo");
    createProjectWithPush("config-repo2", new Project.NameKey(name("config-repo")));
    TestRepository<?> superRepo = createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project", new Project.NameKey(name("config-repo2")));
    allowMatchingSubmoduleSubscription("config-repo", "refs/heads/*", "super-project", "refs/heads/*");
    pushChangeTo(subRepo, "master");
    createSubmoduleSubscription(superRepo, "master", "subscribed-to-project", "master");
    ObjectId subHEAD = pushChangeTo(subRepo, "master");
    expectToHaveSubmoduleState(superRepo, "master", "subscribed-to-project", subHEAD);
}
#end_block

#method_before
@Test
public void testAllowedButNotSubscribed() throws Exception {
    TestRepository<?> superRepo = createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project");
    allowSubmoduleSubscription("subscribed-to-project", "refs/heads/master", "super-project", "refs/heads/master");
    pushChangeTo(subRepo, "master");
    subRepo.branch("HEAD").commit().insertChangeId().message("some change").add("b.txt", "b contents for testing").create();
    String refspec = "HEAD:refs/heads/master";
    PushResult r = Iterables.getOnlyElement(subRepo.git().push().setRemote("origin").setRefSpecs(new RefSpec(refspec)).call());
    assertThat(r.getMessages()).doesNotContain("error");
    assertThat(r.getRemoteUpdate("refs/heads/master").getStatus()).isEqualTo(RemoteRefUpdate.Status.OK);
    assertThat(hasSubmodule(superRepo, "master", "subscribed-to-project")).isFalse();
}
#method_after
@Test
public void testAllowedButNotSubscribed() throws Exception {
    TestRepository<?> superRepo = createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project");
    allowMatchingSubmoduleSubscription("subscribed-to-project", "refs/heads/master", "super-project", "refs/heads/master");
    pushChangeTo(subRepo, "master");
    subRepo.branch("HEAD").commit().insertChangeId().message("some change").add("b.txt", "b contents for testing").create();
    String refspec = "HEAD:refs/heads/master";
    PushResult r = Iterables.getOnlyElement(subRepo.git().push().setRemote("origin").setRefSpecs(new RefSpec(refspec)).call());
    assertThat(r.getMessages()).doesNotContain("error");
    assertThat(r.getRemoteUpdate("refs/heads/master").getStatus()).isEqualTo(RemoteRefUpdate.Status.OK);
    assertThat(hasSubmodule(superRepo, "master", "subscribed-to-project")).isFalse();
}
#end_block

#method_before
@Test
public void testSubscriptionDeepRelative() throws Exception {
    TestRepository<?> superRepo = createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("nested/subscribed-to-project");
    // master is allowed to be subscribed to any superprojects branch:
    allowSubmoduleSubscription("nested/subscribed-to-project", "refs/heads/master", "super-project", null);
    pushChangeTo(subRepo, "master");
    createRelativeSubmoduleSubscription(superRepo, "master", "../", "nested/subscribed-to-project", "master");
    ObjectId subHEAD = pushChangeTo(subRepo, "master");
    expectToHaveSubmoduleState(superRepo, "master", "nested/subscribed-to-project", subHEAD);
}
#method_after
@Test
public void testSubscriptionDeepRelative() throws Exception {
    TestRepository<?> superRepo = createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("nested/subscribed-to-project");
    // master is allowed to be subscribed to any superprojects branch:
    allowMatchingSubmoduleSubscription("nested/subscribed-to-project", "refs/heads/master", "super-project", null);
    pushChangeTo(subRepo, "master");
    createRelativeSubmoduleSubscription(superRepo, "master", "../", "nested/subscribed-to-project", "master");
    ObjectId subHEAD = pushChangeTo(subRepo, "master");
    expectToHaveSubmoduleState(superRepo, "master", "nested/subscribed-to-project", subHEAD);
}
#end_block

#method_before
public List<PatchSetApproval> addReviewers(ReviewDb db, ChangeNotes notes, ChangeUpdate update, LabelTypes labelTypes, Change change, Iterable<Account.Id> wantReviewers) throws OrmException {
    PatchSet.Id psId = change.currentPatchSetId();
    Collection<Account.Id> existingReviewers;
    if (migration.readChanges()) {
        // If using NoteDB, we only want reviewers in the REVIEWER state.
        existingReviewers = notes.load().getReviewers().byState(REVIEWER);
    } else {
        // Prior to NoteDB, we gather all reviewers regardless of state.
        existingReviewers = getReviewers(db, notes).all();
    }
    // Existing reviewers should include pending additions in the REVIEWER
    // state, taken from ChangeUpdate.
    existingReviewers = Lists.newArrayList(existingReviewers);
    for (Map.Entry<Account.Id, ReviewerStateInternal> entry : update.reviewers().entrySet()) {
        if (entry.getValue() == REVIEWER) {
            existingReviewers.add(entry.getKey());
        }
    }
    return addReviewers(db, update, labelTypes, change, psId, false, null, null, wantReviewers, existingReviewers);
}
#method_after
public List<PatchSetApproval> addReviewers(ReviewDb db, ChangeNotes notes, ChangeUpdate update, LabelTypes labelTypes, Change change, Iterable<Account.Id> wantReviewers) throws OrmException {
    PatchSet.Id psId = change.currentPatchSetId();
    Collection<Account.Id> existingReviewers;
    if (migration.readChanges()) {
        // If using NoteDB, we only want reviewers in the REVIEWER state.
        existingReviewers = notes.load().getReviewers().byState(REVIEWER);
    } else {
        // Prior to NoteDB, we gather all reviewers regardless of state.
        existingReviewers = getReviewers(db, notes).all();
    }
    // Existing reviewers should include pending additions in the REVIEWER
    // state, taken from ChangeUpdate.
    existingReviewers = Lists.newArrayList(existingReviewers);
    for (Map.Entry<Account.Id, ReviewerStateInternal> entry : update.getReviewers().entrySet()) {
        if (entry.getValue() == REVIEWER) {
            existingReviewers.add(entry.getKey());
        }
    }
    return addReviewers(db, update, labelTypes, change, psId, false, null, null, wantReviewers, existingReviewers);
}
#end_block

#method_before
private Collection<Account.Id> addCcs(ChangeUpdate update, Collection<Account.Id> wantCCs, ReviewerSet existingReviewers) {
    Set<Account.Id> need = new LinkedHashSet<>(wantCCs);
    need.removeAll(existingReviewers.all());
    need.removeAll(update.reviewers().keySet());
    for (Account.Id account : need) {
        update.putReviewer(account, CC);
    }
    return need;
}
#method_after
private Collection<Account.Id> addCcs(ChangeUpdate update, Collection<Account.Id> wantCCs, ReviewerSet existingReviewers) {
    Set<Account.Id> need = new LinkedHashSet<>(wantCCs);
    need.removeAll(existingReviewers.all());
    need.removeAll(update.getReviewers().keySet());
    for (Account.Id account : need) {
        update.putReviewer(account, CC);
    }
    return need;
}
#end_block

#method_before
@Override
public void starChange(String id) throws RestApiException {
    throw new NotImplementedException();
}
#method_after
@Override
public void starChange(String changeId) throws RestApiException {
    throw new NotImplementedException();
}
#end_block

#method_before
@Override
public void unstarChange(String id) throws RestApiException {
    throw new NotImplementedException();
}
#method_after
@Override
public void unstarChange(String changeId) throws RestApiException {
    throw new NotImplementedException();
}
#end_block

#method_before
@Override
public List<AgreementInfo> apply(AccountResource resource) throws AuthException {
    if (self.get() != resource.getUser()) {
        throw new AuthException("not allowed to get agreements");
    }
    List<AgreementInfo> results = Lists.newArrayList();
    Collection<ContributorAgreement> cas = projectCache.getAllProjects().getConfig().getContributorAgreements();
    for (ContributorAgreement ca : cas) {
        List<AccountGroup.UUID> groupIds = Lists.newArrayList();
        for (PermissionRule rule : ca.getAccepted()) {
            if ((rule.getAction() == Action.ALLOW) && (rule.getGroup() != null)) {
                if (rule.getGroup().getUUID() == null) {
                    log.warn("group \"" + rule.getGroup().getName() + "\" does not " + " exist, referenced in CLA \"" + ca.getName() + "\"");
                } else {
                    groupIds.add(new AccountGroup.UUID(rule.getGroup().getUUID().get()));
                }
            }
        }
        if (self.get().getEffectiveGroups().containsAnyOf(groupIds)) {
            AgreementInfo info = new AgreementInfo();
            info.name = ca.getName();
            info.description = ca.getDescription();
            info.url = ca.getAgreementUrl();
            results.add(info);
        }
    }
    return results;
}
#method_after
@Override
public List<AgreementInfo> apply(AccountResource resource) throws RestApiException {
    if (!agreementsEnabled) {
        throw new MethodNotAllowedException("contributor agreements disabled");
    }
    if (self.get() != resource.getUser()) {
        throw new AuthException("not allowed to get contributor agreements");
    }
    IdentifiedUser user = identifiedUserFactory.create(self.get().getAccountId());
    List<AgreementInfo> results = new ArrayList<>();
    Collection<ContributorAgreement> cas = projectCache.getAllProjects().getConfig().getContributorAgreements();
    for (ContributorAgreement ca : cas) {
        List<AccountGroup.UUID> groupIds = new ArrayList<>();
        for (PermissionRule rule : ca.getAccepted()) {
            if ((rule.getAction() == Action.ALLOW) && (rule.getGroup() != null)) {
                if (rule.getGroup().getUUID() != null) {
                    groupIds.add(rule.getGroup().getUUID());
                } else {
                    log.warn("group \"" + rule.getGroup().getName() + "\" does not " + " exist, referenced in CLA \"" + ca.getName() + "\"");
                }
            }
        }
        if (user.getEffectiveGroups().containsAnyOf(groupIds)) {
            AgreementInfo info = new AgreementInfo();
            info.name = ca.getName();
            info.description = ca.getDescription();
            info.url = ca.getAgreementUrl();
            results.add(info);
        }
    }
    return results;
}
#end_block

#method_before
@Override
protected void configure() {
    bind(AccountsCollection.class);
    bind(Capabilities.class);
    DynamicMap.mapOf(binder(), ACCOUNT_KIND);
    DynamicMap.mapOf(binder(), CAPABILITY_KIND);
    DynamicMap.mapOf(binder(), EMAIL_KIND);
    DynamicMap.mapOf(binder(), SSH_KEY_KIND);
    DynamicMap.mapOf(binder(), STARRED_CHANGE_KIND);
    put(ACCOUNT_KIND).to(PutAccount.class);
    get(ACCOUNT_KIND).to(GetAccount.class);
    get(ACCOUNT_KIND, "detail").to(GetDetail.class);
    get(ACCOUNT_KIND, "name").to(GetName.class);
    put(ACCOUNT_KIND, "name").to(PutName.class);
    delete(ACCOUNT_KIND, "name").to(PutName.class);
    get(ACCOUNT_KIND, "username").to(GetUsername.class);
    put(ACCOUNT_KIND, "username").to(PutUsername.class);
    get(ACCOUNT_KIND, "active").to(GetActive.class);
    put(ACCOUNT_KIND, "active").to(PutActive.class);
    delete(ACCOUNT_KIND, "active").to(DeleteActive.class);
    child(ACCOUNT_KIND, "emails").to(Emails.class);
    get(EMAIL_KIND).to(GetEmail.class);
    put(EMAIL_KIND).to(PutEmail.class);
    delete(EMAIL_KIND).to(DeleteEmail.class);
    put(EMAIL_KIND, "preferred").to(PutPreferred.class);
    get(ACCOUNT_KIND, "password.http").to(GetHttpPassword.class);
    put(ACCOUNT_KIND, "password.http").to(PutHttpPassword.class);
    delete(ACCOUNT_KIND, "password.http").to(PutHttpPassword.class);
    child(ACCOUNT_KIND, "sshkeys").to(SshKeys.class);
    post(ACCOUNT_KIND, "sshkeys").to(AddSshKey.class);
    get(SSH_KEY_KIND).to(GetSshKey.class);
    delete(SSH_KEY_KIND).to(DeleteSshKey.class);
    get(ACCOUNT_KIND, "avatar").to(GetAvatar.class);
    get(ACCOUNT_KIND, "avatar.change.url").to(GetAvatarChangeUrl.class);
    child(ACCOUNT_KIND, "capabilities").to(Capabilities.class);
    get(ACCOUNT_KIND, "groups").to(GetGroups.class);
    get(ACCOUNT_KIND, "preferences").to(GetPreferences.class);
    put(ACCOUNT_KIND, "preferences").to(SetPreferences.class);
    get(ACCOUNT_KIND, "preferences.diff").to(GetDiffPreferences.class);
    put(ACCOUNT_KIND, "preferences.diff").to(SetDiffPreferences.class);
    get(ACCOUNT_KIND, "preferences.edit").to(GetEditPreferences.class);
    put(ACCOUNT_KIND, "preferences.edit").to(SetEditPreferences.class);
    get(CAPABILITY_KIND).to(GetCapabilities.CheckOne.class);
    get(ACCOUNT_KIND, "agreements").to(GetAgreements.class);
    child(ACCOUNT_KIND, "starred.changes").to(StarredChanges.class);
    put(STARRED_CHANGE_KIND).to(StarredChanges.Put.class);
    delete(STARRED_CHANGE_KIND).to(StarredChanges.Delete.class);
    bind(StarredChanges.Create.class);
    factory(CreateAccount.Factory.class);
    factory(CreateEmail.Factory.class);
}
#method_after
@Override
protected void configure() {
    bind(AccountsCollection.class);
    bind(Capabilities.class);
    DynamicMap.mapOf(binder(), ACCOUNT_KIND);
    DynamicMap.mapOf(binder(), CAPABILITY_KIND);
    DynamicMap.mapOf(binder(), EMAIL_KIND);
    DynamicMap.mapOf(binder(), SSH_KEY_KIND);
    DynamicMap.mapOf(binder(), STARRED_CHANGE_KIND);
    DynamicMap.mapOf(binder(), STAR_KIND);
    put(ACCOUNT_KIND).to(PutAccount.class);
    get(ACCOUNT_KIND).to(GetAccount.class);
    get(ACCOUNT_KIND, "detail").to(GetDetail.class);
    get(ACCOUNT_KIND, "name").to(GetName.class);
    put(ACCOUNT_KIND, "name").to(PutName.class);
    delete(ACCOUNT_KIND, "name").to(PutName.class);
    get(ACCOUNT_KIND, "username").to(GetUsername.class);
    put(ACCOUNT_KIND, "username").to(PutUsername.class);
    get(ACCOUNT_KIND, "active").to(GetActive.class);
    put(ACCOUNT_KIND, "active").to(PutActive.class);
    delete(ACCOUNT_KIND, "active").to(DeleteActive.class);
    child(ACCOUNT_KIND, "emails").to(Emails.class);
    get(EMAIL_KIND).to(GetEmail.class);
    put(EMAIL_KIND).to(PutEmail.class);
    delete(EMAIL_KIND).to(DeleteEmail.class);
    put(EMAIL_KIND, "preferred").to(PutPreferred.class);
    get(ACCOUNT_KIND, "password.http").to(GetHttpPassword.class);
    put(ACCOUNT_KIND, "password.http").to(PutHttpPassword.class);
    delete(ACCOUNT_KIND, "password.http").to(PutHttpPassword.class);
    child(ACCOUNT_KIND, "sshkeys").to(SshKeys.class);
    post(ACCOUNT_KIND, "sshkeys").to(AddSshKey.class);
    get(ACCOUNT_KIND, "watched.projects").to(GetWatchedProjects.class);
    post(ACCOUNT_KIND, "watched.projects").to(PostWatchedProjects.class);
    post(ACCOUNT_KIND, "watched.projects:delete").to(DeleteWatchedProjects.class);
    get(SSH_KEY_KIND).to(GetSshKey.class);
    delete(SSH_KEY_KIND).to(DeleteSshKey.class);
    get(ACCOUNT_KIND, "oauthtoken").to(GetOAuthToken.class);
    get(ACCOUNT_KIND, "avatar").to(GetAvatar.class);
    get(ACCOUNT_KIND, "avatar.change.url").to(GetAvatarChangeUrl.class);
    child(ACCOUNT_KIND, "capabilities").to(Capabilities.class);
    get(ACCOUNT_KIND, "groups").to(GetGroups.class);
    get(ACCOUNT_KIND, "preferences").to(GetPreferences.class);
    put(ACCOUNT_KIND, "preferences").to(SetPreferences.class);
    get(ACCOUNT_KIND, "preferences.diff").to(GetDiffPreferences.class);
    put(ACCOUNT_KIND, "preferences.diff").to(SetDiffPreferences.class);
    get(ACCOUNT_KIND, "preferences.edit").to(GetEditPreferences.class);
    put(ACCOUNT_KIND, "preferences.edit").to(SetEditPreferences.class);
    get(CAPABILITY_KIND).to(GetCapabilities.CheckOne.class);
    get(ACCOUNT_KIND, "agreements").to(GetAgreements.class);
    put(ACCOUNT_KIND, "agreements").to(PutAgreement.class);
    child(ACCOUNT_KIND, "starred.changes").to(StarredChanges.class);
    put(STARRED_CHANGE_KIND).to(StarredChanges.Put.class);
    delete(STARRED_CHANGE_KIND).to(StarredChanges.Delete.class);
    bind(StarredChanges.Create.class);
    child(ACCOUNT_KIND, "stars.changes").to(Stars.class);
    get(STAR_KIND).to(Stars.Get.class);
    post(STAR_KIND).to(Stars.Post.class);
    factory(CreateAccount.Factory.class);
    factory(CreateEmail.Factory.class);
}
#end_block

#method_before
@Override
public void starChange(String id) throws RestApiException {
    try {
        ChangeResource rsrc = changes.parse(TopLevelResource.INSTANCE, IdString.fromUrl(id));
        starredChangesCreate.setChange(rsrc);
        starredChangesCreate.apply(account, new StarredChanges.EmptyInput());
    } catch (OrmException | IOException e) {
        throw new RestApiException("Cannot star change", e);
    }
}
#method_after
@Override
public void starChange(String changeId) throws RestApiException {
    try {
        ChangeResource rsrc = changes.parse(TopLevelResource.INSTANCE, IdString.fromUrl(changeId));
        starredChangesCreate.setChange(rsrc);
        starredChangesCreate.apply(account, new StarredChanges.EmptyInput());
    } catch (OrmException | IOException e) {
        throw new RestApiException("Cannot star change", e);
    }
}
#end_block

#method_before
@Override
public void unstarChange(String id) throws RestApiException {
    try {
        ChangeResource rsrc = changes.parse(TopLevelResource.INSTANCE, IdString.fromUrl(id));
        AccountResource.StarredChange starredChange = new AccountResource.StarredChange(account.getUser(), rsrc);
        starredChangesDelete.apply(starredChange, new StarredChanges.EmptyInput());
    } catch (OrmException | IOException e) {
        throw new RestApiException("Cannot unstar change", e);
    }
}
#method_after
@Override
public void unstarChange(String changeId) throws RestApiException {
    try {
        ChangeResource rsrc = changes.parse(TopLevelResource.INSTANCE, IdString.fromUrl(changeId));
        AccountResource.StarredChange starredChange = new AccountResource.StarredChange(account.getUser(), rsrc);
        starredChangesDelete.apply(starredChange, new StarredChanges.EmptyInput());
    } catch (OrmException | IOException e) {
        throw new RestApiException("Cannot unstar change", e);
    }
}
#end_block

#method_before
@Override
public void addEmail(EmailInput input) throws RestApiException {
    AccountResource.Email rsrc = new AccountResource.Email(account.getUser(), input.email);
    try {
        createEmailFactory.create(input.email).apply(rsrc, input);
    } catch (EmailException | OrmException e) {
        throw new RestApiException("Cannot add email", e);
    }
}
#method_after
@Override
public void addEmail(EmailInput input) throws RestApiException {
    AccountResource.Email rsrc = new AccountResource.Email(account.getUser(), input.email);
    try {
        createEmailFactory.create(input.email).apply(rsrc, input);
    } catch (EmailException | OrmException | IOException e) {
        throw new RestApiException("Cannot add email", e);
    }
}
#end_block

#method_before
@Override
public List<SshKeyInfo> listSshKeys() throws RestApiException {
    try {
        return getSshKeys.apply(account);
    } catch (OrmException e) {
        throw new RestApiException("Cannot list SSH keys", e);
    }
}
#method_after
@Override
public List<SshKeyInfo> listSshKeys() throws RestApiException {
    try {
        return getSshKeys.apply(account);
    } catch (OrmException | IOException | ConfigInvalidException e) {
        throw new RestApiException("Cannot list SSH keys", e);
    }
}
#end_block

#method_before
@Override
public SshKeyInfo addSshKey(String key) throws RestApiException {
    AddSshKey.Input in = new AddSshKey.Input();
    in.raw = RawInputUtil.create(key);
    try {
        return addSshKey.apply(account, in).value();
    } catch (OrmException | IOException e) {
        throw new RestApiException("Cannot add SSH key", e);
    }
}
#method_after
@Override
public SshKeyInfo addSshKey(String key) throws RestApiException {
    AddSshKey.Input in = new AddSshKey.Input();
    in.raw = RawInputUtil.create(key);
    try {
        return addSshKey.apply(account, in).value();
    } catch (OrmException | IOException | ConfigInvalidException e) {
        throw new RestApiException("Cannot add SSH key", e);
    }
}
#end_block

#method_before
@After
public void cleanUp() throws Exception {
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers);
    try {
        fetch(allUsersRepo, RefNames.REFS_USERS_DEFAULT + ":defaults");
    } catch (TransportException e) {
        if (e.getMessage().equals("Remote does not have " + RefNames.REFS_USERS_DEFAULT + " available for fetch.")) {
            return;
        }
        throw e;
    }
    allUsersRepo.reset("defaults");
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), allUsersRepo, "Delete default preferences", VersionedAccountPreferences.PREFERENCES, "");
    push.rm(RefNames.REFS_USERS_DEFAULT).assertOkStatus();
}
#method_after
@After
public void cleanUp() throws Exception {
    try (Repository git = repoManager.openRepository(allUsers)) {
        if (git.exactRef(RefNames.REFS_USERS_DEFAULT) != null) {
            RefUpdate u = git.updateRef(RefNames.REFS_USERS_DEFAULT);
            u.setForceUpdate(true);
            assertThat(u.delete()).isEqualTo(RefUpdate.Result.FORCED);
        }
    }
    accountCache.evictAll();
}
#end_block

#method_before
private static AccountState newState(Account account) {
    return new AccountState(account, ImmutableSet.<AccountGroup.UUID>of(), ImmutableSet.<AccountExternalId>of(), ImmutableSet.<AccountProjectWatch>of());
}
#method_after
private static AccountState newState(Account account) {
    return new AccountState(account, ImmutableSet.<AccountGroup.UUID>of(), ImmutableSet.<AccountExternalId>of(), new HashMap<ProjectWatchKey, Set<NotifyType>>());
}
#end_block

#method_before
@After
public void cleanUp() throws Exception {
    gApi.accounts().id(user42.getId().toString()).setPreferences(GeneralPreferencesInfo.defaults());
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers);
    try {
        fetch(allUsersRepo, RefNames.REFS_USERS_DEFAULT + ":defaults");
    } catch (TransportException e) {
        if (e.getMessage().equals("Remote does not have " + RefNames.REFS_USERS_DEFAULT + " available for fetch.")) {
            return;
        }
        throw e;
    }
    allUsersRepo.reset("defaults");
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), allUsersRepo, "Delete default preferences", VersionedAccountPreferences.PREFERENCES, "");
    push.rm(RefNames.REFS_USERS_DEFAULT).assertOkStatus();
}
#method_after
@After
public void cleanUp() throws Exception {
    gApi.accounts().id(user42.getId().toString()).setPreferences(GeneralPreferencesInfo.defaults());
    try (Repository git = repoManager.openRepository(allUsers)) {
        if (git.exactRef(RefNames.REFS_USERS_DEFAULT) != null) {
            RefUpdate u = git.updateRef(RefNames.REFS_USERS_DEFAULT);
            u.setForceUpdate(true);
            assertThat(u.delete()).isEqualTo(RefUpdate.Result.FORCED);
        }
    }
    accountCache.evictAll();
}
#end_block

#method_before
private static AccountState missing(Account.Id accountId) {
    Account account = new Account(accountId, TimeUtil.nowTs());
    account.setActive(false);
    Collection<AccountExternalId> ids = Collections.emptySet();
    Collection<AccountProjectWatch> projectWatches = Collections.emptySet();
    Set<AccountGroup.UUID> anon = ImmutableSet.of();
    return new AccountState(account, anon, ids, projectWatches);
}
#method_after
private static AccountState missing(Account.Id accountId) {
    Account account = new Account(accountId, TimeUtil.nowTs());
    account.setActive(false);
    Collection<AccountExternalId> ids = Collections.emptySet();
    Set<AccountGroup.UUID> anon = ImmutableSet.of();
    return new AccountState(account, anon, ids, new HashMap<ProjectWatchKey, Set<NotifyType>>());
}
#end_block

#method_before
private AccountState load(final ReviewDb db, final Account.Id who) throws OrmException {
    Account account = db.accounts().get(who);
    if (account == null) {
        // Account no longer exists? They are anonymous.
        return missing(who);
    }
    Collection<AccountExternalId> externalIds = Collections.unmodifiableCollection(db.accountExternalIds().byAccount(who).toList());
    Set<AccountGroup.UUID> internalGroups = new HashSet<>();
    for (AccountGroupMember g : db.accountGroupMembers().byAccount(who)) {
        final AccountGroup.Id groupId = g.getAccountGroupId();
        final AccountGroup group = groupCache.get(groupId);
        if (group != null && group.getGroupUUID() != null) {
            internalGroups.add(group.getGroupUUID());
        }
    }
    internalGroups = Collections.unmodifiableSet(internalGroups);
    try {
        account.setGeneralPreferences(loader.load(who));
    } catch (IOException | ConfigInvalidException e) {
        log.warn("Cannot load GeneralPreferences for " + who + " (using default)", e);
        account.setGeneralPreferences(GeneralPreferencesInfo.defaults());
    }
    Collection<AccountProjectWatch> projectWatches = Collections.unmodifiableCollection(db.accountProjectWatches().byAccount(who).toList());
    return new AccountState(account, internalGroups, externalIds, projectWatches);
}
#method_after
private AccountState load(final ReviewDb db, final Account.Id who) throws OrmException, IOException, ConfigInvalidException {
    Account account = db.accounts().get(who);
    if (account == null) {
        // Account no longer exists? They are anonymous.
        return missing(who);
    }
    Collection<AccountExternalId> externalIds = Collections.unmodifiableCollection(db.accountExternalIds().byAccount(who).toList());
    Set<AccountGroup.UUID> internalGroups = new HashSet<>();
    for (AccountGroupMember g : db.accountGroupMembers().byAccount(who)) {
        final AccountGroup.Id groupId = g.getAccountGroupId();
        final AccountGroup group = groupCache.get(groupId);
        if (group != null && group.getGroupUUID() != null) {
            internalGroups.add(group.getGroupUUID());
        }
    }
    internalGroups = Collections.unmodifiableSet(internalGroups);
    try {
        account.setGeneralPreferences(loader.load(who));
    } catch (IOException | ConfigInvalidException e) {
        log.warn("Cannot load GeneralPreferences for " + who + " (using default)", e);
        account.setGeneralPreferences(GeneralPreferencesInfo.defaults());
    }
    Map<ProjectWatchKey, Set<NotifyType>> projectWatches = readFromGit ? watchConfig.get().getProjectWatches(who) : GetWatchedProjects.readProjectWatchesFromDb(db, who);
    return new AccountState(account, internalGroups, externalIds, projectWatches);
}
#end_block

#method_before
@Override
public Optional<Account.Id> load(String username) throws Exception {
    try (ReviewDb db = schema.open()) {
        final AccountExternalId.Key key = new // 
        AccountExternalId.Key(// 
        AccountExternalId.SCHEME_USERNAME, username);
        final AccountExternalId id = db.accountExternalIds().get(key);
        if (id != null) {
            return Optional.of(id.getAccountId());
        }
        return Optional.absent();
    }
}
#method_after
@Override
public Optional<Account.Id> load(String username) throws Exception {
    AccountExternalId.Key key = new // 
    AccountExternalId.Key(// 
    AccountExternalId.SCHEME_USERNAME, username);
    if (accountIndexes.getSearchIndex() != null) {
        AccountState accountState = accountQueryProvider.get().oneByExternalId(key.get());
        return accountState != null ? Optional.of(accountState.getAccount().getId()) : Optional.<Account.Id>absent();
    }
    try (ReviewDb db = schema.open()) {
        AccountExternalId id = db.accountExternalIds().get(key);
        if (id != null) {
            return Optional.of(id.getAccountId());
        }
        return Optional.absent();
    }
}
#end_block

#method_before
@Override
public void postUpdate(Context ctx) throws OrmException {
    try {
        ReplyToChangeSender cm = abandonedSenderFactory.create(ctx.getProject(), change.getId());
        if (account != null) {
            cm.setFrom(account.getId());
        }
        cm.setChangeMessage(message.getMessage(), ctx.getWhen());
        cm.setNotify(notifyHandling);
        cm.send();
    } catch (Exception e) {
        log.error("Cannot email update for change " + change.getId(), e);
    }
    changeAbandoned.fire(change, patchSet, account, msgTxt, ctx.getWhen());
}
#method_after
@Override
public void postUpdate(Context ctx) throws OrmException {
    try {
        ReplyToChangeSender cm = abandonedSenderFactory.create(ctx.getProject(), change.getId());
        if (account != null) {
            cm.setFrom(account.getId());
        }
        cm.setChangeMessage(message.getMessage(), ctx.getWhen());
        cm.setNotify(notifyHandling);
        cm.send();
    } catch (Exception e) {
        log.error("Cannot email update for change " + change.getId(), e);
    }
    changeAbandoned.fire(change, patchSet, account, msgTxt, ctx.getWhen(), notifyHandling);
}
#end_block

#method_before
private Change insertPatchSet(ChangeEdit edit, Change change, Repository repo, RevWalk rw, ObjectInserter oi, PatchSet basePatchSet, RevCommit squashed) throws NoSuchProjectException, RestApiException, UpdateException, IOException {
    RefControl ctl = projectControlFactory.controlFor(change.getProject(), edit.getUser()).controlForRef(change.getDest());
    PatchSet.Id psId = ChangeUtil.nextPatchSetId(repo, change.currentPatchSetId());
    PatchSetInserter inserter = patchSetInserterFactory.create(ctl, psId, squashed);
    inserter.setUploader(ctl.getUser().getAccountId());
    StringBuilder message = new StringBuilder("Patch Set ").append(inserter.getPatchSetId().get()).append(": ");
    ProjectState project = projectCache.get(change.getDest().getParentKey());
    // Previously checked that the base patch set is the current patch set.
    ObjectId prior = ObjectId.fromString(basePatchSet.getRevision().get());
    ChangeKind kind = changeKindCache.getChangeKind(project, repo, prior, squashed);
    if (kind == ChangeKind.NO_CODE_CHANGE) {
        message.append("Commit message was updated.");
    } else {
        message.append("Published edit on patch set ").append(basePatchSet.getPatchSetId()).append(".");
    }
    try (BatchUpdate bu = updateFactory.create(db.get(), change.getProject(), ctl.getUser(), TimeUtil.nowTs())) {
        bu.setRepository(repo, rw, oi);
        bu.addOp(change.getId(), inserter.setDraft(change.getStatus() == Status.DRAFT || basePatchSet.isDraft()).setMessage(message.toString()));
        bu.execute();
    }
    return inserter.getChange();
}
#method_after
private Change insertPatchSet(ChangeEdit edit, Change change, Repository repo, RevWalk rw, ObjectInserter oi, PatchSet basePatchSet, RevCommit squashed) throws NoSuchProjectException, RestApiException, UpdateException, IOException {
    RefControl ctl = projectControlFactory.controlFor(change.getProject(), edit.getUser()).controlForRef(change.getDest());
    PatchSet.Id psId = ChangeUtil.nextPatchSetId(repo, change.currentPatchSetId());
    PatchSetInserter inserter = patchSetInserterFactory.create(ctl, psId, squashed);
    inserter.setUploader(edit.getUser().getAccountId());
    StringBuilder message = new StringBuilder("Patch Set ").append(inserter.getPatchSetId().get()).append(": ");
    ProjectState project = projectCache.get(change.getDest().getParentKey());
    // Previously checked that the base patch set is the current patch set.
    ObjectId prior = ObjectId.fromString(basePatchSet.getRevision().get());
    ChangeKind kind = changeKindCache.getChangeKind(project, repo, prior, squashed);
    if (kind == ChangeKind.NO_CODE_CHANGE) {
        message.append("Commit message was updated.");
    } else {
        message.append("Published edit on patch set ").append(basePatchSet.getPatchSetId()).append(".");
    }
    try (BatchUpdate bu = updateFactory.create(db.get(), change.getProject(), ctl.getUser(), TimeUtil.nowTs())) {
        bu.setRepository(repo, rw, oi);
        bu.addOp(change.getId(), inserter.setDraft(change.getStatus() == Status.DRAFT || basePatchSet.isDraft()).setMessage(message.toString()));
        bu.execute();
    }
    return inserter.getChange();
}
#end_block

#method_before
@Test
public void testSubmoduleSubjectCommitMessage() throws Exception {
    TestRepository<?> superRepo = createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project");
    allowSubmoduleSubscription("subscribed-to-project", "refs/heads/master", "super-project", "refs/heads/master");
    pushChangeTo(subRepo, "master");
    createSubmoduleSubscription(superRepo, "master", "subscribed-to-project", "master");
    ObjectId subHEAD = pushChangeTo(subRepo, "master");
    // The first update doesn't include the rev log
    RevWalk rw = subRepo.getRevWalk();
    expectToHaveCommitMessage(superRepo, "master", "Update git submodules\n\n" + "* Update " + name("subscribed-to-project") + " from branch 'master'");
    // The next commit should generate only its commit message,
    // omitting previous commit logs
    subHEAD = pushChangeTo(subRepo, "master");
    RevCommit subCommitMsg = rw.parseCommit(subHEAD);
    expectToHaveCommitMessage(superRepo, "master", "Update git submodules\n\n" + "* Update " + name("subscribed-to-project") + " from branch 'master'" + "\n  - " + subCommitMsg.getShortMessage());
}
#method_after
@Test
@GerritConfig(name = "submodule.verboseSuperprojectUpdate", value = "SUBJECT_ONLY")
public void testSubmoduleSubjectCommitMessage() throws Exception {
    TestRepository<?> superRepo = createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project");
    allowSubmoduleSubscription("subscribed-to-project", "refs/heads/master", "super-project", "refs/heads/master");
    pushChangeTo(subRepo, "master");
    createSubmoduleSubscription(superRepo, "master", "subscribed-to-project", "master");
    ObjectId subHEAD = pushChangeTo(subRepo, "master");
    // The first update doesn't include the rev log
    RevWalk rw = subRepo.getRevWalk();
    expectToHaveCommitMessage(superRepo, "master", "Update git submodules\n\n" + "* Update " + name("subscribed-to-project") + " from branch 'master'");
    // The next commit should generate only its commit message,
    // omitting previous commit logs
    subHEAD = pushChangeTo(subRepo, "master");
    RevCommit subCommitMsg = rw.parseCommit(subHEAD);
    expectToHaveCommitMessage(superRepo, "master", "Update git submodules\n\n" + "* Update " + name("subscribed-to-project") + " from branch 'master'" + "\n  - " + subCommitMsg.getShortMessage());
}
#end_block

#method_before
@Test
@GerritConfig(name = "submodule.verboseSuperprojectUpdate", value = "true")
public void testSubmoduleCommitMessage() throws Exception {
    TestRepository<?> superRepo = createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project");
    allowSubmoduleSubscription("subscribed-to-project", "refs/heads/master", "super-project", "refs/heads/master");
    pushChangeTo(subRepo, "master");
    createSubmoduleSubscription(superRepo, "master", "subscribed-to-project", "master");
    ObjectId subHEAD = pushChangeTo(subRepo, "master");
    // The first update doesn't include the rev log
    RevWalk rw = subRepo.getRevWalk();
    expectToHaveCommitMessage(superRepo, "master", "Update git submodules\n\n" + "* Update " + name("subscribed-to-project") + " from branch 'master'");
    // The next commit should generate only its commit message,
    // omitting previous commit logs
    subHEAD = pushChangeTo(subRepo, "master");
    RevCommit subCommitMsg = rw.parseCommit(subHEAD);
    expectToHaveCommitMessage(superRepo, "master", "Update git submodules\n\n" + "* Update " + name("subscribed-to-project") + " from branch 'master'" + "\n  - " + subCommitMsg.getFullMessage().replace("\n", "\n    "));
}
#method_after
@Test
public void testSubmoduleCommitMessage() throws Exception {
    TestRepository<?> superRepo = createProjectWithPush("super-project");
    TestRepository<?> subRepo = createProjectWithPush("subscribed-to-project");
    allowSubmoduleSubscription("subscribed-to-project", "refs/heads/master", "super-project", "refs/heads/master");
    pushChangeTo(subRepo, "master");
    createSubmoduleSubscription(superRepo, "master", "subscribed-to-project", "master");
    ObjectId subHEAD = pushChangeTo(subRepo, "master");
    // The first update doesn't include the rev log
    RevWalk rw = subRepo.getRevWalk();
    expectToHaveCommitMessage(superRepo, "master", "Update git submodules\n\n" + "* Update " + name("subscribed-to-project") + " from branch 'master'");
    // The next commit should generate only its commit message,
    // omitting previous commit logs
    subHEAD = pushChangeTo(subRepo, "master");
    RevCommit subCommitMsg = rw.parseCommit(subHEAD);
    expectToHaveCommitMessage(superRepo, "master", "Update git submodules\n\n" + "* Update " + name("subscribed-to-project") + " from branch 'master'" + "\n  - " + subCommitMsg.getFullMessage().replace("\n", "\n    "));
}
#end_block

#method_before
public CodeReviewCommit composeGitlinksCommit(final Branch.NameKey subscriber) throws IOException, SubmoduleException {
    OpenRepo or;
    try {
        or = orm.openRepo(subscriber.getParentKey(), false);
    } catch (NoSuchProjectException | IOException e) {
        throw new SubmoduleException("Cannot access superproject", e);
    }
    CodeReviewCommit currentCommit;
    Ref r = or.repo.exactRef(subscriber.get());
    if (r == null) {
        throw new SubmoduleException("The branch was probably deleted from the subscriber repository");
    }
    currentCommit = or.rw.parseCommit(r.getObjectId());
    StringBuilder msgbuf = new StringBuilder("");
    PersonIdent author = null;
    DirCache dc = readTree(or.rw, currentCommit);
    DirCacheEditor ed = dc.editor();
    for (SubmoduleSubscription s : targets.get(subscriber)) {
        RevCommit newCommit = updateSubmodule(dc, ed, msgbuf, s);
        if (newCommit != null) {
            if (author == null) {
                author = newCommit.getAuthorIdent();
            } else if (!author.equals(newCommit.getAuthorIdent())) {
                author = myIdent;
            }
        }
    }
    ed.finish();
    ObjectId newTreeId = dc.writeTree(or.ins);
    // Gitlinks are already in the branch, return null
    if (newTreeId.equals(currentCommit.getTree())) {
        return null;
    }
    CommitBuilder commit = new CommitBuilder();
    commit.setTreeId(newTreeId);
    commit.setParentId(currentCommit);
    StringBuilder commitMsg = new StringBuilder("Update git submodules\n\n");
    if (!verboseSuperProject.equals(VerboseSuperprojectUpdate.FALSE)) {
        commitMsg.append(msgbuf);
    }
    commit.setMessage(commitMsg.toString());
    commit.setAuthor(author);
    commit.setCommitter(myIdent);
    ObjectId id = or.ins.insert(commit);
    return or.rw.parseCommit(id);
}
#method_after
public CodeReviewCommit composeGitlinksCommit(final Branch.NameKey subscriber) throws IOException, SubmoduleException {
    OpenRepo or;
    try {
        or = orm.openRepo(subscriber.getParentKey(), false);
    } catch (NoSuchProjectException | IOException e) {
        throw new SubmoduleException("Cannot access superproject", e);
    }
    CodeReviewCommit currentCommit;
    Ref r = or.repo.exactRef(subscriber.get());
    if (r == null) {
        throw new SubmoduleException("The branch was probably deleted from the subscriber repository");
    }
    currentCommit = or.rw.parseCommit(r.getObjectId());
    StringBuilder msgbuf = new StringBuilder("");
    PersonIdent author = null;
    DirCache dc = readTree(or.rw, currentCommit);
    DirCacheEditor ed = dc.editor();
    for (SubmoduleSubscription s : targets.get(subscriber)) {
        RevCommit newCommit = updateSubmodule(dc, ed, msgbuf, s);
        if (newCommit != null) {
            if (author == null) {
                author = newCommit.getAuthorIdent();
            } else if (!author.equals(newCommit.getAuthorIdent())) {
                author = myIdent;
            }
        }
    }
    ed.finish();
    ObjectId newTreeId = dc.writeTree(or.ins);
    // Gitlinks are already in the branch, return null
    if (newTreeId.equals(currentCommit.getTree())) {
        return null;
    }
    CommitBuilder commit = new CommitBuilder();
    commit.setTreeId(newTreeId);
    commit.setParentId(currentCommit);
    StringBuilder commitMsg = new StringBuilder("Update git submodules\n\n");
    if (verboseSuperProject != VerboseSuperprojectUpdate.FALSE) {
        commitMsg.append(msgbuf);
    }
    commit.setMessage(commitMsg.toString());
    commit.setAuthor(author);
    commit.setCommitter(myIdent);
    ObjectId id = or.ins.insert(commit);
    return or.rw.parseCommit(id);
}
#end_block

#method_before
public CodeReviewCommit composeGitlinksCommit(final Branch.NameKey subscriber, CodeReviewCommit currentCommit) throws IOException, SubmoduleException {
    OpenRepo or;
    try {
        or = orm.openRepo(subscriber.getParentKey(), false);
    } catch (NoSuchProjectException | IOException e) {
        throw new SubmoduleException("Cannot access superproject", e);
    }
    StringBuilder msgbuf = new StringBuilder("");
    DirCache dc = readTree(or.rw, currentCommit);
    DirCacheEditor ed = dc.editor();
    for (SubmoduleSubscription s : targets.get(subscriber)) {
        updateSubmodule(dc, ed, msgbuf, s);
    }
    ed.finish();
    ObjectId newTreeId = dc.writeTree(or.ins);
    // Gitlinks are already updated, just return the commit
    if (newTreeId.equals(currentCommit.getTree())) {
        return currentCommit;
    }
    or.rw.parseBody(currentCommit);
    CommitBuilder commit = new CommitBuilder();
    commit.setTreeId(newTreeId);
    commit.setParentIds(currentCommit.getParents());
    if (!verboseSuperProject.equals(VerboseSuperprojectUpdate.FALSE)) {
        commit.setMessage(currentCommit.getFullMessage() + "\n\n*submodules:\n" + msgbuf.toString());
    } else {
        commit.setMessage(currentCommit.getFullMessage());
    }
    commit.setAuthor(currentCommit.getAuthorIdent());
    commit.setCommitter(myIdent);
    ObjectId id = or.ins.insert(commit);
    return or.rw.parseCommit(id);
}
#method_after
public CodeReviewCommit composeGitlinksCommit(final Branch.NameKey subscriber, CodeReviewCommit currentCommit) throws IOException, SubmoduleException {
    OpenRepo or;
    try {
        or = orm.openRepo(subscriber.getParentKey(), false);
    } catch (NoSuchProjectException | IOException e) {
        throw new SubmoduleException("Cannot access superproject", e);
    }
    StringBuilder msgbuf = new StringBuilder("");
    DirCache dc = readTree(or.rw, currentCommit);
    DirCacheEditor ed = dc.editor();
    for (SubmoduleSubscription s : targets.get(subscriber)) {
        updateSubmodule(dc, ed, msgbuf, s);
    }
    ed.finish();
    ObjectId newTreeId = dc.writeTree(or.ins);
    // Gitlinks are already updated, just return the commit
    if (newTreeId.equals(currentCommit.getTree())) {
        return currentCommit;
    }
    or.rw.parseBody(currentCommit);
    CommitBuilder commit = new CommitBuilder();
    commit.setTreeId(newTreeId);
    commit.setParentIds(currentCommit.getParents());
    if (verboseSuperProject != VerboseSuperprojectUpdate.FALSE) {
        // TODO:czhen handle cherrypick footer
        commit.setMessage(currentCommit.getFullMessage() + "\n\n*submodules:\n" + msgbuf.toString());
    } else {
        commit.setMessage(currentCommit.getFullMessage());
    }
    commit.setAuthor(currentCommit.getAuthorIdent());
    commit.setCommitter(myIdent);
    ObjectId id = or.ins.insert(commit);
    return or.rw.parseCommit(id);
}
#end_block

#method_before
private RevCommit updateSubmodule(DirCache dc, DirCacheEditor ed, StringBuilder msgbuf, final SubmoduleSubscription s) throws SubmoduleException, IOException {
    OpenRepo subOr;
    try {
        subOr = orm.openRepo(s.getSubmodule().getParentKey(), false);
    } catch (NoSuchProjectException | IOException e) {
        throw new SubmoduleException("Cannot access submodule", e);
    }
    DirCacheEntry dce = dc.getEntry(s.getPath());
    RevCommit oldCommit = null;
    if (dce != null) {
        if (!dce.getFileMode().equals(FileMode.GITLINK)) {
            String errMsg = "Requested to update gitlink " + s.getPath() + " in " + s.getSubmodule().getParentKey().get() + " but entry " + "doesn't have gitlink file mode.";
            throw new SubmoduleException(errMsg);
        }
        oldCommit = subOr.rw.parseCommit(dce.getObjectId());
    }
    final RevCommit newCommit;
    if (branchTips.containsKey(s.getSubmodule())) {
        newCommit = branchTips.get(s.getSubmodule());
    } else {
        Ref ref = subOr.repo.getRefDatabase().exactRef(s.getSubmodule().get());
        if (ref == null) {
            ed.add(new DeletePath(s.getPath()));
            return null;
        }
        newCommit = subOr.rw.parseCommit(ref.getObjectId());
    }
    if (Objects.equals(newCommit, oldCommit)) {
        // gitlink have already been updated for this submodule
        return null;
    }
    ed.add(new PathEdit(s.getPath()) {

        @Override
        public void apply(DirCacheEntry ent) {
            ent.setFileMode(FileMode.GITLINK);
            ent.setObjectId(newCommit.getId());
        }
    });
    if (!verboseSuperProject.equals(VerboseSuperprojectUpdate.FALSE)) {
        createSubmoduleCommitMsg(msgbuf, s, subOr, newCommit, oldCommit);
    }
    subOr.rw.parseBody(newCommit);
    return newCommit;
}
#method_after
private RevCommit updateSubmodule(DirCache dc, DirCacheEditor ed, StringBuilder msgbuf, final SubmoduleSubscription s) throws SubmoduleException, IOException {
    OpenRepo subOr;
    try {
        subOr = orm.openRepo(s.getSubmodule().getParentKey(), false);
    } catch (NoSuchProjectException | IOException e) {
        throw new SubmoduleException("Cannot access submodule", e);
    }
    DirCacheEntry dce = dc.getEntry(s.getPath());
    RevCommit oldCommit = null;
    if (dce != null) {
        if (!dce.getFileMode().equals(FileMode.GITLINK)) {
            String errMsg = "Requested to update gitlink " + s.getPath() + " in " + s.getSubmodule().getParentKey().get() + " but entry " + "doesn't have gitlink file mode.";
            throw new SubmoduleException(errMsg);
        }
        oldCommit = subOr.rw.parseCommit(dce.getObjectId());
    }
    final RevCommit newCommit;
    if (branchTips.containsKey(s.getSubmodule())) {
        newCommit = branchTips.get(s.getSubmodule());
    } else {
        Ref ref = subOr.repo.getRefDatabase().exactRef(s.getSubmodule().get());
        if (ref == null) {
            ed.add(new DeletePath(s.getPath()));
            return null;
        }
        newCommit = subOr.rw.parseCommit(ref.getObjectId());
    }
    if (Objects.equals(newCommit, oldCommit)) {
        // gitlink have already been updated for this submodule
        return null;
    }
    ed.add(new PathEdit(s.getPath()) {

        @Override
        public void apply(DirCacheEntry ent) {
            ent.setFileMode(FileMode.GITLINK);
            ent.setObjectId(newCommit.getId());
        }
    });
    if (verboseSuperProject != VerboseSuperprojectUpdate.FALSE) {
        createSubmoduleCommitMsg(msgbuf, s, subOr, newCommit, oldCommit);
    }
    subOr.rw.parseBody(newCommit);
    return newCommit;
}
#end_block

#method_before
private void createSubmoduleCommitMsg(StringBuilder msgbuf, SubmoduleSubscription s, OpenRepo subOr, RevCommit newCommit, RevCommit oldCommit) throws SubmoduleException {
    msgbuf.append("* Update " + s.getPath());
    msgbuf.append(" from branch '" + s.getSubmodule().getShortName() + "'");
    // newly created submodule gitlink, do not append whole history
    if (oldCommit == null) {
        return;
    }
    try {
        subOr.rw.resetRetain(subOr.canMergeFlag);
        subOr.rw.markStart(newCommit);
        subOr.rw.markUninteresting(oldCommit);
        for (RevCommit c : subOr.rw) {
            subOr.rw.parseBody(c);
            if (verboseSuperProject.equals(VerboseSuperprojectUpdate.SUBJECT_ONLY)) {
                msgbuf.append("\n  - " + c.getShortMessage());
            } else if (verboseSuperProject.equals(VerboseSuperprojectUpdate.TRUE)) {
                msgbuf.append("\n  - " + c.getFullMessage().replace("\n", "\n    "));
            }
        }
    } catch (IOException e) {
        throw new SubmoduleException("Could not perform a revwalk to " + "create superproject commit message", e);
    }
}
#method_after
private void createSubmoduleCommitMsg(StringBuilder msgbuf, SubmoduleSubscription s, OpenRepo subOr, RevCommit newCommit, RevCommit oldCommit) throws SubmoduleException {
    msgbuf.append("* Update " + s.getPath());
    msgbuf.append(" from branch '" + s.getSubmodule().getShortName() + "'");
    // newly created submodule gitlink, do not append whole history
    if (oldCommit == null) {
        return;
    }
    try {
        subOr.rw.resetRetain(subOr.canMergeFlag);
        subOr.rw.markStart(newCommit);
        subOr.rw.markUninteresting(oldCommit);
        for (RevCommit c : subOr.rw) {
            subOr.rw.parseBody(c);
            if (verboseSuperProject == VerboseSuperprojectUpdate.SUBJECT_ONLY) {
                msgbuf.append("\n  - " + c.getShortMessage());
            } else if (verboseSuperProject == VerboseSuperprojectUpdate.TRUE) {
                msgbuf.append("\n  - " + c.getFullMessage().replace("\n", "\n    "));
            }
        }
    } catch (IOException e) {
        throw new SubmoduleException("Could not perform a revwalk to " + "create superproject commit message", e);
    }
}
#end_block

#method_before
@Override
public void close() {
    writerThread.shutdown();
    try {
        if (!writerThread.awaitTermination(5, TimeUnit.SECONDS)) {
            log.warn("shutting down with pending Lucene writes");
        }
    } catch (InterruptedException e) {
        log.warn("interrupted waiting for pending Lucene writes", e);
    }
    reopenThread.close();
    // not have flushed.
    try {
        searcherManager.maybeRefreshBlocking();
    } catch (IOException e) {
        log.warn("error finishing pending Lucene writes", e);
    }
    try {
        writer.getIndexWriter().close();
    } catch (AlreadyClosedException e) {
    // Ignore.
    } catch (IOException e) {
        log.warn("error closing Lucene writer", e);
    }
    try {
        dir.close();
    } catch (IOException e) {
        log.warn("error closing Lucene directory", e);
    }
}
#method_after
@Override
public void close() {
    if (autoCommitExecutor != null) {
        autoCommitExecutor.shutdown();
    }
    writerThread.shutdown();
    try {
        if (!writerThread.awaitTermination(5, TimeUnit.SECONDS)) {
            log.warn("shutting down " + name + " index with pending Lucene writes");
        }
    } catch (InterruptedException e) {
        log.warn("interrupted waiting for pending Lucene writes of " + name + " index", e);
    }
    reopenThread.close();
    // not have flushed.
    try {
        searcherManager.maybeRefreshBlocking();
    } catch (IOException e) {
        log.warn("error finishing pending Lucene writes", e);
    }
    try {
        writer.getIndexWriter().close();
    } catch (AlreadyClosedException e) {
    // Ignore.
    } catch (IOException e) {
        log.warn("error closing Lucene writer", e);
    }
    try {
        dir.close();
    } catch (IOException e) {
        log.warn("error closing Lucene directory", e);
    }
}
#end_block

#method_before
private void decodeChangedLines(Multimap<String, IndexableField> doc, ChangeData cd) {
    IndexableField added = Iterables.getFirst(doc.get(ADDED_FIELD), null);
    IndexableField deleted = Iterables.getFirst(doc.get(DELETED_FIELD), null);
    if (added != null && deleted != null) {
        cd.setChangedLines(added.numericValue().intValue(), deleted.numericValue().intValue());
    }
}
#method_after
private void decodeChangedLines(Multimap<String, IndexableField> doc, ChangeData cd) {
    IndexableField added = Iterables.getFirst(doc.get(ADDED_FIELD), null);
    IndexableField deleted = Iterables.getFirst(doc.get(DELETED_FIELD), null);
    if (added != null && deleted != null) {
        cd.setChangedLines(added.numericValue().intValue(), deleted.numericValue().intValue());
    } else {
        // No ChangedLines stored, likely due to failure during reindexing, for
        // example due to LargeObjectException. But we know the field was
        // requested, so update ChangeData to prevent callers from trying to
        // lazily load it, as that would probably also fail.
        cd.setNoChangedLines();
    }
}
#end_block

#method_before
public synchronized GlobalPluginConfig getGlobalPluginConfig(String pluginName) {
    if (pluginConfigs.containsKey(pluginName)) {
        return pluginConfigs.get(pluginName);
    }
    Path pluginConfigFile = site.etc_dir.resolve(pluginName + ".config");
    FileBasedConfig cfg = new FileBasedConfig(pluginConfigFile.toFile(), FS.DETECTED);
    GlobalPluginConfig pluginConfig = new GlobalPluginConfig(pluginName, cfg, secureStore);
    pluginConfigs.put(pluginName, pluginConfig);
    if (!cfg.getFile().exists()) {
        log.info("No " + pluginConfigFile.toAbsolutePath() + "; assuming defaults");
        return pluginConfig;
    }
    try {
        cfg.load();
    } catch (IOException | ConfigInvalidException e) {
        log.warn("Failed to load " + pluginConfigFile.toAbsolutePath(), e);
    }
    return pluginConfig;
}
#method_after
public synchronized Config getGlobalPluginConfig(String pluginName) {
    if (pluginConfigs.containsKey(pluginName)) {
        return pluginConfigs.get(pluginName);
    }
    Path pluginConfigFile = site.etc_dir.resolve(pluginName + ".config");
    FileBasedConfig cfg = new FileBasedConfig(pluginConfigFile.toFile(), FS.DETECTED);
    GlobalPluginConfig pluginConfig = new GlobalPluginConfig(pluginName, cfg, secureStore);
    pluginConfigs.put(pluginName, pluginConfig);
    if (!cfg.getFile().exists()) {
        log.info("No " + pluginConfigFile.toAbsolutePath() + "; assuming defaults");
        return pluginConfig;
    }
    try {
        cfg.load();
    } catch (IOException | ConfigInvalidException e) {
        log.warn("Failed to load " + pluginConfigFile.toAbsolutePath(), e);
    }
    return pluginConfig;
}
#end_block

#method_before
@Override
public String[] getListForPlugin(String pluginName, String section, String subsection, String name) {
    File pluginConfigFile = site.etc_dir.resolve(pluginName + ".secure.config").toFile();
    if (pluginConfigFile.exists()) {
        FileBasedConfig cfg = new FileBasedConfig(pluginConfigFile, FS.DETECTED);
        try {
            cfg.load();
            return cfg.getStringList(section, subsection, name);
        } catch (Exception e) {
        // Do nothing for now
        }
    }
    return null;
}
#method_after
@Override
public synchronized String[] getListForPlugin(String pluginName, String section, String subsection, String name) {
    FileBasedConfig cfg = null;
    if (pluginSec.containsKey(pluginName)) {
        cfg = pluginSec.get(pluginName);
    } else {
        String filename = pluginName + ".secure.config";
        File pluginConfigFile = site.etc_dir.resolve(filename).toFile();
        if (pluginConfigFile.exists()) {
            cfg = new FileBasedConfig(pluginConfigFile, FS.DETECTED);
            try {
                cfg.load();
                pluginSec.put(pluginName, cfg);
            } catch (IOException | ConfigInvalidException e) {
                throw new RuntimeException("Cannot load " + filename, e);
            }
        }
    }
    return cfg != null ? cfg.getStringList(section, subsection, name) : null;
}
#end_block

#method_before
@Test
public void deleteNonExistingProjectWatch() throws Exception {
    String projectName = project.get();
    // Let another user watch a project
    setApiUser(admin);
    List<ProjectWatchInfo> projectsToWatch = new LinkedList<>();
    ProjectWatchInfo pwi = new ProjectWatchInfo();
    pwi.project = projectName;
    pwi.notifyAbandonedChanges = true;
    pwi.notifyNewChanges = true;
    pwi.notifyAllComments = true;
    projectsToWatch.add(pwi);
    gApi.accounts().self().setWatchedProjects(projectsToWatch);
    // Try to delete a watched project using a different user
    List<ProjectWatchInfo> d = Lists.newArrayList(pwi);
    gApi.accounts().self().deleteWatchedProjects(d);
    // Check that trying to delete a non-existing watch doesn't fail
    gApi.accounts().self().deleteWatchedProjects(d);
}
#method_after
@Test
public void deleteNonExistingProjectWatch() throws Exception {
    String projectName = project.get();
    // Let another user watch a project
    setApiUser(admin);
    List<ProjectWatchInfo> projectsToWatch = new LinkedList<>();
    ProjectWatchInfo pwi = new ProjectWatchInfo();
    pwi.project = projectName;
    pwi.notifyAbandonedChanges = true;
    pwi.notifyNewChanges = true;
    pwi.notifyAllComments = true;
    projectsToWatch.add(pwi);
    gApi.accounts().self().setWatchedProjects(projectsToWatch);
    // Try to delete a watched project using a different user
    List<ProjectWatchInfo> d = Lists.newArrayList(pwi);
    gApi.accounts().self().deleteWatchedProjects(d);
    // Check that trying to delete a non-existing watch doesn't fail
    setApiUser(user);
    gApi.accounts().self().deleteWatchedProjects(d);
}
#end_block

#method_before
public Map<ProjectWatchKey, Collection<NotifyType>> getProjectWatches(Account.Id accountId) throws IOException, ConfigInvalidException {
    try (Repository git = repoManager.openRepository(allUsersName);
        WatchConfig watchConfig = new WatchConfig(accountId)) {
        watchConfig.load(git);
        return watchConfig.getProjectWatches();
    }
}
#method_after
public Map<ProjectWatchKey, Set<NotifyType>> getProjectWatches(Account.Id accountId) throws IOException, ConfigInvalidException {
    try (Repository git = repoManager.openRepository(allUsersName);
        WatchConfig watchConfig = new WatchConfig(accountId)) {
        watchConfig.load(git);
        return watchConfig.getProjectWatches();
    }
}
#end_block

#method_before
public void upsertProjectWatches(Account.Id accountId, Map<ProjectWatchKey, Collection<NotifyType>> newProjectWatches) throws IOException, ConfigInvalidException {
    try (WatchConfig watchConfig = open(accountId)) {
        Map<ProjectWatchKey, Collection<NotifyType>> projectWatches = watchConfig.getProjectWatches();
        projectWatches.putAll(newProjectWatches);
        commit(watchConfig);
    }
}
#method_after
public void upsertProjectWatches(Account.Id accountId, Map<ProjectWatchKey, Set<NotifyType>> newProjectWatches) throws IOException, ConfigInvalidException {
    try (WatchConfig watchConfig = open(accountId)) {
        Map<ProjectWatchKey, Set<NotifyType>> projectWatches = watchConfig.getProjectWatches();
        projectWatches.putAll(newProjectWatches);
        commit(watchConfig);
    }
}
#end_block

#method_before
public void deleteProjectWatches(Account.Id accountId, Collection<ProjectWatchKey> projectWatchKeys) throws IOException, ConfigInvalidException {
    try (WatchConfig watchConfig = open(accountId)) {
        Map<ProjectWatchKey, Collection<NotifyType>> projectWatches = watchConfig.getProjectWatches();
        for (ProjectWatchKey key : projectWatchKeys) {
            projectWatches.remove(key);
        }
        commit(watchConfig);
    }
}
#method_after
public void deleteProjectWatches(Account.Id accountId, Collection<ProjectWatchKey> projectWatchKeys) throws IOException, ConfigInvalidException {
    try (WatchConfig watchConfig = open(accountId)) {
        Map<ProjectWatchKey, Set<NotifyType>> projectWatches = watchConfig.getProjectWatches();
        boolean commit = false;
        for (ProjectWatchKey key : projectWatchKeys) {
            if (projectWatches.remove(key) != null) {
                commit = true;
            }
        }
        if (commit) {
            commit(watchConfig);
        }
    }
}
#end_block

#method_before
@Override
protected void onLoad() throws IOException, ConfigInvalidException {
    projectWatches = new HashMap<>();
    Config cfg = readConfig(WATCH_CONFIG);
    for (String projectWatchKey : cfg.getSubsections(PROJECT)) {
        ProjectWatchKey key = ProjectWatchKey.parse(projectWatchKey);
        projectWatches.put(key, new HashSet<NotifyType>());
        List<String> notifyValues = Arrays.asList(cfg.getStringList(PROJECT, projectWatchKey, KEY_NOTIFY));
        if (!notifyValues.contains(NOTIFY_NONE)) {
            for (String notify : notifyValues) {
                try {
                    projectWatches.get(key).add(AccountProjectWatch.NotifyType.valueOf(notify));
                } catch (IllegalArgumentException e) {
                    log.warn(String.format("Project watch configuration %s of account %d" + " contains invalid notify type: %s", projectWatchKey, accountId.get(), notify), e);
                }
            }
        }
    }
}
#method_after
@Override
protected void onLoad() throws IOException, ConfigInvalidException {
    Config cfg = readConfig(WATCH_CONFIG);
    projectWatches = parse(accountId, cfg);
}
#end_block

#method_before
Map<ProjectWatchKey, Collection<NotifyType>> getProjectWatches() {
    checkLoaded();
    return projectWatches;
}
#method_after
Map<ProjectWatchKey, Set<NotifyType>> getProjectWatches() {
    checkLoaded();
    return projectWatches;
}
#end_block

#method_before
@Override
protected boolean onSave(CommitBuilder commit) throws IOException, ConfigInvalidException {
    checkLoaded();
    if (commit.getMessage() == null || "".equals(commit.getMessage())) {
        commit.setMessage("Updated watch configuration\n");
    }
    Config cfg = readConfig(WATCH_CONFIG);
    clearSection(cfg, PROJECT);
    for (Map.Entry<ProjectWatchKey, Collection<NotifyType>> e : projectWatches.entrySet()) {
        if (e.getValue().isEmpty()) {
            // set notify to 'none' since empty sections are not persisted
            cfg.setString(PROJECT, e.getKey().toString(), KEY_NOTIFY, NOTIFY_NONE);
        } else {
            List<String> notifyValues = FluentIterable.from(e.getValue()).transform(new Function<NotifyType, String>() {

                @Override
                public String apply(NotifyType notify) {
                    return notify.name();
                }
            }).toList();
            cfg.setStringList(PROJECT, e.getKey().toString(), KEY_NOTIFY, notifyValues);
        }
    }
    saveConfig(WATCH_CONFIG, cfg);
    return true;
}
#method_after
@Override
protected boolean onSave(CommitBuilder commit) throws IOException, ConfigInvalidException {
    checkLoaded();
    if (Strings.isNullOrEmpty(commit.getMessage())) {
        commit.setMessage("Updated watch configuration\n");
    }
    Config cfg = readConfig(WATCH_CONFIG);
    for (String projectName : cfg.getSubsections(PROJECT)) {
        cfg.unset(PROJECT, projectName, KEY_NOTIFY);
    }
    Multimap<String, String> notifyValuesByProject = ArrayListMultimap.create();
    for (Map.Entry<ProjectWatchKey, Set<NotifyType>> e : projectWatches.entrySet()) {
        NotifyValue notifyValue = NotifyValue.create(e.getKey().filter(), e.getValue());
        notifyValuesByProject.put(e.getKey().project().get(), notifyValue.toString());
    }
    for (Map.Entry<String, Collection<String>> e : notifyValuesByProject.asMap().entrySet()) {
        cfg.setStringList(PROJECT, e.getKey(), KEY_NOTIFY, new ArrayList<>(e.getValue()));
    }
    saveConfig(WATCH_CONFIG, cfg);
    return true;
}
#end_block

#method_before
private void checkLoaded() {
    checkNotNull(projectWatches, "project watches not loaded yet");
}
#method_after
private void checkLoaded() {
    checkState(projectWatches != null, "project watches not loaded yet");
}
#end_block

#method_before
public final Watchers getWatchers(NotifyType type) throws OrmException {
    Watchers matching = new Watchers();
    Set<Account.Id> projectWatchers = new HashSet<>();
    for (AccountState a : args.accountQueryProvider.get().byWatchedProject(project)) {
        Account.Id accountId = a.getAccount().getId();
        for (Map.Entry<ProjectWatchKey, Collection<NotifyType>> e : a.getProjectWatches().entrySet()) {
            if (add(matching, accountId, e.getKey(), e.getValue(), type)) {
                // We only want to prevent matching All-Projects if this filter hits
                projectWatchers.add(accountId);
            }
        }
    }
    for (AccountState a : args.accountQueryProvider.get().byWatchedProject(args.allProjectsName)) {
        for (Map.Entry<ProjectWatchKey, Collection<NotifyType>> e : a.getProjectWatches().entrySet()) {
            Account.Id accountId = a.getAccount().getId();
            if (!projectWatchers.contains(accountId)) {
                add(matching, accountId, e.getKey(), e.getValue(), type);
            }
        }
    }
    for (ProjectState state : projectState.tree()) {
        for (NotifyConfig nc : state.getConfig().getNotifyConfigs()) {
            if (nc.isNotify(type)) {
                try {
                    add(matching, nc);
                } catch (QueryParseException e) {
                    log.warn("Project {} has invalid notify {} filter \"{}\": {}", state.getProject().getName(), nc.getName(), nc.getFilter(), e.getMessage());
                }
            }
        }
    }
    return matching;
}
#method_after
public final Watchers getWatchers(NotifyType type) throws OrmException {
    Watchers matching;
    if (args.accountIndexes.getSearchIndex() != null) {
        matching = getWatchersFromIndex(type);
    } else {
        matching = getWatchersFromDb(type);
    }
    for (ProjectState state : projectState.tree()) {
        for (NotifyConfig nc : state.getConfig().getNotifyConfigs()) {
            if (nc.isNotify(type)) {
                try {
                    add(matching, nc);
                } catch (QueryParseException e) {
                    log.warn("Project {} has invalid notify {} filter \"{}\": {}", state.getProject().getName(), nc.getName(), nc.getFilter(), e.getMessage());
                }
            }
        }
    }
    return matching;
}
#end_block

#method_before
private boolean add(Watchers matching, Account.Id accountId, ProjectWatchKey key, Collection<NotifyType> watchedTypes, NotifyType type) throws OrmException {
    IdentifiedUser user = args.identifiedUserFactory.create(accountId);
    try {
        if (filterMatch(user, key.filter())) {
            // Otherwise, still return true to stop notifications for this user.
            if (watchedTypes.contains(type)) {
                matching.bcc.accounts.add(accountId);
            }
            return true;
        }
    } catch (QueryParseException e) {
    // Ignore broken filter expressions.
    }
    return false;
}
#method_after
private boolean add(Watchers matching, Account.Id accountId, ProjectWatchKey key, Set<NotifyType> watchedTypes, NotifyType type) throws OrmException {
    IdentifiedUser user = args.identifiedUserFactory.create(accountId);
    try {
        if (filterMatch(user, key.filter())) {
            // Otherwise, still return true to stop notifications for this user.
            if (watchedTypes.contains(type)) {
                matching.bcc.accounts.add(accountId);
            }
            return true;
        }
    } catch (QueryParseException e) {
    // Ignore broken filter expressions.
    }
    return false;
}
#end_block

#method_before
private AccountState makeUser(final String name, final String email) {
    final Account.Id userId = new Account.Id(42);
    final Account account = new Account(userId, TimeUtil.nowTs());
    account.setFullName(name);
    account.setPreferredEmail(email);
    return new AccountState(account, Collections.<AccountGroup.UUID>emptySet(), Collections.<AccountExternalId>emptySet(), new HashMap<ProjectWatchKey, Collection<NotifyType>>());
}
#method_after
private AccountState makeUser(final String name, final String email) {
    final Account.Id userId = new Account.Id(42);
    final Account account = new Account(userId, TimeUtil.nowTs());
    account.setFullName(name);
    account.setPreferredEmail(email);
    return new AccountState(account, Collections.<AccountGroup.UUID>emptySet(), Collections.<AccountExternalId>emptySet(), new HashMap<ProjectWatchKey, Set<NotifyType>>());
}
#end_block

#method_before
private void updateInDb(Account.Id accountId, List<ProjectWatchInfo> input) throws BadRequestException, UnprocessableEntityException, IOException, OrmException {
    Set<AccountProjectWatch.Key> keys = new HashSet<>();
    List<AccountProjectWatch> watchedProjects = new LinkedList<>();
    for (ProjectWatchInfo a : input) {
        if (a.project == null) {
            throw new BadRequestException("project name must be specified");
        }
        Project.NameKey projectKey = projectsCollection.parse(a.project).getNameKey();
        AccountProjectWatch.Key key = new AccountProjectWatch.Key(accountId, projectKey, a.filter);
        if (!keys.add(key)) {
            throw new BadRequestException("duplicate entry for project " + key.getProjectName().get() + (!AccountProjectWatch.FILTER_ALL.equals(key.getFilter().get()) ? " and filter " + key.getFilter().get() : ""));
        }
        AccountProjectWatch apw = new AccountProjectWatch(key);
        apw.setNotify(AccountProjectWatch.NotifyType.ABANDONED_CHANGES, toBoolean(a.notifyAbandonedChanges));
        apw.setNotify(AccountProjectWatch.NotifyType.ALL_COMMENTS, toBoolean(a.notifyAllComments));
        apw.setNotify(AccountProjectWatch.NotifyType.NEW_CHANGES, toBoolean(a.notifyNewChanges));
        apw.setNotify(AccountProjectWatch.NotifyType.NEW_PATCHSETS, toBoolean(a.notifyNewPatchSets));
        apw.setNotify(AccountProjectWatch.NotifyType.SUBMITTED_CHANGES, toBoolean(a.notifySubmittedChanges));
        watchedProjects.add(apw);
    }
    dbProvider.get().accountProjectWatches().upsert(watchedProjects);
}
#method_after
private void updateInDb(Account.Id accountId, List<ProjectWatchInfo> input) throws BadRequestException, UnprocessableEntityException, IOException, OrmException {
    Set<AccountProjectWatch.Key> keys = new HashSet<>();
    List<AccountProjectWatch> watchedProjects = new LinkedList<>();
    for (ProjectWatchInfo a : input) {
        if (a.project == null) {
            throw new BadRequestException("project name must be specified");
        }
        Project.NameKey projectKey = projectsCollection.parse(a.project).getNameKey();
        AccountProjectWatch.Key key = new AccountProjectWatch.Key(accountId, projectKey, a.filter);
        if (!keys.add(key)) {
            throw new BadRequestException("duplicate entry for project " + format(key.getProjectName().get(), key.getFilter().get()));
        }
        AccountProjectWatch apw = new AccountProjectWatch(key);
        apw.setNotify(AccountProjectWatch.NotifyType.ABANDONED_CHANGES, toBoolean(a.notifyAbandonedChanges));
        apw.setNotify(AccountProjectWatch.NotifyType.ALL_COMMENTS, toBoolean(a.notifyAllComments));
        apw.setNotify(AccountProjectWatch.NotifyType.NEW_CHANGES, toBoolean(a.notifyNewChanges));
        apw.setNotify(AccountProjectWatch.NotifyType.NEW_PATCHSETS, toBoolean(a.notifyNewPatchSets));
        apw.setNotify(AccountProjectWatch.NotifyType.SUBMITTED_CHANGES, toBoolean(a.notifySubmittedChanges));
        watchedProjects.add(apw);
    }
    dbProvider.get().accountProjectWatches().upsert(watchedProjects);
}
#end_block

#method_before
private Map<ProjectWatchKey, Collection<NotifyType>> asMap(List<ProjectWatchInfo> input) throws BadRequestException, UnprocessableEntityException, IOException {
    Map<ProjectWatchKey, Collection<NotifyType>> m = new HashMap<>();
    for (ProjectWatchInfo info : input) {
        if (info.project == null) {
            throw new BadRequestException("project name must be specified");
        }
        ProjectWatchKey key = ProjectWatchKey.create(projectsCollection.parse(info.project).getNameKey(), info.filter);
        if (m.containsKey(key)) {
            throw new BadRequestException("duplicate entry for project " + info.project + (info.filter != null ? " and filter " + info.filter : ""));
        }
        Set<NotifyType> notifyValues = new HashSet<>();
        if (toBoolean(info.notifyAbandonedChanges)) {
            notifyValues.add(NotifyType.ABANDONED_CHANGES);
        }
        if (toBoolean(info.notifyAllComments)) {
            notifyValues.add(NotifyType.ALL_COMMENTS);
        }
        if (toBoolean(info.notifyNewChanges)) {
            notifyValues.add(NotifyType.NEW_CHANGES);
        }
        if (toBoolean(info.notifyNewPatchSets)) {
            notifyValues.add(NotifyType.NEW_PATCHSETS);
        }
        if (toBoolean(info.notifySubmittedChanges)) {
            notifyValues.add(NotifyType.SUBMITTED_CHANGES);
        }
        m.put(key, notifyValues);
    }
    return m;
}
#method_after
private Map<ProjectWatchKey, Set<NotifyType>> asMap(List<ProjectWatchInfo> input) throws BadRequestException, UnprocessableEntityException, IOException {
    Map<ProjectWatchKey, Set<NotifyType>> m = new HashMap<>();
    for (ProjectWatchInfo info : input) {
        if (info.project == null) {
            throw new BadRequestException("project name must be specified");
        }
        ProjectWatchKey key = ProjectWatchKey.create(projectsCollection.parse(info.project).getNameKey(), info.filter);
        if (m.containsKey(key)) {
            throw new BadRequestException("duplicate entry for project " + format(info.project, info.filter));
        }
        Set<NotifyType> notifyValues = EnumSet.noneOf(NotifyType.class);
        if (toBoolean(info.notifyAbandonedChanges)) {
            notifyValues.add(NotifyType.ABANDONED_CHANGES);
        }
        if (toBoolean(info.notifyAllComments)) {
            notifyValues.add(NotifyType.ALL_COMMENTS);
        }
        if (toBoolean(info.notifyNewChanges)) {
            notifyValues.add(NotifyType.NEW_CHANGES);
        }
        if (toBoolean(info.notifyNewPatchSets)) {
            notifyValues.add(NotifyType.NEW_PATCHSETS);
        }
        if (toBoolean(info.notifySubmittedChanges)) {
            notifyValues.add(NotifyType.SUBMITTED_CHANGES);
        }
        m.put(key, notifyValues);
    }
    return m;
}
#end_block

#method_before
private static AccountState newState(Account account) {
    return new AccountState(account, ImmutableSet.<AccountGroup.UUID>of(), ImmutableSet.<AccountExternalId>of(), new HashMap<ProjectWatchKey, Collection<NotifyType>>());
}
#method_after
private static AccountState newState(Account account) {
    return new AccountState(account, ImmutableSet.<AccountGroup.UUID>of(), ImmutableSet.<AccountExternalId>of(), new HashMap<ProjectWatchKey, Set<NotifyType>>());
}
#end_block

#method_before
public Map<ProjectWatchKey, Collection<NotifyType>> getProjectWatches() {
    return projectWatches;
}
#method_after
public Map<ProjectWatchKey, Set<NotifyType>> getProjectWatches() {
    return projectWatches;
}
#end_block

#method_before
private static AccountState missing(Account.Id accountId) {
    Account account = new Account(accountId, TimeUtil.nowTs());
    account.setActive(false);
    Collection<AccountExternalId> ids = Collections.emptySet();
    Set<AccountGroup.UUID> anon = ImmutableSet.of();
    return new AccountState(account, anon, ids, new HashMap<ProjectWatchKey, Collection<NotifyType>>());
}
#method_after
private static AccountState missing(Account.Id accountId) {
    Account account = new Account(accountId, TimeUtil.nowTs());
    account.setActive(false);
    Collection<AccountExternalId> ids = Collections.emptySet();
    Set<AccountGroup.UUID> anon = ImmutableSet.of();
    return new AccountState(account, anon, ids, new HashMap<ProjectWatchKey, Set<NotifyType>>());
}
#end_block

#method_before
private AccountState load(final ReviewDb db, final Account.Id who) throws OrmException, IOException, ConfigInvalidException {
    Account account = db.accounts().get(who);
    if (account == null) {
        // Account no longer exists? They are anonymous.
        return missing(who);
    }
    Collection<AccountExternalId> externalIds = Collections.unmodifiableCollection(db.accountExternalIds().byAccount(who).toList());
    Set<AccountGroup.UUID> internalGroups = new HashSet<>();
    for (AccountGroupMember g : db.accountGroupMembers().byAccount(who)) {
        final AccountGroup.Id groupId = g.getAccountGroupId();
        final AccountGroup group = groupCache.get(groupId);
        if (group != null && group.getGroupUUID() != null) {
            internalGroups.add(group.getGroupUUID());
        }
    }
    internalGroups = Collections.unmodifiableSet(internalGroups);
    try {
        account.setGeneralPreferences(loader.load(who));
    } catch (IOException | ConfigInvalidException e) {
        log.warn("Cannot load GeneralPreferences for " + who + " (using default)", e);
        account.setGeneralPreferences(GeneralPreferencesInfo.defaults());
    }
    Map<ProjectWatchKey, Collection<NotifyType>> projectWatches = readFromGit ? watchConfig.get().getProjectWatches(who) : GetWatchedProjects.readProjectWatchesFromDb(db, who);
    return new AccountState(account, internalGroups, externalIds, projectWatches);
}
#method_after
private AccountState load(final ReviewDb db, final Account.Id who) throws OrmException, IOException, ConfigInvalidException {
    Account account = db.accounts().get(who);
    if (account == null) {
        // Account no longer exists? They are anonymous.
        return missing(who);
    }
    Collection<AccountExternalId> externalIds = Collections.unmodifiableCollection(db.accountExternalIds().byAccount(who).toList());
    Set<AccountGroup.UUID> internalGroups = new HashSet<>();
    for (AccountGroupMember g : db.accountGroupMembers().byAccount(who)) {
        final AccountGroup.Id groupId = g.getAccountGroupId();
        final AccountGroup group = groupCache.get(groupId);
        if (group != null && group.getGroupUUID() != null) {
            internalGroups.add(group.getGroupUUID());
        }
    }
    internalGroups = Collections.unmodifiableSet(internalGroups);
    try {
        account.setGeneralPreferences(loader.load(who));
    } catch (IOException | ConfigInvalidException e) {
        log.warn("Cannot load GeneralPreferences for " + who + " (using default)", e);
        account.setGeneralPreferences(GeneralPreferencesInfo.defaults());
    }
    Map<ProjectWatchKey, Set<NotifyType>> projectWatches = readFromGit ? watchConfig.get().getProjectWatches(who) : GetWatchedProjects.readProjectWatchesFromDb(db, who);
    return new AccountState(account, internalGroups, externalIds, projectWatches);
}
#end_block

#method_before
@Override
public Optional<Account.Id> load(String username) throws Exception {
    try (ReviewDb db = schema.open()) {
        final AccountExternalId.Key key = new // 
        AccountExternalId.Key(// 
        AccountExternalId.SCHEME_USERNAME, username);
        final AccountExternalId id = db.accountExternalIds().get(key);
        if (id != null) {
            return Optional.of(id.getAccountId());
        }
        return Optional.absent();
    }
}
#method_after
@Override
public Optional<Account.Id> load(String username) throws Exception {
    AccountExternalId.Key key = new // 
    AccountExternalId.Key(// 
    AccountExternalId.SCHEME_USERNAME, username);
    if (accountIndexes.getSearchIndex() != null) {
        AccountState accountState = accountQueryProvider.get().oneByExternalId(key.get());
        return accountState != null ? Optional.of(accountState.getAccount().getId()) : Optional.<Account.Id>absent();
    }
    try (ReviewDb db = schema.open()) {
        AccountExternalId id = db.accountExternalIds().get(key);
        if (id != null) {
            return Optional.of(id.getAccountId());
        }
        return Optional.absent();
    }
}
#end_block

#method_before
private void deleteFromDb(Account.Id accountId, List<ProjectWatchInfo> input) throws OrmException, IOException {
    ResultSet<AccountProjectWatch> watchedProjects = dbProvider.get().accountProjectWatches().byAccount(accountId);
    HashMap<AccountProjectWatch.Key, AccountProjectWatch> watchedProjectsMap = new HashMap<>();
    for (AccountProjectWatch watchedProject : watchedProjects) {
        watchedProjectsMap.put(watchedProject.getKey(), watchedProject);
    }
    List<AccountProjectWatch> watchesToDelete = new LinkedList<>();
    for (ProjectWatchInfo projectInfo : input) {
        AccountProjectWatch.Key key = new AccountProjectWatch.Key(accountId, new Project.NameKey(projectInfo.project), projectInfo.filter);
        if (watchedProjectsMap.containsKey(key)) {
            watchesToDelete.add(watchedProjectsMap.get(key));
        }
    }
    dbProvider.get().accountProjectWatches().delete(watchesToDelete);
    accountCache.evict(accountId);
}
#method_after
private void deleteFromDb(Account.Id accountId, List<ProjectWatchInfo> input) throws OrmException, IOException {
    ResultSet<AccountProjectWatch> watchedProjects = dbProvider.get().accountProjectWatches().byAccount(accountId);
    HashMap<AccountProjectWatch.Key, AccountProjectWatch> watchedProjectsMap = new HashMap<>();
    for (AccountProjectWatch watchedProject : watchedProjects) {
        watchedProjectsMap.put(watchedProject.getKey(), watchedProject);
    }
    List<AccountProjectWatch> watchesToDelete = new LinkedList<>();
    for (ProjectWatchInfo projectInfo : input) {
        AccountProjectWatch.Key key = new AccountProjectWatch.Key(accountId, new Project.NameKey(projectInfo.project), projectInfo.filter);
        if (watchedProjectsMap.containsKey(key)) {
            watchesToDelete.add(watchedProjectsMap.get(key));
        }
    }
    if (!watchesToDelete.isEmpty()) {
        dbProvider.get().accountProjectWatches().delete(watchesToDelete);
        accountCache.evict(accountId);
    }
}
#end_block

#method_before
@Override
public List<ProjectWatchInfo> apply(AccountResource rsrc) throws OrmException, AuthException, IOException, ConfigInvalidException {
    if (self.get() != rsrc.getUser() && !self.get().getCapabilities().canAdministrateServer()) {
        throw new AuthException("It is not allowed to list project watches " + "of other users");
    }
    Account.Id accountId = rsrc.getUser().getAccountId();
    Map<ProjectWatchKey, Collection<NotifyType>> projectWatches = readFromGit ? watchConfig.getProjectWatches(accountId) : readProjectWatchesFromDb(dbProvider.get(), accountId);
    List<ProjectWatchInfo> projectWatchInfos = new LinkedList<>();
    for (Map.Entry<ProjectWatchKey, Collection<NotifyType>> e : projectWatches.entrySet()) {
        ProjectWatchInfo pwi = new ProjectWatchInfo();
        pwi.filter = e.getKey().filter();
        pwi.project = e.getKey().project().get();
        pwi.notifyAbandonedChanges = toBoolean(e.getValue().contains(NotifyType.ABANDONED_CHANGES));
        pwi.notifyNewChanges = toBoolean(e.getValue().contains(NotifyType.NEW_CHANGES));
        pwi.notifyNewPatchSets = toBoolean(e.getValue().contains(NotifyType.NEW_PATCHSETS));
        pwi.notifySubmittedChanges = toBoolean(e.getValue().contains(NotifyType.SUBMITTED_CHANGES));
        pwi.notifyAllComments = toBoolean(e.getValue().contains(NotifyType.ALL_COMMENTS));
        projectWatchInfos.add(pwi);
    }
    return projectWatchInfos;
}
#method_after
@Override
public List<ProjectWatchInfo> apply(AccountResource rsrc) throws OrmException, AuthException, IOException, ConfigInvalidException {
    if (self.get() != rsrc.getUser() && !self.get().getCapabilities().canAdministrateServer()) {
        throw new AuthException("It is not allowed to list project watches " + "of other users");
    }
    Account.Id accountId = rsrc.getUser().getAccountId();
    Map<ProjectWatchKey, Set<NotifyType>> projectWatches = readFromGit ? watchConfig.getProjectWatches(accountId) : readProjectWatchesFromDb(dbProvider.get(), accountId);
    List<ProjectWatchInfo> projectWatchInfos = new LinkedList<>();
    for (Map.Entry<ProjectWatchKey, Set<NotifyType>> e : projectWatches.entrySet()) {
        ProjectWatchInfo pwi = new ProjectWatchInfo();
        pwi.filter = e.getKey().filter();
        pwi.project = e.getKey().project().get();
        pwi.notifyAbandonedChanges = toBoolean(e.getValue().contains(NotifyType.ABANDONED_CHANGES));
        pwi.notifyNewChanges = toBoolean(e.getValue().contains(NotifyType.NEW_CHANGES));
        pwi.notifyNewPatchSets = toBoolean(e.getValue().contains(NotifyType.NEW_PATCHSETS));
        pwi.notifySubmittedChanges = toBoolean(e.getValue().contains(NotifyType.SUBMITTED_CHANGES));
        pwi.notifyAllComments = toBoolean(e.getValue().contains(NotifyType.ALL_COMMENTS));
        projectWatchInfos.add(pwi);
    }
    Collections.sort(projectWatchInfos, new Comparator<ProjectWatchInfo>() {

        @Override
        public int compare(ProjectWatchInfo pwi1, ProjectWatchInfo pwi2) {
            return ComparisonChain.start().compare(pwi1.project, pwi2.project).compare(Strings.nullToEmpty(pwi1.filter), Strings.nullToEmpty(pwi2.filter)).result();
        }
    });
    return projectWatchInfos;
}
#end_block

#method_before
public static Map<ProjectWatchKey, Collection<NotifyType>> readProjectWatchesFromDb(ReviewDb db, Account.Id who) throws OrmException {
    Map<ProjectWatchKey, Collection<NotifyType>> projectWatches = new HashMap<>();
    Collection<AccountProjectWatch> accountProjectWatches = Collections.unmodifiableCollection(db.accountProjectWatches().byAccount(who).toList());
    for (AccountProjectWatch apw : accountProjectWatches) {
        ProjectWatchKey key = ProjectWatchKey.create(apw.getProjectNameKey(), apw.getFilter());
        Set<NotifyType> notifyValues = new HashSet<>();
        if (apw.isNotify(NotifyType.ABANDONED_CHANGES)) {
            notifyValues.add(NotifyType.ABANDONED_CHANGES);
        }
        if (apw.isNotify(NotifyType.ALL_COMMENTS)) {
            notifyValues.add(NotifyType.ALL_COMMENTS);
        }
        if (apw.isNotify(NotifyType.NEW_CHANGES)) {
            notifyValues.add(NotifyType.NEW_CHANGES);
        }
        if (apw.isNotify(NotifyType.NEW_PATCHSETS)) {
            notifyValues.add(NotifyType.NEW_PATCHSETS);
        }
        if (apw.isNotify(NotifyType.SUBMITTED_CHANGES)) {
            notifyValues.add(NotifyType.SUBMITTED_CHANGES);
        }
        projectWatches.put(key, notifyValues);
    }
    return projectWatches;
}
#method_after
public static Map<ProjectWatchKey, Set<NotifyType>> readProjectWatchesFromDb(ReviewDb db, Account.Id who) throws OrmException {
    Map<ProjectWatchKey, Set<NotifyType>> projectWatches = new HashMap<>();
    for (AccountProjectWatch apw : db.accountProjectWatches().byAccount(who)) {
        ProjectWatchKey key = ProjectWatchKey.create(apw.getProjectNameKey(), apw.getFilter());
        Set<NotifyType> notifyValues = EnumSet.noneOf(NotifyType.class);
        for (NotifyType notifyType : NotifyType.values()) {
            if (apw.isNotify(notifyType)) {
                notifyValues.add(notifyType);
            }
        }
        projectWatches.put(key, notifyValues);
    }
    return projectWatches;
}
#end_block

#method_before
@Override
public void updateRepoImpl(RepoContext ctx) throws IntegrationException, IOException {
    CodeReviewCommit merged = toMerge;
    // Modify the fast forward commit with gitlink update
    if (args.submoduleOp.hasSubscription(args.destBranch)) {
        try {
            merged = args.submoduleOp.composeGitlinksCommit(args.destBranch, merged);
        } catch (SubmoduleException | OrmException e) {
            logError("can not update gitlink for the merge commit at branch: " + args.destBranch);
        }
    }
    args.mergeTip.moveTipTo(merged, toMerge);
}
#method_after
@Override
protected void updateRepoImpl(RepoContext ctx) throws IntegrationException {
    args.mergeTip.moveTipTo(amendGitlink(toMerge), toMerge);
}
#end_block

#method_before
@Override
public void updateRepoImpl(RepoContext ctx) throws IntegrationException, IOException {
    PersonIdent caller = ctx.getUser().asIdentifiedUser().newCommitterIdent(ctx.getWhen(), ctx.getTimeZone());
    if (args.mergeTip.getCurrentTip() == null) {
        throw new IllegalStateException("cannot merge commit " + toMerge.name() + " onto a null tip; expected at least one fast-forward prior to" + " this operation");
    }
    // TODO(dborowitz): args.rw is needed because it's a CodeReviewRevWalk.
    // When hoisting BatchUpdate into MergeOp, we will need to teach
    // BatchUpdate how to produce CodeReviewRevWalks.
    CodeReviewCommit merged = args.mergeUtil.mergeOneCommit(caller, args.serverIdent, ctx.getRepository(), args.rw, ctx.getInserter(), args.destBranch, args.mergeTip.getCurrentTip(), toMerge);
    // Modify the mergy commit with gitlink update
    if (args.submoduleOp.hasSubscription(args.destBranch)) {
        try {
            merged = args.submoduleOp.composeGitlinksCommit(args.destBranch, merged);
        } catch (SubmoduleException | OrmException e) {
            logError("can not update gitlink for the merge commit at branch: " + args.destBranch);
        }
    }
    args.mergeTip.moveTipTo(merged, toMerge);
}
#method_after
@Override
public void updateRepoImpl(RepoContext ctx) throws IntegrationException, IOException {
    PersonIdent caller = ctx.getIdentifiedUser().newCommitterIdent(ctx.getWhen(), ctx.getTimeZone());
    if (args.mergeTip.getCurrentTip() == null) {
        throw new IllegalStateException("cannot merge commit " + toMerge.name() + " onto a null tip; expected at least one fast-forward prior to" + " this operation");
    }
    // TODO(dborowitz): args.rw is needed because it's a CodeReviewRevWalk.
    // When hoisting BatchUpdate into MergeOp, we will need to teach
    // BatchUpdate how to produce CodeReviewRevWalks.
    CodeReviewCommit merged = args.mergeUtil.mergeOneCommit(caller, args.serverIdent, ctx.getRepository(), args.rw, ctx.getInserter(), args.destBranch, args.mergeTip.getCurrentTip(), toMerge);
    args.mergeTip.moveTipTo(amendGitlink(merged), toMerge);
}
#end_block

#method_before
private void checkSubmitRulesAndState() throws ResourceConflictException {
    for (ChangeData cd : commits.changes.values()) {
        try {
            if (cd.change().getStatus() != Change.Status.NEW) {
                commits.problem(cd.getId(), "Change " + cd.getId() + " is " + cd.change().getStatus().toString().toLowerCase());
            } else {
                checkSubmitRule(cd);
            }
        } catch (ResourceConflictException e) {
            commits.problem(cd.getId(), e.getMessage());
        } catch (OrmException e) {
            String msg = "Error checking submit rules for change";
            log.warn(msg + " " + cd.getId(), e);
            commits.problem(cd.getId(), msg);
        }
    }
    commits.maybeFailVerbose();
}
#method_after
private void checkSubmitRulesAndState(ChangeSet cs) throws ResourceConflictException {
    checkArgument(!cs.furtherHiddenChanges(), "checkSubmitRulesAndState called for topic with hidden change");
    for (ChangeData cd : cs.changes()) {
        try {
            if (cd.change().getStatus() != Change.Status.NEW) {
                commits.problem(cd.getId(), "Change " + cd.getId() + " is " + cd.change().getStatus().toString().toLowerCase());
            } else {
                checkSubmitRule(cd);
            }
        } catch (ResourceConflictException e) {
            commits.problem(cd.getId(), e.getMessage());
        } catch (OrmException e) {
            String msg = "Error checking submit rules for change";
            log.warn(msg + " " + cd.getId(), e);
            commits.problem(cd.getId(), msg);
        }
    }
    commits.maybeFailVerbose();
}
#end_block

#method_before
private void bypassSubmitRules(ChangeSet cs) {
    for (ChangeData cd : cs.changes()) {
        List<SubmitRecord> records;
        try {
            records = new ArrayList<>(getSubmitRecords(cd));
        } catch (OrmException e) {
            log.warn("Error checking submit rules for change " + cd.getId(), e);
            records = new ArrayList<>(1);
        }
        SubmitRecord forced = new SubmitRecord();
        forced.status = SubmitRecord.Status.FORCED;
        records.add(forced);
        cd.setSubmitRecords(records);
    }
}
#method_after
private void bypassSubmitRules(ChangeSet cs) {
    checkArgument(!cs.furtherHiddenChanges(), "cannot bypass submit rules for topic with hidden change");
    for (ChangeData cd : cs.changes()) {
        List<SubmitRecord> records;
        try {
            records = new ArrayList<>(getSubmitRecords(cd));
        } catch (OrmException e) {
            log.warn("Error checking submit rules for change " + cd.getId(), e);
            records = new ArrayList<>(1);
        }
        SubmitRecord forced = new SubmitRecord();
        forced.status = SubmitRecord.Status.FORCED;
        records.add(forced);
        cd.setSubmitRecords(records);
    }
}
#end_block

#method_before
public void merge(ReviewDb db, Change change, IdentifiedUser caller, boolean checkSubmitRules, SubmitInput submitInput) throws OrmException, RestApiException {
    this.submitInput = submitInput;
    this.caller = caller;
    updateSubmissionId(change);
    this.db = db;
    orm.setContext(db, ts, caller, submissionId);
    logDebug("Beginning integration of {}", change);
    try {
        ChangeSet cs = mergeSuperSet.completeChangeSet(db, change, caller);
        checkState(cs.ids().contains(change.getId()), "change %s missing from %s", change.getId(), cs);
        this.commits = new CommitStatus(cs);
        MergeSuperSet.reloadChanges(cs);
        logDebug("Calculated to merge {}", cs);
        if (checkSubmitRules) {
            logDebug("Checking submit rules and state");
            checkSubmitRulesAndState();
        } else {
            logDebug("Bypassing submit rules");
            bypassSubmitRules(cs);
        }
        try {
            integrateIntoHistory(cs);
        } catch (IntegrationException e) {
            logError("Error from integrateIntoHistory", e);
            throw new ResourceConflictException(e.getMessage(), e);
        }
    } catch (IOException e) {
        // Anything before the merge attempt is an error
        throw new OrmException(e);
    }
}
#method_after
public void merge(ReviewDb db, Change change, IdentifiedUser caller, boolean checkSubmitRules, SubmitInput submitInput) throws OrmException, RestApiException {
    this.submitInput = submitInput;
    this.caller = caller;
    updateSubmissionId(change);
    this.db = db;
    orm.setContext(db, ts, caller, submissionId);
    logDebug("Beginning integration of {}", change);
    try {
        ChangeSet cs = mergeSuperSet.completeChangeSet(db, change, caller);
        checkState(cs.ids().contains(change.getId()), "change %s missing from %s", change.getId(), cs);
        if (cs.furtherHiddenChanges()) {
            throw new AuthException("A change to be submitted with " + change.getId() + " is not visible");
        }
        this.commits = new CommitStatus(cs);
        MergeSuperSet.reloadChanges(cs);
        logDebug("Calculated to merge {}", cs);
        if (checkSubmitRules) {
            logDebug("Checking submit rules and state");
            checkSubmitRulesAndState(cs);
        } else {
            logDebug("Bypassing submit rules");
            bypassSubmitRules(cs);
        }
        try {
            integrateIntoHistory(cs);
        } catch (IntegrationException e) {
            logError("Error from integrateIntoHistory", e);
            throw new ResourceConflictException(e.getMessage(), e);
        }
    } catch (IOException e) {
        // Anything before the merge attempt is an error
        throw new OrmException(e);
    }
}
#end_block

#method_before
private void integrateIntoHistory(ChangeSet cs) throws IntegrationException, RestApiException {
    logDebug("Beginning merge attempt on {}", cs);
    Map<Branch.NameKey, BranchBatch> toSubmit = new HashMap<>();
    logDebug("Perform the merges");
    Multimap<Project.NameKey, Branch.NameKey> br;
    Multimap<Branch.NameKey, ChangeData> cbb;
    try {
        br = cs.branchesByProject();
        cbb = cs.changesByBranch();
    } catch (OrmException e) {
        throw new IntegrationException("Error reading changes to submit", e);
    }
    Set<Project.NameKey> projectsWithChanges = br.keySet();
    Collection<Branch.NameKey> branchesWithChanges = cbb.keySet();
    openRepos(projectsWithChanges);
    for (Branch.NameKey branch : branchesWithChanges) {
        OpenRepo or = orm.getRepo(branch.getParentKey());
        toSubmit.put(branch, validateChangeList(or, cbb.get(branch)));
    }
    // Done checks that don't involve running submit strategies.
    commits.maybeFailVerbose();
    List<SubmitStrategy> strategies = new ArrayList<>();
    SubmoduleOp submoduleOp = subOpFactory.create(br.values(), orm);
    try {
        LinkedHashSet<Branch.NameKey> branches = submoduleOp.getOrdedBranches();
        for (Branch.NameKey branch : branchesWithChanges) {
            if (!branches.contains(branch)) {
                branches.add(branch);
            }
        }
        for (Branch.NameKey branch : branches) {
            OpenRepo or = orm.getRepo(branch.getParentKey());
            if (cbb.containsKey(branch)) {
                BranchBatch submitting = toSubmit.get(branch);
                OpenBranch ob = or.getBranch(branch);
                checkNotNull(submitting.submitType(), "null submit type for %s; expected to previously fail fast", submitting);
                Set<CodeReviewCommit> commitsToSubmit = commits(submitting.changes());
                ob.mergeTip = new MergeTip(ob.oldTip, commitsToSubmit);
                SubmitStrategy strategy = createStrategy(or, ob.mergeTip, branch, submitting.submitType(), ob.oldTip, submoduleOp);
                strategies.add(strategy);
                strategy.addOps(or.getUpdate(), commitsToSubmit);
            } else {
                // no open change for this branch
                // add submodule triggered op into BatchUpdate
                or.getUpdate().addRepoOnlyOp(new SubmoduleOp.RepoOnlyOp(submoduleOp, branch));
            }
        }
        LinkedHashSet<Project.NameKey> projects = submoduleOp.getOrdedProjects();
        for (Project.NameKey project : projectsWithChanges) {
            if (!projects.contains(project)) {
                projects.add(project);
            }
        }
        BatchUpdate.execute(orm.batchUpdates(projects), new SubmitStrategyListener(submitInput, strategies, commits));
    } catch (UpdateException | SubmoduleException e) {
        // BatchUpdate may have inadvertently wrapped an IntegrationException
        // thrown by some legacy SubmitStrategyOp code that intended the error
        // message to be user-visible. Copy the message from the wrapped
        // exception.
        // 
        // If you happen across one of these, the correct fix is to convert the
        // inner IntegrationException to a ResourceConflictException.
        String msg;
        if (e.getCause() instanceof IntegrationException) {
            msg = e.getCause().getMessage();
        } else {
            msg = "Error submitting change" + (cs.size() != 1 ? "s" : "");
        }
        throw new IntegrationException(msg, e);
    }
}
#method_after
private void integrateIntoHistory(ChangeSet cs) throws IntegrationException, RestApiException {
    checkArgument(!cs.furtherHiddenChanges(), "cannot integrate hidden changes into history");
    logDebug("Beginning merge attempt on {}", cs);
    Map<Branch.NameKey, BranchBatch> toSubmit = new HashMap<>();
    logDebug("Perform the merges");
    Multimap<Project.NameKey, Branch.NameKey> br;
    Multimap<Branch.NameKey, ChangeData> cbb;
    try {
        br = cs.branchesByProject();
        cbb = cs.changesByBranch();
    } catch (OrmException e) {
        throw new IntegrationException("Error reading changes to submit", e);
    }
    Set<Project.NameKey> projects = br.keySet();
    Set<Branch.NameKey> branches = cbb.keySet();
    openRepos(projects);
    for (Branch.NameKey branch : branches) {
        OpenRepo or = orm.getRepo(branch.getParentKey());
        toSubmit.put(branch, validateChangeList(or, cbb.get(branch)));
    }
    // Done checks that don't involve running submit strategies.
    commits.maybeFailVerbose();
    SubmoduleOp submoduleOp = subOpFactory.create(branches, orm);
    try {
        List<SubmitStrategy> strategies = getSubmitStrategies(toSubmit, submoduleOp);
        Set<Project.NameKey> allProjects = submoduleOp.getProjectsInOrder();
        // in case superproject subscription is disabled, allProjects would be null
        if (allProjects == null) {
            allProjects = projects;
        }
        BatchUpdate.execute(orm.batchUpdates(allProjects), new SubmitStrategyListener(submitInput, strategies, commits));
    } catch (UpdateException | SubmoduleException e) {
        // BatchUpdate may have inadvertently wrapped an IntegrationException
        // thrown by some legacy SubmitStrategyOp code that intended the error
        // message to be user-visible. Copy the message from the wrapped
        // exception.
        // 
        // If you happen across one of these, the correct fix is to convert the
        // inner IntegrationException to a ResourceConflictException.
        String msg;
        if (e.getCause() instanceof IntegrationException) {
            msg = e.getCause().getMessage();
        } else {
            msg = "Error submitting change" + (cs.size() != 1 ? "s" : "") + ": \n" + e.getMessage();
        }
        throw new IntegrationException(msg, e);
    }
}
#end_block

#method_before
private Set<RevCommit> getAlreadyAccepted(OpenRepo or, CodeReviewCommit branchTip) throws IntegrationException {
    Set<RevCommit> alreadyAccepted = new HashSet<>();
    if (branchTip != null) {
        alreadyAccepted.add(branchTip);
    }
    try {
        for (Ref r : or.repo.getRefDatabase().getRefs(Constants.R_HEADS).values()) {
            try {
                alreadyAccepted.add(or.rw.parseCommit(r.getObjectId()));
            } catch (IncorrectObjectTypeException iote) {
            // Not a commit? Skip over it.
            }
        }
    } catch (IOException e) {
        throw new IntegrationException("Failed to determine already accepted commits.", e);
    }
    logDebug("Found {} existing heads", alreadyAccepted.size());
    return alreadyAccepted;
}
#method_after
private Set<RevCommit> getAlreadyAccepted(OpenRepo or, CodeReviewCommit branchTip) throws IntegrationException {
    Set<RevCommit> alreadyAccepted = new HashSet<>();
    if (branchTip != null) {
        alreadyAccepted.add(branchTip);
    }
    try {
        for (Ref r : or.repo.getRefDatabase().getRefs(Constants.R_HEADS).values()) {
            try {
                CodeReviewCommit aac = or.rw.parseCommit(r.getObjectId());
                if (!commits.commits.values().contains(aac)) {
                    alreadyAccepted.add(aac);
                }
            } catch (IncorrectObjectTypeException iote) {
            // Not a commit? Skip over it.
            }
        }
    } catch (IOException e) {
        throw new IntegrationException("Failed to determine already accepted commits.", e);
    }
    logDebug("Found {} existing heads", alreadyAccepted.size());
    return alreadyAccepted;
}
#end_block

#method_before
private LabelNormalizer.Result approve(ChangeContext ctx, ChangeUpdate update) throws OrmException {
    PatchSet.Id psId = update.getPatchSetId();
    Map<PatchSetApproval.Key, PatchSetApproval> byKey = new HashMap<>();
    for (PatchSetApproval psa : args.approvalsUtil.byPatchSet(ctx.getDb(), ctx.getControl(), psId)) {
        byKey.put(psa.getKey(), psa);
    }
    submitter = new PatchSetApproval(new PatchSetApproval.Key(psId, ctx.getUser().getAccountId(), LabelId.legacySubmit()), (short) 1, ctx.getWhen());
    byKey.put(submitter.getKey(), submitter);
    submitter.setValue((short) 1);
    submitter.setGranted(ctx.getWhen());
    // Flatten out existing approvals for this patch set based upon the current
    // permissions. Once the change is closed the approvals are not updated at
    // presentation view time, except for zero votes used to indicate a reviewer
    // was added. So we need to make sure votes are accurate now. This way if
    // permissions get modified in the future, historical records stay accurate.
    LabelNormalizer.Result normalized = args.labelNormalizer.normalize(ctx.getControl(), byKey.values());
    update.putApproval(submitter.getLabel(), submitter.getValue());
    saveApprovals(normalized, ctx, update, false);
    return normalized;
}
#method_after
private LabelNormalizer.Result approve(ChangeContext ctx, ChangeUpdate update) throws OrmException {
    PatchSet.Id psId = update.getPatchSetId();
    Map<PatchSetApproval.Key, PatchSetApproval> byKey = new HashMap<>();
    for (PatchSetApproval psa : args.approvalsUtil.byPatchSet(ctx.getDb(), ctx.getControl(), psId)) {
        byKey.put(psa.getKey(), psa);
    }
    submitter = new PatchSetApproval(new PatchSetApproval.Key(psId, ctx.getAccountId(), LabelId.legacySubmit()), (short) 1, ctx.getWhen());
    byKey.put(submitter.getKey(), submitter);
    submitter.setValue((short) 1);
    submitter.setGranted(ctx.getWhen());
    // Flatten out existing approvals for this patch set based upon the current
    // permissions. Once the change is closed the approvals are not updated at
    // presentation view time, except for zero votes used to indicate a reviewer
    // was added. So we need to make sure votes are accurate now. This way if
    // permissions get modified in the future, historical records stay accurate.
    LabelNormalizer.Result normalized = args.labelNormalizer.normalize(ctx.getControl(), byKey.values());
    update.putApproval(submitter.getLabel(), submitter.getValue());
    saveApprovals(normalized, ctx, update, false);
    return normalized;
}
#end_block

#method_before
private ChangeMessage message(ChangeContext ctx, PatchSet.Id psId, String body) {
    checkNotNull(psId);
    String uuid;
    try {
        uuid = ChangeUtil.messageUUID(ctx.getDb());
    } catch (OrmException e) {
        return null;
    }
    ChangeMessage m = new ChangeMessage(new ChangeMessage.Key(psId.getParentKey(), uuid), ctx.getUser().getAccountId(), ctx.getWhen(), psId);
    m.setMessage(body);
    return m;
}
#method_after
private ChangeMessage message(ChangeContext ctx, PatchSet.Id psId, String body) {
    checkNotNull(psId);
    String uuid;
    try {
        uuid = ChangeUtil.messageUUID(ctx.getDb());
    } catch (OrmException e) {
        return null;
    }
    ChangeMessage m = new ChangeMessage(new ChangeMessage.Key(psId.getParentKey(), uuid), ctx.getAccountId(), ctx.getWhen(), psId);
    m.setMessage(body);
    return m;
}
#end_block

#method_before
@Override
public final void postUpdate(Context ctx) throws Exception {
    postUpdateImpl(ctx);
    if (command != null) {
        args.tagCache.updateFastForward(getProject(), command.getRefName(), command.getOldId(), command.getNewId());
        // per project even if multiple changes to refs/meta/config are submitted.
        if (RefNames.REFS_CONFIG.equals(getDest().get())) {
            args.projectCache.evict(getProject());
            ProjectState p = args.projectCache.get(getProject());
            args.repoManager.setProjectDescription(p.getProject().getNameKey(), p.getProject().getDescription());
        }
    }
    // have failed fast in one of the other steps.
    try {
        args.mergedSenderFactory.create(ctx.getProject(), getId(), submitter.getAccountId(), args.notifyHandling).sendAsync();
    } catch (Exception e) {
        log.error("Cannot email merged notification for " + getId(), e);
    }
    if (mergeResultRev != null) {
        try {
            args.hooks.doChangeMergedHook(updatedChange, args.accountCache.get(submitter.getAccountId()).getAccount(), mergedPatchSet, ctx.getDb(), args.mergeTip.getCurrentTip().name());
        } catch (OrmException ex) {
            logError("Cannot run hook for submitted patch set " + getId(), ex);
        }
    }
}
#method_after
@Override
public final void postUpdate(Context ctx) throws Exception {
    postUpdateImpl(ctx);
    if (command != null) {
        args.tagCache.updateFastForward(getProject(), command.getRefName(), command.getOldId(), command.getNewId());
        // per project even if multiple changes to refs/meta/config are submitted.
        if (RefNames.REFS_CONFIG.equals(getDest().get())) {
            args.projectCache.evict(getProject());
            ProjectState p = args.projectCache.get(getProject());
            args.repoManager.setProjectDescription(p.getProject().getNameKey(), p.getProject().getDescription());
        }
    }
    // have failed fast in one of the other steps.
    try {
        args.mergedSenderFactory.create(ctx.getProject(), getId(), submitter.getAccountId(), args.notifyHandling).sendAsync();
    } catch (Exception e) {
        log.error("Cannot email merged notification for " + getId(), e);
    }
    if (mergeResultRev != null) {
        args.changeMerged.fire(updatedChange, mergedPatchSet, args.accountCache.get(submitter.getAccountId()).getAccount(), args.mergeTip.getCurrentTip().name(), ctx.getWhen());
    }
}
#end_block

#method_before
private Collection<SubmoduleSubscription> superProjectSubscriptionsForSubmoduleBranch(Branch.NameKey srcBranch) throws IOException {
    logDebug("Calculating possible superprojects for " + srcBranch);
    Collection<SubmoduleSubscription> ret = new ArrayList<>();
    Project.NameKey srcProject = srcBranch.getParentKey();
    ProjectConfig cfg = projectCache.get(srcProject).getConfig();
    for (SubscribeSection s : projectStateFactory.create(cfg).getSubscribeSections(srcBranch)) {
        logDebug("Checking subscribe section " + s);
        Collection<Branch.NameKey> branches = getDestinationBranches(srcBranch, s);
        for (Branch.NameKey targetBranch : branches) {
            Project.NameKey targetProject = targetBranch.getParentKey();
            try {
                orm.openRepo(targetProject, false);
                OpenRepo or = orm.getRepo(targetProject);
                ObjectId id = or.repo.resolve(targetBranch.get());
                if (id == null) {
                    logDebug("The branch " + targetBranch + " doesn't exist.");
                    continue;
                }
            } catch (NoSuchProjectException e) {
                logDebug("The project " + targetProject + " doesn't exist");
                continue;
            }
            GitModules m = gitmodulesFactory.create(targetBranch, orm);
            for (SubmoduleSubscription ss : m.subscribedTo(srcBranch)) {
                logDebug("Checking SubmoduleSubscription " + ss);
                if (projectCache.get(ss.getSubmodule().getParentKey()) != null) {
                    logDebug("Adding SubmoduleSubscription " + ss);
                    ret.add(ss);
                }
            }
        }
    }
    logDebug("Calculated superprojects for " + srcBranch + " are " + ret);
    return ret;
}
#method_after
public Collection<SubmoduleSubscription> superProjectSubscriptionsForSubmoduleBranch(Branch.NameKey srcBranch) throws IOException {
    logDebug("Calculating possible superprojects for " + srcBranch);
    Collection<SubmoduleSubscription> ret = new ArrayList<>();
    Project.NameKey srcProject = srcBranch.getParentKey();
    ProjectConfig cfg = projectCache.get(srcProject).getConfig();
    for (SubscribeSection s : projectStateFactory.create(cfg).getSubscribeSections(srcBranch)) {
        logDebug("Checking subscribe section " + s);
        Collection<Branch.NameKey> branches = getDestinationBranches(srcBranch, s);
        for (Branch.NameKey targetBranch : branches) {
            Project.NameKey targetProject = targetBranch.getParentKey();
            try {
                orm.openRepo(targetProject, false);
                OpenRepo or = orm.getRepo(targetProject);
                ObjectId id = or.repo.resolve(targetBranch.get());
                if (id == null) {
                    logDebug("The branch " + targetBranch + " doesn't exist.");
                    continue;
                }
            } catch (NoSuchProjectException e) {
                logDebug("The project " + targetProject + " doesn't exist");
                continue;
            }
            GitModules m = branchGitModules.get(targetBranch);
            if (m == null) {
                m = gitmodulesFactory.create(targetBranch, orm);
                branchGitModules.put(targetBranch, m);
            }
            ret.addAll(m.subscribedTo(srcBranch));
        }
    }
    logDebug("Calculated superprojects for " + srcBranch + " are " + ret);
    return ret;
}
#end_block

#method_before
public void updateSuperProjects() throws SubmoduleException {
    SetMultimap<Project.NameKey, Branch.NameKey> dst = branchesByProject();
    LinkedHashSet<Project.NameKey> projects = getOrdedProjects();
    try {
        for (Project.NameKey project : projects) {
            // get a new BatchUpdate for the project
            orm.openRepo(project, false);
            orm.getRepo(project).resetUpdate();
            for (Branch.NameKey branch : dst.get(project)) {
                SubmoduleOp.RepoOnlyOp op = new SubmoduleOp.RepoOnlyOp(this, branch);
                orm.getRepo(project).getUpdate().addRepoOnlyOp(op);
            }
        }
        BatchUpdate.execute(orm.batchUpdates(projects), new Listener());
    } catch (RestApiException | UpdateException | IOException | NoSuchProjectException e) {
        throw new SubmoduleException("Cannot update gitlinks", e);
    }
}
#method_after
public void updateSuperProjects() throws SubmoduleException {
    ImmutableSet<Project.NameKey> projects = getProjectsInOrder();
    if (projects == null) {
        return;
    }
    SetMultimap<Project.NameKey, Branch.NameKey> dst = branchesByProject();
    LinkedHashSet<Project.NameKey> superProjects = new LinkedHashSet<>();
    try {
        for (Project.NameKey project : projects) {
            // only need superprojects
            if (dst.containsKey(project)) {
                superProjects.add(project);
                // get a new BatchUpdate for the super project
                orm.openRepo(project, false);
                for (Branch.NameKey branch : dst.get(project)) {
                    addOp(orm.getRepo(project).getUpdate(), branch);
                }
            }
        }
        BatchUpdate.execute(orm.batchUpdates(superProjects), Listener.NONE);
    } catch (RestApiException | UpdateException | IOException | NoSuchProjectException e) {
        throw new SubmoduleException("Cannot update gitlinks", e);
    }
}
#end_block

#method_before
public CodeReviewCommit composeGitlinksCommit(final Branch.NameKey subscriber, RevCommit baseCommit) throws IOException, SubmoduleException, OrmException {
    PersonIdent author = null;
    StringBuilder msgbuf = new StringBuilder("Update git submodules\n\n");
    boolean sameAuthorForAll = true;
    try {
        orm.openRepo(subscriber.getParentKey(), false);
    } catch (NoSuchProjectException | IOException e) {
        throw new SubmoduleException("Cannot access superproject", e);
    }
    OpenRepo or = orm.getRepo(subscriber.getParentKey());
    Ref r = or.repo.exactRef(subscriber.get());
    if (r == null) {
        throw new SubmoduleException("The branch was probably deleted from the subscriber repository");
    }
    RevCommit currentCommit = (baseCommit != null) ? baseCommit : or.rw.parseCommit(or.repo.exactRef(subscriber.get()).getObjectId());
    or.rw.parseBody(currentCommit);
    DirCache dc = readTree(or.rw, currentCommit);
    DirCacheEditor ed = dc.editor();
    for (SubmoduleSubscription s : targets.get(subscriber)) {
        try {
            orm.openRepo(s.getSubmodule().getParentKey(), false);
        } catch (NoSuchProjectException | IOException e) {
            throw new SubmoduleException("Cannot access submodule", e);
        }
        OpenRepo subOr = orm.getRepo(s.getSubmodule().getParentKey());
        Repository subRepo = subOr.repo;
        Ref ref = subRepo.getRefDatabase().exactRef(s.getSubmodule().get());
        if (ref == null) {
            ed.add(new DeletePath(s.getPath()));
            continue;
        }
        ObjectId updateTo = ref.getObjectId();
        if (branchTips.containsKey(s.getSubmodule())) {
            updateTo = branchTips.get(s.getSubmodule());
        }
        RevWalk subOrRw = subOr.rw;
        final RevCommit newCommit = subOrRw.parseCommit(updateTo);
        subOrRw.parseBody(newCommit);
        if (author == null) {
            author = newCommit.getAuthorIdent();
        } else if (!author.equals(newCommit.getAuthorIdent())) {
            sameAuthorForAll = false;
        }
        DirCacheEntry dce = dc.getEntry(s.getPath());
        ObjectId oldId;
        if (dce != null) {
            if (!dce.getFileMode().equals(FileMode.GITLINK)) {
                log.error("Requested to update gitlink " + s.getPath() + " in " + s.getSubmodule().getParentKey().get() + " but entry " + "doesn't have gitlink file mode.");
                continue;
            }
            oldId = dce.getObjectId();
        } else {
            // This submodule did not exist before. We do not want to add
            // the full submodule history to the commit message, so omit it.
            oldId = updateTo;
        }
        ed.add(new PathEdit(s.getPath()) {

            @Override
            public void apply(DirCacheEntry ent) {
                ent.setFileMode(FileMode.GITLINK);
                ent.setObjectId(newCommit.getId());
            }
        });
        if (verboseSuperProject) {
            msgbuf.append("Project: " + s.getSubmodule().getParentKey().get());
            msgbuf.append(" " + s.getSubmodule().getShortName());
            msgbuf.append(" " + newCommit.getName());
            msgbuf.append("\n\n");
            try {
                subOrRw.resetRetain(subOr.canMergeFlag);
                subOrRw.markStart(newCommit);
                subOrRw.markUninteresting(subOrRw.parseCommit(oldId));
                for (RevCommit c : subOrRw) {
                    subOrRw.parseBody(c);
                    msgbuf.append(c.getFullMessage() + "\n\n");
                }
            } catch (IOException e) {
                throw new SubmoduleException("Could not perform a revwalk to " + "create superproject commit message", e);
            }
        }
    }
    ed.finish();
    ObjectInserter oi = or.repo.newObjectInserter();
    CodeReviewRevWalk rw = or.rw;
    ObjectId tree = dc.writeTree(oi);
    if (!sameAuthorForAll || author == null) {
        author = myIdent;
    }
    CommitBuilder commit = new CommitBuilder();
    commit.setTreeId(tree);
    if (baseCommit != null) {
        // modify the baseCommit
        commit.setParentIds(baseCommit.getParents());
        commit.setMessage(baseCommit.getFullMessage() + "\n\n" + msgbuf.toString());
        commit.setAuthor(baseCommit.getAuthorIdent());
    } else {
        // create a new commit
        commit.setParentId(currentCommit);
        commit.setMessage(msgbuf.toString());
        commit.setAuthor(author);
    }
    commit.setCommitter(myIdent);
    ObjectId id = oi.insert(commit);
    oi.flush();
    return rw.parseCommit(id);
}
#method_after
public CodeReviewCommit composeGitlinksCommit(final Branch.NameKey subscriber, RevCommit baseCommit) throws IOException, SubmoduleException {
    PersonIdent author = null;
    StringBuilder msgbuf = new StringBuilder("Update git submodules\n\n");
    boolean sameAuthorForAll = true;
    try {
        orm.openRepo(subscriber.getParentKey(), false);
    } catch (NoSuchProjectException | IOException e) {
        throw new SubmoduleException("Cannot access superproject", e);
    }
    OpenRepo or = orm.getRepo(subscriber.getParentKey());
    Ref r = or.repo.exactRef(subscriber.get());
    if (r == null) {
        throw new SubmoduleException("The branch was probably deleted from the subscriber repository");
    }
    RevCommit currentCommit = (baseCommit != null) ? baseCommit : or.rw.parseCommit(or.repo.exactRef(subscriber.get()).getObjectId());
    or.rw.parseBody(currentCommit);
    DirCache dc = readTree(or.rw, currentCommit);
    DirCacheEditor ed = dc.editor();
    for (SubmoduleSubscription s : targets.get(subscriber)) {
        try {
            orm.openRepo(s.getSubmodule().getParentKey(), false);
        } catch (NoSuchProjectException | IOException e) {
            throw new SubmoduleException("Cannot access submodule", e);
        }
        OpenRepo subOr = orm.getRepo(s.getSubmodule().getParentKey());
        Repository subRepo = subOr.repo;
        Ref ref = subRepo.getRefDatabase().exactRef(s.getSubmodule().get());
        if (ref == null) {
            ed.add(new DeletePath(s.getPath()));
            continue;
        }
        ObjectId updateTo = ref.getObjectId();
        if (branchTips.containsKey(s.getSubmodule())) {
            updateTo = branchTips.get(s.getSubmodule());
        }
        RevWalk subOrRw = subOr.rw;
        final RevCommit newCommit = subOrRw.parseCommit(updateTo);
        subOrRw.parseBody(newCommit);
        if (author == null) {
            author = newCommit.getAuthorIdent();
        } else if (!author.equals(newCommit.getAuthorIdent())) {
            sameAuthorForAll = false;
        }
        DirCacheEntry dce = dc.getEntry(s.getPath());
        ObjectId oldId;
        if (dce != null) {
            if (!dce.getFileMode().equals(FileMode.GITLINK)) {
                String errMsg = "Requested to update gitlink " + s.getPath() + " in " + s.getSubmodule().getParentKey().get() + " but entry " + "doesn't have gitlink file mode.";
                throw new SubmoduleException(errMsg);
            }
            oldId = dce.getObjectId();
        } else {
            // This submodule did not exist before. We do not want to add
            // the full submodule history to the commit message, so omit it.
            oldId = updateTo;
        }
        ed.add(new PathEdit(s.getPath()) {

            @Override
            public void apply(DirCacheEntry ent) {
                ent.setFileMode(FileMode.GITLINK);
                ent.setObjectId(newCommit.getId());
            }
        });
        if (verboseSuperProject) {
            msgbuf.append("Project: " + s.getSubmodule().getParentKey().get());
            msgbuf.append(" " + s.getSubmodule().getShortName());
            msgbuf.append(" " + newCommit.getName());
            msgbuf.append("\n\n");
            try {
                subOrRw.resetRetain(subOr.canMergeFlag);
                subOrRw.markStart(newCommit);
                subOrRw.markUninteresting(subOrRw.parseCommit(oldId));
                for (RevCommit c : subOrRw) {
                    subOrRw.parseBody(c);
                    msgbuf.append(c.getFullMessage() + "\n\n");
                }
            } catch (IOException e) {
                throw new SubmoduleException("Could not perform a revwalk to " + "create superproject commit message", e);
            }
        }
    }
    ed.finish();
    ObjectInserter oi = or.ins;
    CodeReviewRevWalk rw = or.rw;
    ObjectId tree = dc.writeTree(oi);
    if (!sameAuthorForAll || author == null) {
        author = myIdent;
    }
    CommitBuilder commit = new CommitBuilder();
    commit.setTreeId(tree);
    if (baseCommit != null) {
        // modify the baseCommit
        commit.setParentIds(baseCommit.getParents());
        commit.setMessage(baseCommit.getFullMessage() + "\n\n" + msgbuf.toString());
        commit.setAuthor(baseCommit.getAuthorIdent());
    } else {
        // create a new commit
        commit.setParentId(currentCommit);
        commit.setMessage(msgbuf.toString());
        commit.setAuthor(author);
    }
    commit.setCommitter(myIdent);
    ObjectId id = oi.insert(commit);
    return rw.parseCommit(id);
}
#end_block

#method_before
private Collection<SubmoduleSubscription> superProjectSubscriptionsForSubmoduleBranch(Branch.NameKey srcBranch) throws IOException {
    logDebug("Calculating possible superprojects for " + srcBranch);
    Collection<SubmoduleSubscription> ret = new ArrayList<>();
    Project.NameKey srcProject = srcBranch.getParentKey();
    ProjectConfig cfg = projectCache.get(srcProject).getConfig();
    for (SubscribeSection s : projectStateFactory.create(cfg).getSubscribeSections(srcBranch)) {
        logDebug("Checking subscribe section " + s);
        Collection<Branch.NameKey> branches = getDestinationBranches(srcBranch, s);
        for (Branch.NameKey targetBranch : branches) {
            Project.NameKey targetProject = targetBranch.getParentKey();
            try {
                orm.openRepo(targetProject, false);
                OpenRepo or = orm.getRepo(targetProject);
                ObjectId id = or.repo.resolve(targetBranch.get());
                if (id == null) {
                    logDebug("The branch " + targetBranch + " doesn't exist.");
                    continue;
                }
            } catch (NoSuchProjectException e) {
                logDebug("The project " + targetProject + " doesn't exist");
                continue;
            }
            GitModules m = gitmodulesFactory.create(targetBranch, orm);
            for (SubmoduleSubscription ss : m.subscribedTo(srcBranch)) {
                logDebug("Checking SubmoduleSubscription " + ss);
                if (projectCache.get(ss.getSubmodule().getParentKey()) != null) {
                    logDebug("Adding SubmoduleSubscription " + ss);
                    ret.add(ss);
                }
            }
        }
    }
    logDebug("Calculated superprojects for " + srcBranch + " are " + ret);
    return ret;
}
#method_after
public Collection<SubmoduleSubscription> superProjectSubscriptionsForSubmoduleBranch(Branch.NameKey srcBranch) throws IOException {
    logDebug("Calculating possible superprojects for " + srcBranch);
    Collection<SubmoduleSubscription> ret = new ArrayList<>();
    Project.NameKey srcProject = srcBranch.getParentKey();
    ProjectConfig cfg = projectCache.get(srcProject).getConfig();
    for (SubscribeSection s : projectStateFactory.create(cfg).getSubscribeSections(srcBranch)) {
        logDebug("Checking subscribe section " + s);
        Collection<Branch.NameKey> branches = getDestinationBranches(srcBranch, s);
        for (Branch.NameKey targetBranch : branches) {
            Project.NameKey targetProject = targetBranch.getParentKey();
            try {
                orm.openRepo(targetProject, false);
                OpenRepo or = orm.getRepo(targetProject);
                ObjectId id = or.repo.resolve(targetBranch.get());
                if (id == null) {
                    logDebug("The branch " + targetBranch + " doesn't exist.");
                    continue;
                }
            } catch (NoSuchProjectException e) {
                logDebug("The project " + targetProject + " doesn't exist");
                continue;
            }
            GitModules m = branchGitModules.get(targetBranch);
            if (m == null) {
                m = gitmodulesFactory.create(targetBranch, orm);
                branchGitModules.put(targetBranch, m);
            }
            ret.addAll(m.subscribedTo(srcBranch));
        }
    }
    logDebug("Calculated superprojects for " + srcBranch + " are " + ret);
    return ret;
}
#end_block

#method_before
public void updateSuperProjects() throws SubmoduleException {
    SetMultimap<Project.NameKey, Branch.NameKey> dst = branchesByProject();
    LinkedHashSet<Project.NameKey> projects = getOrdedProjects();
    try {
        for (Project.NameKey project : projects) {
            // get a new BatchUpdate for the project
            orm.openRepo(project, false);
            orm.getRepo(project).resetUpdate();
            for (Branch.NameKey branch : dst.get(project)) {
                SubmoduleOp.RepoOnlyOp op = new SubmoduleOp.RepoOnlyOp(this, branch);
                orm.getRepo(project).getUpdate().addRepoOnlyOp(op);
            }
        }
        BatchUpdate.execute(orm.batchUpdates(projects), new Listener());
    } catch (RestApiException | UpdateException | IOException | NoSuchProjectException e) {
        throw new SubmoduleException("Cannot update gitlinks", e);
    }
}
#method_after
public void updateSuperProjects() throws SubmoduleException {
    ImmutableSet<Project.NameKey> projects = getProjectsInOrder();
    if (projects == null) {
        return;
    }
    SetMultimap<Project.NameKey, Branch.NameKey> dst = branchesByProject();
    LinkedHashSet<Project.NameKey> superProjects = new LinkedHashSet<>();
    try {
        for (Project.NameKey project : projects) {
            // only need superprojects
            if (dst.containsKey(project)) {
                superProjects.add(project);
                // get a new BatchUpdate for the super project
                orm.openRepo(project, false);
                // TODO:czhen remove this when MergeOp combine this into BatchUpdate
                orm.getRepo(project).resetUpdate();
                for (Branch.NameKey branch : dst.get(project)) {
                    SubmoduleOp.GitlinkOp op = new SubmoduleOp.GitlinkOp(branch);
                    orm.getRepo(project).getUpdate().addRepoOnlyOp(op);
                }
            }
        }
        BatchUpdate.execute(orm.batchUpdates(superProjects), Listener.NONE);
    } catch (RestApiException | UpdateException | IOException | NoSuchProjectException e) {
        throw new SubmoduleException("Cannot update gitlinks", e);
    }
}
#end_block

#method_before
public CodeReviewCommit composeGitlinksCommit(final Branch.NameKey subscriber, RevCommit baseCommit) throws IOException, SubmoduleException, OrmException {
    PersonIdent author = null;
    StringBuilder msgbuf = new StringBuilder("Update git submodules\n\n");
    boolean sameAuthorForAll = true;
    try {
        orm.openRepo(subscriber.getParentKey(), false);
    } catch (NoSuchProjectException | IOException e) {
        throw new SubmoduleException("Cannot access superproject", e);
    }
    OpenRepo or = orm.getRepo(subscriber.getParentKey());
    Ref r = or.repo.exactRef(subscriber.get());
    if (r == null) {
        throw new SubmoduleException("The branch was probably deleted from the subscriber repository");
    }
    RevCommit currentCommit = (baseCommit != null) ? baseCommit : or.rw.parseCommit(or.repo.exactRef(subscriber.get()).getObjectId());
    or.rw.parseBody(currentCommit);
    DirCache dc = readTree(or.rw, currentCommit);
    DirCacheEditor ed = dc.editor();
    for (SubmoduleSubscription s : targets.get(subscriber)) {
        try {
            orm.openRepo(s.getSubmodule().getParentKey(), false);
        } catch (NoSuchProjectException | IOException e) {
            throw new SubmoduleException("Cannot access submodule", e);
        }
        OpenRepo subOr = orm.getRepo(s.getSubmodule().getParentKey());
        Repository subRepo = subOr.repo;
        Ref ref = subRepo.getRefDatabase().exactRef(s.getSubmodule().get());
        if (ref == null) {
            ed.add(new DeletePath(s.getPath()));
            continue;
        }
        ObjectId updateTo = ref.getObjectId();
        if (branchTips.containsKey(s.getSubmodule())) {
            updateTo = branchTips.get(s.getSubmodule());
        }
        RevWalk subOrRw = subOr.rw;
        final RevCommit newCommit = subOrRw.parseCommit(updateTo);
        subOrRw.parseBody(newCommit);
        if (author == null) {
            author = newCommit.getAuthorIdent();
        } else if (!author.equals(newCommit.getAuthorIdent())) {
            sameAuthorForAll = false;
        }
        DirCacheEntry dce = dc.getEntry(s.getPath());
        ObjectId oldId;
        if (dce != null) {
            if (!dce.getFileMode().equals(FileMode.GITLINK)) {
                log.error("Requested to update gitlink " + s.getPath() + " in " + s.getSubmodule().getParentKey().get() + " but entry " + "doesn't have gitlink file mode.");
                continue;
            }
            oldId = dce.getObjectId();
        } else {
            // This submodule did not exist before. We do not want to add
            // the full submodule history to the commit message, so omit it.
            oldId = updateTo;
        }
        ed.add(new PathEdit(s.getPath()) {

            @Override
            public void apply(DirCacheEntry ent) {
                ent.setFileMode(FileMode.GITLINK);
                ent.setObjectId(newCommit.getId());
            }
        });
        if (verboseSuperProject) {
            msgbuf.append("Project: " + s.getSubmodule().getParentKey().get());
            msgbuf.append(" " + s.getSubmodule().getShortName());
            msgbuf.append(" " + newCommit.getName());
            msgbuf.append("\n\n");
            try {
                subOrRw.resetRetain(subOr.canMergeFlag);
                subOrRw.markStart(newCommit);
                subOrRw.markUninteresting(subOrRw.parseCommit(oldId));
                for (RevCommit c : subOrRw) {
                    subOrRw.parseBody(c);
                    msgbuf.append(c.getFullMessage() + "\n\n");
                }
            } catch (IOException e) {
                throw new SubmoduleException("Could not perform a revwalk to " + "create superproject commit message", e);
            }
        }
    }
    ed.finish();
    ObjectInserter oi = or.repo.newObjectInserter();
    CodeReviewRevWalk rw = or.rw;
    ObjectId tree = dc.writeTree(oi);
    if (!sameAuthorForAll || author == null) {
        author = myIdent;
    }
    CommitBuilder commit = new CommitBuilder();
    commit.setTreeId(tree);
    if (baseCommit != null) {
        // modify the baseCommit
        commit.setParentIds(baseCommit.getParents());
        commit.setMessage(baseCommit.getFullMessage() + "\n\n" + msgbuf.toString());
        commit.setAuthor(baseCommit.getAuthorIdent());
    } else {
        // create a new commit
        commit.setParentId(currentCommit);
        commit.setMessage(msgbuf.toString());
        commit.setAuthor(author);
    }
    commit.setCommitter(myIdent);
    ObjectId id = oi.insert(commit);
    oi.flush();
    return rw.parseCommit(id);
}
#method_after
public CodeReviewCommit composeGitlinksCommit(final Branch.NameKey subscriber, RevCommit baseCommit) throws IOException, SubmoduleException {
    PersonIdent author = null;
    StringBuilder msgbuf = new StringBuilder("Update git submodules\n\n");
    boolean sameAuthorForAll = true;
    try {
        orm.openRepo(subscriber.getParentKey(), false);
    } catch (NoSuchProjectException | IOException e) {
        throw new SubmoduleException("Cannot access superproject", e);
    }
    OpenRepo or = orm.getRepo(subscriber.getParentKey());
    Ref r = or.repo.exactRef(subscriber.get());
    if (r == null) {
        throw new SubmoduleException("The branch was probably deleted from the subscriber repository");
    }
    RevCommit currentCommit = (baseCommit != null) ? baseCommit : or.rw.parseCommit(or.repo.exactRef(subscriber.get()).getObjectId());
    or.rw.parseBody(currentCommit);
    DirCache dc = readTree(or.rw, currentCommit);
    DirCacheEditor ed = dc.editor();
    for (SubmoduleSubscription s : targets.get(subscriber)) {
        try {
            orm.openRepo(s.getSubmodule().getParentKey(), false);
        } catch (NoSuchProjectException | IOException e) {
            throw new SubmoduleException("Cannot access submodule", e);
        }
        OpenRepo subOr = orm.getRepo(s.getSubmodule().getParentKey());
        Repository subRepo = subOr.repo;
        Ref ref = subRepo.getRefDatabase().exactRef(s.getSubmodule().get());
        if (ref == null) {
            ed.add(new DeletePath(s.getPath()));
            continue;
        }
        ObjectId updateTo = ref.getObjectId();
        if (branchTips.containsKey(s.getSubmodule())) {
            updateTo = branchTips.get(s.getSubmodule());
        }
        RevWalk subOrRw = subOr.rw;
        final RevCommit newCommit = subOrRw.parseCommit(updateTo);
        subOrRw.parseBody(newCommit);
        if (author == null) {
            author = newCommit.getAuthorIdent();
        } else if (!author.equals(newCommit.getAuthorIdent())) {
            sameAuthorForAll = false;
        }
        DirCacheEntry dce = dc.getEntry(s.getPath());
        ObjectId oldId;
        if (dce != null) {
            if (!dce.getFileMode().equals(FileMode.GITLINK)) {
                String errMsg = "Requested to update gitlink " + s.getPath() + " in " + s.getSubmodule().getParentKey().get() + " but entry " + "doesn't have gitlink file mode.";
                throw new SubmoduleException(errMsg);
            }
            oldId = dce.getObjectId();
        } else {
            // This submodule did not exist before. We do not want to add
            // the full submodule history to the commit message, so omit it.
            oldId = updateTo;
        }
        ed.add(new PathEdit(s.getPath()) {

            @Override
            public void apply(DirCacheEntry ent) {
                ent.setFileMode(FileMode.GITLINK);
                ent.setObjectId(newCommit.getId());
            }
        });
        if (verboseSuperProject) {
            msgbuf.append("Project: " + s.getSubmodule().getParentKey().get());
            msgbuf.append(" " + s.getSubmodule().getShortName());
            msgbuf.append(" " + newCommit.getName());
            msgbuf.append("\n\n");
            try {
                subOrRw.resetRetain(subOr.canMergeFlag);
                subOrRw.markStart(newCommit);
                subOrRw.markUninteresting(subOrRw.parseCommit(oldId));
                for (RevCommit c : subOrRw) {
                    subOrRw.parseBody(c);
                    msgbuf.append(c.getFullMessage() + "\n\n");
                }
            } catch (IOException e) {
                throw new SubmoduleException("Could not perform a revwalk to " + "create superproject commit message", e);
            }
        }
    }
    ed.finish();
    ObjectInserter oi = or.ins;
    CodeReviewRevWalk rw = or.rw;
    ObjectId tree = dc.writeTree(oi);
    if (!sameAuthorForAll || author == null) {
        author = myIdent;
    }
    CommitBuilder commit = new CommitBuilder();
    commit.setTreeId(tree);
    if (baseCommit != null) {
        // modify the baseCommit
        commit.setParentIds(baseCommit.getParents());
        commit.setMessage(baseCommit.getFullMessage() + "\n\n" + msgbuf.toString());
        commit.setAuthor(baseCommit.getAuthorIdent());
    } else {
        // create a new commit
        commit.setParentId(currentCommit);
        commit.setMessage(msgbuf.toString());
        commit.setAuthor(author);
    }
    commit.setCommitter(myIdent);
    ObjectId id = oi.insert(commit);
    return rw.parseCommit(id);
}
#end_block

#method_before
@Test
public void testRecursiveSubmodules() throws Exception {
    TestRepository<?> topRepo = createProjectWithPush("top-project");
    TestRepository<?> midRepo = createProjectWithPush("mid-project");
    TestRepository<?> bottomRepo = createProjectWithPush("bottom-project");
    allowSubmoduleSubscription("mid-project", "refs/heads/master", "top-project", "refs/heads/master");
    allowSubmoduleSubscription("bottom-project", "refs/heads/master", "mid-project", "refs/heads/master");
    createSubmoduleSubscription(topRepo, "master", "mid-project", "master");
    createSubmoduleSubscription(midRepo, "master", "bottom-project", "master");
    ObjectId bottomHead = bottomRepo.branch("HEAD").commit().insertChangeId().message("some change").add("a.txt", "a contents ").create();
    bottomRepo.git().push().setRemote("origin").setRefSpecs(new RefSpec("HEAD:refs/heads/master")).call();
    RevCommit c = bottomRepo.getRevWalk().parseCommit(bottomHead);
    RevCommit c1 = bottomRepo.branch("HEAD").commit().insertChangeId().message("first change").add("asdf", "asdf\n").create();
    bottomRepo.git().push().setRemote("origin").setRefSpecs(new RefSpec("HEAD:refs/for/master/" + name("topic-foo"))).call();
    bottomRepo.reset(c.getId());
    RevCommit c2 = bottomRepo.branch("HEAD").commit().insertChangeId().message("qwerty").add("qwerty", "qwerty").create();
    RevCommit c3 = bottomRepo.branch("HEAD").commit().insertChangeId().message("qwerty followup").add("qwerty", "qwerty\nqwerty\n").create();
    bottomRepo.git().push().setRemote("origin").setRefSpecs(new RefSpec("HEAD:refs/for/master/" + name("topic-foo"))).call();
    RevCommit c4 = topRepo.branch("HEAD").commit().insertChangeId().message("new change on top project").add("foo", "bar").create();
    topRepo.git().push().setRemote("origin").setRefSpecs(new RefSpec("HEAD:refs/for/master/" + name("topic-foo"))).call();
    String id1 = getChangeId(bottomRepo, c1).get();
    String id2 = getChangeId(bottomRepo, c2).get();
    String id3 = getChangeId(bottomRepo, c3).get();
    String id4 = getChangeId(topRepo, c4).get();
    gApi.changes().id(id1).current().review(ReviewInput.approve());
    gApi.changes().id(id2).current().review(ReviewInput.approve());
    gApi.changes().id(id3).current().review(ReviewInput.approve());
    gApi.changes().id(id4).current().review(ReviewInput.approve());
    gApi.changes().id(id1).current().submit();
    ObjectId bottomRepoId = bottomRepo.git().fetch().setRemote("origin").call().getAdvertisedRef("refs/heads/master").getObjectId();
    ObjectId midRepoId = midRepo.git().fetch().setRemote("origin").call().getAdvertisedRef("refs/heads/master").getObjectId();
    expectToHaveSubmoduleState(midRepo, "master", "bottom-project", bottomRepoId);
    expectToHaveSubmoduleState(topRepo, "master", "mid-project", midRepoId);
}
#method_after
@Test
public void testRecursiveSubmodules() throws Exception {
    TestRepository<?> topRepo = createProjectWithPush("top-project");
    TestRepository<?> midRepo = createProjectWithPush("mid-project");
    TestRepository<?> bottomRepo = createProjectWithPush("bottom-project");
    allowSubmoduleSubscription("mid-project", "refs/heads/master", "top-project", "refs/heads/master");
    allowSubmoduleSubscription("bottom-project", "refs/heads/master", "mid-project", "refs/heads/master");
    createSubmoduleSubscription(topRepo, "master", "mid-project", "master");
    createSubmoduleSubscription(midRepo, "master", "bottom-project", "master");
    ObjectId bottomHead = pushChangeTo(bottomRepo, "refs/for/master", "some message", "same-topic");
    ObjectId topHead = pushChangeTo(topRepo, "refs/for/master", "some message", "same-topic");
    String id1 = getChangeId(bottomRepo, bottomHead).get();
    String id2 = getChangeId(topRepo, topHead).get();
    gApi.changes().id(id1).current().review(ReviewInput.approve());
    gApi.changes().id(id2).current().review(ReviewInput.approve());
    gApi.changes().id(id1).current().submit();
    assertThat(hasSubmodule(midRepo, "master", "bottom-project")).isTrue();
    assertThat(hasSubmodule(topRepo, "master", "mid-project")).isTrue();
}
#end_block

#method_before
private PatchList readPatchList(final PatchListKey key, final Repository repo) throws IOException, PatchListNotAvailableException {
    final RawTextComparator cmp = comparatorFor(key.getWhitespace());
    try (ObjectReader reader = repo.newObjectReader();
        RevWalk rw = new RevWalk(reader);
        DiffFormatter df = new DiffFormatter(DisabledOutputStream.INSTANCE)) {
        // b - current commit object (not a hash commit)
        final RevCommit b = rw.parseCommit(key.getNewId());
        // a - ancestor object
        final RevObject a = aFor(key, repo, rw, b);
        if (a == null) {
            // TODO(sop) Remove this case.
            // This is a merge commit, compared to its ancestor.
            // 
            final PatchListEntry[] entries = new PatchListEntry[1];
            entries[0] = newCommitMessage(cmp, reader, null, b);
            return new PatchList(a, b, true, entries);
        }
        final boolean againstParent = b.getParentCount() > 0 && b.getParent(0) == a;
        RevCommit aCommit = a instanceof RevCommit ? (RevCommit) a : null;
        RevTree aTree = rw.parseTree(a);
        RevTree bTree = b.getTree();
        df.setRepository(repo);
        df.setDiffComparator(cmp);
        df.setDetectRenames(true);
        List<DiffEntry> diffEntries = df.scan(aTree, bTree);
        Set<String> paths = null;
        if (key.getOldId() != null) {
            PatchListKey newKey = new PatchListKey(null, key.getNewId(), key.getWhitespace());
            PatchListKey oldKey = new PatchListKey(null, key.getOldId(), key.getWhitespace());
            paths = FluentIterable.from(patchListCache.get(newKey, project).getPatches()).append(patchListCache.get(oldKey, project).getPatches()).transform(new Function<PatchListEntry, String>() {

                @Override
                public String apply(PatchListEntry entry) {
                    return entry.getNewName();
                }
            }).toSet();
        }
        int cnt = diffEntries.size();
        List<PatchListEntry> entries = new ArrayList<>();
        entries.add(newCommitMessage(cmp, reader, againstParent ? null : aCommit, b));
        for (int i = 0; i < cnt; i++) {
            DiffEntry e = diffEntries.get(i);
            if (paths == null || paths.contains(e.getNewPath()) || paths.contains(e.getOldPath())) {
                FileHeader fh = toFileHeader(key, df, e);
                long oldSize = getFileSize(repo, reader, e.getOldMode(), e.getOldPath(), aTree);
                long newSize = getFileSize(repo, reader, e.getNewMode(), e.getNewPath(), bTree);
                entries.add(newEntry(aTree, fh, newSize - oldSize));
            }
        }
        return new PatchList(a, b, againstParent, entries.toArray(new PatchListEntry[entries.size()]));
    }
}
#method_after
private PatchList readPatchList(final PatchListKey key, final Repository repo) throws IOException, PatchListNotAvailableException {
    final RawTextComparator cmp = comparatorFor(key.getWhitespace());
    try (ObjectInserter ins = repo.newObjectInserter();
        ObjectReader reader = ins.newReader();
        RevWalk rw = new RevWalk(reader);
        DiffFormatter df = new DiffFormatter(DisabledOutputStream.INSTANCE)) {
        final RevCommit b = rw.parseCommit(key.getNewId());
        final RevObject a = aFor(key, repo, rw, ins, b);
        if (a == null) {
            // TODO(sop) Remove this case.
            // This is a merge commit, compared to its ancestor.
            // 
            final PatchListEntry[] entries = new PatchListEntry[1];
            entries[0] = newCommitMessage(cmp, reader, null, b);
            return new PatchList(a, b, true, entries);
        }
        final boolean againstParent = b.getParentCount() > 0 && b.getParent(0) == a;
        RevCommit aCommit = a instanceof RevCommit ? (RevCommit) a : null;
        RevTree aTree = rw.parseTree(a);
        RevTree bTree = b.getTree();
        df.setRepository(repo);
        df.setDiffComparator(cmp);
        df.setDetectRenames(true);
        List<DiffEntry> diffEntries = df.scan(aTree, bTree);
        Set<String> paths = null;
        if (key.getOldId() != null && b.getParentCount() == 1) {
            PatchListKey newKey = PatchListKey.againstDefaultBase(key.getNewId(), key.getWhitespace());
            PatchListKey oldKey = PatchListKey.againstDefaultBase(key.getOldId(), key.getWhitespace());
            paths = FluentIterable.from(patchListCache.get(newKey, project).getPatches()).append(patchListCache.get(oldKey, project).getPatches()).transform(new Function<PatchListEntry, String>() {

                @Override
                public String apply(PatchListEntry entry) {
                    return entry.getNewName();
                }
            }).toSet();
        }
        int cnt = diffEntries.size();
        List<PatchListEntry> entries = new ArrayList<>();
        entries.add(newCommitMessage(cmp, reader, againstParent ? null : aCommit, b));
        for (int i = 0; i < cnt; i++) {
            DiffEntry e = diffEntries.get(i);
            if (paths == null || paths.contains(e.getNewPath()) || paths.contains(e.getOldPath())) {
                FileHeader fh = toFileHeader(key, df, e);
                long oldSize = getFileSize(repo, reader, e.getOldMode(), e.getOldPath(), aTree);
                long newSize = getFileSize(repo, reader, e.getNewMode(), e.getNewPath(), bTree);
                entries.add(newEntry(aTree, fh, newSize, newSize - oldSize));
            }
        }
        return new PatchList(a, b, againstParent, entries.toArray(new PatchListEntry[entries.size()]));
    }
}
#end_block

#method_before
private FileHeader toFileHeader(PatchListKey key, final DiffFormatter diffFormatter, final DiffEntry diffEntry) throws IOException {
    Future<FileHeader> result = diffExecutor.submit(new Callable<FileHeader>() {

        @Override
        public FileHeader call() throws IOException {
            synchronized (lock) {
                return diffFormatter.toFileHeader(diffEntry);
            }
        }
    });
    try {
        return result.get(timeoutMillis, TimeUnit.MILLISECONDS);
    } catch (InterruptedException | TimeoutException e) {
        log.warn(timeoutMillis + " ms timeout reached for Diff loader" + " in project " + project + " on commit " + key.getNewId().name() + " on path " + diffEntry.getNewPath() + " comparing " + diffEntry.getOldId().name() + ".." + diffEntry.getNewId().name());
        result.cancel(true);
        synchronized (lock) {
            return toFileHeaderWithoutMyersDiff(diffFormatter, diffEntry);
        }
    } catch (ExecutionException e) {
        // If there was an error computing the result, carry it
        // up to the caller so the cache knows this key is invalid.
        Throwables.propagateIfInstanceOf(e.getCause(), IOException.class);
        throw new IOException(e.getMessage(), e.getCause());
    }
}
#method_after
private FileHeader toFileHeader(PatchListKey key, final DiffFormatter diffFormatter, final DiffEntry diffEntry) throws IOException {
    Future<FileHeader> result = diffExecutor.submit(new Callable<FileHeader>() {

        @Override
        public FileHeader call() throws IOException {
            synchronized (diffEntry) {
                return diffFormatter.toFileHeader(diffEntry);
            }
        }
    });
    try {
        return result.get(timeoutMillis, TimeUnit.MILLISECONDS);
    } catch (InterruptedException | TimeoutException e) {
        log.warn(timeoutMillis + " ms timeout reached for Diff loader" + " in project " + project + " on commit " + key.getNewId().name() + " on path " + diffEntry.getNewPath() + " comparing " + diffEntry.getOldId().name() + ".." + diffEntry.getNewId().name());
        result.cancel(true);
        synchronized (diffEntry) {
            return toFileHeaderWithoutMyersDiff(diffFormatter, diffEntry);
        }
    } catch (ExecutionException e) {
        // If there was an error computing the result, carry it
        // up to the caller so the cache knows this key is invalid.
        Throwables.propagateIfInstanceOf(e.getCause(), IOException.class);
        throw new IOException(e.getMessage(), e.getCause());
    }
}
#end_block

#method_before
private PatchListEntry newCommitMessage(final RawTextComparator cmp, final ObjectReader reader, final RevCommit aCommit, final RevCommit bCommit) throws IOException {
    StringBuilder hdr = new StringBuilder();
    hdr.append("diff --git");
    if (aCommit != null) {
        hdr.append(" a/").append(Patch.COMMIT_MSG);
    } else {
        hdr.append(" ").append(FileHeader.DEV_NULL);
    }
    hdr.append(" b/").append(Patch.COMMIT_MSG);
    hdr.append("\n");
    if (aCommit != null) {
        hdr.append("--- a/").append(Patch.COMMIT_MSG).append("\n");
    } else {
        hdr.append("--- ").append(FileHeader.DEV_NULL).append("\n");
    }
    hdr.append("+++ b/").append(Patch.COMMIT_MSG).append("\n");
    Text aText = aCommit != null ? Text.forCommit(reader, aCommit) : Text.EMPTY;
    Text bText = Text.forCommit(reader, bCommit);
    byte[] rawHdr = hdr.toString().getBytes(UTF_8);
    byte[] aContent = aText.getContent();
    byte[] bContent = bText.getContent();
    long sizeDelta = bContent.length - aContent.length;
    RawText aRawText = new RawText(aContent);
    RawText bRawText = new RawText(bContent);
    EditList edits = new HistogramDiff().diff(cmp, aRawText, bRawText);
    FileHeader fh = new FileHeader(rawHdr, edits, PatchType.UNIFIED);
    return new PatchListEntry(fh, edits, sizeDelta);
}
#method_after
private PatchListEntry newCommitMessage(final RawTextComparator cmp, final ObjectReader reader, final RevCommit aCommit, final RevCommit bCommit) throws IOException {
    StringBuilder hdr = new StringBuilder();
    hdr.append("diff --git");
    if (aCommit != null) {
        hdr.append(" a/").append(Patch.COMMIT_MSG);
    } else {
        hdr.append(" ").append(FileHeader.DEV_NULL);
    }
    hdr.append(" b/").append(Patch.COMMIT_MSG);
    hdr.append("\n");
    if (aCommit != null) {
        hdr.append("--- a/").append(Patch.COMMIT_MSG).append("\n");
    } else {
        hdr.append("--- ").append(FileHeader.DEV_NULL).append("\n");
    }
    hdr.append("+++ b/").append(Patch.COMMIT_MSG).append("\n");
    Text aText = aCommit != null ? Text.forCommit(reader, aCommit) : Text.EMPTY;
    Text bText = Text.forCommit(reader, bCommit);
    byte[] rawHdr = hdr.toString().getBytes(UTF_8);
    byte[] aContent = aText.getContent();
    byte[] bContent = bText.getContent();
    long size = bContent.length;
    long sizeDelta = bContent.length - aContent.length;
    RawText aRawText = new RawText(aContent);
    RawText bRawText = new RawText(bContent);
    EditList edits = new HistogramDiff().diff(cmp, aRawText, bRawText);
    FileHeader fh = new FileHeader(rawHdr, edits, PatchType.UNIFIED);
    return new PatchListEntry(fh, edits, size, sizeDelta);
}
#end_block

#method_before
private PatchListEntry newEntry(RevTree aTree, FileHeader fileHeader, long sizeDelta) {
    final FileMode oldMode = fileHeader.getOldMode();
    final FileMode newMode = fileHeader.getNewMode();
    if (oldMode == FileMode.GITLINK || newMode == FileMode.GITLINK) {
        return new PatchListEntry(fileHeader, Collections.<Edit>emptyList(), sizeDelta);
    }
    if (// want combined diff
    aTree == null || fileHeader.getPatchType() != PatchType.UNIFIED || fileHeader.getHunks().isEmpty()) {
        return new PatchListEntry(fileHeader, Collections.<Edit>emptyList(), sizeDelta);
    }
    List<Edit> edits = fileHeader.toEditList();
    if (edits.isEmpty()) {
        return new PatchListEntry(fileHeader, Collections.<Edit>emptyList(), sizeDelta);
    } else {
        return new PatchListEntry(fileHeader, edits, sizeDelta);
    }
}
#method_after
private PatchListEntry newEntry(RevTree aTree, FileHeader fileHeader, long size, long sizeDelta) {
    if (// want combined diff
    aTree == null || fileHeader.getPatchType() != PatchType.UNIFIED || fileHeader.getHunks().isEmpty()) {
        return new PatchListEntry(fileHeader, Collections.<Edit>emptyList(), size, sizeDelta);
    }
    List<Edit> edits = fileHeader.toEditList();
    if (edits.isEmpty()) {
        return new PatchListEntry(fileHeader, Collections.<Edit>emptyList(), size, sizeDelta);
    }
    return new PatchListEntry(fileHeader, edits, size, sizeDelta);
}
#end_block

#method_before
private RevObject aFor(final PatchListKey key, final Repository repo, final RevWalk rw, final RevCommit b) throws IOException {
    if (key.getOldId() != null) {
        return rw.parseAny(key.getOldId());
    }
    switch(b.getParentCount()) {
        case 0:
            return rw.parseAny(emptyTree(repo));
        case 1:
            {
                RevCommit r = b.getParent(0);
                rw.parseBody(r);
                return r;
            }
        case 2:
            return automerge(repo, rw, b, mergeStrategy);
        default:
            // TODO(sop) handle an octopus merge.
            return null;
    }
}
#method_after
private RevObject aFor(PatchListKey key, Repository repo, RevWalk rw, ObjectInserter ins, RevCommit b) throws IOException {
    if (key.getOldId() != null) {
        return rw.parseAny(key.getOldId());
    }
    switch(b.getParentCount()) {
        case 0:
            return rw.parseAny(emptyTree(repo));
        case 1:
            {
                RevCommit r = b.getParent(0);
                rw.parseBody(r);
                return r;
            }
        case 2:
            if (key.getParentNum() != null) {
                RevCommit r = b.getParent(key.getParentNum() - 1);
                rw.parseBody(r);
                return r;
            }
            return autoMerger.merge(repo, rw, ins, b, mergeStrategy);
        default:
            // TODO(sop) handle an octopus merge.
            return null;
    }
}
#end_block

#method_before
@Test
public void pushWatchConfigToUserBranch() throws Exception {
    // change something in the user preferences to ensure that the user branch
    // is created
    GeneralPreferencesInfo input = new GeneralPreferencesInfo();
    input.changesPerPage = GeneralPreferencesInfo.defaults().changesPerPage + 10;
    gApi.accounts().self().setPreferences(input);
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers);
    fetch(allUsersRepo, RefNames.refsUsers(admin.id) + ":userRef");
    allUsersRepo.reset("userRef");
    Config wc = new Config();
    wc.setString(WatchConfig.PROJECT, project.get(), WatchConfig.KEY_NOTIFY, NotifyValue.create(null, EnumSet.of(NotifyType.ALL_COMMENTS)).toString());
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), allUsersRepo, "Add project watch", WatchConfig.WATCH_CONFIG, wc.toText());
    push.to(RefNames.REFS_USERS_SELF).assertOkStatus();
    String invalidNotifyValue = "]invalid[";
    wc.setString(WatchConfig.PROJECT, project.get(), WatchConfig.KEY_NOTIFY, invalidNotifyValue);
    push = pushFactory.create(db, admin.getIdent(), allUsersRepo, "Add invalid project watch", WatchConfig.WATCH_CONFIG, wc.toText());
    PushOneCommit.Result r = push.to(RefNames.REFS_USERS_SELF);
    r.assertErrorStatus("invalid watch configuration");
    r.assertMessage(String.format("%s: Invalid project watch of account %d for project %s: %s", WatchConfig.WATCH_CONFIG, admin.getId().get(), project.get(), invalidNotifyValue));
}
#method_after
@Test
public void pushWatchConfigToUserBranch() throws Exception {
    // change something in the user preferences to ensure that the user branch
    // is created
    GeneralPreferencesInfo input = new GeneralPreferencesInfo();
    input.changesPerPage = GeneralPreferencesInfo.defaults().changesPerPage + 10;
    gApi.accounts().self().setPreferences(input);
    TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers);
    fetch(allUsersRepo, RefNames.refsUsers(admin.id) + ":userRef");
    allUsersRepo.reset("userRef");
    Config wc = new Config();
    wc.setString(WatchConfig.PROJECT, project.get(), WatchConfig.KEY_NOTIFY, WatchConfig.NotifyValue.create(null, EnumSet.of(NotifyType.ALL_COMMENTS)).toString());
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), allUsersRepo, "Add project watch", WatchConfig.WATCH_CONFIG, wc.toText());
    push.to(RefNames.REFS_USERS_SELF).assertOkStatus();
    String invalidNotifyValue = "]invalid[";
    wc.setString(WatchConfig.PROJECT, project.get(), WatchConfig.KEY_NOTIFY, invalidNotifyValue);
    push = pushFactory.create(db, admin.getIdent(), allUsersRepo, "Add invalid project watch", WatchConfig.WATCH_CONFIG, wc.toText());
    PushOneCommit.Result r = push.to(RefNames.REFS_USERS_SELF);
    r.assertErrorStatus("invalid watch configuration");
    r.assertMessage(String.format("%s: Invalid project watch of account %d for project %s: %s", WatchConfig.WATCH_CONFIG, admin.getId().get(), project.get(), invalidNotifyValue));
}
#end_block

#method_before
@Override
public List<CommitValidationMessage> onCommitReceived(CommitReceivedEvent receiveEvent) throws CommitValidationException {
    IdentifiedUser currentUser = refControl.getUser().asIdentifiedUser();
    if (REFS_CONFIG.equals(refControl.getRefName())) {
        List<CommitValidationMessage> messages = new LinkedList<>();
        try {
            ProjectConfig cfg = new ProjectConfig(receiveEvent.project.getNameKey());
            cfg.load(repo, receiveEvent.command.getNewId());
            if (!cfg.getValidationErrors().isEmpty()) {
                addError("Invalid project configuration:", messages);
                for (ValidationError err : cfg.getValidationErrors()) {
                    addError("  " + err.getMessage(), messages);
                }
                throw new ConfigInvalidException("invalid project configuration");
            }
        } catch (Exception e) {
            log.error("User " + currentUser.getUserName() + " tried to push invalid project configuration " + receiveEvent.command.getNewId().name() + " for " + receiveEvent.project.getName(), e);
            throw new CommitValidationException("invalid project configuration", messages);
        }
    }
    if (allUsers.equals(refControl.getProjectControl().getProject().getNameKey()) && RefNames.isRefsUsers(refControl.getRefName())) {
        List<CommitValidationMessage> messages = new LinkedList<>();
        Account.Id accountId = Account.Id.fromRef(refControl.getRefName());
        if (accountId != null) {
            try {
                @SuppressWarnings("resource")
                WatchConfig wc = new WatchConfig(accountId);
                wc.load(repo, receiveEvent.command.getNewId());
                if (!wc.getValidationErrors().isEmpty()) {
                    addError("Invalid project configuration:", messages);
                    for (ValidationError err : wc.getValidationErrors()) {
                        addError("  " + err.getMessage(), messages);
                    }
                    throw new ConfigInvalidException("invalid watch configuration");
                }
            } catch (IOException | ConfigInvalidException e) {
                log.error("User " + currentUser.getUserName() + " tried to push an invalid watch configuration " + receiveEvent.command.getNewId().name() + " for account " + accountId.get(), e);
                throw new CommitValidationException("invalid watch configuration", messages);
            }
        }
    }
    return Collections.emptyList();
}
#method_after
@Override
public List<CommitValidationMessage> onCommitReceived(CommitReceivedEvent receiveEvent) throws CommitValidationException {
    IdentifiedUser currentUser = refControl.getUser().asIdentifiedUser();
    if (REFS_CONFIG.equals(refControl.getRefName())) {
        List<CommitValidationMessage> messages = new LinkedList<>();
        try {
            ProjectConfig cfg = new ProjectConfig(receiveEvent.project.getNameKey());
            cfg.load(repo, receiveEvent.command.getNewId());
            if (!cfg.getValidationErrors().isEmpty()) {
                addError("Invalid project configuration:", messages);
                for (ValidationError err : cfg.getValidationErrors()) {
                    addError("  " + err.getMessage(), messages);
                }
                throw new ConfigInvalidException("invalid project configuration");
            }
        } catch (ConfigInvalidException | IOException e) {
            log.error("User " + currentUser.getUserName() + " tried to push an invalid project configuration " + receiveEvent.command.getNewId().name() + " for project " + receiveEvent.project.getName(), e);
            throw new CommitValidationException("invalid project configuration", messages);
        }
    }
    if (allUsers.equals(refControl.getProjectControl().getProject().getNameKey()) && RefNames.isRefsUsers(refControl.getRefName())) {
        List<CommitValidationMessage> messages = new LinkedList<>();
        Account.Id accountId = Account.Id.fromRef(refControl.getRefName());
        if (accountId != null) {
            try {
                @SuppressWarnings("resource")
                WatchConfig wc = new WatchConfig(accountId);
                wc.load(repo, receiveEvent.command.getNewId());
                if (!wc.getValidationErrors().isEmpty()) {
                    addError("Invalid project configuration:", messages);
                    for (ValidationError err : wc.getValidationErrors()) {
                        addError("  " + err.getMessage(), messages);
                    }
                    throw new ConfigInvalidException("invalid watch configuration");
                }
            } catch (IOException | ConfigInvalidException e) {
                log.error("User " + currentUser.getUserName() + " tried to push an invalid watch configuration " + receiveEvent.command.getNewId().name() + " for account " + accountId.get(), e);
                throw new CommitValidationException("invalid watch configuration", messages);
            }
        }
    }
    return Collections.emptyList();
}
#end_block

#method_before
@Override
public Optional<Account.Id> load(String username) throws Exception {
    try (ReviewDb db = schema.open()) {
        AccountExternalId.Key key = new // 
        AccountExternalId.Key(// 
        AccountExternalId.SCHEME_USERNAME, username);
        if (accountIndexes.getSearchIndex() != null) {
            List<AccountState> accountStates = accountQueryProvider.get().byExternalId(key.get());
            if (accountStates.size() == 1) {
                return Optional.of(accountStates.get(0).getAccount().getId());
            } else if (accountStates.size() > 0) {
                StringBuilder msg = new StringBuilder();
                msg.append("Ambiguous username ").append(username).append("for accounts: ");
                Joiner.on(", ").appendTo(msg, Lists.transform(accountStates, AccountState.ACCOUNT_ID_FUNCTION));
                log.warn(msg.toString());
            }
            return Optional.absent();
        }
        AccountExternalId id = db.accountExternalIds().get(key);
        if (id != null) {
            return Optional.of(id.getAccountId());
        }
        return Optional.absent();
    }
}
#method_after
@Override
public Optional<Account.Id> load(String username) throws Exception {
    AccountExternalId.Key key = new // 
    AccountExternalId.Key(// 
    AccountExternalId.SCHEME_USERNAME, username);
    if (accountIndexes.getSearchIndex() != null) {
        List<AccountState> accountStates = accountQueryProvider.get().byExternalId(key.get());
        if (accountStates.size() == 1) {
            return Optional.of(accountStates.get(0).getAccount().getId());
        } else if (accountStates.size() > 0) {
            StringBuilder msg = new StringBuilder();
            msg.append("Ambiguous username ").append(username).append("for accounts: ");
            Joiner.on(", ").appendTo(msg, Lists.transform(accountStates, AccountState.ACCOUNT_ID_FUNCTION));
            log.warn(msg.toString());
        }
        return Optional.absent();
    }
    try (ReviewDb db = schema.open()) {
        AccountExternalId id = db.accountExternalIds().get(key);
        if (id != null) {
            return Optional.of(id.getAccountId());
        }
        return Optional.absent();
    }
}
#end_block

#method_before
private static S3Config getS3Config(PluginConfigFactory configFactory, String pluginName) {
    Config pluginCfg = configFactory.getGlobalPluginConfig(pluginName);
    String section = "s3";
    String region = pluginCfg.getString(section, null, "region");
    String bucket = pluginCfg.getString(section, null, "bucket");
    String storageClass = MoreObjects.firstNonNull(pluginCfg.getString(section, null, "storageClass"), "REDUCED_REDUNDANCY");
    int expirationSeconds = pluginCfg.getInt(section, null, "expirationSeconds", 60);
    boolean disableSslVerify = pluginCfg.getBoolean(section, null, "disableSslVerify", false);
    PluginConfig cfg = configFactory.getFromGerritConfig(pluginName);
    String accessKey = cfg.getString("accessKey", null);
    String secretKey = cfg.getString("secretKey", null);
    return new S3Config(region, bucket, storageClass, accessKey, secretKey, expirationSeconds, disableSslVerify);
}
#method_after
private static S3Config getS3Config(PluginConfigFactory configFactory, String pluginName) {
    Config config = configFactory.getGlobalPluginConfig(pluginName);
    String section = LfsBackend.S3.name();
    String region = config.getString(section, null, "region");
    String bucket = config.getString(section, null, "bucket");
    String storageClass = MoreObjects.firstNonNull(config.getString(section, null, "storageClass"), "REDUCED_REDUNDANCY");
    int expirationSeconds = config.getInt(section, null, "expirationSeconds", 60);
    boolean disableSslVerify = config.getBoolean(section, null, "disableSslVerify", false);
    PluginConfig pluginCfg = configFactory.getFromGerritConfig(pluginName);
    String accessKey = pluginCfg.getString("s3AccessKey", null);
    String secretKey = pluginCfg.getString("s3SecretKey", null);
    return new S3Config(region, bucket, storageClass, accessKey, secretKey, expirationSeconds, disableSslVerify);
}
#end_block

#method_before
private static Path getOrCreateDataDir(PluginConfigFactory cfgFactory, String pluginName, Path defaultDataDir) throws IOException {
    Config cfg = cfgFactory.getGlobalPluginConfig(pluginName);
    String dataDir = cfg.getString("fs", null, "directory");
    if (Strings.isNullOrEmpty(dataDir)) {
        return defaultDataDir;
    }
    // note that the following method not only creates missing
    // directory/directories but throws exception when path
    // exists and points to file
    Path ensured = Files.createDirectories(Paths.get(dataDir));
    // we should at least make sure that directory is readable
    if (!Files.isReadable(ensured)) {
        throw new IOException("Path '" + ensured.toAbsolutePath() + "' cannot be accessed");
    }
    return ensured;
}
#method_after
private static Path getOrCreateDataDir(PluginConfigFactory cfgFactory, String pluginName, Path defaultDataDir) throws IOException {
    Config cfg = cfgFactory.getGlobalPluginConfig(pluginName);
    String dataDir = cfg.getString(LfsBackend.FS.name(), null, "directory");
    if (Strings.isNullOrEmpty(dataDir)) {
        return defaultDataDir;
    }
    // note that the following method not only creates missing
    // directory/directories but throws exception when path
    // exists and points to file
    Path ensured = Files.createDirectories(Paths.get(dataDir));
    // we should at least make sure that directory is readable
    if (!Files.isReadable(ensured)) {
        throw new IOException("Path '" + ensured.toAbsolutePath() + "' cannot be accessed");
    }
    return ensured;
}
#end_block

#method_before
@Override
protected void configureServlets() {
    LfsBackend backend = config.getEnum("data", null, "backend", LfsBackend.FS);
    switch(backend) {
        case FS:
            serveRegex(URL_REGEX).with(LfsFsApiServlet.class);
            bind(LocalLargeFileRepository.class);
            serve("/" + CONTENT_PATH + "/*").with(LfsFsContentServlet.class);
            break;
        case S3:
            serveRegex(URL_REGEX).with(LfsS3ApiServlet.class);
            bind(S3LargeFileRepository.class);
            break;
        default:
            throw new RuntimeException("Unsupported backend: " + backend);
    }
}
#method_after
@Override
protected void configureServlets() {
    LfsBackend backend = config.getEnum("storage", null, "backend", LfsBackend.FS);
    switch(backend) {
        case FS:
            serveRegex(URL_REGEX).with(LfsFsApiServlet.class);
            bind(LocalLargeFileRepository.class);
            serve("/" + CONTENT_PATH + "/*").with(LfsFsContentServlet.class);
            break;
        case S3:
            serveRegex(URL_REGEX).with(LfsS3ApiServlet.class);
            bind(S3LargeFileRepository.class);
            break;
        default:
            throw new RuntimeException("Unsupported backend: " + backend);
    }
}
#end_block

#method_before
@Override
protected void configureServlets() {
    LfsBackend backend = config.getEnum("backend", LfsBackend.FS);
    switch(backend) {
        case FS:
            serveRegex(URL_REGEX).with(LfsFsApiServlet.class);
            bind(LocalLargeFileRepository.class);
            serve("/" + DATA_URL + "*").with(LfsFsContentServlet.class);
            break;
        case S3:
            serveRegex(URL_REGEX).with(LfsS3ApiServlet.class);
            bind(S3LargeFileRepository.class);
            break;
        default:
            throw new RuntimeException("Unsupported backend: " + backend);
    }
}
#method_after
@Override
protected void configureServlets() {
    LfsBackend backend = config.getEnum("backend", LfsBackend.FS);
    switch(backend) {
        case FS:
            serveRegex(URL_REGEX).with(LfsFsApiServlet.class);
            bind(LocalLargeFileRepository.class);
            serve("/" + CONTENT_PATH + "/*").with(LfsFsContentServlet.class);
            break;
        case S3:
            serveRegex(URL_REGEX).with(LfsS3ApiServlet.class);
            bind(S3LargeFileRepository.class);
            break;
        default:
            throw new RuntimeException("Unsupported backend: " + backend);
    }
}
#end_block

#method_before
void processCommands(Collection<ReceiveCommand> commands, MultiProgressMonitor progress) {
    newProgress = progress.beginSubTask("new", UNKNOWN);
    replaceProgress = progress.beginSubTask("updated", UNKNOWN);
    closeProgress = progress.beginSubTask("closed", UNKNOWN);
    commandProgress = progress.beginSubTask("refs", UNKNOWN);
    batch = repo.getRefDatabase().newBatchUpdate();
    batch.setPushCertificate(rp.getPushCertificate());
    batch.setRefLogIdent(rp.getRefLogIdent());
    batch.setRefLogMessage("push", true);
    parseCommands(commands);
    if (magicBranch != null && magicBranch.cmd.getResult() == NOT_ATTEMPTED) {
        selectNewAndReplacedChangesFromMagicBranch();
    }
    preparePatchSetsForReplace();
    if (!batch.getCommands().isEmpty()) {
        try {
            if (!batch.isAllowNonFastForwards() && magicBranch != null && magicBranch.edit) {
                batch.setAllowNonFastForwards(true);
            }
            batch.execute(rp.getRevWalk(), commandProgress);
        } catch (IOException err) {
            int cnt = 0;
            for (ReceiveCommand cmd : batch.getCommands()) {
                if (cmd.getResult() == NOT_ATTEMPTED) {
                    cmd.setResult(REJECTED_OTHER_REASON, "internal server error");
                    cnt++;
                }
            }
            log.error(String.format("Failed to store %d refs in %s", cnt, project.getName()), err);
        }
    }
    insertChangesAndPatchSets();
    newProgress.end();
    replaceProgress.end();
    if (!errors.isEmpty()) {
        for (Error error : errors.keySet()) {
            rp.sendMessage(buildError(error, errors.get(error)));
        }
        rp.sendMessage(String.format("User: %s", displayName(user)));
        rp.sendMessage(COMMAND_REJECTION_MESSAGE_FOOTER);
    }
    Set<Branch.NameKey> branches = new HashSet<>();
    for (ReceiveCommand c : batch.getCommands()) {
        if (c.getResult() == OK) {
            String refName = c.getRefName();
            if (c.getType() == ReceiveCommand.Type.UPDATE) {
                // aka fast-forward
                tagCache.updateFastForward(project.getNameKey(), refName, c.getOldId(), c.getNewId());
            }
            if (isHead(c) || isConfig(c)) {
                switch(c.getType()) {
                    case CREATE:
                    case UPDATE:
                    case UPDATE_NONFASTFORWARD:
                        autoCloseChanges(c);
                        branches.add(new Branch.NameKey(project.getNameKey(), refName));
                        break;
                    case DELETE:
                        break;
                }
            }
            if (isConfig(c)) {
                projectCache.evict(project);
                ProjectState ps = projectCache.get(project.getNameKey());
                // 
                repoManager.setProjectDescription(// 
                project.getNameKey(), ps.getProject().getDescription());
            }
            if (!MagicBranch.isMagicBranch(refName) && !refName.startsWith(REFS_CHANGES)) {
                // We only fire gitRefUpdated for direct refs updates.
                // Events for change refs are fired when they are created.
                // 
                gitRefUpdated.fire(project.getNameKey(), c, user.getAccount());
                hooks.doRefUpdatedHook(new Branch.NameKey(project.getNameKey(), refName), c.getOldId(), c.getNewId(), user.getAccount());
            }
        }
    }
    // Update superproject gitlinks if required.
    try (MergeOpRepoManager orm = ormProvider.get()) {
        orm.setContext(db, TimeUtil.nowTs(), user, "receiveID");
        SubmoduleOp op = subOpFactory.create(branches, orm);
        op.updateSuperProjects();
    } catch (SubmoduleException e) {
        log.error("Can't update the superprojects", e);
    }
    closeProgress.end();
    commandProgress.end();
    progress.end();
    reportMessages();
}
#method_after
void processCommands(Collection<ReceiveCommand> commands, MultiProgressMonitor progress) {
    newProgress = progress.beginSubTask("new", UNKNOWN);
    replaceProgress = progress.beginSubTask("updated", UNKNOWN);
    closeProgress = progress.beginSubTask("closed", UNKNOWN);
    commandProgress = progress.beginSubTask("refs", UNKNOWN);
    batch = repo.getRefDatabase().newBatchUpdate();
    batch.setPushCertificate(rp.getPushCertificate());
    batch.setRefLogIdent(rp.getRefLogIdent());
    batch.setRefLogMessage("push", true);
    parseCommands(commands);
    if (magicBranch != null && magicBranch.cmd.getResult() == NOT_ATTEMPTED) {
        selectNewAndReplacedChangesFromMagicBranch();
    }
    preparePatchSetsForReplace();
    if (!batch.getCommands().isEmpty()) {
        try {
            if (!batch.isAllowNonFastForwards() && magicBranch != null && magicBranch.edit) {
                batch.setAllowNonFastForwards(true);
            }
            batch.execute(rp.getRevWalk(), commandProgress);
        } catch (IOException err) {
            int cnt = 0;
            for (ReceiveCommand cmd : batch.getCommands()) {
                if (cmd.getResult() == NOT_ATTEMPTED) {
                    cmd.setResult(REJECTED_OTHER_REASON, "internal server error");
                    cnt++;
                }
            }
            log.error(String.format("Failed to store %d refs in %s", cnt, project.getName()), err);
        }
    }
    insertChangesAndPatchSets();
    newProgress.end();
    replaceProgress.end();
    if (!errors.isEmpty()) {
        for (Error error : errors.keySet()) {
            rp.sendMessage(buildError(error, errors.get(error)));
        }
        rp.sendMessage(String.format("User: %s", displayName(user)));
        rp.sendMessage(COMMAND_REJECTION_MESSAGE_FOOTER);
    }
    Set<Branch.NameKey> branches = new HashSet<>();
    for (ReceiveCommand c : batch.getCommands()) {
        if (c.getResult() == OK) {
            String refName = c.getRefName();
            if (c.getType() == ReceiveCommand.Type.UPDATE) {
                // aka fast-forward
                tagCache.updateFastForward(project.getNameKey(), refName, c.getOldId(), c.getNewId());
            }
            if (isHead(c) || isConfig(c)) {
                switch(c.getType()) {
                    case CREATE:
                    case UPDATE:
                    case UPDATE_NONFASTFORWARD:
                        autoCloseChanges(c);
                        branches.add(new Branch.NameKey(project.getNameKey(), refName));
                        break;
                    case DELETE:
                        break;
                }
            }
            if (isConfig(c)) {
                projectCache.evict(project);
                ProjectState ps = projectCache.get(project.getNameKey());
                // 
                repoManager.setProjectDescription(// 
                project.getNameKey(), ps.getProject().getDescription());
            }
            if (!MagicBranch.isMagicBranch(refName) && !refName.startsWith(REFS_CHANGES)) {
                // We only fire gitRefUpdated for direct refs updates.
                // Events for change refs are fired when they are created.
                // 
                gitRefUpdated.fire(project.getNameKey(), c, user.getAccount());
            }
        }
    }
    // Update superproject gitlinks if required.
    try (MergeOpRepoManager orm = ormProvider.get()) {
        orm.setContext(db, TimeUtil.nowTs(), user, "receiveID");
        SubmoduleOp op = subOpFactory.create(branches, orm);
        op.updateSuperProjects();
    } catch (SubmoduleException e) {
        log.error("Can't update the superprojects", e);
    }
    closeProgress.end();
    commandProgress.end();
    progress.end();
    reportMessages();
}
#end_block

#method_before
private void reportMessages() {
    Iterable<CreateRequest> created = Iterables.filter(newChanges, new Predicate<CreateRequest>() {

        @Override
        public boolean apply(CreateRequest input) {
            return input.getChange() != null;
        }
    });
    if (!Iterables.isEmpty(created)) {
        addMessage("");
        addMessage("New Changes:");
        for (CreateRequest c : created) {
            addMessage(formatChangeUrl(canonicalWebUrl, c.getChange(), c.getChange().getSubject(), false));
        }
        addMessage("");
    }
    List<ReplaceRequest> updated = FluentIterable.from(replaceByChange.values()).filter(new Predicate<ReplaceRequest>() {

        @Override
        public boolean apply(ReplaceRequest input) {
            return !input.skip && input.inputCommand.getResult() == OK;
        }
    }).toSortedList(Ordering.natural().onResultOf(new Function<ReplaceRequest, Integer>() {

        @Override
        public Integer apply(ReplaceRequest in) {
            return in.change.getId().get();
        }
    }));
    if (!updated.isEmpty()) {
        addMessage("");
        addMessage("Updated Changes:");
        boolean edit = magicBranch != null && magicBranch.edit;
        for (ReplaceRequest u : updated) {
            addMessage(formatChangeUrl(canonicalWebUrl, u.change, u.info.getSubject(), edit));
        }
        addMessage("");
    }
}
#method_after
private void reportMessages() {
    Iterable<CreateRequest> created = Iterables.filter(newChanges, new Predicate<CreateRequest>() {

        @Override
        public boolean apply(CreateRequest input) {
            return input.change != null;
        }
    });
    if (!Iterables.isEmpty(created)) {
        addMessage("");
        addMessage("New Changes:");
        for (CreateRequest c : created) {
            addMessage(formatChangeUrl(canonicalWebUrl, c.change, c.change.getSubject(), false));
        }
        addMessage("");
    }
    List<ReplaceRequest> updated = FluentIterable.from(replaceByChange.values()).filter(new Predicate<ReplaceRequest>() {

        @Override
        public boolean apply(ReplaceRequest input) {
            return !input.skip && input.inputCommand.getResult() == OK;
        }
    }).toSortedList(Ordering.natural().onResultOf(new Function<ReplaceRequest, Integer>() {

        @Override
        public Integer apply(ReplaceRequest in) {
            return in.notes.getChangeId().get();
        }
    }));
    if (!updated.isEmpty()) {
        addMessage("");
        addMessage("Updated Changes:");
        boolean edit = magicBranch != null && magicBranch.edit;
        for (ReplaceRequest u : updated) {
            String subject;
            if (edit) {
                try {
                    subject = rp.getRevWalk().parseCommit(u.newCommitId).getShortMessage();
                } catch (IOException e) {
                    // Log and fall back to original change subject
                    log.warn("failed to get subject for edit patch set", e);
                    subject = u.notes.getChange().getSubject();
                }
            } else {
                subject = u.info.getMessage();
            }
            addMessage(formatChangeUrl(canonicalWebUrl, u.notes.getChange(), subject, edit));
        }
        addMessage("");
    }
}
#end_block

#method_before
private void insertChangesAndPatchSets() {
    int replaceCount = 0;
    int okToInsert = 0;
    for (Map.Entry<Change.Id, ReplaceRequest> e : replaceByChange.entrySet()) {
        ReplaceRequest replace = e.getValue();
        if (magicBranch != null && replace.inputCommand == magicBranch.cmd) {
            replaceCount++;
            if (replace.cmd != null && replace.cmd.getResult() == OK) {
                okToInsert++;
            }
        } else if (replace.cmd != null && replace.cmd.getResult() == OK) {
            checkState(NEW_PATCHSET.matcher(replace.inputCommand.getRefName()).matches(), "expected a new patch set command as input when creating %s;" + " got %s", replace.cmd.getRefName(), replace.inputCommand.getRefName());
            try {
                replace.insertPatchSetWithoutBatchUpdate();
                replace.inputCommand.setResult(OK);
            } catch (IOException | UpdateException | RestApiException err) {
                reject(replace.inputCommand, "internal server error");
                log.error(String.format("Cannot add patch set to change %d in project %s", e.getKey().get(), project.getName()), err);
            }
        } else if (replace.inputCommand.getResult() == NOT_ATTEMPTED) {
            reject(replace.inputCommand, "internal server error");
            log.error(String.format("Replacement for project %s was not attempted", project.getName()));
        }
    }
    if (magicBranch == null || magicBranch.cmd.getResult() != NOT_ATTEMPTED) {
        // No need to continue.
        return;
    }
    List<String> lastCreateChangeErrors = new ArrayList<>();
    for (CreateRequest create : newChanges) {
        if (create.cmd.getResult() == OK) {
            okToInsert++;
        } else {
            String createChangeResult = String.format("%s %s", create.cmd.getResult(), Strings.nullToEmpty(create.cmd.getMessage())).trim();
            lastCreateChangeErrors.add(createChangeResult);
            log.error(String.format("Command %s on %s:%s not completed: %s", create.cmd.getType(), project.getName(), create.cmd.getRefName(), createChangeResult));
        }
    }
    if (okToInsert != replaceCount + newChanges.size()) {
        // One or more new references failed to create. Assume the
        // system isn't working correctly anymore and abort.
        reject(magicBranch.cmd, "Unable to create changes: " + Joiner.on(' ').join(lastCreateChangeErrors));
        log.error(String.format("Only %d of %d new change refs created in %s; aborting", okToInsert, replaceCount + newChanges.size(), project.getName()));
        return;
    }
    try (BatchUpdate bu = batchUpdateFactory.create(db, magicBranch.dest.getParentKey(), user, TimeUtil.nowTs());
        ObjectInserter ins = repo.newObjectInserter()) {
        bu.setRepository(repo, rp.getRevWalk(), ins).updateChangesInParallel();
        for (ReplaceRequest replace : replaceByChange.values()) {
            if (replace.inputCommand == magicBranch.cmd) {
                replace.addOps(bu);
            }
        }
        for (CreateRequest create : newChanges) {
            create.addOps(bu);
        }
        for (UpdateGroupsRequest update : updateGroups) {
            update.addOps(bu);
        }
        try {
            bu.execute();
        } catch (UpdateException e) {
            throw INSERT_EXCEPTION.apply(e);
        }
        newProgress.update(newChanges.size());
        replaceProgress.update(replaceByChange.size());
        magicBranch.cmd.setResult(OK);
        for (ReplaceRequest replace : replaceByChange.values()) {
            String rejectMessage = replace.getRejectMessage();
            if (rejectMessage != null) {
                reject(replace.inputCommand, rejectMessage);
            }
        }
    } catch (ResourceConflictException e) {
        addMessage(e.getMessage());
        reject(magicBranch.cmd, "conflict");
    } catch (RestApiException | IOException err) {
        log.error("Can't insert change/patch set for " + project.getName(), err);
        reject(magicBranch.cmd, "internal server error: " + err.getMessage());
    }
    if (magicBranch != null && magicBranch.submit) {
        try {
            submit(newChanges, replaceByChange.values());
        } catch (ResourceConflictException e) {
            addMessage(e.getMessage());
            reject(magicBranch.cmd, "conflict");
        } catch (RestApiException | OrmException e) {
            log.error("Error submit changes to " + project.getName(), e);
            reject(magicBranch.cmd, "error during submit");
        }
    }
}
#method_after
private void insertChangesAndPatchSets() {
    int replaceCount = 0;
    int okToInsert = 0;
    for (Map.Entry<Change.Id, ReplaceRequest> e : replaceByChange.entrySet()) {
        ReplaceRequest replace = e.getValue();
        if (magicBranch != null && replace.inputCommand == magicBranch.cmd) {
            replaceCount++;
            if (replace.cmd != null && replace.cmd.getResult() == OK) {
                okToInsert++;
            }
        } else if (replace.cmd != null && replace.cmd.getResult() == OK) {
            checkState(NEW_PATCHSET.matcher(replace.inputCommand.getRefName()).matches(), "expected a new patch set command as input when creating %s;" + " got %s", replace.cmd.getRefName(), replace.inputCommand.getRefName());
            try {
                replace.insertPatchSetWithoutBatchUpdate();
                replace.inputCommand.setResult(OK);
            } catch (IOException | UpdateException | RestApiException err) {
                reject(replace.inputCommand, "internal server error");
                log.error(String.format("Cannot add patch set to change %d in project %s", e.getKey().get(), project.getName()), err);
            }
        } else if (replace.inputCommand.getResult() == NOT_ATTEMPTED) {
            reject(replace.inputCommand, "internal server error");
            log.error(String.format("Replacement for project %s was not attempted", project.getName()));
        }
    }
    if (magicBranch == null || magicBranch.cmd.getResult() != NOT_ATTEMPTED) {
        // No need to continue.
        return;
    }
    List<String> lastCreateChangeErrors = new ArrayList<>();
    for (CreateRequest create : newChanges) {
        if (create.cmd.getResult() == OK) {
            okToInsert++;
        } else {
            String createChangeResult = String.format("%s %s", create.cmd.getResult(), Strings.nullToEmpty(create.cmd.getMessage())).trim();
            lastCreateChangeErrors.add(createChangeResult);
            log.error(String.format("Command %s on %s:%s not completed: %s", create.cmd.getType(), project.getName(), create.cmd.getRefName(), createChangeResult));
        }
    }
    if (okToInsert != replaceCount + newChanges.size()) {
        // One or more new references failed to create. Assume the
        // system isn't working correctly anymore and abort.
        reject(magicBranch.cmd, "Unable to create changes: " + Joiner.on(' ').join(lastCreateChangeErrors));
        log.error(String.format("Only %d of %d new change refs created in %s; aborting", okToInsert, replaceCount + newChanges.size(), project.getName()));
        return;
    }
    try (BatchUpdate bu = batchUpdateFactory.create(db, magicBranch.dest.getParentKey(), user, TimeUtil.nowTs());
        ObjectInserter ins = repo.newObjectInserter()) {
        bu.setRepository(repo, rp.getRevWalk(), ins).updateChangesInParallel();
        for (ReplaceRequest replace : replaceByChange.values()) {
            if (replace.inputCommand == magicBranch.cmd) {
                replace.addOps(bu, replaceProgress);
            }
        }
        for (CreateRequest create : newChanges) {
            create.addOps(bu);
        }
        for (UpdateGroupsRequest update : updateGroups) {
            update.addOps(bu);
        }
        try {
            bu.execute();
        } catch (UpdateException e) {
            throw INSERT_EXCEPTION.apply(e);
        }
        magicBranch.cmd.setResult(OK);
        for (ReplaceRequest replace : replaceByChange.values()) {
            String rejectMessage = replace.getRejectMessage();
            if (rejectMessage != null) {
                reject(replace.inputCommand, rejectMessage);
            }
        }
    } catch (ResourceConflictException e) {
        addMessage(e.getMessage());
        reject(magicBranch.cmd, "conflict");
    } catch (RestApiException | IOException err) {
        log.error("Can't insert change/patch set for " + project.getName(), err);
        reject(magicBranch.cmd, "internal server error: " + err.getMessage());
    }
    if (magicBranch != null && magicBranch.submit) {
        try {
            submit(newChanges, replaceByChange.values());
        } catch (ResourceConflictException e) {
            addMessage(e.getMessage());
            reject(magicBranch.cmd, "conflict");
        } catch (RestApiException | OrmException e) {
            log.error("Error submit changes to " + project.getName(), e);
            reject(magicBranch.cmd, "error during submit");
        }
    }
}
#end_block

#method_before
private void parseCommands(Collection<ReceiveCommand> commands) {
    for (ReceiveCommand cmd : commands) {
        if (cmd.getResult() != NOT_ATTEMPTED) {
            // 
            continue;
        }
        if (!Repository.isValidRefName(cmd.getRefName()) || cmd.getRefName().contains("//")) {
            reject(cmd, "not valid ref");
            continue;
        }
        if (MagicBranch.isMagicBranch(cmd.getRefName())) {
            parseMagicBranch(cmd);
            continue;
        }
        if (projectControl.getProjectState().isAllUsers() && RefNames.REFS_USERS_SELF.equals(cmd.getRefName())) {
            final ReceiveCommand orgCmd = cmd;
            cmd = new ReceiveCommand(cmd.getOldId(), cmd.getNewId(), RefNames.refsUsers(user.getAccountId()), cmd.getType()) {

                @Override
                public void setResult(Result s, String m) {
                    super.setResult(s, m);
                    orgCmd.setResult(s, m);
                }
            };
        }
        Matcher m = NEW_PATCHSET.matcher(cmd.getRefName());
        if (m.matches()) {
            // The referenced change must exist and must still be open.
            // 
            Change.Id changeId = Change.Id.parse(m.group(1));
            parseReplaceCommand(cmd, changeId);
            continue;
        }
        switch(cmd.getType()) {
            case CREATE:
                parseCreate(cmd);
                break;
            case UPDATE:
                parseUpdate(cmd);
                break;
            case DELETE:
                parseDelete(cmd);
                break;
            case UPDATE_NONFASTFORWARD:
                parseRewind(cmd);
                break;
            default:
                reject(cmd);
                continue;
        }
        if (cmd.getResult() != NOT_ATTEMPTED) {
            continue;
        }
        if (isConfig(cmd)) {
            if (!projectControl.isOwner()) {
                reject(cmd, "not project owner");
                continue;
            }
            switch(cmd.getType()) {
                case CREATE:
                case UPDATE:
                case UPDATE_NONFASTFORWARD:
                    try {
                        ProjectConfig cfg = new ProjectConfig(project.getNameKey());
                        cfg.load(rp.getRevWalk(), cmd.getNewId());
                        if (!cfg.getValidationErrors().isEmpty()) {
                            addError("Invalid project configuration:");
                            for (ValidationError err : cfg.getValidationErrors()) {
                                addError("  " + err.getMessage());
                            }
                            reject(cmd, "invalid project configuration");
                            log.error("User " + user.getUserName() + " tried to push invalid project configuration " + cmd.getNewId().name() + " for " + project.getName());
                            continue;
                        }
                        Project.NameKey newParent = cfg.getProject().getParent(allProjectsName);
                        Project.NameKey oldParent = project.getParent(allProjectsName);
                        if (oldParent == null) {
                            // update of the 'All-Projects' project
                            if (newParent != null) {
                                reject(cmd, "invalid project configuration: root project cannot have parent");
                                continue;
                            }
                        } else {
                            if (!oldParent.equals(newParent) && !user.getCapabilities().canAdministrateServer()) {
                                reject(cmd, "invalid project configuration: only Gerrit admin can set parent");
                                continue;
                            }
                            if (projectCache.get(newParent) == null) {
                                reject(cmd, "invalid project configuration: parent does not exist");
                                continue;
                            }
                        }
                        for (Entry<ProjectConfigEntry> e : pluginConfigEntries) {
                            PluginConfig pluginCfg = cfg.getPluginConfig(e.getPluginName());
                            ProjectConfigEntry configEntry = e.getProvider().get();
                            String value = pluginCfg.getString(e.getExportName());
                            String oldValue = projectControl.getProjectState().getConfig().getPluginConfig(e.getPluginName()).getString(e.getExportName());
                            if (configEntry.getType() == ProjectConfigEntry.Type.ARRAY) {
                                List<String> l = Arrays.asList(projectControl.getProjectState().getConfig().getPluginConfig(e.getPluginName()).getStringList(e.getExportName()));
                                oldValue = Joiner.on("\n").join(l);
                            }
                            if ((value == null ? oldValue != null : !value.equals(oldValue)) && !configEntry.isEditable(projectControl.getProjectState())) {
                                reject(cmd, String.format("invalid project configuration: Not allowed to set parameter" + " '%s' of plugin '%s' on project '%s'.", e.getExportName(), e.getPluginName(), project.getName()));
                                continue;
                            }
                            if (ProjectConfigEntry.Type.LIST.equals(configEntry.getType()) && value != null && !configEntry.getPermittedValues().contains(value)) {
                                reject(cmd, String.format("invalid project configuration: The value '%s' is " + "not permitted for parameter '%s' of plugin '%s'.", value, e.getExportName(), e.getPluginName()));
                            }
                        }
                    } catch (Exception e) {
                        reject(cmd, "invalid project configuration");
                        log.error("User " + user.getUserName() + " tried to push invalid project configuration " + cmd.getNewId().name() + " for " + project.getName(), e);
                        continue;
                    }
                    break;
                case DELETE:
                    break;
                default:
                    reject(cmd);
                    continue;
            }
        }
    }
}
#method_after
private void parseCommands(Collection<ReceiveCommand> commands) {
    for (ReceiveCommand cmd : commands) {
        if (cmd.getResult() != NOT_ATTEMPTED) {
            // 
            continue;
        }
        if (!Repository.isValidRefName(cmd.getRefName()) || cmd.getRefName().contains("//")) {
            reject(cmd, "not valid ref");
            continue;
        }
        if (MagicBranch.isMagicBranch(cmd.getRefName())) {
            parseMagicBranch(cmd);
            continue;
        }
        if (projectControl.getProjectState().isAllUsers() && RefNames.REFS_USERS_SELF.equals(cmd.getRefName())) {
            final ReceiveCommand orgCmd = cmd;
            cmd = new ReceiveCommand(cmd.getOldId(), cmd.getNewId(), RefNames.refsUsers(user.getAccountId()), cmd.getType()) {

                @Override
                public void setResult(Result s, String m) {
                    super.setResult(s, m);
                    orgCmd.setResult(s, m);
                }
            };
        }
        Matcher m = NEW_PATCHSET.matcher(cmd.getRefName());
        if (m.matches()) {
            // The referenced change must exist and must still be open.
            // 
            Change.Id changeId = Change.Id.parse(m.group(1));
            parseReplaceCommand(cmd, changeId);
            continue;
        }
        switch(cmd.getType()) {
            case CREATE:
                parseCreate(cmd);
                break;
            case UPDATE:
                parseUpdate(cmd);
                break;
            case DELETE:
                parseDelete(cmd);
                break;
            case UPDATE_NONFASTFORWARD:
                parseRewind(cmd);
                break;
            default:
                reject(cmd);
                continue;
        }
        if (cmd.getResult() != NOT_ATTEMPTED) {
            continue;
        }
        if (isConfig(cmd)) {
            if (!projectControl.isOwner()) {
                reject(cmd, "not project owner");
                continue;
            }
            switch(cmd.getType()) {
                case CREATE:
                case UPDATE:
                case UPDATE_NONFASTFORWARD:
                    try {
                        ProjectConfig cfg = new ProjectConfig(project.getNameKey());
                        cfg.load(rp.getRevWalk(), cmd.getNewId());
                        if (!cfg.getValidationErrors().isEmpty()) {
                            addError("Invalid project configuration:");
                            for (ValidationError err : cfg.getValidationErrors()) {
                                addError("  " + err.getMessage());
                            }
                            reject(cmd, "invalid project configuration");
                            log.error("User " + user.getUserName() + " tried to push invalid project configuration " + cmd.getNewId().name() + " for " + project.getName());
                            continue;
                        }
                        Project.NameKey newParent = cfg.getProject().getParent(allProjectsName);
                        Project.NameKey oldParent = project.getParent(allProjectsName);
                        if (oldParent == null) {
                            // update of the 'All-Projects' project
                            if (newParent != null) {
                                reject(cmd, "invalid project configuration: root project cannot have parent");
                                continue;
                            }
                        } else {
                            if (!oldParent.equals(newParent) && !user.getCapabilities().canAdministrateServer()) {
                                reject(cmd, "invalid project configuration: only Gerrit admin can set parent");
                                continue;
                            }
                            if (projectCache.get(newParent) == null) {
                                reject(cmd, "invalid project configuration: parent does not exist");
                                continue;
                            }
                        }
                        for (Entry<ProjectConfigEntry> e : pluginConfigEntries) {
                            PluginConfig pluginCfg = cfg.getPluginConfig(e.getPluginName());
                            ProjectConfigEntry configEntry = e.getProvider().get();
                            String value = pluginCfg.getString(e.getExportName());
                            String oldValue = projectControl.getProjectState().getConfig().getPluginConfig(e.getPluginName()).getString(e.getExportName());
                            if (configEntry.getType() == ProjectConfigEntryType.ARRAY) {
                                List<String> l = Arrays.asList(projectControl.getProjectState().getConfig().getPluginConfig(e.getPluginName()).getStringList(e.getExportName()));
                                oldValue = Joiner.on("\n").join(l);
                            }
                            if ((value == null ? oldValue != null : !value.equals(oldValue)) && !configEntry.isEditable(projectControl.getProjectState())) {
                                reject(cmd, String.format("invalid project configuration: Not allowed to set parameter" + " '%s' of plugin '%s' on project '%s'.", e.getExportName(), e.getPluginName(), project.getName()));
                                continue;
                            }
                            if (ProjectConfigEntryType.LIST.equals(configEntry.getType()) && value != null && !configEntry.getPermittedValues().contains(value)) {
                                reject(cmd, String.format("invalid project configuration: The value '%s' is " + "not permitted for parameter '%s' of plugin '%s'.", value, e.getExportName(), e.getPluginName()));
                            }
                        }
                    } catch (Exception e) {
                        reject(cmd, "invalid project configuration");
                        log.error("User " + user.getUserName() + " tried to push invalid project configuration " + cmd.getNewId().name() + " for " + project.getName(), e);
                        continue;
                    }
                    break;
                case DELETE:
                    break;
                default:
                    reject(cmd);
                    continue;
            }
        }
    }
}
#end_block

#method_before
private void selectNewAndReplacedChangesFromMagicBranch() {
    newChanges = new ArrayList<>();
    SetMultimap<ObjectId, Ref> existing = changeRefsById();
    GroupCollector groupCollector = GroupCollector.create(refsById, db, psUtil, notesFactory, project.getNameKey());
    rp.getRevWalk().reset();
    rp.getRevWalk().sort(RevSort.TOPO);
    rp.getRevWalk().sort(RevSort.REVERSE, true);
    try {
        rp.getRevWalk().markStart(rp.getRevWalk().parseCommit(magicBranch.cmd.getNewId()));
        if (magicBranch.baseCommit != null) {
            for (RevCommit c : magicBranch.baseCommit) {
                rp.getRevWalk().markUninteresting(c);
            }
            Ref targetRef = allRefs.get(magicBranch.ctl.getRefName());
            if (targetRef != null) {
                rp.getRevWalk().markUninteresting(rp.getRevWalk().parseCommit(targetRef.getObjectId()));
            }
        } else {
            markHeadsAsUninteresting(rp.getRevWalk(), magicBranch.ctl != null ? magicBranch.ctl.getRefName() : null);
        }
        List<ChangeLookup> pending = new ArrayList<>();
        Set<Change.Key> newChangeIds = new HashSet<>();
        int maxBatchChanges = receiveConfig.getEffectiveMaxBatchChangesLimit(user);
        for (; ; ) {
            RevCommit c = rp.getRevWalk().next();
            if (c == null) {
                break;
            }
            groupCollector.visit(c);
            Collection<Ref> existingRefs = existing.get(c);
            if (!existingRefs.isEmpty()) {
                // A's group.
                for (Ref ref : existingRefs) {
                    updateGroups.add(new UpdateGroupsRequest(ref, c));
                }
                continue;
            }
            if (!validCommit(rp.getRevWalk(), magicBranch.ctl, magicBranch.cmd, c)) {
                // Not a change the user can propose? Abort as early as possible.
                newChanges = Collections.emptyList();
                return;
            }
            // Don't allow merges to be uploaded in commit chain via all-not-in-target
            if (newChangeForAllNotInTarget && c.getParentCount() > 1) {
                reject(magicBranch.cmd, "Pushing merges in commit chains with 'all not in target' is not allowed,\n" + "to override please set the base manually");
            }
            List<String> idList = c.getFooterLines(CHANGE_ID);
            if (idList.isEmpty()) {
                newChanges.add(new CreateRequest(c, magicBranch.dest.get()));
                continue;
            }
            String idStr = idList.get(idList.size() - 1).trim();
            if (idStr.matches("^I00*$")) {
                // Reject this invalid line from EGit.
                reject(magicBranch.cmd, "invalid Change-Id");
                newChanges = Collections.emptyList();
                return;
            }
            pending.add(new ChangeLookup(c, new Change.Key(idStr)));
            if (maxBatchChanges != 0 && pending.size() + newChanges.size() > maxBatchChanges) {
                reject(magicBranch.cmd, "the number of pushed changes in a batch exceeds the max limit " + maxBatchChanges);
                newChanges = Collections.emptyList();
                return;
            }
        }
        for (ChangeLookup p : pending) {
            if (newChangeIds.contains(p.changeKey)) {
                reject(magicBranch.cmd, SAME_CHANGE_ID_IN_MULTIPLE_CHANGES);
                newChanges = Collections.emptyList();
                return;
            }
            List<ChangeData> changes = p.destChanges;
            if (changes.size() > 1) {
                // WTF, multiple changes in this project have the same key?
                // Since the commit is new, the user should recreate it with
                // a different Change-Id. In practice, we should never see
                // this error message as Change-Id should be unique.
                // 
                reject(magicBranch.cmd, p.changeKey.get() + " has duplicates");
                newChanges = Collections.emptyList();
                return;
            }
            if (changes.size() == 1) {
                // 
                if (requestReplace(magicBranch.cmd, false, changes.get(0).change(), p.commit)) {
                    continue;
                }
                newChanges = Collections.emptyList();
                return;
            }
            if (changes.size() == 0) {
                if (!isValidChangeId(p.changeKey.get())) {
                    reject(magicBranch.cmd, "invalid Change-Id");
                    newChanges = Collections.emptyList();
                    return;
                }
                newChangeIds.add(p.changeKey);
            }
            newChanges.add(new CreateRequest(p.commit, magicBranch.dest.get()));
        }
    } catch (IOException e) {
        // Should never happen, the core receive process would have
        // identified the missing object earlier before we got control.
        // 
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        log.error("Invalid pack upload; one or more objects weren't sent", e);
        newChanges = Collections.emptyList();
        return;
    } catch (OrmException e) {
        log.error("Cannot query database to locate prior changes", e);
        reject(magicBranch.cmd, "database error");
        newChanges = Collections.emptyList();
        return;
    }
    if (newChanges.isEmpty() && replaceByChange.isEmpty()) {
        reject(magicBranch.cmd, "no new changes");
        return;
    }
    if (!newChanges.isEmpty() && magicBranch.edit) {
        reject(magicBranch.cmd, "edit is not supported for new changes");
        return;
    }
    try {
        SortedSetMultimap<ObjectId, String> groups = groupCollector.getGroups();
        for (CreateRequest create : newChanges) {
            batch.addCommand(create.cmd);
            create.groups = ImmutableList.copyOf(groups.get(create.commitId));
        }
        for (ReplaceRequest replace : replaceByChange.values()) {
            replace.groups = ImmutableList.copyOf(groups.get(replace.newCommitId));
        }
        for (UpdateGroupsRequest update : updateGroups) {
            update.groups = ImmutableList.copyOf((groups.get(update.commit)));
        }
    } catch (OrmException | NoSuchChangeException e) {
        log.error("Error collecting groups for changes", e);
        reject(magicBranch.cmd, "internal server error");
        return;
    }
}
#method_after
private void selectNewAndReplacedChangesFromMagicBranch() {
    newChanges = new ArrayList<>();
    SetMultimap<ObjectId, Ref> existing = changeRefsById();
    GroupCollector groupCollector = GroupCollector.create(changeRefsById(), db, psUtil, notesFactory, project.getNameKey());
    rp.getRevWalk().reset();
    rp.getRevWalk().sort(RevSort.TOPO);
    rp.getRevWalk().sort(RevSort.REVERSE, true);
    try {
        rp.getRevWalk().markStart(rp.getRevWalk().parseCommit(magicBranch.cmd.getNewId()));
        if (magicBranch.baseCommit != null) {
            for (RevCommit c : magicBranch.baseCommit) {
                rp.getRevWalk().markUninteresting(c);
            }
            Ref targetRef = allRefs.get(magicBranch.ctl.getRefName());
            if (targetRef != null) {
                rp.getRevWalk().markUninteresting(rp.getRevWalk().parseCommit(targetRef.getObjectId()));
            }
        } else {
            markHeadsAsUninteresting(rp.getRevWalk(), magicBranch.ctl != null ? magicBranch.ctl.getRefName() : null);
        }
        List<ChangeLookup> pending = new ArrayList<>();
        Set<Change.Key> newChangeIds = new HashSet<>();
        int maxBatchChanges = receiveConfig.getEffectiveMaxBatchChangesLimit(user);
        for (; ; ) {
            RevCommit c = rp.getRevWalk().next();
            if (c == null) {
                break;
            }
            groupCollector.visit(c);
            Collection<Ref> existingRefs = existing.get(c);
            if (!existingRefs.isEmpty()) {
                // different target branch.
                for (Ref ref : existingRefs) {
                    updateGroups.add(new UpdateGroupsRequest(ref, c));
                }
                if (!(newChangeForAllNotInTarget || magicBranch.base != null)) {
                    continue;
                }
            }
            if (!validCommit(rp.getRevWalk(), magicBranch.ctl, magicBranch.cmd, c)) {
                // Not a change the user can propose? Abort as early as possible.
                newChanges = Collections.emptyList();
                return;
            }
            // Don't allow merges to be uploaded in commit chain via all-not-in-target
            if (newChangeForAllNotInTarget && c.getParentCount() > 1) {
                reject(magicBranch.cmd, "Pushing merges in commit chains with 'all not in target' is not allowed,\n" + "to override please set the base manually");
            }
            List<String> idList = c.getFooterLines(CHANGE_ID);
            if (idList.isEmpty()) {
                newChanges.add(new CreateRequest(c, magicBranch.dest.get()));
                continue;
            }
            String idStr = idList.get(idList.size() - 1).trim();
            if (idStr.matches("^I00*$")) {
                // Reject this invalid line from EGit.
                reject(magicBranch.cmd, "invalid Change-Id");
                newChanges = Collections.emptyList();
                return;
            }
            pending.add(new ChangeLookup(c, new Change.Key(idStr)));
            if (maxBatchChanges != 0 && pending.size() + newChanges.size() > maxBatchChanges) {
                reject(magicBranch.cmd, "the number of pushed changes in a batch exceeds the max limit " + maxBatchChanges);
                newChanges = Collections.emptyList();
                return;
            }
        }
        for (Iterator<ChangeLookup> itr = pending.iterator(); itr.hasNext(); ) {
            ChangeLookup p = itr.next();
            if (newChangeIds.contains(p.changeKey)) {
                reject(magicBranch.cmd, SAME_CHANGE_ID_IN_MULTIPLE_CHANGES);
                newChanges = Collections.emptyList();
                return;
            }
            List<ChangeData> changes = p.destChanges;
            if (changes.size() > 1) {
                // WTF, multiple changes in this project have the same key?
                // Since the commit is new, the user should recreate it with
                // a different Change-Id. In practice, we should never see
                // this error message as Change-Id should be unique.
                // 
                reject(magicBranch.cmd, p.changeKey.get() + " has duplicates");
                newChanges = Collections.emptyList();
                return;
            }
            if (changes.size() == 1) {
                // Schedule as a replacement to this one matching change.
                // 
                RevId currentPs = changes.get(0).currentPatchSet().getRevision();
                // If Commit is already current PatchSet of target Change.
                if (p.commit.name().equals(currentPs.get())) {
                    if (pending.size() == 1) {
                        // There are no commits left to check, all commits in pending were already
                        // current PatchSet of the corresponding target changes.
                        reject(magicBranch.cmd, "commit(s) already exists (as current patchset)");
                    } else {
                        // Commit is already current PatchSet.
                        // Remove from pending and try next commit.
                        itr.remove();
                        continue;
                    }
                }
                if (requestReplace(magicBranch.cmd, false, changes.get(0).change(), p.commit)) {
                    continue;
                }
                newChanges = Collections.emptyList();
                return;
            }
            if (changes.size() == 0) {
                if (!isValidChangeId(p.changeKey.get())) {
                    reject(magicBranch.cmd, "invalid Change-Id");
                    newChanges = Collections.emptyList();
                    return;
                }
                newChangeIds.add(p.changeKey);
            }
            newChanges.add(new CreateRequest(p.commit, magicBranch.dest.get()));
        }
    } catch (IOException e) {
        // Should never happen, the core receive process would have
        // identified the missing object earlier before we got control.
        // 
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        log.error("Invalid pack upload; one or more objects weren't sent", e);
        newChanges = Collections.emptyList();
        return;
    } catch (OrmException e) {
        log.error("Cannot query database to locate prior changes", e);
        reject(magicBranch.cmd, "database error");
        newChanges = Collections.emptyList();
        return;
    }
    if (newChanges.isEmpty() && replaceByChange.isEmpty()) {
        reject(magicBranch.cmd, "no new changes");
        return;
    }
    if (!newChanges.isEmpty() && magicBranch.edit) {
        reject(magicBranch.cmd, "edit is not supported for new changes");
        return;
    }
    try {
        SortedSetMultimap<ObjectId, String> groups = groupCollector.getGroups();
        for (CreateRequest create : newChanges) {
            batch.addCommand(create.cmd);
            create.groups = ImmutableList.copyOf(groups.get(create.commitId));
        }
        for (ReplaceRequest replace : replaceByChange.values()) {
            replace.groups = ImmutableList.copyOf(groups.get(replace.newCommitId));
        }
        for (UpdateGroupsRequest update : updateGroups) {
            update.groups = ImmutableList.copyOf((groups.get(update.commit)));
        }
    } catch (OrmException | NoSuchChangeException e) {
        log.error("Error collecting groups for changes", e);
        reject(magicBranch.cmd, "internal server error");
        return;
    }
}
#end_block

#method_before
private void addOps(BatchUpdate bu) throws RestApiException {
    try {
        RevWalk rw = rp.getRevWalk();
        RevCommit commit = rw.parseCommit(commitId);
        rw.parseBody(commit);
        final PatchSet.Id psId = ins.setGroups(groups).getPatchSetId();
        Account.Id me = user.getAccountId();
        List<FooterLine> footerLines = commit.getFooterLines();
        MailRecipients recipients = new MailRecipients();
        Map<String, Short> approvals = new HashMap<>();
        checkNotNull(magicBranch);
        recipients.add(magicBranch.getMailRecipients());
        approvals = magicBranch.labels;
        recipients.add(getRecipientsFromFooters(accountResolver, magicBranch.draft, footerLines));
        recipients.remove(me);
        StringBuilder msg = new StringBuilder(ApprovalsUtil.renderMessageWithApprovals(psId.get(), approvals, Collections.<String, PatchSetApproval>emptyMap()));
        if (!Strings.isNullOrEmpty(magicBranch.message)) {
            msg.append("\n").append(magicBranch.message);
        }
        bu.insertChange(ins.setReviewers(recipients.getReviewers()).setExtraCC(recipients.getCcOnly()).setApprovals(approvals).setMessage(msg.toString()).setNotify(magicBranch.notify).setRequestScopePropagator(requestScopePropagator).setSendMail(true).setUpdateRef(true));
        if (!magicBranch.hashtags.isEmpty()) {
            bu.addOp(changeId, hashtagsFactory.create(new HashtagsInput(magicBranch.hashtags)).setRunHooks(false));
        }
        if (!Strings.isNullOrEmpty(magicBranch.topic)) {
            bu.addOp(changeId, new BatchUpdate.Op() {

                @Override
                public boolean updateChange(ChangeContext ctx) {
                    ctx.getUpdate(psId).setTopic(magicBranch.topic);
                    return true;
                }
            });
        }
    } catch (Exception e) {
        throw INSERT_EXCEPTION.apply(e);
    }
}
#method_after
private void addOps(BatchUpdate bu) throws RestApiException {
    try {
        RevWalk rw = rp.getRevWalk();
        RevCommit commit = rw.parseCommit(commitId);
        rw.parseBody(commit);
        final PatchSet.Id psId = ins.setGroups(groups).getPatchSetId();
        Account.Id me = user.getAccountId();
        List<FooterLine> footerLines = commit.getFooterLines();
        MailRecipients recipients = new MailRecipients();
        Map<String, Short> approvals = new HashMap<>();
        checkNotNull(magicBranch);
        recipients.add(magicBranch.getMailRecipients());
        approvals = magicBranch.labels;
        recipients.add(getRecipientsFromFooters(accountResolver, magicBranch.draft, footerLines));
        recipients.remove(me);
        StringBuilder msg = new StringBuilder(ApprovalsUtil.renderMessageWithApprovals(psId.get(), approvals, Collections.<String, PatchSetApproval>emptyMap()));
        if (!Strings.isNullOrEmpty(magicBranch.message)) {
            msg.append("\n").append(magicBranch.message);
        }
        bu.insertChange(ins.setReviewers(recipients.getReviewers()).setExtraCC(recipients.getCcOnly()).setApprovals(approvals).setMessage(msg.toString()).setNotify(magicBranch.notify).setRequestScopePropagator(requestScopePropagator).setSendMail(true).setUpdateRef(true));
        if (!magicBranch.hashtags.isEmpty()) {
            bu.addOp(changeId, hashtagsFactory.create(new HashtagsInput(magicBranch.hashtags)).setFireEvent(false));
        }
        if (!Strings.isNullOrEmpty(magicBranch.topic)) {
            bu.addOp(changeId, new BatchUpdate.Op() {

                @Override
                public boolean updateChange(ChangeContext ctx) {
                    ctx.getUpdate(psId).setTopic(magicBranch.topic);
                    return true;
                }
            });
        }
        bu.addOp(changeId, new BatchUpdate.Op() {

            @Override
            public boolean updateChange(ChangeContext ctx) {
                change = ctx.getChange();
                return false;
            }
        });
        bu.addOp(changeId, new ChangeProgressOp(newProgress));
    } catch (Exception e) {
        throw INSERT_EXCEPTION.apply(e);
    }
}
#end_block

#method_before
private void submit(Collection<CreateRequest> create, Collection<ReplaceRequest> replace) throws OrmException, RestApiException {
    Map<ObjectId, Change> bySha = Maps.newHashMapWithExpectedSize(create.size() + replace.size());
    for (CreateRequest r : create) {
        bySha.put(r.commitId, r.getChange());
    }
    for (ReplaceRequest r : replace) {
        bySha.put(r.newCommitId, r.change);
    }
    Change tipChange = bySha.get(magicBranch.cmd.getNewId());
    checkState(tipChange != null, "tip of push does not correspond to a change; found these changes: %s", bySha);
    try (MergeOp op = mergeOpProvider.get()) {
        op.merge(db, tipChange, user, false, new SubmitInput());
    }
}
#method_after
private void submit(Collection<CreateRequest> create, Collection<ReplaceRequest> replace) throws OrmException, RestApiException {
    Map<ObjectId, Change> bySha = Maps.newHashMapWithExpectedSize(create.size() + replace.size());
    for (CreateRequest r : create) {
        checkNotNull(r.change, "cannot submit new change %s; op may not have run", r.changeId);
        bySha.put(r.commitId, r.change);
    }
    for (ReplaceRequest r : replace) {
        bySha.put(r.newCommitId, r.notes.getChange());
    }
    Change tipChange = bySha.get(magicBranch.cmd.getNewId());
    checkNotNull(tipChange, "tip of push does not correspond to a change; found these changes: %s", bySha);
    try (MergeOp op = mergeOpProvider.get()) {
        op.merge(db, tipChange, user, false, new SubmitInput());
    }
}
#end_block

#method_before
private void readChangesForReplace() throws OrmException {
    List<CheckedFuture<ChangeNotes, OrmException>> futures = Lists.newArrayListWithCapacity(replaceByChange.size());
    for (ReplaceRequest request : replaceByChange.values()) {
        futures.add(notesFactory.createAsync(changeUpdateExector, db, project.getNameKey(), request.ontoChange));
    }
    for (CheckedFuture<ChangeNotes, OrmException> f : futures) {
        ChangeNotes notes = f.checkedGet();
        if (notes.getChange() != null) {
            replaceByChange.get(notes.getChangeId()).change = notes.getChange();
        }
    }
}
#method_after
private void readChangesForReplace() throws OrmException {
    Collection<ChangeNotes> allNotes = notesFactory.create(db, Collections2.transform(replaceByChange.values(), new Function<ReplaceRequest, Change.Id>() {

        @Override
        public Change.Id apply(ReplaceRequest in) {
            return in.ontoChange;
        }
    }));
    for (ChangeNotes notes : allNotes) {
        replaceByChange.get(notes.getChangeId()).notes = notes;
    }
}
#end_block

#method_before
boolean validate(boolean autoClose) throws IOException, OrmException {
    if (!autoClose && inputCommand.getResult() != NOT_ATTEMPTED) {
        return false;
    } else if (change == null) {
        reject(inputCommand, "change " + ontoChange + " not found");
        return false;
    }
    priorPatchSet = change.currentPatchSetId();
    if (!revisions.containsValue(priorPatchSet)) {
        reject(inputCommand, "change " + ontoChange + " missing revisions");
        return false;
    }
    RevCommit newCommit = rp.getRevWalk().parseCommit(newCommitId);
    RevCommit priorCommit = revisions.inverse().get(priorPatchSet);
    if (newCommit.equals(priorCommit)) {
        // Ignore requests to make the change its current state.
        skip = true;
        reject(inputCommand, "commit already exists (as current patchset)");
        return false;
    }
    changeCtl = projectControl.controlFor(db, change);
    if (!changeCtl.canAddPatchSet(db)) {
        String locked = ".";
        if (changeCtl.isPatchSetLocked(db)) {
            locked = ". Change is patch set locked.";
        }
        reject(inputCommand, "cannot replace " + ontoChange + locked);
        return false;
    } else if (change.getStatus().isClosed()) {
        reject(inputCommand, "change " + ontoChange + " closed");
        return false;
    } else if (revisions.containsKey(newCommit)) {
        reject(inputCommand, "commit already exists (in the change)");
        return false;
    }
    for (Ref r : rp.getRepository().getRefDatabase().getRefs("refs/changes").values()) {
        if (r.getObjectId().equals(newCommit)) {
            reject(inputCommand, "commit already exists (in the project)");
            return false;
        }
    }
    for (RevCommit prior : revisions.keySet()) {
        // amending when trying to address review comments.
        if (rp.getRevWalk().isMergedInto(prior, newCommit)) {
            reject(inputCommand, SAME_CHANGE_ID_IN_MULTIPLE_CHANGES);
            return false;
        }
    }
    if (!validCommit(rp.getRevWalk(), changeCtl.getRefControl(), inputCommand, newCommit)) {
        return false;
    }
    rp.getRevWalk().parseBody(priorCommit);
    // of the commit was modified.
    if (newCommit.getTree().equals(priorCommit.getTree())) {
        boolean messageEq = eq(newCommit.getFullMessage(), priorCommit.getFullMessage());
        boolean parentsEq = parentsEqual(newCommit, priorCommit);
        boolean authorEq = authorEqual(newCommit, priorCommit);
        ObjectReader reader = rp.getRevWalk().getObjectReader();
        if (messageEq && parentsEq && authorEq && !autoClose) {
            addMessage(String.format("(W) No changes between prior commit %s and new commit %s", reader.abbreviate(priorCommit).name(), reader.abbreviate(newCommit).name()));
        } else {
            StringBuilder msg = new StringBuilder();
            msg.append("(I) ");
            msg.append(reader.abbreviate(newCommit).name());
            msg.append(":");
            msg.append(" no files changed");
            if (!authorEq) {
                msg.append(", author changed");
            }
            if (!messageEq) {
                msg.append(", message updated");
            }
            if (!parentsEq) {
                msg.append(", was rebased");
            }
            addMessage(msg.toString());
        }
    }
    if (magicBranch != null && magicBranch.edit) {
        return newEdit();
    }
    newPatchSet();
    return true;
}
#method_after
boolean validate(boolean autoClose) throws IOException, OrmException {
    if (!autoClose && inputCommand.getResult() != NOT_ATTEMPTED) {
        return false;
    } else if (notes == null) {
        reject(inputCommand, "change " + ontoChange + " not found");
        return false;
    }
    priorPatchSet = notes.getChange().currentPatchSetId();
    if (!revisions.containsValue(priorPatchSet)) {
        reject(inputCommand, "change " + ontoChange + " missing revisions");
        return false;
    }
    RevCommit newCommit = rp.getRevWalk().parseCommit(newCommitId);
    RevCommit priorCommit = revisions.inverse().get(priorPatchSet);
    changeCtl = projectControl.controlFor(notes);
    if (!changeCtl.canAddPatchSet(db)) {
        String locked = ".";
        if (changeCtl.isPatchSetLocked(db)) {
            locked = ". Change is patch set locked.";
        }
        reject(inputCommand, "cannot replace " + ontoChange + locked);
        return false;
    } else if (notes.getChange().getStatus().isClosed()) {
        reject(inputCommand, "change " + ontoChange + " closed");
        return false;
    } else if (revisions.containsKey(newCommit)) {
        reject(inputCommand, "commit already exists (in the change)");
        return false;
    }
    for (Ref r : rp.getRepository().getRefDatabase().getRefs("refs/changes").values()) {
        if (r.getObjectId().equals(newCommit)) {
            reject(inputCommand, "commit already exists (in the project)");
            return false;
        }
    }
    for (RevCommit prior : revisions.keySet()) {
        // amending when trying to address review comments.
        if (rp.getRevWalk().isMergedInto(prior, newCommit)) {
            reject(inputCommand, SAME_CHANGE_ID_IN_MULTIPLE_CHANGES);
            return false;
        }
    }
    if (!validCommit(rp.getRevWalk(), changeCtl.getRefControl(), inputCommand, newCommit)) {
        return false;
    }
    rp.getRevWalk().parseBody(priorCommit);
    // of the commit was modified.
    if (newCommit.getTree().equals(priorCommit.getTree())) {
        boolean messageEq = eq(newCommit.getFullMessage(), priorCommit.getFullMessage());
        boolean parentsEq = parentsEqual(newCommit, priorCommit);
        boolean authorEq = authorEqual(newCommit, priorCommit);
        ObjectReader reader = rp.getRevWalk().getObjectReader();
        if (messageEq && parentsEq && authorEq && !autoClose) {
            addMessage(String.format("(W) No changes between prior commit %s and new commit %s", reader.abbreviate(priorCommit).name(), reader.abbreviate(newCommit).name()));
        } else {
            StringBuilder msg = new StringBuilder();
            msg.append("(I) ");
            msg.append(reader.abbreviate(newCommit).name());
            msg.append(":");
            msg.append(" no files changed");
            if (!authorEq) {
                msg.append(", author changed");
            }
            if (!messageEq) {
                msg.append(", message updated");
            }
            if (!parentsEq) {
                msg.append(", was rebased");
            }
            addMessage(msg.toString());
        }
    }
    if (magicBranch != null && magicBranch.edit) {
        return newEdit();
    }
    newPatchSet();
    return true;
}
#end_block

#method_before
private boolean newEdit() {
    psId = change.currentPatchSetId();
    Optional<ChangeEdit> edit = null;
    try {
        edit = editUtil.byChange(changeCtl);
    } catch (AuthException | IOException e) {
        log.error("Cannot retrieve edit", e);
        return false;
    }
    if (edit.isPresent()) {
        if (edit.get().getBasePatchSet().getId().equals(psId)) {
            // replace edit
            cmd = new ReceiveCommand(edit.get().getRef().getObjectId(), newCommitId, edit.get().getRefName());
        } else {
            // delete old edit ref on rebase
            prev = new ReceiveCommand(edit.get().getRef().getObjectId(), ObjectId.zeroId(), edit.get().getRefName());
            createEditCommand();
        }
    } else {
        createEditCommand();
    }
    return true;
}
#method_after
private boolean newEdit() {
    psId = notes.getChange().currentPatchSetId();
    Optional<ChangeEdit> edit = null;
    try {
        edit = editUtil.byChange(changeCtl);
    } catch (AuthException | IOException e) {
        log.error("Cannot retrieve edit", e);
        return false;
    }
    if (edit.isPresent()) {
        if (edit.get().getBasePatchSet().getId().equals(psId)) {
            // replace edit
            cmd = new ReceiveCommand(edit.get().getRef().getObjectId(), newCommitId, edit.get().getRefName());
        } else {
            // delete old edit ref on rebase
            prev = new ReceiveCommand(edit.get().getRef().getObjectId(), ObjectId.zeroId(), edit.get().getRefName());
            createEditCommand();
        }
    } else {
        createEditCommand();
    }
    return true;
}
#end_block

#method_before
private void createEditCommand() {
    // create new edit
    cmd = new ReceiveCommand(ObjectId.zeroId(), newCommitId, RefNames.refsEdit(user.getAccountId(), change.getId(), psId));
}
#method_after
private void createEditCommand() {
    // create new edit
    cmd = new ReceiveCommand(ObjectId.zeroId(), newCommitId, RefNames.refsEdit(user.getAccountId(), notes.getChangeId(), psId));
}
#end_block

#method_before
private void newPatchSet() throws IOException {
    RevCommit newCommit = rp.getRevWalk().parseCommit(newCommitId);
    psId = ChangeUtil.nextPatchSetId(allRefs, change.currentPatchSetId());
    info = patchSetInfoFactory.get(rp.getRevWalk(), newCommit, psId);
    cmd = new ReceiveCommand(ObjectId.zeroId(), newCommitId, psId.toRefName());
}
#method_after
private void newPatchSet() throws IOException {
    RevCommit newCommit = rp.getRevWalk().parseCommit(newCommitId);
    psId = ChangeUtil.nextPatchSetId(allRefs, notes.getChange().currentPatchSetId());
    info = patchSetInfoFactory.get(rp.getRevWalk(), newCommit, psId);
    cmd = new ReceiveCommand(ObjectId.zeroId(), newCommitId, psId.toRefName());
}
#end_block

#method_before
void addOps(BatchUpdate bu) throws IOException {
    if (cmd.getResult() == NOT_ATTEMPTED) {
        // TODO(dborowitz): When does this happen? Only when an edit ref is
        // involved?
        cmd.execute(rp);
    }
    if (magicBranch != null && magicBranch.edit) {
        return;
    }
    RevWalk rw = rp.getRevWalk();
    // TODO(dborowitz): Move to ReplaceOp#updateRepo.
    RevCommit newCommit = rw.parseCommit(newCommitId);
    rw.parseBody(newCommit);
    RevCommit priorCommit = revisions.inverse().get(priorPatchSet);
    replaceOp = replaceOpFactory.create(requestScopePropagator, projectControl, change.getDest(), checkMergedInto, priorPatchSet, priorCommit, psId, newCommit, info, groups, magicBranch, rp.getPushCertificate());
    bu.addOp(change.getId(), replaceOp);
}
#method_after
void addOps(BatchUpdate bu, @Nullable Task progress) throws IOException {
    if (cmd.getResult() == NOT_ATTEMPTED) {
        // TODO(dborowitz): When does this happen? Only when an edit ref is
        // involved?
        cmd.execute(rp);
    }
    if (magicBranch != null && magicBranch.edit) {
        return;
    }
    RevWalk rw = rp.getRevWalk();
    // TODO(dborowitz): Move to ReplaceOp#updateRepo.
    RevCommit newCommit = rw.parseCommit(newCommitId);
    rw.parseBody(newCommit);
    RevCommit priorCommit = revisions.inverse().get(priorPatchSet);
    replaceOp = replaceOpFactory.create(requestScopePropagator, projectControl, notes.getChange().getDest(), checkMergedInto, priorPatchSet, priorCommit, psId, newCommit, info, groups, magicBranch, rp.getPushCertificate());
    bu.addOp(notes.getChangeId(), replaceOp);
    if (progress != null) {
        bu.addOp(notes.getChangeId(), new ChangeProgressOp(progress));
    }
}
#end_block

#method_before
void insertPatchSetWithoutBatchUpdate() throws IOException, UpdateException, RestApiException {
    try (BatchUpdate bu = batchUpdateFactory.create(db, projectControl.getProject().getNameKey(), user, TimeUtil.nowTs());
        ObjectInserter ins = repo.newObjectInserter()) {
        bu.setRepository(repo, rp.getRevWalk(), ins);
        addOps(bu);
        bu.execute();
    }
}
#method_after
void insertPatchSetWithoutBatchUpdate() throws IOException, UpdateException, RestApiException {
    try (BatchUpdate bu = batchUpdateFactory.create(db, projectControl.getProject().getNameKey(), user, TimeUtil.nowTs());
        ObjectInserter ins = repo.newObjectInserter()) {
        bu.setRepository(repo, rp.getRevWalk(), ins);
        addOps(bu, replaceProgress);
        bu.execute();
    }
}
#end_block

#method_before
private void validateNewCommits(RefControl ctl, ReceiveCommand cmd) {
    if (ctl.canForgeAuthor() && ctl.canForgeCommitter() && ctl.canForgeGerritServerIdentity() && ctl.canUploadMerges() && !projectControl.getProjectState().isUseSignedOffBy() && Iterables.isEmpty(rejectCommits) && !RefNames.REFS_CONFIG.equals(ctl.getRefName()) && !(MagicBranch.isMagicBranch(cmd.getRefName()) || NEW_PATCHSET.matcher(cmd.getRefName()).matches())) {
        return;
    }
    boolean defaultName = Strings.isNullOrEmpty(user.getAccount().getFullName());
    RevWalk walk = rp.getRevWalk();
    walk.reset();
    walk.sort(RevSort.NONE);
    try {
        RevObject parsedObject = walk.parseAny(cmd.getNewId());
        if (!(parsedObject instanceof RevCommit)) {
            return;
        }
        walk.markStart((RevCommit) parsedObject);
        markHeadsAsUninteresting(walk, cmd.getRefName());
        Set<ObjectId> existing = changeRefsById().keySet();
        for (RevCommit c; (c = walk.next()) != null; ) {
            if (existing.contains(c)) {
                continue;
            } else if (!validCommit(walk, ctl, cmd, c)) {
                break;
            }
            if (defaultName && user.hasEmailAddress(c.getCommitterIdent().getEmailAddress())) {
                try {
                    Account a = db.accounts().get(user.getAccountId());
                    if (a != null && Strings.isNullOrEmpty(a.getFullName())) {
                        a.setFullName(c.getCommitterIdent().getName());
                        db.accounts().update(Collections.singleton(a));
                        user.getAccount().setFullName(a.getFullName());
                        accountCache.evict(a.getId());
                    }
                } catch (OrmException e) {
                    log.warn("Cannot default full_name", e);
                } finally {
                    defaultName = false;
                }
            }
        }
    } catch (IOException err) {
        cmd.setResult(REJECTED_MISSING_OBJECT);
        log.error("Invalid pack upload; one or more objects weren't sent", err);
    }
}
#method_after
private void validateNewCommits(RefControl ctl, ReceiveCommand cmd) {
    if (ctl.canForgeAuthor() && ctl.canForgeCommitter() && ctl.canForgeGerritServerIdentity() && ctl.canUploadMerges() && !projectControl.getProjectState().isUseSignedOffBy() && Iterables.isEmpty(rejectCommits) && !RefNames.REFS_CONFIG.equals(ctl.getRefName()) && !(MagicBranch.isMagicBranch(cmd.getRefName()) || NEW_PATCHSET.matcher(cmd.getRefName()).matches())) {
        return;
    }
    boolean defaultName = Strings.isNullOrEmpty(user.getAccount().getFullName());
    RevWalk walk = rp.getRevWalk();
    walk.reset();
    walk.sort(RevSort.NONE);
    try {
        RevObject parsedObject = walk.parseAny(cmd.getNewId());
        if (!(parsedObject instanceof RevCommit)) {
            return;
        }
        SetMultimap<ObjectId, Ref> existing = changeRefsById();
        walk.markStart((RevCommit) parsedObject);
        markHeadsAsUninteresting(walk, cmd.getRefName());
        for (RevCommit c; (c = walk.next()) != null; ) {
            if (existing.keySet().contains(c)) {
                continue;
            } else if (!validCommit(walk, ctl, cmd, c)) {
                break;
            }
            if (defaultName && user.hasEmailAddress(c.getCommitterIdent().getEmailAddress())) {
                try {
                    Account a = db.accounts().get(user.getAccountId());
                    if (a != null && Strings.isNullOrEmpty(a.getFullName())) {
                        a.setFullName(c.getCommitterIdent().getName());
                        db.accounts().update(Collections.singleton(a));
                        user.getAccount().setFullName(a.getFullName());
                        accountCache.evict(a.getId());
                    }
                } catch (OrmException e) {
                    log.warn("Cannot default full_name", e);
                } finally {
                    defaultName = false;
                }
            }
        }
    } catch (IOException err) {
        cmd.setResult(REJECTED_MISSING_OBJECT);
        log.error("Invalid pack upload; one or more objects weren't sent", err);
    }
}
#end_block

#method_before
private void autoCloseChanges(final ReceiveCommand cmd) {
    String refName = cmd.getRefName();
    checkState(!MagicBranch.isMagicBranch(refName), "shouldn't be auto-closing changes on magic branch %s", refName);
    RevWalk rw = rp.getRevWalk();
    // insertChangesAndPatchSets.
    try (BatchUpdate bu = batchUpdateFactory.create(db, projectControl.getProject().getNameKey(), user, TimeUtil.nowTs());
        ObjectInserter ins = repo.newObjectInserter()) {
        bu.setRepository(repo, rp.getRevWalk(), ins).updateChangesInParallel();
        // TODO(dborowitz): Teach BatchUpdate to ignore missing changes.
        RevCommit newTip = rw.parseCommit(cmd.getNewId());
        Branch.NameKey branch = new Branch.NameKey(project.getNameKey(), refName);
        rw.reset();
        rw.markStart(newTip);
        if (!ObjectId.zeroId().equals(cmd.getOldId())) {
            rw.markUninteresting(rw.parseCommit(cmd.getOldId()));
        }
        SetMultimap<ObjectId, Ref> byCommit = changeRefsById();
        Map<Change.Key, Change> byKey = null;
        int n = 0;
        COMMIT: for (RevCommit c; (c = rw.next()) != null; ) {
            rw.parseBody(c);
            for (Ref ref : byCommit.get(c.copy())) {
                n++;
                PatchSet.Id psId = PatchSet.Id.fromRef(ref.getName());
                bu.addOp(psId.getParentKey(), mergedByPushOpFactory.create(requestScopePropagator, psId, refName));
                continue COMMIT;
            }
            for (String changeId : c.getFooterLines(CHANGE_ID)) {
                if (byKey == null) {
                    byKey = openChangesByBranch(branch);
                }
                Change onto = byKey.get(new Change.Key(changeId.trim()));
                if (onto != null) {
                    Change.Id id = onto.getId();
                    final ReplaceRequest req = new ReplaceRequest(id, c, cmd, false);
                    req.change = onto;
                    if (req.validate(true)) {
                        n++;
                        req.addOps(bu);
                        bu.addOp(id, mergedByPushOpFactory.create(requestScopePropagator, req.psId, refName).setPatchSetProvider(new Provider<PatchSet>() {

                            @Override
                            public PatchSet get() {
                                return req.replaceOp.getPatchSet();
                            }
                        }));
                    }
                    break;
                }
            }
        }
        bu.execute();
        closeProgress.update(n);
    } catch (RestApiException e) {
        log.error("Can't insert patchset", e);
    } catch (IOException | OrmException | UpdateException e) {
        log.error("Can't scan for changes to close", e);
    }
}
#method_after
private void autoCloseChanges(final ReceiveCommand cmd) {
    String refName = cmd.getRefName();
    checkState(!MagicBranch.isMagicBranch(refName), "shouldn't be auto-closing changes on magic branch %s", refName);
    RevWalk rw = rp.getRevWalk();
    // insertChangesAndPatchSets.
    try (BatchUpdate bu = batchUpdateFactory.create(db, projectControl.getProject().getNameKey(), user, TimeUtil.nowTs());
        ObjectInserter ins = repo.newObjectInserter()) {
        bu.setRepository(repo, rp.getRevWalk(), ins).updateChangesInParallel();
        // TODO(dborowitz): Teach BatchUpdate to ignore missing changes.
        RevCommit newTip = rw.parseCommit(cmd.getNewId());
        Branch.NameKey branch = new Branch.NameKey(project.getNameKey(), refName);
        rw.reset();
        rw.markStart(newTip);
        if (!ObjectId.zeroId().equals(cmd.getOldId())) {
            rw.markUninteresting(rw.parseCommit(cmd.getOldId()));
        }
        SetMultimap<ObjectId, Ref> byCommit = changeRefsById();
        Map<Change.Key, ChangeNotes> byKey = null;
        List<ReplaceRequest> replaceAndClose = new ArrayList<>();
        COMMIT: for (RevCommit c; (c = rw.next()) != null; ) {
            rw.parseBody(c);
            for (Ref ref : byCommit.get(c.copy())) {
                PatchSet.Id psId = PatchSet.Id.fromRef(ref.getName());
                bu.addOp(psId.getParentKey(), mergedByPushOpFactory.create(requestScopePropagator, psId, refName));
                continue COMMIT;
            }
            for (String changeId : c.getFooterLines(CHANGE_ID)) {
                if (byKey == null) {
                    byKey = openChangesByBranch(branch);
                }
                ChangeNotes onto = byKey.get(new Change.Key(changeId.trim()));
                if (onto != null) {
                    // Hold onto this until we're done with the walk, as the call to
                    // req.validate below calls isMergedInto which resets the walk.
                    ReplaceRequest req = new ReplaceRequest(onto.getChangeId(), c, cmd, false);
                    req.notes = onto;
                    replaceAndClose.add(req);
                    continue COMMIT;
                }
            }
        }
        for (final ReplaceRequest req : replaceAndClose) {
            Change.Id id = req.notes.getChangeId();
            if (!req.validate(true)) {
                continue;
            }
            req.addOps(bu, null);
            bu.addOp(id, mergedByPushOpFactory.create(requestScopePropagator, req.psId, refName).setPatchSetProvider(new Provider<PatchSet>() {

                @Override
                public PatchSet get() {
                    return req.replaceOp.getPatchSet();
                }
            }));
            bu.addOp(id, new ChangeProgressOp(closeProgress));
        }
        bu.execute();
    } catch (RestApiException e) {
        log.error("Can't insert patchset", e);
    } catch (IOException | OrmException | UpdateException e) {
        log.error("Can't scan for changes to close", e);
    }
}
#end_block

#method_before
private Map<Change.Key, Change> openChangesByBranch(Branch.NameKey branch) throws OrmException {
    Map<Change.Key, Change> r = new HashMap<>();
    for (ChangeData cd : queryProvider.get().byBranchOpen(branch)) {
        r.put(cd.change().getKey(), cd.change());
    }
    return r;
}
#method_after
private Map<Change.Key, ChangeNotes> openChangesByBranch(Branch.NameKey branch) throws OrmException {
    Map<Change.Key, ChangeNotes> r = new HashMap<>();
    for (ChangeData cd : queryProvider.get().byBranchOpen(branch)) {
        r.put(cd.change().getKey(), cd.notes());
    }
    return r;
}
#end_block

#method_before
public void updateSuperProjects() throws SubmoduleException {
    SetMultimap<Project.NameKey, Branch.NameKey> dst = branchesByProject();
    Set<Project.NameKey> projects = dst.keySet();
    try {
        for (Project.NameKey project : projects) {
            // get a new BatchUpdate for the project
            orm.openRepo(project, false);
            orm.getRepo(project).resetUpdate();
            for (Branch.NameKey branch : dst.get(project)) {
                SubmoduleOp.RepoOnlyOp op = new SubmoduleOp.RepoOnlyOp(this, branch);
                orm.getRepo(project).getUpdate().addRepoOnlyOp(op);
            }
        }
        BatchUpdate.execute(orm.batchUpdates(projects), new Listener());
    } catch (RestApiException | UpdateException | IOException | NoSuchProjectException e) {
        throw new SubmoduleException("Cannot update gitlinks", e);
    }
}
#method_after
public void updateSuperProjects() throws SubmoduleException {
    SetMultimap<Project.NameKey, Branch.NameKey> dst = branchesByProject();
    Set<Project.NameKey> projects = dst.keySet();
    try {
        for (Project.NameKey project : projects) {
            // get a new BatchUpdate for the project
            orm.openRepo(project, false);
            // TODO:czhen remove this when MergeOp combine this into BatchUpdate
            orm.getRepo(project).resetUpdate();
            for (Branch.NameKey branch : dst.get(project)) {
                SubmoduleOp.GitlinkOp op = new SubmoduleOp.GitlinkOp(branch);
                orm.getRepo(project).getUpdate().addRepoOnlyOp(op);
            }
        }
        BatchUpdate.execute(orm.batchUpdates(projects), Listener.NONE);
    } catch (RestApiException | UpdateException | IOException | NoSuchProjectException e) {
        throw new SubmoduleException("Cannot update gitlinks", e);
    }
}
#end_block

#method_before
public CodeReviewCommit composeGitlinksCommit(final Branch.NameKey subscriber, RevCommit baseCommit) throws IOException, SubmoduleException, OrmException {
    PersonIdent author = null;
    StringBuilder msgbuf = new StringBuilder("Update git submodules\n\n");
    boolean sameAuthorForAll = true;
    try {
        orm.openRepo(subscriber.getParentKey(), false);
    } catch (NoSuchProjectException | IOException e) {
        throw new SubmoduleException("Cannot access superproject", e);
    }
    OpenRepo or = orm.getRepo(subscriber.getParentKey());
    Ref r = or.repo.exactRef(subscriber.get());
    if (r == null) {
        throw new SubmoduleException("The branch was probably deleted from the subscriber repository");
    }
    RevCommit currentCommit = (baseCommit != null) ? baseCommit : or.rw.parseCommit(or.repo.exactRef(subscriber.get()).getObjectId());
    or.rw.parseBody(currentCommit);
    DirCache dc = readTree(or.rw, currentCommit);
    DirCacheEditor ed = dc.editor();
    for (SubmoduleSubscription s : targets.get(subscriber)) {
        try {
            orm.openRepo(s.getSubmodule().getParentKey(), false);
        } catch (NoSuchProjectException | IOException e) {
            throw new SubmoduleException("Cannot access submodule", e);
        }
        OpenRepo subOr = orm.getRepo(s.getSubmodule().getParentKey());
        Repository subRepo = subOr.repo;
        Ref ref = subRepo.getRefDatabase().exactRef(s.getSubmodule().get());
        if (ref == null) {
            ed.add(new DeletePath(s.getPath()));
            continue;
        }
        ObjectId updateTo = ref.getObjectId();
        if (branchTips.containsKey(s.getSubmodule())) {
            updateTo = branchTips.get(s.getSubmodule());
        }
        RevWalk subOrRw = subOr.rw;
        final RevCommit newCommit = subOrRw.parseCommit(updateTo);
        subOrRw.parseBody(newCommit);
        if (author == null) {
            author = newCommit.getAuthorIdent();
        } else if (!author.equals(newCommit.getAuthorIdent())) {
            sameAuthorForAll = false;
        }
        DirCacheEntry dce = dc.getEntry(s.getPath());
        ObjectId oldId;
        if (dce != null) {
            if (!dce.getFileMode().equals(FileMode.GITLINK)) {
                log.error("Requested to update gitlink " + s.getPath() + " in " + s.getSubmodule().getParentKey().get() + " but entry " + "doesn't have gitlink file mode.");
                continue;
            }
            oldId = dce.getObjectId();
        } else {
            // This submodule did not exist before. We do not want to add
            // the full submodule history to the commit message, so omit it.
            oldId = updateTo;
        }
        ed.add(new PathEdit(s.getPath()) {

            @Override
            public void apply(DirCacheEntry ent) {
                ent.setFileMode(FileMode.GITLINK);
                ent.setObjectId(newCommit.getId());
            }
        });
        if (verboseSuperProject) {
            msgbuf.append("Project: " + s.getSubmodule().getParentKey().get());
            msgbuf.append(" " + s.getSubmodule().getShortName());
            msgbuf.append(" " + newCommit.getName());
            msgbuf.append("\n\n");
            try {
                subOrRw.resetRetain(subOr.canMergeFlag);
                subOrRw.markStart(newCommit);
                subOrRw.markUninteresting(subOrRw.parseCommit(oldId));
                for (RevCommit c : subOrRw) {
                    subOrRw.parseBody(c);
                    msgbuf.append(c.getFullMessage() + "\n\n");
                }
            } catch (IOException e) {
                throw new SubmoduleException("Could not perform a revwalk to " + "create superproject commit message", e);
            }
        }
    }
    ed.finish();
    ObjectInserter oi = or.repo.newObjectInserter();
    CodeReviewRevWalk rw = or.rw;
    ObjectId tree = dc.writeTree(oi);
    if (!sameAuthorForAll || author == null) {
        author = myIdent;
    }
    CommitBuilder commit = new CommitBuilder();
    commit.setTreeId(tree);
    if (baseCommit != null) {
        // modify the baseCommit
        commit.setParentIds(baseCommit.getParents());
        commit.setMessage(baseCommit.getFullMessage() + "\n\n" + msgbuf.toString());
        commit.setAuthor(baseCommit.getAuthorIdent());
    } else {
        // create a new commit
        commit.setParentId(currentCommit);
        commit.setMessage(msgbuf.toString());
        commit.setAuthor(author);
    }
    commit.setCommitter(myIdent);
    ObjectId id = oi.insert(commit);
    oi.flush();
    return rw.parseCommit(id);
}
#method_after
public CodeReviewCommit composeGitlinksCommit(final Branch.NameKey subscriber, RevCommit baseCommit) throws IOException, SubmoduleException, OrmException {
    PersonIdent author = null;
    StringBuilder msgbuf = new StringBuilder("Update git submodules\n\n");
    boolean sameAuthorForAll = true;
    try {
        orm.openRepo(subscriber.getParentKey(), false);
    } catch (NoSuchProjectException | IOException e) {
        throw new SubmoduleException("Cannot access superproject", e);
    }
    OpenRepo or = orm.getRepo(subscriber.getParentKey());
    Ref r = or.repo.exactRef(subscriber.get());
    if (r == null) {
        throw new SubmoduleException("The branch was probably deleted from the subscriber repository");
    }
    RevCommit currentCommit = (baseCommit != null) ? baseCommit : or.rw.parseCommit(or.repo.exactRef(subscriber.get()).getObjectId());
    or.rw.parseBody(currentCommit);
    DirCache dc = readTree(or.rw, currentCommit);
    DirCacheEditor ed = dc.editor();
    for (SubmoduleSubscription s : targets.get(subscriber)) {
        try {
            orm.openRepo(s.getSubmodule().getParentKey(), false);
        } catch (NoSuchProjectException | IOException e) {
            throw new SubmoduleException("Cannot access submodule", e);
        }
        OpenRepo subOr = orm.getRepo(s.getSubmodule().getParentKey());
        Repository subRepo = subOr.repo;
        Ref ref = subRepo.getRefDatabase().exactRef(s.getSubmodule().get());
        if (ref == null) {
            ed.add(new DeletePath(s.getPath()));
            continue;
        }
        ObjectId updateTo = ref.getObjectId();
        if (branchTips.containsKey(s.getSubmodule())) {
            updateTo = branchTips.get(s.getSubmodule());
        }
        RevWalk subOrRw = subOr.rw;
        final RevCommit newCommit = subOrRw.parseCommit(updateTo);
        subOrRw.parseBody(newCommit);
        if (author == null) {
            author = newCommit.getAuthorIdent();
        } else if (!author.equals(newCommit.getAuthorIdent())) {
            sameAuthorForAll = false;
        }
        DirCacheEntry dce = dc.getEntry(s.getPath());
        ObjectId oldId;
        if (dce != null) {
            if (!dce.getFileMode().equals(FileMode.GITLINK)) {
                String errMsg = "Requested to update gitlink " + s.getPath() + " in " + s.getSubmodule().getParentKey().get() + " but entry " + "doesn't have gitlink file mode.";
                throw new SubmoduleException(errMsg);
            }
            oldId = dce.getObjectId();
        } else {
            // This submodule did not exist before. We do not want to add
            // the full submodule history to the commit message, so omit it.
            oldId = updateTo;
        }
        ed.add(new PathEdit(s.getPath()) {

            @Override
            public void apply(DirCacheEntry ent) {
                ent.setFileMode(FileMode.GITLINK);
                ent.setObjectId(newCommit.getId());
            }
        });
        if (verboseSuperProject) {
            msgbuf.append("Project: " + s.getSubmodule().getParentKey().get());
            msgbuf.append(" " + s.getSubmodule().getShortName());
            msgbuf.append(" " + newCommit.getName());
            msgbuf.append("\n\n");
            try {
                subOrRw.resetRetain(subOr.canMergeFlag);
                subOrRw.markStart(newCommit);
                subOrRw.markUninteresting(subOrRw.parseCommit(oldId));
                for (RevCommit c : subOrRw) {
                    subOrRw.parseBody(c);
                    msgbuf.append(c.getFullMessage() + "\n\n");
                }
            } catch (IOException e) {
                throw new SubmoduleException("Could not perform a revwalk to " + "create superproject commit message", e);
            }
        }
    }
    ed.finish();
    ObjectInserter oi = or.ins;
    CodeReviewRevWalk rw = or.rw;
    ObjectId tree = dc.writeTree(oi);
    if (!sameAuthorForAll || author == null) {
        author = myIdent;
    }
    CommitBuilder commit = new CommitBuilder();
    commit.setTreeId(tree);
    if (baseCommit != null) {
        // modify the baseCommit
        commit.setParentIds(baseCommit.getParents());
        commit.setMessage(baseCommit.getFullMessage() + "\n\n" + msgbuf.toString());
        commit.setAuthor(baseCommit.getAuthorIdent());
    } else {
        // create a new commit
        commit.setParentId(currentCommit);
        commit.setMessage(msgbuf.toString());
        commit.setAuthor(author);
    }
    commit.setCommitter(myIdent);
    ObjectId id = oi.insert(commit);
    return rw.parseCommit(id);
}
#end_block

#method_before
private void checkSubmitRulesAndState() throws ResourceConflictException {
    for (ChangeData cd : commits.changes.values()) {
        try {
            if (cd.change().getStatus() != Change.Status.NEW) {
                commits.problem(cd.getId(), "Change " + cd.getId() + " is " + cd.change().getStatus().toString().toLowerCase());
            } else {
                checkSubmitRule(cd);
            }
        } catch (ResourceConflictException e) {
            commits.problem(cd.getId(), e.getMessage());
        } catch (OrmException e) {
            String msg = "Error checking submit rules for change";
            log.warn(msg + " " + cd.getId(), e);
            commits.problem(cd.getId(), msg);
        }
    }
    commits.maybeFailVerbose();
}
#method_after
private void checkSubmitRulesAndState(ChangeSet cs) throws ResourceConflictException {
    checkArgument(!cs.furtherHiddenChanges(), "checkSubmitRulesAndState called for topic with hidden change");
    for (ChangeData cd : cs.changes()) {
        try {
            if (cd.change().getStatus() != Change.Status.NEW) {
                commits.problem(cd.getId(), "Change " + cd.getId() + " is " + cd.change().getStatus().toString().toLowerCase());
            } else {
                checkSubmitRule(cd);
            }
        } catch (ResourceConflictException e) {
            commits.problem(cd.getId(), e.getMessage());
        } catch (OrmException e) {
            String msg = "Error checking submit rules for change";
            log.warn(msg + " " + cd.getId(), e);
            commits.problem(cd.getId(), msg);
        }
    }
    commits.maybeFailVerbose();
}
#end_block

#method_before
private void bypassSubmitRules(ChangeSet cs) {
    for (ChangeData cd : cs.changes()) {
        List<SubmitRecord> records;
        try {
            records = new ArrayList<>(getSubmitRecords(cd));
        } catch (OrmException e) {
            log.warn("Error checking submit rules for change " + cd.getId(), e);
            records = new ArrayList<>(1);
        }
        SubmitRecord forced = new SubmitRecord();
        forced.status = SubmitRecord.Status.FORCED;
        records.add(forced);
        cd.setSubmitRecords(records);
    }
}
#method_after
private void bypassSubmitRules(ChangeSet cs) {
    checkArgument(!cs.furtherHiddenChanges(), "cannot bypass submit rules for topic with hidden change");
    for (ChangeData cd : cs.changes()) {
        List<SubmitRecord> records;
        try {
            records = new ArrayList<>(getSubmitRecords(cd));
        } catch (OrmException e) {
            log.warn("Error checking submit rules for change " + cd.getId(), e);
            records = new ArrayList<>(1);
        }
        SubmitRecord forced = new SubmitRecord();
        forced.status = SubmitRecord.Status.FORCED;
        records.add(forced);
        cd.setSubmitRecords(records);
    }
}
#end_block

#method_before
public void merge(ReviewDb db, Change change, IdentifiedUser caller, boolean checkSubmitRules, SubmitInput submitInput) throws OrmException, RestApiException {
    this.submitInput = submitInput;
    this.caller = caller;
    updateSubmissionId(change);
    this.db = db;
    orm.setContext(db, ts, caller, submissionId);
    logDebug("Beginning integration of {}", change);
    try {
        ChangeSet cs = mergeSuperSet.completeChangeSet(db, change, caller);
        checkState(cs.ids().contains(change.getId()), "change %s missing from %s", change.getId(), cs);
        this.commits = new CommitStatus(cs);
        MergeSuperSet.reloadChanges(cs);
        logDebug("Calculated to merge {}", cs);
        if (checkSubmitRules) {
            logDebug("Checking submit rules and state");
            checkSubmitRulesAndState();
        } else {
            logDebug("Bypassing submit rules");
            bypassSubmitRules(cs);
        }
        try {
            integrateIntoHistory(cs);
        } catch (IntegrationException e) {
            logError("Error from integrateIntoHistory", e);
            throw new ResourceConflictException(e.getMessage(), e);
        }
    } catch (IOException e) {
        // Anything before the merge attempt is an error
        throw new OrmException(e);
    }
}
#method_after
public void merge(ReviewDb db, Change change, IdentifiedUser caller, boolean checkSubmitRules, SubmitInput submitInput) throws OrmException, RestApiException {
    this.submitInput = submitInput;
    this.caller = caller;
    updateSubmissionId(change);
    this.db = db;
    orm.setContext(db, ts, caller, submissionId);
    logDebug("Beginning integration of {}", change);
    try {
        ChangeSet cs = mergeSuperSet.completeChangeSet(db, change, caller);
        checkState(cs.ids().contains(change.getId()), "change %s missing from %s", change.getId(), cs);
        if (cs.furtherHiddenChanges()) {
            throw new AuthException("A change to be submitted with " + change.getId() + " is not visible");
        }
        this.commits = new CommitStatus(cs);
        MergeSuperSet.reloadChanges(cs);
        logDebug("Calculated to merge {}", cs);
        if (checkSubmitRules) {
            logDebug("Checking submit rules and state");
            checkSubmitRulesAndState(cs);
        } else {
            logDebug("Bypassing submit rules");
            bypassSubmitRules(cs);
        }
        try {
            integrateIntoHistory(cs);
        } catch (IntegrationException e) {
            logError("Error from integrateIntoHistory", e);
            throw new ResourceConflictException(e.getMessage(), e);
        }
    } catch (IOException e) {
        // Anything before the merge attempt is an error
        throw new OrmException(e);
    }
}
#end_block

#method_before
private void integrateIntoHistory(ChangeSet cs) throws IntegrationException, RestApiException {
    logDebug("Beginning merge attempt on {}", cs);
    Map<Branch.NameKey, BranchBatch> toSubmit = new HashMap<>();
    logDebug("Perform the merges");
    Multimap<Project.NameKey, Branch.NameKey> br;
    Multimap<Branch.NameKey, ChangeData> cbb;
    try {
        br = cs.branchesByProject();
        cbb = cs.changesByBranch();
    } catch (OrmException e) {
        throw new IntegrationException("Error reading changes to submit", e);
    }
    Set<Project.NameKey> projects = br.keySet();
    Collection<Branch.NameKey> branches = cbb.keySet();
    openRepos(projects);
    for (Branch.NameKey branch : branches) {
        OpenRepo or = orm.getRepo(branch.getParentKey());
        toSubmit.put(branch, validateChangeList(or, cbb.get(branch)));
    }
    // Done checks that don't involve running submit strategies.
    commits.maybeFailVerbose();
    List<SubmitStrategy> strategies = new ArrayList<>(branches.size());
    for (Branch.NameKey branch : branches) {
        OpenRepo or = orm.getRepo(branch.getParentKey());
        OpenBranch ob = or.getBranch(branch);
        BranchBatch submitting = toSubmit.get(branch);
        checkNotNull(submitting.submitType(), "null submit type for %s; expected to previously fail fast", submitting);
        Set<CodeReviewCommit> commitsToSubmit = commits(submitting.changes());
        ob.mergeTip = new MergeTip(ob.oldTip, commitsToSubmit);
        SubmitStrategy strategy = createStrategy(or, ob.mergeTip, branch, submitting.submitType(), ob.oldTip);
        strategies.add(strategy);
        strategy.addOps(or.getUpdate(), commitsToSubmit);
    }
    try {
        BatchUpdate.execute(batchUpdates(projects), new SubmitStrategyListener(submitInput, strategies, commits));
    } catch (UpdateException e) {
        // BatchUpdate may have inadvertently wrapped an IntegrationException
        // thrown by some legacy SubmitStrategyOp code that intended the error
        // message to be user-visible. Copy the message from the wrapped
        // exception.
        // 
        // If you happen across one of these, the correct fix is to convert the
        // inner IntegrationException to a ResourceConflictException.
        String msg;
        if (e.getCause() instanceof IntegrationException) {
            msg = e.getCause().getMessage();
        } else {
            msg = "Error submitting change" + (cs.size() != 1 ? "s" : "");
        }
        throw new IntegrationException(msg, e);
    }
    updateSuperProjects(br.values());
}
#method_after
private void integrateIntoHistory(ChangeSet cs) throws IntegrationException, RestApiException {
    checkArgument(!cs.furtherHiddenChanges(), "cannot integrate hidden changes into history");
    logDebug("Beginning merge attempt on {}", cs);
    Map<Branch.NameKey, BranchBatch> toSubmit = new HashMap<>();
    logDebug("Perform the merges");
    Multimap<Project.NameKey, Branch.NameKey> br;
    Multimap<Branch.NameKey, ChangeData> cbb;
    try {
        br = cs.branchesByProject();
        cbb = cs.changesByBranch();
    } catch (OrmException e) {
        throw new IntegrationException("Error reading changes to submit", e);
    }
    Set<Project.NameKey> projects = br.keySet();
    Collection<Branch.NameKey> branches = cbb.keySet();
    openRepos(projects);
    for (Branch.NameKey branch : branches) {
        OpenRepo or = orm.getRepo(branch.getParentKey());
        toSubmit.put(branch, validateChangeList(or, cbb.get(branch)));
    }
    // Done checks that don't involve running submit strategies.
    commits.maybeFailVerbose();
    List<SubmitStrategy> strategies = new ArrayList<>(branches.size());
    for (Branch.NameKey branch : branches) {
        OpenRepo or = orm.getRepo(branch.getParentKey());
        OpenBranch ob = or.getBranch(branch);
        BranchBatch submitting = toSubmit.get(branch);
        checkNotNull(submitting.submitType(), "null submit type for %s; expected to previously fail fast", submitting);
        Set<CodeReviewCommit> commitsToSubmit = commits(submitting.changes());
        ob.mergeTip = new MergeTip(ob.oldTip, commitsToSubmit);
        SubmitStrategy strategy = createStrategy(or, ob.mergeTip, branch, submitting.submitType(), ob.oldTip);
        strategies.add(strategy);
        strategy.addOps(or.getUpdate(), commitsToSubmit);
    }
    try {
        BatchUpdate.execute(batchUpdates(projects), new SubmitStrategyListener(submitInput, strategies, commits));
    } catch (UpdateException e) {
        // BatchUpdate may have inadvertently wrapped an IntegrationException
        // thrown by some legacy SubmitStrategyOp code that intended the error
        // message to be user-visible. Copy the message from the wrapped
        // exception.
        // 
        // If you happen across one of these, the correct fix is to convert the
        // inner IntegrationException to a ResourceConflictException.
        String msg;
        if (e.getCause() instanceof IntegrationException) {
            msg = e.getCause().getMessage();
        } else {
            msg = "Error submitting change" + (cs.size() != 1 ? "s" : "");
        }
        throw new IntegrationException(msg, e);
    }
    updateSuperProjects(br.values());
}
#end_block

#method_before
private Set<RevCommit> getAlreadyAccepted(OpenRepo or, CodeReviewCommit branchTip) throws IntegrationException {
    Set<RevCommit> alreadyAccepted = new HashSet<>();
    if (branchTip != null) {
        alreadyAccepted.add(branchTip);
    }
    try {
        for (Ref r : or.repo.getRefDatabase().getRefs(Constants.R_HEADS).values()) {
            try {
                alreadyAccepted.add(or.rw.parseCommit(r.getObjectId()));
            } catch (IncorrectObjectTypeException iote) {
            // Not a commit? Skip over it.
            }
        }
    } catch (IOException e) {
        throw new IntegrationException("Failed to determine already accepted commits.", e);
    }
    logDebug("Found {} existing heads", alreadyAccepted.size());
    return alreadyAccepted;
}
#method_after
private Set<RevCommit> getAlreadyAccepted(OpenRepo or, CodeReviewCommit branchTip) throws IntegrationException {
    Set<RevCommit> alreadyAccepted = new HashSet<>();
    if (branchTip != null) {
        alreadyAccepted.add(branchTip);
    }
    try {
        for (Ref r : or.repo.getRefDatabase().getRefs(Constants.R_HEADS).values()) {
            try {
                CodeReviewCommit aac = or.rw.parseCommit(r.getObjectId());
                if (!commits.commits.values().contains(aac)) {
                    alreadyAccepted.add(aac);
                }
            } catch (IncorrectObjectTypeException iote) {
            // Not a commit? Skip over it.
            }
        }
    } catch (IOException e) {
        throw new IntegrationException("Failed to determine already accepted commits.", e);
    }
    logDebug("Found {} existing heads", alreadyAccepted.size());
    return alreadyAccepted;
}
#end_block

#method_before
public BatchUpdate addOp(Change.Id id, Op op) {
    checkArgument(!(op instanceof InsertChangeOp), "use insertChange");
    ops.put(id, op);
    return this;
}
#method_after
public BatchUpdate addOp(Change.Id id, Op op) {
    checkArgument(!(op instanceof InsertChangeOp), "use insertChange");
    checkNotNull(op);
    ops.put(id, op);
    return this;
}
#end_block

#method_before
private void executeChangeOps(boolean parallel) throws UpdateException, RestApiException {
    ListeningExecutorService executor = parallel ? changeUpdateExector : MoreExecutors.newDirectExecutorService();
    List<ChangeTask> tasks = new ArrayList<>(ops.keySet().size());
    try {
        if (notesMigration.commitChangeWrites() && repo != null) {
            // A NoteDb change may have been rebuilt since the repo was originally
            // opened, so make sure we see that.
            repo.scanForRepoChanges();
        }
        if (!ops.isEmpty() && notesMigration.failChangeWrites()) {
            // this is a programmer error.
            throw new OrmException(NoteDbUpdateManager.CHANGES_READ_ONLY);
        }
        List<ListenableFuture<?>> futures = new ArrayList<>(ops.keySet().size());
        for (Map.Entry<Change.Id, Collection<Op>> e : ops.asMap().entrySet()) {
            ChangeTask task = new ChangeTask(e.getKey(), e.getValue(), Thread.currentThread());
            tasks.add(task);
            futures.add(executor.submit(task));
        }
        long startNanos = System.nanoTime();
        Futures.allAsList(futures).get();
        long elapsedNanos = System.nanoTime() - startNanos;
        if (elapsedNanos > logThresholdNanos && log.isDebugEnabled()) {
            log.debug("Slow change update", new SlowUpdateException("Slow change update (%d ms) to %s for %s", NANOSECONDS.toMillis(elapsedNanos), project, ops.keySet()));
        }
        if (notesMigration.commitChangeWrites()) {
            startNanos = System.nanoTime();
            executeNoteDbUpdates(tasks);
            elapsedNanos = System.nanoTime() - startNanos;
            if (elapsedNanos > logThresholdNanos && log.isDebugEnabled()) {
                log.debug("Slow NoteDb update", new SlowUpdateException("Slow NoteDb update (%d ms) to %s for %s", NANOSECONDS.toMillis(elapsedNanos), project, ops.keySet()));
            }
        }
    } catch (ExecutionException | InterruptedException e) {
        Throwables.propagateIfInstanceOf(e.getCause(), UpdateException.class);
        Throwables.propagateIfInstanceOf(e.getCause(), RestApiException.class);
        throw new UpdateException(e);
    } catch (OrmException | IOException e) {
        throw new UpdateException(e);
    }
    // Reindex changes.
    for (ChangeTask task : tasks) {
        if (task.deleted) {
            indexFutures.add(indexer.deleteAsync(task.id));
        } else if (task.dirty) {
            indexFutures.add(indexer.indexAsync(project, task.id));
        }
    }
}
#method_after
private void executeChangeOps(boolean parallel) throws UpdateException, RestApiException {
    ListeningExecutorService executor = parallel ? changeUpdateExector : MoreExecutors.newDirectExecutorService();
    List<ChangeTask> tasks = new ArrayList<>(ops.keySet().size());
    try {
        if (notesMigration.commitChangeWrites() && repo != null) {
            // A NoteDb change may have been rebuilt since the repo was originally
            // opened, so make sure we see that.
            repo.scanForRepoChanges();
        }
        if (!ops.isEmpty() && notesMigration.failChangeWrites()) {
            // this is a programmer error.
            throw new OrmException(NoteDbUpdateManager.CHANGES_READ_ONLY);
        }
        List<ListenableFuture<?>> futures = new ArrayList<>(ops.keySet().size());
        for (Map.Entry<Change.Id, Collection<Op>> e : ops.asMap().entrySet()) {
            ChangeTask task = new ChangeTask(e.getKey(), e.getValue(), Thread.currentThread());
            tasks.add(task);
            futures.add(executor.submit(task));
        }
        long startNanos = System.nanoTime();
        Futures.allAsList(futures).get();
        maybeLogSlowUpdate(startNanos, "change");
        if (notesMigration.commitChangeWrites()) {
            startNanos = System.nanoTime();
            executeNoteDbUpdates(tasks);
            maybeLogSlowUpdate(startNanos, "NoteDb");
        }
    } catch (ExecutionException | InterruptedException e) {
        Throwables.propagateIfInstanceOf(e.getCause(), UpdateException.class);
        Throwables.propagateIfInstanceOf(e.getCause(), RestApiException.class);
        throw new UpdateException(e);
    } catch (OrmException | IOException e) {
        throw new UpdateException(e);
    }
    // Reindex changes.
    for (ChangeTask task : tasks) {
        if (task.deleted) {
            indexFutures.add(indexer.deleteAsync(task.id));
        } else if (task.dirty) {
            indexFutures.add(indexer.indexAsync(project, task.id));
        }
    }
}
#end_block

#method_before
@Test
public void addGroupAsReviewer() throws Exception {
    // Set up two groups, one that is too large too add as reviewer, and one
    // that is too large to add without confirmation.
    String largeGroup = createGroup("largeGroup");
    String mediumGroup = createGroup("mediumGroup");
    int largeGroupSize = PostReviewers.DEFAULT_MAX_REVIEWERS + 1;
    int mediumGroupSize = PostReviewers.DEFAULT_MAX_REVIEWERS_WITHOUT_CHECK + 1;
    List<TestAccount> users = createAccounts(largeGroupSize, "addGroupAsReviewer");
    List<String> largeGroupUsernames = new ArrayList<>(mediumGroupSize);
    for (TestAccount u : users) {
        largeGroupUsernames.add(u.username);
    }
    List<String> mediumGroupUsernames = largeGroupUsernames.subList(0, mediumGroupSize);
    gApi.groups().id(largeGroup).addMembers(largeGroupUsernames.toArray(new String[largeGroupSize]));
    gApi.groups().id(mediumGroup).addMembers(mediumGroupUsernames.toArray(new String[mediumGroupSize]));
    // Attempt to add overly large group as reviewers.
    PushOneCommit.Result r = createChange();
    String changeId = r.getChangeId();
    AddReviewerResult result = addReviewer(changeId, largeGroup);
    assertThat(result.reviewer).isEqualTo(largeGroup);
    assertThat(result.confirm).isNull();
    assertThat(result.error).contains("has too many members to add them all as reviewers");
    assertThat(result.reviewers).isNull();
    // Attempt to add medium group without confirmation.
    result = addReviewer(changeId, mediumGroup);
    assertThat(result.reviewer).isEqualTo(mediumGroup);
    assertThat(result.confirm).isTrue();
    assertThat(result.error).contains("has " + mediumGroupSize + " members. Do you want to add them" + " all as reviewers?");
    assertThat(result.reviewers).isNull();
    // Add medium group with confirmation.
    AddReviewerInput in = new AddReviewerInput();
    in.reviewer = mediumGroup;
    in.confirmed = true;
    result = addReviewer(changeId, in);
    assertThat(result.reviewer).isEqualTo(mediumGroup);
    assertThat(result.confirm).isNull();
    assertThat(result.error).isNull();
    assertThat(result.reviewers).hasSize(mediumGroupSize);
    // Verify that group members were added as reviewers.
    ChangeInfo c = gApi.changes().id(r.getChangeId()).get();
    assertReviewers(c, notesMigration.readChanges() ? REVIEWER : CC, users.subList(0, mediumGroupSize));
}
#method_after
@Test
public void addGroupAsReviewer() throws Exception {
    // Set up two groups, one that is too large too add as reviewer, and one
    // that is too large to add without confirmation.
    String largeGroup = createGroup("largeGroup");
    String mediumGroup = createGroup("mediumGroup");
    int largeGroupSize = PostReviewers.DEFAULT_MAX_REVIEWERS + 1;
    int mediumGroupSize = PostReviewers.DEFAULT_MAX_REVIEWERS_WITHOUT_CHECK + 1;
    List<TestAccount> users = createAccounts(largeGroupSize, "addGroupAsReviewer");
    List<String> largeGroupUsernames = new ArrayList<>(mediumGroupSize);
    for (TestAccount u : users) {
        largeGroupUsernames.add(u.username);
    }
    List<String> mediumGroupUsernames = largeGroupUsernames.subList(0, mediumGroupSize);
    gApi.groups().id(largeGroup).addMembers(largeGroupUsernames.toArray(new String[largeGroupSize]));
    gApi.groups().id(mediumGroup).addMembers(mediumGroupUsernames.toArray(new String[mediumGroupSize]));
    // Attempt to add overly large group as reviewers.
    PushOneCommit.Result r = createChange();
    String changeId = r.getChangeId();
    AddReviewerResult result = addReviewer(changeId, largeGroup);
    assertThat(result.input).isEqualTo(largeGroup);
    assertThat(result.confirm).isNull();
    assertThat(result.error).contains("has too many members to add them all as reviewers");
    assertThat(result.reviewers).isNull();
    // Attempt to add medium group without confirmation.
    result = addReviewer(changeId, mediumGroup);
    assertThat(result.input).isEqualTo(mediumGroup);
    assertThat(result.confirm).isTrue();
    assertThat(result.error).contains("has " + mediumGroupSize + " members. Do you want to add them" + " all as reviewers?");
    assertThat(result.reviewers).isNull();
    // Add medium group with confirmation.
    AddReviewerInput in = new AddReviewerInput();
    in.reviewer = mediumGroup;
    in.confirmed = true;
    result = addReviewer(changeId, in);
    assertThat(result.input).isEqualTo(mediumGroup);
    assertThat(result.confirm).isNull();
    assertThat(result.error).isNull();
    assertThat(result.reviewers).hasSize(mediumGroupSize);
    // Verify that group members were added as reviewers.
    ChangeInfo c = gApi.changes().id(r.getChangeId()).get();
    assertReviewers(c, notesMigration.readChanges() ? REVIEWER : CC, users.subList(0, mediumGroupSize));
}
#end_block

#method_before
@Test
public void addCcAccount() throws Exception {
    TestTimeUtil.resetWithClockStep(1, SECONDS);
    sender.clear();
    PushOneCommit.Result r = createChange();
    String changeId = r.getChangeId();
    AddReviewerInput in = new AddReviewerInput();
    in.reviewer = user.email;
    in.state = CC;
    AddReviewerResult result = addReviewer(changeId, in);
    assertThat(result.reviewer).isEqualTo(user.email);
    assertThat(result.confirm).isNull();
    assertThat(result.error).isNull();
    ChangeInfo c = gApi.changes().id(r.getChangeId()).get();
    if (notesMigration.readChanges()) {
        assertThat(result.reviewers).isNull();
        assertThat(result.ccs).hasSize(1);
        AccountInfo ai = result.ccs.get(0);
        assertThat(ai._accountId).isEqualTo(user.id.get());
        assertReviewers(c, CC, user);
    } else {
        assertThat(result.ccs).isNull();
        assertThat(result.reviewers).hasSize(1);
        AccountInfo ai = result.reviewers.get(0);
        assertThat(ai._accountId).isEqualTo(user.id.get());
        assertReviewers(c, CC, user);
    }
    // Verify email was sent to CCed account.
    List<Message> messages = sender.getMessages();
    assertThat(messages).hasSize(1);
    Message m = messages.get(0);
    assertThat(m.rcpt()).containsExactly(user.emailAddress);
    if (notesMigration.readChanges()) {
        assertThat(m.body()).contains(admin.fullName + " has uploaded a new change for review.");
    } else {
        assertThat(m.body()).contains("Hello " + user.fullName + ",\n");
        assertThat(m.body()).contains("I'd like you to do a code review.");
    }
}
#method_after
@Test
public void addCcAccount() throws Exception {
    PushOneCommit.Result r = createChange();
    String changeId = r.getChangeId();
    AddReviewerInput in = new AddReviewerInput();
    in.reviewer = user.email;
    in.state = CC;
    AddReviewerResult result = addReviewer(changeId, in);
    assertThat(result.input).isEqualTo(user.email);
    assertThat(result.confirm).isNull();
    assertThat(result.error).isNull();
    ChangeInfo c = gApi.changes().id(r.getChangeId()).get();
    if (notesMigration.readChanges()) {
        assertThat(result.reviewers).isNull();
        assertThat(result.ccs).hasSize(1);
        AccountInfo ai = result.ccs.get(0);
        assertThat(ai._accountId).isEqualTo(user.id.get());
        assertReviewers(c, CC, user);
    } else {
        assertThat(result.ccs).isNull();
        assertThat(result.reviewers).hasSize(1);
        AccountInfo ai = result.reviewers.get(0);
        assertThat(ai._accountId).isEqualTo(user.id.get());
        assertReviewers(c, CC, user);
    }
    // Verify email was sent to CCed account.
    List<Message> messages = sender.getMessages();
    assertThat(messages).hasSize(1);
    Message m = messages.get(0);
    assertThat(m.rcpt()).containsExactly(user.emailAddress);
    if (notesMigration.readChanges()) {
        assertThat(m.body()).contains(admin.fullName + " has uploaded a new change for review.");
    } else {
        assertThat(m.body()).contains("Hello " + user.fullName + ",\n");
        assertThat(m.body()).contains("I'd like you to do a code review.");
    }
}
#end_block

#method_before
@Test
public void addCcGroup() throws Exception {
    List<TestAccount> users = createAccounts(6, "addCcGroup");
    List<String> usernames = new ArrayList<>(6);
    for (TestAccount u : users) {
        usernames.add(u.username);
    }
    List<TestAccount> firstUsers = users.subList(0, 3);
    List<String> firstUsernames = usernames.subList(0, 3);
    TestTimeUtil.resetWithClockStep(1, SECONDS);
    sender.clear();
    PushOneCommit.Result r = createChange();
    String changeId = r.getChangeId();
    AddReviewerInput in = new AddReviewerInput();
    in.reviewer = createGroup("cc1");
    in.state = CC;
    gApi.groups().id(in.reviewer).addMembers(firstUsernames.toArray(new String[firstUsernames.size()]));
    AddReviewerResult result = addReviewer(changeId, in);
    assertThat(result.reviewer).isEqualTo(in.reviewer);
    assertThat(result.confirm).isNull();
    assertThat(result.error).isNull();
    if (notesMigration.readChanges()) {
        assertThat(result.reviewers).isNull();
    } else {
        assertThat(result.ccs).isNull();
    }
    ChangeInfo c = gApi.changes().id(r.getChangeId()).get();
    assertReviewers(c, CC, firstUsers);
    // Verify emails were sent to each of the group's accounts.
    List<Message> messages = sender.getMessages();
    assertThat(messages).hasSize(1);
    Message m = messages.get(0);
    List<Address> expectedAddresses = new ArrayList<>(firstUsers.size());
    for (TestAccount u : firstUsers) {
        expectedAddresses.add(u.emailAddress);
    }
    assertThat(m.rcpt()).containsExactlyElementsIn(expectedAddresses);
    // CC a group that overlaps with some existing reviewers and CCed accounts.
    TestAccount reviewer = accounts.create(name("reviewer"), "addCcGroup-reviewer@example.com", "Reviewer");
    result = addReviewer(changeId, reviewer.username);
    assertThat(result.error).isNull();
    sender.clear();
    in.reviewer = createGroup("cc2");
    gApi.groups().id(in.reviewer).addMembers(usernames.toArray(new String[usernames.size()]));
    gApi.groups().id(in.reviewer).addMembers(reviewer.username);
    result = addReviewer(changeId, in);
    assertThat(result.reviewer).isEqualTo(in.reviewer);
    assertThat(result.confirm).isNull();
    assertThat(result.error).isNull();
    c = gApi.changes().id(r.getChangeId()).get();
    if (notesMigration.readChanges()) {
        assertThat(result.ccs).hasSize(3);
        assertThat(result.reviewers).isNull();
        assertReviewers(c, REVIEWER, reviewer);
        assertReviewers(c, CC, users);
    } else {
        assertThat(result.ccs).isNull();
        assertThat(result.reviewers).hasSize(3);
        List<TestAccount> expectedUsers = new ArrayList<>(users.size() + 2);
        expectedUsers.addAll(users);
        expectedUsers.add(reviewer);
        assertReviewers(c, CC, expectedUsers);
    }
    messages = sender.getMessages();
    assertThat(messages).hasSize(1);
    m = messages.get(0);
    expectedAddresses = new ArrayList<>(4);
    for (int i = 0; i < 3; i++) {
        expectedAddresses.add(users.get(users.size() - i - 1).emailAddress);
    }
    if (notesMigration.readChanges()) {
        expectedAddresses.add(reviewer.emailAddress);
    }
    assertThat(m.rcpt()).containsExactlyElementsIn(expectedAddresses);
}
#method_after
@Test
public void addCcGroup() throws Exception {
    List<TestAccount> users = createAccounts(6, "addCcGroup");
    List<String> usernames = new ArrayList<>(6);
    for (TestAccount u : users) {
        usernames.add(u.username);
    }
    List<TestAccount> firstUsers = users.subList(0, 3);
    List<String> firstUsernames = usernames.subList(0, 3);
    PushOneCommit.Result r = createChange();
    String changeId = r.getChangeId();
    AddReviewerInput in = new AddReviewerInput();
    in.reviewer = createGroup("cc1");
    in.state = CC;
    gApi.groups().id(in.reviewer).addMembers(firstUsernames.toArray(new String[firstUsernames.size()]));
    AddReviewerResult result = addReviewer(changeId, in);
    assertThat(result.input).isEqualTo(in.reviewer);
    assertThat(result.confirm).isNull();
    assertThat(result.error).isNull();
    if (notesMigration.readChanges()) {
        assertThat(result.reviewers).isNull();
    } else {
        assertThat(result.ccs).isNull();
    }
    ChangeInfo c = gApi.changes().id(r.getChangeId()).get();
    assertReviewers(c, CC, firstUsers);
    // Verify emails were sent to each of the group's accounts.
    List<Message> messages = sender.getMessages();
    assertThat(messages).hasSize(1);
    Message m = messages.get(0);
    List<Address> expectedAddresses = new ArrayList<>(firstUsers.size());
    for (TestAccount u : firstUsers) {
        expectedAddresses.add(u.emailAddress);
    }
    assertThat(m.rcpt()).containsExactlyElementsIn(expectedAddresses);
    // CC a group that overlaps with some existing reviewers and CCed accounts.
    TestAccount reviewer = accounts.create(name("reviewer"), "addCcGroup-reviewer@example.com", "Reviewer");
    result = addReviewer(changeId, reviewer.username);
    assertThat(result.error).isNull();
    sender.clear();
    in.reviewer = createGroup("cc2");
    gApi.groups().id(in.reviewer).addMembers(usernames.toArray(new String[usernames.size()]));
    gApi.groups().id(in.reviewer).addMembers(reviewer.username);
    result = addReviewer(changeId, in);
    assertThat(result.input).isEqualTo(in.reviewer);
    assertThat(result.confirm).isNull();
    assertThat(result.error).isNull();
    c = gApi.changes().id(r.getChangeId()).get();
    if (notesMigration.readChanges()) {
        assertThat(result.ccs).hasSize(3);
        assertThat(result.reviewers).isNull();
        assertReviewers(c, REVIEWER, reviewer);
        assertReviewers(c, CC, users);
    } else {
        assertThat(result.ccs).isNull();
        assertThat(result.reviewers).hasSize(3);
        List<TestAccount> expectedUsers = new ArrayList<>(users.size() + 2);
        expectedUsers.addAll(users);
        expectedUsers.add(reviewer);
        assertReviewers(c, CC, expectedUsers);
    }
    messages = sender.getMessages();
    assertThat(messages).hasSize(1);
    m = messages.get(0);
    expectedAddresses = new ArrayList<>(4);
    for (int i = 0; i < 3; i++) {
        expectedAddresses.add(users.get(users.size() - i - 1).emailAddress);
    }
    if (notesMigration.readChanges()) {
        expectedAddresses.add(reviewer.emailAddress);
    }
    assertThat(m.rcpt()).containsExactlyElementsIn(expectedAddresses);
}
#end_block

#method_before
@Test
public void reviewAndAddReviewers() throws Exception {
    TestTimeUtil.resetWithClockStep(1, SECONDS);
    sender.clear();
    TestAccount observer = accounts.user2();
    PushOneCommit.Result r = createChange();
    ReviewInput input = ReviewInput.approve().reviewer(user.email).reviewer(observer.email, CC, false);
    ReviewResult result = review(r.getChangeId(), r.getCommit().name(), input);
    assertThat(result.labels).isNotNull();
    assertThat(result.reviewers).isNotNull();
    assertThat(result.reviewers).hasSize(2);
    // Verify reviewer and CC were added. If not in NoteDb read mode, both
    // parties will be returned as CCed.
    ChangeInfo c = gApi.changes().id(r.getChangeId()).get();
    if (notesMigration.readChanges()) {
        assertReviewers(c, REVIEWER, admin, user);
        assertReviewers(c, CC, observer);
    } else {
        // In legacy mode, change owner should be the only reviewer.
        assertReviewers(c, REVIEWER, admin);
        assertReviewers(c, CC, user, observer);
    }
    // Verify emails were sent to added reviewers.
    List<Message> messages = sender.getMessages();
    assertThat(messages).hasSize(3);
    // First email to user.
    Message m = messages.get(0);
    assertThat(m.rcpt()).containsExactly(user.emailAddress);
    assertThat(m.body()).contains("Hello " + user.fullName + ",\n");
    assertThat(m.body()).contains("I'd like you to do a code review.");
    assertThat(m.body()).contains("Change subject: " + PushOneCommit.SUBJECT + "\n");
    // Second email to reviewer and observer.
    m = messages.get(1);
    if (notesMigration.readChanges()) {
        assertThat(m.rcpt()).containsExactly(user.emailAddress, observer.emailAddress);
        assertThat(m.body()).contains(admin.fullName + " has uploaded a new change for review.");
    } else {
        assertThat(m.rcpt()).containsExactly(observer.emailAddress);
        assertThat(m.body()).contains("Hello " + observer.fullName + ",\n");
        assertThat(m.body()).contains("I'd like you to do a code review.");
    }
    // Third email is review to user and observer.
    m = messages.get(2);
    assertThat(m.rcpt()).containsExactly(user.emailAddress, observer.emailAddress);
    assertThat(m.body()).contains(admin.fullName + " has posted comments on this change.");
    assertThat(m.body()).contains("Change subject: " + PushOneCommit.SUBJECT + "\n");
    assertThat(m.body()).contains("Patch Set 1: Code-Review+2\n");
}
#method_after
@Test
public void reviewAndAddReviewers() throws Exception {
    TestAccount observer = accounts.user2();
    PushOneCommit.Result r = createChange();
    ReviewInput input = ReviewInput.approve().reviewer(user.email).reviewer(observer.email, CC, false);
    ReviewResult result = review(r.getChangeId(), r.getCommit().name(), input);
    assertThat(result.labels).isNotNull();
    assertThat(result.reviewers).isNotNull();
    assertThat(result.reviewers).hasSize(2);
    // Verify reviewer and CC were added. If not in NoteDb read mode, both
    // parties will be returned as CCed.
    ChangeInfo c = gApi.changes().id(r.getChangeId()).get();
    if (notesMigration.readChanges()) {
        assertReviewers(c, REVIEWER, admin, user);
        assertReviewers(c, CC, observer);
    } else {
        // In legacy mode, change owner should be the only reviewer.
        assertReviewers(c, REVIEWER, admin);
        assertReviewers(c, CC, user, observer);
    }
    // Verify emails were sent to added reviewers.
    List<Message> messages = sender.getMessages();
    assertThat(messages).hasSize(3);
    // First email to user.
    Message m = messages.get(0);
    assertThat(m.rcpt()).containsExactly(user.emailAddress);
    assertThat(m.body()).contains("Hello " + user.fullName + ",\n");
    assertThat(m.body()).contains("I'd like you to do a code review.");
    assertThat(m.body()).contains("Change subject: " + PushOneCommit.SUBJECT + "\n");
    // Second email to reviewer and observer.
    m = messages.get(1);
    if (notesMigration.readChanges()) {
        assertThat(m.rcpt()).containsExactly(user.emailAddress, observer.emailAddress);
        assertThat(m.body()).contains(admin.fullName + " has uploaded a new change for review.");
    } else {
        assertThat(m.rcpt()).containsExactly(observer.emailAddress);
        assertThat(m.body()).contains("Hello " + observer.fullName + ",\n");
        assertThat(m.body()).contains("I'd like you to do a code review.");
    }
    // Third email is review to user and observer.
    m = messages.get(2);
    assertThat(m.rcpt()).containsExactly(user.emailAddress, observer.emailAddress);
    assertThat(m.body()).contains(admin.fullName + " has posted comments on this change.");
    assertThat(m.body()).contains("Change subject: " + PushOneCommit.SUBJECT + "\n");
    assertThat(m.body()).contains("Patch Set 1: Code-Review+2\n");
}
#end_block

#method_before
private static void assertReviewers(ChangeInfo c, ReviewerState reviewerState, Iterable<TestAccount> accounts) throws Exception {
    Collection<AccountInfo> actualAccounts = c.reviewers.get(reviewerState);
    assertThat(actualAccounts).isNotNull();
    List<Integer> actualAccountIds = new ArrayList<>(actualAccounts.size());
    for (AccountInfo account : actualAccounts) {
        actualAccountIds.add(account._accountId);
    }
    List<Integer> expectedAccountIds = new ArrayList<>();
    for (TestAccount account : accounts) {
        expectedAccountIds.add(account.getId().get());
    }
    assertThat(actualAccountIds).containsExactlyElementsIn(expectedAccountIds);
}
#method_after
private static void assertReviewers(ChangeInfo c, ReviewerState reviewerState, Iterable<TestAccount> accounts) throws Exception {
    Collection<AccountInfo> actualAccounts = c.reviewers.get(reviewerState);
    if (actualAccounts == null) {
        assertThat(accounts.iterator().hasNext()).isFalse();
        return;
    }
    assertThat(actualAccounts).isNotNull();
    List<Integer> actualAccountIds = new ArrayList<>(actualAccounts.size());
    for (AccountInfo account : actualAccounts) {
        actualAccountIds.add(account._accountId);
    }
    List<Integer> expectedAccountIds = new ArrayList<>();
    for (TestAccount account : accounts) {
        expectedAccountIds.add(account.getId().get());
    }
    assertThat(actualAccountIds).containsExactlyElementsIn(expectedAccountIds);
}
#end_block

#method_before
@Override
public AddReviewerResult apply(ChangeResource rsrc, AddReviewerInput input) throws IOException, OrmException, RestApiException, UpdateException {
    if (input.reviewer == null) {
        throw new BadRequestException("missing reviewer field");
    }
    Addition addition = prepareApplication(rsrc, input);
    addition.apply(rsrc);
    return addition.result;
}
#method_after
@Override
public AddReviewerResult apply(ChangeResource rsrc, AddReviewerInput input) throws IOException, OrmException, RestApiException, UpdateException {
    if (input.reviewer == null) {
        throw new BadRequestException("missing reviewer field");
    }
    Addition addition = prepareApplication(rsrc, input);
    if (addition.op == null) {
        return addition.result;
    }
    try (BatchUpdate bu = batchUpdateFactory.create(dbProvider.get(), rsrc.getProject(), rsrc.getUser(), TimeUtil.nowTs())) {
        Change.Id id = rsrc.getChange().getId();
        bu.addOp(id, addition.op);
        bu.execute();
        addition.gatherResults();
    }
    return addition.result;
}
#end_block

#method_before
public Addition prepareApplication(ChangeResource rsrc, AddReviewerInput input) throws OrmException, RestApiException {
    try {
        Account.Id accountId = accounts.parse(input.reviewer).getAccountId();
        return putAccount(input.reviewer, reviewerFactory.create(rsrc, accountId), input.state());
    } catch (UnprocessableEntityException e) {
        try {
            return putGroup(rsrc, input);
        } catch (UnprocessableEntityException e2) {
            throw new UnprocessableEntityException(MessageFormat.format(ChangeMessages.get().reviewerNotFound, input.reviewer));
        }
    }
}
#method_after
public Addition prepareApplication(ChangeResource rsrc, AddReviewerInput input) throws OrmException, RestApiException, IOException {
    try {
        Account.Id accountId = accounts.parse(input.reviewer).getAccountId();
        return putAccount(input.reviewer, reviewerFactory.create(rsrc, accountId), input.state());
    } catch (UnprocessableEntityException e) {
        try {
            return putGroup(rsrc, input);
        } catch (UnprocessableEntityException e2) {
            throw new UnprocessableEntityException(MessageFormat.format(ChangeMessages.get().reviewerNotFound, input.reviewer));
        }
    }
}
#end_block

#method_before
private Addition putGroup(ChangeResource rsrc, AddReviewerInput input) throws RestApiException, OrmException {
    GroupDescription.Basic group = groupsCollection.parseInternal(input.reviewer);
    if (!isLegalReviewerGroup(group.getGroupUUID())) {
        return fail(input.reviewer, MessageFormat.format(ChangeMessages.get().groupIsNotAllowed, group.getName()));
    }
    Map<Account.Id, ChangeControl> reviewers = new HashMap<>();
    ChangeControl control = rsrc.getControl();
    Set<Account> members;
    try {
        members = groupMembersFactory.create(control.getUser()).listAccounts(group.getGroupUUID(), control.getProject().getNameKey());
    } catch (NoSuchGroupException e) {
        throw new UnprocessableEntityException(e.getMessage());
    } catch (NoSuchProjectException e) {
        throw new BadRequestException(e.getMessage());
    } catch (IOException e) {
        // TODO(logan): return error to client
        throw new UnprocessableEntityException(e.getMessage());
    }
    // if maxAllowed is set to 0, it is allowed to add any number of
    // reviewers
    int maxAllowed = cfg.getInt("addreviewer", "maxAllowed", DEFAULT_MAX_REVIEWERS);
    if (maxAllowed > 0 && members.size() > maxAllowed) {
        return fail(input.reviewer, MessageFormat.format(ChangeMessages.get().groupHasTooManyMembers, group.getName()));
    }
    // if maxWithoutCheck is set to 0, we never ask for confirmation
    int maxWithoutConfirmation = cfg.getInt("addreviewer", "maxWithoutConfirmation", DEFAULT_MAX_REVIEWERS_WITHOUT_CHECK);
    if (!input.confirmed() && maxWithoutConfirmation > 0 && members.size() > maxWithoutConfirmation) {
        return fail(input.reviewer, true, MessageFormat.format(ChangeMessages.get().groupManyMembersConfirmation, group.getName(), members.size()));
    }
    for (Account member : members) {
        if (isValidReviewer(member, control)) {
            reviewers.put(member.getId(), control);
        }
    }
    return new Addition(input.reviewer, rsrc, reviewers, input.state());
}
#method_after
private Addition putGroup(ChangeResource rsrc, AddReviewerInput input) throws RestApiException, OrmException, IOException {
    GroupDescription.Basic group = groupsCollection.parseInternal(input.reviewer);
    if (!isLegalReviewerGroup(group.getGroupUUID())) {
        return fail(input.reviewer, MessageFormat.format(ChangeMessages.get().groupIsNotAllowed, group.getName()));
    }
    Map<Account.Id, ChangeControl> reviewers = new HashMap<>();
    ChangeControl control = rsrc.getControl();
    Set<Account> members;
    try {
        members = groupMembersFactory.create(control.getUser()).listAccounts(group.getGroupUUID(), control.getProject().getNameKey());
    } catch (NoSuchGroupException e) {
        throw new UnprocessableEntityException(e.getMessage());
    } catch (NoSuchProjectException e) {
        throw new BadRequestException(e.getMessage());
    }
    // if maxAllowed is set to 0, it is allowed to add any number of
    // reviewers
    int maxAllowed = cfg.getInt("addreviewer", "maxAllowed", DEFAULT_MAX_REVIEWERS);
    if (maxAllowed > 0 && members.size() > maxAllowed) {
        return fail(input.reviewer, MessageFormat.format(ChangeMessages.get().groupHasTooManyMembers, group.getName()));
    }
    // if maxWithoutCheck is set to 0, we never ask for confirmation
    int maxWithoutConfirmation = cfg.getInt("addreviewer", "maxWithoutConfirmation", DEFAULT_MAX_REVIEWERS_WITHOUT_CHECK);
    if (!input.confirmed() && maxWithoutConfirmation > 0 && members.size() > maxWithoutConfirmation) {
        return fail(input.reviewer, true, MessageFormat.format(ChangeMessages.get().groupManyMembersConfirmation, group.getName(), members.size()));
    }
    for (Account member : members) {
        if (isValidReviewer(member, control)) {
            reviewers.put(member.getId(), control);
        }
    }
    return new Addition(input.reviewer, rsrc, reviewers, input.state());
}
#end_block

#method_before
@Override
public void postUpdate(Context ctx) throws Exception {
    if (addedCCs != null) {
        emailCCs(rsrc.getChange(), addedCCs);
    }
    if (addedReviewers != null) {
        emailReviewers(rsrc.getChange(), addedReviewers);
        if (!addedReviewers.isEmpty()) {
            for (PatchSetApproval psa : addedReviewers) {
                Account account = accountCache.get(psa.getAccountId()).getAccount();
                reviewerAdded.fire(rsrc.getChange(), patchSet, account);
            }
        }
    }
}
#method_after
@Override
public void postUpdate(Context ctx) throws Exception {
    if (addedReviewers != null || addedCCs != null) {
        if (addedReviewers == null) {
            addedReviewers = new ArrayList<>();
        }
        if (addedCCs == null) {
            addedCCs = new ArrayList<>();
        }
        emailReviewers(rsrc.getChange(), addedReviewers, addedCCs);
        if (!addedReviewers.isEmpty()) {
            for (PatchSetApproval psa : addedReviewers) {
                Account account = accountCache.get(psa.getAccountId()).getAccount();
                reviewerAdded.fire(rsrc.getChange(), patchSet, account, ctx.getAccount(), ctx.getWhen());
            }
        }
    }
}
#end_block

#method_before
private void emailReviewers(Change change, List<PatchSetApproval> added) {
    if (added.isEmpty()) {
        return;
    }
    // Email the reviewers
    // 
    // The user knows they added themselves, don't bother emailing them.
    List<Account.Id> toMail = Lists.newArrayListWithCapacity(added.size());
    Account.Id userId = user.get().getAccountId();
    for (PatchSetApproval psa : added) {
        if (!psa.getAccountId().equals(userId)) {
            toMail.add(psa.getAccountId());
        }
    }
    if (!toMail.isEmpty()) {
        try {
            AddReviewerSender cm = addReviewerSenderFactory.create(change.getProject(), change.getId());
            cm.setFrom(userId);
            cm.addReviewers(toMail);
            cm.send();
        } catch (Exception err) {
            log.error("Cannot send email to new reviewers of change " + change.getId(), err);
        }
    }
}
#method_after
private void emailReviewers(Change change, List<PatchSetApproval> added, Collection<Account.Id> copied) {
    if (added.isEmpty() && copied.isEmpty()) {
        return;
    }
    // Email the reviewers
    // 
    // The user knows they added themselves, don't bother emailing them.
    List<Account.Id> toMail = Lists.newArrayListWithCapacity(added.size());
    Account.Id userId = user.get().getAccountId();
    for (PatchSetApproval psa : added) {
        if (!psa.getAccountId().equals(userId)) {
            toMail.add(psa.getAccountId());
        }
    }
    List<Account.Id> toCopy = Lists.newArrayListWithCapacity(copied.size());
    for (Account.Id id : copied) {
        if (!id.equals(userId)) {
            toCopy.add(id);
        }
    }
    if (toMail.isEmpty() && toCopy.isEmpty()) {
        return;
    }
    try {
        AddReviewerSender cm = addReviewerSenderFactory.create(change.getProject(), change.getId());
        cm.setFrom(userId);
        cm.addReviewers(toMail);
        cm.addExtraCC(toCopy);
        cm.send();
    } catch (Exception err) {
        log.error("Cannot send email to new reviewers of change " + change.getId(), err);
    }
}
#end_block

#method_before
@Override
public ReviewResult apply(RevisionResource revision, ReviewInput input) throws RestApiException, UpdateException, OrmException {
    return apply(revision, input, TimeUtil.nowTs());
}
#method_after
@Override
public ReviewResult apply(RevisionResource revision, ReviewInput input) throws RestApiException, UpdateException, OrmException, IOException {
    return apply(revision, input, TimeUtil.nowTs());
}
#end_block

#method_before
public ReviewResult apply(RevisionResource revision, ReviewInput input, Timestamp ts) throws RestApiException, UpdateException, OrmException {
    // Respect timestamp, but truncate at change created-on time.
    ts = Ordering.natural().max(ts, revision.getChange().getCreatedOn());
    if (revision.getEdit().isPresent()) {
        throw new ResourceConflictException("cannot post review on edit");
    }
    if (input.onBehalfOf != null) {
        revision = onBehalfOf(revision, input);
    }
    if (input.labels != null) {
        checkLabels(revision, input.strictLabels, input.labels);
    }
    if (input.comments != null) {
        checkComments(revision, input.comments);
    }
    if (input.notify == null) {
        log.warn("notify = null; assuming notify = NONE");
        input.notify = NotifyHandling.NONE;
    }
    Map<String, AddReviewerResult> reviewerJsonResults = null;
    List<PostReviewers.Addition> reviewerResults = Lists.newArrayList();
    boolean hasError = false;
    boolean confirm = false;
    if (input.reviewers != null) {
        reviewerJsonResults = Maps.newHashMap();
        for (AddReviewerInput reviewerInput : input.reviewers) {
            PostReviewers.Addition result = postReviewers.prepareApplication(revision.getChangeResource(), reviewerInput);
            reviewerJsonResults.put(reviewerInput.reviewer, result.result);
            if (result.result.error != null) {
                hasError = true;
                continue;
            }
            if (result.result.confirm != null) {
                confirm = true;
                continue;
            }
            reviewerResults.add(result);
        // TODO(logan): return new PatchSetApprovals
        }
    }
    ReviewResult output = new ReviewResult();
    output.reviewers = reviewerJsonResults;
    if (hasError || confirm) {
        return output;
    }
    output.labels = input.labels;
    try (BatchUpdate bu = batchUpdateFactory.create(db.get(), revision.getChange().getProject(), revision.getUser(), ts)) {
        // updated set of reviewers.
        for (PostReviewers.Addition reviewerResult : reviewerResults) {
            bu.addOp(revision.getChange().getId(), reviewerResult.op);
        }
        bu.addOp(revision.getChange().getId(), new Op(revision.getPatchSet().getId(), input));
        bu.execute();
        for (PostReviewers.Addition reviewerResult : reviewerResults) {
            // Generate result details and fill AccountLoader. This occurs outside
            // the Op because the accounts are in a different table.
            PostReviewers.Op op = reviewerResult.op;
            if (migration.readChanges() && op.state == ReviewerState.CC) {
                reviewerResult.result.ccs = Lists.newArrayListWithCapacity(op.addedCCs.size());
                for (Account.Id accountId : op.addedCCs) {
                    reviewerResult.result.ccs.add(reviewerJson.format(new ReviewerInfo(accountId.get()), op.reviewers.get(accountId)));
                }
                accountLoaderFactory.create(true).fill(reviewerResult.result.ccs);
            } else {
                reviewerResult.result.reviewers = Lists.newArrayListWithCapacity(op.addedReviewers.size());
                for (PatchSetApproval psa : op.addedReviewers) {
                    // New reviewers have value 0, don't bother normalizing.
                    reviewerResult.result.reviewers.add(reviewerJson.format(new ReviewerInfo(psa.getAccountId().get()), op.reviewers.get(psa.getAccountId()), ImmutableList.of(psa)));
                }
                accountLoaderFactory.create(true).fill(reviewerResult.result.reviewers);
            }
        }
    }
    return output;
}
#method_after
public ReviewResult apply(RevisionResource revision, ReviewInput input, Timestamp ts) throws RestApiException, UpdateException, OrmException, IOException {
    // Respect timestamp, but truncate at change created-on time.
    ts = Ordering.natural().max(ts, revision.getChange().getCreatedOn());
    if (revision.getEdit().isPresent()) {
        throw new ResourceConflictException("cannot post review on edit");
    }
    if (input.onBehalfOf != null) {
        revision = onBehalfOf(revision, input);
    }
    if (input.labels != null) {
        checkLabels(revision, input.strictLabels, input.labels);
    }
    if (input.comments != null) {
        checkComments(revision, input.comments);
    }
    if (input.notify == null) {
        log.warn("notify = null; assuming notify = NONE");
        input.notify = NotifyHandling.NONE;
    }
    Map<String, AddReviewerResult> reviewerJsonResults = null;
    List<PostReviewers.Addition> reviewerResults = Lists.newArrayList();
    boolean hasError = false;
    boolean confirm = false;
    if (input.reviewers != null) {
        reviewerJsonResults = Maps.newHashMap();
        for (AddReviewerInput reviewerInput : input.reviewers) {
            PostReviewers.Addition result = postReviewers.prepareApplication(revision.getChangeResource(), reviewerInput);
            reviewerJsonResults.put(reviewerInput.reviewer, result.result);
            if (result.result.error != null) {
                hasError = true;
                continue;
            }
            if (result.result.confirm != null) {
                confirm = true;
                continue;
            }
            reviewerResults.add(result);
        }
    }
    ReviewResult output = new ReviewResult();
    output.reviewers = reviewerJsonResults;
    if (hasError || confirm) {
        return output;
    }
    output.labels = input.labels;
    try (BatchUpdate bu = batchUpdateFactory.create(db.get(), revision.getChange().getProject(), revision.getUser(), ts)) {
        // updated set of reviewers.
        for (PostReviewers.Addition reviewerResult : reviewerResults) {
            bu.addOp(revision.getChange().getId(), reviewerResult.op);
        }
        bu.addOp(revision.getChange().getId(), new Op(revision.getPatchSet().getId(), input));
        bu.execute();
        for (PostReviewers.Addition reviewerResult : reviewerResults) {
            reviewerResult.gatherResults();
        }
    }
    return output;
}
#end_block

#method_before
@Override
public boolean updateChange(ChangeContext ctx) throws OrmException, ResourceConflictException {
    user = ctx.getUser().asIdentifiedUser();
    notes = ctx.getNotes();
    ps = psUtil.get(ctx.getDb(), ctx.getNotes(), psId);
    boolean dirty = false;
    dirty |= insertComments(ctx);
    dirty |= updateLabels(ctx);
    dirty |= insertMessage(ctx);
    return dirty;
}
#method_after
@Override
public boolean updateChange(ChangeContext ctx) throws OrmException, ResourceConflictException {
    user = ctx.getIdentifiedUser();
    notes = ctx.getNotes();
    ps = psUtil.get(ctx.getDb(), ctx.getNotes(), psId);
    boolean dirty = false;
    dirty |= insertComments(ctx);
    dirty |= updateLabels(ctx);
    dirty |= insertMessage(ctx);
    return dirty;
}
#end_block

#method_before
@Test
public void addGroupAsReviewer() throws Exception {
    // Set up two groups, one that is too large too add as reviewer, and one
    // that is too large to add without confirmation.
    String largeGroup = createGroup("largeGroup");
    String mediumGroup = createGroup("mediumGroup");
    TestAccount[] users = new TestAccount[PostReviewers.DEFAULT_MAX_REVIEWERS + 1];
    String[] largeGroupUsernames = new String[PostReviewers.DEFAULT_MAX_REVIEWERS + 1];
    String[] mediumGroupUsernames = new String[PostReviewers.DEFAULT_MAX_REVIEWERS_WITHOUT_CHECK + 1];
    for (int i = 0; i < users.length; i++) {
        users[i] = accounts.create("u" + i, "u" + i + "@example.com", "Full Name " + i);
        largeGroupUsernames[i] = users[i].username;
        if (i < mediumGroupUsernames.length) {
            mediumGroupUsernames[i] = users[i].username;
        }
    }
    gApi.groups().id(largeGroup).addMembers(largeGroupUsernames);
    gApi.groups().id(mediumGroup).addMembers(mediumGroupUsernames);
    // Attempt to add overly large group as reviewers.
    PushOneCommit.Result r = createChange();
    String changeId = r.getChangeId();
    AddReviewerResult result = addReviewer(changeId, largeGroup);
    assertThat(result.reviewer).isEqualTo(largeGroup);
    assertThat(result.confirm).isNull();
    assertThat(result.error).contains("has too many members to add them all as reviewers");
    assertThat(result.reviewers).isNull();
    // Attempt to add medium group without confirmation.
    result = addReviewer(changeId, mediumGroup);
    assertThat(result.reviewer).isEqualTo(mediumGroup);
    assertThat(result.confirm).isTrue();
    assertThat(result.error).contains("has " + mediumGroupUsernames.length + " members. Do you want to add them all" + " as reviewers?");
    assertThat(result.reviewers).isNull();
    // Add medium group with confirmation.
    AddReviewerInput in = new AddReviewerInput();
    in.reviewer = mediumGroup;
    in.confirmed = true;
    result = addReviewer(changeId, in);
    assertThat(result.reviewer).isEqualTo(mediumGroup);
    assertThat(result.confirm).isNull();
    assertThat(result.error).isNull();
    assertThat(result.reviewers).hasSize(mediumGroupUsernames.length);
    // Verify that group members were added as reviewers.
    ChangeInfo c = gApi.changes().id(r.getChangeId()).get();
    assertReviewers(c, NoteDbMode.readWrite() ? REVIEWER : CC, Arrays.copyOf(users, mediumGroupUsernames.length));
}
#method_after
@Test
public void addGroupAsReviewer() throws Exception {
    // Set up two groups, one that is too large too add as reviewer, and one
    // that is too large to add without confirmation.
    String largeGroup = createGroup("largeGroup");
    String mediumGroup = createGroup("mediumGroup");
    int largeGroupSize = PostReviewers.DEFAULT_MAX_REVIEWERS + 1;
    int mediumGroupSize = PostReviewers.DEFAULT_MAX_REVIEWERS_WITHOUT_CHECK + 1;
    List<TestAccount> users = createAccounts(largeGroupSize, "addGroupAsReviewer");
    List<String> largeGroupUsernames = new ArrayList<>(mediumGroupSize);
    for (TestAccount u : users) {
        largeGroupUsernames.add(u.username);
    }
    List<String> mediumGroupUsernames = largeGroupUsernames.subList(0, mediumGroupSize);
    gApi.groups().id(largeGroup).addMembers(largeGroupUsernames.toArray(new String[largeGroupSize]));
    gApi.groups().id(mediumGroup).addMembers(mediumGroupUsernames.toArray(new String[mediumGroupSize]));
    // Attempt to add overly large group as reviewers.
    PushOneCommit.Result r = createChange();
    String changeId = r.getChangeId();
    AddReviewerResult result = addReviewer(changeId, largeGroup);
    assertThat(result.input).isEqualTo(largeGroup);
    assertThat(result.confirm).isNull();
    assertThat(result.error).contains("has too many members to add them all as reviewers");
    assertThat(result.reviewers).isNull();
    // Attempt to add medium group without confirmation.
    result = addReviewer(changeId, mediumGroup);
    assertThat(result.input).isEqualTo(mediumGroup);
    assertThat(result.confirm).isTrue();
    assertThat(result.error).contains("has " + mediumGroupSize + " members. Do you want to add them" + " all as reviewers?");
    assertThat(result.reviewers).isNull();
    // Add medium group with confirmation.
    AddReviewerInput in = new AddReviewerInput();
    in.reviewer = mediumGroup;
    in.confirmed = true;
    result = addReviewer(changeId, in);
    assertThat(result.input).isEqualTo(mediumGroup);
    assertThat(result.confirm).isNull();
    assertThat(result.error).isNull();
    assertThat(result.reviewers).hasSize(mediumGroupSize);
    // Verify that group members were added as reviewers.
    ChangeInfo c = gApi.changes().id(r.getChangeId()).get();
    assertReviewers(c, notesMigration.readChanges() ? REVIEWER : CC, users.subList(0, mediumGroupSize));
}
#end_block

#method_before
AddReviewerResult addReviewer(String changeId, String reviewer) throws Exception {
    AddReviewerInput in = new AddReviewerInput();
    in.reviewer = reviewer;
    return addReviewer(changeId, in);
}
#method_after
private AddReviewerResult addReviewer(String changeId, String reviewer) throws Exception {
    AddReviewerInput in = new AddReviewerInput();
    in.reviewer = reviewer;
    return addReviewer(changeId, in);
}
#end_block

#method_before
AddReviewerResult addReviewer(String changeId, AddReviewerInput in) throws Exception {
    RestResponse resp = adminRestSession.post("/changes/" + changeId + "/reviewers", in);
    return readContentFromJson(resp, AddReviewerResult.class);
}
#method_after
private AddReviewerResult addReviewer(String changeId, AddReviewerInput in) throws Exception {
    RestResponse resp = adminRestSession.post("/changes/" + changeId + "/reviewers", in);
    return readContentFromJson(resp, AddReviewerResult.class);
}
#end_block

#method_before
private static void assertReviewers(ChangeInfo c, ReviewerState reviewerState, TestAccount... accounts) throws Exception {
    Collection<AccountInfo> actualAccounts = c.reviewers.get(reviewerState);
    assertThat(actualAccounts).isNotNull();
    List<Integer> actualAccountIds = Lists.newArrayListWithCapacity(actualAccounts.size());
    for (AccountInfo account : actualAccounts) {
        actualAccountIds.add(account._accountId);
    }
    List<Integer> expectedAccountIds = Lists.newArrayListWithCapacity(accounts.length);
    for (TestAccount account : accounts) {
        expectedAccountIds.add(account.getId().get());
    }
    assertThat(actualAccountIds).containsExactlyElementsIn(expectedAccountIds);
}
#method_after
private static void assertReviewers(ChangeInfo c, ReviewerState reviewerState, TestAccount... accounts) throws Exception {
    List<TestAccount> accountList = new ArrayList<>(accounts.length);
    for (TestAccount a : accounts) {
        accountList.add(a);
    }
    assertReviewers(c, reviewerState, accountList);
}
#end_block

#method_before
private static void assertReviewers(ChangeInfo c, ReviewerState reviewerState, TestAccount... accounts) throws Exception {
    Collection<AccountInfo> actualAccounts = c.reviewers.get(reviewerState);
    assertThat(actualAccounts).isNotNull();
    List<Integer> actualAccountIds = Lists.newArrayListWithCapacity(actualAccounts.size());
    for (AccountInfo account : actualAccounts) {
        actualAccountIds.add(account._accountId);
    }
    List<Integer> expectedAccountIds = Lists.newArrayListWithCapacity(accounts.length);
    for (TestAccount account : accounts) {
        expectedAccountIds.add(account.getId().get());
    }
    assertThat(actualAccountIds).containsExactlyElementsIn(expectedAccountIds);
}
#method_after
private static void assertReviewers(ChangeInfo c, ReviewerState reviewerState, Iterable<TestAccount> accounts) throws Exception {
    Collection<AccountInfo> actualAccounts = c.reviewers.get(reviewerState);
    if (actualAccounts == null) {
        assertThat(accounts.iterator().hasNext()).isFalse();
        return;
    }
    assertThat(actualAccounts).isNotNull();
    List<Integer> actualAccountIds = new ArrayList<>(actualAccounts.size());
    for (AccountInfo account : actualAccounts) {
        actualAccountIds.add(account._accountId);
    }
    List<Integer> expectedAccountIds = new ArrayList<>();
    for (TestAccount account : accounts) {
        expectedAccountIds.add(account.getId().get());
    }
    assertThat(actualAccountIds).containsExactlyElementsIn(expectedAccountIds);
}
#end_block

#method_before
@Override
public AddReviewerResult apply(ChangeResource rsrc, AddReviewerInput input) throws UpdateException, OrmException, RestApiException, IOException {
    if (input.reviewer == null) {
        throw new BadRequestException("missing reviewer field");
    }
    try {
        Account.Id accountId = accounts.parse(input.reviewer).getAccountId();
        return putAccount(input.reviewer, reviewerFactory.create(rsrc, accountId), input.cc());
    } catch (UnprocessableEntityException e) {
        try {
            return putGroup(rsrc, input);
        } catch (UnprocessableEntityException e2) {
            throw new UnprocessableEntityException(MessageFormat.format(ChangeMessages.get().reviewerNotFound, input.reviewer));
        }
    }
}
#method_after
@Override
public AddReviewerResult apply(ChangeResource rsrc, AddReviewerInput input) throws UpdateException, OrmException, RestApiException, IOException {
    if (input.reviewer == null) {
        throw new BadRequestException("missing reviewer field");
    }
    try {
        Account.Id accountId = accounts.parse(input.reviewer).getAccountId();
        return putAccount(input.reviewer, reviewerFactory.create(rsrc, accountId), input.state());
    } catch (UnprocessableEntityException e) {
        try {
            return putGroup(rsrc, input);
        } catch (UnprocessableEntityException e2) {
            throw new UnprocessableEntityException(MessageFormat.format(ChangeMessages.get().reviewerNotFound, input.reviewer));
        }
    }
}
#end_block

#method_before
private AddReviewerResult putAccount(String reviewer, ReviewerResource rsrc, boolean cc) throws OrmException, UpdateException, RestApiException {
    Account member = rsrc.getReviewerUser().getAccount();
    ChangeControl control = rsrc.getReviewerControl();
    AddReviewerResult result = new AddReviewerResult(reviewer);
    if (isValidReviewer(member, control)) {
        addReviewers(rsrc.getChangeResource(), result, ImmutableMap.of(member.getId(), control), cc);
    }
    return result;
}
#method_after
private AddReviewerResult putAccount(String reviewer, ReviewerResource rsrc, ReviewerState state) throws OrmException, UpdateException, RestApiException {
    Account member = rsrc.getReviewerUser().getAccount();
    ChangeControl control = rsrc.getReviewerControl();
    AddReviewerResult result = new AddReviewerResult(reviewer);
    if (isValidReviewer(member, control)) {
        addReviewers(rsrc.getChangeResource(), result, ImmutableMap.of(member.getId(), control), state);
    }
    return result;
}
#end_block

#method_before
private AddReviewerResult putGroup(ChangeResource rsrc, AddReviewerInput input) throws UpdateException, RestApiException, OrmException, IOException {
    GroupDescription.Basic group = groupsCollection.parseInternal(input.reviewer);
    AddReviewerResult result = new AddReviewerResult(input.reviewer);
    if (!isLegalReviewerGroup(group.getGroupUUID())) {
        result.error = MessageFormat.format(ChangeMessages.get().groupIsNotAllowed, group.getName());
        return result;
    }
    Map<Account.Id, ChangeControl> reviewers = new HashMap<>();
    ChangeControl control = rsrc.getControl();
    Set<Account> members;
    try {
        members = groupMembersFactory.create(control.getUser()).listAccounts(group.getGroupUUID(), control.getProject().getNameKey());
    } catch (NoSuchGroupException e) {
        throw new UnprocessableEntityException(e.getMessage());
    } catch (NoSuchProjectException e) {
        throw new BadRequestException(e.getMessage());
    }
    // if maxAllowed is set to 0, it is allowed to add any number of
    // reviewers
    int maxAllowed = cfg.getInt("addreviewer", "maxAllowed", DEFAULT_MAX_REVIEWERS);
    if (maxAllowed > 0 && members.size() > maxAllowed) {
        result.error = MessageFormat.format(ChangeMessages.get().groupHasTooManyMembers, group.getName());
        return result;
    }
    // if maxWithoutCheck is set to 0, we never ask for confirmation
    int maxWithoutConfirmation = cfg.getInt("addreviewer", "maxWithoutConfirmation", DEFAULT_MAX_REVIEWERS_WITHOUT_CHECK);
    if (!input.confirmed() && maxWithoutConfirmation > 0 && members.size() > maxWithoutConfirmation) {
        result.confirm = true;
        result.error = MessageFormat.format(ChangeMessages.get().groupManyMembersConfirmation, group.getName(), members.size());
        return result;
    }
    for (Account member : members) {
        if (isValidReviewer(member, control)) {
            reviewers.put(member.getId(), control);
        }
    }
    addReviewers(rsrc, result, reviewers, input.cc());
    return result;
}
#method_after
private AddReviewerResult putGroup(ChangeResource rsrc, AddReviewerInput input) throws UpdateException, RestApiException, OrmException, IOException {
    GroupDescription.Basic group = groupsCollection.parseInternal(input.reviewer);
    AddReviewerResult result = new AddReviewerResult(input.reviewer);
    if (!isLegalReviewerGroup(group.getGroupUUID())) {
        result.error = MessageFormat.format(ChangeMessages.get().groupIsNotAllowed, group.getName());
        return result;
    }
    Map<Account.Id, ChangeControl> reviewers = new HashMap<>();
    ChangeControl control = rsrc.getControl();
    Set<Account> members;
    try {
        members = groupMembersFactory.create(control.getUser()).listAccounts(group.getGroupUUID(), control.getProject().getNameKey());
    } catch (NoSuchGroupException e) {
        throw new UnprocessableEntityException(e.getMessage());
    } catch (NoSuchProjectException e) {
        throw new BadRequestException(e.getMessage());
    }
    // if maxAllowed is set to 0, it is allowed to add any number of
    // reviewers
    int maxAllowed = cfg.getInt("addreviewer", "maxAllowed", DEFAULT_MAX_REVIEWERS);
    if (maxAllowed > 0 && members.size() > maxAllowed) {
        result.error = MessageFormat.format(ChangeMessages.get().groupHasTooManyMembers, group.getName());
        return result;
    }
    // if maxWithoutCheck is set to 0, we never ask for confirmation
    int maxWithoutConfirmation = cfg.getInt("addreviewer", "maxWithoutConfirmation", DEFAULT_MAX_REVIEWERS_WITHOUT_CHECK);
    if (!input.confirmed() && maxWithoutConfirmation > 0 && members.size() > maxWithoutConfirmation) {
        result.confirm = true;
        result.error = MessageFormat.format(ChangeMessages.get().groupManyMembersConfirmation, group.getName(), members.size());
        return result;
    }
    for (Account member : members) {
        if (isValidReviewer(member, control)) {
            reviewers.put(member.getId(), control);
        }
    }
    addReviewers(rsrc, result, reviewers, input.state());
    return result;
}
#end_block

#method_before
private void addReviewers(ChangeResource rsrc, AddReviewerResult result, Map<Account.Id, ChangeControl> reviewers, boolean cc) throws OrmException, RestApiException, UpdateException {
    try (BatchUpdate bu = batchUpdateFactory.create(dbProvider.get(), rsrc.getProject(), rsrc.getUser(), TimeUtil.nowTs())) {
        Op op = new Op(rsrc, reviewers, cc);
        Change.Id id = rsrc.getChange().getId();
        bu.addOp(id, op);
        bu.execute();
        // the Op because the accounts are in a different table.
        if (migration.readChanges() && cc) {
            result.ccs = Lists.newArrayListWithCapacity(op.addedCCs.size());
            for (Account.Id accountId : op.addedCCs) {
                result.ccs.add(json.format(new ReviewerInfo(accountId.get()), reviewers.get(accountId)));
            }
            accountLoaderFactory.create(true).fill(result.ccs);
        } else {
            result.reviewers = Lists.newArrayListWithCapacity(op.addedReviewers.size());
            for (PatchSetApproval psa : op.addedReviewers) {
                // New reviewers have value 0, don't bother normalizing.
                result.reviewers.add(json.format(new ReviewerInfo(psa.getAccountId().get()), reviewers.get(psa.getAccountId()), ImmutableList.of(psa)));
            }
            accountLoaderFactory.create(true).fill(result.reviewers);
        }
    }
}
#method_after
private void addReviewers(ChangeResource rsrc, AddReviewerResult result, Map<Account.Id, ChangeControl> reviewers, ReviewerState state) throws OrmException, RestApiException, UpdateException {
    try (BatchUpdate bu = batchUpdateFactory.create(dbProvider.get(), rsrc.getProject(), rsrc.getUser(), TimeUtil.nowTs())) {
        Op op = new Op(rsrc, reviewers, state);
        Change.Id id = rsrc.getChange().getId();
        bu.addOp(id, op);
        bu.execute();
        // the Op because the accounts are in a different table.
        if (migration.readChanges() && state == CC) {
            result.ccs = Lists.newArrayListWithCapacity(op.addedCCs.size());
            for (Account.Id accountId : op.addedCCs) {
                result.ccs.add(json.format(new ReviewerInfo(accountId.get()), reviewers.get(accountId)));
            }
            accountLoaderFactory.create(true).fill(result.ccs);
        } else {
            result.reviewers = Lists.newArrayListWithCapacity(op.addedReviewers.size());
            for (PatchSetApproval psa : op.addedReviewers) {
                // New reviewers have value 0, don't bother normalizing.
                result.reviewers.add(json.format(new ReviewerInfo(psa.getAccountId().get()), reviewers.get(psa.getAccountId()), ImmutableList.of(psa)));
            }
            accountLoaderFactory.create(true).fill(result.reviewers);
        }
    }
}
#end_block

#method_before
@Override
public boolean updateChange(ChangeContext ctx) throws RestApiException, OrmException, IOException {
    if (migration.readChanges() && cc) {
        addedCCs = approvalsUtil.addCCs(ctx.getNotes(), ctx.getUpdate(ctx.getChange().currentPatchSetId()), reviewers.keySet());
        if (addedCCs.isEmpty()) {
            return false;
        }
    } else {
        addedReviewers = approvalsUtil.addReviewers(ctx.getDb(), ctx.getNotes(), ctx.getUpdate(ctx.getChange().currentPatchSetId()), rsrc.getControl().getLabelTypes(), rsrc.getChange(), reviewers.keySet());
        if (addedReviewers.isEmpty()) {
            return false;
        }
    }
    patchSet = psUtil.current(dbProvider.get(), rsrc.getNotes());
    return true;
}
#method_after
@Override
public boolean updateChange(ChangeContext ctx) throws RestApiException, OrmException, IOException {
    if (migration.readChanges() && state == CC) {
        addedCCs = approvalsUtil.addCcs(ctx.getNotes(), ctx.getUpdate(ctx.getChange().currentPatchSetId()), reviewers.keySet());
        if (addedCCs.isEmpty()) {
            return false;
        }
    } else {
        addedReviewers = approvalsUtil.addReviewers(ctx.getDb(), ctx.getNotes(), ctx.getUpdate(ctx.getChange().currentPatchSetId()), rsrc.getControl().getLabelTypes(), rsrc.getChange(), reviewers.keySet());
        if (addedReviewers.isEmpty()) {
            return false;
        }
    }
    patchSet = psUtil.current(dbProvider.get(), rsrc.getNotes());
    return true;
}
#end_block

#method_before
@Override
public void postUpdate(Context ctx) throws Exception {
    if (addedCCs != null) {
        emailCCs(rsrc.getChange(), addedCCs);
    }
    if (addedReviewers != null) {
        emailReviewers(rsrc.getChange(), addedReviewers);
        if (!addedReviewers.isEmpty()) {
            for (PatchSetApproval psa : addedReviewers) {
                Account account = accountCache.get(psa.getAccountId()).getAccount();
                reviewerAdded.fire(rsrc.getChange(), patchSet, account);
            }
        }
    }
}
#method_after
@Override
public void postUpdate(Context ctx) throws Exception {
    if (addedReviewers != null || addedCCs != null) {
        if (addedReviewers == null) {
            addedReviewers = new ArrayList<>();
        }
        if (addedCCs == null) {
            addedCCs = new ArrayList<>();
        }
        emailReviewers(rsrc.getChange(), addedReviewers, addedCCs);
        if (!addedReviewers.isEmpty()) {
            for (PatchSetApproval psa : addedReviewers) {
                Account account = accountCache.get(psa.getAccountId()).getAccount();
                reviewerAdded.fire(rsrc.getChange(), patchSet, account, ctx.getAccount(), ctx.getWhen());
            }
        }
    }
}
#end_block

#method_before
private void emailReviewers(Change change, List<PatchSetApproval> added) {
    if (added.isEmpty()) {
        return;
    }
    // Email the reviewers
    // 
    // The user knows they added themselves, don't bother emailing them.
    List<Account.Id> toMail = Lists.newArrayListWithCapacity(added.size());
    Account.Id userId = user.get().getAccountId();
    for (PatchSetApproval psa : added) {
        if (!psa.getAccountId().equals(userId)) {
            toMail.add(psa.getAccountId());
        }
    }
    if (toMail.isEmpty()) {
        return;
    }
    try {
        AddReviewerSender cm = addReviewerSenderFactory.create(change.getProject(), change.getId());
        cm.setFrom(userId);
        cm.addReviewers(toMail);
        cm.send();
    } catch (Exception err) {
        log.error("Cannot send email to new reviewers of change " + change.getId(), err);
    }
}
#method_after
private void emailReviewers(Change change, List<PatchSetApproval> added, Collection<Account.Id> copied) {
    if (added.isEmpty() && copied.isEmpty()) {
        return;
    }
    // Email the reviewers
    // 
    // The user knows they added themselves, don't bother emailing them.
    List<Account.Id> toMail = Lists.newArrayListWithCapacity(added.size());
    Account.Id userId = user.get().getAccountId();
    for (PatchSetApproval psa : added) {
        if (!psa.getAccountId().equals(userId)) {
            toMail.add(psa.getAccountId());
        }
    }
    List<Account.Id> toCopy = Lists.newArrayListWithCapacity(copied.size());
    for (Account.Id id : copied) {
        if (!id.equals(userId)) {
            toCopy.add(id);
        }
    }
    if (toMail.isEmpty() && toCopy.isEmpty()) {
        return;
    }
    try {
        AddReviewerSender cm = addReviewerSenderFactory.create(change.getProject(), change.getId());
        cm.setFrom(userId);
        cm.addReviewers(toMail);
        cm.addExtraCC(toCopy);
        cm.send();
    } catch (Exception err) {
        log.error("Cannot send email to new reviewers of change " + change.getId(), err);
    }
}
#end_block

#method_before
@Override
public boolean updateChange(ChangeContext ctx) throws OrmException, AuthException, ResourceNotFoundException {
    ChangeControl ctl = ctx.getControl();
    change = ctl.getChange();
    PatchSet.Id psId = change.currentPatchSetId();
    ps = psUtil.current(db.get(), ctl.getNotes());
    PatchSetApproval psa = null;
    StringBuilder msg = new StringBuilder();
    // get all of the current approvals
    LabelTypes labelTypes = ctx.getControl().getLabelTypes();
    Map<String, Short> currentApprovals = new HashMap<>();
    for (LabelType lt : labelTypes.getLabelTypes()) {
        currentApprovals.put(lt.getName(), (short) 0);
        for (PatchSetApproval a : approvalsUtil.byPatchSetUser(ctx.getDb(), ctl, psId, accountId)) {
            if (lt.getLabelId().equals(a.getLabelId())) {
                currentApprovals.put(lt.getName(), a.getValue());
            }
        }
    }
    // removing votes so we need to determine the new set of approval scores
    newApprovals.putAll(currentApprovals);
    for (PatchSetApproval a : approvalsUtil.byPatchSetUser(ctx.getDb(), ctl, psId, accountId)) {
        if (ctl.canRemoveReviewer(a)) {
            if (a.getLabel().equals(label)) {
                // set the approval to 0 if vote is being removed
                newApprovals.put(a.getLabel(), (short) 0);
                // set old value only if the vote changed
                oldApprovals.put(a.getLabel(), a.getValue());
                msg.append("Removed ").append(a.getLabel()).append(formatLabelValue(a.getValue())).append(" by ").append(userFactory.create(a.getAccountId()).getNameEmail()).append("\n");
                psa = a;
                a.setValue((short) 0);
                ctx.getUpdate(psId).removeApprovalFor(a.getAccountId(), label);
                break;
            }
        } else {
            throw new AuthException("delete vote not permitted");
        }
    }
    if (psa == null) {
        throw new ResourceNotFoundException();
    }
    ctx.getDb().patchSetApprovals().update(Collections.singleton(psa));
    if (msg.length() > 0) {
        changeMessage = new ChangeMessage(new ChangeMessage.Key(change.getId(), ChangeUtil.messageUUID(ctx.getDb())), ctx.getUser().asIdentifiedUser().getAccountId(), ctx.getWhen(), change.currentPatchSetId());
        changeMessage.setMessage(msg.toString());
        cmUtil.addChangeMessage(ctx.getDb(), ctx.getUpdate(psId), changeMessage);
    }
    return true;
}
#method_after
@Override
public boolean updateChange(ChangeContext ctx) throws OrmException, AuthException, ResourceNotFoundException {
    ChangeControl ctl = ctx.getControl();
    change = ctl.getChange();
    PatchSet.Id psId = change.currentPatchSetId();
    ps = psUtil.current(db.get(), ctl.getNotes());
    PatchSetApproval psa = null;
    StringBuilder msg = new StringBuilder();
    // get all of the current approvals
    LabelTypes labelTypes = ctx.getControl().getLabelTypes();
    Map<String, Short> currentApprovals = new HashMap<>();
    for (LabelType lt : labelTypes.getLabelTypes()) {
        currentApprovals.put(lt.getName(), (short) 0);
        for (PatchSetApproval a : approvalsUtil.byPatchSetUser(ctx.getDb(), ctl, psId, accountId)) {
            if (lt.getLabelId().equals(a.getLabelId())) {
                currentApprovals.put(lt.getName(), a.getValue());
            }
        }
    }
    // removing votes so we need to determine the new set of approval scores
    newApprovals.putAll(currentApprovals);
    for (PatchSetApproval a : approvalsUtil.byPatchSetUser(ctx.getDb(), ctl, psId, accountId)) {
        if (ctl.canRemoveReviewer(a)) {
            if (a.getLabel().equals(label)) {
                // set the approval to 0 if vote is being removed
                newApprovals.put(a.getLabel(), (short) 0);
                // set old value only if the vote changed
                oldApprovals.put(a.getLabel(), a.getValue());
                msg.append("Removed ").append(a.getLabel()).append(formatLabelValue(a.getValue())).append(" by ").append(userFactory.create(a.getAccountId()).getNameEmail()).append("\n");
                psa = a;
                a.setValue((short) 0);
                ctx.getUpdate(psId).removeApprovalFor(a.getAccountId(), label);
                break;
            }
        } else {
            throw new AuthException("delete vote not permitted");
        }
    }
    if (psa == null) {
        throw new ResourceNotFoundException();
    }
    ctx.getDb().patchSetApprovals().update(Collections.singleton(psa));
    if (msg.length() > 0) {
        changeMessage = new ChangeMessage(new ChangeMessage.Key(change.getId(), ChangeUtil.messageUUID(ctx.getDb())), ctx.getAccountId(), ctx.getWhen(), change.currentPatchSetId());
        changeMessage.setMessage(msg.toString());
        cmUtil.addChangeMessage(ctx.getDb(), ctx.getUpdate(psId), changeMessage);
    }
    return true;
}
#end_block

#method_before
@Override
public void postUpdate(Context ctx) {
    if (changeMessage == null) {
        return;
    }
    IdentifiedUser user = ctx.getUser().asIdentifiedUser();
    if (input.notify.compareTo(NotifyHandling.NONE) > 0) {
        try {
            ReplyToChangeSender cm = deleteVoteSenderFactory.create(ctx.getProject(), change.getId());
            cm.setFrom(user.getAccountId());
            cm.setChangeMessage(changeMessage.getMessage(), ctx.getWhen());
            cm.setNotify(input.notify);
            cm.send();
        } catch (Exception e) {
            log.error("Cannot email update for change " + change.getId(), e);
        }
    }
    voteDeleted.fire(change, ps, newApprovals, oldApprovals, user.getAccount(), ctx.getWhen());
}
#method_after
@Override
public void postUpdate(Context ctx) {
    if (changeMessage == null) {
        return;
    }
    IdentifiedUser user = ctx.getIdentifiedUser();
    if (input.notify.compareTo(NotifyHandling.NONE) > 0) {
        try {
            ReplyToChangeSender cm = deleteVoteSenderFactory.create(ctx.getProject(), change.getId());
            cm.setFrom(user.getAccountId());
            cm.setChangeMessage(changeMessage.getMessage(), ctx.getWhen());
            cm.setNotify(input.notify);
            cm.send();
        } catch (Exception e) {
            log.error("Cannot email update for change " + change.getId(), e);
        }
    }
    voteDeleted.fire(change, ps, newApprovals, oldApprovals, input.notify, changeMessage.getMessage(), user.getAccount(), ctx.getWhen());
}
#end_block

#method_before
public void fire(Change change, PatchSet ps, Map<String, Short> approvals, Map<String, Short> oldApprovals, Account remover, Timestamp when) {
    if (!listeners.iterator().hasNext()) {
        return;
    }
    try {
        fire(util.changeInfo(change), util.revisionInfo(change.getProject(), ps), util.approvals(remover, approvals, when), util.approvals(remover, oldApprovals, when), util.accountInfo(remover), when);
    } catch (PatchListNotAvailableException | GpgException | IOException | OrmException e) {
        log.error("Couldn't fire event", e);
    }
}
#method_after
public void fire(ChangeInfo change, RevisionInfo revision, Map<String, ApprovalInfo> approvals, Map<String, ApprovalInfo> oldApprovals, NotifyHandling notify, String message, AccountInfo remover, Timestamp when) {
    if (!listeners.iterator().hasNext()) {
        return;
    }
    Event event = new Event(change, revision, approvals, oldApprovals, notify, message, remover, when);
    for (VoteDeletedListener l : listeners) {
        try {
            l.onVoteDeleted(event);
        } catch (Exception e) {
            log.warn("Error in event listener", e);
        }
    }
}
#end_block

#method_before
@Before
public void setup() throws Exception {
    count = 1;
    ProjectConfig cfg = projectCache.checkedGet(project).getConfig();
    // Overwrite "Code-Review" label that is inherited from All-Projects.
    // This way changes to the "Code Review" label don't affect other tests.
    LabelType codeReview = category("Code-Review", value(2, "Looks good to me, approved"), value(1, "Looks good to me, but someone else must approve"), value(0, "No score"), value(-1, "I would prefer that you didn't submit this"), value(-2, "Do not submit"));
    cfg.getLabelSections().put(codeReview.getName(), codeReview);
    LabelType verified = category("Verified", value(1, "Passes"), value(0, "No score"), value(-1, "Failed"));
    cfg.getLabelSections().put(verified.getName(), verified);
    AccountGroup.UUID all = SystemGroupBackend.getGroup(REGISTERED_USERS).getUUID();
    String heads = RefNames.REFS_HEADS + "*";
    Util.allow(cfg, Permission.forLabel(Util.codeReview().getName()), -2, 2, all, heads);
    Util.allow(cfg, Permission.forLabel(Util.verified().getName()), -1, 1, all, heads);
    saveProjectConfig(project, cfg);
}
#method_after
@Before
public void setup() throws Exception {
    ProjectConfig cfg = projectCache.checkedGet(project).getConfig();
    // Overwrite "Code-Review" label that is inherited from All-Projects.
    // This way changes to the "Code Review" label don't affect other tests.
    LabelType codeReview = category("Code-Review", value(2, "Looks good to me, approved"), value(1, "Looks good to me, but someone else must approve"), value(0, "No score"), value(-1, "I would prefer that you didn't submit this"), value(-2, "Do not submit"));
    cfg.getLabelSections().put(codeReview.getName(), codeReview);
    LabelType verified = category("Verified", value(1, "Passes"), value(0, "No score"), value(-1, "Failed"));
    cfg.getLabelSections().put(verified.getName(), verified);
    AccountGroup.UUID registeredUsers = SystemGroupBackend.getGroup(REGISTERED_USERS).getUUID();
    String heads = RefNames.REFS_HEADS + "*";
    Util.allow(cfg, Permission.forLabel(Util.codeReview().getName()), -2, 2, registeredUsers, heads);
    Util.allow(cfg, Permission.forLabel(Util.verified().getName()), -1, 1, registeredUsers, heads);
    saveProjectConfig(project, cfg);
}
#end_block

#method_before
@Test
public void notSticky() throws Exception {
    assertNotSticky(EnumSet.of(REWORK, TRIVIAL_REBASE, NO_CODE_CHANGE));
}
#method_after
@Test
public void notSticky() throws Exception {
    assertNotSticky(EnumSet.of(REWORK, TRIVIAL_REBASE, NO_CODE_CHANGE, MERGE_FIRST_PARENT_UPDATE));
}
#end_block

#method_before
@Test
public void stickyOnTrivialRebase() throws Exception {
    ProjectConfig cfg = projectCache.checkedGet(project).getConfig();
    cfg.getLabelSections().get("Code-Review").setCopyAllScoresOnTrivialRebase(true);
    saveProjectConfig(project, cfg);
    String changeId = createChange().getChangeId();
    vote(admin, changeId, 2, 1);
    vote(user, changeId, -2, -1);
    updateChange(changeId, TRIVIAL_REBASE);
    ChangeInfo c = detailedChange(changeId);
    assertVotes(c, admin, 2, 0, TRIVIAL_REBASE);
    assertVotes(c, user, -2, 0, TRIVIAL_REBASE);
    assertNotSticky(EnumSet.of(REWORK, NO_CODE_CHANGE));
}
#method_after
@Test
public void stickyOnTrivialRebase() throws Exception {
    ProjectConfig cfg = projectCache.checkedGet(project).getConfig();
    cfg.getLabelSections().get("Code-Review").setCopyAllScoresOnTrivialRebase(true);
    saveProjectConfig(project, cfg);
    String changeId = createChange(TRIVIAL_REBASE);
    vote(admin, changeId, 2, 1);
    vote(user, changeId, -2, -1);
    updateChange(changeId, TRIVIAL_REBASE);
    ChangeInfo c = detailedChange(changeId);
    assertVotes(c, admin, 2, 0, TRIVIAL_REBASE);
    assertVotes(c, user, -2, 0, TRIVIAL_REBASE);
    assertNotSticky(EnumSet.of(REWORK, NO_CODE_CHANGE, MERGE_FIRST_PARENT_UPDATE));
    // check that votes are sticky when trivial rebase is done by cherry-pick
    testRepo.reset(getRemoteHead());
    changeId = createChange().getChangeId();
    vote(admin, changeId, 2, 1);
    vote(user, changeId, -2, -1);
    String cherryPickChangeId = cherryPick(changeId, TRIVIAL_REBASE);
    c = detailedChange(cherryPickChangeId);
    assertVotes(c, admin, 2, 0);
    assertVotes(c, user, -2, 0);
    // check that votes are not sticky when rework is done by cherry-pick
    testRepo.reset(getRemoteHead());
    changeId = createChange().getChangeId();
    vote(admin, changeId, 2, 1);
    vote(user, changeId, -2, -1);
    cherryPickChangeId = cherryPick(changeId, REWORK);
    c = detailedChange(cherryPickChangeId);
    assertVotes(c, admin, 0, 0);
    assertVotes(c, user, 0, 0);
}
#end_block

#method_before
@Test
public void stickyOnNoCodeChange() throws Exception {
    ProjectConfig cfg = projectCache.checkedGet(project).getConfig();
    cfg.getLabelSections().get("Verified").setCopyAllScoresIfNoCodeChange(true);
    saveProjectConfig(project, cfg);
    String changeId = createChange().getChangeId();
    vote(admin, changeId, 2, 1);
    vote(user, changeId, -2, -1);
    updateChange(changeId, NO_CODE_CHANGE);
    ChangeInfo c = detailedChange(changeId);
    assertVotes(c, admin, 0, 1, NO_CODE_CHANGE);
    assertVotes(c, user, 0, -1, NO_CODE_CHANGE);
    assertNotSticky(EnumSet.of(REWORK, TRIVIAL_REBASE));
}
#method_after
@Test
public void stickyOnNoCodeChange() throws Exception {
    ProjectConfig cfg = projectCache.checkedGet(project).getConfig();
    cfg.getLabelSections().get("Verified").setCopyAllScoresIfNoCodeChange(true);
    saveProjectConfig(project, cfg);
    String changeId = createChange(NO_CODE_CHANGE);
    vote(admin, changeId, 2, 1);
    vote(user, changeId, -2, -1);
    updateChange(changeId, NO_CODE_CHANGE);
    ChangeInfo c = detailedChange(changeId);
    assertVotes(c, admin, 0, 1, NO_CODE_CHANGE);
    assertVotes(c, user, 0, -1, NO_CODE_CHANGE);
    assertNotSticky(EnumSet.of(REWORK, TRIVIAL_REBASE, MERGE_FIRST_PARENT_UPDATE));
}
#end_block

#method_before
private ChangeInfo detailedChange(String changeId) throws Exception {
    return gApi.changes().id(changeId).get(EnumSet.of(ListChangesOption.DETAILED_LABELS));
}
#method_after
private ChangeInfo detailedChange(String changeId) throws Exception {
    return gApi.changes().id(changeId).get(EnumSet.of(ListChangesOption.DETAILED_LABELS, ListChangesOption.CURRENT_REVISION, ListChangesOption.CURRENT_COMMIT));
}
#end_block

#method_before
private void assertNotSticky(Set<ChangeKind> changeKinds) throws Exception {
    for (ChangeKind changeKind : changeKinds) {
        testRepo.reset(getRemoteHead());
        String changeId = createChange().getChangeId();
        vote(admin, changeId, +2, 1);
        vote(user, changeId, -2, -1);
        updateChange(changeId, changeKind);
        ChangeInfo c = detailedChange(changeId);
        assertVotes(c, admin, 0, 0, changeKind);
        assertVotes(c, user, 0, 0, changeKind);
    }
}
#method_after
private void assertNotSticky(Set<ChangeKind> changeKinds) throws Exception {
    for (ChangeKind changeKind : changeKinds) {
        testRepo.reset(getRemoteHead());
        String changeId = createChange(changeKind);
        vote(admin, changeId, +2, 1);
        vote(user, changeId, -2, -1);
        updateChange(changeId, changeKind);
        ChangeInfo c = detailedChange(changeId);
        assertVotes(c, admin, 0, 0, changeKind);
        assertVotes(c, user, 0, 0, changeKind);
    }
}
#end_block

#method_before
private void updateChange(String changeId, ChangeKind kind) throws Exception {
    switch(kind) {
        case NO_CODE_CHANGE:
            noCodeChange(changeId);
            return;
        case REWORK:
            rework(changeId);
            return;
        case TRIVIAL_REBASE:
            trivialRebase(changeId);
            return;
        case NO_CHANGE:
        case MERGE_FIRST_PARENT_UPDATE:
        default:
            fail("unexpexted change kind: " + kind);
    }
}
#method_after
private void updateChange(String changeId, ChangeKind changeKind) throws Exception {
    switch(changeKind) {
        case NO_CODE_CHANGE:
            noCodeChange(changeId);
            return;
        case REWORK:
            rework(changeId);
            return;
        case TRIVIAL_REBASE:
            trivialRebase(changeId);
            return;
        case MERGE_FIRST_PARENT_UPDATE:
            updateFirstParent(changeId);
            return;
        case NO_CHANGE:
        default:
            fail("unexpected change kind: " + changeKind);
    }
}
#end_block

#method_before
private void noCodeChange(String changeId) throws Exception {
    TestRepository<?>.CommitBuilder commitBuilder = testRepo.amendRef("HEAD").insertChangeId(changeId.substring(1));
    commitBuilder.message("New subject " + count++).author(admin.getIdent()).committer(new PersonIdent(admin.getIdent(), testRepo.getDate()));
    commitBuilder.create();
    GitUtil.pushHead(testRepo, "refs/for/master", false);
    assertThat(getChangeKind(changeId)).isEqualTo(NO_CODE_CHANGE);
}
#method_after
private void noCodeChange(String changeId) throws Exception {
    TestRepository<?>.CommitBuilder commitBuilder = testRepo.amendRef("HEAD").insertChangeId(changeId.substring(1));
    commitBuilder.message("New subject " + System.nanoTime()).author(admin.getIdent()).committer(new PersonIdent(admin.getIdent(), testRepo.getDate()));
    commitBuilder.create();
    GitUtil.pushHead(testRepo, "refs/for/master", false);
    assertThat(getChangeKind(changeId)).isEqualTo(NO_CODE_CHANGE);
}
#end_block

#method_before
private void rework(String changeId) throws Exception {
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo, PushOneCommit.SUBJECT, PushOneCommit.FILE_NAME, "new content " + count++, changeId);
    push.to("refs/for/master").assertOkStatus();
    assertThat(getChangeKind(changeId)).isEqualTo(REWORK);
}
#method_after
private void rework(String changeId) throws Exception {
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo, PushOneCommit.SUBJECT, PushOneCommit.FILE_NAME, "new content " + System.nanoTime(), changeId);
    push.to("refs/for/master").assertOkStatus();
    assertThat(getChangeKind(changeId)).isEqualTo(REWORK);
}
#end_block

#method_before
private void trivialRebase(String changeId) throws Exception {
    setApiUser(admin);
    testRepo.reset(getRemoteHead());
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo, "Other Change", "a" + count++ + ".txt", PushOneCommit.FILE_CONTENT);
    PushOneCommit.Result r = push.to("refs/for/master");
    r.assertOkStatus();
    RevisionApi revision = gApi.changes().id(r.getChangeId()).current();
    ReviewInput in = new ReviewInput().label("Code-Review", 2).label("Verified", 1);
    revision.review(in);
    revision.submit();
    gApi.changes().id(changeId).current().rebase();
    assertThat(getChangeKind(changeId)).isEqualTo(TRIVIAL_REBASE);
}
#method_after
private void trivialRebase(String changeId) throws Exception {
    setApiUser(admin);
    testRepo.reset(getRemoteHead());
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo, "Other Change", "a" + System.nanoTime() + ".txt", PushOneCommit.FILE_CONTENT);
    PushOneCommit.Result r = push.to("refs/for/master");
    r.assertOkStatus();
    RevisionApi revision = gApi.changes().id(r.getChangeId()).current();
    ReviewInput in = new ReviewInput().label("Code-Review", 2).label("Verified", 1);
    revision.review(in);
    revision.submit();
    gApi.changes().id(changeId).current().rebase();
    assertThat(getChangeKind(changeId)).isEqualTo(TRIVIAL_REBASE);
}
#end_block

#method_before
private void assertVotes(ChangeInfo c, TestAccount user, String label, int expectedVote, ChangeKind changeKind) {
    Integer vote = null;
    for (ApprovalInfo approval : c.labels.get(label).all) {
        if (approval._accountId == user.id.get()) {
            vote = approval.value;
            break;
        }
    }
    assertThat(vote).named("label = " + label + "; changeKind = " + changeKind.name()).isEqualTo(expectedVote);
}
#method_after
private void assertVotes(ChangeInfo c, TestAccount user, int codeReviewVote, int verifiedVote) {
    assertVotes(c, user, codeReviewVote, verifiedVote, null);
}
#end_block

#method_before
private void assertVotes(ChangeInfo c, TestAccount user, String label, int expectedVote, ChangeKind changeKind) {
    Integer vote = null;
    for (ApprovalInfo approval : c.labels.get(label).all) {
        if (approval._accountId == user.id.get()) {
            vote = approval.value;
            break;
        }
    }
    assertThat(vote).named("label = " + label + "; changeKind = " + changeKind.name()).isEqualTo(expectedVote);
}
#method_after
private void assertVotes(ChangeInfo c, TestAccount user, String label, int expectedVote, ChangeKind changeKind) {
    Integer vote = 0;
    if (c.labels.get(label) != null && c.labels.get(label).all != null) {
        for (ApprovalInfo approval : c.labels.get(label).all) {
            if (approval._accountId == user.id.get()) {
                vote = approval.value;
                break;
            }
        }
    }
    String name = "label = " + label;
    if (changeKind != null) {
        name += "; changeKind = " + changeKind.name();
    }
    assertThat(vote).named(name).isEqualTo(expectedVote);
}
#end_block

#method_before
@Override
public void storeEvent(ProjectEvent event) {
    Project.NameKey projectName = event.getProjectNameKey();
    if (projectName == null) {
        return;
    }
    int failedConnections = 0;
    boolean done = false;
    while (!done) {
        done = true;
        try {
            getEventsDb().storeEvent(event);
        } catch (SQLException e) {
            log.warn("Cannot store ChangeEvent for: " + projectName.get(), e);
            if (e.getCause() instanceof ConnectException || e.getMessage().contains("terminating connection")) {
                done = false;
                try {
                    retryIfAllowed(failedConnections);
                } catch (InterruptedException e1) {
                    Thread.currentThread().interrupt();
                    log.warn("Cannot store ChangeEvent for: " + projectName.get() + ": Interrupted");
                    return;
                }
                failedConnections++;
            }
        }
    }
}
#method_after
@Override
public void storeEvent(ProjectEvent event) {
    Project.NameKey projectName = event.getProjectNameKey();
    if (projectName == null) {
        return;
    }
    int failedConnections = 0;
    boolean done = false;
    while (!done) {
        done = true;
        try {
            getEventsDb().storeEvent(event);
        } catch (SQLException e) {
            log.warn("Cannot store ChangeEvent for: " + projectName.get(), e);
            if (e.getCause() instanceof ConnectException || e.getMessage().contains("terminating connection")) {
                done = false;
                try {
                    retryIfAllowed(failedConnections);
                } catch (InterruptedException e1) {
                    log.warn("Cannot store ChangeEvent for: " + projectName.get() + ": Interrupted");
                    Thread.currentThread().interrupt();
                    return;
                }
                failedConnections++;
            }
        }
    }
}
#end_block

#method_before
public RevisionInfo getRevisionInfo(ChangeControl ctl, PatchSet in) throws PatchListNotAvailableException, GpgException, OrmException, IOException {
    return getRevisionInfo(ctl, in, false);
}
#method_after
public RevisionInfo getRevisionInfo(ChangeControl ctl, PatchSet in) throws PatchListNotAvailableException, GpgException, OrmException, IOException {
    accountLoader = accountLoaderFactory.create(has(DETAILED_ACCOUNTS));
    try (Repository repo = repoManager.openRepository(ctl.getProject().getNameKey())) {
        RevisionInfo rev = toRevisionInfo(ctl, changeDataFactory.create(db.get(), ctl), in, repo, true);
        accountLoader.fill();
        return rev;
    }
}
#end_block

#method_before
private AddReviewerResult putGroup(ChangeResource rsrc, AddReviewerInput input) throws UpdateException, RestApiException, OrmException, IOException {
    GroupDescription.Basic group = groupsCollection.parseInternal(input.reviewer);
    AddReviewerResult result = new AddReviewerResult(input.reviewer);
    if (!isLegalReviewerGroup(group.getGroupUUID())) {
        result.error = MessageFormat.format(ChangeMessages.get().groupIsNotAllowed, group.getName());
        return result;
    }
    Map<Account.Id, ChangeControl> reviewers = new HashMap<>();
    ChangeControl control = rsrc.getControl();
    Set<Account> members;
    try {
        members = groupMembersFactory.create(control.getUser()).listAccounts(group.getGroupUUID(), control.getProject().getNameKey());
    } catch (NoSuchGroupException e) {
        throw new UnprocessableEntityException(e.getMessage());
    } catch (NoSuchProjectException e) {
        throw new BadRequestException(e.getMessage());
    }
    // if maxAllowed is set to 0, it is allowed to add any number of
    // reviewers
    int maxAllowed = cfg.getInt("addreviewer", "maxAllowed", DEFAULT_MAX_REVIEWERS);
    if (maxAllowed > 0 && members.size() > maxAllowed) {
        result.error = MessageFormat.format(ChangeMessages.get().groupHasTooManyMembers, group.getName());
        return result;
    }
    // if maxWithoutCheck is set to 0, we never ask for confirmation
    int maxWithoutConfirmation = cfg.getInt("addreviewer", "maxWithoutConfirmation", DEFAULT_MAX_REVIEWERS_WITHOUT_CHECK);
    if (!input.confirmed() && maxWithoutConfirmation > 0 && members.size() > maxWithoutConfirmation) {
        result.needsConfirmation = true;
        result.error = MessageFormat.format(ChangeMessages.get().groupManyMembersConfirmation, group.getName(), members.size());
        return result;
    }
    for (Account member : members) {
        if (isValidReviewer(member, control)) {
            reviewers.put(member.getId(), control);
        }
    }
    addReviewers(rsrc, result, reviewers);
    return result;
}
#method_after
private AddReviewerResult putGroup(ChangeResource rsrc, AddReviewerInput input) throws UpdateException, RestApiException, OrmException, IOException {
    GroupDescription.Basic group = groupsCollection.parseInternal(input.reviewer);
    AddReviewerResult result = new AddReviewerResult(input.reviewer);
    if (!isLegalReviewerGroup(group.getGroupUUID())) {
        result.error = MessageFormat.format(ChangeMessages.get().groupIsNotAllowed, group.getName());
        return result;
    }
    Map<Account.Id, ChangeControl> reviewers = new HashMap<>();
    ChangeControl control = rsrc.getControl();
    Set<Account> members;
    try {
        members = groupMembersFactory.create(control.getUser()).listAccounts(group.getGroupUUID(), control.getProject().getNameKey());
    } catch (NoSuchGroupException e) {
        throw new UnprocessableEntityException(e.getMessage());
    } catch (NoSuchProjectException e) {
        throw new BadRequestException(e.getMessage());
    }
    // if maxAllowed is set to 0, it is allowed to add any number of
    // reviewers
    int maxAllowed = cfg.getInt("addreviewer", "maxAllowed", DEFAULT_MAX_REVIEWERS);
    if (maxAllowed > 0 && members.size() > maxAllowed) {
        result.error = MessageFormat.format(ChangeMessages.get().groupHasTooManyMembers, group.getName());
        return result;
    }
    // if maxWithoutCheck is set to 0, we never ask for confirmation
    int maxWithoutConfirmation = cfg.getInt("addreviewer", "maxWithoutConfirmation", DEFAULT_MAX_REVIEWERS_WITHOUT_CHECK);
    if (!input.confirmed() && maxWithoutConfirmation > 0 && members.size() > maxWithoutConfirmation) {
        result.confirm = true;
        result.error = MessageFormat.format(ChangeMessages.get().groupManyMembersConfirmation, group.getName(), members.size());
        return result;
    }
    for (Account member : members) {
        if (isValidReviewer(member, control)) {
            reviewers.put(member.getId(), control);
        }
    }
    addReviewers(rsrc, result, reviewers);
    return result;
}
#end_block

#method_before
@Override
public void postUpdate(Context ctx) throws Exception {
    emailReviewers(rsrc.getChange(), added);
    if (!added.isEmpty()) {
        for (PatchSetApproval psa : added) {
            Account account = accountCache.get(psa.getAccountId()).getAccount();
            reviewerAdded.fire(rsrc.getChange(), patchSet, account);
        }
    }
}
#method_after
@Override
public void postUpdate(Context ctx) throws Exception {
    emailReviewers(rsrc.getChange(), added);
    if (!added.isEmpty()) {
        for (PatchSetApproval psa : added) {
            Account account = accountCache.get(psa.getAccountId()).getAccount();
            reviewerAdded.fire(rsrc.getChange(), patchSet, account, ctx.getUser().asIdentifiedUser().getAccount(), ctx.getWhen());
        }
    }
}
#end_block

#method_before
@Override
public void rollback() {
    throw new UnsupportedOperationException("do not call commit; BatchUpdate always manages transactions");
}
#method_after
@Override
public void rollback() {
    throw new UnsupportedOperationException("do not call rollback; BatchUpdate always manages transactions");
}
#end_block

#method_before
@Deprecated
public void setChangeMessage(final ChangeMessage cm) {
    setChangeMessage(cm.getMessage());
}
#method_after
@Deprecated
public void setChangeMessage(final ChangeMessage cm) {
    setChangeMessage(cm.getMessage(), cm.getWrittenOn());
}
#end_block

#method_before
public void setChangeMessage(String cm) {
    changeMessage = cm;
}
#method_after
public void setChangeMessage(String cm, Timestamp t) {
    changeMessage = cm;
    timestamp = t;
}
#end_block

#method_before
@Override
protected void init() throws EmailException {
    if (args.projectCache != null) {
        projectState = args.projectCache.get(change.getProject());
    } else {
        projectState = null;
    }
    if (patchSet == null) {
        try {
            patchSet = changeData.currentPatchSet();
        } catch (OrmException err) {
            patchSet = null;
        }
    }
    if (patchSet != null && patchSetInfo == null) {
        try {
            patchSetInfo = args.patchSetInfoFactory.get(args.db.get(), changeData.notes(), patchSet.getId());
        } catch (PatchSetInfoNotAvailableException | OrmException err) {
            patchSetInfo = null;
        }
    }
    authors = getAuthors();
    super.init();
    setChangeSubjectHeader();
    setHeader("X-Gerrit-Change-Id", "" + change.getKey().get());
    setChangeUrlHeader();
    setCommitIdHeader();
}
#method_after
@Override
protected void init() throws EmailException {
    if (args.projectCache != null) {
        projectState = args.projectCache.get(change.getProject());
    } else {
        projectState = null;
    }
    if (patchSet == null) {
        try {
            patchSet = changeData.currentPatchSet();
        } catch (OrmException err) {
            patchSet = null;
        }
    }
    if (patchSet != null && patchSetInfo == null) {
        try {
            patchSetInfo = args.patchSetInfoFactory.get(args.db.get(), changeData.notes(), patchSet.getId());
        } catch (PatchSetInfoNotAvailableException | OrmException err) {
            patchSetInfo = null;
        }
    }
    authors = getAuthors();
    super.init();
    if (timestamp != null) {
        setHeader("Date", new Date(timestamp.getTime()));
    }
    setChangeSubjectHeader();
    setHeader("X-Gerrit-Change-Id", "" + change.getKey().get());
    setChangeUrlHeader();
    setCommitIdHeader();
}
#end_block

#method_before
@Override
protected void service(HttpServletRequest req, HttpServletResponse res) throws ServletException, IOException {
    if (filter == null) {
        CacheHeaders.setNotCacheable(res);
        res.sendError(SC_NOT_IMPLEMENTED);
        return;
    }
    filter.doFilter(req, res, chain);
}
#method_after
@Override
protected void service(HttpServletRequest req, HttpServletResponse res) throws ServletException, IOException {
    if (filter.get() == null) {
        CacheHeaders.setNotCacheable(res);
        res.sendError(SC_NOT_IMPLEMENTED);
        return;
    }
    filter.get().doFilter(req, res, chain);
}
#end_block

#method_before
private void install(Plugin plugin) {
    if (!plugin.getName().equals(pluginName)) {
        return;
    }
    filter = load(plugin);
}
#method_after
private void install(Plugin plugin) {
    if (!plugin.getName().equals(pluginName)) {
        return;
    }
    final GuiceFilter guiceFilter = load(plugin);
    plugin.add(new RegistrationHandle() {

        @Override
        public void remove() {
            filter.compareAndSet(guiceFilter, null);
        }
    });
    filter.set(guiceFilter);
}
#end_block

#method_before
private GuiceFilter load(Plugin plugin) {
    if (plugin.getHttpInjector() != null) {
        final String name = plugin.getName();
        final GuiceFilter guiceFilter;
        try {
            guiceFilter = plugin.getHttpInjector().getInstance(GuiceFilter.class);
        } catch (RuntimeException e) {
            log.warn(String.format("Plugin %s cannot load GuiceFilter", name), e);
            return null;
        }
        try {
            ServletContext ctx = PluginServletContext.create(plugin, "/");
            guiceFilter.init(new WrappedFilterConfig(ctx));
        } catch (ServletException e) {
            log.warn(String.format("Plugin %s failed to initialize HTTP", name), e);
            return null;
        }
        plugin.add(new RegistrationHandle() {

            @Override
            public void remove() {
                guiceFilter.destroy();
                if (guiceFilter == filter) {
                    filter = null;
                }
            }
        });
        return guiceFilter;
    }
    return null;
}
#method_after
private GuiceFilter load(Plugin plugin) {
    if (plugin.getHttpInjector() != null) {
        final String name = plugin.getName();
        final GuiceFilter guiceFilter;
        try {
            guiceFilter = plugin.getHttpInjector().getInstance(GuiceFilter.class);
        } catch (RuntimeException e) {
            log.warn(String.format("Plugin %s cannot load GuiceFilter", name), e);
            return null;
        }
        try {
            ServletContext ctx = PluginServletContext.create(plugin, "/");
            guiceFilter.init(new WrappedFilterConfig(ctx));
        } catch (ServletException e) {
            log.warn(String.format("Plugin %s failed to initialize HTTP", name), e);
            return null;
        }
        plugin.add(new RegistrationHandle() {

            @Override
            public void remove() {
                guiceFilter.destroy();
            }
        });
        return guiceFilter;
    }
    return null;
}
#end_block

#method_before
private void reportMessages() {
    Iterable<CreateRequest> created = Iterables.filter(newChanges, new Predicate<CreateRequest>() {

        @Override
        public boolean apply(CreateRequest input) {
            return input.change != null;
        }
    });
    if (!Iterables.isEmpty(created)) {
        addMessage("");
        addMessage("New Changes:");
        for (CreateRequest c : created) {
            addMessage(formatChangeUrl(canonicalWebUrl, c.change, c.change.getSubject(), false));
        }
        addMessage("");
    }
    List<ReplaceRequest> updated = FluentIterable.from(replaceByChange.values()).filter(new Predicate<ReplaceRequest>() {

        @Override
        public boolean apply(ReplaceRequest input) {
            return !input.skip && input.inputCommand.getResult() == OK;
        }
    }).toSortedList(Ordering.natural().onResultOf(new Function<ReplaceRequest, Integer>() {

        @Override
        public Integer apply(ReplaceRequest in) {
            return in.notes.getChangeId().get();
        }
    }));
    if (!updated.isEmpty()) {
        addMessage("");
        addMessage("Updated Changes:");
        boolean edit = magicBranch != null && magicBranch.edit;
        for (ReplaceRequest u : updated) {
            addMessage(formatChangeUrl(canonicalWebUrl, u.notes.getChange(), u.info.getSubject(), edit));
        }
        addMessage("");
    }
}
#method_after
private void reportMessages() {
    Iterable<CreateRequest> created = Iterables.filter(newChanges, new Predicate<CreateRequest>() {

        @Override
        public boolean apply(CreateRequest input) {
            return input.change != null;
        }
    });
    if (!Iterables.isEmpty(created)) {
        addMessage("");
        addMessage("New Changes:");
        for (CreateRequest c : created) {
            addMessage(formatChangeUrl(canonicalWebUrl, c.change, c.change.getSubject(), false));
        }
        addMessage("");
    }
    List<ReplaceRequest> updated = FluentIterable.from(replaceByChange.values()).filter(new Predicate<ReplaceRequest>() {

        @Override
        public boolean apply(ReplaceRequest input) {
            return !input.skip && input.inputCommand.getResult() == OK;
        }
    }).toSortedList(Ordering.natural().onResultOf(new Function<ReplaceRequest, Integer>() {

        @Override
        public Integer apply(ReplaceRequest in) {
            return in.notes.getChangeId().get();
        }
    }));
    if (!updated.isEmpty()) {
        addMessage("");
        addMessage("Updated Changes:");
        boolean edit = magicBranch != null && magicBranch.edit;
        for (ReplaceRequest u : updated) {
            String subject;
            if (edit) {
                try {
                    subject = rp.getRevWalk().parseCommit(u.newCommitId).getShortMessage();
                } catch (IOException e) {
                    // Log and fall back to original change subject
                    log.warn("failed to get subject for edit patch set", e);
                    subject = u.notes.getChange().getSubject();
                }
            } else {
                subject = u.info.getMessage();
            }
            addMessage(formatChangeUrl(canonicalWebUrl, u.notes.getChange(), subject, edit));
        }
        addMessage("");
    }
}
#end_block

#method_before
private void selectNewAndReplacedChangesFromMagicBranch() {
    newChanges = new ArrayList<>();
    SetMultimap<ObjectId, Ref> existing = changeRefsById();
    GroupCollector groupCollector = GroupCollector.create(refsById, db, psUtil, notesFactory, project.getNameKey());
    rp.getRevWalk().reset();
    rp.getRevWalk().sort(RevSort.TOPO);
    rp.getRevWalk().sort(RevSort.REVERSE, true);
    try {
        rp.getRevWalk().markStart(rp.getRevWalk().parseCommit(magicBranch.cmd.getNewId()));
        if (magicBranch.baseCommit != null) {
            for (RevCommit c : magicBranch.baseCommit) {
                rp.getRevWalk().markUninteresting(c);
            }
            Ref targetRef = allRefs.get(magicBranch.ctl.getRefName());
            if (targetRef != null) {
                rp.getRevWalk().markUninteresting(rp.getRevWalk().parseCommit(targetRef.getObjectId()));
            }
        } else {
            markHeadsAsUninteresting(rp.getRevWalk(), magicBranch.ctl != null ? magicBranch.ctl.getRefName() : null);
        }
        List<ChangeLookup> pending = new ArrayList<>();
        Set<Change.Key> newChangeIds = new HashSet<>();
        int maxBatchChanges = receiveConfig.getEffectiveMaxBatchChangesLimit(user);
        for (; ; ) {
            RevCommit c = rp.getRevWalk().next();
            if (c == null) {
                break;
            }
            groupCollector.visit(c);
            Collection<Ref> existingRefs = existing.get(c);
            if (!existingRefs.isEmpty()) {
                // A's group.
                for (Ref ref : existingRefs) {
                    updateGroups.add(new UpdateGroupsRequest(ref, c));
                }
                continue;
            }
            if (!validCommit(rp.getRevWalk(), magicBranch.ctl, magicBranch.cmd, c)) {
                // Not a change the user can propose? Abort as early as possible.
                newChanges = Collections.emptyList();
                return;
            }
            // Don't allow merges to be uploaded in commit chain via all-not-in-target
            if (newChangeForAllNotInTarget && c.getParentCount() > 1) {
                reject(magicBranch.cmd, "Pushing merges in commit chains with 'all not in target' is not allowed,\n" + "to override please set the base manually");
            }
            List<String> idList = c.getFooterLines(CHANGE_ID);
            if (idList.isEmpty()) {
                newChanges.add(new CreateRequest(c, magicBranch.dest.get()));
                continue;
            }
            String idStr = idList.get(idList.size() - 1).trim();
            if (idStr.matches("^I00*$")) {
                // Reject this invalid line from EGit.
                reject(magicBranch.cmd, "invalid Change-Id");
                newChanges = Collections.emptyList();
                return;
            }
            pending.add(new ChangeLookup(c, new Change.Key(idStr)));
            if (maxBatchChanges != 0 && pending.size() + newChanges.size() > maxBatchChanges) {
                reject(magicBranch.cmd, "the number of pushed changes in a batch exceeds the max limit " + maxBatchChanges);
                newChanges = Collections.emptyList();
                return;
            }
        }
        for (ChangeLookup p : pending) {
            if (newChangeIds.contains(p.changeKey)) {
                reject(magicBranch.cmd, SAME_CHANGE_ID_IN_MULTIPLE_CHANGES);
                newChanges = Collections.emptyList();
                return;
            }
            List<ChangeData> changes = p.destChanges;
            if (changes.size() > 1) {
                // WTF, multiple changes in this project have the same key?
                // Since the commit is new, the user should recreate it with
                // a different Change-Id. In practice, we should never see
                // this error message as Change-Id should be unique.
                // 
                reject(magicBranch.cmd, p.changeKey.get() + " has duplicates");
                newChanges = Collections.emptyList();
                return;
            }
            if (changes.size() == 1) {
                // 
                if (requestReplace(magicBranch.cmd, false, changes.get(0).change(), p.commit)) {
                    continue;
                }
                newChanges = Collections.emptyList();
                return;
            }
            if (changes.size() == 0) {
                if (!isValidChangeId(p.changeKey.get())) {
                    reject(magicBranch.cmd, "invalid Change-Id");
                    newChanges = Collections.emptyList();
                    return;
                }
                newChangeIds.add(p.changeKey);
            }
            newChanges.add(new CreateRequest(p.commit, magicBranch.dest.get()));
        }
    } catch (IOException e) {
        // Should never happen, the core receive process would have
        // identified the missing object earlier before we got control.
        // 
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        log.error("Invalid pack upload; one or more objects weren't sent", e);
        newChanges = Collections.emptyList();
        return;
    } catch (OrmException e) {
        log.error("Cannot query database to locate prior changes", e);
        reject(magicBranch.cmd, "database error");
        newChanges = Collections.emptyList();
        return;
    }
    if (newChanges.isEmpty() && replaceByChange.isEmpty()) {
        reject(magicBranch.cmd, "no new changes");
        return;
    }
    if (!newChanges.isEmpty() && magicBranch.edit) {
        reject(magicBranch.cmd, "edit is not supported for new changes");
        return;
    }
    try {
        SortedSetMultimap<ObjectId, String> groups = groupCollector.getGroups();
        for (CreateRequest create : newChanges) {
            batch.addCommand(create.cmd);
            create.groups = ImmutableList.copyOf(groups.get(create.commitId));
        }
        for (ReplaceRequest replace : replaceByChange.values()) {
            replace.groups = ImmutableList.copyOf(groups.get(replace.newCommitId));
        }
        for (UpdateGroupsRequest update : updateGroups) {
            update.groups = ImmutableList.copyOf((groups.get(update.commit)));
        }
    } catch (OrmException | NoSuchChangeException e) {
        log.error("Error collecting groups for changes", e);
        reject(magicBranch.cmd, "internal server error");
        return;
    }
}
#method_after
private void selectNewAndReplacedChangesFromMagicBranch() {
    newChanges = new ArrayList<>();
    SetMultimap<ObjectId, Ref> existing = changeRefsById();
    GroupCollector groupCollector = GroupCollector.create(changeRefsById(), db, psUtil, notesFactory, project.getNameKey());
    rp.getRevWalk().reset();
    rp.getRevWalk().sort(RevSort.TOPO);
    rp.getRevWalk().sort(RevSort.REVERSE, true);
    try {
        rp.getRevWalk().markStart(rp.getRevWalk().parseCommit(magicBranch.cmd.getNewId()));
        if (magicBranch.baseCommit != null) {
            for (RevCommit c : magicBranch.baseCommit) {
                rp.getRevWalk().markUninteresting(c);
            }
            Ref targetRef = allRefs.get(magicBranch.ctl.getRefName());
            if (targetRef != null) {
                rp.getRevWalk().markUninteresting(rp.getRevWalk().parseCommit(targetRef.getObjectId()));
            }
        } else {
            markHeadsAsUninteresting(rp.getRevWalk(), magicBranch.ctl != null ? magicBranch.ctl.getRefName() : null);
        }
        List<ChangeLookup> pending = new ArrayList<>();
        Set<Change.Key> newChangeIds = new HashSet<>();
        int maxBatchChanges = receiveConfig.getEffectiveMaxBatchChangesLimit(user);
        for (; ; ) {
            RevCommit c = rp.getRevWalk().next();
            if (c == null) {
                break;
            }
            groupCollector.visit(c);
            Collection<Ref> existingRefs = existing.get(c);
            if (!existingRefs.isEmpty()) {
                // different target branch.
                for (Ref ref : existingRefs) {
                    updateGroups.add(new UpdateGroupsRequest(ref, c));
                }
                if (!(newChangeForAllNotInTarget || magicBranch.base != null)) {
                    continue;
                }
            }
            if (!validCommit(rp.getRevWalk(), magicBranch.ctl, magicBranch.cmd, c)) {
                // Not a change the user can propose? Abort as early as possible.
                newChanges = Collections.emptyList();
                return;
            }
            // Don't allow merges to be uploaded in commit chain via all-not-in-target
            if (newChangeForAllNotInTarget && c.getParentCount() > 1) {
                reject(magicBranch.cmd, "Pushing merges in commit chains with 'all not in target' is not allowed,\n" + "to override please set the base manually");
            }
            List<String> idList = c.getFooterLines(CHANGE_ID);
            if (idList.isEmpty()) {
                newChanges.add(new CreateRequest(c, magicBranch.dest.get()));
                continue;
            }
            String idStr = idList.get(idList.size() - 1).trim();
            if (idStr.matches("^I00*$")) {
                // Reject this invalid line from EGit.
                reject(magicBranch.cmd, "invalid Change-Id");
                newChanges = Collections.emptyList();
                return;
            }
            pending.add(new ChangeLookup(c, new Change.Key(idStr)));
            if (maxBatchChanges != 0 && pending.size() + newChanges.size() > maxBatchChanges) {
                reject(magicBranch.cmd, "the number of pushed changes in a batch exceeds the max limit " + maxBatchChanges);
                newChanges = Collections.emptyList();
                return;
            }
        }
        for (Iterator<ChangeLookup> itr = pending.iterator(); itr.hasNext(); ) {
            ChangeLookup p = itr.next();
            if (newChangeIds.contains(p.changeKey)) {
                reject(magicBranch.cmd, SAME_CHANGE_ID_IN_MULTIPLE_CHANGES);
                newChanges = Collections.emptyList();
                return;
            }
            List<ChangeData> changes = p.destChanges;
            if (changes.size() > 1) {
                // WTF, multiple changes in this project have the same key?
                // Since the commit is new, the user should recreate it with
                // a different Change-Id. In practice, we should never see
                // this error message as Change-Id should be unique.
                // 
                reject(magicBranch.cmd, p.changeKey.get() + " has duplicates");
                newChanges = Collections.emptyList();
                return;
            }
            if (changes.size() == 1) {
                // Schedule as a replacement to this one matching change.
                // 
                RevId currentPs = changes.get(0).currentPatchSet().getRevision();
                // If Commit is already current PatchSet of target Change.
                if (p.commit.name().equals(currentPs.get())) {
                    if (pending.size() == 1) {
                        // There are no commits left to check, all commits in pending were already
                        // current PatchSet of the corresponding target changes.
                        reject(magicBranch.cmd, "commit(s) already exists (as current patchset)");
                    } else {
                        // Commit is already current PatchSet.
                        // Remove from pending and try next commit.
                        itr.remove();
                        continue;
                    }
                }
                if (requestReplace(magicBranch.cmd, false, changes.get(0).change(), p.commit)) {
                    continue;
                }
                newChanges = Collections.emptyList();
                return;
            }
            if (changes.size() == 0) {
                if (!isValidChangeId(p.changeKey.get())) {
                    reject(magicBranch.cmd, "invalid Change-Id");
                    newChanges = Collections.emptyList();
                    return;
                }
                newChangeIds.add(p.changeKey);
            }
            newChanges.add(new CreateRequest(p.commit, magicBranch.dest.get()));
        }
    } catch (IOException e) {
        // Should never happen, the core receive process would have
        // identified the missing object earlier before we got control.
        // 
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        log.error("Invalid pack upload; one or more objects weren't sent", e);
        newChanges = Collections.emptyList();
        return;
    } catch (OrmException e) {
        log.error("Cannot query database to locate prior changes", e);
        reject(magicBranch.cmd, "database error");
        newChanges = Collections.emptyList();
        return;
    }
    if (newChanges.isEmpty() && replaceByChange.isEmpty()) {
        reject(magicBranch.cmd, "no new changes");
        return;
    }
    if (!newChanges.isEmpty() && magicBranch.edit) {
        reject(magicBranch.cmd, "edit is not supported for new changes");
        return;
    }
    try {
        SortedSetMultimap<ObjectId, String> groups = groupCollector.getGroups();
        for (CreateRequest create : newChanges) {
            batch.addCommand(create.cmd);
            create.groups = ImmutableList.copyOf(groups.get(create.commitId));
        }
        for (ReplaceRequest replace : replaceByChange.values()) {
            replace.groups = ImmutableList.copyOf(groups.get(replace.newCommitId));
        }
        for (UpdateGroupsRequest update : updateGroups) {
            update.groups = ImmutableList.copyOf((groups.get(update.commit)));
        }
    } catch (OrmException | NoSuchChangeException e) {
        log.error("Error collecting groups for changes", e);
        reject(magicBranch.cmd, "internal server error");
        return;
    }
}
#end_block

#method_before
private void addOps(BatchUpdate bu) throws RestApiException {
    try {
        RevWalk rw = rp.getRevWalk();
        RevCommit commit = rw.parseCommit(commitId);
        rw.parseBody(commit);
        final PatchSet.Id psId = ins.setGroups(groups).getPatchSetId();
        Account.Id me = user.getAccountId();
        List<FooterLine> footerLines = commit.getFooterLines();
        MailRecipients recipients = new MailRecipients();
        Map<String, Short> approvals = new HashMap<>();
        checkNotNull(magicBranch);
        recipients.add(magicBranch.getMailRecipients());
        approvals = magicBranch.labels;
        recipients.add(getRecipientsFromFooters(accountResolver, magicBranch.draft, footerLines));
        recipients.remove(me);
        StringBuilder msg = new StringBuilder(ApprovalsUtil.renderMessageWithApprovals(psId.get(), approvals, Collections.<String, PatchSetApproval>emptyMap()));
        if (!Strings.isNullOrEmpty(magicBranch.message)) {
            msg.append("\n").append(magicBranch.message);
        }
        bu.insertChange(ins.setReviewers(recipients.getReviewers()).setExtraCC(recipients.getCcOnly()).setApprovals(approvals).setMessage(msg.toString()).setNotify(magicBranch.notify).setRequestScopePropagator(requestScopePropagator).setSendMail(true).setUpdateRef(true));
        if (!magicBranch.hashtags.isEmpty()) {
            bu.addOp(changeId, hashtagsFactory.create(new HashtagsInput(magicBranch.hashtags)).setRunHooks(false));
        }
        if (!Strings.isNullOrEmpty(magicBranch.topic)) {
            bu.addOp(changeId, new BatchUpdate.Op() {

                @Override
                public boolean updateChange(ChangeContext ctx) {
                    ctx.getUpdate(psId).setTopic(magicBranch.topic);
                    return true;
                }
            });
        }
        bu.addOp(changeId, new BatchUpdate.Op() {

            @Override
            public boolean updateChange(ChangeContext ctx) {
                change = ctx.getChange();
                return false;
            }
        });
        bu.addOp(changeId, new ChangeProgressOp(newProgress));
    } catch (Exception e) {
        throw INSERT_EXCEPTION.apply(e);
    }
}
#method_after
private void addOps(BatchUpdate bu) throws RestApiException {
    try {
        RevWalk rw = rp.getRevWalk();
        RevCommit commit = rw.parseCommit(commitId);
        rw.parseBody(commit);
        final PatchSet.Id psId = ins.setGroups(groups).getPatchSetId();
        Account.Id me = user.getAccountId();
        List<FooterLine> footerLines = commit.getFooterLines();
        MailRecipients recipients = new MailRecipients();
        Map<String, Short> approvals = new HashMap<>();
        checkNotNull(magicBranch);
        recipients.add(magicBranch.getMailRecipients());
        approvals = magicBranch.labels;
        recipients.add(getRecipientsFromFooters(accountResolver, magicBranch.draft, footerLines));
        recipients.remove(me);
        StringBuilder msg = new StringBuilder(ApprovalsUtil.renderMessageWithApprovals(psId.get(), approvals, Collections.<String, PatchSetApproval>emptyMap()));
        if (!Strings.isNullOrEmpty(magicBranch.message)) {
            msg.append("\n").append(magicBranch.message);
        }
        bu.insertChange(ins.setReviewers(recipients.getReviewers()).setExtraCC(recipients.getCcOnly()).setApprovals(approvals).setMessage(msg.toString()).setNotify(magicBranch.notify).setRequestScopePropagator(requestScopePropagator).setSendMail(true).setUpdateRef(true));
        if (!magicBranch.hashtags.isEmpty()) {
            bu.addOp(changeId, hashtagsFactory.create(new HashtagsInput(magicBranch.hashtags)).setFireEvent(false));
        }
        if (!Strings.isNullOrEmpty(magicBranch.topic)) {
            bu.addOp(changeId, new BatchUpdate.Op() {

                @Override
                public boolean updateChange(ChangeContext ctx) {
                    ctx.getUpdate(psId).setTopic(magicBranch.topic);
                    return true;
                }
            });
        }
        bu.addOp(changeId, new BatchUpdate.Op() {

            @Override
            public boolean updateChange(ChangeContext ctx) {
                change = ctx.getChange();
                return false;
            }
        });
        bu.addOp(changeId, new ChangeProgressOp(newProgress));
    } catch (Exception e) {
        throw INSERT_EXCEPTION.apply(e);
    }
}
#end_block

#method_before
private void submit(Collection<CreateRequest> create, Collection<ReplaceRequest> replace) throws OrmException, RestApiException {
    Map<ObjectId, Change> bySha = Maps.newHashMapWithExpectedSize(create.size() + replace.size());
    for (CreateRequest r : create) {
        checkNotNull(r.change, "cannot submit new change %s; op may not have run", r.changeId);
        bySha.put(r.commitId, r.change);
    }
    for (ReplaceRequest r : replace) {
        bySha.put(r.newCommitId, r.notes.getChange());
    }
    Change tipChange = bySha.get(magicBranch.cmd.getNewId());
    checkState(tipChange != null, "tip of push does not correspond to a change; found these changes: %s", bySha);
    try (MergeOp op = mergeOpProvider.get()) {
        op.merge(db, tipChange, user, false, new SubmitInput());
    }
}
#method_after
private void submit(Collection<CreateRequest> create, Collection<ReplaceRequest> replace) throws OrmException, RestApiException {
    Map<ObjectId, Change> bySha = Maps.newHashMapWithExpectedSize(create.size() + replace.size());
    for (CreateRequest r : create) {
        checkNotNull(r.change, "cannot submit new change %s; op may not have run", r.changeId);
        bySha.put(r.commitId, r.change);
    }
    for (ReplaceRequest r : replace) {
        bySha.put(r.newCommitId, r.notes.getChange());
    }
    Change tipChange = bySha.get(magicBranch.cmd.getNewId());
    checkNotNull(tipChange, "tip of push does not correspond to a change; found these changes: %s", bySha);
    try (MergeOp op = mergeOpProvider.get()) {
        op.merge(db, tipChange, user, false, new SubmitInput());
    }
}
#end_block

#method_before
boolean validate(boolean autoClose) throws IOException, OrmException {
    if (!autoClose && inputCommand.getResult() != NOT_ATTEMPTED) {
        return false;
    } else if (notes == null) {
        reject(inputCommand, "change " + ontoChange + " not found");
        return false;
    }
    priorPatchSet = notes.getChange().currentPatchSetId();
    if (!revisions.containsValue(priorPatchSet)) {
        reject(inputCommand, "change " + ontoChange + " missing revisions");
        return false;
    }
    RevCommit newCommit = rp.getRevWalk().parseCommit(newCommitId);
    RevCommit priorCommit = revisions.inverse().get(priorPatchSet);
    if (newCommit.equals(priorCommit)) {
        // Ignore requests to make the change its current state.
        skip = true;
        reject(inputCommand, "commit already exists (as current patchset)");
        return false;
    }
    changeCtl = projectControl.controlFor(notes);
    if (!changeCtl.canAddPatchSet(db)) {
        String locked = ".";
        if (changeCtl.isPatchSetLocked(db)) {
            locked = ". Change is patch set locked.";
        }
        reject(inputCommand, "cannot replace " + ontoChange + locked);
        return false;
    } else if (notes.getChange().getStatus().isClosed()) {
        reject(inputCommand, "change " + ontoChange + " closed");
        return false;
    } else if (revisions.containsKey(newCommit)) {
        reject(inputCommand, "commit already exists (in the change)");
        return false;
    }
    for (Ref r : rp.getRepository().getRefDatabase().getRefs("refs/changes").values()) {
        if (r.getObjectId().equals(newCommit)) {
            reject(inputCommand, "commit already exists (in the project)");
            return false;
        }
    }
    for (RevCommit prior : revisions.keySet()) {
        // amending when trying to address review comments.
        if (rp.getRevWalk().isMergedInto(prior, newCommit)) {
            reject(inputCommand, SAME_CHANGE_ID_IN_MULTIPLE_CHANGES);
            return false;
        }
    }
    if (!validCommit(rp.getRevWalk(), changeCtl.getRefControl(), inputCommand, newCommit)) {
        return false;
    }
    rp.getRevWalk().parseBody(priorCommit);
    // of the commit was modified.
    if (newCommit.getTree().equals(priorCommit.getTree())) {
        boolean messageEq = eq(newCommit.getFullMessage(), priorCommit.getFullMessage());
        boolean parentsEq = parentsEqual(newCommit, priorCommit);
        boolean authorEq = authorEqual(newCommit, priorCommit);
        ObjectReader reader = rp.getRevWalk().getObjectReader();
        if (messageEq && parentsEq && authorEq && !autoClose) {
            addMessage(String.format("(W) No changes between prior commit %s and new commit %s", reader.abbreviate(priorCommit).name(), reader.abbreviate(newCommit).name()));
        } else {
            StringBuilder msg = new StringBuilder();
            msg.append("(I) ");
            msg.append(reader.abbreviate(newCommit).name());
            msg.append(":");
            msg.append(" no files changed");
            if (!authorEq) {
                msg.append(", author changed");
            }
            if (!messageEq) {
                msg.append(", message updated");
            }
            if (!parentsEq) {
                msg.append(", was rebased");
            }
            addMessage(msg.toString());
        }
    }
    if (magicBranch != null && magicBranch.edit) {
        return newEdit();
    }
    newPatchSet();
    return true;
}
#method_after
boolean validate(boolean autoClose) throws IOException, OrmException {
    if (!autoClose && inputCommand.getResult() != NOT_ATTEMPTED) {
        return false;
    } else if (notes == null) {
        reject(inputCommand, "change " + ontoChange + " not found");
        return false;
    }
    priorPatchSet = notes.getChange().currentPatchSetId();
    if (!revisions.containsValue(priorPatchSet)) {
        reject(inputCommand, "change " + ontoChange + " missing revisions");
        return false;
    }
    RevCommit newCommit = rp.getRevWalk().parseCommit(newCommitId);
    RevCommit priorCommit = revisions.inverse().get(priorPatchSet);
    changeCtl = projectControl.controlFor(notes);
    if (!changeCtl.canAddPatchSet(db)) {
        String locked = ".";
        if (changeCtl.isPatchSetLocked(db)) {
            locked = ". Change is patch set locked.";
        }
        reject(inputCommand, "cannot replace " + ontoChange + locked);
        return false;
    } else if (notes.getChange().getStatus().isClosed()) {
        reject(inputCommand, "change " + ontoChange + " closed");
        return false;
    } else if (revisions.containsKey(newCommit)) {
        reject(inputCommand, "commit already exists (in the change)");
        return false;
    }
    for (Ref r : rp.getRepository().getRefDatabase().getRefs("refs/changes").values()) {
        if (r.getObjectId().equals(newCommit)) {
            reject(inputCommand, "commit already exists (in the project)");
            return false;
        }
    }
    for (RevCommit prior : revisions.keySet()) {
        // amending when trying to address review comments.
        if (rp.getRevWalk().isMergedInto(prior, newCommit)) {
            reject(inputCommand, SAME_CHANGE_ID_IN_MULTIPLE_CHANGES);
            return false;
        }
    }
    if (!validCommit(rp.getRevWalk(), changeCtl.getRefControl(), inputCommand, newCommit)) {
        return false;
    }
    rp.getRevWalk().parseBody(priorCommit);
    // of the commit was modified.
    if (newCommit.getTree().equals(priorCommit.getTree())) {
        boolean messageEq = eq(newCommit.getFullMessage(), priorCommit.getFullMessage());
        boolean parentsEq = parentsEqual(newCommit, priorCommit);
        boolean authorEq = authorEqual(newCommit, priorCommit);
        ObjectReader reader = rp.getRevWalk().getObjectReader();
        if (messageEq && parentsEq && authorEq && !autoClose) {
            addMessage(String.format("(W) No changes between prior commit %s and new commit %s", reader.abbreviate(priorCommit).name(), reader.abbreviate(newCommit).name()));
        } else {
            StringBuilder msg = new StringBuilder();
            msg.append("(I) ");
            msg.append(reader.abbreviate(newCommit).name());
            msg.append(":");
            msg.append(" no files changed");
            if (!authorEq) {
                msg.append(", author changed");
            }
            if (!messageEq) {
                msg.append(", message updated");
            }
            if (!parentsEq) {
                msg.append(", was rebased");
            }
            addMessage(msg.toString());
        }
    }
    if (magicBranch != null && magicBranch.edit) {
        return newEdit();
    }
    newPatchSet();
    return true;
}
#end_block

#method_before
private void validateNewCommits(RefControl ctl, ReceiveCommand cmd) {
    if (ctl.canForgeAuthor() && ctl.canForgeCommitter() && ctl.canForgeGerritServerIdentity() && ctl.canUploadMerges() && !projectControl.getProjectState().isUseSignedOffBy() && Iterables.isEmpty(rejectCommits) && !RefNames.REFS_CONFIG.equals(ctl.getRefName()) && !(MagicBranch.isMagicBranch(cmd.getRefName()) || NEW_PATCHSET.matcher(cmd.getRefName()).matches())) {
        return;
    }
    boolean defaultName = Strings.isNullOrEmpty(user.getAccount().getFullName());
    RevWalk walk = rp.getRevWalk();
    walk.reset();
    walk.sort(RevSort.NONE);
    try {
        RevObject parsedObject = walk.parseAny(cmd.getNewId());
        if (!(parsedObject instanceof RevCommit)) {
            return;
        }
        walk.markStart((RevCommit) parsedObject);
        markHeadsAsUninteresting(walk, cmd.getRefName());
        Set<ObjectId> existing = changeRefsById().keySet();
        for (RevCommit c; (c = walk.next()) != null; ) {
            if (existing.contains(c)) {
                continue;
            } else if (!validCommit(walk, ctl, cmd, c)) {
                break;
            }
            if (defaultName && user.hasEmailAddress(c.getCommitterIdent().getEmailAddress())) {
                try {
                    Account a = db.accounts().get(user.getAccountId());
                    if (a != null && Strings.isNullOrEmpty(a.getFullName())) {
                        a.setFullName(c.getCommitterIdent().getName());
                        db.accounts().update(Collections.singleton(a));
                        user.getAccount().setFullName(a.getFullName());
                        accountCache.evict(a.getId());
                    }
                } catch (OrmException e) {
                    log.warn("Cannot default full_name", e);
                } finally {
                    defaultName = false;
                }
            }
        }
    } catch (IOException err) {
        cmd.setResult(REJECTED_MISSING_OBJECT);
        log.error("Invalid pack upload; one or more objects weren't sent", err);
    }
}
#method_after
private void validateNewCommits(RefControl ctl, ReceiveCommand cmd) {
    if (ctl.canForgeAuthor() && ctl.canForgeCommitter() && ctl.canForgeGerritServerIdentity() && ctl.canUploadMerges() && !projectControl.getProjectState().isUseSignedOffBy() && Iterables.isEmpty(rejectCommits) && !RefNames.REFS_CONFIG.equals(ctl.getRefName()) && !(MagicBranch.isMagicBranch(cmd.getRefName()) || NEW_PATCHSET.matcher(cmd.getRefName()).matches())) {
        return;
    }
    boolean defaultName = Strings.isNullOrEmpty(user.getAccount().getFullName());
    RevWalk walk = rp.getRevWalk();
    walk.reset();
    walk.sort(RevSort.NONE);
    try {
        RevObject parsedObject = walk.parseAny(cmd.getNewId());
        if (!(parsedObject instanceof RevCommit)) {
            return;
        }
        SetMultimap<ObjectId, Ref> existing = changeRefsById();
        walk.markStart((RevCommit) parsedObject);
        markHeadsAsUninteresting(walk, cmd.getRefName());
        for (RevCommit c; (c = walk.next()) != null; ) {
            if (existing.keySet().contains(c)) {
                continue;
            } else if (!validCommit(walk, ctl, cmd, c)) {
                break;
            }
            if (defaultName && user.hasEmailAddress(c.getCommitterIdent().getEmailAddress())) {
                try {
                    Account a = db.accounts().get(user.getAccountId());
                    if (a != null && Strings.isNullOrEmpty(a.getFullName())) {
                        a.setFullName(c.getCommitterIdent().getName());
                        db.accounts().update(Collections.singleton(a));
                        user.getAccount().setFullName(a.getFullName());
                        accountCache.evict(a.getId());
                    }
                } catch (OrmException e) {
                    log.warn("Cannot default full_name", e);
                } finally {
                    defaultName = false;
                }
            }
        }
    } catch (IOException err) {
        cmd.setResult(REJECTED_MISSING_OBJECT);
        log.error("Invalid pack upload; one or more objects weren't sent", err);
    }
}
#end_block

#method_before
@Override
public String getUrl() {
    String database = cfg.getString("database", null, "database");
    Boolean autoserver = cfg.getBoolean("database", "h2", "autoServer", false);
    if (database == null || database.isEmpty()) {
        database = "db/ReviewDB";
    }
    return "jdbc:h2:" + site.resolve(database).toUri().toString() + (autoserver ? ";AUTO_SERVER=TRUE" : "");
}
#method_after
@Override
public String getUrl() {
    String database = cfg.getString("database", null, "database");
    if (database == null || database.isEmpty()) {
        database = "db/ReviewDB";
    }
    return appendUrlOptions(cfg, createUrl(site.resolve(database)));
}
#end_block

#method_before
@Before
public void setUp() throws Exception {
    Injector injector = Guice.createInjector(new InMemoryModule());
    injector.injectMembers(this);
    lifecycle = new LifecycleManager();
    lifecycle.add(injector);
    lifecycle.start();
    db = schemaFactory.open();
    schemaCreator.create(db);
    // Need create at least one user to be admin before create a "normal"
    // registered user, refer AccountManager#create()
    accountManager.authenticate(AuthRequest.forUser("admin")).getAccountId();
    admins = groupCache.get(new AccountGroup.NameKey("Administrators")).getGroupUUID();
    setUpPermissions();
    Account.Id userId = accountManager.authenticate(AuthRequest.forUser("user")).getAccountId();
    user = userFactory.create(userId);
    Project.NameKey name = new Project.NameKey("project");
    InMemoryRepository inMemoryRepo = repoManager.createRepository(name);
    project = new ProjectConfig(name);
    project.load(inMemoryRepo);
    repo = new TestRepository<>(inMemoryRepo);
    requestContext.setContext(new RequestContext() {

        @Override
        public CurrentUser getUser() {
            return user;
        }

        @Override
        public Provider<ReviewDb> getReviewDbProvider() {
            return Providers.of(db);
        }
    });
}
#method_after
@Before
public void setUp() throws Exception {
    Injector injector = Guice.createInjector(new InMemoryModule());
    injector.injectMembers(this);
    lifecycle = new LifecycleManager();
    lifecycle.add(injector);
    lifecycle.start();
    db = schemaFactory.open();
    schemaCreator.create(db);
    // Need to create at least one user to be admin before creating a "normal"
    // registered user.
    // See AccountManager#create().
    accountManager.authenticate(AuthRequest.forUser("admin")).getAccountId();
    admins = groupCache.get(new AccountGroup.NameKey("Administrators")).getGroupUUID();
    setUpPermissions();
    Account.Id userId = accountManager.authenticate(AuthRequest.forUser("user")).getAccountId();
    user = userFactory.create(userId);
    Project.NameKey name = new Project.NameKey("project");
    InMemoryRepository inMemoryRepo = repoManager.createRepository(name);
    project = new ProjectConfig(name);
    project.load(inMemoryRepo);
    repo = new TestRepository<>(inMemoryRepo);
    requestContext.setContext(new RequestContext() {

        @Override
        public CurrentUser getUser() {
            return user;
        }

        @Override
        public Provider<ReviewDb> getReviewDbProvider() {
            return Providers.of(db);
        }
    });
}
#end_block

#method_before
private void setUpPermissions() throws Exception {
    // Remove read permissions for all users besides admin, because by default
    // Anonymous user group have ALLOW READ permission in refs/*.
    // This method is idempotent, so is safe to call on every test setup.
    ProjectConfig pc = projectCache.checkedGet(allProjects).getConfig();
    for (AccessSection sec : pc.getAccessSections()) {
        sec.removePermission(Permission.READ);
    }
    allow(pc, Permission.READ, admins, "refs/*");
}
#method_after
private void setUpPermissions() throws Exception {
    // Remove read permissions for all users besides admin, because by default
    // Anonymous user group has ALLOW READ permission in refs/*.
    // This method is idempotent, so is safe to call on every test setup.
    ProjectConfig pc = projectCache.checkedGet(allProjects).getConfig();
    for (AccessSection sec : pc.getAccessSections()) {
        sec.removePermission(Permission.READ);
    }
    allow(pc, Permission.READ, admins, "refs/*");
}
#end_block

#method_before
public final Watchers getWatchers(NotifyType type) throws OrmException {
    Watchers matching = new Watchers();
    Set<Account.Id> projectWatchers = new HashSet<>();
    for (AccountState a : args.accountQueryProvider.get().byWatchedProject(project)) {
        for (AccountProjectWatch w : a.getProjectWatches()) {
            if (add(matching, w, type)) {
                // We only want to prevent matching All-Projects if this filter hits
                projectWatchers.add(w.getAccountId());
            }
        }
    }
    for (AccountState a : args.accountQueryProvider.get().byWatchedProject(args.allProjectsName)) {
        for (AccountProjectWatch w : a.getProjectWatches()) {
            if (!projectWatchers.contains(w.getAccountId())) {
                add(matching, w, type);
            }
        }
    }
    for (ProjectState state : projectState.tree()) {
        for (NotifyConfig nc : state.getConfig().getNotifyConfigs()) {
            if (nc.isNotify(type)) {
                try {
                    add(matching, nc);
                } catch (QueryParseException e) {
                    log.warn("Project {} has invalid notify {} filter \"{}\": {}", state.getProject().getName(), nc.getName(), nc.getFilter(), e.getMessage());
                }
            }
        }
    }
    return matching;
}
#method_after
public final Watchers getWatchers(NotifyType type) throws OrmException {
    Watchers matching;
    if (args.accountIndexes.getSearchIndex() != null) {
        matching = getWatchersFromIndex(type);
    } else {
        matching = getWatchersFromDb(type);
    }
    for (ProjectState state : projectState.tree()) {
        for (NotifyConfig nc : state.getConfig().getNotifyConfigs()) {
            if (nc.isNotify(type)) {
                try {
                    add(matching, nc);
                } catch (QueryParseException e) {
                    log.warn("Project {} has invalid notify {} filter \"{}\": {}", state.getProject().getName(), nc.getName(), nc.getFilter(), e.getMessage());
                }
            }
        }
    }
    return matching;
}
#end_block

