424
#method_before
@Override
public void run() throws UnloggedFailure, Failure, Exception {
    if (!currentUser.getCapabilities().canAdministrateServer()) {
        stdout.println("You must be a Gerrit Administrator to run this command.  Goodbye");
        return;
    }
    if (name.isEmpty()) {
        stdout.print("You need to tell me who to find:  LastName,\\ Firstname, email@address.com, account id or an user name.  Be sure to double-escape spaces, for example: \"show-account Last,\\\\ First\"");
        return;
    }
    Set<Id> idList = accountResolver.findAll(name);
    if (idList.isEmpty()) {
        stdout.println("No accounts found for your query: \"" + name + "\"");
        stdout.println("Tip: Try double-escaping spaces, for example: \"show-account Last,\\\\ First\"");
        return;
    } else {
        stdout.println("Found " + idList.size() + " result" + (idList.size() > 1 ? "s" : "") + ": for query: \"" + name + "\"");
        stdout.println();
    }
    for (Id id : idList) {
        account = accountResolver.find(id.toString());
        stdout.println("Full name:         " + account.getFullName());
        stdout.println("Preferred Email:   " + account.getPreferredEmail());
        stdout.println("User Name:         " + account.getUserName());
        stdout.println("Active:            " + account.isActive());
        stdout.println("Registered on:     " + account.getRegisteredOn());
        final ReviewDb db = schema.open();
        stdout.println("");
        stdout.println("External Ids:");
        stdout.println(String.format("%-50s %s", "Email Address:", "External Id:"));
        for (AccountExternalId accountExternalId : db.accountExternalIds().byAccount(account.getId())) {
            stdout.println(String.format("%-50s %s", (accountExternalId.getEmailAddress() == null ? "" : accountExternalId.getEmailAddress()), accountExternalId.getExternalId()));
        }
        if (showKeys) {
            stdout.println("");
            stdout.println("Public Keys:");
            stdout.println(String.format("%-9s %s", "Status:", "Key:"));
            for (AccountSshKey sshKey : db.accountSshKeys().byAccount(account.getId())) {
                stdout.println(String.format("%-9s %s", (sshKey.isValid() ? "Active" : "Inactive"), sshKey.getSshPublicKey()));
            }
        }
        db.close();
        if (showGroups) {
            stdout.println();
            stdout.println("Member of groups" + (filterGroups == null ? "" : " (Filtering on \"" + filterGroups + "\")") + ":");
            List<GroupInfo> groupInfos = accountGetGroups.get().apply(new AccountResource(userFactory.create(id)));
            Collections.sort(groupInfos, new CustomComparator());
            for (GroupInfo groupInfo : groupInfos) {
                if (null == filterGroups || groupInfo.name.toLowerCase().contains(filterGroups.toLowerCase())) {
                    stdout.println(groupInfo.name);
                }
            }
        }
        stdout.println("");
    }
}
#method_after
@Override
public void run() throws UnloggedFailure, Failure, Exception {
    Account account;
    if (!currentUser.getCapabilities().canAdministrateServer()) {
        stdout.println("You must be a Gerrit Administrator to run this command.  Goodbye");
        return;
    }
    if (name.isEmpty()) {
        stdout.print("You need to tell me who to find:  LastName,\\ Firstname, email@address.com, account id or an user name.  Be sure to double-escape spaces, for example: \"show-account Last,\\\\ First\"");
        return;
    }
    Set<Id> idList = accountResolver.findAll(name);
    if (idList.isEmpty()) {
        stdout.println("No accounts found for your query: \"" + name + "\"");
        stdout.println("Tip: Try double-escaping spaces, for example: \"show-account Last,\\\\ First\"");
        return;
    } else {
        stdout.println("Found " + idList.size() + " result" + (idList.size() > 1 ? "s" : "") + ": for query: \"" + name + "\"");
        stdout.println();
    }
    for (Id id : idList) {
        account = accountResolver.find(id.toString());
        stdout.println("Full name:         " + account.getFullName());
        stdout.println("Account Id:        " + id.toString());
        stdout.println("Preferred Email:   " + account.getPreferredEmail());
        stdout.println("User Name:         " + account.getUserName());
        stdout.println("Active:            " + account.isActive());
        stdout.println("Registered on:     " + account.getRegisteredOn());
        final ReviewDb db = schema.open();
        stdout.println("");
        stdout.println("External Ids:");
        stdout.println(String.format("%-50s %s", "Email Address:", "External Id:"));
        for (AccountExternalId accountExternalId : db.accountExternalIds().byAccount(account.getId())) {
            stdout.println(String.format("%-50s %s", (accountExternalId.getEmailAddress() == null ? "" : accountExternalId.getEmailAddress()), accountExternalId.getExternalId()));
        }
        if (showKeys) {
            stdout.println("");
            stdout.println("Public Keys:");
            List<AccountSshKey> sshKeys = db.accountSshKeys().byAccount(account.getId()).toList();
            if (sshKeys == null || sshKeys.isEmpty()) {
                stdout.println("None");
            } else {
                stdout.println(String.format("%-9s %s", "Status:", "Key:"));
                for (AccountSshKey sshKey : sshKeys) {
                    stdout.println(String.format("%-9s %s", (sshKey.isValid() ? "Active" : "Inactive"), sshKey.getSshPublicKey()));
                }
            }
        }
        db.close();
        if (showGroups) {
            stdout.println();
            stdout.println("Member of groups" + (filterGroups == null ? "" : " (Filtering on \"" + filterGroups + "\")") + ":");
            List<GroupInfo> groupInfos = accountGetGroups.get().apply(new AccountResource(userFactory.create(id)));
            Collections.sort(groupInfos, new CustomComparator());
            for (GroupInfo groupInfo : groupInfos) {
                if (null == filterGroups) {
                    stdout.println(groupInfo.name);
                }
            }
        }
        stdout.println("");
    }
}
#end_block

#method_before
@Override
public boolean isChangeUpToDate(Optional<ChangeIndexEvent> indexEvent) throws IOException {
    getComputedChangeTs();
    if (!computedChangeTs.isPresent()) {
        log.warn("Unable to compute last updated ts for change {}", changeId);
        return true;
    }
    if (indexEvent.isPresent() && indexEvent.get().targetSha == null) {
        return indexEvent.map(e -> (computedChangeTs.get() >= e.eventCreatedOn)).orElse(true);
    }
    return indexEvent.map(e -> (computedChangeTs.get() > e.eventCreatedOn) || (computedChangeTs.get() == e.eventCreatedOn) && (Objects.equals(getBranchTargetSha(), e.targetSha))).orElse(true);
}
#method_after
@Override
public boolean isChangeUpToDate(Optional<ChangeIndexEvent> indexEvent) {
    getComputedChangeTs();
    if (!computedChangeTs.isPresent()) {
        log.warn("Unable to compute last updated ts for change {}", changeId);
        return true;
    }
    if (indexEvent.isPresent() && indexEvent.get().targetSha == null) {
        return indexEvent.map(e -> (computedChangeTs.get() >= e.eventCreatedOn)).orElse(true);
    }
    return indexEvent.map(e -> (computedChangeTs.get() > e.eventCreatedOn) || (computedChangeTs.get() == e.eventCreatedOn) && (Objects.equals(getBranchTargetSha(), e.targetSha))).orElse(true);
}
#end_block

#method_before
@Override
public Optional<Long> getComputedChangeTs() throws IOException {
    if (!computedChangeTs.isPresent()) {
        computedChangeTs = computeLastChangeTs();
    }
    return computedChangeTs;
}
#method_after
@Override
public Optional<Long> getComputedChangeTs() {
    if (!computedChangeTs.isPresent()) {
        computedChangeTs = computeLastChangeTs();
    }
    return computedChangeTs;
}
#end_block

#method_before
@Override
public String toString() {
    try {
        return "change-id=" + changeId + "@" + getComputedChangeTs().map(ChangeIndexEvent::format) + "/" + getBranchTargetSha();
    } catch (IOException e) {
        log.error("Unable to render change {}", changeId, e);
        return "change-id=" + changeId;
    }
}
#method_after
@Override
public String toString() {
    return "change-id=" + changeId + "@" + getComputedChangeTs().map(ChangeIndexEvent::format) + "/" + getBranchTargetSha();
}
#end_block

#method_before
@Override
protected void doIndex(String uuid, Optional<GroupIndexEvent> event) throws IOException {
    indexer.index(new AccountGroup.UUID(uuid));
    log.debug("Group {} successfully indexed", uuid);
}
#method_after
@Override
protected void doIndex(String uuid, Optional<GroupIndexEvent> event) {
    indexer.index(new AccountGroup.UUID(uuid));
    log.debug("Group {} successfully indexed", uuid);
}
#end_block

#method_before
@Override
protected void doIndex(String id, Optional<ChangeIndexEvent> indexEvent) throws IOException {
    doIndex(id, indexEvent, 0);
}
#method_after
@Override
protected void doIndex(String id, Optional<ChangeIndexEvent> indexEvent) {
    doIndex(id, indexEvent, 0);
}
#end_block

#method_before
private void doIndex(String id, Optional<ChangeIndexEvent> indexEvent, int retryCount) throws IOException {
    try {
        ChangeChecker checker = changeCheckerFactory.create(id);
        Optional<ChangeNotes> changeNotes = checker.getChangeNotes();
        if (changeNotes.isPresent()) {
            ChangeNotes notes = changeNotes.get();
            reindex(notes);
            if (checker.isChangeUpToDate(indexEvent)) {
                if (retryCount > 0) {
                    log.warn("Change {} has been eventually indexed after {} attempt(s)", id, retryCount);
                } else {
                    log.debug("Change {} successfully indexed", id);
                }
            } else {
                log.warn("Change {} seems too old compared to the event timestamp (event={} >> change-Ts={})", id, indexEvent, checker);
                rescheduleIndex(id, indexEvent, retryCount + 1);
            }
        } else {
            log.warn("Change {} not present yet in local Git repository (event={}) after {} attempt(s)", id, indexEvent, retryCount);
            if (!rescheduleIndex(id, indexEvent, retryCount + 1)) {
                log.error("Change {} could not be found in the local Git repository (event={})", id, indexEvent);
            }
        }
    } catch (Exception e) {
        if (isCausedByNoSuchChangeException(e)) {
            indexer.delete(parseChangeId(id));
            log.warn("Error trying to index Change {}. Deleted from index", id, e);
            return;
        }
        throw e;
    }
}
#method_after
private void doIndex(String id, Optional<ChangeIndexEvent> indexEvent, int retryCount) {
    ChangeChecker checker = changeCheckerFactory.create(id);
    Optional<ChangeNotes> changeNotes = checker.getChangeNotes();
    if (changeNotes.isPresent()) {
        ChangeNotes notes = changeNotes.get();
        reindex(notes);
        if (checker.isChangeUpToDate(indexEvent)) {
            if (retryCount > 0) {
                log.warn("Change {} has been eventually indexed after {} attempt(s)", id, retryCount);
            } else {
                log.debug("Change {} successfully indexed", id);
            }
        } else {
            log.warn("Change {} seems too old compared to the event timestamp (event={} >> change-Ts={})", id, indexEvent, checker);
            rescheduleIndex(id, indexEvent, retryCount + 1);
        }
    } else {
        log.warn("Change {} not present yet in local Git repository (event={}) after {} attempt(s)", id, indexEvent, retryCount);
        if (!rescheduleIndex(id, indexEvent, retryCount + 1)) {
            log.error("Change {} could not be found in the local Git repository (event={})", id, indexEvent);
        }
    }
}
#end_block

#method_before
private void reindex(ChangeNotes notes) throws IOException {
    try (ManualRequestContext ctx = oneOffCtx.open()) {
        notes.reload();
        indexer.index(notes.getChange());
    }
}
#method_after
private void reindex(ChangeNotes notes) {
    try (ManualRequestContext ctx = oneOffCtx.open()) {
        notes.reload();
        indexer.index(notes.getChange());
    }
}
#end_block

#method_before
@Override
protected void doDelete(String id, Optional<ChangeIndexEvent> indexEvent) throws IOException {
    indexer.delete(parseChangeId(id));
    log.debug("Change {} successfully deleted from index", id);
}
#method_after
@Override
protected void doDelete(String id, Optional<ChangeIndexEvent> indexEvent) {
    indexer.delete(parseChangeId(id));
    log.debug("Change {} successfully deleted from index", id);
}
#end_block

#method_before
public Path getForBackend(LfsBackend backend, boolean ensure) throws IOException {
    String dataDir = configFactory.getGlobalConfig().getString(backend.type.name(), backend.name, KEY_DIRECTORY);
    if (Strings.isNullOrEmpty(dataDir)) {
        return defaultDataDir;
    }
    if (ensure) {
        // note that the following method not only creates missing
        // directory/directories but throws exception when path
        // exists and points to file
        Path ensured = Files.createDirectories(Paths.get(dataDir.toString()));
        // we should at least make sure that directory is readable
        if (!Files.isReadable(ensured)) {
            throw new IOException("Path '" + ensured.toAbsolutePath() + "' cannot be accessed");
        }
        return ensured;
    }
    return Paths.get(dataDir);
}
#method_after
public Path getForBackend(LfsBackend backend, boolean ensure) throws IOException {
    String dataDir = configFactory.getGlobalConfig().getString(backend.type.name(), backend.name, KEY_DIRECTORY);
    if (Strings.isNullOrEmpty(dataDir)) {
        return defaultDataDir;
    }
    if (ensure) {
        // note that the following method not only creates missing
        // directory/directories but throws exception when path
        // exists and points to file
        Path ensured = Files.createDirectories(Paths.get(dataDir));
        // we should at least make sure that directory is readable
        if (!Files.isReadable(ensured)) {
            throw new IOException("Path '" + ensured.toAbsolutePath() + "' cannot be accessed");
        }
        return ensured;
    }
    return Paths.get(dataDir);
}
#end_block

#method_before
private List<PGPPublicKeyRing> get(long keyId, byte[] fp) throws IOException {
    if (reader == null) {
        load();
    }
    if (notes == null) {
        return Collections.emptyList();
    }
    ObjectId keyObjectId = keyObjectId(keyId);
    Note note = notes.getNote(keyObjectId);
    if (note == null) {
        return Collections.emptyList();
    }
    boolean foundAtLeastOneKey = false;
    List<PGPPublicKeyRing> keys = new ArrayList<>();
    try (InputStream in = reader.open(note.getData(), OBJ_BLOB).openStream()) {
        while (true) {
            @SuppressWarnings("unchecked")
            Iterator<Object> it = new BcPGPObjectFactory(new ArmoredInputStream(in)).iterator();
            if (!it.hasNext()) {
                break;
            }
            foundAtLeastOneKey = true;
            Object obj = it.next();
            if (obj instanceof PGPPublicKeyRing) {
                PGPPublicKeyRing kr = (PGPPublicKeyRing) obj;
                if (fp == null || Arrays.equals(fp, kr.getPublicKey().getFingerprint())) {
                    keys.add(kr);
                }
            }
            checkState(!it.hasNext(), "expected one PGP object per ArmoredInputStream");
        }
        if (foundAtLeastOneKey) {
            return keys;
        }
        // Subkey handling
        try (InputStream in2 = reader.open(note.getData(), OBJ_BLOB).openStream()) {
            return get(NB.decodeInt64(ByteStreams.toByteArray(in2), 0), fp);
        }
    }
}
#method_after
private List<PGPPublicKeyRing> get(long keyId, byte[] fp) throws IOException {
    if (reader == null) {
        load();
    }
    if (notes == null) {
        return Collections.emptyList();
    }
    return get(keyObjectId(keyId), fp);
}
#end_block

#method_before
private List<PGPPublicKeyRing> get(long keyId, byte[] fp) throws IOException {
    if (reader == null) {
        load();
    }
    if (notes == null) {
        return Collections.emptyList();
    }
    ObjectId keyObjectId = keyObjectId(keyId);
    Note note = notes.getNote(keyObjectId);
    if (note == null) {
        return Collections.emptyList();
    }
    boolean foundAtLeastOneKey = false;
    List<PGPPublicKeyRing> keys = new ArrayList<>();
    try (InputStream in = reader.open(note.getData(), OBJ_BLOB).openStream()) {
        while (true) {
            @SuppressWarnings("unchecked")
            Iterator<Object> it = new BcPGPObjectFactory(new ArmoredInputStream(in)).iterator();
            if (!it.hasNext()) {
                break;
            }
            foundAtLeastOneKey = true;
            Object obj = it.next();
            if (obj instanceof PGPPublicKeyRing) {
                PGPPublicKeyRing kr = (PGPPublicKeyRing) obj;
                if (fp == null || Arrays.equals(fp, kr.getPublicKey().getFingerprint())) {
                    keys.add(kr);
                }
            }
            checkState(!it.hasNext(), "expected one PGP object per ArmoredInputStream");
        }
        if (foundAtLeastOneKey) {
            return keys;
        }
        // Subkey handling
        try (InputStream in2 = reader.open(note.getData(), OBJ_BLOB).openStream()) {
            return get(NB.decodeInt64(ByteStreams.toByteArray(in2), 0), fp);
        }
    }
}
#method_after
private List<PGPPublicKeyRing> get(ObjectId keyObjectId, byte[] fp) throws IOException {
    Note note = notes.getNote(keyObjectId);
    if (note == null) {
        return Collections.emptyList();
    }
    return readKeysFromNote(note, fp);
}
#end_block

#method_before
private void saveToNotes(ObjectInserter ins, PGPPublicKeyRing keyRing) throws PGPException, IOException {
    long masterKeyId = keyRing.getPublicKey().getKeyID();
    PGPPublicKeyRingCollection existing = get(masterKeyId);
    List<PGPPublicKeyRing> toWrite = new ArrayList<>(existing.size() + 1);
    boolean replaced = false;
    for (PGPPublicKeyRing kr : existing) {
        if (sameKey(keyRing, kr)) {
            toWrite.add(keyRing);
            replaced = true;
        } else {
            toWrite.add(kr);
        }
    }
    if (!replaced) {
        toWrite.add(keyRing);
    }
    ObjectId masterKeyObjectId = keyObjectId(masterKeyId);
    notes.set(masterKeyObjectId, ins.insert(OBJ_BLOB, keysToArmored(toWrite)));
    // Subkey to master key
    byte[] masterKeyBytes = masterKeyObjectId.name().getBytes(UTF_8);
    for (PGPPublicKey key : keyRing) {
        long subKeyId = key.getKeyID();
        // Skip master public key
        if (masterKeyId == subKeyId) {
            continue;
        }
        notes.set(keyObjectId(subKeyId), ins.insert(OBJ_BLOB, masterKeyBytes));
    }
}
#method_after
private void saveToNotes(ObjectInserter ins, PGPPublicKeyRing keyRing) throws PGPException, IOException {
    long masterKeyId = keyRing.getPublicKey().getKeyID();
    PGPPublicKeyRingCollection existing = get(masterKeyId);
    List<PGPPublicKeyRing> toWrite = new ArrayList<>(existing.size() + 1);
    boolean replaced = false;
    for (PGPPublicKeyRing kr : existing) {
        if (sameKey(keyRing, kr)) {
            toWrite.add(keyRing);
            replaced = true;
        } else {
            toWrite.add(kr);
        }
    }
    if (!replaced) {
        toWrite.add(keyRing);
    }
    ObjectId masterKeyObjectId = keyObjectId(masterKeyId);
    notes.set(masterKeyObjectId, ins.insert(OBJ_BLOB, keysToArmored(toWrite)));
    saveSubkeyMaping(ins, keyRing, masterKeyId, masterKeyObjectId);
}
#end_block

#method_before
private void deleteFromNotes(ObjectInserter ins, Fingerprint fp) throws PGPException, IOException {
    long keyId = fp.getId();
    PGPPublicKeyRingCollection existing = get(keyId);
    List<PGPPublicKeyRing> toWrite = new ArrayList<>(existing.size());
    for (PGPPublicKeyRing kr : existing) {
        if (!fp.equalsBytes(kr.getPublicKey().getFingerprint())) {
            toWrite.add(kr);
        }
    }
    if (toWrite.size() == existing.size()) {
        return;
    }
    ObjectId keyObjectId = keyObjectId(keyId);
    if (!toWrite.isEmpty()) {
        notes.set(keyObjectId, ins.insert(OBJ_BLOB, keysToArmored(toWrite)));
    } else {
        notes.remove(keyObjectId);
        // TODO(davido): It shouldn't be needed to retrieve the key ring again to invalidate subkey
        // cache. The removal of key ring is not a common operation, though.
        PGPPublicKeyRing keyRing = get(fp.get());
        for (PGPPublicKey key : keyRing) {
            long subKeyId = key.getKeyID();
            // Skip master public key
            if (keyId == subKeyId) {
                continue;
            }
            notes.remove(keyObjectId(subKeyId));
        }
    }
}
#method_after
private void deleteFromNotes(ObjectInserter ins, Fingerprint fp) throws PGPException, IOException {
    long keyId = fp.getId();
    PGPPublicKeyRingCollection existing = get(keyId);
    List<PGPPublicKeyRing> toWrite = new ArrayList<>(existing.size());
    for (PGPPublicKeyRing kr : existing) {
        if (!fp.equalsBytes(kr.getPublicKey().getFingerprint())) {
            toWrite.add(kr);
        }
    }
    if (toWrite.size() == existing.size()) {
        return;
    }
    ObjectId keyObjectId = keyObjectId(keyId);
    if (!toWrite.isEmpty()) {
        notes.set(keyObjectId, ins.insert(OBJ_BLOB, keysToArmored(toWrite)));
    } else {
        PGPPublicKeyRing keyRing = get(fp.get());
        for (PGPPublicKey key : keyRing) {
            long subKeyId = key.getKeyID();
            // Skip master public key
            if (keyId == subKeyId) {
                continue;
            }
            notes.remove(keyObjectId(subKeyId));
        }
        notes.remove(keyObjectId);
    }
}
#end_block

#method_before
private void service() throws IOException, OrmException, PermissionBackendException, Failure {
    project = projectState.getProject();
    projectName = project.getNameKey();
    try {
        repo = repoManager.openRepository(projectName);
    } catch (RepositoryNotFoundException e) {
        throw new Failure(1, "fatal: '" + project.getName() + "': not a git archive", e);
    }
    try {
        runImpl();
    } finally {
        repo.close();
    }
}
#method_after
private void service() throws IOException, PermissionBackendException, Failure {
    project = projectState.getProject();
    projectName = project.getNameKey();
    try {
        repo = repoManager.openRepository(projectName);
    } catch (RepositoryNotFoundException e) {
        throw new Failure(1, "fatal: '" + project.getName() + "': not a git archive", e);
    }
    try {
        runImpl();
    } finally {
        repo.close();
    }
}
#end_block

#method_before
private void addReviewers(Set<Account.Id> topReviewers, Change change) {
    try {
        ChangeResource changeResource = changes.parse(change.getId());
        PostReviewers post = reviewersProvider.get();
        for (Account.Id accountId : topReviewers) {
            AddReviewerInput input = new AddReviewerInput();
            input.reviewer = accountId.toString();
            post.apply(changeResource, input);
        }
    } catch (Exception ex) {
        log.error("Couldn't add reviewers to the change", ex);
    }
}
#method_after
private void addReviewers(Set<Account.Id> topReviewers, Change change) {
    try {
        ReviewInput in = new ReviewInput();
        in.reviewers = new ArrayList<>(topReviewers.size());
        for (Account.Id account : topReviewers) {
            AddReviewerInput addReviewerInput = new AddReviewerInput();
            addReviewerInput.reviewer = account.toString();
            in.reviewers.add(addReviewerInput);
        }
        gApi.changes().id(change.getChangeId()).current().review(in);
    } catch (Exception ex) {
        log.error("Couldn't add reviewers to the change", ex);
    }
}
#end_block

#method_before
private Map<Account, Integer> getReviewersForPatch(List<Edit> edits, BlameResult blameResult) {
    Map<Account, Integer> reviewers = Maps.newHashMap();
    for (Edit edit : edits) {
        for (int i = edit.getBeginA(); i < edit.getEndA(); i++) {
            RevCommit commit = blameResult.getSourceCommit(i);
            try {
                Set<Account.Id> ids = emails.getAccountFor(commit.getAuthorIdent().getEmailAddress());
                for (Account.Id id : ids) {
                    Optional<Account> accountState = accountCache.get(id).map(AccountState::getAccount);
                    if (accountState.isPresent()) {
                        Account account = accountState.get();
                        if (account.isActive() && !change.getOwner().equals(account.getId())) {
                            Integer count = reviewers.get(account);
                            reviewers.put(account, count == null ? 1 : count.intValue() + 1);
                        }
                    }
                }
            } catch (IOException | OrmException e) {
                throw new RuntimeException("Unable to get account with email: " + commit.getAuthorIdent().getEmailAddress(), e);
            }
        }
    }
    return reviewers;
}
#method_after
private Map<Account, Integer> getReviewersForPatch(List<Edit> edits, BlameResult blameResult) {
    Map<Account, Integer> reviewers = Maps.newHashMap();
    for (Edit edit : edits) {
        for (int i = edit.getBeginA(); i < edit.getEndA(); i++) {
            RevCommit commit = blameResult.getSourceCommit(i);
            try {
                Set<Account.Id> ids = emails.getAccountFor(commit.getAuthorIdent().getEmailAddress());
                for (Account.Id id : ids) {
                    Account account = accountCache.get(id).getAccount();
                    if (account.isActive() && !change.getOwner().equals(account.getId())) {
                        Integer count = reviewers.get(account);
                        reviewers.put(account, count == null ? 1 : count.intValue() + 1);
                    }
                }
            } catch (IOException | OrmException e) {
                throw new RuntimeException("Unable to get account with email: " + commit.getAuthorIdent().getEmailAddress(), e);
            }
        }
    }
    return reviewers;
}
#end_block

#method_before
@Override
public void onEvent(Event event) {
    if (!(event instanceof PatchSetCreatedEvent)) {
        return;
    }
    PatchSetCreatedEvent e = (PatchSetCreatedEvent) event;
    Project.NameKey projectName = e.getProjectNameKey();
    int maxReviewers;
    String ignoreSubjectRegEx;
    String ignoreFileRegEx;
    try {
        maxReviewers = cfg.getFromProjectConfigWithInheritance(projectName, pluginName).getInt("maxReviewers", 3);
        ignoreSubjectRegEx = cfg.getFromProjectConfigWithInheritance(projectName, pluginName).getString("ignoreSubjectRegEx", "");
        ignoreFileRegEx = cfg.getFromProjectConfigWithInheritance(projectName, pluginName).getString("ignoreFileRegEx", "");
    } catch (NoSuchProjectException x) {
        log.error(x.getMessage(), x);
        return;
    }
    if (maxReviewers <= 0) {
        return;
    }
    try (Repository git = repoManager.openRepository(projectName);
        RevWalk rw = new RevWalk(git);
        ReviewDb reviewDb = schemaFactory.open()) {
        Change.Id changeId = new Change.Id(Integer.parseInt(Integer.toString(e.change.get().number)));
        PatchSet.Id psId = new PatchSet.Id(changeId, Integer.parseInt(Integer.toString(e.patchSet.get().number)));
        PatchSet ps = reviewDb.patchSets().get(psId);
        if (ps == null) {
            log.warn("Patch set " + psId.get() + " not found.");
            return;
        }
        Change change = reviewDb.changes().get(psId.getParentKey());
        if (change == null) {
            log.warn("Change " + changeId.get() + " not found.");
            return;
        }
        RevCommit commit = rw.parseCommit(ObjectId.fromString(e.patchSet.get().revision));
        if (!ignoreSubjectRegEx.isEmpty() && commit.getShortMessage().matches(ignoreSubjectRegEx)) {
            return;
        }
        Runnable task = reviewersByBlameFactory.create(commit, change, ps, maxReviewers, git, ignoreFileRegEx);
        workQueue.getDefaultQueue().submit(new Runnable() {

            @Override
            public void run() {
                RequestContext old = tl.setContext(new RequestContext() {

                    @Override
                    public CurrentUser getUser() {
                        return identifiedUserFactory.create(change.getOwner());
                    }

                    @Override
                    public Provider<ReviewDb> getReviewDbProvider() {
                        return new Provider<ReviewDb>() {

                            @Override
                            public ReviewDb get() {
                                if (db == null) {
                                    try {
                                        db = schemaFactory.open();
                                    } catch (OrmException e) {
                                        throw new ProvisionException("Cannot open ReviewDb", e);
                                    }
                                }
                                return db;
                            }
                        };
                    }
                });
                try {
                    task.run();
                } finally {
                    tl.setContext(old);
                    if (db != null) {
                        db.close();
                        db = null;
                    }
                }
            }
        });
    } catch (OrmException | IOException x) {
        log.error(x.getMessage(), x);
    }
}
#method_after
@Override
public void onEvent(Event event) {
    if (!(event instanceof PatchSetCreatedEvent)) {
        return;
    }
    PatchSetCreatedEvent e = (PatchSetCreatedEvent) event;
    Project.NameKey projectName = e.getProjectNameKey();
    int maxReviewers;
    String ignoreSubjectRegEx;
    String ignoreFileRegEx;
    try {
        maxReviewers = cfg.getFromProjectConfigWithInheritance(projectName, pluginName).getInt("maxReviewers", 3);
        ignoreSubjectRegEx = cfg.getFromProjectConfigWithInheritance(projectName, pluginName).getString("ignoreSubjectRegEx", "");
        ignoreFileRegEx = cfg.getFromProjectConfigWithInheritance(projectName, pluginName).getString("ignoreFileRegEx", "");
    } catch (NoSuchProjectException x) {
        log.error(x.getMessage(), x);
        return;
    }
    if (maxReviewers <= 0) {
        return;
    }
    try (Repository git = repoManager.openRepository(projectName);
        RevWalk rw = new RevWalk(git);
        ReviewDb reviewDb = schemaFactory.open()) {
        Change.Id changeId = new Change.Id(e.change.get().number);
        ChangeData cd = changeDataFactory.create(reviewDb, projectName, changeId);
        if (cd == null) {
            log.warn("Change with id: '{}' on project key: '{}' not found.", changeId.get(), projectName.toString());
            return;
        }
        Change change = cd.change();
        PatchSet.Id psId = new PatchSet.Id(changeId, e.patchSet.get().number);
        PatchSet ps = cd.patchSet(psId);
        if (ps == null) {
            log.warn("Patch set {} not found in change {}.", psId.get(), changeId.get());
            return;
        }
        RevCommit commit = rw.parseCommit(ObjectId.fromString(e.patchSet.get().revision));
        if (!ignoreSubjectRegEx.isEmpty() && commit.getShortMessage().matches(ignoreSubjectRegEx)) {
            return;
        }
        Runnable task = reviewersByBlameFactory.create(commit, change, ps, maxReviewers, git, ignoreFileRegEx);
        workQueue.getDefaultQueue().submit(new Runnable() {

            @Override
            public void run() {
                RequestContext old = tl.setContext(new RequestContext() {

                    @Override
                    public CurrentUser getUser() {
                        return identifiedUserFactory.create(change.getOwner());
                    }

                    @Override
                    public Provider<ReviewDb> getReviewDbProvider() {
                        return new Provider<ReviewDb>() {

                            @Override
                            public ReviewDb get() {
                                if (db == null) {
                                    try {
                                        db = schemaFactory.open();
                                    } catch (OrmException e) {
                                        throw new ProvisionException("Cannot open ReviewDb", e);
                                    }
                                }
                                return db;
                            }
                        };
                    }
                });
                try {
                    task.run();
                } finally {
                    tl.setContext(old);
                    if (db != null) {
                        db.close();
                        db = null;
                    }
                }
            }
        });
    } catch (OrmException | IOException x) {
        log.error(x.getMessage(), x);
    }
}
#end_block

#method_before
@Override
public void upgrade(UpdateUI ui) throws Exception {
    ui.message("Rebuild GPGP note map to build subkey to master key map");
    try (Repository repo = repoManager.openRepository(allUsersName);
        PublicKeyStore store = new PublicKeyStore(repo)) {
        store.rebuildSubkeyMasterKeyMap(null);
    }
}
#method_after
@Override
public void upgrade(Arguments args, UpdateUI ui) throws Exception {
    ui.message("Rebuild GPGP note map to build subkey to master key map");
    try (Repository repo = args.repoManager.openRepository(args.allUsers);
        PublicKeyStore store = new PublicKeyStore(repo)) {
        store.rebuildSubkeyMasterKeyMap();
    }
}
#end_block

#method_before
public static NoteDbSchemaVersion get(ImmutableSortedMap<Integer, Class<? extends NoteDbSchemaVersion>> schemaVersions, int i, NoteDbSchemaVersion.Arguments args) {
    Class<? extends NoteDbSchemaVersion> clazz = schemaVersions.get(i);
    checkArgument(clazz != null, "Schema version not found: %s", i);
    try {
        return clazz.getDeclaredConstructor(NoteDbSchemaVersion.Arguments.class).newInstance(args);
    } catch (InstantiationException | IllegalAccessException | NoSuchMethodException | InvocationTargetException e) {
        throw new IllegalStateException("failed to invoke constructor on " + clazz.getName(), e);
    }
}
#method_after
public static NoteDbSchemaVersion get(ImmutableSortedMap<Integer, Class<? extends NoteDbSchemaVersion>> schemaVersions, int i) {
    Class<? extends NoteDbSchemaVersion> clazz = schemaVersions.get(i);
    checkArgument(clazz != null, "Schema version not found: %s", i);
    try {
        return clazz.getDeclaredConstructor().newInstance();
    } catch (InstantiationException | IllegalAccessException | NoSuchMethodException | InvocationTargetException e) {
        throw new IllegalStateException("failed to invoke constructor on " + clazz.getName(), e);
    }
}
#end_block

#method_before
public void rebuildSubkeyMasterKeyMap(@Nullable TextProgressMonitor monitor) throws MissingObjectException, IncorrectObjectTypeException, IOException, PGPException {
    if (reader == null) {
        load();
    }
    if (notes != null) {
        try (ObjectInserter ins = repo.newObjectInserter()) {
            for (Note note : notes) {
                for (PGPPublicKeyRing keyRing : new PGPPublicKeyRingCollection(readKeysFromNote(note, null))) {
                    long masterKeyId = keyRing.getPublicKey().getKeyID();
                    ObjectId masterKeyObjectId = keyObjectId(masterKeyId);
                    saveSubkeyMaping(ins, keyRing, masterKeyId, masterKeyObjectId);
                }
                if (monitor != null) {
                    monitor.update(1);
                }
            }
        }
    }
}
#method_after
public void rebuildSubkeyMasterKeyMap() throws MissingObjectException, IncorrectObjectTypeException, IOException, PGPException {
    if (reader == null) {
        load();
    }
    if (notes != null) {
        try (ObjectInserter ins = repo.newObjectInserter()) {
            for (Note note : notes) {
                for (PGPPublicKeyRing keyRing : new PGPPublicKeyRingCollection(readKeysFromNote(note, null))) {
                    long masterKeyId = keyRing.getPublicKey().getKeyID();
                    ObjectId masterKeyObjectId = keyObjectId(masterKeyId);
                    saveSubkeyMaping(ins, keyRing, masterKeyId, masterKeyObjectId);
                }
            }
        }
    }
}
#end_block

#method_before
// The relative order of updateChange and updateRepo doesn't matter as long as all operations are
// executed in a single atomic BatchRefUpdate. Actually deleting the change refs first would not
@Override
public boolean updateChange(ChangeContext ctx) throws RestApiException, OrmException, IOException {
    Collection<PatchSet> patchSets = psUtil.byChange(ctx.getNotes());
    ensureDeletable(ctx, id, patchSets);
    // Cleaning up is only possible as long as the change and its elements are
    // still part of the database.
    cleanUpReferences(ctx, id, patchSets);
    ctx.deleteChange();
    changeDeleted.fire(ctx.getChange(), ctx.getAccount(), ctx.getWhen());
    return true;
}
#method_after
// The relative order of updateChange and updateRepo doesn't matter as long as all operations are
// executed in a single atomic BatchRefUpdate. Actually deleting the change refs first would not
@Override
public boolean updateChange(ChangeContext ctx) throws RestApiException, IOException {
    Collection<PatchSet> patchSets = psUtil.byChange(ctx.getNotes());
    ensureDeletable(ctx, id, patchSets);
    // Cleaning up is only possible as long as the change and its elements are
    // still part of the database.
    cleanUpReferences(id, patchSets);
    ctx.deleteChange();
    changeDeleted.fire(ctx.getChange(), ctx.getAccount(), ctx.getWhen());
    return true;
}
#end_block

#method_before
private void cleanUpReferences(ChangeContext ctx, Change.Id id, Collection<PatchSet> patchSets) throws OrmException {
    for (PatchSet ps : patchSets) {
        accountPatchReviewStore.run(s -> s.clearReviewed(ps.getId()), OrmException.class);
    }
    // Non-atomic operation on All-Users refs; not much we can do to make it atomic.
    starredChangesUtil.unstarAllForChangeDeletion(ctx.getChange().getProject(), id);
}
#method_after
private void cleanUpReferences(Change.Id id, Collection<PatchSet> patchSets) throws IOException {
    for (PatchSet ps : patchSets) {
        accountPatchReviewStore.run(s -> s.clearReviewed(ps.getId()), StorageException.class);
    }
    // Non-atomic operation on All-Users refs; not much we can do to make it atomic.
    starredChangesUtil.unstarAllForChangeDeletion(id);
}
#end_block

#method_before
public ImmutableSortedSet<String> getLabels(Account.Id accountId, Change.Id changeId) throws OrmException {
    try (Repository repo = repoManager.openRepository(allUsers)) {
        return readLabels(repo, RefNames.refsStarredChanges(changeId, accountId)).labels();
    } catch (IOException e) {
        throw new OrmException(String.format("Reading stars from change %d for account %d failed", changeId.get(), accountId.get()), e);
    }
}
#method_after
public ImmutableSortedSet<String> getLabels(Account.Id accountId, Change.Id changeId) {
    try (Repository repo = repoManager.openRepository(allUsers)) {
        return readLabels(repo, RefNames.refsStarredChanges(changeId, accountId)).labels();
    } catch (IOException e) {
        throw new StorageException(String.format("Reading stars from change %d for account %d failed", changeId.get(), accountId.get()), e);
    }
}
#end_block

#method_before
public ImmutableSortedSet<String> star(Account.Id accountId, Project.NameKey project, Change.Id changeId, Set<String> labelsToAdd, Set<String> labelsToRemove) throws OrmException, IllegalLabelException {
    try (Repository repo = repoManager.openRepository(allUsers)) {
        String refName = RefNames.refsStarredChanges(changeId, accountId);
        StarRef old = readLabels(repo, refName);
        Set<String> labels = new HashSet<>(old.labels());
        if (labelsToAdd != null) {
            labels.addAll(labelsToAdd);
        }
        if (labelsToRemove != null) {
            labels.removeAll(labelsToRemove);
        }
        if (labels.isEmpty()) {
            deleteRef(repo, refName, old.objectId());
        } else {
            checkMutuallyExclusiveLabels(labels);
            updateLabels(repo, refName, old.objectId(), labels);
        }
        indexer.index(project, changeId);
        return ImmutableSortedSet.copyOf(labels);
    } catch (IOException e) {
        throw new OrmException(String.format("Star change %d for account %d failed", changeId.get(), accountId.get()), e);
    }
}
#method_after
public ImmutableSortedSet<String> star(Account.Id accountId, Project.NameKey project, Change.Id changeId, Set<String> labelsToAdd, Set<String> labelsToRemove) throws IllegalLabelException {
    try (Repository repo = repoManager.openRepository(allUsers)) {
        String refName = RefNames.refsStarredChanges(changeId, accountId);
        StarRef old = readLabels(repo, refName);
        Set<String> labels = new HashSet<>(old.labels());
        if (labelsToAdd != null) {
            labels.addAll(labelsToAdd);
        }
        if (labelsToRemove != null) {
            labels.removeAll(labelsToRemove);
        }
        if (labels.isEmpty()) {
            deleteRef(repo, refName, old.objectId());
        } else {
            checkMutuallyExclusiveLabels(labels);
            updateLabels(repo, refName, old.objectId(), labels);
        }
        indexer.index(project, changeId);
        return ImmutableSortedSet.copyOf(labels);
    } catch (IOException e) {
        throw new StorageException(String.format("Star change %d for account %d failed", changeId.get(), accountId.get()), e);
    }
}
#end_block

#method_before
public void unstarAllForChangeDeletion(Project.NameKey project, Change.Id changeId) throws OrmException {
    try (Repository repo = repoManager.openRepository(allUsers);
        RevWalk rw = new RevWalk(repo)) {
        BatchRefUpdate batchUpdate = repo.getRefDatabase().newBatchUpdate();
        batchUpdate.setAllowNonFastForwards(true);
        batchUpdate.setRefLogIdent(serverIdent.get());
        batchUpdate.setRefLogMessage("Unstar change " + changeId.get(), true);
        for (Account.Id accountId : byChangeFromIndex(changeId).keySet()) {
            String refName = RefNames.refsStarredChanges(changeId, accountId);
            Ref ref = repo.getRefDatabase().getRef(refName);
            batchUpdate.addCommand(new ReceiveCommand(ref.getObjectId(), ObjectId.zeroId(), refName));
        }
        batchUpdate.execute(rw, NullProgressMonitor.INSTANCE);
        for (ReceiveCommand command : batchUpdate.getCommands()) {
            if (command.getResult() != ReceiveCommand.Result.OK) {
                throw new IOException(String.format("Unstar change %d failed, ref %s could not be deleted: %s", changeId.get(), command.getRefName(), command.getResult()));
            }
        }
        indexer.index(project, changeId);
    } catch (IOException e) {
        throw new OrmException(String.format("Unstar change %d failed", changeId.get()), e);
    }
}
#method_after
public void unstarAllForChangeDeletion(Change.Id changeId) throws IOException {
    try (Repository repo = repoManager.openRepository(allUsers);
        RevWalk rw = new RevWalk(repo)) {
        BatchRefUpdate batchUpdate = repo.getRefDatabase().newBatchUpdate();
        batchUpdate.setAllowNonFastForwards(true);
        batchUpdate.setRefLogIdent(serverIdent.get());
        batchUpdate.setRefLogMessage("Unstar change " + changeId.get(), true);
        for (Account.Id accountId : byChangeFromIndex(changeId).keySet()) {
            String refName = RefNames.refsStarredChanges(changeId, accountId);
            Ref ref = repo.getRefDatabase().getRef(refName);
            batchUpdate.addCommand(new ReceiveCommand(ref.getObjectId(), ObjectId.zeroId(), refName));
        }
        batchUpdate.execute(rw, NullProgressMonitor.INSTANCE);
        for (ReceiveCommand command : batchUpdate.getCommands()) {
            if (command.getResult() != ReceiveCommand.Result.OK) {
                throw new IOException(String.format("Unstar change %d failed, ref %s could not be deleted: %s", changeId.get(), command.getRefName(), command.getResult()));
            }
        }
    }
}
#end_block

#method_before
public ImmutableMap<Account.Id, StarRef> byChange(Change.Id changeId) throws OrmException {
    try (Repository repo = repoManager.openRepository(allUsers)) {
        ImmutableMap.Builder<Account.Id, StarRef> builder = ImmutableMap.builder();
        for (String refPart : getRefNames(repo, RefNames.refsStarredChangesPrefix(changeId))) {
            Integer id = Ints.tryParse(refPart);
            if (id == null) {
                continue;
            }
            Account.Id accountId = new Account.Id(id);
            builder.put(accountId, readLabels(repo, RefNames.refsStarredChanges(changeId, accountId)));
        }
        return builder.build();
    } catch (IOException e) {
        throw new OrmException(String.format("Get accounts that starred change %d failed", changeId.get()), e);
    }
}
#method_after
public ImmutableMap<Account.Id, StarRef> byChange(Change.Id changeId) {
    try (Repository repo = repoManager.openRepository(allUsers)) {
        ImmutableMap.Builder<Account.Id, StarRef> builder = ImmutableMap.builder();
        for (String refPart : getRefNames(repo, RefNames.refsStarredChangesPrefix(changeId))) {
            Integer id = Ints.tryParse(refPart);
            if (id == null) {
                continue;
            }
            Account.Id accountId = new Account.Id(id);
            builder.put(accountId, readLabels(repo, RefNames.refsStarredChanges(changeId, accountId)));
        }
        return builder.build();
    } catch (IOException e) {
        throw new StorageException(String.format("Get accounts that starred change %d failed", changeId.get()), e);
    }
}
#end_block

#method_before
public ImmutableListMultimap<Account.Id, String> byChangeFromIndex(Change.Id changeId) throws OrmException {
    List<ChangeData> changeData = queryProvider.get().setRequestedFields(ChangeField.ID, ChangeField.STAR).byLegacyChangeId(changeId);
    if (changeData.size() != 1) {
        throw new NoSuchChangeException(changeId);
    }
    return changeData.get(0).stars();
}
#method_after
public ImmutableListMultimap<Account.Id, String> byChangeFromIndex(Change.Id changeId) {
    List<ChangeData> changeData = queryProvider.get().setRequestedFields(ChangeField.ID, ChangeField.STAR).byLegacyChangeId(changeId);
    if (changeData.size() != 1) {
        throw new NoSuchChangeException(changeId);
    }
    return changeData.get(0).stars();
}
#end_block

#method_before
public void ignore(ChangeResource rsrc) throws OrmException, IllegalLabelException {
    star(rsrc.getUser().asIdentifiedUser().getAccountId(), rsrc.getProject(), rsrc.getChange().getId(), ImmutableSet.of(IGNORE_LABEL), ImmutableSet.of());
}
#method_after
public void ignore(ChangeResource rsrc) throws IllegalLabelException {
    star(rsrc.getUser().asIdentifiedUser().getAccountId(), rsrc.getProject(), rsrc.getChange().getId(), ImmutableSet.of(IGNORE_LABEL), ImmutableSet.of());
}
#end_block

#method_before
public void unignore(ChangeResource rsrc) throws OrmException, IllegalLabelException {
    star(rsrc.getUser().asIdentifiedUser().getAccountId(), rsrc.getProject(), rsrc.getChange().getId(), ImmutableSet.of(), ImmutableSet.of(IGNORE_LABEL));
}
#method_after
public void unignore(ChangeResource rsrc) throws IllegalLabelException {
    star(rsrc.getUser().asIdentifiedUser().getAccountId(), rsrc.getProject(), rsrc.getChange().getId(), ImmutableSet.of(), ImmutableSet.of(IGNORE_LABEL));
}
#end_block

#method_before
public boolean isIgnoredBy(Change.Id changeId, Account.Id accountId) throws OrmException {
    return getLabels(accountId, changeId).contains(IGNORE_LABEL);
}
#method_after
public boolean isIgnoredBy(Change.Id changeId, Account.Id accountId) {
    return getLabels(accountId, changeId).contains(IGNORE_LABEL);
}
#end_block

#method_before
public boolean isIgnored(ChangeResource rsrc) throws OrmException {
    return isIgnoredBy(rsrc.getChange().getId(), rsrc.getUser().asIdentifiedUser().getAccountId());
}
#method_after
public boolean isIgnored(ChangeResource rsrc) {
    return isIgnoredBy(rsrc.getChange().getId(), rsrc.getUser().asIdentifiedUser().getAccountId());
}
#end_block

#method_before
public void markAsReviewed(ChangeResource rsrc) throws OrmException, IllegalLabelException {
    star(rsrc.getUser().asIdentifiedUser().getAccountId(), rsrc.getProject(), rsrc.getChange().getId(), ImmutableSet.of(getReviewedLabel(rsrc.getChange())), ImmutableSet.of(getUnreviewedLabel(rsrc.getChange())));
}
#method_after
public void markAsReviewed(ChangeResource rsrc) throws IllegalLabelException {
    star(rsrc.getUser().asIdentifiedUser().getAccountId(), rsrc.getProject(), rsrc.getChange().getId(), ImmutableSet.of(getReviewedLabel(rsrc.getChange())), ImmutableSet.of(getUnreviewedLabel(rsrc.getChange())));
}
#end_block

#method_before
public void markAsUnreviewed(ChangeResource rsrc) throws OrmException, IllegalLabelException {
    star(rsrc.getUser().asIdentifiedUser().getAccountId(), rsrc.getProject(), rsrc.getChange().getId(), ImmutableSet.of(getUnreviewedLabel(rsrc.getChange())), ImmutableSet.of(getReviewedLabel(rsrc.getChange())));
}
#method_after
public void markAsUnreviewed(ChangeResource rsrc) throws IllegalLabelException {
    star(rsrc.getUser().asIdentifiedUser().getAccountId(), rsrc.getProject(), rsrc.getChange().getId(), ImmutableSet.of(getUnreviewedLabel(rsrc.getChange())), ImmutableSet.of(getReviewedLabel(rsrc.getChange())));
}
#end_block

#method_before
private void updateLabels(Repository repo, String refName, ObjectId oldObjectId, Collection<String> labels) throws IOException, OrmException, InvalidLabelsException {
    try (TraceTimer traceTimer = TraceContext.newTimer("Update star labels in %s (labels=%s)", refName, labels);
        RevWalk rw = new RevWalk(repo)) {
        RefUpdate u = repo.updateRef(refName);
        u.setExpectedOldObjectId(oldObjectId);
        u.setForceUpdate(true);
        u.setNewObjectId(writeLabels(repo, labels));
        u.setRefLogIdent(serverIdent.get());
        u.setRefLogMessage("Update star labels", true);
        RefUpdate.Result result = u.update(rw);
        switch(result) {
            case NEW:
            case FORCED:
            case NO_CHANGE:
            case FAST_FORWARD:
                gitRefUpdated.fire(allUsers, u, null);
                return;
            case IO_FAILURE:
            case LOCK_FAILURE:
            case NOT_ATTEMPTED:
            case REJECTED:
            case REJECTED_CURRENT_BRANCH:
            case RENAMED:
            case REJECTED_MISSING_OBJECT:
            case REJECTED_OTHER_REASON:
            default:
                throw new OrmException(String.format("Update star labels on ref %s failed: %s", refName, result.name()));
        }
    }
}
#method_after
private void updateLabels(Repository repo, String refName, ObjectId oldObjectId, Collection<String> labels) throws IOException, InvalidLabelsException {
    try (TraceTimer traceTimer = TraceContext.newTimer("Update star labels in %s (labels=%s)", refName, labels);
        RevWalk rw = new RevWalk(repo)) {
        RefUpdate u = repo.updateRef(refName);
        u.setExpectedOldObjectId(oldObjectId);
        u.setForceUpdate(true);
        u.setNewObjectId(writeLabels(repo, labels));
        u.setRefLogIdent(serverIdent.get());
        u.setRefLogMessage("Update star labels", true);
        RefUpdate.Result result = u.update(rw);
        switch(result) {
            case NEW:
            case FORCED:
            case NO_CHANGE:
            case FAST_FORWARD:
                gitRefUpdated.fire(allUsers, u, null);
                return;
            case IO_FAILURE:
            case LOCK_FAILURE:
            case NOT_ATTEMPTED:
            case REJECTED:
            case REJECTED_CURRENT_BRANCH:
            case RENAMED:
            case REJECTED_MISSING_OBJECT:
            case REJECTED_OTHER_REASON:
            default:
                throw new StorageException(String.format("Update star labels on ref %s failed: %s", refName, result.name()));
        }
    }
}
#end_block

#method_before
private void deleteRef(Repository repo, String refName, ObjectId oldObjectId) throws IOException, OrmException {
    if (ObjectId.zeroId().equals(oldObjectId)) {
        // ref doesn't exist
        return;
    }
    try (TraceTimer traceTimer = TraceContext.newTimer("Delete star labels in %s", refName)) {
        RefUpdate u = repo.updateRef(refName);
        u.setForceUpdate(true);
        u.setExpectedOldObjectId(oldObjectId);
        u.setRefLogIdent(serverIdent.get());
        u.setRefLogMessage("Unstar change", true);
        RefUpdate.Result result = u.delete();
        switch(result) {
            case FORCED:
                gitRefUpdated.fire(allUsers, u, null);
                return;
            case NEW:
            case NO_CHANGE:
            case FAST_FORWARD:
            case IO_FAILURE:
            case LOCK_FAILURE:
            case NOT_ATTEMPTED:
            case REJECTED:
            case REJECTED_CURRENT_BRANCH:
            case RENAMED:
            case REJECTED_MISSING_OBJECT:
            case REJECTED_OTHER_REASON:
            default:
                throw new OrmException(String.format("Delete star ref %s failed: %s", refName, result.name()));
        }
    }
}
#method_after
private void deleteRef(Repository repo, String refName, ObjectId oldObjectId) throws IOException {
    if (ObjectId.zeroId().equals(oldObjectId)) {
        // ref doesn't exist
        return;
    }
    try (TraceTimer traceTimer = TraceContext.newTimer("Delete star labels in %s", refName)) {
        RefUpdate u = repo.updateRef(refName);
        u.setForceUpdate(true);
        u.setExpectedOldObjectId(oldObjectId);
        u.setRefLogIdent(serverIdent.get());
        u.setRefLogMessage("Unstar change", true);
        RefUpdate.Result result = u.delete();
        switch(result) {
            case FORCED:
                gitRefUpdated.fire(allUsers, u, null);
                return;
            case NEW:
            case NO_CHANGE:
            case FAST_FORWARD:
            case IO_FAILURE:
            case LOCK_FAILURE:
            case NOT_ATTEMPTED:
            case REJECTED:
            case REJECTED_CURRENT_BRANCH:
            case RENAMED:
            case REJECTED_MISSING_OBJECT:
            case REJECTED_OTHER_REASON:
            default:
                throw new StorageException(String.format("Delete star ref %s failed: %s", refName, result.name()));
        }
    }
}
#end_block

#method_before
private void stage() throws OrmException, IOException {
    try (Timer1.Context timer = metrics.stageUpdateLatency.start(CHANGES)) {
        if (isEmpty()) {
            return;
        }
        initChangeRepo();
        if (!draftUpdates.isEmpty() || !toDelete.isEmpty()) {
            initAllUsersRepo();
        }
        addCommands();
    }
}
#method_after
private void stage() throws IOException {
    try (Timer1.Context timer = metrics.stageUpdateLatency.start(CHANGES)) {
        if (isEmpty()) {
            return;
        }
        initChangeRepo();
        if (!draftUpdates.isEmpty() || !toDelete.isEmpty()) {
            initAllUsersRepo();
        }
        addCommands();
    }
}
#end_block

#method_before
@Nullable
public BatchRefUpdate execute() throws OrmException, IOException {
    return execute(false);
}
#method_after
@Nullable
public BatchRefUpdate execute() throws IOException {
    return execute(false);
}
#end_block

#method_before
@Nullable
public BatchRefUpdate execute(boolean dryrun) throws OrmException, IOException {
    checkNotExecuted();
    if (isEmpty()) {
        executed = true;
        return null;
    }
    try (Timer1.Context timer = metrics.updateLatency.start(CHANGES)) {
        stage();
        // ChangeUpdates must execute before ChangeDraftUpdates.
        // 
        // ChangeUpdate will automatically delete draft comments for any published
        // comments, but the updates to the two repos don't happen atomically.
        // Thus if the change meta update succeeds and the All-Users update fails,
        // we may have stale draft comments. Doing it in this order allows stale
        // comments to be filtered out by ChangeNotes, reflecting the fact that
        // comments can only go from DRAFT to PUBLISHED, not vice versa.
        BatchRefUpdate result = execute(changeRepo, dryrun, pushCert);
        execute(allUsersRepo, dryrun, null);
        executed = true;
        return result;
    } finally {
        close();
    }
}
#method_after
@Nullable
public BatchRefUpdate execute(boolean dryrun) throws IOException {
    checkNotExecuted();
    if (isEmpty()) {
        executed = true;
        return null;
    }
    try (Timer1.Context timer = metrics.updateLatency.start(CHANGES)) {
        stage();
        // ChangeUpdates must execute before ChangeDraftUpdates.
        // 
        // ChangeUpdate will automatically delete draft comments for any published
        // comments, but the updates to the two repos don't happen atomically.
        // Thus if the change meta update succeeds and the All-Users update fails,
        // we may have stale draft comments. Doing it in this order allows stale
        // comments to be filtered out by ChangeNotes, reflecting the fact that
        // comments can only go from DRAFT to PUBLISHED, not vice versa.
        BatchRefUpdate result = execute(changeRepo, dryrun, pushCert);
        execute(allUsersRepo, dryrun, null);
        executed = true;
        return result;
    } finally {
        close();
    }
}
#end_block

#method_before
private void addCommands() throws OrmException, IOException {
    if (isEmpty()) {
        return;
    }
    checkState(changeRepo != null, "must set change repo");
    if (!draftUpdates.isEmpty()) {
        checkState(allUsersRepo != null, "must set all users repo");
    }
    addUpdates(changeUpdates, changeRepo, maxUpdates);
    if (!draftUpdates.isEmpty()) {
        addUpdates(draftUpdates, allUsersRepo, 0);
    }
    if (!robotCommentUpdates.isEmpty()) {
        addUpdates(robotCommentUpdates, changeRepo, 0);
    }
    if (!rewriters.isEmpty()) {
        addRewrites(rewriters, changeRepo);
    }
    for (Change.Id id : toDelete) {
        doDelete(id);
    }
}
#method_after
private void addCommands() throws IOException {
    if (isEmpty()) {
        return;
    }
    checkState(changeRepo != null, "must set change repo");
    if (!draftUpdates.isEmpty()) {
        checkState(allUsersRepo != null, "must set all users repo");
    }
    addUpdates(changeUpdates, changeRepo, Optional.of(maxUpdates));
    if (!draftUpdates.isEmpty()) {
        addUpdates(draftUpdates, allUsersRepo, Optional.empty());
    }
    if (!robotCommentUpdates.isEmpty()) {
        addUpdates(robotCommentUpdates, changeRepo, Optional.empty());
    }
    if (!rewriters.isEmpty()) {
        addRewrites(rewriters, changeRepo);
    }
    for (Change.Id id : toDelete) {
        doDelete(id);
    }
}
#end_block

#method_before
private static <U extends AbstractChangeUpdate> void addUpdates(ListMultimap<String, U> all, OpenRepo or, int maxUpdates) throws OrmException, IOException {
    for (Map.Entry<String, Collection<U>> e : all.asMap().entrySet()) {
        String refName = e.getKey();
        Collection<U> updates = e.getValue();
        ObjectId old = or.cmds.get(refName).orElse(ObjectId.zeroId());
        // writing partial change meta if the change hasn't been backfilled yet.
        if (!allowWrite(updates, old)) {
            continue;
        }
        int updateCount;
        U first = updates.iterator().next();
        if (maxUpdates > 0) {
            checkState(first.getNotes() != null, "expected ChangeNotes on %s", first);
            updateCount = first.getNotes().getUpdateCount();
        } else {
            updateCount = 0;
        }
        ObjectId curr = old;
        for (U u : updates) {
            if (u.isRootOnly() && !old.equals(ObjectId.zeroId())) {
                throw new OrmException("Given ChangeUpdate is only allowed on initial commit");
            }
            ObjectId next = u.apply(or.rw, or.tempIns, curr);
            if (next == null) {
                continue;
            }
            if (maxUpdates > 0 && !Objects.equals(next, curr) && ++updateCount > maxUpdates) {
                throw new TooManyUpdatesException(u.getId(), maxUpdates);
            }
            curr = next;
        }
        if (!old.equals(curr)) {
            or.cmds.add(new ReceiveCommand(old, curr, refName));
        }
    }
}
#method_after
private static <U extends AbstractChangeUpdate> void addUpdates(ListMultimap<String, U> all, OpenRepo or, Optional<Integer> maxUpdates) throws IOException {
    for (Map.Entry<String, Collection<U>> e : all.asMap().entrySet()) {
        String refName = e.getKey();
        Collection<U> updates = e.getValue();
        ObjectId old = or.cmds.get(refName).orElse(ObjectId.zeroId());
        // writing partial change meta if the change hasn't been backfilled yet.
        if (!allowWrite(updates, old)) {
            continue;
        }
        int updateCount;
        U first = updates.iterator().next();
        if (maxUpdates.isPresent()) {
            checkState(first.getNotes() != null, "expected ChangeNotes on %s", first);
            updateCount = first.getNotes().getUpdateCount();
        } else {
            updateCount = 0;
        }
        ObjectId curr = old;
        for (U u : updates) {
            if (u.isRootOnly() && !old.equals(ObjectId.zeroId())) {
                throw new StorageException("Given ChangeUpdate is only allowed on initial commit");
            }
            ObjectId next = u.apply(or.rw, or.tempIns, curr);
            if (next == null) {
                continue;
            }
            if (maxUpdates.isPresent() && !Objects.equals(next, curr) && ++updateCount > maxUpdates.get()) {
                throw new TooManyUpdatesException(u.getId(), maxUpdates.get());
            }
            curr = next;
        }
        if (!old.equals(curr)) {
            or.cmds.add(new ReceiveCommand(old, curr, refName));
        }
    }
}
#end_block

#method_before
private static void addRewrites(ListMultimap<String, NoteDbRewriter> rewriters, OpenRepo openRepo) throws OrmException, IOException {
    for (Map.Entry<String, Collection<NoteDbRewriter>> entry : rewriters.asMap().entrySet()) {
        String refName = entry.getKey();
        ObjectId oldTip = openRepo.cmds.get(refName).orElse(ObjectId.zeroId());
        if (oldTip.equals(ObjectId.zeroId())) {
            throw new OrmException(String.format("Ref %s is empty", refName));
        }
        ObjectId currTip = oldTip;
        try {
            for (NoteDbRewriter noteDbRewriter : entry.getValue()) {
                ObjectId nextTip = noteDbRewriter.rewriteCommitHistory(openRepo.rw, openRepo.tempIns, currTip);
                if (nextTip != null) {
                    currTip = nextTip;
                }
            }
        } catch (ConfigInvalidException e) {
            throw new OrmException("Cannot rewrite commit history", e);
        }
        if (!oldTip.equals(currTip)) {
            openRepo.cmds.add(new ReceiveCommand(oldTip, currTip, refName));
        }
    }
}
#method_after
private static void addRewrites(ListMultimap<String, NoteDbRewriter> rewriters, OpenRepo openRepo) throws IOException {
    for (Map.Entry<String, Collection<NoteDbRewriter>> entry : rewriters.asMap().entrySet()) {
        String refName = entry.getKey();
        ObjectId oldTip = openRepo.cmds.get(refName).orElse(ObjectId.zeroId());
        if (oldTip.equals(ObjectId.zeroId())) {
            throw new StorageException(String.format("Ref %s is empty", refName));
        }
        ObjectId currTip = oldTip;
        try {
            for (NoteDbRewriter noteDbRewriter : entry.getValue()) {
                ObjectId nextTip = noteDbRewriter.rewriteCommitHistory(openRepo.rw, openRepo.tempIns, currTip);
                if (nextTip != null) {
                    currTip = nextTip;
                }
            }
        } catch (ConfigInvalidException e) {
            throw new StorageException("Cannot rewrite commit history", e);
        }
        if (!oldTip.equals(currTip)) {
            openRepo.cmds.add(new ReceiveCommand(oldTip, currTip, refName));
        }
    }
}
#end_block

#method_before
public static void execute(Collection<BatchUpdate> updates, BatchUpdateListener listener, boolean dryrun) throws UpdateException, RestApiException {
    requireNonNull(listener);
    if (updates.isEmpty()) {
        return;
    }
    checkDifferentProject(updates);
    try {
        @SuppressWarnings("deprecation")
        List<com.google.common.util.concurrent.CheckedFuture<?, IOException>> indexFutures = new ArrayList<>();
        List<ChangesHandle> handles = new ArrayList<>(updates.size());
        try {
            for (BatchUpdate u : updates) {
                u.executeUpdateRepo();
            }
            listener.afterUpdateRepos();
            for (BatchUpdate u : updates) {
                handles.add(u.executeChangeOps(dryrun));
            }
            for (ChangesHandle h : handles) {
                h.execute();
                indexFutures.addAll(h.startIndexFutures());
            }
            listener.afterUpdateRefs();
            listener.afterUpdateChanges();
        } finally {
            for (ChangesHandle h : handles) {
                h.close();
            }
        }
        ChangeIndexer.allAsList(indexFutures).get();
        // Fire ref update events only after all mutations are finished, since callers may assume a
        // patch set ref being created means the change was created, or a branch advancing meaning
        // some changes were closed.
        updates.stream().filter(u -> u.batchRefUpdate != null).forEach(u -> u.gitRefUpdated.fire(u.project, u.batchRefUpdate, u.getAccount().orElse(null)));
        if (!dryrun) {
            for (BatchUpdate u : updates) {
                u.executePostOps();
            }
        }
    } catch (Exception e) {
        wrapAndThrowException(e);
    }
}
#method_after
public static void execute(Collection<BatchUpdate> updates, BatchUpdateListener listener, boolean dryrun) throws UpdateException, RestApiException {
    requireNonNull(listener);
    if (updates.isEmpty()) {
        return;
    }
    checkDifferentProject(updates);
    try {
        List<ListenableFuture<?>> indexFutures = new ArrayList<>();
        List<ChangesHandle> handles = new ArrayList<>(updates.size());
        try {
            for (BatchUpdate u : updates) {
                u.executeUpdateRepo();
            }
            listener.afterUpdateRepos();
            for (BatchUpdate u : updates) {
                handles.add(u.executeChangeOps(dryrun));
            }
            for (ChangesHandle h : handles) {
                h.execute();
                indexFutures.addAll(h.startIndexFutures());
            }
            listener.afterUpdateRefs();
            listener.afterUpdateChanges();
        } finally {
            for (ChangesHandle h : handles) {
                h.close();
            }
        }
        ((ListenableFuture<?>) Futures.allAsList(indexFutures)).get();
        // Fire ref update events only after all mutations are finished, since callers may assume a
        // patch set ref being created means the change was created, or a branch advancing meaning
        // some changes were closed.
        updates.stream().filter(u -> u.batchRefUpdate != null).forEach(u -> u.gitRefUpdated.fire(u.project, u.batchRefUpdate, u.getAccount().orElse(null)));
        if (!dryrun) {
            for (BatchUpdate u : updates) {
                u.executePostOps();
            }
        }
    } catch (Exception e) {
        wrapAndThrowException(e);
    }
}
#end_block

#method_before
private static void wrapAndThrowException(Exception e) throws UpdateException, RestApiException {
    Throwables.throwIfUnchecked(e);
    // Propagate REST API exceptions thrown by operations; they commonly throw exceptions like
    // ResourceConflictException to indicate an atomic update failure.
    Throwables.throwIfInstanceOf(e, UpdateException.class);
    Throwables.throwIfInstanceOf(e, RestApiException.class);
    // REST exception types
    if (e instanceof InvalidChangeOperationException || e instanceof TooManyUpdatesException) {
        throw new ResourceConflictException(e.getMessage(), e);
    } else if (e instanceof NoSuchChangeException || e instanceof NoSuchRefException || e instanceof NoSuchProjectException) {
        throw new ResourceNotFoundException(e.getMessage(), e);
    }
    // Otherwise, wrap in a generic UpdateException, which does not include a user-visible message.
    throw new UpdateException(e);
}
#method_after
private static void wrapAndThrowException(Exception e) throws UpdateException, RestApiException {
    // exception types.
    if (e instanceof InvalidChangeOperationException || e instanceof TooManyUpdatesException) {
        throw new ResourceConflictException(e.getMessage(), e);
    } else if (e instanceof NoSuchChangeException || e instanceof NoSuchRefException || e instanceof NoSuchProjectException) {
        throw new ResourceNotFoundException(e.getMessage(), e);
    }
    Throwables.throwIfUnchecked(e);
    // Propagate REST API exceptions thrown by operations; they commonly throw exceptions like
    // ResourceConflictException to indicate an atomic update failure.
    Throwables.throwIfInstanceOf(e, UpdateException.class);
    Throwables.throwIfInstanceOf(e, RestApiException.class);
    // Otherwise, wrap in a generic UpdateException, which does not include a user-visible message.
    throw new UpdateException(e);
}
#end_block

#method_before
void execute() throws OrmException, IOException {
    BatchUpdate.this.batchRefUpdate = manager.execute(dryrun);
}
#method_after
void execute() throws IOException {
    BatchUpdate.this.batchRefUpdate = manager.execute(dryrun);
}
#end_block

#method_before
@SuppressWarnings("deprecation")
List<com.google.common.util.concurrent.CheckedFuture<?, IOException>> startIndexFutures() {
    if (dryrun) {
        return ImmutableList.of();
    }
    logDebug("Reindexing %d changes", results.size());
    List<com.google.common.util.concurrent.CheckedFuture<?, IOException>> indexFutures = new ArrayList<>(results.size());
    for (Map.Entry<Change.Id, ChangeResult> e : results.entrySet()) {
        Change.Id id = e.getKey();
        switch(e.getValue()) {
            case UPSERTED:
                indexFutures.add(indexer.indexAsync(project, id));
                break;
            case DELETED:
                indexFutures.add(indexer.deleteAsync(id));
                break;
            case SKIPPED:
                break;
            default:
                throw new IllegalStateException("unexpected result: " + e.getValue());
        }
    }
    return indexFutures;
}
#method_after
@SuppressWarnings("deprecation")
List<ListenableFuture<?>> startIndexFutures() {
    if (dryrun) {
        return ImmutableList.of();
    }
    logDebug("Reindexing %d changes", results.size());
    List<ListenableFuture<?>> indexFutures = new ArrayList<>(results.size());
    for (Map.Entry<Change.Id, ChangeResult> e : results.entrySet()) {
        Change.Id id = e.getKey();
        switch(e.getValue()) {
            case UPSERTED:
                indexFutures.add(indexer.indexAsync(project, id));
                break;
            case DELETED:
                indexFutures.add(indexer.deleteAsync(id));
                break;
            case SKIPPED:
                break;
            default:
                throw new IllegalStateException("unexpected result: " + e.getValue());
        }
    }
    return indexFutures;
}
#end_block

#method_before
private ChangeContextImpl newChangeContext(Change.Id id) throws OrmException {
    logDebug("Opening change %s for update", id);
    Change c = newChanges.get(id);
    boolean isNew = c != null;
    if (!isNew) {
        // Pass a synthetic change into ChangeNotes.Factory, which will take care of checking for
        // existence and populating columns from the parsed notes state.
        // TODO(dborowitz): This dance made more sense when using Reviewdb; consider a nicer way.
        c = ChangeNotes.Factory.newChange(project, id);
    } else {
        logDebug("Change %s is new", id);
    }
    ChangeNotes notes = changeNotesFactory.createForBatchUpdate(c, !isNew);
    return new ChangeContextImpl(notes);
}
#method_after
private ChangeContextImpl newChangeContext(Change.Id id) {
    logDebug("Opening change %s for update", id);
    Change c = newChanges.get(id);
    boolean isNew = c != null;
    if (!isNew) {
        // Pass a synthetic change into ChangeNotes.Factory, which will take care of checking for
        // existence and populating columns from the parsed notes state.
        // TODO(dborowitz): This dance made more sense when using Reviewdb; consider a nicer way.
        c = ChangeNotes.Factory.newChange(project, id);
    } else {
        logDebug("Change %s is new", id);
    }
    ChangeNotes notes = changeNotesFactory.createForBatchUpdate(c, !isNew);
    return new ChangeContextImpl(notes);
}
#end_block

#method_before
@Override
public void start() {
    try {
        schemaCreator.ensureCreated();
    } catch (OrmException | IOException | ConfigInvalidException e) {
        throw new OrmException(e);
    }
}
#method_after
@Override
public void start() {
    try {
        schemaCreator.ensureCreated();
    } catch (IOException | ConfigInvalidException e) {
        throw new StorageException(e);
    }
}
#end_block

#method_before
@Override
public Response<Map<String, ActionInfo>> apply(RevisionResource rsrc) throws OrmException {
    return Response.withMustRevalidate(delegate.format(rsrc));
}
#method_after
@Override
public Response<Map<String, ActionInfo>> apply(RevisionResource rsrc) throws StorageException {
    return Response.withMustRevalidate(delegate.format(rsrc));
}
#end_block

#method_before
@Override
public String getETag(RevisionResource rsrc) {
    Hasher h = Hashing.murmur3_128().newHasher();
    CurrentUser user = rsrc.getUser();
    try {
        rsrc.getChangeResource().prepareETag(h, user);
        h.putBoolean(MergeSuperSet.wholeTopicEnabled(config));
        ChangeSet cs = mergeSuperSet.get().completeChangeSet(rsrc.getChange(), user);
        for (ChangeData cd : cs.changes()) {
            changeResourceFactory.create(cd.notes(), user).prepareETag(h, user);
        }
        h.putBoolean(cs.furtherHiddenChanges());
    } catch (IOException | OrmException | PermissionBackendException e) {
        throw new OrmException(e);
    }
    return h.hash().toString();
}
#method_after
@Override
public String getETag(RevisionResource rsrc) {
    Hasher h = Hashing.murmur3_128().newHasher();
    CurrentUser user = rsrc.getUser();
    try {
        rsrc.getChangeResource().prepareETag(h, user);
        h.putBoolean(MergeSuperSet.wholeTopicEnabled(config));
        ChangeSet cs = mergeSuperSet.get().completeChangeSet(rsrc.getChange(), user);
        for (ChangeData cd : cs.changes()) {
            changeResourceFactory.create(cd.notes(), user).prepareETag(h, user);
        }
        h.putBoolean(cs.furtherHiddenChanges());
    } catch (IOException | PermissionBackendException e) {
        throw new StorageException(e);
    }
    return h.hash().toString();
}
#end_block

#method_before
public QueryResult<T> query(Predicate<T> query) throws OrmException, QueryParseException {
    return query(ImmutableList.of(query)).get(0);
}
#method_after
public QueryResult<T> query(Predicate<T> query) throws StorageException, QueryParseException {
    return query(ImmutableList.of(query)).get(0);
}
#end_block

#method_before
public List<QueryResult<T>> query(List<Predicate<T>> queries) throws OrmException, QueryParseException {
    try {
        return query(null, queries);
    } catch (OrmException e) {
        if (e.getCause() != null) {
            Throwables.throwIfInstanceOf(e.getCause(), QueryParseException.class);
        }
        throw e;
    }
}
#method_after
public List<QueryResult<T>> query(List<Predicate<T>> queries) throws StorageException, QueryParseException {
    try {
        return query(null, queries);
    } catch (StorageException e) {
        if (e.getCause() != null) {
            Throwables.throwIfInstanceOf(e.getCause(), QueryParseException.class);
        }
        throw e;
    }
}
#end_block

#method_before
private List<QueryResult<T>> query(@Nullable List<String> queryStrings, List<Predicate<T>> queries) throws OrmException, QueryParseException {
    long startNanos = System.nanoTime();
    checkState(!used.getAndSet(true), "%s has already been used", getClass().getSimpleName());
    int cnt = queries.size();
    if (queryStrings != null) {
        int qs = queryStrings.size();
        checkArgument(qs == cnt, "got %s query strings but %s predicates", qs, cnt);
    }
    if (cnt == 0) {
        return ImmutableList.of();
    }
    if (isDisabled()) {
        return disabledResults(queryStrings, queries);
    }
    logger.atFine().log("Executing %d %s index queries for %s", cnt, schemaDef.getName(), callerFinder.findCaller());
    List<QueryResult<T>> out;
    try {
        // Parse and rewrite all queries.
        List<Integer> limits = new ArrayList<>(cnt);
        List<Predicate<T>> predicates = new ArrayList<>(cnt);
        List<DataSource<T>> sources = new ArrayList<>(cnt);
        int queryCount = 0;
        for (Predicate<T> q : queries) {
            int limit = getEffectiveLimit(q);
            limits.add(limit);
            if (limit == getBackendSupportedLimit()) {
                limit--;
            }
            int page = (start / limit) + 1;
            if (page > indexConfig.maxPages()) {
                throw new QueryParseException("Cannot go beyond page " + indexConfig.maxPages() + " of results");
            }
            // Always bump limit by 1, even if this results in exceeding the permitted
            // max for this user. The only way to see if there are more entities is to
            // ask for one more result from the query.
            QueryOptions opts = createOptions(indexConfig, start, limit + 1, getRequestedFields());
            logger.atFine().log("Query options: " + opts);
            Predicate<T> pred = rewriter.rewrite(q, opts);
            if (enforceVisibility) {
                pred = enforceVisibility(pred);
            }
            predicates.add(pred);
            logger.atFine().log("%s index query[%d]:\n%s", schemaDef.getName(), queryCount++, pred instanceof IndexedQuery ? pred.getChild(0) : pred);
            @SuppressWarnings("unchecked")
            DataSource<T> s = (DataSource<T>) pred;
            sources.add(s);
        }
        // Run each query asynchronously, if supported.
        List<ResultSet<T>> matches = new ArrayList<>(cnt);
        for (DataSource<T> s : sources) {
            matches.add(s.read());
        }
        out = new ArrayList<>(cnt);
        for (int i = 0; i < cnt; i++) {
            List<T> matchesList = matches.get(i).toList();
            logger.atFine().log("Matches[%d]:\n%s", i, lazy(() -> matchesList.stream().map(this::formatForLogging).collect(toSet())));
            out.add(QueryResult.create(queryStrings != null ? queryStrings.get(i) : null, predicates.get(i), limits.get(i), matchesList));
        }
        // Only measure successful queries that actually touched the index.
        metrics.executionTime.record(schemaDef.getName(), System.nanoTime() - startNanos, TimeUnit.NANOSECONDS);
    } catch (OrmException e) {
        Optional<QueryParseException> qpe = findQueryParseException(e);
        if (qpe.isPresent()) {
            throw new QueryParseException(qpe.get().getMessage(), e);
        }
        throw e;
    }
    return out;
}
#method_after
private List<QueryResult<T>> query(@Nullable List<String> queryStrings, List<Predicate<T>> queries) throws StorageException, QueryParseException {
    long startNanos = System.nanoTime();
    checkState(!used.getAndSet(true), "%s has already been used", getClass().getSimpleName());
    int cnt = queries.size();
    if (queryStrings != null) {
        int qs = queryStrings.size();
        checkArgument(qs == cnt, "got %s query strings but %s predicates", qs, cnt);
    }
    if (cnt == 0) {
        return ImmutableList.of();
    }
    if (isDisabled()) {
        return disabledResults(queryStrings, queries);
    }
    logger.atFine().log("Executing %d %s index queries for %s", cnt, schemaDef.getName(), callerFinder.findCaller());
    List<QueryResult<T>> out;
    try {
        // Parse and rewrite all queries.
        List<Integer> limits = new ArrayList<>(cnt);
        List<Predicate<T>> predicates = new ArrayList<>(cnt);
        List<DataSource<T>> sources = new ArrayList<>(cnt);
        int queryCount = 0;
        for (Predicate<T> q : queries) {
            int limit = getEffectiveLimit(q);
            limits.add(limit);
            if (limit == getBackendSupportedLimit()) {
                limit--;
            }
            int page = (start / limit) + 1;
            if (page > indexConfig.maxPages()) {
                throw new QueryParseException("Cannot go beyond page " + indexConfig.maxPages() + " of results");
            }
            // Always bump limit by 1, even if this results in exceeding the permitted
            // max for this user. The only way to see if there are more entities is to
            // ask for one more result from the query.
            QueryOptions opts = createOptions(indexConfig, start, limit + 1, getRequestedFields());
            logger.atFine().log("Query options: " + opts);
            Predicate<T> pred = rewriter.rewrite(q, opts);
            if (enforceVisibility) {
                pred = enforceVisibility(pred);
            }
            predicates.add(pred);
            logger.atFine().log("%s index query[%d]:\n%s", schemaDef.getName(), queryCount++, pred instanceof IndexedQuery ? pred.getChild(0) : pred);
            @SuppressWarnings("unchecked")
            DataSource<T> s = (DataSource<T>) pred;
            sources.add(s);
        }
        // Run each query asynchronously, if supported.
        List<ResultSet<T>> matches = new ArrayList<>(cnt);
        for (DataSource<T> s : sources) {
            matches.add(s.read());
        }
        out = new ArrayList<>(cnt);
        for (int i = 0; i < cnt; i++) {
            ImmutableList<T> matchesList = matches.get(i).toList();
            logger.atFine().log("Matches[%d]:\n%s", i, lazy(() -> matchesList.stream().map(this::formatForLogging).collect(toSet())));
            out.add(QueryResult.create(queryStrings != null ? queryStrings.get(i) : null, predicates.get(i), limits.get(i), matchesList));
        }
        // Only measure successful queries that actually touched the index.
        metrics.executionTime.record(schemaDef.getName(), System.nanoTime() - startNanos, TimeUnit.NANOSECONDS);
    } catch (StorageException e) {
        Optional<QueryParseException> qpe = findQueryParseException(e);
        if (qpe.isPresent()) {
            throw new QueryParseException(qpe.get().getMessage(), e);
        }
        throw e;
    }
    return out;
}
#end_block

#method_before
private Set<String> getRequestedFields() {
    if (requestedFields != null) {
        return requestedFields;
    }
    Index<?, T> index = indexes.getSearchIndex();
    return index != null ? index.getSchema().getStoredFields().keySet() : ImmutableSet.<String>of();
}
#method_after
private Set<String> getRequestedFields() {
    if (requestedFields != null) {
        return requestedFields;
    }
    Index<?, T> index = indexes.getSearchIndex();
    return index != null ? index.getSchema().getStoredFields().keySet() : ImmutableSet.of();
}
#end_block

#method_before
private int getEffectiveLimit(Predicate<T> p) {
    List<Integer> possibleLimits = new ArrayList<>(4);
    possibleLimits.add(getBackendSupportedLimit());
    possibleLimits.add(getPermittedLimit());
    if (userProvidedLimit > 0) {
        possibleLimits.add(userProvidedLimit);
    }
    if (limitField != null) {
        Integer limitFromPredicate = LimitPredicate.getLimit(limitField, p);
        if (limitFromPredicate != null) {
            possibleLimits.add(limitFromPredicate);
        }
    }
    int result = Ordering.natural().min(possibleLimits);
    // Should have short-circuited from #query or thrown some other exception before getting here.
    checkState(result > 0, "effective limit should be positive");
    return result;
}
#method_after
private int getEffectiveLimit(Predicate<T> p) {
    if (isNoLimit == true) {
        return Integer.MAX_VALUE;
    }
    List<Integer> possibleLimits = new ArrayList<>(4);
    possibleLimits.add(getBackendSupportedLimit());
    possibleLimits.add(getPermittedLimit());
    if (userProvidedLimit > 0) {
        possibleLimits.add(userProvidedLimit);
    }
    if (limitField != null) {
        Integer limitFromPredicate = LimitPredicate.getLimit(limitField, p);
        if (limitFromPredicate != null) {
            possibleLimits.add(limitFromPredicate);
        }
    }
    int result = Ordering.natural().min(possibleLimits);
    // Should have short-circuited from #query or thrown some other exception before getting here.
    checkState(result > 0, "effective limit should be positive");
    return result;
}
#end_block

#method_before
@Override
public void replace(ChangeData cd) throws IOException {
    Term id = LuceneChangeIndex.idTerm(cd);
    // toDocument is essentially static and doesn't depend on the specific
    // sub-index, so just pick one.
    Document doc = openIndex.toDocument(cd);
    try {
        if (cd.change().getStatus().isOpen()) {
            Futures.allAsList(closedIndex.delete(id), openIndex.replace(id, doc)).get();
        } else {
            Futures.allAsList(openIndex.delete(id), closedIndex.replace(id, doc)).get();
        }
    } catch (OrmException | ExecutionException | InterruptedException e) {
        throw new IOException(e);
    }
}
#method_after
@Override
public void replace(ChangeData cd) throws IOException {
    Term id = LuceneChangeIndex.idTerm(cd);
    // toDocument is essentially static and doesn't depend on the specific
    // sub-index, so just pick one.
    Document doc = openIndex.toDocument(cd);
    try {
        if (cd.change().isNew()) {
            Futures.allAsList(closedIndex.delete(id), openIndex.replace(id, doc)).get();
        } else {
            Futures.allAsList(openIndex.delete(id), closedIndex.replace(id, doc)).get();
        }
    } catch (StorageException | ExecutionException | InterruptedException e) {
        throw new IOException(e);
    }
}
#end_block

#method_before
@Override
public ResultSet<ChangeData> read() throws OrmException {
    if (Thread.interrupted()) {
        Thread.currentThread().interrupt();
        throw new OrmException("interrupted");
    }
    final Set<String> fields = IndexUtils.changeFields(opts);
    return new ChangeDataResults(executor.submit(new Callable<List<Document>>() {

        @Override
        public List<Document> call() throws IOException {
            return doRead(fields);
        }

        @Override
        public String toString() {
            return predicate.toString();
        }
    }), fields);
}
#method_after
@Override
public ResultSet<ChangeData> read() throws StorageException {
    if (Thread.interrupted()) {
        Thread.currentThread().interrupt();
        throw new StorageException("interrupted");
    }
    final Set<String> fields = IndexUtils.changeFields(opts);
    return new ChangeDataResults(executor.submit(new Callable<List<Document>>() {

        @Override
        public List<Document> call() throws IOException {
            return doRead(fields);
        }

        @Override
        public String toString() {
            return predicate.toString();
        }
    }), fields);
}
#end_block

#method_before
@Override
public ResultSet<FieldBundle> readRaw() throws OrmException {
    List<Document> documents;
    try {
        documents = doRead(IndexUtils.changeFields(opts));
    } catch (IOException e) {
        throw new OrmException(e);
    }
    List<FieldBundle> fieldBundles = documents.stream().map(rawDocumentMapper).collect(toList());
    return new ResultSet<FieldBundle>() {

        @Override
        public Iterator<FieldBundle> iterator() {
            return fieldBundles.iterator();
        }

        @Override
        public List<FieldBundle> toList() {
            return fieldBundles;
        }

        @Override
        public void close() {
        // Do nothing.
        }
    };
}
#method_after
@Override
public ResultSet<FieldBundle> readRaw() throws StorageException {
    List<Document> documents;
    try {
        documents = doRead(IndexUtils.changeFields(opts));
    } catch (IOException e) {
        throw new StorageException(e);
    }
    ImmutableList<FieldBundle> fieldBundles = documents.stream().map(rawDocumentMapper).collect(toImmutableList());
    return new ResultSet<FieldBundle>() {

        @Override
        public Iterator<FieldBundle> iterator() {
            return fieldBundles.iterator();
        }

        @Override
        public ImmutableList<FieldBundle> toList() {
            return fieldBundles;
        }

        @Override
        public void close() {
        // Do nothing.
        }
    };
}
#end_block

#method_before
@Override
public List<ChangeData> toList() {
    try {
        List<Document> docs = future.get();
        List<ChangeData> result = new ArrayList<>(docs.size());
        String idFieldName = LEGACY_ID.getName();
        for (Document doc : docs) {
            result.add(toChangeData(fields(doc, fields), fields, idFieldName));
        }
        return result;
    } catch (InterruptedException e) {
        close();
        throw new OrmException(e);
    } catch (ExecutionException e) {
        Throwables.throwIfUnchecked(e.getCause());
        throw new OrmException(e.getCause());
    }
}
#method_after
@Override
public ImmutableList<ChangeData> toList() {
    try {
        List<Document> docs = future.get();
        ImmutableList.Builder<ChangeData> result = ImmutableList.builderWithExpectedSize(docs.size());
        String idFieldName = LEGACY_ID.getName();
        for (Document doc : docs) {
            result.add(toChangeData(fields(doc, fields), fields, idFieldName));
        }
        return result.build();
    } catch (InterruptedException e) {
        close();
        throw new StorageException(e);
    } catch (ExecutionException e) {
        Throwables.throwIfUnchecked(e.getCause());
        throw new StorageException(e.getCause());
    }
}
#end_block

#method_before
private ChangeData toChangeData(ListMultimap<String, IndexableField> doc, Set<String> fields, String idFieldName) {
    ChangeData cd;
    // Either change or the ID field was guaranteed to be included in the call
    // to fields() above.
    IndexableField cb = Iterables.getFirst(doc.get(CHANGE_FIELD), null);
    if (cb != null) {
        BytesRef proto = cb.binaryValue();
        cd = changeDataFactory.create(CHANGE_CODEC.decode(proto.bytes, proto.offset, proto.length));
    } else {
        IndexableField f = Iterables.getFirst(doc.get(idFieldName), null);
        Change.Id id = new Change.Id(f.numericValue().intValue());
        // IndexUtils#changeFields ensures either CHANGE or PROJECT is always present.
        IndexableField project = doc.get(PROJECT.getName()).iterator().next();
        cd = changeDataFactory.create(new Project.NameKey(project.stringValue()), id);
    }
    if (fields.contains(PATCH_SET_FIELD)) {
        decodePatchSets(doc, cd);
    }
    if (fields.contains(APPROVAL_FIELD)) {
        decodeApprovals(doc, cd);
    }
    if (fields.contains(ADDED_FIELD) && fields.contains(DELETED_FIELD)) {
        decodeChangedLines(doc, cd);
    }
    if (fields.contains(MERGEABLE_FIELD)) {
        decodeMergeable(doc, cd);
    }
    if (fields.contains(REVIEWEDBY_FIELD)) {
        decodeReviewedBy(doc, cd);
    }
    if (fields.contains(HASHTAG_FIELD)) {
        decodeHashtags(doc, cd);
    }
    if (fields.contains(STAR_FIELD)) {
        decodeStar(doc, cd);
    }
    if (fields.contains(REVIEWER_FIELD)) {
        decodeReviewers(doc, cd);
    }
    if (fields.contains(REVIEWER_BY_EMAIL_FIELD)) {
        decodeReviewersByEmail(doc, cd);
    }
    if (fields.contains(PENDING_REVIEWER_FIELD)) {
        decodePendingReviewers(doc, cd);
    }
    if (fields.contains(PENDING_REVIEWER_BY_EMAIL_FIELD)) {
        decodePendingReviewersByEmail(doc, cd);
    }
    decodeSubmitRecords(doc, SUBMIT_RECORD_STRICT_FIELD, ChangeField.SUBMIT_RULE_OPTIONS_STRICT, cd);
    decodeSubmitRecords(doc, SUBMIT_RECORD_LENIENT_FIELD, ChangeField.SUBMIT_RULE_OPTIONS_LENIENT, cd);
    if (fields.contains(REF_STATE_FIELD)) {
        decodeRefStates(doc, cd);
    }
    if (fields.contains(REF_STATE_PATTERN_FIELD)) {
        decodeRefStatePatterns(doc, cd);
    }
    decodeUnresolvedCommentCount(doc, cd);
    decodeTotalCommentCount(doc, cd);
    return cd;
}
#method_after
private ChangeData toChangeData(ListMultimap<String, IndexableField> doc, Set<String> fields, String idFieldName) {
    ChangeData cd;
    // Either change or the ID field was guaranteed to be included in the call
    // to fields() above.
    IndexableField cb = Iterables.getFirst(doc.get(CHANGE_FIELD), null);
    if (cb != null) {
        BytesRef proto = cb.binaryValue();
        cd = changeDataFactory.create(parseProtoFrom(proto, ChangeProtoConverter.INSTANCE));
    } else {
        IndexableField f = Iterables.getFirst(doc.get(idFieldName), null);
        Change.Id id = new Change.Id(f.numericValue().intValue());
        // IndexUtils#changeFields ensures either CHANGE or PROJECT is always present.
        IndexableField project = doc.get(PROJECT.getName()).iterator().next();
        cd = changeDataFactory.create(new Project.NameKey(project.stringValue()), id);
    }
    if (fields.contains(PATCH_SET_FIELD)) {
        decodePatchSets(doc, cd);
    }
    if (fields.contains(APPROVAL_FIELD)) {
        decodeApprovals(doc, cd);
    }
    if (fields.contains(ADDED_FIELD) && fields.contains(DELETED_FIELD)) {
        decodeChangedLines(doc, cd);
    }
    if (fields.contains(MERGEABLE_FIELD)) {
        decodeMergeable(doc, cd);
    }
    if (fields.contains(REVIEWEDBY_FIELD)) {
        decodeReviewedBy(doc, cd);
    }
    if (fields.contains(HASHTAG_FIELD)) {
        decodeHashtags(doc, cd);
    }
    if (fields.contains(STAR_FIELD)) {
        decodeStar(doc, cd);
    }
    if (fields.contains(REVIEWER_FIELD)) {
        decodeReviewers(doc, cd);
    }
    if (fields.contains(REVIEWER_BY_EMAIL_FIELD)) {
        decodeReviewersByEmail(doc, cd);
    }
    if (fields.contains(PENDING_REVIEWER_FIELD)) {
        decodePendingReviewers(doc, cd);
    }
    if (fields.contains(PENDING_REVIEWER_BY_EMAIL_FIELD)) {
        decodePendingReviewersByEmail(doc, cd);
    }
    decodeSubmitRecords(doc, SUBMIT_RECORD_STRICT_FIELD, ChangeField.SUBMIT_RULE_OPTIONS_STRICT, cd);
    decodeSubmitRecords(doc, SUBMIT_RECORD_LENIENT_FIELD, ChangeField.SUBMIT_RULE_OPTIONS_LENIENT, cd);
    if (fields.contains(REF_STATE_FIELD)) {
        decodeRefStates(doc, cd);
    }
    if (fields.contains(REF_STATE_PATTERN_FIELD)) {
        decodeRefStatePatterns(doc, cd);
    }
    decodeUnresolvedCommentCount(doc, cd);
    decodeTotalCommentCount(doc, cd);
    return cd;
}
#end_block

#method_before
public ChangeInfo format(ChangeResource rsrc) throws OrmException {
    return format(changeDataFactory.create(rsrc.getNotes()));
}
#method_after
public ChangeInfo format(ChangeResource rsrc) throws StorageException {
    return format(changeDataFactory.create(rsrc.getNotes()));
}
#end_block

#method_before
public ChangeInfo format(Change change) throws OrmException {
    return format(changeDataFactory.create(change));
}
#method_after
public ChangeInfo format(Change change) throws StorageException {
    return format(changeDataFactory.create(change));
}
#end_block

#method_before
public ChangeInfo format(Project.NameKey project, Change.Id id) throws OrmException {
    return format(project, id, ChangeInfo::new);
}
#method_after
public ChangeInfo format(Project.NameKey project, Change.Id id) throws StorageException {
    return format(project, id, ChangeInfo::new);
}
#end_block

#method_before
public ChangeInfo format(ChangeData cd) throws OrmException {
    return format(cd, Optional.empty(), true, ChangeInfo::new);
}
#method_after
public ChangeInfo format(ChangeData cd) throws StorageException {
    return format(cd, Optional.empty(), true, ChangeInfo::new);
}
#end_block

#method_before
public ChangeInfo format(RevisionResource rsrc) throws OrmException {
    ChangeData cd = changeDataFactory.create(rsrc.getNotes());
    return format(cd, Optional.of(rsrc.getPatchSet().getId()), true, ChangeInfo::new);
}
#method_after
public ChangeInfo format(RevisionResource rsrc) throws StorageException {
    ChangeData cd = changeDataFactory.create(rsrc.getNotes());
    return format(cd, Optional.of(rsrc.getPatchSet().getId()), true, ChangeInfo::new);
}
#end_block

#method_before
public List<ChangeInfo> format(Collection<ChangeData> in) throws OrmException, PermissionBackendException {
    accountLoader = accountLoaderFactory.create(has(DETAILED_ACCOUNTS));
    ensureLoaded(in);
    List<ChangeInfo> out = new ArrayList<>(in.size());
    for (ChangeData cd : in) {
        out.add(format(cd, Optional.empty(), false, ChangeInfo::new));
    }
    accountLoader.fill();
    return out;
}
#method_after
public List<ChangeInfo> format(Collection<ChangeData> in) throws StorageException, PermissionBackendException {
    accountLoader = accountLoaderFactory.create(has(DETAILED_ACCOUNTS));
    ensureLoaded(in);
    List<ChangeInfo> out = new ArrayList<>(in.size());
    for (ChangeData cd : in) {
        out.add(format(cd, Optional.empty(), false, ChangeInfo::new));
    }
    accountLoader.fill();
    return out;
}
#end_block

#method_before
public <I extends ChangeInfo> I format(Project.NameKey project, Change.Id id, Supplier<I> changeInfoSupplier) throws OrmException {
    ChangeNotes notes;
    try {
        notes = notesFactory.createChecked(project, id);
    } catch (OrmException e) {
        if (!has(CHECK)) {
            throw e;
        }
        return checkOnly(changeDataFactory.create(project, id), changeInfoSupplier);
    }
    return format(changeDataFactory.create(notes), Optional.empty(), true, changeInfoSupplier);
}
#method_after
public <I extends ChangeInfo> I format(Project.NameKey project, Change.Id id, Supplier<I> changeInfoSupplier) throws StorageException {
    ChangeNotes notes;
    try {
        notes = notesFactory.createChecked(project, id);
    } catch (StorageException e) {
        if (!has(CHECK)) {
            throw e;
        }
        return checkOnly(changeDataFactory.create(project, id), changeInfoSupplier);
    }
    return format(changeDataFactory.create(notes), Optional.empty(), true, changeInfoSupplier);
}
#end_block

#method_before
private <I extends ChangeInfo> I format(ChangeData cd, Optional<PatchSet.Id> limitToPsId, boolean fillAccountLoader, Supplier<I> changeInfoSupplier) throws OrmException {
    try {
        if (fillAccountLoader) {
            accountLoader = accountLoaderFactory.create(has(DETAILED_ACCOUNTS));
            I res = toChangeInfo(cd, limitToPsId, changeInfoSupplier);
            accountLoader.fill();
            return res;
        }
        return toChangeInfo(cd, limitToPsId, changeInfoSupplier);
    } catch (PatchListNotAvailableException | GpgException | IOException | PermissionBackendException | RuntimeException e) {
        if (!has(CHECK)) {
            Throwables.throwIfInstanceOf(e, OrmException.class);
            throw new OrmException(e);
        }
        return checkOnly(cd, changeInfoSupplier);
    }
}
#method_after
private <I extends ChangeInfo> I format(ChangeData cd, Optional<PatchSet.Id> limitToPsId, boolean fillAccountLoader, Supplier<I> changeInfoSupplier) throws StorageException {
    try {
        if (fillAccountLoader) {
            accountLoader = accountLoaderFactory.create(has(DETAILED_ACCOUNTS));
            I res = toChangeInfo(cd, limitToPsId, changeInfoSupplier);
            accountLoader.fill();
            return res;
        }
        return toChangeInfo(cd, limitToPsId, changeInfoSupplier);
    } catch (PatchListNotAvailableException | GpgException | IOException | PermissionBackendException | RuntimeException e) {
        if (!has(CHECK)) {
            Throwables.throwIfInstanceOf(e, StorageException.class);
            throw new StorageException(e);
        }
        return checkOnly(cd, changeInfoSupplier);
    }
}
#end_block

#method_before
private void ensureLoaded(Iterable<ChangeData> all) throws OrmException {
    if (lazyLoad) {
        ChangeData.ensureChangeLoaded(all);
        if (has(ALL_REVISIONS)) {
            ChangeData.ensureAllPatchSetsLoaded(all);
        } else if (has(CURRENT_REVISION) || has(MESSAGES)) {
            ChangeData.ensureCurrentPatchSetLoaded(all);
        }
        if (has(REVIEWED) && userProvider.get().isIdentifiedUser()) {
            ChangeData.ensureReviewedByLoadedForOpenChanges(all);
        }
        ChangeData.ensureCurrentApprovalsLoaded(all);
    } else {
        for (ChangeData cd : all) {
            cd.setLazyLoad(false);
        }
    }
}
#method_after
private void ensureLoaded(Iterable<ChangeData> all) throws StorageException {
    if (lazyLoad) {
        ChangeData.ensureChangeLoaded(all);
        if (has(ALL_REVISIONS)) {
            ChangeData.ensureAllPatchSetsLoaded(all);
        } else if (has(CURRENT_REVISION) || has(MESSAGES)) {
            ChangeData.ensureCurrentPatchSetLoaded(all);
        }
        if (has(REVIEWED) && userProvider.get().isIdentifiedUser()) {
            ChangeData.ensureReviewedByLoadedForOpenChanges(all);
        }
        ChangeData.ensureCurrentApprovalsLoaded(all);
    } else {
        for (ChangeData cd : all) {
            cd.setLazyLoad(false);
        }
    }
}
#end_block

#method_before
private <I extends ChangeInfo> I checkOnly(ChangeData cd, Supplier<I> changeInfoSupplier) {
    ChangeNotes notes;
    try {
        notes = cd.notes();
    } catch (OrmException e) {
        String msg = "Error loading change";
        logger.atWarning().withCause(e).log(msg + " %s", cd.getId());
        I info = changeInfoSupplier.get();
        info._number = cd.getId().get();
        ProblemInfo p = new ProblemInfo();
        p.message = msg;
        info.problems = Lists.newArrayList(p);
        return info;
    }
    ConsistencyChecker.Result result = checkerProvider.get().check(notes, fix);
    I info = changeInfoSupplier.get();
    Change c = result.change();
    if (c != null) {
        info.project = c.getProject().get();
        info.branch = c.getDest().getShortName();
        info.topic = c.getTopic();
        info.changeId = c.getKey().get();
        info.subject = c.getSubject();
        info.status = c.getStatus().asChangeStatus();
        info.owner = new AccountInfo(c.getOwner().get());
        info.created = c.getCreatedOn();
        info.updated = c.getLastUpdatedOn();
        info._number = c.getId().get();
        info.problems = result.problems();
        info.isPrivate = c.isPrivate() ? true : null;
        info.workInProgress = c.isWorkInProgress() ? true : null;
        info.hasReviewStarted = c.hasReviewStarted();
        finish(info);
    } else {
        info._number = result.id().get();
        info.problems = result.problems();
    }
    return info;
}
#method_after
private <I extends ChangeInfo> I checkOnly(ChangeData cd, Supplier<I> changeInfoSupplier) {
    ChangeNotes notes;
    try {
        notes = cd.notes();
    } catch (StorageException e) {
        String msg = "Error loading change";
        logger.atWarning().withCause(e).log(msg + " %s", cd.getId());
        I info = changeInfoSupplier.get();
        info._number = cd.getId().get();
        ProblemInfo p = new ProblemInfo();
        p.message = msg;
        info.problems = Lists.newArrayList(p);
        return info;
    }
    ConsistencyChecker.Result result = checkerProvider.get().check(notes, fix);
    I info = changeInfoSupplier.get();
    Change c = result.change();
    if (c != null) {
        info.project = c.getProject().get();
        info.branch = c.getDest().getShortName();
        info.topic = c.getTopic();
        info.changeId = c.getKey().get();
        info.subject = c.getSubject();
        info.status = c.getStatus().asChangeStatus();
        info.owner = new AccountInfo(c.getOwner().get());
        info.created = c.getCreatedOn();
        info.updated = c.getLastUpdatedOn();
        info._number = c.getId().get();
        info.problems = result.problems();
        info.isPrivate = c.isPrivate() ? true : null;
        info.workInProgress = c.isWorkInProgress() ? true : null;
        info.hasReviewStarted = c.hasReviewStarted();
        finish(info);
    } else {
        info._number = result.id().get();
        info.problems = result.problems();
    }
    return info;
}
#end_block

#method_before
private <I extends ChangeInfo> I toChangeInfo(ChangeData cd, Optional<PatchSet.Id> limitToPsId, Supplier<I> changeInfoSupplier) throws PatchListNotAvailableException, GpgException, OrmException, PermissionBackendException, IOException {
    try (Timer0.Context ignored = metrics.toChangeInfoLatency.start()) {
        return toChangeInfoImpl(cd, limitToPsId, changeInfoSupplier);
    }
}
#method_after
private <I extends ChangeInfo> I toChangeInfo(ChangeData cd, Optional<PatchSet.Id> limitToPsId, Supplier<I> changeInfoSupplier) throws PatchListNotAvailableException, GpgException, StorageException, PermissionBackendException, IOException {
    try (Timer0.Context ignored = metrics.toChangeInfoLatency.start()) {
        return toChangeInfoImpl(cd, limitToPsId, changeInfoSupplier);
    }
}
#end_block

#method_before
private <I extends ChangeInfo> I toChangeInfoImpl(ChangeData cd, Optional<PatchSet.Id> limitToPsId, Supplier<I> changeInfoSupplier) throws PatchListNotAvailableException, GpgException, OrmException, PermissionBackendException, IOException {
    I out = changeInfoSupplier.get();
    CurrentUser user = userProvider.get();
    if (has(CHECK)) {
        out.problems = checkerProvider.get().check(cd.notes(), fix).problems();
        // If any problems were fixed, the ChangeData needs to be reloaded.
        for (ProblemInfo p : out.problems) {
            if (p.status == ProblemInfo.Status.FIXED) {
                cd = changeDataFactory.create(cd.project(), cd.getId());
                break;
            }
        }
    }
    Change in = cd.change();
    out.project = in.getProject().get();
    out.branch = in.getDest().getShortName();
    out.topic = in.getTopic();
    out.assignee = in.getAssignee() != null ? accountLoader.get(in.getAssignee()) : null;
    out.hashtags = cd.hashtags();
    out.changeId = in.getKey().get();
    if (in.getStatus().isOpen()) {
        SubmitTypeRecord str = cd.submitTypeRecord();
        if (str.isOk()) {
            out.submitType = str.type;
        }
        if (!has(SKIP_MERGEABLE)) {
            out.mergeable = cd.isMergeable();
        }
        if (has(SUBMITTABLE)) {
            out.submittable = submittable(cd);
        }
    }
    Optional<ChangedLines> changedLines = cd.changedLines();
    if (changedLines.isPresent()) {
        out.insertions = changedLines.get().insertions;
        out.deletions = changedLines.get().deletions;
    }
    out.isPrivate = in.isPrivate() ? true : null;
    out.workInProgress = in.isWorkInProgress() ? true : null;
    out.hasReviewStarted = in.hasReviewStarted();
    out.subject = in.getSubject();
    out.status = in.getStatus().asChangeStatus();
    out.owner = accountLoader.get(in.getOwner());
    out.created = in.getCreatedOn();
    out.updated = in.getLastUpdatedOn();
    out._number = in.getId().get();
    out.totalCommentCount = cd.totalCommentCount();
    out.unresolvedCommentCount = cd.unresolvedCommentCount();
    if (user.isIdentifiedUser()) {
        Collection<String> stars = cd.stars(user.getAccountId());
        out.starred = stars.contains(StarredChangesUtil.DEFAULT_LABEL) ? true : null;
        if (!stars.isEmpty()) {
            out.stars = stars;
        }
    }
    if (in.getStatus().isOpen() && has(REVIEWED) && user.isIdentifiedUser()) {
        out.reviewed = cd.isReviewedBy(user.getAccountId()) ? true : null;
    }
    out.labels = labelsJson.labelsFor(accountLoader, cd, has(LABELS), has(DETAILED_LABELS));
    out.requirements = requirementsFor(cd);
    if (out.labels != null && has(DETAILED_LABELS)) {
        // list permitted labels, since users can't vote on those patch sets.
        if (user.isIdentifiedUser() && (!limitToPsId.isPresent() || limitToPsId.get().equals(in.currentPatchSetId()))) {
            out.permittedLabels = cd.change().getStatus() != Change.Status.ABANDONED ? labelsJson.permittedLabels(user.getAccountId(), cd) : ImmutableMap.of();
        }
        out.reviewers = reviewerMap(cd.reviewers(), cd.reviewersByEmail(), false);
        out.pendingReviewers = reviewerMap(cd.pendingReviewers(), cd.pendingReviewersByEmail(), true);
        out.removableReviewers = removableReviewers(cd, out);
    }
    setSubmitter(cd, out);
    if (pluginDefinedAttributesFactory.isPresent()) {
        out.plugins = pluginDefinedAttributesFactory.get().create(cd);
    }
    out.revertOf = cd.change().getRevertOf() != null ? cd.change().getRevertOf().get() : null;
    if (has(REVIEWER_UPDATES)) {
        out.reviewerUpdates = reviewerUpdates(cd);
    }
    boolean needMessages = has(MESSAGES);
    boolean needRevisions = has(ALL_REVISIONS) || has(CURRENT_REVISION) || limitToPsId.isPresent();
    Map<PatchSet.Id, PatchSet> src;
    if (needMessages || needRevisions) {
        src = loadPatchSets(cd, limitToPsId);
    } else {
        src = null;
    }
    if (needMessages) {
        out.messages = messages(cd);
    }
    finish(out);
    // it will be passed to ActionVisitors as-is.
    if (needRevisions) {
        out.revisions = revisionJson.getRevisions(accountLoader, cd, src, limitToPsId, out);
        if (out.revisions != null) {
            for (Map.Entry<String, RevisionInfo> entry : out.revisions.entrySet()) {
                if (entry.getValue().isCurrent) {
                    out.currentRevision = entry.getKey();
                    break;
                }
            }
        }
    }
    if (has(CURRENT_ACTIONS) || has(CHANGE_ACTIONS)) {
        actionJson.addChangeActions(out, cd.notes());
    }
    if (has(TRACKING_IDS)) {
        ListMultimap<String, String> set = trackingFooters.extract(cd.commitFooters());
        out.trackingIds = set.entries().stream().map(e -> new TrackingIdInfo(e.getKey(), e.getValue())).collect(toList());
    }
    return out;
}
#method_after
private <I extends ChangeInfo> I toChangeInfoImpl(ChangeData cd, Optional<PatchSet.Id> limitToPsId, Supplier<I> changeInfoSupplier) throws PatchListNotAvailableException, GpgException, StorageException, PermissionBackendException, IOException {
    I out = changeInfoSupplier.get();
    CurrentUser user = userProvider.get();
    if (has(CHECK)) {
        out.problems = checkerProvider.get().check(cd.notes(), fix).problems();
        // If any problems were fixed, the ChangeData needs to be reloaded.
        for (ProblemInfo p : out.problems) {
            if (p.status == ProblemInfo.Status.FIXED) {
                cd = changeDataFactory.create(cd.project(), cd.getId());
                break;
            }
        }
    }
    Change in = cd.change();
    out.project = in.getProject().get();
    out.branch = in.getDest().getShortName();
    out.topic = in.getTopic();
    out.assignee = in.getAssignee() != null ? accountLoader.get(in.getAssignee()) : null;
    out.hashtags = cd.hashtags();
    out.changeId = in.getKey().get();
    if (in.isNew()) {
        SubmitTypeRecord str = cd.submitTypeRecord();
        if (str.isOk()) {
            out.submitType = str.type;
        }
        if (!excludeMergeableInChangeInfo && !has(SKIP_MERGEABLE)) {
            out.mergeable = cd.isMergeable();
        }
        if (has(SUBMITTABLE)) {
            out.submittable = submittable(cd);
        }
    }
    Optional<ChangedLines> changedLines = cd.changedLines();
    if (changedLines.isPresent()) {
        out.insertions = changedLines.get().insertions;
        out.deletions = changedLines.get().deletions;
    }
    out.isPrivate = in.isPrivate() ? true : null;
    out.workInProgress = in.isWorkInProgress() ? true : null;
    out.hasReviewStarted = in.hasReviewStarted();
    out.subject = in.getSubject();
    out.status = in.getStatus().asChangeStatus();
    out.owner = accountLoader.get(in.getOwner());
    out.created = in.getCreatedOn();
    out.updated = in.getLastUpdatedOn();
    out._number = in.getId().get();
    out.totalCommentCount = cd.totalCommentCount();
    out.unresolvedCommentCount = cd.unresolvedCommentCount();
    if (user.isIdentifiedUser()) {
        Collection<String> stars = cd.stars(user.getAccountId());
        out.starred = stars.contains(StarredChangesUtil.DEFAULT_LABEL) ? true : null;
        if (!stars.isEmpty()) {
            out.stars = stars;
        }
    }
    if (in.isNew() && has(REVIEWED) && user.isIdentifiedUser()) {
        out.reviewed = cd.isReviewedBy(user.getAccountId()) ? true : null;
    }
    out.labels = labelsJson.labelsFor(accountLoader, cd, has(LABELS), has(DETAILED_LABELS));
    out.requirements = requirementsFor(cd);
    if (out.labels != null && has(DETAILED_LABELS)) {
        // list permitted labels, since users can't vote on those patch sets.
        if (user.isIdentifiedUser() && (!limitToPsId.isPresent() || limitToPsId.get().equals(in.currentPatchSetId()))) {
            out.permittedLabels = !cd.change().isAbandoned() ? labelsJson.permittedLabels(user.getAccountId(), cd) : ImmutableMap.of();
        }
        out.reviewers = reviewerMap(cd.reviewers(), cd.reviewersByEmail(), false);
        out.pendingReviewers = reviewerMap(cd.pendingReviewers(), cd.pendingReviewersByEmail(), true);
        out.removableReviewers = removableReviewers(cd, out);
    }
    setSubmitter(cd, out);
    if (pluginDefinedAttributesFactory.isPresent()) {
        out.plugins = pluginDefinedAttributesFactory.get().create(cd);
    }
    out.revertOf = cd.change().getRevertOf() != null ? cd.change().getRevertOf().get() : null;
    if (has(REVIEWER_UPDATES)) {
        out.reviewerUpdates = reviewerUpdates(cd);
    }
    boolean needMessages = has(MESSAGES);
    boolean needRevisions = has(ALL_REVISIONS) || has(CURRENT_REVISION) || limitToPsId.isPresent();
    Map<PatchSet.Id, PatchSet> src;
    if (needMessages || needRevisions) {
        src = loadPatchSets(cd, limitToPsId);
    } else {
        src = null;
    }
    if (needMessages) {
        out.messages = messages(cd);
    }
    finish(out);
    // it will be passed to ActionVisitors as-is.
    if (needRevisions) {
        out.revisions = revisionJson.getRevisions(accountLoader, cd, src, limitToPsId, out);
        if (out.revisions != null) {
            for (Map.Entry<String, RevisionInfo> entry : out.revisions.entrySet()) {
                if (entry.getValue().isCurrent) {
                    out.currentRevision = entry.getKey();
                    break;
                }
            }
        }
    }
    if (has(CURRENT_ACTIONS) || has(CHANGE_ACTIONS)) {
        actionJson.addChangeActions(out, cd.notes());
    }
    if (has(TRACKING_IDS)) {
        ListMultimap<String, String> set = trackingFooters.extract(cd.commitFooters());
        out.trackingIds = set.entries().stream().map(e -> new TrackingIdInfo(e.getKey(), e.getValue())).collect(toList());
    }
    return out;
}
#end_block

#method_before
private Collection<ReviewerUpdateInfo> reviewerUpdates(ChangeData cd) throws OrmException {
    List<ReviewerStatusUpdate> reviewerUpdates = cd.reviewerUpdates();
    List<ReviewerUpdateInfo> result = new ArrayList<>(reviewerUpdates.size());
    for (ReviewerStatusUpdate c : reviewerUpdates) {
        ReviewerUpdateInfo change = new ReviewerUpdateInfo();
        change.updated = c.date();
        change.state = c.state().asReviewerState();
        change.updatedBy = accountLoader.get(c.updatedBy());
        change.reviewer = accountLoader.get(c.reviewer());
        result.add(change);
    }
    return result;
}
#method_after
private Collection<ReviewerUpdateInfo> reviewerUpdates(ChangeData cd) throws StorageException {
    List<ReviewerStatusUpdate> reviewerUpdates = cd.reviewerUpdates();
    List<ReviewerUpdateInfo> result = new ArrayList<>(reviewerUpdates.size());
    for (ReviewerStatusUpdate c : reviewerUpdates) {
        ReviewerUpdateInfo change = new ReviewerUpdateInfo();
        change.updated = c.date();
        change.state = c.state().asReviewerState();
        change.updatedBy = accountLoader.get(c.updatedBy());
        change.reviewer = accountLoader.get(c.reviewer());
        result.add(change);
    }
    return result;
}
#end_block

#method_before
private void setSubmitter(ChangeData cd, ChangeInfo out) throws OrmException {
    Optional<PatchSetApproval> s = cd.getSubmitApproval();
    if (!s.isPresent()) {
        return;
    }
    out.submitted = s.get().getGranted();
    out.submitter = accountLoader.get(s.get().getAccountId());
}
#method_after
private void setSubmitter(ChangeData cd, ChangeInfo out) throws StorageException {
    Optional<PatchSetApproval> s = cd.getSubmitApproval();
    if (!s.isPresent()) {
        return;
    }
    out.submitted = s.get().getGranted();
    out.submitter = accountLoader.get(s.get().getAccountId());
}
#end_block

#method_before
private Collection<ChangeMessageInfo> messages(ChangeData cd) throws OrmException {
    List<ChangeMessage> messages = cmUtil.byChange(cd.notes());
    if (messages.isEmpty()) {
        return Collections.emptyList();
    }
    List<ChangeMessageInfo> result = Lists.newArrayListWithCapacity(messages.size());
    for (ChangeMessage message : messages) {
        result.add(createChangeMessageInfo(message, accountLoader));
    }
    return result;
}
#method_after
private Collection<ChangeMessageInfo> messages(ChangeData cd) throws StorageException {
    List<ChangeMessage> messages = cmUtil.byChange(cd.notes());
    if (messages.isEmpty()) {
        return Collections.emptyList();
    }
    List<ChangeMessageInfo> result = Lists.newArrayListWithCapacity(messages.size());
    for (ChangeMessage message : messages) {
        result.add(createChangeMessageInfo(message, accountLoader));
    }
    return result;
}
#end_block

#method_before
private Collection<AccountInfo> removableReviewers(ChangeData cd, ChangeInfo out) throws PermissionBackendException, OrmException {
    // Although this is called removableReviewers, this method also determines
    // which CCs are removable.
    // 
    // For reviewers, we need to look at each approval, because the reviewer
    // should only be considered removable if *all* of their approvals can be
    // removed. First, add all reviewers with *any* removable approval to the
    // "removable" set. Along the way, if we encounter a non-removable approval,
    // add the reviewer to the "fixed" set. Before we return, remove all members
    // of "fixed" from "removable", because not all of their approvals can be
    // removed.
    Collection<LabelInfo> labels = out.labels.values();
    Set<Account.Id> fixed = Sets.newHashSetWithExpectedSize(labels.size());
    Set<Account.Id> removable = Sets.newHashSetWithExpectedSize(labels.size());
    // Check if the user has the permission to remove a reviewer. This means we can bypass the
    // testRemoveReviewer check for a specific reviewer in the loop saving potentially many
    // permission checks.
    boolean canRemoveAnyReviewer = permissionBackendForChange(userProvider.get(), cd).test(ChangePermission.REMOVE_REVIEWER);
    for (LabelInfo label : labels) {
        if (label.all == null) {
            continue;
        }
        for (ApprovalInfo ai : label.all) {
            Account.Id id = new Account.Id(ai._accountId);
            if (canRemoveAnyReviewer || removeReviewerControl.testRemoveReviewer(cd, userProvider.get(), id, MoreObjects.firstNonNull(ai.value, 0))) {
                removable.add(id);
            } else {
                fixed.add(id);
            }
        }
    }
    // CCs are simpler than reviewers. They are removable if the ChangeControl
    // would permit a non-negative approval by that account to be removed, in
    // which case add them to removable. We don't need to add unremovable CCs to
    // "fixed" because we only visit each CC once here.
    Collection<AccountInfo> ccs = out.reviewers.get(ReviewerState.CC);
    if (ccs != null) {
        for (AccountInfo ai : ccs) {
            if (ai._accountId != null) {
                Account.Id id = new Account.Id(ai._accountId);
                if (canRemoveAnyReviewer || removeReviewerControl.testRemoveReviewer(cd, userProvider.get(), id, 0)) {
                    removable.add(id);
                }
            }
        }
    }
    // Subtract any reviewers with non-removable approvals from the "removable"
    // set. This also subtracts any CCs that for some reason also hold
    // unremovable approvals.
    removable.removeAll(fixed);
    List<AccountInfo> result = Lists.newArrayListWithCapacity(removable.size());
    for (Account.Id id : removable) {
        result.add(accountLoader.get(id));
    }
    // Reviewers added by email are always removable
    for (Collection<AccountInfo> infos : out.reviewers.values()) {
        for (AccountInfo info : infos) {
            if (info._accountId == null) {
                result.add(info);
            }
        }
    }
    return result;
}
#method_after
private Collection<AccountInfo> removableReviewers(ChangeData cd, ChangeInfo out) throws PermissionBackendException, StorageException {
    // Although this is called removableReviewers, this method also determines
    // which CCs are removable.
    // 
    // For reviewers, we need to look at each approval, because the reviewer
    // should only be considered removable if *all* of their approvals can be
    // removed. First, add all reviewers with *any* removable approval to the
    // "removable" set. Along the way, if we encounter a non-removable approval,
    // add the reviewer to the "fixed" set. Before we return, remove all members
    // of "fixed" from "removable", because not all of their approvals can be
    // removed.
    Collection<LabelInfo> labels = out.labels.values();
    Set<Account.Id> fixed = Sets.newHashSetWithExpectedSize(labels.size());
    Set<Account.Id> removable = Sets.newHashSetWithExpectedSize(labels.size());
    // Check if the user has the permission to remove a reviewer. This means we can bypass the
    // testRemoveReviewer check for a specific reviewer in the loop saving potentially many
    // permission checks.
    boolean canRemoveAnyReviewer = permissionBackendForChange(userProvider.get(), cd).test(ChangePermission.REMOVE_REVIEWER);
    for (LabelInfo label : labels) {
        if (label.all == null) {
            continue;
        }
        for (ApprovalInfo ai : label.all) {
            Account.Id id = new Account.Id(ai._accountId);
            if (canRemoveAnyReviewer || removeReviewerControl.testRemoveReviewer(cd, userProvider.get(), id, MoreObjects.firstNonNull(ai.value, 0))) {
                removable.add(id);
            } else {
                fixed.add(id);
            }
        }
    }
    // CCs are simpler than reviewers. They are removable if the ChangeControl
    // would permit a non-negative approval by that account to be removed, in
    // which case add them to removable. We don't need to add unremovable CCs to
    // "fixed" because we only visit each CC once here.
    Collection<AccountInfo> ccs = out.reviewers.get(ReviewerState.CC);
    if (ccs != null) {
        for (AccountInfo ai : ccs) {
            if (ai._accountId != null) {
                Account.Id id = new Account.Id(ai._accountId);
                if (canRemoveAnyReviewer || removeReviewerControl.testRemoveReviewer(cd, userProvider.get(), id, 0)) {
                    removable.add(id);
                }
            }
        }
    }
    // Subtract any reviewers with non-removable approvals from the "removable"
    // set. This also subtracts any CCs that for some reason also hold
    // unremovable approvals.
    removable.removeAll(fixed);
    List<AccountInfo> result = Lists.newArrayListWithCapacity(removable.size());
    for (Account.Id id : removable) {
        result.add(accountLoader.get(id));
    }
    // Reviewers added by email are always removable
    for (Collection<AccountInfo> infos : out.reviewers.values()) {
        for (AccountInfo info : infos) {
            if (info._accountId == null) {
                result.add(info);
            }
        }
    }
    return result;
}
#end_block

#method_before
private Map<PatchSet.Id, PatchSet> loadPatchSets(ChangeData cd, Optional<PatchSet.Id> limitToPsId) throws OrmException {
    Collection<PatchSet> src;
    if (has(ALL_REVISIONS) || has(MESSAGES)) {
        src = cd.patchSets();
    } else {
        PatchSet ps;
        if (limitToPsId.isPresent()) {
            ps = cd.patchSet(limitToPsId.get());
            if (ps == null) {
                throw new OrmException("missing patch set " + limitToPsId.get());
            }
        } else {
            ps = cd.currentPatchSet();
            if (ps == null) {
                throw new OrmException("missing current patch set for change " + cd.getId());
            }
        }
        src = Collections.singletonList(ps);
    }
    Map<PatchSet.Id, PatchSet> map = Maps.newHashMapWithExpectedSize(src.size());
    for (PatchSet patchSet : src) {
        map.put(patchSet.getId(), patchSet);
    }
    return map;
}
#method_after
private Map<PatchSet.Id, PatchSet> loadPatchSets(ChangeData cd, Optional<PatchSet.Id> limitToPsId) throws StorageException {
    Collection<PatchSet> src;
    if (has(ALL_REVISIONS) || has(MESSAGES)) {
        src = cd.patchSets();
    } else {
        PatchSet ps;
        if (limitToPsId.isPresent()) {
            ps = cd.patchSet(limitToPsId.get());
            if (ps == null) {
                throw new StorageException("missing patch set " + limitToPsId.get());
            }
        } else {
            ps = cd.currentPatchSet();
            if (ps == null) {
                throw new StorageException("missing current patch set for change " + cd.getId());
            }
        }
        src = Collections.singletonList(ps);
    }
    Map<PatchSet.Id, PatchSet> map = Maps.newHashMapWithExpectedSize(src.size());
    for (PatchSet patchSet : src) {
        map.put(patchSet.getId(), patchSet);
    }
    return map;
}
#end_block

#method_before
private PermissionBackend.ForChange permissionBackendForChange(CurrentUser user, ChangeData cd) throws OrmException {
    PermissionBackend.WithUser withUser = permissionBackend.user(user);
    return lazyLoad ? withUser.change(cd) : withUser.indexedChange(cd, notesFactory.createFromIndexedChange(cd.change()));
}
#method_after
private PermissionBackend.ForChange permissionBackendForChange(CurrentUser user, ChangeData cd) throws StorageException {
    PermissionBackend.WithUser withUser = permissionBackend.user(user);
    return lazyLoad ? withUser.change(cd) : withUser.indexedChange(cd, notesFactory.createFromIndexedChange(cd.change()));
}
#end_block

#method_before
@Override
public BinaryResult apply(RevisionResource rsrc) throws OrmException, RestApiException, UpdateException, IOException, ConfigInvalidException, PermissionBackendException {
    if (Strings.isNullOrEmpty(format)) {
        throw new BadRequestException("format is not specified");
    }
    ArchiveFormat f = allowedFormats.extensions.get("." + format);
    if (f == null && format.equals("tgz")) {
        // Always allow tgz, even when the allowedFormats doesn't contain it.
        // Then we allow at least one format even if the list of allowed
        // formats is empty.
        f = ArchiveFormat.TGZ;
    }
    if (f == null) {
        throw new BadRequestException("unknown archive format");
    }
    Change change = rsrc.getChange();
    if (!change.getStatus().isOpen()) {
        throw new PreconditionFailedException("change is " + ChangeUtil.status(change));
    }
    if (!rsrc.getUser().isIdentifiedUser()) {
        throw new MethodNotAllowedException("Anonymous users cannot submit");
    }
    return getBundles(rsrc, f);
}
#method_after
@Override
public BinaryResult apply(RevisionResource rsrc) throws StorageException, RestApiException, UpdateException, IOException, ConfigInvalidException, PermissionBackendException {
    if (Strings.isNullOrEmpty(format)) {
        throw new BadRequestException("format is not specified");
    }
    ArchiveFormat f = allowedFormats.extensions.get("." + format);
    if (f == null && format.equals("tgz")) {
        // Always allow tgz, even when the allowedFormats doesn't contain it.
        // Then we allow at least one format even if the list of allowed
        // formats is empty.
        f = ArchiveFormat.TGZ;
    }
    if (f == null) {
        throw new BadRequestException("unknown archive format");
    }
    Change change = rsrc.getChange();
    if (!change.isNew()) {
        throw new PreconditionFailedException("change is " + ChangeUtil.status(change));
    }
    if (!rsrc.getUser().isIdentifiedUser()) {
        throw new MethodNotAllowedException("Anonymous users cannot submit");
    }
    return getBundles(rsrc, f);
}
#end_block

#method_before
private BinaryResult getBundles(RevisionResource rsrc, ArchiveFormat f) throws OrmException, RestApiException, UpdateException, IOException, ConfigInvalidException, PermissionBackendException {
    IdentifiedUser caller = rsrc.getUser().asIdentifiedUser();
    Change change = rsrc.getChange();
    // Returned BinaryResult takes ownership and handles closing.
    @SuppressWarnings("resource")
    MergeOp op = mergeOpProvider.get();
    try {
        op.merge(change, caller, false, new SubmitInput(), true);
        BinaryResult bin = new SubmitPreviewResult(op, f, maxBundleSize);
        bin.disableGzip().setContentType(f.getMimeType()).setAttachmentName("submit-preview-" + change.getChangeId() + "." + format);
        return bin;
    } catch (RestApiException | UpdateException | IOException | ConfigInvalidException | RuntimeException | PermissionBackendException e) {
        op.close();
        throw e;
    }
}
#method_after
private BinaryResult getBundles(RevisionResource rsrc, ArchiveFormat f) throws StorageException, RestApiException, UpdateException, IOException, ConfigInvalidException, PermissionBackendException {
    IdentifiedUser caller = rsrc.getUser().asIdentifiedUser();
    Change change = rsrc.getChange();
    // Returned BinaryResult takes ownership and handles closing.
    @SuppressWarnings("resource")
    MergeOp op = mergeOpProvider.get();
    try {
        op.merge(change, caller, false, new SubmitInput(), true);
        BinaryResult bin = new SubmitPreviewResult(op, f, maxBundleSize);
        bin.disableGzip().setContentType(f.getMimeType()).setAttachmentName("submit-preview-" + change.getChangeId() + "." + format);
        return bin;
    } catch (RestApiException | UpdateException | IOException | ConfigInvalidException | RuntimeException | PermissionBackendException e) {
        op.close();
        throw e;
    }
}
#end_block

#method_before
@Override
public Output apply(RevisionResource rsrc, SubmitInput input) throws RestApiException, RepositoryNotFoundException, IOException, OrmException, PermissionBackendException, UpdateException, ConfigInvalidException {
    input.onBehalfOf = Strings.emptyToNull(input.onBehalfOf);
    IdentifiedUser submitter;
    if (input.onBehalfOf != null) {
        submitter = onBehalfOf(rsrc, input);
    } else {
        rsrc.permissions().check(ChangePermission.SUBMIT);
        submitter = rsrc.getUser().asIdentifiedUser();
    }
    projectCache.checkedGet(rsrc.getProject()).checkStatePermitsWrite();
    return new Output(mergeChange(rsrc, submitter, input));
}
#method_after
@Override
public Output apply(RevisionResource rsrc, SubmitInput input) throws RestApiException, RepositoryNotFoundException, IOException, StorageException, PermissionBackendException, UpdateException, ConfigInvalidException {
    input.onBehalfOf = Strings.emptyToNull(input.onBehalfOf);
    IdentifiedUser submitter;
    if (input.onBehalfOf != null) {
        submitter = onBehalfOf(rsrc, input);
    } else {
        rsrc.permissions().check(ChangePermission.SUBMIT);
        submitter = rsrc.getUser().asIdentifiedUser();
    }
    projectCache.checkedGet(rsrc.getProject()).checkStatePermitsWrite();
    return new Output(mergeChange(rsrc, submitter, input));
}
#end_block

#method_before
public Change mergeChange(RevisionResource rsrc, IdentifiedUser submitter, SubmitInput input) throws OrmException, RestApiException, IOException, UpdateException, ConfigInvalidException, PermissionBackendException {
    Change change = rsrc.getChange();
    if (!change.getStatus().isOpen()) {
        throw new ResourceConflictException("change is " + ChangeUtil.status(change));
    } else if (!ProjectUtil.branchExists(repoManager, change.getDest())) {
        throw new ResourceConflictException(String.format("destination branch \"%s\" not found.", change.getDest().get()));
    } else if (!rsrc.getPatchSet().getId().equals(change.currentPatchSetId())) {
        // TODO Allow submitting non-current revision by changing the current.
        throw new ResourceConflictException(String.format("revision %s is not current revision", rsrc.getPatchSet().getRevision().get()));
    }
    try (MergeOp op = mergeOpProvider.get()) {
        op.merge(change, submitter, true, input, false);
        try {
            change = changeNotesFactory.createChecked(change.getProject(), change.getId()).getChange();
        } catch (NoSuchChangeException e) {
            throw new ResourceConflictException("change is deleted");
        }
    }
    switch(change.getStatus()) {
        case MERGED:
            return change;
        case NEW:
            throw new RestApiException("change unexpectedly had status " + change.getStatus() + " after submit attempt");
        case ABANDONED:
        default:
            throw new ResourceConflictException("change is " + ChangeUtil.status(change));
    }
}
#method_after
public Change mergeChange(RevisionResource rsrc, IdentifiedUser submitter, SubmitInput input) throws StorageException, RestApiException, IOException, UpdateException, ConfigInvalidException, PermissionBackendException {
    Change change = rsrc.getChange();
    if (!change.isNew()) {
        throw new ResourceConflictException("change is " + ChangeUtil.status(change));
    } else if (!ProjectUtil.branchExists(repoManager, change.getDest())) {
        throw new ResourceConflictException(String.format("destination branch \"%s\" not found.", change.getDest().get()));
    } else if (!rsrc.getPatchSet().getId().equals(change.currentPatchSetId())) {
        // TODO Allow submitting non-current revision by changing the current.
        throw new ResourceConflictException(String.format("revision %s is not current revision", rsrc.getPatchSet().getRevision().get()));
    }
    try (MergeOp op = mergeOpProvider.get()) {
        op.merge(change, submitter, true, input, false);
    }
    // to have the correct state of the repo.
    try {
        change = changeNotesFactory.createChecked(change.getProject(), change.getId()).getChange();
    } catch (NoSuchChangeException e) {
        throw new ResourceConflictException("change is deleted");
    }
    if (change.isMerged()) {
        return change;
    }
    if (change.isNew()) {
        throw new RestApiException("change unexpectedly had status NEW after submit attempt");
    }
    throw new ResourceConflictException("change is " + ChangeUtil.status(change));
}
#end_block

#method_before
private String problemsForSubmittingChangeset(ChangeData cd, ChangeSet cs, CurrentUser user) {
    try {
        if (cs.furtherHiddenChanges()) {
            logger.atFine().log("Change %d cannot be submitted by user %s because it depends on hidden changes: %s", cd.getId().get(), user.getLoggableName(), cs.nonVisibleChanges());
            return BLOCKED_HIDDEN_SUBMIT_TOOLTIP;
        }
        for (ChangeData c : cs.changes()) {
            if (cd.getId().equals(c.getId())) {
                // #apply and #getDescription methods.
                continue;
            }
            Set<ChangePermission> can = permissionBackend.user(user).change(c).test(EnumSet.of(ChangePermission.READ, ChangePermission.SUBMIT));
            if (!can.contains(ChangePermission.READ)) {
                logger.atFine().log("Change %d cannot be submitted by user %s because it depends on change %d which the user cannot read", cd.getId().get(), user.getLoggableName(), c.getId().get());
                return BLOCKED_HIDDEN_SUBMIT_TOOLTIP;
            }
            if (!can.contains(ChangePermission.SUBMIT)) {
                return "You don't have permission to submit change " + c.getId();
            }
            if (c.change().isWorkInProgress()) {
                return "Change " + c.getId() + " is marked work in progress";
            }
            try {
                MergeOp.checkSubmitRule(c, false);
            } catch (ResourceConflictException e) {
                return "Change " + c.getId() + " is not ready: " + e.getMessage();
            }
        }
        Collection<ChangeData> unmergeable = unmergeableChanges(cs);
        if (unmergeable == null) {
            return CLICK_FAILURE_TOOLTIP;
        } else if (!unmergeable.isEmpty()) {
            for (ChangeData c : unmergeable) {
                if (c.change().getKey().equals(cd.change().getKey())) {
                    return CHANGE_UNMERGEABLE;
                }
            }
            return "Problems with change(s): " + unmergeable.stream().map(c -> c.getId().toString()).collect(joining(", "));
        }
    } catch (PermissionBackendException | OrmException | IOException e) {
        logger.atSevere().withCause(e).log("Error checking if change is submittable");
        throw new OrmException("Could not determine problems for the change", e);
    }
    return null;
}
#method_after
private String problemsForSubmittingChangeset(ChangeData cd, ChangeSet cs, CurrentUser user) {
    try {
        if (cs.furtherHiddenChanges()) {
            logger.atFine().log("Change %d cannot be submitted by user %s because it depends on hidden changes: %s", cd.getId().get(), user.getLoggableName(), cs.nonVisibleChanges());
            return BLOCKED_HIDDEN_SUBMIT_TOOLTIP;
        }
        for (ChangeData c : cs.changes()) {
            if (cd.getId().equals(c.getId())) {
                // #apply and #getDescription methods.
                continue;
            }
            Set<ChangePermission> can = permissionBackend.user(user).change(c).test(EnumSet.of(ChangePermission.READ, ChangePermission.SUBMIT));
            if (!can.contains(ChangePermission.READ)) {
                logger.atFine().log("Change %d cannot be submitted by user %s because it depends on change %d which the user cannot read", cd.getId().get(), user.getLoggableName(), c.getId().get());
                return BLOCKED_HIDDEN_SUBMIT_TOOLTIP;
            }
            if (!can.contains(ChangePermission.SUBMIT)) {
                return "You don't have permission to submit change " + c.getId();
            }
            if (c.change().isWorkInProgress()) {
                return "Change " + c.getId() + " is marked work in progress";
            }
            try {
                MergeOp.checkSubmitRule(c, false);
            } catch (ResourceConflictException e) {
                return "Change " + c.getId() + " is not ready: " + e.getMessage();
            }
        }
        Collection<ChangeData> unmergeable = unmergeableChanges(cs);
        if (unmergeable == null) {
            return CLICK_FAILURE_TOOLTIP;
        } else if (!unmergeable.isEmpty()) {
            for (ChangeData c : unmergeable) {
                if (c.change().getKey().equals(cd.change().getKey())) {
                    return CHANGE_UNMERGEABLE;
                }
            }
            return "Problems with change(s): " + unmergeable.stream().map(c -> c.getId().toString()).collect(joining(", "));
        }
    } catch (PermissionBackendException | IOException e) {
        logger.atSevere().withCause(e).log("Error checking if change is submittable");
        throw new StorageException("Could not determine problems for the change", e);
    }
    return null;
}
#end_block

#method_before
@Override
public UiAction.Description getDescription(RevisionResource resource) {
    Change change = resource.getChange();
    if (!change.getStatus().isOpen() || change.isWorkInProgress() || !resource.isCurrent() || !resource.permissions().testOrFalse(ChangePermission.SUBMIT)) {
        // submit not visible
        return null;
    }
    try {
        if (!projectCache.checkedGet(resource.getProject()).statePermitsWrite()) {
            // submit not visible
            return null;
        }
    } catch (IOException e) {
        logger.atSevere().withCause(e).log("Error checking if change is submittable");
        throw new OrmException("Could not determine problems for the change", e);
    }
    ChangeData cd = changeDataFactory.create(resource.getNotes());
    try {
        MergeOp.checkSubmitRule(cd, false);
    } catch (ResourceConflictException e) {
        // submit not visible
        return null;
    } catch (OrmException e) {
        logger.atSevere().withCause(e).log("Error checking if change is submittable");
        throw new OrmException("Could not determine problems for the change", e);
    }
    ChangeSet cs;
    try {
        cs = mergeSuperSet.get().completeChangeSet(cd.change(), resource.getUser());
    } catch (OrmException | IOException | PermissionBackendException e) {
        throw new OrmException("Could not determine complete set of changes to be submitted", e);
    }
    String topic = change.getTopic();
    int topicSize = 0;
    if (!Strings.isNullOrEmpty(topic)) {
        topicSize = getChangesByTopic(topic).size();
    }
    boolean treatWithTopic = submitWholeTopic && !Strings.isNullOrEmpty(topic) && topicSize > 1;
    String submitProblems = problemsForSubmittingChangeset(cd, cs, resource.getUser());
    Boolean enabled;
    try {
        // Recheck mergeability rather than using value stored in the index,
        // which may be stale.
        // TODO(dborowitz): This is ugly; consider providing a way to not read
        // stored fields from the index in the first place.
        // cd.setMergeable(null);
        // That was done in unmergeableChanges which was called by
        // problemsForSubmittingChangeset, so now it is safe to read from
        // the cache, as it yields the same result.
        enabled = cd.isMergeable();
    } catch (OrmException e) {
        throw new OrmException("Could not determine mergeability", e);
    }
    if (submitProblems != null) {
        return new UiAction.Description().setLabel(treatWithTopic ? submitTopicLabel : (cs.size() > 1) ? labelWithParents : label).setTitle(submitProblems).setVisible(true).setEnabled(false);
    }
    if (treatWithTopic) {
        Map<String, String> params = ImmutableMap.of("topicSize", String.valueOf(topicSize), "submitSize", String.valueOf(cs.size()));
        return new UiAction.Description().setLabel(submitTopicLabel).setTitle(Strings.emptyToNull(submitTopicTooltip.replace(params))).setVisible(true).setEnabled(Boolean.TRUE.equals(enabled));
    }
    RevId revId = resource.getPatchSet().getRevision();
    Map<String, String> params = ImmutableMap.of("patchSet", String.valueOf(resource.getPatchSet().getPatchSetId()), "branch", change.getDest().getShortName(), "commit", ObjectId.fromString(revId.get()).abbreviate(7).name(), "submitSize", String.valueOf(cs.size()));
    ParameterizedString tp = cs.size() > 1 ? titlePatternWithAncestors : titlePattern;
    return new UiAction.Description().setLabel(cs.size() > 1 ? labelWithParents : label).setTitle(Strings.emptyToNull(tp.replace(params))).setVisible(true).setEnabled(Boolean.TRUE.equals(enabled));
}
#method_after
@Override
public UiAction.Description getDescription(RevisionResource resource) {
    Change change = resource.getChange();
    if (!change.isNew() || change.isWorkInProgress() || !resource.isCurrent() || !resource.permissions().testOrFalse(ChangePermission.SUBMIT)) {
        // submit not visible
        return null;
    }
    try {
        if (!projectCache.checkedGet(resource.getProject()).statePermitsWrite()) {
            // submit not visible
            return null;
        }
    } catch (IOException e) {
        logger.atSevere().withCause(e).log("Error checking if change is submittable");
        throw new StorageException("Could not determine problems for the change", e);
    }
    ChangeData cd = changeDataFactory.create(resource.getNotes());
    try {
        MergeOp.checkSubmitRule(cd, false);
    } catch (ResourceConflictException e) {
        // submit not visible
        return null;
    }
    ChangeSet cs;
    try {
        cs = mergeSuperSet.get().completeChangeSet(cd.change(), resource.getUser());
    } catch (IOException | PermissionBackendException e) {
        throw new StorageException("Could not determine complete set of changes to be submitted", e);
    }
    String topic = change.getTopic();
    int topicSize = 0;
    if (!Strings.isNullOrEmpty(topic)) {
        topicSize = queryProvider.get().byTopicOpen(topic).size();
    }
    boolean treatWithTopic = submitWholeTopic && !Strings.isNullOrEmpty(topic) && topicSize > 1;
    String submitProblems = problemsForSubmittingChangeset(cd, cs, resource.getUser());
    // Recheck mergeability rather than using value stored in the index, which may be stale.
    // TODO(dborowitz): This is ugly; consider providing a way to not read stored fields from the
    // index in the first place.
    // cd.setMergeable(null);
    // That was done in unmergeableChanges which was called by problemsForSubmittingChangeset, so
    // now it is safe to read from the cache, as it yields the same result.
    Boolean enabled = cd.isMergeable();
    if (submitProblems != null) {
        return new UiAction.Description().setLabel(treatWithTopic ? submitTopicLabel : (cs.size() > 1) ? labelWithParents : label).setTitle(submitProblems).setVisible(true).setEnabled(false);
    }
    if (treatWithTopic) {
        Map<String, String> params = ImmutableMap.of("topicSize", String.valueOf(topicSize), "submitSize", String.valueOf(cs.size()));
        return new UiAction.Description().setLabel(submitTopicLabel).setTitle(Strings.emptyToNull(submitTopicTooltip.replace(params))).setVisible(true).setEnabled(Boolean.TRUE.equals(enabled));
    }
    RevId revId = resource.getPatchSet().getRevision();
    Map<String, String> params = ImmutableMap.of("patchSet", String.valueOf(resource.getPatchSet().getPatchSetId()), "branch", change.getDest().getShortName(), "commit", ObjectId.fromString(revId.get()).abbreviate(7).name(), "submitSize", String.valueOf(cs.size()));
    ParameterizedString tp = cs.size() > 1 ? titlePatternWithAncestors : titlePattern;
    return new UiAction.Description().setLabel(cs.size() > 1 ? labelWithParents : label).setTitle(Strings.emptyToNull(tp.replace(params))).setVisible(true).setEnabled(Boolean.TRUE.equals(enabled));
}
#end_block

#method_before
public Collection<ChangeData> unmergeableChanges(ChangeSet cs) throws OrmException, IOException {
    Set<ChangeData> mergeabilityMap = new HashSet<>();
    for (ChangeData change : cs.changes()) {
        mergeabilityMap.add(change);
    }
    ListMultimap<Branch.NameKey, ChangeData> cbb = cs.changesByBranch();
    for (Branch.NameKey branch : cbb.keySet()) {
        Collection<ChangeData> targetBranch = cbb.get(branch);
        HashMap<Change.Id, RevCommit> commits = findCommits(targetBranch, branch.getParentKey());
        Set<ObjectId> allParents = Sets.newHashSetWithExpectedSize(cs.size());
        for (RevCommit commit : commits.values()) {
            for (RevCommit parent : commit.getParents()) {
                allParents.add(parent.getId());
            }
        }
        for (ChangeData change : targetBranch) {
            RevCommit commit = commits.get(change.getId());
            boolean isMergeCommit = commit.getParentCount() > 1;
            boolean isLastInChain = !allParents.contains(commit.getId());
            // Recheck mergeability rather than using value stored in the index,
            // which may be stale.
            // TODO(dborowitz): This is ugly; consider providing a way to not read
            // stored fields from the index in the first place.
            change.setMergeable(null);
            Boolean mergeable = change.isMergeable();
            if (mergeable == null) {
                // Skip whole check, cannot determine if mergeable
                return null;
            }
            if (mergeable) {
                mergeabilityMap.remove(change);
            }
            if (isLastInChain && isMergeCommit && mergeable) {
                for (ChangeData c : targetBranch) {
                    mergeabilityMap.remove(c);
                }
                break;
            }
        }
    }
    return mergeabilityMap;
}
#method_after
public Collection<ChangeData> unmergeableChanges(ChangeSet cs) throws StorageException, IOException {
    Set<ChangeData> mergeabilityMap = new HashSet<>();
    for (ChangeData change : cs.changes()) {
        mergeabilityMap.add(change);
    }
    ListMultimap<Branch.NameKey, ChangeData> cbb = cs.changesByBranch();
    for (Branch.NameKey branch : cbb.keySet()) {
        Collection<ChangeData> targetBranch = cbb.get(branch);
        HashMap<Change.Id, RevCommit> commits = findCommits(targetBranch, branch.getParentKey());
        Set<ObjectId> allParents = Sets.newHashSetWithExpectedSize(cs.size());
        for (RevCommit commit : commits.values()) {
            for (RevCommit parent : commit.getParents()) {
                allParents.add(parent.getId());
            }
        }
        for (ChangeData change : targetBranch) {
            RevCommit commit = commits.get(change.getId());
            boolean isMergeCommit = commit.getParentCount() > 1;
            boolean isLastInChain = !allParents.contains(commit.getId());
            // Recheck mergeability rather than using value stored in the index,
            // which may be stale.
            // TODO(dborowitz): This is ugly; consider providing a way to not read
            // stored fields from the index in the first place.
            change.setMergeable(null);
            Boolean mergeable = change.isMergeable();
            if (mergeable == null) {
                // Skip whole check, cannot determine if mergeable
                return null;
            }
            if (mergeable) {
                mergeabilityMap.remove(change);
            }
            if (isLastInChain && isMergeCommit && mergeable) {
                for (ChangeData c : targetBranch) {
                    mergeabilityMap.remove(c);
                }
                break;
            }
        }
    }
    return mergeabilityMap;
}
#end_block

#method_before
private HashMap<Change.Id, RevCommit> findCommits(Collection<ChangeData> changes, Project.NameKey project) throws IOException, OrmException {
    HashMap<Change.Id, RevCommit> commits = new HashMap<>();
    try (Repository repo = repoManager.openRepository(project);
        RevWalk walk = new RevWalk(repo)) {
        for (ChangeData change : changes) {
            RevCommit commit = walk.parseCommit(ObjectId.fromString(psUtil.current(change.notes()).getRevision().get()));
            commits.put(change.getId(), commit);
        }
    }
    return commits;
}
#method_after
private HashMap<Change.Id, RevCommit> findCommits(Collection<ChangeData> changes, Project.NameKey project) throws IOException, StorageException {
    HashMap<Change.Id, RevCommit> commits = new HashMap<>();
    try (Repository repo = repoManager.openRepository(project);
        RevWalk walk = new RevWalk(repo)) {
        for (ChangeData change : changes) {
            RevCommit commit = walk.parseCommit(ObjectId.fromString(psUtil.current(change.notes()).getRevision().get()));
            commits.put(change.getId(), commit);
        }
    }
    return commits;
}
#end_block

#method_before
private IdentifiedUser onBehalfOf(RevisionResource rsrc, SubmitInput in) throws AuthException, UnprocessableEntityException, OrmException, PermissionBackendException, IOException, ConfigInvalidException {
    PermissionBackend.ForChange perm = rsrc.permissions();
    perm.check(ChangePermission.SUBMIT);
    perm.check(ChangePermission.SUBMIT_AS);
    CurrentUser caller = rsrc.getUser();
    IdentifiedUser submitter = accountResolver.parseOnBehalfOf(caller, in.onBehalfOf);
    try {
        permissionBackend.user(submitter).change(rsrc.getNotes()).check(ChangePermission.READ);
    } catch (AuthException e) {
        throw new UnprocessableEntityException(String.format("on_behalf_of account %s cannot see change", submitter.getAccountId()));
    }
    return submitter;
}
#method_after
private IdentifiedUser onBehalfOf(RevisionResource rsrc, SubmitInput in) throws AuthException, UnprocessableEntityException, StorageException, PermissionBackendException, IOException, ConfigInvalidException {
    PermissionBackend.ForChange perm = rsrc.permissions();
    perm.check(ChangePermission.SUBMIT);
    perm.check(ChangePermission.SUBMIT_AS);
    CurrentUser caller = rsrc.getUser();
    IdentifiedUser submitter = accountResolver.resolve(in.onBehalfOf).asUniqueUserOnBehalfOf(caller);
    try {
        permissionBackend.user(submitter).change(rsrc.getNotes()).check(ChangePermission.READ);
    } catch (AuthException e) {
        throw new UnprocessableEntityException(String.format("on_behalf_of account %s cannot see change", submitter.getAccountId()));
    }
    return submitter;
}
#end_block

#method_before
@Override
public ChangeInfo apply(ChangeResource rsrc, SubmitInput input) throws RestApiException, RepositoryNotFoundException, IOException, OrmException, PermissionBackendException, UpdateException, ConfigInvalidException {
    PatchSet ps = psUtil.current(rsrc.getNotes());
    if (ps == null) {
        throw new ResourceConflictException("current revision is missing");
    }
    Output out = submit.apply(new RevisionResource(rsrc, ps), input);
    return json.noOptions().format(out.change);
}
#method_after
@Override
public ChangeInfo apply(ChangeResource rsrc, SubmitInput input) throws RestApiException, RepositoryNotFoundException, IOException, StorageException, PermissionBackendException, UpdateException, ConfigInvalidException {
    PatchSet ps = psUtil.current(rsrc.getNotes());
    if (ps == null) {
        throw new ResourceConflictException("current revision is missing");
    }
    Output out = submit.apply(new RevisionResource(rsrc, ps), input);
    return json.noOptions().format(out.change);
}
#end_block

#method_before
@Override
protected List<ChangeData> transformBuffer(List<ChangeData> buffer) throws OrmException {
    if (!hasChange()) {
        try {
            ChangeData.ensureChangeLoaded(buffer);
        } catch (OrmException e) {
            throw new OrmException(e);
        }
    }
    return super.transformBuffer(buffer);
}
#method_after
@Override
protected List<ChangeData> transformBuffer(List<ChangeData> buffer) {
    if (!hasChange()) {
        ChangeData.ensureChangeLoaded(buffer);
    }
    return super.transformBuffer(buffer);
}
#end_block

#method_before
@Override
public ResultSet<T> read() throws OrmException {
    try {
        return readImpl();
    } catch (OrmException err) {
        if (err.getCause() != null) {
            Throwables.throwIfInstanceOf(err.getCause(), OrmException.class);
        }
        throw new OrmException(err);
    }
}
#method_after
@Override
public ResultSet<T> read() throws StorageException {
    if (source == null) {
        throw new StorageException("No DataSource: " + this);
    }
    List<T> r = new ArrayList<>();
    T last = null;
    int nextStart = 0;
    boolean skipped = false;
    for (T data : buffer(source.read())) {
        if (!isMatchable() || match(data)) {
            r.add(data);
        } else {
            skipped = true;
        }
        last = data;
        nextStart++;
    }
    if (skipped && last != null && source instanceof Paginated) {
        // If our source is a paginated source and we skipped at
        // least one of its results, we may not have filled the full
        // limit the caller wants.  Restart the source and continue.
        // 
        @SuppressWarnings("unchecked")
        Paginated<T> p = (Paginated<T>) source;
        while (skipped && r.size() < p.getOptions().limit() + start) {
            skipped = false;
            ResultSet<T> next = p.restart(nextStart);
            for (T data : buffer(next)) {
                if (match(data)) {
                    r.add(data);
                } else {
                    skipped = true;
                }
                nextStart++;
            }
        }
    }
    if (start >= r.size()) {
        r = ImmutableList.of();
    } else if (start > 0) {
        r = ImmutableList.copyOf(r.subList(start, r.size()));
    }
    return new ListResultSet<>(r);
}
#end_block

#method_before
@Override
public ResultSet<FieldBundle> readRaw() throws OrmException {
    // TOOD(hiesel): Implement
    throw new UnsupportedOperationException("not implemented");
}
#method_after
@Override
public ResultSet<FieldBundle> readRaw() throws StorageException {
    // TOOD(hiesel): Implement
    throw new UnsupportedOperationException("not implemented");
}
#end_block

#method_before
@Override
public boolean match(T object) throws OrmException {
    if (isVisibleToPredicate != null && !isVisibleToPredicate.match(object)) {
        return false;
    }
    if (super.isMatchable() && !super.match(object)) {
        return false;
    }
    return true;
}
#method_after
@Override
public boolean match(T object) throws StorageException {
    if (isVisibleToPredicate != null && !isVisibleToPredicate.match(object)) {
        return false;
    }
    if (super.isMatchable() && !super.match(object)) {
        return false;
    }
    return true;
}
#end_block

#method_before
protected List<T> transformBuffer(List<T> buffer) throws OrmException {
    return buffer;
}
#method_after
protected List<T> transformBuffer(List<T> buffer) {
    return buffer;
}
#end_block

#method_before
@Override
protected void configure() {
    if (cfgFactory.getFromGerritConfig(pluginName, true).getBoolean("enableImageServer", true)) {
        bind(com.google.gerrit.extensions.config.CapabilityDefinition.class).annotatedWith(Exports.named(DELETE_OWN_IMAGES)).to(DeleteOwnImagesCapability.class);
        install(new RestApiModule() {

            @Override
            protected void configure() {
                DynamicMap.mapOf(binder(), IMAGE_KIND);
                bind(ImagesCollection.class);
                child(PROJECT_KIND, "images").to(ImagesCollection.class);
                delete(IMAGE_KIND).to(DeleteImage.class);
                postOnCollection(IMAGE_KIND).to(PostImage.class);
            }
        });
    }
    DynamicSet.bind(binder(), TopMenu.class).to(ImagareMenu.class);
    install(new RestApiModule() {

        @Override
        protected void configure() {
            get(CONFIG_KIND, "config").to(GetConfig.class);
            put(CONFIG_KIND, "config").to(PutConfig.class);
            get(ACCOUNT_KIND, "preference").to(GetPreference.class);
            put(ACCOUNT_KIND, "preference").to(PutPreference.class);
        }
    });
}
#method_after
@Override
protected void configure() {
    if (cfgFactory.getFromGerritConfig(pluginName, true).getBoolean("enableImageServer", true)) {
        bind(com.google.gerrit.extensions.config.CapabilityDefinition.class).annotatedWith(Exports.named(DELETE_OWN_IMAGES)).to(DeleteOwnImagesCapability.class);
        install(new RestApiModule() {

            @Override
            protected void configure() {
                DynamicMap.mapOf(binder(), IMAGE_KIND);
                bind(ImagesCollection.class);
                child(PROJECT_KIND, "images").to(ImagesCollection.class);
                delete(IMAGE_KIND).to(DeleteImage.class);
                post(PROJECT_KIND, "images").to(PostImage.class);
            }
        });
    }
    DynamicSet.bind(binder(), TopMenu.class).to(ImagareMenu.class);
    install(new RestApiModule() {

        @Override
        protected void configure() {
            get(CONFIG_KIND, "config").to(GetConfig.class);
            put(CONFIG_KIND, "config").to(PutConfig.class);
            get(ACCOUNT_KIND, "preference").to(GetPreference.class);
            put(ACCOUNT_KIND, "preference").to(PutPreference.class);
        }
    });
}
#end_block

#method_before
@Before
public void createEvaluator() {
    when(event.getProjectName()).thenReturn(NAME_KEY.get());
    /**
     * Config
     */
    when(config.getExpireTimeRecheck()).thenReturn(0L);
    when(gerritConfig.getInt("receive", null, "threadPoolSize", Runtime.getRuntime().availableProcessors())).thenReturn(1);
    /**
     * Repositories
     */
    when(repository.getDirectory()).thenReturn(new File(REPOSITORY_PATH));
    when(repositoryOther.getDirectory()).thenReturn(new File(REPOSITORY_PATH_OTHER));
    /**
     * Tasks
     */
    taskSamePathCompleted = new EvaluationTask(null, null, null, REPOSITORY_PATH);
    taskSamePathNotCompleted = new EvaluationTask(null, null, null, REPOSITORY_PATH);
    taskDifferentPath = new EvaluationTask(null, null, null, REPOSITORY_PATH_OTHER);
    /**
     * Task factory
     */
    Factory eventTaskFactory = mock(Factory.class);
    when(eventTaskFactory.create(REPOSITORY_PATH)).thenReturn(taskSamePathNotCompleted).thenReturn(taskSamePathCompleted);
    when(eventTaskFactory.create(REPOSITORY_PATH_OTHER)).thenReturn(taskDifferentPath);
    /**
     * Executor
     */
    when(executor.submit(taskSamePathCompleted)).thenReturn(CompletableFuture.completedFuture(null));
    when(executor.submit(taskSamePathNotCompleted)).thenReturn(new CompletableFuture());
    when(executor.submit(taskDifferentPath)).thenReturn(CompletableFuture.completedFuture(null));
    evaluator = new Evaluator(executor, eventTaskFactory, repoManager, config, gerritConfig);
}
#method_after
@Before
public void createEvaluator() {
    when(event.getProjectName()).thenReturn(NAME_KEY.get());
    when(config.getExpireTimeRecheck()).thenReturn(0L);
    when(gerritConfig.getInt("receive", null, "threadPoolSize", Runtime.getRuntime().availableProcessors())).thenReturn(1);
    when(repository.getDirectory()).thenReturn(new File(REPOSITORY_PATH));
    when(repositoryOther.getDirectory()).thenReturn(new File(REPOSITORY_PATH_OTHER));
    taskSamePathCompleted = new EvaluationTask(null, null, null, REPOSITORY_PATH);
    taskSamePathNotCompleted = new EvaluationTask(null, null, null, REPOSITORY_PATH);
    taskDifferentPath = new EvaluationTask(null, null, null, REPOSITORY_PATH_OTHER);
    Factory eventTaskFactory = mock(Factory.class);
    when(eventTaskFactory.create(REPOSITORY_PATH)).thenReturn(taskSamePathNotCompleted).thenReturn(taskSamePathCompleted);
    when(eventTaskFactory.create(REPOSITORY_PATH_OTHER)).thenReturn(taskDifferentPath);
    when(executor.submit(taskSamePathCompleted)).thenReturn(CompletableFuture.completedFuture(null));
    when(executor.submit(taskSamePathNotCompleted)).thenReturn(new CompletableFuture<>());
    when(executor.submit(taskDifferentPath)).thenReturn(CompletableFuture.completedFuture(null));
    evaluator = new Evaluator(executor, eventTaskFactory, repoManager, config, gerritConfig);
}
#end_block

#method_before
private void queueEvaluationIfNecessary(String repositoryPath) {
    if (lastCheckExpired(repositoryPath)) {
        EvaluationTask evaluationTask = evaluationTaskFactory.create(repositoryPath);
        if (queuedEvaluationTasks.add(evaluationTask)) {
            Future future = executor.submit(evaluationTask);
            addTaskListener(future, evaluationTask);
            timestamps.put(repositoryPath, System.currentTimeMillis());
        }
    }
}
#method_after
private void queueEvaluationIfNecessary(String repositoryPath) {
    if (lastCheckExpired(repositoryPath)) {
        EvaluationTask evaluationTask = evaluationTaskFactory.create(repositoryPath);
        if (queuedEvaluationTasks.add(evaluationTask)) {
            Future<?> future = executor.submit(evaluationTask);
            addTaskListener(future, evaluationTask);
            timestamps.put(repositoryPath, System.currentTimeMillis());
        }
    }
}
#end_block

#method_before
private void addTaskListener(Future future, EvaluationTask evaluationTask) {
    ListenableFuture listenableFuture = JdkFutureAdapters.listenInPoolThread(future);
    listenableFuture.addListener(new Runnable() {

        public void run() {
            queuedEvaluationTasks.remove(evaluationTask);
        }
    }, MoreExecutors.directExecutor());
}
#method_after
private void addTaskListener(Future<?> future, EvaluationTask evaluationTask) {
    ListenableFuture<?> listenableFuture = JdkFutureAdapters.listenInPoolThread(future);
    listenableFuture.addListener(() -> queuedEvaluationTasks.remove(evaluationTask), MoreExecutors.directExecutor());
}
#end_block

#method_before
@Test
public void testContextUser() throws Exception {
    // Branch flow for contextUser is master -> ds_one -> ds_two
    Project.NameKey manifestNameKey = defaultSetup();
    // Create initial change
    PushOneCommit.Result initialResult = createChange("subject", "filename", "echo Hello");
    // Project name is scoped by test, so we need to get it from our initial change
    Project.NameKey projectNameKey = initialResult.getChange().project();
    String projectName = projectNameKey.get();
    createBranch(new Branch.NameKey(projectName, "ds_one"));
    createBranch(new Branch.NameKey(projectName, "ds_two"));
    initialResult.assertOkStatus();
    merge(initialResult);
    // Create normalUserGroup, containing current user, and contextUserGroup, containing contextUser
    String normalUserGroup = groupOperations.newGroup().name("normalUserGroup").create().get();
    gApi.groups().id(normalUserGroup).addMembers(user.id().toString());
    AccountApi contextUserApi = gApi.accounts().create("someContextUser");
    String contextUserGroup = groupOperations.newGroup().name("contextUserGroup").create().get();
    gApi.groups().id(contextUserGroup).addMembers(contextUserApi.get().name);
    // Grant exclusive +2 to context user
    grantLabel("Code-Review", -2, 2, projectNameKey, "refs/heads/ds_one", false, AccountGroup.UUID.parse(gApi.groups().id(contextUserGroup).get().id), true);
    pushContextUserConfig(manifestNameKey.get(), projectName, contextUserApi.get()._accountId.toString());
    // After we upload our config, we upload a new patchset to create the downstreams
    PushOneCommit.Result result = createChange(testRepo, "master", "subject", "filename2", "echo Hello", "sometopic");
    result.assertOkStatus();
    // Check that there are the correct number of changes in the topic
    List<ChangeInfo> changesInTopic = gApi.changes().query("topic: " + gApi.changes().id(result.getChangeId()).topic()).withOptions(CURRENT_REVISION, CURRENT_COMMIT).get();
    assertThat(changesInTopic).hasSize(3);
    List<ChangeInfo> sortedChanges = sortedChanges(changesInTopic);
    // Check that downstream is at Code-Review 0
    ChangeInfo dsOneChangeInfo = sortedChanges.get(0);
    assertThat(dsOneChangeInfo.branch).isEqualTo("ds_one");
    assertCodeReview(dsOneChangeInfo.id, 0, null);
    // Try to +2 master and see it succeed to +2 master and ds_one
    ChangeInfo masterChangeInfo = sortedChanges.get(2);
    assertThat(masterChangeInfo.branch).isEqualTo("master");
    assertCodeReviewMissing(masterChangeInfo.id);
    approve(masterChangeInfo.id);
    assertCodeReview(masterChangeInfo.id, 2, null);
    assertCodeReview(dsOneChangeInfo.id, 2, "autogenerated:Automerger");
    // Try to +2 downstream and see it fail
    exception.expect(AuthException.class);
    exception.expectMessage("Applying label \"Code-Review\": 2 is restricted");
    approve(dsOneChangeInfo.id);
}
#method_after
@Test
public void testContextUser() throws Exception {
    // Branch flow for contextUser is master -> ds_one -> ds_two
    Project.NameKey manifestNameKey = defaultSetup();
    // Create initial change
    PushOneCommit.Result initialResult = createChange("subject", "filename", "echo Hello");
    // Project name is scoped by test, so we need to get it from our initial change
    Project.NameKey projectNameKey = initialResult.getChange().project();
    String projectName = projectNameKey.get();
    createBranch(new Branch.NameKey(projectName, "ds_one"));
    createBranch(new Branch.NameKey(projectName, "ds_two"));
    initialResult.assertOkStatus();
    merge(initialResult);
    // Create normalUserGroup, containing user, and contextUserGroup, containing contextUser
    String normalUserGroup = groupOperations.newGroup().name("normalUserGroup").create().get();
    gApi.groups().id(normalUserGroup).addMembers(user.id().toString());
    AccountApi contextUserApi = gApi.accounts().create("someContextUser");
    String contextUserGroup = groupOperations.newGroup().name("contextUserGroup").create().get();
    gApi.groups().id(contextUserGroup).addMembers(contextUserApi.get().name);
    // Grant exclusive +2 to context user
    grantLabel("Code-Review", -2, 2, projectNameKey, "refs/heads/ds_one", false, AccountGroup.UUID.parse(gApi.groups().id(contextUserGroup).get().id), true);
    pushContextUserConfig(manifestNameKey.get(), projectName, contextUserApi.get()._accountId.toString());
    // After we upload our config, we upload a new patchset to create the downstreams
    PushOneCommit.Result result = createChange(testRepo, "master", "subject", "filename2", "echo Hello", "sometopic");
    result.assertOkStatus();
    // Check that there are the correct number of changes in the topic
    List<ChangeInfo> changesInTopic = gApi.changes().query("topic: " + gApi.changes().id(result.getChangeId()).topic()).withOptions(CURRENT_REVISION, CURRENT_COMMIT).get();
    assertThat(changesInTopic).hasSize(3);
    List<ChangeInfo> sortedChanges = sortedChanges(changesInTopic);
    // Check that downstream is at Code-Review 0
    ChangeInfo dsOneChangeInfo = sortedChanges.get(0);
    assertThat(dsOneChangeInfo.branch).isEqualTo("ds_one");
    assertCodeReview(dsOneChangeInfo.id, 0, null);
    // Try to +2 master and see it succeed to +2 master and ds_one
    ChangeInfo masterChangeInfo = sortedChanges.get(2);
    assertThat(masterChangeInfo.branch).isEqualTo("master");
    assertCodeReviewMissing(masterChangeInfo.id);
    approve(masterChangeInfo.id);
    assertCodeReview(masterChangeInfo.id, 2, null);
    assertCodeReview(dsOneChangeInfo.id, 2, "autogenerated:Automerger");
    // Try to +2 downstream and see it fail
    exception.expect(AuthException.class);
    exception.expectMessage("Applying label \"Code-Review\": 2 is restricted");
    approve(dsOneChangeInfo.id);
}
#end_block

#method_before
@Test
public void testContextUser_downstreamHighestVote() throws Exception {
    // Branch flow for contextUser is master -> ds_one -> ds_two
    Project.NameKey manifestNameKey = defaultSetup();
    // Create initial change
    PushOneCommit.Result initialResult = createChange("subject", "filename", "echo Hello");
    // Project name is scoped by test, so we need to get it from our initial change
    Project.NameKey projectNameKey = initialResult.getChange().project();
    String projectName = projectNameKey.get();
    createBranch(new Branch.NameKey(projectName, "ds_one"));
    createBranch(new Branch.NameKey(projectName, "ds_two"));
    initialResult.assertOkStatus();
    merge(initialResult);
    // Create normalUserGroup, containing current user, and contextUserGroup, containing contextUser
    String normalUserGroup = groupOperations.newGroup().name("normalUserGroup").create().get();
    gApi.groups().id(normalUserGroup).addMembers(user.id().toString());
    AccountApi contextUserApi = gApi.accounts().create("randomContextUser");
    String contextUserGroup = groupOperations.newGroup().name("contextUserGroup").create().get();
    gApi.groups().id(contextUserGroup).addMembers(contextUserApi.get().name);
    // Grant +2 to context user, since it doesn't have it by default
    grantLabel("Code-Review", -2, 2, projectNameKey, "refs/heads/*", false, AccountGroup.UUID.parse(gApi.groups().id(contextUserGroup).get().id), false);
    pushContextUserConfig(manifestNameKey.get(), projectName, contextUserApi.get()._accountId.toString());
    // After we upload our config, we upload a new patchset to create the downstreams
    PushOneCommit.Result result = createChange(testRepo, "master", "subject", "filename2", "echo Hello", "sometopic");
    result.assertOkStatus();
    // Check that there are the correct number of changes in the topic
    List<ChangeInfo> changesInTopic = gApi.changes().query("topic: " + gApi.changes().id(result.getChangeId()).topic()).withOptions(CURRENT_REVISION, CURRENT_COMMIT).get();
    assertThat(changesInTopic).hasSize(3);
    List<ChangeInfo> sortedChanges = sortedChanges(changesInTopic);
    // Check that downstream is at Code-Review 0
    ChangeInfo dsOneChangeInfo = sortedChanges.get(0);
    assertThat(dsOneChangeInfo.branch).isEqualTo("ds_one");
    assertCodeReview(dsOneChangeInfo.id, 0, null);
    // Try to +1 master and see it succeed to +1 master and ds_one
    ChangeInfo masterChangeInfo = sortedChanges.get(2);
    assertThat(masterChangeInfo.branch).isEqualTo("master");
    assertCodeReviewMissing(masterChangeInfo.id);
    recommend(masterChangeInfo.id);
    assertCodeReview(masterChangeInfo.id, 1, null);
    assertCodeReview(dsOneChangeInfo.id, 1, "autogenerated:Automerger");
    ChangeInfo dsTwoChangeInfo = sortedChanges.get(1);
    assertThat(dsTwoChangeInfo.branch).isEqualTo("ds_two");
    assertCodeReview(dsTwoChangeInfo.id, 1, "autogenerated:Automerger");
    // +2 ds_one and see that it overrides the +1 of the contextUser
    approve(dsOneChangeInfo.id);
    assertCodeReview(dsOneChangeInfo.id, 2, null);
    assertCodeReview(dsTwoChangeInfo.id, 2, "autogenerated:Automerger");
    // +0 ds_one and see that it goes back to the +1 of the contextUser
    gApi.changes().id(dsOneChangeInfo.id).revision("current").review(ReviewInput.noScore());
    assertCodeReview(dsOneChangeInfo.id, 1, "autogenerated:Automerger");
    assertCodeReview(dsTwoChangeInfo.id, 1, "autogenerated:Automerger");
}
#method_after
@Test
public void testContextUser_downstreamHighestVote() throws Exception {
    // Branch flow for contextUser is master -> ds_one -> ds_two
    Project.NameKey manifestNameKey = defaultSetup();
    // Create initial change
    PushOneCommit.Result initialResult = createChange("subject", "filename", "echo Hello");
    // Project name is scoped by test, so we need to get it from our initial change
    Project.NameKey projectNameKey = initialResult.getChange().project();
    String projectName = projectNameKey.get();
    createBranch(new Branch.NameKey(projectName, "ds_one"));
    createBranch(new Branch.NameKey(projectName, "ds_two"));
    initialResult.assertOkStatus();
    merge(initialResult);
    // Create normalUserGroup, containing user, and contextUserGroup, containing contextUser
    String normalUserGroup = groupOperations.newGroup().name("normalUserGroup").create().get();
    gApi.groups().id(normalUserGroup).addMembers(user.id().toString());
    AccountApi contextUserApi = gApi.accounts().create("randomContextUser");
    String contextUserGroup = groupOperations.newGroup().name("contextUserGroup").create().get();
    gApi.groups().id(contextUserGroup).addMembers(contextUserApi.get().name);
    // Grant +2 to context user, since it doesn't have it by default
    grantLabel("Code-Review", -2, 2, projectNameKey, "refs/heads/*", false, AccountGroup.UUID.parse(gApi.groups().id(contextUserGroup).get().id), false);
    pushContextUserConfig(manifestNameKey.get(), projectName, contextUserApi.get()._accountId.toString());
    // After we upload our config, we upload a new patchset to create the downstreams
    PushOneCommit.Result result = createChange(testRepo, "master", "subject", "filename2", "echo Hello", "sometopic");
    result.assertOkStatus();
    // Check that there are the correct number of changes in the topic
    List<ChangeInfo> changesInTopic = gApi.changes().query("topic: " + gApi.changes().id(result.getChangeId()).topic()).withOptions(CURRENT_REVISION, CURRENT_COMMIT).get();
    assertThat(changesInTopic).hasSize(3);
    List<ChangeInfo> sortedChanges = sortedChanges(changesInTopic);
    // Check that downstream is at Code-Review 0
    ChangeInfo dsOneChangeInfo = sortedChanges.get(0);
    assertThat(dsOneChangeInfo.branch).isEqualTo("ds_one");
    assertCodeReview(dsOneChangeInfo.id, 0, null);
    // Try to +1 master and see it succeed to +1 master and ds_one
    ChangeInfo masterChangeInfo = sortedChanges.get(2);
    assertThat(masterChangeInfo.branch).isEqualTo("master");
    assertCodeReviewMissing(masterChangeInfo.id);
    recommend(masterChangeInfo.id);
    assertCodeReview(masterChangeInfo.id, 1, null);
    assertCodeReview(dsOneChangeInfo.id, 1, "autogenerated:Automerger");
    ChangeInfo dsTwoChangeInfo = sortedChanges.get(1);
    assertThat(dsTwoChangeInfo.branch).isEqualTo("ds_two");
    assertCodeReview(dsTwoChangeInfo.id, 1, "autogenerated:Automerger");
    // +2 ds_one and see that it overrides the +1 of the contextUser
    approve(dsOneChangeInfo.id);
    assertCodeReview(dsOneChangeInfo.id, 2, null);
    assertCodeReview(dsTwoChangeInfo.id, 2, "autogenerated:Automerger");
    // +0 ds_one and see that it goes back to the +1 of the contextUser
    gApi.changes().id(dsOneChangeInfo.id).revision("current").review(ReviewInput.noScore());
    assertCodeReview(dsOneChangeInfo.id, 1, "autogenerated:Automerger");
    assertCodeReview(dsTwoChangeInfo.id, 1, "autogenerated:Automerger");
}
#end_block

#method_before
public String generate(RevCommit original, RevCommit mergeTip, Branch.NameKey dest, String current) {
    requireNonNull(original.getRawBuffer());
    if (mergeTip != null) {
        requireNonNull(mergeTip.getRawBuffer());
    }
    for (ChangeMessageModifier changeMessageModifier : changeMessageModifiers) {
        current = changeMessageModifier.onSubmit(current, original, mergeTip, dest);
        requireNonNull(current, () -> String.format("%s.OnSubmit returned null instead of new commit message", changeMessageModifier.getClass().getName()));
    }
    return current;
}
#method_after
public String generate(RevCommit original, RevCommit mergeTip, Branch.NameKey dest, String originalMessage) {
    requireNonNull(original.getRawBuffer());
    if (mergeTip != null) {
        requireNonNull(mergeTip.getRawBuffer());
    }
    int count = 0;
    String current = originalMessage;
    for (Extension<ChangeMessageModifier> ext : changeMessageModifiers.entries()) {
        ChangeMessageModifier changeMessageModifier = ext.get();
        String className = changeMessageModifier.getClass().getName();
        current = changeMessageModifier.onSubmit(current, original, mergeTip, dest);
        checkState(current != null, "%s.onSubmit from plugin %s returned null instead of new commit message", className, ext.getPluginName());
        count++;
        logger.atFine().log("Invoked %s from plugin %s, message length now %d", className, ext.getPluginName(), current.length());
    }
    logger.atFine().log("Invoked %d ChangeMessageModifiers on message with original length %d", count, originalMessage.length());
    return current;
}
#end_block

#method_before
public static ObjectId mergeWithConflicts(RevWalk rw, ObjectInserter ins, DirCache dc, String oursName, RevCommit ours, String theirsName, RevCommit theirs, Map<String, MergeResult<? extends Sequence>> mergeResults) throws IOException {
    rw.parseBody(ours);
    rw.parseBody(theirs);
    String oursMsg = ours.getShortMessage();
    String theirsMsg = theirs.getShortMessage();
    int nameLength = Math.max(oursName.length(), theirsName.length());
    String oursNameFormatted = String.format("%0$-" + nameLength + "s (%s %s)", oursName, ours.abbreviate(6).name(), oursMsg.substring(0, Math.min(oursMsg.length(), 60)));
    String theirsNameFormatted = String.format("%0$-" + nameLength + "s (%s %s)", theirsName, theirs.abbreviate(6).name(), theirsMsg.substring(0, Math.min(theirsMsg.length(), 60)));
    MergeFormatter fmt = new MergeFormatter();
    Map<String, ObjectId> resolved = new HashMap<>();
    for (Map.Entry<String, MergeResult<? extends Sequence>> entry : mergeResults.entrySet()) {
        MergeResult<? extends Sequence> p = entry.getValue();
        TemporaryBuffer buf = null;
        try {
            // TODO(dborowitz): Respect inCoreLimit here.
            buf = new TemporaryBuffer.LocalFile(null, 10 * 1024 * 1024);
            fmt.formatMerge(buf, p, "BASE", oursNameFormatted, theirsNameFormatted, UTF_8);
            buf.close();
            try (InputStream in = buf.openInputStream()) {
                resolved.put(entry.getKey(), ins.insert(Constants.OBJ_BLOB, buf.length(), in));
            }
        } finally {
            if (buf != null) {
                buf.destroy();
            }
        }
    }
    DirCacheBuilder builder = dc.builder();
    int cnt = dc.getEntryCount();
    for (int i = 0; i < cnt; ) {
        DirCacheEntry entry = dc.getEntry(i);
        if (entry.getStage() == 0) {
            builder.add(entry);
            i++;
            continue;
        }
        int next = dc.nextEntry(i);
        String path = entry.getPathString();
        DirCacheEntry res = new DirCacheEntry(path);
        if (resolved.containsKey(path)) {
            // For a file with content merge conflict that we produced a result
            // above on, collapse the file down to a single stage 0 with just
            // the blob content, and a randomly selected mode (the lowest stage,
            // which should be the merge base, or ours).
            res.setFileMode(entry.getFileMode());
            res.setObjectId(resolved.get(path));
        } else if (next == i + 1) {
            // If there is exactly one stage present, shouldn't be a conflict...
            res.setFileMode(entry.getFileMode());
            res.setObjectId(entry.getObjectId());
        } else if (next == i + 2) {
            // Two stages suggests a delete/modify conflict. Pick the higher
            // stage as the automatic result.
            entry = dc.getEntry(i + 1);
            res.setFileMode(entry.getFileMode());
            res.setObjectId(entry.getObjectId());
        } else {
            // 3 stage conflict, no resolve above
            // Punt on the 3-stage conflict and show the base, for now.
            res.setFileMode(entry.getFileMode());
            res.setObjectId(entry.getObjectId());
        }
        builder.add(res);
        i = next;
    }
    builder.finish();
    return dc.writeTree(ins);
}
#method_after
public static ObjectId mergeWithConflicts(RevWalk rw, ObjectInserter ins, DirCache dc, String oursName, RevCommit ours, String theirsName, RevCommit theirs, Map<String, MergeResult<? extends Sequence>> mergeResults) throws IOException {
    rw.parseBody(ours);
    rw.parseBody(theirs);
    String oursMsg = ours.getShortMessage();
    String theirsMsg = theirs.getShortMessage();
    int nameLength = Math.max(oursName.length(), theirsName.length());
    String oursNameFormatted = String.format("%0$-" + nameLength + "s (%s %s)", oursName, ours.abbreviate(6).name(), oursMsg.substring(0, Math.min(oursMsg.length(), 60)));
    String theirsNameFormatted = String.format("%0$-" + nameLength + "s (%s %s)", theirsName, theirs.abbreviate(6).name(), theirsMsg.substring(0, Math.min(theirsMsg.length(), 60)));
    MergeFormatter fmt = new MergeFormatter();
    Map<String, ObjectId> resolved = new HashMap<>();
    for (Map.Entry<String, MergeResult<? extends Sequence>> entry : mergeResults.entrySet()) {
        MergeResult<? extends Sequence> p = entry.getValue();
        // TemporaryBuffer requires calling close before reading.
        @SuppressWarnings("resource")
        TemporaryBuffer buf = null;
        try {
            // TODO(dborowitz): Respect inCoreLimit here.
            buf = new TemporaryBuffer.LocalFile(null, 10 * 1024 * 1024);
            fmt.formatMerge(buf, p, "BASE", oursNameFormatted, theirsNameFormatted, UTF_8);
            // Flush file and close for writes, but leave available for reading.
            buf.close();
            try (InputStream in = buf.openInputStream()) {
                resolved.put(entry.getKey(), ins.insert(Constants.OBJ_BLOB, buf.length(), in));
            }
        } finally {
            if (buf != null) {
                buf.destroy();
            }
        }
    }
    DirCacheBuilder builder = dc.builder();
    int cnt = dc.getEntryCount();
    for (int i = 0; i < cnt; ) {
        DirCacheEntry entry = dc.getEntry(i);
        if (entry.getStage() == 0) {
            builder.add(entry);
            i++;
            continue;
        }
        int next = dc.nextEntry(i);
        String path = entry.getPathString();
        DirCacheEntry res = new DirCacheEntry(path);
        if (resolved.containsKey(path)) {
            // For a file with content merge conflict that we produced a result
            // above on, collapse the file down to a single stage 0 with just
            // the blob content, and a randomly selected mode (the lowest stage,
            // which should be the merge base, or ours).
            res.setFileMode(entry.getFileMode());
            res.setObjectId(resolved.get(path));
        } else if (next == i + 1) {
            // If there is exactly one stage present, shouldn't be a conflict...
            res.setFileMode(entry.getFileMode());
            res.setObjectId(entry.getObjectId());
        } else if (next == i + 2) {
            // Two stages suggests a delete/modify conflict. Pick the higher
            // stage as the automatic result.
            entry = dc.getEntry(i + 1);
            res.setFileMode(entry.getFileMode());
            res.setObjectId(entry.getObjectId());
        } else {
            // 3 stage conflict, no resolve above
            // Punt on the 3-stage conflict and show the base, for now.
            res.setFileMode(entry.getFileMode());
            res.setObjectId(entry.getObjectId());
        }
        builder.add(res);
        i = next;
    }
    builder.finish();
    return dc.writeTree(ins);
}
#end_block

#method_before
@Override
public boolean compareAndRemove(String project, Ref oldRef) throws IOException {
    return ignoreRefInSharedDb(oldRef) || compareAndPut(project, oldRef, NULL_REF);
}
#method_after
@Override
public boolean compareAndRemove(String project, Ref oldRef) throws IOException {
    return compareAndPut(project, oldRef, NULL_REF);
}
#end_block

#method_before
@Override
public boolean compareAndPut(String projectName, Ref oldRef, Ref newRef) throws IOException {
    if ((newRef != NULL_REF && ignoreRefInSharedDb(newRef)) || newRef == NULL_REF && ignoreRefInSharedDb(oldRef)) {
        return true;
    }
    final DistributedAtomicValue distributedRefValue = new DistributedAtomicValue(client, pathFor(projectName, oldRef, newRef), retryPolicy);
    try {
        if (oldRef == NULL_REF) {
            return distributedRefValue.initialize(writeObjectId(newRef.getObjectId()));
        }
        final ObjectId newValue = newRef.getObjectId() == null ? ObjectId.zeroId() : newRef.getObjectId();
        final AtomicValue<byte[]> newDistributedValue = distributedRefValue.compareAndSet(writeObjectId(oldRef.getObjectId()), writeObjectId(newValue));
        if (!newDistributedValue.succeeded() && refNotInZk(projectName, oldRef, newRef)) {
            return distributedRefValue.initialize(writeObjectId(newRef.getObjectId()));
        }
        return newDistributedValue.succeeded();
    } catch (Exception e) {
        logger.atWarning().withCause(e).log("Error trying to perform CAS at path %s", pathFor(projectName, oldRef, newRef));
        throw new IOException(String.format("Error trying to perform CAS at path %s", pathFor(projectName, oldRef, newRef)), e);
    }
}
#method_after
@Override
public boolean compareAndPut(String projectName, Ref oldRef, Ref newRef) throws IOException {
    if (ignoreRefInSharedDb(MoreObjects.firstNonNull(oldRef.getName(), newRef.getName()))) {
        return true;
    }
    final DistributedAtomicValue distributedRefValue = new DistributedAtomicValue(client, pathFor(projectName, oldRef, newRef), retryPolicy);
    try {
        if (oldRef == NULL_REF) {
            return distributedRefValue.initialize(writeObjectId(newRef.getObjectId()));
        }
        final ObjectId newValue = newRef.getObjectId() == null ? ObjectId.zeroId() : newRef.getObjectId();
        final AtomicValue<byte[]> newDistributedValue = distributedRefValue.compareAndSet(writeObjectId(oldRef.getObjectId()), writeObjectId(newValue));
        if (!newDistributedValue.succeeded() && refNotInZk(projectName, oldRef, newRef)) {
            return distributedRefValue.initialize(writeObjectId(newRef.getObjectId()));
        }
        return newDistributedValue.succeeded();
    } catch (Exception e) {
        logger.atWarning().withCause(e).log("Error trying to perform CAS at path %s", pathFor(projectName, oldRef, newRef));
        throw new IOException(String.format("Error trying to perform CAS at path %s", pathFor(projectName, oldRef, newRef)), e);
    }
}
#end_block

#method_before
@Test
public void anImmutableChangeShouldBeIgnored() {
    Ref immutableChangeRef = zkSharedRefDatabase.newRef(A_REF_NAME_OF_A_PATCHSET, AN_OBJECT_ID_1);
    assertThat(zkSharedRefDatabase.ignoreRefInSharedDb(immutableChangeRef)).isTrue();
}
#method_after
@Test
public void anImmutableChangeShouldBeIgnored() {
    Ref immutableChangeRef = zkSharedRefDatabase.newRef(A_REF_NAME_OF_A_PATCHSET, AN_OBJECT_ID_1);
    assertThat(zkSharedRefDatabase.ignoreRefInSharedDb(immutableChangeRef.getName())).isTrue();
}
#end_block

#method_before
@Test
public void aChangeMetaShouldNotBeIgnored() {
    Ref immutableChangeRef = zkSharedRefDatabase.newRef("refs/changes/01/1/meta", AN_OBJECT_ID_1);
    assertThat(zkSharedRefDatabase.ignoreRefInSharedDb(immutableChangeRef)).isFalse();
}
#method_after
@Test
public void aChangeMetaShouldNotBeIgnored() {
    Ref immutableChangeRef = zkSharedRefDatabase.newRef("refs/changes/01/1/meta", AN_OBJECT_ID_1);
    assertThat(zkSharedRefDatabase.ignoreRefInSharedDb(immutableChangeRef.getName())).isFalse();
}
#end_block

#method_before
@Test
public void aDraftCommentsShouldBeIgnored() {
    Ref immutableChangeRef = zkSharedRefDatabase.newRef("refs/draft-comments/01/1/1000000", AN_OBJECT_ID_1);
    assertThat(zkSharedRefDatabase.ignoreRefInSharedDb(immutableChangeRef)).isTrue();
}
#method_after
@Test
public void aDraftCommentsShouldBeIgnored() {
    Ref immutableChangeRef = zkSharedRefDatabase.newRef("refs/draft-comments/01/1/1000000", AN_OBJECT_ID_1);
    assertThat(zkSharedRefDatabase.ignoreRefInSharedDb(immutableChangeRef.getName())).isTrue();
}
#end_block

#method_before
@Test
public void regularRefHeadsMasterShouldNotBeIgnored() {
    Ref immutableChangeRef = zkSharedRefDatabase.newRef("refs/heads/master", AN_OBJECT_ID_1);
    assertThat(zkSharedRefDatabase.ignoreRefInSharedDb(immutableChangeRef)).isFalse();
}
#method_after
@Test
public void regularRefHeadsMasterShouldNotBeIgnored() {
    Ref immutableChangeRef = zkSharedRefDatabase.newRef("refs/heads/master", AN_OBJECT_ID_1);
    assertThat(zkSharedRefDatabase.ignoreRefInSharedDb(immutableChangeRef.getName())).isFalse();
}
#end_block

#method_before
@Test
public void regularCommitShouldNotBeIgnored() {
    Ref immutableChangeRef = zkSharedRefDatabase.newRef("refs/heads/stable-2.16", AN_OBJECT_ID_1);
    assertThat(zkSharedRefDatabase.ignoreRefInSharedDb(immutableChangeRef)).isFalse();
}
#method_after
@Test
public void regularCommitShouldNotBeIgnored() {
    Ref immutableChangeRef = zkSharedRefDatabase.newRef("refs/heads/stable-2.16", AN_OBJECT_ID_1);
    assertThat(zkSharedRefDatabase.ignoreRefInSharedDb(immutableChangeRef.getName())).isFalse();
}
#end_block

#method_before
@Override
public boolean compareAndRemove(String project, Ref oldRef) throws IOException {
    return compareAndPut(project, oldRef, NULL_REF);
}
#method_after
@Override
public boolean compareAndRemove(String project, Ref oldRef) throws IOException {
    return ignoreRefInSharedDb(oldRef) || compareAndPut(project, oldRef, NULL_REF);
}
#end_block

#method_before
@Override
public boolean compareAndPut(String projectName, Ref oldRef, Ref newRef) throws IOException {
    if (newRef != NULL_REF) {
        if (ignoreRefInSharedDb(newRef)) {
            return true;
        }
    }
    final DistributedAtomicValue distributedRefValue = new DistributedAtomicValue(client, pathFor(projectName, oldRef, newRef), retryPolicy);
    try {
        if (oldRef == NULL_REF) {
            return distributedRefValue.initialize(writeObjectId(newRef.getObjectId()));
        }
        final ObjectId newValue = newRef.getObjectId() == null ? ObjectId.zeroId() : newRef.getObjectId();
        final AtomicValue<byte[]> newDistributedValue = distributedRefValue.compareAndSet(writeObjectId(oldRef.getObjectId()), writeObjectId(newValue));
        if (!newDistributedValue.succeeded() && refNotInZk(projectName, oldRef, newRef)) {
            return distributedRefValue.initialize(writeObjectId(newRef.getObjectId()));
        }
        return newDistributedValue.succeeded();
    } catch (Exception e) {
        logger.atWarning().withCause(e).log("Error trying to perform CAS at path %s", pathFor(projectName, oldRef, newRef));
        throw new IOException(String.format("Error trying to perform CAS at path %s", pathFor(projectName, oldRef, newRef)), e);
    }
}
#method_after
@Override
public boolean compareAndPut(String projectName, Ref oldRef, Ref newRef) throws IOException {
    if (newRef != NULL_REF && ignoreRefInSharedDb(newRef)) {
        return true;
    }
    final DistributedAtomicValue distributedRefValue = new DistributedAtomicValue(client, pathFor(projectName, oldRef, newRef), retryPolicy);
    try {
        if (oldRef == NULL_REF) {
            return distributedRefValue.initialize(writeObjectId(newRef.getObjectId()));
        }
        final ObjectId newValue = newRef.getObjectId() == null ? ObjectId.zeroId() : newRef.getObjectId();
        final AtomicValue<byte[]> newDistributedValue = distributedRefValue.compareAndSet(writeObjectId(oldRef.getObjectId()), writeObjectId(newValue));
        if (!newDistributedValue.succeeded() && refNotInZk(projectName, oldRef, newRef)) {
            return distributedRefValue.initialize(writeObjectId(newRef.getObjectId()));
        }
        return newDistributedValue.succeeded();
    } catch (Exception e) {
        logger.atWarning().withCause(e).log("Error trying to perform CAS at path %s", pathFor(projectName, oldRef, newRef));
        throw new IOException(String.format("Error trying to perform CAS at path %s", pathFor(projectName, oldRef, newRef)), e);
    }
}
#end_block

#method_before
default boolean ignoreRefInSharedDb(Ref ref) {
    for (String ignoreRefRegex : refsToIgnoreInSharedDb) {
        if (ref.getName().matches(ignoreRefRegex)) {
            return true;
        }
    }
    return false;
}
#method_after
default boolean ignoreRefInSharedDb(Ref ref) {
    String refName = ref.getName();
    return refName == null || refName.startsWith("refs/draft-comments") || (refName.startsWith("refs/changes") && !refName.endsWith("/meta"));
}
#end_block

#method_before
@Test
public void immutableChangeShouldReturnTrue() throws Exception {
    Ref changeRef = newRef("refs/changes/01/1/1", AN_OBJECT_ID_1);
    boolean shouldReturnTrue = zkSharedRefDatabase.compareAndPut(A_TEST_PROJECT_NAME, SharedRefDatabase.NULL_REF, changeRef);
    assertThat(shouldReturnTrue).isTrue();
}
#method_after
@Test
public void immutableChangeShouldReturnTrue() throws Exception {
    Ref changeRef = zkSharedRefDatabase.newRef("refs/changes/01/1/1", AN_OBJECT_ID_1);
    boolean shouldReturnTrue = zkSharedRefDatabase.compareAndPut(A_TEST_PROJECT_NAME, SharedRefDatabase.NULL_REF, changeRef);
    assertThat(shouldReturnTrue).isTrue();
}
#end_block

#method_before
@Test(expected = Exception.class)
public void immutableChangeShouldNotBeStored() throws Exception {
    Ref changeRef = newRef("refs/changes/01/1/1", AN_OBJECT_ID_1);
    zkSharedRefDatabase.compareAndPut(A_TEST_PROJECT_NAME, SharedRefDatabase.NULL_REF, changeRef);
    zookeeperContainer.readRefValueFromZk(A_TEST_PROJECT_NAME, changeRef);
}
#method_after
@Test(expected = Exception.class)
public void immutableChangeShouldNotBeStored() throws Exception {
    Ref changeRef = zkSharedRefDatabase.newRef(A_REF_NAME_OF_A_PATCHSET, AN_OBJECT_ID_1);
    zkSharedRefDatabase.compareAndPut(A_TEST_PROJECT_NAME, SharedRefDatabase.NULL_REF, changeRef);
    zookeeperContainer.readRefValueFromZk(A_TEST_PROJECT_NAME, changeRef);
}
#end_block

#method_before
@Test
public void anImmutableChangeShouldBeIgnored() {
    Ref immutableChangeRef = newRef("refs/changes/01/1/1", AN_OBJECT_ID_1);
    assertThat(zkSharedRefDatabase.ignoreRefInSharedDb(immutableChangeRef)).isTrue();
}
#method_after
@Test
public void anImmutableChangeShouldBeIgnored() {
    Ref immutableChangeRef = zkSharedRefDatabase.newRef(A_REF_NAME_OF_A_PATCHSET, AN_OBJECT_ID_1);
    assertThat(zkSharedRefDatabase.ignoreRefInSharedDb(immutableChangeRef)).isTrue();
}
#end_block

#method_before
@Test
public void aChangeMetaShouldNotBeIgnored() {
    Ref immutableChangeRef = newRef("refs/changes/01/1/meta", AN_OBJECT_ID_1);
    assertThat(zkSharedRefDatabase.ignoreRefInSharedDb(immutableChangeRef)).isFalse();
}
#method_after
@Test
public void aChangeMetaShouldNotBeIgnored() {
    Ref immutableChangeRef = zkSharedRefDatabase.newRef("refs/changes/01/1/meta", AN_OBJECT_ID_1);
    assertThat(zkSharedRefDatabase.ignoreRefInSharedDb(immutableChangeRef)).isFalse();
}
#end_block

#method_before
@Test
public void aDraftCommentsShouldBeIgnored() {
    Ref immutableChangeRef = newRef("refs/draft-comments/01/1/1000000", AN_OBJECT_ID_1);
    assertThat(zkSharedRefDatabase.ignoreRefInSharedDb(immutableChangeRef)).isTrue();
}
#method_after
@Test
public void aDraftCommentsShouldBeIgnored() {
    Ref immutableChangeRef = zkSharedRefDatabase.newRef("refs/draft-comments/01/1/1000000", AN_OBJECT_ID_1);
    assertThat(zkSharedRefDatabase.ignoreRefInSharedDb(immutableChangeRef)).isTrue();
}
#end_block

#method_before
@Test
public void regularRefHeadsMasterShouldNotBeIgnored() {
    Ref immutableChangeRef = newRef("refs/heads/master", AN_OBJECT_ID_1);
    assertThat(zkSharedRefDatabase.ignoreRefInSharedDb(immutableChangeRef)).isFalse();
}
#method_after
@Test
public void regularRefHeadsMasterShouldNotBeIgnored() {
    Ref immutableChangeRef = zkSharedRefDatabase.newRef("refs/heads/master", AN_OBJECT_ID_1);
    assertThat(zkSharedRefDatabase.ignoreRefInSharedDb(immutableChangeRef)).isFalse();
}
#end_block

#method_before
@Test
public void regularCommitShouldNotBeIgnored() {
    Ref immutableChangeRef = newRef("refs/heads/stable-2.16", AN_OBJECT_ID_1);
    assertThat(zkSharedRefDatabase.ignoreRefInSharedDb(immutableChangeRef)).isFalse();
}
#method_after
@Test
public void regularCommitShouldNotBeIgnored() {
    Ref immutableChangeRef = zkSharedRefDatabase.newRef("refs/heads/stable-2.16", AN_OBJECT_ID_1);
    assertThat(zkSharedRefDatabase.ignoreRefInSharedDb(immutableChangeRef)).isFalse();
}
#end_block

#method_before
private Injector createSysInjector() {
    final List<Module> modules = new ArrayList<>();
    modules.add(SchemaVersionCheck.module());
    modules.add(new DropWizardMetricMaker.RestModule());
    modules.add(new LogFileCompressor.Module());
    // Plugin module needs to be inserted *before* the index module
    // otherwise any on-line reindexing will happen without the proper
    // plugins loaded (e.g. group backends, custom Prolog predicates) and
    // the associated rules results would be invalid and will poison the
    // Prolog predicates cache.
    modules.add(new PluginRestApiModule());
    // Index module shutdown must happen before work queue shutdown, otherwise
    // work queue can get stuck waiting on index futures that will never return.
    modules.add(createIndexModule());
    modules.add(new WorkQueue.Module());
    modules.add(new StreamEventsApiListener.Module());
    modules.add(new EventBroker.Module());
    modules.add(test ? new H2AccountPatchReviewStore.InMemoryModule() : new JdbcAccountPatchReviewStore.Module(config));
    modules.add(new ReceiveCommitsExecutorModule());
    modules.add(new DiffExecutorModule());
    modules.add(new MimeUtil2Module());
    modules.add(cfgInjector.getInstance(GerritGlobalModule.class));
    modules.add(new SearchingChangeCacheImpl.Module(slave));
    modules.add(new InternalAccountDirectory.Module());
    modules.add(new DefaultCacheFactory.Module());
    modules.add(cfgInjector.getInstance(MailReceiver.Module.class));
    if (emailModule != null) {
        modules.add(emailModule);
    } else {
        modules.add(new SmtpEmailSender.Module());
    }
    modules.add(new SignedTokenEmailTokenVerifier.Module());
    modules.add(new RestCacheAdminModule());
    modules.add(new GpgModule(config));
    modules.add(new StartupChecks.Module());
    if (MoreObjects.firstNonNull(httpd, true)) {
        modules.add(new CanonicalWebUrlModule() {

            @Override
            protected Class<? extends Provider<String>> provider() {
                return HttpCanonicalWebUrlProvider.class;
            }
        });
    } else {
        modules.add(new CanonicalWebUrlModule() {

            @Override
            protected Class<? extends Provider<String>> provider() {
                return CanonicalWebUrlProvider.class;
            }
        });
    }
    if (sshd) {
        modules.add(SshKeyCacheImpl.module());
    } else {
        modules.add(NoSshKeyCache.module());
    }
    modules.add(new AbstractModule() {

        @Override
        protected void configure() {
            bind(GerritOptions.class).toInstance(new GerritOptions(config, headless, slave, polyGerritDev));
            if (test) {
                bind(String.class).annotatedWith(SecureStoreClassName.class).toInstance(DefaultSecureStore.class.getName());
                bind(SecureStore.class).toProvider(SecureStoreProvider.class);
            }
        }
    });
    modules.add(new GarbageCollectionModule());
    if (!slave) {
        modules.add(new ChangeCleanupRunner.Module());
    }
    return cfgInjector.createChildInjector(modules);
}
#method_after
private Injector createSysInjector() {
    final List<Module> modules = new ArrayList<>();
    modules.add(SchemaVersionCheck.module());
    modules.add(new DropWizardMetricMaker.RestModule());
    modules.add(new LogFileCompressor.Module());
    // Plugin module needs to be inserted *before* the index module.
    // There is the concept of LifecycleModule, in Gerrit's own extension
    // to Guice, which has these:
    // listener().to(SomeClassImplementingLifecycleListener.class);
    // and the start() methods of each such listener are executed in the
    // order they are declared.
    // Makes sure that PluginLoader.start() is executed before the
    // LuceneIndexModule.start() so that plugins get loaded and the respective
    // Guice modules installed so that the on-line reindexing will happen
    // with the proper classes (e.g. group backends, custom Prolog
    // predicates) and the associated rules ready to be evaluated.
    modules.add(new PluginModule());
    // Index module shutdown must happen before work queue shutdown, otherwise
    // work queue can get stuck waiting on index futures that will never return.
    modules.add(createIndexModule());
    modules.add(new WorkQueue.Module());
    modules.add(new StreamEventsApiListener.Module());
    modules.add(new EventBroker.Module());
    modules.add(test ? new H2AccountPatchReviewStore.InMemoryModule() : new JdbcAccountPatchReviewStore.Module(config));
    modules.add(new ReceiveCommitsExecutorModule());
    modules.add(new DiffExecutorModule());
    modules.add(new MimeUtil2Module());
    modules.add(cfgInjector.getInstance(GerritGlobalModule.class));
    modules.add(new SearchingChangeCacheImpl.Module(slave));
    modules.add(new InternalAccountDirectory.Module());
    modules.add(new DefaultCacheFactory.Module());
    modules.add(cfgInjector.getInstance(MailReceiver.Module.class));
    if (emailModule != null) {
        modules.add(emailModule);
    } else {
        modules.add(new SmtpEmailSender.Module());
    }
    modules.add(new SignedTokenEmailTokenVerifier.Module());
    modules.add(new PluginRestApiModule());
    modules.add(new RestCacheAdminModule());
    modules.add(new GpgModule(config));
    modules.add(new StartupChecks.Module());
    if (MoreObjects.firstNonNull(httpd, true)) {
        modules.add(new CanonicalWebUrlModule() {

            @Override
            protected Class<? extends Provider<String>> provider() {
                return HttpCanonicalWebUrlProvider.class;
            }
        });
    } else {
        modules.add(new CanonicalWebUrlModule() {

            @Override
            protected Class<? extends Provider<String>> provider() {
                return CanonicalWebUrlProvider.class;
            }
        });
    }
    if (sshd) {
        modules.add(SshKeyCacheImpl.module());
    } else {
        modules.add(NoSshKeyCache.module());
    }
    modules.add(new AbstractModule() {

        @Override
        protected void configure() {
            bind(GerritOptions.class).toInstance(new GerritOptions(config, headless, slave, polyGerritDev));
            if (test) {
                bind(String.class).annotatedWith(SecureStoreClassName.class).toInstance(DefaultSecureStore.class.getName());
                bind(SecureStore.class).toProvider(SecureStoreProvider.class);
            }
        }
    });
    modules.add(new GarbageCollectionModule());
    if (!slave) {
        modules.add(new ChangeCleanupRunner.Module());
    }
    return cfgInjector.createChildInjector(modules);
}
#end_block

#method_before
@Override
public void stop() {
    try {
        zookeeper.stop();
    } catch (IOException e) {
        logger.atWarning().withCause(e).log("Cannot start zookeeper");
        throw new RuntimeException("Cannot start zookeeper", e);
    }
}
#method_after
@Override
public void stop() {
    zookeeperContainer.cleanup();
}
#end_block

#method_before
@Override
public void start() {
    try {
        zookeeper.start();
    } catch (Exception e) {
        logger.atWarning().withCause(e).log("Cannot stop zookeeper");
    }
}
#method_after
@Override
public void start() {
// Do nothing
}
#end_block

#method_before
@Test
public void inSyncChangeValidatorShouldAcceptNewChange() throws Exception {
    final PushOneCommit.Result change = createChange("refs/for/master");
    change.assertOkStatus();
}
#method_after
@Test
public void inSyncChangeValidatorShouldAcceptNewChange() throws Exception {
    // FIXME: The code does not work for already existing refs (need a migration step for first
    // run - T0). Using "refs/heads/master2" in this test for now
    final PushOneCommit.Result change = createCommitAndPush(testRepo, "refs/heads/master2", "msg", "file", "content");
    change.assertOkStatus();
}
#end_block

#method_before
@Override
public boolean compareAndPut(String projectName, Ref oldRef, Ref newRef) throws IOException {
    boolean isCreate = oldRef == NULL_REF;
    final ZkRefInfoMarshaller marshaller = new ZkRefInfoMarshaller(client);
    final InterProcessMutex refPathMutex = new InterProcessMutex(client, "/locks" + ZkRefInfoMarshaller.pathFor(projectName, newRef));
    try (Locker locker = new Locker(refPathMutex, lockTimeout.toMillis(), MILLISECONDS)) {
        final Optional<ZkRefInfo> infoCurrentlyInZkMaybe = marshaller.read(projectName, newRef.getName());
        final ZkRefInfo newRefInfo = new ZkRefInfo(projectName, newRef, instanceId);
        if (isCreate) {
            return doCreate(marshaller, infoCurrentlyInZkMaybe, newRefInfo);
        } else {
            return doUpdate(oldRef, marshaller, infoCurrentlyInZkMaybe, newRefInfo);
        }
    } catch (Exception e) {
        logger.atWarning().withCause(e).log("Error trying to perform CAS at path %s", ZkRefInfoMarshaller.pathFor(projectName, newRef));
        throw new IOException(String.format("Error trying to perform CAS at path %s", ZkRefInfoMarshaller.pathFor(projectName, newRef)), e);
    }
}
#method_after
@Override
public boolean compareAndPut(String projectName, Ref oldRef, Ref newRef) throws IOException {
    boolean isCreate = oldRef == NULL_REF;
    final ZkRefInfoDAO marshaller = new ZkRefInfoDAO(client);
    final InterProcessMutex refPathMutex = new InterProcessMutex(client, "/locks" + ZkRefInfoDAO.pathFor(projectName, newRef));
    try (Locker locker = new Locker(refPathMutex, lockTimeout.toMillis(), MILLISECONDS)) {
        final Optional<ZkRefInfo> infoCurrentlyInZkMaybe = marshaller.read(projectName, newRef.getName());
        final ZkRefInfo newRefInfo = new ZkRefInfo(projectName, newRef);
        if (isCreate) {
            return doCreate(marshaller, infoCurrentlyInZkMaybe, newRefInfo);
        }
        return doUpdate(oldRef, marshaller, infoCurrentlyInZkMaybe, newRefInfo);
    } catch (Exception e) {
        throw new IOException(String.format("Error trying to perform CAS at path %s", ZkRefInfoDAO.pathFor(projectName, newRef)), e);
    }
}
#end_block

#method_before
private boolean doUpdate(Ref oldRef, ZkRefInfoMarshaller marshaller, Optional<ZkRefInfo> infoCurrentlyInZkMaybe, ZkRefInfo newRefInfo) throws Exception {
    if (!infoCurrentlyInZkMaybe.isPresent()) {
        logger.atWarning().log("Asked to update ref %s but it is not in ZK at path %s", newRefInfo.refName(), ZkRefInfoMarshaller.pathFor(newRefInfo));
        return false;
    }
    if (!infoCurrentlyInZkMaybe.get().objectId().equals(oldRef.getObjectId())) {
        return false;
    }
    marshaller.update(newRefInfo);
    return true;
}
#method_after
private boolean doUpdate(Ref oldRef, ZkRefInfoDAO marshaller, Optional<ZkRefInfo> infoCurrentlyInZkMaybe, ZkRefInfo newRefInfo) throws Exception {
    if (!infoCurrentlyInZkMaybe.isPresent()) {
        logger.atWarning().log("Asked to update ref %s but it is not in ZK at path %s", newRefInfo.refName(), ZkRefInfoDAO.pathFor(newRefInfo));
        return false;
    }
    if (!infoCurrentlyInZkMaybe.get().objectId().equals(oldRef.getObjectId())) {
        logger.atWarning().log("Old Ref %s does not match the current Rf content in Zookeeper %s. Not applying the update.", oldRef.getObjectId(), infoCurrentlyInZkMaybe.get().objectId());
        return false;
    }
    marshaller.update(newRefInfo);
    return true;
}
#end_block

#method_before
private boolean doCreate(ZkRefInfoMarshaller marshaller, Optional<ZkRefInfo> infoCurrentlyInZkMaybe, ZkRefInfo newRefInfo) throws Exception {
    if (infoCurrentlyInZkMaybe.isPresent()) {
        logger.atWarning().log("Asked to create ref %s but it is already in ZK at path %s", newRefInfo.refName(), ZkRefInfoMarshaller.pathFor(newRefInfo));
        return false;
    }
    marshaller.create(newRefInfo);
    return true;
}
#method_after
private boolean doCreate(ZkRefInfoDAO marshaller, Optional<ZkRefInfo> infoCurrentlyInZkMaybe, ZkRefInfo newRefInfo) throws Exception {
    if (infoCurrentlyInZkMaybe.isPresent()) {
        logger.atWarning().log("Asked to create ref %s but it is already in ZK at path %s", newRefInfo.refName(), ZkRefInfoDAO.pathFor(newRefInfo));
        return false;
    }
    marshaller.create(newRefInfo);
    return true;
}
#end_block

#method_before
@Override
public boolean equals(Object o) {
    if (this == o) {
        return true;
    }
    if (o == null || getClass() != o.getClass()) {
        return false;
    }
    ZkRefInfo zkRefInfo = (ZkRefInfo) o;
    return Objects.equal(refName, zkRefInfo.refName) && Objects.equal(projectName, zkRefInfo.projectName) && Objects.equal(objectId, zkRefInfo.objectId) && Objects.equal(lastWriterInstanceId, zkRefInfo.lastWriterInstanceId) && Objects.equal(lastUpdatedAt, zkRefInfo.lastUpdatedAt);
}
#method_after
@Override
public boolean equals(Object other) {
    if (this == other) {
        return true;
    }
    if (other == null || getClass() != other.getClass()) {
        return false;
    }
    ZkRefInfo zkRefInfo = (ZkRefInfo) other;
    return Objects.equal(refName, zkRefInfo.refName) && Objects.equal(projectName, zkRefInfo.projectName) && Objects.equal(objectId, zkRefInfo.objectId);
}
#end_block

#method_before
@Override
public int hashCode() {
    return Objects.hashCode(refName, projectName, objectId, lastWriterInstanceId, lastUpdatedAt);
}
#method_after
@Override
public int hashCode() {
    return Objects.hashCode(refName, projectName, objectId);
}
#end_block

#method_before
@Test
public void shouldCompareAndPutSuccessfully() throws Exception {
    Ref oldRef = aRefObject();
    String projectName = RefFixture.aProjectName();
    marshaller.create(new ZkRefInfo(projectName, oldRef, UUID.randomUUID()));
    assertThat(zkSharedRefDatabase.compareAndPut(projectName, oldRef, aRefObject(oldRef.getName()))).isTrue();
}
#method_after
@Test
public void shouldCompareAndPutSuccessfully() throws Exception {
    Ref oldRef = refOf(AN_OBJECT_ID_1);
    Ref newRef = refOf(AN_OBJECT_ID_2);
    String projectName = RefFixture.A_TEST_PROJECT_NAME;
    marshaller.create(new ZkRefInfo(projectName, oldRef));
    assertThat(zkSharedRefDatabase.compareAndPut(projectName, oldRef, newRef)).isTrue();
}
#end_block

#method_before
@Test
public void compareAndPutShouldFailIfTheObjectionHasNotTheExpectedValue() throws Exception {
    String projectName = RefFixture.aProjectName();
    Ref oldRef = aRefObject();
    Ref expectedRef = aRefObject(oldRef.getName());
    marshaller.create(new ZkRefInfo(projectName, oldRef, UUID.randomUUID()));
    assertThat(zkSharedRefDatabase.compareAndPut(projectName, expectedRef, aRefObject(oldRef.getName()))).isFalse();
}
#method_after
@Test
public void compareAndPutShouldFailIfTheObjectionHasNotTheExpectedValue() throws Exception {
    String projectName = RefFixture.A_TEST_PROJECT_NAME;
    Ref oldRef = refOf(AN_OBJECT_ID_1);
    Ref expectedRef = refOf(AN_OBJECT_ID_2);
    marshaller.create(new ZkRefInfo(projectName, oldRef));
    assertThat(zkSharedRefDatabase.compareAndPut(projectName, expectedRef, refOf(AN_OBJECT_ID_3))).isFalse();
}
#end_block

#method_before
@Test
public void compareAndPutShouldFaiIfTheObjectionDoesNotExist() throws IOException {
    Ref oldRef = aRefObject();
    assertThat(zkSharedRefDatabase.compareAndPut(RefFixture.aProjectName(), oldRef, aRefObject(oldRef.getName()))).isFalse();
}
#method_after
@Test
public void compareAndPutShouldFaiIfTheObjectionDoesNotExist() throws IOException {
    Ref oldRef = refOf(AN_OBJECT_ID_1);
    assertThat(zkSharedRefDatabase.compareAndPut(RefFixture.A_TEST_PROJECT_NAME, oldRef, refOf(AN_OBJECT_ID_2))).isFalse();
}
#end_block

#method_before
@Test
public void shouldCompareAndRemoveSuccessfully() throws Exception {
    Ref oldRef = aRefObject();
    String projectName = RefFixture.aProjectName();
    marshaller.create(new ZkRefInfo(projectName, oldRef, UUID.randomUUID()));
    assertThat(zkSharedRefDatabase.compareAndRemove(projectName, oldRef)).isTrue();
}
#method_after
@Test
public void shouldCompareAndRemoveSuccessfully() throws Exception {
    Ref oldRef = refOf(AN_OBJECT_ID_1);
    String projectName = RefFixture.A_TEST_PROJECT_NAME;
    marshaller.create(new ZkRefInfo(projectName, oldRef));
    assertThat(zkSharedRefDatabase.compareAndRemove(projectName, oldRef)).isTrue();
}
#end_block

#method_before
@Test
public void shouldReplaceTheRefWithATombstoneAfterCompareAndPutRemove() throws Exception {
    Ref oldRef = aRefObject();
    String projectName = RefFixture.aProjectName();
    marshaller.create(new ZkRefInfo(projectName, oldRef, UUID.randomUUID()));
    assertThat(zkSharedRefDatabase.compareAndRemove(projectName, oldRef)).isTrue();
    Optional<ZkRefInfo> inZk = marshaller.read(projectName, oldRef.getName());
    assertThat(inZk.isPresent()).isTrue();
    assertThat(inZk.get().projectName()).isEqualTo(projectName);
    assertThat(inZk.get().refName()).isEqualTo(oldRef.getName());
    assertThat(inZk.get().objectId()).isEqualTo(ObjectId.zeroId());
}
#method_after
@Test
public void shouldReplaceTheRefWithATombstoneAfterCompareAndPutRemove() throws Exception {
    Ref oldRef = refOf(AN_OBJECT_ID_1);
    String projectName = RefFixture.A_TEST_PROJECT_NAME;
    marshaller.create(new ZkRefInfo(projectName, oldRef));
    assertThat(zkSharedRefDatabase.compareAndRemove(projectName, oldRef)).isTrue();
    Optional<ZkRefInfo> inZk = marshaller.read(projectName, oldRef.getName());
    assertThat(inZk.isPresent()).isTrue();
    inZk.get().equals(TombstoneRef.forRef(oldRef));
}
#end_block

#method_before
@Test
public void shouldNotCompareAndPutSuccessfullyAfterACompareAndRemove() throws Exception {
    Ref oldRef = aRefObject();
    String projectName = RefFixture.aProjectName();
    marshaller.create(new ZkRefInfo(projectName, oldRef, UUID.randomUUID()));
    zkSharedRefDatabase.compareAndRemove(projectName, oldRef);
    assertThat(zkSharedRefDatabase.compareAndPut(projectName, oldRef, aRefObject(oldRef.getName()))).isFalse();
}
#method_after
@Test
public void shouldNotCompareAndPutSuccessfullyAfterACompareAndRemove() throws Exception {
    Ref oldRef = refOf(AN_OBJECT_ID_1);
    String projectName = RefFixture.A_TEST_PROJECT_NAME;
    marshaller.create(new ZkRefInfo(projectName, oldRef));
    zkSharedRefDatabase.compareAndRemove(projectName, oldRef);
    assertThat(zkSharedRefDatabase.compareAndPut(projectName, oldRef, refOf(AN_OBJECT_ID_2))).isFalse();
}
#end_block

#method_before
static ZkRefInfo aZkRefInfo() {
    return new ZkRefInfo(aProjectName(), aChangeRefName(), anObjectId(), Instant.now(), UUID.randomUUID());
}
#method_after
default ZkRefInfo aZkRefInfo(ObjectId objectId) {
    return new ZkRefInfo(A_TEST_PROJECT_NAME, aBranchRef(), objectId);
}
#end_block

#method_before
@Test
public void shouldCreateAZRefInfo() throws Exception {
    ZkRefInfo refInfo = aZkRefInfo();
    marshaller.create(refInfo);
    Optional<ZkRefInfo> readRefInfo = marshaller.read(refInfo.projectName(), refInfo.refName());
    assertThat(readRefInfo).isEqualTo(Optional.of(refInfo));
}
#method_after
@Test
public void shouldCreateAZRefInfo() throws Exception {
    ZkRefInfo refInfo = aZkRefInfo(AN_OBJECT_ID_1);
    marshaller.create(refInfo);
    Optional<ZkRefInfo> readRefInfo = marshaller.read(refInfo.projectName(), refInfo.refName());
    assertThat(readRefInfo).isEqualTo(Optional.of(refInfo));
}
#end_block

#method_before
@Test
public void shouldReturnEmptyIfARefDoesNotExist() throws Exception {
    assertThat(marshaller.read(aProjectName(), aChangeRefName())).isEqualTo(Optional.empty());
}
#method_after
@Test
public void shouldReturnEmptyIfARefDoesNotExist() throws Exception {
    assertThat(marshaller.read(A_TEST_PROJECT_NAME, aBranchRef())).isEqualTo(Optional.empty());
}
#end_block

#method_before
@Test
public void shouldUpdateAZrefInfo() throws Exception {
    ZkRefInfo newRefInfo = aZkRefInfo();
    ZkRefInfo updateRefInfo = new ZkRefInfo(newRefInfo.projectName(), newRefInfo.refName(), anObjectId(), Instant.now(), UUID.randomUUID());
    // Make sure new refInfo and updateRefInfo are never the same
    assertThat(newRefInfo).isNotEqualTo(updateRefInfo);
    marshaller.create(newRefInfo);
    marshaller.update(updateRefInfo);
    Optional<ZkRefInfo> readUpdatedRefInfo = marshaller.read(updateRefInfo.projectName(), updateRefInfo.refName());
    assertThat(readUpdatedRefInfo).isEqualTo(Optional.of(updateRefInfo));
}
#method_after
@Test
public void shouldUpdateAZrefInfo() throws Exception {
    ZkRefInfo newRefInfo = aZkRefInfo(AN_OBJECT_ID_1);
    ZkRefInfo updateRefInfo = new ZkRefInfo(newRefInfo.projectName(), newRefInfo.refName(), AN_OBJECT_ID_2);
    marshaller.create(newRefInfo);
    marshaller.update(updateRefInfo);
    Optional<ZkRefInfo> readUpdatedRefInfo = marshaller.read(updateRefInfo.projectName(), updateRefInfo.refName());
    assertThat(readUpdatedRefInfo).isEqualTo(Optional.of(updateRefInfo));
}
#end_block

#method_before
@Test
public void shouldFailToReadZkRefInfoIfSomeOfTheInfoIsMissing() throws Exception {
    String projectName = aProjectName();
    String refName = aChangeRefName();
    curator.createContainers(ZkRefInfoMarshaller.pathFor(projectName, refName));
    expectedException.expect(CorruptedZkStorageException.class);
    expectedException.expectCause(nullValue(Exception.class));
    marshaller.read(projectName, refName);
}
#method_after
@Test
public void shouldFailToReadZkRefInfoIfSomeOfTheInfoIsMissing() throws Exception {
    String projectName = A_TEST_PROJECT_NAME;
    String refName = aBranchRef();
    curator.createContainers(ZkRefInfoDAO.pathFor(projectName, refName));
    expectedException.expect(CorruptedZkStorageException.class);
    expectedException.expectCause(nullValue(Exception.class));
    marshaller.read(projectName, refName);
}
#end_block

#method_before
@After
public void cleanup() {
    container.stop();
    curator.delete();
}
#method_after
public void cleanup() {
    this.curator.delete();
    this.container.stop();
}
#end_block

#method_before
@Override
protected void configure() {
    if (!noteDb.enabled()) {
        throw new ProvisionException("Gerrit is still running on ReviewDb: please migrate to NoteDb " + "and then reload the multi-site plugin.");
    }
    listener().to(Log4jMessageLogger.class);
    bind(MessageLogger.class).to(Log4jMessageLogger.class);
    install(new ForwarderModule());
    if (config.cache().synchronize()) {
        install(new CacheModule());
    }
    if (config.event().synchronize()) {
        install(new EventModule());
    }
    if (config.index().synchronize()) {
        install(new IndexModule());
    }
    if (config.kafkaSubscriber().enabled()) {
        install(new KafkaConsumerModule(config.kafkaSubscriber()));
        install(new ForwardedEventRouterModule());
    }
    if (config.kafkaPublisher().enabled()) {
        install(new BrokerForwarderModule(config.kafkaPublisher()));
    }
    if (runningAsATest) {
        install(new ZkValidationModule(config));
    } else {
        install(new ValidationModule(config));
    }
    bind(Gson.class).toProvider(GsonProvider.class).in(Singleton.class);
}
#method_after
@Override
protected void configure() {
    if (!noteDb.enabled()) {
        throw new ProvisionException("Gerrit is still running on ReviewDb: please migrate to NoteDb " + "and then reload the multi-site plugin.");
    }
    listener().to(Log4jMessageLogger.class);
    bind(MessageLogger.class).to(Log4jMessageLogger.class);
    install(new ForwarderModule());
    if (config.cache().synchronize()) {
        install(new CacheModule());
    }
    if (config.event().synchronize()) {
        install(new EventModule());
    }
    if (config.index().synchronize()) {
        install(new IndexModule());
    }
    if (config.kafkaSubscriber().enabled()) {
        install(new KafkaConsumerModule(config.kafkaSubscriber()));
        install(new ForwardedEventRouterModule());
    }
    if (config.kafkaPublisher().enabled()) {
        install(new BrokerForwarderModule(config.kafkaPublisher()));
    }
    install(new ValidationModule(config, disableGitRepositoryValidation));
    bind(Gson.class).toProvider(GsonProvider.class).in(Singleton.class);
}
#end_block

#method_before
@Override
protected void configure() {
    factory(MultiSiteRepository.Factory.class);
    factory(MultiSiteRefDatabase.Factory.class);
    factory(MultiSiteRefUpdate.Factory.class);
    bind(GitRepositoryManager.class).to(MultiSiteGitRepositoryManager.class);
    install(new ZkValidationModule(cfg));
}
#method_after
@Override
protected void configure() {
    factory(MultiSiteRepository.Factory.class);
    factory(MultiSiteRefDatabase.Factory.class);
    factory(MultiSiteRefUpdate.Factory.class);
    if (!disableGitRepositoryValidation) {
        bind(GitRepositoryManager.class).to(MultiSiteGitRepositoryManager.class);
    }
    install(new ZkValidationModule(cfg));
}
#end_block

#method_before
public ZookeeperConfig getZookeeperConfig() {
    return zookeeperConfig;
}
#method_after
public ZookeeperConfig getZookeeperConfig() {
    return zookeeperConfig.get();
}
#end_block

#method_before
public Kafka getKafka() {
    return kafka;
}
#method_after
public Kafka getKafka() {
    return kafka.get();
}
#end_block

#method_before
public KafkaPublisher kafkaPublisher() {
    return publisher;
}
#method_after
public KafkaPublisher kafkaPublisher() {
    return publisher.get();
}
#end_block

#method_before
public Cache cache() {
    return cache;
}
#method_after
public Cache cache() {
    return cache.get();
}
#end_block

#method_before
public Event event() {
    return event;
}
#method_after
public Event event() {
    return event.get();
}
#end_block

#method_before
public Index index() {
    return index;
}
#method_after
public Index index() {
    return index.get();
}
#end_block

#method_before
public KafkaSubscriber kafkaSubscriber() {
    return subscriber;
}
#method_after
public KafkaSubscriber kafkaSubscriber() {
    return subscriber.get();
}
#end_block

#method_before
private static boolean getBoolean(Config cfg, String section, String subsection, String name, boolean defaultValue) {
    return cfg.getBoolean(section, subsection, name, defaultValue);
}
#method_after
private static boolean getBoolean(Supplier<Config> cfg, String section, String subsection, String name, boolean defaultValue) {
    return cfg.get().getBoolean(section, subsection, name, defaultValue);
}
#end_block

#method_before
private static int getInt(Config cfg, String section, String subSection, String name, int defaultValue) {
    try {
        return cfg.getInt(section, subSection, name, defaultValue);
    } catch (IllegalArgumentException e) {
        log.error("invalid value for {}; using default value {}", name, defaultValue);
        log.debug("Failed to retrieve integer value: {}", e.getMessage(), e);
        return defaultValue;
    }
}
#method_after
private static int getInt(Supplier<Config> cfg, String section, String subSection, String name, int defaultValue) {
    try {
        return cfg.get().getInt(section, subSection, name, defaultValue);
    } catch (IllegalArgumentException e) {
        log.error("invalid value for {}; using default value {}", name, defaultValue);
        log.debug("Failed to retrieve integer value: {}", e.getMessage(), e);
        return defaultValue;
    }
}
#end_block

#method_before
private static String getString(Config cfg, String section, String subsection, String name, String defaultValue) {
    String value = cfg.getString(section, subsection, name);
    if (!Strings.isNullOrEmpty(value)) {
        return value;
    }
    return defaultValue;
}
#method_after
private static String getString(Supplier<Config> cfg, String section, String subsection, String name, String defaultValue) {
    String value = cfg.get().getString(section, subsection, name);
    if (!Strings.isNullOrEmpty(value)) {
        return value;
    }
    return defaultValue;
}
#end_block

#method_before
private static Map<EventFamily, Boolean> eventsEnabled(Config config, String subsection) {
    Map<EventFamily, Boolean> eventsEnabled = new HashMap<>();
    for (EventFamily eventFamily : EventFamily.values()) {
        String enabledConfigKey = eventFamily.lowerCamelName() + "Enabled";
        eventsEnabled.put(eventFamily, config.getBoolean(KAFKA_SECTION, subsection, enabledConfigKey, DEFAULT_ENABLE_PROCESSING));
    }
    return eventsEnabled;
}
#method_after
private static Map<EventFamily, Boolean> eventsEnabled(Supplier<Config> config, String subsection) {
    Map<EventFamily, Boolean> eventsEnabled = new HashMap<>();
    for (EventFamily eventFamily : EventFamily.values()) {
        String enabledConfigKey = eventFamily.lowerCamelName() + "Enabled";
        eventsEnabled.put(eventFamily, config.get().getBoolean(KAFKA_SECTION, subsection, enabledConfigKey, DEFAULT_ENABLE_PROCESSING));
    }
    return eventsEnabled;
}
#end_block

#method_before
private static void applyKafkaConfig(Config config, String subsectionName, Properties target) {
    for (String section : config.getSubsections(KAFKA_SECTION)) {
        if (section.equals(subsectionName)) {
            for (String name : config.getNames(KAFKA_SECTION, section, true)) {
                if (name.startsWith(KAFKA_PROPERTY_PREFIX)) {
                    Object value = config.getString(KAFKA_SECTION, subsectionName, name);
                    String configProperty = name.replaceFirst(KAFKA_PROPERTY_PREFIX, "");
                    String propName = CaseFormat.LOWER_CAMEL.to(CaseFormat.LOWER_HYPHEN, configProperty).replaceAll("-", ".");
                    log.info("[{}] Setting kafka property: {} = {}", subsectionName, propName, value);
                    target.put(propName, value);
                }
            }
        }
    }
    target.put("bootstrap.servers", getString(config, KAFKA_SECTION, null, "bootstrapServers", DEFAULT_KAFKA_BOOTSTRAP_SERVERS));
}
#method_after
private static void applyKafkaConfig(Supplier<Config> configSupplier, String subsectionName, Properties target) {
    Config config = configSupplier.get();
    for (String section : config.getSubsections(KAFKA_SECTION)) {
        if (section.equals(subsectionName)) {
            for (String name : config.getNames(KAFKA_SECTION, section, true)) {
                if (name.startsWith(KAFKA_PROPERTY_PREFIX)) {
                    Object value = config.getString(KAFKA_SECTION, subsectionName, name);
                    String configProperty = name.replaceFirst(KAFKA_PROPERTY_PREFIX, "");
                    String propName = CaseFormat.LOWER_CAMEL.to(CaseFormat.LOWER_HYPHEN, configProperty).replaceAll("-", ".");
                    log.info("[{}] Setting kafka property: {} = {}", subsectionName, propName, value);
                    target.put(propName, value);
                }
            }
        }
    }
    target.put("bootstrap.servers", getString(configSupplier, KAFKA_SECTION, null, "bootstrapServers", DEFAULT_KAFKA_BOOTSTRAP_SERVERS));
}
#end_block

#method_before
private static boolean getBoolean(Config cfg, String section, String name, boolean defaultValue) {
    try {
        return cfg.getBoolean(section, name, defaultValue);
    } catch (IllegalArgumentException e) {
        log.error("invalid value for {}; using default value {}", name, defaultValue);
        log.debug("Failed to retrieve boolean value: {}", e.getMessage(), e);
        return defaultValue;
    }
}
#method_after
private static boolean getBoolean(Supplier<Config> cfg, String section, String name, boolean defaultValue) {
    try {
        return cfg.get().getBoolean(section, name, defaultValue);
    } catch (IllegalArgumentException e) {
        log.error("invalid value for {}; using default value {}", name, defaultValue);
        log.debug("Failed to retrieve boolean value: {}", e.getMessage(), e);
        return defaultValue;
    }
}
#end_block

#method_before
@Before
public void setUp() {
    globalPluginConfig = new Config();
    when(pluginConfigFactoryMock.getGlobalPluginConfig(PLUGIN_NAME)).thenReturn(globalPluginConfig);
}
#method_after
@Before
public void setUp() {
    globalPluginConfig = new Config();
}
#end_block

#method_before
@Override
public void doFilter(ServletRequest req, ServletResponse res, final FilterChain chain) throws IOException, ServletException {
    if (isRest((HttpServletRequest) req)) {
        Holder rateLimiterHolder;
        CurrentUser u = user.get();
        if (u.isIdentifiedUser()) {
            Account.Id accountId = u.asIdentifiedUser().getAccountId();
            try {
                rateLimiterHolder = limitsPerAccount.get(accountId);
            } catch (ExecutionException e) {
                rateLimiterHolder = Holder.EMPTY;
                String msg = MessageFormat.format("Cannot get rate limits for account ''{0}''", accountId);
                log.warn(msg, e);
            }
        } else {
            try {
                rateLimiterHolder = limitsPerRemoteHost.get(req.getRemoteHost());
            } catch (ExecutionException e) {
                rateLimiterHolder = Holder.EMPTY;
                String msg = MessageFormat.format("Cannot get rate limits for anonymous access from remote host ''{0}''", req.getRemoteHost());
                log.warn(msg, e);
            }
        }
        if (!rateLimiterHolder.hasGracePermits() && rateLimiterHolder.get() != null && !rateLimiterHolder.get().tryAcquire()) {
            String msg = MessageFormat.format(limitExceededMsg, rateLimiterHolder.get().getRate() * SECONDS_PER_HOUR, rateLimiterHolder.getBurstPermits());
            ((HttpServletResponse) res).sendError(SC_TOO_MANY_REQUESTS, msg);
            return;
        }
    }
    chain.doFilter(req, res);
}
#method_after
@Override
public void doFilter(ServletRequest req, ServletResponse res, final FilterChain chain) throws IOException, ServletException {
    if (isRest(req)) {
        Holder rateLimiterHolder;
        CurrentUser u = user.get();
        if (u.isIdentifiedUser()) {
            Account.Id accountId = u.asIdentifiedUser().getAccountId();
            try {
                rateLimiterHolder = limitsPerAccount.get(accountId);
            } catch (ExecutionException e) {
                rateLimiterHolder = Holder.EMPTY;
                log.warn("Cannot get rate limits for account ''{}''", accountId, e);
            }
        } else {
            try {
                rateLimiterHolder = limitsPerRemoteHost.get(req.getRemoteHost());
            } catch (ExecutionException e) {
                rateLimiterHolder = Holder.EMPTY;
                log.warn("Cannot get rate limits for anonymous access from remote host ''{}''", req.getRemoteHost(), e);
            }
        }
        if (!rateLimiterHolder.hasGracePermits() && rateLimiterHolder.get() != null && !rateLimiterHolder.get().tryAcquire()) {
            String msg = MessageFormat.format(limitExceededMsg, rateLimiterHolder.get().getRate() * SECONDS_PER_HOUR, rateLimiterHolder.getBurstPermits());
            ((HttpServletResponse) res).sendError(SC_TOO_MANY_REQUESTS, msg);
            return;
        }
    }
    chain.doFilter(req, res);
}
#end_block

#method_before
boolean isRest(HttpServletRequest req) {
    String servletPath = req.getServletPath();
    return servletPath.contains("/access/") || servletPath.contains("/accounts/") || servletPath.contains("/changes/") || servletPath.contains("/config/") || servletPath.contains("/Documentation/") || servletPath.contains("/groups/") || servletPath.contains("/plugins/") || servletPath.contains("/projects/") || servletPath.contains("/tools/");
}
#method_after
boolean isRest(ServletRequest req) {
    return req instanceof HttpServletRequest && servletPath.matcher(((HttpServletRequest) req).getServletPath()).matches();
}
#end_block

#method_before
boolean execute() {
    log.atFine().log("Executing %s %s towards %s", action, key, destination);
    for (; ; ) {
        try {
            execCnt++;
            tryOnce();
            log.atFine().log("%s %s towards %s OK", action, key, destination);
            return true;
        } catch (ForwardingException e) {
            int maxTries = cfg.http().maxTries();
            log.atFine().withCause(e).log("Failed to %s %s on %s [%d/%s]", action, key, destination, execCnt, maxTries);
            if (!e.isRecoverable()) {
                log.atSevere().withCause(e).log("%s %s towards %s failed with unrecoverable error; giving up", action, key, destination);
                return false;
            }
            if (execCnt >= maxTries) {
                log.atSevere().log("Failed to %s %s on %s after %d tries; giving up", action, key, destination, maxTries);
                return false;
            }
            log.atFine().log("Retrying to %s %s on %s", action, key, destination);
            try {
                Thread.sleep(cfg.http().retryInterval());
            } catch (InterruptedException ie) {
                log.atSevere().withCause(e).log("%s %s towards %s was interrupted; giving up", action, key, destination);
                Thread.currentThread().interrupt();
                return false;
            }
        }
    }
}
#method_after
boolean execute() {
    log.atFine().log("Executing %s %s towards %s", action, key, destination);
    for (; ; ) {
        try {
            execCnt++;
            tryOnce();
            log.atFine().log("%s %s towards %s OK", action, key, destination);
            return true;
        } catch (ForwardingException e) {
            int maxTries = cfg.http().maxTries();
            log.atFine().withCause(e).log("Failed to %s %s on %s [%d/%d]", action, key, destination, execCnt, maxTries);
            if (!e.isRecoverable()) {
                log.atSevere().withCause(e).log("%s %s towards %s failed with unrecoverable error; giving up", action, key, destination);
                return false;
            }
            if (execCnt >= maxTries) {
                log.atSevere().log("Failed to %s %s on %s after %d tries; giving up", action, key, destination, maxTries);
                return false;
            }
            log.atFine().log("Retrying to %s %s on %s", action, key, destination);
            try {
                Thread.sleep(cfg.http().retryInterval());
            } catch (InterruptedException ie) {
                log.atSevere().withCause(ie).log("%s %s towards %s was interrupted; giving up", action, key, destination);
                Thread.currentThread().interrupt();
                return false;
            }
        }
    }
}
#end_block

#method_before
private void doIndex(String id, Optional<IndexEvent> indexEvent, int retryCount) throws IOException, OrmException {
    try {
        ChangeChecker checker = changeCheckerFactory.create(id);
        Optional<ChangeNotes> changeNotes = checker.getChangeNotes();
        if (changeNotes.isPresent()) {
            ChangeNotes notes = changeNotes.get();
            reindex(notes);
            if (checker.isChangeUpToDate(indexEvent)) {
                if (retryCount > 0) {
                    log.atWarning().log("Change %s has been eventually indexed after %d attempt(s)", id, retryCount);
                } else {
                    log.atFine().log("Change {} successfully indexed", id);
                }
            } else {
                log.atWarning().log("Change %s seems too old compared to the event timestamp (event-Ts=%s >> change-Ts=%s)", id, indexEvent, checker);
                rescheduleIndex(id, indexEvent, retryCount + 1);
            }
        } else {
            indexer.delete(parseChangeId(id));
            log.atWarning().log("Change %s could not be found in the local Git repository (eventTs=%s), deleted from index", id, indexEvent);
        }
    } catch (Exception e) {
        if (isCausedByNoSuchChangeException(e)) {
            indexer.delete(parseChangeId(id));
            log.atWarning().withCause(e).log("Error trying to index Change %s. Deleted from index", id);
            return;
        }
        throw e;
    }
}
#method_after
private void doIndex(String id, Optional<IndexEvent> indexEvent, int retryCount) throws IOException, OrmException {
    try {
        ChangeChecker checker = changeCheckerFactory.create(id);
        Optional<ChangeNotes> changeNotes = checker.getChangeNotes();
        if (changeNotes.isPresent()) {
            ChangeNotes notes = changeNotes.get();
            reindex(notes);
            if (checker.isChangeUpToDate(indexEvent)) {
                if (retryCount > 0) {
                    log.atWarning().log("Change %s has been eventually indexed after %d attempt(s)", id, retryCount);
                } else {
                    log.atFine().log("Change %s successfully indexed", id);
                }
            } else {
                log.atWarning().log("Change %s seems too old compared to the event timestamp (event-Ts=%s >> change-Ts=%s)", id, indexEvent, checker);
                rescheduleIndex(id, indexEvent, retryCount + 1);
            }
        } else {
            indexer.delete(parseChangeId(id));
            log.atWarning().log("Change %s could not be found in the local Git repository (eventTs=%s), deleted from index", id, indexEvent);
        }
    } catch (Exception e) {
        if (isCausedByNoSuchChangeException(e)) {
            indexer.delete(parseChangeId(id));
            log.atWarning().withCause(e).log("Error trying to index Change %s. Deleted from index", id);
            return;
        }
        throw e;
    }
}
#end_block

#method_before
@Override
public void viewAccepted(View view) {
    log.atInfo().log("viewAccepted(view: %s) called", view);
    synchronized (this) {
        if (view.getMembers().size() > 2) {
            log.atWarning().log("%d members joined the jgroups cluster %s (%s). " + " Only two members are supported. Members: {}", view.getMembers().size(), jgroupsConfig.clusterName(), channel.getName(), view.getMembers());
        }
        if (peerAddress != null && !view.getMembers().contains(peerAddress)) {
            log.atInfo().log("viewAccepted(): removed peerInfo");
            peerAddress = null;
            peerInfo = Optional.empty();
        }
    }
    if (view.size() > 1) {
        try {
            channel.send(new Message(null, myUrl));
        } catch (Exception e) {
            // channel communication caused an error. Can't do much about it.
            log.atSevere().withCause(e).log("Sending a message over channel %s to cluster %s failed", channel.getName(), jgroupsConfig.clusterName());
        }
    }
}
#method_after
@Override
public void viewAccepted(View view) {
    log.atInfo().log("viewAccepted(view: %s) called", view);
    synchronized (this) {
        if (view.getMembers().size() > 2) {
            log.atWarning().log("%d members joined the jgroups cluster %s (%s). " + " Only two members are supported. Members: %s", view.getMembers().size(), jgroupsConfig.clusterName(), channel.getName(), view.getMembers());
        }
        if (peerAddress != null && !view.getMembers().contains(peerAddress)) {
            log.atInfo().log("viewAccepted(): removed peerInfo");
            peerAddress = null;
            peerInfo = Optional.empty();
        }
    }
    if (view.size() > 1) {
        try {
            channel.send(new Message(null, myUrl));
        } catch (Exception e) {
            // channel communication caused an error. Can't do much about it.
            log.atSevere().withCause(e).log("Sending a message over channel %s to cluster %s failed", channel.getName(), jgroupsConfig.clusterName());
        }
    }
}
#end_block

#method_before
public void connect() {
    try {
        channel = getChannel();
        Optional<InetAddress> address = finder.findAddress();
        if (address.isPresent()) {
            log.atFine().log("Protocol stack: %s", channel.getProtocolStack());
            channel.getProtocolStack().getTransport().setBindAddress(address.get());
            log.atFine().log("Channel bound to {}", address.get());
        } else {
            log.atWarning().log("Channel not bound: address not present");
        }
        channel.setReceiver(this);
        channel.setDiscardOwnMessages(true);
        channel.connect(jgroupsConfig.clusterName());
        log.atInfo().log("Channel %s successfully joined jgroups cluster %s", channel.getName(), jgroupsConfig.clusterName());
    } catch (Exception e) {
        if (channel != null) {
            log.atSevere().withCause(e).log("joining cluster %s (channel %s) failed", jgroupsConfig.clusterName(), channel.getName());
        } else {
            log.atSevere().withCause(e).log("joining cluster %s failed", jgroupsConfig.clusterName());
        }
    }
}
#method_after
public void connect() {
    try {
        channel = getChannel();
        Optional<InetAddress> address = finder.findAddress();
        if (address.isPresent()) {
            log.atFine().log("Protocol stack: %s", channel.getProtocolStack());
            channel.getProtocolStack().getTransport().setBindAddress(address.get());
            log.atFine().log("Channel bound to %s", address.get());
        } else {
            log.atWarning().log("Channel not bound: address not present");
        }
        channel.setReceiver(this);
        channel.setDiscardOwnMessages(true);
        channel.connect(jgroupsConfig.clusterName());
        log.atInfo().log("Channel %s successfully joined jgroups cluster %s", channel.getName(), jgroupsConfig.clusterName());
    } catch (Exception e) {
        if (channel != null) {
            log.atSevere().withCause(e).log("joining cluster %s (channel %s) failed", jgroupsConfig.clusterName(), channel.getName());
        } else {
            log.atSevere().withCause(e).log("joining cluster %s failed", jgroupsConfig.clusterName());
        }
    }
}
#end_block

#method_before
@Override
public void run() {
    Optional<LocalDateTime> maybeIndexTs = indexTs.getUpdateTs(itemName);
    String itemNameString = itemName.name().toLowerCase();
    if (maybeIndexTs.isPresent()) {
        newLastIndexTs = maxTimestamp(newLastIndexTs, Timestamp.valueOf(maybeIndexTs.get()));
        log.atFine().log("Scanning for all the %ss after %s", itemNameString, newLastIndexTs);
        try (ManualRequestContext mctx = ctx.open();
            ReviewDb db = mctx.getReviewDbProvider().get()) {
            int count = 0;
            int errors = 0;
            Stopwatch stopwatch = Stopwatch.createStarted();
            for (T c : fetchItems(db)) {
                try {
                    Optional<Timestamp> itemTs = indexIfNeeded(db, c, newLastIndexTs);
                    if (itemTs.isPresent()) {
                        count++;
                        newLastIndexTs = maxTimestamp(newLastIndexTs, itemTs.get());
                    }
                } catch (Exception e) {
                    log.atSevere().withCause(e).log("Unable to reindex %s %s", itemNameString, c);
                    errors++;
                }
            }
            long elapsedNanos = stopwatch.stop().elapsed(TimeUnit.NANOSECONDS);
            if (count > 0) {
                log.atInfo().log("%s %ss reindexed in %d msec (%d/sec), %d failed", count, itemNameString, elapsedNanos / 1000000L, (count * 1000L) / (elapsedNanos / 1000000L), errors);
            } else if (errors > 0) {
                log.atInfo().log("%d %ss failed to reindex", errors, itemNameString);
            } else {
                log.atFine().log("Scanning finished");
            }
            indexTs.update(itemName, newLastIndexTs.toLocalDateTime());
        } catch (Exception e) {
            log.atSevere().withCause(e).log("Unable to scan %ss", itemNameString);
        }
    }
}
#method_after
@Override
public void run() {
    Optional<LocalDateTime> maybeIndexTs = indexTs.getUpdateTs(itemName);
    String itemNameString = itemName.name().toLowerCase();
    if (maybeIndexTs.isPresent()) {
        newLastIndexTs = maxTimestamp(newLastIndexTs, Timestamp.valueOf(maybeIndexTs.get()));
        log.atFine().log("Scanning for all the %ss after %s", itemNameString, newLastIndexTs);
        try (ManualRequestContext mctx = ctx.open();
            ReviewDb db = mctx.getReviewDbProvider().get()) {
            int count = 0;
            int errors = 0;
            Stopwatch stopwatch = Stopwatch.createStarted();
            for (T c : fetchItems(db)) {
                try {
                    Optional<Timestamp> itemTs = indexIfNeeded(db, c, newLastIndexTs);
                    if (itemTs.isPresent()) {
                        count++;
                        newLastIndexTs = maxTimestamp(newLastIndexTs, itemTs.get());
                    }
                } catch (Exception e) {
                    log.atSevere().withCause(e).log("Unable to reindex %s %s", itemNameString, c);
                    errors++;
                }
            }
            long elapsedNanos = stopwatch.stop().elapsed(TimeUnit.NANOSECONDS);
            if (count > 0) {
                log.atInfo().log("%d %ss reindexed in %d msec (%d/sec), %d failed", count, itemNameString, elapsedNanos / 1000000L, (count * 1000L) / (elapsedNanos / 1000000L), errors);
            } else if (errors > 0) {
                log.atInfo().log("%d %ss failed to reindex", errors, itemNameString);
            } else {
                log.atFine().log("Scanning finished");
            }
            indexTs.update(itemName, newLastIndexTs.toLocalDateTime());
        } catch (Exception e) {
            log.atSevere().withCause(e).log("Unable to scan %ss", itemNameString);
        }
    }
}
#end_block

#method_before
@Override
protected void doPost(HttpServletRequest req, HttpServletResponse rsp) {
    setHeaders(rsp);
    try {
        List<String> params = Splitter.on('/').splitToList(req.getPathInfo());
        String cacheName = params.get(CACHENAME_INDEX);
        String json = req.getReader().readLine();
        forwardedCacheEvictionHandler.evict(CacheEntry.from(cacheName, GsonParser.fromJson(cacheName, json)));
        rsp.setStatus(SC_NO_CONTENT);
    } catch (CacheNotFoundException e) {
        log.atSevere().log("Failed to process eviction request: {}", e.getMessage());
        sendError(rsp, SC_BAD_REQUEST, e.getMessage());
    } catch (IOException e) {
        log.atSevere().withCause(e).log("Failed to process eviction request");
        sendError(rsp, SC_BAD_REQUEST, e.getMessage());
    }
}
#method_after
@Override
protected void doPost(HttpServletRequest req, HttpServletResponse rsp) {
    setHeaders(rsp);
    try {
        List<String> params = Splitter.on('/').splitToList(req.getPathInfo());
        String cacheName = params.get(CACHENAME_INDEX);
        String json = req.getReader().readLine();
        forwardedCacheEvictionHandler.evict(CacheEntry.from(cacheName, GsonParser.fromJson(cacheName, json)));
        rsp.setStatus(SC_NO_CONTENT);
    } catch (CacheNotFoundException e) {
        log.atSevere().log("Failed to process eviction request: %s", e.getMessage());
        sendError(rsp, SC_BAD_REQUEST, e.getMessage());
    } catch (IOException e) {
        log.atSevere().withCause(e).log("Failed to process eviction request");
        sendError(rsp, SC_BAD_REQUEST, e.getMessage());
    }
}
#end_block

#method_before
@Override
public void run() {
    try {
        dispatcher.get().postEvent(new HeartbeatEvent());
    } catch (OrmException e) {
        logger.error("Failed to post heartbeat event: %s", e.getMessage(), e);
    }
}
#method_after
@Override
public void run() {
    try {
        dispatcher.get().postEvent(new HeartbeatEvent());
    } catch (OrmException e) {
        logger.error("Failed to post heartbeat event: {}", e.getMessage(), e);
    }
}
#end_block

#method_before
@Override
public void doFilter(ServletRequest req, ServletResponse res, final FilterChain chain) throws IOException, ServletException {
    if (isRest(req)) {
        Holder rateLimiterHolder;
        CurrentUser u = user.get();
        if (u.isIdentifiedUser()) {
            Account.Id accountId = u.asIdentifiedUser().getAccountId();
            try {
                rateLimiterHolder = limitsPerAccount.get(accountId);
            } catch (ExecutionException e) {
                rateLimiterHolder = Holder.EMPTY;
                log.warn("Cannot get rate limits for account ''{}''", accountId, e);
            }
        } else {
            try {
                rateLimiterHolder = limitsPerRemoteHost.get(req.getRemoteHost());
            } catch (ExecutionException e) {
                rateLimiterHolder = Holder.EMPTY;
                log.warn("Cannot get rate limits for anonymous access from remote host ''%s''", req.getRemoteHost(), e);
            }
        }
        if (!rateLimiterHolder.hasGracePermits() && rateLimiterHolder.get() != null && !rateLimiterHolder.get().tryAcquire()) {
            String msg = MessageFormat.format(limitExceededMsg, rateLimiterHolder.get().getRate() * SECONDS_PER_HOUR, rateLimiterHolder.getBurstPermits());
            ((HttpServletResponse) res).sendError(SC_TOO_MANY_REQUESTS, msg);
            return;
        }
    }
    chain.doFilter(req, res);
}
#method_after
@Override
public void doFilter(ServletRequest req, ServletResponse res, final FilterChain chain) throws IOException, ServletException {
    if (isRest(req)) {
        Holder rateLimiterHolder;
        CurrentUser u = user.get();
        if (u.isIdentifiedUser()) {
            Account.Id accountId = u.asIdentifiedUser().getAccountId();
            try {
                rateLimiterHolder = limitsPerAccount.get(accountId);
            } catch (ExecutionException e) {
                rateLimiterHolder = Holder.EMPTY;
                log.warn("Cannot get rate limits for account ''{}''", accountId, e);
            }
        } else {
            try {
                rateLimiterHolder = limitsPerRemoteHost.get(req.getRemoteHost());
            } catch (ExecutionException e) {
                rateLimiterHolder = Holder.EMPTY;
                log.warn("Cannot get rate limits for anonymous access from remote host ''{}''", req.getRemoteHost(), e);
            }
        }
        if (!rateLimiterHolder.hasGracePermits() && rateLimiterHolder.get() != null && !rateLimiterHolder.get().tryAcquire()) {
            String msg = MessageFormat.format(limitExceededMsg, rateLimiterHolder.get().getRate() * SECONDS_PER_HOUR, rateLimiterHolder.getBurstPermits());
            ((HttpServletResponse) res).sendError(SC_TOO_MANY_REQUESTS, msg);
            return;
        }
    }
    chain.doFilter(req, res);
}
#end_block

#method_before
@Override
public RefUpdate newUpdate(String name, boolean detach) throws IOException {
    RefUpdate refUpdate = refDatabase.newUpdate(name, detach);
    return refUpdateFactory.create(projectName, refUpdate);
}
#method_after
@Override
public RefUpdate newUpdate(String name, boolean detach) throws IOException {
    return wrapRefUpdate(refDatabase.newUpdate(name, detach));
}
#end_block

#method_before
@Override
public Map<String, Ref> exactRef(String... refs) throws IOException {
    return refDatabase.exactRef(refs);
}
#method_after
@Override
public Ref exactRef(String name) throws IOException {
    return refDatabase.exactRef(name);
}
#end_block

#method_before
@Override
public Map<String, Ref> getRefs(String prefix) throws IOException {
    return refDatabase.getRefs(prefix);
}
#method_after
@SuppressWarnings("deprecation")
@Override
public Map<String, Ref> getRefs(String prefix) throws IOException {
    return refDatabase.getRefs(prefix);
}
#end_block

#method_before
@Override
public RefDatabase getRefDatabase() {
    RefDatabase refDatabase = repository.getRefDatabase();
    return multiSiteRefDbFactory.create(projectName, refDatabase);
}
#method_after
@Override
public RefDatabase getRefDatabase() {
    return multiSiteRefDatabase;
}
#end_block

#method_before
@Override
public void create(boolean b) throws IOException {
}
#method_after
@Override
public void create() throws IOException {
    repository.create();
}
#end_block

#method_before
@Test
public void shouldInvokeMultiSiteRefDbFactoryCreate() {
    setMockitoCommon();
    MultiSiteRepository multiSiteRepository = new MultiSiteRepository(multiSiteRefDbFactory, PROJECT_NAME, repository, repositoryBuilder);
    multiSiteRepository.getRefDatabase();
    verify(multiSiteRefDbFactory).create(PROJECT_NAME, genericRefDb);
}
#method_after
@Test
public void shouldInvokeMultiSiteRefDbFactoryCreate() {
    setMockitoCommon();
    MultiSiteRepository multiSiteRepository = new MultiSiteRepository(multiSiteRefDbFactory, PROJECT_NAME, repository);
    multiSiteRepository.getRefDatabase();
    verify(multiSiteRefDbFactory).create(PROJECT_NAME, genericRefDb);
}
#end_block

#method_before
@Test
public void shouldInvokeNewUpdateInMultiSiteRefDatabase() throws IOException {
    setMockitoCommon();
    MultiSiteRepository multiSiteRepository = new MultiSiteRepository(multiSiteRefDbFactory, PROJECT_NAME, repository, repositoryBuilder);
    multiSiteRepository.getRefDatabase().newUpdate(REFS_HEADS_MASTER, false);
    verify(multiSiteRefDb).newUpdate(REFS_HEADS_MASTER, false);
}
#method_after
@Test
public void shouldInvokeNewUpdateInMultiSiteRefDatabase() throws IOException {
    setMockitoCommon();
    MultiSiteRepository multiSiteRepository = new MultiSiteRepository(multiSiteRefDbFactory, PROJECT_NAME, repository);
    multiSiteRepository.getRefDatabase().newUpdate(REFS_HEADS_MASTER, false);
    verify(multiSiteRefDb).newUpdate(REFS_HEADS_MASTER, false);
}
#end_block

#method_before
@Test
public void shouldInvokeUpdateInMultiSiteRefUpdate() throws IOException {
    setMockitoCommon();
    doReturn(Result.NEW).when(multiSiteRefUpdate).update();
    doReturn(multiSiteRefUpdate).when(multiSiteRefDb).newUpdate(REFS_HEADS_MASTER, false);
    MultiSiteRepository multiSiteRepository = new MultiSiteRepository(multiSiteRefDbFactory, PROJECT_NAME, repository, repositoryBuilder);
    Result updateResult = multiSiteRepository.getRefDatabase().newUpdate(REFS_HEADS_MASTER, false).update();
    verify(multiSiteRefUpdate).update();
    assertThat(updateResult).isEqualTo(Result.NEW);
}
#method_after
@Test
public void shouldInvokeUpdateInMultiSiteRefUpdate() throws IOException {
    setMockitoCommon();
    doReturn(Result.NEW).when(multiSiteRefUpdate).update();
    doReturn(multiSiteRefUpdate).when(multiSiteRefDb).newUpdate(REFS_HEADS_MASTER, false);
    MultiSiteRepository multiSiteRepository = new MultiSiteRepository(multiSiteRefDbFactory, PROJECT_NAME, repository);
    Result updateResult = multiSiteRepository.getRefDatabase().newUpdate(REFS_HEADS_MASTER, false).update();
    verify(multiSiteRefUpdate).update();
    assertThat(updateResult).isEqualTo(Result.NEW);
}
#end_block

#method_before
private String describeForError() {
    return checkerUuid.map(CheckerUuid::toString).orElse(ref);
}
#method_after
private String describeForError() {
    return checkerUuid.map(CheckerUuid::get).orElse(ref);
}
#end_block

#method_before
@Test
public void updateMultipleCheckerPropertiesAtOnce() throws Exception {
    CheckerUuid checkerUuid = checkerOperations.newChecker().name("my-checker").repository(allProjects).create();
    Checker checker = checkerOperations.checker(checkerUuid).get();
    Project.NameKey repositoryName = projectOperations.newProject().create();
    CheckerInput input = new CheckerInput();
    input.name = "my-renamed-checker";
    input.description = "A description.";
    input.url = "http://example.com/my-checker";
    input.repository = repositoryName.get();
    CheckerInfo info = checkersApi.id(checkerUuid).update(input);
    assertThat(info.uuid).isEqualTo(checkerUuid.toString());
    assertThat(info.name).isEqualTo(input.name);
    assertThat(info.description).isEqualTo(input.description);
    assertThat(info.url).isEqualTo(input.url);
    assertThat(info.repository).isEqualTo(input.repository);
    assertThat(info.created).isEqualTo(checker.getCreated());
    assertThat(info.created).isLessThan(info.updated);
    PerCheckerOperations perCheckerOps = checkerOperations.checker(checkerUuid);
    assertCommit(perCheckerOps.commit(), "Update checker", info.updated, perCheckerOps.get().getRefState());
    assertThat(checkerOperations.sha1sOfRepositoriesWithCheckers()).containsExactly(CheckersByRepositoryNotes.computeRepositorySha1(repositoryName));
    assertThat(checkerOperations.checkersOf(repositoryName)).containsExactly(CheckerUuid.parse(info.uuid));
}
#method_after
@Test
public void updateMultipleCheckerPropertiesAtOnce() throws Exception {
    CheckerUuid checkerUuid = checkerOperations.newChecker().name("my-checker").repository(allProjects).create();
    Checker checker = checkerOperations.checker(checkerUuid).get();
    Project.NameKey repositoryName = projectOperations.newProject().create();
    CheckerInput input = new CheckerInput();
    input.name = "my-renamed-checker";
    input.description = "A description.";
    input.url = "http://example.com/my-checker";
    input.repository = repositoryName.get();
    CheckerInfo info = checkersApi.id(checkerUuid).update(input);
    assertThat(info.uuid).isEqualTo(checkerUuid.get());
    assertThat(info.name).isEqualTo(input.name);
    assertThat(info.description).isEqualTo(input.description);
    assertThat(info.url).isEqualTo(input.url);
    assertThat(info.repository).isEqualTo(input.repository);
    assertThat(info.created).isEqualTo(checker.getCreated());
    assertThat(info.created).isLessThan(info.updated);
    PerCheckerOperations perCheckerOps = checkerOperations.checker(checkerUuid);
    assertCommit(perCheckerOps.commit(), "Update checker", info.updated, perCheckerOps.get().getRefState());
    assertThat(checkerOperations.sha1sOfRepositoriesWithCheckers()).containsExactly(CheckersByRepositoryNotes.computeRepositorySha1(repositoryName));
    assertThat(checkerOperations.checkersOf(repositoryName)).containsExactly(CheckerUuid.parse(info.uuid));
}
#end_block

#method_before
@Test
public void uuidIsAllowedIfItMatchesCurrentUuid() throws Exception {
    CheckerUuid checkerUuid = checkerOperations.newChecker().create();
    CheckerInput input = new CheckerInput();
    input.uuid = checkerUuid.toString();
    input.name = "some-name";
    CheckerInfo info = checkersApi.id(checkerUuid).update(input);
    assertThat(info.uuid).isEqualTo(input.uuid);
    assertThat(info.name).isEqualTo(input.name);
}
#method_after
@Test
public void uuidIsAllowedIfItMatchesCurrentUuid() throws Exception {
    CheckerUuid checkerUuid = checkerOperations.newChecker().create();
    CheckerInput input = new CheckerInput();
    input.uuid = checkerUuid.get();
    input.name = "some-name";
    CheckerInfo info = checkersApi.id(checkerUuid).update(input);
    assertThat(info.uuid).isEqualTo(input.uuid);
    assertThat(info.name).isEqualTo(input.name);
}
#end_block

#method_before
@Override
protected Response<?> applyImpl(BatchUpdate.Factory updateFactory, ChangeResource rsrc, Input input) throws RestApiException, UpdateException, PermissionBackendException {
    rsrc.permissions().check(ChangePermission.TOGGLE_WORK_IN_PROGRESS_STATE);
    Change change = rsrc.getChange();
    if (change.getStatus() != Status.NEW) {
        throw new ResourceConflictException("change is " + ChangeUtil.status(change));
    }
    if (!change.isWorkInProgress()) {
        throw new ResourceConflictException("change is not work in progress");
    }
    try (BatchUpdate bu = updateFactory.create(rsrc.getProject(), rsrc.getUser(), TimeUtil.nowTs())) {
        bu.addOp(rsrc.getChange().getId(), opFactory.create(false, input));
        bu.execute();
        return Response.ok("");
    }
}
#method_after
@Override
protected Response<?> applyImpl(BatchUpdate.Factory updateFactory, ChangeResource rsrc, Input input) throws RestApiException, UpdateException, PermissionBackendException {
    rsrc.permissions().check(ChangePermission.TOGGLE_WORK_IN_PROGRESS_STATE);
    Change change = rsrc.getChange();
    if (!change.isNew()) {
        throw new ResourceConflictException("change is " + ChangeUtil.status(change));
    }
    if (!change.isWorkInProgress()) {
        throw new ResourceConflictException("change is not work in progress");
    }
    try (BatchUpdate bu = updateFactory.create(rsrc.getProject(), rsrc.getUser(), TimeUtil.nowTs())) {
        bu.setNotify(NotifyResolver.Result.create(firstNonNull(input.notify, NotifyHandling.ALL)));
        bu.addOp(rsrc.getChange().getId(), opFactory.create(false, input));
        bu.execute();
        return Response.ok("");
    }
}
#end_block

#method_before
@Override
public Description getDescription(ChangeResource rsrc) {
    return new Description().setLabel("Start Review").setTitle("Set Ready For Review").setVisible(and(rsrc.getChange().getStatus() == Status.NEW && rsrc.getChange().isWorkInProgress(), rsrc.permissions().testCond(ChangePermission.TOGGLE_WORK_IN_PROGRESS_STATE)));
}
#method_after
@Override
public Description getDescription(ChangeResource rsrc) {
    return new Description().setLabel("Start Review").setTitle("Set Ready For Review").setVisible(and(rsrc.getChange().isNew() && rsrc.getChange().isWorkInProgress(), rsrc.permissions().testCond(ChangePermission.TOGGLE_WORK_IN_PROGRESS_STATE)));
}
#end_block

#method_before
@Override
protected Response<?> applyImpl(BatchUpdate.Factory updateFactory, ChangeResource rsrc, Input input) throws RestApiException, UpdateException, PermissionBackendException {
    rsrc.permissions().check(ChangePermission.TOGGLE_WORK_IN_PROGRESS_STATE);
    Change change = rsrc.getChange();
    if (change.getStatus() != Status.NEW) {
        throw new ResourceConflictException("change is " + ChangeUtil.status(change));
    }
    if (change.isWorkInProgress()) {
        throw new ResourceConflictException("change is already work in progress");
    }
    try (BatchUpdate bu = updateFactory.create(rsrc.getProject(), rsrc.getUser(), TimeUtil.nowTs())) {
        bu.addOp(rsrc.getChange().getId(), opFactory.create(true, input));
        bu.execute();
        return Response.ok("");
    }
}
#method_after
@Override
protected Response<?> applyImpl(BatchUpdate.Factory updateFactory, ChangeResource rsrc, Input input) throws RestApiException, UpdateException, PermissionBackendException {
    rsrc.permissions().check(ChangePermission.TOGGLE_WORK_IN_PROGRESS_STATE);
    Change change = rsrc.getChange();
    if (!change.isNew()) {
        throw new ResourceConflictException("change is " + ChangeUtil.status(change));
    }
    if (change.isWorkInProgress()) {
        throw new ResourceConflictException("change is already work in progress");
    }
    try (BatchUpdate bu = updateFactory.create(rsrc.getProject(), rsrc.getUser(), TimeUtil.nowTs())) {
        bu.setNotify(NotifyResolver.Result.create(firstNonNull(input.notify, NotifyHandling.NONE)));
        bu.addOp(rsrc.getChange().getId(), opFactory.create(true, input));
        bu.execute();
        return Response.ok("");
    }
}
#end_block

#method_before
@Override
public Description getDescription(ChangeResource rsrc) {
    return new Description().setLabel("WIP").setTitle("Set Work In Progress").setVisible(and(rsrc.getChange().getStatus() == Status.NEW && !rsrc.getChange().isWorkInProgress(), rsrc.permissions().testCond(ChangePermission.TOGGLE_WORK_IN_PROGRESS_STATE)));
}
#method_after
@Override
public Description getDescription(ChangeResource rsrc) {
    return new Description().setLabel("WIP").setTitle("Set Work In Progress").setVisible(and(rsrc.getChange().isNew() && !rsrc.getChange().isWorkInProgress(), rsrc.permissions().testCond(ChangePermission.TOGGLE_WORK_IN_PROGRESS_STATE)));
}
#end_block

#method_before
@Test
public void addReviewerThatIsInactive() throws Exception {
    PushOneCommit.Result result = createChange();
    String username = name("new-user");
    accountOperations.newAccount().username(username).inactive().create();
    AddReviewerInput in = new AddReviewerInput();
    in.reviewer = username;
    AddReviewerResult r = gApi.changes().id(result.getChangeId()).addReviewer(in);
    assertThat(r.input).isEqualTo(username);
    assertThat(r.error).contains("identifies an inactive account");
    assertThat(r.reviewers).isNull();
}
#method_after
@Test
public void addReviewerThatIsInactive() throws Exception {
    PushOneCommit.Result result = createChange();
    String username = name("new-user");
    Account.Id id = accountOperations.newAccount().username(username).inactive().create();
    AddReviewerInput in = new AddReviewerInput();
    in.reviewer = username;
    AddReviewerResult r = gApi.changes().id(result.getChangeId()).addReviewer(in);
    assertThat(r.input).isEqualTo(in.reviewer);
    assertThat(r.error).isEqualTo("Account '" + username + "' only matches inactive accounts. To use an inactive account, retry with one of" + " the following exact account IDs:\n" + id + ": Name of user not set (" + id + ")\n" + username + " does not identify a registered user or group");
    assertThat(r.reviewers).isNull();
}
#end_block

#method_before
@Test
public void createEmptyChange() throws Exception {
    ChangeInput in = new ChangeInput();
    in.branch = Constants.MASTER;
    in.subject = "Create a change from the API";
    in.project = project.get();
    ChangeInfo info = gApi.changes().create(in).get();
    assertThat(info.project).isEqualTo(in.project);
    assertThat(info.branch).isEqualTo(in.branch);
    assertThat(info.subject).isEqualTo(in.subject);
    assertThat(Iterables.getOnlyElement(info.messages).message).isEqualTo("Uploaded patch set 1.");
}
#method_after
@Test
public void createEmptyChange() throws Exception {
    ChangeInput in = new ChangeInput();
    in.branch = Constants.MASTER;
    in.subject = "Create a change from the API";
    in.project = project.get();
    ChangeInfo info = gApi.changes().create(in).get();
    assertThat(info.project).isEqualTo(in.project);
    assertThat(RefNames.fullName(info.branch)).isEqualTo(RefNames.fullName(in.branch));
    assertThat(info.subject).isEqualTo(in.subject);
    assertThat(Iterables.getOnlyElement(info.messages).message).isEqualTo("Uploaded patch set 1.");
}
#end_block

#method_before
@Test
public void commitFooters() throws Exception {
    LabelType verified = category("Verified", value(1, "Passes"), value(0, "No score"), value(-1, "Failed"));
    LabelType custom1 = category("Custom1", value(1, "Positive"), value(0, "No score"), value(-1, "Negative"));
    LabelType custom2 = category("Custom2", value(1, "Positive"), value(0, "No score"), value(-1, "Negative"));
    try (ProjectConfigUpdate u = updateProject(project)) {
        u.getConfig().getLabelSections().put(verified.getName(), verified);
        u.getConfig().getLabelSections().put(custom1.getName(), custom1);
        u.getConfig().getLabelSections().put(custom2.getName(), custom2);
        String heads = "refs/heads/*";
        AccountGroup.UUID anon = systemGroupBackend.getGroup(ANONYMOUS_USERS).getUUID();
        Util.allow(u.getConfig(), Permission.forLabel("Verified"), -1, 1, anon, heads);
        Util.allow(u.getConfig(), Permission.forLabel("Custom1"), -1, 1, anon, heads);
        Util.allow(u.getConfig(), Permission.forLabel("Custom2"), -1, 1, anon, heads);
        u.save();
    }
    PushOneCommit.Result r1 = createChange();
    r1.assertOkStatus();
    PushOneCommit.Result r2 = pushFactory.create(admin.getIdent(), testRepo, SUBJECT, FILE_NAME, "new content", r1.getChangeId()).to("refs/for/master");
    r2.assertOkStatus();
    ReviewInput in = new ReviewInput();
    in.label("Code-Review", 1);
    in.label("Verified", 1);
    in.label("Custom1", -1);
    in.label("Custom2", 1);
    gApi.changes().id(r2.getChangeId()).current().review(in);
    ChangeInfo actual = gApi.changes().id(r2.getChangeId()).get(ALL_REVISIONS, COMMIT_FOOTERS);
    assertThat(actual.revisions).hasSize(2);
    // No footers except on latest patch set.
    assertThat(actual.revisions.get(r1.getCommit().getName()).commitWithFooters).isNull();
    List<String> footers = new ArrayList<>(Arrays.asList(actual.revisions.get(r2.getCommit().getName()).commitWithFooters.split("\\n")));
    // remove subject + blank line
    footers.remove(0);
    footers.remove(0);
    List<String> expectedFooters = Arrays.asList("Change-Id: " + r2.getChangeId(), "Reviewed-on: " + canonicalWebUrl.get() + "c/" + r2.getChange().getId(), "Reviewed-by: Administrator <admin@example.com>", "Custom2: Administrator <admin@example.com>", "Tested-by: Administrator <admin@example.com>");
    assertThat(footers).containsExactlyElementsIn(expectedFooters);
}
#method_after
@Test
public void commitFooters() throws Exception {
    LabelType verified = category("Verified", value(1, "Passes"), value(0, "No score"), value(-1, "Failed"));
    LabelType custom1 = category("Custom1", value(1, "Positive"), value(0, "No score"), value(-1, "Negative"));
    LabelType custom2 = category("Custom2", value(1, "Positive"), value(0, "No score"), value(-1, "Negative"));
    try (ProjectConfigUpdate u = updateProject(project)) {
        u.getConfig().getLabelSections().put(verified.getName(), verified);
        u.getConfig().getLabelSections().put(custom1.getName(), custom1);
        u.getConfig().getLabelSections().put(custom2.getName(), custom2);
        String heads = "refs/heads/*";
        AccountGroup.UUID anon = systemGroupBackend.getGroup(ANONYMOUS_USERS).getUUID();
        Util.allow(u.getConfig(), Permission.forLabel("Verified"), -1, 1, anon, heads);
        Util.allow(u.getConfig(), Permission.forLabel("Custom1"), -1, 1, anon, heads);
        Util.allow(u.getConfig(), Permission.forLabel("Custom2"), -1, 1, anon, heads);
        u.save();
    }
    PushOneCommit.Result r1 = createChange();
    r1.assertOkStatus();
    PushOneCommit.Result r2 = pushFactory.create(admin.getIdent(), testRepo, SUBJECT, FILE_NAME, "new content", r1.getChangeId()).to("refs/for/master");
    r2.assertOkStatus();
    ReviewInput in = new ReviewInput();
    in.label("Code-Review", 1);
    in.label("Verified", 1);
    in.label("Custom1", -1);
    in.label("Custom2", 1);
    gApi.changes().id(r2.getChangeId()).current().review(in);
    ChangeInfo actual = gApi.changes().id(r2.getChangeId()).get(ALL_REVISIONS, COMMIT_FOOTERS);
    assertThat(actual.revisions).hasSize(2);
    // No footers except on latest patch set.
    assertThat(actual.revisions.get(r1.getCommit().getName()).commitWithFooters).isNull();
    List<String> footers = new ArrayList<>(Arrays.asList(actual.revisions.get(r2.getCommit().getName()).commitWithFooters.split("\\n")));
    // remove subject + blank line
    footers.remove(0);
    footers.remove(0);
    List<String> expectedFooters = Arrays.asList("Change-Id: " + r2.getChangeId(), "Reviewed-on: " + canonicalWebUrl.get() + "c/" + project.get() + "/+/" + r2.getChange().getId(), "Reviewed-by: Administrator <admin@example.com>", "Custom2: Administrator <admin@example.com>", "Tested-by: Administrator <admin@example.com>");
    assertThat(footers).containsExactlyElementsIn(expectedFooters);
}
#end_block

#method_before
@Test
public void customCommitFooters() throws Exception {
    PushOneCommit.Result change = createChange();
    RegistrationHandle handle = changeMessageModifiers.add("gerrit", (newCommitMessage, original, mergeTip, destination) -> {
        assertThat(original.getName()).isNotEqualTo(mergeTip.getName());
        return newCommitMessage + "Custom: " + destination.get();
    });
    ChangeInfo actual;
    try {
        actual = gApi.changes().id(change.getChangeId()).get(ALL_REVISIONS, COMMIT_FOOTERS);
    } finally {
        handle.remove();
    }
    List<String> footers = new ArrayList<>(Arrays.asList(actual.revisions.get(change.getCommit().getName()).commitWithFooters.split("\\n")));
    // remove subject + blank line
    footers.remove(0);
    footers.remove(0);
    List<String> expectedFooters = Arrays.asList("Change-Id: " + change.getChangeId(), "Reviewed-on: " + canonicalWebUrl.get() + "c/" + change.getChange().getId(), "Custom: refs/heads/master");
    assertThat(footers).containsExactlyElementsIn(expectedFooters);
}
#method_after
@Test
public void customCommitFooters() throws Exception {
    PushOneCommit.Result change = createChange();
    RegistrationHandle handle = changeMessageModifiers.add("gerrit", (newCommitMessage, original, mergeTip, destination) -> {
        assertThat(original.getName()).isNotEqualTo(mergeTip.getName());
        return newCommitMessage + "Custom: " + destination.get();
    });
    ChangeInfo actual;
    try {
        actual = gApi.changes().id(change.getChangeId()).get(ALL_REVISIONS, COMMIT_FOOTERS);
    } finally {
        handle.remove();
    }
    List<String> footers = new ArrayList<>(Arrays.asList(actual.revisions.get(change.getCommit().getName()).commitWithFooters.split("\\n")));
    // remove subject + blank line
    footers.remove(0);
    footers.remove(0);
    List<String> expectedFooters = Arrays.asList("Change-Id: " + change.getChangeId(), "Reviewed-on: " + canonicalWebUrl.get() + "c/" + project.get() + "/+/" + change.getChange().getId(), "Custom: refs/heads/master");
    assertThat(footers).containsExactlyElementsIn(expectedFooters);
}
#end_block

#method_before
@Test
public void createEmptyChangeOnNonExistingBranch() throws Exception {
    ChangeInput in = new ChangeInput();
    in.branch = "foo";
    in.subject = "Create a change on new branch from the API";
    in.project = project.get();
    in.newBranch = true;
    ChangeInfo info = gApi.changes().create(in).get();
    assertThat(info.project).isEqualTo(in.project);
    assertThat(info.branch).isEqualTo(in.branch);
    assertThat(info.subject).isEqualTo(in.subject);
    assertThat(Iterables.getOnlyElement(info.messages).message).isEqualTo("Uploaded patch set 1.");
}
#method_after
@Test
public void createEmptyChangeOnNonExistingBranch() throws Exception {
    ChangeInput in = new ChangeInput();
    in.branch = "foo";
    in.subject = "Create a change on new branch from the API";
    in.project = project.get();
    in.newBranch = true;
    ChangeInfo info = gApi.changes().create(in).get();
    assertThat(info.project).isEqualTo(in.project);
    assertThat(RefNames.fullName(info.branch)).isEqualTo(RefNames.fullName(in.branch));
    assertThat(info.subject).isEqualTo(in.subject);
    assertThat(Iterables.getOnlyElement(info.messages).message).isEqualTo("Uploaded patch set 1.");
}
#end_block

#method_before
@Test
public void ignore() throws Exception {
    String email = "user2@example.com";
    String fullname = "User2";
    accountOperations.newAccount().username("user2").preferredEmail(email).fullname(fullname).create();
    PushOneCommit.Result r = createChange();
    AddReviewerInput in = new AddReviewerInput();
    in.reviewer = user.email;
    gApi.changes().id(r.getChangeId()).addReviewer(in);
    in = new AddReviewerInput();
    in.reviewer = email;
    gApi.changes().id(r.getChangeId()).addReviewer(in);
    requestScopeOperations.setApiUser(user.getId());
    gApi.changes().id(r.getChangeId()).ignore(true);
    assertThat(gApi.changes().id(r.getChangeId()).ignored()).isTrue();
    sender.clear();
    requestScopeOperations.setApiUser(admin.getId());
    gApi.changes().id(r.getChangeId()).abandon();
    List<Message> messages = sender.getMessages();
    assertThat(messages).hasSize(1);
    assertThat(messages.get(0).rcpt()).containsExactly(new Address(fullname, email));
    requestScopeOperations.setApiUser(user.getId());
    gApi.changes().id(r.getChangeId()).ignore(false);
    assertThat(gApi.changes().id(r.getChangeId()).ignored()).isFalse();
}
#method_after
@Test
public void ignore() throws Exception {
    String email = "user2@example.com";
    String fullname = "User2";
    accountOperations.newAccount().username("user2").preferredEmail(email).fullname(fullname).create();
    PushOneCommit.Result r = createChange();
    AddReviewerInput in = new AddReviewerInput();
    in.reviewer = user.email;
    gApi.changes().id(r.getChangeId()).addReviewer(in);
    in = new AddReviewerInput();
    in.reviewer = email;
    gApi.changes().id(r.getChangeId()).addReviewer(in);
    requestScopeOperations.setApiUser(user.getId());
    gApi.changes().id(r.getChangeId()).ignore(true);
    assertThat(gApi.changes().id(r.getChangeId()).ignored()).isTrue();
    // New patch set notification is not sent to users ignoring the change
    sender.clear();
    requestScopeOperations.setApiUser(admin.getId());
    amendChange(r.getChangeId());
    List<Message> messages = sender.getMessages();
    assertThat(messages).hasSize(1);
    Address address = new Address(fullname, email);
    assertThat(messages.get(0).rcpt()).containsExactly(address);
    // Review notification is not sent to users ignoring the change
    sender.clear();
    gApi.changes().id(r.getChangeId()).current().review(ReviewInput.approve());
    messages = sender.getMessages();
    assertThat(messages).hasSize(1);
    assertThat(messages.get(0).rcpt()).containsExactly(address);
    // Abandoned notification is not sent to users ignoring the change
    sender.clear();
    gApi.changes().id(r.getChangeId()).abandon();
    messages = sender.getMessages();
    assertThat(messages).hasSize(1);
    assertThat(messages.get(0).rcpt()).containsExactly(address);
    requestScopeOperations.setApiUser(user.getId());
    gApi.changes().id(r.getChangeId()).ignore(false);
    assertThat(gApi.changes().id(r.getChangeId()).ignored()).isFalse();
}
#end_block

#method_before
@Override
public void postUpdate(Context ctx) {
    stateChanged.fire(change, ps, ctx.getAccount(), ctx.getWhen());
    if (workInProgress || notify.ordinal() < NotifyHandling.OWNER_REVIEWERS.ordinal()) {
        return;
    }
    email.create(notify, ImmutableListMultimap.of(), notes, ps, ctx.getIdentifiedUser(), cmsg, ImmutableList.of(), cmsg.getMessage(), ImmutableList.of()).sendAsync();
}
#method_after
@Override
public void postUpdate(Context ctx) {
    stateChanged.fire(change, ps, ctx.getAccount(), ctx.getWhen());
    NotifyResolver.Result notify = ctx.getNotify(change.getId());
    if (workInProgress || notify.handling().compareTo(NotifyHandling.OWNER_REVIEWERS) < 0 || !sendEmail) {
        return;
    }
    email.create(notify, notes, ps, ctx.getIdentifiedUser(), cmsg, ImmutableList.of(), cmsg.getMessage(), ImmutableList.of()).sendAsync();
}
#end_block

#method_before
public Response<ReviewResult> apply(BatchUpdate.Factory updateFactory, RevisionResource revision, ReviewInput input, Timestamp ts) throws RestApiException, UpdateException, OrmException, IOException, PermissionBackendException, ConfigInvalidException, PatchListNotAvailableException {
    // Respect timestamp, but truncate at change created-on time.
    ts = Ordering.natural().max(ts, revision.getChange().getCreatedOn());
    if (revision.getEdit().isPresent()) {
        throw new ResourceConflictException("cannot post review on edit");
    }
    ProjectState projectState = projectCache.checkedGet(revision.getProject());
    LabelTypes labelTypes = projectState.getLabelTypes(revision.getNotes());
    input.drafts = firstNonNull(input.drafts, DraftHandling.KEEP);
    if (input.onBehalfOf != null) {
        revision = onBehalfOf(revision, labelTypes, input);
    }
    if (input.labels != null) {
        checkLabels(revision, labelTypes, input.labels);
    }
    if (input.comments != null) {
        cleanUpComments(input.comments);
        checkComments(revision, input.comments);
    }
    if (input.robotComments != null) {
        checkRobotComments(revision, input.robotComments);
    }
    NotifyHandling reviewerNotify = input.notify;
    if (input.notify == null) {
        input.notify = defaultNotify(revision.getChange(), input);
    }
    ListMultimap<RecipientType, Account.Id> accountsToNotify = notifyUtil.resolveAccounts(input.notifyDetails);
    Map<String, AddReviewerResult> reviewerJsonResults = null;
    List<ReviewerAddition> reviewerResults = Lists.newArrayList();
    boolean hasError = false;
    boolean confirm = false;
    if (input.reviewers != null) {
        reviewerJsonResults = Maps.newHashMap();
        for (AddReviewerInput reviewerInput : input.reviewers) {
            // Prevent individual AddReviewersOps from sending one email each. Instead, we call
            // batchEmailReviewers at the very end to send out a single email.
            // TODO(dborowitz): I think this still sends out separate emails if any of input.reviewers
            // specifies explicit accountsToNotify. Unclear whether that's a good thing.
            reviewerInput.notify = NotifyHandling.NONE;
            ReviewerAddition result = reviewerAdder.prepare(revision.getNotes(), revision.getUser(), reviewerInput, true);
            reviewerJsonResults.put(reviewerInput.reviewer, result.result);
            if (result.result.error != null) {
                hasError = true;
                continue;
            }
            if (result.result.confirm != null) {
                confirm = true;
                continue;
            }
            reviewerResults.add(result);
        }
    }
    ReviewResult output = new ReviewResult();
    output.reviewers = reviewerJsonResults;
    if (hasError || confirm) {
        output.error = ERROR_ADDING_REVIEWER;
        return Response.withStatusCode(SC_BAD_REQUEST, output);
    }
    output.labels = input.labels;
    try (BatchUpdate bu = updateFactory.create(revision.getChange().getProject(), revision.getUser(), ts)) {
        Account.Id id = revision.getUser().getAccountId();
        boolean ccOrReviewer = false;
        if (input.labels != null && !input.labels.isEmpty()) {
            ccOrReviewer = input.labels.values().stream().filter(v -> v != 0).findFirst().isPresent();
        }
        if (!ccOrReviewer) {
            // Check if user was already CCed or reviewing prior to this review.
            ReviewerSet currentReviewers = approvalsUtil.getReviewers(revision.getChangeResource().getNotes());
            ccOrReviewer = currentReviewers.all().contains(id);
        }
        // themselves as a reviewer or to the CC list.
        for (ReviewerAddition reviewerResult : reviewerResults) {
            bu.addOp(revision.getChange().getId(), reviewerResult.op);
            if (!ccOrReviewer && reviewerResult.result.reviewers != null) {
                for (ReviewerInfo reviewerInfo : reviewerResult.result.reviewers) {
                    if (Objects.equals(id.get(), reviewerInfo._accountId)) {
                        ccOrReviewer = true;
                        break;
                    }
                }
            }
            if (!ccOrReviewer && reviewerResult.result.ccs != null) {
                for (AccountInfo accountInfo : reviewerResult.result.ccs) {
                    if (Objects.equals(id.get(), accountInfo._accountId)) {
                        ccOrReviewer = true;
                        break;
                    }
                }
            }
        }
        if (!ccOrReviewer) {
            // User posting this review isn't currently in the reviewer or CC list,
            // isn't being explicitly added, and isn't voting on any label.
            // Automatically CC them on this change so they receive replies.
            ReviewerAddition selfAddition = reviewerAdder.ccCurrentUser(revision.getUser(), revision);
            bu.addOp(revision.getChange().getId(), selfAddition.op);
        }
        // Add WorkInProgressOp if requested.
        if (input.ready || input.workInProgress) {
            if (input.ready && input.workInProgress) {
                output.error = ERROR_WIP_READY_MUTUALLY_EXCLUSIVE;
                return Response.withStatusCode(SC_BAD_REQUEST, output);
            }
            revision.getChangeResource().permissions().check(ChangePermission.TOGGLE_WORK_IN_PROGRESS_STATE);
            if (input.ready) {
                output.ready = true;
            }
            // Suppress notifications in WorkInProgressOp, we'll take care of
            // them in this endpoint.
            WorkInProgressOp.Input wipIn = new WorkInProgressOp.Input();
            wipIn.notify = NotifyHandling.NONE;
            bu.addOp(revision.getChange().getId(), workInProgressOpFactory.create(input.workInProgress, wipIn));
        }
        // Add the review op.
        bu.addOp(revision.getChange().getId(), new Op(projectState, revision.getPatchSet().getId(), input, accountsToNotify));
        bu.execute();
        // Re-read change to take into account results of the update.
        ChangeData cd = changeDataFactory.create(revision.getProject(), revision.getChange().getId());
        for (ReviewerAddition reviewerResult : reviewerResults) {
            reviewerResult.gatherResults(cd);
        }
        boolean readyForReview = (output.ready != null && output.ready) || !revision.getChange().isWorkInProgress();
        // Sending from AddReviewersOp was suppressed so we can send a single batch email here.
        batchEmailReviewers(revision.getUser(), revision.getChange(), reviewerResults, reviewerNotify, accountsToNotify, readyForReview);
    }
    return Response.ok(output);
}
#method_after
public Response<ReviewResult> apply(BatchUpdate.Factory updateFactory, RevisionResource revision, ReviewInput input, Timestamp ts) throws RestApiException, UpdateException, OrmException, IOException, PermissionBackendException, ConfigInvalidException, PatchListNotAvailableException {
    // Respect timestamp, but truncate at change created-on time.
    ts = Ordering.natural().max(ts, revision.getChange().getCreatedOn());
    if (revision.getEdit().isPresent()) {
        throw new ResourceConflictException("cannot post review on edit");
    }
    ProjectState projectState = projectCache.checkedGet(revision.getProject());
    LabelTypes labelTypes = projectState.getLabelTypes(revision.getNotes());
    input.drafts = firstNonNull(input.drafts, DraftHandling.KEEP);
    if (input.onBehalfOf != null) {
        revision = onBehalfOf(revision, labelTypes, input);
    }
    if (input.labels != null) {
        checkLabels(revision, labelTypes, input.labels);
    }
    if (input.comments != null) {
        cleanUpComments(input.comments);
        checkComments(revision, input.comments);
    }
    if (input.robotComments != null) {
        checkRobotComments(revision, input.robotComments);
    }
    if (input.notify == null) {
        input.notify = defaultNotify(revision.getChange(), input);
    }
    Map<String, AddReviewerResult> reviewerJsonResults = null;
    List<ReviewerAddition> reviewerResults = Lists.newArrayList();
    boolean hasError = false;
    boolean confirm = false;
    if (input.reviewers != null) {
        reviewerJsonResults = Maps.newHashMap();
        for (AddReviewerInput reviewerInput : input.reviewers) {
            ReviewerAddition result = reviewerAdder.prepare(revision.getNotes(), revision.getUser(), reviewerInput, true);
            reviewerJsonResults.put(reviewerInput.reviewer, result.result);
            if (result.result.error != null) {
                hasError = true;
                continue;
            }
            if (result.result.confirm != null) {
                confirm = true;
                continue;
            }
            reviewerResults.add(result);
        }
    }
    ReviewResult output = new ReviewResult();
    output.reviewers = reviewerJsonResults;
    if (hasError || confirm) {
        output.error = ERROR_ADDING_REVIEWER;
        return Response.withStatusCode(SC_BAD_REQUEST, output);
    }
    output.labels = input.labels;
    try (BatchUpdate bu = updateFactory.create(revision.getChange().getProject(), revision.getUser(), ts)) {
        Account.Id id = revision.getUser().getAccountId();
        boolean ccOrReviewer = false;
        if (input.labels != null && !input.labels.isEmpty()) {
            ccOrReviewer = input.labels.values().stream().filter(v -> v != 0).findFirst().isPresent();
        }
        if (!ccOrReviewer) {
            // Check if user was already CCed or reviewing prior to this review.
            ReviewerSet currentReviewers = approvalsUtil.getReviewers(revision.getChangeResource().getNotes());
            ccOrReviewer = currentReviewers.all().contains(id);
        }
        // themselves as a reviewer or to the CC list.
        for (ReviewerAddition reviewerResult : reviewerResults) {
            // Send a single batch email below.
            reviewerResult.op.suppressEmail();
            bu.addOp(revision.getChange().getId(), reviewerResult.op);
            if (!ccOrReviewer && reviewerResult.result.reviewers != null) {
                for (ReviewerInfo reviewerInfo : reviewerResult.result.reviewers) {
                    if (Objects.equals(id.get(), reviewerInfo._accountId)) {
                        ccOrReviewer = true;
                        break;
                    }
                }
            }
            if (!ccOrReviewer && reviewerResult.result.ccs != null) {
                for (AccountInfo accountInfo : reviewerResult.result.ccs) {
                    if (Objects.equals(id.get(), accountInfo._accountId)) {
                        ccOrReviewer = true;
                        break;
                    }
                }
            }
        }
        if (!ccOrReviewer) {
            // User posting this review isn't currently in the reviewer or CC list,
            // isn't being explicitly added, and isn't voting on any label.
            // Automatically CC them on this change so they receive replies.
            ReviewerAddition selfAddition = reviewerAdder.ccCurrentUser(revision.getUser(), revision);
            selfAddition.op.suppressEmail();
            bu.addOp(revision.getChange().getId(), selfAddition.op);
        }
        // Add WorkInProgressOp if requested.
        if (input.ready || input.workInProgress) {
            if (input.ready && input.workInProgress) {
                output.error = ERROR_WIP_READY_MUTUALLY_EXCLUSIVE;
                return Response.withStatusCode(SC_BAD_REQUEST, output);
            }
            revision.getChangeResource().permissions().check(ChangePermission.TOGGLE_WORK_IN_PROGRESS_STATE);
            if (input.ready) {
                output.ready = true;
            }
            WorkInProgressOp wipOp = workInProgressOpFactory.create(input.workInProgress, new WorkInProgressOp.Input());
            wipOp.suppressEmail();
            bu.addOp(revision.getChange().getId(), wipOp);
        }
        // Add the review op.
        bu.addOp(revision.getChange().getId(), new Op(projectState, revision.getPatchSet().getId(), input));
        // Notify based on ReviewInput, ignoring the notify settings from any AddReviewerInputs.
        NotifyResolver.Result notify = notifyResolver.resolve(getNotifyHandling(input, output, revision), input.notifyDetails);
        bu.setNotify(notify);
        bu.execute();
        // Re-read change to take into account results of the update.
        ChangeData cd = changeDataFactory.create(revision.getProject(), revision.getChange().getId());
        for (ReviewerAddition reviewerResult : reviewerResults) {
            reviewerResult.gatherResults(cd);
        }
        // Sending from AddReviewersOp was suppressed so we can send a single batch email here.
        batchEmailReviewers(revision.getUser(), revision.getChange(), reviewerResults, notify);
    }
    return Response.ok(output);
}
#end_block

#method_before
private NotifyHandling defaultNotify(Change c, ReviewInput in) {
    boolean workInProgress = c.isWorkInProgress();
    if (in.workInProgress) {
        workInProgress = true;
    }
    if (in.ready) {
        workInProgress = false;
    }
    if (ChangeMessagesUtil.isAutogenerated(in.tag)) {
        // Autogenerated comments default to lower notify levels.
        return workInProgress ? NotifyHandling.OWNER : NotifyHandling.OWNER_REVIEWERS;
    }
    if (workInProgress && !c.hasReviewStarted()) {
        // the author is.
        return NotifyHandling.OWNER;
    }
    return NotifyHandling.ALL;
}
#method_after
private NotifyHandling defaultNotify(Change c, ReviewInput in) {
    boolean workInProgress = c.isWorkInProgress();
    if (in.workInProgress) {
        workInProgress = true;
    }
    if (in.ready) {
        workInProgress = false;
    }
    if (ChangeMessagesUtil.isAutogenerated(in.tag)) {
        // Autogenerated comments default to lower notify levels.
        return workInProgress ? NotifyHandling.OWNER : NotifyHandling.OWNER_REVIEWERS;
    }
    if (workInProgress && !c.hasReviewStarted()) {
        // If review hasn't started we want to eliminate notifications, no matter who the author is.
        return NotifyHandling.NONE;
    }
    // everyone.
    return NotifyHandling.ALL;
}
#end_block

#method_before
private void batchEmailReviewers(CurrentUser user, Change change, List<ReviewerAddition> reviewerAdditions, @Nullable NotifyHandling notify, ListMultimap<RecipientType, Account.Id> accountsToNotify, boolean readyForReview) {
    List<Account.Id> to = new ArrayList<>();
    List<Account.Id> cc = new ArrayList<>();
    List<Address> toByEmail = new ArrayList<>();
    List<Address> ccByEmail = new ArrayList<>();
    for (ReviewerAddition addition : reviewerAdditions) {
        if (addition.state() == ReviewerState.REVIEWER) {
            to.addAll(addition.reviewers);
            toByEmail.addAll(addition.reviewersByEmail);
        } else if (addition.state() == ReviewerState.CC) {
            cc.addAll(addition.reviewers);
            ccByEmail.addAll(addition.reviewersByEmail);
        }
    }
    addReviewersEmail.emailReviewers(user.asIdentifiedUser(), change, to, cc, toByEmail, ccByEmail, notify, accountsToNotify, readyForReview);
}
#method_after
private void batchEmailReviewers(CurrentUser user, Change change, List<ReviewerAddition> reviewerAdditions, NotifyResolver.Result notify) {
    List<Account.Id> to = new ArrayList<>();
    List<Account.Id> cc = new ArrayList<>();
    List<Address> toByEmail = new ArrayList<>();
    List<Address> ccByEmail = new ArrayList<>();
    for (ReviewerAddition addition : reviewerAdditions) {
        if (addition.state() == ReviewerState.REVIEWER) {
            to.addAll(addition.reviewers);
            toByEmail.addAll(addition.reviewersByEmail);
        } else if (addition.state() == ReviewerState.CC) {
            cc.addAll(addition.reviewers);
            ccByEmail.addAll(addition.reviewersByEmail);
        }
    }
    addReviewersEmail.emailReviewers(user.asIdentifiedUser(), change, to, cc, toByEmail, ccByEmail, notify);
}
#end_block

#method_before
private RevisionResource onBehalfOf(RevisionResource rev, LabelTypes labelTypes, ReviewInput in) throws BadRequestException, AuthException, UnprocessableEntityException, OrmException, PermissionBackendException, IOException, ConfigInvalidException {
    if (in.labels == null || in.labels.isEmpty()) {
        throw new AuthException(String.format("label required to post review on behalf of \"%s\"", in.onBehalfOf));
    }
    if (in.drafts != DraftHandling.KEEP) {
        throw new AuthException("not allowed to modify other user's drafts");
    }
    CurrentUser caller = rev.getUser();
    PermissionBackend.ForChange perm = rev.permissions();
    Iterator<Map.Entry<String, Short>> itr = in.labels.entrySet().iterator();
    while (itr.hasNext()) {
        Map.Entry<String, Short> ent = itr.next();
        LabelType type = labelTypes.byLabel(ent.getKey());
        if (type == null) {
            if (strictLabels) {
                throw new BadRequestException(String.format("label \"%s\" is not a configured label", ent.getKey()));
            }
            itr.remove();
            continue;
        }
        if (!caller.isInternalUser()) {
            try {
                perm.check(new LabelPermission.WithValue(ON_BEHALF_OF, type, ent.getValue()));
            } catch (AuthException e) {
                throw new AuthException(String.format("not permitted to modify label \"%s\" on behalf of \"%s\"", type.getName(), in.onBehalfOf));
            }
        }
    }
    if (in.labels.isEmpty()) {
        throw new AuthException(String.format("label required to post review on behalf of \"%s\"", in.onBehalfOf));
    }
    IdentifiedUser reviewer = accountResolver.parseOnBehalfOf(caller, in.onBehalfOf);
    try {
        permissionBackend.user(reviewer).change(rev.getNotes()).check(ChangePermission.READ);
    } catch (AuthException e) {
        throw new UnprocessableEntityException(String.format("on_behalf_of account %s cannot see change", reviewer.getAccountId()));
    }
    return new RevisionResource(changeResourceFactory.create(rev.getNotes(), reviewer), rev.getPatchSet());
}
#method_after
private RevisionResource onBehalfOf(RevisionResource rev, LabelTypes labelTypes, ReviewInput in) throws BadRequestException, AuthException, UnprocessableEntityException, OrmException, PermissionBackendException, IOException, ConfigInvalidException {
    if (in.labels == null || in.labels.isEmpty()) {
        throw new AuthException(String.format("label required to post review on behalf of \"%s\"", in.onBehalfOf));
    }
    if (in.drafts != DraftHandling.KEEP) {
        throw new AuthException("not allowed to modify other user's drafts");
    }
    CurrentUser caller = rev.getUser();
    PermissionBackend.ForChange perm = rev.permissions();
    Iterator<Map.Entry<String, Short>> itr = in.labels.entrySet().iterator();
    while (itr.hasNext()) {
        Map.Entry<String, Short> ent = itr.next();
        LabelType type = labelTypes.byLabel(ent.getKey());
        if (type == null) {
            if (strictLabels) {
                throw new BadRequestException(String.format("label \"%s\" is not a configured label", ent.getKey()));
            }
            itr.remove();
            continue;
        }
        if (!caller.isInternalUser()) {
            try {
                perm.check(new LabelPermission.WithValue(ON_BEHALF_OF, type, ent.getValue()));
            } catch (AuthException e) {
                throw new AuthException(String.format("not permitted to modify label \"%s\" on behalf of \"%s\"", type.getName(), in.onBehalfOf));
            }
        }
    }
    if (in.labels.isEmpty()) {
        throw new AuthException(String.format("label required to post review on behalf of \"%s\"", in.onBehalfOf));
    }
    IdentifiedUser reviewer = accountResolver.resolve(in.onBehalfOf).asUniqueUserOnBehalfOf(caller);
    try {
        permissionBackend.user(reviewer).change(rev.getNotes()).check(ChangePermission.READ);
    } catch (AuthException e) {
        throw new UnprocessableEntityException(String.format("on_behalf_of account %s cannot see change", reviewer.getAccountId()));
    }
    return new RevisionResource(changeResourceFactory.create(rev.getNotes(), reviewer), rev.getPatchSet());
}
#end_block

#method_before
@Override
public void postUpdate(Context ctx) throws OrmException {
    if (message == null) {
        return;
    }
    if (in.notify.compareTo(NotifyHandling.NONE) > 0 || !accountsToNotify.isEmpty()) {
        email.create(in.notify, accountsToNotify, notes, ps, user, message, comments, in.message, labelDelta).sendAsync();
    }
    commentAdded.fire(notes.getChange(), ps, user.state(), message.getMessage(), approvals, oldApprovals, ctx.getWhen());
}
#method_after
@Override
public void postUpdate(Context ctx) throws OrmException {
    if (message == null) {
        return;
    }
    NotifyResolver.Result notify = ctx.getNotify(notes.getChangeId());
    if (notify.shouldNotify()) {
        email.create(notify, notes, ps, user, message, comments, in.message, labelDelta).sendAsync();
    }
    commentAdded.fire(notes.getChange(), ps, user.state(), message.getMessage(), approvals, oldApprovals, ctx.getWhen());
}
#end_block

#method_before
private boolean updateLabels(ProjectState projectState, ChangeContext ctx) throws OrmException, ResourceConflictException, IOException {
    Map<String, Short> inLabels = firstNonNull(in.labels, Collections.emptyMap());
    // losing access to a label after the change was submitted.
    if (inLabels.isEmpty() && ctx.getChange().getStatus().isClosed()) {
        return false;
    }
    List<PatchSetApproval> del = new ArrayList<>();
    List<PatchSetApproval> ups = new ArrayList<>();
    Map<String, PatchSetApproval> current = scanLabels(projectState, ctx, del);
    LabelTypes labelTypes = projectState.getLabelTypes(ctx.getNotes());
    Map<String, Short> allApprovals = getAllApprovals(labelTypes, approvalsByKey(current.values()), inLabels);
    Map<String, Short> previous = getPreviousApprovals(allApprovals, approvalsByKey(current.values()));
    ChangeUpdate update = ctx.getUpdate(psId);
    for (Map.Entry<String, Short> ent : allApprovals.entrySet()) {
        String name = ent.getKey();
        LabelType lt = requireNonNull(labelTypes.byLabel(name), name);
        PatchSetApproval c = current.remove(lt.getName());
        String normName = lt.getName();
        approvals.put(normName, (short) 0);
        if (ent.getValue() == null || ent.getValue() == 0) {
            // User requested delete of this label.
            oldApprovals.put(normName, null);
            if (c != null) {
                if (c.getValue() != 0) {
                    addLabelDelta(normName, (short) 0);
                    oldApprovals.put(normName, previous.get(normName));
                }
                del.add(c);
                update.putApproval(normName, (short) 0);
            }
        } else if (c != null && c.getValue() != ent.getValue()) {
            c.setValue(ent.getValue());
            c.setGranted(ctx.getWhen());
            c.setTag(in.tag);
            ctx.getUser().updateRealAccountId(c::setRealAccountId);
            ups.add(c);
            addLabelDelta(normName, c.getValue());
            oldApprovals.put(normName, previous.get(normName));
            approvals.put(normName, c.getValue());
            update.putApproval(normName, ent.getValue());
        } else if (c != null && c.getValue() == ent.getValue()) {
            current.put(normName, c);
            oldApprovals.put(normName, null);
            approvals.put(normName, c.getValue());
        } else if (c == null) {
            c = ApprovalsUtil.newApproval(psId, user, lt.getLabelId(), ent.getValue(), ctx.getWhen());
            c.setTag(in.tag);
            c.setGranted(ctx.getWhen());
            ups.add(c);
            addLabelDelta(normName, c.getValue());
            oldApprovals.put(normName, previous.get(normName));
            approvals.put(normName, c.getValue());
            update.putReviewer(user.getAccountId(), REVIEWER);
            update.putApproval(normName, ent.getValue());
        }
    }
    validatePostSubmitLabels(ctx, labelTypes, previous, ups, del);
    // This allows us to preserve their CC status.
    if (current.isEmpty() && del.isEmpty() && ups.isEmpty() && !isReviewer(ctx)) {
        return false;
    }
    forceCallerAsReviewer(projectState, ctx, current, ups, del);
    return !del.isEmpty() || !ups.isEmpty();
}
#method_after
private boolean updateLabels(ProjectState projectState, ChangeContext ctx) throws OrmException, ResourceConflictException, IOException {
    Map<String, Short> inLabels = firstNonNull(in.labels, Collections.emptyMap());
    // losing access to a label after the change was submitted.
    if (inLabels.isEmpty() && ctx.getChange().isClosed()) {
        return false;
    }
    List<PatchSetApproval> del = new ArrayList<>();
    List<PatchSetApproval> ups = new ArrayList<>();
    Map<String, PatchSetApproval> current = scanLabels(projectState, ctx, del);
    LabelTypes labelTypes = projectState.getLabelTypes(ctx.getNotes());
    Map<String, Short> allApprovals = getAllApprovals(labelTypes, approvalsByKey(current.values()), inLabels);
    Map<String, Short> previous = getPreviousApprovals(allApprovals, approvalsByKey(current.values()));
    ChangeUpdate update = ctx.getUpdate(psId);
    for (Map.Entry<String, Short> ent : allApprovals.entrySet()) {
        String name = ent.getKey();
        LabelType lt = requireNonNull(labelTypes.byLabel(name), name);
        PatchSetApproval c = current.remove(lt.getName());
        String normName = lt.getName();
        approvals.put(normName, (short) 0);
        if (ent.getValue() == null || ent.getValue() == 0) {
            // User requested delete of this label.
            oldApprovals.put(normName, null);
            if (c != null) {
                if (c.getValue() != 0) {
                    addLabelDelta(normName, (short) 0);
                    oldApprovals.put(normName, previous.get(normName));
                }
                del.add(c);
                update.putApproval(normName, (short) 0);
            }
        } else if (c != null && c.getValue() != ent.getValue()) {
            c.setValue(ent.getValue());
            c.setGranted(ctx.getWhen());
            c.setTag(in.tag);
            ctx.getUser().updateRealAccountId(c::setRealAccountId);
            ups.add(c);
            addLabelDelta(normName, c.getValue());
            oldApprovals.put(normName, previous.get(normName));
            approvals.put(normName, c.getValue());
            update.putApproval(normName, ent.getValue());
        } else if (c != null && c.getValue() == ent.getValue()) {
            current.put(normName, c);
            oldApprovals.put(normName, null);
            approvals.put(normName, c.getValue());
        } else if (c == null) {
            c = ApprovalsUtil.newApproval(psId, user, lt.getLabelId(), ent.getValue(), ctx.getWhen());
            c.setTag(in.tag);
            c.setGranted(ctx.getWhen());
            ups.add(c);
            addLabelDelta(normName, c.getValue());
            oldApprovals.put(normName, previous.get(normName));
            approvals.put(normName, c.getValue());
            update.putReviewer(user.getAccountId(), REVIEWER);
            update.putApproval(normName, ent.getValue());
        }
    }
    validatePostSubmitLabels(ctx, labelTypes, previous, ups, del);
    // This allows us to preserve their CC status.
    if (current.isEmpty() && del.isEmpty() && ups.isEmpty() && !isReviewer(ctx)) {
        return false;
    }
    forceCallerAsReviewer(projectState, ctx, current, ups, del);
    return !del.isEmpty() || !ups.isEmpty();
}
#end_block

#method_before
private void validatePostSubmitLabels(ChangeContext ctx, LabelTypes labelTypes, Map<String, Short> previous, List<PatchSetApproval> ups, List<PatchSetApproval> del) throws ResourceConflictException {
    if (ctx.getChange().getStatus().isOpen()) {
        // Not closed, nothing to validate.
        return;
    } else if (del.isEmpty() && ups.isEmpty()) {
        // No new votes.
        return;
    } else if (ctx.getChange().getStatus() != Change.Status.MERGED) {
        throw new ResourceConflictException("change is closed");
    }
    // Disallow reducing votes on any labels post-submit. This assumes the
    // high values were broadly necessary to submit, so reducing them would
    // make it possible to take a merged change and make it no longer
    // submittable.
    List<PatchSetApproval> reduced = new ArrayList<>(ups.size() + del.size());
    List<String> disallowed = new ArrayList<>(labelTypes.getLabelTypes().size());
    for (PatchSetApproval psa : del) {
        LabelType lt = requireNonNull(labelTypes.byLabel(psa.getLabel()));
        String normName = lt.getName();
        if (!lt.allowPostSubmit()) {
            disallowed.add(normName);
        }
        Short prev = previous.get(normName);
        if (prev != null && prev != 0) {
            reduced.add(psa);
        }
    }
    for (PatchSetApproval psa : ups) {
        LabelType lt = requireNonNull(labelTypes.byLabel(psa.getLabel()));
        String normName = lt.getName();
        if (!lt.allowPostSubmit()) {
            disallowed.add(normName);
        }
        Short prev = previous.get(normName);
        if (prev == null) {
            continue;
        }
        // Should be filtered out above.
        checkState(prev != psa.getValue());
        if (prev > psa.getValue()) {
            reduced.add(psa);
        }
    // No need to set postSubmit bit, which is set automatically when parsing from NoteDb.
    }
    if (!disallowed.isEmpty()) {
        throw new ResourceConflictException("Voting on labels disallowed after submit: " + disallowed.stream().distinct().sorted().collect(joining(", ")));
    }
    if (!reduced.isEmpty()) {
        throw new ResourceConflictException("Cannot reduce vote on labels for closed change: " + reduced.stream().map(PatchSetApproval::getLabel).distinct().sorted().collect(joining(", ")));
    }
}
#method_after
private void validatePostSubmitLabels(ChangeContext ctx, LabelTypes labelTypes, Map<String, Short> previous, List<PatchSetApproval> ups, List<PatchSetApproval> del) throws ResourceConflictException {
    if (ctx.getChange().isNew()) {
        // Not closed, nothing to validate.
        return;
    } else if (del.isEmpty() && ups.isEmpty()) {
        // No new votes.
        return;
    } else if (!ctx.getChange().isMerged()) {
        throw new ResourceConflictException("change is closed");
    }
    // Disallow reducing votes on any labels post-submit. This assumes the
    // high values were broadly necessary to submit, so reducing them would
    // make it possible to take a merged change and make it no longer
    // submittable.
    List<PatchSetApproval> reduced = new ArrayList<>(ups.size() + del.size());
    List<String> disallowed = new ArrayList<>(labelTypes.getLabelTypes().size());
    for (PatchSetApproval psa : del) {
        LabelType lt = requireNonNull(labelTypes.byLabel(psa.getLabel()));
        String normName = lt.getName();
        if (!lt.allowPostSubmit()) {
            disallowed.add(normName);
        }
        Short prev = previous.get(normName);
        if (prev != null && prev != 0) {
            reduced.add(psa);
        }
    }
    for (PatchSetApproval psa : ups) {
        LabelType lt = requireNonNull(labelTypes.byLabel(psa.getLabel()));
        String normName = lt.getName();
        if (!lt.allowPostSubmit()) {
            disallowed.add(normName);
        }
        Short prev = previous.get(normName);
        if (prev == null) {
            continue;
        }
        // Should be filtered out above.
        checkState(prev != psa.getValue());
        if (prev > psa.getValue()) {
            reduced.add(psa);
        }
    // No need to set postSubmit bit, which is set automatically when parsing from NoteDb.
    }
    if (!disallowed.isEmpty()) {
        throw new ResourceConflictException("Voting on labels disallowed after submit: " + disallowed.stream().distinct().sorted().collect(joining(", ")));
    }
    if (!reduced.isEmpty()) {
        throw new ResourceConflictException("Cannot reduce vote on labels for closed change: " + reduced.stream().map(PatchSetApproval::getLabel).distinct().sorted().collect(joining(", ")));
    }
}
#end_block

#method_before
private boolean canEditTopicName() {
    if (getChange().getStatus().isOpen()) {
        return // owner (aka creator) of the change can edit topic
        isOwner() || // branch owner can edit topic
        refControl.isOwner() || // project owner can edit topic
        getProjectControl().isOwner() || refControl.canPerform(// user can edit topic on a specific ref
        Permission.EDIT_TOPIC_NAME) || getProjectControl().isAdmin();
    }
    return refControl.canForceEditTopicName();
}
#method_after
private boolean canEditTopicName() {
    if (getChange().isNew()) {
        return // owner (aka creator) of the change can edit topic
        isOwner() || // branch owner can edit topic
        refControl.isOwner() || // project owner can edit topic
        getProjectControl().isOwner() || refControl.canPerform(// user can edit topic on a specific ref
        Permission.EDIT_TOPIC_NAME) || getProjectControl().isAdmin();
    }
    return refControl.canForceEditTopicName();
}
#end_block

#method_before
private boolean canEditDescription() {
    if (getChange().getStatus().isOpen()) {
        return // owner (aka creator) of the change can edit desc
        isOwner() || // branch owner can edit desc
        refControl.isOwner() || // project owner can edit desc
        getProjectControl().isOwner() || getProjectControl().isAdmin();
    }
    return false;
}
#method_after
private boolean canEditDescription() {
    if (getChange().isNew()) {
        return // owner (aka creator) of the change can edit desc
        isOwner() || // branch owner can edit desc
        refControl.isOwner() || // project owner can edit desc
        getProjectControl().isOwner() || getProjectControl().isAdmin();
    }
    return false;
}
#end_block

#method_before
@Override
public List<String> queryChangeEvents(String query) throws EventsLogException {
    if (!online) {
        throw new ServiceUnavailableException();
    }
    List<SQLEntry> entries = new ArrayList<>();
    for (Entry<String, Collection<SQLEntry>> entry : eventsDb.getEvents(query).asMap().entrySet()) {
        String projectName = entry.getKey();
        try {
            permissionBackend.currentUser().project(new Project.NameKey(projectName)).check(ProjectPermission.ACCESS);
            entries.addAll(entry.getValue());
        } catch (AuthException e) {
        // Ignore
        } catch (PermissionBackendException e) {
            log.atFine().withCause(e).log("Cannot check project access permission");
        }
    }
    return entries.stream().sorted().map(SQLEntry::getEvent).collect(toList());
}
#method_after
@Override
public List<String> queryChangeEvents(String query) throws EventsLogException {
    if (!online) {
        throw new ServiceUnavailableException();
    }
    List<SQLEntry> entries = new ArrayList<>();
    for (Entry<String, Collection<SQLEntry>> entry : eventsDb.getEvents(query).asMap().entrySet()) {
        String projectName = entry.getKey();
        try {
            permissionBackend.currentUser().project(new Project.NameKey(projectName)).check(ProjectPermission.ACCESS);
            entries.addAll(entry.getValue());
        } catch (AuthException e) {
        // Ignore
        } catch (PermissionBackendException e) {
            log.atWarning().withCause(e).log("Cannot check project access permission");
        }
    }
    return entries.stream().sorted().map(SQLEntry::getEvent).collect(toList());
}
#end_block

#method_before
@Nullable
public Boolean isPureRevert() throws OrmException {
    if (change().getRevertOf() == null) {
        return null;
    }
    try {
        return pureRevertCache.isPureRevert(notes());
    } catch (IOException | BadRequestException e) {
        throw new OrmException("could not compute pure revert", e);
    }
}
#method_after
@Nullable
public Boolean isPureRevert() throws OrmException {
    if (change().getRevertOf() == null) {
        return null;
    }
    try {
        return pureRevert.get(notes(), Optional.empty());
    } catch (IOException | BadRequestException | ResourceConflictException e) {
        throw new OrmException("could not compute pure revert", e);
    }
}
#end_block

#method_before
public boolean isPureRevert(ChangeNotes claimedRevert) throws OrmException, IOException, BadRequestException {
    if (claimedRevert.getChange().getRevertOf() == null) {
        throw new BadRequestException("revertOf not set");
    }
    PatchSet ps = psUtil.current(notesFactory.createChecked(claimedRevert.getProjectName(), claimedRevert.getChange().getRevertOf()));
    return isPureRevert(claimedRevert.getProjectName(), ObjectId.fromString(claimedRevert.getCurrentPatchSet().getRevision().get()), ObjectId.fromString(ps.getRevision().get()));
}
#method_after
public boolean isPureRevert(ChangeNotes claimedRevert) throws OrmException, IOException, BadRequestException {
    if (claimedRevert.getChange().getRevertOf() == null) {
        throw new BadRequestException("revertOf not set");
    }
    ChangeNotes claimedOriginal = notesFactory.createChecked(claimedRevert.getProjectName(), claimedRevert.getChange().getRevertOf());
    return isPureRevert(claimedRevert.getProjectName(), ObjectId.fromString(claimedRevert.getCurrentPatchSet().getRevision().get()), ObjectId.fromString(claimedOriginal.getCurrentPatchSet().getRevision().get()));
}
#end_block

#method_before
public boolean isPureRevert(Project.NameKey project, ObjectId claimedRevert, ObjectId claimedOriginal) throws IOException, BadRequestException {
    ByteString original = ObjectIdConverter.create().toByteString(claimedOriginal);
    ByteString revert = ObjectIdConverter.create().toByteString(claimedRevert);
    try {
        return cache.get(PureRevertKeyProto.newBuilder().setProject(project.get()).setClaimedOriginal(original).setClaimedRevert(revert).build());
    } catch (ExecutionException e) {
        Throwables.throwIfInstanceOf(e.getCause(), BadRequestException.class);
        throw new IOException(e);
    }
}
#method_after
public boolean isPureRevert(Project.NameKey project, ObjectId claimedRevert, ObjectId claimedOriginal) throws IOException, BadRequestException {
    try {
        return cache.get(key(project, claimedRevert, claimedOriginal));
    } catch (ExecutionException e) {
        Throwables.throwIfInstanceOf(e.getCause(), BadRequestException.class);
        throw new IOException(e);
    }
}
#end_block

#method_before
@Override
public Boolean load(PureRevertKeyProto key) throws BadRequestException, IOException {
    try (TraceContext.TraceTimer ignored = TraceContext.newTimer("Loading pure revert for %s", key)) {
        ObjectId original = ObjectIdConverter.create().fromByteString(key.getClaimedOriginal());
        ObjectId revert = ObjectIdConverter.create().fromByteString(key.getClaimedRevert());
        Project.NameKey project = new Project.NameKey(key.getProject());
        try (Repository repo = repoManager.openRepository(project);
            ObjectInserter oi = repo.newObjectInserter();
            RevWalk rw = new RevWalk(repo)) {
            RevCommit claimedOriginalCommit;
            try {
                claimedOriginalCommit = rw.parseCommit(original);
            } catch (InvalidObjectIdException | MissingObjectException e) {
                throw new BadRequestException("invalid object ID");
            }
            if (claimedOriginalCommit.getParentCount() == 0) {
                throw new BadRequestException("can't check against initial commit");
            }
            RevCommit claimedRevertCommit = rw.parseCommit(revert);
            if (claimedRevertCommit.getParentCount() == 0) {
                throw new BadRequestException("claimed revert has no parents");
            }
            // Rebase claimed revert onto claimed original
            ThreeWayMerger merger = mergeUtilFactory.create(projectCache.checkedGet(project)).newThreeWayMerger(oi, repo.getConfig());
            merger.setBase(claimedRevertCommit.getParent(0));
            boolean success = merger.merge(claimedRevertCommit, claimedOriginalCommit);
            if (!success || merger.getResultTreeId() == null) {
                // Merge conflict during rebase
                return false;
            }
            // claimedRevert is not a pure revert but made content changes
            try (DiffFormatter df = new DiffFormatter(new ByteArrayOutputStream())) {
                df.setReader(oi.newReader(), repo.getConfig());
                List<DiffEntry> entries = df.scan(claimedOriginalCommit.getParent(0), merger.getResultTreeId());
                return entries.isEmpty();
            }
        }
    }
}
#method_after
@Override
public Boolean load(PureRevertKeyProto key) throws BadRequestException, IOException {
    try (TraceContext.TraceTimer ignored = TraceContext.newTimer("Loading pure revert for %s", key)) {
        ObjectId original = ObjectIdConverter.create().fromByteString(key.getClaimedOriginal());
        ObjectId revert = ObjectIdConverter.create().fromByteString(key.getClaimedRevert());
        Project.NameKey project = new Project.NameKey(key.getProject());
        try (Repository repo = repoManager.openRepository(project);
            ObjectInserter oi = repo.newObjectInserter();
            RevWalk rw = new RevWalk(repo)) {
            RevCommit claimedOriginalCommit;
            try {
                claimedOriginalCommit = rw.parseCommit(original);
            } catch (InvalidObjectIdException | MissingObjectException e) {
                throw new BadRequestException("invalid object ID");
            }
            if (claimedOriginalCommit.getParentCount() == 0) {
                throw new BadRequestException("can't check against initial commit");
            }
            RevCommit claimedRevertCommit = rw.parseCommit(revert);
            if (claimedRevertCommit.getParentCount() == 0) {
                return false;
            }
            // Rebase claimed revert onto claimed original
            ThreeWayMerger merger = mergeUtilFactory.create(projectCache.checkedGet(project)).newThreeWayMerger(oi, repo.getConfig());
            merger.setBase(claimedRevertCommit.getParent(0));
            boolean success = merger.merge(claimedRevertCommit, claimedOriginalCommit);
            if (!success || merger.getResultTreeId() == null) {
                // Merge conflict during rebase
                return false;
            }
            // claimedRevert is not a pure revert but made content changes
            try (DiffFormatter df = new DiffFormatter(new ByteArrayOutputStream())) {
                df.setReader(oi.newReader(), repo.getConfig());
                List<DiffEntry> entries = df.scan(claimedOriginalCommit.getParent(0), merger.getResultTreeId());
                return entries.isEmpty();
            }
        }
    }
}
#end_block

#method_before
public PureRevertInfo get(ChangeNotes notes, @Nullable String claimedOriginal) throws OrmException, IOException, BadRequestException, ResourceConflictException {
    PatchSet currentPatchSet = notes.getCurrentPatchSet();
    if (currentPatchSet == null) {
        throw new ResourceConflictException("current revision is missing");
    }
    if (claimedOriginal == null) {
        return new PureRevertInfo(pureRevertCache.isPureRevert(notes));
    }
    ObjectId claimedOriginalObjectId;
    try {
        claimedOriginalObjectId = ObjectId.fromString(claimedOriginal);
    } catch (InvalidObjectIdException e) {
        throw new BadRequestException("invalid object ID");
    }
    Boolean result = pureRevertCache.isPureRevert(notes.getProjectName(), ObjectId.fromString(notes.getCurrentPatchSet().getRevision().get()), claimedOriginalObjectId);
    return new PureRevertInfo(result);
}
#method_after
public boolean get(ChangeNotes notes, Optional<String> claimedOriginal) throws OrmException, IOException, BadRequestException, ResourceConflictException {
    PatchSet currentPatchSet = notes.getCurrentPatchSet();
    if (currentPatchSet == null) {
        throw new ResourceConflictException("current revision is missing");
    }
    if (!claimedOriginal.isPresent()) {
        return pureRevertCache.isPureRevert(notes);
    }
    ObjectId claimedOriginalObjectId;
    try {
        claimedOriginalObjectId = ObjectId.fromString(claimedOriginal.get());
    } catch (InvalidObjectIdException e) {
        throw new BadRequestException("invalid object ID");
    }
    return pureRevertCache.isPureRevert(notes.getProjectName(), ObjectId.fromString(notes.getCurrentPatchSet().getRevision().get()), claimedOriginalObjectId);
}
#end_block

#method_before
@SuppressWarnings("rawtypes")
@Override
protected void configure() {
    install(new DiffExecutorModule());
    install(new SysExecutorModule());
    install(BatchUpdate.module());
    install(PatchListCacheImpl.module());
    install(new DefaultUrlFormatter.Module());
    // There is the concept of LifecycleModule, in Gerrit's own extension to Guice, which has these:
    // listener().to(SomeClassImplementingLifecycleListener.class);
    // and the start() methods of each such listener are executed in the order they are declared.
    // Makes sure that PluginLoader.start() is executed before the LuceneIndexModule.start() so that
    // plugins get loaded and the respective Guice modules installed so that the on-line reindexing
    // will happen with the proper classes (e.g. group backends, custom Prolog predicates) and the
    // associated rules ready to be evaluated.
    install(new PluginModule());
    // We're just running through each change
    // once, so don't worry about cache removal.
    bind(new TypeLiteral<DynamicSet<CacheRemovalListener>>() {
    }).toInstance(DynamicSet.emptySet());
    bind(new TypeLiteral<DynamicMap<Cache<?, ?>>>() {
    }).toInstance(DynamicMap.emptyMap());
    bind(new TypeLiteral<List<CommentLinkInfo>>() {
    }).toProvider(CommentLinkProvider.class).in(SINGLETON);
    bind(new TypeLiteral<DynamicMap<ChangeQueryProcessor.ChangeAttributeFactory>>() {
    }).toInstance(DynamicMap.emptyMap());
    bind(new TypeLiteral<DynamicMap<RestView<CommitResource>>>() {
    }).toInstance(DynamicMap.emptyMap());
    bind(String.class).annotatedWith(CanonicalWebUrl.class).toProvider(CanonicalWebUrlProvider.class);
    bind(Boolean.class).annotatedWith(DisableReverseDnsLookup.class).toProvider(DisableReverseDnsLookupProvider.class).in(SINGLETON);
    bind(Realm.class).to(FakeRealm.class);
    bind(IdentifiedUser.class).toProvider(Providers.of(null));
    bind(ReplacePatchSetSender.Factory.class).toProvider(Providers.of(null));
    bind(CurrentUser.class).to(IdentifiedUser.class);
    factory(MergeUtil.Factory.class);
    factory(PatchSetInserter.Factory.class);
    factory(RebaseChangeOp.Factory.class);
    // As Reindex is a batch program, don't assume the index is available for
    // the change cache.
    bind(SearchingChangeCacheImpl.class).toProvider(Providers.of(null));
    bind(new TypeLiteral<ImmutableSet<GroupReference>>() {
    }).annotatedWith(AdministrateServerGroups.class).toInstance(ImmutableSet.of());
    bind(new TypeLiteral<Set<AccountGroup.UUID>>() {
    }).annotatedWith(GitUploadPackGroups.class).toInstance(Collections.emptySet());
    bind(new TypeLiteral<Set<AccountGroup.UUID>>() {
    }).annotatedWith(GitReceivePackGroups.class).toInstance(Collections.emptySet());
    install(new BatchGitModule());
    install(new DefaultPermissionBackendModule());
    install(new DefaultMemoryCacheModule());
    install(new H2CacheModule());
    install(new ExternalIdModule());
    install(new GroupModule());
    install(new NoteDbModule());
    install(AccountCacheImpl.module());
    install(GroupCacheImpl.module());
    install(GroupIncludeCacheImpl.module());
    install(ProjectCacheImpl.module());
    install(SectionSortCache.module());
    install(ChangeKindCacheImpl.module());
    install(MergeabilityCacheImpl.module());
    install(TagCache.module());
    install(new PureRevertCache.Module());
    factory(CapabilityCollection.Factory.class);
    factory(ChangeData.AssistedFactory.class);
    factory(ProjectState.Factory.class);
    // Submit rules
    DynamicSet.setOf(binder(), SubmitRule.class);
    factory(SubmitRuleEvaluator.Factory.class);
    install(new PrologModule());
    install(new DefaultSubmitRule.Module());
    install(new IgnoreSelfApprovalRule.Module());
    bind(ChangeJson.Factory.class).toProvider(Providers.of(null));
    bind(EventUtil.class).toProvider(Providers.of(null));
    bind(GitReferenceUpdated.class).toInstance(GitReferenceUpdated.DISABLED);
    bind(RevisionCreated.class).toInstance(RevisionCreated.DISABLED);
    bind(AccountVisibility.class).toProvider(AccountVisibilityProvider.class).in(SINGLETON);
}
#method_after
@SuppressWarnings("rawtypes")
@Override
protected void configure() {
    install(new DiffExecutorModule());
    install(new SysExecutorModule());
    install(BatchUpdate.module());
    install(PatchListCacheImpl.module());
    install(new DefaultUrlFormatter.Module());
    // There is the concept of LifecycleModule, in Gerrit's own extension to Guice, which has these:
    // listener().to(SomeClassImplementingLifecycleListener.class);
    // and the start() methods of each such listener are executed in the order they are declared.
    // Makes sure that PluginLoader.start() is executed before the LuceneIndexModule.start() so that
    // plugins get loaded and the respective Guice modules installed so that the on-line reindexing
    // will happen with the proper classes (e.g. group backends, custom Prolog predicates) and the
    // associated rules ready to be evaluated.
    install(new PluginModule());
    // We're just running through each change
    // once, so don't worry about cache removal.
    bind(new TypeLiteral<DynamicSet<CacheRemovalListener>>() {
    }).toInstance(DynamicSet.emptySet());
    bind(new TypeLiteral<DynamicMap<Cache<?, ?>>>() {
    }).toInstance(DynamicMap.emptyMap());
    bind(new TypeLiteral<List<CommentLinkInfo>>() {
    }).toProvider(CommentLinkProvider.class).in(SINGLETON);
    bind(new TypeLiteral<DynamicSet<ChangeAttributeFactory>>() {
    }).toInstance(DynamicSet.emptySet());
    bind(new TypeLiteral<DynamicMap<RestView<CommitResource>>>() {
    }).toInstance(DynamicMap.emptyMap());
    bind(String.class).annotatedWith(CanonicalWebUrl.class).toProvider(CanonicalWebUrlProvider.class);
    bind(Boolean.class).annotatedWith(EnableReverseDnsLookup.class).toProvider(EnableReverseDnsLookupProvider.class).in(SINGLETON);
    bind(Realm.class).to(FakeRealm.class);
    bind(IdentifiedUser.class).toProvider(Providers.of(null));
    bind(ReplacePatchSetSender.Factory.class).toProvider(Providers.of(null));
    bind(CurrentUser.class).to(IdentifiedUser.class);
    factory(MergeUtil.Factory.class);
    factory(PatchSetInserter.Factory.class);
    factory(RebaseChangeOp.Factory.class);
    // As Reindex is a batch program, don't assume the index is available for
    // the change cache.
    bind(SearchingChangeCacheImpl.class).toProvider(Providers.of(null));
    bind(new TypeLiteral<ImmutableSet<GroupReference>>() {
    }).annotatedWith(AdministrateServerGroups.class).toInstance(ImmutableSet.of());
    bind(new TypeLiteral<Set<AccountGroup.UUID>>() {
    }).annotatedWith(GitUploadPackGroups.class).toInstance(Collections.emptySet());
    bind(new TypeLiteral<Set<AccountGroup.UUID>>() {
    }).annotatedWith(GitReceivePackGroups.class).toInstance(Collections.emptySet());
    install(new BatchGitModule());
    install(new DefaultPermissionBackendModule());
    install(new DefaultMemoryCacheModule());
    install(new H2CacheModule());
    install(new ExternalIdModule());
    install(new GroupModule());
    install(new NoteDbModule());
    install(AccountCacheImpl.module());
    install(GroupCacheImpl.module());
    install(GroupIncludeCacheImpl.module());
    install(ProjectCacheImpl.module());
    install(SectionSortCache.module());
    install(ChangeKindCacheImpl.module());
    install(MergeabilityCacheImpl.module());
    install(TagCache.module());
    install(PureRevertCache.module());
    factory(CapabilityCollection.Factory.class);
    factory(ChangeData.AssistedFactory.class);
    factory(ProjectState.Factory.class);
    // Submit rules
    DynamicSet.setOf(binder(), SubmitRule.class);
    factory(SubmitRuleEvaluator.Factory.class);
    install(new PrologModule());
    install(new DefaultSubmitRule.Module());
    install(new IgnoreSelfApprovalRule.Module());
    bind(ChangeJson.Factory.class).toProvider(Providers.of(null));
    bind(EventUtil.class).toProvider(Providers.of(null));
    bind(GitReferenceUpdated.class).toInstance(GitReferenceUpdated.DISABLED);
    bind(RevisionCreated.class).toInstance(RevisionCreated.DISABLED);
    bind(AccountVisibility.class).toProvider(AccountVisibilityProvider.class).in(SINGLETON);
}
#end_block

#method_before
@Test
public void setWorkInProgressNotAllowedWithoutPermission() throws Exception {
    PushOneCommit.Result rwip = createChange();
    String changeId = rwip.getChangeId();
    requestScopeOperations.setApiUser(user.getId());
    exception.expect(AuthException.class);
    exception.expectMessage("not allowed to toggle work in progress");
    gApi.changes().id(changeId).setWorkInProgress();
}
#method_after
@Test
public void setWorkInProgressNotAllowedWithoutPermission() throws Exception {
    PushOneCommit.Result rwip = createChange();
    String changeId = rwip.getChangeId();
    requestScopeOperations.setApiUser(user.getId());
    exception.expect(AuthException.class);
    exception.expectMessage("toggle work in progress state not permitted");
    gApi.changes().id(changeId).setWorkInProgress();
}
#end_block

#method_before
@Test
public void setReadyForReviewNotAllowedWithoutPermission() throws Exception {
    PushOneCommit.Result rready = createChange();
    String changeId = rready.getChangeId();
    gApi.changes().id(changeId).setWorkInProgress();
    requestScopeOperations.setApiUser(user.getId());
    exception.expect(AuthException.class);
    exception.expectMessage("not allowed to toggle work in progress");
    gApi.changes().id(changeId).setReadyForReview();
}
#method_after
@Test
public void setReadyForReviewNotAllowedWithoutPermission() throws Exception {
    PushOneCommit.Result rready = createChange();
    String changeId = rready.getChangeId();
    gApi.changes().id(changeId).setWorkInProgress();
    requestScopeOperations.setApiUser(user.getId());
    exception.expect(AuthException.class);
    exception.expectMessage("toggle work in progress state not permitted");
    gApi.changes().id(changeId).setReadyForReview();
}
#end_block

#method_before
@Test
public void reviewWithWorkInProgressByNonOwnerReturnsError() throws Exception {
    PushOneCommit.Result r = createChange();
    ReviewInput in = ReviewInput.noScore().setWorkInProgress(true);
    requestScopeOperations.setApiUser(user.getId());
    exception.expect(AuthException.class);
    exception.expectMessage("not allowed to toggle work in progress");
    gApi.changes().id(r.getChangeId()).current().review(in);
}
#method_after
@Test
public void reviewWithWorkInProgressByNonOwnerReturnsError() throws Exception {
    PushOneCommit.Result r = createChange();
    ReviewInput in = ReviewInput.noScore().setWorkInProgress(true);
    requestScopeOperations.setApiUser(user.getId());
    exception.expect(AuthException.class);
    exception.expectMessage("toggle work in progress state not permitted");
    gApi.changes().id(r.getChangeId()).current().review(in);
}
#end_block

#method_before
@Test
public void reviewWithReadyByNonOwnerReturnsError() throws Exception {
    PushOneCommit.Result r = createChange();
    ReviewInput in = ReviewInput.noScore().setReady(true);
    requestScopeOperations.setApiUser(user.getId());
    exception.expect(AuthException.class);
    exception.expectMessage("not allowed to toggle work in progress");
    gApi.changes().id(r.getChangeId()).current().review(in);
}
#method_after
@Test
public void reviewWithReadyByNonOwnerReturnsError() throws Exception {
    PushOneCommit.Result r = createChange();
    ReviewInput in = ReviewInput.noScore().setReady(true);
    requestScopeOperations.setApiUser(user.getId());
    exception.expect(AuthException.class);
    exception.expectMessage("toggle work in progress state not permitted");
    gApi.changes().id(r.getChangeId()).current().review(in);
}
#end_block

#method_before
@Test
public void commitFooters() throws Exception {
    LabelType verified = category("Verified", value(1, "Passes"), value(0, "No score"), value(-1, "Failed"));
    LabelType custom1 = category("Custom1", value(1, "Positive"), value(0, "No score"), value(-1, "Negative"));
    LabelType custom2 = category("Custom2", value(1, "Positive"), value(0, "No score"), value(-1, "Negative"));
    try (ProjectConfigUpdate u = updateProject(project)) {
        u.getConfig().getLabelSections().put(verified.getName(), verified);
        u.getConfig().getLabelSections().put(custom1.getName(), custom1);
        u.getConfig().getLabelSections().put(custom2.getName(), custom2);
        String heads = "refs/heads/*";
        AccountGroup.UUID anon = systemGroupBackend.getGroup(ANONYMOUS_USERS).getUUID();
        Util.allow(u.getConfig(), Permission.forLabel("Verified"), -1, 1, anon, heads);
        Util.allow(u.getConfig(), Permission.forLabel("Custom1"), -1, 1, anon, heads);
        Util.allow(u.getConfig(), Permission.forLabel("Custom2"), -1, 1, anon, heads);
        u.save();
    }
    PushOneCommit.Result r1 = createChange();
    r1.assertOkStatus();
    PushOneCommit.Result r2 = pushFactory.create(admin.getIdent(), testRepo, SUBJECT, FILE_NAME, "new content", r1.getChangeId()).to("refs/for/master");
    r2.assertOkStatus();
    ReviewInput in = new ReviewInput();
    in.label("Code-Review", 1);
    in.label("Verified", 1);
    in.label("Custom1", -1);
    in.label("Custom2", 1);
    gApi.changes().id(r2.getChangeId()).current().review(in);
    ChangeInfo actual = gApi.changes().id(r2.getChangeId()).get(ALL_REVISIONS, COMMIT_FOOTERS);
    assertThat(actual.revisions).hasSize(2);
    // No footers except on latest patch set.
    assertThat(actual.revisions.get(r1.getCommit().getName()).commitWithFooters).isNull();
    List<String> footers = new ArrayList<>(Arrays.asList(actual.revisions.get(r2.getCommit().getName()).commitWithFooters.split("\\n")));
    // remove subject + blank line
    footers.remove(0);
    footers.remove(0);
    List<String> expectedFooters = Arrays.asList("Change-Id: " + r2.getChangeId(), "Reviewed-on: " + canonicalWebUrl.get() + "c/" + r2.getChange().getId(), "Reviewed-by: Administrator <admin@example.com>", "Custom2: Administrator <admin@example.com>", "Tested-by: Administrator <admin@example.com>");
    assertThat(footers).containsExactlyElementsIn(expectedFooters);
}
#method_after
@Test
public void commitFooters() throws Exception {
    LabelType verified = category("Verified", value(1, "Passes"), value(0, "No score"), value(-1, "Failed"));
    LabelType custom1 = category("Custom1", value(1, "Positive"), value(0, "No score"), value(-1, "Negative"));
    LabelType custom2 = category("Custom2", value(1, "Positive"), value(0, "No score"), value(-1, "Negative"));
    try (ProjectConfigUpdate u = updateProject(project)) {
        u.getConfig().getLabelSections().put(verified.getName(), verified);
        u.getConfig().getLabelSections().put(custom1.getName(), custom1);
        u.getConfig().getLabelSections().put(custom2.getName(), custom2);
        String heads = "refs/heads/*";
        AccountGroup.UUID anon = systemGroupBackend.getGroup(ANONYMOUS_USERS).getUUID();
        Util.allow(u.getConfig(), Permission.forLabel("Verified"), -1, 1, anon, heads);
        Util.allow(u.getConfig(), Permission.forLabel("Custom1"), -1, 1, anon, heads);
        Util.allow(u.getConfig(), Permission.forLabel("Custom2"), -1, 1, anon, heads);
        u.save();
    }
    PushOneCommit.Result r1 = createChange();
    r1.assertOkStatus();
    PushOneCommit.Result r2 = pushFactory.create(admin.getIdent(), testRepo, SUBJECT, FILE_NAME, "new content", r1.getChangeId()).to("refs/for/master");
    r2.assertOkStatus();
    ReviewInput in = new ReviewInput();
    in.label("Code-Review", 1);
    in.label("Verified", 1);
    in.label("Custom1", -1);
    in.label("Custom2", 1);
    gApi.changes().id(r2.getChangeId()).current().review(in);
    ChangeInfo actual = gApi.changes().id(r2.getChangeId()).get(ALL_REVISIONS, COMMIT_FOOTERS);
    assertThat(actual.revisions).hasSize(2);
    // No footers except on latest patch set.
    assertThat(actual.revisions.get(r1.getCommit().getName()).commitWithFooters).isNull();
    List<String> footers = new ArrayList<>(Arrays.asList(actual.revisions.get(r2.getCommit().getName()).commitWithFooters.split("\\n")));
    // remove subject + blank line
    footers.remove(0);
    footers.remove(0);
    List<String> expectedFooters = Arrays.asList("Change-Id: " + r2.getChangeId(), "Reviewed-on: " + canonicalWebUrl.get() + "c/" + project.get() + "/+/" + r2.getChange().getId(), "Reviewed-by: Administrator <admin@example.com>", "Custom2: Administrator <admin@example.com>", "Tested-by: Administrator <admin@example.com>");
    assertThat(footers).containsExactlyElementsIn(expectedFooters);
}
#end_block

#method_before
@Test
public void customCommitFooters() throws Exception {
    PushOneCommit.Result change = createChange();
    RegistrationHandle handle = changeMessageModifiers.add("gerrit", (newCommitMessage, original, mergeTip, destination) -> {
        assertThat(original.getName()).isNotEqualTo(mergeTip.getName());
        return newCommitMessage + "Custom: " + destination.get();
    });
    ChangeInfo actual;
    try {
        actual = gApi.changes().id(change.getChangeId()).get(ALL_REVISIONS, COMMIT_FOOTERS);
    } finally {
        handle.remove();
    }
    List<String> footers = new ArrayList<>(Arrays.asList(actual.revisions.get(change.getCommit().getName()).commitWithFooters.split("\\n")));
    // remove subject + blank line
    footers.remove(0);
    footers.remove(0);
    List<String> expectedFooters = Arrays.asList("Change-Id: " + change.getChangeId(), "Reviewed-on: " + canonicalWebUrl.get() + "c/" + change.getChange().getId(), "Custom: refs/heads/master");
    assertThat(footers).containsExactlyElementsIn(expectedFooters);
}
#method_after
@Test
public void customCommitFooters() throws Exception {
    PushOneCommit.Result change = createChange();
    RegistrationHandle handle = changeMessageModifiers.add("gerrit", (newCommitMessage, original, mergeTip, destination) -> {
        assertThat(original.getName()).isNotEqualTo(mergeTip.getName());
        return newCommitMessage + "Custom: " + destination.get();
    });
    ChangeInfo actual;
    try {
        actual = gApi.changes().id(change.getChangeId()).get(ALL_REVISIONS, COMMIT_FOOTERS);
    } finally {
        handle.remove();
    }
    List<String> footers = new ArrayList<>(Arrays.asList(actual.revisions.get(change.getCommit().getName()).commitWithFooters.split("\\n")));
    // remove subject + blank line
    footers.remove(0);
    footers.remove(0);
    List<String> expectedFooters = Arrays.asList("Change-Id: " + change.getChangeId(), "Reviewed-on: " + canonicalWebUrl.get() + "c/" + project.get() + "/+/" + change.getChange().getId(), "Custom: refs/heads/master");
    assertThat(footers).containsExactlyElementsIn(expectedFooters);
}
#end_block

#method_before
@Test
public void ignore() throws Exception {
    String email = "user2@example.com";
    String fullname = "User2";
    accountOperations.newAccount().username("user2").preferredEmail(email).fullname(fullname).create();
    PushOneCommit.Result r = createChange();
    AddReviewerInput in = new AddReviewerInput();
    in.reviewer = user.email;
    gApi.changes().id(r.getChangeId()).addReviewer(in);
    in = new AddReviewerInput();
    in.reviewer = email;
    gApi.changes().id(r.getChangeId()).addReviewer(in);
    requestScopeOperations.setApiUser(user.getId());
    gApi.changes().id(r.getChangeId()).ignore(true);
    assertThat(gApi.changes().id(r.getChangeId()).ignored()).isTrue();
    sender.clear();
    requestScopeOperations.setApiUser(admin.getId());
    gApi.changes().id(r.getChangeId()).abandon();
    List<Message> messages = sender.getMessages();
    assertThat(messages).hasSize(1);
    assertThat(messages.get(0).rcpt()).containsExactly(new Address(fullname, email));
    requestScopeOperations.setApiUser(user.getId());
    gApi.changes().id(r.getChangeId()).ignore(false);
    assertThat(gApi.changes().id(r.getChangeId()).ignored()).isFalse();
}
#method_after
@Test
public void ignore() throws Exception {
    String email = "user2@example.com";
    String fullname = "User2";
    accountOperations.newAccount().username("user2").preferredEmail(email).fullname(fullname).create();
    PushOneCommit.Result r = createChange();
    AddReviewerInput in = new AddReviewerInput();
    in.reviewer = user.email;
    gApi.changes().id(r.getChangeId()).addReviewer(in);
    in = new AddReviewerInput();
    in.reviewer = email;
    gApi.changes().id(r.getChangeId()).addReviewer(in);
    requestScopeOperations.setApiUser(user.getId());
    gApi.changes().id(r.getChangeId()).ignore(true);
    assertThat(gApi.changes().id(r.getChangeId()).ignored()).isTrue();
    // New patch set notification is not sent to users ignoring the change
    sender.clear();
    requestScopeOperations.setApiUser(admin.getId());
    amendChange(r.getChangeId());
    List<Message> messages = sender.getMessages();
    assertThat(messages).hasSize(1);
    Address address = new Address(fullname, email);
    assertThat(messages.get(0).rcpt()).containsExactly(address);
    // Review notification is not sent to users ignoring the change
    sender.clear();
    gApi.changes().id(r.getChangeId()).current().review(ReviewInput.approve());
    messages = sender.getMessages();
    assertThat(messages).hasSize(1);
    assertThat(messages.get(0).rcpt()).containsExactly(address);
    // Abandoned notification is not sent to users ignoring the change
    sender.clear();
    gApi.changes().id(r.getChangeId()).abandon();
    messages = sender.getMessages();
    assertThat(messages).hasSize(1);
    assertThat(messages.get(0).rcpt()).containsExactly(address);
    requestScopeOperations.setApiUser(user.getId());
    gApi.changes().id(r.getChangeId()).ignore(false);
    assertThat(gApi.changes().id(r.getChangeId()).ignored()).isFalse();
}
#end_block

#method_before
@Test
public void changeDetailsDoesNotRequireIndex() throws Exception {
    PushOneCommit.Result change = createChange();
    int number = gApi.changes().id(change.getChangeId()).get()._number;
    try (AutoCloseable ctx = disableChangeIndex()) {
        assertThat(gApi.changes().id(project.get(), number).get(ImmutableSet.of()).changeId).isEqualTo(change.getChangeId());
    }
}
#method_after
@Test
public void changeDetailsDoesNotRequireIndex() throws Exception {
    // This set of options must be kept in sync with gr-rest-api-interface.js
    Set<ListChangesOption> options = ImmutableSet.of(ListChangesOption.ALL_COMMITS, ListChangesOption.ALL_REVISIONS, ListChangesOption.CHANGE_ACTIONS, ListChangesOption.CURRENT_ACTIONS, ListChangesOption.DETAILED_LABELS, ListChangesOption.DOWNLOAD_COMMANDS, ListChangesOption.MESSAGES, ListChangesOption.SUBMITTABLE, ListChangesOption.WEB_LINKS, ListChangesOption.SKIP_MERGEABLE);
    PushOneCommit.Result change = createChange();
    int number = gApi.changes().id(change.getChangeId()).get(options)._number;
    try (AutoCloseable ignored = disableChangeIndex()) {
        assertThat(gApi.changes().id(project.get(), number).get().changeId).isEqualTo(change.getChangeId());
    }
}
#end_block

#method_before
public void hasType(int expectedType) {
    isNotNull();
    int actualType = actual().getType();
    check("getType()").that(actualType).named("expected %s, actual %s", typeName(expectedType), typeName(actualType)).isEqualTo(expectedType);
}
#method_after
public void hasType(int expectedType) {
    isNotNull();
    check("getType()").that(typeName(actual().getType())).isEqualTo(typeName(expectedType));
}
#end_block

#method_before
@Test
public void verifyTestUrls() throws Exception {
    try {
        CheckerUrl.clean(CheckerTestData.INVALID_URL);
        assert_().fail("expected BadRequestException");
    } catch (BadRequestException e) {
        assertThat(e).hasMessageThat().isEqualTo("only http/https URLs supported: " + CheckerTestData.INVALID_URL);
    }
}
#method_after
@Test
public void verifyTestUrls() throws Exception {
    try {
        CheckerUrl.clean(CheckerTestData.INVALID_URL);
        assert_().fail("expected BadRequestException");
    } catch (BadRequestException e) {
        assertMessage(e, "only http/https URLs supported", CheckerTestData.INVALID_URL);
    }
}
#end_block

#method_before
@Test
public void verifyTestQueries() throws Exception {
    assertInvalidQuery(CheckerTestData.QUERY_WITH_UNSUPPORTED_OPERATOR, "Unsupported operator: " + CheckerTestData.UNSUPPORTED_OPERATOR);
    assertInvalidQuery(CheckerTestData.INVALID_QUERY, "Invalid query: " + CheckerTestData.INVALID_QUERY + "\nline 1:0 no viable alternative at input ':'");
}
#method_after
@Test
public void verifyTestQueries() throws Exception {
    assertInvalidQuery(CheckerTestData.QUERY_WITH_UNSUPPORTED_OPERATOR, "unsupported operator", CheckerTestData.UNSUPPORTED_OPERATOR);
    assertInvalidQuery(CheckerTestData.INVALID_QUERY, "invalid", CheckerTestData.INVALID_QUERY);
}
#end_block

#method_before
private static void assertInvalidQuery(String query, String expectedMessage) {
    try {
        CheckerQuery.clean(query);
        assert_().fail("expected BadRequestException");
    } catch (BadRequestException e) {
        assertThat(e).hasMessageThat().isEqualTo(expectedMessage);
    }
}
#method_after
private static void assertInvalidQuery(String query, String... expectedMessageParts) {
    try {
        CheckerQuery.clean(query);
        assert_().fail("expected BadRequestException");
    } catch (BadRequestException e) {
        assertMessage(e, expectedMessageParts);
    }
}
#end_block

#method_before
@Override
public WithUser currentUser() {
    return new WithUser(userProvider.get());
}
#method_after
@Override
public WithUser currentUser() {
    return new WithUser(quotaEnforcers, userProvider.get());
}
#end_block

#method_before
@Override
public WithUser user(CurrentUser user) {
    return new WithUser(user);
}
#method_after
@Override
public WithUser user(CurrentUser user) {
    return new WithUser(quotaEnforcers, user);
}
#end_block

#method_before
private QuotaResponse.Aggregated request(String quotaGroup, QuotaRequestContext requestContext, long numTokens, boolean deduct) {
    List<QuotaEnforcer> enforcers = ImmutableList.copyOf(quotaEnforcers);
    List<QuotaResponse> responses = new ArrayList<>(enforcers.size());
    for (QuotaEnforcer enforcer : enforcers) {
        if (deduct) {
            responses.add(enforcer.request(quotaGroup, requestContext, numTokens));
        } else {
            responses.add(enforcer.requestNoDeduction(quotaGroup, requestContext, numTokens));
        }
    }
    if (deduct && responses.stream().anyMatch(r -> !r.status().isOk())) {
        // requests should not be deducted.
        for (int i = 0; i < responses.size(); i++) {
            if (responses.get(i).status().isOk()) {
                enforcers.get(i).refill(quotaGroup, requestContext, numTokens);
            }
        }
    }
    logger.atInfo().log("Quota request for %s with %s %s for %s token returned %s", quotaGroup, requestContext, deduct ? "(deduction=yes)" : "(deduction=no)", numTokens, responses);
    return new QuotaResponse.Aggregated(responses);
}
#method_after
private static QuotaResponse.Aggregated request(PluginSetContext<QuotaEnforcer> quotaEnforcers, String quotaGroup, QuotaRequestContext requestContext, long numTokens, boolean deduct) {
    checkState(numTokens > 0, "numTokens must be a positive, non-zero long");
    // PluginSets can change their content when plugins (de-)register. Copy the currently registered
    // plugins so that we can iterate twice on a stable list.
    List<PluginSetEntryContext<QuotaEnforcer>> enforcers = ImmutableList.copyOf(quotaEnforcers);
    List<QuotaResponse> responses = new ArrayList<>(enforcers.size());
    for (PluginSetEntryContext<QuotaEnforcer> enforcer : enforcers) {
        try {
            if (deduct) {
                responses.add(enforcer.call(p -> p.requestTokens(quotaGroup, requestContext, numTokens)));
            } else {
                responses.add(enforcer.call(p -> p.dryRun(quotaGroup, requestContext, numTokens)));
            }
        } catch (RuntimeException e) {
            logger.atSevere().withCause(e).log("exception while enforcing quota");
            responses.add(QuotaResponse.error(e.getMessage()));
        }
    }
    if (deduct && responses.stream().anyMatch(r -> r.status().isError())) {
        // requests should not be deducted.
        for (int i = 0; i < responses.size(); i++) {
            if (responses.get(i).status().isOk()) {
                enforcers.get(i).run(p -> p.refill(quotaGroup, requestContext, numTokens));
            }
        }
    }
    logger.atFine().log("Quota request for %s with %s (deduction=%s) for %s token returned %s", quotaGroup, requestContext, deduct ? "(deduction=yes)" : "(deduction=no)", numTokens, responses);
    return new AutoValue_QuotaResponse_Aggregated(ImmutableList.copyOf(responses));
}
#end_block

#method_before
@Override
public QuotaBackend.WithResource account(Account.Id account) {
    return new WithResource(user, Optional.empty(), Optional.empty(), Optional.of(account));
}
#method_after
@Override
public QuotaBackend.WithResource account(Account.Id account) {
    QuotaRequestContext ctx = requestContext.toBuilder().account(account).build();
    return new WithResource(quotaEnforcers, ctx);
}
#end_block

#method_before
@Override
public QuotaBackend.WithResource project(NameKey project) {
    return new WithResource(user, Optional.of(project), Optional.empty(), Optional.empty());
}
#method_after
@Override
public QuotaBackend.WithResource project(NameKey project) {
    QuotaRequestContext ctx = requestContext.toBuilder().project(project).build();
    return new WithResource(quotaEnforcers, ctx);
}
#end_block

#method_before
@Override
public QuotaBackend.WithResource change(Change.Id change, NameKey project) {
    return new WithResource(user, Optional.of(project), Optional.of(change), Optional.empty());
}
#method_after
@Override
public QuotaBackend.WithResource change(Change.Id change, NameKey project) {
    QuotaRequestContext ctx = requestContext.toBuilder().change(change).project(project).build();
    return new WithResource(quotaEnforcers, ctx);
}
#end_block

#method_before
public static QuotaResponse ok() {
    return new AutoValue_QuotaResponse.Builder().status(Status.OK).message(Optional.empty()).build();
}
#method_after
public static QuotaResponse ok() {
    return new AutoValue_QuotaResponse.Builder().status(Status.OK).build();
}
#end_block

#method_before
public static QuotaResponse noOp() {
    return new AutoValue_QuotaResponse.Builder().status(Status.NO_OP).message(Optional.empty()).build();
}
#method_after
public static QuotaResponse noOp() {
    return new AutoValue_QuotaResponse.Builder().status(Status.NO_OP).build();
}
#end_block

#method_before
public static QuotaResponse error(String message) {
    return new AutoValue_QuotaResponse.Builder().status(Status.ERROR).message(Optional.of(message)).build();
}
#method_after
public static QuotaResponse error(String message) {
    return new AutoValue_QuotaResponse.Builder().status(Status.ERROR).message(message).build();
}
#end_block

#method_before
public ImmutableList<QuotaResponse> all() {
    return responses;
}
#method_after
public ImmutableList<QuotaResponse> all() {
    return responses();
}
#end_block

#method_before
public ImmutableList<QuotaResponse> ok() {
    return responses.stream().filter(r -> r.status().isOk()).collect(toImmutableList());
}
#method_after
public ImmutableList<QuotaResponse> ok() {
    return responses().stream().filter(r -> r.status().isOk()).collect(toImmutableList());
}
#end_block

#method_before
public ImmutableList<QuotaResponse> error() {
    return responses.stream().filter(r -> !r.status().isOk()).collect(toImmutableList());
}
#method_after
public ImmutableList<QuotaResponse> error() {
    return responses().stream().filter(r -> r.status().isError()).collect(toImmutableList());
}
#end_block

#method_before
public static Builder builder() {
    return defaults.toBuilder();
}
#method_after
public static Builder builder() {
    return new AutoValue_QuotaRequestContext.Builder().user(new AnonymousUser());
}
#end_block

#method_before
@Test
public void shouldCompareAndCreateSuccessfully() throws Exception {
    Ref ref = refOf(AN_OBJECT_ID_1);
    zookeeperContainer.createRefInZk(A_TEST_PROJECT_NAME, ref);
    assertThat(zkSharedRefDatabase.compareAndCreate(A_TEST_PROJECT_NAME, ref)).isTrue();
    assertThat(zookeeperContainer.readRefValueFromZk(A_TEST_PROJECT_NAME, ref)).isEqualTo(ref.getObjectId());
}
#method_after
@Test
public void shouldCompareAndCreateSuccessfully() throws Exception {
    Ref ref = refOf(AN_OBJECT_ID_1);
    assertThat(zkSharedRefDatabase.compareAndCreate(A_TEST_PROJECT_NAME, ref)).isTrue();
    assertThat(zookeeperContainer.readRefValueFromZk(A_TEST_PROJECT_NAME, ref)).isEqualTo(ref.getObjectId());
}
#end_block

#method_before
@Override
public boolean compareAndPut(String projectName, Ref oldRef, Ref newRef) throws IOException {
    final DistributedAtomicValue distributedRefValue = new DistributedAtomicValue(client, pathFor(projectName, oldRef), retryPolicy);
    try {
        if (oldRef == NULL_REF) {
            return distributedRefValue.initialize(writeObjectId(newRef.getObjectId()));
        } else {
            final ObjectId newValue = newRef.getObjectId() == null ? ObjectId.zeroId() : newRef.getObjectId();
            final AtomicValue<byte[]> newDistributedValue = distributedRefValue.compareAndSet(writeObjectId(oldRef.getObjectId()), writeObjectId(newValue));
            if (!newDistributedValue.succeeded() && operationMode == OperationMode.MIGRATION && refNotInZk(projectName, oldRef)) {
                logger.atInfo().log("Missing entry in ZK for ref at path '%'. Assuming this is because we are in migration mode and creating it", pathFor(projectName, oldRef));
                return distributedRefValue.initialize(writeObjectId(newRef.getObjectId()));
            }
            return newDistributedValue.succeeded();
        }
    } catch (Exception e) {
        logger.atWarning().withCause(e).log("Error trying to perform CAS at path %s", pathFor(projectName, newRef));
        throw new IOException(String.format("Error trying to perform CAS at path %s", pathFor(projectName, newRef)), e);
    }
}
#method_after
@Override
public boolean compareAndPut(String projectName, Ref oldRef, Ref newRef) throws IOException {
    final DistributedAtomicValue distributedRefValue = new DistributedAtomicValue(client, pathFor(projectName, oldRef, newRef), retryPolicy);
    try {
        if (oldRef == NULL_REF) {
            return distributedRefValue.initialize(writeObjectId(newRef.getObjectId()));
        }
        final ObjectId newValue = newRef.getObjectId() == null ? ObjectId.zeroId() : newRef.getObjectId();
        final AtomicValue<byte[]> newDistributedValue = distributedRefValue.compareAndSet(writeObjectId(oldRef.getObjectId()), writeObjectId(newValue));
        if (!newDistributedValue.succeeded() && operationMode == OperationMode.MIGRATION && refNotInZk(projectName, oldRef, newRef)) {
            logger.atInfo().log("Missing entry in ZK for ref at path '%'. Assuming this is because we are in migration mode and creating it", pathFor(projectName, oldRef, newRef));
            return distributedRefValue.initialize(writeObjectId(newRef.getObjectId()));
        }
        return newDistributedValue.succeeded();
    } catch (Exception e) {
        logger.atWarning().withCause(e).log("Error trying to perform CAS at path %s", pathFor(projectName, oldRef, newRef));
        throw new IOException(String.format("Error trying to perform CAS at path %s", pathFor(projectName, oldRef, newRef)), e);
    }
}
#end_block

#method_before
private boolean refNotInZk(String projectName, Ref oldRef) throws Exception {
    return client.checkExists().forPath(pathFor(projectName, oldRef)) == null;
}
#method_after
private boolean refNotInZk(String projectName, Ref oldRef, Ref newRef) throws Exception {
    return client.checkExists().forPath(pathFor(projectName, oldRef, newRef)) == null;
}
#end_block

#method_before
static String pathFor(String projectName, String refName) {
    return "/" + projectName + "/" + refName;
}
#method_after
static String pathFor(String projectName, Ref oldRef, Ref newRef) {
    return pathFor(projectName, MoreObjects.firstNonNull(oldRef.getName(), newRef.getName()));
}
#end_block

#method_before
public GenericContainer getContainer() {
    return container;
}
#method_after
public ZookeeperContainer getContainer() {
    return container;
}
#end_block

#method_before
public ObjectId readRefValueFromZk(String projectName, Ref ref) throws Exception {
    final byte[] bytes = curator.getData().forPath(pathFor(projectName, ref));
    return ZkSharedRefDatabase.readObjectId(bytes);
}
#method_after
public ObjectId readRefValueFromZk(String projectName, Ref ref) throws Exception {
    final byte[] bytes = curator.getData().forPath(pathFor(projectName, NULL_REF, ref));
    return ZkSharedRefDatabase.readObjectId(bytes);
}
#end_block

#method_before
public void createRefInZk(String projectName, Ref ref) throws Exception {
    curator.create().creatingParentContainersIfNeeded().forPath(pathFor(projectName, ref), writeObjectId(ref.getObjectId()));
}
#method_after
public void createRefInZk(String projectName, Ref ref) throws Exception {
    curator.create().creatingParentContainersIfNeeded().forPath(pathFor(projectName, NULL_REF, ref), writeObjectId(ref.getObjectId()));
}
#end_block

#method_before
private static boolean getBoolean(Config cfg, String section, String subsection, String name, boolean defaultValue) {
    try {
        return cfg.getBoolean(section, subsection, name, defaultValue);
    } catch (IllegalArgumentException e) {
        log.error("invalid value for {}; using default value {}", name, defaultValue);
        log.debug("Failed to retrieve integer value: {}", e.getMessage(), e);
        return defaultValue;
    }
}
#method_after
private static boolean getBoolean(Config cfg, String section, String subsection, String name, boolean defaultValue) {
    return cfg.getBoolean(section, subsection, name, defaultValue);
}
#end_block

#method_before
@Override
public boolean compareAndPut(String projectName, Ref oldRef, Ref newRef) throws IOException {
    final DistributedAtomicValue distributedRefValue = new DistributedAtomicValue(client, pathFor(projectName, oldRef), retryPolicy);
    try {
        if (oldRef == NULL_REF) {
            return distributedRefValue.initialize(writeObjectId(newRef.getObjectId()));
        } else {
            final ObjectId newValue = newRef.getObjectId() == null ? ObjectId.zeroId() : newRef.getObjectId();
            final AtomicValue<byte[]> newDistributedValue = distributedRefValue.compareAndSet(writeObjectId(oldRef.getObjectId()), writeObjectId(newValue));
            return newDistributedValue.succeeded();
        }
    } catch (Exception e) {
        logger.atWarning().withCause(e).log("Error trying to perform CAS at path %s", pathFor(projectName, newRef));
        throw new IOException(String.format("Error trying to perform CAS at path %s", pathFor(projectName, newRef)), e);
    }
}
#method_after
@Override
public boolean compareAndPut(String projectName, Ref oldRef, Ref newRef) throws IOException {
    final DistributedAtomicValue distributedRefValue = new DistributedAtomicValue(client, pathFor(projectName, oldRef, newRef), retryPolicy);
    try {
        if (oldRef == NULL_REF) {
            return distributedRefValue.initialize(writeObjectId(newRef.getObjectId()));
        }
        final ObjectId newValue = newRef.getObjectId() == null ? ObjectId.zeroId() : newRef.getObjectId();
        final AtomicValue<byte[]> newDistributedValue = distributedRefValue.compareAndSet(writeObjectId(oldRef.getObjectId()), writeObjectId(newValue));
        return newDistributedValue.succeeded();
    } catch (Exception e) {
        logger.atWarning().withCause(e).log("Error trying to perform CAS at path %s", pathFor(projectName, oldRef, newRef));
        throw new IOException(String.format("Error trying to perform CAS at path %s", pathFor(projectName, oldRef, newRef)), e);
    }
}
#end_block

#method_before
public static String pathFor(String projectName, String refName) {
    return "/" + projectName + "/" + refName;
}
#method_after
static String pathFor(String projectName, Ref oldRef, Ref newRef) {
    return pathFor(projectName, MoreObjects.firstNonNull(oldRef.getName(), newRef.getName()));
}
#end_block

#method_before
public static String pathFor(String projectName, String refName) {
    return "/" + projectName + "/" + refName;
}
#method_after
static String pathFor(String projectName, String refName) {
    return "/" + projectName + "/" + refName;
}
#end_block

#method_before
public static ObjectId readObjectId(byte[] value) {
    return ObjectId.fromRaw(value);
}
#method_after
static ObjectId readObjectId(byte[] value) {
    return ObjectId.fromRaw(value);
}
#end_block

#method_before
public static byte[] writeObjectId(ObjectId value) throws IOException {
    final ByteArrayOutputStream out = new ByteArrayOutputStream();
    final DataOutputStream stream = new DataOutputStream(out);
    value.copyRawTo(stream);
    return out.toByteArray();
}
#method_after
static byte[] writeObjectId(ObjectId value) throws IOException {
    final ByteArrayOutputStream out = new ByteArrayOutputStream();
    final DataOutputStream stream = new DataOutputStream(out);
    value.copyRawTo(stream);
    return out.toByteArray();
}
#end_block

#method_before
@Test
public void shouldCompareAndCreateSuccessfully() throws Exception {
    Ref ref = refOf(AN_OBJECT_ID_1);
    zookeeperContainer.createRefInZk(A_TEST_PROJECT_NAME, ref);
    assertThat(zkSharedRefDatabase.compareAndCreate(A_TEST_PROJECT_NAME, ref)).isTrue();
    assertThat(zookeeperContainer.readRefValueFromZk(A_TEST_PROJECT_NAME, ref)).isEqualTo(ref.getObjectId());
}
#method_after
@Test
public void shouldCompareAndCreateSuccessfully() throws Exception {
    Ref ref = refOf(AN_OBJECT_ID_1);
    assertThat(zkSharedRefDatabase.compareAndCreate(A_TEST_PROJECT_NAME, ref)).isTrue();
    assertThat(zookeeperContainer.readRefValueFromZk(A_TEST_PROJECT_NAME, ref)).isEqualTo(ref.getObjectId());
}
#end_block

#method_before
private static boolean getBoolean(Config cfg, String section, String subsection, String name, boolean defaultValue) {
    try {
        return cfg.getBoolean(section, subsection, name, defaultValue);
    } catch (IllegalArgumentException e) {
        log.error("invalid value for {}; using default value {}", name, defaultValue);
        log.debug("Failed to retrieve integer value: {}", e.getMessage(), e);
        return defaultValue;
    }
}
#method_after
private static boolean getBoolean(Config cfg, String section, String subsection, String name, boolean defaultValue) {
    return cfg.getBoolean(section, subsection, name, defaultValue);
}
#end_block

#method_before
@Override
protected void configure() {
    DynamicSet.bind(binder(), RefOperationValidationListener.class).to(InSyncChangeValidator.class);
    bind(SharedRefDatabase.class).to(ZkSharedRefDatabase.class);
    bind(CuratorFramework.class).toInstance(cfg.getSplitBrain().getZookeeper().buildCurator());
    bind(RetryPolicy.class).annotatedWith(Names.named("ZkLockRetryPolicy")).toInstance(cfg.getSplitBrain().getZookeeper().buildCasRetryPolicy());
}
#method_after
@Override
protected void configure() {
    DynamicSet.bind(binder(), RefOperationValidationListener.class).to(InSyncChangeValidator.class);
    install(new ZkValidationModule(cfg));
}
#end_block

#method_before
public GenericContainer getContainer() {
    return container;
}
#method_after
public ZookeeperContainer getContainer() {
    return container;
}
#end_block

#method_before
public ObjectId readRefValueFromZk(String projectName, Ref ref) throws Exception {
    final byte[] bytes = curator.getData().forPath(pathFor(projectName, ref));
    return ZkSharedRefDatabase.readObjectId(bytes);
}
#method_after
public ObjectId readRefValueFromZk(String projectName, Ref ref) throws Exception {
    final byte[] bytes = curator.getData().forPath(pathFor(projectName, NULL_REF, ref));
    return ZkSharedRefDatabase.readObjectId(bytes);
}
#end_block

#method_before
public void createRefInZk(String projectName, Ref ref) throws Exception {
    curator.create().creatingParentContainersIfNeeded().forPath(pathFor(projectName, ref), writeObjectId(ref.getObjectId()));
}
#method_after
public void createRefInZk(String projectName, Ref ref) throws Exception {
    curator.create().creatingParentContainersIfNeeded().forPath(pathFor(projectName, NULL_REF, ref), writeObjectId(ref.getObjectId()));
}
#end_block

#method_before
@Override
protected void configure() {
    DynamicSet.bind(binder(), ProjectCreationValidationListener.class).to(MaxRepositoriesQuotaValidator.class);
    DynamicSet.bind(binder(), ReceivePackInitializer.class).to(MaxRepositorySizeQuota.class);
    DynamicSet.bind(binder(), PostReceiveHook.class).to(MaxRepositorySizeQuota.class);
    DynamicSet.bind(binder(), ProjectDeletedListener.class).to(DeletionListener.class);
    DynamicSet.bind(binder(), GarbageCollectorListener.class).to(GCListener.class);
    DynamicSet.setOf(binder(), UsageDataEventCreator.class);
    install(MaxRepositorySizeQuota.module());
    install(new RestApiModule() {

        @Override
        protected void configure() {
            DynamicMap.mapOf(binder(), QUOTA_KIND);
            get(PROJECT_KIND, "quota").to(GetQuota.class);
            child(CONFIG_KIND, "quota").to(GetQuotas.class);
        }
    });
    bind(Publisher.class).in(Scopes.SINGLETON);
    bind(PublisherScheduler.class).in(Scopes.SINGLETON);
    bind(ProjectNameResolver.class).in(Scopes.SINGLETON);
    bind(LifecycleListener.class).annotatedWith(UniqueAnnotations.create()).to(PublisherScheduler.class);
    DynamicSet.bind(binder(), UploadValidationListener.class).to(RateLimitUploadListener.class);
    cache(CACHE_NAME_ACCOUNTID, Account.Id.class, Holder.class).loader(LoaderAccountId.class);
    cache(CACHE_NAME_REMOTEHOST, String.class, Holder.class).loader(LoaderRemoteHost.class);
    bindConstant().annotatedWith(Names.named(RateMsgHelper.UPLOADPACK_CONFIGURABLE_MSG_ANNOTATION)).to(uploadpackLimitExceededMsg);
}
#method_after
@Override
protected void configure() {
    DynamicSet.bind(binder(), ProjectCreationValidationListener.class).to(MaxRepositoriesQuotaValidator.class);
    DynamicSet.bind(binder(), ReceivePackInitializer.class).to(MaxRepositorySizeQuota.class);
    DynamicSet.bind(binder(), PostReceiveHook.class).to(MaxRepositorySizeQuota.class);
    DynamicSet.bind(binder(), ProjectDeletedListener.class).to(DeletionListener.class);
    DynamicSet.bind(binder(), GarbageCollectorListener.class).to(GCListener.class);
    DynamicSet.setOf(binder(), UsageDataEventCreator.class);
    install(MaxRepositorySizeQuota.module());
    install(new RestApiModule() {

        @Override
        protected void configure() {
            DynamicMap.mapOf(binder(), QUOTA_KIND);
            get(PROJECT_KIND, "quota").to(GetQuota.class);
            child(CONFIG_KIND, "quota").to(GetQuotas.class);
        }
    });
    bind(Publisher.class).in(Scopes.SINGLETON);
    bind(PublisherScheduler.class).in(Scopes.SINGLETON);
    bind(ProjectNameResolver.class).in(Scopes.SINGLETON);
    bind(LifecycleListener.class).annotatedWith(UniqueAnnotations.create()).to(PublisherScheduler.class);
    DynamicSet.bind(binder(), UploadValidationListener.class).to(RateLimitUploadListener.class);
    bindConstant().annotatedWith(Names.named(RateMsgHelper.UPLOADPACK_CONFIGURABLE_MSG_ANNOTATION)).to(uploadpackLimitExceededMsg);
}
#end_block

#method_before
public RateLimiter get() {
    return l;
}
#method_after
RateLimiter get() {
    return l;
}
#end_block

#method_before
static final Holder createWithBurstyRateLimiter(Optional<RateLimit> limit) {
    return new Holder(RateLimitUploadListener.createSmoothBurstyRateLimiter(limit.get().getRatePerSecond(), limit.get().getMaxBurstSeconds()), (int) (limit.get().getMaxBurstSeconds() * limit.get().getRatePerSecond()));
}
#method_after
private static final Holder createWithBurstyRateLimiter(Optional<RateLimit> limit) {
    return new Holder(RateLimitUploadListener.createSmoothBurstyRateLimiter(limit.get().getRatePerSecond(), limit.get().getMaxBurstSeconds()), (int) (limit.get().getMaxBurstSeconds() * limit.get().getRatePerSecond()));
}
#end_block

#method_before
private final Holder createWithBurstyRateLimiter(Optional<RateLimit> limit) throws Exception {
    if (limit.isPresent()) {
        return Holder.createWithBurstyRateLimiter(limit);
    }
    return Holder.EMPTY;
}
#method_after
protected final Holder createWithBurstyRateLimiter(Optional<RateLimit> limit) throws Exception {
    if (limit.isPresent()) {
        return Holder.createWithBurstyRateLimiter(limit);
    }
    return Holder.EMPTY;
}
#end_block

#method_before
@Override
protected void configure() {
    DynamicSet.bind(binder(), AllRequestFilter.class).to(RestApiRequestRateEnforcer.class);
    cache(CACHE_NAME_RESTAPI_ACCOUNTID, Account.Id.class, Module.Holder.class).loader(RestApiLoaderAccountId.class);
    cache(CACHE_NAME_RESTAPI_REMOTEHOST, String.class, Module.Holder.class).loader(RestApiLoaderRemoteHost.class);
    bindConstant().annotatedWith(Names.named(RateMsgHelper.RESTAPI_CONFIGURABLE_MSG_ANNOTATION)).to(RESTAPI_LIMIT_EXCEEDED_MSG);
}
#method_after
@Override
protected void configure() {
    DynamicSet.bind(binder(), AllRequestFilter.class).to(RestApiRateLimiter.class);
    bindConstant().annotatedWith(Names.named(RateMsgHelper.RESTAPI_CONFIGURABLE_MSG_ANNOTATION)).to(restapiLimitExceededMsg);
}
#end_block

#method_before
static String getDefaultTemplateMsg(String rateLimitTypeName) {
    return DEFAULT_TEMPLATE_MSG_PARTS[0] + rateLimitTypeName + DEFAULT_TEMPLATE_MSG_PARTS[1];
}
#method_after
private static String getDefaultTemplateMsg(String rateLimitTypeName) {
    return "Exceeded rate limit of " + RATE_LIMIT_TOKEN + " " + rateLimitTypeName + " requests/hour";
}
#end_block

#method_before
static String getDefaultTemplateMsgWithBursts(String rateLimitTypeName) {
    return DEFAULT_TEMPLATE_MSG_PARTS[0] + rateLimitTypeName + DEFAULT_TEMPLATE_MSG_PARTS[2];
}
#method_after
private static String getDefaultTemplateMsgWithBursts(String rateLimitTypeName) {
    return "Exceeded rate limit of " + RATE_LIMIT_TOKEN + " " + rateLimitTypeName + " requests/hour (or idle time used up in bursts of max " + BURSTS_LIMIT_TOKEN + " requests)";
}
#end_block

#method_before
public static GetCheckOptions defaults() {
    return builder().build();
}
#method_after
public static GetCheckOptions defaults() {
    return new AutoValue_Checks_GetCheckOptions(false);
}
#end_block

#method_before
@Override
public ImmutableList<Check> getChecks(Project.NameKey projectName, PatchSet.Id psId, GetChecksOptions options) throws OrmException, IOException {
    return getChecksAsStream(projectName, psId, options).collect(toImmutableList());
}
#method_after
@Override
public ImmutableList<Check> getChecks(Project.NameKey projectName, PatchSet.Id psId, GetCheckOptions options) throws IOException, OrmException {
    return getChecksFromNoteDb(projectName, psId, options);
}
#end_block

#method_before
@Override
public Optional<Check> getCheck(CheckKey checkKey, GetCheckOptions options) throws OrmException, IOException {
    // TODO(gerrit-team): Instead of reading the complete notes map, read just one note.
    Optional<Check> result = getChecksAsStream(checkKey.project(), checkKey.patchSet(), GetChecksOptions.defaults()).filter(c -> c.key().checkerUuid().equals(checkKey.checkerUuid())).findAny();
    if (!result.isPresent() && options.backfillCheck()) {
        ChangeNotes notes = changeNotesFactory.create(checkKey.project(), checkKey.patchSet().getParentKey());
        return checkBackfiller.getBackfilledCheckForRelevantChecker(checkKey.checkerUuid(), notes, checkKey.patchSet());
    }
    return result;
}
#method_after
@Override
public Optional<Check> getCheck(CheckKey checkKey, GetCheckOptions options) throws OrmException, IOException {
    // TODO(gerrit-team): Instead of reading the complete notes map, read just one note.
    Optional<Check> result = getChecksFromNoteDb(checkKey.project(), checkKey.patchSet(), GetCheckOptions.defaults()).stream().filter(c -> c.key().checkerUuid().equals(checkKey.checkerUuid())).findAny();
    if (!result.isPresent() && options.backfillChecks()) {
        ChangeData changeData = changeDataFactory.create(checkKey.project(), checkKey.patchSet().getParentKey());
        return checkBackfiller.getBackfilledCheckForRelevantChecker(checkKey.checkerUuid(), changeData, checkKey.patchSet());
    }
    return result;
}
#end_block

#method_before
@Override
public CombinedCheckState getCombinedCheckState(NameKey projectName, Id patchSetId, boolean includeNotRequiredCheckers) throws IOException, OrmException {
    ImmutableMap<String, Checker> applicableCheckers = checkers.checkersOf(projectName).stream().collect(ImmutableMap.toImmutableMap(c -> c.getUuid().toString(), c -> c));
    // Always backfilling checks to have a meaningful "CombinedCheckState" even when there are some
    // or all checks missing.
    GetChecksOptions options = GetChecksOptions.builder().setBackfillChecks(true).build();
    ImmutableMap<String, Check> checks = getChecks(projectName, patchSetId, options).stream().collect(ImmutableMap.toImmutableMap(c -> c.key().checkerUuid().toString(), c -> c));
    ImmutableListMultimap.Builder<CheckState, Boolean> statesAndRequired = ImmutableListMultimap.builder();
    for (Map.Entry<String, Checker> entry : applicableCheckers.entrySet()) {
        String checkerUuid = entry.getKey();
        Checker checker = entry.getValue();
        if (checker.getStatus() == CheckerStatus.DISABLED) {
            // Disabled checkers are not considered.
            continue;
        }
        boolean required = true;
        ImmutableSortedSet<BlockingCondition> blockingConditions = checker.getBlockingConditions();
        if (blockingConditions.isEmpty()) {
            required = false;
        } else if (blockingConditions.size() > 1 || !blockingConditions.contains(BlockingCondition.STATE_NOT_PASSING)) {
            // When a new blocking condition is introduced, this needs to be adjusted to respect that.
            String errorMessage = String.format("illegal blocking conditions %s", blockingConditions);
            throw new IllegalStateException(errorMessage);
        }
        if (!required && !includeNotRequiredCheckers) {
            continue;
        }
        statesAndRequired.put(checks.get(checkerUuid).state(), required);
    }
    return CombinedCheckState.combine(statesAndRequired.build());
}
#method_after
@Override
public CombinedCheckState getCombinedCheckState(NameKey projectName, Id patchSetId) throws IOException, OrmException {
    ChangeData changeData = changeDataFactory.create(projectName, patchSetId.changeId);
    ImmutableMap<String, Checker> allCheckersOfProject = checkers.checkersOf(projectName).stream().collect(ImmutableMap.toImmutableMap(c -> c.getUuid().toString(), c -> c));
    // Always backfilling checks to have a meaningful "CombinedCheckState" even when there are some
    // or all checks missing.
    ImmutableMap<String, Check> checks = getChecks(projectName, patchSetId, GetCheckOptions.withBackfilling()).stream().collect(ImmutableMap.toImmutableMap(c -> c.key().checkerUuid().toString(), c -> c));
    ChangeQueryBuilder queryBuilder = queryBuilderProvider.get().asUser(anonymousUserProvider.get());
    ImmutableListMultimap.Builder<CheckState, Boolean> statesAndRequired = ImmutableListMultimap.builder();
    for (Map.Entry<String, Check> entry : checks.entrySet()) {
        String checkerUuid = entry.getKey();
        Check check = entry.getValue();
        Checker checker = allCheckersOfProject.get(checkerUuid);
        if (checker == null) {
            // A not-relevant check.
            statesAndRequired.put(check.state(), false);
            continue;
        }
        boolean isRequired = checker.getStatus() == CheckerStatus.ENABLED && checker.isRequired() && checker.isCheckerRelevant(changeData, queryBuilder);
        statesAndRequired.put(check.state(), isRequired);
    }
    return CombinedCheckState.combine(statesAndRequired.build());
}
#end_block

#method_before
private ImmutableList<Checker> getCheckersForBackfiller(Project.NameKey projectName, List<Check> existingChecks) throws IOException {
    ImmutableSet<CheckerUuid> existingCheckersWithChecks = existingChecks.stream().map(c -> c.key().checkerUuid()).collect(toImmutableSet());
    return checkers.checkersOf(projectName).stream().filter(c -> !existingCheckersWithChecks.contains(c.getUuid())).collect(toImmutableList());
}
#method_after
private ImmutableList<Checker> getCheckersForBackfiller(Project.NameKey projectName, List<Check> existingChecks) throws IOException {
    ImmutableSet<CheckerUuid> checkersWithExistingChecks = existingChecks.stream().map(c -> c.key().checkerUuid()).collect(toImmutableSet());
    return checkers.checkersOf(projectName).stream().filter(c -> !checkersWithExistingChecks.contains(c.getUuid())).collect(toImmutableList());
}
#end_block

#method_before
@Override
public Collection<SubmitRecord> evaluate(ChangeData changeData, SubmitRuleOptions options) {
    Project.NameKey project = changeData.project();
    Change.Id changeId = changeData.getId();
    // Gets all check results of the given change.
    ImmutableMap<String, CheckInfo> checks;
    try {
        checks = listChecks.getAllChecks(project, changeData.notes(), changeData.currentPatchSet().getId()).stream().collect(ImmutableMap.toImmutableMap(c -> c.checkerUuid, c -> c));
    } catch (OrmException | IOException e) {
        String errorMessage = String.format("failed to get all checks for change %s", changeId);
        logger.atSevere().withCause(e).log(errorMessage);
        return singletonRecordForRuleError(errorMessage);
    }
    // Gets all checkers applicable to the given change.
    ImmutableMap<String, Checker> appliedCheckers;
    try {
        appliedCheckers = checkers.checkersOf(project).stream().collect(ImmutableMap.toImmutableMap(c -> c.getUuid().toString(), c -> c));
    } catch (IOException e) {
        String errorMessage = String.format("failed to get all checkers applied for change %s", changeId);
        logger.atSevere().log(errorMessage);
        return singletonRecordForRuleError(errorMessage);
    }
    CombinedCheckState combinedCheckState = getCombinedCheckState(checks, appliedCheckers, changeId);
    SubmitRecord submitRecord = new SubmitRecord();
    if (combinedCheckState.isPassing()) {
        submitRecord.status = Status.OK;
        return ImmutableList.of(submitRecord);
    }
    submitRecord.status = Status.NOT_READY;
    submitRecord.requirements = ImmutableList.of(DEFAULT_SUBMIT_REQUIREMENT_FOR_CHECKS);
    return ImmutableSet.of(submitRecord);
}
#method_after
@Override
public Collection<SubmitRecord> evaluate(ChangeData changeData, SubmitRuleOptions options) {
    Project.NameKey project = changeData.project();
    Change.Id changeId = changeData.getId();
    PatchSet.Id currentPathSetId;
    try {
        currentPathSetId = changeData.currentPatchSet().getId();
    } catch (OrmException e) {
        String errorMessage = String.format("failed to load the current patch set of change %s", changeId);
        logger.atSevere().withCause(e).log(errorMessage);
        return singletonRecordForRuleError(errorMessage);
    }
    CombinedCheckState combinedCheckState;
    try {
        combinedCheckState = checks.getCombinedCheckState(project, currentPathSetId);
    } catch (IOException | OrmException e) {
        String errorMessage = String.format("failed to evaluate check states for change %s", changeId);
        logger.atSevere().withCause(e).log(errorMessage);
        return singletonRecordForRuleError(errorMessage);
    }
    SubmitRecord submitRecord = new SubmitRecord();
    if (combinedCheckState.isPassing()) {
        submitRecord.status = Status.OK;
        return ImmutableList.of(submitRecord);
    }
    submitRecord.status = Status.NOT_READY;
    submitRecord.requirements = ImmutableList.of(DEFAULT_SUBMIT_REQUIREMENT_FOR_CHECKS);
    return ImmutableSet.of(submitRecord);
}
#end_block

#method_before
@Before
public void setUp() throws Exception {
    PushOneCommit.Result result = createChange();
    result.assertOkStatus();
    testChangeId = result.getChangeId();
    testPatchSetId = result.getPatchSetId();
    // Approves "Code-Review" label so that the change only needs to meet the submit requirements
    // about checks.
    approve(testChangeId);
    // Creates a test Checker which is enabled and required for the test repository.
    testCheckerUuid = checkerOperations.newChecker().repository(project).blockingConditions(BlockingCondition.STATE_NOT_PASSING).status(CheckerStatus.ENABLED).create();
    assertThat(checkerOperations.checker(testCheckerUuid).get().getStatus()).isEqualTo(CheckerStatus.ENABLED);
    assertThat(checkerOperations.checker(testCheckerUuid).get().getBlockingConditions()).containsExactly(BlockingCondition.STATE_NOT_PASSING);
}
#method_after
@Before
public void setUp() throws Exception {
    PushOneCommit.Result result = createChange();
    testPatchSetId = result.getPatchSetId();
    testChangeId = result.getChangeId();
    // Approves "Code-Review" label so that the change only needs to meet the submit requirements
    // about checks.
    approve(testChangeId);
}
#end_block

#method_before
@Test
public void nonApplicableCheckerNotBlockingSubmit() throws Exception {
    postCheckResult(testCheckerUuid, CheckState.FAILED);
    // Updates the checker so that it isn't applicable to the change any more.
    Project.NameKey otherRepo = new Project.NameKey("other-project");
    gApi.projects().create(otherRepo.get());
    checkerOperations.checker(testCheckerUuid).forUpdate().repository(otherRepo).update();
    assertThat(checkerOperations.checker(testCheckerUuid).get().getRepository()).isEqualTo(otherRepo);
    gApi.changes().id(testChangeId).current().submit();
    assertThat(gApi.changes().id(testChangeId).get().status).isEqualTo(ChangeStatus.MERGED);
}
#method_after
@Test
public void nonApplicableCheckerNotBlockingSubmit() throws Exception {
    CheckerUuid checkerUuid = newRequiredChecker().create();
    postCheckResult(checkerUuid, CheckState.FAILED);
    // Updates the checker so that it isn't applicable to the change any more.
    checkerOperations.checker(checkerUuid).forUpdate().repository(allProjects).update();
    ChangeInfo changeInfo = gApi.changes().id(testChangeId).get();
    assertThat(changeInfo.submittable).isTrue();
    assertThat(changeInfo.requirements).isEmpty();
}
#end_block

#method_before
@Test
public void enabledCheckerNotBlockingSubmitIfNotInBlockingState() throws Exception {
    postCheckResult(testCheckerUuid, CheckState.SUCCESSFUL);
    assertThat(checkerOperations.checker(testCheckerUuid).get().getStatus()).isEqualTo(CheckerStatus.ENABLED);
    assertThat(checkerOperations.checker(testCheckerUuid).get().getBlockingConditions()).containsExactly(BlockingCondition.STATE_NOT_PASSING);
    gApi.changes().id(testChangeId).current().submit();
    assertThat(gApi.changes().id(testChangeId).get().status).isEqualTo(ChangeStatus.MERGED);
}
#method_after
// @Test
// public void enabledCheckerNotBlockingSubmitIfNotRequired() throws Exception {
// CheckerUuid checkerUuid = newRequiredChecker().create();
// postCheckResult(checkerUuid, CheckState.FAILED);
// checkerOperations
// .checker(checkerUuid)
// .forUpdate()
// .blockingConditions(ImmutableSortedSet.of())
// .update();
// 
// ChangeInfo changeInfo = gApi.changes().id(testChangeId).get();
// 
// assertThat(changeInfo.submittable).isTrue();
// }
@Test
public void enabledCheckerNotBlockingSubmitIfNotInBlockingState() throws Exception {
    CheckerUuid checkerUuid = newRequiredChecker().create();
    postCheckResult(checkerUuid, CheckState.SUCCESSFUL);
    ChangeInfo changeInfo = gApi.changes().id(testChangeId).get();
    assertThat(changeInfo.submittable).isTrue();
    assertThat(changeInfo.requirements).isEmpty();
}
#end_block

#method_before
@Test
public void enabledCheckerBlockingSubmitIfInBlockingState() throws Exception {
    postCheckResult(testCheckerUuid, CheckState.FAILED);
    exception.expect(ResourceConflictException.class);
    exception.expectMessage("Passing all blocking checks required");
    gApi.changes().id(testChangeId).current().submit();
}
#method_after
@Test
public void enabledCheckerBlockingSubmitIfInBlockingState() throws Exception {
    CheckerUuid checkerUuid = newRequiredChecker().create();
    postCheckResult(checkerUuid, CheckState.FAILED);
    ChangeInfo changeInfo = gApi.changes().id(testChangeId).get();
    assertThat(changeInfo.submittable).isFalse();
    assertThat(changeInfo.requirements).containsExactly(SUBMIT_REQUIREMENT_INFO);
}
#end_block

#method_before
@Test
@Sandboxed
public void multipleCheckerBlockingSubmit() throws Exception {
    // Two enabled and required checkers. They are blocking if any of them isn't passing.
    CheckerUuid testCheckerUuid2 = checkerOperations.newChecker().repository(project).blockingConditions(BlockingCondition.STATE_NOT_PASSING).create();
    postCheckResult(testCheckerUuid, CheckState.SUCCESSFUL);
    postCheckResult(testCheckerUuid2, CheckState.FAILED);
    exception.expect(ResourceConflictException.class);
    exception.expectMessage("Passing all blocking checks required");
    gApi.changes().id(testChangeId).current().submit();
}
#method_after
@Test
public void multipleCheckerBlockingSubmit() throws Exception {
    CheckerUuid checkerUuid = newRequiredChecker().create();
    // Two enabled and required checkers. They are blocking if any of them isn't passing.
    CheckerUuid testCheckerUuid2 = newRequiredChecker().create();
    postCheckResult(checkerUuid, CheckState.SUCCESSFUL);
    postCheckResult(testCheckerUuid2, CheckState.FAILED);
    ChangeInfo changeInfo = gApi.changes().id(testChangeId).get();
    assertThat(changeInfo.submittable).isFalse();
    assertThat(changeInfo.requirements).containsExactly(SUBMIT_REQUIREMENT_INFO);
}
#end_block

#method_before
private void postCheckResult(CheckerUuid checkerUuid, CheckState checkState) throws Exception {
    CheckInput input = new CheckInput();
    input.checkerUuid = checkerUuid.toString();
    input.state = checkState;
    CheckInfo checkInfo = checksApiFactory.revision(testPatchSetId).create(input).get();
    assertThat(checkInfo.state).isEqualTo(checkState);
    assertThat(checkInfo.checkerUuid).isEqualTo(input.checkerUuid);
}
#method_after
private void postCheckResult(CheckerUuid checkerUuid, CheckState checkState) {
    CheckKey checkKey = CheckKey.create(project, testPatchSetId, checkerUuid);
    checkOperations.newCheck(checkKey).setState(checkState).upsert();
}
#end_block

#method_before
@Override
public List<PendingChecksInfo> apply(TopLevelResource resource) throws RestApiException, PermissionBackendException, IOException, ConfigInvalidException, OrmException {
    permissionBackend.currentUser().check(permission);
    if (states.isEmpty()) {
        // If no state was specified, assume NOT_STARTED by default.
        states.add(CheckState.NOT_STARTED);
    }
    if (checkerUuid == null) {
        throw new BadRequestException("checker UUID is required");
    }
    Checker checker = checkers.getChecker(checkerUuid).orElseThrow(() -> new UnprocessableEntityException(String.format("checker %s not found", checkerUuid)));
    if (checker.getStatus() == CheckerStatus.DISABLED) {
        return ImmutableList.of();
    }
    // The query system can only match against the current patch set; ignore non-current patch sets
    // for now.
    List<ChangeData> changes = queryMatchingChangesFor(checker);
    List<PendingChecksInfo> pendingChecks = new ArrayList<>(changes.size());
    for (ChangeData cd : changes) {
        getMatchingPendingChecks(cd.project(), cd.currentPatchSet().getId()).ifPresent(pendingChecks::add);
    }
    return pendingChecks;
}
#method_after
@Override
public List<PendingChecksInfo> apply(TopLevelResource resource) throws RestApiException, PermissionBackendException, IOException, ConfigInvalidException, OrmException {
    permissionBackend.currentUser().check(permission);
    if (states.isEmpty()) {
        // If no state was specified, assume NOT_STARTED by default.
        states.add(CheckState.NOT_STARTED);
    }
    if (checkerUuid == null) {
        throw new BadRequestException("checker UUID is required");
    }
    Checker checker = checkers.getChecker(checkerUuid).orElseThrow(() -> new UnprocessableEntityException(String.format("checker %s not found", checkerUuid)));
    if (checker.getStatus() == CheckerStatus.DISABLED) {
        return ImmutableList.of();
    }
    // The query system can only match against the current patch set; ignore non-current patch sets
    // for now.
    List<ChangeData> changes = checker.queryMatchingChanges(retryHelper, queryBuilderProvider.get(), changeQueryProvider);
    List<PendingChecksInfo> pendingChecks = new ArrayList<>(changes.size());
    for (ChangeData cd : changes) {
        getPostFilteredPendingChecks(cd.project(), cd.currentPatchSet().getId()).ifPresent(pendingChecks::add);
    }
    return pendingChecks;
}
#end_block

#method_before
private CheckState getCheckState(Project.NameKey project, PatchSet.Id patchSetId) throws OrmException, IOException {
    Optional<Check> check = checks.getChecks(project, patchSetId).stream().filter(c -> c.key().checkerUuid().equals(checkerUuid)).findFirst();
    // Backfill if check is not present.
    return check.map(Check::state).orElse(CheckState.NOT_STARTED);
}
#method_after
private CheckState getCheckState(Project.NameKey project, PatchSet.Id patchSetId) throws OrmException, IOException {
    Optional<Check> check = checks.getCheck(CheckKey.create(project, patchSetId, checkerUuid), GetCheckOptions.defaults());
    // that the checker is relevant for this patch set and hence backfilling should be done.
    return check.map(Check::state).orElse(CheckState.NOT_STARTED);
}
#end_block

#method_before
public void hasProject(Project.NameKey expectedProject) {
    Truth.assertThat(patchSet().project).named("project").isEqualTo(expectedProject.get());
}
#method_after
public void hasProject(Project.NameKey expectedProject) {
    check("patchSet().project()").that(patchSet().project).isEqualTo(expectedProject.get());
}
#end_block

#method_before
public void hasPatchSet(PatchSet.Id expectedPatchSetId) {
    CheckablePatchSetInfo patchSet = patchSet();
    Truth.assertThat(patchSet.changeNumber).named("change number").isEqualTo(expectedPatchSetId.getParentKey().get());
    Truth.assertThat(patchSet.patchSetId).named("patch set ID").isEqualTo(expectedPatchSetId.get());
}
#method_after
public void hasPatchSet(PatchSet.Id expectedPatchSetId) {
    CheckablePatchSetInfo patchSet = patchSet();
    check("patchSet().changeNumber()").that(patchSet.changeNumber).isEqualTo(expectedPatchSetId.getParentKey().get());
    check("patchSet().id()").that(patchSet.patchSetId).isEqualTo(expectedPatchSetId.get());
}
#end_block

#method_before
public MapSubject hasPendingChecksMapThat() {
    return Truth.assertThat(pendingChecks()).named("pending checks");
}
#method_after
public MapSubject hasPendingChecksMapThat() {
    return check("pendingChecks()").that(pendingChecks());
}
#end_block

#method_before
private CheckablePatchSetInfo patchSet() {
    isNotNull();
    CheckablePatchSetInfo patchSet = actual().patchSet;
    Truth.assertThat(patchSet).named("patch set").isNotNull();
    return patchSet;
}
#method_after
private CheckablePatchSetInfo patchSet() {
    isNotNull();
    CheckablePatchSetInfo patchSet = actual().patchSet;
    check("patchSet()").that(patchSet).isNotNull();
    return patchSet;
}
#end_block

#method_before
private Map<String, PendingCheckInfo> pendingChecks() {
    isNotNull();
    Map<String, PendingCheckInfo> pendingChecks = actual().pendingChecks;
    Truth.assertThat(pendingChecks).named("pending checks").isNotNull();
    return pendingChecks;
}
#method_after
private Map<String, PendingCheckInfo> pendingChecks() {
    isNotNull();
    Map<String, PendingCheckInfo> pendingChecks = actual().pendingChecks;
    check("pendingChecks()").that(pendingChecks).isNotNull();
    return pendingChecks;
}
#end_block

#method_before
@Override
protected void configure() {
    bind(EmailExpander.class).toProvider(EmailExpanderProvider.class).in(SINGLETON);
    bind(IdGenerator.class);
    bind(RulesCache.class);
    bind(BlameCache.class).to(BlameCacheImpl.class);
    bind(Sequences.class);
    install(authModule);
    install(AccountCacheImpl.module());
    install(BatchUpdate.module());
    install(ChangeKindCacheImpl.module());
    install(ChangeFinder.module());
    install(ConflictsCacheImpl.module());
    install(GroupCacheImpl.module());
    install(GroupIncludeCacheImpl.module());
    install(MergeabilityCacheImpl.module());
    install(PatchListCacheImpl.module());
    install(ProjectCacheImpl.module());
    install(SectionSortCache.module());
    install(SubmitStrategy.module());
    install(TagCache.module());
    install(OAuthTokenCache.module());
    install(new AccessControlModule());
    install(new CmdLineParserModule());
    install(new EmailModule());
    install(new ExternalIdModule());
    install(new GitModule());
    install(new GroupModule());
    install(new NoteDbModule(cfg));
    install(new PrologModule());
    install(new ReceiveCommitsModule());
    install(new SshAddressesModule());
    install(ThreadLocalRequestContext.module());
    bind(AccountResolver.class);
    factory(AddReviewerSender.Factory.class);
    factory(DeleteReviewerSender.Factory.class);
    factory(AddKeySender.Factory.class);
    factory(CapabilityCollection.Factory.class);
    factory(ChangeData.AssistedFactory.class);
    factory(ChangeJson.AssistedFactory.class);
    factory(CreateChangeSender.Factory.class);
    factory(GroupDetailFactory.Factory.class);
    factory(GroupMembers.Factory.class);
    factory(EmailMerge.Factory.class);
    factory(MergedSender.Factory.class);
    factory(MergeUtil.Factory.class);
    factory(PatchScriptFactory.Factory.class);
    factory(PluginUser.Factory.class);
    factory(ProjectNode.Factory.class);
    factory(ProjectState.Factory.class);
    factory(RegisterNewEmailSender.Factory.class);
    factory(ReplacePatchSetSender.Factory.class);
    factory(SetAssigneeSender.Factory.class);
    factory(VisibleRefFilter.Factory.class);
    bind(PermissionCollection.Factory.class);
    bind(AccountVisibility.class).toProvider(AccountVisibilityProvider.class).in(SINGLETON);
    factory(ProjectOwnerGroupsProvider.Factory.class);
    bind(AuthBackend.class).to(UniversalAuthBackend.class).in(SINGLETON);
    DynamicSet.setOf(binder(), AuthBackend.class);
    bind(GroupControl.Factory.class).in(SINGLETON);
    bind(GroupControl.GenericFactory.class).in(SINGLETON);
    bind(FileTypeRegistry.class).to(MimeUtilFileTypeRegistry.class);
    bind(ToolsCatalog.class);
    bind(EventFactory.class);
    bind(TransferConfig.class);
    bind(GcConfig.class);
    bind(ChangeCleanupConfig.class);
    bind(ApprovalsUtil.class);
    bind(RuntimeInstance.class).toProvider(VelocityRuntimeProvider.class);
    bind(SoyTofu.class).annotatedWith(MailTemplates.class).toProvider(MailSoyTofuProvider.class);
    bind(FromAddressGenerator.class).toProvider(FromAddressGeneratorProvider.class).in(SINGLETON);
    bind(Boolean.class).annotatedWith(DisableReverseDnsLookup.class).toProvider(DisableReverseDnsLookupProvider.class).in(SINGLETON);
    bind(PatchSetInfoFactory.class);
    bind(IdentifiedUser.GenericFactory.class).in(SINGLETON);
    bind(AccountControl.Factory.class);
    install(new AuditModule());
    bind(UiActions.class);
    install(new com.google.gerrit.server.access.Module());
    install(new com.google.gerrit.server.account.Module());
    install(new com.google.gerrit.server.api.Module());
    install(new com.google.gerrit.server.change.Module());
    install(new com.google.gerrit.server.config.Module());
    install(new com.google.gerrit.server.group.Module());
    install(new com.google.gerrit.server.project.Module());
    bind(GitReferenceUpdated.class);
    DynamicMap.mapOf(binder(), new TypeLiteral<Cache<?, ?>>() {
    });
    DynamicSet.setOf(binder(), CacheRemovalListener.class);
    DynamicMap.mapOf(binder(), CapabilityDefinition.class);
    DynamicSet.setOf(binder(), GitReferenceUpdatedListener.class);
    DynamicSet.setOf(binder(), AssigneeChangedListener.class);
    DynamicSet.setOf(binder(), ChangeAbandonedListener.class);
    DynamicSet.setOf(binder(), CommentAddedListener.class);
    DynamicSet.setOf(binder(), DraftPublishedListener.class);
    DynamicSet.setOf(binder(), HashtagsEditedListener.class);
    DynamicSet.setOf(binder(), ChangeMergedListener.class);
    DynamicSet.setOf(binder(), ChangeRestoredListener.class);
    DynamicSet.setOf(binder(), ChangeRevertedListener.class);
    DynamicSet.setOf(binder(), ReviewerAddedListener.class);
    DynamicSet.setOf(binder(), ReviewerDeletedListener.class);
    DynamicSet.setOf(binder(), VoteDeletedListener.class);
    DynamicSet.setOf(binder(), RevisionCreatedListener.class);
    DynamicSet.setOf(binder(), TopicEditedListener.class);
    DynamicSet.setOf(binder(), AgreementSignupListener.class);
    DynamicSet.setOf(binder(), PluginEventListener.class);
    DynamicSet.setOf(binder(), ReceivePackInitializer.class);
    DynamicSet.setOf(binder(), PostReceiveHook.class);
    DynamicSet.setOf(binder(), PreUploadHook.class);
    DynamicSet.setOf(binder(), PostUploadHook.class);
    DynamicSet.setOf(binder(), AccountIndexedListener.class);
    DynamicSet.setOf(binder(), ChangeIndexedListener.class);
    DynamicSet.setOf(binder(), GroupIndexedListener.class);
    DynamicSet.setOf(binder(), NewProjectCreatedListener.class);
    DynamicSet.setOf(binder(), ProjectDeletedListener.class);
    DynamicSet.setOf(binder(), GarbageCollectorListener.class);
    DynamicSet.setOf(binder(), HeadUpdatedListener.class);
    DynamicSet.setOf(binder(), UsageDataPublishedListener.class);
    DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(ReindexAfterRefUpdate.class);
    DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(ProjectConfigEntry.UpdateChecker.class);
    DynamicSet.setOf(binder(), EventListener.class);
    DynamicSet.bind(binder(), EventListener.class).to(EventsMetrics.class);
    DynamicSet.setOf(binder(), UserScopedEventListener.class);
    DynamicSet.setOf(binder(), CommitValidationListener.class);
    DynamicSet.setOf(binder(), ChangeMessageModifier.class);
    DynamicSet.setOf(binder(), RefOperationValidationListener.class);
    DynamicSet.setOf(binder(), OnSubmitValidationListener.class);
    DynamicSet.setOf(binder(), MergeValidationListener.class);
    DynamicSet.setOf(binder(), ProjectCreationValidationListener.class);
    DynamicSet.setOf(binder(), GroupCreationValidationListener.class);
    DynamicSet.setOf(binder(), HashtagValidationListener.class);
    DynamicSet.setOf(binder(), OutgoingEmailValidationListener.class);
    DynamicItem.itemOf(binder(), AvatarProvider.class);
    DynamicSet.setOf(binder(), LifecycleListener.class);
    DynamicSet.setOf(binder(), TopMenu.class);
    DynamicSet.setOf(binder(), MessageOfTheDay.class);
    DynamicMap.mapOf(binder(), DownloadScheme.class);
    DynamicMap.mapOf(binder(), DownloadCommand.class);
    DynamicMap.mapOf(binder(), CloneCommand.class);
    DynamicMap.mapOf(binder(), ReviewerSuggestion.class);
    DynamicSet.setOf(binder(), ExternalIncludedIn.class);
    DynamicMap.mapOf(binder(), ProjectConfigEntry.class);
    DynamicSet.setOf(binder(), PatchSetWebLink.class);
    DynamicSet.setOf(binder(), ParentWebLink.class);
    DynamicSet.setOf(binder(), FileWebLink.class);
    DynamicSet.setOf(binder(), FileHistoryWebLink.class);
    DynamicSet.setOf(binder(), DiffWebLink.class);
    DynamicSet.setOf(binder(), ProjectWebLink.class);
    DynamicSet.setOf(binder(), BranchWebLink.class);
    DynamicSet.setOf(binder(), TagWebLink.class);
    DynamicMap.mapOf(binder(), OAuthLoginProvider.class);
    DynamicItem.itemOf(binder(), OAuthTokenEncrypter.class);
    DynamicSet.setOf(binder(), AccountExternalIdCreator.class);
    DynamicSet.setOf(binder(), WebUiPlugin.class);
    DynamicItem.itemOf(binder(), AccountPatchReviewStore.class);
    DynamicSet.setOf(binder(), AssigneeValidationListener.class);
    DynamicSet.setOf(binder(), ActionVisitor.class);
    DynamicMap.mapOf(binder(), MailFilter.class);
    bind(MailFilter.class).annotatedWith(Exports.named("ListMailFilter")).to(ListMailFilter.class);
    factory(UploadValidators.Factory.class);
    DynamicSet.setOf(binder(), UploadValidationListener.class);
    DynamicMap.mapOf(binder(), ChangeQueryBuilder.ChangeOperatorFactory.class);
    DynamicMap.mapOf(binder(), ChangeQueryBuilder.ChangeHasOperandFactory.class);
    DynamicMap.mapOf(binder(), ChangeQueryProcessor.ChangeAttributeFactory.class);
    install(new GitwebConfig.LegacyModule(cfg));
    bind(AnonymousUser.class);
    factory(AbandonOp.Factory.class);
    factory(AccountValidator.Factory.class);
    factory(RefOperationValidators.Factory.class);
    factory(OnSubmitValidators.Factory.class);
    factory(MergeValidators.Factory.class);
    factory(ProjectConfigValidator.Factory.class);
    factory(NotesBranchUtil.Factory.class);
    factory(MergedByPushOp.Factory.class);
    factory(GitModules.Factory.class);
    factory(VersionedAuthorizedKeys.Factory.class);
    bind(AccountManager.class);
    factory(ChangeUserName.Factory.class);
    bind(new TypeLiteral<List<CommentLinkInfo>>() {
    }).toProvider(CommentLinkProvider.class).in(SINGLETON);
    bind(ReloadPluginListener.class).annotatedWith(UniqueAnnotations.create()).to(PluginConfigFactory.class);
}
#method_after
@Override
protected void configure() {
    bind(EmailExpander.class).toProvider(EmailExpanderProvider.class).in(SINGLETON);
    bind(IdGenerator.class);
    bind(RulesCache.class);
    bind(BlameCache.class).to(BlameCacheImpl.class);
    bind(Sequences.class);
    install(authModule);
    install(AccountCacheImpl.module());
    install(BatchUpdate.module());
    install(ChangeKindCacheImpl.module());
    install(ChangeFinder.module());
    install(ConflictsCacheImpl.module());
    install(GroupCacheImpl.module());
    install(GroupIncludeCacheImpl.module());
    install(MergeabilityCacheImpl.module());
    install(PatchListCacheImpl.module());
    install(ProjectCacheImpl.module());
    install(SectionSortCache.module());
    install(SubmitStrategy.module());
    install(TagCache.module());
    install(OAuthTokenCache.module());
    install(new AccessControlModule());
    install(new CmdLineParserModule());
    install(new EmailModule());
    install(new ExternalIdModule());
    install(new GitModule());
    install(new GroupModule());
    install(new NoteDbModule(cfg));
    install(new PrologModule());
    install(new ReceiveCommitsModule());
    install(new SshAddressesModule());
    install(ThreadLocalRequestContext.module());
    bind(AccountResolver.class);
    factory(AddReviewerSender.Factory.class);
    factory(DeleteReviewerSender.Factory.class);
    factory(AddKeySender.Factory.class);
    factory(CapabilityCollection.Factory.class);
    factory(ChangeData.AssistedFactory.class);
    factory(ChangeJson.AssistedFactory.class);
    factory(CreateChangeSender.Factory.class);
    factory(EmailMerge.Factory.class);
    factory(MergedSender.Factory.class);
    factory(MergeUtil.Factory.class);
    factory(PatchScriptFactory.Factory.class);
    factory(PluginUser.Factory.class);
    factory(ProjectNode.Factory.class);
    factory(ProjectState.Factory.class);
    factory(RegisterNewEmailSender.Factory.class);
    factory(ReplacePatchSetSender.Factory.class);
    factory(SetAssigneeSender.Factory.class);
    factory(VisibleRefFilter.Factory.class);
    bind(PermissionCollection.Factory.class);
    bind(AccountVisibility.class).toProvider(AccountVisibilityProvider.class).in(SINGLETON);
    factory(ProjectOwnerGroupsProvider.Factory.class);
    factory(SubmitRuleEvaluator.Factory.class);
    bind(AuthBackend.class).to(UniversalAuthBackend.class).in(SINGLETON);
    DynamicSet.setOf(binder(), AuthBackend.class);
    bind(GroupControl.Factory.class).in(SINGLETON);
    bind(GroupControl.GenericFactory.class).in(SINGLETON);
    bind(FileTypeRegistry.class).to(MimeUtilFileTypeRegistry.class);
    bind(ToolsCatalog.class);
    bind(EventFactory.class);
    bind(TransferConfig.class);
    bind(GcConfig.class);
    bind(ChangeCleanupConfig.class);
    bind(AccountDeactivator.class);
    bind(ApprovalsUtil.class);
    bind(SoyTofu.class).annotatedWith(MailTemplates.class).toProvider(MailSoyTofuProvider.class);
    bind(FromAddressGenerator.class).toProvider(FromAddressGeneratorProvider.class).in(SINGLETON);
    bind(Boolean.class).annotatedWith(DisableReverseDnsLookup.class).toProvider(DisableReverseDnsLookupProvider.class).in(SINGLETON);
    bind(PatchSetInfoFactory.class);
    bind(IdentifiedUser.GenericFactory.class).in(SINGLETON);
    bind(AccountControl.Factory.class);
    install(new AuditModule());
    bind(UiActions.class);
    install(new com.google.gerrit.server.access.Module());
    install(new com.google.gerrit.server.account.Module());
    install(new com.google.gerrit.server.api.Module());
    install(new com.google.gerrit.server.change.Module());
    install(new com.google.gerrit.server.config.Module());
    install(new com.google.gerrit.server.group.Module());
    install(new com.google.gerrit.server.project.Module());
    bind(GitReferenceUpdated.class);
    DynamicMap.mapOf(binder(), new TypeLiteral<Cache<?, ?>>() {
    });
    DynamicSet.setOf(binder(), CacheRemovalListener.class);
    DynamicMap.mapOf(binder(), CapabilityDefinition.class);
    DynamicSet.setOf(binder(), GitReferenceUpdatedListener.class);
    DynamicSet.setOf(binder(), AssigneeChangedListener.class);
    DynamicSet.setOf(binder(), ChangeAbandonedListener.class);
    DynamicSet.setOf(binder(), CommentAddedListener.class);
    DynamicSet.setOf(binder(), HashtagsEditedListener.class);
    DynamicSet.setOf(binder(), ChangeMergedListener.class);
    DynamicSet.setOf(binder(), ChangeRestoredListener.class);
    DynamicSet.setOf(binder(), ChangeRevertedListener.class);
    DynamicSet.setOf(binder(), ReviewerAddedListener.class);
    DynamicSet.setOf(binder(), ReviewerDeletedListener.class);
    DynamicSet.setOf(binder(), VoteDeletedListener.class);
    DynamicSet.setOf(binder(), RevisionCreatedListener.class);
    DynamicSet.setOf(binder(), TopicEditedListener.class);
    DynamicSet.setOf(binder(), AgreementSignupListener.class);
    DynamicSet.setOf(binder(), PluginEventListener.class);
    DynamicSet.setOf(binder(), ReceivePackInitializer.class);
    DynamicSet.setOf(binder(), PostReceiveHook.class);
    DynamicSet.setOf(binder(), PreUploadHook.class);
    DynamicSet.setOf(binder(), PostUploadHook.class);
    DynamicSet.setOf(binder(), AccountIndexedListener.class);
    DynamicSet.setOf(binder(), ChangeIndexedListener.class);
    DynamicSet.setOf(binder(), GroupIndexedListener.class);
    DynamicSet.setOf(binder(), ProjectIndexedListener.class);
    DynamicSet.setOf(binder(), NewProjectCreatedListener.class);
    DynamicSet.setOf(binder(), ProjectDeletedListener.class);
    DynamicSet.setOf(binder(), GarbageCollectorListener.class);
    DynamicSet.setOf(binder(), HeadUpdatedListener.class);
    DynamicSet.setOf(binder(), UsageDataPublishedListener.class);
    DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(ReindexAfterRefUpdate.class);
    DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(ProjectConfigEntry.UpdateChecker.class);
    DynamicSet.setOf(binder(), EventListener.class);
    DynamicSet.bind(binder(), EventListener.class).to(EventsMetrics.class);
    DynamicSet.setOf(binder(), UserScopedEventListener.class);
    DynamicSet.setOf(binder(), CommitValidationListener.class);
    DynamicSet.setOf(binder(), ChangeMessageModifier.class);
    DynamicSet.setOf(binder(), RefOperationValidationListener.class);
    DynamicSet.setOf(binder(), OnSubmitValidationListener.class);
    DynamicSet.setOf(binder(), MergeValidationListener.class);
    DynamicSet.setOf(binder(), ProjectCreationValidationListener.class);
    DynamicSet.setOf(binder(), GroupCreationValidationListener.class);
    DynamicSet.setOf(binder(), HashtagValidationListener.class);
    DynamicSet.setOf(binder(), OutgoingEmailValidationListener.class);
    DynamicItem.itemOf(binder(), AvatarProvider.class);
    DynamicSet.setOf(binder(), LifecycleListener.class);
    DynamicSet.setOf(binder(), TopMenu.class);
    DynamicSet.setOf(binder(), MessageOfTheDay.class);
    DynamicMap.mapOf(binder(), DownloadScheme.class);
    DynamicMap.mapOf(binder(), DownloadCommand.class);
    DynamicMap.mapOf(binder(), CloneCommand.class);
    DynamicMap.mapOf(binder(), ReviewerSuggestion.class);
    DynamicSet.setOf(binder(), ExternalIncludedIn.class);
    DynamicMap.mapOf(binder(), ProjectConfigEntry.class);
    DynamicSet.setOf(binder(), PatchSetWebLink.class);
    DynamicSet.setOf(binder(), ParentWebLink.class);
    DynamicSet.setOf(binder(), FileWebLink.class);
    DynamicSet.setOf(binder(), FileHistoryWebLink.class);
    DynamicSet.setOf(binder(), DiffWebLink.class);
    DynamicSet.setOf(binder(), ProjectWebLink.class);
    DynamicSet.setOf(binder(), BranchWebLink.class);
    DynamicSet.setOf(binder(), TagWebLink.class);
    DynamicMap.mapOf(binder(), OAuthLoginProvider.class);
    DynamicItem.itemOf(binder(), OAuthTokenEncrypter.class);
    DynamicSet.setOf(binder(), AccountExternalIdCreator.class);
    DynamicSet.setOf(binder(), WebUiPlugin.class);
    DynamicItem.itemOf(binder(), AccountPatchReviewStore.class);
    DynamicSet.setOf(binder(), AssigneeValidationListener.class);
    DynamicSet.setOf(binder(), ActionVisitor.class);
    DynamicItem.itemOf(binder(), MergeSuperSetComputation.class);
    DynamicItem.itemOf(binder(), ProjectNameLockManager.class);
    DynamicMap.mapOf(binder(), MailFilter.class);
    bind(MailFilter.class).annotatedWith(Exports.named("ListMailFilter")).to(ListMailFilter.class);
    factory(UploadValidators.Factory.class);
    DynamicSet.setOf(binder(), UploadValidationListener.class);
    DynamicMap.mapOf(binder(), ChangeQueryBuilder.ChangeOperatorFactory.class);
    DynamicMap.mapOf(binder(), ChangeQueryBuilder.ChangeHasOperandFactory.class);
    DynamicMap.mapOf(binder(), ChangeQueryProcessor.ChangeAttributeFactory.class);
    install(new GitwebConfig.LegacyModule(cfg));
    bind(AnonymousUser.class);
    factory(AbandonOp.Factory.class);
    factory(AccountMergeValidator.Factory.class);
    factory(RefOperationValidators.Factory.class);
    factory(OnSubmitValidators.Factory.class);
    factory(MergeValidators.Factory.class);
    factory(ProjectConfigValidator.Factory.class);
    factory(NotesBranchUtil.Factory.class);
    factory(MergedByPushOp.Factory.class);
    factory(GitModules.Factory.class);
    factory(VersionedAuthorizedKeys.Factory.class);
    bind(AccountManager.class);
    factory(ChangeUserName.Factory.class);
    bind(new TypeLiteral<List<CommentLinkInfo>>() {
    }).toProvider(CommentLinkProvider.class).in(SINGLETON);
    bind(ReloadPluginListener.class).annotatedWith(UniqueAnnotations.create()).to(PluginConfigFactory.class);
}
#end_block

#method_before
@Override
protected void onExit(int rc) {
    eventListenerRegistration.remove();
    synchronized (taskLock) {
        done = true;
    }
    super.onExit(rc);
}
#method_after
@Override
protected void onExit(int rc) {
    removeEventListenerRegistration();
    synchronized (taskLock) {
        done = true;
    }
    super.onExit(rc);
}
#end_block

#method_before
@Override
public void destroy() {
    eventListenerRegistration.remove();
    final boolean exit;
    synchronized (taskLock) {
        if (task != null) {
            task.cancel(true);
            // onExit will be invoked by the task cancellation.
            exit = false;
        } else {
            exit = !done;
        }
        done = true;
    }
    if (exit) {
        onExit(0);
    }
}
#method_after
@Override
public void destroy() {
    removeEventListenerRegistration();
    final boolean exit;
    synchronized (taskLock) {
        if (task != null) {
            task.cancel(true);
            // onExit will be invoked by the task cancellation.
            exit = false;
        } else {
            exit = !done;
        }
        done = true;
    }
    if (exit) {
        onExit(0);
    }
}
#end_block

#method_before
private void writeEvents() {
    int processed = 0;
    while (processed < BATCH_SIZE) {
        if (Thread.interrupted() || stdout.checkError()) {
            // The other side either requested a shutdown by calling our
            // destroy() above, or it closed the stream and is no longer
            // accepting output. Either way terminate this instance.
            // 
            eventListenerRegistration.remove();
            flush();
            onExit(0);
            return;
        }
        if (dropped) {
            write(new DroppedOutputEvent());
            dropped = false;
        }
        final Event event = poll();
        if (event == null) {
            break;
        }
        write(event);
        processed++;
    }
    flush();
    if (BATCH_SIZE <= processed) {
        // 
        synchronized (taskLock) {
            task = pool.submit(writer);
        }
    }
}
#method_after
private void writeEvents() {
    int processed = 0;
    while (processed < BATCH_SIZE) {
        if (Thread.interrupted() || stdout.checkError()) {
            // The other side either requested a shutdown by calling our
            // destroy() above, or it closed the stream and is no longer
            // accepting output. Either way terminate this instance.
            // 
            removeEventListenerRegistration();
            flush();
            onExit(0);
            return;
        }
        if (dropped) {
            write(new DroppedOutputEvent());
            dropped = false;
        }
        final Event event = poll();
        if (event == null) {
            break;
        }
        write(event);
        processed++;
    }
    flush();
    if (BATCH_SIZE <= processed) {
        // 
        synchronized (taskLock) {
            task = pool.submit(writer);
        }
    }
}
#end_block

#method_before
private Injector createSysInjector() {
    final List<Module> modules = new ArrayList<>();
    modules.add(SchemaVersionCheck.module());
    modules.add(new DropWizardMetricMaker.RestModule());
    modules.add(new LogFileCompressor.Module());
    // Plugin module needs to be inserted *before* the index module.
    // There is the concept of LifecycleModule, in Gerrit's own extension
    // to Guice, which has these:
    // listener().to(SomeClassImplementingLifecycleListener.class);
    // and the start() methods of each such listener are executed in the
    // order they are declared.
    // Makes sure that PluginLoader.start() is executed before the
    // LuceneIndexModule.start() so that plugins get loaded and the respective
    // Guice modules installed so that the on-line reindexing will happen
    // with the proper classes (e.g. group backends, custom Prolog
    // predicates) and the associated rules ready to be evaluated.
    modules.add(new PluginModule());
    // Index module shutdown must happen before work queue shutdown, otherwise
    // work queue can get stuck waiting on index futures that will never return.
    modules.add(createIndexModule());
    modules.add(new WorkQueue.Module());
    modules.add(new StreamEventsApiListener.Module());
    modules.add(new EventBroker.Module());
    modules.add(inMemoryTest ? new InMemoryAccountPatchReviewStore.Module() : new JdbcAccountPatchReviewStore.Module(config));
    modules.add(new ReceiveCommitsExecutorModule());
    modules.add(new DiffExecutorModule());
    modules.add(new MimeUtil2Module());
    modules.add(cfgInjector.getInstance(GerritGlobalModule.class));
    modules.add(new SearchingChangeCacheImpl.Module(slave));
    modules.add(new InternalAccountDirectory.Module());
    modules.add(new DefaultPermissionBackendModule());
    modules.add(new DefaultCacheFactory.Module());
    modules.add(cfgInjector.getInstance(MailReceiver.Module.class));
    if (emailModule != null) {
        modules.add(emailModule);
    } else {
        modules.add(new SmtpEmailSender.Module());
    }
    modules.add(new SignedTokenEmailTokenVerifier.Module());
    modules.add(new PluginRestApiModule());
    modules.add(new RestCacheAdminModule());
    modules.add(new GpgModule(config));
    modules.add(new StartupChecks.Module());
    if (MoreObjects.firstNonNull(httpd, true)) {
        modules.add(new CanonicalWebUrlModule() {

            @Override
            protected Class<? extends Provider<String>> provider() {
                return HttpCanonicalWebUrlProvider.class;
            }
        });
    } else {
        modules.add(new CanonicalWebUrlModule() {

            @Override
            protected Class<? extends Provider<String>> provider() {
                return CanonicalWebUrlProvider.class;
            }
        });
    }
    if (sshd) {
        modules.add(SshKeyCacheImpl.module());
    } else {
        modules.add(NoSshKeyCache.module());
    }
    modules.add(new AbstractModule() {

        @Override
        protected void configure() {
            bind(GerritOptions.class).toInstance(new GerritOptions(config, headless, slave, polyGerritDev));
            if (inMemoryTest) {
                bind(String.class).annotatedWith(SecureStoreClassName.class).toInstance(DefaultSecureStore.class.getName());
                bind(SecureStore.class).toProvider(SecureStoreProvider.class);
            }
        }
    });
    modules.add(new GarbageCollectionModule());
    if (!slave) {
        modules.add(new ChangeCleanupRunner.Module());
    }
    modules.addAll(LibModuleLoader.loadModules(cfgInjector));
    if (migrateToNoteDb()) {
        modules.add(new OnlineNoteDbMigrator.Module());
    }
    if (testSysModule != null) {
        modules.add(testSysModule);
    }
    return cfgInjector.createChildInjector(modules);
}
#method_after
private Injector createSysInjector() {
    final List<Module> modules = new ArrayList<>();
    modules.add(SchemaVersionCheck.module());
    modules.add(new DropWizardMetricMaker.RestModule());
    modules.add(new LogFileCompressor.Module());
    // Plugin module needs to be inserted *before* the index module.
    // There is the concept of LifecycleModule, in Gerrit's own extension
    // to Guice, which has these:
    // listener().to(SomeClassImplementingLifecycleListener.class);
    // and the start() methods of each such listener are executed in the
    // order they are declared.
    // Makes sure that PluginLoader.start() is executed before the
    // LuceneIndexModule.start() so that plugins get loaded and the respective
    // Guice modules installed so that the on-line reindexing will happen
    // with the proper classes (e.g. group backends, custom Prolog
    // predicates) and the associated rules ready to be evaluated.
    modules.add(new PluginModule());
    // Index module shutdown must happen before work queue shutdown, otherwise
    // work queue can get stuck waiting on index futures that will never return.
    modules.add(createIndexModule());
    modules.add(new WorkQueue.Module());
    modules.add(new StreamEventsApiListener.Module());
    modules.add(new EventBroker.Module());
    modules.add(inMemoryTest ? new InMemoryAccountPatchReviewStore.Module() : new JdbcAccountPatchReviewStore.Module(config));
    modules.add(new ReceiveCommitsExecutorModule());
    modules.add(new DiffExecutorModule());
    modules.add(new MimeUtil2Module());
    modules.add(cfgInjector.getInstance(GerritGlobalModule.class));
    modules.add(new SearchingChangeCacheImpl.Module(slave));
    modules.add(new InternalAccountDirectory.Module());
    modules.add(new DefaultPermissionBackendModule());
    modules.add(new DefaultCacheFactory.Module());
    modules.add(cfgInjector.getInstance(MailReceiver.Module.class));
    if (emailModule != null) {
        modules.add(emailModule);
    } else {
        modules.add(new SmtpEmailSender.Module());
    }
    modules.add(new SignedTokenEmailTokenVerifier.Module());
    modules.add(new PluginRestApiModule());
    modules.add(new RestCacheAdminModule());
    modules.add(new GpgModule(config));
    modules.add(new StartupChecks.Module());
    if (MoreObjects.firstNonNull(httpd, true)) {
        modules.add(new CanonicalWebUrlModule() {

            @Override
            protected Class<? extends Provider<String>> provider() {
                return HttpCanonicalWebUrlProvider.class;
            }
        });
    } else {
        modules.add(new CanonicalWebUrlModule() {

            @Override
            protected Class<? extends Provider<String>> provider() {
                return CanonicalWebUrlProvider.class;
            }
        });
    }
    if (sshd) {
        modules.add(SshKeyCacheImpl.module());
    } else {
        modules.add(NoSshKeyCache.module());
    }
    modules.add(new AbstractModule() {

        @Override
        protected void configure() {
            bind(GerritOptions.class).toInstance(new GerritOptions(config, headless, slave, polyGerritDev));
            if (inMemoryTest) {
                bind(String.class).annotatedWith(SecureStoreClassName.class).toInstance(DefaultSecureStore.class.getName());
                bind(SecureStore.class).toProvider(SecureStoreProvider.class);
            }
        }
    });
    modules.add(new GarbageCollectionModule());
    if (!slave) {
        modules.add(new AccountDeactivator.Module());
        modules.add(new ChangeCleanupRunner.Module());
    }
    modules.addAll(LibModuleLoader.loadModules(cfgInjector));
    if (migrateToNoteDb()) {
        modules.add(new OnlineNoteDbMigrator.Module(trial));
    }
    if (testSysModule != null) {
        modules.add(testSysModule);
    }
    modules.add(new LocalMergeSuperSetComputation.Module());
    modules.add(new DefaultProjectNameLockManager.Module());
    return cfgInjector.createChildInjector(modules);
}
#end_block

#method_before
@Override
protected void configure() {
    DynamicSet.bind(binder(), AssigneeChangedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), ChangeAbandonedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), ChangeMergedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), ChangeRestoredListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), CommentAddedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), DraftPublishedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), HashtagsEditedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), NewProjectCreatedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), ReviewerAddedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), ReviewerDeletedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), RevisionCreatedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), TopicEditedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), VoteDeletedListener.class).to(StreamEventsApiListener.class);
}
#method_after
@Override
protected void configure() {
    DynamicSet.bind(binder(), AssigneeChangedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), ChangeAbandonedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), ChangeMergedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), ChangeRestoredListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), CommentAddedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), HashtagsEditedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), NewProjectCreatedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), ReviewerAddedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), ReviewerDeletedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), RevisionCreatedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), TopicEditedListener.class).to(StreamEventsApiListener.class);
    DynamicSet.bind(binder(), VoteDeletedListener.class).to(StreamEventsApiListener.class);
}
#end_block

#method_before
static <O extends Enum<O> & ListOption> EnumSet<O> fromBits(Class<O> clazz, int v) {
    EnumSet<O> r = EnumSet.noneOf(clazz);
    O[] values;
    try {
        @SuppressWarnings("unchecked")
        O[] tmp = (O[]) clazz.getMethod("values").invoke(null);
        values = tmp;
    } catch (IllegalAccessException | NoSuchMethodException | InvocationTargetException e) {
        throw new IllegalStateException(e);
    }
    for (O o : values) {
        if ((v & (1 << o.getValue())) != 0) {
            r.add(o);
            v &= ~(1 << o.getValue());
        }
        if (v == 0) {
            return r;
        }
    }
    if (v != 0) {
        throw new IllegalArgumentException("unknown " + clazz.getName() + ": " + Integer.toHexString(v));
    }
    return r;
}
#method_after
static <T extends Enum<T> & ListOption> EnumSet<T> fromBits(Class<T> clazz, int v) {
    EnumSet<T> r = EnumSet.noneOf(clazz);
    T[] values;
    try {
        @SuppressWarnings("unchecked")
        T[] tmp = (T[]) clazz.getMethod("values").invoke(null);
        values = tmp;
    } catch (IllegalAccessException | NoSuchMethodException | InvocationTargetException e) {
        throw new IllegalStateException(e);
    }
    for (T o : values) {
        if ((v & (1 << o.getValue())) != 0) {
            r.add(o);
            v &= ~(1 << o.getValue());
        }
        if (v == 0) {
            return r;
        }
    }
    if (v != 0) {
        throw new IllegalArgumentException("unknown " + clazz.getName() + ": " + Integer.toHexString(v));
    }
    return r;
}
#end_block

#method_before
@Override
public TestCheckUpdate.Builder forUpdate() {
    throw new UnsupportedOperationException("todo");
}
#method_after
@Override
public TestCheckUpdate.Builder forUpdate() {
    return TestCheckUpdate.builder(key).setCheckUpdater(testUpdate -> checksUpdate.updateCheck(key, toCheckUpdate(testUpdate)));
}
#end_block

#method_before
@Override
public CheckInfo apply(RevisionResource rsrc, CheckInput input) throws OrmException, IOException, RestApiException, PermissionBackendException, ConfigInvalidException {
    if (input == null) {
        input = new CheckInput();
    }
    if (input.checkerUuid == null) {
        throw new BadRequestException("checker UUID is required");
    }
    if (!CheckerUuid.isUuid(input.checkerUuid)) {
        throw new BadRequestException(String.format("invalid checker UUID: %s", input.checkerUuid));
    }
    permissionBackend.currentUser().check(permission);
    CheckerUuid checkerUuid = CheckerUuid.parse(input.checkerUuid);
    CheckKey key = CheckKey.create(rsrc.getProject(), rsrc.getPatchSet().getId(), checkerUuid);
    Optional<Check> check = checks.getCheck(key);
    Check updatedCheck;
    if (!check.isPresent()) {
        checkers.getChecker(checkerUuid).orElseThrow(() -> new UnprocessableEntityException(String.format("checker %s not found", checkerUuid)));
        if (input.state == null) {
            throw new BadRequestException("state is required on creation");
        }
        updatedCheck = checksUpdate.get().createCheck(key, toCheckUpdate(input));
    } else {
        updatedCheck = checksUpdate.get().updateCheck(key, toCheckUpdate(input));
    }
    return checkJsonFactory.noOptions().format(updatedCheck);
}
#method_after
@Override
public CheckInfo apply(RevisionResource rsrc, CheckInput input) throws OrmException, IOException, RestApiException, PermissionBackendException, ConfigInvalidException {
    if (input == null) {
        input = new CheckInput();
    }
    if (input.checkerUuid == null) {
        throw new BadRequestException("checker UUID is required");
    }
    if (!CheckerUuid.isUuid(input.checkerUuid)) {
        throw new BadRequestException(String.format("invalid checker UUID: %s", input.checkerUuid));
    }
    permissionBackend.currentUser().check(permission);
    CheckerUuid checkerUuid = CheckerUuid.parse(input.checkerUuid);
    CheckKey key = CheckKey.create(rsrc.getProject(), rsrc.getPatchSet().getId(), checkerUuid);
    Optional<Check> check = checks.getCheck(key);
    Check updatedCheck;
    if (!check.isPresent()) {
        checkers.getChecker(checkerUuid).orElseThrow(() -> new UnprocessableEntityException(String.format("checker %s not found", checkerUuid)));
        updatedCheck = checksUpdate.get().createCheck(key, toCheckUpdate(input));
    } else {
        updatedCheck = checksUpdate.get().updateCheck(key, toCheckUpdate(input));
    }
    return checkJsonFactory.noOptions().format(updatedCheck);
}
#end_block

#method_before
@Override
public CheckInfo get(ListChecksOption... options) throws RestApiException {
    try {
        Arrays.stream(options).forEach(getCheck::addOption);
        return getCheck.apply(checkResource);
    } catch (Exception e) {
        throw asRestApiException("Cannot update check", e);
    }
}
#method_after
@Override
public CheckInfo get(ListChecksOption... options) throws RestApiException {
    try {
        Arrays.stream(options).forEach(getCheck::addOption);
        return getCheck.apply(checkResource);
    } catch (Exception e) {
        throw asRestApiException("Cannot retrieve check", e);
    }
}
#end_block

#method_before
@Override
protected void configure() {
    final KafkaContainer kafka = new KafkaContainer();
    kafka.start();
    Config config = new Config();
    config.setString("kafka", null, "bootstrapServers", kafka.getBootstrapServers());
    config.setBoolean("kafka", "publisher", "enabled", true);
    config.setBoolean("kafka", "subscriber", "enabled", true);
    Configuration multiSiteConfig = new Configuration(config);
    bind(Configuration.class).toInstance(multiSiteConfig);
    install(new Module(multiSiteConfig));
    listener().toInstance(new KafkaStopAtShutdown(kafka));
}
#method_after
@Override
protected void configure() {
    final KafkaContainer kafka = new KafkaContainer();
    kafka.start();
    Config config = new Config();
    config.setString("kafka", null, "bootstrapServers", kafka.getBootstrapServers());
    config.setBoolean("kafka", "publisher", "enabled", true);
    config.setBoolean("kafka", "subscriber", "enabled", true);
    Configuration multiSiteConfig = new Configuration(config);
    bind(Configuration.class).toInstance(multiSiteConfig);
    install(new Module(multiSiteConfig, noteDb));
    listener().toInstance(new KafkaStopAtShutdown(kafka));
}
#end_block

#method_before
@Test
public void createChangeShouldPropagateChangeIndexAndRefUpdateStreamEvent() throws Exception {
    LinkedBlockingQueue<SourceAwareEventWrapper> droppedEventsQueue = captureDroppedEvents();
    drainQueue(droppedEventsQueue);
    PushOneCommit.Result r = createChange();
    int numberOfEvents = 3;
    if (notesMigration.commitChangeWrites()) {
        numberOfEvents = 4;
    }
    List<Event> createdChangeEvents = receiveFromQueue(droppedEventsQueue, numberOfEvents);
    assertThat(createdChangeEvents).hasSize(numberOfEvents);
    ChangeData change = r.getChange();
    assertThat(createdChangeEvents.stream().filter(e -> e.type.equals("change-index")).collect(toSet())).containsExactlyElementsIn(ImmutableList.of(createChangeIndexEvent(change.project().get(), change.getId().get(), getParentCommit(change))));
    List<String> refNames = new ArrayList<>();
    refNames.add(change.currentPatchSet().getRefName());
    if (notesMigration.commitChangeWrites()) {
        refNames.add("refs/sequences/changes");
    }
    assertThat(createdChangeEvents.stream().filter(e -> e.type.equals("ref-updated")).map(RefUpdatedEvent.class::cast).map(e -> e.getRefName()).collect(toSet())).containsExactlyElementsIn(refNames);
    PatchSetCreatedEvent patchSetCreated = createdChangeEvents.stream().filter(e -> e.type.equals("patchset-created")).map(PatchSetCreatedEvent.class::cast).findFirst().get();
    PatchSetAttribute patchSetAttribute = patchSetCreated.patchSet.get();
    PatchSet currentPatchSet = change.currentPatchSet();
    assertThat(patchSetAttribute.number).isEqualTo(currentPatchSet.getPatchSetId());
    assertThat(patchSetAttribute.revision).isEqualTo(currentPatchSet.getRevision().get());
    assertThat(patchSetAttribute.ref).isEqualTo(currentPatchSet.getRefName());
}
#method_after
@Test
public void createChangeShouldPropagateChangeIndexAndRefUpdateStreamEvent() throws Exception {
    LinkedBlockingQueue<SourceAwareEventWrapper> droppedEventsQueue = captureDroppedEvents();
    drainQueue(droppedEventsQueue);
    ChangeData change = createChange().getChange();
    String project = change.project().get();
    int changeNum = change.getId().get();
    String changeNotesRef = change.notes().getRefName();
    int patchsetNum = change.currentPatchSet().getPatchSetId();
    String patchsetRevision = change.currentPatchSet().getRevision().get();
    String patchsetRef = change.currentPatchSet().getRefName();
    Map<String, List<Event>> eventsByType = receiveEventsByType(droppedEventsQueue);
    assertThat(eventsByType.get("change-index")).containsExactly(createChangeIndexEvent(project, changeNum, getParentCommit(change)));
    assertThat(eventsByType.get("ref-updated").stream().map(e -> ((RefUpdatedEvent) e).getRefName()).collect(toSet())).containsAllOf(changeNotesRef, // 'refs/sequences/changes' not always updated thus not checked
    patchsetRef);
    List<Event> patchSetCreatedEvents = eventsByType.get("patchset-created");
    assertThat(patchSetCreatedEvents).hasSize(1);
    assertPatchSetAttributes((PatchSetCreatedEvent) patchSetCreatedEvents.get(0), patchsetNum, patchsetRevision, patchsetRef);
}
#end_block

#method_before
@Test
public void reviewChangeShouldPropagateChangeIndexAndCommentAdded() throws Exception {
    LinkedBlockingQueue<SourceAwareEventWrapper> droppedEventsQueue = captureDroppedEvents();
    PushOneCommit.Result r = createChange();
    drainQueue(droppedEventsQueue);
    ReviewInput in = ReviewInput.recommend();
    in.message = "LGTM";
    gApi.changes().id(r.getChangeId()).revision("current").review(in);
    List<Event> createdChangeEvents = receiveFromQueue(droppedEventsQueue, 2);
    assertThat(createdChangeEvents).hasSize(2);
    ChangeData change = r.getChange();
    assertThat(createdChangeEvents.stream().filter(e -> e.type.equals("change-index")).collect(toSet())).containsExactlyElementsIn(ImmutableList.of(createChangeIndexEvent(change.project().get(), change.getId().get(), getParentCommit(change))));
    CommentAddedEvent commentAdded = createdChangeEvents.stream().filter(e -> e.type.equals("comment-added")).map(CommentAddedEvent.class::cast).findFirst().get();
    assertThat(commentAdded.comment).isEqualTo("Patch Set 1: Code-Review+1\n\n" + in.message);
}
#method_after
@Test
public void reviewChangeShouldPropagateChangeIndexAndCommentAdded() throws Exception {
    LinkedBlockingQueue<SourceAwareEventWrapper> droppedEventsQueue = captureDroppedEvents();
    ChangeData change = createChange().getChange();
    String project = change.project().get();
    int changeNum = change.getId().get();
    drainQueue(droppedEventsQueue);
    ReviewInput in = ReviewInput.recommend();
    in.message = "LGTM";
    gApi.changes().id(changeNum).revision("current").review(in);
    Map<String, List<Event>> eventsByType = receiveEventsByType(droppedEventsQueue);
    assertThat(eventsByType.get("change-index")).containsExactly(createChangeIndexEvent(project, changeNum, getParentCommit(change)));
    List<Event> commentAddedEvents = eventsByType.get("comment-added");
    assertThat(commentAddedEvents).hasSize(1);
    assertThat(((CommentAddedEvent) commentAddedEvents.get(0)).comment).isEqualTo("Patch Set 1: Code-Review+1\n\n" + in.message);
}
#end_block

#method_before
private void drainQueue(LinkedBlockingQueue<SourceAwareEventWrapper> queue) throws InterruptedException {
    while (queue.poll(QUEUE_POLL_TIMEOUT_MSECS, TimeUnit.MILLISECONDS) != null) {
    // Just consume the event
    }
}
#method_after
private List<Event> drainQueue(LinkedBlockingQueue<SourceAwareEventWrapper> queue) throws InterruptedException {
    GsonProvider gsonProvider = plugin.getSysInjector().getInstance(Key.get(GsonProvider.class));
    SourceAwareEventWrapper event;
    List<Event> eventsList = new ArrayList<>();
    while ((event = queue.poll(QUEUE_POLL_TIMEOUT_MSECS, TimeUnit.MILLISECONDS)) != null) {
        eventsList.add(event.getEventBody(gsonProvider));
    }
    return eventsList;
}
#end_block

#method_before
@Override
public void onPreReceive(ReceivePack rp, Collection<ReceiveCommand> commands) {
    if (commands.stream().anyMatch(c -> c.getResult() != Result.NOT_ATTEMPTED)) {
        // pre-receive hooks
        return;
    }
    long startNanos = System.nanoTime();
    Worker w = new Worker(commands);
    try {
        w.progress.waitFor(executor.submit(scopePropagator.wrap(w)), timeoutMillis, TimeUnit.MILLISECONDS);
    } catch (ExecutionException e) {
        metrics.timeouts.increment();
        logger.atWarning().withCause(e).log("Error in ReceiveCommits while processing changes for project %s", projectState.getName());
        rp.sendError("internal error while processing changes");
        // point is very bad.
        for (ReceiveCommand c : commands) {
            if (c.getResult() == Result.NOT_ATTEMPTED) {
                c.setResult(Result.REJECTED_OTHER_REASON, "internal error");
            }
        }
    } finally {
        w.sendMessages();
    }
    long deltaNanos = System.nanoTime() - startNanos;
    int totalChanges = 0;
    if (resultChangeIds.isMagicPush()) {
        List<Change.Id> created = resultChangeIds.get(ResultChangeIds.Key.CREATED);
        metrics.changes.record(ResultChangeIds.Key.CREATED, created.size());
        List<Change.Id> replaced = resultChangeIds.get(ResultChangeIds.Key.REPLACED);
        metrics.changes.record(ResultChangeIds.Key.REPLACED, replaced.size());
        totalChanges += replaced.size() + created.size();
    } else {
        List<Change.Id> autoclosed = resultChangeIds.get(ResultChangeIds.Key.AUTOCLOSED);
        metrics.changes.record(ResultChangeIds.Key.AUTOCLOSED, autoclosed.size());
        totalChanges += autoclosed.size();
    }
    String pushType = resultChangeIds.isMagicPush() ? "CREATE_REPLACE" : ResultChangeIds.Key.AUTOCLOSED.name();
    if (totalChanges > 0) {
        metrics.latencyPerChange.record(pushType, deltaNanos / totalChanges, NANOSECONDS);
    }
    metrics.latencyPerPush.record(pushType, deltaNanos, NANOSECONDS);
}
#method_after
@Override
public void onPreReceive(ReceivePack rp, Collection<ReceiveCommand> commands) {
    if (commands.stream().anyMatch(c -> c.getResult() != Result.NOT_ATTEMPTED)) {
        // pre-receive hooks
        return;
    }
    long startNanos = System.nanoTime();
    Worker w = new Worker(commands);
    try {
        w.progress.waitFor(executor.submit(scopePropagator.wrap(w)), timeoutMillis, TimeUnit.MILLISECONDS);
    } catch (ExecutionException e) {
        metrics.timeouts.increment();
        logger.atWarning().withCause(e).log("Error in ReceiveCommits while processing changes for project %s", projectState.getName());
        rp.sendError("internal error while processing changes");
        // point is very bad.
        for (ReceiveCommand c : commands) {
            if (c.getResult() == Result.NOT_ATTEMPTED) {
                c.setResult(Result.REJECTED_OTHER_REASON, "internal error");
            }
        }
    } finally {
        w.sendMessages();
    }
    long deltaNanos = System.nanoTime() - startNanos;
    int totalChanges = 0;
    PushType pushType;
    if (resultChangeIds.isMagicPush()) {
        pushType = PushType.CREATE_REPLACE;
        List<Change.Id> created = resultChangeIds.get(ResultChangeIds.Key.CREATED);
        List<Change.Id> replaced = resultChangeIds.get(ResultChangeIds.Key.REPLACED);
        metrics.changes.record(pushType, created.size() + replaced.size());
        totalChanges = replaced.size() + created.size();
    } else {
        List<Change.Id> autoclosed = resultChangeIds.get(ResultChangeIds.Key.AUTOCLOSED);
        if (!autoclosed.isEmpty()) {
            pushType = PushType.AUTOCLOSE;
            metrics.changes.record(pushType, autoclosed.size());
            totalChanges = autoclosed.size();
        } else {
            pushType = PushType.NORMAL;
        }
    }
    if (totalChanges > 0) {
        metrics.latencyPerChange.record(pushType, deltaNanos / totalChanges, NANOSECONDS);
    }
    metrics.latencyPerPush.record(pushType, deltaNanos, NANOSECONDS);
}
#end_block

#method_before
@Override
public List<PendingChecksInfo> list(String checkerUuidString, CheckState... checkStates) throws RestApiException {
    CheckerUuid checkerUuid = CheckerUuid.tryParse(checkerUuidString).orElseThrow(() -> new BadRequestException(String.format("invalid checker UUID: %s", checkerUuidString)));
    try {
        ListPendingChecks listPendingChecks = listPendingChecksProvider.get();
        listPendingChecks.setChecker(checkerUuid);
        if (checkStates != null) {
            Stream.of(checkStates).forEach(listPendingChecks::addState);
        }
        return listPendingChecks.apply(TopLevelResource.INSTANCE);
    } catch (Exception e) {
        throw asRestApiException("Cannot list pending checks", e);
    }
}
#method_after
@Override
public List<PendingChecksInfo> list(CheckerUuid checkerUuid, CheckState... checkStates) throws RestApiException {
    try {
        ListPendingChecks listPendingChecks = listPendingChecksProvider.get();
        listPendingChecks.setChecker(checkerUuid);
        Stream.of(checkStates).forEach(listPendingChecks::addState);
        return listPendingChecks.apply(TopLevelResource.INSTANCE);
    } catch (Exception e) {
        throw asRestApiException("Cannot list pending checks", e);
    }
}
#end_block

#method_before
@Override
public List<PendingChecksInfo> listForScheme(String scheme, CheckState... checkStates) throws RestApiException {
    try {
        ListPendingChecks listPendingChecks = listPendingChecksProvider.get();
        listPendingChecks.setScheme(scheme);
        if (checkStates != null) {
            Stream.of(checkStates).forEach(listPendingChecks::addState);
        }
        return listPendingChecks.apply(TopLevelResource.INSTANCE);
    } catch (Exception e) {
        throw asRestApiException("Cannot list pending checks for scheme", e);
    }
}
#method_after
@Override
public List<PendingChecksInfo> listForScheme(String scheme, CheckState... checkStates) throws RestApiException {
    try {
        ListPendingChecks listPendingChecks = listPendingChecksProvider.get();
        listPendingChecks.setScheme(scheme);
        Stream.of(checkStates).forEach(listPendingChecks::addState);
        return listPendingChecks.apply(TopLevelResource.INSTANCE);
    } catch (Exception e) {
        throw asRestApiException("Cannot list pending checks for scheme", e);
    }
}
#end_block

#method_before
@Override
public List<PendingChecksInfo> list(String checkerUuid, CheckState... checkStates) {
    throw new NotImplementedException();
}
#method_after
@Override
public List<PendingChecksInfo> list(CheckerUuid checkerUuid, CheckState... checkStates) {
    throw new NotImplementedException();
}
#end_block

#method_before
public static LfsBackend create(String name, LfsBackendType type) {
    return new LfsBackend(name, type);
}
#method_after
public static LfsBackend create(@Nullable String name, LfsBackendType type) {
    return new LfsBackend(name, type);
}
#end_block

#method_before
public static LfsBackend createDefault(LfsBackendType type) {
    return new LfsBackend(null, type);
}
#method_after
public static LfsBackend createDefault(LfsBackendType type) {
    return create(null, type);
}
#end_block

#method_before
@Override
public String toString() {
    return toStringHelper(this).add("name", name).add("type", type).toString();
}
#method_after
@Override
public String toString() {
    return toStringHelper(this).add("name", name()).add("type", type).toString();
}
#end_block

#method_before
@Override
public int hashCode() {
    return Objects.hash(name(), type);
}
#method_after
@Override
public int hashCode() {
    return Objects.hash(name, type);
}
#end_block

#method_before
@Override
public boolean equals(Object obj) {
    if (obj instanceof LfsBackend) {
        LfsBackend other = (LfsBackend) obj;
        return Objects.equals(name(), other.name()) && type == other.type;
    }
    return false;
}
#method_after
@Override
public boolean equals(Object obj) {
    if (obj instanceof LfsBackend) {
        LfsBackend other = (LfsBackend) obj;
        return Objects.equals(name, other.name) && type == other.type;
    }
    return false;
}
#end_block

#method_before
@Override
public void execute(ItsFacade its, String itsProject, ActionRequest actionRequest, Map<String, String> properties) throws IOException {
    Optional<MarkPropertyAsReleasedVersionParameters> parameters = parametersExtractor.extract(actionRequest, properties);
    if (!parameters.isPresent()) {
        return;
    }
    jiraClient.markVersionAsReleased(itsProject, parameters.get().getPropertyValue());
}
#method_after
@Override
public void execute(ItsFacade its, String itsProject, ActionRequest actionRequest, Map<String, String> properties) throws IOException {
    Optional<MarkPropertyAsReleasedVersionParameters> parameters = parametersExtractor.extract(actionRequest, properties);
    if (!parameters.isPresent()) {
        return;
    }
    Project.NameKey projectName = new Project.NameKey(properties.get("project"));
    JiraItsServerInfo jiraItsServerInfo = serverInfoProvider.get(projectName);
    jiraClient.markVersionAsReleased(jiraItsServerInfo, itsProject, parameters.get().getPropertyValue());
}
#end_block

#method_before
@Override
protected void configure() {
    if (gerritConfig.getString(pluginName, null, "url") != null) {
        LOG.info("JIRA is configured as ITS");
        bind(ItsFacade.class).to(JiraItsFacade.class).asEagerSingleton();
        bind(ItsFacadeFactory.class).to(SingleItsServer.class);
        bind(CustomAction.class).annotatedWith(Exports.named(MarkPropertyAsReleasedVersion.ACTION_NAME)).to(MarkPropertyAsReleasedVersion.class);
        install(new ItsHookModule(pluginName, pluginCfgFactory));
    }
}
#method_after
@Override
protected void configure() {
    bind(ItsFacade.class).to(JiraItsFacade.class);
    bind(ItsFacadeFactory.class).to(JiraItsServer.class).asEagerSingleton();
    bind(ProjectConfigEntry.class).annotatedWith(Exports.named(PROJECT_CONFIG_URL_KEY)).toInstance(new JiraUrlProjectConfigEntry("Server URL"));
    bind(ProjectConfigEntry.class).annotatedWith(Exports.named(PROJECT_CONFIG_USERNAME_KEY)).toInstance(new ProjectConfigEntry("JIRA username", ""));
    bind(ProjectConfigEntry.class).annotatedWith(Exports.named(PROJECT_CONFIG_PASSWORD_KEY)).toInstance(new ProjectConfigEntry("JIRA password", ""));
    bind(ItsConfig.class);
    bind(JiraItsServerInfoProvider.class);
    bind(CustomAction.class).annotatedWith(Exports.named(MarkPropertyAsReleasedVersion.ACTION_NAME)).to(MarkPropertyAsReleasedVersion.class);
    install(new ItsHookModule(pluginName, pluginCfgFactory));
    install(JiraItsServerCacheImpl.module());
    LOG.info("JIRA is configured as ITS");
}
#end_block

#method_before
@Before
public void before() {
    its = mock(ItsFacade.class);
    jiraClient = mock(JiraClient.class);
    parametersExtractor = mock(MarkPropertyAsReleasedVersionParametersExtractor.class);
    markPropertyAsReleasedVersion = new MarkPropertyAsReleasedVersion(jiraClient, parametersExtractor);
}
#method_after
@Before
public void before() {
    its = mock(ItsFacade.class);
    JiraItsServerInfoProvider serverInfoProvider = mock(JiraItsServerInfoProvider.class);
    serverInfo = mock(JiraItsServerInfo.class);
    when(serverInfoProvider.get(new Project.NameKey(PROJECT_NAME))).thenReturn(serverInfo);
    jiraClient = mock(JiraClient.class);
    parametersExtractor = mock(MarkPropertyAsReleasedVersionParametersExtractor.class);
    markPropertyAsReleasedVersion = new MarkPropertyAsReleasedVersion(serverInfoProvider, jiraClient, parametersExtractor);
}
#end_block

#method_before
@Test
public void testHappyPath() throws IOException {
    MarkPropertyAsReleasedVersionParameters extractedParameters = mock(MarkPropertyAsReleasedVersionParameters.class);
    when(extractedParameters.getPropertyValue()).thenReturn(PROPERTY_VALUE);
    ActionRequest actionRequest = mock(ActionRequest.class);
    Map<String, String> properties = Collections.singletonMap(PROPERTY_ID, PROPERTY_VALUE);
    when(parametersExtractor.extract(actionRequest, properties)).thenReturn(Optional.of(extractedParameters));
    markPropertyAsReleasedVersion.execute(its, ITS_PROJECT, actionRequest, properties);
    verify(jiraClient).markVersionAsReleased(ITS_PROJECT, PROPERTY_VALUE);
}
#method_after
@Test
public void testHappyPath() throws IOException {
    MarkPropertyAsReleasedVersionParameters extractedParameters = mock(MarkPropertyAsReleasedVersionParameters.class);
    when(extractedParameters.getPropertyValue()).thenReturn(PROPERTY_VALUE);
    ActionRequest actionRequest = mock(ActionRequest.class);
    Map<String, String> properties = buildProperties();
    when(parametersExtractor.extract(actionRequest, properties)).thenReturn(Optional.of(extractedParameters));
    markPropertyAsReleasedVersion.execute(its, ITS_PROJECT, actionRequest, properties);
    verify(jiraClient).markVersionAsReleased(serverInfo, ITS_PROJECT, PROPERTY_VALUE);
}
#end_block

#method_before
public <T> JiraRestApi<T> get(Class<T> classOfT, String classPrefix) {
    return new JiraRestApi<>(jiraConfig.getJiraUrl(), jiraConfig.getUsername(), jiraConfig.getPassword(), classOfT, classPrefix);
}
#method_after
public <T> JiraRestApi<T> get(JiraItsServerInfo serverInfo, Class<T> classOfT, String classPrefix) {
    return new JiraRestApi<>(serverInfo.getUrl(), serverInfo.getUsername(), serverInfo.getPassword(), classOfT, classPrefix);
}
#end_block

#method_before
public JiraRestApi<JiraIssue> getIssue() {
    return get(JiraIssue.class, "/issue");
}
#method_after
public JiraRestApi<JiraIssue> getIssue(JiraItsServerInfo serverInfo) {
    return get(serverInfo, JiraIssue.class, "/issue");
}
#end_block

#method_before
public JiraRestApi<JiraServerInfo> getServerInfo() {
    return get(JiraServerInfo.class, "/serverInfo");
}
#method_after
public JiraRestApi<JiraServerInfo> getServerInfo(JiraItsServerInfo server) {
    return get(server, JiraServerInfo.class, "/serverInfo");
}
#end_block

#method_before
public JiraRestApi<JiraProject[]> getProjects() {
    return get(JiraProject[].class, "/project");
}
#method_after
public JiraRestApi<JiraProject[]> getProjects(JiraItsServerInfo serverInfo) {
    return get(serverInfo, JiraProject[].class, "/project");
}
#end_block

#method_before
public JiraRestApi<JiraVersion[]> getVersions() {
    return get(JiraVersion[].class, "/version");
}
#method_after
public JiraRestApi<JiraVersion[]> getVersions(JiraItsServerInfo serverInfo) {
    return get(serverInfo, JiraVersion[].class, "/version");
}
#end_block

#method_before
public JiraRestApi<JiraVersionsPage> getProjectVersions(String projectKey) {
    return get(JiraVersionsPage.class, "/project/" + projectKey + "/version");
}
#method_after
public JiraRestApi<JiraVersionsPage> getProjectVersions(JiraItsServerInfo serverInfo, String projectKey) {
    return get(serverInfo, JiraVersionsPage.class, "/project/" + projectKey + "/version");
}
#end_block

#method_before
public boolean issueExists(String issueKey) throws IOException {
    JiraRestApi<JiraIssue> api = apiBuilder.getIssue();
    api.doGet(issueKey, HTTP_OK, new int[] { HTTP_NOT_FOUND, HTTP_FORBIDDEN });
    Integer code = api.getResponseCode();
    switch(code) {
        case HTTP_OK:
            return true;
        case HTTP_NOT_FOUND:
            log.error("Issue {} not found", issueKey);
            return false;
        case HTTP_FORBIDDEN:
            log.error("No permission to read Issue {}", issueKey);
            return false;
        default:
            // Cannot happen due to passCodes filter
            throw new IOException("Unexpected HTTP code received:" + code.toString());
    }
}
#method_after
public boolean issueExists(JiraItsServerInfo server, String issueKey) throws IOException {
    JiraRestApi<JiraIssue> api = apiBuilder.getIssue(server);
    api.doGet(issueKey, HTTP_OK, new int[] { HTTP_NOT_FOUND, HTTP_FORBIDDEN });
    Integer code = api.getResponseCode();
    switch(code) {
        case HTTP_OK:
            return true;
        case HTTP_NOT_FOUND:
            log.error("Issue {} not found", issueKey);
            return false;
        case HTTP_FORBIDDEN:
            log.error("No permission to read Issue {}", issueKey);
            return false;
        default:
            // Cannot happen due to passCodes filter
            throw new IOException("Unexpected HTTP code received:" + code.toString());
    }
}
#end_block

#method_before
public List<JiraTransition.Item> getTransitions(String issueKey) throws IOException {
    JiraRestApi<JiraTransition> api = apiBuilder.get(JiraTransition.class, "/issue");
    return Arrays.asList(api.doGet(issueKey + "/transitions", HTTP_OK).getTransitions());
}
#method_after
public List<JiraTransition.Item> getTransitions(JiraItsServerInfo server, String issueKey) throws IOException {
    JiraRestApi<JiraTransition> api = apiBuilder.get(server, JiraTransition.class, "/issue");
    return Arrays.asList(api.doGet(issueKey + "/transitions", HTTP_OK).getTransitions());
}
#end_block

#method_before
public void addComment(String issueKey, String comment) throws IOException {
    if (issueExists(issueKey)) {
        log.debug("Trying to add comment for issue {}", issueKey);
        apiBuilder.getIssue().doPost(issueKey + "/comment", gson.toJson(new JiraComment(comment)), HTTP_CREATED);
        log.debug("Comment added to issue {}", issueKey);
    } else {
        log.error("Issue {} does not exist or no access permission", issueKey);
    }
}
#method_after
public void addComment(JiraItsServerInfo server, String issueKey, String comment) throws IOException {
    if (issueExists(server, issueKey)) {
        log.debug("Trying to add comment for issue {}", issueKey);
        apiBuilder.getIssue(server).doPost(issueKey + "/comment", gson.toJson(new JiraComment(comment)), HTTP_CREATED);
        log.debug("Comment added to issue {}", issueKey);
    } else {
        log.error("Issue {} does not exist or no access permission", issueKey);
    }
}
#end_block

#method_before
public void createVersion(String projectKey, String version) throws IOException {
    log.debug("Trying to create version {} on project {}", version, projectKey);
    JiraVersion jiraVersion = JiraVersion.builder().project(projectKey).name(version).build();
    apiBuilder.getVersions().doPost("", gson.toJson(jiraVersion), HTTP_CREATED);
    log.debug("Version {} created on project {}", version, projectKey);
}
#method_after
public void createVersion(JiraItsServerInfo server, String projectKey, String version) throws IOException {
    log.debug("Trying to create version {} on project {}", version, projectKey);
    JiraVersion jiraVersion = JiraVersion.builder().project(projectKey).name(version).build();
    apiBuilder.getVersions(server).doPost("", gson.toJson(jiraVersion), HTTP_CREATED);
    log.debug("Version {} created on project {}", version, projectKey);
}
#end_block

#method_before
public void markVersionAsReleased(String projectKey, String version) throws IOException {
    JiraVersion jiraVersion = findVersion(projectKey, version);
    if (jiraVersion == null) {
        log.error("Version {} of project {} does not exist or no access permission", version, projectKey);
        return;
    }
    log.debug("Trying to mark version {} with id {} of project {} as released", version, jiraVersion.getId(), projectKey);
    JiraVersion markAsReleased = JiraVersion.builder().released(true).releaseDate(new Date()).build();
    apiBuilder.getVersions().doPut(jiraVersion.getId(), gson.toJson(markAsReleased), HTTP_OK);
    log.debug("Version {} of project {} was marked as released", version, projectKey);
}
#method_after
public void markVersionAsReleased(JiraItsServerInfo server, String projectKey, String version) throws IOException {
    JiraVersion jiraVersion = findVersion(server, projectKey, version);
    if (jiraVersion == null) {
        log.error("Version {} of project {} does not exist or no access permission", version, projectKey);
        return;
    }
    log.debug("Trying to mark version {} with id {} of project {} as released", version, jiraVersion.getId(), projectKey);
    JiraVersion markAsReleased = JiraVersion.builder().released(true).releaseDate(new Date()).build();
    apiBuilder.getVersions(server).doPut(jiraVersion.getId(), gson.toJson(markAsReleased), HTTP_OK);
    log.debug("Version {} of project {} was marked as released", version, projectKey);
}
#end_block

#method_before
private JiraVersion findVersion(String projectKey, String version) throws IOException {
    JiraRestApi<JiraVersionsPage> api = apiBuilder.getProjectVersions(projectKey);
    JiraPageRequest pageRequest = JiraPageRequest.builder().orderBy("-sequence").build();
    JiraVersion jiraVersion = null;
    while (pageRequest != null) {
        JiraVersionsPage versionsPage = api.doGet(pageRequest.toSpec(), HTTP_OK);
        jiraVersion = versionsPage.findByName(version);
        if (jiraVersion != null) {
            break;
        }
        pageRequest = versionsPage.nextPageRequest(pageRequest);
    }
    return jiraVersion;
}
#method_after
private JiraVersion findVersion(JiraItsServerInfo server, String projectKey, String version) throws IOException {
    JiraRestApi<JiraVersionsPage> api = apiBuilder.getProjectVersions(server, projectKey);
    JiraPageRequest pageRequest = JiraPageRequest.builder().orderBy("-sequence").build();
    JiraVersion jiraVersion = null;
    while (pageRequest != null) {
        JiraVersionsPage versionsPage = api.doGet(pageRequest.toSpec(), HTTP_OK);
        jiraVersion = versionsPage.findByName(version);
        if (jiraVersion != null) {
            break;
        }
        pageRequest = versionsPage.nextPageRequest(pageRequest);
    }
    return jiraVersion;
}
#end_block

#method_before
public boolean doTransition(String issueKey, String transition) throws IOException, InvalidTransitionException {
    log.debug("Making transition to {} for {}", transition, issueKey);
    JiraTransition.Item t = getTransitionByName(issueKey, transition);
    if (t == null) {
        throw new InvalidTransitionException("Action " + transition + " not executable on issue " + issueKey);
    }
    log.debug("Transition issue {} to '{}' ({})", issueKey, transition, t.getId());
    return apiBuilder.getIssue().doPost(issueKey + "/transitions", gson.toJson(new JiraTransition(t)), HTTP_NO_CONTENT);
}
#method_after
public boolean doTransition(JiraItsServerInfo server, String issueKey, String transition) throws IOException, InvalidTransitionException {
    log.debug("Making transition to {} for {}", transition, issueKey);
    JiraTransition.Item t = getTransitionByName(server, issueKey, transition);
    if (t == null) {
        throw new InvalidTransitionException("Action " + transition + " not executable on issue " + issueKey);
    }
    log.debug("Transition issue {} to '{}' ({})", issueKey, transition, t.getId());
    return apiBuilder.getIssue(server).doPost(issueKey + "/transitions", gson.toJson(new JiraTransition(t)), HTTP_NO_CONTENT);
}
#end_block

#method_before
public JiraServerInfo sysInfo() throws IOException {
    return apiBuilder.getServerInfo().doGet("", HTTP_OK);
}
#method_after
public JiraServerInfo sysInfo(JiraItsServerInfo server) throws IOException {
    return apiBuilder.getServerInfo(server).doGet("", HTTP_OK);
}
#end_block

#method_before
public JiraProject[] getProjects() throws IOException {
    return apiBuilder.getProjects().doGet("", HTTP_OK);
}
#method_after
public JiraProject[] getProjects(JiraItsServerInfo server) throws IOException {
    return apiBuilder.getProjects(server).doGet("", HTTP_OK);
}
#end_block

#method_before
private JiraTransition.Item getTransitionByName(String issueKey, String transition) throws IOException {
    for (JiraTransition.Item t : getTransitions(issueKey)) {
        if (transition.equals(t.getName())) {
            return t;
        }
    }
    return null;
}
#method_after
private JiraTransition.Item getTransitionByName(JiraItsServerInfo server, String issueKey, String transition) throws IOException {
    for (JiraTransition.Item t : getTransitions(server, issueKey)) {
        if (transition.equals(t.getName())) {
            return t;
        }
    }
    return null;
}
#end_block

#method_before
public String healthCheckAccess() throws IOException {
    sysInfo();
    String result = "{\"status\"=\"ok\"}";
    log.debug("Health check on access result: {}", result);
    return result;
}
#method_after
public String healthCheckAccess(JiraItsServerInfo server) throws IOException {
    sysInfo(server);
    String result = "{\"status\"=\"ok\"}";
    log.debug("Health check on access result: {}", result);
    return result;
}
#end_block

#method_before
public String healthCheckSysinfo() throws IOException {
    JiraServerInfo info = sysInfo();
    String result = "{\"status\"=\"ok\",\"system\"=\"Jira\",\"version\"=\"" + info.getVersion() + "\",\"url\"=\"" + info.getBaseUri() + "\",\"build\"=\"" + info.getBuildNumber() + "\"}";
    log.debug("Health check on sysinfo result: {}", result);
    return result;
}
#method_after
public String healthCheckSysinfo(JiraItsServerInfo server) throws IOException {
    JiraServerInfo info = sysInfo(server);
    String result = "{\"status\"=\"ok\",\"system\"=\"Jira\",\"version\"=\"" + info.getVersion() + "\",\"url\"=\"" + info.getBaseUri() + "\",\"build\"=\"" + info.getBuildNumber() + "\"}";
    log.debug("Health check on sysinfo result: {}", result);
    return result;
}
#end_block

#method_before
public void testChangeAttribute() {
    AccountAttribute owner = new AccountAttribute();
    owner.email = "testEmail";
    owner.name = "testName";
    owner.username = "testUsername";
    ChangeAttribute changeAttribute = new ChangeAttribute();
    changeAttribute.branch = "testBranch";
    changeAttribute.topic = "testTopic";
    changeAttribute.subject = "testSubject";
    changeAttribute.id = "testId";
    changeAttribute.number = 4711;
    changeAttribute.url = "http://www.example.org/test";
    changeAttribute.owner = owner;
    changeAttribute.commitMessage = "Commit Message";
    changeAttribute.status = Change.Status.NEW;
    expect(facade.createLinkForWebui("http://www.example.org/test", "http://www.example.org/test")).andReturn("http://www.example.org/test");
    replayMocks();
    PropertyAttributeExtractor extractor = injector.getInstance(PropertyAttributeExtractor.class);
    Map<String, String> actual = extractor.extractFrom(changeAttribute);
    ImmutableMap<String, String> expected = new ImmutableMap.Builder<String, String>().put("branch", "testBranch").put("topic", "testTopic").put("subject", "testSubject").put("escapedSubject", "testSubject").put("changeId", "testId").put("changeNumber", "4711").put("changeUrl", "http://www.example.org/test").put("status", Change.Status.NEW.name()).put("ownerEmail", "testEmail").put("ownerName", "testName").put("ownerUsername", "testUsername").put("commitMessage", "Commit Message").put("formatChangeUrl", "http://www.example.org/test").build();
    assertEquals("Properties do not match", expected, actual);
}
#method_after
public void testChangeAttribute() {
    AccountAttribute owner = new AccountAttribute();
    owner.email = "testEmail";
    owner.name = "testName";
    owner.username = "testUsername";
    ChangeAttribute changeAttribute = new ChangeAttribute();
    changeAttribute.branch = "testBranch";
    changeAttribute.topic = "testTopic";
    changeAttribute.subject = "testSubject";
    changeAttribute.id = "testId";
    changeAttribute.number = 4711;
    changeAttribute.url = "http://www.example.org/test";
    changeAttribute.owner = owner;
    changeAttribute.commitMessage = "Commit Message";
    changeAttribute.status = Change.Status.NEW;
    expect(facade.createLinkForWebui("http://www.example.org/test", "http://www.example.org/test")).andReturn("http://www.example.org/test");
    replayMocks();
    PropertyAttributeExtractor extractor = injector.getInstance(PropertyAttributeExtractor.class);
    Map<String, String> actual = extractor.extractFrom(changeAttribute);
    ImmutableMap<String, String> expected = new ImmutableMap.Builder<String, String>().put("branch", "testBranch").put("topic", "testTopic").put("subject", "testSubject").put("escapedSubject", "testSubject").put("changeId", "testId").put("changeNumber", "4711").put("changeUrl", "http://www.example.org/test").put("status", Change.Status.NEW.name()).put("ownerEmail", "testEmail").put("ownerName", "testName").put("ownerUsername", "testUsername").put("commitMessage", "Commit Message").put("formatChangeUrl", "http://www.example.org/test").put("private", "false").put("wip", "false").build();
    assertEquals("Properties do not match", expected, actual);
}
#end_block

#method_before
public void testChangeAttributeFull() {
    AccountAttribute owner = new AccountAttribute();
    owner.email = "testEmail";
    owner.name = "testName";
    owner.username = "testUsername";
    ChangeAttribute changeAttribute = new ChangeAttribute();
    changeAttribute.branch = "testBranch";
    changeAttribute.topic = "testTopic";
    changeAttribute.subject = "testSubject";
    changeAttribute.id = "testId";
    changeAttribute.number = 4711;
    changeAttribute.url = "http://www.example.org/test";
    changeAttribute.status = Status.ABANDONED;
    changeAttribute.owner = owner;
    changeAttribute.commitMessage = "Commit Message";
    expect(facade.createLinkForWebui("http://www.example.org/test", "http://www.example.org/test")).andReturn("http://www.example.org/test");
    replayMocks();
    PropertyAttributeExtractor extractor = injector.getInstance(PropertyAttributeExtractor.class);
    Map<String, String> actual = extractor.extractFrom(changeAttribute);
    ImmutableMap<String, String> expected = new ImmutableMap.Builder<String, String>().put("branch", "testBranch").put("topic", "testTopic").put("subject", "testSubject").put("escapedSubject", "testSubject").put("changeId", "testId").put("changeNumber", "4711").put("changeUrl", "http://www.example.org/test").put("status", Change.Status.ABANDONED.name()).put("ownerEmail", "testEmail").put("ownerName", "testName").put("ownerUsername", "testUsername").put("commitMessage", "Commit Message").put("formatChangeUrl", "http://www.example.org/test").build();
    assertEquals("Properties do not match", expected, actual);
}
#method_after
public void testChangeAttributeFull() {
    AccountAttribute owner = new AccountAttribute();
    owner.email = "testEmail";
    owner.name = "testName";
    owner.username = "testUsername";
    ChangeAttribute changeAttribute = new ChangeAttribute();
    changeAttribute.branch = "testBranch";
    changeAttribute.topic = "testTopic";
    changeAttribute.subject = "testSubject";
    changeAttribute.id = "testId";
    changeAttribute.number = 4711;
    changeAttribute.url = "http://www.example.org/test";
    changeAttribute.status = Status.ABANDONED;
    changeAttribute.owner = owner;
    changeAttribute.commitMessage = "Commit Message";
    expect(facade.createLinkForWebui("http://www.example.org/test", "http://www.example.org/test")).andReturn("http://www.example.org/test");
    replayMocks();
    PropertyAttributeExtractor extractor = injector.getInstance(PropertyAttributeExtractor.class);
    Map<String, String> actual = extractor.extractFrom(changeAttribute);
    ImmutableMap<String, String> expected = new ImmutableMap.Builder<String, String>().put("branch", "testBranch").put("topic", "testTopic").put("subject", "testSubject").put("escapedSubject", "testSubject").put("changeId", "testId").put("changeNumber", "4711").put("changeUrl", "http://www.example.org/test").put("status", Change.Status.ABANDONED.name()).put("ownerEmail", "testEmail").put("ownerName", "testName").put("ownerUsername", "testUsername").put("commitMessage", "Commit Message").put("formatChangeUrl", "http://www.example.org/test").put("private", "false").put("wip", "false").build();
    assertEquals("Properties do not match", expected, actual);
}
#end_block

#method_before
public void testRefUpdateAttribute() {
    RefUpdateAttribute refUpdateAttribute = new RefUpdateAttribute();
    refUpdateAttribute.newRev = "1234567891123456789212345678931234567894";
    refUpdateAttribute.oldRev = "9876543211987654321298765432139876543214";
    refUpdateAttribute.refName = "refs/heads/master";
    replayMocks();
    PropertyAttributeExtractor extractor = injector.getInstance(PropertyAttributeExtractor.class);
    Map<String, String> actual = extractor.extractFrom(refUpdateAttribute);
    ImmutableMap<String, String> expected = new ImmutableMap.Builder<String, String>().put("revision", "1234567891123456789212345678931234567894").put("revisionOld", "9876543211987654321298765432139876543214").put("ref", "refs/heads/master").put("refShort", "master").put("refGroup", "refs/heads/").build();
    assertEquals("Properties do not match", expected, actual);
}
#method_after
public void testRefUpdateAttribute() {
    RefUpdateAttribute refUpdateAttribute = new RefUpdateAttribute();
    refUpdateAttribute.newRev = "1234567891123456789212345678931234567894";
    refUpdateAttribute.oldRev = "9876543211987654321298765432139876543214";
    refUpdateAttribute.refName = "refs/heads/master";
    replayMocks();
    PropertyAttributeExtractor extractor = injector.getInstance(PropertyAttributeExtractor.class);
    Map<String, String> actual = extractor.extractFrom(refUpdateAttribute);
    ImmutableMap<String, String> expected = new ImmutableMap.Builder<String, String>().put("revision", "1234567891123456789212345678931234567894").put("revisionOld", "9876543211987654321298765432139876543214").put("ref", "refs/heads/master").put("refSuffix", "master").put("refPrefix", "refs/heads/").build();
    assertEquals("Properties do not match", expected, actual);
}
#end_block

#method_before
Map<String, String> extractFrom(ChangeAttribute changeAttribute) {
    return ImmutableMap.<String, String>builder().put("branch", changeAttribute.branch).put("topic", changeAttribute.topic != null ? changeAttribute.topic : "").put("subject", changeAttribute.subject).put("escapedSubject", StringEscapeUtils.escapeJava(changeAttribute.subject)).put("commitMessage", changeAttribute.commitMessage).put("changeId", changeAttribute.id).put("changeNumber", String.valueOf(changeAttribute.number)).put("changeUrl", changeAttribute.url).put("formatChangeUrl", its.createLinkForWebui(changeAttribute.url, changeAttribute.url)).put("status", changeAttribute.status != null ? changeAttribute.status.toString() : "").putAll(extractFrom(changeAttribute.owner, "owner")).build();
}
#method_after
Map<String, String> extractFrom(ChangeAttribute changeAttribute) {
    return ImmutableMap.<String, String>builder().put("branch", changeAttribute.branch).put("topic", changeAttribute.topic != null ? changeAttribute.topic : "").put("subject", changeAttribute.subject).put("escapedSubject", StringEscapeUtils.escapeJava(changeAttribute.subject)).put("commitMessage", changeAttribute.commitMessage).put("changeId", changeAttribute.id).put("changeNumber", String.valueOf(changeAttribute.number)).put("changeUrl", changeAttribute.url).put("formatChangeUrl", its.createLinkForWebui(changeAttribute.url, changeAttribute.url)).put("status", changeAttribute.status != null ? changeAttribute.status.toString() : "").put("private", changeAttribute.isPrivate != null ? changeAttribute.isPrivate.toString() : "false").put("wip", changeAttribute.wip != null ? changeAttribute.wip.toString() : "false").putAll(extractFrom(changeAttribute.owner, "owner")).build();
}
#end_block

#method_before
Map<String, String> extractFrom(RefUpdateAttribute refUpdateAttribute) {
    String refName = refUpdateAttribute.refName;
    String refShortName = RefNames.shortName(refName);
    return ImmutableMap.<String, String>builder().put("revision", refUpdateAttribute.newRev).put("revisionOld", refUpdateAttribute.oldRev).put("ref", refUpdateAttribute.refName).put("refShort", refShortName).put("refGroup", refName.substring(0, refName.length() - refShortName.length())).build();
}
#method_after
Map<String, String> extractFrom(RefUpdateAttribute refUpdateAttribute) {
    String refName = refUpdateAttribute.refName;
    String refShortName = RefNames.shortName(refName);
    return ImmutableMap.<String, String>builder().put("revision", refUpdateAttribute.newRev).put("revisionOld", refUpdateAttribute.oldRev).put("ref", refUpdateAttribute.refName).put("refSuffix", refShortName).put("refPrefix", refName.substring(0, refName.length() - refShortName.length())).build();
}
#end_block

#method_before
@Override
public String healthCheck(Check check) throws IOException {
    return execute(() -> {
        if (check.equals(Check.ACCESS)) {
            return jiraClient.healthCheckAccess();
        }
        return jiraClient.healthCheckSysinfo();
    });
}
#method_after
@Override
public String healthCheck(Check check) throws IOException {
    return execute(() -> {
        if (check.equals(Check.ACCESS)) {
            return jiraClient.healthCheckAccess(getJiraServerInstance());
        }
        return jiraClient.healthCheckSysinfo(getJiraServerInstance());
    });
}
#end_block

#method_before
@Override
public void addComment(String issueKey, String comment) throws IOException {
    execute(() -> {
        log.debug("Adding comment {} to issue {}", comment, issueKey);
        jiraClient.addComment(issueKey, comment);
        log.debug("Added comment {} to issue {}", comment, issueKey);
        return issueKey;
    });
}
#method_after
@Override
public void addComment(String issueKey, String comment) throws IOException {
    execute(() -> {
        log.debug("Adding comment {} to issue {}", comment, issueKey);
        jiraClient.addComment(getJiraServerInstance(), issueKey, comment);
        log.debug("Added comment {} to issue {}", comment, issueKey);
        return issueKey;
    });
}
#end_block

#method_before
@Override
public void addValueToField(String issueKey, String value, String fieldId) throws IOException {
    execute(() -> {
        log.debug("Adding value {} to field {} on issue {}", value, fieldId, issueKey);
        jiraClient.addValueToField(issueKey, value, fieldId);
        return issueKey;
    });
}
#method_after
@Override
public void addValueToField(String issueKey, String value, String fieldId) throws IOException {
    execute(() -> {
        log.debug("Adding value {} to field {} on issue {}", value, fieldId, issueKey);
        jiraClient.addValueToField(itsServerInfo, issueKey, value, fieldId);
        // No value to return
        return null;
    });
}
#end_block

#method_before
private void doPerformAction(String issueKey, String actionName) throws IOException, InvalidTransitionException {
    log.debug("Trying to perform action: {} on issue {}", actionName, issueKey);
    boolean ret = jiraClient.doTransition(issueKey, actionName);
    if (ret) {
        log.debug("Action {} successful on Issue {}", actionName, issueKey);
    } else {
        log.debug("Action {} on Issue {} not possible", actionName, issueKey);
    }
}
#method_after
private void doPerformAction(String issueKey, String actionName) throws IOException, InvalidTransitionException {
    log.debug("Trying to perform action: {} on issue {}", actionName, issueKey);
    boolean ret = jiraClient.doTransition(getJiraServerInstance(), issueKey, actionName);
    if (ret) {
        log.debug("Action {} successful on Issue {}", actionName, issueKey);
    } else {
        log.debug("Action {} on Issue {} not possible", actionName, issueKey);
    }
}
#end_block

#method_before
@Override
public boolean exists(String issueKey) throws IOException {
    return execute(() -> jiraClient.issueExists(issueKey));
}
#method_after
@Override
public boolean exists(String issueKey) throws IOException {
    return execute(() -> jiraClient.issueExists(getJiraServerInstance(), issueKey));
}
#end_block

#method_before
public boolean issueExists(String issueKey) throws IOException {
    JiraRestApi<JiraIssue> api = apiBuilder.getIssue();
    api.doGet(issueKey, HTTP_OK, new int[] { HTTP_NOT_FOUND, HTTP_FORBIDDEN });
    Integer code = api.getResponseCode();
    switch(code) {
        case HTTP_OK:
            return true;
        case HTTP_NOT_FOUND:
            log.error("Issue {} not found", issueKey);
            return false;
        case HTTP_FORBIDDEN:
            log.error("No permission to read Issue {}", issueKey);
            return false;
        default:
            // Cannot happen due to passCodes filter
            throw new IOException("Unexpected HTTP code received:" + code.toString());
    }
}
#method_after
public boolean issueExists(JiraItsServerInfo server, String issueKey) throws IOException {
    JiraRestApi<JiraIssue> api = apiBuilder.getIssue(server);
    api.doGet(issueKey, HTTP_OK, new int[] { HTTP_NOT_FOUND, HTTP_FORBIDDEN });
    Integer code = api.getResponseCode();
    switch(code) {
        case HTTP_OK:
            return true;
        case HTTP_NOT_FOUND:
            log.error("Issue {} not found", issueKey);
            return false;
        case HTTP_FORBIDDEN:
            log.error("No permission to read Issue {}", issueKey);
            return false;
        default:
            // Cannot happen due to passCodes filter
            throw new IOException("Unexpected HTTP code received:" + code.toString());
    }
}
#end_block

#method_before
public List<JiraTransition.Item> getTransitions(String issueKey) throws IOException {
    JiraRestApi<JiraTransition> api = apiBuilder.get(JiraTransition.class, "/issue");
    return Arrays.asList(api.doGet(issueKey + "/transitions", HTTP_OK).getTransitions());
}
#method_after
public List<JiraTransition.Item> getTransitions(JiraItsServerInfo server, String issueKey) throws IOException {
    JiraRestApi<JiraTransition> api = apiBuilder.get(server, JiraTransition.class, "/issue");
    return Arrays.asList(api.doGet(issueKey + "/transitions", HTTP_OK).getTransitions());
}
#end_block

#method_before
public void addComment(String issueKey, String comment) throws IOException {
    if (issueExists(issueKey)) {
        log.debug("Trying to add comment for issue {}", issueKey);
        apiBuilder.getIssue().doPost(issueKey + "/comment", gson.toJson(new JiraComment(comment)), HTTP_CREATED);
        log.debug("Comment added to issue {}", issueKey);
    } else {
        log.error("Issue {} does not exist or no access permission", issueKey);
    }
}
#method_after
public void addComment(JiraItsServerInfo server, String issueKey, String comment) throws IOException {
    if (issueExists(server, issueKey)) {
        log.debug("Trying to add comment for issue {}", issueKey);
        apiBuilder.getIssue(server).doPost(issueKey + "/comment", gson.toJson(new JiraComment(comment)), HTTP_CREATED);
        log.debug("Comment added to issue {}", issueKey);
    } else {
        log.error("Issue {} does not exist or no access permission", issueKey);
    }
}
#end_block

#method_before
public void addValueToField(String issueKey, String value, String fieldId) throws IOException {
    if (!issueExists(issueKey)) {
        log.error("Issue {} does not exist or no access permission", issueKey);
        return;
    }
    log.debug("Trying to add value {} to field {} for issue {}", value, fieldId, issueKey);
    JiraIssueEdition edition = JiraIssueEdition.builder().appendUpdate(fieldId, "add", value).build();
    apiBuilder.getIssue().doPut(issueKey, gson.toJson(edition), HTTP_NO_CONTENT);
    log.debug("Value {} added to field {} for issue {}", value, fieldId, issueKey);
}
#method_after
public void addValueToField(JiraItsServerInfo server, String issueKey, String value, String fieldId) throws IOException {
    if (!issueExists(server, issueKey)) {
        log.error("Issue {} does not exist", issueKey);
        return;
    }
    log.debug("Trying to add value {} to field {} for issue {}", value, fieldId, issueKey);
    JiraIssueUpdate edition = JiraIssueUpdate.builder().appendUpdate(fieldId, "add", value).build();
    apiBuilder.getIssue(server).doPut(issueKey, gson.toJson(edition), HTTP_NO_CONTENT);
    log.debug("Value {} added to field {} for issue {}", value, fieldId, issueKey);
}
#end_block

#method_before
public boolean doTransition(String issueKey, String transition) throws IOException, InvalidTransitionException {
    log.debug("Making transition to {} for {}", transition, issueKey);
    JiraTransition.Item t = getTransitionByName(issueKey, transition);
    if (t == null) {
        throw new InvalidTransitionException("Action " + transition + " not executable on issue " + issueKey);
    }
    log.debug("Transition issue {} to '{}' ({})", issueKey, transition, t.getId());
    return apiBuilder.getIssue().doPost(issueKey + "/transitions", gson.toJson(new JiraTransition(t)), HTTP_NO_CONTENT);
}
#method_after
public boolean doTransition(JiraItsServerInfo server, String issueKey, String transition) throws IOException, InvalidTransitionException {
    log.debug("Making transition to {} for {}", transition, issueKey);
    JiraTransition.Item t = getTransitionByName(server, issueKey, transition);
    if (t == null) {
        throw new InvalidTransitionException("Action " + transition + " not executable on issue " + issueKey);
    }
    log.debug("Transition issue {} to '{}' ({})", issueKey, transition, t.getId());
    return apiBuilder.getIssue(server).doPost(issueKey + "/transitions", gson.toJson(new JiraTransition(t)), HTTP_NO_CONTENT);
}
#end_block

#method_before
public JiraServerInfo sysInfo() throws IOException {
    return apiBuilder.getServerInfo().doGet("", HTTP_OK);
}
#method_after
public JiraServerInfo sysInfo(JiraItsServerInfo server) throws IOException {
    return apiBuilder.getServerInfo(server).doGet("", HTTP_OK);
}
#end_block

#method_before
public JiraProject[] getProjects() throws IOException {
    return apiBuilder.getProjects().doGet("", HTTP_OK);
}
#method_after
public JiraProject[] getProjects(JiraItsServerInfo server) throws IOException {
    return apiBuilder.getProjects(server).doGet("", HTTP_OK);
}
#end_block

#method_before
private JiraTransition.Item getTransitionByName(String issueKey, String transition) throws IOException {
    for (JiraTransition.Item t : getTransitions(issueKey)) {
        if (transition.equals(t.getName())) {
            return t;
        }
    }
    return null;
}
#method_after
private JiraTransition.Item getTransitionByName(JiraItsServerInfo server, String issueKey, String transition) throws IOException {
    for (JiraTransition.Item t : getTransitions(server, issueKey)) {
        if (transition.equals(t.getName())) {
            return t;
        }
    }
    return null;
}
#end_block

#method_before
public String healthCheckAccess() throws IOException {
    sysInfo();
    String result = "{\"status\"=\"ok\"}";
    log.debug("Health check on access result: {}", result);
    return result;
}
#method_after
public String healthCheckAccess(JiraItsServerInfo server) throws IOException {
    sysInfo(server);
    String result = "{\"status\"=\"ok\"}";
    log.debug("Health check on access result: {}", result);
    return result;
}
#end_block

#method_before
public String healthCheckSysinfo() throws IOException {
    JiraServerInfo info = sysInfo();
    String result = "{\"status\"=\"ok\",\"system\"=\"Jira\",\"version\"=\"" + info.getVersion() + "\",\"url\"=\"" + info.getBaseUri() + "\",\"build\"=\"" + info.getBuildNumber() + "\"}";
    log.debug("Health check on sysinfo result: {}", result);
    return result;
}
#method_after
public String healthCheckSysinfo(JiraItsServerInfo server) throws IOException {
    JiraServerInfo info = sysInfo(server);
    String result = "{\"status\"=\"ok\",\"system\"=\"Jira\",\"version\"=\"" + info.getVersion() + "\",\"url\"=\"" + info.getBaseUri() + "\",\"build\"=\"" + info.getBuildNumber() + "\"}";
    log.debug("Health check on sysinfo result: {}", result);
    return result;
}
#end_block

#method_before
@Test
public void healthCheckAccess() throws IOException {
    jiraFacade = new JiraItsFacade(jiraClient);
    jiraFacade.healthCheck(Check.ACCESS);
    verify(jiraClient).healthCheckAccess();
}
#method_after
@Test
public void healthCheckAccess() throws IOException {
    jiraFacade = new JiraItsFacade(jiraClient);
    jiraFacade.healthCheck(Check.ACCESS);
    verify(jiraClient).healthCheckAccess(server);
}
#end_block

#method_before
@Test
public void healthCheckSysInfo() throws IOException {
    jiraFacade = new JiraItsFacade(jiraClient);
    jiraFacade.healthCheck(Check.SYSINFO);
    verify(jiraClient).healthCheckSysinfo();
}
#method_after
@Test
public void healthCheckSysInfo() throws IOException {
    jiraFacade = new JiraItsFacade(jiraClient);
    jiraFacade.healthCheck(Check.SYSINFO);
    verify(jiraClient).healthCheckSysinfo(server);
}
#end_block

#method_before
@Test
public void addComment() throws IOException {
    jiraFacade = new JiraItsFacade(jiraClient);
    jiraFacade.addComment(ISSUE_KEY, COMMENT);
    verify(jiraClient).addComment(ISSUE_KEY, COMMENT);
}
#method_after
@Test
public void addComment() throws IOException {
    jiraFacade = new JiraItsFacade(jiraClient);
    jiraFacade.addComment(ISSUE_KEY, COMMENT);
    verify(jiraClient).addComment(server, ISSUE_KEY, COMMENT);
}
#end_block

#method_before
@Test
public void addRelatedLink() throws IOException {
    jiraFacade = new JiraItsFacade(jiraClient);
    jiraFacade.addRelatedLink(ISSUE_KEY, new URL("http://jira.com"), "description");
    verify(jiraClient).addComment(ISSUE_KEY, "Related URL: [description|http://jira.com]");
}
#method_after
@Test
public void addRelatedLink() throws IOException {
    jiraFacade = new JiraItsFacade(jiraClient);
    jiraFacade.addRelatedLink(ISSUE_KEY, new URL("http://jira.com"), "description");
    verify(jiraClient).addComment(server, ISSUE_KEY, "Related URL: [description|http://jira.com]");
}
#end_block

#method_before
@Test
public void addValueToField() throws IOException {
    jiraFacade = new JiraItsFacade(jiraClient);
    jiraFacade.addValueToField(ISSUE_KEY, VALUE, FIELD_ID);
    verify(jiraClient).addValueToField(ISSUE_KEY, VALUE, FIELD_ID);
}
#method_after
@Test
public void addValueToField() throws IOException {
    jiraFacade = new JiraItsFacade(jiraClient);
    jiraFacade.addValueToField(ISSUE_KEY, VALUE, FIELD_ID);
    verify(jiraClient).addValueToField(server, ISSUE_KEY, VALUE, FIELD_ID);
}
#end_block

#method_before
@Test
public void performAction() throws IOException, InvalidTransitionException {
    jiraFacade = new JiraItsFacade(jiraClient);
    jiraFacade.performAction(ISSUE_KEY, ACTION);
    verify(jiraClient).doTransition(ISSUE_KEY, ACTION);
}
#method_after
@Test
public void performAction() throws IOException, InvalidTransitionException {
    jiraFacade = new JiraItsFacade(jiraClient);
    jiraFacade.performAction(ISSUE_KEY, ACTION);
    verify(jiraClient).doTransition(server, ISSUE_KEY, ACTION);
}
#end_block

#method_before
@Test
public void exists() throws IOException {
    jiraFacade = new JiraItsFacade(jiraClient);
    jiraFacade.exists(ISSUE_KEY);
    verify(jiraClient).issueExists(ISSUE_KEY);
}
#method_after
@Test
public void exists() throws IOException {
    jiraFacade = new JiraItsFacade(jiraClient);
    jiraFacade.exists(ISSUE_KEY);
    verify(jiraClient).issueExists(server, ISSUE_KEY);
}
#end_block

#method_before
@Override
public List<ValidationMessage> onRefOperation(RefReceivedEvent refEvent) throws ValidationException {
    logger.atFine().log("Validating operation %s", refEvent);
    if (isImmutableRef(refEvent.getRefName())) {
        return Collections.emptyList();
    }
    switch(refEvent.command.getType()) {
        case CREATE:
            return onCreateRef(refEvent);
        case UPDATE:
        case UPDATE_NONFASTFORWARD:
            return onUpdateRef(refEvent);
        case DELETE:
            return onDeleteRef(refEvent);
        default:
            throw new IllegalArgumentException(String.format("Unsupported command type '%s', in event %s", refEvent.command.getType().name(), refEvent));
    }
}
#method_after
@Override
public List<ValidationMessage> onRefOperation(RefReceivedEvent refEvent) throws ValidationException {
    logger.atFine().log("Validating operation %s", refEvent);
    if (isImmutableRef(refEvent.getRefName())) {
        return Collections.emptyList();
    }
    try (Repository repo = repoManager.openRepository(refEvent.getProjectNameKey())) {
        switch(refEvent.command.getType()) {
            case CREATE:
                return onCreateRef(refEvent);
            case UPDATE:
            case UPDATE_NONFASTFORWARD:
                return onUpdateRef(repo, refEvent);
            case DELETE:
                return onDeleteRef(repo, refEvent);
            default:
                throw new IllegalArgumentException(String.format("Unsupported command type '%s', in event %s", refEvent.command.getType().name(), refEvent));
        }
    } catch (IOException e) {
        throw new ValidationException("Unable to access repository " + refEvent.getProjectNameKey(), e);
    }
}
#end_block

#method_before
private boolean isImmutableRef(String refName) {
    return refName.startsWith("refs/changes");
}
#method_after
private boolean isImmutableRef(String refName) {
    return refName.startsWith("refs/changes") && !refName.endsWith("/meta");
}
#end_block

#method_before
private List<ValidationMessage> onDeleteRef(RefReceivedEvent refEvent) throws ValidationException {
    try {
        if (!dfsRefDatabase.deleteRef(refEvent.getRefName(), refEvent.command.getOldId())) {
            throw new ValidationException(String.format("Unable to delete ref '%s', the old ID '%s' is not equal to the most recent one " + "in the shared ref database", refEvent.getRefName(), refEvent.command.getOldId()));
        }
    } catch (NoSuchElementException refNotInDB) {
        logger.atSevere().withCause(refNotInDB).log("Local status inconsistent with shared ref database for ref %s. " + "Trying to delete it but it is not in the DB", refEvent.getRefName());
        throw new ValidationException(String.format("Unable to delete ref '%s', cannot find it in the shared ref database", refEvent.getRefName()), refNotInDB);
    }
    return Collections.emptyList();
}
#method_after
private List<ValidationMessage> onDeleteRef(Repository repo, RefReceivedEvent refEvent) throws ValidationException {
    try {
        Ref localRef = repo.findRef(refEvent.getRefName());
        if (localRef == null) {
            logger.atWarning().log("Local status inconsistent with shared ref database for ref %s. " + "Trying to delete it but it is not in the local DB", refEvent.getRefName());
            throw new ValidationException(String.format("Unable to delete ref '%s', cannot find it in the local ref database", refEvent.getRefName()));
        }
        if (!dfsRefDatabase.compareAndRemove(refEvent.getProjectNameKey().get(), localRef)) {
            throw new ValidationException(String.format("Unable to delete ref '%s', the local ObjectId '%s' is not equal to the one " + "in the shared ref database", refEvent.getRefName(), localRef.getObjectId().getName()));
        }
    } catch (IOException ioe) {
        logger.atSevere().withCause(ioe).log("Local status inconsistent with shared ref database for ref %s. " + "Trying to delete it but it is not in the DB", refEvent.getRefName());
        throw new ValidationException(String.format("Unable to delete ref '%s', cannot find it in the shared ref database", refEvent.getRefName()), ioe);
    }
    return Collections.emptyList();
}
#end_block

#method_before
private List<ValidationMessage> onUpdateRef(RefReceivedEvent refEvent) throws ValidationException {
    try {
        if (!dfsRefDatabase.updateRefId(refEvent.getRefName(), refEvent.command.getNewId(), refEvent.command.getOldId())) {
            throw new ValidationException(String.format("Unable to update ref '%s', the old ID '%s' is not equal to the most recent one " + "in the shared ref database", refEvent.getRefName(), refEvent.command.getOldId()));
        }
    } catch (NoSuchElementException refNotInDB) {
        logger.atSevere().withCause(refNotInDB).log("Local status inconsistent with shared ref database for ref %s. " + "Trying to delete it but it is not in the DB", refEvent.getRefName());
        throw new ValidationException(String.format("Unable to update ref '%s', cannot find it in the shared ref database", refEvent.getRefName()), refNotInDB);
    }
    return Collections.emptyList();
}
#method_after
private List<ValidationMessage> onUpdateRef(Repository repo, RefReceivedEvent refEvent) throws ValidationException {
    try {
        Ref localRef = repo.findRef(refEvent.getRefName());
        if (localRef == null) {
            logger.atWarning().log("Local status inconsistent with shared ref database for ref %s. " + "Trying to update it but it is not in the local DB", refEvent.getRefName());
            throw new ValidationException(String.format("Unable to update ref '%s', cannot find it in the local ref database", refEvent.getRefName()));
        }
        Ref newRef = dfsRefDatabase.newRef(refEvent.getRefName(), refEvent.command.getNewId());
        if (!dfsRefDatabase.compareAndPut(refEvent.getProjectNameKey().get(), localRef, newRef)) {
            throw new ValidationException(String.format("Unable to update ref '%s', the local objectId '%s' is not equal to the one " + "in the shared ref database", refEvent.getRefName(), localRef.getObjectId().getName()));
        }
    } catch (IOException ioe) {
        logger.atSevere().withCause(ioe).log("Local status inconsistent with shared ref database for ref %s. " + "Trying to update it cannot extract the existing one on DB", refEvent.getRefName());
        throw new ValidationException(String.format("Unable to update ref '%s', cannot open the local ref on the local DB", refEvent.getRefName()), ioe);
    }
    return Collections.emptyList();
}
#end_block

#method_before
private List<ValidationMessage> onCreateRef(RefReceivedEvent refEvent) throws ValidationException {
    try {
        dfsRefDatabase.createRef(refEvent.getRefName(), refEvent.command.getNewId());
    } catch (IllegalArgumentException alreadyInDB) {
        logger.atSevere().withCause(alreadyInDB).log("Local status inconsistent with shared ref database for ref %s. " + "Trying to delete it but it is not in the DB", refEvent.getRefName());
        throw new ValidationException(String.format("Unable to update ref '%s', cannot find it in the shared ref database", refEvent.getRefName()), alreadyInDB);
    }
    return Collections.emptyList();
}
#method_after
private List<ValidationMessage> onCreateRef(RefReceivedEvent refEvent) throws ValidationException {
    try {
        Ref newRef = dfsRefDatabase.newRef(refEvent.getRefName(), refEvent.command.getNewId());
        dfsRefDatabase.compareAndCreate(refEvent.getProjectNameKey().get(), newRef);
    } catch (IllegalArgumentException | IOException alreadyInDB) {
        logger.atSevere().withCause(alreadyInDB).log("Local status inconsistent with shared ref database for ref %s. " + "Trying to delete it but it is not in the DB", refEvent.getRefName());
        throw new ValidationException(String.format("Unable to update ref '%s', cannot find it in the shared ref database", refEvent.getRefName()), alreadyInDB);
    }
    return Collections.emptyList();
}
#end_block

#method_before
@Before
public void setUp() {
    validator = new InSyncChangeValidator(dfsRefDatabase);
}
#method_after
@Before
public void setUp() throws IOException {
    doReturn(testRef).when(dfsRefDatabase).newRef(REF_NAME, REF_OBJID);
    doReturn(repo).when(repoManager).openRepository(PROJECT_NAMEKEY);
    doReturn(localRefDatabase).when(repo).getRefDatabase();
    lenient().doThrow(new NullPointerException("oldRef is null")).when(dfsRefDatabase).compareAndPut(any(), eq(null), any());
    lenient().doThrow(new NullPointerException("newRef is null")).when(dfsRefDatabase).compareAndPut(any(), any(), eq(null));
    lenient().doThrow(new NullPointerException("project name is null")).when(dfsRefDatabase).compareAndPut(eq(null), any(), any());
    validator = new InSyncChangeValidator(dfsRefDatabase, repoManager);
    repoManager.createRepository(PROJECT_NAMEKEY);
}
#end_block

#method_before
@Test
public void shouldInsertNewRefInDfsDatabaseWhenHandlingRefCreationEvents() throws ValidationException {
    final RefReceivedEvent refEvent = new RefReceivedEventBuilder().refCreation().build();
    final List<ValidationMessage> validationMessages = validator.onRefOperation(refEvent);
    assertThat(validationMessages).isEmpty();
    verify(dfsRefDatabase).createRef(refEvent.getRefName(), refEvent.command.getNewId());
}
#method_after
@Test
public void shouldInsertNewRefInDfsDatabaseWhenHandlingRefCreationEvents() throws Exception {
    testRefReceivedEvent.command = RECEIVE_COMMAND_CREATE_REF;
    final List<ValidationMessage> validationMessages = validator.onRefOperation(testRefReceivedEvent);
    assertThat(validationMessages).isEmpty();
    verify(dfsRefDatabase).compareAndCreate(eq(PROJECT_NAME), eqRef(REF_NAME, REF_OBJID));
}
#end_block

#method_before
@Test
public void shouldFailRefCreationIfInsertANewRefInDfsDatabaseFails() throws ValidationException {
    final RefReceivedEvent refEvent = new RefReceivedEventBuilder().refCreation().build();
    IllegalArgumentException alreadyInDb = new IllegalArgumentException("obj is already in db");
    doThrow(alreadyInDb).when(dfsRefDatabase).createRef(refEvent.getRefName(), refEvent.command.getNewId());
    expectedException.expect(ValidationException.class);
    expectedException.expectCause(sameInstance(alreadyInDb));
    validator.onRefOperation(refEvent);
}
#method_after
@Test
public void shouldFailRefCreationIfInsertANewRefInDfsDatabaseFails() throws Exception {
    testRefReceivedEvent.command = RECEIVE_COMMAND_CREATE_REF;
    IllegalArgumentException alreadyInDb = new IllegalArgumentException("obj is already in db");
    doThrow(alreadyInDb).when(dfsRefDatabase).compareAndCreate(eq(PROJECT_NAME), eqRef(REF_NAME, REF_OBJID));
    expectedException.expect(ValidationException.class);
    expectedException.expectCause(sameInstance(alreadyInDb));
    validator.onRefOperation(testRefReceivedEvent);
}
#end_block

#method_before
@Test
public void shouldUpdateRefInDfsDatabaseWhenHandlingRefUpdateEvents() throws ValidationException {
    final RefReceivedEvent refEvent = new RefReceivedEventBuilder().build();
    when(dfsRefDatabase.updateRefId(refEvent.getRefName(), refEvent.command.getNewId(), refEvent.command.getOldId())).thenReturn(true);
    final List<ValidationMessage> validationMessages = validator.onRefOperation(refEvent);
    assertThat(validationMessages).isEmpty();
    verify(dfsRefDatabase).updateRefId(refEvent.getRefName(), refEvent.command.getNewId(), refEvent.command.getOldId());
}
#method_after
@Test
public void shouldUpdateRefInDfsDatabaseWhenHandlingRefUpdateEvents() throws Exception {
    testRefReceivedEvent.command = RECEIVE_COMMAND_UPDATE_REF;
    doReturn(new TestRef(REF_NAME, REF_OBJID_OLD)).when(localRefDatabase).getRef(REF_NAME);
    doReturn(true).when(dfsRefDatabase).compareAndPut(eq(PROJECT_NAME), eqRef(REF_NAME, REF_OBJID_OLD), eqRef(REF_NAME, REF_OBJID));
    final List<ValidationMessage> validationMessages = validator.onRefOperation(testRefReceivedEvent);
    assertThat(validationMessages).isEmpty();
    verify(dfsRefDatabase).compareAndPut(eq(PROJECT_NAME), eqRef(REF_NAME, REF_OBJID_OLD), eqRef(REF_NAME, REF_OBJID));
}
#end_block

#method_before
@Test
public void shouldFailRefUpdateIfRefUpdateInDfsRefDatabaseReturnsFalse() throws ValidationException {
    final RefReceivedEvent refEvent = new RefReceivedEventBuilder().build();
    when(dfsRefDatabase.updateRefId(refEvent.getRefName(), refEvent.command.getNewId(), refEvent.command.getOldId())).thenReturn(false);
    expectedException.expect(ValidationException.class);
    expectedException.expectCause(nullValue(Exception.class));
    validator.onRefOperation(refEvent);
}
#method_after
@Test
public void shouldFailRefUpdateIfRefUpdateInDfsRefDatabaseReturnsFalse() throws Exception {
    testRefReceivedEvent.command = RECEIVE_COMMAND_UPDATE_REF;
    doReturn(new TestRef(REF_NAME, REF_OBJID_OLD)).when(localRefDatabase).getRef(REF_NAME);
    doReturn(false).when(dfsRefDatabase).compareAndPut(eq(PROJECT_NAME), eqRef(REF_NAME, REF_OBJID_OLD), eqRef(REF_NAME, REF_OBJID));
    expectedException.expect(ValidationException.class);
    expectedException.expectCause(nullValue(Exception.class));
    validator.onRefOperation(testRefReceivedEvent);
}
#end_block

#method_before
@Test
public void shouldFailRefUpdateIfRefIsNotInDfsRefDatabase() throws ValidationException {
    final RefReceivedEvent refEvent = new RefReceivedEventBuilder().build();
    NoSuchElementException notInDb = new NoSuchElementException("obj is not in db");
    doThrow(notInDb).when(dfsRefDatabase).updateRefId(refEvent.getRefName(), refEvent.command.getNewId(), refEvent.command.getOldId());
    expectedException.expect(ValidationException.class);
    expectedException.expectCause(sameInstance(notInDb));
    validator.onRefOperation(refEvent);
}
#method_after
@Test
public void shouldFailRefUpdateIfRefIsNotInDfsRefDatabase() throws Exception {
    testRefReceivedEvent.command = RECEIVE_COMMAND_UPDATE_REF;
    doReturn(null).when(localRefDatabase).getRef(REF_NAME);
    expectedException.expect(ValidationException.class);
    expectedException.expectCause(nullValue(Exception.class));
    validator.onRefOperation(testRefReceivedEvent);
}
#end_block

#method_before
@Test
public void shouldDeleteRefInDfsDatabaseWhenHandlingRefDeleteEvents() throws ValidationException {
    final RefReceivedEvent refEvent = new RefReceivedEventBuilder().refDeletion().build();
    when(dfsRefDatabase.deleteRef(refEvent.getRefName(), refEvent.command.getOldId())).thenReturn(true);
    final List<ValidationMessage> validationMessages = validator.onRefOperation(refEvent);
    assertThat(validationMessages).isEmpty();
    verify(dfsRefDatabase).deleteRef(refEvent.getRefName(), refEvent.command.getOldId());
}
#method_after
@Test
public void shouldDeleteRefInDfsDatabaseWhenHandlingRefDeleteEvents() throws Exception {
    testRefReceivedEvent.command = RECEIVE_COMMAND_DELETE_REF;
    doReturn(new TestRef(REF_NAME, REF_OBJID_OLD)).when(localRefDatabase).getRef(REF_NAME);
    doReturn(true).when(dfsRefDatabase).compareAndRemove(eq(PROJECT_NAME), eqRef(REF_NAME, REF_OBJID_OLD));
    final List<ValidationMessage> validationMessages = validator.onRefOperation(testRefReceivedEvent);
    assertThat(validationMessages).isEmpty();
    verify(dfsRefDatabase).compareAndRemove(eq(PROJECT_NAME), eqRef(REF_NAME, REF_OBJID_OLD));
}
#end_block

#method_before
@Test
public void shouldFailRefDeletionIfRefDeletionInDfsRefDatabaseReturnsFalse() throws ValidationException {
    final RefReceivedEvent refEvent = new RefReceivedEventBuilder().refDeletion().build();
    when(dfsRefDatabase.deleteRef(refEvent.getRefName(), refEvent.command.getOldId())).thenReturn(false);
    expectedException.expect(ValidationException.class);
    expectedException.expectCause(nullValue(Exception.class));
    validator.onRefOperation(refEvent);
}
#method_after
@Test
public void shouldFailRefDeletionIfRefDeletionInDfsRefDatabaseReturnsFalse() throws Exception {
    testRefReceivedEvent.command = RECEIVE_COMMAND_DELETE_REF;
    doReturn(new TestRef(REF_NAME, REF_OBJID_OLD)).when(localRefDatabase).getRef(REF_NAME);
    doReturn(false).when(dfsRefDatabase).compareAndRemove(eq(PROJECT_NAME), eqRef(REF_NAME, REF_OBJID_OLD));
    expectedException.expect(ValidationException.class);
    expectedException.expectCause(nullValue(Exception.class));
    validator.onRefOperation(testRefReceivedEvent);
}
#end_block

#method_before
@Test
public void shouldFailRefDeletionIfRefIsNotInDfsDatabase() throws ValidationException {
    final RefReceivedEvent refEvent = new RefReceivedEventBuilder().refDeletion().build();
    NoSuchElementException notInDb = new NoSuchElementException("obj is not in db");
    doThrow(notInDb).when(dfsRefDatabase).deleteRef(refEvent.getRefName(), refEvent.command.getOldId());
    expectedException.expect(ValidationException.class);
    expectedException.expectCause(sameInstance(notInDb));
    validator.onRefOperation(refEvent);
}
#method_after
@Test
public void shouldFailRefDeletionIfRefIsNotInDfsDatabase() throws Exception {
    testRefReceivedEvent.command = RECEIVE_COMMAND_DELETE_REF;
    doReturn(null).when(localRefDatabase).getRef(REF_NAME);
    expectedException.expect(ValidationException.class);
    expectedException.expectCause(nullValue(Exception.class));
    validator.onRefOperation(testRefReceivedEvent);
}
#end_block

#method_before
@Override
protected void configure() {
    DynamicSet.bind(binder(), RefOperationValidationListener.class).to(InSyncChangeValidator.class);
    bind(DfsRefDatabase.class).toInstance(new InMemoryDfsRefDatabase(Executors.newSingleThreadScheduledExecutor(), InMemoryDfsRefDatabaseCleaner.cleanIfNotTouchedFor(Duration.ofDays(7)), 300));
}
#method_after
@Override
protected void configure() {
    DynamicSet.bind(binder(), RefOperationValidationListener.class).to(InSyncChangeValidator.class);
    bind(SharedRefDatabase.class).to(NoOpDfsRefDatabase.class);
}
#end_block

#method_before
@Override
public CheckInfo apply(CheckResource checkResource, CheckInput input) throws RestApiException, IOException, OrmException {
    if (input.checkerUuid == null) {
        input.checkerUuid = checkResource.getCheckerUuid().toString();
    } else if (!checkResource.getCheckerUuid().toString().equals(input.checkerUuid)) {
        throw new BadRequestException(String.format("checkerUuid must either be null or the same as on the resource:\n" + "the check resource belongs to checker %s," + " but in the input checker %s was specified", checkResource.getCheckerUuid(), input.checkerUuid));
    }
    return postCheck.apply(checkResource.getRevisionResource(), input);
}
#method_after
@Override
public CheckInfo apply(CheckResource checkResource, CheckInput input) throws RestApiException, IOException, OrmException {
    if (input == null) {
        input = new CheckInput();
    }
    if (input.checkerUuid == null) {
        input.checkerUuid = checkResource.getCheckerUuid().toString();
    } else if (!checkResource.getCheckerUuid().toString().equals(input.checkerUuid)) {
        throw new BadRequestException(String.format("checkerUuid must either be null or the same as on the resource:\n" + "the check resource belongs to checker %s," + " but in the input checker %s was specified", checkResource.getCheckerUuid(), input.checkerUuid));
    }
    return postCheck.apply(checkResource.getRevisionResource(), input);
}
#end_block

#method_before
@Override
public CheckInfo apply(RevisionResource rsrc, CheckInput input) throws OrmException, IOException, RestApiException {
    if (input == null) {
        throw new BadRequestException("input is required");
    }
    if (input.checkerUuid == null) {
        throw new BadRequestException("checkerUuid is required");
    }
    CheckKey key = CheckKey.create(rsrc.getProject(), rsrc.getPatchSet().getId(), CheckerUuid.parse(input.checkerUuid));
    Optional<Check> check = checks.getCheck(key);
    if (!check.isPresent()) {
        if (input.state == null) {
            throw new BadRequestException("state is required on creation");
        }
        Check updatedCheck = checksUpdate.get().createCheck(key, toCheckUpdate(input));
        return checkJson.format(updatedCheck);
    }
    Check updatedCheck = checksUpdate.get().updateCheck(key, toCheckUpdate(input));
    return checkJson.format(updatedCheck);
}
#method_after
@Override
public CheckInfo apply(RevisionResource rsrc, CheckInput input) throws OrmException, IOException, RestApiException {
    if (input == null) {
        input = new CheckInput();
    }
    if (input.checkerUuid == null) {
        throw new BadRequestException("checkerUuid is required");
    }
    CheckKey key = CheckKey.create(rsrc.getProject(), rsrc.getPatchSet().getId(), CheckerUuid.parse(input.checkerUuid));
    Optional<Check> check = checks.getCheck(key);
    if (!check.isPresent()) {
        if (input.state == null) {
            throw new BadRequestException("state is required on creation");
        }
        Check updatedCheck = checksUpdate.get().createCheck(key, toCheckUpdate(input));
        return checkJson.format(updatedCheck);
    }
    Check updatedCheck = checksUpdate.get().updateCheck(key, toCheckUpdate(input));
    return checkJson.format(updatedCheck);
}
#end_block

#method_before
@Test
public void checkerCanBeCreatedWithoutSpecifyingAnyParameters() throws Exception {
    CheckerUuid checkerUuid = checkerOperations.newChecker().create();
    CheckerInfo foundChecker = getCheckerFromServer(checkerUuid);
    assertThat(foundChecker.uuid).isEqualTo(checkerUuid.toString());
    assertThat(foundChecker.name).isNull();
    assertThat(foundChecker.description).isNull();
    assertThat(foundChecker.createdOn).isNotNull();
}
#method_after
@Test
public void checkerCanBeCreatedWithoutSpecifyingAnyParameters() throws Exception {
    CheckerUuid checkerUuid = checkerOperations.newChecker().create();
    CheckerInfo foundChecker = getCheckerFromServer(checkerUuid);
    assertThat(foundChecker.uuid).isEqualTo(checkerUuid.toString());
    assertThat(foundChecker.name).isNull();
    assertThat(foundChecker.repository).isEqualTo(allProjects.get());
    assertThat(foundChecker.status).isEqualTo(CheckerStatus.ENABLED);
    assertThat(foundChecker.description).isNull();
    assertThat(foundChecker.createdOn).isNotNull();
}
#end_block

#method_before
public static Optional<CheckerUuid> tryParse(@Nullable String uuid) {
    if (uuid == null) {
        return Optional.empty();
    }
    Matcher m = UUID_PATTERN.matcher(uuid);
    if (!m.find()) {
        return Optional.empty();
    }
    String scheme = m.group("scheme");
    // But JGit's isValidRefName doesn't currently enforce the .lock constraint.
    if (scheme.endsWith(Constants.LOCK_SUFFIX)) {
        return Optional.empty();
    }
    if (!Repository.isValidRefName(toRefName(scheme, "x"))) {
        return Optional.empty();
    }
    return Optional.of(new AutoValue_CheckerUuid(scheme, m.group("id")));
}
#method_after
public static Optional<CheckerUuid> tryParse(@Nullable String uuid) {
    if (uuid == null) {
        return Optional.empty();
    }
    Matcher m = UUID_PATTERN.matcher(uuid);
    if (!m.find()) {
        return Optional.empty();
    }
    String scheme = m.group("scheme");
    if (scheme.length() > MAX_SCHEME_LENGTH) {
        return Optional.empty();
    }
    // But JGit's isValidRefName doesn't currently enforce the .lock constraint.
    if (scheme.endsWith(Constants.LOCK_SUFFIX)) {
        return Optional.empty();
    }
    if (!Repository.isValidRefName(toRefName(scheme, "x"))) {
        return Optional.empty();
    }
    return Optional.of(new AutoValue_CheckerUuid(scheme, m.group("id")));
}
#end_block

#method_before
private static CheckerUpdate toCheckerUpdate(TestCheckerCreation checkerCreation) {
    CheckerUpdate.Builder builder = CheckerUpdate.builder();
    checkerCreation.name().ifPresent(builder::setName);
    checkerCreation.description().ifPresent(builder::setDescription);
    checkerCreation.url().ifPresent(builder::setUrl);
    checkerCreation.repository().ifPresent(builder::setRepository);
    checkerCreation.query().ifPresent(builder::setQuery);
    return builder.build();
}
#method_after
private static CheckerUpdate toCheckerUpdate(TestCheckerCreation checkerCreation) {
    CheckerUpdate.Builder builder = CheckerUpdate.builder();
    checkerCreation.name().ifPresent(builder::setName);
    checkerCreation.description().ifPresent(builder::setDescription);
    checkerCreation.url().ifPresent(builder::setUrl);
    checkerCreation.repository().ifPresent(builder::setRepository);
    checkerCreation.status().ifPresent(builder::setStatus);
    checkerCreation.query().ifPresent(builder::setQuery);
    return builder.build();
}
#end_block

#method_before
public TestCheckerUpdate.Builder forUpdate() {
    return TestCheckerUpdate.builder(this::updateChecker);
}
#method_after
@Override
public TestCheckerUpdate.Builder forUpdate() {
    return TestCheckerUpdate.builder(this::updateChecker);
}
#end_block

#method_before
@Override
public Response<ProjectInfo> apply(TopLevelResource resource, IdString id, ProjectInput input) throws RestApiException, IOException, ConfigInvalidException, PermissionBackendException {
    String name = id.get();
    if (input == null) {
        input = new ProjectInput();
    }
    if (input.name != null && !name.equals(input.name)) {
        throw new BadRequestException("name must match URL");
    }
    CreateProjectArgs args = new CreateProjectArgs();
    args.setProjectName(strip(name));
    String parentName = MoreObjects.firstNonNull(Strings.emptyToNull(input.parent), allProjects.get());
    args.newParent = projectsCollection.get().parse(parentName, false).getNameKey();
    if (args.newParent.equals(allUsers)) {
        throw new ResourceConflictException(String.format("Cannot inherit from '%s' project", allUsers.get()));
    }
    args.createEmptyCommit = input.createEmptyCommit;
    args.permissionsOnly = input.permissionsOnly;
    args.projectDescription = Strings.emptyToNull(input.description);
    args.submitType = input.submitType;
    args.branch = normalizeBranchNames(input.branches);
    if (input.owners == null || input.owners.isEmpty()) {
        args.ownerIds = new ArrayList<>(projectOwnerGroups.create(args.getProject()).get());
    } else {
        args.ownerIds = Lists.newArrayListWithCapacity(input.owners.size());
        for (String owner : input.owners) {
            args.ownerIds.add(groupResolver.get().parse(owner).getGroupUUID());
        }
    }
    args.contributorAgreements = MoreObjects.firstNonNull(input.useContributorAgreements, InheritableBoolean.INHERIT);
    args.signedOffBy = MoreObjects.firstNonNull(input.useSignedOffBy, InheritableBoolean.INHERIT);
    args.contentMerge = input.submitType == SubmitType.FAST_FORWARD_ONLY ? InheritableBoolean.FALSE : MoreObjects.firstNonNull(input.useContentMerge, InheritableBoolean.INHERIT);
    args.newChangeForAllNotInTarget = MoreObjects.firstNonNull(input.createNewChangeForAllNotInTarget, InheritableBoolean.INHERIT);
    args.changeIdRequired = MoreObjects.firstNonNull(input.requireChangeId, InheritableBoolean.INHERIT);
    args.rejectEmptyCommit = MoreObjects.firstNonNull(input.rejectEmptyCommit, InheritableBoolean.INHERIT);
    args.enableSignedPush = MoreObjects.firstNonNull(input.enableSignedPush, InheritableBoolean.INHERIT);
    args.requireSignedPush = MoreObjects.firstNonNull(input.requireSignedPush, InheritableBoolean.INHERIT);
    try {
        args.maxObjectSizeLimit = ProjectConfig.validMaxObjectSizeLimit(input.maxObjectSizeLimit);
    } catch (ConfigInvalidException e) {
        throw new BadRequestException(e.getMessage());
    }
    Lock nameLock = lockManager.call(lockManager -> lockManager.getLock(args.getProject()));
    nameLock.lock();
    try {
        try {
            projectCreationValidationListeners.runEach(l -> l.validateNewProject(args), ValidationException.class);
        } catch (ValidationException e) {
            throw new ResourceConflictException(e.getMessage(), e);
        }
        ProjectState projectState = createProject(args);
        requireNonNull(projectState, () -> String.format("failed to create project %s", args.getProject().get()));
        if (input.pluginConfigValues != null) {
            ConfigInput in = new ConfigInput();
            in.pluginConfigValues = input.pluginConfigValues;
            putConfig.get().apply(projectState, in);
        }
        return Response.created(json.format(projectState));
    } finally {
        nameLock.unlock();
    }
}
#method_after
@Override
public Response<ProjectInfo> apply(TopLevelResource resource, IdString id, ProjectInput input) throws RestApiException, IOException, ConfigInvalidException, PermissionBackendException {
    String name = id.get();
    if (input == null) {
        input = new ProjectInput();
    }
    if (input.name != null && !name.equals(input.name)) {
        throw new BadRequestException("name must match URL");
    }
    CreateProjectArgs args = new CreateProjectArgs();
    args.setProjectName(ProjectUtil.sanitizeProjectName(name));
    String parentName = MoreObjects.firstNonNull(Strings.emptyToNull(input.parent), allProjects.get());
    args.newParent = projectsCollection.get().parse(parentName, false).getNameKey();
    if (args.newParent.equals(allUsers)) {
        throw new ResourceConflictException(String.format("Cannot inherit from '%s' project", allUsers.get()));
    }
    args.createEmptyCommit = input.createEmptyCommit;
    args.permissionsOnly = input.permissionsOnly;
    args.projectDescription = Strings.emptyToNull(input.description);
    args.submitType = input.submitType;
    args.branch = normalizeBranchNames(input.branches);
    if (input.owners == null || input.owners.isEmpty()) {
        args.ownerIds = new ArrayList<>(projectOwnerGroups.create(args.getProject()).get());
    } else {
        args.ownerIds = Lists.newArrayListWithCapacity(input.owners.size());
        for (String owner : input.owners) {
            args.ownerIds.add(groupResolver.get().parse(owner).getGroupUUID());
        }
    }
    args.contributorAgreements = MoreObjects.firstNonNull(input.useContributorAgreements, InheritableBoolean.INHERIT);
    args.signedOffBy = MoreObjects.firstNonNull(input.useSignedOffBy, InheritableBoolean.INHERIT);
    args.contentMerge = input.submitType == SubmitType.FAST_FORWARD_ONLY ? InheritableBoolean.FALSE : MoreObjects.firstNonNull(input.useContentMerge, InheritableBoolean.INHERIT);
    args.newChangeForAllNotInTarget = MoreObjects.firstNonNull(input.createNewChangeForAllNotInTarget, InheritableBoolean.INHERIT);
    args.changeIdRequired = MoreObjects.firstNonNull(input.requireChangeId, InheritableBoolean.INHERIT);
    args.rejectEmptyCommit = MoreObjects.firstNonNull(input.rejectEmptyCommit, InheritableBoolean.INHERIT);
    args.enableSignedPush = MoreObjects.firstNonNull(input.enableSignedPush, InheritableBoolean.INHERIT);
    args.requireSignedPush = MoreObjects.firstNonNull(input.requireSignedPush, InheritableBoolean.INHERIT);
    try {
        args.maxObjectSizeLimit = ProjectConfig.validMaxObjectSizeLimit(input.maxObjectSizeLimit);
    } catch (ConfigInvalidException e) {
        throw new BadRequestException(e.getMessage());
    }
    Lock nameLock = lockManager.call(lockManager -> lockManager.getLock(args.getProject()));
    nameLock.lock();
    try {
        try {
            projectCreationValidationListeners.runEach(l -> l.validateNewProject(args), ValidationException.class);
        } catch (ValidationException e) {
            throw new ResourceConflictException(e.getMessage(), e);
        }
        ProjectState projectState = createProject(args);
        requireNonNull(projectState, () -> String.format("failed to create project %s", args.getProject().get()));
        if (input.pluginConfigValues != null) {
            ConfigInput in = new ConfigInput();
            in.pluginConfigValues = input.pluginConfigValues;
            putConfig.get().apply(projectState, in);
        }
        return Response.created(json.format(projectState));
    } finally {
        nameLock.unlock();
    }
}
#end_block

#method_before
@Test
public void withDotGit() throws Exception {
    String newGroupName = "newGroup";
    adminRestSession.put("/groups/" + newGroupName);
    String newProjectName = "newProject";
    adminSshSession.exec("gerrit create-project --branch master --owner " + newGroupName + " " + newProjectName + ".git");
    adminSshSession.assertSuccess();
    ProjectState projectState = projectCache.get(new Project.NameKey(newProjectName));
    assertThat(projectState).isNotNull();
    assertThat(projectState.getName()).isEqualTo(newProjectName);
}
#method_after
@Test
public void withDotGit() throws Exception {
    String newGroupName = "newGroup";
    adminRestSession.put("/groups/" + newGroupName);
    String newProjectName = name("newProject");
    adminSshSession.exec("gerrit create-project --branch master --owner " + newGroupName + " " + newProjectName + ".git");
    adminSshSession.assertSuccess();
    ProjectState projectState = projectCache.get(new Project.NameKey(newProjectName));
    assertThat(projectState).isNotNull();
    assertThat(projectState.getName()).isEqualTo(newProjectName);
}
#end_block

#method_before
public void createProjectThatEndsWithSlash() throws Exception {
    String newProjectName = name("newProject");
    ProjectInfo p = gApi.projects().create(newProjectName + "/").get();
    assertThat(p.name).isEqualTo(newProjectName);
    ProjectState projectState = projectCache.get(new Project.NameKey(newProjectName));
    assertThat(projectState).isNotNull();
    assertProjectInfo(projectState.getProject(), p);
    assertHead(newProjectName, "refs/heads/master");
}
#method_after
@Test
public void createProjectThatEndsWithSlash() throws Exception {
    String newProjectName = name("newProject");
    ProjectInfo p = gApi.projects().create(newProjectName + "/").get();
    assertThat(p.name).isEqualTo(newProjectName);
    ProjectState projectState = projectCache.get(new Project.NameKey(newProjectName));
    assertThat(projectState).isNotNull();
    assertProjectInfo(projectState.getProject(), p);
    assertHead(newProjectName, "refs/heads/master");
}
#end_block

#method_before
public void createProjectThatContainsSlash() throws Exception {
    String newProjectName = name("newProject/newProject");
    ProjectInfo p = gApi.projects().create(newProjectName).get();
    assertThat(p.name).isEqualTo(newProjectName);
    ProjectState projectState = projectCache.get(new Project.NameKey(newProjectName));
    assertThat(projectState).isNotNull();
    assertProjectInfo(projectState.getProject(), p);
    assertHead(newProjectName, "refs/heads/master");
}
#method_after
@Test
public void createProjectThatContainsSlash() throws Exception {
    String newProjectName = name("newProject/newProject");
    ProjectInfo p = gApi.projects().create(newProjectName).get();
    assertThat(p.name).isEqualTo(newProjectName);
    ProjectState projectState = projectCache.get(new Project.NameKey(newProjectName));
    assertThat(projectState).isNotNull();
    assertProjectInfo(projectState.getProject(), p);
    assertHead(newProjectName, "refs/heads/master");
}
#end_block

#method_before
@Override
public void run() {
    try {
        final String topic = configuration.getKafka().getTopic(getEventFamily());
        multisiteLog.info("Kafka consumer subscribing to topic {} for event family {}", topic, getEventFamily());
        consumer.subscribe(Collections.singleton(topic));
        while (!closed.get()) {
            ConsumerRecords<byte[], byte[]> consumerRecords = consumer.poll(Duration.ofMillis(configuration.kafkaSubscriber().getPollingInterval()));
            consumerRecords.forEach(this::processRecord);
        }
    } catch (WakeupException e) {
        // Ignore exception if closing
        if (!closed.get())
            throw e;
    } finally {
        consumer.close();
    }
}
#method_after
@Override
public void run() {
    try {
        final String topic = configuration.getKafka().getTopic(getEventFamily());
        logger.atInfo().log("Kafka consumer subscribing to topic [%s] for event family [%s]", topic, getEventFamily());
        consumer.subscribe(Collections.singleton(topic));
        while (!closed.get()) {
            ConsumerRecords<byte[], byte[]> consumerRecords = consumer.poll(Duration.ofMillis(configuration.kafkaSubscriber().getPollingInterval()));
            consumerRecords.forEach(this::processRecord);
        }
    } catch (WakeupException e) {
        // Ignore exception if closing
        if (!closed.get())
            throw e;
    } finally {
        consumer.close();
    }
}
#end_block

#method_before
private void processRecord(ConsumerRecord<byte[], byte[]> consumerRecord) {
    try (ManualRequestContext ctx = oneOffCtx.open()) {
        SourceAwareEventWrapper event = valueDeserializer.deserialize(consumerRecord.topic(), consumerRecord.value());
        if (event.getHeader().getSourceInstanceId().equals(instanceId)) {
            multisiteLog.debug("Dropping event {} produced by our instanceId {}", event.toString(), instanceId.toString());
            droppedEventListeners.forEach(l -> l.onEventDropped(event));
        } else {
            try {
                multisiteLog.debug("Header[{}] Body[{}]", event.getHeader(), event.getBody());
                eventRouter.route(event.getEventBody(gsonProvider));
            } catch (IOException e) {
                multisiteLog.error("Malformed event '{}': [Exception: {}]", event.getHeader().getEventType(), e);
            } catch (PermissionBackendException | OrmException e) {
                multisiteLog.error("Cannot handle message {}: [Exception: {}]", event.getHeader().getEventType(), e);
            }
        }
    } catch (Exception e) {
        multisiteLog.error("Malformed event '{}': [Exception: {}]", new String(consumerRecord.value()), e);
    }
}
#method_after
private void processRecord(ConsumerRecord<byte[], byte[]> consumerRecord) {
    try (ManualRequestContext ctx = oneOffCtx.open()) {
        SourceAwareEventWrapper event = valueDeserializer.deserialize(consumerRecord.topic(), consumerRecord.value());
        if (event.getHeader().getSourceInstanceId().equals(instanceId)) {
            logger.atFiner().log("Dropping event %s produced by our instanceId %s", event.toString(), instanceId.toString());
            droppedEventListeners.forEach(l -> l.onEventDropped(event));
        } else {
            try {
                msgLog.log(Direction.CONSUME, event);
                eventRouter.route(event.getEventBody(gsonProvider));
            } catch (IOException e) {
                logger.atSevere().withCause(e).log("Malformed event '%s': [Exception: %s]", event.getHeader().getEventType());
            } catch (PermissionBackendException | OrmException e) {
                logger.atSevere().withCause(e).log("Cannot handle message %s: [Exception: %s]", event.getHeader().getEventType());
            }
        }
    } catch (Exception e) {
        logger.atSevere().withCause(e).log("Malformed event '%s': [Exception: %s]", new String(consumerRecord.value()));
    }
}
#end_block

#method_before
@Override
protected void configure() {
    bind(LifecycleListener.class).annotatedWith(UniqueAnnotations.create()).to(MultiSiteLogFile.class);
    install(new ForwarderModule());
    if (config.cache().synchronize()) {
        install(new CacheModule());
    }
    if (config.event().synchronize()) {
        install(new EventModule());
    }
    if (config.index().synchronize()) {
        install(new IndexModule());
    }
    if (config.kafkaSubscriber().enabled()) {
        install(new KafkaConsumerModule(config.kafkaSubscriber()));
        install(new ForwardedEventRouterModule());
    }
    if (config.kafkaPublisher().enabled()) {
        install(new BrokerForwarderModule(config.kafkaPublisher()));
    }
    bind(Gson.class).toProvider(GsonProvider.class).in(Singleton.class);
}
#method_after
@Override
protected void configure() {
    listener().to(Log4jMessageLogger.class);
    bind(MessageLogger.class).to(Log4jMessageLogger.class);
    install(new ForwarderModule());
    if (config.cache().synchronize()) {
        install(new CacheModule());
    }
    if (config.event().synchronize()) {
        install(new EventModule());
    }
    if (config.index().synchronize()) {
        install(new IndexModule());
    }
    if (config.kafkaSubscriber().enabled()) {
        install(new KafkaConsumerModule(config.kafkaSubscriber()));
        install(new ForwardedEventRouterModule());
    }
    if (config.kafkaPublisher().enabled()) {
        install(new BrokerForwarderModule(config.kafkaPublisher()));
    }
    bind(Gson.class).toProvider(GsonProvider.class).in(Singleton.class);
}
#end_block

#method_before
@Provides
@Singleton
@InstanceId
UUID getInstanceId(@PluginData java.nio.file.Path dataDir) throws IOException {
    UUID instanceId = null;
    String serverIdFile = dataDir.toAbsolutePath().toString() + "/" + Configuration.INSTANCE_ID_FILE;
    instanceId = tryToLoadSavedInstanceId(serverIdFile);
    if (instanceId == null) {
        instanceId = UUID.randomUUID();
        Files.createFile(Paths.get(serverIdFile));
        try (BufferedWriter writer = Files.newBufferedWriter(Paths.get(serverIdFile))) {
            writer.write(instanceId.toString());
        } catch (IOException e) {
            multisiteLog.warn(String.format("Cannot write instance ID, a new one will be generated at instance restart. (%s)", e.getMessage()));
        }
    }
    return instanceId;
}
#method_after
@Provides
@Singleton
@InstanceId
UUID getInstanceId(@PluginData java.nio.file.Path dataDir) throws IOException {
    UUID instanceId = null;
    String serverIdFile = dataDir.toAbsolutePath().toString() + "/" + Configuration.INSTANCE_ID_FILE;
    instanceId = tryToLoadSavedInstanceId(serverIdFile);
    if (instanceId == null) {
        instanceId = UUID.randomUUID();
        Files.createFile(Paths.get(serverIdFile));
        try (BufferedWriter writer = Files.newBufferedWriter(Paths.get(serverIdFile))) {
            writer.write(instanceId.toString());
        } catch (IOException e) {
            log.warn(String.format("Cannot write instance ID, a new one will be generated at instance restart. (%s)", e.getMessage()));
        }
    }
    return instanceId;
}
#end_block

#method_before
private UUID tryToLoadSavedInstanceId(String serverIdFile) {
    if (Files.exists(Paths.get(serverIdFile))) {
        try (BufferedReader br = new BufferedReader(new FileReader(serverIdFile))) {
            return UUID.fromString(br.readLine());
        } catch (IOException e) {
            multisiteLog.warn(String.format("Cannot read instance ID from path '%s', deleting the old file and generating a new ID: (%s)", serverIdFile, e.getMessage()));
            try {
                Files.delete(Paths.get(serverIdFile));
            } catch (IOException e1) {
                multisiteLog.warn(String.format("Cannot delete old instance ID file at path '%s' with instance ID while generating a new one: (%s)", serverIdFile, e1.getMessage()));
            }
        }
    }
    return null;
}
#method_after
private UUID tryToLoadSavedInstanceId(String serverIdFile) {
    if (Files.exists(Paths.get(serverIdFile))) {
        try (BufferedReader br = new BufferedReader(new FileReader(serverIdFile))) {
            return UUID.fromString(br.readLine());
        } catch (IOException e) {
            log.warn(String.format("Cannot read instance ID from path '%s', deleting the old file and generating a new ID: (%s)", serverIdFile, e.getMessage()));
            try {
                Files.delete(Paths.get(serverIdFile));
            } catch (IOException e1) {
                log.warn(String.format("Cannot delete old instance ID file at path '%s' with instance ID while generating a new one: (%s)", serverIdFile, e1.getMessage()));
            }
        }
    }
    return null;
}
#end_block

#method_before
@Override
public List<Check> getChecks(Project.NameKey projectName, PatchSet.Id psId) throws OrmException {
    // TODO(gerrit-team): Instead of reading the complete notes map, read just one note.
    ChangeNotes notes = changeNotesFactory.create(projectName, psId.getParentKey());
    PatchSet patchSet = psUtil.get(notes, psId);
    CheckNotes checkNotes = checkNotesFactory.create(notes.getChange());
    checkNotes.load();
    return checkNotes.getChecks().getOrDefault(patchSet.getRevision(), NoteDbCheckMap.empty()).checks.entrySet().stream().map(e -> e.getValue().toCheck(projectName, psId, e.getKey())).collect(toImmutableList());
}
#method_after
@Override
public ImmutableList<Check> getChecks(Project.NameKey projectName, PatchSet.Id psId) throws OrmException {
    return getChecksAsStream(projectName, psId).collect(toImmutableList());
}
#end_block

#method_before
@Override
public Optional<Check> getCheck(CheckKey checkKey) throws IOException, OrmException {
    // TODO(gerrit-team): Instead of reading the complete notes map, read just one note.
    return getChecks(checkKey.project(), checkKey.patchSet()).stream().filter(c -> c.key().checkerUuid().equals(checkKey.checkerUuid())).findAny();
}
#method_after
@Override
public Optional<Check> getCheck(CheckKey checkKey) throws OrmException {
    // TODO(gerrit-team): Instead of reading the complete notes map, read just one note.
    return getChecksAsStream(checkKey.project(), checkKey.patchSet()).filter(c -> c.key().checkerUuid().equals(checkKey.checkerUuid())).findAny();
}
#end_block

#method_before
// TODO(gerrit-team) More tests, especially for multiple checkers and PS and how commits behave
private String noteDbContent() {
    return "" + "{\n" + "  \"checks\": {\n" + "    \"my-checker\": {\n" + "      \"state\": \"RUNNING\",\n" + "      \"created\": \"1970-01-01T00:00:23Z\",\n" + "      \"updated\": \"1970-01-01T00:00:23Z\"\n" + "    }\n" + "  }\n" + "}";
}
#method_after
// TODO(gerrit-team) More tests, especially for multiple checkers and PS and how commits behave
private String noteDbContent() {
    return "" + "{\n" + "  \"checks\": {\n" + "    \"my-checker\": {\n" + "      \"state\": \"RUNNING\",\n" + "      \"created\": \"1970-01-01T00:00:22Z\",\n" + "      \"updated\": \"1970-01-01T00:00:22Z\"\n" + "    }\n" + "  }\n" + "}";
}
#end_block

#method_before
Check toCheck(CheckKey key) {
    {
        Check.Builder newCheck = Check.builder(key).setState(state).setCreated(created).setUpdated(updated);
        if (url != null) {
            newCheck.setUrl(url);
        }
        if (started != null) {
            newCheck.setStarted(started);
        }
        if (finished != null) {
            newCheck.setFinished(finished);
        }
        return newCheck.build();
    }
}
#method_after
Check toCheck(CheckKey key) {
    Check.Builder newCheck = Check.builder(key).setState(state).setCreated(created).setUpdated(updated);
    if (url != null) {
        newCheck.setUrl(url);
    }
    if (started != null) {
        newCheck.setStarted(started);
    }
    if (finished != null) {
        newCheck.setFinished(finished);
    }
    return newCheck.build();
}
#end_block

#method_before
boolean applyUpdate(CheckUpdate update) {
    boolean modified = false;
    if (update.state().isPresent() && !Objects.equals(update.state().orElse(null), state)) {
        state = update.state().get();
        modified = true;
    }
    if (update.url().isPresent() && !Objects.equals(update.url().orElse(null), url)) {
        url = update.url().get();
        modified = true;
    }
    if (update.started().isPresent() && !Objects.equals(update.started().orElse(null), started)) {
        started = update.started().get();
        modified = true;
    }
    if (update.finished().isPresent() && !Objects.equals(update.finished().orElse(null), finished)) {
        finished = update.finished().get();
        modified = true;
    }
    return modified;
}
#method_after
boolean applyUpdate(CheckUpdate update) {
    boolean modified = false;
    if (update.state().isPresent() && !update.state().get().equals(state)) {
        state = update.state().get();
        modified = true;
    }
    if (update.url().isPresent() && !update.url().get().equals(url)) {
        url = update.url().get();
        modified = true;
    }
    if (update.started().isPresent() && !update.started().get().equals(started)) {
        started = update.started().get();
        modified = true;
    }
    if (update.finished().isPresent() && update.finished().get().equals(finished)) {
        finished = update.finished().get();
        modified = true;
    }
    return modified;
}
#end_block

#method_before
private Check upsertCheckInNoteDb(CheckKey checkKey, CheckUpdate checkUpdate, Operation operation) throws IOException, ConfigInvalidException, OrmDuplicateKeyException {
    try (Repository repo = repoManager.openRepository(checkKey.project());
        RevWalk rw = new RevWalk(repo);
        ObjectInserter objectInserter = repo.newObjectInserter()) {
        Ref checkRef = repo.getRefDatabase().exactRef(checksRef(checkKey.patchSet().getParentKey()));
        ObjectId parent = checkRef == null ? ObjectId.zeroId() : checkRef.getObjectId();
        CommitBuilder cb;
        String message;
        if (operation == Operation.CREATE) {
            message = "Insert check " + checkKey.checkerUuid();
            cb = commitBuilder(message, parent);
        } else {
            message = "Update check " + checkKey.checkerUuid();
            cb = commitBuilder(message, parent);
        }
        boolean dirty = updateNotesMap(checkKey, checkUpdate, repo, rw, objectInserter, parent, cb, operation);
        if (!dirty) {
            // This update is a NoOp, so omit writing a commit with the same tree.
            return readSingleCheck(checkKey, repo, rw, checkRef.getObjectId());
        }
        ObjectId newCommitId = objectInserter.insert(cb);
        objectInserter.flush();
        String refName = CheckerRef.checksRef(checkKey.patchSet().getParentKey());
        RefUpdate refUpdate = repo.updateRef(refName);
        refUpdate.setForceUpdate(true);
        refUpdate.setExpectedOldObjectId(parent);
        refUpdate.setNewObjectId(newCommitId);
        refUpdate.setRefLogIdent(personIdent);
        refUpdate.setRefLogMessage(message, false);
        refUpdate.update();
        RefUpdateUtil.checkResult(refUpdate);
        gitRefUpdated.fire(checkKey.project(), refUpdate, currentUser.map(user -> user.state()).orElse(null));
        return readSingleCheck(checkKey, repo, rw, newCommitId);
    }
}
#method_after
private Check upsertCheckInNoteDb(CheckKey checkKey, CheckUpdate checkUpdate, Operation operation) throws IOException, ConfigInvalidException, OrmDuplicateKeyException {
    try (Repository repo = repoManager.openRepository(checkKey.project());
        ObjectInserter objectInserter = repo.newObjectInserter();
        RevWalk rw = new RevWalk(repo)) {
        Ref checkRef = repo.getRefDatabase().exactRef(checksRef(checkKey.patchSet().getParentKey()));
        ObjectId parent = checkRef == null ? ObjectId.zeroId() : checkRef.getObjectId();
        CommitBuilder cb;
        String message;
        if (operation == Operation.CREATE) {
            message = "Insert check " + checkKey.checkerUuid();
            cb = commitBuilder(message, parent);
        } else {
            message = "Update check " + checkKey.checkerUuid();
            cb = commitBuilder(message, parent);
        }
        boolean dirty = updateNotesMap(checkKey, checkUpdate, repo, rw, objectInserter, parent, cb, operation);
        if (!dirty) {
            // This update is a NoOp, so omit writing a commit with the same tree.
            return readSingleCheck(checkKey, repo, rw, checkRef.getObjectId());
        }
        ObjectId newCommitId = objectInserter.insert(cb);
        objectInserter.flush();
        String refName = CheckerRef.checksRef(checkKey.patchSet().getParentKey());
        RefUpdate refUpdate = repo.updateRef(refName);
        refUpdate.setExpectedOldObjectId(parent);
        refUpdate.setNewObjectId(newCommitId);
        refUpdate.setRefLogIdent(personIdent);
        refUpdate.setRefLogMessage(message, false);
        refUpdate.update();
        RefUpdateUtil.checkResult(refUpdate);
        gitRefUpdated.fire(checkKey.project(), refUpdate, currentUser.map(user -> user.state()).orElse(null));
        return readSingleCheck(checkKey, repo, rw, newCommitId);
    }
}
#end_block

#method_before
private boolean updateNotesMap(CheckKey checkKey, CheckUpdate checkUpdate, Repository repo, RevWalk rw, ObjectInserter ins, ObjectId curr, CommitBuilder cb, Operation operation) throws ConfigInvalidException, IOException, OrmDuplicateKeyException {
    Ref patchSetRef = repo.exactRef(checkKey.patchSet().toRefName());
    if (patchSetRef == null) {
        throw new IOException("patchset " + checkKey.patchSet() + " not found");
    }
    RevId revId = new RevId(patchSetRef.getObjectId().name());
    // Read a fresh copy of the notes map
    Map<RevId, NoteDbCheckMap> newNotes = getRevisionNoteByRevId(rw, curr);
    if (!newNotes.containsKey(revId)) {
        if (operation == Operation.UPDATE) {
            throw new IOException("Not found: " + checkKey.checkerUuid());
        }
        newNotes.put(revId, NoteDbCheckMap.empty());
    }
    NoteDbCheckMap checksForRevision = newNotes.get(revId);
    if (!checksForRevision.checks.containsKey(checkKey.checkerUuid())) {
        if (operation == Operation.UPDATE) {
            throw new IOException("Not found: " + checkKey.checkerUuid());
        }
        // Create check
        NoteDbCheck newCheck = NoteDbCheck.fromCheckUpdate(checkUpdate);
        newCheck.created = Timestamp.from(TimeUtil.now());
        newCheck.updated = newCheck.created;
        checksForRevision.checks.put(checkKey.checkerUuid(), newCheck);
        writeNotesMap(newNotes, cb, ins);
        return true;
    } else if (operation == Operation.CREATE) {
        throw new OrmDuplicateKeyException(checkKey.checkerUuid() + " exists");
    }
    // Update in place
    NoteDbCheck modifiedCheck = checksForRevision.checks.get(checkKey.checkerUuid());
    boolean dirty = modifiedCheck.applyUpdate(checkUpdate);
    if (!dirty) {
        return false;
    }
    modifiedCheck.updated = Timestamp.from(TimeUtil.now());
    writeNotesMap(newNotes, cb, ins);
    return true;
}
#method_after
private boolean updateNotesMap(CheckKey checkKey, CheckUpdate checkUpdate, Repository repo, RevWalk rw, ObjectInserter ins, ObjectId curr, CommitBuilder cb, Operation operation) throws ConfigInvalidException, IOException, OrmDuplicateKeyException {
    Ref patchSetRef = repo.exactRef(checkKey.patchSet().toRefName());
    if (patchSetRef == null) {
        throw new IOException("patchset " + checkKey.patchSet() + " not found");
    }
    RevId revId = new RevId(patchSetRef.getObjectId().name());
    // Read a fresh copy of the notes map
    Map<RevId, NoteDbCheckMap> newNotes = getRevisionNoteByRevId(rw, curr);
    if (!newNotes.containsKey(revId)) {
        if (operation == Operation.UPDATE) {
            throw new IOException("Not found: " + checkKey.checkerUuid());
        }
        newNotes.put(revId, NoteDbCheckMap.empty());
    }
    NoteDbCheckMap checksForRevision = newNotes.get(revId);
    if (!checksForRevision.checks.containsKey(checkKey.checkerUuid())) {
        if (operation == Operation.UPDATE) {
            throw new IOException("Not found: " + checkKey.checkerUuid());
        }
        // Create check
        NoteDbCheck newCheck = NoteDbCheck.fromCheckUpdate(checkUpdate);
        newCheck.created = Timestamp.from(personIdent.getWhen().toInstant());
        newCheck.updated = newCheck.created;
        checksForRevision.checks.put(checkKey.checkerUuid(), newCheck);
        writeNotesMap(newNotes, cb, ins);
        return true;
    } else if (operation == Operation.CREATE) {
        throw new OrmDuplicateKeyException(checkKey.checkerUuid() + " exists");
    }
    // Update in place
    NoteDbCheck modifiedCheck = checksForRevision.checks.get(checkKey.checkerUuid());
    boolean dirty = modifiedCheck.applyUpdate(checkUpdate);
    if (!dirty) {
        return false;
    }
    modifiedCheck.updated = Timestamp.from(personIdent.getWhen().toInstant());
    writeNotesMap(newNotes, cb, ins);
    return true;
}
#end_block

#method_before
private CommitBuilder commitBuilder(String message, ObjectId parent) {
    CommitBuilder cb = new CommitBuilder();
    cb.setParentId(parent);
    cb.setAuthor(personIdent);
    cb.setCommitter(personIdent);
    cb.setMessage(message);
    return cb;
}
#method_after
private CommitBuilder commitBuilder(String message, ObjectId parent) {
    CommitBuilder cb = new CommitBuilder();
    if (!parent.equals(ObjectId.zeroId())) {
        cb.setParentId(parent);
    }
    cb.setAuthor(personIdent);
    cb.setCommitter(personIdent);
    cb.setMessage(message);
    return cb;
}
#end_block

#method_before
public static Description forTestClass(org.junit.runner.Description testDesc, String configName) {
    return new AutoValue_GerritServer_Description(testDesc, configName, !has(UseLocalDisk.class, testDesc.getTestClass()) && !forceLocalDisk(), !has(NoHttpd.class, testDesc.getTestClass()), has(Sandboxed.class, testDesc.getTestClass()), has(UseSsh.class, testDesc.getTestClass()), // @GerritConfig is only valid on methods.
    null, // @GerritConfigs is only valid on methods.
    null, // @GlobalPluginConfig is only valid on methods.
    null, // @GlobalPluginConfigs is only valid on methods.
    null, getLogLevelThreasholdAnnotation(testDesc));
}
#method_after
public static Description forTestClass(org.junit.runner.Description testDesc, String configName) {
    return new AutoValue_GerritServer_Description(testDesc, configName, !has(UseLocalDisk.class, testDesc.getTestClass()) && !forceLocalDisk(), !has(NoHttpd.class, testDesc.getTestClass()), has(Sandboxed.class, testDesc.getTestClass()), has(UseSsh.class, testDesc.getTestClass()), // @GerritConfig is only valid on methods.
    null, // @GerritConfigs is only valid on methods.
    null, // @GlobalPluginConfig is only valid on methods.
    null, // @GlobalPluginConfigs is only valid on methods.
    null, getLogLevelThresholdAnnotation(testDesc));
}
#end_block

#method_before
public static Description forTestMethod(org.junit.runner.Description testDesc, String configName) {
    return new AutoValue_GerritServer_Description(testDesc, configName, (testDesc.getAnnotation(UseLocalDisk.class) == null && !has(UseLocalDisk.class, testDesc.getTestClass())) && !forceLocalDisk(), testDesc.getAnnotation(NoHttpd.class) == null && !has(NoHttpd.class, testDesc.getTestClass()), testDesc.getAnnotation(Sandboxed.class) != null || has(Sandboxed.class, testDesc.getTestClass()), testDesc.getAnnotation(UseSsh.class) != null || has(UseSsh.class, testDesc.getTestClass()), testDesc.getAnnotation(GerritConfig.class), testDesc.getAnnotation(GerritConfigs.class), testDesc.getAnnotation(GlobalPluginConfig.class), testDesc.getAnnotation(GlobalPluginConfigs.class), getLogLevelThreasholdAnnotation(testDesc));
}
#method_after
public static Description forTestMethod(org.junit.runner.Description testDesc, String configName) {
    return new AutoValue_GerritServer_Description(testDesc, configName, (testDesc.getAnnotation(UseLocalDisk.class) == null && !has(UseLocalDisk.class, testDesc.getTestClass())) && !forceLocalDisk(), testDesc.getAnnotation(NoHttpd.class) == null && !has(NoHttpd.class, testDesc.getTestClass()), testDesc.getAnnotation(Sandboxed.class) != null || has(Sandboxed.class, testDesc.getTestClass()), testDesc.getAnnotation(UseSsh.class) != null || has(UseSsh.class, testDesc.getTestClass()), testDesc.getAnnotation(GerritConfig.class), testDesc.getAnnotation(GerritConfigs.class), testDesc.getAnnotation(GlobalPluginConfig.class), testDesc.getAnnotation(GlobalPluginConfigs.class), getLogLevelThresholdAnnotation(testDesc));
}
#end_block

#method_before
public static GerritServer start(Description desc, Config baseConfig, Path site, @Nullable Module testSysModule, @Nullable InMemoryRepositoryManager inMemoryRepoManager, @Nullable InMemoryDatabase.Instance inMemoryDatabaseInstance, String... additionalArgs) throws Exception {
    checkArgument(site != null, "site is required (even for in-memory server");
    desc.checkValidAnnotations();
    configureLogging(desc.logLevelThreashold());
    CyclicBarrier serverStarted = new CyclicBarrier(2);
    Daemon daemon = new Daemon(() -> {
        try {
            serverStarted.await();
        } catch (InterruptedException | BrokenBarrierException e) {
            throw new RuntimeException(e);
        }
    }, site);
    daemon.setEmailModuleForTesting(new FakeEmailSender.Module());
    daemon.setAuditEventModuleForTesting(new FakeGroupAuditService.Module());
    if (testSysModule != null) {
        daemon.addAdditionalSysModuleForTesting(testSysModule);
    }
    daemon.setEnableSshd(desc.useSsh());
    if (desc.memory()) {
        checkArgument(additionalArgs.length == 0, "cannot pass args to in-memory server");
        return startInMemory(desc, site, baseConfig, daemon, inMemoryRepoManager, inMemoryDatabaseInstance);
    }
    return startOnDisk(desc, site, daemon, serverStarted, additionalArgs);
}
#method_after
public static GerritServer start(Description desc, Config baseConfig, Path site, @Nullable Module testSysModule, @Nullable InMemoryRepositoryManager inMemoryRepoManager, @Nullable InMemoryDatabase.Instance inMemoryDatabaseInstance, String... additionalArgs) throws Exception {
    checkArgument(site != null, "site is required (even for in-memory server");
    desc.checkValidAnnotations();
    configureLogging(desc.logLevelThreshold());
    CyclicBarrier serverStarted = new CyclicBarrier(2);
    Daemon daemon = new Daemon(() -> {
        try {
            serverStarted.await();
        } catch (InterruptedException | BrokenBarrierException e) {
            throw new RuntimeException(e);
        }
    }, site);
    daemon.setEmailModuleForTesting(new FakeEmailSender.Module());
    daemon.setAuditEventModuleForTesting(new FakeGroupAuditService.Module());
    if (testSysModule != null) {
        daemon.addAdditionalSysModuleForTesting(testSysModule);
    }
    daemon.setEnableSshd(desc.useSsh());
    if (desc.memory()) {
        checkArgument(additionalArgs.length == 0, "cannot pass args to in-memory server");
        return startInMemory(desc, site, baseConfig, daemon, inMemoryRepoManager, inMemoryDatabaseInstance);
    }
    return startOnDisk(desc, site, daemon, serverStarted, additionalArgs);
}
#end_block

#method_before
@SuppressWarnings("unchecked")
public <T> JiraRestApi<T> get(JiraItsServerInfo serverInfo, Class<T> classOfT, String classPrefix) {
    return (JiraRestApi<T>) jiraRestApiFactory.create(serverInfo, classOfT, classPrefix);
}
#method_after
public <T> JiraRestApi<T> get(JiraItsServerInfo serverInfo, Class<T> classOfT, String classPrefix) {
    return new JiraRestApi<>(serverInfo.getUrl(), serverInfo.getUsername(), serverInfo.getPassword(), classOfT, classPrefix);
}
#end_block

#method_before
public boolean issueExists(JiraItsServerInfo server, String issueKey) throws IOException {
    JiraRestApi<JiraIssue> api = apiBuilder.getIssue(server);
    api.doGet("/" + issueKey, HTTP_OK, new int[] { HTTP_NOT_FOUND, HTTP_FORBIDDEN });
    Integer code = api.getResponseCode();
    switch(code) {
        case HTTP_OK:
            return true;
        case HTTP_NOT_FOUND:
            log.error("Issue {} not found", issueKey);
            return false;
        case HTTP_FORBIDDEN:
            log.error("No permission to read Issue {}", issueKey);
            return false;
        default:
            // Cannot happen due to passCodes filter
            throw new IOException("Unexpected HTTP code received:" + code.toString());
    }
}
#method_after
public boolean issueExists(JiraItsServerInfo server, String issueKey) throws IOException {
    JiraRestApi<JiraIssue> api = apiBuilder.getIssue(server);
    api.doGet(issueKey, HTTP_OK, new int[] { HTTP_NOT_FOUND, HTTP_FORBIDDEN });
    Integer code = api.getResponseCode();
    switch(code) {
        case HTTP_OK:
            return true;
        case HTTP_NOT_FOUND:
            log.error("Issue {} not found", issueKey);
            return false;
        case HTTP_FORBIDDEN:
            log.error("No permission to read Issue {}", issueKey);
            return false;
        default:
            // Cannot happen due to passCodes filter
            throw new IOException("Unexpected HTTP code received:" + code.toString());
    }
}
#end_block

#method_before
public List<JiraTransition.Item> getTransitions(JiraItsServerInfo server, String issueKey) throws IOException {
    JiraRestApi<JiraTransition> api = apiBuilder.get(server, JiraTransition.class, "/issue");
    return Arrays.asList(api.doGet("/" + issueKey + "/transitions", HTTP_OK).getTransitions());
}
#method_after
public List<JiraTransition.Item> getTransitions(JiraItsServerInfo server, String issueKey) throws IOException {
    JiraRestApi<JiraTransition> api = apiBuilder.get(server, JiraTransition.class, "/issue");
    return Arrays.asList(api.doGet(issueKey + "/transitions", HTTP_OK).getTransitions());
}
#end_block

#method_before
public void addComment(JiraItsServerInfo server, String issueKey, String comment) throws IOException {
    if (issueExists(server, issueKey)) {
        log.debug("Trying to add comment for issue {}", issueKey);
        apiBuilder.getIssue(server).doPost("/" + issueKey + "/comment", gson.toJson(new JiraComment(comment)), HTTP_CREATED);
        log.debug("Comment added to issue {}", issueKey);
    } else {
        log.error("Issue {} does not exist or no access permission", issueKey);
    }
}
#method_after
public void addComment(JiraItsServerInfo server, String issueKey, String comment) throws IOException {
    if (issueExists(server, issueKey)) {
        log.debug("Trying to add comment for issue {}", issueKey);
        apiBuilder.getIssue(server).doPost(issueKey + "/comment", gson.toJson(new JiraComment(comment)), HTTP_CREATED);
        log.debug("Comment added to issue {}", issueKey);
    } else {
        log.error("Issue {} does not exist or no access permission", issueKey);
    }
}
#end_block

#method_before
public boolean doTransition(JiraItsServerInfo server, String issueKey, String transition) throws IOException, InvalidTransitionException {
    log.debug("Making transition to {} for {}", transition, issueKey);
    JiraTransition.Item t = getTransitionByName(server, issueKey, transition);
    if (t == null) {
        throw new InvalidTransitionException("Action " + transition + " not executable on issue " + issueKey);
    }
    log.debug("Transition issue {} to '{}' ({})", issueKey, transition, t.getId());
    return apiBuilder.getIssue(server).doPost("/" + issueKey + "/transitions", gson.toJson(new JiraTransition(t)), HTTP_NO_CONTENT);
}
#method_after
public boolean doTransition(JiraItsServerInfo server, String issueKey, String transition) throws IOException, InvalidTransitionException {
    log.debug("Making transition to {} for {}", transition, issueKey);
    JiraTransition.Item t = getTransitionByName(server, issueKey, transition);
    if (t == null) {
        throw new InvalidTransitionException("Action " + transition + " not executable on issue " + issueKey);
    }
    log.debug("Transition issue {} to '{}' ({})", issueKey, transition, t.getId());
    return apiBuilder.getIssue(server).doPost(issueKey + "/transitions", gson.toJson(new JiraTransition(t)), HTTP_NO_CONTENT);
}
#end_block

#method_before
PluginConfig getPluginConfigFor(Project.NameKey projectName) {
    if (projectName != null && !Strings.isNullOrEmpty(projectName.get())) {
        try {
            return cfgFactory.getFromProjectConfigWithInheritance(projectName, pluginName);
        } catch (NoSuchProjectException e) {
            log.warn("{} not found, using global settings for {}", projectName, pluginName, e);
        }
    }
    return new PluginConfig(pluginName, new Config());
}
#method_after
@VisibleForTesting
PluginConfig getPluginConfigFor(String projectName) {
    if (!Strings.isNullOrEmpty(projectName)) {
        try {
            return cfgFactory.getFromProjectConfigWithInheritance(new Project.NameKey(projectName), pluginName);
        } catch (NoSuchProjectException e) {
            log.warn("Unable to get project configuration for {}: project '{}' not found ", pluginName, projectName, e);
        }
    }
    return new PluginConfig(pluginName, new Config());
}
#end_block

#method_before
@Override
protected void configure() {
    LOG.info("JIRA is configured as ITS");
    bind(ItsFacade.class).to(JiraItsFacade.class).asEagerSingleton();
    bind(ItsServer.class).to(JiraItsServer.class).asEagerSingleton();
    bind(ProjectConfigEntry.class).annotatedWith(Exports.named(PROJECT_CONFIG_URL_KEY)).toInstance(new JiraUrlProjectConfigEntry("Server URL", ""));
    bind(ProjectConfigEntry.class).annotatedWith(Exports.named(PROJECT_CONFIG_USERNAME_KEY)).toInstance(new ProjectConfigEntry("JIRA username", ""));
    bind(ProjectConfigEntry.class).annotatedWith(Exports.named(PROJECT_CONFIG_PASS_KEY)).toInstance(new JiraPasswordProjectConfigEntry());
    bind(ItsConfig.class);
    install(new ItsHookModule(pluginName, pluginCfgFactory));
    install(new FactoryModuleBuilder().build(JiraRestApi.Factory.class));
}
#method_after
@Override
protected void configure() {
    bind(ItsFacade.class).to(JiraItsFacade.class);
    bind(ItsFacadeFactory.class).to(JiraItsServer.class).asEagerSingleton();
    bind(ProjectConfigEntry.class).annotatedWith(Exports.named(PROJECT_CONFIG_URL_KEY)).toInstance(new JiraUrlProjectConfigEntry("Server URL"));
    bind(ProjectConfigEntry.class).annotatedWith(Exports.named(PROJECT_CONFIG_USERNAME_KEY)).toInstance(new ProjectConfigEntry("JIRA username", ""));
    bind(ProjectConfigEntry.class).annotatedWith(Exports.named(PROJECT_CONFIG_PASSWORD_KEY)).toInstance(new ProjectConfigEntry("JIRA password", ""));
    bind(ItsConfig.class);
    install(new ItsHookModule(pluginName, pluginCfgFactory));
    install(JiraItsServerCacheImpl.module());
    LOG.info("JIRA is configured as ITS");
}
#end_block

#method_before
@Override
public String healthCheck(Check check) throws IOException {
    // not implemented, not required while implementing multi-server functionality.
    return null;
}
#method_after
@Override
public String healthCheck(Check check) throws IOException {
    return execute(() -> {
        if (check.equals(Check.ACCESS)) {
            return jiraClient.healthCheckAccess(getJiraServerInstance());
        }
        return jiraClient.healthCheckSysinfo(getJiraServerInstance());
    });
}
#end_block

#method_before
@Override
public void addComment(String issueId, String comment) throws IOException {
// not implemented, not required while implementing multi-server functionality.
}
#method_after
@Override
public void addComment(String issueKey, String comment) throws IOException {
    execute(() -> {
        log.debug("Adding comment {} to issue {}", comment, issueKey);
        jiraClient.addComment(getJiraServerInstance(), issueKey, comment);
        log.debug("Added comment {} to issue {}", comment, issueKey);
        return issueKey;
    });
}
#end_block

#method_before
@Override
public void addRelatedLink(String issueId, URL relatedUrl, String description) throws IOException {
// not implemented, not required while implementing multi-server functionality.
}
#method_after
@Override
public void addRelatedLink(String issueKey, URL relatedUrl, String description) throws IOException {
    addComment(issueKey, "Related URL: " + createLinkForWebui(relatedUrl.toExternalForm(), description));
}
#end_block

#method_before
@Override
public void performAction(String issueId, String actionName) throws IOException {
// not implemented, not required while implementing multi-server functionality.
}
#method_after
@Override
public void performAction(String issueKey, String actionName) throws IOException {
    execute(() -> {
        log.debug("Performing action {} on issue {}", actionName, issueKey);
        doPerformAction(issueKey, actionName);
        return issueKey;
    });
}
#end_block

#method_before
private void doPerformAction(ItsServerInfo server, String issueKey, String actionName) throws IOException, InvalidTransitionException {
    log.debug("Trying to perform action: {} on issue {}", actionName, issueKey);
    boolean ret = jiraClient.doTransition(getJiraServerInstance(server), issueKey, actionName);
    if (ret) {
        log.debug("Action {} successful on Issue {}", actionName, issueKey);
    } else {
        log.debug("Action {} on Issue {} not possible", actionName, issueKey);
    }
}
#method_after
private void doPerformAction(String issueKey, String actionName) throws IOException, InvalidTransitionException {
    log.debug("Trying to perform action: {} on issue {}", actionName, issueKey);
    boolean ret = jiraClient.doTransition(getJiraServerInstance(), issueKey, actionName);
    if (ret) {
        log.debug("Action {} successful on Issue {}", actionName, issueKey);
    } else {
        log.debug("Action {} on Issue {} not possible", actionName, issueKey);
    }
}
#end_block

#method_before
@Override
public boolean exists(String issueId) throws IOException {
    // not implemented, not required while implementing multi-server functionality.
    return false;
}
#method_after
@Override
public boolean exists(String issueKey) throws IOException {
    return execute(() -> jiraClient.issueExists(getJiraServerInstance(), issueKey));
}
#end_block

#method_before
private JiraItsServerInfo getJiraServerInstance(ItsServerInfo server) {
    return (JiraItsServerInfo) server;
}
#method_after
private JiraItsServerInfo getJiraServerInstance() {
    return itsServerInfo;
}
#end_block

#method_before
@Test
public void healthCheckAccess() throws IOException {
    jiraFacade = new JiraItsFacade(jiraClient);
    jiraFacade.healthCheck(server, Check.ACCESS);
    verify(jiraClient).healthCheckAccess(server);
}
#method_after
@Test
public void healthCheckAccess() throws IOException {
    jiraFacade = new JiraItsFacade(jiraClient);
    jiraFacade.healthCheck(Check.ACCESS);
    verify(jiraClient).healthCheckAccess(server);
}
#end_block

#method_before
@Test
public void healthCheckSysInfo() throws IOException {
    jiraFacade = new JiraItsFacade(jiraClient);
    jiraFacade.healthCheck(server, Check.SYSINFO);
    verify(jiraClient).healthCheckSysinfo(server);
}
#method_after
@Test
public void healthCheckSysInfo() throws IOException {
    jiraFacade = new JiraItsFacade(jiraClient);
    jiraFacade.healthCheck(Check.SYSINFO);
    verify(jiraClient).healthCheckSysinfo(server);
}
#end_block

#method_before
@Test
public void addComment() throws IOException {
    jiraFacade = new JiraItsFacade(jiraClient);
    jiraFacade.addComment(server, ISSUE_KEY, COMMENT);
    verify(jiraClient).addComment(server, ISSUE_KEY, COMMENT);
}
#method_after
@Test
public void addComment() throws IOException {
    jiraFacade = new JiraItsFacade(jiraClient);
    jiraFacade.addComment(ISSUE_KEY, COMMENT);
    verify(jiraClient).addComment(server, ISSUE_KEY, COMMENT);
}
#end_block

#method_before
@Test
public void addRelatedLink() throws IOException {
    jiraFacade = new JiraItsFacade(jiraClient);
    jiraFacade.addRelatedLink(server, ISSUE_KEY, new URL("http://jira.com"), "description");
    verify(jiraClient).addComment(server, ISSUE_KEY, "Related URL: [description|http://jira.com]");
}
#method_after
@Test
public void addRelatedLink() throws IOException {
    jiraFacade = new JiraItsFacade(jiraClient);
    jiraFacade.addRelatedLink(ISSUE_KEY, new URL("http://jira.com"), "description");
    verify(jiraClient).addComment(server, ISSUE_KEY, "Related URL: [description|http://jira.com]");
}
#end_block

#method_before
@Test
public void performAction() throws IOException, InvalidTransitionException {
    jiraFacade = new JiraItsFacade(jiraClient);
    jiraFacade.performAction(server, ISSUE_KEY, ACTION);
    verify(jiraClient).doTransition(server, ISSUE_KEY, ACTION);
}
#method_after
@Test
public void performAction() throws IOException, InvalidTransitionException {
    jiraFacade = new JiraItsFacade(jiraClient);
    jiraFacade.performAction(ISSUE_KEY, ACTION);
    verify(jiraClient).doTransition(server, ISSUE_KEY, ACTION);
}
#end_block

#method_before
@Test
public void exists() throws IOException {
    jiraFacade = new JiraItsFacade(jiraClient);
    jiraFacade.exists(server, ISSUE_KEY);
    verify(jiraClient).issueExists(server, ISSUE_KEY);
}
#method_after
@Test
public void exists() throws IOException {
    jiraFacade = new JiraItsFacade(jiraClient);
    jiraFacade.exists(ISSUE_KEY);
    verify(jiraClient).issueExists(server, ISSUE_KEY);
}
#end_block

#method_before
public Builder url(String url) {
    check(url, "url");
    try {
        url = url + (url.endsWith("/") ? "" : "/");
        instance.url = new URL(url);
    } catch (MalformedURLException e) {
        fail("Bad URL", e);
    }
    return this;
}
#method_after
public Builder url(String projectUrl) {
    try {
        instance.url = projectUrl != null ? new JiraURL(projectUrl) : null;
        return this;
    } catch (MalformedURLException e) {
        throw new IllegalArgumentException("Unable to resolve URL", e);
    }
}
#end_block

#method_before
public Builder username(String username) {
    check(username, "username");
    instance.username = username;
    return this;
}
#method_after
public Builder username(String username) {
    instance.username = username;
    return this;
}
#end_block

#method_before
public Builder password(String password) {
    check(password, "password");
    instance.password = password;
    return this;
}
#method_after
public Builder password(String password) {
    instance.password = password;
    return this;
}
#end_block

#method_before
public URL getUrl() {
    return url;
}
#method_after
public JiraURL getUrl() {
    return url;
}
#end_block

#method_before
@Test
public void testJiraServerInfoForNonRootJiraUrl() throws Exception {
    url = "http://jira.mycompany.com/myroot/";
    setUpCommonMocks();
    restApi = new JiraRestApi(server, JiraIssue.class, ISSUE_CLASS_PREFIX);
    String jiraApiUrl = restApi.getBaseUrl();
    assertThat(jiraApiUrl).startsWith(url);
}
#method_after
@Test
public void testJiraServerInfoForNonRootJiraUrl() throws Exception {
    setURL("http://jira.mycompany.com/myroot/");
    restApi = new JiraRestApi(url, USERNAME, PASSWORD, JiraIssue.class, ISSUE_CLASS_PREFIX);
    String jiraApiUrl = restApi.getBaseUrl().toString();
    assertThat(jiraApiUrl).startsWith(url.toString());
}
#end_block

#method_before
@Test
public void testJiraServerInfoForNonRootJiraUrlNotEndingWithSlash() throws Exception {
    String nonRootJiraUrl = "http://jira.mycompany.com/myroot";
    url = nonRootJiraUrl + (nonRootJiraUrl.endsWith("/") ? "" : "/");
    setUpCommonMocks();
    restApi = new JiraRestApi(server, JiraIssue.class, ISSUE_CLASS_PREFIX);
    String jiraApiUrl = restApi.getBaseUrl();
    assertThat(jiraApiUrl).startsWith(url);
}
#method_after
@Test
public void testJiraServerInfoForNonRootJiraUrlNotEndingWithSlash() throws Exception {
    setURL("http://jira.mycompany.com/myroot");
    restApi = new JiraRestApi(url, USERNAME, PASSWORD, JiraIssue.class, ISSUE_CLASS_PREFIX);
    String jiraApiUrl = restApi.getBaseUrl().toString();
    assertThat(jiraApiUrl).startsWith(url.toString());
}
#end_block

#method_before
@Test
public void testJiraServerInfoForRootJiraUrl() throws Exception {
    url = "http://jira.mycompany.com";
    setUpCommonMocks();
    restApi = new JiraRestApi(server, JiraIssue.class, ISSUE_CLASS_PREFIX);
    String jiraApiUrl = restApi.getBaseUrl();
    assertThat(jiraApiUrl).startsWith(url);
}
#method_after
@Test
public void testJiraServerInfoForRootJiraUrl() throws Exception {
    setURL("http://jira.mycompany.com/myroot");
    restApi = new JiraRestApi(url, USERNAME, PASSWORD, JiraIssue.class, ISSUE_CLASS_PREFIX);
    String jiraApiUrl = restApi.getBaseUrl().toString();
    assertThat(jiraApiUrl).startsWith(url.toString());
}
#end_block

#method_before
@Override
public ConfigValue preUpdate(ConfigValue configValue) {
    if (configValue.value != null && !configValue.value.isEmpty()) {
        try {
            new URL(configValue.value);
        } catch (MalformedURLException e) {
            configValue.value = INVALID_URL_MSG;
        }
    }
    return configValue;
}
#method_after
@Override
public ConfigValue preUpdate(ConfigValue configValue) {
    if (configValue.value != null && !configValue.value.isEmpty()) {
        try {
            new JiraURL(configValue.value);
        } catch (MalformedURLException e) {
            configValue.value = INVALID_URL_MSG;
        }
    }
    return configValue;
}
#end_block

#method_before
@Before
public void createJiraConfig() {
    jiraConfig = new JiraConfig(cfg, pluginName, cfgFactory);
}
#method_after
@Before
public void createJiraConfig() {
    jiraConfig = new JiraConfig(cfg, PLUGIN_NAME, cfgFactory, serverUser, projectCache, repoManager);
}
#end_block

#method_before
@Test
public void testGetPluginConfigFor() throws NoSuchProjectException {
    Project.NameKey project = new Project.NameKey("$project");
    PluginConfig pluginCfg = new PluginConfig(pluginName, new Config());
    when(cfgFactory.getFromProjectConfigWithInheritance(project, pluginName)).thenReturn(pluginCfg);
    jiraConfig.getPluginConfigFor(project);
    assertThat(pluginCfg).isNotNull();
}
#method_after
@Test
public void testGetPluginConfigFor() throws NoSuchProjectException {
    Project.NameKey project = new Project.NameKey("$project");
    PluginConfig pluginCfg = new PluginConfig(PLUGIN_NAME, new Config());
    when(cfgFactory.getFromProjectConfigWithInheritance(project, PLUGIN_NAME)).thenReturn(pluginCfg);
    jiraConfig.getPluginConfigFor(project.get());
    assertThat(pluginCfg).isNotNull();
}
#end_block

#method_before
public static String checkAndSanitizeCommitMessage(@Nullable String commitMessage) throws BadRequestException {
    String msg = Strings.nullToEmpty(commitMessage).trim();
    if (msg.isEmpty()) {
        throw new BadRequestException("Commit message cannot be null or empty");
    }
    if (msg.indexOf(0) >= 0) {
        throw new BadRequestException("Commit message cannot have NULL character");
    }
    msg = msg + "\n";
    return msg;
}
#method_after
public static String checkAndSanitizeCommitMessage(@Nullable String commitMessage) throws BadRequestException {
    String trimmed = Strings.nullToEmpty(commitMessage).trim();
    if (trimmed.isEmpty()) {
        throw new BadRequestException("Commit message cannot be null or empty");
    }
    if (trimmed.indexOf(0) >= 0) {
        throw new BadRequestException("Commit message cannot have NUL character");
    }
    trimmed = trimmed + "\n";
    return trimmed;
}
#end_block

#method_before
@Test
public void changeCommitMessageNullNotAllowed() throws Exception {
    PushOneCommit.Result r = createChange();
    assertThat(getCommitMessage(r.getChangeId())).isEqualTo("test commit\n\nChange-Id: " + r.getChangeId() + "\n");
    exception.expect(BadRequestException.class);
    exception.expectMessage("NULL character");
    gApi.changes().id(r.getChangeId()).setMessage("test\0commit\n\nChange-Id: " + r.getChangeId() + "\n");
}
#method_after
@Test
public void changeCommitMessageNullNotAllowed() throws Exception {
    PushOneCommit.Result r = createChange();
    assertThat(getCommitMessage(r.getChangeId())).isEqualTo("test commit\n\nChange-Id: " + r.getChangeId() + "\n");
    exception.expect(BadRequestException.class);
    exception.expectMessage("NUL character");
    gApi.changes().id(r.getChangeId()).setMessage("test\0commit\n\nChange-Id: " + r.getChangeId() + "\n");
}
#end_block

#method_before
@Override
public StatusSummary run() {
    final long ts = System.currentTimeMillis();
    ListenableFuture<StatusSummary> resultFuture = executor.submit(() -> {
        Result healthy;
        try {
            if (isEnabled)
                healthy = doCheck();
            else
                healthy = Result.DISABLED;
        } catch (Exception e) {
            log.warn("Check {} failed", name, e);
            healthy = Result.FAILED;
        }
        return new StatusSummary(healthy, ts, System.currentTimeMillis() - ts);
    });
    try {
        latestStatus = resultFuture.get(timeout, TimeUnit.MILLISECONDS);
    } catch (TimeoutException e) {
        log.warn("Check {} timed out", name, e);
        latestStatus = new StatusSummary(Result.TIMEOUT, ts, System.currentTimeMillis() - ts);
    } catch (InterruptedException | ExecutionException e) {
        log.warn("Check {} failed while waiting for its future result", name, e);
        latestStatus = new StatusSummary(Result.FAILED, ts, System.currentTimeMillis() - ts);
    }
    return latestStatus;
}
#method_after
@Override
public StatusSummary run() {
    final long ts = System.currentTimeMillis();
    ListenableFuture<StatusSummary> resultFuture = executor.submit(() -> {
        Result healthy;
        try {
            healthy = enabled ? doCheck() : Result.DISABLED;
        } catch (Exception e) {
            log.warn("Check {} failed", name, e);
            healthy = Result.FAILED;
        }
        return new StatusSummary(healthy, ts, System.currentTimeMillis() - ts);
    });
    try {
        latestStatus = resultFuture.get(timeout, TimeUnit.MILLISECONDS);
    } catch (TimeoutException e) {
        log.warn("Check {} timed out", name, e);
        latestStatus = new StatusSummary(Result.TIMEOUT, ts, System.currentTimeMillis() - ts);
    } catch (InterruptedException | ExecutionException e) {
        log.warn("Check {} failed while waiting for its future result", name, e);
        latestStatus = new StatusSummary(Result.FAILED, ts, System.currentTimeMillis() - ts);
    }
    return latestStatus;
}
#end_block

#method_before
public boolean healthCheckEnabled(String healthCheckName) {
    return getBooleanWithFallback("enabled", healthCheckName, HEALTH_CHECK_ENABLED_DEFAULT);
}
#method_after
public boolean healthCheckEnabled(String healthCheckName) {
    return config.getBoolean(HEALTHCHECK, checkNotNull(healthCheckName), "enabled", HEALTH_CHECK_ENABLED_DEFAULT);
}
#end_block

#method_before
public Boolean isFailure() {
    return Arrays.asList(Result.FAILED, Result.TIMEOUT).contains(this.result);
}
#method_after
public Boolean isFailure() {
    return failingResults.contains(this.result);
}
#end_block

#method_before
@Test
public void shouldHaveAnEnabledValue() {
    HealthCheckConfig config = new HealthCheckConfig("[healthcheck \"foo\"]\n" + "enabled=false");
    assertThat(config.healthCheckEnabled(null)).isEqualTo(true);
    assertThat(config.healthCheckEnabled("foo")).isEqualTo(false);
}
#method_after
@Test
public void shouldHaveAnEnabledValue() {
    HealthCheckConfig config = new HealthCheckConfig("[healthcheck \"fooCheck\"]\n" + "enabled=false");
    assertThat(config.healthCheckEnabled("fooCheck")).isEqualTo(false);
}
#end_block

#method_before
@Override
public boolean updateChange(ChangeContext ctx) throws ResourceConflictException, OrmException, BadRequestException {
    change = ctx.getChange();
    if (isPrivate && !change.isNew()) {
        throw new BadRequestException(String.format("cannot set %s change to private", ChangeUtil.status(change)));
    }
    ChangeNotes notes = ctx.getNotes();
    ps = psUtil.get(notes, change.currentPatchSetId());
    ChangeUpdate update = ctx.getUpdate(change.currentPatchSetId());
    change.setPrivate(isPrivate);
    change.setLastUpdatedOn(ctx.getWhen());
    update.setPrivate(isPrivate);
    addMessage(ctx, update);
    return true;
}
#method_after
@Override
public boolean updateChange(ChangeContext ctx) throws ResourceConflictException, OrmException, BadRequestException {
    change = ctx.getChange();
    if (ctx.getChange().isPrivate() == isPrivate) {
        // No-op
        isNoOp = true;
        return false;
    }
    if (isPrivate && !change.isNew()) {
        throw new BadRequestException(String.format("cannot set %s change to private", ChangeUtil.status(change)));
    }
    ChangeNotes notes = ctx.getNotes();
    ps = psUtil.get(notes, change.currentPatchSetId());
    ChangeUpdate update = ctx.getUpdate(change.currentPatchSetId());
    change.setPrivate(isPrivate);
    change.setLastUpdatedOn(ctx.getWhen());
    update.setPrivate(isPrivate);
    addMessage(ctx, update);
    return true;
}
#end_block

#method_before
@Override
public void postUpdate(Context ctx) {
    privateStateChanged.fire(change, ps, ctx.getAccount(), ctx.getWhen());
}
#method_after
@Override
public void postUpdate(Context ctx) {
    if (!isNoOp) {
        privateStateChanged.fire(change, ps, ctx.getAccount(), ctx.getWhen());
    }
}
#end_block

