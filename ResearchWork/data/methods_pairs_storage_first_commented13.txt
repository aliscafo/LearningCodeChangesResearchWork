346
#method_before
void createDBIfNotCreated() throws SQLException {
    execute(SQLTable.createTableQuery(databaseType));
    execute(SQLTable.createIndexes(databaseType));
}
#method_after
void createDBIfNotCreated() throws SQLException {
    execute(SQLTable.createTableQuery(databaseDialect));
    execute(SQLTable.createIndexes(databaseDialect));
}
#end_block

#method_before
static String createTableQuery(String databaseType) {
    StringBuilder query = new StringBuilder(140);
    query.append(format("CREATE TABLE IF NOT EXISTS %s(", TABLE_NAME));
    if (databaseType.equals("postgres")) {
        query.append(format("%s SERIAL PRIMARY KEY,", PRIMARY_ENTRY));
    } else {
        query.append(format("%s INT AUTO_INCREMENT PRIMARY KEY,", PRIMARY_ENTRY));
    }
    query.append(format("%s VARCHAR(255),", PROJECT_ENTRY));
    query.append(format("%s TIMESTAMP DEFAULT NOW(),", DATE_ENTRY));
    query.append(format("%s TEXT)", EVENT_ENTRY));
    return query.toString();
}
#method_after
static String createTableQuery(SQLDialect databaseDialect) {
    StringBuilder query = new StringBuilder(140);
    query.append(format("CREATE TABLE IF NOT EXISTS %s(", TABLE_NAME));
    switch(databaseDialect) {
        case POSTGRESQL:
            query.append(format("%s SERIAL PRIMARY KEY,", PRIMARY_ENTRY));
            break;
        case MYSQL:
        case H2:
        default:
            query.append(format("%s INT AUTO_INCREMENT PRIMARY KEY,", PRIMARY_ENTRY));
    }
    query.append(format("%s VARCHAR(255),", PROJECT_ENTRY));
    query.append(format("%s TIMESTAMP DEFAULT NOW(),", DATE_ENTRY));
    query.append(format("%s TEXT)", EVENT_ENTRY));
    return query.toString();
}
#end_block

#method_before
static String createIndexes(String databaseType) {
    if (databaseType.equals("postgres")) {
        return getPostgresqlQuery();
    } else if (databaseType.equals("mysql")) {
        return getMysqlQuery();
    } else {
        return getH2Query();
    }
}
#method_after
static String createIndexes(SQLDialect databaseDialect) {
    switch(databaseDialect) {
        case POSTGRESQL:
            return getPostgresqlIndexQuery();
        case MYSQL:
            return getMysqlIndexQuery();
        case H2:
        default:
            return getH2IndexQuery();
    }
}
#end_block

#method_before
Map<String, Ref> filter(Map<String, Ref> refs, Repository repo, RefFilterOptions opts) throws PermissionBackendException {
    if (projectState.isAllUsers()) {
        refs = addUsersSelfSymref(refs);
    }
    PermissionBackend.WithUser withUser = permissionBackend.user(user);
    if (!projectState.isAllUsers()) {
        if (projectState.statePermitsRead() && checkProjectPermission(permissionBackendForProject, ProjectPermission.READ)) {
            return refs;
        } else if (projectControl.allRefsAreVisible(ImmutableSet.of(RefNames.REFS_CONFIG))) {
            return fastHideRefsMetaConfig(refs);
        }
    }
    boolean viewMetadata;
    boolean isAdmin;
    Account.Id userId;
    IdentifiedUser identifiedUser;
    if (user.isIdentifiedUser()) {
        viewMetadata = withUser.testOrFalse(GlobalPermission.ACCESS_DATABASE);
        isAdmin = withUser.testOrFalse(GlobalPermission.ADMINISTRATE_SERVER);
        identifiedUser = user.asIdentifiedUser();
        userId = identifiedUser.getAccountId();
    } else {
        viewMetadata = false;
        isAdmin = false;
        userId = null;
        identifiedUser = null;
    }
    Map<String, Ref> result = new HashMap<>();
    List<Ref> deferredTags = new ArrayList<>();
    for (Ref ref : refs.values()) {
        String name = ref.getName();
        Change.Id changeId;
        Account.Id accountId;
        AccountGroup.UUID accountGroupUuid;
        if (name.startsWith(REFS_CACHE_AUTOMERGE) || (opts.filterMeta() && isMetadata(name))) {
            continue;
        } else if (RefNames.isRefsEdit(name)) {
            // Edits are visible only to the owning user, if change is visible.
            if (viewMetadata || visibleEdit(repo, name)) {
                result.put(name, ref);
            }
        } else if ((changeId = Change.Id.fromRef(name)) != null) {
            // Change ref is visible only if the change is visible.
            if (viewMetadata || visible(repo, changeId)) {
                result.put(name, ref);
            }
        } else if ((accountId = Account.Id.fromRef(name)) != null) {
            // Account ref is visible only to the corresponding account.
            if (viewMetadata || (accountId.equals(userId) && canReadRef(name))) {
                result.put(name, ref);
            }
        } else if ((accountGroupUuid = AccountGroup.UUID.fromRef(name)) != null) {
            // Group ref is visible only to the corresponding owner group.
            InternalGroup group = groupCache.get(accountGroupUuid).orElse(null);
            if (viewMetadata || (group != null && isGroupOwner(group, identifiedUser, isAdmin) && canReadRef(name))) {
                result.put(name, ref);
            }
        } else if (isTag(ref)) {
            // If its a tag, consider it later.
            if (ref.getObjectId() != null) {
                deferredTags.add(ref);
            }
        } else if (name.startsWith(RefNames.REFS_SEQUENCES)) {
            // Sequences are internal database implementation details.
            if (viewMetadata) {
                result.put(name, ref);
            }
        } else if (projectState.isAllUsers() && (name.equals(RefNames.REFS_EXTERNAL_IDS) || name.equals(RefNames.REFS_GROUPNAMES))) {
            // users.
            if (viewMetadata) {
                result.put(name, ref);
            }
        } else if (canReadRef(ref.getLeaf().getName())) {
            // Use the leaf to lookup the control data. If the reference is
            // symbolic we want the control around the final target. If its
            // not symbolic then getLeaf() is a no-op returning ref itself.
            result.put(name, ref);
        } else if (isRefsUsersSelf(ref)) {
            // well
            if (viewMetadata) {
                result.put(name, ref);
            }
        }
    }
    // 
    if (!deferredTags.isEmpty() && (!result.isEmpty() || opts.filterTagsSeparately())) {
        TagMatcher tags = tagCache.get(projectState.getNameKey()).matcher(tagCache, repo, opts.filterTagsSeparately() ? filter(repo.getAllRefs(), repo, opts.toBuilder().setFilterTagsSeparately(false).build()).values() : result.values());
        for (Ref tag : deferredTags) {
            if (tags.isReachable(tag)) {
                result.put(tag.getName(), tag);
            }
        }
    }
    return result;
}
#method_after
Map<String, Ref> filter(Map<String, Ref> refs, Repository repo, RefFilterOptions opts) throws PermissionBackendException {
    if (projectState.isAllUsers()) {
        refs = addUsersSelfSymref(refs);
    }
    if (!projectState.isAllUsers()) {
        if (projectState.statePermitsRead() && checkProjectPermission(permissionBackendForProject, ProjectPermission.READ)) {
            return refs;
        } else if (projectControl.allRefsAreVisible(ImmutableSet.of(RefNames.REFS_CONFIG))) {
            return fastHideRefsMetaConfig(refs);
        }
    }
    boolean viewMetadata;
    boolean isAdmin;
    Account.Id userId;
    IdentifiedUser identifiedUser;
    PermissionBackend.WithUser withUser = permissionBackend.user(user);
    if (user.isIdentifiedUser()) {
        viewMetadata = withUser.testOrFalse(GlobalPermission.ACCESS_DATABASE);
        isAdmin = withUser.testOrFalse(GlobalPermission.ADMINISTRATE_SERVER);
        identifiedUser = user.asIdentifiedUser();
        userId = identifiedUser.getAccountId();
    } else {
        viewMetadata = false;
        isAdmin = false;
        userId = null;
        identifiedUser = null;
    }
    Map<String, Ref> result = new HashMap<>();
    List<Ref> deferredTags = new ArrayList<>();
    for (Ref ref : refs.values()) {
        String name = ref.getName();
        Change.Id changeId;
        Account.Id accountId;
        AccountGroup.UUID accountGroupUuid;
        if (name.startsWith(REFS_CACHE_AUTOMERGE) || (opts.filterMeta() && isMetadata(name))) {
            continue;
        } else if (RefNames.isRefsEdit(name)) {
            // Edits are visible only to the owning user, if change is visible.
            if (viewMetadata || visibleEdit(repo, name)) {
                result.put(name, ref);
            }
        } else if ((changeId = Change.Id.fromRef(name)) != null) {
            // Change ref is visible only if the change is visible.
            if (viewMetadata || visible(repo, changeId)) {
                result.put(name, ref);
            }
        } else if ((accountId = Account.Id.fromRef(name)) != null) {
            // Account ref is visible only to the corresponding account.
            if (viewMetadata || (accountId.equals(userId) && canReadRef(name))) {
                result.put(name, ref);
            }
        } else if ((accountGroupUuid = AccountGroup.UUID.fromRef(name)) != null) {
            // Group ref is visible only to the corresponding owner group.
            InternalGroup group = groupCache.get(accountGroupUuid).orElse(null);
            if (viewMetadata || (group != null && isGroupOwner(group, identifiedUser, isAdmin) && canReadRef(name))) {
                result.put(name, ref);
            }
        } else if (isTag(ref)) {
            // If its a tag, consider it later.
            if (ref.getObjectId() != null) {
                deferredTags.add(ref);
            }
        } else if (name.startsWith(RefNames.REFS_SEQUENCES)) {
            // Sequences are internal database implementation details.
            if (viewMetadata) {
                result.put(name, ref);
            }
        } else if (projectState.isAllUsers() && (name.equals(RefNames.REFS_EXTERNAL_IDS) || name.equals(RefNames.REFS_GROUPNAMES))) {
            // users.
            if (viewMetadata) {
                result.put(name, ref);
            }
        } else if (canReadRef(ref.getLeaf().getName())) {
            // Use the leaf to lookup the control data. If the reference is
            // symbolic we want the control around the final target. If its
            // not symbolic then getLeaf() is a no-op returning ref itself.
            result.put(name, ref);
        } else if (isRefsUsersSelf(ref)) {
            // well
            if (viewMetadata) {
                result.put(name, ref);
            }
        }
    }
    // 
    if (!deferredTags.isEmpty() && (!result.isEmpty() || opts.filterTagsSeparately())) {
        TagMatcher tags = tagCache.get(projectState.getNameKey()).matcher(tagCache, repo, opts.filterTagsSeparately() ? filter(repo.getAllRefs(), repo, opts.toBuilder().setFilterTagsSeparately(false).build()).values() : result.values());
        for (Ref tag : deferredTags) {
            if (tags.isReachable(tag)) {
                result.put(tag.getName(), tag);
            }
        }
    }
    return result;
}
#end_block

#method_before
private Map<String, Ref> fastHideRefsMetaConfig(Map<String, Ref> refs) {
    if (refs.containsKey(REFS_CONFIG) && !canReadRef(REFS_CONFIG)) {
        Map<String, Ref> r = new HashMap<>(refs);
        r.remove(REFS_CONFIG);
        return r;
    }
    return refs;
}
#method_after
private Map<String, Ref> fastHideRefsMetaConfig(Map<String, Ref> refs) throws PermissionBackendException {
    if (refs.containsKey(REFS_CONFIG) && !canReadRef(REFS_CONFIG)) {
        Map<String, Ref> r = new HashMap<>(refs);
        r.remove(REFS_CONFIG);
        return r;
    }
    return refs;
}
#end_block

#method_before
private Map<Change.Id, Branch.NameKey> visibleChangesBySearch() throws PermissionBackendException {
    Project.NameKey project = projectState.getNameKey();
    try {
        Map<Change.Id, Branch.NameKey> visibleChanges = new HashMap<>();
        for (ChangeData cd : changeCache.getChangeData(db.get(), project)) {
            ChangeNotes notes = changeNotesFactory.createFromIndexedChange(cd.change());
            if (projectState.statePermitsRead() && permissionBackendForProject.indexedChange(cd, notes).test(ChangePermission.READ)) {
                visibleChanges.put(cd.getId(), cd.change().getDest());
            }
        }
        return visibleChanges;
    } catch (OrmException e) {
        log.error("Cannot load changes for project " + project + ", assuming no changes are visible", e);
        return Collections.emptyMap();
    }
}
#method_after
private Map<Change.Id, Branch.NameKey> visibleChangesBySearch() throws PermissionBackendException {
    Project.NameKey project = projectState.getNameKey();
    try {
        Map<Change.Id, Branch.NameKey> visibleChanges = new HashMap<>();
        for (ChangeData cd : changeCache.getChangeData(db.get(), project)) {
            ChangeNotes notes = changeNotesFactory.createFromIndexedChange(cd.change());
            if (!projectState.statePermitsRead()) {
                continue;
            }
            try {
                permissionBackendForProject.indexedChange(cd, notes).check(ChangePermission.READ);
                visibleChanges.put(cd.getId(), cd.change().getDest());
            } catch (AuthException e) {
            // Do nothing.
            }
        }
        return visibleChanges;
    } catch (OrmException e) {
        logger.atSevere().withCause(e).log("Cannot load changes for project %s, assuming no changes are visible", project);
        return Collections.emptyMap();
    }
}
#end_block

#method_before
private Map<Change.Id, Branch.NameKey> visibleChangesByScan(Repository repo) throws PermissionBackendException {
    Project.NameKey p = projectState.getNameKey();
    Stream<ChangeNotesResult> s;
    try {
        s = changeNotesFactory.scan(repo, db.get(), p);
    } catch (IOException e) {
        log.error("Cannot load changes for project " + p + ", assuming no changes are visible", e);
        return Collections.emptyMap();
    }
    Map<Change.Id, Branch.NameKey> result = Maps.newHashMapWithExpectedSize((int) s.count());
    for (ChangeNotesResult notesResult : s.collect(toList())) {
        ChangeNotes notes = toNotes(notesResult);
        if (notes != null) {
            result.put(notes.getChangeId(), notes.getChange().getDest());
        }
    }
    return result;
}
#method_after
private Map<Change.Id, Branch.NameKey> visibleChangesByScan(Repository repo) throws PermissionBackendException {
    Project.NameKey p = projectState.getNameKey();
    Stream<ChangeNotesResult> s;
    try {
        s = changeNotesFactory.scan(repo, db.get(), p);
    } catch (IOException e) {
        logger.atSevere().withCause(e).log("Cannot load changes for project %s, assuming no changes are visible", p);
        return Collections.emptyMap();
    }
    Map<Change.Id, Branch.NameKey> result = Maps.newHashMapWithExpectedSize((int) s.count());
    for (ChangeNotesResult notesResult : s.collect(toImmutableList())) {
        ChangeNotes notes = toNotes(notesResult);
        if (notes != null) {
            result.put(notes.getChangeId(), notes.getChange().getDest());
        }
    }
    return result;
}
#end_block

#method_before
@Nullable
private ChangeNotes toNotes(ChangeNotesResult r) throws PermissionBackendException {
    if (r.error().isPresent()) {
        log.warn("Failed to load change " + r.id() + " in " + projectState.getName(), r.error().get());
        return null;
    }
    if (projectState.statePermitsRead() && permissionBackendForProject.change(r.notes()).test(ChangePermission.READ)) {
        return r.notes();
    }
    return null;
}
#method_after
@Nullable
private ChangeNotes toNotes(ChangeNotesResult r) throws PermissionBackendException {
    if (r.error().isPresent()) {
        logger.atWarning().withCause(r.error().get()).log("Failed to load change %s in %s", r.id(), projectState.getName());
        return null;
    }
    if (!projectState.statePermitsRead()) {
        return null;
    }
    try {
        permissionBackendForProject.change(r.notes()).check(ChangePermission.READ);
        return r.notes();
    } catch (AuthException e) {
    // Skip.
    }
    return null;
}
#end_block

#method_before
private static ListMultimap<String, String> extractParameters(HttpServletRequest request) {
    ListMultimap<String, String> multiMap = ArrayListMultimap.create();
    if (request.getQueryString() != null) {
        @SuppressWarnings("cast")
        Map<String, String[]> parameterMap = (Map<String, String[]>) request.getParameterMap();
        parameterMap.forEach((k, v) -> {
            for (String aV : v) {
                multiMap.put(k, aV);
            }
        });
    }
    return multiMap;
}
#method_after
private static ListMultimap<String, String> extractParameters(HttpServletRequest request) {
    ListMultimap<String, String> multiMap = ArrayListMultimap.create();
    if (request.getQueryString() != null) {
        request.getParameterMap().forEach((k, v) -> {
            for (String aV : v) {
                multiMap.put(k, aV);
            }
        });
    }
    return multiMap;
}
#end_block

#method_before
static void toGerrit(String target, HttpServletRequest req, HttpServletResponse rsp) throws IOException {
    toGerrit(target, req, rsp, false);
}
#method_after
static void toGerrit(String target, HttpServletRequest req, HttpServletResponse rsp) throws IOException {
    final StringBuilder url = new StringBuilder();
    url.append(req.getContextPath());
    url.append(target);
    rsp.sendRedirect(url.toString());
}
#end_block

#method_before
@Override
public Operation exec(Prolog engine) throws PrologException {
    engine.setB0();
    Term a1 = arg1.dereference();
    Term a2 = arg2.dereference();
    Pattern fileRegex = getRegexParameter(a1);
    Pattern editRegex = getRegexParameter(a2);
    PatchList pl = StoredValues.PATCH_LIST.get(engine);
    Repository repo = StoredValues.REPOSITORY.get(engine);
    try (ObjectReader reader = repo.newObjectReader();
        RevWalk rw = new RevWalk(reader)) {
        final RevTree aTree;
        final RevTree bTree;
        final RevCommit bCommit = rw.parseCommit(pl.getNewId());
        if (pl.getOldId() != null) {
            aTree = rw.parseTree(pl.getOldId());
        } else {
            // web UI returns no files to match against, just fail.
            return engine.fail();
        }
        bTree = bCommit.getTree();
        for (PatchListEntry entry : pl.getPatches()) {
            String newName = entry.getNewName();
            String oldName = entry.getOldName();
            if (Patch.isMagic(newName)) {
                continue;
            }
            if (fileRegex.matcher(newName).find() || (oldName != null && fileRegex.matcher(oldName).find())) {
                // This cast still seems to be needed on JDK 8 as workaround for:
                // https://bugs.openjdk.java.net/browse/JDK-8039214
                @SuppressWarnings("cast")
                List<Edit> edits = entry.getEdits();
                if (edits.isEmpty()) {
                    continue;
                }
                Text tA;
                if (oldName != null) {
                    tA = load(aTree, oldName, reader);
                } else {
                    tA = load(aTree, newName, reader);
                }
                Text tB = load(bTree, newName, reader);
                for (Edit edit : edits) {
                    if (tA != Text.EMPTY) {
                        String aDiff = tA.getString(edit.getBeginA(), edit.getEndA(), true);
                        if (editRegex.matcher(aDiff).find()) {
                            return cont;
                        }
                    }
                    if (tB != Text.EMPTY) {
                        String bDiff = tB.getString(edit.getBeginB(), edit.getEndB(), true);
                        if (editRegex.matcher(bDiff).find()) {
                            return cont;
                        }
                    }
                }
            }
        }
    } catch (IOException err) {
        throw new JavaException(this, 1, err);
    }
    return engine.fail();
}
#method_after
@Override
public Operation exec(Prolog engine) throws PrologException {
    engine.setB0();
    Term a1 = arg1.dereference();
    Term a2 = arg2.dereference();
    Pattern fileRegex = getRegexParameter(a1);
    Pattern editRegex = getRegexParameter(a2);
    PatchList pl = StoredValues.PATCH_LIST.get(engine);
    Repository repo = StoredValues.REPOSITORY.get(engine);
    try (ObjectReader reader = repo.newObjectReader();
        RevWalk rw = new RevWalk(reader)) {
        final RevTree aTree;
        final RevTree bTree;
        final RevCommit bCommit = rw.parseCommit(pl.getNewId());
        if (pl.getOldId() != null) {
            aTree = rw.parseTree(pl.getOldId());
        } else {
            // web UI returns no files to match against, just fail.
            return engine.fail();
        }
        bTree = bCommit.getTree();
        for (PatchListEntry entry : pl.getPatches()) {
            String newName = entry.getNewName();
            String oldName = entry.getOldName();
            if (Patch.isMagic(newName)) {
                continue;
            }
            if (fileRegex.matcher(newName).find() || (oldName != null && fileRegex.matcher(oldName).find())) {
                List<Edit> edits = entry.getEdits();
                if (edits.isEmpty()) {
                    continue;
                }
                Text tA;
                if (oldName != null) {
                    tA = load(aTree, oldName, reader);
                } else {
                    tA = load(aTree, newName, reader);
                }
                Text tB = load(bTree, newName, reader);
                for (Edit edit : edits) {
                    if (tA != Text.EMPTY) {
                        String aDiff = tA.getString(edit.getBeginA(), edit.getEndA(), true);
                        if (editRegex.matcher(aDiff).find()) {
                            return cont;
                        }
                    }
                    if (tB != Text.EMPTY) {
                        String bDiff = tB.getString(edit.getBeginB(), edit.getEndB(), true);
                        if (editRegex.matcher(bDiff).find()) {
                            return cont;
                        }
                    }
                }
            }
        }
    } catch (IOException err) {
        throw new JavaException(this, 1, err);
    }
    return engine.fail();
}
#end_block

#method_before
private Key<HttpServlet> gerritUrl() {
    return key(new HttpServlet() {

        private static final long serialVersionUID = 1L;

        @Override
        protected void doGet(HttpServletRequest req, HttpServletResponse rsp) throws IOException {
            toGerrit(true, req.getRequestURI().substring(req.getContextPath().length()), req, rsp);
        }
    });
}
#method_after
private Key<HttpServlet> gerritUrl() {
    return key(new HttpServlet() {

        private static final long serialVersionUID = 1L;

        @Override
        protected void doGet(HttpServletRequest req, HttpServletResponse rsp) throws IOException {
            String path = req.getRequestURI().substring(req.getContextPath().length());
            toGerrit(path, req, rsp, true);
        }
    });
}
#end_block

#method_before
private Key<HttpServlet> screen(String target) {
    return key(new HttpServlet() {

        private static final long serialVersionUID = 1L;

        @Override
        protected void doGet(HttpServletRequest req, HttpServletResponse rsp) throws IOException {
            toGerrit(false, target, req, rsp);
        }
    });
}
#method_after
private Key<HttpServlet> screen(String target) {
    return key(new HttpServlet() {

        private static final long serialVersionUID = 1L;

        @Override
        protected void doGet(HttpServletRequest req, HttpServletResponse rsp) throws IOException {
            toGerrit(target, req, rsp);
        }
    });
}
#end_block

#method_before
private Key<HttpServlet> legacyGerritScreen() {
    return key(new HttpServlet() {

        private static final long serialVersionUID = 1L;

        @Override
        protected void doGet(HttpServletRequest req, HttpServletResponse rsp) throws IOException {
            final String token = req.getPathInfo().substring(1);
            toGerrit(false, token, req, rsp);
        }
    });
}
#method_after
private Key<HttpServlet> legacyGerritScreen() {
    return key(new HttpServlet() {

        private static final long serialVersionUID = 1L;

        @Override
        protected void doGet(HttpServletRequest req, HttpServletResponse rsp) throws IOException {
            final String token = req.getPathInfo().substring(1);
            toGerrit(token, req, rsp);
        }
    });
}
#end_block

#method_before
private Key<HttpServlet> directChangeById() {
    return key(new HttpServlet() {

        private static final long serialVersionUID = 1L;

        @Override
        protected void doGet(HttpServletRequest req, HttpServletResponse rsp) throws IOException {
            try {
                String idString = req.getPathInfo();
                if (idString.endsWith("/")) {
                    idString = idString.substring(0, idString.length() - 1);
                }
                Change.Id id = Change.Id.parse(idString);
                // User accessed Gerrit with /1234, so we have no project yet.
                // TODO(hiesel) Replace with a preflight request to obtain project before we deprecate
                // the numeric change id.
                toGerrit(false, PageLinks.toChange(null, id), req, rsp);
            } catch (IllegalArgumentException err) {
                rsp.sendError(HttpServletResponse.SC_NOT_FOUND);
            }
        }
    });
}
#method_after
private Key<HttpServlet> directChangeById() {
    return key(new HttpServlet() {

        private static final long serialVersionUID = 1L;

        @Override
        protected void doGet(HttpServletRequest req, HttpServletResponse rsp) throws IOException {
            try {
                String idString = req.getPathInfo();
                if (idString.endsWith("/")) {
                    idString = idString.substring(0, idString.length() - 1);
                }
                Change.Id id = Change.Id.parse(idString);
                // User accessed Gerrit with /1234, so we have no project yet.
                // TODO(hiesel) Replace with a preflight request to obtain project before we deprecate
                // the numeric change id.
                toGerrit(PageLinks.toChange(null, id), req, rsp);
            } catch (IllegalArgumentException err) {
                rsp.sendError(HttpServletResponse.SC_NOT_FOUND);
            }
        }
    });
}
#end_block

#method_before
private Key<HttpServlet> queryProjectNew() {
    return key(new HttpServlet() {

        private static final long serialVersionUID = 1L;

        @Override
        protected void doGet(HttpServletRequest req, HttpServletResponse rsp) throws IOException {
            String name = req.getPathInfo();
            if (Strings.isNullOrEmpty(name)) {
                toGerrit(false, PageLinks.ADMIN_PROJECTS, req, rsp);
                return;
            }
            while (name.endsWith("/")) {
                name = name.substring(0, name.length() - 1);
            }
            if (name.endsWith(Constants.DOT_GIT_EXT)) {
                name = name.substring(// 
                0, name.length() - Constants.DOT_GIT_EXT.length());
            }
            while (name.endsWith("/")) {
                name = name.substring(0, name.length() - 1);
            }
            Project.NameKey project = new Project.NameKey(name);
            toGerrit(false, PageLinks.toChangeQuery(PageLinks.projectQuery(project, Change.Status.NEW)), req, rsp);
        }
    });
}
#method_after
private Key<HttpServlet> queryProjectNew() {
    return key(new HttpServlet() {

        private static final long serialVersionUID = 1L;

        @Override
        protected void doGet(HttpServletRequest req, HttpServletResponse rsp) throws IOException {
            String name = req.getPathInfo();
            if (Strings.isNullOrEmpty(name)) {
                toGerrit(PageLinks.ADMIN_PROJECTS, req, rsp);
                return;
            }
            while (name.endsWith("/")) {
                name = name.substring(0, name.length() - 1);
            }
            if (name.endsWith(Constants.DOT_GIT_EXT)) {
                name = name.substring(// 
                0, name.length() - Constants.DOT_GIT_EXT.length());
            }
            while (name.endsWith("/")) {
                name = name.substring(0, name.length() - 1);
            }
            Project.NameKey project = new Project.NameKey(name);
            toGerrit(PageLinks.toChangeQuery(PageLinks.projectQuery(project, Change.Status.NEW)), req, rsp);
        }
    });
}
#end_block

#method_before
private Key<HttpServlet> query(String query) {
    return key(new HttpServlet() {

        private static final long serialVersionUID = 1L;

        @Override
        protected void doGet(HttpServletRequest req, HttpServletResponse rsp) throws IOException {
            toGerrit(false, PageLinks.toChangeQuery(query), req, rsp);
        }
    });
}
#method_after
private Key<HttpServlet> query(String query) {
    return key(new HttpServlet() {

        private static final long serialVersionUID = 1L;

        @Override
        protected void doGet(HttpServletRequest req, HttpServletResponse rsp) throws IOException {
            toGerrit(PageLinks.toChangeQuery(query), req, rsp);
        }
    });
}
#end_block

#method_before
private Key<HttpServlet> registerScreen(final Boolean slash) {
    return key(new HttpServlet() {

        private static final long serialVersionUID = 1L;

        @Override
        protected void doGet(HttpServletRequest req, HttpServletResponse rsp) throws IOException {
            String path = String.format("/register%s", slash ? req.getPathInfo() : "");
            toGerrit(false, path, req, rsp);
        }
    });
}
#method_after
private Key<HttpServlet> registerScreen(final Boolean slash) {
    return key(new HttpServlet() {

        private static final long serialVersionUID = 1L;

        @Override
        protected void doGet(HttpServletRequest req, HttpServletResponse rsp) throws IOException {
            String path = String.format("/register%s", slash ? req.getPathInfo() : "");
            toGerrit(path, req, rsp);
        }
    });
}
#end_block

#method_before
private Key<HttpServlet> redirectDocumentation() {
    return key(new HttpServlet() {

        private static final long serialVersionUID = 1L;

        @Override
        protected void doGet(HttpServletRequest req, HttpServletResponse rsp) throws IOException {
            String path = "/Documentation/index.html";
            toGerrit(false, path, req, rsp);
        }
    });
}
#method_after
private Key<HttpServlet> redirectDocumentation() {
    return key(new HttpServlet() {

        private static final long serialVersionUID = 1L;

        @Override
        protected void doGet(HttpServletRequest req, HttpServletResponse rsp) throws IOException {
            String path = "/Documentation/index.html";
            toGerrit(path, req, rsp);
        }
    });
}
#end_block

#method_before
static void toGerrit(boolean gwt, String target, HttpServletRequest req, HttpServletResponse rsp) throws IOException {
    final StringBuilder url = new StringBuilder();
    url.append(req.getContextPath());
    if (gwt) {
        url.append('/');
        url.append('#');
    }
    url.append(target);
    rsp.sendRedirect(url.toString());
}
#method_after
static void toGerrit(String target, HttpServletRequest req, HttpServletResponse rsp) throws IOException {
    toGerrit(target, req, rsp, false);
}
#end_block

#method_before
public Connection getConnection() throws SQLException {
    return connectionSupplier.get();
}
#method_after
public Connection getConnection() throws SQLException {
    return ds.getConnection();
}
#end_block

#method_before
public void createTableIfNotExists() throws OrmException {
    try (Connection con = getConnection();
        Statement stmt = con.createStatement()) {
        doCreateTable(stmt);
    } catch (SQLException e) {
        throw convertError("create", e);
    }
}
#method_after
public void createTableIfNotExists() throws OrmException {
    try (Connection con = ds.getConnection();
        Statement stmt = con.createStatement()) {
        doCreateTable(stmt);
    } catch (SQLException e) {
        throw convertError("create", e);
    }
}
#end_block

#method_before
public void dropTableIfExists() throws OrmException {
    try (Connection con = getConnection();
        Statement stmt = con.createStatement()) {
        stmt.executeUpdate("DROP TABLE IF EXISTS account_patch_reviews");
    } catch (SQLException e) {
        throw convertError("create", e);
    }
}
#method_after
public void dropTableIfExists() throws OrmException {
    try (Connection con = ds.getConnection();
        Statement stmt = con.createStatement()) {
        stmt.executeUpdate("DROP TABLE IF EXISTS account_patch_reviews");
    } catch (SQLException e) {
        throw convertError("create", e);
    }
}
#end_block

#method_before
@Override
public boolean markReviewed(PatchSet.Id psId, Account.Id accountId, String path) throws OrmException {
    try (Connection con = getConnection();
        PreparedStatement stmt = con.prepareStatement("INSERT INTO account_patch_reviews " + "(account_id, change_id, patch_set_id, file_name) VALUES " + "(?, ?, ?, ?)")) {
        stmt.setInt(1, accountId.get());
        stmt.setInt(2, psId.getParentKey().get());
        stmt.setInt(3, psId.get());
        stmt.setString(4, path);
        stmt.executeUpdate();
        return true;
    } catch (SQLException e) {
        OrmException ormException = convertError("insert", e);
        if (ormException instanceof OrmDuplicateKeyException) {
            return false;
        }
        throw ormException;
    }
}
#method_after
@Override
public boolean markReviewed(PatchSet.Id psId, Account.Id accountId, String path) throws OrmException {
    try (Connection con = ds.getConnection();
        PreparedStatement stmt = con.prepareStatement("INSERT INTO account_patch_reviews " + "(account_id, change_id, patch_set_id, file_name) VALUES " + "(?, ?, ?, ?)")) {
        stmt.setInt(1, accountId.get());
        stmt.setInt(2, psId.getParentKey().get());
        stmt.setInt(3, psId.get());
        stmt.setString(4, path);
        stmt.executeUpdate();
        return true;
    } catch (SQLException e) {
        OrmException ormException = convertError("insert", e);
        if (ormException instanceof OrmDuplicateKeyException) {
            return false;
        }
        throw ormException;
    }
}
#end_block

#method_before
@Override
public void markReviewed(PatchSet.Id psId, Account.Id accountId, Collection<String> paths) throws OrmException {
    if (paths == null || paths.isEmpty()) {
        return;
    }
    try (Connection con = getConnection();
        PreparedStatement stmt = con.prepareStatement("INSERT INTO account_patch_reviews " + "(account_id, change_id, patch_set_id, file_name) VALUES " + "(?, ?, ?, ?)")) {
        for (String path : paths) {
            stmt.setInt(1, accountId.get());
            stmt.setInt(2, psId.getParentKey().get());
            stmt.setInt(3, psId.get());
            stmt.setString(4, path);
            stmt.addBatch();
        }
        stmt.executeBatch();
    } catch (SQLException e) {
        OrmException ormException = convertError("insert", e);
        if (ormException instanceof OrmDuplicateKeyException) {
            return;
        }
        throw ormException;
    }
}
#method_after
@Override
public void markReviewed(PatchSet.Id psId, Account.Id accountId, Collection<String> paths) throws OrmException {
    if (paths == null || paths.isEmpty()) {
        return;
    }
    try (Connection con = ds.getConnection();
        PreparedStatement stmt = con.prepareStatement("INSERT INTO account_patch_reviews " + "(account_id, change_id, patch_set_id, file_name) VALUES " + "(?, ?, ?, ?)")) {
        for (String path : paths) {
            stmt.setInt(1, accountId.get());
            stmt.setInt(2, psId.getParentKey().get());
            stmt.setInt(3, psId.get());
            stmt.setString(4, path);
            stmt.addBatch();
        }
        stmt.executeBatch();
    } catch (SQLException e) {
        OrmException ormException = convertError("insert", e);
        if (ormException instanceof OrmDuplicateKeyException) {
            return;
        }
        throw ormException;
    }
}
#end_block

#method_before
@Override
public void clearReviewed(PatchSet.Id psId, Account.Id accountId, String path) throws OrmException {
    try (Connection con = getConnection();
        PreparedStatement stmt = con.prepareStatement("DELETE FROM account_patch_reviews " + "WHERE account_id = ? AND change_id = ? AND " + "patch_set_id = ? AND file_name = ?")) {
        stmt.setInt(1, accountId.get());
        stmt.setInt(2, psId.getParentKey().get());
        stmt.setInt(3, psId.get());
        stmt.setString(4, path);
        stmt.executeUpdate();
    } catch (SQLException e) {
        throw convertError("delete", e);
    }
}
#method_after
@Override
public void clearReviewed(PatchSet.Id psId, Account.Id accountId, String path) throws OrmException {
    try (Connection con = ds.getConnection();
        PreparedStatement stmt = con.prepareStatement("DELETE FROM account_patch_reviews " + "WHERE account_id = ? AND change_id = ? AND " + "patch_set_id = ? AND file_name = ?")) {
        stmt.setInt(1, accountId.get());
        stmt.setInt(2, psId.getParentKey().get());
        stmt.setInt(3, psId.get());
        stmt.setString(4, path);
        stmt.executeUpdate();
    } catch (SQLException e) {
        throw convertError("delete", e);
    }
}
#end_block

#method_before
@Override
public void clearReviewed(PatchSet.Id psId) throws OrmException {
    try (Connection con = getConnection();
        PreparedStatement stmt = con.prepareStatement("DELETE FROM account_patch_reviews " + "WHERE change_id = ? AND patch_set_id = ?")) {
        stmt.setInt(1, psId.getParentKey().get());
        stmt.setInt(2, psId.get());
        stmt.executeUpdate();
    } catch (SQLException e) {
        throw convertError("delete", e);
    }
}
#method_after
@Override
public void clearReviewed(PatchSet.Id psId) throws OrmException {
    try (Connection con = ds.getConnection();
        PreparedStatement stmt = con.prepareStatement("DELETE FROM account_patch_reviews " + "WHERE change_id = ? AND patch_set_id = ?")) {
        stmt.setInt(1, psId.getParentKey().get());
        stmt.setInt(2, psId.get());
        stmt.executeUpdate();
    } catch (SQLException e) {
        throw convertError("delete", e);
    }
}
#end_block

#method_before
@Override
public Optional<PatchSetWithReviewedFiles> findReviewed(PatchSet.Id psId, Account.Id accountId) throws OrmException {
    try (Connection con = getConnection();
        PreparedStatement stmt = con.prepareStatement("SELECT patch_set_id, file_name FROM account_patch_reviews APR1 " + "WHERE account_id = ? AND change_id = ? AND patch_set_id = " + "(SELECT MAX(patch_set_id) FROM account_patch_reviews APR2 WHERE " + "APR1.account_id = APR2.account_id " + "AND APR1.change_id = APR2.change_id " + "AND patch_set_id <= ?)")) {
        stmt.setInt(1, accountId.get());
        stmt.setInt(2, psId.getParentKey().get());
        stmt.setInt(3, psId.get());
        try (ResultSet rs = stmt.executeQuery()) {
            if (rs.next()) {
                PatchSet.Id id = new PatchSet.Id(psId.getParentKey(), rs.getInt("patch_set_id"));
                ImmutableSet.Builder<String> builder = ImmutableSet.builder();
                do {
                    builder.add(rs.getString("file_name"));
                } while (rs.next());
                return Optional.of(AccountPatchReviewStore.PatchSetWithReviewedFiles.create(id, builder.build()));
            }
            return Optional.empty();
        }
    } catch (SQLException e) {
        throw convertError("select", e);
    }
}
#method_after
@Override
public Optional<PatchSetWithReviewedFiles> findReviewed(PatchSet.Id psId, Account.Id accountId) throws OrmException {
    try (Connection con = ds.getConnection();
        PreparedStatement stmt = con.prepareStatement("SELECT patch_set_id, file_name FROM account_patch_reviews APR1 " + "WHERE account_id = ? AND change_id = ? AND patch_set_id = " + "(SELECT MAX(patch_set_id) FROM account_patch_reviews APR2 WHERE " + "APR1.account_id = APR2.account_id " + "AND APR1.change_id = APR2.change_id " + "AND patch_set_id <= ?)")) {
        stmt.setInt(1, accountId.get());
        stmt.setInt(2, psId.getParentKey().get());
        stmt.setInt(3, psId.get());
        try (ResultSet rs = stmt.executeQuery()) {
            if (rs.next()) {
                PatchSet.Id id = new PatchSet.Id(psId.getParentKey(), rs.getInt("patch_set_id"));
                ImmutableSet.Builder<String> builder = ImmutableSet.builder();
                do {
                    builder.add(rs.getString("file_name"));
                } while (rs.next());
                return Optional.of(AccountPatchReviewStore.PatchSetWithReviewedFiles.create(id, builder.build()));
            }
            return Optional.empty();
        }
    } catch (SQLException e) {
        throw convertError("select", e);
    }
}
#end_block

#method_before
private void updateCachesOnGroupCreation(InternalGroup createdGroup) throws IOException {
    groupCache.evict(createdGroup.getNameKey());
    indexer.get().index(createdGroup.getGroupUUID());
    createdGroup.getMembers().forEach(groupIncludeCache::evictGroupsWithMember);
    createdGroup.getSubgroups().forEach(groupIncludeCache::evictParentGroupsOf);
}
#method_after
private void updateCachesOnGroupCreation(InternalGroup createdGroup) throws IOException {
    groupCache.evict(createdGroup.getGroupUUID());
    groupCache.evict(createdGroup.getId());
    groupCache.evict(createdGroup.getNameKey());
    indexer.get().index(createdGroup.getGroupUUID());
    createdGroup.getMembers().forEach(groupIncludeCache::evictGroupsWithMember);
    createdGroup.getSubgroups().forEach(groupIncludeCache::evictParentGroupsOf);
}
#end_block

#method_before
@Test
public void createGroup() throws Exception {
    String newGroupName = name("newGroup");
    AccountGroup.NameKey nameKey = new AccountGroup.NameKey(newGroupName);
    assertThat(groupCache.get(nameKey)).isEmpty();
    GroupInfo g = gApi.groups().create(newGroupName).get();
    assertThat(groupCache.get(nameKey)).isPresent();
    assertGroupInfo(group(newGroupName), g);
}
#method_after
@Test
public void createGroup() throws Exception {
    String newGroupName = name("newGroup");
    GroupInfo g = gApi.groups().create(newGroupName).get();
    assertGroupInfo(group(newGroupName), g);
}
#end_block

#method_before
@Before
public void setUp() throws Exception {
    when(config.index()).thenReturn(index);
    when(index.numStripedLocks()).thenReturn(10);
    handler = new ForwardedIndexAccountHandler(indexerMock, config);
    id = new Account.Id(123);
}
#method_after
@Before
public void setUp() throws Exception {
    when(configMock.index()).thenReturn(indexMock);
    when(indexMock.numStripedLocks()).thenReturn(10);
    handler = new ForwardedIndexAccountHandler(indexerMock, configMock);
    id = new Account.Id(123);
}
#end_block

#method_before
@Before
public void setUp() throws Exception {
    when(config.index()).thenReturn(index);
    when(index.numStripedLocks()).thenReturn(10);
    handler = new ForwardedIndexGroupHandler(indexerMock, config);
    uuid = new AccountGroup.UUID("123");
}
#method_after
@Before
public void setUp() throws Exception {
    when(configMock.index()).thenReturn(indexMock);
    when(indexMock.numStripedLocks()).thenReturn(10);
    handler = new ForwardedIndexGroupHandler(indexerMock, configMock);
    uuid = new AccountGroup.UUID("123");
}
#end_block

#method_before
@Before
public void setUp() throws Exception {
    when(schemaFactoryMock.open()).thenReturn(dbMock);
    when(dbMock.changes()).thenReturn(changeAccessMock);
    when(config.index()).thenReturn(index);
    when(index.numStripedLocks()).thenReturn(10);
    id = new Change.Id(123);
    change = new Change(null, id, null, null, TimeUtil.nowTs());
    handler = new ForwardedIndexChangeHandler(indexerMock, schemaFactoryMock, config);
}
#method_after
@Before
public void setUp() throws Exception {
    when(schemaFactoryMock.open()).thenReturn(dbMock);
    when(dbMock.changes()).thenReturn(changeAccessMock);
    when(configMock.index()).thenReturn(indexMock);
    when(indexMock.numStripedLocks()).thenReturn(10);
    id = new Change.Id(123);
    change = new Change(null, id, null, null, TimeUtil.nowTs());
    handler = new ForwardedIndexChangeHandler(indexerMock, schemaFactoryMock, configMock);
}
#end_block

#method_before
@Override
protected void doPost(HttpServletRequest req, HttpServletResponse rsp) throws IOException, ServletException {
    process(req, rsp, Operation.INDEX);
}
#method_after
@Override
protected void doPost(HttpServletRequest req, HttpServletResponse rsp) {
    process(req, rsp, Operation.INDEX);
}
#end_block

#method_before
@Override
protected void doDelete(HttpServletRequest req, HttpServletResponse rsp) throws IOException, ServletException {
    if (!allowDelete) {
        sendError(rsp, SC_METHOD_NOT_ALLOWED, String.format("cannot delete %s from index", type));
    } else {
        process(req, rsp, Operation.DELETE);
    }
}
#method_after
@Override
protected void doDelete(HttpServletRequest req, HttpServletResponse rsp) {
    if (!allowDelete) {
        sendError(rsp, SC_METHOD_NOT_ALLOWED, String.format("cannot delete %s from index", type));
    } else {
        process(req, rsp, Operation.DELETE);
    }
}
#end_block

#method_before
private void process(HttpServletRequest req, HttpServletResponse rsp, Operation operation) {
    rsp.setContentType("text/plain");
    rsp.setCharacterEncoding(UTF_8.name());
    String path = req.getPathInfo();
    T id = parse(path.substring(path.lastIndexOf('/') + 1));
    logger.debug("{} {} {}", operation.name().toLowerCase(Locale.US), type, id);
    try {
        Context.setForwardedEvent(true);
        AtomicInteger idLock = getAndIncrementIdLock(id);
        synchronized (this) {
            index(id, operation);
        }
        if (idLock.decrementAndGet() == 0) {
            removeIdLock(id);
        }
        rsp.setStatus(SC_NO_CONTENT);
    } catch (IOException e) {
        sendError(rsp, SC_CONFLICT, e.getMessage());
        logger.error("Unable to update {} index", type, e);
    } catch (OrmException e) {
        String msg = String.format("Error trying to find %s \n", type);
        sendError(rsp, SC_NOT_FOUND, msg);
        logger.debug(msg, e);
    } finally {
        Context.unsetForwardedEvent();
    }
}
#method_after
private void process(HttpServletRequest req, HttpServletResponse rsp, Operation operation) {
    rsp.setContentType("text/plain");
    rsp.setCharacterEncoding(UTF_8.name());
    String path = req.getPathInfo();
    T id = parse(path.substring(path.lastIndexOf('/') + 1));
    logger.debug("{} {} {}", operation, type, id);
    try {
        Context.setForwardedEvent(true);
        Lock idLock = idLocks.get(id);
        idLock.lock();
        try {
            index(id, operation);
        } finally {
            idLock.unlock();
        }
        rsp.setStatus(SC_NO_CONTENT);
    } catch (IOException e) {
        sendError(rsp, SC_CONFLICT, e.getMessage());
        logger.error("Unable to update {} index", type, e);
    } catch (OrmException e) {
        String msg = String.format("Error trying to find %s \n", type);
        sendError(rsp, SC_NOT_FOUND, msg);
        logger.debug(msg, e);
    } finally {
        Context.unsetForwardedEvent();
    }
}
#end_block

#method_before
private void handleRegularCommands(List<ReceiveCommand> cmds, MultiProgressMonitor progress) throws PermissionBackendException, IOException, NoSuchProjectException {
    for (ReceiveCommand cmd : cmds) {
        parseRegularCommand(cmd);
    }
    try (BatchUpdate bu = batchUpdateFactory.create(db, project.getNameKey(), user.materializedCopy(), TimeUtil.nowTs());
        ObjectInserter ins = repo.newObjectInserter();
        ObjectReader reader = ins.newReader();
        RevWalk rw = new RevWalk(reader)) {
        bu.setRepository(repo, rw, ins);
        bu.setRefLogMessage("push");
        int added = 0;
        for (ReceiveCommand cmd : cmds) {
            if (cmd.getResult() == NOT_ATTEMPTED) {
                bu.addRepoOnlyOp(new UpdateOneRefOp(cmd));
                added++;
            }
        }
        logger.atFine().log("Added %d additional ref updates", added);
        bu.execute();
    } catch (UpdateException | RestApiException e) {
        rejectRemaining(cmds, "internal server error");
        logger.atFine().withCause(e).log("update failed:");
    }
    Set<Branch.NameKey> branches = new HashSet<>();
    for (ReceiveCommand c : cmds) {
        // they involve kicking off an additional BatchUpdate.
        if (c.getResult() != OK) {
            continue;
        }
        if (isHead(c) || isConfig(c)) {
            switch(c.getType()) {
                case CREATE:
                case UPDATE:
                case UPDATE_NONFASTFORWARD:
                    Task closeProgress = progress.beginSubTask("closed", UNKNOWN);
                    autoCloseChanges(c, closeProgress);
                    closeProgress.end();
                    branches.add(new Branch.NameKey(project.getNameKey(), c.getRefName()));
                    break;
                case DELETE:
                    break;
            }
        }
    }
    // Update superproject gitlinks if required.
    if (!branches.isEmpty()) {
        try (MergeOpRepoManager orm = ormProvider.get()) {
            orm.setContext(db, TimeUtil.nowTs(), user);
            SubmoduleOp op = subOpFactory.create(branches, orm);
            op.updateSuperProjects();
        } catch (SubmoduleException e) {
            logger.atSevere().withCause(e).log("Can't update the superprojects");
        }
    }
}
#method_after
private void handleRegularCommands(List<ReceiveCommand> cmds, MultiProgressMonitor progress) throws PermissionBackendException, IOException, NoSuchProjectException {
    resultChangeIds.setMagicPush(false);
    for (ReceiveCommand cmd : cmds) {
        parseRegularCommand(cmd);
    }
    try (BatchUpdate bu = batchUpdateFactory.create(db, project.getNameKey(), user.materializedCopy(), TimeUtil.nowTs());
        ObjectInserter ins = repo.newObjectInserter();
        ObjectReader reader = ins.newReader();
        RevWalk rw = new RevWalk(reader)) {
        bu.setRepository(repo, rw, ins);
        bu.setRefLogMessage("push");
        int added = 0;
        for (ReceiveCommand cmd : cmds) {
            if (cmd.getResult() == NOT_ATTEMPTED) {
                bu.addRepoOnlyOp(new UpdateOneRefOp(cmd));
                added++;
            }
        }
        logger.atFine().log("Added %d additional ref updates", added);
        bu.execute();
    } catch (UpdateException | RestApiException e) {
        rejectRemaining(cmds, "internal server error");
        logger.atFine().withCause(e).log("update failed:");
    }
    Set<Branch.NameKey> branches = new HashSet<>();
    for (ReceiveCommand c : cmds) {
        // they involve kicking off an additional BatchUpdate.
        if (c.getResult() != OK) {
            continue;
        }
        if (isHead(c) || isConfig(c)) {
            switch(c.getType()) {
                case CREATE:
                case UPDATE:
                case UPDATE_NONFASTFORWARD:
                    Task closeProgress = progress.beginSubTask("closed", UNKNOWN);
                    autoCloseChanges(c, closeProgress);
                    closeProgress.end();
                    branches.add(new Branch.NameKey(project.getNameKey(), c.getRefName()));
                    break;
                case DELETE:
                    break;
            }
        }
    }
    // Update superproject gitlinks if required.
    if (!branches.isEmpty()) {
        try (MergeOpRepoManager orm = ormProvider.get()) {
            orm.setContext(db, TimeUtil.nowTs(), user);
            SubmoduleOp op = subOpFactory.create(branches, orm);
            op.updateSuperProjects();
        } catch (SubmoduleException e) {
            logger.atSevere().withCause(e).log("Can't update the superprojects");
        }
    }
}
#end_block

#method_before
private void parseMagicBranch(ReceiveCommand cmd) throws PermissionBackendException {
    logger.atFine().log("Found magic branch %s", cmd.getRefName());
    MagicBranchInput magicBranch = new MagicBranchInput(user, cmd, labelTypes, notesMigration);
    String ref;
    magicBranch.cmdLineParser = optionParserFactory.create(magicBranch);
    try {
        ref = magicBranch.parse(repo, receivePack.getAdvertisedRefs().keySet(), pushOptions);
    } catch (CmdLineException e) {
        if (!magicBranch.cmdLineParser.wasHelpRequestedByOption()) {
            logger.atFine().log("Invalid branch syntax");
            reject(cmd, e.getMessage());
            return;
        }
        // never happens
        ref = null;
    }
    if (magicBranch.topic != null && magicBranch.topic.length() > ChangeUtil.TOPIC_MAX_LENGTH) {
        reject(cmd, String.format("topic length exceeds the limit (%d)", ChangeUtil.TOPIC_MAX_LENGTH));
    }
    if (magicBranch.cmdLineParser.wasHelpRequestedByOption()) {
        StringWriter w = new StringWriter();
        w.write("\nHelp for refs/for/branch:\n\n");
        magicBranch.cmdLineParser.printUsage(w, null);
        addMessage(w.toString());
        reject(cmd, "see help");
        return;
    }
    if (projectState.isAllUsers() && RefNames.REFS_USERS_SELF.equals(ref)) {
        logger.atFine().log("Handling %s", RefNames.REFS_USERS_SELF);
        ref = RefNames.refsUsers(user.getAccountId());
    }
    // configuration.
    if (!receivePack.getAdvertisedRefs().containsKey(ref) && !ref.equals(readHEAD(repo)) && !ref.equals(RefNames.REFS_CONFIG)) {
        logger.atFine().log("Ref %s not found", ref);
        if (ref.startsWith(Constants.R_HEADS)) {
            String n = ref.substring(Constants.R_HEADS.length());
            reject(cmd, "branch " + n + " not found");
        } else {
            reject(cmd, ref + " not found");
        }
        return;
    }
    magicBranch.dest = new Branch.NameKey(project.getNameKey(), ref);
    magicBranch.perm = permissions.ref(ref);
    Optional<AuthException> err = checkRefPermission(magicBranch.perm, RefPermission.CREATE_CHANGE);
    if (err.isPresent()) {
        rejectProhibited(cmd, err.get());
        return;
    }
    // after repo-tool supports private and work-in-progress changes.
    if (magicBranch.draft && !receiveConfig.allowDrafts) {
        errors.put(CODE_REVIEW_ERROR, ref);
        reject(cmd, "draft workflow is disabled");
        return;
    }
    if (magicBranch.isPrivate && magicBranch.removePrivate) {
        reject(cmd, "the options 'private' and 'remove-private' are mutually exclusive");
        return;
    }
    boolean privateByDefault = projectCache.get(project.getNameKey()).is(BooleanProjectConfig.PRIVATE_BY_DEFAULT);
    setChangeAsPrivate = magicBranch.draft || magicBranch.isPrivate || (privateByDefault && !magicBranch.removePrivate);
    if (receiveConfig.disablePrivateChanges && setChangeAsPrivate) {
        reject(cmd, "private changes are disabled");
        return;
    }
    if (magicBranch.workInProgress && magicBranch.ready) {
        reject(cmd, "the options 'wip' and 'ready' are mutually exclusive");
        return;
    }
    if (magicBranch.publishComments && magicBranch.noPublishComments) {
        reject(cmd, "the options 'publish-comments' and 'no-publish-comments' are mutually exclusive");
        return;
    }
    if (magicBranch.submit) {
        err = checkRefPermission(magicBranch.perm, RefPermission.UPDATE_BY_SUBMIT);
        if (err.isPresent()) {
            rejectProhibited(cmd, err.get());
            return;
        }
    }
    RevWalk walk = receivePack.getRevWalk();
    RevCommit tip;
    try {
        tip = walk.parseCommit(magicBranch.cmd.getNewId());
        logger.atFine().log("Tip of push: %s", tip.name());
    } catch (IOException ex) {
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logger.atSevere().withCause(ex).log("Invalid pack upload; one or more objects weren't sent");
        return;
    }
    String destBranch = magicBranch.dest.get();
    try {
        if (magicBranch.merged) {
            if (magicBranch.base != null) {
                reject(cmd, "cannot use merged with base");
                return;
            }
            RevCommit branchTip = readBranchTip(magicBranch.dest);
            if (branchTip == null) {
                reject(cmd, magicBranch.dest.get() + " not found");
                return;
            }
            if (!walk.isMergedInto(tip, branchTip)) {
                reject(cmd, "not merged into branch");
                return;
            }
        }
        // if %base or %merged was specified, ignore newChangeForAllNotInTarget.
        if (tip.getParentCount() > 1 || magicBranch.base != null || magicBranch.merged || tip.getParentCount() == 0) {
            logger.atFine().log("Forcing newChangeForAllNotInTarget = false");
            newChangeForAllNotInTarget = false;
        }
        if (magicBranch.base != null) {
            logger.atFine().log("Handling %%base: %s", magicBranch.base);
            magicBranch.baseCommit = Lists.newArrayListWithCapacity(magicBranch.base.size());
            for (ObjectId id : magicBranch.base) {
                try {
                    magicBranch.baseCommit.add(walk.parseCommit(id));
                } catch (IncorrectObjectTypeException notCommit) {
                    reject(cmd, "base must be a commit");
                    return;
                } catch (MissingObjectException e) {
                    reject(cmd, "base not found");
                    return;
                } catch (IOException e) {
                    logger.atWarning().withCause(e).log("Project %s cannot read %s", project.getName(), id.name());
                    reject(cmd, "internal server error");
                    return;
                }
            }
        } else if (newChangeForAllNotInTarget) {
            RevCommit branchTip = readBranchTip(magicBranch.dest);
            if (branchTip != null) {
                magicBranch.baseCommit = Collections.singletonList(branchTip);
                logger.atFine().log("Set baseCommit = %s", magicBranch.baseCommit.get(0).name());
            } else {
                // repository and to review an initial project configuration.
                if (!ref.equals(readHEAD(repo)) && !ref.equals(RefNames.REFS_CONFIG)) {
                    reject(cmd, magicBranch.dest.get() + " not found");
                    return;
                }
            }
        }
    } catch (IOException ex) {
        logger.atWarning().withCause(ex).log("Error walking to %s in project %s", destBranch, project.getName());
        reject(cmd, "internal server error");
        return;
    }
    if (magicBranch.deprecatedTopicSeen) {
        messages.add(new ValidationMessage("WARNING: deprecated topic syntax. Use %topic=TOPIC instead", false));
        logger.atInfo().log("deprecated topic push seen for project %s", project.getName());
    }
    if (validateConnected(magicBranch.cmd, magicBranch.dest, tip)) {
        this.magicBranch = magicBranch;
    }
}
#method_after
private void parseMagicBranch(ReceiveCommand cmd) throws PermissionBackendException {
    logger.atFine().log("Found magic branch %s", cmd.getRefName());
    MagicBranchInput magicBranch = new MagicBranchInput(user, cmd, labelTypes, notesMigration);
    String ref;
    magicBranch.cmdLineParser = optionParserFactory.create(magicBranch);
    try {
        ref = magicBranch.parse(repo, receivePack.getAdvertisedRefs().keySet(), pushOptions);
    } catch (CmdLineException e) {
        if (!magicBranch.cmdLineParser.wasHelpRequestedByOption()) {
            logger.atFine().log("Invalid branch syntax");
            reject(cmd, e.getMessage());
            return;
        }
        // never happens
        ref = null;
    }
    if (magicBranch.topic != null && magicBranch.topic.length() > ChangeUtil.TOPIC_MAX_LENGTH) {
        reject(cmd, String.format("topic length exceeds the limit (%d)", ChangeUtil.TOPIC_MAX_LENGTH));
    }
    if (magicBranch.cmdLineParser.wasHelpRequestedByOption()) {
        StringWriter w = new StringWriter();
        w.write("\nHelp for refs/for/branch:\n\n");
        magicBranch.cmdLineParser.printUsage(w, null);
        addMessage(w.toString());
        reject(cmd, "see help");
        return;
    }
    if (projectState.isAllUsers() && RefNames.REFS_USERS_SELF.equals(ref)) {
        logger.atFine().log("Handling %s", RefNames.REFS_USERS_SELF);
        ref = RefNames.refsUsers(user.getAccountId());
    }
    // configuration.
    if (!receivePack.getAdvertisedRefs().containsKey(ref) && !ref.equals(readHEAD(repo)) && !ref.equals(RefNames.REFS_CONFIG)) {
        logger.atFine().log("Ref %s not found", ref);
        if (ref.startsWith(Constants.R_HEADS)) {
            String n = ref.substring(Constants.R_HEADS.length());
            reject(cmd, "branch " + n + " not found");
        } else {
            reject(cmd, ref + " not found");
        }
        return;
    }
    magicBranch.dest = new Branch.NameKey(project.getNameKey(), ref);
    magicBranch.perm = permissions.ref(ref);
    Optional<AuthException> err = checkRefPermission(magicBranch.perm, RefPermission.CREATE_CHANGE);
    if (err.isPresent()) {
        rejectProhibited(cmd, err.get());
        return;
    }
    // after repo-tool supports private and work-in-progress changes.
    if (magicBranch.draft && !receiveConfig.allowDrafts) {
        errors.put(CODE_REVIEW_ERROR, ref);
        reject(cmd, "draft workflow is disabled");
        return;
    }
    if (magicBranch.isPrivate && magicBranch.removePrivate) {
        reject(cmd, "the options 'private' and 'remove-private' are mutually exclusive");
        return;
    }
    boolean privateByDefault = projectCache.get(project.getNameKey()).is(BooleanProjectConfig.PRIVATE_BY_DEFAULT);
    setChangeAsPrivate = magicBranch.draft || magicBranch.isPrivate || (privateByDefault && !magicBranch.removePrivate);
    if (receiveConfig.disablePrivateChanges && setChangeAsPrivate) {
        reject(cmd, "private changes are disabled");
        return;
    }
    if (magicBranch.workInProgress && magicBranch.ready) {
        reject(cmd, "the options 'wip' and 'ready' are mutually exclusive");
        return;
    }
    if (magicBranch.publishComments && magicBranch.noPublishComments) {
        reject(cmd, "the options 'publish-comments' and 'no-publish-comments' are mutually exclusive");
        return;
    }
    if (magicBranch.submit) {
        err = checkRefPermission(magicBranch.perm, RefPermission.UPDATE_BY_SUBMIT);
        if (err.isPresent()) {
            rejectProhibited(cmd, err.get());
            return;
        }
    }
    RevWalk walk = receivePack.getRevWalk();
    RevCommit tip;
    try {
        tip = walk.parseCommit(magicBranch.cmd.getNewId());
        logger.atFine().log("Tip of push: %s", tip.name());
    } catch (IOException ex) {
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logger.atSevere().withCause(ex).log("Invalid pack upload; one or more objects weren't sent");
        return;
    }
    String destBranch = magicBranch.dest.get();
    try {
        if (magicBranch.merged) {
            if (magicBranch.base != null) {
                reject(cmd, "cannot use merged with base");
                return;
            }
            RevCommit branchTip = readBranchTip(magicBranch.dest);
            if (branchTip == null) {
                reject(cmd, magicBranch.dest.get() + " not found");
                return;
            }
            if (!walk.isMergedInto(tip, branchTip)) {
                reject(cmd, "not merged into branch");
                return;
            }
        }
        // if %base or %merged was specified, ignore newChangeForAllNotInTarget.
        if (tip.getParentCount() > 1 || magicBranch.base != null || magicBranch.merged || tip.getParentCount() == 0) {
            logger.atFine().log("Forcing newChangeForAllNotInTarget = false");
            newChangeForAllNotInTarget = false;
        }
        if (magicBranch.base != null) {
            logger.atFine().log("Handling %%base: %s", magicBranch.base);
            magicBranch.baseCommit = Lists.newArrayListWithCapacity(magicBranch.base.size());
            for (ObjectId id : magicBranch.base) {
                try {
                    magicBranch.baseCommit.add(walk.parseCommit(id));
                } catch (IncorrectObjectTypeException notCommit) {
                    reject(cmd, "base must be a commit");
                    return;
                } catch (MissingObjectException e) {
                    reject(cmd, "base not found");
                    return;
                } catch (IOException e) {
                    logger.atWarning().withCause(e).log("Project %s cannot read %s", project.getName(), id.name());
                    reject(cmd, "internal server error");
                    return;
                }
            }
        } else if (newChangeForAllNotInTarget) {
            RevCommit branchTip = readBranchTip(magicBranch.dest);
            if (branchTip != null) {
                magicBranch.baseCommit = Collections.singletonList(branchTip);
                logger.atFine().log("Set baseCommit = %s", magicBranch.baseCommit.get(0).name());
            } else {
                // repository and to review an initial project configuration.
                if (!ref.equals(readHEAD(repo)) && !ref.equals(RefNames.REFS_CONFIG)) {
                    reject(cmd, magicBranch.dest.get() + " not found");
                    return;
                }
            }
        }
    } catch (IOException ex) {
        logger.atWarning().withCause(ex).log("Error walking to %s in project %s", destBranch, project.getName());
        reject(cmd, "internal server error");
        return;
    }
    if (magicBranch.deprecatedTopicSeen) {
        messages.add(new ValidationMessage("WARNING: deprecated topic syntax. Use %topic=TOPIC instead", false));
        logger.atInfo().log("deprecated topic push seen for project %s", project.getName());
    }
    if (validateConnected(magicBranch.cmd, magicBranch.dest, tip)) {
        this.magicBranch = magicBranch;
        this.resultChangeIds.setMagicPush(true);
    }
}
#end_block

#method_before
public static void ensureChangeLoaded(Iterable<ChangeData> changes) throws OrmException {
    ChangeData first = Iterables.getFirst(changes, null);
    if (first == null) {
        return;
    }
    for (ChangeData cd : changes) {
        cd.change();
    }
    return;
}
#method_after
public static void ensureChangeLoaded(Iterable<ChangeData> changes) throws OrmException {
    ChangeData first = Iterables.getFirst(changes, null);
    if (first == null) {
        return;
    }
    for (ChangeData cd : changes) {
        cd.change();
    }
}
#end_block

#method_before
public static void ensureAllPatchSetsLoaded(Iterable<ChangeData> changes) throws OrmException {
    ChangeData first = Iterables.getFirst(changes, null);
    if (first == null) {
        return;
    }
    for (ChangeData cd : changes) {
        cd.patchSets();
    }
    return;
}
#method_after
public static void ensureAllPatchSetsLoaded(Iterable<ChangeData> changes) throws OrmException {
    ChangeData first = Iterables.getFirst(changes, null);
    if (first == null) {
        return;
    }
    for (ChangeData cd : changes) {
        cd.patchSets();
    }
}
#end_block

#method_before
public static void ensureCurrentPatchSetLoaded(Iterable<ChangeData> changes) throws OrmException {
    ChangeData first = Iterables.getFirst(changes, null);
    if (first == null) {
        return;
    }
    for (ChangeData cd : changes) {
        cd.currentPatchSet();
    }
    return;
}
#method_after
public static void ensureCurrentPatchSetLoaded(Iterable<ChangeData> changes) throws OrmException {
    ChangeData first = Iterables.getFirst(changes, null);
    if (first == null) {
        return;
    }
    for (ChangeData cd : changes) {
        cd.currentPatchSet();
    }
}
#end_block

#method_before
public static void ensureCurrentApprovalsLoaded(Iterable<ChangeData> changes) throws OrmException {
    ChangeData first = Iterables.getFirst(changes, null);
    if (first == null) {
        return;
    }
    for (ChangeData cd : changes) {
        cd.currentApprovals();
    }
    return;
}
#method_after
public static void ensureCurrentApprovalsLoaded(Iterable<ChangeData> changes) throws OrmException {
    ChangeData first = Iterables.getFirst(changes, null);
    if (first == null) {
        return;
    }
    for (ChangeData cd : changes) {
        cd.currentApprovals();
    }
}
#end_block

#method_before
public static void ensureMessagesLoaded(Iterable<ChangeData> changes) throws OrmException {
    ChangeData first = Iterables.getFirst(changes, null);
    if (first == null) {
        return;
    }
    for (ChangeData cd : changes) {
        cd.messages();
    }
    return;
}
#method_after
public static void ensureMessagesLoaded(Iterable<ChangeData> changes) throws OrmException {
    ChangeData first = Iterables.getFirst(changes, null);
    if (first == null) {
        return;
    }
    for (ChangeData cd : changes) {
        cd.messages();
    }
}
#end_block

#method_before
@Test
public void uploadPackSequencesWithAccessDatabase() throws Exception {
    assume().that(notesMigration.readChangeSequence()).isTrue();
    try (Repository repo = repoManager.openRepository(allProjects)) {
        assertRefs(repo, newFilter(allProjects, user), true);
        allowGlobalCapabilities(REGISTERED_USERS, GlobalCapability.ACCESS_DATABASE);
        assertRefs(repo, newFilter(allProjects, user), true, "refs/sequences/changes");
    }
}
#method_after
@Test
public void uploadPackSequencesWithAccessDatabase() throws Exception {
    try (Repository repo = repoManager.openRepository(allProjects)) {
        assertRefs(repo, newFilter(allProjects, user), true);
        allowGlobalCapabilities(REGISTERED_USERS, GlobalCapability.ACCESS_DATABASE);
        assertRefs(repo, newFilter(allProjects, user), true, "refs/sequences/changes");
    }
}
#end_block

#method_before
@Test
public void advertisedReferencesIncludePrivateChangesWhenAllRefsMayBeRead() throws Exception {
    allow("refs/*", Permission.READ, REGISTERED_USERS);
    TestRepository<?> userTestRepository = cloneProject(project, user);
    try (Git git = userTestRepository.git()) {
        String change3RefName = c3.currentPatchSet().getRefName();
        assertWithMessage("Precondition violated").that(getRefs(git)).contains(change3RefName);
        gApi.changes().id(c3.getId().get()).setPrivate(true, null);
        assertThat(getRefs(git)).contains(change3RefName);
    }
}
#method_after
@Test
public void advertisedReferencesIncludePrivateChangesWhenAllRefsMayBeRead() throws Exception {
    assume().that(baseConfig.getBoolean("auth", "skipFullRefEvaluationIfAllRefsAreVisible", true)).isTrue();
    allow("refs/*", Permission.READ, REGISTERED_USERS);
    TestRepository<?> userTestRepository = cloneProject(project, user);
    try (Git git = userTestRepository.git()) {
        String change3RefName = c3.currentPatchSet().getRefName();
        assertWithMessage("Precondition violated").that(getRefs(git)).contains(change3RefName);
        gApi.changes().id(c3.getId().get()).setPrivate(true, null);
        assertThat(getRefs(git)).contains(change3RefName);
    }
}
#end_block

#method_before
@Test
@GerritConfig(name = "noteDb.groups.write", value = "true")
public void hideMetadata() throws Exception {
    allowGlobalCapabilities(REGISTERED_USERS, GlobalCapability.ACCESS_DATABASE);
    // create change
    TestRepository<?> allUsersRepo = cloneProject(allUsers);
    fetch(allUsersRepo, RefNames.REFS_USERS_SELF + ":userRef");
    allUsersRepo.reset("userRef");
    PushOneCommit.Result mr = pushFactory.create(admin.getIdent(), allUsersRepo).to("refs/for/" + RefNames.REFS_USERS_SELF);
    mr.assertOkStatus();
    List<String> expectedNonMetaRefs = ImmutableList.of(RefNames.REFS_USERS_SELF, RefNames.refsUsers(admin.id), RefNames.refsUsers(user.id), RefNames.REFS_EXTERNAL_IDS, RefNames.REFS_GROUPNAMES, RefNames.refsGroups(admins), RefNames.refsGroups(nonInteractiveUsers), RefNames.REFS_SEQUENCES + Sequences.NAME_ACCOUNTS, RefNames.REFS_SEQUENCES + Sequences.NAME_GROUPS, RefNames.REFS_CONFIG, Constants.HEAD);
    List<String> expectedMetaRefs = new ArrayList<>(ImmutableList.of(mr.getPatchSetId().toRefName()));
    if (NoteDbMode.get() != NoteDbMode.OFF) {
        expectedMetaRefs.add(changeRefPrefix(mr.getChange().getId()) + "meta");
    }
    List<String> expectedAllRefs = new ArrayList<>(expectedNonMetaRefs);
    expectedAllRefs.addAll(expectedMetaRefs);
    try (Repository repo = repoManager.openRepository(allUsers)) {
        Map<String, Ref> all = repo.getAllRefs();
        PermissionBackend.ForProject forProject = newFilter(allUsers, admin);
        assertThat(forProject.filter(all, repo, RefFilterOptions.defaults()).keySet()).containsExactlyElementsIn(expectedAllRefs);
        assertThat(forProject.filter(all, repo, RefFilterOptions.builder().setFilterMeta(true).build()).keySet()).containsExactlyElementsIn(expectedNonMetaRefs);
    }
}
#method_after
@Test
@GerritConfig(name = "noteDb.groups.write", value = "true")
public void hideMetadata() throws Exception {
    allowGlobalCapabilities(REGISTERED_USERS, GlobalCapability.ACCESS_DATABASE);
    // create change
    TestRepository<?> allUsersRepo = cloneProject(allUsers);
    fetch(allUsersRepo, RefNames.REFS_USERS_SELF + ":userRef");
    allUsersRepo.reset("userRef");
    PushOneCommit.Result mr = pushFactory.create(admin.getIdent(), allUsersRepo).to("refs/for/" + RefNames.REFS_USERS_SELF);
    mr.assertOkStatus();
    List<String> expectedNonMetaRefs = ImmutableList.of(RefNames.REFS_USERS_SELF, RefNames.refsUsers(admin.id), RefNames.refsUsers(user.id), RefNames.REFS_EXTERNAL_IDS, RefNames.REFS_GROUPNAMES, RefNames.refsGroups(admins), RefNames.refsGroups(nonInteractiveUsers), RefNames.REFS_SEQUENCES + Sequences.NAME_ACCOUNTS, RefNames.REFS_SEQUENCES + Sequences.NAME_GROUPS, RefNames.REFS_CONFIG, Constants.HEAD);
    List<String> expectedMetaRefs = new ArrayList<>(ImmutableList.of(mr.getPatchSetId().toRefName()));
    expectedMetaRefs.add(changeRefPrefix(mr.getChange().getId()) + "meta");
    List<String> expectedAllRefs = new ArrayList<>(expectedNonMetaRefs);
    expectedAllRefs.addAll(expectedMetaRefs);
    try (Repository repo = repoManager.openRepository(allUsers)) {
        Map<String, Ref> all = repo.getAllRefs();
        PermissionBackend.ForProject forProject = newFilter(allUsers, admin);
        assertThat(forProject.filter(all, repo, RefFilterOptions.defaults()).keySet()).containsExactlyElementsIn(expectedAllRefs);
        assertThat(forProject.filter(all, repo, RefFilterOptions.builder().setFilterMeta(true).build()).keySet()).containsExactlyElementsIn(expectedNonMetaRefs);
    }
}
#end_block

#method_before
protected void afterTest() throws Exception {
    Transport.unregister(inProcessProtocol);
    for (Repository repo : toClose) {
        repo.close();
    }
    db.close();
    closeSsh();
    if (server != commonServer) {
        server.close();
        server = null;
    }
    NoteDbMode.resetFromEnv(notesMigration);
}
#method_after
protected void afterTest() throws Exception {
    Transport.unregister(inProcessProtocol);
    for (Repository repo : toClose) {
        repo.close();
    }
    db.close();
    closeSsh();
    if (server != commonServer) {
        server.close();
        server = null;
    }
}
#end_block

#method_before
protected Context disableDb() {
    notesMigration.setFailOnLoadForTest(true);
    return atrScope.disableDb();
}
#method_after
protected Context disableDb() {
    changeNotesArgs.failOnLoadForTest.set(true);
    return atrScope.disableDb();
}
#end_block

#method_before
protected void enableDb(Context preDisableContext) {
    notesMigration.setFailOnLoadForTest(false);
    atrScope.set(preDisableContext);
}
#method_after
protected void enableDb(Context preDisableContext) {
    changeNotesArgs.failOnLoadForTest.set(false);
    atrScope.set(preDisableContext);
}
#end_block

#method_before
@Test
public void getRelatedManyGroups() throws Exception {
    List<RevCommit> commits = new ArrayList<>();
    RevCommit last = null;
    int n = 2 * MAX_TERMS;
    assertThat(n).isGreaterThan(indexConfig.maxTerms());
    for (int i = 1; i <= n; i++) {
        TestRepository<?>.CommitBuilder cb = last != null ? amendBuilder() : commitBuilder();
        last = cb.add("a.txt", Integer.toString(i)).message("subject: " + i).create();
        testRepo.reset(last);
        assertPushOk(pushHead(testRepo, "refs/for/master", false), "refs/for/master");
        commits.add(last);
    }
    ChangeData cd = getChange(last);
    assertThat(cd.patchSets()).hasSize(n);
    assertThat(GetRelated.getAllGroups(cd.notes(), psUtil)).hasSize(n);
    assertRelated(cd.change().currentPatchSetId());
}
#method_after
@Test
public void getRelatedManyGroups() throws Exception {
    RevCommit last = null;
    int n = 2 * MAX_TERMS;
    assertThat(n).isGreaterThan(indexConfig.maxTerms());
    for (int i = 1; i <= n; i++) {
        TestRepository<?>.CommitBuilder cb = last != null ? amendBuilder() : commitBuilder();
        last = cb.add("a.txt", Integer.toString(i)).message("subject: " + i).create();
        testRepo.reset(last);
        assertPushOk(pushHead(testRepo, "refs/for/master", false), "refs/for/master");
    }
    ChangeData cd = getChange(last);
    assertThat(cd.patchSets()).hasSize(n);
    assertThat(GetRelated.getAllGroups(cd.notes(), psUtil)).hasSize(n);
    assertRelated(cd.change().currentPatchSetId());
}
#end_block

#method_before
@Override
public Object apply(ProjectResource rsrc, Input input) throws OrmException, IOException, RestApiException {
    preConditions.assertDeletePermission(rsrc);
    preConditions.assertCanBeDeleted(rsrc, input);
    doDelete(rsrc, input);
    return Response.none();
}
#method_after
@Override
public Object apply(ProjectResource rsrc, Input input) throws IOException, RestApiException {
    preConditions.assertDeletePermission(rsrc);
    preConditions.assertCanBeDeleted(rsrc, input);
    doDelete(rsrc, input);
    return Response.none();
}
#end_block

#method_before
private void assertIsNotSubmodule(Project.NameKey projectNameKey) throws CannotDeleteProjectException {
    try (Repository repo = repoManager.openRepository(projectNameKey);
        MergeOpRepoManager mergeOp = mergeOpProvider.get()) {
        Set<Branch.NameKey> branches = repo.getRefDatabase().getRefsByPrefix(REFS_HEADS).stream().map(r -> new Branch.NameKey(projectNameKey, r.getName().substring(REFS_HEADS.length()))).collect(toSet());
        SubmoduleOp sub = subOpFactory.create(branches, mergeOp);
        for (Branch.NameKey b : branches) {
            if (!sub.superProjectSubscriptionsForSubmoduleBranch(b).isEmpty()) {
                throw new CannotDeleteProjectException("Project is subscribed by other projects.");
            }
        }
    } catch (RepositoryNotFoundException e) {
    // we're trying to delete the repository,
    // so this exception should not stop us
    } catch (IOException | SubmoduleException e) {
        throw new CannotDeleteProjectException("Project is subscribed by other projects.");
    }
}
#method_after
private void assertIsNotSubmodule(Project.NameKey projectNameKey) throws CannotDeleteProjectException {
    try (Repository repo = repoManager.openRepository(projectNameKey);
        MergeOpRepoManager mergeOp = mergeOpProvider.get()) {
        Set<Branch.NameKey> branches = repo.getRefDatabase().getRefsByPrefix(REFS_HEADS).stream().map(ref -> new Branch.NameKey(projectNameKey, ref.getName())).collect(toSet());
        SubmoduleOp sub = subOpFactory.create(branches, mergeOp);
        for (Branch.NameKey b : branches) {
            if (!sub.superProjectSubscriptionsForSubmoduleBranch(b).isEmpty()) {
                throw new CannotDeleteProjectException("Project is subscribed by other projects.");
            }
        }
    } catch (RepositoryNotFoundException e) {
    // we're trying to delete the repository,
    // so this exception should not stop us
    } catch (IOException | SubmoduleException e) {
        throw new CannotDeleteProjectException("Project is subscribed by other projects.");
    }
}
#end_block

#method_before
@Test
public void output() throws Exception {
    String url = canonicalWebUrl.get() + "c/" + project.get() + "/+/";
    ObjectId initialHead = testRepo.getRepository().resolve("HEAD");
    PushOneCommit.Result r1 = pushTo("refs/for/master");
    Change.Id id1 = r1.getChange().getId();
    r1.assertOkStatus();
    r1.assertChange(Change.Status.NEW, null);
    r1.assertMessage("New changes:\n  " + url + id1 + " " + r1.getCommit().getShortMessage() + "\n");
    testRepo.reset(initialHead);
    String newMsg = r1.getCommit().getShortMessage() + " v2";
    testRepo.branch("HEAD").commit().message(newMsg).insertChangeId(r1.getChangeId().substring(1)).create();
    PushOneCommit.Result r2 = pushFactory.create(db, admin.getIdent(), testRepo, "another commit", "b.txt", "bbb").to("refs/for/master");
    Change.Id id2 = r2.getChange().getId();
    r2.assertOkStatus();
    r2.assertChange(Change.Status.NEW, null);
    r2.assertMessage("New changes:\n" + "  " + url + id2 + " another commit\n" + "\n" + "\n" + "Updated changes:\n" + "  " + url + id1 + " " + newMsg + "\n");
}
#method_after
@Test
public void output() throws Exception {
    String url = canonicalWebUrl.get() + "c/" + project.get() + "/+/";
    ObjectId initialHead = testRepo.getRepository().resolve("HEAD");
    PushOneCommit.Result r1 = pushTo("refs/for/master");
    Change.Id id1 = r1.getChange().getId();
    r1.assertOkStatus();
    r1.assertChange(Change.Status.NEW, null);
    r1.assertMessage("New changes:\n  " + url + id1 + " " + r1.getCommit().getShortMessage() + "\n");
    testRepo.reset(initialHead);
    String newMsg = r1.getCommit().getShortMessage() + " v2";
    testRepo.branch("HEAD").commit().message(newMsg).insertChangeId(r1.getChangeId().substring(1)).create();
    PushOneCommit.Result r2 = pushFactory.create(db, admin.getIdent(), testRepo, "another commit", "b.txt", "bbb").to("refs/for/master");
    Change.Id id2 = r2.getChange().getId();
    r2.assertOkStatus();
    r2.assertChange(Change.Status.NEW, null);
    r2.assertMessage("success\n" + "\n" + "New changes:\n" + "  " + url + id2 + " another commit\n" + "\n" + "Updated changes:\n" + "  " + url + id1 + " " + newMsg + "\n");
}
#end_block

#method_before
@Test
public void pushForMasterWithTopic() throws Exception {
    // specify topic in ref
    String topic = "my/topic";
    PushOneCommit.Result r = pushTo("refs/for/master/" + topic);
    r.assertOkStatus();
    r.assertChange(Change.Status.NEW, topic);
    // specify topic as option
    r = pushTo("refs/for/master%topic=" + topic);
    r.assertOkStatus();
    r.assertChange(Change.Status.NEW, topic);
}
#method_after
@Test
public void pushForMasterWithTopic() throws Exception {
    // specify topic in ref
    String topic = "my/topic";
    PushOneCommit.Result r = pushTo("refs/for/master/" + topic);
    r.assertOkStatus();
    r.assertChange(Change.Status.NEW, topic);
    r.assertMessage("deprecated topic syntax");
    // specify topic as option
    r = pushTo("refs/for/master%topic=" + topic);
    r.assertOkStatus();
    r.assertChange(Change.Status.NEW, topic);
}
#end_block

#method_before
@Test
public void pushForMasterWithNotify() throws Exception {
    // create a user that watches the project
    TestAccount user3 = accountCreator.create("user3", "user3@example.com", "User3");
    List<ProjectWatchInfo> projectsToWatch = new ArrayList<>();
    ProjectWatchInfo pwi = new ProjectWatchInfo();
    pwi.project = project.get();
    pwi.filter = "*";
    pwi.notifyNewChanges = true;
    projectsToWatch.add(pwi);
    setApiUser(user3);
    gApi.accounts().self().setWatchedProjects(projectsToWatch);
    TestAccount user2 = accountCreator.user2();
    String pushSpec = "refs/for/master%reviewer=" + user.email + ",cc=" + user2.email;
    sender.clear();
    PushOneCommit.Result r = pushTo(pushSpec + ",notify=" + NotifyHandling.NONE);
    r.assertOkStatus();
    assertThat(sender.getMessages()).isEmpty();
    sender.clear();
    r = pushTo(pushSpec + ",notify=" + NotifyHandling.OWNER);
    r.assertOkStatus();
    // no email notification about own changes
    assertThat(sender.getMessages()).isEmpty();
    sender.clear();
    r = pushTo(pushSpec + ",notify=" + NotifyHandling.OWNER_REVIEWERS);
    r.assertOkStatus();
    assertThat(sender.getMessages()).hasSize(1);
    Message m = sender.getMessages().get(0);
    assertThat(m.rcpt()).containsExactly(user.emailAddress);
    sender.clear();
    r = pushTo(pushSpec + ",notify=" + NotifyHandling.ALL);
    r.assertOkStatus();
    assertThat(sender.getMessages()).hasSize(1);
    m = sender.getMessages().get(0);
    assertThat(m.rcpt()).containsExactly(user.emailAddress, user2.emailAddress, user3.emailAddress);
    sender.clear();
    r = pushTo(pushSpec + ",notify=" + NotifyHandling.NONE + ",notify-to=" + user3.email);
    r.assertOkStatus();
    assertNotifyTo(user3);
    sender.clear();
    r = pushTo(pushSpec + ",notify=" + NotifyHandling.NONE + ",notify-cc=" + user3.email);
    r.assertOkStatus();
    assertNotifyCc(user3);
    sender.clear();
    r = pushTo(pushSpec + ",notify=" + NotifyHandling.NONE + ",notify-bcc=" + user3.email);
    r.assertOkStatus();
    assertNotifyBcc(user3);
    // request that sender gets notified as TO, CC and BCC, email should be sent
    // even if the sender is the only recipient
    sender.clear();
    r = pushTo(pushSpec + ",notify=" + NotifyHandling.NONE + ",notify-to=" + admin.email);
    assertNotifyTo(admin);
    sender.clear();
    r = pushTo(pushSpec + ",notify=" + NotifyHandling.NONE + ",notify-cc=" + admin.email);
    r.assertOkStatus();
    assertNotifyCc(admin);
    sender.clear();
    r = pushTo(pushSpec + ",notify=" + NotifyHandling.NONE + ",notify-bcc=" + admin.email);
    r.assertOkStatus();
    assertNotifyBcc(admin);
}
#method_after
@Test
public void pushForMasterWithNotify() throws Exception {
    // create a user that watches the project
    TestAccount user3 = accountCreator.create("user3", "user3@example.com", "User3");
    List<ProjectWatchInfo> projectsToWatch = new ArrayList<>();
    ProjectWatchInfo pwi = new ProjectWatchInfo();
    pwi.project = project.get();
    pwi.filter = "*";
    pwi.notifyNewChanges = true;
    projectsToWatch.add(pwi);
    setApiUser(user3);
    gApi.accounts().self().setWatchedProjects(projectsToWatch);
    TestAccount user2 = accountCreator.user2();
    String pushSpec = "refs/for/master%reviewer=" + user.email + ",cc=" + user2.email;
    sender.clear();
    PushOneCommit.Result r = pushTo(pushSpec + ",notify=" + NotifyHandling.NONE);
    r.assertOkStatus();
    assertThat(sender.getMessages()).isEmpty();
    sender.clear();
    r = pushTo(pushSpec + ",notify=" + NotifyHandling.OWNER);
    r.assertOkStatus();
    // no email notification about own changes
    assertThat(sender.getMessages()).isEmpty();
    sender.clear();
    r = pushTo(pushSpec + ",notify=" + NotifyHandling.OWNER_REVIEWERS);
    r.assertOkStatus();
    assertThat(sender.getMessages()).hasSize(1);
    Message m = sender.getMessages().get(0);
    if (notesMigration.readChanges()) {
        assertThat(m.rcpt()).containsExactly(user.emailAddress);
    } else {
        // CCs are considered reviewers in the storage layer and so get notified.
        assertThat(m.rcpt()).containsExactly(user.emailAddress, user2.emailAddress);
    }
    sender.clear();
    r = pushTo(pushSpec + ",notify=" + NotifyHandling.ALL);
    r.assertOkStatus();
    assertThat(sender.getMessages()).hasSize(1);
    m = sender.getMessages().get(0);
    assertThat(m.rcpt()).containsExactly(user.emailAddress, user2.emailAddress, user3.emailAddress);
    sender.clear();
    r = pushTo(pushSpec + ",notify=" + NotifyHandling.NONE + ",notify-to=" + user3.email);
    r.assertOkStatus();
    assertNotifyTo(user3);
    sender.clear();
    r = pushTo(pushSpec + ",notify=" + NotifyHandling.NONE + ",notify-cc=" + user3.email);
    r.assertOkStatus();
    assertNotifyCc(user3);
    sender.clear();
    r = pushTo(pushSpec + ",notify=" + NotifyHandling.NONE + ",notify-bcc=" + user3.email);
    r.assertOkStatus();
    assertNotifyBcc(user3);
    // request that sender gets notified as TO, CC and BCC, email should be sent
    // even if the sender is the only recipient
    sender.clear();
    pushTo(pushSpec + ",notify=" + NotifyHandling.NONE + ",notify-to=" + admin.email);
    assertNotifyTo(admin);
    sender.clear();
    r = pushTo(pushSpec + ",notify=" + NotifyHandling.NONE + ",notify-cc=" + admin.email);
    r.assertOkStatus();
    assertNotifyCc(admin);
    sender.clear();
    r = pushTo(pushSpec + ",notify=" + NotifyHandling.NONE + ",notify-bcc=" + admin.email);
    r.assertOkStatus();
    assertNotifyBcc(admin);
}
#end_block

#method_before
@Test
public void pushForMasterWithCc() throws Exception {
    // cc one user
    String topic = "my/topic";
    PushOneCommit.Result r = pushTo("refs/for/master/" + topic + "%cc=" + user.email);
    r.assertOkStatus();
    r.assertChange(Change.Status.NEW, topic, ImmutableList.of(), ImmutableList.of(user));
    // cc several users
    r = pushTo("refs/for/master/" + topic + "%cc=" + admin.email + ",cc=" + user.email + ",cc=" + accountCreator.user2().email);
    r.assertOkStatus();
    // Check that admin isn't CC'd as they own the change
    r.assertChange(Change.Status.NEW, topic, ImmutableList.of(), ImmutableList.of(user, accountCreator.user2()));
    // cc non-existing user
    String nonExistingEmail = "non.existing@example.com";
    r = pushTo("refs/for/master/" + topic + "%cc=" + admin.email + ",cc=" + nonExistingEmail + ",cc=" + user.email);
    r.assertErrorStatus("user \"" + nonExistingEmail + "\" not found");
}
#method_after
@Test
public void pushForMasterWithCc() throws Exception {
    // cc one user
    String topic = "my/topic";
    PushOneCommit.Result r = pushTo("refs/for/master/" + topic + "%cc=" + user.email);
    r.assertOkStatus();
    r.assertChange(Change.Status.NEW, topic, ImmutableList.of(), ImmutableList.of(user));
    // cc several users
    r = pushTo("refs/for/master/" + topic + "%cc=" + admin.email + ",cc=" + user.email + ",cc=" + accountCreator.user2().email);
    r.assertOkStatus();
    // Check that admin isn't CC'd as they own the change
    r.assertChange(Change.Status.NEW, topic, ImmutableList.of(), ImmutableList.of(user, accountCreator.user2()));
    // cc non-existing user
    String nonExistingEmail = "non.existing@example.com";
    r = pushTo("refs/for/master/" + topic + "%cc=" + admin.email + ",cc=" + nonExistingEmail + ",cc=" + user.email);
    r.assertErrorStatus(nonExistingEmail + " does not identify a registered user or group");
}
#end_block

#method_before
@Test
public void pushForMasterWithReviewer() throws Exception {
    // add one reviewer
    String topic = "my/topic";
    PushOneCommit.Result r = pushTo("refs/for/master/" + topic + "%r=" + user.email);
    r.assertOkStatus();
    r.assertChange(Change.Status.NEW, topic, user);
    // add several reviewers
    TestAccount user2 = accountCreator.create("another-user", "another.user@example.com", "Another User");
    r = pushTo("refs/for/master/" + topic + "%r=" + admin.email + ",r=" + user.email + ",r=" + user2.email);
    r.assertOkStatus();
    // admin is the owner of the change and should not appear as reviewer
    r.assertChange(Change.Status.NEW, topic, user, user2);
    // add non-existing user as reviewer
    String nonExistingEmail = "non.existing@example.com";
    r = pushTo("refs/for/master/" + topic + "%r=" + admin.email + ",r=" + nonExistingEmail + ",r=" + user.email);
    r.assertErrorStatus("user \"" + nonExistingEmail + "\" not found");
}
#method_after
@Test
public void pushForMasterWithReviewer() throws Exception {
    // add one reviewer
    String topic = "my/topic";
    PushOneCommit.Result r = pushTo("refs/for/master/" + topic + "%r=" + user.email);
    r.assertOkStatus();
    r.assertChange(Change.Status.NEW, topic, user);
    // add several reviewers
    TestAccount user2 = accountCreator.create("another-user", "another.user@example.com", "Another User");
    r = pushTo("refs/for/master/" + topic + "%r=" + admin.email + ",r=" + user.email + ",r=" + user2.email);
    r.assertOkStatus();
    // admin is the owner of the change and should not appear as reviewer
    r.assertChange(Change.Status.NEW, topic, user, user2);
    // add non-existing user as reviewer
    String nonExistingEmail = "non.existing@example.com";
    r = pushTo("refs/for/master/" + topic + "%r=" + admin.email + ",r=" + nonExistingEmail + ",r=" + user.email);
    r.assertErrorStatus(nonExistingEmail + " does not identify a registered user or group");
}
#end_block

#method_before
@Test
public void pushCommitUsingSignedOffBy() throws Exception {
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo, PushOneCommit.SUBJECT, "b.txt", "anotherContent");
    PushOneCommit.Result r = push.to("refs/for/master");
    r.assertOkStatus();
    setUseSignedOffBy(InheritableBoolean.TRUE);
    block(project, "refs/heads/master", Permission.FORGE_COMMITTER, REGISTERED_USERS);
    push = pushFactory.create(db, admin.getIdent(), testRepo, PushOneCommit.SUBJECT + String.format("\n\nSigned-off-by: %s <%s>", admin.fullName, admin.email), "b.txt", "anotherContent");
    r = push.to("refs/for/master");
    r.assertOkStatus();
    push = pushFactory.create(db, admin.getIdent(), testRepo, PushOneCommit.SUBJECT, "b.txt", "anotherContent");
    r = push.to("refs/for/master");
    r.assertErrorStatus("not Signed-off-by author/committer/uploader in commit message footer");
}
#method_after
@Test
public void pushCommitUsingSignedOffBy() throws Exception {
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo, PushOneCommit.SUBJECT, "b.txt", "anotherContent");
    PushOneCommit.Result r = push.to("refs/for/master");
    r.assertOkStatus();
    setUseSignedOffBy(InheritableBoolean.TRUE);
    block(project, "refs/heads/master", Permission.FORGE_COMMITTER, REGISTERED_USERS);
    push = pushFactory.create(db, admin.getIdent(), testRepo, PushOneCommit.SUBJECT + String.format("\n\nSigned-off-by: %s <%s>", admin.fullName, admin.email), "b.txt", "anotherContent");
    r = push.to("refs/for/master");
    r.assertOkStatus();
    push = pushFactory.create(db, admin.getIdent(), testRepo, PushOneCommit.SUBJECT, "b.txt", "anotherContent");
    r = push.to("refs/for/master");
    r.assertErrorStatus("not Signed-off-by author/committer/uploader in message footer");
}
#end_block

#method_before
@Test
public void pushSameCommitTwiceUsingMagicBranchBaseOption() throws Exception {
    grant(project, "refs/heads/master", Permission.PUSH);
    PushOneCommit.Result rBase = pushTo("refs/heads/master");
    rBase.assertOkStatus();
    gApi.projects().name(project.get()).branch("foo").create(new BranchInput());
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo, PushOneCommit.SUBJECT, "b.txt", "anotherContent");
    PushOneCommit.Result r = push.to("refs/for/master");
    r.assertOkStatus();
    PushResult pr = GitUtil.pushHead(testRepo, "refs/for/foo%base=" + rBase.getCommit().name(), false, false);
    // BatchUpdate implementations differ in how they hook into progress monitors. We mostly just
    // care that there is a new change.
    assertThat(pr.getMessages()).containsMatch("changes: new: 1,( refs: 1)? done");
    assertTwoChangesWithSameRevision(r);
}
#method_after
@Test
public void pushSameCommitTwiceUsingMagicBranchBaseOption() throws Exception {
    grant(project, "refs/heads/master", Permission.PUSH);
    PushOneCommit.Result rBase = pushTo("refs/heads/master");
    rBase.assertOkStatus();
    gApi.projects().name(project.get()).branch("foo").create(new BranchInput());
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo, PushOneCommit.SUBJECT, "b.txt", "anotherContent");
    PushOneCommit.Result r = push.to("refs/for/master");
    r.assertOkStatus();
    PushResult pr = GitUtil.pushHead(testRepo, "refs/for/foo%base=" + rBase.getCommit().name(), false, false);
    // BatchUpdate implementations differ in how they hook into progress monitors. We mostly just
    // care that there is a new change.
    assertThat(pr.getMessages()).containsMatch("changes: .*new: 1.*done");
    assertTwoChangesWithSameRevision(r);
}
#end_block

#method_before
@Test
public void pushSameCommitTwice() throws Exception {
    try (ProjectConfigUpdate u = updateProject(project)) {
        u.getConfig().getProject().setBooleanConfig(BooleanProjectConfig.CREATE_NEW_CHANGE_FOR_ALL_NOT_IN_TARGET, InheritableBoolean.TRUE);
        u.save();
    }
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo, PushOneCommit.SUBJECT, "a.txt", "content");
    PushOneCommit.Result r = push.to("refs/for/master");
    r.assertOkStatus();
    push = pushFactory.create(db, admin.getIdent(), testRepo, PushOneCommit.SUBJECT, "b.txt", "anotherContent");
    r = push.to("refs/for/master");
    r.assertOkStatus();
    assertPushRejected(pushHead(testRepo, "refs/for/master", false), "refs/for/master", "commit(s) already exists (as current patchset)");
}
#method_after
@Test
public void pushSameCommitTwice() throws Exception {
    enableCreateNewChangeForAllNotInTarget();
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo, PushOneCommit.SUBJECT, "a.txt", "content");
    PushOneCommit.Result r = push.to("refs/for/master");
    r.assertOkStatus();
    push = pushFactory.create(db, admin.getIdent(), testRepo, PushOneCommit.SUBJECT, "b.txt", "anotherContent");
    r = push.to("refs/for/master");
    r.assertOkStatus();
    assertPushRejected(pushHead(testRepo, "refs/for/master", false), "refs/for/master", "commit(s) already exists (as current patchset)");
}
#end_block

#method_before
@Test
public void pushSameCommitTwiceWhenIndexFailed() throws Exception {
    try (ProjectConfigUpdate u = updateProject(project)) {
        u.getConfig().getProject().setBooleanConfig(BooleanProjectConfig.CREATE_NEW_CHANGE_FOR_ALL_NOT_IN_TARGET, InheritableBoolean.TRUE);
        u.save();
    }
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo, PushOneCommit.SUBJECT, "a.txt", "content");
    PushOneCommit.Result r = push.to("refs/for/master");
    r.assertOkStatus();
    push = pushFactory.create(db, admin.getIdent(), testRepo, PushOneCommit.SUBJECT, "b.txt", "anotherContent");
    r = push.to("refs/for/master");
    r.assertOkStatus();
    indexer.delete(r.getChange().getId());
    assertPushRejected(pushHead(testRepo, "refs/for/master", false), "refs/for/master", "commit(s) already exists (as current patchset)");
}
#method_after
@Test
public void pushSameCommitTwiceWhenIndexFailed() throws Exception {
    enableCreateNewChangeForAllNotInTarget();
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo, PushOneCommit.SUBJECT, "a.txt", "content");
    PushOneCommit.Result r = push.to("refs/for/master");
    r.assertOkStatus();
    push = pushFactory.create(db, admin.getIdent(), testRepo, PushOneCommit.SUBJECT, "b.txt", "anotherContent");
    r = push.to("refs/for/master");
    r.assertOkStatus();
    indexer.delete(r.getChange().getId());
    assertPushRejected(pushHead(testRepo, "refs/for/master", false), "refs/for/master", "commit(s) already exists (as current patchset)");
}
#end_block

#method_before
private void testPushWithoutChangeId() throws Exception {
    RevCommit c = createCommit(testRepo, "Message without Change-Id");
    assertThat(GitUtil.getChangeId(testRepo, c)).isEmpty();
    pushForReviewRejected(testRepo, "missing Change-Id in commit message footer");
    setRequireChangeId(InheritableBoolean.FALSE);
    pushForReviewOk(testRepo);
}
#method_after
private void testPushWithoutChangeId() throws Exception {
    RevCommit c = createCommit(testRepo, "Message without Change-Id");
    assertThat(GitUtil.getChangeId(testRepo, c)).isEmpty();
    pushForReviewRejected(testRepo, "missing Change-Id in message footer");
    setRequireChangeId(InheritableBoolean.FALSE);
    pushForReviewOk(testRepo);
}
#end_block

#method_before
@Test
@GerritConfig(name = "receive.allowPushToRefsChanges", value = "true")
public void testPushWithChangedChangeId() throws Exception {
    PushOneCommit.Result r = pushTo("refs/for/master");
    r.assertOkStatus();
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo, PushOneCommit.SUBJECT + "\n\n" + "Change-Id: I55eab7c7a76e95005fa9cc469aa8f9fc16da9eba\n", "b.txt", "anotherContent", r.getChangeId());
    r = push.to("refs/changes/" + r.getChange().change().getId().get());
    r.assertErrorStatus(String.format(ChangeIdValidator.CHANGE_ID_MISMATCH_MSG, r.getCommit().abbreviate(RevId.ABBREV_LEN).name()));
}
#method_after
@Test
@GerritConfig(name = "receive.allowPushToRefsChanges", value = "true")
public void testPushWithChangedChangeId() throws Exception {
    PushOneCommit.Result r = pushTo("refs/for/master");
    r.assertOkStatus();
    PushOneCommit push = pushFactory.create(db, admin.getIdent(), testRepo, PushOneCommit.SUBJECT + "\n\n" + "Change-Id: I55eab7c7a76e95005fa9cc469aa8f9fc16da9eba\n", "b.txt", "anotherContent", r.getChangeId());
    r = push.to("refs/changes/" + r.getChange().change().getId().get());
    r.assertErrorStatus(String.format("commit %s: %s", r.getCommit().abbreviate(RevId.ABBREV_LEN).name(), ChangeIdValidator.CHANGE_ID_MISMATCH_MSG));
}
#end_block

#method_before
private void testPushWithMultipleChangeIds() throws Exception {
    createCommit(testRepo, "Message with multiple Change-Id\n" + "\n" + "Change-Id: I10f98c2ef76e52e23aa23be5afeb71e40b350e86\n" + "Change-Id: Ie9a132e107def33bdd513b7854b50de911edba0a\n");
    pushForReviewRejected(testRepo, "multiple Change-Id lines in commit message footer");
    setRequireChangeId(InheritableBoolean.FALSE);
    pushForReviewRejected(testRepo, "multiple Change-Id lines in commit message footer");
}
#method_after
private void testPushWithMultipleChangeIds() throws Exception {
    createCommit(testRepo, "Message with multiple Change-Id\n" + "\n" + "Change-Id: I10f98c2ef76e52e23aa23be5afeb71e40b350e86\n" + "Change-Id: Ie9a132e107def33bdd513b7854b50de911edba0a\n");
    pushForReviewRejected(testRepo, "multiple Change-Id lines in message footer");
    setRequireChangeId(InheritableBoolean.FALSE);
    pushForReviewRejected(testRepo, "multiple Change-Id lines in message footer");
}
#end_block

#method_before
private void testpushWithInvalidChangeId() throws Exception {
    createCommit(testRepo, "Message with invalid Change-Id\n\nChange-Id: X\n");
    pushForReviewRejected(testRepo, "invalid Change-Id line format in commit message footer");
    setRequireChangeId(InheritableBoolean.FALSE);
    pushForReviewRejected(testRepo, "invalid Change-Id line format in commit message footer");
}
#method_after
private void testpushWithInvalidChangeId() throws Exception {
    createCommit(testRepo, "Message with invalid Change-Id\n\nChange-Id: X\n");
    pushForReviewRejected(testRepo, "invalid Change-Id line format in message footer");
    setRequireChangeId(InheritableBoolean.FALSE);
    pushForReviewRejected(testRepo, "invalid Change-Id line format in message footer");
}
#end_block

#method_before
private void testPushWithInvalidChangeIdFromEgit() throws Exception {
    createCommit(testRepo, "Message with invalid Change-Id\n" + "\n" + "Change-Id: I0000000000000000000000000000000000000000\n");
    pushForReviewRejected(testRepo, "invalid Change-Id line format in commit message footer");
    setRequireChangeId(InheritableBoolean.FALSE);
    pushForReviewRejected(testRepo, "invalid Change-Id line format in commit message footer");
}
#method_after
private void testPushWithInvalidChangeIdFromEgit() throws Exception {
    createCommit(testRepo, "Message with invalid Change-Id\n" + "\n" + "Change-Id: I0000000000000000000000000000000000000000\n");
    pushForReviewRejected(testRepo, "invalid Change-Id line format in message footer");
    setRequireChangeId(InheritableBoolean.FALSE);
    pushForReviewRejected(testRepo, "invalid Change-Id line format in message footer");
}
#end_block

#method_before
@Test
public void pushWithChangeIdInSubjectLine() throws Exception {
    createCommit(testRepo, "Change-Id: I1234000000000000000000000000000000000000");
    pushForReviewRejected(testRepo, "missing subject; Change-Id must be in commit message footer");
    setRequireChangeId(InheritableBoolean.FALSE);
    pushForReviewRejected(testRepo, "missing subject; Change-Id must be in commit message footer");
}
#method_after
@Test
public void pushWithChangeIdInSubjectLine() throws Exception {
    createCommit(testRepo, "Change-Id: I1234000000000000000000000000000000000000");
    pushForReviewRejected(testRepo, "missing subject; Change-Id must be in message footer");
    setRequireChangeId(InheritableBoolean.FALSE);
    pushForReviewRejected(testRepo, "missing subject; Change-Id must be in message footer");
}
#end_block

#method_before
@Test
public void publishCommentsOnPushOnlyPublishesDraftsOnUpdatedChanges() throws Exception {
    PushOneCommit.Result r1 = createChange();
    PushOneCommit.Result r2 = createChange();
    String id1 = r1.getChangeId();
    String id2 = r2.getChangeId();
    addDraft(id1, r1.getCommit().name(), newDraft(FILE_NAME, 1, "comment1"));
    CommentInfo c2 = addDraft(id2, r2.getCommit().name(), newDraft(FILE_NAME, 1, "comment2"));
    assertThat(getPublishedComments(id1)).isEmpty();
    assertThat(getPublishedComments(id2)).isEmpty();
    r2 = amendChange(id2, "refs/for/master%publish-comments");
    assertThat(getPublishedComments(id1)).isEmpty();
    assertThat(gApi.changes().id(id1).drafts()).hasSize(1);
    Collection<CommentInfo> cs2 = getPublishedComments(id2);
    assertThat(cs2.stream().map(c -> c.message)).containsExactly("comment2");
    assertThat(cs2.stream().map(c -> c.id)).containsExactly(c2.id);
    assertThat(getLastMessage(id1)).doesNotMatch("[Cc]omment");
    assertThat(getLastMessage(id2)).isEqualTo("Uploaded patch set 2.\n\n(1 comment)");
}
#method_after
@Test
public void publishCommentsOnPushOnlyPublishesDraftsOnUpdatedChanges() throws Exception {
    PushOneCommit.Result r1 = createChange();
    PushOneCommit.Result r2 = createChange();
    String id1 = r1.getChangeId();
    String id2 = r2.getChangeId();
    addDraft(id1, r1.getCommit().name(), newDraft(FILE_NAME, 1, "comment1"));
    CommentInfo c2 = addDraft(id2, r2.getCommit().name(), newDraft(FILE_NAME, 1, "comment2"));
    assertThat(getPublishedComments(id1)).isEmpty();
    assertThat(getPublishedComments(id2)).isEmpty();
    amendChange(id2, "refs/for/master%publish-comments");
    assertThat(getPublishedComments(id1)).isEmpty();
    assertThat(gApi.changes().id(id1).drafts()).hasSize(1);
    Collection<CommentInfo> cs2 = getPublishedComments(id2);
    assertThat(cs2.stream().map(c -> c.message)).containsExactly("comment2");
    assertThat(cs2.stream().map(c -> c.id)).containsExactly(c2.id);
    assertThat(getLastMessage(id1)).doesNotMatch("[Cc]omment");
    assertThat(getLastMessage(id2)).isEqualTo("Uploaded patch set 2.\n\n(1 comment)");
}
#end_block

#method_before
@GerritConfig(name = "receive.maxBatchCommits", value = "2")
@Test
public void maxBatchCommits() throws Exception {
    List<RevCommit> commits = new ArrayList<>();
    commits.addAll(initChanges(2));
    String master = "refs/heads/master";
    assertPushOk(pushHead(testRepo, master), master);
    commits.addAll(initChanges(3));
    assertPushRejected(pushHead(testRepo, master), master, "too many commits");
    grantSkipValidation(project, master, SystemGroupBackend.REGISTERED_USERS);
    PushResult r = pushHead(testRepo, master, false, false, ImmutableList.of(PUSH_OPTION_SKIP_VALIDATION));
    assertPushOk(r, master);
    // No open changes; branch was advanced.
    String q = commits.stream().map(ObjectId::name).collect(joining(" OR commit:", "commit:", ""));
    assertThat(gApi.changes().query(q).get()).isEmpty();
    assertThat(gApi.projects().name(project.get()).branch(master).get().revision).isEqualTo(Iterables.getLast(commits).name());
}
#method_after
@GerritConfig(name = "receive.maxBatchCommits", value = "2")
@Test
public void maxBatchCommits() throws Exception {
    List<RevCommit> commits = new ArrayList<>();
    commits.addAll(initChanges(2));
    String master = "refs/heads/master";
    assertPushOk(pushHead(testRepo, master), master);
    commits.addAll(initChanges(3));
    assertPushRejected(pushHead(testRepo, master), master, "more than 2 commits, and skip-validation not set");
    grantSkipValidation(project, master, SystemGroupBackend.REGISTERED_USERS);
    PushResult r = pushHead(testRepo, master, false, false, ImmutableList.of(PUSH_OPTION_SKIP_VALIDATION));
    assertPushOk(r, master);
    // No open changes; branch was advanced.
    String q = commits.stream().map(ObjectId::name).collect(joining(" OR commit:", "commit:", ""));
    assertThat(gApi.changes().query(q).get()).isEmpty();
    assertThat(gApi.projects().name(project.get()).branch(master).get().revision).isEqualTo(Iterables.getLast(commits).name());
}
#end_block

#method_before
@Test
public void pushNoteDbRefWithoutOptionOnlyFailsThatCommand() throws Exception {
    String ref = "refs/changes/34/1234/meta";
    RevCommit noteDbCommit = testRepo.commit().message("Junk NoteDb commit").create();
    RevCommit changeCommit = testRepo.branch("HEAD").commit().message("A change").insertChangeId().create();
    PushResult pr = Iterables.getOnlyElement(testRepo.git().push().setRefSpecs(new RefSpec(noteDbCommit.name() + ":" + ref), new RefSpec(changeCommit.name() + ":refs/for/master")).call());
    assertPushRejected(pr, ref, "NoteDb update requires -o notedb=allow");
    assertPushOk(pr, "refs/for/master");
}
#method_after
@Test
public void pushNoteDbRefWithoutOptionOnlyFailsThatCommand() throws Exception {
    String ref = "refs/changes/34/1234/meta";
    RevCommit noteDbCommit = testRepo.commit().message("Junk NoteDb commit").create();
    RevCommit changeCommit = testRepo.branch("HEAD").commit().message("A change").insertChangeId().create();
    PushResult pr = Iterables.getOnlyElement(testRepo.git().push().setRefSpecs(new RefSpec(noteDbCommit.name() + ":" + ref), new RefSpec(changeCommit.name() + ":refs/heads/permitted")).call());
    assertPushRejected(pr, ref, "NoteDb update requires -o notedb=allow");
    assertPushOk(pr, "refs/heads/permitted");
}
#end_block

#method_before
private void pushWithReviewerInFooter(String nameEmail, TestAccount expectedReviewer) throws Exception {
    int n = 5;
    String r = "refs/for/master";
    ObjectId initialHead = testRepo.getRepository().resolve("HEAD");
    List<RevCommit> commits = createChanges(n, r, ImmutableList.of("Acked-By: " + nameEmail));
    for (int i = 0; i < n; i++) {
        RevCommit c = commits.get(i);
        ChangeData cd = byCommit(c);
        String name = "reviewers for " + (i + 1);
        if (expectedReviewer != null) {
            assertThat(cd.reviewers().all()).named(name).containsExactly(expectedReviewer.getId());
            gApi.changes().id(cd.getId().get()).reviewer(expectedReviewer.getId().toString()).remove();
        }
        assertThat(byCommit(c).reviewers().all()).named(name).isEmpty();
    }
    List<RevCommit> commits2 = amendChanges(initialHead, commits, r);
    for (int i = 0; i < n; i++) {
        RevCommit c = commits2.get(i);
        ChangeData cd = byCommit(c);
        String name = "reviewers for " + (i + 1);
        if (expectedReviewer != null) {
            assertThat(cd.reviewers().all()).named(name).containsExactly(expectedReviewer.getId());
        } else {
            assertThat(byCommit(c).reviewers().all()).named(name).isEmpty();
        }
    }
}
#method_after
private void pushWithReviewerInFooter(String nameEmail, TestAccount expectedReviewer) throws Exception {
    int n = 5;
    String r = "refs/for/master";
    ObjectId initialHead = testRepo.getRepository().resolve("HEAD");
    List<RevCommit> commits = createChanges(n, r, ImmutableList.of("Acked-By: " + nameEmail));
    for (int i = 0; i < n; i++) {
        RevCommit c = commits.get(i);
        ChangeData cd = byCommit(c);
        String name = "reviewers for " + (i + 1);
        if (expectedReviewer != null) {
            assertThat(cd.reviewers().all()).named(name).containsExactly(expectedReviewer.getId());
            // Remove reviewer from PS1 so we can test adding this same reviewer on PS2 below.
            gApi.changes().id(cd.getId().get()).reviewer(expectedReviewer.getId().toString()).remove();
        }
        assertThat(byCommit(c).reviewers().all()).named(name).isEmpty();
    }
    List<RevCommit> commits2 = amendChanges(initialHead, commits, r);
    for (int i = 0; i < n; i++) {
        RevCommit c = commits2.get(i);
        ChangeData cd = byCommit(c);
        String name = "reviewers for " + (i + 1);
        if (expectedReviewer != null) {
            assertThat(cd.reviewers().all()).named(name).containsExactly(expectedReviewer.getId());
        } else {
            assertThat(byCommit(c).reviewers().all()).named(name).isEmpty();
        }
    }
}
#end_block

#method_before
void init() {
    for (ReceivePackInitializer i : initializers) {
        i.init(projectState.getNameKey(), receivePack);
    }
}
#method_after
void init() {
    initializers.runEach(i -> i.init(projectState.getNameKey(), receivePack));
}
#end_block

#method_before
private void addMessage(String message) {
    messages.add(new CommitValidationMessage(message, false));
}
#method_after
private void addMessage(String message, ValidationMessage.Type type) {
    messages.add(new CommitValidationMessage(message, type));
}
#end_block

#method_before
private void addMessage(String message) {
    messages.add(new CommitValidationMessage(message, false));
}
#method_after
private void addMessage(String message) {
    messages.add(new CommitValidationMessage(message, ValidationMessage.Type.OTHER));
}
#end_block

#method_before
void addError(String error) {
    messages.add(new CommitValidationMessage(error, true));
}
#method_after
private void addError(String error) {
    addMessage(error, ValidationMessage.Type.ERROR);
}
#end_block

#method_before
void sendMessages() {
    for (ValidationMessage m : messages) {
        if (m.isError()) {
            messageSender.sendError(m.getMessage());
        } else {
            messageSender.sendMessage(m.getMessage());
        }
    }
}
#method_after
void sendMessages() {
    for (ValidationMessage m : messages) {
        String msg = m.getType().getPrefix() + m.getMessage();
        // Avoid calling sendError which will add its own error: prefix.
        messageSender.sendMessage(msg);
    }
}
#end_block

#method_before
void processCommands(Collection<ReceiveCommand> commands, MultiProgressMonitor progress) {
    newProgress = progress.beginSubTask("new", UNKNOWN);
    replaceProgress = progress.beginSubTask("updated", UNKNOWN);
    closeProgress = progress.beginSubTask("closed", UNKNOWN);
    commandProgress = progress.beginSubTask("refs", UNKNOWN);
    try {
        parsePushOptions();
        logDebug("Parsing %d commands", commands.size());
        for (ReceiveCommand cmd : commands) {
            if (!projectState.getProject().getState().permitsWrite()) {
                reject(cmd, "prohibited by Gerrit: project state does not permit write");
                break;
            }
            parseCommand(cmd);
        }
    } catch (PermissionBackendException | NoSuchProjectException | IOException err) {
        for (ReceiveCommand cmd : actualCommands) {
            if (cmd.getResult() == NOT_ATTEMPTED) {
                cmd.setResult(REJECTED_OTHER_REASON, "internal server error");
            }
        }
        logError(String.format("Failed to process refs in %s", project.getName()), err);
    }
    List<CreateRequest> newChanges = Collections.emptyList();
    if (magicBranch != null && magicBranch.cmd.getResult() == NOT_ATTEMPTED) {
        newChanges = selectNewAndReplacedChangesFromMagicBranch();
    }
    preparePatchSetsForReplace(newChanges);
    insertChangesAndPatchSets(newChanges);
    newProgress.end();
    replaceProgress.end();
    if (!errors.isEmpty()) {
        logDebug("Handling error conditions: %s", errors.keySet());
        for (String error : errors.keySet()) {
            receivePack.sendMessage(buildError(error, errors.get(error)));
        }
        receivePack.sendMessage(String.format("User: %s", user.getLoggableName()));
        receivePack.sendMessage(COMMAND_REJECTION_MESSAGE_FOOTER);
    }
    Set<Branch.NameKey> branches = new HashSet<>();
    for (ReceiveCommand c : actualCommands) {
        // involve kicking off an additional BatchUpdate.
        if (c.getResult() != OK) {
            continue;
        }
        if (isHead(c) || isConfig(c)) {
            switch(c.getType()) {
                case CREATE:
                case UPDATE:
                case UPDATE_NONFASTFORWARD:
                    autoCloseChanges(c);
                    branches.add(new Branch.NameKey(project.getNameKey(), c.getRefName()));
                    break;
                case DELETE:
                    break;
            }
        }
    }
    // Update superproject gitlinks if required.
    if (!branches.isEmpty()) {
        try (MergeOpRepoManager orm = ormProvider.get()) {
            orm.setContext(db, TimeUtil.nowTs(), user, receiveId);
            SubmoduleOp op = subOpFactory.create(branches, orm);
            op.updateSuperProjects();
        } catch (SubmoduleException e) {
            logError("Can't update the superprojects", e);
        }
    }
    // Update account info with details discovered during commit walking.
    updateAccountInfo();
    closeProgress.end();
    commandProgress.end();
    progress.end();
    reportMessages(newChanges);
}
#method_after
void processCommands(Collection<ReceiveCommand> commands, MultiProgressMonitor progress) {
    Task commandProgress = progress.beginSubTask("refs", UNKNOWN);
    commands = commands.stream().map(c -> wrapReceiveCommand(c, commandProgress)).collect(toList());
    processCommandsUnsafe(commands, progress);
    rejectRemaining(commands, "internal server error");
    // This sends error messages before the 'done' string of the progress monitor is sent.
    // Currently, the test framework relies on this ordering to understand if pushes completed
    // successfully.
    sendErrorMessages();
    commandProgress.end();
    progress.end();
}
#end_block

#method_before
private void insertChangesAndPatchSets(List<CreateRequest> newChanges) {
    ReceiveCommand magicBranchCmd = magicBranch != null ? magicBranch.cmd : null;
    if (magicBranchCmd != null && magicBranchCmd.getResult() != NOT_ATTEMPTED) {
        logWarn(String.format("Skipping change updates on %s because ref update failed: %s %s", project.getName(), magicBranchCmd.getResult(), Strings.nullToEmpty(magicBranchCmd.getMessage())));
        return;
    }
    try (BatchUpdate bu = batchUpdateFactory.create(db, project.getNameKey(), user.materializedCopy(), TimeUtil.nowTs());
        ObjectInserter ins = repo.newObjectInserter();
        ObjectReader reader = ins.newReader();
        RevWalk rw = new RevWalk(reader)) {
        bu.setRepository(repo, rw, ins).updateChangesInParallel();
        bu.setRequestId(receiveId);
        bu.setRefLogMessage("push");
        logDebug("Adding %d replace requests", newChanges.size());
        for (ReplaceRequest replace : replaceByChange.values()) {
            replace.addOps(bu, replaceProgress);
        }
        logDebug("Adding %d create requests", newChanges.size());
        for (CreateRequest create : newChanges) {
            create.addOps(bu);
        }
        logDebug("Adding %d group update requests", newChanges.size());
        updateGroups.forEach(r -> r.addOps(bu));
        logDebug("Adding %d additional ref updates", actualCommands.size());
        actualCommands.forEach(c -> bu.addRepoOnlyOp(new UpdateOneRefOp(c)));
        logDebug("Executing batch");
        try {
            bu.execute();
        } catch (UpdateException e) {
            throw INSERT_EXCEPTION.apply(e);
        }
        if (magicBranchCmd != null) {
            magicBranchCmd.setResult(OK);
        }
        for (ReplaceRequest replace : replaceByChange.values()) {
            String rejectMessage = replace.getRejectMessage();
            if (rejectMessage == null) {
                if (replace.inputCommand.getResult() == NOT_ATTEMPTED) {
                    // Not necessarily the magic branch, so need to set OK on the original value.
                    replace.inputCommand.setResult(OK);
                }
            } else {
                logDebug("Rejecting due to message from ReplaceOp");
                reject(replace.inputCommand, rejectMessage);
            }
        }
    } catch (ResourceConflictException e) {
        addMessage(e.getMessage());
        reject(magicBranchCmd, "conflict");
    } catch (RestApiException | IOException err) {
        logError("Can't insert change/patch set for " + project.getName(), err);
        reject(magicBranchCmd, "internal server error: " + err.getMessage());
    }
    if (magicBranch != null && magicBranch.submit) {
        try {
            submit(newChanges, replaceByChange.values());
        } catch (ResourceConflictException e) {
            addMessage(e.getMessage());
            reject(magicBranchCmd, "conflict");
        } catch (RestApiException | OrmException | UpdateException | IOException | ConfigInvalidException | PermissionBackendException e) {
            logError("Error submitting changes to " + project.getName(), e);
            reject(magicBranchCmd, "error during submit");
        }
    }
}
#method_after
private void insertChangesAndPatchSets(List<CreateRequest> newChanges, Task replaceProgress) {
    ReceiveCommand magicBranchCmd = magicBranch != null ? magicBranch.cmd : null;
    if (magicBranchCmd != null && magicBranchCmd.getResult() != NOT_ATTEMPTED) {
        logger.atWarning().log("Skipping change updates on %s because ref update failed: %s %s", project.getName(), magicBranchCmd.getResult(), Strings.nullToEmpty(magicBranchCmd.getMessage()));
        return;
    }
    try (BatchUpdate bu = batchUpdateFactory.create(db, project.getNameKey(), user.materializedCopy(), TimeUtil.nowTs());
        ObjectInserter ins = repo.newObjectInserter();
        ObjectReader reader = ins.newReader();
        RevWalk rw = new RevWalk(reader)) {
        bu.setRepository(repo, rw, ins).updateChangesInParallel();
        bu.setRefLogMessage("push");
        logger.atFine().log("Adding %d replace requests", newChanges.size());
        for (ReplaceRequest replace : replaceByChange.values()) {
            replace.addOps(bu, replaceProgress);
        }
        logger.atFine().log("Adding %d create requests", newChanges.size());
        for (CreateRequest create : newChanges) {
            create.addOps(bu);
        }
        logger.atFine().log("Adding %d group update requests", newChanges.size());
        updateGroups.forEach(r -> r.addOps(bu));
        logger.atFine().log("Executing batch");
        try {
            bu.execute();
        } catch (UpdateException e) {
            throw INSERT_EXCEPTION.apply(e);
        }
        replaceByChange.values().stream().forEach(req -> resultChangeIds.add(Key.REPLACED, req.ontoChange));
        newChanges.stream().forEach(req -> resultChangeIds.add(Key.CREATED, req.changeId));
        if (magicBranchCmd != null) {
            magicBranchCmd.setResult(OK);
        }
        for (ReplaceRequest replace : replaceByChange.values()) {
            String rejectMessage = replace.getRejectMessage();
            if (rejectMessage == null) {
                if (replace.inputCommand.getResult() == NOT_ATTEMPTED) {
                    // Not necessarily the magic branch, so need to set OK on the original value.
                    replace.inputCommand.setResult(OK);
                }
            } else {
                logger.atFine().log("Rejecting due to message from ReplaceOp");
                reject(replace.inputCommand, rejectMessage);
            }
        }
    } catch (ResourceConflictException e) {
        addError(e.getMessage());
        reject(magicBranchCmd, "conflict");
    } catch (BadRequestException | UnprocessableEntityException e) {
        logger.atFine().withCause(e).log("Rejecting due to client error");
        reject(magicBranchCmd, e.getMessage());
    } catch (RestApiException | IOException e) {
        logger.atSevere().withCause(e).log("Can't insert change/patch set for %s", project.getName());
        reject(magicBranchCmd, "internal server error: " + e.getMessage());
    }
    if (magicBranch != null && magicBranch.submit) {
        try {
            submit(newChanges, replaceByChange.values());
        } catch (ResourceConflictException e) {
            addError(e.getMessage());
            reject(magicBranchCmd, "conflict");
        } catch (RestApiException | OrmException | UpdateException | IOException | ConfigInvalidException | PermissionBackendException e) {
            logger.atSevere().withCause(e).log("Error submitting changes to %s", project.getName());
            reject(magicBranchCmd, "error during submit");
        }
    }
}
#end_block

#method_before
private String buildError(String error, List<String> branches) {
    StringBuilder sb = new StringBuilder();
    if (branches.size() == 1) {
        sb.append("Branch ").append(branches.get(0)).append(":\n");
        sb.append(error);
        return sb.toString();
    }
    sb.append("Branches");
    String delim = " ";
    for (String branch : branches) {
        sb.append(delim).append(branch);
        delim = ", ";
    }
    return sb.append(":\n").append(error).toString();
}
#method_after
private String buildError(String error, List<String> branches) {
    StringBuilder sb = new StringBuilder();
    if (branches.size() == 1) {
        sb.append("branch ").append(branches.get(0)).append(":\n");
        sb.append(error);
        return sb.toString();
    }
    sb.append("branches ").append(Joiner.on(", ").join(branches));
    return sb.append(":\n").append(error).toString();
}
#end_block

#method_before
private void parsePushOptions() {
    List<String> optionList = receivePack.getPushOptions();
    if (optionList != null) {
        for (String option : optionList) {
            int e = option.indexOf('=');
            if (e > 0) {
                pushOptions.put(option.substring(0, e), option.substring(e + 1));
            } else {
                pushOptions.put(option, "");
            }
        }
    }
    List<String> noteDbValues = pushOptions.get("notedb");
    if (!noteDbValues.isEmpty()) {
        // These semantics for duplicates/errors are somewhat arbitrary and may not match e.g. the
        // CommandLineParser behavior used by MagicBranchInput.
        String value = noteDbValues.get(noteDbValues.size() - 1);
        noteDbPushOption = NoteDbPushOption.parse(value);
        if (!noteDbPushOption.isPresent()) {
            addError("Invalid value in -o " + NoteDbPushOption.OPTION_NAME + "=" + value);
        }
    } else {
        noteDbPushOption = Optional.of(NoteDbPushOption.DISALLOW);
    }
}
#method_after
private void parsePushOptions() {
    List<String> optionList = receivePack.getPushOptions();
    if (optionList != null) {
        for (String option : optionList) {
            int e = option.indexOf('=');
            if (e > 0) {
                pushOptions.put(option.substring(0, e), option.substring(e + 1));
            } else {
                pushOptions.put(option, "");
            }
        }
    }
    List<String> noteDbValues = pushOptions.get("notedb");
    if (!noteDbValues.isEmpty()) {
        // These semantics for duplicates/errors are somewhat arbitrary and may not match e.g. the
        // CmdLineParser behavior used by MagicBranchInput.
        String value = noteDbValues.get(noteDbValues.size() - 1);
        noteDbPushOption = NoteDbPushOption.parse(value);
        if (!noteDbPushOption.isPresent()) {
            addError("Invalid value in -o " + NoteDbPushOption.OPTION_NAME + "=" + value);
        }
    } else {
        noteDbPushOption = Optional.of(NoteDbPushOption.DISALLOW);
    }
    List<String> traceValues = pushOptions.get("trace");
    if (!traceValues.isEmpty()) {
        String value = traceValues.get(traceValues.size() - 1);
        tracePushOption = Optional.of(value);
    } else {
        tracePushOption = Optional.empty();
    }
}
#end_block

#method_before
private void parseCreate(ReceiveCommand cmd) throws PermissionBackendException, NoSuchProjectException, IOException {
    RevObject obj;
    try {
        obj = receivePack.getRevWalk().parseAny(cmd.getNewId());
    } catch (IOException err) {
        logError("Invalid object " + cmd.getNewId().name() + " for " + cmd.getRefName() + " creation", err);
        reject(cmd, "invalid object");
        return;
    }
    logDebug("Creating %s", cmd);
    if (isHead(cmd) && !isCommit(cmd)) {
        return;
    }
    Branch.NameKey branch = new Branch.NameKey(project.getName(), cmd.getRefName());
    try {
        // Must pass explicit user instead of injecting a provider into CreateRefControl, since
        // Provider<CurrentUser> within ReceiveCommits will always return anonymous.
        createRefControl.checkCreateRef(Providers.of(user), receivePack.getRepository(), branch, obj);
    } catch (AuthException denied) {
        rejectProhibited(cmd, denied);
        return;
    } catch (ResourceConflictException denied) {
        reject(cmd, "prohibited by Gerrit: " + denied.getMessage());
        return;
    }
    if (!validRefOperation(cmd)) {
        // validRefOperation sets messages, so no need to provide more feedback.
        return;
    }
    validateNewCommits(new Branch.NameKey(project.getNameKey(), cmd.getRefName()), cmd);
    actualCommands.add(cmd);
}
#method_after
private void parseCreate(ReceiveCommand cmd) throws PermissionBackendException, NoSuchProjectException, IOException {
    RevObject obj;
    try {
        obj = receivePack.getRevWalk().parseAny(cmd.getNewId());
    } catch (IOException err) {
        logger.atSevere().withCause(err).log("Invalid object %s for %s creation", cmd.getNewId().name(), cmd.getRefName());
        reject(cmd, "invalid object");
        return;
    }
    logger.atFine().log("Creating %s", cmd);
    if (isHead(cmd) && !isCommit(cmd)) {
        return;
    }
    Branch.NameKey branch = new Branch.NameKey(project.getName(), cmd.getRefName());
    try {
        // Must pass explicit user instead of injecting a provider into CreateRefControl, since
        // Provider<CurrentUser> within ReceiveCommits will always return anonymous.
        createRefControl.checkCreateRef(Providers.of(user), receivePack.getRepository(), branch, obj);
    } catch (AuthException denied) {
        rejectProhibited(cmd, denied);
        return;
    } catch (ResourceConflictException denied) {
        reject(cmd, "prohibited by Gerrit: " + denied.getMessage());
        return;
    }
    if (validRefOperation(cmd)) {
        validateRegularPushCommits(new Branch.NameKey(project.getNameKey(), cmd.getRefName()), cmd);
    }
}
#end_block

#method_before
private void parseUpdate(ReceiveCommand cmd) throws PermissionBackendException {
    logDebug("Updating %s", cmd);
    Optional<AuthException> err = checkRefPermission(cmd, RefPermission.UPDATE);
    if (!err.isPresent()) {
        if (isHead(cmd) && !isCommit(cmd)) {
            return;
        }
        if (!validRefOperation(cmd)) {
            return;
        }
        validateNewCommits(new Branch.NameKey(project.getNameKey(), cmd.getRefName()), cmd);
        actualCommands.add(cmd);
    } else {
        rejectProhibited(cmd, err.get());
    }
}
#method_after
private void parseUpdate(ReceiveCommand cmd) throws PermissionBackendException {
    logger.atFine().log("Updating %s", cmd);
    Optional<AuthException> err = checkRefPermission(cmd, RefPermission.UPDATE);
    if (!err.isPresent()) {
        if (isHead(cmd) && !isCommit(cmd)) {
            reject(cmd, "head must point to commit");
            return;
        }
        if (validRefOperation(cmd)) {
            validateRegularPushCommits(new Branch.NameKey(project.getNameKey(), cmd.getRefName()), cmd);
        }
    } else {
        rejectProhibited(cmd, err.get());
    }
}
#end_block

#method_before
private boolean isCommit(ReceiveCommand cmd) {
    RevObject obj;
    try {
        obj = receivePack.getRevWalk().parseAny(cmd.getNewId());
    } catch (IOException err) {
        logError("Invalid object " + cmd.getNewId().name() + " for " + cmd.getRefName(), err);
        reject(cmd, "invalid object");
        return false;
    }
    if (obj instanceof RevCommit) {
        return true;
    }
    reject(cmd, "not a commit");
    return false;
}
#method_after
private boolean isCommit(ReceiveCommand cmd) {
    RevObject obj;
    try {
        obj = receivePack.getRevWalk().parseAny(cmd.getNewId());
    } catch (IOException err) {
        logger.atSevere().withCause(err).log("Invalid object %s for %s", cmd.getNewId().name(), cmd.getRefName());
        reject(cmd, "invalid object");
        return false;
    }
    if (obj instanceof RevCommit) {
        return true;
    }
    reject(cmd, "not a commit");
    return false;
}
#end_block

#method_before
private void parseDelete(ReceiveCommand cmd) throws PermissionBackendException {
    logDebug("Deleting %s", cmd);
    if (cmd.getRefName().startsWith(REFS_CHANGES)) {
        errors.put(CANNOT_DELETE_CHANGES, cmd.getRefName());
        reject(cmd, "cannot delete changes");
    } else if (isConfigRef(cmd.getRefName())) {
        errors.put(CANNOT_DELETE_CONFIG, cmd.getRefName());
        reject(cmd, "cannot delete project configuration");
    }
    Optional<AuthException> err = checkRefPermission(cmd, RefPermission.DELETE);
    if (!err.isPresent()) {
        if (!validRefOperation(cmd)) {
            return;
        }
        actualCommands.add(cmd);
    } else {
        rejectProhibited(cmd, err.get());
    }
}
#method_after
private void parseDelete(ReceiveCommand cmd) throws PermissionBackendException {
    logger.atFine().log("Deleting %s", cmd);
    if (cmd.getRefName().startsWith(REFS_CHANGES)) {
        errors.put(CANNOT_DELETE_CHANGES, cmd.getRefName());
        reject(cmd, "cannot delete changes");
    } else if (isConfigRef(cmd.getRefName())) {
        errors.put(CANNOT_DELETE_CONFIG, cmd.getRefName());
        reject(cmd, "cannot delete project configuration");
    }
    Optional<AuthException> err = checkRefPermission(cmd, RefPermission.DELETE);
    if (!err.isPresent()) {
        validRefOperation(cmd);
    } else {
        rejectProhibited(cmd, err.get());
    }
}
#end_block

#method_before
private void parseRewind(ReceiveCommand cmd) throws PermissionBackendException {
    RevCommit newObject;
    try {
        newObject = receivePack.getRevWalk().parseCommit(cmd.getNewId());
    } catch (IncorrectObjectTypeException notCommit) {
        newObject = null;
    } catch (IOException err) {
        logError("Invalid object " + cmd.getNewId().name() + " for " + cmd.getRefName() + " forced update", err);
        reject(cmd, "invalid object");
        return;
    }
    logDebug("Rewinding %s", cmd);
    if (newObject != null) {
        validateNewCommits(new Branch.NameKey(project.getNameKey(), cmd.getRefName()), cmd);
        if (cmd.getResult() != NOT_ATTEMPTED) {
            return;
        }
    }
    Optional<AuthException> err = checkRefPermission(cmd, RefPermission.FORCE_UPDATE);
    if (!err.isPresent()) {
        if (!validRefOperation(cmd)) {
            return;
        }
        actualCommands.add(cmd);
    } else {
        rejectProhibited(cmd, err.get());
    }
}
#method_after
private void parseRewind(ReceiveCommand cmd) throws PermissionBackendException {
    RevCommit newObject;
    try {
        newObject = receivePack.getRevWalk().parseCommit(cmd.getNewId());
    } catch (IncorrectObjectTypeException notCommit) {
        newObject = null;
    } catch (IOException err) {
        logger.atSevere().withCause(err).log("Invalid object %s for %s forced update", cmd.getNewId().name(), cmd.getRefName());
        reject(cmd, "invalid object");
        return;
    }
    logger.atFine().log("Rewinding %s", cmd);
    if (newObject != null) {
        validateRegularPushCommits(new Branch.NameKey(project.getNameKey(), cmd.getRefName()), cmd);
        if (cmd.getResult() != NOT_ATTEMPTED) {
            return;
        }
    }
    Optional<AuthException> err = checkRefPermission(cmd, RefPermission.FORCE_UPDATE);
    if (!err.isPresent()) {
        validRefOperation(cmd);
    } else {
        rejectProhibited(cmd, err.get());
    }
}
#end_block

#method_before
@Option(name = "--reviewer", aliases = { "-r" }, metaVar = "EMAIL", usage = "add reviewer to changes")
void reviewer(Account.Id id) {
    reviewer.add(id);
}
#method_after
@Option(name = "--reviewer", aliases = { "-r" }, metaVar = "REVIEWER", usage = "add reviewer to changes")
void reviewer(String str) {
    reviewer.add(str);
}
#end_block

#method_before
@Option(name = "--cc", metaVar = "EMAIL", usage = "notify user by CC")
void cc(Account.Id id) {
    cc.add(id);
}
#method_after
@Option(name = "--cc", metaVar = "CC", usage = "add CC to changes")
void cc(String str) {
    cc.add(str);
}
#end_block

#method_before
ListMultimap<RecipientType, Account.Id> getAccountsToNotify() {
    ListMultimap<RecipientType, Account.Id> accountsToNotify = MultimapBuilder.hashKeys().arrayListValues().build();
    accountsToNotify.putAll(RecipientType.TO, tos);
    accountsToNotify.putAll(RecipientType.CC, ccs);
    accountsToNotify.putAll(RecipientType.BCC, bccs);
    return accountsToNotify;
}
#method_after
ListMultimap<RecipientType, Account.Id> getAccountsToNotify() {
    ListMultimap<RecipientType, Account.Id> accountsToNotify = MultimapBuilder.hashKeys().arrayListValues().build();
    accountsToNotify.putAll(RecipientType.TO, notifyTo);
    accountsToNotify.putAll(RecipientType.CC, notifyCc);
    accountsToNotify.putAll(RecipientType.BCC, notifyBcc);
    return accountsToNotify;
}
#end_block

#method_before
String parse(Repository repo, Set<String> refs, ListMultimap<String, String> pushOptions) throws CmdLineException {
    String ref = RefNames.fullName(MagicBranch.getDestBranchName(cmd.getRefName()));
    ListMultimap<String, String> options = LinkedListMultimap.create(pushOptions);
    // Process and lop off the "%OPTION" suffix.
    int optionStart = ref.indexOf('%');
    if (0 < optionStart) {
        for (String s : COMMAS.split(ref.substring(optionStart + 1))) {
            int e = s.indexOf('=');
            if (0 < e) {
                options.put(s.substring(0, e), s.substring(e + 1));
            } else {
                options.put(s, "");
            }
        }
        ref = ref.substring(0, optionStart);
    }
    if (!options.isEmpty()) {
        cmdLineParser.parseOptionMap(options);
    }
    // We accept refs/for/BRANCHNAME/TOPIC. Since we don't know
    // for sure where the branch ends and the topic starts, look
    // backward for a split that works. This behavior has not been
    // documented and should probably be deprecated.
    String head = readHEAD(repo);
    int split = ref.length();
    for (; ; ) {
        String name = ref.substring(0, split);
        if (refs.contains(name) || name.equals(head)) {
            break;
        }
        split = name.lastIndexOf('/', split - 1);
        if (split <= Constants.R_REFS.length()) {
            return ref;
        }
    }
    if (split < ref.length()) {
        topic = Strings.emptyToNull(ref.substring(split + 1));
    }
    return ref.substring(0, split);
}
#method_after
String parse(Repository repo, Set<String> refs, ListMultimap<String, String> pushOptions) throws CmdLineException {
    String ref = RefNames.fullName(MagicBranch.getDestBranchName(cmd.getRefName()));
    ListMultimap<String, String> options = LinkedListMultimap.create(pushOptions);
    // Process and lop off the "%OPTION" suffix.
    int optionStart = ref.indexOf('%');
    if (0 < optionStart) {
        for (String s : COMMAS.split(ref.substring(optionStart + 1))) {
            int e = s.indexOf('=');
            if (0 < e) {
                options.put(s.substring(0, e), s.substring(e + 1));
            } else {
                options.put(s, "");
            }
        }
        ref = ref.substring(0, optionStart);
    }
    if (!options.isEmpty()) {
        cmdLineParser.parseOptionMap(options);
    }
    // We accept refs/for/BRANCHNAME/TOPIC. Since we don't know
    // for sure where the branch ends and the topic starts, look
    // backward for a split that works. This behavior is deprecated.
    String head = readHEAD(repo);
    int split = ref.length();
    for (; ; ) {
        String name = ref.substring(0, split);
        if (refs.contains(name) || name.equals(head)) {
            break;
        }
        split = name.lastIndexOf('/', split - 1);
        if (split <= Constants.R_REFS.length()) {
            return ref;
        }
    }
    if (split < ref.length()) {
        topic = Strings.emptyToNull(ref.substring(split + 1));
        deprecatedTopicSeen = true;
    }
    return ref.substring(0, split);
}
#end_block

#method_before
private void parseMagicBranch(ReceiveCommand cmd) throws PermissionBackendException {
    // Permit exactly one new change request per push.
    if (magicBranch != null) {
        reject(cmd, "duplicate request");
        return;
    }
    logDebug("Found magic branch %s", cmd.getRefName());
    magicBranch = new MagicBranchInput(user, cmd, labelTypes, notesMigration);
    magicBranch.reviewer.addAll(extraReviewers.get(ReviewerStateInternal.REVIEWER));
    magicBranch.cc.addAll(extraReviewers.get(ReviewerStateInternal.CC));
    String ref;
    magicBranch.cmdLineParser = optionParserFactory.create(magicBranch);
    try {
        ref = magicBranch.parse(repo, receivePack.getAdvertisedRefs().keySet(), pushOptions);
    } catch (CmdLineException e) {
        if (!magicBranch.cmdLineParser.wasHelpRequestedByOption()) {
            logDebug("Invalid branch syntax");
            reject(cmd, e.getMessage());
            return;
        }
        // never happens
        ref = null;
    }
    if (magicBranch.topic != null && magicBranch.topic.length() > ChangeUtil.TOPIC_MAX_LENGTH) {
        reject(cmd, String.format("topic length exceeds the limit (%d)", ChangeUtil.TOPIC_MAX_LENGTH));
    }
    if (magicBranch.cmdLineParser.wasHelpRequestedByOption()) {
        StringWriter w = new StringWriter();
        w.write("\nHelp for refs/for/branch:\n\n");
        magicBranch.cmdLineParser.printUsage(w, null);
        addMessage(w.toString());
        reject(cmd, "see help");
        return;
    }
    if (projectState.isAllUsers() && RefNames.REFS_USERS_SELF.equals(ref)) {
        logDebug("Handling %s", RefNames.REFS_USERS_SELF);
        ref = RefNames.refsUsers(user.getAccountId());
    }
    if (!receivePack.getAdvertisedRefs().containsKey(ref) && !ref.equals(readHEAD(repo)) && !ref.equals(RefNames.REFS_CONFIG)) {
        logDebug("Ref %s not found", ref);
        if (ref.startsWith(Constants.R_HEADS)) {
            String n = ref.substring(Constants.R_HEADS.length());
            reject(cmd, "branch " + n + " not found");
        } else {
            reject(cmd, ref + " not found");
        }
        return;
    }
    magicBranch.dest = new Branch.NameKey(project.getNameKey(), ref);
    magicBranch.perm = permissions.ref(ref);
    Optional<AuthException> err = checkRefPermission(magicBranch.perm, RefPermission.CREATE_CHANGE);
    if (err.isPresent()) {
        rejectProhibited(cmd, err.get());
        return;
    }
    if (!projectState.statePermitsWrite()) {
        reject(cmd, "project state does not permit write");
        return;
    }
    // after repo-tool supports private and work-in-progress changes.
    if (magicBranch.draft && !receiveConfig.allowDrafts) {
        errors.put(ReceiveError.CODE_REVIEW.get(), ref);
        reject(cmd, "draft workflow is disabled");
        return;
    }
    if (magicBranch.isPrivate && magicBranch.removePrivate) {
        reject(cmd, "the options 'private' and 'remove-private' are mutually exclusive");
        return;
    }
    boolean privateByDefault = projectCache.get(project.getNameKey()).is(BooleanProjectConfig.PRIVATE_BY_DEFAULT);
    setChangeAsPrivate = magicBranch.draft || magicBranch.isPrivate || (privateByDefault && !magicBranch.removePrivate);
    if (receiveConfig.disablePrivateChanges && setChangeAsPrivate) {
        reject(cmd, "private changes are disabled");
        return;
    }
    if (magicBranch.workInProgress && magicBranch.ready) {
        reject(cmd, "the options 'wip' and 'ready' are mutually exclusive");
        return;
    }
    if (magicBranch.publishComments && magicBranch.noPublishComments) {
        reject(cmd, "the options 'publish-comments' and 'no-publish-comments' are mutually exclusive");
        return;
    }
    if (magicBranch.submit) {
        err = checkRefPermission(magicBranch.perm, RefPermission.UPDATE_BY_SUBMIT);
        if (err.isPresent()) {
            rejectProhibited(cmd, err.get());
            return;
        }
    }
    RevWalk walk = receivePack.getRevWalk();
    RevCommit tip;
    try {
        tip = walk.parseCommit(magicBranch.cmd.getNewId());
        logDebug("Tip of push: %s", tip.name());
    } catch (IOException ex) {
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", ex);
        return;
    }
    String destBranch = magicBranch.dest.get();
    try {
        if (magicBranch.merged) {
            if (magicBranch.base != null) {
                reject(cmd, "cannot use merged with base");
                return;
            }
            RevCommit branchTip = readBranchTip(cmd, magicBranch.dest);
            if (branchTip == null) {
                // readBranchTip already rejected cmd.
                return;
            }
            if (!walk.isMergedInto(tip, branchTip)) {
                reject(cmd, "not merged into branch");
                return;
            }
        }
        // if %base or %merged was specified, ignore newChangeForAllNotInTarget.
        if (tip.getParentCount() > 1 || magicBranch.base != null || magicBranch.merged || tip.getParentCount() == 0) {
            logDebug("Forcing newChangeForAllNotInTarget = false");
            newChangeForAllNotInTarget = false;
        }
        if (magicBranch.base != null) {
            logDebug("Handling %base: %s", magicBranch.base);
            magicBranch.baseCommit = Lists.newArrayListWithCapacity(magicBranch.base.size());
            for (ObjectId id : magicBranch.base) {
                try {
                    magicBranch.baseCommit.add(walk.parseCommit(id));
                } catch (IncorrectObjectTypeException notCommit) {
                    reject(cmd, "base must be a commit");
                    return;
                } catch (MissingObjectException e) {
                    reject(cmd, "base not found");
                    return;
                } catch (IOException e) {
                    logWarn(String.format("Project %s cannot read %s", project.getName(), id.name()), e);
                    reject(cmd, "internal server error");
                    return;
                }
            }
        } else if (newChangeForAllNotInTarget) {
            RevCommit branchTip = readBranchTip(cmd, magicBranch.dest);
            if (branchTip == null) {
                // readBranchTip already rejected cmd.
                return;
            }
            magicBranch.baseCommit = Collections.singletonList(branchTip);
            logDebug("Set baseCommit = %s", magicBranch.baseCommit.get(0).name());
        }
    } catch (IOException ex) {
        logWarn(String.format("Error walking to %s in project %s", destBranch, project.getName()), ex);
        reject(cmd, "internal server error");
        return;
    }
    // 
    try {
        Ref targetRef = receivePack.getAdvertisedRefs().get(magicBranch.dest.get());
        if (targetRef == null || targetRef.getObjectId() == null) {
            // The destination branch does not yet exist. Assume the
            // history being sent for review will start it and thus
            // is "connected" to the branch.
            logDebug("Branch is unborn");
            return;
        }
        RevCommit h = walk.parseCommit(targetRef.getObjectId());
        logDebug("Current branch tip: %s", h.name());
        RevFilter oldRevFilter = walk.getRevFilter();
        try {
            walk.reset();
            walk.setRevFilter(RevFilter.MERGE_BASE);
            walk.markStart(tip);
            walk.markStart(h);
            if (walk.next() == null) {
                reject(magicBranch.cmd, "no common ancestry");
            }
        } finally {
            walk.reset();
            walk.setRevFilter(oldRevFilter);
        }
    } catch (IOException e) {
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", e);
    }
}
#method_after
private void parseMagicBranch(ReceiveCommand cmd) throws PermissionBackendException {
    logger.atFine().log("Found magic branch %s", cmd.getRefName());
    MagicBranchInput magicBranch = new MagicBranchInput(user, cmd, labelTypes, notesMigration);
    String ref;
    magicBranch.cmdLineParser = optionParserFactory.create(magicBranch);
    try {
        ref = magicBranch.parse(repo, receivePack.getAdvertisedRefs().keySet(), pushOptions);
    } catch (CmdLineException e) {
        if (!magicBranch.cmdLineParser.wasHelpRequestedByOption()) {
            logger.atFine().log("Invalid branch syntax");
            reject(cmd, e.getMessage());
            return;
        }
        // never happens
        ref = null;
    }
    if (magicBranch.topic != null && magicBranch.topic.length() > ChangeUtil.TOPIC_MAX_LENGTH) {
        reject(cmd, String.format("topic length exceeds the limit (%d)", ChangeUtil.TOPIC_MAX_LENGTH));
    }
    if (magicBranch.cmdLineParser.wasHelpRequestedByOption()) {
        StringWriter w = new StringWriter();
        w.write("\nHelp for refs/for/branch:\n\n");
        magicBranch.cmdLineParser.printUsage(w, null);
        addMessage(w.toString());
        reject(cmd, "see help");
        return;
    }
    if (projectState.isAllUsers() && RefNames.REFS_USERS_SELF.equals(ref)) {
        logger.atFine().log("Handling %s", RefNames.REFS_USERS_SELF);
        ref = RefNames.refsUsers(user.getAccountId());
    }
    // configuration.
    if (!receivePack.getAdvertisedRefs().containsKey(ref) && !ref.equals(readHEAD(repo)) && !ref.equals(RefNames.REFS_CONFIG)) {
        logger.atFine().log("Ref %s not found", ref);
        if (ref.startsWith(Constants.R_HEADS)) {
            String n = ref.substring(Constants.R_HEADS.length());
            reject(cmd, "branch " + n + " not found");
        } else {
            reject(cmd, ref + " not found");
        }
        return;
    }
    magicBranch.dest = new Branch.NameKey(project.getNameKey(), ref);
    magicBranch.perm = permissions.ref(ref);
    Optional<AuthException> err = checkRefPermission(magicBranch.perm, RefPermission.CREATE_CHANGE);
    if (err.isPresent()) {
        rejectProhibited(cmd, err.get());
        return;
    }
    // after repo-tool supports private and work-in-progress changes.
    if (magicBranch.draft && !receiveConfig.allowDrafts) {
        errors.put(CODE_REVIEW_ERROR, ref);
        reject(cmd, "draft workflow is disabled");
        return;
    }
    if (magicBranch.isPrivate && magicBranch.removePrivate) {
        reject(cmd, "the options 'private' and 'remove-private' are mutually exclusive");
        return;
    }
    boolean privateByDefault = projectCache.get(project.getNameKey()).is(BooleanProjectConfig.PRIVATE_BY_DEFAULT);
    setChangeAsPrivate = magicBranch.draft || magicBranch.isPrivate || (privateByDefault && !magicBranch.removePrivate);
    if (receiveConfig.disablePrivateChanges && setChangeAsPrivate) {
        reject(cmd, "private changes are disabled");
        return;
    }
    if (magicBranch.workInProgress && magicBranch.ready) {
        reject(cmd, "the options 'wip' and 'ready' are mutually exclusive");
        return;
    }
    if (magicBranch.publishComments && magicBranch.noPublishComments) {
        reject(cmd, "the options 'publish-comments' and 'no-publish-comments' are mutually exclusive");
        return;
    }
    if (magicBranch.submit) {
        err = checkRefPermission(magicBranch.perm, RefPermission.UPDATE_BY_SUBMIT);
        if (err.isPresent()) {
            rejectProhibited(cmd, err.get());
            return;
        }
    }
    RevWalk walk = receivePack.getRevWalk();
    RevCommit tip;
    try {
        tip = walk.parseCommit(magicBranch.cmd.getNewId());
        logger.atFine().log("Tip of push: %s", tip.name());
    } catch (IOException ex) {
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logger.atSevere().withCause(ex).log("Invalid pack upload; one or more objects weren't sent");
        return;
    }
    String destBranch = magicBranch.dest.get();
    try {
        if (magicBranch.merged) {
            if (magicBranch.base != null) {
                reject(cmd, "cannot use merged with base");
                return;
            }
            RevCommit branchTip = readBranchTip(magicBranch.dest);
            if (branchTip == null) {
                reject(cmd, magicBranch.dest.get() + " not found");
                return;
            }
            if (!walk.isMergedInto(tip, branchTip)) {
                reject(cmd, "not merged into branch");
                return;
            }
        }
        // if %base or %merged was specified, ignore newChangeForAllNotInTarget.
        if (tip.getParentCount() > 1 || magicBranch.base != null || magicBranch.merged || tip.getParentCount() == 0) {
            logger.atFine().log("Forcing newChangeForAllNotInTarget = false");
            newChangeForAllNotInTarget = false;
        }
        if (magicBranch.base != null) {
            logger.atFine().log("Handling %%base: %s", magicBranch.base);
            magicBranch.baseCommit = Lists.newArrayListWithCapacity(magicBranch.base.size());
            for (ObjectId id : magicBranch.base) {
                try {
                    magicBranch.baseCommit.add(walk.parseCommit(id));
                } catch (IncorrectObjectTypeException notCommit) {
                    reject(cmd, "base must be a commit");
                    return;
                } catch (MissingObjectException e) {
                    reject(cmd, "base not found");
                    return;
                } catch (IOException e) {
                    logger.atWarning().withCause(e).log("Project %s cannot read %s", project.getName(), id.name());
                    reject(cmd, "internal server error");
                    return;
                }
            }
        } else if (newChangeForAllNotInTarget) {
            RevCommit branchTip = readBranchTip(magicBranch.dest);
            if (branchTip != null) {
                magicBranch.baseCommit = Collections.singletonList(branchTip);
                logger.atFine().log("Set baseCommit = %s", magicBranch.baseCommit.get(0).name());
            } else {
                // repository and to review an initial project configuration.
                if (!ref.equals(readHEAD(repo)) && !ref.equals(RefNames.REFS_CONFIG)) {
                    reject(cmd, magicBranch.dest.get() + " not found");
                    return;
                }
            }
        }
    } catch (IOException ex) {
        logger.atWarning().withCause(ex).log("Error walking to %s in project %s", destBranch, project.getName());
        reject(cmd, "internal server error");
        return;
    }
    if (magicBranch.deprecatedTopicSeen) {
        messages.add(new ValidationMessage("WARNING: deprecated topic syntax. Use %topic=TOPIC instead", false));
        logger.atInfo().log("deprecated topic push seen for project %s", project.getName());
    }
    if (validateConnected(magicBranch.cmd, magicBranch.dest, tip)) {
        this.magicBranch = magicBranch;
    }
}
#end_block

#method_before
private static String readHEAD(Repository repo) {
    try {
        return repo.getFullBranch();
    } catch (IOException e) {
        logger.atSevere().withCause(e).log("Cannot read HEAD symref");
        return null;
    }
}
#method_after
private static String readHEAD(Repository repo) {
    try {
        String head = repo.getFullBranch();
        logger.atFine().log("HEAD = %s", head);
        return head;
    } catch (IOException e) {
        logger.atSevere().withCause(e).log("Cannot read HEAD symref");
        return null;
    }
}
#end_block

#method_before
private RevCommit readBranchTip(ReceiveCommand cmd, Branch.NameKey branch) throws IOException {
    Ref r = allRefs().get(branch.get());
    if (r == null) {
        reject(cmd, branch.get() + " not found");
        return null;
    }
    return receivePack.getRevWalk().parseCommit(r.getObjectId());
}
#method_after
private RevCommit readBranchTip(Branch.NameKey branch) throws IOException {
    Ref r = allRefs().get(branch.get());
    if (r == null) {
        return null;
    }
    return receivePack.getRevWalk().parseCommit(r.getObjectId());
}
#end_block

#method_before
private void parseReplaceCommand(ReceiveCommand cmd, Change.Id changeId) {
    logDebug("Parsing replace command");
    if (cmd.getType() != ReceiveCommand.Type.CREATE) {
        reject(cmd, "invalid usage");
        return;
    }
    RevCommit newCommit;
    try {
        newCommit = receivePack.getRevWalk().parseCommit(cmd.getNewId());
        logDebug("Replacing with %s", newCommit);
    } catch (IOException e) {
        logError("Cannot parse " + cmd.getNewId().name() + " as commit", e);
        reject(cmd, "invalid commit");
        return;
    }
    Change changeEnt;
    try {
        changeEnt = notesFactory.createChecked(db, project.getNameKey(), changeId).getChange();
    } catch (NoSuchChangeException e) {
        logError("Change not found " + changeId, e);
        reject(cmd, "change " + changeId + " not found");
        return;
    } catch (OrmException e) {
        logError("Cannot lookup existing change " + changeId, e);
        reject(cmd, "database error");
        return;
    }
    if (!project.getNameKey().equals(changeEnt.getProject())) {
        reject(cmd, "change " + changeId + " does not belong to project " + project.getName());
        return;
    }
    logDebug("Replacing change %s", changeEnt.getId());
    requestReplace(cmd, true, changeEnt, newCommit);
}
#method_after
private void parseReplaceCommand(ReceiveCommand cmd, Change.Id changeId) {
    logger.atFine().log("Parsing replace command");
    if (cmd.getType() != ReceiveCommand.Type.CREATE) {
        reject(cmd, "invalid usage");
        return;
    }
    RevCommit newCommit;
    try {
        newCommit = receivePack.getRevWalk().parseCommit(cmd.getNewId());
        logger.atFine().log("Replacing with %s", newCommit);
    } catch (IOException e) {
        logger.atSevere().withCause(e).log("Cannot parse %s as commit", cmd.getNewId().name());
        reject(cmd, "invalid commit");
        return;
    }
    Change changeEnt;
    try {
        changeEnt = notesFactory.createChecked(db, project.getNameKey(), changeId).getChange();
    } catch (NoSuchChangeException e) {
        logger.atSevere().withCause(e).log("Change not found %s", changeId);
        reject(cmd, "change " + changeId + " not found");
        return;
    } catch (OrmException e) {
        logger.atSevere().withCause(e).log("Cannot lookup existing change %s", changeId);
        reject(cmd, "database error");
        return;
    }
    if (!project.getNameKey().equals(changeEnt.getProject())) {
        reject(cmd, "change " + changeId + " does not belong to project " + project.getName());
        return;
    }
    BranchCommitValidator validator = commitValidatorFactory.create(projectState, changeEnt.getDest(), user);
    try {
        if (validator.validCommit(receivePack.getRevWalk().getObjectReader(), cmd, newCommit, false, messages, rejectCommits, changeEnt)) {
            logger.atFine().log("Replacing change %s", changeEnt.getId());
            requestReplace(cmd, true, changeEnt, newCommit);
        }
    } catch (IOException e) {
        reject(cmd, "I/O exception validating commit");
    }
}
#end_block

#method_before
private List<CreateRequest> selectNewAndReplacedChangesFromMagicBranch() {
    logDebug("Finding new and replaced changes");
    List<CreateRequest> newChanges = new ArrayList<>();
    ListMultimap<ObjectId, Ref> existing = changeRefsById();
    GroupCollector groupCollector = GroupCollector.create(changeRefsById(), db, psUtil, notesFactory, project.getNameKey());
    try {
        RevCommit start = setUpWalkForSelectingChanges();
        if (start == null) {
            return Collections.emptyList();
        }
        LinkedHashMap<RevCommit, ChangeLookup> pending = new LinkedHashMap<>();
        Set<Change.Key> newChangeIds = new HashSet<>();
        int maxBatchChanges = receiveConfig.getEffectiveMaxBatchChangesLimit(user);
        int total = 0;
        int alreadyTracked = 0;
        boolean rejectImplicitMerges = start.getParentCount() == 1 && projectCache.get(project.getNameKey()).is(BooleanProjectConfig.REJECT_IMPLICIT_MERGES) && // late.
        !magicBranch.merged;
        Set<RevCommit> mergedParents;
        if (rejectImplicitMerges) {
            mergedParents = new HashSet<>();
        } else {
            mergedParents = null;
        }
        for (; ; ) {
            RevCommit c = receivePack.getRevWalk().next();
            if (c == null) {
                break;
            }
            total++;
            receivePack.getRevWalk().parseBody(c);
            String name = c.name();
            groupCollector.visit(c);
            Collection<Ref> existingRefs = existing.get(c);
            if (rejectImplicitMerges) {
                Collections.addAll(mergedParents, c.getParents());
                mergedParents.remove(c);
            }
            boolean commitAlreadyTracked = !existingRefs.isEmpty();
            if (commitAlreadyTracked) {
                alreadyTracked++;
                // different target branch.
                for (Ref ref : existingRefs) {
                    updateGroups.add(new UpdateGroupsRequest(ref, c));
                }
                if (!(newChangeForAllNotInTarget || magicBranch.base != null)) {
                    continue;
                }
            }
            List<String> idList = c.getFooterLines(CHANGE_ID);
            if (!idList.isEmpty()) {
                pending.put(c, new ChangeLookup(c, new Change.Key(idList.get(idList.size() - 1).trim())));
            } else {
                pending.put(c, new ChangeLookup(c));
            }
            int n = pending.size() + newChanges.size();
            if (maxBatchChanges != 0 && n > maxBatchChanges) {
                logDebug("%d changes exceeds limit of %d", n, maxBatchChanges);
                reject(magicBranch.cmd, "the number of pushed changes in a batch exceeds the max limit " + maxBatchChanges);
                return Collections.emptyList();
            }
            if (commitAlreadyTracked) {
                boolean changeExistsOnDestBranch = false;
                for (ChangeData cd : pending.get(c).destChanges) {
                    if (cd.change().getDest().equals(magicBranch.dest)) {
                        changeExistsOnDestBranch = true;
                        break;
                    }
                }
                if (changeExistsOnDestBranch) {
                    continue;
                }
                logDebug("Creating new change for %s even though it is already tracked", name);
            }
            if (!validCommit(receivePack.getRevWalk(), magicBranch.dest, magicBranch.cmd, c, null)) {
                // Not a change the user can propose? Abort as early as possible.
                logDebug("Aborting early due to invalid commit");
                return Collections.emptyList();
            }
            // Don't allow merges to be uploaded in commit chain via all-not-in-target
            if (newChangeForAllNotInTarget && c.getParentCount() > 1) {
                reject(magicBranch.cmd, "Pushing merges in commit chains with 'all not in target' is not allowed,\n" + "to override please set the base manually");
                logDebug("Rejecting merge commit %s with newChangeForAllNotInTarget", name);
            // TODO(dborowitz): Should we early return here?
            }
            if (idList.isEmpty()) {
                newChanges.add(new CreateRequest(c, magicBranch.dest.get()));
                continue;
            }
        }
        logDebug("Finished initial RevWalk with %d commits total: %d already" + " tracked, %d new changes with no Change-Id, and %d deferred" + " lookups", total, alreadyTracked, newChanges.size(), pending.size());
        if (rejectImplicitMerges) {
            rejectImplicitMerges(mergedParents);
        }
        for (Iterator<ChangeLookup> itr = pending.values().iterator(); itr.hasNext(); ) {
            ChangeLookup p = itr.next();
            if (p.changeKey == null) {
                continue;
            }
            if (newChangeIds.contains(p.changeKey)) {
                logDebug("Multiple commits with Change-Id %s", p.changeKey);
                reject(magicBranch.cmd, SAME_CHANGE_ID_IN_MULTIPLE_CHANGES);
                return Collections.emptyList();
            }
            List<ChangeData> changes = p.destChanges;
            if (changes.size() > 1) {
                logDebug("Multiple changes in branch %s with Change-Id %s: %s", magicBranch.dest, p.changeKey, changes.stream().map(cd -> cd.getId().toString()).collect(joining()));
                // WTF, multiple changes in this branch have the same key?
                // Since the commit is new, the user should recreate it with
                // a different Change-Id. In practice, we should never see
                // this error message as Change-Id should be unique per branch.
                // 
                reject(magicBranch.cmd, p.changeKey.get() + " has duplicates");
                return Collections.emptyList();
            }
            if (changes.size() == 1) {
                // Schedule as a replacement to this one matching change.
                // 
                RevId currentPs = changes.get(0).currentPatchSet().getRevision();
                // If Commit is already current PatchSet of target Change.
                if (p.commit.name().equals(currentPs.get())) {
                    if (pending.size() == 1) {
                        // There are no commits left to check, all commits in pending were already
                        // current PatchSet of the corresponding target changes.
                        reject(magicBranch.cmd, "commit(s) already exists (as current patchset)");
                    } else {
                        // Commit is already current PatchSet.
                        // Remove from pending and try next commit.
                        itr.remove();
                        continue;
                    }
                }
                if (requestReplace(magicBranch.cmd, false, changes.get(0).change(), p.commit)) {
                    continue;
                }
                return Collections.emptyList();
            }
            if (changes.size() == 0) {
                if (!isValidChangeId(p.changeKey.get())) {
                    reject(magicBranch.cmd, "invalid Change-Id");
                    return Collections.emptyList();
                }
                // double check against the existing refs
                if (foundInExistingRef(existing.get(p.commit))) {
                    if (pending.size() == 1) {
                        reject(magicBranch.cmd, "commit(s) already exists (as current patchset)");
                        return Collections.emptyList();
                    }
                    itr.remove();
                    continue;
                }
                newChangeIds.add(p.changeKey);
            }
            newChanges.add(new CreateRequest(p.commit, magicBranch.dest.get()));
        }
        logDebug("Finished deferred lookups with %d updates and %d new changes", replaceByChange.size(), newChanges.size());
    } catch (IOException e) {
        // Should never happen, the core receive process would have
        // identified the missing object earlier before we got control.
        // 
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logError("Invalid pack upload; one or more objects weren't sent", e);
        return Collections.emptyList();
    } catch (OrmException e) {
        logError("Cannot query database to locate prior changes", e);
        reject(magicBranch.cmd, "database error");
        return Collections.emptyList();
    }
    if (newChanges.isEmpty() && replaceByChange.isEmpty()) {
        reject(magicBranch.cmd, "no new changes");
        return Collections.emptyList();
    }
    if (!newChanges.isEmpty() && magicBranch.edit) {
        reject(magicBranch.cmd, "edit is not supported for new changes");
        return newChanges;
    }
    try {
        SortedSetMultimap<ObjectId, String> groups = groupCollector.getGroups();
        List<Integer> newIds = seq.nextChangeIds(newChanges.size());
        for (int i = 0; i < newChanges.size(); i++) {
            CreateRequest create = newChanges.get(i);
            create.setChangeId(newIds.get(i));
            create.groups = ImmutableList.copyOf(groups.get(create.commit));
        }
        for (ReplaceRequest replace : replaceByChange.values()) {
            replace.groups = ImmutableList.copyOf(groups.get(replace.newCommitId));
        }
        for (UpdateGroupsRequest update : updateGroups) {
            update.groups = ImmutableList.copyOf((groups.get(update.commit)));
        }
        logDebug("Finished updating groups from GroupCollector");
    } catch (OrmException e) {
        logError("Error collecting groups for changes", e);
        reject(magicBranch.cmd, "internal server error");
    }
    return newChanges;
}
#method_after
private List<CreateRequest> selectNewAndReplacedChangesFromMagicBranch(Task newProgress) {
    logger.atFine().log("Finding new and replaced changes");
    List<CreateRequest> newChanges = new ArrayList<>();
    ListMultimap<ObjectId, Ref> existing = changeRefsById();
    GroupCollector groupCollector = GroupCollector.create(changeRefsById(), db, psUtil, notesFactory, project.getNameKey());
    BranchCommitValidator validator = commitValidatorFactory.create(projectState, magicBranch.dest, user);
    try {
        RevCommit start = setUpWalkForSelectingChanges();
        if (start == null) {
            return Collections.emptyList();
        }
        LinkedHashMap<RevCommit, ChangeLookup> pending = new LinkedHashMap<>();
        Set<Change.Key> newChangeIds = new HashSet<>();
        int maxBatchChanges = receiveConfig.getEffectiveMaxBatchChangesLimit(user);
        int total = 0;
        int alreadyTracked = 0;
        boolean rejectImplicitMerges = start.getParentCount() == 1 && projectCache.get(project.getNameKey()).is(BooleanProjectConfig.REJECT_IMPLICIT_MERGES) && // late.
        !magicBranch.merged;
        Set<RevCommit> mergedParents;
        if (rejectImplicitMerges) {
            mergedParents = new HashSet<>();
        } else {
            mergedParents = null;
        }
        for (; ; ) {
            RevCommit c = receivePack.getRevWalk().next();
            if (c == null) {
                break;
            }
            total++;
            receivePack.getRevWalk().parseBody(c);
            String name = c.name();
            groupCollector.visit(c);
            Collection<Ref> existingRefs = existing.get(c);
            if (rejectImplicitMerges) {
                Collections.addAll(mergedParents, c.getParents());
                mergedParents.remove(c);
            }
            boolean commitAlreadyTracked = !existingRefs.isEmpty();
            if (commitAlreadyTracked) {
                alreadyTracked++;
                // different target branch.
                for (Ref ref : existingRefs) {
                    updateGroups.add(new UpdateGroupsRequest(ref, c));
                }
                if (!(newChangeForAllNotInTarget || magicBranch.base != null)) {
                    continue;
                }
            }
            List<String> idList = c.getFooterLines(CHANGE_ID);
            if (!idList.isEmpty()) {
                pending.put(c, lookupByChangeKey(c, new Change.Key(idList.get(idList.size() - 1).trim())));
            } else {
                pending.put(c, lookupByCommit(c));
            }
            int n = pending.size() + newChanges.size();
            if (maxBatchChanges != 0 && n > maxBatchChanges) {
                logger.atFine().log("%d changes exceeds limit of %d", n, maxBatchChanges);
                reject(magicBranch.cmd, "the number of pushed changes in a batch exceeds the max limit " + maxBatchChanges);
                return Collections.emptyList();
            }
            if (commitAlreadyTracked) {
                boolean changeExistsOnDestBranch = false;
                for (ChangeData cd : pending.get(c).destChanges) {
                    if (cd.change().getDest().equals(magicBranch.dest)) {
                        changeExistsOnDestBranch = true;
                        break;
                    }
                }
                if (changeExistsOnDestBranch) {
                    continue;
                }
                logger.atFine().log("Creating new change for %s even though it is already tracked", name);
            }
            if (!validator.validCommit(receivePack.getRevWalk().getObjectReader(), magicBranch.cmd, c, magicBranch.merged, messages, rejectCommits, null)) {
                // Not a change the user can propose? Abort as early as possible.
                logger.atFine().log("Aborting early due to invalid commit");
                return Collections.emptyList();
            }
            // Don't allow merges to be uploaded in commit chain via all-not-in-target
            if (newChangeForAllNotInTarget && c.getParentCount() > 1) {
                reject(magicBranch.cmd, "Pushing merges in commit chains with 'all not in target' is not allowed,\n" + "to override please set the base manually");
                logger.atFine().log("Rejecting merge commit %s with newChangeForAllNotInTarget", name);
            // TODO(dborowitz): Should we early return here?
            }
            if (idList.isEmpty()) {
                newChanges.add(new CreateRequest(c, magicBranch.dest.get(), newProgress));
                continue;
            }
        }
        logger.atFine().log("Finished initial RevWalk with %d commits total: %d already" + " tracked, %d new changes with no Change-Id, and %d deferred" + " lookups", total, alreadyTracked, newChanges.size(), pending.size());
        if (rejectImplicitMerges) {
            rejectImplicitMerges(mergedParents);
        }
        for (Iterator<ChangeLookup> itr = pending.values().iterator(); itr.hasNext(); ) {
            ChangeLookup p = itr.next();
            if (p.changeKey == null) {
                continue;
            }
            if (newChangeIds.contains(p.changeKey)) {
                logger.atFine().log("Multiple commits with Change-Id %s", p.changeKey);
                reject(magicBranch.cmd, SAME_CHANGE_ID_IN_MULTIPLE_CHANGES);
                return Collections.emptyList();
            }
            List<ChangeData> changes = p.destChanges;
            if (changes.size() > 1) {
                logger.atFine().log("Multiple changes in branch %s with Change-Id %s: %s", magicBranch.dest, p.changeKey, changes.stream().map(cd -> cd.getId().toString()).collect(joining()));
                // WTF, multiple changes in this branch have the same key?
                // Since the commit is new, the user should recreate it with
                // a different Change-Id. In practice, we should never see
                // this error message as Change-Id should be unique per branch.
                // 
                reject(magicBranch.cmd, p.changeKey.get() + " has duplicates");
                return Collections.emptyList();
            }
            if (changes.size() == 1) {
                // Schedule as a replacement to this one matching change.
                // 
                RevId currentPs = changes.get(0).currentPatchSet().getRevision();
                // If Commit is already current PatchSet of target Change.
                if (p.commit.name().equals(currentPs.get())) {
                    if (pending.size() == 1) {
                        // There are no commits left to check, all commits in pending were already
                        // current PatchSet of the corresponding target changes.
                        reject(magicBranch.cmd, "commit(s) already exists (as current patchset)");
                    } else {
                        // Commit is already current PatchSet.
                        // Remove from pending and try next commit.
                        itr.remove();
                        continue;
                    }
                }
                if (requestReplace(magicBranch.cmd, false, changes.get(0).change(), p.commit)) {
                    continue;
                }
                return Collections.emptyList();
            }
            if (changes.size() == 0) {
                if (!isValidChangeId(p.changeKey.get())) {
                    reject(magicBranch.cmd, "invalid Change-Id");
                    return Collections.emptyList();
                }
                // double check against the existing refs
                if (foundInExistingRef(existing.get(p.commit))) {
                    if (pending.size() == 1) {
                        reject(magicBranch.cmd, "commit(s) already exists (as current patchset)");
                        return Collections.emptyList();
                    }
                    itr.remove();
                    continue;
                }
                newChangeIds.add(p.changeKey);
            }
            newChanges.add(new CreateRequest(p.commit, magicBranch.dest.get(), newProgress));
        }
        logger.atFine().log("Finished deferred lookups with %d updates and %d new changes", replaceByChange.size(), newChanges.size());
    } catch (IOException e) {
        // Should never happen, the core receive process would have
        // identified the missing object earlier before we got control.
        // 
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logger.atSevere().withCause(e).log("Invalid pack upload; one or more objects weren't sent");
        return Collections.emptyList();
    } catch (OrmException e) {
        logger.atSevere().withCause(e).log("Cannot query database to locate prior changes");
        reject(magicBranch.cmd, "database error");
        return Collections.emptyList();
    }
    if (newChanges.isEmpty() && replaceByChange.isEmpty()) {
        reject(magicBranch.cmd, "no new changes");
        return Collections.emptyList();
    }
    if (!newChanges.isEmpty() && magicBranch.edit) {
        reject(magicBranch.cmd, "edit is not supported for new changes");
        return newChanges;
    }
    try {
        SortedSetMultimap<ObjectId, String> groups = groupCollector.getGroups();
        List<Integer> newIds = seq.nextChangeIds(newChanges.size());
        for (int i = 0; i < newChanges.size(); i++) {
            CreateRequest create = newChanges.get(i);
            create.setChangeId(newIds.get(i));
            create.groups = ImmutableList.copyOf(groups.get(create.commit));
        }
        for (ReplaceRequest replace : replaceByChange.values()) {
            replace.groups = ImmutableList.copyOf(groups.get(replace.newCommitId));
        }
        for (UpdateGroupsRequest update : updateGroups) {
            update.groups = ImmutableList.copyOf((groups.get(update.commit)));
        }
        logger.atFine().log("Finished updating groups from GroupCollector");
    } catch (OrmException e) {
        logger.atSevere().withCause(e).log("Error collecting groups for changes");
        reject(magicBranch.cmd, "internal server error");
    }
    return newChanges;
}
#end_block

#method_before
private boolean foundInExistingRef(Collection<Ref> existingRefs) throws OrmException {
    for (Ref ref : existingRefs) {
        ChangeNotes notes = notesFactory.create(db, project.getNameKey(), Change.Id.fromRef(ref.getName()));
        Change change = notes.getChange();
        if (change.getDest().equals(magicBranch.dest)) {
            logDebug("Found change %s from existing refs.", change.getKey());
            // Reindex the change asynchronously, ignoring errors.
            @SuppressWarnings("unused")
            Future<?> possiblyIgnoredError = indexer.indexAsync(project.getNameKey(), change.getId());
            return true;
        }
    }
    return false;
}
#method_after
private boolean foundInExistingRef(Collection<Ref> existingRefs) throws OrmException {
    for (Ref ref : existingRefs) {
        ChangeNotes notes = notesFactory.create(db, project.getNameKey(), Change.Id.fromRef(ref.getName()));
        Change change = notes.getChange();
        if (change.getDest().equals(magicBranch.dest)) {
            logger.atFine().log("Found change %s from existing refs.", change.getKey());
            // Reindex the change asynchronously, ignoring errors.
            @SuppressWarnings("unused")
            Future<?> possiblyIgnoredError = indexer.indexAsync(project.getNameKey(), change.getId());
            return true;
        }
    }
    return false;
}
#end_block

#method_before
private RevCommit setUpWalkForSelectingChanges() throws IOException {
    RevWalk rw = receivePack.getRevWalk();
    RevCommit start = rw.parseCommit(magicBranch.cmd.getNewId());
    rw.reset();
    rw.sort(RevSort.TOPO);
    rw.sort(RevSort.REVERSE, true);
    receivePack.getRevWalk().markStart(start);
    if (magicBranch.baseCommit != null) {
        markExplicitBasesUninteresting();
    } else if (magicBranch.merged) {
        logDebug("Marking parents of merged commit %s uninteresting", start.name());
        for (RevCommit c : start.getParents()) {
            rw.markUninteresting(c);
        }
    } else {
        markHeadsAsUninteresting(rw, magicBranch.dest != null ? magicBranch.dest.get() : null);
    }
    return start;
}
#method_after
private RevCommit setUpWalkForSelectingChanges() throws IOException {
    RevWalk rw = receivePack.getRevWalk();
    RevCommit start = rw.parseCommit(magicBranch.cmd.getNewId());
    rw.reset();
    rw.sort(RevSort.TOPO);
    rw.sort(RevSort.REVERSE, true);
    receivePack.getRevWalk().markStart(start);
    if (magicBranch.baseCommit != null) {
        markExplicitBasesUninteresting();
    } else if (magicBranch.merged) {
        logger.atFine().log("Marking parents of merged commit %s uninteresting", start.name());
        for (RevCommit c : start.getParents()) {
            rw.markUninteresting(c);
        }
    } else {
        markHeadsAsUninteresting(rw, magicBranch.dest != null ? magicBranch.dest.get() : null);
    }
    return start;
}
#end_block

#method_before
private void markExplicitBasesUninteresting() throws IOException {
    logDebug("Marking %d base commits uninteresting", magicBranch.baseCommit.size());
    for (RevCommit c : magicBranch.baseCommit) {
        receivePack.getRevWalk().markUninteresting(c);
    }
    Ref targetRef = allRefs().get(magicBranch.dest.get());
    if (targetRef != null) {
        logDebug("Marking target ref %s (%s) uninteresting", magicBranch.dest.get(), targetRef.getObjectId().name());
        receivePack.getRevWalk().markUninteresting(receivePack.getRevWalk().parseCommit(targetRef.getObjectId()));
    }
}
#method_after
private void markExplicitBasesUninteresting() throws IOException {
    logger.atFine().log("Marking %d base commits uninteresting", magicBranch.baseCommit.size());
    for (RevCommit c : magicBranch.baseCommit) {
        receivePack.getRevWalk().markUninteresting(c);
    }
    Ref targetRef = allRefs().get(magicBranch.dest.get());
    if (targetRef != null) {
        logger.atFine().log("Marking target ref %s (%s) uninteresting", magicBranch.dest.get(), targetRef.getObjectId().name());
        receivePack.getRevWalk().markUninteresting(receivePack.getRevWalk().parseCommit(targetRef.getObjectId()));
    }
}
#end_block

#method_before
private void rejectImplicitMerges(Set<RevCommit> mergedParents) throws IOException {
    if (!mergedParents.isEmpty()) {
        Ref targetRef = allRefs().get(magicBranch.dest.get());
        if (targetRef != null) {
            RevWalk rw = receivePack.getRevWalk();
            RevCommit tip = rw.parseCommit(targetRef.getObjectId());
            boolean containsImplicitMerges = true;
            for (RevCommit p : mergedParents) {
                containsImplicitMerges &= !rw.isMergedInto(p, tip);
            }
            if (containsImplicitMerges) {
                rw.reset();
                for (RevCommit p : mergedParents) {
                    rw.markStart(p);
                }
                rw.markUninteresting(tip);
                RevCommit c;
                while ((c = rw.next()) != null) {
                    rw.parseBody(c);
                    messages.add(new CommitValidationMessage("ERROR: Implicit Merge of " + c.abbreviate(7).name() + " " + c.getShortMessage(), false));
                }
                reject(magicBranch.cmd, "implicit merges detected");
            }
        }
    }
}
#method_after
private void rejectImplicitMerges(Set<RevCommit> mergedParents) throws IOException {
    if (!mergedParents.isEmpty()) {
        Ref targetRef = allRefs().get(magicBranch.dest.get());
        if (targetRef != null) {
            RevWalk rw = receivePack.getRevWalk();
            RevCommit tip = rw.parseCommit(targetRef.getObjectId());
            boolean containsImplicitMerges = true;
            for (RevCommit p : mergedParents) {
                containsImplicitMerges &= !rw.isMergedInto(p, tip);
            }
            if (containsImplicitMerges) {
                rw.reset();
                for (RevCommit p : mergedParents) {
                    rw.markStart(p);
                }
                rw.markUninteresting(tip);
                RevCommit c;
                while ((c = rw.next()) != null) {
                    rw.parseBody(c);
                    messages.add(new CommitValidationMessage("Implicit Merge of " + c.abbreviate(7).name() + " " + c.getShortMessage(), ValidationMessage.Type.ERROR));
                }
                reject(magicBranch.cmd, "implicit merges detected");
            }
        }
    }
}
#end_block

#method_before
// Mark all branch tips as uninteresting in the given revwalk,
private void markHeadsAsUninteresting(RevWalk rw, @Nullable String forRef) {
    int i = 0;
    for (Ref ref : allRefs().values()) {
        if ((ref.getName().startsWith(R_HEADS) || ref.getName().equals(forRef)) && ref.getObjectId() != null) {
            try {
                rw.markUninteresting(rw.parseCommit(ref.getObjectId()));
                i++;
            } catch (IOException e) {
                logWarn(String.format("Invalid ref %s in %s", ref.getName(), project.getName()), e);
            }
        }
    }
    logDebug("Marked %d heads as uninteresting", i);
}
#method_after
// Mark all branch tips as uninteresting in the given revwalk,
private void markHeadsAsUninteresting(RevWalk rw, @Nullable String forRef) {
    int i = 0;
    for (Ref ref : allRefs().values()) {
        if ((ref.getName().startsWith(R_HEADS) || ref.getName().equals(forRef)) && ref.getObjectId() != null) {
            try {
                rw.markUninteresting(rw.parseCommit(ref.getObjectId()));
                i++;
            } catch (IOException e) {
                logger.atWarning().withCause(e).log("Invalid ref %s in %s", ref.getName(), project.getName());
            }
        }
    }
    logger.atFine().log("Marked %d heads as uninteresting", i);
}
#end_block

#method_before
private void addOps(BatchUpdate bu) throws RestApiException {
    checkState(changeId != null, "must call setChangeId before addOps");
    try {
        RevWalk rw = receivePack.getRevWalk();
        rw.parseBody(commit);
        final PatchSet.Id psId = ins.setGroups(groups).getPatchSetId();
        Account.Id me = user.getAccountId();
        List<FooterLine> footerLines = commit.getFooterLines();
        MailRecipients recipients = new MailRecipients();
        Map<String, Short> approvals = new HashMap<>();
        checkNotNull(magicBranch);
        recipients.add(magicBranch.getMailRecipients());
        approvals = magicBranch.labels;
        recipients.add(getRecipientsFromFooters(accountResolver, footerLines));
        recipients.remove(me);
        StringBuilder msg = new StringBuilder(ApprovalsUtil.renderMessageWithApprovals(psId.get(), approvals, Collections.<String, PatchSetApproval>emptyMap()));
        msg.append('.');
        if (!Strings.isNullOrEmpty(magicBranch.message)) {
            msg.append("\n").append(magicBranch.message);
        }
        bu.insertChange(ins.setReviewers(recipients.getReviewers()).setExtraCC(recipients.getCcOnly()).setApprovals(approvals).setMessage(msg.toString()).setNotify(magicBranch.getNotify()).setAccountsToNotify(magicBranch.getAccountsToNotify()).setRequestScopePropagator(requestScopePropagator).setSendMail(true).setPatchSetDescription(magicBranch.message));
        if (!magicBranch.hashtags.isEmpty()) {
            // Any change owner is allowed to add hashtags when creating a change.
            bu.addOp(changeId, hashtagsFactory.create(new HashtagsInput(magicBranch.hashtags)).setFireEvent(false));
        }
        if (!Strings.isNullOrEmpty(magicBranch.topic)) {
            bu.addOp(changeId, new BatchUpdateOp() {

                @Override
                public boolean updateChange(ChangeContext ctx) {
                    ctx.getUpdate(psId).setTopic(magicBranch.topic);
                    return true;
                }
            });
        }
        bu.addOp(changeId, new BatchUpdateOp() {

            @Override
            public boolean updateChange(ChangeContext ctx) {
                change = ctx.getChange();
                return false;
            }
        });
        bu.addOp(changeId, new ChangeProgressOp(newProgress));
    } catch (Exception e) {
        throw INSERT_EXCEPTION.apply(e);
    }
}
#method_after
private void addOps(BatchUpdate bu) throws RestApiException {
    checkState(changeId != null, "must call setChangeId before addOps");
    try {
        RevWalk rw = receivePack.getRevWalk();
        rw.parseBody(commit);
        final PatchSet.Id psId = ins.setGroups(groups).getPatchSetId();
        Account.Id me = user.getAccountId();
        List<FooterLine> footerLines = commit.getFooterLines();
        requireNonNull(magicBranch);
        // TODO(dborowitz): Support reviewers by email from footers? Maybe not: kernel developers
        // with AOSP accounts already complain about these notifications, and that would make it
        // worse. Might be better to get rid of the feature entirely:
        // https://groups.google.com/d/topic/repo-discuss/tIFxY7L4DXk/discussion
        MailRecipients fromFooters = getRecipientsFromFooters(accountResolver, footerLines);
        fromFooters.remove(me);
        Map<String, Short> approvals = magicBranch.labels;
        StringBuilder msg = new StringBuilder(ApprovalsUtil.renderMessageWithApprovals(psId.get(), approvals, Collections.emptyMap()));
        msg.append('.');
        if (!Strings.isNullOrEmpty(magicBranch.message)) {
            msg.append("\n").append(magicBranch.message);
        }
        bu.insertChange(ins.setReviewersAndCcsAsStrings(magicBranch.getCombinedReviewers(fromFooters), magicBranch.getCombinedCcs(fromFooters)).setApprovals(approvals).setMessage(msg.toString()).setNotify(magicBranch.getNotify()).setAccountsToNotify(magicBranch.getAccountsToNotify()).setRequestScopePropagator(requestScopePropagator).setSendMail(true).setPatchSetDescription(magicBranch.message));
        if (!magicBranch.hashtags.isEmpty()) {
            // Any change owner is allowed to add hashtags when creating a change.
            bu.addOp(changeId, hashtagsFactory.create(new HashtagsInput(magicBranch.hashtags)).setFireEvent(false));
        }
        if (!Strings.isNullOrEmpty(magicBranch.topic)) {
            bu.addOp(changeId, new BatchUpdateOp() {

                @Override
                public boolean updateChange(ChangeContext ctx) {
                    ctx.getUpdate(psId).setTopic(magicBranch.topic);
                    return true;
                }
            });
        }
        bu.addOp(changeId, new BatchUpdateOp() {

            @Override
            public boolean updateChange(ChangeContext ctx) {
                CreateRequest.this.change = ctx.getChange();
                return false;
            }
        });
        bu.addOp(changeId, new ChangeProgressOp(progress));
    } catch (Exception e) {
        throw INSERT_EXCEPTION.apply(e);
    }
}
#end_block

#method_before
private void submit(Collection<CreateRequest> create, Collection<ReplaceRequest> replace) throws OrmException, RestApiException, UpdateException, IOException, ConfigInvalidException, PermissionBackendException {
    Map<ObjectId, Change> bySha = Maps.newHashMapWithExpectedSize(create.size() + replace.size());
    for (CreateRequest r : create) {
        checkNotNull(r.change, "cannot submit new change %s; op may not have run", r.changeId);
        bySha.put(r.commit, r.change);
    }
    for (ReplaceRequest r : replace) {
        bySha.put(r.newCommitId, r.notes.getChange());
    }
    Change tipChange = bySha.get(magicBranch.cmd.getNewId());
    checkNotNull(tipChange, "tip of push does not correspond to a change; found these changes: %s", bySha);
    logDebug("Processing submit with tip change %s (%s)", tipChange.getId(), magicBranch.cmd.getNewId());
    try (MergeOp op = mergeOpProvider.get()) {
        op.merge(db, tipChange, user, false, new SubmitInput(), false);
    }
}
#method_after
private void submit(Collection<CreateRequest> create, Collection<ReplaceRequest> replace) throws OrmException, RestApiException, UpdateException, IOException, ConfigInvalidException, PermissionBackendException {
    Map<ObjectId, Change> bySha = Maps.newHashMapWithExpectedSize(create.size() + replace.size());
    for (CreateRequest r : create) {
        requireNonNull(r.change, () -> String.format("cannot submit new change %s; op may not have run", r.changeId));
        bySha.put(r.commit, r.change);
    }
    for (ReplaceRequest r : replace) {
        bySha.put(r.newCommitId, r.notes.getChange());
    }
    Change tipChange = bySha.get(magicBranch.cmd.getNewId());
    requireNonNull(tipChange, () -> String.format("tip of push does not correspond to a change; found these changes: %s", bySha));
    logger.atFine().log("Processing submit with tip change %s (%s)", tipChange.getId(), magicBranch.cmd.getNewId());
    try (MergeOp op = mergeOpProvider.get()) {
        op.merge(db, tipChange, user, false, new SubmitInput(), false);
    }
}
#end_block

#method_before
private void preparePatchSetsForReplace(List<CreateRequest> newChanges) {
    try {
        readChangesForReplace();
        for (Iterator<ReplaceRequest> itr = replaceByChange.values().iterator(); itr.hasNext(); ) {
            ReplaceRequest req = itr.next();
            if (req.inputCommand.getResult() == NOT_ATTEMPTED) {
                req.validate(false);
            }
        }
    } catch (OrmException err) {
        logError(String.format("Cannot read database before replacement for project %s", project.getName()), err);
        for (ReplaceRequest req : replaceByChange.values()) {
            if (req.inputCommand.getResult() == NOT_ATTEMPTED) {
                req.inputCommand.setResult(REJECTED_OTHER_REASON, "internal server error");
            }
        }
    } catch (IOException | PermissionBackendException err) {
        logError(String.format("Cannot read repository before replacement for project %s", project.getName()), err);
        for (ReplaceRequest req : replaceByChange.values()) {
            if (req.inputCommand.getResult() == NOT_ATTEMPTED) {
                req.inputCommand.setResult(REJECTED_OTHER_REASON, "internal server error");
            }
        }
    }
    logDebug("Read %d changes to replace", replaceByChange.size());
    if (magicBranch != null && magicBranch.cmd.getResult() != NOT_ATTEMPTED) {
        // Cancel creations tied to refs/for/ or refs/drafts/ command.
        for (ReplaceRequest req : replaceByChange.values()) {
            if (req.inputCommand == magicBranch.cmd && req.cmd != null) {
                req.cmd.setResult(Result.REJECTED_OTHER_REASON, "aborted");
            }
        }
        for (CreateRequest req : newChanges) {
            req.cmd.setResult(Result.REJECTED_OTHER_REASON, "aborted");
        }
    }
}
#method_after
private void preparePatchSetsForReplace(List<CreateRequest> newChanges) {
    try {
        readChangesForReplace();
        for (ReplaceRequest req : replaceByChange.values()) {
            if (req.inputCommand.getResult() == NOT_ATTEMPTED) {
                req.validateNewPatchSet();
            }
        }
    } catch (OrmException err) {
        logger.atSevere().withCause(err).log("Cannot read database before replacement for project %s", project.getName());
        rejectRemainingRequests(replaceByChange.values(), "internal server error");
    } catch (IOException | PermissionBackendException err) {
        logger.atSevere().withCause(err).log("Cannot read repository before replacement for project %s", project.getName());
        rejectRemainingRequests(replaceByChange.values(), "internal server error");
    }
    logger.atFine().log("Read %d changes to replace", replaceByChange.size());
    if (magicBranch != null && magicBranch.cmd.getResult() != NOT_ATTEMPTED) {
        // Cancel creations tied to refs/for/ or refs/drafts/ command.
        for (ReplaceRequest req : replaceByChange.values()) {
            if (req.inputCommand == magicBranch.cmd && req.cmd != null) {
                req.cmd.setResult(Result.REJECTED_OTHER_REASON, "aborted");
            }
        }
        for (CreateRequest req : newChanges) {
            req.cmd.setResult(Result.REJECTED_OTHER_REASON, "aborted");
        }
    }
}
#end_block

#method_before
private boolean newEdit() {
    psId = notes.getChange().currentPatchSetId();
    Optional<ChangeEdit> edit = null;
    try {
        edit = editUtil.byChange(notes, user);
    } catch (AuthException | IOException e) {
        logError("Cannot retrieve edit", e);
        return false;
    }
    if (edit.isPresent()) {
        if (edit.get().getBasePatchSet().getId().equals(psId)) {
            // replace edit
            cmd = new ReceiveCommand(edit.get().getEditCommit(), newCommitId, edit.get().getRefName());
        } else {
            // delete old edit ref on rebase
            prev = new ReceiveCommand(edit.get().getEditCommit(), ObjectId.zeroId(), edit.get().getRefName());
            createEditCommand();
        }
    } else {
        createEditCommand();
    }
    return true;
}
#method_after
private boolean newEdit() {
    psId = notes.getChange().currentPatchSetId();
    Optional<ChangeEdit> edit;
    try {
        edit = editUtil.byChange(notes, user);
    } catch (AuthException | IOException e) {
        logger.atSevere().withCause(e).log("Cannot retrieve edit");
        return false;
    }
    if (edit.isPresent()) {
        if (edit.get().getBasePatchSet().getId().equals(psId)) {
            // replace edit
            cmd = new ReceiveCommand(edit.get().getEditCommit(), newCommitId, edit.get().getRefName());
        } else {
            // delete old edit ref on rebase
            prev = new ReceiveCommand(edit.get().getEditCommit(), ObjectId.zeroId(), edit.get().getRefName());
            createEditCommand();
        }
    } else {
        createEditCommand();
    }
    return true;
}
#end_block

#method_before
private void createEditCommand() {
    // create new edit
    cmd = new ReceiveCommand(ObjectId.zeroId(), newCommitId, RefNames.refsEdit(user.getAccountId(), notes.getChangeId(), psId));
}
#method_after
private void createEditCommand() {
    cmd = new ReceiveCommand(ObjectId.zeroId(), newCommitId, RefNames.refsEdit(user.getAccountId(), notes.getChangeId(), psId));
}
#end_block

#method_before
@Override
public void postUpdate(Context ctx) {
    String refName = cmd.getRefName();
    if (cmd.getType() == ReceiveCommand.Type.UPDATE) {
        // aka fast-forward
        logDebug("Updating tag cache on fast-forward of %s", cmd.getRefName());
        tagCache.updateFastForward(project.getNameKey(), refName, cmd.getOldId(), cmd.getNewId());
    }
    if (isConfig(cmd)) {
        logDebug("Reloading project in cache");
        try {
            projectCache.evict(project);
        } catch (IOException e) {
            logger.atWarning().withCause(e).log("Cannot evict from project cache, name key: %s", project.getName());
        }
        ProjectState ps = projectCache.get(project.getNameKey());
        try {
            logDebug("Updating project description");
            repo.setGitwebDescription(ps.getProject().getDescription());
        } catch (IOException e) {
            logger.atWarning().withCause(e).log("cannot update description of %s", project.getName());
        }
        if (allProjectsName.equals(project.getNameKey())) {
            try {
                createGroupPermissionSyncer.syncIfNeeded();
            } catch (IOException | ConfigInvalidException e) {
                logger.atSevere().withCause(e).log("Can't sync create group permissions");
            }
        }
    }
}
#method_after
@Override
public void postUpdate(Context ctx) {
    String refName = cmd.getRefName();
    if (cmd.getType() == ReceiveCommand.Type.UPDATE) {
        // aka fast-forward
        logger.atFine().log("Updating tag cache on fast-forward of %s", cmd.getRefName());
        tagCache.updateFastForward(project.getNameKey(), refName, cmd.getOldId(), cmd.getNewId());
    }
    if (isConfig(cmd)) {
        logger.atFine().log("Reloading project in cache");
        try {
            projectCache.evict(project);
        } catch (IOException e) {
            logger.atWarning().withCause(e).log("Cannot evict from project cache, name key: %s", project.getName());
        }
        ProjectState ps = projectCache.get(project.getNameKey());
        try {
            logger.atFine().log("Updating project description");
            repo.setGitwebDescription(ps.getProject().getDescription());
        } catch (IOException e) {
            logger.atWarning().withCause(e).log("cannot update description of %s", project.getName());
        }
        if (allProjectsName.equals(project.getNameKey())) {
            try {
                createGroupPermissionSyncer.syncIfNeeded();
            } catch (IOException | ConfigInvalidException e) {
                logger.atSevere().withCause(e).log("Can't sync create group permissions");
            }
        }
    }
}
#end_block

#method_before
static boolean parentsEqual(RevCommit a, RevCommit b) {
    if (a.getParentCount() != b.getParentCount()) {
        return false;
    }
    for (int i = 0; i < a.getParentCount(); i++) {
        if (!a.getParent(i).equals(b.getParent(i))) {
            return false;
        }
    }
    return true;
}
#method_after
private static boolean parentsEqual(RevCommit a, RevCommit b) {
    if (a.getParentCount() != b.getParentCount()) {
        return false;
    }
    for (int i = 0; i < a.getParentCount(); i++) {
        if (!a.getParent(i).equals(b.getParent(i))) {
            return false;
        }
    }
    return true;
}
#end_block

#method_before
static boolean authorEqual(RevCommit a, RevCommit b) {
    PersonIdent aAuthor = a.getAuthorIdent();
    PersonIdent bAuthor = b.getAuthorIdent();
    if (aAuthor == null && bAuthor == null) {
        return true;
    } else if (aAuthor == null || bAuthor == null) {
        return false;
    }
    return Objects.equals(aAuthor.getName(), bAuthor.getName()) && Objects.equals(aAuthor.getEmailAddress(), bAuthor.getEmailAddress());
}
#method_after
private static boolean authorEqual(RevCommit a, RevCommit b) {
    PersonIdent aAuthor = a.getAuthorIdent();
    PersonIdent bAuthor = b.getAuthorIdent();
    if (aAuthor == null && bAuthor == null) {
        return true;
    } else if (aAuthor == null || bAuthor == null) {
        return false;
    }
    return Objects.equals(aAuthor.getName(), bAuthor.getName()) && Objects.equals(aAuthor.getEmailAddress(), bAuthor.getEmailAddress());
}
#end_block

#method_before
private boolean validRefOperation(ReceiveCommand cmd) {
    RefOperationValidators refValidators = refValidatorsFactory.create(getProject(), user, cmd);
    try {
        messages.addAll(refValidators.validateForRefOperation());
    } catch (RefOperationValidationException e) {
        messages.addAll(Lists.newArrayList(e.getMessages()));
        reject(cmd, e.getMessage());
        return false;
    }
    return true;
}
#method_after
// Run RefValidators on the command. If any validator fails, the command status is set to
private boolean validRefOperation(ReceiveCommand cmd) {
    RefOperationValidators refValidators = refValidatorsFactory.create(getProject(), user, cmd);
    try {
        messages.addAll(refValidators.validateForRefOperation());
    } catch (RefOperationValidationException e) {
        messages.addAll(Lists.newArrayList(e.getMessages()));
        reject(cmd, e.getMessage());
        return false;
    }
    return true;
}
#end_block

#method_before
private void autoCloseChanges(ReceiveCommand cmd) {
    logDebug("Starting auto-closing of changes");
    String refName = cmd.getRefName();
    checkState(!MagicBranch.isMagicBranch(refName), "shouldn't be auto-closing changes on magic branch %s", refName);
    // insertChangesAndPatchSets.
    try {
        retryHelper.execute(updateFactory -> {
            try (BatchUpdate bu = updateFactory.create(db, projectState.getNameKey(), user, TimeUtil.nowTs());
                ObjectInserter ins = repo.newObjectInserter();
                ObjectReader reader = ins.newReader();
                RevWalk rw = new RevWalk(reader)) {
                bu.setRepository(repo, rw, ins).updateChangesInParallel();
                bu.setRequestId(receiveId);
                // TODO(dborowitz): Teach BatchUpdate to ignore missing changes.
                RevCommit newTip = rw.parseCommit(cmd.getNewId());
                Branch.NameKey branch = new Branch.NameKey(project.getNameKey(), refName);
                rw.reset();
                rw.markStart(newTip);
                if (!ObjectId.zeroId().equals(cmd.getOldId())) {
                    rw.markUninteresting(rw.parseCommit(cmd.getOldId()));
                }
                ListMultimap<ObjectId, Ref> byCommit = changeRefsById();
                Map<Change.Key, ChangeNotes> byKey = null;
                List<ReplaceRequest> replaceAndClose = new ArrayList<>();
                int existingPatchSets = 0;
                int newPatchSets = 0;
                COMMIT: for (RevCommit c; (c = rw.next()) != null; ) {
                    rw.parseBody(c);
                    for (Ref ref : byCommit.get(c.copy())) {
                        PatchSet.Id psId = PatchSet.Id.fromRef(ref.getName());
                        Optional<ChangeNotes> notes = getChangeNotes(psId.getParentKey());
                        if (notes.isPresent() && notes.get().getChange().getDest().equals(branch)) {
                            existingPatchSets++;
                            bu.addOp(psId.getParentKey(), mergedByPushOpFactory.create(requestScopePropagator, psId, refName));
                            continue COMMIT;
                        }
                    }
                    for (String changeId : c.getFooterLines(CHANGE_ID)) {
                        if (byKey == null) {
                            byKey = executeIndexQuery(() -> openChangesByKeyByBranch(branch));
                        }
                        ChangeNotes onto = byKey.get(new Change.Key(changeId.trim()));
                        if (onto != null) {
                            newPatchSets++;
                            // Hold onto this until we're done with the walk, as the call to
                            // req.validate below calls isMergedInto which resets the walk.
                            ReplaceRequest req = new ReplaceRequest(onto.getChangeId(), c, cmd, false);
                            req.notes = onto;
                            replaceAndClose.add(req);
                            continue COMMIT;
                        }
                    }
                }
                for (ReplaceRequest req : replaceAndClose) {
                    Change.Id id = req.notes.getChangeId();
                    if (!req.validate(true)) {
                        logDebug("Not closing %s because validation failed", id);
                        continue;
                    }
                    req.addOps(bu, null);
                    bu.addOp(id, mergedByPushOpFactory.create(requestScopePropagator, req.psId, refName).setPatchSetProvider(req.replaceOp::getPatchSet));
                    bu.addOp(id, new ChangeProgressOp(closeProgress));
                }
                logDebug("Auto-closing %s changes with existing patch sets and %s with new patch sets", existingPatchSets, newPatchSets);
                bu.execute();
            } catch (IOException | OrmException | PermissionBackendException e) {
                logError("Failed to auto-close changes", e);
            }
            return null;
        }, // eat up the whole timeout so that no time is left to retry this outer action.
        RetryHelper.options().timeout(retryHelper.getDefaultTimeout(ActionType.CHANGE_UPDATE).multipliedBy(5)).build());
    } catch (RestApiException e) {
        logError("Can't insert patchset", e);
    } catch (UpdateException e) {
        logError("Failed to auto-close changes", e);
    }
}
#method_after
private void autoCloseChanges(ReceiveCommand cmd, Task progress) {
    logger.atFine().log("Starting auto-closing of changes");
    String refName = cmd.getRefName();
    Set<Change.Id> ids = new HashSet<>();
    // handleRegularCommands
    try {
        retryHelper.execute(updateFactory -> {
            try (BatchUpdate bu = updateFactory.create(db, projectState.getNameKey(), user, TimeUtil.nowTs());
                ObjectInserter ins = repo.newObjectInserter();
                ObjectReader reader = ins.newReader();
                RevWalk rw = new RevWalk(reader)) {
                bu.setRepository(repo, rw, ins).updateChangesInParallel();
                // TODO(dborowitz): Teach BatchUpdate to ignore missing changes.
                RevCommit newTip = rw.parseCommit(cmd.getNewId());
                Branch.NameKey branch = new Branch.NameKey(project.getNameKey(), refName);
                rw.reset();
                rw.markStart(newTip);
                if (!ObjectId.zeroId().equals(cmd.getOldId())) {
                    rw.markUninteresting(rw.parseCommit(cmd.getOldId()));
                }
                ListMultimap<ObjectId, Ref> byCommit = changeRefsById();
                Map<Change.Key, ChangeNotes> byKey = null;
                List<ReplaceRequest> replaceAndClose = new ArrayList<>();
                int existingPatchSets = 0;
                int newPatchSets = 0;
                COMMIT: for (RevCommit c; (c = rw.next()) != null; ) {
                    rw.parseBody(c);
                    for (Ref ref : byCommit.get(c.copy())) {
                        PatchSet.Id psId = PatchSet.Id.fromRef(ref.getName());
                        Optional<ChangeNotes> notes = getChangeNotes(psId.getParentKey());
                        if (notes.isPresent() && notes.get().getChange().getDest().equals(branch)) {
                            existingPatchSets++;
                            bu.addOp(psId.getParentKey(), mergedByPushOpFactory.create(requestScopePropagator, psId, refName));
                            continue COMMIT;
                        }
                    }
                    for (String changeId : c.getFooterLines(CHANGE_ID)) {
                        if (byKey == null) {
                            byKey = executeIndexQuery(() -> openChangesByKeyByBranch(branch));
                        }
                        ChangeNotes onto = byKey.get(new Change.Key(changeId.trim()));
                        if (onto != null) {
                            newPatchSets++;
                            // Hold onto this until we're done with the walk, as the call to
                            // req.validate below calls isMergedInto which resets the walk.
                            ReplaceRequest req = new ReplaceRequest(onto.getChangeId(), c, cmd, false);
                            req.notes = onto;
                            replaceAndClose.add(req);
                            continue COMMIT;
                        }
                    }
                }
                for (ReplaceRequest req : replaceAndClose) {
                    Change.Id id = req.notes.getChangeId();
                    if (!req.validateNewPatchSetForAutoClose()) {
                        logger.atFine().log("Not closing %s because validation failed", id);
                        continue;
                    }
                    req.addOps(bu, null);
                    bu.addOp(id, mergedByPushOpFactory.create(requestScopePropagator, req.psId, refName).setPatchSetProvider(req.replaceOp::getPatchSet));
                    bu.addOp(id, new ChangeProgressOp(progress));
                    ids.add(id);
                }
                logger.atFine().log("Auto-closing %s changes with existing patch sets and %s with new patch sets", existingPatchSets, newPatchSets);
                bu.execute();
            } catch (IOException | OrmException | PermissionBackendException e) {
                logger.atSevere().withCause(e).log("Failed to auto-close changes");
                return null;
            }
            // If we are here, we didn't throw UpdateException. Record the result.
            // The ordering is indeterminate due to the HashSet; unfortunately, Change.Id doesn't
            // fit into TreeSet.
            ids.stream().forEach(id -> resultChangeIds.add(Key.AUTOCLOSED, id));
            return null;
        }, // eat up the whole timeout so that no time is left to retry this outer action.
        RetryHelper.options().timeout(retryHelper.getDefaultTimeout(ActionType.CHANGE_UPDATE).multipliedBy(5)).build());
    } catch (RestApiException e) {
        logger.atSevere().withCause(e).log("Can't insert patchset");
    } catch (UpdateException e) {
        logger.atSevere().withCause(e).log("Failed to auto-close changes");
    }
}
#end_block

#method_before
private void reject(@Nullable ReceiveCommand cmd, String why) {
    if (cmd != null) {
        cmd.setResult(REJECTED_OTHER_REASON, why);
        commandProgress.update(1);
    }
}
#method_after
private static void reject(ReceiveCommand cmd, String why) {
    cmd.setResult(REJECTED_OTHER_REASON, why);
}
#end_block

#method_before
@Override
public GroupMembership membershipsOf(IdentifiedUser user) {
    String username = user.getUserName().get();
    if (Strings.isNullOrEmpty(username)) {
        return GroupMembership.EMPTY;
    }
    return ghMembershipProvider.get(username);
}
#method_after
@Override
public GroupMembership membershipsOf(IdentifiedUser user) {
    String username = user.getUserName().orElse(null);
    if (Strings.isNullOrEmpty(username)) {
        return GroupMembership.EMPTY;
    }
    return ghMembershipProvider.get(username);
}
#end_block

#method_before
public Change.Id internalAddCommitToChange(ReviewDb db, BatchUpdate bu, final Project project, final Repository repo, final String destinationBranch, final Account.Id pullRequestOwner, final RevCommit pullRequestCommit, final String pullRequestMesage, final String topic) throws InvalidChangeOperationException, IOException, NoSuchProjectException, OrmException, UpdateException, RestApiException {
    if (destinationBranch == null || destinationBranch.length() == 0) {
        throw new InvalidChangeOperationException("Destination branch cannot be null or empty");
    }
    Ref destRef = repo.findRef(destinationBranch);
    if (destRef == null) {
        throw new InvalidChangeOperationException("Branch " + destinationBranch + " does not exist.");
    }
    String pullRequestSha1 = pullRequestCommit.getId().getName();
    List<ChangeData> existingChanges = queryChangesForSha1(pullRequestSha1);
    if (!existingChanges.isEmpty()) {
        LOG.debug("Pull request commit ID " + pullRequestSha1 + " has been already uploaded as Change-Id=" + existingChanges.get(0).getId());
        return null;
    }
    Change.Key changeKey;
    final List<String> idList = pullRequestCommit.getFooterLines(CHANGE_ID);
    if (!idList.isEmpty()) {
        final String idStr = idList.get(idList.size() - 1).trim();
        changeKey = new Change.Key(idStr);
    } else {
        final ObjectId computedChangeId = ChangeIdUtil.computeChangeId(pullRequestCommit.getTree(), pullRequestCommit, pullRequestCommit.getAuthorIdent(), pullRequestCommit.getCommitterIdent(), pullRequestMesage);
        changeKey = new Change.Key("I" + computedChangeId.name());
    }
    String branchName = destRef.getName();
    List<ChangeData> destChanges = queryProvider.get().byBranchKey(new Branch.NameKey(project.getNameKey(), branchName.startsWith(REFS_HEADS) ? branchName.substring(REFS_HEADS.length()) : branchName), changeKey);
    if (destChanges.size() > 1) {
        throw new InvalidChangeOperationException("Multiple Changes with Change-ID " + changeKey + " already exist on the target branch: cannot add a new patch-set " + destinationBranch);
    }
    if (destChanges.size() == 1) {
        // The change key exists on the destination branch: adding a new
        // patch-set
        ChangeData destChangeData = destChanges.get(0);
        Change destChange = destChangeData.change();
        insertPatchSet(bu, repo, destChange, pullRequestCommit, destChangeData.notes(), pullRequestMesage);
        return destChange.getId();
    }
    // change.
    return createNewChange(db, bu, changeKey, project.getNameKey(), destRef, pullRequestOwner, pullRequestCommit, "refs/for/" + destinationBranch, pullRequestMesage, topic);
}
#method_after
public Change.Id internalAddCommitToChange(ReviewDb db, BatchUpdate bu, final Project project, final Repository repo, final String destinationBranch, final Account.Id pullRequestOwner, final RevCommit pullRequestCommit, final String pullRequestMesage, final String topic) throws InvalidChangeOperationException, IOException, NoSuchProjectException, OrmException, UpdateException, RestApiException {
    if (destinationBranch == null || destinationBranch.length() == 0) {
        throw new InvalidChangeOperationException("Destination branch cannot be null or empty");
    }
    Ref destRef = repo.findRef(destinationBranch);
    if (destRef == null) {
        throw new InvalidChangeOperationException("Branch " + destinationBranch + " does not exist.");
    }
    String pullRequestSha1 = pullRequestCommit.getId().getName();
    List<ChangeData> existingChanges = queryChangesForSha1(pullRequestSha1);
    if (!existingChanges.isEmpty()) {
        LOG.debug("Pull request commit ID " + pullRequestSha1 + " has been already uploaded as Change-Id=" + existingChanges.get(0).getId());
        return null;
    }
    Change.Key changeKey;
    final List<String> idList = pullRequestCommit.getFooterLines(CHANGE_ID);
    if (!idList.isEmpty()) {
        final String idStr = idList.get(idList.size() - 1).trim();
        changeKey = new Change.Key(idStr);
    } else {
        final ObjectId computedChangeId = ChangeIdUtil.computeChangeId(pullRequestCommit.getTree(), pullRequestCommit, pullRequestCommit.getAuthorIdent(), pullRequestCommit.getCommitterIdent(), pullRequestMesage);
        changeKey = new Change.Key("I" + computedChangeId.name());
    }
    String branchName = destRef.getName();
    List<ChangeData> destChanges = queryProvider.get().byBranchKey(new Branch.NameKey(project.getNameKey(), branchName.startsWith(REFS_HEADS) ? branchName.substring(REFS_HEADS.length()) : branchName), changeKey);
    if (destChanges.size() > 1) {
        throw new InvalidChangeOperationException("Multiple Changes with Change-ID " + changeKey + " already exist on the target branch: cannot add a new patch-set " + destinationBranch);
    }
    if (destChanges.size() == 1) {
        // The change key exists on the destination branch: adding a new
        // patch-set
        ChangeData destChangeData = destChanges.get(0);
        Change destChange = destChangeData.change();
        insertPatchSet(bu, repo, destChange, pullRequestCommit, destChangeData.notes(), pullRequestMesage);
        return destChange.getId();
    }
    // change.
    return createNewChange(db, bu, changeKey, project.getNameKey(), destRef, pullRequestOwner, pullRequestCommit, destinationBranch, pullRequestMesage, topic);
}
#end_block

#method_before
public MutableNotesMigration setFrom(NotesMigrationState state) {
    snapshot.set(state.snapshot());
    return this;
}
#method_after
@VisibleForTesting
public MutableNotesMigration setFrom(NotesMigrationState state) {
    snapshot.set(state.snapshot());
    return this;
}
#end_block

#method_before
@Override
public ReviewDb open() throws OrmException {
    // There are two levels at which this class disables access to Changes and related tables,
    // corresponding to two phases of the NoteDb migration:
    // 
    // 1. When changes are read from NoteDb but some changes might still have their primary storage
    // in ReviewDb, it is generally programmer error to read changes from ReviewDb. However,
    // since ReviewDb is still the primary storage for most or all changes, we still need to
    // support writing to ReviewDb. This behavior is accomplished by wrapping in a
    // DisallowedReviewDb.
    // 
    // Some codepaths might need to be able to read from ReviewDb if they really need to,
    // because they need to operate on the underlying source of truth, for example when reading
    // a change to determine its primary storage. To support this, ReviewDbUtil#unwrapDb can
    // detect and unwrap databases of this type.
    // 
    // 2. After all changes have their primary storage in NoteDb, we can completely shut off access
    // to the change tables. At this point in the migration, we are by definition not using the
    // ReviewDb tables at all; we could even delete the tables at this point, and Gerrit would
    // continue to function.
    // 
    // This is accomplished by setting the delegate ReviewDb *underneath*
    // DisallowReadFromChanges to be a complete no-op, with NoChangesReviewDb. With this
    // wrapper, all read operations return no results, and write operations silently do nothing.
    // This wrapper is not a public class and nobody should ever attempt to unwrap it.
    // First create the wrappers which can not be removed by ReviewDbUtil#unwrapDb(ReviewDb).
    checkState(migration.readChanges() && migration.disableChangeReviewDb());
    // Disable writes to change tables in ReviewDb (ReviewDb access for changes are No-Ops).
    ReviewDb db = new NoChangesReviewDb();
    // Second create the wrappers which can be removed by ReviewDbUtil#unwrapDb(ReviewDb).
    if (migration.readChanges()) {
        // If reading changes from NoteDb is configured, changes should not be read from ReviewDb.
        // Make sure that any attempt to read a change from ReviewDb anyway fails with an exception.
        db = new DisallowedReviewDb(db);
    }
    return db;
}
#method_after
@Override
public ReviewDb open() throws OrmException {
    // There are two levels at which this class disables access to Changes and related tables,
    // corresponding to two phases of the NoteDb migration:
    // 
    // 1. When changes are read from NoteDb but some changes might still have their primary storage
    // in ReviewDb, it is generally programmer error to read changes from ReviewDb. However,
    // since ReviewDb is still the primary storage for most or all changes, we still need to
    // support writing to ReviewDb. This behavior is accomplished by wrapping in a
    // DisallowedReviewDb.
    // 
    // Some codepaths might need to be able to read from ReviewDb if they really need to,
    // because they need to operate on the underlying source of truth, for example when reading
    // a change to determine its primary storage. To support this, ReviewDbUtil#unwrapDb can
    // detect and unwrap databases of this type.
    // 
    // 2. After all changes have their primary storage in NoteDb, we can completely shut off access
    // to the change tables. At this point in the migration, we are by definition not using the
    // ReviewDb tables at all; we could even delete the tables at this point, and Gerrit would
    // continue to function.
    // 
    // This is accomplished by setting the delegate ReviewDb *underneath*
    // DisallowReadFromChanges to be a complete no-op, with NoChangesReviewDb. With this
    // stub implementation, all read operations return no results, and write operations silently
    // do nothing. This implementation is not a public class and callers couldn't do anything
    // useful with it even if it were.
    // First create the underlying stub.
    checkState(migration.readChanges() && migration.disableChangeReviewDb());
    // Disable writes to change tables in ReviewDb (ReviewDb access for changes are No-Ops); all
    // other table accesses throw runtime exceptions.
    ReviewDb db = new NoChangesReviewDb();
    // Second create the wrappers which can be removed by ReviewDbUtil#unwrapDb(ReviewDb).
    if (migration.readChanges()) {
        // If reading changes from NoteDb is configured, changes should not be read from ReviewDb.
        // Make sure that any attempt to read a change from ReviewDb anyway fails with an exception.
        db = new DisallowedReviewDb(db);
    }
    return db;
}
#end_block

#method_before
@Override
public ResultSet<ChangeMessage> byChange(Change.Id id) throws OrmException {
    return empty();
}
#method_after
@Override
public ResultSet<ChangeMessage> byChange(Change.Id id) {
    return empty();
}
#end_block

#method_before
@Override
public ResultSet<ChangeMessage> byPatchSet(PatchSet.Id id) throws OrmException {
    return empty();
}
#method_after
@Override
public ResultSet<ChangeMessage> byPatchSet(PatchSet.Id id) {
    return empty();
}
#end_block

#method_before
@Override
public ResultSet<ChangeMessage> all() throws OrmException {
    return empty();
}
#method_after
@Override
public ResultSet<ChangeMessage> all() {
    return empty();
}
#end_block

#method_before
@Test
@UseLocalDisk
@GerritConfig(name = "plugin.kafka-events.bootstrapServers", value = "localhost:9092")
@GerritConfig(name = "plugin.kafka-events.groupId", value = "test-consumer-group")
@GerritConfig(name = "plugin.kafka-events.keyDeserializer", value = "org.apache.kafka.common.serialization.StringDeserializer")
@GerritConfig(name = "plugin.kafka-events.valueDeserializer", value = "org.apache.kafka.common.serialization.StringDeserializer")
public void consumeEvents() throws Exception {
    PushOneCommit.Result r = createChange();
    ReviewInput in = ReviewInput.recommend();
    in.message = "LGTM";
    gApi.changes().id(r.getChangeId()).revision("current").review(in);
    List<ChangeMessageInfo> messages = new ArrayList<>(gApi.changes().id(r.getChangeId()).get().messages);
    assertThat(messages).hasSize(2);
    String expectedMessage = "Patch Set 1: Code-Review+1\n\nLGTM";
    assertThat(messages.get(1).message).isEqualTo(expectedMessage);
    KafkaProperties kafkaProperties = kafkaProperties();
    List<String> events = new ArrayList<>();
    try (Consumer<String, String> consumer = new KafkaConsumer<>(kafkaProperties)) {
        consumer.subscribe(Collections.singleton(kafkaProperties.getTopic()));
        ConsumerRecords<String, String> records = consumer.poll(Long.MAX_VALUE);
        for (ConsumerRecord<String, String> record : records) {
            events.add(record.value());
        }
    }
    // The received events in order:
    // 
    // 1. RefUpdatedEvent
    // 2. PatchSetCreatedEvent
    // 3. CommentAddedEvent
    assertThat(events).hasSize(3);
    String commentAddedEventJson = events.get(2);
    Gson gson = new GsonBuilder().registerTypeAdapter(Event.class, new EventDeserializer()).registerTypeAdapter(Supplier.class, new SupplierDeserializer()).create();
    Event event = gson.fromJson(commentAddedEventJson, Event.class);
    assertThat(event).isInstanceOf(CommentAddedEvent.class);
    CommentAddedEvent commentAddedEvent = (CommentAddedEvent) event;
    assertThat(commentAddedEvent.comment).isEqualTo(expectedMessage);
}
#method_after
@Test
@UseLocalDisk
@GerritConfig(name = "plugin.kafka-events.bootstrapServers", value = "localhost:9092")
@GerritConfig(name = "plugin.kafka-events.groupId", value = "test-consumer-group")
@GerritConfig(name = "plugin.kafka-events.keyDeserializer", value = "org.apache.kafka.common.serialization.StringDeserializer")
@GerritConfig(name = "plugin.kafka-events.valueDeserializer", value = "org.apache.kafka.common.serialization.StringDeserializer")
public void consumeEvents() throws Exception {
    PushOneCommit.Result r = createChange();
    ReviewInput in = ReviewInput.recommend();
    in.message = "LGTM";
    gApi.changes().id(r.getChangeId()).revision("current").review(in);
    List<ChangeMessageInfo> messages = new ArrayList<>(gApi.changes().id(r.getChangeId()).get().messages);
    assertThat(messages).hasSize(2);
    String expectedMessage = "Patch Set 1: Code-Review+1\n\nLGTM";
    assertThat(messages.get(1).message).isEqualTo(expectedMessage);
    KafkaProperties kafkaProperties = kafkaProperties();
    List<String> events = new ArrayList<>();
    try (Consumer<String, String> consumer = new KafkaConsumer<>(kafkaProperties)) {
        consumer.subscribe(Collections.singleton(kafkaProperties.getTopic()));
        ConsumerRecords<String, String> records = consumer.poll(KAFKA_POLL_TIMEOUT);
        for (ConsumerRecord<String, String> record : records) {
            events.add(record.value());
        }
    }
    // The received 6 events in order:
    // 
    // 1. refUpdate:        ref: refs/sequences/changes
    // 2. refUpdate:        ref: refs/changes/01/1/1
    // 3. refUpdate:        ref: refs/changes/01/1/meta
    // 4. patchset-created: ref: refs/changes/01/1/1
    // 5. refUpdate:        ref: refs/changes/01/1/meta"
    // 6. comment-added:    ref: refs/heads/master
    assertThat(events).hasSize(6);
    String commentAddedEventJson = events.get(5);
    Gson gson = new GsonBuilder().registerTypeAdapter(Event.class, new EventDeserializer()).registerTypeAdapter(Supplier.class, new SupplierDeserializer()).create();
    Event event = gson.fromJson(commentAddedEventJson, Event.class);
    assertThat(event).isInstanceOf(CommentAddedEvent.class);
    CommentAddedEvent commentAddedEvent = (CommentAddedEvent) event;
    assertThat(commentAddedEvent.comment).isEqualTo(expectedMessage);
}
#end_block

#method_before
private void processCommandsUnsafe(Collection<ReceiveCommand> commands, MultiProgressMonitor progress) {
    parsePushOptions();
    try (TraceContext traceContext = TraceContext.newTrace(tracePushOption.isPresent(), tracePushOption.orElse(null), (tagName, traceId) -> addMessage(tagName + ": " + traceId))) {
        traceContext.addTag(RequestId.Type.RECEIVE_ID, new RequestId(project.getNameKey().get()));
        // Log the push options here, rather than in parsePushOptions(), so that they are included
        // into the trace if tracing is enabled.
        logger.atFine().log("push options: %s", receivePack.getPushOptions());
        if (!projectState.getProject().getState().permitsWrite()) {
            for (ReceiveCommand cmd : commands) {
                reject(cmd, "prohibited by Gerrit: project state does not permit write");
            }
            return;
        }
        logger.atFine().log("Parsing %d commands", commands.size());
        List<ReceiveCommand> magicCommands = new ArrayList<>();
        List<ReceiveCommand> directPatchSetPushCommands = new ArrayList<>();
        List<ReceiveCommand> regularCommands = new ArrayList<>();
        for (ReceiveCommand cmd : commands) {
            if (MagicBranch.isMagicBranch(cmd.getRefName())) {
                magicCommands.add(cmd);
            } else if (isDirectChangesPush(cmd.getRefName())) {
                directPatchSetPushCommands.add(cmd);
            } else {
                regularCommands.add(cmd);
            }
        }
        int commandTypes = (magicCommands.isEmpty() ? 0 : 1) + (directPatchSetPushCommands.isEmpty() ? 0 : 1) + (regularCommands.isEmpty() ? 0 : 1);
        if (commandTypes > 1) {
            rejectRemaining(commands, "cannot combine normal pushes and magic pushes");
            return;
        }
        try {
            if (!regularCommands.isEmpty()) {
                handleRegularCommands(regularCommands, progress);
                return;
            }
            for (ReceiveCommand cmd : directPatchSetPushCommands) {
                parseDirectChangesPush(cmd);
            }
            boolean first = true;
            for (ReceiveCommand cmd : magicCommands) {
                if (first) {
                    parseMagicBranch(cmd);
                    first = false;
                } else {
                    reject(cmd, "duplicate request");
                }
            }
        } catch (PermissionBackendException | NoSuchProjectException | IOException err) {
            logger.atSevere().withCause(err).log("Failed to process refs in %s", project.getName());
            return;
        }
        Task newProgress = progress.beginSubTask("new", UNKNOWN);
        Task replaceProgress = progress.beginSubTask("updated", UNKNOWN);
        List<CreateRequest> newChanges = Collections.emptyList();
        if (magicBranch != null && magicBranch.cmd.getResult() == NOT_ATTEMPTED) {
            newChanges = selectNewAndReplacedChangesFromMagicBranch(newProgress);
        }
        // Commit validation has already happened, so any changes without Change-Id are for the
        // deprecated feature.
        warnAboutMissingChangeId(newChanges);
        preparePatchSetsForReplace(newChanges);
        insertChangesAndPatchSets(newChanges, replaceProgress);
        newProgress.end();
        replaceProgress.end();
        queueSuccessMessages(newChanges);
        refsPublishDeprecationWarning();
        logger.atFine().log("Command results: %s", lazy(() -> commands.stream().collect(toMap(cmd -> cmd, cmd -> {
            String msg = cmd.getMessage();
            if (msg != null) {
                return cmd.getResult() + " (" + msg + ")";
            }
            return cmd.getResult();
        }))));
    }
}
#method_after
private void processCommandsUnsafe(Collection<ReceiveCommand> commands, MultiProgressMonitor progress) {
    parsePushOptions();
    try (TraceContext traceContext = TraceContext.newTrace(tracePushOption.isPresent(), tracePushOption.orElse(null), (tagName, traceId) -> addMessage(tagName + ": " + traceId))) {
        traceContext.addTag(RequestId.Type.RECEIVE_ID, new RequestId(project.getNameKey().get()));
        // Log the push options here, rather than in parsePushOptions(), so that they are included
        // into the trace if tracing is enabled.
        logger.atFine().log("push options: %s", receivePack.getPushOptions());
        if (!projectState.getProject().getState().permitsWrite()) {
            for (ReceiveCommand cmd : commands) {
                reject(cmd, "prohibited by Gerrit: project state does not permit write");
            }
            return;
        }
        logger.atFine().log("Parsing %d commands", commands.size());
        List<ReceiveCommand> magicCommands = new ArrayList<>();
        List<ReceiveCommand> directPatchSetPushCommands = new ArrayList<>();
        List<ReceiveCommand> regularCommands = new ArrayList<>();
        for (ReceiveCommand cmd : commands) {
            if (MagicBranch.isMagicBranch(cmd.getRefName())) {
                magicCommands.add(cmd);
            } else if (isDirectChangesPush(cmd.getRefName())) {
                directPatchSetPushCommands.add(cmd);
            } else {
                regularCommands.add(cmd);
            }
        }
        int commandTypes = (magicCommands.isEmpty() ? 0 : 1) + (directPatchSetPushCommands.isEmpty() ? 0 : 1) + (regularCommands.isEmpty() ? 0 : 1);
        if (commandTypes > 1) {
            rejectRemaining(commands, "cannot combine normal pushes and magic pushes");
            return;
        }
        try {
            if (!regularCommands.isEmpty()) {
                handleRegularCommands(regularCommands, progress);
                return;
            }
            for (ReceiveCommand cmd : directPatchSetPushCommands) {
                parseDirectChangesPush(cmd);
            }
            boolean first = true;
            for (ReceiveCommand cmd : magicCommands) {
                if (first) {
                    parseMagicBranch(cmd);
                    first = false;
                } else {
                    reject(cmd, "duplicate request");
                }
            }
        } catch (PermissionBackendException | NoSuchProjectException | IOException err) {
            logger.atSevere().withCause(err).log("Failed to process refs in %s", project.getName());
            return;
        }
        Task newProgress = progress.beginSubTask("new", UNKNOWN);
        Task replaceProgress = progress.beginSubTask("updated", UNKNOWN);
        List<CreateRequest> newChanges = Collections.emptyList();
        if (magicBranch != null && magicBranch.cmd.getResult() == NOT_ATTEMPTED) {
            newChanges = selectNewAndReplacedChangesFromMagicBranch(newProgress);
        }
        // Commit validation has already happened, so any changes without Change-Id are for the
        // deprecated feature.
        warnAboutMissingChangeId(newChanges);
        preparePatchSetsForReplace(newChanges);
        insertChangesAndPatchSets(newChanges, replaceProgress);
        newProgress.end();
        replaceProgress.end();
        queueSuccessMessages(newChanges);
        refsPublishDeprecationWarning();
        logger.atFine().log("Command results: %s", lazy(() -> commands.stream().map(ReceiveCommits::commandToString).collect(joining(","))));
    }
}
#end_block

#method_before
private void parseMagicBranch(ReceiveCommand cmd) throws PermissionBackendException {
    logger.atFine().log("Found magic branch %s", cmd.getRefName());
    MagicBranchInput magicBranch = new MagicBranchInput(user, cmd, labelTypes, notesMigration);
    String ref;
    magicBranch.cmdLineParser = optionParserFactory.create(magicBranch);
    try {
        ref = magicBranch.parse(repo, receivePack.getAdvertisedRefs().keySet(), pushOptions);
    } catch (CmdLineException e) {
        if (!magicBranch.cmdLineParser.wasHelpRequestedByOption()) {
            logger.atFine().log("Invalid branch syntax");
            reject(cmd, e.getMessage());
            return;
        }
        // never happens
        ref = null;
    }
    if (magicBranch.topic != null && magicBranch.topic.length() > ChangeUtil.TOPIC_MAX_LENGTH) {
        reject(cmd, String.format("topic length exceeds the limit (%d)", ChangeUtil.TOPIC_MAX_LENGTH));
    }
    if (magicBranch.cmdLineParser.wasHelpRequestedByOption()) {
        StringWriter w = new StringWriter();
        w.write("\nHelp for refs/for/branch:\n\n");
        magicBranch.cmdLineParser.printUsage(w, null);
        addMessage(w.toString());
        reject(cmd, "see help");
        return;
    }
    if (projectState.isAllUsers() && RefNames.REFS_USERS_SELF.equals(ref)) {
        logger.atFine().log("Handling %s", RefNames.REFS_USERS_SELF);
        ref = RefNames.refsUsers(user.getAccountId());
    }
    if (!receivePack.getAdvertisedRefs().containsKey(ref) && !ref.equals(readHEAD(repo)) && !ref.equals(RefNames.REFS_CONFIG)) {
        logger.atFine().log("Ref %s not found", ref);
        if (ref.startsWith(Constants.R_HEADS)) {
            String n = ref.substring(Constants.R_HEADS.length());
            reject(cmd, "branch " + n + " not found");
        } else {
            reject(cmd, ref + " not found");
        }
        return;
    }
    magicBranch.dest = new Branch.NameKey(project.getNameKey(), ref);
    magicBranch.perm = permissions.ref(ref);
    Optional<AuthException> err = checkRefPermission(magicBranch.perm, RefPermission.CREATE_CHANGE);
    if (err.isPresent()) {
        rejectProhibited(cmd, err.get());
        return;
    }
    // after repo-tool supports private and work-in-progress changes.
    if (magicBranch.draft && !receiveConfig.allowDrafts) {
        errors.put(CODE_REVIEW_ERROR, ref);
        reject(cmd, "draft workflow is disabled");
        return;
    }
    if (magicBranch.isPrivate && magicBranch.removePrivate) {
        reject(cmd, "the options 'private' and 'remove-private' are mutually exclusive");
        return;
    }
    boolean privateByDefault = projectCache.get(project.getNameKey()).is(BooleanProjectConfig.PRIVATE_BY_DEFAULT);
    setChangeAsPrivate = magicBranch.draft || magicBranch.isPrivate || (privateByDefault && !magicBranch.removePrivate);
    if (receiveConfig.disablePrivateChanges && setChangeAsPrivate) {
        reject(cmd, "private changes are disabled");
        return;
    }
    if (magicBranch.workInProgress && magicBranch.ready) {
        reject(cmd, "the options 'wip' and 'ready' are mutually exclusive");
        return;
    }
    if (magicBranch.publishComments && magicBranch.noPublishComments) {
        reject(cmd, "the options 'publish-comments' and 'no-publish-comments' are mutually exclusive");
        return;
    }
    if (magicBranch.submit) {
        err = checkRefPermission(magicBranch.perm, RefPermission.UPDATE_BY_SUBMIT);
        if (err.isPresent()) {
            rejectProhibited(cmd, err.get());
            return;
        }
    }
    RevWalk walk = receivePack.getRevWalk();
    RevCommit tip;
    try {
        tip = walk.parseCommit(magicBranch.cmd.getNewId());
        logger.atFine().log("Tip of push: %s", tip.name());
    } catch (IOException ex) {
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logger.atSevere().withCause(ex).log("Invalid pack upload; one or more objects weren't sent");
        return;
    }
    String destBranch = magicBranch.dest.get();
    try {
        if (magicBranch.merged) {
            if (magicBranch.base != null) {
                reject(cmd, "cannot use merged with base");
                return;
            }
            RevCommit branchTip = readBranchTip(cmd, magicBranch.dest);
            if (branchTip == null) {
                // readBranchTip already rejected cmd.
                return;
            }
            if (!walk.isMergedInto(tip, branchTip)) {
                reject(cmd, "not merged into branch");
                return;
            }
        }
        // if %base or %merged was specified, ignore newChangeForAllNotInTarget.
        if (tip.getParentCount() > 1 || magicBranch.base != null || magicBranch.merged || tip.getParentCount() == 0) {
            logger.atFine().log("Forcing newChangeForAllNotInTarget = false");
            newChangeForAllNotInTarget = false;
        }
        if (magicBranch.base != null) {
            logger.atFine().log("Handling %%base: %s", magicBranch.base);
            magicBranch.baseCommit = Lists.newArrayListWithCapacity(magicBranch.base.size());
            for (ObjectId id : magicBranch.base) {
                try {
                    magicBranch.baseCommit.add(walk.parseCommit(id));
                } catch (IncorrectObjectTypeException notCommit) {
                    reject(cmd, "base must be a commit");
                    return;
                } catch (MissingObjectException e) {
                    reject(cmd, "base not found");
                    return;
                } catch (IOException e) {
                    logger.atWarning().withCause(e).log("Project %s cannot read %s", project.getName(), id.name());
                    reject(cmd, "internal server error");
                    return;
                }
            }
        } else if (newChangeForAllNotInTarget) {
            RevCommit branchTip = readBranchTip(cmd, magicBranch.dest);
            if (branchTip == null) {
                // readBranchTip already rejected cmd.
                return;
            }
            magicBranch.baseCommit = Collections.singletonList(branchTip);
            logger.atFine().log("Set baseCommit = %s", magicBranch.baseCommit.get(0).name());
        }
    } catch (IOException ex) {
        logger.atWarning().withCause(ex).log("Error walking to %s in project %s", destBranch, project.getName());
        reject(cmd, "internal server error");
        return;
    }
    if (magicBranch.deprecatedTopicSeen) {
        messages.add(new ValidationMessage("WARNING: deprecated topic syntax. Use %topic=TOPIC instead", false));
        logger.atInfo().log("deprecated topic push seen for project %s", project.getName());
    }
    if (validateConnected(magicBranch.cmd, magicBranch.dest, tip)) {
        this.magicBranch = magicBranch;
    }
}
#method_after
private void parseMagicBranch(ReceiveCommand cmd) throws PermissionBackendException {
    logger.atFine().log("Found magic branch %s", cmd.getRefName());
    MagicBranchInput magicBranch = new MagicBranchInput(user, cmd, labelTypes, notesMigration);
    String ref;
    magicBranch.cmdLineParser = optionParserFactory.create(magicBranch);
    try {
        ref = magicBranch.parse(repo, receivePack.getAdvertisedRefs().keySet(), pushOptions);
    } catch (CmdLineException e) {
        if (!magicBranch.cmdLineParser.wasHelpRequestedByOption()) {
            logger.atFine().log("Invalid branch syntax");
            reject(cmd, e.getMessage());
            return;
        }
        // never happens
        ref = null;
    }
    if (magicBranch.topic != null && magicBranch.topic.length() > ChangeUtil.TOPIC_MAX_LENGTH) {
        reject(cmd, String.format("topic length exceeds the limit (%d)", ChangeUtil.TOPIC_MAX_LENGTH));
    }
    if (magicBranch.cmdLineParser.wasHelpRequestedByOption()) {
        StringWriter w = new StringWriter();
        w.write("\nHelp for refs/for/branch:\n\n");
        magicBranch.cmdLineParser.printUsage(w, null);
        addMessage(w.toString());
        reject(cmd, "see help");
        return;
    }
    if (projectState.isAllUsers() && RefNames.REFS_USERS_SELF.equals(ref)) {
        logger.atFine().log("Handling %s", RefNames.REFS_USERS_SELF);
        ref = RefNames.refsUsers(user.getAccountId());
    }
    // configuration.
    if (!receivePack.getAdvertisedRefs().containsKey(ref) && !ref.equals(readHEAD(repo)) && !ref.equals(RefNames.REFS_CONFIG)) {
        logger.atFine().log("Ref %s not found", ref);
        if (ref.startsWith(Constants.R_HEADS)) {
            String n = ref.substring(Constants.R_HEADS.length());
            reject(cmd, "branch " + n + " not found");
        } else {
            reject(cmd, ref + " not found");
        }
        return;
    }
    magicBranch.dest = new Branch.NameKey(project.getNameKey(), ref);
    magicBranch.perm = permissions.ref(ref);
    Optional<AuthException> err = checkRefPermission(magicBranch.perm, RefPermission.CREATE_CHANGE);
    if (err.isPresent()) {
        rejectProhibited(cmd, err.get());
        return;
    }
    // after repo-tool supports private and work-in-progress changes.
    if (magicBranch.draft && !receiveConfig.allowDrafts) {
        errors.put(CODE_REVIEW_ERROR, ref);
        reject(cmd, "draft workflow is disabled");
        return;
    }
    if (magicBranch.isPrivate && magicBranch.removePrivate) {
        reject(cmd, "the options 'private' and 'remove-private' are mutually exclusive");
        return;
    }
    boolean privateByDefault = projectCache.get(project.getNameKey()).is(BooleanProjectConfig.PRIVATE_BY_DEFAULT);
    setChangeAsPrivate = magicBranch.draft || magicBranch.isPrivate || (privateByDefault && !magicBranch.removePrivate);
    if (receiveConfig.disablePrivateChanges && setChangeAsPrivate) {
        reject(cmd, "private changes are disabled");
        return;
    }
    if (magicBranch.workInProgress && magicBranch.ready) {
        reject(cmd, "the options 'wip' and 'ready' are mutually exclusive");
        return;
    }
    if (magicBranch.publishComments && magicBranch.noPublishComments) {
        reject(cmd, "the options 'publish-comments' and 'no-publish-comments' are mutually exclusive");
        return;
    }
    if (magicBranch.submit) {
        err = checkRefPermission(magicBranch.perm, RefPermission.UPDATE_BY_SUBMIT);
        if (err.isPresent()) {
            rejectProhibited(cmd, err.get());
            return;
        }
    }
    RevWalk walk = receivePack.getRevWalk();
    RevCommit tip;
    try {
        tip = walk.parseCommit(magicBranch.cmd.getNewId());
        logger.atFine().log("Tip of push: %s", tip.name());
    } catch (IOException ex) {
        magicBranch.cmd.setResult(REJECTED_MISSING_OBJECT);
        logger.atSevere().withCause(ex).log("Invalid pack upload; one or more objects weren't sent");
        return;
    }
    String destBranch = magicBranch.dest.get();
    try {
        if (magicBranch.merged) {
            if (magicBranch.base != null) {
                reject(cmd, "cannot use merged with base");
                return;
            }
            RevCommit branchTip = readBranchTip(magicBranch.dest);
            if (branchTip == null) {
                reject(cmd, magicBranch.dest.get() + " not found");
                return;
            }
            if (!walk.isMergedInto(tip, branchTip)) {
                reject(cmd, "not merged into branch");
                return;
            }
        }
        // if %base or %merged was specified, ignore newChangeForAllNotInTarget.
        if (tip.getParentCount() > 1 || magicBranch.base != null || magicBranch.merged || tip.getParentCount() == 0) {
            logger.atFine().log("Forcing newChangeForAllNotInTarget = false");
            newChangeForAllNotInTarget = false;
        }
        if (magicBranch.base != null) {
            logger.atFine().log("Handling %%base: %s", magicBranch.base);
            magicBranch.baseCommit = Lists.newArrayListWithCapacity(magicBranch.base.size());
            for (ObjectId id : magicBranch.base) {
                try {
                    magicBranch.baseCommit.add(walk.parseCommit(id));
                } catch (IncorrectObjectTypeException notCommit) {
                    reject(cmd, "base must be a commit");
                    return;
                } catch (MissingObjectException e) {
                    reject(cmd, "base not found");
                    return;
                } catch (IOException e) {
                    logger.atWarning().withCause(e).log("Project %s cannot read %s", project.getName(), id.name());
                    reject(cmd, "internal server error");
                    return;
                }
            }
        } else if (newChangeForAllNotInTarget) {
            RevCommit branchTip = readBranchTip(magicBranch.dest);
            if (branchTip != null) {
                magicBranch.baseCommit = Collections.singletonList(branchTip);
                logger.atFine().log("Set baseCommit = %s", magicBranch.baseCommit.get(0).name());
            } else {
                // repository and to review an initial project configuration.
                if (!ref.equals(readHEAD(repo)) && !ref.equals(RefNames.REFS_CONFIG)) {
                    reject(cmd, magicBranch.dest.get() + " not found");
                    return;
                }
            }
        }
    } catch (IOException ex) {
        logger.atWarning().withCause(ex).log("Error walking to %s in project %s", destBranch, project.getName());
        reject(cmd, "internal server error");
        return;
    }
    if (magicBranch.deprecatedTopicSeen) {
        messages.add(new ValidationMessage("WARNING: deprecated topic syntax. Use %topic=TOPIC instead", false));
        logger.atInfo().log("deprecated topic push seen for project %s", project.getName());
    }
    if (validateConnected(magicBranch.cmd, magicBranch.dest, tip)) {
        this.magicBranch = magicBranch;
    }
}
#end_block

#method_before
private static String readHEAD(Repository repo) {
    try {
        return repo.getFullBranch();
    } catch (IOException e) {
        logger.atSevere().withCause(e).log("Cannot read HEAD symref");
        return null;
    }
}
#method_after
private static String readHEAD(Repository repo) {
    try {
        String head = repo.getFullBranch();
        logger.atFine().log("HEAD = %s", head);
        return head;
    } catch (IOException e) {
        logger.atSevere().withCause(e).log("Cannot read HEAD symref");
        return null;
    }
}
#end_block

#method_before
private RevCommit readBranchTip(ReceiveCommand cmd, Branch.NameKey branch) throws IOException {
    Ref r = allRefs().get(branch.get());
    if (r == null) {
        reject(cmd, branch.get() + " not found");
        return null;
    }
    return receivePack.getRevWalk().parseCommit(r.getObjectId());
}
#method_after
private RevCommit readBranchTip(Branch.NameKey branch) throws IOException {
    Ref r = allRefs().get(branch.get());
    if (r == null) {
        return null;
    }
    return receivePack.getRevWalk().parseCommit(r.getObjectId());
}
#end_block

#method_before
private void sameTreeWarning() throws IOException {
    RevCommit newCommit = receivePack.getRevWalk().parseCommit(newCommitId);
    RevCommit priorCommit = revisions.inverse().get(priorPatchSet);
    if (newCommit.getTree().equals(priorCommit.getTree())) {
        boolean messageEq = Objects.equals(newCommit.getFullMessage(), priorCommit.getFullMessage());
        boolean parentsEq = parentsEqual(newCommit, priorCommit);
        boolean authorEq = authorEqual(newCommit, priorCommit);
        ObjectReader reader = receivePack.getRevWalk().getObjectReader();
        if (messageEq && parentsEq && authorEq) {
            addMessage(String.format("warning: no changes between prior commit %s and new commit %s", reader.abbreviate(priorCommit).name(), reader.abbreviate(newCommit).name()));
        } else {
            StringBuilder msg = new StringBuilder();
            msg.append("warning: ").append(reader.abbreviate(newCommit).name());
            msg.append(":");
            msg.append(" no files changed");
            if (!authorEq) {
                msg.append(", author changed");
            }
            if (!messageEq) {
                msg.append(", message updated");
            }
            if (!parentsEq) {
                msg.append(", was rebased");
            }
            addMessage(msg.toString());
        }
    }
}
#method_after
private void sameTreeWarning() throws IOException {
    RevWalk rw = receivePack.getRevWalk();
    RevCommit newCommit = rw.parseCommit(newCommitId);
    RevCommit priorCommit = revisions.inverse().get(priorPatchSet);
    if (newCommit.getTree().equals(priorCommit.getTree())) {
        rw.parseBody(newCommit);
        rw.parseBody(priorCommit);
        boolean messageEq = Objects.equals(newCommit.getFullMessage(), priorCommit.getFullMessage());
        boolean parentsEq = parentsEqual(newCommit, priorCommit);
        boolean authorEq = authorEqual(newCommit, priorCommit);
        ObjectReader reader = receivePack.getRevWalk().getObjectReader();
        if (messageEq && parentsEq && authorEq) {
            addMessage(String.format("warning: no changes between prior commit %s and new commit %s", reader.abbreviate(priorCommit).name(), reader.abbreviate(newCommit).name()));
        } else {
            StringBuilder msg = new StringBuilder();
            msg.append("warning: ").append(reader.abbreviate(newCommit).name());
            msg.append(":");
            msg.append(" no files changed");
            if (!authorEq) {
                msg.append(", author changed");
            }
            if (!messageEq) {
                msg.append(", message updated");
            }
            if (!parentsEq) {
                msg.append(", was rebased");
            }
            addMessage(msg.toString());
        }
    }
}
#end_block

#method_before
private AccountGroup.UUID createGroupWithArbitraryMembers(int numMembers) throws Exception {
    Set<Account.Id> members = new HashSet<>();
    for (int i = 0; i < numMembers; i++) {
        Account.Id user = accountOperations.newAccount().create();
        members.add(user);
    }
    return groupOperations.newGroup().members(members).create();
}
#method_after
private AccountGroup.UUID createGroupWithArbitraryMembers(int numMembers) {
    Set<Account.Id> members = IntStream.rangeClosed(1, numMembers).mapToObj(i -> accountOperations.newAccount().create()).collect(toImmutableSet());
    return groupOperations.newGroup().members(members).create();
}
#end_block

#method_before
@Override
public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException {
    HttpServletRequest httpRequest = (HttpServletRequest) request;
    HttpServletResponseRecorder wrappedResponse = new HttpServletResponseRecorder((HttpServletResponse) response);
    Optional<IdentifiedUser> loggedInUserBefore = loggedInUser();
    chain.doFilter(request, wrappedResponse);
    Optional<IdentifiedUser> loggedInUserAfter = loggedInUser();
    if (!loggedInUserBefore.isPresent() && loggedInUserAfter.isPresent()) {
        webLoginListeners.runEach(loginListener -> loginListener.onLogin(loggedInUserAfter.get(), httpRequest, wrappedResponse));
    } else if (loggedInUserBefore.isPresent() && !loggedInUserAfter.isPresent()) {
        webLoginListeners.runEach(loginListener -> loginListener.onLogout(loggedInUserBefore.get(), httpRequest, wrappedResponse));
    }
    wrappedResponse.play();
}
#method_after
@Override
public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException {
    HttpServletRequest httpRequest = (HttpServletRequest) request;
    HttpServletResponseRecorder wrappedResponse = new HttpServletResponseRecorder((HttpServletResponse) response);
    Optional<IdentifiedUser> loggedInUserBefore = loggedInUser();
    chain.doFilter(request, wrappedResponse);
    Optional<IdentifiedUser> loggedInUserAfter = loggedInUser();
    if (!loggedInUserBefore.isPresent() && loggedInUserAfter.isPresent()) {
        webLoginListeners.runEach(l -> l.onLogin(loggedInUserAfter.get(), httpRequest, wrappedResponse));
    } else if (loggedInUserBefore.isPresent() && !loggedInUserAfter.isPresent()) {
        webLoginListeners.runEach(l -> l.onLogout(loggedInUserBefore.get(), httpRequest, wrappedResponse));
    }
    wrappedResponse.play();
}
#end_block

#method_before
private void createCodeReviewNote(ChangeNotes notes, PatchSet ps, HeaderFormatter fmt) throws OrmException, NoSuchChangeException {
    // This races with the label normalization/writeback done by MergeOp. It may
    // repeat some work, but results should be identical except in the case of
    // an additional race with a permissions change.
    // TODO(dborowitz): These will eventually be stamped in the ChangeNotes at
    // commit time so we will be able to skip this normalization step.
    Change change = notes.getChange();
    PatchSetApproval submit = null;
    for (PatchSetApproval a : approvalsUtil.byPatchSet(reviewDb, notes, ps.getId(), null, null)) {
        if (a.getValue() == 0) {
        // Ignore 0 values.
        } else if (a.isLegacySubmit()) {
            submit = a;
        } else {
            LabelType type = labelTypes.byLabel(a.getLabelId());
            if (type != null) {
                fmt.appendApproval(type, a.getValue(), a.getAccountId(), accountCache.get(a.getAccountId()).map(AccountState::getAccount));
            }
        }
    }
    if (submit != null) {
        fmt.appendSubmittedBy(submit.getAccountId(), accountCache.get(submit.getAccountId()).map(AccountState::getAccount));
        fmt.appendSubmittedAt(submit.getGranted());
    }
    UrlFormatter urlFormatter = urlFormatterItem.get();
    if (urlFormatter != null && urlFormatter.getWebUrl().isPresent()) {
        fmt.appendReviewedOn(urlFormatter, notes.getChange().getProject(), ps.getId().getParentKey());
    }
    fmt.appendProject(project.get());
    fmt.appendBranch(change.getDest().get());
}
#method_after
private void createCodeReviewNote(ChangeNotes notes, PatchSet ps, HeaderFormatter fmt) throws OrmException, NoSuchChangeException {
    // This races with the label normalization/writeback done by MergeOp. It may
    // repeat some work, but results should be identical except in the case of
    // an additional race with a permissions change.
    // TODO(dborowitz): These will eventually be stamped in the ChangeNotes at
    // commit time so we will be able to skip this normalization step.
    Change change = notes.getChange();
    PatchSetApproval submit = null;
    for (PatchSetApproval a : approvalsUtil.byPatchSet(reviewDb, notes, ps.getId(), null, null)) {
        if (a.getValue() == 0) {
        // Ignore 0 values.
        } else if (a.isLegacySubmit()) {
            submit = a;
        } else {
            LabelType type = labelTypes.byLabel(a.getLabelId());
            if (type != null) {
                fmt.appendApproval(type, a.getValue(), a.getAccountId(), accountCache.get(a.getAccountId()).map(AccountState::getAccount));
            }
        }
    }
    if (submit != null) {
        fmt.appendSubmittedBy(submit.getAccountId(), accountCache.get(submit.getAccountId()).map(AccountState::getAccount));
        fmt.appendSubmittedAt(submit.getGranted());
    }
    UrlFormatter uf = urlFormatter.get();
    if (uf != null && uf.getWebUrl().isPresent()) {
        fmt.appendReviewedOn(uf, notes.getChange().getProject(), ps.getId().getParentKey());
    }
    fmt.appendProject(project.get());
    fmt.appendBranch(change.getDest().get());
}
#end_block

#method_before
@Override
public void run() {
    Optional<AdminApi> adminApi = adminApiFactory.create(replicateURI);
    if (adminApi.isPresent()) {
        adminApi.get().deleteProject(project);
        return;
    }
    repLog.warn("Cannot delete project on remote site {}.", replicateURI);
}
#method_after
@Override
public void run() {
    Optional<AdminApi> adminApi = adminApiFactory.create(replicateURI);
    if (adminApi.isPresent()) {
        adminApi.get().deleteProject(project);
        return;
    }
    repLog.warn("Cannot delete project {} on remote site {}.", project, replicateURI);
}
#end_block

#method_before
@Override
public void run() {
    Optional<AdminApi> adminApi = adminApiFactory.create(replicateURI);
    if (adminApi.isPresent()) {
        adminApi.get().updateHead(project, newHead);
        return;
    }
    repLog.warn("Cannot update HEAD of project on remote site {}.", replicateURI);
}
#method_after
@Override
public void run() {
    Optional<AdminApi> adminApi = adminApiFactory.create(replicateURI);
    if (adminApi.isPresent()) {
        adminApi.get().updateHead(project, newHead);
        return;
    }
    repLog.warn("Cannot update HEAD of project {} on remote site {}.", project, replicateURI);
}
#end_block

#method_before
private boolean createProject(URIish replicateURI, Project.NameKey projectName, String head) {
    Optional<AdminApi> adminApi = adminApiFactory.create(replicateURI);
    if (adminApi.isPresent() && adminApi.get().createProject(projectName, head)) {
        return true;
    }
    repLog.warn("Cannot create new project on remote site {}.", replicateURI);
    return false;
}
#method_after
private boolean createProject(URIish replicateURI, Project.NameKey projectName, String head) {
    Optional<AdminApi> adminApi = adminApiFactory.create(replicateURI);
    if (adminApi.isPresent() && adminApi.get().createProject(projectName, head)) {
        return true;
    }
    repLog.warn("Cannot create new project {} on remote site {}.", projectName, replicateURI);
    return false;
}
#end_block

#method_before
private void runPushOperation() {
    // Lock the queue, and remove ourselves, so we can't be modified once
    // we start replication (instead a new instance, with the same URI, is
    // created and scheduled for a future point in time.)
    // 
    MDC.put(ID_MDC_KEY, HexFormat.fromInt(id));
    if (!pool.requestRunway(this)) {
        if (!canceled) {
            repLog.info("Rescheduling replication to {} to avoid collision with an in-flight push.", uri);
            pool.reschedule(this, Destination.RetryReason.COLLISION);
        }
        return;
    }
    repLog.info("Replication to {} started...", uri);
    Timer1.Context context = metrics.start(config.getName());
    try {
        long startedAt = context.getStartTime();
        long delay = NANOSECONDS.toMillis(startedAt - createdAt);
        metrics.record(config.getName(), delay, retryCount);
        git = gitManager.openRepository(projectName);
        runImpl();
        long elapsed = NANOSECONDS.toMillis(context.stop());
        repLog.info("Replication to {} completed in {}ms, {}ms delay, {} retries", uri, elapsed, delay, retryCount);
    } catch (RepositoryNotFoundException e) {
        stateLog.error("Cannot replicate " + projectName + "; Local repository error: " + e.getMessage(), getStatesAsArray());
    } catch (RemoteRepositoryException e) {
        // Tried to replicate to a remote via anonymous git:// but the repository
        // does not exist.  In this case NoRemoteRepositoryException is not
        // raised.
        String msg = e.getMessage();
        if (msg.contains("access denied") || msg.contains("no such repository") || msg.contains("Git repository not found")) {
            createRepository();
        } else {
            repLog.error("Cannot replicate {}; Remote repository error: {}", projectName, msg);
        }
    } catch (NoRemoteRepositoryException e) {
        createRepository();
    } catch (NotSupportedException e) {
        stateLog.error("Cannot replicate to " + uri, e, getStatesAsArray());
    } catch (TransportException e) {
        Throwable cause = e.getCause();
        if (cause instanceof JSchException && cause.getMessage().startsWith("UnknownHostKey:")) {
            repLog.error("Cannot replicate to {}: {}", uri, cause.getMessage());
        } else if (e instanceof LockFailureException) {
            lockRetryCount++;
            // The LockFailureException message contains both URI and reason
            // for this failure.
            repLog.error("Cannot replicate to {}: {}", uri, e.getMessage());
            // The remote push operation should be retried.
            if (lockRetryCount <= maxLockRetries) {
                if (canceledWhileRunning.get()) {
                    logCanceledWhileRunningException(e);
                } else {
                    pool.reschedule(this, Destination.RetryReason.TRANSPORT_ERROR);
                }
            } else {
                repLog.error("Giving up after {} occurrences of this error: {} during replication to {}", lockRetryCount, e.getMessage(), uri);
            }
        } else {
            if (canceledWhileRunning.get()) {
                logCanceledWhileRunningException(e);
            } else {
                repLog.error("Cannot replicate to {}", uri, e);
                // The remote push operation should be retried.
                pool.reschedule(this, Destination.RetryReason.TRANSPORT_ERROR);
            }
        }
    } catch (IOException e) {
        stateLog.error("Cannot replicate to " + uri, e, getStatesAsArray());
    } catch (PermissionBackendException | RuntimeException | Error e) {
        stateLog.error("Unexpected error during replication to " + uri, e, getStatesAsArray());
    } finally {
        if (git != null) {
            git.close();
        }
        pool.notifyFinished(this);
    }
}
#method_after
private void runPushOperation() {
    // Lock the queue, and remove ourselves, so we can't be modified once
    // we start replication (instead a new instance, with the same URI, is
    // created and scheduled for a future point in time.)
    // 
    MDC.put(ID_MDC_KEY, HexFormat.fromInt(id));
    if (!pool.requestRunway(this)) {
        if (!canceled) {
            repLog.info("Rescheduling replication to {} to avoid collision with an in-flight push.", uri);
            pool.reschedule(this, Destination.RetryReason.COLLISION);
        }
        return;
    }
    repLog.info("Replication to {} started...", uri);
    Timer1.Context context = metrics.start(config.getName());
    try {
        long startedAt = context.getStartTime();
        long delay = NANOSECONDS.toMillis(startedAt - createdAt);
        metrics.record(config.getName(), delay, retryCount);
        git = gitManager.openRepository(projectName);
        runImpl();
        long elapsed = NANOSECONDS.toMillis(context.stop());
        repLog.info("Replication to {} completed in {}ms, {}ms delay, {} retries", uri, elapsed, delay, retryCount);
    } catch (RepositoryNotFoundException e) {
        stateLog.error("Cannot replicate " + projectName + "; Local repository error: " + e.getMessage(), getStatesAsArray());
    } catch (RemoteRepositoryException e) {
        // Tried to replicate to a remote via anonymous git:// but the repository
        // does not exist.  In this case NoRemoteRepositoryException is not
        // raised.
        String msg = e.getMessage();
        if (msg.contains("access denied") || msg.contains("no such repository") || msg.contains("Git repository not found") || msg.contains("unavailable")) {
            createRepository();
        } else {
            repLog.error("Cannot replicate {}; Remote repository error: {}", projectName, msg);
        }
    } catch (NoRemoteRepositoryException e) {
        createRepository();
    } catch (NotSupportedException e) {
        stateLog.error("Cannot replicate to " + uri, e, getStatesAsArray());
    } catch (TransportException e) {
        Throwable cause = e.getCause();
        if (cause instanceof JSchException && cause.getMessage().startsWith("UnknownHostKey:")) {
            repLog.error("Cannot replicate to {}: {}", uri, cause.getMessage());
        } else if (e instanceof LockFailureException) {
            lockRetryCount++;
            // The LockFailureException message contains both URI and reason
            // for this failure.
            repLog.error("Cannot replicate to {}: {}", uri, e.getMessage());
            // The remote push operation should be retried.
            if (lockRetryCount <= maxLockRetries) {
                if (canceledWhileRunning.get()) {
                    logCanceledWhileRunningException(e);
                } else {
                    pool.reschedule(this, Destination.RetryReason.TRANSPORT_ERROR);
                }
            } else {
                repLog.error("Giving up after {} occurrences of this error: {} during replication to {}", lockRetryCount, e.getMessage(), uri);
            }
        } else {
            if (canceledWhileRunning.get()) {
                logCanceledWhileRunningException(e);
            } else {
                repLog.error("Cannot replicate to {}", uri, e);
                // The remote push operation should be retried.
                pool.reschedule(this, Destination.RetryReason.TRANSPORT_ERROR);
            }
        }
    } catch (IOException e) {
        stateLog.error("Cannot replicate to " + uri, e, getStatesAsArray());
    } catch (PermissionBackendException | RuntimeException | Error e) {
        stateLog.error("Unexpected error during replication to " + uri, e, getStatesAsArray());
    } finally {
        if (git != null) {
            git.close();
        }
        pool.notifyFinished(this);
    }
}
#end_block

#method_before
private boolean createProject(Project.NameKey project, String head) {
    return createProjectFactory.create(project, head).call();
}
#method_after
private boolean createProject(Project.NameKey project, String head) {
    return createProjectFactory.create(project, head).create();
}
#end_block

#method_before
public LabelFunction getFunction() {
    return functionName;
}
#method_after
public LabelFunction getFunction() {
    return function;
}
#end_block

#method_before
public void setFunction(@Nullable LabelFunction function) {
    this.functionName = function;
}
#method_after
public void setFunction(@Nullable LabelFunction function) {
    this.function = function;
}
#end_block

#method_before
@Test
public void subscriptionInheritACL() throws Exception {
    Project.NameKey configKey = this.projectOperations.newProject().submitType(getSubmitType()).createEmptyCommit(true).create();
    grantPush(configKey);
    Project.NameKey config2Key = projectOperations.newProject().parent(configKey).submitType(getSubmitType()).create();
    grantPush(config2Key);
    cloneProject(config2Key);
    subKey = projectOperations.newProject().parent(config2Key).submitType(getSubmitType()).create();
    grantPush(subKey);
    subRepo = cloneProject(subKey);
    allowMatchingSubmoduleSubscription(configKey, "refs/heads/*", superKey, "refs/heads/*");
    pushChangeTo(subRepo, "master");
    createSubmoduleSubscription(superRepo, "master", subKey, "master");
    ObjectId subHEAD = pushChangeTo(subRepo, "master");
    expectToHaveSubmoduleState(superRepo, "master", subKey, subHEAD);
}
#method_after
@Test
public void subscriptionInheritACL() throws Exception {
    Project.NameKey configKey = this.projectOperations.newProject().submitType(getSubmitType()).create();
    grantPush(configKey);
    Project.NameKey config2Key = projectOperations.newProject().parent(configKey).submitType(getSubmitType()).create();
    grantPush(config2Key);
    cloneProject(config2Key);
    subKey = projectOperations.newProject().parent(config2Key).submitType(getSubmitType()).create();
    grantPush(subKey);
    subRepo = cloneProject(subKey);
    allowMatchingSubmoduleSubscription(configKey, "refs/heads/*", superKey, "refs/heads/*");
    pushChangeTo(subRepo, "master");
    createSubmoduleSubscription(superRepo, "master", subKey, "master");
    ObjectId subHEAD = pushChangeTo(subRepo, "master");
    expectToHaveSubmoduleState(superRepo, "master", subKey, subHEAD);
}
#end_block

#method_before
@Before
public void setUp() throws Exception {
    project1 = projectOperations.newProject().create();
    // Default for createEmptyCommit should match TestProjectConfig.
    project2 = this.projectOperations.newProject().parent(project1).create();
    setPrivateByDefault(project1, InheritableBoolean.FALSE);
}
#method_after
@Before
public void setUp() throws Exception {
    project1 = projectOperations.newProject().create();
    project2 = this.projectOperations.newProject().parent(project1).create();
    setPrivateByDefault(project1, InheritableBoolean.FALSE);
}
#end_block

#method_before
@Test
public void stalenessChecker_hierarchyChange_isStale() throws Exception {
    // Default for createEmptyCommit should match TestProjectConfig.
    Project.NameKey p1 = projectOperations.newProject().parent(allProjects).create();
    // Default for createEmptyCommit should match TestProjectConfig.
    Project.NameKey p2 = projectOperations.newProject().parent(allProjects).create();
    try (ProjectConfigUpdate u = updateProject(project)) {
        u.getConfig().getProject().setParentName(p1);
        u.save();
    }
    assertThat(stalenessChecker.isStale(project)).isFalse();
    updateProjectConfigWithoutIndexUpdate(p1, c -> c.getProject().setParentName(p2));
    assertThat(stalenessChecker.isStale(project)).isTrue();
}
#method_after
@Test
public void stalenessChecker_hierarchyChange_isStale() throws Exception {
    Project.NameKey p1 = projectOperations.newProject().create();
    Project.NameKey p2 = projectOperations.newProject().create();
    try (ProjectConfigUpdate u = updateProject(project)) {
        u.getConfig().getProject().setParentName(p1);
        u.save();
    }
    assertThat(stalenessChecker.isStale(project)).isFalse();
    updateProjectConfigWithoutIndexUpdate(p1, c -> c.getProject().setParentName(p2));
    assertThat(stalenessChecker.isStale(project)).isTrue();
}
#end_block

#method_before
@Test
public void listChildren() throws Exception {
    Project.NameKey child1 = projectOperations.newProject().create();
    // Default for createEmptyCommit should match TestProjectConfig.
    Project.NameKey child1_1 = this.projectOperations.newProject().parent(child1).create();
    // Default for createEmptyCommit should match TestProjectConfig.
    Project.NameKey child1_2 = this.projectOperations.newProject().parent(child1).create();
    assertThatNameList(gApi.projects().name(child1.get()).children()).isOrdered();
    assertThatNameList(gApi.projects().name(child1.get()).children()).containsExactly(child1_1, child1_2);
}
#method_after
@Test
public void listChildren() throws Exception {
    Project.NameKey child1 = projectOperations.newProject().create();
    Project.NameKey child1_1 = this.projectOperations.newProject().parent(child1).create();
    Project.NameKey child1_2 = this.projectOperations.newProject().parent(child1).create();
    assertThatNameList(gApi.projects().name(child1.get()).children()).isOrdered();
    assertThatNameList(gApi.projects().name(child1.get()).children()).containsExactly(child1_1, child1_2);
}
#end_block

#method_before
@Test
public void reindexProject() throws Exception {
    // Default for createEmptyCommit should match TestProjectConfig.
    projectOperations.newProject().parent(project).create();
    projectIndexedCounter.clear();
    gApi.projects().name(allProjects.get()).index(false);
    projectIndexedCounter.assertReindexOf(allProjects.get());
}
#method_after
@Test
public void reindexProject() throws Exception {
    projectOperations.newProject().parent(project).create();
    projectIndexedCounter.clear();
    gApi.projects().name(allProjects.get()).index(false);
    projectIndexedCounter.assertReindexOf(allProjects.get());
}
#end_block

#method_before
@Test
public void reindexProjectWithChildren() throws Exception {
    // Default for createEmptyCommit should match TestProjectConfig.
    Project.NameKey middle = projectOperations.newProject().parent(project).create();
    // Default for createEmptyCommit should match TestProjectConfig.
    Project.NameKey leave = projectOperations.newProject().parent(middle).create();
    projectIndexedCounter.clear();
    gApi.projects().name(project.get()).index(true);
    projectIndexedCounter.assertReindexExactly(ImmutableMap.of(project.get(), 1L, middle.get(), 1L, leave.get(), 1L));
}
#method_after
@Test
public void reindexProjectWithChildren() throws Exception {
    Project.NameKey middle = projectOperations.newProject().parent(project).create();
    Project.NameKey leave = projectOperations.newProject().parent(middle).create();
    projectIndexedCounter.clear();
    gApi.projects().name(project.get()).index(true);
    projectIndexedCounter.assertReindexExactly(ImmutableMap.of(project.get(), 1L, middle.get(), 1L, leave.get(), 1L));
}
#end_block

#method_before
@Test
@GerritConfig(name = "receive.inheritProjectMaxObjectSizeLimit", value = "true")
public void maxObjectSizeIsInheritedFromParentProject() throws Exception {
    // Default for createEmptyCommit should match TestProjectConfig.
    Project.NameKey child = projectOperations.newProject().parent(project).create();
    ConfigInfo info = setMaxObjectSize("100k");
    assertThat(info.maxObjectSizeLimit.value).isEqualTo("102400");
    assertThat(info.maxObjectSizeLimit.configuredValue).isEqualTo("100k");
    assertThat(info.maxObjectSizeLimit.summary).isNull();
    info = getConfig(child);
    assertThat(info.maxObjectSizeLimit.value).isEqualTo("102400");
    assertThat(info.maxObjectSizeLimit.configuredValue).isNull();
    assertThat(info.maxObjectSizeLimit.summary).isEqualTo(String.format(INHERITED_FROM_PARENT, project));
}
#method_after
@Test
@GerritConfig(name = "receive.inheritProjectMaxObjectSizeLimit", value = "true")
public void maxObjectSizeIsInheritedFromParentProject() throws Exception {
    Project.NameKey child = projectOperations.newProject().parent(project).create();
    ConfigInfo info = setMaxObjectSize("100k");
    assertThat(info.maxObjectSizeLimit.value).isEqualTo("102400");
    assertThat(info.maxObjectSizeLimit.configuredValue).isEqualTo("100k");
    assertThat(info.maxObjectSizeLimit.summary).isNull();
    info = getConfig(child);
    assertThat(info.maxObjectSizeLimit.value).isEqualTo("102400");
    assertThat(info.maxObjectSizeLimit.configuredValue).isNull();
    assertThat(info.maxObjectSizeLimit.summary).isEqualTo(String.format(INHERITED_FROM_PARENT, project));
}
#end_block

#method_before
@Test
public void maxObjectSizeIsNotInheritedFromParentProject() throws Exception {
    // Default for createEmptyCommit should match TestProjectConfig.
    Project.NameKey child = projectOperations.newProject().parent(project).create();
    ConfigInfo info = setMaxObjectSize("100k");
    assertThat(info.maxObjectSizeLimit.value).isEqualTo("102400");
    assertThat(info.maxObjectSizeLimit.configuredValue).isEqualTo("100k");
    assertThat(info.maxObjectSizeLimit.summary).isNull();
    info = getConfig(child);
    assertThat(info.maxObjectSizeLimit.value).isNull();
    assertThat(info.maxObjectSizeLimit.configuredValue).isNull();
    assertThat(info.maxObjectSizeLimit.summary).isNull();
}
#method_after
@Test
public void maxObjectSizeIsNotInheritedFromParentProject() throws Exception {
    Project.NameKey child = projectOperations.newProject().parent(project).create();
    ConfigInfo info = setMaxObjectSize("100k");
    assertThat(info.maxObjectSizeLimit.value).isEqualTo("102400");
    assertThat(info.maxObjectSizeLimit.configuredValue).isEqualTo("100k");
    assertThat(info.maxObjectSizeLimit.summary).isNull();
    info = getConfig(child);
    assertThat(info.maxObjectSizeLimit.value).isNull();
    assertThat(info.maxObjectSizeLimit.configuredValue).isNull();
    assertThat(info.maxObjectSizeLimit.summary).isNull();
}
#end_block

#method_before
@Test
public void maxObjectSizeOverridesParentProjectWhenNotSetOnParent() throws Exception {
    // Default for createEmptyCommit should match TestProjectConfig.
    Project.NameKey child = projectOperations.newProject().parent(project).create();
    ConfigInfo info = setMaxObjectSize("0");
    assertThat(info.maxObjectSizeLimit.value).isNull();
    assertThat(info.maxObjectSizeLimit.configuredValue).isNull();
    assertThat(info.maxObjectSizeLimit.summary).isNull();
    info = setMaxObjectSize(child, "100k");
    assertThat(info.maxObjectSizeLimit.value).isEqualTo("102400");
    assertThat(info.maxObjectSizeLimit.configuredValue).isEqualTo("100k");
    assertThat(info.maxObjectSizeLimit.summary).isNull();
}
#method_after
@Test
public void maxObjectSizeOverridesParentProjectWhenNotSetOnParent() throws Exception {
    Project.NameKey child = projectOperations.newProject().parent(project).create();
    ConfigInfo info = setMaxObjectSize("0");
    assertThat(info.maxObjectSizeLimit.value).isNull();
    assertThat(info.maxObjectSizeLimit.configuredValue).isNull();
    assertThat(info.maxObjectSizeLimit.summary).isNull();
    info = setMaxObjectSize(child, "100k");
    assertThat(info.maxObjectSizeLimit.value).isEqualTo("102400");
    assertThat(info.maxObjectSizeLimit.configuredValue).isEqualTo("100k");
    assertThat(info.maxObjectSizeLimit.summary).isNull();
}
#end_block

#method_before
@Test
public void maxObjectSizeOverridesParentProjectWhenLower() throws Exception {
    // Default for createEmptyCommit should match TestProjectConfig.
    Project.NameKey child = projectOperations.newProject().parent(project).create();
    ConfigInfo info = setMaxObjectSize("200k");
    assertThat(info.maxObjectSizeLimit.value).isEqualTo("204800");
    assertThat(info.maxObjectSizeLimit.configuredValue).isEqualTo("200k");
    assertThat(info.maxObjectSizeLimit.summary).isNull();
    info = setMaxObjectSize(child, "100k");
    assertThat(info.maxObjectSizeLimit.value).isEqualTo("102400");
    assertThat(info.maxObjectSizeLimit.configuredValue).isEqualTo("100k");
    assertThat(info.maxObjectSizeLimit.summary).isNull();
}
#method_after
@Test
public void maxObjectSizeOverridesParentProjectWhenLower() throws Exception {
    Project.NameKey child = projectOperations.newProject().parent(project).create();
    ConfigInfo info = setMaxObjectSize("200k");
    assertThat(info.maxObjectSizeLimit.value).isEqualTo("204800");
    assertThat(info.maxObjectSizeLimit.configuredValue).isEqualTo("200k");
    assertThat(info.maxObjectSizeLimit.summary).isNull();
    info = setMaxObjectSize(child, "100k");
    assertThat(info.maxObjectSizeLimit.value).isEqualTo("102400");
    assertThat(info.maxObjectSizeLimit.configuredValue).isEqualTo("100k");
    assertThat(info.maxObjectSizeLimit.summary).isNull();
}
#end_block

#method_before
@Test
@GerritConfig(name = "receive.inheritProjectMaxObjectSizeLimit", value = "true")
public void maxObjectSizeDoesNotOverrideParentProjectWhenHigher() throws Exception {
    // Default for createEmptyCommit should match TestProjectConfig.
    Project.NameKey child = projectOperations.newProject().parent(project).create();
    ConfigInfo info = setMaxObjectSize("100k");
    assertThat(info.maxObjectSizeLimit.value).isEqualTo("102400");
    assertThat(info.maxObjectSizeLimit.configuredValue).isEqualTo("100k");
    assertThat(info.maxObjectSizeLimit.summary).isNull();
    info = setMaxObjectSize(child, "200k");
    assertThat(info.maxObjectSizeLimit.value).isEqualTo("102400");
    assertThat(info.maxObjectSizeLimit.configuredValue).isEqualTo("200k");
    assertThat(info.maxObjectSizeLimit.summary).isEqualTo(String.format(OVERRIDDEN_BY_PARENT, project));
}
#method_after
@Test
@GerritConfig(name = "receive.inheritProjectMaxObjectSizeLimit", value = "true")
public void maxObjectSizeDoesNotOverrideParentProjectWhenHigher() throws Exception {
    Project.NameKey child = projectOperations.newProject().parent(project).create();
    ConfigInfo info = setMaxObjectSize("100k");
    assertThat(info.maxObjectSizeLimit.value).isEqualTo("102400");
    assertThat(info.maxObjectSizeLimit.configuredValue).isEqualTo("100k");
    assertThat(info.maxObjectSizeLimit.summary).isNull();
    info = setMaxObjectSize(child, "200k");
    assertThat(info.maxObjectSizeLimit.value).isEqualTo("102400");
    assertThat(info.maxObjectSizeLimit.configuredValue).isEqualTo("200k");
    assertThat(info.maxObjectSizeLimit.summary).isEqualTo(String.format(OVERRIDDEN_BY_PARENT, project));
}
#end_block

#method_before
@Test
@GerritConfig(name = "receive.maxObjectSizeLimit", value = "200k")
public void maxObjectSizeIsInheritedFromGlobalConfig() throws Exception {
    // Default for createEmptyCommit should match TestProjectConfig.
    Project.NameKey child = projectOperations.newProject().parent(project).create();
    ConfigInfo info = getConfig();
    assertThat(info.maxObjectSizeLimit.value).isEqualTo("204800");
    assertThat(info.maxObjectSizeLimit.configuredValue).isNull();
    assertThat(info.maxObjectSizeLimit.summary).isEqualTo(INHERITED_FROM_GLOBAL);
    info = getConfig(child);
    assertThat(info.maxObjectSizeLimit.value).isEqualTo("204800");
    assertThat(info.maxObjectSizeLimit.configuredValue).isNull();
    assertThat(info.maxObjectSizeLimit.summary).isEqualTo(INHERITED_FROM_GLOBAL);
}
#method_after
@Test
@GerritConfig(name = "receive.maxObjectSizeLimit", value = "200k")
public void maxObjectSizeIsInheritedFromGlobalConfig() throws Exception {
    Project.NameKey child = projectOperations.newProject().parent(project).create();
    ConfigInfo info = getConfig();
    assertThat(info.maxObjectSizeLimit.value).isEqualTo("204800");
    assertThat(info.maxObjectSizeLimit.configuredValue).isNull();
    assertThat(info.maxObjectSizeLimit.summary).isEqualTo(INHERITED_FROM_GLOBAL);
    info = getConfig(child);
    assertThat(info.maxObjectSizeLimit.value).isEqualTo("204800");
    assertThat(info.maxObjectSizeLimit.configuredValue).isNull();
    assertThat(info.maxObjectSizeLimit.summary).isEqualTo(INHERITED_FROM_GLOBAL);
}
#end_block

#method_before
@Test
@GerritConfig(name = "receive.maxObjectSizeLimit", value = "300k")
public void inheritedMaxObjectSizeOverridesGlobalConfigWhenLower() throws Exception {
    // Default for createEmptyCommit should match TestProjectConfig.
    Project.NameKey child = projectOperations.newProject().parent(project).create();
    ConfigInfo info = setMaxObjectSize("200k");
    assertThat(info.maxObjectSizeLimit.value).isEqualTo("204800");
    assertThat(info.maxObjectSizeLimit.configuredValue).isEqualTo("200k");
    assertThat(info.maxObjectSizeLimit.summary).isNull();
    info = setMaxObjectSize(child, "100k");
    assertThat(info.maxObjectSizeLimit.value).isEqualTo("102400");
    assertThat(info.maxObjectSizeLimit.configuredValue).isEqualTo("100k");
    assertThat(info.maxObjectSizeLimit.summary).isNull();
}
#method_after
@Test
@GerritConfig(name = "receive.maxObjectSizeLimit", value = "300k")
public void inheritedMaxObjectSizeOverridesGlobalConfigWhenLower() throws Exception {
    Project.NameKey child = projectOperations.newProject().parent(project).create();
    ConfigInfo info = setMaxObjectSize("200k");
    assertThat(info.maxObjectSizeLimit.value).isEqualTo("204800");
    assertThat(info.maxObjectSizeLimit.configuredValue).isEqualTo("200k");
    assertThat(info.maxObjectSizeLimit.summary).isNull();
    info = setMaxObjectSize(child, "100k");
    assertThat(info.maxObjectSizeLimit.value).isEqualTo("102400");
    assertThat(info.maxObjectSizeLimit.configuredValue).isEqualTo("100k");
    assertThat(info.maxObjectSizeLimit.summary).isNull();
}
#end_block

#method_before
@Test
@GerritConfig(name = "receive.maxObjectSizeLimit", value = "200k")
@GerritConfig(name = "receive.inheritProjectMaxObjectSizeLimit", value = "true")
public void maxObjectSizeDoesNotOverrideGlobalConfigWhenHigher() throws Exception {
    // Default for createEmptyCommit should match TestProjectConfig.
    Project.NameKey child = projectOperations.newProject().parent(project).create();
    ConfigInfo info = setMaxObjectSize("300k");
    assertThat(info.maxObjectSizeLimit.value).isEqualTo("204800");
    assertThat(info.maxObjectSizeLimit.configuredValue).isEqualTo("300k");
    assertThat(info.maxObjectSizeLimit.summary).isEqualTo(OVERRIDDEN_BY_GLOBAL);
    info = getConfig(child);
    assertThat(info.maxObjectSizeLimit.value).isEqualTo("204800");
    assertThat(info.maxObjectSizeLimit.configuredValue).isNull();
    assertThat(info.maxObjectSizeLimit.summary).isEqualTo(OVERRIDDEN_BY_GLOBAL);
}
#method_after
@Test
@GerritConfig(name = "receive.maxObjectSizeLimit", value = "200k")
@GerritConfig(name = "receive.inheritProjectMaxObjectSizeLimit", value = "true")
public void maxObjectSizeDoesNotOverrideGlobalConfigWhenHigher() throws Exception {
    Project.NameKey child = projectOperations.newProject().parent(project).create();
    ConfigInfo info = setMaxObjectSize("300k");
    assertThat(info.maxObjectSizeLimit.value).isEqualTo("204800");
    assertThat(info.maxObjectSizeLimit.configuredValue).isEqualTo("300k");
    assertThat(info.maxObjectSizeLimit.summary).isEqualTo(OVERRIDDEN_BY_GLOBAL);
    info = getConfig(child);
    assertThat(info.maxObjectSizeLimit.value).isEqualTo("204800");
    assertThat(info.maxObjectSizeLimit.configuredValue).isNull();
    assertThat(info.maxObjectSizeLimit.summary).isEqualTo(OVERRIDDEN_BY_GLOBAL);
}
#end_block

#method_before
@Test
public void childProjectEndpoints() throws Exception {
    // Default for createEmptyCommit should match TestProjectConfig.
    Project.NameKey childProject = projectOperations.newProject().parent(project).create();
    RestApiCallHelper.execute(adminRestSession, CHILD_PROJECT_ENDPOINTS, project.get(), childProject.get());
}
#method_after
@Test
public void childProjectEndpoints() throws Exception {
    Project.NameKey childProject = projectOperations.newProject().parent(project).create();
    RestApiCallHelper.execute(adminRestSession, CHILD_PROJECT_ENDPOINTS, project.get(), childProject.get());
}
#end_block

#method_before
@Test
public void testChangeOwner_OwnerACLGrantedOnParentProject() throws Exception {
    setApiUser(admin);
    grantApproveToChangeOwner(project);
    // Default for createEmptyCommit should match TestProjectConfig.
    Project.NameKey child = projectOperations.newProject().parent(project).create();
    setApiUser(user);
    TestRepository<InMemoryRepository> childRepo = cloneProject(child, user);
    approve(user, createMyChange(childRepo));
}
#method_after
@Test
public void testChangeOwner_OwnerACLGrantedOnParentProject() throws Exception {
    setApiUser(admin);
    grantApproveToChangeOwner(project);
    Project.NameKey child = projectOperations.newProject().parent(project).create();
    setApiUser(user);
    TestRepository<InMemoryRepository> childRepo = cloneProject(child, user);
    approve(user, createMyChange(childRepo));
}
#end_block

#method_before
@Test
public void testChangeOwner_BlockedOnParentProject() throws Exception {
    setApiUser(admin);
    blockApproveForChangeOwner(project);
    // Default for createEmptyCommit should match TestProjectConfig.
    Project.NameKey child = projectOperations.newProject().parent(project).create();
    setApiUser(user);
    grantApproveToAll(child);
    TestRepository<InMemoryRepository> childRepo = cloneProject(child, user);
    String changeId = createMyChange(childRepo);
    // change owner cannot approve because Change-Owner group is blocked on parent
    assertApproveFails(user, changeId);
    // other user can approve
    approve(user2, changeId);
}
#method_after
@Test
public void testChangeOwner_BlockedOnParentProject() throws Exception {
    setApiUser(admin);
    blockApproveForChangeOwner(project);
    Project.NameKey child = projectOperations.newProject().parent(project).create();
    setApiUser(user);
    grantApproveToAll(child);
    TestRepository<InMemoryRepository> childRepo = cloneProject(child, user);
    String changeId = createMyChange(childRepo);
    // change owner cannot approve because Change-Owner group is blocked on parent
    assertApproveFails(user, changeId);
    // other user can approve
    approve(user2, changeId);
}
#end_block

#method_before
@Test
public void testChangeOwner_BlockedOnParentProjectAndExclusiveAllowOnChild() throws Exception {
    setApiUser(admin);
    blockApproveForChangeOwner(project);
    // Default for createEmptyCommit should match TestProjectConfig.
    Project.NameKey child = projectOperations.newProject().parent(project).create();
    setApiUser(user);
    grantExclusiveApproveToAll(child);
    TestRepository<InMemoryRepository> childRepo = cloneProject(child, user);
    String changeId = createMyChange(childRepo);
    // change owner cannot approve because Change-Owner group is blocked on parent
    assertApproveFails(user, changeId);
    // other user can approve
    approve(user2, changeId);
}
#method_after
@Test
public void testChangeOwner_BlockedOnParentProjectAndExclusiveAllowOnChild() throws Exception {
    setApiUser(admin);
    blockApproveForChangeOwner(project);
    Project.NameKey child = projectOperations.newProject().parent(project).create();
    setApiUser(user);
    grantExclusiveApproveToAll(child);
    TestRepository<InMemoryRepository> childRepo = cloneProject(child, user);
    String changeId = createMyChange(childRepo);
    // change owner cannot approve because Change-Owner group is blocked on parent
    assertApproveFails(user, changeId);
    // other user can approve
    approve(user2, changeId);
}
#end_block

#method_before
@Test
public void getGrandChildProject_NotFound() throws Exception {
    Project.NameKey child = projectOperations.newProject().create();
    // Default for createEmptyCommit should match TestProjectConfig.
    Project.NameKey grandChild = this.projectOperations.newProject().parent(child).create();
    assertChildNotFound(allProjects, grandChild.get());
}
#method_after
@Test
public void getGrandChildProject_NotFound() throws Exception {
    Project.NameKey child = projectOperations.newProject().create();
    Project.NameKey grandChild = this.projectOperations.newProject().parent(child).create();
    assertChildNotFound(allProjects, grandChild.get());
}
#end_block

#method_before
@Test
public void getGrandChildProjectWithRecursiveFlag() throws Exception {
    Project.NameKey child = projectOperations.newProject().create();
    // Default for createEmptyCommit should match TestProjectConfig.
    Project.NameKey grandChild = this.projectOperations.newProject().parent(child).create();
    ProjectInfo grandChildInfo = gApi.projects().name(allProjects.get()).child(grandChild.get()).get(true);
    assertProjectInfo(projectCache.get(grandChild).getProject(), grandChildInfo);
}
#method_after
@Test
public void getGrandChildProjectWithRecursiveFlag() throws Exception {
    Project.NameKey child = projectOperations.newProject().create();
    Project.NameKey grandChild = this.projectOperations.newProject().parent(child).create();
    ProjectInfo grandChildInfo = gApi.projects().name(allProjects.get()).child(grandChild.get()).get(true);
    assertProjectInfo(projectCache.get(grandChild).getProject(), grandChildInfo);
}
#end_block

#method_before
@Test
public void setParentNotAllowed() throws Exception {
    String parent = this.projectOperations.newProject().createEmptyCommit(true).create().get();
    setApiUser(user);
    exception.expect(AuthException.class);
    gApi.projects().name(project.get()).parent(parent);
}
#method_after
@Test
public void setParentNotAllowed() throws Exception {
    String parent = this.projectOperations.newProject().create().get();
    setApiUser(user);
    exception.expect(AuthException.class);
    gApi.projects().name(project.get()).parent(parent);
}
#end_block

#method_before
@Test
@GerritConfig(name = "receive.allowProjectOwnersToChangeParent", value = "true")
public void setParentNotAllowedForNonOwners() throws Exception {
    String parent = this.projectOperations.newProject().createEmptyCommit(true).create().get();
    setApiUser(user);
    exception.expect(AuthException.class);
    gApi.projects().name(project.get()).parent(parent);
}
#method_after
@Test
@GerritConfig(name = "receive.allowProjectOwnersToChangeParent", value = "true")
public void setParentNotAllowedForNonOwners() throws Exception {
    String parent = this.projectOperations.newProject().create().get();
    setApiUser(user);
    exception.expect(AuthException.class);
    gApi.projects().name(project.get()).parent(parent);
}
#end_block

#method_before
@Test
@GerritConfig(name = "receive.allowProjectOwnersToChangeParent", value = "true")
public void setParentAllowedByAdminWhenAllowProjectOwnersEnabled() throws Exception {
    String parent = this.projectOperations.newProject().createEmptyCommit(true).create().get();
    gApi.projects().name(project.get()).parent(parent);
    assertThat(gApi.projects().name(project.get()).parent()).isEqualTo(parent);
    // When the parent name is not explicitly set, it should be
    // set to "All-Projects".
    gApi.projects().name(project.get()).parent(null);
    assertThat(gApi.projects().name(project.get()).parent()).isEqualTo(AllProjectsNameProvider.DEFAULT);
}
#method_after
@Test
@GerritConfig(name = "receive.allowProjectOwnersToChangeParent", value = "true")
public void setParentAllowedByAdminWhenAllowProjectOwnersEnabled() throws Exception {
    String parent = this.projectOperations.newProject().create().get();
    gApi.projects().name(project.get()).parent(parent);
    assertThat(gApi.projects().name(project.get()).parent()).isEqualTo(parent);
    // When the parent name is not explicitly set, it should be
    // set to "All-Projects".
    gApi.projects().name(project.get()).parent(null);
    assertThat(gApi.projects().name(project.get()).parent()).isEqualTo(AllProjectsNameProvider.DEFAULT);
}
#end_block

#method_before
@Test
@GerritConfig(name = "receive.allowProjectOwnersToChangeParent", value = "true")
public void setParentAllowedForOwners() throws Exception {
    String parent = this.projectOperations.newProject().createEmptyCommit(true).create().get();
    setApiUser(user);
    grant(project, "refs/*", Permission.OWNER, false, SystemGroupBackend.REGISTERED_USERS);
    gApi.projects().name(project.get()).parent(parent);
    assertThat(gApi.projects().name(project.get()).parent()).isEqualTo(parent);
}
#method_after
@Test
@GerritConfig(name = "receive.allowProjectOwnersToChangeParent", value = "true")
public void setParentAllowedForOwners() throws Exception {
    String parent = this.projectOperations.newProject().create().get();
    setApiUser(user);
    grant(project, "refs/*", Permission.OWNER, false, SystemGroupBackend.REGISTERED_USERS);
    gApi.projects().name(project.get()).parent(parent);
    assertThat(gApi.projects().name(project.get()).parent()).isEqualTo(parent);
}
#end_block

#method_before
@Test
public void setParent() throws Exception {
    String parent = this.projectOperations.newProject().createEmptyCommit(true).create().get();
    gApi.projects().name(project.get()).parent(parent);
    assertThat(gApi.projects().name(project.get()).parent()).isEqualTo(parent);
    // When the parent name is not explicitly set, it should be
    // set to "All-Projects".
    gApi.projects().name(project.get()).parent(null);
    assertThat(gApi.projects().name(project.get()).parent()).isEqualTo(AllProjectsNameProvider.DEFAULT);
}
#method_after
@Test
public void setParent() throws Exception {
    String parent = this.projectOperations.newProject().create().get();
    gApi.projects().name(project.get()).parent(parent);
    assertThat(gApi.projects().name(project.get()).parent()).isEqualTo(parent);
    // When the parent name is not explicitly set, it should be
    // set to "All-Projects".
    gApi.projects().name(project.get()).parent(null);
    assertThat(gApi.projects().name(project.get()).parent()).isEqualTo(AllProjectsNameProvider.DEFAULT);
}
#end_block

#method_before
@Test
public void setParentToOwnChildNotAllowed() throws Exception {
    String child = projectOperations.newProject().parent(project).createEmptyCommit(true).create().get();
    exception.expect(ResourceConflictException.class);
    exception.expectMessage("cycle exists between");
    gApi.projects().name(project.get()).parent(child);
}
#method_after
@Test
public void setParentToOwnChildNotAllowed() throws Exception {
    String child = projectOperations.newProject().parent(project).create().get();
    exception.expect(ResourceConflictException.class);
    exception.expectMessage("cycle exists between");
    gApi.projects().name(project.get()).parent(child);
}
#end_block

#method_before
@Test
public void setParentToGrandchildNotAllowed() throws Exception {
    Project.NameKey child = this.projectOperations.newProject().parent(project).createEmptyCommit(true).create();
    String grandchild = this.projectOperations.newProject().parent(child).createEmptyCommit(true).create().get();
    exception.expect(ResourceConflictException.class);
    exception.expectMessage("cycle exists between");
    gApi.projects().name(project.get()).parent(grandchild);
}
#method_after
@Test
public void setParentToGrandchildNotAllowed() throws Exception {
    Project.NameKey child = this.projectOperations.newProject().parent(project).create();
    String grandchild = this.projectOperations.newProject().parent(child).create().get();
    exception.expect(ResourceConflictException.class);
    exception.expectMessage("cycle exists between");
    gApi.projects().name(project.get()).parent(grandchild);
}
#end_block

#method_before
@Test
public void setParentForAllUsersMustBeAllProjects() throws Exception {
    gApi.projects().name(allUsers.get()).parent(allProjects.get());
    String parent = this.projectOperations.newProject().createEmptyCommit(true).create().get();
    exception.expect(BadRequestException.class);
    exception.expectMessage("All-Users must inherit from All-Projects");
    gApi.projects().name(allUsers.get()).parent(parent);
}
#method_after
@Test
public void setParentForAllUsersMustBeAllProjects() throws Exception {
    gApi.projects().name(allUsers.get()).parent(allProjects.get());
    String parent = this.projectOperations.newProject().create().get();
    exception.expect(BadRequestException.class);
    exception.expectMessage("All-Users must inherit from All-Projects");
    gApi.projects().name(allUsers.get()).parent(parent);
}
#end_block

#method_before
@Test
public void withInheritance() throws Exception {
    String configName = "test.config";
    Config parentCfg = new Config();
    parentCfg.setString("s1", null, "k1", "parentValue1");
    parentCfg.setString("s1", null, "k2", "parentValue2");
    parentCfg.setString("s2", "ss", "k3", "parentValue3");
    parentCfg.setString("s2", "ss", "k4", "parentValue4");
    pushFactory.create(db, admin.getIdent(), testRepo, "Create Project Level Config", configName, parentCfg.toText()).to(RefNames.REFS_CONFIG).assertOkStatus();
    // Default for createEmptyCommit should match TestProjectConfig.
    Project.NameKey childProject = projectOperations.newProject().parent(project).create();
    TestRepository<?> childTestRepo = cloneProject(childProject);
    fetch(childTestRepo, RefNames.REFS_CONFIG + ":refs/heads/config");
    childTestRepo.reset("refs/heads/config");
    Config cfg = new Config();
    cfg.setString("s1", null, "k1", "childValue1");
    cfg.setString("s2", "ss", "k3", "childValue2");
    pushFactory.create(db, admin.getIdent(), childTestRepo, "Create Project Level Config", configName, cfg.toText()).to(RefNames.REFS_CONFIG).assertOkStatus();
    ProjectState state = projectCache.get(childProject);
    Config expectedCfg = new Config();
    expectedCfg.setString("s1", null, "k1", "childValue1");
    expectedCfg.setString("s1", null, "k2", "parentValue2");
    expectedCfg.setString("s2", "ss", "k3", "childValue2");
    expectedCfg.setString("s2", "ss", "k4", "parentValue4");
    assertThat(state.getConfig(configName).getWithInheritance().toText()).isEqualTo(expectedCfg.toText());
    assertThat(state.getConfig(configName).get().toText()).isEqualTo(cfg.toText());
}
#method_after
@Test
public void withInheritance() throws Exception {
    String configName = "test.config";
    Config parentCfg = new Config();
    parentCfg.setString("s1", null, "k1", "parentValue1");
    parentCfg.setString("s1", null, "k2", "parentValue2");
    parentCfg.setString("s2", "ss", "k3", "parentValue3");
    parentCfg.setString("s2", "ss", "k4", "parentValue4");
    pushFactory.create(db, admin.getIdent(), testRepo, "Create Project Level Config", configName, parentCfg.toText()).to(RefNames.REFS_CONFIG).assertOkStatus();
    Project.NameKey childProject = projectOperations.newProject().parent(project).create();
    TestRepository<?> childTestRepo = cloneProject(childProject);
    fetch(childTestRepo, RefNames.REFS_CONFIG + ":refs/heads/config");
    childTestRepo.reset("refs/heads/config");
    Config cfg = new Config();
    cfg.setString("s1", null, "k1", "childValue1");
    cfg.setString("s2", "ss", "k3", "childValue2");
    pushFactory.create(db, admin.getIdent(), childTestRepo, "Create Project Level Config", configName, cfg.toText()).to(RefNames.REFS_CONFIG).assertOkStatus();
    ProjectState state = projectCache.get(childProject);
    Config expectedCfg = new Config();
    expectedCfg.setString("s1", null, "k1", "childValue1");
    expectedCfg.setString("s1", null, "k2", "parentValue2");
    expectedCfg.setString("s2", "ss", "k3", "childValue2");
    expectedCfg.setString("s2", "ss", "k4", "parentValue4");
    assertThat(state.getConfig(configName).getWithInheritance().toText()).isEqualTo(expectedCfg.toText());
    assertThat(state.getConfig(configName).get().toText()).isEqualTo(cfg.toText());
}
#end_block

#method_before
@Test
public void withMergedInheritance() throws Exception {
    String configName = "test.config";
    Config parentCfg = new Config();
    parentCfg.setString("s1", null, "k1", "parentValue1");
    parentCfg.setString("s1", null, "k2", "parentValue2");
    parentCfg.setString("s2", "ss", "k3", "parentValue3");
    parentCfg.setString("s2", "ss", "k4", "parentValue4");
    pushFactory.create(db, admin.getIdent(), testRepo, "Create Project Level Config", configName, parentCfg.toText()).to(RefNames.REFS_CONFIG).assertOkStatus();
    // Default for createEmptyCommit should match TestProjectConfig.
    Project.NameKey childProject = projectOperations.newProject().parent(project).create();
    TestRepository<?> childTestRepo = cloneProject(childProject);
    fetch(childTestRepo, RefNames.REFS_CONFIG + ":refs/heads/config");
    childTestRepo.reset("refs/heads/config");
    Config cfg = new Config();
    cfg.setString("s1", null, "k1", "parentValue1");
    cfg.setString("s1", null, "k2", "parentValue2");
    cfg.setString("s2", "ss", "k3", "parentValue3");
    cfg.setString("s2", "ss", "k4", "parentValue4");
    cfg.setString("s1", null, "k1", "childValue1");
    cfg.setString("s2", "ss", "k3", "childValue2");
    cfg.setString("s3", null, "k5", "childValue3");
    cfg.setString("s3", "ss", "k6", "childValue4");
    pushFactory.create(db, admin.getIdent(), childTestRepo, "Create Project Level Config", configName, cfg.toText()).to(RefNames.REFS_CONFIG).assertOkStatus();
    ProjectState state = projectCache.get(childProject);
    Config expectedCfg = new Config();
    expectedCfg.setStringList("s1", null, "k1", Arrays.asList("childValue1", "parentValue1"));
    expectedCfg.setString("s1", null, "k2", "parentValue2");
    expectedCfg.setStringList("s2", "ss", "k3", Arrays.asList("childValue2", "parentValue3"));
    expectedCfg.setString("s2", "ss", "k4", "parentValue4");
    expectedCfg.setString("s3", null, "k5", "childValue3");
    expectedCfg.setString("s3", "ss", "k6", "childValue4");
    assertThat(state.getConfig(configName).getWithInheritance(true).toText()).isEqualTo(expectedCfg.toText());
    assertThat(state.getConfig(configName).get().toText()).isEqualTo(cfg.toText());
}
#method_after
@Test
public void withMergedInheritance() throws Exception {
    String configName = "test.config";
    Config parentCfg = new Config();
    parentCfg.setString("s1", null, "k1", "parentValue1");
    parentCfg.setString("s1", null, "k2", "parentValue2");
    parentCfg.setString("s2", "ss", "k3", "parentValue3");
    parentCfg.setString("s2", "ss", "k4", "parentValue4");
    pushFactory.create(db, admin.getIdent(), testRepo, "Create Project Level Config", configName, parentCfg.toText()).to(RefNames.REFS_CONFIG).assertOkStatus();
    Project.NameKey childProject = projectOperations.newProject().parent(project).create();
    TestRepository<?> childTestRepo = cloneProject(childProject);
    fetch(childTestRepo, RefNames.REFS_CONFIG + ":refs/heads/config");
    childTestRepo.reset("refs/heads/config");
    Config cfg = new Config();
    cfg.setString("s1", null, "k1", "parentValue1");
    cfg.setString("s1", null, "k2", "parentValue2");
    cfg.setString("s2", "ss", "k3", "parentValue3");
    cfg.setString("s2", "ss", "k4", "parentValue4");
    cfg.setString("s1", null, "k1", "childValue1");
    cfg.setString("s2", "ss", "k3", "childValue2");
    cfg.setString("s3", null, "k5", "childValue3");
    cfg.setString("s3", "ss", "k6", "childValue4");
    pushFactory.create(db, admin.getIdent(), childTestRepo, "Create Project Level Config", configName, cfg.toText()).to(RefNames.REFS_CONFIG).assertOkStatus();
    ProjectState state = projectCache.get(childProject);
    Config expectedCfg = new Config();
    expectedCfg.setStringList("s1", null, "k1", Arrays.asList("childValue1", "parentValue1"));
    expectedCfg.setString("s1", null, "k2", "parentValue2");
    expectedCfg.setStringList("s2", "ss", "k3", Arrays.asList("childValue2", "parentValue3"));
    expectedCfg.setString("s2", "ss", "k4", "parentValue4");
    expectedCfg.setString("s3", null, "k5", "childValue3");
    expectedCfg.setString("s3", "ss", "k6", "childValue4");
    assertThat(state.getConfig(configName).getWithInheritance(true).toText()).isEqualTo(expectedCfg.toText());
    assertThat(state.getConfig(configName).get().toText()).isEqualTo(cfg.toText());
}
#end_block

#method_before
@Test
public void supportedVersion() throws Exception {
    assertThat(ElasticVersion.forVersion("5.6.0")).isEqualTo(ElasticVersion.V5_6);
    assertThat(ElasticVersion.forVersion("5.6.11")).isEqualTo(ElasticVersion.V5_6);
    assertThat(ElasticVersion.forVersion("6.2.0")).isEqualTo(ElasticVersion.V6_2);
    assertThat(ElasticVersion.forVersion("6.2.4")).isEqualTo(ElasticVersion.V6_2);
    assertThat(ElasticVersion.forVersion("6.3.0")).isEqualTo(ElasticVersion.V6_3);
    assertThat(ElasticVersion.forVersion("6.3.2")).isEqualTo(ElasticVersion.V6_3);
    assertThat(ElasticVersion.forVersion("6.4.0")).isEqualTo(ElasticVersion.V6_4);
    assertThat(ElasticVersion.forVersion("6.4.1")).isEqualTo(ElasticVersion.V6_4);
    assertThat(ElasticVersion.forVersion("6.5.0")).isEqualTo(ElasticVersion.V6_5);
    assertThat(ElasticVersion.forVersion("6.5.1")).isEqualTo(ElasticVersion.V6_5);
}
#method_after
@Test
public void supportedVersion() throws Exception {
    assertThat(ElasticVersion.forVersion("5.6.0")).isEqualTo(ElasticVersion.V5_6);
    assertThat(ElasticVersion.forVersion("5.6.11")).isEqualTo(ElasticVersion.V5_6);
    assertThat(ElasticVersion.forVersion("6.2.0")).isEqualTo(ElasticVersion.V6_2);
    assertThat(ElasticVersion.forVersion("6.2.4")).isEqualTo(ElasticVersion.V6_2);
    assertThat(ElasticVersion.forVersion("6.3.0")).isEqualTo(ElasticVersion.V6_3);
    assertThat(ElasticVersion.forVersion("6.3.2")).isEqualTo(ElasticVersion.V6_3);
    assertThat(ElasticVersion.forVersion("6.4.0")).isEqualTo(ElasticVersion.V6_4);
    assertThat(ElasticVersion.forVersion("6.4.1")).isEqualTo(ElasticVersion.V6_4);
    assertThat(ElasticVersion.forVersion("6.5.0")).isEqualTo(ElasticVersion.V6_5);
    assertThat(ElasticVersion.forVersion("6.5.1")).isEqualTo(ElasticVersion.V6_5);
    assertThat(ElasticVersion.forVersion("7.0.0")).isEqualTo(ElasticVersion.V7_0);
    assertThat(ElasticVersion.forVersion("7.0.1")).isEqualTo(ElasticVersion.V7_0);
}
#end_block

#method_before
@Override
protected Injector createInjector() {
    Config elasticsearchConfig = new Config(config);
    InMemoryModule.setDefaults(elasticsearchConfig);
    String indicesPrefix = testName();
    ElasticTestUtils.configure(elasticsearchConfig, nodeInfo.port, indicesPrefix);
    return Guice.createInjector(new InMemoryModule(elasticsearchConfig, notesMigration));
}
#method_after
@Override
protected Injector createInjector() {
    Config elasticsearchConfig = new Config(config);
    InMemoryModule.setDefaults(elasticsearchConfig);
    String indicesPrefix = getSanitizedMethodName();
    ElasticTestUtils.configure(elasticsearchConfig, nodeInfo.port, indicesPrefix);
    return Guice.createInjector(new InMemoryModule(elasticsearchConfig, notesMigration));
}
#end_block

#method_before
@Override
protected Injector createInjector() {
    Config elasticsearchConfig = new Config(config);
    InMemoryModule.setDefaults(elasticsearchConfig);
    String indicesPrefix = testName();
    ElasticTestUtils.configure(elasticsearchConfig, nodeInfo.port, indicesPrefix);
    return Guice.createInjector(new InMemoryModule(elasticsearchConfig, notesMigration));
}
#method_after
@Override
protected Injector createInjector() {
    Config elasticsearchConfig = new Config(config);
    InMemoryModule.setDefaults(elasticsearchConfig);
    String indicesPrefix = getSanitizedMethodName();
    ElasticTestUtils.configure(elasticsearchConfig, nodeInfo.port, indicesPrefix);
    return Guice.createInjector(new InMemoryModule(elasticsearchConfig, notesMigration));
}
#end_block

#method_before
@Override
protected Injector createInjector() {
    Config elasticsearchConfig = new Config(config);
    InMemoryModule.setDefaults(elasticsearchConfig);
    String indicesPrefix = testName();
    ElasticTestUtils.configure(elasticsearchConfig, nodeInfo.port, indicesPrefix);
    return Guice.createInjector(new InMemoryModule(elasticsearchConfig, notesMigration));
}
#method_after
@Override
protected Injector createInjector() {
    Config elasticsearchConfig = new Config(config);
    InMemoryModule.setDefaults(elasticsearchConfig);
    String indicesPrefix = getSanitizedMethodName();
    ElasticTestUtils.configure(elasticsearchConfig, nodeInfo.port, indicesPrefix);
    return Guice.createInjector(new InMemoryModule(elasticsearchConfig, notesMigration));
}
#end_block

#method_before
@Override
protected void configure() {
    addExposedPort(ELASTICSEARCH_DEFAULT_PORT);
    // https://github.com/docker-library/elasticsearch/issues/58
    addEnv("-Ees.network.host", "0.0.0.0");
}
#method_after
@Override
protected void configure() {
    addExposedPort(ELASTICSEARCH_DEFAULT_PORT);
}
#end_block

#method_before
@Override
protected Injector createInjector() {
    Config elasticsearchConfig = new Config(config);
    InMemoryModule.setDefaults(elasticsearchConfig);
    String indicesPrefix = testName();
    ElasticTestUtils.configure(elasticsearchConfig, nodeInfo.port, indicesPrefix);
    return Guice.createInjector(new InMemoryModule(elasticsearchConfig, notesMigration));
}
#method_after
@Override
protected Injector createInjector() {
    Config elasticsearchConfig = new Config(config);
    InMemoryModule.setDefaults(elasticsearchConfig);
    String indicesPrefix = getSanitizedMethodName();
    ElasticTestUtils.configure(elasticsearchConfig, nodeInfo.port, indicesPrefix);
    return Guice.createInjector(new InMemoryModule(elasticsearchConfig, notesMigration));
}
#end_block

#method_before
@AfterClass
public static void stopCommonServer() throws Exception {
    if (commonServer != null) {
        try {
            commonServer.close();
        } catch (Throwable t) {
            throw new AssertionError("Error stopping common server in " + (firstTest != null ? firstTest.getTestClass().getName() : "unknown test class"), t);
        } finally {
            commonServer = null;
        }
    }
    TempFileUtil.cleanup();
}
#method_after
@AfterClass
public static void stopCommonServer() throws Exception {
    if (commonServer != null) {
        try {
            commonServer.close();
        } catch (Throwable t) {
            throw new AssertionError("Error stopping common server in " + (firstTest != null ? firstTest.getTestClass().getName() : "unknown test class"), t);
        } finally {
            commonServer = null;
        }
    }
}
#end_block

#method_before
protected void beforeTest(Description description) throws Exception {
    this.description = description;
    GerritServer.Description classDesc = GerritServer.Description.forTestClass(description, configName);
    GerritServer.Description methodDesc = GerritServer.Description.forTestMethod(description, configName);
    testRequiresSsh = classDesc.useSshAnnotation() || methodDesc.useSshAnnotation();
    if (!testRequiresSsh) {
        baseConfig.setString("sshd", null, "listenAddress", "off");
    }
    baseConfig.setInt("index", null, "batchThreads", -1);
    baseConfig.setInt("receive", null, "changeUpdateThreads", 4);
    Module module = createModule();
    if (classDesc.equals(methodDesc) && !classDesc.sandboxed() && !methodDesc.sandboxed()) {
        if (commonServer == null) {
            commonServer = GerritServer.initAndStart(classDesc, baseConfig, module);
        }
        server = commonServer;
    } else {
        server = GerritServer.initAndStart(methodDesc, baseConfig, module);
    }
    server.getTestInjector().injectMembers(this);
    Transport.register(inProcessProtocol);
    toClose = Collections.synchronizedList(new ArrayList<Repository>());
    db = reviewDbProvider.open();
    // All groups which were added during the server start (e.g. in SchemaCreator) aren't contained
    // in the instance of the group index which is available here and in tests. There are two
    // reasons:
    // 1) No group index is available in SchemaCreator when using an in-memory database. (This could
    // be fixed by using the IndexManagerOnInit in InMemoryDatabase similar as BaseInit uses it.)
    // 2) During the on-init part of the server start, we use another instance of the index than
    // later on. As test indexes are non-permanent, closing an instance and opening another one
    // removes all indexed data.
    // As a workaround, we simply reindex all available groups here.
    reindexAllGroups();
    admin = accountCreator.admin();
    user = accountCreator.user();
    // Evict and reindex accounts in case tests modify them.
    evictAndReindexAccount(admin.getId());
    evictAndReindexAccount(user.getId());
    adminRestSession = new RestSession(server, admin);
    userRestSession = new RestSession(server, user);
    anonymousRestSession = new RestSession(server, null);
    initSsh();
    resourcePrefix = UNSAFE_PROJECT_NAME.matcher(description.getClassName() + "_" + description.getMethodName() + "_").replaceAll("");
    GerritServer.setResourcePrefix(resourcePrefix);
    Context ctx = newRequestContext(admin);
    atrScope.set(ctx);
    ProjectInput in = projectInput(description);
    gApi.projects().create(in);
    project = new Project.NameKey(in.name);
    testRepo = cloneProject(project, getCloneAsAccount(description));
}
#method_after
protected void beforeTest(Description description) throws Exception {
    this.description = description;
    GerritServer.Description classDesc = GerritServer.Description.forTestClass(description, configName);
    GerritServer.Description methodDesc = GerritServer.Description.forTestMethod(description, configName);
    testRequiresSsh = classDesc.useSshAnnotation() || methodDesc.useSshAnnotation();
    if (!testRequiresSsh) {
        baseConfig.setString("sshd", null, "listenAddress", "off");
    }
    baseConfig.setInt("index", null, "batchThreads", -1);
    baseConfig.setInt("receive", null, "changeUpdateThreads", 4);
    Module module = createModule();
    if (classDesc.equals(methodDesc) && !classDesc.sandboxed() && !methodDesc.sandboxed()) {
        if (commonServer == null) {
            commonServer = GerritServer.initAndStart(temporaryFolder, classDesc, baseConfig, module);
        }
        server = commonServer;
    } else {
        server = GerritServer.initAndStart(temporaryFolder, methodDesc, baseConfig, module);
    }
    server.getTestInjector().injectMembers(this);
    Transport.register(inProcessProtocol);
    toClose = Collections.synchronizedList(new ArrayList<Repository>());
    db = reviewDbProvider.open();
    // All groups which were added during the server start (e.g. in ReviewDbSchemaCreator) aren't
    // contained in the instance of the group index which is available here and in tests. There are
    // two reasons:
    // 1) No group index is available in ReviewDbSchemaCreator when using an in-memory database.
    // (This could be fixed by using the IndexManagerOnInit in InMemoryDatabase similar as BaseInit
    // uses it.)
    // 2) During the on-init part of the server start, we use another instance of the index than
    // later on. As test indexes are non-permanent, closing an instance and opening another one
    // removes all indexed data.
    // As a workaround, we simply reindex all available groups here.
    reindexAllGroups();
    admin = accountCreator.admin();
    user = accountCreator.user();
    // Evict and reindex accounts in case tests modify them.
    evictAndReindexAccount(admin.getId());
    evictAndReindexAccount(user.getId());
    adminRestSession = new RestSession(server, admin);
    userRestSession = new RestSession(server, user);
    anonymousRestSession = new RestSession(server, null);
    initSsh();
    resourcePrefix = UNSAFE_PROJECT_NAME.matcher(description.getClassName() + "_" + description.getMethodName() + "_").replaceAll("");
    Context ctx = newRequestContext(admin);
    atrScope.set(ctx);
    ProjectInput in = projectInput(description);
    gApi.projects().create(in);
    project = new Project.NameKey(in.name);
    testRepo = cloneProject(project, getCloneAsAccount(description));
}
#end_block

#method_before
protected Project.NameKey createProject(String nameSuffix) throws Exception {
    return createProject(nameSuffix, null);
}
#method_after
protected Project.NameKey createProject(String nameSuffix) throws Exception {
    return projectOperations.newProject().withEmptyCommit().create();
}
#end_block

#method_before
protected Project.NameKey createProject(String nameSuffix, Project.NameKey parent) throws Exception {
    // Default for createEmptyCommit should match TestProjectConfig.
    return createProject(nameSuffix, parent, true, null);
}
#method_after
protected Project.NameKey createProject(String nameSuffix, Project.NameKey parent) throws Exception {
    // Default for createEmptyCommit should match TestProjectConfig.
    return projectOperations.newProject().withEmptyCommit().parent(parent).create();
}
#end_block

#method_before
protected Project.NameKey createProject(String nameSuffix, Project.NameKey parent, boolean createEmptyCommit) throws Exception {
    // Default for createEmptyCommit should match TestProjectConfig.
    return createProject(nameSuffix, parent, createEmptyCommit, null);
}
#method_after
protected Project.NameKey createProject(String nameSuffix, Project.NameKey parent, boolean createEmptyCommit) throws Exception {
    // Default for createEmptyCommit should match TestProjectConfig.
    if (parent == null) {
        return projectOperations.newProject().createEmptyCommit(createEmptyCommit).create();
    }
    return projectOperations.newProject().parent(parent).createEmptyCommit(createEmptyCommit).create();
}
#end_block

#method_before
protected Project.NameKey createProject(String nameSuffix, Project.NameKey parent, boolean createEmptyCommit, SubmitType submitType) throws Exception {
    TestProjectCreation.Builder b = projectOperations.newProject().name(nameSuffix).createEmptyCommit(createEmptyCommit);
    if (parent != null) {
        b.parent(parent.get());
    }
    if (submitType != null) {
        b.submitType(submitType);
    }
    return b.create();
}
#method_after
protected Project.NameKey createProject(String nameSuffix, Project.NameKey parent, boolean createEmptyCommit, SubmitType submitType) throws Exception {
    if (parent == null) {
        return projectOperations.newProject().createEmptyCommit(createEmptyCommit).submitType(submitType).create();
    }
    return projectOperations.newProject().submitType(submitType).parent(parent).createEmptyCommit(createEmptyCommit).parent(parent).create();
}
#end_block

#method_before
public void addUrl(ChangeInfo change) {
    args.add("--change-url");
    if (change != null) {
        Optional<UrlFormatter> urlFormatter = Optional.ofNullable(urlFormatterItem.get());
        args.add(urlFormatter.flatMap(f -> f.getChangeViewUrl(new Project.NameKey(change.project), new Change.Id(change._number))).orElse(""));
    } else {
        args.add("");
    }
}
#method_after
public void addUrl(ChangeInfo change) {
    args.add("--change-url");
    if (change != null) {
        Optional<UrlFormatter> uf = Optional.ofNullable(urlFormatter.get());
        args.add(uf.flatMap(f -> f.getChangeViewUrl(new Project.NameKey(change.project), new Change.Id(change._number))).orElse(""));
    } else {
        args.add("");
    }
}
#end_block

#method_before
@Test
public void version6() throws Exception {
    assertThat(ElasticVersion.V6_2.isV6OrLater()).isTrue();
    assertThat(ElasticVersion.V6_3.isV6OrLater()).isTrue();
    assertThat(ElasticVersion.V6_4.isV6OrLater()).isTrue();
    assertThat(ElasticVersion.V7_0.isV6OrLater()).isTrue();
    assertThat(ElasticVersion.V5_6.isV6OrLater()).isFalse();
}
#method_after
@Test
public void version6() throws Exception {
    assertThat(ElasticVersion.V5_6.isV6OrLater()).isFalse();
    assertThat(ElasticVersion.V6_2.isV6OrLater()).isTrue();
    assertThat(ElasticVersion.V6_3.isV6OrLater()).isTrue();
    assertThat(ElasticVersion.V6_4.isV6OrLater()).isTrue();
    assertThat(ElasticVersion.V7_0.isV6OrLater()).isTrue();
}
#end_block

#method_before
@Test
public void version7() throws Exception {
    assertThat(ElasticVersion.V6_2.isV7OrLater()).isFalse();
    assertThat(ElasticVersion.V6_3.isV7OrLater()).isFalse();
    assertThat(ElasticVersion.V6_4.isV7OrLater()).isFalse();
    assertThat(ElasticVersion.V7_0.isV7OrLater()).isTrue();
    assertThat(ElasticVersion.V5_6.isV7OrLater()).isFalse();
}
#method_after
@Test
public void version7() throws Exception {
    assertThat(ElasticVersion.V5_6.isV7OrLater()).isFalse();
    assertThat(ElasticVersion.V6_2.isV7OrLater()).isFalse();
    assertThat(ElasticVersion.V6_3.isV7OrLater()).isFalse();
    assertThat(ElasticVersion.V6_4.isV7OrLater()).isFalse();
    assertThat(ElasticVersion.V7_0.isV7OrLater()).isTrue();
}
#end_block

#method_before
protected String getURI(String type, String request) throws UnsupportedEncodingException {
    String encodedIndexName = URLEncoder.encode(indexName, UTF_8.toString());
    if (SEARCH.equals(request) && !client.adapter().omitTypeFromSearch()) {
        String encodedType = URLEncoder.encode(type, UTF_8.toString());
        return encodedIndexName + "/" + encodedType + "/" + request;
    }
    return encodedIndexName + "/" + request;
}
#method_after
protected String getURI(String type, String request) throws UnsupportedEncodingException {
    String encodedIndexName = URLEncoder.encode(indexName, UTF_8.toString());
    if (SEARCH.equals(request) && client.adapter().omitTypeFromSearch()) {
        return encodedIndexName + "/" + request;
    }
    String encodedType = URLEncoder.encode(type, UTF_8.toString());
    return encodedIndexName + "/" + encodedType + "/" + request;
}
#end_block

#method_before
private void configurePeerInfoSection() {
    ui.header("PeerInfo section");
    PeerInfoStrategy strategy = ui.readEnum(PeerInfoStrategy.JGROUPS, EnumSet.allOf(PeerInfoStrategy.class), "Peer info strategy");
    config.setEnum(PEER_INFO_SECTION, null, STRATEGY_KEY, strategy);
    if (strategy == PeerInfoStrategy.STATIC) {
        promptAndSetString("Peer URL", PEER_INFO_SECTION, STATIC_SUBSECTION, URL_KEY, null);
    } else {
        promptAndSetString("JGroups cluster name", PEER_INFO_SECTION, JGROUPS_SUBSECTION, CLUSTER_NAME_KEY, DEFAULT_CLUSTER_NAME);
        promptAndSetString("Protocol stack (optional)", PEER_INFO_SECTION, JGROUPS_SUBSECTION, PROTOCOL_STACK_KEY, null);
        promptAndSetString("Skip interface (optional); multiply this line to add more", PEER_INFO_SECTION, JGROUPS_SUBSECTION, SKIP_INTERFACE_KEY, null);
    }
}
#method_after
private void configurePeerInfoSection() {
    ui.header("PeerInfo section");
    PeerInfoStrategy strategy = ui.readEnum(PeerInfoStrategy.JGROUPS, EnumSet.allOf(PeerInfoStrategy.class), "Peer info strategy");
    config.setEnum(PEER_INFO_SECTION, null, STRATEGY_KEY, strategy);
    if (strategy == PeerInfoStrategy.STATIC) {
        promptAndSetString("Peer URL", PEER_INFO_SECTION, STATIC_SUBSECTION, URL_KEY, null);
    } else {
        promptAndSetString("JGroups cluster name", PEER_INFO_SECTION, JGROUPS_SUBSECTION, CLUSTER_NAME_KEY, DEFAULT_CLUSTER_NAME);
        promptAndSetString("Protocol stack (optional)", PEER_INFO_SECTION, JGROUPS_SUBSECTION, PROTOCOL_STACK_KEY, null);
        promptAndSetString(titleForOptionalWithNote("Skip interface", "interfaces"), PEER_INFO_SECTION, JGROUPS_SUBSECTION, SKIP_INTERFACE_KEY, null);
    }
}
#end_block

#method_before
private void configureCacheSection() {
    ui.header("Cache section");
    promptAndSetSynchronize("Cache", CACHE_SECTION);
    promptAndSetString("Cache thread pool size", CACHE_SECTION, THREAD_POOL_SIZE_KEY, numberToString(DEFAULT_THREAD_POOL_SIZE));
    promptAndSetString("Cache pattern (optional); multiply this line to add more", CACHE_SECTION, PATTERN_KEY, null);
}
#method_after
private void configureCacheSection() {
    ui.header("Cache section");
    promptAndSetSynchronize("Cache", CACHE_SECTION);
    promptAndSetString("Cache thread pool size", CACHE_SECTION, THREAD_POOL_SIZE_KEY, numberToString(DEFAULT_THREAD_POOL_SIZE));
    promptAndSetString(titleForOptionalWithNote("Cache pattern", "patterns"), CACHE_SECTION, PATTERN_KEY, null);
}
#end_block

#method_before
private void configureCacheSection() {
    ui.header("Cache section");
    promptAndSetSynchronize("Cache", CACHE_SECTION);
    promptAndSetString("Cache thread pool size", CACHE_SECTION, THREAD_POOL_SIZE_KEY, numberToString(DEFAULT_THREAD_POOL_SIZE));
    promptAndSetString("Cache pattern (optional); multiply this line to add more", CACHE_SECTION, PATTERN_KEY, null);
}
#method_after
private void configureCacheSection() {
    ui.header("Cache section");
    promptAndSetSynchronize("Cache", CACHE_SECTION);
    promptAndSetString("Cache thread pool size", CACHE_SECTION, THREAD_POOL_SIZE_KEY, numberToString(DEFAULT_THREAD_POOL_SIZE));
    promptAndSetString("Cache pattern (optional); manually multiply this line to configure more patterns", CACHE_SECTION, PATTERN_KEY, null);
}
#end_block

#method_before
private void configureCacheSection() {
    ui.header("Cache section");
    promptAndSetString("Cache thread pool size", CACHE_SECTION, THREAD_POOL_SIZE_KEY, numberToString(DEFAULT_THREAD_POOL_SIZE));
    promptAndSetString("Cache pattern (optional); multiply this line to add more", CACHE_SECTION, PATTERN_KEY, null);
}
#method_after
private void configureCacheSection() {
    ui.header("Cache section");
    promptAndSetString("Cache thread pool size", CACHE_SECTION, THREAD_POOL_SIZE_KEY, numberToString(DEFAULT_THREAD_POOL_SIZE));
    promptAndSetString("Cache pattern (optional); manually multiply this line to configure more patterns", CACHE_SECTION, PATTERN_KEY, null);
}
#end_block

#method_before
@Override
protected void runImpl() throws IOException, Failure {
    PermissionBackend.ForProject perm = permissionBackend.user(user).project(projectState.getNameKey());
    try {
        perm.check(ProjectPermission.RUN_UPLOAD_PACK);
    } catch (AuthException e) {
        throw new Failure(1, "fatal: upload-pack not permitted on this server");
    } catch (PermissionBackendException e) {
        throw new Failure(1, "fatal: unable to check permissions " + e);
    }
    final UploadPack up = new UploadPack(repo);
    up.setAdvertiseRefsHook(new DefaultAdvertiseRefsHook(perm, RefFilterOptions.defaults()));
    up.setPackConfig(config.getPackConfig());
    up.setTimeout(config.getTimeout());
    up.setPostUploadHook(PostUploadHookChain.newChain(Lists.newArrayList(postUploadHooks)));
    if (config.enableProtocolV2() && extraParameters != null) {
        up.setExtraParameters(Arrays.asList(extraParameters));
    }
    List<PreUploadHook> allPreUploadHooks = Lists.newArrayList(preUploadHooks);
    allPreUploadHooks.add(uploadValidatorsFactory.create(project, repo, session.getRemoteAddressAsString()));
    up.setPreUploadHook(PreUploadHookChain.newChain(allPreUploadHooks));
    for (UploadPackInitializer initializer : uploadPackInitializers) {
        initializer.init(projectState.getNameKey(), up);
    }
    try {
        up.upload(in, out, err);
        session.setPeerAgent(up.getPeerUserAgent());
    } catch (UploadValidationException e) {
        // internal server error to the client.
        if (!e.isOutput()) {
            up.sendMessage(e.getMessage());
        }
    }
}
#method_after
@Override
protected void runImpl() throws IOException, Failure {
    PermissionBackend.ForProject perm = permissionBackend.user(user).project(projectState.getNameKey());
    try {
        perm.check(ProjectPermission.RUN_UPLOAD_PACK);
    } catch (AuthException e) {
        throw new Failure(1, "fatal: upload-pack not permitted on this server");
    } catch (PermissionBackendException e) {
        throw new Failure(1, "fatal: unable to check permissions " + e);
    }
    final UploadPack up = new UploadPack(repo);
    up.setAdvertiseRefsHook(new DefaultAdvertiseRefsHook(perm, RefFilterOptions.defaults()));
    up.setPackConfig(config.getPackConfig());
    up.setTimeout(config.getTimeout());
    up.setPostUploadHook(PostUploadHookChain.newChain(Lists.newArrayList(postUploadHooks)));
    if (config.enableProtocolV2() && extraParameters != null) {
        up.setExtraParameters(ImmutableList.copyOf(extraParameters));
    }
    List<PreUploadHook> allPreUploadHooks = Lists.newArrayList(preUploadHooks);
    allPreUploadHooks.add(uploadValidatorsFactory.create(project, repo, session.getRemoteAddressAsString()));
    up.setPreUploadHook(PreUploadHookChain.newChain(allPreUploadHooks));
    for (UploadPackInitializer initializer : uploadPackInitializers) {
        initializer.init(projectState.getNameKey(), up);
    }
    try {
        up.upload(in, out, err);
        session.setPeerAgent(up.getPeerUserAgent());
    } catch (UploadValidationException e) {
        // internal server error to the client.
        if (!e.isOutput()) {
            up.sendMessage(e.getMessage());
        }
    }
}
#end_block

#method_before
@Test
public void addReviewerThatIsInactive() throws Exception {
    PushOneCommit.Result result = createChange();
    String username = name("new-user");
    gApi.accounts().create(username).setActive(false);
    AddReviewerInput in = new AddReviewerInput();
    in.reviewer = username;
    AddReviewerResult r = gApi.changes().id(result.getChangeId()).addReviewer(in);
    assertThat(r.input).isEqualTo(username);
    assertThat(r.error).contains("identifies an inactive account");
    assertThat(r.reviewers).isNull();
}
#method_after
@Test
public void addReviewerThatIsInactive() throws Exception {
    PushOneCommit.Result result = createChange();
    String username = name("new-user");
    accountOperations.newAccount().username(username).inactive().create();
    AddReviewerInput in = new AddReviewerInput();
    in.reviewer = username;
    AddReviewerResult r = gApi.changes().id(result.getChangeId()).addReviewer(in);
    assertThat(r.input).isEqualTo(username);
    assertThat(r.error).contains("identifies an inactive account");
    assertThat(r.reviewers).isNull();
}
#end_block

#method_before
@Test
public void addReviewerThatIsInactiveEmailFallback() throws Exception {
    assume().that(notesMigration.readChanges()).isTrue();
    ConfigInput conf = new ConfigInput();
    conf.enableReviewerByEmail = InheritableBoolean.TRUE;
    gApi.projects().name(project.get()).config(conf);
    PushOneCommit.Result result = createChange();
    String username = "user@domain.com";
    gApi.accounts().create(username).setActive(false);
    AddReviewerInput in = new AddReviewerInput();
    in.reviewer = username;
    in.state = ReviewerState.CC;
    AddReviewerResult r = gApi.changes().id(result.getChangeId()).addReviewer(in);
    assertThat(r.input).isEqualTo(username);
    assertThat(r.error).isNull();
    // When adding by email, the reviewers field is also empty because we can't
    // render a ReviewerInfo object for a non-account.
    assertThat(r.reviewers).isNull();
}
#method_after
@Test
public void addReviewerThatIsInactiveEmailFallback() throws Exception {
    assume().that(notesMigration.readChanges()).isTrue();
    ConfigInput conf = new ConfigInput();
    conf.enableReviewerByEmail = InheritableBoolean.TRUE;
    gApi.projects().name(project.get()).config(conf);
    PushOneCommit.Result result = createChange();
    String username = "user@domain.com";
    accountOperations.newAccount().username(username).inactive().create();
    AddReviewerInput in = new AddReviewerInput();
    in.reviewer = username;
    in.state = ReviewerState.CC;
    AddReviewerResult r = gApi.changes().id(result.getChangeId()).addReviewer(in);
    assertThat(r.input).isEqualTo(username);
    assertThat(r.error).isNull();
    // When adding by email, the reviewers field is also empty because we can't
    // render a ReviewerInfo object for a non-account.
    assertThat(r.reviewers).isNull();
}
#end_block

#method_before
@Test
public void addReviewerThatIsNotPerfectMatch() throws Exception {
    TestTimeUtil.resetWithClockStep(1, SECONDS);
    PushOneCommit.Result r = createChange();
    ChangeResource rsrc = parseResource(r);
    String oldETag = rsrc.getETag();
    Timestamp oldTs = rsrc.getChange().getLastUpdatedOn();
    // create a group named "ab" with one user: testUser
    String email = "abcd@test.com";
    String fullname = "abcd";
    Account.Id accountIdOfTestUser = accountOperations.newAccount().username("abcd").preferredEmail(email).fullname(fullname).create();
    String testGroup = groupOperations.newGroup().name("ab").createName();
    GroupApi groupApi = gApi.groups().id(testGroup);
    groupApi.description("test group");
    groupApi.addMembers(user.fullName);
    AddReviewerInput in = new AddReviewerInput();
    in.reviewer = "abc";
    gApi.changes().id(r.getChangeId()).addReviewer(in.reviewer);
    List<Message> messages = sender.getMessages();
    assertThat(messages).hasSize(1);
    Message m = messages.get(0);
    assertThat(m.rcpt()).containsExactly(new Address(fullname, email));
    assertThat(m.body()).contains("Hello " + fullname + ",\n");
    assertThat(m.body()).contains("I'd like you to do a code review.");
    assertThat(m.body()).contains("Change subject: " + PushOneCommit.SUBJECT + "\n");
    assertMailReplyTo(m, email);
    ChangeInfo c = gApi.changes().id(r.getChangeId()).get();
    // When NoteDb is enabled adding a reviewer records that user as reviewer
    // in NoteDb. When NoteDb is disabled adding a reviewer results in a dummy 0
    // approval on the change which is treated as CC when the ChangeInfo is
    // created.
    Collection<AccountInfo> reviewers = c.reviewers.get(REVIEWER);
    assertThat(reviewers).isNotNull();
    assertThat(reviewers).hasSize(1);
    assertThat(reviewers.iterator().next()._accountId).isEqualTo(accountIdOfTestUser.get());
    // Ensure ETag and lastUpdatedOn are updated.
    rsrc = parseResource(r);
    assertThat(rsrc.getETag()).isNotEqualTo(oldETag);
    assertThat(rsrc.getChange().getLastUpdatedOn()).isNotEqualTo(oldTs);
}
#method_after
@Test
public void addReviewerThatIsNotPerfectMatch() throws Exception {
    TestTimeUtil.resetWithClockStep(1, SECONDS);
    PushOneCommit.Result r = createChange();
    ChangeResource rsrc = parseResource(r);
    String oldETag = rsrc.getETag();
    Timestamp oldTs = rsrc.getChange().getLastUpdatedOn();
    // create a group named "ab" with one user: testUser
    String email = "abcd@test.com";
    String fullname = "abcd";
    Account.Id accountIdOfTestUser = accountOperations.newAccount().username("abcd").preferredEmail(email).fullname(fullname).create();
    String testGroup = groupOperations.newGroup().name("ab").create().get();
    GroupApi groupApi = gApi.groups().id(testGroup);
    groupApi.description("test group");
    groupApi.addMembers(user.fullName);
    AddReviewerInput in = new AddReviewerInput();
    in.reviewer = "abc";
    gApi.changes().id(r.getChangeId()).addReviewer(in.reviewer);
    List<Message> messages = sender.getMessages();
    assertThat(messages).hasSize(1);
    Message m = messages.get(0);
    assertThat(m.rcpt()).containsExactly(new Address(fullname, email));
    assertThat(m.body()).contains("Hello " + fullname + ",\n");
    assertThat(m.body()).contains("I'd like you to do a code review.");
    assertThat(m.body()).contains("Change subject: " + PushOneCommit.SUBJECT + "\n");
    assertMailReplyTo(m, email);
    ChangeInfo c = gApi.changes().id(r.getChangeId()).get();
    // When NoteDb is enabled adding a reviewer records that user as reviewer
    // in NoteDb. When NoteDb is disabled adding a reviewer results in a dummy 0
    // approval on the change which is treated as CC when the ChangeInfo is
    // created.
    Collection<AccountInfo> reviewers = c.reviewers.get(REVIEWER);
    assertThat(reviewers).isNotNull();
    assertThat(reviewers).hasSize(1);
    assertThat(reviewers.iterator().next()._accountId).isEqualTo(accountIdOfTestUser.get());
    // Ensure ETag and lastUpdatedOn are updated.
    rsrc = parseResource(r);
    assertThat(rsrc.getETag()).isNotEqualTo(oldETag);
    assertThat(rsrc.getChange().getLastUpdatedOn()).isNotEqualTo(oldTs);
}
#end_block

#method_before
@Test
public void addGroupAsReviewersWhenANotPerfectMatchedUserExists() throws Exception {
    TestTimeUtil.resetWithClockStep(1, SECONDS);
    PushOneCommit.Result r = createChange();
    ChangeResource rsrc = parseResource(r);
    String oldETag = rsrc.getETag();
    Timestamp oldTs = rsrc.getChange().getLastUpdatedOn();
    // create a group named "kobe" with one user: lee
    String testUserFullname = "kobebryant";
    accountOperations.newAccount().username("kobebryant").preferredEmail("kobebryant@test.com").fullname(testUserFullname).create();
    String myGroupUserEmail = "lee@test.com";
    String myGroupUserFullname = "lee";
    Account.Id accountIdOfGroupUser = accountOperations.newAccount().username("lee").preferredEmail(myGroupUserEmail).fullname(myGroupUserFullname).create();
    String testGroup = groupOperations.newGroup().name("kobe").createName();
    GroupApi groupApi = gApi.groups().id(testGroup);
    groupApi.description("test group");
    groupApi.addMembers(myGroupUserFullname);
    // ensure that user "user" is not in the group
    groupApi.removeMembers(testUserFullname);
    AddReviewerInput in = new AddReviewerInput();
    in.reviewer = testGroup;
    gApi.changes().id(r.getChangeId()).addReviewer(in.reviewer);
    List<Message> messages = sender.getMessages();
    assertThat(messages).hasSize(1);
    Message m = messages.get(0);
    assertThat(m.rcpt()).containsExactly(new Address(myGroupUserFullname, myGroupUserEmail));
    assertThat(m.body()).contains("Hello " + myGroupUserFullname + ",\n");
    assertThat(m.body()).contains("I'd like you to do a code review.");
    assertThat(m.body()).contains("Change subject: " + PushOneCommit.SUBJECT + "\n");
    assertMailReplyTo(m, myGroupUserEmail);
    ChangeInfo c = gApi.changes().id(r.getChangeId()).get();
    // When NoteDb is enabled adding a reviewer records that user as reviewer
    // in NoteDb. When NoteDb is disabled adding a reviewer results in a dummy 0
    // approval on the change which is treated as CC when the ChangeInfo is
    // created.
    Collection<AccountInfo> reviewers = c.reviewers.get(REVIEWER);
    assertThat(reviewers).isNotNull();
    assertThat(reviewers).hasSize(1);
    assertThat(reviewers.iterator().next()._accountId).isEqualTo(accountIdOfGroupUser.get());
    // Ensure ETag and lastUpdatedOn are updated.
    rsrc = parseResource(r);
    assertThat(rsrc.getETag()).isNotEqualTo(oldETag);
    assertThat(rsrc.getChange().getLastUpdatedOn()).isNotEqualTo(oldTs);
}
#method_after
@Test
public void addGroupAsReviewersWhenANotPerfectMatchedUserExists() throws Exception {
    TestTimeUtil.resetWithClockStep(1, SECONDS);
    PushOneCommit.Result r = createChange();
    ChangeResource rsrc = parseResource(r);
    String oldETag = rsrc.getETag();
    Timestamp oldTs = rsrc.getChange().getLastUpdatedOn();
    // create a group named "kobe" with one user: lee
    String testUserFullname = "kobebryant";
    accountOperations.newAccount().username("kobebryant").preferredEmail("kobebryant@test.com").fullname(testUserFullname).create();
    String myGroupUserEmail = "lee@test.com";
    String myGroupUserFullname = "lee";
    Account.Id accountIdOfGroupUser = accountOperations.newAccount().username("lee").preferredEmail(myGroupUserEmail).fullname(myGroupUserFullname).create();
    String testGroup = groupOperations.newGroup().name("kobe").create().get();
    GroupApi groupApi = gApi.groups().id(testGroup);
    groupApi.description("test group");
    groupApi.addMembers(myGroupUserFullname);
    // ensure that user "user" is not in the group
    groupApi.removeMembers(testUserFullname);
    AddReviewerInput in = new AddReviewerInput();
    in.reviewer = testGroup;
    gApi.changes().id(r.getChangeId()).addReviewer(in.reviewer);
    List<Message> messages = sender.getMessages();
    assertThat(messages).hasSize(1);
    Message m = messages.get(0);
    assertThat(m.rcpt()).containsExactly(new Address(myGroupUserFullname, myGroupUserEmail));
    assertThat(m.body()).contains("Hello " + myGroupUserFullname + ",\n");
    assertThat(m.body()).contains("I'd like you to do a code review.");
    assertThat(m.body()).contains("Change subject: " + PushOneCommit.SUBJECT + "\n");
    assertMailReplyTo(m, myGroupUserEmail);
    ChangeInfo c = gApi.changes().id(r.getChangeId()).get();
    // When NoteDb is enabled adding a reviewer records that user as reviewer
    // in NoteDb. When NoteDb is disabled adding a reviewer results in a dummy 0
    // approval on the change which is treated as CC when the ChangeInfo is
    // created.
    Collection<AccountInfo> reviewers = c.reviewers.get(REVIEWER);
    assertThat(reviewers).isNotNull();
    assertThat(reviewers).hasSize(1);
    assertThat(reviewers.iterator().next()._accountId).isEqualTo(accountIdOfGroupUser.get());
    // Ensure ETag and lastUpdatedOn are updated.
    rsrc = parseResource(r);
    assertThat(rsrc.getETag()).isNotEqualTo(oldETag);
    assertThat(rsrc.getChange().getLastUpdatedOn()).isNotEqualTo(oldTs);
}
#end_block

#method_before
@Test
public void eTagChangesWhenOwnerUpdatesAccountStatus() throws Exception {
    PushOneCommit.Result r = createChange();
    ChangeResource rsrc = parseResource(r);
    String oldETag = rsrc.getETag();
    gApi.accounts().id(admin.id.get()).setStatus("new status");
    rsrc = parseResource(r);
    assertThat(rsrc.getETag()).isNotEqualTo(oldETag);
}
#method_after
@Test
public void eTagChangesWhenOwnerUpdatesAccountStatus() throws Exception {
    PushOneCommit.Result r = createChange();
    ChangeResource rsrc = parseResource(r);
    String oldETag = rsrc.getETag();
    accountOperations.account(admin.id).forUpdate().status("new status").update();
    rsrc = parseResource(r);
    assertThat(rsrc.getETag()).isNotEqualTo(oldETag);
}
#end_block

#method_before
@Test
public void indexChangeAfterOwnerLosesVisibility() throws Exception {
    // Create a test group with 2 users as members
    TestAccount user2 = accountCreator.user2();
    String group = groupOperations.newGroup().name("test").createName();
    gApi.groups().id(group).addMembers("admin", "user", user2.username);
    // Create a project and restrict its visibility to the group
    Project.NameKey p = createProject("p");
    try (ProjectConfigUpdate u = updateProject(p)) {
        Util.allow(u.getConfig(), Permission.READ, groupCache.get(new AccountGroup.NameKey(group)).get().getGroupUUID(), "refs/*");
        Util.block(u.getConfig(), Permission.READ, REGISTERED_USERS, "refs/*");
        u.save();
    }
    // Clone it and push a change as a regular user
    TestRepository<InMemoryRepository> repo = cloneProject(p, user);
    PushOneCommit push = pushFactory.create(db, user.getIdent(), repo);
    PushOneCommit.Result result = push.to("refs/for/master");
    result.assertOkStatus();
    assertThat(result.getChange().change().getOwner()).isEqualTo(user.id);
    String changeId = result.getChangeId();
    // User can see the change and it is mergeable
    setApiUser(user);
    List<ChangeInfo> changes = gApi.changes().query(changeId).get();
    assertThat(changes).hasSize(1);
    assertThat(changes.get(0).mergeable).isNotNull();
    // Other user can see the change and it is mergeable
    setApiUser(user2);
    changes = gApi.changes().query(changeId).get();
    assertThat(changes).hasSize(1);
    assertThat(changes.get(0).mergeable).isTrue();
    // Remove the user from the group so they can no longer see the project
    setApiUser(admin);
    gApi.groups().id(group).removeMembers("user");
    // User can no longer see the change
    setApiUser(user);
    changes = gApi.changes().query(changeId).get();
    assertThat(changes).isEmpty();
    // Reindex the change
    setApiUser(admin);
    gApi.changes().id(changeId).index();
    // Other user can still see the change and it is still mergeable
    setApiUser(user2);
    changes = gApi.changes().query(changeId).get();
    assertThat(changes).hasSize(1);
    assertThat(changes.get(0).mergeable).isTrue();
}
#method_after
@Test
public void indexChangeAfterOwnerLosesVisibility() throws Exception {
    // Create a test group with 2 users as members
    TestAccount user2 = accountCreator.user2();
    AccountGroup.UUID groupId = groupOperations.newGroup().name("test").create();
    String group = groupOperations.group(groupId).get().name();
    gApi.groups().id(group).addMembers("admin", "user", user2.username);
    // Create a project and restrict its visibility to the group
    Project.NameKey p = createProject("p");
    try (ProjectConfigUpdate u = updateProject(p)) {
        Util.allow(u.getConfig(), Permission.READ, groupCache.get(new AccountGroup.NameKey(group)).get().getGroupUUID(), "refs/*");
        Util.block(u.getConfig(), Permission.READ, REGISTERED_USERS, "refs/*");
        u.save();
    }
    // Clone it and push a change as a regular user
    TestRepository<InMemoryRepository> repo = cloneProject(p, user);
    PushOneCommit push = pushFactory.create(db, user.getIdent(), repo);
    PushOneCommit.Result result = push.to("refs/for/master");
    result.assertOkStatus();
    assertThat(result.getChange().change().getOwner()).isEqualTo(user.id);
    String changeId = result.getChangeId();
    // User can see the change and it is mergeable
    setApiUser(user);
    List<ChangeInfo> changes = gApi.changes().query(changeId).get();
    assertThat(changes).hasSize(1);
    assertThat(changes.get(0).mergeable).isNotNull();
    // Other user can see the change and it is mergeable
    setApiUser(user2);
    changes = gApi.changes().query(changeId).get();
    assertThat(changes).hasSize(1);
    assertThat(changes.get(0).mergeable).isTrue();
    // Remove the user from the group so they can no longer see the project
    setApiUser(admin);
    gApi.groups().id(group).removeMembers("user");
    // User can no longer see the change
    setApiUser(user);
    changes = gApi.changes().query(changeId).get();
    assertThat(changes).isEmpty();
    // Reindex the change
    setApiUser(admin);
    gApi.changes().id(changeId).index();
    // Other user can still see the change and it is still mergeable
    setApiUser(user2);
    changes = gApi.changes().query(changeId).get();
    assertThat(changes).hasSize(1);
    assertThat(changes.get(0).mergeable).isTrue();
}
#end_block

#method_before
protected String createGroup(String name) throws Exception {
    name = name(name);
    GroupInput in = new GroupInput();
    in.name = name;
    in.ownerId = "Administrators";
    gApi.groups().create(in);
    return name;
}
#method_after
protected String createGroup(String name) throws Exception {
    // TODO(hanwen): rewrite this test in terms of UUID. This requires redoing the assertion helpers
    // too.
    AccountGroup.UUID g = groupOperations.newGroup().ownerGroupUuid(adminGroupUuid()).create();
    return groupRef(g).getName();
}
#end_block

#method_before
@Before
public void basicSetup() throws Exception {
    allowGlobalCapabilities(REGISTERED_USERS, GlobalCapability.ACCESS_DATABASE);
    String name1 = groupOperations.newGroup().name("g1").createName();
    String name2 = groupOperations.newGroup().name("g2").createName();
    gApi.groups().id(name1).addMembers(user.fullName);
    gApi.groups().id(name2).addMembers(admin.fullName);
    gApi.groups().id(name1).addGroups(name2);
    this.g1 = gApi.groups().id(name1).detail();
    this.g2 = gApi.groups().id(name2).detail();
    this.gAdmin = gApi.groups().id("Administrators").detail();
}
#method_after
@Before
public void basicSetup() throws Exception {
    allowGlobalCapabilities(REGISTERED_USERS, GlobalCapability.ACCESS_DATABASE);
    String name1 = groupOperations.newGroup().name("g1").create().get();
    String name2 = groupOperations.newGroup().name("g2").create().get();
    gApi.groups().id(name1).addMembers(user.fullName);
    gApi.groups().id(name2).addMembers(admin.fullName);
    gApi.groups().id(name1).addGroups(name2);
    this.g1 = gApi.groups().id(name1).detail();
    this.g2 = gApi.groups().id(name2).detail();
    this.gAdmin = gApi.groups().id("Administrators").detail();
}
#end_block

#method_before
@Test
public void addGroupAsReviewer() throws Exception {
    // Set up two groups, one that is too large too add as reviewer, and one
    // that is too large to add without confirmation.
    String largeGroup = groupOperations.newGroup().name("largeGroup").createName();
    String mediumGroup = groupOperations.newGroup().name("mediumGroup").createName();
    int largeGroupSize = ReviewerAdder.DEFAULT_MAX_REVIEWERS + 1;
    int mediumGroupSize = ReviewerAdder.DEFAULT_MAX_REVIEWERS_WITHOUT_CHECK + 1;
    List<TestAccount> users = createAccounts(largeGroupSize, "addGroupAsReviewer");
    List<String> largeGroupUsernames = new ArrayList<>(mediumGroupSize);
    for (TestAccount u : users) {
        largeGroupUsernames.add(u.username);
    }
    List<String> mediumGroupUsernames = largeGroupUsernames.subList(0, mediumGroupSize);
    gApi.groups().id(largeGroup).addMembers(largeGroupUsernames.toArray(new String[largeGroupSize]));
    gApi.groups().id(mediumGroup).addMembers(mediumGroupUsernames.toArray(new String[mediumGroupSize]));
    // Attempt to add overly large group as reviewers.
    PushOneCommit.Result r = createChange();
    String changeId = r.getChangeId();
    AddReviewerResult result = addReviewer(changeId, largeGroup);
    assertThat(result.input).isEqualTo(largeGroup);
    assertThat(result.confirm).isNull();
    assertThat(result.error).contains("has too many members to add them all as reviewers");
    assertThat(result.reviewers).isNull();
    // Attempt to add medium group without confirmation.
    result = addReviewer(changeId, mediumGroup);
    assertThat(result.input).isEqualTo(mediumGroup);
    assertThat(result.confirm).isTrue();
    assertThat(result.error).contains("has " + mediumGroupSize + " members. Do you want to add them all as reviewers?");
    assertThat(result.reviewers).isNull();
    // Add medium group with confirmation.
    AddReviewerInput in = new AddReviewerInput();
    in.reviewer = mediumGroup;
    in.confirmed = true;
    result = addReviewer(changeId, in);
    assertThat(result.input).isEqualTo(mediumGroup);
    assertThat(result.confirm).isNull();
    assertThat(result.error).isNull();
    assertThat(result.reviewers).hasSize(mediumGroupSize);
    // Verify that group members were added as reviewers.
    ChangeInfo c = gApi.changes().id(r.getChangeId()).get();
    assertReviewers(c, REVIEWER, users.subList(0, mediumGroupSize));
}
#method_after
@Test
public void addGroupAsReviewer() throws Exception {
    // Set up two groups, one that is too large too add as reviewer, and one
    // that is too large to add without confirmation.
    String largeGroup = groupOperations.newGroup().name("largeGroup").create().get();
    String mediumGroup = groupOperations.newGroup().name("mediumGroup").create().get();
    int largeGroupSize = ReviewerAdder.DEFAULT_MAX_REVIEWERS + 1;
    int mediumGroupSize = ReviewerAdder.DEFAULT_MAX_REVIEWERS_WITHOUT_CHECK + 1;
    List<TestAccount> users = createAccounts(largeGroupSize, "addGroupAsReviewer");
    List<String> largeGroupUsernames = new ArrayList<>(mediumGroupSize);
    for (TestAccount u : users) {
        largeGroupUsernames.add(u.username);
    }
    List<String> mediumGroupUsernames = largeGroupUsernames.subList(0, mediumGroupSize);
    gApi.groups().id(largeGroup).addMembers(largeGroupUsernames.toArray(new String[largeGroupSize]));
    gApi.groups().id(mediumGroup).addMembers(mediumGroupUsernames.toArray(new String[mediumGroupSize]));
    // Attempt to add overly large group as reviewers.
    PushOneCommit.Result r = createChange();
    String changeId = r.getChangeId();
    AddReviewerResult result = addReviewer(changeId, largeGroup);
    assertThat(result.input).isEqualTo(largeGroup);
    assertThat(result.confirm).isNull();
    assertThat(result.error).contains("has too many members to add them all as reviewers");
    assertThat(result.reviewers).isNull();
    // Attempt to add medium group without confirmation.
    result = addReviewer(changeId, mediumGroup);
    assertThat(result.input).isEqualTo(mediumGroup);
    assertThat(result.confirm).isTrue();
    assertThat(result.error).contains("has " + mediumGroupSize + " members. Do you want to add them all as reviewers?");
    assertThat(result.reviewers).isNull();
    // Add medium group with confirmation.
    AddReviewerInput in = new AddReviewerInput();
    in.reviewer = mediumGroup;
    in.confirmed = true;
    result = addReviewer(changeId, in);
    assertThat(result.input).isEqualTo(mediumGroup);
    assertThat(result.confirm).isNull();
    assertThat(result.error).isNull();
    assertThat(result.reviewers).hasSize(mediumGroupSize);
    // Verify that group members were added as reviewers.
    ChangeInfo c = gApi.changes().id(r.getChangeId()).get();
    assertReviewers(c, REVIEWER, users.subList(0, mediumGroupSize));
}
#end_block

#method_before
@Test
public void addCcGroup() throws Exception {
    List<TestAccount> users = createAccounts(6, "addCcGroup");
    List<String> usernames = new ArrayList<>(6);
    for (TestAccount u : users) {
        usernames.add(u.username);
    }
    List<TestAccount> firstUsers = users.subList(0, 3);
    List<String> firstUsernames = usernames.subList(0, 3);
    PushOneCommit.Result r = createChange();
    String changeId = r.getChangeId();
    AddReviewerInput in = new AddReviewerInput();
    in.reviewer = groupOperations.newGroup().name("cc1").createName();
    in.state = CC;
    gApi.groups().id(in.reviewer).addMembers(firstUsernames.toArray(new String[firstUsernames.size()]));
    AddReviewerResult result = addReviewer(changeId, in);
    assertThat(result.input).isEqualTo(in.reviewer);
    assertThat(result.confirm).isNull();
    assertThat(result.error).isNull();
    if (notesMigration.readChanges()) {
        assertThat(result.reviewers).isNull();
    } else {
        assertThat(result.ccs).isNull();
    }
    ChangeInfo c = gApi.changes().id(r.getChangeId()).get();
    if (notesMigration.readChanges()) {
        assertReviewers(c, CC, firstUsers);
    } else {
        assertReviewers(c, REVIEWER, firstUsers);
        assertReviewers(c, CC);
    }
    // Verify emails were sent to each of the group's accounts.
    List<Message> messages = sender.getMessages();
    assertThat(messages).hasSize(1);
    Message m = messages.get(0);
    List<Address> expectedAddresses = new ArrayList<>(firstUsers.size());
    for (TestAccount u : firstUsers) {
        expectedAddresses.add(u.emailAddress);
    }
    assertThat(m.rcpt()).containsExactlyElementsIn(expectedAddresses);
    // CC a group that overlaps with some existing reviewers and CCed accounts.
    TestAccount reviewer = accountCreator.create(name("reviewer"), "addCcGroup-reviewer@example.com", "Reviewer");
    result = addReviewer(changeId, reviewer.username);
    assertThat(result.error).isNull();
    sender.clear();
    in.reviewer = groupOperations.newGroup().name("cc2").createName();
    gApi.groups().id(in.reviewer).addMembers(usernames.toArray(new String[usernames.size()]));
    gApi.groups().id(in.reviewer).addMembers(reviewer.username);
    result = addReviewer(changeId, in);
    assertThat(result.input).isEqualTo(in.reviewer);
    assertThat(result.confirm).isNull();
    assertThat(result.error).isNull();
    c = gApi.changes().id(r.getChangeId()).get();
    if (notesMigration.readChanges()) {
        assertThat(result.ccs).hasSize(3);
        assertThat(result.reviewers).isNull();
        assertReviewers(c, REVIEWER, reviewer);
        assertReviewers(c, CC, users);
    } else {
        assertThat(result.ccs).isNull();
        assertThat(result.reviewers).hasSize(3);
        List<TestAccount> expectedUsers = new ArrayList<>(users.size() + 2);
        expectedUsers.addAll(users);
        expectedUsers.add(reviewer);
        assertReviewers(c, REVIEWER, expectedUsers);
    }
    messages = sender.getMessages();
    assertThat(messages).hasSize(1);
    m = messages.get(0);
    expectedAddresses = new ArrayList<>(4);
    for (int i = 0; i < 3; i++) {
        expectedAddresses.add(users.get(users.size() - i - 1).emailAddress);
    }
    if (!notesMigration.readChanges()) {
        for (int i = 0; i < 3; i++) {
            expectedAddresses.add(users.get(i).emailAddress);
        }
    }
    expectedAddresses.add(reviewer.emailAddress);
    assertThat(m.rcpt()).containsExactlyElementsIn(expectedAddresses);
}
#method_after
@Test
public void addCcGroup() throws Exception {
    List<TestAccount> users = createAccounts(6, "addCcGroup");
    List<String> usernames = new ArrayList<>(6);
    for (TestAccount u : users) {
        usernames.add(u.username);
    }
    List<TestAccount> firstUsers = users.subList(0, 3);
    List<String> firstUsernames = usernames.subList(0, 3);
    PushOneCommit.Result r = createChange();
    String changeId = r.getChangeId();
    AddReviewerInput in = new AddReviewerInput();
    in.reviewer = groupOperations.newGroup().name("cc1").create().get();
    in.state = CC;
    gApi.groups().id(in.reviewer).addMembers(firstUsernames.toArray(new String[firstUsernames.size()]));
    AddReviewerResult result = addReviewer(changeId, in);
    assertThat(result.input).isEqualTo(in.reviewer);
    assertThat(result.confirm).isNull();
    assertThat(result.error).isNull();
    if (notesMigration.readChanges()) {
        assertThat(result.reviewers).isNull();
    } else {
        assertThat(result.ccs).isNull();
    }
    ChangeInfo c = gApi.changes().id(r.getChangeId()).get();
    if (notesMigration.readChanges()) {
        assertReviewers(c, CC, firstUsers);
    } else {
        assertReviewers(c, REVIEWER, firstUsers);
        assertReviewers(c, CC);
    }
    // Verify emails were sent to each of the group's accounts.
    List<Message> messages = sender.getMessages();
    assertThat(messages).hasSize(1);
    Message m = messages.get(0);
    List<Address> expectedAddresses = new ArrayList<>(firstUsers.size());
    for (TestAccount u : firstUsers) {
        expectedAddresses.add(u.emailAddress);
    }
    assertThat(m.rcpt()).containsExactlyElementsIn(expectedAddresses);
    // CC a group that overlaps with some existing reviewers and CCed accounts.
    TestAccount reviewer = accountCreator.create(name("reviewer"), "addCcGroup-reviewer@example.com", "Reviewer");
    result = addReviewer(changeId, reviewer.username);
    assertThat(result.error).isNull();
    sender.clear();
    in.reviewer = groupOperations.newGroup().name("cc2").create().get();
    gApi.groups().id(in.reviewer).addMembers(usernames.toArray(new String[usernames.size()]));
    gApi.groups().id(in.reviewer).addMembers(reviewer.username);
    result = addReviewer(changeId, in);
    assertThat(result.input).isEqualTo(in.reviewer);
    assertThat(result.confirm).isNull();
    assertThat(result.error).isNull();
    c = gApi.changes().id(r.getChangeId()).get();
    if (notesMigration.readChanges()) {
        assertThat(result.ccs).hasSize(3);
        assertThat(result.reviewers).isNull();
        assertReviewers(c, REVIEWER, reviewer);
        assertReviewers(c, CC, users);
    } else {
        assertThat(result.ccs).isNull();
        assertThat(result.reviewers).hasSize(3);
        List<TestAccount> expectedUsers = new ArrayList<>(users.size() + 2);
        expectedUsers.addAll(users);
        expectedUsers.add(reviewer);
        assertReviewers(c, REVIEWER, expectedUsers);
    }
    messages = sender.getMessages();
    assertThat(messages).hasSize(1);
    m = messages.get(0);
    expectedAddresses = new ArrayList<>(4);
    for (int i = 0; i < 3; i++) {
        expectedAddresses.add(users.get(users.size() - i - 1).emailAddress);
    }
    if (!notesMigration.readChanges()) {
        for (int i = 0; i < 3; i++) {
            expectedAddresses.add(users.get(i).emailAddress);
        }
    }
    expectedAddresses.add(reviewer.emailAddress);
    assertThat(m.rcpt()).containsExactlyElementsIn(expectedAddresses);
}
#end_block

#method_before
@Test
public void reviewAndAddGroupReviewers() throws Exception {
    int largeGroupSize = ReviewerAdder.DEFAULT_MAX_REVIEWERS + 1;
    int mediumGroupSize = ReviewerAdder.DEFAULT_MAX_REVIEWERS_WITHOUT_CHECK + 1;
    List<TestAccount> users = createAccounts(largeGroupSize, "reviewAndAddGroupReviewers");
    List<String> usernames = new ArrayList<>(largeGroupSize);
    for (TestAccount u : users) {
        usernames.add(u.username);
    }
    String largeGroup = groupOperations.newGroup().name("largeGroup").createName();
    String mediumGroup = groupOperations.newGroup().name("mediumGroup").createName();
    gApi.groups().id(largeGroup).addMembers(usernames.toArray(new String[largeGroupSize]));
    gApi.groups().id(mediumGroup).addMembers(usernames.subList(0, mediumGroupSize).toArray(new String[mediumGroupSize]));
    TestAccount observer = accountCreator.user2();
    PushOneCommit.Result r = createChange();
    // Attempt to add overly large group as reviewers.
    ReviewInput input = ReviewInput.approve().reviewer(user.email).reviewer(observer.email, CC, false).reviewer(largeGroup);
    ReviewResult result = review(r.getChangeId(), r.getCommit().name(), input, SC_BAD_REQUEST);
    assertThat(result.labels).isNull();
    assertThat(result.reviewers).isNotNull();
    assertThat(result.reviewers).hasSize(3);
    AddReviewerResult reviewerResult = result.reviewers.get(largeGroup);
    assertThat(reviewerResult).isNotNull();
    assertThat(reviewerResult.confirm).isNull();
    assertThat(reviewerResult.error).isNotNull();
    assertThat(reviewerResult.error).contains("has too many members to add them all as reviewers");
    // No labels should have changed, and no reviewers/CCs should have been added.
    ChangeInfo c = gApi.changes().id(r.getChangeId()).get();
    assertThat(c.messages).hasSize(1);
    assertThat(c.reviewers.get(REVIEWER)).isNull();
    assertThat(c.reviewers.get(CC)).isNull();
    // Attempt to add group large enough to require confirmation, without
    // confirmation, as reviewers.
    input = ReviewInput.approve().reviewer(user.email).reviewer(observer.email, CC, false).reviewer(mediumGroup);
    result = review(r.getChangeId(), r.getCommit().name(), input, SC_BAD_REQUEST);
    assertThat(result.labels).isNull();
    assertThat(result.reviewers).isNotNull();
    assertThat(result.reviewers).hasSize(3);
    reviewerResult = result.reviewers.get(mediumGroup);
    assertThat(reviewerResult).isNotNull();
    assertThat(reviewerResult.confirm).isTrue();
    assertThat(reviewerResult.error).contains("has " + mediumGroupSize + " members. Do you want to add them all as reviewers?");
    // No labels should have changed, and no reviewers/CCs should have been added.
    c = gApi.changes().id(r.getChangeId()).get();
    assertThat(c.messages).hasSize(1);
    assertThat(c.reviewers.get(REVIEWER)).isNull();
    assertThat(c.reviewers.get(CC)).isNull();
    // Retrying with confirmation should successfully approve and add reviewers/CCs.
    input = ReviewInput.approve().reviewer(user.email).reviewer(mediumGroup, CC, true);
    result = review(r.getChangeId(), r.getCommit().name(), input);
    assertThat(result.labels).isNotNull();
    assertThat(result.reviewers).isNotNull();
    assertThat(result.reviewers).hasSize(2);
    c = gApi.changes().id(r.getChangeId()).get();
    assertThat(c.messages).hasSize(2);
    if (notesMigration.readChanges()) {
        assertReviewers(c, REVIEWER, admin, user);
        assertReviewers(c, CC, users.subList(0, mediumGroupSize));
    } else {
        // If not in NoteDb mode, then everyone is a REVIEWER.
        List<TestAccount> expected = users.subList(0, mediumGroupSize);
        expected.add(admin);
        expected.add(user);
        assertReviewers(c, REVIEWER, expected);
        assertReviewers(c, CC);
    }
}
#method_after
@Test
public void reviewAndAddGroupReviewers() throws Exception {
    int largeGroupSize = ReviewerAdder.DEFAULT_MAX_REVIEWERS + 1;
    int mediumGroupSize = ReviewerAdder.DEFAULT_MAX_REVIEWERS_WITHOUT_CHECK + 1;
    List<TestAccount> users = createAccounts(largeGroupSize, "reviewAndAddGroupReviewers");
    List<String> usernames = new ArrayList<>(largeGroupSize);
    for (TestAccount u : users) {
        usernames.add(u.username);
    }
    String largeGroup = groupOperations.newGroup().name("largeGroup").create().get();
    String mediumGroup = groupOperations.newGroup().name("mediumGroup").create().get();
    gApi.groups().id(largeGroup).addMembers(usernames.toArray(new String[largeGroupSize]));
    gApi.groups().id(mediumGroup).addMembers(usernames.subList(0, mediumGroupSize).toArray(new String[mediumGroupSize]));
    TestAccount observer = accountCreator.user2();
    PushOneCommit.Result r = createChange();
    // Attempt to add overly large group as reviewers.
    ReviewInput input = ReviewInput.approve().reviewer(user.email).reviewer(observer.email, CC, false).reviewer(largeGroup);
    ReviewResult result = review(r.getChangeId(), r.getCommit().name(), input, SC_BAD_REQUEST);
    assertThat(result.labels).isNull();
    assertThat(result.reviewers).isNotNull();
    assertThat(result.reviewers).hasSize(3);
    AddReviewerResult reviewerResult = result.reviewers.get(largeGroup);
    assertThat(reviewerResult).isNotNull();
    assertThat(reviewerResult.confirm).isNull();
    assertThat(reviewerResult.error).isNotNull();
    assertThat(reviewerResult.error).contains("has too many members to add them all as reviewers");
    // No labels should have changed, and no reviewers/CCs should have been added.
    ChangeInfo c = gApi.changes().id(r.getChangeId()).get();
    assertThat(c.messages).hasSize(1);
    assertThat(c.reviewers.get(REVIEWER)).isNull();
    assertThat(c.reviewers.get(CC)).isNull();
    // Attempt to add group large enough to require confirmation, without
    // confirmation, as reviewers.
    input = ReviewInput.approve().reviewer(user.email).reviewer(observer.email, CC, false).reviewer(mediumGroup);
    result = review(r.getChangeId(), r.getCommit().name(), input, SC_BAD_REQUEST);
    assertThat(result.labels).isNull();
    assertThat(result.reviewers).isNotNull();
    assertThat(result.reviewers).hasSize(3);
    reviewerResult = result.reviewers.get(mediumGroup);
    assertThat(reviewerResult).isNotNull();
    assertThat(reviewerResult.confirm).isTrue();
    assertThat(reviewerResult.error).contains("has " + mediumGroupSize + " members. Do you want to add them all as reviewers?");
    // No labels should have changed, and no reviewers/CCs should have been added.
    c = gApi.changes().id(r.getChangeId()).get();
    assertThat(c.messages).hasSize(1);
    assertThat(c.reviewers.get(REVIEWER)).isNull();
    assertThat(c.reviewers.get(CC)).isNull();
    // Retrying with confirmation should successfully approve and add reviewers/CCs.
    input = ReviewInput.approve().reviewer(user.email).reviewer(mediumGroup, CC, true);
    result = review(r.getChangeId(), r.getCommit().name(), input);
    assertThat(result.labels).isNotNull();
    assertThat(result.reviewers).isNotNull();
    assertThat(result.reviewers).hasSize(2);
    c = gApi.changes().id(r.getChangeId()).get();
    assertThat(c.messages).hasSize(2);
    if (notesMigration.readChanges()) {
        assertReviewers(c, REVIEWER, admin, user);
        assertReviewers(c, CC, users.subList(0, mediumGroupSize));
    } else {
        // If not in NoteDb mode, then everyone is a REVIEWER.
        List<TestAccount> expected = users.subList(0, mediumGroupSize);
        expected.add(admin);
        expected.add(user);
        assertReviewers(c, REVIEWER, expected);
        assertReviewers(c, CC);
    }
}
#end_block

#method_before
@Test
public void addOverlappingGroups() throws Exception {
    String emailPrefix = "addOverlappingGroups-";
    TestAccount user1 = accountCreator.create(name("user1"), emailPrefix + "user1@example.com", "User1");
    TestAccount user2 = accountCreator.create(name("user2"), emailPrefix + "user2@example.com", "User2");
    TestAccount user3 = accountCreator.create(name("user3"), emailPrefix + "user3@example.com", "User3");
    String group1 = groupOperations.newGroup().name("group1").createName();
    String group2 = groupOperations.newGroup().name("group2").createName();
    gApi.groups().id(group1).addMembers(user1.username, user2.username);
    gApi.groups().id(group2).addMembers(user2.username, user3.username);
    PushOneCommit.Result r = createChange();
    ReviewInput input = ReviewInput.approve().reviewer(group1).reviewer(group2);
    ReviewResult result = review(r.getChangeId(), r.getCommit().name(), input);
    assertThat(result.reviewers).isNotNull();
    assertThat(result.reviewers).hasSize(2);
    AddReviewerResult reviewerResult = result.reviewers.get(group1);
    assertThat(reviewerResult.error).isNull();
    assertThat(reviewerResult.reviewers).hasSize(2);
    reviewerResult = result.reviewers.get(group2);
    assertThat(reviewerResult.error).isNull();
    assertThat(reviewerResult.reviewers).hasSize(1);
    // Repeat the above for CCs
    if (!notesMigration.readChanges()) {
        return;
    }
    r = createChange();
    input = ReviewInput.approve().reviewer(group1, CC, false).reviewer(group2, CC, false);
    result = review(r.getChangeId(), r.getCommit().name(), input);
    assertThat(result.reviewers).isNotNull();
    assertThat(result.reviewers).hasSize(2);
    reviewerResult = result.reviewers.get(group1);
    assertThat(reviewerResult.error).isNull();
    assertThat(reviewerResult.ccs).hasSize(2);
    reviewerResult = result.reviewers.get(group2);
    assertThat(reviewerResult.error).isNull();
    assertThat(reviewerResult.ccs).hasSize(1);
    // Repeat again with one group REVIEWER, the other CC. The overlapping
    // member should end up as a REVIEWER.
    r = createChange();
    input = ReviewInput.approve().reviewer(group1, REVIEWER, false).reviewer(group2, CC, false);
    result = review(r.getChangeId(), r.getCommit().name(), input);
    assertThat(result.reviewers).isNotNull();
    assertThat(result.reviewers).hasSize(2);
    reviewerResult = result.reviewers.get(group1);
    assertThat(reviewerResult.error).isNull();
    assertThat(reviewerResult.reviewers).hasSize(2);
    reviewerResult = result.reviewers.get(group2);
    assertThat(reviewerResult.error).isNull();
    assertThat(reviewerResult.reviewers).isNull();
    assertThat(reviewerResult.ccs).hasSize(1);
}
#method_after
@Test
public void addOverlappingGroups() throws Exception {
    String emailPrefix = "addOverlappingGroups-";
    TestAccount user1 = accountCreator.create(name("user1"), emailPrefix + "user1@example.com", "User1");
    TestAccount user2 = accountCreator.create(name("user2"), emailPrefix + "user2@example.com", "User2");
    TestAccount user3 = accountCreator.create(name("user3"), emailPrefix + "user3@example.com", "User3");
    String group1 = groupOperations.newGroup().name("group1").create().get();
    String group2 = groupOperations.newGroup().name("group2").create().get();
    gApi.groups().id(group1).addMembers(user1.username, user2.username);
    gApi.groups().id(group2).addMembers(user2.username, user3.username);
    PushOneCommit.Result r = createChange();
    ReviewInput input = ReviewInput.approve().reviewer(group1).reviewer(group2);
    ReviewResult result = review(r.getChangeId(), r.getCommit().name(), input);
    assertThat(result.reviewers).isNotNull();
    assertThat(result.reviewers).hasSize(2);
    AddReviewerResult reviewerResult = result.reviewers.get(group1);
    assertThat(reviewerResult.error).isNull();
    assertThat(reviewerResult.reviewers).hasSize(2);
    reviewerResult = result.reviewers.get(group2);
    assertThat(reviewerResult.error).isNull();
    assertThat(reviewerResult.reviewers).hasSize(1);
    // Repeat the above for CCs
    if (!notesMigration.readChanges()) {
        return;
    }
    r = createChange();
    input = ReviewInput.approve().reviewer(group1, CC, false).reviewer(group2, CC, false);
    result = review(r.getChangeId(), r.getCommit().name(), input);
    assertThat(result.reviewers).isNotNull();
    assertThat(result.reviewers).hasSize(2);
    reviewerResult = result.reviewers.get(group1);
    assertThat(reviewerResult.error).isNull();
    assertThat(reviewerResult.ccs).hasSize(2);
    reviewerResult = result.reviewers.get(group2);
    assertThat(reviewerResult.error).isNull();
    assertThat(reviewerResult.ccs).hasSize(1);
    // Repeat again with one group REVIEWER, the other CC. The overlapping
    // member should end up as a REVIEWER.
    r = createChange();
    input = ReviewInput.approve().reviewer(group1, REVIEWER, false).reviewer(group2, CC, false);
    result = review(r.getChangeId(), r.getCommit().name(), input);
    assertThat(result.reviewers).isNotNull();
    assertThat(result.reviewers).hasSize(2);
    reviewerResult = result.reviewers.get(group1);
    assertThat(reviewerResult.error).isNull();
    assertThat(reviewerResult.reviewers).hasSize(2);
    reviewerResult = result.reviewers.get(group2);
    assertThat(reviewerResult.error).isNull();
    assertThat(reviewerResult.reviewers).isNull();
    assertThat(reviewerResult.ccs).hasSize(1);
}
#end_block

#method_before
protected ContributorAgreement configureContributorAgreement(boolean autoVerify) throws Exception {
    ContributorAgreement ca;
    String name = autoVerify ? "cla-test-group" : "cla-test-no-auto-verify-group";
    String g = groupOperations.newGroup().name(name).createName();
    GroupApi groupApi = gApi.groups().id(g);
    groupApi.description("CLA test group");
    InternalGroup caGroup = group(new AccountGroup.UUID(groupApi.detail().id));
    GroupReference groupRef = new GroupReference(caGroup.getGroupUUID(), caGroup.getName());
    PermissionRule rule = new PermissionRule(groupRef);
    rule.setAction(PermissionRule.Action.ALLOW);
    if (autoVerify) {
        ca = new ContributorAgreement("cla-test");
        ca.setAutoVerify(groupRef);
        ca.setAccepted(ImmutableList.of(rule));
    } else {
        ca = new ContributorAgreement("cla-test-no-auto-verify");
    }
    ca.setDescription("description");
    ca.setAgreementUrl("agreement-url");
    ca.setAccepted(ImmutableList.of(rule));
    ca.setExcludeProjectsRegexes(ImmutableList.of("ExcludedProject"));
    try (ProjectConfigUpdate u = updateProject(allProjects)) {
        u.getConfig().replace(ca);
        u.save();
        return ca;
    }
}
#method_after
protected ContributorAgreement configureContributorAgreement(boolean autoVerify) throws Exception {
    ContributorAgreement ca;
    String name = autoVerify ? "cla-test-group" : "cla-test-no-auto-verify-group";
    String g = groupOperations.newGroup().name(name).create().get();
    GroupApi groupApi = gApi.groups().id(g);
    groupApi.description("CLA test group");
    InternalGroup caGroup = group(new AccountGroup.UUID(groupApi.detail().id));
    GroupReference groupRef = new GroupReference(caGroup.getGroupUUID(), caGroup.getName());
    PermissionRule rule = new PermissionRule(groupRef);
    rule.setAction(PermissionRule.Action.ALLOW);
    if (autoVerify) {
        ca = new ContributorAgreement("cla-test");
        ca.setAutoVerify(groupRef);
        ca.setAccepted(ImmutableList.of(rule));
    } else {
        ca = new ContributorAgreement("cla-test-no-auto-verify");
    }
    ca.setDescription("description");
    ca.setAgreementUrl("agreement-url");
    ca.setAccepted(ImmutableList.of(rule));
    ca.setExcludeProjectsRegexes(ImmutableList.of("ExcludedProject"));
    try (ProjectConfigUpdate u = updateProject(allProjects)) {
        u.getConfig().replace(ca);
        u.save();
        return ca;
    }
}
#end_block

#method_before
@Test
public void allGroupsForAUserAccountCanBeRetrieved() throws Exception {
    String username = name("user1");
    accountOperations.newAccount().username(username).create();
    String group = groupOperations.newGroup().name("group").createName();
    gApi.groups().id(group).addMembers(username);
    List<GroupInfo> allGroups = gApi.accounts().id(username).getGroups();
    assertThat(allGroups).comparingElementsUsing(getGroupToNameCorrespondence()).containsExactly("Anonymous Users", "Registered Users", group);
}
#method_after
@Test
public void allGroupsForAUserAccountCanBeRetrieved() throws Exception {
    String username = name("user1");
    accountOperations.newAccount().username(username).create();
    AccountGroup.UUID groupID = groupOperations.newGroup().name("group").create();
    String group = groupOperations.group(groupID).get().name();
    gApi.groups().id(group).addMembers(username);
    List<GroupInfo> allGroups = gApi.accounts().id(username).getGroups();
    assertThat(allGroups).comparingElementsUsing(getGroupToNameCorrespondence()).containsExactly("Anonymous Users", "Registered Users", group);
}
#end_block

#method_before
@Override
public Map<String, List<ConfigUpdateEntryInfo>> apply(ConfigResource resource, Input input) throws RestApiException, PermissionBackendException {
    permissions.currentUser().check(GlobalPermission.ADMINISTRATE_SERVER);
    Map<ConfigUpdatedEvent.UpdateResult, Set<ConfigUpdatedEvent.ConfigUpdateEntry>> updates = config.reloadConfig();
    if (updates.isEmpty()) {
        return Collections.emptyMap();
    }
    return updates.keySet().stream().collect(Collectors.toMap(k -> k.name().toLowerCase(), k -> toEntryInfos(updates.get(k))));
}
#method_after
@Override
public Map<String, List<ConfigUpdateEntryInfo>> apply(ConfigResource resource, Input input) throws RestApiException, PermissionBackendException {
    permissions.currentUser().check(GlobalPermission.ADMINISTRATE_SERVER);
    Multimap<UpdateResult, ConfigUpdateEntry> updates = config.reloadConfig();
    if (updates.isEmpty()) {
        return Collections.emptyMap();
    }
    return updates.asMap().entrySet().stream().collect(Collectors.toMap(e -> e.getKey().name().toLowerCase(), e -> toEntryInfos(e.getValue())));
}
#end_block

#method_before
private static List<ConfigUpdateEntryInfo> toEntryInfos(Set<ConfigUpdateEntry> updateEntries) {
    return updateEntries.stream().map(ReloadConfig::toConfigUpdateEntryInfo).collect(toImmutableList());
}
#method_after
private static List<ConfigUpdateEntryInfo> toEntryInfos(Collection<ConfigUpdateEntry> updateEntries) {
    return updateEntries.stream().map(ReloadConfig::toConfigUpdateEntryInfo).collect(toImmutableList());
}
#end_block

#method_before
@Override
public Optional<ConfigUpdatedEvent.Update> configUpdated(ConfigUpdatedEvent event) {
    ConfigKey sshdRequestLog = ConfigKey.create("sshd", "requestLog");
    if (!event.isValueUpdated(sshdRequestLog)) {
        return Optional.empty();
    }
    boolean stateUpdated;
    try {
        boolean enabled = event.getNewConfig().getBoolean("sshd", "requestLog", true);
        if (enabled) {
            stateUpdated = enableLogging();
        } else {
            stateUpdated = disableLogging();
        }
        return stateUpdated ? Optional.of(event.accept(sshdRequestLog)) : Optional.empty();
    } catch (IllegalArgumentException iae) {
        return Optional.of(event.reject(sshdRequestLog));
    }
}
#method_after
@Override
public Multimap<UpdateResult, ConfigUpdateEntry> configUpdated(ConfigUpdatedEvent event) {
    ConfigKey sshdRequestLog = ConfigKey.create("sshd", "requestLog");
    if (!event.isValueUpdated(sshdRequestLog)) {
        return ConfigUpdatedEvent.NO_UPDATES;
    }
    boolean stateUpdated;
    try {
        boolean enabled = event.getNewConfig().getBoolean("sshd", "requestLog", true);
        if (enabled) {
            stateUpdated = enableLogging();
        } else {
            stateUpdated = disableLogging();
        }
        return stateUpdated ? event.accept(sshdRequestLog) : ConfigUpdatedEvent.NO_UPDATES;
    } catch (IllegalArgumentException iae) {
        return event.reject(sshdRequestLog);
    }
}
#end_block

#method_before
public Map<ConfigUpdatedEvent.UpdateResult, Set<ConfigUpdatedEvent.ConfigUpdateEntry>> reloadConfig() {
    logger.atInfo().log("Starting server configuration reload");
    Map<ConfigUpdatedEvent.UpdateResult, Set<ConfigUpdatedEvent.ConfigUpdateEntry>> updates = fireUpdatedConfigEvent(configProvider.updateConfig());
    logger.atInfo().log("Server configuration reload completed succesfully");
    return updates;
}
#method_after
public Multimap<UpdateResult, ConfigUpdateEntry> reloadConfig() {
    logger.atInfo().log("Starting server configuration reload");
    Multimap<UpdateResult, ConfigUpdateEntry> updates = fireUpdatedConfigEvent(configProvider.updateConfig());
    logger.atInfo().log("Server configuration reload completed succesfully");
    return updates;
}
#end_block

#method_before
public Map<ConfigUpdatedEvent.UpdateResult, Set<ConfigUpdatedEvent.ConfigUpdateEntry>> fireUpdatedConfigEvent(ConfigUpdatedEvent event) {
    Map<ConfigUpdatedEvent.UpdateResult, Set<ConfigUpdatedEvent.ConfigUpdateEntry>> updates = new HashMap<>();
    for (GerritConfigListener configListener : configListeners) {
        configListener.configUpdated(event).ifPresent(value -> value.getUpdates().forEach((k, v) -> {
            if (updates.containsKey(k)) {
                updates.get(k).addAll(v);
            } else {
                updates.put(k, v);
            }
        }));
    }
    return updates;
}
#method_after
public Multimap<UpdateResult, ConfigUpdateEntry> fireUpdatedConfigEvent(ConfigUpdatedEvent event) {
    Multimap<UpdateResult, ConfigUpdateEntry> updates = ArrayListMultimap.create();
    for (GerritConfigListener configListener : configListeners) {
        updates.putAll(configListener.configUpdated(event));
    }
    return updates;
}
#end_block

#method_before
public Update accept(ConfigKey entry) {
    return accept(Collections.singleton(entry));
}
#method_after
public Multimap<UpdateResult, ConfigUpdateEntry> accept(ConfigKey entry) {
    return accept(Collections.singleton(entry));
}
#end_block

#method_before
public Update accept(Set<ConfigKey> entries) {
    return createUpdate(entries, UpdateResult.APPLIED);
}
#method_after
public Multimap<UpdateResult, ConfigUpdateEntry> accept(Set<ConfigKey> entries) {
    return createUpdate(entries, UpdateResult.APPLIED);
}
#end_block

#method_before
public Update accept(String section) {
    Set<ConfigKey> entries = getEntriesFromSection(oldConfig, section);
    entries.addAll(getEntriesFromSection(newConfig, section));
    return createUpdate(entries, UpdateResult.APPLIED);
}
#method_after
public Multimap<UpdateResult, ConfigUpdateEntry> accept(String section) {
    Set<ConfigKey> entries = getEntriesFromSection(oldConfig, section);
    entries.addAll(getEntriesFromSection(newConfig, section));
    return createUpdate(entries, UpdateResult.APPLIED);
}
#end_block

#method_before
public Update reject(ConfigKey entry) {
    return reject(Collections.singleton(entry));
}
#method_after
public Multimap<UpdateResult, ConfigUpdateEntry> reject(ConfigKey entry) {
    return reject(Collections.singleton(entry));
}
#end_block

#method_before
public Update reject(Set<ConfigKey> entries) {
    return createUpdate(entries, UpdateResult.REJECTED);
}
#method_after
public Multimap<UpdateResult, ConfigUpdateEntry> reject(Set<ConfigKey> entries) {
    return createUpdate(entries, UpdateResult.REJECTED);
}
#end_block

#method_before
private Update createUpdate(Set<ConfigKey> entries, UpdateResult updateResult) {
    Update update = new Update();
    entries.stream().filter(this::isValueUpdated).forEach(key -> {
        update.addConfigUpdate(new ConfigUpdateEntry(key, oldConfig.getString(key.section(), key.subsection(), key.name()), newConfig.getString(key.section(), key.subsection(), key.name())), updateResult);
    });
    return update;
}
#method_after
private Multimap<UpdateResult, ConfigUpdateEntry> createUpdate(Set<ConfigKey> entries, UpdateResult updateResult) {
    Multimap<UpdateResult, ConfigUpdateEntry> updates = ArrayListMultimap.create();
    entries.stream().filter(this::isValueUpdated).map(e -> new ConfigUpdateEntry(e, getString(e, oldConfig), getString(e, newConfig))).forEach(e -> updates.put(updateResult, e));
    return updates;
}
#end_block

#method_before
@Override
public Optional<ConfigUpdatedEvent.Update> configUpdated(ConfigUpdatedEvent event) {
    if (event.isSectionUpdated(ProjectConfig.COMMENTLINK)) {
        commentLinks = parseConfig(event.getNewConfig());
        return Optional.of(event.accept(ProjectConfig.COMMENTLINK));
    }
    return Optional.empty();
}
#method_after
@Override
public Multimap<UpdateResult, ConfigUpdateEntry> configUpdated(ConfigUpdatedEvent event) {
    if (event.isSectionUpdated(ProjectConfig.COMMENTLINK)) {
        commentLinks = parseConfig(event.getNewConfig());
        return event.accept(ProjectConfig.COMMENTLINK);
    }
    return ConfigUpdatedEvent.NO_UPDATES;
}
#end_block

#method_before
@Override
public Optional<ConfigUpdatedEvent.Update> configUpdated(ConfigUpdatedEvent event) {
    ConfigKey receiveSetParent = ConfigKey.create("receive", "allowProjectOwnersToChangeParent");
    if (!event.isValueUpdated(receiveSetParent)) {
        return Optional.empty();
    }
    try {
        boolean enabled = event.getNewConfig().getBoolean("receive", "allowProjectOwnersToChangeParent", false);
        this.allowProjectOwnersToChangeParent = enabled;
        return Optional.of(event.accept(receiveSetParent));
    } catch (IllegalArgumentException iae) {
        return Optional.of(event.reject(receiveSetParent));
    }
}
#method_after
@Override
public Multimap<UpdateResult, ConfigUpdateEntry> configUpdated(ConfigUpdatedEvent event) {
    ConfigKey receiveSetParent = ConfigKey.create("receive", "allowProjectOwnersToChangeParent");
    if (!event.isValueUpdated(receiveSetParent)) {
        return ConfigUpdatedEvent.NO_UPDATES;
    }
    try {
        boolean enabled = event.getNewConfig().getBoolean("receive", "allowProjectOwnersToChangeParent", false);
        this.allowProjectOwnersToChangeParent = enabled;
    } catch (IllegalArgumentException iae) {
        return event.reject(receiveSetParent);
    }
    return event.accept(receiveSetParent);
}
#end_block

#method_before
public static GerritConfigListener acceptIfChanged(ConfigKey... keys) {
    return e -> e.isEntriesUpdated(ImmutableSet.copyOf(keys)) ? Optional.of(e.accept(ImmutableSet.copyOf(keys))) : Optional.empty();
}
#method_after
public static GerritConfigListener acceptIfChanged(ConfigKey... keys) {
    return e -> e.isEntriesUpdated(ImmutableSet.copyOf(keys)) ? e.accept(ImmutableSet.copyOf(keys)) : ConfigUpdatedEvent.NO_UPDATES;
}
#end_block

#method_before
@Override
protected void run() throws Failure {
    Map<UpdateResult, Set<ConfigUpdateEntry>> updates = gerritServerConfigReloader.reloadConfig();
    if (updates.isEmpty()) {
        stdout.println("No config entries updated!");
        return;
    }
    // Print out UpdateResult.{ACCEPTED|REJECTED} entries grouped by their type
    for (UpdateResult result : UpdateResult.values()) {
        if (!updates.containsKey(result)) {
            continue;
        }
        stdout.println(result.toString() + " configuration changes:");
        updates.get(result).forEach(cfgEntry -> stdout.println(cfgEntry.toString()));
    }
}
#method_after
@Override
protected void run() throws Failure {
    Multimap<UpdateResult, ConfigUpdateEntry> updates = gerritServerConfigReloader.reloadConfig();
    if (updates.isEmpty()) {
        stdout.println("No config entries updated!");
        return;
    }
    // Print out UpdateResult.{ACCEPTED|REJECTED} entries grouped by their type
    for (UpdateResult result : updates.keySet()) {
        stdout.println(result.toString() + " configuration changes:");
        updates.get(result).forEach(cfgEntry -> stdout.println(cfgEntry.toString()));
    }
}
#end_block

#method_before
HttpResult post(String endpoint, Object content) throws IOException {
    HttpPost post = new HttpPost(getPeerInfo().getDirectUrl() + endpoint);
    if (content != null) {
        post.addHeader("Content-Type", MediaType.JSON_UTF_8.toString());
        post.setEntity(new StringEntity(gson.toJson(content), Charsets.UTF_8));
    }
    return httpClient.execute(post, new HttpResponseHandler());
}
#method_after
HttpResult post(String endpoint, Object content) throws IOException {
    HttpPost post = new HttpPost(getPeerInfo().getDirectUrl() + endpoint);
    setContent(post, content);
    return httpClient.execute(post, new HttpResponseHandler());
}
#end_block

#method_before
HttpResult delete(String endpoint) throws IOException {
    return httpClient.execute(new HttpDelete(getPeerInfo().getDirectUrl() + endpoint), new HttpResponseHandler());
}
#method_after
HttpResult delete(String endpoint) throws IOException {
    return delete(endpoint, null);
}
#end_block

#method_before
HttpResult delete(String endpoint) throws IOException {
    return httpClient.execute(new HttpDelete(getPeerInfo().getDirectUrl() + endpoint), new HttpResponseHandler());
}
#method_after
HttpResult delete(String endpoint, Object content) throws IOException {
    HttpDeleteWithBody delete = new HttpDeleteWithBody(getPeerInfo().getDirectUrl() + endpoint);
    setContent(delete, content);
    return httpClient.execute(delete, new HttpResponseHandler());
}
#end_block

#method_before
private void process(HttpServletRequest req, HttpServletResponse rsp, Operation operation) {
    setHeaders(rsp);
    String path = req.getRequestURI();
    T id = parse(path.substring(path.lastIndexOf('/') + 1));
    Optional<Object> maybeBody = Optional.empty();
    try {
        String contentType = req.getContentType();
        if (contentType != null && contentType.contains("application/json")) {
            maybeBody = parseBody(req.getInputStream());
            forwardedIndexingHandler.index(id, operation, maybeBody);
        } else {
            forwardedIndexingHandler.index(id, operation);
        }
        rsp.setStatus(SC_NO_CONTENT);
    } catch (IOException e) {
        sendError(rsp, SC_CONFLICT, e.getMessage());
        log.error("Unable to update {} index", indexName, e);
    } catch (OrmException e) {
        String msg = String.format("Error trying to find %s", indexName);
        sendError(rsp, SC_NOT_FOUND, msg);
        log.debug(msg, e);
    }
}
#method_after
private void process(HttpServletRequest req, HttpServletResponse rsp, Operation operation) {
    setHeaders(rsp);
    String path = req.getRequestURI();
    T id = parse(path.substring(path.lastIndexOf('/') + 1));
    try {
        forwardedIndexingHandler.index(id, operation, parseBody(req));
        rsp.setStatus(SC_NO_CONTENT);
    } catch (IOException e) {
        sendError(rsp, SC_CONFLICT, e.getMessage());
        log.error("Unable to update {} index", indexName, e);
    } catch (OrmException e) {
        String msg = String.format("Error trying to find %s", indexName);
        sendError(rsp, SC_NOT_FOUND, msg);
        log.debug(msg, e);
    }
}
#end_block

#method_before
protected Optional<Object> parseBody(ServletInputStream bodyIn) {
    return Optional.empty();
}
#method_after
protected Optional<IndexEvent> parseBody(HttpServletRequest req) throws IOException {
    String contentType = req.getContentType();
    if (contentType != null && contentType.contains("application/json")) {
        return Optional.ofNullable(gson.fromJson(new InputStreamReader(req.getInputStream(), Charsets.UTF_8), IndexEvent.class));
    }
    return Optional.empty();
}
#end_block

#method_before
@Test
public void testIndexAccountOK() throws Exception {
    when(httpSessionMock.post(INDEX_ACCOUNT_ENDPOINT)).thenReturn(new HttpResult(SUCCESSFUL, EMPTY_MSG));
    assertThat(forwarder.indexAccount(ACCOUNT_NUMBER)).isTrue();
}
#method_after
@Test
public void testIndexAccountOK() throws Exception {
    when(httpSessionMock.post(eq(INDEX_ACCOUNT_ENDPOINT), any())).thenReturn(new HttpResult(SUCCESSFUL, EMPTY_MSG));
    assertThat(forwarder.indexAccount(ACCOUNT_NUMBER, new IndexEvent())).isTrue();
}
#end_block

#method_before
@Test
public void testIndexAccountFailed() throws Exception {
    when(httpSessionMock.post(INDEX_ACCOUNT_ENDPOINT)).thenReturn(new HttpResult(FAILED, EMPTY_MSG));
    assertThat(forwarder.indexAccount(ACCOUNT_NUMBER)).isFalse();
}
#method_after
@Test
public void testIndexAccountFailed() throws Exception {
    when(httpSessionMock.post(eq(INDEX_ACCOUNT_ENDPOINT), any())).thenReturn(new HttpResult(FAILED, EMPTY_MSG));
    assertThat(forwarder.indexAccount(ACCOUNT_NUMBER, new IndexEvent())).isFalse();
}
#end_block

#method_before
@Test
public void testIndexAccountThrowsException() throws Exception {
    doThrow(new IOException()).when(httpSessionMock).post(INDEX_ACCOUNT_ENDPOINT);
    assertThat(forwarder.indexAccount(ACCOUNT_NUMBER)).isFalse();
}
#method_after
@Test
public void testIndexAccountThrowsException() throws Exception {
    doThrow(new IOException()).when(httpSessionMock).post(eq(INDEX_ACCOUNT_ENDPOINT), any());
    assertThat(forwarder.indexAccount(ACCOUNT_NUMBER, new IndexEvent())).isFalse();
}
#end_block

#method_before
@Test
public void testIndexGroupOK() throws Exception {
    when(httpSessionMock.post(INDEX_GROUP_ENDPOINT)).thenReturn(new HttpResult(SUCCESSFUL, EMPTY_MSG));
    assertThat(forwarder.indexGroup(UUID)).isTrue();
}
#method_after
@Test
public void testIndexGroupOK() throws Exception {
    when(httpSessionMock.post(eq(INDEX_GROUP_ENDPOINT), any())).thenReturn(new HttpResult(SUCCESSFUL, EMPTY_MSG));
    assertThat(forwarder.indexGroup(UUID, new IndexEvent())).isTrue();
}
#end_block

#method_before
@Test
public void testIndexGroupFailed() throws Exception {
    when(httpSessionMock.post(INDEX_GROUP_ENDPOINT)).thenReturn(new HttpResult(FAILED, EMPTY_MSG));
    assertThat(forwarder.indexGroup(UUID)).isFalse();
}
#method_after
@Test
public void testIndexGroupFailed() throws Exception {
    when(httpSessionMock.post(eq(INDEX_GROUP_ENDPOINT), any())).thenReturn(new HttpResult(FAILED, EMPTY_MSG));
    assertThat(forwarder.indexGroup(UUID, new IndexEvent())).isFalse();
}
#end_block

#method_before
@Test
public void testIndexGroupThrowsException() throws Exception {
    doThrow(new IOException()).when(httpSessionMock).post(INDEX_GROUP_ENDPOINT);
    assertThat(forwarder.indexGroup(UUID)).isFalse();
}
#method_after
@Test
public void testIndexGroupThrowsException() throws Exception {
    doThrow(new IOException()).when(httpSessionMock).post(eq(INDEX_GROUP_ENDPOINT), any());
    assertThat(forwarder.indexGroup(UUID, new IndexEvent())).isFalse();
}
#end_block

#method_before
@Test
public void testIndexChangeOK() throws Exception {
    when(httpSessionMock.post(eq(INDEX_CHANGE_ENDPOINT), any())).thenReturn(new HttpResult(SUCCESSFUL, EMPTY_MSG));
    assertThat(forwarder.indexChange(PROJECT_NAME, CHANGE_NUMBER)).isTrue();
}
#method_after
@Test
public void testIndexChangeOK() throws Exception {
    when(httpSessionMock.post(eq(INDEX_CHANGE_ENDPOINT), any())).thenReturn(new HttpResult(SUCCESSFUL, EMPTY_MSG));
    assertThat(forwarder.indexChange(PROJECT_NAME, CHANGE_NUMBER, new IndexEvent())).isTrue();
}
#end_block

#method_before
@Test
public void testIndexChangeFailed() throws Exception {
    when(httpSessionMock.post(eq(INDEX_CHANGE_ENDPOINT), any())).thenReturn(new HttpResult(FAILED, EMPTY_MSG));
    assertThat(forwarder.indexChange(PROJECT_NAME, CHANGE_NUMBER)).isFalse();
}
#method_after
@Test
public void testIndexChangeFailed() throws Exception {
    when(httpSessionMock.post(eq(INDEX_CHANGE_ENDPOINT), any())).thenReturn(new HttpResult(FAILED, EMPTY_MSG));
    assertThat(forwarder.indexChange(PROJECT_NAME, CHANGE_NUMBER, new IndexEvent())).isFalse();
}
#end_block

#method_before
@Test
public void testIndexChangeThrowsException() throws Exception {
    doThrow(new IOException()).when(httpSessionMock).post(eq(INDEX_CHANGE_ENDPOINT), any());
    assertThat(forwarder.indexChange(PROJECT_NAME, CHANGE_NUMBER)).isFalse();
}
#method_after
@Test
public void testIndexChangeThrowsException() throws Exception {
    doThrow(new IOException()).when(httpSessionMock).post(eq(INDEX_CHANGE_ENDPOINT), any());
    assertThat(forwarder.indexChange(PROJECT_NAME, CHANGE_NUMBER, new IndexEvent())).isFalse();
}
#end_block

#method_before
@Test
public void testChangeDeletedFromIndexOK() throws Exception {
    when(httpSessionMock.delete(DELETE_CHANGE_ENDPOINT)).thenReturn(new HttpResult(SUCCESSFUL, EMPTY_MSG));
    assertThat(forwarder.deleteChangeFromIndex(CHANGE_NUMBER)).isTrue();
}
#method_after
@Test
public void testChangeDeletedFromIndexOK() throws Exception {
    when(httpSessionMock.delete(eq(DELETE_CHANGE_ENDPOINT), any())).thenReturn(new HttpResult(SUCCESSFUL, EMPTY_MSG));
    assertThat(forwarder.deleteChangeFromIndex(CHANGE_NUMBER, new IndexEvent())).isTrue();
}
#end_block

#method_before
@Test
public void testChangeDeletedFromIndexFailed() throws Exception {
    when(httpSessionMock.delete(DELETE_CHANGE_ENDPOINT)).thenReturn(new HttpResult(FAILED, EMPTY_MSG));
    assertThat(forwarder.deleteChangeFromIndex(CHANGE_NUMBER)).isFalse();
}
#method_after
@Test
public void testChangeDeletedFromIndexFailed() throws Exception {
    when(httpSessionMock.delete(eq(DELETE_CHANGE_ENDPOINT), any())).thenReturn(new HttpResult(FAILED, EMPTY_MSG));
    assertThat(forwarder.deleteChangeFromIndex(CHANGE_NUMBER, new IndexEvent())).isFalse();
}
#end_block

#method_before
@Test
public void testChangeDeletedFromThrowsException() throws Exception {
    doThrow(new IOException()).when(httpSessionMock).delete(DELETE_CHANGE_ENDPOINT);
    assertThat(forwarder.deleteChangeFromIndex(CHANGE_NUMBER)).isFalse();
}
#method_after
@Test
public void testChangeDeletedFromThrowsException() throws Exception {
    doThrow(new IOException()).when(httpSessionMock).delete(eq(DELETE_CHANGE_ENDPOINT), any());
    assertThat(forwarder.deleteChangeFromIndex(CHANGE_NUMBER, new IndexEvent())).isFalse();
}
#end_block

#method_before
@Override
protected void doIndex(String id, Optional<Object> maybeBody) throws IOException, OrmException {
    ChangeNotes change = null;
    try (ReviewDb db = schemaFactory.open()) {
        change = changeFinder.findOne(id);
        if (change != null) {
            indexer.index(db, change.getChange());
            log.debug("Change {} successfully indexed", id);
        }
    } catch (Exception e) {
        if (!isCausedByNoSuchChangeException(e)) {
            throw e;
        }
        log.debug("Change {} was deleted, aborting forwarded indexing the change.", id);
    }
    if (change == null) {
        indexer.delete(parseChangeId(id));
        log.debug("Change {} not found, deleted from index", id);
    }
}
#method_after
@Override
protected void doIndex(String id, Optional<IndexEvent> indexEvent) throws IOException, OrmException {
    ChangeNotes change = null;
    try (ReviewDb db = schemaFactory.open()) {
        change = changeFinder.findOne(id);
        if (change != null) {
            change.reload();
            indexer.index(db, change.getChange());
            log.debug("Change {} successfully indexed", id);
        }
    } catch (Exception e) {
        if (!isCausedByNoSuchChangeException(e)) {
            throw e;
        }
        log.debug("Change {} was deleted, aborting forwarded indexing the change.", id);
    }
    if (change == null) {
        indexer.delete(parseChangeId(id));
        log.debug("Change {} not found, deleted from index", id);
    }
}
#end_block

#method_before
@Override
protected void doDelete(String id) throws IOException {
    indexer.delete(parseChangeId(id));
    log.debug("Change {} successfully deleted from index", id);
}
#method_after
@Override
protected void doDelete(String id, Optional<IndexEvent> indexEvent) throws IOException {
    indexer.delete(parseChangeId(id));
    log.debug("Change {} successfully deleted from index", id);
}
#end_block

#method_before
public void index(T id, Operation operation, Optional<Object> maybeBody) throws IOException, OrmException {
    log.debug("{} {} {}", operation, id, maybeBody);
    try {
        Context.setForwardedEvent(true);
        Lock idLock = idLocks.get(id);
        idLock.lock();
        try {
            switch(operation) {
                case INDEX:
                    doIndex(id, maybeBody);
                    break;
                case DELETE:
                    doDelete(id);
                    break;
                default:
                    log.error("unexpected operation: {}", operation);
                    break;
            }
        } finally {
            idLock.unlock();
        }
    } finally {
        Context.unsetForwardedEvent();
    }
}
#method_after
public void index(T id, Operation operation, Optional<IndexEvent> indexEvent) throws IOException, OrmException {
    log.debug("{} {} {}", operation, id, indexEvent);
    try {
        Context.setForwardedEvent(true);
        Lock idLock = idLocks.get(id);
        idLock.lock();
        try {
            switch(operation) {
                case INDEX:
                    doIndex(id, indexEvent);
                    break;
                case DELETE:
                    doDelete(id, indexEvent);
                    break;
                default:
                    log.error("unexpected operation: {}", operation);
                    break;
            }
        } finally {
            idLock.unlock();
        }
    } finally {
        Context.unsetForwardedEvent();
    }
}
#end_block

#method_before
@Override
public boolean indexAccount(final int accountId) {
    return new Request("index account", accountId) {

        @Override
        HttpResult send() throws IOException {
            return httpSession.post(Joiner.on("/").join(pluginRelativePath, "index/account", accountId));
        }
    }.execute();
}
#method_after
@Override
public boolean indexAccount(final int accountId, IndexEvent event) {
    return new Request("index account", accountId) {

        @Override
        HttpResult send() throws IOException {
            return httpSession.post(Joiner.on("/").join(pluginRelativePath, "index/account", accountId), event);
        }
    }.execute();
}
#end_block

#method_before
@Override
public boolean indexChange(final String projectName, final int changeId, final long eventTs) {
    return new Request("index change", changeId) {

        @Override
        HttpResult send() throws IOException {
            return httpSession.post(buildIndexEndpoint(projectName, changeId), new ChangeIndexedEvent());
        }
    }.execute();
}
#method_after
@Override
public boolean indexChange(String projectName, int changeId, IndexEvent event) {
    return new Request("index change", changeId) {

        @Override
        HttpResult send() throws IOException {
            return httpSession.post(buildIndexEndpoint(projectName, changeId), event);
        }
    }.execute();
}
#end_block

#method_before
@Override
public boolean deleteChangeFromIndex(final int changeId) {
    return new Request("delete change", changeId) {

        @Override
        HttpResult send() throws IOException {
            return httpSession.delete(buildIndexEndpoint(changeId));
        }
    }.execute();
}
#method_after
@Override
public boolean deleteChangeFromIndex(final int changeId, IndexEvent event) {
    return new Request("delete change", changeId) {

        @Override
        HttpResult send() throws IOException {
            return httpSession.delete(buildIndexEndpoint(changeId), event);
        }
    }.execute();
}
#end_block

#method_before
@Override
public boolean indexGroup(final String uuid) {
    return new Request("index group", uuid) {

        @Override
        HttpResult send() throws IOException {
            return httpSession.post(Joiner.on("/").join(pluginRelativePath, "index/group", uuid));
        }
    }.execute();
}
#method_after
@Override
public boolean indexGroup(final String uuid, IndexEvent event) {
    return new Request("index group", uuid) {

        @Override
        HttpResult send() throws IOException {
            return httpSession.post(Joiner.on("/").join(pluginRelativePath, "index/group", uuid), event);
        }
    }.execute();
}
#end_block

#method_before
boolean isRecoverable(IOException e) {
    return !(e instanceof SSLException);
}
#method_after
boolean isRecoverable(IOException e) {
    Throwable cause = e.getCause();
    return !(e instanceof SSLException || cause instanceof HttpException || cause instanceof ClientProtocolException);
}
#end_block

#method_before
private void setDefaults() {
    put("acks", "all");
    put("retries", 0);
    put("batch.size", 16384);
    put("linger.ms", 1);
    put("buffer.memory", 33554432);
    put("key.serializer", StringSerializer.class.getName());
    put("value.serializer", StringSerializer.class.getName());
}
#method_after
private void setDefaults() {
    put("acks", "all");
    put("retries", 0);
    put("batch.size", 16384);
    put("linger.ms", 1);
    put("buffer.memory", 33554432);
    put("key.serializer", KAFKA_STRING_SERIALIZER);
    put("value.serializer", KAFKA_STRING_SERIALIZER);
}
#end_block

#method_before
public void connect() {
    if (isOpen()) {
        LOGGER.debug("Already connected.");
        return;
    }
    LOGGER.info("Connect to {}...", properties.getProperty("bootstrap.servers"));
    producer = new KafkaProducer<>(properties);
    LOGGER.info("Connection established.");
}
#method_after
public void connect() {
    if (isOpen()) {
        LOGGER.debug("Already connected.");
        return;
    }
    LOGGER.info("Connect to {}...", properties.getProperty("bootstrap.servers"));
    /* Need to make sure that the thread of the running connection uses
     * the correct class loader otherwize you can endup with hard to debug
     * ClassNotFoundExceptions
     */
    setConnectionClassLoader();
    producer = new KafkaProducer<>(properties);
    LOGGER.info("Connection established.");
}
#end_block

#method_before
@Test
public void addReviewerThatIsInactive() throws Exception {
    PushOneCommit.Result result = createChange();
    String username = name("new-user");
    gApi.accounts().create(username).setActive(false);
    AddReviewerInput in = new AddReviewerInput();
    in.reviewer = username;
    AddReviewerResult r = gApi.changes().id(result.getChangeId()).addReviewer(in);
    assertThat(r.input).isEqualTo(username);
    assertThat(r.error).contains("identifies an inactive account");
    assertThat(r.reviewers).isNull();
}
#method_after
@Test
public void addReviewerThatIsInactive() throws Exception {
    PushOneCommit.Result result = createChange();
    String username = name("new-user");
    accountOperations.newAccount().username(username).inactive().create();
    AddReviewerInput in = new AddReviewerInput();
    in.reviewer = username;
    AddReviewerResult r = gApi.changes().id(result.getChangeId()).addReviewer(in);
    assertThat(r.input).isEqualTo(username);
    assertThat(r.error).contains("identifies an inactive account");
    assertThat(r.reviewers).isNull();
}
#end_block

#method_before
@Test
public void addReviewerThatIsInactiveEmailFallback() throws Exception {
    assume().that(notesMigration.readChanges()).isTrue();
    ConfigInput conf = new ConfigInput();
    conf.enableReviewerByEmail = InheritableBoolean.TRUE;
    gApi.projects().name(project.get()).config(conf);
    PushOneCommit.Result result = createChange();
    String username = "user@domain.com";
    gApi.accounts().create(username).setActive(false);
    AddReviewerInput in = new AddReviewerInput();
    in.reviewer = username;
    in.state = ReviewerState.CC;
    AddReviewerResult r = gApi.changes().id(result.getChangeId()).addReviewer(in);
    assertThat(r.input).isEqualTo(username);
    assertThat(r.error).isNull();
    // When adding by email, the reviewers field is also empty because we can't
    // render a ReviewerInfo object for a non-account.
    assertThat(r.reviewers).isNull();
}
#method_after
@Test
public void addReviewerThatIsInactiveEmailFallback() throws Exception {
    assume().that(notesMigration.readChanges()).isTrue();
    ConfigInput conf = new ConfigInput();
    conf.enableReviewerByEmail = InheritableBoolean.TRUE;
    gApi.projects().name(project.get()).config(conf);
    PushOneCommit.Result result = createChange();
    String username = "user@domain.com";
    accountOperations.newAccount().username(username).inactive().create();
    AddReviewerInput in = new AddReviewerInput();
    in.reviewer = username;
    in.state = ReviewerState.CC;
    AddReviewerResult r = gApi.changes().id(result.getChangeId()).addReviewer(in);
    assertThat(r.input).isEqualTo(username);
    assertThat(r.error).isNull();
    // When adding by email, the reviewers field is also empty because we can't
    // render a ReviewerInfo object for a non-account.
    assertThat(r.reviewers).isNull();
}
#end_block

#method_before
@Test
public void eTagChangesWhenOwnerUpdatesAccountStatus() throws Exception {
    PushOneCommit.Result r = createChange();
    ChangeResource rsrc = parseResource(r);
    String oldETag = rsrc.getETag();
    gApi.accounts().id(admin.id.get()).setStatus("new status");
    rsrc = parseResource(r);
    assertThat(rsrc.getETag()).isNotEqualTo(oldETag);
}
#method_after
@Test
public void eTagChangesWhenOwnerUpdatesAccountStatus() throws Exception {
    PushOneCommit.Result r = createChange();
    ChangeResource rsrc = parseResource(r);
    String oldETag = rsrc.getETag();
    accountOperations.account(admin.id).forUpdate().status("new status").update();
    rsrc = parseResource(r);
    assertThat(rsrc.getETag()).isNotEqualTo(oldETag);
}
#end_block

#method_before
protected String createGroup(String name) throws Exception {
    return groupOperations.newGroup().name(name).createName();
}
#method_after
protected String createGroup(String name) throws Exception {
    groupOperations.newGroup().name(name).create();
    return name;
}
#end_block

#method_before
@Override
public void configure() {
    bind(AuditService.class).to(FakeAuditService.class);
}
#method_after
@Override
public void configure() {
    DynamicSet.setOf(binder(), GroupMemberAuditListener.class);
    bind(AuditService.class).to(FakeAuditService.class);
}
#end_block

#method_before
@Override
public void dispatchAddAccountsToGroup(Account.Id actor, Collection<AccountGroupMember> added) {
}
#method_after
@Override
public void dispatchAddAccountsToGroup(Account.Id actor, Collection<AccountGroupMember> added) {
    for (GroupMemberAuditListener auditListener : groupMemberAuditListeners) {
        auditListener.onAddAccountsToGroup(actor, added);
    }
}
#end_block

#method_before
@Override
public void dispatchDeleteAccountsFromGroup(Account.Id actor, Collection<AccountGroupMember> removed) {
}
#method_after
@Override
public void dispatchDeleteAccountsFromGroup(Account.Id actor, Collection<AccountGroupMember> removed) {
    for (GroupMemberAuditListener auditListener : groupMemberAuditListeners) {
        auditListener.onDeleteAccountsFromGroup(actor, removed);
    }
}
#end_block

#method_before
@Override
public void dispatchAddGroupsToGroup(Account.Id actor, Collection<AccountGroupById> added) {
}
#method_after
@Override
public void dispatchAddGroupsToGroup(Account.Id actor, Collection<AccountGroupById> added) {
    for (GroupMemberAuditListener auditListener : groupMemberAuditListeners) {
        auditListener.onAddGroupsToGroup(actor, added);
    }
}
#end_block

#method_before
@Override
public void dispatchDeleteGroupsFromGroup(Account.Id actor, Collection<AccountGroupById> removed) {
}
#method_after
@Override
public void dispatchDeleteGroupsFromGroup(Account.Id actor, Collection<AccountGroupById> removed) {
    for (GroupMemberAuditListener auditListener : groupMemberAuditListeners) {
        auditListener.onDeleteGroupsFromGroup(actor, removed);
    }
}
#end_block

#method_before
@Override
protected void doGetJson(HttpServletRequest req, HttpServletResponse res) throws IOException {
    GitilesView view = ViewFilter.getView(req);
    RefsResult refs = getRefs(ServletUtils.getRepository(req).getRefDatabase(), view.getPathPart());
    Map<String, RefJsonData> jsonRefs = new LinkedHashMap<>();
    for (Ref ref : refs.refs) {
        jsonRefs.put(ref.getName().substring(refs.prefix.length()), new RefJsonData(ref));
    }
    renderJson(req, res, jsonRefs, new TypeToken<Map<String, RefJsonData>>() {
    }.getType());
}
#method_after
@Override
protected void doGetJson(HttpServletRequest req, HttpServletResponse res) throws IOException {
    GitilesView view = ViewFilter.getView(req);
    RefsResult refs = getRefs(ServletUtils.getRepository(req).getRefDatabase(), view.getPathPart());
    Map<String, RefJsonData> jsonRefs = new LinkedHashMap<>();
    int prefixLen = refs.prefix.length();
    for (Ref ref : refs.refs) {
        jsonRefs.put(ref.getName().substring(prefixLen), new RefJsonData(ref));
    }
    renderJson(req, res, jsonRefs, new TypeToken<Map<String, RefJsonData>>() {
    }.getType());
}
#end_block

#method_before
private static List<Map<String, Object>> getRefsSoyData(RefDatabase refdb, GitilesView view, String prefix, Ordering<Ref> ordering, @Nullable Ref headLeaf, int limit) throws IOException {
    Collection<Ref> refs = refdb.getRefsByPrefix(prefix);
    refs = ordering.leastOf(refs, limit > 0 ? Ints.saturatedCast(limit + 1L) : refs.size());
    List<Map<String, Object>> result = Lists.newArrayListWithCapacity(refs.size());
    for (Ref ref : refs) {
        String name = ref.getName().substring(prefix.length());
        Ref refForName = refdb.getRef(name);
        if (refForName != null) {
            boolean needPrefix = !ref.getName().equals(refForName.getName());
            Map<String, Object> value = Maps.newHashMapWithExpectedSize(3);
            value.put("url", GitilesView.revision().copyFrom(view).setRevision(Revision.unpeeled(needPrefix ? ref.getName() : name, ref.getObjectId())).toUrl());
            value.put("name", name);
            if (headLeaf != null) {
                value.put("isHead", headLeaf.equals(ref));
            }
            result.add(value);
        }
    }
    return result;
}
#method_after
private static List<Map<String, Object>> getRefsSoyData(RefDatabase refdb, GitilesView view, String prefix, Ordering<Ref> ordering, @Nullable Ref headLeaf, int limit) throws IOException {
    checkArgument(prefix.endsWith("/"), "ref hierarchy prefix should end with /: %s", prefix);
    Collection<Ref> refs = refdb.getRefsByPrefix(prefix);
    refs = ordering.leastOf(refs, limit > 0 ? Ints.saturatedCast(limit + 1L) : refs.size());
    List<Map<String, Object>> result = Lists.newArrayListWithCapacity(refs.size());
    for (Ref ref : refs) {
        String name = ref.getName().substring(prefix.length());
        Ref refForName = refdb.getRef(name);
        if (refForName != null) {
            boolean needPrefix = !ref.getName().equals(refForName.getName());
            Map<String, Object> value = Maps.newHashMapWithExpectedSize(3);
            value.put("url", GitilesView.revision().copyFrom(view).setRevision(Revision.unpeeled(needPrefix ? ref.getName() : name, ref.getObjectId())).toUrl());
            value.put("name", name);
            if (headLeaf != null) {
                value.put("isHead", headLeaf.equals(ref));
            }
            result.add(value);
        }
    }
    return result;
}
#end_block

#method_before
public void apply(ProjectResource rsrc) throws IOException, RestApiException {
    try {
        MetaDataUpdate md = metaDataUpdateFactory.create(rsrc.getNameKey());
        ProjectConfig projectConfig = new ProjectConfig.Factory().read(md);
        Project p = projectConfig.getProject();
        p.setState(ProjectState.HIDDEN);
        for (AccessSection as : projectConfig.getAccessSections()) {
            projectConfig.remove(as);
        }
        String parentForDeletedProjects = cfg.getDeletedProjectsParent();
        createProjectIfMissing(parentForDeletedProjects);
        p.setParentName(parentForDeletedProjects);
        md.setMessage("Hide project\n");
        projectConfig.commit(md);
        projectCache.evict(projectConfig.getProject());
    } catch (RepositoryNotFoundException e) {
        throw new ResourceNotFoundException();
    } catch (ConfigInvalidException e) {
        throw new ResourceConflictException(e.getMessage());
    }
}
#method_after
public void apply(ProjectResource rsrc) throws IOException, RestApiException {
    try {
        MetaDataUpdate md = metaDataUpdateFactory.create(rsrc.getNameKey());
        ProjectConfig projectConfig = projectConfigFactory.read(md);
        Project p = projectConfig.getProject();
        p.setState(ProjectState.HIDDEN);
        for (AccessSection as : projectConfig.getAccessSections()) {
            projectConfig.remove(as);
        }
        String parentForDeletedProjects = cfg.getDeletedProjectsParent();
        createProjectIfMissing(parentForDeletedProjects);
        p.setParentName(parentForDeletedProjects);
        md.setMessage("Hide project\n");
        projectConfig.commit(md);
        projectCache.evict(projectConfig.getProject());
    } catch (RepositoryNotFoundException e) {
        throw new ResourceNotFoundException();
    } catch (ConfigInvalidException e) {
        throw new ResourceConflictException(e.getMessage());
    }
}
#end_block

#method_before
@Override
protected void doGetHtml(HttpServletRequest req, HttpServletResponse res) throws IOException {
    MarkdownConfig cfg = MarkdownConfig.get(getAccess(req).getConfig());
    if (!cfg.render) {
        res.setStatus(SC_NOT_FOUND);
        return;
    }
    GitilesView view = ViewFilter.getView(req);
    Repository repo = ServletUtils.getRepository(req);
    try (RevWalk rw = new RevWalk(repo)) {
        ObjectReader reader = rw.getObjectReader();
        String path = view.getPathPart();
        RevTree root;
        try {
            root = rw.parseTree(view.getRevision().getId());
        } catch (IncorrectObjectTypeException e) {
            res.setStatus(SC_NOT_FOUND);
            return;
        }
        MarkdownFile srcmd = findFile(rw, root, path);
        if (srcmd == null) {
            res.setStatus(SC_NOT_FOUND);
            return;
        }
        MarkdownFile navmd = findNavbar(cfg, rw, root, path);
        String curEtag = etag(srcmd, navmd);
        if (etagMatch(req, curEtag)) {
            res.setStatus(SC_NOT_MODIFIED);
            return;
        }
        view = view.toBuilder().setPathPart(srcmd.path).build();
        try {
            srcmd.read(reader, cfg);
            if (navmd != null) {
                navmd.read(reader, cfg);
            }
        } catch (LargeObjectException.ExceedsLimit errBig) {
            fileTooBig(res, view, errBig);
            return;
        } catch (IOException err) {
            readError(res, view, err);
            return;
        }
        MarkdownToHtml.Builder fmt = MarkdownToHtml.builder().setConfig(cfg).setGitilesView(view).setRequestUri(req.getRequestURI()).setReader(reader).setRootTree(root).setHtmlSanitizer(htmlSanitizer.create(req));
        Navbar navbar = createNavbar(cfg, fmt, navmd);
        res.setHeader(HttpHeaders.ETAG, curEtag);
        showDoc(req, res, view, fmt, navbar, srcmd);
    }
}
#method_after
@Override
protected void doGetHtml(HttpServletRequest req, HttpServletResponse res) throws IOException {
    MarkdownConfig cfg = MarkdownConfig.get(getAccess(req).getConfig());
    if (!cfg.render) {
        res.setStatus(SC_NOT_FOUND);
        return;
    }
    GitilesView view = ViewFilter.getView(req);
    Repository repo = ServletUtils.getRepository(req);
    try (RevWalk rw = new RevWalk(repo)) {
        ObjectReader reader = rw.getObjectReader();
        String path = view.getPathPart();
        RevTree root;
        try {
            root = rw.parseTree(view.getRevision().getId());
        } catch (IncorrectObjectTypeException e) {
            res.setStatus(SC_NOT_FOUND);
            return;
        }
        MarkdownFile srcmd = findFile(rw, root, path);
        if (srcmd == null) {
            res.setStatus(SC_NOT_FOUND);
            return;
        }
        MarkdownFile navmd = findNavbar(rw, root, path);
        String curEtag = etag(srcmd, navmd);
        if (etagMatch(req, curEtag)) {
            res.setStatus(SC_NOT_MODIFIED);
            return;
        }
        view = view.toBuilder().setPathPart(srcmd.path).build();
        try {
            srcmd.read(reader, cfg);
            if (navmd != null) {
                navmd.read(reader, cfg);
            }
        } catch (LargeObjectException.ExceedsLimit errBig) {
            fileTooBig(res, view, errBig);
            return;
        } catch (IOException err) {
            readError(res, view, err);
            return;
        }
        MarkdownToHtml.Builder fmt = MarkdownToHtml.builder().setConfig(cfg).setGitilesView(view).setRequestUri(req.getRequestURI()).setReader(reader).setRootTree(root).setHtmlSanitizer(htmlSanitizer.create(req));
        Navbar navbar = createNavbar(cfg, fmt, navmd);
        res.setHeader(HttpHeaders.ETAG, curEtag);
        showDoc(req, res, view, fmt, navbar, srcmd);
    }
}
#end_block

#method_before
private MarkdownFile findNavbar(MarkdownConfig cfg, RevWalk rw, RevTree root, String path) throws IOException {
    if (cfg.subNavbar && !path.isEmpty()) {
        // Traverse up the path until we find a NAVBAR_MD.
        StringBuilder pathRemaining = new StringBuilder(path);
        while (pathRemaining.length() > 0) {
            int lastPathSeparatorIndex = pathRemaining.lastIndexOf("/");
            pathRemaining.setLength(lastPathSeparatorIndex + 1);
            MarkdownFile navmd = findFile(rw, root, pathRemaining.toString() + NAVBAR_MD);
            if (navmd != null) {
                return navmd;
            }
            pathRemaining.setLength(Math.max(lastPathSeparatorIndex, 0));
        }
        return null;
    }
    return findFile(rw, root, NAVBAR_MD);
}
#method_after
private MarkdownFile findNavbar(RevWalk rw, RevTree root, String path) throws IOException {
    if (!Strings.isNullOrEmpty(path)) {
        // Traverse up the path until we find a NAVBAR_MD.
        StringBuilder pathRemaining = new StringBuilder(path);
        while (pathRemaining.length() > 0) {
            int lastPathSeparatorIndex = pathRemaining.lastIndexOf("/");
            pathRemaining.setLength(lastPathSeparatorIndex + 1);
            MarkdownFile navmd = findFile(rw, root, pathRemaining.toString() + NAVBAR_MD);
            if (navmd != null) {
                return navmd;
            }
            pathRemaining.setLength(Math.max(lastPathSeparatorIndex, 0));
        }
        return null;
    }
    return findFile(rw, root, NAVBAR_MD);
}
#end_block

#method_before
private Injector createSysInjector() {
    final List<Module> modules = new ArrayList<>();
    modules.add(new DropWizardMetricMaker.RestModule());
    modules.add(new LogFileCompressor.Module());
    modules.add(new EventBroker.Module());
    modules.add(new JdbcAccountPatchReviewStore.Module(config));
    modules.add(cfgInjector.getInstance(GitRepositoryManagerModule.class));
    modules.add(new StreamEventsApiListener.Module());
    modules.add(new ReceiveCommitsExecutorModule());
    modules.add(new DiffExecutorModule());
    modules.add(new MimeUtil2Module());
    modules.add(cfgInjector.getInstance(GerritGlobalModule.class));
    modules.add(new SearchingChangeCacheImpl.Module());
    modules.add(new InternalAccountDirectory.Module());
    modules.add(new DefaultPermissionBackendModule());
    modules.add(new DefaultCacheFactory.Module());
    modules.add(cfgInjector.getInstance(MailReceiver.Module.class));
    modules.add(new SmtpEmailSender.Module());
    modules.add(new SignedTokenEmailTokenVerifier.Module());
    // Plugin module needs to be inserted *before* the index module.
    // There is the concept of LifecycleModule, in Gerrit's own extension
    // to Guice, which has these:
    // listener().to(SomeClassImplementingLifecycleListener.class);
    // and the start() methods of each such listener are executed in the
    // order they are declared.
    // Makes sure that PluginLoader.start() is executed before the
    // LuceneIndexModule.start() so that plugins get loaded and the respective
    // Guice modules installed so that the on-line reindexing will happen
    // with the proper classes (e.g. group backends, custom Prolog
    // predicates) and the associated rules ready to be evaluated.
    modules.add(new PluginModule());
    modules.add(new PluginRestApiModule());
    modules.add(new RestCacheAdminModule());
    modules.add(new GpgModule(config));
    modules.add(new StartupChecks.Module());
    // Index module shutdown must happen before work queue shutdown, otherwise
    // work queue can get stuck waiting on index futures that will never return.
    modules.add(createIndexModule());
    modules.add(new WorkQueue.Module());
    modules.add(new CanonicalWebUrlModule() {

        @Override
        protected Class<? extends Provider<String>> provider() {
            return HttpCanonicalWebUrlProvider.class;
        }
    });
    modules.add(SshKeyCacheImpl.module());
    modules.add(new AbstractModule() {

        @Override
        protected void configure() {
            bind(GerritOptions.class).toInstance(new GerritOptions(config, false, false, false));
        }
    });
    modules.add(new GarbageCollectionModule());
    modules.add(new ChangeCleanupRunner.Module());
    modules.addAll(LibModuleLoader.loadModules(cfgInjector));
    return cfgInjector.createChildInjector(modules);
}
#method_after
private Injector createSysInjector() {
    final List<Module> modules = new ArrayList<>();
    modules.add(new DropWizardMetricMaker.RestModule());
    modules.add(new LogFileCompressor.Module());
    modules.add(new EventBroker.Module());
    modules.add(new JdbcAccountPatchReviewStore.Module(config));
    modules.add(cfgInjector.getInstance(GitRepositoryManagerModule.class));
    modules.add(new StreamEventsApiListener.Module());
    modules.add(new ReceiveCommitsExecutorModule());
    modules.add(new DiffExecutorModule());
    modules.add(new MimeUtil2Module());
    modules.add(cfgInjector.getInstance(GerritGlobalModule.class));
    modules.add(new SearchingChangeCacheImpl.Module());
    modules.add(new InternalAccountDirectory.Module());
    modules.add(new DefaultPermissionBackendModule());
    modules.add(new DefaultCacheFactory.Module());
    modules.add(cfgInjector.getInstance(MailReceiver.Module.class));
    modules.add(new SmtpEmailSender.Module());
    modules.add(new SignedTokenEmailTokenVerifier.Module());
    modules.add(new LocalMergeSuperSetComputation.Module());
    // Plugin module needs to be inserted *before* the index module.
    // There is the concept of LifecycleModule, in Gerrit's own extension
    // to Guice, which has these:
    // listener().to(SomeClassImplementingLifecycleListener.class);
    // and the start() methods of each such listener are executed in the
    // order they are declared.
    // Makes sure that PluginLoader.start() is executed before the
    // LuceneIndexModule.start() so that plugins get loaded and the respective
    // Guice modules installed so that the on-line reindexing will happen
    // with the proper classes (e.g. group backends, custom Prolog
    // predicates) and the associated rules ready to be evaluated.
    modules.add(new PluginModule());
    modules.add(new PluginRestApiModule());
    modules.add(new RestCacheAdminModule());
    modules.add(new GpgModule(config));
    modules.add(new StartupChecks.Module());
    // Index module shutdown must happen before work queue shutdown, otherwise
    // work queue can get stuck waiting on index futures that will never return.
    modules.add(createIndexModule());
    modules.add(new WorkQueue.Module());
    modules.add(new CanonicalWebUrlModule() {

        @Override
        protected Class<? extends Provider<String>> provider() {
            return HttpCanonicalWebUrlProvider.class;
        }
    });
    modules.add(SshKeyCacheImpl.module());
    modules.add(new AbstractModule() {

        @Override
        protected void configure() {
            bind(GerritOptions.class).toInstance(new GerritOptions(config, false, false, false));
        }
    });
    modules.add(new GarbageCollectionModule());
    modules.add(new ChangeCleanupRunner.Module());
    modules.add(new AccountDeactivator.Module());
    modules.addAll(LibModuleLoader.loadModules(cfgInjector));
    modules.add(new DefaultProjectNameLockManager.Module());
    return cfgInjector.createChildInjector(modules);
}
#end_block

#method_before
@Provides
@Singleton
@Named(POLYGERRIT_INDEX_SERVLET)
HttpServlet getPolyGerritUiIndexServlet(@CanonicalWebUrl @Nullable String canonicalUrl, @GerritServerConfig Config cfg) throws URISyntaxException {
    String cdnPath = cfg.getString("gerrit", null, "cdnPath");
    return new IndexServlet(canonicalUrl, cdnPath);
}
#method_after
@Provides
@Singleton
@Named(POLYGERRIT_INDEX_SERVLET)
HttpServlet getPolyGerritUiIndexServlet(@CanonicalWebUrl @Nullable String canonicalUrl, @GerritServerConfig Config cfg) throws URISyntaxException {
    String cdnPath = cfg.getString("gerrit", null, "cdnPath");
    String faviconPath = cfg.getString("gerrit", null, "faviconPath");
    return new IndexServlet(canonicalUrl, cdnPath, faviconPath);
}
#end_block

#method_before
@Override
protected void doGet(HttpServletRequest req, HttpServletResponse rsp) throws IOException {
    String idString = req.getPathInfo();
    if (idString.endsWith("/")) {
        idString = idString.substring(0, idString.length() - 1);
    }
    Change.Id id;
    try {
        id = Change.Id.parse(idString);
    } catch (IllegalArgumentException e) {
        rsp.sendError(HttpServletResponse.SC_NOT_FOUND);
        return;
    }
    ChangeResource changeResource;
    try {
        changeResource = changesCollection.parse(id);
    } catch (ResourceConflictException | ResourceNotFoundException e) {
        rsp.sendError(HttpServletResponse.SC_NOT_FOUND);
        return;
    } catch (OrmException | PermissionBackendException e) {
        throw new IOException("Unable to lookup change", e);
    }
    String path = PageLinks.toChange(changeResource.getProject(), changeResource.getChange().getId());
    UrlModule.toGerrit(path, req, rsp);
}
#method_after
@Override
protected void doGet(HttpServletRequest req, HttpServletResponse rsp) throws IOException {
    String idString = req.getPathInfo();
    if (idString.endsWith("/")) {
        idString = idString.substring(0, idString.length() - 1);
    }
    Change.Id id;
    try {
        id = Change.Id.parse(idString);
    } catch (IllegalArgumentException e) {
        rsp.sendError(HttpServletResponse.SC_NOT_FOUND);
        return;
    }
    ChangeResource changeResource;
    try {
        changeResource = changesCollection.parse(id);
    } catch (ResourceConflictException | ResourceNotFoundException e) {
        rsp.sendError(HttpServletResponse.SC_NOT_FOUND);
        return;
    } catch (OrmException | PermissionBackendException e) {
        throw new IOException("Unable to lookup change " + id.id, e);
    }
    String path = PageLinks.toChange(changeResource.getProject(), changeResource.getChange().getId());
    UrlModule.toGerrit(path, req, rsp);
}
#end_block

#method_before
@Override
public void doFilter(ServletRequest req, ServletResponse rsp, FilterChain chain) throws IOException, ServletException {
    try {
        permissionBackend.currentUser().check(GlobalPermission.ADMINISTRATE_SERVER);
    } catch (AuthException | PermissionBackendException e) {
        ((HttpServletResponse) rsp).sendError(HttpServletResponse.SC_NOT_FOUND, "Not Found");
        return;
    }
    chain.doFilter(req, rsp);
}
#method_after
@Override
public void doFilter(ServletRequest req, ServletResponse rsp, FilterChain chain) throws IOException, ServletException {
    try {
        permissionBackend.user(user.get()).check(GlobalPermission.ADMINISTRATE_SERVER);
    } catch (AuthException | PermissionBackendException e) {
        ((HttpServletResponse) rsp).sendError(HttpServletResponse.SC_NOT_FOUND, "Not Found");
        return;
    }
    chain.doFilter(req, rsp);
}
#end_block

#method_before
@Before
public void setUp() {
    PluginMetrics mockMetrics = mock(PluginMetrics.class);
    listenerMock = mock(EventListener.class);
    DynamicSet<EventListener> set = DynamicSet.emptySet();
    set.add("high-availability", listenerMock);
    PluginSetContext<EventListener> listeners = new PluginSetContext<EventListener>(set, mockMetrics);
    broker = new ForwardedAwareEventBroker(null, listeners, null, null, null, null);
}
#method_after
@Before
public void setUp() {
    PluginMetrics mockMetrics = mock(PluginMetrics.class);
    listenerMock = mock(EventListener.class);
    DynamicSet<EventListener> set = DynamicSet.emptySet();
    set.add("high-availability", listenerMock);
    PluginSetContext<EventListener> listeners = new PluginSetContext<>(set, mockMetrics);
    broker = new ForwardedAwareEventBroker(null, listeners, null, null, null, null);
}
#end_block

#method_before
@Test
public void readConfig() throws Exception {
    RevCommit rev = tr.commit().add("groups", group(developers)).add("project.config", "[access \"refs/heads/*\"]\n" + "  exclusiveGroupPermissions = read submit create\n" + "  submit = group Developers\n" + "  push = group Developers\n" + "  read = group Developers\n" + "[accounts]\n" + "  sameGroupVisibility = deny group Developers\n" + "  sameGroupVisibility = block group Staff\n" + "[contributor-agreement \"Individual\"]\n" + "  description = A simple description\n" + "  matchProjects = ^/ourproject\n" + "  matchProjects = ^/ourotherproject\n" + "  matchProjects = ^/someotherroot/ourproject\n" + "  excludeProjects = ^/theirproject\n" + "  excludeProjects = ^/theirotherproject\n" + "  excludeProjects = ^/someotherroot/theirproject\n" + "  excludeProjects = ^/someotherroot/theirotherproject\n" + "  accepted = group Developers\n" + "  accepted = group Staff\n" + "  autoVerify = group Developers\n" + "  agreementUrl = http://www.example.com/agree\n").create();
    ProjectConfig cfg = read(rev);
    assertThat(cfg.getAccountsSection().getSameGroupVisibility()).hasSize(2);
    ContributorAgreement ca = cfg.getContributorAgreement("Individual");
    assertThat(ca.getName()).isEqualTo("Individual");
    assertThat(ca.getDescription()).isEqualTo("A simple description");
    assertThat(ca.getMatchProjects()).hasSize(3);
    assertThat(ca.getMatchProjects().get(0)).isEqualTo("^/ourproject");
    assertThat(ca.getMatchProjects().get(1)).isEqualTo("^/ourotherproject");
    assertThat(ca.getMatchProjects().get(2)).isEqualTo("^/someotherroot/ourproject");
    assertThat(ca.getExcludeProjects()).hasSize(4);
    assertThat(ca.getExcludeProjects().get(0)).isEqualTo("^/theirproject");
    assertThat(ca.getExcludeProjects().get(1)).isEqualTo("^/theirotherproject");
    assertThat(ca.getExcludeProjects().get(2)).isEqualTo("^/someotherroot/theirproject");
    assertThat(ca.getExcludeProjects().get(3)).isEqualTo("^/someotherroot/theirotherproject");
    assertThat(ca.getAgreementUrl()).isEqualTo("http://www.example.com/agree");
    assertThat(ca.getAccepted()).hasSize(2);
    assertThat(ca.getAccepted().get(0).getGroup()).isEqualTo(developers);
    assertThat(ca.getAccepted().get(1).getGroup().getName()).isEqualTo("Staff");
    assertThat(ca.getAutoVerify().getName()).isEqualTo("Developers");
    AccessSection section = cfg.getAccessSection("refs/heads/*");
    assertThat(section).isNotNull();
    assertThat(cfg.getAccessSection("refs/*")).isNull();
    Permission create = section.getPermission(Permission.CREATE);
    Permission submit = section.getPermission(Permission.SUBMIT);
    Permission read = section.getPermission(Permission.READ);
    Permission push = section.getPermission(Permission.PUSH);
    assertThat(create.getExclusiveGroup()).isTrue();
    assertThat(submit.getExclusiveGroup()).isTrue();
    assertThat(read.getExclusiveGroup()).isTrue();
    assertThat(push.getExclusiveGroup()).isFalse();
}
#method_after
@Test
public void readConfig() throws Exception {
    RevCommit rev = tr.commit().add("groups", group(developers)).add("project.config", "[access \"refs/heads/*\"]\n" + "  exclusiveGroupPermissions = read submit create\n" + "  submit = group Developers\n" + "  push = group Developers\n" + "  read = group Developers\n" + "[accounts]\n" + "  sameGroupVisibility = deny group Developers\n" + "  sameGroupVisibility = block group Staff\n" + "[contributor-agreement \"Individual\"]\n" + "  description = A simple description\n" + "  matchProjects = ^/ourproject\n" + "  matchProjects = ^/ourotherproject\n" + "  matchProjects = ^/someotherroot/ourproject\n" + "  excludeProjects = ^/theirproject\n" + "  excludeProjects = ^/theirotherproject\n" + "  excludeProjects = ^/someotherroot/theirproject\n" + "  excludeProjects = ^/someotherroot/theirotherproject\n" + "  accepted = group Developers\n" + "  accepted = group Staff\n" + "  autoVerify = group Developers\n" + "  agreementUrl = http://www.example.com/agree\n").create();
    ProjectConfig cfg = read(rev);
    assertThat(cfg.getAccountsSection().getSameGroupVisibility()).hasSize(2);
    ContributorAgreement ca = cfg.getContributorAgreement("Individual");
    assertThat(ca.getName()).isEqualTo("Individual");
    assertThat(ca.getDescription()).isEqualTo("A simple description");
    assertThat(ca.getMatchProjectsRegexes()).containsExactly("^/ourproject", "^/ourotherproject", "^/someotherroot/ourproject");
    assertThat(ca.getExcludeProjectsRegexes()).containsExactly("^/theirproject", "^/theirotherproject", "^/someotherroot/theirproject", "^/someotherroot/theirotherproject");
    assertThat(ca.getAgreementUrl()).isEqualTo("http://www.example.com/agree");
    assertThat(ca.getAccepted()).hasSize(2);
    assertThat(ca.getAccepted().get(0).getGroup()).isEqualTo(developers);
    assertThat(ca.getAccepted().get(1).getGroup().getName()).isEqualTo("Staff");
    assertThat(ca.getAutoVerify().getName()).isEqualTo("Developers");
    AccessSection section = cfg.getAccessSection("refs/heads/*");
    assertThat(section).isNotNull();
    assertThat(cfg.getAccessSection("refs/*")).isNull();
    Permission create = section.getPermission(Permission.CREATE);
    Permission submit = section.getPermission(Permission.SUBMIT);
    Permission read = section.getPermission(Permission.READ);
    Permission push = section.getPermission(Permission.PUSH);
    assertThat(create.getExclusiveGroup()).isTrue();
    assertThat(submit.getExclusiveGroup()).isTrue();
    assertThat(read.getExclusiveGroup()).isTrue();
    assertThat(push.getExclusiveGroup()).isFalse();
}
#end_block

#method_before
@Test
public void editConfig() throws Exception {
    RevCommit rev = tr.commit().add("groups", group(developers)).add("project.config", "[access \"refs/heads/*\"]\n" + "  exclusiveGroupPermissions = read submit\n" + "  submit = group Developers\n" + "  upload = group Developers\n" + "  read = group Developers\n" + "[accounts]\n" + "  sameGroupVisibility = deny group Developers\n" + "  sameGroupVisibility = block group Staff\n" + "[contributor-agreement \"Individual\"]\n" + "  description = A simple description\n" + "  matchProjects = ^/ourproject\n" + "  accepted = group Developers\n" + "  autoVerify = group Developers\n" + "  agreementUrl = http://www.example.com/agree\n" + "[label \"CustomLabel\"]\n" + LABEL_SCORES_CONFIG).create();
    update(rev);
    ProjectConfig cfg = read(rev);
    AccessSection section = cfg.getAccessSection("refs/heads/*");
    cfg.getAccountsSection().setSameGroupVisibility(Collections.singletonList(new PermissionRule(cfg.resolve(staff))));
    Permission submit = section.getPermission(Permission.SUBMIT);
    submit.add(new PermissionRule(cfg.resolve(staff)));
    ContributorAgreement ca = cfg.getContributorAgreement("Individual");
    ca.setAccepted(Collections.singletonList(new PermissionRule(cfg.resolve(staff))));
    ca.setAutoVerify(null);
    ca.setMatchProjects(null);
    ca.setExcludeProjects(Collections.singletonList("^/theirproject"));
    ca.setDescription("A new description");
    rev = commit(cfg);
    assertThat(text(rev, "project.config")).isEqualTo("[access \"refs/heads/*\"]\n" + "  exclusiveGroupPermissions = read submit\n" + "  submit = group Developers\n" + "\tsubmit = group Staff\n" + "  upload = group Developers\n" + "  read = group Developers\n" + "[accounts]\n" + "  sameGroupVisibility = group Staff\n" + "[contributor-agreement \"Individual\"]\n" + "  description = A new description\n" + "  accepted = group Staff\n" + "  agreementUrl = http://www.example.com/agree\n" + "\texcludeProjects = ^/theirproject\n" + "[label \"CustomLabel\"]\n" + LABEL_SCORES_CONFIG + // label gets this function when it is created
    "\tfunction = MaxWithBlock\n" + // label gets this value when it is created
    "\tdefaultValue = 0\n");
}
#method_after
@Test
public void editConfig() throws Exception {
    RevCommit rev = tr.commit().add("groups", group(developers)).add("project.config", "[access \"refs/heads/*\"]\n" + "  exclusiveGroupPermissions = read submit\n" + "  submit = group Developers\n" + "  upload = group Developers\n" + "  read = group Developers\n" + "[accounts]\n" + "  sameGroupVisibility = deny group Developers\n" + "  sameGroupVisibility = block group Staff\n" + "[contributor-agreement \"Individual\"]\n" + "  description = A simple description\n" + "  matchProjects = ^/ourproject\n" + "  accepted = group Developers\n" + "  autoVerify = group Developers\n" + "  agreementUrl = http://www.example.com/agree\n" + "[label \"CustomLabel\"]\n" + LABEL_SCORES_CONFIG).create();
    update(rev);
    ProjectConfig cfg = read(rev);
    AccessSection section = cfg.getAccessSection("refs/heads/*");
    cfg.getAccountsSection().setSameGroupVisibility(Collections.singletonList(new PermissionRule(cfg.resolve(staff))));
    Permission submit = section.getPermission(Permission.SUBMIT);
    submit.add(new PermissionRule(cfg.resolve(staff)));
    ContributorAgreement ca = cfg.getContributorAgreement("Individual");
    ca.setAccepted(Collections.singletonList(new PermissionRule(cfg.resolve(staff))));
    ca.setAutoVerify(null);
    ca.setMatchProjectsRegexes(null);
    ca.setExcludeProjectsRegexes(Collections.singletonList("^/theirproject"));
    ca.setDescription("A new description");
    rev = commit(cfg);
    assertThat(text(rev, "project.config")).isEqualTo("[access \"refs/heads/*\"]\n" + "  exclusiveGroupPermissions = read submit\n" + "  submit = group Developers\n" + "\tsubmit = group Staff\n" + "  upload = group Developers\n" + "  read = group Developers\n" + "[accounts]\n" + "  sameGroupVisibility = group Staff\n" + "[contributor-agreement \"Individual\"]\n" + "  description = A new description\n" + "  accepted = group Staff\n" + "  agreementUrl = http://www.example.com/agree\n" + "\texcludeProjects = ^/theirproject\n" + "[label \"CustomLabel\"]\n" + LABEL_SCORES_CONFIG + // label gets this function when it is created
    "\tfunction = MaxWithBlock\n" + // label gets this value when it is created
    "\tdefaultValue = 0\n");
}
#end_block

#method_before
private void loadContributorAgreements(Config rc) {
    contributorAgreements = new HashMap<>();
    for (String name : rc.getSubsections(CONTRIBUTOR_AGREEMENT)) {
        ContributorAgreement ca = getContributorAgreement(name, true);
        ca.setDescription(rc.getString(CONTRIBUTOR_AGREEMENT, name, KEY_DESCRIPTION));
        ca.setAgreementUrl(rc.getString(CONTRIBUTOR_AGREEMENT, name, KEY_AGREEMENT_URL));
        ca.setAccepted(loadPermissionRules(rc, CONTRIBUTOR_AGREEMENT, name, KEY_ACCEPTED, groupsByName, false));
        ca.setExcludeProjects(loadPatterns(rc, CONTRIBUTOR_AGREEMENT, name, KEY_EXCLUDE_PROJECTS));
        ca.setMatchProjects(loadPatterns(rc, CONTRIBUTOR_AGREEMENT, name, KEY_MATCH_PROJECTS));
        List<PermissionRule> rules = loadPermissionRules(rc, CONTRIBUTOR_AGREEMENT, name, KEY_AUTO_VERIFY, groupsByName, false);
        if (rules.isEmpty()) {
            ca.setAutoVerify(null);
        } else if (rules.size() > 1) {
            error(new ValidationError(PROJECT_CONFIG, "Invalid rule in " + CONTRIBUTOR_AGREEMENT + "." + name + "." + KEY_AUTO_VERIFY + ": at most one group may be set"));
        } else if (rules.get(0).getAction() != Action.ALLOW) {
            error(new ValidationError(PROJECT_CONFIG, "Invalid rule in " + CONTRIBUTOR_AGREEMENT + "." + name + "." + KEY_AUTO_VERIFY + ": the group must be allowed"));
        } else {
            ca.setAutoVerify(rules.get(0).getGroup());
        }
    }
}
#method_after
private void loadContributorAgreements(Config rc) {
    contributorAgreements = new HashMap<>();
    for (String name : rc.getSubsections(CONTRIBUTOR_AGREEMENT)) {
        ContributorAgreement ca = getContributorAgreement(name, true);
        ca.setDescription(rc.getString(CONTRIBUTOR_AGREEMENT, name, KEY_DESCRIPTION));
        ca.setAgreementUrl(rc.getString(CONTRIBUTOR_AGREEMENT, name, KEY_AGREEMENT_URL));
        ca.setAccepted(loadPermissionRules(rc, CONTRIBUTOR_AGREEMENT, name, KEY_ACCEPTED, groupsByName, false));
        ca.setExcludeProjectsRegexes(loadPatterns(rc, CONTRIBUTOR_AGREEMENT, name, KEY_EXCLUDE_PROJECTS));
        ca.setMatchProjectsRegexes(loadPatterns(rc, CONTRIBUTOR_AGREEMENT, name, KEY_MATCH_PROJECTS));
        List<PermissionRule> rules = loadPermissionRules(rc, CONTRIBUTOR_AGREEMENT, name, KEY_AUTO_VERIFY, groupsByName, false);
        if (rules.isEmpty()) {
            ca.setAutoVerify(null);
        } else if (rules.size() > 1) {
            error(new ValidationError(PROJECT_CONFIG, "Invalid rule in " + CONTRIBUTOR_AGREEMENT + "." + name + "." + KEY_AUTO_VERIFY + ": at most one group may be set"));
        } else if (rules.get(0).getAction() != Action.ALLOW) {
            error(new ValidationError(PROJECT_CONFIG, "Invalid rule in " + CONTRIBUTOR_AGREEMENT + "." + name + "." + KEY_AUTO_VERIFY + ": the group must be allowed"));
        } else {
            ca.setAutoVerify(rules.get(0).getGroup());
        }
    }
}
#end_block

#method_before
private ImmutableList<String> loadPatterns(Config rc, String section, String subsection, String varName) {
    ImmutableList.Builder<String> patterns = ImmutableList.builder();
    for (String patternString : rc.getStringList(section, subsection, varName)) {
        try {
            patterns.add(Pattern.compile(patternString).pattern());
        } catch (PatternSyntaxException e) {
            error(new ValidationError(PROJECT_CONFIG, "Invalid regular expression: " + e.getMessage()));
            continue;
        }
    }
    return patterns.build();
}
#method_after
private ImmutableList<String> loadPatterns(Config rc, String section, String subsection, String varName) {
    ImmutableList.Builder<String> patterns = ImmutableList.builder();
    for (String patternString : rc.getStringList(section, subsection, varName)) {
        try {
            // While one could just use getStringList directly, compiling first will cause the server
            // to fail fast if any of the patterns are invalid.
            patterns.add(Pattern.compile(patternString).pattern());
        } catch (PatternSyntaxException e) {
            error(new ValidationError(PROJECT_CONFIG, "Invalid regular expression: " + e.getMessage()));
            continue;
        }
    }
    return patterns.build();
}
#end_block

#method_before
private void saveContributorAgreements(Config rc, Set<AccountGroup.UUID> keepGroups) {
    for (ContributorAgreement ca : sort(contributorAgreements.values())) {
        set(rc, CONTRIBUTOR_AGREEMENT, ca.getName(), KEY_DESCRIPTION, ca.getDescription());
        set(rc, CONTRIBUTOR_AGREEMENT, ca.getName(), KEY_AGREEMENT_URL, ca.getAgreementUrl());
        if (ca.getAutoVerify() != null) {
            if (ca.getAutoVerify().getUUID() != null) {
                keepGroups.add(ca.getAutoVerify().getUUID());
            }
            String autoVerify = new PermissionRule(ca.getAutoVerify()).asString(false);
            set(rc, CONTRIBUTOR_AGREEMENT, ca.getName(), KEY_AUTO_VERIFY, autoVerify);
        } else {
            rc.unset(CONTRIBUTOR_AGREEMENT, ca.getName(), KEY_AUTO_VERIFY);
        }
        rc.setStringList(CONTRIBUTOR_AGREEMENT, ca.getName(), KEY_ACCEPTED, ruleToStringList(ca.getAccepted(), keepGroups));
        rc.setStringList(CONTRIBUTOR_AGREEMENT, ca.getName(), KEY_EXCLUDE_PROJECTS, patternToStringList(ca.getExcludeProjects()));
        rc.setStringList(CONTRIBUTOR_AGREEMENT, ca.getName(), KEY_MATCH_PROJECTS, patternToStringList(ca.getMatchProjects()));
    }
}
#method_after
private void saveContributorAgreements(Config rc, Set<AccountGroup.UUID> keepGroups) {
    for (ContributorAgreement ca : sort(contributorAgreements.values())) {
        set(rc, CONTRIBUTOR_AGREEMENT, ca.getName(), KEY_DESCRIPTION, ca.getDescription());
        set(rc, CONTRIBUTOR_AGREEMENT, ca.getName(), KEY_AGREEMENT_URL, ca.getAgreementUrl());
        if (ca.getAutoVerify() != null) {
            if (ca.getAutoVerify().getUUID() != null) {
                keepGroups.add(ca.getAutoVerify().getUUID());
            }
            String autoVerify = new PermissionRule(ca.getAutoVerify()).asString(false);
            set(rc, CONTRIBUTOR_AGREEMENT, ca.getName(), KEY_AUTO_VERIFY, autoVerify);
        } else {
            rc.unset(CONTRIBUTOR_AGREEMENT, ca.getName(), KEY_AUTO_VERIFY);
        }
        rc.setStringList(CONTRIBUTOR_AGREEMENT, ca.getName(), KEY_ACCEPTED, ruleToStringList(ca.getAccepted(), keepGroups));
        rc.setStringList(CONTRIBUTOR_AGREEMENT, ca.getName(), KEY_EXCLUDE_PROJECTS, patternToStringList(ca.getExcludeProjectsRegexes()));
        rc.setStringList(CONTRIBUTOR_AGREEMENT, ca.getName(), KEY_MATCH_PROJECTS, patternToStringList(ca.getMatchProjectsRegexes()));
    }
}
#end_block

#method_before
public void check(Project.NameKey project, CurrentUser user) throws IOException, AuthException {
    metrics.claCheckCount.increment();
    ProjectState projectState = projectCache.checkedGet(project);
    if (projectState == null) {
        throw new IOException("Can't load All-Projects");
    }
    if (!projectState.is(BooleanProjectConfig.USE_CONTRIBUTOR_AGREEMENTS)) {
        return;
    }
    if (!user.isIdentifiedUser()) {
        throw new AuthException("Must be logged in to verify Contributor Agreement");
    }
    IdentifiedUser iUser = user.asIdentifiedUser();
    Collection<ContributorAgreement> contributorAgreements = projectCache.getAllProjects().getConfig().getContributorAgreements();
    List<UUID> okGroupIds = new ArrayList<>();
    for (ContributorAgreement ca : contributorAgreements) {
        List<AccountGroup.UUID> groupIds;
        groupIds = okGroupIds;
        // matchProjects defaults to match all projects when missing.
        List<String> matchProjects = ca.getMatchProjects();
        if (!matchProjects.isEmpty()) {
            // Only checks projects that match when present.
            boolean found = false;
            for (String patternString : matchProjects) {
                Pattern pattern;
                try {
                    pattern = Pattern.compile(patternString);
                } catch (PatternSyntaxException e) {
                    continue;
                }
                if (pattern.matcher(project.get()).matches()) {
                    found = true;
                    break;
                }
            }
            if (!found) {
                // Doesn't match, isn't checked.
                continue;
            }
        }
        // excludeProjects defaults to exclude no projects when missing.
        List<String> excludeProjects = ca.getExcludeProjects();
        if (!excludeProjects.isEmpty()) {
            // Doesn't check projects that match when present.
            boolean found = false;
            for (String patternString : excludeProjects) {
                Pattern pattern;
                try {
                    pattern = Pattern.compile(patternString);
                } catch (PatternSyntaxException e) {
                    continue;
                }
                if (pattern.matcher(project.get()).matches()) {
                    found = true;
                    break;
                }
            }
            if (found) {
                // Matches, isn't checked.
                continue;
            }
        }
        for (PermissionRule rule : ca.getAccepted()) {
            if ((rule.getAction() == Action.ALLOW) && (rule.getGroup() != null) && (rule.getGroup().getUUID() != null)) {
                groupIds.add(new AccountGroup.UUID(rule.getGroup().getUUID().get()));
            }
        }
    }
    if (!iUser.getEffectiveGroups().containsAnyOf(okGroupIds)) {
        final StringBuilder msg = new StringBuilder();
        msg.append("No Contributor Agreement on file for user ").append(iUser.getNameEmail()).append(" (id=").append(iUser.getAccountId()).append(")");
        msg.append(urlFormatter.getSettingsUrl("Agreements").orElse(""));
        throw new AuthException(msg.toString());
    }
}
#method_after
public void check(Project.NameKey project, CurrentUser user) throws IOException, AuthException {
    metrics.claCheckCount.increment();
    ProjectState projectState = projectCache.checkedGet(project);
    if (projectState == null) {
        throw new IOException("Can't load All-Projects");
    }
    if (!projectState.is(BooleanProjectConfig.USE_CONTRIBUTOR_AGREEMENTS)) {
        return;
    }
    if (!user.isIdentifiedUser()) {
        throw new AuthException("Must be logged in to verify Contributor Agreement");
    }
    IdentifiedUser iUser = user.asIdentifiedUser();
    Collection<ContributorAgreement> contributorAgreements = projectCache.getAllProjects().getConfig().getContributorAgreements();
    List<UUID> okGroupIds = new ArrayList<>();
    for (ContributorAgreement ca : contributorAgreements) {
        List<AccountGroup.UUID> groupIds;
        groupIds = okGroupIds;
        // matchProjects defaults to match all projects when missing.
        List<String> matchProjectsRegexes = ca.getMatchProjectsRegexes();
        if (!matchProjectsRegexes.isEmpty() && !projectMatchesAnyPattern(project.get(), matchProjectsRegexes)) {
            // Doesn't match, isn't checked.
            continue;
        }
        // excludeProjects defaults to exclude no projects when missing.
        List<String> excludeProjectsRegexes = ca.getExcludeProjectsRegexes();
        if (!excludeProjectsRegexes.isEmpty() && projectMatchesAnyPattern(project.get(), excludeProjectsRegexes)) {
            // Matches, isn't checked.
            continue;
        }
        for (PermissionRule rule : ca.getAccepted()) {
            if ((rule.getAction() == Action.ALLOW) && (rule.getGroup() != null) && (rule.getGroup().getUUID() != null)) {
                groupIds.add(new AccountGroup.UUID(rule.getGroup().getUUID().get()));
            }
        }
    }
    if (!okGroupIds.isEmpty() && !iUser.getEffectiveGroups().containsAnyOf(okGroupIds)) {
        final StringBuilder msg = new StringBuilder();
        msg.append("No Contributor Agreement on file for user ").append(iUser.getNameEmail()).append(" (id=").append(iUser.getAccountId()).append(")");
        msg.append(urlFormatter.getSettingsUrl("Agreements").orElse(""));
        throw new AuthException(msg.toString());
    }
}
#end_block

#method_before
@Test
public void cherryPick() throws Exception {
    PushOneCommit.Result r = pushTo("refs/for/master%topic=someTopic");
    CherryPickInput in = new CherryPickInput();
    in.destination = "foo";
    in.message = "it goes to stable branch";
    gApi.projects().name(project.get()).branch(in.destination).create(new BranchInput());
    ChangeApi orig = gApi.changes().id(project.get() + "~master~" + r.getChangeId());
    assertThat(orig.get().messages).hasSize(1);
    ChangeApi cherry = orig.revision(r.getCommit().name()).cherryPick(in);
    Collection<ChangeMessageInfo> messages = gApi.changes().id(project.get() + "~master~" + r.getChangeId()).get().messages;
    assertThat(messages).hasSize(2);
    String cherryPickedRevision = cherry.get().currentRevision;
    String expectedMessage = String.format("Patch Set 1: Cherry Picked\n\n" + "This patchset was cherry picked to branch %s as commit %s", in.destination, cherryPickedRevision);
    Iterator<ChangeMessageInfo> origIt = messages.iterator();
    origIt.next();
    assertThat(origIt.next().message).isEqualTo(expectedMessage);
    assertThat(cherry.get().messages).hasSize(1);
    Iterator<ChangeMessageInfo> cherryIt = cherry.get().messages.iterator();
    expectedMessage = "Patch Set 1: Cherry Picked from branch master.";
    assertThat(cherryIt.next().message).isEqualTo(expectedMessage);
    assertThat(cherry.get().subject).contains(in.message);
    assertThat(cherry.get().topic).isEqualTo("someTopic-foo");
    cherry.current().review(ReviewInput.approve());
    cherry.current().submit();
}
#method_after
@Test
public void cherryPick() throws Exception {
    PushOneCommit.Result r = pushTo("refs/for/master%topic=someTopic");
    CherryPickInput in = new CherryPickInput();
    in.destination = "foo";
    in.message = "it goes to stable branch";
    gApi.projects().name(project.get()).branch(in.destination).create(new BranchInput());
    ChangeApi orig = gApi.changes().id(project.get() + "~master~" + r.getChangeId());
    assertThat(orig.get().messages).hasSize(1);
    ChangeApi cherry = orig.revision(r.getCommit().name()).cherryPick(in);
    ChangeInfo changeInfoWithDetails = gApi.changes().id(project.get() + "~master~" + r.getChangeId()).get();
    assertThat(changeInfoWithDetails.workInProgress).isNull();
    Collection<ChangeMessageInfo> messages = changeInfoWithDetails.messages;
    assertThat(messages).hasSize(2);
    String cherryPickedRevision = cherry.get().currentRevision;
    String expectedMessage = String.format("Patch Set 1: Cherry Picked\n\n" + "This patchset was cherry picked to branch %s as commit %s", in.destination, cherryPickedRevision);
    Iterator<ChangeMessageInfo> origIt = messages.iterator();
    origIt.next();
    assertThat(origIt.next().message).isEqualTo(expectedMessage);
    assertThat(cherry.get().messages).hasSize(1);
    Iterator<ChangeMessageInfo> cherryIt = cherry.get().messages.iterator();
    expectedMessage = "Patch Set 1: Cherry Picked from branch master.";
    assertThat(cherryIt.next().message).isEqualTo(expectedMessage);
    assertThat(cherry.get().subject).contains(in.message);
    assertThat(cherry.get().topic).isEqualTo("someTopic-foo");
    cherry.current().review(ReviewInput.approve());
    cherry.current().submit();
}
#end_block

#method_before
private static void label(TestSubmitRuleInfo info, SubmitRecord.Label n, AccountInfo who) {
    switch(n.status) {
        case OK:
            if (info.ok == null) {
                info.ok = new LinkedHashMap<>();
            }
            info.ok.put(n.label, who);
            break;
        case REJECT:
            if (info.reject == null) {
                info.reject = new LinkedHashMap<>();
            }
            info.reject.put(n.label, who);
            break;
        case NEED:
            if (info.need == null) {
                info.need = new LinkedHashMap<>();
            }
            info.need.put(n.label, new TestSubmitRuleInfo.None());
            break;
        case MAY:
            if (info.may == null) {
                info.may = new LinkedHashMap<>();
            }
            info.may.put(n.label, who);
            break;
        case IMPOSSIBLE:
            if (info.impossible == null) {
                info.impossible = new LinkedHashMap<>();
            }
            info.impossible.put(n.label, new TestSubmitRuleInfo.None());
            break;
    }
}
#method_after
private static void label(TestSubmitRuleInfo info, SubmitRecord.Label n, AccountInfo who) {
    switch(n.status) {
        case OK:
            if (info.ok == null) {
                info.ok = new LinkedHashMap<>();
            }
            info.ok.put(n.label, who);
            break;
        case REJECT:
            if (info.reject == null) {
                info.reject = new LinkedHashMap<>();
            }
            info.reject.put(n.label, who);
            break;
        case NEED:
            if (info.need == null) {
                info.need = new LinkedHashMap<>();
            }
            info.need.put(n.label, TestSubmitRuleInfo.None.INSTANCE);
            break;
        case MAY:
            if (info.may == null) {
                info.may = new LinkedHashMap<>();
            }
            info.may.put(n.label, who);
            break;
        case IMPOSSIBLE:
            if (info.impossible == null) {
                info.impossible = new LinkedHashMap<>();
            }
            info.impossible.put(n.label, TestSubmitRuleInfo.None.INSTANCE);
            break;
    }
}
#end_block

#method_before
@Override
public void setDynamicBean(String plugin, DynamicOptions.DynamicBean dynamicBean) {
    dynamicBeans.put(plugin, dynamicBean);
}
#method_after
@Override
public void setDynamicBean(String plugin, DynamicBean dynamicBean) {
    dynamicBeans.put(plugin, dynamicBean);
}
#end_block

#method_before
public DynamicOptions.DynamicBean getDynamicBean(String plugin) {
    return dynamicBeans.get(plugin);
}
#method_after
public DynamicBean getDynamicBean(String plugin) {
    return dynamicBeans.get(plugin);
}
#end_block

#method_before
private Path getArchiveFolderFromConfig() {
    String archiveFolder = cfg.getString("archiveFolder", pluginData.toString());
    File newDir = new File(archiveFolder);
    if (!newDir.exists()) {
        boolean created = newDir.mkdirs();
        if (created) {
            log.info("Archive folder {} does not exist, creating it then now", archiveFolder);
        } else {
            log.warn("Archive folder {} does not exist, just failed to create it, so using default path: {}", archiveFolder, pluginData.toString());
            archiveFolder = pluginData.toString();
        }
    }
    return Paths.get(archiveFolder);
}
#method_after
private Path getArchiveFolderFromConfig(String configValue) {
    try {
        return Files.createDirectories(Paths.get(configValue));
    } catch (Exception e) {
        log.warn("Failed to create folder {}: {}; using default path: {}", configValue, e.getMessage(), pluginData);
        return pluginData.toPath();
    }
}
#end_block

#method_before
private long getArchiveDurationFromConfig() {
    long duration;
    try {
        duration = ConfigUtil.getTimeUnit(Strings.nullToEmpty(cfg.getString("deleteArchivedReposAfter")), TimeUnit.DAYS.toMillis(DEFAULT_ARCHIVE_DURATION_DAYS), MILLISECONDS);
    } catch (IllegalArgumentException e) {
        log.warn("The configured archive duration is not valid, use the default value: {} days", DEFAULT_ARCHIVE_DURATION_DAYS);
        duration = TimeUnit.DAYS.toMillis(DEFAULT_ARCHIVE_DURATION_DAYS);
    }
    return duration;
}
#method_after
private long getArchiveDurationFromConfig(String configValue) {
    try {
        return ConfigUtil.getTimeUnit(configValue, DAYS.toMillis(DEFAULT_ARCHIVE_DURATION_DAYS), MILLISECONDS);
    } catch (IllegalArgumentException e) {
        log.warn("The configured archive duration is not valid: {}; using the default value: {} days", e.getMessage(), DEFAULT_ARCHIVE_DURATION_DAYS);
        return DAYS.toMillis(DEFAULT_ARCHIVE_DURATION_DAYS);
    }
}
#end_block

#method_before
private void cleanUpOverdueRepositories() {
    for (Path path : listOverdueFiles(config.getArchiveDuration())) {
        try {
            filesystemDeleteHandler.recursiveDelete(path);
        } catch (IOException e) {
            logger.warn("Error trying to clean the archived git repository: {}", path, e);
        }
    }
}
#method_after
private void cleanUpOverdueRepositories() {
    for (Path path : listOverdueFiles(config.getArchiveDuration())) {
        try {
            MoreFiles.deleteRecursively(path);
        } catch (IOException e) {
            logger.warn("Error trying to clean the archived git repository: {}", path, e);
        }
    }
}
#end_block

#method_before
private List<Path> listOverdueFiles(long duration) {
    List<Path> files = new ArrayList<>();
    File targetDir = config.getArchiveFolder().toFile();
    for (File repo : targetDir.listFiles()) {
        try {
            FileTime lastModifiedTime = Files.getLastModifiedTime(repo.toPath());
            FileTime nowTime = FileTime.fromMillis(TimeMachine.now().toEpochMilli());
            FileTime expires = FileTime.fromMillis(lastModifiedTime.toMillis() + duration);
            if (nowTime.compareTo(expires) > 0) {
                files.add(repo.toPath());
            }
        } catch (IOException e) {
            logger.warn("Error trying to get last modified time for file: {} ", repo.toPath(), e);
        }
    }
    return files;
}
#method_after
private List<Path> listOverdueFiles(long duration) {
    List<Path> files = new ArrayList<>();
    File targetDir = config.getArchiveFolder().toFile();
    FileTime nowTime = FileTime.fromMillis(TimeMachine.now().toEpochMilli());
    for (File repo : targetDir.listFiles()) {
        try {
            FileTime lastModifiedTime = Files.getLastModifiedTime(repo.toPath());
            FileTime expires = FileTime.fromMillis(lastModifiedTime.toMillis() + duration);
            if (nowTime.compareTo(expires) > 0) {
                files.add(repo.toPath());
            }
        } catch (IOException e) {
            logger.warn("Error trying to get last modified time for file: {} ", repo.toPath(), e);
        }
    }
    return files;
}
#end_block

#method_before
@Before
public void setUp() throws Exception {
    pluginDataDir = tempFolder.newFolder("data").toPath();
    customArchiveFolder = tempFolder.newFolder("archive").toPath();
}
#method_after
@Before
public void setUp() throws Exception {
    pluginDataDir = tempFolder.newFolder("data");
    customArchiveFolder = tempFolder.newFolder("archive").toPath();
}
#end_block

#method_before
@Test
public void defaultValuesAreLoaded() {
    when(pluginConfigFactoryMock.getFromGerritConfig(PLUGIN_NAME)).thenReturn(new PluginConfig(PLUGIN_NAME, new Config()));
    deleteConfig = new Configuration(pluginConfigFactoryMock, PLUGIN_NAME, pluginDataDir.toFile());
    assertThat(deleteConfig.getDeletedProjectsParent()).isEqualTo("Deleted-Projects");
    assertThat(deleteConfig.deletionWithTagsAllowed()).isTrue();
    assertThat(deleteConfig.projectOnPreserveHidden()).isFalse();
    assertThat(deleteConfig.shouldArchiveDeletedRepos()).isFalse();
    assertThat(deleteConfig.getArchiveDuration()).isEqualTo(TimeUnit.DAYS.toMillis(Long.parseLong("180")));
    assertThat(deleteConfig.getArchiveFolder().toString()).isEqualTo(pluginDataDir.toFile().toString());
}
#method_after
@Test
public void defaultValuesAreLoaded() {
    when(pluginConfigFactoryMock.getFromGerritConfig(PLUGIN_NAME)).thenReturn(new PluginConfig(PLUGIN_NAME, new Config()));
    deleteConfig = new Configuration(pluginConfigFactoryMock, PLUGIN_NAME, pluginDataDir);
    assertThat(deleteConfig.getDeletedProjectsParent()).isEqualTo("Deleted-Projects");
    assertThat(deleteConfig.deletionWithTagsAllowed()).isTrue();
    assertThat(deleteConfig.projectOnPreserveHidden()).isFalse();
    assertThat(deleteConfig.shouldArchiveDeletedRepos()).isFalse();
    assertThat(deleteConfig.getArchiveDuration()).isEqualTo(DEFAULT_ARCHIVE_DURATION_MS);
    assertThat(deleteConfig.getArchiveFolder().toString()).isEqualTo(pluginDataDir.toString());
}
#end_block

#method_before
@Test
public void customValuesAreLoaded() {
    PluginConfig pluginConfig = new PluginConfig(PLUGIN_NAME, new Config());
    pluginConfig.setString("parentForDeletedProjects", CUSTOM_PARENT);
    pluginConfig.setBoolean("allowDeletionOfReposWithTags", false);
    pluginConfig.setBoolean("hideProjectOnPreserve", true);
    pluginConfig.setBoolean("archiveDeletedRepos", true);
    pluginConfig.setString("deleteArchivedReposAfter", CUSTOM_DURATION);
    pluginConfig.setString("archiveFolder", customArchiveFolder.toString());
    when(pluginConfigFactoryMock.getFromGerritConfig(PLUGIN_NAME)).thenReturn(pluginConfig);
    deleteConfig = new Configuration(pluginConfigFactoryMock, PLUGIN_NAME, pluginDataDir.toFile());
    assertThat(deleteConfig.getDeletedProjectsParent()).isEqualTo(CUSTOM_PARENT);
    assertThat(deleteConfig.deletionWithTagsAllowed()).isFalse();
    assertThat(deleteConfig.projectOnPreserveHidden()).isTrue();
    assertThat(deleteConfig.shouldArchiveDeletedRepos()).isTrue();
    assertThat(deleteConfig.getArchiveDuration()).isEqualTo(Long.parseLong(CUSTOM_DURATION));
    assertThat(deleteConfig.getArchiveFolder().toString()).isEqualTo(customArchiveFolder.toString());
}
#method_after
@Test
public void customValuesAreLoaded() {
    PluginConfig pluginConfig = new PluginConfig(PLUGIN_NAME, new Config());
    pluginConfig.setString("parentForDeletedProjects", CUSTOM_PARENT);
    pluginConfig.setBoolean("allowDeletionOfReposWithTags", false);
    pluginConfig.setBoolean("hideProjectOnPreserve", true);
    pluginConfig.setBoolean("archiveDeletedRepos", true);
    pluginConfig.setString("deleteArchivedReposAfter", CUSTOM_DURATION);
    pluginConfig.setString("archiveFolder", customArchiveFolder.toString());
    when(pluginConfigFactoryMock.getFromGerritConfig(PLUGIN_NAME)).thenReturn(pluginConfig);
    deleteConfig = new Configuration(pluginConfigFactoryMock, PLUGIN_NAME, pluginDataDir);
    assertThat(deleteConfig.getDeletedProjectsParent()).isEqualTo(CUSTOM_PARENT);
    assertThat(deleteConfig.deletionWithTagsAllowed()).isFalse();
    assertThat(deleteConfig.projectOnPreserveHidden()).isTrue();
    assertThat(deleteConfig.shouldArchiveDeletedRepos()).isTrue();
    assertThat(deleteConfig.getArchiveDuration()).isEqualTo(Long.parseLong(CUSTOM_DURATION));
    assertThat(deleteConfig.getArchiveFolder().toString()).isEqualTo(customArchiveFolder.toString());
}
#end_block

#method_before
@Test
public void archiveDurationWithUnitIsLoaded() {
    PluginConfig pluginConfig = new PluginConfig(PLUGIN_NAME, new Config());
    pluginConfig.setString("deleteArchivedReposAfter", CUSTOM_DURATION + ("years"));
    when(pluginConfigFactoryMock.getFromGerritConfig(PLUGIN_NAME)).thenReturn(pluginConfig);
    deleteConfig = new Configuration(pluginConfigFactoryMock, PLUGIN_NAME, pluginDataDir.toFile());
    assertThat(deleteConfig.getArchiveDuration()).isEqualTo(TimeUnit.DAYS.toMillis(Long.parseLong(CUSTOM_DURATION)) * 365);
}
#method_after
@Test
public void archiveDurationWithUnitIsLoaded() {
    PluginConfig pluginConfig = new PluginConfig(PLUGIN_NAME, new Config());
    pluginConfig.setString("deleteArchivedReposAfter", CUSTOM_DURATION + "years");
    when(pluginConfigFactoryMock.getFromGerritConfig(PLUGIN_NAME)).thenReturn(pluginConfig);
    deleteConfig = new Configuration(pluginConfigFactoryMock, PLUGIN_NAME, pluginDataDir);
    assertThat(deleteConfig.getArchiveDuration()).isEqualTo(TimeUnit.DAYS.toMillis(Long.parseLong(CUSTOM_DURATION)) * 365);
}
#end_block

#method_before
@Test
public void invalidArchiveDuration() {
    PluginConfig pluginConfig = new PluginConfig(PLUGIN_NAME, new Config());
    pluginConfig.setString("deleteArchivedReposAfter", INVALID_ARCHIVE_DURATION);
    when(pluginConfigFactoryMock.getFromGerritConfig(PLUGIN_NAME)).thenReturn(pluginConfig);
    deleteConfig = new Configuration(pluginConfigFactoryMock, PLUGIN_NAME, pluginDataDir.toFile());
    assertThat(deleteConfig.getArchiveDuration()).isEqualTo(TimeUnit.DAYS.toMillis(Long.parseLong("180")));
}
#method_after
@Test
public void invalidArchiveDuration() {
    PluginConfig pluginConfig = new PluginConfig(PLUGIN_NAME, new Config());
    pluginConfig.setString("deleteArchivedReposAfter", INVALID_ARCHIVE_DURATION);
    when(pluginConfigFactoryMock.getFromGerritConfig(PLUGIN_NAME)).thenReturn(pluginConfig);
    deleteConfig = new Configuration(pluginConfigFactoryMock, PLUGIN_NAME, pluginDataDir);
    assertThat(deleteConfig.getArchiveDuration()).isEqualTo(DEFAULT_ARCHIVE_DURATION_MS);
}
#end_block

#method_before
@Test
public void invalidTargetArchiveFolder() {
    PluginConfig pluginConfig = new PluginConfig(PLUGIN_NAME, new Config());
    pluginConfig.setString("archiveFolder", INVALID_CUSTOM_FOLDER);
    when(pluginConfigFactoryMock.getFromGerritConfig(PLUGIN_NAME)).thenReturn(pluginConfig);
    deleteConfig = new Configuration(pluginConfigFactoryMock, PLUGIN_NAME, pluginDataDir.toFile());
    assertThat(deleteConfig.getArchiveFolder().toString()).isEqualTo(pluginDataDir.toFile().toString());
}
#method_after
@Test
public void invalidTargetArchiveFolder() {
    PluginConfig pluginConfig = new PluginConfig(PLUGIN_NAME, new Config());
    pluginConfig.setString("archiveFolder", INVALID_CUSTOM_FOLDER);
    when(pluginConfigFactoryMock.getFromGerritConfig(PLUGIN_NAME)).thenReturn(pluginConfig);
    deleteConfig = new Configuration(pluginConfigFactoryMock, PLUGIN_NAME, pluginDataDir);
    assertThat(deleteConfig.getArchiveFolder().toString()).isEqualTo(pluginDataDir.toString());
}
#end_block

#method_before
public void delete(Project project, boolean preserveGitRepository) throws IOException, RepositoryNotFoundException {
    // Remove from the jgit cache
    Repository repository = repoManager.openRepository(project.getNameKey());
    File repoFile = repository.getDirectory();
    cleanCache(repository);
    if (!preserveGitRepository) {
        deleteGitRepository(project.getNameKey(), repoFile);
    }
}
#method_after
public void delete(Project project, boolean preserveGitRepository) throws IOException, RepositoryNotFoundException {
    // Remove from the jgit cache
    Repository repository = repoManager.openRepository(project.getNameKey());
    cleanCache(repository);
    if (!preserveGitRepository) {
        Path repoPath = repository.getDirectory().toPath();
        String projectName = project.getNameKey().get();
        if (config.shouldArchiveDeletedRepos()) {
            archiveGitRepository(projectName, repoPath);
        } else {
            deleteGitRepository(projectName, repoPath);
        }
    }
}
#end_block

#method_before
private void cleanCache(final Repository repository) {
    repository.close();
    RepositoryCache.close(repository);
}
#method_after
private void cleanCache(Repository repository) {
    repository.close();
    RepositoryCache.close(repository);
}
#end_block

#method_before
private void deleteGitRepository(final Project.NameKey project, final File repoFile) throws IOException {
    // Delete the repository from disk
    Path basePath = getBasePath(repoFile.toPath(), project);
    Path trash = moveToTrash(repoFile.toPath(), basePath, project);
    if (config.shouldArchiveDeletedRepos()) {
        try {
            Path archiveRepo = config.getArchiveFolder().resolve(trash.getFileName());
            recursiveArchive(trash, archiveRepo);
        } catch (IOException e) {
            log.warn("Error trying to archive {}, repo already moved to trash.", repoFile.toPath(), e);
        }
    }
    boolean ok = false;
    try {
        recursiveDelete(trash);
        ok = true;
    } catch (IOException e) {
        // Only log if delete failed - repo already moved to trash.
        // Otherwise, listeners are never called.
        log.warn("Error trying to delete {}", trash, e);
    }
    // Delete parent folders if they are (now) empty
    if (ok) {
        try {
            recursiveDeleteParent(repoFile.getParentFile(), basePath.toFile());
        } catch (IOException e) {
            log.warn("Couldn't delete (empty) parents of {}", repoFile, e);
        }
    }
    // Send an event that the repository was deleted
    ProjectDeletedListener.Event event = new ProjectDeletedListener.Event() {

        @Override
        public String getProjectName() {
            return project.get();
        }

        @Override
        public NotifyHandling getNotify() {
            return NotifyHandling.NONE;
        }
    };
    for (ProjectDeletedListener l : deletedListener) {
        try {
            l.onProjectDeleted(event);
        } catch (RuntimeException e) {
            log.warn("Failure in ProjectDeletedListener", e);
        }
    }
}
#method_after
private void deleteGitRepository(String projectName, Path repoPath) throws IOException {
    // Delete the repository from disk
    Path basePath = getBasePath(repoPath, projectName);
    Path trash = renameRepository(repoPath, basePath, projectName, "deleted");
    try {
        MoreFiles.deleteRecursively(trash);
        recursivelyDeleteEmptyParents(repoPath.toFile().getParentFile(), basePath.toFile());
    } catch (IOException e) {
        // Only log if delete failed - repo already moved to trash.
        log.warn("Error trying to delete {} or its parents", trash, e);
    } finally {
        sendProjectDeletedEvent(projectName);
    }
}
#end_block

#method_before
private Path getBasePath(Path repo, Project.NameKey project) {
    Path projectPath = Paths.get(project.get());
    return repo.getRoot().resolve(repo.subpath(0, repo.getNameCount() - projectPath.getNameCount()));
}
#method_after
private Path getBasePath(Path repo, String projectName) {
    Path projectPath = Paths.get(projectName);
    return repo.getRoot().resolve(repo.subpath(0, repo.getNameCount() - projectPath.getNameCount()));
}
#end_block

#method_before
@Before
public void setUp() throws Exception {
    fsDeleteHandler = new FilesystemDeleteHandler(null, null, null);
    archiveRepo = tempFolder.newFolder("archive").toPath();
    projectRepo = tempFolder.newFolder("project").toPath();
}
#method_after
@Before
public void setUp() throws Exception {
    basePath = tempFolder.newFolder().toPath().resolve("base");
    deletedListener = new DynamicSet<>();
    deletedListener.add(projectDeleteListener);
}
#end_block

#method_before
@Before
public void setUp() throws Exception {
    when(cleanupTaskProviderMock.get()).thenReturn(new RepositoryCleanupTask(null, null, PLUGIN_NAME));
    when(workQueueMock.getDefaultQueue()).thenReturn(executorMock);
    doReturn(scheduledFutureMock).when(executorMock).scheduleAtFixedRate(isA(RepositoryCleanupTask.class), anyLong(), anyLong(), isA(TimeUnit.class));
    remover = new ArchiveRepositoryRemover(workQueueMock, cleanupTaskProviderMock);
    fsDeleteHandler = new FilesystemDeleteHandler(null, null, configMock);
    archiveRepo = tempFolder.newFolder("archive").toPath();
}
#method_after
@Before
public void setUp() throws Exception {
    when(cleanupTaskProviderMock.get()).thenReturn(new RepositoryCleanupTask(null, null));
    when(workQueueMock.getDefaultQueue()).thenReturn(executorMock);
    doReturn(scheduledFutureMock).when(executorMock).scheduleAtFixedRate(isA(RepositoryCleanupTask.class), anyLong(), anyLong(), isA(TimeUnit.class));
    remover = new ArchiveRepositoryRemover(workQueueMock, cleanupTaskProviderMock);
    archiveRepo = tempFolder.newFolder("archive").toPath();
    when(configMock.getArchiveFolder()).thenReturn(archiveRepo);
    when(configMock.getArchiveDuration()).thenReturn(ARCHIVE_DURATION);
}
#end_block

#method_before
@Test
public void cleanUpOverdueRepositoriesTest() throws IOException {
    setupConfigMock();
    try {
        TimeMachine.useFixedClockAt(Instant.ofEpochMilli(Files.getLastModifiedTime(archiveRepo).toMillis()).plusMillis(TimeUnit.DAYS.toMillis(Long.parseLong(ARCHIVE_DURATION)) + 10));
        fsDeleteHandler = new FilesystemDeleteHandler(null, null, configMock);
        RepositoryCleanupTask task = new RepositoryCleanupTask(fsDeleteHandler, configMock, PLUGIN_NAME);
        task.run();
        assertThat(isDirEmpty(archiveRepo)).isTrue();
    } finally {
        TimeMachine.useSystemDefaultZoneClock();
    }
}
#method_after
@Test
public void cleanUpOverdueRepositoriesTest() throws IOException {
    setupArchiveFolder();
    try {
        TimeMachine.useFixedClockAt(Instant.ofEpochMilli(Files.getLastModifiedTime(archiveRepo).toMillis()).plusMillis(TimeUnit.DAYS.toMillis(ARCHIVE_DURATION) + 10));
        RepositoryCleanupTask task = new RepositoryCleanupTask(configMock, PLUGIN_NAME);
        task.run();
        assertThat(task.toString()).isEqualTo(String.format("[%s]: Clean up expired git repositories from the archive [%s]", PLUGIN_NAME, archiveRepo));
        assertThat(isDirEmpty(archiveRepo)).isTrue();
    } finally {
        TimeMachine.useSystemDefaultZoneClock();
    }
}
#end_block

#method_before
@Override
protected void configure() {
    bind(LifecycleListener.class).annotatedWith(UniqueAnnotations.create()).to(DeleteLog.class);
    bind(LifecycleListener.class).annotatedWith(UniqueAnnotations.create()).to(DeleteTrashFolders.class);
    bind(CacheDeleteHandler.class);
    bind(CapabilityDefinition.class).annotatedWith(Exports.named(DELETE_PROJECT)).to(DeleteProjectCapability.class);
    bind(CapabilityDefinition.class).annotatedWith(Exports.named(DELETE_OWN_PROJECT)).to(DeleteOwnProjectCapability.class);
    bind(DatabaseDeleteHandler.class);
    bind(FilesystemDeleteHandler.class);
    bind(LifecycleListener.class).annotatedWith(UniqueAnnotations.create()).to(ArchiveRepositoryRemover.class);
    bind(ProjectConfigDeleteHandler.class);
    install(new RestApiModule() {

        @Override
        protected void configure() {
            delete(PROJECT_KIND).to(DeleteProject.class);
            post(PROJECT_KIND, "delete").to(DeleteAction.class);
        }
    });
}
#method_after
@Override
protected void configure() {
    bind(LifecycleListener.class).annotatedWith(UniqueAnnotations.create()).to(DeleteLog.class);
    bind(LifecycleListener.class).annotatedWith(UniqueAnnotations.create()).to(DeleteTrashFolders.class);
    bind(CacheDeleteHandler.class);
    bind(CapabilityDefinition.class).annotatedWith(Exports.named(DELETE_PROJECT)).to(DeleteProjectCapability.class);
    bind(CapabilityDefinition.class).annotatedWith(Exports.named(DELETE_OWN_PROJECT)).to(DeleteOwnProjectCapability.class);
    bind(DatabaseDeleteHandler.class);
    bind(FilesystemDeleteHandler.class);
    bind(DeletePreconditions.class);
    if (scheduleCleaning) {
        bind(LifecycleListener.class).annotatedWith(UniqueAnnotations.create()).to(ArchiveRepositoryRemover.class);
    }
    install(new RestApiModule() {

        @Override
        protected void configure() {
            delete(PROJECT_KIND).to(DeleteProject.class);
            post(PROJECT_KIND, "delete").to(DeleteAction.class);
        }
    });
}
#end_block

#method_before
@VisibleForTesting
static final boolean match(String fName) {
    return TRASH_1.matcher(fName).matches() || TRASH_2.matcher(fName).matches();
}
#method_after
@VisibleForTesting
static final boolean match(String fName) {
    return TRASH_1.matcher(fName).matches() || TRASH_2.matcher(fName).matches() || TRASH_3.matcher(fName).matches();
}
#end_block

#method_before
@Test
public void matchingNames() {
    matches("a.1234567890123.deleted");
    matches("aa.1234567890123.deleted");
    matches("a.b.c.1234567890123.deleted");
    matches("a.20181010120101.%deleted%.git");
    matches("aa.20181010120101.%deleted%.git");
    matches("a.b.c.20181010120101.%deleted%.git");
}
#method_after
@Test
public void matchingNames() {
    matches("a.1234567890123.deleted");
    matches("aa.1234567890123.deleted");
    matches("a.b.c.1234567890123.deleted");
    matches("a.1234567890123.%deleted%.git");
    matches("aa.1234567890123.%deleted%.git");
    matches("a.b.c.1234567890123.%deleted%.git");
    matches("a.20181010120101.%deleted%.git");
    matches("aa.20181010120101.%deleted%.git");
    matches("a.b.c.20181010120101.%deleted%.git");
}
#end_block

#method_before
@Test
public void nonMatchingNames() {
    doesNotMatch("a.git");
    doesNotMatch("a.1234567890123.git");
    doesNotMatch("a.1234567890123.deleted.git");
    // timestamp one digit shorter
    doesNotMatch("a.123456789012.deleted");
    // additional characters after the "deleted" suffix
    doesNotMatch("a.1234567890123.deleted.");
    doesNotMatch("a.1234567890123.deleted.git");
    // missing .git suffix
    doesNotMatch("a.20181010120101.%deleted%");
    // additional characters after the "git" suffix
    doesNotMatch("a.20181010120101.%deleted%.git.");
    doesNotMatch("a.20181010120101.%deleted%.git.git");
}
#method_after
@Test
public void nonMatchingNames() {
    doesNotMatch("a.git");
    doesNotMatch("a.1234567890123.git");
    doesNotMatch("a.1234567890123.deleted.git");
    // timestamp one digit shorter
    doesNotMatch("a.123456789012.deleted");
    // additional characters after the "deleted" suffix
    doesNotMatch("a.1234567890123.deleted.");
    doesNotMatch("a.1234567890123.deleted.git");
    // missing .git suffix
    doesNotMatch("a.1234567890123.%deleted%");
    doesNotMatch("a.20181010120101.%deleted%");
    // additional characters after the "git" suffix
    doesNotMatch("a.1234567890123.%deleted%.git.");
    doesNotMatch("a.1234567890123.%deleted%.git.git");
    doesNotMatch("a.20181010120101.%deleted%.git.");
    doesNotMatch("a.20181010120101.%deleted%.git.git");
}
#end_block

#method_before
protected void startThreadWithContext(SshScope.Context context, final CommandRunnable thunk) {
    final TaskThunk tt = new TaskThunk(thunk, Optional.of(context));
    if (isAdminHighPriorityCommand() && user.getCapabilities().canAdministrateServer()) {
        // Admin commands should not block the main work threads (there
        // might be an interactive shell there), nor should they wait
        // for the main work threads.
        // 
        new Thread(tt, tt.toString()).start();
    } else {
        task.set(executor.submit(tt));
    }
}
#method_after
protected void startThreadWithContext(SshScope.Context context, final CommandRunnable thunk) {
    final TaskThunk tt = new TaskThunk(thunk, Optional.ofNullable(context));
    if (isAdminHighPriorityCommand() && user.getCapabilities().canAdministrateServer()) {
        // Admin commands should not block the main work threads (there
        // might be an interactive shell there), nor should they wait
        // for the main work threads.
        // 
        new Thread(tt, tt.toString()).start();
    } else {
        task.set(executor.submit(tt));
    }
}
#end_block

#method_before
public ChangeInfo format(Project.NameKey project, Change.Id id) throws OrmException {
    ChangeNotes notes;
    try {
        notes = notesFactory.createChecked(db.get(), project, id);
    } catch (OrmException e) {
        if (!has(CHECK)) {
            throw e;
        }
        return checkOnly(changeDataFactory.create(db.get(), project, id));
    }
    return format(changeDataFactory.create(db.get(), notes));
}
#method_after
public ChangeInfo format(Project.NameKey project, Change.Id id) throws OrmException {
    return format(project, id, ChangeInfo::new);
}
#end_block

#method_before
public ChangeInfo format(RevisionResource rsrc) throws OrmException {
    ChangeData cd = changeDataFactory.create(db.get(), rsrc.getNotes());
    return format(cd, Optional.of(rsrc.getPatchSet().getId()), true);
}
#method_after
public <I extends ChangeInfo> I format(Project.NameKey project, Change.Id id, Supplier<I> changeInfoSupplier) throws OrmException {
    ChangeNotes notes;
    try {
        notes = notesFactory.createChecked(db.get(), project, id);
    } catch (OrmException e) {
        if (!has(CHECK)) {
            throw e;
        }
        return checkOnly(changeDataFactory.create(db.get(), project, id), changeInfoSupplier);
    }
    return format(changeDataFactory.create(db.get(), notes), changeInfoSupplier);
}
#end_block

#method_before
public ChangeInfo format(ChangeData cd) throws OrmException {
    return format(cd, Optional.empty(), true);
}
#method_after
public ChangeInfo format(ChangeData cd) throws OrmException {
    return format(cd, ChangeInfo::new);
}
#end_block

#method_before
private ChangeInfo format(ChangeData cd, Optional<PatchSet.Id> limitToPsId, boolean fillAccountLoader) throws OrmException {
    try {
        if (fillAccountLoader) {
            accountLoader = accountLoaderFactory.create(has(DETAILED_ACCOUNTS));
            ChangeInfo res = toChangeInfo(cd, limitToPsId);
            accountLoader.fill();
            return res;
        }
        return toChangeInfo(cd, limitToPsId);
    } catch (PatchListNotAvailableException | GpgException | OrmException | IOException | PermissionBackendException | RuntimeException e) {
        if (!has(CHECK)) {
            Throwables.throwIfInstanceOf(e, OrmException.class);
            throw new OrmException(e);
        }
        return checkOnly(cd);
    }
}
#method_after
private ChangeInfo format(ChangeData cd, Optional<PatchSet.Id> limitToPsId, boolean fillAccountLoader) throws OrmException {
    return format(cd, limitToPsId, fillAccountLoader, ChangeInfo::new);
}
#end_block

#method_before
private ChangeInfo checkOnly(ChangeData cd) {
    ChangeNotes notes;
    try {
        notes = cd.notes();
    } catch (OrmException e) {
        String msg = "Error loading change";
        logger.atWarning().withCause(e).log(msg + " %s", cd.getId());
        ChangeInfo info = new ChangeInfo();
        info._number = cd.getId().get();
        ProblemInfo p = new ProblemInfo();
        p.message = msg;
        info.problems = Lists.newArrayList(p);
        return info;
    }
    ConsistencyChecker.Result result = checkerProvider.get().check(notes, fix);
    ChangeInfo info;
    Change c = result.change();
    if (c != null) {
        info = new ChangeInfo();
        info.project = c.getProject().get();
        info.branch = c.getDest().getShortName();
        info.topic = c.getTopic();
        info.changeId = c.getKey().get();
        info.subject = c.getSubject();
        info.status = c.getStatus().asChangeStatus();
        info.owner = new AccountInfo(c.getOwner().get());
        info.created = c.getCreatedOn();
        info.updated = c.getLastUpdatedOn();
        info._number = c.getId().get();
        info.problems = result.problems();
        info.isPrivate = c.isPrivate() ? true : null;
        info.workInProgress = c.isWorkInProgress() ? true : null;
        info.hasReviewStarted = c.hasReviewStarted();
        finish(info);
    } else {
        info = new ChangeInfo();
        info._number = result.id().get();
        info.problems = result.problems();
    }
    return info;
}
#method_after
private <I extends ChangeInfo> I checkOnly(ChangeData cd, Supplier<I> changeInfoSupplier) {
    ChangeNotes notes;
    try {
        notes = cd.notes();
    } catch (OrmException e) {
        String msg = "Error loading change";
        logger.atWarning().withCause(e).log(msg + " %s", cd.getId());
        I info = changeInfoSupplier.get();
        info._number = cd.getId().get();
        ProblemInfo p = new ProblemInfo();
        p.message = msg;
        info.problems = Lists.newArrayList(p);
        return info;
    }
    ConsistencyChecker.Result result = checkerProvider.get().check(notes, fix);
    I info = changeInfoSupplier.get();
    Change c = result.change();
    if (c != null) {
        info.project = c.getProject().get();
        info.branch = c.getDest().getShortName();
        info.topic = c.getTopic();
        info.changeId = c.getKey().get();
        info.subject = c.getSubject();
        info.status = c.getStatus().asChangeStatus();
        info.owner = new AccountInfo(c.getOwner().get());
        info.created = c.getCreatedOn();
        info.updated = c.getLastUpdatedOn();
        info._number = c.getId().get();
        info.problems = result.problems();
        info.isPrivate = c.isPrivate() ? true : null;
        info.workInProgress = c.isWorkInProgress() ? true : null;
        info.hasReviewStarted = c.hasReviewStarted();
        finish(info);
    } else {
        info._number = result.id().get();
        info.problems = result.problems();
    }
    return info;
}
#end_block

#method_before
private ChangeInfo toChangeInfo(ChangeData cd, Optional<PatchSet.Id> limitToPsId) throws PatchListNotAvailableException, GpgException, OrmException, PermissionBackendException, IOException {
    try (Timer0.Context ignored = metrics.toChangeInfoLatency.start()) {
        return toChangeInfoImpl(cd, limitToPsId);
    }
}
#method_after
private <I extends ChangeInfo> I toChangeInfo(ChangeData cd, Optional<PatchSet.Id> limitToPsId, Supplier<I> changeInfoSupplier) throws PatchListNotAvailableException, GpgException, OrmException, PermissionBackendException, IOException {
    try (Timer0.Context ignored = metrics.toChangeInfoLatency.start()) {
        return toChangeInfoImpl(cd, limitToPsId, changeInfoSupplier);
    }
}
#end_block

#method_before
private ChangeInfo toChangeInfoImpl(ChangeData cd, Optional<PatchSet.Id> limitToPsId) throws PatchListNotAvailableException, GpgException, OrmException, PermissionBackendException, IOException {
    ChangeInfo out = new ChangeInfo();
    CurrentUser user = userProvider.get();
    if (has(CHECK)) {
        out.problems = checkerProvider.get().check(cd.notes(), fix).problems();
        // If any problems were fixed, the ChangeData needs to be reloaded.
        for (ProblemInfo p : out.problems) {
            if (p.status == ProblemInfo.Status.FIXED) {
                cd = changeDataFactory.create(cd.db(), cd.project(), cd.getId());
                break;
            }
        }
    }
    Change in = cd.change();
    out.project = in.getProject().get();
    out.branch = in.getDest().getShortName();
    out.topic = in.getTopic();
    out.assignee = in.getAssignee() != null ? accountLoader.get(in.getAssignee()) : null;
    out.hashtags = cd.hashtags();
    out.changeId = in.getKey().get();
    if (in.getStatus().isOpen()) {
        SubmitTypeRecord str = cd.submitTypeRecord();
        if (str.isOk()) {
            out.submitType = str.type;
        }
        if (!has(SKIP_MERGEABLE)) {
            out.mergeable = cd.isMergeable();
        }
        if (has(SUBMITTABLE)) {
            out.submittable = submittable(cd);
        }
    }
    Optional<ChangedLines> changedLines = cd.changedLines();
    if (changedLines.isPresent()) {
        out.insertions = changedLines.get().insertions;
        out.deletions = changedLines.get().deletions;
    }
    out.isPrivate = in.isPrivate() ? true : null;
    out.workInProgress = in.isWorkInProgress() ? true : null;
    out.hasReviewStarted = in.hasReviewStarted();
    out.subject = in.getSubject();
    out.status = in.getStatus().asChangeStatus();
    out.owner = accountLoader.get(in.getOwner());
    out.created = in.getCreatedOn();
    out.updated = in.getLastUpdatedOn();
    out._number = in.getId().get();
    out.unresolvedCommentCount = cd.unresolvedCommentCount();
    if (user.isIdentifiedUser()) {
        Collection<String> stars = cd.stars(user.getAccountId());
        out.starred = stars.contains(StarredChangesUtil.DEFAULT_LABEL) ? true : null;
        if (!stars.isEmpty()) {
            out.stars = stars;
        }
    }
    if (in.getStatus().isOpen() && has(REVIEWED) && user.isIdentifiedUser()) {
        out.reviewed = cd.isReviewedBy(user.getAccountId()) ? true : null;
    }
    out.labels = labelsFor(cd, has(LABELS), has(DETAILED_LABELS));
    out.requirements = requirementsFor(cd);
    if (out.labels != null && has(DETAILED_LABELS)) {
        // list permitted labels, since users can't vote on those patch sets.
        if (user.isIdentifiedUser() && (!limitToPsId.isPresent() || limitToPsId.get().equals(in.currentPatchSetId()))) {
            out.permittedLabels = cd.change().getStatus() != Change.Status.ABANDONED ? permittedLabels(user.getAccountId(), cd) : ImmutableMap.of();
        }
        out.reviewers = reviewerMap(cd.reviewers(), cd.reviewersByEmail(), false);
        out.pendingReviewers = reviewerMap(cd.pendingReviewers(), cd.pendingReviewersByEmail(), true);
        out.removableReviewers = removableReviewers(cd, out);
    }
    setSubmitter(cd, out);
    out.plugins = pluginDefinedAttributesFactory != null ? pluginDefinedAttributesFactory.create(cd) : null;
    out.revertOf = cd.change().getRevertOf() != null ? cd.change().getRevertOf().get() : null;
    if (has(REVIEWER_UPDATES)) {
        out.reviewerUpdates = reviewerUpdates(cd);
    }
    boolean needMessages = has(MESSAGES);
    boolean needRevisions = has(ALL_REVISIONS) || has(CURRENT_REVISION) || limitToPsId.isPresent();
    Map<PatchSet.Id, PatchSet> src;
    if (needMessages || needRevisions) {
        src = loadPatchSets(cd, limitToPsId);
    } else {
        src = null;
    }
    if (needMessages) {
        out.messages = messages(cd);
    }
    finish(out);
    // it will be passed to ActionVisitors as-is.
    if (needRevisions) {
        out.revisions = revisionJson.getRevisions(accountLoader, cd, src, limitToPsId, out);
        if (out.revisions != null) {
            for (Map.Entry<String, RevisionInfo> entry : out.revisions.entrySet()) {
                if (entry.getValue().isCurrent) {
                    out.currentRevision = entry.getKey();
                    break;
                }
            }
        }
    }
    if (has(CURRENT_ACTIONS) || has(CHANGE_ACTIONS)) {
        actionJson.addChangeActions(out, cd.notes());
    }
    if (has(TRACKING_IDS)) {
        ListMultimap<String, String> set = trackingFooters.extract(cd.commitFooters());
        out.trackingIds = set.entries().stream().map(e -> new TrackingIdInfo(e.getKey(), e.getValue())).collect(toList());
    }
    return out;
}
#method_after
private <I extends ChangeInfo> I toChangeInfoImpl(ChangeData cd, Optional<PatchSet.Id> limitToPsId, Supplier<I> changeInfoSupplier) throws PatchListNotAvailableException, GpgException, OrmException, PermissionBackendException, IOException {
    I out = changeInfoSupplier.get();
    CurrentUser user = userProvider.get();
    if (has(CHECK)) {
        out.problems = checkerProvider.get().check(cd.notes(), fix).problems();
        // If any problems were fixed, the ChangeData needs to be reloaded.
        for (ProblemInfo p : out.problems) {
            if (p.status == ProblemInfo.Status.FIXED) {
                cd = changeDataFactory.create(cd.db(), cd.project(), cd.getId());
                break;
            }
        }
    }
    Change in = cd.change();
    out.project = in.getProject().get();
    out.branch = in.getDest().getShortName();
    out.topic = in.getTopic();
    out.assignee = in.getAssignee() != null ? accountLoader.get(in.getAssignee()) : null;
    out.hashtags = cd.hashtags();
    out.changeId = in.getKey().get();
    if (in.getStatus().isOpen()) {
        SubmitTypeRecord str = cd.submitTypeRecord();
        if (str.isOk()) {
            out.submitType = str.type;
        }
        if (!has(SKIP_MERGEABLE)) {
            out.mergeable = cd.isMergeable();
        }
        if (has(SUBMITTABLE)) {
            out.submittable = submittable(cd);
        }
    }
    Optional<ChangedLines> changedLines = cd.changedLines();
    if (changedLines.isPresent()) {
        out.insertions = changedLines.get().insertions;
        out.deletions = changedLines.get().deletions;
    }
    out.isPrivate = in.isPrivate() ? true : null;
    out.workInProgress = in.isWorkInProgress() ? true : null;
    out.hasReviewStarted = in.hasReviewStarted();
    out.subject = in.getSubject();
    out.status = in.getStatus().asChangeStatus();
    out.owner = accountLoader.get(in.getOwner());
    out.created = in.getCreatedOn();
    out.updated = in.getLastUpdatedOn();
    out._number = in.getId().get();
    out.unresolvedCommentCount = cd.unresolvedCommentCount();
    if (user.isIdentifiedUser()) {
        Collection<String> stars = cd.stars(user.getAccountId());
        out.starred = stars.contains(StarredChangesUtil.DEFAULT_LABEL) ? true : null;
        if (!stars.isEmpty()) {
            out.stars = stars;
        }
    }
    if (in.getStatus().isOpen() && has(REVIEWED) && user.isIdentifiedUser()) {
        out.reviewed = cd.isReviewedBy(user.getAccountId()) ? true : null;
    }
    out.labels = labelsFor(cd, has(LABELS), has(DETAILED_LABELS));
    out.requirements = requirementsFor(cd);
    if (out.labels != null && has(DETAILED_LABELS)) {
        // list permitted labels, since users can't vote on those patch sets.
        if (user.isIdentifiedUser() && (!limitToPsId.isPresent() || limitToPsId.get().equals(in.currentPatchSetId()))) {
            out.permittedLabels = cd.change().getStatus() != Change.Status.ABANDONED ? permittedLabels(user.getAccountId(), cd) : ImmutableMap.of();
        }
        out.reviewers = reviewerMap(cd.reviewers(), cd.reviewersByEmail(), false);
        out.pendingReviewers = reviewerMap(cd.pendingReviewers(), cd.pendingReviewersByEmail(), true);
        out.removableReviewers = removableReviewers(cd, out);
    }
    setSubmitter(cd, out);
    out.plugins = pluginDefinedAttributesFactory != null ? pluginDefinedAttributesFactory.create(cd) : null;
    out.revertOf = cd.change().getRevertOf() != null ? cd.change().getRevertOf().get() : null;
    if (has(REVIEWER_UPDATES)) {
        out.reviewerUpdates = reviewerUpdates(cd);
    }
    boolean needMessages = has(MESSAGES);
    boolean needRevisions = has(ALL_REVISIONS) || has(CURRENT_REVISION) || limitToPsId.isPresent();
    Map<PatchSet.Id, PatchSet> src;
    if (needMessages || needRevisions) {
        src = loadPatchSets(cd, limitToPsId);
    } else {
        src = null;
    }
    if (needMessages) {
        out.messages = messages(cd);
    }
    finish(out);
    // it will be passed to ActionVisitors as-is.
    if (needRevisions) {
        out.revisions = revisionJson.getRevisions(accountLoader, cd, src, limitToPsId, out);
        if (out.revisions != null) {
            for (Map.Entry<String, RevisionInfo> entry : out.revisions.entrySet()) {
                if (entry.getValue().isCurrent) {
                    out.currentRevision = entry.getKey();
                    break;
                }
            }
        }
    }
    if (has(CURRENT_ACTIONS) || has(CHANGE_ACTIONS)) {
        actionJson.addChangeActions(out, cd.notes());
    }
    if (has(TRACKING_IDS)) {
        ListMultimap<String, String> set = trackingFooters.extract(cd.commitFooters());
        out.trackingIds = set.entries().stream().map(e -> new TrackingIdInfo(e.getKey(), e.getValue())).collect(toList());
    }
    return out;
}
#end_block

#method_before
public static void populateFetchMap(DownloadScheme scheme, DynamicMap<DownloadCommand> commands, String projectName, String refName, FetchInfo fetchInfo) {
    for (Extension<DownloadCommand> e2 : commands) {
        String commandName = e2.getExportName();
        DownloadCommand command = e2.getProvider().get();
        String c = command.getCommand(scheme, projectName, refName);
        if (c != null) {
            addCommand(fetchInfo, commandName, c);
        }
    }
}
#method_after
public static void populateFetchMap(DownloadScheme scheme, DynamicMap<DownloadCommand> commands, String projectName, String refName, FetchInfo fetchInfo) {
    for (Extension<DownloadCommand> ext : commands) {
        String commandName = ext.getExportName();
        DownloadCommand command = ext.getProvider().get();
        String c = command.getCommand(scheme, projectName, refName);
        if (c != null) {
            if (fetchInfo.commands == null) {
                fetchInfo.commands = new TreeMap<>();
            }
            fetchInfo.commands.put(commandName, c);
        }
    }
}
#end_block

#method_before
@Override
public void onPostUpload(PackStatistics stats) {
    String repositoryPath = uploadRepositoryPath.get();
    if (repositoryPath != null) {
        queueEvaluationIfNecessary(repositoryPath);
        uploadRepositoryPath.remove();
    }
}
#method_after
@Override
public void onPostUpload(PackStatistics stats) {
    String repositoryPath = uploadRepositoryPath.get();
    if (repositoryPath != null && needsCheck(repositoryPath)) {
        executor.execute(evaluationTaskFactory.create(repositoryPath));
        uploadRepositoryPath.remove();
    }
}
#end_block

#method_before
@Override
public void onGitReferenceUpdated(Event event) {
    String projectName = event.getProjectName();
    Project.NameKey projectNameKey = new Project.NameKey(projectName);
    try (Repository repository = repoManager.openRepository(projectNameKey)) {
        String repositoryPath = repository.getDirectory().getAbsolutePath();
        queueEvaluationIfNecessary(repositoryPath);
    } catch (RepositoryNotFoundException e) {
        log.error("Project not found {}", projectName, e);
    } catch (IOException e) {
        log.error("Error getting repository for project {}", projectName, e);
    }
}
#method_after
@Override
public void onGitReferenceUpdated(Event event) {
    String projectName = event.getProjectName();
    Project.NameKey projectNameKey = new Project.NameKey(projectName);
    try (Repository repository = repoManager.openRepository(projectNameKey)) {
        String repositoryPath = repository.getDirectory().getAbsolutePath();
        if (needsCheck(repositoryPath)) {
            executor.execute(evaluationTaskFactory.create(repositoryPath));
        }
    } catch (RepositoryNotFoundException e) {
        log.error("Project not found {}", projectName, e);
    } catch (IOException e) {
        log.error("Error getting repository for project {}", projectName, e);
    }
}
#end_block

#method_before
@Test
public void onPostUploadShouldCreateTaskOnlyIfPreUploadCalled() {
    evaluator.onPreUpload(repository, null, null, null, null, null);
    evaluator.onPostUpload(null);
    verify(executor).execute(any(Runnable.class));
}
#method_after
@Test
public void onPostUploadShouldCreateTaskOnlyIfPreUploadCalled() {
    evaluator.onPreUpload(repository, null, null, null, null, null);
    evaluator.onPostUpload(null);
    verify(executor).execute(task);
}
#end_block

#method_before
@Test
public void onPostUploadShouldNotCreateTaskIfRepositoryIsNull() {
    File fileMock = mock(File.class);
    when(fileMock.getAbsolutePath()).thenReturn(null);
    when(repository.getDirectory()).thenReturn(fileMock);
    evaluator.onPreUpload(repository, null, null, null, null, null);
    evaluator.onPostUpload(null);
    verify(executor, never()).execute(any(Runnable.class));
}
#method_after
@Test
public void onPostUploadShouldNotCreateTaskIfRepositoryIsNull() {
    File fileMock = mock(File.class);
    when(fileMock.getAbsolutePath()).thenReturn(null);
    when(repository.getDirectory()).thenReturn(fileMock);
    evaluator.onPreUpload(repository, null, null, null, null, null);
    evaluator.onPostUpload(null);
    verify(executor, never()).execute(task);
}
#end_block

#method_before
@Test
public void onPostUploadShouldNotCreateTaskRepoIsNull() {
    evaluator.onPreUpload(repository, null, null, null, null, null);
    evaluator.onPostUpload(null);
    evaluator.onPostUpload(null);
    verify(executor, times(1)).execute(any(Runnable.class));
}
#method_after
@Test
public void onPostUploadShouldNotCreateTaskRepoIsNull() {
    evaluator.onPreUpload(repository, null, null, null, null, null);
    evaluator.onPostUpload(null);
    evaluator.onPostUpload(null);
    verify(executor, times(1)).execute(task);
}
#end_block

#method_before
@Test
public void onPostUploadShouldCreateTaskExpired() {
    evaluator.onPreUpload(repository, null, null, null, null, null);
    evaluator.onPostUpload(null);
    evaluator.onPreUpload(repository, null, null, null, null, null);
    evaluator.onPostUpload(null);
    verify(executor, times(2)).execute(any(Runnable.class));
}
#method_after
@Test
public void onPostUploadShouldCreateTaskExpired() {
    evaluator.onPreUpload(repository, null, null, null, null, null);
    evaluator.onPostUpload(null);
    evaluator.onPreUpload(repository, null, null, null, null, null);
    evaluator.onPostUpload(null);
    verify(executor, times(2)).execute(task);
}
#end_block

#method_before
@Test
public void onPostUploadShouldNotCreateTaskNotExpired() {
    when(config.getExpireTimeRecheck()).thenReturn(1000L);
    Factory eventTaskFactory = mock(Factory.class);
    when(eventTaskFactory.create(REPOSITORY_PATH)).thenReturn(task);
    evaluator = new Evaluator(executor, eventTaskFactory, repoManager, config, gerritConfig);
    evaluator.onPreUpload(repository, null, null, null, null, null);
    evaluator.onPostUpload(null);
    evaluator.onPreUpload(repository, null, null, null, null, null);
    evaluator.onPostUpload(null);
    verify(executor, times(1)).execute(any(Runnable.class));
}
#method_after
@Test
public void onPostUploadShouldNotCreateTaskNotExpired() {
    when(config.getExpireTimeRecheck()).thenReturn(1000L);
    Factory eventTaskFactory = mock(Factory.class);
    when(eventTaskFactory.create(REPOSITORY_PATH)).thenReturn(task);
    evaluator = new Evaluator(executor, eventTaskFactory, repoManager, config, gerritConfig);
    evaluator.onPreUpload(repository, null, null, null, null, null);
    evaluator.onPostUpload(null);
    evaluator.onPreUpload(repository, null, null, null, null, null);
    evaluator.onPostUpload(null);
    verify(executor, times(1)).execute(task);
}
#end_block

#method_before
@Test
public void onGitReferenceUpdatedShouldCreateTaskExpired() throws Exception {
    when(repoManager.openRepository(NAME_KEY)).thenReturn(repository);
    evaluator.onGitReferenceUpdated(event);
    evaluator.onGitReferenceUpdated(event);
    verify(executor, times(2)).execute(any(Runnable.class));
}
#method_after
@Test
public void onGitReferenceUpdatedShouldCreateTaskExpired() throws Exception {
    when(repoManager.openRepository(NAME_KEY)).thenReturn(repository);
    evaluator.onGitReferenceUpdated(event);
    evaluator.onGitReferenceUpdated(event);
    verify(executor, times(2)).execute(task);
}
#end_block

#method_before
@Test
public void onGitReferenceUpdatedShouldNotCreateTaskNotExpired() throws Exception {
    when(repoManager.openRepository(NAME_KEY)).thenReturn(repository);
    when(config.getExpireTimeRecheck()).thenReturn(1000L);
    Factory eventTaskFactory = mock(Factory.class);
    when(eventTaskFactory.create(REPOSITORY_PATH)).thenReturn(task);
    evaluator = new Evaluator(executor, eventTaskFactory, repoManager, config, gerritConfig);
    evaluator.onGitReferenceUpdated(event);
    evaluator.onGitReferenceUpdated(event);
    verify(executor, times(1)).execute(any(Runnable.class));
}
#method_after
@Test
public void onGitReferenceUpdatedShouldNotCreateTaskNotExpired() throws Exception {
    when(repoManager.openRepository(NAME_KEY)).thenReturn(repository);
    when(config.getExpireTimeRecheck()).thenReturn(1000L);
    Factory eventTaskFactory = mock(Factory.class);
    when(eventTaskFactory.create(REPOSITORY_PATH)).thenReturn(task);
    evaluator = new Evaluator(executor, eventTaskFactory, repoManager, config, gerritConfig);
    evaluator.onGitReferenceUpdated(event);
    evaluator.onGitReferenceUpdated(event);
    verify(executor, times(1)).execute(task);
}
#end_block

#method_before
@Test
public void onGitReferenceUpdatedThrowsRepositoryNotFoundException() throws Exception {
    doThrow(new RepositoryNotFoundException("")).when(repoManager).openRepository(NAME_KEY);
    evaluator.onGitReferenceUpdated(event);
    verify(executor, never()).execute(any(Runnable.class));
}
#method_after
@Test
public void onGitReferenceUpdatedThrowsRepositoryNotFoundException() throws Exception {
    doThrow(new RepositoryNotFoundException("")).when(repoManager).openRepository(NAME_KEY);
    evaluator.onGitReferenceUpdated(event);
    verify(executor, never()).execute(task);
}
#end_block

#method_before
@Test
public void onGitReferenceUpdatedThrowsIOException() throws Exception {
    doThrow(new IOException()).when(repoManager).openRepository(NAME_KEY);
    evaluator.onGitReferenceUpdated(event);
    verify(executor, never()).execute(any(Runnable.class));
}
#method_after
@Test
public void onGitReferenceUpdatedThrowsIOException() throws Exception {
    doThrow(new IOException()).when(repoManager).openRepository(NAME_KEY);
    evaluator.onGitReferenceUpdated(event);
    verify(executor, never()).execute(task);
}
#end_block

#method_before
public RevCommit merge(Repository repo, RevWalk rw, ObjectInserter ins, RevCommit merge, ThreeWayMergeStrategy mergeStrategy) throws IOException {
    checkArgument(rw.getObjectReader().getCreatedFromInserter() == ins);
    InMemoryInserter tmpIns = null;
    if (ins instanceof InMemoryInserter) {
        // Caller gave us an in-memory inserter, so ensure anything we write from
        // this method is visible to them.
        tmpIns = (InMemoryInserter) ins;
    } else if (!save) {
        // If we don't plan on saving results, use a fully in-memory inserter.
        // Using just a non-flushing wrapper is not sufficient, since in
        // particular DfsInserter might try to write to storage after exceeding an
        // internal buffer size.
        tmpIns = new InMemoryInserter(rw.getObjectReader());
    }
    rw.parseHeaders(merge);
    String refName = RefNames.refsCacheAutomerge(merge.name());
    Ref ref = repo.getRefDatabase().exactRef(refName);
    if (ref != null && ref.getObjectId() != null) {
        RevObject obj = rw.parseAny(ref.getObjectId());
        if (obj instanceof RevCommit) {
            return (RevCommit) obj;
        }
        return commit(repo, rw, tmpIns, ins, refName, obj, merge);
    }
    ResolveMerger m = (ResolveMerger) mergeStrategy.newMerger(repo, true);
    DirCache dc = DirCache.newInCore();
    m.setDirCache(dc);
    m.setObjectInserter(tmpIns == null ? new NonFlushingWrapper(ins) : tmpIns);
    boolean couldMerge;
    try {
        couldMerge = m.merge(merge.getParents());
    } catch (IOException | RuntimeException e) {
        // It is not safe to continue further down in this method as throwing
        // an exception most likely means that the merge tree was not created
        // and m.getMergeResults() is empty. This would mean that all paths are
        // unmerged and Gerrit UI would show all paths in the patch list.
        logger.atWarning().withCause(e).log("Error attempting automerge %s", refName);
        return null;
    }
    ObjectId treeId;
    if (couldMerge) {
        treeId = m.getResultTreeId();
    } else {
        treeId = autoMerge(rw, ins, dc, "HEAD", merge.getParent(0), "BRANCH", merge.getParent(1), m.getMergeResults());
    }
    return commit(repo, rw, tmpIns, ins, refName, treeId, merge);
}
#method_after
public RevCommit merge(Repository repo, RevWalk rw, ObjectInserter ins, RevCommit merge, ThreeWayMergeStrategy mergeStrategy) throws IOException {
    checkArgument(rw.getObjectReader().getCreatedFromInserter() == ins);
    InMemoryInserter tmpIns = null;
    if (ins instanceof InMemoryInserter) {
        // Caller gave us an in-memory inserter, so ensure anything we write from
        // this method is visible to them.
        tmpIns = (InMemoryInserter) ins;
    } else if (!save) {
        // If we don't plan on saving results, use a fully in-memory inserter.
        // Using just a non-flushing wrapper is not sufficient, since in
        // particular DfsInserter might try to write to storage after exceeding an
        // internal buffer size.
        tmpIns = new InMemoryInserter(rw.getObjectReader());
    }
    rw.parseHeaders(merge);
    String refName = RefNames.refsCacheAutomerge(merge.name());
    Ref ref = repo.getRefDatabase().exactRef(refName);
    if (ref != null && ref.getObjectId() != null) {
        RevObject obj = rw.parseAny(ref.getObjectId());
        if (obj instanceof RevCommit) {
            return (RevCommit) obj;
        }
        return commit(repo, rw, tmpIns, ins, refName, obj, merge);
    }
    ResolveMerger m = (ResolveMerger) mergeStrategy.newMerger(repo, true);
    DirCache dc = DirCache.newInCore();
    m.setDirCache(dc);
    m.setObjectInserter(tmpIns == null ? new NonFlushingWrapper(ins) : tmpIns);
    boolean couldMerge;
    try {
        couldMerge = m.merge(merge.getParents());
    } catch (IOException | RuntimeException e) {
        // It is not safe to continue further down in this method as throwing
        // an exception most likely means that the merge tree was not created
        // and m.getMergeResults() is empty. This would mean that all paths are
        // unmerged and Gerrit UI would show all paths in the patch list.
        logger.atWarning().withCause(e).log("Error attempting automerge %s", refName);
        return null;
    }
    ObjectId treeId;
    if (couldMerge) {
        treeId = m.getResultTreeId();
    } else {
        treeId = MergeUtil.mergeWithConflicts(rw, ins, dc, "HEAD", merge.getParent(0), "BRANCH", merge.getParent(1), m.getMergeResults());
    }
    return commit(repo, rw, tmpIns, ins, refName, treeId, merge);
}
#end_block

#method_before
public Change.Id cherryPick(BatchUpdate.Factory batchUpdateFactory, Change change, PatchSet patch, CherryPickInput input, Branch.NameKey dest) throws OrmException, IOException, InvalidChangeOperationException, IntegrationException, UpdateException, RestApiException, ConfigInvalidException, NoSuchProjectException {
    return cherryPick(batchUpdateFactory, change, patch.getId(), change.getProject(), ObjectId.fromString(patch.getRevision().get()), input, dest);
}
#method_after
public Result cherryPick(BatchUpdate.Factory batchUpdateFactory, Change change, PatchSet patch, CherryPickInput input, Branch.NameKey dest) throws OrmException, IOException, InvalidChangeOperationException, IntegrationException, UpdateException, RestApiException, ConfigInvalidException, NoSuchProjectException {
    return cherryPick(batchUpdateFactory, change, patch.getId(), change.getProject(), ObjectId.fromString(patch.getRevision().get()), input, dest);
}
#end_block

#method_before
public Change.Id cherryPick(BatchUpdate.Factory batchUpdateFactory, @Nullable Change sourceChange, @Nullable PatchSet.Id sourcePatchId, Project.NameKey project, ObjectId sourceCommit, CherryPickInput input, Branch.NameKey dest) throws OrmException, IOException, InvalidChangeOperationException, IntegrationException, UpdateException, RestApiException, ConfigInvalidException, NoSuchProjectException {
    IdentifiedUser identifiedUser = user.get();
    try (Repository git = gitManager.openRepository(project);
        // before patch sets are updated.
        ObjectInserter oi = git.newObjectInserter();
        ObjectReader reader = oi.newReader();
        CodeReviewRevWalk revWalk = CodeReviewCommit.newRevWalk(reader)) {
        Ref destRef = git.getRefDatabase().exactRef(dest.get());
        if (destRef == null) {
            throw new InvalidChangeOperationException(String.format("Branch %s does not exist.", dest.get()));
        }
        RevCommit baseCommit = getBaseCommit(destRef, project.get(), revWalk, input.base);
        CodeReviewCommit commitToCherryPick = revWalk.parseCommit(sourceCommit);
        if (input.parent <= 0 || input.parent > commitToCherryPick.getParentCount()) {
            throw new InvalidChangeOperationException(String.format("Cherry Pick: Parent %s does not exist. Please specify a parent in" + " range [1, %s].", input.parent, commitToCherryPick.getParentCount()));
        }
        Timestamp now = TimeUtil.nowTs();
        PersonIdent committerIdent = identifiedUser.newCommitterIdent(now, serverTimeZone);
        final ObjectId computedChangeId = ChangeIdUtil.computeChangeId(commitToCherryPick.getTree(), baseCommit, commitToCherryPick.getAuthorIdent(), committerIdent, input.message);
        String commitMessage = ChangeIdUtil.insertId(input.message, computedChangeId).trim() + '\n';
        CodeReviewCommit cherryPickCommit;
        ProjectState projectState = projectCache.checkedGet(dest.getParentKey());
        if (projectState == null) {
            throw new NoSuchProjectException(dest.getParentKey());
        }
        try {
            cherryPickCommit = mergeUtilFactory.create(projectState).createCherryPickFromCommit(oi, git.getConfig(), baseCommit, commitToCherryPick, committerIdent, commitMessage, revWalk, input.parent - 1, false, input.autoMerge);
            Change.Key changeKey;
            final List<String> idList = cherryPickCommit.getFooterLines(FooterConstants.CHANGE_ID);
            if (!idList.isEmpty()) {
                final String idStr = idList.get(idList.size() - 1).trim();
                changeKey = new Change.Key(idStr);
            } else {
                changeKey = new Change.Key("I" + computedChangeId.name());
            }
            Branch.NameKey newDest = new Branch.NameKey(project, destRef.getName());
            List<ChangeData> destChanges = queryProvider.get().setLimit(2).byBranchKey(newDest, changeKey);
            if (destChanges.size() > 1) {
                throw new InvalidChangeOperationException("Several changes with key " + changeKey + " reside on the same branch. " + "Cannot create a new patch set.");
            }
            try (BatchUpdate bu = batchUpdateFactory.create(dbProvider.get(), project, identifiedUser, now)) {
                bu.setRepository(git, revWalk, oi);
                Change.Id result;
                if (destChanges.size() == 1) {
                    // The change key exists on the destination branch. The cherry pick
                    // will be added as a new patch set.
                    result = insertPatchSet(bu, git, destChanges.get(0).notes(), cherryPickCommit, input);
                } else {
                    // Change key not found on destination branch. We can create a new
                    // change.
                    String newTopic = null;
                    if (sourceChange != null && !Strings.isNullOrEmpty(sourceChange.getTopic())) {
                        newTopic = sourceChange.getTopic() + "-" + newDest.getShortName();
                    }
                    result = createNewChange(bu, cherryPickCommit, dest.get(), newTopic, sourceChange, sourceCommit, input);
                    if (sourceChange != null && sourcePatchId != null) {
                        bu.addOp(sourceChange.getId(), new AddMessageToSourceChangeOp(changeMessagesUtil, sourcePatchId, dest.getShortName(), cherryPickCommit));
                    }
                }
                bu.execute();
                return result;
            }
        } catch (MergeIdenticalTreeException | MergeConflictException e) {
            throw new IntegrationException("Cherry pick failed: " + e.getMessage());
        }
    }
}
#method_after
public Result cherryPick(BatchUpdate.Factory batchUpdateFactory, @Nullable Change sourceChange, @Nullable PatchSet.Id sourcePatchId, Project.NameKey project, ObjectId sourceCommit, CherryPickInput input, Branch.NameKey dest) throws OrmException, IOException, InvalidChangeOperationException, IntegrationException, UpdateException, RestApiException, ConfigInvalidException, NoSuchProjectException {
    IdentifiedUser identifiedUser = user.get();
    try (Repository git = gitManager.openRepository(project);
        // before patch sets are updated.
        ObjectInserter oi = git.newObjectInserter();
        ObjectReader reader = oi.newReader();
        CodeReviewRevWalk revWalk = CodeReviewCommit.newRevWalk(reader)) {
        Ref destRef = git.getRefDatabase().exactRef(dest.get());
        if (destRef == null) {
            throw new InvalidChangeOperationException(String.format("Branch %s does not exist.", dest.get()));
        }
        RevCommit baseCommit = getBaseCommit(destRef, project.get(), revWalk, input.base);
        CodeReviewCommit commitToCherryPick = revWalk.parseCommit(sourceCommit);
        if (input.parent <= 0 || input.parent > commitToCherryPick.getParentCount()) {
            throw new InvalidChangeOperationException(String.format("Cherry Pick: Parent %s does not exist. Please specify a parent in" + " range [1, %s].", input.parent, commitToCherryPick.getParentCount()));
        }
        Timestamp now = TimeUtil.nowTs();
        PersonIdent committerIdent = identifiedUser.newCommitterIdent(now, serverTimeZone);
        final ObjectId computedChangeId = ChangeIdUtil.computeChangeId(commitToCherryPick.getTree(), baseCommit, commitToCherryPick.getAuthorIdent(), committerIdent, input.message);
        String commitMessage = ChangeIdUtil.insertId(input.message, computedChangeId).trim() + '\n';
        CodeReviewCommit cherryPickCommit;
        ProjectState projectState = projectCache.checkedGet(dest.getParentKey());
        if (projectState == null) {
            throw new NoSuchProjectException(dest.getParentKey());
        }
        try {
            MergeUtil mergeUtil;
            if (input.allowConflicts) {
                // allowConflicts requires to use content merge
                mergeUtil = mergeUtilFactory.create(projectState, true);
            } else {
                // use content merge only if it's configured on the project
                mergeUtil = mergeUtilFactory.create(projectState);
            }
            cherryPickCommit = mergeUtil.createCherryPickFromCommit(oi, git.getConfig(), baseCommit, commitToCherryPick, committerIdent, commitMessage, revWalk, input.parent - 1, false, input.allowConflicts);
            Change.Key changeKey;
            final List<String> idList = cherryPickCommit.getFooterLines(FooterConstants.CHANGE_ID);
            if (!idList.isEmpty()) {
                final String idStr = idList.get(idList.size() - 1).trim();
                changeKey = new Change.Key(idStr);
            } else {
                changeKey = new Change.Key("I" + computedChangeId.name());
            }
            Branch.NameKey newDest = new Branch.NameKey(project, destRef.getName());
            List<ChangeData> destChanges = queryProvider.get().setLimit(2).byBranchKey(newDest, changeKey);
            if (destChanges.size() > 1) {
                throw new InvalidChangeOperationException("Several changes with key " + changeKey + " reside on the same branch. " + "Cannot create a new patch set.");
            }
            try (BatchUpdate bu = batchUpdateFactory.create(dbProvider.get(), project, identifiedUser, now)) {
                bu.setRepository(git, revWalk, oi);
                Change.Id changeId;
                if (destChanges.size() == 1) {
                    // The change key exists on the destination branch. The cherry pick
                    // will be added as a new patch set.
                    changeId = insertPatchSet(bu, git, destChanges.get(0).notes(), cherryPickCommit, input);
                } else {
                    // Change key not found on destination branch. We can create a new
                    // change.
                    String newTopic = null;
                    if (sourceChange != null && !Strings.isNullOrEmpty(sourceChange.getTopic())) {
                        newTopic = sourceChange.getTopic() + "-" + newDest.getShortName();
                    }
                    changeId = createNewChange(bu, cherryPickCommit, dest.get(), newTopic, sourceChange, sourceCommit, input);
                    if (sourceChange != null && sourcePatchId != null) {
                        bu.addOp(sourceChange.getId(), new AddMessageToSourceChangeOp(changeMessagesUtil, sourcePatchId, dest.getShortName(), cherryPickCommit));
                    }
                }
                bu.execute();
                return Result.create(changeId, cherryPickCommit.containsGitConflicts());
            }
        } catch (MergeIdenticalTreeException | MergeConflictException e) {
            throw new IntegrationException("Cherry pick failed: " + e.getMessage());
        }
    }
}
#end_block

#method_before
@Override
protected void updateRepoImpl(RepoContext ctx) throws IntegrationException, IOException, OrmException {
    // If there is only one parent, a cherry-pick can be done by taking the
    // delta relative to that one parent and redoing that on the current merge
    // tip.
    args.rw.parseBody(toMerge);
    psId = ChangeUtil.nextPatchSetIdFromChangeRefsMap(ctx.getRepoView().getRefs(getId().toRefPrefix()), toMerge.change().currentPatchSetId());
    RevCommit mergeTip = args.mergeTip.getCurrentTip();
    args.rw.parseBody(mergeTip);
    String cherryPickCmtMsg = args.mergeUtil.createCommitMessageOnSubmit(toMerge, mergeTip);
    PersonIdent committer = args.caller.newCommitterIdent(ctx.getWhen(), args.serverIdent.getTimeZone());
    try {
        newCommit = args.mergeUtil.createCherryPickFromCommit(ctx.getInserter(), ctx.getRepoView().getConfig(), args.mergeTip.getCurrentTip(), toMerge, committer, cherryPickCmtMsg, args.rw, 0, false, false);
    } catch (MergeConflictException mce) {
        // Keep going in the case of a single merge failure; the goal is to
        // cherry-pick as many commits as possible.
        toMerge.setStatusCode(CommitMergeStatus.PATH_CONFLICT);
        return;
    } catch (MergeIdenticalTreeException mie) {
        if (args.project.is(BooleanProjectConfig.REJECT_EMPTY_COMMIT)) {
            toMerge.setStatusCode(EMPTY_COMMIT);
            return;
        }
        toMerge.setStatusCode(SKIPPED_IDENTICAL_TREE);
        return;
    }
    // Initial copy doesn't have new patch set ID since change hasn't been
    // updated yet.
    newCommit = amendGitlink(newCommit);
    newCommit.copyFrom(toMerge);
    newCommit.setPatchsetId(psId);
    newCommit.setStatusCode(CommitMergeStatus.CLEAN_PICK);
    args.mergeTip.moveTipTo(newCommit, newCommit);
    args.commitStatus.put(newCommit);
    ctx.addRefUpdate(ObjectId.zeroId(), newCommit, psId.toRefName());
    patchSetInfo = args.patchSetInfoFactory.get(ctx.getRevWalk(), newCommit, psId);
}
#method_after
@Override
protected void updateRepoImpl(RepoContext ctx) throws IntegrationException, IOException, OrmException, MethodNotAllowedException {
    // If there is only one parent, a cherry-pick can be done by taking the
    // delta relative to that one parent and redoing that on the current merge
    // tip.
    args.rw.parseBody(toMerge);
    psId = ChangeUtil.nextPatchSetIdFromChangeRefsMap(ctx.getRepoView().getRefs(getId().toRefPrefix()), toMerge.change().currentPatchSetId());
    RevCommit mergeTip = args.mergeTip.getCurrentTip();
    args.rw.parseBody(mergeTip);
    String cherryPickCmtMsg = args.mergeUtil.createCommitMessageOnSubmit(toMerge, mergeTip);
    PersonIdent committer = args.caller.newCommitterIdent(ctx.getWhen(), args.serverIdent.getTimeZone());
    try {
        newCommit = args.mergeUtil.createCherryPickFromCommit(ctx.getInserter(), ctx.getRepoView().getConfig(), args.mergeTip.getCurrentTip(), toMerge, committer, cherryPickCmtMsg, args.rw, 0, false, false);
    } catch (MergeConflictException mce) {
        // Keep going in the case of a single merge failure; the goal is to
        // cherry-pick as many commits as possible.
        toMerge.setStatusCode(CommitMergeStatus.PATH_CONFLICT);
        return;
    } catch (MergeIdenticalTreeException mie) {
        if (args.project.is(BooleanProjectConfig.REJECT_EMPTY_COMMIT)) {
            toMerge.setStatusCode(EMPTY_COMMIT);
            return;
        }
        toMerge.setStatusCode(SKIPPED_IDENTICAL_TREE);
        return;
    }
    // Initial copy doesn't have new patch set ID since change hasn't been
    // updated yet.
    newCommit = amendGitlink(newCommit);
    newCommit.copyFrom(toMerge);
    newCommit.setPatchsetId(psId);
    newCommit.setStatusCode(CommitMergeStatus.CLEAN_PICK);
    args.mergeTip.moveTipTo(newCommit, newCommit);
    args.commitStatus.put(newCommit);
    ctx.addRefUpdate(ObjectId.zeroId(), newCommit, psId.toRefName());
    patchSetInfo = args.patchSetInfoFactory.get(ctx.getRevWalk(), newCommit, psId);
}
#end_block

#method_before
public CodeReviewCommit createCherryPickFromCommit(ObjectInserter inserter, Config repoConfig, RevCommit mergeTip, RevCommit originalCommit, PersonIdent cherryPickCommitterIdent, String commitMsg, CodeReviewRevWalk rw, int parentIndex, boolean ignoreIdenticalTree, boolean autoMerge) throws MissingObjectException, IncorrectObjectTypeException, IOException, MergeIdenticalTreeException, MergeConflictException {
    ThreeWayMerger m = newThreeWayMerger(inserter, repoConfig);
    m.setBase(originalCommit.getParent(parentIndex));
    DirCache dc = DirCache.newInCore();
    if (autoMerge && m instanceof ResolveMerger) {
        ((ResolveMerger) m).setDirCache(dc);
    }
    ObjectId tree;
    if (m.merge(mergeTip, originalCommit)) {
        tree = m.getResultTreeId();
        if (tree.equals(mergeTip.getTree()) && !ignoreIdenticalTree) {
            throw new MergeIdenticalTreeException("identical tree");
        }
    } else {
        if (!autoMerge) {
            throw new MergeConflictException("merge conflict");
        }
        // For auto merge we need a ResolveMerger, double-check that we have one.
        checkState(m instanceof ResolveMerger, "auto merge is not supported");
        tree = AutoMerger.autoMerge(rw, inserter, dc, "HEAD", mergeTip, "CHANGE", originalCommit, ((ResolveMerger) m).getMergeResults());
    }
    CommitBuilder cherryPickCommit = new CommitBuilder();
    cherryPickCommit.setTreeId(tree);
    cherryPickCommit.setParentId(mergeTip);
    cherryPickCommit.setAuthor(originalCommit.getAuthorIdent());
    cherryPickCommit.setCommitter(cherryPickCommitterIdent);
    cherryPickCommit.setMessage(commitMsg);
    matchAuthorToCommitterDate(project, cherryPickCommit);
    return rw.parseCommit(inserter.insert(cherryPickCommit));
}
#method_after
public CodeReviewCommit createCherryPickFromCommit(ObjectInserter inserter, Config repoConfig, RevCommit mergeTip, RevCommit originalCommit, PersonIdent cherryPickCommitterIdent, String commitMsg, CodeReviewRevWalk rw, int parentIndex, boolean ignoreIdenticalTree, boolean allowConflicts) throws MissingObjectException, IncorrectObjectTypeException, IOException, MergeIdenticalTreeException, MergeConflictException, MethodNotAllowedException {
    ThreeWayMerger m = newThreeWayMerger(inserter, repoConfig);
    m.setBase(originalCommit.getParent(parentIndex));
    DirCache dc = DirCache.newInCore();
    if (allowConflicts && m instanceof ResolveMerger) {
        // The DirCache must be set on ResolveMerger before calling
        // ResolveMerger#merge(AnyObjectId...) otherwise the entries in DirCache don't get populated.
        ((ResolveMerger) m).setDirCache(dc);
    }
    ObjectId tree;
    boolean containsGitConflicts;
    if (m.merge(mergeTip, originalCommit)) {
        containsGitConflicts = false;
        tree = m.getResultTreeId();
        if (tree.equals(mergeTip.getTree()) && !ignoreIdenticalTree) {
            throw new MergeIdenticalTreeException("identical tree");
        }
    } else {
        if (!allowConflicts) {
            throw new MergeConflictException("merge conflict");
        }
        if (!useContentMerge) {
            // conflict markers.
            throw new MethodNotAllowedException("Cherry-pick with allow conflicts requires that content merge is enabled.");
        }
        // For merging with conflict markers we need a ResolveMerger, double-check that we have one.
        checkState(m instanceof ResolveMerger, "allow conflicts is not supported");
        containsGitConflicts = true;
        tree = mergeWithConflicts(rw, inserter, dc, "HEAD", mergeTip, "CHANGE", originalCommit, ((ResolveMerger) m).getMergeResults());
    }
    CommitBuilder cherryPickCommit = new CommitBuilder();
    cherryPickCommit.setTreeId(tree);
    cherryPickCommit.setParentId(mergeTip);
    cherryPickCommit.setAuthor(originalCommit.getAuthorIdent());
    cherryPickCommit.setCommitter(cherryPickCommitterIdent);
    cherryPickCommit.setMessage(commitMsg);
    matchAuthorToCommitterDate(project, cherryPickCommit);
    CodeReviewCommit commit = rw.parseCommit(inserter.insert(cherryPickCommit));
    commit.setContainsGitConflicts(containsGitConflicts);
    return commit;
}
#end_block

#method_before
@Test
public void cherryPick() throws Exception {
    PushOneCommit.Result r = pushTo("refs/for/master%topic=someTopic");
    CherryPickInput in = new CherryPickInput();
    in.destination = "foo";
    in.message = "it goes to stable branch";
    gApi.projects().name(project.get()).branch(in.destination).create(new BranchInput());
    ChangeApi orig = gApi.changes().id(project.get() + "~master~" + r.getChangeId());
    assertThat(orig.get().messages).hasSize(1);
    ChangeApi cherry = orig.revision(r.getCommit().name()).cherryPick(in);
    Collection<ChangeMessageInfo> messages = gApi.changes().id(project.get() + "~master~" + r.getChangeId()).get().messages;
    assertThat(messages).hasSize(2);
    String cherryPickedRevision = cherry.get().currentRevision;
    String expectedMessage = String.format("Patch Set 1: Cherry Picked\n\n" + "This patchset was cherry picked to branch %s as commit %s", in.destination, cherryPickedRevision);
    Iterator<ChangeMessageInfo> origIt = messages.iterator();
    origIt.next();
    assertThat(origIt.next().message).isEqualTo(expectedMessage);
    assertThat(cherry.get().messages).hasSize(1);
    Iterator<ChangeMessageInfo> cherryIt = cherry.get().messages.iterator();
    expectedMessage = "Patch Set 1: Cherry Picked from branch master.";
    assertThat(cherryIt.next().message).isEqualTo(expectedMessage);
    assertThat(cherry.get().subject).contains(in.message);
    assertThat(cherry.get().topic).isEqualTo("someTopic-foo");
    cherry.current().review(ReviewInput.approve());
    cherry.current().submit();
}
#method_after
@Test
public void cherryPick() throws Exception {
    PushOneCommit.Result r = pushTo("refs/for/master%topic=someTopic");
    CherryPickInput in = new CherryPickInput();
    in.destination = "foo";
    in.message = "it goes to stable branch";
    gApi.projects().name(project.get()).branch(in.destination).create(new BranchInput());
    ChangeApi orig = gApi.changes().id(project.get() + "~master~" + r.getChangeId());
    assertThat(orig.get().messages).hasSize(1);
    CherryPickChangeInfo changeInfo = orig.revision(r.getCommit().name()).cherryPickAsInfo(in);
    assertThat(changeInfo.containsGitConflicts).isNull();
    ChangeApi cherry = gApi.changes().id(changeInfo._number);
    Collection<ChangeMessageInfo> messages = gApi.changes().id(project.get() + "~master~" + r.getChangeId()).get().messages;
    assertThat(messages).hasSize(2);
    String cherryPickedRevision = cherry.get().currentRevision;
    String expectedMessage = String.format("Patch Set 1: Cherry Picked\n\n" + "This patchset was cherry picked to branch %s as commit %s", in.destination, cherryPickedRevision);
    Iterator<ChangeMessageInfo> origIt = messages.iterator();
    origIt.next();
    assertThat(origIt.next().message).isEqualTo(expectedMessage);
    assertThat(cherry.get().messages).hasSize(1);
    Iterator<ChangeMessageInfo> cherryIt = cherry.get().messages.iterator();
    expectedMessage = "Patch Set 1: Cherry Picked from branch master.";
    assertThat(cherryIt.next().message).isEqualTo(expectedMessage);
    assertThat(cherry.get().subject).contains(in.message);
    assertThat(cherry.get().topic).isEqualTo("someTopic-foo");
    cherry.current().review(ReviewInput.approve());
    cherry.current().submit();
}
#end_block

#method_before
private void insertChangesAndPatchSets(List<CreateRequest> newChanges, Task replaceProgress) {
    ReceiveCommand magicBranchCmd = magicBranch != null ? magicBranch.cmd : null;
    if (magicBranchCmd != null && magicBranchCmd.getResult() != NOT_ATTEMPTED) {
        logger.atWarning().log("Skipping change updates on %s because ref update failed: %s %s", project.getName(), magicBranchCmd.getResult(), Strings.nullToEmpty(magicBranchCmd.getMessage()));
        return;
    }
    try (BatchUpdate bu = batchUpdateFactory.create(db, project.getNameKey(), user.materializedCopy(), TimeUtil.nowTs());
        ObjectInserter ins = repo.newObjectInserter();
        ObjectReader reader = ins.newReader();
        RevWalk rw = new RevWalk(reader)) {
        bu.setRepository(repo, rw, ins).updateChangesInParallel();
        bu.setRefLogMessage("push");
        logger.atFine().log("Adding %d replace requests", newChanges.size());
        for (ReplaceRequest replace : replaceByChange.values()) {
            replace.addOps(bu, replaceProgress);
        }
        logger.atFine().log("Adding %d create requests", newChanges.size());
        for (CreateRequest create : newChanges) {
            create.addOps(bu);
        }
        logger.atFine().log("Adding %d group update requests", newChanges.size());
        updateGroups.forEach(r -> r.addOps(bu));
        logger.atFine().log("Executing batch");
        try {
            bu.execute();
        } catch (UpdateException e) {
            throw INSERT_EXCEPTION.apply(e);
        }
        for (ReplaceRequest replace : replaceByChange.values()) {
            resultChangeIds.add(Key.REPLACED, replace.ontoChange);
        }
        for (CreateRequest create : newChanges) {
            resultChangeIds.add(Key.CREATED, create.changeId);
        }
        if (magicBranchCmd != null) {
            magicBranchCmd.setResult(OK);
        }
        for (ReplaceRequest replace : replaceByChange.values()) {
            String rejectMessage = replace.getRejectMessage();
            if (rejectMessage == null) {
                if (replace.inputCommand.getResult() == NOT_ATTEMPTED) {
                    // Not necessarily the magic branch, so need to set OK on the original value.
                    replace.inputCommand.setResult(OK);
                }
            } else {
                logger.atFine().log("Rejecting due to message from ReplaceOp");
                reject(replace.inputCommand, rejectMessage);
            }
        }
    } catch (ResourceConflictException e) {
        addError(e.getMessage());
        reject(magicBranchCmd, "conflict");
    } catch (RestApiException | IOException err) {
        logger.atSevere().withCause(err).log("Can't insert change/patch set for %s", project.getName());
        reject(magicBranchCmd, "internal server error: " + err.getMessage());
    }
    if (magicBranch != null && magicBranch.submit) {
        try {
            submit(newChanges, replaceByChange.values());
        } catch (ResourceConflictException e) {
            addError(e.getMessage());
            reject(magicBranchCmd, "conflict");
        } catch (RestApiException | OrmException | UpdateException | IOException | ConfigInvalidException | PermissionBackendException e) {
            logger.atSevere().withCause(e).log("Error submitting changes to %s", project.getName());
            reject(magicBranchCmd, "error during submit");
        }
    }
}
#method_after
private void insertChangesAndPatchSets(List<CreateRequest> newChanges, Task replaceProgress) {
    ReceiveCommand magicBranchCmd = magicBranch != null ? magicBranch.cmd : null;
    if (magicBranchCmd != null && magicBranchCmd.getResult() != NOT_ATTEMPTED) {
        logger.atWarning().log("Skipping change updates on %s because ref update failed: %s %s", project.getName(), magicBranchCmd.getResult(), Strings.nullToEmpty(magicBranchCmd.getMessage()));
        return;
    }
    try (BatchUpdate bu = batchUpdateFactory.create(db, project.getNameKey(), user.materializedCopy(), TimeUtil.nowTs());
        ObjectInserter ins = repo.newObjectInserter();
        ObjectReader reader = ins.newReader();
        RevWalk rw = new RevWalk(reader)) {
        bu.setRepository(repo, rw, ins).updateChangesInParallel();
        bu.setRefLogMessage("push");
        logger.atFine().log("Adding %d replace requests", newChanges.size());
        for (ReplaceRequest replace : replaceByChange.values()) {
            replace.addOps(bu, replaceProgress);
        }
        logger.atFine().log("Adding %d create requests", newChanges.size());
        for (CreateRequest create : newChanges) {
            create.addOps(bu);
        }
        logger.atFine().log("Adding %d group update requests", newChanges.size());
        updateGroups.forEach(r -> r.addOps(bu));
        logger.atFine().log("Executing batch");
        try {
            bu.execute();
        } catch (UpdateException e) {
            throw INSERT_EXCEPTION.apply(e);
        }
        replaceByChange.values().stream().forEach(req -> resultChangeIds.add(Key.REPLACED, req.ontoChange));
        newChanges.stream().forEach(req -> resultChangeIds.add(Key.CREATED, req.changeId));
        if (magicBranchCmd != null) {
            magicBranchCmd.setResult(OK);
        }
        for (ReplaceRequest replace : replaceByChange.values()) {
            String rejectMessage = replace.getRejectMessage();
            if (rejectMessage == null) {
                if (replace.inputCommand.getResult() == NOT_ATTEMPTED) {
                    // Not necessarily the magic branch, so need to set OK on the original value.
                    replace.inputCommand.setResult(OK);
                }
            } else {
                logger.atFine().log("Rejecting due to message from ReplaceOp");
                reject(replace.inputCommand, rejectMessage);
            }
        }
    } catch (ResourceConflictException e) {
        addError(e.getMessage());
        reject(magicBranchCmd, "conflict");
    } catch (RestApiException | IOException err) {
        logger.atSevere().withCause(err).log("Can't insert change/patch set for %s", project.getName());
        reject(magicBranchCmd, "internal server error: " + err.getMessage());
    }
    if (magicBranch != null && magicBranch.submit) {
        try {
            submit(newChanges, replaceByChange.values());
        } catch (ResourceConflictException e) {
            addError(e.getMessage());
            reject(magicBranchCmd, "conflict");
        } catch (RestApiException | OrmException | UpdateException | IOException | ConfigInvalidException | PermissionBackendException e) {
            logger.atSevere().withCause(e).log("Error submitting changes to %s", project.getName());
            reject(magicBranchCmd, "error during submit");
        }
    }
}
#end_block

#method_before
@Option(name = "--reviewer", aliases = { "-r" }, metaVar = "EMAIL", usage = "add reviewer to changes")
void reviewer(Account.Id id) {
    reviewer.add(id);
}
#method_after
@Option(name = "--reviewer", aliases = { "-r" }, metaVar = "USER", usage = "add reviewer to changes")
void reviewer(Account.Id id) {
    reviewer.add(id);
}
#end_block

#method_before
@Option(name = "--cc", metaVar = "EMAIL", usage = "notify user by CC")
void cc(Account.Id id) {
    cc.add(id);
}
#method_after
@Option(name = "--cc", metaVar = "USER", usage = "add user as CC to changes")
void cc(Account.Id id) {
    cc.add(id);
}
#end_block

#method_before
ListMultimap<RecipientType, Account.Id> getAccountsToNotify() {
    ListMultimap<RecipientType, Account.Id> accountsToNotify = MultimapBuilder.hashKeys().arrayListValues().build();
    accountsToNotify.putAll(RecipientType.TO, tos);
    accountsToNotify.putAll(RecipientType.CC, ccs);
    accountsToNotify.putAll(RecipientType.BCC, bccs);
    return accountsToNotify;
}
#method_after
ListMultimap<RecipientType, Account.Id> getAccountsToNotify() {
    ListMultimap<RecipientType, Account.Id> accountsToNotify = MultimapBuilder.hashKeys().arrayListValues().build();
    accountsToNotify.putAll(RecipientType.TO, notifyTo);
    accountsToNotify.putAll(RecipientType.CC, notifyCc);
    accountsToNotify.putAll(RecipientType.BCC, notifyBcc);
    return accountsToNotify;
}
#end_block

#method_before
private void autoCloseChanges(ReceiveCommand cmd, Task progress) {
    logger.atFine().log("Starting auto-closing of changes");
    String refName = cmd.getRefName();
    Set<Change.Id> ids = new TreeSet<>();
    // handleRegularCommands
    try {
        retryHelper.execute(updateFactory -> {
            try (BatchUpdate bu = updateFactory.create(db, projectState.getNameKey(), user, TimeUtil.nowTs());
                ObjectInserter ins = repo.newObjectInserter();
                ObjectReader reader = ins.newReader();
                RevWalk rw = new RevWalk(reader)) {
                bu.setRepository(repo, rw, ins).updateChangesInParallel();
                // TODO(dborowitz): Teach BatchUpdate to ignore missing changes.
                RevCommit newTip = rw.parseCommit(cmd.getNewId());
                Branch.NameKey branch = new Branch.NameKey(project.getNameKey(), refName);
                rw.reset();
                rw.markStart(newTip);
                if (!ObjectId.zeroId().equals(cmd.getOldId())) {
                    rw.markUninteresting(rw.parseCommit(cmd.getOldId()));
                }
                ListMultimap<ObjectId, Ref> byCommit = changeRefsById();
                Map<Change.Key, ChangeNotes> byKey = null;
                List<ReplaceRequest> replaceAndClose = new ArrayList<>();
                int existingPatchSets = 0;
                int newPatchSets = 0;
                COMMIT: for (RevCommit c; (c = rw.next()) != null; ) {
                    rw.parseBody(c);
                    for (Ref ref : byCommit.get(c.copy())) {
                        PatchSet.Id psId = PatchSet.Id.fromRef(ref.getName());
                        Optional<ChangeNotes> notes = getChangeNotes(psId.getParentKey());
                        if (notes.isPresent() && notes.get().getChange().getDest().equals(branch)) {
                            existingPatchSets++;
                            bu.addOp(psId.getParentKey(), mergedByPushOpFactory.create(requestScopePropagator, psId, refName));
                            continue COMMIT;
                        }
                    }
                    for (String changeId : c.getFooterLines(CHANGE_ID)) {
                        if (byKey == null) {
                            byKey = executeIndexQuery(() -> openChangesByKeyByBranch(branch));
                        }
                        ChangeNotes onto = byKey.get(new Change.Key(changeId.trim()));
                        if (onto != null) {
                            newPatchSets++;
                            // Hold onto this until we're done with the walk, as the call to
                            // req.validate below calls isMergedInto which resets the walk.
                            ReplaceRequest req = new ReplaceRequest(onto.getChangeId(), c, cmd, false);
                            req.notes = onto;
                            replaceAndClose.add(req);
                            continue COMMIT;
                        }
                    }
                }
                for (ReplaceRequest req : replaceAndClose) {
                    Change.Id id = req.notes.getChangeId();
                    if (!req.validateNewPatchSetForAutoClose()) {
                        logger.atFine().log("Not closing %s because validation failed", id);
                        continue;
                    }
                    req.addOps(bu, null);
                    bu.addOp(id, mergedByPushOpFactory.create(requestScopePropagator, req.psId, refName).setPatchSetProvider(req.replaceOp::getPatchSet));
                    bu.addOp(id, new ChangeProgressOp(progress));
                    ids.add(id);
                }
                logger.atFine().log("Auto-closing %s changes with existing patch sets and %s with new patch sets", existingPatchSets, newPatchSets);
                bu.execute();
            } catch (IOException | OrmException | PermissionBackendException e) {
                logger.atSevere().withCause(e).log("Failed to auto-close changes");
                return null;
            }
            // If we are here, we didn't throw UpdateException. Record the result.
            for (Change.Id id : ids) {
                resultChangeIds.add(Key.AUTOCLOSED, id);
            }
            return null;
        }, // eat up the whole timeout so that no time is left to retry this outer action.
        RetryHelper.options().timeout(retryHelper.getDefaultTimeout(ActionType.CHANGE_UPDATE).multipliedBy(5)).build());
    } catch (RestApiException e) {
        logger.atSevere().withCause(e).log("Can't insert patchset");
    } catch (UpdateException e) {
        logger.atSevere().withCause(e).log("Failed to auto-close changes");
    }
}
#method_after
private void autoCloseChanges(ReceiveCommand cmd, Task progress) {
    logger.atFine().log("Starting auto-closing of changes");
    String refName = cmd.getRefName();
    Set<Change.Id> ids = new HashSet<>();
    // handleRegularCommands
    try {
        retryHelper.execute(updateFactory -> {
            try (BatchUpdate bu = updateFactory.create(db, projectState.getNameKey(), user, TimeUtil.nowTs());
                ObjectInserter ins = repo.newObjectInserter();
                ObjectReader reader = ins.newReader();
                RevWalk rw = new RevWalk(reader)) {
                bu.setRepository(repo, rw, ins).updateChangesInParallel();
                // TODO(dborowitz): Teach BatchUpdate to ignore missing changes.
                RevCommit newTip = rw.parseCommit(cmd.getNewId());
                Branch.NameKey branch = new Branch.NameKey(project.getNameKey(), refName);
                rw.reset();
                rw.markStart(newTip);
                if (!ObjectId.zeroId().equals(cmd.getOldId())) {
                    rw.markUninteresting(rw.parseCommit(cmd.getOldId()));
                }
                ListMultimap<ObjectId, Ref> byCommit = changeRefsById();
                Map<Change.Key, ChangeNotes> byKey = null;
                List<ReplaceRequest> replaceAndClose = new ArrayList<>();
                int existingPatchSets = 0;
                int newPatchSets = 0;
                COMMIT: for (RevCommit c; (c = rw.next()) != null; ) {
                    rw.parseBody(c);
                    for (Ref ref : byCommit.get(c.copy())) {
                        PatchSet.Id psId = PatchSet.Id.fromRef(ref.getName());
                        Optional<ChangeNotes> notes = getChangeNotes(psId.getParentKey());
                        if (notes.isPresent() && notes.get().getChange().getDest().equals(branch)) {
                            existingPatchSets++;
                            bu.addOp(psId.getParentKey(), mergedByPushOpFactory.create(requestScopePropagator, psId, refName));
                            continue COMMIT;
                        }
                    }
                    for (String changeId : c.getFooterLines(CHANGE_ID)) {
                        if (byKey == null) {
                            byKey = executeIndexQuery(() -> openChangesByKeyByBranch(branch));
                        }
                        ChangeNotes onto = byKey.get(new Change.Key(changeId.trim()));
                        if (onto != null) {
                            newPatchSets++;
                            // Hold onto this until we're done with the walk, as the call to
                            // req.validate below calls isMergedInto which resets the walk.
                            ReplaceRequest req = new ReplaceRequest(onto.getChangeId(), c, cmd, false);
                            req.notes = onto;
                            replaceAndClose.add(req);
                            continue COMMIT;
                        }
                    }
                }
                for (ReplaceRequest req : replaceAndClose) {
                    Change.Id id = req.notes.getChangeId();
                    if (!req.validateNewPatchSetForAutoClose()) {
                        logger.atFine().log("Not closing %s because validation failed", id);
                        continue;
                    }
                    req.addOps(bu, null);
                    bu.addOp(id, mergedByPushOpFactory.create(requestScopePropagator, req.psId, refName).setPatchSetProvider(req.replaceOp::getPatchSet));
                    bu.addOp(id, new ChangeProgressOp(progress));
                    ids.add(id);
                }
                logger.atFine().log("Auto-closing %s changes with existing patch sets and %s with new patch sets", existingPatchSets, newPatchSets);
                bu.execute();
            } catch (IOException | OrmException | PermissionBackendException e) {
                logger.atSevere().withCause(e).log("Failed to auto-close changes");
                return null;
            }
            // If we are here, we didn't throw UpdateException. Record the result.
            // The ordering is indeterminate due to the HashSet; unfortunately, Change.Id doesn't
            // fit into TreeSet.
            ids.stream().forEach(id -> resultChangeIds.add(Key.AUTOCLOSED, id));
            return null;
        }, // eat up the whole timeout so that no time is left to retry this outer action.
        RetryHelper.options().timeout(retryHelper.getDefaultTimeout(ActionType.CHANGE_UPDATE).multipliedBy(5)).build());
    } catch (RestApiException e) {
        logger.atSevere().withCause(e).log("Can't insert patchset");
    } catch (UpdateException e) {
        logger.atSevere().withCause(e).log("Failed to auto-close changes");
    }
}
#end_block

#method_before
@Override
public void onPreReceive(ReceivePack rp, Collection<ReceiveCommand> commands) {
    if (commands.stream().anyMatch(c -> c.getResult() != Result.NOT_ATTEMPTED)) {
        // pre-receive hooks
        return;
    }
    long startNanos = System.nanoTime();
    Worker w = new Worker(commands);
    try {
        w.progress.waitFor(executor.submit(scopePropagator.wrap(w)), timeoutMillis, TimeUnit.MILLISECONDS);
    } catch (ExecutionException e) {
        logger.atWarning().withCause(e).log("Error in ReceiveCommits while processing changes for project %s", projectState.getName());
        rp.sendError("internal error while processing changes");
        // point is very bad.
        for (ReceiveCommand c : commands) {
            if (c.getResult() == Result.NOT_ATTEMPTED) {
                c.setResult(Result.REJECTED_OTHER_REASON, "internal error");
            }
        }
        metrics.timeouts.increment();
    } finally {
        w.sendMessages();
    }
    long deltaNanos = System.nanoTime() - startNanos;
    int totalChanges = 0;
    for (ResultChangeIds.Key key : ResultChangeIds.Key.values()) {
        List<Change.Id> ids = resultChangeIds.get(key);
        metrics.changes.record(key.name(), ids.size());
        totalChanges += ids.size();
    }
    if (totalChanges > 0) {
        metrics.latencyPerChange.record(resultChangeIds.get(Key.AUTOCLOSED).isEmpty() ? "CREATE_REPLACE" : Key.AUTOCLOSED, deltaNanos / totalChanges, // NOSUBMIT - should I convert to millis?
        NANOSECONDS);
    }
}
#method_after
@Override
public void onPreReceive(ReceivePack rp, Collection<ReceiveCommand> commands) {
    if (commands.stream().anyMatch(c -> c.getResult() != Result.NOT_ATTEMPTED)) {
        // pre-receive hooks
        return;
    }
    long startNanos = System.nanoTime();
    Worker w = new Worker(commands);
    try {
        w.progress.waitFor(executor.submit(scopePropagator.wrap(w)), timeoutMillis, TimeUnit.MILLISECONDS);
    } catch (ExecutionException e) {
        metrics.timeouts.increment();
        logger.atWarning().withCause(e).log("Error in ReceiveCommits while processing changes for project %s", projectState.getName());
        rp.sendError("internal error while processing changes");
        // point is very bad.
        for (ReceiveCommand c : commands) {
            if (c.getResult() == Result.NOT_ATTEMPTED) {
                c.setResult(Result.REJECTED_OTHER_REASON, "internal error");
            }
        }
    } finally {
        w.sendMessages();
    }
    long deltaNanos = System.nanoTime() - startNanos;
    int totalChanges = 0;
    for (ResultChangeIds.Key key : ResultChangeIds.Key.values()) {
        List<Change.Id> ids = resultChangeIds.get(key);
        metrics.changes.record(key, ids.size());
        totalChanges += ids.size();
    }
    if (totalChanges > 0) {
        metrics.latencyPerChange.record(resultChangeIds.get(ResultChangeIds.Key.AUTOCLOSED).isEmpty() ? "CREATE_REPLACE" : ResultChangeIds.Key.AUTOCLOSED.name(), deltaNanos / totalChanges, NANOSECONDS);
    }
}
#end_block

#method_before
@Test
public void dependencyOnOutdatedPatchSetPreventsMerge() throws Exception {
    // Create a change
    PushOneCommit change = pushFactory.create(db, user.getIdent(), testRepo, "fix", "a.txt", "foo");
    PushOneCommit.Result changeResult = change.to("refs/for/master");
    // Create a successor change.
    PushOneCommit change2 = pushFactory.create(db, user.getIdent(), testRepo, "feature", "b.txt", "bar");
    PushOneCommit.Result change2Result = change2.to("refs/for/master");
    // Create new patch set for first change.
    testRepo.reset(changeResult.getCommit().name());
    amendChange(changeResult.getChangeId());
    // Approve both changes
    approve(changeResult.getChangeId());
    approve(change2Result.getChangeId());
    submitWithConflict(change2Result.getChangeId(), "Failed to submit 2 changes due to the following problems:\n" + "Change " + change2Result.getChange().getId() + ": Depends on change that was not submitted." + " Commit " + change2Result.getCommit().name() + " depends on commit " + changeResult.getCommit().name() + " of change " + changeResult.getChange().getId() + " which cannot be merged because it is an outdated patch set.");
    assertRefUpdatedEvents();
    assertChangeMergedEvents();
}
#method_after
@Test
public void dependencyOnOutdatedPatchSetPreventsMerge() throws Exception {
    // Create a change
    PushOneCommit change = pushFactory.create(db, user.getIdent(), testRepo, "fix", "a.txt", "foo");
    PushOneCommit.Result changeResult = change.to("refs/for/master");
    PatchSet.Id patchSetId = changeResult.getPatchSetId();
    // Create a successor change.
    PushOneCommit change2 = pushFactory.create(db, user.getIdent(), testRepo, "feature", "b.txt", "bar");
    PushOneCommit.Result change2Result = change2.to("refs/for/master");
    // Create new patch set for first change.
    testRepo.reset(changeResult.getCommit().name());
    amendChange(changeResult.getChangeId());
    // Approve both changes
    approve(changeResult.getChangeId());
    approve(change2Result.getChangeId());
    submitWithConflict(change2Result.getChangeId(), "Failed to submit 2 changes due to the following problems:\n" + "Change " + change2Result.getChange().getId() + ": Depends on change that was not submitted." + " Commit " + change2Result.getCommit().name() + " depends on commit " + changeResult.getCommit().name() + ", which is outdated patch set " + patchSetId.get() + " of change " + changeResult.getChange().getId() + ". The latest patch set is " + changeResult.getPatchSetId().get() + ".");
    assertRefUpdatedEvents();
    assertChangeMergedEvents();
}
#end_block

#method_before
@Test
public void dependencyOnDeletedChangePreventsMerge() throws Exception {
    // Create a change
    PushOneCommit change = pushFactory.create(db, user.getIdent(), testRepo, "fix", "a.txt", "foo");
    PushOneCommit.Result changeResult = change.to("refs/for/master");
    // Create a successor change.
    PushOneCommit change2 = pushFactory.create(db, user.getIdent(), testRepo, "feature", "b.txt", "bar");
    PushOneCommit.Result change2Result = change2.to("refs/for/master");
    // Delete first change.
    gApi.changes().id(changeResult.getChangeId()).delete();
    submitWithConflict(change2Result.getChangeId(), "Failed to submit 1 change due to the following problems:\n" + "Change " + change2Result.getChange().getId() + ": Depends on change that was not submitted." + " Commit " + change2Result.getCommit().name() + " depends on commit " + changeResult.getCommit().name() + " which cannot be merged. Was the change of this commit deleted?");
    assertRefUpdatedEvents();
    assertChangeMergedEvents();
}
#method_after
@Test
public void dependencyOnDeletedChangePreventsMerge() throws Exception {
    // Create a change
    PushOneCommit change = pushFactory.create(db, user.getIdent(), testRepo, "fix", "a.txt", "foo");
    PushOneCommit.Result changeResult = change.to("refs/for/master");
    // Create a successor change.
    PushOneCommit change2 = pushFactory.create(db, user.getIdent(), testRepo, "feature", "b.txt", "bar");
    PushOneCommit.Result change2Result = change2.to("refs/for/master");
    // Delete first change.
    gApi.changes().id(changeResult.getChangeId()).delete();
    // Submit is expected to fail.
    submitWithConflict(change2Result.getChangeId(), "Failed to submit 1 change due to the following problems:\n" + "Change " + change2Result.getChange().getId() + ": Depends on change that was not submitted." + " Commit " + change2Result.getCommit().name() + " depends on commit " + changeResult.getCommit().name() + " which cannot be merged." + " Is the change of this commit not visible or was it deleted?");
    assertRefUpdatedEvents();
    assertChangeMergedEvents();
}
#end_block

#method_before
@Test
public void dependencyOnDeletedChangePreventsMerge() throws Exception {
    // Create a change
    PushOneCommit change = pushFactory.create(db, user.getIdent(), testRepo, "fix", "a.txt", "foo");
    PushOneCommit.Result changeResult = change.to("refs/for/master");
    // Create a successor change.
    PushOneCommit change2 = pushFactory.create(db, user.getIdent(), testRepo, "feature", "b.txt", "bar");
    PushOneCommit.Result change2Result = change2.to("refs/for/master");
    // Delete first change.
    gApi.changes().id(changeResult.getChangeId()).delete();
    submitWithConflict(change2Result.getChangeId(), "Failed to submit 1 change due to the following problems:\n" + "Change " + change2Result.getChange().getId() + ": Depends on change that was not submitted." + " Commit " + change2Result.getCommit().name() + " depends on commit " + changeResult.getCommit().name() + " which cannot be merged. Was the change of this commit deleted?");
    assertRefUpdatedEvents();
    assertChangeMergedEvents();
}
#method_after
@Test
public void dependencyOnDeletedChangePreventsMerge() throws Exception {
    // Create a change
    PushOneCommit change = pushFactory.create(db, user.getIdent(), testRepo, "fix", "a.txt", "foo");
    PushOneCommit.Result changeResult = change.to("refs/for/master");
    // Create a successor change.
    PushOneCommit change2 = pushFactory.create(db, user.getIdent(), testRepo, "feature", "b.txt", "bar");
    PushOneCommit.Result change2Result = change2.to("refs/for/master");
    // Delete first change.
    gApi.changes().id(changeResult.getChangeId()).delete();
    // Submit is expected to fail.
    submitWithConflict(change2Result.getChangeId(), "Failed to submit 1 change due to the following problems:\n" + "Change " + change2Result.getChange().getId() + ": Depends on change that was not submitted." + " Commit " + change2Result.getCommit().name() + " depends on commit " + changeResult.getCommit().name() + " which cannot be merged." + " Is the change of this commit not visible or was it deleted?");
    assertRefUpdatedEvents();
    assertChangeMergedEvents();
}
#end_block

#method_before
private void pushGitmodules(String name, String url, String path, String expectedErrorMessage) throws Exception {
    Config config = new Config();
    if (url != null) {
        config.setString("submodule", name, "url", url);
    }
    if (path != null) {
        config.setString("submodule", name, "path", path);
    }
    TestRepository<?> repo = cloneProject(project);
    repo.branch("HEAD").commit().insertChangeId().message("subject: adding new subscription").add(".gitmodules", config.toText().toString()).create();
    exception.expectMessage(expectedErrorMessage);
    exception.expect(TransportException.class);
    repo.git().push().setRemote("origin").setRefSpecs(new RefSpec("HEAD:refs/for/master")).call();
}
#method_after
private void pushGitmodules(String name, String url, String path, String expectedErrorMessage) throws Exception {
    Config config = new Config();
    config.setString("submodule", name, "url", url);
    config.setString("submodule", name, "path", path);
    TestRepository<?> repo = cloneProject(project);
    repo.branch("HEAD").commit().insertChangeId().message("subject: adding new subscription").add(".gitmodules", config.toText().toString()).create();
    exception.expectMessage(expectedErrorMessage);
    exception.expect(TransportException.class);
    repo.git().push().setRemote("origin").setRefSpecs(new RefSpec("HEAD:refs/for/master")).call();
}
#end_block

#method_before
private ChangesHandle executeChangeOps(boolean dryrun) throws Exception {
    logDebug("Executing change ops");
    initRepository();
    Repository repo = repoView.getRepository();
    checkState(repo.getRefDatabase().performsAtomicTransactions(), "cannot use NoteDb with a repository that does not support atomic batch ref updates: %s", repo);
    ChangesHandle handle = new ChangesHandle(updateManagerFactory.create(project).setChangeRepo(repo, repoView.getRevWalk(), repoView.getInserter(), repoView.getCommands()), dryrun);
    if (user.isIdentifiedUser()) {
        handle.manager.setRefLogIdent(user.asIdentifiedUser().newRefLogIdent(when, tz));
    }
    handle.manager.setRefLogMessage(refLogMessage);
    handle.manager.setPushCertificate(pushCert);
    for (Map.Entry<Change.Id, Collection<BatchUpdateOp>> e : ops.asMap().entrySet()) {
        Change.Id id = e.getKey();
        ChangeContextImpl ctx = newChangeContext(id);
        boolean dirty = false;
        logDebug("Applying %d ops for change %s: %s", e.getValue().size(), id, e.getValue().stream().map(op -> op.getClass().getName()).collect(toSet()));
        for (BatchUpdateOp op : e.getValue()) {
            dirty |= op.updateChange(ctx);
        }
        if (!dirty) {
            logDebug("No ops reported dirty, short-circuiting");
            handle.setResult(id, ChangeResult.SKIPPED);
            continue;
        }
        for (ChangeUpdate u : ctx.updates.values()) {
            handle.manager.add(u);
        }
        if (ctx.deleted) {
            logDebug("Change %s was deleted", id);
            handle.manager.deleteChange(id);
            handle.setResult(id, ChangeResult.DELETED);
        } else {
            handle.setResult(id, ChangeResult.UPSERTED);
        }
    }
    return handle;
}
#method_after
private ChangesHandle executeChangeOps(boolean dryrun) throws Exception {
    logDebug("Executing change ops");
    initRepository();
    Repository repo = repoView.getRepository();
    checkState(repo.getRefDatabase().performsAtomicTransactions(), "cannot use NoteDb with a repository that does not support atomic batch ref updates: %s", repo);
    ChangesHandle handle = new ChangesHandle(updateManagerFactory.create(project).setChangeRepo(repo, repoView.getRevWalk(), repoView.getInserter(), repoView.getCommands()), dryrun);
    if (user.isIdentifiedUser()) {
        handle.manager.setRefLogIdent(user.asIdentifiedUser().newRefLogIdent(when, tz));
    }
    handle.manager.setRefLogMessage(refLogMessage);
    handle.manager.setPushCertificate(pushCert);
    for (Map.Entry<Change.Id, Collection<BatchUpdateOp>> e : ops.asMap().entrySet()) {
        Change.Id id = e.getKey();
        ChangeContextImpl ctx = newChangeContext(id);
        boolean dirty = false;
        logDebug("Applying %d ops for change %s: %s", e.getValue().size(), id, lazy(() -> e.getValue().stream().map(op -> op.getClass().getName()).collect(toSet())));
        for (BatchUpdateOp op : e.getValue()) {
            dirty |= op.updateChange(ctx);
        }
        if (!dirty) {
            logDebug("No ops reported dirty, short-circuiting");
            handle.setResult(id, ChangeResult.SKIPPED);
            continue;
        }
        for (ChangeUpdate u : ctx.updates.values()) {
            handle.manager.add(u);
        }
        if (ctx.deleted) {
            logDebug("Change %s was deleted", id);
            handle.manager.deleteChange(id);
            handle.setResult(id, ChangeResult.DELETED);
        } else {
            handle.setResult(id, ChangeResult.UPSERTED);
        }
    }
    return handle;
}
#end_block

#method_before
void init() {
    for (ReceivePackInitializer i : initializers) {
        i.init(projectState.getNameKey(), receivePack);
    }
}
#method_after
void init() {
    initializers.runEach(i -> i.init(projectState.getNameKey(), receivePack));
}
#end_block

#method_before
private void addMessage(String message) {
    messages.add(new CommitValidationMessage(message, Type.OTHER));
}
#method_after
private void addMessage(String message) {
    messages.add(new CommitValidationMessage(message, ValidationMessage.Type.OTHER));
}
#end_block

#method_before
void addError(String error) {
    addMessage(error, Type.ERROR);
}
#method_after
private void addError(String error) {
    addMessage(error, ValidationMessage.Type.ERROR);
}
#end_block

#method_before
void sendMessages() {
    for (ValidationMessage m : messages) {
        String prefix = ValidationMessage.getPrefix(m.getType());
        if (m.isError()) {
            messageSender.sendError(prefix + m.getMessage());
        } else {
            messageSender.sendMessage(prefix + m.getMessage());
        }
    }
}
#method_after
void sendMessages() {
    for (ValidationMessage m : messages) {
        String msg = m.getType().getPrefix() + m.getMessage();
        if (m.isError()) {
            messageSender.sendError(msg);
        } else {
            messageSender.sendMessage(msg);
        }
    }
}
#end_block

#method_before
void processCommands(Collection<ReceiveCommand> commands, MultiProgressMonitor progress) {
    Task commandProgress = progress.beginSubTask("refs", UNKNOWN);
    commands = commands.stream().map(c -> wrapReceiveCommand(c, commandProgress)).collect(toList());
    processCommandsUnsafe(commands, progress);
    for (ReceiveCommand cmd : commands) {
        if (cmd.getResult() == NOT_ATTEMPTED) {
            cmd.setResult(REJECTED_OTHER_REASON, "internal server error");
        }
    }
    // This sends error messages before the 'done' string of the progress monitor is sent.
    // Currently, the test framework relies on this ordering to understand if pushes completed
    // successfully.
    sendErrorMessages();
    commandProgress.end();
    progress.end();
}
#method_after
void processCommands(Collection<ReceiveCommand> commands, MultiProgressMonitor progress) {
    Task commandProgress = progress.beginSubTask("refs", UNKNOWN);
    commands = commands.stream().map(c -> wrapReceiveCommand(c, commandProgress)).collect(toList());
    processCommandsUnsafe(commands, progress);
    rejectRemaining(commands, "internal server error");
    // This sends error messages before the 'done' string of the progress monitor is sent.
    // Currently, the test framework relies on this ordering to understand if pushes completed
    // successfully.
    sendErrorMessages();
    commandProgress.end();
    progress.end();
}
#end_block

#method_before
private void processCommandsUnsafe(Collection<ReceiveCommand> commands, MultiProgressMonitor progress) {
    parsePushOptions();
    try (TraceContext traceContext = TraceContext.newTrace(tracePushOption.isPresent(), tracePushOption.orElse(null), (tagName, traceId) -> addMessage(tagName + ": " + traceId))) {
        traceContext.addTag(RequestId.Type.RECEIVE_ID, new RequestId(project.getNameKey().get()));
        // Log the push options here, rather than in parsePushOptions(), so that they are included
        // into the trace if tracing is enabled.
        logger.atFine().log("push options: %s", receivePack.getPushOptions());
        if (!projectState.getProject().getState().permitsWrite()) {
            for (ReceiveCommand cmd : commands) {
                reject(cmd, "prohibited by Gerrit: project state does not permit write");
            }
            return;
        }
        logger.atFine().log("Parsing %d commands", commands.size());
        List<ReceiveCommand> magicCommands = new ArrayList<>();
        List<ReceiveCommand> directPatchSetPushCommands = new ArrayList<>();
        List<ReceiveCommand> regularCommands = new ArrayList<>();
        for (ReceiveCommand cmd : commands) {
            if (MagicBranch.isMagicBranch(cmd.getRefName())) {
                magicCommands.add(cmd);
            } else if (isDirectChangesPush(cmd.getRefName())) {
                directPatchSetPushCommands.add(cmd);
            } else {
                regularCommands.add(cmd);
            }
        }
        int commandTypes = (magicCommands.isEmpty() ? 0 : 1) + (directPatchSetPushCommands.isEmpty() ? 0 : 1) + (regularCommands.isEmpty() ? 0 : 1);
        if (commandTypes > 1) {
            for (ReceiveCommand cmd : commands) {
                if (cmd.getResult() == NOT_ATTEMPTED) {
                    cmd.setResult(REJECTED_OTHER_REASON, "cannot combine normal pushes and magic pushes");
                }
            }
            return;
        }
        try {
            if (!regularCommands.isEmpty()) {
                handleRegularCommands(regularCommands, progress);
                return;
            }
            for (ReceiveCommand cmd : directPatchSetPushCommands) {
                parseDirectChangesPush(cmd);
            }
            boolean first = true;
            for (ReceiveCommand cmd : magicCommands) {
                if (first) {
                    parseMagicBranch(cmd);
                    first = false;
                } else {
                    reject(cmd, "duplicate request");
                }
            }
        } catch (PermissionBackendException | NoSuchProjectException | IOException err) {
            logger.atSevere().withCause(err).log("Failed to process refs in %s", project.getName());
            return;
        }
        Task newProgress = progress.beginSubTask("new", UNKNOWN);
        Task replaceProgress = progress.beginSubTask("updated", UNKNOWN);
        List<CreateRequest> newChanges = Collections.emptyList();
        if (magicBranch != null && magicBranch.cmd.getResult() == NOT_ATTEMPTED) {
            newChanges = selectNewAndReplacedChangesFromMagicBranch(newProgress);
        }
        // Commit validation has already happened, so any changes without Change-Id are for the
        // deprecated feature.
        warnAboutMissingChangeId(newChanges);
        preparePatchSetsForReplace(newChanges);
        insertChangesAndPatchSets(newChanges, replaceProgress);
        newProgress.end();
        replaceProgress.end();
        queueSuccessMessages(newChanges);
        refsPublishDeprecationWarning();
    }
}
#method_after
private void processCommandsUnsafe(Collection<ReceiveCommand> commands, MultiProgressMonitor progress) {
    parsePushOptions();
    try (TraceContext traceContext = TraceContext.newTrace(tracePushOption.isPresent(), tracePushOption.orElse(null), (tagName, traceId) -> addMessage(tagName + ": " + traceId))) {
        traceContext.addTag(RequestId.Type.RECEIVE_ID, new RequestId(project.getNameKey().get()));
        // Log the push options here, rather than in parsePushOptions(), so that they are included
        // into the trace if tracing is enabled.
        logger.atFine().log("push options: %s", receivePack.getPushOptions());
        if (!projectState.getProject().getState().permitsWrite()) {
            for (ReceiveCommand cmd : commands) {
                reject(cmd, "prohibited by Gerrit: project state does not permit write");
            }
            return;
        }
        logger.atFine().log("Parsing %d commands", commands.size());
        List<ReceiveCommand> magicCommands = new ArrayList<>();
        List<ReceiveCommand> directPatchSetPushCommands = new ArrayList<>();
        List<ReceiveCommand> regularCommands = new ArrayList<>();
        for (ReceiveCommand cmd : commands) {
            if (MagicBranch.isMagicBranch(cmd.getRefName())) {
                magicCommands.add(cmd);
            } else if (isDirectChangesPush(cmd.getRefName())) {
                directPatchSetPushCommands.add(cmd);
            } else {
                regularCommands.add(cmd);
            }
        }
        int commandTypes = (magicCommands.isEmpty() ? 0 : 1) + (directPatchSetPushCommands.isEmpty() ? 0 : 1) + (regularCommands.isEmpty() ? 0 : 1);
        if (commandTypes > 1) {
            rejectRemaining(commands, "cannot combine normal pushes and magic pushes");
            return;
        }
        try {
            if (!regularCommands.isEmpty()) {
                handleRegularCommands(regularCommands, progress);
                return;
            }
            for (ReceiveCommand cmd : directPatchSetPushCommands) {
                parseDirectChangesPush(cmd);
            }
            boolean first = true;
            for (ReceiveCommand cmd : magicCommands) {
                if (first) {
                    parseMagicBranch(cmd);
                    first = false;
                } else {
                    reject(cmd, "duplicate request");
                }
            }
        } catch (PermissionBackendException | NoSuchProjectException | IOException err) {
            logger.atSevere().withCause(err).log("Failed to process refs in %s", project.getName());
            return;
        }
        Task newProgress = progress.beginSubTask("new", UNKNOWN);
        Task replaceProgress = progress.beginSubTask("updated", UNKNOWN);
        List<CreateRequest> newChanges = Collections.emptyList();
        if (magicBranch != null && magicBranch.cmd.getResult() == NOT_ATTEMPTED) {
            newChanges = selectNewAndReplacedChangesFromMagicBranch(newProgress);
        }
        // Commit validation has already happened, so any changes without Change-Id are for the
        // deprecated feature.
        warnAboutMissingChangeId(newChanges);
        preparePatchSetsForReplace(newChanges);
        insertChangesAndPatchSets(newChanges, replaceProgress);
        newProgress.end();
        replaceProgress.end();
        queueSuccessMessages(newChanges);
        refsPublishDeprecationWarning();
    }
}
#end_block

#method_before
private void handleRegularCommands(List<ReceiveCommand> cmds, MultiProgressMonitor progress) throws PermissionBackendException, IOException, NoSuchProjectException {
    for (ReceiveCommand cmd : cmds) {
        parseRegularCommand(cmd);
    }
    try (BatchUpdate bu = batchUpdateFactory.create(db, project.getNameKey(), user.materializedCopy(), TimeUtil.nowTs());
        ObjectInserter ins = repo.newObjectInserter();
        ObjectReader reader = ins.newReader();
        RevWalk rw = new RevWalk(reader)) {
        bu.setRepository(repo, rw, ins).updateChangesInParallel();
        bu.setRefLogMessage("push");
        int added = 0;
        for (ReceiveCommand cmd : cmds) {
            if (cmd.getResult() == NOT_ATTEMPTED) {
                bu.addRepoOnlyOp(new UpdateOneRefOp(cmd));
                added++;
            }
        }
        logger.atFine().log("Added %d additional ref updates", added);
        bu.execute();
    } catch (UpdateException | RestApiException e) {
        for (ReceiveCommand cmd : cmds) {
            if (cmd.getResult() == NOT_ATTEMPTED) {
                cmd.setResult(REJECTED_OTHER_REASON, "internal server error");
            }
        }
        logger.atFine().withCause(e).log("update failed:");
    }
    Set<Branch.NameKey> branches = new HashSet<>();
    for (ReceiveCommand c : cmds) {
        // they involve kicking off an additional BatchUpdate.
        if (c.getResult() != OK) {
            continue;
        }
        if (isHead(c) || isConfig(c)) {
            switch(c.getType()) {
                case CREATE:
                case UPDATE:
                case UPDATE_NONFASTFORWARD:
                    Task closeProgress = progress.beginSubTask("closed", UNKNOWN);
                    autoCloseChanges(c, closeProgress);
                    closeProgress.end();
                    branches.add(new Branch.NameKey(project.getNameKey(), c.getRefName()));
                    break;
                case DELETE:
                    break;
            }
        }
    }
    // Update superproject gitlinks if required.
    if (!branches.isEmpty()) {
        try (MergeOpRepoManager orm = ormProvider.get()) {
            orm.setContext(db, TimeUtil.nowTs(), user);
            SubmoduleOp op = subOpFactory.create(branches, orm);
            op.updateSuperProjects();
        } catch (SubmoduleException e) {
            logger.atSevere().withCause(e).log("Can't update the superprojects");
        }
    }
}
#method_after
private void handleRegularCommands(List<ReceiveCommand> cmds, MultiProgressMonitor progress) throws PermissionBackendException, IOException, NoSuchProjectException {
    for (ReceiveCommand cmd : cmds) {
        parseRegularCommand(cmd);
    }
    try (BatchUpdate bu = batchUpdateFactory.create(db, project.getNameKey(), user.materializedCopy(), TimeUtil.nowTs());
        ObjectInserter ins = repo.newObjectInserter();
        ObjectReader reader = ins.newReader();
        RevWalk rw = new RevWalk(reader)) {
        bu.setRepository(repo, rw, ins).updateChangesInParallel();
        bu.setRefLogMessage("push");
        int added = 0;
        for (ReceiveCommand cmd : cmds) {
            if (cmd.getResult() == NOT_ATTEMPTED) {
                bu.addRepoOnlyOp(new UpdateOneRefOp(cmd));
                added++;
            }
        }
        logger.atFine().log("Added %d additional ref updates", added);
        bu.execute();
    } catch (UpdateException | RestApiException e) {
        rejectRemaining(cmds, "internal server error");
        logger.atFine().withCause(e).log("update failed:");
    }
    Set<Branch.NameKey> branches = new HashSet<>();
    for (ReceiveCommand c : cmds) {
        // they involve kicking off an additional BatchUpdate.
        if (c.getResult() != OK) {
            continue;
        }
        if (isHead(c) || isConfig(c)) {
            switch(c.getType()) {
                case CREATE:
                case UPDATE:
                case UPDATE_NONFASTFORWARD:
                    Task closeProgress = progress.beginSubTask("closed", UNKNOWN);
                    autoCloseChanges(c, closeProgress);
                    closeProgress.end();
                    branches.add(new Branch.NameKey(project.getNameKey(), c.getRefName()));
                    break;
                case DELETE:
                    break;
            }
        }
    }
    // Update superproject gitlinks if required.
    if (!branches.isEmpty()) {
        try (MergeOpRepoManager orm = ormProvider.get()) {
            orm.setContext(db, TimeUtil.nowTs(), user);
            SubmoduleOp op = subOpFactory.create(branches, orm);
            op.updateSuperProjects();
        } catch (SubmoduleException e) {
            logger.atSevere().withCause(e).log("Can't update the superprojects");
        }
    }
}
#end_block

#method_before
private void rejectImplicitMerges(Set<RevCommit> mergedParents) throws IOException {
    if (!mergedParents.isEmpty()) {
        Ref targetRef = allRefs().get(magicBranch.dest.get());
        if (targetRef != null) {
            RevWalk rw = receivePack.getRevWalk();
            RevCommit tip = rw.parseCommit(targetRef.getObjectId());
            boolean containsImplicitMerges = true;
            for (RevCommit p : mergedParents) {
                containsImplicitMerges &= !rw.isMergedInto(p, tip);
            }
            if (containsImplicitMerges) {
                rw.reset();
                for (RevCommit p : mergedParents) {
                    rw.markStart(p);
                }
                rw.markUninteresting(tip);
                RevCommit c;
                while ((c = rw.next()) != null) {
                    rw.parseBody(c);
                    messages.add(new CommitValidationMessage("Implicit Merge of " + c.abbreviate(7).name() + " " + c.getShortMessage(), Type.ERROR));
                }
                reject(magicBranch.cmd, "implicit merges detected");
            }
        }
    }
}
#method_after
private void rejectImplicitMerges(Set<RevCommit> mergedParents) throws IOException {
    if (!mergedParents.isEmpty()) {
        Ref targetRef = allRefs().get(magicBranch.dest.get());
        if (targetRef != null) {
            RevWalk rw = receivePack.getRevWalk();
            RevCommit tip = rw.parseCommit(targetRef.getObjectId());
            boolean containsImplicitMerges = true;
            for (RevCommit p : mergedParents) {
                containsImplicitMerges &= !rw.isMergedInto(p, tip);
            }
            if (containsImplicitMerges) {
                rw.reset();
                for (RevCommit p : mergedParents) {
                    rw.markStart(p);
                }
                rw.markUninteresting(tip);
                RevCommit c;
                while ((c = rw.next()) != null) {
                    rw.parseBody(c);
                    messages.add(new CommitValidationMessage("Implicit Merge of " + c.abbreviate(7).name() + " " + c.getShortMessage(), ValidationMessage.Type.ERROR));
                }
                reject(magicBranch.cmd, "implicit merges detected");
            }
        }
    }
}
#end_block

#method_before
ChangeLookup lookupByChangeKey(RevCommit c, Change.Key key) throws OrmException {
    return new ChangeLookup(c, key, queryProvider.get().byBranchKey(magicBranch.dest, key));
}
#method_after
private ChangeLookup lookupByChangeKey(RevCommit c, Change.Key key) throws OrmException {
    return new ChangeLookup(c, key, queryProvider.get().byBranchKey(magicBranch.dest, key));
}
#end_block

#method_before
ChangeLookup lookupByCommit(RevCommit c) throws OrmException {
    return new ChangeLookup(c, null, queryProvider.get().byBranchCommit(magicBranch.dest, c.getName()));
}
#method_after
private ChangeLookup lookupByCommit(RevCommit c) throws OrmException {
    return new ChangeLookup(c, null, queryProvider.get().byBranchCommit(magicBranch.dest, c.getName()));
}
#end_block

#method_before
private void addOps(BatchUpdate bu) throws RestApiException {
    checkState(changeId != null, "must call setChangeId before addOps");
    try {
        RevWalk rw = receivePack.getRevWalk();
        rw.parseBody(commit);
        final PatchSet.Id psId = ins.setGroups(groups).getPatchSetId();
        Account.Id me = user.getAccountId();
        List<FooterLine> footerLines = commit.getFooterLines();
        MailRecipients recipients = new MailRecipients();
        checkNotNull(magicBranch);
        recipients.add(magicBranch.getMailRecipients());
        Map<String, Short> approvals = magicBranch.labels;
        recipients.add(getRecipientsFromFooters(accountResolver, footerLines));
        recipients.remove(me);
        StringBuilder msg = new StringBuilder(ApprovalsUtil.renderMessageWithApprovals(psId.get(), approvals, Collections.emptyMap()));
        msg.append('.');
        if (!Strings.isNullOrEmpty(magicBranch.message)) {
            msg.append("\n").append(magicBranch.message);
        }
        bu.insertChange(ins.setReviewers(recipients.getReviewers()).setExtraCC(recipients.getCcOnly()).setApprovals(approvals).setMessage(msg.toString()).setNotify(magicBranch.getNotify()).setAccountsToNotify(magicBranch.getAccountsToNotify()).setRequestScopePropagator(requestScopePropagator).setSendMail(true).setPatchSetDescription(magicBranch.message));
        if (!magicBranch.hashtags.isEmpty()) {
            // Any change owner is allowed to add hashtags when creating a change.
            bu.addOp(changeId, hashtagsFactory.create(new HashtagsInput(magicBranch.hashtags)).setFireEvent(false));
        }
        if (!Strings.isNullOrEmpty(magicBranch.topic)) {
            bu.addOp(changeId, new BatchUpdateOp() {

                @Override
                public boolean updateChange(ChangeContext ctx) {
                    ctx.getUpdate(psId).setTopic(magicBranch.topic);
                    return true;
                }
            });
        }
        bu.addOp(changeId, new BatchUpdateOp() {

            @Override
            public boolean updateChange(ChangeContext ctx) {
                change = ctx.getChange();
                return false;
            }
        });
        bu.addOp(changeId, new ChangeProgressOp(progress));
    } catch (Exception e) {
        throw INSERT_EXCEPTION.apply(e);
    }
}
#method_after
private void addOps(BatchUpdate bu) throws RestApiException {
    checkState(changeId != null, "must call setChangeId before addOps");
    try {
        RevWalk rw = receivePack.getRevWalk();
        rw.parseBody(commit);
        final PatchSet.Id psId = ins.setGroups(groups).getPatchSetId();
        Account.Id me = user.getAccountId();
        List<FooterLine> footerLines = commit.getFooterLines();
        MailRecipients recipients = new MailRecipients();
        checkNotNull(magicBranch);
        recipients.add(magicBranch.getMailRecipients());
        Map<String, Short> approvals = magicBranch.labels;
        recipients.add(getRecipientsFromFooters(accountResolver, footerLines));
        recipients.remove(me);
        StringBuilder msg = new StringBuilder(ApprovalsUtil.renderMessageWithApprovals(psId.get(), approvals, Collections.emptyMap()));
        msg.append('.');
        if (!Strings.isNullOrEmpty(magicBranch.message)) {
            msg.append("\n").append(magicBranch.message);
        }
        bu.insertChange(ins.setReviewers(recipients.getReviewers()).setExtraCC(recipients.getCcOnly()).setApprovals(approvals).setMessage(msg.toString()).setNotify(magicBranch.getNotify()).setAccountsToNotify(magicBranch.getAccountsToNotify()).setRequestScopePropagator(requestScopePropagator).setSendMail(true).setPatchSetDescription(magicBranch.message));
        if (!magicBranch.hashtags.isEmpty()) {
            // Any change owner is allowed to add hashtags when creating a change.
            bu.addOp(changeId, hashtagsFactory.create(new HashtagsInput(magicBranch.hashtags)).setFireEvent(false));
        }
        if (!Strings.isNullOrEmpty(magicBranch.topic)) {
            bu.addOp(changeId, new BatchUpdateOp() {

                @Override
                public boolean updateChange(ChangeContext ctx) {
                    ctx.getUpdate(psId).setTopic(magicBranch.topic);
                    return true;
                }
            });
        }
        bu.addOp(changeId, new BatchUpdateOp() {

            @Override
            public boolean updateChange(ChangeContext ctx) {
                CreateRequest.this.change = ctx.getChange();
                return false;
            }
        });
        bu.addOp(changeId, new ChangeProgressOp(progress));
    } catch (Exception e) {
        throw INSERT_EXCEPTION.apply(e);
    }
}
#end_block

#method_before
private void preparePatchSetsForReplace(List<CreateRequest> newChanges) {
    try {
        readChangesForReplace();
        for (Iterator<ReplaceRequest> itr = replaceByChange.values().iterator(); itr.hasNext(); ) {
            ReplaceRequest req = itr.next();
            if (req.inputCommand.getResult() == NOT_ATTEMPTED) {
                req.validateNewPatchSet();
            }
        }
    } catch (OrmException err) {
        logger.atSevere().withCause(err).log("Cannot read database before replacement for project %s", project.getName());
        for (ReplaceRequest req : replaceByChange.values()) {
            if (req.inputCommand.getResult() == NOT_ATTEMPTED) {
                req.inputCommand.setResult(REJECTED_OTHER_REASON, "internal server error");
            }
        }
    } catch (IOException | PermissionBackendException err) {
        logger.atSevere().withCause(err).log("Cannot read repository before replacement for project %s", project.getName());
        for (ReplaceRequest req : replaceByChange.values()) {
            if (req.inputCommand.getResult() == NOT_ATTEMPTED) {
                req.inputCommand.setResult(REJECTED_OTHER_REASON, "internal server error");
            }
        }
    }
    logger.atFine().log("Read %d changes to replace", replaceByChange.size());
    if (magicBranch != null && magicBranch.cmd.getResult() != NOT_ATTEMPTED) {
        // Cancel creations tied to refs/for/ or refs/drafts/ command.
        for (ReplaceRequest req : replaceByChange.values()) {
            if (req.inputCommand == magicBranch.cmd && req.cmd != null) {
                req.cmd.setResult(Result.REJECTED_OTHER_REASON, "aborted");
            }
        }
        for (CreateRequest req : newChanges) {
            req.cmd.setResult(Result.REJECTED_OTHER_REASON, "aborted");
        }
    }
}
#method_after
private void preparePatchSetsForReplace(List<CreateRequest> newChanges) {
    try {
        readChangesForReplace();
        for (ReplaceRequest req : replaceByChange.values()) {
            if (req.inputCommand.getResult() == NOT_ATTEMPTED) {
                req.validateNewPatchSet();
            }
        }
    } catch (OrmException err) {
        logger.atSevere().withCause(err).log("Cannot read database before replacement for project %s", project.getName());
        rejectRemainingRequests(replaceByChange.values(), "internal server error");
    } catch (IOException | PermissionBackendException err) {
        logger.atSevere().withCause(err).log("Cannot read repository before replacement for project %s", project.getName());
        rejectRemainingRequests(replaceByChange.values(), "internal server error");
    }
    logger.atFine().log("Read %d changes to replace", replaceByChange.size());
    if (magicBranch != null && magicBranch.cmd.getResult() != NOT_ATTEMPTED) {
        // Cancel creations tied to refs/for/ or refs/drafts/ command.
        for (ReplaceRequest req : replaceByChange.values()) {
            if (req.inputCommand == magicBranch.cmd && req.cmd != null) {
                req.cmd.setResult(Result.REJECTED_OTHER_REASON, "aborted");
            }
        }
        for (CreateRequest req : newChanges) {
            req.cmd.setResult(Result.REJECTED_OTHER_REASON, "aborted");
        }
    }
}
#end_block

#method_before
static boolean parentsEqual(RevCommit a, RevCommit b) {
    if (a.getParentCount() != b.getParentCount()) {
        return false;
    }
    for (int i = 0; i < a.getParentCount(); i++) {
        if (!a.getParent(i).equals(b.getParent(i))) {
            return false;
        }
    }
    return true;
}
#method_after
private static boolean parentsEqual(RevCommit a, RevCommit b) {
    if (a.getParentCount() != b.getParentCount()) {
        return false;
    }
    for (int i = 0; i < a.getParentCount(); i++) {
        if (!a.getParent(i).equals(b.getParent(i))) {
            return false;
        }
    }
    return true;
}
#end_block

#method_before
static boolean authorEqual(RevCommit a, RevCommit b) {
    PersonIdent aAuthor = a.getAuthorIdent();
    PersonIdent bAuthor = b.getAuthorIdent();
    if (aAuthor == null && bAuthor == null) {
        return true;
    } else if (aAuthor == null || bAuthor == null) {
        return false;
    }
    return Objects.equals(aAuthor.getName(), bAuthor.getName()) && Objects.equals(aAuthor.getEmailAddress(), bAuthor.getEmailAddress());
}
#method_after
private static boolean authorEqual(RevCommit a, RevCommit b) {
    PersonIdent aAuthor = a.getAuthorIdent();
    PersonIdent bAuthor = b.getAuthorIdent();
    if (aAuthor == null && bAuthor == null) {
        return true;
    } else if (aAuthor == null || bAuthor == null) {
        return false;
    }
    return Objects.equals(aAuthor.getName(), bAuthor.getName()) && Objects.equals(aAuthor.getEmailAddress(), bAuthor.getEmailAddress());
}
#end_block

#method_before
@Override
public List<CommitValidationMessage> onCommitReceived(CommitReceivedEvent receiveEvent) throws CommitValidationException {
    List<CommitValidationMessage> messages = new ArrayList<>();
    for (CommitValidationListener validator : commitValidationListeners) {
        try {
            messages.addAll(validator.onCommitReceived(receiveEvent));
        } catch (CommitValidationException e) {
            messages.addAll(e.getMessages());
            throw new CommitValidationException(e.getMessage(), messages);
        }
    }
    return messages;
}
#method_after
@Override
public List<CommitValidationMessage> onCommitReceived(CommitReceivedEvent receiveEvent) throws CommitValidationException {
    List<CommitValidationMessage> messages = new ArrayList<>();
    try {
        commitValidationListeners.runEach(l -> l.onCommitReceived(receiveEvent), CommitValidationException.class);
    } catch (CommitValidationException e) {
        messages.addAll(e.getMessages());
        throw new CommitValidationException(e.getMessage(), messages);
    }
    return messages;
}
#end_block

#method_before
@Override
public Response<ProjectInfo> apply(TopLevelResource resource, IdString id, ProjectInput input) throws RestApiException, IOException, ConfigInvalidException, PermissionBackendException {
    String name = id.get();
    if (input == null) {
        input = new ProjectInput();
    }
    if (input.name != null && !name.equals(input.name)) {
        throw new BadRequestException("name must match URL");
    }
    CreateProjectArgs args = new CreateProjectArgs();
    args.setProjectName(ProjectUtil.stripGitSuffix(name));
    String parentName = MoreObjects.firstNonNull(Strings.emptyToNull(input.parent), allProjects.get());
    args.newParent = projectsCollection.get().parse(parentName, false).getNameKey();
    if (args.newParent.equals(allUsers)) {
        throw new ResourceConflictException(String.format("Cannot inherit from '%s' project", allUsers.get()));
    }
    args.createEmptyCommit = input.createEmptyCommit;
    args.permissionsOnly = input.permissionsOnly;
    args.projectDescription = Strings.emptyToNull(input.description);
    args.submitType = input.submitType;
    args.branch = normalizeBranchNames(input.branches);
    if (input.owners == null || input.owners.isEmpty()) {
        args.ownerIds = new ArrayList<>(projectOwnerGroups.create(args.getProject()).get());
    } else {
        args.ownerIds = Lists.newArrayListWithCapacity(input.owners.size());
        for (String owner : input.owners) {
            args.ownerIds.add(groupsCollection.get().parse(owner).getGroupUUID());
        }
    }
    args.contributorAgreements = MoreObjects.firstNonNull(input.useContributorAgreements, InheritableBoolean.INHERIT);
    args.signedOffBy = MoreObjects.firstNonNull(input.useSignedOffBy, InheritableBoolean.INHERIT);
    args.contentMerge = input.submitType == SubmitType.FAST_FORWARD_ONLY ? InheritableBoolean.FALSE : MoreObjects.firstNonNull(input.useContentMerge, InheritableBoolean.INHERIT);
    args.newChangeForAllNotInTarget = MoreObjects.firstNonNull(input.createNewChangeForAllNotInTarget, InheritableBoolean.INHERIT);
    args.changeIdRequired = MoreObjects.firstNonNull(input.requireChangeId, InheritableBoolean.INHERIT);
    args.rejectEmptyCommit = MoreObjects.firstNonNull(input.rejectEmptyCommit, InheritableBoolean.INHERIT);
    try {
        args.maxObjectSizeLimit = ProjectConfig.validMaxObjectSizeLimit(input.maxObjectSizeLimit);
    } catch (ConfigInvalidException e) {
        throw new BadRequestException(e.getMessage());
    }
    Lock nameLock = lockManager.get().getLock(args.getProject());
    nameLock.lock();
    try {
        for (ProjectCreationValidationListener l : projectCreationValidationListeners) {
            try {
                l.validateNewProject(args);
            } catch (ValidationException e) {
                throw new ResourceConflictException(e.getMessage(), e);
            }
        }
        ProjectState projectState = createProject(args);
        checkNotNull(projectState, "failed to create project " + args.getProject().get());
        if (input.pluginConfigValues != null) {
            ConfigInput in = new ConfigInput();
            in.pluginConfigValues = input.pluginConfigValues;
            putConfig.get().apply(projectState, in);
        }
        return Response.created(json.format(projectState));
    } finally {
        nameLock.unlock();
    }
}
#method_after
@Override
public Response<ProjectInfo> apply(TopLevelResource resource, IdString id, ProjectInput input) throws RestApiException, IOException, ConfigInvalidException, PermissionBackendException {
    String name = id.get();
    if (input == null) {
        input = new ProjectInput();
    }
    if (input.name != null && !name.equals(input.name)) {
        throw new BadRequestException("name must match URL");
    }
    CreateProjectArgs args = new CreateProjectArgs();
    args.setProjectName(ProjectUtil.stripGitSuffix(name));
    String parentName = MoreObjects.firstNonNull(Strings.emptyToNull(input.parent), allProjects.get());
    args.newParent = projectsCollection.get().parse(parentName, false).getNameKey();
    if (args.newParent.equals(allUsers)) {
        throw new ResourceConflictException(String.format("Cannot inherit from '%s' project", allUsers.get()));
    }
    args.createEmptyCommit = input.createEmptyCommit;
    args.permissionsOnly = input.permissionsOnly;
    args.projectDescription = Strings.emptyToNull(input.description);
    args.submitType = input.submitType;
    args.branch = normalizeBranchNames(input.branches);
    if (input.owners == null || input.owners.isEmpty()) {
        args.ownerIds = new ArrayList<>(projectOwnerGroups.create(args.getProject()).get());
    } else {
        args.ownerIds = Lists.newArrayListWithCapacity(input.owners.size());
        for (String owner : input.owners) {
            args.ownerIds.add(groupsCollection.get().parse(owner).getGroupUUID());
        }
    }
    args.contributorAgreements = MoreObjects.firstNonNull(input.useContributorAgreements, InheritableBoolean.INHERIT);
    args.signedOffBy = MoreObjects.firstNonNull(input.useSignedOffBy, InheritableBoolean.INHERIT);
    args.contentMerge = input.submitType == SubmitType.FAST_FORWARD_ONLY ? InheritableBoolean.FALSE : MoreObjects.firstNonNull(input.useContentMerge, InheritableBoolean.INHERIT);
    args.newChangeForAllNotInTarget = MoreObjects.firstNonNull(input.createNewChangeForAllNotInTarget, InheritableBoolean.INHERIT);
    args.changeIdRequired = MoreObjects.firstNonNull(input.requireChangeId, InheritableBoolean.INHERIT);
    args.rejectEmptyCommit = MoreObjects.firstNonNull(input.rejectEmptyCommit, InheritableBoolean.INHERIT);
    args.enableSignedPush = MoreObjects.firstNonNull(input.enableSignedPush, InheritableBoolean.INHERIT);
    args.requireSignedPush = MoreObjects.firstNonNull(input.requireSignedPush, InheritableBoolean.INHERIT);
    try {
        args.maxObjectSizeLimit = ProjectConfig.validMaxObjectSizeLimit(input.maxObjectSizeLimit);
    } catch (ConfigInvalidException e) {
        throw new BadRequestException(e.getMessage());
    }
    Lock nameLock = lockManager.call(lockManager -> lockManager.getLock(args.getProject()));
    nameLock.lock();
    try {
        try {
            projectCreationValidationListeners.runEach(l -> l.validateNewProject(args), ValidationException.class);
        } catch (ValidationException e) {
            throw new ResourceConflictException(e.getMessage(), e);
        }
        ProjectState projectState = createProject(args);
        checkNotNull(projectState, "failed to create project " + args.getProject().get());
        if (input.pluginConfigValues != null) {
            ConfigInput in = new ConfigInput();
            in.pluginConfigValues = input.pluginConfigValues;
            putConfig.get().apply(projectState, in);
        }
        return Response.created(json.format(projectState));
    } finally {
        nameLock.unlock();
    }
}
#end_block

#method_before
private void createProjectConfig(CreateProjectArgs args) throws IOException, ConfigInvalidException {
    try (MetaDataUpdate md = metaDataUpdateFactory.create(args.getProject())) {
        ProjectConfig config = ProjectConfig.read(md);
        Project newProject = config.getProject();
        newProject.setDescription(args.projectDescription);
        newProject.setSubmitType(MoreObjects.firstNonNull(args.submitType, repositoryCfg.getDefaultSubmitType(args.getProject())));
        newProject.setBooleanConfig(BooleanProjectConfig.USE_CONTRIBUTOR_AGREEMENTS, args.contributorAgreements);
        newProject.setBooleanConfig(BooleanProjectConfig.USE_SIGNED_OFF_BY, args.signedOffBy);
        newProject.setBooleanConfig(BooleanProjectConfig.USE_CONTENT_MERGE, args.contentMerge);
        newProject.setBooleanConfig(BooleanProjectConfig.CREATE_NEW_CHANGE_FOR_ALL_NOT_IN_TARGET, args.newChangeForAllNotInTarget);
        newProject.setBooleanConfig(BooleanProjectConfig.REQUIRE_CHANGE_ID, args.changeIdRequired);
        newProject.setBooleanConfig(BooleanProjectConfig.REJECT_EMPTY_COMMIT, args.rejectEmptyCommit);
        newProject.setMaxObjectSizeLimit(args.maxObjectSizeLimit);
        if (args.newParent != null) {
            newProject.setParentName(args.newParent);
        }
        if (!args.ownerIds.isEmpty()) {
            AccessSection all = config.getAccessSection(AccessSection.ALL, true);
            for (AccountGroup.UUID ownerId : args.ownerIds) {
                GroupDescription.Basic g = groupBackend.get(ownerId);
                if (g != null) {
                    GroupReference group = config.resolve(GroupReference.forGroup(g));
                    all.getPermission(Permission.OWNER, true).add(new PermissionRule(group));
                }
            }
        }
        md.setMessage("Created project\n");
        config.commit(md);
        md.getRepository().setGitwebDescription(args.projectDescription);
    }
    projectCache.onCreateProject(args.getProject());
}
#method_after
private void createProjectConfig(CreateProjectArgs args) throws IOException, ConfigInvalidException {
    try (MetaDataUpdate md = metaDataUpdateFactory.create(args.getProject())) {
        ProjectConfig config = ProjectConfig.read(md);
        Project newProject = config.getProject();
        newProject.setDescription(args.projectDescription);
        newProject.setSubmitType(MoreObjects.firstNonNull(args.submitType, repositoryCfg.getDefaultSubmitType(args.getProject())));
        newProject.setBooleanConfig(BooleanProjectConfig.USE_CONTRIBUTOR_AGREEMENTS, args.contributorAgreements);
        newProject.setBooleanConfig(BooleanProjectConfig.USE_SIGNED_OFF_BY, args.signedOffBy);
        newProject.setBooleanConfig(BooleanProjectConfig.USE_CONTENT_MERGE, args.contentMerge);
        newProject.setBooleanConfig(BooleanProjectConfig.CREATE_NEW_CHANGE_FOR_ALL_NOT_IN_TARGET, args.newChangeForAllNotInTarget);
        newProject.setBooleanConfig(BooleanProjectConfig.REQUIRE_CHANGE_ID, args.changeIdRequired);
        newProject.setBooleanConfig(BooleanProjectConfig.REJECT_EMPTY_COMMIT, args.rejectEmptyCommit);
        newProject.setMaxObjectSizeLimit(args.maxObjectSizeLimit);
        newProject.setBooleanConfig(BooleanProjectConfig.ENABLE_SIGNED_PUSH, args.enableSignedPush);
        newProject.setBooleanConfig(BooleanProjectConfig.REQUIRE_SIGNED_PUSH, args.requireSignedPush);
        if (args.newParent != null) {
            newProject.setParentName(args.newParent);
        }
        if (!args.ownerIds.isEmpty()) {
            AccessSection all = config.getAccessSection(AccessSection.ALL, true);
            for (AccountGroup.UUID ownerId : args.ownerIds) {
                GroupDescription.Basic g = groupBackend.get(ownerId);
                if (g != null) {
                    GroupReference group = config.resolve(GroupReference.forGroup(g));
                    all.getPermission(Permission.OWNER, true).add(new PermissionRule(group));
                }
            }
        }
        md.setMessage("Created project\n");
        config.commit(md);
        md.getRepository().setGitwebDescription(args.projectDescription);
    }
    projectCache.onCreateProject(args.getProject());
}
#end_block

#method_before
private void fire(Project.NameKey name, String head) {
    if (!createdListeners.iterator().hasNext()) {
        return;
    }
    Event event = new Event(name, head);
    TraceContext.invokeExtensionPoint(createdListeners, l -> l.onNewProjectCreated(event));
}
#method_after
private void fire(Project.NameKey name, String head) {
    if (createdListeners.isEmpty()) {
        return;
    }
    Event event = new Event(name, head);
    createdListeners.runEach(l -> l.onNewProjectCreated(event));
}
#end_block

#method_before
@Override
public void close() {
    for (Table.Cell<String, String, Boolean> cell : tags.cellSet()) {
        if (cell.getValue()) {
            LoggingContext.getInstance().removeTag(cell.getRowKey(), cell.getColumnKey());
        }
    }
}
#method_after
@Override
public void close() {
    for (Table.Cell<String, String, Boolean> cell : tags.cellSet()) {
        if (cell.getValue()) {
            LoggingContext.getInstance().removeTag(cell.getRowKey(), cell.getColumnKey());
        }
    }
    if (stopForceLoggingOnClose) {
        LoggingContext.getInstance().forceLogging(false);
    }
}
#end_block

