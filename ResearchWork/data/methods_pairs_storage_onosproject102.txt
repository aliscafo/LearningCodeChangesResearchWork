471
#method_before
public String toString() {
    String out = String.format("(%s, %s)\n\tingress: %s ", saddr.toString(), gaddr.toString(), (ingressPoint == null) ? "NULL" : ingressPoint.toString());
    out += "\n\tegress: {\n";
    if (egressPoints != null && !egressPoints.isEmpty()) {
        for (ConnectPoint eg : egressPoints) {
            out += "\t\t" + eg.toString() + "\n";
        }
    }
    out += ("\t}\n");
    return out;
}
#method_after
public String toString() {
    String out = String.format("(%s, %s)\n\t", saddr.toString(), gaddr.toString());
    out += "intent: ";
    out += (intentKey == null) ? "not installed" : this.intentKey.toString();
    out += "\n\tingress: ";
    out += (ingressPoint == null) ? "NULL" : ingressPoint.toString();
    out += "\n\tegress: {\n";
    if (egressPoints != null && !egressPoints.isEmpty()) {
        for (ConnectPoint eg : egressPoints) {
            out += "\t\t" + eg.toString() + "\n";
        }
    }
    out += ("\t}\n");
    return out;
}
#end_block

#method_before
private void addBucketToGroup(NextObjective nextObjective) {
    Collection<TrafficTreatment> treatments = nextObjective.next();
    TrafficTreatment treatment = treatments.iterator().next();
    final GroupKey key = new DefaultGroupKey(appKryo.serialize(nextObjective.id()));
    Group group = groupService.getGroup(deviceId, key);
    GroupBucket bucket;
    if (group.type() == GroupDescription.Type.INDIRECT) {
        bucket = DefaultGroupBucket.createIndirectGroupBucket(treatment);
    } else if (group.type() == GroupDescription.Type.SELECT) {
        bucket = DefaultGroupBucket.createSelectGroupBucket(treatment);
    } else {
        log.warn("Unsupported Group type {}", group.type());
        return;
    }
    GroupBuckets bucketsToAdd = new GroupBuckets(Arrays.asList(bucket));
    groupService.addBucketsToGroup(deviceId, key, bucketsToAdd, key, appId);
}
#method_after
private void addBucketToGroup(NextObjective nextObjective) {
    Collection<TrafficTreatment> treatments = nextObjective.next();
    TrafficTreatment treatment = treatments.iterator().next();
    final GroupKey key = new DefaultGroupKey(appKryo.serialize(nextObjective.id()));
    Group group = groupService.getGroup(deviceId, key);
    if (group == null) {
        log.warn("Group is not found in {} for {}", deviceId, key);
        return;
    }
    GroupBucket bucket;
    if (group.type() == GroupDescription.Type.INDIRECT) {
        bucket = DefaultGroupBucket.createIndirectGroupBucket(treatment);
    } else if (group.type() == GroupDescription.Type.SELECT) {
        bucket = DefaultGroupBucket.createSelectGroupBucket(treatment);
    } else {
        log.warn("Unsupported Group type {}", group.type());
        return;
    }
    GroupBuckets bucketsToAdd = new GroupBuckets(Arrays.asList(bucket));
    groupService.addBucketsToGroup(deviceId, key, bucketsToAdd, key, appId);
}
#end_block

#method_before
private void removeBucketFromGroup(NextObjective nextObjective) {
    NextGroup nextGroup = flowObjectiveStore.getNextGroup(nextObjective.id());
    if (nextGroup != null) {
        Collection<TrafficTreatment> treatments = nextObjective.next();
        TrafficTreatment treatment = treatments.iterator().next();
        final GroupKey key = new DefaultGroupKey(appKryo.serialize(nextObjective.id()));
        Group group = groupService.getGroup(deviceId, key);
        GroupBucket bucket;
        if (group.type() == GroupDescription.Type.INDIRECT) {
            bucket = DefaultGroupBucket.createIndirectGroupBucket(treatment);
        } else if (group.type() == GroupDescription.Type.SELECT) {
            bucket = DefaultGroupBucket.createSelectGroupBucket(treatment);
        } else {
            log.warn("Unsupported Group type {}", group.type());
            return;
        }
        GroupBuckets removeBuckets = new GroupBuckets(Arrays.asList(bucket));
        groupService.removeBucketsFromGroup(deviceId, key, removeBuckets, key, appId);
    }
}
#method_after
private void removeBucketFromGroup(NextObjective nextObjective) {
    NextGroup nextGroup = flowObjectiveStore.getNextGroup(nextObjective.id());
    if (nextGroup != null) {
        Collection<TrafficTreatment> treatments = nextObjective.next();
        TrafficTreatment treatment = treatments.iterator().next();
        final GroupKey key = new DefaultGroupKey(appKryo.serialize(nextObjective.id()));
        Group group = groupService.getGroup(deviceId, key);
        if (group == null) {
            log.warn("Group is not found in {} for {}", deviceId, key);
            return;
        }
        GroupBucket bucket;
        if (group.type() == GroupDescription.Type.INDIRECT) {
            bucket = DefaultGroupBucket.createIndirectGroupBucket(treatment);
        } else if (group.type() == GroupDescription.Type.SELECT) {
            bucket = DefaultGroupBucket.createSelectGroupBucket(treatment);
        } else {
            log.warn("Unsupported Group type {}", group.type());
            return;
        }
        GroupBuckets removeBuckets = new GroupBuckets(Arrays.asList(bucket));
        groupService.removeBucketsFromGroup(deviceId, key, removeBuckets, key, appId);
    }
}
#end_block

#method_before
@Override
public void run() {
    error = null;
    state = State.STARTING;
    try {
        loop();
    } catch (IOException e) {
        error = e;
        log.error("Loop aborted", e);
    }
    notifyDone();
}
#method_after
@Override
public void run() {
    error = null;
    state = State.STARTING;
    try {
        loop();
    } catch (Exception e) {
        error = e;
        log.error("Loop aborted", e);
    }
    notifyDone();
}
#end_block

#method_before
@Activate
public void activate() {
    intentAllocMap = storageService.<IntentId, LinkResourceAllocations>consistentMapBuilder().withName(INTENT_ALLOCATIONS).withSerializer(SERIALIZER).build();
    linkAllocMap = storageService.<LinkKey, List<LinkResourceAllocations>>consistentMapBuilder().withName(LINK_RESOURCE_ALLOCATIONS).withSerializer(SERIALIZER).build();
    log.info("Started");
}
#method_after
@Activate
public void activate() {
    intentAllocMap = storageService.<IntentId, LinkResourceAllocations>consistentMapBuilder().withName(INTENT_ALLOCATIONS).withSerializer(SERIALIZER).build();
    log.info("Started");
}
#end_block

#method_before
private Set<? extends ResourceAllocation> getResourceCapacity(ResourceType type, Link link) {
    if (type == ResourceType.BANDWIDTH) {
        return ImmutableSet.of(getBandwidthResourceCapacity(link));
    }
    if (type == ResourceType.LAMBDA) {
        return getLambdaResourceCapacity(link);
    }
    if (type == ResourceType.MPLS_LABEL) {
        return getMplsResourceCapacity();
    }
    return null;
}
#method_after
private Set<? extends ResourceAllocation> getResourceCapacity(ResourceType type, Link link) {
    if (type == ResourceType.BANDWIDTH) {
        return ImmutableSet.of(getBandwidthResourceCapacity(link));
    }
    if (type == ResourceType.LAMBDA) {
        return getLambdaResourceCapacity(link);
    }
    if (type == ResourceType.MPLS_LABEL) {
        return getMplsResourceCapacity();
    }
    return ImmutableSet.of();
}
#end_block

#method_before
private Set<LambdaResourceAllocation> getLambdaResourceCapacity(Link link) {
    Set<LambdaResourceAllocation> allocations = new HashSet<>();
    try {
        final int waves = Integer.parseInt(link.annotations().value(OPTICAL_WAVES));
        for (int i = 1; i <= waves; i++) {
            allocations.add(new LambdaResourceAllocation(Lambda.valueOf(i)));
        }
    } catch (NumberFormatException e) {
        log.debug("No {} annotation on link %s", OPTICAL_WAVES, link);
    }
    return allocations;
}
#method_after
private Set<LambdaResourceAllocation> getLambdaResourceCapacity(Link link) {
    Set<LambdaResourceAllocation> allocations = new HashSet<>();
    try {
        final int waves = Integer.parseInt(link.annotations().value(OPTICAL_WAVES));
        for (int i = 1; i <= waves; i++) {
            allocations.add(new LambdaResourceAllocation(Lambda.valueOf(i)));
        }
    } catch (NumberFormatException e) {
        log.debug("No {} annotation on link {}", OPTICAL_WAVES, link);
    }
    return allocations;
}
#end_block

#method_before
private Set<MplsLabelResourceAllocation> getMplsResourceCapacity() {
    Set<MplsLabelResourceAllocation> allocations = new HashSet<>();
    // Ignoring reserved labels of 0 through 15
    for (int i = UNRESERVED; i <= MAX_MPLS_LABEL; i++) {
        allocations.add(new MplsLabelResourceAllocation(MplsLabel.valueOf(i)));
    }
    return allocations;
}
#method_after
private Set<MplsLabelResourceAllocation> getMplsResourceCapacity() {
    Set<MplsLabelResourceAllocation> allocations = new HashSet<>();
    // Ignoring reserved labels of 0 through 15
    for (int i = MIN_UNRESERVED_LABEL; i <= MAX_UNRESERVED_LABEL; i++) {
        allocations.add(new MplsLabelResourceAllocation(MplsLabel.valueOf(i)));
    }
    return allocations;
}
#end_block

#method_before
@Override
public Set<ResourceAllocation> getFreeResources(Link link) {
    TransactionContext tx = storageService.createTransactionContext();
    tx.begin();
    try {
        Map<ResourceType, Set<? extends ResourceAllocation>> freeResources = getFreeResourcesEx(tx, link);
        Set<ResourceAllocation> allFree = new HashSet<>();
        freeResources.values().forEach(allFree::addAll);
        return allFree;
    } finally {
        tx.abort();
    }
}
#method_after
@Override
public Set<ResourceAllocation> getFreeResources(Link link) {
    TransactionContext tx = getTxContext();
    tx.begin();
    try {
        Map<ResourceType, Set<? extends ResourceAllocation>> freeResources = getFreeResourcesEx(tx, link);
        Set<ResourceAllocation> allFree = new HashSet<>();
        freeResources.values().forEach(allFree::addAll);
        return allFree;
    } finally {
        tx.abort();
    }
}
#end_block

#method_before
@Override
public void allocateResources(LinkResourceAllocations allocations) {
    checkNotNull(allocations);
    TransactionContext tx = storageService.createTransactionContext();
    tx.begin();
    try {
        TransactionalMap<IntentId, LinkResourceAllocations> intentAllocs = getIntentAllocs(tx);
        intentAllocs.put(allocations.intentId(), allocations);
        allocations.links().forEach(link -> allocateLinkResource(tx, link, allocations));
        tx.commit();
    } catch (TransactionException e) {
        log.error("Exception thrown, rolling back", e);
        tx.abort();
        throw e;
    }
}
#method_after
@Override
public void allocateResources(LinkResourceAllocations allocations) {
    checkNotNull(allocations);
    TransactionContext tx = getTxContext();
    tx.begin();
    try {
        TransactionalMap<IntentId, LinkResourceAllocations> intentAllocs = getIntentAllocs(tx);
        intentAllocs.put(allocations.intentId(), allocations);
        allocations.links().forEach(link -> allocateLinkResource(tx, link, allocations));
        tx.commit();
    } catch (Exception e) {
        log.error("Exception thrown, rolling back", e);
        tx.abort();
        throw e;
    }
}
#end_block

#method_before
@Override
public LinkResourceEvent releaseResources(LinkResourceAllocations allocations) {
    checkNotNull(allocations);
    final IntentId intentId = allocations.intentId();
    final Collection<Link> links = allocations.links();
    boolean success = false;
    do {
        TransactionContext tx = storageService.createTransactionContext();
        tx.begin();
        try {
            TransactionalMap<IntentId, LinkResourceAllocations> intentAllocs = getIntentAllocs(tx);
            intentAllocs.remove(intentId);
            TransactionalMap<LinkKey, List<LinkResourceAllocations>> linkAllocs = getLinkAllocs(tx);
            links.forEach(link -> {
                final LinkKey linkId = LinkKey.linkKey(link);
                List<LinkResourceAllocations> before = linkAllocs.get(linkId);
                if (before == null || before.isEmpty()) {
                    // something is wrong, but it is already freed
                    log.warn("There was no resource left to release on {}", linkId);
                    return;
                }
                List<LinkResourceAllocations> after = new ArrayList<>(before);
                after.remove(allocations);
                linkAllocs.replace(linkId, before, after);
            });
            tx.commit();
            success = true;
        } catch (TransactionException e) {
            log.debug("Transaction failed, retrying", e);
        } catch (Exception e) {
            log.error("Exception thrown during releaseResource {}", allocations, e);
            tx.abort();
            throw e;
        }
    } while (!success);
    // Issue events to force recompilation of intents.
    final List<LinkResourceAllocations> releasedResources = ImmutableList.of(allocations);
    return new LinkResourceEvent(LinkResourceEvent.Type.ADDITIONAL_RESOURCES_AVAILABLE, releasedResources);
}
#method_after
@Override
public LinkResourceEvent releaseResources(LinkResourceAllocations allocations) {
    checkNotNull(allocations);
    final IntentId intentId = allocations.intentId();
    final Collection<Link> links = allocations.links();
    boolean success = false;
    do {
        TransactionContext tx = getTxContext();
        tx.begin();
        try {
            TransactionalMap<IntentId, LinkResourceAllocations> intentAllocs = getIntentAllocs(tx);
            intentAllocs.remove(intentId);
            TransactionalMap<LinkKey, List<LinkResourceAllocations>> linkAllocs = getLinkAllocs(tx);
            links.forEach(link -> {
                final LinkKey linkId = LinkKey.linkKey(link);
                List<LinkResourceAllocations> before = linkAllocs.get(linkId);
                if (before == null || before.isEmpty()) {
                    // something is wrong, but it is already freed
                    log.warn("There was no resource left to release on {}", linkId);
                    return;
                }
                List<LinkResourceAllocations> after = new ArrayList<>(before);
                after.remove(allocations);
                linkAllocs.replace(linkId, before, after);
            });
            tx.commit();
            success = true;
        } catch (TransactionException e) {
            log.debug("Transaction failed, retrying", e);
            tx.abort();
        } catch (Exception e) {
            log.error("Exception thrown during releaseResource {}", allocations, e);
            tx.abort();
            throw e;
        }
    } while (!success);
    // Issue events to force recompilation of intents.
    final List<LinkResourceAllocations> releasedResources = ImmutableList.of(allocations);
    return new LinkResourceEvent(LinkResourceEvent.Type.ADDITIONAL_RESOURCES_AVAILABLE, releasedResources);
}
#end_block

#method_before
@Override
public Iterable<LinkResourceAllocations> getAllocations(Link link) {
    checkNotNull(link);
    TransactionContext tx = storageService.createTransactionContext();
    Iterable<LinkResourceAllocations> res = null;
    tx.begin();
    try {
        res = getAllocations(tx, link);
    } finally {
        tx.abort();
    }
    return res == null ? Collections.emptyList() : res;
}
#method_after
@Override
public Iterable<LinkResourceAllocations> getAllocations(Link link) {
    checkNotNull(link);
    TransactionContext tx = getTxContext();
    Iterable<LinkResourceAllocations> res = null;
    tx.begin();
    try {
        res = getAllocations(tx, link);
    } finally {
        tx.abort();
    }
    return res == null ? Collections.emptyList() : res;
}
#end_block

#method_before
@Override
public Iterable<LinkResourceAllocations> getAllocations() {
    try {
        Set<LinkResourceAllocations> allocs = intentAllocMap.values().stream().map(v -> v.value()).collect(Collectors.toSet());
        return ImmutableSet.copyOf(allocs);
    } catch (Exception e) {
        log.warn("Could not read resource allocation information", e);
    }
    return ImmutableSet.of();
}
#method_after
@Override
public Iterable<LinkResourceAllocations> getAllocations() {
    try {
        Set<LinkResourceAllocations> allocs = intentAllocMap.values().stream().map(Versioned::value).collect(Collectors.toSet());
        return ImmutableSet.copyOf(allocs);
    } catch (Exception e) {
        log.warn("Could not read resource allocation information", e);
    }
    return ImmutableSet.of();
}
#end_block

#method_before
@Override
protected void execute() {
    LinkResourceService resourceService = get(LinkResourceService.class);
    LinkService linkService = get(LinkService.class);
    Iterable<LinkResourceAllocations> itr = null;
    if (srcString == null || dstString == null) {
        itr = resourceService.getAllocations();
        print("----- Displaying all resource allocations -----");
        for (LinkResourceAllocations allocation : itr) {
            print("%s", allocation);
        }
        return;
    }
    DeviceId ingressDeviceId = deviceId(getDeviceId(srcString));
    PortNumber ingressPortNumber = portNumber(getPortNumber(srcString));
    ConnectPoint src = new ConnectPoint(ingressDeviceId, ingressPortNumber);
    DeviceId egressDeviceId = deviceId(getDeviceId(dstString));
    PortNumber egressPortNumber = portNumber(getPortNumber(dstString));
    ConnectPoint dst = new ConnectPoint(egressDeviceId, egressPortNumber);
    Link link = linkService.getLink(src, dst);
    if (link != null) {
        itr = resourceService.getAllocations(link);
        for (LinkResourceAllocations allocation : itr) {
            print("%s", allocation.getResourceAllocation(link));
        }
    }
}
#method_after
@Override
protected void execute() {
    LinkResourceService resourceService = get(LinkResourceService.class);
    LinkService linkService = get(LinkService.class);
    if (srcString == null || dstString == null) {
        print("----- Displaying all resource allocations -----");
        resourceService.getAllocations().forEach(alloc -> print("%s", alloc));
        return;
    }
    ConnectPoint src = ConnectPoint.deviceConnectPoint(srcString);
    ConnectPoint dst = ConnectPoint.deviceConnectPoint(dstString);
    Link link = linkService.getLink(src, dst);
    if (link != null) {
        resourceService.getAllocations(link).forEach(alloc -> print("%s", alloc));
    } else {
        print("No path found for endpoints: %s, %s", src, dst);
    }
}
#end_block

#method_before
public short channelSpacing() {
    return channelSpacing;
}
#method_after
public ChannelSpacing channelSpacing() {
    return channelSpacing;
}
#end_block

#method_before
public double slotWidth() {
    return m * 12.5;
}
#method_after
public Frequency slotWidth() {
    return FLEX_GRID_SLOT.multiply(slotGranularity);
}
#end_block

#method_before
@Override
public int hashCode() {
    return Objects.hash(number(), isEnabled(), type(), signalType, isWavelengthTunable, gridType, channelSpacing, n, m);
}
#method_after
@Override
public int hashCode() {
    return Objects.hash(number(), isEnabled(), type(), signalType, isTunable, gridType, channelSpacing, spacingMultiplier, slotGranularity, annotations());
}
#end_block

#method_before
@Override
public boolean equals(Object obj) {
    if (this == obj) {
        return true;
    }
    if (obj instanceof OchPort) {
        final OchPort other = (OchPort) obj;
        return Objects.equals(this.element().id(), other.element().id()) && Objects.equals(this.number(), other.number()) && Objects.equals(this.isEnabled(), other.isEnabled()) && Objects.equals(this.signalType, other.signalType) && Objects.equals(this.isWavelengthTunable, other.isWavelengthTunable) && Objects.equals(this.gridType, other.gridType) && Objects.equals(this.channelSpacing, other.channelSpacing) && Objects.equals(this.n, other.n) && Objects.equals(this.m, other.m);
    }
    return false;
}
#method_after
@Override
public boolean equals(Object obj) {
    if (this == obj) {
        return true;
    }
    if (obj instanceof OchPort) {
        final OchPort other = (OchPort) obj;
        return Objects.equals(this.element().id(), other.element().id()) && Objects.equals(this.number(), other.number()) && Objects.equals(this.isEnabled(), other.isEnabled()) && Objects.equals(this.signalType, other.signalType) && Objects.equals(this.isTunable, other.isTunable) && Objects.equals(this.gridType, other.gridType) && Objects.equals(this.channelSpacing, other.channelSpacing) && Objects.equals(this.spacingMultiplier, other.spacingMultiplier) && Objects.equals(this.slotGranularity, other.slotGranularity) && Objects.equals(this.annotations(), other.annotations());
    }
    return false;
}
#end_block

#method_before
@Override
public String toString() {
    return toStringHelper(this).add("element", element().id()).add("number", number()).add("isEnabled", isEnabled()).add("type", type()).add("signalType", signalType).add("isWavelengthTunable", isWavelengthTunable).add("gridType", gridType).add("channelSpacing", channelSpacing).add("n", n).add("m", m).toString();
}
#method_after
@Override
public String toString() {
    return toStringHelper(this).add("element", element().id()).add("number", number()).add("isEnabled", isEnabled()).add("type", type()).add("signalType", signalType).add("isTunable", isTunable).add("gridType", gridType).add("channelSpacing", channelSpacing).add("spacingMultiplier", spacingMultiplier).add("slotGranularity", slotGranularity).toString();
}
#end_block

#method_before
public long grid() {
    return grid;
}
#method_after
public Frequency grid() {
    return grid;
}
#end_block

#method_before
@Override
public String toString() {
    return MoreObjects.toStringHelper(getClass()).add("number", portNumber()).add("isEnabled", isEnabled()).add("type", type()).add("minFreq", minFreq).add("maxFreq", maxFreq).add("grid", grid).add("annotations", annotations()).toString();
}
#method_after
@Override
public String toString() {
    return MoreObjects.toStringHelper(getClass()).add("number", portNumber()).add("isEnabled", isEnabled()).add("type", type()).add("minFrequency", minFrequency).add("maxFrequency", maxFrequency).add("grid", grid).add("annotations", annotations()).toString();
}
#end_block

#method_before
@Override
public int hashCode() {
    return Objects.hash(number(), isEnabled(), type(), signalType);
}
#method_after
@Override
public int hashCode() {
    return Objects.hash(number(), isEnabled(), type(), signalType, annotations());
}
#end_block

#method_before
@Override
public boolean equals(Object obj) {
    if (this == obj) {
        return true;
    }
    if (obj instanceof OduCltPort) {
        final OduCltPort other = (OduCltPort) obj;
        return Objects.equals(this.element().id(), other.element().id()) && Objects.equals(this.number(), other.number()) && Objects.equals(this.isEnabled(), other.isEnabled()) && Objects.equals(this.signalType, other.signalType);
    }
    return false;
}
#method_after
@Override
public boolean equals(Object obj) {
    if (this == obj) {
        return true;
    }
    if (obj instanceof OduCltPort) {
        final OduCltPort other = (OduCltPort) obj;
        return Objects.equals(this.element().id(), other.element().id()) && Objects.equals(this.number(), other.number()) && Objects.equals(this.isEnabled(), other.isEnabled()) && Objects.equals(this.signalType, other.signalType) && Objects.equals(this.annotations(), other.annotations());
    }
    return false;
}
#end_block

#method_before
public short channelSpacing() {
    return channelSpacing;
}
#method_after
public OchPort.ChannelSpacing channelSpacing() {
    return channelSpacing;
}
#end_block

#method_before
@Override
public String toString() {
    return MoreObjects.toStringHelper(getClass()).add("number", portNumber()).add("isEnabled", isEnabled()).add("type", type()).add("signalType", signalType).add("isWavelengthTunable", isWavelengthTunable).add("gridType", gridType).add("channelSpacing", channelSpacing).add("n", n).add("m", m).add("annotations", annotations()).toString();
}
#method_after
@Override
public String toString() {
    return MoreObjects.toStringHelper(getClass()).add("number", portNumber()).add("isEnabled", isEnabled()).add("type", type()).add("signalType", signalType).add("isTunable", isTunable).add("gridType", gridType).add("channelSpacing", channelSpacing).add("spacingMultiplier", spacingMultiplier).add("slotGranularity", slotGranularity).add("annotations", annotations()).toString();
}
#end_block

#method_before
public short totalChannels() {
    return (short) ((maxFreq - minFreq) / (grid + 1));
}
#method_after
public short totalChannels() {
    Frequency diff = maxFrequency.subtract(minFrequency);
    return (short) (diff.asHz() / (grid.asHz() + 1));
}
#end_block

#method_before
public long grid() {
    return grid;
}
#method_after
public Frequency grid() {
    return grid;
}
#end_block

#method_before
@Override
public int hashCode() {
    return Objects.hash(number(), isEnabled(), type(), minFreq, maxFreq, grid);
}
#method_after
@Override
public int hashCode() {
    return Objects.hash(number(), isEnabled(), type(), minFrequency, maxFrequency, grid, annotations());
}
#end_block

#method_before
@Override
public boolean equals(Object obj) {
    if (this == obj) {
        return true;
    }
    if (obj instanceof OmsPort) {
        final OmsPort other = (OmsPort) obj;
        return Objects.equals(this.element().id(), other.element().id()) && Objects.equals(this.number(), other.number()) && Objects.equals(this.isEnabled(), other.isEnabled()) && Objects.equals(this.minFreq, other.minFreq) && Objects.equals(this.maxFreq, other.maxFreq) && Objects.equals(this.grid, other.grid);
    }
    return false;
}
#method_after
@Override
public boolean equals(Object obj) {
    if (this == obj) {
        return true;
    }
    if (obj instanceof OmsPort) {
        final OmsPort other = (OmsPort) obj;
        return Objects.equals(this.element().id(), other.element().id()) && Objects.equals(this.number(), other.number()) && Objects.equals(this.isEnabled(), other.isEnabled()) && Objects.equals(this.minFrequency, other.minFrequency) && Objects.equals(this.maxFrequency, other.maxFrequency) && Objects.equals(this.grid, other.grid) && Objects.equals(this.annotations(), other.annotations());
    }
    return false;
}
#end_block

#method_before
@Override
public String toString() {
    return toStringHelper(this).add("element", element().id()).add("number", number()).add("isEnabled", isEnabled()).add("type", type()).add("minFreq", minFreq).add("maxFreq", maxFreq).add("grid", grid).toString();
}
#method_after
@Override
public String toString() {
    return toStringHelper(this).add("element", element().id()).add("number", number()).add("isEnabled", isEnabled()).add("type", type()).add("minFrequency", minFrequency).add("maxFrequency", maxFrequency).add("grid", grid).toString();
}
#end_block

#method_before
@Activate
protected void activate() {
    appId = coreService.registerApplication("org.onosproject.segmentrouting");
    networkConfigService.init();
    deviceConfiguration = new DeviceConfiguration(networkConfigService);
    networkConfigHandler = new NetworkConfigHandler(this, deviceConfiguration);
    arpHandler = new ArpHandler(this);
    icmpHandler = new IcmpHandler(this);
    ipHandler = new IpHandler(this);
    routingRulePopulator = new RoutingRulePopulator(this);
    defaultRoutingHandler = new DefaultRoutingHandler(this);
    packetService.addProcessor(processor, PacketProcessor.ADVISOR_MAX + 2);
    linkService.addListener(new InternalLinkListener());
    // groupService.addListener(new InternalGroupListener());
    deviceService.addListener(new InternalDeviceListener());
    for (Device device : deviceService.getDevices()) {
        if (mastershipService.getLocalRole(device.id()) == MastershipRole.MASTER) {
            DefaultGroupHandler groupHandler = DefaultGroupHandler.createGroupHandler(device.id(), appId, deviceConfiguration, linkService, null);
            groupHandler.createGroups();
            groupHandlerMap.put(device.id(), groupHandler);
            log.debug("Initiating default group handling for {}", device.id());
            defaultRoutingHandler.startPopulationProcess();
        } else {
            log.debug("Activate: Local role {} " + "is not MASTER for device {}", mastershipService.getLocalRole(device.id()), device.id());
        }
    }
    log.info("Started");
}
#method_after
@Activate
protected void activate() {
    appId = coreService.registerApplication("org.onosproject.segmentrouting");
    networkConfigService.init();
    deviceConfiguration = new DeviceConfiguration(networkConfigService);
    arpHandler = new ArpHandler(this);
    icmpHandler = new IcmpHandler(this);
    ipHandler = new IpHandler(this);
    routingRulePopulator = new RoutingRulePopulator(this);
    defaultRoutingHandler = new DefaultRoutingHandler(this);
    packetService.addProcessor(processor, PacketProcessor.ADVISOR_MAX + 2);
    linkService.addListener(new InternalLinkListener());
    deviceService.addListener(new InternalDeviceListener());
    for (Device device : deviceService.getDevices()) {
        if (mastershipService.getLocalRole(device.id()) == MastershipRole.MASTER) {
            DefaultGroupHandler groupHandler = DefaultGroupHandler.createGroupHandler(device.id(), appId, deviceConfiguration, linkService, flowObjectiveService);
            groupHandlerMap.put(device.id(), groupHandler);
            defaultRoutingHandler.populateTtpRules(device.id());
            log.debug("Initiating default group handling for {}", device.id());
        } else {
            log.debug("Activate: Local role {} " + "is not MASTER for device {}", mastershipService.getLocalRole(device.id()), device.id());
        }
    }
    defaultRoutingHandler.startPopulationProcess();
    log.info("Started");
}
#end_block

#method_before
public int getNextObjectiveId(DeviceId deviceId, GroupKey key) {
    return (groupHandlerMap.get(deviceId) != null) ? groupHandlerMap.get(deviceId).getNextObjectiveId(key) : -1;
}
#method_after
public int getNextObjectiveId(DeviceId deviceId, NeighborSet ns) {
    return (groupHandlerMap.get(deviceId) != null) ? groupHandlerMap.get(deviceId).getNextObjectiveId(ns) : -1;
}
#end_block

#method_before
@Override
public void event(DeviceEvent event) {
    if (mastershipService.getLocalRole(event.subject().id()) != MastershipRole.MASTER) {
        log.debug("Local role {} is not MASTER for device {}", mastershipService.getLocalRole(event.subject().id()), event.subject().id());
        return;
    }
    switch(event.type()) {
        case DEVICE_ADDED:
        case PORT_REMOVED:
            scheduleEventHandlerIfNotScheduled(event);
            break;
        default:
    }
}
#method_after
@Override
public void event(DeviceEvent event) {
    if (mastershipService.getLocalRole(event.subject().id()) != MastershipRole.MASTER) {
        log.debug("Local role {} is not MASTER for device {}", mastershipService.getLocalRole(event.subject().id()), event.subject().id());
        return;
    }
    switch(event.type()) {
        case DEVICE_ADDED:
        case PORT_REMOVED:
        case DEVICE_UPDATED:
        case DEVICE_AVAILABILITY_CHANGED:
            scheduleEventHandlerIfNotScheduled(event);
            break;
        default:
    }
}
#end_block

#method_before
@Override
public void run() {
    numOfHandlerExecution++;
    while (!eventQueue.isEmpty()) {
        Event event = eventQueue.poll();
        if (event.type() == LinkEvent.Type.LINK_ADDED) {
            processLinkAdded((Link) event.subject());
        } else if (event.type() == LinkEvent.Type.LINK_REMOVED) {
            processLinkRemoved((Link) event.subject());
        } else if (event.type() == GroupEvent.Type.GROUP_ADDED) {
            processGroupAdded((Group) event.subject());
        } else if (event.type() == DeviceEvent.Type.DEVICE_ADDED) {
            processDeviceAdded((Device) event.subject());
        } else if (event.type() == DeviceEvent.Type.PORT_REMOVED) {
            processPortRemoved((Device) event.subject(), ((DeviceEvent) event).port());
        } else {
            log.warn("Unhandled event type: {}", event.type());
        }
    }
    log.debug("numOfHandlerExecution {} numOfEventHanlderScheduled {} numOfEvents {}", numOfHandlerExecution, numOfHandlerScheduled, numOfEvents);
}
#method_after
@Override
public void run() {
    numOfHandlerExecution++;
    while (!eventQueue.isEmpty()) {
        Event event = eventQueue.poll();
        if (event.type() == LinkEvent.Type.LINK_ADDED) {
            processLinkAdded((Link) event.subject());
        } else if (event.type() == LinkEvent.Type.LINK_REMOVED) {
            processLinkRemoved((Link) event.subject());
        } else if (event.type() == GroupEvent.Type.GROUP_ADDED) {
            processGroupAdded((Group) event.subject());
        } else if (event.type() == DeviceEvent.Type.DEVICE_ADDED || event.type() == DeviceEvent.Type.DEVICE_AVAILABILITY_CHANGED || event.type() == DeviceEvent.Type.DEVICE_UPDATED) {
            if (deviceService.isAvailable(((Device) event.subject()).id())) {
                processDeviceAdded((Device) event.subject());
            }
        } else if (event.type() == DeviceEvent.Type.PORT_REMOVED) {
            processPortRemoved((Device) event.subject(), ((DeviceEvent) event).port());
        } else {
            log.warn("Unhandled event type: {}", event.type());
        }
    }
    log.debug("numOfHandlerExecution {} numOfEventHanlderScheduled {} numOfEvents {}", numOfHandlerExecution, numOfHandlerScheduled, numOfEvents);
}
#end_block

#method_before
private void processLinkAdded(Link link) {
    log.debug("A new link {} was added", link.toString());
    if (mastershipService.getLocalRole(link.src().deviceId()) == MastershipRole.MASTER) {
        DefaultGroupHandler groupHandler = groupHandlerMap.get(link.src().deviceId());
        if (groupHandler != null) {
            groupHandler.linkUp(link);
        }
    }
    defaultRoutingHandler.startPopulationProcess();
}
#method_after
private void processLinkAdded(Link link) {
    log.debug("A new link {} was added", link.toString());
    if (mastershipService.getLocalRole(link.src().deviceId()) == MastershipRole.MASTER) {
        DefaultGroupHandler groupHandler = groupHandlerMap.get(link.src().deviceId());
        if (groupHandler != null) {
            groupHandler.linkUp(link);
        }
    }
    defaultRoutingHandler.populateRoutingRulesForLinkStatusChange(null);
}
#end_block

#method_before
private void processLinkRemoved(Link link) {
    log.debug("A link {} was removed", link.toString());
    defaultRoutingHandler.startPopulationProcess();
}
#method_after
private void processLinkRemoved(Link link) {
    log.debug("A link {} was removed", link.toString());
    defaultRoutingHandler.populateRoutingRulesForLinkStatusChange(link);
}
#end_block

#method_before
private void processDeviceAdded(Device device) {
    log.debug("A new device with ID {} was added", device.id());
    defaultRoutingHandler.populateTtpRules(device.id());
    DefaultGroupHandler dgh = DefaultGroupHandler.createGroupHandler(device.id(), appId, deviceConfiguration, linkService, null);
    dgh.createGroups();
    groupHandlerMap.put(device.id(), dgh);
}
#method_after
private void processDeviceAdded(Device device) {
    log.debug("A new device with ID {} was added", device.id());
    defaultRoutingHandler.populateTtpRules(device.id());
    DefaultGroupHandler dgh = DefaultGroupHandler.createGroupHandler(device.id(), appId, deviceConfiguration, linkService, flowObjectiveService);
    groupHandlerMap.put(device.id(), dgh);
}
#end_block

#method_before
public static DefaultGroupHandler createGroupHandler(DeviceId deviceId, ApplicationId appId, DeviceProperties config, LinkService linkService, GroupService groupService) {
    if (config.isEdgeDevice(deviceId)) {
        return new DefaultEdgeGroupHandler(deviceId, appId, config, linkService, groupService);
    } else {
        return new DefaultTransitGroupHandler(deviceId, appId, config, linkService, groupService);
    }
}
#method_after
public static DefaultGroupHandler createGroupHandler(DeviceId deviceId, ApplicationId appId, DeviceProperties config, LinkService linkService, FlowObjectiveService flowObjService) {
    if (config.isEdgeDevice(deviceId)) {
        return new DefaultEdgeGroupHandler(deviceId, appId, config, linkService, flowObjService);
    } else {
        return new DefaultTransitGroupHandler(deviceId, appId, config, linkService, flowObjService);
    }
}
#end_block

#method_before
public void portDown(PortNumber port) {
    if (portDeviceMap.get(port) == null) {
        log.warn("portDown: unknown port");
        return;
    }
    log.debug("Device {} portDown {} to neighbor {}", deviceId, port, portDeviceMap.get(port));
    Set<NeighborSet> nsSet = computeImpactedNeighborsetForPortEvent(portDeviceMap.get(port), devicePortMap.keySet());
    for (NeighborSet ns : nsSet) {
        // Create the bucket to be removed
        TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
        tBuilder.setOutput(port).setEthDst(deviceConfig.getDeviceMac(portDeviceMap.get(port))).setEthSrc(nodeMacAddr);
        if (ns.getEdgeLabel() != NeighborSet.NO_EDGE_LABEL) {
            tBuilder.pushMpls().setMpls(MplsLabel.mplsLabel(ns.getEdgeLabel()));
        }
    /*
             * GroupBucket removeBucket = DefaultGroupBucket.
             * createSelectGroupBucket(tBuilder.build()); GroupBuckets
             * removeBuckets = new GroupBuckets( Arrays.asList(removeBucket));
             * log.debug("portDown in device{}: " +
             * "groupService.removeBucketsFromGroup " + "for neighborset{}",
             * deviceId, ns); groupService.removeBucketsFromGroup(deviceId,
             * getGroupKey(ns), removeBuckets, getGroupKey(ns), appId);
             */
    }
    devicePortMap.get(portDeviceMap.get(port)).remove(port);
    portDeviceMap.remove(port);
}
#method_after
public void portDown(PortNumber port) {
    if (portDeviceMap.get(port) == null) {
        log.warn("portDown: unknown port");
        return;
    }
    log.debug("Device {} portDown {} to neighbor {}", deviceId, port, portDeviceMap.get(port));
    Set<NeighborSet> nsSet = computeImpactedNeighborsetForPortEvent(portDeviceMap.get(port), devicePortMap.keySet());
    for (NeighborSet ns : nsSet) {
        // Create the bucket to be removed
        TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
        tBuilder.setOutput(port).setEthDst(deviceConfig.getDeviceMac(portDeviceMap.get(port))).setEthSrc(nodeMacAddr);
        if (ns.getEdgeLabel() != NeighborSet.NO_EDGE_LABEL) {
            tBuilder.pushMpls().setMpls(MplsLabel.mplsLabel(ns.getEdgeLabel()));
        }
    /*
             * GroupBucket removeBucket = DefaultGroupBucket.
             * createSelectGroupBucket(tBuilder.build()); GroupBuckets
             * removeBuckets = new GroupBuckets( Arrays.asList(removeBucket));
             * log.debug("portDown in device{}: " +
             * "groupService.removeBucketsFromGroup " + "for neighborset{}",
             * deviceId, ns); groupService.removeBucketsFromGroup(deviceId,
             * getGroupKey(ns), removeBuckets, getGroupKey(ns), appId);
             */
    // TODO: Use next objective API to update the previously created
    // next objectives.
    }
    devicePortMap.get(portDeviceMap.get(port)).remove(port);
    portDeviceMap.remove(port);
}
#end_block

#method_before
public int getNextObjectiveId(GroupKey key) {
    Integer nextId = deviceNextObjectiveIds.get(key);
    return (nextId != null) ? nextId.intValue() : -1;
}
#method_after
public int getNextObjectiveId(NeighborSet ns) {
    Integer nextId = deviceNextObjectiveIds.get(getGroupKey(ns));
    if (nextId == null) {
        createGroupsFromNeighborsets(Collections.singleton(ns));
        nextId = deviceNextObjectiveIds.get(getGroupKey(ns));
        if (nextId == null) {
            log.warn("getNextObjectiveId: unable to create next objective");
            return -1;
        }
    }
    return nextId.intValue();
}
#end_block

#method_before
protected void createGroupsFromNeighborsets(Set<NeighborSet> nsSet) {
    for (NeighborSet ns : nsSet) {
        // Create the bucket array from the neighbor set
        // List<GroupBucket> buckets = new ArrayList<GroupBucket>();
        int nextId = flowObjectiveService.allocateNextId();
        NextObjective.Builder nextObjBuilder = DefaultNextObjective.builder().withId(nextId).withType(NextObjective.Type.HASHED).fromApp(appId);
        for (DeviceId d : ns.getDeviceIds()) {
            for (PortNumber sp : devicePortMap.get(d)) {
                TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
                tBuilder.setOutput(sp).setEthDst(deviceConfig.getDeviceMac(d)).setEthSrc(nodeMacAddr);
                if (ns.getEdgeLabel() != NeighborSet.NO_EDGE_LABEL) {
                    tBuilder.pushMpls().setMpls(MplsLabel.mplsLabel(ns.getEdgeLabel()));
                }
                /*
                     * buckets.add(DefaultGroupBucket.createSelectGroupBucket(
                     * tBuilder.build()));
                     */
                nextObjBuilder.addTreatment(tBuilder.build());
            }
        }
        NextObjective nextObj = nextObjBuilder.add();
        flowObjectiveService.next(deviceId, nextObj);
        deviceNextObjectiveIds.put(getGroupKey(ns), nextId);
    /*
             * GroupBuckets groupBuckets = new GroupBuckets(buckets);
             * GroupDescription newGroupDesc = new DefaultGroupDescription(
             * deviceId, Group.Type.SELECT, groupBuckets, getGroupKey(ns),
             * appId); log.debug("createGroupsFromNeighborsets: " +
             * "groupService.addGroup for neighborset{}", ns);
             * groupService.addGroup(newGroupDesc);
             */
    }
}
#method_after
protected void createGroupsFromNeighborsets(Set<NeighborSet> nsSet) {
    for (NeighborSet ns : nsSet) {
        int nextId = flowObjectiveService.allocateNextId();
        NextObjective.Builder nextObjBuilder = DefaultNextObjective.builder().withId(nextId).withType(NextObjective.Type.HASHED).fromApp(appId);
        for (DeviceId d : ns.getDeviceIds()) {
            for (PortNumber sp : devicePortMap.get(d)) {
                TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
                tBuilder.setOutput(sp).setEthDst(deviceConfig.getDeviceMac(d)).setEthSrc(nodeMacAddr);
                if (ns.getEdgeLabel() != NeighborSet.NO_EDGE_LABEL) {
                    tBuilder.pushMpls().setMpls(MplsLabel.mplsLabel(ns.getEdgeLabel()));
                }
                nextObjBuilder.addTreatment(tBuilder.build());
            }
        }
        NextObjective nextObj = nextObjBuilder.add();
        flowObjectiveService.next(deviceId, nextObj);
        deviceNextObjectiveIds.put(getGroupKey(ns), nextId);
    }
}
#end_block

#method_before
// TODO: Knock off once the migration to flow objective is complete
/*
     * protected void handleGroupEvent(GroupEvent event) { switch (event.type())
     * { case GROUP_ADDED: log.debug("Received GROUP_ADDED from group service "
     * + "for device {} with group key{} with id{}", event.subject().deviceId(),
     * event.subject().appCookie(), event.subject().id()); break; case
     * GROUP_UPDATED: log.trace("Received GROUP_UPDATED from group service " +
     * "for device {} with group key{} with id{}", event.subject().deviceId(),
     * event.subject().appCookie(), event.subject().id()); break; case
     * GROUP_REMOVED: log.debug("Received GROUP_REMOVED from group service " +
     * "for device {} with group key{} with id{}", event.subject().deviceId(),
     * event.subject().appCookie(), event.subject().id()); break; default:
     * break; } }
     *
     * private class InternalGroupListener implements GroupListener {
     *
     * @Override public void event(GroupEvent event) { handleGroupEvent(event);
     * } }
     */
public GroupKey getGroupKey(Object obj) {
    return new DefaultGroupKey(kryo.build().serialize(obj));
}
#method_after
public GroupKey getGroupKey(Object obj) {
    return new DefaultGroupKey(kryo.build().serialize(obj));
}
#end_block

#method_before
public void populateIpRuleForHost(DeviceId deviceId, Ip4Address hostIp, MacAddress hostMac, PortNumber outPort) {
    TrafficSelector.Builder sbuilder = DefaultTrafficSelector.builder();
    TrafficTreatment.Builder tbuilder = DefaultTrafficTreatment.builder();
    sbuilder.matchIPDst(IpPrefix.valueOf(hostIp, 32));
    sbuilder.matchEthType(Ethernet.TYPE_IPV4);
    tbuilder.setEthDst(hostMac).setEthSrc(config.getRouterMacAddress(deviceId)).setOutput(outPort);
    TrafficTreatment treatment = tbuilder.build();
    TrafficSelector selector = sbuilder.build();
    ForwardingObjective.Builder fwdBuilder = DefaultForwardingObjective.builder().fromApp(srManager.appId).makeTemporary(600).withSelector(selector).withTreatment(treatment).withPriority(100).withFlag(ForwardingObjective.Flag.SPECIFIC);
    srManager.flowObjectiveService.forward(deviceId, fwdBuilder.add());
/*
         * FlowRule f = new DefaultFlowRule(deviceId, selector, treatment, 100,
         * srManager.appId, 600, false, FlowRule.Type.IP);
         *
         * srManager.flowRuleService.applyFlowRules(f);
         * log.debug("Flow rule {} is set to switch {}", f, deviceId);
         */
}
#method_after
public void populateIpRuleForHost(DeviceId deviceId, Ip4Address hostIp, MacAddress hostMac, PortNumber outPort) {
    TrafficSelector.Builder sbuilder = DefaultTrafficSelector.builder();
    TrafficTreatment.Builder tbuilder = DefaultTrafficTreatment.builder();
    sbuilder.matchIPDst(IpPrefix.valueOf(hostIp, 32));
    sbuilder.matchEthType(Ethernet.TYPE_IPV4);
    tbuilder.setEthDst(hostMac).setEthSrc(config.getDeviceMac(deviceId)).setOutput(outPort);
    TrafficTreatment treatment = tbuilder.build();
    TrafficSelector selector = sbuilder.build();
    ForwardingObjective.Builder fwdBuilder = DefaultForwardingObjective.builder().fromApp(srManager.appId).makePermanent().withSelector(selector).withTreatment(treatment).withPriority(100).withFlag(ForwardingObjective.Flag.SPECIFIC);
    log.debug("Installing IPv4 forwarding objective " + "for host {} in switch {}", hostIp, deviceId);
    srManager.flowObjectiveService.forward(deviceId, fwdBuilder.add());
    rulePopulationCounter.incrementAndGet();
}
#end_block

#method_before
public boolean populateIpRuleForSubnet(DeviceId deviceId, List<Ip4Prefix> subnets, DeviceId destSw, Set<DeviceId> nextHops) {
    // List<IpPrefix> subnets = extractSubnet(subnetInfo);
    for (IpPrefix subnet : subnets) {
        if (!populateIpRuleForRouter(deviceId, subnet, destSw, nextHops)) {
            return false;
        }
    }
    return true;
}
#method_after
public boolean populateIpRuleForSubnet(DeviceId deviceId, List<Ip4Prefix> subnets, DeviceId destSw, Set<DeviceId> nextHops) {
    for (IpPrefix subnet : subnets) {
        if (!populateIpRuleForRouter(deviceId, subnet, destSw, nextHops)) {
            return false;
        }
    }
    return true;
}
#end_block

#method_before
public boolean populateIpRuleForRouter(DeviceId deviceId, IpPrefix ipPrefix, DeviceId destSw, Set<DeviceId> nextHops) {
    TrafficSelector.Builder sbuilder = DefaultTrafficSelector.builder();
    TrafficTreatment.Builder tbuilder = DefaultTrafficTreatment.builder();
    sbuilder.matchIPDst(ipPrefix);
    sbuilder.matchEthType(Ethernet.TYPE_IPV4);
    NeighborSet ns = null;
    // is not set.
    if (nextHops.size() == 1 && nextHops.toArray()[0].equals(destSw)) {
        tbuilder.decNwTtl();
        ns = new NeighborSet(nextHops);
    } else {
        tbuilder.copyTtlOut();
        ns = new NeighborSet(nextHops, config.getMplsId(destSw));
    }
    DefaultGroupKey groupKey = (DefaultGroupKey) srManager.getGroupKey(ns);
    if (groupKey == null) {
        log.warn("Group key is not found for ns {}", ns);
        return false;
    }
    /*
         * Group group = srManager.groupService.getGroup(deviceId, groupKey); if
         * (group != null) { tbuilder.group(group.id()); } else {
         * log.warn("No group found for NeighborSet {} from {} to {}", ns,
         * deviceId, destSw); return false; }
         */
    TrafficTreatment treatment = tbuilder.build();
    TrafficSelector selector = sbuilder.build();
    ForwardingObjective.Builder fwdBuilder = DefaultForwardingObjective.builder().fromApp(srManager.appId).makeTemporary(600).nextStep(srManager.getNextObjectiveId(deviceId, groupKey)).withSelector(selector).withPriority(100).withFlag(ForwardingObjective.Flag.SPECIFIC);
    srManager.flowObjectiveService.forward(deviceId, fwdBuilder.add());
    return true;
}
#method_after
public boolean populateIpRuleForRouter(DeviceId deviceId, IpPrefix ipPrefix, DeviceId destSw, Set<DeviceId> nextHops) {
    TrafficSelector.Builder sbuilder = DefaultTrafficSelector.builder();
    TrafficTreatment.Builder tbuilder = DefaultTrafficTreatment.builder();
    sbuilder.matchIPDst(ipPrefix);
    sbuilder.matchEthType(Ethernet.TYPE_IPV4);
    NeighborSet ns = null;
    // is not set.
    if (nextHops.size() == 1 && nextHops.toArray()[0].equals(destSw)) {
        tbuilder.decNwTtl();
        ns = new NeighborSet(nextHops);
    } else {
        tbuilder.copyTtlOut();
        ns = new NeighborSet(nextHops, config.getSegmentId(destSw));
    }
    TrafficTreatment treatment = tbuilder.build();
    TrafficSelector selector = sbuilder.build();
    ForwardingObjective.Builder fwdBuilder = DefaultForwardingObjective.builder().fromApp(srManager.appId).makePermanent().nextStep(srManager.getNextObjectiveId(deviceId, ns)).withTreatment(treatment).withSelector(selector).withPriority(100).withFlag(ForwardingObjective.Flag.SPECIFIC);
    log.debug("Installing IPv4 forwarding objective " + "for router IP/subnet {} in switch {}", ipPrefix, deviceId);
    srManager.flowObjectiveService.forward(deviceId, fwdBuilder.add());
    rulePopulationCounter.incrementAndGet();
    return true;
}
#end_block

#method_before
public boolean populateMplsRule(DeviceId deviceId, DeviceId destSwId, Set<DeviceId> nextHops) {
    TrafficSelector.Builder sbuilder = DefaultTrafficSelector.builder();
    // Collection<TrafficTreatment> treatments = new ArrayList<>();
    List<ForwardingObjective.Builder> fwdObjBuilders = new ArrayList<ForwardingObjective.Builder>();
    // TODO Handle the case of Bos == false
    sbuilder.matchMplsLabel(MplsLabel.mplsLabel(config.getMplsId(destSwId)));
    sbuilder.matchEthType(Ethernet.MPLS_UNICAST);
    // If the next hop is the destination router, do PHP
    if (nextHops.size() == 1 && destSwId.equals(nextHops.toArray()[0])) {
        /*
             * TrafficTreatment treatmentBos = getMplsTreatment(deviceId,
             * destSwId, nextHops, true, true); TrafficTreatment treatment =
             * getMplsTreatment(deviceId, destSwId, nextHops, true, false); if
             * (treatmentBos != null) { treatments.add(treatmentBos); } else {
             * log.warn("Failed to set MPLS rules."); return false; }
             */
        ForwardingObjective.Builder fwdObjBosBuilder = getMplsForwardingObjective(deviceId, destSwId, nextHops, true, true);
        // TODO: Check with Sangho on why we need this
        ForwardingObjective.Builder fwdObjNoBosBuilder = getMplsForwardingObjective(deviceId, destSwId, nextHops, true, false);
        if (fwdObjBosBuilder != null) {
            fwdObjBuilders.add(fwdObjBosBuilder);
        } else {
            log.warn("Failed to set MPLS rules.");
            return false;
        }
    } else {
        /*
             * TrafficTreatment treatmentBos = getMplsTreatment(deviceId,
             * destSwId, nextHops, false, true); TrafficTreatment treatment =
             * getMplsTreatment(deviceId, destSwId, nextHops, false, false);
             *
             * if (treatmentBos != null) { treatments.add(treatmentBos); } else
             * { log.warn("Failed to set MPLS rules."); return false; }
             */
        ForwardingObjective.Builder fwdObjBosBuilder = getMplsForwardingObjective(deviceId, destSwId, nextHops, false, true);
        // TODO: Check with Sangho on why we need this
        ForwardingObjective.Builder fwdObjNoBosBuilder = getMplsForwardingObjective(deviceId, destSwId, nextHops, false, false);
        if (fwdObjBosBuilder != null) {
            fwdObjBuilders.add(fwdObjBosBuilder);
        } else {
            log.warn("Failed to set MPLS rules.");
            return false;
        }
    }
    TrafficSelector selector = sbuilder.build();
    /*
         * for (TrafficTreatment treatment: treatments) { FlowRule f = new
         * DefaultFlowRule(deviceId, selector, treatment, 100, srManager.appId,
         * 600, false, FlowRule.Type.MPLS);
         * srManager.flowRuleService.applyFlowRules(f);
         * log.debug("MPLS rule {} is set to {}", f, deviceId); }
         */
    for (ForwardingObjective.Builder fwdObjBuilder : fwdObjBuilders) {
        ((Builder) ((Builder) fwdObjBuilder.fromApp(srManager.appId).makeTemporary(600)).withSelector(selector).withPriority(100)).withFlag(ForwardingObjective.Flag.SPECIFIC);
        srManager.flowObjectiveService.forward(deviceId, fwdObjBuilder.add());
    }
    return true;
}
#method_after
public boolean populateMplsRule(DeviceId deviceId, DeviceId destSwId, Set<DeviceId> nextHops) {
    TrafficSelector.Builder sbuilder = DefaultTrafficSelector.builder();
    List<ForwardingObjective.Builder> fwdObjBuilders = new ArrayList<ForwardingObjective.Builder>();
    // TODO Handle the case of Bos == false
    sbuilder.matchMplsLabel(MplsLabel.mplsLabel(config.getSegmentId(destSwId)));
    sbuilder.matchEthType(Ethernet.MPLS_UNICAST);
    // If the next hop is the destination router, do PHP
    if (nextHops.size() == 1 && destSwId.equals(nextHops.toArray()[0])) {
        ForwardingObjective.Builder fwdObjBosBuilder = getMplsForwardingObjective(deviceId, destSwId, nextHops, true, true);
        // TODO: Check with Sangho on why we need this
        ForwardingObjective.Builder fwdObjNoBosBuilder = getMplsForwardingObjective(deviceId, destSwId, nextHops, true, false);
        if (fwdObjBosBuilder != null) {
            fwdObjBuilders.add(fwdObjBosBuilder);
        } else {
            log.warn("Failed to set MPLS rules.");
            return false;
        }
    } else {
        ForwardingObjective.Builder fwdObjBosBuilder = getMplsForwardingObjective(deviceId, destSwId, nextHops, false, true);
        // TODO: Check with Sangho on why we need this
        ForwardingObjective.Builder fwdObjNoBosBuilder = getMplsForwardingObjective(deviceId, destSwId, nextHops, false, false);
        if (fwdObjBosBuilder != null) {
            fwdObjBuilders.add(fwdObjBosBuilder);
        } else {
            log.warn("Failed to set MPLS rules.");
            return false;
        }
    }
    TrafficSelector selector = sbuilder.build();
    for (ForwardingObjective.Builder fwdObjBuilder : fwdObjBuilders) {
        ((Builder) ((Builder) fwdObjBuilder.fromApp(srManager.appId).makePermanent()).withSelector(selector).withPriority(100)).withFlag(ForwardingObjective.Flag.SPECIFIC);
        log.debug("Installing MPLS forwarding objective in switch {}", deviceId);
        srManager.flowObjectiveService.forward(deviceId, fwdObjBuilder.add());
        rulePopulationCounter.incrementAndGet();
    }
    return true;
}
#end_block

#method_before
// TODO: Knock off once the migration to flow objective is complete
/*
     * private TrafficTreatment getMplsTreatment(DeviceId deviceId, DeviceId
     * destSw, Set<DeviceId> nextHops, boolean phpRequired, boolean isBos) {
     *
     * TrafficTreatment.Builder tbuilder = DefaultTrafficTreatment.builder();
     *
     * if (phpRequired) { tbuilder.copyTtlIn(); if (isBos) {
     * tbuilder.popMpls(Ethernet.TYPE_IPV4) .decNwTtl(); } else {
     * tbuilder.popMpls(Ethernet.MPLS_UNICAST) .decMplsTtl(); } } else {
     * tbuilder.decMplsTtl(); }
     *
     * if (config.isEcmpNotSupportedInTransit(deviceId) &&
     * config.isTransitRouter(deviceId)) { Link link = selectOneLink(deviceId,
     * nextHops); if (link == null) { log.warn("No link from {} to {}",
     * deviceId, nextHops); return null; }
     * tbuilder.setEthSrc(config.getRouterMacAddress(deviceId))
     * .setEthDst(config.getRouterMacAddress(link.dst().deviceId()))
     * .setOutput(link.src().port()); } else { NeighborSet ns = new
     * NeighborSet(nextHops); DefaultGroupKey groupKey = (DefaultGroupKey)
     * srManager.getGroupKey(ns); if (groupKey == null) {
     * log.warn("Group key is not found for ns {}", ns); return null; } Group
     * group = srManager.groupService.getGroup(deviceId, groupKey); if (group !=
     * null) { tbuilder.group(group.id()); } else {
     * log.warn("No group found for ns {} key {} in {}", ns,
     * srManager.getGroupKey(ns), deviceId); return null; } }
     *
     * return tbuilder.build(); }
     */
private ForwardingObjective.Builder getMplsForwardingObjective(DeviceId deviceId, DeviceId destSw, Set<DeviceId> nextHops, boolean phpRequired, boolean isBos) {
    ForwardingObjective.Builder fwdBuilder = DefaultForwardingObjective.builder().withFlag(ForwardingObjective.Flag.SPECIFIC);
    TrafficTreatment.Builder tbuilder = DefaultTrafficTreatment.builder();
    if (phpRequired) {
        tbuilder.copyTtlIn();
        if (isBos) {
            tbuilder.popMpls(Ethernet.TYPE_IPV4).decNwTtl();
        } else {
            tbuilder.popMpls(Ethernet.MPLS_UNICAST).decMplsTtl();
        }
    } else {
        tbuilder.decMplsTtl();
    }
    if (config.isEcmpNotSupportedInTransit(deviceId) && config.isTransitRouter(deviceId)) {
        Link link = selectOneLink(deviceId, nextHops);
        if (link == null) {
            log.warn("No link from {} to {}", deviceId, nextHops);
            return null;
        }
        tbuilder.setEthSrc(config.getRouterMacAddress(deviceId)).setEthDst(config.getRouterMacAddress(link.dst().deviceId())).setOutput(link.src().port());
        fwdBuilder.withTreatment(tbuilder.build());
    } else {
        NeighborSet ns = new NeighborSet(nextHops);
        DefaultGroupKey groupKey = (DefaultGroupKey) srManager.getGroupKey(ns);
        if (groupKey == null) {
            log.warn("Group key is not found for ns {}", ns);
            return null;
        }
        fwdBuilder.nextStep(srManager.getNextObjectiveId(deviceId, groupKey));
    /*
             * Group group = srManager.groupService.getGroup(deviceId,
             * groupKey); if (group != null) { tbuilder.group(group.id()); }
             * else { log.warn("No group found for ns {} key {} in {}", ns,
             * srManager.getGroupKey(ns), deviceId); return null; }
             */
    }
    return fwdBuilder;
}
#method_after
private ForwardingObjective.Builder getMplsForwardingObjective(DeviceId deviceId, DeviceId destSw, Set<DeviceId> nextHops, boolean phpRequired, boolean isBos) {
    ForwardingObjective.Builder fwdBuilder = DefaultForwardingObjective.builder().withFlag(ForwardingObjective.Flag.SPECIFIC);
    TrafficTreatment.Builder tbuilder = DefaultTrafficTreatment.builder();
    if (phpRequired) {
        log.debug("getMplsForwardingObjective: php required");
        tbuilder.copyTtlIn();
        if (isBos) {
            tbuilder.popMpls(Ethernet.TYPE_IPV4).decNwTtl();
        } else {
            tbuilder.popMpls(Ethernet.MPLS_UNICAST).decMplsTtl();
        }
    } else {
        log.debug("getMplsForwardingObjective: php not required");
        tbuilder.decMplsTtl();
    }
    if (!isECMPSupportedInTransitRouter() && !config.isEdgeDevice(deviceId)) {
        Link link = selectOneLink(deviceId, nextHops);
        DeviceId nextHop = (DeviceId) nextHops.toArray()[0];
        if (link == null) {
            log.warn("No link from {} to {}", deviceId, nextHops);
            return null;
        }
        tbuilder.setEthSrc(config.getDeviceMac(deviceId)).setEthDst(config.getDeviceMac(nextHop)).setOutput(link.src().port());
        fwdBuilder.withTreatment(tbuilder.build());
    } else {
        NeighborSet ns = new NeighborSet(nextHops);
        fwdBuilder.nextStep(srManager.getNextObjectiveId(deviceId, ns));
    }
    return fwdBuilder;
}
#end_block

#method_before
public void populateTableVlan(DeviceId deviceId) {
    FilteringObjective.Builder fob = DefaultFilteringObjective.builder();
    fob.withKey(Criteria.matchInPort(PortNumber.ALL)).addCondition(Criteria.matchVlanId(VlanId.NONE));
    fob.permit().fromApp(srManager.appId);
    srManager.flowObjectiveService.filter(deviceId, fob.add());
/*
         * FlowRule f = new DefaultFlowRule(deviceId, selector, treatment, 100,
         * srManager.appId, 600, false, FlowRule.Type.VLAN);
         *
         * srManager.flowRuleService.applyFlowRules(f);
         *
         * log.debug("Vlan flow rule {} is set to switch {}", f, deviceId);
         */
}
#method_after
public void populateTableVlan(DeviceId deviceId) {
    FilteringObjective.Builder fob = DefaultFilteringObjective.builder();
    fob.withKey(Criteria.matchInPort(PortNumber.ALL)).addCondition(Criteria.matchVlanId(VlanId.NONE));
    fob.permit().fromApp(srManager.appId);
    log.debug("populateTableVlan: Installing filtering objective for untagged packets");
    srManager.flowObjectiveService.filter(deviceId, fob.add());
}
#end_block

#method_before
public void populateTableTMac(DeviceId deviceId) {
    FilteringObjective.Builder fob = DefaultFilteringObjective.builder();
    fob.withKey(Criteria.matchInPort(PortNumber.ALL)).addCondition(Criteria.matchEthDst(config.getRouterMacAddress(deviceId)));
    fob.permit().fromApp(srManager.appId);
    srManager.flowObjectiveService.filter(deviceId, fob.add());
}
#method_after
public void populateTableTMac(DeviceId deviceId) {
    FilteringObjective.Builder fob = DefaultFilteringObjective.builder();
    fob.withKey(Criteria.matchInPort(PortNumber.ALL)).addCondition(Criteria.matchEthDst(config.getDeviceMac(deviceId)));
    fob.permit().fromApp(srManager.appId);
    log.debug("populateTableVlan: Installing filtering objective for router mac");
    srManager.flowObjectiveService.filter(deviceId, fob.add());
}
#end_block

#method_before
// TODO: Knock off once the migration to flow objective is complete
/**
 * Populates a table miss entry.
 *
 * @param deviceId switch ID to set rules
 * @param tableToAdd table to set the rules
 * @param toControllerNow flag to send packets to controller immediately
 * @param toControllerWrite flag to send packets to controller at the end of
 *            pipeline
 * @param toTable flag to send packets to a specific table
 * @param tableToSend table type to send packets when the toTable flag is
 *            set
 */
/*
     * public void populateTableMissEntry(DeviceId deviceId, FlowRule.Type
     * tableToAdd, boolean toControllerNow, boolean toControllerWrite, boolean
     * toTable, FlowRule.Type tableToSend) { // TODO: Change arguments to
     * EnumSet TrafficSelector selector = DefaultTrafficSelector.builder()
     * .build(); TrafficTreatment.Builder tBuilder =
     * DefaultTrafficTreatment.builder();
     *
     * if (toControllerNow) { tBuilder.setOutput(PortNumber.CONTROLLER); }
     *
     * if (toControllerWrite) {
     * tBuilder.deferred().setOutput(PortNumber.CONTROLLER); }
     *
     * if (toTable) { tBuilder.transition(tableToSend); }
     *
     * ForwardingObjective.Builder fwdBuilder =
     * DefaultForwardingObjective.builder() .fromApp(srManager.appId)
     * .makeTemporary(600) .withSelector(selector)
     * .withTreatment(tBuilder.build()) .withPriority(100)
     * .withFlag(ForwardingObjective.Flag.SPECIFIC);
     *
     * srManager.flowObjectiveService.forward(deviceId, fwdBuilder.add());
     * FlowRule flow = new DefaultFlowRule(deviceId, selector, tBuilder.build(),
     * 0, srManager.appId, 600, false, tableToAdd);
     *
     * srManager.flowRuleService.applyFlowRules(flow);
     *
     * }
     */
private Link selectOneLink(DeviceId srcId, Set<DeviceId> destIds) {
    Set<Link> links = srManager.linkService.getDeviceEgressLinks(srcId);
    DeviceId destId = (DeviceId) destIds.toArray()[0];
    for (Link link : links) {
        if (link.dst().deviceId().equals(destId)) {
            return link;
        }
    }
    return null;
}
#method_after
private Link selectOneLink(DeviceId srcId, Set<DeviceId> destIds) {
    Set<Link> links = srManager.linkService.getDeviceEgressLinks(srcId);
    DeviceId destId = (DeviceId) destIds.toArray()[0];
    for (Link link : links) {
        if (link.dst().deviceId().equals(destId)) {
            return link;
        }
    }
    return null;
}
#end_block

#method_before
@Override
protected void newPortToExistingNeighbor(Link newNeighborLink) {
    log.debug("New port to existing neighbor: Updating " + "groups for edge device {}", deviceId);
    addNeighborAtPort(newNeighborLink.dst().deviceId(), newNeighborLink.src().port());
    Set<NeighborSet> nsSet = computeImpactedNeighborsetForPortEvent(newNeighborLink.dst().deviceId(), devicePortMap.keySet());
    for (NeighborSet ns : nsSet) {
        // Create the new bucket to be updated
        TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
        tBuilder.setOutput(newNeighborLink.src().port()).setEthDst(deviceConfig.getDeviceMac(newNeighborLink.dst().deviceId())).setEthSrc(nodeMacAddr);
        if (ns.getEdgeLabel() != NeighborSet.NO_EDGE_LABEL) {
            tBuilder.pushMpls().setMpls(MplsLabel.mplsLabel(ns.getEdgeLabel()));
        }
    /*GroupBucket updatedBucket = DefaultGroupBucket.
                    createSelectGroupBucket(tBuilder.build());
            GroupBuckets updatedBuckets = new GroupBuckets(
                                        Arrays.asList(updatedBucket));
            log.debug("newPortToExistingNeighborAtEdgeRouter: "
                    + "groupService.addBucketsToGroup for neighborset{}", ns);
            groupService.addBucketsToGroup(deviceId,
                                           getGroupKey(ns),
                                           updatedBuckets,
                                           getGroupKey(ns),
                                           appId);*/
    // TODO: Use nextObjective APIs to update the objective
    }
}
#method_after
@Override
protected void newPortToExistingNeighbor(Link newNeighborLink) {
    log.debug("New port to existing neighbor: Updating " + "groups for edge device {}", deviceId);
    addNeighborAtPort(newNeighborLink.dst().deviceId(), newNeighborLink.src().port());
    Set<NeighborSet> nsSet = computeImpactedNeighborsetForPortEvent(newNeighborLink.dst().deviceId(), devicePortMap.keySet());
    for (NeighborSet ns : nsSet) {
        // Create the new bucket to be updated
        TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
        tBuilder.setOutput(newNeighborLink.src().port()).setEthDst(deviceConfig.getDeviceMac(newNeighborLink.dst().deviceId())).setEthSrc(nodeMacAddr);
        if (ns.getEdgeLabel() != NeighborSet.NO_EDGE_LABEL) {
            tBuilder.pushMpls().setMpls(MplsLabel.mplsLabel(ns.getEdgeLabel()));
        }
    /*GroupBucket updatedBucket = DefaultGroupBucket.
                    createSelectGroupBucket(tBuilder.build());
            GroupBuckets updatedBuckets = new GroupBuckets(
                                        Arrays.asList(updatedBucket));
            log.debug("newPortToExistingNeighborAtEdgeRouter: "
                    + "groupService.addBucketsToGroup for neighborset{}", ns);
            groupService.addBucketsToGroup(deviceId,
                                           getGroupKey(ns),
                                           updatedBuckets,
                                           getGroupKey(ns),
                                           appId);*/
    // TODO: Use nextObjective APIs to update the next objective
    }
}
#end_block

#method_before
@Override
public void init(DeviceId deviceId, PipelinerContext context) {
    this.serviceDirectory = context.directory();
    this.deviceId = deviceId;
    pendingGroups = CacheBuilder.newBuilder().expireAfterWrite(20, TimeUnit.SECONDS).removalListener((RemovalNotification<GroupKey, NextObjective> notification) -> {
        if (notification.getCause() == RemovalCause.EXPIRED) {
            fail(notification.getValue(), ObjectiveError.GROUPINSTALLATIONFAILED);
        }
    }).build();
    groupChecker.scheduleAtFixedRate(new GroupChecker(), 0, 500, TimeUnit.MILLISECONDS);
    coreService = serviceDirectory.get(CoreService.class);
    flowRuleService = serviceDirectory.get(FlowRuleService.class);
    groupService = serviceDirectory.get(GroupService.class);
    flowObjectiveStore = context.store();
    groupService.addListener(new InnerGroupListener());
    appId = coreService.registerApplication("org.onosproject.driver.SpringOpenTTP");
    setTableMissEntries();
}
#method_after
@Override
public void init(DeviceId deviceId, PipelinerContext context) {
    this.serviceDirectory = context.directory();
    this.deviceId = deviceId;
    pendingGroups = CacheBuilder.newBuilder().expireAfterWrite(20, TimeUnit.SECONDS).removalListener((RemovalNotification<GroupKey, NextObjective> notification) -> {
        if (notification.getCause() == RemovalCause.EXPIRED) {
            fail(notification.getValue(), ObjectiveError.GROUPINSTALLATIONFAILED);
        }
    }).build();
    groupChecker.scheduleAtFixedRate(new GroupChecker(), 0, 500, TimeUnit.MILLISECONDS);
    coreService = serviceDirectory.get(CoreService.class);
    flowRuleService = serviceDirectory.get(FlowRuleService.class);
    groupService = serviceDirectory.get(GroupService.class);
    flowObjectiveStore = context.store();
    groupService.addListener(new InnerGroupListener());
    appId = coreService.registerApplication("org.onosproject.driver.SpringOpenTTP");
    setTableMissEntries();
    log.info("Spring Open TTP driver initialized");
}
#end_block

#method_before
@Override
public void filter(FilteringObjective filteringObjective) {
    if (filteringObjective.type() == FilteringObjective.Type.PERMIT) {
        processFilter(filteringObjective, filteringObjective.op() == Objective.Operation.ADD, filteringObjective.appId());
    } else {
        fail(filteringObjective, ObjectiveError.UNSUPPORTED);
    }
}
#method_after
@Override
public void filter(FilteringObjective filteringObjective) {
    if (filteringObjective.type() == FilteringObjective.Type.PERMIT) {
        log.debug("processing PERMIT filter objective");
        processFilter(filteringObjective, filteringObjective.op() == Objective.Operation.ADD, filteringObjective.appId());
    } else {
        log.debug("filter objective other than PERMIT not supported");
        fail(filteringObjective, ObjectiveError.UNSUPPORTED);
    }
}
#end_block

#method_before
@Override
public void next(NextObjective nextObjective) {
    switch(nextObjective.type()) {
        case SIMPLE:
            Collection<TrafficTreatment> treatments = nextObjective.next();
            if (treatments.size() == 1) {
                TrafficTreatment treatment = treatments.iterator().next();
                GroupBucket bucket = DefaultGroupBucket.createIndirectGroupBucket(treatment);
                final GroupKey key = new DefaultGroupKey(appKryo.serialize(nextObjective.id()));
                GroupDescription groupDescription = new DefaultGroupDescription(deviceId, GroupDescription.Type.INDIRECT, new GroupBuckets(Collections.singletonList(bucket)), key, nextObjective.appId());
                groupService.addGroup(groupDescription);
                pendingGroups.put(key, nextObjective);
            }
            break;
        case HASHED:
            List<GroupBucket> buckets = nextObjective.next().stream().map((treatment) -> DefaultGroupBucket.createSelectGroupBucket(treatment)).collect(Collectors.toList());
            if (!buckets.isEmpty()) {
                final GroupKey key = new DefaultGroupKey(appKryo.serialize(nextObjective.id()));
                GroupDescription groupDescription = new DefaultGroupDescription(deviceId, GroupDescription.Type.SELECT, new GroupBuckets(buckets), key, nextObjective.appId());
                groupService.addGroup(groupDescription);
                pendingGroups.put(key, nextObjective);
            }
            break;
        case BROADCAST:
        case FAILOVER:
            fail(nextObjective, ObjectiveError.UNSUPPORTED);
            log.warn("Unsupported next objective type {}", nextObjective.type());
            break;
        default:
            fail(nextObjective, ObjectiveError.UNKNOWN);
            log.warn("Unknown next objective type {}", nextObjective.type());
    }
}
#method_after
@Override
public void next(NextObjective nextObjective) {
    switch(nextObjective.type()) {
        case SIMPLE:
            log.debug("processing SIMPLE next objective");
            Collection<TrafficTreatment> treatments = nextObjective.next();
            if (treatments.size() == 1) {
                TrafficTreatment treatment = treatments.iterator().next();
                GroupBucket bucket = DefaultGroupBucket.createIndirectGroupBucket(treatment);
                final GroupKey key = new DefaultGroupKey(appKryo.serialize(nextObjective.id()));
                GroupDescription groupDescription = new DefaultGroupDescription(deviceId, GroupDescription.Type.INDIRECT, new GroupBuckets(Collections.singletonList(bucket)), key, nextObjective.appId());
                groupService.addGroup(groupDescription);
                pendingGroups.put(key, nextObjective);
            }
            break;
        case HASHED:
            log.debug("processing HASHED next objective");
            List<GroupBucket> buckets = nextObjective.next().stream().map((treatment) -> DefaultGroupBucket.createSelectGroupBucket(treatment)).collect(Collectors.toList());
            if (!buckets.isEmpty()) {
                final GroupKey key = new DefaultGroupKey(appKryo.serialize(nextObjective.id()));
                GroupDescription groupDescription = new DefaultGroupDescription(deviceId, GroupDescription.Type.SELECT, new GroupBuckets(buckets), key, nextObjective.appId());
                groupService.addGroup(groupDescription);
                pendingGroups.put(key, nextObjective);
            }
            break;
        case BROADCAST:
        case FAILOVER:
            log.debug("BROADCAST and FAILOVER next objectives not supported");
            fail(nextObjective, ObjectiveError.UNSUPPORTED);
            log.warn("Unsupported next objective type {}", nextObjective.type());
            break;
        default:
            fail(nextObjective, ObjectiveError.UNKNOWN);
            log.warn("Unknown next objective type {}", nextObjective.type());
    }
}
#end_block

#method_before
private Collection<FlowRule> processSpecific(ForwardingObjective fwd) {
    log.warn("Processing specific");
    TrafficSelector selector = fwd.selector();
    Criteria.EthTypeCriterion ethType = (Criteria.EthTypeCriterion) selector.getCriterion(Criterion.Type.ETH_TYPE);
    if (ethType == null || ethType.ethType() != Ethernet.TYPE_IPV4) {
        fail(fwd, ObjectiveError.UNSUPPORTED);
        return Collections.emptySet();
    }
    TrafficSelector filteredSelector = DefaultTrafficSelector.builder().matchEthType(Ethernet.TYPE_IPV4).matchIPDst(((Criteria.IPCriterion) selector.getCriterion(Criterion.Type.IPV4_DST)).ip()).build();
    TrafficTreatment.Builder treatmentBuilder = DefaultTrafficTreatment.builder();
    for (Instruction i : fwd.treatment().allInstructions()) {
        treatmentBuilder.add(i);
    }
    NextGroup next = flowObjectiveStore.getNextGroup(fwd.nextId());
    if (next != null) {
        GroupKey key = appKryo.deserialize(next.data());
        Group group = groupService.getGroup(deviceId, key);
        if (group == null) {
            log.warn("The group left!");
            fail(fwd, ObjectiveError.GROUPMISSING);
            return Collections.emptySet();
        }
        treatmentBuilder.group(group.id());
    }
    TrafficTreatment treatment = treatmentBuilder.transition(aclTableId).build();
    FlowRule.Builder ruleBuilder = DefaultFlowRule.builder().fromApp(fwd.appId()).withPriority(fwd.priority()).forDevice(deviceId).withSelector(filteredSelector).withTreatment(treatment);
    if (fwd.permanent()) {
        ruleBuilder.makePermanent();
    } else {
        ruleBuilder.makeTemporary(fwd.timeout());
    }
    ruleBuilder.forTable(ipv4UnicastTableId);
    return Collections.singletonList(ruleBuilder.build());
}
#method_after
protected Collection<FlowRule> processSpecific(ForwardingObjective fwd) {
    log.debug("Processing specific");
    TrafficSelector selector = fwd.selector();
    EthTypeCriterion ethType = (EthTypeCriterion) selector.getCriterion(Criterion.Type.ETH_TYPE);
    if ((ethType == null) || ((((short) ethType.ethType()) != Ethernet.TYPE_IPV4) && (((short) ethType.ethType()) != Ethernet.MPLS_UNICAST))) {
        log.debug("processSpecific: Unsupported " + "forwarding objective criteraia");
        fail(fwd, ObjectiveError.UNSUPPORTED);
        return Collections.emptySet();
    }
    TrafficSelector.Builder filteredSelectorBuilder = DefaultTrafficSelector.builder();
    int forTableId = -1;
    if (((short) ethType.ethType()) == Ethernet.TYPE_IPV4) {
        filteredSelectorBuilder = filteredSelectorBuilder.matchEthType(Ethernet.TYPE_IPV4).matchIPDst(((IPCriterion) selector.getCriterion(Criterion.Type.IPV4_DST)).ip());
        forTableId = ipv4UnicastTableId;
        log.debug("processing IPv4 specific forwarding objective");
    } else {
        filteredSelectorBuilder = filteredSelectorBuilder.matchEthType(Ethernet.MPLS_UNICAST).matchMplsLabel(((MplsCriterion) selector.getCriterion(Criterion.Type.MPLS_LABEL)).label());
        // TODO: Add Match for BoS
        // if (selector.getCriterion(Criterion.Type.MPLS_BOS) != null) {
        // }
        forTableId = mplsTableId;
        log.debug("processing MPLS specific forwarding objective");
    }
    TrafficTreatment.Builder treatmentBuilder = DefaultTrafficTreatment.builder();
    if (fwd.treatment() != null) {
        for (Instruction i : fwd.treatment().allInstructions()) {
            treatmentBuilder.add(i);
        }
    }
    // switches.
    if (fwd.nextId() != null) {
        NextGroup next = flowObjectiveStore.getNextGroup(fwd.nextId());
        if (next != null) {
            GroupKey key = appKryo.deserialize(next.data());
            Group group = groupService.getGroup(deviceId, key);
            if (group == null) {
                log.warn("The group left!");
                fail(fwd, ObjectiveError.GROUPMISSING);
                return Collections.emptySet();
            }
            treatmentBuilder.group(group.id());
            log.debug("Adding OUTGROUP action");
        }
    }
    TrafficSelector filteredSelector = filteredSelectorBuilder.build();
    TrafficTreatment treatment = treatmentBuilder.transition(aclTableId).build();
    FlowRule.Builder ruleBuilder = DefaultFlowRule.builder().fromApp(fwd.appId()).withPriority(fwd.priority()).forDevice(deviceId).withSelector(filteredSelector).withTreatment(treatment);
    if (fwd.permanent()) {
        ruleBuilder.makePermanent();
    } else {
        ruleBuilder.makeTemporary(fwd.timeout());
    }
    ruleBuilder.forTable(forTableId);
    return Collections.singletonList(ruleBuilder.build());
}
#end_block

#method_before
private void processFilter(FilteringObjective filt, boolean install, ApplicationId applicationId) {
    // This driver only processes filtering criteria defined with switch
    // ports as the key
    Criteria.PortCriterion p;
    if (!filt.key().equals(Criteria.dummy()) && filt.key().type() == Criterion.Type.IN_PORT) {
        p = (Criteria.PortCriterion) filt.key();
    } else {
        log.warn("No key defined in filtering objective from app: {}. Not" + "processing filtering objective", applicationId);
        fail(filt, ObjectiveError.UNKNOWN);
        return;
    }
    // convert filtering conditions for switch-intfs into flowrules
    FlowRuleOperations.Builder ops = FlowRuleOperations.builder();
    for (Criterion c : filt.conditions()) {
        if (c.type() == Criterion.Type.ETH_DST) {
            Criteria.EthCriterion e = (Criteria.EthCriterion) c;
            log.debug("adding rule for MAC: {}", e.mac());
            TrafficSelector.Builder selectorIp = DefaultTrafficSelector.builder();
            TrafficTreatment.Builder treatmentIp = DefaultTrafficTreatment.builder();
            selectorIp.matchEthDst(e.mac());
            selectorIp.matchEthType(Ethernet.TYPE_IPV4);
            treatmentIp.transition(ipv4UnicastTableId);
            FlowRule ruleIp = DefaultFlowRule.builder().forDevice(deviceId).withSelector(selectorIp.build()).withTreatment(treatmentIp.build()).withPriority(filt.priority()).fromApp(applicationId).makePermanent().forTable(tmacTableId).build();
            ops = install ? ops.add(ruleIp) : ops.remove(ruleIp);
            TrafficSelector.Builder selectorMpls = DefaultTrafficSelector.builder();
            TrafficTreatment.Builder treatmentMpls = DefaultTrafficTreatment.builder();
            selectorMpls.matchEthDst(e.mac());
            selectorMpls.matchEthType(Ethernet.MPLS_UNICAST);
            treatmentIp.transition(mplsTableId);
            FlowRule ruleMpls = DefaultFlowRule.builder().forDevice(deviceId).withSelector(selectorMpls.build()).withTreatment(treatmentMpls.build()).withPriority(filt.priority()).fromApp(applicationId).makePermanent().forTable(tmacTableId).build();
            ops = install ? ops.add(ruleMpls) : ops.remove(ruleMpls);
        } else if (c.type() == Criterion.Type.VLAN_VID) {
            Criteria.VlanIdCriterion v = (Criteria.VlanIdCriterion) c;
            log.debug("adding rule for VLAN: {}", v.vlanId());
            TrafficSelector.Builder selector = DefaultTrafficSelector.builder();
            TrafficTreatment.Builder treatment = DefaultTrafficTreatment.builder();
            selector.matchVlanId(v.vlanId());
            selector.matchInPort(p.port());
            treatment.transition(tmacTableId);
            treatment.deferred().popVlan();
            FlowRule rule = DefaultFlowRule.builder().forDevice(deviceId).withSelector(selector.build()).withTreatment(treatment.build()).withPriority(filt.priority()).fromApp(applicationId).makePermanent().forTable(vlanTableId).build();
            ops = install ? ops.add(rule) : ops.remove(rule);
        } else if (c.type() == Criterion.Type.IPV4_DST) {
            Criteria.IPCriterion ip = (Criteria.IPCriterion) c;
            log.debug("adding rule for IP: {}", ip.ip());
            TrafficSelector.Builder selector = DefaultTrafficSelector.builder();
            TrafficTreatment.Builder treatment = DefaultTrafficTreatment.builder();
            selector.matchEthType(Ethernet.TYPE_IPV4);
            selector.matchIPDst(ip.ip());
            treatment.transition(aclTableId);
            FlowRule rule = DefaultFlowRule.builder().forDevice(deviceId).withSelector(selector.build()).withTreatment(treatment.build()).withPriority(filt.priority()).fromApp(applicationId).makePermanent().forTable(ipv4UnicastTableId).build();
            ops = install ? ops.add(rule) : ops.remove(rule);
        } else {
            log.warn("Driver does not currently process filtering condition" + " of type: {}", c.type());
            fail(filt, ObjectiveError.UNSUPPORTED);
        }
    }
    // apply filtering flow rules
    flowRuleService.apply(ops.build(new FlowRuleOperationsContext() {

        @Override
        public void onSuccess(FlowRuleOperations ops) {
            pass(filt);
            log.info("Provisioned default table for bgp router");
        }

        @Override
        public void onError(FlowRuleOperations ops) {
            fail(filt, ObjectiveError.FLOWINSTALLATIONFAILED);
            log.info("Failed to provision default table for bgp router");
        }
    }));
}
#method_after
private void processFilter(FilteringObjective filt, boolean install, ApplicationId applicationId) {
    // This driver only processes filtering criteria defined with switch
    // ports as the key
    PortCriterion p;
    if (!filt.key().equals(Criteria.dummy()) && filt.key().type() == Criterion.Type.IN_PORT) {
        p = (PortCriterion) filt.key();
    } else {
        log.warn("No key defined in filtering objective from app: {}. Not" + "processing filtering objective", applicationId);
        fail(filt, ObjectiveError.UNKNOWN);
        return;
    }
    // convert filtering conditions for switch-intfs into flowrules
    FlowRuleOperations.Builder ops = FlowRuleOperations.builder();
    for (Criterion c : filt.conditions()) {
        if (c.type() == Criterion.Type.ETH_DST) {
            for (FlowRule rule : processEthDstFilter(c, filt, applicationId)) {
                ops = install ? ops.add(rule) : ops.remove(rule);
            }
        } else if (c.type() == Criterion.Type.VLAN_VID) {
            VlanIdCriterion v = (VlanIdCriterion) c;
            log.debug("adding rule for VLAN: {}", v.vlanId());
            TrafficSelector.Builder selector = DefaultTrafficSelector.builder();
            TrafficTreatment.Builder treatment = DefaultTrafficTreatment.builder();
            if (v.vlanId() != VlanId.NONE) {
                selector.matchVlanId(v.vlanId());
                selector.matchInPort(p.port());
                treatment.deferred().popVlan();
            }
            treatment.transition(tmacTableId);
            FlowRule rule = DefaultFlowRule.builder().forDevice(deviceId).withSelector(selector.build()).withTreatment(treatment.build()).withPriority(filt.priority()).fromApp(applicationId).makePermanent().forTable(vlanTableId).build();
            ops = install ? ops.add(rule) : ops.remove(rule);
        } else if (c.type() == Criterion.Type.IPV4_DST) {
            IPCriterion ip = (IPCriterion) c;
            log.debug("adding rule for IP: {}", ip.ip());
            TrafficSelector.Builder selector = DefaultTrafficSelector.builder();
            TrafficTreatment.Builder treatment = DefaultTrafficTreatment.builder();
            selector.matchEthType(Ethernet.TYPE_IPV4);
            selector.matchIPDst(ip.ip());
            treatment.transition(aclTableId);
            FlowRule rule = DefaultFlowRule.builder().forDevice(deviceId).withSelector(selector.build()).withTreatment(treatment.build()).withPriority(filt.priority()).fromApp(applicationId).makePermanent().forTable(ipv4UnicastTableId).build();
            ops = install ? ops.add(rule) : ops.remove(rule);
        } else {
            log.warn("Driver does not currently process filtering condition" + " of type: {}", c.type());
            fail(filt, ObjectiveError.UNSUPPORTED);
        }
    }
    // apply filtering flow rules
    flowRuleService.apply(ops.build(new FlowRuleOperationsContext() {

        @Override
        public void onSuccess(FlowRuleOperations ops) {
            pass(filt);
            log.info("Provisioned tables for segment router");
        }

        @Override
        public void onError(FlowRuleOperations ops) {
            fail(filt, ObjectiveError.FLOWINSTALLATIONFAILED);
            log.info("Failed to provision tables for segment router");
        }
    }));
}
#end_block

#method_before
private void fail(Objective obj, ObjectiveError error) {
    if (obj.context().isPresent()) {
        obj.context().get().onError(obj, error);
    }
}
#method_after
protected void fail(Objective obj, ObjectiveError error) {
    if (obj.context().isPresent()) {
        obj.context().get().onError(obj, error);
    }
}
#end_block

#method_before
@Override
protected void newPortToExistingNeighbor(Link newNeighborLink) {
    log.debug("New port to existing neighbor: Updating " + "groups for transit device {}", deviceId);
    addNeighborAtPort(newNeighborLink.dst().deviceId(), newNeighborLink.src().port());
    Set<NeighborSet> nsSet = computeImpactedNeighborsetForPortEvent(newNeighborLink.dst().deviceId(), devicePortMap.keySet());
    for (NeighborSet ns : nsSet) {
        // Create the new bucket to be updated
        TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
        tBuilder.setOutput(newNeighborLink.src().port()).setEthDst(deviceConfig.getDeviceMac(newNeighborLink.dst().deviceId())).setEthSrc(nodeMacAddr);
        if (ns.getEdgeLabel() != NeighborSet.NO_EDGE_LABEL) {
            tBuilder.pushMpls().setMpls(MplsLabel.mplsLabel(ns.getEdgeLabel()));
        }
    /*GroupBucket updatedBucket = DefaultGroupBucket.
                    createSelectGroupBucket(tBuilder.build());
            GroupBuckets updatedBuckets = new GroupBuckets(
                                        Arrays.asList(updatedBucket));
            log.debug("newPortToExistingNeighborAtEdgeRouter: "
                    + "groupService.addBucketsToGroup for neighborset{}", ns);
            groupService.addBucketsToGroup(deviceId,
                                           getGroupKey(ns),
                                           updatedBuckets,
                                           getGroupKey(ns),
                                           appId);*/
    // TODO: Use nextObjective APIs to update the objective
    }
}
#method_after
@Override
protected void newPortToExistingNeighbor(Link newNeighborLink) {
    log.debug("New port to existing neighbor: Updating " + "groups for transit device {}", deviceId);
    addNeighborAtPort(newNeighborLink.dst().deviceId(), newNeighborLink.src().port());
    Set<NeighborSet> nsSet = computeImpactedNeighborsetForPortEvent(newNeighborLink.dst().deviceId(), devicePortMap.keySet());
    for (NeighborSet ns : nsSet) {
        // Create the new bucket to be updated
        TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
        tBuilder.setOutput(newNeighborLink.src().port()).setEthDst(deviceConfig.getDeviceMac(newNeighborLink.dst().deviceId())).setEthSrc(nodeMacAddr);
        if (ns.getEdgeLabel() != NeighborSet.NO_EDGE_LABEL) {
            tBuilder.pushMpls().setMpls(MplsLabel.mplsLabel(ns.getEdgeLabel()));
        }
    /*GroupBucket updatedBucket = DefaultGroupBucket.
                    createSelectGroupBucket(tBuilder.build());
            GroupBuckets updatedBuckets = new GroupBuckets(
                                        Arrays.asList(updatedBucket));
            log.debug("newPortToExistingNeighborAtEdgeRouter: "
                    + "groupService.addBucketsToGroup for neighborset{}", ns);
            groupService.addBucketsToGroup(deviceId,
                                           getGroupKey(ns),
                                           updatedBuckets,
                                           getGroupKey(ns),
                                           appId);*/
    // TODO: Use nextObjective APIs to update the next objective
    }
}
#end_block

#method_before
public boolean populateAllRoutingRules() {
    populationStatus = Status.STARTED;
    log.info("Starts to populate routing rules");
    for (Device sw : srManager.deviceService.getDevices()) {
        if (srManager.mastershipService.getLocalRole(sw.id()) != MastershipRole.MASTER) {
            continue;
        }
        ECMPShortestPathGraph ecmpSPG = new ECMPShortestPathGraph(sw.id(), srManager);
        if (!populateEcmpRoutingRules(sw, ecmpSPG)) {
            populationStatus = Status.ABORTED;
            log.debug("Abort routing rule population");
            return false;
        }
    // TODO: Set adjacency routing rule for all switches
    }
    populationStatus = Status.SUCCEEDED;
    log.info("Completes routing rule population");
    return true;
}
#method_after
public boolean populateAllRoutingRules() {
    populationStatus = Status.STARTED;
    rulePopulator.resetCounter();
    log.info("Starts to populate routing rules");
    for (Device sw : srManager.deviceService.getDevices()) {
        if (srManager.mastershipService.getLocalRole(sw.id()) != MastershipRole.MASTER) {
            continue;
        }
        ECMPShortestPathGraph ecmpSpg = new ECMPShortestPathGraph(sw.id(), srManager);
        if (!populateEcmpRoutingRules(sw.id(), ecmpSpg)) {
            populationStatus = Status.ABORTED;
            log.debug("Abort routing rule population");
            return false;
        }
        currentEcmpSpgMap.put(sw.id(), ecmpSpg);
    // TODO: Set adjacency routing rule for all switches
    }
    populationStatus = Status.SUCCEEDED;
    log.info("Completes routing rule population. Total # of rules pushed : {}", rulePopulator.getCounter());
    return true;
}
#end_block

#method_before
private boolean populateEcmpRoutingRules(Device sw, ECMPShortestPathGraph ecmpSPG) {
    HashMap<Integer, HashMap<DeviceId, ArrayList<ArrayList<DeviceId>>>> switchVia = ecmpSPG.getAllLearnedSwitchesAndVia();
    for (Integer itrIdx : switchVia.keySet()) {
        HashMap<DeviceId, ArrayList<ArrayList<DeviceId>>> swViaMap = switchVia.get(itrIdx);
        for (DeviceId targetSw : swViaMap.keySet()) {
            DeviceId destSw = sw.id();
            Set<DeviceId> nextHops = new HashSet<>();
            for (ArrayList<DeviceId> via : swViaMap.get(targetSw)) {
                if (via.isEmpty()) {
                    nextHops.add(destSw);
                } else {
                    nextHops.add(via.get(0));
                }
            }
            if (!populateEcmpRoutingRulePartial(targetSw, destSw, nextHops)) {
                return false;
            }
        }
    }
    return true;
}
#method_after
private boolean populateEcmpRoutingRules(DeviceId destSw, ECMPShortestPathGraph ecmpSPG) {
    HashMap<Integer, HashMap<DeviceId, ArrayList<ArrayList<DeviceId>>>> switchVia = ecmpSPG.getAllLearnedSwitchesAndVia();
    for (Integer itrIdx : switchVia.keySet()) {
        HashMap<DeviceId, ArrayList<ArrayList<DeviceId>>> swViaMap = switchVia.get(itrIdx);
        for (DeviceId targetSw : swViaMap.keySet()) {
            Set<DeviceId> nextHops = new HashSet<>();
            for (ArrayList<DeviceId> via : swViaMap.get(targetSw)) {
                if (via.isEmpty()) {
                    nextHops.add(destSw);
                } else {
                    nextHops.add(via.get(0));
                }
            }
            if (!populateEcmpRoutingRulePartial(targetSw, destSw, nextHops)) {
                return false;
            }
        }
    }
    return true;
}
#end_block

#method_before
private boolean populateEcmpRoutingRulePartial(DeviceId targetSw, DeviceId destSw, Set<DeviceId> nextHops) {
    boolean result;
    if (nextHops.isEmpty()) {
        nextHops.add(destSw);
    }
    // for both subnet and router IP.
    if (config.isEdgeRouter(targetSw) && config.isEdgeRouter(destSw)) {
        List<Ip4Prefix> subnets = config.getSubnetInfo(destSw);
        result = rulePopulator.populateIpRuleForSubnet(targetSw, subnets, destSw, nextHops);
        if (!result) {
            return false;
        }
        IpPrefix routerIp = config.getRouterIpAddress(destSw);
        result = rulePopulator.populateIpRuleForRouter(targetSw, routerIp, destSw, nextHops);
        if (!result) {
            return false;
        }
    // If the target switch is an edge router, then set IP rules for the
    // router IP.
    } else if (config.isEdgeRouter(targetSw)) {
        IpPrefix routerIp = config.getRouterIpAddress(destSw);
        result = rulePopulator.populateIpRuleForRouter(targetSw, routerIp, destSw, nextHops);
        if (!result) {
            return false;
        }
    // If the target switch is an transit router, then set MPLS rules
    // only.
    } else if (config.isTransitRouter(targetSw)) {
        result = rulePopulator.populateMplsRule(targetSw, destSw, nextHops);
        if (!result) {
            return false;
        }
    } else {
        log.warn("The switch {} is neither an edge router nor a transit router.", targetSw);
        return false;
    }
    return true;
}
#method_after
private boolean populateEcmpRoutingRulePartial(DeviceId targetSw, DeviceId destSw, Set<DeviceId> nextHops) {
    boolean result;
    if (nextHops.isEmpty()) {
        nextHops.add(destSw);
    }
    // for both subnet and router IP.
    if (config.isEdgeDevice(targetSw) && config.isEdgeDevice(destSw)) {
        List<Ip4Prefix> subnets = config.getSubnets(destSw);
        result = rulePopulator.populateIpRuleForSubnet(targetSw, subnets, destSw, nextHops);
        if (!result) {
            return false;
        }
        Ip4Address routerIp = config.getRouterIp(destSw);
        IpPrefix routerIpPrefix = IpPrefix.valueOf(routerIp, IpPrefix.MAX_INET_MASK_LENGTH);
        result = rulePopulator.populateIpRuleForRouter(targetSw, routerIpPrefix, destSw, nextHops);
        if (!result) {
            return false;
        }
    // TODO: If the target switch is an edge router, then set IP rules for the router IP.
    } else if (config.isEdgeDevice(targetSw)) {
        Ip4Address routerIp = config.getRouterIp(destSw);
        IpPrefix routerIpPrefix = IpPrefix.valueOf(routerIp, IpPrefix.MAX_INET_MASK_LENGTH);
        result = rulePopulator.populateIpRuleForRouter(targetSw, routerIpPrefix, destSw, nextHops);
        if (!result) {
            return false;
        }
    // TODO: If the target switch is an transit router, then set MPLS rules only.
    } else if (!config.isEdgeDevice(targetSw)) {
        result = rulePopulator.populateMplsRule(targetSw, destSw, nextHops);
        if (!result) {
            return false;
        }
    }
    return true;
}
#end_block

#method_before
public void populateTtpRules(DeviceId deviceId) {
    /*
         * rulePopulator.populateTableMissEntry(deviceId, FlowRule.Type.VLAN,
         * true, false, false, FlowRule.Type.DEFAULT);
         * rulePopulator.populateTableMissEntry(deviceId, FlowRule.Type.ETHER,
         * true, false, false, FlowRule.Type.DEFAULT);
         * rulePopulator.populateTableMissEntry(deviceId, FlowRule.Type.IP,
         * false, true, true, FlowRule.Type.ACL);
         * rulePopulator.populateTableMissEntry(deviceId, FlowRule.Type.MPLS,
         * false, true, true, FlowRule.Type.ACL);
         * rulePopulator.populateTableMissEntry(deviceId, FlowRule.Type.ACL,
         * false, false, false, FlowRule.Type.DEFAULT);
         */
    rulePopulator.populateTableVlan(deviceId);
    rulePopulator.populateTableTMac(deviceId);
}
#method_after
public void populateTtpRules(DeviceId deviceId) {
    rulePopulator.populateTableVlan(deviceId);
    rulePopulator.populateTableTMac(deviceId);
}
#end_block

#method_before
public Map<IpPrefix, McastGroup> getMrib4() {
    return mrib4;
}
#method_after
public Map<IpPrefix, McastRouteGroup> getMrib4() {
    return mrib4;
}
#end_block

#method_before
public Map<IpPrefix, McastGroup> getMrib6() {
    return mrib6;
}
#method_after
public Map<IpPrefix, McastRouteGroup> getMrib6() {
    return mrib6;
}
#end_block

#method_before
private void storeMcastGroup(McastGroup group) {
    if (group.isIp4()) {
        mrib4.put(group.getGaddr(), group);
    } else {
        if (ipv6Enabled) {
            mrib6.put(group.getGaddr(), group);
        }
    }
}
#method_after
private void storeMcastGroup(McastRouteGroup group) {
    if (group.isIp4()) {
        mrib4.put(group.getGaddr(), group);
    } else {
        if (ipv6Enabled) {
            mrib6.put(group.getGaddr(), group);
        }
    }
}
#end_block

#method_before
/**
 */
public McastRoute addRoute(String saddr, String gaddr) {
    IpPrefix gpfx = IpPrefix.valueOf(gaddr);
    IpPrefix spfx = IpPrefix.valueOf(0, 0);
    if (saddr != null && !saddr.equals("*")) {
        spfx = IpPrefix.valueOf(saddr);
    }
    return addRoute(spfx, gpfx);
}
#method_after
/**
 */
public McastRouteBase addRoute(String saddr, String gaddr) {
    IpPrefix gpfx = IpPrefix.valueOf(gaddr);
    IpPrefix spfx = IpPrefix.valueOf(0, 0);
    if (saddr != null && !saddr.equals("*")) {
        spfx = IpPrefix.valueOf(saddr);
    }
    return addRoute(spfx, gpfx);
}
#end_block

#method_before
public McastRoute addRoute(IpPrefix spfx, IpPrefix gpfx) {
    /**
     * If a group route (*, g) does not exist we will need to make so we
     * can start attaching our sources to the group entry.
     */
    McastGroup group = findMcastGroup(gpfx);
    if (group == null) {
        group = new McastGroup(gpfx);
        // Save it for later
        if (gpfx.isIp4()) {
            this.mrib4.put(gpfx, group);
        } else {
            if (ipv6Enabled) {
                this.mrib6.put(gpfx, group);
            }
        }
    }
    /**
     * If the source prefix length is 0 then we have our (*, g) entry, we can
     * just return now.
     */
    if (spfx.prefixLength() == 0) {
        return group;
    }
    // See if the source already exists.  If so just return it.
    McastSource source = group.findSource(spfx);
    if (source != null) {
        return source;
    }
    /**
     * We have the group but no source.  We need to create the source then add it
     * to the group.
     */
    source = new McastSource(spfx, gpfx);
    // Have the source save it's parent
    source.setGroup(group);
    // Save this source as part of this group
    group.addSource(source);
    return source;
}
#method_after
public McastRouteBase addRoute(IpPrefix spfx, IpPrefix gpfx) {
    /**
     * If a group route (*, g) does not exist we will need to make so we
     * can start attaching our sources to the group entry.
     */
    McastRouteGroup group = findMcastGroup(gpfx);
    if (group == null) {
        group = new McastRouteGroup(gpfx);
        // Save it for later
        if (gpfx.isIp4()) {
            this.mrib4.put(gpfx, group);
        } else {
            if (ipv6Enabled) {
                this.mrib6.put(gpfx, group);
            }
        }
    }
    /**
     * If the source prefix length is 0 then we have our (*, g) entry, we can
     * just return now.
     */
    if (spfx.prefixLength() == 0) {
        return group;
    }
    // See if the source already exists.  If so just return it.
    McastRouteSource source = group.findSource(spfx);
    if (source != null) {
        return source;
    }
    /**
     * We have the group but no source.  We need to create the source then add it
     * to the group.
     */
    source = new McastRouteSource(spfx, gpfx);
    // Have the source save it's parent
    source.setGroup(group);
    // Save this source as part of this group
    group.addSource(source);
    return source;
}
#end_block

#method_before
private void storeGroup(McastGroup group) {
    if (group.isIp4()) {
        mrib4.put(group.getGaddr(), group);
    } else {
        if (ipv6Enabled) {
            mrib6.put(group.getGaddr(), group);
        }
    }
}
#method_after
private void storeGroup(McastRouteGroup group) {
    if (group.isIp4()) {
        mrib4.put(group.getGaddr(), group);
    } else {
        if (ipv6Enabled) {
            mrib6.put(group.getGaddr(), group);
        }
    }
}
#end_block

#method_before
public McastGroup findMcastGroup(IpPrefix group) {
    McastGroup g = null;
    if (group.isIp4()) {
        g = mrib4.get(group);
    } else {
        if (ipv6Enabled) {
            g = mrib6.get(group);
        }
    }
    return g;
}
#method_after
public McastRouteGroup findMcastGroup(IpPrefix group) {
    McastRouteGroup g = null;
    if (group.isIp4()) {
        g = mrib4.get(group);
    } else {
        if (ipv6Enabled) {
            g = mrib6.get(group);
        }
    }
    return g;
}
#end_block

#method_before
public McastSource findMcastSource(IpPrefix gaddr, IpPrefix saddr) {
    McastGroup grp = findMcastGroup(checkNotNull(gaddr));
    if (grp == null) {
        return null;
    }
    return grp.findSource(saddr);
}
#method_after
public McastRouteSource findMcastSource(IpPrefix gaddr, IpPrefix saddr) {
    McastRouteGroup grp = findMcastGroup(checkNotNull(gaddr));
    if (grp == null) {
        return null;
    }
    return grp.findSource(saddr);
}
#end_block

#method_before
public McastRouteInterface findBestMatch(IpPrefix saddr, IpPrefix gaddr) {
    McastGroup grp = this.findMcastGroup(checkNotNull(gaddr));
    if (grp == null) {
        return null;
    }
    // Found a group now look for a source
    McastSource src = grp.findSource(checkNotNull(saddr));
    if (src == null) {
        return grp;
    }
    return src;
}
#method_after
public McastRoute findBestMatch(IpPrefix saddr, IpPrefix gaddr) {
    McastRouteGroup grp = this.findMcastGroup(checkNotNull(gaddr));
    if (grp == null) {
        return null;
    }
    // Found a group now look for a source
    McastRouteSource src = grp.findSource(checkNotNull(saddr));
    if (src == null) {
        return grp;
    }
    return src;
}
#end_block

#method_before
public void addStaticRoutes() {
    // Hard code group interest for a couple different groups and some receive points.
    // XXX this will go away as soon as the mcast-join cli command has been added
    McastRoute g1 = this.addRoute("*", "225.1.1.1/32");
    g1.addIngressPoint("of:0000000000000023", 4);
    g1.addEgressPoint("of:0000000000000023", 3);
    McastRoute s1 = this.addRoute("10.1.1.1/32", "225.1.1.1/32");
    s1.addIngressPoint("of:0000000000000011", 3);
    s1.addEgressPoint("of:0000000000000023", 3);
    s1.addEgressPoint("of:0000000000000023", 4);
    McastRoute s2 = this.addRoute("10.1.1.2/32", "226.1.1.1/32");
    s2.addIngressPoint("of:0000000000000012", 3);
    s2.addEgressPoint("of:0000000000000023", 4);
    s2.addEgressPoint("of:0000000000000023", 5);
}
#method_after
public void addStaticRoutes() {
    // Hard code group interest for a couple different groups and some receive points.
    // XXX this will go away as soon as the mcast-join cli command has been added
    McastRouteBase g1 = this.addRoute("*", "225.1.1.1/32");
    g1.addIngressPoint("of:0000000000000023", 4);
    g1.addEgressPoint("of:0000000000000023", 3);
    McastRouteBase s1 = this.addRoute("10.1.1.1/32", "225.1.1.1/32");
    s1.addIngressPoint("of:0000000000000011", 3);
    s1.addEgressPoint("of:0000000000000023", 3);
    s1.addEgressPoint("of:0000000000000023", 4);
    McastRouteBase s2 = this.addRoute("10.1.1.2/32", "226.1.1.1/32");
    s2.addIngressPoint("of:0000000000000012", 3);
    s2.addEgressPoint("of:0000000000000023", 4);
    s2.addEgressPoint("of:0000000000000023", 5);
}
#end_block

#method_before
public String printMcastRouteTable() {
    String out = this.toString() + "\n";
    for (McastGroup grp : mrib4.values()) {
        out += grp.toString() + "\n";
        for (McastSource src : grp.getSources().values()) {
            out += src.toString() + "\n";
        }
    }
    return out;
}
#method_after
public String printMcastRouteTable() {
    String out = this.toString() + "\n";
    for (McastRouteGroup grp : mrib4.values()) {
        out += grp.toString() + "\n";
        for (McastRouteSource src : grp.getSources().values()) {
            out += src.toString() + "\n";
        }
    }
    return out;
}
#end_block

#method_before
@GET
@Path("show-all")
@Produces(MediaType.APPLICATION_JSON)
public Response showAll() throws IOException {
    final Iterable<Device> devices = get(DeviceService.class).getDevices();
    for (final Device device : devices) {
        final Iterable<FlowEntry> deviceEntries = service.getFlowEntries(device.id());
        if (deviceEntries != null) {
            for (final FlowEntry entry : deviceEntries) {
                flowsNode.add(codec(FlowEntry.class).encode(entry, this));
            }
        }
    }
    return ok(root).build();
}
#method_after
@GET
@Produces(MediaType.APPLICATION_JSON)
public Response showAll() throws IOException {
    ObjectMapper mapper = new ObjectMapper();
    McastRouteTable mcastRouteTable = McastRouteTable.getInstance();
    Map<IpPrefix, McastRouteGroup> map = mcastRouteTable.getMrib4();
    return Response.ok(mapper.createObjectNode().toString()).build();
}
#end_block

#method_before
@POST
@Path("join")
@Consumes(MediaType.APPLICATION_JSON)
@Produces(MediaType.APPLICATION_JSON)
public Response join(InputStream input) throws IOException {
    ObjectMapper mapper = new ObjectMapper();
    JsonNode cfg = mapper.readTree(input);
    // DemoAPI demo = get(DemoAPI.class);
    return null;
}
#method_after
@POST
@Consumes(MediaType.APPLICATION_JSON)
@Produces(MediaType.APPLICATION_JSON)
public Response join(InputStream input) throws IOException {
    ObjectMapper mapper = new ObjectMapper();
    JsonNode cfg = mapper.readTree(input);
    return null;
}
#end_block

#method_before
@Override
public boolean prepare(Transaction transaction) {
    try {
        if (transaction.updates().stream().anyMatch(update -> isLockedByAnotherTransaction(update.tableName(), update.key(), transaction.id()))) {
            return false;
        }
        if (transaction.updates().stream().allMatch(this::isUpdatePossible)) {
            transaction.updates().forEach(update -> doProvisionalUpdate(update, transaction.id()));
            return true;
        }
    } catch (Exception e) {
        log.info("Caught exception", e);
    }
    return false;
}
#method_after
@Override
public boolean prepare(Transaction transaction) {
    if (transaction.updates().stream().anyMatch(update -> isLockedByAnotherTransaction(update.tableName(), update.key(), transaction.id()))) {
        return false;
    }
    if (transaction.updates().stream().allMatch(this::isUpdatePossible)) {
        transaction.updates().forEach(update -> doProvisionalUpdate(update, transaction.id()));
        return true;
    }
    return false;
}
#end_block

#method_before
public static Frequency ofMHz(long value) {
    return new Frequency(value);
}
#method_after
public static Frequency ofMHz(double value) {
    return new Frequency((long) (value * MHZ));
}
#end_block

#method_before
public static Frequency ofGHz(long value) {
    return new Frequency(value * 1_000);
}
#method_after
public static Frequency ofGHz(double value) {
    return new Frequency((long) (value * GHZ));
}
#end_block

#method_before
public static Frequency ofTHz(long value) {
    return new Frequency(value * 1_000_000);
}
#method_after
public static Frequency ofTHz(double value) {
    return new Frequency((long) (value * THZ));
}
#end_block

#method_before
@Override
public String toString() {
    return MoreObjects.toStringHelper(this).add("frequency", frequency + "MHz").toString();
}
#method_after
@Override
public String toString() {
    return MoreObjects.toStringHelper(this).add("frequency", frequency + "Hz").toString();
}
#end_block

#method_before
@Test
public void testEquality() {
    new EqualsTester().addEqualityGroup(frequency1, sameFrequency1).addEqualityGroup(frequency2, sameFrequency2, moreSameFrequency2).testEquals();
}
#method_after
@Test
public void testEquality() {
    new EqualsTester().addEqualityGroup(frequency1, sameFrequency1).addEqualityGroup(frequency2, sameFrequency2, moreSameFrequency2).addEqualityGroup(frequency3, sameFrequency3).testEquals();
}
#end_block

#method_before
public void processPacketIn(InboundPacket pkt) {
    Ethernet ethernet = pkt.parsed();
    IPv4 ipv4 = (IPv4) ethernet.getPayload();
    ConnectPoint connectPoint = pkt.receivedFrom();
    DeviceId deviceId = connectPoint.deviceId();
    Ip4Address destinationAddress = Ip4Address.valueOf(ipv4.getDestinationAddress());
    List<Ip4Address> gatewayIpAddresses = config.getSubnetGatewayIps(deviceId);
    Ip4Address routerIp = config.getRouterIp(deviceId);
    IpPrefix routerIpPrefix = IpPrefix.valueOf(routerIp, IpPrefix.MAX_INET_MASK_LENGTH);
    Ip4Address routerIpAddress = routerIpPrefix.getIp4Prefix().address();
    // ICMP to the router IP or gateway IP
    if (((ICMP) ipv4.getPayload()).getIcmpType() == ICMP.TYPE_ECHO_REQUEST && (destinationAddress.equals(routerIpAddress) || gatewayIpAddresses.contains(destinationAddress))) {
        sendICMPResponse(ethernet, connectPoint);
    // TODO: do we need to set the flow rule again ??
    // ICMP for any known host
    } else if (!srManager.hostService.getHostsByIp(destinationAddress).isEmpty()) {
        srManager.ipHandler.forwardPackets(deviceId, destinationAddress);
    // ICMP for an unknown host in the subnet of the router
    } else if (inSameSubnet(deviceId, destinationAddress)) {
        srManager.arpHandler.sendArpRequest(deviceId, destinationAddress, connectPoint);
    // ICMP for an unknown host
    } else {
        log.debug("ICMP request for unknown host {} ", destinationAddress);
    // Do nothing
    }
}
#method_after
public void processPacketIn(InboundPacket pkt) {
    Ethernet ethernet = pkt.parsed();
    IPv4 ipv4 = (IPv4) ethernet.getPayload();
    ConnectPoint connectPoint = pkt.receivedFrom();
    DeviceId deviceId = connectPoint.deviceId();
    Ip4Address destinationAddress = Ip4Address.valueOf(ipv4.getDestinationAddress());
    List<Ip4Address> gatewayIpAddresses = config.getSubnetGatewayIps(deviceId);
    Ip4Address routerIp = config.getRouterIp(deviceId);
    IpPrefix routerIpPrefix = IpPrefix.valueOf(routerIp, IpPrefix.MAX_INET_MASK_LENGTH);
    Ip4Address routerIpAddress = routerIpPrefix.getIp4Prefix().address();
    // ICMP to the router IP or gateway IP
    if (((ICMP) ipv4.getPayload()).getIcmpType() == ICMP.TYPE_ECHO_REQUEST && (destinationAddress.equals(routerIpAddress) || gatewayIpAddresses.contains(destinationAddress))) {
        sendICMPResponse(ethernet, connectPoint);
    // TODO: do we need to set the flow rule again ??
    // ICMP for any known host
    } else if (!srManager.hostService.getHostsByIp(destinationAddress).isEmpty()) {
        srManager.ipHandler.forwardPackets(deviceId, destinationAddress);
    // ICMP for an unknown host in the subnet of the router
    } else if (config.inSameSubnet(deviceId, destinationAddress)) {
        srManager.arpHandler.sendArpRequest(deviceId, destinationAddress, connectPoint);
    // ICMP for an unknown host
    } else {
        log.debug("ICMP request for unknown host {} ", destinationAddress);
    // Do nothing
    }
}
#end_block

#method_before
private void sendPacketOut(ConnectPoint outport, Ethernet payload, int sid) {
    IPv4 ipPacket = (IPv4) payload.getPayload();
    Ip4Address destIpAddress = Ip4Address.valueOf(ipPacket.getDestinationAddress());
    if (sid == -1 || config.getSegmentId(payload.getDestinationMAC()) == sid || inSameSubnet(outport.deviceId(), destIpAddress)) {
        TrafficTreatment treatment = DefaultTrafficTreatment.builder().setOutput(outport.port()).build();
        OutboundPacket packet = new DefaultOutboundPacket(outport.deviceId(), treatment, ByteBuffer.wrap(payload.serialize()));
        srManager.packetService.emit(packet);
    } else {
        log.warn("Send a MPLS packet as a ICMP response");
        TrafficTreatment treatment = DefaultTrafficTreatment.builder().setOutput(outport.port()).build();
        payload.setEtherType(Ethernet.MPLS_UNICAST);
        MPLS mplsPkt = new MPLS();
        mplsPkt.setLabel(sid);
        mplsPkt.setTtl(((IPv4) payload.getPayload()).getTtl());
        mplsPkt.setPayload(payload.getPayload());
        payload.setPayload(mplsPkt);
        OutboundPacket packet = new DefaultOutboundPacket(outport.deviceId(), treatment, ByteBuffer.wrap(payload.serialize()));
        srManager.packetService.emit(packet);
    }
}
#method_after
private void sendPacketOut(ConnectPoint outport, Ethernet payload, int sid) {
    IPv4 ipPacket = (IPv4) payload.getPayload();
    Ip4Address destIpAddress = Ip4Address.valueOf(ipPacket.getDestinationAddress());
    if (sid == -1 || config.getSegmentId(payload.getDestinationMAC()) == sid || config.inSameSubnet(outport.deviceId(), destIpAddress)) {
        TrafficTreatment treatment = DefaultTrafficTreatment.builder().setOutput(outport.port()).build();
        OutboundPacket packet = new DefaultOutboundPacket(outport.deviceId(), treatment, ByteBuffer.wrap(payload.serialize()));
        srManager.packetService.emit(packet);
    } else {
        log.warn("Send a MPLS packet as a ICMP response");
        TrafficTreatment treatment = DefaultTrafficTreatment.builder().setOutput(outport.port()).build();
        payload.setEtherType(Ethernet.MPLS_UNICAST);
        MPLS mplsPkt = new MPLS();
        mplsPkt.setLabel(sid);
        mplsPkt.setTtl(((IPv4) payload.getPayload()).getTtl());
        mplsPkt.setPayload(payload.getPayload());
        payload.setPayload(mplsPkt);
        OutboundPacket packet = new DefaultOutboundPacket(outport.deviceId(), treatment, ByteBuffer.wrap(payload.serialize()));
        srManager.packetService.emit(packet);
    }
}
#end_block

#method_before
public void processPacketIn(InboundPacket pkt) {
    Ethernet ethernet = pkt.parsed();
    IPv4 ipv4 = (IPv4) ethernet.getPayload();
    ConnectPoint connectPoint = pkt.receivedFrom();
    DeviceId deviceId = connectPoint.deviceId();
    Ip4Address destinationAddress = Ip4Address.valueOf(ipv4.getDestinationAddress());
    // IP packet for know hosts
    if (!srManager.hostService.getHostsByIp(destinationAddress).isEmpty()) {
        forwardPackets(deviceId, destinationAddress);
    // IP packet for unknown host in the subnet of the router
    } else if (inSameSubnet(deviceId, destinationAddress)) {
        srManager.arpHandler.sendArpRequest(deviceId, destinationAddress, connectPoint);
    // IP packets for unknown host
    } else {
        log.debug("ICMP request for unknown host {} which is not in the subnet", destinationAddress);
    // Do nothing
    }
}
#method_after
public void processPacketIn(InboundPacket pkt) {
    Ethernet ethernet = pkt.parsed();
    IPv4 ipv4 = (IPv4) ethernet.getPayload();
    ConnectPoint connectPoint = pkt.receivedFrom();
    DeviceId deviceId = connectPoint.deviceId();
    Ip4Address destinationAddress = Ip4Address.valueOf(ipv4.getDestinationAddress());
    // IP packet for know hosts
    if (!srManager.hostService.getHostsByIp(destinationAddress).isEmpty()) {
        forwardPackets(deviceId, destinationAddress);
    // IP packet for unknown host in the subnet of the router
    } else if (config.inSameSubnet(deviceId, destinationAddress)) {
        srManager.arpHandler.sendArpRequest(deviceId, destinationAddress, connectPoint);
    // IP packets for unknown host
    } else {
        log.debug("ICMP request for unknown host {} which is not in the subnet", destinationAddress);
    // Do nothing
    }
}
#end_block

#method_before
public void forwardPackets(DeviceId deviceId, Ip4Address destIpAddress) {
    for (IPv4 ipPacket : ipPacketQueue.get(destIpAddress)) {
        Ip4Address destAddress = Ip4Address.valueOf(ipPacket.getDestinationAddress());
        if (ipPacket != null && inSameSubnet(deviceId, destAddress)) {
            ipPacket.setTtl((byte) (ipPacket.getTtl() - 1));
            ipPacket.setChecksum((short) 0);
            for (Host dest : srManager.hostService.getHostsByIp(destIpAddress)) {
                Ethernet eth = new Ethernet();
                eth.setDestinationMACAddress(dest.mac());
                eth.setSourceMACAddress(config.getDeviceMac(deviceId));
                eth.setEtherType(Ethernet.TYPE_IPV4);
                eth.setPayload(ipPacket);
                TrafficTreatment treatment = DefaultTrafficTreatment.builder().setOutput(dest.location().port()).build();
                OutboundPacket packet = new DefaultOutboundPacket(deviceId, treatment, ByteBuffer.wrap(eth.serialize()));
                srManager.packetService.emit(packet);
            }
            ipPacketQueue.get(destIpAddress).remove(ipPacket);
        }
    }
}
#method_after
public void forwardPackets(DeviceId deviceId, Ip4Address destIpAddress) {
    for (IPv4 ipPacket : ipPacketQueue.get(destIpAddress)) {
        Ip4Address destAddress = Ip4Address.valueOf(ipPacket.getDestinationAddress());
        if (ipPacket != null && config.inSameSubnet(deviceId, destAddress)) {
            ipPacket.setTtl((byte) (ipPacket.getTtl() - 1));
            ipPacket.setChecksum((short) 0);
            for (Host dest : srManager.hostService.getHostsByIp(destIpAddress)) {
                Ethernet eth = new Ethernet();
                eth.setDestinationMACAddress(dest.mac());
                eth.setSourceMACAddress(config.getDeviceMac(deviceId));
                eth.setEtherType(Ethernet.TYPE_IPV4);
                eth.setPayload(ipPacket);
                TrafficTreatment treatment = DefaultTrafficTreatment.builder().setOutput(dest.location().port()).build();
                OutboundPacket packet = new DefaultOutboundPacket(deviceId, treatment, ByteBuffer.wrap(eth.serialize()));
                srManager.packetService.emit(packet);
                ipPacketQueue.get(destIpAddress).remove(ipPacket);
            }
            ipPacketQueue.get(destIpAddress).remove(ipPacket);
        }
    }
}
#end_block

#method_before
@Override
public void event(DeviceEvent event) {
    if (mastershipService.getLocalRole(event.subject().id()) != MastershipRole.MASTER) {
        log.debug("Local role {} is not MASTER for device {}", mastershipService.getLocalRole(event.subject().id()), event.subject().id());
        return;
    }
    switch(event.type()) {
        case DEVICE_ADDED:
        case PORT_REMOVED:
            scheduleEventHandlerIfNotScheduled(event);
            break;
        default:
    }
}
#method_after
@Override
public void event(DeviceEvent event) {
    if (mastershipService.getLocalRole(event.subject().id()) != MastershipRole.MASTER) {
        log.debug("Local role {} is not MASTER for device {}", mastershipService.getLocalRole(event.subject().id()), event.subject().id());
        return;
    }
    switch(event.type()) {
        case DEVICE_ADDED:
        case PORT_REMOVED:
        case DEVICE_UPDATED:
        case DEVICE_AVAILABILITY_CHANGED:
            scheduleEventHandlerIfNotScheduled(event);
            break;
        default:
    }
}
#end_block

#method_before
@Override
public void run() {
    numOfHandlerExecution++;
    while (!eventQueue.isEmpty()) {
        Event event = eventQueue.poll();
        if (event.type() == LinkEvent.Type.LINK_ADDED) {
            processLinkAdded((Link) event.subject());
        } else if (event.type() == LinkEvent.Type.LINK_REMOVED) {
            processLinkRemoved((Link) event.subject());
        } else if (event.type() == GroupEvent.Type.GROUP_ADDED) {
            processGroupAdded((Group) event.subject());
        } else if (event.type() == DeviceEvent.Type.DEVICE_ADDED) {
            processDeviceAdded((Device) event.subject());
        } else if (event.type() == DeviceEvent.Type.PORT_REMOVED) {
            processPortRemoved((Device) event.subject(), ((DeviceEvent) event).port());
        } else {
            log.warn("Unhandled event type: {}", event.type());
        }
    }
    log.debug("numOfHandlerExecution {} numOfEventHanlderScheduled {} numOfEvents {}", numOfHandlerExecution, numOfHandlerScheduled, numOfEvents);
}
#method_after
@Override
public void run() {
    numOfHandlerExecution++;
    while (!eventQueue.isEmpty()) {
        Event event = eventQueue.poll();
        if (event.type() == LinkEvent.Type.LINK_ADDED) {
            processLinkAdded((Link) event.subject());
        } else if (event.type() == LinkEvent.Type.LINK_REMOVED) {
            processLinkRemoved((Link) event.subject());
        } else if (event.type() == GroupEvent.Type.GROUP_ADDED) {
            processGroupAdded((Group) event.subject());
        } else if (event.type() == DeviceEvent.Type.DEVICE_ADDED || event.type() == DeviceEvent.Type.DEVICE_AVAILABILITY_CHANGED || event.type() == DeviceEvent.Type.DEVICE_UPDATED) {
            if (deviceService.isAvailable(((Device) event.subject()).id())) {
                processDeviceAdded((Device) event.subject());
            }
        } else if (event.type() == DeviceEvent.Type.PORT_REMOVED) {
            processPortRemoved((Device) event.subject(), ((DeviceEvent) event).port());
        } else {
            log.warn("Unhandled event type: {}", event.type());
        }
    }
    log.debug("numOfHandlerExecution {} numOfEventHanlderScheduled {} numOfEvents {}", numOfHandlerExecution, numOfHandlerScheduled, numOfEvents);
}
#end_block

#method_before
private void processLinkAdded(Link link) {
    log.debug("A new link {} was added", link.toString());
    if (mastershipService.getLocalRole(link.src().deviceId()) == MastershipRole.MASTER) {
        DefaultGroupHandler groupHandler = groupHandlerMap.get(link.src().deviceId());
        if (groupHandler != null) {
            groupHandler.linkUp(link);
        }
    }
    defaultRoutingHandler.startPopulationProcess();
}
#method_after
private void processLinkAdded(Link link) {
    log.debug("A new link {} was added", link.toString());
    if (mastershipService.getLocalRole(link.src().deviceId()) == MastershipRole.MASTER) {
        DefaultGroupHandler groupHandler = groupHandlerMap.get(link.src().deviceId());
        if (groupHandler != null) {
            groupHandler.linkUp(link);
        }
    }
    defaultRoutingHandler.populateRoutingRulesForLinkStatusChange(null);
}
#end_block

#method_before
private void processLinkRemoved(Link link) {
    log.debug("A link {} was removed", link.toString());
    defaultRoutingHandler.startPopulationProcess();
}
#method_after
private void processLinkRemoved(Link link) {
    log.debug("A link {} was removed", link.toString());
    defaultRoutingHandler.populateRoutingRulesForLinkStatusChange(link);
}
#end_block

#method_before
public boolean populateAllRoutingRules() {
    populationStatus = Status.STARTED;
    log.info("Starts to populate routing rules");
    for (Device sw : srManager.deviceService.getDevices()) {
        if (srManager.mastershipService.getLocalRole(sw.id()) != MastershipRole.MASTER) {
            continue;
        }
        ECMPShortestPathGraph ecmpSPG = new ECMPShortestPathGraph(sw.id(), srManager);
        if (!populateEcmpRoutingRules(sw, ecmpSPG)) {
            populationStatus = Status.ABORTED;
            log.debug("Abort routing rule population");
            return false;
        }
    // TODO: Set adjacency routing rule for all switches
    }
    populationStatus = Status.SUCCEEDED;
    log.info("Completes routing rule population");
    return true;
}
#method_after
public boolean populateAllRoutingRules() {
    populationStatus = Status.STARTED;
    rulePopulator.resetCounter();
    log.info("Starts to populate routing rules");
    for (Device sw : srManager.deviceService.getDevices()) {
        if (srManager.mastershipService.getLocalRole(sw.id()) != MastershipRole.MASTER) {
            continue;
        }
        ECMPShortestPathGraph ecmpSpg = new ECMPShortestPathGraph(sw.id(), srManager);
        if (!populateEcmpRoutingRules(sw.id(), ecmpSpg)) {
            populationStatus = Status.ABORTED;
            log.debug("Abort routing rule population");
            return false;
        }
        currentEcmpSpgMap.put(sw.id(), ecmpSpg);
    // TODO: Set adjacency routing rule for all switches
    }
    populationStatus = Status.SUCCEEDED;
    log.info("Completes routing rule population. Total # of rules pushed : {}", rulePopulator.getCounter());
    return true;
}
#end_block

#method_before
private boolean populateEcmpRoutingRules(Device sw, ECMPShortestPathGraph ecmpSPG) {
    HashMap<Integer, HashMap<DeviceId, ArrayList<ArrayList<DeviceId>>>> switchVia = ecmpSPG.getAllLearnedSwitchesAndVia();
    for (Integer itrIdx : switchVia.keySet()) {
        HashMap<DeviceId, ArrayList<ArrayList<DeviceId>>> swViaMap = switchVia.get(itrIdx);
        for (DeviceId targetSw : swViaMap.keySet()) {
            DeviceId destSw = sw.id();
            Set<DeviceId> nextHops = new HashSet<>();
            for (ArrayList<DeviceId> via : swViaMap.get(targetSw)) {
                if (via.isEmpty()) {
                    nextHops.add(destSw);
                } else {
                    nextHops.add(via.get(0));
                }
            }
            if (!populateEcmpRoutingRulePartial(targetSw, destSw, nextHops)) {
                return false;
            }
        }
    }
    return true;
}
#method_after
private boolean populateEcmpRoutingRules(DeviceId destSw, ECMPShortestPathGraph ecmpSPG) {
    HashMap<Integer, HashMap<DeviceId, ArrayList<ArrayList<DeviceId>>>> switchVia = ecmpSPG.getAllLearnedSwitchesAndVia();
    for (Integer itrIdx : switchVia.keySet()) {
        HashMap<DeviceId, ArrayList<ArrayList<DeviceId>>> swViaMap = switchVia.get(itrIdx);
        for (DeviceId targetSw : swViaMap.keySet()) {
            Set<DeviceId> nextHops = new HashSet<>();
            for (ArrayList<DeviceId> via : swViaMap.get(targetSw)) {
                if (via.isEmpty()) {
                    nextHops.add(destSw);
                } else {
                    nextHops.add(via.get(0));
                }
            }
            if (!populateEcmpRoutingRulePartial(targetSw, destSw, nextHops)) {
                return false;
            }
        }
    }
    return true;
}
#end_block

#method_before
public void populateIpRuleForHost(DeviceId deviceId, Ip4Address hostIp, MacAddress hostMac, PortNumber outPort) {
    TrafficSelector.Builder sbuilder = DefaultTrafficSelector.builder();
    TrafficTreatment.Builder tbuilder = DefaultTrafficTreatment.builder();
    sbuilder.matchIPDst(IpPrefix.valueOf(hostIp, 32));
    sbuilder.matchEthType(Ethernet.TYPE_IPV4);
    tbuilder.setEthDst(hostMac).setEthSrc(config.getDeviceMac(deviceId)).setOutput(outPort);
    TrafficTreatment treatment = tbuilder.build();
    TrafficSelector selector = sbuilder.build();
    FlowRule f = new DefaultFlowRule(deviceId, selector, treatment, 100, srManager.appId, 600, false, FlowRule.Type.IP);
    srManager.flowRuleService.applyFlowRules(f);
    log.debug("Flow rule {} is set to switch {}", f, deviceId);
}
#method_after
public void populateIpRuleForHost(DeviceId deviceId, Ip4Address hostIp, MacAddress hostMac, PortNumber outPort) {
    TrafficSelector.Builder sbuilder = DefaultTrafficSelector.builder();
    TrafficTreatment.Builder tbuilder = DefaultTrafficTreatment.builder();
    sbuilder.matchIPDst(IpPrefix.valueOf(hostIp, 32));
    sbuilder.matchEthType(Ethernet.TYPE_IPV4);
    tbuilder.setEthDst(hostMac).setEthSrc(config.getDeviceMac(deviceId)).setOutput(outPort);
    TrafficTreatment treatment = tbuilder.build();
    TrafficSelector selector = sbuilder.build();
    FlowRule f = new DefaultFlowRule(deviceId, selector, treatment, 100, srManager.appId, 600, false, FlowRule.Type.IP);
    srManager.flowRuleService.applyFlowRules(f);
    rulePopulationCounter.incrementAndGet();
    log.debug("Flow rule {} is set to switch {}", f, deviceId);
}
#end_block

#method_before
public boolean populateIpRuleForRouter(DeviceId deviceId, IpPrefix ipPrefix, DeviceId destSw, Set<DeviceId> nextHops) {
    TrafficSelector.Builder sbuilder = DefaultTrafficSelector.builder();
    TrafficTreatment.Builder tbuilder = DefaultTrafficTreatment.builder();
    sbuilder.matchIPDst(ipPrefix);
    sbuilder.matchEthType(Ethernet.TYPE_IPV4);
    NeighborSet ns = null;
    // If the next hop is the same as the final destination, then MPLS label is not set.
    if (nextHops.size() == 1 && nextHops.toArray()[0].equals(destSw)) {
        tbuilder.decNwTtl();
        ns = new NeighborSet(nextHops);
    } else {
        tbuilder.copyTtlOut();
        ns = new NeighborSet(nextHops, config.getSegmentId(destSw));
    }
    DefaultGroupKey groupKey = (DefaultGroupKey) srManager.getGroupKey(ns);
    if (groupKey == null) {
        log.warn("Group key is not found for ns {}", ns);
        return false;
    }
    Group group = srManager.groupService.getGroup(deviceId, groupKey);
    if (group != null) {
        tbuilder.group(group.id());
    } else {
        log.warn("No group found for NeighborSet {} from {} to {}", ns, deviceId, destSw);
        return false;
    }
    TrafficTreatment treatment = tbuilder.build();
    TrafficSelector selector = sbuilder.build();
    FlowRule f = new DefaultFlowRule(deviceId, selector, treatment, 100, srManager.appId, 600, false, FlowRule.Type.IP);
    srManager.flowRuleService.applyFlowRules(f);
    log.debug("IP flow rule {} is set to switch {}", f, deviceId);
    return true;
}
#method_after
public boolean populateIpRuleForRouter(DeviceId deviceId, IpPrefix ipPrefix, DeviceId destSw, Set<DeviceId> nextHops) {
    TrafficSelector.Builder sbuilder = DefaultTrafficSelector.builder();
    TrafficTreatment.Builder tbuilder = DefaultTrafficTreatment.builder();
    sbuilder.matchIPDst(ipPrefix);
    sbuilder.matchEthType(Ethernet.TYPE_IPV4);
    NeighborSet ns = null;
    // If the next hop is the same as the final destination, then MPLS label is not set.
    if (nextHops.size() == 1 && nextHops.toArray()[0].equals(destSw)) {
        tbuilder.decNwTtl();
        ns = new NeighborSet(nextHops);
    } else {
        tbuilder.copyTtlOut();
        ns = new NeighborSet(nextHops, config.getSegmentId(destSw));
    }
    DefaultGroupKey groupKey = (DefaultGroupKey) srManager.getGroupKey(ns);
    if (groupKey == null) {
        log.warn("Group key is not found for ns {}", ns);
        return false;
    }
    Group group = srManager.groupService.getGroup(deviceId, groupKey);
    if (group != null) {
        tbuilder.group(group.id());
    } else {
        log.warn("No group found for NeighborSet {} from {} to {}", ns, deviceId, destSw);
        return false;
    }
    TrafficTreatment treatment = tbuilder.build();
    TrafficSelector selector = sbuilder.build();
    FlowRule f = new DefaultFlowRule(deviceId, selector, treatment, 100, srManager.appId, 600, false, FlowRule.Type.IP);
    srManager.flowRuleService.applyFlowRules(f);
    rulePopulationCounter.incrementAndGet();
    log.debug("IP flow rule {} is set to switch {}", f, deviceId);
    return true;
}
#end_block

#method_before
public boolean populateMplsRule(DeviceId deviceId, DeviceId destSwId, Set<DeviceId> nextHops) {
    TrafficSelector.Builder sbuilder = DefaultTrafficSelector.builder();
    Collection<TrafficTreatment> treatments = new ArrayList<>();
    // TODO Handle the case of Bos == false
    sbuilder.matchMplsLabel(MplsLabel.mplsLabel(config.getSegmentId(destSwId)));
    sbuilder.matchEthType(Ethernet.MPLS_UNICAST);
    // If the next hop is the destination router, do PHP
    if (nextHops.size() == 1 && destSwId.equals(nextHops.toArray()[0])) {
        TrafficTreatment treatmentBos = getMplsTreatment(deviceId, destSwId, nextHops, true, true);
        TrafficTreatment treatment = getMplsTreatment(deviceId, destSwId, nextHops, true, false);
        if (treatmentBos != null) {
            treatments.add(treatmentBos);
        } else {
            log.warn("Failed to set MPLS rules.");
            return false;
        }
    } else {
        TrafficTreatment treatmentBos = getMplsTreatment(deviceId, destSwId, nextHops, false, true);
        TrafficTreatment treatment = getMplsTreatment(deviceId, destSwId, nextHops, false, false);
        if (treatmentBos != null) {
            treatments.add(treatmentBos);
        } else {
            log.warn("Failed to set MPLS rules.");
            return false;
        }
    }
    TrafficSelector selector = sbuilder.build();
    for (TrafficTreatment treatment : treatments) {
        FlowRule f = new DefaultFlowRule(deviceId, selector, treatment, 100, srManager.appId, 600, false, FlowRule.Type.MPLS);
        srManager.flowRuleService.applyFlowRules(f);
        log.debug("MPLS rule {} is set to {}", f, deviceId);
    }
    return true;
}
#method_after
public boolean populateMplsRule(DeviceId deviceId, DeviceId destSwId, Set<DeviceId> nextHops) {
    TrafficSelector.Builder sbuilder = DefaultTrafficSelector.builder();
    Collection<TrafficTreatment> treatments = new ArrayList<>();
    // TODO Handle the case of Bos == false
    sbuilder.matchMplsLabel(MplsLabel.mplsLabel(config.getSegmentId(destSwId)));
    sbuilder.matchEthType(Ethernet.MPLS_UNICAST);
    // If the next hop is the destination router, do PHP
    if (nextHops.size() == 1 && destSwId.equals(nextHops.toArray()[0])) {
        TrafficTreatment treatmentBos = getMplsTreatment(deviceId, destSwId, nextHops, true, true);
        TrafficTreatment treatment = getMplsTreatment(deviceId, destSwId, nextHops, true, false);
        if (treatmentBos != null) {
            treatments.add(treatmentBos);
        } else {
            log.warn("Failed to set MPLS rules.");
            return false;
        }
    } else {
        TrafficTreatment treatmentBos = getMplsTreatment(deviceId, destSwId, nextHops, false, true);
        TrafficTreatment treatment = getMplsTreatment(deviceId, destSwId, nextHops, false, false);
        if (treatmentBos != null) {
            treatments.add(treatmentBos);
        } else {
            log.warn("Failed to set MPLS rules.");
            return false;
        }
    }
    TrafficSelector selector = sbuilder.build();
    for (TrafficTreatment treatment : treatments) {
        FlowRule f = new DefaultFlowRule(deviceId, selector, treatment, 100, srManager.appId, 600, false, FlowRule.Type.MPLS);
        srManager.flowRuleService.applyFlowRules(f);
        rulePopulationCounter.incrementAndGet();
        log.debug("MPLS rule {} is set to {}", f, deviceId);
    }
    return true;
}
#end_block

#method_before
private void tryLeaderLock(String path) {
    if (!activeTopics.contains(path)) {
        return;
    }
    try {
        Versioned<List<NodeId>> candidates = candidateMap.get(path);
        if (candidates != null) {
            List<NodeId> activeNodes = candidates.value().stream().filter(n -> clusterService.getState(n) == ACTIVE).collect(Collectors.toList());
            log.info("activeNodes:{}", activeNodes);
            if (localNodeId.equals(activeNodes.get(LEADER_CANDIDATE_POS))) {
                leaderLockAttempt(path, candidates.value());
            } else {
                retryLock(path);
            }
        } else {
            throw new IllegalStateException("should not be here");
        }
    } catch (Exception e) {
        log.debug("Failed to fetch candidate information for {}", path, e);
        retryLock(path);
    }
}
#method_after
private void tryLeaderLock(String path) {
    if (!activeTopics.contains(path)) {
        return;
    }
    try {
        Versioned<List<NodeId>> candidates = candidateMap.get(path);
        if (candidates != null) {
            List<NodeId> activeNodes = candidates.value().stream().filter(n -> clusterService.getState(n) == ACTIVE).collect(Collectors.toList());
            if (localNodeId.equals(activeNodes.get(LEADER_CANDIDATE_POS))) {
                leaderLockAttempt(path, candidates.value());
            } else {
                retryLock(path);
            }
        } else {
            throw new IllegalStateException("should not be here");
        }
    } catch (Exception e) {
        log.debug("Failed to fetch candidate information for {}", path, e);
        retryLock(path);
    }
}
#end_block

#method_before
private void notifyCandidateAdded(String path, List<NodeId> candidates, long epoch, long electedTime) {
    Leadership newInfo = new Leadership(path, candidates, epoch, electedTime);
    final MutableBoolean updated = new MutableBoolean(false);
    candidateBoard.compute(path, (k, current) -> {
        if (current == null || current.epoch() < newInfo.epoch()) {
            log.info("updating candidateboard with {}", newInfo);
            updated.setTrue();
            return newInfo;
        }
        return current;
    });
    // maybe rethink types of candidates events
    if (updated.booleanValue()) {
        LeadershipEvent event = new LeadershipEvent(LeadershipEvent.Type.CANDIDATES_CHANGED, newInfo);
        notifyPeers(event);
    }
}
#method_after
private void notifyCandidateAdded(String path, List<NodeId> candidates, long epoch, long electedTime) {
    Leadership newInfo = new Leadership(path, candidates, epoch, electedTime);
    final MutableBoolean updated = new MutableBoolean(false);
    candidateBoard.compute(path, (k, current) -> {
        if (current == null || current.epoch() < newInfo.epoch()) {
            log.debug("updating candidateboard with {}", newInfo);
            updated.setTrue();
            return newInfo;
        }
        return current;
    });
    // maybe rethink types of candidates events
    if (updated.booleanValue()) {
        LeadershipEvent event = new LeadershipEvent(LeadershipEvent.Type.CANDIDATES_CHANGED, newInfo);
        notifyPeers(event);
    }
}
#end_block

#method_before
private void displayCandidates(Map<String, Leadership> leaderBoard, Map<String, List<NodeId>> candidates) {
    print("--------------------------------------------------------------");
    print(FMT_C, "Topic", "Leader", "Candidates");
    print("--------------------------------------------------------------");
    candidates.entrySet().stream().filter(es -> allTopics || pattern.matcher(es.getKey()).matches()).forEach(es -> {
        List<NodeId> list = es.getValue();
        Leadership l = leaderBoard.get(es.getKey());
        print(FMT_C, es.getKey(), l == null ? "none" : l.leader(), (list == null || list.isEmpty()) ? "none" : list.get(0).toString());
        // formatting hacks to get it into a table
        list.subList(1, list.size()).forEach(n -> print(FMT_C, " ", " ", n));
        print(FMT_C, " ", " ", " ");
    });
    print("--------------------------------------------------------------");
}
#method_after
private void displayCandidates(Map<String, Leadership> leaderBoard, Map<String, List<NodeId>> candidates) {
    print("--------------------------------------------------------------");
    print(FMT_C, "Topic", "Leader", "Candidates");
    print("--------------------------------------------------------------");
    candidates.entrySet().stream().filter(es -> allTopics || pattern.matcher(es.getKey()).matches()).forEach(es -> {
        List<NodeId> list = es.getValue();
        if (list == null || list.isEmpty()) {
            return;
        }
        Leadership l = leaderBoard.get(es.getKey());
        print(FMT_C, es.getKey(), l == null ? "null" : l.leader(), // formatting hacks to get it into a table
        list.get(0).toString());
        list.subList(1, list.size()).forEach(n -> print(FMT_C, " ", " ", n));
        print(FMT_C, " ", " ", " ");
    });
    print("--------------------------------------------------------------");
}
#end_block

#method_before
private void tryLeaderLock(String path) {
    if (!activeTopics.contains(path)) {
        return;
    }
    Versioned<List<NodeId>> candidates = candidateMap.get(path);
    if (candidates != null) {
        List<NodeId> activeNodes = candidates.value().stream().filter(n -> clusterService.getState(n).equals(State.ACTIVE)).collect(Collectors.toList());
        if (localNodeId.equals(activeNodes.get(LEADER_CANDIDATE_POS))) {
            leaderLockAttempt(path, candidates.value());
        } else {
            retryLock(path);
        }
    } else {
        throw new IllegalStateException("should not be here");
    }
}
#method_after
private void tryLeaderLock(String path) {
    if (!activeTopics.contains(path)) {
        return;
    }
    Versioned<List<NodeId>> candidates = candidateMap.get(path);
    if (candidates != null) {
        List<NodeId> activeNodes = candidates.value().stream().filter(n -> clusterService.getState(n) == ACTIVE).collect(Collectors.toList());
        if (localNodeId.equals(activeNodes.get(LEADER_CANDIDATE_POS))) {
            leaderLockAttempt(path, candidates.value());
        } else {
            retryLock(path);
        }
    } else {
        throw new IllegalStateException("should not be here");
    }
}
#end_block

#method_before
private void purgeStaleLocks() {
    try {
        leaderMap.entrySet().stream().filter(e -> clusterService.getState(e.getValue().value()).equals(State.INACTIVE)).filter(e -> activeTopics.contains(e.getKey())).forEach(entry -> {
            String path = entry.getKey();
            NodeId nodeId = entry.getValue().value();
            long epoch = entry.getValue().version();
            long creationTime = entry.getValue().creationTime();
            try {
                if (leaderMap.remove(path, epoch)) {
                    log.info("Purged stale lock held by {} for {}", nodeId, path);
                    notifyRemovedLeader(path, nodeId, epoch, creationTime);
                }
            } catch (Exception e) {
                log.warn("Failed to purge stale lock held by {} for {}", nodeId, path, e);
            }
        });
    } catch (Exception e) {
        log.debug("Failed cleaning up stale locks", e);
    }
}
#method_after
private void purgeStaleLocks() {
    try {
        leaderMap.entrySet().stream().filter(e -> clusterService.getState(e.getValue().value()) == INACTIVE).filter(e -> activeTopics.contains(e.getKey())).forEach(entry -> {
            String path = entry.getKey();
            NodeId nodeId = entry.getValue().value();
            long epoch = entry.getValue().version();
            long creationTime = entry.getValue().creationTime();
            try {
                if (leaderMap.remove(path, epoch)) {
                    log.info("Purged stale lock held by {} for {}", nodeId, path);
                    notifyRemovedLeader(path, nodeId, epoch, creationTime);
                }
            } catch (Exception e) {
                log.warn("Failed to purge stale lock held by {} for {}", nodeId, path, e);
            }
        });
    } catch (Exception e) {
        log.debug("Failed cleaning up stale locks", e);
    }
}
#end_block

#method_before
private void applyRule(FlowRule flowRule) {
    OpenFlowSwitch sw = controller.getSwitch(Dpid.dpid(flowRule.deviceId().uri()));
    if (flowRule.payLoad().payLoad().length > 0) {
        OFMessage msg = new ThirdPartyMessage(flowRule.payLoad().payLoad());
        sw.sendMsg(msg);
    }
    if (flowRule.payLoad().payLoad().length <= 0 && flowRule.type() == FlowRule.Type.DEFAULT) {
        sw.sendMsg(FlowModBuilder.builder(flowRule, sw.factory(), Optional.empty()).buildFlowAdd());
    } else {
        OpenFlowSwitch.TableType type = getTableType(flowRule.type());
        sw.transformAndSendMsg(FlowModBuilder.builder(flowRule, sw.factory(), Optional.empty()).buildFlowAdd(), type);
    }
}
#method_after
private void applyRule(FlowRule flowRule) {
    OpenFlowSwitch sw = controller.getSwitch(Dpid.dpid(flowRule.deviceId().uri()));
    if (flowRule.payLoad().payLoad().length > 0) {
        OFMessage msg = new ThirdPartyMessage(flowRule.payLoad().payLoad());
        sw.sendMsg(msg);
        return;
    }
    sw.sendMsg(FlowModBuilder.builder(flowRule, sw.factory(), Optional.empty()).buildFlowAdd());
}
#end_block

#method_before
private void removeRule(FlowRule flowRule) {
    OpenFlowSwitch sw = controller.getSwitch(Dpid.dpid(flowRule.deviceId().uri()));
    if (flowRule.payLoad().payLoad().length > 0) {
        OFMessage msg = new ThirdPartyMessage(flowRule.payLoad().payLoad());
        sw.sendMsg(msg);
    }
    if (flowRule.payLoad().payLoad().length <= 0 && flowRule.type() == FlowRule.Type.DEFAULT) {
        sw.sendMsg(FlowModBuilder.builder(flowRule, sw.factory(), Optional.empty()).buildFlowDel());
    } else {
        sw.transformAndSendMsg(FlowModBuilder.builder(flowRule, sw.factory(), Optional.empty()).buildFlowDel(), getTableType(flowRule.type()));
    }
}
#method_after
private void removeRule(FlowRule flowRule) {
    OpenFlowSwitch sw = controller.getSwitch(Dpid.dpid(flowRule.deviceId().uri()));
    if (flowRule.payLoad().payLoad().length > 0) {
        OFMessage msg = new ThirdPartyMessage(flowRule.payLoad().payLoad());
        sw.sendMsg(msg);
        return;
    }
    sw.sendMsg(FlowModBuilder.builder(flowRule, sw.factory(), Optional.empty()).buildFlowDel());
}
#end_block

#method_before
@Override
public void executeBatch(FlowRuleBatchOperation batch) {
    pendingBatches.put(batch.id(), new InternalCacheEntry(batch));
    OpenFlowSwitch sw = controller.getSwitch(Dpid.dpid(batch.deviceId().uri()));
    OFFlowMod mod;
    for (FlowRuleBatchEntry fbe : batch.getOperations()) {
        // flow is the third party privacy flow
        if (fbe.target().payLoad().payLoad().length > 0) {
            OFMessage msg = new ThirdPartyMessage(fbe.target().payLoad().payLoad());
            sw.sendMsg(msg);
            continue;
        }
        FlowModBuilder builder = FlowModBuilder.builder(fbe.target(), sw.factory(), Optional.of(batch.id()));
        switch(fbe.operator()) {
            case ADD:
                mod = builder.buildFlowAdd();
                break;
            case REMOVE:
                mod = builder.buildFlowDel();
                break;
            case MODIFY:
                mod = builder.buildFlowMod();
                break;
            default:
                log.error("Unsupported batch operation {}; skipping flowmod {}", fbe.operator(), fbe);
                continue;
        }
        if (fbe.target().type() == FlowRule.Type.DEFAULT) {
            sw.sendMsg(mod);
        } else {
            sw.transformAndSendMsg(mod, getTableType(fbe.target().type()));
        }
    }
    OFBarrierRequest.Builder builder = sw.factory().buildBarrierRequest().setXid(batch.id());
    sw.sendMsg(builder.build());
}
#method_after
@Override
public void executeBatch(FlowRuleBatchOperation batch) {
    pendingBatches.put(batch.id(), new InternalCacheEntry(batch));
    OpenFlowSwitch sw = controller.getSwitch(Dpid.dpid(batch.deviceId().uri()));
    OFFlowMod mod;
    for (FlowRuleBatchEntry fbe : batch.getOperations()) {
        // flow is the third party privacy flow
        if (fbe.target().payLoad().payLoad().length > 0) {
            OFMessage msg = new ThirdPartyMessage(fbe.target().payLoad().payLoad());
            sw.sendMsg(msg);
            continue;
        }
        FlowModBuilder builder = FlowModBuilder.builder(fbe.target(), sw.factory(), Optional.of(batch.id()));
        switch(fbe.operator()) {
            case ADD:
                mod = builder.buildFlowAdd();
                break;
            case REMOVE:
                mod = builder.buildFlowDel();
                break;
            case MODIFY:
                mod = builder.buildFlowMod();
                break;
            default:
                log.error("Unsupported batch operation {}; skipping flowmod {}", fbe.operator(), fbe);
                continue;
        }
        sw.sendMsg(mod);
    }
    OFBarrierRequest.Builder builder = sw.factory().buildBarrierRequest().setXid(batch.id());
    sw.sendMsg(builder.build());
}
#end_block

#method_before
@Override
public void handleMessage(Dpid dpid, OFMessage msg) {
    OpenFlowSwitch sw = controller.getSwitch(dpid);
    switch(msg.getType()) {
        case FLOW_REMOVED:
            OFFlowRemoved removed = (OFFlowRemoved) msg;
            FlowEntry fr = new FlowEntryBuilder(dpid, removed, getType(sw.getTableType(removed.getTableId()))).build();
            providerService.flowRemoved(fr);
            break;
        case STATS_REPLY:
            if (((OFStatsReply) msg).getStatsType() == OFStatsType.FLOW) {
                pushFlowMetrics(dpid, (OFFlowStatsReply) msg);
            }
            break;
        case BARRIER_REPLY:
            try {
                InternalCacheEntry entry = pendingBatches.getIfPresent(msg.getXid());
                if (entry != null) {
                    providerService.batchOperationCompleted(msg.getXid(), entry.completed());
                } else {
                    log.warn("Received unknown Barrier Reply: {}", msg.getXid());
                }
            } finally {
                pendingBatches.invalidate(msg.getXid());
            }
            break;
        case ERROR:
            log.warn("received Error message {} from {}", msg, dpid);
            OFErrorMsg error = (OFErrorMsg) msg;
            if (error.getErrType() == OFErrorType.FLOW_MOD_FAILED) {
                OFFlowModFailedErrorMsg fmFailed = (OFFlowModFailedErrorMsg) error;
                if (fmFailed.getData().getParsedMessage().isPresent()) {
                    OFMessage m = fmFailed.getData().getParsedMessage().get();
                    OFFlowMod fm = (OFFlowMod) m;
                    InternalCacheEntry entry = pendingBatches.getIfPresent(msg.getXid());
                    if (entry != null) {
                        entry.appendFailure(new FlowEntryBuilder(dpid, fm, getType(sw.getTableType(fm.getTableId()))).build());
                    } else {
                        log.error("No matching batch for this error: {}", error);
                    }
                } else {
                    // FIXME: Potentially add flowtracking to avoid this
                    // message.
                    log.error("Flow installation failed but switch didn't" + " tell us which one.");
                }
            } else {
                log.warn("Received error {}", error);
            }
        default:
            log.debug("Unhandled message type: {}", msg.getType());
    }
}
#method_after
@Override
public void handleMessage(Dpid dpid, OFMessage msg) {
    OpenFlowSwitch sw = controller.getSwitch(dpid);
    switch(msg.getType()) {
        case FLOW_REMOVED:
            OFFlowRemoved removed = (OFFlowRemoved) msg;
            FlowEntry fr = new FlowEntryBuilder(dpid, removed).build();
            providerService.flowRemoved(fr);
            break;
        case STATS_REPLY:
            if (((OFStatsReply) msg).getStatsType() == OFStatsType.FLOW) {
                pushFlowMetrics(dpid, (OFFlowStatsReply) msg);
            }
            break;
        case BARRIER_REPLY:
            try {
                InternalCacheEntry entry = pendingBatches.getIfPresent(msg.getXid());
                if (entry != null) {
                    providerService.batchOperationCompleted(msg.getXid(), entry.completed());
                } else {
                    log.warn("Received unknown Barrier Reply: {}", msg.getXid());
                }
            } finally {
                pendingBatches.invalidate(msg.getXid());
            }
            break;
        case ERROR:
            log.warn("received Error message {} from {}", msg, dpid);
            OFErrorMsg error = (OFErrorMsg) msg;
            if (error.getErrType() == OFErrorType.FLOW_MOD_FAILED) {
                OFFlowModFailedErrorMsg fmFailed = (OFFlowModFailedErrorMsg) error;
                if (fmFailed.getData().getParsedMessage().isPresent()) {
                    OFMessage m = fmFailed.getData().getParsedMessage().get();
                    OFFlowMod fm = (OFFlowMod) m;
                    InternalCacheEntry entry = pendingBatches.getIfPresent(msg.getXid());
                    if (entry != null) {
                        entry.appendFailure(new FlowEntryBuilder(dpid, fm).build());
                    } else {
                        log.error("No matching batch for this error: {}", error);
                    }
                } else {
                    // FIXME: Potentially add flowtracking to avoid this
                    // message.
                    log.error("Flow installation failed but switch didn't" + " tell us which one.");
                }
            } else {
                log.warn("Received error {}", error);
            }
        default:
            log.debug("Unhandled message type: {}", msg.getType());
    }
}
#end_block

#method_before
private void pushFlowMetrics(Dpid dpid, OFFlowStatsReply replies) {
    DeviceId did = DeviceId.deviceId(Dpid.uri(dpid));
    OpenFlowSwitch sw = controller.getSwitch(dpid);
    List<FlowEntry> flowEntries = replies.getEntries().stream().map(entry -> new FlowEntryBuilder(dpid, entry, getType(sw.getTableType(entry.getTableId()))).build()).collect(Collectors.toList());
    providerService.pushFlowMetrics(did, flowEntries);
}
#method_after
private void pushFlowMetrics(Dpid dpid, OFFlowStatsReply replies) {
    DeviceId did = DeviceId.deviceId(Dpid.uri(dpid));
    OpenFlowSwitch sw = controller.getSwitch(dpid);
    List<FlowEntry> flowEntries = replies.getEntries().stream().map(entry -> new FlowEntryBuilder(dpid, entry).build()).collect(Collectors.toList());
    providerService.pushFlowMetrics(did, flowEntries);
}
#end_block

#method_before
@Override
public boolean equals(Object obj) {
    if (this == obj) {
        return true;
    }
    if (obj instanceof FlowRuleExtPayLoad) {
        FlowRuleExtPayLoad that = (FlowRuleExtPayLoad) obj;
        return Objects.equals(payLoad, that.payLoad);
    }
    return false;
}
#method_after
@Override
public boolean equals(Object obj) {
    if (this == obj) {
        return true;
    }
    if (obj instanceof FlowRuleExtPayLoad) {
        FlowRuleExtPayLoad that = (FlowRuleExtPayLoad) obj;
        return Arrays.equals(payLoad, that.payLoad);
    }
    return false;
}
#end_block

#method_before
@Override
public /*
     * The priority and statistics can change on a given treatment and selector
     *
     * (non-Javadoc)
     *
     * @see java.lang.Object#equals(java.lang.Object)
     */
int hashCode() {
    return Objects.hash(deviceId, selector, priority, type, payLoad);
}
#method_after
@Override
public /*
     * The priority and statistics can change on a given treatment and selector
     *
     * (non-Javadoc)
     *
     * @see java.lang.Object#equals(java.lang.Object)
     */
int hashCode() {
    return Objects.hash(deviceId, selector, priority, tableId, payLoad);
}
#end_block

#method_before
public int hash() {
    return Objects.hash(deviceId, selector, treatment, type, payLoad);
}
#method_after
public int hash() {
    return Objects.hash(deviceId, selector, treatment, tableId, payLoad);
}
#end_block

#method_before
@Override
public /*
     * The priority and statistics can change on a given treatment and selector
     *
     * (non-Javadoc)
     *
     * @see java.lang.Object#equals(java.lang.Object)
     */
boolean equals(Object obj) {
    if (this == obj) {
        return true;
    }
    if (obj instanceof DefaultFlowRule) {
        DefaultFlowRule that = (DefaultFlowRule) obj;
        return Objects.equals(deviceId, that.deviceId) && Objects.equals(priority, that.priority) && Objects.equals(selector, that.selector) && Objects.equals(type, that.type) && Objects.equals(payLoad, that.payLoad);
    }
    return false;
}
#method_after
@Override
public /*
     * The priority and statistics can change on a given treatment and selector
     *
     * (non-Javadoc)
     *
     * @see java.lang.Object#equals(java.lang.Object)
     */
boolean equals(Object obj) {
    if (this == obj) {
        return true;
    }
    if (obj instanceof DefaultFlowRule) {
        DefaultFlowRule that = (DefaultFlowRule) obj;
        return Objects.equals(deviceId, that.deviceId) && Objects.equals(priority, that.priority) && Objects.equals(selector, that.selector) && Objects.equals(tableId, that.tableId) && Objects.equals(payLoad, that.payLoad);
    }
    return false;
}
#end_block

#method_before
@Override
public String toString() {
    return toStringHelper(this).add("id", Long.toHexString(id.value())).add("deviceId", deviceId).add("priority", priority).add("selector", selector.criteria()).add("treatment", treatment == null ? "N/A" : treatment.allInstructions()).add("table type", type).add("created", created).add("payLoad", payLoad).toString();
}
#method_after
@Override
public String toString() {
    return toStringHelper(this).add("id", Long.toHexString(id.value())).add("deviceId", deviceId).add("priority", priority).add("selector", selector.criteria()).add("treatment", treatment == null ? "N/A" : treatment.allInstructions()).add("tableId", tableId).add("created", created).add("payLoad", payLoad).toString().toString();
}
#end_block

#method_before
@Override
public FlowId id() {
    return FlowId.valueOf(1);
}
#method_after
@Override
public FlowId id() {
    return FlowId.valueOf(id);
}
#end_block

#method_before
@Override
public boolean equals(Object obj) {
    if (this == obj) {
        return true;
    }
    if (obj == null || getClass() != obj.getClass()) {
        return false;
    }
    final MockFlowRule other = (MockFlowRule) obj;
    return Objects.equals(this.priority, other.priority);
}
#method_after
@Override
public boolean equals(Object obj) {
    if (this == obj) {
        return true;
    }
    if (obj == null || getClass() != obj.getClass()) {
        return false;
    }
    final MockFlowRule other = (MockFlowRule) obj;
    return Objects.equals(this.timestamp, other.timestamp) && this.id == other.id;
}
#end_block

#method_before
@Activate
protected void activate() {
    log.info("Election-test app started");
    appId = coreService.registerApplication(ELECTION_APP);
    localControllerNode = clusterService.getLocalNode();
    leadershipService.addListener(leadershipEventListener);
// leadershipService.runForLeadership(appId.name());
}
#method_after
@Activate
protected void activate() {
    log.info("Election-test app started");
    appId = coreService.registerApplication(ELECTION_APP);
    localControllerNode = clusterService.getLocalNode();
    leadershipService.addListener(leadershipEventListener);
}
#end_block

#method_before
@Override
public Iterable<Tunnel> getTunnels(Type type) {
    // TODO Auto-generated method stub
    return null;
}
#method_after
@Override
public Collection<Tunnel> getTunnels(Type type) {
    // TODO Auto-generated method stub
    return null;
}
#end_block

#method_before
@Override
public void removeTunnels(DeviceId deviceId) {
// TODO Auto-generated method stub
}
#method_after
@Override
public void removeTunnels(ConnectPoint src, ConnectPoint dst) {
// TODO Auto-generated method stub
}
#end_block

#method_before
@Override
public void updateTunnel(Label src, Label dst, long bw) {
// TODO Auto-generated method stub
}
#method_after
@Override
public void updateTunnel(Tunnel tunnel, Path path) {
// TODO Auto-generated method stub
}
#end_block

#method_before
@Override
public Set<Tunnel> getTunnels(ConnectPoint connectPoint, Type type) {
    // TODO Auto-generated method stub
    return null;
}
#method_after
@Override
public Collection<Tunnel> getTunnels(ConnectPoint src, ConnectPoint dst, Type type) {
    // TODO Auto-generated method stub
    return null;
}
#end_block

#method_before
@Override
public void withdraw(String path) {
    activeTopics.remove(path);
    try {
        Versioned<NodeId> leader = leaderMap.get(path);
        if (leader != null && Objects.equals(leader.value(), localNodeId)) {
            if (leaderMap.remove(path, leader.version())) {
                log.info("Gave up leadership for {}", path);
                notifyRemovedLeader(path, localNodeId, leader.version(), leader.creationTime());
            }
        }
        // else we are not the current leader, can still be a candidate.
        Versioned<List<NodeId>> candidates = candidateMap.get(path);
        List<NodeId> candidateList = candidates != null ? Lists.newArrayList(candidates.value()) : Lists.newArrayList();
        if (!candidateList.remove(localNodeId)) {
            return;
        }
        boolean success = false;
        if (candidateList.isEmpty()) {
            if (candidateMap.remove(path, candidates.version())) {
                success = true;
            }
        } else {
            if (candidateMap.replace(path, candidates.version(), candidateList)) {
                success = true;
            }
        }
        if (success) {
            Versioned<List<NodeId>> newCandidates = candidateMap.get(path);
            notifyCandidateRemoved(path, candidates.version(), newCandidates);
        } else {
            log.warn("Failed to withdraw from candidates list. Will retry");
            retryWithdraw(path);
        }
    } catch (Exception e) {
        log.debug("Failed to verify (and clear) any lock this node might be holding for {}", path, e);
        retryWithdraw(path);
    }
}
#method_after
@Override
public void withdraw(String path) {
    activeTopics.remove(path);
    try {
        Versioned<NodeId> leader = leaderMap.get(path);
        if (leader != null && Objects.equals(leader.value(), localNodeId)) {
            if (leaderMap.remove(path, leader.version())) {
                log.info("Gave up leadership for {}", path);
                notifyRemovedLeader(path, localNodeId, leader.version(), leader.creationTime());
            }
        }
        // else we are not the current leader, can still be a candidate.
        Versioned<List<NodeId>> candidates = candidateMap.get(path);
        List<NodeId> candidateList = candidates != null ? Lists.newArrayList(candidates.value()) : Lists.newArrayList();
        if (!candidateList.remove(localNodeId)) {
            return;
        }
        boolean success = false;
        if (candidateList.isEmpty()) {
            if (candidateMap.remove(path, candidates.version())) {
                success = true;
            }
        } else {
            if (candidateMap.replace(path, candidates.version(), candidateList)) {
                success = true;
            }
        }
        if (success) {
            Versioned<List<NodeId>> newCandidates = candidateMap.get(path);
            notifyCandidateRemoved(path, candidates.version(), candidates.creationTime(), newCandidates);
        } else {
            log.warn("Failed to withdraw from candidates list. Will retry");
            retryWithdraw(path);
        }
    } catch (Exception e) {
        log.debug("Failed to verify (and clear) any lock this node might be holding for {}", path, e);
        retryWithdraw(path);
    }
}
#end_block

#method_before
private void notifyCandidateRemoved(String path, long oldEpoch, Versioned<List<NodeId>> candidates) {
    Leadership newInfo = new Leadership(path, candidates.value(), candidates.version(), candidates.creationTime());
    final MutableBoolean updated = new MutableBoolean(false);
    candidateBoard.compute(path, (k, current) -> {
        if (current != null && current.epoch() == oldEpoch) {
            log.info("updating candidateboard with removal: {}", newInfo);
            updated.setTrue();
            if (candidates.value().isEmpty()) {
                return null;
            } else {
                return newInfo;
            }
        }
        return current;
    });
    // maybe rethink types of candidates events
    if (updated.booleanValue()) {
        LeadershipEvent event = new LeadershipEvent(LeadershipEvent.Type.CANDIDATES_CHANGED, newInfo);
        notifyPeers(event);
    }
}
#method_after
private void notifyCandidateRemoved(String path, long oldEpoch, long oldTime, Versioned<List<NodeId>> candidates) {
    Leadership newInfo = (candidates == null) ? new Leadership(path, ImmutableList.of(), oldEpoch, oldTime) : new Leadership(path, candidates.value(), candidates.version(), candidates.creationTime());
    final MutableBoolean updated = new MutableBoolean(false);
    candidateBoard.compute(path, (k, current) -> {
        if (candidates != null) {
            if (current != null && current.epoch() < newInfo.epoch()) {
                updated.setTrue();
                if (candidates.value().isEmpty()) {
                    return null;
                } else {
                    return newInfo;
                }
            }
        } else {
            if (current != null && current.epoch() == oldEpoch) {
                updated.setTrue();
                return null;
            }
        }
        return current;
    });
    // maybe rethink types of candidates events
    if (updated.booleanValue()) {
        log.debug("updated candidateboard with removal: {}", newInfo);
        LeadershipEvent event = new LeadershipEvent(LeadershipEvent.Type.CANDIDATES_CHANGED, newInfo);
        notifyPeers(event);
    }
}
#end_block

#method_before
@Override
public Annotations annotations() {
    // TODO Auto-generated method stub
    return null;
}
#method_after
@Override
public Annotations annotations() {
    return null;
}
#end_block

#method_before
@Override
public ProviderId providerId() {
    // TODO Auto-generated method stub
    return null;
}
#method_after
@Override
public ProviderId providerId() {
    return null;
}
#end_block

#method_before
@Override
public int hashCode() {
    // TODO Auto-generated method stub
    return Objects.hashCode(deviceId.toString() + labelResourceId.toString());
}
#method_after
@Override
public int hashCode() {
    return Objects.hash(deviceId, labelResourceId);
}
#end_block

#method_before
@Override
public boolean equals(Object obj) {
    if (obj instanceof DefaultLabelResource) {
        DefaultLabelResource that = (DefaultLabelResource) obj;
        return Objects.equals(this.deviceId.toString() + this.labelResourceId.toString(), that.deviceId.toString() + that.labelResourceId.toString());
    }
    return false;
}
#method_after
@Override
public boolean equals(Object obj) {
    if (obj instanceof DefaultLabelResource) {
        DefaultLabelResource that = (DefaultLabelResource) obj;
        return Objects.equals(this.deviceId, that.deviceId) && Objects.equals(this.labelResourceId, that.labelResourceId);
    }
    return false;
}
#end_block

#method_before
@Override
public String toString() {
    // TODO Auto-generated method stub
    return String.valueOf(deviceId.toString() + labelResourceId.toString());
}
#method_after
@Override
public String toString() {
    return toStringHelper(this).add("deviceId", deviceId).add("labelResourceId", labelResourceId).toString();
}
#end_block

#method_before
@Override
public int hashCode() {
    // TODO Auto-generated method stub
    return Objects.hashCode(this.deviceId.toString() + this.applyNum + this.type + this.releaseCollection.size() + this.releaseCollection.toString());
}
#method_after
@Override
public int hashCode() {
    return Objects.hash(this.deviceId, this.applyNum, this.type, this.releaseCollection);
}
#end_block

#method_before
@Override
public boolean equals(Object obj) {
    if (obj instanceof LabelResourceRequest) {
        LabelResourceRequest that = (LabelResourceRequest) obj;
        return Objects.equals(this.deviceId.toString() + this.applyNum + this.type + this.releaseCollection.size() + this.releaseCollection.toString(), that.deviceId.toString() + that.applyNum + that.type + that.releaseCollection.size() + that.releaseCollection.toString());
    }
    return false;
}
#method_after
@Override
public boolean equals(Object obj) {
    if (obj instanceof LabelResourceRequest) {
        LabelResourceRequest that = (LabelResourceRequest) obj;
        return Objects.equals(this.deviceId, that.deviceId) && Objects.equals(this.applyNum, that.applyNum) && Objects.equals(this.type, that.type) && Objects.equals(this.releaseCollection, that.releaseCollection);
    }
    return false;
}
#end_block

#method_before
@Override
public String toString() {
    // TODO Auto-generated method stub
    return MoreObjects.toStringHelper(this).add("deviceId", this.deviceId.toString()).add("applyNum", this.applyNum).add("type", this.type).add("releaseCollectionSize", this.releaseCollection.size()).add("releaseCollection", this.releaseCollection.toString()).toString();
}
#method_after
@Override
public String toString() {
    return MoreObjects.toStringHelper(this).add("deviceId", this.deviceId).add("applyNum", this.applyNum).add("type", this.type).add("releaseCollection", this.releaseCollection).toString();
}
#end_block

#method_before
@Override
public int hashCode() {
    // TODO Auto-generated method stub
    return Objects.hashCode(labelId);
}
#method_after
@Override
public int hashCode() {
    return Objects.hashCode(labelId);
}
#end_block

#method_before
@Override
public String toString() {
    // TODO Auto-generated method stub
    return String.valueOf(this.labelId);
}
#method_after
@Override
public String toString() {
    return String.valueOf(this.labelId);
}
#end_block

#method_before
@Override
public int hashCode() {
    // TODO Auto-generated method stub
    return Objects.hashCode(this.deviceId.toString() + this.beginLabel.toString() + this.endLabel.toString() + this.totalNum + this.usedNum + this.currentUsedMaxLabelId.toString() + this.releaseLabelId.toString());
}
#method_after
@Override
public int hashCode() {
    return Objects.hash(this.deviceId, this.beginLabel, this.endLabel, this.totalNum, this.usedNum, this.currentUsedMaxLabelId, this.releaseLabelId);
}
#end_block

#method_before
@Override
public boolean equals(Object obj) {
    if (obj instanceof LabelResourcePool) {
        LabelResourcePool that = (LabelResourcePool) obj;
        return Objects.equals(this.deviceId.toString() + this.beginLabel.toString() + this.endLabel.toString() + this.totalNum + this.usedNum + this.currentUsedMaxLabelId.toString() + this.releaseLabelId.toString(), that.deviceId.toString() + that.beginLabel + that.endLabel + that.totalNum + that.usedNum + that.currentUsedMaxLabelId + that.releaseLabelId.toString());
    }
    return false;
}
#method_after
@Override
public boolean equals(Object obj) {
    if (obj instanceof LabelResourcePool) {
        LabelResourcePool that = (LabelResourcePool) obj;
        return Objects.equals(this.deviceId, that.deviceId) && Objects.equals(this.beginLabel, that.beginLabel) && Objects.equals(this.endLabel, that.endLabel) && Objects.equals(this.totalNum, that.totalNum) && Objects.equals(this.usedNum, that.usedNum) && Objects.equals(this.currentUsedMaxLabelId, that.currentUsedMaxLabelId) && Objects.equals(this.releaseLabelId, that.releaseLabelId);
    }
    return false;
}
#end_block

#method_before
@Override
public String toString() {
    // TODO Auto-generated method stub
    return MoreObjects.toStringHelper(this).add("deviceId", this.deviceId.toString()).add("beginLabel", this.beginLabel.toString()).add("endLabel", this.endLabel.toString()).add("totalNum", this.totalNum).add("usedNum", this.usedNum).add("currentUsedMaxLabelId", this.currentUsedMaxLabelId.toString()).add("releaseLabelId", this.releaseLabelId.toString()).toString();
}
#method_after
@Override
public String toString() {
    // TODO Auto-generated method stub
    return MoreObjects.toStringHelper(this).add("deviceId", this.deviceId).add("beginLabel", this.beginLabel).add("endLabel", this.endLabel).add("totalNum", this.totalNum).add("usedNum", this.usedNum).add("currentUsedMaxLabelId", this.currentUsedMaxLabelId).add("releaseLabelId", this.releaseLabelId).toString();
}
#end_block

#method_before
@Override
public MastershipRole getRole(NodeId nodeId, DeviceId deviceId) {
    checkArgument(nodeId != null, NODE_ID_NULL);
    checkArgument(deviceId != null, DEVICE_ID_NULL);
    String leadershipTopic = createDeviceMastershipTopic(deviceId);
    Leadership leadership = leadershipService.getLeadership(leadershipTopic);
    if (leadership != null && nodeId.equals(leadership.leader())) {
        return MastershipRole.MASTER;
    }
    if (localNodeId.equals(nodeId)) {
        if (connectedDevices.contains(deviceId)) {
            return MastershipRole.STANDBY;
        } else {
            return MastershipRole.NONE;
        }
    }
    MastershipRole role = complete(clusterCommunicator.sendAndReceive(deviceId, ROLE_QUERY_SUBJECT, SERIALIZER::encode, SERIALIZER::decode, nodeId));
    return role == null ? MastershipRole.NONE : role;
}
#method_after
@Override
public MastershipRole getRole(NodeId nodeId, DeviceId deviceId) {
    checkArgument(nodeId != null, NODE_ID_NULL);
    checkArgument(deviceId != null, DEVICE_ID_NULL);
    String leadershipTopic = createDeviceMastershipTopic(deviceId);
    Leadership leadership = leadershipService.getLeadership(leadershipTopic);
    if (leadership != null && nodeId.equals(leadership.leader())) {
        return MastershipRole.MASTER;
    }
    if (localNodeId.equals(nodeId)) {
        if (connectedDevices.contains(deviceId)) {
            return MastershipRole.STANDBY;
        } else {
            return MastershipRole.NONE;
        }
    }
    MastershipRole role = futureGetOrElse(clusterCommunicator.sendAndReceive(deviceId, ROLE_QUERY_SUBJECT, SERIALIZER::encode, SERIALIZER::decode, nodeId), null);
    return role == null ? MastershipRole.NONE : role;
}
#end_block

#method_before
@Override
public MastershipEvent relinquishRole(NodeId nodeId, DeviceId deviceId) {
    checkArgument(nodeId != null, NODE_ID_NULL);
    checkArgument(deviceId != null, DEVICE_ID_NULL);
    if (!nodeId.equals(localNodeId)) {
        log.debug("Forwarding request to relinquish " + "role for device {} to {}", deviceId, nodeId);
        return complete(clusterCommunicator.sendAndReceive(deviceId, ROLE_RELINQUISH_SUBJECT, SERIALIZER::encode, SERIALIZER::decode, nodeId));
    }
    // Check if this node is can be managed by this node.
    if (!connectedDevices.contains(deviceId)) {
        return null;
    }
    String leadershipTopic = createDeviceMastershipTopic(deviceId);
    Leadership currentLeadership = leadershipService.getLeadership(leadershipTopic);
    MastershipEvent.Type eventType = null;
    if (currentLeadership != null && currentLeadership.leader().equals(localNodeId)) {
        eventType = MastershipEvent.Type.MASTER_CHANGED;
    } else {
        eventType = MastershipEvent.Type.BACKUPS_CHANGED;
    }
    connectedDevices.remove(deviceId);
    leadershipService.withdraw(leadershipTopic);
    return new MastershipEvent(eventType, deviceId, getNodes(deviceId));
}
#method_after
@Override
public MastershipEvent relinquishRole(NodeId nodeId, DeviceId deviceId) {
    checkArgument(nodeId != null, NODE_ID_NULL);
    checkArgument(deviceId != null, DEVICE_ID_NULL);
    if (!nodeId.equals(localNodeId)) {
        log.debug("Forwarding request to relinquish " + "role for device {} to {}", deviceId, nodeId);
        return futureGetOrElse(clusterCommunicator.sendAndReceive(deviceId, ROLE_RELINQUISH_SUBJECT, SERIALIZER::encode, SERIALIZER::decode, nodeId), null);
    }
    // Check if this node is can be managed by this node.
    if (!connectedDevices.contains(deviceId)) {
        return null;
    }
    String leadershipTopic = createDeviceMastershipTopic(deviceId);
    Leadership currentLeadership = leadershipService.getLeadership(leadershipTopic);
    MastershipEvent.Type eventType = null;
    if (currentLeadership != null && currentLeadership.leader().equals(localNodeId)) {
        eventType = MastershipEvent.Type.MASTER_CHANGED;
    } else {
        eventType = MastershipEvent.Type.BACKUPS_CHANGED;
    }
    connectedDevices.remove(deviceId);
    leadershipService.withdraw(leadershipTopic);
    return new MastershipEvent(eventType, deviceId, getNodes(deviceId));
}
#end_block

#method_before
@Override
public void process(PacketContext context) {
    InboundPacket pkt = context.inPacket();
    Ethernet ethPkt = pkt.parsed();
    if (ethPkt == null) {
        return;
    }
    ConnectPoint srcConnectPoint = pkt.receivedFrom();
    switch(ethPkt.getEtherType()) {
        case Ethernet.TYPE_ARP:
            ARP arpPacket = (ARP) ethPkt.getPayload();
            Ip4Address targetIpAddress = Ip4Address.valueOf(arpPacket.getTargetProtocolAddress());
            // processed.
            if (arpPacket.getOpCode() == ARP.OP_REQUEST && config.isVirtualGatewayIpAddress(targetIpAddress)) {
                MacAddress gatewayMacAddress = config.getVirtualGatewayMacAddress();
                if (gatewayMacAddress == null) {
                    break;
                }
                Ethernet eth = proxyArpService.buildArpReply(targetIpAddress, gatewayMacAddress, ethPkt);
                proxyArpService.sendTo(eth, srcConnectPoint);
            }
            break;
        case Ethernet.TYPE_IPV4:
            // Parse packet
            IPv4 ipv4Packet = (IPv4) ethPkt.getPayload();
            IpAddress dstIp = IpAddress.valueOf(ipv4Packet.getDestinationAddress());
            IpAddress srcIp = IpAddress.valueOf(ipv4Packet.getSourceAddress());
            MacAddress srcMac = ethPkt.getSourceMAC();
            routingService.packetReactiveProcessor(dstIp, srcIp, srcConnectPoint, srcMac);
            // TODO emit packet first or packetReactiveProcessor first
            ConnectPoint egressConnectPoint = null;
            egressConnectPoint = routingService.getEgressConnectPoint(dstIp);
            if (egressConnectPoint != null) {
                forwardPacketToDst(context, egressConnectPoint);
            }
            break;
        default:
            break;
    }
}
#method_after
@Override
public void process(PacketContext context) {
    InboundPacket pkt = context.inPacket();
    Ethernet ethPkt = pkt.parsed();
    if (ethPkt == null) {
        return;
    }
    ConnectPoint srcConnectPoint = pkt.receivedFrom();
    switch(ethPkt.getEtherType()) {
        case Ethernet.TYPE_ARP:
            ARP arpPacket = (ARP) ethPkt.getPayload();
            Ip4Address targetIpAddress = Ip4Address.valueOf(arpPacket.getTargetProtocolAddress());
            // processed.
            if (arpPacket.getOpCode() == ARP.OP_REQUEST && config.isVirtualGatewayIpAddress(targetIpAddress)) {
                MacAddress gatewayMacAddress = config.getVirtualGatewayMacAddress();
                if (gatewayMacAddress == null) {
                    break;
                }
                Ethernet eth = ARP.buildArpReply(targetIpAddress, gatewayMacAddress, ethPkt);
                TrafficTreatment.Builder builder = DefaultTrafficTreatment.builder();
                builder.setOutput(srcConnectPoint.port());
                packetService.emit(new DefaultOutboundPacket(srcConnectPoint.deviceId(), builder.build(), ByteBuffer.wrap(eth.serialize())));
            }
            break;
        case Ethernet.TYPE_IPV4:
            // Parse packet
            IPv4 ipv4Packet = (IPv4) ethPkt.getPayload();
            IpAddress dstIp = IpAddress.valueOf(ipv4Packet.getDestinationAddress());
            IpAddress srcIp = IpAddress.valueOf(ipv4Packet.getSourceAddress());
            MacAddress srcMac = ethPkt.getSourceMAC();
            routingService.packetReactiveProcessor(dstIp, srcIp, srcConnectPoint, srcMac);
            // TODO emit packet first or packetReactiveProcessor first
            ConnectPoint egressConnectPoint = null;
            egressConnectPoint = routingService.getEgressConnectPoint(dstIp);
            if (egressConnectPoint != null) {
                forwardPacketToDst(context, egressConnectPoint);
            }
            break;
        default:
            break;
    }
}
#end_block

#method_before
private void readConfiguration(String configFilename) {
    File configFile = new File(CONFIG_DIR, configFilename);
    ObjectMapper mapper = new ObjectMapper();
    try {
        log.info("Loading config: {}", configFile.getAbsolutePath());
        Configuration config = mapper.readValue(configFile, Configuration.class);
        for (BgpSpeaker speaker : config.getBgpSpeakers()) {
            bgpSpeakers.put(speaker.name(), speaker);
        }
        for (BgpPeer peer : config.getPeers()) {
            bgpPeers.put(peer.ipAddress(), peer);
        }
        for (LocalIpPrefixEntry entry : config.getLocalIp4PrefixEntries()) {
            localPrefixTable4.put(createBinaryString(entry.ipPrefix()), entry);
        }
        for (LocalIpPrefixEntry entry : config.getLocalIp6PrefixEntries()) {
            localPrefixTable6.put(createBinaryString(entry.ipPrefix()), entry);
        }
        virtualGatewayMacAddress = config.getVirtualGatewayMacAddress();
    } catch (FileNotFoundException e) {
        log.warn("Configuration file not found: {}", configFileName);
    } catch (IOException e) {
        log.error("Error loading configuration", e);
    }
}
#method_after
private void readConfiguration(String configFilename) {
    File configFile = new File(CONFIG_DIR, configFilename);
    ObjectMapper mapper = new ObjectMapper();
    try {
        log.info("Loading config: {}", configFile.getAbsolutePath());
        Configuration config = mapper.readValue(configFile, Configuration.class);
        for (BgpSpeaker speaker : config.getBgpSpeakers()) {
            bgpSpeakers.put(speaker.name(), speaker);
        }
        for (BgpPeer peer : config.getPeers()) {
            bgpPeers.put(peer.ipAddress(), peer);
        }
        for (LocalIpPrefixEntry entry : config.getLocalIp4PrefixEntries()) {
            localPrefixTable4.put(createBinaryString(entry.ipPrefix()), entry);
            gatewayIpAddresses.add(entry.getGatewayIpAddress());
        }
        for (LocalIpPrefixEntry entry : config.getLocalIp6PrefixEntries()) {
            localPrefixTable6.put(createBinaryString(entry.ipPrefix()), entry);
            gatewayIpAddresses.add(entry.getGatewayIpAddress());
        }
        virtualGatewayMacAddress = config.getVirtualGatewayMacAddress();
    } catch (FileNotFoundException e) {
        log.warn("Configuration file not found: {}", configFileName);
    } catch (IOException e) {
        log.error("Error loading configuration", e);
    }
}
#end_block

#method_before
@Override
public boolean isVirtualGatewayIpAddress(IpAddress ipAddress) {
    String ipAddressBinaryString = RouteEntry.createBinaryString(ipAddress.toIpPrefix());
    // in the future we will support arbitrary IP address
    if (!ipAddressBinaryString.endsWith("1")) {
        return false;
    }
    // Check whether there is an IP prefix for this IP address
    if (ipAddress.isIp4() && localPrefixTable4.getKeysPrefixing(ipAddressBinaryString).iterator().hasNext()) {
        return true;
    } else if (localPrefixTable6.getKeysPrefixing(ipAddressBinaryString).iterator().hasNext()) {
        return true;
    }
    return false;
}
#method_after
@Override
public boolean isVirtualGatewayIpAddress(IpAddress ipAddress) {
    return gatewayIpAddresses.contains(ipAddress);
}
#end_block

#method_before
private void replyArp(Ethernet eth, ConnectPoint inPort) {
    ARP arp = (ARP) eth.getPayload();
    checkArgument(arp.getOpCode() == ARP.OP_REQUEST, NOT_ARP_REQUEST);
    checkNotNull(inPort);
    Ip4Address targetAddress = Ip4Address.valueOf(arp.getTargetProtocolAddress());
    VlanId vlan = VlanId.vlanId(eth.getVlanID());
    if (isOutsidePort(inPort)) {
        // If the request came from outside the network, only reply if it was
        // for one of our external addresses.
        Set<PortAddresses> addressSet = hostService.getAddressBindingsForPort(inPort);
        for (PortAddresses addresses : addressSet) {
            for (InterfaceIpAddress ia : addresses.ipAddresses()) {
                if (ia.ipAddress().equals(targetAddress)) {
                    Ethernet arpReply = buildArpReply(targetAddress, addresses.mac(), eth);
                    sendTo(arpReply, inPort);
                }
            }
        }
        return;
    }
    // See if we have the target host in the host store
    Set<Host> hosts = hostService.getHostsByIp(targetAddress);
    Host dst = null;
    Host src = hostService.getHost(HostId.hostId(eth.getSourceMAC(), VlanId.vlanId(eth.getVlanID())));
    for (Host host : hosts) {
        if (host.vlan().equals(vlan)) {
            dst = host;
            break;
        }
    }
    if (src != null && dst != null) {
        // We know the target host so we can respond
        Ethernet arpReply = buildArpReply(targetAddress, dst.mac(), eth);
        sendTo(arpReply, inPort);
        return;
    }
    // If the source address matches one of our external addresses
    // it could be a request from an internal host to an external
    // address. Forward it over to the correct port.
    Ip4Address source = Ip4Address.valueOf(arp.getSenderProtocolAddress());
    Set<PortAddresses> sourceAddresses = findPortsInSubnet(source);
    boolean matched = false;
    for (PortAddresses pa : sourceAddresses) {
        for (InterfaceIpAddress ia : pa.ipAddresses()) {
            if (ia.ipAddress().equals(source) && pa.vlan().equals(vlan)) {
                matched = true;
                sendTo(eth, pa.connectPoint());
                break;
            }
        }
    }
    if (matched) {
        return;
    }
    // 
    // The request couldn't be resolved.
    // Flood the request on all ports except the incoming port.
    // 
    flood(eth, inPort);
    return;
}
#method_after
private void replyArp(Ethernet eth, ConnectPoint inPort) {
    ARP arp = (ARP) eth.getPayload();
    checkArgument(arp.getOpCode() == ARP.OP_REQUEST, NOT_ARP_REQUEST);
    checkNotNull(inPort);
    Ip4Address targetAddress = Ip4Address.valueOf(arp.getTargetProtocolAddress());
    VlanId vlan = VlanId.vlanId(eth.getVlanID());
    if (isOutsidePort(inPort)) {
        // If the request came from outside the network, only reply if it was
        // for one of our external addresses.
        Set<PortAddresses> addressSet = hostService.getAddressBindingsForPort(inPort);
        for (PortAddresses addresses : addressSet) {
            for (InterfaceIpAddress ia : addresses.ipAddresses()) {
                if (ia.ipAddress().equals(targetAddress)) {
                    Ethernet arpReply = ARP.buildArpReply(targetAddress, addresses.mac(), eth);
                    sendTo(arpReply, inPort);
                }
            }
        }
        return;
    }
    // See if we have the target host in the host store
    Set<Host> hosts = hostService.getHostsByIp(targetAddress);
    Host dst = null;
    Host src = hostService.getHost(HostId.hostId(eth.getSourceMAC(), VlanId.vlanId(eth.getVlanID())));
    for (Host host : hosts) {
        if (host.vlan().equals(vlan)) {
            dst = host;
            break;
        }
    }
    if (src != null && dst != null) {
        // We know the target host so we can respond
        Ethernet arpReply = ARP.buildArpReply(targetAddress, dst.mac(), eth);
        sendTo(arpReply, inPort);
        return;
    }
    // If the source address matches one of our external addresses
    // it could be a request from an internal host to an external
    // address. Forward it over to the correct port.
    Ip4Address source = Ip4Address.valueOf(arp.getSenderProtocolAddress());
    Set<PortAddresses> sourceAddresses = findPortsInSubnet(source);
    boolean matched = false;
    for (PortAddresses pa : sourceAddresses) {
        for (InterfaceIpAddress ia : pa.ipAddresses()) {
            if (ia.ipAddress().equals(source) && pa.vlan().equals(vlan)) {
                matched = true;
                sendTo(eth, pa.connectPoint());
                break;
            }
        }
    }
    if (matched) {
        return;
    }
    // 
    // The request couldn't be resolved.
    // Flood the request on all ports except the incoming port.
    // 
    flood(eth, inPort);
    return;
}
#end_block

#method_before
@Override
public void sendTo(Ethernet packet, ConnectPoint outPort) {
    if (internalPorts.containsEntry(deviceService.getDevice(outPort.deviceId()), outPort.port())) {
        // misconfiguration).
        return;
    }
    TrafficTreatment.Builder builder = DefaultTrafficTreatment.builder();
    builder.setOutput(outPort.port());
    packetService.emit(new DefaultOutboundPacket(outPort.deviceId(), builder.build(), ByteBuffer.wrap(packet.serialize())));
}
#method_after
private void sendTo(Ethernet packet, ConnectPoint outPort) {
    if (internalPorts.containsEntry(deviceService.getDevice(outPort.deviceId()), outPort.port())) {
        // misconfiguration).
        return;
    }
    TrafficTreatment.Builder builder = DefaultTrafficTreatment.builder();
    builder.setOutput(outPort.port());
    packetService.emit(new DefaultOutboundPacket(outPort.deviceId(), builder.build(), ByteBuffer.wrap(packet.serialize())));
}
#end_block

#method_before
@Override
public void runForLeadership(String path) {
    log.debug("Running for leadership for topic: {}", path);
    try {
        Versioned<List<NodeId>> candidates = candidateMap.get(path);
        if (candidates != null) {
            List<NodeId> candidateList = Lists.newArrayList(candidates.value());
            if (!candidateList.contains(localNodeId)) {
                candidateList.add(localNodeId);
                if (candidateMap.replace(path, candidates.version(), candidateList)) {
                    notifyCandidateAdded(path, candidateList, candidates.version(), candidates.creationTime());
                } else {
                    rerunForLeadership(path);
                    return;
                }
            }
        } else {
            List<NodeId> candidateList = ImmutableList.of(localNodeId);
            if ((candidateMap.putIfAbsent(path, candidateList) == null)) {
                Versioned<List<NodeId>> newCandidates = candidateMap.get(path);
                notifyCandidateAdded(path, candidateList, newCandidates.version(), newCandidates.creationTime());
            } else {
                rerunForLeadership(path);
                return;
            }
        }
        log.debug("In the leadership race for topic {} with candidates {}", path, candidates);
        activeTopics.add(path);
        tryLeaderLock(path);
    } catch (ConsistentMapException e) {
        log.debug("Failed to enter topic leader race for {}. Retrying.", path, e);
        rerunForLeadership(path);
    }
}
#method_after
@Override
public void runForLeadership(String path) {
    log.debug("Running for leadership for topic: {}", path);
    try {
        Versioned<List<NodeId>> candidates = candidateMap.get(path);
        if (candidates != null) {
            List<NodeId> candidateList = Lists.newArrayList(candidates.value());
            if (!candidateList.contains(localNodeId)) {
                candidateList.add(localNodeId);
                if (candidateMap.replace(path, candidates.version(), candidateList)) {
                    Versioned<List<NodeId>> newCandidates = candidateMap.get(path);
                    notifyCandidateAdded(path, candidateList, newCandidates.version(), newCandidates.creationTime());
                } else {
                    rerunForLeadership(path);
                    return;
                }
            }
        } else {
            List<NodeId> candidateList = ImmutableList.of(localNodeId);
            if ((candidateMap.putIfAbsent(path, candidateList) == null)) {
                Versioned<List<NodeId>> newCandidates = candidateMap.get(path);
                notifyCandidateAdded(path, candidateList, newCandidates.version(), newCandidates.creationTime());
            } else {
                rerunForLeadership(path);
                return;
            }
        }
        log.debug("In the leadership race for topic {} with candidates {}", path, candidates);
        activeTopics.add(path);
        tryLeaderLock(path);
    } catch (ConsistentMapException e) {
        log.debug("Failed to enter topic leader race for {}. Retrying.", path, e);
        rerunForLeadership(path);
    }
}
#end_block

#method_before
@Override
public void withdraw(String path) {
    activeTopics.remove(path);
    try {
        Versioned<NodeId> leader = leaderMap.get(path);
        if (leader != null && Objects.equals(leader.value(), localNodeId)) {
            if (leaderMap.remove(path, leader.version())) {
                log.info("Gave up leadership for {}", path);
                notifyRemovedLeader(path, localNodeId, leader.version(), leader.creationTime());
            }
        }
        // else we are not the current leader, can still be a candidate.
        Versioned<List<NodeId>> candidates = candidateMap.get(path);
        List<NodeId> candidateList = candidates != null ? Lists.newArrayList(candidates.value()) : Lists.newArrayList();
        if (!candidateList.remove(localNodeId)) {
            return;
        }
        boolean success = candidateList.isEmpty() ? candidateMap.remove(path, candidates.version()) : candidateMap.replace(path, candidates.version(), candidateList);
        if (success) {
            notifyCandidateRemoved(path, candidateList, candidates.version(), candidates.creationTime());
        } else {
            log.warn("Failed to withdraw from candidates list. Will retry");
            retryWithdraw(path);
        }
    } catch (Exception e) {
        log.debug("Failed to verify (and clear) any lock this node might be holding for {}", path, e);
        retryWithdraw(path);
    }
}
#method_after
@Override
public void withdraw(String path) {
    activeTopics.remove(path);
    try {
        Versioned<NodeId> leader = leaderMap.get(path);
        if (leader != null && Objects.equals(leader.value(), localNodeId)) {
            if (leaderMap.remove(path, leader.version())) {
                log.info("Gave up leadership for {}", path);
                notifyRemovedLeader(path, localNodeId, leader.version(), leader.creationTime());
            }
        }
        // else we are not the current leader, can still be a candidate.
        Versioned<List<NodeId>> candidates = candidateMap.get(path);
        List<NodeId> candidateList = candidates != null ? Lists.newArrayList(candidates.value()) : Lists.newArrayList();
        if (!candidateList.remove(localNodeId)) {
            return;
        }
        boolean success = false;
        if (candidateList.isEmpty()) {
            if (candidateMap.remove(path, candidates.version())) {
                success = true;
            }
        } else {
            if (candidateMap.replace(path, candidates.version(), candidateList)) {
                success = true;
            }
        }
        if (success) {
            notifyCandidateRemoved(path, candidateList, candidates.version(), candidates.creationTime());
        } else {
            log.warn("Failed to withdraw from candidates list. Will retry");
            retryWithdraw(path);
        }
    } catch (Exception e) {
        log.debug("Failed to verify (and clear) any lock this node might be holding for {}", path, e);
        retryWithdraw(path);
    }
}
#end_block

#method_before
private void notifyCandidateAdded(String path, List<NodeId> candidates, long epoch, long electedTime) {
    Leadership newInfo = new Leadership(path, candidates, epoch, electedTime);
    boolean updated = false;
    synchronized (candidateBoard) {
        Leadership current = candidateBoard.get(path);
        if (current == null || current.epoch() < newInfo.epoch()) {
            log.info("updating candidateboard with {}", newInfo);
            candidateBoard.put(path, newInfo);
            updated = true;
        }
    }
    // maybe rethink types of candidates events
    if (updated) {
        LeadershipEvent event = new LeadershipEvent(LeadershipEvent.Type.CANDIDATES_CHANGED, newInfo);
        notifyPeers(event);
    }
}
#method_after
private void notifyCandidateAdded(String path, List<NodeId> candidates, long epoch, long electedTime) {
    Leadership newInfo = new Leadership(path, candidates, epoch, electedTime);
    final MutableBoolean updated = new MutableBoolean(false);
    candidateBoard.compute(path, (k, current) -> {
        if (current == null || current.epoch() < newInfo.epoch()) {
            log.info("updating candidateboard with {}", newInfo);
            updated.setTrue();
            return newInfo;
        }
        return current;
    });
    // maybe rethink types of candidates events
    if (updated.booleanValue()) {
        LeadershipEvent event = new LeadershipEvent(LeadershipEvent.Type.CANDIDATES_CHANGED, newInfo);
        notifyPeers(event);
    }
}
#end_block

#method_before
private void notifyCandidateRemoved(String path, List<NodeId> candidates, long epoch, long electedTime) {
    Leadership oldInfo = new Leadership(path, candidates, epoch, electedTime);
    boolean updated = false;
    synchronized (candidateBoard) {
        Leadership current = candidateBoard.get(path);
        if (current != null && current.epoch() == oldInfo.epoch()) {
            log.info("updating candidateboard with {}", oldInfo);
            candidateBoard.remove(path);
            updated = true;
        }
    }
    // maybe rethink types of candidates events
    if (updated) {
        LeadershipEvent event = new LeadershipEvent(LeadershipEvent.Type.CANDIDATES_CHANGED, oldInfo);
        notifyPeers(event);
    }
}
#method_after
private void notifyCandidateRemoved(String path, List<NodeId> candidates, long epoch, long electedTime) {
    Leadership newInfo = new Leadership(path, candidates, epoch, electedTime);
    final MutableBoolean updated = new MutableBoolean(false);
    candidateBoard.compute(path, (k, current) -> {
        if (current != null && current.epoch() == newInfo.epoch()) {
            log.info("updating candidateboard with {}", newInfo);
            updated.setTrue();
            if (candidates.isEmpty()) {
                return null;
            } else {
                return newInfo;
            }
        }
        return current;
    });
    // maybe rethink types of candidates events
    if (updated.booleanValue()) {
        LeadershipEvent event = new LeadershipEvent(LeadershipEvent.Type.CANDIDATES_CHANGED, newInfo);
        notifyPeers(event);
    }
}
#end_block

#method_before
private void notifyNewLeader(String path, NodeId leader, List<NodeId> candidates, long epoch, long electedTime) {
    Leadership newLeadership = new Leadership(path, leader, candidates, epoch, electedTime);
    boolean updatedLeader = false;
    log.debug("candidates for new Leadership {}", candidates);
    synchronized (leaderBoard) {
        Leadership currentLeader = leaderBoard.get(path);
        if (currentLeader == null || currentLeader.epoch() < epoch) {
            log.debug("updating leaderboard with new {}", newLeadership);
            leaderBoard.put(path, newLeadership);
            updatedLeader = true;
        }
    }
    if (updatedLeader) {
        LeadershipEvent event = new LeadershipEvent(LeadershipEvent.Type.LEADER_ELECTED, newLeadership);
        notifyPeers(event);
    }
}
#method_after
private void notifyNewLeader(String path, NodeId leader, List<NodeId> candidates, long epoch, long electedTime) {
    Leadership newLeadership = new Leadership(path, leader, candidates, epoch, electedTime);
    final MutableBoolean updatedLeader = new MutableBoolean(false);
    log.debug("candidates for new Leadership {}", candidates);
    leaderBoard.compute(path, (k, currentLeader) -> {
        if (currentLeader == null || currentLeader.epoch() < epoch) {
            log.debug("updating leaderboard with new {}", newLeadership);
            updatedLeader.setTrue();
            return newLeadership;
        }
        return currentLeader;
    });
    if (updatedLeader.booleanValue()) {
        LeadershipEvent event = new LeadershipEvent(LeadershipEvent.Type.LEADER_ELECTED, newLeadership);
        notifyPeers(event);
    }
}
#end_block

#method_before
private void notifyPeers(LeadershipEvent event) {
    eventDispatcher.post(event);
    clusterCommunicator.broadcast(new ClusterMessage(clusterService.getLocalNode().id(), LEADERSHIP_EVENT_MESSAGE_SUBJECT, SERIALIZER.encode(event)));
}
#method_after
private void notifyPeers(LeadershipEvent event) {
    eventDispatcher.post(event);
    clusterCommunicator.broadcast(event, LEADERSHIP_EVENT_MESSAGE_SUBJECT, SERIALIZER::encode);
}
#end_block

#method_before
private void notifyRemovedLeader(String path, NodeId leader, long epoch, long electedTime) {
    Versioned<List<NodeId>> candidates = candidateMap.get(path);
    Leadership oldLeadership = new Leadership(path, leader, candidates.value(), epoch, electedTime);
    boolean updatedLeader = false;
    synchronized (leaderBoard) {
        Leadership currentLeader = leaderBoard.get(path);
        if (currentLeader != null && currentLeader.epoch() == oldLeadership.epoch()) {
            leaderBoard.remove(path);
            updatedLeader = true;
        }
    }
    if (updatedLeader) {
        LeadershipEvent event = new LeadershipEvent(LeadershipEvent.Type.LEADER_BOOTED, oldLeadership);
        notifyPeers(event);
    }
}
#method_after
private void notifyRemovedLeader(String path, NodeId leader, long epoch, long electedTime) {
    Versioned<List<NodeId>> candidates = candidateMap.get(path);
    Leadership oldLeadership = new Leadership(path, leader, candidates.value(), epoch, electedTime);
    final MutableBoolean updatedLeader = new MutableBoolean(false);
    leaderBoard.compute(path, (k, currentLeader) -> {
        if (currentLeader != null && currentLeader.epoch() == oldLeadership.epoch()) {
            updatedLeader.setTrue();
            return null;
        }
        return currentLeader;
    });
    if (updatedLeader.booleanValue()) {
        LeadershipEvent event = new LeadershipEvent(LeadershipEvent.Type.LEADER_BOOTED, oldLeadership);
        notifyPeers(event);
    }
}
#end_block

#method_before
@Override
public void handle(ClusterMessage message) {
    LeadershipEvent leadershipEvent = SERIALIZER.decode(message.payload());
    log.trace("Leadership Event: time = {} type = {} event = {}", leadershipEvent.time(), leadershipEvent.type(), leadershipEvent);
    Leadership leadershipUpdate = leadershipEvent.subject();
    LeadershipEvent.Type eventType = leadershipEvent.type();
    String topic = leadershipUpdate.topic();
    boolean updateAccepted = false;
    synchronized (leaderBoard) {
        Leadership currentLeadership = leaderBoard.get(topic);
        if (eventType.equals(LeadershipEvent.Type.LEADER_ELECTED)) {
            if (currentLeadership == null || currentLeadership.epoch() < leadershipUpdate.epoch()) {
                leaderBoard.put(topic, leadershipUpdate);
                updateAccepted = true;
            }
        } else if (eventType.equals(LeadershipEvent.Type.LEADER_BOOTED)) {
            if (currentLeadership != null && currentLeadership.epoch() == leadershipUpdate.epoch()) {
                leaderBoard.remove(topic);
                updateAccepted = true;
            }
        } else if (eventType.equals(LeadershipEvent.Type.CANDIDATES_CHANGED)) {
            Leadership currentInfo = candidateBoard.get(topic);
            if (currentInfo == null || currentInfo.epoch() <= leadershipUpdate.epoch()) {
                candidateBoard.put(topic, leadershipUpdate);
                updateAccepted = true;
            }
        } else {
            throw new IllegalStateException("Unknown event type.");
        }
        if (updateAccepted) {
            eventDispatcher.post(leadershipEvent);
        }
    }
}
#method_after
@Override
public void handle(ClusterMessage message) {
    LeadershipEvent leadershipEvent = SERIALIZER.decode(message.payload());
    log.trace("Leadership Event: time = {} type = {} event = {}", leadershipEvent.time(), leadershipEvent.type(), leadershipEvent);
    Leadership leadershipUpdate = leadershipEvent.subject();
    LeadershipEvent.Type eventType = leadershipEvent.type();
    String topic = leadershipUpdate.topic();
    MutableBoolean updateAccepted = new MutableBoolean(false);
    if (eventType.equals(LeadershipEvent.Type.LEADER_ELECTED)) {
        leaderBoard.compute(topic, (k, currentLeadership) -> {
            if (currentLeadership == null || currentLeadership.epoch() < leadershipUpdate.epoch()) {
                updateAccepted.setTrue();
                return leadershipUpdate;
            }
            return currentLeadership;
        });
    } else if (eventType.equals(LeadershipEvent.Type.LEADER_BOOTED)) {
        leaderBoard.compute(topic, (k, currentLeadership) -> {
            if (currentLeadership == null || currentLeadership.epoch() < leadershipUpdate.epoch()) {
                updateAccepted.setTrue();
                return null;
            }
            return currentLeadership;
        });
    } else if (eventType.equals(LeadershipEvent.Type.CANDIDATES_CHANGED)) {
        candidateBoard.compute(topic, (k, currentInfo) -> {
            if (currentInfo == null || currentInfo.epoch() <= leadershipUpdate.epoch()) {
                updateAccepted.setTrue();
                return leadershipUpdate;
            }
            return currentInfo;
        });
    } else {
        throw new IllegalStateException("Unknown event type.");
    }
    if (updateAccepted.booleanValue()) {
        eventDispatcher.post(leadershipEvent);
    }
}
#end_block

#method_before
private void sendLeadershipStatus() {
    try {
        leaderBoard.forEach((path, leadership) -> {
            if (leadership.leader().equals(localNodeId)) {
                LeadershipEvent event = new LeadershipEvent(LeadershipEvent.Type.LEADER_ELECTED, leadership);
                clusterCommunicator.broadcast(new ClusterMessage(clusterService.getLocalNode().id(), LEADERSHIP_EVENT_MESSAGE_SUBJECT, SERIALIZER.encode(event)));
            }
        });
    } catch (Exception e) {
        log.debug("Failed to send leadership updates", e);
    }
}
#method_after
private void sendLeadershipStatus() {
    try {
        leaderBoard.forEach((path, leadership) -> {
            if (leadership.leader().equals(localNodeId)) {
                LeadershipEvent event = new LeadershipEvent(LeadershipEvent.Type.LEADER_ELECTED, leadership);
                clusterCommunicator.broadcast(event, LEADERSHIP_EVENT_MESSAGE_SUBJECT, SERIALIZER::encode);
            }
        });
        candidateBoard.forEach((path, leadership) -> {
            LeadershipEvent event = new LeadershipEvent(LeadershipEvent.Type.CANDIDATES_CHANGED, leadership);
            clusterCommunicator.broadcast(event, LEADERSHIP_EVENT_MESSAGE_SUBJECT, SERIALIZER::encode);
        });
    } catch (Exception e) {
        log.debug("Failed to send leadership updates", e);
    }
}
#end_block

#method_before
private void doPeriodicProcessing() {
    while (!isShutdown) {
        // 
        synchronized (this) {
            LeadershipEvent leadershipEvent;
            if (leader != null) {
                if (leader.equals(localNodeId)) {
                    // 
                    // Advertise ourselves as the leader
                    // 
                    leadershipEvent = new LeadershipEvent(LeadershipEvent.Type.LEADER_REELECTED, new Leadership(topicName, localNodeId, myLastLeaderTerm, 0));
                    // Dispatch to all instances
                    clusterCommunicator.broadcastIncludeSelf(new ClusterMessage(clusterService.getLocalNode().id(), LEADERSHIP_EVENT_MESSAGE_SUBJECT, SERIALIZER.encode(leadershipEvent)));
                } else {
                    // 
                    // Test if time to expire a stale leader
                    // 
                    long delta = System.currentTimeMillis() - lastLeadershipUpdateMs;
                    if (delta > LEADERSHIP_REMOTE_TIMEOUT_MS) {
                        log.debug("Topic {} leader {} booted due to heartbeat timeout", topicName, leader);
                        leadershipEvent = new LeadershipEvent(LeadershipEvent.Type.LEADER_BOOTED, new Leadership(topicName, leader, myLastLeaderTerm, 0));
                        // Dispatch only to the local listener(s)
                        eventDispatcher.post(leadershipEvent);
                        leader = null;
                    }
                }
            }
        }
        // Sleep before re-advertising
        try {
            Thread.sleep(LEADERSHIP_PERIODIC_INTERVAL_MS);
        } catch (InterruptedException e) {
            log.debug("Leader Election periodic thread interrupted");
        }
    }
}
#method_after
private void doPeriodicProcessing() {
    while (!isShutdown) {
        // 
        synchronized (this) {
            LeadershipEvent leadershipEvent;
            if (leader != null) {
                if (leader.equals(localNodeId)) {
                    // 
                    // Advertise ourselves as the leader
                    // 
                    leadershipEvent = new LeadershipEvent(LeadershipEvent.Type.LEADER_REELECTED, new Leadership(topicName, localNodeId, myLastLeaderTerm, 0));
                    // Dispatch to all instances
                    clusterCommunicator.broadcastIncludeSelf(leadershipEvent, LEADERSHIP_EVENT_MESSAGE_SUBJECT, SERIALIZER::encode);
                } else {
                    // 
                    // Test if time to expire a stale leader
                    // 
                    long delta = System.currentTimeMillis() - lastLeadershipUpdateMs;
                    if (delta > LEADERSHIP_REMOTE_TIMEOUT_MS) {
                        log.debug("Topic {} leader {} booted due to heartbeat timeout", topicName, leader);
                        leadershipEvent = new LeadershipEvent(LeadershipEvent.Type.LEADER_BOOTED, new Leadership(topicName, leader, myLastLeaderTerm, 0));
                        // Dispatch only to the local listener(s)
                        eventDispatcher.post(leadershipEvent);
                        leader = null;
                    }
                }
            }
        }
        // Sleep before re-advertising
        try {
            Thread.sleep(LEADERSHIP_PERIODIC_INTERVAL_MS);
        } catch (InterruptedException e) {
            log.debug("Leader Election periodic thread interrupted");
        }
    }
}
#end_block

#method_before
private void doLeaderElectionThread() {
    while (!isShutdown) {
        LeadershipEvent leadershipEvent;
        // 
        // Try to acquire the lock and keep it until the instance is
        // shutdown.
        // 
        log.debug("Leader Election begin for topic {}", topicName);
        try {
            // Block until it becomes the leader
            leaderLock.lockInterruptibly();
        } catch (InterruptedException e) {
            // 
            // Thread interrupted. Either shutdown or run for
            // re-election.
            // 
            log.debug("Election interrupted for topic {}", topicName);
            continue;
        }
        try {
            synchronized (this) {
                // 
                // This instance is now the leader
                // 
                log.info("Leader Elected for topic {}", topicName);
                updateTerm();
                leader = localNodeId;
                leadershipEvent = new LeadershipEvent(LeadershipEvent.Type.LEADER_ELECTED, new Leadership(topicName, localNodeId, myLastLeaderTerm, 0));
                clusterCommunicator.broadcastIncludeSelf(new ClusterMessage(clusterService.getLocalNode().id(), LEADERSHIP_EVENT_MESSAGE_SUBJECT, SERIALIZER.encode(leadershipEvent)));
            }
            // Sleep forever until interrupted
            Thread.sleep(Long.MAX_VALUE);
        } catch (InterruptedException e) {
            // 
            // Thread interrupted. Either shutdown or run for
            // re-election.
            // 
            log.debug("Leader Interrupted for topic {}", topicName);
        } finally {
            synchronized (this) {
                // If we reach here, we should release the leadership
                log.debug("Leader Lock Released for topic {}", topicName);
                if ((leader != null) && leader.equals(localNodeId)) {
                    leader = null;
                }
                leadershipEvent = new LeadershipEvent(LeadershipEvent.Type.LEADER_BOOTED, new Leadership(topicName, localNodeId, myLastLeaderTerm, 0));
                clusterCommunicator.broadcastIncludeSelf(new ClusterMessage(clusterService.getLocalNode().id(), LEADERSHIP_EVENT_MESSAGE_SUBJECT, SERIALIZER.encode(leadershipEvent)));
                if (leaderLock.isLockedByCurrentThread()) {
                    leaderLock.unlock();
                }
            }
        }
    }
    isRunningForLeadership = false;
}
#method_after
private void doLeaderElectionThread() {
    while (!isShutdown) {
        LeadershipEvent leadershipEvent;
        // 
        // Try to acquire the lock and keep it until the instance is
        // shutdown.
        // 
        log.debug("Leader Election begin for topic {}", topicName);
        try {
            // Block until it becomes the leader
            leaderLock.lockInterruptibly();
        } catch (InterruptedException e) {
            // 
            // Thread interrupted. Either shutdown or run for
            // re-election.
            // 
            log.debug("Election interrupted for topic {}", topicName);
            continue;
        }
        try {
            synchronized (this) {
                // 
                // This instance is now the leader
                // 
                log.info("Leader Elected for topic {}", topicName);
                updateTerm();
                leader = localNodeId;
                leadershipEvent = new LeadershipEvent(LeadershipEvent.Type.LEADER_ELECTED, new Leadership(topicName, localNodeId, myLastLeaderTerm, 0));
                clusterCommunicator.broadcastIncludeSelf(leadershipEvent, LEADERSHIP_EVENT_MESSAGE_SUBJECT, SERIALIZER::encode);
            }
            // Sleep forever until interrupted
            Thread.sleep(Long.MAX_VALUE);
        } catch (InterruptedException e) {
            // 
            // Thread interrupted. Either shutdown or run for
            // re-election.
            // 
            log.debug("Leader Interrupted for topic {}", topicName);
        } finally {
            synchronized (this) {
                // If we reach here, we should release the leadership
                log.debug("Leader Lock Released for topic {}", topicName);
                if ((leader != null) && leader.equals(localNodeId)) {
                    leader = null;
                }
                leadershipEvent = new LeadershipEvent(LeadershipEvent.Type.LEADER_BOOTED, new Leadership(topicName, localNodeId, myLastLeaderTerm, 0));
                clusterCommunicator.broadcastIncludeSelf(leadershipEvent, LEADERSHIP_EVENT_MESSAGE_SUBJECT, SERIALIZER::encode);
                if (leaderLock.isLockedByCurrentThread()) {
                    leaderLock.unlock();
                }
            }
        }
    }
    isRunningForLeadership = false;
}
#end_block

#method_before
/**
 * The nodeId of leader for this topic.
 * @return leader node.
 */
public NodeId leader() {
    return leader.orElseGet(() -> null);
}
#method_after
/**
 * The nodeId of leader for this topic.
 *
 * @return leader node.
 */
public NodeId leader() {
    return leader.orElse(null);
}
#end_block

#method_before
private JsonNode jsonComponent(String component, ObjectMapper mapper) {
    ObjectNode node = mapper.createObjectNode().put("componentName", component);
    final ArrayNode properties = node.putArray("properties");
    service.getProperties(component).forEach(configProperty -> properties.add(jsonProperty(configProperty, mapper)));
    return node;
}
#method_after
private JsonNode jsonComponent(String component, ObjectMapper mapper) {
    ObjectNode node = mapper.createObjectNode().put("componentName", component);
    final ArrayNode propertiesJson = node.putArray("properties");
    Set<ConfigProperty> properties = service.getProperties(component);
    if (properties != null) {
        properties.forEach(configProperty -> propertiesJson.add(jsonProperty(configProperty, mapper)));
    }
    return node;
}
#end_block

#method_before
@Override
public void process(ObjectNode event) {
    String type = string(event, "event", "unknown");
    if (type.equals("deviceDataRequest")) {
        dataRequest(event);
    } else if (type.equals("deviceDetailsReq")) {
        detailsRequest(event);
    }
}
#method_after
@Override
public void process(ObjectNode event) {
    String type = string(event, "event", "unknown");
    if (type.equals("deviceDataRequest")) {
        dataRequest(event);
    } else if (type.equals("deviceDetailsRequest")) {
        detailsRequest(event);
    }
}
#end_block

#method_before
private void detailsRequest(ObjectNode event) {
    ObjectNode payload = payload(event);
    String id = string(payload, "id", "of:0000000000000000");
    DeviceId deviceId = DeviceId.deviceId(id);
    DeviceService service = get(DeviceService.class);
    MastershipService ms = get(MastershipService.class);
    Device device = service.getDevice(deviceId);
    ObjectNode data = MAPPER.createObjectNode();
    data.put(ID, deviceId.toString());
    data.put(TYPE, device.type().toString());
    data.put(MFR, device.manufacturer());
    data.put(HW, device.hwVersion());
    data.put(SW, device.swVersion());
    data.put(SERIAL, device.serialNumber());
    data.put(CHASSIS_ID, device.chassisId().toString());
    data.put(MASTER_ID, ms.getMasterFor(deviceId).toString());
    data.put(PROTOCOL, device.annotations().value(PROTOCOL));
    ArrayNode ports = MAPPER.createArrayNode();
    for (Port p : service.getPorts(deviceId)) {
        ports.add(portData(p));
    }
    data.set(PORTS, ports);
    ObjectNode rootNode = mapper.createObjectNode();
    rootNode.set("details", data);
    connection().sendMessage("deviceDetailsResp", 0, rootNode);
}
#method_after
private void detailsRequest(ObjectNode event) {
    ObjectNode payload = payload(event);
    String id = string(payload, "id", "of:0000000000000000");
    DeviceId deviceId = DeviceId.deviceId(id);
    DeviceService service = get(DeviceService.class);
    MastershipService ms = get(MastershipService.class);
    Device device = service.getDevice(deviceId);
    ObjectNode data = MAPPER.createObjectNode();
    data.put(ID, deviceId.toString());
    data.put(TYPE, device.type().toString());
    data.put(MFR, device.manufacturer());
    data.put(HW, device.hwVersion());
    data.put(SW, device.swVersion());
    data.put(SERIAL, device.serialNumber());
    data.put(CHASSIS_ID, device.chassisId().toString());
    data.put(MASTER_ID, ms.getMasterFor(deviceId).toString());
    data.put(PROTOCOL, device.annotations().value(PROTOCOL));
    ArrayNode ports = MAPPER.createArrayNode();
    for (Port p : service.getPorts(deviceId)) {
        ports.add(portData(p, deviceId));
    }
    data.set(PORTS, ports);
    ObjectNode rootNode = mapper.createObjectNode();
    rootNode.set("details", data);
    connection().sendMessage("deviceDetailsResponse", 0, rootNode);
}
#end_block

#method_before
private ObjectNode portData(Port p) {
    ObjectNode port = MAPPER.createObjectNode();
    port.put(ID, p.number().toString());
    port.put(TYPE, p.type().toString());
    port.put(SPEED, p.portSpeed());
    port.put(ENABLED, p.isEnabled());
    return port;
}
#method_after
private ObjectNode portData(Port p, DeviceId id) {
    ObjectNode port = MAPPER.createObjectNode();
    LinkService ls = get(LinkService.class);
    port.put(ID, p.number().toString());
    port.put(TYPE, p.type().toString());
    port.put(SPEED, p.portSpeed());
    port.put(ENABLED, p.isEnabled());
    Set<Link> links = ls.getEgressLinks(new ConnectPoint(id, p.number()));
    if (!links.isEmpty()) {
        String egressLinks = "";
        for (Link l : links) {
            ConnectPoint dest = l.dst();
            egressLinks += dest.elementId().toString() + "/" + dest.port().toString() + " ";
        }
        port.put(LINK_DEST, egressLinks);
    }
    return port;
}
#end_block

#method_before
@Override
public void processPacket(Dpid dpid, OFMessage msg) {
    Collection<OFFlowStatsEntry> flowStats;
    Collection<OFGroupStatsEntry> groupStats;
    Collection<OFGroupDescStatsEntry> groupDescStats;
    Collection<OFPortStatsEntry> portStats;
    switch(msg.getType()) {
        case PORT_STATUS:
            for (OpenFlowSwitchListener l : ofSwitchListener) {
                l.portChanged(dpid, (OFPortStatus) msg);
            }
            break;
        case FEATURES_REPLY:
            for (OpenFlowSwitchListener l : ofSwitchListener) {
                l.switchChanged(dpid);
            }
            break;
        case PACKET_IN:
            OpenFlowPacketContext pktCtx = DefaultOpenFlowPacketContext.packetContextFromPacketIn(this.getSwitch(dpid), (OFPacketIn) msg);
            for (PacketListener p : ofPacketListener.values()) {
                p.handlePacket(pktCtx);
            }
            break;
        // ie. Back to back error could cause us to starve.
        case FLOW_REMOVED:
        case ERROR:
            executorMsgs.submit(new OFMessageHandler(dpid, msg));
            break;
        case STATS_REPLY:
            OFStatsReply reply = (OFStatsReply) msg;
            switch(reply.getStatsType()) {
                case PORT_DESC:
                    for (OpenFlowSwitchListener l : ofSwitchListener) {
                        l.switchChanged(dpid);
                    }
                    break;
                case FLOW:
                    flowStats = publishFlowStats(dpid, (OFFlowStatsReply) reply);
                    if (flowStats != null) {
                        OFFlowStatsReply.Builder rep = OFFactories.getFactory(msg.getVersion()).buildFlowStatsReply();
                        rep.setEntries(Lists.newLinkedList(flowStats));
                        executorMsgs.submit(new OFMessageHandler(dpid, rep.build()));
                    }
                    break;
                case GROUP:
                    groupStats = publishGroupStats(dpid, (OFGroupStatsReply) reply);
                    if (groupStats != null) {
                        OFGroupStatsReply.Builder rep = OFFactories.getFactory(msg.getVersion()).buildGroupStatsReply();
                        rep.setEntries(Lists.newLinkedList(groupStats));
                        rep.setXid(reply.getXid());
                        executorMsgs.submit(new OFMessageHandler(dpid, rep.build()));
                    }
                    break;
                case GROUP_DESC:
                    groupDescStats = publishGroupDescStats(dpid, (OFGroupDescStatsReply) reply);
                    if (groupDescStats != null) {
                        OFGroupDescStatsReply.Builder rep = OFFactories.getFactory(msg.getVersion()).buildGroupDescStatsReply();
                        rep.setEntries(Lists.newLinkedList(groupDescStats));
                        rep.setXid(reply.getXid());
                        executorMsgs.submit(new OFMessageHandler(dpid, rep.build()));
                    }
                    break;
                case PORT:
                    portStats = publishPortStats(dpid, (OFPortStatsReply) reply);
                    if (portStats != null) {
                        OFPortStatsReply.Builder rep = OFFactories.getFactory(msg.getVersion()).buildPortStatsReply();
                        rep.setEntries(Lists.newLinkedList(portStats));
                        executorMsgs.submit(new OFMessageHandler(dpid, rep.build()));
                    }
                    break;
                default:
                    log.warn("Unsupported stats type : {}", reply.getStatsType());
            }
            break;
        case BARRIER_REPLY:
            executorBarrier.submit(new OFMessageHandler(dpid, msg));
            break;
        case EXPERIMENTER:
            // Handle optical port stats
            if (((OFExperimenter) msg).getExperimenter() == 0x748771) {
                OFCircuitPortStatus circuitPortStatus = (OFCircuitPortStatus) msg;
                OFPortStatus.Builder portStatus = this.getSwitch(dpid).factory().buildPortStatus();
                OFPortDesc.Builder portDesc = this.getSwitch(dpid).factory().buildPortDesc();
                portDesc.setPortNo(circuitPortStatus.getPortNo()).setHwAddr(circuitPortStatus.getHwAddr()).setName(circuitPortStatus.getName()).setConfig(circuitPortStatus.getConfig()).setState(circuitPortStatus.getState());
                portStatus.setReason(circuitPortStatus.getReason()).setDesc(portDesc.build());
                for (OpenFlowSwitchListener l : ofSwitchListener) {
                    l.portChanged(dpid, portStatus.build());
                }
            } else {
                log.warn("Handling experimenter type {} not yet implemented", ((OFExperimenter) msg).getExperimenter(), msg);
            }
            break;
        default:
            log.warn("Handling message type {} not yet implemented {}", msg.getType(), msg);
    }
}
#method_after
@Override
public void processPacket(Dpid dpid, OFMessage msg) {
    Collection<OFFlowStatsEntry> flowStats;
    Collection<OFGroupStatsEntry> groupStats;
    Collection<OFGroupDescStatsEntry> groupDescStats;
    Collection<OFPortStatsEntry> portStats;
    switch(msg.getType()) {
        case PORT_STATUS:
            for (OpenFlowSwitchListener l : ofSwitchListener) {
                l.portChanged(dpid, (OFPortStatus) msg);
            }
            break;
        case FEATURES_REPLY:
            for (OpenFlowSwitchListener l : ofSwitchListener) {
                l.switchChanged(dpid);
            }
            break;
        case PACKET_IN:
            OpenFlowPacketContext pktCtx = DefaultOpenFlowPacketContext.packetContextFromPacketIn(this.getSwitch(dpid), (OFPacketIn) msg);
            for (PacketListener p : ofPacketListener.values()) {
                p.handlePacket(pktCtx);
            }
            break;
        // ie. Back to back error could cause us to starve.
        case FLOW_REMOVED:
        case ERROR:
            executorMsgs.submit(new OFMessageHandler(dpid, msg));
            break;
        case STATS_REPLY:
            OFStatsReply reply = (OFStatsReply) msg;
            switch(reply.getStatsType()) {
                case PORT_DESC:
                    for (OpenFlowSwitchListener l : ofSwitchListener) {
                        l.switchChanged(dpid);
                    }
                    break;
                case FLOW:
                    flowStats = publishFlowStats(dpid, (OFFlowStatsReply) reply);
                    if (flowStats != null) {
                        OFFlowStatsReply.Builder rep = OFFactories.getFactory(msg.getVersion()).buildFlowStatsReply();
                        rep.setEntries(Lists.newLinkedList(flowStats));
                        executorMsgs.submit(new OFMessageHandler(dpid, rep.build()));
                    }
                    break;
                case GROUP:
                    groupStats = publishGroupStats(dpid, (OFGroupStatsReply) reply);
                    if (groupStats != null) {
                        OFGroupStatsReply.Builder rep = OFFactories.getFactory(msg.getVersion()).buildGroupStatsReply();
                        rep.setEntries(Lists.newLinkedList(groupStats));
                        rep.setXid(reply.getXid());
                        executorMsgs.submit(new OFMessageHandler(dpid, rep.build()));
                    }
                    break;
                case GROUP_DESC:
                    groupDescStats = publishGroupDescStats(dpid, (OFGroupDescStatsReply) reply);
                    if (groupDescStats != null) {
                        OFGroupDescStatsReply.Builder rep = OFFactories.getFactory(msg.getVersion()).buildGroupDescStatsReply();
                        rep.setEntries(Lists.newLinkedList(groupDescStats));
                        rep.setXid(reply.getXid());
                        executorMsgs.submit(new OFMessageHandler(dpid, rep.build()));
                    }
                    break;
                case PORT:
                    executorMsgs.submit(new OFMessageHandler(dpid, reply));
                    break;
                default:
                    log.warn("Unsupported stats type : {}", reply.getStatsType());
            }
            break;
        case BARRIER_REPLY:
            executorBarrier.submit(new OFMessageHandler(dpid, msg));
            break;
        case EXPERIMENTER:
            // Handle optical port stats
            if (((OFExperimenter) msg).getExperimenter() == 0x748771) {
                OFCircuitPortStatus circuitPortStatus = (OFCircuitPortStatus) msg;
                OFPortStatus.Builder portStatus = this.getSwitch(dpid).factory().buildPortStatus();
                OFPortDesc.Builder portDesc = this.getSwitch(dpid).factory().buildPortDesc();
                portDesc.setPortNo(circuitPortStatus.getPortNo()).setHwAddr(circuitPortStatus.getHwAddr()).setName(circuitPortStatus.getName()).setConfig(circuitPortStatus.getConfig()).setState(circuitPortStatus.getState());
                portStatus.setReason(circuitPortStatus.getReason()).setDesc(portDesc.build());
                for (OpenFlowSwitchListener l : ofSwitchListener) {
                    l.portChanged(dpid, portStatus.build());
                }
            } else {
                log.warn("Handling experimenter type {} not yet implemented", ((OFExperimenter) msg).getExperimenter(), msg);
            }
            break;
        default:
            log.warn("Handling message type {} not yet implemented {}", msg.getType(), msg);
    }
}
#end_block

#method_before
@Override
public void updatePortStatistics(DeviceId deviceId, Collection<PortStatistics> portStatistics) {
    checkNotNull(deviceId, DEVICE_ID_NULL);
    checkNotNull(portStatistics, "Port statistics list cannot be null");
    checkValidity();
    DeviceEvent event = store.updatePortStatistics(this.provider().id(), deviceId, portStatistics);
// TODO: post events if required
}
#method_after
@Override
public void updatePortStatistics(DeviceId deviceId, Collection<PortStatistics> portStatistics) {
    checkNotNull(deviceId, DEVICE_ID_NULL);
    checkNotNull(portStatistics, "Port statistics list cannot be null");
    checkValidity();
    DeviceEvent event = store.updatePortStatistics(this.provider().id(), deviceId, portStatistics);
    post(event);
}
#end_block

#method_before
@Override
public DeviceEvent updatePortStatistics(ProviderId providerId, DeviceId deviceId, Collection<PortStatistics> portStats) {
    ConcurrentMap<PortNumber, PortStatistics> statsMap = devicePortStats.get(deviceId);
    if (statsMap == null) {
        statsMap = Maps.newConcurrentMap();
        devicePortStats.put(deviceId, statsMap);
    }
    for (PortStatistics stat : portStats) {
        PortNumber portNumber = PortNumber.portNumber(stat.port());
        statsMap.put(portNumber, stat);
    }
    // TODO: Create a new event if required
    return null;
}
#method_after
@Override
public DeviceEvent updatePortStatistics(ProviderId providerId, DeviceId deviceId, Collection<PortStatistics> portStats) {
    ConcurrentMap<PortNumber, PortStatistics> statsMap = devicePortStats.get(deviceId);
    if (statsMap == null) {
        statsMap = Maps.newConcurrentMap();
        devicePortStats.put(deviceId, statsMap);
    }
    for (PortStatistics stat : portStats) {
        PortNumber portNumber = PortNumber.portNumber(stat.port());
        statsMap.put(portNumber, stat);
    }
    return new DeviceEvent(PORT_STATS_UPDATED, devices.get(deviceId), null);
}
#end_block

#method_before
@Override
public Iterable<Device> getDevices() {
    return null;
}
#method_after
@Override
public Iterable<Device> getDevices() {
    return Collections.emptyList();
}
#end_block

#method_before
@Override
public MastershipRole getRole(DeviceId deviceId) {
    return null;
}
#method_after
@Override
public MastershipRole getRole(DeviceId deviceId) {
    return MastershipRole.NONE;
}
#end_block

#method_before
@Override
public List<Port> getPorts(DeviceId deviceId) {
    return null;
}
#method_after
@Override
public List<Port> getPorts(DeviceId deviceId) {
    return Collections.emptyList();
}
#end_block

#method_before
@Override
public DeviceEvent updatePortStatistics(ProviderId providerId, DeviceId deviceId, Collection<PortStatistics> portStats) {
    // TODO: Implement with ECMap
    return updatePortStatsInternal(deviceId, portStats);
}
#method_after
@Override
public DeviceEvent updatePortStatistics(ProviderId providerId, DeviceId deviceId, Collection<PortStatistics> portStats) {
    ConcurrentMap<PortNumber, PortStatistics> statsMap = devicePortStats.get(deviceId);
    if (statsMap == null) {
        statsMap = Maps.newConcurrentMap();
        devicePortStats.put(deviceId, statsMap);
    }
    for (PortStatistics stat : portStats) {
        PortNumber portNumber = PortNumber.portNumber(stat.port());
        statsMap.put(portNumber, stat);
    }
    return new DeviceEvent(PORT_STATS_UPDATED, devices.get(deviceId), null);
}
#end_block

#method_before
@Deactivate
public void deactivate() {
    log.info("Stopped");
}
#method_after
@Deactivate
public void deactivate() {
    groupStoreEntriesByKey.destroy();
    auditPendingReqQueue.destroy();
    log.info("Stopped");
}
#end_block

#method_before
private void storeGroupDescriptionInternal(GroupDescription groupDesc) {
    // Check if a group is existing with the same key
    if (getGroup(groupDesc.deviceId(), groupDesc.appCookie()) != null) {
        return;
    }
    if (deviceAuditStatus.get(groupDesc.deviceId()) == null) {
        // Device group audit has not completed yet
        // Add this group description to pending group key table
        // Create a group entry object with Dummy Group ID
        log.debug("storeGroupDescriptionInternal: Device {} AUDIT " + "pending...Queuing Group ADD request", groupDesc.deviceId());
        StoredGroupEntry group = new DefaultGroup(dummyGroupId, groupDesc);
        group.setState(GroupState.WAITING_AUDIT_COMPLETE);
        EventuallyConsistentMap<GroupStoreKeyMapKey, StoredGroupEntry> pendingKeyTable = getPendingGroupKeyTable();
        pendingKeyTable.put(new GroupStoreKeyMapKey(groupDesc.deviceId(), groupDesc.appCookie()), group);
        return;
    }
    // Get a new group identifier
    GroupId id = new DefaultGroupId(getFreeGroupIdValue(groupDesc.deviceId()));
    // Create a group entry object
    StoredGroupEntry group = new DefaultGroup(id, groupDesc);
    // Insert the newly created group entry into key and id maps
    getGroupStoreKeyMap().put(new GroupStoreKeyMapKey(groupDesc.deviceId(), groupDesc.appCookie()), group);
    /* Ensure it also inserted into group id based table to
         * avoid any chances of duplication in group id generation
         */
    getGroupIdTable(groupDesc.deviceId()).put(id, group);
    notifyDelegate(new GroupEvent(GroupEvent.Type.GROUP_ADD_REQUESTED, group));
}
#method_after
private void storeGroupDescriptionInternal(GroupDescription groupDesc) {
    // Check if a group is existing with the same key
    if (getGroup(groupDesc.deviceId(), groupDesc.appCookie()) != null) {
        return;
    }
    if (deviceAuditStatus.get(groupDesc.deviceId()) == null) {
        // Device group audit has not completed yet
        // Add this group description to pending group key table
        // Create a group entry object with Dummy Group ID
        log.debug("storeGroupDescriptionInternal: Device {} AUDIT " + "pending...Queuing Group ADD request", groupDesc.deviceId());
        StoredGroupEntry group = new DefaultGroup(dummyGroupId, groupDesc);
        group.setState(GroupState.WAITING_AUDIT_COMPLETE);
        EventuallyConsistentMap<GroupStoreKeyMapKey, StoredGroupEntry> pendingKeyTable = getPendingGroupKeyTable();
        pendingKeyTable.put(new GroupStoreKeyMapKey(groupDesc.deviceId(), groupDesc.appCookie()), group);
        return;
    }
    // Get a new group identifier
    GroupId id = new DefaultGroupId(getFreeGroupIdValue(groupDesc.deviceId()));
    // Create a group entry object
    StoredGroupEntry group = new DefaultGroup(id, groupDesc);
    // Insert the newly created group entry into key and id maps
    getGroupStoreKeyMap().put(new GroupStoreKeyMapKey(groupDesc.deviceId(), groupDesc.appCookie()), group);
    // Ensure it also inserted into group id based table to
    // avoid any chances of duplication in group id generation
    getGroupIdTable(groupDesc.deviceId()).put(id, group);
    notifyDelegate(new GroupEvent(GroupEvent.Type.GROUP_ADD_REQUESTED, group));
}
#end_block

#method_before
@Override
public void event(EventuallyConsistentMapEvent<GroupStoreKeyMapKey, StoredGroupEntry> mapEvent) {
    GroupEvent groupEvent = null;
    StoredGroupEntry group = mapEvent.value();
    log.trace("GroupStoreKeyMapListener: received groupid map event {}", mapEvent.type());
    if (mapEvent.type() == EventuallyConsistentMapEvent.Type.PUT) {
        log.trace("GroupStoreKeyMapListener: Received PUT event");
        /* Update the group ID table */
        getGroupIdTable(group.deviceId()).put(group.id(), group);
        if (mapEvent.value().state() == Group.GroupState.ADDED) {
            if (mapEvent.value().isGroupStateAddedFirstTime()) {
                groupEvent = new GroupEvent(Type.GROUP_ADDED, mapEvent.value());
                log.trace("GroupStoreKeyMapListener: Received first time " + "GROUP_ADDED state update");
            } else {
                groupEvent = new GroupEvent(Type.GROUP_UPDATED, mapEvent.value());
                log.trace("GroupStoreKeyMapListener: Received following " + "GROUP_ADDED state update");
            }
        }
    } else if (mapEvent.type() == EventuallyConsistentMapEvent.Type.REMOVE) {
        log.trace("GroupStoreKeyMapListener: Received REMOVE event");
        groupEvent = new GroupEvent(Type.GROUP_REMOVED, mapEvent.value());
        /* Remove the entry from the group ID table */
        getGroupIdTable(group.deviceId()).remove(group.id(), group);
    }
    if (groupEvent != null) {
        notifyDelegate(groupEvent);
    }
}
#method_after
@Override
public void event(EventuallyConsistentMapEvent<GroupStoreKeyMapKey, StoredGroupEntry> mapEvent) {
    GroupEvent groupEvent = null;
    StoredGroupEntry group = mapEvent.value();
    log.trace("GroupStoreKeyMapListener: received groupid map event {}", mapEvent.type());
    if (mapEvent.type() == EventuallyConsistentMapEvent.Type.PUT) {
        log.trace("GroupStoreKeyMapListener: Received PUT event");
        // Update the group ID table
        getGroupIdTable(group.deviceId()).put(group.id(), group);
        if (mapEvent.value().state() == Group.GroupState.ADDED) {
            if (mapEvent.value().isGroupStateAddedFirstTime()) {
                groupEvent = new GroupEvent(Type.GROUP_ADDED, mapEvent.value());
                log.trace("GroupStoreKeyMapListener: Received first time " + "GROUP_ADDED state update");
            } else {
                groupEvent = new GroupEvent(Type.GROUP_UPDATED, mapEvent.value());
                log.trace("GroupStoreKeyMapListener: Received following " + "GROUP_ADDED state update");
            }
        }
    } else if (mapEvent.type() == EventuallyConsistentMapEvent.Type.REMOVE) {
        log.trace("GroupStoreKeyMapListener: Received REMOVE event");
        groupEvent = new GroupEvent(Type.GROUP_REMOVED, mapEvent.value());
        // Remove the entry from the group ID table
        getGroupIdTable(group.deviceId()).remove(group.id(), group);
    }
    if (groupEvent != null) {
        notifyDelegate(groupEvent);
    }
}
#end_block

#method_before
public boolean populateIpRuleForRouter(DeviceId deviceId, IpPrefix ipPrefix, DeviceId destSw, Set<DeviceId> nextHops) {
    TrafficSelector.Builder sbuilder = DefaultTrafficSelector.builder();
    TrafficTreatment.Builder tbuilder = DefaultTrafficTreatment.builder();
    sbuilder.matchIPDst(ipPrefix);
    sbuilder.matchEthType(Ethernet.TYPE_IPV4);
    NeighborSet ns = null;
    // If the next hop is the same as the final destination, then MPLS label is not set.
    if (nextHops.size() == 1 && nextHops.toArray()[0].equals(destSw)) {
        tbuilder.decNwTtl();
        ns = new NeighborSet(nextHops);
    } else {
        tbuilder.copyTtlOut();
        ns = new NeighborSet(nextHops, config.getMplsId(destSw));
    }
    DefaultGroupKey groupKey = (DefaultGroupKey) srManager.getGroupKey(deviceId, ns);
    if (groupKey == null) {
        log.warn("Group key is not found for ns {}", ns);
        return false;
    }
    Group group = srManager.groupService.getGroup(deviceId, groupKey);
    if (group != null) {
        tbuilder.group(group.id());
    } else {
        log.warn("No group found for NeighborSet {} from {} to {}", ns, deviceId, destSw);
        return false;
    }
    TrafficTreatment treatment = tbuilder.build();
    TrafficSelector selector = sbuilder.build();
    FlowRule f = new DefaultFlowRule(deviceId, selector, treatment, 100, srManager.appId, 600, false, FlowRule.Type.IP);
    srManager.flowRuleService.applyFlowRules(f);
    log.debug("IP flow rule {} is set to switch {}", f, deviceId);
    return true;
}
#method_after
public boolean populateIpRuleForRouter(DeviceId deviceId, IpPrefix ipPrefix, DeviceId destSw, Set<DeviceId> nextHops) {
    TrafficSelector.Builder sbuilder = DefaultTrafficSelector.builder();
    TrafficTreatment.Builder tbuilder = DefaultTrafficTreatment.builder();
    sbuilder.matchIPDst(ipPrefix);
    sbuilder.matchEthType(Ethernet.TYPE_IPV4);
    NeighborSet ns = null;
    // If the next hop is the same as the final destination, then MPLS label is not set.
    if (nextHops.size() == 1 && nextHops.toArray()[0].equals(destSw)) {
        tbuilder.decNwTtl();
        ns = new NeighborSet(nextHops);
    } else {
        tbuilder.copyTtlOut();
        ns = new NeighborSet(nextHops, config.getMplsId(destSw));
    }
    DefaultGroupKey groupKey = (DefaultGroupKey) srManager.getGroupKey(ns);
    if (groupKey == null) {
        log.warn("Group key is not found for ns {}", ns);
        return false;
    }
    Group group = srManager.groupService.getGroup(deviceId, groupKey);
    if (group != null) {
        tbuilder.group(group.id());
    } else {
        log.warn("No group found for NeighborSet {} from {} to {}", ns, deviceId, destSw);
        return false;
    }
    TrafficTreatment treatment = tbuilder.build();
    TrafficSelector selector = sbuilder.build();
    FlowRule f = new DefaultFlowRule(deviceId, selector, treatment, 100, srManager.appId, 600, false, FlowRule.Type.IP);
    srManager.flowRuleService.applyFlowRules(f);
    log.debug("IP flow rule {} is set to switch {}", f, deviceId);
    return true;
}
#end_block

#method_before
private TrafficTreatment getMplsTreatment(DeviceId deviceId, DeviceId destSw, Set<DeviceId> nextHops, boolean phpRequired, boolean isBos) {
    TrafficTreatment.Builder tbuilder = DefaultTrafficTreatment.builder();
    if (phpRequired) {
        tbuilder.copyTtlIn();
        if (isBos) {
            tbuilder.popMpls(Ethernet.TYPE_IPV4).decNwTtl();
        } else {
            tbuilder.popMpls(Ethernet.MPLS_UNICAST).decMplsTtl();
        }
    } else {
        tbuilder.decMplsTtl();
    }
    if (config.isEcmpNotSupportedInTransit(deviceId) && config.isTransitRouter(deviceId)) {
        Link link = selectOneLink(deviceId, nextHops);
        if (link == null) {
            log.warn("No link from {} to {}", deviceId, nextHops);
            return null;
        }
        tbuilder.setEthSrc(config.getRouterMacAddress(deviceId)).setEthDst(config.getRouterMacAddress(link.dst().deviceId())).setOutput(link.src().port());
    } else {
        NeighborSet ns = new NeighborSet(nextHops);
        DefaultGroupKey groupKey = (DefaultGroupKey) srManager.getGroupKey(deviceId, ns);
        if (groupKey == null) {
            log.warn("Group key is not found for ns {}", ns);
            return null;
        }
        Group group = srManager.groupService.getGroup(deviceId, groupKey);
        if (group != null) {
            tbuilder.group(group.id());
        } else {
            log.warn("No group found for ns {} key {} in {}", ns, srManager.getGroupKey(deviceId, ns), deviceId);
            return null;
        }
    }
    return tbuilder.build();
}
#method_after
private TrafficTreatment getMplsTreatment(DeviceId deviceId, DeviceId destSw, Set<DeviceId> nextHops, boolean phpRequired, boolean isBos) {
    TrafficTreatment.Builder tbuilder = DefaultTrafficTreatment.builder();
    if (phpRequired) {
        tbuilder.copyTtlIn();
        if (isBos) {
            tbuilder.popMpls(Ethernet.TYPE_IPV4).decNwTtl();
        } else {
            tbuilder.popMpls(Ethernet.MPLS_UNICAST).decMplsTtl();
        }
    } else {
        tbuilder.decMplsTtl();
    }
    if (config.isEcmpNotSupportedInTransit(deviceId) && config.isTransitRouter(deviceId)) {
        Link link = selectOneLink(deviceId, nextHops);
        if (link == null) {
            log.warn("No link from {} to {}", deviceId, nextHops);
            return null;
        }
        tbuilder.setEthSrc(config.getRouterMacAddress(deviceId)).setEthDst(config.getRouterMacAddress(link.dst().deviceId())).setOutput(link.src().port());
    } else {
        NeighborSet ns = new NeighborSet(nextHops);
        DefaultGroupKey groupKey = (DefaultGroupKey) srManager.getGroupKey(ns);
        if (groupKey == null) {
            log.warn("Group key is not found for ns {}", ns);
            return null;
        }
        Group group = srManager.groupService.getGroup(deviceId, groupKey);
        if (group != null) {
            tbuilder.group(group.id());
        } else {
            log.warn("No group found for ns {} key {} in {}", ns, srManager.getGroupKey(ns), deviceId);
            return null;
        }
    }
    return tbuilder.build();
}
#end_block

#method_before
private List<IpPrefix> extractSubnet(String subnetInfo) {
    List<IpPrefix> subnetIpPrefixes = new ArrayList<>();
    // TODO
    IpPrefix prefix = IpPrefix.valueOf(subnetInfo);
    if (prefix == null) {
        log.error("Wrong ip prefix type {}", subnetInfo);
    } else {
        subnetIpPrefixes.add(prefix);
    }
    return subnetIpPrefixes;
}
#method_after
private List<IpPrefix> extractSubnet(String subnetInfo) {
    List<IpPrefix> subnetIpPrefixes = new ArrayList<>();
    // TODO: refactoring required depending on the format of the subnet info
    IpPrefix prefix = IpPrefix.valueOf(subnetInfo);
    if (prefix == null) {
        log.error("Wrong ip prefix type {}", subnetInfo);
    } else {
        subnetIpPrefixes.add(prefix);
    }
    return subnetIpPrefixes;
}
#end_block

#method_before
private void handleArpRequest(DeviceId deviceId, ConnectPoint inPort, Ethernet payload) {
    ARP arpRequest = (ARP) payload.getPayload();
    HostId targetHostId = HostId.hostId(MacAddress.valueOf(arpRequest.getTargetHardwareAddress()));
    /* ARP request for router */
    if (isArpReqForRouter(deviceId, arpRequest)) {
        Ip4Address targetAddress = Ip4Address.valueOf(arpRequest.getTargetProtocolAddress());
        sendArpResponse(arpRequest, config.getRouterMac(targetAddress));
    /* ARP request for known hosts */
    } else if (srManager.hostService.getHost(targetHostId) != null) {
        MacAddress targetMac = srManager.hostService.getHost(targetHostId).mac();
        sendArpResponse(arpRequest, targetMac);
    /* ARP request for unknown host in the subnet */
    } else if (isArpReqForSubnet(deviceId, arpRequest)) {
        flood(payload, inPort);
    }
}
#method_after
private void handleArpRequest(DeviceId deviceId, ConnectPoint inPort, Ethernet payload) {
    ARP arpRequest = (ARP) payload.getPayload();
    HostId targetHostId = HostId.hostId(MacAddress.valueOf(arpRequest.getTargetHardwareAddress()));
    // ARP request for router
    if (isArpReqForRouter(deviceId, arpRequest)) {
        Ip4Address targetAddress = Ip4Address.valueOf(arpRequest.getTargetProtocolAddress());
        sendArpResponse(arpRequest, config.getRouterMac(targetAddress));
    // ARP request for known hosts
    } else if (srManager.hostService.getHost(targetHostId) != null) {
        MacAddress targetMac = srManager.hostService.getHost(targetHostId).mac();
        sendArpResponse(arpRequest, targetMac);
    // ARP request for unknown host in the subnet
    } else if (isArpReqForSubnet(deviceId, arpRequest)) {
        flood(payload, inPort);
    }
}
#end_block

#method_before
public GroupKey getGroupKey(DeviceId deviceId, NeighborSet ns) {
    for (DefaultGroupHandler groupHandler : groupHandlerMap.values()) {
        return groupHandler.getGroupKey(ns);
    }
    return null;
}
#method_after
public GroupKey getGroupKey(NeighborSet ns) {
    for (DefaultGroupHandler groupHandler : groupHandlerMap.values()) {
        return groupHandler.getGroupKey(ns);
    }
    return null;
}
#end_block

#method_before
public boolean populateAllRoutingRules() {
    populationStatus = Status.STARTED;
    log.info("Start to populate routing rules");
    for (Device sw : srManager.deviceService.getDevices()) {
        if (srManager.mastershipService.getLocalRole(sw.id()) != MastershipRole.MASTER) {
            continue;
        }
        ECMPShortestPathGraph ecmpSPG = new ECMPShortestPathGraph(sw.id(), srManager);
        if (!populateEcmpRoutingRules(sw, ecmpSPG)) {
            populationStatus = Status.ABORTED;
            log.debug("Abort routing rule population");
            return false;
        }
    // Set adjacency routing rule for all switches
    /*
                try {
                    populateAdjacencyncyRule(sw);
                } catch (JSONException e) {
                    e.printStackTrace();
                }
                */
    }
    // UpdatePolicyRules();
    populationStatus = Status.SUCCEEDED;
    log.info("Complete routing rule population");
    return true;
}
#method_after
public boolean populateAllRoutingRules() {
    populationStatus = Status.STARTED;
    log.info("Starts to populate routing rules");
    for (Device sw : srManager.deviceService.getDevices()) {
        if (srManager.mastershipService.getLocalRole(sw.id()) != MastershipRole.MASTER) {
            continue;
        }
        ECMPShortestPathGraph ecmpSPG = new ECMPShortestPathGraph(sw.id(), srManager);
        if (!populateEcmpRoutingRules(sw, ecmpSPG)) {
            populationStatus = Status.ABORTED;
            log.debug("Abort routing rule population");
            return false;
        }
    // TODO: Set adjacency routing rule for all switches
    }
    populationStatus = Status.SUCCEEDED;
    log.info("Completes routing rule population");
    return true;
}
#end_block

#method_before
public void processPacketIn(InboundPacket pkt) {
    Ethernet ethernet = pkt.parsed();
    IPv4 ipv4 = (IPv4) ethernet.getPayload();
    ConnectPoint connectPoint = pkt.receivedFrom();
    DeviceId deviceId = connectPoint.deviceId();
    Ip4Address destinationAddress = Ip4Address.valueOf(ipv4.getDestinationAddress());
    Ip4Address gatewayIpAddress = config.getGatewayIpAddress(deviceId);
    IpPrefix routerIpPrefix = config.getRouterIpAddress(deviceId);
    Ip4Address routerIpAddress = routerIpPrefix.getIp4Prefix().address();
    /* ICMP to the router IP or gateway IP */
    if (((ICMP) ipv4.getPayload()).getIcmpType() == ICMP.TYPE_ECHO_REQUEST && (destinationAddress.equals(routerIpAddress) || gatewayIpAddress.equals(destinationAddress))) {
        sendICMPResponse(ethernet, connectPoint);
    // TODO: do we need to set the flow rule again ??
    /* ICMP for any known host */
    } else if (!srManager.hostService.getHostsByIp(destinationAddress).isEmpty()) {
        srManager.ipHandler.forwardPackets(deviceId, destinationAddress);
    /* ICMP for an unknown host in the subnet of the router */
    } else if (config.inSameSubnet(deviceId, destinationAddress)) {
        srManager.arpHandler.sendArpRequest(deviceId, destinationAddress, connectPoint);
    /* ICMP for an unknown host */
    } else {
        log.debug("ICMP request for unknown host {} ", destinationAddress);
    // Do nothing
    }
}
#method_after
public void processPacketIn(InboundPacket pkt) {
    Ethernet ethernet = pkt.parsed();
    IPv4 ipv4 = (IPv4) ethernet.getPayload();
    ConnectPoint connectPoint = pkt.receivedFrom();
    DeviceId deviceId = connectPoint.deviceId();
    Ip4Address destinationAddress = Ip4Address.valueOf(ipv4.getDestinationAddress());
    Ip4Address gatewayIpAddress = config.getGatewayIpAddress(deviceId);
    IpPrefix routerIpPrefix = config.getRouterIpAddress(deviceId);
    Ip4Address routerIpAddress = routerIpPrefix.getIp4Prefix().address();
    // ICMP to the router IP or gateway IP
    if (((ICMP) ipv4.getPayload()).getIcmpType() == ICMP.TYPE_ECHO_REQUEST && (destinationAddress.equals(routerIpAddress) || gatewayIpAddress.equals(destinationAddress))) {
        sendICMPResponse(ethernet, connectPoint);
    // TODO: do we need to set the flow rule again ??
    // ICMP for any known host
    } else if (!srManager.hostService.getHostsByIp(destinationAddress).isEmpty()) {
        srManager.ipHandler.forwardPackets(deviceId, destinationAddress);
    // ICMP for an unknown host in the subnet of the router
    } else if (config.inSameSubnet(deviceId, destinationAddress)) {
        srManager.arpHandler.sendArpRequest(deviceId, destinationAddress, connectPoint);
    // ICMP for an unknown host
    } else {
        log.debug("ICMP request for unknown host {} ", destinationAddress);
    // Do nothing
    }
}
#end_block

#method_before
public void processPacketIn(InboundPacket pkt) {
    Ethernet ethernet = pkt.parsed();
    IPv4 ipv4 = (IPv4) ethernet.getPayload();
    ConnectPoint connectPoint = pkt.receivedFrom();
    DeviceId deviceId = connectPoint.deviceId();
    Ip4Address destinationAddress = Ip4Address.valueOf(ipv4.getDestinationAddress());
    /* IP packet for know hosts */
    if (!srManager.hostService.getHostsByIp(destinationAddress).isEmpty()) {
        forwardPackets(deviceId, destinationAddress);
    /* IP packet for unknown host in the subnet of the router */
    } else if (config.inSameSubnet(deviceId, destinationAddress)) {
        srManager.arpHandler.sendArpRequest(deviceId, destinationAddress, connectPoint);
    /* IP packets for unknown host */
    } else {
        log.debug("ICMP request for unknown host {} which is not in the subnet", destinationAddress);
    // Do nothing
    }
}
#method_after
public void processPacketIn(InboundPacket pkt) {
    Ethernet ethernet = pkt.parsed();
    IPv4 ipv4 = (IPv4) ethernet.getPayload();
    ConnectPoint connectPoint = pkt.receivedFrom();
    DeviceId deviceId = connectPoint.deviceId();
    Ip4Address destinationAddress = Ip4Address.valueOf(ipv4.getDestinationAddress());
    // IP packet for know hosts
    if (!srManager.hostService.getHostsByIp(destinationAddress).isEmpty()) {
        forwardPackets(deviceId, destinationAddress);
    // IP packet for unknown host in the subnet of the router
    } else if (config.inSameSubnet(deviceId, destinationAddress)) {
        srManager.arpHandler.sendArpRequest(deviceId, destinationAddress, connectPoint);
    // IP packets for unknown host
    } else {
        log.debug("ICMP request for unknown host {} which is not in the subnet", destinationAddress);
    // Do nothing
    }
}
#end_block

#method_before
private KryoSerializer createSerializer(KryoNamespace.Builder builder) {
    return new KryoSerializer() {

        @Override
        protected void setupKryoPool() {
            // Add the map's internal helper classes to the user-supplied serializer
            serializerPool = builder.register(WallClockTimestamp.class).register(PutEntry.class).register(RemoveEntry.class).register(ArrayList.class).register(AntiEntropyAdvertisement.class).register(HashMap.class).register(Timestamped.class).build();
        }
    };
}
#method_after
private KryoSerializer createSerializer(KryoNamespace.Builder builder) {
    return new KryoSerializer() {

        @Override
        protected void setupKryoPool() {
            // Add the map's internal helper classes to the user-supplied serializer
            serializerPool = builder.register(LogicalTimestamp.class).register(WallClockTimestamp.class).register(PutEntry.class).register(RemoveEntry.class).register(ArrayList.class).register(AntiEntropyAdvertisement.class).register(HashMap.class).register(Timestamped.class).build();
        }
    };
}
#end_block

#method_before
@Override
public void put(K key, V value) {
    checkState(!destroyed, destroyedMessage);
    checkNotNull(key, ERROR_NULL_KEY);
    checkNotNull(value, ERROR_NULL_VALUE);
    Timestamp timestamp = clockService.getTimestamp(key, value);
    if (putInternal(key, value, timestamp)) {
        notifyPeers(new PutEntry<>(key, value, timestamp), peerUpdateFunction.apply(key, value));
        notifyListeners(new EventuallyConsistentMapEvent<>(EventuallyConsistentMapEvent.Type.PUT, key, value));
        if (persistent) {
            persistentStore.put(key, value, timestamp);
        }
    }
}
#method_after
@Override
public void put(K key, V value) {
    checkState(!destroyed, destroyedMessage);
    checkNotNull(key, ERROR_NULL_KEY);
    checkNotNull(value, ERROR_NULL_VALUE);
    Timestamp timestamp = clockService.getTimestamp(key, value);
    if (putInternal(key, value, timestamp)) {
        notifyPeers(new PutEntry<>(key, value, timestamp), peerUpdateFunction.apply(key, value));
        notifyListeners(new EventuallyConsistentMapEvent<>(EventuallyConsistentMapEvent.Type.PUT, key, value));
    }
}
#end_block

#method_before
private boolean putInternal(K key, V value, Timestamp timestamp) {
    counter.incrementCount();
    Timestamp removed = removedItems.get(key);
    if (removed != null && removed.isNewerThan(timestamp)) {
        log.debug("ecmap - removed was newer {}", value);
        return false;
    }
    final MutableBoolean updated = new MutableBoolean(false);
    items.compute(key, (k, existing) -> {
        if (existing != null && existing.isNewerThan(timestamp)) {
            updated.setFalse();
            return existing;
        } else {
            updated.setTrue();
            return new Timestamped<>(value, timestamp);
        }
    });
    boolean success = updated.booleanValue();
    if (!success) {
        log.debug("ecmap - existing was newer {}", value);
    }
    if (success && removed != null) {
        removedItems.remove(key, removed);
    }
    return success;
}
#method_after
private boolean putInternal(K key, V value, Timestamp timestamp) {
    counter.incrementCount();
    Timestamp removed = removedItems.get(key);
    if (removed != null && removed.isNewerThan(timestamp)) {
        log.debug("ecmap - removed was newer {}", value);
        return false;
    }
    final MutableBoolean updated = new MutableBoolean(false);
    items.compute(key, (k, existing) -> {
        if (existing != null && existing.isNewerThan(timestamp)) {
            updated.setFalse();
            return existing;
        } else {
            updated.setTrue();
            return new Timestamped<>(value, timestamp);
        }
    });
    boolean success = updated.booleanValue();
    if (!success) {
        log.debug("ecmap - existing was newer {}", value);
    }
    if (success && removed != null) {
        removedItems.remove(key, removed);
    }
    if (success && persistent) {
        persistentStore.put(key, value, timestamp);
    }
    return success;
}
#end_block

#method_before
@Override
public void remove(K key) {
    checkState(!destroyed, destroyedMessage);
    checkNotNull(key, ERROR_NULL_KEY);
    // TODO prevent calls here if value is important for timestamp
    Timestamp timestamp = clockService.getTimestamp(key, null);
    if (removeInternal(key, timestamp)) {
        notifyPeers(new RemoveEntry<>(key, timestamp), peerUpdateFunction.apply(key, null));
        notifyListeners(new EventuallyConsistentMapEvent<>(EventuallyConsistentMapEvent.Type.REMOVE, key, null));
        if (persistent) {
            persistentStore.remove(key, timestamp);
        }
    }
}
#method_after
@Override
public void remove(K key) {
    checkState(!destroyed, destroyedMessage);
    checkNotNull(key, ERROR_NULL_KEY);
    // TODO prevent calls here if value is important for timestamp
    Timestamp timestamp = clockService.getTimestamp(key, null);
    if (removeInternal(key, timestamp)) {
        notifyPeers(new RemoveEntry<>(key, timestamp), peerUpdateFunction.apply(key, null));
        notifyListeners(new EventuallyConsistentMapEvent<>(EventuallyConsistentMapEvent.Type.REMOVE, key, null));
    }
}
#end_block

#method_before
private boolean removeInternal(K key, Timestamp timestamp) {
    if (timestamp == null) {
        return false;
    }
    counter.incrementCount();
    final MutableBoolean updated = new MutableBoolean(false);
    items.compute(key, (k, existing) -> {
        if (existing != null && existing.isNewerThan(timestamp)) {
            updated.setFalse();
            return existing;
        } else {
            updated.setTrue();
            // remove from items map
            return null;
        }
    });
    if (updated.isFalse()) {
        return false;
    }
    if (!tombstonesDisabled) {
        Timestamp removedTimestamp = removedItems.get(key);
        if (removedTimestamp == null) {
            return removedItems.putIfAbsent(key, timestamp) == null;
        } else if (timestamp.isNewerThan(removedTimestamp)) {
            return removedItems.replace(key, removedTimestamp, timestamp);
        } else {
            return false;
        }
    }
    return updated.booleanValue();
}
#method_after
private boolean removeInternal(K key, Timestamp timestamp) {
    if (timestamp == null) {
        return false;
    }
    counter.incrementCount();
    final MutableBoolean updated = new MutableBoolean(false);
    items.compute(key, (k, existing) -> {
        if (existing != null && existing.isNewerThan(timestamp)) {
            updated.setFalse();
            return existing;
        } else {
            updated.setTrue();
            // remove from items map
            return null;
        }
    });
    if (updated.isFalse()) {
        return false;
    }
    boolean updatedTombstone = false;
    if (!tombstonesDisabled) {
        Timestamp removedTimestamp = removedItems.get(key);
        if (removedTimestamp == null) {
            // Timestamp removed = removedItems.putIfAbsent(key, timestamp);
            updatedTombstone = (removedItems.putIfAbsent(key, timestamp) == null);
        } else if (timestamp.isNewerThan(removedTimestamp)) {
            updatedTombstone = removedItems.replace(key, removedTimestamp, timestamp);
        }
    }
    if (updated.booleanValue() && persistent) {
        persistentStore.remove(key, timestamp);
    }
    return (!tombstonesDisabled && updatedTombstone) || updated.booleanValue();
}
#end_block

#method_before
@Override
public void run() {
    if (Thread.currentThread().isInterrupted()) {
        log.info("Interrupted, quitting");
        return;
    }
    if (underHighLoad()) {
        return;
    }
    try {
        final NodeId self = clusterService.getLocalNode().id();
        Set<ControllerNode> nodes = clusterService.getNodes();
        List<NodeId> nodeIds = nodes.stream().map(ControllerNode::id).collect(Collectors.toList());
        if (nodeIds.size() == 1 && nodeIds.get(0).equals(self)) {
            log.trace("No other peers in the cluster.");
            return;
        }
        NodeId peer;
        do {
            int idx = RandomUtils.nextInt(0, nodeIds.size());
            peer = nodeIds.get(idx);
        } while (peer.equals(self));
        if (Thread.currentThread().isInterrupted()) {
            log.info("Interrupted, quitting");
            return;
        }
        AntiEntropyAdvertisement<K> ad = createAdvertisement();
        if (!unicastMessage(peer, antiEntropyAdvertisementSubject, ad)) {
            log.debug("Failed to send anti-entropy advertisement to {}", peer);
        }
    } catch (Exception e) {
        // Catch all exceptions to avoid scheduled task being suppressed.
        log.error("Exception thrown while sending advertisement", e);
    }
}
#method_after
@Override
public void run() {
    if (Thread.currentThread().isInterrupted()) {
        log.info("Interrupted, quitting");
        return;
    }
    if (underHighLoad() || destroyed) {
        return;
    }
    try {
        final NodeId self = clusterService.getLocalNode().id();
        Set<ControllerNode> nodes = clusterService.getNodes();
        List<NodeId> nodeIds = nodes.stream().map(ControllerNode::id).collect(Collectors.toList());
        if (nodeIds.size() == 1 && nodeIds.get(0).equals(self)) {
            log.trace("No other peers in the cluster.");
            return;
        }
        NodeId peer;
        do {
            int idx = RandomUtils.nextInt(0, nodeIds.size());
            peer = nodeIds.get(idx);
        } while (peer.equals(self));
        if (Thread.currentThread().isInterrupted()) {
            log.info("Interrupted, quitting");
            return;
        }
        AntiEntropyAdvertisement<K> ad = createAdvertisement();
        if (!unicastMessage(peer, antiEntropyAdvertisementSubject, ad)) {
            log.debug("Failed to send anti-entropy advertisement to {}", peer);
        }
    } catch (Exception e) {
        // Catch all exceptions to avoid scheduled task being suppressed.
        log.error("Exception thrown while sending advertisement", e);
    }
}
#end_block

#method_before
@Override
public void handle(ClusterMessage message) {
    log.debug("Received update event from peer: {}", message.sender());
    Collection<AbstractEntry<K, V>> events = serializer.decode(message.payload());
    try {
        // TODO clean this for loop up
        for (AbstractEntry<K, V> entry : events) {
            final K key = entry.key();
            final V value;
            final Timestamp timestamp = entry.timestamp();
            final EventuallyConsistentMapEvent.Type type;
            if (entry instanceof PutEntry) {
                PutEntry<K, V> putEntry = (PutEntry<K, V>) entry;
                value = putEntry.value();
                type = EventuallyConsistentMapEvent.Type.PUT;
            } else if (entry instanceof RemoveEntry) {
                type = EventuallyConsistentMapEvent.Type.REMOVE;
                value = null;
            } else {
                throw new IllegalStateException("Unknown entry type " + entry.getClass());
            }
            boolean success;
            switch(type) {
                case PUT:
                    success = putInternal(key, value, timestamp);
                    break;
                case REMOVE:
                    success = removeInternal(key, timestamp);
                    break;
                default:
                    success = false;
            }
            if (success) {
                notifyListeners(new EventuallyConsistentMapEvent<>(type, key, value));
            }
        }
    } catch (Exception e) {
        log.warn("Exception thrown handling put", e);
    }
}
#method_after
@Override
public void handle(ClusterMessage message) {
    if (destroyed) {
        return;
    }
    log.debug("Received update event from peer: {}", message.sender());
    Collection<AbstractEntry<K, V>> events = serializer.decode(message.payload());
    try {
        // TODO clean this for loop up
        for (AbstractEntry<K, V> entry : events) {
            final K key = entry.key();
            final V value;
            final Timestamp timestamp = entry.timestamp();
            final EventuallyConsistentMapEvent.Type type;
            if (entry instanceof PutEntry) {
                PutEntry<K, V> putEntry = (PutEntry<K, V>) entry;
                value = putEntry.value();
                type = EventuallyConsistentMapEvent.Type.PUT;
            } else if (entry instanceof RemoveEntry) {
                type = EventuallyConsistentMapEvent.Type.REMOVE;
                value = null;
            } else {
                throw new IllegalStateException("Unknown entry type " + entry.getClass());
            }
            boolean success;
            switch(type) {
                case PUT:
                    success = putInternal(key, value, timestamp);
                    break;
                case REMOVE:
                    success = removeInternal(key, timestamp);
                    break;
                default:
                    success = false;
            }
            if (success) {
                notifyListeners(new EventuallyConsistentMapEvent<>(type, key, value));
            }
        }
    } catch (Exception e) {
        log.warn("Exception thrown handling put", e);
    }
}
#end_block

#method_before
@Override
public Map<String, List<NodeId>> getCandidates() {
    return null;
}
#method_after
@Override
public List<NodeId> getCandidates(String path) {
    return null;
}
#end_block

#method_before
@Override
public Map<String, List<NodeId>> getCandidates() {
    return null;
}
#method_after
@Override
public List<NodeId> getCandidates(String path) {
    return null;
}
#end_block

#method_before
@Override
public Map<String, List<NodeId>> getCandidates() {
    return null;
}
#method_after
@Override
public List<NodeId> getCandidates(String path) {
    return null;
}
#end_block

#method_before
@Activate
public void activate() {
    leaderMap = storageService.<String, NodeId>consistentMapBuilder().withName("onos-topic-leaders").withSerializer(MAP_SERIALIZER).withPartitionsDisabled().build();
    candidateMap = storageService.<String, List<NodeId>>consistentMapBuilder().withName("onos-topic-candidates").withSerializer(MAP_SERIALIZER).withPartitionsDisabled().build();
    localNodeId = clusterService.getLocalNode().id();
    messageHandlingExecutor = Executors.newSingleThreadExecutor(groupedThreads("onos/store/leadership", "message-handler"));
    retryLeaderLockExecutor = Executors.newScheduledThreadPool(4, groupedThreads("onos/store/leadership", "election-thread-%d"));
    deadLockDetectionExecutor = Executors.newSingleThreadScheduledExecutor(groupedThreads("onos/store/leadership", "dead-lock-detector"));
    leadershipStatusBroadcaster = Executors.newSingleThreadScheduledExecutor(groupedThreads("onos/store/leadership", "peer-updater"));
    clusterCommunicator.addSubscriber(LEADERSHIP_EVENT_MESSAGE_SUBJECT, new InternalLeadershipEventListener(), messageHandlingExecutor);
    deadLockDetectionExecutor.scheduleWithFixedDelay(this::purgeStaleLocks, 0, DEADLOCK_DETECTION_INTERVAL_SEC, TimeUnit.SECONDS);
    leadershipStatusBroadcaster.scheduleWithFixedDelay(this::sendLeadershipStatus, 0, LEADERSHIP_STATUS_UPDATE_INTERVAL_SEC, TimeUnit.SECONDS);
    listenerRegistry = new AbstractListenerRegistry<>();
    eventDispatcher.addSink(LeadershipEvent.class, listenerRegistry);
    log.info("Started.");
}
#method_after
@Activate
public void activate() {
    leaderMap = storageService.<String, NodeId>consistentMapBuilder().withName("onos-topic-leaders").withSerializer(SERIALIZER).withPartitionsDisabled().build();
    candidateMap = storageService.<String, List<NodeId>>consistentMapBuilder().withName("onos-topic-candidates").withSerializer(SERIALIZER).withPartitionsDisabled().build();
    localNodeId = clusterService.getLocalNode().id();
    messageHandlingExecutor = Executors.newSingleThreadExecutor(groupedThreads("onos/store/leadership", "message-handler"));
    retryLeaderLockExecutor = Executors.newScheduledThreadPool(4, groupedThreads("onos/store/leadership", "election-thread-%d"));
    deadLockDetectionExecutor = Executors.newSingleThreadScheduledExecutor(groupedThreads("onos/store/leadership", "dead-lock-detector"));
    leadershipStatusBroadcaster = Executors.newSingleThreadScheduledExecutor(groupedThreads("onos/store/leadership", "peer-updater"));
    clusterCommunicator.addSubscriber(LEADERSHIP_EVENT_MESSAGE_SUBJECT, new InternalLeadershipEventListener(), messageHandlingExecutor);
    deadLockDetectionExecutor.scheduleWithFixedDelay(this::purgeStaleLocks, 0, DEADLOCK_DETECTION_INTERVAL_SEC, TimeUnit.SECONDS);
    leadershipStatusBroadcaster.scheduleWithFixedDelay(this::sendLeadershipStatus, 0, LEADERSHIP_STATUS_UPDATE_INTERVAL_SEC, TimeUnit.SECONDS);
    listenerRegistry = new AbstractListenerRegistry<>();
    eventDispatcher.addSink(LeadershipEvent.class, listenerRegistry);
    log.info("Started.");
}
#end_block

#method_before
@Override
public Map<String, List<NodeId>> getCandidates() {
    Map<String, List<NodeId>> candidates = Maps.newHashMap();
    candidateMap.entrySet().forEach(el -> candidates.put(el.getKey(), el.getValue().value()));
    return candidates;
}
#method_after
@Override
public Map<String, List<NodeId>> getCandidates() {
    Map<String, List<NodeId>> candidates = Maps.newHashMap();
    candidateMap.entrySet().forEach(el -> candidates.put(el.getKey(), el.getValue().value()));
    return ImmutableMap.copyOf(candidates);
}
#end_block

#method_before
@Override
public Map<String, List<NodeId>> getCandidates() {
    Map<String, List<NodeId>> candidates = Maps.newHashMap();
    candidateMap.entrySet().forEach(el -> candidates.put(el.getKey(), el.getValue().value()));
    return candidates;
}
#method_after
@Override
public List<NodeId> getCandidates(String path) {
    Versioned<List<NodeId>> candidates = candidateMap.get(path);
    return candidates == null ? ImmutableList.of() : ImmutableList.copyOf(candidates.value());
}
#end_block

#method_before
@Override
public void runForLeadership(String path) {
    log.debug("Running for leadership for topic: {}", path);
    try {
        List<NodeId> candidateList;
        Versioned<List<NodeId>> candidates = candidateMap.get(path);
        if (candidates != null) {
            candidateList = Lists.newArrayList(candidates.value());
            if (!candidateList.contains(localNodeId)) {
                candidateList.add(localNodeId);
                if (!candidateMap.replace(path, candidates.version(), candidateList)) {
                    rerunForLeadership(path);
                    return;
                }
            }
        } else {
            if (!(candidateMap.putIfAbsent(path, ImmutableList.of(localNodeId)) == null)) {
                rerunForLeadership(path);
            }
        }
        log.info("In the leadership race for topic {}", path);
        activeTopics.add(path);
        tryLeaderLock(path);
    } catch (ConsistentMapException e) {
        log.debug("failed to enter topic leader race for {}", path, e);
        rerunForLeadership(path);
    }
}
#method_after
@Override
public void runForLeadership(String path) {
    log.debug("Running for leadership for topic: {}", path);
    try {
        Versioned<List<NodeId>> candidates = candidateMap.get(path);
        if (candidates != null) {
            List<NodeId> candidateList = Lists.newArrayList(candidates.value());
            if (!candidateList.contains(localNodeId)) {
                candidateList.add(localNodeId);
                if (!candidateMap.replace(path, candidates.version(), candidateList)) {
                    rerunForLeadership(path);
                    return;
                }
            }
        } else {
            if (!(candidateMap.putIfAbsent(path, ImmutableList.of(localNodeId)) == null)) {
                rerunForLeadership(path);
                return;
            }
        }
        log.debug("In the leadership race for topic {} with candidates {}", path, candidates);
        activeTopics.add(path);
        tryLeaderLock(path);
    } catch (ConsistentMapException e) {
        log.debug("Failed to enter topic leader race for {}. Retrying.", path, e);
        rerunForLeadership(path);
    }
}
#end_block

#method_before
@Override
public void withdraw(String path) {
    activeTopics.remove(path);
    try {
        Versioned<NodeId> leader = leaderMap.get(path);
        if (Objects.equals(leader.value(), localNodeId)) {
            if (leaderMap.remove(path, leader.version())) {
                log.info("Gave up leadership for {}", path);
                notifyRemovedLeader(path, localNodeId, leader.version(), leader.creationTime());
            }
        }
        // else we are not the current owner, but is a candidate.
        Versioned<List<NodeId>> candidates = candidateMap.get(path);
        List<NodeId> candidateList = Lists.newArrayList(candidates.value());
        candidateList.remove(leader);
        if (!candidateMap.replace(path, candidates.version(), candidateList)) {
            log.warn("Failed to withdraw from candidates list. Will retry");
            retryWithdraw(path);
        }
    } catch (Exception e) {
        log.debug("Failed to verify (and clear) any lock this node might be holding for {}", path, e);
        retryWithdraw(path);
    }
}
#method_after
@Override
public void withdraw(String path) {
    activeTopics.remove(path);
    try {
        Versioned<NodeId> leader = leaderMap.get(path);
        if (leader != null && Objects.equals(leader.value(), localNodeId)) {
            if (leaderMap.remove(path, leader.version())) {
                log.info("Gave up leadership for {}", path);
                notifyRemovedLeader(path, localNodeId, leader.version(), leader.creationTime());
            }
        }
        // else we are not the current leader, can still be a candidate.
        Versioned<List<NodeId>> candidates = candidateMap.get(path);
        List<NodeId> candidateList = candidates != null ? Lists.newArrayList(candidates.value()) : Lists.newArrayList();
        if (!candidateList.remove(localNodeId)) {
            return;
        }
        boolean success = candidateList.isEmpty() ? candidateMap.remove(path, candidates.version()) : candidateMap.replace(path, candidates.version(), candidateList);
        if (!success) {
            log.warn("Failed to withdraw from candidates list. Will retry");
            retryWithdraw(path);
        }
    } catch (Exception e) {
        log.debug("Failed to verify (and clear) any lock this node might be holding for {}", path, e);
        retryWithdraw(path);
    }
}
#end_block

#method_before
private void tryLeaderLock(String path) {
    if (!activeTopics.contains(path)) {
        return;
    }
    Versioned<List<NodeId>> candidates = candidateMap.get(path);
    if (candidates != null) {
        List<NodeId> activeNodes = candidates.value().stream().filter(n -> clusterService.getState(n) == State.ACTIVE).collect(Collectors.toList());
        if (localNodeId.equals(activeNodes.get(0))) {
            leaderLockAttempt(path, candidates.value());
        } else {
            retryLock(path);
        }
    } else {
        throw new IllegalStateException("should not be here");
    }
}
#method_after
private void tryLeaderLock(String path) {
    if (!activeTopics.contains(path)) {
        return;
    }
    Versioned<List<NodeId>> candidates = candidateMap.get(path);
    if (candidates != null) {
        List<NodeId> activeNodes = candidates.value().stream().filter(n -> clusterService.getState(n) == State.ACTIVE).collect(Collectors.toList());
        if (localNodeId.equals(activeNodes.get(LEADER_CANDIDATE_POS))) {
            leaderLockAttempt(path, candidates.value());
        } else {
            retryLock(path);
        }
    } else {
        throw new IllegalStateException("should not be here");
    }
}
#end_block

#method_before
private void leaderLockAttempt(String path, List<NodeId> candidates) {
    try {
        Versioned<NodeId> currentLeader = leaderMap.get(path);
        if (currentLeader != null) {
            if (localNodeId.equals(currentLeader.value())) {
                log.info("Already has leadership for {}", path);
                notifyNewLeader(path, localNodeId, candidates, currentLeader.version(), currentLeader.creationTime());
            } else {
                // someone else has leadership. will retry after sometime.
                retryLock(path);
            }
        } else {
            if (leaderMap.putIfAbsent(path, localNodeId) == null) {
                log.info("Assumed leadership for {}", path);
                // do a get again to get the version (epoch)
                Versioned<NodeId> newLeader = leaderMap.get(path);
                notifyNewLeader(path, localNodeId, candidates, newLeader.version(), newLeader.creationTime());
            } else {
                // someone beat us to it.
                retryLock(path);
            }
        }
    } catch (Exception e) {
        log.debug("Attempt to acquire leadership lock for topic {} failed", path, e);
        retryLock(path);
    }
}
#method_after
private void leaderLockAttempt(String path, List<NodeId> candidates) {
    try {
        Versioned<NodeId> currentLeader = leaderMap.get(path);
        if (currentLeader != null) {
            if (localNodeId.equals(currentLeader.value())) {
                log.info("Already has leadership for {}", path);
                // FIXME: candidates can get out of sync.
                notifyNewLeader(path, localNodeId, candidates, currentLeader.version(), currentLeader.creationTime());
            } else {
                // someone else has leadership. will retry after sometime.
                retryLock(path);
            }
        } else {
            if (leaderMap.putIfAbsent(path, localNodeId) == null) {
                log.info("Assumed leadership for {}", path);
                // do a get again to get the version (epoch)
                Versioned<NodeId> newLeader = leaderMap.get(path);
                // FIXME: candidates can get out of sync
                notifyNewLeader(path, localNodeId, candidates, newLeader.version(), newLeader.creationTime());
            } else {
                // someone beat us to it.
                retryLock(path);
            }
        }
    } catch (Exception e) {
        log.debug("Attempt to acquire leadership lock for topic {} failed", path, e);
        retryLock(path);
    }
}
#end_block

#method_before
private void notifyNewLeader(String path, NodeId leader, List<NodeId> candidates, long epoch, long electedTime) {
    Leadership newLeadership = new Leadership(path, leader, candidates, epoch, electedTime);
    boolean updatedLeader = false;
    log.info("candidates for new Leadership {}", candidates);
    synchronized (leaderBoard) {
        Leadership currentLeader = leaderBoard.get(path);
        if (currentLeader == null || currentLeader.epoch() < epoch) {
            log.info("updating leaderboard with new {}", newLeadership);
            leaderBoard.put(path, newLeadership);
            updatedLeader = true;
        }
    }
    if (updatedLeader) {
        LeadershipEvent event = new LeadershipEvent(LeadershipEvent.Type.LEADER_ELECTED, newLeadership);
        notifyPeers(event);
    }
}
#method_after
private void notifyNewLeader(String path, NodeId leader, List<NodeId> candidates, long epoch, long electedTime) {
    Leadership newLeadership = new Leadership(path, leader, candidates, epoch, electedTime);
    boolean updatedLeader = false;
    log.debug("candidates for new Leadership {}", candidates);
    synchronized (leaderBoard) {
        Leadership currentLeader = leaderBoard.get(path);
        if (currentLeader == null || currentLeader.epoch() < epoch) {
            log.debug("updating leaderboard with new {}", newLeadership);
            leaderBoard.put(path, newLeadership);
            updatedLeader = true;
        }
    }
    if (updatedLeader) {
        LeadershipEvent event = new LeadershipEvent(LeadershipEvent.Type.LEADER_ELECTED, newLeadership);
        notifyPeers(event);
    }
}
#end_block

#method_before
private void notifyRemovedLeader(String path, NodeId leader, long epoch, long electedTime) {
    Versioned<List<NodeId>> candidates = candidateMap.get(path);
    Leadership oldLeadership = new Leadership(path, leader, candidates.value(), epoch, electedTime);
    boolean updatedLeader = false;
    synchronized (leaderBoard) {
        Leadership currentLeader = leaderBoard.get(path);
        if (currentLeader != null && currentLeader.epoch() == oldLeadership.epoch()) {
            leaderBoard.remove(path);
            // node no longer in leaderBoard or leaderMap - now remove from candidateMap
            List<NodeId> candidateList = Lists.newArrayList(candidates.value());
            candidateList.remove(leader);
            if (!candidateMap.replace(path, candidates.version(), candidateList)) {
                log.warn("Failed to remove leader from candidates list");
            }
            updatedLeader = true;
        }
    }
    if (updatedLeader) {
        LeadershipEvent event = new LeadershipEvent(LeadershipEvent.Type.LEADER_BOOTED, oldLeadership);
        eventDispatcher.post(event);
        clusterCommunicator.broadcast(new ClusterMessage(clusterService.getLocalNode().id(), LEADERSHIP_EVENT_MESSAGE_SUBJECT, SERIALIZER.encode(event)));
    }
}
#method_after
private void notifyRemovedLeader(String path, NodeId leader, long epoch, long electedTime) {
    Versioned<List<NodeId>> candidates = candidateMap.get(path);
    Leadership oldLeadership = new Leadership(path, leader, candidates.value(), epoch, electedTime);
    boolean updatedLeader = false;
    synchronized (leaderBoard) {
        Leadership currentLeader = leaderBoard.get(path);
        if (currentLeader != null && currentLeader.epoch() == oldLeadership.epoch()) {
            leaderBoard.remove(path);
            updatedLeader = true;
        }
    }
    if (updatedLeader) {
        LeadershipEvent event = new LeadershipEvent(LeadershipEvent.Type.LEADER_BOOTED, oldLeadership);
        eventDispatcher.post(event);
        clusterCommunicator.broadcast(new ClusterMessage(clusterService.getLocalNode().id(), LEADERSHIP_EVENT_MESSAGE_SUBJECT, SERIALIZER.encode(event)));
    }
}
#end_block

#method_before
private void purgeStaleLocks() {
    try {
        Set<Entry<String, Versioned<NodeId>>> entries = leaderMap.entrySet();
        entries.forEach(entry -> {
            String path = entry.getKey();
            NodeId nodeId = entry.getValue().value();
            long epoch = entry.getValue().version();
            long creationTime = entry.getValue().creationTime();
            if (clusterService.getState(nodeId) == ControllerNode.State.INACTIVE) {
                log.info("Lock for {} is held by {} which is currently inactive", path, nodeId);
                try {
                    if (leaderMap.remove(path, epoch)) {
                        log.info("Purged stale lock held by {} for {}", nodeId, path);
                        notifyRemovedLeader(path, nodeId, epoch, creationTime);
                    }
                } catch (Exception e) {
                    log.warn("Failed to purge stale lock held by {} for {}", nodeId, path, e);
                }
            }
            if (localNodeId.equals(nodeId) && !activeTopics.contains(path)) {
                log.debug("Lock for {} is held by {} when it's not running for leadership.", path, nodeId);
                try {
                    if (leaderMap.remove(path, epoch)) {
                        log.info("Purged stale lock held by {} for {}", nodeId, path);
                        notifyRemovedLeader(path, nodeId, epoch, creationTime);
                    }
                } catch (Exception e) {
                    log.warn("Failed to purge stale lock held by {} for {}", nodeId, path, e);
                }
            }
        });
    } catch (Exception e) {
        log.debug("Failed cleaning up stale locks", e);
    }
}
#method_after
private void purgeStaleLocks() {
    try {
        leaderMap.entrySet().stream().filter(e -> clusterService.getState(e.getValue().value()) == ControllerNode.State.INACTIVE).filter(e -> localNodeId.equals(e.getValue().value()) && !activeTopics.contains(e.getKey())).forEach(entry -> {
            String path = entry.getKey();
            NodeId nodeId = entry.getValue().value();
            long epoch = entry.getValue().version();
            long creationTime = entry.getValue().creationTime();
            try {
                if (leaderMap.remove(path, epoch)) {
                    log.info("Purged stale lock held by {} for {}", nodeId, path);
                    notifyRemovedLeader(path, nodeId, epoch, creationTime);
                }
            } catch (Exception e) {
                log.warn("Failed to purge stale lock held by {} for {}", nodeId, path, e);
            }
        });
    } catch (Exception e) {
        log.debug("Failed cleaning up stale locks", e);
    }
}
#end_block

#method_before
@Modified
public void modified(ComponentContext context) {
    Dictionary<?, ?> properties = context.getProperties();
    Integer sharedThreadPoolSizeConfig = getIntegerProperty(properties, "sharedThreadPoolSize");
    if (sharedThreadPoolSizeConfig == null) {
        log.info("Shared Pool Size is not configured, default value is {}", sharedThreadPoolSize);
    } else {
        if (sharedThreadPoolSizeConfig > 0) {
            sharedThreadPoolSize = sharedThreadPoolSizeConfig;
            SharedExecutors.setNumberOfThreads(sharedThreadPoolSize);
            log.info("Configured. Shared Pool Size is configured to {}", sharedThreadPoolSize);
        } else {
            log.warn("Shared Pool Size size must be greater than 0");
        }
    }
}
#method_after
@Modified
public void modified(ComponentContext context) {
    Dictionary<?, ?> properties = context.getProperties();
    Integer sharedThreadPoolSizeConfig = getIntegerProperty(properties, "sharedThreadPoolSize");
    if (sharedThreadPoolSizeConfig == null) {
        log.info("Shared Pool Size is not configured, default value is {}", sharedThreadPoolSize);
    } else {
        if (sharedThreadPoolSizeConfig > 0) {
            sharedThreadPoolSize = sharedThreadPoolSizeConfig;
            SharedExecutors.setPoolSize(sharedThreadPoolSize);
            log.info("Configured. Shared Pool Size is configured to {}", sharedThreadPoolSize);
        } else {
            log.warn("Shared Pool Size size must be greater than 0");
        }
    }
}
#end_block

#method_before
@Override
public void start(FibListener listener) {
    this.fibComponent = checkNotNull(listener);
    this.hostService.addListener(hostListener);
    bgpService.start(new InternalRouteListener());
    bgpUpdatesExecutor.execute(new Runnable() {

        @Override
        public void run() {
            doUpdatesThread();
        }
    });
}
#method_after
@Override
public void start() {
    this.hostService.addListener(hostListener);
    bgpService.start(new InternalRouteListener());
    bgpUpdatesExecutor.execute(new Runnable() {

        @Override
        public void run() {
            doUpdatesThread();
        }
    });
}
#end_block

#method_before
private void update(Collection<RouteUpdate> routeUpdates) {
    try {
        routeUpdatesQueue.put(routeUpdates);
    } catch (InterruptedException e) {
        log.debug("Interrupted while putting on routeUpdatesQueue", e);
        Thread.currentThread().interrupt();
    }
}
#method_after
private void update(Collection<RouteUpdate> routeUpdates) {
    try {
        routeUpdatesQueue.put(routeUpdates);
    } catch (InterruptedException e) {
        log.error("Interrupted while putting on routeUpdatesQueue", e);
        Thread.currentThread().interrupt();
    }
}
#end_block

#method_before
private void doUpdatesThread() {
    boolean interrupted = false;
    try {
        while (!interrupted) {
            try {
                Collection<RouteUpdate> routeUpdates = routeUpdatesQueue.take();
                processRouteUpdates(routeUpdates);
            } catch (InterruptedException e) {
                log.debug("Interrupted while taking from updates queue", e);
                interrupted = true;
            } catch (Exception e) {
                log.debug("exception", e);
            }
        }
    } finally {
        if (interrupted) {
            Thread.currentThread().interrupt();
        }
    }
}
#method_after
private void doUpdatesThread() {
    boolean interrupted = false;
    try {
        while (!interrupted) {
            try {
                Collection<RouteUpdate> routeUpdates = routeUpdatesQueue.take();
                processRouteUpdates(routeUpdates);
            } catch (InterruptedException e) {
                log.error("Interrupted while taking from updates queue", e);
                interrupted = true;
            } catch (Exception e) {
                log.error("exception", e);
            }
        }
    } finally {
        if (interrupted) {
            Thread.currentThread().interrupt();
        }
    }
}
#end_block

#method_before
public Collection<RouteEntry> getRoutes4() {
    Iterator<KeyValuePair<RouteEntry>> it = ribTable4.getKeyValuePairsForKeysStartingWith("").iterator();
    List<RouteEntry> routes = new LinkedList<>();
    while (it.hasNext()) {
        KeyValuePair<RouteEntry> entry = it.next();
        routes.add(entry.getValue());
    }
    return routes;
}
#method_after
@Override
public Collection<RouteEntry> getRoutes4() {
    Iterator<KeyValuePair<RouteEntry>> it = ribTable4.getKeyValuePairsForKeysStartingWith("").iterator();
    List<RouteEntry> routes = new LinkedList<>();
    while (it.hasNext()) {
        KeyValuePair<RouteEntry> entry = it.next();
        routes.add(entry.getValue());
    }
    return routes;
}
#end_block

#method_before
public Collection<RouteEntry> getRoutes6() {
    Iterator<KeyValuePair<RouteEntry>> it = ribTable6.getKeyValuePairsForKeysStartingWith("").iterator();
    List<RouteEntry> routes = new LinkedList<>();
    while (it.hasNext()) {
        KeyValuePair<RouteEntry> entry = it.next();
        routes.add(entry.getValue());
    }
    return routes;
}
#method_after
@Override
public Collection<RouteEntry> getRoutes6() {
    Iterator<KeyValuePair<RouteEntry>> it = ribTable6.getKeyValuePairsForKeysStartingWith("").iterator();
    List<RouteEntry> routes = new LinkedList<>();
    while (it.hasNext()) {
        KeyValuePair<RouteEntry> entry = it.next();
        routes.add(entry.getValue());
    }
    return routes;
}
#end_block

#method_before
RouteEntry findRibRoute(IpPrefix prefix) {
    String binaryString = RouteEntry.createBinaryString(prefix);
    if (prefix.isIp4()) {
        // IPv4
        return ribTable4.getValueForExactKey(binaryString);
    }
    // IPv6
    return ribTable6.getValueForExactKey(binaryString);
}
#method_after
RouteEntry findRibRoute(IpPrefix prefix) {
    String binaryString = createBinaryString(prefix);
    if (prefix.isIp4()) {
        // IPv4
        return ribTable4.getValueForExactKey(binaryString);
    }
    // IPv6
    return ribTable6.getValueForExactKey(binaryString);
}
#end_block

#method_before
void addRibRoute(RouteEntry routeEntry) {
    if (routeEntry.isIp4()) {
        // IPv4
        ribTable4.put(RouteEntry.createBinaryString(routeEntry.prefix()), routeEntry);
    } else {
        // IPv6
        ribTable6.put(RouteEntry.createBinaryString(routeEntry.prefix()), routeEntry);
    }
}
#method_after
void addRibRoute(RouteEntry routeEntry) {
    if (routeEntry.isIp4()) {
        // IPv4
        ribTable4.put(createBinaryString(routeEntry.prefix()), routeEntry);
    } else {
        // IPv6
        ribTable6.put(createBinaryString(routeEntry.prefix()), routeEntry);
    }
}
#end_block

#method_before
boolean removeRibRoute(IpPrefix prefix) {
    if (prefix.isIp4()) {
        // IPv4
        return ribTable4.remove(RouteEntry.createBinaryString(prefix));
    }
    // IPv6
    return ribTable6.remove(RouteEntry.createBinaryString(prefix));
}
#method_after
boolean removeRibRoute(IpPrefix prefix) {
    if (prefix.isIp4()) {
        // IPv4
        return ribTable4.remove(createBinaryString(prefix));
    }
    // IPv6
    return ribTable6.remove(createBinaryString(prefix));
}
#end_block

#method_before
private FibEntry processRouteAdd(RouteEntry routeEntry, Collection<IpPrefix> withdrawPrefixes) {
    log.debug("Processing route add: {}", routeEntry);
    // Find the old next-hop if we are updating an old route entry
    IpAddress oldNextHop = null;
    RouteEntry oldRouteEntry = findRibRoute(routeEntry.prefix());
    if (oldRouteEntry != null) {
        oldNextHop = oldRouteEntry.nextHop();
    }
    // Add the new route to the RIB
    addRibRoute(routeEntry);
    if (oldNextHop != null) {
        if (oldNextHop.equals(routeEntry.nextHop())) {
            // No change
            return null;
        }
        // 
        // Update an existing nexthop for the prefix.
        // We need to remove the old flows for this prefix from the
        // switches before the new flows are added.
        // 
        withdrawPrefixes.add(routeEntry.prefix());
    }
    if (routeEntry.nextHop().isZero()) {
        // Route originated by SDN domain
        // We don't handle these at the moment
        log.debug("Own route {} to {}", routeEntry.prefix(), routeEntry.nextHop());
        return null;
    }
    // 
    // Find the MAC address of next hop router for this route entry.
    // If the MAC address can not be found in ARP cache, then this prefix
    // will be put in routesWaitingOnArp queue. Otherwise, generate
    // a new route intent.
    // 
    // Monitor the IP address for updates of the MAC address
    hostService.startMonitoringIp(routeEntry.nextHop());
    // Check if we know the MAC address of the next hop
    MacAddress nextHopMacAddress = ip2Mac.get(routeEntry.nextHop());
    if (nextHopMacAddress == null) {
        Set<Host> hosts = hostService.getHostsByIp(routeEntry.nextHop());
        if (!hosts.isEmpty()) {
            nextHopMacAddress = hosts.iterator().next().mac();
        }
        if (nextHopMacAddress != null) {
            ip2Mac.put(routeEntry.nextHop(), nextHopMacAddress);
        }
    }
    if (nextHopMacAddress == null) {
        routesWaitingOnArp.put(routeEntry.nextHop(), routeEntry);
        return null;
    }
    return new FibEntry(routeEntry.prefix(), routeEntry.nextHop(), nextHopMacAddress);
}
#method_after
private FibEntry processRouteAdd(RouteEntry routeEntry, Collection<IpPrefix> withdrawPrefixes) {
    log.debug("Processing route add: {}", routeEntry);
    // Find the old next-hop if we are updating an old route entry
    IpAddress oldNextHop = null;
    RouteEntry oldRouteEntry = findRibRoute(routeEntry.prefix());
    if (oldRouteEntry != null) {
        oldNextHop = oldRouteEntry.nextHop();
    }
    // Add the new route to the RIB
    addRibRoute(routeEntry);
    if (oldNextHop != null) {
        if (oldNextHop.equals(routeEntry.nextHop())) {
            // No change
            return null;
        }
        // 
        // Update an existing nexthop for the prefix.
        // We need to remove the old flows for this prefix from the
        // switches before the new flows are added.
        // 
        withdrawPrefixes.add(routeEntry.prefix());
    }
    if (routingConfigurationService.isIpPrefixLocal(routeEntry.prefix())) {
        // Route originated by local SDN domain
        // We don't handle these here, reactive routing APP will handle
        // these
        log.debug("Own route {} to {}", routeEntry.prefix(), routeEntry.nextHop());
        return null;
    }
    // 
    // Find the MAC address of next hop router for this route entry.
    // If the MAC address can not be found in ARP cache, then this prefix
    // will be put in routesWaitingOnArp queue. Otherwise, generate
    // a new route intent.
    // 
    // Monitor the IP address for updates of the MAC address
    hostService.startMonitoringIp(routeEntry.nextHop());
    // Check if we know the MAC address of the next hop
    MacAddress nextHopMacAddress = ip2Mac.get(routeEntry.nextHop());
    if (nextHopMacAddress == null) {
        Set<Host> hosts = hostService.getHostsByIp(routeEntry.nextHop());
        if (!hosts.isEmpty()) {
            nextHopMacAddress = hosts.iterator().next().mac();
        }
        if (nextHopMacAddress != null) {
            ip2Mac.put(routeEntry.nextHop(), nextHopMacAddress);
        }
    }
    if (nextHopMacAddress == null) {
        routesWaitingOnArp.put(routeEntry.nextHop(), routeEntry);
        return null;
    }
    return new FibEntry(routeEntry.prefix(), routeEntry.nextHop(), nextHopMacAddress);
}
#end_block

#method_before
@Initializer
@Override
public void init(StateContext<DatabaseState<String, byte[]>> context) {
    tables = context.get("tables");
    if (tables == null) {
        tables = new HashMap<>();
        context.put("tables", tables);
    }
    locks = context.get("locks");
    if (locks == null) {
        locks = new HashMap<>();
        context.put("locks", locks);
    }
    nextVersion = context.get("nextVersion");
    if (nextVersion == null) {
        nextVersion = new Long(0);
        context.put("nextVersion", nextVersion);
    }
}
#method_after
@Initializer
@Override
public void init(StateContext<DatabaseState<String, byte[]>> context) {
    tables = context.get("tables");
    if (tables == null) {
        tables = Maps.newConcurrentMap();
        context.put("tables", tables);
    }
    locks = context.get("locks");
    if (locks == null) {
        locks = Maps.newConcurrentMap();
        context.put("locks", locks);
    }
    nextVersion = context.get("nextVersion");
    if (nextVersion == null) {
        nextVersion = new Long(0);
        context.put("nextVersion", nextVersion);
    }
}
#end_block

#method_before
@Override
public Result<Versioned<byte[]>> put(String tableName, String key, byte[] value) {
    return isAnotherUpdateInProgress(tableName, key) ? new Result<>(null, Status.LOCKED) : new Result<>(getTableMap(tableName).put(key, new Versioned<>(value, ++nextVersion)), Status.OK);
}
#method_after
@Override
public Result<Versioned<byte[]>> put(String tableName, String key, byte[] value) {
    return isLockedForUpdates(tableName, key) ? Result.locked() : Result.ok(getTableMap(tableName).put(key, new Versioned<>(value, ++nextVersion)));
}
#end_block

#method_before
@Override
public Result<Versioned<byte[]>> remove(String tableName, String key) {
    return isAnotherUpdateInProgress(tableName, key) ? new Result<>(null, Status.LOCKED) : new Result<>(getTableMap(tableName).remove(key), Status.OK);
}
#method_after
@Override
public Result<Versioned<byte[]>> remove(String tableName, String key) {
    return isLockedForUpdates(tableName, key) ? Result.locked() : Result.ok(getTableMap(tableName).remove(key));
}
#end_block

#method_before
@Override
public Result<Void> clear(String tableName) {
    if (isAnotherUpdateInProgress(tableName)) {
        return new Result<>(null, Status.LOCKED);
    }
    getTableMap(tableName).clear();
    return new Result<>(null, Status.OK);
}
#method_after
@Override
public Result<Void> clear(String tableName) {
    if (areTransactionsInProgress(tableName)) {
        return Result.locked();
    }
    getTableMap(tableName).clear();
    return Result.ok(null);
}
#end_block

#method_before
@Override
public Result<Versioned<byte[]>> putIfAbsent(String tableName, String key, byte[] value) {
    if (isAnotherUpdateInProgress(tableName, key)) {
        return new Result<>(null, Status.LOCKED);
    }
    Versioned<byte[]> existingValue = get(tableName, key);
    Versioned<byte[]> currentValue = existingValue != null ? existingValue : put(tableName, key, value).value();
    return new Result<>(currentValue, Status.OK);
}
#method_after
@Override
public Result<Versioned<byte[]>> putIfAbsent(String tableName, String key, byte[] value) {
    if (isLockedForUpdates(tableName, key)) {
        return Result.locked();
    }
    Versioned<byte[]> existingValue = get(tableName, key);
    Versioned<byte[]> currentValue = existingValue != null ? existingValue : put(tableName, key, value).value();
    return Result.ok(currentValue);
}
#end_block

#method_before
@Override
public Result<Boolean> remove(String tableName, String key, byte[] value) {
    if (isAnotherUpdateInProgress(tableName, key)) {
        return new Result<>(false, Status.LOCKED);
    }
    Versioned<byte[]> existing = get(tableName, key);
    if (existing != null && Arrays.equals(existing.value(), value)) {
        getTableMap(tableName).remove(key);
        return new Result<>(true, Status.OK);
    }
    return new Result<>(false, Status.OK);
}
#method_after
@Override
public Result<Boolean> remove(String tableName, String key, byte[] value) {
    if (isLockedForUpdates(tableName, key)) {
        return Result.locked();
    }
    Versioned<byte[]> existing = get(tableName, key);
    if (existing != null && Arrays.equals(existing.value(), value)) {
        getTableMap(tableName).remove(key);
        return Result.ok(true);
    }
    return Result.ok(false);
}
#end_block

#method_before
@Override
public Result<Boolean> remove(String tableName, String key, long version) {
    if (isAnotherUpdateInProgress(tableName, key)) {
        return new Result<>(false, Status.LOCKED);
    }
    Versioned<byte[]> existing = get(tableName, key);
    if (existing != null && existing.version() == version) {
        remove(tableName, key);
        return new Result<>(true, Status.OK);
    }
    return new Result<>(false, Status.OK);
}
#method_after
@Override
public Result<Boolean> remove(String tableName, String key, long version) {
    if (isLockedForUpdates(tableName, key)) {
        return Result.locked();
    }
    Versioned<byte[]> existing = get(tableName, key);
    if (existing != null && existing.version() == version) {
        remove(tableName, key);
        return Result.ok(true);
    }
    return Result.ok(false);
}
#end_block

#method_before
@Override
public Result<Boolean> replace(String tableName, String key, byte[] oldValue, byte[] newValue) {
    if (isAnotherUpdateInProgress(tableName, key)) {
        return new Result<>(false, Status.LOCKED);
    }
    Versioned<byte[]> existing = get(tableName, key);
    if (existing != null && Arrays.equals(existing.value(), oldValue)) {
        put(tableName, key, newValue);
        return new Result<>(true, Status.OK);
    }
    return new Result<>(false, Status.OK);
}
#method_after
@Override
public Result<Boolean> replace(String tableName, String key, byte[] oldValue, byte[] newValue) {
    if (isLockedForUpdates(tableName, key)) {
        return Result.locked();
    }
    Versioned<byte[]> existing = get(tableName, key);
    if (existing != null && Arrays.equals(existing.value(), oldValue)) {
        put(tableName, key, newValue);
        return Result.ok(true);
    }
    return Result.ok(false);
}
#end_block

#method_before
@Override
public Result<Boolean> replace(String tableName, String key, long oldVersion, byte[] newValue) {
    Versioned<byte[]> existing = get(tableName, key);
    if (existing != null && existing.version() == oldVersion) {
        put(tableName, key, newValue);
        return new Result<>(true, Status.OK);
    }
    return new Result<>(false, Status.OK);
}
#method_after
@Override
public Result<Boolean> replace(String tableName, String key, long oldVersion, byte[] newValue) {
    if (isLockedForUpdates(tableName, key)) {
        return Result.locked();
    }
    Versioned<byte[]> existing = get(tableName, key);
    if (existing != null && existing.version() == oldVersion) {
        put(tableName, key, newValue);
        return Result.ok(true);
    }
    return Result.ok(false);
}
#end_block

#method_before
@Override
public Result<Boolean> prepareAndCommit(List<DatabaseUpdate> updates) {
    Result<Boolean> prepareResult = prepare(updates);
    if (prepareResult.status() == Status.OK && prepareResult.value()) {
        commit(updates);
    }
    return prepareResult;
}
#method_after
@Override
public boolean prepareAndCommit(Transaction transaction) {
    if (prepare(transaction)) {
        return commit(transaction);
    }
    return false;
}
#end_block

#method_before
@Override
public Result<Boolean> prepare(List<DatabaseUpdate> updates) {
    if (updates.stream().anyMatch(update -> isAnotherUpdateInProgress(update.tableName(), update.key()))) {
        return new Result<>(false, Status.LOCKED);
    }
    if (updates.stream().allMatch(this::isUpdatePossible)) {
        updates.stream().forEach(this::doProvisionalUpdate);
        return new Result<>(true, Status.OK);
    }
    return new Result<>(false, Status.OK);
}
#method_after
@Override
public boolean prepare(Transaction transaction) {
    if (transaction.updates().stream().anyMatch(update -> isLockedByAnotherTransaction(update.tableName(), update.key(), transaction.id()))) {
        return false;
    }
    if (transaction.updates().stream().allMatch(this::isUpdatePossible)) {
        transaction.updates().forEach(update -> doProvisionalUpdate(update, transaction.id()));
        return true;
    }
    return false;
}
#end_block

#method_before
@Override
public Result<Void> commit(List<DatabaseUpdate> updates) {
    updates.forEach(this::commitProvisionalUpdate);
    return new Result<>(null, Status.OK);
}
#method_after
@Override
public boolean commit(Transaction transaction) {
    transaction.updates().forEach(update -> commitProvisionalUpdate(update, transaction.id()));
    return true;
}
#end_block

#method_before
@Override
public Result<Void> rollback(List<DatabaseUpdate> updates) {
    updates.forEach(this::undoProvisionalUpdate);
    return new Result<>(null, Status.OK);
}
#method_after
@Override
public boolean rollback(Transaction transaction) {
    transaction.updates().forEach(update -> undoProvisionalUpdate(update, transaction.id()));
    return true;
}
#end_block

#method_before
private Map<String, Versioned<byte[]>> getTableMap(String tableName) {
    return tables.computeIfAbsent(tableName, name -> new HashMap<>());
}
#method_after
private Map<String, Versioned<byte[]>> getTableMap(String tableName) {
    return tables.computeIfAbsent(tableName, name -> Maps.newConcurrentMap());
}
#end_block

#method_before
private Map<String, byte[]> getLockMap(String tableName) {
    return locks.computeIfAbsent(tableName, name -> new HashMap<>());
}
#method_after
private Map<String, Pair<Long, byte[]>> getLockMap(String tableName) {
    return locks.computeIfAbsent(tableName, name -> Maps.newConcurrentMap());
}
#end_block

#method_before
private void doProvisionalUpdate(DatabaseUpdate update) {
    Map<String, byte[]> lockMap = getLockMap(update.tableName());
    switch(update.type()) {
        case PUT:
        case PUT_IF_ABSENT:
        case PUT_IF_VERSION_MATCH:
        case PUT_IF_VALUE_MATCH:
            lockMap.put(update.key(), update.value());
            break;
        case REMOVE:
        case REMOVE_IF_VERSION_MATCH:
        case REMOVE_IF_VALUE_MATCH:
            lockMap.put(update.key(), null);
            break;
        default:
            throw new IllegalStateException("Unsupported type: " + update.type());
    }
}
#method_after
private void doProvisionalUpdate(DatabaseUpdate update, long transactionId) {
    Map<String, Pair<Long, byte[]>> lockMap = getLockMap(update.tableName());
    switch(update.type()) {
        case PUT:
        case PUT_IF_ABSENT:
        case PUT_IF_VERSION_MATCH:
        case PUT_IF_VALUE_MATCH:
            lockMap.put(update.key(), Pair.of(transactionId, update.value()));
            break;
        case REMOVE:
        case REMOVE_IF_VERSION_MATCH:
        case REMOVE_IF_VALUE_MATCH:
            lockMap.put(update.key(), null);
            break;
        default:
            throw new IllegalStateException("Unsupported type: " + update.type());
    }
}
#end_block

#method_before
private void commitProvisionalUpdate(DatabaseUpdate update) {
    String tableName = update.tableName();
    String key = update.key();
    Type type = update.type();
    switch(type) {
        case PUT:
        case PUT_IF_ABSENT:
        case PUT_IF_VERSION_MATCH:
        case PUT_IF_VALUE_MATCH:
            put(tableName, key, getLockMap(tableName).remove(key));
            break;
        case REMOVE:
        case REMOVE_IF_VERSION_MATCH:
        case REMOVE_IF_VALUE_MATCH:
            remove(tableName, key);
            break;
        default:
            throw new IllegalStateException("Unsupported type: " + update.type());
    }
}
#method_after
private void commitProvisionalUpdate(DatabaseUpdate update, long transactionId) {
    String tableName = update.tableName();
    String key = update.key();
    Type type = update.type();
    Pair<Long, byte[]> provisionalUpdate = getLockMap(tableName).get(key);
    if (Objects.equal(transactionId, provisionalUpdate.getLeft())) {
        getLockMap(tableName).remove(key);
    } else {
        return;
    }
    switch(type) {
        case PUT:
        case PUT_IF_ABSENT:
        case PUT_IF_VERSION_MATCH:
        case PUT_IF_VALUE_MATCH:
            put(tableName, key, provisionalUpdate.getRight());
            break;
        case REMOVE:
        case REMOVE_IF_VERSION_MATCH:
        case REMOVE_IF_VALUE_MATCH:
            remove(tableName, key);
            break;
        default:
            break;
    }
}
#end_block

#method_before
private void undoProvisionalUpdate(DatabaseUpdate update) {
    getLockMap(update.tableName()).remove(update.key());
}
#method_after
private void undoProvisionalUpdate(DatabaseUpdate update, long transactionId) {
    String tableName = update.tableName();
    String key = update.key();
    Pair<Long, byte[]> provisionalUpdate = getLockMap(tableName).get(key);
    if (provisionalUpdate == null) {
        return;
    }
    if (Objects.equal(transactionId, provisionalUpdate.getLeft())) {
        getLockMap(tableName).remove(key);
    }
}
#end_block

#method_before
@Override
public CompletableFuture<Result<Void>> clear(String tableName) {
    AtomicBoolean isLocked = new AtomicBoolean(false);
    checkState(isOpen.get(), DB_NOT_OPEN);
    return CompletableFuture.allOf(partitions.stream().map(p -> p.clear(tableName).thenApply(v -> isLocked.compareAndSet(false, v.status() == Status.LOCKED))).toArray(CompletableFuture[]::new)).thenApply(v -> new Result<>(null, isLocked.get() ? Status.LOCKED : Status.OK));
}
#method_after
@Override
public CompletableFuture<Result<Void>> clear(String tableName) {
    AtomicBoolean isLocked = new AtomicBoolean(false);
    checkState(isOpen.get(), DB_NOT_OPEN);
    return CompletableFuture.allOf(partitions.stream().map(p -> p.clear(tableName).thenApply(v -> isLocked.compareAndSet(false, Result.Status.LOCKED == v.status()))).toArray(CompletableFuture[]::new)).thenApply(v -> isLocked.get() ? Result.locked() : Result.ok(null));
}
#end_block

#method_before
@Override
public CompletableFuture<Result<Boolean>> prepareAndCommit(List<DatabaseUpdate> updates) {
    Map<Database, List<DatabaseUpdate>> perPartitionUpdates = groupUpdatesByPartition(updates);
    if (perPartitionUpdates.size() == 1) {
        Entry<Database, List<DatabaseUpdate>> entry = perPartitionUpdates.entrySet().iterator().next();
        return entry.getKey().prepareAndCommit(entry.getValue());
    }
    AtomicBoolean status = new AtomicBoolean(true);
    return CompletableFuture.allOf(perPartitionUpdates.entrySet().stream().map(entry -> entry.getKey().prepareAndCommit(entry.getValue()).thenApply(v -> status.compareAndSet(true, v.value()))).toArray(CompletableFuture[]::new)).thenApply(v -> new Result<>(status.get(), Status.OK));
}
#method_after
@Override
public CompletableFuture<Boolean> prepareAndCommit(Transaction transaction) {
    Map<Database, Transaction> subTransactions = createSubTransactions(transaction);
    if (subTransactions.isEmpty()) {
        return CompletableFuture.completedFuture(true);
    } else if (subTransactions.size() == 1) {
        Entry<Database, Transaction> entry = subTransactions.entrySet().iterator().next();
        return entry.getKey().prepareAndCommit(entry.getValue());
    } else {
        return new TransactionManager(this).execute(transaction);
    }
}
#end_block

#method_before
@Override
public CompletableFuture<Result<Boolean>> prepare(List<DatabaseUpdate> updates) {
    Map<Database, List<DatabaseUpdate>> perPartitionUpdates = groupUpdatesByPartition(updates);
    AtomicBoolean status = new AtomicBoolean(true);
    return CompletableFuture.allOf(perPartitionUpdates.entrySet().stream().map(entry -> entry.getKey().prepare(entry.getValue()).thenApply(v -> status.compareAndSet(true, v.value()))).toArray(CompletableFuture[]::new)).thenApply(v -> new Result<>(status.get(), Status.OK));
}
#method_after
@Override
public CompletableFuture<Boolean> prepare(Transaction transaction) {
    Map<Database, Transaction> subTransactions = createSubTransactions(transaction);
    AtomicBoolean status = new AtomicBoolean(true);
    return CompletableFuture.allOf(subTransactions.entrySet().stream().map(entry -> entry.getKey().prepare(entry.getValue()).thenApply(v -> status.compareAndSet(true, v))).toArray(CompletableFuture[]::new)).thenApply(v -> status.get());
}
#end_block

#method_before
@Override
public CompletableFuture<Result<Void>> commit(List<DatabaseUpdate> updates) {
    Map<Database, List<DatabaseUpdate>> perPartitionUpdates = groupUpdatesByPartition(updates);
    return CompletableFuture.allOf(perPartitionUpdates.entrySet().stream().map(entry -> entry.getKey().commit(entry.getValue())).toArray(CompletableFuture[]::new)).thenApply(v -> new Result<>(null, Status.OK));
}
#method_after
@Override
public CompletableFuture<Boolean> commit(Transaction transaction) {
    Map<Database, Transaction> subTransactions = createSubTransactions(transaction);
    return CompletableFuture.allOf(subTransactions.entrySet().stream().map(entry -> entry.getKey().commit(entry.getValue())).toArray(CompletableFuture[]::new)).thenApply(v -> true);
}
#end_block

#method_before
@Override
public CompletableFuture<Result<Void>> rollback(List<DatabaseUpdate> updates) {
    Map<Database, List<DatabaseUpdate>> perPartitionUpdates = groupUpdatesByPartition(updates);
    return CompletableFuture.allOf(perPartitionUpdates.entrySet().stream().map(entry -> entry.getKey().rollback(entry.getValue())).toArray(CompletableFuture[]::new)).thenApply(v -> new Result<>(null, Status.OK));
}
#method_after
@Override
public CompletableFuture<Boolean> rollback(Transaction transaction) {
    Map<Database, Transaction> subTransactions = createSubTransactions(transaction);
    return CompletableFuture.allOf(subTransactions.entrySet().stream().map(entry -> entry.getKey().rollback(entry.getValue())).toArray(CompletableFuture[]::new)).thenApply(v -> true);
}
#end_block

#method_before
@Activate
public void activate() {
    // load database configuration
    File file = new File(CONFIG_DIR, PARTITION_DEFINITION_FILE);
    log.info("Loading database definition: {}", file.getAbsolutePath());
    Map<String, Set<NodeInfo>> partitionMap;
    try {
        DatabaseDefinitionStore databaseDef = new DatabaseDefinitionStore(file);
        partitionMap = databaseDef.read().getPartitions();
    } catch (IOException e) {
        throw new IllegalStateException("Failed to load database config", e);
    }
    String[] activeNodeUris = partitionMap.values().stream().reduce((s1, s2) -> Sets.union(s1, s2)).get().stream().map(this::nodeToUri).toArray(String[]::new);
    String localNodeUri = nodeToUri(NodeInfo.of(clusterService.getLocalNode()));
    ClusterConfig clusterConfig = new ClusterConfig().withProtocol(newNettyProtocol()).withElectionTimeout(RAFT_ELECTION_TIMEOUT).withHeartbeatInterval(RAFT_HEARTBEAT_TIMEOUT).withMembers(activeNodeUris).withLocalMember(localNodeUri);
    CopycatConfig copycatConfig = new CopycatConfig().withName("onos").withClusterConfig(clusterConfig).withDefaultSerializer(new DatabaseSerializer()).withDefaultExecutor(Executors.newSingleThreadExecutor(new NamedThreadFactory("copycat-coordinator-%d")));
    coordinator = new DefaultClusterCoordinator(copycatConfig.resolve());
    DatabaseConfig inMemoryDatabaseConfig = newDatabaseConfig(BASE_PARTITION_NAME, newInMemoryLog(), activeNodeUris);
    inMemoryDatabase = coordinator.getResource(inMemoryDatabaseConfig.getName(), inMemoryDatabaseConfig.resolve(clusterConfig).withSerializer(copycatConfig.getDefaultSerializer()).withDefaultExecutor(copycatConfig.getDefaultExecutor()));
    List<Database> partitions = partitionMap.entrySet().stream().map(entry -> {
        String[] replicas = entry.getValue().stream().map(this::nodeToUri).toArray(String[]::new);
        return newDatabaseConfig(entry.getKey(), newPersistentLog(), replicas);
    }).map(config -> {
        Database db = coordinator.getResource(config.getName(), config.resolve(clusterConfig).withSerializer(copycatConfig.getDefaultSerializer()).withDefaultExecutor(copycatConfig.getDefaultExecutor()));
        return db;
    }).collect(Collectors.toList());
    partitionedDatabase = new PartitionedDatabase("onos-store", partitions);
    CountDownLatch latch = new CountDownLatch(1);
    coordinator.open().thenCompose(v -> CompletableFuture.allOf(inMemoryDatabase.open(), partitionedDatabase.open()).whenComplete((db, error) -> {
        if (error != null) {
            log.warn("Failed to create databases.", error);
        } else {
            latch.countDown();
            log.info("Successfully created databases.");
        }
    }));
    try {
        if (!latch.await(DATABASE_STARTUP_TIMEOUT_SEC, TimeUnit.SECONDS)) {
            log.warn("Timed out waiting for database to initialize.");
        }
    } catch (InterruptedException e) {
        Thread.currentThread().interrupt();
        log.warn("Failed to complete database initialization.");
    }
    log.info("Started");
}
#method_after
@Activate
public void activate() {
    // load database configuration
    File databaseDefFile = new File(PARTITION_DEFINITION_FILE);
    log.info("Loading database definition: {}", databaseDefFile.getAbsolutePath());
    Map<String, Set<NodeInfo>> partitionMap;
    try {
        DatabaseDefinitionStore databaseDefStore = new DatabaseDefinitionStore(databaseDefFile);
        if (!databaseDefFile.exists()) {
            createDefaultDatabaseDefinition(databaseDefStore);
        }
        partitionMap = databaseDefStore.read().getPartitions();
    } catch (IOException e) {
        throw new IllegalStateException("Failed to load database config", e);
    }
    String[] activeNodeUris = partitionMap.values().stream().reduce((s1, s2) -> Sets.union(s1, s2)).get().stream().map(this::nodeToUri).toArray(String[]::new);
    String localNodeUri = nodeToUri(NodeInfo.of(clusterService.getLocalNode()));
    ClusterConfig clusterConfig = new ClusterConfig().withProtocol(newNettyProtocol()).withElectionTimeout(electionTimeoutMillis(activeNodeUris)).withHeartbeatInterval(heartbeatTimeoutMillis(activeNodeUris)).withMembers(activeNodeUris).withLocalMember(localNodeUri);
    CopycatConfig copycatConfig = new CopycatConfig().withName("onos").withClusterConfig(clusterConfig).withDefaultSerializer(new DatabaseSerializer()).withDefaultExecutor(Executors.newSingleThreadExecutor(new NamedThreadFactory("copycat-coordinator-%d")));
    coordinator = new DefaultClusterCoordinator(copycatConfig.resolve());
    DatabaseConfig inMemoryDatabaseConfig = newDatabaseConfig(BASE_PARTITION_NAME, newInMemoryLog(), activeNodeUris);
    inMemoryDatabase = coordinator.getResource(inMemoryDatabaseConfig.getName(), inMemoryDatabaseConfig.resolve(clusterConfig).withSerializer(copycatConfig.getDefaultSerializer()).withDefaultExecutor(copycatConfig.getDefaultExecutor()));
    List<Database> partitions = partitionMap.entrySet().stream().map(entry -> {
        String[] replicas = entry.getValue().stream().map(this::nodeToUri).toArray(String[]::new);
        return newDatabaseConfig(entry.getKey(), newPersistentLog(), replicas);
    }).map(config -> {
        Database db = coordinator.getResource(config.getName(), config.resolve(clusterConfig).withSerializer(copycatConfig.getDefaultSerializer()).withDefaultExecutor(copycatConfig.getDefaultExecutor()));
        return db;
    }).collect(Collectors.toList());
    partitionedDatabase = new PartitionedDatabase("onos-store", partitions);
    CountDownLatch latch = new CountDownLatch(1);
    coordinator.open().thenCompose(v -> CompletableFuture.allOf(inMemoryDatabase.open(), partitionedDatabase.open()).whenComplete((db, error) -> {
        if (error != null) {
            log.warn("Failed to create databases.", error);
        } else {
            latch.countDown();
            log.info("Successfully created databases.");
        }
    }));
    try {
        if (!latch.await(DATABASE_STARTUP_TIMEOUT_SEC, TimeUnit.SECONDS)) {
            log.warn("Timed out waiting for database to initialize.");
        }
    } catch (InterruptedException e) {
        Thread.currentThread().interrupt();
        log.warn("Failed to complete database initialization.");
    }
    transactionManager = new TransactionManager(partitionedDatabase);
    log.info("Started");
}
#end_block

#method_before
@Override
public TransactionContext createTransactionContext() {
    return new DefaultTransactionContext(partitionedDatabase);
}
#method_after
@Override
public TransactionContext createTransactionContext() {
    return new DefaultTransactionContext(partitionedDatabase, transactionIdGenerator.getNewId());
}
#end_block

#method_before
private DatabaseConfig newDatabaseConfig(String name, Log log, String[] replicas) {
    return new DatabaseConfig().withName(name).withElectionTimeout(RAFT_ELECTION_TIMEOUT).withHeartbeatInterval(RAFT_HEARTBEAT_TIMEOUT).withConsistency(Consistency.STRONG).withLog(log).withDefaultSerializer(new DatabaseSerializer()).withReplicas(replicas);
}
#method_after
private DatabaseConfig newDatabaseConfig(String name, Log log, String[] replicas) {
    return new DatabaseConfig().withName(name).withElectionTimeout(electionTimeoutMillis(replicas)).withHeartbeatInterval(heartbeatTimeoutMillis(replicas)).withConsistency(Consistency.STRONG).withLog(log).withDefaultSerializer(new DatabaseSerializer()).withReplicas(replicas);
}
#end_block

#method_before
private <T> T unwrapResult(Result<T> result) {
    if (result.status() == Status.LOCKED) {
        throw new ConsistentMapException.ConcurrentModification();
    } else if (result.status() == Status.OK) {
        return result.value();
    } else {
        throw new IllegalStateException("Unknown status: " + result.status());
    }
}
#method_after
private <T> T unwrapResult(Result<T> result) {
    if (result.status() == Result.Status.LOCKED) {
        throw new ConsistentMapException.ConcurrentModification();
    } else if (result.success()) {
        return result.value();
    } else {
        throw new IllegalStateException("Must not be here");
    }
}
#end_block

#method_before
@Override
public CompletableFuture<Result<Boolean>> prepareAndCommit(List<DatabaseUpdate> updates) {
    return checkOpen(() -> proxy.prepareAndCommit(updates));
}
#method_after
@Override
public CompletableFuture<Boolean> prepareAndCommit(Transaction transaction) {
    return checkOpen(() -> proxy.prepareAndCommit(transaction));
}
#end_block

#method_before
@Override
public CompletableFuture<Result<Boolean>> prepare(List<DatabaseUpdate> updates) {
    return checkOpen(() -> proxy.prepare(updates));
}
#method_after
@Override
public CompletableFuture<Boolean> prepare(Transaction transaction) {
    return checkOpen(() -> proxy.prepare(transaction));
}
#end_block

#method_before
@Override
public CompletableFuture<Result<Void>> commit(List<DatabaseUpdate> updates) {
    return checkOpen(() -> proxy.commit(updates));
}
#method_after
@Override
public CompletableFuture<Boolean> commit(Transaction transaction) {
    return checkOpen(() -> proxy.commit(transaction));
}
#end_block

#method_before
@Override
public CompletableFuture<Result<Void>> rollback(List<DatabaseUpdate> updates) {
    return checkOpen(() -> proxy.rollback(updates));
}
#method_after
@Override
public CompletableFuture<Boolean> rollback(Transaction transaction) {
    return checkOpen(() -> proxy.rollback(transaction));
}
#end_block

#method_before
public CompletableFuture<Void> execute(Transaction transaction) {
    if (transaction.state() == Transaction.State.COMMITTED || transaction.state() == Transaction.State.ROLLEDBACK) {
        transactions.remove(transaction.id());
        CompletableFuture<Void> result = new CompletableFuture<>();
        result.complete(null);
        return result;
    } else if (transaction.state() == Transaction.State.COMMITTING) {
        return commit(transaction);
    } else if (transaction.state() == Transaction.State.ROLLINGBACK) {
        return rollback(transaction);
    } else {
        return prepare(transaction).thenCompose(v -> {
            return v ? commit(transaction) : rollback(transaction);
        });
    }
}
#method_after
public CompletableFuture<Boolean> execute(Transaction transaction) {
    // clean up if this transaction in already in a terminal state.
    if (transaction.state() == Transaction.State.COMMITTED || transaction.state() == Transaction.State.ROLLEDBACK) {
        return transactions.remove(transaction.id()).thenApply(v -> true);
    } else if (transaction.state() == Transaction.State.COMMITTING) {
        return commit(transaction);
    } else if (transaction.state() == Transaction.State.ROLLINGBACK) {
        return rollback(transaction);
    } else {
        return prepare(transaction).thenCompose(v -> v ? commit(transaction) : rollback(transaction));
    }
}
#end_block

#method_before
private CompletableFuture<Boolean> prepare(Transaction tx) {
    CompletableFuture<Boolean> result = new CompletableFuture<>();
    try {
        return database.prepare(tx.payload()).whenComplete((r, e) -> {
            if (e == null && r.status() == Status.OK) {
                transactions.put(tx.id(), tx.transition(Transaction.State.PREPARED));
            }
        }).thenApply(Result::value);
    } catch (Exception e) {
        result.completeExceptionally(e);
    }
    return result;
}
#method_after
private CompletableFuture<Boolean> prepare(Transaction transaction) {
    return transactions.put(transaction.id(), transaction).thenCompose(v -> database.prepare(transaction)).thenCompose(status -> transactions.put(transaction.id(), transaction.transition(status ? State.COMMITTING : State.ROLLINGBACK)).thenApply(v -> status));
}
#end_block

#method_before
private CompletableFuture<Void> commit(Transaction tx) {
    CompletableFuture<Void> result = new CompletableFuture<>();
    try {
        transactions.put(tx.id(), tx.transition(Transaction.State.COMMITTING));
        return database.commit(tx.payload()).whenComplete((r, e) -> {
            if (e == null) {
                transactions.put(tx.id(), tx.transition(Transaction.State.COMMITTED));
            }
        }).thenApply(Result::value);
    } catch (Exception e) {
        result.completeExceptionally(e);
    }
    return result;
}
#method_after
private CompletableFuture<Boolean> commit(Transaction transaction) {
    return database.commit(transaction).thenCompose(v -> transactions.put(transaction.id(), transaction.transition(Transaction.State.COMMITTED))).thenApply(v -> true);
}
#end_block

#method_before
private CompletableFuture<Void> rollback(Transaction tx) {
    CompletableFuture<Void> result = new CompletableFuture<>();
    try {
        transactions.put(tx.id(), tx.transition(Transaction.State.ROLLINGBACK));
        return database.rollback(tx.payload()).whenComplete((r, e) -> {
            if (e != null) {
                transactions.put(tx.id(), tx.transition(Transaction.State.ROLLEDBACK));
            }
        }).thenApply(Result::value);
    } catch (Exception e) {
        result.completeExceptionally(e);
    }
    return result;
}
#method_after
private CompletableFuture<Boolean> rollback(Transaction transaction) {
    return database.rollback(transaction).thenCompose(v -> transactions.put(transaction.id(), transaction.transition(Transaction.State.ROLLEDBACK))).thenApply(v -> true);
}
#end_block

#method_before
@Override
public void begin() {
    isOpen = true;
}
#method_after
@Override
public void begin() {
    checkState(!isOpen, "Transaction Context is already open");
    isOpen = true;
}
#end_block

#method_before
@SuppressWarnings("unchecked")
@Override
public void commit() {
    checkState(isOpen, TX_NOT_OPEN_ERROR);
    List<DatabaseUpdate> allUpdates = Lists.newLinkedList();
    try {
        txMaps.values().stream().forEach(m -> {
            allUpdates.addAll(m.prepareDatabaseUpdates());
        });
        Result<Boolean> result = complete(database.prepareAndCommit(allUpdates));
        if (!result.value()) {
            throw new TransactionException.OptimisticConcurrencyFailure();
        }
        if (result.status() == Status.LOCKED) {
            throw new TransactionException.ConcurrentModification();
        }
    } finally {
        isOpen = false;
    }
}
#method_after
@SuppressWarnings("unchecked")
@Override
public void commit() {
    checkState(isOpen, TX_NOT_OPEN_ERROR);
    try {
        List<DatabaseUpdate> updates = Lists.newLinkedList();
        txMaps.values().forEach(m -> {
            updates.addAll(m.prepareDatabaseUpdates());
        });
        database.prepareAndCommit(new DefaultTransaction(transactionId, updates));
    } catch (Exception e) {
        abort();
        throw new TransactionException(e);
    } finally {
        isOpen = false;
    }
}
#end_block

#method_before
@Override
public V put(K key, V value) {
    checkState(txContext.isOpen(), TX_CLOSED_ERROR);
    checkNotNull(value, ERROR_NULL_VALUE);
    V latest = get(key);
    writeCache.put(key, value);
    return latest;
}
#method_after
@Override
public V put(K key, V value) {
    checkState(txContext.isOpen(), TX_CLOSED_ERROR);
    checkNotNull(value, ERROR_NULL_VALUE);
    V latest = get(key);
    writeCache.put(key, value);
    deleteSet.remove(key);
    return latest;
}
#end_block

#method_before
public static String getSiteLocalAddress() {
    try {
        for (NetworkInterface nif : list(getNetworkInterfaces())) {
            for (InetAddress address : list(nif.getInetAddresses())) {
                if (address.getAddress()[0] == SITE_LOCAL_BYTE) {
                    return IpAddress.valueOf(address).toString();
                }
            }
        }
        return IpAddress.valueOf(InetAddress.getLoopbackAddress()).toString();
    } catch (SocketException e) {
        log.error("Unable to get network interfaces", e);
    }
    return null;
}
#method_after
public static String getSiteLocalAddress() {
    try {
        String ipPrefix = System.getenv(ONOS_NIC);
        for (NetworkInterface nif : list(getNetworkInterfaces())) {
            for (InetAddress address : list(nif.getInetAddresses())) {
                IpAddress ip = IpAddress.valueOf(address);
                if (ipPrefix == null && address.isSiteLocalAddress() || ipPrefix != null && matchInterface(ip.toString(), ipPrefix)) {
                    return ip.toString();
                }
            }
        }
    } catch (SocketException e) {
        log.error("Unable to get network interfaces", e);
    }
    return IpAddress.valueOf(InetAddress.getLoopbackAddress()).toString();
}
#end_block

#method_before
@Override
public ControllerNode decode(ObjectNode json, CodecContext context) {
    checkNotNull(json, "JSON cannot be null");
    String ip = json.path("ip").asText();
    return new DefaultControllerNode(new NodeId(json.path("id").asText(ip)), IpAddress.valueOf(ip), json.path("tcpPort").asInt(9876));
}
#method_after
@Override
public ControllerNode decode(ObjectNode json, CodecContext context) {
    checkNotNull(json, "JSON cannot be null");
    String ip = json.path("ip").asText();
    return new DefaultControllerNode(new NodeId(json.path("id").asText(ip)), IpAddress.valueOf(ip), json.path("tcpPort").asInt(DEFAULT_PORT));
}
#end_block

#method_before
@Activate
public void activate() {
    // load database configuration
    File file = new File(PARTITION_DEFINITION_FILE);
    log.info("Loading database definition: {}", file.getAbsolutePath());
    Map<String, Set<NodeInfo>> partitionMap;
    try {
        DatabaseDefinitionStore databaseDefStore = new DatabaseDefinitionStore(file);
        if (!file.exists()) {
            createDefaultDatabaseDefinition(databaseDefStore);
        }
        partitionMap = databaseDefStore.read().getPartitions();
    } catch (IOException e) {
        throw new IllegalStateException("Failed to load database config", e);
    }
    String[] activeNodeUris = partitionMap.values().stream().reduce((s1, s2) -> Sets.union(s1, s2)).get().stream().map(this::nodeToUri).toArray(String[]::new);
    String localNodeUri = nodeToUri(NodeInfo.of(clusterService.getLocalNode()));
    ClusterConfig clusterConfig = new ClusterConfig().withProtocol(newNettyProtocol()).withElectionTimeout(RAFT_ELECTION_TIMEOUT).withHeartbeatInterval(RAFT_HEARTBEAT_TIMEOUT).withMembers(activeNodeUris).withLocalMember(localNodeUri);
    CopycatConfig copycatConfig = new CopycatConfig().withName("onos").withClusterConfig(clusterConfig).withDefaultSerializer(new DatabaseSerializer()).withDefaultExecutor(Executors.newSingleThreadExecutor(new NamedThreadFactory("copycat-coordinator-%d")));
    coordinator = new DefaultClusterCoordinator(copycatConfig.resolve());
    DatabaseConfig inMemoryDatabaseConfig = newDatabaseConfig(BASE_PARTITION_NAME, newInMemoryLog(), activeNodeUris);
    inMemoryDatabase = coordinator.getResource(inMemoryDatabaseConfig.getName(), inMemoryDatabaseConfig.resolve(clusterConfig).withSerializer(copycatConfig.getDefaultSerializer()).withDefaultExecutor(copycatConfig.getDefaultExecutor()));
    List<Database> partitions = partitionMap.entrySet().stream().map(entry -> {
        String[] replicas = entry.getValue().stream().map(this::nodeToUri).toArray(String[]::new);
        return newDatabaseConfig(entry.getKey(), newPersistentLog(), replicas);
    }).map(config -> {
        Database db = coordinator.getResource(config.getName(), config.resolve(clusterConfig).withSerializer(copycatConfig.getDefaultSerializer()).withDefaultExecutor(copycatConfig.getDefaultExecutor()));
        return db;
    }).collect(Collectors.toList());
    partitionedDatabase = new PartitionedDatabase("onos-store", partitions);
    CountDownLatch latch = new CountDownLatch(1);
    coordinator.open().thenCompose(v -> CompletableFuture.allOf(inMemoryDatabase.open(), partitionedDatabase.open()).whenComplete((db, error) -> {
        if (error != null) {
            log.warn("Failed to create databases.", error);
        } else {
            latch.countDown();
            log.info("Successfully created databases.");
        }
    }));
    try {
        if (!latch.await(DATABASE_STARTUP_TIMEOUT_SEC, TimeUnit.SECONDS)) {
            log.warn("Timed out waiting for database to initialize.");
        }
    } catch (InterruptedException e) {
        Thread.currentThread().interrupt();
        log.warn("Failed to complete database initialization.");
    }
    log.info("Started");
}
#method_after
@Activate
public void activate() {
    // load database configuration
    File databaseDefFile = new File(PARTITION_DEFINITION_FILE);
    log.info("Loading database definition: {}", databaseDefFile.getAbsolutePath());
    Map<String, Set<NodeInfo>> partitionMap;
    try {
        DatabaseDefinitionStore databaseDefStore = new DatabaseDefinitionStore(databaseDefFile);
        if (!databaseDefFile.exists()) {
            createDefaultDatabaseDefinition(databaseDefStore);
        }
        partitionMap = databaseDefStore.read().getPartitions();
    } catch (IOException e) {
        throw new IllegalStateException("Failed to load database config", e);
    }
    String[] activeNodeUris = partitionMap.values().stream().reduce((s1, s2) -> Sets.union(s1, s2)).get().stream().map(this::nodeToUri).toArray(String[]::new);
    String localNodeUri = nodeToUri(NodeInfo.of(clusterService.getLocalNode()));
    ClusterConfig clusterConfig = new ClusterConfig().withProtocol(newNettyProtocol()).withElectionTimeout(RAFT_ELECTION_TIMEOUT).withHeartbeatInterval(RAFT_HEARTBEAT_TIMEOUT).withMembers(activeNodeUris).withLocalMember(localNodeUri);
    CopycatConfig copycatConfig = new CopycatConfig().withName("onos").withClusterConfig(clusterConfig).withDefaultSerializer(new DatabaseSerializer()).withDefaultExecutor(Executors.newSingleThreadExecutor(new NamedThreadFactory("copycat-coordinator-%d")));
    coordinator = new DefaultClusterCoordinator(copycatConfig.resolve());
    DatabaseConfig inMemoryDatabaseConfig = newDatabaseConfig(BASE_PARTITION_NAME, newInMemoryLog(), activeNodeUris);
    inMemoryDatabase = coordinator.getResource(inMemoryDatabaseConfig.getName(), inMemoryDatabaseConfig.resolve(clusterConfig).withSerializer(copycatConfig.getDefaultSerializer()).withDefaultExecutor(copycatConfig.getDefaultExecutor()));
    List<Database> partitions = partitionMap.entrySet().stream().map(entry -> {
        String[] replicas = entry.getValue().stream().map(this::nodeToUri).toArray(String[]::new);
        return newDatabaseConfig(entry.getKey(), newPersistentLog(), replicas);
    }).map(config -> {
        Database db = coordinator.getResource(config.getName(), config.resolve(clusterConfig).withSerializer(copycatConfig.getDefaultSerializer()).withDefaultExecutor(copycatConfig.getDefaultExecutor()));
        return db;
    }).collect(Collectors.toList());
    partitionedDatabase = new PartitionedDatabase("onos-store", partitions);
    CountDownLatch latch = new CountDownLatch(1);
    coordinator.open().thenCompose(v -> CompletableFuture.allOf(inMemoryDatabase.open(), partitionedDatabase.open()).whenComplete((db, error) -> {
        if (error != null) {
            log.warn("Failed to create databases.", error);
        } else {
            latch.countDown();
            log.info("Successfully created databases.");
        }
    }));
    try {
        if (!latch.await(DATABASE_STARTUP_TIMEOUT_SEC, TimeUnit.SECONDS)) {
            log.warn("Timed out waiting for database to initialize.");
        }
    } catch (InterruptedException e) {
        Thread.currentThread().interrupt();
        log.warn("Failed to complete database initialization.");
    }
    log.info("Started");
}
#end_block

#method_before
private void createDefaultDatabaseDefinition(DatabaseDefinitionStore store) {
    // Assumes IPv4 is returned.
    String ip = DistributedClusterStore.getSiteLocalAddress();
    NodeInfo node = NodeInfo.from(ip, ip, DistributedClusterStore.DEFAULT_PORT);
    try {
        store.write(DatabaseDefinition.from(ImmutableSet.of(node)));
    } catch (IOException e) {
        log.warn("Unable to write default cluster definition", e);
    }
}
#method_after
private void createDefaultDatabaseDefinition(DatabaseDefinitionStore store) {
    // Assumes IPv4 is returned.
    String ip = DistributedClusterStore.getSiteLocalAddress();
    NodeInfo node = NodeInfo.from(ip, ip, COPYCAT_TCP_PORT);
    try {
        store.write(DatabaseDefinition.from(ImmutableSet.of(node)));
    } catch (IOException e) {
        log.warn("Unable to write default cluster definition", e);
    }
}
#end_block

#method_before
private void buildConnectivityDetails(ConnectivityIntent intent) {
    if (!intent.selector().criteria().isEmpty()) {
        details.append("selector=").append(intent.selector().criteria());
    }
    if (!intent.treatment().allInstructions().isEmpty()) {
        details.append("treatment=").append(intent.treatment().allInstructions());
    }
    if (intent.constraints() != null && !intent.constraints().isEmpty()) {
        details.append("constraints=").append(intent.constraints());
    }
}
#method_after
private void buildConnectivityDetails(ConnectivityIntent intent) {
    Set<Criterion> criteria = intent.selector().criteria();
    List<Instruction> instructions = intent.treatment().allInstructions();
    List<Constraint> constraints = intent.constraints();
    if (!criteria.isEmpty()) {
        details.append("selector=").append(criteria);
    }
    if (!instructions.isEmpty()) {
        details.append("treatment=").append(instructions);
    }
    if (constraints != null && !constraints.isEmpty()) {
        details.append("constraints=").append(constraints);
    }
}
#end_block

#method_before
private String formatDetails(Intent intent) {
    if (intent instanceof ConnectivityIntent) {
        buildConnectivityDetails((ConnectivityIntent) intent);
    }
    if (intent instanceof HostToHostIntent) {
        buildHostToHostDetails((HostToHostIntent) intent);
    } else if (intent instanceof PointToPointIntent) {
        buildPointToPointDetails((PointToPointIntent) intent);
    } else if (intent instanceof MultiPointToSinglePointIntent) {
        buildMPToSPDetails((MultiPointToSinglePointIntent) intent);
    } else if (intent instanceof SinglePointToMultiPointIntent) {
        buildSPToMPDetails((SinglePointToMultiPointIntent) intent);
    } else if (intent instanceof PathIntent) {
        buildPathDetails((PathIntent) intent);
    } else if (intent instanceof LinkCollectionIntent) {
        buildLinkConnectionDetails((LinkCollectionIntent) intent);
    }
    if (details.length() == 0) {
        details.append("No details for this intent");
    } else {
        details.insert(0, "Details: ");
    }
    return details.toString();
}
#method_after
private String formatDetails(Intent intent) {
    if (intent instanceof ConnectivityIntent) {
        buildConnectivityDetails((ConnectivityIntent) intent);
    }
    if (intent instanceof HostToHostIntent) {
        buildHostToHostDetails((HostToHostIntent) intent);
    } else if (intent instanceof PointToPointIntent) {
        buildPointToPointDetails((PointToPointIntent) intent);
    } else if (intent instanceof MultiPointToSinglePointIntent) {
        buildMPToSPDetails((MultiPointToSinglePointIntent) intent);
    } else if (intent instanceof SinglePointToMultiPointIntent) {
        buildSPToMPDetails((SinglePointToMultiPointIntent) intent);
    } else if (intent instanceof PathIntent) {
        buildPathDetails((PathIntent) intent);
    } else if (intent instanceof LinkCollectionIntent) {
        buildLinkConnectionDetails((LinkCollectionIntent) intent);
    }
    if (details.length() == 0) {
        details.append("(No details for this intent)");
    } else {
        details.insert(0, "Details: ");
    }
    return details.toString();
}
#end_block

#method_before
private String formatResources(Intent i) {
    return (i.resources().isEmpty() ? "No resources for this intent." : "Resources: " + i.resources().toString());
}
#method_after
private String formatResources(Intent intent) {
    return (intent.resources().isEmpty() ? "(No resources for this intent)" : "Resources: " + intent.resources());
}
#end_block

#method_before
@Override
protected void execute() {
    ApplicationAdminService service = get(ApplicationAdminService.class);
    if (command.equals(INSTALL)) {
        print("Not supported via CLI yet.");
    } else {
        for (String appName : name) {
            ApplicationId appId = service.getId(appName);
            if (appId == null) {
                print("No such application: %s", appName);
                return;
            }
            if (command.equals(UNINSTALL)) {
                service.uninstall(appId);
            } else if (command.equals(ACTIVATE)) {
                service.activate(appId);
            } else if (command.equals(DEACTIVATE)) {
                service.deactivate(appId);
            } else {
                print("Unsupported command: %s", command);
            }
        }
    }
}
#method_after
@Override
protected void execute() {
    ApplicationAdminService service = get(ApplicationAdminService.class);
    if (command.equals(INSTALL)) {
        print("Not supported via CLI yet.");
    } else {
        for (String name : names) {
            ApplicationId appId = service.getId(name);
            if (appId == null) {
                print("No such application: %s", name);
                return;
            }
            if (command.equals(UNINSTALL)) {
                service.uninstall(appId);
            } else if (command.equals(ACTIVATE)) {
                service.activate(appId);
            } else if (command.equals(DEACTIVATE)) {
                service.deactivate(appId);
            } else {
                print("Unsupported command: %s", command);
            }
        }
    }
}
#end_block

#method_before
@Override
public int compareTo(Timestamp o) {
    if (!(o instanceof MockTimestamp)) {
        return -1;
    }
    MockTimestamp that = (MockTimestamp) o;
    return (this.value > that.value ? -1 : (this.value == that.value ? 0 : 1));
}
#method_after
@Override
public int compareTo(Timestamp o) {
    if (!(o instanceof MockTimestamp)) {
        return -1;
    }
    MockTimestamp that = (MockTimestamp) o;
    return this.value - that.value;
}
#end_block

#method_before
@Activate
public void activate() {
    KryoNamespace.Builder intentSerializer = KryoNamespace.newBuilder().register(KryoNamespaces.API).register(IntentData.class).register(MultiValuedTimestamp.class).register(WallClockTimestamp.class);
    currentMap = storageService.<Key, IntentData>eventuallyConsistentMapBuilder().name("intent-current").serializer(intentSerializer).clockService(new IntentDataLogicalClockManager<>()).peerUpdateFunction((key, intentData) -> getPeerNodes(key, intentData)).build();
    pendingMap = storageService.<Key, IntentData>eventuallyConsistentMapBuilder().name("intent-pending").serializer(intentSerializer).clockService(new IntentDataClockManager<>()).peerUpdateFunction((key, intentData) -> getPeerNodes(key, intentData)).build();
    currentMap.addListener(new InternalCurrentListener());
    pendingMap.addListener(new InternalPendingListener());
    log.info("Started");
}
#method_after
@Activate
public void activate() {
    KryoNamespace.Builder intentSerializer = KryoNamespace.newBuilder().register(KryoNamespaces.API).register(IntentData.class).register(MultiValuedTimestamp.class).register(WallClockTimestamp.class);
    currentMap = storageService.<Key, IntentData>eventuallyConsistentMapBuilder().withName("intent-current").withSerializer(intentSerializer).withClockService(new IntentDataLogicalClockManager<>()).withPeerUpdateFunction((key, intentData) -> getPeerNodes(key, intentData)).build();
    pendingMap = storageService.<Key, IntentData>eventuallyConsistentMapBuilder().withName("intent-pending").withSerializer(intentSerializer).withClockService(new IntentDataClockManager<>()).withPeerUpdateFunction((key, intentData) -> getPeerNodes(key, intentData)).build();
    currentMap.addListener(new InternalCurrentListener());
    pendingMap.addListener(new InternalPendingListener());
    log.info("Started");
}
#end_block

#method_before
@Override
public void write(IntentData newData) {
    checkNotNull(newData);
    IntentData currentData = currentMap.get(newData.key());
    if (isUpdateAcceptable(currentData, newData)) {
        // this always succeeds
        if (newData.state() == PURGE_REQ) {
            currentMap.remove(newData.key(), newData);
        } else {
            currentMap.put(newData.key(), new IntentData(newData));
        }
        // if current.put succeeded
        pendingMap.remove(newData.key(), newData);
    }
}
#method_after
@Override
public void write(IntentData newData) {
    checkNotNull(newData);
    IntentData currentData = currentMap.get(newData.key());
    if (IntentData.isUpdateAcceptable(currentData, newData)) {
        // this always succeeds
        if (newData.state() == PURGE_REQ) {
            currentMap.remove(newData.key(), newData);
        } else {
            currentMap.put(newData.key(), new IntentData(newData));
        }
        // if current.put succeeded
        pendingMap.remove(newData.key(), newData);
    }
}
#end_block

#method_before
@Activate
public void activate() {
    KryoNamespace.Builder serializer = KryoNamespace.newBuilder().register(KryoNamespaces.API).register(MultiValuedTimestamp.class).register(InternalState.class);
    executor = Executors.newSingleThreadScheduledExecutor(groupedThreads("onos/app", "store"));
    messageHandlingExecutor = Executors.newSingleThreadExecutor(groupedThreads("onos/store/app", "message-handler"));
    clusterCommunicator.addSubscriber(APP_BITS_REQUEST, new InternalBitServer(), messageHandlingExecutor);
    // FIXME: Consider consolidating into a single map.
    ClockService<ApplicationId, Application> appsClockService = (appId, app) -> new MultiValuedTimestamp<>(getUpdateTime(appId.name()), sequence.incrementAndGet());
    apps = storageService.<ApplicationId, Application>eventuallyConsistentMapBuilder().name("apps").serializer(serializer).clockService(appsClockService).build();
    ClockService<Application, InternalState> statesClockService = (app, state) -> new MultiValuedTimestamp<>(getUpdateTime(app.id().name()), sequence.incrementAndGet());
    states = storageService.<Application, InternalState>eventuallyConsistentMapBuilder().name("app-states").serializer(serializer).clockService(statesClockService).build();
    states.addListener(new InternalAppStatesListener());
    permissions = storageService.<Application, Set<Permission>>eventuallyConsistentMapBuilder().name("app-permissions").serializer(serializer).clockService(new WallclockClockManager<>()).build();
    log.info("Started");
}
#method_after
@Activate
public void activate() {
    KryoNamespace.Builder serializer = KryoNamespace.newBuilder().register(KryoNamespaces.API).register(MultiValuedTimestamp.class).register(InternalState.class);
    executor = Executors.newSingleThreadScheduledExecutor(groupedThreads("onos/app", "store"));
    messageHandlingExecutor = Executors.newSingleThreadExecutor(groupedThreads("onos/store/app", "message-handler"));
    clusterCommunicator.addSubscriber(APP_BITS_REQUEST, new InternalBitServer(), messageHandlingExecutor);
    // FIXME: Consider consolidating into a single map.
    ClockService<ApplicationId, Application> appsClockService = (appId, app) -> new MultiValuedTimestamp<>(getUpdateTime(appId.name()), sequence.incrementAndGet());
    apps = storageService.<ApplicationId, Application>eventuallyConsistentMapBuilder().withName("apps").withSerializer(serializer).withClockService(appsClockService).build();
    ClockService<Application, InternalState> statesClockService = (app, state) -> new MultiValuedTimestamp<>(getUpdateTime(app.id().name()), sequence.incrementAndGet());
    states = storageService.<Application, InternalState>eventuallyConsistentMapBuilder().withName("app-states").withSerializer(serializer).withClockService(statesClockService).build();
    states.addListener(new InternalAppStatesListener());
    permissions = storageService.<Application, Set<Permission>>eventuallyConsistentMapBuilder().withName("app-permissions").withSerializer(serializer).withClockService(new WallclockClockManager<>()).build();
    log.info("Started");
}
#end_block

#method_before
@Activate
public void activate() {
    KryoNamespace.Builder serializer = KryoNamespace.newBuilder().register(KryoNamespaces.API);
    properties = storageService.<String, String>eventuallyConsistentMapBuilder().name("cfg").serializer(serializer).clockService(new WallclockClockManager<>()).build();
    properties.addListener(new InternalPropertiesListener());
    log.info("Started");
}
#method_after
@Activate
public void activate() {
    KryoNamespace.Builder serializer = KryoNamespace.newBuilder().register(KryoNamespaces.API);
    properties = storageService.<String, String>eventuallyConsistentMapBuilder().withName("cfg").withSerializer(serializer).withClockService(new WallclockClockManager<>()).build();
    properties.addListener(new InternalPropertiesListener());
    log.info("Started");
}
#end_block

#method_before
@Override
public EventuallyConsistentMap<K, V> build() {
    if (name == null) {
        throw new RuntimeException("name is a mandatory parameter");
    }
    if (serializerBuilder == null) {
        throw new RuntimeException("serializerBuilder is a mandatory parameter");
    }
    if (clockService == null) {
        throw new RuntimeException("clockService is a mandatory parameter");
    }
    return new EventuallyConsistentMapImpl<>(name, clusterService, clusterCommunicator, serializerBuilder, clockService, peerUpdateFunction, eventExecutor, communicationExecutor, backgroundExecutor, tombstonesDisabled, antiEntropyPeriod, convergeFaster);
}
#method_after
@Override
public EventuallyConsistentMap<K, V> build() {
    checkNotNull(name, "name is a mandatory parameter");
    checkNotNull(serializerBuilder, "serializerBuilder is a mandatory parameter");
    checkNotNull(clockService, "clockService is a mandatory parameter");
    return new EventuallyConsistentMapImpl<>(name, clusterService, clusterCommunicator, serializerBuilder, clockService, peerUpdateFunction, eventExecutor, communicationExecutor, backgroundExecutor, tombstonesDisabled, antiEntropyPeriod, antiEntropyTimeUnit, convergeFaster);
}
#end_block

#method_before
@Activate
public void activate() {
    kryoBuilder = new KryoNamespace.Builder().register(DefaultGroup.class, DefaultGroupBucket.class, DefaultGroupDescription.class, DefaultGroupKey.class, GroupDescription.Type.class, Group.GroupState.class, GroupBuckets.class, DefaultGroupId.class, GroupStoreMessage.class, GroupStoreMessage.Type.class, UpdateType.class, GroupStoreMessageSubjects.class, MultiValuedTimestamp.class, GroupStoreKeyMapKey.class, GroupStoreIdMapKey.class, GroupStoreMapKey.class).register(URI.class).register(DeviceId.class).register(PortNumber.class).register(DefaultApplicationId.class).register(DefaultTrafficTreatment.class, Instructions.DropInstruction.class, Instructions.OutputInstruction.class, Instructions.GroupInstruction.class, Instructions.TableTypeTransition.class, FlowRule.Type.class, L0ModificationInstruction.class, L0ModificationInstruction.L0SubType.class, L0ModificationInstruction.ModLambdaInstruction.class, L2ModificationInstruction.class, L2ModificationInstruction.L2SubType.class, L2ModificationInstruction.ModEtherInstruction.class, L2ModificationInstruction.PushHeaderInstructions.class, L2ModificationInstruction.ModVlanIdInstruction.class, L2ModificationInstruction.ModVlanPcpInstruction.class, L2ModificationInstruction.ModMplsLabelInstruction.class, L2ModificationInstruction.ModMplsTtlInstruction.class, L3ModificationInstruction.class, L3ModificationInstruction.L3SubType.class, L3ModificationInstruction.ModIPInstruction.class, L3ModificationInstruction.ModIPv6FlowLabelInstruction.class, L3ModificationInstruction.ModTtlInstruction.class, org.onlab.packet.MplsLabel.class).register(org.onosproject.cluster.NodeId.class).register(KryoNamespaces.BASIC).register(KryoNamespaces.MISC);
    messageHandlingExecutor = Executors.newFixedThreadPool(MESSAGE_HANDLER_THREAD_POOL_SIZE, groupedThreads("onos/store/group", "message-handlers"));
    clusterCommunicator.addSubscriber(GroupStoreMessageSubjects.REMOTE_GROUP_OP_REQUEST, new ClusterGroupMsgHandler(), messageHandlingExecutor);
    log.debug("Creating EC map groupstorekeymap");
    EventuallyConsistentMapBuilder<GroupStoreKeyMapKey, StoredGroupEntry> keyMapBuilder = storageService.eventuallyConsistentMapBuilder();
    groupStoreEntriesByKey = keyMapBuilder.name("groupstorekeymap").serializer(kryoBuilder).clockService(new GroupStoreLogicalClockManager<>()).build();
    log.trace("Current size {}", groupStoreEntriesByKey.size());
    log.debug("Creating EC map groupstoreidmap");
    EventuallyConsistentMapBuilder<GroupStoreIdMapKey, StoredGroupEntry> idMapBuilder = storageService.eventuallyConsistentMapBuilder();
    groupStoreEntriesById = idMapBuilder.name("groupstoreidmap").serializer(kryoBuilder).clockService(new GroupStoreLogicalClockManager<>()).build();
    groupStoreEntriesById.addListener(new GroupStoreIdMapListener());
    log.trace("Current size {}", groupStoreEntriesById.size());
    log.debug("Creating EC map pendinggroupkeymap");
    EventuallyConsistentMapBuilder<GroupStoreKeyMapKey, StoredGroupEntry> auditMapBuilder = storageService.eventuallyConsistentMapBuilder();
    auditPendingReqQueue = auditMapBuilder.name("pendinggroupkeymap").serializer(kryoBuilder).clockService(new GroupStoreLogicalClockManager<>()).build();
    log.trace("Current size {}", auditPendingReqQueue.size());
    log.info("Started");
}
#method_after
@Activate
public void activate() {
    kryoBuilder = new KryoNamespace.Builder().register(DefaultGroup.class, DefaultGroupBucket.class, DefaultGroupDescription.class, DefaultGroupKey.class, GroupDescription.Type.class, Group.GroupState.class, GroupBuckets.class, DefaultGroupId.class, GroupStoreMessage.class, GroupStoreMessage.Type.class, UpdateType.class, GroupStoreMessageSubjects.class, MultiValuedTimestamp.class, GroupStoreKeyMapKey.class, GroupStoreIdMapKey.class, GroupStoreMapKey.class).register(URI.class).register(DeviceId.class).register(PortNumber.class).register(DefaultApplicationId.class).register(DefaultTrafficTreatment.class, Instructions.DropInstruction.class, Instructions.OutputInstruction.class, Instructions.GroupInstruction.class, Instructions.TableTypeTransition.class, FlowRule.Type.class, L0ModificationInstruction.class, L0ModificationInstruction.L0SubType.class, L0ModificationInstruction.ModLambdaInstruction.class, L2ModificationInstruction.class, L2ModificationInstruction.L2SubType.class, L2ModificationInstruction.ModEtherInstruction.class, L2ModificationInstruction.PushHeaderInstructions.class, L2ModificationInstruction.ModVlanIdInstruction.class, L2ModificationInstruction.ModVlanPcpInstruction.class, L2ModificationInstruction.ModMplsLabelInstruction.class, L2ModificationInstruction.ModMplsTtlInstruction.class, L3ModificationInstruction.class, L3ModificationInstruction.L3SubType.class, L3ModificationInstruction.ModIPInstruction.class, L3ModificationInstruction.ModIPv6FlowLabelInstruction.class, L3ModificationInstruction.ModTtlInstruction.class, org.onlab.packet.MplsLabel.class).register(org.onosproject.cluster.NodeId.class).register(KryoNamespaces.BASIC).register(KryoNamespaces.MISC);
    messageHandlingExecutor = Executors.newFixedThreadPool(MESSAGE_HANDLER_THREAD_POOL_SIZE, groupedThreads("onos/store/group", "message-handlers"));
    clusterCommunicator.addSubscriber(GroupStoreMessageSubjects.REMOTE_GROUP_OP_REQUEST, new ClusterGroupMsgHandler(), messageHandlingExecutor);
    log.debug("Creating EC map groupstorekeymap");
    EventuallyConsistentMapBuilder<GroupStoreKeyMapKey, StoredGroupEntry> keyMapBuilder = storageService.eventuallyConsistentMapBuilder();
    groupStoreEntriesByKey = keyMapBuilder.withName("groupstorekeymap").withSerializer(kryoBuilder).withClockService(new GroupStoreLogicalClockManager<>()).build();
    log.trace("Current size {}", groupStoreEntriesByKey.size());
    log.debug("Creating EC map groupstoreidmap");
    EventuallyConsistentMapBuilder<GroupStoreIdMapKey, StoredGroupEntry> idMapBuilder = storageService.eventuallyConsistentMapBuilder();
    groupStoreEntriesById = idMapBuilder.withName("groupstoreidmap").withSerializer(kryoBuilder).withClockService(new GroupStoreLogicalClockManager<>()).build();
    groupStoreEntriesById.addListener(new GroupStoreIdMapListener());
    log.trace("Current size {}", groupStoreEntriesById.size());
    log.debug("Creating EC map pendinggroupkeymap");
    EventuallyConsistentMapBuilder<GroupStoreKeyMapKey, StoredGroupEntry> auditMapBuilder = storageService.eventuallyConsistentMapBuilder();
    auditPendingReqQueue = auditMapBuilder.withName("pendinggroupkeymap").withSerializer(kryoBuilder).withClockService(new GroupStoreLogicalClockManager<>()).build();
    log.trace("Current size {}", auditPendingReqQueue.size());
    log.info("Started");
}
#end_block

#method_before
@Before
public void setUp() throws Exception {
    clusterService = createMock(ClusterService.class);
    expect(clusterService.getLocalNode()).andReturn(self).anyTimes();
    expect(clusterService.getNodes()).andReturn(ImmutableSet.of(self)).anyTimes();
    replay(clusterService);
    clusterCommunicator = createMock(ClusterCommunicationService.class);
    // Add expectation for adding cluster message subscribers which
    // delegate to our ClusterCommunicationService implementation. This
    // allows us to get a reference to the map's internal cluster message
    // handlers so we can induce events coming in from a peer.
    clusterCommunicator.addSubscriber(anyObject(MessageSubject.class), anyObject(ClusterMessageHandler.class), anyObject(ExecutorService.class));
    expectLastCall().andDelegateTo(new TestClusterCommunicationService()).times(3);
    replay(clusterCommunicator);
    clockService = new SequentialClockService<>();
    KryoNamespace.Builder serializer = KryoNamespace.newBuilder().register(KryoNamespaces.API).register(TestTimestamp.class);
    ecMap = new EventuallyConsistentMapBuilderImpl<>(clusterService, clusterCommunicator).name(MAP_NAME).serializer(serializer).clockService(clockService).communicationExecutor(MoreExecutors.newDirectExecutorService()).build();
    // Reset ready for tests to add their own expectations
    reset(clusterCommunicator);
}
#method_after
@Before
public void setUp() throws Exception {
    clusterService = createMock(ClusterService.class);
    expect(clusterService.getLocalNode()).andReturn(self).anyTimes();
    expect(clusterService.getNodes()).andReturn(ImmutableSet.of(self)).anyTimes();
    replay(clusterService);
    clusterCommunicator = createMock(ClusterCommunicationService.class);
    // Add expectation for adding cluster message subscribers which
    // delegate to our ClusterCommunicationService implementation. This
    // allows us to get a reference to the map's internal cluster message
    // handlers so we can induce events coming in from a peer.
    clusterCommunicator.addSubscriber(anyObject(MessageSubject.class), anyObject(ClusterMessageHandler.class), anyObject(ExecutorService.class));
    expectLastCall().andDelegateTo(new TestClusterCommunicationService()).times(3);
    replay(clusterCommunicator);
    clockService = new SequentialClockService<>();
    KryoNamespace.Builder serializer = KryoNamespace.newBuilder().register(KryoNamespaces.API).register(TestTimestamp.class);
    ecMap = new EventuallyConsistentMapBuilderImpl<>(clusterService, clusterCommunicator).withName(MAP_NAME).withSerializer(serializer).withClockService(clockService).withCommunicationExecutor(MoreExecutors.newDirectExecutorService()).build();
    // Reset ready for tests to add their own expectations
    reset(clusterCommunicator);
}
#end_block

#method_before
public PolicyGroupIdentifier createPolicyGroupChain(String id, List<PolicyGroupParams> params) {
    List<GroupBucketIdentifier> bucketIds = new ArrayList<GroupBucketIdentifier>();
    for (PolicyGroupParams param : params) {
        List<PortNumber> ports = param.getPorts();
        if (ports == null) {
            log.warn("createPolicyGroupChain in sw {} with wrong " + "input parameters", deviceId);
            return null;
        }
        int labelStackSize = (param.getLabelStack() != null) ? param.getLabelStack().size() : 0;
        if (labelStackSize > 1) {
            for (PortNumber sp : ports) {
                PolicyGroupIdentifier previousGroupkey = null;
                DeviceId neighbor = portDeviceMap.get(sp);
                for (int idx = 0; idx < param.getLabelStack().size(); idx++) {
                    int label = param.getLabelStack().get(idx).intValue();
                    if (idx == (labelStackSize - 1)) {
                        // Innermost Group
                        GroupBucketIdentifier bucketId = new GroupBucketIdentifier(label, previousGroupkey);
                        bucketIds.add(bucketId);
                    } else if (idx == 0) {
                        // Outermost Group
                        List<GroupBucket> outBuckets = new ArrayList<GroupBucket>();
                        GroupBucketIdentifier bucketId = new GroupBucketIdentifier(label, sp);
                        PolicyGroupIdentifier key = new PolicyGroupIdentifier(id, Arrays.asList(param), Arrays.asList(bucketId));
                        TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
                        tBuilder.setOutput(sp).setEthDst(deviceConfig.getDeviceMac(neighbor)).setEthSrc(nodeMacAddr).pushMpls().setMpls(MplsLabel.mplsLabel(label));
                        outBuckets.add(DefaultGroupBucket.createSelectGroupBucket(tBuilder.build()));
                        GroupDescription desc = new DefaultGroupDescription(deviceId, GroupDescription.Type.INDIRECT, new GroupBuckets(outBuckets));
                        // TODO: BoS
                        previousGroupkey = key;
                        groupService.addGroup(desc);
                    } else {
                        // Intermediate Groups
                        GroupBucketIdentifier bucketId = new GroupBucketIdentifier(label, previousGroupkey);
                        PolicyGroupIdentifier key = new PolicyGroupIdentifier(id, Arrays.asList(param), Arrays.asList(bucketId));
                        // Add to group dependency list
                        dependentGroups.put(previousGroupkey, key);
                        previousGroupkey = key;
                    }
                }
            }
        } else {
            int label = -1;
            if (labelStackSize == 1) {
                label = param.getLabelStack().get(0).intValue();
            }
            for (PortNumber sp : ports) {
                GroupBucketIdentifier bucketId = new GroupBucketIdentifier(label, sp);
                bucketIds.add(bucketId);
            }
        }
    }
    PolicyGroupIdentifier innermostGroupkey = null;
    if (!bucketIds.isEmpty()) {
        innermostGroupkey = new PolicyGroupIdentifier(id, params, bucketIds);
        // Add to group dependency list
        boolean fullyResolved = true;
        for (GroupBucketIdentifier bucketId : bucketIds) {
            if (bucketId.type() == BucketOutputType.GROUP) {
                dependentGroups.put(bucketId.outGroup(), innermostGroupkey);
                fullyResolved = false;
            }
        }
        if (fullyResolved) {
            List<GroupBucket> outBuckets = new ArrayList<GroupBucket>();
            for (GroupBucketIdentifier bucketId : bucketIds) {
                DeviceId neighbor = portDeviceMap.get(bucketId.outPort());
                TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
                tBuilder.setOutput(bucketId.outPort()).setEthDst(deviceConfig.getDeviceMac(neighbor)).setEthSrc(nodeMacAddr);
                if (bucketId.label() != -1) {
                    tBuilder.pushMpls().setMpls(MplsLabel.mplsLabel(bucketId.label()));
                }
                // TODO: BoS
                outBuckets.add(DefaultGroupBucket.createSelectGroupBucket(tBuilder.build()));
            }
            GroupDescription desc = new DefaultGroupDescription(deviceId, GroupDescription.Type.SELECT, new GroupBuckets(outBuckets));
            groupService.addGroup(desc);
        }
    }
    return innermostGroupkey;
}
#method_after
public PolicyGroupIdentifier createPolicyGroupChain(String id, List<PolicyGroupParams> params) {
    List<GroupBucketIdentifier> bucketIds = new ArrayList<GroupBucketIdentifier>();
    for (PolicyGroupParams param : params) {
        List<PortNumber> ports = param.getPorts();
        if (ports == null) {
            log.warn("createPolicyGroupChain in sw {} with wrong " + "input parameters", deviceId);
            return null;
        }
        int labelStackSize = (param.getLabelStack() != null) ? param.getLabelStack().size() : 0;
        if (labelStackSize > 1) {
            for (PortNumber sp : ports) {
                PolicyGroupIdentifier previousGroupkey = null;
                DeviceId neighbor = portDeviceMap.get(sp);
                for (int idx = 0; idx < param.getLabelStack().size(); idx++) {
                    int label = param.getLabelStack().get(idx).intValue();
                    if (idx == (labelStackSize - 1)) {
                        // Innermost Group
                        GroupBucketIdentifier bucketId = new GroupBucketIdentifier(label, previousGroupkey);
                        bucketIds.add(bucketId);
                    } else if (idx == 0) {
                        // Outermost Group
                        List<GroupBucket> outBuckets = new ArrayList<GroupBucket>();
                        GroupBucketIdentifier bucketId = new GroupBucketIdentifier(label, sp);
                        PolicyGroupIdentifier key = new PolicyGroupIdentifier(id, Arrays.asList(param), Arrays.asList(bucketId));
                        TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
                        tBuilder.setOutput(sp).setEthDst(deviceConfig.getDeviceMac(neighbor)).setEthSrc(nodeMacAddr).pushMpls().setMpls(MplsLabel.mplsLabel(label));
                        outBuckets.add(DefaultGroupBucket.createSelectGroupBucket(tBuilder.build()));
                        GroupDescription desc = new DefaultGroupDescription(deviceId, GroupDescription.Type.INDIRECT, new GroupBuckets(outBuckets));
                        // TODO: BoS
                        previousGroupkey = key;
                        groupService.addGroup(desc);
                    } else {
                        // Intermediate Groups
                        GroupBucketIdentifier bucketId = new GroupBucketIdentifier(label, previousGroupkey);
                        PolicyGroupIdentifier key = new PolicyGroupIdentifier(id, Arrays.asList(param), Arrays.asList(bucketId));
                        // Add to group dependency list
                        dependentGroups.put(previousGroupkey, key);
                        previousGroupkey = key;
                    }
                }
            }
        } else {
            int label = -1;
            if (labelStackSize == 1) {
                label = param.getLabelStack().get(0).intValue();
            }
            for (PortNumber sp : ports) {
                GroupBucketIdentifier bucketId = new GroupBucketIdentifier(label, sp);
                bucketIds.add(bucketId);
            }
        }
    }
    PolicyGroupIdentifier innermostGroupkey = null;
    if (!bucketIds.isEmpty()) {
        innermostGroupkey = new PolicyGroupIdentifier(id, params, bucketIds);
        // Add to group dependency list
        boolean fullyResolved = true;
        for (GroupBucketIdentifier bucketId : bucketIds) {
            if (bucketId.type() == BucketOutputType.GROUP) {
                dependentGroups.put(bucketId.outGroup(), innermostGroupkey);
                fullyResolved = false;
            }
        }
        if (fullyResolved) {
            List<GroupBucket> outBuckets = new ArrayList<GroupBucket>();
            for (GroupBucketIdentifier bucketId : bucketIds) {
                DeviceId neighbor = portDeviceMap.get(bucketId.outPort());
                TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
                tBuilder.setOutput(bucketId.outPort()).setEthDst(deviceConfig.getDeviceMac(neighbor)).setEthSrc(nodeMacAddr);
                if (bucketId.label() != NeighborSet.NO_EDGE_LABEL) {
                    tBuilder.pushMpls().setMpls(MplsLabel.mplsLabel(bucketId.label()));
                }
                // TODO: BoS
                outBuckets.add(DefaultGroupBucket.createSelectGroupBucket(tBuilder.build()));
            }
            GroupDescription desc = new DefaultGroupDescription(deviceId, GroupDescription.Type.SELECT, new GroupBuckets(outBuckets));
            groupService.addGroup(desc);
        }
    }
    return innermostGroupkey;
}
#end_block

#method_before
@Override
protected void handleGroupEvent(GroupEvent event) {
    if (event.type() == GroupEvent.Type.GROUP_ADDED) {
        if (dependentGroups.get(event.subject().appCookie()) != null) {
            PolicyGroupIdentifier dependentGroupKey = dependentGroups.get(event.subject().appCookie());
            dependentGroups.remove(event.subject().appCookie());
            boolean fullyResolved = true;
            for (GroupBucketIdentifier bucketId : dependentGroupKey.bucketIds()) {
                if (bucketId.type() != BucketOutputType.GROUP) {
                    continue;
                }
                if (dependentGroups.containsKey(bucketId.outGroup())) {
                    fullyResolved = false;
                    break;
                }
            }
            if (fullyResolved) {
                List<GroupBucket> outBuckets = new ArrayList<GroupBucket>();
                for (GroupBucketIdentifier bucketId : dependentGroupKey.bucketIds()) {
                    TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
                    if (bucketId.label() != -1) {
                        tBuilder.pushMpls().setMpls(MplsLabel.mplsLabel(bucketId.label()));
                    }
                    // TODO: BoS
                    if (bucketId.type() == BucketOutputType.PORT) {
                        DeviceId neighbor = portDeviceMap.get(bucketId.outPort());
                        tBuilder.setOutput(bucketId.outPort()).setEthDst(deviceConfig.getDeviceMac(neighbor)).setEthSrc(nodeMacAddr);
                    } else {
                        if (groupService.getGroup(deviceId, getGroupKey(bucketId.outGroup())) == null) {
                            throw new IllegalStateException();
                        }
                        GroupId indirectGroupId = groupService.getGroup(deviceId, getGroupKey(bucketId.outGroup())).id();
                        tBuilder.group(indirectGroupId);
                    }
                    outBuckets.add(DefaultGroupBucket.createSelectGroupBucket(tBuilder.build()));
                }
                GroupDescription desc = new DefaultGroupDescription(deviceId, GroupDescription.Type.SELECT, new GroupBuckets(outBuckets));
                groupService.addGroup(desc);
            }
        }
    }
}
#method_after
@Override
protected void handleGroupEvent(GroupEvent event) {
    if (event.type() == GroupEvent.Type.GROUP_ADDED) {
        if (dependentGroups.get(event.subject().appCookie()) != null) {
            PolicyGroupIdentifier dependentGroupKey = dependentGroups.get(event.subject().appCookie());
            dependentGroups.remove(event.subject().appCookie());
            boolean fullyResolved = true;
            for (GroupBucketIdentifier bucketId : dependentGroupKey.bucketIds()) {
                if (bucketId.type() != BucketOutputType.GROUP) {
                    continue;
                }
                if (dependentGroups.containsKey(bucketId.outGroup())) {
                    fullyResolved = false;
                    break;
                }
            }
            if (fullyResolved) {
                List<GroupBucket> outBuckets = new ArrayList<GroupBucket>();
                for (GroupBucketIdentifier bucketId : dependentGroupKey.bucketIds()) {
                    TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
                    if (bucketId.label() != NeighborSet.NO_EDGE_LABEL) {
                        tBuilder.pushMpls().setMpls(MplsLabel.mplsLabel(bucketId.label()));
                    }
                    // TODO: BoS
                    if (bucketId.type() == BucketOutputType.PORT) {
                        DeviceId neighbor = portDeviceMap.get(bucketId.outPort());
                        tBuilder.setOutput(bucketId.outPort()).setEthDst(deviceConfig.getDeviceMac(neighbor)).setEthSrc(nodeMacAddr);
                    } else {
                        if (groupService.getGroup(deviceId, getGroupKey(bucketId.outGroup())) == null) {
                            throw new IllegalStateException();
                        }
                        GroupId indirectGroupId = groupService.getGroup(deviceId, getGroupKey(bucketId.outGroup())).id();
                        tBuilder.group(indirectGroupId);
                    }
                    outBuckets.add(DefaultGroupBucket.createSelectGroupBucket(tBuilder.build()));
                }
                GroupDescription desc = new DefaultGroupDescription(deviceId, GroupDescription.Type.SELECT, new GroupBuckets(outBuckets));
                groupService.addGroup(desc);
            }
        }
    }
}
#end_block

#method_before
@Activate
public void activate() {
    kryoBuilder = new KryoNamespace.Builder().register(DefaultGroup.class, DefaultGroupBucket.class, DefaultGroupDescription.class, DefaultGroupKey.class, GroupDescription.Type.class, Group.GroupState.class, GroupBuckets.class, DefaultGroupId.class, GroupStoreMessage.class, GroupStoreMessage.Type.class, UpdateType.class, GroupStoreMessageSubjects.class, MultiValuedTimestamp.class, GroupStoreKeyMapKey.class, GroupStoreIdMapKey.class, GroupStoreMapKey.class).register(URI.class).register(DeviceId.class).register(PortNumber.class).register(DefaultApplicationId.class).register(DefaultTrafficTreatment.class, Instructions.DropInstruction.class, Instructions.OutputInstruction.class, Instructions.GroupInstruction.class, Instructions.TableTypeTransition.class, FlowRule.Type.class, L0ModificationInstruction.class, L0ModificationInstruction.L0SubType.class, L0ModificationInstruction.ModLambdaInstruction.class, L2ModificationInstruction.class, L2ModificationInstruction.L2SubType.class, L2ModificationInstruction.ModEtherInstruction.class, L2ModificationInstruction.PushHeaderInstructions.class, L2ModificationInstruction.ModVlanIdInstruction.class, L2ModificationInstruction.ModVlanPcpInstruction.class, L2ModificationInstruction.ModMplsLabelInstruction.class, L2ModificationInstruction.ModMplsTtlInstruction.class, L3ModificationInstruction.class, L3ModificationInstruction.L3SubType.class, L3ModificationInstruction.ModIPInstruction.class, L3ModificationInstruction.ModIPv6FlowLabelInstruction.class, L3ModificationInstruction.ModTtlInstruction.class, org.onlab.packet.MplsLabel.class).register(org.onosproject.cluster.NodeId.class).register(KryoNamespaces.BASIC).register(KryoNamespaces.MISC);
    messageHandlingExecutor = Executors.newFixedThreadPool(MESSAGE_HANDLER_THREAD_POOL_SIZE, groupedThreads("onos/store/group", "message-handlers"));
    clusterCommunicator.addSubscriber(GroupStoreMessageSubjects.REMOTE_GROUP_OP_REQUEST, new ClusterGroupMsgHandler(), messageHandlingExecutor);
    getGroupStoreKeyMap();
    getGroupStoreIdMap();
    getPendingGroupKeyTable();
    log.info("Started");
}
#method_after
@Activate
public void activate() {
    kryoBuilder = new KryoNamespace.Builder().register(DefaultGroup.class, DefaultGroupBucket.class, DefaultGroupDescription.class, DefaultGroupKey.class, GroupDescription.Type.class, Group.GroupState.class, GroupBuckets.class, DefaultGroupId.class, GroupStoreMessage.class, GroupStoreMessage.Type.class, UpdateType.class, GroupStoreMessageSubjects.class, MultiValuedTimestamp.class, GroupStoreKeyMapKey.class, GroupStoreIdMapKey.class, GroupStoreMapKey.class).register(URI.class).register(DeviceId.class).register(PortNumber.class).register(DefaultApplicationId.class).register(DefaultTrafficTreatment.class, Instructions.DropInstruction.class, Instructions.OutputInstruction.class, Instructions.GroupInstruction.class, Instructions.TableTypeTransition.class, FlowRule.Type.class, L0ModificationInstruction.class, L0ModificationInstruction.L0SubType.class, L0ModificationInstruction.ModLambdaInstruction.class, L2ModificationInstruction.class, L2ModificationInstruction.L2SubType.class, L2ModificationInstruction.ModEtherInstruction.class, L2ModificationInstruction.PushHeaderInstructions.class, L2ModificationInstruction.ModVlanIdInstruction.class, L2ModificationInstruction.ModVlanPcpInstruction.class, L2ModificationInstruction.ModMplsLabelInstruction.class, L2ModificationInstruction.ModMplsTtlInstruction.class, L3ModificationInstruction.class, L3ModificationInstruction.L3SubType.class, L3ModificationInstruction.ModIPInstruction.class, L3ModificationInstruction.ModIPv6FlowLabelInstruction.class, L3ModificationInstruction.ModTtlInstruction.class, org.onlab.packet.MplsLabel.class).register(org.onosproject.cluster.NodeId.class).register(KryoNamespaces.BASIC).register(KryoNamespaces.MISC);
    messageHandlingExecutor = Executors.newFixedThreadPool(MESSAGE_HANDLER_THREAD_POOL_SIZE, groupedThreads("onos/store/group", "message-handlers"));
    clusterCommunicator.addSubscriber(GroupStoreMessageSubjects.REMOTE_GROUP_OP_REQUEST, new ClusterGroupMsgHandler(), messageHandlingExecutor);
    log.debug("Creating EC map groupstorekeymap");
    groupStoreEntriesByKey = new EventuallyConsistentMapImpl<>("groupstorekeymap", clusterService, clusterCommunicator, kryoBuilder, new GroupStoreLogicalClockManager<>());
    log.trace("Current size {}", groupStoreEntriesByKey.size());
    log.debug("Creating EC map groupstoreidmap");
    groupStoreEntriesById = new EventuallyConsistentMapImpl<>("groupstoreidmap", clusterService, clusterCommunicator, kryoBuilder, new GroupStoreLogicalClockManager<>());
    groupStoreEntriesById.addListener(new GroupStoreIdMapListener());
    log.trace("Current size {}", groupStoreEntriesById.size());
    log.debug("Creating EC map pendinggroupkeymap");
    auditPendingReqQueue = new EventuallyConsistentMapImpl<>("pendinggroupkeymap", clusterService, clusterCommunicator, kryoBuilder, new GroupStoreLogicalClockManager<>());
    log.trace("Current size {}", auditPendingReqQueue.size());
    log.info("Started");
}
#end_block

#method_before
private EventuallyConsistentMap<GroupStoreKeyMapKey, StoredGroupEntry> getGroupStoreKeyMap() {
    synchronized (keyMapLock) {
        if (groupStoreEntriesByKey == null) {
            log.debug("Creating EC map groupstorekeymap");
            groupStoreEntriesByKey = new EventuallyConsistentMapImpl<>("groupstorekeymap", clusterService, clusterCommunicator, kryoBuilder, new GroupStoreLogicalClockManager<>());
            log.trace("Current size {}", groupStoreEntriesByKey.size());
        }
    }
    return groupStoreEntriesByKey;
}
#method_after
private EventuallyConsistentMap<GroupStoreKeyMapKey, StoredGroupEntry> getGroupStoreKeyMap() {
    return groupStoreEntriesByKey;
}
#end_block

#method_before
private EventuallyConsistentMap<GroupStoreIdMapKey, StoredGroupEntry> getGroupStoreIdMap() {
    synchronized (idMapLock) {
        if (groupStoreEntriesById == null) {
            log.debug("Creating EC map groupstoreidmap");
            groupStoreEntriesById = new EventuallyConsistentMapImpl<>("groupstoreidmap", clusterService, clusterCommunicator, kryoBuilder, new GroupStoreLogicalClockManager<>());
            groupStoreEntriesById.addListener(new GroupStoreIdMapListener());
            log.trace("Current size {}", groupStoreEntriesById.size());
        }
    }
    return groupStoreEntriesById;
}
#method_after
private EventuallyConsistentMap<GroupStoreIdMapKey, StoredGroupEntry> getGroupStoreIdMap() {
    return groupStoreEntriesById;
}
#end_block

#method_before
private EventuallyConsistentMap<GroupStoreKeyMapKey, StoredGroupEntry> getPendingGroupKeyTable() {
    synchronized (pendingQueueLock) {
        if (auditPendingReqQueue == null) {
            log.debug("Creating EC map pendinggroupkeymap");
            auditPendingReqQueue = new EventuallyConsistentMapImpl<>("pendinggroupkeymap", clusterService, clusterCommunicator, kryoBuilder, new GroupStoreLogicalClockManager<>());
            log.trace("Current size {}", auditPendingReqQueue.size());
        }
    }
    return auditPendingReqQueue;
}
#method_after
private EventuallyConsistentMap<GroupStoreKeyMapKey, StoredGroupEntry> getPendingGroupKeyTable() {
    return auditPendingReqQueue;
}
#end_block

#method_before
@Override
public Iterable<Group> getGroups(DeviceId deviceId) {
    // flatten and make iterator unmodifiable
    log.trace("getGroups: for device {} total number of groups {}", deviceId, getGroupStoreKeyMap().values().size());
    return FluentIterable.from(getGroupStoreKeyMap().values()).filter(new GroupPredicate(deviceId)).transform(new Function<StoredGroupEntry, Group>() {

        @Override
        public Group apply(StoredGroupEntry input) {
            return input;
        }
    });
}
#method_after
@Override
public Iterable<Group> getGroups(DeviceId deviceId) {
    // flatten and make iterator unmodifiable
    log.trace("getGroups: for device {} total number of groups {}", deviceId, getGroupStoreKeyMap().values().size());
    return FluentIterable.from(getGroupStoreKeyMap().values()).filter(input -> input.deviceId().equals(deviceId)).transform(input -> input);
}
#end_block

#method_before
@Override
public void deviceInitialAuditCompleted(DeviceId deviceId, boolean completed) {
    synchronized (deviceAuditStatus) {
        if (completed) {
            log.debug("deviceInitialAuditCompleted: AUDIT " + "completed for device {}", deviceId);
            deviceAuditStatus.put(deviceId, true);
            // Execute all pending group requests
            Collection<StoredGroupEntry> pendingGroupRequests = Collections2.filter(getPendingGroupKeyTable().values(), new GroupPredicate(deviceId));
            log.trace("deviceInitialAuditCompleted: processing " + "pending group add requests for device {} and " + "number of pending requests {}", deviceId, pendingGroupRequests.size());
            for (Group group : pendingGroupRequests) {
                GroupDescription tmp = new DefaultGroupDescription(group.deviceId(), group.type(), group.buckets(), group.appCookie(), group.appId());
                storeGroupDescriptionInternal(tmp);
                getPendingGroupKeyTable().remove(new GroupStoreKeyMapKey(deviceId, group.appCookie()));
            }
        } else {
            if (deviceAuditStatus.get(deviceId)) {
                log.debug("deviceInitialAuditCompleted: Clearing AUDIT " + "status for device {}", deviceId);
                deviceAuditStatus.put(deviceId, false);
            }
        }
    }
}
#method_after
@Override
public void deviceInitialAuditCompleted(DeviceId deviceId, boolean completed) {
    synchronized (deviceAuditStatus) {
        if (completed) {
            log.debug("deviceInitialAuditCompleted: AUDIT " + "completed for device {}", deviceId);
            deviceAuditStatus.put(deviceId, true);
            // Execute all pending group requests
            List<StoredGroupEntry> pendingGroupRequests = getPendingGroupKeyTable().values().stream().filter(g -> g.deviceId().equals(deviceId)).collect(Collectors.toList());
            log.trace("deviceInitialAuditCompleted: processing " + "pending group add requests for device {} and " + "number of pending requests {}", deviceId, pendingGroupRequests.size());
            for (Group group : pendingGroupRequests) {
                GroupDescription tmp = new DefaultGroupDescription(group.deviceId(), group.type(), group.buckets(), group.appCookie(), group.appId());
                storeGroupDescriptionInternal(tmp);
                getPendingGroupKeyTable().remove(new GroupStoreKeyMapKey(deviceId, group.appCookie()));
            }
        } else {
            if (deviceAuditStatus.get(deviceId)) {
                log.debug("deviceInitialAuditCompleted: Clearing AUDIT " + "status for device {}", deviceId);
                deviceAuditStatus.put(deviceId, false);
            }
        }
    }
}
#end_block

#method_before
public void portDown(PortNumber port) {
    if (portDeviceMap.get(port) == null) {
        log.warn("portDown: unknown port");
        return;
    }
    log.debug("Device {} portDown {} to neighbor {}", deviceId, port, portDeviceMap.get(port));
    Set<NeighborSet> nsSet = computeImpactedNeighborsetForPortEvent(portDeviceMap.get(port), devicePortMap.keySet());
    for (NeighborSet ns : nsSet) {
        // Create the bucket to be removed
        TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
        tBuilder.setOutput(port).setEthDst(deviceConfig.getDeviceMac(portDeviceMap.get(port))).setEthSrc(nodeMacAddr);
        if (ns.getEdgeLabel() != -1) {
            tBuilder.pushMpls().setMpls(MplsLabel.mplsLabel(ns.getEdgeLabel()));
        }
        GroupBucket removeBucket = DefaultGroupBucket.createSelectGroupBucket(tBuilder.build());
        GroupBuckets removeBuckets = new GroupBuckets(Arrays.asList(removeBucket));
        log.debug("portDown in device{}: " + "groupService.removeBucketsFromGroup " + "for neighborset{}", deviceId, ns);
        groupService.removeBucketsFromGroup(deviceId, getGroupKey(ns), removeBuckets, getGroupKey(ns), appId);
    }
    devicePortMap.get(portDeviceMap.get(port)).remove(port);
    portDeviceMap.remove(port);
}
#method_after
public void portDown(PortNumber port) {
    if (portDeviceMap.get(port) == null) {
        log.warn("portDown: unknown port");
        return;
    }
    log.debug("Device {} portDown {} to neighbor {}", deviceId, port, portDeviceMap.get(port));
    Set<NeighborSet> nsSet = computeImpactedNeighborsetForPortEvent(portDeviceMap.get(port), devicePortMap.keySet());
    for (NeighborSet ns : nsSet) {
        // Create the bucket to be removed
        TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
        tBuilder.setOutput(port).setEthDst(deviceConfig.getDeviceMac(portDeviceMap.get(port))).setEthSrc(nodeMacAddr);
        if (ns.getEdgeLabel() != NeighborSet.NO_EDGE_LABEL) {
            tBuilder.pushMpls().setMpls(MplsLabel.mplsLabel(ns.getEdgeLabel()));
        }
        GroupBucket removeBucket = DefaultGroupBucket.createSelectGroupBucket(tBuilder.build());
        GroupBuckets removeBuckets = new GroupBuckets(Arrays.asList(removeBucket));
        log.debug("portDown in device{}: " + "groupService.removeBucketsFromGroup " + "for neighborset{}", deviceId, ns);
        groupService.removeBucketsFromGroup(deviceId, getGroupKey(ns), removeBuckets, getGroupKey(ns), appId);
    }
    devicePortMap.get(portDeviceMap.get(port)).remove(port);
    portDeviceMap.remove(port);
}
#end_block

#method_before
protected void createGroupsFromNeighborsets(Set<NeighborSet> nsSet) {
    for (NeighborSet ns : nsSet) {
        // Create the bucket array from the neighbor set
        List<GroupBucket> buckets = new ArrayList<GroupBucket>();
        for (DeviceId d : ns.getDeviceIds()) {
            for (PortNumber sp : devicePortMap.get(d)) {
                TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
                tBuilder.setOutput(sp).setEthDst(deviceConfig.getDeviceMac(d)).setEthSrc(nodeMacAddr);
                if (ns.getEdgeLabel() != -1) {
                    tBuilder.pushMpls().setMpls(MplsLabel.mplsLabel(ns.getEdgeLabel()));
                }
                buckets.add(DefaultGroupBucket.createSelectGroupBucket(tBuilder.build()));
            }
        }
        GroupBuckets groupBuckets = new GroupBuckets(buckets);
        GroupDescription newGroupDesc = new DefaultGroupDescription(deviceId, Group.Type.SELECT, groupBuckets, getGroupKey(ns), appId);
        log.debug("createGroupsFromNeighborsets: " + "groupService.addGroup for neighborset{}", ns);
        groupService.addGroup(newGroupDesc);
    }
}
#method_after
protected void createGroupsFromNeighborsets(Set<NeighborSet> nsSet) {
    for (NeighborSet ns : nsSet) {
        // Create the bucket array from the neighbor set
        List<GroupBucket> buckets = new ArrayList<GroupBucket>();
        for (DeviceId d : ns.getDeviceIds()) {
            for (PortNumber sp : devicePortMap.get(d)) {
                TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
                tBuilder.setOutput(sp).setEthDst(deviceConfig.getDeviceMac(d)).setEthSrc(nodeMacAddr);
                if (ns.getEdgeLabel() != NeighborSet.NO_EDGE_LABEL) {
                    tBuilder.pushMpls().setMpls(MplsLabel.mplsLabel(ns.getEdgeLabel()));
                }
                buckets.add(DefaultGroupBucket.createSelectGroupBucket(tBuilder.build()));
            }
        }
        GroupBuckets groupBuckets = new GroupBuckets(buckets);
        GroupDescription newGroupDesc = new DefaultGroupDescription(deviceId, Group.Type.SELECT, groupBuckets, getGroupKey(ns), appId);
        log.debug("createGroupsFromNeighborsets: " + "groupService.addGroup for neighborset{}", ns);
        groupService.addGroup(newGroupDesc);
    }
}
#end_block

#method_before
@Override
protected void newPortToExistingNeighbor(Link newNeighborLink) {
    log.debug("New port to existing neighbor: Updating " + "groups for transit device {}", deviceId);
    addNeighborAtPort(newNeighborLink.dst().deviceId(), newNeighborLink.src().port());
    Set<NeighborSet> nsSet = computeImpactedNeighborsetForPortEvent(newNeighborLink.dst().deviceId(), devicePortMap.keySet());
    for (NeighborSet ns : nsSet) {
        // Create the new bucket to be updated
        TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
        tBuilder.setOutput(newNeighborLink.src().port()).setEthDst(deviceConfig.getDeviceMac(newNeighborLink.dst().deviceId())).setEthSrc(nodeMacAddr);
        if (ns.getEdgeLabel() != -1) {
            tBuilder.pushMpls().setMpls(MplsLabel.mplsLabel(ns.getEdgeLabel()));
        }
        GroupBucket updatedBucket = DefaultGroupBucket.createSelectGroupBucket(tBuilder.build());
        GroupBuckets updatedBuckets = new GroupBuckets(Arrays.asList(updatedBucket));
        log.debug("newPortToExistingNeighborAtEdgeRouter: " + "groupService.addBucketsToGroup for neighborset{}", ns);
        groupService.addBucketsToGroup(deviceId, getGroupKey(ns), updatedBuckets, getGroupKey(ns), appId);
    }
}
#method_after
@Override
protected void newPortToExistingNeighbor(Link newNeighborLink) {
    log.debug("New port to existing neighbor: Updating " + "groups for transit device {}", deviceId);
    addNeighborAtPort(newNeighborLink.dst().deviceId(), newNeighborLink.src().port());
    Set<NeighborSet> nsSet = computeImpactedNeighborsetForPortEvent(newNeighborLink.dst().deviceId(), devicePortMap.keySet());
    for (NeighborSet ns : nsSet) {
        // Create the new bucket to be updated
        TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
        tBuilder.setOutput(newNeighborLink.src().port()).setEthDst(deviceConfig.getDeviceMac(newNeighborLink.dst().deviceId())).setEthSrc(nodeMacAddr);
        if (ns.getEdgeLabel() != NeighborSet.NO_EDGE_LABEL) {
            tBuilder.pushMpls().setMpls(MplsLabel.mplsLabel(ns.getEdgeLabel()));
        }
        GroupBucket updatedBucket = DefaultGroupBucket.createSelectGroupBucket(tBuilder.build());
        GroupBuckets updatedBuckets = new GroupBuckets(Arrays.asList(updatedBucket));
        log.debug("newPortToExistingNeighborAtEdgeRouter: " + "groupService.addBucketsToGroup for neighborset{}", ns);
        groupService.addBucketsToGroup(deviceId, getGroupKey(ns), updatedBuckets, getGroupKey(ns), appId);
    }
}
#end_block

#method_before
@Override
protected void newPortToExistingNeighbor(Link newNeighborLink) {
    log.debug("New port to existing neighbor: Updating " + "groups for edge device {}", deviceId);
    addNeighborAtPort(newNeighborLink.dst().deviceId(), newNeighborLink.src().port());
    Set<NeighborSet> nsSet = computeImpactedNeighborsetForPortEvent(newNeighborLink.dst().deviceId(), devicePortMap.keySet());
    for (NeighborSet ns : nsSet) {
        // Create the new bucket to be updated
        TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
        tBuilder.setOutput(newNeighborLink.src().port()).setEthDst(deviceConfig.getDeviceMac(newNeighborLink.dst().deviceId())).setEthSrc(nodeMacAddr);
        if (ns.getEdgeLabel() != -1) {
            tBuilder.pushMpls().setMpls(MplsLabel.mplsLabel(ns.getEdgeLabel()));
        }
        GroupBucket updatedBucket = DefaultGroupBucket.createSelectGroupBucket(tBuilder.build());
        GroupBuckets updatedBuckets = new GroupBuckets(Arrays.asList(updatedBucket));
        log.debug("newPortToExistingNeighborAtEdgeRouter: " + "groupService.addBucketsToGroup for neighborset{}", ns);
        groupService.addBucketsToGroup(deviceId, getGroupKey(ns), updatedBuckets, getGroupKey(ns), appId);
    }
}
#method_after
@Override
protected void newPortToExistingNeighbor(Link newNeighborLink) {
    log.debug("New port to existing neighbor: Updating " + "groups for edge device {}", deviceId);
    addNeighborAtPort(newNeighborLink.dst().deviceId(), newNeighborLink.src().port());
    Set<NeighborSet> nsSet = computeImpactedNeighborsetForPortEvent(newNeighborLink.dst().deviceId(), devicePortMap.keySet());
    for (NeighborSet ns : nsSet) {
        // Create the new bucket to be updated
        TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
        tBuilder.setOutput(newNeighborLink.src().port()).setEthDst(deviceConfig.getDeviceMac(newNeighborLink.dst().deviceId())).setEthSrc(nodeMacAddr);
        if (ns.getEdgeLabel() != NeighborSet.NO_EDGE_LABEL) {
            tBuilder.pushMpls().setMpls(MplsLabel.mplsLabel(ns.getEdgeLabel()));
        }
        GroupBucket updatedBucket = DefaultGroupBucket.createSelectGroupBucket(tBuilder.build());
        GroupBuckets updatedBuckets = new GroupBuckets(Arrays.asList(updatedBucket));
        log.debug("newPortToExistingNeighborAtEdgeRouter: " + "groupService.addBucketsToGroup for neighborset{}", ns);
        groupService.addBucketsToGroup(deviceId, getGroupKey(ns), updatedBuckets, getGroupKey(ns), appId);
    }
}
#end_block

#method_before
@Override
public String toString() {
    return MoreObjects.toStringHelper(getClass()).add("id", id()).add("appId", appId()).add("resources", resources()).add("ingressPort", src).add("egressPort", dst).add("path", path).toString();
}
#method_after
@Override
public String toString() {
    return MoreObjects.toStringHelper(getClass()).add("id", id()).add("appId", appId()).add("key", key()).add("resources", resources()).add("ingressPort", src).add("egressPort", dst).add("path", path).toString();
}
#end_block

#method_before
@DELETE
@Path("{appId}/{key}")
public void deleteIntentById(@PathParam("appId") Short appId, @PathParam("key") String keyString) {
    final ApplicationId app = get(CoreService.class).getAppId(appId);
    Intent intent = get(IntentService.class).getIntent(Key.of(keyString, app));
    IntentService service = get(IntentService.class);
    if (intent == null) {
        intent = service.getIntent(Key.of(Long.parseLong(keyString), app));
    }
    if (intent == null) {
        // in this case.
        return;
    }
    Key key = intent.key();
    // set up latch and listener to track uninstall progress
    CountDownLatch latch = new CountDownLatch(1);
    IntentListener listener = new DeleteListener(key, latch);
    service.addListener(listener);
    // request the withdraw
    service.withdraw(intent);
    try {
        latch.await(5, TimeUnit.SECONDS);
    } catch (InterruptedException e) {
        log.info("REST Delete operation timed out waiting for intent {}", key);
    }
    // double check the state
    IntentState state = service.getIntentState(key);
    if ((state == WITHDRAWN || state == FAILED)) {
        service.purge(intent);
    }
    // clean up the listener
    service.removeListener(listener);
}
#method_after
@DELETE
@Path("{appId}/{key}")
public void deleteIntentById(@PathParam("appId") Short appId, @PathParam("key") String keyString) {
    final ApplicationId app = get(CoreService.class).getAppId(appId);
    Intent intent = get(IntentService.class).getIntent(Key.of(keyString, app));
    IntentService service = get(IntentService.class);
    if (intent == null) {
        intent = service.getIntent(Key.of(Long.parseLong(keyString), app));
    }
    if (intent == null) {
        // in this case.
        return;
    }
    Key key = intent.key();
    // set up latch and listener to track uninstall progress
    CountDownLatch latch = new CountDownLatch(1);
    IntentListener listener = new DeleteListener(key, latch);
    service.addListener(listener);
    try {
        // request the withdraw
        service.withdraw(intent);
        try {
            latch.await(WITHDRAW_EVENT_TIMEOUT_SECONDS, TimeUnit.SECONDS);
        } catch (InterruptedException e) {
            log.info("REST Delete operation timed out waiting for intent {}", key);
        }
        // double check the state
        IntentState state = service.getIntentState(key);
        if (state == WITHDRAWN || state == FAILED) {
            service.purge(intent);
        }
    } finally {
        // clean up the listener
        service.removeListener(listener);
    }
}
#end_block

#method_before
@GET
@Produces(MediaType.APPLICATION_JSON)
public Response getFlows() {
    final Iterable<Device> devices = get(DeviceService.class).getDevices();
    for (final Device device : devices) {
        final Iterable<FlowEntry> deviceEntries = service.getFlowEntries(device.id());
        if (deviceEntries != null) {
            for (final FlowEntry entry : deviceEntries) {
                flowsNode.add(codec(FlowRule.class).encode(entry, this));
            }
        }
    }
    return ok(root).build();
}
#method_after
@GET
@Produces(MediaType.APPLICATION_JSON)
public Response getFlows() {
    final Iterable<Device> devices = get(DeviceService.class).getDevices();
    for (final Device device : devices) {
        final Iterable<FlowEntry> deviceEntries = service.getFlowEntries(device.id());
        if (deviceEntries != null) {
            for (final FlowEntry entry : deviceEntries) {
                flowsNode.add(codec(FlowEntry.class).encode(entry, this));
            }
        }
    }
    return ok(root).build();
}
#end_block

#method_before
@GET
@Produces(MediaType.APPLICATION_JSON)
@Path("{deviceId}")
public Response getFlowByDeviceId(@PathParam("deviceId") String deviceId) {
    final Iterable<FlowEntry> deviceEntries = service.getFlowEntries(DeviceId.deviceId(deviceId));
    if (!deviceEntries.iterator().hasNext()) {
        throw new ItemNotFoundException(DEVICE_NOT_FOUND);
    }
    for (final FlowEntry entry : deviceEntries) {
        flowsNode.add(codec(FlowRule.class).encode(entry, this));
    }
    return ok(root).build();
}
#method_after
@GET
@Produces(MediaType.APPLICATION_JSON)
@Path("{deviceId}")
public Response getFlowByDeviceId(@PathParam("deviceId") String deviceId) {
    final Iterable<FlowEntry> deviceEntries = service.getFlowEntries(DeviceId.deviceId(deviceId));
    if (!deviceEntries.iterator().hasNext()) {
        throw new ItemNotFoundException(DEVICE_NOT_FOUND);
    }
    for (final FlowEntry entry : deviceEntries) {
        flowsNode.add(codec(FlowEntry.class).encode(entry, this));
    }
    return ok(root).build();
}
#end_block

#method_before
@GET
@Produces(MediaType.APPLICATION_JSON)
@Path("{deviceId}/{flowId}")
public Response getFlowByDeviceIdAndFlowId(@PathParam("deviceId") String deviceId, @PathParam("flowId") long flowId) {
    final Iterable<FlowEntry> deviceEntries = service.getFlowEntries(DeviceId.deviceId(deviceId));
    if (!deviceEntries.iterator().hasNext()) {
        throw new ItemNotFoundException(DEVICE_NOT_FOUND);
    }
    for (final FlowEntry entry : deviceEntries) {
        if (entry.id().value() == flowId) {
            flowsNode.add(codec(FlowRule.class).encode(entry, this));
        }
    }
    return ok(root).build();
}
#method_after
@GET
@Produces(MediaType.APPLICATION_JSON)
@Path("{deviceId}/{flowId}")
public Response getFlowByDeviceIdAndFlowId(@PathParam("deviceId") String deviceId, @PathParam("flowId") long flowId) {
    final Iterable<FlowEntry> deviceEntries = service.getFlowEntries(DeviceId.deviceId(deviceId));
    if (!deviceEntries.iterator().hasNext()) {
        throw new ItemNotFoundException(DEVICE_NOT_FOUND);
    }
    for (final FlowEntry entry : deviceEntries) {
        if (entry.id().value() == flowId) {
            flowsNode.add(codec(FlowEntry.class).encode(entry, this));
        }
    }
    return ok(root).build();
}
#end_block

#method_before
@Activate
public void activate(ComponentContext context) {
    cfgService.registerProperties(getClass());
    providerService = providerRegistry.register(this);
    modified(context);
    if (!flicker) {
        LinkDriver driver = new LinkDriver(linkDescrs);
        driverMap.computeIfAbsent(DEFAULT, k -> Sets.newConcurrentHashSet()).add(driver);
        linkDriver.schedule(driver, eventRate, TimeUnit.MICROSECONDS);
    }
    log.info("started");
}
#method_after
@Activate
public void activate(ComponentContext context) {
    cfgService.registerProperties(getClass());
    providerService = providerRegistry.register(this);
    modified(context);
    log.info("started");
}
#end_block

#method_before
@Modified
public void modified(ComponentContext context) {
    if (context == null) {
        log.info("No configs, using defaults: eventRate={}", DEFAULT_RATE);
        return;
    }
    Dictionary<?, ?> properties = context.getProperties();
    int newRate;
    String newPath;
    try {
        String s = String.valueOf(properties.get("eventRate"));
        newRate = isNullOrEmpty(s) ? DEFAULT_RATE : Integer.parseInt(s.trim());
        s = (String) properties.get("cfgFile");
        newPath = s.trim();
    } catch (NumberFormatException | ClassCastException e) {
        log.warn(e.getMessage());
        newRate = eventRate;
        newPath = cfgFile;
    }
    // topology file configuration
    if (!newPath.equals(cfgFile)) {
        cfgFile = newPath;
    }
    readGraph(cfgFile, nodeService.getLocalNode().id());
    if (newRate != eventRate) {
        if (eventRate < 0) {
            log.warn("Invalid rate, ignoring and using default");
            eventRate = DEFAULT_RATE;
        } else {
            eventRate = newRate;
        }
    }
    if (eventRate > 0) {
        allocateLinks();
        if (!flicker) {
            // previously not flickering
            flicker = true;
            driverMap.remove(DEFAULT);
            for (int i = 0; i < linkTasks.size(); i++) {
                List<LinkDescription> links = linkTasks.get(i);
                LinkDriver driver = new LinkDriver(links);
                links.forEach(v -> {
                    DeviceId sd = v.src().deviceId();
                    DeviceId dd = v.src().deviceId();
                    driverMap.computeIfAbsent(sd, k -> Sets.newConcurrentHashSet()).add(driver);
                    driverMap.computeIfAbsent(dd, k -> Sets.newConcurrentHashSet()).add(driver);
                });
                try {
                    linkDriver.schedule(driver, eventRate, TimeUnit.MICROSECONDS);
                } catch (Exception e) {
                    log.warn(e.getMessage());
                }
            }
        }
    } else {
        Set<LinkDriver> drivers = driverMap.computeIfAbsent(DEFAULT, k -> Sets.newConcurrentHashSet());
        if (flicker) {
            driverMap.forEach((dev, lds) -> lds.forEach(l -> l.deviceRemoved(dev)));
            driverMap.clear();
            linkTasks.clear();
            flicker = false;
            LinkDriver driver = new LinkDriver(linkDescrs);
            drivers.add(driver);
            try {
                linkDriver.schedule(driver, eventRate, TimeUnit.MICROSECONDS);
            } catch (Exception e) {
                log.warn(e.getMessage());
            }
        } else {
            // update current live thread.
            drivers.forEach(v -> v.setTasks(linkDescrs));
        }
    }
    log.info("Using settings: eventRate={}, topofile={}", eventRate, cfgFile);
}
#method_after
@Modified
public void modified(ComponentContext context) {
    if (context == null) {
        log.info("No configs, using defaults: eventRate={}", DEFAULT_RATE);
        return;
    }
    Dictionary<?, ?> properties = context.getProperties();
    int newRate;
    String newPath;
    try {
        String s = get(properties, "eventRate");
        newRate = isNullOrEmpty(s) ? DEFAULT_RATE : Integer.parseInt(s.trim());
        s = (String) properties.get("cfgFile");
        newPath = isNullOrEmpty(s) ? CFG_PATH : s.trim();
    } catch (NumberFormatException e) {
        log.warn(e.getMessage());
        newRate = eventRate;
        newPath = cfgFile;
    }
    // find/read topology file.
    if (!newPath.equals(cfgFile)) {
        cfgFile = newPath;
    }
    readGraph(cfgFile, nodeService.getLocalNode().id());
    // check for new eventRate settings.
    if (newRate != eventRate) {
        if (eventRate < 0) {
            log.warn("Invalid rate, ignoring and using default");
            eventRate = DEFAULT_RATE;
        } else {
            eventRate = newRate;
        }
    }
    configureWorkers();
    log.info("Using settings: eventRate={}, topofile={}", eventRate, cfgFile);
}
#end_block

#method_before
private void readGraph(String path, NodeId me) {
    log.info("path: {}, local: {}", path, me);
    Set<LinkDescription> read = Sets.newHashSet();
    BufferedReader br = null;
    try {
        br = new BufferedReader(new FileReader(path));
        String cur = br.readLine();
        while (cur != null) {
            if (cur.startsWith("#")) {
                cur = br.readLine();
                continue;
            }
            String[] parts = cur.trim().split(" ");
            if (parts.length < 1) {
                continue;
            }
            if (parts[0].equals("graph")) {
                String node = parts[1].trim();
                if (node.equals(me.toString())) {
                    // move to next line, start of links list
                    cur = br.readLine();
                    while (cur != null) {
                        if (cur.trim().contains("}")) {
                            break;
                        }
                        readLink(cur.trim().split(" "), me, read);
                        cur = br.readLine();
                    }
                } else {
                    while (cur != null) {
                        if (cur.trim().equals("}")) {
                            break;
                        }
                        cur = br.readLine();
                    }
                }
            }
            cur = br.readLine();
        }
    } catch (IOException e) {
        log.warn("Could not find topology file: {}", e);
    } finally {
        try {
            if (br != null) {
                br.close();
            }
        } catch (IOException e) {
            log.warn("Could not close topology file: {}", e);
        }
    }
    synchronized (linkDescrs) {
        if (!read.isEmpty()) {
            linkDescrs.clear();
            linkDescrs.addAll(read);
        }
    }
}
#method_after
private void readGraph(String path, NodeId me) {
    log.info("path: {}, local: {}", path, me);
    Set<LinkDescription> read = Sets.newHashSet();
    BufferedReader br = null;
    try {
        br = Files.newReader(new File(path), Charsets.US_ASCII);
        String cur = br.readLine();
        while (cur != null) {
            if (cur.startsWith("#")) {
                cur = br.readLine();
                continue;
            }
            String[] parts = cur.trim().split(" ");
            if (parts.length < 1) {
                continue;
            }
            if (parts[0].equals("graph")) {
                String node = parts[1].trim();
                if (node.equals(me.toString())) {
                    // move to next line, start of links list
                    cur = br.readLine();
                    while (cur != null) {
                        if (cur.trim().contains("}")) {
                            break;
                        }
                        readLink(cur.trim().split(" "), me, read);
                        cur = br.readLine();
                    }
                } else {
                    while (cur != null) {
                        if (cur.trim().equals("}")) {
                            break;
                        }
                        cur = br.readLine();
                    }
                }
            }
            cur = br.readLine();
        }
    } catch (IOException e) {
        log.warn("Could not find topology file: {}", e);
    } finally {
        try {
            if (br != null) {
                br.close();
            }
        } catch (IOException e) {
            log.warn("Could not close topology file: {}", e);
        }
    }
    synchronized (linkDescrs) {
        if (!read.isEmpty()) {
            linkDescrs.clear();
            linkDescrs.addAll(read);
        }
    }
}
#end_block

#method_before
private DeviceId recover(String base, NodeId node) {
    long hash = node.hashCode() << 16;
    int dev = Integer.valueOf(base);
    try {
        return DeviceId.deviceId(new URI("null", toHex(hash | dev), null));
    } catch (URISyntaxException e) {
        log.warn("could not create a DeviceID for descriptor {}", dev);
        return DeviceId.NONE;
    }
}
#method_after
private DeviceId recover(String base, NodeId node) {
    long hash = node.hashCode() << 16;
    int dev = Integer.parseInt(base);
    try {
        return DeviceId.deviceId(new URI("null", toHex(hash | dev), null));
    } catch (URISyntaxException e) {
        log.warn("could not create a DeviceID for descriptor {}", dev);
        return DeviceId.NONE;
    }
}
#end_block

#method_before
private void allocateLinks() {
    int index, lcount = 0;
    for (LinkDescription ld : linkDescrs) {
        index = (lcount % THREADS);
        log.info("allocation: total={}, index={}", linkDescrs.size(), lcount, index);
        if (linkTasks.size() <= index) {
            linkTasks.add(index, Lists.newArrayList(ld));
        } else {
            linkTasks.get(index).add(ld);
        }
        lcount++;
    }
}
#method_after
private void allocateLinks() {
    int index, lcount = 0;
    linkTasks.clear();
    for (LinkDescription ld : linkDescrs) {
        index = (lcount % THREADS);
        log.info("allocation: total={}, index={}", linkDescrs.size(), lcount, index);
        if (linkTasks.size() <= index) {
            linkTasks.add(index, Lists.newArrayList(ld));
        } else {
            linkTasks.get(index).add(ld);
        }
        lcount++;
    }
}
#end_block

#method_before
public void setTasks(List<LinkDescription> links) {
    HashMultimap<ConnectPoint, ConnectPoint> nm = HashMultimap.create();
    links.forEach(v -> nm.put(v.src(), v.dst()));
    // remove and send linkVanished for stale links.
    for (LinkDescription l : tasks) {
        if (!nm.containsEntry(l.src(), l.dst())) {
            providerService.linkVanished(l);
        }
    }
    tasks.clear();
    tasks.addAll(links);
}
#method_after
public void setTasks(List<LinkDescription> links) {
    HashMultimap<ConnectPoint, ConnectPoint> nm = HashMultimap.create();
    List<LinkDescription> rm = Lists.newArrayList();
    links.forEach(v -> nm.put(v.src(), v.dst()));
    // remove and send linkVanished for stale links.
    for (LinkDescription l : tasks) {
        if (!nm.containsEntry(l.src(), l.dst())) {
            rm.add(l);
        }
    }
    tasks.clear();
    tasks.addAll(links);
    rm.forEach(l -> providerService.linkVanished(l));
}
#end_block

#method_before
@Modified
public boolean modified(ComponentContext context) {
    if (context == null) {
        log.info("No configuration file, using defaults: numDevices={}, numPorts={}", numDevices, numPorts);
        return false;
    }
    Dictionary<?, ?> properties = context.getProperties();
    int newDevNum = DEF_NUMDEVICES;
    int newPortNum = DEF_NUMPORTS;
    try {
        String s = (String) properties.get("devConfigs");
        if (!isNullOrEmpty(s)) {
            newDevNum = getDevicesConfig(s);
        }
        s = String.valueOf(properties.get("numPorts"));
        newPortNum = isNullOrEmpty(s) ? DEF_NUMPORTS : Integer.parseInt(s.trim());
    } catch (NumberFormatException | ClassCastException e) {
        log.warn(e.getMessage());
        newDevNum = numDevices;
        newPortNum = numPorts;
    }
    boolean chgd = false;
    if (newDevNum != numDevices) {
        numDevices = newDevNum;
        chgd |= true;
    }
    if (newPortNum != numPorts) {
        numPorts = newPortNum;
        chgd |= true;
    }
    log.info("Using settings numDevices={}, numPorts={}", numDevices, numPorts);
    if (chgd) {
        deviceBuilder.submit(new DeviceCreator(true));
    }
    return chgd;
}
#method_after
@Modified
public boolean modified(ComponentContext context) {
    if (context == null) {
        log.info("No configuration file, using defaults: numDevices={}, numPorts={}", numDevices, numPorts);
        return false;
    }
    Dictionary<?, ?> properties = context.getProperties();
    int newDevNum = DEF_NUMDEVICES;
    int newPortNum = DEF_NUMPORTS;
    try {
        String s = get(properties, "devConfigs");
        if (!isNullOrEmpty(s)) {
            newDevNum = getDevicesConfig(s);
        }
        s = get(properties, "numPorts");
        newPortNum = isNullOrEmpty(s) ? DEF_NUMPORTS : Integer.parseInt(s.trim());
    } catch (NumberFormatException e) {
        log.warn(e.getMessage());
        newDevNum = numDevices;
        newPortNum = numPorts;
    }
    boolean chgd = false;
    if (newDevNum != numDevices) {
        numDevices = newDevNum;
        chgd |= true;
    }
    if (newPortNum != numPorts) {
        numPorts = newPortNum;
        chgd |= true;
    }
    log.info("Using settings numDevices={}, numPorts={}", numDevices, numPorts);
    if (chgd) {
        deviceBuilder.submit(new DeviceCreator(true));
    }
    return chgd;
}
#end_block

#method_before
@Activate
public void activate() {
    this.nodeId = clusterService.getLocalNode().id();
    this.oldestTime = 0;
    this.newestTime = 0;
    messageHandlingExecutor = Executors.newSingleThreadExecutor(groupedThreads("onos/store/app", "message-handler"));
    communicationService.addSubscriber(SAMPLE, new InternalSampleCollector(), messageHandlingExecutor);
    nodes = clusterService.getNodes().toArray(new ControllerNode[] {});
    Arrays.sort(nodes, (a, b) -> a.id().toString().compareTo(b.id().toString()));
    nodeToIndex = new HashMap<>();
    for (int i = 0; i < nodes.length; i++) {
        nodeToIndex.put(nodes[i].id(), i);
    }
    overall = new Sample(0, nodes.length);
    current = new Sample(0, nodes.length);
    log.info("Started");
}
#method_after
@Activate
public void activate() {
    this.nodeId = clusterService.getLocalNode().id();
    this.newestTime = 0;
    messageHandlingExecutor = Executors.newSingleThreadExecutor(groupedThreads("onos/perf", "message-handler"));
    communicationService.addSubscriber(SAMPLE, new InternalSampleCollector(), messageHandlingExecutor);
    nodes = clusterService.getNodes().toArray(new ControllerNode[] {});
    Arrays.sort(nodes, (a, b) -> a.id().toString().compareTo(b.id().toString()));
    nodeToIndex = new HashMap<>();
    for (int i = 0; i < nodes.length; i++) {
        nodeToIndex.put(nodes[i].id(), i);
    }
    overall = new Sample(0, nodes.length);
    current = new Sample(0, nodes.length);
    log.info("Started");
}
#end_block

#method_before
public List<Sample> getSamples() {
    return ImmutableList.copyOf(samples);
}
#method_after
public synchronized List<Sample> getSamples() {
    return ImmutableList.copyOf(samples);
}
#end_block

#method_before
private void pruneSamplesIfNeeded() {
    if (samples.size() > MAX_SAMPLES) {
        samples.remove(0);
        oldestTime = samples.get(0).time;
    }
}
#method_after
private void pruneSamplesIfNeeded() {
    if (samples.size() > MAX_SAMPLES) {
        samples.remove(0);
    }
}
#end_block

#method_before
@Override
public void purge(Intent intent) {
    checkNotNull(intent, INTENT_NULL);
    IntentData data = new IntentData(intent, IntentState.PURGE_REQ, null);
    store.addPending(data);
// FIXME remove!
// store.purge(key);
}
#method_after
@Override
public void purge(Intent intent) {
    checkNotNull(intent, INTENT_NULL);
    IntentData data = new IntentData(intent, IntentState.PURGE_REQ, null);
    store.addPending(data);
}
#end_block

#method_before
@Override
public void remove(K key, V value) {
    checkState(!destroyed, destroyedMessage);
    checkNotNull(key, ERROR_NULL_KEY);
    checkNotNull(value, ERROR_NULL_VALUE);
    Timestamp timestamp = clockService.getTimestamp(key, value);
    if (removeInternal(key, timestamp)) {
        notifyPeers(new RemoveEntry<>(key, timestamp), peerUpdateFunction.apply(key, value));
        notifyListeners(new EventuallyConsistentMapEvent<>(EventuallyConsistentMapEvent.Type.REMOVE, key, value));
    } else {
        // TODO remove this extra call when ONOS-1207 is resolved
        Timestamped<V> latest = (Timestamped) get(key);
        log.info("Remove of intent {} failed; request time {} vs. latest time {}", key, timestamp, latest.timestamp());
    }
}
#method_after
@Override
public void remove(K key, V value) {
    checkState(!destroyed, destroyedMessage);
    checkNotNull(key, ERROR_NULL_KEY);
    checkNotNull(value, ERROR_NULL_VALUE);
    Timestamp timestamp = clockService.getTimestamp(key, value);
    if (removeInternal(key, timestamp)) {
        notifyPeers(new RemoveEntry<>(key, timestamp), peerUpdateFunction.apply(key, value));
        notifyListeners(new EventuallyConsistentMapEvent<>(EventuallyConsistentMapEvent.Type.REMOVE, key, value));
    } else {
        // TODO remove this extra call when ONOS-1207 is resolved
        Timestamped<V> latest = (Timestamped) items.get(key);
        log.info("Remove of intent {} failed; request time {} vs. latest time {}", key, timestamp, latest.timestamp());
    }
}
#end_block

#method_before
@Override
protected void execute() {
    IntentService intentService = get(IntentService.class);
    CoreService coreService = get(CoreService.class);
    ApplicationId appId = appId();
    if (applicationIdString != null) {
        appId = coreService.getAppId(applicationIdString);
        if (appId == null) {
            print("Cannot find application Id %s", applicationIdString);
            return;
        }
    }
    if (id.startsWith("0x")) {
        id = id.replaceFirst("0x", "");
    }
    Key key = Key.of(new BigInteger(id, 16).longValue(), appId);
    Intent intent = intentService.getIntent(key);
    if (intent != null) {
        // set up latch and listener to track uninstall progress
        CountDownLatch latch = new CountDownLatch(1);
        IntentListener listener = (IntentEvent event) -> {
            if (Objects.equals(event.subject().key(), key) && (event.type() == IntentEvent.Type.WITHDRAWN || event.type() == IntentEvent.Type.FAILED)) {
                latch.countDown();
            }
        };
        intentService.addListener(listener);
        // request the withdraw
        intentService.withdraw(intent);
        if (purgeAfterRemove || sync) {
            try {
                latch.await(5, TimeUnit.SECONDS);
            } catch (InterruptedException e) {
                print("Timed out waiting for intent {}", key);
            }
            // double check the state
            IntentState state = intentService.getIntentState(key);
            if (purgeAfterRemove && (state == WITHDRAWN || state == FAILED)) {
                intentService.removeListener(listener);
                listener = (IntentEvent event) -> {
                    if (Objects.equals(event.subject().key(), key) && (event.type() == IntentEvent.Type.PURGED)) {
                        latch.countDown();
                    }
                };
                intentService.addListener(listener);
                intentService.purge(intent);
            }
        }
        if (sync) {
            try {
                latch.await(5, TimeUnit.SECONDS);
            } catch (InterruptedException e) {
                print("Timed out waiting for intent {}", key);
            }
        }
        // clean up the listener
        intentService.removeListener(listener);
    }
}
#method_after
@Override
protected void execute() {
    IntentService intentService = get(IntentService.class);
    CoreService coreService = get(CoreService.class);
    ApplicationId appId = appId();
    if (applicationIdString != null) {
        appId = coreService.getAppId(applicationIdString);
        if (appId == null) {
            print("Cannot find application Id %s", applicationIdString);
            return;
        }
    }
    if (id.startsWith("0x")) {
        id = id.replaceFirst("0x", "");
    }
    Key key = Key.of(new BigInteger(id, 16).longValue(), appId);
    Intent intent = intentService.getIntent(key);
    if (intent != null) {
        IntentListener listener = null;
        final CountDownLatch withdrawLatch, purgeLatch;
        if (purgeAfterRemove || sync) {
            // set up latch and listener to track uninstall progress
            withdrawLatch = new CountDownLatch(1);
            purgeLatch = purgeAfterRemove ? new CountDownLatch(1) : null;
            listener = (IntentEvent event) -> {
                if (Objects.equals(event.subject().key(), key)) {
                    if (event.type() == IntentEvent.Type.WITHDRAWN || event.type() == IntentEvent.Type.FAILED) {
                        withdrawLatch.countDown();
                    } else if (purgeAfterRemove && event.type() == IntentEvent.Type.PURGED) {
                        purgeLatch.countDown();
                    }
                }
            };
            intentService.addListener(listener);
        } else {
            purgeLatch = null;
            withdrawLatch = null;
        }
        // request the withdraw
        intentService.withdraw(intent);
        if (purgeAfterRemove || sync) {
            try {
                // wait for withdraw event
                withdrawLatch.await(5, TimeUnit.SECONDS);
            } catch (InterruptedException e) {
                print("Timed out waiting for intent {} withdraw", key);
            }
            // double check the state
            IntentState state = intentService.getIntentState(key);
            if (purgeAfterRemove && (state == WITHDRAWN || state == FAILED)) {
                intentService.purge(intent);
            }
            if (sync) {
                /* TODO
                       Technically, the event comes before map.remove() is called.
                       If we depend on sync and purge working together, we will
                       need to address this.
                    */
                try {
                    purgeLatch.await(5, TimeUnit.SECONDS);
                } catch (InterruptedException e) {
                    print("Timed out waiting for intent {} purge", key);
                }
            }
        }
        if (listener != null) {
            // clean up the listener
            intentService.removeListener(listener);
        }
    }
}
#end_block

#method_before
@Override
public IntentData data() {
    if (shouldAcceptPurge()) {
        return pending;
    } else {
        return null;
    // or
    // return current;
    }
}
#method_after
@Override
public IntentData data() {
    if (shouldAcceptPurge()) {
        return pending;
    } else {
        return current;
    }
}
#end_block

#method_before
@Override
public String toString() {
    return subtype().toString();
}
#method_after
@Override
public String toString() {
    return toStringHelper(subtype().toString()).toString();
}
#end_block

#method_before
@Override
public boolean equals(Object obj) {
    if (this == obj) {
        return true;
    }
    return false;
}
#method_after
@Override
public boolean equals(Object obj) {
    if (this == obj) {
        return true;
    }
    if (obj instanceof StripVlanInstruction) {
        return true;
    }
    return false;
}
#end_block

#method_before
private ConnectPoint buildConnectPoint(FlowRule rule) {
    PortNumber port = getOutput(rule);
    boolean hasGoto = rule.treatment().allInstructions().stream().anyMatch(i -> (i instanceof Instructions.GroupInstruction) || (i instanceof Instructions.TableTypeTransition));
    hasGoto = hasGoto || rule.treatment().tableTransition() != null;
    if (port == null) {
        if (!hasGoto) {
            log.debug("Rule {} has no output.", rule);
        }
        return null;
    }
    ConnectPoint cp = new ConnectPoint(rule.deviceId(), port);
    return cp;
}
#method_after
private ConnectPoint buildConnectPoint(FlowRule rule) {
    PortNumber port = getOutput(rule);
    if (port == null) {
        return null;
    }
    ConnectPoint cp = new ConnectPoint(rule.deviceId(), port);
    return cp;
}
#end_block

#method_before
private TrafficTreatment buildTreatment(List<OFAction> actions) {
    TrafficTreatment.Builder builder = DefaultTrafficTreatment.builder();
    // If this is a drop rule
    if (actions.size() == 0) {
        builder.drop();
        return builder.build();
    }
    for (OFAction act : actions) {
        switch(act.getType()) {
            case OUTPUT:
                OFActionOutput out = (OFActionOutput) act;
                builder.setOutput(PortNumber.portNumber(out.getPort().getPortNumber()));
                break;
            case SET_VLAN_VID:
                OFActionSetVlanVid vlan = (OFActionSetVlanVid) act;
                builder.setVlanId(VlanId.vlanId(vlan.getVlanVid().getVlan()));
                break;
            case SET_VLAN_PCP:
                OFActionSetVlanPcp pcp = (OFActionSetVlanPcp) act;
                builder.setVlanPcp(pcp.getVlanPcp().getValue());
                break;
            case SET_DL_DST:
                OFActionSetDlDst dldst = (OFActionSetDlDst) act;
                builder.setEthDst(MacAddress.valueOf(dldst.getDlAddr().getLong()));
                break;
            case SET_DL_SRC:
                OFActionSetDlSrc dlsrc = (OFActionSetDlSrc) act;
                builder.setEthSrc(MacAddress.valueOf(dlsrc.getDlAddr().getLong()));
                break;
            case SET_NW_DST:
                OFActionSetNwDst nwdst = (OFActionSetNwDst) act;
                IPv4Address di = nwdst.getNwAddr();
                builder.setIpDst(Ip4Address.valueOf(di.getInt()));
                break;
            case SET_NW_SRC:
                OFActionSetNwSrc nwsrc = (OFActionSetNwSrc) act;
                IPv4Address si = nwsrc.getNwAddr();
                builder.setIpSrc(Ip4Address.valueOf(si.getInt()));
                break;
            case EXPERIMENTER:
                OFActionExperimenter exp = (OFActionExperimenter) act;
                if (exp.getExperimenter() == 0x80005A06 || exp.getExperimenter() == 0x748771) {
                    OFActionCircuit ct = (OFActionCircuit) exp;
                    builder.setLambda(((OFOxmOchSigidBasic) ct.getField()).getValue().getChannelNumber());
                } else {
                    log.warn("Unsupported OFActionExperimenter {}", exp.getExperimenter());
                }
                break;
            case SET_FIELD:
                OFActionSetField setField = (OFActionSetField) act;
                handleSetField(builder, setField.getField());
                break;
            case POP_MPLS:
                OFActionPopMpls popMpls = (OFActionPopMpls) act;
                builder.popMpls((short) popMpls.getEthertype().getValue());
                break;
            case PUSH_MPLS:
                OFActionPushMpls pushMpls = (OFActionPushMpls) act;
                builder.pushMpls();
                break;
            case COPY_TTL_IN:
                OFActionCopyTtlIn copyTtlIn = (OFActionCopyTtlIn) act;
                builder.copyTtlIn();
                break;
            case COPY_TTL_OUT:
                OFActionCopyTtlOut copyTtlOut = (OFActionCopyTtlOut) act;
                builder.copyTtlOut();
                break;
            case DEC_MPLS_TTL:
                OFActionDecMplsTtl decMplsTtl = (OFActionDecMplsTtl) act;
                builder.decMplsTtl();
                break;
            case DEC_NW_TTL:
                OFActionDecNwTtl decNwTtl = (OFActionDecNwTtl) act;
                builder.decNwTtl();
                break;
            case SET_TP_DST:
            case SET_TP_SRC:
            case POP_PBB:
            case POP_VLAN:
            case PUSH_PBB:
            case PUSH_VLAN:
            case SET_MPLS_LABEL:
            case SET_MPLS_TC:
            case SET_MPLS_TTL:
            case SET_NW_ECN:
            case SET_NW_TOS:
            case SET_NW_TTL:
            case SET_QUEUE:
            case STRIP_VLAN:
            case ENQUEUE:
            case GROUP:
            default:
                log.warn("Action type {} not yet implemented.", act.getType());
        }
    }
    return builder.build();
}
#method_after
private TrafficTreatment buildTreatment(List<OFAction> actions) {
    TrafficTreatment.Builder builder = DefaultTrafficTreatment.builder();
    // If this is a drop rule
    if (actions.size() == 0) {
        builder.drop();
        return builder.build();
    }
    for (OFAction act : actions) {
        switch(act.getType()) {
            case OUTPUT:
                OFActionOutput out = (OFActionOutput) act;
                builder.setOutput(PortNumber.portNumber(out.getPort().getPortNumber()));
                break;
            case SET_VLAN_VID:
                OFActionSetVlanVid vlan = (OFActionSetVlanVid) act;
                builder.setVlanId(VlanId.vlanId(vlan.getVlanVid().getVlan()));
                break;
            case SET_VLAN_PCP:
                OFActionSetVlanPcp pcp = (OFActionSetVlanPcp) act;
                builder.setVlanPcp(pcp.getVlanPcp().getValue());
                break;
            case POP_VLAN:
                builder.popVlan();
                break;
            case PUSH_VLAN:
                builder.pushVlan();
                break;
            case SET_DL_DST:
                OFActionSetDlDst dldst = (OFActionSetDlDst) act;
                builder.setEthDst(MacAddress.valueOf(dldst.getDlAddr().getLong()));
                break;
            case SET_DL_SRC:
                OFActionSetDlSrc dlsrc = (OFActionSetDlSrc) act;
                builder.setEthSrc(MacAddress.valueOf(dlsrc.getDlAddr().getLong()));
                break;
            case SET_NW_DST:
                OFActionSetNwDst nwdst = (OFActionSetNwDst) act;
                IPv4Address di = nwdst.getNwAddr();
                builder.setIpDst(Ip4Address.valueOf(di.getInt()));
                break;
            case SET_NW_SRC:
                OFActionSetNwSrc nwsrc = (OFActionSetNwSrc) act;
                IPv4Address si = nwsrc.getNwAddr();
                builder.setIpSrc(Ip4Address.valueOf(si.getInt()));
                break;
            case EXPERIMENTER:
                OFActionExperimenter exp = (OFActionExperimenter) act;
                if (exp.getExperimenter() == 0x80005A06 || exp.getExperimenter() == 0x748771) {
                    OFActionCircuit ct = (OFActionCircuit) exp;
                    builder.setLambda(((OFOxmOchSigidBasic) ct.getField()).getValue().getChannelNumber());
                } else {
                    log.warn("Unsupported OFActionExperimenter {}", exp.getExperimenter());
                }
                break;
            case SET_FIELD:
                OFActionSetField setField = (OFActionSetField) act;
                handleSetField(builder, setField.getField());
                break;
            case POP_MPLS:
                OFActionPopMpls popMpls = (OFActionPopMpls) act;
                builder.popMpls((short) popMpls.getEthertype().getValue());
                break;
            case PUSH_MPLS:
                OFActionPushMpls pushMpls = (OFActionPushMpls) act;
                builder.pushMpls();
                break;
            case COPY_TTL_IN:
                OFActionCopyTtlIn copyTtlIn = (OFActionCopyTtlIn) act;
                builder.copyTtlIn();
                break;
            case COPY_TTL_OUT:
                OFActionCopyTtlOut copyTtlOut = (OFActionCopyTtlOut) act;
                builder.copyTtlOut();
                break;
            case DEC_MPLS_TTL:
                OFActionDecMplsTtl decMplsTtl = (OFActionDecMplsTtl) act;
                builder.decMplsTtl();
                break;
            case DEC_NW_TTL:
                OFActionDecNwTtl decNwTtl = (OFActionDecNwTtl) act;
                builder.decNwTtl();
                break;
            case SET_TP_DST:
            case SET_TP_SRC:
            case POP_PBB:
            case PUSH_PBB:
            case SET_MPLS_LABEL:
            case SET_MPLS_TC:
            case SET_MPLS_TTL:
            case SET_NW_ECN:
            case SET_NW_TOS:
            case SET_NW_TTL:
            case SET_QUEUE:
            case STRIP_VLAN:
            case ENQUEUE:
            case GROUP:
            default:
                log.warn("Action type {} not yet implemented.", act.getType());
        }
    }
    return builder.build();
}
#end_block

#method_before
@Override
@Activate
public void activate() {
    flowTable = new InternalFlowTable();
    super.serializer = SERIALIZER;
    super.theInstance = storeService.getHazelcastInstance();
    idGenerator = coreService.getIdGenerator(FlowRuleService.FLOW_OP_TOPIC);
    final NodeId local = clusterService.getLocalNode().id();
    messageHandlingExecutor = Executors.newFixedThreadPool(MESSAGE_HANDLER_THREAD_POOL_SIZE, groupedThreads("onos/store/flow", "message-handlers"));
    clusterCommunicator.addSubscriber(APPLY_BATCH_FLOWS, new OnStoreBatch(local), messageHandlingExecutor);
    clusterCommunicator.addSubscriber(REMOTE_APPLY_COMPLETED, new ClusterMessageHandler() {

        @Override
        public void handle(ClusterMessage message) {
            FlowRuleBatchEvent event = SERIALIZER.decode(message.payload());
            log.trace("received completed notification for {}", event);
            notifyDelegate(event);
        }
    }, messageHandlingExecutor);
    clusterCommunicator.addSubscriber(GET_FLOW_ENTRY, new ClusterMessageHandler() {

        @Override
        public void handle(ClusterMessage message) {
            FlowRule rule = SERIALIZER.decode(message.payload());
            log.trace("received get flow entry request for {}", rule);
            // getFlowEntryInternal(rule);
            FlowEntry flowEntry = flowTable.getFlowEntry(rule);
            try {
                message.respond(SERIALIZER.encode(flowEntry));
            } catch (IOException e) {
                log.error("Failed to respond back", e);
            }
        }
    }, messageHandlingExecutor);
    clusterCommunicator.addSubscriber(GET_DEVICE_FLOW_ENTRIES, new ClusterMessageHandler() {

        @Override
        public void handle(ClusterMessage message) {
            DeviceId deviceId = SERIALIZER.decode(message.payload());
            log.trace("Received get flow entries request for {} from {}", deviceId, message.sender());
            Set<FlowEntry> flowEntries = flowTable.getFlowEntries(deviceId);
            try {
                message.respond(SERIALIZER.encode(flowEntries));
            } catch (IOException e) {
                log.error("Failed to respond to peer's getFlowEntries request", e);
            }
        }
    }, messageHandlingExecutor);
    clusterCommunicator.addSubscriber(REMOVE_FLOW_ENTRY, new ClusterMessageHandler() {

        @Override
        public void handle(ClusterMessage message) {
            FlowEntry rule = SERIALIZER.decode(message.payload());
            log.trace("received get flow entry request for {}", rule);
            FlowRuleEvent event = removeFlowRuleInternal(rule);
            try {
                message.respond(SERIALIZER.encode(event));
            } catch (IOException e) {
                log.error("Failed to respond back", e);
            }
        }
    }, messageHandlingExecutor);
    replicaInfoEventListener = new InternalReplicaInfoEventListener();
    replicaInfoManager.addListener(replicaInfoEventListener);
    log.info("Started");
}
#method_after
@Activate
public void activate() {
    flowTable = new InternalFlowTable();
    idGenerator = coreService.getIdGenerator(FlowRuleService.FLOW_OP_TOPIC);
    final NodeId local = clusterService.getLocalNode().id();
    messageHandlingExecutor = Executors.newFixedThreadPool(MESSAGE_HANDLER_THREAD_POOL_SIZE, groupedThreads("onos/store/flow", "message-handlers"));
    clusterCommunicator.addSubscriber(APPLY_BATCH_FLOWS, new OnStoreBatch(local), messageHandlingExecutor);
    clusterCommunicator.addSubscriber(REMOTE_APPLY_COMPLETED, new ClusterMessageHandler() {

        @Override
        public void handle(ClusterMessage message) {
            FlowRuleBatchEvent event = SERIALIZER.decode(message.payload());
            log.trace("received completed notification for {}", event);
            notifyDelegate(event);
        }
    }, messageHandlingExecutor);
    clusterCommunicator.addSubscriber(GET_FLOW_ENTRY, new ClusterMessageHandler() {

        @Override
        public void handle(ClusterMessage message) {
            FlowRule rule = SERIALIZER.decode(message.payload());
            log.trace("received get flow entry request for {}", rule);
            // getFlowEntryInternal(rule);
            FlowEntry flowEntry = flowTable.getFlowEntry(rule);
            try {
                message.respond(SERIALIZER.encode(flowEntry));
            } catch (IOException e) {
                log.error("Failed to respond back", e);
            }
        }
    }, messageHandlingExecutor);
    clusterCommunicator.addSubscriber(GET_DEVICE_FLOW_ENTRIES, new ClusterMessageHandler() {

        @Override
        public void handle(ClusterMessage message) {
            DeviceId deviceId = SERIALIZER.decode(message.payload());
            log.trace("Received get flow entries request for {} from {}", deviceId, message.sender());
            Set<StoredFlowEntry> flowEntries = flowTable.getFlowEntries(deviceId);
            try {
                message.respond(SERIALIZER.encode(flowEntries));
            } catch (IOException e) {
                log.error("Failed to respond to peer's getFlowEntries request", e);
            }
        }
    }, messageHandlingExecutor);
    clusterCommunicator.addSubscriber(REMOVE_FLOW_ENTRY, new ClusterMessageHandler() {

        @Override
        public void handle(ClusterMessage message) {
            FlowEntry rule = SERIALIZER.decode(message.payload());
            log.trace("received get flow entry request for {}", rule);
            FlowRuleEvent event = removeFlowRuleInternal(rule);
            try {
                message.respond(SERIALIZER.encode(event));
            } catch (IOException e) {
                log.error("Failed to respond back", e);
            }
        }
    }, messageHandlingExecutor);
    replicaInfoEventListener = new InternalReplicaInfoEventListener();
    replicaInfoManager.addListener(replicaInfoEventListener);
    log.info("Started");
}
#end_block

#method_before
@Override
public Iterable<FlowEntry> getFlowEntries(DeviceId deviceId) {
    ReplicaInfo replicaInfo = replicaInfoManager.getReplicaInfoFor(deviceId);
    if (!replicaInfo.master().isPresent()) {
        log.warn("Failed to getFlowEntries: No master for {}", deviceId);
        return Collections.emptyList();
    }
    if (replicaInfo.master().get().equals(clusterService.getLocalNode().id())) {
        return flowTable.getFlowEntries(deviceId);
    }
    log.trace("Forwarding getFlowEntries to {}, which is the primary (master) for device {}", replicaInfo.master().orNull(), deviceId);
    ClusterMessage message = new ClusterMessage(clusterService.getLocalNode().id(), GET_DEVICE_FLOW_ENTRIES, SERIALIZER.encode(deviceId));
    try {
        Future<byte[]> responseFuture = clusterCommunicator.sendAndReceive(message, replicaInfo.master().get());
        return SERIALIZER.decode(responseFuture.get(FLOW_RULE_STORE_TIMEOUT_MILLIS, TimeUnit.MILLISECONDS));
    } catch (IOException | TimeoutException | ExecutionException | InterruptedException e) {
        log.warn("Unable to fetch flow store contents from {}", replicaInfo.master().get());
    }
    return Collections.emptyList();
}
#method_after
@Override
public Iterable<FlowEntry> getFlowEntries(DeviceId deviceId) {
    ReplicaInfo replicaInfo = replicaInfoManager.getReplicaInfoFor(deviceId);
    if (!replicaInfo.master().isPresent()) {
        log.warn("Failed to getFlowEntries: No master for {}", deviceId);
        return Collections.emptyList();
    }
    if (replicaInfo.master().get().equals(clusterService.getLocalNode().id())) {
        return flowTable.getFlowEntries(deviceId).stream().collect(Collectors.toSet());
    }
    log.trace("Forwarding getFlowEntries to {}, which is the primary (master) for device {}", replicaInfo.master().orNull(), deviceId);
    ClusterMessage message = new ClusterMessage(clusterService.getLocalNode().id(), GET_DEVICE_FLOW_ENTRIES, SERIALIZER.encode(deviceId));
    try {
        Future<byte[]> responseFuture = clusterCommunicator.sendAndReceive(message, replicaInfo.master().get());
        return SERIALIZER.decode(responseFuture.get(FLOW_RULE_STORE_TIMEOUT_MILLIS, TimeUnit.MILLISECONDS));
    } catch (IOException | TimeoutException | ExecutionException | InterruptedException e) {
        log.warn("Unable to fetch flow store contents from {}", replicaInfo.master().get());
    }
    return Collections.emptyList();
}
#end_block

#method_before
@Override
public FlowRuleEvent addOrUpdateFlowRule(FlowEntry rule) {
    ReplicaInfo replicaInfo = replicaInfoManager.getReplicaInfoFor(rule.deviceId());
    final NodeId localId = clusterService.getLocalNode().id();
    if (localId.equals(replicaInfo.master().orNull())) {
        return addOrUpdateFlowRuleInternal(rule);
    }
    log.warn("Tried to update FlowRule {} state," + " while the Node was not the master.", rule);
    return null;
}
#method_after
@Override
public FlowRuleEvent addOrUpdateFlowRule(FlowEntry rule) {
    ReplicaInfo replicaInfo = replicaInfoManager.getReplicaInfoFor(rule.deviceId());
    final NodeId localId = clusterService.getLocalNode().id();
    if (localId.equals(replicaInfo.master().orNull())) {
        return addOrUpdateFlowRuleInternal((StoredFlowEntry) rule);
    }
    log.warn("Tried to update FlowRule {} state," + " while the Node was not the master.", rule);
    return null;
}
#end_block

#method_before
private FlowRuleEvent addOrUpdateFlowRuleInternal(FlowEntry rule) {
    // check if this new rule is an update to an existing entry
    StoredFlowEntry stored = flowTable.getFlowEntry(rule);
    if (stored != null) {
        stored.setBytes(rule.bytes());
        stored.setLife(rule.life());
        stored.setPackets(rule.packets());
        if (stored.state() == FlowEntryState.PENDING_ADD) {
            stored.setState(FlowEntryState.ADDED);
            return new FlowRuleEvent(Type.RULE_ADDED, rule);
        }
        return new FlowRuleEvent(Type.RULE_UPDATED, rule);
    }
    // TODO: Confirm if this behavior is correct. See SimpleFlowRuleStore
    flowTable.add(rule);
    return null;
}
#method_after
private FlowRuleEvent addOrUpdateFlowRuleInternal(StoredFlowEntry rule) {
    // check if this new rule is an update to an existing entry
    StoredFlowEntry stored = flowTable.getFlowEntry(rule);
    if (stored != null) {
        stored.setBytes(rule.bytes());
        stored.setLife(rule.life());
        stored.setPackets(rule.packets());
        if (stored.state() == FlowEntryState.PENDING_ADD) {
            stored.setState(FlowEntryState.ADDED);
            return new FlowRuleEvent(Type.RULE_ADDED, rule);
        }
        return new FlowRuleEvent(Type.RULE_UPDATED, rule);
    }
    // TODO: Confirm if this behavior is correct. See SimpleFlowRuleStore
    flowTable.add(rule);
    return null;
}
#end_block

#method_before
private Set<FlowEntry> getFlowEntriesInternal(DeviceId deviceId) {
    return flowEntries.computeIfAbsent(deviceId, key -> Maps.newConcurrentMap()).values().stream().flatMap(Set::stream).collect(Collectors.toSet());
}
#method_after
private Set<StoredFlowEntry> getFlowEntriesInternal(DeviceId deviceId) {
    Set<StoredFlowEntry> entries = Sets.newHashSet();
    flowEntries.computeIfAbsent(deviceId, key -> Maps.newConcurrentMap()).values().forEach(entries::addAll);
    return entries;
}
#end_block

#method_before
public Set<FlowEntry> getFlowEntries(DeviceId deviceId) {
    return getFlowEntriesInternal(deviceId);
}
#method_after
public Set<StoredFlowEntry> getFlowEntries(DeviceId deviceId) {
    return getFlowEntriesInternal(deviceId);
}
#end_block

#method_before
public void add(FlowEntry rule) {
    getFlowEntriesInternal(rule.deviceId(), rule.id()).add((StoredFlowEntry) rule);
    try {
        backupMap.put(rule.id(), (DefaultFlowEntry) rule);
    } catch (Exception e) {
        log.warn("Failed to backup flow rule", e);
    }
}
#method_after
public void add(StoredFlowEntry rule) {
    getFlowEntriesInternal(rule.deviceId(), rule.id()).add(rule);
    try {
        backupMap.put(rule.id(), rule);
    } catch (Exception e) {
        log.warn("Failed to backup flow rule", e);
    }
}
#end_block

#method_before
private void updateFibEntry(Collection<FibUpdate> updates) {
    for (FibUpdate update : updates) {
        FibEntry entry = update.entry();
        addNextHop(entry);
        Group group;
        synchronized (pendingUpdates) {
            NextHop nextHop = nextHops.get(entry.nextHopIp());
            group = groupService.getGroup(deviceId, nextHop.group());
            if (group == null) {
                log.debug("Adding pending flow {}", update.entry());
                pendingUpdates.put(nextHop.group(), update.entry());
                continue;
            }
        }
        installFlow(update.entry(), group);
    }
}
#method_after
private void updateFibEntry(Collection<FibUpdate> updates) {
    Map<FibEntry, Group> toInstall = new HashMap<>(updates.size());
    for (FibUpdate update : updates) {
        FibEntry entry = update.entry();
        addNextHop(entry);
        Group group;
        synchronized (pendingUpdates) {
            NextHop nextHop = nextHops.get(entry.nextHopIp());
            group = groupService.getGroup(deviceId, nextHop.group());
            if (group == null) {
                log.debug("Adding pending flow {}", update.entry());
                pendingUpdates.put(nextHop.group(), update.entry());
                continue;
            }
        }
        toInstall.put(update.entry(), group);
    }
    installFlows(toInstall);
}
#end_block

#method_before
private synchronized void deleteFibEntry(Collection<FibUpdate> withdraws) {
    for (FibUpdate update : withdraws) {
        FibEntry entry = update.entry();
        Group group = deleteNextHop(entry.prefix());
        if (group == null) {
            log.warn("Group not found when deleting {}", entry);
            return;
        }
        FlowRule flowRule = generateRibFlowRule(entry.prefix(), group);
        flowService.removeFlowRules(flowRule);
    }
}
#method_after
private synchronized void deleteFibEntry(Collection<FibUpdate> withdraws) {
    FlowRuleOperations.Builder builder = FlowRuleOperations.builder();
    for (FibUpdate update : withdraws) {
        FibEntry entry = update.entry();
        Group group = deleteNextHop(entry.prefix());
        if (group == null) {
            log.warn("Group not found when deleting {}", entry);
            return;
        }
        FlowRule flowRule = generateRibFlowRule(entry.prefix(), group);
        builder.remove(flowRule);
    }
    flowService.apply(builder.build());
}
#end_block

#method_before
public void provision(boolean install, Set<Interface> intfs) {
    getIntefaceConfig(intfs);
    processTableZero(install);
    processTableOne(install);
    processTableTwo(install);
    processTableFour(install);
    processTableFive(install);
    processTableSix(install);
    processTableNine(install);
}
#method_after
public void provision(boolean install, Set<Interface> intfs) {
    getInterfaceConfig(intfs);
    processTableZero(install);
    processTableOne(install);
    processTableTwo(install);
    processTableFour(install);
    processTableFive(install);
    processTableSix(install);
    processTableNine(install);
}
#end_block

#method_before
@Override
public void event(GroupEvent event) {
    Group group = event.subject();
    if (event.type() == GroupEvent.Type.GROUP_ADDED || event.type() == GroupEvent.Type.GROUP_UPDATED) {
        synchronized (pendingUpdates) {
            pendingUpdates.removeAll(group.appCookie()).forEach((entry) -> installFlow(entry, group));
        }
    }
}
#method_after
@Override
public void event(GroupEvent event) {
    Group group = event.subject();
    if (event.type() == GroupEvent.Type.GROUP_ADDED || event.type() == GroupEvent.Type.GROUP_UPDATED) {
        synchronized (pendingUpdates) {
            Map<FibEntry, Group> entriesToInstall = pendingUpdates.removeAll(group.appCookie()).stream().collect(Collectors.toMap(e -> e, e -> group));
            installFlows(entriesToInstall);
        }
    }
}
#end_block

#method_before
private void processPacketIn(InboundPacket pkt) {
    Ethernet ethernet = pkt.parsed();
    IPv4 ipv4 = (IPv4) ethernet.getPayload();
    ConnectPoint connectPoint = pkt.receivedFrom();
    Ip4Address dest = Ip4Address.valueOf(ipv4.getDestinationAddress());
    Set<Interface> interfaces = configService.getInterfaces();
    Interface targetInterface = configService.getMatchingInterface(dest);
    if (targetInterface == null) {
        return;
    }
    if (((ICMP) ipv4.getPayload()).getIcmpType() == ICMP_TYPE_ECHO && interfaces.contains(targetInterface)) {
        sendICMPResponse(ethernet, connectPoint);
    }
}
#method_after
private void processPacketIn(InboundPacket pkt) {
    boolean ipMatches = false;
    Ethernet ethernet = pkt.parsed();
    IPv4 ipv4 = (IPv4) ethernet.getPayload();
    ConnectPoint connectPoint = pkt.receivedFrom();
    IpAddress destIpAddress = IpAddress.valueOf(ipv4.getDestinationAddress());
    Interface targetInterface = configService.getMatchingInterface(destIpAddress);
    if (targetInterface == null) {
        log.trace("No matching interface for {}", destIpAddress);
        return;
    }
    for (InterfaceIpAddress interfaceIpAddress : targetInterface.ipAddresses()) {
        if (interfaceIpAddress.ipAddress().equals(destIpAddress)) {
            ipMatches = true;
            break;
        }
    }
    if (((ICMP) ipv4.getPayload()).getIcmpType() == ICMP.TYPE_ECHO_REQUEST && ipMatches) {
        sendICMPResponse(ethernet, connectPoint);
    }
}
#end_block

#method_before
private void sendICMPResponse(Ethernet icmpRequest, ConnectPoint outport) {
    Ethernet icmpReplyEth = new Ethernet();
    IPv4 icmpRequestIpv4 = (IPv4) icmpRequest.getPayload();
    IPv4 icmpReplyIpv4 = new IPv4();
    int destAddress = icmpRequestIpv4.getDestinationAddress();
    icmpReplyIpv4.setDestinationAddress(icmpRequestIpv4.getSourceAddress());
    icmpReplyIpv4.setSourceAddress(destAddress);
    icmpReplyIpv4.setTtl((byte) 64);
    icmpReplyIpv4.setChecksum((short) 0);
    ICMP icmpReply = (ICMP) icmpRequestIpv4.getPayload().clone();
    icmpReply.setIcmpCode((byte) 0x00);
    icmpReply.setIcmpType((byte) ICMP_TYPE_REPLY);
    icmpReply.setChecksum((short) 0);
    icmpReplyIpv4.setPayload(icmpReply);
    icmpReplyEth.setPayload(icmpReplyIpv4);
    icmpReplyEth.setEtherType(Ethernet.TYPE_IPV4);
    icmpReplyEth.setDestinationMACAddress(icmpRequest.getSourceMACAddress());
    icmpReplyEth.setSourceMACAddress(icmpRequest.getDestinationMACAddress());
    icmpReplyEth.setVlanID(icmpRequest.getVlanID());
    sendPacketOut(outport, icmpReplyEth);
    log.debug("Send an ICMP response {} to {}", icmpReplyIpv4, outport);
}
#method_after
private void sendICMPResponse(Ethernet icmpRequest, ConnectPoint outport) {
    Ethernet icmpReplyEth = new Ethernet();
    IPv4 icmpRequestIpv4 = (IPv4) icmpRequest.getPayload();
    IPv4 icmpReplyIpv4 = new IPv4();
    int destAddress = icmpRequestIpv4.getDestinationAddress();
    icmpReplyIpv4.setDestinationAddress(icmpRequestIpv4.getSourceAddress());
    icmpReplyIpv4.setSourceAddress(destAddress);
    icmpReplyIpv4.setTtl((byte) 64);
    icmpReplyIpv4.setChecksum((short) 0);
    ICMP icmpReply = (ICMP) icmpRequestIpv4.getPayload().clone();
    icmpReply.setIcmpType(ICMP.TYPE_ECHO_REPLY);
    icmpReply.setIcmpCode(ICMP.SUBTYPE_ECHO_REPLY);
    icmpReply.setChecksum((short) 0);
    icmpReplyIpv4.setPayload(icmpReply);
    icmpReplyEth.setPayload(icmpReplyIpv4);
    icmpReplyEth.setEtherType(Ethernet.TYPE_IPV4);
    icmpReplyEth.setDestinationMACAddress(icmpRequest.getSourceMACAddress());
    icmpReplyEth.setSourceMACAddress(icmpRequest.getDestinationMACAddress());
    icmpReplyEth.setVlanID(icmpRequest.getVlanID());
    sendPacketOut(outport, icmpReplyEth);
}
#end_block

#method_before
@Test
public void equality() {
    new EqualsTester().addEqualityGroup(defineProperty("foo", STRING, "bar", "Desc"), defineProperty("foo", STRING, "goo", "Desc")).addEqualityGroup(defineProperty("foo", BOOLEAN, "bar", "Desc"), defineProperty("foo", BOOLEAN, "goo", "Desc")).addEqualityGroup(defineProperty("bar", BOOLEAN, "bar", "Desc"), defineProperty("bar", BOOLEAN, "goo", "Desc")).testEquals();
}
#method_after
@Test
public void equality() {
    new EqualsTester().addEqualityGroup(defineProperty("foo", STRING, "bar", "Desc"), defineProperty("foo", STRING, "goo", "Desc")).addEqualityGroup(defineProperty("bar", STRING, "bar", "Desc"), defineProperty("bar", STRING, "goo", "Desc")).testEquals();
}
#end_block

#method_before
@Override
public int hashCode() {
    return Objects.hash(name, type);
}
#method_after
@Override
public int hashCode() {
    return Objects.hash(name);
}
#end_block

#method_before
@Override
public boolean equals(Object obj) {
    if (this == obj) {
        return true;
    }
    if (obj instanceof ConfigProperty) {
        final ConfigProperty other = (ConfigProperty) obj;
        return Objects.equals(this.name, other.name) && Objects.equals(this.type, other.type);
    }
    return false;
}
#method_after
@Override
public boolean equals(Object obj) {
    if (this == obj) {
        return true;
    }
    if (obj instanceof ConfigProperty) {
        final ConfigProperty other = (ConfigProperty) obj;
        return Objects.equals(this.name, other.name);
    }
    return false;
}
#end_block

#method_before
@Override
protected void execute() {
    init();
    // FIXME - May be erroneous here since it is wall clock time
    // being taken into account. Unsynchronized timestamps may result
    // in topologyUptime being calculated to be a negative value that
    // consequently affects the date formatting.
    final long topologyUptime = System.currentTimeMillis() - topology.creationTime();
    if (recompute) {
        get(TopologyProvider.class).triggerRecompute();
    } else if (outputJson()) {
        print("%s", new ObjectMapper().createObjectNode().put("time", topology.time()).put("created", formatMillis(topology.creationTime(), "creationTime")).put("uptime", formatMillis(topologyUptime, "upTime")).put("deviceCount", topology.deviceCount()).put("linkCount", topology.linkCount()).put("clusterCount", topology.clusterCount()));
    } else {
        print(FMT, formatMillis(topology.creationTime(), "creationTime"), formatMillis(topologyUptime, "upTime"), topology.deviceCount(), topology.linkCount(), topology.clusterCount());
    }
}
#method_after
@Override
protected void execute() {
    init();
    long topologyUptime = Math.max(0, (System.currentTimeMillis() - topology.creationTime()));
    if (recompute) {
        get(TopologyProvider.class).triggerRecompute();
    } else if (outputJson()) {
        print("%s", new ObjectMapper().createObjectNode().put("time", topology.time()).put("created", formatCreationTime(topology.creationTime())).put("uptime", formatElapsedTime(topologyUptime)).put("deviceCount", topology.deviceCount()).put("linkCount", topology.linkCount()).put("clusterCount", topology.clusterCount()));
    } else {
        print(FMT, formatCreationTime(topology.creationTime()), formatElapsedTime(topologyUptime), topology.deviceCount(), topology.linkCount(), topology.clusterCount());
    }
}
#end_block

#method_before
@Override
public boolean isMine(Key intentKey) {
    return Objects.equals(getLeader(intentKey), clusterService.getLocalNode().id());
}
#method_after
@Override
public boolean isMine(Key intentKey) {
    return Objects.equals(leadershipService.getLeader(getPartitionPath(getPartitionForKey(intentKey))), clusterService.getLocalNode().id());
}
#end_block

#method_before
@Override
public boolean broadcast(ClusterMessage message) {
    boolean ok = true;
    final ControllerNode localNode = clusterService.getLocalNode();
    byte[] payload = SERIALIZER.encode(message);
    for (ControllerNode node : clusterService.getNodes()) {
        if (!node.equals(localNode)) {
            ok = unicastUnchecked(message.subject(), payload, node.id()) && ok;
        }
    }
    return ok;
}
#method_after
@Override
public boolean broadcast(ClusterMessage message) {
    boolean ok = true;
    final ControllerNode localNode = clusterService.getLocalNode();
    byte[] payload = message.getBytes();
    for (ControllerNode node : clusterService.getNodes()) {
        if (!node.equals(localNode)) {
            ok = unicastUnchecked(message.subject(), payload, node.id()) && ok;
        }
    }
    return ok;
}
#end_block

#method_before
@Override
public boolean broadcastIncludeSelf(ClusterMessage message) {
    boolean ok = true;
    byte[] payload = SERIALIZER.encode(message);
    for (ControllerNode node : clusterService.getNodes()) {
        ok = unicastUnchecked(message.subject(), payload, node.id()) && ok;
    }
    return ok;
}
#method_after
@Override
public boolean broadcastIncludeSelf(ClusterMessage message) {
    boolean ok = true;
    byte[] payload = message.getBytes();
    for (ControllerNode node : clusterService.getNodes()) {
        ok = unicastUnchecked(message.subject(), payload, node.id()) && ok;
    }
    return ok;
}
#end_block

#method_before
@Override
public boolean multicast(ClusterMessage message, Iterable<NodeId> nodes) {
    boolean ok = true;
    final ControllerNode localNode = clusterService.getLocalNode();
    byte[] payload = SERIALIZER.encode(message);
    for (NodeId nodeId : nodes) {
        if (!nodeId.equals(localNode.id())) {
            ok = unicastUnchecked(message.subject(), payload, nodeId) && ok;
        }
    }
    return ok;
}
#method_after
@Override
public boolean multicast(ClusterMessage message, Iterable<NodeId> nodes) {
    boolean ok = true;
    final ControllerNode localNode = clusterService.getLocalNode();
    byte[] payload = message.getBytes();
    for (NodeId nodeId : nodes) {
        if (!nodeId.equals(localNode.id())) {
            ok = unicastUnchecked(message.subject(), payload, nodeId) && ok;
        }
    }
    return ok;
}
#end_block

#method_before
@Override
public boolean unicast(ClusterMessage message, NodeId toNodeId) {
    return unicastUnchecked(message.subject(), SERIALIZER.encode(message), toNodeId);
}
#method_after
@Override
public boolean unicast(ClusterMessage message, NodeId toNodeId) {
    return unicastUnchecked(message.subject(), message.getBytes(), toNodeId);
}
#end_block

#method_before
@Override
public ListenableFuture<byte[]> sendAndReceive(ClusterMessage message, NodeId toNodeId) throws IOException {
    ControllerNode node = clusterService.getNode(toNodeId);
    checkArgument(node != null, "Unknown nodeId: %s", toNodeId);
    Endpoint nodeEp = new Endpoint(node.ip(), node.tcpPort());
    try {
        return messagingService.sendAndReceive(nodeEp, message.subject().value(), SERIALIZER.encode(message));
    } catch (IOException e) {
        log.trace("Failed interaction with remote nodeId: " + toNodeId, e);
        throw e;
    }
}
#method_after
@Override
public ListenableFuture<byte[]> sendAndReceive(ClusterMessage message, NodeId toNodeId) throws IOException {
    ControllerNode node = clusterService.getNode(toNodeId);
    checkArgument(node != null, "Unknown nodeId: %s", toNodeId);
    Endpoint nodeEp = new Endpoint(node.ip(), node.tcpPort());
    try {
        return messagingService.sendAndReceive(nodeEp, message.subject().value(), message.getBytes());
    } catch (IOException e) {
        log.trace("Failed interaction with remote nodeId: " + toNodeId, e);
        throw e;
    }
}
#end_block

#method_before
@Override
public void handle(Message message) {
    final ClusterMessage clusterMessage;
    try {
        clusterMessage = SERIALIZER.decode(message.payload());
    } catch (Exception e) {
        log.error("Failed decoding {}", message, e);
        throw e;
    }
    try {
        handler.handle(new InternalClusterMessage(clusterMessage, message));
    } catch (Exception e) {
        log.trace("Failed handling {}", clusterMessage, e);
        throw e;
    }
}
#method_after
@Override
public void handle(Message message) {
    final ClusterMessage clusterMessage;
    try {
        clusterMessage = ClusterMessage.fromBytes(message.payload());
    } catch (Exception e) {
        log.error("Failed decoding {}", message, e);
        throw e;
    }
    try {
        handler.handle(new InternalClusterMessage(clusterMessage, message));
    } catch (Exception e) {
        log.trace("Failed handling {}", clusterMessage, e);
        throw e;
    }
}
#end_block

#method_before
private boolean underHighLoad() {
    return counter.get(2) > 0;
}
#method_after
private boolean underHighLoad() {
    return counter.get(LOAD_WINDOW) > HIGH_LOAD_THRESHOLD;
}
#end_block

#method_before
public long get(int slots) {
    checkArgument(slots <= windowLengthInSlots, "Requested window must be less than total window");
    long sum = 0;
    for (int i = 0; i < slots; i++) {
        int currentIndex = headSlot - i;
        if (currentIndex < 0) {
            currentIndex = counters.size() + currentIndex;
        }
        sum += counters.get(currentIndex).get();
    }
    return sum;
}
#method_after
public long get(int slots) {
    checkArgument(slots <= windowSlots, "Requested window must be less than the total window slots");
    long sum = 0;
    for (int i = 0; i < slots; i++) {
        int currentIndex = headSlot - i;
        if (currentIndex < 0) {
            currentIndex = counters.size() + currentIndex;
        }
        sum += counters.get(currentIndex).get();
    }
    return sum;
}
#end_block

#method_before
private void advanceHead() {
    headSlot = slotAfter(headSlot);
    // tailSlot = slotAfter(tailSlot);
    counters.get(headSlot).set(0);
}
#method_after
void advanceHead() {
    counters.get(slotAfter(headSlot)).set(0);
    headSlot = slotAfter(headSlot);
}
#end_block

#method_before
private int slotAfter(int slot) {
    return (slot + 1) % windowLengthInSlots;
}
#method_after
private int slotAfter(int slot) {
    return (slot + 1) % windowSlots;
}
#end_block

#method_before
@Test
public void testIncrementCount() throws Exception {
}
#method_after
@Test
public void testIncrementCount() {
    assertEquals(0, counter.get(1));
    assertEquals(0, counter.get(2));
    counter.incrementCount();
    assertEquals(1, counter.get(1));
    assertEquals(1, counter.get(2));
    counter.incrementCount(2);
    assertEquals(3, counter.get(2));
}
#end_block

#method_before
@Override
public void withdraw(String path) {
    activeTopics.remove(path);
    try {
        Versioned<NodeId> id = lockMap.get(path);
        if (Objects.equals(id.value(), localNodeId)) {
            if (lockMap.remove(path, id.version())) {
                log.info("Gave up leadership for {}", path);
                notifyRemovedLeader(path, localNodeId, id.version(), id.creationTime());
            }
        }
    // else we are not the current owner.
    } catch (Exception e) {
        log.debug("Failed to verify (and clear) any lock this node might be holding for {}", path, e);
    }
}
#method_after
@Override
public void withdraw(String path) {
    activeTopics.remove(path);
    try {
        Versioned<NodeId> leader = lockMap.get(path);
        if (Objects.equals(leader.value(), localNodeId)) {
            if (lockMap.remove(path, leader.version())) {
                log.info("Gave up leadership for {}", path);
                notifyRemovedLeader(path, localNodeId, leader.version(), leader.creationTime());
            }
        }
    // else we are not the current owner.
    } catch (Exception e) {
        log.debug("Failed to verify (and clear) any lock this node might be holding for {}", path, e);
    }
}
#end_block

#method_before
@Override
public void sendMsg(OFMessage m) {
    if (role == RoleState.MASTER) {
        this.write(m);
    }
}
#method_after
@Override
public final void sendMsg(OFMessage m) {
    if (role == RoleState.MASTER) {
        this.write(m);
    }
}
#end_block

#method_before
@Override
public void sendMsg(List<OFMessage> msgs) {
    if (role == RoleState.MASTER) {
        this.write(msgs);
    }
}
#method_after
@Override
public final void sendMsg(List<OFMessage> msgs) {
    if (role == RoleState.MASTER) {
        this.write(msgs);
    }
}
#end_block

#method_before
@Override
public void write(OFMessage msg) {
    this.write(Collections.singletonList(msg));
}
#method_after
@Override
public void write(OFMessage msg) {
    if (msg.getType() == OFType.FLOW_MOD) {
        OFFlowMod flowMod = (OFFlowMod) msg;
        OFFlowMod.Builder builder = flowMod.createBuilder();
        builder.setTableId(TableId.of(LOCAL_TABLE));
        channel.write(Collections.singletonList(builder.build()));
    } else {
        channel.write(Collections.singletonList(msg));
    }
}
#end_block

#method_before
@Override
public void write(List<OFMessage> msgs) {
    channel.write(msgs);
}
#method_after
@Override
public void write(List<OFMessage> msgs) {
    List<OFMessage> newMsgs = new ArrayList<OFMessage>();
    for (OFMessage msg : msgs) {
        if (msg.getType() == OFType.FLOW_MOD) {
            OFFlowMod flowMod = (OFFlowMod) msg;
            OFFlowMod.Builder builder = flowMod.createBuilder();
            builder.setTableId(TableId.of(LOCAL_TABLE));
            newMsgs.add(builder.build());
        } else {
            newMsgs.add(msg);
        }
    }
    channel.write(newMsgs);
}
#end_block

#method_before
private void applyRule(FlowRule flowRule) {
    OpenFlowSwitch sw = controller.getSwitch(Dpid.dpid(flowRule.deviceId().uri()));
    if (flowRule.type() == FlowRule.Type.DEFAULT) {
        sw.sendMsg(FlowModBuilder.builder(flowRule, sw.factory(), Optional.empty()).buildFlowAdd());
    } else {
        OpenFlowSwitch.TableType type = getTableType(flowRule.type());
        sw.sendMsg(FlowModBuilder.builder(flowRule, sw.factory(), Optional.empty()).buildFlowAdd(), type);
    }
}
#method_after
private void applyRule(FlowRule flowRule) {
    OpenFlowSwitch sw = controller.getSwitch(Dpid.dpid(flowRule.deviceId().uri()));
    if (flowRule.type() == FlowRule.Type.DEFAULT) {
        sw.sendMsg(FlowModBuilder.builder(flowRule, sw.factory(), Optional.empty()).buildFlowAdd());
    } else {
        OpenFlowSwitch.TableType type = getTableType(flowRule.type());
        sw.transformAndSendMsg(FlowModBuilder.builder(flowRule, sw.factory(), Optional.empty()).buildFlowAdd(), type);
    }
}
#end_block

#method_before
private void removeRule(FlowRule flowRule) {
    OpenFlowSwitch sw = controller.getSwitch(Dpid.dpid(flowRule.deviceId().uri()));
    if (flowRule.type() == FlowRule.Type.DEFAULT) {
        sw.sendMsg(FlowModBuilder.builder(flowRule, sw.factory(), Optional.empty()).buildFlowDel());
    } else {
        sw.sendMsg(FlowModBuilder.builder(flowRule, sw.factory(), Optional.empty()).buildFlowDel(), getTableType(flowRule.type()));
    }
}
#method_after
private void removeRule(FlowRule flowRule) {
    OpenFlowSwitch sw = controller.getSwitch(Dpid.dpid(flowRule.deviceId().uri()));
    if (flowRule.type() == FlowRule.Type.DEFAULT) {
        sw.sendMsg(FlowModBuilder.builder(flowRule, sw.factory(), Optional.empty()).buildFlowDel());
    } else {
        sw.transformAndSendMsg(FlowModBuilder.builder(flowRule, sw.factory(), Optional.empty()).buildFlowDel(), getTableType(flowRule.type()));
    }
}
#end_block

#method_before
@Override
public void executeBatch(FlowRuleBatchOperation batch) {
    pendingBatches.put(batch.id(), new InternalCacheEntry(batch));
    OpenFlowSwitch sw = controller.getSwitch(Dpid.dpid(batch.deviceId().uri()));
    OFFlowMod mod;
    for (FlowRuleBatchEntry fbe : batch.getOperations()) {
        FlowModBuilder builder = FlowModBuilder.builder(fbe.target(), sw.factory(), Optional.of(batch.id()));
        switch(fbe.operator()) {
            case ADD:
                mod = builder.buildFlowAdd();
                break;
            case REMOVE:
                mod = builder.buildFlowDel();
                break;
            case MODIFY:
                mod = builder.buildFlowMod();
                break;
            default:
                log.error("Unsupported batch operation {}; skipping flowmod {}", fbe.operator(), fbe);
                continue;
        }
        if (fbe.target().type() == FlowRule.Type.DEFAULT) {
            sw.sendMsg(mod);
        } else {
            sw.sendMsg(mod, getTableType(fbe.target().type()));
        }
    }
    OFBarrierRequest.Builder builder = sw.factory().buildBarrierRequest().setXid(batch.id());
    sw.sendMsg(builder.build());
}
#method_after
@Override
public void executeBatch(FlowRuleBatchOperation batch) {
    pendingBatches.put(batch.id(), new InternalCacheEntry(batch));
    OpenFlowSwitch sw = controller.getSwitch(Dpid.dpid(batch.deviceId().uri()));
    OFFlowMod mod;
    for (FlowRuleBatchEntry fbe : batch.getOperations()) {
        FlowModBuilder builder = FlowModBuilder.builder(fbe.target(), sw.factory(), Optional.of(batch.id()));
        switch(fbe.operator()) {
            case ADD:
                mod = builder.buildFlowAdd();
                break;
            case REMOVE:
                mod = builder.buildFlowDel();
                break;
            case MODIFY:
                mod = builder.buildFlowMod();
                break;
            default:
                log.error("Unsupported batch operation {}; skipping flowmod {}", fbe.operator(), fbe);
                continue;
        }
        if (fbe.target().type() == FlowRule.Type.DEFAULT) {
            sw.sendMsg(mod);
        } else {
            sw.transformAndSendMsg(mod, getTableType(fbe.target().type()));
        }
    }
    OFBarrierRequest.Builder builder = sw.factory().buildBarrierRequest().setXid(batch.id());
    sw.sendMsg(builder.build());
}
#end_block

#method_before
@Override
public OpenFlowSwitchDriver getOFSwitchImpl(Dpid dpid, OFDescStatsReply desc, OFVersion ofv) {
    String vendor = desc.getMfrDesc();
    String hw = desc.getHwDesc();
    if (vendor.startsWith("Stanford University, Ericsson Research and CPqD Research") && hw.startsWith("OpenFlow 1.3 Reference Userspace Switch")) {
        return new OFSwitchImplCPqD13(dpid, desc);
    }
    if (hw.startsWith("Open vSwitch")) {
        if (ofv == OFVersion.OF_10) {
            return new OFSwitchImplOVS10(dpid, desc);
        } else if (ofv == OFVersion.OF_13) {
            return new OFSwitchImplOVS13(dpid, desc);
        }
    }
    String sw = desc.getSwDesc();
    if (sw.startsWith("LINC-OE")) {
        log.warn("Optical Emulator LINC-OE with DPID:{} found..", dpid);
        return new OFOpticalSwitchImplLINC13(dpid, desc);
    }
    log.warn("DriverManager could not identify switch desc: {}. " + "Assigning AbstractOpenFlowSwich", desc);
    return new AbstractOpenFlowSwitch(dpid, desc) {

        @Override
        public void setRole(RoleState state) {
            this.role = RoleState.MASTER;
        }

        @Override
        public void write(List<OFMessage> msgs) {
            channel.write(msgs);
        }

        @Override
        public void write(OFMessage msg) {
            channel.write(Collections.singletonList(msg));
        }

        @Override
        public Boolean supportNxRole() {
            return false;
        }

        @Override
        public void startDriverHandshake() {
            if (factory().getVersion() == OFVersion.OF_10) {
                OFFlowAdd.Builder fmBuilder = factory().buildFlowAdd();
                fmBuilder.setPriority(LOWEST_PRIORITY);
                write(fmBuilder.build());
            }
        }

        @Override
        public void processDriverHandshakeMessage(OFMessage m) {
        }

        @Override
        public boolean isDriverHandshakeComplete() {
            return true;
        }

        @Override
        public List<OFPortDesc> getPorts() {
            if (this.factory().getVersion() == OFVersion.OF_10) {
                return Collections.unmodifiableList(features.getPorts());
            } else {
                return Collections.unmodifiableList(ports.getEntries());
            }
        }

        @Override
        public TableType getTableType(TableId tid) {
            return TableType.NONE;
        }
    };
}
#method_after
@Override
public OpenFlowSwitchDriver getOFSwitchImpl(Dpid dpid, OFDescStatsReply desc, OFVersion ofv) {
    String vendor = desc.getMfrDesc();
    String hw = desc.getHwDesc();
    if (vendor.startsWith("Stanford University, Ericsson Research and CPqD Research") && hw.startsWith("OpenFlow 1.3 Reference Userspace Switch")) {
        return new OFSwitchImplCPqD13(dpid, desc);
    }
    if (hw.startsWith("Open vSwitch")) {
        if (ofv == OFVersion.OF_10) {
            return new OFSwitchImplOVS10(dpid, desc);
        } else if (ofv == OFVersion.OF_13) {
            return new OFSwitchImplOVS13(dpid, desc);
        }
    }
    String sw = desc.getSwDesc();
    if (sw.startsWith("LINC-OE")) {
        log.warn("Optical Emulator LINC-OE with DPID:{} found..", dpid);
        return new OFOpticalSwitchImplLINC13(dpid, desc);
    }
    log.warn("DriverManager could not identify switch desc: {}. " + "Assigning AbstractOpenFlowSwich", desc);
    return new AbstractOpenFlowSwitch(dpid, desc) {

        @Override
        public void setRole(RoleState state) {
            this.role = RoleState.MASTER;
        }

        @Override
        public void write(List<OFMessage> msgs) {
            channel.write(msgs);
        }

        @Override
        public void write(OFMessage msg) {
            channel.write(Collections.singletonList(msg));
        }

        @Override
        public Boolean supportNxRole() {
            return false;
        }

        @Override
        public void startDriverHandshake() {
            if (factory().getVersion() == OFVersion.OF_10) {
                OFFlowAdd.Builder fmBuilder = factory().buildFlowAdd();
                fmBuilder.setPriority(LOWEST_PRIORITY);
                write(fmBuilder.build());
            }
        }

        @Override
        public void processDriverHandshakeMessage(OFMessage m) {
        }

        @Override
        public boolean isDriverHandshakeComplete() {
            return true;
        }

        @Override
        public List<OFPortDesc> getPorts() {
            if (this.factory().getVersion() == OFVersion.OF_10) {
                return Collections.unmodifiableList(features.getPorts());
            } else {
                return Collections.unmodifiableList(ports.getEntries());
            }
        }

        @Override
        public TableType getTableType(TableId tid) {
            return TableType.NONE;
        }

        @Override
        public void transformAndSendMsg(OFMessage msg, TableType tableType) {
        // TODO Auto-generated method stub
        }
    };
}
#end_block

#method_before
private boolean putInternal(K key, V value, Timestamp timestamp) {
    Timestamp removed = removedItems.get(key);
    if (removed != null && removed.isNewerThan(timestamp)) {
        log.debug("ecmap - removed was newer {}", value);
        return false;
    }
    boolean success;
    synchronized (this) {
        Timestamped<V> existing = items.get(key);
        if (existing != null && existing.isNewerThan(timestamp)) {
            log.debug("ecmap - existing was newer {}", value);
            success = false;
        } else {
            items.put(key, new Timestamped<>(value, timestamp));
            success = true;
        }
    }
    if (success && removed != null) {
        removedItems.remove(key, removed);
    }
    return success;
}
#method_after
private boolean putInternal(K key, V value, Timestamp timestamp) {
    Timestamp removed = removedItems.get(key);
    if (removed != null && removed.isNewerThan(timestamp)) {
        log.debug("ecmap - removed was newer {}", value);
        return false;
    }
    final MutableBoolean updated = new MutableBoolean(false);
    items.compute(key, (k, existing) -> {
        if (existing != null && existing.isNewerThan(timestamp)) {
            updated.setFalse();
            return existing;
        } else {
            updated.setTrue();
            return new Timestamped<>(value, timestamp);
        }
    });
    boolean success = updated.booleanValue();
    if (!success) {
        log.debug("ecmap - existing was newer {}", value);
    }
    if (success && removed != null) {
        removedItems.remove(key, removed);
    }
    return success;
}
#end_block

#method_before
private boolean removeInternal(K key, Timestamp timestamp) {
    Timestamped<V> value = items.get(key);
    if (value != null) {
        if (value.isNewerThan(timestamp)) {
            return false;
        } else {
            items.remove(key, value);
        }
    }
    Timestamp removedTimestamp = removedItems.get(key);
    if (removedTimestamp == null) {
        return removedItems.putIfAbsent(key, timestamp) == null;
    } else if (timestamp.isNewerThan(removedTimestamp)) {
        return removedItems.replace(key, removedTimestamp, timestamp);
    } else {
        return false;
    }
}
#method_after
private boolean removeInternal(K key, Timestamp timestamp) {
    final MutableBoolean updated = new MutableBoolean(false);
    items.compute(key, (k, existing) -> {
        if (existing != null && existing.isNewerThan(timestamp)) {
            updated.setFalse();
            return existing;
        } else {
            updated.setTrue();
            // remove from items map
            return null;
        }
    });
    if (updated.isFalse()) {
        return false;
    }
    Timestamp removedTimestamp = removedItems.get(key);
    if (removedTimestamp == null) {
        return removedItems.putIfAbsent(key, timestamp) == null;
    } else if (timestamp.isNewerThan(removedTimestamp)) {
        return removedItems.replace(key, removedTimestamp, timestamp);
    } else {
        return false;
    }
}
#end_block

#method_before
private void handleAntiEntropyAdvertisement(AntiEntropyAdvertisement<K> ad) {
    List<EventuallyConsistentMapEvent<K, V>> externalEvents;
    boolean sync = false;
    synchronized (this) {
        externalEvents = antiEntropyCheckLocalItems(ad);
        antiEntropyCheckLocalRemoved(ad);
        externalEvents.addAll(antiEntropyCheckRemoteRemoved(ad));
        // if remote ad has something unknown, actively sync
        for (K key : ad.timestamps().keySet()) {
            if (!items.containsKey(key)) {
                sync = true;
                break;
            }
        }
    }
    // Send the advertisement outside the synchronized block
    if (sync) {
        final NodeId sender = ad.sender();
        AntiEntropyAdvertisement<K> myAd = createAdvertisement();
        try {
            unicastMessage(sender, antiEntropyAdvertisementSubject, myAd);
        } catch (IOException e) {
            log.debug("Failed to send reactive anti-entropy advertisement to {}", sender);
        }
    }
    externalEvents.forEach(this::notifyListeners);
}
#method_after
private void handleAntiEntropyAdvertisement(AntiEntropyAdvertisement<K> ad) {
    List<EventuallyConsistentMapEvent<K, V>> externalEvents;
    externalEvents = antiEntropyCheckLocalItems(ad);
    antiEntropyCheckLocalRemoved(ad);
    if (!lightweightAntiEntropy) {
        externalEvents.addAll(antiEntropyCheckRemoteRemoved(ad));
        // if remote ad has something unknown, actively sync
        for (K key : ad.timestamps().keySet()) {
            if (!items.containsKey(key)) {
                // Send the advertisement back if this peer is out-of-sync
                final NodeId sender = ad.sender();
                AntiEntropyAdvertisement<K> myAd = createAdvertisement();
                try {
                    unicastMessage(sender, antiEntropyAdvertisementSubject, myAd);
                } catch (IOException e) {
                    log.debug("Failed to send reactive anti-entropy advertisement to {}", sender);
                }
                break;
            }
        }
    }
    externalEvents.forEach(this::notifyListeners);
}
#end_block

#method_before
/**
 * Checks if any of the remote's live items or tombstones are out of date
 * according to our local live item list, or if our live items are out of
 * date according to the remote's tombstone list.
 * If the local copy is more recent, it will be pushed to the remote. If the
 * remote has a more recent remove, we apply that to the local state.
 *
 * @param ad remote anti-entropy advertisement
 * @return list of external events relating to local operations performed
 */
private List<EventuallyConsistentMapEvent<K, V>> antiEntropyCheckLocalItems(AntiEntropyAdvertisement<K> ad) {
    final List<EventuallyConsistentMapEvent<K, V>> externalEvents = new LinkedList<>();
    final NodeId sender = ad.sender();
    final List<PutEntry<K, V>> updatesToSend = new ArrayList<>();
    for (Map.Entry<K, Timestamped<V>> item : items.entrySet()) {
        K key = item.getKey();
        Timestamped<V> localValue = item.getValue();
        Timestamp remoteTimestamp = ad.timestamps().get(key);
        if (remoteTimestamp == null) {
            remoteTimestamp = ad.tombstones().get(key);
        }
        if (remoteTimestamp == null || localValue.isNewerThan(remoteTimestamp)) {
            // local value is more recent, push to sender
            updatesToSend.add(new PutEntry<>(key, localValue.value(), localValue.timestamp()));
        }
        Timestamp remoteDeadTimestamp = ad.tombstones().get(key);
        if (remoteDeadTimestamp != null && remoteDeadTimestamp.isNewerThan(localValue.timestamp())) {
            // sender has a more recent remove
            if (removeInternal(key, remoteDeadTimestamp)) {
                externalEvents.add(new EventuallyConsistentMapEvent<>(EventuallyConsistentMapEvent.Type.REMOVE, key, null));
            }
        }
    }
    // Send all updates to the peer at once
    if (!updatesToSend.isEmpty()) {
        try {
            unicastMessage(sender, updateMessageSubject, new InternalPutEvent<>(updatesToSend));
        } catch (IOException e) {
            log.warn("Failed to send advertisement response", e);
        }
    }
    return externalEvents;
}
#method_after
private List<EventuallyConsistentMapEvent<K, V>> antiEntropyCheckLocalItems(AntiEntropyAdvertisement<K> ad) {
    final List<EventuallyConsistentMapEvent<K, V>> externalEvents = new LinkedList<>();
    final NodeId sender = ad.sender();
    final List<PutEntry<K, V>> updatesToSend = new ArrayList<>();
    for (Map.Entry<K, Timestamped<V>> item : items.entrySet()) {
        K key = item.getKey();
        Timestamped<V> localValue = item.getValue();
        Timestamp remoteTimestamp = ad.timestamps().get(key);
        if (remoteTimestamp == null) {
            remoteTimestamp = ad.tombstones().get(key);
        }
        if (remoteTimestamp == null || localValue.isNewerThan(remoteTimestamp)) {
            // local value is more recent, push to sender
            updatesToSend.add(new PutEntry<>(key, localValue.value(), localValue.timestamp()));
        }
        Timestamp remoteDeadTimestamp = ad.tombstones().get(key);
        if (remoteDeadTimestamp != null && remoteDeadTimestamp.isNewerThan(localValue.timestamp())) {
            // sender has a more recent remove
            if (removeInternal(key, remoteDeadTimestamp)) {
                externalEvents.add(new EventuallyConsistentMapEvent<>(EventuallyConsistentMapEvent.Type.REMOVE, key, null));
            }
        }
    }
    // Send all updates to the peer at once
    if (!updatesToSend.isEmpty()) {
        try {
            unicastMessage(sender, updateMessageSubject, new InternalPutEvent<>(updatesToSend));
        } catch (IOException e) {
            log.warn("Failed to send advertisement response", e);
        }
    }
    return externalEvents;
}
#end_block

#method_before
/**
 * Checks if any items in the remote live list are out of date according
 * to our tombstone list. If we find we have a more up to date tombstone,
 * we'll send it to the remote.
 *
 * @param ad remote anti-entropy advertisement
 */
private void antiEntropyCheckLocalRemoved(AntiEntropyAdvertisement<K> ad) {
    final NodeId sender = ad.sender();
    final List<RemoveEntry<K>> removesToSend = new ArrayList<>();
    for (Map.Entry<K, Timestamp> dead : removedItems.entrySet()) {
        K key = dead.getKey();
        Timestamp localDeadTimestamp = dead.getValue();
        Timestamp remoteLiveTimestamp = ad.timestamps().get(key);
        if (remoteLiveTimestamp != null && localDeadTimestamp.isNewerThan(remoteLiveTimestamp)) {
            // sender has zombie, push remove
            removesToSend.add(new RemoveEntry<>(key, localDeadTimestamp));
        }
    }
    // Send all removes to the peer at once
    if (!removesToSend.isEmpty()) {
        try {
            unicastMessage(sender, removeMessageSubject, new InternalRemoveEvent<>(removesToSend));
        } catch (IOException e) {
            log.warn("Failed to send advertisement response", e);
        }
    }
}
#method_after
private void antiEntropyCheckLocalRemoved(AntiEntropyAdvertisement<K> ad) {
    final NodeId sender = ad.sender();
    final List<RemoveEntry<K>> removesToSend = new ArrayList<>();
    for (Map.Entry<K, Timestamp> dead : removedItems.entrySet()) {
        K key = dead.getKey();
        Timestamp localDeadTimestamp = dead.getValue();
        Timestamp remoteLiveTimestamp = ad.timestamps().get(key);
        if (remoteLiveTimestamp != null && localDeadTimestamp.isNewerThan(remoteLiveTimestamp)) {
            // sender has zombie, push remove
            removesToSend.add(new RemoveEntry<>(key, localDeadTimestamp));
        }
    }
    // Send all removes to the peer at once
    if (!removesToSend.isEmpty()) {
        try {
            unicastMessage(sender, removeMessageSubject, new InternalRemoveEvent<>(removesToSend));
        } catch (IOException e) {
            log.warn("Failed to send advertisement response", e);
        }
    }
}
#end_block

#method_before
/**
 * Checks if any of the local live items are out of date according to the
 * remote's tombstone advertisements. If we find a local item is out of date,
 * we'll apply the remove operation to the local state.
 *
 * @param ad remote anti-entropy advertisement
 * @return list of external events relating to local operations performed
 */
private List<EventuallyConsistentMapEvent<K, V>> antiEntropyCheckRemoteRemoved(AntiEntropyAdvertisement<K> ad) {
    final List<EventuallyConsistentMapEvent<K, V>> externalEvents = new LinkedList<>();
    for (Map.Entry<K, Timestamp> remoteDead : ad.tombstones().entrySet()) {
        K key = remoteDead.getKey();
        Timestamp remoteDeadTimestamp = remoteDead.getValue();
        Timestamped<V> local = items.get(key);
        Timestamp localDead = removedItems.get(key);
        if (local != null && remoteDeadTimestamp.isNewerThan(local.timestamp())) {
            // value, then do a remove with their timestamp
            if (removeInternal(key, remoteDeadTimestamp)) {
                externalEvents.add(new EventuallyConsistentMapEvent<>(EventuallyConsistentMapEvent.Type.REMOVE, key, null));
            }
        } else if (localDead != null && remoteDeadTimestamp.isNewerThan(localDead)) {
            // If the remote has a more recent tombstone than us, update ours
            // to their timestamp
            removeInternal(key, remoteDeadTimestamp);
        }
    }
    return externalEvents;
}
#method_after
private List<EventuallyConsistentMapEvent<K, V>> antiEntropyCheckRemoteRemoved(AntiEntropyAdvertisement<K> ad) {
    final List<EventuallyConsistentMapEvent<K, V>> externalEvents = new LinkedList<>();
    for (Map.Entry<K, Timestamp> remoteDead : ad.tombstones().entrySet()) {
        K key = remoteDead.getKey();
        Timestamp remoteDeadTimestamp = remoteDead.getValue();
        Timestamped<V> local = items.get(key);
        Timestamp localDead = removedItems.get(key);
        if (local != null && remoteDeadTimestamp.isNewerThan(local.timestamp())) {
            // value, then do a remove with their timestamp
            if (removeInternal(key, remoteDeadTimestamp)) {
                externalEvents.add(new EventuallyConsistentMapEvent<>(EventuallyConsistentMapEvent.Type.REMOVE, key, null));
            }
        } else if (localDead != null && remoteDeadTimestamp.isNewerThan(localDead)) {
            // If the remote has a more recent tombstone than us, update ours
            // to their timestamp
            removeInternal(key, remoteDeadTimestamp);
        }
    }
    return externalEvents;
}
#end_block

#method_before
@Override
public void requestPackets(TrafficSelector selector, PacketPriority priority, ApplicationId appId, FlowRule.Type tableType) {
    checkNotNull(selector, "Selector cannot be null");
    checkNotNull(appId, "Application ID cannot be null");
    PacketRequest request = new PacketRequest(selector, priority, appId, tableType);
    packetRequests.add(request);
    pushToAllDevices(request);
}
#method_after
@Override
public void requestPackets(TrafficSelector selector, PacketPriority priority, ApplicationId appId, FlowRule.Type tableType) {
    checkNotNull(selector, "Selector cannot be null");
    checkNotNull(appId, "Application ID cannot be null");
    checkNotNull(tableType, "Table Type cannot be null. For requesting packets +" + "without table hints, use other methods in the packetService API");
    PacketRequest request = new PacketRequest(selector, priority, appId, tableType);
    packetRequests.add(request);
    pushToAllDevices(request);
}
#end_block

#method_before
@Deactivate
public void deactivate() {
    leadershipService.removeListener(leaderListener);
    clusterService.removeListener(clusterListener);
}
#method_after
@Deactivate
public void deactivate() {
    executor.shutdownNow();
    leadershipService.removeListener(leaderListener);
    clusterService.removeListener(clusterListener);
}
#end_block

#method_before
private void relinquish() {
    int activeNodes = (int) clusterService.getNodes().stream().filter(n -> clusterService.getState(n.id()) == ControllerNode.State.ACTIVE).count();
    int myShare = (int) Math.ceil((double) NUM_PARTITIONS / activeNodes);
    List<Leadership> myPartitions = leadershipService.getLeaderBoard().values().stream().filter(l -> clusterService.getLocalNode().id().equals(l.leader())).collect(Collectors.toList());
    int relinquish = myPartitions.size() - myShare;
    if (relinquish <= 0) {
        return;
    }
    for (int i = 0; i < relinquish; i++) {
        String topic = myPartitions.get(i).topic();
        leadershipService.withdraw(topic);
        executor.schedule(() -> recontest(topic), BACKOFF_TIME, TimeUnit.SECONDS);
    }
}
#method_after
private void relinquish() {
    int activeNodes = (int) clusterService.getNodes().stream().filter(n -> clusterService.getState(n.id()) == ControllerNode.State.ACTIVE).count();
    int myShare = (int) Math.ceil((double) NUM_PARTITIONS / activeNodes);
    List<Leadership> myPartitions = leadershipService.getLeaderBoard().values().stream().filter(l -> clusterService.getLocalNode().id().equals(l.leader())).filter(l -> l.topic().startsWith(ELECTION_PREFIX)).collect(Collectors.toList());
    int relinquish = myPartitions.size() - myShare;
    if (relinquish <= 0) {
        return;
    }
    for (int i = 0; i < relinquish; i++) {
        String topic = myPartitions.get(i).topic();
        leadershipService.withdraw(topic);
        executor.schedule(() -> recontest(topic), BACKOFF_TIME, TimeUnit.SECONDS);
    }
}
#end_block

#method_before
private boolean putInternal(K key, V value, Timestamp timestamp) {
    Timestamp removed = removedItems.get(key);
    if (removed != null && removed.isNewerThan(timestamp)) {
        log.debug("ecmap - removed was newer {}", value);
        return false;
    }
    boolean success;
    synchronized (this) {
        Timestamped<V> existing = items.get(key);
        if (existing != null && existing.isNewerThan(timestamp)) {
            log.debug("ecmap - existing was newer {}", value);
            success = false;
        } else {
            items.put(key, new Timestamped<>(value, timestamp));
            success = true;
        }
    }
    if (success && removed != null) {
        removedItems.remove(key, removed);
    }
    return success;
}
#method_after
private boolean putInternal(K key, V value, Timestamp timestamp) {
    Timestamp removed = removedItems.get(key);
    if (removed != null && removed.isNewerThan(timestamp)) {
        log.debug("ecmap - removed was newer {}", value);
        return false;
    }
    final MutableBoolean updated = new MutableBoolean(false);
    items.compute(key, (k, existing) -> {
        if (existing != null && existing.isNewerThan(timestamp)) {
            updated.setFalse();
            return existing;
        } else {
            updated.setTrue();
            return new Timestamped<>(value, timestamp);
        }
    });
    boolean success = updated.booleanValue();
    if (!success) {
        log.debug("ecmap - existing was newer {}", value);
    }
    if (success && removed != null) {
        removedItems.remove(key, removed);
    }
    return success;
}
#end_block

#method_before
private boolean removeInternal(K key, Timestamp timestamp) {
    Timestamped<V> value = items.get(key);
    if (value != null) {
        if (value.isNewerThan(timestamp)) {
            return false;
        } else {
            items.remove(key, value);
        }
    }
    Timestamp removedTimestamp = removedItems.get(key);
    if (removedTimestamp == null) {
        return removedItems.putIfAbsent(key, timestamp) == null;
    } else if (timestamp.isNewerThan(removedTimestamp)) {
        return removedItems.replace(key, removedTimestamp, timestamp);
    } else {
        return false;
    }
}
#method_after
private boolean removeInternal(K key, Timestamp timestamp) {
    final MutableBoolean updated = new MutableBoolean(false);
    items.compute(key, (k, existing) -> {
        if (existing != null && existing.isNewerThan(timestamp)) {
            updated.setFalse();
            return existing;
        } else {
            updated.setTrue();
            // remove from items map
            return null;
        }
    });
    if (updated.isFalse()) {
        return false;
    }
    Timestamp removedTimestamp = removedItems.get(key);
    if (removedTimestamp == null) {
        return removedItems.putIfAbsent(key, timestamp) == null;
    } else if (timestamp.isNewerThan(removedTimestamp)) {
        return removedItems.replace(key, removedTimestamp, timestamp);
    } else {
        return false;
    }
}
#end_block

#method_before
private void handleAntiEntropyAdvertisement(AntiEntropyAdvertisement<K> ad) {
    List<EventuallyConsistentMapEvent<K, V>> externalEvents;
    boolean sync = false;
    // synchronized (this) {
    // TODO clean up commented out code
    externalEvents = antiEntropyCheckLocalItems(ad);
    antiEntropyCheckLocalRemoved(ad);
    // Send the advertisement outside the synchronized block
    if (sync) {
        final NodeId sender = ad.sender();
        AntiEntropyAdvertisement<K> myAd = createAdvertisement();
        try {
            unicastMessage(sender, antiEntropyAdvertisementSubject, myAd);
        } catch (IOException e) {
            log.debug("Failed to send reactive anti-entropy advertisement to {}", sender);
        }
    }
    externalEvents.forEach(this::notifyListeners);
}
#method_after
private void handleAntiEntropyAdvertisement(AntiEntropyAdvertisement<K> ad) {
    List<EventuallyConsistentMapEvent<K, V>> externalEvents;
    externalEvents = antiEntropyCheckLocalItems(ad);
    antiEntropyCheckLocalRemoved(ad);
    if (!lightweightAntiEntropy) {
        externalEvents.addAll(antiEntropyCheckRemoteRemoved(ad));
        // if remote ad has something unknown, actively sync
        for (K key : ad.timestamps().keySet()) {
            if (!items.containsKey(key)) {
                // Send the advertisement back if this peer is out-of-sync
                final NodeId sender = ad.sender();
                AntiEntropyAdvertisement<K> myAd = createAdvertisement();
                try {
                    unicastMessage(sender, antiEntropyAdvertisementSubject, myAd);
                } catch (IOException e) {
                    log.debug("Failed to send reactive anti-entropy advertisement to {}", sender);
                }
                break;
            }
        }
    }
    externalEvents.forEach(this::notifyListeners);
}
#end_block

#method_before
/**
 * Checks if any of the remote's live items or tombstones are out of date
 * according to our local live item list, or if our live items are out of
 * date according to the remote's tombstone list.
 * If the local copy is more recent, it will be pushed to the remote. If the
 * remote has a more recent remove, we apply that to the local state.
 *
 * @param ad remote anti-entropy advertisement
 * @return list of external events relating to local operations performed
 */
private List<EventuallyConsistentMapEvent<K, V>> antiEntropyCheckLocalItems(AntiEntropyAdvertisement<K> ad) {
    final List<EventuallyConsistentMapEvent<K, V>> externalEvents = new LinkedList<>();
    final NodeId sender = ad.sender();
    final List<PutEntry<K, V>> updatesToSend = new ArrayList<>();
    for (Map.Entry<K, Timestamped<V>> item : items.entrySet()) {
        K key = item.getKey();
        Timestamped<V> localValue = item.getValue();
        Timestamp remoteTimestamp = ad.timestamps().get(key);
        if (remoteTimestamp == null) {
            remoteTimestamp = ad.tombstones().get(key);
        }
        if (remoteTimestamp == null || localValue.isNewerThan(remoteTimestamp)) {
            // local value is more recent, push to sender
            updatesToSend.add(new PutEntry<>(key, localValue.value(), localValue.timestamp()));
        }
        Timestamp remoteDeadTimestamp = ad.tombstones().get(key);
        if (remoteDeadTimestamp != null && remoteDeadTimestamp.isNewerThan(localValue.timestamp())) {
            // sender has a more recent remove
            if (removeInternal(key, remoteDeadTimestamp)) {
                externalEvents.add(new EventuallyConsistentMapEvent<>(EventuallyConsistentMapEvent.Type.REMOVE, key, null));
            }
        }
    }
    // Send all updates to the peer at once
    if (!updatesToSend.isEmpty()) {
        try {
            unicastMessage(sender, updateMessageSubject, new InternalPutEvent<>(updatesToSend));
        } catch (IOException e) {
            log.warn("Failed to send advertisement response", e);
        }
    }
    return externalEvents;
}
#method_after
private List<EventuallyConsistentMapEvent<K, V>> antiEntropyCheckLocalItems(AntiEntropyAdvertisement<K> ad) {
    final List<EventuallyConsistentMapEvent<K, V>> externalEvents = new LinkedList<>();
    final NodeId sender = ad.sender();
    final List<PutEntry<K, V>> updatesToSend = new ArrayList<>();
    for (Map.Entry<K, Timestamped<V>> item : items.entrySet()) {
        K key = item.getKey();
        Timestamped<V> localValue = item.getValue();
        Timestamp remoteTimestamp = ad.timestamps().get(key);
        if (remoteTimestamp == null) {
            remoteTimestamp = ad.tombstones().get(key);
        }
        if (remoteTimestamp == null || localValue.isNewerThan(remoteTimestamp)) {
            // local value is more recent, push to sender
            updatesToSend.add(new PutEntry<>(key, localValue.value(), localValue.timestamp()));
        }
        Timestamp remoteDeadTimestamp = ad.tombstones().get(key);
        if (remoteDeadTimestamp != null && remoteDeadTimestamp.isNewerThan(localValue.timestamp())) {
            // sender has a more recent remove
            if (removeInternal(key, remoteDeadTimestamp)) {
                externalEvents.add(new EventuallyConsistentMapEvent<>(EventuallyConsistentMapEvent.Type.REMOVE, key, null));
            }
        }
    }
    // Send all updates to the peer at once
    if (!updatesToSend.isEmpty()) {
        try {
            unicastMessage(sender, updateMessageSubject, new InternalPutEvent<>(updatesToSend));
        } catch (IOException e) {
            log.warn("Failed to send advertisement response", e);
        }
    }
    return externalEvents;
}
#end_block

#method_before
/**
 * Checks if any items in the remote live list are out of date according
 * to our tombstone list. If we find we have a more up to date tombstone,
 * we'll send it to the remote.
 *
 * @param ad remote anti-entropy advertisement
 */
private void antiEntropyCheckLocalRemoved(AntiEntropyAdvertisement<K> ad) {
    final NodeId sender = ad.sender();
    final List<RemoveEntry<K>> removesToSend = new ArrayList<>();
    for (Map.Entry<K, Timestamp> dead : removedItems.entrySet()) {
        K key = dead.getKey();
        Timestamp localDeadTimestamp = dead.getValue();
        Timestamp remoteLiveTimestamp = ad.timestamps().get(key);
        if (remoteLiveTimestamp != null && localDeadTimestamp.isNewerThan(remoteLiveTimestamp)) {
            // sender has zombie, push remove
            removesToSend.add(new RemoveEntry<>(key, localDeadTimestamp));
        }
    }
    // Send all removes to the peer at once
    if (!removesToSend.isEmpty()) {
        try {
            unicastMessage(sender, removeMessageSubject, new InternalRemoveEvent<>(removesToSend));
        } catch (IOException e) {
            log.warn("Failed to send advertisement response", e);
        }
    }
}
#method_after
private void antiEntropyCheckLocalRemoved(AntiEntropyAdvertisement<K> ad) {
    final NodeId sender = ad.sender();
    final List<RemoveEntry<K>> removesToSend = new ArrayList<>();
    for (Map.Entry<K, Timestamp> dead : removedItems.entrySet()) {
        K key = dead.getKey();
        Timestamp localDeadTimestamp = dead.getValue();
        Timestamp remoteLiveTimestamp = ad.timestamps().get(key);
        if (remoteLiveTimestamp != null && localDeadTimestamp.isNewerThan(remoteLiveTimestamp)) {
            // sender has zombie, push remove
            removesToSend.add(new RemoveEntry<>(key, localDeadTimestamp));
        }
    }
    // Send all removes to the peer at once
    if (!removesToSend.isEmpty()) {
        try {
            unicastMessage(sender, removeMessageSubject, new InternalRemoveEvent<>(removesToSend));
        } catch (IOException e) {
            log.warn("Failed to send advertisement response", e);
        }
    }
}
#end_block

#method_before
/**
 * Checks if any of the local live items are out of date according to the
 * remote's tombstone advertisements. If we find a local item is out of date,
 * we'll apply the remove operation to the local state.
 *
 * @param ad remote anti-entropy advertisement
 * @return list of external events relating to local operations performed
 */
private List<EventuallyConsistentMapEvent<K, V>> antiEntropyCheckRemoteRemoved(AntiEntropyAdvertisement<K> ad) {
    final List<EventuallyConsistentMapEvent<K, V>> externalEvents = new LinkedList<>();
    for (Map.Entry<K, Timestamp> remoteDead : ad.tombstones().entrySet()) {
        K key = remoteDead.getKey();
        Timestamp remoteDeadTimestamp = remoteDead.getValue();
        Timestamped<V> local = items.get(key);
        Timestamp localDead = removedItems.get(key);
        if (local != null && remoteDeadTimestamp.isNewerThan(local.timestamp())) {
            // value, then do a remove with their timestamp
            if (removeInternal(key, remoteDeadTimestamp)) {
                externalEvents.add(new EventuallyConsistentMapEvent<>(EventuallyConsistentMapEvent.Type.REMOVE, key, null));
            }
        } else if (localDead != null && remoteDeadTimestamp.isNewerThan(localDead)) {
            // If the remote has a more recent tombstone than us, update ours
            // to their timestamp
            removeInternal(key, remoteDeadTimestamp);
        }
    }
    return externalEvents;
}
#method_after
private List<EventuallyConsistentMapEvent<K, V>> antiEntropyCheckRemoteRemoved(AntiEntropyAdvertisement<K> ad) {
    final List<EventuallyConsistentMapEvent<K, V>> externalEvents = new LinkedList<>();
    for (Map.Entry<K, Timestamp> remoteDead : ad.tombstones().entrySet()) {
        K key = remoteDead.getKey();
        Timestamp remoteDeadTimestamp = remoteDead.getValue();
        Timestamped<V> local = items.get(key);
        Timestamp localDead = removedItems.get(key);
        if (local != null && remoteDeadTimestamp.isNewerThan(local.timestamp())) {
            // value, then do a remove with their timestamp
            if (removeInternal(key, remoteDeadTimestamp)) {
                externalEvents.add(new EventuallyConsistentMapEvent<>(EventuallyConsistentMapEvent.Type.REMOVE, key, null));
            }
        } else if (localDead != null && remoteDeadTimestamp.isNewerThan(localDead)) {
            // If the remote has a more recent tombstone than us, update ours
            // to their timestamp
            removeInternal(key, remoteDeadTimestamp);
        }
    }
    return externalEvents;
}
#end_block

#method_before
@Activate
public void activate() {
    KryoNamespace.Builder intentSerializer = KryoNamespace.newBuilder().register(KryoNamespaces.API).register(IntentData.class).register(MultiValuedTimestamp.class).register(WallClockTimestamp.class);
    currentState = new EventuallyConsistentMapImpl<>("intent-current", clusterService, clusterCommunicator, intentSerializer, new IntentDataLogicalClockManager<>());
    pending = new EventuallyConsistentMapImpl<>("intent-pending", clusterService, clusterCommunicator, // TODO
    intentSerializer, new IntentDataClockManager<>());
    currentState.addListener(new InternalIntentStatesListener());
    pending.addListener(new InternalPendingListener());
    log.info("Started");
}
#method_after
@Activate
public void activate() {
    KryoNamespace.Builder intentSerializer = KryoNamespace.newBuilder().register(KryoNamespaces.API).register(IntentData.class).register(MultiValuedTimestamp.class).register(WallClockTimestamp.class);
    currentMap = new EventuallyConsistentMapImpl<>("intent-current", clusterService, clusterCommunicator, intentSerializer, new IntentDataLogicalClockManager<>());
    pendingMap = new EventuallyConsistentMapImpl<>("intent-pending", clusterService, clusterCommunicator, // TODO
    intentSerializer, new IntentDataClockManager<>());
    currentMap.addListener(new InternalIntentStatesListener());
    pendingMap.addListener(new InternalPendingListener());
    log.info("Started");
}
#end_block

#method_before
@Deactivate
public void deactivate() {
    currentState.destroy();
    pending.destroy();
    log.info("Stopped");
}
#method_after
@Deactivate
public void deactivate() {
    currentMap.destroy();
    pendingMap.destroy();
    log.info("Stopped");
}
#end_block

#method_before
@Override
public long getIntentCount() {
    return currentState.size();
}
#method_after
@Override
public long getIntentCount() {
    return currentMap.size();
}
#end_block

#method_before
@Override
public Iterable<Intent> getIntents() {
    return currentState.values().stream().map(IntentData::intent).collect(Collectors.toList());
}
#method_after
@Override
public Iterable<Intent> getIntents() {
    return currentMap.values().stream().map(IntentData::intent).collect(Collectors.toList());
}
#end_block

#method_before
@Override
public IntentState getIntentState(Key intentKey) {
    IntentData data = currentState.get(intentKey);
    if (data != null) {
        return data.state();
    }
    return null;
}
#method_after
@Override
public IntentState getIntentState(Key intentKey) {
    IntentData data = currentMap.get(intentKey);
    if (data != null) {
        return data.state();
    }
    return null;
}
#end_block

#method_before
@Override
public List<Intent> getInstallableIntents(Key intentKey) {
    IntentData data = currentState.get(intentKey);
    if (data != null) {
        return data.installables();
    }
    return null;
}
#method_after
@Override
public List<Intent> getInstallableIntents(Key intentKey) {
    IntentData data = currentMap.get(intentKey);
    if (data != null) {
        return data.installables();
    }
    return null;
}
#end_block

#method_before
@Override
public void write(IntentData newData) {
    IntentData currentData = currentState.get(newData.key());
    if (isUpdateAcceptable(currentData, newData)) {
        // Only the master is modifying the current state. Therefore assume
        // this always succeeds
        currentState.put(newData.key(), copyData(newData));
        // if current.put succeeded
        pending.remove(newData.key(), newData);
    } else {
        log.debug("not writing update: {}", newData);
    }
}
#method_after
@Override
public void write(IntentData newData) {
    IntentData currentData = currentMap.get(newData.key());
    if (isUpdateAcceptable(currentData, newData)) {
        // Only the master is modifying the current state. Therefore assume
        // this always succeeds
        currentMap.put(newData.key(), copyData(newData));
        // if current.put succeeded
        pendingMap.remove(newData.key(), newData);
    } else {
        log.debug("not writing update: current {}, new {}", currentData, newData);
    }
}
#end_block

#method_before
@Override
public Intent getIntent(Key key) {
    IntentData data = currentState.get(key);
    if (data != null) {
        return data.intent();
    }
    return null;
}
#method_after
@Override
public Intent getIntent(Key key) {
    IntentData data = currentMap.get(key);
    if (data != null) {
        return data.intent();
    }
    return null;
}
#end_block

#method_before
@Override
public IntentData getIntentData(Key key) {
    return copyData(currentState.get(key));
}
#method_after
@Override
public IntentData getIntentData(Key key) {
    return copyData(currentMap.get(key));
}
#end_block

#method_before
@Override
public void addPending(IntentData data) {
    if (data.version() == null) {
        data.setVersion(new WallClockTimestamp());
    }
    pending.put(data.key(), copyData(data));
}
#method_after
@Override
public void addPending(IntentData data) {
    if (data.version() == null) {
        data.setVersion(new WallClockTimestamp());
    }
    pendingMap.put(data.key(), copyData(data));
}
#end_block

#method_before
@Override
public void event(EventuallyConsistentMapEvent<Key, IntentData> event) {
    if (event.type() == EventuallyConsistentMapEvent.Type.PUT) {
        // some work.
        if (isMaster(event.value().intent().key())) {
            if (delegate != null) {
                delegate.process(copyData(event.value()));
            }
        }
        notifyDelegateIfNotNull(IntentEvent.getEvent(event.value()));
    }
}
#method_after
@Override
public void event(EventuallyConsistentMapEvent<Key, IntentData> event) {
    if (event.type() == EventuallyConsistentMapEvent.Type.PUT) {
        // some work.
        if (isMaster(event.value().intent().key())) {
            if (delegate != null) {
                log.debug("processing {}", event.key());
                delegate.process(copyData(event.value()));
            }
        }
        notifyDelegateIfNotNull(IntentEvent.getEvent(event.value()));
    }
}
#end_block

#method_before
public Double phi(NodeId nodeId) {
    if (!states.containsKey(nodeId)) {
        return BOOTSTRAP_PHI_VALUE;
    }
    checkNotNull(nodeId, "NodeId must not be null");
    History nodeState = states.get(nodeId);
    synchronized (nodeState) {
        long latestHeartbeat = nodeState.latestHeartbeatTime();
        DescriptiveStatistics samples = nodeState.samples();
        if (latestHeartbeat == -1 || samples.getN() < MIN_SAMPLES) {
            return 0.0;
        }
        return computePhi(samples, latestHeartbeat, System.currentTimeMillis());
    }
}
#method_after
public double phi(NodeId nodeId) {
    checkNotNull(nodeId, "NodeId must not be null");
    if (!states.containsKey(nodeId)) {
        return BOOTSTRAP_PHI_VALUE;
    }
    History nodeState = states.get(nodeId);
    synchronized (nodeState) {
        long latestHeartbeat = nodeState.latestHeartbeatTime();
        DescriptiveStatistics samples = nodeState.samples();
        if (latestHeartbeat == -1 || samples.getN() < MIN_SAMPLES) {
            return 0.0;
        }
        return computePhi(samples, latestHeartbeat, System.currentTimeMillis());
    }
}
#end_block

#method_before
private double computePhi(DescriptiveStatistics samples, long tLast, long tNow) {
    long size = samples.getN();
    long t = tNow - tLast;
    return (size > 0) ? (1.0 / Math.log(10.0)) * t / samples.getMean() : BOOTSTRAP_PHI_VALUE;
}
#method_after
private double computePhi(DescriptiveStatistics samples, long tLast, long tNow) {
    long size = samples.getN();
    long t = tNow - tLast;
    return (size > 0) ? PHI_FACTOR * t / samples.getMean() : BOOTSTRAP_PHI_VALUE;
}
#end_block

#method_before
@Activate
public void activate() {
    File clusterDefinitionFile = new File(CONFIG_DIR, CLUSTER_DEFINITION_FILE);
    try {
        clusterDefinition = new ClusterDefinitionStore(clusterDefinitionFile.getPath()).read();
        seedNodes = ImmutableSet.copyOf(clusterDefinition.nodes());
    } catch (IOException e) {
        log.warn("Failed to read cluster definition.", e);
    }
    seedNodes.forEach(node -> {
        allNodes.put(node.id(), node);
        nodeStates.put(node.id(), State.INACTIVE);
    });
    establishSelfIdentity();
    messagingService = new NettyMessagingService(HEARTBEAT_FD_PORT);
    try {
        messagingService.activate();
    } catch (InterruptedException e) {
        Thread.currentThread().interrupt();
        log.warn("Failed to cleanly initialize membership and" + " failure detector communication channel.", e);
    }
    messagingService.registerHandler(HEARTBEAT_MESSAGE, new HeartbeatMessageHandler(), heartBeatMessageHandler);
    eventDispatcher.addSink(ClusterEvent.class, listenerRegistry);
    failureDetector = new PhiAccrualFailureDetector();
    heartBeatSender.scheduleWithFixedDelay(this::heartbeat, 0, HEARTBEAT_INTERVAL_MS, TimeUnit.MILLISECONDS);
    log.info("Started");
}
#method_after
@Activate
public void activate() {
    File clusterDefinitionFile = new File(CONFIG_DIR, CLUSTER_DEFINITION_FILE);
    try {
        clusterDefinition = new ClusterDefinitionStore(clusterDefinitionFile.getPath()).read();
        seedNodes = ImmutableSet.copyOf(clusterDefinition.nodes());
    } catch (IOException e) {
        log.warn("Failed to read cluster definition.", e);
    }
    seedNodes.forEach(node -> {
        allNodes.put(node.id(), node);
        nodeStates.put(node.id(), State.INACTIVE);
    });
    establishSelfIdentity();
    messagingService = new NettyMessagingService(HEARTBEAT_FD_PORT);
    try {
        messagingService.activate();
    } catch (InterruptedException e) {
        Thread.currentThread().interrupt();
        throw new IllegalStateException("Failed to cleanly initialize membership and" + " failure detector communication channel.", e);
    }
    messagingService.registerHandler(HEARTBEAT_MESSAGE, new HeartbeatMessageHandler(), heartBeatMessageHandler);
    eventDispatcher.addSink(ClusterEvent.class, listenerRegistry);
    failureDetector = new PhiAccrualFailureDetector();
    heartBeatSender.scheduleWithFixedDelay(this::heartbeat, 0, HEARTBEAT_INTERVAL_MS, TimeUnit.MILLISECONDS);
    log.info("Started");
}
#end_block

#method_before
@Deactivate
public void deactivate() {
    try {
        messagingService.deactivate();
    } catch (Exception e) {
        log.trace("Failed to cleanly shutdown cluster membership messaging", e);
    }
    heartBeatSender.shutdown();
    heartBeatMessageHandler.shutdown();
    eventDispatcher.removeSink(ClusterEvent.class);
    log.info("Stopped");
}
#method_after
@Deactivate
public void deactivate() {
    try {
        messagingService.deactivate();
    } catch (Exception e) {
        log.trace("Failed to cleanly shutdown cluster membership messaging", e);
    }
    heartBeatSender.shutdownNow();
    heartBeatMessageHandler.shutdownNow();
    eventDispatcher.removeSink(ClusterEvent.class);
    log.info("Stopped");
}
#end_block

#method_before
private IpAddress findLocalIp() throws SocketException {
    Pattern ipPattern = Pattern.compile(clusterDefinition.ipPrefix());
    Enumeration<NetworkInterface> interfaces = NetworkInterface.getNetworkInterfaces();
    while (interfaces.hasMoreElements()) {
        NetworkInterface iface = interfaces.nextElement();
        Enumeration<InetAddress> inetAddresses = iface.getInetAddresses();
        while (inetAddresses.hasMoreElements()) {
            InetAddress ia = inetAddresses.nextElement();
            if (!ia.isLinkLocalAddress()) {
                IpAddress ip = IpAddress.valueOf(ia);
                if (ipPattern.matcher(ip.toString()).matches()) {
                    return ip;
                }
            }
        }
    }
    throw new IllegalStateException("Unable to determine local ip");
}
#method_after
private IpAddress findLocalIp() throws SocketException {
    Enumeration<NetworkInterface> interfaces = NetworkInterface.getNetworkInterfaces();
    while (interfaces.hasMoreElements()) {
        NetworkInterface iface = interfaces.nextElement();
        Enumeration<InetAddress> inetAddresses = iface.getInetAddresses();
        while (inetAddresses.hasMoreElements()) {
            IpAddress ip = IpAddress.valueOf(inetAddresses.nextElement());
            if (AddressUtil.matchInterface(ip.toString(), clusterDefinition.ipPrefix())) {
                return ip;
            }
        }
    }
    throw new IllegalStateException("Unable to determine local ip");
}
#end_block

#method_before
@Activate
public void activate() {
    providerService = providerRegistry.register(this);
    controller.addListener(listener);
    controller.addEventListener(listener);
    for (OpenFlowSwitch sw : controller.getSwitches()) {
        GroupStatsCollector gsc = new GroupStatsCollector(sw, POLL_INTERVAL);
        gsc.start();
        collectors.put(new Dpid(sw.getId()), gsc);
    }
    log.info("Started");
}
#method_after
@Activate
public void activate() {
    providerService = providerRegistry.register(this);
    controller.addListener(listener);
    controller.addEventListener(listener);
    for (OpenFlowSwitch sw : controller.getSwitches()) {
        if (isGroupSupported(sw)) {
            GroupStatsCollector gsc = new GroupStatsCollector(sw, POLL_INTERVAL);
            gsc.start();
            collectors.put(new Dpid(sw.getId()), gsc);
        }
    }
    log.info("Started");
}
#end_block

#method_before
@Override
public void performGroupOperation(DeviceId deviceId, GroupOperations groupOps) {
    Map<OFGroupMod, OpenFlowSwitch> mods = Maps.newIdentityHashMap();
    final Dpid dpid = Dpid.dpid(deviceId.uri());
    OpenFlowSwitch sw = controller.getSwitch(dpid);
    for (GroupOperation groupOperation : groupOps.operations()) {
        if (sw == null) {
            log.error("SW {} is not found", dpid);
            return;
        }
        final Long groupModXid = XID_COUNTER.getAndIncrement();
        GroupModBuilder builder = GroupModBuilder.builder(groupOperation.buckets(), groupOperation.groupId(), groupOperation.groupType(), sw.factory(), Optional.of(groupModXid));
        OFGroupMod groupMod = null;
        switch(groupOperation.opType()) {
            case ADD:
                groupMod = builder.buildGroupAdd();
                break;
            case MODIFY:
                groupMod = builder.buildGroupMod();
                break;
            case DELETE:
                groupMod = builder.buildGroupDel();
                break;
            default:
                log.error("Unsupported Group operation");
        }
        sw.sendMsg(groupMod);
        pendingGroupOperations.put(groupMod.getGroup().getGroupNumber(), groupOperation);
        pendingXidMaps.put(groupMod.getGroup().getGroupNumber(), groupModXid);
    }
}
#method_after
@Override
public void performGroupOperation(DeviceId deviceId, GroupOperations groupOps) {
    Map<OFGroupMod, OpenFlowSwitch> mods = Maps.newIdentityHashMap();
    final Dpid dpid = Dpid.dpid(deviceId.uri());
    OpenFlowSwitch sw = controller.getSwitch(dpid);
    for (GroupOperation groupOperation : groupOps.operations()) {
        if (sw == null) {
            log.error("SW {} is not found", dpid);
            return;
        }
        final Long groupModXid = XID_COUNTER.getAndIncrement();
        GroupModBuilder builder = GroupModBuilder.builder(groupOperation.buckets(), groupOperation.groupId(), groupOperation.groupType(), sw.factory(), Optional.of(groupModXid));
        OFGroupMod groupMod = null;
        switch(groupOperation.opType()) {
            case ADD:
                groupMod = builder.buildGroupAdd();
                break;
            case MODIFY:
                groupMod = builder.buildGroupMod();
                break;
            case DELETE:
                groupMod = builder.buildGroupDel();
                break;
            default:
                log.error("Unsupported Group operation");
        }
        sw.sendMsg(groupMod);
        GroupId groudId = new DefaultGroupId(groupMod.getGroup().getGroupNumber());
        pendingGroupOperations.put(groudId, groupOperation);
        pendingXidMaps.put(groudId, groupModXid);
    }
}
#end_block

#method_before
private void pushGroupMetrics(Dpid dpid, OFStatsReply statsReply) {
    DeviceId deviceId = DeviceId.deviceId(Dpid.uri(dpid));
    OFGroupStatsReply groupStatsReply = null;
    OFGroupDescStatsReply groupDescStatsReply = null;
    synchronized (groupStats) {
        if (statsReply.getStatsType() == OFStatsType.GROUP) {
            OFStatsReply reply = groupStats.get(statsReply.getXid() + 1);
            if (reply != null) {
                groupStatsReply = (OFGroupStatsReply) statsReply;
                groupDescStatsReply = (OFGroupDescStatsReply) reply;
                groupStats.remove(statsReply.getXid() + 1);
            } else {
                groupStats.put(statsReply.getXid(), statsReply);
            }
        } else if (statsReply.getStatsType() == OFStatsType.GROUP_DESC) {
            OFStatsReply reply = groupStats.get(statsReply.getXid() - 1);
            if (reply != null) {
                groupStatsReply = (OFGroupStatsReply) reply;
                groupDescStatsReply = (OFGroupDescStatsReply) statsReply;
                groupStats.remove(statsReply.getXid() - 1);
            } else {
                groupStats.put(statsReply.getXid(), statsReply);
            }
        }
    }
    if (groupStatsReply != null && groupDescStatsReply != null) {
        Collection<Group> groups = buildGroupMetrics(deviceId, groupStatsReply, groupDescStatsReply);
        providerService.pushGroupMetrics(deviceId, groups);
        for (Group group : groups) {
            pendingGroupOperations.remove(group.id().id());
            pendingXidMaps.remove(group.id().id());
        }
    }
}
#method_after
private void pushGroupMetrics(Dpid dpid, OFStatsReply statsReply) {
    DeviceId deviceId = DeviceId.deviceId(Dpid.uri(dpid));
    OFGroupStatsReply groupStatsReply = null;
    OFGroupDescStatsReply groupDescStatsReply = null;
    synchronized (groupStats) {
        if (statsReply.getStatsType() == OFStatsType.GROUP) {
            OFStatsReply reply = groupStats.get(statsReply.getXid() + 1);
            if (reply != null) {
                groupStatsReply = (OFGroupStatsReply) statsReply;
                groupDescStatsReply = (OFGroupDescStatsReply) reply;
                groupStats.remove(statsReply.getXid() + 1);
            } else {
                groupStats.put(statsReply.getXid(), statsReply);
            }
        } else if (statsReply.getStatsType() == OFStatsType.GROUP_DESC) {
            OFStatsReply reply = groupStats.get(statsReply.getXid() - 1);
            if (reply != null) {
                groupStatsReply = (OFGroupStatsReply) reply;
                groupDescStatsReply = (OFGroupDescStatsReply) statsReply;
                groupStats.remove(statsReply.getXid() - 1);
            } else {
                groupStats.put(statsReply.getXid(), statsReply);
            }
        }
    }
    if (groupStatsReply != null && groupDescStatsReply != null) {
        Collection<Group> groups = buildGroupMetrics(deviceId, groupStatsReply, groupDescStatsReply);
        providerService.pushGroupMetrics(deviceId, groups);
        for (Group group : groups) {
            pendingGroupOperations.remove(group.id());
            pendingXidMaps.remove(group.id());
        }
    }
}
#end_block

#method_before
@Override
public void handleMessage(Dpid dpid, OFMessage msg) {
    switch(msg.getType()) {
        case STATS_REPLY:
            pushGroupMetrics(dpid, (OFStatsReply) msg);
            break;
        case ERROR:
            OFErrorMsg errorMsg = (OFErrorMsg) msg;
            if (errorMsg.getErrType() == OFErrorType.GROUP_MOD_FAILED) {
                int pendingGroupId = -1;
                for (Map.Entry<Integer, Long> entry : pendingXidMaps.entrySet()) {
                    if (entry.getValue() == errorMsg.getXid()) {
                        pendingGroupId = entry.getKey();
                        break;
                    }
                }
                if (pendingGroupId == -1) {
                    log.warn("Error for unknown group operation: {}", errorMsg.getXid());
                } else {
                    GroupOperation operation = pendingGroupOperations.get(pendingGroupId);
                    DeviceId deviceId = DeviceId.deviceId(Dpid.uri(dpid));
                    if (operation != null) {
                        providerService.groupOperationFailed(deviceId, operation);
                        pendingGroupOperations.remove(pendingGroupId);
                        pendingXidMaps.remove(pendingGroupId);
                        log.warn("Received an group mod error {}", msg);
                    } else {
                        log.error("Cannot find pending group operation with group ID: {}", pendingGroupId);
                    }
                }
                break;
            }
        default:
            log.debug("Unhandled message type: {}", msg.getType());
    }
}
#method_after
@Override
public void handleMessage(Dpid dpid, OFMessage msg) {
    switch(msg.getType()) {
        case STATS_REPLY:
            pushGroupMetrics(dpid, (OFStatsReply) msg);
            break;
        case ERROR:
            OFErrorMsg errorMsg = (OFErrorMsg) msg;
            if (errorMsg.getErrType() == OFErrorType.GROUP_MOD_FAILED) {
                GroupId pendingGroupId = null;
                for (Map.Entry<GroupId, Long> entry : pendingXidMaps.entrySet()) {
                    if (entry.getValue() == errorMsg.getXid()) {
                        pendingGroupId = entry.getKey();
                        break;
                    }
                }
                if (pendingGroupId == null) {
                    log.warn("Error for unknown group operation: {}", errorMsg.getXid());
                } else {
                    GroupOperation operation = pendingGroupOperations.get(pendingGroupId);
                    DeviceId deviceId = DeviceId.deviceId(Dpid.uri(dpid));
                    if (operation != null) {
                        providerService.groupOperationFailed(deviceId, operation);
                        pendingGroupOperations.remove(pendingGroupId);
                        pendingXidMaps.remove(pendingGroupId);
                        log.warn("Received an group mod error {}", msg);
                    } else {
                        log.error("Cannot find pending group operation with group ID: {}", pendingGroupId);
                    }
                }
                break;
            }
        default:
            log.debug("Unhandled message type: {}", msg.getType());
    }
}
#end_block

#method_before
@Override
public void switchAdded(Dpid dpid) {
    GroupStatsCollector gsc = new GroupStatsCollector(controller.getSwitch(dpid), POLL_INTERVAL);
    gsc.start();
    collectors.put(dpid, gsc);
}
#method_after
@Override
public void switchAdded(Dpid dpid) {
    OpenFlowSwitch sw = controller.getSwitch(dpid);
    if (isGroupSupported(sw)) {
        GroupStatsCollector gsc = new GroupStatsCollector(controller.getSwitch(dpid), POLL_INTERVAL);
        gsc.start();
        collectors.put(dpid, gsc);
    }
}
#end_block

#method_before
private void applyRule(FlowRule flowRule) {
    OpenFlowSwitch sw = controller.getSwitch(Dpid.dpid(flowRule.deviceId().uri()));
    if (flowRule.type() == FlowRule.Type.DEFAULT) {
        sw.sendMsg(FlowModBuilder.builder(flowRule, sw.factory(), Optional.empty()).buildFlowAdd());
    } else {
        sw.sendMsg(FlowModBuilder.builder(flowRule, sw.factory(), Optional.empty()).buildFlowAdd(), getTableType(flowRule.type()));
    }
}
#method_after
private void applyRule(FlowRule flowRule) {
    OpenFlowSwitch sw = controller.getSwitch(Dpid.dpid(flowRule.deviceId().uri()));
    if (flowRule.type() == FlowRule.Type.DEFAULT) {
        sw.sendMsg(FlowModBuilder.builder(flowRule, sw.factory(), Optional.empty()).buildFlowAdd());
    } else {
        OpenFlowSwitch.TableType type = getTableType(flowRule.type());
        sw.sendMsg(FlowModBuilder.builder(flowRule, sw.factory(), Optional.empty()).buildFlowAdd(), type);
    }
}
#end_block

#method_before
private OpenFlowSwitch.TableType getTableType(FlowRule.Type type) {
    switch(type) {
        case IP:
            return OpenFlowSwitch.TableType.IP;
        case MPLS:
            return OpenFlowSwitch.TableType.MPLS;
        case ACL:
            return OpenFlowSwitch.TableType.ACL;
        default:
            return OpenFlowSwitch.TableType.NONE;
    }
}
#method_after
private OpenFlowSwitch.TableType getTableType(FlowRule.Type type) {
    switch(type) {
        case DEFAULT:
            return OpenFlowSwitch.TableType.NONE;
        case IP:
            return OpenFlowSwitch.TableType.IP;
        case MPLS:
            return OpenFlowSwitch.TableType.MPLS;
        case ACL:
            return OpenFlowSwitch.TableType.ACL;
        case VLAN_MPLS:
            return OpenFlowSwitch.TableType.VLAN_MPLS;
        case VLAN:
            return OpenFlowSwitch.TableType.VLAN;
        case ETHER:
            return OpenFlowSwitch.TableType.ETHER;
        case COS:
            return OpenFlowSwitch.TableType.COS;
        default:
            return OpenFlowSwitch.TableType.NONE;
    }
}
#end_block

#method_before
public boolean isNewer(Timestamped<T> other) {
    return isNewer(checkNotNull(other).timestamp());
}
#method_after
public boolean isNewer(Timestamped<T> other) {
    return isNewerThan(checkNotNull(other).timestamp());
}
#end_block

#method_before
private boolean putInternal(K key, V value, Timestamp timestamp) {
    Timestamp removed = removedItems.get(key);
    if (removed != null && removed.isNewer(timestamp)) {
        log.debug("ecmap - removed was newer {}", value);
        return false;
    }
    boolean success;
    synchronized (this) {
        Timestamped<V> existing = items.get(key);
        if (existing != null && existing.isNewer(timestamp)) {
            log.debug("ecmap - existing was newer {}", value);
            success = false;
        } else {
            items.put(key, new Timestamped<>(value, timestamp));
            success = true;
        }
    }
    if (success && removed != null) {
        removedItems.remove(key, removed);
    }
    return success;
}
#method_after
private boolean putInternal(K key, V value, Timestamp timestamp) {
    Timestamp removed = removedItems.get(key);
    if (removed != null && removed.isNewerThan(timestamp)) {
        log.debug("ecmap - removed was newer {}", value);
        return false;
    }
    boolean success;
    synchronized (this) {
        Timestamped<V> existing = items.get(key);
        if (existing != null && existing.isNewerThan(timestamp)) {
            log.debug("ecmap - existing was newer {}", value);
            success = false;
        } else {
            items.put(key, new Timestamped<>(value, timestamp));
            success = true;
        }
    }
    if (success && removed != null) {
        removedItems.remove(key, removed);
    }
    return success;
}
#end_block

#method_before
private boolean removeInternal(K key, Timestamp timestamp) {
    Timestamped<V> value = items.get(key);
    if (value != null) {
        if (value.isNewer(timestamp)) {
            return false;
        } else {
            items.remove(key, value);
        }
    }
    Timestamp removedTimestamp = removedItems.get(key);
    if (removedTimestamp == null) {
        return removedItems.putIfAbsent(key, timestamp) == null;
    } else if (timestamp.isNewer(removedTimestamp)) {
        return removedItems.replace(key, removedTimestamp, timestamp);
    } else {
        return false;
    }
}
#method_after
private boolean removeInternal(K key, Timestamp timestamp) {
    Timestamped<V> value = items.get(key);
    if (value != null) {
        if (value.isNewerThan(timestamp)) {
            return false;
        } else {
            items.remove(key, value);
        }
    }
    Timestamp removedTimestamp = removedItems.get(key);
    if (removedTimestamp == null) {
        return removedItems.putIfAbsent(key, timestamp) == null;
    } else if (timestamp.isNewerThan(removedTimestamp)) {
        return removedItems.replace(key, removedTimestamp, timestamp);
    } else {
        return false;
    }
}
#end_block

#method_before
/**
 * Checks if any of the remote's live items or tombstones are out of date
 * according to our local live item list, or if our live items are out of
 * date according to the remote's tombstone list.
 * If the local copy is more recent, it will be pushed to the remote. If the
 * remote has a more recent remove, we apply that to the local state.
 *
 * @param ad remote anti-entropy advertisement
 * @return list of external events relating to local operations performed
 */
private List<EventuallyConsistentMapEvent<K, V>> antiEntropyCheckLocalItems(AntiEntropyAdvertisement<K> ad) {
    final List<EventuallyConsistentMapEvent<K, V>> externalEvents = new LinkedList<>();
    final NodeId sender = ad.sender();
    final List<PutEntry<K, V>> updatesToSend = new ArrayList<>();
    for (Map.Entry<K, Timestamped<V>> item : items.entrySet()) {
        K key = item.getKey();
        Timestamped<V> localValue = item.getValue();
        Timestamp remoteTimestamp = ad.timestamps().get(key);
        if (remoteTimestamp == null) {
            remoteTimestamp = ad.tombstones().get(key);
        }
        if (remoteTimestamp == null || localValue.isNewer(remoteTimestamp)) {
            // local value is more recent, push to sender
            updatesToSend.add(new PutEntry<>(key, localValue.value(), localValue.timestamp()));
        }
        Timestamp remoteDeadTimestamp = ad.tombstones().get(key);
        if (remoteDeadTimestamp != null && remoteDeadTimestamp.isNewer(localValue.timestamp())) {
            // sender has a more recent remove
            if (removeInternal(key, remoteDeadTimestamp)) {
                externalEvents.add(new EventuallyConsistentMapEvent<>(EventuallyConsistentMapEvent.Type.REMOVE, key, null));
            }
        }
    }
    // Send all updates to the peer at once
    if (!updatesToSend.isEmpty()) {
        try {
            unicastMessage(sender, updateMessageSubject, new InternalPutEvent<>(updatesToSend));
        } catch (IOException e) {
            log.warn("Failed to send advertisement response", e);
        }
    }
    return externalEvents;
}
#method_after
/**
 * Checks if any of the remote's live items or tombstones are out of date
 * according to our local live item list, or if our live items are out of
 * date according to the remote's tombstone list.
 * If the local copy is more recent, it will be pushed to the remote. If the
 * remote has a more recent remove, we apply that to the local state.
 *
 * @param ad remote anti-entropy advertisement
 * @return list of external events relating to local operations performed
 */
private List<EventuallyConsistentMapEvent<K, V>> antiEntropyCheckLocalItems(AntiEntropyAdvertisement<K> ad) {
    final List<EventuallyConsistentMapEvent<K, V>> externalEvents = new LinkedList<>();
    final NodeId sender = ad.sender();
    final List<PutEntry<K, V>> updatesToSend = new ArrayList<>();
    for (Map.Entry<K, Timestamped<V>> item : items.entrySet()) {
        K key = item.getKey();
        Timestamped<V> localValue = item.getValue();
        Timestamp remoteTimestamp = ad.timestamps().get(key);
        if (remoteTimestamp == null) {
            remoteTimestamp = ad.tombstones().get(key);
        }
        if (remoteTimestamp == null || localValue.isNewerThan(remoteTimestamp)) {
            // local value is more recent, push to sender
            updatesToSend.add(new PutEntry<>(key, localValue.value(), localValue.timestamp()));
        }
        Timestamp remoteDeadTimestamp = ad.tombstones().get(key);
        if (remoteDeadTimestamp != null && remoteDeadTimestamp.isNewerThan(localValue.timestamp())) {
            // sender has a more recent remove
            if (removeInternal(key, remoteDeadTimestamp)) {
                externalEvents.add(new EventuallyConsistentMapEvent<>(EventuallyConsistentMapEvent.Type.REMOVE, key, null));
            }
        }
    }
    // Send all updates to the peer at once
    if (!updatesToSend.isEmpty()) {
        try {
            unicastMessage(sender, updateMessageSubject, new InternalPutEvent<>(updatesToSend));
        } catch (IOException e) {
            log.warn("Failed to send advertisement response", e);
        }
    }
    return externalEvents;
}
#end_block

#method_before
/**
 * Checks if any items in the remote live list are out of date according
 * to our tombstone list. If we find we have a more up to date tombstone,
 * we'll send it to the remote.
 *
 * @param ad remote anti-entropy advertisement
 */
private void antiEntropyCheckLocalRemoved(AntiEntropyAdvertisement<K> ad) {
    final NodeId sender = ad.sender();
    final List<RemoveEntry<K>> removesToSend = new ArrayList<>();
    for (Map.Entry<K, Timestamp> dead : removedItems.entrySet()) {
        K key = dead.getKey();
        Timestamp localDeadTimestamp = dead.getValue();
        Timestamp remoteLiveTimestamp = ad.timestamps().get(key);
        if (remoteLiveTimestamp != null && localDeadTimestamp.isNewer(remoteLiveTimestamp)) {
            // sender has zombie, push remove
            removesToSend.add(new RemoveEntry<>(key, localDeadTimestamp));
        }
    }
    // Send all removes to the peer at once
    if (!removesToSend.isEmpty()) {
        try {
            unicastMessage(sender, removeMessageSubject, new InternalRemoveEvent<>(removesToSend));
        } catch (IOException e) {
            log.warn("Failed to send advertisement response", e);
        }
    }
}
#method_after
/**
 * Checks if any items in the remote live list are out of date according
 * to our tombstone list. If we find we have a more up to date tombstone,
 * we'll send it to the remote.
 *
 * @param ad remote anti-entropy advertisement
 */
private void antiEntropyCheckLocalRemoved(AntiEntropyAdvertisement<K> ad) {
    final NodeId sender = ad.sender();
    final List<RemoveEntry<K>> removesToSend = new ArrayList<>();
    for (Map.Entry<K, Timestamp> dead : removedItems.entrySet()) {
        K key = dead.getKey();
        Timestamp localDeadTimestamp = dead.getValue();
        Timestamp remoteLiveTimestamp = ad.timestamps().get(key);
        if (remoteLiveTimestamp != null && localDeadTimestamp.isNewerThan(remoteLiveTimestamp)) {
            // sender has zombie, push remove
            removesToSend.add(new RemoveEntry<>(key, localDeadTimestamp));
        }
    }
    // Send all removes to the peer at once
    if (!removesToSend.isEmpty()) {
        try {
            unicastMessage(sender, removeMessageSubject, new InternalRemoveEvent<>(removesToSend));
        } catch (IOException e) {
            log.warn("Failed to send advertisement response", e);
        }
    }
}
#end_block

#method_before
/**
 * Checks if any of the local live items are out of date according to the
 * remote's tombstone advertisements. If we find a local item is out of date,
 * we'll apply the remove operation to the local state.
 *
 * @param ad remote anti-entropy advertisement
 * @return list of external events relating to local operations performed
 */
private List<EventuallyConsistentMapEvent<K, V>> antiEntropyCheckRemoteRemoved(AntiEntropyAdvertisement<K> ad) {
    final List<EventuallyConsistentMapEvent<K, V>> externalEvents = new LinkedList<>();
    for (Map.Entry<K, Timestamp> remoteDead : ad.tombstones().entrySet()) {
        K key = remoteDead.getKey();
        Timestamp remoteDeadTimestamp = remoteDead.getValue();
        Timestamped<V> local = items.get(key);
        Timestamp localDead = removedItems.get(key);
        if ((local != null && remoteDeadTimestamp.isNewer(local.timestamp())) || (localDead != null && remoteDeadTimestamp.isNewer(localDead))) {
            // value or our tombstone value, then do a remove with their timestamp
            if (removeInternal(key, remoteDeadTimestamp)) {
                externalEvents.add(new EventuallyConsistentMapEvent<>(EventuallyConsistentMapEvent.Type.REMOVE, key, null));
            }
        }
    }
    return externalEvents;
}
#method_after
/**
 * Checks if any of the local live items are out of date according to the
 * remote's tombstone advertisements. If we find a local item is out of date,
 * we'll apply the remove operation to the local state.
 *
 * @param ad remote anti-entropy advertisement
 * @return list of external events relating to local operations performed
 */
private List<EventuallyConsistentMapEvent<K, V>> antiEntropyCheckRemoteRemoved(AntiEntropyAdvertisement<K> ad) {
    final List<EventuallyConsistentMapEvent<K, V>> externalEvents = new LinkedList<>();
    for (Map.Entry<K, Timestamp> remoteDead : ad.tombstones().entrySet()) {
        K key = remoteDead.getKey();
        Timestamp remoteDeadTimestamp = remoteDead.getValue();
        Timestamped<V> local = items.get(key);
        Timestamp localDead = removedItems.get(key);
        if (local != null && remoteDeadTimestamp.isNewerThan(local.timestamp())) {
            // value, then do a remove with their timestamp
            if (removeInternal(key, remoteDeadTimestamp)) {
                externalEvents.add(new EventuallyConsistentMapEvent<>(EventuallyConsistentMapEvent.Type.REMOVE, key, null));
            }
        } else if (localDead != null && remoteDeadTimestamp.isNewerThan(localDead)) {
            // If the remote has a more recent tombstone than us, update ours
            // to their timestamp
            removeInternal(key, remoteDeadTimestamp);
        }
    }
    return externalEvents;
}
#end_block

#method_before
@Activate
public void activate() {
    providerService = providerRegistry.register(this);
    controller.addListener(listener);
    controller.addEventListener(listener);
    for (OpenFlowSwitch sw : controller.getSwitches()) {
        if (sw.factory().getVersion() != OFVersion.OF_10 && sw.factory().getVersion() != OFVersion.OF_11 && sw.factory().getVersion() != OFVersion.OF_12) {
            GroupStatsCollector gsc = new GroupStatsCollector(sw, POLL_INTERVAL);
            gsc.start();
            collectors.put(new Dpid(sw.getId()), gsc);
        }
    }
    log.info("Started");
}
#method_after
@Activate
public void activate() {
    providerService = providerRegistry.register(this);
    controller.addListener(listener);
    controller.addEventListener(listener);
    for (OpenFlowSwitch sw : controller.getSwitches()) {
        if (isGroupSupported(sw)) {
            GroupStatsCollector gsc = new GroupStatsCollector(sw, POLL_INTERVAL);
            gsc.start();
            collectors.put(new Dpid(sw.getId()), gsc);
        }
    }
    log.info("Started");
}
#end_block

#method_before
@Override
public void switchAdded(Dpid dpid) {
    OpenFlowSwitch sw = controller.getSwitch(dpid);
    if (sw.factory().getVersion() != OFVersion.OF_10 && sw.factory().getVersion() != OFVersion.OF_11 && sw.factory().getVersion() != OFVersion.OF_12) {
        GroupStatsCollector gsc = new GroupStatsCollector(controller.getSwitch(dpid), POLL_INTERVAL);
        gsc.start();
        collectors.put(dpid, gsc);
    }
}
#method_after
@Override
public void switchAdded(Dpid dpid) {
    OpenFlowSwitch sw = controller.getSwitch(dpid);
    if (isGroupSupported(sw)) {
        GroupStatsCollector gsc = new GroupStatsCollector(controller.getSwitch(dpid), POLL_INTERVAL);
        gsc.start();
        collectors.put(dpid, gsc);
    }
}
#end_block

#method_before
@Activate
public void activate() {
    final String logDir = System.getProperty("karaf.data", "./data");
    // load database configuration
    File file = new File(CONFIG_DIR, PARTITION_DEFINITION_FILE);
    log.info("Loading database definition: {}", file.getAbsolutePath());
    DatabaseDefinitionStore databaseDef = new DatabaseDefinitionStore(file);
    Map<String, Set<DefaultControllerNode>> partitionMap;
    try {
        partitionMap = databaseDef.read();
    } catch (IOException e) {
        log.error("Failed to load database config {}", file);
        throw new IllegalStateException("Failed to load database config", e);
    }
    String[] activeNodeUris = partitionMap.values().stream().reduce((s1, s2) -> Sets.union(s1, s2)).get().stream().map(this::nodeToUri).toArray(String[]::new);
    String localNodeUri = nodeToUri(clusterService.getLocalNode());
    ClusterConfig clusterConfig = new ClusterConfig().withProtocol(new NettyTcpProtocol().withSsl(false).withConnectTimeout(60000).withAcceptBacklog(1024).withTrafficClass(-1).withSoLinger(-1).withReceiveBufferSize(32768).withSendBufferSize(8192).withThreads(1)).withElectionTimeout(300).withHeartbeatInterval(150).withMembers(activeNodeUris).withLocalMember(localNodeUri);
    PartitionedDatabaseConfig databaseConfig = new PartitionedDatabaseConfig();
    partitionMap.forEach((name, nodes) -> {
        Set<String> replicas = nodes.stream().map(this::nodeToUri).collect(Collectors.toSet());
        DatabaseConfig partitionConfig = new DatabaseConfig().withElectionTimeout(300).withHeartbeatInterval(150).withConsistency(Consistency.STRONG).withLog(new FileLog().withDirectory(logDir).withSegmentSize(// 1GB
        1073741824).withFlushOnWrite(true).withSegmentInterval(Long.MAX_VALUE)).withDefaultSerializer(new DatabaseSerializer()).withReplicas(replicas);
        databaseConfig.addPartition(name, partitionConfig);
    });
    partitionedDatabase = PartitionedDatabaseManager.create("onos-store", clusterConfig, databaseConfig);
    partitionedDatabase.open().whenComplete((db, error) -> {
        if (error != null) {
            log.warn("Failed to open database.", error);
        } else {
            log.info("Successfully opened database.");
        }
    });
    log.info("Started");
}
#method_after
@Activate
public void activate() {
    final String logDir = System.getProperty("karaf.data", "./data");
    // load database configuration
    File file = new File(CONFIG_DIR, PARTITION_DEFINITION_FILE);
    log.info("Loading database definition: {}", file.getAbsolutePath());
    DatabaseDefinitionStore databaseDef = new DatabaseDefinitionStore(file);
    Map<String, Set<DefaultControllerNode>> partitionMap;
    try {
        partitionMap = databaseDef.read();
    } catch (IOException e) {
        log.error("Failed to load database config {}", file);
        throw new IllegalStateException("Failed to load database config", e);
    }
    String[] activeNodeUris = partitionMap.values().stream().reduce((s1, s2) -> Sets.union(s1, s2)).get().stream().map(this::nodeToUri).toArray(String[]::new);
    String localNodeUri = nodeToUri(clusterService.getLocalNode());
    ClusterConfig clusterConfig = new ClusterConfig().withProtocol(new NettyTcpProtocol().withSsl(false).withConnectTimeout(60000).withAcceptBacklog(1024).withTrafficClass(-1).withSoLinger(-1).withReceiveBufferSize(32768).withSendBufferSize(8192).withThreads(1)).withElectionTimeout(3000).withHeartbeatInterval(1500).withMembers(activeNodeUris).withLocalMember(localNodeUri);
    PartitionedDatabaseConfig databaseConfig = new PartitionedDatabaseConfig();
    partitionMap.forEach((name, nodes) -> {
        Set<String> replicas = nodes.stream().map(this::nodeToUri).collect(Collectors.toSet());
        DatabaseConfig partitionConfig = new DatabaseConfig().withElectionTimeout(3000).withHeartbeatInterval(1500).withConsistency(Consistency.STRONG).withLog(new FileLog().withDirectory(logDir).withSegmentSize(// 1GB
        1073741824).withFlushOnWrite(true).withSegmentInterval(Long.MAX_VALUE)).withDefaultSerializer(new DatabaseSerializer()).withReplicas(replicas);
        databaseConfig.addPartition(name, partitionConfig);
    });
    partitionedDatabase = PartitionedDatabaseManager.create("onos-store", clusterConfig, databaseConfig);
    partitionedDatabase.open().whenComplete((db, error) -> {
        if (error != null) {
            log.warn("Failed to open database.", error);
        } else {
            log.info("Successfully opened database.");
        }
    });
    log.info("Started");
}
#end_block

#method_before
@Override
public List<PartitionInfo> getPartitionInfo() {
    return partitionedDatabase.getRegisteredPartitions().values().stream().filter(d -> d.cluster().leader() != null).map((database) -> new PartitionInfo(database.name(), database.cluster().term(), database.cluster().members().stream().map(Member::uri).collect(Collectors.toList()), database.cluster().leader().uri())).collect(Collectors.toList());
}
#method_after
@Override
public List<PartitionInfo> getPartitionInfo() {
    return partitionedDatabase.getRegisteredPartitions().values().stream().map(DatabaseManager::toPartitionInfo).collect(Collectors.toList());
}
#end_block

#method_before
private static Integer getIntegerProperty(Dictionary<?, ?> properties, String propertyName) {
    Integer value = null;
    try {
        String s = (String) properties.get(propertyName);
        value = isNullOrEmpty(s) ? value : Integer.parseInt(s.trim());
    } catch (Exception e) {
        value = null;
    }
    return value;
}
#method_after
private static Integer getIntegerProperty(Dictionary<?, ?> properties, String propertyName) {
    Integer value = null;
    try {
        String s = (String) properties.get(propertyName);
        value = isNullOrEmpty(s) ? value : Integer.parseInt(s.trim());
    } catch (NumberFormatException e) {
        value = null;
    }
    return value;
}
#end_block

#method_before
private void installRule(PacketContext context, PortNumber portNumber) {
    // We don't yet support bufferids in the flowservice so packet out first.
    Ethernet inPkt = context.inPacket().parsed();
    TrafficSelector.Builder builder = DefaultTrafficSelector.builder();
    // If PacketOutOnly or ARP packet than forward directly to output port
    if (packetOutOnly || inPkt.getEtherType() == Ethernet.TYPE_ARP) {
        packetOut(context, portNumber);
        return;
    }
    // else - create flows with default matching and include configured fields
    if (matchDstMacOnly) {
        builder.matchEthDst(inPkt.getDestinationMAC());
    } else {
        builder.matchInPort(context.inPacket().receivedFrom().port()).matchEthSrc(inPkt.getSourceMAC()).matchEthDst(inPkt.getDestinationMAC()).matchEthType(inPkt.getEtherType());
        // If configured Match Vlan ID
        if (matchVlanId && inPkt.getVlanID() != Ethernet.VLAN_UNTAGGED) {
            builder.matchVlanId(VlanId.vlanId(inPkt.getVlanID()));
        }
        // If configured and EtherType is IPv4 - Match IPv4 and TCP/UDP/ICMP fields
        if (matchIpv4Address && inPkt.getEtherType() == Ethernet.TYPE_IPV4) {
            IPv4 ipv4Packet = (IPv4) inPkt.getPayload();
            byte ipv4Protocol = ipv4Packet.getProtocol();
            builder.matchIPSrc(IpPrefix.valueOf(ipv4Packet.getSourceAddress(), 32)).matchIPDst(IpPrefix.valueOf(ipv4Packet.getDestinationAddress(), 32)).matchIPProtocol(ipv4Protocol);
            if (matchIpv4Dscp) {
                int dscp = ipv4Packet.getDiffServ() >>> 2;
                int ecn = ipv4Packet.getDiffServ() % 4;
                builder.matchIPDscp((byte) (dscp)).matchIPEcn((byte) (ecn));
            }
            if (matchTcpUdpPorts && ipv4Protocol == IPv4.PROTOCOL_TCP) {
                TCP tcpPacket = (TCP) ipv4Packet.getPayload();
                builder.matchTcpSrc(tcpPacket.getSourcePort()).matchTcpDst(tcpPacket.getDestinationPort());
            }
            if (matchTcpUdpPorts && ipv4Protocol == IPv4.PROTOCOL_UDP) {
                UDP udpPacket = (UDP) ipv4Packet.getPayload();
                builder.matchUdpSrc(udpPacket.getSourcePort()).matchUdpDst(udpPacket.getDestinationPort());
            }
            if (matchIcmpFields && ipv4Protocol == IPv4.PROTOCOL_ICMP) {
                ICMP icmpPacket = (ICMP) ipv4Packet.getPayload();
                builder.matchIcmpType(icmpPacket.getIcmpType()).matchIcmpCode(icmpPacket.getIcmpCode());
            }
        }
        // If configured and EtherType is IPv6 - Match IPv6 and TCP/UDP/ICMP fields
        if (matchIpv6Address && inPkt.getEtherType() == Ethernet.TYPE_IPV6) {
            IPv6 ipv6Packet = (IPv6) inPkt.getPayload();
            byte ipv6NextHeader = ipv6Packet.getNextHeader();
            builder.matchIPv6Src(Ip6Prefix.valueOf(ipv6Packet.getSourceAddress(), 128)).matchIPv6Dst(Ip6Prefix.valueOf(ipv6Packet.getDestinationAddress(), 128)).matchIPProtocol(ipv6NextHeader);
            if (matchIpv6FlowLabel) {
                builder.matchIPv6FlowLabel(ipv6Packet.getFlowLabel());
            }
            if (matchTcpUdpPorts && ipv6NextHeader == IPv6.PROTOCOL_TCP) {
                TCP tcpPacket = (TCP) ipv6Packet.getPayload();
                builder.matchTcpSrc(tcpPacket.getSourcePort()).matchTcpDst(tcpPacket.getDestinationPort());
            }
            if (matchTcpUdpPorts && ipv6NextHeader == IPv6.PROTOCOL_UDP) {
                UDP udpPacket = (UDP) ipv6Packet.getPayload();
                builder.matchUdpSrc(udpPacket.getSourcePort()).matchUdpDst(udpPacket.getDestinationPort());
            }
            if (matchIcmpFields && ipv6NextHeader == IPv6.PROTOCOL_ICMP6) {
                ICMP6 icmp6Packet = (ICMP6) ipv6Packet.getPayload();
                builder.matchIcmpv6Type(icmp6Packet.getIcmpType()).matchIcmpv6Code(icmp6Packet.getIcmpCode());
            }
        }
    }
    TrafficTreatment.Builder treat = DefaultTrafficTreatment.builder();
    treat.setOutput(portNumber);
    FlowRule f = new DefaultFlowRule(context.inPacket().receivedFrom().deviceId(), builder.build(), treat.build(), flowPriority, appId, flowTimeout, false);
    flowRuleService.applyFlowRules(f);
    // else send packet to appropriate port directly
    if (packetOutOfppTable) {
        packetOut(context, PortNumber.TABLE);
    } else {
        packetOut(context, portNumber);
    }
}
#method_after
private void installRule(PacketContext context, PortNumber portNumber) {
    // 
    // We don't support (yet) buffer IDs in the Flow Service so
    // packet out first.
    // 
    Ethernet inPkt = context.inPacket().parsed();
    TrafficSelector.Builder builder = DefaultTrafficSelector.builder();
    // If PacketOutOnly or ARP packet than forward directly to output port
    if (packetOutOnly || inPkt.getEtherType() == Ethernet.TYPE_ARP) {
        packetOut(context, portNumber);
        return;
    }
    // 
    if (matchDstMacOnly) {
        builder.matchEthDst(inPkt.getDestinationMAC());
    } else {
        builder.matchInPort(context.inPacket().receivedFrom().port()).matchEthSrc(inPkt.getSourceMAC()).matchEthDst(inPkt.getDestinationMAC()).matchEthType(inPkt.getEtherType());
        // If configured Match Vlan ID
        if (matchVlanId && inPkt.getVlanID() != Ethernet.VLAN_UNTAGGED) {
            builder.matchVlanId(VlanId.vlanId(inPkt.getVlanID()));
        }
        // 
        if (matchIpv4Address && inPkt.getEtherType() == Ethernet.TYPE_IPV4) {
            IPv4 ipv4Packet = (IPv4) inPkt.getPayload();
            byte ipv4Protocol = ipv4Packet.getProtocol();
            Ip4Prefix matchIp4SrcPrefix = Ip4Prefix.valueOf(ipv4Packet.getSourceAddress(), Ip4Prefix.MAX_MASK_LENGTH);
            Ip4Prefix matchIp4DstPrefix = Ip4Prefix.valueOf(ipv4Packet.getDestinationAddress(), Ip4Prefix.MAX_MASK_LENGTH);
            builder.matchIPSrc(matchIp4SrcPrefix).matchIPDst(matchIp4DstPrefix).matchIPProtocol(ipv4Protocol);
            if (matchIpv4Dscp) {
                int dscp = ipv4Packet.getDiffServ() >>> 2;
                int ecn = ipv4Packet.getDiffServ() % 4;
                builder.matchIPDscp((byte) (dscp)).matchIPEcn((byte) (ecn));
            }
            if (matchTcpUdpPorts && ipv4Protocol == IPv4.PROTOCOL_TCP) {
                TCP tcpPacket = (TCP) ipv4Packet.getPayload();
                builder.matchTcpSrc(tcpPacket.getSourcePort()).matchTcpDst(tcpPacket.getDestinationPort());
            }
            if (matchTcpUdpPorts && ipv4Protocol == IPv4.PROTOCOL_UDP) {
                UDP udpPacket = (UDP) ipv4Packet.getPayload();
                builder.matchUdpSrc(udpPacket.getSourcePort()).matchUdpDst(udpPacket.getDestinationPort());
            }
            if (matchIcmpFields && ipv4Protocol == IPv4.PROTOCOL_ICMP) {
                ICMP icmpPacket = (ICMP) ipv4Packet.getPayload();
                builder.matchIcmpType(icmpPacket.getIcmpType()).matchIcmpCode(icmpPacket.getIcmpCode());
            }
        }
        // 
        if (matchIpv6Address && inPkt.getEtherType() == Ethernet.TYPE_IPV6) {
            IPv6 ipv6Packet = (IPv6) inPkt.getPayload();
            byte ipv6NextHeader = ipv6Packet.getNextHeader();
            Ip6Prefix matchIp6SrcPrefix = Ip6Prefix.valueOf(ipv6Packet.getSourceAddress(), Ip6Prefix.MAX_MASK_LENGTH);
            Ip6Prefix matchIp6DstPrefix = Ip6Prefix.valueOf(ipv6Packet.getDestinationAddress(), Ip6Prefix.MAX_MASK_LENGTH);
            builder.matchIPv6Src(matchIp6SrcPrefix).matchIPv6Dst(matchIp6DstPrefix).matchIPProtocol(ipv6NextHeader);
            if (matchIpv6FlowLabel) {
                builder.matchIPv6FlowLabel(ipv6Packet.getFlowLabel());
            }
            if (matchTcpUdpPorts && ipv6NextHeader == IPv6.PROTOCOL_TCP) {
                TCP tcpPacket = (TCP) ipv6Packet.getPayload();
                builder.matchTcpSrc(tcpPacket.getSourcePort()).matchTcpDst(tcpPacket.getDestinationPort());
            }
            if (matchTcpUdpPorts && ipv6NextHeader == IPv6.PROTOCOL_UDP) {
                UDP udpPacket = (UDP) ipv6Packet.getPayload();
                builder.matchUdpSrc(udpPacket.getSourcePort()).matchUdpDst(udpPacket.getDestinationPort());
            }
            if (matchIcmpFields && ipv6NextHeader == IPv6.PROTOCOL_ICMP6) {
                ICMP6 icmp6Packet = (ICMP6) ipv6Packet.getPayload();
                builder.matchIcmpv6Type(icmp6Packet.getIcmpType()).matchIcmpv6Code(icmp6Packet.getIcmpCode());
            }
        }
    }
    TrafficTreatment.Builder treat = DefaultTrafficTreatment.builder();
    treat.setOutput(portNumber);
    FlowRule f = new DefaultFlowRule(context.inPacket().receivedFrom().deviceId(), builder.build(), treat.build(), flowPriority, appId, flowTimeout, false);
    flowRuleService.applyFlowRules(f);
    // 
    if (packetOutOfppTable) {
        packetOut(context, PortNumber.TABLE);
    } else {
        packetOut(context, portNumber);
    }
}
#end_block

#method_before
@Activate
public void activate(ComponentContext context) {
    providerService = providerRegistry.register(this);
    linkService = (LinkService) providerRegistry;
    linkService.addListener(listener);
    deviceService.addListener(linkProvider);
    modified(context);
    log.info("started");
}
#method_after
@Activate
public void activate(ComponentContext context) {
    providerService = providerRegistry.register(this);
    linkService = (LinkService) providerRegistry;
    modified(context);
    linkService.addListener(listener);
    deviceService.addListener(linkProvider);
    log.info("started");
}
#end_block

#method_before
@Deactivate
public void deactivate(ComponentContext context) {
    if (flicker) {
        try {
            linkDriver.awaitTermination(1000, TimeUnit.MILLISECONDS);
        } catch (InterruptedException e) {
            log.error("LinkBuilder did not terminate");
        }
        linkDriver.shutdownNow();
    }
    deviceService.removeListener(linkProvider);
    providerRegistry.unregister(this);
    linkService.removeListener(listener);
    deviceService = null;
    linkService = null;
    log.info("stopped");
}
#method_after
@Deactivate
public void deactivate(ComponentContext context) {
    linkDriver.shutdown();
    try {
        linkDriver.awaitTermination(1000, TimeUnit.MILLISECONDS);
    } catch (InterruptedException e) {
        log.error("LinkBuilder did not terminate");
        linkDriver.shutdownNow();
    }
    deviceService.removeListener(linkProvider);
    providerRegistry.unregister(this);
    linkService.removeListener(listener);
    deviceService = null;
    linkService = null;
    log.info("stopped");
}
#end_block

#method_before
@Modified
public void modified(ComponentContext context) {
    if (context == null) {
        log.info("No configs, using defaults: eventRate={}", DEFAULT_RATE);
        return;
    }
    Dictionary<?, ?> properties = context.getProperties();
    int newRate;
    String newNbor;
    try {
        String s = (String) properties.get("eventRate");
        newRate = isNullOrEmpty(s) ? eventRate : Integer.parseInt(s.trim());
        s = (String) properties.get("neighbors");
        newNbor = isNullOrEmpty(s) ? neighbor : getNeighbor(s.trim());
    } catch (Exception e) {
        log.warn(e.getMessage());
        newRate = eventRate;
        newNbor = neighbor;
    }
    if (newNbor != neighbor) {
        neighbor = newNbor;
    }
    if (newRate != 0 & eventRate != newRate) {
        eventRate = newRate;
        flicker = true;
    }
    log.info("Using new settings: eventRate={}", eventRate);
}
#method_after
@Modified
public void modified(ComponentContext context) {
    if (context == null) {
        log.info("No configs, using defaults: eventRate={}", DEFAULT_RATE);
        return;
    }
    Dictionary<?, ?> properties = context.getProperties();
    int newRate;
    String newNbor;
    try {
        String s = (String) properties.get("eventRate");
        newRate = isNullOrEmpty(s) ? eventRate : Integer.parseInt(s.trim());
        s = (String) properties.get("neighbors");
        newNbor = isNullOrEmpty(s) ? neighbor : getNeighbor(s.trim());
    } catch (Exception e) {
        log.warn(e.getMessage());
        newRate = eventRate;
        newNbor = neighbor;
    }
    if (newNbor != neighbor) {
        neighbor = newNbor;
    }
    if (newRate != 0 & eventRate != newRate) {
        eventRate = newRate;
        flicker = true;
        // try to find and add drivers for current devices
        for (Device dev : deviceService.getDevices()) {
            DeviceId did = dev.id();
            synchronized (this) {
                if (driverMap.get(did) == null || !driverMap.get(did)) {
                    driverMap.put(dev.id(), true);
                    linkDriver.submit(new LinkDriver(dev));
                }
            }
        }
    } else if (newRate == 0) {
        driverMap.replaceAll((k, v) -> false);
    } else {
        log.warn("Invalid link flicker rate {}", newRate);
    }
    log.info("Using new settings: eventRate={}", eventRate);
}
#end_block

#method_before
private boolean addLdesc(DeviceId did, LinkDescription ldesc) {
    Set<LinkDescription> ldescs = linkDescrs.get(did);
    if (ldescs == null) {
        ldescs = Sets.newConcurrentHashSet();
        linkDescrs.put(did, ldescs);
    }
    return ldescs.add(ldesc);
}
#method_after
private boolean addLdesc(DeviceId did, LinkDescription ldesc) {
    Set<LinkDescription> ldescs = ConcurrentUtils.putIfAbsent(linkDescrs, did, Sets.newConcurrentHashSet());
    return ldescs.add(ldesc);
}
#end_block

#method_before
@Override
public void event(DeviceEvent event) {
    Device dev = event.subject();
    switch(event.type()) {
        case DEVICE_ADDED:
            if (flicker) {
                linkDriver.submit(new LinkDriver(dev.id()));
            }
            addLink(dev);
            break;
        case DEVICE_REMOVED:
            removeLink(dev);
            break;
        default:
            break;
    }
}
#method_after
@Override
public void event(DeviceEvent event) {
    Device dev = event.subject();
    switch(event.type()) {
        case DEVICE_ADDED:
            synchronized (this) {
                if (flicker && !driverMap.getOrDefault(dev.id(), false)) {
                    driverMap.put(dev.id(), true);
                    linkDriver.submit(new LinkDriver(dev));
                }
            }
            addLink(dev);
            break;
        case DEVICE_REMOVED:
            driverMap.put(dev.id(), false);
            removeLink(dev);
            break;
        default:
            break;
    }
}
#end_block

#method_before
private void removeLink(Device device) {
    if (!MASTER.equals(roleService.getLocalRole(device.id()))) {
        return;
    }
    providerService.linksVanished(device.id());
    devices.remove(device.id());
}
#method_after
private void removeLink(Device device) {
    if (!MASTER.equals(roleService.getLocalRole(device.id()))) {
        return;
    }
    providerService.linksVanished(device.id());
    devices.remove(device.id());
    synchronized (linkDescrs) {
        Set<LinkDescription> lds = linkDescrs.remove(device.id());
        for (LinkDescription ld : lds) {
            ConnectPoint src = ld.src();
            DeviceId dst = ld.dst().deviceId();
            Iterator<LinkDescription> it = linkDescrs.get(dst).iterator();
            while (it.hasNext()) {
                if (it.next().dst().equals(src)) {
                    it.remove();
                }
            }
        }
    }
}
#end_block

#method_before
@Override
public void event(LinkEvent event) {
    switch(event.type()) {
        case LINK_ADDED:
            // If a link from another island, cast one back.
            DeviceId sdid = event.subject().src().deviceId();
            PortNumber pn = event.subject().src().port();
            if (roleService.getLocalRole(sdid).equals(MASTER)) {
                String part = part(sdid.toString());
                if (part.equals("ffff") && SRCPORT.equals(pn)) {
                    LinkDescription ld = new DefaultLinkDescription(event.subject().dst(), event.subject().src(), Link.Type.DIRECT);
                    // descriptions.put(event.subject().dst(), ld);
                    addLdesc(event.subject().dst().deviceId(), ld);
                    providerService.linkDetected(ld);
                }
                return;
            }
            break;
        default:
            break;
    }
}
#method_after
@Override
public void event(LinkEvent event) {
    switch(event.type()) {
        case LINK_ADDED:
            // If a link from another island, cast one back.
            DeviceId sdid = event.subject().src().deviceId();
            PortNumber pn = event.subject().src().port();
            if (roleService.getLocalRole(sdid).equals(MASTER)) {
                String part = part(sdid.toString());
                if (part.equals("ffff") && SRCPORT.equals(pn)) {
                    LinkDescription ld = new DefaultLinkDescription(event.subject().dst(), event.subject().src(), Link.Type.DIRECT);
                    addLdesc(event.subject().dst().deviceId(), ld);
                    providerService.linkDetected(ld);
                }
                return;
            }
            break;
        default:
            break;
    }
}
#end_block

#method_before
@Override
public void run() {
    log.info("Thread started for dev {}", myDev);
    long startTime = System.currentTimeMillis();
    long countEvent = 0;
    float effLoad = 0;
    while (!linkDriver.isShutdown()) {
        // Assuming eventRate is in microsecond unit
        if (countEvent <= checkRateDuration * 1000000 / eventRate) {
            for (LinkDescription desc : linkDescrs.get(myDev)) {
                providerService.linkVanished(desc);
                countEvent++;
                try {
                    TimeUnit.MICROSECONDS.sleep(eventRate);
                } catch (InterruptedException e) {
                    log.warn(String.valueOf(e));
                }
                providerService.linkDetected(desc);
                countEvent++;
                try {
                    TimeUnit.MICROSECONDS.sleep(eventRate);
                } catch (InterruptedException e) {
                    log.warn(String.valueOf(e));
                }
            }
        } else {
            // log in WARN the effective load generation rate in events/sec, every 10 seconds
            effLoad = countEvent * 1000 / (System.currentTimeMillis() - startTime);
            log.warn("Effective Loading for thread-{} is {} events/second", myDev, String.valueOf(effLoad));
            countEvent = 0;
            startTime = System.currentTimeMillis();
        }
    }
}
#method_after
@Override
public void run() {
    log.info("Thread started for dev {}", myDev.id());
    long startTime = System.currentTimeMillis();
    long countEvent = 0;
    float effLoad = 0;
    while (!linkDriver.isShutdown() && driverMap.get(myDev.id())) {
        if (linkDescrs.get(myDev.id()) == null) {
            addLink(myDev);
        }
        // Assuming eventRate is in microsecond unit
        if (countEvent <= checkRateDuration * 1000000 / eventRate) {
            for (LinkDescription desc : linkDescrs.get(myDev.id())) {
                providerService.linkVanished(desc);
                countEvent++;
                try {
                    TimeUnit.MICROSECONDS.sleep(eventRate);
                } catch (InterruptedException e) {
                    log.warn(String.valueOf(e));
                }
                providerService.linkDetected(desc);
                countEvent++;
                try {
                    TimeUnit.MICROSECONDS.sleep(eventRate);
                } catch (InterruptedException e) {
                    log.warn(String.valueOf(e));
                }
            }
        } else {
            // log in WARN the effective load generation rate in events/sec, every 10 seconds
            effLoad = (float) (countEvent * 1000.0 / (System.currentTimeMillis() - startTime));
            log.warn("Effective Loading for thread is {} events/second", String.valueOf(effLoad));
            countEvent = 0;
            startTime = System.currentTimeMillis();
        }
    }
}
#end_block

#method_before
private FlowRuleOperations.Builder merge(List<List<Set<FlowRuleOperation>>> plans) {
    FlowRuleOperations.Builder builder = FlowRuleOperations.builder();
    // Build a batch one stage at a time
    for (int stageNumber = 0; ; stageNumber++) {
        // Get the sub-stage from each plan (List<Set<FlowRuleOperation>)
        for (Iterator<List<Set<FlowRuleOperation>>> itr = plans.iterator(); itr.hasNext(); ) {
            List<Set<FlowRuleOperation>> plan = itr.next();
            if (plan.size() <= stageNumber) {
                // we have consumed all stages from this plan, so remove it
                itr.remove();
                continue;
            }
            // write operations from this sub-stage into the builder
            Set<FlowRuleOperation> stage = plan.get(stageNumber);
            for (FlowRuleOperation entry : stage) {
                builder.add(entry);
            }
        }
        // we are done with the stage, start the next one...
        if (plans.isEmpty()) {
            // we don't need to start a new stage, we are done.
            break;
        }
        builder.newStage();
    }
    return builder;
}
#method_after
private FlowRuleOperations.Builder merge(List<List<Set<FlowRuleOperation>>> plans) {
    FlowRuleOperations.Builder builder = FlowRuleOperations.builder();
    // Build a batch one stage at a time
    for (int stageNumber = 0; ; stageNumber++) {
        // Get the sub-stage from each plan (List<Set<FlowRuleOperation>)
        for (Iterator<List<Set<FlowRuleOperation>>> itr = plans.iterator(); itr.hasNext(); ) {
            List<Set<FlowRuleOperation>> plan = itr.next();
            if (plan.size() <= stageNumber) {
                // we have consumed all stages from this plan, so remove it
                itr.remove();
                continue;
            }
            // write operations from this sub-stage into the builder
            Set<FlowRuleOperation> stage = plan.get(stageNumber);
            for (FlowRuleOperation entry : stage) {
                builder.operation(entry);
            }
        }
        // we are done with the stage, start the next one...
        if (plans.isEmpty()) {
            // we don't need to start a new stage, we are done.
            break;
        }
        builder.newStage();
    }
    return builder;
}
#end_block

#method_before
public static GroupedThreadFactory groupedThreadFactory(String groupName) {
    GroupedThreadFactory factory = FACTORIES.get(groupName);
    if (factory != null) {
        return factory;
    }
    // Find the parent group or root the group hierarchy under default group.
    int i = groupName.lastIndexOf(DELIMITER);
    if (i > 0) {
        String name = groupName.substring(0, i);
        ThreadGroup parentGroup = groupedThreadFactory(name).threadGroup();
        factory = new GroupedThreadFactory(new ThreadGroup(parentGroup, groupName));
    } else {
        factory = new GroupedThreadFactory(new ThreadGroup(groupName));
    }
    FACTORIES.putIfAbsent(groupName, factory);
    return factory;
}
#method_after
public static GroupedThreadFactory groupedThreadFactory(String groupName) {
    GroupedThreadFactory factory = FACTORIES.get(groupName);
    if (factory != null) {
        return factory;
    }
    // Find the parent group or root the group hierarchy under default group.
    int i = groupName.lastIndexOf(DELIMITER);
    if (i > 0) {
        String name = groupName.substring(0, i);
        ThreadGroup parentGroup = groupedThreadFactory(name).threadGroup();
        factory = new GroupedThreadFactory(new ThreadGroup(parentGroup, groupName));
    } else {
        factory = new GroupedThreadFactory(new ThreadGroup(groupName));
    }
    return ConcurrentUtils.putIfAbsent(FACTORIES, groupName, factory);
}
#end_block

#method_before
@javax.ws.rs.Path("/{src}/{dst}/{srcPort}/{dstPort}/{bandwidth}/{latency}")
@POST
public Response setupPath(@PathParam("src") String src, @PathParam("dst") String dst, @PathParam("srcPort") String srcPort, @PathParam("dstPort") String dstPort, @PathParam("bandwidth") String bandwidth, @PathParam("latency") String latency) {
    log.info("Path Constraints: Src = {} SrcPort = {} Dest = {} DestPort = {} " + "BW = {} latency = {}", src, srcPort, dst, dstPort, bandwidth, latency);
    if ((src == null) || dst == null || srcPort == null || dstPort == null) {
        return Response.ok("INVALID_PARAMETER").build();
    }
    String intent1 = createIntent(src, dst, srcPort, dstPort, bandwidth, latency);
    if (intent1.trim().equals("FAILED")) {
        return Response.ok("FAILED").build();
    } else if (intent1.equals("SERVER_ERROR")) {
        return Response.status(Response.Status.INTERNAL_SERVER_ERROR).build();
    }
    String intent2 = createIntent(dst, src, dstPort, srcPort, bandwidth, latency);
    if (intent2.trim().equals("FAILED")) {
        return Response.ok("FAILED").build();
    } else if (intent2.equals("SERVER_ERROR")) {
        return Response.status(Response.Status.INTERNAL_SERVER_ERROR).build();
    }
    return Response.ok(intent1.trim() + "-" + intent2.trim() + "\n").build();
}
#method_after
@javax.ws.rs.Path("/{src}/{dst}/{srcPort}/{dstPort}/{bandwidth}/{latency}")
@POST
public // ... if you do, you will need to change from LongKeys to StringKeys
Response setupPath(@PathParam("src") String src, @PathParam("dst") String dst, @PathParam("srcPort") String srcPort, @PathParam("dstPort") String dstPort, @PathParam("bandwidth") String bandwidth, @PathParam("latency") String latency) {
    log.info("Path Constraints: Src = {} SrcPort = {} Dest = {} DestPort = {} " + "BW = {} latency = {}", src, srcPort, dst, dstPort, bandwidth, latency);
    if (src == null || dst == null || srcPort == null || dstPort == null) {
        return Response.ok(INVALID_PARAMETER).build();
    }
    Long bandwidthL = 0L;
    Long latencyL = 0L;
    try {
        bandwidthL = Long.parseLong(bandwidth, 10);
        latencyL = Long.parseLong(latency, 10);
    } catch (Exception e) {
        return Response.ok(INVALID_PARAMETER).build();
    }
    Intent intent = createIntent(null, src, dst, srcPort, dstPort, bandwidthL, latencyL);
    try {
        if (submitIntent(intent)) {
            return Response.ok(intent.key() + "\n").build();
        } else {
            return Response.ok(OPERATION_FAILED).build();
        }
    } catch (Exception e) {
        return Response.status(Response.Status.INTERNAL_SERVER_ERROR).build();
    }
}
#end_block

#method_before
@javax.ws.rs.Path("/{intentId}/{src}/{dst}/{srcPort}/{dstPort}/{bandwidth}")
@PUT
public Response modifyBandwidth(@PathParam("intentId") String intentId, @PathParam("src") String src, @PathParam("dst") String dst, @PathParam("srcPort") String srcPort, @PathParam("dstPort") String dstPort, @PathParam("bandwidth") String bandwidth) {
    log.info("Modify bw for intentId = {}; src = {}; dst = {};" + "srcPort = {}; dstPort = {}; with new bandwidth = {}", intentId, src, dst, srcPort, dstPort, bandwidth);
    if ((src == null) || dst == null || srcPort == null || dstPort == null) {
        return Response.ok("INVALID_PARAMETER").build();
    }
    String delims = "[- ]+";
    String[] tokens = intentId.split(delims);
    if (tokens[1] == null) {
        return Response.ok("INVALID_PARAMETER").build();
    }
    String intent1 = tokens[0];
    String intent2 = tokens[1];
    log.info("Modify Intent1 = {} intent2 = {}", intent1, intent2);
    String modifyIntent1 = modifyIntent(intent1, src, dst, srcPort, dstPort, bandwidth);
    if (modifyIntent1.trim().equals("NOT_FOUND")) {
        return Response.status(Response.Status.NOT_FOUND).build();
    } else if (modifyIntent1.equals("SERVER_ERROR")) {
        return Response.status(Response.Status.INTERNAL_SERVER_ERROR).build();
    }
    String modifyIntent2 = modifyIntent(intent2, dst, src, dstPort, srcPort, bandwidth);
    if (modifyIntent2.trim().equals("NOT_FOUND")) {
        return Response.status(Response.Status.NOT_FOUND).build();
    } else if (modifyIntent2.equals("SERVER_ERROR")) {
        return Response.status(Response.Status.INTERNAL_SERVER_ERROR).build();
    }
    return Response.ok(modifyIntent1).build();
}
#method_after
@javax.ws.rs.Path("/{intentKey}/{src}/{dst}/{srcPort}/{dstPort}/{bandwidth}")
@PUT
public Response modifyBandwidth(@PathParam("intentKey") String intentKey, @PathParam("src") String src, @PathParam("dst") String dst, @PathParam("srcPort") String srcPort, @PathParam("dstPort") String dstPort, @PathParam("bandwidth") String bandwidth) {
    log.info("Modify bw for intentKey = {}; src = {}; dst = {};" + "srcPort = {}; dstPort = {}; with new bandwidth = {}", intentKey, src, dst, srcPort, dstPort, bandwidth);
    if (src == null || dst == null || srcPort == null || dstPort == null) {
        return Response.ok(INVALID_PARAMETER).build();
    }
    Long bandwidthL = 0L;
    try {
        bandwidthL = Long.parseLong(bandwidth, 10);
    } catch (Exception e) {
        return Response.ok(INVALID_PARAMETER).build();
    }
    IntentService service = get(IntentService.class);
    Intent originalIntent = service.getIntent(Key.of(Tools.fromHex(intentKey.replace("0x", "")), appId()));
    if (originalIntent == null) {
        return Response.status(Response.Status.NOT_FOUND).build();
    }
    // get the latency constraint from the original intent
    Long latencyL = 0L;
    if (originalIntent instanceof ConnectivityIntent) {
        ConnectivityIntent connectivityIntent = (ConnectivityIntent) originalIntent;
        for (Constraint constraint : connectivityIntent.constraints()) {
            if (constraint instanceof LatencyConstraint) {
                latencyL = ((LatencyConstraint) constraint).latency().get(ChronoUnit.MICROS);
            }
        }
    }
    Intent newIntent = createIntent(originalIntent.key(), src, dst, srcPort, dstPort, bandwidthL, latencyL);
    try {
        if (submitIntent(newIntent)) {
            return Response.ok(OPERATION_INSTALLED).build();
        } else {
            return Response.ok(OPERATION_FAILED).build();
        }
    } catch (Exception e) {
        return Response.status(Response.Status.INTERNAL_SERVER_ERROR).build();
    }
}
#end_block

#method_before
private String createIntent(String src, String dst, String srcPort, String dstPort, String bandwidth, String latency) {
    Intent intent;
    IntentService service = get(IntentService.class);
    TrafficSelector selector = buildTrafficSelector();
    TrafficTreatment treatment = builder().build();
    final Constraint constraintBandwidth = new BandwidthConstraint(Bandwidth.mbps(Long.parseLong(bandwidth)));
    // new BandwidthConstraint(Bandwidth.valueOf(Long.parseLong(bandwidth)));
    final Constraint constraintLatency = new LatencyConstraint(Duration.of(Long.parseLong(latency), ChronoUnit.MICROS));
    final List<Constraint> constraints = new LinkedList<>();
    constraints.add(constraintBandwidth);
    constraints.add(constraintLatency);
    if (srcPort.equals("-1")) {
        HostId srcPoint = HostId.hostId(src);
        HostId dstPoint = HostId.hostId(dst);
        // log.info("src mac = {}; vlanID = {}", srcPoint.mac(), srcPoint.vlanId());
        intent = new HostToHostIntent(appId(), srcPoint, dstPoint, selector, treatment, constraints);
    } else {
        ConnectPoint srcPoint = new ConnectPoint(deviceId(src), portNumber(srcPort));
        ConnectPoint dstPoint = new ConnectPoint(deviceId(dst), portNumber(dstPort));
        intent = new PointToPointIntent(appId(), selector, treatment, srcPoint, dstPoint, constraints);
    }
    CountDownLatch latch = new CountDownLatch(1);
    InternalIntentListener listener = new InternalIntentListener(intent, service, latch);
    service.addListener(listener);
    service.submit(intent);
    log.info("Submitted Calendar App intent and waiting: src = {}; dst = {}; " + "srcPort = {}; dstPort = {}; intentID = {}", src, dst, srcPort, dstPort, intent.id());
    try {
        if (latch.await(TIMEOUT, TimeUnit.SECONDS)) {
            if (listener.getState() == INSTALLED) {
                return intent.id().toString();
            } else {
                return "FAILED\n";
            }
        }
    } catch (InterruptedException e) {
        log.warn("Interrupted while waiting for intent {} status", intent.id());
    }
    return "SERVER_ERROR\n";
}
#method_after
private Intent createIntent(Key key, String src, String dst, String srcPort, String dstPort, Long bandwidth, Long latency) {
    TrafficSelector selector = buildTrafficSelector();
    TrafficTreatment treatment = builder().build();
    final Constraint constraintBandwidth = new BandwidthConstraint(Bandwidth.mbps(bandwidth));
    final Constraint constraintLatency = new LatencyConstraint(Duration.of(latency, ChronoUnit.MICROS));
    final List<Constraint> constraints = new LinkedList<>();
    constraints.add(constraintBandwidth);
    constraints.add(constraintLatency);
    if (srcPort.equals("-1")) {
        HostId srcPoint = HostId.hostId(src);
        HostId dstPoint = HostId.hostId(dst);
        return new HostToHostIntent(appId(), key, srcPoint, dstPoint, selector, treatment, constraints);
    } else {
        ConnectPoint srcPoint = new ConnectPoint(deviceId(src), portNumber(srcPort));
        ConnectPoint dstPoint = new ConnectPoint(deviceId(dst), portNumber(dstPort));
        return new TwoWayP2PIntent(appId(), key, srcPoint, dstPoint, selector, treatment, constraints);
    }
}
#end_block

#method_before
@javax.ws.rs.Path("/{intentId}")
@DELETE
public Response removePath(@PathParam("intentId") String intentId) {
    log.info("Receiving Teardown request for {}", intentId);
    if (intentId == null) {
        return Response.ok("INVALID_PARAMETER").build();
    }
    String delims = "[- ]+";
    String[] tokens = intentId.split(delims);
    if (tokens[1] == null) {
        return Response.ok("INVALID_PARAMETER").build();
    }
    String intent1 = tokens[0];
    String intent2 = tokens[1];
    log.info("Withdraw Intent1 = {} intent2 = {}", intent1, intent2);
    String removeIntent1 = withdrawIntent(intent1);
    if (removeIntent1.trim().equals("NOT_FOUND")) {
        return Response.status(Response.Status.NOT_FOUND).build();
    } else if (removeIntent1.equals("SERVER_ERROR")) {
        return Response.status(Response.Status.INTERNAL_SERVER_ERROR).build();
    }
    String removeIntent2 = withdrawIntent(intent2);
    if (removeIntent2.trim().equals("NOT_FOUND")) {
        return Response.status(Response.Status.NOT_FOUND).build();
    } else if (removeIntent2.equals("SERVER_ERROR")) {
        return Response.status(Response.Status.INTERNAL_SERVER_ERROR).build();
    }
    return Response.ok(removeIntent1).build();
}
#method_after
@javax.ws.rs.Path("/{intentKey}")
@DELETE
public Response removePath(@PathParam("intentKey") String intentKey) {
    log.info("Receiving tear down request for {}", intentKey);
    if (intentKey == null) {
        return Response.ok(INVALID_PARAMETER).build();
    }
    IntentService service = get(IntentService.class);
    Intent intent = service.getIntent(Key.of(Tools.fromHex(intentKey.replace("0x", "")), appId()));
    if (intent == null) {
        return Response.status(Response.Status.NOT_FOUND).build();
    }
    try {
        if (withdrawIntent(intent)) {
            return Response.ok(OPERATION_WITHDRAWN).build();
        } else {
            return Response.ok(OPERATION_FAILED).build();
        }
    } catch (Exception e) {
        return Response.status(Response.Status.INTERNAL_SERVER_ERROR).build();
    }
}
#end_block

#method_before
private String withdrawIntent(String intentId) {
    IntentService service = get(IntentService.class);
    Intent intent = service.getIntent(IntentId.valueOf(Tools.fromHex(intentId.replace("0x", ""))));
    if (intent != null) {
        log.info("Withdraw Intent ID = {}", intent.id());
        CountDownLatch latch = new CountDownLatch(1);
        InternalIntentListener listener = new InternalIntentListener(intent, service, latch);
        service.addListener(listener);
        service.withdraw(intent);
        try {
            if (latch.await(TIMEOUT, TimeUnit.SECONDS)) {
                return listener.getState() + "\n";
            }
        } catch (InterruptedException e) {
            log.warn("Interrupted while waiting for intent {} status", intent.id());
        }
        return "SERVER_ERROR\n";
    }
    log.info("Withdraw Intent ID = NULL");
    return "NOT_FOUND\n";
}
#method_after
private boolean withdrawIntent(Intent intent) throws InterruptedException {
    IntentService service = get(IntentService.class);
    CountDownLatch latch = new CountDownLatch(1);
    InternalIntentListener listener = new InternalIntentListener(intent, service, latch);
    service.addListener(listener);
    service.withdraw(intent);
    log.info("Withdrawing intent and waiting: {}", intent);
    if (latch.await(TIMEOUT, TimeUnit.SECONDS) && listener.getState() == WITHDRAWN) {
        return true;
    }
    return false;
}
#end_block

#method_before
private TrafficSelector buildTrafficSelector() {
    TrafficSelector.Builder selectorBuilder = DefaultTrafficSelector.builder();
    Short ethType = Ethernet.TYPE_IPV4;
    selectorBuilder.matchEthType(ethType);
    return selectorBuilder.build();
}
#method_after
private static TrafficSelector buildTrafficSelector() {
    TrafficSelector.Builder selectorBuilder = DefaultTrafficSelector.builder();
    Short ethType = Ethernet.TYPE_IPV4;
    selectorBuilder.matchEthType(ethType);
    return selectorBuilder.build();
}
#end_block

#method_before
private DeviceId deviceId(String dpid) {
    return DeviceId.deviceId(URI.create("of:" + dpid));
}
#method_after
private static DeviceId deviceId(String dpid) {
    return DeviceId.deviceId(URI.create("of:" + dpid));
}
#end_block

#method_before
@Override
public void event(IntentEvent event) {
    if (event.subject().equals(intent)) {
        state = service.getIntentState(intent.id());
        if (state == INSTALLED || state == FAILED || state == WITHDRAWN) {
            latch.countDown();
            service.removeListener(this);
        }
    }
}
#method_after
@Override
public void event(IntentEvent event) {
    if (event.subject().equals(intent)) {
        state = service.getIntentState(intent.key());
        if (state == INSTALLED || state == FAILED || state == WITHDRAWN) {
            latch.countDown();
            service.removeListener(this);
        }
    }
}
#end_block

#method_before
@Override
public LinkEvent createOrUpdateLink(ProviderId providerId, LinkDescription linkDescription) {
    final DeviceId dstDeviceId = linkDescription.dst().deviceId();
    final NodeId localNode = clusterService.getLocalNode().id();
    final NodeId dstNode = mastershipService.getMasterFor(dstDeviceId);
    // otherwise signal the actual master.
    if (localNode.equals(dstNode)) {
        Timestamp newTimestamp = deviceClockService.getTimestamp(dstDeviceId);
        final Timestamped<LinkDescription> deltaDesc = new Timestamped<>(linkDescription, newTimestamp);
        LinkKey key = linkKey(linkDescription.src(), linkDescription.dst());
        final Timestamped<LinkDescription> mergedDesc;
        Map<ProviderId, Timestamped<LinkDescription>> map = getOrCreateLinkDescriptions(key);
        LinkEvent linkEvent;
        synchronized (map) {
            linkEvent = createOrUpdateLinkInternal(providerId, deltaDesc);
            mergedDesc = map.get(providerId);
        }
        if (linkEvent != null) {
            log.info("Notifying peers of a link update topology event from providerId: " + "{}  between src: {} and dst: {}", providerId, linkDescription.src(), linkDescription.dst());
            notifyPeers(new InternalLinkEvent(providerId, mergedDesc));
            return linkEvent;
        }
    } else {
        LinkInjectedEvent linkInjectedEvent = new LinkInjectedEvent(providerId, linkDescription);
        ClusterMessage linkInjectedMessage = new ClusterMessage(localNode, GossipLinkStoreMessageSubjects.LINK_INJECTED, SERIALIZER.encode(linkInjectedEvent));
        try {
            Future<byte[]> response = clusterCommunicator.sendAndReceive(linkInjectedMessage, dstNode);
            response.get(1000, TimeUnit.MILLISECONDS);
        } catch (IOException | InterruptedException | ExecutionException | TimeoutException e) {
            log.warn("Failed to process link update between src: {} and dst: {} " + "(cluster messaging failed: {})", linkDescription.src(), linkDescription.dst(), e);
        }
    }
    return null;
}
#method_after
@Override
public LinkEvent createOrUpdateLink(ProviderId providerId, LinkDescription linkDescription) {
    final DeviceId dstDeviceId = linkDescription.dst().deviceId();
    final NodeId localNode = clusterService.getLocalNode().id();
    final NodeId dstNode = mastershipService.getMasterFor(dstDeviceId);
    // Process link update only if we're the master of the destination node,
    // otherwise signal the actual master.
    LinkEvent linkEvent = null;
    if (localNode.equals(dstNode)) {
        Timestamp newTimestamp = deviceClockService.getTimestamp(dstDeviceId);
        final Timestamped<LinkDescription> deltaDesc = new Timestamped<>(linkDescription, newTimestamp);
        LinkKey key = linkKey(linkDescription.src(), linkDescription.dst());
        final Timestamped<LinkDescription> mergedDesc;
        Map<ProviderId, Timestamped<LinkDescription>> map = getOrCreateLinkDescriptions(key);
        synchronized (map) {
            linkEvent = createOrUpdateLinkInternal(providerId, deltaDesc);
            mergedDesc = map.get(providerId);
        }
        if (linkEvent != null) {
            log.info("Notifying peers of a link update topology event from providerId: " + "{}  between src: {} and dst: {}", providerId, linkDescription.src(), linkDescription.dst());
            notifyPeers(new InternalLinkEvent(providerId, mergedDesc));
        }
    } else {
        LinkInjectedEvent linkInjectedEvent = new LinkInjectedEvent(providerId, linkDescription);
        ClusterMessage linkInjectedMessage = new ClusterMessage(localNode, GossipLinkStoreMessageSubjects.LINK_INJECTED, SERIALIZER.encode(linkInjectedEvent));
        try {
            clusterCommunicator.unicast(linkInjectedMessage, dstNode);
        } catch (IOException e) {
            log.warn("Failed to process link update between src: {} and dst: {} " + "(cluster messaging failed: {})", linkDescription.src(), linkDescription.dst(), e);
        }
    }
    return linkEvent;
}
#end_block

#method_before
@Override
public void handle(ClusterMessage message) {
    log.trace("Received injected link event from peer: {}", message.sender());
    LinkInjectedEvent linkInjectedEvent = (LinkInjectedEvent) SERIALIZER.decode(message.payload());
    ProviderId providerId = linkInjectedEvent.providerId();
    LinkDescription linkDescription = linkInjectedEvent.linkDescription();
    executor.submit(new Runnable() {

        @Override
        public void run() {
            createOrUpdateLink(providerId, linkDescription);
            try {
                message.respond(message.payload());
            } catch (Exception e) {
                log.warn("Failed to respond to LinkInjectedEvent", e);
            }
        }
    });
}
#method_after
@Override
public void handle(ClusterMessage message) {
    log.trace("Received injected link event from peer: {}", message.sender());
    LinkInjectedEvent linkInjectedEvent = SERIALIZER.decode(message.payload());
    ProviderId providerId = linkInjectedEvent.providerId();
    LinkDescription linkDescription = linkInjectedEvent.linkDescription();
    executor.submit(new Runnable() {

        @Override
        public void run() {
            createOrUpdateLink(providerId, linkDescription);
        }
    });
}
#end_block

#method_before
private void mastershipCheck() {
    log.debug("Checking mastership");
    for (Device device : getDevices()) {
        final DeviceId deviceId = device.id();
        log.debug("Checking device {}", deviceId);
        if (!isReachable(deviceId)) {
            continue;
        }
        if (mastershipService.getLocalRole(deviceId) != NONE) {
            continue;
        }
        log.info("{} is reachable but did not have a valid role, reasserting", deviceId);
        // isReachable but was not MASTER or STANDBY, get a role and apply
        // Note: NONE triggers request to MastershipService
        reassertRole(deviceId, NONE);
    }
}
#method_after
private void mastershipCheck() {
    log.debug("Checking mastership");
    for (Device device : getDevices()) {
        final DeviceId deviceId = device.id();
        log.trace("Checking device {}", deviceId);
        if (!isReachable(deviceId)) {
            continue;
        }
        if (mastershipService.getLocalRole(deviceId) != NONE) {
            continue;
        }
        log.info("{} is reachable but did not have a valid role, reasserting", deviceId);
        // isReachable but was not MASTER or STANDBY, get a role and apply
        // Note: NONE triggers request to MastershipService
        reassertRole(deviceId, NONE);
    }
}
#end_block

#method_before
@Override
public void event(MastershipEvent event) {
    if (event.type() != MastershipEvent.Type.MASTER_CHANGED) {
        // Don't care if backup list changed.
        return;
    }
    final DeviceId did = event.subject();
    final NodeId myNodeId = clusterService.getLocalNode().id();
    // myRole suggested by MastershipService
    MastershipRole myNextRole;
    if (myNodeId.equals(event.roleInfo().master())) {
        // confirm latest info
        MastershipTerm term = termService.getMastershipTerm(did);
        final boolean iHaveControl = myNodeId.equals(term.master());
        if (iHaveControl) {
            deviceClockProviderService.setMastershipTerm(did, term);
            myNextRole = MASTER;
        } else {
            myNextRole = STANDBY;
        }
    } else if (event.roleInfo().backups().contains(myNodeId)) {
        myNextRole = STANDBY;
    } else {
        myNextRole = NONE;
    }
    final boolean isReachable = isReachable(did);
    if (!isReachable) {
        // device is not connected to this node
        if (myNextRole != NONE) {
            log.warn("Node was instructed to be {} role for {}, " + "but this node cannot reach the device.  " + "Relinquishing role.  ", myNextRole, did);
            mastershipService.relinquishMastership(did);
        }
        return;
    }
    // device is connected to this node:
    reassertRole(did, myNextRole);
}
#method_after
@Override
public void event(MastershipEvent event) {
    if (event.type() != MastershipEvent.Type.MASTER_CHANGED) {
        // Don't care if backup list changed.
        return;
    }
    final DeviceId did = event.subject();
    final NodeId myNodeId = clusterService.getLocalNode().id();
    // myRole suggested by MastershipService
    MastershipRole myNextRole;
    if (myNodeId.equals(event.roleInfo().master())) {
        // confirm latest info
        MastershipTerm term = termService.getMastershipTerm(did);
        final boolean iHaveControl = myNodeId.equals(term.master());
        if (iHaveControl) {
            deviceClockProviderService.setMastershipTerm(did, term);
            myNextRole = MASTER;
        } else {
            myNextRole = STANDBY;
        }
    } else if (event.roleInfo().backups().contains(myNodeId)) {
        myNextRole = STANDBY;
    } else {
        myNextRole = NONE;
    }
    final boolean isReachable = isReachable(did);
    if (!isReachable) {
        // device is not connected to this node
        if (myNextRole != NONE) {
            log.warn("Node was instructed to be {} role for {}, " + "but this node cannot reach the device.  " + "Relinquishing role.  ", myNextRole, did);
            mastershipService.relinquishMastership(did);
        }
        return;
    }
    // device is connected to this node:
    if (store.getDevice(did) != null) {
        reassertRole(did, myNextRole);
    } else {
        log.warn("Device is not yet/no longer in the store: {}", did);
    }
}
#end_block

#method_before
@Override
public synchronized DeviceEvent createOrUpdateDevice(ProviderId providerId, DeviceId deviceId, DeviceDescription deviceDescription) {
    NodeId localNode = clusterService.getLocalNode().id();
    NodeId deviceNode = mastershipService.getMasterFor(deviceId);
    // otherwise signal the actual master.
    if (localNode.equals(deviceNode)) {
        final Timestamp newTimestamp = deviceClockService.getTimestamp(deviceId);
        final Timestamped<DeviceDescription> deltaDesc = new Timestamped<>(deviceDescription, newTimestamp);
        final DeviceEvent event;
        final Timestamped<DeviceDescription> mergedDesc;
        final Map<ProviderId, DeviceDescriptions> device = getOrCreateDeviceDescriptionsMap(deviceId);
        synchronized (device) {
            event = createOrUpdateDeviceInternal(providerId, deviceId, deltaDesc);
            mergedDesc = device.get(providerId).getDeviceDesc();
        }
        if (event != null) {
            log.info("Notifying peers of a device update topology event for providerId: {} and deviceId: {}", providerId, deviceId);
            notifyPeers(new InternalDeviceEvent(providerId, deviceId, mergedDesc));
        }
        return event;
    } else {
        DeviceInjectedEvent deviceInjectedEvent = new DeviceInjectedEvent(providerId, deviceId, deviceDescription);
        ClusterMessage clusterMessage = new ClusterMessage(localNode, DEVICE_INJECTED, SERIALIZER.encode(deviceInjectedEvent));
        try {
            Future<byte[]> response = clusterCommunicator.sendAndReceive(clusterMessage, deviceNode);
            response.get(REMOTE_MASTER_TIMEOUT, TimeUnit.MILLISECONDS);
        } catch (IOException | InterruptedException | ExecutionException | TimeoutException e) {
            log.warn("Failed to process injected device id: {} desc: {} " + "(cluster messaging failed: {})", deviceId, deviceDescription, e);
        }
    }
    return null;
}
#method_after
@Override
public synchronized DeviceEvent createOrUpdateDevice(ProviderId providerId, DeviceId deviceId, DeviceDescription deviceDescription) {
    NodeId localNode = clusterService.getLocalNode().id();
    NodeId deviceNode = mastershipService.getMasterFor(deviceId);
    // Process device update only if we're the master,
    // otherwise signal the actual master.
    DeviceEvent deviceEvent = null;
    if (localNode.equals(deviceNode)) {
        final Timestamp newTimestamp = deviceClockService.getTimestamp(deviceId);
        final Timestamped<DeviceDescription> deltaDesc = new Timestamped<>(deviceDescription, newTimestamp);
        final Timestamped<DeviceDescription> mergedDesc;
        final Map<ProviderId, DeviceDescriptions> device = getOrCreateDeviceDescriptionsMap(deviceId);
        synchronized (device) {
            deviceEvent = createOrUpdateDeviceInternal(providerId, deviceId, deltaDesc);
            mergedDesc = device.get(providerId).getDeviceDesc();
        }
        if (deviceEvent != null) {
            log.info("Notifying peers of a device update topology event for providerId: {} and deviceId: {}", providerId, deviceId);
            notifyPeers(new InternalDeviceEvent(providerId, deviceId, mergedDesc));
        }
    } else {
        DeviceInjectedEvent deviceInjectedEvent = new DeviceInjectedEvent(providerId, deviceId, deviceDescription);
        ClusterMessage clusterMessage = new ClusterMessage(localNode, DEVICE_INJECTED, SERIALIZER.encode(deviceInjectedEvent));
        try {
            clusterCommunicator.unicast(clusterMessage, deviceNode);
        } catch (IOException e) {
            log.warn("Failed to process injected device id: {} desc: {} " + "(cluster messaging failed: {})", deviceId, deviceDescription, e);
        }
    }
    return deviceEvent;
}
#end_block

#method_before
@Override
public synchronized List<DeviceEvent> updatePorts(ProviderId providerId, DeviceId deviceId, List<PortDescription> portDescriptions) {
    NodeId localNode = clusterService.getLocalNode().id();
    NodeId deviceNode = mastershipService.getMasterFor(deviceId);
    // otherwise signal the actual master.
    if (localNode.equals(deviceNode)) {
        final Timestamp newTimestamp;
        try {
            newTimestamp = deviceClockService.getTimestamp(deviceId);
        } catch (IllegalStateException e) {
            log.info("Timestamp was not available for device {}", deviceId);
            log.debug("  discarding {}", portDescriptions);
            return Collections.emptyList();
        }
        log.debug("timestamp for {} {}", deviceId, newTimestamp);
        final Timestamped<List<PortDescription>> timestampedInput = new Timestamped<>(portDescriptions, newTimestamp);
        final List<DeviceEvent> events;
        final Timestamped<List<PortDescription>> merged;
        final Map<ProviderId, DeviceDescriptions> device = getOrCreateDeviceDescriptionsMap(deviceId);
        synchronized (device) {
            events = updatePortsInternal(providerId, deviceId, timestampedInput);
            final DeviceDescriptions descs = device.get(providerId);
            List<PortDescription> mergedList = FluentIterable.from(portDescriptions).transform(new Function<PortDescription, PortDescription>() {

                @Override
                public PortDescription apply(PortDescription input) {
                    // lookup merged port description
                    return descs.getPortDesc(input.portNumber()).value();
                }
            }).toList();
            merged = new Timestamped<List<PortDescription>>(mergedList, newTimestamp);
        }
        if (!events.isEmpty()) {
            log.info("Notifying peers of a ports update topology event for providerId: {} and deviceId: {}", providerId, deviceId);
            notifyPeers(new InternalPortEvent(providerId, deviceId, merged));
        }
        return events;
    } else {
        PortInjectedEvent portInjectedEvent = new PortInjectedEvent(providerId, deviceId, portDescriptions);
        ClusterMessage clusterMessage = new ClusterMessage(localNode, PORT_INJECTED, SERIALIZER.encode(portInjectedEvent));
        try {
            Future<byte[]> response = clusterCommunicator.sendAndReceive(clusterMessage, deviceNode);
            response.get(REMOTE_MASTER_TIMEOUT, TimeUnit.MILLISECONDS);
        } catch (IOException | InterruptedException | ExecutionException | TimeoutException e) {
            log.warn("Failed to process injected ports of device id: {} " + "(cluster messaging failed: {})", deviceId, e);
        }
    }
    return null;
}
#method_after
@Override
public synchronized List<DeviceEvent> updatePorts(ProviderId providerId, DeviceId deviceId, List<PortDescription> portDescriptions) {
    NodeId localNode = clusterService.getLocalNode().id();
    // TODO: It might be negligible, but this will have negative impact to topology discovery performance,
    // since it will trigger distributed store read.
    // Also, it'll probably be better if side-way communication happened on ConfigurationProvider, etc.
    // outside Device subsystem. so that we don't have to modify both Device and Link stores.
    // If we don't care much about topology performance, then it might be OK.
    NodeId deviceNode = mastershipService.getMasterFor(deviceId);
    // Process port update only if we're the master of the device,
    // otherwise signal the actual master.
    List<DeviceEvent> deviceEvents = null;
    if (localNode.equals(deviceNode)) {
        final Timestamp newTimestamp;
        try {
            newTimestamp = deviceClockService.getTimestamp(deviceId);
        } catch (IllegalStateException e) {
            log.info("Timestamp was not available for device {}", deviceId);
            log.debug("  discarding {}", portDescriptions);
            return Collections.emptyList();
        }
        log.debug("timestamp for {} {}", deviceId, newTimestamp);
        final Timestamped<List<PortDescription>> timestampedInput = new Timestamped<>(portDescriptions, newTimestamp);
        final Timestamped<List<PortDescription>> merged;
        final Map<ProviderId, DeviceDescriptions> device = getOrCreateDeviceDescriptionsMap(deviceId);
        synchronized (device) {
            deviceEvents = updatePortsInternal(providerId, deviceId, timestampedInput);
            final DeviceDescriptions descs = device.get(providerId);
            List<PortDescription> mergedList = FluentIterable.from(portDescriptions).transform(new Function<PortDescription, PortDescription>() {

                @Override
                public PortDescription apply(PortDescription input) {
                    // lookup merged port description
                    return descs.getPortDesc(input.portNumber()).value();
                }
            }).toList();
            merged = new Timestamped<List<PortDescription>>(mergedList, newTimestamp);
        }
        if (!deviceEvents.isEmpty()) {
            log.info("Notifying peers of a ports update topology event for providerId: {} and deviceId: {}", providerId, deviceId);
            notifyPeers(new InternalPortEvent(providerId, deviceId, merged));
        }
    } else {
        PortInjectedEvent portInjectedEvent = new PortInjectedEvent(providerId, deviceId, portDescriptions);
        ClusterMessage clusterMessage = new ClusterMessage(localNode, PORT_INJECTED, SERIALIZER.encode(portInjectedEvent));
        try {
            clusterCommunicator.unicast(clusterMessage, deviceNode);
        } catch (IOException e) {
            log.warn("Failed to process injected ports of device id: {} " + "(cluster messaging failed: {})", deviceId, e);
        }
    }
    return deviceEvents;
}
#end_block

#method_before
@Override
public void handle(ClusterMessage message) {
    log.debug("Received injected device event from peer: {}", message.sender());
    DeviceInjectedEvent event = SERIALIZER.decode(message.payload());
    ProviderId providerId = event.providerId();
    DeviceId deviceId = event.deviceId();
    DeviceDescription deviceDescription = event.deviceDescription();
    executor.submit(new Runnable() {

        @Override
        public void run() {
            createOrUpdateDevice(providerId, deviceId, deviceDescription);
            try {
                message.respond(message.payload());
            } catch (Exception e) {
                log.warn("Failed to respond to DeviceInjectedEvent", e);
            }
        }
    });
}
#method_after
@Override
public void handle(ClusterMessage message) {
    log.debug("Received injected device event from peer: {}", message.sender());
    DeviceInjectedEvent event = SERIALIZER.decode(message.payload());
    ProviderId providerId = event.providerId();
    DeviceId deviceId = event.deviceId();
    DeviceDescription deviceDescription = event.deviceDescription();
    executor.submit(new Runnable() {

        @Override
        public void run() {
            createOrUpdateDevice(providerId, deviceId, deviceDescription);
        }
    });
}
#end_block

#method_before
@Override
public void handle(ClusterMessage message) {
    log.debug("Received injected port event from peer: {}", message.sender());
    PortInjectedEvent event = SERIALIZER.decode(message.payload());
    ProviderId providerId = event.providerId();
    DeviceId deviceId = event.deviceId();
    List<PortDescription> portDescriptions = event.portDescriptions();
    executor.submit(new Runnable() {

        @Override
        public void run() {
            updatePorts(providerId, deviceId, portDescriptions);
            try {
                message.respond(message.payload());
            } catch (Exception e) {
                log.warn("Failed to respond to PortInjectedEvent", e);
            }
        }
    });
}
#method_after
@Override
public void handle(ClusterMessage message) {
    log.debug("Received injected port event from peer: {}", message.sender());
    PortInjectedEvent event = SERIALIZER.decode(message.payload());
    ProviderId providerId = event.providerId();
    DeviceId deviceId = event.deviceId();
    List<PortDescription> portDescriptions = event.portDescriptions();
    executor.submit(new Runnable() {

        @Override
        public void run() {
            updatePorts(providerId, deviceId, portDescriptions);
        }
    });
}
#end_block

#method_before
@Override
public String toString() {
    return MoreObjects.toStringHelper(getClass()).add("success?", success).add("failedItems", failures).toString();
}
#method_after
@Override
public String toString() {
    return MoreObjects.toStringHelper(getClass()).add("success?", isSuccess()).add("failedItems", failedIds()).toString();
}
#end_block

#method_before
@Override
public void notify(GroupEvent event) {
    final Group group = event.subject();
    GroupProvider groupProvider = getProvider(group.deviceId());
    GroupOperations groupOps = null;
    switch(event.type()) {
        case GROUP_ADD_REQUESTED:
            log.debug("GROUP_ADD_REQUESTED for Group {} on device {}", group.id(), group.deviceId());
            GroupOperation groupAddOp = GroupOperation.createAddGroupOperation(group.id(), group.type(), group.buckets());
            groupOps = new GroupOperations(Arrays.asList(groupAddOp));
            groupProvider.performGroupOperation(group.deviceId(), groupOps);
            break;
        case GROUP_UPDATE_REQUESTED:
            log.debug("GROUP_UPDATE_REQUESTED for Group {} on device {}", group.id(), group.deviceId());
            GroupOperation groupModifyOp = GroupOperation.createModifyGroupOperation(group.id(), group.type(), group.buckets());
            groupOps = new GroupOperations(Arrays.asList(groupModifyOp));
            groupProvider.performGroupOperation(group.deviceId(), groupOps);
            break;
        case GROUP_REMOVE_REQUESTED:
            log.debug("GROUP_REMOVE_REQUESTED for Group {} on device {}", group.id(), group.deviceId());
            GroupOperation groupDeleteOp = GroupOperation.createDeleteGroupOperation(group.id(), group.type());
            groupOps = new GroupOperations(Arrays.asList(groupDeleteOp));
            groupProvider.performGroupOperation(group.deviceId(), groupOps);
            break;
        case GROUP_ADDED:
        case GROUP_UPDATED:
        case GROUP_REMOVED:
            eventDispatcher.post(event);
            break;
        default:
            break;
    }
}
#method_after
@Override
public void notify(GroupEvent event) {
    final Group group = event.subject();
    GroupProvider groupProvider = getProvider(group.deviceId());
    GroupOperations groupOps = null;
    switch(event.type()) {
        case GROUP_ADD_REQUESTED:
            log.debug("GROUP_ADD_REQUESTED for Group {} on device {}", group.id(), group.deviceId());
            GroupOperation groupAddOp = GroupOperation.createAddGroupOperation(group.id(), group.type(), group.buckets());
            groupOps = new GroupOperations(Arrays.asList(groupAddOp));
            groupProvider.performGroupOperation(group.deviceId(), groupOps);
            break;
        case GROUP_UPDATE_REQUESTED:
            log.debug("GROUP_UPDATE_REQUESTED for Group {} on device {}", group.id(), group.deviceId());
            GroupOperation groupModifyOp = GroupOperation.createModifyGroupOperation(group.id(), group.type(), group.buckets());
            groupOps = new GroupOperations(Arrays.asList(groupModifyOp));
            groupProvider.performGroupOperation(group.deviceId(), groupOps);
            break;
        case GROUP_REMOVE_REQUESTED:
            log.debug("GROUP_REMOVE_REQUESTED for Group {} on device {}", group.id(), group.deviceId());
            GroupOperation groupDeleteOp = GroupOperation.createDeleteGroupOperation(group.id(), group.type());
            groupOps = new GroupOperations(Arrays.asList(groupDeleteOp));
            groupProvider.performGroupOperation(group.deviceId(), groupOps);
            break;
        case GROUP_ADDED:
        case GROUP_UPDATED:
        case GROUP_REMOVED:
        case GROUP_ADD_FAILED:
        case GROUP_UPDATE_FAILED:
        case GROUP_REMOVE_FAILED:
            eventDispatcher.post(event);
            break;
        default:
            break;
    }
}
#end_block

#method_before
@Override
public void groupOperationFailed(GroupOperation operation) {
// TODO Auto-generated method stub
}
#method_after
@Override
public void groupOperationFailed(DeviceId deviceId, GroupOperation operation) {
    store.groupOperationFailed(deviceId, operation);
}
#end_block

#method_before
@Override
public void pushGroupMetrics(DeviceId deviceId, Collection<Group> groupEntries) {
    log.trace("Received group metrics from device {}", deviceId);
    boolean deviceInitialAuditStatus = store.deviceInitialAuditStatus(deviceId);
    Set<Group> southboundGroupEntries = Sets.newHashSet(groupEntries);
    Set<Group> storedGroupEntries = Sets.newHashSet(store.getGroups(deviceId));
    Set<Group> extraneousStoredEntries = Sets.newHashSet(store.getExtraneousGroups(deviceId));
    log.trace("Dispalying all southboundGroupEntries for device {}", deviceId);
    for (Iterator<Group> it = southboundGroupEntries.iterator(); it.hasNext(); ) {
        Group group = it.next();
        log.trace("Group {} in device {}", group, deviceId);
    }
    log.trace("Dispalying all stored group entries for device {}", deviceId);
    for (Iterator<Group> it = storedGroupEntries.iterator(); it.hasNext(); ) {
        Group group = it.next();
        log.trace("Stored Group {} for device {}", group, deviceId);
    }
    for (Iterator<Group> it = southboundGroupEntries.iterator(); it.hasNext(); ) {
        Group group = it.next();
        if (storedGroupEntries.remove(group)) {
            // we both have the group, let's update some info then.
            log.trace("Group AUDIT: group {} exists " + "in both planes for device {}", group.id(), deviceId);
            groupAdded(group);
            it.remove();
        }
    }
    for (Group group : southboundGroupEntries) {
        // there are groups in the switch that aren't in the store
        log.trace("Group AUDIT: extraneous group {} exists " + "in data plane for device {}", group.id(), deviceId);
        extraneousStoredEntries.remove(group);
        extraneousGroup(group);
    }
    for (Group group : storedGroupEntries) {
        // there are groups in the store that aren't in the switch
        log.trace("Group AUDIT: group {} missing " + "in data plane for device {}", group.id(), deviceId);
        groupMissing(group);
    }
    for (Group group : extraneousStoredEntries) {
        // there are groups in the extraneous store that
        // aren't in the switch
        log.trace("Group AUDIT: clearing extransoeus group {} " + "from store for device {}", group.id(), deviceId);
        store.removeExtraneousGroupEntry(group);
    }
    if (!deviceInitialAuditStatus) {
        log.info("Group AUDIT: Setting device {} initial " + "AUDIT completed", deviceId);
        store.deviceInitialAuditCompleted(deviceId, true);
    }
}
#method_after
@Override
public void pushGroupMetrics(DeviceId deviceId, Collection<Group> groupEntries) {
    log.trace("Received group metrics from device {}", deviceId);
    boolean deviceInitialAuditStatus = store.deviceInitialAuditStatus(deviceId);
    Set<Group> southboundGroupEntries = Sets.newHashSet(groupEntries);
    Set<Group> storedGroupEntries = Sets.newHashSet(store.getGroups(deviceId));
    Set<Group> extraneousStoredEntries = Sets.newHashSet(store.getExtraneousGroups(deviceId));
    log.trace("Displaying all southboundGroupEntries for device {}", deviceId);
    for (Iterator<Group> it = southboundGroupEntries.iterator(); it.hasNext(); ) {
        Group group = it.next();
        log.trace("Group {} in device {}", group, deviceId);
    }
    log.trace("Displaying all stored group entries for device {}", deviceId);
    for (Iterator<Group> it = storedGroupEntries.iterator(); it.hasNext(); ) {
        Group group = it.next();
        log.trace("Stored Group {} for device {}", group, deviceId);
    }
    for (Iterator<Group> it = southboundGroupEntries.iterator(); it.hasNext(); ) {
        Group group = it.next();
        if (storedGroupEntries.remove(group)) {
            // we both have the group, let's update some info then.
            log.trace("Group AUDIT: group {} exists " + "in both planes for device {}", group.id(), deviceId);
            groupAdded(group);
            it.remove();
        }
    }
    for (Group group : southboundGroupEntries) {
        // there are groups in the switch that aren't in the store
        log.trace("Group AUDIT: extraneous group {} exists " + "in data plane for device {}", group.id(), deviceId);
        extraneousStoredEntries.remove(group);
        extraneousGroup(group);
    }
    for (Group group : storedGroupEntries) {
        // there are groups in the store that aren't in the switch
        log.trace("Group AUDIT: group {} missing " + "in data plane for device {}", group.id(), deviceId);
        groupMissing(group);
    }
    for (Group group : extraneousStoredEntries) {
        // there are groups in the extraneous store that
        // aren't in the switch
        log.trace("Group AUDIT: clearing extransoeus group {} " + "from store for device {}", group.id(), deviceId);
        store.removeExtraneousGroupEntry(group);
    }
    if (!deviceInitialAuditStatus) {
        log.debug("Group AUDIT: Setting device {} initial " + "AUDIT completed", deviceId);
        store.deviceInitialAuditCompleted(deviceId, true);
    }
}
#end_block

#method_before
@Override
public void event(DeviceEvent event) {
    switch(event.type()) {
        case DEVICE_REMOVED:
            log.info("Clearing device {} initial " + "AUDIT completed status as device is going down", event.subject().id());
            store.deviceInitialAuditCompleted(event.subject().id(), false);
            break;
        default:
            break;
    }
}
#method_after
@Override
public void event(DeviceEvent event) {
    switch(event.type()) {
        case DEVICE_REMOVED:
            log.debug("Clearing device {} initial " + "AUDIT completed status as device is going down", event.subject().id());
            store.deviceInitialAuditCompleted(event.subject().id(), false);
            break;
        default:
            break;
    }
}
#end_block

#method_before
@Override
public void createGroups() {
    Set<DeviceId> neighbors = devicePortMap.keySet();
    if (neighbors == null || neighbors.isEmpty()) {
        return;
    }
    /* Create all possible Neighbor sets from this router
         * NOTE: Avoid any pairings of edge routers only
         */
    Set<Set<DeviceId>> sets = getPowerSetOfNeighbors(neighbors);
    sets = filterEdgeRouterOnlyPairings(sets);
    log.debug("createGroupsAtTransitRouter: The size of neighbor powerset " + "for sw {} is {}", deviceId, sets.size());
    Set<NeighborSet> nsSet = new HashSet<NeighborSet>();
    for (Set<DeviceId> combo : sets) {
        if (combo.isEmpty()) {
            continue;
        }
        NeighborSet ns = new NeighborSet();
        ns.addDeviceIds(combo);
        log.debug("createGroupsAtTransitRouter: sw {} combo {} ns {}", deviceId, combo, ns);
        nsSet.add(ns);
    }
    log.debug("createGroupsAtTransitRouter: The neighborset with label " + "for sw {} is {}", deviceId, nsSet);
    createGroupsFromNeighborsets(nsSet);
}
#method_after
@Override
public void createGroups() {
    Set<DeviceId> neighbors = devicePortMap.keySet();
    if (neighbors == null || neighbors.isEmpty()) {
        return;
    }
    // Create all possible Neighbor sets from this router
    // NOTE: Avoid any pairings of edge routers only
    Set<Set<DeviceId>> sets = getPowerSetOfNeighbors(neighbors);
    sets = filterEdgeRouterOnlyPairings(sets);
    log.debug("createGroupsAtTransitRouter: The size of neighbor powerset " + "for sw {} is {}", deviceId, sets.size());
    Set<NeighborSet> nsSet = new HashSet<NeighborSet>();
    for (Set<DeviceId> combo : sets) {
        if (combo.isEmpty()) {
            continue;
        }
        NeighborSet ns = new NeighborSet(combo);
        log.debug("createGroupsAtTransitRouter: sw {} combo {} ns {}", deviceId, combo, ns);
        nsSet.add(ns);
    }
    log.debug("createGroupsAtTransitRouter: The neighborset with label " + "for sw {} is {}", deviceId, nsSet);
    createGroupsFromNeighborsets(nsSet);
}
#end_block

#method_before
@Override
protected void newNeighbor(Link newNeighborLink) {
    log.debug("New Neighbor: Updating groups for " + "transit device {}", deviceId);
    /* Recompute neighbor power set */
    addNeighborAtPort(newNeighborLink.dst().deviceId(), newNeighborLink.src().port());
    /* Compute new neighbor sets due to the addition of new neighbor */
    Set<NeighborSet> nsSet = computeImpactedNeighborsetForPortEvent(newNeighborLink.dst().deviceId(), devicePortMap.keySet());
    createGroupsFromNeighborsets(nsSet);
}
#method_after
@Override
protected void newNeighbor(Link newNeighborLink) {
    log.debug("New Neighbor: Updating groups for " + "transit device {}", deviceId);
    // Recompute neighbor power set
    addNeighborAtPort(newNeighborLink.dst().deviceId(), newNeighborLink.src().port());
    // Compute new neighbor sets due to the addition of new neighbor
    Set<NeighborSet> nsSet = computeImpactedNeighborsetForPortEvent(newNeighborLink.dst().deviceId(), devicePortMap.keySet());
    createGroupsFromNeighborsets(nsSet);
}
#end_block

#method_before
@Override
protected void newPortToExistingNeighbor(Link newNeighborLink) {
    log.debug("New port to existing neighbor: Updating " + "groups for transit device {}", deviceId);
    addNeighborAtPort(newNeighborLink.dst().deviceId(), newNeighborLink.src().port());
    Set<NeighborSet> nsSet = computeImpactedNeighborsetForPortEvent(newNeighborLink.dst().deviceId(), devicePortMap.keySet());
    for (NeighborSet ns : nsSet) {
        /* Create the new bucket to be updated */
        TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
        tBuilder.setOutput(newNeighborLink.src().port()).setEthDst(deviceConfig.getDeviceMac(newNeighborLink.dst().deviceId())).setEthSrc(nodeMacAddr).pushMpls().setMpls(ns.getEdgeLabel());
        GroupBucket updatedBucket = DefaultGroupBucket.createSelectGroupBucket(tBuilder.build());
        GroupBuckets updatedBuckets = new GroupBuckets(Arrays.asList(updatedBucket));
        log.debug("newPortToExistingNeighborAtEdgeRouter: " + "groupService.addBucketsToGroup for neighborset{}", ns);
        groupService.addBucketsToGroup(deviceId, ns, updatedBuckets, ns, appId);
    }
}
#method_after
@Override
protected void newPortToExistingNeighbor(Link newNeighborLink) {
    log.debug("New port to existing neighbor: Updating " + "groups for transit device {}", deviceId);
    addNeighborAtPort(newNeighborLink.dst().deviceId(), newNeighborLink.src().port());
    Set<NeighborSet> nsSet = computeImpactedNeighborsetForPortEvent(newNeighborLink.dst().deviceId(), devicePortMap.keySet());
    for (NeighborSet ns : nsSet) {
        // Create the new bucket to be updated
        TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
        tBuilder.setOutput(newNeighborLink.src().port()).setEthDst(deviceConfig.getDeviceMac(newNeighborLink.dst().deviceId())).setEthSrc(nodeMacAddr).pushMpls().setMpls(ns.getEdgeLabel());
        GroupBucket updatedBucket = DefaultGroupBucket.createSelectGroupBucket(tBuilder.build());
        GroupBuckets updatedBuckets = new GroupBuckets(Arrays.asList(updatedBucket));
        log.debug("newPortToExistingNeighborAtEdgeRouter: " + "groupService.addBucketsToGroup for neighborset{}", ns);
        groupService.addBucketsToGroup(deviceId, ns, updatedBuckets, ns, appId);
    }
}
#end_block

#method_before
@Override
protected Set<NeighborSet> computeImpactedNeighborsetForPortEvent(DeviceId impactedNeighbor, Set<DeviceId> updatedNeighbors) {
    Set<Set<DeviceId>> powerSet = getPowerSetOfNeighbors(updatedNeighbors);
    Set<DeviceId> tmp = updatedNeighbors;
    tmp.remove(impactedNeighbor);
    Set<Set<DeviceId>> tmpPowerSet = getPowerSetOfNeighbors(tmp);
    /* Compute the impacted neighbor sets */
    powerSet.removeAll(tmpPowerSet);
    powerSet = filterEdgeRouterOnlyPairings(powerSet);
    Set<NeighborSet> nsSet = new HashSet<NeighborSet>();
    for (Set<DeviceId> combo : powerSet) {
        if (combo.isEmpty()) {
            continue;
        }
        NeighborSet ns = new NeighborSet();
        ns.addDeviceIds(combo);
        log.debug("createGroupsAtTransitRouter: sw {} combo {} ns {}", deviceId, combo, ns);
        nsSet.add(ns);
    }
    log.debug("computeImpactedNeighborsetForPortEvent: The neighborset with label " + "for sw {} is {}", deviceId, nsSet);
    return nsSet;
}
#method_after
@Override
protected Set<NeighborSet> computeImpactedNeighborsetForPortEvent(DeviceId impactedNeighbor, Set<DeviceId> updatedNeighbors) {
    Set<Set<DeviceId>> powerSet = getPowerSetOfNeighbors(updatedNeighbors);
    Set<DeviceId> tmp = updatedNeighbors;
    tmp.remove(impactedNeighbor);
    Set<Set<DeviceId>> tmpPowerSet = getPowerSetOfNeighbors(tmp);
    // Compute the impacted neighbor sets
    powerSet.removeAll(tmpPowerSet);
    powerSet = filterEdgeRouterOnlyPairings(powerSet);
    Set<NeighborSet> nsSet = new HashSet<NeighborSet>();
    for (Set<DeviceId> combo : powerSet) {
        if (combo.isEmpty()) {
            continue;
        }
        NeighborSet ns = new NeighborSet(combo);
        log.debug("createGroupsAtTransitRouter: sw {} combo {} ns {}", deviceId, combo, ns);
        nsSet.add(ns);
    }
    log.debug("computeImpactedNeighborsetForPortEvent: The neighborset with label " + "for sw {} is {}", deviceId, nsSet);
    return nsSet;
}
#end_block

#method_before
@Override
public void notify(GroupEvent event) {
    assertEquals(expectedEvent, event.type());
    assertEquals(Group.Type.SELECT, event.subject().type());
    assertEquals(D1, event.subject().deviceId());
    assertEquals(createdGroupKey, event.subject().appCookie());
    assertEquals(createdBuckets.buckets(), event.subject().buckets().buckets());
    if (expectedEvent == GroupEvent.Type.GROUP_ADD_REQUESTED) {
        createdGroupId = event.subject().id();
        assertEquals(Group.GroupState.PENDING_ADD, event.subject().state());
    } else if (expectedEvent == GroupEvent.Type.GROUP_ADDED) {
        createdGroupId = event.subject().id();
        assertEquals(Group.GroupState.ADDED, event.subject().state());
    } else if (expectedEvent == GroupEvent.Type.GROUP_UPDATE_REQUESTED) {
        assertEquals(Group.GroupState.PENDING_UPDATE, event.subject().state());
    } else if (expectedEvent == GroupEvent.Type.GROUP_REMOVE_REQUESTED) {
        assertEquals(Group.GroupState.PENDING_DELETE, event.subject().state());
    } else if (expectedEvent == GroupEvent.Type.GROUP_REMOVED) {
        createdGroupId = event.subject().id();
        assertEquals(Group.GroupState.PENDING_DELETE, event.subject().state());
    }
}
#method_after
@Override
public void notify(GroupEvent event) {
    assertEquals(expectedEvent, event.type());
    assertEquals(Group.Type.SELECT, event.subject().type());
    assertEquals(D1, event.subject().deviceId());
    assertEquals(createdGroupKey, event.subject().appCookie());
    assertEquals(createdBuckets.buckets(), event.subject().buckets().buckets());
    if (expectedEvent == GroupEvent.Type.GROUP_ADD_REQUESTED) {
        createdGroupId = event.subject().id();
        assertEquals(Group.GroupState.PENDING_ADD, event.subject().state());
    } else if (expectedEvent == GroupEvent.Type.GROUP_ADDED) {
        createdGroupId = event.subject().id();
        assertEquals(Group.GroupState.ADDED, event.subject().state());
    } else if (expectedEvent == GroupEvent.Type.GROUP_UPDATE_REQUESTED) {
        assertEquals(Group.GroupState.PENDING_UPDATE, event.subject().state());
    } else if (expectedEvent == GroupEvent.Type.GROUP_REMOVE_REQUESTED) {
        assertEquals(Group.GroupState.PENDING_DELETE, event.subject().state());
    } else if (expectedEvent == GroupEvent.Type.GROUP_REMOVED) {
        createdGroupId = event.subject().id();
        assertEquals(Group.GroupState.PENDING_DELETE, event.subject().state());
    } else if (expectedEvent == GroupEvent.Type.GROUP_ADD_FAILED) {
        createdGroupId = event.subject().id();
        assertEquals(Group.GroupState.PENDING_ADD, event.subject().state());
    } else if (expectedEvent == GroupEvent.Type.GROUP_UPDATE_FAILED) {
        createdGroupId = event.subject().id();
        assertEquals(Group.GroupState.PENDING_UPDATE, event.subject().state());
    } else if (expectedEvent == GroupEvent.Type.GROUP_REMOVE_FAILED) {
        createdGroupId = event.subject().id();
        assertEquals(Group.GroupState.PENDING_DELETE, event.subject().state());
    }
}
#end_block

#method_before
@Test
public void testGroupStoreOperations() {
    // Set the Device AUDIT completed in the store
    simpleGroupStore.deviceInitialAuditCompleted(D1, true);
    ApplicationId appId = new DefaultApplicationId(2, "org.groupstore.test");
    TestGroupKey key = new TestGroupKey("group1");
    PortNumber[] ports = { PortNumber.portNumber(31), PortNumber.portNumber(32) };
    List<PortNumber> outPorts = new ArrayList<PortNumber>();
    outPorts.add(ports[0]);
    outPorts.add(ports[1]);
    List<GroupBucket> buckets = new ArrayList<GroupBucket>();
    for (PortNumber portNumber : outPorts) {
        TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
        tBuilder.setOutput(portNumber).setEthDst(MacAddress.valueOf("00:00:00:00:00:02")).setEthSrc(MacAddress.valueOf("00:00:00:00:00:01")).pushMpls().setMpls(106);
        buckets.add(DefaultGroupBucket.createSelectGroupBucket(tBuilder.build()));
    }
    GroupBuckets groupBuckets = new GroupBuckets(buckets);
    GroupDescription groupDesc = new DefaultGroupDescription(D1, Group.Type.SELECT, groupBuckets, key, appId);
    InternalGroupStoreDelegate checkStoreGroupDelegate = new InternalGroupStoreDelegate(key, groupBuckets, GroupEvent.Type.GROUP_ADD_REQUESTED);
    simpleGroupStore.setDelegate(checkStoreGroupDelegate);
    // Testing storeGroup operation
    simpleGroupStore.storeGroupDescription(groupDesc);
    // Testing getGroupCount operation
    assertEquals(1, simpleGroupStore.getGroupCount(D1));
    // Testing getGroup operation
    Group createdGroup = simpleGroupStore.getGroup(D1, key);
    checkStoreGroupDelegate.verifyGroupId(createdGroup.id());
    // Testing getGroups operation
    Iterable<Group> createdGroups = simpleGroupStore.getGroups(D1);
    int groupCount = 0;
    for (Group group : createdGroups) {
        checkStoreGroupDelegate.verifyGroupId(group.id());
        groupCount++;
    }
    assertEquals(1, groupCount);
    simpleGroupStore.unsetDelegate(checkStoreGroupDelegate);
    // Testing addOrUpdateGroupEntry operation from southbound
    InternalGroupStoreDelegate addGroupEntryDelegate = new InternalGroupStoreDelegate(key, groupBuckets, GroupEvent.Type.GROUP_ADDED);
    simpleGroupStore.setDelegate(addGroupEntryDelegate);
    simpleGroupStore.addOrUpdateGroupEntry(createdGroup);
    simpleGroupStore.unsetDelegate(addGroupEntryDelegate);
    // Testing updateGroupDescription for ADD operation from northbound
    TestGroupKey addKey = new TestGroupKey("group1AddBuckets");
    PortNumber[] newNeighborPorts = { PortNumber.portNumber(41), PortNumber.portNumber(42) };
    List<PortNumber> newOutPorts = new ArrayList<PortNumber>();
    newOutPorts.add(newNeighborPorts[0]);
    newOutPorts.add(newNeighborPorts[1]);
    List<GroupBucket> toAddBuckets = new ArrayList<GroupBucket>();
    for (PortNumber portNumber : newOutPorts) {
        TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
        tBuilder.setOutput(portNumber).setEthDst(MacAddress.valueOf("00:00:00:00:00:03")).setEthSrc(MacAddress.valueOf("00:00:00:00:00:01")).pushMpls().setMpls(106);
        toAddBuckets.add(DefaultGroupBucket.createSelectGroupBucket(tBuilder.build()));
    }
    GroupBuckets toAddGroupBuckets = new GroupBuckets(toAddBuckets);
    buckets.addAll(toAddBuckets);
    GroupBuckets updatedGroupBuckets = new GroupBuckets(buckets);
    InternalGroupStoreDelegate updateGroupDescDelegate = new InternalGroupStoreDelegate(addKey, updatedGroupBuckets, GroupEvent.Type.GROUP_UPDATE_REQUESTED);
    simpleGroupStore.setDelegate(updateGroupDescDelegate);
    simpleGroupStore.updateGroupDescription(D1, key, UpdateType.ADD, toAddGroupBuckets, addKey);
    simpleGroupStore.unsetDelegate(updateGroupDescDelegate);
    // Testing updateGroupDescription for REMOVE operation from northbound
    TestGroupKey removeKey = new TestGroupKey("group1RemoveBuckets");
    List<GroupBucket> toRemoveBuckets = new ArrayList<GroupBucket>();
    toRemoveBuckets.add(updatedGroupBuckets.buckets().get(0));
    toRemoveBuckets.add(updatedGroupBuckets.buckets().get(1));
    GroupBuckets toRemoveGroupBuckets = new GroupBuckets(toRemoveBuckets);
    List<GroupBucket> remainingBuckets = new ArrayList<GroupBucket>();
    remainingBuckets.add(updatedGroupBuckets.buckets().get(2));
    remainingBuckets.add(updatedGroupBuckets.buckets().get(3));
    GroupBuckets remainingGroupBuckets = new GroupBuckets(remainingBuckets);
    InternalGroupStoreDelegate removeGroupDescDelegate = new InternalGroupStoreDelegate(removeKey, remainingGroupBuckets, GroupEvent.Type.GROUP_UPDATE_REQUESTED);
    simpleGroupStore.setDelegate(removeGroupDescDelegate);
    simpleGroupStore.updateGroupDescription(D1, addKey, UpdateType.REMOVE, toRemoveGroupBuckets, removeKey);
    simpleGroupStore.unsetDelegate(removeGroupDescDelegate);
    // Testing getGroup operation
    Group existingGroup = simpleGroupStore.getGroup(D1, removeKey);
    checkStoreGroupDelegate.verifyGroupId(existingGroup.id());
    // Testing addOrUpdateGroupEntry operation from southbound
    InternalGroupStoreDelegate updateGroupEntryDelegate = new InternalGroupStoreDelegate(removeKey, remainingGroupBuckets, GroupEvent.Type.GROUP_UPDATED);
    simpleGroupStore.setDelegate(updateGroupEntryDelegate);
    simpleGroupStore.addOrUpdateGroupEntry(existingGroup);
    simpleGroupStore.unsetDelegate(updateGroupEntryDelegate);
    // Testing deleteGroupDescription operation from northbound
    InternalGroupStoreDelegate deleteGroupDescDelegate = new InternalGroupStoreDelegate(removeKey, remainingGroupBuckets, GroupEvent.Type.GROUP_REMOVE_REQUESTED);
    simpleGroupStore.setDelegate(deleteGroupDescDelegate);
    simpleGroupStore.deleteGroupDescription(D1, removeKey);
    simpleGroupStore.unsetDelegate(deleteGroupDescDelegate);
    // Testing removeGroupEntry operation from southbound
    InternalGroupStoreDelegate removeGroupEntryDelegate = new InternalGroupStoreDelegate(removeKey, remainingGroupBuckets, GroupEvent.Type.GROUP_REMOVED);
    simpleGroupStore.setDelegate(removeGroupEntryDelegate);
    simpleGroupStore.removeGroupEntry(existingGroup);
    // Testing getGroup operation
    existingGroup = simpleGroupStore.getGroup(D1, removeKey);
    assertEquals(null, existingGroup);
    assertEquals(0, Iterables.size(simpleGroupStore.getGroups(D1)));
    assertEquals(0, simpleGroupStore.getGroupCount(D1));
    simpleGroupStore.unsetDelegate(removeGroupEntryDelegate);
}
#method_after
@Test
public void testGroupStoreOperations() {
    // Set the Device AUDIT completed in the store
    simpleGroupStore.deviceInitialAuditCompleted(D1, true);
    // Testing storeGroup operation
    TestGroupKey newKey = new TestGroupKey("group1");
    testStoreAndGetGroup(newKey);
    // Testing addOrUpdateGroupEntry operation from southbound
    TestGroupKey currKey = newKey;
    testAddGroupEntryFromSB(currKey);
    // Testing updateGroupDescription for ADD operation from northbound
    newKey = new TestGroupKey("group1AddBuckets");
    testAddBuckets(currKey, newKey);
    // Testing updateGroupDescription for REMOVE operation from northbound
    currKey = newKey;
    newKey = new TestGroupKey("group1RemoveBuckets");
    testRemoveBuckets(currKey, newKey);
    // Testing addOrUpdateGroupEntry operation from southbound
    currKey = newKey;
    testUpdateGroupEntryFromSB(currKey);
    // Testing deleteGroupDescription operation from northbound
    testDeleteGroup(currKey);
    // Testing removeGroupEntry operation from southbound
    testRemoveGroupFromSB(currKey);
}
#end_block

#method_before
public PolicyGroupIdentifier createPolicyGroupChain(String id, List<PolicyGroupParams> params) {
    // List<GroupChain> groupChains = new ArrayList<GroupChain>();
    List<GroupBucketIdentifier> bucketIds = new ArrayList<GroupBucketIdentifier>();
    for (PolicyGroupParams param : params) {
        List<PortNumber> ports = param.getPorts();
        if (ports == null) {
            log.warn("createPolicyGroupChain in sw {} with wrong " + "input parameters", deviceId);
            return null;
        }
        int labelStackSize = (param.getLabelStack() != null) ? param.getLabelStack().size() : 0;
        if (labelStackSize > 1) {
            for (PortNumber sp : ports) {
                PolicyGroupIdentifier previousGroupkey = null;
                DeviceId neighbor = portDeviceMap.get(sp);
                for (int idx = 0; idx < param.getLabelStack().size(); idx++) {
                    int label = param.getLabelStack().get(idx).intValue();
                    if (idx == (labelStackSize - 1)) {
                        /* Innermost Group */
                        GroupBucketIdentifier bucketId = new GroupBucketIdentifier();
                        bucketId.label = label;
                        bucketId.type = BucketOutputType.GROUP;
                        bucketId.outGroup = previousGroupkey;
                        bucketIds.add(bucketId);
                    } else if (idx == 0) {
                        /* Outermost Group */
                        List<GroupBucket> outBuckets = new ArrayList<GroupBucket>();
                        GroupBucketIdentifier bucketId = new GroupBucketIdentifier();
                        bucketId.label = label;
                        bucketId.type = BucketOutputType.PORT;
                        bucketId.outPort = sp;
                        PolicyGroupIdentifier key = new PolicyGroupIdentifier(id, Arrays.asList(param), Arrays.asList(bucketId));
                        TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
                        tBuilder.setOutput(sp).setEthDst(deviceConfig.getDeviceMac(neighbor)).setEthSrc(nodeMacAddr).pushMpls().setMpls(label);
                        outBuckets.add(DefaultGroupBucket.createSelectGroupBucket(tBuilder.build()));
                        GroupDescription desc = new DefaultGroupDescription(deviceId, GroupDescription.Type.INDIRECT, new GroupBuckets(outBuckets));
                        // TODO: BoS
                        previousGroupkey = key;
                        groupService.addGroup(desc);
                    } else {
                        /* Intermediate Groups */
                        GroupBucketIdentifier bucketId = new GroupBucketIdentifier();
                        bucketId.label = label;
                        bucketId.type = BucketOutputType.GROUP;
                        bucketId.outGroup = previousGroupkey;
                        PolicyGroupIdentifier key = new PolicyGroupIdentifier(id, Arrays.asList(param), Arrays.asList(bucketId));
                        /* Add to group dependency list */
                        dependentGroups.put(previousGroupkey, key);
                        previousGroupkey = key;
                    }
                }
            }
        } else {
            int label = -1;
            if (labelStackSize == 1) {
                label = param.getLabelStack().get(0).intValue();
            }
            for (PortNumber sp : ports) {
                GroupBucketIdentifier bucketId = new GroupBucketIdentifier();
                bucketId.label = label;
                bucketId.type = BucketOutputType.PORT;
                bucketId.outPort = sp;
                bucketIds.add(bucketId);
            }
        }
    }
    PolicyGroupIdentifier innermostGroupkey = null;
    if (!bucketIds.isEmpty()) {
        innermostGroupkey = new PolicyGroupIdentifier(id, params, bucketIds);
        /* Add to group dependency list */
        boolean fullyResolved = true;
        for (GroupBucketIdentifier bucketId : bucketIds) {
            if (bucketId.type == BucketOutputType.GROUP) {
                dependentGroups.put(bucketId.outGroup, innermostGroupkey);
                fullyResolved = false;
            }
        }
        if (fullyResolved) {
            List<GroupBucket> outBuckets = new ArrayList<GroupBucket>();
            for (GroupBucketIdentifier bucketId : bucketIds) {
                DeviceId neighbor = portDeviceMap.get(bucketId.outPort);
                TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
                tBuilder.setOutput(bucketId.outPort).setEthDst(deviceConfig.getDeviceMac(neighbor)).setEthSrc(nodeMacAddr).pushMpls().setMpls(bucketId.label);
                // TODO: BoS
                outBuckets.add(DefaultGroupBucket.createSelectGroupBucket(tBuilder.build()));
            }
            GroupDescription desc = new DefaultGroupDescription(deviceId, GroupDescription.Type.SELECT, new GroupBuckets(outBuckets));
            groupService.addGroup(desc);
        }
    }
    return innermostGroupkey;
}
#method_after
public PolicyGroupIdentifier createPolicyGroupChain(String id, List<PolicyGroupParams> params) {
    List<GroupBucketIdentifier> bucketIds = new ArrayList<GroupBucketIdentifier>();
    for (PolicyGroupParams param : params) {
        List<PortNumber> ports = param.getPorts();
        if (ports == null) {
            log.warn("createPolicyGroupChain in sw {} with wrong " + "input parameters", deviceId);
            return null;
        }
        int labelStackSize = (param.getLabelStack() != null) ? param.getLabelStack().size() : 0;
        if (labelStackSize > 1) {
            for (PortNumber sp : ports) {
                PolicyGroupIdentifier previousGroupkey = null;
                DeviceId neighbor = portDeviceMap.get(sp);
                for (int idx = 0; idx < param.getLabelStack().size(); idx++) {
                    int label = param.getLabelStack().get(idx).intValue();
                    if (idx == (labelStackSize - 1)) {
                        // Innermost Group
                        GroupBucketIdentifier bucketId = new GroupBucketIdentifier(label, previousGroupkey);
                        bucketIds.add(bucketId);
                    } else if (idx == 0) {
                        // Outermost Group
                        List<GroupBucket> outBuckets = new ArrayList<GroupBucket>();
                        GroupBucketIdentifier bucketId = new GroupBucketIdentifier(label, sp);
                        PolicyGroupIdentifier key = new PolicyGroupIdentifier(id, Arrays.asList(param), Arrays.asList(bucketId));
                        TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
                        tBuilder.setOutput(sp).setEthDst(deviceConfig.getDeviceMac(neighbor)).setEthSrc(nodeMacAddr).pushMpls().setMpls(label);
                        outBuckets.add(DefaultGroupBucket.createSelectGroupBucket(tBuilder.build()));
                        GroupDescription desc = new DefaultGroupDescription(deviceId, GroupDescription.Type.INDIRECT, new GroupBuckets(outBuckets));
                        // TODO: BoS
                        previousGroupkey = key;
                        groupService.addGroup(desc);
                    } else {
                        // Intermediate Groups
                        GroupBucketIdentifier bucketId = new GroupBucketIdentifier(label, previousGroupkey);
                        PolicyGroupIdentifier key = new PolicyGroupIdentifier(id, Arrays.asList(param), Arrays.asList(bucketId));
                        // Add to group dependency list
                        dependentGroups.put(previousGroupkey, key);
                        previousGroupkey = key;
                    }
                }
            }
        } else {
            int label = -1;
            if (labelStackSize == 1) {
                label = param.getLabelStack().get(0).intValue();
            }
            for (PortNumber sp : ports) {
                GroupBucketIdentifier bucketId = new GroupBucketIdentifier(label, sp);
                bucketIds.add(bucketId);
            }
        }
    }
    PolicyGroupIdentifier innermostGroupkey = null;
    if (!bucketIds.isEmpty()) {
        innermostGroupkey = new PolicyGroupIdentifier(id, params, bucketIds);
        // Add to group dependency list
        boolean fullyResolved = true;
        for (GroupBucketIdentifier bucketId : bucketIds) {
            if (bucketId.type() == BucketOutputType.GROUP) {
                dependentGroups.put(bucketId.outGroup(), innermostGroupkey);
                fullyResolved = false;
            }
        }
        if (fullyResolved) {
            List<GroupBucket> outBuckets = new ArrayList<GroupBucket>();
            for (GroupBucketIdentifier bucketId : bucketIds) {
                DeviceId neighbor = portDeviceMap.get(bucketId.outPort());
                TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
                tBuilder.setOutput(bucketId.outPort()).setEthDst(deviceConfig.getDeviceMac(neighbor)).setEthSrc(nodeMacAddr).pushMpls().setMpls(bucketId.label());
                // TODO: BoS
                outBuckets.add(DefaultGroupBucket.createSelectGroupBucket(tBuilder.build()));
            }
            GroupDescription desc = new DefaultGroupDescription(deviceId, GroupDescription.Type.SELECT, new GroupBuckets(outBuckets));
            groupService.addGroup(desc);
        }
    }
    return innermostGroupkey;
}
#end_block

#method_before
@Override
protected void handleGroupEvent(GroupEvent event) {
    if (event.type() == GroupEvent.Type.GROUP_ADDED) {
        if (dependentGroups.get(event.subject().appCookie()) != null) {
            PolicyGroupIdentifier dependentGroupKey = (PolicyGroupIdentifier) dependentGroups.get(event.subject().appCookie());
            dependentGroups.remove(event.subject().appCookie());
            boolean fullyResolved = true;
            for (GroupBucketIdentifier bucketId : dependentGroupKey.bucketIds) {
                if (bucketId.type != BucketOutputType.GROUP) {
                    continue;
                }
                if (dependentGroups.containsKey(bucketId.outGroup)) {
                    fullyResolved = false;
                    break;
                }
            }
            if (fullyResolved) {
                List<GroupBucket> outBuckets = new ArrayList<GroupBucket>();
                for (GroupBucketIdentifier bucketId : dependentGroupKey.bucketIds) {
                    TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
                    tBuilder.pushMpls().setMpls(bucketId.label);
                    // TODO: BoS
                    if (bucketId.type == BucketOutputType.PORT) {
                        DeviceId neighbor = portDeviceMap.get(bucketId.outPort);
                        tBuilder.setOutput(bucketId.outPort).setEthDst(deviceConfig.getDeviceMac(neighbor)).setEthSrc(nodeMacAddr);
                    } else {
                        if (groupService.getGroup(deviceId, bucketId.outGroup) == null) {
                            throw new IllegalStateException();
                        }
                        GroupId indirectGroupId = groupService.getGroup(deviceId, bucketId.outGroup).id();
                        tBuilder.group(indirectGroupId);
                    }
                    outBuckets.add(DefaultGroupBucket.createSelectGroupBucket(tBuilder.build()));
                }
                GroupDescription desc = new DefaultGroupDescription(deviceId, GroupDescription.Type.SELECT, new GroupBuckets(outBuckets));
                groupService.addGroup(desc);
            }
        }
    }
}
#method_after
@Override
protected void handleGroupEvent(GroupEvent event) {
    if (event.type() == GroupEvent.Type.GROUP_ADDED) {
        if (dependentGroups.get(event.subject().appCookie()) != null) {
            PolicyGroupIdentifier dependentGroupKey = (PolicyGroupIdentifier) dependentGroups.get(event.subject().appCookie());
            dependentGroups.remove(event.subject().appCookie());
            boolean fullyResolved = true;
            for (GroupBucketIdentifier bucketId : dependentGroupKey.bucketIds()) {
                if (bucketId.type() != BucketOutputType.GROUP) {
                    continue;
                }
                if (dependentGroups.containsKey(bucketId.outGroup())) {
                    fullyResolved = false;
                    break;
                }
            }
            if (fullyResolved) {
                List<GroupBucket> outBuckets = new ArrayList<GroupBucket>();
                for (GroupBucketIdentifier bucketId : dependentGroupKey.bucketIds()) {
                    TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
                    tBuilder.pushMpls().setMpls(bucketId.label());
                    // TODO: BoS
                    if (bucketId.type() == BucketOutputType.PORT) {
                        DeviceId neighbor = portDeviceMap.get(bucketId.outPort());
                        tBuilder.setOutput(bucketId.outPort()).setEthDst(deviceConfig.getDeviceMac(neighbor)).setEthSrc(nodeMacAddr);
                    } else {
                        if (groupService.getGroup(deviceId, bucketId.outGroup()) == null) {
                            throw new IllegalStateException();
                        }
                        GroupId indirectGroupId = groupService.getGroup(deviceId, bucketId.outGroup()).id();
                        tBuilder.group(indirectGroupId);
                    }
                    outBuckets.add(DefaultGroupBucket.createSelectGroupBucket(tBuilder.build()));
                }
                GroupDescription desc = new DefaultGroupDescription(deviceId, GroupDescription.Type.SELECT, new GroupBuckets(outBuckets));
                groupService.addGroup(desc);
            }
        }
    }
}
#end_block

#method_before
public GroupKey generatePolicyGroupKey(String id, List<PolicyGroupParams> params) {
    List<GroupBucketIdentifier> bucketIds = new ArrayList<GroupBucketIdentifier>();
    for (PolicyGroupParams param : params) {
        List<PortNumber> ports = param.getPorts();
        if (ports == null) {
            log.warn("generateGroupKey in sw {} with wrong " + "input parameters", deviceId);
            return null;
        }
        int labelStackSize = (param.getLabelStack() != null) ? param.getLabelStack().size() : 0;
        if (labelStackSize > 1) {
            for (PortNumber sp : ports) {
                PolicyGroupIdentifier previousGroupkey = null;
                for (int idx = 0; idx < param.getLabelStack().size(); idx++) {
                    int label = param.getLabelStack().get(idx).intValue();
                    if (idx == (labelStackSize - 1)) {
                        /* Innermost Group */
                        GroupBucketIdentifier bucketId = new GroupBucketIdentifier();
                        bucketId.label = label;
                        bucketId.type = BucketOutputType.GROUP;
                        bucketId.outGroup = previousGroupkey;
                        bucketIds.add(bucketId);
                    } else if (idx == 0) {
                        /* Outermost Group */
                        GroupBucketIdentifier bucketId = new GroupBucketIdentifier();
                        bucketId.label = label;
                        bucketId.type = BucketOutputType.PORT;
                        bucketId.outPort = sp;
                        PolicyGroupIdentifier key = new PolicyGroupIdentifier(id, Arrays.asList(param), Arrays.asList(bucketId));
                        previousGroupkey = key;
                    } else {
                        /* Intermediate Groups */
                        GroupBucketIdentifier bucketId = new GroupBucketIdentifier();
                        bucketId.label = label;
                        bucketId.type = BucketOutputType.GROUP;
                        bucketId.outGroup = previousGroupkey;
                        PolicyGroupIdentifier key = new PolicyGroupIdentifier(id, Arrays.asList(param), Arrays.asList(bucketId));
                        previousGroupkey = key;
                    }
                }
            }
        } else {
            int label = -1;
            if (labelStackSize == 1) {
                label = param.getLabelStack().get(0).intValue();
            }
            for (PortNumber sp : ports) {
                GroupBucketIdentifier bucketId = new GroupBucketIdentifier();
                bucketId.label = label;
                bucketId.type = BucketOutputType.PORT;
                bucketId.outPort = sp;
                bucketIds.add(bucketId);
            }
        }
    }
    PolicyGroupIdentifier innermostGroupkey = null;
    if (!bucketIds.isEmpty()) {
        innermostGroupkey = new PolicyGroupIdentifier(id, params, bucketIds);
    }
    return innermostGroupkey;
}
#method_after
public GroupKey generatePolicyGroupKey(String id, List<PolicyGroupParams> params) {
    List<GroupBucketIdentifier> bucketIds = new ArrayList<GroupBucketIdentifier>();
    for (PolicyGroupParams param : params) {
        List<PortNumber> ports = param.getPorts();
        if (ports == null) {
            log.warn("generateGroupKey in sw {} with wrong " + "input parameters", deviceId);
            return null;
        }
        int labelStackSize = (param.getLabelStack() != null) ? param.getLabelStack().size() : 0;
        if (labelStackSize > 1) {
            for (PortNumber sp : ports) {
                PolicyGroupIdentifier previousGroupkey = null;
                for (int idx = 0; idx < param.getLabelStack().size(); idx++) {
                    int label = param.getLabelStack().get(idx).intValue();
                    if (idx == (labelStackSize - 1)) {
                        // Innermost Group
                        GroupBucketIdentifier bucketId = new GroupBucketIdentifier(label, previousGroupkey);
                        bucketIds.add(bucketId);
                    } else if (idx == 0) {
                        // Outermost Group
                        GroupBucketIdentifier bucketId = new GroupBucketIdentifier(label, sp);
                        PolicyGroupIdentifier key = new PolicyGroupIdentifier(id, Arrays.asList(param), Arrays.asList(bucketId));
                        previousGroupkey = key;
                    } else {
                        // Intermediate Groups
                        GroupBucketIdentifier bucketId = new GroupBucketIdentifier(label, previousGroupkey);
                        PolicyGroupIdentifier key = new PolicyGroupIdentifier(id, Arrays.asList(param), Arrays.asList(bucketId));
                        previousGroupkey = key;
                    }
                }
            }
        } else {
            int label = -1;
            if (labelStackSize == 1) {
                label = param.getLabelStack().get(0).intValue();
            }
            for (PortNumber sp : ports) {
                GroupBucketIdentifier bucketId = new GroupBucketIdentifier(label, sp);
                bucketIds.add(bucketId);
            }
        }
    }
    PolicyGroupIdentifier innermostGroupkey = null;
    if (!bucketIds.isEmpty()) {
        innermostGroupkey = new PolicyGroupIdentifier(id, params, bucketIds);
    }
    return innermostGroupkey;
}
#end_block

#method_before
public void removeGroupChain(GroupKey key) {
    if (!(key instanceof PolicyGroupIdentifier)) {
        throw new IllegalArgumentException();
    }
    List<GroupKey> groupsToBeDeleted = new ArrayList<GroupKey>();
    groupsToBeDeleted.add(key);
    Iterator<GroupKey> it = groupsToBeDeleted.iterator();
    while (it.hasNext()) {
        PolicyGroupIdentifier innerMostGroupKey = (PolicyGroupIdentifier) it.next();
        for (GroupBucketIdentifier bucketId : innerMostGroupKey.bucketIds) {
            if (bucketId.type != BucketOutputType.GROUP) {
                groupsToBeDeleted.add(bucketId.outGroup);
            }
        }
        groupService.removeGroup(deviceId, innerMostGroupKey, appId);
        it.remove();
    }
}
#method_after
public void removeGroupChain(GroupKey key) {
    if (!(key instanceof PolicyGroupIdentifier)) {
        throw new IllegalArgumentException();
    }
    List<GroupKey> groupsToBeDeleted = new ArrayList<GroupKey>();
    groupsToBeDeleted.add(key);
    Iterator<GroupKey> it = groupsToBeDeleted.iterator();
    while (it.hasNext()) {
        PolicyGroupIdentifier innerMostGroupKey = (PolicyGroupIdentifier) it.next();
        for (GroupBucketIdentifier bucketId : innerMostGroupKey.bucketIds()) {
            if (bucketId.type() != BucketOutputType.GROUP) {
                groupsToBeDeleted.add(bucketId.outGroup());
            }
        }
        groupService.removeGroup(deviceId, innerMostGroupKey, appId);
        it.remove();
    }
}
#end_block

#method_before
@Test
public void testGroupService() {
    PortNumber[] ports1 = { PortNumber.portNumber(31), PortNumber.portNumber(32) };
    PortNumber[] ports2 = { PortNumber.portNumber(41), PortNumber.portNumber(42) };
    // Test Group creation before AUDIT process
    TestGroupKey key = new TestGroupKey("group1BeforeAudit");
    List<GroupBucket> buckets = new ArrayList<GroupBucket>();
    List<PortNumber> outPorts = new ArrayList<PortNumber>();
    outPorts.addAll(Arrays.asList(ports1));
    outPorts.addAll(Arrays.asList(ports2));
    for (PortNumber portNumber : outPorts) {
        TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
        tBuilder.setOutput(portNumber).setEthDst(MacAddress.valueOf("00:00:00:00:00:02")).setEthSrc(MacAddress.valueOf("00:00:00:00:00:01")).pushMpls().setMpls(106);
        buckets.add(DefaultGroupBucket.createSelectGroupBucket(tBuilder.build()));
    }
    GroupBuckets groupBuckets = new GroupBuckets(buckets);
    GroupDescription newGroupDesc = new DefaultGroupDescription(DID, Group.Type.SELECT, groupBuckets, key, appId);
    groupService.addGroup(newGroupDesc);
    internalProvider.validate(DID, null);
    assertEquals(null, groupService.getGroup(DID, key));
    assertEquals(0, Iterables.size(groupService.getGroups(DID, appId)));
    // Test initial group audit process
    GroupId gId1 = new DefaultGroupId(1);
    Group group1 = createSouthboundGroupEntry(gId1, Arrays.asList(ports1), 0);
    GroupId gId2 = new DefaultGroupId(2);
    // Non zero reference count will make the group manager to queue
    // the extraneous groups until reference count is zero.
    Group group2 = createSouthboundGroupEntry(gId2, Arrays.asList(ports2), 2);
    List<Group> groupEntries = Arrays.asList(group1, group2);
    providerService.pushGroupMetrics(DID, groupEntries);
    // First group metrics would trigger the device audit completion
    // post which all pending group requests are also executed.
    Group createdGroup = groupService.getGroup(DID, key);
    int createdGroupId = createdGroup.id().id();
    assertNotEquals(gId1.id(), createdGroupId);
    assertNotEquals(gId2.id(), createdGroupId);
    List<GroupOperation> expectedGroupOps = Arrays.asList(GroupOperation.createDeleteGroupOperation(gId1, Group.Type.SELECT), GroupOperation.createAddGroupOperation(createdGroup.id(), Group.Type.SELECT, groupBuckets));
    internalProvider.validate(DID, expectedGroupOps);
    group1 = createSouthboundGroupEntry(gId1, Arrays.asList(ports1), 0);
    group2 = createSouthboundGroupEntry(gId2, Arrays.asList(ports2), 0);
    groupEntries = Arrays.asList(group1, group2);
    providerService.pushGroupMetrics(DID, groupEntries);
    expectedGroupOps = Arrays.asList(GroupOperation.createDeleteGroupOperation(gId1, Group.Type.SELECT), GroupOperation.createDeleteGroupOperation(gId2, Group.Type.SELECT), GroupOperation.createAddGroupOperation(createdGroup.id(), Group.Type.SELECT, groupBuckets));
    internalProvider.validate(DID, expectedGroupOps);
    createdGroup = new DefaultGroup(createdGroup.id(), DID, Group.Type.SELECT, groupBuckets);
    groupEntries = Arrays.asList(createdGroup);
    providerService.pushGroupMetrics(DID, groupEntries);
    internalListener.validateEvent(Arrays.asList(GroupEvent.Type.GROUP_ADDED));
    // Test group add bucket operations
    TestGroupKey addKey = new TestGroupKey("group1AddBuckets");
    PortNumber[] addPorts = { PortNumber.portNumber(51), PortNumber.portNumber(52) };
    outPorts.clear();
    outPorts.addAll(Arrays.asList(addPorts));
    List<GroupBucket> addBuckets = new ArrayList<GroupBucket>();
    for (PortNumber portNumber : outPorts) {
        TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
        tBuilder.setOutput(portNumber).setEthDst(MacAddress.valueOf("00:00:00:00:00:02")).setEthSrc(MacAddress.valueOf("00:00:00:00:00:01")).pushMpls().setMpls(106);
        addBuckets.add(DefaultGroupBucket.createSelectGroupBucket(tBuilder.build()));
        buckets.add(DefaultGroupBucket.createSelectGroupBucket(tBuilder.build()));
    }
    GroupBuckets groupAddBuckets = new GroupBuckets(addBuckets);
    groupService.addBucketsToGroup(DID, key, groupAddBuckets, addKey, appId);
    GroupBuckets updatedBuckets = new GroupBuckets(buckets);
    expectedGroupOps = Arrays.asList(GroupOperation.createModifyGroupOperation(createdGroup.id(), Group.Type.SELECT, updatedBuckets));
    internalProvider.validate(DID, expectedGroupOps);
    Group existingGroup = groupService.getGroup(DID, addKey);
    groupEntries = Arrays.asList(existingGroup);
    providerService.pushGroupMetrics(DID, groupEntries);
    internalListener.validateEvent(Arrays.asList(GroupEvent.Type.GROUP_UPDATED));
    // Test group remove bucket operations
    TestGroupKey removeKey = new TestGroupKey("group1RemoveBuckets");
    PortNumber[] removePorts = { PortNumber.portNumber(31), PortNumber.portNumber(32) };
    outPorts.clear();
    outPorts.addAll(Arrays.asList(removePorts));
    List<GroupBucket> removeBuckets = new ArrayList<GroupBucket>();
    for (PortNumber portNumber : outPorts) {
        TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
        tBuilder.setOutput(portNumber).setEthDst(MacAddress.valueOf("00:00:00:00:00:02")).setEthSrc(MacAddress.valueOf("00:00:00:00:00:01")).pushMpls().setMpls(106);
        removeBuckets.add(DefaultGroupBucket.createSelectGroupBucket(tBuilder.build()));
        buckets.remove(DefaultGroupBucket.createSelectGroupBucket(tBuilder.build()));
    }
    GroupBuckets groupRemoveBuckets = new GroupBuckets(removeBuckets);
    groupService.removeBucketsFromGroup(DID, addKey, groupRemoveBuckets, removeKey, appId);
    updatedBuckets = new GroupBuckets(buckets);
    expectedGroupOps = Arrays.asList(GroupOperation.createModifyGroupOperation(createdGroup.id(), Group.Type.SELECT, updatedBuckets));
    internalProvider.validate(DID, expectedGroupOps);
    existingGroup = groupService.getGroup(DID, removeKey);
    groupEntries = Arrays.asList(existingGroup);
    providerService.pushGroupMetrics(DID, groupEntries);
    internalListener.validateEvent(Arrays.asList(GroupEvent.Type.GROUP_UPDATED));
    // Test group remove operations
    groupService.removeGroup(DID, removeKey, appId);
    expectedGroupOps = Arrays.asList(GroupOperation.createDeleteGroupOperation(createdGroup.id(), Group.Type.SELECT));
    internalProvider.validate(DID, expectedGroupOps);
    groupEntries = Collections.emptyList();
    providerService.pushGroupMetrics(DID, groupEntries);
    internalListener.validateEvent(Arrays.asList(GroupEvent.Type.GROUP_REMOVED));
}
#method_after
@Test
public void testGroupService() {
    // Test Group creation before AUDIT process
    testGroupCreationBeforeAudit();
    // Test initial group audit process
    testInitialAuditWithPendingGroupRequests();
    // Test audit with extraneous and missing groups
    testAuditWithExtraneousMissingGroups();
    // Test audit with confirmed groups
    testAuditWithConfirmedGroups();
    // Test group add bucket operations
    testAddBuckets();
    // Test group remove bucket operations
    testRemoveBuckets();
    // Test group remove operations
    testRemoveGroup();
}
#end_block

#method_before
private Group createSouthboundGroupEntry(GroupId gId, List<PortNumber> ports, long referenceCount) {
    List<PortNumber> outPorts = new ArrayList<PortNumber>();
    outPorts.addAll(ports);
    List<GroupBucket> buckets = new ArrayList<GroupBucket>();
    for (PortNumber portNumber : outPorts) {
        TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
        tBuilder.setOutput(portNumber).setEthDst(MacAddress.valueOf("00:00:00:00:00:02")).setEthSrc(MacAddress.valueOf("00:00:00:00:00:01")).pushMpls().setMpls(106);
        buckets.add(DefaultGroupBucket.createSelectGroupBucket(tBuilder.build()));
    }
    GroupBuckets groupBuckets = new GroupBuckets(buckets);
    StoredGroupEntry group = new DefaultGroup(gId, DID, Group.Type.SELECT, groupBuckets);
    group.setReferenceCount(referenceCount);
    return group;
}
#method_after
private Group createSouthboundGroupEntry(GroupId gId, List<PortNumber> ports, long referenceCount) {
    List<PortNumber> outPorts = new ArrayList<PortNumber>();
    outPorts.addAll(ports);
    List<GroupBucket> buckets = new ArrayList<GroupBucket>();
    for (PortNumber portNumber : outPorts) {
        TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
        tBuilder.setOutput(portNumber).setEthDst(MacAddress.valueOf("00:00:00:00:00:02")).setEthSrc(MacAddress.valueOf("00:00:00:00:00:01")).pushMpls().setMpls(MplsLabel.mplsLabel(106));
        buckets.add(DefaultGroupBucket.createSelectGroupBucket(tBuilder.build()));
    }
    GroupBuckets groupBuckets = new GroupBuckets(buckets);
    StoredGroupEntry group = new DefaultGroup(gId, DID, Group.Type.SELECT, groupBuckets);
    group.setReferenceCount(referenceCount);
    return group;
}
#end_block

#method_before
@Override
public void deviceInitialAuditCompleted(DeviceId deviceId, boolean completed) {
    synchronized (deviceAuditStatus) {
        if (completed) {
            log.info("deviceInitialAuditCompleted: AUDIT " + "completed for device {}", deviceId);
            deviceAuditStatus.put(deviceId, true);
            // Execute all pending group requests
            ConcurrentMap<GroupKey, StoredGroupEntry> pendingGroupRequests = getPendingGroupKeyTable(deviceId);
            for (Group group : pendingGroupRequests.values()) {
                GroupDescription tmp = new DefaultGroupDescription(group.deviceId(), group.type(), group.buckets(), group.appCookie(), group.appId());
                storeGroupDescriptionInternal(tmp);
            }
            getPendingGroupKeyTable(deviceId).clear();
        } else {
            if (deviceAuditStatus.get(deviceId)) {
                log.info("deviceInitialAuditCompleted: Clearing AUDIT " + "status for device {}", deviceId);
                deviceAuditStatus.put(deviceId, false);
            }
        }
    }
}
#method_after
@Override
public void deviceInitialAuditCompleted(DeviceId deviceId, boolean completed) {
    synchronized (deviceAuditStatus) {
        if (completed) {
            log.debug("deviceInitialAuditCompleted: AUDIT " + "completed for device {}", deviceId);
            deviceAuditStatus.put(deviceId, true);
            // Execute all pending group requests
            ConcurrentMap<GroupKey, StoredGroupEntry> pendingGroupRequests = getPendingGroupKeyTable(deviceId);
            for (Group group : pendingGroupRequests.values()) {
                GroupDescription tmp = new DefaultGroupDescription(group.deviceId(), group.type(), group.buckets(), group.appCookie(), group.appId());
                storeGroupDescriptionInternal(tmp);
            }
            getPendingGroupKeyTable(deviceId).clear();
        } else {
            if (deviceAuditStatus.get(deviceId)) {
                log.debug("deviceInitialAuditCompleted: Clearing AUDIT " + "status for device {}", deviceId);
                deviceAuditStatus.put(deviceId, false);
            }
        }
    }
}
#end_block

#method_before
@Override
public void createGroups() {
    log.debug("Creating default groups " + "for edge device {}", deviceId);
    Set<DeviceId> neighbors = devicePortMap.keySet();
    if (neighbors == null || neighbors.isEmpty()) {
        return;
    }
    /* Create all possible Neighbor sets from this router
         */
    Set<Set<DeviceId>> powerSet = getPowerSetOfNeighbors(neighbors);
    log.trace("createGroupsAtEdgeRouter: The size of neighbor powerset " + "for sw {} is {}", deviceId, powerSet.size());
    Set<NeighborSet> nsSet = new HashSet<NeighborSet>();
    for (Set<DeviceId> combo : powerSet) {
        if (combo.isEmpty()) {
            continue;
        }
        List<Integer> groupSegmentIds = getSegmentIdsTobePairedWithNeighborSet(combo);
        if (!groupSegmentIds.isEmpty()) {
            for (Integer sId : groupSegmentIds) {
                NeighborSet ns = new NeighborSet();
                ns.addDeviceIds(combo);
                ns.setEdgeLabel(sId);
                log.trace("createGroupsAtEdgeRouter: sw {} " + "combo {} sId {} ns {}", deviceId, combo, sId, ns);
                nsSet.add(ns);
            }
        }
    }
    log.trace("createGroupsAtEdgeRouter: The neighborset " + "with label for sw {} is {}", deviceId, nsSet);
    createGroupsFromNeighborsets(nsSet);
}
#method_after
@Override
public void createGroups() {
    log.debug("Creating default groups " + "for edge device {}", deviceId);
    Set<DeviceId> neighbors = devicePortMap.keySet();
    if (neighbors == null || neighbors.isEmpty()) {
        return;
    }
    // Create all possible Neighbor sets from this router
    Set<Set<DeviceId>> powerSet = getPowerSetOfNeighbors(neighbors);
    log.trace("createGroupsAtEdgeRouter: The size of neighbor powerset " + "for sw {} is {}", deviceId, powerSet.size());
    Set<NeighborSet> nsSet = new HashSet<NeighborSet>();
    for (Set<DeviceId> combo : powerSet) {
        if (combo.isEmpty()) {
            continue;
        }
        List<Integer> groupSegmentIds = getSegmentIdsTobePairedWithNeighborSet(combo);
        for (Integer sId : groupSegmentIds) {
            NeighborSet ns = new NeighborSet(combo, sId);
            log.trace("createGroupsAtEdgeRouter: sw {} " + "combo {} sId {} ns {}", deviceId, combo, sId, ns);
            nsSet.add(ns);
        }
    }
    log.trace("createGroupsAtEdgeRouter: The neighborset " + "with label for sw {} is {}", deviceId, nsSet);
    createGroupsFromNeighborsets(nsSet);
}
#end_block

#method_before
@Override
protected void newNeighbor(Link newNeighborLink) {
    log.debug("New Neighbor: Updating groups " + "for edge device {}", deviceId);
    /* Recompute neighbor power set */
    addNeighborAtPort(newNeighborLink.dst().deviceId(), newNeighborLink.src().port());
    /* Compute new neighbor sets due to the addition of new neighbor */
    Set<NeighborSet> nsSet = computeImpactedNeighborsetForPortEvent(newNeighborLink.dst().deviceId(), devicePortMap.keySet());
    createGroupsFromNeighborsets(nsSet);
}
#method_after
@Override
protected void newNeighbor(Link newNeighborLink) {
    log.debug("New Neighbor: Updating groups " + "for edge device {}", deviceId);
    // Recompute neighbor power set
    addNeighborAtPort(newNeighborLink.dst().deviceId(), newNeighborLink.src().port());
    // Compute new neighbor sets due to the addition of new neighbor
    Set<NeighborSet> nsSet = computeImpactedNeighborsetForPortEvent(newNeighborLink.dst().deviceId(), devicePortMap.keySet());
    createGroupsFromNeighborsets(nsSet);
}
#end_block

#method_before
@Override
protected void newPortToExistingNeighbor(Link newNeighborLink) {
    log.debug("New port to existing neighbor: Updating " + "groups for edge device {}", deviceId);
    addNeighborAtPort(newNeighborLink.dst().deviceId(), newNeighborLink.src().port());
    Set<NeighborSet> nsSet = computeImpactedNeighborsetForPortEvent(newNeighborLink.dst().deviceId(), devicePortMap.keySet());
    for (NeighborSet ns : nsSet) {
        /* Create the new bucket to be updated */
        TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
        tBuilder.setOutput(newNeighborLink.src().port()).setEthDst(deviceConfig.getDeviceMac(newNeighborLink.dst().deviceId())).setEthSrc(nodeMacAddr).pushMpls().setMpls(ns.getEdgeLabel());
        GroupBucket updatedBucket = DefaultGroupBucket.createSelectGroupBucket(tBuilder.build());
        GroupBuckets updatedBuckets = new GroupBuckets(Arrays.asList(updatedBucket));
        log.debug("newPortToExistingNeighborAtEdgeRouter: " + "groupService.addBucketsToGroup for neighborset{}", ns);
        groupService.addBucketsToGroup(deviceId, ns, updatedBuckets, ns, appId);
    }
}
#method_after
@Override
protected void newPortToExistingNeighbor(Link newNeighborLink) {
    log.debug("New port to existing neighbor: Updating " + "groups for edge device {}", deviceId);
    addNeighborAtPort(newNeighborLink.dst().deviceId(), newNeighborLink.src().port());
    Set<NeighborSet> nsSet = computeImpactedNeighborsetForPortEvent(newNeighborLink.dst().deviceId(), devicePortMap.keySet());
    for (NeighborSet ns : nsSet) {
        // Create the new bucket to be updated
        TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
        tBuilder.setOutput(newNeighborLink.src().port()).setEthDst(deviceConfig.getDeviceMac(newNeighborLink.dst().deviceId())).setEthSrc(nodeMacAddr).pushMpls().setMpls(ns.getEdgeLabel());
        GroupBucket updatedBucket = DefaultGroupBucket.createSelectGroupBucket(tBuilder.build());
        GroupBuckets updatedBuckets = new GroupBuckets(Arrays.asList(updatedBucket));
        log.debug("newPortToExistingNeighborAtEdgeRouter: " + "groupService.addBucketsToGroup for neighborset{}", ns);
        groupService.addBucketsToGroup(deviceId, ns, updatedBuckets, ns, appId);
    }
}
#end_block

#method_before
@Override
protected Set<NeighborSet> computeImpactedNeighborsetForPortEvent(DeviceId impactedNeighbor, Set<DeviceId> updatedNeighbors) {
    Set<Set<DeviceId>> powerSet = getPowerSetOfNeighbors(updatedNeighbors);
    Set<DeviceId> tmp = new HashSet<DeviceId>();
    tmp.addAll(updatedNeighbors);
    tmp.remove(impactedNeighbor);
    Set<Set<DeviceId>> tmpPowerSet = getPowerSetOfNeighbors(tmp);
    /* Compute the impacted neighbor sets */
    powerSet.removeAll(tmpPowerSet);
    Set<NeighborSet> nsSet = new HashSet<NeighborSet>();
    for (Set<DeviceId> combo : powerSet) {
        if (combo.isEmpty()) {
            continue;
        }
        List<Integer> groupSegmentIds = getSegmentIdsTobePairedWithNeighborSet(combo);
        if (!groupSegmentIds.isEmpty()) {
            for (Integer sId : groupSegmentIds) {
                NeighborSet ns = new NeighborSet();
                ns.addDeviceIds(combo);
                ns.setEdgeLabel(sId);
                log.trace("computeImpactedNeighborsetForPortEvent: sw {} " + "combo {} sId {} ns {}", deviceId, combo, sId, ns);
                nsSet.add(ns);
            }
        }
    }
    log.trace("computeImpactedNeighborsetForPortEvent: The neighborset " + "with label for sw {} is {}", deviceId, nsSet);
    return nsSet;
}
#method_after
@Override
protected Set<NeighborSet> computeImpactedNeighborsetForPortEvent(DeviceId impactedNeighbor, Set<DeviceId> updatedNeighbors) {
    Set<Set<DeviceId>> powerSet = getPowerSetOfNeighbors(updatedNeighbors);
    Set<DeviceId> tmp = new HashSet<DeviceId>();
    tmp.addAll(updatedNeighbors);
    tmp.remove(impactedNeighbor);
    Set<Set<DeviceId>> tmpPowerSet = getPowerSetOfNeighbors(tmp);
    // Compute the impacted neighbor sets
    powerSet.removeAll(tmpPowerSet);
    Set<NeighborSet> nsSet = new HashSet<NeighborSet>();
    for (Set<DeviceId> combo : powerSet) {
        if (combo.isEmpty()) {
            continue;
        }
        List<Integer> groupSegmentIds = getSegmentIdsTobePairedWithNeighborSet(combo);
        for (Integer sId : groupSegmentIds) {
            NeighborSet ns = new NeighborSet(combo, sId);
            log.trace("computeImpactedNeighborsetForPortEvent: sw {} " + "combo {} sId {} ns {}", deviceId, combo, sId, ns);
            nsSet.add(ns);
        }
    }
    log.trace("computeImpactedNeighborsetForPortEvent: The neighborset " + "with label for sw {} is {}", deviceId, nsSet);
    return nsSet;
}
#end_block

#method_before
public void createGroups() {
}
#method_after
/**
 * Creates the auto created groups for this device based on the
 * current snapshot of the topology.
 */
public void createGroups() {
}
#end_block

#method_before
public void linkUp(Link newLink) {
    if (newLink.type() != Link.Type.DIRECT) {
        log.warn("linkUp: unknown link type");
        return;
    }
    if (!newLink.src().deviceId().equals(deviceId)) {
        log.warn("linkUp: deviceId{} doesn't match with link src{}", deviceId, newLink.src().deviceId());
        return;
    }
    log.debug("Device {} linkUp at local port {} to neighbor {}", deviceId, newLink.src().port(), newLink.dst().deviceId());
    if (devicePortMap.get(newLink.dst().deviceId()) == null) {
        /* New Neighbor */
        newNeighbor(newLink);
    } else {
        /* Old Neighbor */
        newPortToExistingNeighbor(newLink);
    }
}
#method_after
public void linkUp(Link newLink) {
    if (newLink.type() != Link.Type.DIRECT) {
        log.warn("linkUp: unknown link type");
        return;
    }
    if (!newLink.src().deviceId().equals(deviceId)) {
        log.warn("linkUp: deviceId{} doesn't match with link src{}", deviceId, newLink.src().deviceId());
        return;
    }
    log.debug("Device {} linkUp at local port {} to neighbor {}", deviceId, newLink.src().port(), newLink.dst().deviceId());
    if (devicePortMap.get(newLink.dst().deviceId()) == null) {
        // New Neighbor
        newNeighbor(newLink);
    } else {
        // Old Neighbor
        newPortToExistingNeighbor(newLink);
    }
}
#end_block

#method_before
public void portDown(PortNumber port) {
    if (portDeviceMap.get(port) == null) {
        log.warn("portDown: unknown port");
        return;
    }
    log.debug("Device {} portDown {} to neighbor {}", deviceId, port, portDeviceMap.get(port));
    Set<NeighborSet> nsSet = computeImpactedNeighborsetForPortEvent(portDeviceMap.get(port), devicePortMap.keySet());
    for (NeighborSet ns : nsSet) {
        /* Create the bucket to be removed */
        TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
        tBuilder.setOutput(port).setEthDst(deviceConfig.getDeviceMac(portDeviceMap.get(port))).setEthSrc(nodeMacAddr).pushMpls().setMpls(ns.getEdgeLabel());
        GroupBucket removeBucket = DefaultGroupBucket.createSelectGroupBucket(tBuilder.build());
        GroupBuckets removeBuckets = new GroupBuckets(Arrays.asList(removeBucket));
        log.debug("portDown in device{}: " + "groupService.removeBucketsFromGroup " + "for neighborset{}", deviceId, ns);
        groupService.removeBucketsFromGroup(deviceId, ns, removeBuckets, ns, appId);
    }
    devicePortMap.get(portDeviceMap.get(port)).remove(port);
    portDeviceMap.remove(port);
}
#method_after
public void portDown(PortNumber port) {
    if (portDeviceMap.get(port) == null) {
        log.warn("portDown: unknown port");
        return;
    }
    log.debug("Device {} portDown {} to neighbor {}", deviceId, port, portDeviceMap.get(port));
    Set<NeighborSet> nsSet = computeImpactedNeighborsetForPortEvent(portDeviceMap.get(port), devicePortMap.keySet());
    for (NeighborSet ns : nsSet) {
        // Create the bucket to be removed
        TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
        tBuilder.setOutput(port).setEthDst(deviceConfig.getDeviceMac(portDeviceMap.get(port))).setEthSrc(nodeMacAddr).pushMpls().setMpls(ns.getEdgeLabel());
        GroupBucket removeBucket = DefaultGroupBucket.createSelectGroupBucket(tBuilder.build());
        GroupBuckets removeBuckets = new GroupBuckets(Arrays.asList(removeBucket));
        log.debug("portDown in device{}: " + "groupService.removeBucketsFromGroup " + "for neighborset{}", deviceId, ns);
        groupService.removeBucketsFromGroup(deviceId, ns, removeBuckets, ns, appId);
    }
    devicePortMap.get(portDeviceMap.get(port)).remove(port);
    portDeviceMap.remove(port);
}
#end_block

#method_before
protected void addNeighborAtPort(DeviceId neighborId, PortNumber portToNeighbor) {
    /* Update DeviceToPort database */
    log.debug("Device {} addNeighborAtPort: neighbor {} at port {}", deviceId, neighborId, portToNeighbor);
    if (devicePortMap.get(neighborId) != null) {
        devicePortMap.get(neighborId).add(portToNeighbor);
    } else {
        Set<PortNumber> ports = new HashSet<PortNumber>();
        ports.add(portToNeighbor);
        devicePortMap.put(neighborId, ports);
    }
    /* Update portToDevice database */
    if (portDeviceMap.get(portToNeighbor) == null) {
        portDeviceMap.put(portToNeighbor, neighborId);
    }
}
#method_after
protected void addNeighborAtPort(DeviceId neighborId, PortNumber portToNeighbor) {
    // Update DeviceToPort database
    log.debug("Device {} addNeighborAtPort: neighbor {} at port {}", deviceId, neighborId, portToNeighbor);
    if (devicePortMap.get(neighborId) != null) {
        devicePortMap.get(neighborId).add(portToNeighbor);
    } else {
        Set<PortNumber> ports = new HashSet<PortNumber>();
        ports.add(portToNeighbor);
        devicePortMap.put(neighborId, ports);
    }
    // Update portToDevice database
    if (portDeviceMap.get(portToNeighbor) == null) {
        portDeviceMap.put(portToNeighbor, neighborId);
    }
}
#end_block

#method_before
protected Set<Set<DeviceId>> getPowerSetOfNeighbors(Set<DeviceId> neighbors) {
    List<DeviceId> list = new ArrayList<DeviceId>(neighbors);
    Set<Set<DeviceId>> sets = new HashSet<Set<DeviceId>>();
    /* get the number of elements in the neighbors */
    int elements = list.size();
    /* the number of members of a power set is 2^n
         * including the empty set
         */
    int powerElements = (1 << elements);
    /* run a binary counter for the number of power elements
         * NOTE: Exclude empty set
         */
    for (long i = 1; i < powerElements; i++) {
        Set<DeviceId> neighborSubSet = new HashSet<DeviceId>();
        for (int j = 0; j < elements; j++) {
            if ((i >> j) % 2 == 1) {
                neighborSubSet.add(list.get(j));
            }
        }
        sets.add(neighborSubSet);
    }
    return sets;
}
#method_after
protected Set<Set<DeviceId>> getPowerSetOfNeighbors(Set<DeviceId> neighbors) {
    List<DeviceId> list = new ArrayList<DeviceId>(neighbors);
    Set<Set<DeviceId>> sets = new HashSet<Set<DeviceId>>();
    // get the number of elements in the neighbors
    int elements = list.size();
    // the number of members of a power set is 2^n
    // including the empty set
    int powerElements = (1 << elements);
    // NOTE: Exclude empty set
    for (long i = 1; i < powerElements; i++) {
        Set<DeviceId> neighborSubSet = new HashSet<DeviceId>();
        for (int j = 0; j < elements; j++) {
            if ((i >> j) % 2 == 1) {
                neighborSubSet.add(list.get(j));
            }
        }
        sets.add(neighborSubSet);
    }
    return sets;
}
#end_block

#method_before
protected List<Integer> getSegmentIdsTobePairedWithNeighborSet(Set<DeviceId> neighbors) {
    List<Integer> nsSegmentIds = new ArrayList<Integer>();
    /* Add one entry for "no label" (-1) to the list if
         * dpid list has not more than one node/neighbor as
         * there will never be a case a packet going to more than one
         * neighbor without a label at an edge router
         */
    if (neighbors.size() == 1) {
        nsSegmentIds.add(-1);
    }
    if (!allSegmentIds.isEmpty()) {
        /* Filter out SegmentIds matching with the
             * nodes in the combo
             */
        for (Integer sId : allSegmentIds) {
            if (sId.equals(nodeSegmentId)) {
                continue;
            }
            boolean filterOut = false;
            /* Check if the edge label being set is of
                 * any node in the Neighbor set
                 */
            for (DeviceId deviceId : neighbors) {
                if (isSegmentIdSameAsNodeSegmentId(deviceId, sId)) {
                    filterOut = true;
                    break;
                }
            }
            if (!filterOut) {
                nsSegmentIds.add(sId);
            }
        }
    }
    return nsSegmentIds;
}
#method_after
protected List<Integer> getSegmentIdsTobePairedWithNeighborSet(Set<DeviceId> neighbors) {
    List<Integer> nsSegmentIds = new ArrayList<Integer>();
    // neighbor without a label at an edge router
    if (neighbors.size() == 1) {
        nsSegmentIds.add(-1);
    }
    // nodes in the combo
    for (Integer sId : allSegmentIds) {
        if (sId.equals(nodeSegmentId)) {
            continue;
        }
        boolean filterOut = false;
        // any node in the Neighbor set
        for (DeviceId deviceId : neighbors) {
            if (isSegmentIdSameAsNodeSegmentId(deviceId, sId)) {
                filterOut = true;
                break;
            }
        }
        if (!filterOut) {
            nsSegmentIds.add(sId);
        }
    }
    return nsSegmentIds;
}
#end_block

#method_before
protected void createGroupsFromNeighborsets(Set<NeighborSet> nsSet) {
    for (NeighborSet ns : nsSet) {
        // updatePortNeighborSetMap(ns);
        /* Create the bucket array from the neighbor set */
        List<GroupBucket> buckets = new ArrayList<GroupBucket>();
        for (DeviceId d : ns.getDeviceIds()) {
            for (PortNumber sp : devicePortMap.get(d)) {
                TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
                tBuilder.setOutput(sp).setEthDst(deviceConfig.getDeviceMac(d)).setEthSrc(nodeMacAddr).pushMpls().setMpls(ns.getEdgeLabel());
                buckets.add(DefaultGroupBucket.createSelectGroupBucket(tBuilder.build()));
            }
        }
        GroupBuckets groupBuckets = new GroupBuckets(buckets);
        GroupDescription newGroupDesc = new DefaultGroupDescription(deviceId, Group.Type.SELECT, groupBuckets, ns, appId);
        log.debug("createGroupsFromNeighborsets: " + "groupService.addGroup for neighborset{}", ns);
        groupService.addGroup(newGroupDesc);
    }
}
#method_after
protected void createGroupsFromNeighborsets(Set<NeighborSet> nsSet) {
    for (NeighborSet ns : nsSet) {
        // Create the bucket array from the neighbor set
        List<GroupBucket> buckets = new ArrayList<GroupBucket>();
        for (DeviceId d : ns.getDeviceIds()) {
            for (PortNumber sp : devicePortMap.get(d)) {
                TrafficTreatment.Builder tBuilder = DefaultTrafficTreatment.builder();
                tBuilder.setOutput(sp).setEthDst(deviceConfig.getDeviceMac(d)).setEthSrc(nodeMacAddr).pushMpls().setMpls(ns.getEdgeLabel());
                buckets.add(DefaultGroupBucket.createSelectGroupBucket(tBuilder.build()));
            }
        }
        GroupBuckets groupBuckets = new GroupBuckets(buckets);
        GroupDescription newGroupDesc = new DefaultGroupDescription(deviceId, Group.Type.SELECT, groupBuckets, ns, appId);
        log.debug("createGroupsFromNeighborsets: " + "groupService.addGroup for neighborset{}", ns);
        groupService.addGroup(newGroupDesc);
    }
}
#end_block

#method_before
@Override
public Builder popMpls(short etherType) {
    return add(Instructions.popMpls(etherType));
}
#method_after
@Override
public Builder popMpls(Short etherType) {
    return add(Instructions.popMpls(etherType));
}
#end_block

#method_before
@Override
public Builder setMpls(Integer mplsLabel) {
    return add(Instructions.modMplsLabel(mplsLabel));
}
#method_after
@Override
public Builder setMpls(MplsLabel mplsLabel) {
    return add(Instructions.modMplsLabel(mplsLabel));
}
#end_block

#method_before
private Set<? extends ResourceAllocation> getResourceCapacity(ResourceType type, Link link) {
    if (type == ResourceType.BANDWIDTH) {
        return ImmutableSet.of(getBandwidthResourceCapacity(link));
    }
    if (type == ResourceType.LAMBDA) {
        return getLambdaResourceCapacity(link);
    }
    if (type == ResourceType.MPLS_LABEL) {
        return getMplsResourceCapacity(link);
    }
    return null;
}
#method_after
private Set<? extends ResourceAllocation> getResourceCapacity(ResourceType type, Link link) {
    if (type == ResourceType.BANDWIDTH) {
        return ImmutableSet.of(getBandwidthResourceCapacity(link));
    }
    if (type == ResourceType.LAMBDA) {
        return getLambdaResourceCapacity(link);
    }
    if (type == ResourceType.MPLS_LABEL) {
        return getMplsResourceCapacity();
    }
    return null;
}
#end_block

#method_before
private BandwidthResourceAllocation getBandwidthResourceCapacity(Link link) {
    // if Link annotation exist, use them
    // if all fails, use DEFAULT_BANDWIDTH
    Bandwidth bandwidth = null;
    String strBw = link.annotations().value(bandwidthAnnotation);
    if (strBw != null) {
        try {
            bandwidth = Bandwidth.valueOf(Double.parseDouble(strBw));
        } catch (NumberFormatException e) {
            // do nothings
            bandwidth = null;
        }
    }
    if (bandwidth == null) {
        // fall back, use fixed default
        bandwidth = DEFAULT_BANDWIDTH;
    }
    return new BandwidthResourceAllocation(bandwidth);
}
#method_after
private BandwidthResourceAllocation getBandwidthResourceCapacity(Link link) {
    // if Link annotation exist, use them
    // if all fails, use DEFAULT_BANDWIDTH
    Bandwidth bandwidth = null;
    String strBw = link.annotations().value(bandwidthAnnotation);
    if (strBw != null) {
        try {
            bandwidth = Bandwidth.mbps(Double.parseDouble(strBw));
        } catch (NumberFormatException e) {
            // do nothings
            bandwidth = null;
        }
    }
    if (bandwidth == null) {
        // fall back, use fixed default
        bandwidth = DEFAULT_BANDWIDTH;
    }
    return new BandwidthResourceAllocation(bandwidth);
}
#end_block

#method_before
private Set<MplsLabelResourceAllocation> getMplsResourceCapacity(Link link) {
    Set<MplsLabelResourceAllocation> allocations = new HashSet<>();
    for (int i = 2; i <= maxMplsLabel; i++) {
        allocations.add(new MplsLabelResourceAllocation(MplsLabel.valueOf(i)));
    }
    return allocations;
}
#method_after
private Set<MplsLabelResourceAllocation> getMplsResourceCapacity() {
    Set<MplsLabelResourceAllocation> allocations = new HashSet<>();
    // Ignoring reserved labels of 0 through 15
    for (int i = 16; i <= maxMplsLabel; i++) {
        allocations.add(new MplsLabelResourceAllocation(MplsLabel.valueOf(i)));
    }
    return allocations;
}
#end_block

#method_before
private Map<ResourceType, Set<? extends ResourceAllocation>> getFreeResourcesEx(Link link) {
    // returns capacity - allocated
    checkNotNull(link);
    Map<ResourceType, Set<? extends ResourceAllocation>> free = new HashMap<>();
    final Map<ResourceType, Set<? extends ResourceAllocation>> caps = getResourceCapacity(link);
    final Iterable<LinkResourceAllocations> allocations = getAllocations(link);
    for (ResourceType type : ResourceType.values()) {
        // there should be class/category of resources
        switch(type) {
            case BANDWIDTH:
                {
                    Set<? extends ResourceAllocation> bw = caps.get(ResourceType.BANDWIDTH);
                    if (bw == null || bw.isEmpty()) {
                        bw = Sets.newHashSet(new BandwidthResourceAllocation(EMPTY_BW));
                    }
                    BandwidthResourceAllocation cap = (BandwidthResourceAllocation) bw.iterator().next();
                    double freeBw = cap.bandwidth().toDouble();
                    // enumerate current allocations, subtracting resources
                    for (LinkResourceAllocations alloc : allocations) {
                        Set<ResourceAllocation> types = alloc.getResourceAllocation(link);
                        for (ResourceAllocation a : types) {
                            if (a instanceof BandwidthResourceAllocation) {
                                BandwidthResourceAllocation bwA = (BandwidthResourceAllocation) a;
                                freeBw -= bwA.bandwidth().toDouble();
                            }
                        }
                    }
                    free.put(type, Sets.newHashSet(new BandwidthResourceAllocation(Bandwidth.valueOf(freeBw))));
                    break;
                }
            case LAMBDA:
                {
                    Set<? extends ResourceAllocation> lmd = caps.get(type);
                    if (lmd == null || lmd.isEmpty()) {
                        // nothing left
                        break;
                    }
                    Set<LambdaResourceAllocation> freeL = new HashSet<>();
                    for (ResourceAllocation r : lmd) {
                        if (r instanceof LambdaResourceAllocation) {
                            freeL.add((LambdaResourceAllocation) r);
                        }
                    }
                    // enumerate current allocations, removing resources
                    for (LinkResourceAllocations alloc : allocations) {
                        Set<ResourceAllocation> types = alloc.getResourceAllocation(link);
                        for (ResourceAllocation a : types) {
                            if (a instanceof LambdaResourceAllocation) {
                                freeL.remove(a);
                            }
                        }
                    }
                    free.put(type, freeL);
                    break;
                }
            case MPLS_LABEL:
                {
                    Set<? extends ResourceAllocation> mpls = caps.get(type);
                    if (mpls == null || mpls.isEmpty()) {
                        // nothing left
                        break;
                    }
                    Set<MplsLabelResourceAllocation> freeLabel = new HashSet<>();
                    for (ResourceAllocation r : mpls) {
                        if (r instanceof MplsLabelResourceAllocation) {
                            freeLabel.add((MplsLabelResourceAllocation) r);
                        }
                    }
                    // enumerate current allocations, removing resources
                    for (LinkResourceAllocations alloc : allocations) {
                        Set<ResourceAllocation> types = alloc.getResourceAllocation(link);
                        for (ResourceAllocation a : types) {
                            if (a instanceof MplsLabelResourceAllocation) {
                                freeLabel.remove(a);
                            }
                        }
                    }
                    free.put(type, freeLabel);
                    break;
                }
            default:
                break;
        }
    }
    return free;
}
#method_after
private Map<ResourceType, Set<? extends ResourceAllocation>> getFreeResourcesEx(Link link) {
    // returns capacity - allocated
    checkNotNull(link);
    Map<ResourceType, Set<? extends ResourceAllocation>> free = new HashMap<>();
    final Map<ResourceType, Set<? extends ResourceAllocation>> caps = getResourceCapacity(link);
    final Iterable<LinkResourceAllocations> allocations = getAllocations(link);
    for (ResourceType type : ResourceType.values()) {
        // there should be class/category of resources
        switch(type) {
            case BANDWIDTH:
                {
                    Set<? extends ResourceAllocation> bw = caps.get(ResourceType.BANDWIDTH);
                    if (bw == null || bw.isEmpty()) {
                        bw = Sets.newHashSet(new BandwidthResourceAllocation(EMPTY_BW));
                    }
                    BandwidthResourceAllocation cap = (BandwidthResourceAllocation) bw.iterator().next();
                    double freeBw = cap.bandwidth().toDouble();
                    // enumerate current allocations, subtracting resources
                    for (LinkResourceAllocations alloc : allocations) {
                        Set<ResourceAllocation> types = alloc.getResourceAllocation(link);
                        for (ResourceAllocation a : types) {
                            if (a instanceof BandwidthResourceAllocation) {
                                BandwidthResourceAllocation bwA = (BandwidthResourceAllocation) a;
                                freeBw -= bwA.bandwidth().toDouble();
                            }
                        }
                    }
                    free.put(type, Sets.newHashSet(new BandwidthResourceAllocation(Bandwidth.bps(freeBw))));
                    break;
                }
            case LAMBDA:
                {
                    Set<? extends ResourceAllocation> lmd = caps.get(type);
                    if (lmd == null || lmd.isEmpty()) {
                        // nothing left
                        break;
                    }
                    Set<LambdaResourceAllocation> freeL = new HashSet<>();
                    for (ResourceAllocation r : lmd) {
                        if (r instanceof LambdaResourceAllocation) {
                            freeL.add((LambdaResourceAllocation) r);
                        }
                    }
                    // enumerate current allocations, removing resources
                    for (LinkResourceAllocations alloc : allocations) {
                        Set<ResourceAllocation> types = alloc.getResourceAllocation(link);
                        for (ResourceAllocation a : types) {
                            if (a instanceof LambdaResourceAllocation) {
                                freeL.remove(a);
                            }
                        }
                    }
                    free.put(type, freeL);
                    break;
                }
            case MPLS_LABEL:
                {
                    Set<? extends ResourceAllocation> mpls = caps.get(type);
                    if (mpls == null || mpls.isEmpty()) {
                        // nothing left
                        break;
                    }
                    Set<MplsLabelResourceAllocation> freeLabel = new HashSet<>();
                    for (ResourceAllocation r : mpls) {
                        if (r instanceof MplsLabelResourceAllocation) {
                            freeLabel.add((MplsLabelResourceAllocation) r);
                        }
                    }
                    // enumerate current allocations, removing resources
                    for (LinkResourceAllocations alloc : allocations) {
                        Set<ResourceAllocation> types = alloc.getResourceAllocation(link);
                        for (ResourceAllocation a : types) {
                            if (a instanceof MplsLabelResourceAllocation) {
                                freeLabel.remove(a);
                            }
                        }
                    }
                    free.put(type, freeLabel);
                    break;
                }
            default:
                break;
        }
    }
    return free;
}
#end_block

#method_before
private Builder allocateLinkResource(Builder builder, Link link, LinkResourceAllocations allocations) {
    // requested resources
    Set<ResourceAllocation> reqs = allocations.getResourceAllocation(link);
    Map<ResourceType, Set<? extends ResourceAllocation>> available = getFreeResourcesEx(link);
    for (ResourceAllocation req : reqs) {
        Set<? extends ResourceAllocation> avail = available.get(req.type());
        if (req instanceof BandwidthResourceAllocation) {
            // check if allocation should be accepted
            if (avail.isEmpty()) {
                checkState(!avail.isEmpty(), "There's no Bandwidth resource on %s?", link);
            }
            BandwidthResourceAllocation bw = (BandwidthResourceAllocation) avail.iterator().next();
            double bwLeft = bw.bandwidth().toDouble();
            bwLeft -= ((BandwidthResourceAllocation) req).bandwidth().toDouble();
            BandwidthResourceAllocation bwReq = ((BandwidthResourceAllocation) req);
            if (bwLeft < 0) {
                throw new ResourceAllocationException(PositionalParameterStringFormatter.format("Unable to allocate bandwidth for link {} " + " requested amount is {} current allocation is {}", link, bwReq.bandwidth().toDouble(), bw));
            }
        } else if (req instanceof LambdaResourceAllocation) {
            final LambdaResourceAllocation lambdaAllocation = (LambdaResourceAllocation) req;
            // check if allocation should be accepted
            if (!avail.contains(req)) {
                // requested lambda was not available
                throw new ResourceAllocationException(PositionalParameterStringFormatter.format("Unable to allocate lambda for link {} lamdba is {}", link, lambdaAllocation.lambda().toInt()));
            }
        } else if (req instanceof MplsLabelResourceAllocation) {
            final MplsLabelResourceAllocation mplsAllocation = (MplsLabelResourceAllocation) req;
            // check if allocation should be accepted
            if (!avail.contains(req)) {
                // requested mpls label was not available
                throw new ResourceAllocationException(PositionalParameterStringFormatter.format("Unable to allocate lambda for " + "link {} lamdba is {}", link, mplsAllocation.mplsLabel().toInt()));
            }
        }
    }
    // all requests allocatable => add allocation
    final List<LinkResourceAllocations> before = getAllocations(link);
    List<LinkResourceAllocations> after = new ArrayList<>(before.size());
    after.addAll(before);
    after.add(allocations);
    replaceLinkAllocations(builder, LinkKey.linkKey(link), before, after);
    return builder;
}
#method_after
private Builder allocateLinkResource(Builder builder, Link link, LinkResourceAllocations allocations) {
    // requested resources
    Set<ResourceAllocation> reqs = allocations.getResourceAllocation(link);
    Map<ResourceType, Set<? extends ResourceAllocation>> available = getFreeResourcesEx(link);
    for (ResourceAllocation req : reqs) {
        Set<? extends ResourceAllocation> avail = available.get(req.type());
        if (req instanceof BandwidthResourceAllocation) {
            // check if allocation should be accepted
            if (avail.isEmpty()) {
                checkState(!avail.isEmpty(), "There's no Bandwidth resource on %s?", link);
            }
            BandwidthResourceAllocation bw = (BandwidthResourceAllocation) avail.iterator().next();
            double bwLeft = bw.bandwidth().toDouble();
            bwLeft -= ((BandwidthResourceAllocation) req).bandwidth().toDouble();
            BandwidthResourceAllocation bwReq = ((BandwidthResourceAllocation) req);
            if (bwLeft < 0) {
                throw new ResourceAllocationException(PositionalParameterStringFormatter.format("Unable to allocate bandwidth for link {} " + " requested amount is {} current allocation is {}", link, bwReq.bandwidth().toDouble(), bw));
            }
        } else if (req instanceof LambdaResourceAllocation) {
            final LambdaResourceAllocation lambdaAllocation = (LambdaResourceAllocation) req;
            // check if allocation should be accepted
            if (!avail.contains(req)) {
                // requested lambda was not available
                throw new ResourceAllocationException(PositionalParameterStringFormatter.format("Unable to allocate lambda for link {} lambda is {}", link, lambdaAllocation.lambda().toInt()));
            }
        } else if (req instanceof MplsLabelResourceAllocation) {
            final MplsLabelResourceAllocation mplsAllocation = (MplsLabelResourceAllocation) req;
            // check if allocation should be accepted
            if (!avail.contains(req)) {
                // requested mpls label was not available
                throw new ResourceAllocationException(PositionalParameterStringFormatter.format("Unable to allocate MPLS label for " + "link {} MPLS label is {}", link, mplsAllocation.mplsLabel().toString()));
            }
        }
    }
    // all requests allocatable => add allocation
    final List<LinkResourceAllocations> before = getAllocations(link);
    List<LinkResourceAllocations> after = new ArrayList<>(before.size());
    after.addAll(before);
    after.add(allocations);
    replaceLinkAllocations(builder, LinkKey.linkKey(link), before, after);
    return builder;
}
#end_block

#method_before
private List<FlowRuleBatchOperation> generateRules(MplsPathIntent intent, LinkResourceAllocations allocations, FlowRuleOperation operation) {
    Iterator<Link> links = intent.path().links().iterator();
    Link srcLink = links.next();
    ConnectPoint prev = srcLink.dst();
    Integer prevLabel;
    List<FlowRuleBatchEntry> rules = Lists.newLinkedList();
    TrafficSelector.Builder ingressSelector = DefaultTrafficSelector.builder(intent.selector());
    TrafficTreatment.Builder treat = DefaultTrafficTreatment.builder();
    ingressSelector.matchInport(prev.port());
    Link link = links.next();
    if (intent.ingressLabel().isPresent()) {
        ingressSelector.matchEthType(Ethernet.MPLS_UNICAST).matchMplsLabel(intent.ingressLabel().get());
    }
    MplsLabel mpls = null;
    // Get the new MPLS label
    for (ResourceAllocation allocation : allocations.getResourceAllocation(link)) {
        if (allocation.type() == ResourceType.MPLS_LABEL) {
            mpls = ((MplsLabelResourceAllocation) allocation).mplsLabel();
            break;
        }
    }
    if (mpls == null) {
        log.info("MPLS label was not assigned successfully");
        return null;
    }
    prevLabel = mpls.toInt();
    treat.pushMpls().setMpls(prevLabel).setOutput(link.src().port());
    rules.add(flowRuleBatchEntry(intent, link.src().deviceId(), ingressSelector, treat, operation));
    prev = link.dst();
    while (links.hasNext()) {
        // Ignore the ingress Traffic Selector and use only the MPLS label
        // assigned in the previous link
        TrafficSelector.Builder selector = DefaultTrafficSelector.builder();
        selector.matchInport(prev.port()).matchEthType(Ethernet.MPLS_UNICAST).matchMplsLabel(prevLabel);
        link = links.next();
        treat = DefaultTrafficTreatment.builder();
        if (links.hasNext()) {
            // Get the new MPLS label
            mpls = null;
            for (ResourceAllocation allocation : allocations.getResourceAllocation(link)) {
                if (allocation.type() == ResourceType.MPLS_LABEL) {
                    mpls = ((MplsLabelResourceAllocation) allocation).mplsLabel();
                    break;
                }
            }
            if (mpls == null) {
                log.info("MPLS label was not assigned successfully");
                return null;
            }
            // different
            if (prevLabel != mpls.toInt()) {
                prevLabel = mpls.toInt();
                treat.setMpls(prevLabel);
            }
        } else {
            // egress point: either set the egress MPLS label or pop the
            // MPLS label based on the intent annotations
            // apply the intent's treatments
            treat = DefaultTrafficTreatment.builder(intent.treatment());
            if (intent.egressLabel().isPresent()) {
                treat.setMpls(intent.egressLabel().get());
            } else {
                // if the ingress ethertype is defined, the egress traffic
                // will be
                // use that value, otherwise the IPv4 ethertype is used.
                Criterion c = intent.selector().getCriterion(Type.ETH_TYPE);
                if (c != null && c instanceof EthTypeCriterion) {
                    EthTypeCriterion ethertype = (EthTypeCriterion) c;
                    treat.popMpls(ethertype.ethType());
                } else {
                    treat.popMpls(Ethernet.TYPE_IPV4);
                }
            }
        }
        treat.setOutput(link.src().port());
        rules.add(flowRuleBatchEntry(intent, link.src().deviceId(), selector, treat, operation));
        prev = link.dst();
    }
    return Lists.newArrayList(new FlowRuleBatchOperation(rules));
}
#method_after
private List<FlowRuleBatchOperation> generateRules(MplsPathIntent intent, LinkResourceAllocations allocations, FlowRuleOperation operation) {
    Iterator<Link> links = intent.path().links().iterator();
    Link srcLink = links.next();
    ConnectPoint prev = srcLink.dst();
    Link link = links.next();
    // List of flow rules to be installed
    List<FlowRuleBatchEntry> rules = Lists.newLinkedList();
    // Ingress traffic
    // Get the new MPLS label
    MplsLabel mpls = getMplsLabel(allocations, link);
    checkNotNull(mpls);
    MplsLabel prevLabel = mpls;
    rules.add(ingressFlow(prev.port(), link, intent, mpls, operation));
    prev = link.dst();
    while (links.hasNext()) {
        link = links.next();
        if (links.hasNext()) {
            // Transit traffic
            // Get the new MPLS label
            mpls = getMplsLabel(allocations, link);
            checkNotNull(mpls);
            rules.add(transitFlow(prev.port(), link, intent, prevLabel, mpls, operation));
            prevLabel = mpls;
        } else {
            // Egress traffic
            rules.add(egressFlow(prev.port(), link, intent, prevLabel, operation));
        }
        prev = link.dst();
    }
    return Lists.newArrayList(new FlowRuleBatchOperation(rules, null, 0));
}
#end_block

#method_before
protected FlowRuleBatchEntry flowRuleBatchEntry(MplsPathIntent intent, DeviceId deviceId, TrafficSelector.Builder selector, TrafficTreatment.Builder treat, FlowRuleOperation operation) {
    FlowRule rule = new DefaultFlowRule(deviceId, selector.build(), treat.build(), // FIXME 123
    123, appId, new DefaultGroupId((short) (intent.id().fingerprint() & 0xffff)), 0, true);
    return new FlowRuleBatchEntry(operation, rule, intent.id().fingerprint());
}
#method_after
protected FlowRuleBatchEntry flowRuleBatchEntry(MplsPathIntent intent, DeviceId deviceId, TrafficSelector selector, TrafficTreatment treat, FlowRuleOperation operation) {
    FlowRule rule = new DefaultFlowRule(deviceId, selector, treat, // FIXME 123
    123, appId, 0, true);
    return new FlowRuleBatchEntry(operation, rule, intent.id().fingerprint());
}
#end_block

#method_before
private MplsIntent makeIntent(String ingressIdString, Optional<Integer> ingressLabel, String egressIdString, Optional<Integer> egressLabel) {
    return new MplsIntent(APPID, selector, treatment, connectPoint(ingressIdString, 1), ingressLabel, connectPoint(egressIdString, 1), egressLabel);
}
#method_after
private MplsIntent makeIntent(String ingressIdString, Optional<MplsLabel> ingressLabel, String egressIdString, Optional<MplsLabel> egressLabel) {
    return new MplsIntent(APPID, selector, treatment, connectPoint(ingressIdString, 1), ingressLabel, connectPoint(egressIdString, 1), egressLabel);
}
#end_block

#method_before
@Test
public void testForwardPathCompilation() {
    Optional<Integer> ingressLabel = Optional.ofNullable(10);
    Optional<Integer> egressLabel = Optional.ofNullable(20);
    MplsIntent intent = makeIntent("d1", ingressLabel, "d8", egressLabel);
    assertThat(intent, is(notNullValue()));
    String[] hops = { "d1", "d2", "d3", "d4", "d5", "d6", "d7", "d8" };
    MplsIntentCompiler compiler = makeCompiler(hops);
    assertThat(compiler, is(notNullValue()));
    List<Intent> result = compiler.compile(intent, null, null);
    assertThat(result, is(Matchers.notNullValue()));
    assertThat(result, hasSize(1));
    Intent forwardResultIntent = result.get(0);
    assertThat(forwardResultIntent instanceof MplsPathIntent, is(true));
    if (forwardResultIntent instanceof MplsIntent) {
        MplsPathIntent forwardPathIntent = (MplsPathIntent) forwardResultIntent;
        // 7 links for the hops, plus one default lnk on ingress and egress
        assertThat(forwardPathIntent.path().links(), hasSize(hops.length + 1));
        assertThat(forwardPathIntent.path().links(), linksHasPath("d1", "d2"));
        assertThat(forwardPathIntent.path().links(), linksHasPath("d2", "d3"));
        assertThat(forwardPathIntent.path().links(), linksHasPath("d3", "d4"));
        assertThat(forwardPathIntent.path().links(), linksHasPath("d4", "d5"));
        assertThat(forwardPathIntent.path().links(), linksHasPath("d5", "d6"));
        assertThat(forwardPathIntent.path().links(), linksHasPath("d6", "d7"));
        assertThat(forwardPathIntent.path().links(), linksHasPath("d7", "d8"));
        assertEquals(forwardPathIntent.egressLabel(), egressLabel);
        assertEquals(forwardPathIntent.ingressLabel(), ingressLabel);
    }
}
#method_after
@Test
public void testForwardPathCompilation() {
    Optional<MplsLabel> ingressLabel = Optional.ofNullable(MplsLabel.mplsLabel(10));
    Optional<MplsLabel> egressLabel = Optional.ofNullable(MplsLabel.mplsLabel(20));
    MplsIntent intent = makeIntent("d1", ingressLabel, "d8", egressLabel);
    assertThat(intent, is(notNullValue()));
    String[] hops = { "d1", "d2", "d3", "d4", "d5", "d6", "d7", "d8" };
    MplsIntentCompiler compiler = makeCompiler(hops);
    assertThat(compiler, is(notNullValue()));
    List<Intent> result = compiler.compile(intent, null, null);
    assertThat(result, is(Matchers.notNullValue()));
    assertThat(result, hasSize(1));
    Intent forwardResultIntent = result.get(0);
    assertThat(forwardResultIntent instanceof MplsPathIntent, is(true));
    if (forwardResultIntent instanceof MplsIntent) {
        MplsPathIntent forwardPathIntent = (MplsPathIntent) forwardResultIntent;
        // 7 links for the hops, plus one default lnk on ingress and egress
        assertThat(forwardPathIntent.path().links(), hasSize(hops.length + 1));
        assertThat(forwardPathIntent.path().links(), linksHasPath("d1", "d2"));
        assertThat(forwardPathIntent.path().links(), linksHasPath("d2", "d3"));
        assertThat(forwardPathIntent.path().links(), linksHasPath("d3", "d4"));
        assertThat(forwardPathIntent.path().links(), linksHasPath("d4", "d5"));
        assertThat(forwardPathIntent.path().links(), linksHasPath("d5", "d6"));
        assertThat(forwardPathIntent.path().links(), linksHasPath("d6", "d7"));
        assertThat(forwardPathIntent.path().links(), linksHasPath("d7", "d8"));
        assertEquals(forwardPathIntent.egressLabel(), egressLabel);
        assertEquals(forwardPathIntent.ingressLabel(), ingressLabel);
    }
}
#end_block

#method_before
@Test
public void testReversePathCompilation() {
    Optional<Integer> ingressLabel = Optional.ofNullable(10);
    Optional<Integer> egressLabel = Optional.ofNullable(20);
    MplsIntent intent = makeIntent("d8", ingressLabel, "d1", egressLabel);
    assertThat(intent, is(notNullValue()));
    String[] hops = { "d1", "d2", "d3", "d4", "d5", "d6", "d7", "d8" };
    MplsIntentCompiler compiler = makeCompiler(hops);
    assertThat(compiler, is(notNullValue()));
    List<Intent> result = compiler.compile(intent, null, null);
    assertThat(result, is(Matchers.notNullValue()));
    assertThat(result, hasSize(1));
    Intent reverseResultIntent = result.get(0);
    assertThat(reverseResultIntent instanceof MplsPathIntent, is(true));
    if (reverseResultIntent instanceof MplsIntent) {
        MplsPathIntent reversePathIntent = (MplsPathIntent) reverseResultIntent;
        assertThat(reversePathIntent.path().links(), hasSize(hops.length + 1));
        assertThat(reversePathIntent.path().links(), linksHasPath("d2", "d1"));
        assertThat(reversePathIntent.path().links(), linksHasPath("d3", "d2"));
        assertThat(reversePathIntent.path().links(), linksHasPath("d4", "d3"));
        assertThat(reversePathIntent.path().links(), linksHasPath("d5", "d4"));
        assertThat(reversePathIntent.path().links(), linksHasPath("d6", "d5"));
        assertThat(reversePathIntent.path().links(), linksHasPath("d7", "d6"));
        assertThat(reversePathIntent.path().links(), linksHasPath("d8", "d7"));
        assertEquals(reversePathIntent.egressLabel(), egressLabel);
        assertEquals(reversePathIntent.ingressLabel(), ingressLabel);
    }
}
#method_after
@Test
public void testReversePathCompilation() {
    Optional<MplsLabel> ingressLabel = Optional.ofNullable(MplsLabel.mplsLabel(10));
    Optional<MplsLabel> egressLabel = Optional.ofNullable(MplsLabel.mplsLabel(20));
    MplsIntent intent = makeIntent("d8", ingressLabel, "d1", egressLabel);
    assertThat(intent, is(notNullValue()));
    String[] hops = { "d1", "d2", "d3", "d4", "d5", "d6", "d7", "d8" };
    MplsIntentCompiler compiler = makeCompiler(hops);
    assertThat(compiler, is(notNullValue()));
    List<Intent> result = compiler.compile(intent, null, null);
    assertThat(result, is(Matchers.notNullValue()));
    assertThat(result, hasSize(1));
    Intent reverseResultIntent = result.get(0);
    assertThat(reverseResultIntent instanceof MplsPathIntent, is(true));
    if (reverseResultIntent instanceof MplsIntent) {
        MplsPathIntent reversePathIntent = (MplsPathIntent) reverseResultIntent;
        assertThat(reversePathIntent.path().links(), hasSize(hops.length + 1));
        assertThat(reversePathIntent.path().links(), linksHasPath("d2", "d1"));
        assertThat(reversePathIntent.path().links(), linksHasPath("d3", "d2"));
        assertThat(reversePathIntent.path().links(), linksHasPath("d4", "d3"));
        assertThat(reversePathIntent.path().links(), linksHasPath("d5", "d4"));
        assertThat(reversePathIntent.path().links(), linksHasPath("d6", "d5"));
        assertThat(reversePathIntent.path().links(), linksHasPath("d7", "d6"));
        assertThat(reversePathIntent.path().links(), linksHasPath("d8", "d7"));
        assertEquals(reversePathIntent.egressLabel(), egressLabel);
        assertEquals(reversePathIntent.ingressLabel(), ingressLabel);
    }
}
#end_block

#method_before
@Test
public void testSameSwitchDifferentPortsIntentCompilation() {
    ConnectPoint src = new ConnectPoint(deviceId("1"), portNumber(1));
    ConnectPoint dst = new ConnectPoint(deviceId("1"), portNumber(2));
    MplsIntent intent = new MplsIntent(APP_ID, selector, treatment, src, null, dst, null);
    String[] hops = { "1" };
    MplsIntentCompiler sut = makeCompiler(hops);
    List<Intent> compiled = sut.compile(intent, null, null);
    assertThat(compiled, hasSize(1));
    assertThat(compiled.get(0), is(instanceOf(MplsPathIntent.class)));
    Path path = ((MplsPathIntent) compiled.get(0)).path();
    assertThat(path.links(), hasSize(2));
    Link firstLink = path.links().get(0);
    assertThat(firstLink, is(createEdgeLink(src, true)));
    Link secondLink = path.links().get(1);
    assertThat(secondLink, is(createEdgeLink(dst, false)));
}
#method_after
@Test
public void testSameSwitchDifferentPortsIntentCompilation() {
    ConnectPoint src = new ConnectPoint(deviceId("1"), portNumber(1));
    ConnectPoint dst = new ConnectPoint(deviceId("1"), portNumber(2));
    MplsIntent intent = new MplsIntent(APP_ID, selector, treatment, src, Optional.empty(), dst, Optional.empty());
    String[] hops = { "1" };
    MplsIntentCompiler sut = makeCompiler(hops);
    List<Intent> compiled = sut.compile(intent, null, null);
    assertThat(compiled, hasSize(1));
    assertThat(compiled.get(0), is(instanceOf(MplsPathIntent.class)));
    Path path = ((MplsPathIntent) compiled.get(0)).path();
    assertThat(path.links(), hasSize(2));
    Link firstLink = path.links().get(0);
    assertThat(firstLink, is(createEdgeLink(src, true)));
    Link secondLink = path.links().get(1);
    assertThat(secondLink, is(createEdgeLink(dst, false)));
}
#end_block

#method_before
public Optional<Integer> ingressLabel() {
    return ingressLabel;
}
#method_after
public Optional<MplsLabel> ingressLabel() {
    return ingressLabel;
}
#end_block

#method_before
public Optional<Integer> egressLabel() {
    return egressLabel;
}
#method_after
public Optional<MplsLabel> egressLabel() {
    return egressLabel;
}
#end_block

#method_before
@Override
protected void execute() {
    IntentService service = get(IntentService.class);
    DeviceId ingressDeviceId = deviceId(getDeviceId(ingressDeviceString));
    PortNumber ingressPortNumber = portNumber(getPortNumber(ingressDeviceString));
    ConnectPoint ingress = new ConnectPoint(ingressDeviceId, ingressPortNumber);
    Optional<Integer> ingressLabel = Optional.ofNullable(parseInt(ingressLabelString));
    DeviceId egressDeviceId = deviceId(getDeviceId(egressDeviceString));
    PortNumber egressPortNumber = portNumber(getPortNumber(egressDeviceString));
    ConnectPoint egress = new ConnectPoint(egressDeviceId, egressPortNumber);
    Optional<Integer> egressLabel = Optional.ofNullable(parseInt(egressLabelString));
    TrafficSelector selector = buildTrafficSelector();
    TrafficTreatment treatment = buildTrafficTreatment();
    List<Constraint> constraints = buildConstraints();
    MplsIntent intent = new MplsIntent(appId(), selector, treatment, ingress, ingressLabel, egress, egressLabel, constraints);
    service.submit(intent);
}
#method_after
@Override
protected void execute() {
    IntentService service = get(IntentService.class);
    DeviceId ingressDeviceId = deviceId(getDeviceId(ingressDeviceString));
    PortNumber ingressPortNumber = portNumber(getPortNumber(ingressDeviceString));
    ConnectPoint ingress = new ConnectPoint(ingressDeviceId, ingressPortNumber);
    Optional<MplsLabel> ingressLabel = Optional.empty();
    if (!ingressLabelString.isEmpty()) {
        ingressLabel = Optional.ofNullable(MplsLabel.mplsLabel(parseInt(ingressLabelString)));
    }
    DeviceId egressDeviceId = deviceId(getDeviceId(egressDeviceString));
    PortNumber egressPortNumber = portNumber(getPortNumber(egressDeviceString));
    ConnectPoint egress = new ConnectPoint(egressDeviceId, egressPortNumber);
    Optional<MplsLabel> egressLabel = Optional.empty();
    if (!ingressLabelString.isEmpty()) {
        egressLabel = Optional.ofNullable(MplsLabel.mplsLabel(parseInt(egressLabelString)));
    }
    TrafficSelector selector = buildTrafficSelector();
    TrafficTreatment treatment = buildTrafficTreatment();
    List<Constraint> constraints = buildConstraints();
    MplsIntent intent = new MplsIntent(appId(), selector, treatment, ingress, ingressLabel, egress, egressLabel, constraints);
    service.submit(intent);
}
#end_block

#method_before
public static L2ModificationInstruction modMplsLabel(Integer mplsLabel) {
    checkNotNull(mplsLabel, "MPLS label cannot be null");
    return new ModMplsLabelInstruction(mplsLabel);
}
#method_after
public static L2ModificationInstruction modMplsLabel(MplsLabel mplsLabel) {
    checkNotNull(mplsLabel, "MPLS label cannot be null");
    return new ModMplsLabelInstruction(mplsLabel);
}
#end_block

#method_before
public static L3ModificationInstruction modL3Src(IpAddress addr) {
    checkNotNull(addr, "Src l3 address cannot be null");
    return new ModIPInstruction(L3SubType.IP_SRC, addr);
}
#method_after
public static L3ModificationInstruction modL3Src(IpAddress addr) {
    checkNotNull(addr, "Src l3 IPv4 address cannot be null");
    return new ModIPInstruction(L3SubType.IPV4_SRC, addr);
}
#end_block

#method_before
public static L3ModificationInstruction modL3Dst(IpAddress addr) {
    checkNotNull(addr, "Dst l3 address cannot be null");
    return new ModIPInstruction(L3SubType.IP_DST, addr);
}
#method_after
public static L3ModificationInstruction modL3Dst(IpAddress addr) {
    checkNotNull(addr, "Dst l3 IPv4 address cannot be null");
    return new ModIPInstruction(L3SubType.IPV4_DST, addr);
}
#end_block

#method_before
public static Instruction pushMpls() {
    return new PushHeaderInstructions(L2SubType.MPLS_PUSH, new Ethernet().setEtherType(Ethernet.MPLS_UNICAST));
}
#method_after
public static Instruction pushMpls() {
    return new PushHeaderInstructions(L2SubType.MPLS_PUSH, Ethernet.MPLS_UNICAST);
}
#end_block

#method_before
public static Instruction popMpls() {
    return new PushHeaderInstructions(L2SubType.MPLS_POP, new Ethernet().setEtherType(Ethernet.MPLS_UNICAST));
}
#method_after
public static Instruction popMpls() {
    return new PushHeaderInstructions(L2SubType.MPLS_POP, Ethernet.MPLS_UNICAST);
}
#end_block

#method_before
public static Instruction popMpls(Short ethetType) {
    return new PushHeaderInstructions(L2SubType.MPLS_POP, new Ethernet().setEtherType(ethetType));
}
#method_after
public static Instruction popMpls(Short etherType) {
    checkNotNull(etherType, "Ethernet type cannot be null");
    return new PushHeaderInstructions(L2SubType.MPLS_POP, etherType);
}
#end_block

#method_before
// private Integer max_MplsLabel = 20;
@Override
@Activate
public void activate() {
    super.activate();
    final Config config = theInstance.getConfig();
    MapConfig linkCfg = config.getMapConfig(LINK_RESOURCE_ALLOCATIONS);
    linkCfg.setAsyncBackupCount(MapConfig.MAX_BACKUP_COUNT - linkCfg.getBackupCount());
    MapConfig intentCfg = config.getMapConfig(INTENT_ALLOCATIONS);
    intentCfg.setAsyncBackupCount(MapConfig.MAX_BACKUP_COUNT - intentCfg.getBackupCount());
    log.info("Started");
}
#method_after
@Override
@Activate
public void activate() {
    super.activate();
    final Config config = theInstance.getConfig();
    MapConfig linkCfg = config.getMapConfig(LINK_RESOURCE_ALLOCATIONS);
    linkCfg.setAsyncBackupCount(MapConfig.MAX_BACKUP_COUNT - linkCfg.getBackupCount());
    MapConfig intentCfg = config.getMapConfig(INTENT_ALLOCATIONS);
    intentCfg.setAsyncBackupCount(MapConfig.MAX_BACKUP_COUNT - intentCfg.getBackupCount());
    log.info("Started");
}
#end_block

#method_before
private Set<? extends ResourceAllocation> getResourceCapacity(ResourceType type, Link link) {
    if (type == ResourceType.BANDWIDTH) {
        return ImmutableSet.of(getBandwidthResourceCapacity(link));
    }
    if (type == ResourceType.LAMBDA) {
        return getLambdaResourceCapacity(link);
    }
    if (type == ResourceType.MPLS_LABEL) {
        return getMplsResourceCapacity(link);
    }
    return null;
}
#method_after
private Set<? extends ResourceAllocation> getResourceCapacity(ResourceType type, Link link) {
    if (type == ResourceType.BANDWIDTH) {
        return ImmutableSet.of(getBandwidthResourceCapacity(link));
    }
    if (type == ResourceType.LAMBDA) {
        return getLambdaResourceCapacity(link);
    }
    if (type == ResourceType.MPLS_LABEL) {
        return getMplsResourceCapacity();
    }
    return null;
}
#end_block

#method_before
private BandwidthResourceAllocation getBandwidthResourceCapacity(Link link) {
    // if Link annotation exist, use them
    // if all fails, use DEFAULT_BANDWIDTH
    Bandwidth bandwidth = null;
    String strBw = link.annotations().value(bandwidthAnnotation);
    if (strBw != null) {
        try {
            bandwidth = Bandwidth.valueOf(Double.parseDouble(strBw));
        } catch (NumberFormatException e) {
            // do nothings
            bandwidth = null;
        }
    }
    if (bandwidth == null) {
        // fall back, use fixed default
        bandwidth = DEFAULT_BANDWIDTH;
    }
    return new BandwidthResourceAllocation(bandwidth);
}
#method_after
private BandwidthResourceAllocation getBandwidthResourceCapacity(Link link) {
    // if Link annotation exist, use them
    // if all fails, use DEFAULT_BANDWIDTH
    Bandwidth bandwidth = null;
    String strBw = link.annotations().value(bandwidthAnnotation);
    if (strBw != null) {
        try {
            bandwidth = Bandwidth.mbps(Double.parseDouble(strBw));
        } catch (NumberFormatException e) {
            // do nothings
            bandwidth = null;
        }
    }
    if (bandwidth == null) {
        // fall back, use fixed default
        bandwidth = DEFAULT_BANDWIDTH;
    }
    return new BandwidthResourceAllocation(bandwidth);
}
#end_block

#method_before
private Set<MplsLabelResourceAllocation> getMplsResourceCapacity(Link link) {
    Set<MplsLabelResourceAllocation> allocations = new HashSet<>();
    // Ignoring reserved labels of 0 through 15
    for (int i = 16; i <= maxMplsLabel; i++) {
        allocations.add(new MplsLabelResourceAllocation(MplsLabel.valueOf(i)));
    }
    return allocations;
}
#method_after
private Set<MplsLabelResourceAllocation> getMplsResourceCapacity() {
    Set<MplsLabelResourceAllocation> allocations = new HashSet<>();
    // Ignoring reserved labels of 0 through 15
    for (int i = 16; i <= maxMplsLabel; i++) {
        allocations.add(new MplsLabelResourceAllocation(MplsLabel.valueOf(i)));
    }
    return allocations;
}
#end_block

#method_before
private Map<ResourceType, Set<? extends ResourceAllocation>> getFreeResourcesEx(TransactionContext tx, Link link) {
    // returns capacity - allocated
    checkNotNull(link);
    Map<ResourceType, Set<? extends ResourceAllocation>> free = new HashMap<>();
    final Map<ResourceType, Set<? extends ResourceAllocation>> caps = getResourceCapacity(link);
    final Iterable<LinkResourceAllocations> allocations = getAllocations(tx, link);
    for (ResourceType type : ResourceType.values()) {
        // there should be class/category of resources
        switch(type) {
            case BANDWIDTH:
                {
                    Set<? extends ResourceAllocation> bw = caps.get(ResourceType.BANDWIDTH);
                    if (bw == null || bw.isEmpty()) {
                        bw = Sets.newHashSet(new BandwidthResourceAllocation(EMPTY_BW));
                    }
                    BandwidthResourceAllocation cap = (BandwidthResourceAllocation) bw.iterator().next();
                    double freeBw = cap.bandwidth().toDouble();
                    // enumerate current allocations, subtracting resources
                    for (LinkResourceAllocations alloc : allocations) {
                        Set<ResourceAllocation> types = alloc.getResourceAllocation(link);
                        for (ResourceAllocation a : types) {
                            if (a instanceof BandwidthResourceAllocation) {
                                BandwidthResourceAllocation bwA = (BandwidthResourceAllocation) a;
                                freeBw -= bwA.bandwidth().toDouble();
                            }
                        }
                    }
                    free.put(type, Sets.newHashSet(new BandwidthResourceAllocation(Bandwidth.valueOf(freeBw))));
                    break;
                }
            case LAMBDA:
                {
                    Set<? extends ResourceAllocation> lmd = caps.get(type);
                    if (lmd == null || lmd.isEmpty()) {
                        // nothing left
                        break;
                    }
                    Set<LambdaResourceAllocation> freeL = new HashSet<>();
                    for (ResourceAllocation r : lmd) {
                        if (r instanceof LambdaResourceAllocation) {
                            freeL.add((LambdaResourceAllocation) r);
                        }
                    }
                    // enumerate current allocations, removing resources
                    for (LinkResourceAllocations alloc : allocations) {
                        Set<ResourceAllocation> types = alloc.getResourceAllocation(link);
                        for (ResourceAllocation a : types) {
                            if (a instanceof LambdaResourceAllocation) {
                                freeL.remove(a);
                            }
                        }
                    }
                    free.put(type, freeL);
                    break;
                }
            case MPLS_LABEL:
                Set<? extends ResourceAllocation> mpls = caps.get(type);
                if (mpls == null || mpls.isEmpty()) {
                    // nothing left
                    break;
                }
                Set<MplsLabelResourceAllocation> freeLabel = new HashSet<>();
                for (ResourceAllocation r : mpls) {
                    if (r instanceof MplsLabelResourceAllocation) {
                        freeLabel.add((MplsLabelResourceAllocation) r);
                    }
                }
                // enumerate current allocations, removing resources
                for (LinkResourceAllocations alloc : allocations) {
                    Set<ResourceAllocation> types = alloc.getResourceAllocation(link);
                    for (ResourceAllocation a : types) {
                        if (a instanceof MplsLabelResourceAllocation) {
                            freeLabel.remove(a);
                        }
                    }
                }
                free.put(type, freeLabel);
                break;
            default:
                break;
        }
    }
    return free;
}
#method_after
private Map<ResourceType, Set<? extends ResourceAllocation>> getFreeResourcesEx(TransactionContext tx, Link link) {
    // returns capacity - allocated
    checkNotNull(link);
    Map<ResourceType, Set<? extends ResourceAllocation>> free = new HashMap<>();
    final Map<ResourceType, Set<? extends ResourceAllocation>> caps = getResourceCapacity(link);
    final Iterable<LinkResourceAllocations> allocations = getAllocations(tx, link);
    for (ResourceType type : ResourceType.values()) {
        // there should be class/category of resources
        switch(type) {
            case BANDWIDTH:
                {
                    Set<? extends ResourceAllocation> bw = caps.get(ResourceType.BANDWIDTH);
                    if (bw == null || bw.isEmpty()) {
                        bw = Sets.newHashSet(new BandwidthResourceAllocation(EMPTY_BW));
                    }
                    BandwidthResourceAllocation cap = (BandwidthResourceAllocation) bw.iterator().next();
                    double freeBw = cap.bandwidth().toDouble();
                    // enumerate current allocations, subtracting resources
                    for (LinkResourceAllocations alloc : allocations) {
                        Set<ResourceAllocation> types = alloc.getResourceAllocation(link);
                        for (ResourceAllocation a : types) {
                            if (a instanceof BandwidthResourceAllocation) {
                                BandwidthResourceAllocation bwA = (BandwidthResourceAllocation) a;
                                freeBw -= bwA.bandwidth().toDouble();
                            }
                        }
                    }
                    free.put(type, Sets.newHashSet(new BandwidthResourceAllocation(Bandwidth.bps(freeBw))));
                    break;
                }
            case LAMBDA:
                {
                    Set<? extends ResourceAllocation> lmd = caps.get(type);
                    if (lmd == null || lmd.isEmpty()) {
                        // nothing left
                        break;
                    }
                    Set<LambdaResourceAllocation> freeL = new HashSet<>();
                    for (ResourceAllocation r : lmd) {
                        if (r instanceof LambdaResourceAllocation) {
                            freeL.add((LambdaResourceAllocation) r);
                        }
                    }
                    // enumerate current allocations, removing resources
                    for (LinkResourceAllocations alloc : allocations) {
                        Set<ResourceAllocation> types = alloc.getResourceAllocation(link);
                        for (ResourceAllocation a : types) {
                            if (a instanceof LambdaResourceAllocation) {
                                freeL.remove(a);
                            }
                        }
                    }
                    free.put(type, freeL);
                    break;
                }
            case MPLS_LABEL:
                Set<? extends ResourceAllocation> mpls = caps.get(type);
                if (mpls == null || mpls.isEmpty()) {
                    // nothing left
                    break;
                }
                Set<MplsLabelResourceAllocation> freeLabel = new HashSet<>();
                for (ResourceAllocation r : mpls) {
                    if (r instanceof MplsLabelResourceAllocation) {
                        freeLabel.add((MplsLabelResourceAllocation) r);
                    }
                }
                // enumerate current allocations, removing resources
                for (LinkResourceAllocations alloc : allocations) {
                    Set<ResourceAllocation> types = alloc.getResourceAllocation(link);
                    for (ResourceAllocation a : types) {
                        if (a instanceof MplsLabelResourceAllocation) {
                            freeLabel.remove(a);
                        }
                    }
                }
                free.put(type, freeLabel);
                break;
            default:
                break;
        }
    }
    return free;
}
#end_block

#method_before
private void allocateLinkResource(TransactionContext tx, Link link, LinkResourceAllocations allocations) {
    // requested resources
    Set<ResourceAllocation> reqs = allocations.getResourceAllocation(link);
    Map<ResourceType, Set<? extends ResourceAllocation>> available = getFreeResourcesEx(tx, link);
    for (ResourceAllocation req : reqs) {
        Set<? extends ResourceAllocation> avail = available.get(req.type());
        if (req instanceof BandwidthResourceAllocation) {
            // check if allocation should be accepted
            if (avail.isEmpty()) {
                checkState(!avail.isEmpty(), "There's no Bandwidth resource on %s?", link);
            }
            BandwidthResourceAllocation bw = (BandwidthResourceAllocation) avail.iterator().next();
            double bwLeft = bw.bandwidth().toDouble();
            BandwidthResourceAllocation bwReq = ((BandwidthResourceAllocation) req);
            bwLeft -= bwReq.bandwidth().toDouble();
            if (bwLeft < 0) {
                throw new ResourceAllocationException(PositionalParameterStringFormatter.format("Unable to allocate bandwidth for link {} " + " requested amount is {} current allocation is {}", link, bwReq.bandwidth().toDouble(), bw));
            }
        } else if (req instanceof LambdaResourceAllocation) {
            LambdaResourceAllocation lambdaAllocation = (LambdaResourceAllocation) req;
            // check if allocation should be accepted
            if (!avail.contains(req)) {
                // requested lambda was not available
                throw new ResourceAllocationException(PositionalParameterStringFormatter.format("Unable to allocate lambda for link {} lamdba is {}", link, lambdaAllocation.lambda().toInt()));
            }
        } else if (req instanceof MplsLabelResourceAllocation) {
            MplsLabelResourceAllocation mplsAllocation = (MplsLabelResourceAllocation) req;
            if (!avail.contains(req)) {
                throw new ResourceAllocationException(PositionalParameterStringFormatter.format("Unable to allocate MPLS label for link " + "{} MPLS label is {}", link, mplsAllocation.mplsLabel().toInt()));
            }
        }
    }
    // all requests allocatable => add allocation
    final LinkKey linkKey = LinkKey.linkKey(link);
    STxMap<LinkKey, List<LinkResourceAllocations>> linkAllocs = getLinkAllocs(tx);
    List<LinkResourceAllocations> before = linkAllocs.get(linkKey);
    if (before == null) {
        List<LinkResourceAllocations> after = new ArrayList<>();
        after.add(allocations);
        before = linkAllocs.putIfAbsent(linkKey, after);
        if (before != null) {
            // concurrent allocation detected, retry transaction
            throw new TransactionException("Concurrent Allocation, retry");
        }
    } else {
        List<LinkResourceAllocations> after = new ArrayList<>(before.size() + 1);
        after.addAll(before);
        after.add(allocations);
        linkAllocs.replace(linkKey, before, after);
    }
}
#method_after
private void allocateLinkResource(TransactionContext tx, Link link, LinkResourceAllocations allocations) {
    // requested resources
    Set<ResourceAllocation> reqs = allocations.getResourceAllocation(link);
    Map<ResourceType, Set<? extends ResourceAllocation>> available = getFreeResourcesEx(tx, link);
    for (ResourceAllocation req : reqs) {
        Set<? extends ResourceAllocation> avail = available.get(req.type());
        if (req instanceof BandwidthResourceAllocation) {
            // check if allocation should be accepted
            if (avail.isEmpty()) {
                checkState(!avail.isEmpty(), "There's no Bandwidth resource on %s?", link);
            }
            BandwidthResourceAllocation bw = (BandwidthResourceAllocation) avail.iterator().next();
            double bwLeft = bw.bandwidth().toDouble();
            BandwidthResourceAllocation bwReq = ((BandwidthResourceAllocation) req);
            bwLeft -= bwReq.bandwidth().toDouble();
            if (bwLeft < 0) {
                throw new ResourceAllocationException(PositionalParameterStringFormatter.format("Unable to allocate bandwidth for link {} " + " requested amount is {} current allocation is {}", link, bwReq.bandwidth().toDouble(), bw));
            }
        } else if (req instanceof LambdaResourceAllocation) {
            LambdaResourceAllocation lambdaAllocation = (LambdaResourceAllocation) req;
            // check if allocation should be accepted
            if (!avail.contains(req)) {
                // requested lambda was not available
                throw new ResourceAllocationException(PositionalParameterStringFormatter.format("Unable to allocate lambda for link {} lambda is {}", link, lambdaAllocation.lambda().toInt()));
            }
        } else if (req instanceof MplsLabelResourceAllocation) {
            MplsLabelResourceAllocation mplsAllocation = (MplsLabelResourceAllocation) req;
            if (!avail.contains(req)) {
                throw new ResourceAllocationException(PositionalParameterStringFormatter.format("Unable to allocate MPLS label for link " + "{} MPLS label is {}", link, mplsAllocation.mplsLabel().toString()));
            }
        }
    }
    // all requests allocatable => add allocation
    final LinkKey linkKey = LinkKey.linkKey(link);
    STxMap<LinkKey, List<LinkResourceAllocations>> linkAllocs = getLinkAllocs(tx);
    List<LinkResourceAllocations> before = linkAllocs.get(linkKey);
    if (before == null) {
        List<LinkResourceAllocations> after = new ArrayList<>();
        after.add(allocations);
        before = linkAllocs.putIfAbsent(linkKey, after);
        if (before != null) {
            // concurrent allocation detected, retry transaction
            throw new TransactionException("Concurrent Allocation, retry");
        }
    } else {
        List<LinkResourceAllocations> after = new ArrayList<>(before.size() + 1);
        after.addAll(before);
        after.add(allocations);
        linkAllocs.replace(linkKey, before, after);
    }
}
#end_block

#method_before
public Optional<Integer> ingressLabel() {
    return ingressLabel;
}
#method_after
public Optional<MplsLabel> ingressLabel() {
    return ingressLabel;
}
#end_block

#method_before
public Optional<Integer> egressLabel() {
    return egressLabel;
}
#method_after
public Optional<MplsLabel> egressLabel() {
    return egressLabel;
}
#end_block

#method_before
@Override
public String toString() {
    return MoreObjects.toStringHelper(this).add("MplsLabel", mplsLabel).toString();
}
#method_after
@Override
public String toString() {
    return MoreObjects.toStringHelper(this).add("mplsLabel", mplsLabel).toString();
}
#end_block

#method_before
private Iterable<MplsLabel> getAvailableMplsLabels(Link link) {
    checkNotNull(link);
    Set<ResourceAllocation> resAllocs = store.getFreeResources(link);
    if (resAllocs == null) {
        return Collections.emptySet();
    }
    Set<MplsLabel> mplsLabels = new HashSet<>();
    for (ResourceAllocation res : resAllocs) {
        if (res.type() == ResourceType.MPLS_LABEL) {
            mplsLabels.add(((MplsLabelResourceAllocation) res).mplsLabel());
        }
    }
    return mplsLabels;
}
#method_after
private Iterable<MplsLabel> getAvailableMplsLabels(Link link) {
    Set<ResourceAllocation> resAllocs = store.getFreeResources(link);
    if (resAllocs == null) {
        return Collections.emptySet();
    }
    Set<MplsLabel> mplsLabels = new HashSet<>();
    for (ResourceAllocation res : resAllocs) {
        if (res.type() == ResourceType.MPLS_LABEL) {
            mplsLabels.add(((MplsLabelResourceAllocation) res).mplsLabel());
        }
    }
    return mplsLabels;
}
#end_block

#method_before
// /**
// * Returns map of available MPLS labels per link
// *
// * @param links the links
// * @return map of available MPLS labels per link
// */
// private Map<Link, MplsLabel> getFirstAvailableMplsLabels(Iterable<Link> links) {
// checkNotNull(links);
// Iterator<Link> i = links.iterator();
// checkArgument(i.hasNext());
// Map<Link, MplsLabel> linkMplsLabel = new HashMap<Link, MplsLabel>();
// while (i.hasNext()) {
// Iterator<MplsLabel> mplsLabels = getAvailableMplsLabels(i.next())
// .iterator();
// if (mplsLabels.hasNext()) {
// linkMplsLabel.put(i.next(), mplsLabels.next());
// } else {
// log.info("Failed to allocate MPLS resource.");
// }
// }
// return linkMplsLabel;
// }
@Override
public LinkResourceAllocations requestResources(LinkResourceRequest req) {
    // TODO Concatenate multiple bandwidth requests.
    // TODO Support multiple lambda resource requests.
    // TODO Throw appropriate exception.
    Set<ResourceAllocation> allocs = new HashSet<>();
    Map<Link, Set<ResourceAllocation>> allocsPerLink = new HashMap<>();
    for (ResourceRequest r : req.resources()) {
        switch(r.type()) {
            case BANDWIDTH:
                BandwidthResourceRequest br = (BandwidthResourceRequest) r;
                allocs.add(new BandwidthResourceAllocation(br.bandwidth()));
                break;
            case LAMBDA:
                Iterator<Lambda> lambdaIterator = getAvailableLambdas(req.links()).iterator();
                if (lambdaIterator.hasNext()) {
                    allocs.add(new LambdaResourceAllocation(lambdaIterator.next()));
                } else {
                    log.info("Failed to allocate lambda resource.");
                    return null;
                }
                break;
            case MPLS_LABEL:
                for (Link link : req.links()) {
                    if (allocsPerLink.get(link) == null) {
                        allocsPerLink.put(link, new HashSet<ResourceAllocation>());
                    }
                    Iterator<MplsLabel> mplsIter = getAvailableMplsLabels(link).iterator();
                    if (mplsIter.hasNext()) {
                        allocsPerLink.get(link).add(new MplsLabelResourceAllocation(mplsIter.next()));
                    } else {
                        log.info("Failed to allocate MPLS resource.");
                        break;
                    }
                }
                break;
            default:
                break;
        }
    }
    Map<Link, Set<ResourceAllocation>> allocations = new HashMap<>();
    for (Link link : req.links()) {
        allocations.put(link, new HashSet<ResourceAllocation>(allocs));
        allocations.get(link).addAll(allocsPerLink.get(link));
    }
    LinkResourceAllocations result = new DefaultLinkResourceAllocations(req, allocations);
    store.allocateResources(result);
    return result;
}
#method_after
@Override
public LinkResourceAllocations requestResources(LinkResourceRequest req) {
    // TODO Concatenate multiple bandwidth requests.
    // TODO Support multiple lambda resource requests.
    // TODO Throw appropriate exception.
    Set<ResourceAllocation> allocs = new HashSet<>();
    Map<Link, Set<ResourceAllocation>> allocsPerLink = new HashMap<>();
    for (ResourceRequest r : req.resources()) {
        switch(r.type()) {
            case BANDWIDTH:
                BandwidthResourceRequest br = (BandwidthResourceRequest) r;
                allocs.add(new BandwidthResourceAllocation(br.bandwidth()));
                break;
            case LAMBDA:
                Iterator<Lambda> lambdaIterator = getAvailableLambdas(req.links()).iterator();
                if (lambdaIterator.hasNext()) {
                    allocs.add(new LambdaResourceAllocation(lambdaIterator.next()));
                } else {
                    log.info("Failed to allocate lambda resource.");
                    return null;
                }
                break;
            case MPLS_LABEL:
                for (Link link : req.links()) {
                    if (allocsPerLink.get(link) == null) {
                        allocsPerLink.put(link, new HashSet<ResourceAllocation>());
                    }
                    Iterator<MplsLabel> mplsIter = getAvailableMplsLabels(link).iterator();
                    if (mplsIter.hasNext()) {
                        allocsPerLink.get(link).add(new MplsLabelResourceAllocation(mplsIter.next()));
                    } else {
                        log.info("Failed to allocate MPLS resource.");
                        break;
                    }
                }
                break;
            default:
                break;
        }
    }
    Map<Link, Set<ResourceAllocation>> allocations = new HashMap<>();
    for (Link link : req.links()) {
        allocations.put(link, new HashSet<ResourceAllocation>(allocs));
        allocations.get(link).addAll(allocsPerLink.get(link));
    }
    LinkResourceAllocations result = new DefaultLinkResourceAllocations(req, allocations);
    store.allocateResources(result);
    return result;
}
#end_block

#method_before
@Override
public Optional<IntentUpdate> execute() {
    try {
        if (isNullOrEmpty(current.installables())) {
            // we are done
            return Optional.of(new Withdrawn(pending, IntentState.WITHDRAWN));
        }
        FlowRuleOperations flowRules = intentManager.uninstallCoordinate(current, pending);
        pending.setInstallables(current.installables());
        return Optional.of(new Withdrawing(intentManager, pending, flowRules));
    } catch (IntentException e) {
        log.warn("Unable to generate generate a FlowRuleOperations from intent {} due to:", pending.intent(), e);
        return Optional.of(new WithdrawingFailed(pending));
    }
}
#method_after
@Override
public Optional<IntentUpdate> execute() {
    try {
        // Note: current.installables() are not null or empty due to createIntentUpdate check
        FlowRuleOperations flowRules = intentManager.uninstallCoordinate(current, pending);
        pending.setInstallables(current.installables());
        return Optional.of(new Withdrawing(intentManager, pending, flowRules));
    } catch (IntentException e) {
        log.warn("Unable to generate generate a FlowRuleOperations from intent {} due to:", pending.intent(), e);
        return Optional.of(new WithdrawingFailed(pending));
    }
}
#end_block

#method_before
@Override
public List<FlowRuleBatchOperation> replace(LinkCollectionIntent oldIntent, LinkCollectionIntent newIntent) {
    // FIXME: implement this
    List<FlowRuleBatchOperation> batches = Lists.newArrayList();
    batches.addAll(uninstall(oldIntent));
    batches.addAll(install(newIntent));
    return batches;
}
#method_after
@Override
public List<FlowRuleBatchOperation> replace(LinkCollectionIntent oldIntent, LinkCollectionIntent newIntent) {
    // FIXME: implement this in a more intelligent/less brute force way
    List<FlowRuleBatchOperation> batches = Lists.newArrayList();
    batches.addAll(uninstall(oldIntent));
    batches.addAll(install(newIntent));
    return batches;
}
#end_block

#method_before
// TODO javadoc
FlowRuleOperations coordinate(IntentData current, IntentData pending) {
    List<Intent> oldInstallables = (current != null) ? current.installables() : null;
    List<Intent> newInstallables = pending.installables();
    checkState(isNullOrEmpty(oldInstallables) || oldInstallables.size() == newInstallables.size(), "Old and New Intent must have equivalent installable intents.");
    List<List<FlowRuleBatchOperation>> plans = new ArrayList<>();
    for (int i = 0; i < newInstallables.size(); i++) {
        Intent newInstallable = newInstallables.get(i);
        registerSubclassInstallerIfNeeded(newInstallable);
        // TODO consider migrating installers to FlowRuleOperations
        if (isNullOrEmpty(oldInstallables)) {
            plans.add(getInstaller(newInstallable).install(newInstallable));
        } else {
            Intent oldInstallable = oldInstallables.get(i);
            checkState(oldInstallable.getClass().equals(newInstallable.getClass()), "Installable Intent type mismatch.");
            trackerService.removeTrackedResources(pending.key(), oldInstallable.resources());
            plans.add(getInstaller(newInstallable).replace(oldInstallable, newInstallable));
        }
        trackerService.addTrackedResources(pending.key(), newInstallable.resources());
    // } catch (IntentException e) {
    // log.warn("Unable to update intent {} due to:", oldIntent.id(), e);
    // //FIXME... we failed. need to uninstall (if same) or revert (if different)
    // trackerService.removeTrackedResources(newIntent.id(), newInstallable.resources());
    // exception = e;
    // batches = uninstallIntent(oldIntent, oldInstallables);
    // }
    }
    return merge(plans).build(new // TODO move this out
    FlowRuleOperationsContext() {

        @Override
        public void onSuccess(FlowRuleOperations ops) {
            log.info("Completed installing: {}", pending.key());
            pending.setState(INSTALLED);
            store.write(pending);
        }

        @Override
        public void onError(FlowRuleOperations ops) {
            log.warn("Failed installation: {} {} on {}", pending.key(), pending.intent(), ops);
            // TODO store.write(pending.setState(BROKEN));
            pending.setState(FAILED);
            store.write(pending);
        }
    });
}
#method_after
// TODO javadoc
FlowRuleOperations coordinate(IntentData current, IntentData pending) {
    List<Intent> oldInstallables = (current != null) ? current.installables() : null;
    List<Intent> newInstallables = pending.installables();
    checkState(isNullOrEmpty(oldInstallables) || oldInstallables.size() == newInstallables.size(), "Old and New Intent must have equivalent installable intents.");
    List<List<FlowRuleBatchOperation>> plans = new ArrayList<>();
    for (int i = 0; i < newInstallables.size(); i++) {
        Intent newInstallable = newInstallables.get(i);
        registerSubclassInstallerIfNeeded(newInstallable);
        /* FIXME
               - we need to do another pass on this method about that doesn't
               require the length of installables to be equal, and also doesn't
               depend on ordering
               - we should also reconsider when to start/stop tracking resources
             */
        if (isNullOrEmpty(oldInstallables)) {
            plans.add(getInstaller(newInstallable).install(newInstallable));
        } else {
            Intent oldInstallable = oldInstallables.get(i);
            checkState(oldInstallable.getClass().equals(newInstallable.getClass()), "Installable Intent type mismatch.");
            trackerService.removeTrackedResources(pending.key(), oldInstallable.resources());
            plans.add(getInstaller(newInstallable).replace(oldInstallable, newInstallable));
        }
        trackerService.addTrackedResources(pending.key(), newInstallable.resources());
    // } catch (IntentException e) {
    // log.warn("Unable to update intent {} due to:", oldIntent.id(), e);
    // //FIXME... we failed. need to uninstall (if same) or revert (if different)
    // trackerService.removeTrackedResources(newIntent.id(), newInstallable.resources());
    // exception = e;
    // batches = uninstallIntent(oldIntent, oldInstallables);
    // }
    }
    return merge(plans).build(new // TODO move this out
    FlowRuleOperationsContext() {

        @Override
        public void onSuccess(FlowRuleOperations ops) {
            log.info("Completed installing: {}", pending.key());
            pending.setState(INSTALLED);
            store.write(pending);
        }

        @Override
        public void onError(FlowRuleOperations ops) {
            log.warn("Failed installation: {} {} on {}", pending.key(), pending.intent(), ops);
            // TODO store.write(pending.setState(BROKEN));
            pending.setState(FAILED);
            store.write(pending);
        }
    });
}
#end_block

#method_before
private IntentUpdate createIntentUpdate(IntentData intentData) {
    IntentData current = store.getIntentData(intentData.key());
    switch(intentData.state()) {
        case INSTALL_REQ:
            return new InstallRequest(this, intentData, Optional.ofNullable(current));
        case WITHDRAW_REQ:
            if (current == null) {
                return new Withdrawn(current, WITHDRAWN);
            } else {
                return new WithdrawRequest(this, intentData, current);
            }
        default:
            // illegal state
            return new CompilingFailed(intentData);
    }
}
#method_after
private IntentUpdate createIntentUpdate(IntentData intentData) {
    IntentData current = store.getIntentData(intentData.key());
    switch(intentData.state()) {
        case INSTALL_REQ:
            return new InstallRequest(this, intentData, Optional.ofNullable(current));
        case WITHDRAW_REQ:
            if (current == null || isNullOrEmpty(current.installables())) {
                return new Withdrawn(current, WITHDRAWN);
            } else {
                return new WithdrawRequest(this, intentData, current);
            }
        default:
            // illegal state
            return new CompilingFailed(intentData);
    }
}
#end_block

