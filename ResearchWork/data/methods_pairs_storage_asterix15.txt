843
#method_before
@Override
public PhysicalRequirements getRequiredPropertiesForChildren(ILogicalOperator op, IPhysicalPropertiesVector requiredByParent, IOptimizationContext context) {
    // broadcast the range map to the cluster node domain
    INodeDomain targetDomain = context.getComputationNodeDomain();
    List<ILocalStructuralProperty> noProp = new ArrayList<>();
    StructuralPropertiesVector[] requiredAtInputs = new StructuralPropertiesVector[2];
    requiredAtInputs[0] = StructuralPropertiesVector.EMPTY_PROPERTIES_VECTOR;
    requiredAtInputs[1] = new StructuralPropertiesVector(new BroadcastPartitioningProperty(targetDomain), noProp);
    return new PhysicalRequirements(requiredAtInputs, IPartitioningRequirementsCoordinator.NO_COORDINATION);
}
#method_after
@Override
public PhysicalRequirements getRequiredPropertiesForChildren(ILogicalOperator op, IPhysicalPropertiesVector requiredByParent, IOptimizationContext context) {
    // broadcast the side activity output to the cluster node domain
    INodeDomain targetDomain = context.getComputationNodeDomain();
    List<ILocalStructuralProperty> noProp = new ArrayList<>();
    StructuralPropertiesVector[] requiredAtInputs = new StructuralPropertiesVector[2];
    requiredAtInputs[0] = StructuralPropertiesVector.EMPTY_PROPERTIES_VECTOR;
    requiredAtInputs[1] = new StructuralPropertiesVector(new BroadcastPartitioningProperty(targetDomain), noProp);
    return new PhysicalRequirements(requiredAtInputs, IPartitioningRequirementsCoordinator.NO_COORDINATION);
}
#end_block

#method_before
@Override
public void contributeRuntimeOperator(IHyracksJobBuilder builder, JobGenContext context, ILogicalOperator op, IOperatorSchema propagatedSchema, IOperatorSchema[] inputSchemas, IOperatorSchema outerPlanSchema) throws AlgebricksException {
    ForwardOperator forwardOp = (ForwardOperator) op;
    RecordDescriptor dataInputDescriptor = JobGenHelper.mkRecordDescriptor(context.getTypeEnvironment(forwardOp.getInputs().get(0).getValue()), inputSchemas[0], context);
    AbstractForwardOperatorDescriptor forwardDescriptor = getOperatorDescriptor(builder, forwardOp, dataInputDescriptor);
    builder.contributeHyracksOperator(forwardOp, forwardDescriptor);
    ILogicalOperator dataSource = forwardOp.getInputs().get(0).getValue();
    builder.contributeGraphEdge(dataSource, 0, forwardOp, 0);
    ILogicalOperator rangemapSource = forwardOp.getInputs().get(1).getValue();
    builder.contributeGraphEdge(rangemapSource, 0, forwardOp, 1);
}
#method_after
@Override
public void contributeRuntimeOperator(IHyracksJobBuilder builder, JobGenContext context, ILogicalOperator op, IOperatorSchema propagatedSchema, IOperatorSchema[] inputSchemas, IOperatorSchema outerPlanSchema) throws AlgebricksException {
    ForwardOperator forwardOp = (ForwardOperator) op;
    RecordDescriptor dataInputDescriptor = JobGenHelper.mkRecordDescriptor(context.getTypeEnvironment(forwardOp.getInputs().get(0).getValue()), inputSchemas[0], context);
    AbstractForwardOperatorDescriptor forwardDescriptor = getOperatorDescriptor(builder, forwardOp, dataInputDescriptor);
    builder.contributeHyracksOperator(forwardOp, forwardDescriptor);
    ILogicalOperator dataSource = forwardOp.getInputs().get(0).getValue();
    builder.contributeGraphEdge(dataSource, 0, forwardOp, 0);
    ILogicalOperator sideDataSource = forwardOp.getInputs().get(1).getValue();
    builder.contributeGraphEdge(sideDataSource, 0, forwardOp, 1);
}
#end_block

#method_before
public AbstractForwardOperatorDescriptor getOperatorDescriptor(IHyracksJobBuilder builder, ForwardOperator forwardOp, RecordDescriptor dataInputDescriptor) {
    return new SortForwardOperatorDescriptor(builder.getJobSpec(), forwardOp.getRangeMapKey(), dataInputDescriptor);
}
#method_after
@Override
public AbstractForwardOperatorDescriptor getOperatorDescriptor(IHyracksJobBuilder builder, ForwardOperator forwardOp, RecordDescriptor dataInputDescriptor) {
    return new SortForwardOperatorDescriptor(builder.getJobSpec(), forwardOp.getSideDataKey(), dataInputDescriptor);
}
#end_block

#method_before
@Override
public void open() throws HyracksDataException {
    // retrieve the range map from the state object (previous activity should have already stored it)
    // then deposit it into the ctx so that MToN-partition can pick it up
    Object stateObjKey = new TaskId(new ActivityId(odId, SIDE_DATA_ACTIVITY_ID), partition);
    RangeMapState rangeMapState = (RangeMapState) ctx.getStateObject(stateObjKey);
    TaskUtil.put(keyInContext, rangeMapState.rangeMap, ctx);
    writer.open();
}
#method_after
@Override
public void open() throws HyracksDataException {
    // retrieve the range map from the state object (previous activity should have already stored it)
    // then deposit it into the ctx so that MToN-partition can pick it up
    Object stateObjKey = new TaskId(new ActivityId(odId, SIDE_DATA_ACTIVITY_ID), partition);
    RangeMapState rangeMapState = (RangeMapState) ctx.getStateObject(stateObjKey);
    TaskUtil.put(sideDataKey, rangeMapState.rangeMap, ctx);
    writer.open();
}
#end_block

#method_before
@Override
public void contributeActivities(IActivityGraphBuilder builder) {
    // side data activity, its input is coming through the operator's in-port = 1 & activity's in-port = 0
    builder.addActivity(this, sideDataActivity);
    builder.addSourceEdge(1, sideDataActivity, 0);
    // forward data activity, its input is coming through the operator's in-port = 0 & activity's in-port = 0
    builder.addActivity(this, forwardDataActivity);
    builder.addSourceEdge(0, forwardDataActivity, 0);
    // forward data activity will wait for the side data activity
    builder.addBlockingEdge(sideDataActivity, forwardDataActivity);
    // data leaves from the operator's out-port = 0 & forward data activity's out-port = 0
    builder.addTargetEdge(0, forwardDataActivity, 0);
}
#method_after
@Override
public void contributeActivities(IActivityGraphBuilder builder) {
    AbstractActivityNode forwardDataActivity = createForwardDataActivity();
    AbstractActivityNode sideDataActivity = createSideDataActivity();
    // side data activity, its input is coming through the operator's in-port = 1 & activity's in-port = 0
    builder.addActivity(this, sideDataActivity);
    builder.addSourceEdge(1, sideDataActivity, 0);
    // forward data activity, its input is coming through the operator's in-port = 0 & activity's in-port = 0
    builder.addActivity(this, forwardDataActivity);
    builder.addSourceEdge(0, forwardDataActivity, 0);
    // forward data activity will wait for the side data activity
    builder.addBlockingEdge(sideDataActivity, forwardDataActivity);
    // data leaves from the operator's out-port = 0 & forward data activity's out-port = 0
    builder.addTargetEdge(0, forwardDataActivity, 0);
}
#end_block

#method_before
public void validateOperation(ICcApplicationContext appCtx, Dataverse defaultDataverse, Statement stmt) throws AlgebricksException {
    final IClusterStateManager clusterStateManager = appCtx.getClusterStateManager();
    final IGlobalRecoveryManager globalRecoveryManager = appCtx.getGlobalRecoveryManager();
    if (!(clusterStateManager.getState().equals(ClusterState.ACTIVE) && globalRecoveryManager.isRecoveryCompleted())) {
        int maxWaitCycles = appCtx.getExternalProperties().getMaxWaitClusterActive();
        try {
            clusterStateManager.waitForState(ClusterState.ACTIVE, maxWaitCycles, TimeUnit.SECONDS);
        } catch (HyracksDataException e) {
            throw new AsterixException(e);
        } catch (InterruptedException e) {
            if (LOGGER.isWarnEnabled()) {
                LOGGER.warn("Thread interrupted while waiting for cluster to be " + ClusterState.ACTIVE);
            }
            Thread.currentThread().interrupt();
        }
        synchronized (clusterStateManager) {
            if (!clusterStateManager.getState().equals(ClusterState.ACTIVE)) {
                ClusterPartition[] configuredPartitions = clusterStateManager.getClusterPartitons();
                List<String> inactiveNodes = new ArrayList<>();
                for (ClusterPartition cp : configuredPartitions) {
                    if (!cp.isActive()) {
                        inactiveNodes.add(cp.getNodeId());
                    }
                }
                throw AsterixException.create(ErrorCode.REJECT_BAD_CLUSTER_STATE, "Not all node controllers required for query execution" + " have joined the cluster. Nodes " + inactiveNodes + " appear " + "missing, double check the logs on these machines and the cluster configuration");
            } else {
                if (LOGGER.isInfoEnabled()) {
                    LOGGER.info("Cluster is now " + ClusterState.ACTIVE);
                }
            }
        }
    }
    if (clusterStateManager.getState().equals(ClusterState.UNUSABLE)) {
        throw new AsterixException("Cluster is in " + ClusterState.UNUSABLE + " state." + "\n One or more Node Controllers have left.\n");
    }
    if (!globalRecoveryManager.isRecoveryCompleted()) {
        int maxWaitCycles = appCtx.getExternalProperties().getMaxWaitClusterActive();
        int waitCycleCount = 0;
        try {
            while (!globalRecoveryManager.isRecoveryCompleted() && waitCycleCount < maxWaitCycles) {
                Thread.sleep(1000);
                waitCycleCount++;
            }
        } catch (InterruptedException e) {
            if (LOGGER.isWarnEnabled()) {
                LOGGER.warn("Thread interrupted while waiting for cluster to complete global recovery ");
            }
            Thread.currentThread().interrupt();
        }
        if (!globalRecoveryManager.isRecoveryCompleted()) {
            throw new AsterixException("Cluster Global recovery is not yet complete and the system is in " + ClusterState.ACTIVE + " state");
        }
    }
    boolean invalidOperation = false;
    String message = null;
    String dataverse = defaultDataverse != null ? defaultDataverse.getDataverseName() : null;
    switch(stmt.getKind()) {
        case INSERT:
            InsertStatement insertStmt = (InsertStatement) stmt;
            if (insertStmt.getDataverseName() != null) {
                dataverse = insertStmt.getDataverseName().getValue();
            }
            invalidOperation = MetadataConstants.METADATA_DATAVERSE_NAME.equals(dataverse);
            if (invalidOperation) {
                message = "Insert operation is not permitted in dataverse " + MetadataConstants.METADATA_DATAVERSE_NAME;
            }
            break;
        case DELETE:
            DeleteStatement deleteStmt = (DeleteStatement) stmt;
            if (deleteStmt.getDataverseName() != null) {
                dataverse = deleteStmt.getDataverseName().getValue();
            }
            invalidOperation = MetadataConstants.METADATA_DATAVERSE_NAME.equals(dataverse);
            if (invalidOperation) {
                message = "Delete operation is not permitted in dataverse " + MetadataConstants.METADATA_DATAVERSE_NAME;
            }
            break;
        case DATAVERSE_DROP:
            DataverseDropStatement dvDropStmt = (DataverseDropStatement) stmt;
            invalidOperation = MetadataConstants.METADATA_DATAVERSE_NAME.equals(dvDropStmt.getDataverseName().getValue());
            if (invalidOperation) {
                message = "Cannot drop dataverse:" + dvDropStmt.getDataverseName().getValue();
            }
            break;
        case DATASET_DROP:
            DropDatasetStatement dropStmt = (DropDatasetStatement) stmt;
            if (dropStmt.getDataverseName() != null) {
                dataverse = dropStmt.getDataverseName().getValue();
            }
            invalidOperation = MetadataConstants.METADATA_DATAVERSE_NAME.equals(dataverse);
            if (invalidOperation) {
                message = "Cannot drop a dataset belonging to the dataverse:" + MetadataConstants.METADATA_DATAVERSE_NAME;
            }
            break;
        case DATASET_DECL:
            DatasetDecl datasetStmt = (DatasetDecl) stmt;
            Map<String, String> hints = datasetStmt.getHints();
            if (hints != null && !hints.isEmpty()) {
                StringBuilder errorMsgBuffer = new StringBuilder();
                for (Entry<String, String> hint : hints.entrySet()) {
                    Pair<Boolean, String> validationResult = DatasetHints.validate(appCtx, hint.getKey(), hint.getValue());
                    if (!validationResult.first) {
                        errorMsgBuffer.append("Dataset: ").append(datasetStmt.getName().getValue()).append(" error in processing hint: ").append(hint.getKey()).append(" ").append(validationResult.second);
                        errorMsgBuffer.append(" \n");
                    }
                }
                invalidOperation = errorMsgBuffer.length() > 0;
                if (invalidOperation) {
                    message = errorMsgBuffer.toString();
                }
            }
            break;
        default:
            break;
    }
    if (invalidOperation) {
        throw new AsterixException("Invalid operation - " + message);
    }
}
#method_after
public void validateOperation(ICcApplicationContext appCtx, Dataverse defaultDataverse, Statement stmt) throws AlgebricksException {
    final IClusterStateManager clusterStateManager = appCtx.getClusterStateManager();
    final IGlobalRecoveryManager globalRecoveryManager = appCtx.getGlobalRecoveryManager();
    if (!(clusterStateManager.getState().equals(ClusterState.ACTIVE) && globalRecoveryManager.isRecoveryCompleted())) {
        int maxWaitCycles = appCtx.getExternalProperties().getMaxWaitClusterActive();
        try {
            clusterStateManager.waitForState(ClusterState.ACTIVE, maxWaitCycles, TimeUnit.SECONDS);
        } catch (HyracksDataException e) {
            throw new AsterixException(e);
        } catch (InterruptedException e) {
            if (LOGGER.isWarnEnabled()) {
                LOGGER.warn("Thread interrupted while waiting for cluster to be " + ClusterState.ACTIVE);
            }
            Thread.currentThread().interrupt();
        }
        synchronized (clusterStateManager) {
            if (!clusterStateManager.getState().equals(ClusterState.ACTIVE)) {
                ClusterPartition[] configuredPartitions = clusterStateManager.getClusterPartitons();
                Set<String> inactiveNodes = new HashSet<>();
                for (ClusterPartition cp : configuredPartitions) {
                    if (!cp.isActive()) {
                        inactiveNodes.add(cp.getNodeId());
                    }
                }
                throw AsterixException.create(ErrorCode.CLUSTER_STATE_UNUSABLE, Arrays.toString(inactiveNodes.toArray()));
            } else {
                if (LOGGER.isInfoEnabled()) {
                    LOGGER.info("Cluster is now " + ClusterState.ACTIVE);
                }
            }
        }
    }
    if (!globalRecoveryManager.isRecoveryCompleted()) {
        int maxWaitCycles = appCtx.getExternalProperties().getMaxWaitClusterActive();
        int waitCycleCount = 0;
        try {
            while (!globalRecoveryManager.isRecoveryCompleted() && waitCycleCount < maxWaitCycles) {
                Thread.sleep(1000);
                waitCycleCount++;
            }
        } catch (InterruptedException e) {
            if (LOGGER.isWarnEnabled()) {
                LOGGER.warn("Thread interrupted while waiting for cluster to complete global recovery ");
            }
            Thread.currentThread().interrupt();
        }
        if (!globalRecoveryManager.isRecoveryCompleted()) {
            throw new AsterixException("Cluster Global recovery is not yet complete and the system is in " + ClusterState.ACTIVE + " state");
        }
    }
    boolean invalidOperation = false;
    String message = null;
    String dataverse = defaultDataverse != null ? defaultDataverse.getDataverseName() : null;
    switch(stmt.getKind()) {
        case INSERT:
            InsertStatement insertStmt = (InsertStatement) stmt;
            if (insertStmt.getDataverseName() != null) {
                dataverse = insertStmt.getDataverseName().getValue();
            }
            invalidOperation = MetadataConstants.METADATA_DATAVERSE_NAME.equals(dataverse);
            if (invalidOperation) {
                message = "Insert operation is not permitted in dataverse " + MetadataConstants.METADATA_DATAVERSE_NAME;
            }
            break;
        case DELETE:
            DeleteStatement deleteStmt = (DeleteStatement) stmt;
            if (deleteStmt.getDataverseName() != null) {
                dataverse = deleteStmt.getDataverseName().getValue();
            }
            invalidOperation = MetadataConstants.METADATA_DATAVERSE_NAME.equals(dataverse);
            if (invalidOperation) {
                message = "Delete operation is not permitted in dataverse " + MetadataConstants.METADATA_DATAVERSE_NAME;
            }
            break;
        case DATAVERSE_DROP:
            DataverseDropStatement dvDropStmt = (DataverseDropStatement) stmt;
            invalidOperation = MetadataConstants.METADATA_DATAVERSE_NAME.equals(dvDropStmt.getDataverseName().getValue());
            if (invalidOperation) {
                message = "Cannot drop dataverse:" + dvDropStmt.getDataverseName().getValue();
            }
            break;
        case DATASET_DROP:
            DropDatasetStatement dropStmt = (DropDatasetStatement) stmt;
            if (dropStmt.getDataverseName() != null) {
                dataverse = dropStmt.getDataverseName().getValue();
            }
            invalidOperation = MetadataConstants.METADATA_DATAVERSE_NAME.equals(dataverse);
            if (invalidOperation) {
                message = "Cannot drop a dataset belonging to the dataverse:" + MetadataConstants.METADATA_DATAVERSE_NAME;
            }
            break;
        case DATASET_DECL:
            DatasetDecl datasetStmt = (DatasetDecl) stmt;
            Map<String, String> hints = datasetStmt.getHints();
            if (hints != null && !hints.isEmpty()) {
                StringBuilder errorMsgBuffer = new StringBuilder();
                for (Entry<String, String> hint : hints.entrySet()) {
                    Pair<Boolean, String> validationResult = DatasetHints.validate(appCtx, hint.getKey(), hint.getValue());
                    if (!validationResult.first) {
                        errorMsgBuffer.append("Dataset: ").append(datasetStmt.getName().getValue()).append(" error in processing hint: ").append(hint.getKey()).append(" ").append(validationResult.second);
                        errorMsgBuffer.append(" \n");
                    }
                }
                invalidOperation = errorMsgBuffer.length() > 0;
                if (invalidOperation) {
                    message = errorMsgBuffer.toString();
                }
            }
            break;
        default:
            break;
    }
    if (invalidOperation) {
        throw new AsterixException("Invalid operation - " + message);
    }
}
#end_block

#method_before
@Override
public void init() throws HyracksDataException {
    numSamples = 0;
    recordBuilder.init();
    rangeMapBits.reset();
    // write a dummy integer at the beginning to be filled later with the actual number of samples taken
    IntegerSerializerDeserializer.write(0, rangeMapBits.getDataOutput());
}
#method_after
@Override
public void init() throws HyracksDataException {
    numSamples = 0;
    rangeMapBits.reset();
    // write a dummy integer at the beginning to be filled later with the actual number of samples taken
    IntegerSerializerDeserializer.write(0, rangeMapBits.getDataOutput());
}
#end_block

#method_before
@Override
public IScalarEvaluatorFactory createEvaluatorFactory(final IScalarEvaluatorFactory[] args) throws AlgebricksException {
    return new IScalarEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IScalarEvaluator createScalarEvaluator(final IHyracksTaskContext ctx) throws HyracksDataException {
            return new ArrayRemoveEval(args, ctx);
        }
    };
}
#method_after
@Override
public IScalarEvaluatorFactory createEvaluatorFactory(final IScalarEvaluatorFactory[] args) throws AlgebricksException {
    return new IScalarEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IScalarEvaluator createScalarEvaluator(final IHyracksTaskContext ctx) throws HyracksDataException {
            return new ArrayRemoveEval(args, ctx, argTypes);
        }
    };
}
#end_block

#method_before
private IBinaryComparator[] createValuesComparators(IAType[] argTypes) {
    // one comparator for each value since the values will not be opened (they won't be added to a list).
    // for the list item, it's either the item type if input list is determined to be a list or ANY if not.
    IAType itemType = argTypes[0].getTypeTag().isListType() ? ((AbstractCollectionType) argTypes[0]).getItemType() : BuiltinType.ANY;
    IBinaryComparator[] comp = new IBinaryComparator[argTypes.length - 1];
    for (int i = 1; i < argTypes.length; i++) {
        comp[i - 1] = BinaryComparatorFactoryProvider.INSTANCE.getBinaryComparatorFactory(itemType, argTypes[i], true).createBinaryComparator();
    }
    return comp;
}
#method_after
private static IBinaryComparator[] createValuesComparators(IAType[] argTypes) {
    // one comparator for each value since the values will not be opened (they won't be added to a list).
    // for the list item, it's either the item type if input list is determined to be a list or ANY if not.
    IAType itemType = argTypes[0].getTypeTag().isListType() ? ((AbstractCollectionType) argTypes[0]).getItemType() : BuiltinType.ANY;
    IBinaryComparator[] comparators = new IBinaryComparator[argTypes.length - 1];
    for (int i = 1; i < argTypes.length; i++) {
        comparators[i - 1] = BinaryComparatorFactoryProvider.INSTANCE.getBinaryComparatorFactory(itemType, argTypes[i], true).createBinaryComparator();
    }
    return comparators;
}
#end_block

#method_before
private boolean fingAggFuncExprRef(List<Mutable<ILogicalExpression>> exprRefs, LogicalVariable aggVar, List<Mutable<ILogicalExpression>> srcAssignExprRefs) {
    for (Mutable<ILogicalExpression> exprRef : exprRefs) {
        ILogicalExpression expr = exprRef.getValue();
        if (expr.getExpressionTag() == LogicalExpressionTag.VARIABLE) {
            if (((VariableReferenceExpression) expr).getVariableReference().equals(aggVar)) {
                return false;
            }
        }
        if (expr.getExpressionTag() != LogicalExpressionTag.FUNCTION_CALL) {
            continue;
        }
        AbstractFunctionCallExpression funcExpr = (AbstractFunctionCallExpression) expr;
        FunctionIdentifier funcIdent = BuiltinFunctions.getAggregateFunction(funcExpr.getFunctionIdentifier());
        if (funcIdent == null) {
            // Recursively look in func args.
            if (fingAggFuncExprRef(funcExpr.getArguments(), aggVar, srcAssignExprRefs) == false) {
                return false;
            }
        } else {
            // Check if this is the expr that uses aggVar.
            Collection<LogicalVariable> usedVars = new HashSet<LogicalVariable>();
            funcExpr.getUsedVariables(usedVars);
            if (usedVars.contains(aggVar)) {
                srcAssignExprRefs.add(exprRef);
            }
        }
    }
    return true;
}
#method_after
private boolean fingAggFuncExprRef(List<Mutable<ILogicalExpression>> exprRefs, LogicalVariable aggVar, List<Mutable<ILogicalExpression>> srcAssignExprRefs) {
    for (Mutable<ILogicalExpression> exprRef : exprRefs) {
        ILogicalExpression expr = exprRef.getValue();
        if ((expr.getExpressionTag() == LogicalExpressionTag.VARIABLE) && ((VariableReferenceExpression) expr).getVariableReference().equals(aggVar)) {
            return false;
        }
        if (expr.getExpressionTag() != LogicalExpressionTag.FUNCTION_CALL) {
            continue;
        }
        AbstractFunctionCallExpression funcExpr = (AbstractFunctionCallExpression) expr;
        FunctionIdentifier funcIdent = BuiltinFunctions.getAggregateFunction(funcExpr.getFunctionIdentifier());
        if (funcIdent == null) {
            // Recursively look in func args.
            if (fingAggFuncExprRef(funcExpr.getArguments(), aggVar, srcAssignExprRefs) == false) {
                return false;
            }
        } else {
            // Check if this is the expr that uses aggVar.
            Collection<LogicalVariable> usedVars = new HashSet<LogicalVariable>();
            funcExpr.getUsedVariables(usedVars);
            if (usedVars.contains(aggVar)) {
                srcAssignExprRefs.add(exprRef);
            }
        }
    }
    return true;
}
#end_block

#method_before
protected Pair<Boolean, Mutable<ILogicalOperator>> tryToPushAgg(AggregateOperator initAgg, GroupByOperator newGbyOp, Set<SimilarAggregatesInfo> toReplaceSet, IOptimizationContext context) throws AlgebricksException {
    SourceLocation sourceLoc = initAgg.getSourceLocation();
    List<LogicalVariable> initVars = initAgg.getVariables();
    List<Mutable<ILogicalExpression>> initExprs = initAgg.getExpressions();
    int numExprs = initVars.size();
    // First make sure that all agg funcs are two step, otherwise we cannot use local aggs.
    for (int i = 0; i < numExprs; i++) {
        AggregateFunctionCallExpression aggFun = (AggregateFunctionCallExpression) initExprs.get(i).getValue();
        if (!aggFun.isTwoStep()) {
            return new Pair<>(false, null);
        }
    }
    ArrayList<LogicalVariable> pushedVars = new ArrayList<>();
    ArrayList<Mutable<ILogicalExpression>> pushedExprs = new ArrayList<>();
    boolean haveAggToReplace = false;
    for (int i = 0; i < numExprs; i++) {
        Mutable<ILogicalExpression> expRef = initExprs.get(i);
        AggregateFunctionCallExpression aggFun = (AggregateFunctionCallExpression) expRef.getValue();
        SourceLocation aggFunSourceLoc = aggFun.getSourceLocation();
        IFunctionInfo fi1 = aggFun.getStepOneAggregate();
        // Clone the aggregate's args.
        List<Mutable<ILogicalExpression>> newArgs = new ArrayList<>(aggFun.getArguments().size());
        for (Mutable<ILogicalExpression> er : aggFun.getArguments()) {
            newArgs.add(new MutableObject<>(er.getValue().cloneExpression()));
        }
        IFunctionInfo fi2 = aggFun.getStepTwoAggregate();
        SimilarAggregatesInfo inf = new SimilarAggregatesInfo();
        LogicalVariable newAggVar = context.newVar();
        pushedVars.add(newAggVar);
        VariableReferenceExpression newAggVarRef = new VariableReferenceExpression(newAggVar);
        newAggVarRef.setSourceLocation(aggFunSourceLoc);
        inf.stepOneResult = newAggVarRef;
        inf.simAggs = new ArrayList<>();
        toReplaceSet.add(inf);
        AggregateFunctionCallExpression aggLocal = new AggregateFunctionCallExpression(fi1, false, newArgs);
        aggLocal.setSourceLocation(aggFunSourceLoc);
        pushedExprs.add(new MutableObject<>(aggLocal));
        AggregateExprInfo aei = new AggregateExprInfo();
        aei.aggExprRef = expRef;
        aei.newFunInfo = fi2;
        inf.simAggs.add(aei);
        haveAggToReplace = true;
    }
    if (!pushedVars.isEmpty()) {
        AggregateOperator pushedAgg = new AggregateOperator(pushedVars, pushedExprs);
        pushedAgg.setSourceLocation(sourceLoc);
        pushedAgg.setExecutionMode(ExecutionMode.LOCAL);
        // If newGbyOp is null, then we optimizing an aggregate without group by.
        if (newGbyOp != null) {
            // Cut and paste nested input pipelines of initAgg to pushedAgg's input
            Mutable<ILogicalOperator> inputRef = initAgg.getInputs().get(0);
            if (!isPushableInput(inputRef.getValue())) {
                return new Pair<>(false, null);
            }
            Mutable<ILogicalOperator> bottomRef = inputRef;
            while (bottomRef.getValue().getInputs().size() > 0) {
                bottomRef = bottomRef.getValue().getInputs().get(0);
                if (!isPushableInput(bottomRef.getValue())) {
                    return new Pair<>(false, null);
                }
            }
            ILogicalOperator oldNts = bottomRef.getValue();
            initAgg.getInputs().clear();
            initAgg.getInputs().add(new MutableObject<>(oldNts));
            // Hook up the nested aggregate op with the outer group by.
            NestedTupleSourceOperator nts = new NestedTupleSourceOperator(new MutableObject<>(newGbyOp));
            nts.setSourceLocation(sourceLoc);
            nts.setExecutionMode(ExecutionMode.LOCAL);
            bottomRef.setValue(nts);
            pushedAgg.getInputs().add(inputRef);
        } else {
            // The local aggregate operator is fed by the input of the original aggregate operator.
            pushedAgg.getInputs().add(new MutableObject<>(initAgg.getInputs().get(0).getValue()));
            // Reintroduce assign op for the global agg partitioning var.
            initAgg.getInputs().get(0).setValue(pushedAgg);
            pushedAgg.setGlobal(false);
            context.computeAndSetTypeEnvironmentForOperator(pushedAgg);
        }
        return new Pair<>(true, new MutableObject<ILogicalOperator>(pushedAgg));
    } else {
        return new Pair<>(haveAggToReplace, null);
    }
}
#method_after
protected Pair<Boolean, Mutable<ILogicalOperator>> tryToPushAgg(AggregateOperator initAgg, GroupByOperator newGbyOp, Set<SimilarAggregatesInfo> toReplaceSet, IOptimizationContext context) throws AlgebricksException {
    SourceLocation sourceLoc = initAgg.getSourceLocation();
    List<LogicalVariable> initVars = initAgg.getVariables();
    List<Mutable<ILogicalExpression>> initExprs = initAgg.getExpressions();
    int numExprs = initVars.size();
    // First make sure that all agg funcs are two step, otherwise we cannot use local aggs.
    for (int i = 0; i < numExprs; i++) {
        AggregateFunctionCallExpression aggFun = (AggregateFunctionCallExpression) initExprs.get(i).getValue();
        if (!aggFun.isTwoStep()) {
            return new Pair<>(false, null);
        }
    }
    ArrayList<LogicalVariable> pushedVars = new ArrayList<>();
    ArrayList<Mutable<ILogicalExpression>> pushedExprs = new ArrayList<>();
    boolean haveAggToReplace = false;
    for (int i = 0; i < numExprs; i++) {
        Mutable<ILogicalExpression> expRef = initExprs.get(i);
        AggregateFunctionCallExpression aggFun = (AggregateFunctionCallExpression) expRef.getValue();
        SourceLocation aggFunSourceLoc = aggFun.getSourceLocation();
        IFunctionInfo fi1 = aggFun.getStepOneAggregate();
        // Clone the aggregate's args.
        List<Mutable<ILogicalExpression>> newArgs = new ArrayList<>(aggFun.getArguments().size());
        for (Mutable<ILogicalExpression> er : aggFun.getArguments()) {
            newArgs.add(new MutableObject<>(er.getValue().cloneExpression()));
        }
        IFunctionInfo fi2 = aggFun.getStepTwoAggregate();
        SimilarAggregatesInfo inf = new SimilarAggregatesInfo();
        LogicalVariable newAggVar = context.newVar();
        pushedVars.add(newAggVar);
        VariableReferenceExpression newAggVarRef = new VariableReferenceExpression(newAggVar);
        newAggVarRef.setSourceLocation(aggFunSourceLoc);
        inf.stepOneResult = newAggVarRef;
        inf.simAggs = new ArrayList<>();
        toReplaceSet.add(inf);
        AggregateFunctionCallExpression aggLocal = new AggregateFunctionCallExpression(fi1, false, newArgs);
        aggLocal.setSourceLocation(aggFunSourceLoc);
        pushedExprs.add(new MutableObject<>(aggLocal));
        AggregateExprInfo aei = new AggregateExprInfo();
        aei.aggExprRef = expRef;
        aei.newFunInfo = fi2;
        inf.simAggs.add(aei);
        haveAggToReplace = true;
    }
    if (!pushedVars.isEmpty()) {
        AggregateOperator pushedAgg = new AggregateOperator(pushedVars, pushedExprs);
        pushedAgg.setSourceLocation(sourceLoc);
        pushedAgg.setExecutionMode(ExecutionMode.LOCAL);
        // If newGbyOp is null, then we optimizing an aggregate without group by.
        if (newGbyOp != null) {
            // Cut and paste nested input pipelines of initAgg to pushedAgg's input
            Mutable<ILogicalOperator> inputRef = initAgg.getInputs().get(0);
            if (!isPushableInput(inputRef.getValue())) {
                return new Pair<>(false, null);
            }
            Mutable<ILogicalOperator> bottomRef = inputRef;
            while (!bottomRef.getValue().getInputs().isEmpty()) {
                bottomRef = bottomRef.getValue().getInputs().get(0);
                if (!isPushableInput(bottomRef.getValue())) {
                    return new Pair<>(false, null);
                }
            }
            ILogicalOperator oldNts = bottomRef.getValue();
            initAgg.getInputs().clear();
            initAgg.getInputs().add(new MutableObject<>(oldNts));
            // Hook up the nested aggregate op with the outer group by.
            NestedTupleSourceOperator nts = new NestedTupleSourceOperator(new MutableObject<>(newGbyOp));
            nts.setSourceLocation(sourceLoc);
            nts.setExecutionMode(ExecutionMode.LOCAL);
            bottomRef.setValue(nts);
            pushedAgg.getInputs().add(inputRef);
        } else {
            // The local aggregate operator is fed by the input of the original aggregate operator.
            pushedAgg.getInputs().add(new MutableObject<>(initAgg.getInputs().get(0).getValue()));
            // Reintroduce assign op for the global agg partitioning var.
            initAgg.getInputs().get(0).setValue(pushedAgg);
            pushedAgg.setGlobal(false);
            context.computeAndSetTypeEnvironmentForOperator(pushedAgg);
        }
        return new Pair<>(true, new MutableObject<ILogicalOperator>(pushedAgg));
    } else {
        return new Pair<>(haveAggToReplace, null);
    }
}
#end_block

#method_before
@Override
public IScalarEvaluatorFactory createEvaluatorFactory(final IScalarEvaluatorFactory[] args) throws AlgebricksException {
    // The aggregate function will get a SingleFieldFrameTupleReference that points to the result of the ScanCollection.
    // The list-item will always reside in the first field (column) of the SingleFieldFrameTupleReference.
    int numArgs = aggFuncDesc.getNumArguments();
    // array size  should depend of TypeInferer; how to get to TypeInferener
    IScalarEvaluatorFactory[] aggFuncArgs = new IScalarEvaluatorFactory[numArgs];
    aggFuncArgs[0] = new ColumnAccessEvalFactory(0);
    for (int i = 1; i < numArgs; ++i) {
        aggFuncArgs[i] = args[i];
    }
    // Create aggregate function from this scalar version.
    final IAggregateEvaluatorFactory aggFuncFactory = aggFuncDesc.createAggregateEvaluatorFactory(aggFuncArgs);
    return new IScalarEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IScalarEvaluator createScalarEvaluator(IHyracksTaskContext ctx) throws HyracksDataException {
            // Use ScanCollection to iterate over list items.
            ScanCollectionUnnestingFunctionFactory scanCollectionFactory = new ScanCollectionUnnestingFunctionFactory(args[0], sourceLoc);
            return new GenericScalarAggregateFunction(aggFuncFactory.createAggregateEvaluator(ctx), scanCollectionFactory, ctx);
        }
    };
}
#method_after
@Override
public IScalarEvaluatorFactory createEvaluatorFactory(final IScalarEvaluatorFactory[] args) throws AlgebricksException {
    // The aggregate function will get a SingleFieldFrameTupleReference that points to the result of the
    // ScanCollection. The list-item will always reside in the first field (column) of the
    // SingleFieldFrameTupleReference.
    int numArgs = args.length;
    IScalarEvaluatorFactory[] aggFuncArgs = new IScalarEvaluatorFactory[numArgs];
    aggFuncArgs[0] = new ColumnAccessEvalFactory(0);
    for (int i = 1; i < numArgs; ++i) {
        aggFuncArgs[i] = args[i];
    }
    // Create aggregate function from this scalar version.
    final IAggregateEvaluatorFactory aggFuncFactory = aggFuncDesc.createAggregateEvaluatorFactory(aggFuncArgs);
    return new IScalarEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IScalarEvaluator createScalarEvaluator(IHyracksTaskContext ctx) throws HyracksDataException {
            // Use ScanCollection to iterate over list items.
            ScanCollectionUnnestingFunctionFactory scanCollectionFactory = new ScanCollectionUnnestingFunctionFactory(args[0], sourceLoc);
            return createScalarAggregateEvaluator(aggFuncFactory.createAggregateEvaluator(ctx), scanCollectionFactory, ctx);
        }
    };
}
#end_block

#method_before
@Override
public void nextFrame(ByteBuffer buffer) throws HyracksDataException {
    accessor.reset(buffer);
    ILSMIndexAccessor lsmAccessor = (ILSMIndexAccessor) indexAccessor;
    int tupleCount = accessor.getTupleCount();
    for (int i = 0; i < tupleCount; i++) {
        try {
            frameTuple.reset(accessor, i);
            boolean isUpsert = upsertIndicatorInspector.getBooleanValue(frameTuple.getFieldData(upsertIndicatorFieldIndex), frameTuple.getFieldStart(upsertIndicatorFieldIndex), frameTuple.getFieldLength(upsertIndicatorFieldIndex));
            // if both previous value and new value are null, then we skip
            tuple.reset(accessor, i);
            prevValueTuple.reset(accessor, i);
            boolean isNewValueMissing = isMissing(tuple, 0);
            boolean isNewValueNull = isNull(tuple, 0);
            boolean isOldValueMissing = isMissing(prevValueTuple, 0);
            boolean isOldValueNull = isNull(prevValueTuple, 0);
            if (isNewValueMissing && isOldValueMissing) {
                // No op
                continue;
            }
            // At least, one is not null
            if (!isPrimaryKeyIndex && TupleUtils.equalTuples(tuple, prevValueTuple, numberOfFields)) {
                // which are always the same
                continue;
            }
            if (!isOldValueMissing && !isOldValueNull) {
                // We need to delete previous
                abstractModCallback.setOp(Operation.DELETE);
                lsmAccessor.forceDelete(prevValueTuple);
            }
            if (isUpsert && !isNewValueMissing && !isNewValueNull) {
                // we need to insert the new value
                abstractModCallback.setOp(Operation.INSERT);
                lsmAccessor.forceInsert(tuple);
            }
        } catch (Exception e) {
            throw HyracksDataException.create(e);
        }
    }
    // No partial flushing was necessary. Forward entire frame.
    writeBuffer.ensureFrameSize(buffer.capacity());
    FrameUtils.copyAndFlip(buffer, writeBuffer.getBuffer());
    FrameUtils.flushFrame(writeBuffer.getBuffer(), writer);
}
#method_after
@Override
public void nextFrame(ByteBuffer buffer) throws HyracksDataException {
    accessor.reset(buffer);
    ILSMIndexAccessor lsmAccessor = (ILSMIndexAccessor) indexAccessor;
    int tupleCount = accessor.getTupleCount();
    for (int i = 0; i < tupleCount; i++) {
        try {
            frameTuple.reset(accessor, i);
            boolean isUpsert = upsertIndicatorInspector.getBooleanValue(frameTuple.getFieldData(upsertIndicatorFieldIndex), frameTuple.getFieldStart(upsertIndicatorFieldIndex), frameTuple.getFieldLength(upsertIndicatorFieldIndex));
            // if both previous value and new value are null, then we skip
            tuple.reset(accessor, i);
            prevValueTuple.reset(accessor, i);
            boolean isNewValueNullOrMissing = isNullOrMissing(tuple);
            boolean isOldValueNullOrMissing = isNullOrMissing(prevValueTuple);
            if (isNewValueNullOrMissing && isOldValueNullOrMissing) {
                // No op
                continue;
            }
            // At least, one is not null
            if (!isPrimaryKeyIndex && TupleUtils.equalTuples(tuple, prevValueTuple, numberOfFields)) {
                // which are always the same
                continue;
            }
            if (!isOldValueNullOrMissing) {
                // We need to delete previous
                abstractModCallback.setOp(Operation.DELETE);
                lsmAccessor.forceDelete(prevValueTuple);
            }
            if (isUpsert && !isNewValueNullOrMissing) {
                // we need to insert the new value
                abstractModCallback.setOp(Operation.INSERT);
                lsmAccessor.forceInsert(tuple);
            }
        } catch (Exception e) {
            throw HyracksDataException.create(e);
        }
    }
    // No partial flushing was necessary. Forward entire frame.
    writeBuffer.ensureFrameSize(buffer.capacity());
    FrameUtils.copyAndFlip(buffer, writeBuffer.getBuffer());
    FrameUtils.flushFrame(writeBuffer.getBuffer(), writer);
}
#end_block

#method_before
@Override
protected IDatasourceFunction createFunction(MetadataProvider metadataProvider, AlgebricksAbsolutePartitionConstraint locations) {
    AlgebricksAbsolutePartitionConstraint randomLocation = AlgebricksAbsolutePartitionConstraint.randomLocation(locations.getLocations());
    return new ClientRequestsFunction(randomLocation, ClientRequestsRequest.RequestsType.RUNNING);
}
#method_after
@Override
protected IDatasourceFunction createFunction(MetadataProvider metadataProvider, AlgebricksAbsolutePartitionConstraint locations) {
    AlgebricksAbsolutePartitionConstraint randomLocation = AlgebricksAbsolutePartitionConstraint.randomLocation(locations.getLocations());
    return new ClientRequestsFunction(randomLocation, ClientRequestsRequest.RequestType.RUNNING);
}
#end_block

#method_before
@Override
protected IDatasourceFunction createFunction(MetadataProvider metadataProvider, AlgebricksAbsolutePartitionConstraint locations) {
    AlgebricksAbsolutePartitionConstraint randomLocation = AlgebricksAbsolutePartitionConstraint.randomLocation(locations.getLocations());
    return new ClientRequestsFunction(randomLocation, ClientRequestsRequest.RequestsType.COMPLETED);
}
#method_after
@Override
protected IDatasourceFunction createFunction(MetadataProvider metadataProvider, AlgebricksAbsolutePartitionConstraint locations) {
    AlgebricksAbsolutePartitionConstraint randomLocation = AlgebricksAbsolutePartitionConstraint.randomLocation(locations.getLocations());
    return new ClientRequestsFunction(randomLocation, ClientRequestsRequest.RequestType.COMPLETED);
}
#end_block

#method_before
@Override
public IRecordReader<char[]> createRecordReader(IHyracksTaskContext ctx, int partition) throws HyracksDataException {
    INCServiceContext serviceCtx = ctx.getJobletContext().getServiceContext();
    INCMessageBroker messageBroker = (INCMessageBroker) serviceCtx.getMessageBroker();
    MessageFuture messageFuture = messageBroker.registerMessageFuture();
    long futureId = messageFuture.getFutureId();
    ClientRequestsRequest request = new ClientRequestsRequest(serviceCtx.getNodeId(), futureId, requestsType);
    try {
        messageBroker.sendMessageToPrimaryCC(request);
        ClientRequestsResponse response = (ClientRequestsResponse) messageFuture.get(DEFAULT_NC_TIMEOUT_MILLIS, TimeUnit.MILLISECONDS);
        return new ClientRequestsReader(response.getRequests());
    } catch (Exception e) {
        LOGGER.warn("Could not retrieve active requests", e);
        throw HyracksDataException.create(e);
    } finally {
        messageBroker.deregisterMessageFuture(futureId);
    }
}
#method_after
@Override
public IRecordReader<char[]> createRecordReader(IHyracksTaskContext ctx, int partition) throws HyracksDataException {
    INCServiceContext serviceCtx = ctx.getJobletContext().getServiceContext();
    INCMessageBroker messageBroker = (INCMessageBroker) serviceCtx.getMessageBroker();
    MessageFuture messageFuture = messageBroker.registerMessageFuture();
    long futureId = messageFuture.getFutureId();
    ClientRequestsRequest request = new ClientRequestsRequest(serviceCtx.getNodeId(), futureId, requestType);
    try {
        messageBroker.sendMessageToPrimaryCC(request);
        ClientRequestsResponse response = (ClientRequestsResponse) messageFuture.get(DEFAULT_NC_TIMEOUT_MILLIS, TimeUnit.MILLISECONDS);
        return new ClientRequestsReader(response.getRequests());
    } catch (Exception e) {
        LOGGER.warn("Could not retrieve active requests", e);
        throw HyracksDataException.create(e);
    } finally {
        messageBroker.deregisterMessageFuture(futureId);
    }
}
#end_block

#method_before
@Override
public void handle(ICcApplicationContext appCtx) throws HyracksDataException, InterruptedException {
    Collection<IClientRequest> clientRequests;
    switch(requestsType) {
        case RUNNING:
            clientRequests = appCtx.getRequestTracker().getRunningRequests();
            break;
        case COMPLETED:
            clientRequests = appCtx.getRequestTracker().getCompletedRequests();
            break;
        default:
            throw new IllegalStateException("unrecognized requests type: " + requestsType);
    }
    final String[] requests = clientRequests.stream().map(IClientRequest::toJson).toArray(String[]::new);
    ClientRequestsResponse response = new ClientRequestsResponse(reqId, requests);
    CCMessageBroker messageBroker = (CCMessageBroker) appCtx.getServiceContext().getMessageBroker();
    try {
        messageBroker.sendApplicationMessageToNC(response, nodeId);
    } catch (Exception e) {
        LOGGER.log(Level.WARN, "Failure sending response to nc", e);
    }
}
#method_after
@Override
public void handle(ICcApplicationContext appCtx) throws HyracksDataException, InterruptedException {
    Collection<IClientRequest> clientRequests;
    switch(requestType) {
        case RUNNING:
            clientRequests = appCtx.getRequestTracker().getRunningRequests();
            break;
        case COMPLETED:
            clientRequests = appCtx.getRequestTracker().getCompletedRequests();
            break;
        default:
            throw new IllegalStateException("unrecognized request type: " + requestType);
    }
    final String[] requests = clientRequests.stream().map(IClientRequest::toJson).toArray(String[]::new);
    ClientRequestsResponse response = new ClientRequestsResponse(reqId, requests);
    CCMessageBroker messageBroker = (CCMessageBroker) appCtx.getServiceContext().getMessageBroker();
    try {
        messageBroker.sendApplicationMessageToNC(response, nodeId);
    } catch (Exception e) {
        LOGGER.log(Level.WARN, "Failure sending response to nc", e);
    }
}
#end_block

#method_before
@Override
protected void processList(ListAccessor listAccessor, IAsterixListBuilder listBuilder) throws IOException {
    distinctHelper.reset();
    item = pointableAllocator.allocateEmpty();
    storage = (ArrayBackedValueStorage) storageAllocator.allocate(null);
    boolean nullMissingWasAdded = false;
    for (int i = 0; i < listAccessor.size(); i++) {
        // get the item and compute its hash
        boolean itemInStorage = listAccessor.getOrWriteItem(i, item, storage);
        if (isNullOrMissing(item)) {
            if (!nullMissingWasAdded) {
                listBuilder.addItem(item);
                nullMissingWasAdded = true;
            }
        } else if (distinctHelper.add(item)) {
            listBuilder.addItem(item);
            item = pointableAllocator.allocateEmpty();
            if (itemInStorage) {
                // create new storage since the added item is using it now
                storage = (ArrayBackedValueStorage) storageAllocator.allocate(null);
            }
        }
    }
}
#method_after
@Override
protected void processList(ListAccessor listAccessor, IAsterixListBuilder listBuilder) throws IOException {
    itemSet.clear();
    item = pointableAllocator.allocateEmpty();
    storage = (ArrayBackedValueStorage) storageAllocator.allocate(null);
    boolean nullMissingWasAdded = false;
    for (int i = 0; i < listAccessor.size(); i++) {
        // get the item and compute its hash
        boolean itemInStorage = listAccessor.getOrWriteItem(i, item, storage);
        if (isNullOrMissing(item)) {
            if (!nullMissingWasAdded) {
                listBuilder.addItem(item);
                nullMissingWasAdded = true;
            }
        } else if (itemSet.add(item)) {
            listBuilder.addItem(item);
            item = pointableAllocator.allocateEmpty();
            if (itemInStorage) {
                // create new storage since the added item is using it now
                storage = (ArrayBackedValueStorage) storageAllocator.allocate(null);
            }
        }
    }
}
#end_block

#method_before
@Override
protected void aggInit() throws HyracksDataException {
    super.aggInit();
    storageAllocator.reset();
    arrayListAllocator.reset();
    distinctHelper.reset();
}
#method_after
@Override
protected void aggInit() throws HyracksDataException {
    super.aggInit();
    storageAllocator.reset();
    arrayListAllocator.reset();
    itemSet.clear();
}
#end_block

#method_before
@Override
protected void aggStep(IPointable item) throws HyracksDataException {
    if (distinctHelper.add(item)) {
        super.aggStep(item);
    }
}
#method_after
@Override
protected void aggStep(IPointable item) throws HyracksDataException {
    if (itemSet.add(item)) {
        super.aggStep(item);
    }
}
#end_block

#method_before
protected IScalarEvaluator createScalarAggregateEvaluator(IAggregateEvaluator aggEval, ScanCollectionDescriptor.ScanCollectionUnnestingFunctionFactory scanCollectionFactory, IHyracksTaskContext ctx) throws HyracksDataException {
    return new GenericScalarDistinctAggregateFunction(aggEval, scanCollectionFactory, ctx, sourceLoc);
}
#method_after
@Override
protected IScalarEvaluator createScalarAggregateEvaluator(IAggregateEvaluator aggEval, ScanCollectionDescriptor.ScanCollectionUnnestingFunctionFactory scanCollectionFactory, IHyracksTaskContext ctx) throws HyracksDataException {
    return new GenericScalarDistinctAggregateFunction(aggEval, scanCollectionFactory, ctx, sourceLoc);
}
#end_block

#method_before
public static FunctionCollection createDefaultFunctionCollection() {
    FunctionCollection fc = new FunctionCollection();
    // array functions
    fc.add(ArrayRemoveDescriptor.FACTORY);
    fc.add(ArrayPutDescriptor.FACTORY);
    fc.add(ArrayPrependDescriptor.FACTORY);
    fc.add(ArrayAppendDescriptor.FACTORY);
    fc.add(ArrayInsertDescriptor.FACTORY);
    fc.addGenerated(ArrayPositionDescriptor.FACTORY);
    fc.addGenerated(ArrayRepeatDescriptor.FACTORY);
    fc.addGenerated(ArrayContainsDescriptor.FACTORY);
    fc.addGenerated(ArrayReverseDescriptor.FACTORY);
    fc.addGenerated(ArraySortDescriptor.FACTORY);
    fc.addGenerated(ArrayDistinctDescriptor.FACTORY);
    fc.addGenerated(ArrayUnionDescriptor.FACTORY);
    fc.addGenerated(ArrayIntersectDescriptor.FACTORY);
    fc.addGenerated(ArrayIfNullDescriptor.FACTORY);
    fc.addGenerated(ArrayConcatDescriptor.FACTORY);
    fc.addGenerated(ArrayRangeDescriptor.FACTORY);
    fc.addGenerated(ArrayFlattenDescriptor.FACTORY);
    fc.add(ArrayReplaceDescriptor.FACTORY);
    fc.addGenerated(ArraySliceWithEndPositionDescriptor.FACTORY);
    fc.addGenerated(ArraySliceWithoutEndPositionDescriptor.FACTORY);
    fc.addGenerated(ArraySymDiffDescriptor.FACTORY);
    fc.addGenerated(ArraySymDiffnDescriptor.FACTORY);
    fc.addGenerated(ArrayStarDescriptor.FACTORY);
    // unnesting functions
    fc.add(TidRunningAggregateDescriptor.FACTORY);
    fc.add(ScanCollectionDescriptor.FACTORY);
    fc.add(RangeDescriptor.FACTORY);
    fc.add(SubsetCollectionDescriptor.FACTORY);
    // aggregate functions
    fc.add(ListifyAggregateDescriptor.FACTORY);
    fc.add(CountAggregateDescriptor.FACTORY);
    fc.add(AvgAggregateDescriptor.FACTORY);
    fc.add(LocalAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SumAggregateDescriptor.FACTORY);
    fc.add(LocalSumAggregateDescriptor.FACTORY);
    fc.add(IntermediateSumAggregateDescriptor.FACTORY);
    fc.add(GlobalSumAggregateDescriptor.FACTORY);
    fc.add(MaxAggregateDescriptor.FACTORY);
    fc.add(LocalMaxAggregateDescriptor.FACTORY);
    fc.add(MinAggregateDescriptor.FACTORY);
    fc.add(LocalMinAggregateDescriptor.FACTORY);
    fc.add(FirstElementAggregateDescriptor.FACTORY);
    fc.add(LocalFirstElementAggregateDescriptor.FACTORY);
    fc.add(LastElementAggregateDescriptor.FACTORY);
    fc.add(StddevAggregateDescriptor.FACTORY);
    fc.add(LocalStddevAggregateDescriptor.FACTORY);
    fc.add(IntermediateStddevAggregateDescriptor.FACTORY);
    fc.add(GlobalStddevAggregateDescriptor.FACTORY);
    fc.add(LocalSamplingAggregateDescriptor.FACTORY);
    fc.add(RangeMapAggregateDescriptor.FACTORY);
    fc.add(StddevPopAggregateDescriptor.FACTORY);
    fc.add(LocalStddevPopAggregateDescriptor.FACTORY);
    fc.add(IntermediateStddevPopAggregateDescriptor.FACTORY);
    fc.add(GlobalStddevPopAggregateDescriptor.FACTORY);
    fc.add(VarAggregateDescriptor.FACTORY);
    fc.add(LocalVarAggregateDescriptor.FACTORY);
    fc.add(IntermediateVarAggregateDescriptor.FACTORY);
    fc.add(GlobalVarAggregateDescriptor.FACTORY);
    fc.add(VarPopAggregateDescriptor.FACTORY);
    fc.add(LocalVarPopAggregateDescriptor.FACTORY);
    fc.add(IntermediateVarPopAggregateDescriptor.FACTORY);
    fc.add(GlobalVarPopAggregateDescriptor.FACTORY);
    fc.add(KurtosisAggregateDescriptor.FACTORY);
    fc.add(LocalKurtosisAggregateDescriptor.FACTORY);
    fc.add(IntermediateKurtosisAggregateDescriptor.FACTORY);
    fc.add(GlobalKurtosisAggregateDescriptor.FACTORY);
    fc.add(SkewnessAggregateDescriptor.FACTORY);
    fc.add(LocalSkewnessAggregateDescriptor.FACTORY);
    fc.add(IntermediateSkewnessAggregateDescriptor.FACTORY);
    fc.add(GlobalSkewnessAggregateDescriptor.FACTORY);
    // serializable aggregates
    fc.add(SerializableCountAggregateDescriptor.FACTORY);
    fc.add(SerializableAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSumAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSumAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSumAggregateDescriptor.FACTORY);
    fc.add(SerializableStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableVarAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalVarAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateVarAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalVarAggregateDescriptor.FACTORY);
    fc.add(SerializableVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableKurtosisAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalKurtosisAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateKurtosisAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalKurtosisAggregateDescriptor.FACTORY);
    fc.add(SerializableSkewnessAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSkewnessAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSkewnessAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSkewnessAggregateDescriptor.FACTORY);
    // scalar aggregates
    fc.add(ScalarCountAggregateDescriptor.FACTORY);
    fc.add(ScalarCountDistinctAggregateDescriptor.FACTORY);
    fc.add(ScalarAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarAvgDistinctAggregateDescriptor.FACTORY);
    fc.add(ScalarSumAggregateDescriptor.FACTORY);
    fc.add(ScalarSumDistinctAggregateDescriptor.FACTORY);
    fc.add(ScalarMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarMaxDistinctAggregateDescriptor.FACTORY);
    fc.add(ScalarMinAggregateDescriptor.FACTORY);
    fc.add(ScalarMinDistinctAggregateDescriptor.FACTORY);
    fc.add(EmptyStreamAggregateDescriptor.FACTORY);
    fc.add(NonEmptyStreamAggregateDescriptor.FACTORY);
    fc.add(ScalarStddevAggregateDescriptor.FACTORY);
    fc.add(ScalarStddevDistinctAggregateDescriptor.FACTORY);
    fc.add(ScalarStddevPopAggregateDescriptor.FACTORY);
    fc.add(ScalarStddevPopDistinctAggregateDescriptor.FACTORY);
    fc.add(ScalarVarAggregateDescriptor.FACTORY);
    fc.add(ScalarVarDistinctAggregateDescriptor.FACTORY);
    fc.add(ScalarVarPopAggregateDescriptor.FACTORY);
    fc.add(ScalarVarPopDistinctAggregateDescriptor.FACTORY);
    fc.add(ScalarKurtosisAggregateDescriptor.FACTORY);
    fc.add(ScalarKurtosisDistinctAggregateDescriptor.FACTORY);
    fc.add(ScalarSkewnessAggregateDescriptor.FACTORY);
    fc.add(ScalarSkewnessDistinctAggregateDescriptor.FACTORY);
    // SQL aggregates
    fc.add(SqlCountAggregateDescriptor.FACTORY);
    fc.add(SqlAvgAggregateDescriptor.FACTORY);
    fc.add(LocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SqlSumAggregateDescriptor.FACTORY);
    fc.add(LocalSqlSumAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlSumAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SqlMaxAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMaxAggregateDescriptor.FACTORY);
    fc.add(SqlMinAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMinAggregateDescriptor.FACTORY);
    fc.add(SqlStddevAggregateDescriptor.FACTORY);
    fc.add(LocalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlStddevAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(LocalSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SqlVarAggregateDescriptor.FACTORY);
    fc.add(LocalSqlVarAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlVarAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlVarAggregateDescriptor.FACTORY);
    fc.add(SqlVarPopAggregateDescriptor.FACTORY);
    fc.add(LocalSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(SqlKurtosisAggregateDescriptor.FACTORY);
    fc.add(LocalSqlKurtosisAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlKurtosisAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlKurtosisAggregateDescriptor.FACTORY);
    fc.add(SqlSkewnessAggregateDescriptor.FACTORY);
    fc.add(LocalSqlSkewnessAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlSkewnessAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlSkewnessAggregateDescriptor.FACTORY);
    // SQL serializable aggregates
    fc.add(SerializableSqlCountAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlVarAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlVarAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlVarAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlVarAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlKurtosisAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlKurtosisAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlKurtosisAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlKurtosisAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlSkewnessAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlSkewnessAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlSkewnessAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlSkewnessAggregateDescriptor.FACTORY);
    // SQL scalar aggregates
    fc.add(ScalarSqlCountAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlCountDistinctAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlAvgDistinctAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlSumAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlSumDistinctAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMaxDistinctAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMinAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMinDistinctAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlStddevAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlStddevDistinctAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlStddevPopDistinctAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlVarAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlVarDistinctAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlVarPopDistinctAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlKurtosisAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlKurtosisDistinctAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlSkewnessAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlSkewnessDistinctAggregateDescriptor.FACTORY);
    // window functions
    fc.add(DenseRankRunningAggregateDescriptor.FACTORY);
    fc.add(NtileRunningAggregateDescriptor.FACTORY);
    fc.add(RankRunningAggregateDescriptor.FACTORY);
    fc.add(RowNumberRunningAggregateDescriptor.FACTORY);
    fc.add(PercentRankRunningAggregateDescriptor.FACTORY);
    fc.add(WinPartitionLenRunningAggregateDescriptor.FACTORY);
    // boolean functions
    fc.add(AndDescriptor.FACTORY);
    fc.add(OrDescriptor.FACTORY);
    // Record constructors / functions
    fc.add(ClosedRecordConstructorDescriptor.FACTORY);
    fc.add(OpenRecordConstructorDescriptor.FACTORY);
    fc.add(RecordConcatDescriptor.FACTORY);
    fc.add(RecordConcatStrictDescriptor.FACTORY);
    // List constructors
    fc.add(OrderedListConstructorDescriptor.FACTORY);
    fc.add(UnorderedListConstructorDescriptor.FACTORY);
    // Sleep function
    fc.add(SleepDescriptor.FACTORY);
    // Inject failure function
    fc.add(InjectFailureDescriptor.FACTORY);
    // Get Job Parameter function
    fc.add(GetJobParameterByNameDescriptor.FACTORY);
    // Switch case
    fc.add(SwitchCaseDescriptor.FACTORY);
    // null functions
    fc.add(IsMissingDescriptor.FACTORY);
    fc.add(IsNullDescriptor.FACTORY);
    fc.add(IsUnknownDescriptor.FACTORY);
    fc.add(IsSystemNullDescriptor.FACTORY);
    fc.add(CheckUnknownDescriptor.FACTORY);
    fc.add(IfMissingDescriptor.FACTORY);
    fc.add(IfNullDescriptor.FACTORY);
    fc.add(IfMissingOrNullDescriptor.FACTORY);
    fc.add(IfSystemNullDescriptor.FACTORY);
    // uuid generators (zero independent functions)
    fc.add(CreateUUIDDescriptor.FACTORY);
    fc.add(UUIDDescriptor.FACTORY);
    fc.add(CreateQueryUIDDescriptor.FACTORY);
    fc.add(RandomDescriptor.FACTORY);
    fc.add(CurrentDateDescriptor.FACTORY);
    fc.add(CurrentTimeDescriptor.FACTORY);
    fc.add(CurrentDateTimeDescriptor.FACTORY);
    // functions that need generated class for null-handling.
    // Element accessors.
    fc.addGenerated(FieldAccessByIndexDescriptor.FACTORY);
    fc.addGenerated(FieldAccessByNameDescriptor.FACTORY);
    fc.addGenerated(FieldAccessNestedDescriptor.FACTORY);
    fc.addGenerated(AnyCollectionMemberDescriptor.FACTORY);
    fc.addGenerated(GetItemDescriptor.FACTORY);
    // Numeric functions
    fc.add(IfInfDescriptor.FACTORY);
    fc.add(IfNanDescriptor.FACTORY);
    fc.add(IfNanOrInfDescriptor.FACTORY);
    fc.addGenerated(NumericUnaryMinusDescriptor.FACTORY);
    fc.addGenerated(NumericAddDescriptor.FACTORY);
    fc.addGenerated(NumericDivideDescriptor.FACTORY);
    fc.addGenerated(NumericDivDescriptor.FACTORY);
    fc.addGenerated(NumericMultiplyDescriptor.FACTORY);
    fc.addGenerated(NumericSubDescriptor.FACTORY);
    fc.addGenerated(NumericModuloDescriptor.FACTORY);
    fc.addGenerated(NumericPowerDescriptor.FACTORY);
    fc.addGenerated(NotDescriptor.FACTORY);
    fc.addGenerated(LenDescriptor.FACTORY);
    fc.addGenerated(NumericAbsDescriptor.FACTORY);
    fc.addGenerated(NumericCeilingDescriptor.FACTORY);
    fc.addGenerated(NumericFloorDescriptor.FACTORY);
    fc.addGenerated(NumericRoundDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEvenDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEven2Descriptor.FACTORY);
    fc.addGenerated(NumericACosDescriptor.FACTORY);
    fc.addGenerated(NumericASinDescriptor.FACTORY);
    fc.addGenerated(NumericATanDescriptor.FACTORY);
    fc.addGenerated(NumericDegreesDescriptor.FACTORY);
    fc.addGenerated(NumericRadiansDescriptor.FACTORY);
    fc.addGenerated(NumericCosDescriptor.FACTORY);
    fc.addGenerated(NumericCoshDescriptor.FACTORY);
    fc.addGenerated(NumericSinDescriptor.FACTORY);
    fc.addGenerated(NumericSinhDescriptor.FACTORY);
    fc.addGenerated(NumericTanDescriptor.FACTORY);
    fc.addGenerated(NumericTanhDescriptor.FACTORY);
    fc.addGenerated(NumericExpDescriptor.FACTORY);
    fc.addGenerated(NumericLnDescriptor.FACTORY);
    fc.addGenerated(NumericLogDescriptor.FACTORY);
    fc.addGenerated(NumericSqrtDescriptor.FACTORY);
    fc.addGenerated(NumericSignDescriptor.FACTORY);
    fc.addGenerated(NumericTruncDescriptor.FACTORY);
    fc.addGenerated(NumericATan2Descriptor.FACTORY);
    // Comparisons.
    fc.addGenerated(EqualsDescriptor.FACTORY);
    fc.addGenerated(GreaterThanDescriptor.FACTORY);
    fc.addGenerated(GreaterThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(LessThanDescriptor.FACTORY);
    fc.addGenerated(LessThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(NotEqualsDescriptor.FACTORY);
    // If-Equals functions
    fc.addGenerated(MissingIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NullIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NanIfEqualsDescriptor.FACTORY);
    fc.addGenerated(PosInfIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NegInfIfEqualsDescriptor.FACTORY);
    // Binary functions
    fc.addGenerated(BinaryLengthDescriptor.FACTORY);
    fc.addGenerated(ParseBinaryDescriptor.FACTORY);
    fc.addGenerated(PrintBinaryDescriptor.FACTORY);
    fc.addGenerated(BinaryConcatDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromToDescriptor.FACTORY);
    fc.addGenerated(FindBinaryDescriptor.FACTORY);
    fc.addGenerated(FindBinaryFromDescriptor.FACTORY);
    // String functions
    fc.addGenerated(StringLikeDescriptor.FACTORY);
    fc.addGenerated(StringContainsDescriptor.FACTORY);
    fc.addGenerated(StringEndsWithDescriptor.FACTORY);
    fc.addGenerated(StringStartsWithDescriptor.FACTORY);
    fc.addGenerated(SubstringDescriptor.FACTORY);
    fc.addGenerated(StringEqualDescriptor.FACTORY);
    fc.addGenerated(StringLowerCaseDescriptor.FACTORY);
    fc.addGenerated(StringUpperCaseDescriptor.FACTORY);
    fc.addGenerated(StringLengthDescriptor.FACTORY);
    fc.addGenerated(Substring2Descriptor.FACTORY);
    fc.addGenerated(SubstringBeforeDescriptor.FACTORY);
    fc.addGenerated(SubstringAfterDescriptor.FACTORY);
    fc.addGenerated(StringToCodePointDescriptor.FACTORY);
    fc.addGenerated(CodePointToStringDescriptor.FACTORY);
    fc.addGenerated(StringConcatDescriptor.FACTORY);
    fc.addGenerated(StringJoinDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringInitCapDescriptor.FACTORY);
    fc.addGenerated(StringTrimDescriptor.FACTORY);
    fc.addGenerated(StringLTrimDescriptor.FACTORY);
    fc.addGenerated(StringRTrimDescriptor.FACTORY);
    fc.addGenerated(StringTrim2Descriptor.FACTORY);
    fc.addGenerated(StringLTrim2Descriptor.FACTORY);
    fc.addGenerated(StringRTrim2Descriptor.FACTORY);
    fc.addGenerated(StringPositionDescriptor.FACTORY);
    fc.addGenerated(StringRepeatDescriptor.FACTORY);
    fc.addGenerated(StringReplaceDescriptor.FACTORY);
    fc.addGenerated(StringReplaceWithLimitDescriptor.FACTORY);
    fc.addGenerated(StringReverseDescriptor.FACTORY);
    fc.addGenerated(StringSplitDescriptor.FACTORY);
    // Constructors
    fc.addGenerated(ABooleanConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryHexStringConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryBase64StringConstructorDescriptor.FACTORY);
    fc.addGenerated(AStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt8ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt16ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt32ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt64ConstructorDescriptor.FACTORY);
    fc.addGenerated(AFloatConstructorDescriptor.FACTORY);
    fc.addGenerated(ADoubleConstructorDescriptor.FACTORY);
    fc.addGenerated(APointConstructorDescriptor.FACTORY);
    fc.addGenerated(APoint3DConstructorDescriptor.FACTORY);
    fc.addGenerated(ALineConstructorDescriptor.FACTORY);
    fc.addGenerated(APolygonConstructorDescriptor.FACTORY);
    fc.addGenerated(ACircleConstructorDescriptor.FACTORY);
    fc.addGenerated(ARectangleConstructorDescriptor.FACTORY);
    fc.addGenerated(ATimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AYearMonthDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(ADayTimeDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AUUIDFromStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromTimeConstructorDescriptor.FACTORY);
    // Spatial
    fc.addGenerated(CreatePointDescriptor.FACTORY);
    fc.addGenerated(CreateLineDescriptor.FACTORY);
    fc.addGenerated(CreatePolygonDescriptor.FACTORY);
    fc.addGenerated(CreateCircleDescriptor.FACTORY);
    fc.addGenerated(CreateRectangleDescriptor.FACTORY);
    fc.addGenerated(SpatialAreaDescriptor.FACTORY);
    fc.addGenerated(SpatialDistanceDescriptor.FACTORY);
    fc.addGenerated(CreateMBRDescriptor.FACTORY);
    fc.addGenerated(SpatialCellDescriptor.FACTORY);
    fc.addGenerated(PointXCoordinateAccessor.FACTORY);
    fc.addGenerated(PointYCoordinateAccessor.FACTORY);
    fc.addGenerated(CircleRadiusAccessor.FACTORY);
    fc.addGenerated(CircleCenterAccessor.FACTORY);
    fc.addGenerated(LineRectanglePolygonAccessor.FACTORY);
    // full-text function
    fc.addGenerated(FullTextContainsDescriptor.FACTORY);
    fc.addGenerated(FullTextContainsWithoutOptionDescriptor.FACTORY);
    // Record functions.
    fc.addGenerated(GetRecordFieldsDescriptor.FACTORY);
    fc.addGenerated(GetRecordFieldValueDescriptor.FACTORY);
    fc.addGenerated(DeepEqualityDescriptor.FACTORY);
    fc.addGenerated(RecordMergeDescriptor.FACTORY);
    fc.addGenerated(RecordAddFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordLengthDescriptor.FACTORY);
    fc.addGenerated(RecordNamesDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveDescriptor.FACTORY);
    fc.addGenerated(RecordRenameDescriptor.FACTORY);
    fc.addGenerated(RecordUnwrapDescriptor.FACTORY);
    fc.add(RecordReplaceDescriptor.FACTORY);
    fc.add(RecordAddDescriptor.FACTORY);
    fc.add(RecordPutDescriptor.FACTORY);
    fc.addGenerated(RecordValuesDescriptor.FACTORY);
    fc.addGenerated(PairsDescriptor.FACTORY);
    // Spatial and temporal type accessors
    fc.addGenerated(TemporalYearAccessor.FACTORY);
    fc.addGenerated(TemporalMonthAccessor.FACTORY);
    fc.addGenerated(TemporalDayAccessor.FACTORY);
    fc.addGenerated(TemporalHourAccessor.FACTORY);
    fc.addGenerated(TemporalMinuteAccessor.FACTORY);
    fc.addGenerated(TemporalSecondAccessor.FACTORY);
    fc.addGenerated(TemporalMillisecondAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDatetimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDatetimeAccessor.FACTORY);
    // Temporal functions
    fc.addGenerated(UnixTimeFromDateInDaysDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromTimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DateFromUnixTimeInDaysDescriptor.FACTORY);
    fc.addGenerated(DateFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(TimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(TimeFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromDateAndTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDurationFromDateTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDuartionFromDateDescriptor.FACTORY);
    fc.addGenerated(AdjustDateTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(AdjustTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(IntervalBeforeDescriptor.FACTORY);
    fc.addGenerated(IntervalAfterDescriptor.FACTORY);
    fc.addGenerated(IntervalMeetsDescriptor.FACTORY);
    fc.addGenerated(IntervalMetByDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlapsDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlappedByDescriptor.FACTORY);
    fc.addGenerated(OverlapDescriptor.FACTORY);
    fc.addGenerated(IntervalStartsDescriptor.FACTORY);
    fc.addGenerated(IntervalStartedByDescriptor.FACTORY);
    fc.addGenerated(IntervalCoversDescriptor.FACTORY);
    fc.addGenerated(IntervalCoveredByDescriptor.FACTORY);
    fc.addGenerated(IntervalEndsDescriptor.FACTORY);
    fc.addGenerated(IntervalEndedByDescriptor.FACTORY);
    fc.addGenerated(DurationFromMillisecondsDescriptor.FACTORY);
    fc.addGenerated(DurationFromMonthsDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(MonthsFromYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(MillisecondsFromDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(DurationEqualDescriptor.FACTORY);
    fc.addGenerated(GetYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(GetDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(IntervalBinDescriptor.FACTORY);
    fc.addGenerated(OverlapBinsDescriptor.FACTORY);
    fc.addGenerated(DayOfWeekDescriptor.FACTORY);
    fc.addGenerated(ParseDateDescriptor.FACTORY);
    fc.addGenerated(ParseTimeDescriptor.FACTORY);
    fc.addGenerated(ParseDateTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateDescriptor.FACTORY);
    fc.addGenerated(PrintTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateTimeDescriptor.FACTORY);
    fc.addGenerated(GetOverlappingIntervalDescriptor.FACTORY);
    fc.addGenerated(DurationFromIntervalDescriptor.FACTORY);
    // Type functions.
    fc.addGenerated(IsArrayDescriptor.FACTORY);
    fc.addGenerated(IsAtomicDescriptor.FACTORY);
    fc.addGenerated(IsBooleanDescriptor.FACTORY);
    fc.addGenerated(IsNumberDescriptor.FACTORY);
    fc.addGenerated(IsObjectDescriptor.FACTORY);
    fc.addGenerated(IsStringDescriptor.FACTORY);
    fc.addGenerated(ToArrayDescriptor.FACTORY);
    fc.addGenerated(ToAtomicDescriptor.FACTORY);
    fc.addGenerated(ToBigIntDescriptor.FACTORY);
    fc.addGenerated(ToBooleanDescriptor.FACTORY);
    fc.addGenerated(ToDoubleDescriptor.FACTORY);
    fc.addGenerated(ToNumberDescriptor.FACTORY);
    fc.addGenerated(ToObjectDescriptor.FACTORY);
    fc.addGenerated(ToStringDescriptor.FACTORY);
    fc.addGenerated(TreatAsIntegerDescriptor.FACTORY);
    // Cast function
    fc.addGenerated(CastTypeDescriptor.FACTORY);
    fc.addGenerated(CastTypeLaxDescriptor.FACTORY);
    // Record function
    fc.addGenerated(RecordPairsDescriptor.FACTORY);
    // Other functions
    fc.addGenerated(RandomWithSeedDescriptor.FACTORY);
    ServiceLoader.load(IFunctionRegistrant.class).iterator().forEachRemaining(c -> c.register(fc));
    return fc;
}
#method_after
public static FunctionCollection createDefaultFunctionCollection() {
    FunctionCollection fc = new FunctionCollection();
    // array functions
    fc.add(ArrayRemoveDescriptor.FACTORY);
    fc.add(ArrayPutDescriptor.FACTORY);
    fc.add(ArrayPrependDescriptor.FACTORY);
    fc.add(ArrayAppendDescriptor.FACTORY);
    fc.add(ArrayInsertDescriptor.FACTORY);
    fc.addGenerated(ArrayPositionDescriptor.FACTORY);
    fc.addGenerated(ArrayRepeatDescriptor.FACTORY);
    fc.addGenerated(ArrayContainsDescriptor.FACTORY);
    fc.addGenerated(ArrayReverseDescriptor.FACTORY);
    fc.addGenerated(ArraySortDescriptor.FACTORY);
    fc.addGenerated(ArrayDistinctDescriptor.FACTORY);
    fc.addGenerated(ArrayUnionDescriptor.FACTORY);
    fc.addGenerated(ArrayIntersectDescriptor.FACTORY);
    fc.addGenerated(ArrayIfNullDescriptor.FACTORY);
    fc.addGenerated(ArrayConcatDescriptor.FACTORY);
    fc.addGenerated(ArrayRangeDescriptor.FACTORY);
    fc.addGenerated(ArrayFlattenDescriptor.FACTORY);
    fc.add(ArrayReplaceDescriptor.FACTORY);
    fc.addGenerated(ArraySliceWithEndPositionDescriptor.FACTORY);
    fc.addGenerated(ArraySliceWithoutEndPositionDescriptor.FACTORY);
    fc.addGenerated(ArraySymDiffDescriptor.FACTORY);
    fc.addGenerated(ArraySymDiffnDescriptor.FACTORY);
    fc.addGenerated(ArrayStarDescriptor.FACTORY);
    // unnesting functions
    fc.add(TidRunningAggregateDescriptor.FACTORY);
    fc.add(ScanCollectionDescriptor.FACTORY);
    fc.add(RangeDescriptor.FACTORY);
    fc.add(SubsetCollectionDescriptor.FACTORY);
    // aggregate functions
    fc.add(ListifyAggregateDescriptor.FACTORY);
    fc.add(CountAggregateDescriptor.FACTORY);
    fc.add(AvgAggregateDescriptor.FACTORY);
    fc.add(LocalAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SumAggregateDescriptor.FACTORY);
    fc.add(LocalSumAggregateDescriptor.FACTORY);
    fc.add(IntermediateSumAggregateDescriptor.FACTORY);
    fc.add(GlobalSumAggregateDescriptor.FACTORY);
    fc.add(MaxAggregateDescriptor.FACTORY);
    fc.add(LocalMaxAggregateDescriptor.FACTORY);
    fc.add(MinAggregateDescriptor.FACTORY);
    fc.add(LocalMinAggregateDescriptor.FACTORY);
    fc.add(FirstElementAggregateDescriptor.FACTORY);
    fc.add(LocalFirstElementAggregateDescriptor.FACTORY);
    fc.add(LastElementAggregateDescriptor.FACTORY);
    fc.add(StddevAggregateDescriptor.FACTORY);
    fc.add(LocalStddevAggregateDescriptor.FACTORY);
    fc.add(IntermediateStddevAggregateDescriptor.FACTORY);
    fc.add(GlobalStddevAggregateDescriptor.FACTORY);
    fc.add(LocalSamplingAggregateDescriptor.FACTORY);
    fc.add(RangeMapAggregateDescriptor.FACTORY);
    fc.add(StddevPopAggregateDescriptor.FACTORY);
    fc.add(LocalStddevPopAggregateDescriptor.FACTORY);
    fc.add(IntermediateStddevPopAggregateDescriptor.FACTORY);
    fc.add(GlobalStddevPopAggregateDescriptor.FACTORY);
    fc.add(VarAggregateDescriptor.FACTORY);
    fc.add(LocalVarAggregateDescriptor.FACTORY);
    fc.add(IntermediateVarAggregateDescriptor.FACTORY);
    fc.add(GlobalVarAggregateDescriptor.FACTORY);
    fc.add(VarPopAggregateDescriptor.FACTORY);
    fc.add(LocalVarPopAggregateDescriptor.FACTORY);
    fc.add(IntermediateVarPopAggregateDescriptor.FACTORY);
    fc.add(GlobalVarPopAggregateDescriptor.FACTORY);
    fc.add(KurtosisAggregateDescriptor.FACTORY);
    fc.add(LocalKurtosisAggregateDescriptor.FACTORY);
    fc.add(IntermediateKurtosisAggregateDescriptor.FACTORY);
    fc.add(GlobalKurtosisAggregateDescriptor.FACTORY);
    fc.add(SkewnessAggregateDescriptor.FACTORY);
    fc.add(LocalSkewnessAggregateDescriptor.FACTORY);
    fc.add(IntermediateSkewnessAggregateDescriptor.FACTORY);
    fc.add(GlobalSkewnessAggregateDescriptor.FACTORY);
    fc.add(EmptyStreamAggregateDescriptor.FACTORY);
    fc.add(NonEmptyStreamAggregateDescriptor.FACTORY);
    // serializable aggregates
    fc.add(SerializableCountAggregateDescriptor.FACTORY);
    fc.add(SerializableAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSumAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSumAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSumAggregateDescriptor.FACTORY);
    fc.add(SerializableStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableVarAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalVarAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateVarAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalVarAggregateDescriptor.FACTORY);
    fc.add(SerializableVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableKurtosisAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalKurtosisAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateKurtosisAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalKurtosisAggregateDescriptor.FACTORY);
    fc.add(SerializableSkewnessAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSkewnessAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSkewnessAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSkewnessAggregateDescriptor.FACTORY);
    // scalar aggregates
    fc.add(ScalarCountAggregateDescriptor.FACTORY);
    fc.add(ScalarCountDistinctAggregateDescriptor.FACTORY);
    fc.add(ScalarAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarAvgDistinctAggregateDescriptor.FACTORY);
    fc.add(ScalarSumAggregateDescriptor.FACTORY);
    fc.add(ScalarSumDistinctAggregateDescriptor.FACTORY);
    fc.add(ScalarMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarMaxDistinctAggregateDescriptor.FACTORY);
    fc.add(ScalarMinAggregateDescriptor.FACTORY);
    fc.add(ScalarMinDistinctAggregateDescriptor.FACTORY);
    fc.add(ScalarStddevAggregateDescriptor.FACTORY);
    fc.add(ScalarStddevDistinctAggregateDescriptor.FACTORY);
    fc.add(ScalarStddevPopAggregateDescriptor.FACTORY);
    fc.add(ScalarStddevPopDistinctAggregateDescriptor.FACTORY);
    fc.add(ScalarVarAggregateDescriptor.FACTORY);
    fc.add(ScalarVarDistinctAggregateDescriptor.FACTORY);
    fc.add(ScalarVarPopAggregateDescriptor.FACTORY);
    fc.add(ScalarVarPopDistinctAggregateDescriptor.FACTORY);
    fc.add(ScalarKurtosisAggregateDescriptor.FACTORY);
    fc.add(ScalarKurtosisDistinctAggregateDescriptor.FACTORY);
    fc.add(ScalarSkewnessAggregateDescriptor.FACTORY);
    fc.add(ScalarSkewnessDistinctAggregateDescriptor.FACTORY);
    // SQL aggregates
    fc.add(SqlCountAggregateDescriptor.FACTORY);
    fc.add(SqlAvgAggregateDescriptor.FACTORY);
    fc.add(LocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SqlSumAggregateDescriptor.FACTORY);
    fc.add(LocalSqlSumAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlSumAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SqlMaxAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMaxAggregateDescriptor.FACTORY);
    fc.add(SqlMinAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMinAggregateDescriptor.FACTORY);
    fc.add(SqlStddevAggregateDescriptor.FACTORY);
    fc.add(LocalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlStddevAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(LocalSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SqlVarAggregateDescriptor.FACTORY);
    fc.add(LocalSqlVarAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlVarAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlVarAggregateDescriptor.FACTORY);
    fc.add(SqlVarPopAggregateDescriptor.FACTORY);
    fc.add(LocalSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(SqlKurtosisAggregateDescriptor.FACTORY);
    fc.add(LocalSqlKurtosisAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlKurtosisAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlKurtosisAggregateDescriptor.FACTORY);
    fc.add(SqlSkewnessAggregateDescriptor.FACTORY);
    fc.add(LocalSqlSkewnessAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlSkewnessAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlSkewnessAggregateDescriptor.FACTORY);
    // SQL serializable aggregates
    fc.add(SerializableSqlCountAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlVarAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlVarAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlVarAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlVarAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlKurtosisAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlKurtosisAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlKurtosisAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlKurtosisAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlSkewnessAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlSkewnessAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlSkewnessAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlSkewnessAggregateDescriptor.FACTORY);
    // SQL scalar aggregates
    fc.add(ScalarSqlCountAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlCountDistinctAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlAvgDistinctAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlSumAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlSumDistinctAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMaxDistinctAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMinAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMinDistinctAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlStddevAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlStddevDistinctAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlStddevPopDistinctAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlVarAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlVarDistinctAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlVarPopDistinctAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlKurtosisAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlKurtosisDistinctAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlSkewnessAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlSkewnessDistinctAggregateDescriptor.FACTORY);
    // window functions
    fc.add(DenseRankRunningAggregateDescriptor.FACTORY);
    fc.add(NtileRunningAggregateDescriptor.FACTORY);
    fc.add(RankRunningAggregateDescriptor.FACTORY);
    fc.add(RowNumberRunningAggregateDescriptor.FACTORY);
    fc.add(PercentRankRunningAggregateDescriptor.FACTORY);
    fc.add(WinPartitionLenRunningAggregateDescriptor.FACTORY);
    // boolean functions
    fc.add(AndDescriptor.FACTORY);
    fc.add(OrDescriptor.FACTORY);
    // Record constructors / functions
    fc.add(ClosedRecordConstructorDescriptor.FACTORY);
    fc.add(OpenRecordConstructorDescriptor.FACTORY);
    fc.add(RecordConcatDescriptor.FACTORY);
    fc.add(RecordConcatStrictDescriptor.FACTORY);
    // List constructors
    fc.add(OrderedListConstructorDescriptor.FACTORY);
    fc.add(UnorderedListConstructorDescriptor.FACTORY);
    // Sleep function
    fc.add(SleepDescriptor.FACTORY);
    // Inject failure function
    fc.add(InjectFailureDescriptor.FACTORY);
    // Get Job Parameter function
    fc.add(GetJobParameterByNameDescriptor.FACTORY);
    // Switch case
    fc.add(SwitchCaseDescriptor.FACTORY);
    // null functions
    fc.add(IsMissingDescriptor.FACTORY);
    fc.add(IsNullDescriptor.FACTORY);
    fc.add(IsUnknownDescriptor.FACTORY);
    fc.add(IsSystemNullDescriptor.FACTORY);
    fc.add(CheckUnknownDescriptor.FACTORY);
    fc.add(IfMissingDescriptor.FACTORY);
    fc.add(IfNullDescriptor.FACTORY);
    fc.add(IfMissingOrNullDescriptor.FACTORY);
    fc.add(IfSystemNullDescriptor.FACTORY);
    // uuid generators (zero independent functions)
    fc.add(CreateUUIDDescriptor.FACTORY);
    fc.add(UUIDDescriptor.FACTORY);
    fc.add(CreateQueryUIDDescriptor.FACTORY);
    fc.add(RandomDescriptor.FACTORY);
    fc.add(CurrentDateDescriptor.FACTORY);
    fc.add(CurrentTimeDescriptor.FACTORY);
    fc.add(CurrentDateTimeDescriptor.FACTORY);
    // functions that need generated class for null-handling.
    // Element accessors.
    fc.addGenerated(FieldAccessByIndexDescriptor.FACTORY);
    fc.addGenerated(FieldAccessByNameDescriptor.FACTORY);
    fc.addGenerated(FieldAccessNestedDescriptor.FACTORY);
    fc.addGenerated(AnyCollectionMemberDescriptor.FACTORY);
    fc.addGenerated(GetItemDescriptor.FACTORY);
    // Numeric functions
    fc.add(IfInfDescriptor.FACTORY);
    fc.add(IfNanDescriptor.FACTORY);
    fc.add(IfNanOrInfDescriptor.FACTORY);
    fc.addGenerated(NumericUnaryMinusDescriptor.FACTORY);
    fc.addGenerated(NumericAddDescriptor.FACTORY);
    fc.addGenerated(NumericDivideDescriptor.FACTORY);
    fc.addGenerated(NumericDivDescriptor.FACTORY);
    fc.addGenerated(NumericMultiplyDescriptor.FACTORY);
    fc.addGenerated(NumericSubDescriptor.FACTORY);
    fc.addGenerated(NumericModuloDescriptor.FACTORY);
    fc.addGenerated(NumericPowerDescriptor.FACTORY);
    fc.addGenerated(NotDescriptor.FACTORY);
    fc.addGenerated(LenDescriptor.FACTORY);
    fc.addGenerated(NumericAbsDescriptor.FACTORY);
    fc.addGenerated(NumericCeilingDescriptor.FACTORY);
    fc.addGenerated(NumericFloorDescriptor.FACTORY);
    fc.addGenerated(NumericRoundDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEvenDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEven2Descriptor.FACTORY);
    fc.addGenerated(NumericACosDescriptor.FACTORY);
    fc.addGenerated(NumericASinDescriptor.FACTORY);
    fc.addGenerated(NumericATanDescriptor.FACTORY);
    fc.addGenerated(NumericDegreesDescriptor.FACTORY);
    fc.addGenerated(NumericRadiansDescriptor.FACTORY);
    fc.addGenerated(NumericCosDescriptor.FACTORY);
    fc.addGenerated(NumericCoshDescriptor.FACTORY);
    fc.addGenerated(NumericSinDescriptor.FACTORY);
    fc.addGenerated(NumericSinhDescriptor.FACTORY);
    fc.addGenerated(NumericTanDescriptor.FACTORY);
    fc.addGenerated(NumericTanhDescriptor.FACTORY);
    fc.addGenerated(NumericExpDescriptor.FACTORY);
    fc.addGenerated(NumericLnDescriptor.FACTORY);
    fc.addGenerated(NumericLogDescriptor.FACTORY);
    fc.addGenerated(NumericSqrtDescriptor.FACTORY);
    fc.addGenerated(NumericSignDescriptor.FACTORY);
    fc.addGenerated(NumericTruncDescriptor.FACTORY);
    fc.addGenerated(NumericATan2Descriptor.FACTORY);
    // Comparisons.
    fc.addGenerated(EqualsDescriptor.FACTORY);
    fc.addGenerated(GreaterThanDescriptor.FACTORY);
    fc.addGenerated(GreaterThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(LessThanDescriptor.FACTORY);
    fc.addGenerated(LessThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(NotEqualsDescriptor.FACTORY);
    // If-Equals functions
    fc.addGenerated(MissingIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NullIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NanIfEqualsDescriptor.FACTORY);
    fc.addGenerated(PosInfIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NegInfIfEqualsDescriptor.FACTORY);
    // Binary functions
    fc.addGenerated(BinaryLengthDescriptor.FACTORY);
    fc.addGenerated(ParseBinaryDescriptor.FACTORY);
    fc.addGenerated(PrintBinaryDescriptor.FACTORY);
    fc.addGenerated(BinaryConcatDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromToDescriptor.FACTORY);
    fc.addGenerated(FindBinaryDescriptor.FACTORY);
    fc.addGenerated(FindBinaryFromDescriptor.FACTORY);
    // String functions
    fc.addGenerated(StringLikeDescriptor.FACTORY);
    fc.addGenerated(StringContainsDescriptor.FACTORY);
    fc.addGenerated(StringEndsWithDescriptor.FACTORY);
    fc.addGenerated(StringStartsWithDescriptor.FACTORY);
    fc.addGenerated(SubstringDescriptor.FACTORY);
    fc.addGenerated(StringEqualDescriptor.FACTORY);
    fc.addGenerated(StringLowerCaseDescriptor.FACTORY);
    fc.addGenerated(StringUpperCaseDescriptor.FACTORY);
    fc.addGenerated(StringLengthDescriptor.FACTORY);
    fc.addGenerated(Substring2Descriptor.FACTORY);
    fc.addGenerated(SubstringBeforeDescriptor.FACTORY);
    fc.addGenerated(SubstringAfterDescriptor.FACTORY);
    fc.addGenerated(StringToCodePointDescriptor.FACTORY);
    fc.addGenerated(CodePointToStringDescriptor.FACTORY);
    fc.addGenerated(StringConcatDescriptor.FACTORY);
    fc.addGenerated(StringJoinDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringInitCapDescriptor.FACTORY);
    fc.addGenerated(StringTrimDescriptor.FACTORY);
    fc.addGenerated(StringLTrimDescriptor.FACTORY);
    fc.addGenerated(StringRTrimDescriptor.FACTORY);
    fc.addGenerated(StringTrim2Descriptor.FACTORY);
    fc.addGenerated(StringLTrim2Descriptor.FACTORY);
    fc.addGenerated(StringRTrim2Descriptor.FACTORY);
    fc.addGenerated(StringPositionDescriptor.FACTORY);
    fc.addGenerated(StringRepeatDescriptor.FACTORY);
    fc.addGenerated(StringReplaceDescriptor.FACTORY);
    fc.addGenerated(StringReplaceWithLimitDescriptor.FACTORY);
    fc.addGenerated(StringReverseDescriptor.FACTORY);
    fc.addGenerated(StringSplitDescriptor.FACTORY);
    // Constructors
    fc.addGenerated(ABooleanConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryHexStringConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryBase64StringConstructorDescriptor.FACTORY);
    fc.addGenerated(AStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt8ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt16ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt32ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt64ConstructorDescriptor.FACTORY);
    fc.addGenerated(AFloatConstructorDescriptor.FACTORY);
    fc.addGenerated(ADoubleConstructorDescriptor.FACTORY);
    fc.addGenerated(APointConstructorDescriptor.FACTORY);
    fc.addGenerated(APoint3DConstructorDescriptor.FACTORY);
    fc.addGenerated(ALineConstructorDescriptor.FACTORY);
    fc.addGenerated(APolygonConstructorDescriptor.FACTORY);
    fc.addGenerated(ACircleConstructorDescriptor.FACTORY);
    fc.addGenerated(ARectangleConstructorDescriptor.FACTORY);
    fc.addGenerated(ATimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AYearMonthDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(ADayTimeDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AUUIDFromStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromTimeConstructorDescriptor.FACTORY);
    // Spatial
    fc.addGenerated(CreatePointDescriptor.FACTORY);
    fc.addGenerated(CreateLineDescriptor.FACTORY);
    fc.addGenerated(CreatePolygonDescriptor.FACTORY);
    fc.addGenerated(CreateCircleDescriptor.FACTORY);
    fc.addGenerated(CreateRectangleDescriptor.FACTORY);
    fc.addGenerated(SpatialAreaDescriptor.FACTORY);
    fc.addGenerated(SpatialDistanceDescriptor.FACTORY);
    fc.addGenerated(CreateMBRDescriptor.FACTORY);
    fc.addGenerated(SpatialCellDescriptor.FACTORY);
    fc.addGenerated(PointXCoordinateAccessor.FACTORY);
    fc.addGenerated(PointYCoordinateAccessor.FACTORY);
    fc.addGenerated(CircleRadiusAccessor.FACTORY);
    fc.addGenerated(CircleCenterAccessor.FACTORY);
    fc.addGenerated(LineRectanglePolygonAccessor.FACTORY);
    // full-text function
    fc.addGenerated(FullTextContainsDescriptor.FACTORY);
    fc.addGenerated(FullTextContainsWithoutOptionDescriptor.FACTORY);
    // Record functions.
    fc.addGenerated(GetRecordFieldsDescriptor.FACTORY);
    fc.addGenerated(GetRecordFieldValueDescriptor.FACTORY);
    fc.addGenerated(DeepEqualityDescriptor.FACTORY);
    fc.addGenerated(RecordMergeDescriptor.FACTORY);
    fc.addGenerated(RecordAddFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordLengthDescriptor.FACTORY);
    fc.addGenerated(RecordNamesDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveDescriptor.FACTORY);
    fc.addGenerated(RecordRenameDescriptor.FACTORY);
    fc.addGenerated(RecordUnwrapDescriptor.FACTORY);
    fc.add(RecordReplaceDescriptor.FACTORY);
    fc.add(RecordAddDescriptor.FACTORY);
    fc.add(RecordPutDescriptor.FACTORY);
    fc.addGenerated(RecordValuesDescriptor.FACTORY);
    fc.addGenerated(PairsDescriptor.FACTORY);
    // Spatial and temporal type accessors
    fc.addGenerated(TemporalYearAccessor.FACTORY);
    fc.addGenerated(TemporalMonthAccessor.FACTORY);
    fc.addGenerated(TemporalDayAccessor.FACTORY);
    fc.addGenerated(TemporalHourAccessor.FACTORY);
    fc.addGenerated(TemporalMinuteAccessor.FACTORY);
    fc.addGenerated(TemporalSecondAccessor.FACTORY);
    fc.addGenerated(TemporalMillisecondAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDatetimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDatetimeAccessor.FACTORY);
    // Temporal functions
    fc.addGenerated(UnixTimeFromDateInDaysDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromTimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DateFromUnixTimeInDaysDescriptor.FACTORY);
    fc.addGenerated(DateFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(TimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(TimeFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromDateAndTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDurationFromDateTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDuartionFromDateDescriptor.FACTORY);
    fc.addGenerated(AdjustDateTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(AdjustTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(IntervalBeforeDescriptor.FACTORY);
    fc.addGenerated(IntervalAfterDescriptor.FACTORY);
    fc.addGenerated(IntervalMeetsDescriptor.FACTORY);
    fc.addGenerated(IntervalMetByDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlapsDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlappedByDescriptor.FACTORY);
    fc.addGenerated(OverlapDescriptor.FACTORY);
    fc.addGenerated(IntervalStartsDescriptor.FACTORY);
    fc.addGenerated(IntervalStartedByDescriptor.FACTORY);
    fc.addGenerated(IntervalCoversDescriptor.FACTORY);
    fc.addGenerated(IntervalCoveredByDescriptor.FACTORY);
    fc.addGenerated(IntervalEndsDescriptor.FACTORY);
    fc.addGenerated(IntervalEndedByDescriptor.FACTORY);
    fc.addGenerated(DurationFromMillisecondsDescriptor.FACTORY);
    fc.addGenerated(DurationFromMonthsDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(MonthsFromYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(MillisecondsFromDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(DurationEqualDescriptor.FACTORY);
    fc.addGenerated(GetYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(GetDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(IntervalBinDescriptor.FACTORY);
    fc.addGenerated(OverlapBinsDescriptor.FACTORY);
    fc.addGenerated(DayOfWeekDescriptor.FACTORY);
    fc.addGenerated(ParseDateDescriptor.FACTORY);
    fc.addGenerated(ParseTimeDescriptor.FACTORY);
    fc.addGenerated(ParseDateTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateDescriptor.FACTORY);
    fc.addGenerated(PrintTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateTimeDescriptor.FACTORY);
    fc.addGenerated(GetOverlappingIntervalDescriptor.FACTORY);
    fc.addGenerated(DurationFromIntervalDescriptor.FACTORY);
    // Type functions.
    fc.addGenerated(IsArrayDescriptor.FACTORY);
    fc.addGenerated(IsAtomicDescriptor.FACTORY);
    fc.addGenerated(IsBooleanDescriptor.FACTORY);
    fc.addGenerated(IsNumberDescriptor.FACTORY);
    fc.addGenerated(IsObjectDescriptor.FACTORY);
    fc.addGenerated(IsStringDescriptor.FACTORY);
    fc.addGenerated(ToArrayDescriptor.FACTORY);
    fc.addGenerated(ToAtomicDescriptor.FACTORY);
    fc.addGenerated(ToBigIntDescriptor.FACTORY);
    fc.addGenerated(ToBooleanDescriptor.FACTORY);
    fc.addGenerated(ToDoubleDescriptor.FACTORY);
    fc.addGenerated(ToNumberDescriptor.FACTORY);
    fc.addGenerated(ToObjectDescriptor.FACTORY);
    fc.addGenerated(ToStringDescriptor.FACTORY);
    fc.addGenerated(TreatAsIntegerDescriptor.FACTORY);
    // Cast function
    fc.addGenerated(CastTypeDescriptor.FACTORY);
    fc.addGenerated(CastTypeLaxDescriptor.FACTORY);
    // Record function
    fc.addGenerated(RecordPairsDescriptor.FACTORY);
    // Other functions
    fc.addGenerated(RandomWithSeedDescriptor.FACTORY);
    ServiceLoader.load(IFunctionRegistrant.class).iterator().forEachRemaining(c -> c.register(fc));
    return fc;
}
#end_block

#method_before
@Override
public boolean rewritePre(Mutable<ILogicalOperator> opRef, IOptimizationContext context) throws AlgebricksException {
    ILogicalOperator op = opRef.getValue();
    switch(op.getOperatorTag()) {
        case AGGREGATE:
            if (context.checkIfInDontApplySet(this, op)) {
                return false;
            }
            newAggOps.clear();
            if (rewriteAggregate((AggregateOperator) op, newAggOps, context)) {
                ILogicalOperator newOp = join(newAggOps, context);
                opRef.setValue(newOp);
                return true;
            }
            return false;
        case GROUP:
            if (context.checkIfInDontApplySet(this, op)) {
                return false;
            }
            GroupByOperator gbyOp = (GroupByOperator) op;
            List<ILogicalPlan> nestedPlans = gbyOp.getNestedPlans();
            boolean applied = false;
            for (int i = nestedPlans.size() - 1; i >= 0; i--) {
                ILogicalPlan nestedPlan = nestedPlans.get(i);
                for (Mutable<ILogicalOperator> rootOpRef : nestedPlan.getRoots()) {
                    ILogicalOperator rootOp = rootOpRef.getValue();
                    if (rootOp.getOperatorTag() == LogicalOperatorTag.AGGREGATE) {
                        newAggOps.clear();
                        if (rewriteAggregate((AggregateOperator) rootOp, newAggOps, context)) {
                            applied = true;
                            rootOpRef.setValue(newAggOps.get(0));
                            for (int j = 1, ln = newAggOps.size(); j < ln; j++) {
                                nestedPlans.add(new ALogicalPlanImpl(new MutableObject<>(newAggOps.get(j))));
                            }
                        }
                    }
                }
            }
            if (applied) {
                context.addToDontApplySet(this, gbyOp);
                return true;
            }
            return false;
        default:
            return false;
    }
}
#method_after
@Override
public boolean rewritePre(Mutable<ILogicalOperator> opRef, IOptimizationContext context) throws AlgebricksException {
    ILogicalOperator op = opRef.getValue();
    switch(op.getOperatorTag()) {
        case AGGREGATE:
            if (context.checkIfInDontApplySet(this, op)) {
                return false;
            }
            newAggOps.clear();
            if (rewriteAggregate((AggregateOperator) op, newAggOps, context)) {
                ILogicalOperator newOp = join(newAggOps, context);
                opRef.setValue(newOp);
                return true;
            }
            return false;
        case GROUP:
            if (context.checkIfInDontApplySet(this, op)) {
                return false;
            }
            GroupByOperator gbyOp = (GroupByOperator) op;
            List<ILogicalPlan> nestedPlans = gbyOp.getNestedPlans();
            boolean applied = false;
            for (int i = nestedPlans.size() - 1; i >= 0; i--) {
                ILogicalPlan nestedPlan = nestedPlans.get(i);
                for (Mutable<ILogicalOperator> rootOpRef : nestedPlan.getRoots()) {
                    ILogicalOperator rootOp = rootOpRef.getValue();
                    if (rootOp.getOperatorTag() == LogicalOperatorTag.AGGREGATE) {
                        newAggOps.clear();
                        if (rewriteAggregate((AggregateOperator) rootOp, newAggOps, context)) {
                            applied = true;
                            rootOpRef.setValue(newAggOps.get(0));
                            for (int j = 1, ln = newAggOps.size(); j < ln; j++) {
                                nestedPlans.add(new ALogicalPlanImpl(new MutableObject<>(newAggOps.get(j))));
                            }
                        }
                    }
                }
            }
            if (applied) {
                context.computeAndSetTypeEnvironmentForOperator(gbyOp);
                context.addToDontApplySet(this, gbyOp);
                return true;
            }
            return false;
        default:
            return false;
    }
}
#end_block

#method_before
private void rewriteDistinctAggregate(AggregateOperator aggOp, IOptimizationContext context) throws AlgebricksException {
    ILogicalOperator inputOp = aggOp.getInputs().get(0).getValue();
    // Introduce ASSIGN operator if distinct expression is not a variable
    ILogicalExpression distinctExpr = ((AbstractFunctionCallExpression) aggOp.getExpressions().get(0).getValue()).getArguments().get(0).getValue();
    AssignOperator assignOp = null;
    LogicalVariable distinctVar;
    if (distinctExpr.getExpressionTag() == LogicalExpressionTag.VARIABLE) {
        distinctVar = ((VariableReferenceExpression) distinctExpr).getVariableReference();
    } else {
        distinctVar = context.newVar();
        assignOp = new AssignOperator(distinctVar, new MutableObject<>(distinctExpr));
        assignOp.setSourceLocation(aggOp.getSourceLocation());
        assignOp.getInputs().add(new MutableObject<>(inputOp));
        context.computeAndSetTypeEnvironmentForOperator(assignOp);
        inputOp = assignOp;
    }
    // Introduce DISTINCT operator
    VariableReferenceExpression distinctVarRef = new VariableReferenceExpression(distinctVar);
    distinctVarRef.setSourceLocation(distinctExpr.getSourceLocation());
    List<Mutable<ILogicalExpression>> distinctExprs = new ArrayList<>(1);
    distinctExprs.add(new MutableObject<>(distinctVarRef));
    DistinctOperator distinctOp = new DistinctOperator(distinctExprs);
    distinctOp.setSourceLocation(aggOp.getSourceLocation());
    distinctOp.getInputs().add(new MutableObject<>(inputOp));
    context.computeAndSetTypeEnvironmentForOperator(distinctOp);
    // replace 'expr' with variable reference if ASSIGN was introduced
    for (Mutable<ILogicalExpression> aggExprRef : aggOp.getExpressions()) {
        AbstractFunctionCallExpression callExpr = (AbstractFunctionCallExpression) aggExprRef.getValue();
        FunctionIdentifier regularAggForDistinct = BuiltinFunctions.getAggregateFunctionForDistinct(callExpr.getFunctionIdentifier());
        if (regularAggForDistinct == null) {
            throw new IllegalStateException(String.valueOf(callExpr.getFunctionIdentifier()));
        }
        callExpr.setFunctionInfo(BuiltinFunctions.getAsterixFunctionInfo(regularAggForDistinct));
        if (assignOp != null) {
            callExpr.getArguments().get(0).setValue(distinctVarRef.cloneExpression());
        }
    }
    aggOp.getInputs().clear();
    aggOp.getInputs().add(new MutableObject<>(distinctOp));
    context.computeAndSetTypeEnvironmentForOperator(aggOp);
}
#method_after
private void rewriteDistinctAggregate(AggregateOperator aggOp, IOptimizationContext context) throws AlgebricksException {
    ILogicalOperator inputOp = aggOp.getInputs().get(0).getValue();
    // Introduce ASSIGN operator if distinct expression is not a variable
    ILogicalExpression distinctExpr = ((AbstractFunctionCallExpression) aggOp.getExpressions().get(0).getValue()).getArguments().get(0).getValue();
    AssignOperator assignOp = null;
    LogicalVariable distinctVar;
    if (distinctExpr.getExpressionTag() == LogicalExpressionTag.VARIABLE) {
        distinctVar = ((VariableReferenceExpression) distinctExpr).getVariableReference();
    } else {
        distinctVar = context.newVar();
        assignOp = new AssignOperator(distinctVar, new MutableObject<>(distinctExpr));
        assignOp.setSourceLocation(aggOp.getSourceLocation());
        assignOp.getInputs().add(new MutableObject<>(inputOp));
        assignOp.setExecutionMode(inputOp.getExecutionMode());
        context.computeAndSetTypeEnvironmentForOperator(assignOp);
        inputOp = assignOp;
    }
    // Introduce DISTINCT operator
    VariableReferenceExpression distinctVarRef = new VariableReferenceExpression(distinctVar);
    distinctVarRef.setSourceLocation(distinctExpr.getSourceLocation());
    List<Mutable<ILogicalExpression>> distinctExprs = new ArrayList<>(1);
    distinctExprs.add(new MutableObject<>(distinctVarRef));
    DistinctOperator distinctOp = new DistinctOperator(distinctExprs);
    distinctOp.setSourceLocation(aggOp.getSourceLocation());
    distinctOp.getInputs().add(new MutableObject<>(inputOp));
    distinctOp.setExecutionMode(inputOp.getExecutionMode());
    context.computeAndSetTypeEnvironmentForOperator(distinctOp);
    // replace 'expr' with variable reference if ASSIGN was introduced
    for (Mutable<ILogicalExpression> aggExprRef : aggOp.getExpressions()) {
        AbstractFunctionCallExpression callExpr = (AbstractFunctionCallExpression) aggExprRef.getValue();
        FunctionIdentifier regularAggForDistinct = BuiltinFunctions.getAggregateFunctionForDistinct(callExpr.getFunctionIdentifier());
        if (regularAggForDistinct == null) {
            throw new IllegalStateException(String.valueOf(callExpr.getFunctionIdentifier()));
        }
        callExpr.setFunctionInfo(BuiltinFunctions.getAsterixFunctionInfo(regularAggForDistinct));
        if (assignOp != null) {
            callExpr.getArguments().get(0).setValue(distinctVarRef.cloneExpression());
        }
    }
    aggOp.getInputs().clear();
    aggOp.getInputs().add(new MutableObject<>(distinctOp));
    context.computeAndSetTypeEnvironmentForOperator(aggOp);
}
#end_block

#method_before
@Override
public boolean rewritePost(Mutable<ILogicalOperator> opRef, IOptimizationContext context) throws AlgebricksException {
    return false;
}
#method_after
@Override
public boolean rewritePost(Mutable<ILogicalOperator> opRef, IOptimizationContext context) {
    return false;
}
#end_block

#method_before
@Override
public IBinaryComparator createBinaryComparator() {
    return INSTANCE_COMP;
}
#method_after
@Override
public IBinaryComparator createBinaryComparator() {
    return ALinePartialBinaryComparatorFactory::compare;
}
#end_block

#method_before
@Override
public IBinaryComparator createBinaryComparator() {
    return INSTANCE_COMP;
}
#method_after
@Override
public IBinaryComparator createBinaryComparator() {
    return ACirclePartialBinaryComparatorFactory::compare;
}
#end_block

#method_before
@Override
public IBinaryComparator createBinaryComparator() {
    return INSTANCE_COMP;
}
#method_after
@Override
public IBinaryComparator createBinaryComparator() {
    return AIntervalDescPartialBinaryComparatorFactory::compare;
}
#end_block

#method_before
@Override
public IBinaryComparator createBinaryComparator() {
    return INSTANCE_COMP;
}
#method_after
@Override
public IBinaryComparator createBinaryComparator() {
    return APointPartialBinaryComparatorFactory::compare;
}
#end_block

#method_before
@Override
public IBinaryComparator createBinaryComparator() {
    return INSTANCE_COMP;
}
#method_after
@Override
public IBinaryComparator createBinaryComparator() {
    return ADurationPartialBinaryComparatorFactory::compare;
}
#end_block

#method_before
protected int compare(IAType leftType, byte[] b1, int s1, int l1, IAType rightType, byte[] b2, int s2, int l2) throws HyracksDataException {
    // therefore, inside this method, we return an order between two values even if one value is MISSING.
    if (b1[s1] == ATypeTag.SERIALIZED_MISSING_TYPE_TAG) {
        return b2[s2] == ATypeTag.SERIALIZED_MISSING_TYPE_TAG ? 0 : -1;
    } else {
        if (b2[s2] == ATypeTag.SERIALIZED_MISSING_TYPE_TAG) {
            return 1;
        }
    }
    // therefore, inside this method, we return an order between two values even if one value is NULL.
    if (b1[s1] == ATypeTag.SERIALIZED_NULL_TYPE_TAG) {
        return b2[s2] == ATypeTag.SERIALIZED_NULL_TYPE_TAG ? 0 : -1;
    } else {
        if (b2[s2] == ATypeTag.SERIALIZED_NULL_TYPE_TAG) {
            return 1;
        }
    }
    ATypeTag tag1 = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(b1[s1]);
    ATypeTag tag2 = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(b2[s2]);
    // and, we don't need to continue. We just compare raw byte by byte.
    if (tag1 == null || tag2 == null) {
        return rawComp.compare(b1, s1, l1, b2, s2, l2);
    }
    // if two type does not match, we identify the source and the target and
    // promote the source to the target type if they are compatible.
    ATypeTag sourceTypeTag = null;
    ATypeTag targetTypeTag = null;
    boolean areTwoTagsEqual = false;
    boolean typePromotionApplied = false;
    boolean leftValueChanged = false;
    if (tag1 != tag2) {
        // tag1 can be promoted to tag2 (e.g. tag1: SMALLINT, tag2: INTEGER)
        if (ATypeHierarchy.canPromote(tag1, tag2)) {
            sourceTypeTag = tag1;
            targetTypeTag = tag2;
            typePromotionApplied = true;
            leftValueChanged = true;
        // or tag2 can be promoted to tag1 (e.g. tag2: INTEGER, tag1: DOUBLE)
        } else if (ATypeHierarchy.canPromote(tag2, tag1)) {
            sourceTypeTag = tag2;
            targetTypeTag = tag1;
            typePromotionApplied = true;
        }
        // we promote the source to the target by using a promoteComputer
        if (typePromotionApplied) {
            castBuffer.reset();
            ITypeConvertComputer promoter = ATypeHierarchy.getTypePromoteComputer(sourceTypeTag, targetTypeTag);
            if (promoter != null) {
                try {
                    if (leftValueChanged) {
                        // left side is the source
                        promoter.convertType(b1, s1 + 1, l1 - 1, castBuffer.getDataOutput());
                    } else {
                        // right side is the source
                        promoter.convertType(b2, s2 + 1, l2 - 1, castBuffer.getDataOutput());
                    }
                } catch (IOException e) {
                    throw new HyracksDataException("ComparatorFactory - failed to promote the type:" + sourceTypeTag + " to the type:" + targetTypeTag);
                }
            } else {
                // No appropriate typePromoteComputer.
                throw new HyracksDataException("No appropriate typePromoteComputer exists for " + sourceTypeTag + " to the " + targetTypeTag + " type. Please check the code.");
            }
        }
    } else {
        // tag1 == tag2.
        sourceTypeTag = tag1;
        targetTypeTag = tag1;
        areTwoTagsEqual = true;
    }
    // this is especially useful when we need to generate some order between any two types.
    if ((!areTwoTagsEqual && !typePromotionApplied)) {
        return rawComp.compare(b1, s1, l1, b2, s2, l2);
    }
    // conduct actual compare()
    switch(targetTypeTag) {
        case UUID:
            return ascUUIDComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case BOOLEAN:
            return ascBoolComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case TINYINT:
            // No type promotion from another type to the TINYINT can happen
            return ascByteComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case SMALLINT:
            {
                if (!typePromotionApplied) {
                    // No type promotion case
                    return ascShortComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
                } else if (leftValueChanged) {
                    // Type promotion happened. Left side was the source
                    return ascShortComp.compare(castBuffer.getByteArray(), castBuffer.getStartOffset() + 1, castBuffer.getLength() - 1, b2, s2 + 1, l2 - 1);
                } else {
                    // Type promotion happened. Right side was the source
                    return ascShortComp.compare(b1, s1 + 1, l1 - 1, castBuffer.getByteArray(), castBuffer.getStartOffset() + 1, castBuffer.getLength() - 1);
                }
            }
        case TIME:
        case DATE:
        case YEARMONTHDURATION:
        case INTEGER:
            {
                if (!typePromotionApplied) {
                    // No type promotion case
                    return ascIntComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
                } else if (leftValueChanged) {
                    // Type promotion happened. Left side was the source
                    return ascIntComp.compare(castBuffer.getByteArray(), castBuffer.getStartOffset() + 1, castBuffer.getLength() - 1, b2, s2 + 1, l2 - 1);
                } else {
                    // Type promotion happened. Right side was the source
                    return ascIntComp.compare(b1, s1 + 1, l1 - 1, castBuffer.getByteArray(), castBuffer.getStartOffset() + 1, castBuffer.getLength() - 1);
                }
            }
        case DATETIME:
        case DAYTIMEDURATION:
        case BIGINT:
            {
                if (!typePromotionApplied) {
                    // No type promotion case
                    return ascLongComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
                } else if (leftValueChanged) {
                    // Type promotion happened. Left side was the source
                    return ascLongComp.compare(castBuffer.getByteArray(), castBuffer.getStartOffset() + 1, castBuffer.getLength() - 1, b2, s2 + 1, l2 - 1);
                } else {
                    // Type promotion happened. Right side was the source
                    return ascLongComp.compare(b1, s1 + 1, l1 - 1, castBuffer.getByteArray(), castBuffer.getStartOffset() + 1, castBuffer.getLength() - 1);
                }
            }
        case FLOAT:
            {
                if (!typePromotionApplied) {
                    // No type promotion case
                    return ascFloatComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
                } else if (leftValueChanged) {
                    // Type promotion happened. Left side was the source
                    return ascFloatComp.compare(castBuffer.getByteArray(), castBuffer.getStartOffset() + 1, castBuffer.getLength() - 1, b2, s2 + 1, l2 - 1);
                } else {
                    // Type promotion happened. Right side was the source
                    return ascFloatComp.compare(b1, s1 + 1, l1 - 1, castBuffer.getByteArray(), castBuffer.getStartOffset() + 1, castBuffer.getLength() - 1);
                }
            }
        case DOUBLE:
            {
                if (!typePromotionApplied) {
                    // No type promotion case
                    return ascDoubleComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
                } else if (leftValueChanged) {
                    // Type promotion happened. Left side was the source
                    return ascDoubleComp.compare(castBuffer.getByteArray(), castBuffer.getStartOffset() + 1, castBuffer.getLength() - 1, b2, s2 + 1, l2 - 1);
                } else {
                    // Type promotion happened. Right side was the source
                    return ascDoubleComp.compare(b1, s1 + 1, l1 - 1, castBuffer.getByteArray(), castBuffer.getStartOffset() + 1, castBuffer.getLength() - 1);
                }
            }
        case STRING:
            return ascStrComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case RECTANGLE:
            return ascRectangleComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case CIRCLE:
            return ascCircleComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case POINT:
            return ascPointComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case POINT3D:
            return ascPoint3DComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case LINE:
            return ascLineComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case POLYGON:
            return ascPolygonComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case DURATION:
            return ascDurationComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case INTERVAL:
            return compareInterval(b1, s1, l1, b2, s2, l2);
        case BINARY:
            return ascByteArrayComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case ARRAY:
            return compareArrays(leftType, b1, s1, l1, rightType, b2, s2, l2);
        case OBJECT:
            return compareRecords(leftType, b1, s1, l1, rightType, b2, s2, l2);
        default:
            // we include typeTag in comparison to compare between two type to enforce some ordering
            return rawComp.compare(b1, s1, l1, b2, s2, l2);
    }
}
#method_after
protected final int compare(IAType leftType, byte[] b1, int s1, int l1, IAType rightType, byte[] b2, int s2, int l2) throws HyracksDataException {
    if (b1[s1] == ATypeTag.SERIALIZED_MISSING_TYPE_TAG) {
        return b2[s2] == ATypeTag.SERIALIZED_MISSING_TYPE_TAG ? 0 : -1;
    } else if (b2[s2] == ATypeTag.SERIALIZED_MISSING_TYPE_TAG) {
        return 1;
    }
    if (b1[s1] == ATypeTag.SERIALIZED_NULL_TYPE_TAG) {
        return b2[s2] == ATypeTag.SERIALIZED_NULL_TYPE_TAG ? 0 : -1;
    } else if (b2[s2] == ATypeTag.SERIALIZED_NULL_TYPE_TAG) {
        return 1;
    }
    ATypeTag tag1 = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(b1[s1]);
    ATypeTag tag2 = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(b2[s2]);
    // tag being null could mean several things among of which is that the passed args are not tagged
    if (tag1 == null || tag2 == null) {
        return rawComp.compare(b1, s1, l1, b2, s2, l2);
    }
    if (ATypeHierarchy.isCompatible(tag1, tag2) && ATypeHierarchy.getTypeDomain(tag1) == Domain.NUMERIC) {
        return ComparatorUtil.compareNumbers(tag1, b1, s1 + 1, tag2, b2, s2 + 1);
    }
    // currently only numbers are compatible. if two tags are not compatible, we compare the tags to generate order
    if (tag1 != tag2) {
        return Byte.compare(b1[s1], b2[s2]);
    }
    switch(tag1) {
        case STRING:
            return ascStrComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case UUID:
            return ascUUIDComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case BOOLEAN:
            return ascBoolComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case TIME:
            return Integer.compare(ATimeSerializerDeserializer.getChronon(b1, s1 + 1), ATimeSerializerDeserializer.getChronon(b2, s2 + 1));
        case DATE:
            return Integer.compare(ADateSerializerDeserializer.getChronon(b1, s1 + 1), ADateSerializerDeserializer.getChronon(b2, s2 + 1));
        case YEARMONTHDURATION:
            return Integer.compare(AYearMonthDurationSerializerDeserializer.getYearMonth(b1, s1 + 1), AYearMonthDurationSerializerDeserializer.getYearMonth(b2, s2 + 1));
        case DATETIME:
            return Long.compare(ADateTimeSerializerDeserializer.getChronon(b1, s1 + 1), ADateTimeSerializerDeserializer.getChronon(b2, s2 + 1));
        case DAYTIMEDURATION:
            return Long.compare(ADayTimeDurationSerializerDeserializer.getDayTime(b1, s1 + 1), ADayTimeDurationSerializerDeserializer.getDayTime(b2, s2 + 1));
        case RECTANGLE:
            return ascRectangleComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case CIRCLE:
            return ascCircleComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case POINT:
            return ascPointComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case POINT3D:
            return ascPoint3DComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case LINE:
            return ascLineComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case POLYGON:
            return ascPolygonComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case DURATION:
            return ascDurationComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case INTERVAL:
            return compareInterval(b1, s1, l1, b2, s2, l2);
        case BINARY:
            return ascByteArrayComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case ARRAY:
            return compareArrays(leftType, b1, s1, l1, rightType, b2, s2, l2);
        case OBJECT:
            return compareRecords(leftType, b1, s1, l1, rightType, b2, s2, l2);
        default:
            return rawComp.compare(b1, s1, l1, b2, s2, l2);
    }
}
#end_block

#method_before
private int compareRecords(IAType leftType, byte[] b1, int s1, int l1, IAType rightType, byte[] b2, int s2, int l2) throws HyracksDataException {
    if (leftType == null || rightType == null) {
        return rawComp.compare(b1, s1, l1, b2, s2, l2);
    }
    ARecordType leftRecordType = (ARecordType) TypeComputeUtils.getActualTypeOrOpen(leftType, ATypeTag.OBJECT);
    ARecordType rightRecordType = (ARecordType) TypeComputeUtils.getActualTypeOrOpen(rightType, ATypeTag.OBJECT);
    ARecordVisitablePointable leftRecord = recordAllocator.allocateRecordValue(leftRecordType);
    ARecordVisitablePointable rightRecord = recordAllocator.allocateRecordValue(rightRecordType);
    PriorityQueue<IVisitablePointable> leftNamesHeap = null, rightNamesHeap = null;
    try {
        leftRecord.set(b1, s1, l1);
        rightRecord.set(b2, s2, l2);
        List<IVisitablePointable> leftFieldsNames = leftRecord.getFieldNames();
        List<IVisitablePointable> rightFieldsNames = rightRecord.getFieldNames();
        List<IVisitablePointable> leftFieldsValues = leftRecord.getFieldValues();
        List<IVisitablePointable> rightFieldsValues = rightRecord.getFieldValues();
        leftNamesHeap = heapAllocator.allocate(null);
        rightNamesHeap = heapAllocator.allocate(null);
        leftNamesHeap.clear();
        rightNamesHeap.clear();
        int numLeftValuedFields = CompareHashUtil.addToHeap(leftFieldsNames, leftFieldsValues, leftNamesHeap);
        int numRightValuedFields = CompareHashUtil.addToHeap(rightFieldsNames, rightFieldsValues, rightNamesHeap);
        if (numLeftValuedFields == 0 && numRightValuedFields == 0) {
            return 0;
        } else if (numLeftValuedFields == 0) {
            return -1;
        } else if (numRightValuedFields == 0) {
            return 1;
        }
        int result;
        int leftFieldIdx, rightFieldIdx;
        IAType leftFieldType, rightFieldType;
        IVisitablePointable leftFieldName, leftFieldValue, rightFieldName, rightFieldValue;
        while (!leftNamesHeap.isEmpty() && !rightNamesHeap.isEmpty()) {
            leftFieldName = leftNamesHeap.poll();
            rightFieldName = rightNamesHeap.poll();
            // compare the names first
            result = ascStrComp.compare(leftFieldName.getByteArray(), leftFieldName.getStartOffset() + 1, leftFieldName.getLength() - 1, rightFieldName.getByteArray(), rightFieldName.getStartOffset() + 1, rightFieldName.getLength() - 1);
            if (result != 0) {
                return result;
            }
            // then compare the values if the names are equal
            leftFieldIdx = CompareHashUtil.getIndex(leftFieldsNames, leftFieldName);
            rightFieldIdx = CompareHashUtil.getIndex(rightFieldsNames, rightFieldName);
            leftFieldValue = leftFieldsValues.get(leftFieldIdx);
            rightFieldValue = rightFieldsValues.get(rightFieldIdx);
            leftFieldType = CompareHashUtil.getType(leftRecordType, leftFieldIdx, leftFieldValue);
            rightFieldType = CompareHashUtil.getType(rightRecordType, rightFieldIdx, rightFieldValue);
            result = compare(leftFieldType, leftFieldValue.getByteArray(), leftFieldValue.getStartOffset(), leftFieldValue.getLength(), rightFieldType, rightFieldValue.getByteArray(), rightFieldValue.getStartOffset(), rightFieldValue.getLength());
            if (result != 0) {
                return result;
            }
        }
        return Integer.compare(numLeftValuedFields, numRightValuedFields);
    } finally {
        recordAllocator.freeRecord(rightRecord);
        recordAllocator.freeRecord(leftRecord);
        if (rightNamesHeap != null) {
            heapAllocator.free(rightNamesHeap);
        }
        if (leftNamesHeap != null) {
            heapAllocator.free(leftNamesHeap);
        }
    }
}
#method_after
private int compareRecords(IAType leftType, byte[] b1, int s1, int l1, IAType rightType, byte[] b2, int s2, int l2) throws HyracksDataException {
    if (leftType == null || rightType == null) {
        return rawComp.compare(b1, s1, l1, b2, s2, l2);
    }
    ARecordType leftRecordType = (ARecordType) TypeComputeUtils.getActualTypeOrOpen(leftType, ATypeTag.OBJECT);
    ARecordType rightRecordType = (ARecordType) TypeComputeUtils.getActualTypeOrOpen(rightType, ATypeTag.OBJECT);
    SortedRecord leftRecord = recordPool.allocate(leftRecordType);
    SortedRecord rightRecord = recordPool.allocate(rightRecordType);
    IPointable leftFieldValue = voidPointableAllocator.allocate(null);
    IPointable rightFieldValue = voidPointableAllocator.allocate(null);
    // TODO(ali): this is not ideal. should be removed when tagged pointables are introduced
    ArrayBackedValueStorage leftStorage = (ArrayBackedValueStorage) storageAllocator.allocate(null);
    ArrayBackedValueStorage rightStorage = (ArrayBackedValueStorage) storageAllocator.allocate(null);
    try {
        leftRecord.reset(b1, s1);
        rightRecord.reset(b2, s2);
        IAType leftFieldType, rightFieldType;
        RecordField leftField, rightField;
        int result;
        while (!leftRecord.isEmpty() && !rightRecord.isEmpty()) {
            leftField = leftRecord.poll();
            rightField = rightRecord.poll();
            // compare the names first
            result = RecordField.FIELD_NAME_COMP.compare(leftField, rightField);
            if (result != 0) {
                return result;
            }
            // then compare the values if the names are equal
            leftStorage.reset();
            rightStorage.reset();
            leftRecord.getFieldValue(leftField, leftFieldValue, leftStorage);
            rightRecord.getFieldValue(rightField, rightFieldValue, rightStorage);
            leftFieldType = leftRecord.getFieldType(leftField);
            rightFieldType = rightRecord.getFieldType(rightField);
            result = compare(leftFieldType, leftFieldValue.getByteArray(), leftFieldValue.getStartOffset(), leftFieldValue.getLength(), rightFieldType, rightFieldValue.getByteArray(), rightFieldValue.getStartOffset(), rightFieldValue.getLength());
            if (result != 0) {
                return result;
            }
        }
        return Integer.compare(leftRecord.size(), rightRecord.size());
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    } finally {
        recordPool.free(rightRecord);
        recordPool.free(leftRecord);
        voidPointableAllocator.free(rightFieldValue);
        voidPointableAllocator.free(leftFieldValue);
        storageAllocator.free(rightStorage);
        storageAllocator.free(leftStorage);
    }
}
#end_block

#method_before
@Override
public IBinaryComparator createBinaryComparator() {
    return INSTANCE_COMP;
}
#method_after
@Override
public IBinaryComparator createBinaryComparator() {
    return LongBinaryComparatorFactory::compare;
}
#end_block

#method_before
@Override
public IBinaryComparator createBinaryComparator() {
    return INSTANCE_COMP;
}
#method_after
@Override
public IBinaryComparator createBinaryComparator() {
    return BooleanBinaryComparatorFactory::compare;
}
#end_block

#method_before
public IBinaryComparator createBinaryComparator(final ATypeTag firstItemTypeTag, final ATypeTag secondItemTypeTag, final boolean ignoreCase) {
    return new IBinaryComparator() {

        final IBinaryComparator ascBoolComp = BooleanBinaryComparatorFactory.INSTANCE.createBinaryComparator();

        final IBinaryComparator ascIntComp = IntegerBinaryComparatorFactory.INSTANCE.createBinaryComparator();

        final IBinaryComparator ascLongComp = LongBinaryComparatorFactory.INSTANCE.createBinaryComparator();

        final IBinaryComparator ascStrComp = UTF8StringBinaryComparatorFactory.INSTANCE.createBinaryComparator();

        final IBinaryComparator ascLowerCaseStrComp = UTF8StringLowercaseBinaryComparatorFactory.INSTANCE.createBinaryComparator();

        final IBinaryComparator ascFloatComp = FloatBinaryComparatorFactory.INSTANCE.createBinaryComparator();

        final IBinaryComparator ascDoubleComp = DoubleBinaryComparatorFactory.INSTANCE.createBinaryComparator();

        final IBinaryComparator ascRectangleComp = ARectanglePartialBinaryComparatorFactory.INSTANCE.createBinaryComparator();

        final IBinaryComparator ascCircleComp = ACirclePartialBinaryComparatorFactory.INSTANCE.createBinaryComparator();

        final IBinaryComparator ascDurationComp = ADurationPartialBinaryComparatorFactory.INSTANCE.createBinaryComparator();

        final IBinaryComparator ascIntervalComp = AIntervalAscPartialBinaryComparatorFactory.INSTANCE.createBinaryComparator();

        final IBinaryComparator ascLineComp = ALinePartialBinaryComparatorFactory.INSTANCE.createBinaryComparator();

        final IBinaryComparator ascPointComp = APointPartialBinaryComparatorFactory.INSTANCE.createBinaryComparator();

        final IBinaryComparator ascPoint3DComp = APoint3DPartialBinaryComparatorFactory.INSTANCE.createBinaryComparator();

        final IBinaryComparator ascPolygonComp = APolygonPartialBinaryComparatorFactory.INSTANCE.createBinaryComparator();

        final IBinaryComparator ascUUIDComp = AUUIDPartialBinaryComparatorFactory.INSTANCE.createBinaryComparator();

        final IBinaryComparator ascByteArrayComp = ByteArrayBinaryComparatorFactory.INSTANCE.createBinaryComparator();

        final IBinaryComparator rawComp = RawBinaryComparatorFactory.INSTANCE.createBinaryComparator();

        @Override
        public int compare(byte[] b1, int s1, int l1, byte[] b2, int s2, int l2) throws HyracksDataException {
            // A list item cannot be MISSING.
            if (b1[s1] == ATypeTag.SERIALIZED_NULL_TYPE_TAG) {
                if (b2[s2] == ATypeTag.SERIALIZED_NULL_TYPE_TAG) {
                    return 0;
                } else {
                    return -1;
                }
            } else {
                if (b2[s2] == ATypeTag.SERIALIZED_NULL_TYPE_TAG) {
                    return 1;
                }
            }
            ATypeTag tag1 = firstItemTypeTag;
            int skip1 = 0;
            if (firstItemTypeTag == ATypeTag.ANY) {
                tag1 = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(b1[s1]);
                skip1 = 1;
            }
            ATypeTag tag2 = secondItemTypeTag;
            int skip2 = 0;
            if (secondItemTypeTag == ATypeTag.ANY) {
                tag2 = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(b2[s2]);
                skip2 = 1;
            }
            if (tag1 != tag2) {
                return rawComp.compare(b1, s1 + skip1, l1 - skip1, b2, s2 + skip2, l2 - skip2);
            }
            switch(tag1) {
                case UUID:
                    {
                        return ascUUIDComp.compare(b1, s1 + skip1, l1 - skip1, b2, s2 + skip2, l2 - skip2);
                    }
                case BOOLEAN:
                    {
                        return ascBoolComp.compare(b1, s1 + skip1, l1 - skip1, b2, s2 + skip2, l2 - skip2);
                    }
                case TIME:
                case DATE:
                case YEARMONTHDURATION:
                case INTEGER:
                    {
                        return ascIntComp.compare(b1, s1 + skip1, l1 - skip1, b2, s2 + skip2, l2 - skip2);
                    }
                case DATETIME:
                case DAYTIMEDURATION:
                case BIGINT:
                    {
                        return ascLongComp.compare(b1, s1 + skip1, l1 - skip1, b2, s2 + skip2, l2 - skip2);
                    }
                case FLOAT:
                    {
                        return ascFloatComp.compare(b1, s1 + skip1, l1 - skip1, b2, s2 + skip2, l2 - skip2);
                    }
                case DOUBLE:
                    {
                        return ascDoubleComp.compare(b1, s1 + skip1, l1 - skip1, b2, s2 + skip2, l2 - skip2);
                    }
                case STRING:
                    {
                        if (ignoreCase) {
                            return ascLowerCaseStrComp.compare(b1, s1 + skip1, l1 - skip1, b2, s2 + skip2, l2 - skip2);
                        } else {
                            return ascStrComp.compare(b1, s1 + skip1, l1 - skip1, b2, s2 + skip2, l2 - skip2);
                        }
                    }
                case RECTANGLE:
                    {
                        return ascRectangleComp.compare(b1, s1 + skip1, l1 - skip1, b2, s2 + skip2, l2 - skip2);
                    }
                case CIRCLE:
                    {
                        return ascCircleComp.compare(b1, s1 + skip1, l1 - skip1, b2, s2 + skip2, l2 - skip2);
                    }
                case POINT:
                    {
                        return ascPointComp.compare(b1, s1 + skip1, l1 - skip1, b2, s2 + skip2, l2 - skip2);
                    }
                case POINT3D:
                    {
                        return ascPoint3DComp.compare(b1, s1 + skip1, l1 - skip1, b2, s2 + skip2, l2 - skip2);
                    }
                case LINE:
                    {
                        return ascLineComp.compare(b1, s1 + skip1, l1 - skip1, b2, s2 + skip2, l2 - skip2);
                    }
                case POLYGON:
                    {
                        return ascPolygonComp.compare(b1, s1 + skip1, l1 - skip1, b2, s2 + skip2, l2 - skip2);
                    }
                case DURATION:
                    {
                        return ascDurationComp.compare(b1, s1 + skip1, l1 - skip1, b2, s2 + skip2, l2 - skip2);
                    }
                case INTERVAL:
                    {
                        return ascIntervalComp.compare(b1, s1 + skip1, l1 - skip1, b2, s2 + skip2, l2 - skip2);
                    }
                case BINARY:
                    {
                        return ascByteArrayComp.compare(b1, s1 + skip1, l1 - skip1, b2, s2 + skip2, l2 - skip2);
                    }
                default:
                    {
                        return rawComp.compare(b1, s1 + skip1, l1 - skip1, b2, s2 + skip2, l2 - skip2);
                    }
            }
        }
    };
}
#method_after
public IBinaryComparator createBinaryComparator(final ATypeTag firstItemTypeTag, final ATypeTag secondItemTypeTag, final boolean ignoreCase) {
    return new IBinaryComparator() {

        final IBinaryComparator ascBoolComp = BooleanBinaryComparatorFactory.INSTANCE.createBinaryComparator();

        final IBinaryComparator ascIntComp = new PointableBinaryComparatorFactory(IntegerPointable.FACTORY).createBinaryComparator();

        final IBinaryComparator ascLongComp = LongBinaryComparatorFactory.INSTANCE.createBinaryComparator();

        final IBinaryComparator ascStrComp = new PointableBinaryComparatorFactory(UTF8StringPointable.FACTORY).createBinaryComparator();

        final IBinaryComparator ascLowerCaseStrComp = new PointableBinaryComparatorFactory(UTF8StringLowercasePointable.FACTORY).createBinaryComparator();

        final IBinaryComparator ascFloatComp = new PointableBinaryComparatorFactory(FloatPointable.FACTORY).createBinaryComparator();

        final IBinaryComparator ascDoubleComp = new PointableBinaryComparatorFactory(DoublePointable.FACTORY).createBinaryComparator();

        final IBinaryComparator ascRectangleComp = ARectanglePartialBinaryComparatorFactory.INSTANCE.createBinaryComparator();

        final IBinaryComparator ascCircleComp = ACirclePartialBinaryComparatorFactory.INSTANCE.createBinaryComparator();

        final IBinaryComparator ascDurationComp = ADurationPartialBinaryComparatorFactory.INSTANCE.createBinaryComparator();

        final IBinaryComparator ascIntervalComp = AIntervalAscPartialBinaryComparatorFactory.INSTANCE.createBinaryComparator();

        final IBinaryComparator ascLineComp = ALinePartialBinaryComparatorFactory.INSTANCE.createBinaryComparator();

        final IBinaryComparator ascPointComp = APointPartialBinaryComparatorFactory.INSTANCE.createBinaryComparator();

        final IBinaryComparator ascPoint3DComp = APoint3DPartialBinaryComparatorFactory.INSTANCE.createBinaryComparator();

        final IBinaryComparator ascPolygonComp = APolygonPartialBinaryComparatorFactory.INSTANCE.createBinaryComparator();

        final IBinaryComparator ascUUIDComp = AUUIDPartialBinaryComparatorFactory.INSTANCE.createBinaryComparator();

        final IBinaryComparator ascByteArrayComp = new PointableBinaryComparatorFactory(ByteArrayPointable.FACTORY).createBinaryComparator();

        final IBinaryComparator rawComp = RawBinaryComparatorFactory.INSTANCE.createBinaryComparator();

        @Override
        public int compare(byte[] b1, int s1, int l1, byte[] b2, int s2, int l2) throws HyracksDataException {
            // A list item cannot be MISSING.
            if (b1[s1] == ATypeTag.SERIALIZED_NULL_TYPE_TAG) {
                if (b2[s2] == ATypeTag.SERIALIZED_NULL_TYPE_TAG) {
                    return 0;
                } else {
                    return -1;
                }
            } else {
                if (b2[s2] == ATypeTag.SERIALIZED_NULL_TYPE_TAG) {
                    return 1;
                }
            }
            ATypeTag tag1 = firstItemTypeTag;
            int skip1 = 0;
            if (firstItemTypeTag == ATypeTag.ANY) {
                tag1 = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(b1[s1]);
                skip1 = 1;
            }
            ATypeTag tag2 = secondItemTypeTag;
            int skip2 = 0;
            if (secondItemTypeTag == ATypeTag.ANY) {
                tag2 = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(b2[s2]);
                skip2 = 1;
            }
            if (tag1 != tag2) {
                return rawComp.compare(b1, s1 + skip1, l1 - skip1, b2, s2 + skip2, l2 - skip2);
            }
            switch(tag1) {
                case UUID:
                    {
                        return ascUUIDComp.compare(b1, s1 + skip1, l1 - skip1, b2, s2 + skip2, l2 - skip2);
                    }
                case BOOLEAN:
                    {
                        return ascBoolComp.compare(b1, s1 + skip1, l1 - skip1, b2, s2 + skip2, l2 - skip2);
                    }
                case TIME:
                case DATE:
                case YEARMONTHDURATION:
                case INTEGER:
                    {
                        return ascIntComp.compare(b1, s1 + skip1, l1 - skip1, b2, s2 + skip2, l2 - skip2);
                    }
                case DATETIME:
                case DAYTIMEDURATION:
                case BIGINT:
                    {
                        return ascLongComp.compare(b1, s1 + skip1, l1 - skip1, b2, s2 + skip2, l2 - skip2);
                    }
                case FLOAT:
                    {
                        return ascFloatComp.compare(b1, s1 + skip1, l1 - skip1, b2, s2 + skip2, l2 - skip2);
                    }
                case DOUBLE:
                    {
                        return ascDoubleComp.compare(b1, s1 + skip1, l1 - skip1, b2, s2 + skip2, l2 - skip2);
                    }
                case STRING:
                    {
                        if (ignoreCase) {
                            return ascLowerCaseStrComp.compare(b1, s1 + skip1, l1 - skip1, b2, s2 + skip2, l2 - skip2);
                        } else {
                            return ascStrComp.compare(b1, s1 + skip1, l1 - skip1, b2, s2 + skip2, l2 - skip2);
                        }
                    }
                case RECTANGLE:
                    {
                        return ascRectangleComp.compare(b1, s1 + skip1, l1 - skip1, b2, s2 + skip2, l2 - skip2);
                    }
                case CIRCLE:
                    {
                        return ascCircleComp.compare(b1, s1 + skip1, l1 - skip1, b2, s2 + skip2, l2 - skip2);
                    }
                case POINT:
                    {
                        return ascPointComp.compare(b1, s1 + skip1, l1 - skip1, b2, s2 + skip2, l2 - skip2);
                    }
                case POINT3D:
                    {
                        return ascPoint3DComp.compare(b1, s1 + skip1, l1 - skip1, b2, s2 + skip2, l2 - skip2);
                    }
                case LINE:
                    {
                        return ascLineComp.compare(b1, s1 + skip1, l1 - skip1, b2, s2 + skip2, l2 - skip2);
                    }
                case POLYGON:
                    {
                        return ascPolygonComp.compare(b1, s1 + skip1, l1 - skip1, b2, s2 + skip2, l2 - skip2);
                    }
                case DURATION:
                    {
                        return ascDurationComp.compare(b1, s1 + skip1, l1 - skip1, b2, s2 + skip2, l2 - skip2);
                    }
                case INTERVAL:
                    {
                        return ascIntervalComp.compare(b1, s1 + skip1, l1 - skip1, b2, s2 + skip2, l2 - skip2);
                    }
                case BINARY:
                    {
                        return ascByteArrayComp.compare(b1, s1 + skip1, l1 - skip1, b2, s2 + skip2, l2 - skip2);
                    }
                default:
                    {
                        return rawComp.compare(b1, s1 + skip1, l1 - skip1, b2, s2 + skip2, l2 - skip2);
                    }
            }
        }
    };
}
#end_block

#method_before
protected void registerClasses() {
    /* WARNING: Changing a resource id will break storage format backward compatibility.*/
    REGISTERED_CLASSES.put("Checkpoint", Checkpoint.class);
    // IResource
    REGISTERED_CLASSES.put("LocalResource", LocalResource.class);
    REGISTERED_CLASSES.put("DatasetLocalResource", DatasetLocalResource.class);
    REGISTERED_CLASSES.put("LSMBTreeLocalResource", LSMBTreeLocalResource.class);
    REGISTERED_CLASSES.put("LSMRTreeLocalResource", LSMRTreeLocalResource.class);
    REGISTERED_CLASSES.put("LSMRTreeWithAntiMatterLocalResource", LSMRTreeWithAntiMatterLocalResource.class);
    REGISTERED_CLASSES.put("LSMInvertedIndexLocalResource", LSMInvertedIndexLocalResource.class);
    REGISTERED_CLASSES.put("ExternalBTreeLocalResource", ExternalBTreeLocalResource.class);
    REGISTERED_CLASSES.put("ExternalBTreeWithBuddyLocalResource", ExternalBTreeWithBuddyLocalResource.class);
    REGISTERED_CLASSES.put("ExternalRTreeLocalResource", ExternalRTreeLocalResource.class);
    // ILSMMergePolicyFactory
    REGISTERED_CLASSES.put("NoMergePolicyFactory", NoMergePolicyFactory.class);
    REGISTERED_CLASSES.put("PrefixMergePolicyFactory", PrefixMergePolicyFactory.class);
    REGISTERED_CLASSES.put("ConstantMergePolicyFactory", ConstantMergePolicyFactory.class);
    REGISTERED_CLASSES.put("CorrelatedPrefixMergePolicyFactory", CorrelatedPrefixMergePolicyFactory.class);
    // ILSMIOOperationSchedulerProvider
    REGISTERED_CLASSES.put("RuntimeComponentsProvider", RuntimeComponentsProvider.class);
    // ITypeTraits
    REGISTERED_CLASSES.put("FixedLengthTypeTrait", FixedLengthTypeTrait.class);
    REGISTERED_CLASSES.put("VarLengthTypeTrait", VarLengthTypeTrait.class);
    // ILSMOperationTrackerFactory
    REGISTERED_CLASSES.put("PrimaryIndexOperationTrackerFactory", PrimaryIndexOperationTrackerFactory.class);
    REGISTERED_CLASSES.put("SecondaryIndexOperationTrackerFactory", SecondaryIndexOperationTrackerFactory.class);
    // ILSMComponentIdGeneratorFactory
    REGISTERED_CLASSES.put("DatasetLSMComponentIdGeneratorFactory", DatasetLSMComponentIdGeneratorFactory.class);
    // IDatasetInfoProvider
    REGISTERED_CLASSES.put("DatasetInfoProvider", DatasetInfoProvider.class);
    // ILSMOperationTrackerFactory
    REGISTERED_CLASSES.put("NoOpIOOperationCallbackFactory", NoOpIOOperationCallbackFactory.class);
    REGISTERED_CLASSES.put("LSMBTreeIOOperationCallbackFactory", LSMIndexIOOperationCallbackFactory.class);
    // ILSMIOOperationSchedulerProvider
    REGISTERED_CLASSES.put("AppendOnlyLinkedMetadataPageManagerFactory", AppendOnlyLinkedMetadataPageManagerFactory.class);
    // ILSMIOOperationSchedulerProvider
    REGISTERED_CLASSES.put("AsterixVirtualBufferCacheProvider", AsterixVirtualBufferCacheProvider.class);
    // IBinaryComparatorFactory
    REGISTERED_CLASSES.put("ACirclePartialBinaryComparatorFactory", ACirclePartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("ADurationPartialBinaryComparatorFactory", ADurationPartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("AIntervalAscPartialBinaryComparatorFactory", AIntervalAscPartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("AIntervalDescPartialBinaryComparatorFactory", AIntervalDescPartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("ALinePartialBinaryComparatorFactory", ALinePartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("AObjectAscBinaryComparatorFactory", AGenericAscBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("AObjectDescBinaryComparatorFactory", AGenericDescBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("APoint3DPartialBinaryComparatorFactory", APoint3DPartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("APointPartialBinaryComparatorFactory", APointPartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("APolygonPartialBinaryComparatorFactory", APolygonPartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("ARectanglePartialBinaryComparatorFactory", ARectanglePartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("AUUIDPartialBinaryComparatorFactory", AUUIDPartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("BooleanBinaryComparatorFactory", BooleanBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("ListItemBinaryComparatorFactory", ListItemBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("LongBinaryComparatorFactory", LongBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("RawBinaryComparatorFactory", RawBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("PointableBinaryComparatorFactory", PointableBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("HilbertDoubleComparatorFactory", HilbertDoubleComparatorFactory.class);
    REGISTERED_CLASSES.put("ZCurveDoubleComparatorFactory", ZCurveDoubleComparatorFactory.class);
    REGISTERED_CLASSES.put("ZCurveIntComparatorFactory", ZCurveIntComparatorFactory.class);
    REGISTERED_CLASSES.put("ComponentPosComparatorFactory", SecondaryCorrelatedTreeIndexOperationsHelper.ComponentPosComparatorFactory.class);
    REGISTERED_CLASSES.put("AnyBinaryComparatorFactory", AnyBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("OrderedBinaryComparatorFactory", OrderedBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("OrderedLinearizeComparatorFactory", OrderedLinearizeComparatorFactory.class);
    REGISTERED_CLASSES.put("ByteArrayBinaryComparatorFactory", ByteArrayBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("ByteBinaryComparatorFactory", ByteBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("DoubleBinaryComparatorFactory", DoubleBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("FloatBinaryComparatorFactory", FloatBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("IntegerBinaryComparatorFactory", IntegerBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("ShortBinaryComparatorFactory", ShortBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("UTF8StringBinaryComparatorFactory", UTF8StringBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("UTF8StringLowercaseBinaryComparatorFactory", UTF8StringLowercaseBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("UTF8StringLowercaseTokenBinaryComparatorFactory", UTF8StringLowercaseTokenBinaryComparatorFactory.class);
    // IPointableFactory
    REGISTERED_CLASSES.put("AIntervalPointableFactory", AIntervalPointable.AIntervalPointableFactory.class);
    REGISTERED_CLASSES.put("AListPointableFactory", AListPointable.AListPointableFactory.class);
    REGISTERED_CLASSES.put("ARecordPointableFactory", ARecordPointable.ARecordPointableFactory.class);
    REGISTERED_CLASSES.put("BooleanPointableFactory", BooleanPointable.BooleanPointableFactory.class);
    REGISTERED_CLASSES.put("ByteArrayPointableFactory", ByteArrayPointable.ByteArrayPointableFactory.class);
    REGISTERED_CLASSES.put("BytePointableFactory", BytePointable.BytePointableFactory.class);
    REGISTERED_CLASSES.put("DoublePointableFactory", DoublePointable.DoublePointableFactory.class);
    REGISTERED_CLASSES.put("FloatPointableFactory", FloatPointable.FloatPointableFactory.class);
    REGISTERED_CLASSES.put("IntegerPointableFactory", IntegerPointable.IntegerPointableFactory.class);
    REGISTERED_CLASSES.put("LongPointableFactory", LongPointable.LongPointableFactory.class);
    REGISTERED_CLASSES.put("RawUTF8StringPointableFactory", RawUTF8StringPointable.RawUTF8StringPointableFactory.class);
    REGISTERED_CLASSES.put("ShortPointableFactory", ShortPointable.ShortPointableFactory.class);
    REGISTERED_CLASSES.put("TaggedValuePointableFactory", TaggedValuePointable.TaggedValuePointableFactory.class);
    REGISTERED_CLASSES.put("UTF8StringLowercasePointableFactory", UTF8StringLowercasePointable.UTF8StringLowercasePointableFactory.class);
    REGISTERED_CLASSES.put("UTF8StringLowercaseTokenPointableFactory", UTF8StringLowercaseTokenPointable.UTF8StringLowercaseTokenPointableFactory.class);
    REGISTERED_CLASSES.put("UTF8StringPointableFactory", UTF8StringPointable.UTF8StringPointableFactory.class);
    REGISTERED_CLASSES.put("VoidPointableFactory", VoidPointable.VoidPointableFactory.class);
    // IPrimitiveValueProviderFactory
    REGISTERED_CLASSES.put("DoublePrimitiveValueProviderFactory", DoublePrimitiveValueProviderFactory.class);
    REGISTERED_CLASSES.put("FloatPrimitiveValueProviderFactory", FloatPrimitiveValueProviderFactory.class);
    REGISTERED_CLASSES.put("IntegerPrimitiveValueProviderFactory", IntegerPrimitiveValueProviderFactory.class);
    REGISTERED_CLASSES.put("PointablePrimitiveValueProviderFactory", PointablePrimitiveValueProviderFactory.class);
    REGISTERED_CLASSES.put("PrimitiveValueProviderFactory", PrimitiveValueProviderFactory.class);
    // IBinaryTokenizerFactory
    REGISTERED_CLASSES.put("AOrderedListBinaryTokenizerFactory", AOrderedListBinaryTokenizerFactory.class);
    REGISTERED_CLASSES.put("AUnorderedListBinaryTokenizerFactory", AUnorderedListBinaryTokenizerFactory.class);
    REGISTERED_CLASSES.put("NGramUTF8StringBinaryTokenizerFactory", NGramUTF8StringBinaryTokenizerFactory.class);
    REGISTERED_CLASSES.put("DelimitedUTF8StringBinaryTokenizerFactory", DelimitedUTF8StringBinaryTokenizerFactory.class);
    // ITokenFactory
    REGISTERED_CLASSES.put("AListElementTokenFactory", AListElementTokenFactory.class);
    REGISTERED_CLASSES.put("HashedUTF8NGramTokenFactory", HashedUTF8NGramTokenFactory.class);
    REGISTERED_CLASSES.put("HashedUTF8WordTokenFactory", HashedUTF8WordTokenFactory.class);
    REGISTERED_CLASSES.put("UTF8NGramTokenFactory", UTF8NGramTokenFactory.class);
    REGISTERED_CLASSES.put("UTF8WordTokenFactory", UTF8WordTokenFactory.class);
    REGISTERED_CLASSES.put("RTreePolicyType", RTreePolicyType.class);
    // IAType
    REGISTERED_CLASSES.put("BuiltinType", BuiltinType.class);
    REGISTERED_CLASSES.put("AOrderedListType", AOrderedListType.class);
    REGISTERED_CLASSES.put("ARecordType", ARecordType.class);
    REGISTERED_CLASSES.put("AUnionType", AUnionType.class);
    REGISTERED_CLASSES.put("AUnorderedListType", AUnorderedListType.class);
    // ICompressorDecompressorFactory
    CompressionManager.registerCompressorDecompressorsFactoryClasses(REGISTERED_CLASSES);
}
#method_after
protected void registerClasses() {
    /* WARNING: Changing a resource id will break storage format backward compatibility.*/
    REGISTERED_CLASSES.put("Checkpoint", Checkpoint.class);
    // IResource
    REGISTERED_CLASSES.put("LocalResource", LocalResource.class);
    REGISTERED_CLASSES.put("DatasetLocalResource", DatasetLocalResource.class);
    REGISTERED_CLASSES.put("LSMBTreeLocalResource", LSMBTreeLocalResource.class);
    REGISTERED_CLASSES.put("LSMRTreeLocalResource", LSMRTreeLocalResource.class);
    REGISTERED_CLASSES.put("LSMRTreeWithAntiMatterLocalResource", LSMRTreeWithAntiMatterLocalResource.class);
    REGISTERED_CLASSES.put("LSMInvertedIndexLocalResource", LSMInvertedIndexLocalResource.class);
    REGISTERED_CLASSES.put("ExternalBTreeLocalResource", ExternalBTreeLocalResource.class);
    REGISTERED_CLASSES.put("ExternalBTreeWithBuddyLocalResource", ExternalBTreeWithBuddyLocalResource.class);
    REGISTERED_CLASSES.put("ExternalRTreeLocalResource", ExternalRTreeLocalResource.class);
    // ILSMMergePolicyFactory
    REGISTERED_CLASSES.put("NoMergePolicyFactory", NoMergePolicyFactory.class);
    REGISTERED_CLASSES.put("PrefixMergePolicyFactory", PrefixMergePolicyFactory.class);
    REGISTERED_CLASSES.put("ConstantMergePolicyFactory", ConstantMergePolicyFactory.class);
    REGISTERED_CLASSES.put("CorrelatedPrefixMergePolicyFactory", CorrelatedPrefixMergePolicyFactory.class);
    // ILSMIOOperationSchedulerProvider
    REGISTERED_CLASSES.put("RuntimeComponentsProvider", RuntimeComponentsProvider.class);
    // ITypeTraits
    REGISTERED_CLASSES.put("FixedLengthTypeTrait", FixedLengthTypeTrait.class);
    REGISTERED_CLASSES.put("VarLengthTypeTrait", VarLengthTypeTrait.class);
    // ILSMOperationTrackerFactory
    REGISTERED_CLASSES.put("PrimaryIndexOperationTrackerFactory", PrimaryIndexOperationTrackerFactory.class);
    REGISTERED_CLASSES.put("SecondaryIndexOperationTrackerFactory", SecondaryIndexOperationTrackerFactory.class);
    // ILSMComponentIdGeneratorFactory
    REGISTERED_CLASSES.put("DatasetLSMComponentIdGeneratorFactory", DatasetLSMComponentIdGeneratorFactory.class);
    // IDatasetInfoProvider
    REGISTERED_CLASSES.put("DatasetInfoProvider", DatasetInfoProvider.class);
    // ILSMOperationTrackerFactory
    REGISTERED_CLASSES.put("NoOpIOOperationCallbackFactory", NoOpIOOperationCallbackFactory.class);
    REGISTERED_CLASSES.put("LSMBTreeIOOperationCallbackFactory", LSMIndexIOOperationCallbackFactory.class);
    // ILSMIOOperationSchedulerProvider
    REGISTERED_CLASSES.put("AppendOnlyLinkedMetadataPageManagerFactory", AppendOnlyLinkedMetadataPageManagerFactory.class);
    // ILSMIOOperationSchedulerProvider
    REGISTERED_CLASSES.put("AsterixVirtualBufferCacheProvider", AsterixVirtualBufferCacheProvider.class);
    // IBinaryComparatorFactory
    REGISTERED_CLASSES.put("ACirclePartialBinaryComparatorFactory", ACirclePartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("ADurationPartialBinaryComparatorFactory", ADurationPartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("AIntervalAscPartialBinaryComparatorFactory", AIntervalAscPartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("AIntervalDescPartialBinaryComparatorFactory", AIntervalDescPartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("ALinePartialBinaryComparatorFactory", ALinePartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("AObjectAscBinaryComparatorFactory", AGenericAscBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("AObjectDescBinaryComparatorFactory", AGenericDescBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("APoint3DPartialBinaryComparatorFactory", APoint3DPartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("APointPartialBinaryComparatorFactory", APointPartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("APolygonPartialBinaryComparatorFactory", APolygonPartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("ARectanglePartialBinaryComparatorFactory", ARectanglePartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("AUUIDPartialBinaryComparatorFactory", AUUIDPartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("BooleanBinaryComparatorFactory", BooleanBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("ListItemBinaryComparatorFactory", ListItemBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("LongBinaryComparatorFactory", LongBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("RawBinaryComparatorFactory", RawBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("PointableBinaryComparatorFactory", PointableBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("HilbertDoubleComparatorFactory", HilbertDoubleComparatorFactory.class);
    REGISTERED_CLASSES.put("ZCurveDoubleComparatorFactory", ZCurveDoubleComparatorFactory.class);
    REGISTERED_CLASSES.put("ZCurveIntComparatorFactory", ZCurveIntComparatorFactory.class);
    REGISTERED_CLASSES.put("ComponentPosComparatorFactory", SecondaryCorrelatedTreeIndexOperationsHelper.ComponentPosComparatorFactory.class);
    REGISTERED_CLASSES.put("AnyBinaryComparatorFactory", AnyBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("OrderedBinaryComparatorFactory", OrderedBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("OrderedLinearizeComparatorFactory", OrderedLinearizeComparatorFactory.class);
    // IPointableFactory
    REGISTERED_CLASSES.put("AIntervalPointableFactory", AIntervalPointable.AIntervalPointableFactory.class);
    REGISTERED_CLASSES.put("AListPointableFactory", AListPointable.AListPointableFactory.class);
    REGISTERED_CLASSES.put("ARecordPointableFactory", ARecordPointable.ARecordPointableFactory.class);
    REGISTERED_CLASSES.put("BooleanPointableFactory", BooleanPointable.BooleanPointableFactory.class);
    REGISTERED_CLASSES.put("ByteArrayPointableFactory", ByteArrayPointable.ByteArrayPointableFactory.class);
    REGISTERED_CLASSES.put("BytePointableFactory", BytePointable.BytePointableFactory.class);
    REGISTERED_CLASSES.put("DoublePointableFactory", DoublePointable.DoublePointableFactory.class);
    REGISTERED_CLASSES.put("FloatPointableFactory", FloatPointable.FloatPointableFactory.class);
    REGISTERED_CLASSES.put("IntegerPointableFactory", IntegerPointable.IntegerPointableFactory.class);
    REGISTERED_CLASSES.put("LongPointableFactory", LongPointable.LongPointableFactory.class);
    REGISTERED_CLASSES.put("RawUTF8StringPointableFactory", RawUTF8StringPointable.RawUTF8StringPointableFactory.class);
    REGISTERED_CLASSES.put("ShortPointableFactory", ShortPointable.ShortPointableFactory.class);
    REGISTERED_CLASSES.put("TaggedValuePointableFactory", TaggedValuePointable.TaggedValuePointableFactory.class);
    REGISTERED_CLASSES.put("UTF8StringLowercasePointableFactory", UTF8StringLowercasePointable.UTF8StringLowercasePointableFactory.class);
    REGISTERED_CLASSES.put("UTF8StringLowercaseTokenPointableFactory", UTF8StringLowercaseTokenPointable.UTF8StringLowercaseTokenPointableFactory.class);
    REGISTERED_CLASSES.put("UTF8StringPointableFactory", UTF8StringPointable.UTF8StringPointableFactory.class);
    REGISTERED_CLASSES.put("VoidPointableFactory", VoidPointable.VoidPointableFactory.class);
    // IPrimitiveValueProviderFactory
    REGISTERED_CLASSES.put("DoublePrimitiveValueProviderFactory", DoublePrimitiveValueProviderFactory.class);
    REGISTERED_CLASSES.put("FloatPrimitiveValueProviderFactory", FloatPrimitiveValueProviderFactory.class);
    REGISTERED_CLASSES.put("IntegerPrimitiveValueProviderFactory", IntegerPrimitiveValueProviderFactory.class);
    REGISTERED_CLASSES.put("PointablePrimitiveValueProviderFactory", PointablePrimitiveValueProviderFactory.class);
    REGISTERED_CLASSES.put("PrimitiveValueProviderFactory", PrimitiveValueProviderFactory.class);
    // IBinaryTokenizerFactory
    REGISTERED_CLASSES.put("AOrderedListBinaryTokenizerFactory", AOrderedListBinaryTokenizerFactory.class);
    REGISTERED_CLASSES.put("AUnorderedListBinaryTokenizerFactory", AUnorderedListBinaryTokenizerFactory.class);
    REGISTERED_CLASSES.put("NGramUTF8StringBinaryTokenizerFactory", NGramUTF8StringBinaryTokenizerFactory.class);
    REGISTERED_CLASSES.put("DelimitedUTF8StringBinaryTokenizerFactory", DelimitedUTF8StringBinaryTokenizerFactory.class);
    // ITokenFactory
    REGISTERED_CLASSES.put("AListElementTokenFactory", AListElementTokenFactory.class);
    REGISTERED_CLASSES.put("HashedUTF8NGramTokenFactory", HashedUTF8NGramTokenFactory.class);
    REGISTERED_CLASSES.put("HashedUTF8WordTokenFactory", HashedUTF8WordTokenFactory.class);
    REGISTERED_CLASSES.put("UTF8NGramTokenFactory", UTF8NGramTokenFactory.class);
    REGISTERED_CLASSES.put("UTF8WordTokenFactory", UTF8WordTokenFactory.class);
    REGISTERED_CLASSES.put("RTreePolicyType", RTreePolicyType.class);
    // IAType
    REGISTERED_CLASSES.put("BuiltinType", BuiltinType.class);
    REGISTERED_CLASSES.put("AOrderedListType", AOrderedListType.class);
    REGISTERED_CLASSES.put("ARecordType", ARecordType.class);
    REGISTERED_CLASSES.put("AUnionType", AUnionType.class);
    REGISTERED_CLASSES.put("AUnorderedListType", AUnorderedListType.class);
    // ICompressorDecompressorFactory
    CompressionManager.registerCompressorDecompressorsFactoryClasses(REGISTERED_CLASSES);
}
#end_block

#method_before
@Override
public IBinaryComparator createBinaryComparator() {
    return INSTANCE_COMP;
}
#method_after
@Override
public IBinaryComparator createBinaryComparator() {
    return ARectanglePartialBinaryComparatorFactory::compare;
}
#end_block

#method_before
@Override
public IBinaryComparator createBinaryComparator() {
    return INSTANCE_COMP;
}
#method_after
@Override
public IBinaryComparator createBinaryComparator() {
    return AIntervalAscPartialBinaryComparatorFactory::compare;
}
#end_block

#method_before
@Override
public IBinaryComparator createBinaryComparator() {
    return INSTANCE_COMP;
}
#method_after
@Override
public IBinaryComparator createBinaryComparator() {
    return APolygonPartialBinaryComparatorFactory::compare;
}
#end_block

#method_before
@Override
public IBinaryComparator createBinaryComparator() {
    return INSTANCE_COMP;
}
#method_after
@Override
public IBinaryComparator createBinaryComparator() {
    return APoint3DPartialBinaryComparatorFactory::compare;
}
#end_block

#method_before
@Override
public IBinaryComparator createBinaryComparator() {
    return INSTANCE_COMP;
}
#method_after
@Override
public IBinaryComparator createBinaryComparator() {
    return AUUIDPartialBinaryComparatorFactory::compare;
}
#end_block

#method_before
public static IAType getBuiltinTypeByTag(ATypeTag typeTag) throws HyracksDataException {
    IAType type = TAGS_TO_TYPES.get(typeTag);
    if (type != null) {
        return type;
    }
    // TODO(tillw) should be an internal error
    throw new HyracksDataException("Typetag " + typeTag + " is not a built-in type");
}
#method_after
public static IAType getBuiltinTypeByTag(ATypeTag typeTag) throws HyracksDataException {
    switch(typeTag) {
        case TINYINT:
            return BuiltinType.AINT8;
        case SMALLINT:
            return BuiltinType.AINT16;
        case INTEGER:
            return BuiltinType.AINT32;
        case BIGINT:
            return BuiltinType.AINT64;
        case BINARY:
            return BuiltinType.ABINARY;
        case BITARRAY:
            return BuiltinType.ABITARRAY;
        case FLOAT:
            return BuiltinType.AFLOAT;
        case DOUBLE:
            return BuiltinType.ADOUBLE;
        case STRING:
            return BuiltinType.ASTRING;
        case MISSING:
            return BuiltinType.AMISSING;
        case NULL:
            return BuiltinType.ANULL;
        case BOOLEAN:
            return BuiltinType.ABOOLEAN;
        case DATETIME:
            return BuiltinType.ADATETIME;
        case DATE:
            return BuiltinType.ADATE;
        case TIME:
            return BuiltinType.ATIME;
        case DURATION:
            return BuiltinType.ADURATION;
        case POINT:
            return BuiltinType.APOINT;
        case POINT3D:
            return BuiltinType.APOINT3D;
        case TYPE:
            return BuiltinType.ALL_TYPE;
        case ANY:
            return BuiltinType.ANY;
        case LINE:
            return BuiltinType.ALINE;
        case POLYGON:
            return BuiltinType.APOLYGON;
        case CIRCLE:
            return BuiltinType.ACIRCLE;
        case RECTANGLE:
            return BuiltinType.ARECTANGLE;
        case INTERVAL:
            return BuiltinType.AINTERVAL;
        case YEARMONTHDURATION:
            return BuiltinType.AYEARMONTHDURATION;
        case DAYTIMEDURATION:
            return BuiltinType.ADAYTIMEDURATION;
        case UUID:
            return BuiltinType.AUUID;
        case OBJECT:
            return RecordUtil.FULLY_OPEN_RECORD_TYPE;
        case MULTISET:
            return AUnorderedListType.FULLY_OPEN_UNORDEREDLIST_TYPE;
        case ARRAY:
            return AOrderedListType.FULL_OPEN_ORDEREDLIST_TYPE;
        case GEOMETRY:
            return BuiltinType.AGEOMETRY;
        default:
            // TODO(tillw) should be an internal error
            throw new HyracksDataException("Typetag " + typeTag + " is not a built-in type");
    }
}
#end_block

#method_before
public int getSchemeFieldCount(ARecordType recordType) {
    return recordType.getFieldNames().length;
}
#method_after
public final int getSchemeFieldCount(ARecordType recordType) {
    return recordType.getFieldNames().length;
}
#end_block

#method_before
@Override
public int getLength() {
    return IntegerPointable.getInteger(bytes, getLengthOffset());
}
#method_after
@Override
public int getLength() {
    return IntegerPointable.getInteger(bytes, start + TAG_SIZE);
}
#end_block

#method_before
private boolean isExpanded(ARecordType recordType) {
    if (isOpen(recordType)) {
        return BooleanPointable.getBoolean(bytes, getExpandedOffset());
    }
    return false;
}
#method_after
private boolean isExpanded(ARecordType recordType) {
    return isOpen(recordType) && BooleanPointable.getBoolean(bytes, start + TAG_SIZE + RECORD_LENGTH_SIZE);
}
#end_block

#method_before
private int getOpenPartOffset(ARecordType recordType) {
    return getExpandedOffset() + getExpandedSize(recordType);
}
#method_after
private int getOpenPartOffset(ARecordType recordType) {
    return start + TAG_SIZE + RECORD_LENGTH_SIZE + (isOpen(recordType) ? EXPANDED_SIZE : 0);
}
#end_block

#method_before
private int getNullBitmapOffset(ARecordType recordType) {
    return getClosedFieldCountOffset(recordType) + CLOSED_COUNT_SIZE;
}
#method_after
private int getNullBitmapOffset(ARecordType recordType) {
    return getOpenPartOffset(recordType) + (isExpanded(recordType) ? OPEN_OFFSET_SIZE : 0) + CLOSED_COUNT_SIZE;
}
#end_block

#method_before
public boolean isClosedFieldNull(ARecordType recordType, int fieldId) {
    if (getNullBitmapSize(recordType) > 0) {
        return RecordUtil.isNull(bytes[getNullBitmapOffset(recordType) + fieldId / 4], fieldId);
    }
    return false;
}
#method_after
public boolean isClosedFieldNull(ARecordType recordType, int fieldId) {
    return getNullBitmapSize(recordType) > 0 && RecordUtil.isNull(bytes[getNullBitmapOffset(recordType) + fieldId / 4], fieldId);
}
#end_block

#method_before
private boolean isClosedFieldMissing(ARecordType recordType, int fieldId) {
    if (getNullBitmapSize(recordType) > 0) {
        return RecordUtil.isMissing(bytes[getNullBitmapOffset(recordType) + fieldId / 4], fieldId);
    }
    return false;
}
#method_after
private boolean isClosedFieldMissing(ARecordType recordType, int fieldId) {
    return getNullBitmapSize(recordType) > 0 && RecordUtil.isMissing(bytes[getNullBitmapOffset(recordType) + fieldId / 4], fieldId);
}
#end_block

#method_before
// -----------------------
// Closed field accessors.
// -----------------------
public void getClosedFieldValue(ARecordType recordType, int fieldId, DataOutput dOut) throws IOException {
    if (isClosedFieldNull(recordType, fieldId)) {
        dOut.writeByte(ATypeTag.SERIALIZED_NULL_TYPE_TAG);
    } else if (isClosedFieldMissing(recordType, fieldId)) {
        dOut.writeByte(ATypeTag.SERIALIZED_MISSING_TYPE_TAG);
    } else {
        dOut.write(getClosedFieldTag(recordType, fieldId));
        dOut.write(bytes, getClosedFieldOffset(recordType, fieldId), getClosedFieldSize(recordType, fieldId));
    }
}
#method_after
// -----------------------
// Closed field accessors.
// -----------------------
public final void getClosedFieldValue(ARecordType recordType, int fieldId, DataOutput dOut) throws IOException {
    if (isClosedFieldNull(recordType, fieldId)) {
        dOut.writeByte(ATypeTag.SERIALIZED_NULL_TYPE_TAG);
    } else if (isClosedFieldMissing(recordType, fieldId)) {
        dOut.writeByte(ATypeTag.SERIALIZED_MISSING_TYPE_TAG);
    } else {
        dOut.write(getClosedFieldTag(recordType, fieldId));
        dOut.write(bytes, getClosedFieldOffset(recordType, fieldId), getClosedFieldSize(recordType, fieldId));
    }
}
#end_block

#method_before
public void getClosedFieldValue(ARecordType recordType, int fieldId, IPointable pointable) throws IOException {
    if (isClosedFieldNull(recordType, fieldId) || isClosedFieldMissing(recordType, fieldId)) {
        throw new IllegalStateException("Can't read a null or missing field");
    }
    pointable.set(bytes, getClosedFieldOffset(recordType, fieldId), getClosedFieldSize(recordType, fieldId));
}
#method_after
public final void getClosedFieldValue(ARecordType recordType, int fieldId, IPointable pointable) throws IOException {
    if (isClosedFieldNull(recordType, fieldId) || isClosedFieldMissing(recordType, fieldId)) {
        throw new IllegalStateException("Can't read a null or missing field");
    }
    pointable.set(bytes, getClosedFieldOffset(recordType, fieldId), getClosedFieldSize(recordType, fieldId));
}
#end_block

#method_before
public void getClosedFieldName(ARecordType recordType, int fieldId, DataOutput dOut) throws IOException {
    dOut.writeByte(ATypeTag.SERIALIZED_STRING_TYPE_TAG);
    utf8Writer.writeUTF8(getClosedFieldName(recordType, fieldId), dOut);
}
#method_after
public final void getClosedFieldName(ARecordType recordType, int fieldId, DataOutput dOut) throws IOException {
    dOut.writeByte(ATypeTag.SERIALIZED_STRING_TYPE_TAG);
    utf8Writer.writeUTF8(getClosedFieldName(recordType, fieldId), dOut);
}
#end_block

#method_before
public byte getClosedFieldTag(ARecordType recordType, int fieldId) {
    return getClosedFieldType(recordType, fieldId).getTypeTag().serialize();
}
#method_after
public final byte getClosedFieldTag(ARecordType recordType, int fieldId) {
    return getClosedFieldType(recordType, fieldId).getTypeTag().serialize();
}
#end_block

#method_before
public IAType getClosedFieldType(ARecordType recordType, int fieldId) {
    IAType aType = recordType.getFieldTypes()[fieldId];
    if (NonTaggedFormatUtil.isOptional(aType)) {
        // optional field: add the embedded non-null type tag
        aType = ((AUnionType) aType).getActualType();
    }
    return aType;
}
#method_after
public final IAType getClosedFieldType(ARecordType recordType, int fieldId) {
    IAType aType = recordType.getFieldTypes()[fieldId];
    if (NonTaggedFormatUtil.isOptional(aType)) {
        // optional field: add the embedded non-null type tag
        aType = ((AUnionType) aType).getActualType();
    }
    return aType;
}
#end_block

#method_before
public int getClosedFieldSize(ARecordType recordType, int fieldId) throws HyracksDataException {
    if (isClosedFieldNull(recordType, fieldId)) {
        return 0;
    }
    return NonTaggedFormatUtil.getFieldValueLength(bytes, getClosedFieldOffset(recordType, fieldId), getClosedFieldType(recordType, fieldId).getTypeTag(), false);
}
#method_after
public final int getClosedFieldSize(ARecordType recordType, int fieldId) throws HyracksDataException {
    if (isClosedFieldNull(recordType, fieldId)) {
        return 0;
    }
    return NonTaggedFormatUtil.getFieldValueLength(bytes, getClosedFieldOffset(recordType, fieldId), getClosedFieldType(recordType, fieldId).getTypeTag(), false);
}
#end_block

#method_before
public int getClosedFieldOffset(ARecordType recordType, int fieldId) {
    int offset = getNullBitmapOffset(recordType) + getNullBitmapSize(recordType) + fieldId * FIELD_OFFSET_SIZE;
    return start + IntegerPointable.getInteger(bytes, offset);
}
#method_after
public final int getClosedFieldOffset(ARecordType recordType, int fieldId) {
    int offset = getNullBitmapOffset(recordType) + getNullBitmapSize(recordType) + fieldId * FIELD_OFFSET_SIZE;
    return start + IntegerPointable.getInteger(bytes, offset);
}
#end_block

#method_before
// -----------------------
// Open field count.
// -----------------------
public int getOpenFieldCount(ARecordType recordType) {
    return isExpanded(recordType) ? IntegerPointable.getInteger(bytes, getOpenFieldCountOffset(recordType)) : 0;
}
#method_after
// -----------------------
// Open field count.
// -----------------------
public final int getOpenFieldCount(ARecordType recordType) {
    return isExpanded(recordType) ? IntegerPointable.getInteger(bytes, getOpenFieldCountOffset(recordType)) : 0;
}
#end_block

#method_before
// -----------------------
// Open field accessors.
// -----------------------
public void getOpenFieldValue(ARecordType recordType, int fieldId, DataOutput dOut) throws IOException {
    dOut.write(bytes, getOpenFieldValueOffset(recordType, fieldId), getOpenFieldValueSize(recordType, fieldId));
}
#method_after
// -----------------------
// Open field accessors.
// -----------------------
public final void getOpenFieldValue(ARecordType recordType, int fieldId, DataOutput dOut) throws IOException {
    dOut.write(bytes, getOpenFieldValueOffset(recordType, fieldId), getOpenFieldValueSize(recordType, fieldId));
}
#end_block

#method_before
public int getOpenFieldValueOffset(ARecordType recordType, int fieldId) {
    return getOpenFieldNameOffset(recordType, fieldId) + getOpenFieldNameSize(recordType, fieldId);
}
#method_after
public final int getOpenFieldValueOffset(ARecordType recordType, int fieldId) {
    return getOpenFieldNameOffset(recordType, fieldId) + getOpenFieldNameSize(recordType, fieldId);
}
#end_block

#method_before
public int getOpenFieldValueSize(ARecordType recordType, int fieldId) throws HyracksDataException {
    int offset = getOpenFieldValueOffset(recordType, fieldId);
    ATypeTag tag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(getOpenFieldTag(recordType, fieldId));
    return NonTaggedFormatUtil.getFieldValueLength(bytes, offset, tag, true);
}
#method_after
public final int getOpenFieldValueSize(ARecordType recordType, int fieldId) throws HyracksDataException {
    int offset = getOpenFieldValueOffset(recordType, fieldId);
    ATypeTag tag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(getOpenFieldTag(recordType, fieldId));
    return NonTaggedFormatUtil.getFieldValueLength(bytes, offset, tag, true);
}
#end_block

#method_before
public void getOpenFieldName(ARecordType recordType, int fieldId, DataOutput dOut) throws IOException {
    dOut.writeByte(ATypeTag.SERIALIZED_STRING_TYPE_TAG);
    dOut.write(bytes, getOpenFieldNameOffset(recordType, fieldId), getOpenFieldNameSize(recordType, fieldId));
}
#method_after
public final void getOpenFieldName(ARecordType recordType, int fieldId, DataOutput dOut) throws IOException {
    dOut.writeByte(ATypeTag.SERIALIZED_STRING_TYPE_TAG);
    dOut.write(bytes, getOpenFieldNameOffset(recordType, fieldId), getOpenFieldNameSize(recordType, fieldId));
}
#end_block

#method_before
public String getOpenFieldName(ARecordType recordType, int fieldId) throws IOException {
    StringBuilder str = new StringBuilder();
    int offset = getOpenFieldNameOffset(recordType, fieldId);
    UTF8StringUtil.toString(str, bytes, offset);
    String fieldName = str.toString();
    return fieldName;
}
#method_after
public final String getOpenFieldName(ARecordType recordType, int fieldId) {
    StringBuilder str = new StringBuilder();
    int offset = getOpenFieldNameOffset(recordType, fieldId);
    return UTF8StringUtil.toString(str, bytes, offset).toString();
}
#end_block

#method_before
public byte getOpenFieldTag(ARecordType recordType, int fieldId) {
    return bytes[getOpenFieldValueOffset(recordType, fieldId)];
}
#method_after
public final byte getOpenFieldTag(ARecordType recordType, int fieldId) {
    return bytes[getOpenFieldValueOffset(recordType, fieldId)];
}
#end_block

#method_before
@Override
protected IAType getResultType(ILogicalExpression expr, IAType... strippedInputTypes) throws AlgebricksException {
    AbstractFunctionCallExpression funcExpr = (AbstractFunctionCallExpression) expr;
    FunctionIdentifier funcId = funcExpr.getFunctionIdentifier();
    IAType t1 = strippedInputTypes[0];
    IAType t2 = strippedInputTypes[1];
    ATypeTag tag1 = t1.getTypeTag();
    ATypeTag tag2 = t2.getTypeTag();
    IAType type;
    switch(tag1) {
        case DOUBLE:
            switch(tag2) {
                case TINYINT:
                case SMALLINT:
                case INTEGER:
                case BIGINT:
                case FLOAT:
                case DOUBLE:
                    type = BuiltinType.ADOUBLE;
                    break;
                case ANY:
                    type = BuiltinType.ANY;
                    break;
                default:
                    throw new IncompatibleTypeException(funcExpr.getSourceLocation(), funcId, tag1, tag2);
            }
            break;
        case FLOAT:
            switch(tag2) {
                case TINYINT:
                case SMALLINT:
                case INTEGER:
                case BIGINT:
                case FLOAT:
                    type = BuiltinType.AFLOAT;
                    break;
                case DOUBLE:
                    type = BuiltinType.ADOUBLE;
                    break;
                case ANY:
                    type = BuiltinType.ANY;
                    break;
                default:
                    throw new IncompatibleTypeException(funcExpr.getSourceLocation(), funcId, tag1, tag2);
            }
            break;
        case BIGINT:
            switch(tag2) {
                case TINYINT:
                case SMALLINT:
                case INTEGER:
                case BIGINT:
                    type = BuiltinType.AINT64;
                    break;
                case FLOAT:
                    type = BuiltinType.AFLOAT;
                    break;
                case DOUBLE:
                    type = BuiltinType.ADOUBLE;
                    break;
                case ANY:
                    type = BuiltinType.ANY;
                    break;
                default:
                    throw new IncompatibleTypeException(funcExpr.getSourceLocation(), funcId, tag1, tag2);
            }
            break;
        case INTEGER:
            switch(tag2) {
                case TINYINT:
                case SMALLINT:
                case INTEGER:
                    type = BuiltinType.AINT32;
                    break;
                case BIGINT:
                    type = BuiltinType.AINT64;
                    break;
                case FLOAT:
                    type = BuiltinType.AFLOAT;
                    break;
                case DOUBLE:
                    type = BuiltinType.ADOUBLE;
                    break;
                case ANY:
                    type = BuiltinType.ANY;
                    break;
                default:
                    throw new IncompatibleTypeException(funcExpr.getSourceLocation(), funcId, tag1, tag2);
            }
            break;
        case SMALLINT:
            switch(tag2) {
                case TINYINT:
                case SMALLINT:
                    type = BuiltinType.AINT16;
                    break;
                case INTEGER:
                    type = BuiltinType.AINT32;
                    break;
                case BIGINT:
                    type = BuiltinType.AINT64;
                    break;
                case FLOAT:
                    type = BuiltinType.AFLOAT;
                    break;
                case DOUBLE:
                    type = BuiltinType.ADOUBLE;
                    break;
                case ANY:
                    type = BuiltinType.ANY;
                    break;
                default:
                    throw new IncompatibleTypeException(funcExpr.getSourceLocation(), funcId, tag1, tag2);
            }
            break;
        case TINYINT:
            switch(tag2) {
                case TINYINT:
                    type = BuiltinType.AINT8;
                    break;
                case SMALLINT:
                    type = BuiltinType.AINT16;
                    break;
                case INTEGER:
                    type = BuiltinType.AINT32;
                    break;
                case BIGINT:
                    type = BuiltinType.AINT64;
                    break;
                case FLOAT:
                    type = BuiltinType.AFLOAT;
                    break;
                case DOUBLE:
                    type = BuiltinType.ADOUBLE;
                    break;
                case ANY:
                    type = BuiltinType.ANY;
                    break;
                default:
                    throw new IncompatibleTypeException(funcExpr.getSourceLocation(), funcId, tag1, tag2);
            }
            break;
        case ANY:
            switch(tag2) {
                case TINYINT:
                case SMALLINT:
                case INTEGER:
                case BIGINT:
                case FLOAT:
                case ANY:
                case DOUBLE:
                    type = BuiltinType.ANY;
                    break;
                default:
                    throw new IncompatibleTypeException(funcExpr.getSourceLocation(), funcId, tag1, tag2);
            }
            break;
        case DATE:
            switch(tag2) {
                case DATE:
                    type = BuiltinType.ADURATION;
                    break;
                case YEARMONTHDURATION:
                case DAYTIMEDURATION:
                case DURATION:
                    type = BuiltinType.ADATE;
                    break;
                case ANY:
                    type = BuiltinType.ANY;
                    break;
                default:
                    throw new IncompatibleTypeException(funcExpr.getSourceLocation(), funcId, tag1, tag2);
            }
            break;
        case TIME:
            switch(tag2) {
                case TIME:
                    type = BuiltinType.ADURATION;
                    break;
                case YEARMONTHDURATION:
                case DAYTIMEDURATION:
                case DURATION:
                    type = BuiltinType.ATIME;
                    break;
                case ANY:
                    type = BuiltinType.ANY;
                    break;
                default:
                    throw new IncompatibleTypeException(funcExpr.getSourceLocation(), funcId, tag1, tag2);
            }
            break;
        case DATETIME:
            switch(tag2) {
                case DATETIME:
                    type = BuiltinType.ADURATION;
                    break;
                case YEARMONTHDURATION:
                case DAYTIMEDURATION:
                case DURATION:
                    type = BuiltinType.ADATETIME;
                    break;
                default:
                    throw new IncompatibleTypeException(funcExpr.getSourceLocation(), funcId, tag1, tag2);
            }
            break;
        case DURATION:
            switch(tag2) {
                case DATE:
                    type = BuiltinType.ADATE;
                    break;
                case TIME:
                    type = BuiltinType.ATIME;
                    break;
                case DATETIME:
                    type = BuiltinType.ADATETIME;
                    break;
                case ANY:
                    type = BuiltinType.ANY;
                    break;
                default:
                    throw new IncompatibleTypeException(funcExpr.getSourceLocation(), funcId, tag1, tag2);
            }
            break;
        case YEARMONTHDURATION:
            switch(tag2) {
                case DATE:
                    type = BuiltinType.ADATE;
                    break;
                case TIME:
                    type = BuiltinType.ATIME;
                    break;
                case DATETIME:
                    type = BuiltinType.ADATETIME;
                    break;
                case YEARMONTHDURATION:
                    type = BuiltinType.AYEARMONTHDURATION;
                    break;
                case ANY:
                    type = BuiltinType.ANY;
                    break;
                default:
                    throw new IncompatibleTypeException(funcExpr.getSourceLocation(), funcId, tag1, tag2);
            }
            break;
        case DAYTIMEDURATION:
            switch(tag2) {
                case DATE:
                    type = BuiltinType.ADATE;
                    break;
                case TIME:
                    type = BuiltinType.ATIME;
                    break;
                case DATETIME:
                    type = BuiltinType.ADATETIME;
                    break;
                case DAYTIMEDURATION:
                    type = BuiltinType.ADAYTIMEDURATION;
                    break;
                case ANY:
                    type = BuiltinType.ANY;
                    break;
                default:
                    throw new IncompatibleTypeException(funcExpr.getSourceLocation(), funcId, tag1, tag2);
            }
            break;
        default:
            throw new IncompatibleTypeException(funcExpr.getSourceLocation(), funcId, tag1, tag2);
    }
    if (nullable && type.getTypeTag() != ATypeTag.ANY) {
        type = AUnionType.createNullableType(type);
    }
    return type;
}
#method_after
@Override
protected IAType getResultType(ILogicalExpression expr, IAType... strippedInputTypes) throws AlgebricksException {
    AbstractFunctionCallExpression funcExpr = (AbstractFunctionCallExpression) expr;
    FunctionIdentifier funcId = funcExpr.getFunctionIdentifier();
    IAType t1 = strippedInputTypes[0];
    IAType t2 = strippedInputTypes[1];
    ATypeTag tag1 = t1.getTypeTag();
    ATypeTag tag2 = t2.getTypeTag();
    IAType type;
    switch(tag1) {
        case DOUBLE:
            switch(tag2) {
                case TINYINT:
                case SMALLINT:
                case INTEGER:
                case BIGINT:
                case FLOAT:
                case DOUBLE:
                    type = BuiltinType.ADOUBLE;
                    break;
                case ANY:
                    type = BuiltinType.ANY;
                    break;
                default:
                    throw new IncompatibleTypeException(funcExpr.getSourceLocation(), funcId, tag1, tag2);
            }
            break;
        case FLOAT:
            switch(tag2) {
                case TINYINT:
                case SMALLINT:
                case INTEGER:
                case BIGINT:
                case FLOAT:
                    type = BuiltinType.AFLOAT;
                    break;
                case DOUBLE:
                    type = BuiltinType.ADOUBLE;
                    break;
                case ANY:
                    type = BuiltinType.ANY;
                    break;
                default:
                    throw new IncompatibleTypeException(funcExpr.getSourceLocation(), funcId, tag1, tag2);
            }
            break;
        case BIGINT:
            switch(tag2) {
                case TINYINT:
                case SMALLINT:
                case INTEGER:
                case BIGINT:
                    type = BuiltinType.AINT64;
                    break;
                case FLOAT:
                    type = BuiltinType.AFLOAT;
                    break;
                case DOUBLE:
                    type = BuiltinType.ADOUBLE;
                    break;
                case ANY:
                    type = BuiltinType.ANY;
                    break;
                default:
                    throw new IncompatibleTypeException(funcExpr.getSourceLocation(), funcId, tag1, tag2);
            }
            break;
        case INTEGER:
            switch(tag2) {
                case TINYINT:
                case SMALLINT:
                case INTEGER:
                    type = BuiltinType.AINT32;
                    break;
                case BIGINT:
                    type = BuiltinType.AINT64;
                    break;
                case FLOAT:
                    type = BuiltinType.AFLOAT;
                    break;
                case DOUBLE:
                    type = BuiltinType.ADOUBLE;
                    break;
                case ANY:
                    type = BuiltinType.ANY;
                    break;
                default:
                    throw new IncompatibleTypeException(funcExpr.getSourceLocation(), funcId, tag1, tag2);
            }
            break;
        case SMALLINT:
            switch(tag2) {
                case TINYINT:
                case SMALLINT:
                    type = BuiltinType.AINT16;
                    break;
                case INTEGER:
                    type = BuiltinType.AINT32;
                    break;
                case BIGINT:
                    type = BuiltinType.AINT64;
                    break;
                case FLOAT:
                    type = BuiltinType.AFLOAT;
                    break;
                case DOUBLE:
                    type = BuiltinType.ADOUBLE;
                    break;
                case ANY:
                    type = BuiltinType.ANY;
                    break;
                default:
                    throw new IncompatibleTypeException(funcExpr.getSourceLocation(), funcId, tag1, tag2);
            }
            break;
        case TINYINT:
            switch(tag2) {
                case TINYINT:
                    type = BuiltinType.AINT8;
                    break;
                case SMALLINT:
                    type = BuiltinType.AINT16;
                    break;
                case INTEGER:
                    type = BuiltinType.AINT32;
                    break;
                case BIGINT:
                    type = BuiltinType.AINT64;
                    break;
                case FLOAT:
                    type = BuiltinType.AFLOAT;
                    break;
                case DOUBLE:
                    type = BuiltinType.ADOUBLE;
                    break;
                case ANY:
                    type = BuiltinType.ANY;
                    break;
                default:
                    throw new IncompatibleTypeException(funcExpr.getSourceLocation(), funcId, tag1, tag2);
            }
            break;
        case ANY:
            switch(tag2) {
                case TINYINT:
                case SMALLINT:
                case INTEGER:
                case BIGINT:
                case FLOAT:
                case DOUBLE:
                case DATE:
                case TIME:
                case DATETIME:
                case DURATION:
                case YEARMONTHDURATION:
                case DAYTIMEDURATION:
                case ANY:
                    type = BuiltinType.ANY;
                    break;
                default:
                    throw new IncompatibleTypeException(funcExpr.getSourceLocation(), funcId, tag1, tag2);
            }
            break;
        case DATE:
            switch(tag2) {
                case DATE:
                    type = BuiltinType.ADURATION;
                    break;
                case YEARMONTHDURATION:
                case DAYTIMEDURATION:
                case DURATION:
                    type = BuiltinType.ADATE;
                    break;
                case ANY:
                    type = BuiltinType.ANY;
                    break;
                default:
                    throw new IncompatibleTypeException(funcExpr.getSourceLocation(), funcId, tag1, tag2);
            }
            break;
        case TIME:
            switch(tag2) {
                case TIME:
                    type = BuiltinType.ADURATION;
                    break;
                case YEARMONTHDURATION:
                case DAYTIMEDURATION:
                case DURATION:
                    type = BuiltinType.ATIME;
                    break;
                case ANY:
                    type = BuiltinType.ANY;
                    break;
                default:
                    throw new IncompatibleTypeException(funcExpr.getSourceLocation(), funcId, tag1, tag2);
            }
            break;
        case DATETIME:
            switch(tag2) {
                case DATETIME:
                    type = BuiltinType.ADURATION;
                    break;
                case YEARMONTHDURATION:
                case DAYTIMEDURATION:
                case DURATION:
                    type = BuiltinType.ADATETIME;
                    break;
                default:
                    throw new IncompatibleTypeException(funcExpr.getSourceLocation(), funcId, tag1, tag2);
            }
            break;
        case DURATION:
            switch(tag2) {
                case DATE:
                    type = BuiltinType.ADATE;
                    break;
                case TIME:
                    type = BuiltinType.ATIME;
                    break;
                case DATETIME:
                    type = BuiltinType.ADATETIME;
                    break;
                case ANY:
                    type = BuiltinType.ANY;
                    break;
                default:
                    throw new IncompatibleTypeException(funcExpr.getSourceLocation(), funcId, tag1, tag2);
            }
            break;
        case YEARMONTHDURATION:
            switch(tag2) {
                case DATE:
                    type = BuiltinType.ADATE;
                    break;
                case TIME:
                    type = BuiltinType.ATIME;
                    break;
                case DATETIME:
                    type = BuiltinType.ADATETIME;
                    break;
                case YEARMONTHDURATION:
                    type = BuiltinType.AYEARMONTHDURATION;
                    break;
                case ANY:
                    type = BuiltinType.ANY;
                    break;
                default:
                    throw new IncompatibleTypeException(funcExpr.getSourceLocation(), funcId, tag1, tag2);
            }
            break;
        case DAYTIMEDURATION:
            switch(tag2) {
                case DATE:
                    type = BuiltinType.ADATE;
                    break;
                case TIME:
                    type = BuiltinType.ATIME;
                    break;
                case DATETIME:
                    type = BuiltinType.ADATETIME;
                    break;
                case DAYTIMEDURATION:
                    type = BuiltinType.ADAYTIMEDURATION;
                    break;
                case ANY:
                    type = BuiltinType.ANY;
                    break;
                default:
                    throw new IncompatibleTypeException(funcExpr.getSourceLocation(), funcId, tag1, tag2);
            }
            break;
        default:
            throw new IncompatibleTypeException(funcExpr.getSourceLocation(), funcId, tag1, tag2);
    }
    if (nullable && type.getTypeTag() != ATypeTag.ANY) {
        type = AUnionType.createNullableType(type);
    }
    return type;
}
#end_block

#method_before
static Result compareNumbers(ATypeTag leftTag, IPointable left, ATypeTag rightTag, IPointable right) {
    int result = compareNumbers(leftTag, left.getByteArray(), left.getStartOffset() + 1, rightTag, right.getByteArray(), right.getStartOffset() + 1);
    return ILogicalBinaryComparator.asResult(result);
}
#method_after
static Result compareNumbers(ATypeTag leftTag, IPointable left, ATypeTag rightTag, IPointable right) {
    return asResult(compareNumbers(leftTag, left.getByteArray(), left.getStartOffset() + 1, rightTag, right.getByteArray(), right.getStartOffset() + 1));
}
#end_block

#method_before
static int compareNumbers(ATypeTag lTag, byte[] l, int lStart, ATypeTag rTag, byte[] r, int rStart) {
    int result;
    if (lTag == DOUBLE || rTag == DOUBLE) {
        result = Double.compare(getDoubleValue(lTag, l, lStart), getDoubleValue(rTag, r, rStart));
    } else if (lTag == FLOAT || rTag == FLOAT) {
        result = Float.compare((float) getDoubleValue(lTag, l, lStart), (float) getDoubleValue(rTag, r, rStart));
    } else if (lTag == BIGINT || rTag == BIGINT) {
        result = Long.compare(getLongValue(lTag, l, lStart), getLongValue(rTag, r, rStart));
    } else if (lTag == INTEGER || lTag == SMALLINT || lTag == TINYINT) {
        result = Integer.compare((int) getLongValue(lTag, l, lStart), (int) getLongValue(rTag, r, rStart));
    } else {
        // TODO(ali): use unsupported type
        throw new UnsupportedOperationException();
    }
    return result;
}
#method_after
static int compareNumbers(ATypeTag lTag, byte[] l, int lStart, ATypeTag rTag, byte[] r, int rStart) {
    if (lTag == DOUBLE || rTag == DOUBLE) {
        return Double.compare(getDoubleValue(lTag, l, lStart), getDoubleValue(rTag, r, rStart));
    } else if (lTag == FLOAT || rTag == FLOAT) {
        return Float.compare((float) getDoubleValue(lTag, l, lStart), (float) getDoubleValue(rTag, r, rStart));
    } else if (lTag == BIGINT || rTag == BIGINT) {
        return Long.compare(getLongValue(lTag, l, lStart), getLongValue(rTag, r, rStart));
    } else if (lTag == INTEGER || lTag == SMALLINT || lTag == TINYINT) {
        return Integer.compare((int) getLongValue(lTag, l, lStart), (int) getLongValue(rTag, r, rStart));
    }
    // TODO(ali): use unsupported type
    throw new UnsupportedOperationException();
}
#end_block

#method_before
static Result compareNumWithConstant(ATypeTag leftTag, IPointable left, IAObject right) {
    int result;
    ATypeTag rightTag = right.getType().getTypeTag();
    byte[] leftBytes = left.getByteArray();
    int start = left.getStartOffset() + 1;
    if (leftTag == DOUBLE || rightTag == DOUBLE) {
        result = Double.compare(getDoubleValue(leftTag, leftBytes, start), getConstantDouble(right));
    } else if (leftTag == FLOAT || rightTag == FLOAT) {
        result = Float.compare((float) getDoubleValue(leftTag, leftBytes, start), (float) getConstantDouble(right));
    } else if (leftTag == BIGINT || rightTag == BIGINT) {
        result = Long.compare(getLongValue(leftTag, leftBytes, start), getConstantLong(right));
    } else if (leftTag == INTEGER || leftTag == SMALLINT || leftTag == TINYINT) {
        result = Integer.compare((int) getLongValue(leftTag, leftBytes, start), (int) getConstantLong(right));
    } else {
        return null;
    }
    return ILogicalBinaryComparator.asResult(result);
}
#method_after
static Result compareNumWithConstant(ATypeTag leftTag, IPointable left, IAObject right) {
    ATypeTag rightTag = right.getType().getTypeTag();
    byte[] leftBytes = left.getByteArray();
    int start = left.getStartOffset() + 1;
    if (leftTag == DOUBLE || rightTag == DOUBLE) {
        return asResult(Double.compare(getDoubleValue(leftTag, leftBytes, start), getConstantDouble(right)));
    } else if (leftTag == FLOAT || rightTag == FLOAT) {
        return asResult(Float.compare((float) getDoubleValue(leftTag, leftBytes, start), (float) getConstantDouble(right)));
    } else if (leftTag == BIGINT || rightTag == BIGINT) {
        return asResult(Long.compare(getLongValue(leftTag, leftBytes, start), getConstantLong(right)));
    } else if (leftTag == INTEGER || leftTag == SMALLINT || leftTag == TINYINT) {
        return asResult(Integer.compare((int) getLongValue(leftTag, leftBytes, start), (int) getConstantLong(right)));
    }
    // TODO(ali): use unsupported type
    throw new UnsupportedOperationException();
}
#end_block

#method_before
static Result compareConstants(IAObject leftConstant, IAObject rightConstant) {
    int result;
    ATypeTag leftTag = leftConstant.getType().getTypeTag();
    ATypeTag rightTag = rightConstant.getType().getTypeTag();
    if (leftTag == DOUBLE || rightTag == DOUBLE) {
        result = Double.compare(getConstantDouble(leftConstant), getConstantDouble(rightConstant));
    } else if (leftTag == FLOAT || rightTag == FLOAT) {
        result = Float.compare((float) getConstantDouble(leftConstant), (float) getConstantDouble(rightConstant));
    } else if (leftTag == BIGINT || rightTag == BIGINT) {
        result = Long.compare(getConstantLong(leftConstant), getConstantLong(rightConstant));
    } else if (leftTag == INTEGER || leftTag == SMALLINT || leftTag == TINYINT) {
        result = Integer.compare((int) getConstantLong(leftConstant), (int) getConstantLong(rightConstant));
    } else {
        return null;
    }
    return ILogicalBinaryComparator.asResult(result);
}
#method_after
static Result compareConstants(IAObject leftConstant, IAObject rightConstant) {
    ATypeTag leftTag = leftConstant.getType().getTypeTag();
    ATypeTag rightTag = rightConstant.getType().getTypeTag();
    if (leftTag == DOUBLE || rightTag == DOUBLE) {
        return asResult(Double.compare(getConstantDouble(leftConstant), getConstantDouble(rightConstant)));
    } else if (leftTag == FLOAT || rightTag == FLOAT) {
        return asResult(Float.compare((float) getConstantDouble(leftConstant), (float) getConstantDouble(rightConstant)));
    } else if (leftTag == BIGINT || rightTag == BIGINT) {
        return asResult(Long.compare(getConstantLong(leftConstant), getConstantLong(rightConstant)));
    } else if (leftTag == INTEGER || leftTag == SMALLINT || leftTag == TINYINT) {
        return asResult(Integer.compare((int) getConstantLong(leftConstant), (int) getConstantLong(rightConstant)));
    }
    // TODO(ali): use unsupported type
    throw new UnsupportedOperationException();
}
#end_block

#method_before
private int hash(IAType type, byte[] bytes, int offset, int length) throws HyracksDataException {
    // if a numeric type is encountered, then we promote each numeric type to the DOUBLE type.
    valueBuffer.reset();
    ATypeTag sourceTag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(bytes[offset]);
    switch(sourceTag) {
        case TINYINT:
        case SMALLINT:
        case INTEGER:
        case BIGINT:
            try {
                IntegerToDoubleTypeConvertComputer.getInstance().convertType(bytes, offset + 1, length - 1, valueOut);
            } catch (IOException e) {
                throw HyracksDataException.create(ErrorCode.NUMERIC_PROMOTION_ERROR, e.getMessage());
            }
            return MurmurHash3BinaryHash.hash(valueBuffer.getByteArray(), valueBuffer.getStartOffset(), valueBuffer.getLength(), seed);
        case FLOAT:
            try {
                FloatToDoubleTypeConvertComputer.getInstance().convertType(bytes, offset + 1, length - 1, valueOut);
            } catch (IOException e) {
                throw HyracksDataException.create(ErrorCode.NUMERIC_PROMOTION_ERROR, e.getMessage());
            }
            return MurmurHash3BinaryHash.hash(valueBuffer.getByteArray(), valueBuffer.getStartOffset(), valueBuffer.getLength(), seed);
        case ARRAY:
            try {
                return hashArray(type, bytes, offset, length);
            } catch (IOException e) {
                throw HyracksDataException.create(e);
            }
        case OBJECT:
            return hashRecord(type, bytes, offset, length);
        default:
            return MurmurHash3BinaryHash.hash(bytes, offset, length, seed);
    }
}
#method_after
private int hash(IAType type, byte[] bytes, int offset, int length) throws HyracksDataException {
    // if a numeric type is encountered, then we promote each numeric type to the DOUBLE type.
    valueBuffer.reset();
    ATypeTag sourceTag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(bytes[offset]);
    switch(sourceTag) {
        case TINYINT:
        case SMALLINT:
        case INTEGER:
        case BIGINT:
            try {
                IntegerToDoubleTypeConvertComputer.getInstance().convertType(bytes, offset + 1, length - 1, valueOut);
            } catch (IOException e) {
                throw HyracksDataException.create(ErrorCode.NUMERIC_PROMOTION_ERROR, e.getMessage());
            }
            return MurmurHash3BinaryHash.hash(valueBuffer.getByteArray(), valueBuffer.getStartOffset(), valueBuffer.getLength(), seed);
        case FLOAT:
            try {
                FloatToDoubleTypeConvertComputer.getInstance().convertType(bytes, offset + 1, length - 1, valueOut);
            } catch (IOException e) {
                throw HyracksDataException.create(ErrorCode.NUMERIC_PROMOTION_ERROR, e.getMessage());
            }
            return MurmurHash3BinaryHash.hash(valueBuffer.getByteArray(), valueBuffer.getStartOffset(), valueBuffer.getLength(), seed);
        case ARRAY:
            try {
                return hashArray(type, bytes, offset, length);
            } catch (IOException e) {
                throw HyracksDataException.create(e);
            }
        case OBJECT:
            return hashRecord(type, bytes, offset, length);
        case DOUBLE:
        default:
            return MurmurHash3BinaryHash.hash(bytes, offset, length, seed);
    }
}
#end_block

#method_before
protected int compare(IAType leftType, byte[] b1, int s1, int l1, IAType rightType, byte[] b2, int s2, int l2) throws HyracksDataException {
    if (b1[s1] == ATypeTag.SERIALIZED_MISSING_TYPE_TAG) {
        return b2[s2] == ATypeTag.SERIALIZED_MISSING_TYPE_TAG ? 0 : -1;
    } else if (b2[s2] == ATypeTag.SERIALIZED_MISSING_TYPE_TAG) {
        return 1;
    }
    if (b1[s1] == ATypeTag.SERIALIZED_NULL_TYPE_TAG) {
        return b2[s2] == ATypeTag.SERIALIZED_NULL_TYPE_TAG ? 0 : -1;
    } else if (b2[s2] == ATypeTag.SERIALIZED_NULL_TYPE_TAG) {
        return 1;
    }
    ATypeTag tag1 = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(b1[s1]);
    ATypeTag tag2 = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(b2[s2]);
    // and, we don't need to continue. We just compare raw byte by byte.
    if (tag1 == null || tag2 == null) {
        return rawComp.compare(b1, s1, l1, b2, s2, l2);
    }
    if (ATypeHierarchy.isCompatible(tag1, tag2) && tag1.isNumber()) {
        return ComparatorUtil.compareNumbers(tag1, b1, s1 + 1, tag2, b2, s2 + 1);
    }
    // this is especially useful when we need to generate some order between any two types.
    if (tag1 != tag2) {
        return rawComp.compare(b1, s1, l1, b2, s2, l2);
    }
    switch(tag1) {
        case STRING:
            return ascStrComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case UUID:
            return ascUUIDComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case BOOLEAN:
            return ascBoolComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case TIME:
            return Integer.compare(ATimeSerializerDeserializer.getChronon(b1, s1 + 1), ATimeSerializerDeserializer.getChronon(b2, s2 + 1));
        case DATE:
            return Integer.compare(ADateSerializerDeserializer.getChronon(b1, s1 + 1), ADateSerializerDeserializer.getChronon(b2, s2 + 1));
        case YEARMONTHDURATION:
            return Integer.compare(AYearMonthDurationSerializerDeserializer.getYearMonth(b1, s1 + 1), AYearMonthDurationSerializerDeserializer.getYearMonth(b2, s2 + 1));
        case DATETIME:
            return Long.compare(ADateTimeSerializerDeserializer.getChronon(b1, s1 + 1), ADateTimeSerializerDeserializer.getChronon(b2, s2 + 1));
        case DAYTIMEDURATION:
            return Long.compare(ADayTimeDurationSerializerDeserializer.getDayTime(b1, s1 + 1), ADayTimeDurationSerializerDeserializer.getDayTime(b2, s2 + 1));
        case RECTANGLE:
            return ascRectangleComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case CIRCLE:
            return ascCircleComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case POINT:
            return ascPointComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case POINT3D:
            return ascPoint3DComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case LINE:
            return ascLineComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case POLYGON:
            return ascPolygonComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case DURATION:
            return ascDurationComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case INTERVAL:
            return compareInterval(b1, s1, l1, b2, s2, l2);
        case BINARY:
            return ascByteArrayComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case ARRAY:
            return compareArrays(leftType, b1, s1, l1, rightType, b2, s2, l2);
        case OBJECT:
            return compareRecords(leftType, b1, s1, l1, rightType, b2, s2, l2);
        default:
            // we include typeTag in comparison to compare between two type to enforce some ordering
            return rawComp.compare(b1, s1, l1, b2, s2, l2);
    }
}
#method_after
protected int compare(IAType leftType, byte[] b1, int s1, int l1, IAType rightType, byte[] b2, int s2, int l2) throws HyracksDataException {
    if (b1[s1] == ATypeTag.SERIALIZED_MISSING_TYPE_TAG) {
        return b2[s2] == ATypeTag.SERIALIZED_MISSING_TYPE_TAG ? 0 : -1;
    } else if (b2[s2] == ATypeTag.SERIALIZED_MISSING_TYPE_TAG) {
        return 1;
    }
    if (b1[s1] == ATypeTag.SERIALIZED_NULL_TYPE_TAG) {
        return b2[s2] == ATypeTag.SERIALIZED_NULL_TYPE_TAG ? 0 : -1;
    } else if (b2[s2] == ATypeTag.SERIALIZED_NULL_TYPE_TAG) {
        return 1;
    }
    ATypeTag tag1 = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(b1[s1]);
    ATypeTag tag2 = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(b2[s2]);
    // and, we don't need to continue. We just compare raw byte by byte.
    if (tag1 == null || tag2 == null) {
        return rawComp.compare(b1, s1, l1, b2, s2, l2);
    }
    if (ATypeHierarchy.isCompatible(tag1, tag2) && ATypeHierarchy.getTypeDomain(tag1) == Domain.NUMERIC) {
        return ComparatorUtil.compareNumbers(tag1, b1, s1 + 1, tag2, b2, s2 + 1);
    }
    // this is especially useful when we need to generate some order between any two types.
    if (tag1 != tag2) {
        return Byte.compare(b1[s1], b2[s2]);
    }
    switch(tag1) {
        case STRING:
            return ascStrComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case UUID:
            return ascUUIDComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case BOOLEAN:
            return ascBoolComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case TIME:
            return Integer.compare(ATimeSerializerDeserializer.getChronon(b1, s1 + 1), ATimeSerializerDeserializer.getChronon(b2, s2 + 1));
        case DATE:
            return Integer.compare(ADateSerializerDeserializer.getChronon(b1, s1 + 1), ADateSerializerDeserializer.getChronon(b2, s2 + 1));
        case YEARMONTHDURATION:
            return Integer.compare(AYearMonthDurationSerializerDeserializer.getYearMonth(b1, s1 + 1), AYearMonthDurationSerializerDeserializer.getYearMonth(b2, s2 + 1));
        case DATETIME:
            return Long.compare(ADateTimeSerializerDeserializer.getChronon(b1, s1 + 1), ADateTimeSerializerDeserializer.getChronon(b2, s2 + 1));
        case DAYTIMEDURATION:
            return Long.compare(ADayTimeDurationSerializerDeserializer.getDayTime(b1, s1 + 1), ADayTimeDurationSerializerDeserializer.getDayTime(b2, s2 + 1));
        case RECTANGLE:
            return ascRectangleComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case CIRCLE:
            return ascCircleComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case POINT:
            return ascPointComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case POINT3D:
            return ascPoint3DComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case LINE:
            return ascLineComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case POLYGON:
            return ascPolygonComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case DURATION:
            return ascDurationComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case INTERVAL:
            return compareInterval(b1, s1, l1, b2, s2, l2);
        case BINARY:
            return ascByteArrayComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
        case ARRAY:
            return compareArrays(leftType, b1, s1, l1, rightType, b2, s2, l2);
        case OBJECT:
            return compareRecords(leftType, b1, s1, l1, rightType, b2, s2, l2);
        default:
            // we include typeTag in comparison to compare between two type to enforce some ordering
            return rawComp.compare(b1, s1, l1, b2, s2, l2);
    }
}
#end_block

#method_before
@Override
public Result compare(IPointable left, IPointable right) throws HyracksDataException {
    ATypeTag leftTag = VALUE_TYPE_MAPPING[left.getByteArray()[left.getStartOffset()]];
    ATypeTag rightTag = VALUE_TYPE_MAPPING[right.getByteArray()[right.getStartOffset()]];
    Result comparisonResult = ComparatorUtil.returnMissingOrNullOrMismatch(leftTag, rightTag);
    if (comparisonResult != null) {
        return comparisonResult;
    }
    if (comparisonUndefined(leftTag, rightTag, isEquality)) {
        return Result.INCOMPARABLE;
    }
    // compare number if one of args is number since compatibility has already been checked above
    if (leftTag.isNumber()) {
        return ComparatorUtil.compareNumbers(leftTag, left, rightTag, right);
    }
    // throw an exception if !=, the assumption here is only numeric types are compatible with each other
    if (leftTag != rightTag) {
        throw new IllegalStateException("Two different non-numeric tags but they are compatible");
    }
    byte[] leftBytes = left.getByteArray();
    byte[] rightBytes = right.getByteArray();
    int leftStart = left.getStartOffset() + 1;
    int rightStart = right.getStartOffset() + 1;
    int leftLen = left.getLength() - 1;
    int rightLen = right.getLength() - 1;
    int result;
    switch(leftTag) {
        case BOOLEAN:
            result = Integer.compare(leftBytes[leftStart], rightBytes[rightStart]);
            break;
        case STRING:
            result = strBinaryComp.compare(leftBytes, leftStart, leftLen, rightBytes, rightStart, rightLen);
            break;
        case YEARMONTHDURATION:
            result = Integer.compare(AYearMonthDurationSerializerDeserializer.getYearMonth(leftBytes, leftStart), AYearMonthDurationSerializerDeserializer.getYearMonth(rightBytes, rightStart));
            break;
        case TIME:
            result = Integer.compare(ATimeSerializerDeserializer.getChronon(leftBytes, leftStart), ATimeSerializerDeserializer.getChronon(rightBytes, rightStart));
            break;
        case DATE:
            result = Integer.compare(ADateSerializerDeserializer.getChronon(leftBytes, leftStart), ADateSerializerDeserializer.getChronon(rightBytes, rightStart));
            break;
        case DAYTIMEDURATION:
            result = Long.compare(ADayTimeDurationSerializerDeserializer.getDayTime(leftBytes, leftStart), ADayTimeDurationSerializerDeserializer.getDayTime(rightBytes, rightStart));
            break;
        case DATETIME:
            result = Long.compare(ADateTimeSerializerDeserializer.getChronon(leftBytes, leftStart), ADateTimeSerializerDeserializer.getChronon(rightBytes, rightStart));
            break;
        case CIRCLE:
            result = circleBinaryComp.compare(leftBytes, leftStart, leftLen, rightBytes, rightStart, rightLen);
            break;
        case LINE:
            result = lineBinaryComparator.compare(leftBytes, leftStart, leftLen, rightBytes, rightStart, rightLen);
            break;
        case POINT:
            result = pointBinaryComparator.compare(leftBytes, leftStart, leftLen, rightBytes, rightStart, rightLen);
            break;
        case POINT3D:
            result = point3DBinaryComparator.compare(leftBytes, leftStart, leftLen, rightBytes, rightStart, rightLen);
            break;
        case POLYGON:
            result = polygonBinaryComparator.compare(leftBytes, leftStart, leftLen, rightBytes, rightStart, rightLen);
            break;
        case DURATION:
            result = durationBinaryComp.compare(leftBytes, leftStart, leftLen, rightBytes, rightStart, rightLen);
            break;
        case INTERVAL:
            result = intervalBinaryComp.compare(leftBytes, leftStart, leftLen, rightBytes, rightStart, rightLen);
            break;
        case RECTANGLE:
            result = rectangleBinaryComparator.compare(leftBytes, leftStart, leftLen, rightBytes, rightStart, rightLen);
            break;
        case BINARY:
            result = byteArrayComparator.compare(leftBytes, leftStart, leftLen, rightBytes, rightStart, rightLen);
            break;
        case UUID:
            result = uuidBinaryComparator.compare(leftBytes, leftStart, leftLen, rightBytes, rightStart, rightLen);
            break;
        default:
            return Result.NULL;
    }
    return ILogicalBinaryComparator.asResult(result);
}
#method_after
@Override
public Result compare(IPointable left, IPointable right) throws HyracksDataException {
    ATypeTag leftTag = VALUE_TYPE_MAPPING[left.getByteArray()[left.getStartOffset()]];
    ATypeTag rightTag = VALUE_TYPE_MAPPING[right.getByteArray()[right.getStartOffset()]];
    Result comparisonResult = ComparatorUtil.returnMissingOrNullOrMismatch(leftTag, rightTag);
    if (comparisonResult != null) {
        return comparisonResult;
    }
    if (comparisonUndefined(leftTag, rightTag, isEquality)) {
        return Result.INCOMPARABLE;
    }
    // compare number if one of args is number since compatibility has already been checked above
    if (ATypeHierarchy.getTypeDomain(leftTag) == ATypeHierarchy.Domain.NUMERIC) {
        return ComparatorUtil.compareNumbers(leftTag, left, rightTag, right);
    }
    // throw an exception if !=, the assumption here is only numeric types are compatible with each other
    if (leftTag != rightTag) {
        throw new IllegalStateException("Two different non-numeric tags but they are compatible");
    }
    byte[] leftBytes = left.getByteArray();
    byte[] rightBytes = right.getByteArray();
    int leftStart = left.getStartOffset() + 1;
    int rightStart = right.getStartOffset() + 1;
    int leftLen = left.getLength() - 1;
    int rightLen = right.getLength() - 1;
    int result;
    switch(leftTag) {
        case BOOLEAN:
            result = Integer.compare(leftBytes[leftStart], rightBytes[rightStart]);
            break;
        case STRING:
            result = strBinaryComp.compare(leftBytes, leftStart, leftLen, rightBytes, rightStart, rightLen);
            break;
        case YEARMONTHDURATION:
            result = Integer.compare(AYearMonthDurationSerializerDeserializer.getYearMonth(leftBytes, leftStart), AYearMonthDurationSerializerDeserializer.getYearMonth(rightBytes, rightStart));
            break;
        case TIME:
            result = Integer.compare(ATimeSerializerDeserializer.getChronon(leftBytes, leftStart), ATimeSerializerDeserializer.getChronon(rightBytes, rightStart));
            break;
        case DATE:
            result = Integer.compare(ADateSerializerDeserializer.getChronon(leftBytes, leftStart), ADateSerializerDeserializer.getChronon(rightBytes, rightStart));
            break;
        case DAYTIMEDURATION:
            result = Long.compare(ADayTimeDurationSerializerDeserializer.getDayTime(leftBytes, leftStart), ADayTimeDurationSerializerDeserializer.getDayTime(rightBytes, rightStart));
            break;
        case DATETIME:
            result = Long.compare(ADateTimeSerializerDeserializer.getChronon(leftBytes, leftStart), ADateTimeSerializerDeserializer.getChronon(rightBytes, rightStart));
            break;
        case CIRCLE:
            result = circleBinaryComp.compare(leftBytes, leftStart, leftLen, rightBytes, rightStart, rightLen);
            break;
        case LINE:
            result = lineBinaryComparator.compare(leftBytes, leftStart, leftLen, rightBytes, rightStart, rightLen);
            break;
        case POINT:
            result = pointBinaryComparator.compare(leftBytes, leftStart, leftLen, rightBytes, rightStart, rightLen);
            break;
        case POINT3D:
            result = point3DBinaryComparator.compare(leftBytes, leftStart, leftLen, rightBytes, rightStart, rightLen);
            break;
        case POLYGON:
            result = polygonBinaryComparator.compare(leftBytes, leftStart, leftLen, rightBytes, rightStart, rightLen);
            break;
        case DURATION:
            result = durationBinaryComp.compare(leftBytes, leftStart, leftLen, rightBytes, rightStart, rightLen);
            break;
        case INTERVAL:
            result = intervalBinaryComp.compare(leftBytes, leftStart, leftLen, rightBytes, rightStart, rightLen);
            break;
        case RECTANGLE:
            result = rectangleBinaryComparator.compare(leftBytes, leftStart, leftLen, rightBytes, rightStart, rightLen);
            break;
        case BINARY:
            result = byteArrayComparator.compare(leftBytes, leftStart, leftLen, rightBytes, rightStart, rightLen);
            break;
        case UUID:
            result = uuidBinaryComparator.compare(leftBytes, leftStart, leftLen, rightBytes, rightStart, rightLen);
            break;
        default:
            return Result.NULL;
    }
    return ILogicalBinaryComparator.asResult(result);
}
#end_block

#method_before
@Override
public Result compare(IPointable left, IAObject rightConstant) {
    // TODO(ali): currently defined for numbers only
    ATypeTag leftTag = VALUE_TYPE_MAPPING[left.getByteArray()[left.getStartOffset()]];
    ATypeTag rightTag = rightConstant.getType().getTypeTag();
    Result comparisonResult = ComparatorUtil.returnMissingOrNullOrMismatch(leftTag, rightTag);
    if (comparisonResult != null) {
        return comparisonResult;
    }
    if (comparisonUndefined(leftTag, rightTag, isEquality)) {
        return Result.NULL;
    }
    comparisonResult = ComparatorUtil.compareNumWithConstant(leftTag, left, rightConstant);
    if (comparisonResult != null) {
        return comparisonResult;
    }
    return Result.NULL;
}
#method_after
@Override
public Result compare(IPointable left, IAObject rightConstant) {
    // TODO(ali): currently defined for numbers only
    ATypeTag leftTag = VALUE_TYPE_MAPPING[left.getByteArray()[left.getStartOffset()]];
    ATypeTag rightTag = rightConstant.getType().getTypeTag();
    Result comparisonResult = ComparatorUtil.returnMissingOrNullOrMismatch(leftTag, rightTag);
    if (comparisonResult != null) {
        return comparisonResult;
    }
    if (comparisonUndefined(leftTag, rightTag, isEquality)) {
        return Result.NULL;
    }
    if (ATypeHierarchy.getTypeDomain(leftTag) == ATypeHierarchy.Domain.NUMERIC) {
        return ComparatorUtil.compareNumWithConstant(leftTag, left, rightConstant);
    }
    return Result.NULL;
}
#end_block

#method_before
@Override
public Result compare(IAObject leftConstant, IAObject rightConstant) {
    // TODO(ali): currently defined for numbers only
    ATypeTag leftTag = leftConstant.getType().getTypeTag();
    ATypeTag rightTag = rightConstant.getType().getTypeTag();
    Result comparisonResult = ComparatorUtil.returnMissingOrNullOrMismatch(leftTag, rightTag);
    if (comparisonResult != null) {
        return comparisonResult;
    }
    if (comparisonUndefined(leftTag, rightTag, isEquality)) {
        return Result.NULL;
    }
    comparisonResult = ComparatorUtil.compareConstants(leftConstant, rightConstant);
    if (comparisonResult != null) {
        return comparisonResult;
    }
    return Result.NULL;
}
#method_after
@Override
public Result compare(IAObject leftConstant, IAObject rightConstant) {
    // TODO(ali): currently defined for numbers only
    ATypeTag leftTag = leftConstant.getType().getTypeTag();
    ATypeTag rightTag = rightConstant.getType().getTypeTag();
    Result comparisonResult = ComparatorUtil.returnMissingOrNullOrMismatch(leftTag, rightTag);
    if (comparisonResult != null) {
        return comparisonResult;
    }
    if (comparisonUndefined(leftTag, rightTag, isEquality)) {
        return Result.NULL;
    }
    if (ATypeHierarchy.getTypeDomain(leftTag) == ATypeHierarchy.Domain.NUMERIC) {
        return ComparatorUtil.compareConstants(leftConstant, rightConstant);
    }
    return Result.NULL;
}
#end_block

#method_before
@Override
public boolean expired() {
    return System.nanoTime() - lastCacheTime >= expiryNanos;
}
#method_after
@Override
public synchronized boolean expired() {
    return System.nanoTime() - lastCacheTime >= expiryNanos;
}
#end_block

#method_before
@Override
public void cached() {
    lastCacheTime = System.nanoTime();
}
#method_after
@Override
public synchronized void cached() {
    lastCacheTime = System.nanoTime();
}
#end_block

#method_before
@Override
public void put(String key, ICacheableValue value) {
    registry.put(key, value);
    cacheNow(value);
}
#method_after
@Override
public void put(String key, ICacheableValue value) {
    registry.put(key, value);
    value.cache();
}
#end_block

#method_before
@Override
public Object get(String key) {
    final ICacheableValue value = registry.get(key);
    if (value == null) {
        return null;
    }
    synchronized (value) {
        if (value.getPolicy().expired()) {
            cacheNow(value);
        }
    }
    return value.get();
}
#method_after
@Override
public Object get(String key) {
    final ICacheableValue value = registry.get(key);
    if (value == null) {
        return null;
    }
    synchronized (value) {
        if (value.getPolicy().expired()) {
            value.cache();
        }
        return value.get();
    }
}
#end_block

#method_before
public static void addWindowFunction(FunctionIdentifier fi, FunctionIdentifier implfi, boolean requiresOrderArgs, boolean requiresMaterialization) {
    IFunctionInfo implFinfo = getAsterixFunctionInfo(implfi);
    builtinWindowFunctions.put(getAsterixFunctionInfo(fi), implFinfo);
    if (requiresOrderArgs) {
        builtinWindowFunctionsWithOrderArgs.add(implFinfo);
    }
    if (requiresMaterialization) {
        builtinWindowFunctionsWithMaterialization.add(implFinfo);
    }
}
#method_after
public static void addWindowFunction(FunctionIdentifier sqlfi, FunctionIdentifier winfi, WindowFunctionProperty... properties) {
    IFunctionInfo sqlinfo = getAsterixFunctionInfo(sqlfi);
    IFunctionInfo wininfo = getAsterixFunctionInfo(winfi);
    sqlToWindowFunctions.put(sqlinfo, wininfo);
    windowFunctions.add(wininfo);
    registerFunctionProperties(wininfo, WindowFunctionProperty.class, properties);
}
#end_block

#method_before
public static AbstractFunctionCallExpression makeWindowFunctionExpression(FunctionIdentifier scalarfi, List<Mutable<ILogicalExpression>> args) {
    IFunctionInfo finfo = getAsterixFunctionInfo(scalarfi);
    IFunctionInfo implFinfo = builtinWindowFunctions.get(finfo);
    if (implFinfo == null) {
        throw new IllegalStateException("no implementation for window function " + finfo);
    }
    return new StatefulFunctionCallExpression(implFinfo, UnpartitionedPropertyComputer.INSTANCE, args);
}
#method_after
public static AbstractFunctionCallExpression makeWindowFunctionExpression(FunctionIdentifier winfi, List<Mutable<ILogicalExpression>> args) {
    IFunctionInfo finfo = getAsterixFunctionInfo(winfi);
    if (finfo == null) {
        throw new IllegalStateException("no implementation for window function " + finfo);
    }
    return new StatefulFunctionCallExpression(finfo, UnpartitionedPropertyComputer.INSTANCE, args);
}
#end_block

#method_before
protected void finishSkewFinalResults(IPointable result) throws HyracksDataException {
    resultStorage.reset();
    try {
        long count = moments.getCount();
        double m2 = moments.getM2();
        if (count <= 2 || aggType == ATypeTag.NULL || m2 == 0) {
            nullSerde.serialize(ANull.NULL, resultStorage.getDataOutput());
        } else {
            aDouble.setValue(Math.sqrt(count) * moments.getM3() / Math.pow(m2, 1.5));
            doubleSerde.serialize(aDouble, resultStorage.getDataOutput());
        }
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    }
    result.set(resultStorage);
}
#method_after
protected void finishSkewFinalResults(IPointable result) throws HyracksDataException {
    resultStorage.reset();
    try {
        long count = moments.getCount();
        double m2 = moments.getM2();
        if (count <= 2 || aggType == ATypeTag.NULL || (m2 < Double.MIN_VALUE && m2 > -Double.MIN_VALUE)) {
            nullSerde.serialize(ANull.NULL, resultStorage.getDataOutput());
        } else {
            aDouble.setValue(Math.sqrt(count) * moments.getM3() / Math.pow(m2, 1.5));
            doubleSerde.serialize(aDouble, resultStorage.getDataOutput());
        }
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    }
    result.set(resultStorage);
}
#end_block

#method_before
protected void finishKurtFinalResults(IPointable result) throws HyracksDataException {
    resultStorage.reset();
    try {
        long count = moments.getCount();
        double m2 = moments.getM2();
        if (count <= 2 || aggType == ATypeTag.NULL || m2 == 0) {
            nullSerde.serialize(ANull.NULL, resultStorage.getDataOutput());
        } else {
            aDouble.setValue(moments.getM4() * count / (m2 * m2) - 3);
            doubleSerde.serialize(aDouble, resultStorage.getDataOutput());
        }
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    }
    result.set(resultStorage);
}
#method_after
protected void finishKurtFinalResults(IPointable result) throws HyracksDataException {
    resultStorage.reset();
    try {
        long count = moments.getCount();
        double m2 = moments.getM2();
        if (count <= 2 || aggType == ATypeTag.NULL || (m2 < Double.MIN_VALUE && m2 > -Double.MIN_VALUE)) {
            nullSerde.serialize(ANull.NULL, resultStorage.getDataOutput());
        } else {
            aDouble.setValue(moments.getM4() * count / (m2 * m2) - 3);
            doubleSerde.serialize(aDouble, resultStorage.getDataOutput());
        }
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    }
    result.set(resultStorage);
}
#end_block

#method_before
protected void processDataValues(IFrameTupleReference tuple, byte[] state, int start, int len) throws HyracksDataException {
    if (skipStep(state, start)) {
        return;
    }
    eval.evaluate(tuple, inputVal);
    byte[] bytes = inputVal.getByteArray();
    int offset = inputVal.getStartOffset();
    double m1 = BufferSerDeUtil.getDouble(state, start + M1_OFFSET);
    double m2 = BufferSerDeUtil.getDouble(state, start + M2_OFFSET);
    double m3 = BufferSerDeUtil.getDouble(state, start + M3_OFFSET);
    double m4 = BufferSerDeUtil.getDouble(state, start + M4_OFFSET);
    long count = BufferSerDeUtil.getLong(state, start + COUNT_OFFSET);
    moments.set(m1, m2, 0, 0, count, getM3Flag(), getM4Flag());
    ATypeTag typeTag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(bytes[offset]);
    ATypeTag aggType = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(state[start + AGG_TYPE_OFFSET]);
    if (typeTag == ATypeTag.MISSING || typeTag == ATypeTag.NULL) {
        processNull(state, start);
        return;
    } else if (aggType == ATypeTag.SYSTEM_NULL) {
        aggType = typeTag;
    } else if (typeTag != ATypeTag.SYSTEM_NULL && !ATypeHierarchy.isCompatible(typeTag, aggType)) {
        if (typeTag.ordinal() > aggType.ordinal()) {
            throw new IncompatibleTypeException(sourceLoc, getFunctionIdentifier(), bytes[offset], aggType.serialize());
        } else {
            throw new IncompatibleTypeException(sourceLoc, getFunctionIdentifier(), aggType.serialize(), bytes[offset]);
        }
    } else if (ATypeHierarchy.canPromote(aggType, typeTag)) {
        aggType = typeTag;
    }
    double val;
    switch(typeTag) {
        case TINYINT:
            val = AInt8SerializerDeserializer.getByte(bytes, offset + 1);
            moments.push(val);
            break;
        case SMALLINT:
            val = AInt16SerializerDeserializer.getShort(bytes, offset + 1);
            moments.push(val);
            break;
        case INTEGER:
            val = AInt32SerializerDeserializer.getInt(bytes, offset + 1);
            moments.push(val);
            break;
        case BIGINT:
            val = AInt64SerializerDeserializer.getLong(bytes, offset + 1);
            moments.push(val);
            break;
        case FLOAT:
            val = AFloatSerializerDeserializer.getFloat(bytes, offset + 1);
            moments.push(val);
            break;
        case DOUBLE:
            val = ADoubleSerializerDeserializer.getDouble(bytes, offset + 1);
            moments.push(val);
            break;
        default:
            throw new UnsupportedItemTypeException(sourceLoc, getFunctionIdentifier(), bytes[offset]);
    }
    BufferSerDeUtil.writeDouble(moments.getM1(), state, start + M1_OFFSET);
    BufferSerDeUtil.writeDouble(moments.getM2(), state, start + M2_OFFSET);
    BufferSerDeUtil.writeDouble(moments.getM3(), state, start + M3_OFFSET);
    BufferSerDeUtil.writeDouble(moments.getM4(), state, start + M4_OFFSET);
    BufferSerDeUtil.writeLong(moments.getCount(), state, start + COUNT_OFFSET);
    state[start + AGG_TYPE_OFFSET] = aggType.serialize();
}
#method_after
protected void processDataValues(IFrameTupleReference tuple, byte[] state, int start, int len) throws HyracksDataException {
    if (skipStep(state, start)) {
        return;
    }
    eval.evaluate(tuple, inputVal);
    byte[] bytes = inputVal.getByteArray();
    int offset = inputVal.getStartOffset();
    double m1 = BufferSerDeUtil.getDouble(state, start + M1_OFFSET);
    double m2 = BufferSerDeUtil.getDouble(state, start + M2_OFFSET);
    double m3 = BufferSerDeUtil.getDouble(state, start + M3_OFFSET);
    double m4 = BufferSerDeUtil.getDouble(state, start + M4_OFFSET);
    long count = BufferSerDeUtil.getLong(state, start + COUNT_OFFSET);
    moments.set(m1, m2, m3, m4, count, getM3Flag(), getM4Flag());
    ATypeTag typeTag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(bytes[offset]);
    ATypeTag aggType = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(state[start + AGG_TYPE_OFFSET]);
    if (typeTag == ATypeTag.MISSING || typeTag == ATypeTag.NULL) {
        processNull(state, start);
        return;
    } else if (aggType == ATypeTag.SYSTEM_NULL) {
        aggType = typeTag;
    } else if (typeTag != ATypeTag.SYSTEM_NULL && !ATypeHierarchy.isCompatible(typeTag, aggType)) {
        if (typeTag.ordinal() > aggType.ordinal()) {
            throw new IncompatibleTypeException(sourceLoc, getFunctionIdentifier(), bytes[offset], aggType.serialize());
        } else {
            throw new IncompatibleTypeException(sourceLoc, getFunctionIdentifier(), aggType.serialize(), bytes[offset]);
        }
    } else if (ATypeHierarchy.canPromote(aggType, typeTag)) {
        aggType = typeTag;
    }
    double val;
    switch(typeTag) {
        case TINYINT:
            val = AInt8SerializerDeserializer.getByte(bytes, offset + 1);
            moments.push(val);
            break;
        case SMALLINT:
            val = AInt16SerializerDeserializer.getShort(bytes, offset + 1);
            moments.push(val);
            break;
        case INTEGER:
            val = AInt32SerializerDeserializer.getInt(bytes, offset + 1);
            moments.push(val);
            break;
        case BIGINT:
            val = AInt64SerializerDeserializer.getLong(bytes, offset + 1);
            moments.push(val);
            break;
        case FLOAT:
            val = AFloatSerializerDeserializer.getFloat(bytes, offset + 1);
            moments.push(val);
            break;
        case DOUBLE:
            val = ADoubleSerializerDeserializer.getDouble(bytes, offset + 1);
            moments.push(val);
            break;
        default:
            throw new UnsupportedItemTypeException(sourceLoc, getFunctionIdentifier(), bytes[offset]);
    }
    BufferSerDeUtil.writeDouble(moments.getM1(), state, start + M1_OFFSET);
    BufferSerDeUtil.writeDouble(moments.getM2(), state, start + M2_OFFSET);
    BufferSerDeUtil.writeDouble(moments.getM3(), state, start + M3_OFFSET);
    BufferSerDeUtil.writeDouble(moments.getM4(), state, start + M4_OFFSET);
    BufferSerDeUtil.writeLong(moments.getCount(), state, start + COUNT_OFFSET);
    state[start + AGG_TYPE_OFFSET] = aggType.serialize();
}
#end_block

#method_before
protected void finishSkewFinalResults(byte[] state, int start, int len, DataOutput result) throws HyracksDataException {
    double m2 = BufferSerDeUtil.getDouble(state, start + M2_OFFSET);
    double m3 = BufferSerDeUtil.getDouble(state, start + M3_OFFSET);
    long count = BufferSerDeUtil.getLong(state, start + COUNT_OFFSET);
    ATypeTag aggType = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(state[start + AGG_TYPE_OFFSET]);
    try {
        if (count <= 1 || aggType == ATypeTag.NULL || m2 == 0) {
            nullSerde.serialize(ANull.NULL, result);
        } else {
            aDouble.setValue(Math.sqrt(count) * m3 / Math.pow(m2, 1.5));
            doubleSerde.serialize(aDouble, result);
        }
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    }
}
#method_after
protected void finishSkewFinalResults(byte[] state, int start, int len, DataOutput result) throws HyracksDataException {
    double m2 = BufferSerDeUtil.getDouble(state, start + M2_OFFSET);
    double m3 = BufferSerDeUtil.getDouble(state, start + M3_OFFSET);
    long count = BufferSerDeUtil.getLong(state, start + COUNT_OFFSET);
    ATypeTag aggType = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(state[start + AGG_TYPE_OFFSET]);
    try {
        if (count <= 1 || aggType == ATypeTag.NULL || (m2 < Double.MIN_VALUE && m2 > -Double.MIN_VALUE)) {
            nullSerde.serialize(ANull.NULL, result);
        } else {
            aDouble.setValue(Math.sqrt(count) * m3 / Math.pow(m2, 1.5));
            doubleSerde.serialize(aDouble, result);
        }
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    }
}
#end_block

#method_before
protected void finishKurtFinalResults(byte[] state, int start, int len, DataOutput result) throws HyracksDataException {
    double m2 = BufferSerDeUtil.getDouble(state, start + M2_OFFSET);
    double m4 = BufferSerDeUtil.getDouble(state, start + M4_OFFSET);
    long count = BufferSerDeUtil.getLong(state, start + COUNT_OFFSET);
    ATypeTag aggType = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(state[start + AGG_TYPE_OFFSET]);
    try {
        if (count <= 1 || aggType == ATypeTag.NULL || m2 == 0) {
            nullSerde.serialize(ANull.NULL, result);
        } else {
            aDouble.setValue(m4 * count / (m2 * m2 - 3));
            doubleSerde.serialize(aDouble, result);
        }
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    }
}
#method_after
protected void finishKurtFinalResults(byte[] state, int start, int len, DataOutput result) throws HyracksDataException {
    double m2 = BufferSerDeUtil.getDouble(state, start + M2_OFFSET);
    double m4 = BufferSerDeUtil.getDouble(state, start + M4_OFFSET);
    long count = BufferSerDeUtil.getLong(state, start + COUNT_OFFSET);
    ATypeTag aggType = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(state[start + AGG_TYPE_OFFSET]);
    try {
        if (count <= 1 || aggType == ATypeTag.NULL || (m2 < Double.MIN_VALUE && m2 > -Double.MIN_VALUE)) {
            nullSerde.serialize(ANull.NULL, result);
        } else {
            aDouble.setValue(m4 * count / (m2 * m2 - 3));
            doubleSerde.serialize(aDouble, result);
        }
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    }
}
#end_block

#method_before
public static FunctionCollection createDefaultFunctionCollection() {
    FunctionCollection fc = new FunctionCollection();
    // array functions
    fc.add(ArrayRemoveDescriptor.FACTORY);
    fc.add(ArrayPutDescriptor.FACTORY);
    fc.add(ArrayPrependDescriptor.FACTORY);
    fc.add(ArrayAppendDescriptor.FACTORY);
    fc.add(ArrayInsertDescriptor.FACTORY);
    fc.addGenerated(ArrayPositionDescriptor.FACTORY);
    fc.addGenerated(ArrayRepeatDescriptor.FACTORY);
    fc.addGenerated(ArrayContainsDescriptor.FACTORY);
    fc.addGenerated(ArrayReverseDescriptor.FACTORY);
    fc.addGenerated(ArraySortDescriptor.FACTORY);
    fc.addGenerated(ArrayDistinctDescriptor.FACTORY);
    fc.addGenerated(ArrayUnionDescriptor.FACTORY);
    fc.addGenerated(ArrayIntersectDescriptor.FACTORY);
    fc.addGenerated(ArrayIfNullDescriptor.FACTORY);
    fc.addGenerated(ArrayConcatDescriptor.FACTORY);
    fc.addGenerated(ArrayRangeDescriptor.FACTORY);
    fc.addGenerated(ArrayFlattenDescriptor.FACTORY);
    fc.add(ArrayReplaceDescriptor.FACTORY);
    fc.addGenerated(ArraySymDiffDescriptor.FACTORY);
    fc.addGenerated(ArraySymDiffnDescriptor.FACTORY);
    fc.addGenerated(ArrayStarDescriptor.FACTORY);
    // unnesting functions
    fc.add(TidRunningAggregateDescriptor.FACTORY);
    fc.add(ScanCollectionDescriptor.FACTORY);
    fc.add(RangeDescriptor.FACTORY);
    fc.add(SubsetCollectionDescriptor.FACTORY);
    // aggregate functions
    fc.add(ListifyAggregateDescriptor.FACTORY);
    fc.add(CountAggregateDescriptor.FACTORY);
    fc.add(AvgAggregateDescriptor.FACTORY);
    fc.add(LocalAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SumAggregateDescriptor.FACTORY);
    fc.add(LocalSumAggregateDescriptor.FACTORY);
    fc.add(IntermediateSumAggregateDescriptor.FACTORY);
    fc.add(GlobalSumAggregateDescriptor.FACTORY);
    fc.add(MaxAggregateDescriptor.FACTORY);
    fc.add(LocalMaxAggregateDescriptor.FACTORY);
    fc.add(MinAggregateDescriptor.FACTORY);
    fc.add(LocalMinAggregateDescriptor.FACTORY);
    fc.add(FirstElementAggregateDescriptor.FACTORY);
    fc.add(LocalFirstElementAggregateDescriptor.FACTORY);
    fc.add(StddevAggregateDescriptor.FACTORY);
    fc.add(LocalStddevAggregateDescriptor.FACTORY);
    fc.add(IntermediateStddevAggregateDescriptor.FACTORY);
    fc.add(GlobalStddevAggregateDescriptor.FACTORY);
    fc.add(LocalSamplingAggregateDescriptor.FACTORY);
    fc.add(RangeMapAggregateDescriptor.FACTORY);
    fc.add(StddevPopAggregateDescriptor.FACTORY);
    fc.add(LocalStddevPopAggregateDescriptor.FACTORY);
    fc.add(IntermediateStddevPopAggregateDescriptor.FACTORY);
    fc.add(GlobalStddevPopAggregateDescriptor.FACTORY);
    fc.add(VarAggregateDescriptor.FACTORY);
    fc.add(LocalVarAggregateDescriptor.FACTORY);
    fc.add(IntermediateVarAggregateDescriptor.FACTORY);
    fc.add(GlobalVarAggregateDescriptor.FACTORY);
    fc.add(VarPopAggregateDescriptor.FACTORY);
    fc.add(LocalVarPopAggregateDescriptor.FACTORY);
    fc.add(IntermediateVarPopAggregateDescriptor.FACTORY);
    fc.add(GlobalVarPopAggregateDescriptor.FACTORY);
    fc.add(KurtosisAggregateDescriptor.FACTORY);
    fc.add(LocalKurtosisAggregateDescriptor.FACTORY);
    fc.add(IntermediateKurtosisAggregateDescriptor.FACTORY);
    fc.add(GlobalKurtosisAggregateDescriptor.FACTORY);
    fc.add(SkewnessAggregateDescriptor.FACTORY);
    fc.add(LocalSkewnessAggregateDescriptor.FACTORY);
    fc.add(IntermediateSkewnessAggregateDescriptor.FACTORY);
    fc.add(GlobalSkewnessAggregateDescriptor.FACTORY);
    // serializable aggregates
    fc.add(SerializableCountAggregateDescriptor.FACTORY);
    fc.add(SerializableAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSumAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSumAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSumAggregateDescriptor.FACTORY);
    fc.add(SerializableStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableVarAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalVarAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateVarAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalVarAggregateDescriptor.FACTORY);
    fc.add(SerializableVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableKurtosisAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalKurtosisAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateKurtosisAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalKurtosisAggregateDescriptor.FACTORY);
    fc.add(SerializableSkewnessAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSkewnessAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSkewnessAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSkewnessAggregateDescriptor.FACTORY);
    // scalar aggregates
    fc.add(ScalarCountAggregateDescriptor.FACTORY);
    fc.add(ScalarAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSumAggregateDescriptor.FACTORY);
    fc.add(ScalarMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarMinAggregateDescriptor.FACTORY);
    fc.add(EmptyStreamAggregateDescriptor.FACTORY);
    fc.add(NonEmptyStreamAggregateDescriptor.FACTORY);
    fc.add(ScalarStddevAggregateDescriptor.FACTORY);
    fc.add(ScalarStddevPopAggregateDescriptor.FACTORY);
    fc.add(ScalarVarAggregateDescriptor.FACTORY);
    fc.add(ScalarVarPopAggregateDescriptor.FACTORY);
    fc.add(ScalarKurtosisAggregateDescriptor.FACTORY);
    fc.add(ScalarSkewnessAggregateDescriptor.FACTORY);
    // SQL aggregates
    fc.add(SqlCountAggregateDescriptor.FACTORY);
    fc.add(SqlAvgAggregateDescriptor.FACTORY);
    fc.add(LocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SqlSumAggregateDescriptor.FACTORY);
    fc.add(LocalSqlSumAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlSumAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SqlMaxAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMaxAggregateDescriptor.FACTORY);
    fc.add(SqlMinAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMinAggregateDescriptor.FACTORY);
    fc.add(SqlStddevAggregateDescriptor.FACTORY);
    fc.add(LocalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlStddevAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(LocalSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SqlVarAggregateDescriptor.FACTORY);
    fc.add(LocalSqlVarAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlVarAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlVarAggregateDescriptor.FACTORY);
    fc.add(SqlVarPopAggregateDescriptor.FACTORY);
    fc.add(LocalSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(SqlKurtosisAggregateDescriptor.FACTORY);
    fc.add(LocalSqlKurtosisAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlKurtosisAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlKurtosisAggregateDescriptor.FACTORY);
    fc.add(SqlSkewnessAggregateDescriptor.FACTORY);
    fc.add(LocalSqlSkewnessAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlSkewnessAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlSkewnessAggregateDescriptor.FACTORY);
    // SQL serializable aggregates
    fc.add(SerializableSqlCountAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlVarAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlVarAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlVarAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlVarAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlKurtosisAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlKurtosisAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlKurtosisAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlKurtosisAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlSkewnessAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlSkewnessAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlSkewnessAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlSkewnessAggregateDescriptor.FACTORY);
    // SQL scalar aggregates
    fc.add(ScalarSqlCountAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlSumAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMinAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlStddevAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlVarAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlKurtosisAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlSkewnessAggregateDescriptor.FACTORY);
    // window functions
    fc.add(RowNumberRunningAggregateDescriptor.FACTORY);
    fc.add(RankRunningAggregateDescriptor.FACTORY);
    fc.add(DenseRankRunningAggregateDescriptor.FACTORY);
    fc.add(PercentRankRunningAggregateDescriptor.FACTORY);
    fc.add(NtileRunningAggregateDescriptor.FACTORY);
    // boolean functions
    fc.add(AndDescriptor.FACTORY);
    fc.add(OrDescriptor.FACTORY);
    // Record constructors / functions
    fc.add(ClosedRecordConstructorDescriptor.FACTORY);
    fc.add(OpenRecordConstructorDescriptor.FACTORY);
    fc.add(RecordConcatDescriptor.FACTORY);
    fc.add(RecordConcatStrictDescriptor.FACTORY);
    // List constructors
    fc.add(OrderedListConstructorDescriptor.FACTORY);
    fc.add(UnorderedListConstructorDescriptor.FACTORY);
    // Sleep function
    fc.add(SleepDescriptor.FACTORY);
    // Inject failure function
    fc.add(InjectFailureDescriptor.FACTORY);
    // Get Job Parameter function
    fc.add(GetJobParameterByNameDescriptor.FACTORY);
    // Switch case
    fc.add(SwitchCaseDescriptor.FACTORY);
    // null functions
    fc.add(IsMissingDescriptor.FACTORY);
    fc.add(IsNullDescriptor.FACTORY);
    fc.add(IsUnknownDescriptor.FACTORY);
    fc.add(IsSystemNullDescriptor.FACTORY);
    fc.add(CheckUnknownDescriptor.FACTORY);
    fc.add(IfMissingDescriptor.FACTORY);
    fc.add(IfNullDescriptor.FACTORY);
    fc.add(IfMissingOrNullDescriptor.FACTORY);
    // uuid generators (zero independent functions)
    fc.add(CreateUUIDDescriptor.FACTORY);
    fc.add(UUIDDescriptor.FACTORY);
    fc.add(CreateQueryUIDDescriptor.FACTORY);
    fc.add(RandomDescriptor.FACTORY);
    fc.add(CurrentDateDescriptor.FACTORY);
    fc.add(CurrentTimeDescriptor.FACTORY);
    fc.add(CurrentDateTimeDescriptor.FACTORY);
    // functions that need generated class for null-handling.
    // Element accessors.
    fc.addGenerated(FieldAccessByIndexDescriptor.FACTORY);
    fc.addGenerated(FieldAccessByNameDescriptor.FACTORY);
    fc.addGenerated(FieldAccessNestedDescriptor.FACTORY);
    fc.addGenerated(AnyCollectionMemberDescriptor.FACTORY);
    fc.addGenerated(GetItemDescriptor.FACTORY);
    // Numeric functions
    fc.add(IfInfDescriptor.FACTORY);
    fc.add(IfNanDescriptor.FACTORY);
    fc.add(IfNanOrInfDescriptor.FACTORY);
    fc.addGenerated(NumericUnaryMinusDescriptor.FACTORY);
    fc.addGenerated(NumericAddDescriptor.FACTORY);
    fc.addGenerated(NumericDivideDescriptor.FACTORY);
    fc.addGenerated(NumericDivDescriptor.FACTORY);
    fc.addGenerated(NumericMultiplyDescriptor.FACTORY);
    fc.addGenerated(NumericSubDescriptor.FACTORY);
    fc.addGenerated(NumericModuloDescriptor.FACTORY);
    fc.addGenerated(NumericPowerDescriptor.FACTORY);
    fc.addGenerated(NotDescriptor.FACTORY);
    fc.addGenerated(LenDescriptor.FACTORY);
    fc.addGenerated(NumericAbsDescriptor.FACTORY);
    fc.addGenerated(NumericCeilingDescriptor.FACTORY);
    fc.addGenerated(NumericFloorDescriptor.FACTORY);
    fc.addGenerated(NumericRoundDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEvenDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEven2Descriptor.FACTORY);
    fc.addGenerated(NumericACosDescriptor.FACTORY);
    fc.addGenerated(NumericASinDescriptor.FACTORY);
    fc.addGenerated(NumericATanDescriptor.FACTORY);
    fc.addGenerated(NumericDegreesDescriptor.FACTORY);
    fc.addGenerated(NumericRadiansDescriptor.FACTORY);
    fc.addGenerated(NumericCosDescriptor.FACTORY);
    fc.addGenerated(NumericSinDescriptor.FACTORY);
    fc.addGenerated(NumericTanDescriptor.FACTORY);
    fc.addGenerated(NumericExpDescriptor.FACTORY);
    fc.addGenerated(NumericLnDescriptor.FACTORY);
    fc.addGenerated(NumericLogDescriptor.FACTORY);
    fc.addGenerated(NumericSqrtDescriptor.FACTORY);
    fc.addGenerated(NumericSignDescriptor.FACTORY);
    fc.addGenerated(NumericTruncDescriptor.FACTORY);
    fc.addGenerated(NumericATan2Descriptor.FACTORY);
    // Comparisons.
    fc.addGenerated(EqualsDescriptor.FACTORY);
    fc.addGenerated(GreaterThanDescriptor.FACTORY);
    fc.addGenerated(GreaterThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(LessThanDescriptor.FACTORY);
    fc.addGenerated(LessThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(NotEqualsDescriptor.FACTORY);
    // If-Equals functions
    fc.addGenerated(MissingIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NullIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NanIfEqualsDescriptor.FACTORY);
    fc.addGenerated(PosInfIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NegInfIfEqualsDescriptor.FACTORY);
    // Binary functions
    fc.addGenerated(BinaryLengthDescriptor.FACTORY);
    fc.addGenerated(ParseBinaryDescriptor.FACTORY);
    fc.addGenerated(PrintBinaryDescriptor.FACTORY);
    fc.addGenerated(BinaryConcatDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromToDescriptor.FACTORY);
    fc.addGenerated(FindBinaryDescriptor.FACTORY);
    fc.addGenerated(FindBinaryFromDescriptor.FACTORY);
    // String functions
    fc.addGenerated(StringLikeDescriptor.FACTORY);
    fc.addGenerated(StringContainsDescriptor.FACTORY);
    fc.addGenerated(StringEndsWithDescriptor.FACTORY);
    fc.addGenerated(StringStartsWithDescriptor.FACTORY);
    fc.addGenerated(SubstringDescriptor.FACTORY);
    fc.addGenerated(StringEqualDescriptor.FACTORY);
    fc.addGenerated(StringLowerCaseDescriptor.FACTORY);
    fc.addGenerated(StringUpperCaseDescriptor.FACTORY);
    fc.addGenerated(StringLengthDescriptor.FACTORY);
    fc.addGenerated(Substring2Descriptor.FACTORY);
    fc.addGenerated(SubstringBeforeDescriptor.FACTORY);
    fc.addGenerated(SubstringAfterDescriptor.FACTORY);
    fc.addGenerated(StringToCodePointDescriptor.FACTORY);
    fc.addGenerated(CodePointToStringDescriptor.FACTORY);
    fc.addGenerated(StringConcatDescriptor.FACTORY);
    fc.addGenerated(StringJoinDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringInitCapDescriptor.FACTORY);
    fc.addGenerated(StringTrimDescriptor.FACTORY);
    fc.addGenerated(StringLTrimDescriptor.FACTORY);
    fc.addGenerated(StringRTrimDescriptor.FACTORY);
    fc.addGenerated(StringTrim2Descriptor.FACTORY);
    fc.addGenerated(StringLTrim2Descriptor.FACTORY);
    fc.addGenerated(StringRTrim2Descriptor.FACTORY);
    fc.addGenerated(StringPositionDescriptor.FACTORY);
    fc.addGenerated(StringRepeatDescriptor.FACTORY);
    fc.addGenerated(StringReplaceDescriptor.FACTORY);
    fc.addGenerated(StringReplaceWithLimitDescriptor.FACTORY);
    fc.addGenerated(StringReverseDescriptor.FACTORY);
    fc.addGenerated(StringSplitDescriptor.FACTORY);
    // Constructors
    fc.addGenerated(ABooleanConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryHexStringConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryBase64StringConstructorDescriptor.FACTORY);
    fc.addGenerated(AStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt8ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt16ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt32ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt64ConstructorDescriptor.FACTORY);
    fc.addGenerated(AFloatConstructorDescriptor.FACTORY);
    fc.addGenerated(ADoubleConstructorDescriptor.FACTORY);
    fc.addGenerated(APointConstructorDescriptor.FACTORY);
    fc.addGenerated(APoint3DConstructorDescriptor.FACTORY);
    fc.addGenerated(ALineConstructorDescriptor.FACTORY);
    fc.addGenerated(APolygonConstructorDescriptor.FACTORY);
    fc.addGenerated(ACircleConstructorDescriptor.FACTORY);
    fc.addGenerated(ARectangleConstructorDescriptor.FACTORY);
    fc.addGenerated(ATimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AYearMonthDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(ADayTimeDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AUUIDFromStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromTimeConstructorDescriptor.FACTORY);
    // Spatial
    fc.addGenerated(CreatePointDescriptor.FACTORY);
    fc.addGenerated(CreateLineDescriptor.FACTORY);
    fc.addGenerated(CreatePolygonDescriptor.FACTORY);
    fc.addGenerated(CreateCircleDescriptor.FACTORY);
    fc.addGenerated(CreateRectangleDescriptor.FACTORY);
    fc.addGenerated(SpatialAreaDescriptor.FACTORY);
    fc.addGenerated(SpatialDistanceDescriptor.FACTORY);
    fc.addGenerated(CreateMBRDescriptor.FACTORY);
    fc.addGenerated(SpatialCellDescriptor.FACTORY);
    fc.addGenerated(PointXCoordinateAccessor.FACTORY);
    fc.addGenerated(PointYCoordinateAccessor.FACTORY);
    fc.addGenerated(CircleRadiusAccessor.FACTORY);
    fc.addGenerated(CircleCenterAccessor.FACTORY);
    fc.addGenerated(LineRectanglePolygonAccessor.FACTORY);
    // full-text function
    fc.addGenerated(FullTextContainsDescriptor.FACTORY);
    fc.addGenerated(FullTextContainsWithoutOptionDescriptor.FACTORY);
    // Record functions.
    fc.addGenerated(GetRecordFieldsDescriptor.FACTORY);
    fc.addGenerated(GetRecordFieldValueDescriptor.FACTORY);
    fc.addGenerated(DeepEqualityDescriptor.FACTORY);
    fc.addGenerated(RecordMergeDescriptor.FACTORY);
    fc.addGenerated(RecordAddFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordLengthDescriptor.FACTORY);
    fc.addGenerated(RecordNamesDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveDescriptor.FACTORY);
    fc.addGenerated(RecordRenameDescriptor.FACTORY);
    fc.addGenerated(RecordUnwrapDescriptor.FACTORY);
    fc.add(RecordReplaceDescriptor.FACTORY);
    fc.add(RecordAddDescriptor.FACTORY);
    fc.add(RecordPutDescriptor.FACTORY);
    fc.addGenerated(RecordValuesDescriptor.FACTORY);
    fc.addGenerated(PairsDescriptor.FACTORY);
    // Spatial and temporal type accessors
    fc.addGenerated(TemporalYearAccessor.FACTORY);
    fc.addGenerated(TemporalMonthAccessor.FACTORY);
    fc.addGenerated(TemporalDayAccessor.FACTORY);
    fc.addGenerated(TemporalHourAccessor.FACTORY);
    fc.addGenerated(TemporalMinuteAccessor.FACTORY);
    fc.addGenerated(TemporalSecondAccessor.FACTORY);
    fc.addGenerated(TemporalMillisecondAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDatetimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDatetimeAccessor.FACTORY);
    // Temporal functions
    fc.addGenerated(UnixTimeFromDateInDaysDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromTimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DateFromUnixTimeInDaysDescriptor.FACTORY);
    fc.addGenerated(DateFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(TimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(TimeFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromDateAndTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDurationFromDateTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDuartionFromDateDescriptor.FACTORY);
    fc.addGenerated(AdjustDateTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(AdjustTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(IntervalBeforeDescriptor.FACTORY);
    fc.addGenerated(IntervalAfterDescriptor.FACTORY);
    fc.addGenerated(IntervalMeetsDescriptor.FACTORY);
    fc.addGenerated(IntervalMetByDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlapsDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlappedByDescriptor.FACTORY);
    fc.addGenerated(OverlapDescriptor.FACTORY);
    fc.addGenerated(IntervalStartsDescriptor.FACTORY);
    fc.addGenerated(IntervalStartedByDescriptor.FACTORY);
    fc.addGenerated(IntervalCoversDescriptor.FACTORY);
    fc.addGenerated(IntervalCoveredByDescriptor.FACTORY);
    fc.addGenerated(IntervalEndsDescriptor.FACTORY);
    fc.addGenerated(IntervalEndedByDescriptor.FACTORY);
    fc.addGenerated(DurationFromMillisecondsDescriptor.FACTORY);
    fc.addGenerated(DurationFromMonthsDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(MonthsFromYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(MillisecondsFromDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(DurationEqualDescriptor.FACTORY);
    fc.addGenerated(GetYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(GetDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(IntervalBinDescriptor.FACTORY);
    fc.addGenerated(OverlapBinsDescriptor.FACTORY);
    fc.addGenerated(DayOfWeekDescriptor.FACTORY);
    fc.addGenerated(ParseDateDescriptor.FACTORY);
    fc.addGenerated(ParseTimeDescriptor.FACTORY);
    fc.addGenerated(ParseDateTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateDescriptor.FACTORY);
    fc.addGenerated(PrintTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateTimeDescriptor.FACTORY);
    fc.addGenerated(GetOverlappingIntervalDescriptor.FACTORY);
    fc.addGenerated(DurationFromIntervalDescriptor.FACTORY);
    // Type functions.
    fc.addGenerated(IsArrayDescriptor.FACTORY);
    fc.addGenerated(IsAtomicDescriptor.FACTORY);
    fc.addGenerated(IsBooleanDescriptor.FACTORY);
    fc.addGenerated(IsNumberDescriptor.FACTORY);
    fc.addGenerated(IsObjectDescriptor.FACTORY);
    fc.addGenerated(IsStringDescriptor.FACTORY);
    fc.addGenerated(ToArrayDescriptor.FACTORY);
    fc.addGenerated(ToAtomicDescriptor.FACTORY);
    fc.addGenerated(ToBigIntDescriptor.FACTORY);
    fc.addGenerated(ToBooleanDescriptor.FACTORY);
    fc.addGenerated(ToDoubleDescriptor.FACTORY);
    fc.addGenerated(ToNumberDescriptor.FACTORY);
    fc.addGenerated(ToObjectDescriptor.FACTORY);
    fc.addGenerated(ToStringDescriptor.FACTORY);
    fc.addGenerated(TreatAsIntegerDescriptor.FACTORY);
    // Cast function
    fc.addGenerated(CastTypeDescriptor.FACTORY);
    fc.addGenerated(CastTypeLaxDescriptor.FACTORY);
    // Record function
    fc.addGenerated(RecordPairsDescriptor.FACTORY);
    // Other functions
    fc.addGenerated(RandomWithSeedDescriptor.FACTORY);
    ServiceLoader.load(IFunctionRegistrant.class).iterator().forEachRemaining(c -> c.register(fc));
    return fc;
}
#method_after
public static FunctionCollection createDefaultFunctionCollection() {
    FunctionCollection fc = new FunctionCollection();
    // array functions
    fc.add(ArrayRemoveDescriptor.FACTORY);
    fc.add(ArrayPutDescriptor.FACTORY);
    fc.add(ArrayPrependDescriptor.FACTORY);
    fc.add(ArrayAppendDescriptor.FACTORY);
    fc.add(ArrayInsertDescriptor.FACTORY);
    fc.addGenerated(ArrayPositionDescriptor.FACTORY);
    fc.addGenerated(ArrayRepeatDescriptor.FACTORY);
    fc.addGenerated(ArrayContainsDescriptor.FACTORY);
    fc.addGenerated(ArrayReverseDescriptor.FACTORY);
    fc.addGenerated(ArraySortDescriptor.FACTORY);
    fc.addGenerated(ArrayDistinctDescriptor.FACTORY);
    fc.addGenerated(ArrayUnionDescriptor.FACTORY);
    fc.addGenerated(ArrayIntersectDescriptor.FACTORY);
    fc.addGenerated(ArrayIfNullDescriptor.FACTORY);
    fc.addGenerated(ArrayConcatDescriptor.FACTORY);
    fc.addGenerated(ArrayRangeDescriptor.FACTORY);
    fc.addGenerated(ArrayFlattenDescriptor.FACTORY);
    fc.add(ArrayReplaceDescriptor.FACTORY);
    fc.addGenerated(ArraySliceWithEndPositionDescriptor.FACTORY);
    fc.addGenerated(ArraySliceWithoutEndPositionDescriptor.FACTORY);
    fc.addGenerated(ArraySymDiffDescriptor.FACTORY);
    fc.addGenerated(ArraySymDiffnDescriptor.FACTORY);
    fc.addGenerated(ArrayStarDescriptor.FACTORY);
    // unnesting functions
    fc.add(TidRunningAggregateDescriptor.FACTORY);
    fc.add(ScanCollectionDescriptor.FACTORY);
    fc.add(RangeDescriptor.FACTORY);
    fc.add(SubsetCollectionDescriptor.FACTORY);
    // aggregate functions
    fc.add(ListifyAggregateDescriptor.FACTORY);
    fc.add(CountAggregateDescriptor.FACTORY);
    fc.add(AvgAggregateDescriptor.FACTORY);
    fc.add(LocalAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SumAggregateDescriptor.FACTORY);
    fc.add(LocalSumAggregateDescriptor.FACTORY);
    fc.add(IntermediateSumAggregateDescriptor.FACTORY);
    fc.add(GlobalSumAggregateDescriptor.FACTORY);
    fc.add(MaxAggregateDescriptor.FACTORY);
    fc.add(LocalMaxAggregateDescriptor.FACTORY);
    fc.add(MinAggregateDescriptor.FACTORY);
    fc.add(LocalMinAggregateDescriptor.FACTORY);
    fc.add(FirstElementAggregateDescriptor.FACTORY);
    fc.add(LocalFirstElementAggregateDescriptor.FACTORY);
    fc.add(LastElementAggregateDescriptor.FACTORY);
    fc.add(StddevAggregateDescriptor.FACTORY);
    fc.add(LocalStddevAggregateDescriptor.FACTORY);
    fc.add(IntermediateStddevAggregateDescriptor.FACTORY);
    fc.add(GlobalStddevAggregateDescriptor.FACTORY);
    fc.add(LocalSamplingAggregateDescriptor.FACTORY);
    fc.add(RangeMapAggregateDescriptor.FACTORY);
    fc.add(StddevPopAggregateDescriptor.FACTORY);
    fc.add(LocalStddevPopAggregateDescriptor.FACTORY);
    fc.add(IntermediateStddevPopAggregateDescriptor.FACTORY);
    fc.add(GlobalStddevPopAggregateDescriptor.FACTORY);
    fc.add(VarAggregateDescriptor.FACTORY);
    fc.add(LocalVarAggregateDescriptor.FACTORY);
    fc.add(IntermediateVarAggregateDescriptor.FACTORY);
    fc.add(GlobalVarAggregateDescriptor.FACTORY);
    fc.add(VarPopAggregateDescriptor.FACTORY);
    fc.add(LocalVarPopAggregateDescriptor.FACTORY);
    fc.add(IntermediateVarPopAggregateDescriptor.FACTORY);
    fc.add(GlobalVarPopAggregateDescriptor.FACTORY);
    fc.add(KurtosisAggregateDescriptor.FACTORY);
    fc.add(LocalKurtosisAggregateDescriptor.FACTORY);
    fc.add(IntermediateKurtosisAggregateDescriptor.FACTORY);
    fc.add(GlobalKurtosisAggregateDescriptor.FACTORY);
    fc.add(SkewnessAggregateDescriptor.FACTORY);
    fc.add(LocalSkewnessAggregateDescriptor.FACTORY);
    fc.add(IntermediateSkewnessAggregateDescriptor.FACTORY);
    fc.add(GlobalSkewnessAggregateDescriptor.FACTORY);
    // serializable aggregates
    fc.add(SerializableCountAggregateDescriptor.FACTORY);
    fc.add(SerializableAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSumAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSumAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSumAggregateDescriptor.FACTORY);
    fc.add(SerializableStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableVarAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalVarAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateVarAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalVarAggregateDescriptor.FACTORY);
    fc.add(SerializableVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableKurtosisAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalKurtosisAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateKurtosisAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalKurtosisAggregateDescriptor.FACTORY);
    fc.add(SerializableSkewnessAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSkewnessAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSkewnessAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSkewnessAggregateDescriptor.FACTORY);
    // scalar aggregates
    fc.add(ScalarCountAggregateDescriptor.FACTORY);
    fc.add(ScalarAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSumAggregateDescriptor.FACTORY);
    fc.add(ScalarMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarMinAggregateDescriptor.FACTORY);
    fc.add(EmptyStreamAggregateDescriptor.FACTORY);
    fc.add(NonEmptyStreamAggregateDescriptor.FACTORY);
    fc.add(ScalarStddevAggregateDescriptor.FACTORY);
    fc.add(ScalarStddevPopAggregateDescriptor.FACTORY);
    fc.add(ScalarVarAggregateDescriptor.FACTORY);
    fc.add(ScalarVarPopAggregateDescriptor.FACTORY);
    fc.add(ScalarKurtosisAggregateDescriptor.FACTORY);
    fc.add(ScalarSkewnessAggregateDescriptor.FACTORY);
    // SQL aggregates
    fc.add(SqlCountAggregateDescriptor.FACTORY);
    fc.add(SqlAvgAggregateDescriptor.FACTORY);
    fc.add(LocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SqlSumAggregateDescriptor.FACTORY);
    fc.add(LocalSqlSumAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlSumAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SqlMaxAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMaxAggregateDescriptor.FACTORY);
    fc.add(SqlMinAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMinAggregateDescriptor.FACTORY);
    fc.add(SqlStddevAggregateDescriptor.FACTORY);
    fc.add(LocalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlStddevAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(LocalSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SqlVarAggregateDescriptor.FACTORY);
    fc.add(LocalSqlVarAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlVarAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlVarAggregateDescriptor.FACTORY);
    fc.add(SqlVarPopAggregateDescriptor.FACTORY);
    fc.add(LocalSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(SqlKurtosisAggregateDescriptor.FACTORY);
    fc.add(LocalSqlKurtosisAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlKurtosisAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlKurtosisAggregateDescriptor.FACTORY);
    fc.add(SqlSkewnessAggregateDescriptor.FACTORY);
    fc.add(LocalSqlSkewnessAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlSkewnessAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlSkewnessAggregateDescriptor.FACTORY);
    // SQL serializable aggregates
    fc.add(SerializableSqlCountAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlVarAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlVarAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlVarAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlVarAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlKurtosisAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlKurtosisAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlKurtosisAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlKurtosisAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlSkewnessAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlSkewnessAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlSkewnessAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlSkewnessAggregateDescriptor.FACTORY);
    // SQL scalar aggregates
    fc.add(ScalarSqlCountAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlSumAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMinAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlStddevAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlVarAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlKurtosisAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlSkewnessAggregateDescriptor.FACTORY);
    // window functions
    fc.add(DenseRankRunningAggregateDescriptor.FACTORY);
    fc.add(NtileRunningAggregateDescriptor.FACTORY);
    fc.add(RankRunningAggregateDescriptor.FACTORY);
    fc.add(RowNumberRunningAggregateDescriptor.FACTORY);
    fc.add(PercentRankRunningAggregateDescriptor.FACTORY);
    fc.add(WinPartitionLenRunningAggregateDescriptor.FACTORY);
    // boolean functions
    fc.add(AndDescriptor.FACTORY);
    fc.add(OrDescriptor.FACTORY);
    // Record constructors / functions
    fc.add(ClosedRecordConstructorDescriptor.FACTORY);
    fc.add(OpenRecordConstructorDescriptor.FACTORY);
    fc.add(RecordConcatDescriptor.FACTORY);
    fc.add(RecordConcatStrictDescriptor.FACTORY);
    // List constructors
    fc.add(OrderedListConstructorDescriptor.FACTORY);
    fc.add(UnorderedListConstructorDescriptor.FACTORY);
    // Sleep function
    fc.add(SleepDescriptor.FACTORY);
    // Inject failure function
    fc.add(InjectFailureDescriptor.FACTORY);
    // Get Job Parameter function
    fc.add(GetJobParameterByNameDescriptor.FACTORY);
    // Switch case
    fc.add(SwitchCaseDescriptor.FACTORY);
    // null functions
    fc.add(IsMissingDescriptor.FACTORY);
    fc.add(IsNullDescriptor.FACTORY);
    fc.add(IsUnknownDescriptor.FACTORY);
    fc.add(IsSystemNullDescriptor.FACTORY);
    fc.add(CheckUnknownDescriptor.FACTORY);
    fc.add(IfMissingDescriptor.FACTORY);
    fc.add(IfNullDescriptor.FACTORY);
    fc.add(IfMissingOrNullDescriptor.FACTORY);
    fc.add(IfSystemNullDescriptor.FACTORY);
    // uuid generators (zero independent functions)
    fc.add(CreateUUIDDescriptor.FACTORY);
    fc.add(UUIDDescriptor.FACTORY);
    fc.add(CreateQueryUIDDescriptor.FACTORY);
    fc.add(RandomDescriptor.FACTORY);
    fc.add(CurrentDateDescriptor.FACTORY);
    fc.add(CurrentTimeDescriptor.FACTORY);
    fc.add(CurrentDateTimeDescriptor.FACTORY);
    // functions that need generated class for null-handling.
    // Element accessors.
    fc.addGenerated(FieldAccessByIndexDescriptor.FACTORY);
    fc.addGenerated(FieldAccessByNameDescriptor.FACTORY);
    fc.addGenerated(FieldAccessNestedDescriptor.FACTORY);
    fc.addGenerated(AnyCollectionMemberDescriptor.FACTORY);
    fc.addGenerated(GetItemDescriptor.FACTORY);
    // Numeric functions
    fc.add(IfInfDescriptor.FACTORY);
    fc.add(IfNanDescriptor.FACTORY);
    fc.add(IfNanOrInfDescriptor.FACTORY);
    fc.addGenerated(NumericUnaryMinusDescriptor.FACTORY);
    fc.addGenerated(NumericAddDescriptor.FACTORY);
    fc.addGenerated(NumericDivideDescriptor.FACTORY);
    fc.addGenerated(NumericDivDescriptor.FACTORY);
    fc.addGenerated(NumericMultiplyDescriptor.FACTORY);
    fc.addGenerated(NumericSubDescriptor.FACTORY);
    fc.addGenerated(NumericModuloDescriptor.FACTORY);
    fc.addGenerated(NumericPowerDescriptor.FACTORY);
    fc.addGenerated(NotDescriptor.FACTORY);
    fc.addGenerated(LenDescriptor.FACTORY);
    fc.addGenerated(NumericAbsDescriptor.FACTORY);
    fc.addGenerated(NumericCeilingDescriptor.FACTORY);
    fc.addGenerated(NumericFloorDescriptor.FACTORY);
    fc.addGenerated(NumericRoundDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEvenDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEven2Descriptor.FACTORY);
    fc.addGenerated(NumericACosDescriptor.FACTORY);
    fc.addGenerated(NumericASinDescriptor.FACTORY);
    fc.addGenerated(NumericATanDescriptor.FACTORY);
    fc.addGenerated(NumericDegreesDescriptor.FACTORY);
    fc.addGenerated(NumericRadiansDescriptor.FACTORY);
    fc.addGenerated(NumericCosDescriptor.FACTORY);
    fc.addGenerated(NumericCoshDescriptor.FACTORY);
    fc.addGenerated(NumericSinDescriptor.FACTORY);
    fc.addGenerated(NumericSinhDescriptor.FACTORY);
    fc.addGenerated(NumericTanDescriptor.FACTORY);
    fc.addGenerated(NumericTanhDescriptor.FACTORY);
    fc.addGenerated(NumericExpDescriptor.FACTORY);
    fc.addGenerated(NumericLnDescriptor.FACTORY);
    fc.addGenerated(NumericLogDescriptor.FACTORY);
    fc.addGenerated(NumericSqrtDescriptor.FACTORY);
    fc.addGenerated(NumericSignDescriptor.FACTORY);
    fc.addGenerated(NumericTruncDescriptor.FACTORY);
    fc.addGenerated(NumericATan2Descriptor.FACTORY);
    // Comparisons.
    fc.addGenerated(EqualsDescriptor.FACTORY);
    fc.addGenerated(GreaterThanDescriptor.FACTORY);
    fc.addGenerated(GreaterThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(LessThanDescriptor.FACTORY);
    fc.addGenerated(LessThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(NotEqualsDescriptor.FACTORY);
    // If-Equals functions
    fc.addGenerated(MissingIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NullIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NanIfEqualsDescriptor.FACTORY);
    fc.addGenerated(PosInfIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NegInfIfEqualsDescriptor.FACTORY);
    // Binary functions
    fc.addGenerated(BinaryLengthDescriptor.FACTORY);
    fc.addGenerated(ParseBinaryDescriptor.FACTORY);
    fc.addGenerated(PrintBinaryDescriptor.FACTORY);
    fc.addGenerated(BinaryConcatDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromToDescriptor.FACTORY);
    fc.addGenerated(FindBinaryDescriptor.FACTORY);
    fc.addGenerated(FindBinaryFromDescriptor.FACTORY);
    // String functions
    fc.addGenerated(StringLikeDescriptor.FACTORY);
    fc.addGenerated(StringContainsDescriptor.FACTORY);
    fc.addGenerated(StringEndsWithDescriptor.FACTORY);
    fc.addGenerated(StringStartsWithDescriptor.FACTORY);
    fc.addGenerated(SubstringDescriptor.FACTORY);
    fc.addGenerated(StringEqualDescriptor.FACTORY);
    fc.addGenerated(StringLowerCaseDescriptor.FACTORY);
    fc.addGenerated(StringUpperCaseDescriptor.FACTORY);
    fc.addGenerated(StringLengthDescriptor.FACTORY);
    fc.addGenerated(Substring2Descriptor.FACTORY);
    fc.addGenerated(SubstringBeforeDescriptor.FACTORY);
    fc.addGenerated(SubstringAfterDescriptor.FACTORY);
    fc.addGenerated(StringToCodePointDescriptor.FACTORY);
    fc.addGenerated(CodePointToStringDescriptor.FACTORY);
    fc.addGenerated(StringConcatDescriptor.FACTORY);
    fc.addGenerated(StringJoinDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringInitCapDescriptor.FACTORY);
    fc.addGenerated(StringTrimDescriptor.FACTORY);
    fc.addGenerated(StringLTrimDescriptor.FACTORY);
    fc.addGenerated(StringRTrimDescriptor.FACTORY);
    fc.addGenerated(StringTrim2Descriptor.FACTORY);
    fc.addGenerated(StringLTrim2Descriptor.FACTORY);
    fc.addGenerated(StringRTrim2Descriptor.FACTORY);
    fc.addGenerated(StringPositionDescriptor.FACTORY);
    fc.addGenerated(StringRepeatDescriptor.FACTORY);
    fc.addGenerated(StringReplaceDescriptor.FACTORY);
    fc.addGenerated(StringReplaceWithLimitDescriptor.FACTORY);
    fc.addGenerated(StringReverseDescriptor.FACTORY);
    fc.addGenerated(StringSplitDescriptor.FACTORY);
    // Constructors
    fc.addGenerated(ABooleanConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryHexStringConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryBase64StringConstructorDescriptor.FACTORY);
    fc.addGenerated(AStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt8ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt16ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt32ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt64ConstructorDescriptor.FACTORY);
    fc.addGenerated(AFloatConstructorDescriptor.FACTORY);
    fc.addGenerated(ADoubleConstructorDescriptor.FACTORY);
    fc.addGenerated(APointConstructorDescriptor.FACTORY);
    fc.addGenerated(APoint3DConstructorDescriptor.FACTORY);
    fc.addGenerated(ALineConstructorDescriptor.FACTORY);
    fc.addGenerated(APolygonConstructorDescriptor.FACTORY);
    fc.addGenerated(ACircleConstructorDescriptor.FACTORY);
    fc.addGenerated(ARectangleConstructorDescriptor.FACTORY);
    fc.addGenerated(ATimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AYearMonthDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(ADayTimeDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AUUIDFromStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromTimeConstructorDescriptor.FACTORY);
    // Spatial
    fc.addGenerated(CreatePointDescriptor.FACTORY);
    fc.addGenerated(CreateLineDescriptor.FACTORY);
    fc.addGenerated(CreatePolygonDescriptor.FACTORY);
    fc.addGenerated(CreateCircleDescriptor.FACTORY);
    fc.addGenerated(CreateRectangleDescriptor.FACTORY);
    fc.addGenerated(SpatialAreaDescriptor.FACTORY);
    fc.addGenerated(SpatialDistanceDescriptor.FACTORY);
    fc.addGenerated(CreateMBRDescriptor.FACTORY);
    fc.addGenerated(SpatialCellDescriptor.FACTORY);
    fc.addGenerated(PointXCoordinateAccessor.FACTORY);
    fc.addGenerated(PointYCoordinateAccessor.FACTORY);
    fc.addGenerated(CircleRadiusAccessor.FACTORY);
    fc.addGenerated(CircleCenterAccessor.FACTORY);
    fc.addGenerated(LineRectanglePolygonAccessor.FACTORY);
    // full-text function
    fc.addGenerated(FullTextContainsDescriptor.FACTORY);
    fc.addGenerated(FullTextContainsWithoutOptionDescriptor.FACTORY);
    // Record functions.
    fc.addGenerated(GetRecordFieldsDescriptor.FACTORY);
    fc.addGenerated(GetRecordFieldValueDescriptor.FACTORY);
    fc.addGenerated(DeepEqualityDescriptor.FACTORY);
    fc.addGenerated(RecordMergeDescriptor.FACTORY);
    fc.addGenerated(RecordAddFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordLengthDescriptor.FACTORY);
    fc.addGenerated(RecordNamesDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveDescriptor.FACTORY);
    fc.addGenerated(RecordRenameDescriptor.FACTORY);
    fc.addGenerated(RecordUnwrapDescriptor.FACTORY);
    fc.add(RecordReplaceDescriptor.FACTORY);
    fc.add(RecordAddDescriptor.FACTORY);
    fc.add(RecordPutDescriptor.FACTORY);
    fc.addGenerated(RecordValuesDescriptor.FACTORY);
    fc.addGenerated(PairsDescriptor.FACTORY);
    // Spatial and temporal type accessors
    fc.addGenerated(TemporalYearAccessor.FACTORY);
    fc.addGenerated(TemporalMonthAccessor.FACTORY);
    fc.addGenerated(TemporalDayAccessor.FACTORY);
    fc.addGenerated(TemporalHourAccessor.FACTORY);
    fc.addGenerated(TemporalMinuteAccessor.FACTORY);
    fc.addGenerated(TemporalSecondAccessor.FACTORY);
    fc.addGenerated(TemporalMillisecondAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDatetimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDatetimeAccessor.FACTORY);
    // Temporal functions
    fc.addGenerated(UnixTimeFromDateInDaysDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromTimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DateFromUnixTimeInDaysDescriptor.FACTORY);
    fc.addGenerated(DateFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(TimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(TimeFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromDateAndTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDurationFromDateTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDuartionFromDateDescriptor.FACTORY);
    fc.addGenerated(AdjustDateTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(AdjustTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(IntervalBeforeDescriptor.FACTORY);
    fc.addGenerated(IntervalAfterDescriptor.FACTORY);
    fc.addGenerated(IntervalMeetsDescriptor.FACTORY);
    fc.addGenerated(IntervalMetByDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlapsDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlappedByDescriptor.FACTORY);
    fc.addGenerated(OverlapDescriptor.FACTORY);
    fc.addGenerated(IntervalStartsDescriptor.FACTORY);
    fc.addGenerated(IntervalStartedByDescriptor.FACTORY);
    fc.addGenerated(IntervalCoversDescriptor.FACTORY);
    fc.addGenerated(IntervalCoveredByDescriptor.FACTORY);
    fc.addGenerated(IntervalEndsDescriptor.FACTORY);
    fc.addGenerated(IntervalEndedByDescriptor.FACTORY);
    fc.addGenerated(DurationFromMillisecondsDescriptor.FACTORY);
    fc.addGenerated(DurationFromMonthsDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(MonthsFromYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(MillisecondsFromDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(DurationEqualDescriptor.FACTORY);
    fc.addGenerated(GetYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(GetDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(IntervalBinDescriptor.FACTORY);
    fc.addGenerated(OverlapBinsDescriptor.FACTORY);
    fc.addGenerated(DayOfWeekDescriptor.FACTORY);
    fc.addGenerated(ParseDateDescriptor.FACTORY);
    fc.addGenerated(ParseTimeDescriptor.FACTORY);
    fc.addGenerated(ParseDateTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateDescriptor.FACTORY);
    fc.addGenerated(PrintTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateTimeDescriptor.FACTORY);
    fc.addGenerated(GetOverlappingIntervalDescriptor.FACTORY);
    fc.addGenerated(DurationFromIntervalDescriptor.FACTORY);
    // Type functions.
    fc.addGenerated(IsArrayDescriptor.FACTORY);
    fc.addGenerated(IsAtomicDescriptor.FACTORY);
    fc.addGenerated(IsBooleanDescriptor.FACTORY);
    fc.addGenerated(IsNumberDescriptor.FACTORY);
    fc.addGenerated(IsObjectDescriptor.FACTORY);
    fc.addGenerated(IsStringDescriptor.FACTORY);
    fc.addGenerated(ToArrayDescriptor.FACTORY);
    fc.addGenerated(ToAtomicDescriptor.FACTORY);
    fc.addGenerated(ToBigIntDescriptor.FACTORY);
    fc.addGenerated(ToBooleanDescriptor.FACTORY);
    fc.addGenerated(ToDoubleDescriptor.FACTORY);
    fc.addGenerated(ToNumberDescriptor.FACTORY);
    fc.addGenerated(ToObjectDescriptor.FACTORY);
    fc.addGenerated(ToStringDescriptor.FACTORY);
    fc.addGenerated(TreatAsIntegerDescriptor.FACTORY);
    // Cast function
    fc.addGenerated(CastTypeDescriptor.FACTORY);
    fc.addGenerated(CastTypeLaxDescriptor.FACTORY);
    // Record function
    fc.addGenerated(RecordPairsDescriptor.FACTORY);
    // Other functions
    fc.addGenerated(RandomWithSeedDescriptor.FACTORY);
    ServiceLoader.load(IFunctionRegistrant.class).iterator().forEachRemaining(c -> c.register(fc));
    return fc;
}
#end_block

#method_before
public void setAvailableCharsets(Collection<Charset> charsets) {
    synchronized (allCharsets) {
        allCharsets.clear();
        allCharsets.addAll(charsets);
        charsetsRemaining.clear();
    }
}
#method_after
public synchronized void setAvailableCharsets(Charset... charsets) {
    allCharsets.clear();
    allCharsets.addAll(Arrays.asList(charsets));
    charsetsRemaining.clear();
}
#end_block

#method_before
public Charset nextCharset(Predicate<Charset> test) {
    synchronized (allCharsets) {
        while (true) {
            for (Iterator<Charset> iter = charsetsRemaining.iterator(); iter.hasNext(); ) {
                Charset next = iter.next();
                if (test.test(next)) {
                    iter.remove();
                    return next;
                }
            }
            Collections.shuffle(allCharsets);
            charsetsRemaining.addAll(allCharsets);
        }
    }
}
#method_after
private synchronized Charset nextCharset() {
    while (true) {
        Charset nextCharset = charsetsRemaining.poll();
        if (nextCharset != null) {
            return nextCharset;
        }
        Collections.shuffle(allCharsets);
        charsetsRemaining.addAll(allCharsets);
    }
}
#end_block

#method_before
protected HttpUriRequest constructPostMethodUrl(String statement, URI uri, String stmtParam, List<Parameter> otherParams) {
    if (stmtParam == null) {
        throw new NullPointerException("Statement parameter required.");
    }
    RequestBuilder builder = RequestBuilder.post(uri);
    for (Parameter param : upsertParam(otherParams, stmtParam, ParameterTypeEnum.STRING, statement)) {
        builder.addParameter(param.getName(), param.getValue());
    }
    builder.addParameter(stmtParam, statement);
    builder.setCharset(UTF_8);
    return builder.build();
}
#method_after
protected HttpUriRequest constructPostMethodUrl(String statement, URI uri, String stmtParam, List<Parameter> otherParams) {
    Objects.requireNonNull(stmtParam, "statement parameter required");
    RequestBuilder builder = RequestBuilder.post(uri);
    for (Parameter param : upsertParam(otherParams, stmtParam, ParameterTypeEnum.STRING, statement)) {
        builder.addParameter(param.getName(), param.getValue());
    }
    builder.setCharset(statement.length() > MAX_NON_UTF_8_STATEMENT_SIZE ? UTF_8 : nextCharset());
    return builder.build();
}
#end_block

#method_before
protected HttpUriRequest constructPostMethodJson(String statement, URI uri, String stmtParam, List<Parameter> otherParams) {
    if (stmtParam == null) {
        throw new NullPointerException("Statement parameter required.");
    }
    RequestBuilder builder = RequestBuilder.post(uri);
    ObjectMapper om = new ObjectMapper();
    ObjectNode content = om.createObjectNode();
    for (Parameter param : upsertParam(otherParams, stmtParam, ParameterTypeEnum.STRING, statement)) {
        String paramName = param.getName();
        ParameterTypeEnum paramType = param.getType();
        if (paramType == null) {
            paramType = ParameterTypeEnum.STRING;
        }
        String paramValue = param.getValue();
        switch(paramType) {
            case STRING:
                content.put(paramName, paramValue);
                break;
            case JSON:
                content.putRawValue(paramName, new RawValue(paramValue));
                break;
            default:
                throw new IllegalStateException(paramType.toString());
        }
    }
    try {
        builder.setEntity(new StringEntity(om.writeValueAsString(content), ContentType.APPLICATION_JSON));
    } catch (JsonProcessingException e) {
        e.printStackTrace();
    }
    builder.setCharset(UTF_8);
    return builder.build();
}
#method_after
protected HttpUriRequest constructPostMethodJson(String statement, URI uri, String stmtParam, List<Parameter> otherParams) {
    Objects.requireNonNull(stmtParam, "statement parameter required");
    RequestBuilder builder = RequestBuilder.post(uri);
    ObjectMapper om = new ObjectMapper();
    ObjectNode content = om.createObjectNode();
    for (Parameter param : upsertParam(otherParams, stmtParam, ParameterTypeEnum.STRING, statement)) {
        String paramName = param.getName();
        ParameterTypeEnum paramType = param.getType();
        if (paramType == null) {
            paramType = ParameterTypeEnum.STRING;
        }
        String paramValue = param.getValue();
        switch(paramType) {
            case STRING:
                content.put(paramName, paramValue);
                break;
            case JSON:
                content.putRawValue(paramName, new RawValue(paramValue));
                break;
            default:
                throw new IllegalStateException(paramType.toString());
        }
    }
    try {
        builder.setEntity(new StringEntity(om.writeValueAsString(content), ContentType.create(ContentType.APPLICATION_JSON.getMimeType(), statement.length() > MAX_NON_UTF_8_STATEMENT_SIZE ? UTF_8 : nextCharset())));
    } catch (JsonProcessingException e) {
        e.printStackTrace();
    }
    return builder.build();
}
#end_block

#method_before
public void executeQuery(OutputFormat fmt, String statement, Map<String, Object> variableCtx, String reqType, File testFile, File expectedResultFile, File actualResultFile, MutableInt queryCount, int numResultFiles, List<Parameter> params, ComparisonEnum compare) throws Exception {
    String delivery = DELIVERY_IMMEDIATE;
    if (reqType.equalsIgnoreCase("async")) {
        delivery = DELIVERY_ASYNC;
    } else if (reqType.equalsIgnoreCase("deferred")) {
        delivery = DELIVERY_DEFERRED;
    }
    URI uri = testFile.getName().endsWith("aql") ? getEndpoint(Servlets.QUERY_AQL) : getEndpoint(Servlets.QUERY_SERVICE);
    boolean isJsonEncoded = isJsonEncoded(extractHttpRequestType(statement));
    Charset responseCharset = expectedResultFile == null ? UTF_8 : selectCharset(expectedResultFile);
    InputStream resultStream;
    if (DELIVERY_IMMEDIATE.equals(delivery)) {
        resultStream = executeQueryService(statement, fmt, uri, params, isJsonEncoded, responseCharset, null, isCancellable(reqType));
        switch(reqType) {
            case METRICS_QUERY_TYPE:
                resultStream = ResultExtractor.extractMetrics(resultStream, responseCharset);
                break;
            default:
                resultStream = ResultExtractor.extract(resultStream, responseCharset);
                break;
        }
    } else {
        String handleVar = getHandleVariable(statement);
        resultStream = executeQueryService(statement, fmt, uri, upsertParam(params, "mode", ParameterTypeEnum.STRING, delivery), isJsonEncoded, responseCharset);
        String handle = ResultExtractor.extractHandle(resultStream, responseCharset);
        Assert.assertNotNull("no handle for " + reqType + " test " + testFile.toString(), handleVar);
        variableCtx.put(handleVar, toQueryServiceHandle(handle));
    }
    if (actualResultFile == null) {
        if (testFile.getName().startsWith(DIAGNOSE)) {
            LOGGER.info("Diagnostic output: {}", IOUtils.toString(resultStream, responseCharset));
        } else {
            Assert.fail("no result file for " + testFile.toString() + "; queryCount: " + queryCount + ", filectxs.size: " + numResultFiles);
        }
    } else {
        writeOutputToFile(actualResultFile, resultStream);
        if (expectedResultFile == null) {
            if (reqType.equals("store")) {
                return;
            }
            Assert.fail("no result file for " + testFile.toString() + "; queryCount: " + queryCount + ", filectxs.size: " + numResultFiles);
        }
    }
    runScriptAndCompareWithResult(testFile, expectedResultFile, actualResultFile, compare, responseCharset);
    if (!reqType.equals("validate")) {
        queryCount.increment();
    }
    // Deletes the matched result file.
    actualResultFile.getParentFile().delete();
}
#method_after
public void executeQuery(OutputFormat fmt, String statement, Map<String, Object> variableCtx, String reqType, File testFile, File expectedResultFile, File actualResultFile, MutableInt queryCount, int numResultFiles, List<Parameter> params, ComparisonEnum compare) throws Exception {
    String delivery = DELIVERY_IMMEDIATE;
    if (reqType.equalsIgnoreCase("async")) {
        delivery = DELIVERY_ASYNC;
    } else if (reqType.equalsIgnoreCase("deferred")) {
        delivery = DELIVERY_DEFERRED;
    }
    URI uri = testFile.getName().endsWith("aql") ? getEndpoint(Servlets.QUERY_AQL) : getEndpoint(Servlets.QUERY_SERVICE);
    boolean isJsonEncoded = isJsonEncoded(extractHttpRequestType(statement));
    Charset responseCharset = expectedResultFile == null ? UTF_8 : nextCharset();
    InputStream resultStream;
    if (DELIVERY_IMMEDIATE.equals(delivery)) {
        resultStream = executeQueryService(statement, fmt, uri, params, isJsonEncoded, responseCharset, null, isCancellable(reqType));
        switch(reqType) {
            case METRICS_QUERY_TYPE:
                resultStream = ResultExtractor.extractMetrics(resultStream, responseCharset);
                break;
            default:
                resultStream = ResultExtractor.extract(resultStream, responseCharset);
                break;
        }
    } else {
        String handleVar = getHandleVariable(statement);
        resultStream = executeQueryService(statement, fmt, uri, upsertParam(params, "mode", ParameterTypeEnum.STRING, delivery), isJsonEncoded, responseCharset);
        String handle = ResultExtractor.extractHandle(resultStream, responseCharset);
        Assert.assertNotNull("no handle for " + reqType + " test " + testFile.toString(), handleVar);
        variableCtx.put(handleVar, toQueryServiceHandle(handle));
    }
    if (actualResultFile == null) {
        if (testFile.getName().startsWith(DIAGNOSE)) {
            LOGGER.info("Diagnostic output: {}", IOUtils.toString(resultStream, responseCharset));
        } else {
            Assert.fail("no result file for " + testFile.toString() + "; queryCount: " + queryCount + ", filectxs.size: " + numResultFiles);
        }
    } else {
        writeOutputToFile(actualResultFile, resultStream);
        if (expectedResultFile == null) {
            if (reqType.equals("store")) {
                return;
            }
            Assert.fail("no result file for " + testFile.toString() + "; queryCount: " + queryCount + ", filectxs.size: " + numResultFiles);
        }
    }
    runScriptAndCompareWithResult(testFile, expectedResultFile, actualResultFile, compare, responseCharset);
    if (!reqType.equals("validate")) {
        queryCount.increment();
    }
    // Deletes the matched result file.
    actualResultFile.getParentFile().delete();
}
#end_block

#method_before
@Override
public Pair<ILogicalOperator, LogicalVariable> visit(CallExpr fcall, Mutable<ILogicalOperator> tupSource) throws CompilationException {
    LogicalVariable v = context.newVar();
    FunctionSignature signature = fcall.getFunctionSignature();
    List<Mutable<ILogicalExpression>> args = new ArrayList<>();
    Mutable<ILogicalOperator> topOp = tupSource;
    for (Expression expr : fcall.getExprList()) {
        switch(expr.getKind()) {
            case VARIABLE_EXPRESSION:
                VariableExpr varExpr = (VariableExpr) expr;
                ILogicalExpression varRefExpr = translateVariableRef(varExpr);
                args.add(new MutableObject<>(varRefExpr));
                break;
            case LITERAL_EXPRESSION:
                LiteralExpr val = (LiteralExpr) expr;
                args.add(new MutableObject<>(new ConstantExpression(new AsterixConstantValue(ConstantHelper.objectFromLiteral(val.getValue())))));
                break;
            default:
                Pair<ILogicalExpression, Mutable<ILogicalOperator>> eo = langExprToAlgExpression(expr, topOp);
                AbstractLogicalOperator o1 = (AbstractLogicalOperator) eo.second.getValue();
                args.add(new MutableObject<>(eo.first));
                if (o1 != null) {
                    topOp = eo.second;
                }
                break;
        }
    }
    SourceLocation sourceLoc = fcall.getSourceLocation();
    AbstractFunctionCallExpression f = lookupFunction(signature, args, sourceLoc);
    // Put hints into function call expr.
    if (fcall.hasHints()) {
        for (IExpressionAnnotation hint : fcall.getHints()) {
            f.getAnnotations().put(hint, hint);
        }
    }
    AssignOperator op = new AssignOperator(v, new MutableObject<>(f));
    if (topOp != null) {
        op.getInputs().add(topOp);
    }
    op.setSourceLocation(sourceLoc);
    return new Pair<>(op, v);
}
#method_after
@Override
public Pair<ILogicalOperator, LogicalVariable> visit(CallExpr fcall, Mutable<ILogicalOperator> tupSource) throws CompilationException {
    LogicalVariable v = context.newVar();
    FunctionSignature signature = fcall.getFunctionSignature();
    List<Mutable<ILogicalExpression>> args = new ArrayList<>();
    Mutable<ILogicalOperator> topOp = tupSource;
    for (Expression expr : fcall.getExprList()) {
        switch(expr.getKind()) {
            case VARIABLE_EXPRESSION:
                VariableExpr varExpr = (VariableExpr) expr;
                ILogicalExpression varRefExpr = translateVariableRef(varExpr);
                args.add(new MutableObject<>(varRefExpr));
                break;
            case LITERAL_EXPRESSION:
                LiteralExpr val = (LiteralExpr) expr;
                args.add(new MutableObject<>(new ConstantExpression(new AsterixConstantValue(ConstantHelper.objectFromLiteral(val.getValue())))));
                break;
            default:
                Pair<ILogicalExpression, Mutable<ILogicalOperator>> eo = langExprToAlgExpression(expr, topOp);
                AbstractLogicalOperator o1 = (AbstractLogicalOperator) eo.second.getValue();
                args.add(new MutableObject<>(eo.first));
                if (o1 != null) {
                    topOp = eo.second;
                }
                break;
        }
    }
    SourceLocation sourceLoc = fcall.getSourceLocation();
    AbstractFunctionCallExpression f = lookupFunction(signature, args, sourceLoc);
    if (f == null) {
        throw new CompilationException(ErrorCode.UNKNOWN_FUNCTION, sourceLoc, signature.getName() + "@" + signature.getArity());
    }
    // Put hints into function call expr.
    if (fcall.hasHints()) {
        for (IExpressionAnnotation hint : fcall.getHints()) {
            f.getAnnotations().put(hint, hint);
        }
    }
    AssignOperator op = new AssignOperator(v, new MutableObject<>(f));
    if (topOp != null) {
        op.getInputs().add(topOp);
    }
    op.setSourceLocation(sourceLoc);
    return new Pair<>(op, v);
}
#end_block

#method_before
protected AbstractFunctionCallExpression lookupFunction(FunctionSignature signature, List<Mutable<ILogicalExpression>> args, SourceLocation sourceLoc) throws CompilationException {
    AbstractFunctionCallExpression f;
    if ((f = lookupUserDefinedFunction(signature, args, sourceLoc)) == null) {
        f = lookupBuiltinFunction(signature.getName(), signature.getArity(), args, sourceLoc);
    }
    if (f == null) {
        throw new CompilationException(ErrorCode.UNKNOWN_FUNCTION, sourceLoc, signature.getName() + "@" + signature.getArity());
    }
    return f;
}
#method_after
protected AbstractFunctionCallExpression lookupFunction(FunctionSignature signature, List<Mutable<ILogicalExpression>> args, SourceLocation sourceLoc) throws CompilationException {
    AbstractFunctionCallExpression f;
    if ((f = lookupUserDefinedFunction(signature, args, sourceLoc)) == null) {
        f = lookupBuiltinFunction(signature.getName(), signature.getArity(), args, sourceLoc);
    }
    return f;
}
#end_block

#method_before
private int hashRecord(IAType type, byte[] bytes, int offset, int length) throws HyracksDataException {
    if (type == null) {
        return MurmurHash3BinaryHash.hash(bytes, offset, length, seed);
    }
    ARecordType recordType = (ARecordType) TypeComputeUtils.getActualTypeOrOpen(type, ATypeTag.OBJECT);
    ARecordVisitablePointable record = recordAllocator.allocateRecordValue(recordType);
    PriorityQueue<IVisitablePointable> namesHeap = heapAllocator.allocate(null);
    try {
        record.set(bytes, offset, length);
        namesHeap.clear();
        List<IVisitablePointable> fieldsNames = record.getFieldNames();
        List<IVisitablePointable> fieldsValues = record.getFieldValues();
        CompareHashUtil.addToHeap(fieldsNames, fieldsValues, namesHeap);
        IVisitablePointable fieldName, fieldValue;
        IAType fieldType;
        int hash = 0;
        int fieldIdx;
        while (!namesHeap.isEmpty()) {
            fieldName = namesHeap.poll();
            // TODO(ali): currently doing another lookup to find the target field index and get its value & type
            fieldIdx = CompareHashUtil.getIndex(fieldsNames, fieldName);
            fieldValue = fieldsValues.get(fieldIdx);
            fieldType = CompareHashUtil.getType(recordType, fieldIdx, fieldValue);
            hash ^= hash(fieldType, fieldValue.getByteArray(), fieldValue.getStartOffset(), fieldValue.getLength());
        }
        return hash;
    } finally {
        recordAllocator.freeRecord(record);
        heapAllocator.free(namesHeap);
    }
}
#method_after
private int hashRecord(IAType type, byte[] bytes, int offset, int length) throws HyracksDataException {
    if (type == null) {
        return MurmurHash3BinaryHash.hash(bytes, offset, length, seed);
    }
    ARecordType recordType = (ARecordType) TypeComputeUtils.getActualTypeOrOpen(type, ATypeTag.OBJECT);
    ARecordVisitablePointable record = recordAllocator.allocateRecordValue(recordType);
    PriorityQueue<IVisitablePointable> namesHeap = heapAllocator.allocate(null);
    try {
        record.set(bytes, offset, length);
        namesHeap.clear();
        List<IVisitablePointable> fieldsNames = record.getFieldNames();
        List<IVisitablePointable> fieldsValues = record.getFieldValues();
        CompareHashUtil.addToHeap(fieldsNames, fieldsValues, namesHeap);
        IVisitablePointable fieldName, fieldValue;
        IAType fieldType;
        int hash = 0;
        int fieldIdx;
        while (!namesHeap.isEmpty()) {
            fieldName = namesHeap.poll();
            // TODO(ali): currently doing another lookup to find the target field index and get its value & type
            fieldIdx = CompareHashUtil.getIndex(fieldsNames, fieldName);
            fieldValue = fieldsValues.get(fieldIdx);
            fieldType = CompareHashUtil.getType(recordType, fieldIdx, fieldValue);
            hash ^= MurmurHash3BinaryHash.hash(fieldName.getByteArray(), fieldName.getStartOffset(), fieldName.getLength(), seed) ^ hash(fieldType, fieldValue.getByteArray(), fieldValue.getStartOffset(), fieldValue.getLength());
        }
        return hash;
    } finally {
        recordAllocator.freeRecord(record);
        heapAllocator.free(namesHeap);
    }
}
#end_block

#method_before
@Override
public void contributeRuntimeOperator(IHyracksJobBuilder builder, JobGenContext context, ILogicalOperator op, IOperatorSchema propagatedSchema, IOperatorSchema[] inputSchemas, IOperatorSchema outerPlanSchema) throws AlgebricksException {
    validateNumKeys(keysLeftBranch, keysRightBranch);
    int[] keysLeft = JobGenHelper.variablesToFieldIndexes(keysLeftBranch, inputSchemas[0]);
    int[] keysRight = JobGenHelper.variablesToFieldIndexes(keysRightBranch, inputSchemas[1]);
    IVariableTypeEnvironment env = context.getTypeEnvironment(op);
    IBinaryHashFunctionFactory[] leftHashFunFactories = JobGenHelper.variablesToBinaryHashFunctionFactories(keysLeftBranch, env, context);
    IBinaryHashFunctionFactory[] rightHashFunFactories = JobGenHelper.variablesToBinaryHashFunctionFactories(keysLeftBranch, env, context);
    IBinaryComparatorFactory[] comparatorFactories = new IBinaryComparatorFactory[keysLeft.length];
    IBinaryComparatorFactoryProvider bcfp = context.getBinaryComparatorFactoryProvider();
    Object leftType;
    Object rightType;
    for (int i = 0; i < keysLeftBranch.size(); i++) {
        leftType = env.getVarType(keysLeftBranch.get(i));
        rightType = env.getVarType(keysRightBranch.get(i));
        comparatorFactories[i] = bcfp.getBinaryComparatorFactory(leftType, rightType, true);
    }
    IPredicateEvaluatorFactoryProvider predEvaluatorFactoryProvider = context.getPredicateEvaluatorFactoryProvider();
    IPredicateEvaluatorFactory predEvaluatorFactory = (predEvaluatorFactoryProvider == null ? null : predEvaluatorFactoryProvider.getPredicateEvaluatorFactory(keysLeft, keysRight));
    RecordDescriptor recDescriptor = JobGenHelper.mkRecordDescriptor(context.getTypeEnvironment(op), propagatedSchema, context);
    IOperatorDescriptorRegistry spec = builder.getJobSpec();
    IOperatorDescriptor opDesc;
    switch(kind) {
        case INNER:
            opDesc = new InMemoryHashJoinOperatorDescriptor(spec, keysLeft, keysRight, leftHashFunFactories, rightHashFunFactories, comparatorFactories, recDescriptor, tableSize, predEvaluatorFactory, memSizeInFrames);
            break;
        case LEFT_OUTER:
            IMissingWriterFactory[] nonMatchWriterFactories = new IMissingWriterFactory[inputSchemas[1].getSize()];
            for (int j = 0; j < nonMatchWriterFactories.length; j++) {
                nonMatchWriterFactories[j] = context.getMissingWriterFactory();
            }
            opDesc = new InMemoryHashJoinOperatorDescriptor(spec, keysLeft, keysRight, leftHashFunFactories, rightHashFunFactories, comparatorFactories, predEvaluatorFactory, recDescriptor, true, nonMatchWriterFactories, tableSize, memSizeInFrames);
            break;
        default:
            throw new NotImplementedException();
    }
    opDesc.setSourceLocation(op.getSourceLocation());
    contributeOpDesc(builder, (AbstractLogicalOperator) op, opDesc);
    ILogicalOperator src1 = op.getInputs().get(0).getValue();
    builder.contributeGraphEdge(src1, 0, op, 0);
    ILogicalOperator src2 = op.getInputs().get(1).getValue();
    builder.contributeGraphEdge(src2, 0, op, 1);
}
#method_after
@Override
public void contributeRuntimeOperator(IHyracksJobBuilder builder, JobGenContext context, ILogicalOperator op, IOperatorSchema propagatedSchema, IOperatorSchema[] inputSchemas, IOperatorSchema outerPlanSchema) throws AlgebricksException {
    validateNumKeys(keysLeftBranch, keysRightBranch);
    int[] keysLeft = JobGenHelper.variablesToFieldIndexes(keysLeftBranch, inputSchemas[0]);
    int[] keysRight = JobGenHelper.variablesToFieldIndexes(keysRightBranch, inputSchemas[1]);
    IVariableTypeEnvironment env = context.getTypeEnvironment(op);
    IBinaryHashFunctionFactory[] leftHashFunFactories = JobGenHelper.variablesToBinaryHashFunctionFactories(keysLeftBranch, env, context);
    IBinaryHashFunctionFactory[] rightHashFunFactories = JobGenHelper.variablesToBinaryHashFunctionFactories(keysRightBranch, env, context);
    IBinaryComparatorFactory[] comparatorFactories = new IBinaryComparatorFactory[keysLeft.length];
    IBinaryComparatorFactoryProvider bcfp = context.getBinaryComparatorFactoryProvider();
    Object leftType;
    Object rightType;
    for (int i = 0; i < keysLeftBranch.size(); i++) {
        leftType = env.getVarType(keysLeftBranch.get(i));
        rightType = env.getVarType(keysRightBranch.get(i));
        comparatorFactories[i] = bcfp.getBinaryComparatorFactory(leftType, rightType, true);
    }
    IPredicateEvaluatorFactoryProvider predEvaluatorFactoryProvider = context.getPredicateEvaluatorFactoryProvider();
    IPredicateEvaluatorFactory predEvaluatorFactory = (predEvaluatorFactoryProvider == null ? null : predEvaluatorFactoryProvider.getPredicateEvaluatorFactory(keysLeft, keysRight));
    RecordDescriptor recDescriptor = JobGenHelper.mkRecordDescriptor(context.getTypeEnvironment(op), propagatedSchema, context);
    IOperatorDescriptorRegistry spec = builder.getJobSpec();
    IOperatorDescriptor opDesc;
    switch(kind) {
        case INNER:
            opDesc = new InMemoryHashJoinOperatorDescriptor(spec, keysLeft, keysRight, leftHashFunFactories, rightHashFunFactories, comparatorFactories, recDescriptor, tableSize, predEvaluatorFactory, memSizeInFrames);
            break;
        case LEFT_OUTER:
            IMissingWriterFactory[] nonMatchWriterFactories = new IMissingWriterFactory[inputSchemas[1].getSize()];
            for (int j = 0; j < nonMatchWriterFactories.length; j++) {
                nonMatchWriterFactories[j] = context.getMissingWriterFactory();
            }
            opDesc = new InMemoryHashJoinOperatorDescriptor(spec, keysLeft, keysRight, leftHashFunFactories, rightHashFunFactories, comparatorFactories, predEvaluatorFactory, recDescriptor, true, nonMatchWriterFactories, tableSize, memSizeInFrames);
            break;
        default:
            throw new NotImplementedException();
    }
    opDesc.setSourceLocation(op.getSourceLocation());
    contributeOpDesc(builder, (AbstractLogicalOperator) op, opDesc);
    ILogicalOperator src1 = op.getInputs().get(0).getValue();
    builder.contributeGraphEdge(src1, 0, op, 0);
    ILogicalOperator src2 = op.getInputs().get(1).getValue();
    builder.contributeGraphEdge(src2, 0, op, 1);
}
#end_block

#method_before
public static IAType getActualType(IAType inputType) {
    return inputType.getTypeTag() == ATypeTag.UNION ? ((AUnionType) inputType).getActualType() : inputType;
}
#method_after
private static IAType[] getActualType(IAType... inputTypes) {
    IAType[] actualTypes = new IAType[inputTypes.length];
    int index = 0;
    for (IAType inputType : inputTypes) {
        actualTypes[index++] = getActualType(inputType);
    }
    return actualTypes;
}
#end_block

#method_before
private int hashArray(IAType type, byte[] bytes, int offset, int length, int seed) throws IOException {
    if (type == null) {
        return MurmurHash3BinaryHash.hash(bytes, offset, length, seed);
    }
    IAType arrayType = TypeComputeUtils.getActualTypeOrOpen(type, ATypeTag.ARRAY);
    IAType itemType = ((AbstractCollectionType) arrayType).getItemType();
    ATypeTag itemTag = itemType.getTypeTag();
    int numItems = ListAccessorUtil.numberOfItems(bytes, offset);
    int hash = ATypeTag.ARRAY.hashCode();
    IPointable item = voidPointableAllocator.allocate(null);
    ArrayBackedValueStorage storage = (ArrayBackedValueStorage) storageAllocator.allocate(null);
    try {
        for (int i = 0; i < numItems; i++) {
            ListAccessorUtil.getItem(bytes, offset, i, ATypeTag.ARRAY, itemTag, item, storage);
            hash ^= hash(itemType, item.getByteArray(), item.getStartOffset(), item.getLength());
        }
    } finally {
        voidPointableAllocator.free(item);
        storageAllocator.free(storage);
    }
    return hash;
}
#method_after
private int hashArray(IAType type, byte[] bytes, int offset, int length, int seed) throws IOException {
    if (type == null) {
        return MurmurHash3BinaryHash.hash(bytes, offset, length, seed);
    }
    IAType arrayType = TypeComputeUtils.getActualTypeOrOpen(type, ATypeTag.ARRAY);
    IAType itemType = ((AbstractCollectionType) arrayType).getItemType();
    ATypeTag itemTag = itemType.getTypeTag();
    int numItems = ListAccessorUtil.numberOfItems(bytes, offset);
    int hash = 0;
    IPointable item = voidPointableAllocator.allocate(null);
    ArrayBackedValueStorage storage = (ArrayBackedValueStorage) storageAllocator.allocate(null);
    try {
        for (int i = 0; i < numItems; i++) {
            ListAccessorUtil.getItem(bytes, offset, i, ATypeTag.ARRAY, itemTag, item, storage);
            hash ^= hash(itemType, item.getByteArray(), item.getStartOffset(), item.getLength());
        }
    } finally {
        voidPointableAllocator.free(item);
        storageAllocator.free(storage);
    }
    return hash;
}
#end_block

#method_before
@Override
public boolean rewritePre(Mutable<ILogicalOperator> opRef, IOptimizationContext context) throws AlgebricksException {
    AbstractLogicalOperator op1 = (AbstractLogicalOperator) opRef.getValue();
    if (op1.getOperatorTag() != LogicalOperatorTag.SUBPLAN) {
        return false;
    }
    SubplanOperator subplan1 = (SubplanOperator) op1;
    Mutable<ILogicalOperator> op2Ref = subplan1.getInputs().get(0);
    ILogicalOperator op2 = op2Ref.getValue();
    if (op2.getOperatorTag() != LogicalOperatorTag.SUBPLAN) {
        return false;
    }
    SubplanOperator subplan2 = (SubplanOperator) op2;
    Map<LogicalVariable, LogicalVariable> assignVarMap = new LinkedHashMap<>();
    Map<LogicalVariable, LogicalVariable> tmpVarMap = new LinkedHashMap<>();
    List<LogicalVariable> tmpVarList = new ArrayList<>();
    for (Iterator<ILogicalPlan> nestedPlanIter = subplan1.getNestedPlans().iterator(); nestedPlanIter.hasNext(); ) {
        ILogicalPlan nestedPlan = nestedPlanIter.next();
        for (Iterator<Mutable<ILogicalOperator>> rootOpIter = nestedPlan.getRoots().iterator(); rootOpIter.hasNext(); ) {
            ILogicalOperator rootOp = rootOpIter.next().getValue();
            if (findIsomorphicPlanRoot(rootOp, subplan2, assignVarMap, tmpVarList, tmpVarMap)) {
                rootOpIter.remove();
            }
        }
        if (nestedPlan.getRoots().isEmpty()) {
            nestedPlanIter.remove();
        }
    }
    int assignVarCount = assignVarMap.size();
    if (assignVarCount == 0) {
        return false;
    }
    List<LogicalVariable> assignVars = new ArrayList<>(assignVarCount);
    List<Mutable<ILogicalExpression>> assignExprs = new ArrayList<>(assignVarCount);
    for (Map.Entry<LogicalVariable, LogicalVariable> me : assignVarMap.entrySet()) {
        LogicalVariable subplan1Var = me.getKey();
        LogicalVariable subplan2Var = me.getValue();
        VariableReferenceExpression subplan2VarRef = new VariableReferenceExpression(subplan2Var);
        subplan2VarRef.setSourceLocation(subplan2.getSourceLocation());
        assignVars.add(subplan1Var);
        assignExprs.add(new MutableObject<>(subplan2VarRef));
    }
    Mutable<ILogicalOperator> assignInputOp = subplan1.getNestedPlans().isEmpty() ? op2Ref : new MutableObject<>(subplan1);
    AssignOperator assignOp = new AssignOperator(assignVars, assignExprs);
    assignOp.setSourceLocation(subplan1.getSourceLocation());
    assignOp.getInputs().add(assignInputOp);
    context.computeAndSetTypeEnvironmentForOperator(assignOp);
    opRef.setValue(assignOp);
    return true;
}
#method_after
@Override
public boolean rewritePre(Mutable<ILogicalOperator> opRef, IOptimizationContext context) throws AlgebricksException {
    AbstractLogicalOperator op1 = (AbstractLogicalOperator) opRef.getValue();
    if (op1.getOperatorTag() != LogicalOperatorTag.SUBPLAN) {
        return false;
    }
    SubplanOperator subplan1 = (SubplanOperator) op1;
    Mutable<ILogicalOperator> op2Ref = subplan1.getInputs().get(0);
    ILogicalOperator op2 = op2Ref.getValue();
    if (op2.getOperatorTag() != LogicalOperatorTag.SUBPLAN) {
        return false;
    }
    SubplanOperator subplan2 = (SubplanOperator) op2;
    Map<LogicalVariable, LogicalVariable> assignVarMap = new LinkedHashMap<>();
    Map<LogicalVariable, LogicalVariable> tmpVarMap = new LinkedHashMap<>();
    List<LogicalVariable> tmpVarList = new ArrayList<>();
    for (Iterator<ILogicalPlan> nestedPlanIter = subplan1.getNestedPlans().iterator(); nestedPlanIter.hasNext(); ) {
        ILogicalPlan nestedPlan = nestedPlanIter.next();
        for (Iterator<Mutable<ILogicalOperator>> rootOpIter = nestedPlan.getRoots().iterator(); rootOpIter.hasNext(); ) {
            ILogicalOperator rootOp = rootOpIter.next().getValue();
            if (findIsomorphicPlanRoot(rootOp, subplan2, assignVarMap, tmpVarList, tmpVarMap)) {
                rootOpIter.remove();
            }
        }
        if (nestedPlan.getRoots().isEmpty()) {
            nestedPlanIter.remove();
        }
    }
    int assignVarCount = assignVarMap.size();
    if (assignVarCount == 0) {
        return false;
    }
    List<LogicalVariable> assignVars = new ArrayList<>(assignVarCount);
    List<Mutable<ILogicalExpression>> assignExprs = new ArrayList<>(assignVarCount);
    for (Map.Entry<LogicalVariable, LogicalVariable> me : assignVarMap.entrySet()) {
        LogicalVariable subplan1Var = me.getKey();
        LogicalVariable subplan2Var = me.getValue();
        VariableReferenceExpression subplan2VarRef = new VariableReferenceExpression(subplan2Var);
        subplan2VarRef.setSourceLocation(subplan2.getSourceLocation());
        assignVars.add(subplan1Var);
        assignExprs.add(new MutableObject<>(subplan2VarRef));
    }
    Mutable<ILogicalOperator> assignInputOp;
    if (subplan1.getNestedPlans().isEmpty()) {
        assignInputOp = op2Ref;
    } else {
        // some nested plans were removed from subplan1 -> recompute its type environment
        context.computeAndSetTypeEnvironmentForOperator(subplan1);
        assignInputOp = new MutableObject<>(subplan1);
    }
    AssignOperator assignOp = new AssignOperator(assignVars, assignExprs);
    assignOp.setSourceLocation(subplan1.getSourceLocation());
    assignOp.getInputs().add(assignInputOp);
    context.computeAndSetTypeEnvironmentForOperator(assignOp);
    opRef.setValue(assignOp);
    return true;
}
#end_block

#method_before
protected int compareInterval(byte[] b1, int s1, int l1, byte[] b2, int s2, int l2) throws HyracksDataException {
    return -descIntervalComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
}
#method_after
@Override
protected int compareInterval(byte[] b1, int s1, int l1, byte[] b2, int s2, int l2) throws HyracksDataException {
    return -descIntervalComp.compare(b1, s1 + 1, l1 - 1, b2, s2 + 1, l2 - 1);
}
#end_block

#method_before
@Override
public boolean rewritePost(Mutable<ILogicalOperator> opRef, IOptimizationContext context) throws AlgebricksException {
    AbstractLogicalOperator op = (AbstractLogicalOperator) opRef.getValue();
    if (op.getOperatorTag() != LogicalOperatorTag.SELECT) {
        return false;
    }
    SelectOperator select = (SelectOperator) op;
    ILogicalExpression condition = select.getCondition().getValue();
    // Get the output type environment
    IVariableTypeEnvironment env = context.getOutputTypeEnvironment(select);
    if (env == null) {
        env = select.computeOutputTypeEnvironment(context);
    }
    IAType condType = (IAType) env.getType(condition);
    if (condType.getTypeTag() != ATypeTag.BOOLEAN && condType.getTypeTag() != ATypeTag.ANY && !isPossibleBoolean(condType)) {
        throw new CompilationException(ErrorCode.COMPILATION_ERROR, condition.getSourceLocation(), "The select condition " + LogRedactionUtil.userData(condition.toString()) + " should be of the " + "boolean type.");
    }
    return false;
}
#method_after
@Override
public boolean rewritePost(Mutable<ILogicalOperator> opRef, IOptimizationContext context) throws AlgebricksException {
    AbstractLogicalOperator op = (AbstractLogicalOperator) opRef.getValue();
    if (op.getOperatorTag() != LogicalOperatorTag.SELECT) {
        return false;
    }
    SelectOperator select = (SelectOperator) op;
    ILogicalExpression condition = select.getCondition().getValue();
    // Get the output type environment
    IVariableTypeEnvironment env = context.getOutputTypeEnvironment(select);
    IAType condType = (IAType) env.getType(condition);
    if (condType.getTypeTag() != ATypeTag.BOOLEAN && condType.getTypeTag() != ATypeTag.ANY && !isPossibleBoolean(condType)) {
        throw new CompilationException(ErrorCode.COMPILATION_ERROR, condition.getSourceLocation(), "The select condition " + LogRedactionUtil.userData(condition.toString()) + " should be of the " + "boolean type.");
    }
    return false;
}
#end_block

#method_before
public static IAType getActualType(IAType inputType) {
    return inputType.getTypeTag() == ATypeTag.UNION ? ((AUnionType) inputType).getActualType() : inputType;
}
#method_after
private static IAType[] getActualType(IAType... inputTypes) {
    IAType[] actualTypes = new IAType[inputTypes.length];
    int index = 0;
    for (IAType inputType : inputTypes) {
        actualTypes[index++] = getActualType(inputType);
    }
    return actualTypes;
}
#end_block

#method_before
@Override
public void runWork() {
    final ICCServiceContext ctx = ccs.getContext();
    try {
        final IMessage data = (IMessage) DeploymentUtils.deserialize(message, deploymentId, ctx);
        ccs.getExecutor().execute(() -> {
            try {
                ctx.getMessageBroker().receivedMessage(data, nodeId);
            } catch (Exception e) {
                throw new IllegalStateException(e);
            }
        });
    } catch (Exception e) {
        LOGGER.error("unexpected error", e);
        throw new IllegalStateException(e);
    }
}
#method_after
@Override
public void runWork() {
    final ICCServiceContext ctx = ccs.getContext();
    try {
        final IMessage data = (IMessage) DeploymentUtils.deserialize(message, deploymentId, ctx);
        notifyMessageBroker(ctx, data, nodeId);
    } catch (Exception e) {
        LOGGER.error("unexpected error", e);
        throw new IllegalStateException(e);
    }
}
#end_block

#method_before
@Override
public Result compare(byte[] leftBytes, int leftStart, int leftLen, byte[] rightBytes, int rightStart, int rightLen) throws HyracksDataException {
    ATypeTag leftRuntimeTag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(leftBytes[leftStart]);
    ATypeTag rightRuntimeTag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(rightBytes[rightStart]);
    Result comparisonResult = LogicalComparatorUtil.returnMissingOrNullOrMismatch(leftRuntimeTag, rightRuntimeTag);
    if (comparisonResult != null) {
        return comparisonResult;
    }
    // make sure both left and right are complex types
    if (!leftRuntimeTag.isDerivedType() || !rightRuntimeTag.isDerivedType()) {
        // maybe we can invoke the scalar comparison? or we can even reduce this comparator to be the generic one?
        return Result.NULL;
    }
    try {
        return compareComplex(leftType, leftRuntimeTag, leftBytes, leftStart, leftLen, rightType, rightRuntimeTag, rightBytes, rightStart, rightLen);
    } finally {
        storageAllocator.reset();
        voidPointableAllocator.reset();
    }
}
#method_after
@Override
public Result compare(byte[] leftBytes, int leftStart, int leftLen, byte[] rightBytes, int rightStart, int rightLen) throws HyracksDataException {
    ATypeTag leftRuntimeTag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(leftBytes[leftStart]);
    ATypeTag rightRuntimeTag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(rightBytes[rightStart]);
    Result comparisonResult = LogicalComparatorUtil.returnMissingOrNullOrMismatch(leftRuntimeTag, rightRuntimeTag);
    if (comparisonResult != null) {
        return comparisonResult;
    }
    // make sure both left and right are complex types
    if (!leftRuntimeTag.isDerivedType() || !rightRuntimeTag.isDerivedType()) {
        throw new IllegalStateException("Input types are not complex type");
    }
    try {
        return compareComplex(leftType, leftRuntimeTag, leftBytes, leftStart, leftLen, rightType, rightRuntimeTag, rightBytes, rightStart, rightLen);
    } finally {
        storageAllocator.reset();
        voidPointableAllocator.reset();
    }
}
#end_block

#method_before
@Override
public Result compare(IAObject leftConstant, byte[] rightBytes, int rightStart, int rightLen) {
    // TODO(ali): not defined currently for constant complex types
    Result result = compare(rightBytes, rightStart, rightLen, leftConstant);
    if (result == Result.LT) {
        return Result.GT;
    } else if (result == Result.GT) {
        return Result.LT;
    }
    return result;
}
#method_after
@Override
public Result compare(IAObject leftConstant, byte[] rightBytes, int rightStart, int rightLen) {
    // TODO(ali): not defined currently for constant complex types
    Result result = compare(rightBytes, rightStart, rightLen, leftConstant);
    switch(result) {
        case LT:
            return Result.GT;
        case GT:
            return Result.LT;
        default:
            return result;
    }
}
#end_block

#method_before
private Result compareComplex(IAType leftType, ATypeTag leftRuntimeTag, byte[] leftBytes, int leftStart, int leftLen, IAType rightType, ATypeTag rightRuntimeTag, byte[] rightBytes, int rightStart, int rightLen) throws HyracksDataException {
    if (!ATypeHierarchy.isCompatible(leftRuntimeTag, rightRuntimeTag)) {
        return Result.MISMATCH;
    }
    switch(leftRuntimeTag) {
        case MULTISET:
            // equality is the only operation defined for multiset
            if (!isEquality) {
                return Result.NULL;
            }
            return compareMultisets(leftType, leftRuntimeTag, leftBytes, leftStart, rightType, rightRuntimeTag, rightBytes, rightStart);
        case ARRAY:
            return compareArrays(leftType, leftRuntimeTag, leftBytes, leftStart, rightType, rightRuntimeTag, rightBytes, rightStart);
        case OBJECT:
            // equality is the only operation defined for records
            if (!isEquality) {
                return Result.NULL;
            }
            return compareRecords(leftType, leftBytes, leftStart, leftLen, rightType, rightBytes, rightStart, rightLen);
        default:
            return Result.NULL;
    }
}
#method_after
private Result compareComplex(IAType leftType, ATypeTag leftRuntimeTag, byte[] leftBytes, int leftStart, int leftLen, IAType rightType, ATypeTag rightRuntimeTag, byte[] rightBytes, int rightStart, int rightLen) throws HyracksDataException {
    if (leftRuntimeTag != rightRuntimeTag) {
        return Result.INCOMPARABLE;
    }
    switch(leftRuntimeTag) {
        case MULTISET:
            return compareMultisets(leftType, leftRuntimeTag, leftBytes, leftStart, rightType, rightRuntimeTag, rightBytes, rightStart);
        case ARRAY:
            return compareArrays(leftType, leftRuntimeTag, leftBytes, leftStart, rightType, rightRuntimeTag, rightBytes, rightStart);
        case OBJECT:
            return compareRecords(leftType, leftBytes, leftStart, leftLen, rightType, rightBytes, rightStart, rightLen);
        default:
            return Result.NULL;
    }
}
#end_block

#method_before
private Result compareArrays(IAType leftType, ATypeTag leftListTag, byte[] leftBytes, int leftStart, IAType rightType, ATypeTag rightListTag, byte[] rightBytes, int rightStart) throws HyracksDataException {
    // reaching here, both left and right have to be arrays (should be enforced)
    int leftNumItems = ListAccessorUtil.numberOfItems(leftBytes, leftStart);
    int rightNumItems = ListAccessorUtil.numberOfItems(rightBytes, rightStart);
    // short-circuiting when comparison is for equality and the two arrays have different sizes
    if (isEquality && leftNumItems != rightNumItems) {
        return ILogicalBinaryComparator.asResult(Integer.compare(leftNumItems, rightNumItems));
    }
    IAType leftListCompileType = leftType;
    if (leftListCompileType.getTypeTag() == ATypeTag.ANY) {
        leftListCompileType = DefaultOpenFieldType.getDefaultOpenFieldType(leftListTag);
    }
    IAType rightListCompileType = rightType;
    if (rightListCompileType.getTypeTag() == ATypeTag.ANY) {
        rightListCompileType = DefaultOpenFieldType.getDefaultOpenFieldType(rightListTag);
    }
    IAType leftItemCompileType = ((AbstractCollectionType) leftListCompileType).getItemType();
    IAType rightItemCompileType = ((AbstractCollectionType) rightListCompileType).getItemType();
    ATypeTag leftItemTag = leftItemCompileType.getTypeTag();
    ATypeTag rightItemTag = rightItemCompileType.getTypeTag();
    // TODO(ali): could be optimized to not need pointable when changing comparator to be non-tagged & no visitable
    IPointable leftItem = voidPointableAllocator.allocate(null);
    IPointable rightItem = voidPointableAllocator.allocate(null);
    // TODO(ali): optimize to not need this storage, will require optimizing records comparison to not use visitable
    ArrayBackedValueStorage leftStorage = (ArrayBackedValueStorage) storageAllocator.allocate(null);
    ArrayBackedValueStorage rightStorage = (ArrayBackedValueStorage) storageAllocator.allocate(null);
    Result result;
    byte leftItemTagByte;
    byte rightItemTagByte;
    ATypeTag leftItemRuntimeTag;
    ATypeTag rightItemRuntimeTag;
    try {
        for (int i = 0; i < leftNumItems && i < rightNumItems; i++) {
            ListAccessorUtil.getOrWriteItem(leftBytes, leftStart, i, leftListTag, leftItemTag, leftItem, leftStorage);
            ListAccessorUtil.getOrWriteItem(rightBytes, rightStart, i, rightListTag, rightItemTag, rightItem, rightStorage);
            leftItemTagByte = leftItem.getByteArray()[leftItem.getStartOffset()];
            rightItemTagByte = rightItem.getByteArray()[rightItem.getStartOffset()];
            // if both tags are derived, get item type or default to open item if array is open, then call complex
            leftItemRuntimeTag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(leftItemTagByte);
            rightItemRuntimeTag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(rightItemTagByte);
            if (leftItemRuntimeTag.isDerivedType() && rightItemRuntimeTag.isDerivedType()) {
                result = compareComplex(leftItemCompileType, leftItemRuntimeTag, leftItem.getByteArray(), leftItem.getStartOffset(), leftItem.getLength(), rightItemCompileType, rightItemRuntimeTag, rightItem.getByteArray(), rightItem.getStartOffset(), rightItem.getLength());
            } else {
                result = scalarComparator.compare(leftItem.getByteArray(), leftItem.getStartOffset(), leftItem.getLength(), rightItem.getByteArray(), rightItem.getStartOffset(), rightItem.getLength());
            }
            if (result != Result.EQ) {
                return result;
            }
        }
        return ILogicalBinaryComparator.asResult(Integer.compare(leftNumItems, rightNumItems));
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    } finally {
        storageAllocator.markFree(rightStorage);
        storageAllocator.markFree(leftStorage);
        voidPointableAllocator.markFree(rightItem);
        voidPointableAllocator.markFree(leftItem);
    }
}
#method_after
private Result compareArrays(IAType leftType, ATypeTag leftListTag, byte[] leftBytes, int leftStart, IAType rightType, ATypeTag rightListTag, byte[] rightBytes, int rightStart) throws HyracksDataException {
    // reaching here, both left and right have to be arrays (should be enforced)
    int leftNumItems = ListAccessorUtil.numberOfItems(leftBytes, leftStart);
    int rightNumItems = ListAccessorUtil.numberOfItems(rightBytes, rightStart);
    IAType leftListCompileType = TypeComputeUtils.getActualType(leftType);
    if (leftListCompileType.getTypeTag() == ATypeTag.ANY) {
        leftListCompileType = DefaultOpenFieldType.getDefaultOpenFieldType(leftListTag);
    }
    IAType rightListCompileType = TypeComputeUtils.getActualType(rightType);
    if (rightListCompileType.getTypeTag() == ATypeTag.ANY) {
        rightListCompileType = DefaultOpenFieldType.getDefaultOpenFieldType(rightListTag);
    }
    IAType leftItemCompileType = ((AbstractCollectionType) leftListCompileType).getItemType();
    IAType rightItemCompileType = ((AbstractCollectionType) rightListCompileType).getItemType();
    ATypeTag leftItemTag = leftItemCompileType.getTypeTag();
    ATypeTag rightItemTag = rightItemCompileType.getTypeTag();
    // TODO(ali): could be optimized to not need pointable when changing comparator to be non-tagged & no visitable
    IPointable leftItem = voidPointableAllocator.allocate(null);
    IPointable rightItem = voidPointableAllocator.allocate(null);
    // TODO(ali): optimize to not need this storage, will require optimizing records comparison to not use visitable
    ArrayBackedValueStorage leftStorage = (ArrayBackedValueStorage) storageAllocator.allocate(null);
    ArrayBackedValueStorage rightStorage = (ArrayBackedValueStorage) storageAllocator.allocate(null);
    Result unknownResult = null;
    Result determiningResult = null;
    Result tempResult;
    byte leftItemTagByte;
    byte rightItemTagByte;
    ATypeTag leftItemRuntimeTag;
    ATypeTag rightItemRuntimeTag;
    try {
        for (int i = 0; i < leftNumItems && i < rightNumItems; i++) {
            ListAccessorUtil.getItem(leftBytes, leftStart, i, leftListTag, leftItemTag, leftItem, leftStorage);
            ListAccessorUtil.getItem(rightBytes, rightStart, i, rightListTag, rightItemTag, rightItem, rightStorage);
            leftItemTagByte = leftItem.getByteArray()[leftItem.getStartOffset()];
            rightItemTagByte = rightItem.getByteArray()[rightItem.getStartOffset()];
            // if both tags are derived, get item type or default to open item if array is open, then call complex
            leftItemRuntimeTag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(leftItemTagByte);
            rightItemRuntimeTag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(rightItemTagByte);
            if (leftItemRuntimeTag.isDerivedType() && rightItemRuntimeTag.isDerivedType()) {
                tempResult = compareComplex(leftItemCompileType, leftItemRuntimeTag, leftItem.getByteArray(), leftItem.getStartOffset(), leftItem.getLength(), rightItemCompileType, rightItemRuntimeTag, rightItem.getByteArray(), rightItem.getStartOffset(), rightItem.getLength());
            } else {
                tempResult = scalarComparator.compare(leftItem.getByteArray(), leftItem.getStartOffset(), leftItem.getLength(), rightItem.getByteArray(), rightItem.getStartOffset(), rightItem.getLength());
            }
            if (tempResult == Result.INCOMPARABLE) {
                return tempResult;
            }
            // skip to next pair if current one is equal or the result of the comparison has already been decided
            if (tempResult != Result.EQ && determiningResult == null) {
                // tempResult = NULL, MISSING, LT, GT
                if ((tempResult == Result.NULL || tempResult == Result.MISSING)) {
                    // keep unknown response if there is no yet a determining result switching to missing if found
                    if (unknownResult != Result.MISSING) {
                        unknownResult = tempResult;
                    }
                } else {
                    // tempResult = LT, GT
                    determiningResult = tempResult;
                }
            }
        }
        // reaching here means the two arrays are comparable
        if (isEquality && leftNumItems != rightNumItems) {
            return ILogicalBinaryComparator.asResult(Integer.compare(leftNumItems, rightNumItems));
        }
        // for >, < make unknownResult the determiningResult if unknownResult was encountered before finding one
        if (!isEquality && unknownResult != null) {
            determiningResult = unknownResult;
        }
        if (determiningResult != null) {
            return determiningResult;
        }
        if (unknownResult != null) {
            return unknownResult;
        }
        return ILogicalBinaryComparator.asResult(Integer.compare(leftNumItems, rightNumItems));
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    } finally {
        storageAllocator.free(rightStorage);
        storageAllocator.free(leftStorage);
        voidPointableAllocator.free(rightItem);
        voidPointableAllocator.free(leftItem);
    }
}
#end_block

#method_before
private Result compareMultisets(IAType leftType, ATypeTag leftListTag, byte[] leftBytes, int leftStart, IAType rightType, ATypeTag rightListTag, byte[] rightBytes, int rightStart) throws HyracksDataException {
    // TODO(ali): multiset comparison logic here
    return Result.NULL;
}
#method_after
private Result compareMultisets(IAType leftType, ATypeTag leftListTag, byte[] leftBytes, int leftStart, IAType rightType, ATypeTag rightListTag, byte[] rightBytes, int rightStart) throws HyracksDataException {
    // equality is the only operation defined for multiset
    if (!isEquality) {
        return Result.INCOMPARABLE;
    }
    return Result.NULL;
}
#end_block

#method_before
private Result compareRecords(IAType leftType, byte[] leftBytes, int leftStart, int leftLen, IAType rightType, byte[] rightBytes, int rightStart, int rightLen) {
    // TODO(ali): record comparison logic here
    return Result.NULL;
}
#method_after
private Result compareRecords(IAType leftType, byte[] leftBytes, int leftStart, int leftLen, IAType rightType, byte[] rightBytes, int rightStart, int rightLen) {
    // equality is the only operation defined for records
    if (!isEquality) {
        return Result.INCOMPARABLE;
    }
    return Result.NULL;
}
#end_block

#method_before
public HyracksNCServiceProcess addNCService(File configFile, File logFile) throws IOException {
    HyracksNCServiceProcess proc = new HyracksNCServiceProcess(configFile, logFile, appHome, workingDir);
    proc.start();
    ncProcs.add(proc);
    return proc;
}
#method_after
public HyracksNCServiceProcess addNCService(File configFile, File logFile, File log4jConfig) throws IOException {
    HyracksNCServiceProcess proc = new HyracksNCServiceProcess(configFile, logFile, appHome, workingDir, log4jConfig);
    proc.start();
    ncProcs.add(proc);
    return proc;
}
#end_block

#method_before
public HyracksCCProcess start(File ccConfigFile, File logFile) throws IOException {
    ccProc = new HyracksCCProcess(ccConfigFile, logFile, appHome, workingDir);
    ccProc.start();
    return ccProc;
}
#method_after
public HyracksCCProcess start(File ccConfigFile, File logFile, File log4jConfig) throws IOException {
    ccProc = new HyracksCCProcess(ccConfigFile, logFile, appHome, workingDir, log4jConfig);
    ccProc.start();
    return ccProc;
}
#end_block

#method_before
@BeforeClass
public static void setUp() throws Exception {
    cluster = new HyracksVirtualCluster(new File(APP_HOME), null);
    File tempConf = new File(TARGET_DIR, "cc.conf");
    FileUtils.copyFile(new File(RESOURCE_DIR, "cc.conf"), tempConf);
    Files.write(tempConf.toPath(), ("log.dir: " + LOG_DIR).getBytes(), StandardOpenOption.APPEND);
    String log4jPath = "-Dlog4j.configurationFile=" + FileUtil.joinPath(".", "src", "test", "resources", "log4j2-hyracks-test.xml");
    HyracksNCServiceProcess red = cluster.addNCService(new File(RESOURCE_DIR, "nc-red.conf"), new File(LOG_DIR, "nc-red.log"));
    red.addArg(log4jPath);
    HyracksNCServiceProcess blue = cluster.addNCService(new File(RESOURCE_DIR, "nc-blue.conf"), new File(LOG_DIR, "nc-blue.log"));
    blue.addArg(log4jPath);
    try {
        Thread.sleep(2000);
    } catch (InterruptedException ignored) {
    }
    // Start CC
    HyracksCCProcess cc = cluster.init(new File(TARGET_DIR, "cc.conf"), new File(LOG_DIR, "cc.log"));
    cc.addArg(log4jPath);
    cc.start();
    try {
        Thread.sleep(10000);
    } catch (InterruptedException ignored) {
    }
}
#method_after
@BeforeClass
public static void setUp() throws Exception {
    cluster = new HyracksVirtualCluster(new File(APP_HOME), null);
    File tempConf = new File(TARGET_DIR, "cc.conf");
    FileUtils.copyFile(new File(RESOURCE_DIR, "cc.conf"), tempConf);
    Files.write(tempConf.toPath(), ("log.dir: " + LOG_DIR).getBytes(), StandardOpenOption.APPEND);
    File log4jPath = new File(FileUtil.joinPath("..", "..", "src", "test", "resources", "log4j2-hyracks-test.xml"));
    cluster.addNCService(new File(RESOURCE_DIR, "nc-red.conf"), new File(LOG_DIR, "nc-red.log"), log4jPath);
    cluster.addNCService(new File(RESOURCE_DIR, "nc-blue.conf"), new File(LOG_DIR, "nc-blue.log"), log4jPath);
    try {
        Thread.sleep(2000);
    } catch (InterruptedException ignored) {
    }
    // Start CC
    cluster.start(tempConf, new File(LOG_DIR, "cc.log"), log4jPath);
    try {
        Thread.sleep(10000);
    } catch (InterruptedException ignored) {
    }
}
#end_block

#method_before
public Configuration createConfiguration(ConfigurationBuilder<BuiltConfiguration> builder) {
    String nodeId = config.getNodeId();
    String logDir = config.getLogDir();
    builder.setStatusLevel(Level.WARN);
    builder.setConfigurationName("RollingBuilder");
    // create a rolling file appender
    LayoutComponentBuilder defaultLayout = builder.newLayout("PatternLayout").addAttribute("pattern", "%d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n");
    ComponentBuilder triggeringPolicy = builder.newComponent("Policies").addComponent(builder.newComponent("CronTriggeringPolicy").addAttribute("schedule", "0 0 0 * * ?")).addComponent(builder.newComponent("SizeBasedTriggeringPolicy").addAttribute("size", "50M"));
    AppenderComponentBuilder defaultRoll = builder.newAppender("default", "RollingFile").addAttribute("fileName", new File(logDir, "nc-" + nodeId + ".log").getAbsolutePath()).addAttribute("filePattern", logDir + "nc-" + nodeId + "-%d{MM-dd-yy}.log.gz").add(defaultLayout).addComponent(triggeringPolicy);
    builder.add(defaultRoll);
    // create the new logger
    builder.add(builder.newRootLogger(Level.INFO).add(builder.newAppenderRef("default")));
    LayoutComponentBuilder accessLayout = builder.newLayout("PatternLayout").addAttribute("pattern", "%m%n");
    AppenderComponentBuilder accessRoll = builder.newAppender("access", "RollingFile").addAttribute("fileName", logDir + "access-" + nodeId + ".log").addAttribute("filePattern", new File(logDir, "access-" + nodeId + "-%d{MM-dd-yy}.log.gz").getAbsolutePath()).add(accessLayout).addComponent(triggeringPolicy);
    builder.add(accessRoll);
    builder.add(builder.newLogger("org.apache.hyracks.http.server.CLFLogger", Level.forName("ACCESS", 550)).add(builder.newAppenderRef("access")).addAttribute("additivity", false));
    return builder.build();
}
#method_after
public Configuration createConfiguration(ConfigurationBuilder<BuiltConfiguration> builder) {
    String nodeId = config.getNodeId();
    File logDir = new File(config.getLogDir());
    builder.setStatusLevel(Level.WARN);
    builder.setConfigurationName("RollingBuilder");
    // create a rolling file appender
    LayoutComponentBuilder defaultLayout = builder.newLayout("PatternLayout").addAttribute("pattern", "%d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n");
    ComponentBuilder triggeringPolicy = builder.newComponent("Policies").addComponent(builder.newComponent("CronTriggeringPolicy").addAttribute("schedule", "0 0 0 * * ?")).addComponent(builder.newComponent("SizeBasedTriggeringPolicy").addAttribute("size", "50M"));
    AppenderComponentBuilder defaultRoll = builder.newAppender("default", "RollingFile").addAttribute("fileName", new File(logDir, "nc-" + nodeId + ".log").getAbsolutePath()).addAttribute("filePattern", new File(logDir, "nc-" + nodeId + "-%d{MM-dd-yy}.log.gz").getAbsolutePath()).add(defaultLayout).addComponent(triggeringPolicy);
    builder.add(defaultRoll);
    // create the new logger
    builder.add(builder.newRootLogger(Level.INFO).add(builder.newAppenderRef("default")));
    LayoutComponentBuilder accessLayout = builder.newLayout("PatternLayout").addAttribute("pattern", "%m%n");
    AppenderComponentBuilder accessRoll = builder.newAppender("access", "RollingFile").addAttribute("fileName", new File(logDir, "access-" + nodeId + ".log").getAbsolutePath()).addAttribute("filePattern", new File(logDir, "access-" + nodeId + "-%d{MM-dd-yy}.log.gz").getAbsolutePath()).add(accessLayout).addComponent(triggeringPolicy);
    builder.add(accessRoll);
    builder.add(builder.newLogger("org.apache.hyracks.http.server.CLFLogger", Level.forName("ACCESS", 550)).add(builder.newAppenderRef("access")).addAttribute("additivity", false));
    return builder.build();
}
#end_block

#method_before
public static <T> T retryUntilSuccessOrExhausted(Span span, ComputingAction<T> action, IRetryPolicy policy, IDelay delay, IFailedAttemptCallback onFailure) throws HyracksDataException {
    Throwable failure;
    int attempt = 0;
    while (true) {
        attempt++;
        try {
            return action.compute();
        } catch (Throwable th) {
            failure = th;
            try {
                long delayMs = delay.calculate(attempt);
                if (!policy.retry(th) || span.remaining(TimeUnit.MILLISECONDS) < delayMs) {
                    onFailure.onFailedAttempt(action, attempt, true, span, failure);
                    throw HyracksDataException.create(failure);
                } else {
                    onFailure.onFailedAttempt(action, attempt, false, span, failure);
                }
                span.sleep(delayMs, TimeUnit.MILLISECONDS);
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
                throw HyracksDataException.create(e);
            }
        }
    }
}
#method_after
public static <T> T retryUntilSuccessOrExhausted(Span span, ComputingAction<T> action, IRetryPolicy policy, IDelay delay, IFailedAttemptCallback onFailure) throws HyracksDataException {
    Throwable failure;
    int attempt = 0;
    while (true) {
        attempt++;
        try {
            return action.compute();
        } catch (Throwable th) {
            failure = th;
            try {
                long delayMs = delay.calculate(attempt);
                if (!policy.retry(th) || span.remaining(TimeUnit.MILLISECONDS) < delayMs) {
                    onFailure.attemptFailed(action, attempt, true, span, failure);
                    throw HyracksDataException.create(failure);
                } else {
                    onFailure.attemptFailed(action, attempt, false, span, failure);
                }
                span.sleep(delayMs, TimeUnit.MILLISECONDS);
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
                throw HyracksDataException.create(e);
            }
        }
    }
}
#end_block

#method_before
private static void createAndRunJob(IHyracksClientConnection hcc, EnumSet<JobFlag> jobFlags, Mutable<JobId> jId, IStatementCompiler compiler, IMetadataLocker locker, ResultDelivery resultDelivery, IResultPrinter printer, IRequestParameters requestParameters, boolean cancellable, ICcApplicationContext appCtx, MetadataProvider metadataProvider) throws Exception {
    final IRequestTracker requestTracker = appCtx.getRequestTracker();
    final ClientRequest clientRequest = (ClientRequest) requestTracker.get(requestParameters.getRequestReference().getUuid());
    locker.lock();
    try {
        final JobSpecification jobSpec = compiler.compile();
        if (jobSpec == null) {
            return;
        }
        final ClientRequestRequirements requestRequirements = ClientRequestRequirements.of(clientRequest, requestParameters, metadataProvider, jobSpec);
        appCtx.getReceptionist().ensureRequirements(requestRequirements);
        final JobId jobId = JobUtils.runJob(hcc, jobSpec, jobFlags, false);
        clientRequest.setJobId(jobId);
        if (cancellable) {
            clientRequest.markCancellable();
        }
        if (jId != null) {
            jId.setValue(jobId);
        }
        if (ResultDelivery.ASYNC == resultDelivery) {
            printer.print(jobId);
            hcc.waitForCompletion(jobId);
        } else {
            hcc.waitForCompletion(jobId);
            printer.print(jobId);
        }
    } finally {
        // complete async jobs after their job completes
        if (ResultDelivery.ASYNC == resultDelivery) {
            requestTracker.complete(clientRequest.getId());
        }
        locker.unlock();
    }
}
#method_after
private static void createAndRunJob(IHyracksClientConnection hcc, EnumSet<JobFlag> jobFlags, Mutable<JobId> jId, IStatementCompiler compiler, IMetadataLocker locker, ResultDelivery resultDelivery, IResultPrinter printer, IRequestParameters requestParameters, boolean cancellable, ICcApplicationContext appCtx, MetadataProvider metadataProvider) throws Exception {
    final IRequestTracker requestTracker = appCtx.getRequestTracker();
    final ClientRequest clientRequest = (ClientRequest) requestTracker.get(requestParameters.getRequestReference().getUuid());
    locker.lock();
    try {
        final JobSpecification jobSpec = compiler.compile();
        if (jobSpec == null) {
            return;
        }
        if (cancellable) {
            clientRequest.markCancellable();
        }
        final SchedulableClientRequest schedulableRequest = SchedulableClientRequest.of(clientRequest, requestParameters, metadataProvider, jobSpec);
        appCtx.getReceptionist().ensureSchedulable(schedulableRequest);
        final JobId jobId = JobUtils.runJob(hcc, jobSpec, jobFlags, false);
        clientRequest.setJobId(jobId);
        if (jId != null) {
            jId.setValue(jobId);
        }
        if (ResultDelivery.ASYNC == resultDelivery) {
            printer.print(jobId);
            hcc.waitForCompletion(jobId);
        } else {
            hcc.waitForCompletion(jobId);
            printer.print(jobId);
        }
    } catch (InterruptedException e) {
        Thread.currentThread().interrupt();
        throw new RuntimeDataException(ErrorCode.REQUEST_CANCELLED, clientRequest.getId());
    } finally {
        // complete async jobs after their job completes
        if (ResultDelivery.ASYNC == resultDelivery) {
            requestTracker.complete(clientRequest.getId());
        }
        locker.unlock();
    }
}
#end_block

#method_before
@Override
public void handle(ICcApplicationContext appCtx) throws HyracksDataException, InterruptedException {
    final IRequestTracker requestTracker = appCtx.getRequestTracker();
    IClientRequest req = requestTracker.getByClientContextId(contextId);
    RequestStatus status;
    if (req == null) {
        LOGGER.log(Level.WARN, "No job found for context id " + contextId);
        status = RequestStatus.NOT_FOUND;
    } else {
        try {
            requestTracker.cancel(req.getId());
            status = RequestStatus.SUCCESS;
        } catch (Exception e) {
            LOGGER.log(Level.WARN, "unexpected exception thrown from cancel", e);
            status = RequestStatus.FAILED;
        }
    }
    CancelQueryResponse response = new CancelQueryResponse(reqId, status);
    CCMessageBroker messageBroker = (CCMessageBroker) appCtx.getServiceContext().getMessageBroker();
    try {
        messageBroker.sendApplicationMessageToNC(response, nodeId);
    } catch (Exception e) {
        LOGGER.log(Level.WARN, "Failure sending response to nc", e);
    }
}
#method_after
@Override
public void handle(ICcApplicationContext appCtx) throws HyracksDataException, InterruptedException {
    final IRequestTracker requestTracker = appCtx.getRequestTracker();
    IClientRequest req = requestTracker.getByClientContextId(contextId);
    RequestStatus status;
    if (req == null) {
        LOGGER.log(Level.WARN, "No job found for context id " + contextId);
        status = RequestStatus.NOT_FOUND;
    } else {
        if (!req.isCancellable()) {
            status = RequestStatus.REJECTED;
        } else {
            try {
                requestTracker.cancel(req.getId());
                status = RequestStatus.SUCCESS;
            } catch (Exception e) {
                LOGGER.log(Level.WARN, "unexpected exception thrown from cancel", e);
                status = RequestStatus.FAILED;
            }
        }
    }
    CancelQueryResponse response = new CancelQueryResponse(reqId, status);
    CCMessageBroker messageBroker = (CCMessageBroker) appCtx.getServiceContext().getMessageBroker();
    try {
        messageBroker.sendApplicationMessageToNC(response, nodeId);
    } catch (Exception e) {
        LOGGER.log(Level.WARN, "Failure sending response to nc", e);
    }
}
#end_block

#method_before
public void compile(boolean optimize, boolean printRewrittenExpressions, boolean printLogicalPlan, boolean printOptimizedPlan, boolean printPhysicalOpsOnly, boolean generateBinaryRuntime, boolean printJob, PlanFormat pformat) throws Exception {
    queryJobSpec = null;
    dmlJobs = null;
    if (queryText == null) {
        return;
    }
    int ch;
    StringBuilder builder = new StringBuilder();
    while ((ch = queryText.read()) != -1) {
        builder.append((char) ch);
    }
    String statement = builder.toString();
    IParser parser = parserFactory.createParser(statement);
    List<Statement> statements = parser.parse();
    MetadataManager.INSTANCE.init();
    SessionConfig conf = new SessionConfig(OutputFormat.ADM, optimize, true, generateBinaryRuntime, pformat);
    conf.setOOBData(false, printRewrittenExpressions, printLogicalPlan, printOptimizedPlan, printJob);
    if (printPhysicalOpsOnly) {
        conf.set(SessionConfig.FORMAT_ONLY_PHYSICAL_OPS, true);
    }
    SessionOutput output = new SessionOutput(conf, writer);
    IStatementExecutor translator = statementExecutorFactory.create(appCtx, statements, output, compilationProvider, storageComponentProvider);
    final IRequestParameters requestParameters = new RequestParameters(null, statement, null, new ResultProperties(IStatementExecutor.ResultDelivery.IMMEDIATE), new IStatementExecutor.Stats(), null, null, null, statementParams, true);
    translator.compileAndExecute(hcc, requestParameters);
    writer.flush();
}
#method_after
public void compile(boolean optimize, boolean printRewrittenExpressions, boolean printLogicalPlan, boolean printOptimizedPlan, boolean printPhysicalOpsOnly, boolean generateBinaryRuntime, boolean printJob, PlanFormat pformat) throws Exception {
    queryJobSpec = null;
    dmlJobs = null;
    if (queryText == null) {
        return;
    }
    int ch;
    StringBuilder builder = new StringBuilder();
    while ((ch = queryText.read()) != -1) {
        builder.append((char) ch);
    }
    String statement = builder.toString();
    IParser parser = parserFactory.createParser(statement);
    List<Statement> statements = parser.parse();
    MetadataManager.INSTANCE.init();
    SessionConfig conf = new SessionConfig(OutputFormat.ADM, optimize, true, generateBinaryRuntime, pformat);
    conf.setOOBData(false, printRewrittenExpressions, printLogicalPlan, printOptimizedPlan, printJob);
    if (printPhysicalOpsOnly) {
        conf.set(SessionConfig.FORMAT_ONLY_PHYSICAL_OPS, true);
    }
    SessionOutput output = new SessionOutput(conf, writer);
    IStatementExecutor translator = statementExecutorFactory.create(appCtx, statements, output, compilationProvider, storageComponentProvider);
    final RequestReference requestReference = RequestReference.of(UUID.randomUUID().toString(), "CC", System.currentTimeMillis());
    final IRequestParameters requestParameters = new RequestParameters(requestReference, statement, null, new ResultProperties(IStatementExecutor.ResultDelivery.IMMEDIATE), new IStatementExecutor.Stats(), null, null, null, statementParams, true);
    translator.compileAndExecute(hcc, requestParameters);
    writer.flush();
}
#end_block

#method_before
protected void setJsonOptionalParameters(JsonNode jsonRequest, Map<String, String> optionalParameters) {
}
#method_after
protected void setJsonOptionalParameters(JsonNode jsonRequest, Map<String, String> optionalParameters) {
// allows extensions to set extra parameters
}
#end_block

#method_before
private static void createAndRunJob(IHyracksClientConnection hcc, EnumSet<JobFlag> jobFlags, Mutable<JobId> jId, IStatementCompiler compiler, IMetadataLocker locker, ResultDelivery resultDelivery, IResultPrinter printer, IRequestParameters requestParameters, boolean cancellable, ICcApplicationContext appCtx) throws Exception {
    final IRequestTracker requestTracker = appCtx.getRequestTracker();
    final ClientRequest clientRequest = (ClientRequest) requestTracker.get(requestParameters.getRequestReference().getUuid());
    if (cancellable) {
        clientRequest.markCancellable();
    }
    locker.lock();
    try {
        final JobSpecification jobSpec = compiler.compile();
        if (jobSpec == null) {
            return;
        }
        final JobId jobId = JobUtils.runJob(hcc, jobSpec, jobFlags, false);
        clientRequest.setJobId(jobId);
        if (jId != null) {
            jId.setValue(jobId);
        }
        if (ResultDelivery.ASYNC == resultDelivery) {
            printer.print(jobId);
            hcc.waitForCompletion(jobId);
        } else {
            hcc.waitForCompletion(jobId);
            printer.print(jobId);
        }
    } finally {
        // complete async jobs after their job completes
        if (ResultDelivery.ASYNC == resultDelivery) {
            requestTracker.complete(clientRequest.getId());
        }
        locker.unlock();
    }
}
#method_after
private static void createAndRunJob(IHyracksClientConnection hcc, EnumSet<JobFlag> jobFlags, Mutable<JobId> jId, IStatementCompiler compiler, IMetadataLocker locker, ResultDelivery resultDelivery, IResultPrinter printer, IRequestParameters requestParameters, boolean cancellable, ICcApplicationContext appCtx) throws Exception {
    final IRequestTracker requestTracker = appCtx.getRequestTracker();
    final ClientRequest clientRequest = (ClientRequest) requestTracker.get(requestParameters.getRequestReference().getUuid());
    locker.lock();
    try {
        final JobSpecification jobSpec = compiler.compile();
        if (jobSpec == null) {
            return;
        }
        final JobId jobId = JobUtils.runJob(hcc, jobSpec, jobFlags, false);
        clientRequest.setJobId(jobId);
        if (cancellable) {
            clientRequest.markCancellable();
        }
        if (jId != null) {
            jId.setValue(jobId);
        }
        if (ResultDelivery.ASYNC == resultDelivery) {
            printer.print(jobId);
            hcc.waitForCompletion(jobId);
        } else {
            hcc.waitForCompletion(jobId);
            printer.print(jobId);
        }
    } finally {
        // complete async jobs after their job completes
        if (ResultDelivery.ASYNC == resultDelivery) {
            requestTracker.complete(clientRequest.getId());
        }
        locker.unlock();
    }
}
#end_block

#method_before
@Override
protected void delete(IServletRequest request, IServletResponse response) throws IOException {
    String clientContextId = request.getParameter(Parameter.CLIENT_ID.str());
    if (clientContextId == null) {
        response.setStatus(HttpResponseStatus.BAD_REQUEST);
        return;
    }
    final IRequestTracker requestTracker = appCtx.getRequestTracker();
    final IClientRequest req = requestTracker.getByClientContextId(clientContextId);
    if (req == null) {
        // response: NOT FOUND
        response.setStatus(HttpResponseStatus.NOT_FOUND);
        return;
    }
    try {
        // Cancels the on-going job.
        req.cancel(appCtx);
        // response: OK
        response.setStatus(HttpResponseStatus.OK);
    } catch (Exception e) {
        LOGGER.log(Level.WARN, "unexpected exception thrown from cancel", e);
        // response: INTERNAL SERVER ERROR
        response.setStatus(HttpResponseStatus.INTERNAL_SERVER_ERROR);
    }
}
#method_after
@Override
protected void delete(IServletRequest request, IServletResponse response) throws IOException {
    String clientContextId = request.getParameter(Parameter.CLIENT_ID.str());
    if (clientContextId == null) {
        response.setStatus(HttpResponseStatus.BAD_REQUEST);
        return;
    }
    final IRequestTracker requestTracker = appCtx.getRequestTracker();
    final IClientRequest req = requestTracker.getByClientContextId(clientContextId);
    if (req == null) {
        // response: NOT FOUND
        response.setStatus(HttpResponseStatus.NOT_FOUND);
        return;
    }
    if (!req.isCancellable()) {
        response.setStatus(HttpResponseStatus.FORBIDDEN);
        return;
    }
    try {
        // Cancels the on-going job.
        requestTracker.cancel(req.getId());
        // response: OK
        response.setStatus(HttpResponseStatus.OK);
    } catch (Exception e) {
        LOGGER.log(Level.WARN, "unexpected exception thrown from cancel", e);
        // response: INTERNAL SERVER ERROR
        response.setStatus(HttpResponseStatus.INTERNAL_SERVER_ERROR);
    }
}
#end_block

#method_before
private static WindowPOperator createWindowPOperator(WindowOperator winOp) throws CompilationException {
    List<Mutable<ILogicalExpression>> partitionExprs = winOp.getPartitionExpressions();
    List<LogicalVariable> partitionColumns = new ArrayList<>(partitionExprs.size());
    for (Mutable<ILogicalExpression> pe : partitionExprs) {
        ILogicalExpression partExpr = pe.getValue();
        if (partExpr.getExpressionTag() != LogicalExpressionTag.VARIABLE) {
            throw new CompilationException(ErrorCode.COMPILATION_ILLEGAL_STATE, winOp.getSourceLocation(), "Window partition/order expression has not been normalized");
        }
        LogicalVariable var = ((VariableReferenceExpression) partExpr).getVariableReference();
        partitionColumns.add(var);
    }
    List<Pair<OrderOperator.IOrder, Mutable<ILogicalExpression>>> orderExprs = winOp.getOrderExpressions();
    List<OrderColumn> orderColumns = new ArrayList<>(orderExprs.size());
    for (Pair<OrderOperator.IOrder, Mutable<ILogicalExpression>> p : orderExprs) {
        ILogicalExpression orderExpr = p.second.getValue();
        if (orderExpr.getExpressionTag() != LogicalExpressionTag.VARIABLE) {
            throw new CompilationException(ErrorCode.COMPILATION_ILLEGAL_STATE, winOp.getSourceLocation(), "Window partition/order expression has not been normalized");
        }
        LogicalVariable var = ((VariableReferenceExpression) orderExpr).getVariableReference();
        orderColumns.add(new OrderColumn(var, p.first.getKind()));
    }
    boolean partitionMaterialization = winOp.hasNestedPlans() || AnalysisUtil.hasFunctionWithProperty(winOp, BuiltinFunctions.WindowFunctionProperty.MATERIALIZE_PARTITION);
    boolean frameStartIsMonotonic = AnalysisUtil.isWindowFrameBoundaryMonotonic(winOp.getFrameStartExpressions(), winOp.getFrameValueExpressions());
    boolean frameEndIsMonotonic = AnalysisUtil.isWindowFrameBoundaryMonotonic(winOp.getFrameEndExpressions(), winOp.getFrameValueExpressions());
    boolean nestedAggregates = false;
    if (winOp.hasNestedPlans()) {
        Set<LogicalOperatorTag> roots = OperatorPropertiesUtil.getRootOperatorTags(winOp.getNestedPlans());
        nestedAggregates = roots.size() == 1 && roots.contains(LogicalOperatorTag.AGGREGATE);
    }
    return new WindowPOperator(partitionColumns, partitionMaterialization, orderColumns, frameStartIsMonotonic, frameEndIsMonotonic, nestedAggregates);
}
#method_after
private static WindowPOperator createWindowPOperator(WindowOperator winOp) throws CompilationException {
    List<Mutable<ILogicalExpression>> partitionExprs = winOp.getPartitionExpressions();
    List<LogicalVariable> partitionColumns = new ArrayList<>(partitionExprs.size());
    for (Mutable<ILogicalExpression> pe : partitionExprs) {
        ILogicalExpression partExpr = pe.getValue();
        if (partExpr.getExpressionTag() != LogicalExpressionTag.VARIABLE) {
            throw new CompilationException(ErrorCode.COMPILATION_ILLEGAL_STATE, winOp.getSourceLocation(), "Window partition/order expression has not been normalized");
        }
        LogicalVariable var = ((VariableReferenceExpression) partExpr).getVariableReference();
        partitionColumns.add(var);
    }
    List<Pair<OrderOperator.IOrder, Mutable<ILogicalExpression>>> orderExprs = winOp.getOrderExpressions();
    List<OrderColumn> orderColumns = new ArrayList<>(orderExprs.size());
    for (Pair<OrderOperator.IOrder, Mutable<ILogicalExpression>> p : orderExprs) {
        ILogicalExpression orderExpr = p.second.getValue();
        if (orderExpr.getExpressionTag() != LogicalExpressionTag.VARIABLE) {
            throw new CompilationException(ErrorCode.COMPILATION_ILLEGAL_STATE, winOp.getSourceLocation(), "Window partition/order expression has not been normalized");
        }
        LogicalVariable var = ((VariableReferenceExpression) orderExpr).getVariableReference();
        orderColumns.add(new OrderColumn(var, p.first.getKind()));
    }
    boolean partitionMaterialization = winOp.hasNestedPlans() || AnalysisUtil.hasFunctionWithProperty(winOp, BuiltinFunctions.WindowFunctionProperty.MATERIALIZE_PARTITION);
    boolean frameStartIsMonotonic = AnalysisUtil.isWindowFrameBoundaryMonotonic(winOp.getFrameStartExpressions(), winOp.getFrameValueExpressions());
    boolean frameEndIsMonotonic = AnalysisUtil.isWindowFrameBoundaryMonotonic(winOp.getFrameEndExpressions(), winOp.getFrameValueExpressions());
    boolean nestedTrivialAggregates = winOp.hasNestedPlans() && winOp.getNestedPlans().stream().allMatch(AnalysisUtil::isTrivialAggregateSubplan);
    return new WindowPOperator(partitionColumns, partitionMaterialization, orderColumns, frameStartIsMonotonic, frameEndIsMonotonic, nestedTrivialAggregates);
}
#end_block

#method_before
@Override
public void contributeRuntimeOperator(IHyracksJobBuilder builder, JobGenContext context, ILogicalOperator op, IOperatorSchema opSchema, IOperatorSchema[] inputSchemas, IOperatorSchema outerPlanSchema) throws AlgebricksException {
    WindowOperator winOp = (WindowOperator) op;
    int[] partitionColumnsList = JobGenHelper.projectVariables(inputSchemas[0], partitionColumns);
    IVariableTypeEnvironment opTypeEnv = context.getTypeEnvironment(op);
    IBinaryComparatorFactory[] partitionComparatorFactories = JobGenHelper.variablesToAscBinaryComparatorFactories(partitionColumns, opTypeEnv, context);
    // TODO not all functions need order comparators
    IBinaryComparatorFactory[] orderComparatorFactories = JobGenHelper.variablesToBinaryComparatorFactories(orderColumns, opTypeEnv, context);
    IVariableTypeEnvironment inputTypeEnv = context.getTypeEnvironment(op.getInputs().get(0).getValue());
    IExpressionRuntimeProvider exprRuntimeProvider = context.getExpressionRuntimeProvider();
    IBinaryComparatorFactoryProvider binaryComparatorFactoryProvider = context.getBinaryComparatorFactoryProvider();
    List<Mutable<ILogicalExpression>> frameStartExprList = winOp.getFrameStartExpressions();
    IScalarEvaluatorFactory[] frameStartExprEvals = createEvaluatorFactories(frameStartExprList, inputSchemas, inputTypeEnv, exprRuntimeProvider, context);
    List<Mutable<ILogicalExpression>> frameEndExprList = winOp.getFrameEndExpressions();
    IScalarEvaluatorFactory[] frameEndExprEvals = createEvaluatorFactories(frameEndExprList, inputSchemas, inputTypeEnv, exprRuntimeProvider, context);
    List<Pair<OrderOperator.IOrder, Mutable<ILogicalExpression>>> frameValueExprList = winOp.getFrameValueExpressions();
    Pair<IScalarEvaluatorFactory[], IBinaryComparatorFactory[]> frameValueExprEvalsAndComparators = createEvaluatorAndComparatorFactories(frameValueExprList, Pair::getSecond, Pair::getFirst, inputSchemas, inputTypeEnv, exprRuntimeProvider, binaryComparatorFactoryProvider, context);
    List<Mutable<ILogicalExpression>> frameExcludeExprList = winOp.getFrameExcludeExpressions();
    Pair<IScalarEvaluatorFactory[], IBinaryComparatorFactory[]> frameExcludeExprEvalsAndComparators = createEvaluatorAndComparatorFactories(frameExcludeExprList, v -> v, v -> OrderOperator.ASC_ORDER, inputSchemas, inputTypeEnv, exprRuntimeProvider, binaryComparatorFactoryProvider, context);
    IScalarEvaluatorFactory frameOffsetExprEval = null;
    ILogicalExpression frameOffsetExpr = winOp.getFrameOffset().getValue();
    if (frameOffsetExpr != null) {
        frameOffsetExprEval = exprRuntimeProvider.createEvaluatorFactory(frameOffsetExpr, inputTypeEnv, inputSchemas, context);
    }
    int[] projectionColumnsExcludingSubplans = JobGenHelper.projectAllVariables(opSchema);
    int[] runningAggOutColumns = JobGenHelper.projectVariables(opSchema, winOp.getVariables());
    List<Mutable<ILogicalExpression>> runningAggExprs = winOp.getExpressions();
    int runningAggExprCount = runningAggExprs.size();
    IRunningAggregateEvaluatorFactory[] runningAggFactories = new IRunningAggregateEvaluatorFactory[runningAggExprCount];
    for (int i = 0; i < runningAggExprCount; i++) {
        StatefulFunctionCallExpression expr = (StatefulFunctionCallExpression) runningAggExprs.get(i).getValue();
        runningAggFactories[i] = exprRuntimeProvider.createRunningAggregateFunctionFactory(expr, inputTypeEnv, inputSchemas, context);
    }
    AbstractWindowRuntimeFactory runtime = null;
    if (winOp.hasNestedPlans()) {
        int opSchemaSizePreSubplans = opSchema.getSize();
        AlgebricksPipeline[] subplans = compileSubplans(inputSchemas[0], winOp, opSchema, context);
        int aggregatorOutputSchemaSize = opSchema.getSize() - opSchemaSizePreSubplans;
        WindowAggregatorDescriptorFactory nestedAggFactory = new WindowAggregatorDescriptorFactory(subplans);
        nestedAggFactory.setSourceLocation(winOp.getSourceLocation());
        int frameMaxObjects = winOp.getFrameMaxObjects();
        // special cases
        if (frameStartExprList.isEmpty() && frameExcludeExprList.isEmpty() && frameOffsetExpr == null) {
            if (frameEndExprList.isEmpty()) {
                // special case #1: frame == whole partition, no exclusions, no offset
                runtime = new WindowNestedPlansUnboundedRuntimeFactory(partitionColumnsList, partitionComparatorFactories, orderComparatorFactories, frameMaxObjects, projectionColumnsExcludingSubplans, runningAggOutColumns, runningAggFactories, aggregatorOutputSchemaSize, nestedAggFactory);
            } else if (frameEndIsMonotonic && nestedAggregates) {
                // special case #2: accumulating frame from beginning of the partition, no exclusions, no offset
                nestedAggFactory.setPartialOutputEnabled(true);
                runtime = new WindowNestedPlansRunningRuntimeFactory(partitionColumnsList, partitionComparatorFactories, orderComparatorFactories, frameValueExprEvalsAndComparators.first, frameValueExprEvalsAndComparators.second, frameEndExprEvals, frameMaxObjects, projectionColumnsExcludingSubplans, runningAggOutColumns, runningAggFactories, aggregatorOutputSchemaSize, nestedAggFactory);
            }
        }
        // default case
        if (runtime == null) {
            runtime = new WindowNestedPlansRuntimeFactory(partitionColumnsList, partitionComparatorFactories, orderComparatorFactories, frameValueExprEvalsAndComparators.first, frameValueExprEvalsAndComparators.second, frameStartExprEvals, frameStartIsMonotonic, frameEndExprEvals, frameExcludeExprEvalsAndComparators.first, winOp.getFrameExcludeNegationStartIdx(), frameExcludeExprEvalsAndComparators.second, frameOffsetExprEval, context.getBinaryIntegerInspectorFactory(), frameMaxObjects, projectionColumnsExcludingSubplans, runningAggOutColumns, runningAggFactories, aggregatorOutputSchemaSize, nestedAggFactory);
        }
    } else if (partitionMaterialization) {
        runtime = new WindowMaterializingRuntimeFactory(partitionColumnsList, partitionComparatorFactories, orderComparatorFactories, projectionColumnsExcludingSubplans, runningAggOutColumns, runningAggFactories);
    } else {
        runtime = new WindowSimpleRuntimeFactory(partitionColumnsList, partitionComparatorFactories, orderComparatorFactories, projectionColumnsExcludingSubplans, runningAggOutColumns, runningAggFactories);
    }
    runtime.setSourceLocation(winOp.getSourceLocation());
    // contribute one Asterix framewriter
    RecordDescriptor recDesc = JobGenHelper.mkRecordDescriptor(opTypeEnv, opSchema, context);
    builder.contributeMicroOperator(winOp, runtime, recDesc);
    // and contribute one edge from its child
    ILogicalOperator src = winOp.getInputs().get(0).getValue();
    builder.contributeGraphEdge(src, 0, winOp, 0);
}
#method_after
@Override
public void contributeRuntimeOperator(IHyracksJobBuilder builder, JobGenContext context, ILogicalOperator op, IOperatorSchema opSchema, IOperatorSchema[] inputSchemas, IOperatorSchema outerPlanSchema) throws AlgebricksException {
    WindowOperator winOp = (WindowOperator) op;
    int[] partitionColumnsList = JobGenHelper.projectVariables(inputSchemas[0], partitionColumns);
    IVariableTypeEnvironment opTypeEnv = context.getTypeEnvironment(op);
    IBinaryComparatorFactory[] partitionComparatorFactories = JobGenHelper.variablesToAscBinaryComparatorFactories(partitionColumns, opTypeEnv, context);
    // TODO not all functions need order comparators
    IBinaryComparatorFactory[] orderComparatorFactories = JobGenHelper.variablesToBinaryComparatorFactories(orderColumns, opTypeEnv, context);
    IVariableTypeEnvironment inputTypeEnv = context.getTypeEnvironment(op.getInputs().get(0).getValue());
    IExpressionRuntimeProvider exprRuntimeProvider = context.getExpressionRuntimeProvider();
    IBinaryComparatorFactoryProvider binaryComparatorFactoryProvider = context.getBinaryComparatorFactoryProvider();
    List<Mutable<ILogicalExpression>> frameStartExprList = winOp.getFrameStartExpressions();
    IScalarEvaluatorFactory[] frameStartExprEvals = createEvaluatorFactories(frameStartExprList, inputSchemas, inputTypeEnv, exprRuntimeProvider, context);
    List<Mutable<ILogicalExpression>> frameEndExprList = winOp.getFrameEndExpressions();
    IScalarEvaluatorFactory[] frameEndExprEvals = createEvaluatorFactories(frameEndExprList, inputSchemas, inputTypeEnv, exprRuntimeProvider, context);
    List<Pair<OrderOperator.IOrder, Mutable<ILogicalExpression>>> frameValueExprList = winOp.getFrameValueExpressions();
    Pair<IScalarEvaluatorFactory[], IBinaryComparatorFactory[]> frameValueExprEvalsAndComparators = createEvaluatorAndComparatorFactories(frameValueExprList, Pair::getSecond, Pair::getFirst, inputSchemas, inputTypeEnv, exprRuntimeProvider, binaryComparatorFactoryProvider, context);
    List<Mutable<ILogicalExpression>> frameExcludeExprList = winOp.getFrameExcludeExpressions();
    Pair<IScalarEvaluatorFactory[], IBinaryComparatorFactory[]> frameExcludeExprEvalsAndComparators = createEvaluatorAndComparatorFactories(frameExcludeExprList, v -> v, v -> OrderOperator.ASC_ORDER, inputSchemas, inputTypeEnv, exprRuntimeProvider, binaryComparatorFactoryProvider, context);
    IScalarEvaluatorFactory frameOffsetExprEval = null;
    ILogicalExpression frameOffsetExpr = winOp.getFrameOffset().getValue();
    if (frameOffsetExpr != null) {
        frameOffsetExprEval = exprRuntimeProvider.createEvaluatorFactory(frameOffsetExpr, inputTypeEnv, inputSchemas, context);
    }
    int[] projectionColumnsExcludingSubplans = JobGenHelper.projectAllVariables(opSchema);
    int[] runningAggOutColumns = JobGenHelper.projectVariables(opSchema, winOp.getVariables());
    List<Mutable<ILogicalExpression>> runningAggExprs = winOp.getExpressions();
    int runningAggExprCount = runningAggExprs.size();
    IRunningAggregateEvaluatorFactory[] runningAggFactories = new IRunningAggregateEvaluatorFactory[runningAggExprCount];
    for (int i = 0; i < runningAggExprCount; i++) {
        StatefulFunctionCallExpression expr = (StatefulFunctionCallExpression) runningAggExprs.get(i).getValue();
        runningAggFactories[i] = exprRuntimeProvider.createRunningAggregateFunctionFactory(expr, inputTypeEnv, inputSchemas, context);
    }
    AbstractWindowRuntimeFactory runtime = null;
    if (winOp.hasNestedPlans()) {
        int opSchemaSizePreSubplans = opSchema.getSize();
        AlgebricksPipeline[] subplans = compileSubplans(inputSchemas[0], winOp, opSchema, context);
        int aggregatorOutputSchemaSize = opSchema.getSize() - opSchemaSizePreSubplans;
        WindowAggregatorDescriptorFactory nestedAggFactory = new WindowAggregatorDescriptorFactory(subplans);
        nestedAggFactory.setSourceLocation(winOp.getSourceLocation());
        int frameMaxObjects = winOp.getFrameMaxObjects();
        // special cases
        if (frameStartExprList.isEmpty() && frameExcludeExprList.isEmpty() && frameOffsetExpr == null) {
            if (frameEndExprList.isEmpty()) {
                // special case #1: frame == whole partition, no exclusions, no offset
                runtime = new WindowNestedPlansUnboundedRuntimeFactory(partitionColumnsList, partitionComparatorFactories, orderComparatorFactories, frameMaxObjects, projectionColumnsExcludingSubplans, runningAggOutColumns, runningAggFactories, aggregatorOutputSchemaSize, nestedAggFactory);
            } else if (frameEndIsMonotonic && nestedTrivialAggregates) {
                // special case #2: accumulating frame from beginning of the partition, no exclusions, no offset,
                // trivial aggregate subplan ( aggregate + nts )
                nestedAggFactory.setPartialOutputEnabled(true);
                runtime = new WindowNestedPlansRunningRuntimeFactory(partitionColumnsList, partitionComparatorFactories, orderComparatorFactories, frameValueExprEvalsAndComparators.first, frameValueExprEvalsAndComparators.second, frameEndExprEvals, frameMaxObjects, projectionColumnsExcludingSubplans, runningAggOutColumns, runningAggFactories, aggregatorOutputSchemaSize, nestedAggFactory);
            }
        }
        // default case
        if (runtime == null) {
            runtime = new WindowNestedPlansRuntimeFactory(partitionColumnsList, partitionComparatorFactories, orderComparatorFactories, frameValueExprEvalsAndComparators.first, frameValueExprEvalsAndComparators.second, frameStartExprEvals, frameStartIsMonotonic, frameEndExprEvals, frameExcludeExprEvalsAndComparators.first, winOp.getFrameExcludeNegationStartIdx(), frameExcludeExprEvalsAndComparators.second, frameOffsetExprEval, context.getBinaryIntegerInspectorFactory(), frameMaxObjects, projectionColumnsExcludingSubplans, runningAggOutColumns, runningAggFactories, aggregatorOutputSchemaSize, nestedAggFactory);
        }
    } else if (partitionMaterialization) {
        runtime = new WindowMaterializingRuntimeFactory(partitionColumnsList, partitionComparatorFactories, orderComparatorFactories, projectionColumnsExcludingSubplans, runningAggOutColumns, runningAggFactories);
    } else {
        runtime = new WindowSimpleRuntimeFactory(partitionColumnsList, partitionComparatorFactories, orderComparatorFactories, projectionColumnsExcludingSubplans, runningAggOutColumns, runningAggFactories);
    }
    runtime.setSourceLocation(winOp.getSourceLocation());
    // contribute one Asterix framewriter
    RecordDescriptor recDesc = JobGenHelper.mkRecordDescriptor(opTypeEnv, opSchema, context);
    builder.contributeMicroOperator(winOp, runtime, recDesc);
    // and contribute one edge from its child
    ILogicalOperator src = winOp.getInputs().get(0).getValue();
    builder.contributeGraphEdge(src, 0, winOp, 0);
}
#end_block

#method_before
@Override
public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("assign [");
    for (int i = 0; i < aggFactories.length; i++) {
        if (i > 0) {
            sb.append(", ");
        }
        sb.append(aggFactories[i]);
    }
    sb.append("]");
    return sb.toString();
}
#method_after
@Override
public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("assign [");
    for (int i = 0; i < aggregFactories.length; i++) {
        if (i > 0) {
            sb.append(", ");
        }
        sb.append(aggregFactories[i]);
    }
    sb.append("]");
    return sb.toString();
}
#end_block

#method_before
@Override
public AbstractOneInputOneOutputOneFramePushRuntime createOneOutputPushRuntime(IHyracksTaskContext ctx) {
    return new AggregatePushRuntime(aggFactories, ctx);
}
#method_after
@Override
public AbstractOneInputOneOutputOneFramePushRuntime createOneOutputPushRuntime(IHyracksTaskContext ctx) {
    return new AggregatePushRuntime(aggregFactories, ctx);
}
#end_block

#method_before
@Override
public IScalarEvaluatorFactory createEvaluatorFactory(IScalarEvaluatorFactory[] args) {
    return new IScalarEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IScalarEvaluator createScalarEvaluator(IHyracksTaskContext ctx) throws HyracksDataException {
            return new AbstractValueComparisonEvaluator(args[0], leftType, args[1], rightType, ctx, sourceLoc, Operation.EQUALITY) {

                @Override
                protected boolean getComparisonResult(Result r) {
                    return r == Result.EQ;
                }
            };
        }
    };
}
#method_after
@Override
public IScalarEvaluatorFactory createEvaluatorFactory(IScalarEvaluatorFactory[] args) {
    return new IScalarEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IScalarEvaluator createScalarEvaluator(IHyracksTaskContext ctx) throws HyracksDataException {
            return new AbstractValueComparisonEvaluator(args[0], leftType, args[1], rightType, ctx, sourceLoc, true) {

                @Override
                protected boolean getComparisonResult(Result r) {
                    return r == Result.EQ;
                }
            };
        }
    };
}
#end_block

#method_before
Result compare() throws HyracksDataException {
    if (leftConstant != null && rightConstant != null) {
        // both are constants
        return logicalComparator.compare(leftConstant, rightConstant, operation);
    } else if (leftConstant != null) {
        // left is constant, right isn't
        return logicalComparator.compare(leftConstant, argRight.getByteArray(), argRight.getStartOffset(), argRight.getLength(), operation);
    } else if (rightConstant != null) {
        // right is constant, left isn't
        return logicalComparator.compare(argLeft.getByteArray(), argLeft.getStartOffset(), argLeft.getLength(), rightConstant, operation);
    } else {
        return logicalComparator.compare(argLeft.getByteArray(), argLeft.getStartOffset(), argLeft.getLength(), argRight.getByteArray(), argRight.getStartOffset(), argRight.getLength(), operation);
    }
}
#method_after
Result compare() throws HyracksDataException {
    if (leftConstant != null) {
        if (rightConstant != null) {
            // both are constants
            return logicalComparator.compare(leftConstant, rightConstant);
        } else {
            // left is constant, right isn't
            return logicalComparator.compare(leftConstant, argRight.getByteArray(), argRight.getStartOffset(), argRight.getLength());
        }
    } else {
        if (rightConstant != null) {
            // right is constant, left isn't
            return logicalComparator.compare(argLeft.getByteArray(), argLeft.getStartOffset(), argLeft.getLength(), rightConstant);
        } else {
            return logicalComparator.compare(argLeft.getByteArray(), argLeft.getStartOffset(), argLeft.getLength(), argRight.getByteArray(), argRight.getStartOffset(), argRight.getLength());
        }
    }
}
#end_block

#method_before
@Override
public Result compare(IAObject leftConstant, IAObject rightConstant, Operation operation) {
    // TODO(ali): not defined currently for constant complex types
    if (leftConstant == null || rightConstant == null) {
        // illegal state maybe???
        return Result.NULL;
    }
    ATypeTag leftTag = leftConstant.getType().getTypeTag();
    ATypeTag rightTag = rightConstant.getType().getTypeTag();
    Result comparisonResult = LogicalComparatorUtil.returnMissingOrNull(leftTag, rightTag);
    if (comparisonResult != null) {
        return comparisonResult;
    }
    return Result.NULL;
}
#method_after
@Override
public Result compare(byte[] leftBytes, int leftStart, int leftLen, byte[] rightBytes, int rightStart, int rightLen) throws HyracksDataException {
    ATypeTag leftTag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(leftBytes[leftStart]);
    ATypeTag rightTag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(rightBytes[rightStart]);
    Result comparisonResult = LogicalComparatorUtil.returnMissingOrNullOrMismatch(leftTag, rightTag);
    if (comparisonResult != null) {
        return comparisonResult;
    }
    if (!leftTag.isDerivedType() || !rightTag.isDerivedType()) {
        return Result.NULL;
    }
    // TODO(ali): complex types(records, arrays, multisets) logic here
    return Result.NULL;
}
#end_block

#method_before
@Override
public Result compare(IAObject leftConstant, IAObject rightConstant, Operation operation) {
    if (leftConstant == null || rightConstant == null) {
        // illegal state maybe???
        return Result.NULL;
    }
    ATypeTag leftTag = leftConstant.getType().getTypeTag();
    ATypeTag rightTag = rightConstant.getType().getTypeTag();
    if (leftTag.isDerivedType() && rightTag.isDerivedType()) {
        return complexComparator.compare(leftConstant, rightConstant, operation);
    }
    return scalarComparator.compare(leftConstant, rightConstant, operation);
}
#method_after
@Override
public Result compare(byte[] leftBytes, int leftStart, int leftLen, byte[] rightBytes, int rightStart, int rightLen) throws HyracksDataException {
    ATypeTag leftTag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(leftBytes[leftStart]);
    ATypeTag rightTag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(rightBytes[rightStart]);
    if (leftTag.isDerivedType() && rightTag.isDerivedType()) {
        return complexComparator.compare(leftBytes, leftStart, leftLen, rightBytes, rightStart, rightLen);
    }
    return scalarComparator.compare(leftBytes, leftStart, leftLen, rightBytes, rightStart, rightLen);
}
#end_block

#method_before
@Override
public IScalarEvaluatorFactory createEvaluatorFactory(IScalarEvaluatorFactory[] args) {
    return new IScalarEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IScalarEvaluator createScalarEvaluator(IHyracksTaskContext ctx) throws HyracksDataException {
            return new AbstractValueComparisonEvaluator(args[0], leftType, args[1], rightType, ctx, sourceLoc, Operation.INEQUALITY) {

                @Override
                protected boolean getComparisonResult(Result r) {
                    return r == Result.LT || r == Result.EQ;
                }
            };
        }
    };
}
#method_after
@Override
public IScalarEvaluatorFactory createEvaluatorFactory(IScalarEvaluatorFactory[] args) {
    return new IScalarEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IScalarEvaluator createScalarEvaluator(IHyracksTaskContext ctx) throws HyracksDataException {
            return new AbstractValueComparisonEvaluator(args[0], leftType, args[1], rightType, ctx, sourceLoc, false) {

                @Override
                protected boolean getComparisonResult(Result r) {
                    return r == Result.LT || r == Result.EQ;
                }
            };
        }
    };
}
#end_block

#method_before
@Override
public IScalarEvaluatorFactory createEvaluatorFactory(IScalarEvaluatorFactory[] args) {
    return new IScalarEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IScalarEvaluator createScalarEvaluator(IHyracksTaskContext ctx) throws HyracksDataException {
            return new AbstractValueComparisonEvaluator(args[0], leftType, args[1], rightType, ctx, sourceLoc, Operation.INEQUALITY) {

                @Override
                protected boolean getComparisonResult(Result r) {
                    return r == Result.LT;
                }
            };
        }
    };
}
#method_after
@Override
public IScalarEvaluatorFactory createEvaluatorFactory(IScalarEvaluatorFactory[] args) {
    return new IScalarEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IScalarEvaluator createScalarEvaluator(IHyracksTaskContext ctx) throws HyracksDataException {
            return new AbstractValueComparisonEvaluator(args[0], leftType, args[1], rightType, ctx, sourceLoc, false) {

                @Override
                protected boolean getComparisonResult(Result r) {
                    return r == Result.LT;
                }
            };
        }
    };
}
#end_block

#method_before
@Override
public IScalarEvaluatorFactory createEvaluatorFactory(IScalarEvaluatorFactory[] args) {
    return new IScalarEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IScalarEvaluator createScalarEvaluator(IHyracksTaskContext ctx) throws HyracksDataException {
            return new AbstractValueComparisonEvaluator(args[0], leftType, args[1], rightType, ctx, sourceLoc, Operation.INEQUALITY) {

                @Override
                protected boolean getComparisonResult(Result r) {
                    return r == Result.GT;
                }
            };
        }
    };
}
#method_after
@Override
public IScalarEvaluatorFactory createEvaluatorFactory(IScalarEvaluatorFactory[] args) {
    return new IScalarEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IScalarEvaluator createScalarEvaluator(IHyracksTaskContext ctx) throws HyracksDataException {
            return new AbstractValueComparisonEvaluator(args[0], leftType, args[1], rightType, ctx, sourceLoc, false) {

                @Override
                protected boolean getComparisonResult(Result r) {
                    return r == Result.GT;
                }
            };
        }
    };
}
#end_block

#method_before
@Override
public IScalarEvaluatorFactory createEvaluatorFactory(IScalarEvaluatorFactory[] args) {
    return new IScalarEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IScalarEvaluator createScalarEvaluator(IHyracksTaskContext ctx) throws HyracksDataException {
            return new AbstractValueComparisonEvaluator(args[0], leftType, args[1], rightType, ctx, sourceLoc, Operation.INEQUALITY) {

                @Override
                protected boolean getComparisonResult(Result r) {
                    return r == Result.GT || r == Result.EQ;
                }
            };
        }
    };
}
#method_after
@Override
public IScalarEvaluatorFactory createEvaluatorFactory(IScalarEvaluatorFactory[] args) {
    return new IScalarEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IScalarEvaluator createScalarEvaluator(IHyracksTaskContext ctx) throws HyracksDataException {
            return new AbstractValueComparisonEvaluator(args[0], leftType, args[1], rightType, ctx, sourceLoc, false) {

                @Override
                protected boolean getComparisonResult(Result r) {
                    return r == Result.GT || r == Result.EQ;
                }
            };
        }
    };
}
#end_block

#method_before
@Override
protected void evaluateImpl(IPointable result) throws HyracksDataException {
    Result comparisonResult = compare();
    if (comparisonResult == Result.MISSING) {
        writeMissing(result);
    } else if (comparisonResult == Result.NULL) {
        writeNull(result);
    } else if (comparisonResult == Result.EQ) {
        resultStorage.reset();
        writeEqualsResult();
        result.set(resultStorage);
    } else {
        result.set(argLeft);
    }
}
#method_after
@Override
protected void evaluateImpl(IPointable result) throws HyracksDataException {
    switch(compare()) {
        case MISSING:
            writeMissing(result);
            break;
        case NULL:
            writeNull(result);
            break;
        case EQ:
            resultStorage.reset();
            writeEqualsResult();
            result.set(resultStorage);
            break;
        default:
            result.set(argLeft);
    }
}
#end_block

#method_before
@Override
public IScalarEvaluatorFactory createEvaluatorFactory(IScalarEvaluatorFactory[] args) {
    return new IScalarEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IScalarEvaluator createScalarEvaluator(IHyracksTaskContext ctx) throws HyracksDataException {
            return new AbstractValueComparisonEvaluator(args[0], leftType, args[1], rightType, ctx, sourceLoc, Operation.EQUALITY) {

                @Override
                protected boolean getComparisonResult(Result r) {
                    return r != Result.EQ;
                }
            };
        }
    };
}
#method_after
@Override
public IScalarEvaluatorFactory createEvaluatorFactory(IScalarEvaluatorFactory[] args) {
    return new IScalarEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IScalarEvaluator createScalarEvaluator(IHyracksTaskContext ctx) throws HyracksDataException {
            return new AbstractValueComparisonEvaluator(args[0], leftType, args[1], rightType, ctx, sourceLoc, true) {

                @Override
                protected boolean getComparisonResult(Result r) {
                    return r != Result.EQ;
                }
            };
        }
    };
}
#end_block

#method_before
@Override
protected void evaluateImpl(IPointable result) throws HyracksDataException {
    Result comparisonResult = compare();
    if (comparisonResult == Result.MISSING) {
        writeMissing(result);
    } else if (comparisonResult == Result.NULL || comparisonResult == Result.MISMATCH) {
        writeNull(result);
    } else {
        resultStorage.reset();
        ABoolean b = getComparisonResult(comparisonResult) ? ABoolean.TRUE : ABoolean.FALSE;
        serde.serialize(b, out);
        result.set(resultStorage);
    }
}
#method_after
@Override
protected void evaluateImpl(IPointable result) throws HyracksDataException {
    Result comparisonResult = compare();
    switch(comparisonResult) {
        case MISSING:
            writeMissing(result);
            break;
        case NULL:
        case MISMATCH:
            writeNull(result);
            break;
        default:
            resultStorage.reset();
            ABoolean b = getComparisonResult(comparisonResult) ? ABoolean.TRUE : ABoolean.FALSE;
            serde.serialize(b, out);
            result.set(resultStorage);
    }
}
#end_block

#method_before
@Override
public Result compare(IAObject leftConstant, IAObject rightConstant, Operation operation) {
    // TODO(ali): currently defined for numbers only
    if (leftConstant == null || rightConstant == null) {
        // illegal state maybe???
        return Result.NULL;
    }
    ATypeTag leftTag = leftConstant.getType().getTypeTag();
    ATypeTag rightTag = rightConstant.getType().getTypeTag();
    Result comparisonResult = LogicalComparatorUtil.returnMissingOrNull(leftTag, rightTag);
    if (comparisonResult != null) {
        return comparisonResult;
    }
    if (comparisonUndefined(leftTag, rightTag, operation)) {
        return Result.NULL;
    }
    comparisonResult = LogicalComparatorUtil.compareConstants(leftConstant, rightConstant);
    if (comparisonResult != null) {
        return comparisonResult;
    }
    return Result.NULL;
}
#method_after
// asking for introducing a new variable for incremented local variables
@SuppressWarnings("squid:S1226")
@Override
public Result compare(byte[] leftBytes, int leftStart, int leftLen, byte[] rightBytes, int rightStart, int rightLen) throws HyracksDataException {
    ATypeTag leftTag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(leftBytes[leftStart]);
    ATypeTag rightTag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(rightBytes[rightStart]);
    Result comparisonResult = LogicalComparatorUtil.returnMissingOrNullOrMismatch(leftTag, rightTag);
    if (comparisonResult != null) {
        return comparisonResult;
    }
    if (comparisonUndefined(leftTag, rightTag, isEquality)) {
        return Result.NULL;
    }
    // compare number if one of args is number
    comparisonResult = LogicalComparatorUtil.compareNumbers(leftTag, leftBytes, leftStart, rightTag, rightBytes, rightStart);
    if (comparisonResult != null) {
        return comparisonResult;
    }
    // return null if !=, the assumption here is only numeric types are compatible with each other
    if (leftTag != rightTag) {
        return Result.NULL;
    }
    leftStart++;
    leftLen--;
    rightStart++;
    rightLen--;
    int result;
    switch(leftTag) {
        case BOOLEAN:
            result = Integer.compare(leftBytes[leftStart], rightBytes[rightStart]);
            break;
        case STRING:
            result = strBinaryComp.compare(leftBytes, leftStart, leftLen, rightBytes, rightStart, rightLen);
            break;
        case YEARMONTHDURATION:
            result = Integer.compare(AYearMonthDurationSerializerDeserializer.getYearMonth(leftBytes, leftStart), AYearMonthDurationSerializerDeserializer.getYearMonth(rightBytes, rightStart));
            break;
        case TIME:
            result = Integer.compare(ATimeSerializerDeserializer.getChronon(leftBytes, leftStart), ATimeSerializerDeserializer.getChronon(rightBytes, rightStart));
            break;
        case DATE:
            result = Integer.compare(ADateSerializerDeserializer.getChronon(leftBytes, leftStart), ADateSerializerDeserializer.getChronon(rightBytes, rightStart));
            break;
        case DAYTIMEDURATION:
            result = Long.compare(ADayTimeDurationSerializerDeserializer.getDayTime(leftBytes, leftStart), ADayTimeDurationSerializerDeserializer.getDayTime(rightBytes, rightStart));
            break;
        case DATETIME:
            result = Long.compare(ADateTimeSerializerDeserializer.getChronon(leftBytes, leftStart), ADateTimeSerializerDeserializer.getChronon(rightBytes, rightStart));
            break;
        case CIRCLE:
            result = circleBinaryComp.compare(leftBytes, leftStart, leftLen, rightBytes, rightStart, rightLen);
            break;
        case LINE:
            result = lineBinaryComparator.compare(leftBytes, leftStart, leftLen, rightBytes, rightStart, rightLen);
            break;
        case POINT:
            result = pointBinaryComparator.compare(leftBytes, leftStart, leftLen, rightBytes, rightStart, rightLen);
            break;
        case POINT3D:
            result = point3DBinaryComparator.compare(leftBytes, leftStart, leftLen, rightBytes, rightStart, rightLen);
            break;
        case POLYGON:
            result = polygonBinaryComparator.compare(leftBytes, leftStart, leftLen, rightBytes, rightStart, rightLen);
            break;
        case DURATION:
            result = durationBinaryComp.compare(leftBytes, leftStart, leftLen, rightBytes, rightStart, rightLen);
            break;
        case INTERVAL:
            result = intervalBinaryComp.compare(leftBytes, leftStart, leftLen, rightBytes, rightStart, rightLen);
            break;
        case RECTANGLE:
            result = rectangleBinaryComparator.compare(leftBytes, leftStart, leftLen, rightBytes, rightStart, rightLen);
            break;
        case BINARY:
            result = byteArrayComparator.compare(leftBytes, leftStart, leftLen, rightBytes, rightStart, rightLen);
            break;
        case UUID:
            result = uuidBinaryComparator.compare(leftBytes, leftStart, leftLen, rightBytes, rightStart, rightLen);
            break;
        default:
            return Result.NULL;
    }
    return ILogicalBinaryComparator.asResult(result);
}
#end_block

#method_before
private static boolean comparisonUndefined(ATypeTag leftTag, ATypeTag rightTag, Operation op) {
    return op == Operation.INEQUALITY && (UNDEFINED_TYPES.contains(leftTag) || UNDEFINED_TYPES.contains(rightTag));
}
#method_after
private static boolean comparisonUndefined(ATypeTag leftTag, ATypeTag rightTag, boolean isEquality) {
    return !isEquality && (INEQUALITY_UNDEFINED_TYPES.contains(leftTag) || INEQUALITY_UNDEFINED_TYPES.contains(rightTag));
}
#end_block

#method_before
public static Field getAccessibleField(Class<?> clazz, String fieldName) {
    Field f = null;
    try {
        f = clazz.getDeclaredField(fieldName);
    } catch (NoSuchFieldException e) {
        throw new IllegalStateException(e);
    }
    f.setAccessible(true);
    return f;
}
#method_after
public static Field getAccessibleField(Class<?> clazz, String fieldName) throws NoSuchFieldException {
    Field f = clazz.getDeclaredField(fieldName);
    f.setAccessible(true);
    return f;
}
#end_block

#method_before
public static Field getAccessibleField(Object obj, String fieldName) {
    Class<?> cl = obj.getClass();
    while (true) {
        Field f = null;
        try {
            f = getAccessibleField(cl, fieldName);
            return f;
        } catch (IllegalStateException e) {
            cl = cl.getSuperclass();
            if (cl == null) {
                throw new IllegalStateException("no such field: '" + fieldName + "' found in " + obj.getClass());
            }
        }
    }
}
#method_after
public static Field getAccessibleField(Object obj, String fieldName) throws NoSuchFieldException {
    Class<?> cl = obj.getClass();
    while (true) {
        Field f = null;
        try {
            f = getAccessibleField(cl, fieldName);
            return f;
        } catch (NoSuchFieldException e) {
            cl = cl.getSuperclass();
            if (cl == null) {
                throw new NoSuchFieldException("field: '" + fieldName + "' not found in (hierarchy of) " + obj.getClass());
            }
        }
    }
}
#end_block

#method_before
public static Object readField(Object obj, String fieldName) throws IOException {
    return readField(obj, getAccessibleField(obj, fieldName));
}
#method_after
public static Object readField(Object obj, String fieldName) throws IOException {
    try {
        return readField(obj, getAccessibleField(obj, fieldName));
    } catch (NoSuchFieldException e) {
        throw new IOException(e);
    }
}
#end_block

#method_before
public static void writeField(Object obj, String fieldName, Object newValue) throws IOException {
    writeField(obj, getAccessibleField(obj, fieldName), newValue);
}
#method_after
public static void writeField(Object obj, String fieldName, Object newValue) throws IOException {
    try {
        writeField(obj, getAccessibleField(obj, fieldName), newValue);
    } catch (NoSuchFieldException e) {
        throw new IOException(e);
    }
}
#end_block

#method_before
public int getSplitCount() {
    return endOffsets.length / numFields;
}
#method_after
public int getSplitCount() {
    return endOffsets.length / fields;
}
#end_block

#method_before
private int getSplitValueIndex(int fieldIndex, int splitIndex) {
    return splitIndex * numFields + fieldIndex;
}
#method_after
private int getSplitValueIndex(int fieldIndex, int splitIndex) {
    return splitIndex * fields + fieldIndex;
}
#end_block

#method_before
@Override
public int hashCode() {
    return numFields + Arrays.hashCode(bytes) + Arrays.hashCode(endOffsets);
}
#method_after
@Override
public int hashCode() {
    return fields + Arrays.hashCode(bytes) + Arrays.hashCode(endOffsets);
}
#end_block

#method_before
@Override
public boolean equals(Object object) {
    if (this == object) {
        return true;
    }
    if (!(object instanceof RangeMap)) {
        return false;
    }
    RangeMap other = (RangeMap) object;
    return numFields == other.numFields && Arrays.equals(endOffsets, other.endOffsets) && Arrays.equals(bytes, other.bytes);
}
#method_after
@Override
public boolean equals(Object object) {
    if (this == object) {
        return true;
    }
    if (!(object instanceof RangeMap)) {
        return false;
    }
    RangeMap other = (RangeMap) object;
    return fields == other.fields && Arrays.equals(endOffsets, other.endOffsets) && Arrays.equals(bytes, other.bytes);
}
#end_block

#method_before
@Override
public void start() throws Exception {
    LOGGER.log(Level.INFO, "Starting ClusterControllerService: " + this);
    serverCtx = new ServerContext(ServerContext.ServerType.CLUSTER_CONTROLLER, new File(ccConfig.getRootDir()));
    IIPCI ccIPCI = new ClusterControllerIPCI(this);
    clusterIPC = new IPCSystem(new InetSocketAddress(ccConfig.getClusterListenPort()), networkSecurityManager.getSocketChannelFactory(), ccIPCI, new CCNCFunctions.SerializerDeserializer());
    IIPCI ciIPCI = new ClientInterfaceIPCI(this, jobIdFactory);
    clientIPC = new IPCSystem(new InetSocketAddress(ccConfig.getClientListenAddress(), ccConfig.getClientListenPort()), networkSecurityManager.getSocketChannelFactory(), ciIPCI, new JavaSerializationBasedPayloadSerializerDeserializer());
    webServer = new WebServer(this, ccConfig.getConsoleListenPort());
    clusterIPC.start();
    clientIPC.start();
    webServer.start();
    info = new ClusterControllerInfo(ccId, ccConfig.getClientPublicAddress(), ccConfig.getClientPublicPort(), ccConfig.getConsolePublicPort(), null);
    timer.schedule(sweeper, 0, ccConfig.getDeadNodeSweepThreshold());
    jobLog.open();
    startApplication();
    resultDirectoryService.init(executor);
    workQueue.start();
    connectNCs();
    LOGGER.log(Level.INFO, "Started ClusterControllerService");
    notifyApplication();
}
#method_after
@Override
public void start() throws Exception {
    LOGGER.log(Level.INFO, "Starting ClusterControllerService: " + this);
    serverCtx = new ServerContext(ServerContext.ServerType.CLUSTER_CONTROLLER, new File(ccConfig.getRootDir()));
    IIPCI ccIPCI = new ClusterControllerIPCI(this);
    clusterIPC = new IPCSystem(new InetSocketAddress(ccConfig.getClusterListenPort()), networkSecurityManager.getSocketChannelFactory(), ccIPCI, new CCNCFunctions.SerializerDeserializer());
    IIPCI ciIPCI = new ClientInterfaceIPCI(this, jobIdFactory);
    clientIPC = new IPCSystem(new InetSocketAddress(ccConfig.getClientListenAddress(), ccConfig.getClientListenPort()), networkSecurityManager.getSocketChannelFactory(), ciIPCI, new JavaSerializationBasedPayloadSerializerDeserializer());
    webServer = new WebServer(this, ccConfig.getConsoleListenPort());
    clusterIPC.start();
    clientIPC.start();
    webServer.start();
    info = new ClusterControllerInfo(ccId, ccConfig.getClientPublicAddress(), ccConfig.getClientPublicPort(), ccConfig.getConsolePublicPort());
    timer.schedule(sweeper, 0, ccConfig.getDeadNodeSweepThreshold());
    jobLog.open();
    startApplication();
    resultDirectoryService.init(executor);
    workQueue.start();
    connectNCs();
    LOGGER.log(Level.INFO, "Started ClusterControllerService");
    notifyApplication();
}
#end_block

#method_before
public HashMap<Pair<String, String>, Object> getConfig() {
    return config;
}
#method_after
public Map<SerializedOption, Object> getConfig() {
    return config;
}
#end_block

#method_before
public static Deployment getSimpleClusterDeployment() {
    mavenVersion = getMavenArtifactVersion();
    asterixHome = "/asterix/apache-asterixdb-" + mavenVersion;
    return new Deployment.DeploymentBuilder("simpleClusterDeployment").withService("asterix").applicationPath("../asterix-server/target/asterix-server-" + mavenVersion + "-binary-assembly.zip", "/asterix", false, true, false).dockerFileAddress("docker/Dockerfile", false).dockerImage("spidersilk/test-asterix").instrumentablePath(asterixHome + "/repo/asterix-server-0.9.5-SNAPSHOT.jar").libraryPath(asterixHome + "/repo/*.jar").libraryPath(asterixHome + "/lib/*.jar").logDirectory(asterixHome + "/logs").serviceType(ServiceType.JAVA).and().withNode("cc", "asterix").applicationPath("config", "/asterix/config").startCommand(asterixHome + "/bin/asterixcc -config-file /asterix/config/cc.conf").tcpPort(19002).and().withNode("nc1", "asterix").startCommand(asterixHome + "/bin/asterixncservice").and().withNode("nc2", "asterix").startCommand(asterixHome + "/bin/asterixncservice").and().build();
}
#method_after
public static Deployment getSimpleClusterDeployment() {
    mavenVersion = getMavenArtifactVersion();
    asterixHome = "/asterix/apache-asterixdb-" + mavenVersion;
    return new Deployment.DeploymentBuilder("simpleClusterDeployment").withService("asterix").applicationPath("../asterix-server/target/asterix-server-" + mavenVersion + "-binary-assembly.zip", "/asterix", false, true, false).dockerFileAddress("docker/Dockerfile", false).dockerImage("spidersilk/test-asterix").instrumentablePath(asterixHome + "/repo/asterix-server-" + mavenVersion + ".jar").libraryPath(asterixHome + "/repo/*.jar").libraryPath(asterixHome + "/lib/*.jar").logDirectory(asterixHome + "/logs").serviceType(ServiceType.JAVA).and().withNode("cc", "asterix").applicationPath("config", "/asterix/config").startCommand(asterixHome + "/bin/asterixcc -config-file /asterix/config/cc.conf").tcpPort(19002).and().withNode("nc1", "asterix").startCommand(asterixHome + "/bin/asterixncservice").and().withNode("nc2", "asterix").startCommand(asterixHome + "/bin/asterixncservice").and().build();
}
#end_block

#method_before
public void executeQuery(OutputFormat fmt, String statement, Map<String, Object> variableCtx, String reqType, File testFile, File expectedResultFile, File actualResultFile, MutableInt queryCount, int numResultFiles, List<Parameter> params, ComparisonEnum compare) throws Exception {
    String delivery = DELIVERY_IMMEDIATE;
    if (reqType.equalsIgnoreCase("async")) {
        delivery = DELIVERY_ASYNC;
    } else if (reqType.equalsIgnoreCase("deferred")) {
        delivery = DELIVERY_DEFERRED;
    }
    URI uri = testFile.getName().endsWith("aql") ? getEndpoint(Servlets.QUERY_AQL) : getEndpoint(Servlets.QUERY_SERVICE);
    boolean isJsonEncoded = isJsonEncoded(extractHttpRequestType(statement));
    InputStream resultStream;
    if (DELIVERY_IMMEDIATE.equals(delivery)) {
        resultStream = executeQueryService(statement, fmt, uri, params, isJsonEncoded, null, isCancellable(reqType));
        switch(reqType) {
            case METRICS_QUERY_TYPE:
                resultStream = ResultExtractor.extractMetrics(resultStream);
                break;
            case PARSE_QUERY_TYPE:
                resultStream = ResultExtractor.extractParseResults(resultStream);
                break;
            default:
                resultStream = ResultExtractor.extract(resultStream);
                break;
        }
    } else {
        String handleVar = getHandleVariable(statement);
        resultStream = executeQueryService(statement, fmt, uri, upsertParam(params, "mode", ParameterTypeEnum.STRING, delivery), isJsonEncoded);
        String handle = ResultExtractor.extractHandle(resultStream);
        Assert.assertNotNull("no handle for " + reqType + " test " + testFile.toString(), handleVar);
        variableCtx.put(handleVar, toQueryServiceHandle(handle));
    }
    if (actualResultFile == null) {
        if (testFile.getName().startsWith(DIAGNOSE)) {
            LOGGER.info("Diagnostic output: {}", IOUtils.toString(resultStream, StandardCharsets.UTF_8));
        } else {
            Assert.fail("no result file for " + testFile.toString() + "; queryCount: " + queryCount + ", filectxs.size: " + numResultFiles);
        }
    } else {
        writeOutputToFile(actualResultFile, resultStream);
        if (expectedResultFile == null) {
            if (reqType.equals("store")) {
                return;
            }
            Assert.fail("no result file for " + testFile.toString() + "; queryCount: " + queryCount + ", filectxs.size: " + numResultFiles);
        }
    }
    runScriptAndCompareWithResult(testFile, expectedResultFile, actualResultFile, compare);
    if (!reqType.equals("validate")) {
        queryCount.increment();
    }
    // Deletes the matched result file.
    actualResultFile.getParentFile().delete();
}
#method_after
public void executeQuery(OutputFormat fmt, String statement, Map<String, Object> variableCtx, String reqType, File testFile, File expectedResultFile, File actualResultFile, MutableInt queryCount, int numResultFiles, List<Parameter> params, ComparisonEnum compare) throws Exception {
    String delivery = DELIVERY_IMMEDIATE;
    if (reqType.equalsIgnoreCase("async")) {
        delivery = DELIVERY_ASYNC;
    } else if (reqType.equalsIgnoreCase("deferred")) {
        delivery = DELIVERY_DEFERRED;
    }
    URI uri = testFile.getName().endsWith("aql") ? getEndpoint(Servlets.QUERY_AQL) : getEndpoint(Servlets.QUERY_SERVICE);
    boolean isJsonEncoded = isJsonEncoded(extractHttpRequestType(statement));
    InputStream resultStream;
    if (DELIVERY_IMMEDIATE.equals(delivery)) {
        resultStream = executeQueryService(statement, fmt, uri, params, isJsonEncoded, null, isCancellable(reqType));
        switch(reqType) {
            case METRICS_QUERY_TYPE:
                resultStream = ResultExtractor.extractMetrics(resultStream);
                break;
            default:
                resultStream = ResultExtractor.extract(resultStream);
                break;
        }
    } else {
        String handleVar = getHandleVariable(statement);
        resultStream = executeQueryService(statement, fmt, uri, upsertParam(params, "mode", ParameterTypeEnum.STRING, delivery), isJsonEncoded);
        String handle = ResultExtractor.extractHandle(resultStream);
        Assert.assertNotNull("no handle for " + reqType + " test " + testFile.toString(), handleVar);
        variableCtx.put(handleVar, toQueryServiceHandle(handle));
    }
    if (actualResultFile == null) {
        if (testFile.getName().startsWith(DIAGNOSE)) {
            LOGGER.info("Diagnostic output: {}", IOUtils.toString(resultStream, StandardCharsets.UTF_8));
        } else {
            Assert.fail("no result file for " + testFile.toString() + "; queryCount: " + queryCount + ", filectxs.size: " + numResultFiles);
        }
    } else {
        writeOutputToFile(actualResultFile, resultStream);
        if (expectedResultFile == null) {
            if (reqType.equals("store")) {
                return;
            }
            Assert.fail("no result file for " + testFile.toString() + "; queryCount: " + queryCount + ", filectxs.size: " + numResultFiles);
        }
    }
    runScriptAndCompareWithResult(testFile, expectedResultFile, actualResultFile, compare);
    if (!reqType.equals("validate")) {
        queryCount.increment();
    }
    // Deletes the matched result file.
    actualResultFile.getParentFile().delete();
}
#end_block

#method_before
public static List<Parameter> extractParameters(String statement) {
    List<Parameter> params = new ArrayList<>();
    final Matcher m = HTTP_PARAM_PATTERN.matcher(statement);
    while (m.find()) {
        final Parameter param = new Parameter();
        String name = m.group("name");
        param.setName(name);
        /*            if (name.equals("parse")) {
                String newname = "parse-only";
                param.setName(newname);
            } else {
                param.setName(name);
            }*/
        String value = m.group("value");
        param.setValue(value);
        String type = m.group("type");
        if (type != null) {
            try {
                param.setType(ParameterTypeEnum.fromValue(type.toLowerCase()));
            } catch (IllegalArgumentException e) {
                throw new IllegalArgumentException(String.format("Invalid type '%s' specified for parameter '%s'", type, name));
            }
        }
        params.add(param);
    }
    return params;
}
#method_after
public static List<Parameter> extractParameters(String statement) {
    List<Parameter> params = new ArrayList<>();
    final Matcher m = HTTP_PARAM_PATTERN.matcher(statement);
    while (m.find()) {
        final Parameter param = new Parameter();
        String name = m.group("name");
        param.setName(name);
        String value = m.group("value");
        param.setValue(value);
        String type = m.group("type");
        if (type != null) {
            try {
                param.setType(ParameterTypeEnum.fromValue(type.toLowerCase()));
            } catch (IllegalArgumentException e) {
                throw new IllegalArgumentException(String.format("Invalid type '%s' specified for parameter '%s'", type, name));
            }
        }
        params.add(param);
    }
    return params;
}
#end_block

#method_before
@Override
public Void visit(GroupbyClause gc, Void arg) throws CompilationException {
    for (GbyVariableExpressionPair p : gc.getGbyPairList()) {
        p.getExpr().accept(this, arg);
    }
    for (GbyVariableExpressionPair p : gc.getDecorPairList()) {
        p.getExpr().accept(this, arg);
    }
    return null;
}
#method_after
@Override
public Void visit(GroupbyClause gc, Void arg) throws CompilationException {
    for (GbyVariableExpressionPair p : gc.getGbyPairList()) {
        p.getExpr().accept(this, arg);
    }
    if (gc.hasDecorList()) {
        for (GbyVariableExpressionPair p : gc.getDecorPairList()) {
            p.getExpr().accept(this, arg);
        }
    }
    if (gc.hasGroupFieldList()) {
        for (Pair<Expression, Identifier> p : gc.getGroupFieldList()) {
            p.first.accept(this, arg);
        }
    }
    if (gc.hasWithMap()) {
        for (Map.Entry<Expression, VariableExpr> me : gc.getWithVarMap().entrySet()) {
            me.getKey().accept(this, arg);
        }
    }
    return null;
}
#end_block

#method_before
protected void setRequestParam(IServletRequest request, QueryServiceRequestParameters param) throws IOException, AlgebricksException {
    param.setHost(host(request));
    param.setPath(servletPath(request));
    String contentType = HttpUtil.getContentTypeOnly(request);
    if (HttpUtil.ContentType.APPLICATION_JSON.equals(contentType)) {
        try {
            setParamFromJSON(request, param);
        } catch (JsonParseException | JsonMappingException e) {
            // if the JSON parsing fails, the statement is empty and we get an empty statement error
            GlobalConfig.ASTERIX_LOGGER.log(Level.ERROR, e.getMessage(), e);
        }
    } else {
        setParamFromRequest(request, param);
    }
}
#method_after
protected void setRequestParam(IServletRequest request, QueryServiceRequestParameters param, Map<String, String> optionalParams) throws IOException, AlgebricksException {
    param.setHost(host(request));
    param.setPath(servletPath(request));
    String contentType = HttpUtil.getContentTypeOnly(request);
    if (HttpUtil.ContentType.APPLICATION_JSON.equals(contentType)) {
        try {
            setParamFromJSON(request, param);
        } catch (JsonParseException | JsonMappingException e) {
            // if the JSON parsing fails, the statement is empty and we get an empty statement error
            GlobalConfig.ASTERIX_LOGGER.log(Level.ERROR, e.getMessage(), e);
        }
    } else {
        setParamFromRequest(request, param);
    }
}
#end_block

#method_before
private void handleRequest(IServletRequest request, IServletResponse response) {
    long elapsedStart = System.nanoTime();
    long errorCount = 1;
    Stats stats = new Stats();
    RequestExecutionState execution = new RequestExecutionState();
    List<ExecutionWarning> warnings = Collections.emptyList();
    PrintWriter httpWriter = response.writer();
    SessionOutput sessionOutput = createSessionOutput(httpWriter);
    QueryServiceRequestParameters param = new QueryServiceRequestParameters();
    try {
        // buffer the output until we are ready to set the status of the response message correctly
        sessionOutput.hold();
        sessionOutput.out().print("{\n");
        HttpUtil.setContentType(response, HttpUtil.ContentType.APPLICATION_JSON, HttpUtil.Encoding.UTF8);
        setRequestParam(request, param);
        LOGGER.info("handleRequest: {}", param);
        ResultDelivery delivery = parseResultDelivery(param.getMode());
        setSessionConfig(sessionOutput, param, delivery);
        final ResultProperties resultProperties = param.getMaxResultReads() == null ? new ResultProperties(delivery) : new ResultProperties(delivery, Long.parseLong(param.getMaxResultReads()));
        printAdditionalResultFields(sessionOutput.out());
        printRequestId(sessionOutput.out());
        printClientContextID(sessionOutput.out(), param);
        if (!param.isParseOnly()) {
            printSignature(sessionOutput.out(), param);
        }
        printType(sessionOutput.out(), sessionOutput.config());
        if (param.getStatement() == null || param.getStatement().isEmpty()) {
            throw new RuntimeDataException(ErrorCode.NO_STATEMENT_PROVIDED);
        }
        String statementsText = param.getStatement() + ";";
        Map<String, String> optionalParams = null;
        if (optionalParamProvider != null) {
            optionalParams = optionalParamProvider.apply(request);
        }
        if (param.isParseOnly()) {
            // is cousin of executeStatement
            ParseOnlyResult parseOnlyResult = parseStatement(statementsText);
            response.setStatus(HttpResponseStatus.OK);
            // CORS
            if (request.getHeader("Origin") != null) {
                response.setHeader("Access-Control-Allow-Origin", request.getHeader("Origin"));
            }
            response.setHeader("Access-Control-Allow-Headers", "Origin, X-Requested-With, Content-Type, Accept");
            printParseValues(sessionOutput, parseOnlyResult);
        } else {
            Map<String, byte[]> statementParams = org.apache.asterix.app.translator.RequestParameters.serializeParameterValues(param.getStatementParams());
            // CORS
            if (request.getHeader("Origin") != null) {
                response.setHeader("Access-Control-Allow-Origin", request.getHeader("Origin"));
            }
            response.setHeader("Access-Control-Allow-Headers", "Origin, X-Requested-With, Content-Type, Accept");
            response.setStatus(execution.getHttpStatus());
            executeStatement(statementsText, sessionOutput, resultProperties, stats, param, execution, optionalParams, statementParams);
            if (ResultDelivery.IMMEDIATE == delivery || ResultDelivery.DEFERRED == delivery) {
                ResultUtil.printStatus(sessionOutput, execution.getResultStatus());
            }
        }
        if (!warnings.isEmpty()) {
            printWarnings(sessionOutput.out(), warnings);
        }
        errorCount = 0;
    } catch (Exception | TokenMgrError | org.apache.asterix.aqlplus.parser.TokenMgrError e) {
        handleExecuteStatementException(e, execution, param);
        response.setStatus(execution.getHttpStatus());
        printError(sessionOutput.out(), e);
        ResultUtil.printStatus(sessionOutput, execution.getResultStatus());
    } finally {
        // make sure that we stop buffering and return the result to the http response
        sessionOutput.release();
        execution.finish();
    }
    printMetrics(sessionOutput.out(), System.nanoTime() - elapsedStart, execution.duration(), stats.getCount(), stats.getSize(), stats.getProcessedObjects(), errorCount, warnings.size());
    sessionOutput.out().print("}\n");
    sessionOutput.out().flush();
    if (sessionOutput.out().checkError()) {
        LOGGER.warn("Error flushing output writer");
    }
}
#method_after
private void handleRequest(IServletRequest request, IServletResponse response) {
    long elapsedStart = System.nanoTime();
    long errorCount = 1;
    Stats stats = new Stats();
    RequestExecutionState execution = new RequestExecutionState();
    List<ExecutionWarning> warnings = Collections.emptyList();
    PrintWriter httpWriter = response.writer();
    SessionOutput sessionOutput = createSessionOutput(httpWriter);
    QueryServiceRequestParameters param = new QueryServiceRequestParameters();
    try {
        // buffer the output until we are ready to set the status of the response message correctly
        sessionOutput.hold();
        sessionOutput.out().print("{\n");
        HttpUtil.setContentType(response, HttpUtil.ContentType.APPLICATION_JSON, HttpUtil.Encoding.UTF8);
        Map<String, String> optionalParams = null;
        if (optionalParamProvider != null) {
            optionalParams = optionalParamProvider.apply(request);
        }
        setRequestParam(request, param, optionalParams);
        LOGGER.info("handleRequest: {}", param);
        ResultDelivery delivery = parseResultDelivery(param.getMode());
        setSessionConfig(sessionOutput, param, delivery);
        final ResultProperties resultProperties = param.getMaxResultReads() == null ? new ResultProperties(delivery) : new ResultProperties(delivery, Long.parseLong(param.getMaxResultReads()));
        printAdditionalResultFields(sessionOutput.out());
        printRequestId(sessionOutput.out());
        printClientContextID(sessionOutput.out(), param);
        if (!param.isParseOnly()) {
            printSignature(sessionOutput.out(), param);
        }
        printType(sessionOutput.out(), sessionOutput.config());
        if (param.getStatement() == null || param.getStatement().isEmpty()) {
            throw new RuntimeDataException(ErrorCode.NO_STATEMENT_PROVIDED);
        }
        String statementsText = param.getStatement() + ";";
        if (param.isParseOnly()) {
            ResultUtil.ParseOnlyResult parseOnlyResult = parseStatement(statementsText);
            setAccessControlHeaders(request, response);
            response.setStatus(HttpResponseStatus.OK);
            printParseOnlyValueResult(sessionOutput, parseOnlyResult);
            ResultUtil.printStatus(sessionOutput, execution.getResultStatus());
        } else {
            Map<String, byte[]> statementParams = org.apache.asterix.app.translator.RequestParameters.serializeParameterValues(param.getStatementParams());
            setAccessControlHeaders(request, response);
            response.setStatus(execution.getHttpStatus());
            executeStatement(statementsText, sessionOutput, resultProperties, stats, param, execution, optionalParams, statementParams);
            if (ResultDelivery.IMMEDIATE == delivery || ResultDelivery.DEFERRED == delivery) {
                ResultUtil.printStatus(sessionOutput, execution.getResultStatus());
            }
        }
        if (!warnings.isEmpty()) {
            printWarnings(sessionOutput.out(), warnings);
        }
        errorCount = 0;
    } catch (Exception | TokenMgrError | org.apache.asterix.aqlplus.parser.TokenMgrError e) {
        handleExecuteStatementException(e, execution, param);
        response.setStatus(execution.getHttpStatus());
        printError(sessionOutput.out(), e);
        ResultUtil.printStatus(sessionOutput, execution.getResultStatus());
    } finally {
        // make sure that we stop buffering and return the result to the http response
        sessionOutput.release();
        execution.finish();
    }
    printMetrics(sessionOutput.out(), System.nanoTime() - elapsedStart, execution.duration(), stats.getCount(), stats.getSize(), stats.getProcessedObjects(), errorCount, warnings.size());
    sessionOutput.out().print("}\n");
    sessionOutput.out().flush();
    if (sessionOutput.out().checkError()) {
        LOGGER.warn("Error flushing output writer");
    }
}
#end_block

#method_before
protected ParseOnlyResult parseStatement(String statementsText) throws Exception {
    IParserFactory factory = compilationProvider.getParserFactory();
    IParser parser = factory.createParser(statementsText);
    List<Statement> stmts = parser.parse();
    if (stmts.size() != 1) {
        // TODO: proper exception message
        throw new CompilationException("MultiStatement not support");
    }
    Query query = (Query) stmts.get(0);
    Set<VariableExpr> extVars = compilationProvider.getRewriterFactory().createQueryRewriter().getExternalVariables(query.getBody());
    ParseOnlyResult parseOnlyResult = new ParseOnlyResult();
    parseOnlyResult.setExternalVariables(extVars);
    return parseOnlyResult;
}
#method_after
protected ResultUtil.ParseOnlyResult parseStatement(String statementsText) throws CompilationException {
    IParserFactory factory = compilationProvider.getParserFactory();
    IParser parser = factory.createParser(statementsText);
    List<Statement> stmts = parser.parse();
    QueryTranslator.validateStatements(stmts);
    Query query = (Query) stmts.get(stmts.size() - 1);
    Set<VariableExpr> extVars = compilationProvider.getRewriterFactory().createQueryRewriter().getExternalVariables(query.getBody());
    ResultUtil.ParseOnlyResult parseOnlyResult = new ResultUtil.ParseOnlyResult(extVars);
    return parseOnlyResult;
}
#end_block

#method_before
protected void setup(List<FunctionDecl> declaredFunctions, IReturningStatement topExpr, MetadataProvider metadataProvider, LangRewritingContext context, Collection<VarIdentifier> externalVars) {
    this.topExpr = topExpr;
    this.context = context;
    this.declaredFunctions = declaredFunctions;
    this.metadataProvider = metadataProvider;
    this.externalVars = externalVars;
}
#method_after
protected void setup(List<FunctionDecl> declaredFunctions, IReturningStatement topExpr, MetadataProvider metadataProvider, LangRewritingContext context, Collection<VarIdentifier> externalVars) throws CompilationException {
    this.topExpr = topExpr;
    this.context = context;
    this.declaredFunctions = declaredFunctions;
    this.metadataProvider = metadataProvider;
    this.externalVars = externalVars;
    this.isLogEnabled = LOGGER.isTraceEnabled();
    logExpression("Starting AST rewrites on", "");
}
#end_block

#method_before
@Override
public void rewrite(List<FunctionDecl> declaredFunctions, IReturningStatement topStatement, MetadataProvider metadataProvider, LangRewritingContext context, boolean inlineUdfs, Collection<VarIdentifier> externalVars) throws CompilationException {
    if (topStatement == null) {
        return;
    }
    // Sets up parameters.
    setup(declaredFunctions, topStatement, metadataProvider, context, externalVars);
    // Generates column names.
    generateColumnNames();
    // Substitutes group-by key expressions.
    substituteGroupbyKeyExpression();
    // Group-by core rewrites
    rewriteGroupBys();
    // Rewrites set operations.
    rewriteSetOperations();
    // Inlines column aliases.
    inlineColumnAlias();
    // Generate ids for variables (considering scopes) and replace global variable access with the dataset function.
    variableCheckAndRewrite();
    // Rewrites SQL-92 aggregate functions
    rewriteGroupByAggregationSugar();
    // Rewrites like/not-like expressions.
    rewriteOperatorExpression();
    // Inlines WITH expressions after variableCheckAndRewrite(...) so that the variable scoping for WITH
    // expression is correct.
    inlineWithExpressions();
    // Rewrites several variable-arg functions into their corresponding internal list-input functions.
    rewriteListInputFunctions();
    // Inlines functions.
    inlineDeclaredUdfs(inlineUdfs);
    // Rewrites function names.
    // This should be done after inlineDeclaredUdfs() because user-defined function
    // names could be case sensitive.
    rewriteFunctionNames();
    // Rewrites distinct aggregates into regular aggregates
    rewriteDistinctAggregations();
    // Sets the var counter of the query.
    topStatement.setVarCounter(context.getVarCounter().get());
}
#method_after
@Override
public void rewrite(List<FunctionDecl> declaredFunctions, IReturningStatement topStatement, MetadataProvider metadataProvider, LangRewritingContext context, boolean inlineUdfs, Collection<VarIdentifier> externalVars) throws CompilationException {
    if (topStatement == null) {
        return;
    }
    // Sets up parameters.
    setup(declaredFunctions, topStatement, metadataProvider, context, externalVars);
    // Generates column names.
    generateColumnNames();
    // Substitutes group-by key expressions.
    substituteGroupbyKeyExpression();
    // Group-by core rewrites
    rewriteGroupBys();
    // Rewrites set operations.
    rewriteSetOperations();
    // Inlines column aliases.
    inlineColumnAlias();
    // Window expression core rewrites.
    rewriteWindowExpressions();
    // Generate ids for variables (considering scopes) and replace global variable access with the dataset function.
    variableCheckAndRewrite();
    // Rewrites SQL-92 aggregate functions
    rewriteGroupByAggregationSugar();
    // Rewrite window expression aggregations.
    rewriteWindowAggregationSugar();
    // Rewrites like/not-like expressions.
    rewriteOperatorExpression();
    // Inlines WITH expressions after variableCheckAndRewrite(...) so that the variable scoping for WITH
    // expression is correct.
    inlineWithExpressions();
    // Rewrites several variable-arg functions into their corresponding internal list-input functions.
    rewriteListInputFunctions();
    // Inlines functions.
    inlineDeclaredUdfs(inlineUdfs);
    // Rewrites function names.
    // This should be done after inlineDeclaredUdfs() because user-defined function
    // names could be case sensitive.
    rewriteFunctionNames();
    // Rewrites distinct aggregates into regular aggregates
    rewriteDistinctAggregations();
    // Sets the var counter of the query.
    topStatement.setVarCounter(context.getVarCounter().get());
}
#end_block

#method_before
protected void rewriteGroupByAggregationSugar() throws CompilationException {
    SqlppGroupByAggregationSugarVisitor visitor = new SqlppGroupByAggregationSugarVisitor(context);
    topExpr.accept(visitor, null);
}
#method_after
protected void rewriteGroupByAggregationSugar() throws CompilationException {
    SqlppGroupByAggregationSugarVisitor visitor = new SqlppGroupByAggregationSugarVisitor(context);
    rewriteTopExpr(visitor, null);
}
#end_block

#method_before
protected void rewriteDistinctAggregations() throws CompilationException {
    SqlppDistinctAggregationSugarVisitor distinctAggregationVisitor = new SqlppDistinctAggregationSugarVisitor(context);
    topExpr.accept(distinctAggregationVisitor, null);
}
#method_after
protected void rewriteDistinctAggregations() throws CompilationException {
    SqlppDistinctAggregationSugarVisitor distinctAggregationVisitor = new SqlppDistinctAggregationSugarVisitor(context);
    rewriteTopExpr(distinctAggregationVisitor, null);
}
#end_block

#method_before
protected void rewriteListInputFunctions() throws CompilationException {
    SqlppListInputFunctionRewriteVisitor listInputFunctionVisitor = new SqlppListInputFunctionRewriteVisitor();
    topExpr.accept(listInputFunctionVisitor, null);
}
#method_after
protected void rewriteListInputFunctions() throws CompilationException {
    SqlppListInputFunctionRewriteVisitor listInputFunctionVisitor = new SqlppListInputFunctionRewriteVisitor();
    rewriteTopExpr(listInputFunctionVisitor, null);
}
#end_block

#method_before
protected void rewriteFunctionNames() throws CompilationException {
    SqlppBuiltinFunctionRewriteVisitor functionNameMapVisitor = new SqlppBuiltinFunctionRewriteVisitor();
    topExpr.accept(functionNameMapVisitor, null);
}
#method_after
protected void rewriteFunctionNames() throws CompilationException {
    SqlppBuiltinFunctionRewriteVisitor functionNameMapVisitor = new SqlppBuiltinFunctionRewriteVisitor();
    rewriteTopExpr(functionNameMapVisitor, null);
}
#end_block

#method_before
protected void inlineWithExpressions() throws CompilationException {
    if (!metadataProvider.getBooleanProperty(INLINE_WITH_OPTION, INLINE_WITH_OPTION_DEFAULT)) {
        return;
    }
    // Inlines with expressions.
    InlineWithExpressionVisitor inlineWithExpressionVisitor = new InlineWithExpressionVisitor(context);
    topExpr.accept(inlineWithExpressionVisitor, null);
}
#method_after
protected void inlineWithExpressions() throws CompilationException {
    if (!metadataProvider.getBooleanProperty(INLINE_WITH_OPTION, INLINE_WITH_OPTION_DEFAULT)) {
        return;
    }
    // Inlines with expressions.
    InlineWithExpressionVisitor inlineWithExpressionVisitor = new InlineWithExpressionVisitor(context);
    rewriteTopExpr(inlineWithExpressionVisitor, null);
}
#end_block

#method_before
protected void generateColumnNames() throws CompilationException {
    // Generate column names if they are missing in the user query.
    GenerateColumnNameVisitor generateColumnNameVisitor = new GenerateColumnNameVisitor(context);
    topExpr.accept(generateColumnNameVisitor, null);
}
#method_after
protected void generateColumnNames() throws CompilationException {
    // Generate column names if they are missing in the user query.
    GenerateColumnNameVisitor generateColumnNameVisitor = new GenerateColumnNameVisitor(context);
    rewriteTopExpr(generateColumnNameVisitor, null);
}
#end_block

#method_before
protected void substituteGroupbyKeyExpression() throws CompilationException {
    // Substitute group-by key expressions that appear in the select clause.
    SubstituteGroupbyExpressionWithVariableVisitor substituteGbyExprVisitor = new SubstituteGroupbyExpressionWithVariableVisitor(context);
    topExpr.accept(substituteGbyExprVisitor, null);
}
#method_after
protected void substituteGroupbyKeyExpression() throws CompilationException {
    // Substitute group-by key expressions that appear in the select clause.
    SubstituteGroupbyExpressionWithVariableVisitor substituteGbyExprVisitor = new SubstituteGroupbyExpressionWithVariableVisitor(context);
    rewriteTopExpr(substituteGbyExprVisitor, null);
}
#end_block

#method_before
protected void rewriteSetOperations() throws CompilationException {
    // Rewrites set operation queries that contain order-by and limit clauses.
    SetOperationVisitor setOperationVisitor = new SetOperationVisitor(context);
    topExpr.accept(setOperationVisitor, null);
}
#method_after
protected void rewriteSetOperations() throws CompilationException {
    // Rewrites set operation queries that contain order-by and limit clauses.
    SetOperationVisitor setOperationVisitor = new SetOperationVisitor(context);
    rewriteTopExpr(setOperationVisitor, null);
}
#end_block

#method_before
protected void rewriteOperatorExpression() throws CompilationException {
    // Rewrites like/not-like/in/not-in operators into function call expressions.
    OperatorExpressionVisitor operatorExpressionVisitor = new OperatorExpressionVisitor(context);
    topExpr.accept(operatorExpressionVisitor, null);
}
#method_after
protected void rewriteOperatorExpression() throws CompilationException {
    // Rewrites like/not-like/in/not-in operators into function call expressions.
    OperatorExpressionVisitor operatorExpressionVisitor = new OperatorExpressionVisitor(context);
    rewriteTopExpr(operatorExpressionVisitor, null);
}
#end_block

#method_before
protected void inlineColumnAlias() throws CompilationException {
    // Inline column aliases.
    InlineColumnAliasVisitor inlineColumnAliasVisitor = new InlineColumnAliasVisitor(context);
    topExpr.accept(inlineColumnAliasVisitor, null);
}
#method_after
protected void inlineColumnAlias() throws CompilationException {
    // Inline column aliases.
    InlineColumnAliasVisitor inlineColumnAliasVisitor = new InlineColumnAliasVisitor(context);
    rewriteTopExpr(inlineColumnAliasVisitor, null);
}
#end_block

#method_before
protected void variableCheckAndRewrite() throws CompilationException {
    VariableCheckAndRewriteVisitor variableCheckAndRewriteVisitor = new VariableCheckAndRewriteVisitor(context, metadataProvider, externalVars);
    topExpr.accept(variableCheckAndRewriteVisitor, null);
}
#method_after
protected void variableCheckAndRewrite() throws CompilationException {
    VariableCheckAndRewriteVisitor variableCheckAndRewriteVisitor = new VariableCheckAndRewriteVisitor(context, metadataProvider, externalVars);
    rewriteTopExpr(variableCheckAndRewriteVisitor, null);
}
#end_block

#method_before
protected void rewriteGroupBys() throws CompilationException {
    SqlppGroupByVisitor groupByVisitor = new SqlppGroupByVisitor(context);
    topExpr.accept(groupByVisitor, null);
}
#method_after
protected void rewriteGroupBys() throws CompilationException {
    SqlppGroupByVisitor groupByVisitor = new SqlppGroupByVisitor(context);
    rewriteTopExpr(groupByVisitor, null);
}
#end_block

#method_before
protected void inlineDeclaredUdfs(boolean inlineUdfs) throws CompilationException {
    List<FunctionSignature> funIds = new ArrayList<FunctionSignature>();
    for (FunctionDecl fdecl : declaredFunctions) {
        funIds.add(fdecl.getSignature());
    }
    List<FunctionDecl> usedStoredFunctionDecls = new ArrayList<>();
    for (Expression topLevelExpr : topExpr.getDirectlyEnclosedExpressions()) {
        usedStoredFunctionDecls.addAll(FunctionUtil.retrieveUsedStoredFunctions(metadataProvider, topLevelExpr, funIds, null, expr -> getFunctionCalls(expr), func -> functionRepository.getFunctionDecl(func), (signature, sourceLoc) -> FunctionMapUtil.normalizeBuiltinFunctionSignature(signature, false, sourceLoc)));
    }
    declaredFunctions.addAll(usedStoredFunctionDecls);
    if (inlineUdfs && !declaredFunctions.isEmpty()) {
        SqlppInlineUdfsVisitor visitor = new SqlppInlineUdfsVisitor(context, new SqlppFunctionBodyRewriterFactory(), /* the rewriter for function bodies expressions*/
        declaredFunctions, metadataProvider);
        while (topExpr.accept(visitor, declaredFunctions)) {
        // loop until no more changes
        }
    }
    declaredFunctions.removeAll(usedStoredFunctionDecls);
}
#method_after
protected void inlineDeclaredUdfs(boolean inlineUdfs) throws CompilationException {
    List<FunctionSignature> funIds = new ArrayList<FunctionSignature>();
    for (FunctionDecl fdecl : declaredFunctions) {
        funIds.add(fdecl.getSignature());
    }
    List<FunctionDecl> usedStoredFunctionDecls = new ArrayList<>();
    for (Expression topLevelExpr : topExpr.getDirectlyEnclosedExpressions()) {
        usedStoredFunctionDecls.addAll(FunctionUtil.retrieveUsedStoredFunctions(metadataProvider, topLevelExpr, funIds, null, expr -> getFunctionCalls(expr), func -> functionRepository.getFunctionDecl(func), (signature, sourceLoc) -> FunctionMapUtil.normalizeBuiltinFunctionSignature(signature, false, sourceLoc)));
    }
    declaredFunctions.addAll(usedStoredFunctionDecls);
    if (inlineUdfs && !declaredFunctions.isEmpty()) {
        SqlppInlineUdfsVisitor visitor = new SqlppInlineUdfsVisitor(context, new SqlppFunctionBodyRewriterFactory(), /* the rewriter for function bodies expressions*/
        declaredFunctions, metadataProvider);
        while (rewriteTopExpr(visitor, declaredFunctions)) {
        // loop until no more changes
        }
    }
    declaredFunctions.removeAll(usedStoredFunctionDecls);
}
#end_block

#method_before
@Override
public Set<VariableExpr> getExternalVariables(Expression expr) throws CompilationException {
    Set<VariableExpr> freeVars = getFreeVariables(expr);
    Set<VariableExpr> extVars = new HashSet<>();
    for (VariableExpr ve : freeVars) {
        if (SqlppVariableUtil.isExternalVariableReference(ve)) {
            extVars.add(ve);
        }
    }
    return extVars;
}
#method_after
@Override
public Set<VariableExpr> getExternalVariables(Expression expr) throws CompilationException {
    Set<VariableExpr> freeVars = SqlppVariableUtil.getFreeVariables(expr);
    Set<VariableExpr> extVars = new HashSet<>();
    for (VariableExpr ve : freeVars) {
        if (SqlppVariableUtil.isExternalVariableReference(ve)) {
            extVars.add(ve);
        }
    }
    return extVars;
}
#end_block

#method_before
@Override
public Void visit(WindowExpression winExpr, Void arg) throws CompilationException {
    winExpr.getExpr().accept(this, arg);
    if (winExpr.hasPartitionList()) {
        for (Expression expr : winExpr.getPartitionList()) {
            expr.accept(this, arg);
        }
    }
    for (Expression expr : winExpr.getOrderbyList()) {
        expr.accept(this, arg);
    }
    return null;
}
#method_after
@Override
public Void visit(WindowExpression winExpr, Void arg) throws CompilationException {
    if (winExpr.hasPartitionList()) {
        for (Expression expr : winExpr.getPartitionList()) {
            expr.accept(this, arg);
        }
    }
    if (winExpr.hasOrderByList()) {
        for (Expression expr : winExpr.getOrderbyList()) {
            expr.accept(this, arg);
        }
    }
    if (winExpr.hasFrameStartExpr()) {
        winExpr.getFrameStartExpr().accept(this, arg);
    }
    if (winExpr.hasFrameEndExpr()) {
        winExpr.getFrameEndExpr().accept(this, arg);
    }
    if (winExpr.hasWindowFieldList()) {
        for (Pair<Expression, Identifier> p : winExpr.getWindowFieldList()) {
            p.first.accept(this, arg);
        }
    }
    for (Expression expr : winExpr.getExprList()) {
        expr.accept(this, arg);
    }
    return null;
}
#end_block

#method_before
@Override
public Void visit(WindowExpression winExpr, Void arg) throws CompilationException {
    winExpr.getExpr().accept(this, arg);
    if (winExpr.hasPartitionList()) {
        for (Expression expr : winExpr.getPartitionList()) {
            expr.accept(this, arg);
        }
    }
    for (Expression expr : winExpr.getOrderbyList()) {
        expr.accept(this, arg);
    }
    return null;
}
#method_after
@Override
public Void visit(ListSliceExpression expression, Void arg) throws CompilationException {
    expression.getExpr().accept(this, arg);
    expression.getStartIndexExpression().accept(this, arg);
    if (expression.hasEndExpression()) {
        expression.getEndIndexExpression().accept(this, arg);
    }
    return null;
}
#end_block

#method_before
public void optimize() throws AlgebricksException {
    if (plan == null) {
        return;
    }
    if (AlgebricksConfig.ALGEBRICKS_LOGGER.isTraceEnabled()) {
        AlgebricksConfig.ALGEBRICKS_LOGGER.trace("Starting logical optimizations.\n");
    }
    logPlanAt("Logical Plan", Level.TRACE);
    runLogicalOptimizationSets(plan, logicalRewrites);
    computeSchemaBottomUpForPlan(plan);
    runPhysicalOptimizationSets(plan, physicalRewrites);
    logPlanAt("Optimized Plan", Level.TRACE);
}
#method_after
public void optimize() throws AlgebricksException {
    if (plan == null) {
        return;
    }
    logPlanAt("Plan Before Optimization", Level.TRACE);
    runLogicalOptimizationSets(plan, logicalRewrites);
    computeSchemaBottomUpForPlan(plan);
    runPhysicalOptimizationSets(plan, physicalRewrites);
    logPlanAt("Plan After Optimization", Level.TRACE);
}
#end_block

#method_before
@Override
public void run() {
    while (true) {
        try {
            int n = selector.select();
            collectOutstandingWork();
            if (!workingPendingConnections.isEmpty()) {
                for (InetSocketAddress address : workingPendingConnections) {
                    SocketChannel channel = SocketChannel.open();
                    register(channel);
                    boolean connect = false;
                    boolean failure = false;
                    try {
                        connect = channel.connect(address);
                    } catch (IOException e) {
                        failure = true;
                        synchronized (connectionListener) {
                            connectionListener.connectionFailure(address, e);
                        }
                    }
                    if (!failure) {
                        if (!connect) {
                            SelectionKey key = channel.register(selector, SelectionKey.OP_CONNECT);
                            key.attach(address);
                        } else {
                            SelectionKey key = channel.register(selector, 0);
                            socketConnected(key, channel);
                        }
                    }
                }
                workingPendingConnections.clear();
            }
            if (!workingIncomingConnections.isEmpty()) {
                for (SocketChannel channel : workingIncomingConnections) {
                    register(channel);
                    final SelectionKey sKey = channel.register(selector, 0);
                    ISocketChannel socketChannel = socketChannelFactory.createServerChannel(channel);
                    if (socketChannel.requiresHandshake()) {
                        asyncHandshake(socketChannel, sKey, INCOMING);
                    } else {
                        connectionAccepted(socketChannel, sKey);
                    }
                }
                workingIncomingConnections.clear();
            }
            if (n > 0) {
                Iterator<SelectionKey> i = selector.selectedKeys().iterator();
                while (i.hasNext()) {
                    SelectionKey key = i.next();
                    i.remove();
                    SelectableChannel sc = key.channel();
                    boolean readable = key.isReadable();
                    boolean writable = key.isWritable();
                    if (readable || writable) {
                        TCPConnection connection = (TCPConnection) key.attachment();
                        try {
                            connection.getEventListener().notifyIOReady(connection, readable, writable);
                        } catch (Exception e) {
                            LOGGER.error("Unexpected tcp io error in connection {}", connection, e);
                            connection.getEventListener().notifyIOError(e);
                            connection.close();
                            synchronized (connectionListener) {
                                connectionListener.connectionClosed(connection);
                            }
                            continue;
                        }
                    }
                    if (key.isAcceptable()) {
                        assert sc == serverSocketChannel;
                        SocketChannel channel = serverSocketChannel.accept();
                        distributeIncomingConnection(channel);
                    } else if (key.isConnectable()) {
                        SocketChannel channel = (SocketChannel) sc;
                        boolean finishConnect = false;
                        try {
                            finishConnect = channel.finishConnect();
                        } catch (IOException e) {
                            LOGGER.error("Failed to finish connect to channel {}", key.attachment(), e);
                            key.cancel();
                            synchronized (connectionListener) {
                                connectionListener.connectionFailure((InetSocketAddress) key.attachment(), e);
                            }
                        }
                        if (finishConnect) {
                            socketConnected(key, channel);
                        }
                    }
                }
            }
        } catch (Exception e) {
            LOGGER.error("Error in TCPEndpoint {}", TCPEndpoint.this, e);
        }
    }
}
#method_after
@Override
public void run() {
    while (true) {
        try {
            int n = selector.select();
            collectOutstandingWork();
            if (!workingPendingConnections.isEmpty()) {
                for (InetSocketAddress address : workingPendingConnections) {
                    SocketChannel channel = SocketChannel.open();
                    register(channel);
                    boolean connect = false;
                    boolean failure = false;
                    try {
                        connect = channel.connect(address);
                    } catch (IOException e) {
                        failure = true;
                        synchronized (connectionListener) {
                            connectionListener.connectionFailure(address, e);
                        }
                    }
                    if (!failure) {
                        if (!connect) {
                            SelectionKey key = channel.register(selector, SelectionKey.OP_CONNECT);
                            key.attach(address);
                        } else {
                            socketConnected(address, channel);
                        }
                    }
                }
                workingPendingConnections.clear();
            }
            if (!workingIncomingConnections.isEmpty()) {
                for (SocketChannel channel : workingIncomingConnections) {
                    register(channel);
                    connectionReceived(channel);
                }
                workingIncomingConnections.clear();
            }
            if (!handshakeCompletedConnections.isEmpty()) {
                for (final PendingHandshakeConnection conn : handshakeCompletedConnections) {
                    handshakeCompleted(conn);
                }
                handshakeCompletedConnections.clear();
            }
            if (n > 0) {
                Iterator<SelectionKey> i = selector.selectedKeys().iterator();
                while (i.hasNext()) {
                    SelectionKey key = i.next();
                    i.remove();
                    SelectableChannel sc = key.channel();
                    boolean readable = key.isReadable();
                    boolean writable = key.isWritable();
                    if (readable || writable) {
                        TCPConnection connection = (TCPConnection) key.attachment();
                        try {
                            connection.getEventListener().notifyIOReady(connection, readable, writable);
                        } catch (Exception e) {
                            LOGGER.error("Unexpected tcp io error in connection {}", connection, e);
                            connection.getEventListener().notifyIOError(e);
                            connection.close();
                            synchronized (connectionListener) {
                                connectionListener.connectionClosed(connection);
                            }
                            continue;
                        }
                    }
                    if (key.isAcceptable()) {
                        assert sc == serverSocketChannel;
                        SocketChannel channel = serverSocketChannel.accept();
                        distributeIncomingConnection(channel);
                    } else if (key.isConnectable()) {
                        SocketChannel channel = (SocketChannel) sc;
                        boolean finishConnect = false;
                        try {
                            finishConnect = channel.finishConnect();
                        } catch (IOException e) {
                            LOGGER.error("Failed to finish connect to channel {}", key.attachment(), e);
                            key.cancel();
                            synchronized (connectionListener) {
                                connectionListener.connectionFailure((InetSocketAddress) key.attachment(), e);
                            }
                        }
                        if (finishConnect) {
                            socketConnected((InetSocketAddress) key.attachment(), channel);
                        }
                    }
                }
            }
        } catch (Exception e) {
            LOGGER.error("Error in TCPEndpoint {}", TCPEndpoint.this, e);
        }
    }
}
#end_block

#method_before
private void socketConnected(SelectionKey key, SocketChannel channel) {
    ISocketChannel socketChannel = socketChannelFactory.createClientChannel(channel);
    if (socketChannel.requiresHandshake()) {
        asyncHandshake(socketChannel, key, OUTGOING);
    } else {
        connectionEstablished(socketChannel, key);
    }
}
#method_after
private void socketConnected(InetSocketAddress remoteAddress, SocketChannel channel) {
    final ISocketChannel socketChannel = socketChannelFactory.createClientChannel(channel);
    final PendingHandshakeConnection conn = new PendingHandshakeConnection(socketChannel, remoteAddress, OUTGOING);
    if (socketChannel.requiresHandshake()) {
        asyncHandshake(conn);
    } else {
        conn.handshakeSuccess = true;
        handshakeCompletedConnections.add(conn);
    }
}
#end_block

#method_before
private void asyncHandshake(ISocketChannel socketChannel, SelectionKey key, ConnectionType connectionType) {
    CompletableFuture.supplyAsync(socketChannel::handshake).exceptionally(ex -> false).thenAccept(handshakeSuccess -> handleHandshakeCompletion(handshakeSuccess, socketChannel, key, connectionType));
}
#method_after
private void asyncHandshake(PendingHandshakeConnection connection) {
    CompletableFuture.supplyAsync(connection.socketChannel::handshake).exceptionally(ex -> false).thenAccept(handshakeSuccess -> handleHandshakeCompletion(handshakeSuccess, connection));
}
#end_block

#method_before
private void handleHandshakeCompletion(Boolean handshakeSuccess, ISocketChannel socketChannel, SelectionKey key, ConnectionType connectionType) {
    if (handshakeSuccess) {
        if (connectionType == OUTGOING) {
            connectionEstablished(socketChannel, key);
        } else if (connectionType == INCOMING) {
            connectionAccepted(socketChannel, key);
        }
    } else {
        handleHandshakeFailure(socketChannel, key);
    }
}
#method_after
private void handleHandshakeCompletion(Boolean handshakeSuccess, PendingHandshakeConnection conn) {
    conn.handshakeSuccess = handshakeSuccess;
    handshakeCompletedConnections.add(conn);
    selector.wakeup();
}
#end_block

#method_before
private void connectionEstablished(ISocketChannel socketChannel, SelectionKey key) {
    TCPConnection connection = createConnection(socketChannel, key, OUTGOING);
    synchronized (connectionListener) {
        connectionListener.connectionEstablished(connection);
    }
}
#method_after
private void connectionEstablished(TCPConnection connection) {
    synchronized (connectionListener) {
        connectionListener.connectionEstablished(connection);
    }
}
#end_block

#method_before
private void connectionAccepted(ISocketChannel socketChannel, SelectionKey key) {
    TCPConnection connection = createConnection(socketChannel, key, INCOMING);
    synchronized (connectionListener) {
        connectionListener.acceptedConnection(connection);
    }
}
#method_after
private void connectionAccepted(TCPConnection connection) {
    synchronized (connectionListener) {
        connectionListener.acceptedConnection(connection);
    }
}
#end_block

#method_before
private void handleHandshakeFailure(ISocketChannel socketChannel, SelectionKey key) {
    key.cancel();
    NetworkUtil.closeQuietly(socketChannel);
    synchronized (connectionListener) {
        connectionListener.connectionFailure((InetSocketAddress) key.attachment(), new IOException("handshake failure"));
    }
}
#method_after
private void handleHandshakeFailure(PendingHandshakeConnection conn) {
    NetworkUtil.closeQuietly(conn.socketChannel);
    if (conn.type == OUTGOING) {
        synchronized (connectionListener) {
            connectionListener.connectionFailure(conn.address, new IOException("handshake failure"));
        }
    }
}
#end_block

#method_before
private static Query makeConnectionQuery(FeedConnection feedConnection) throws AlgebricksException {
    // Construct from clause
    VarIdentifier fromVarId = SqlppVariableUtil.toInternalVariableIdentifier(feedConnection.getFeedName());
    VariableExpr fromTermLeftExpr = new VariableExpr(fromVarId);
    // TODO: remove target feedid from args list (xikui)
    // TODO: Get rid of this INTAKE
    List<Expression> exprList = addArgs(feedConnection.getDataverseName(), feedConnection.getFeedId().getEntityName(), feedConnection.getFeedId().getEntityName(), FeedRuntimeType.INTAKE.toString(), feedConnection.getDatasetName(), feedConnection.getOutputType());
    CallExpr datasrouceCallFunction = new CallExpr(new FunctionSignature(BuiltinFunctions.FEED_COLLECT), exprList);
    FromTerm fromterm = new FromTerm(datasrouceCallFunction, fromTermLeftExpr, null, null);
    FromClause fromClause = new FromClause(Arrays.asList(fromterm));
    WhereClause whereClause = null;
    if (feedConnection.getWhereClauseBody().length() != 0) {
        String whereClauseExpr = feedConnection.getWhereClauseBody() + ";";
        IParserFactory sqlppParserFactory = new SqlppParserFactory();
        IParser sqlppParser = sqlppParserFactory.createParser(whereClauseExpr);
        List<Statement> stmts = sqlppParser.parse();
        if (stmts.size() != 1) {
            throw new CompilationException("Exceptions happened in processing where clause.");
        }
        Query whereClauseQuery = (Query) stmts.get(0);
        whereClause = new WhereClause(whereClauseQuery.getBody());
    }
    // Attaching functions
    int varIdx = 1;
    Expression previousVarExpr = fromTermLeftExpr;
    for (FunctionSignature functionSignature : feedConnection.getAppliedFunctions()) {
        CallExpr functionCallExpr = new CallExpr(functionSignature, addArgs(previousVarExpr));
        previousVarExpr = functionCallExpr;
    }
    // ArrayList<LetClause> letClauses = new ArrayList<>();
    // for (FunctionSignature funcSig : feedConnection.getAppliedFunctions()) {
    // VarIdentifier intermediateVar = SqlppVariableUtil
    // .toInternalVariableIdentifier(FEED_DATAFLOW_INTERMEIDATE_VAL_PREFIX + String.valueOf(varIdx));
    // VariableExpr intermediateVarExpr = new VariableExpr(intermediateVar);
    // CallExpr functionCallExpr = new CallExpr(funcSig, addArgs(previousVarExpr));
    // previousVarExpr = intermediateVarExpr;
    // LetClause letClause = new LetClause(intermediateVarExpr, functionCallExpr);
    // letClauses.add(letClause);
    // varIdx++;
    // }
    // Constructing select clause
    SelectElement selectElement = new SelectElement(previousVarExpr);
    SelectClause selectClause = new SelectClause(selectElement, null, false);
    SelectBlock selectBlock = new SelectBlock(selectClause, fromClause, null, whereClause, null, null, null);
    SelectSetOperation selectSetOperation = new SelectSetOperation(new SetOperationInput(selectBlock, null), null);
    SelectExpression body = new SelectExpression(null, selectSetOperation, null, null, true);
    Query query = new Query(false, true, body, 0);
    return query;
}
#method_after
private static Query makeConnectionQuery(FeedConnection feedConnection) throws AlgebricksException {
    // Construct from clause
    VarIdentifier fromVarId = SqlppVariableUtil.toInternalVariableIdentifier(feedConnection.getFeedName());
    VariableExpr fromTermLeftExpr = new VariableExpr(fromVarId);
    // TODO: remove target feedid from args list (xikui)
    // TODO: Get rid of this INTAKE
    List<Expression> exprList = addArgs(feedConnection.getDataverseName(), feedConnection.getFeedId().getEntityName(), feedConnection.getFeedId().getEntityName(), FeedRuntimeType.INTAKE.toString(), feedConnection.getDatasetName(), feedConnection.getOutputType());
    CallExpr datasrouceCallFunction = new CallExpr(new FunctionSignature(BuiltinFunctions.FEED_COLLECT), exprList);
    FromTerm fromterm = new FromTerm(datasrouceCallFunction, fromTermLeftExpr, null, null);
    FromClause fromClause = new FromClause(Arrays.asList(fromterm));
    WhereClause whereClause = null;
    if (feedConnection.getWhereClauseBody().length() != 0) {
        String whereClauseExpr = feedConnection.getWhereClauseBody() + ";";
        IParserFactory sqlppParserFactory = new SqlppParserFactory();
        IParser sqlppParser = sqlppParserFactory.createParser(whereClauseExpr);
        List<Statement> stmts = sqlppParser.parse();
        if (stmts.size() != 1) {
            throw new CompilationException("Exceptions happened in processing where clause.");
        }
        Query whereClauseQuery = (Query) stmts.get(0);
        whereClause = new WhereClause(whereClauseQuery.getBody());
    }
    // Attaching functions
    Expression previousVarExpr = fromTermLeftExpr;
    for (FunctionSignature functionSignature : feedConnection.getAppliedFunctions()) {
        CallExpr functionCallExpr = new CallExpr(functionSignature, addArgs(previousVarExpr));
        previousVarExpr = functionCallExpr;
    }
    // Constructing select clause
    SelectElement selectElement = new SelectElement(previousVarExpr);
    SelectClause selectClause = new SelectClause(selectElement, null, false);
    SelectBlock selectBlock = new SelectBlock(selectClause, fromClause, null, whereClause, null, null, null);
    SelectSetOperation selectSetOperation = new SelectSetOperation(new SetOperationInput(selectBlock, null), null);
    SelectExpression body = new SelectExpression(null, selectSetOperation, null, null, true);
    Query query = new Query(false, true, body, 0);
    return query;
}
#end_block

#method_before
private void visit(List<Expression> exprs, Collection<VariableExpr> arg) throws CompilationException {
    for (Expression expr : exprs) {
        expr.accept(this, arg);
    }
}
#method_after
@Override
public Void visit(ListSliceExpression expression, Collection<VariableExpr> freeVars) throws CompilationException {
    expression.getExpr().accept(this, freeVars);
    expression.getStartIndexExpression().accept(this, freeVars);
    // End index expression can be null (optional)
    if (expression.hasEndExpression()) {
        expression.getEndIndexExpression().accept(this, freeVars);
    }
    return null;
}
#end_block

#method_before
private List<Expression> visit(List<Expression> exprs, ILangExpression arg) throws CompilationException {
    List<Expression> newExprList = new ArrayList<>();
    for (Expression expr : exprs) {
        newExprList.add(visit(expr, arg));
    }
    return newExprList;
}
#method_after
@Override
public Expression visit(ListSliceExpression expression, ILangExpression arg) throws CompilationException {
    expression.setExpr(visit(expression.getExpr(), expression));
    expression.setStartIndexExpression(visit(expression.getStartIndexExpression(), arg));
    // End index expression can be null (optional)
    if (expression.hasEndExpression()) {
        expression.setEndIndexExpression(visit(expression.getEndIndexExpression(), arg));
    }
    return expression;
}
#end_block

#method_before
private List<Expression> visit(List<Expression> exprs, ILangExpression arg) throws CompilationException {
    List<Expression> newExprList = new ArrayList<>();
    for (Expression expr : exprs) {
        newExprList.add(visit(expr, arg));
    }
    return newExprList;
}
#method_after
@Override
public Expression visit(ListSliceExpression expression, ILangExpression arg) throws CompilationException {
    // This functionality is not supported for AQL
    return null;
}
#end_block

#method_before
@Override
public Void visit(IndexAccessor ia, Void arg) throws CompilationException {
    ia.getExpr().accept(this, arg);
    return null;
}
#method_after
@Override
public Void visit(IndexAccessor ia, Void arg) throws CompilationException {
    ia.getExpr().accept(this, arg);
    if (!ia.isAny()) {
        ia.getIndexExpr().accept(this, arg);
    }
    return null;
}
#end_block

#method_before
@Override
public Void visit(FunctionDecl fd, Void arg) throws CompilationException {
    return null;
}
#method_after
@Override
public Void visit(ListSliceExpression expression, Void arg) throws CompilationException {
    expression.getExpr().accept(this, arg);
    expression.getStartIndexExpression().accept(this, arg);
    if (expression.hasEndExpression()) {
        expression.getEndIndexExpression().accept(this, arg);
    }
    return null;
}
#end_block

#method_before
@Override
public Boolean visit(WindowExpression windowExpression, ILangExpression arg) throws CompilationException {
    return false;
}
#method_after
@Override
public Boolean visit(ListSliceExpression expression, ILangExpression expr) throws CompilationException {
    return false;
}
#end_block

#method_before
@Override
public Boolean visit(IndexAccessor ia, ILangExpression parentSelectBlock) throws CompilationException {
    return ia.getExpr().accept(this, parentSelectBlock);
}
#method_after
@Override
public Boolean visit(IndexAccessor ia, ILangExpression parentSelectBlock) throws CompilationException {
    if (ia.getExpr().accept(this, parentSelectBlock)) {
        return true;
    }
    if (!ia.isAny() && ia.getIndexExpr().accept(this, parentSelectBlock)) {
        return true;
    }
    return false;
}
#end_block

#method_before
@Override
public Boolean visit(WindowExpression winExpr, ILangExpression arg) throws CompilationException {
    return winExpr.getExpr().accept(this, arg) || (winExpr.hasPartitionList() && visitExprList(winExpr.getPartitionList(), arg)) || visitExprList(winExpr.getOrderbyList(), arg);
}
#method_after
@Override
public Boolean visit(ListSliceExpression expression, ILangExpression parentSelectBlock) throws CompilationException {
    // Expression
    if (expression.getExpr().accept(this, parentSelectBlock)) {
        return true;
    }
    // Start index expression
    if (expression.getStartIndexExpression().accept(this, parentSelectBlock)) {
        return true;
    }
    // End index expression
    if (expression.hasEndExpression() && expression.getEndIndexExpression().accept(this, parentSelectBlock)) {
        return true;
    }
    return false;
}
#end_block

#method_before
private boolean visit(ILangExpression langExpr, ILangExpression arg) throws CompilationException {
    if (langExpr == null) {
        return false;
    }
    return langExpr.accept(this, arg);
}
#method_after
@Override
public Boolean visit(ListSliceExpression expression, ILangExpression arg) throws CompilationException {
    return visit(expression.getExpr(), arg) || visit(expression.getStartIndexExpression(), arg) || visit(expression.getEndIndexExpression(), arg);
}
#end_block

#method_before
@Override
public Pair<ILogicalOperator, LogicalVariable> visit(IndexAccessor ia, Mutable<ILogicalOperator> tupSource) throws CompilationException {
    SourceLocation sourceLoc = ia.getSourceLocation();
    Pair<ILogicalExpression, Mutable<ILogicalOperator>> p = langExprToAlgExpression(ia.getExpr(), tupSource);
    LogicalVariable v = context.newVar();
    AbstractFunctionCallExpression f;
    if (ia.isAny()) {
        f = new ScalarFunctionCallExpression(FunctionUtil.getFunctionInfo(BuiltinFunctions.ANY_COLLECTION_MEMBER));
        f.getArguments().add(new MutableObject<>(p.first));
        f.setSourceLocation(sourceLoc);
    } else {
        Pair<ILogicalExpression, Mutable<ILogicalOperator>> indexPair = langExprToAlgExpression(ia.getIndexExpr(), tupSource);
        f = new ScalarFunctionCallExpression(FunctionUtil.getFunctionInfo(BuiltinFunctions.GET_ITEM));
        f.getArguments().add(new MutableObject<>(p.first));
        f.getArguments().add(new MutableObject<>(indexPair.first));
        f.setSourceLocation(sourceLoc);
    }
    AssignOperator a = new AssignOperator(v, new MutableObject<>(f));
    a.getInputs().add(p.second);
    a.setSourceLocation(sourceLoc);
    return new Pair<>(a, v);
}
#method_after
@Override
public Pair<ILogicalOperator, LogicalVariable> visit(IndexAccessor ia, Mutable<ILogicalOperator> tupSource) throws CompilationException {
    SourceLocation sourceLoc = ia.getSourceLocation();
    // Expression pair
    Pair<ILogicalExpression, Mutable<ILogicalOperator>> expressionPair = langExprToAlgExpression(ia.getExpr(), tupSource);
    LogicalVariable v = context.newVar();
    AbstractFunctionCallExpression f;
    // Index expression
    Pair<ILogicalExpression, Mutable<ILogicalOperator>> indexPair = null;
    if (ia.isAny()) {
        f = new ScalarFunctionCallExpression(FunctionUtil.getFunctionInfo(BuiltinFunctions.ANY_COLLECTION_MEMBER));
        f.getArguments().add(new MutableObject<>(expressionPair.first));
    } else {
        indexPair = langExprToAlgExpression(ia.getIndexExpr(), expressionPair.second);
        f = new ScalarFunctionCallExpression(FunctionUtil.getFunctionInfo(BuiltinFunctions.GET_ITEM));
        f.getArguments().add(new MutableObject<>(expressionPair.first));
        f.getArguments().add(new MutableObject<>(indexPair.first));
    }
    f.setSourceLocation(sourceLoc);
    AssignOperator a = new AssignOperator(v, new MutableObject<>(f));
    if (ia.isAny()) {
        a.getInputs().add(expressionPair.second);
    } else {
        // NOSONAR: Called only if value exists
        a.getInputs().add(indexPair.second);
    }
    a.setSourceLocation(sourceLoc);
    return new Pair<>(a, v);
}
#end_block

#method_before
@Override
public Pair<ILogicalOperator, LogicalVariable> visit(LimitClause lc, Mutable<ILogicalOperator> tupSource) throws CompilationException {
    SourceLocation sourceLoc = lc.getSourceLocation();
    LimitOperator opLim;
    Pair<ILogicalExpression, Mutable<ILogicalOperator>> p1 = langExprToAlgExpression(lc.getLimitExpr(), tupSource);
    ILogicalExpression maxObjectsExpr = createLimitOffsetValueExpression(p1.first, lc.getLimitExpr().getSourceLocation());
    Expression offset = lc.getOffset();
    if (offset != null) {
        Pair<ILogicalExpression, Mutable<ILogicalOperator>> p2 = langExprToAlgExpression(offset, p1.second);
        ILogicalExpression offsetExpr = createLimitOffsetValueExpression(p2.first, lc.getOffset().getSourceLocation());
        opLim = new LimitOperator(maxObjectsExpr, offsetExpr);
        opLim.getInputs().add(p2.second);
        opLim.setSourceLocation(sourceLoc);
    } else {
        opLim = new LimitOperator(maxObjectsExpr);
        opLim.getInputs().add(p1.second);
        opLim.setSourceLocation(sourceLoc);
    }
    return new Pair<>(opLim, null);
}
#method_after
@Override
public Pair<ILogicalOperator, LogicalVariable> visit(ListSliceExpression expression, Mutable<ILogicalOperator> tupSource) throws CompilationException {
    SourceLocation sourceLoc = expression.getSourceLocation();
    // Expression pair
    Pair<ILogicalExpression, Mutable<ILogicalOperator>> expressionPair = langExprToAlgExpression(expression.getExpr(), tupSource);
    LogicalVariable variable = context.newVar();
    AbstractFunctionCallExpression functionCallExpression;
    // Start index expression pair
    Pair<ILogicalExpression, Mutable<ILogicalOperator>> startIndexPair = langExprToAlgExpression(expression.getStartIndexExpression(), expressionPair.second);
    // End index expression can be null (optional)
    // End index expression pair
    Pair<ILogicalExpression, Mutable<ILogicalOperator>> endIndexPair = null;
    if (expression.hasEndExpression()) {
        endIndexPair = langExprToAlgExpression(expression.getEndIndexExpression(), startIndexPair.second);
        functionCallExpression = new ScalarFunctionCallExpression(FunctionUtil.getFunctionInfo(BuiltinFunctions.ARRAY_SLICE_WITH_END_POSITION));
        functionCallExpression.getArguments().add(new MutableObject<>(expressionPair.first));
        functionCallExpression.getArguments().add(new MutableObject<>(startIndexPair.first));
        functionCallExpression.getArguments().add(new MutableObject<>(endIndexPair.first));
        functionCallExpression.setSourceLocation(sourceLoc);
    } else {
        functionCallExpression = new ScalarFunctionCallExpression(FunctionUtil.getFunctionInfo(BuiltinFunctions.ARRAY_SLICE_WITHOUT_END_POSITION));
        functionCallExpression.getArguments().add(new MutableObject<>(expressionPair.first));
        functionCallExpression.getArguments().add(new MutableObject<>(startIndexPair.first));
        functionCallExpression.setSourceLocation(sourceLoc);
    }
    AssignOperator assignOperator = new AssignOperator(variable, new MutableObject<>(functionCallExpression));
    if (expression.hasEndExpression()) {
        // NOSONAR: Called only if value exists
        assignOperator.getInputs().add(endIndexPair.second);
    } else {
        assignOperator.getInputs().add(startIndexPair.second);
    }
    assignOperator.setSourceLocation(sourceLoc);
    return new Pair<>(assignOperator, variable);
}
#end_block

#method_before
@Override
public ILangExpression visit(WindowExpression winExpr, Void arg) throws CompilationException {
    Expression newExpr = (Expression) winExpr.getExpr().accept(this, arg);
    List<Expression> newPartitionList = winExpr.hasPartitionList() ? copyExprList(winExpr.getPartitionList(), arg) : null;
    List<Expression> newOrderbyList = copyExprList(winExpr.getOrderbyList(), arg);
    List<OrderbyClause.OrderModifier> newOrderbyModifierList = new ArrayList<>(winExpr.getOrderbyModifierList());
    WindowExpression copy = new WindowExpression(newExpr, newPartitionList, newOrderbyList, newOrderbyModifierList);
    copy.setSourceLocation(winExpr.getSourceLocation());
    copy.addHints(winExpr.getHints());
    return copy;
}
#method_after
@Override
public Expression visit(ListSliceExpression expression, Void arg) throws CompilationException {
    Expression expr = (Expression) expression.getExpr().accept(this, arg);
    Expression startIndexExpression = (Expression) expression.getStartIndexExpression().accept(this, arg);
    // End index expression can be null (optional)
    Expression endIndexExpression = null;
    if (expression.hasEndExpression()) {
        endIndexExpression = (Expression) expression.getEndIndexExpression().accept(this, arg);
    }
    ListSliceExpression copy = new ListSliceExpression(expr, startIndexExpression, endIndexExpression);
    copy.setSourceLocation(expression.getSourceLocation());
    copy.addHints(expression.getHints());
    return copy;
}
#end_block

#method_before
@Override
public Pair<ILangExpression, VariableSubstitutionEnvironment> visit(VariableExpr v, VariableSubstitutionEnvironment env) throws CompilationException {
    return new Pair<>(rewriteVariableExpr(v, env), env);
}
#method_after
@Override
public Pair<ILangExpression, VariableSubstitutionEnvironment> visit(ListSliceExpression expression, VariableSubstitutionEnvironment env) throws CompilationException {
    Pair<ILangExpression, VariableSubstitutionEnvironment> expressionPair = expression.getExpr().accept(this, env);
    Expression startIndexExpression;
    Expression endIndexExpression = null;
    // Start index expression
    Pair<ILangExpression, VariableSubstitutionEnvironment> startExpressionPair = expression.getStartIndexExpression().accept(this, env);
    startIndexExpression = (Expression) startExpressionPair.first;
    // End index expression (optional)
    if (expression.hasEndExpression()) {
        Pair<ILangExpression, VariableSubstitutionEnvironment> endExpressionPair = expression.getEndIndexExpression().accept(this, env);
        endIndexExpression = (Expression) endExpressionPair.first;
    }
    // Resulted expression
    ListSliceExpression resultExpression = new ListSliceExpression((Expression) expressionPair.first, startIndexExpression, endIndexExpression);
    resultExpression.setSourceLocation(expression.getSourceLocation());
    resultExpression.addHints(expression.getHints());
    return new Pair<>(resultExpression, env);
}
#end_block

#method_before
@Override
public Void visit(CompactStatement del, Integer step) throws CompilationException {
    return null;
}
#method_after
@Override
public Void visit(ListSliceExpression expression, Integer step) throws CompilationException {
    out.println(skip(step) + "ListSliceExpression [");
    expression.getExpr().accept(this, step + 1);
    out.print(skip(step + 1) + "Index: ");
    expression.getStartIndexExpression().accept(this, step + 1);
    out.println(skip(step) + ":");
    // End index expression can be null (optional)
    if (expression.hasEndExpression()) {
        expression.getEndIndexExpression().accept(this, step + 1);
    }
    out.println(skip(step) + "]");
    return null;
}
#end_block

#method_before
public Configuration createConfiguration(ConfigurationBuilder<BuiltConfiguration> builder) {
    String nodeId = config.getNodeId();
    String logDir = config.getLogDir();
    builder.setStatusLevel(Level.WARN);
    builder.setConfigurationName("RollingBuilder");
    // create a rolling file appender
    LayoutComponentBuilder defaultLayout = builder.newLayout("PatternLayout").addAttribute("pattern", "%d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n");
    ComponentBuilder triggeringPolicy = builder.newComponent("Policies").addComponent(builder.newComponent("CronTriggeringPolicy").addAttribute("schedule", "0 0 0 * * ?")).addComponent(builder.newComponent("SizeBasedTriggeringPolicy").addAttribute("size", "50M"));
    AppenderComponentBuilder defaultRoll = builder.newAppender("default", "RollingFile").addAttribute("fileName", FileUtil.joinPath(logDir, "nc-" + nodeId + ".log")).addAttribute("filePattern", FileUtil.joinPath(logDir, "nc-" + nodeId + "-%d{MM-dd-yy-ss}.log.gz")).add(defaultLayout).addComponent(triggeringPolicy);
    builder.add(defaultRoll);
    // create the new logger
    builder.add(builder.newRootLogger(Level.INFO).add(builder.newAppenderRef("default")));
    LayoutComponentBuilder accessLayout = builder.newLayout("PatternLayout").addAttribute("pattern", "%m%n");
    AppenderComponentBuilder accessRoll = builder.newAppender("access", "RollingFile").addAttribute("fileName", FileUtil.joinPath(logDir, "access-" + nodeId + ".log")).addAttribute("filePattern", FileUtil.joinPath(logDir, "access-" + nodeId + "-%d{MM-dd-yy-ss}.log.gz")).add(accessLayout).addComponent(triggeringPolicy);
    builder.add(accessRoll);
    builder.add(builder.newLogger("org.apache.hyracks.http.server.CLFLogger", Level.forName("ACCESS", 550)).add(builder.newAppenderRef("access")).addAttribute("additivity", false));
    LayoutComponentBuilder traceLayout = builder.newLayout("PatternLayout").addAttribute("pattern", "%m%n");
    AppenderComponentBuilder traceRoll = builder.newAppender("trace", "RollingFile").addAttribute("fileName", logDir + "trace-" + nodeId + ".log").addAttribute("filePattern", logDir + "trace-" + nodeId + "-%d{MM-dd-yy-ss}.log.gz").add(traceLayout).addComponent(triggeringPolicy);
    builder.add(traceRoll);
    builder.add(builder.newLogger("org.apache.hyracks.util.trace", Level.forName("TRACER", 600)).add(builder.newAppenderRef("trace")).addAttribute("additivity", false));
    return builder.build();
}
#method_after
public Configuration createConfiguration(ConfigurationBuilder<BuiltConfiguration> builder) {
    String nodeId = config.getNodeId();
    String logDir = config.getLogDir();
    builder.setStatusLevel(Level.WARN);
    builder.setConfigurationName("RollingBuilder");
    // create a rolling file appender
    LayoutComponentBuilder defaultLayout = builder.newLayout("PatternLayout").addAttribute("pattern", "%d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n");
    ComponentBuilder triggeringPolicy = builder.newComponent("Policies").addComponent(builder.newComponent("CronTriggeringPolicy").addAttribute("schedule", "0 0 0 * * ?")).addComponent(builder.newComponent("SizeBasedTriggeringPolicy").addAttribute("size", "50M"));
    AppenderComponentBuilder defaultRoll = builder.newAppender("default", "RollingFile").addAttribute("fileName", FileUtil.joinPath(logDir, "nc-" + nodeId + ".log")).addAttribute("filePattern", FileUtil.joinPath(logDir, "nc-" + nodeId + "-%d{MM-dd-yy-ss}.log.gz")).add(defaultLayout).addComponent(triggeringPolicy);
    builder.add(defaultRoll);
    // create the new logger
    builder.add(builder.newRootLogger(Level.INFO).add(builder.newAppenderRef("default")));
    LayoutComponentBuilder accessLayout = builder.newLayout("PatternLayout").addAttribute("pattern", "%m%n");
    AppenderComponentBuilder accessRoll = builder.newAppender("access", "RollingFile").addAttribute("fileName", FileUtil.joinPath(logDir, "access-" + nodeId + ".log")).addAttribute("filePattern", FileUtil.joinPath(logDir, "access-" + nodeId + "-%d{MM-dd-yy-ss}.log.gz")).add(accessLayout).addComponent(triggeringPolicy);
    builder.add(accessRoll);
    builder.add(builder.newLogger("org.apache.hyracks.http.server.CLFLogger", Level.forName("ACCESS", 550)).add(builder.newAppenderRef("access")).addAttribute("additivity", false));
    LayoutComponentBuilder traceLayout = builder.newLayout("PatternLayout").addAttribute("pattern", "%m,%n").addAttribute("header", "[").addAttribute("footer", "]");
    AppenderComponentBuilder traceRoll = builder.newAppender("trace", "RollingFile").addAttribute("fileName", logDir + "trace-" + nodeId + ".log").addAttribute("filePattern", logDir + "trace-" + nodeId + "-%d{MM-dd-yy-ss}.log.gz").add(traceLayout).addComponent(triggeringPolicy);
    builder.add(traceRoll);
    builder.add(builder.newLogger("org.apache.hyracks.util.trace.Tracer.Traces", Level.forName("TRACER", 570)).add(builder.newAppenderRef("trace")).addAttribute("additivity", false));
    return builder.build();
}
#end_block

#method_before
@Override
public void setCategories(String... categories) {
    LOGGER.log(INFO, "Set categories for Tracer " + this.traceLog.getName() + " to " + Arrays.toString(categories));
    this.categories = set(categories);
}
#method_after
@Override
public void setCategories(String... categories) {
    LOGGER.info("Set categories for Tracer " + this.traceLog.getName() + " to " + Arrays.toString(categories));
    this.categories = set(categories);
}
#end_block

#method_before
@Override
public long durationB(String name, long cat, String args) {
    if (isEnabled(cat)) {
        Event e = Event.create(name, cat, Phase.B, pid, Thread.currentThread().getId(), null, args, getRegistry());
        traceLog.log(TRACE_LOG_LEVEL, e.toJson() + ",");
        return e.tid;
    }
    return -1;
}
#method_after
@Override
public long durationB(String name, long cat, String args) {
    if (isEnabled(cat)) {
        Event e = Event.create(name, cat, Phase.B, pid, Thread.currentThread().getId(), null, args, getRegistry());
        traceLog.log(TRACE_LOG_LEVEL, e.toJson());
        return e.tid;
    }
    return -1;
}
#end_block

#method_before
@Override
public void durationE(String name, long cat, long tid, String args) {
    if (isEnabled(cat)) {
        Event e = Event.create(name, cat, Phase.E, pid, tid, null, args, getRegistry());
        traceLog.log(TRACE_LOG_LEVEL, e.toJson() + ",");
    }
}
#method_after
@Override
public void durationE(String name, long cat, long tid, String args) {
    if (isEnabled(cat)) {
        Event e = Event.create(name, cat, Phase.E, pid, tid, null, args, getRegistry());
        traceLog.log(TRACE_LOG_LEVEL, e.toJson());
    }
}
#end_block

#method_before
@Override
public void durationE(long tid, long cat, String args) {
    if (isEnabled(cat)) {
        Event e = Event.create(null, 0L, Phase.E, pid, tid, null, args, getRegistry());
        traceLog.log(TRACE_LOG_LEVEL, e.toJson() + ",");
    }
}
#method_after
@Override
public void durationE(long tid, long cat, String args) {
    if (isEnabled(cat)) {
        Event e = Event.create(null, 0L, Phase.E, pid, tid, null, args, getRegistry());
        traceLog.log(TRACE_LOG_LEVEL, e.toJson());
    }
}
#end_block

#method_before
@Override
public void instant(String name, long cat, Scope scope, String args) {
    if (isEnabled(cat)) {
        Event e = Event.create(name, cat, Phase.i, pid, Thread.currentThread().getId(), scope, args, getRegistry());
        traceLog.log(TRACE_LOG_LEVEL, e.toJson() + ",");
    }
}
#method_after
@Override
public void instant(String name, long cat, Scope scope, String args) {
    if (isEnabled(cat)) {
        Event e = Event.create(name, cat, Phase.i, pid, Thread.currentThread().getId(), scope, args, getRegistry());
        traceLog.log(TRACE_LOG_LEVEL, e.toJson());
    }
}
#end_block

#method_before
public StringBuilder append(StringBuilder sb) {
    sb.append("{");
    if (name != null) {
        sb.append("\"name\":\"").append(name).append("\",");
    }
    if (cat != 0L) {
        final String catName = registry.getName(cat);
        sb.append("\"cat\":\"").append(catName).append("\",");
    }
    sb.append("\"ph\":\"").append(ph).append("\",");
    sb.append("\"pid\":\"").append(pid).append("\",");
    sb.append("\"tid\":").append(tid).append(",");
    sb.append("\"ts\":").append(ts);
    if (scope != null) {
        sb.append(",\"s\":\"").append(scope).append("\"");
    }
    if (args != null) {
        if ("".equals(args)) {
            sb.append(",\"args\":").append("\"\"");
        } else {
            sb.append(",\"args\":").append(args);
        }
    }
    sb.append("}");
    return sb;
}
#method_after
public StringBuilder append(StringBuilder sb) {
    sb.append("{");
    if (name != null) {
        sb.append("\"name\":\"").append(name).append("\",");
    }
    if (cat != 0L) {
        final String catName = registry.getName(cat);
        sb.append("\"cat\":\"").append(catName).append("\",");
    }
    sb.append("\"ph\":\"").append(ph).append("\",");
    sb.append("\"pid\":\"").append(pid).append("\",");
    sb.append("\"tid\":").append(tid).append(",");
    sb.append("\"ts\":").append(ts);
    if (scope != null) {
        sb.append(",\"s\":\"").append(scope).append("\"");
    }
    if (args != null) {
        if (args.isEmpty()) {
            sb.append(",\"args\":").append("\"\"");
        } else {
            sb.append(",\"args\":").append(args);
        }
    }
    sb.append("}");
    return sb;
}
#end_block

#method_before
private KeyStore loadKeyStoreFromFile(char[] password) {
    try {
        final String ksFile = config.getKeyStorePath();
        if (ksFile == null || ksFile.isEmpty()) {
            throw new IllegalArgumentException("invalid keystore path");
        }
        KeyStore ks = KeyStore.getInstance(KeyStore.getDefaultType());
        ks.load(new FileInputStream(ksFile), password);
        return ks;
    } catch (Exception e) {
        throw new IllegalStateException("failed to load key store", e);
    }
}
#method_after
private KeyStore loadKeyStoreFromFile(char[] password) {
    try {
        final KeyStore ks = KeyStore.getInstance(KeyStore.getDefaultType());
        ks.load(new FileInputStream(config.getKeyStoreFile()), password);
        return ks;
    } catch (Exception e) {
        throw new IllegalStateException("failed to load key store", e);
    }
}
#end_block

#method_before
private KeyStore loadTrustStoreFromFile(char[] password) {
    try {
        final String trustStorePath = config.getTrustStorePath();
        if (trustStorePath == null || trustStorePath.isEmpty()) {
            throw new IllegalArgumentException("invalid trust path");
        }
        KeyStore ks = KeyStore.getInstance(KeyStore.getDefaultType());
        ks.load(new FileInputStream(trustStorePath), password);
        return ks;
    } catch (Exception e) {
        throw new IllegalStateException("failed to load trust store", e);
    }
}
#method_after
private KeyStore loadTrustStoreFromFile(char[] password) {
    try {
        final KeyStore ks = KeyStore.getInstance(KeyStore.getDefaultType());
        ks.load(new FileInputStream(config.getTrustStoreFile()), password);
        return ks;
    } catch (Exception e) {
        throw new IllegalStateException("failed to load trust store", e);
    }
}
#end_block

#method_before
public boolean handshake() throws IOException {
    handshakeStatus = engine.getHandshakeStatus();
    while (handshakeStatus != SSLEngineResult.HandshakeStatus.FINISHED && handshakeStatus != SSLEngineResult.HandshakeStatus.NOT_HANDSHAKING) {
        switch(handshakeStatus) {
            case NEED_UNWRAP:
                if (!unwrap()) {
                    return false;
                }
                break;
            case NEED_WRAP:
                if (!wrap()) {
                    return false;
                }
                break;
            case NEED_TASK:
                Runnable task;
                while ((task = engine.getDelegatedTask()) != null) {
                    executor.execute(task);
                }
                handshakeStatus = engine.getHandshakeStatus();
                break;
            default:
                throw new IllegalStateException("Invalid SSL handshake status: " + handshakeStatus);
        }
    }
    return true;
}
#method_after
public boolean handshake() throws IOException {
    handshakeStatus = engine.getHandshakeStatus();
    while (handshakeStatus != SSLEngineResult.HandshakeStatus.FINISHED && handshakeStatus != SSLEngineResult.HandshakeStatus.NOT_HANDSHAKING) {
        switch(handshakeStatus) {
            case NEED_UNWRAP:
                if (!unwrap()) {
                    return false;
                }
                break;
            case NEED_WRAP:
                wrap();
                break;
            case NEED_TASK:
                Runnable task;
                while ((task = engine.getDelegatedTask()) != null) {
                    executor.execute(task);
                }
                handshakeStatus = engine.getHandshakeStatus();
                break;
            default:
                throw new IllegalStateException("Invalid SSL handshake status: " + handshakeStatus);
        }
    }
    return true;
}
#end_block

#method_before
private boolean wrap() throws IOException {
    outEncryptedData.clear();
    SSLEngineResult result;
    try {
        result = engine.wrap(handshakeOutData, outEncryptedData);
        handshakeStatus = result.getHandshakeStatus();
    } catch (SSLException sslException) {
        engine.closeOutbound();
        handshakeStatus = engine.getHandshakeStatus();
        return false;
    }
    switch(result.getStatus()) {
        case OK:
            outEncryptedData.flip();
            while (outEncryptedData.hasRemaining()) {
                socketChannel.write(outEncryptedData);
            }
            break;
        case BUFFER_OVERFLOW:
            outEncryptedData = NetworkUtil.enlargeSslPacketBuffer(engine, outEncryptedData);
            break;
        case CLOSED:
            outEncryptedData.flip();
            while (outEncryptedData.hasRemaining()) {
                socketChannel.write(outEncryptedData);
            }
            inEncryptedData.clear();
            handshakeStatus = engine.getHandshakeStatus();
            break;
        case BUFFER_UNDERFLOW:
        default:
            throw new IllegalStateException("Invalid SSL status " + result.getStatus());
    }
    return true;
}
#method_after
private void wrap() throws IOException {
    outEncryptedData.clear();
    SSLEngineResult result;
    try {
        result = engine.wrap(handshakeOutData, outEncryptedData);
        handshakeStatus = result.getHandshakeStatus();
    } catch (SSLException sslException) {
        engine.closeOutbound();
        handshakeStatus = engine.getHandshakeStatus();
        throw sslException;
    }
    switch(result.getStatus()) {
        case OK:
            outEncryptedData.flip();
            while (outEncryptedData.hasRemaining()) {
                socketChannel.write(outEncryptedData);
            }
            break;
        case BUFFER_OVERFLOW:
            outEncryptedData = NetworkUtil.enlargeSslPacketBuffer(engine, outEncryptedData);
            break;
        case CLOSED:
            outEncryptedData.flip();
            while (outEncryptedData.hasRemaining()) {
                socketChannel.write(outEncryptedData);
            }
            inEncryptedData.clear();
            handshakeStatus = engine.getHandshakeStatus();
            break;
        case BUFFER_UNDERFLOW:
        default:
            throw new IllegalStateException("Invalid SSL status " + result.getStatus());
    }
}
#end_block

#method_before
private boolean unwrap() throws IOException {
    final int read = socketChannel.read(inEncryptedData);
    if (read < 0) {
        if (engine.isInboundDone() && engine.isOutboundDone()) {
            return false;
        }
        engine.closeInbound();
        // close output to put engine in WRAP status to attempt graceful ssl session end
        engine.closeOutbound();
        return false;
    }
    inEncryptedData.flip();
    SSLEngineResult result;
    try {
        result = engine.unwrap(inEncryptedData, handshakeInData);
        inEncryptedData.compact();
        handshakeStatus = result.getHandshakeStatus();
    } catch (SSLException sslException) {
        engine.closeOutbound();
        handshakeStatus = engine.getHandshakeStatus();
        return false;
    }
    switch(result.getStatus()) {
        case OK:
            break;
        case BUFFER_OVERFLOW:
            handshakeInData = NetworkUtil.enlargeSslApplicationBuffer(engine, handshakeInData);
            break;
        case BUFFER_UNDERFLOW:
            inEncryptedData = handleBufferUnderflow(engine, inEncryptedData);
            break;
        case CLOSED:
            if (engine.isOutboundDone()) {
                return false;
            } else {
                engine.closeOutbound();
                handshakeStatus = engine.getHandshakeStatus();
                break;
            }
        default:
            throw new IllegalStateException("Invalid SSL status " + result.getStatus());
    }
    return true;
}
#method_after
private boolean unwrap() throws IOException {
    final int read = socketChannel.read(inEncryptedData);
    if (read < 0) {
        if (engine.isInboundDone() && engine.isOutboundDone()) {
            return false;
        }
        engine.closeInbound();
        // close output to put engine in WRAP status to attempt graceful ssl session end
        engine.closeOutbound();
        return false;
    }
    inEncryptedData.flip();
    SSLEngineResult result;
    try {
        result = engine.unwrap(inEncryptedData, handshakeInData);
        inEncryptedData.compact();
        handshakeStatus = result.getHandshakeStatus();
    } catch (SSLException sslException) {
        engine.closeOutbound();
        handshakeStatus = engine.getHandshakeStatus();
        throw sslException;
    }
    switch(result.getStatus()) {
        case OK:
            break;
        case BUFFER_OVERFLOW:
            handshakeInData = NetworkUtil.enlargeSslApplicationBuffer(engine, handshakeInData);
            break;
        case BUFFER_UNDERFLOW:
            inEncryptedData = handleBufferUnderflow(engine, inEncryptedData);
            break;
        case CLOSED:
            if (engine.isOutboundDone()) {
                return false;
            } else {
                engine.closeOutbound();
                handshakeStatus = engine.getHandshakeStatus();
                break;
            }
        default:
            throw new IllegalStateException("Invalid SSL status " + result.getStatus());
    }
    return true;
}
#end_block

#method_before
@Override
public synchronized boolean handshake() {
    try {
        LOGGER.debug("starting SSL handshake {}", this);
        engine.beginHandshake();
        final SslHandshake sslHandshake = new SslHandshake(this);
        final boolean success = sslHandshake.handshake();
        if (success) {
            LOGGER.debug("SSL handshake successful {}", this);
        }
        return success;
    } catch (Exception e) {
        LOGGER.error("Handshake failed {}", this, e);
        throw new IllegalStateException(e);
    }
}
#method_after
@Override
public synchronized boolean handshake() {
    try {
        LOGGER.debug("starting SSL handshake {}", this);
        engine.beginHandshake();
        final SslHandshake sslHandshake = new SslHandshake(this);
        final boolean success = sslHandshake.handshake();
        if (success) {
            LOGGER.debug("SSL handshake successful {}", this);
        }
        return success;
    } catch (Exception e) {
        LOGGER.error("handshake failed {}", this, e);
        throw new IllegalStateException(e);
    }
}
#end_block

#method_before
private void handleEndOfStreamQuietly() {
    try {
        engine.closeInbound();
        close();
    } catch (Exception e) {
        LOGGER.error("This engine was forced to close inbound due to end of stream");
    }
}
#method_after
private void handleEndOfStreamQuietly() {
    try {
        engine.closeInbound();
        close();
    } catch (Exception e) {
        LOGGER.warn("failed to close socket gracefully", e);
    }
}
#end_block

#method_before
private String getConnectionInfo() {
    try {
        return getSocketChannel().getLocalAddress() + " -> " + getSocketChannel().getRemoteAddress();
    } catch (IOException e) {
        return "";
    }
}
#method_after
private String getConnectionInfo() {
    try {
        return getSocketChannel().getLocalAddress() + " -> " + getSocketChannel().getRemoteAddress();
    } catch (IOException e) {
        LOGGER.warn("failed to get connection info", e);
        return "";
    }
}
#end_block

#method_before
public void cleanup(String testCase, List<String> badtestcases) throws Exception {
    try {
        ArrayList<String> toBeDropped = new ArrayList<>();
        InputStream resultStream = executeQueryService("select dv.DataverseName from Metadata.`Dataverse` as dv order by dv.DataverseName;", getEndpoint(Servlets.QUERY_SERVICE), OutputFormat.CLEAN_JSON);
        String out = IOUtils.toString(resultStream, StandardCharsets.UTF_8);
        ObjectMapper om = new ObjectMapper();
        om.setConfig(om.getDeserializationConfig().with(DeserializationFeature.ACCEPT_EMPTY_STRING_AS_NULL_OBJECT));
        JsonNode result;
        try {
            result = om.readValue(out, ObjectNode.class).get("results");
        } catch (JsonMappingException e) {
            LOGGER.warn("error mapping response '{}' to json", out, e);
            result = null;
        }
        if (result == null) {
            return;
        }
        for (int i = 0; i < result.size(); i++) {
            JsonNode json = result.get(i);
            if (json != null) {
                String dvName = json.get("DataverseName").asText();
                if (!dvName.equals("Metadata") && !dvName.equals("Default")) {
                    toBeDropped.add("`" + dvName + "`");
                }
            }
        }
        if (!toBeDropped.isEmpty()) {
            badtestcases.add(testCase);
            LOGGER.info("Last test left some garbage. Dropping dataverses: " + StringUtils.join(toBeDropped, ','));
            StringBuilder dropStatement = new StringBuilder();
            for (String dv : toBeDropped) {
                dropStatement.setLength(0);
                dropStatement.append("drop dataverse ");
                dropStatement.append(dv);
                dropStatement.append(";\n");
                resultStream = executeQueryService(dropStatement.toString(), getEndpoint(Servlets.QUERY_SERVICE), OutputFormat.CLEAN_JSON);
                ResultExtractor.extract(resultStream);
            }
        }
    } catch (Throwable th) {
        th.printStackTrace();
        throw th;
    }
}
#method_after
public void cleanup(String testCase, List<String> badtestcases) throws Exception {
    try {
        ArrayList<String> toBeDropped = new ArrayList<>();
        InputStream resultStream = executeQueryService("select dv.DataverseName from Metadata.`Dataverse` as dv order by dv.DataverseName;", getEndpoint(Servlets.QUERY_SERVICE), OutputFormat.CLEAN_JSON);
        JsonNode result = extractResult(IOUtils.toString(resultStream, StandardCharsets.UTF_8));
        for (int i = 0; i < result.size(); i++) {
            JsonNode json = result.get(i);
            if (json != null) {
                String dvName = json.get("DataverseName").asText();
                if (!dvName.equals("Metadata") && !dvName.equals("Default")) {
                    toBeDropped.add(SqlppStatementUtil.enclose(dvName));
                }
            }
        }
        if (!toBeDropped.isEmpty()) {
            badtestcases.add(testCase);
            LOGGER.info("Last test left some garbage. Dropping dataverses: " + StringUtils.join(toBeDropped, ','));
            StringBuilder dropStatement = new StringBuilder();
            for (String dv : toBeDropped) {
                dropStatement.setLength(0);
                dropStatement.append("drop dataverse ");
                dropStatement.append(dv);
                dropStatement.append(";\n");
                resultStream = executeQueryService(dropStatement.toString(), getEndpoint(Servlets.QUERY_SERVICE), OutputFormat.CLEAN_JSON);
                ResultExtractor.extract(resultStream);
            }
        }
    } catch (Throwable th) {
        th.printStackTrace();
        throw th;
    }
}
#end_block

#method_before
@Override
protected void post(IServletRequest request, IServletResponse response) {
    try {
        handleRequest(request, response);
    } catch (IOException e) {
        // Servlet methods should not throw exceptions
        // http://cwe.mitre.org/data/definitions/600.html
        GlobalConfig.ASTERIX_LOGGER.log(Level.ERROR, e.getMessage(), e);
    } catch (Throwable th) {
        // NOSONAR: Logging and re-throwing
        try {
            GlobalConfig.ASTERIX_LOGGER.log(Level.ERROR, th.getMessage(), th);
        } catch (Throwable ignored) {
        // NOSONAR: Logging failure
        }
        throw th;
    }
}
#method_after
@Override
protected void post(IServletRequest request, IServletResponse response) {
    handleRequest(request, response);
}
#end_block

#method_before
void setStatus(ResultStatus resultStatus, HttpResponseStatus httpResponseStatus) {
    this.resultStatus = resultStatus;
    this.httpResponseStatus = httpResponseStatus;
}
#method_after
public void setStatus(ResultStatus resultStatus, HttpResponseStatus httpResponseStatus) {
    this.resultStatus = resultStatus;
    this.httpResponseStatus = httpResponseStatus;
}
#end_block

#method_before
private static SessionOutput createSessionOutput(QueryServiceRequestParameters param, String handleUrl, PrintWriter resultWriter) {
    SessionOutput.ResultDecorator resultPrefix = ResultUtil.createPreResultDecorator();
    SessionOutput.ResultDecorator resultPostfix = ResultUtil.createPostResultDecorator();
    SessionOutput.ResultAppender appendHandle = ResultUtil.createResultHandleAppender(handleUrl);
    SessionOutput.ResultAppender appendStatus = ResultUtil.createResultStatusAppender();
    SessionConfig.OutputFormat format = getFormat(param.getFormat());
    final SessionConfig.PlanFormat planFormat = SessionConfig.PlanFormat.get(param.getPlanFormat(), param.getPlanFormat(), SessionConfig.PlanFormat.JSON, LOGGER);
    SessionConfig sessionConfig = new SessionConfig(format, planFormat);
    sessionConfig.set(SessionConfig.FORMAT_WRAPPER_ARRAY, true);
    sessionConfig.set(SessionConfig.OOB_EXPR_TREE, param.isExpressionTree());
    sessionConfig.set(SessionConfig.OOB_REWRITTEN_EXPR_TREE, param.isRewrittenExpressionTree());
    sessionConfig.set(SessionConfig.OOB_LOGICAL_PLAN, param.isLogicalPlan());
    sessionConfig.set(SessionConfig.OOB_OPTIMIZED_LOGICAL_PLAN, param.isOptimizedLogicalPlan());
    sessionConfig.set(SessionConfig.OOB_HYRACKS_JOB, param.isJob());
    sessionConfig.set(SessionConfig.FORMAT_INDENT_JSON, param.isPretty());
    sessionConfig.set(SessionConfig.FORMAT_QUOTE_RECORD, format != SessionConfig.OutputFormat.CLEAN_JSON && format != SessionConfig.OutputFormat.LOSSLESS_JSON);
    sessionConfig.set(SessionConfig.FORMAT_CSV_HEADER, format == SessionConfig.OutputFormat.CSV && "present".equals(getParameterValue(param.getFormat(), Attribute.HEADER.str())));
    return new SessionOutput(sessionConfig, resultWriter, resultPrefix, resultPostfix, appendHandle, appendStatus);
}
#method_after
private static SessionOutput createSessionOutput(PrintWriter resultWriter) {
    SessionOutput.ResultDecorator resultPrefix = ResultUtil.createPreResultDecorator();
    SessionOutput.ResultDecorator resultPostfix = ResultUtil.createPostResultDecorator();
    SessionOutput.ResultAppender appendStatus = ResultUtil.createResultStatusAppender();
    SessionConfig sessionConfig = new SessionConfig(SessionConfig.OutputFormat.CLEAN_JSON);
    return new SessionOutput(sessionConfig, resultWriter, resultPrefix, resultPostfix, null, appendStatus);
}
#end_block

#method_before
protected void setRequestParam(IServletRequest request, QueryServiceRequestParameters param) throws IOException {
    String contentType = HttpUtil.getContentTypeOnly(request);
    if (HttpUtil.ContentType.APPLICATION_JSON.equals(contentType)) {
        try {
            setFromJSON(request, param);
        } catch (JsonParseException | JsonMappingException e) {
            // if the JSON parsing fails, the statement is empty and we get an empty statement error
            GlobalConfig.ASTERIX_LOGGER.log(Level.ERROR, e.getMessage(), e);
        }
    } else {
        setFromRequest(request, param);
    }
}
#method_after
protected void setRequestParam(IServletRequest request, QueryServiceRequestParameters param) throws IOException, AlgebricksException {
    param.setHost(host(request));
    param.setPath(servletPath(request));
    String contentType = HttpUtil.getContentTypeOnly(request);
    if (HttpUtil.ContentType.APPLICATION_JSON.equals(contentType)) {
        try {
            setParamFromJSON(request, param);
        } catch (JsonParseException | JsonMappingException e) {
            // if the JSON parsing fails, the statement is empty and we get an empty statement error
            GlobalConfig.ASTERIX_LOGGER.log(Level.ERROR, e.getMessage(), e);
        }
    } else {
        setParamFromRequest(request, param);
    }
}
#end_block

#method_before
private void handleRequest(IServletRequest request, IServletResponse response) throws IOException {
    QueryServiceRequestParameters param = createRequestParameters(request);
    LOGGER.info("handleRequest: {}", param);
    long elapsedStart = System.nanoTime();
    final PrintWriter httpWriter = response.writer();
    ResultDelivery delivery = parseResultDelivery(param.getMode());
    final ResultProperties resultProperties = param.getMaxResultReads() == null ? new ResultProperties(delivery) : new ResultProperties(delivery, Long.parseLong(param.getMaxResultReads()));
    String handleUrl = getHandleUrl(param.getHost(), param.getPath(), delivery);
    SessionOutput sessionOutput = createSessionOutput(param, handleUrl, httpWriter);
    SessionConfig sessionConfig = sessionOutput.config();
    HttpUtil.setContentType(response, HttpUtil.ContentType.APPLICATION_JSON, HttpUtil.Encoding.UTF8);
    Stats stats = new Stats();
    RequestExecutionState execution = new RequestExecutionState();
    // buffer the output until we are ready to set the status of the response message correctly
    sessionOutput.hold();
    sessionOutput.out().print("{\n");
    printPre(sessionOutput.out());
    printRequestId(sessionOutput.out());
    printClientContextID(sessionOutput.out(), param);
    printSignature(sessionOutput.out(), param);
    printType(sessionOutput.out(), sessionConfig);
    // so far we just return 1 error
    long errorCount = 1;
    // we don't have any warnings yet
    List<ExecutionWarning> warnings = Collections.emptyList();
    try {
        if (param.getStatement() == null || param.getStatement().isEmpty()) {
            throw new RuntimeDataException(ErrorCode.NO_STATEMENT_PROVIDED);
        }
        String statementsText = param.getStatement() + ";";
        Map<String, String> optionalParams = null;
        if (optionalParamProvider != null) {
            optionalParams = optionalParamProvider.apply(request);
        }
        Map<String, byte[]> statementParams = org.apache.asterix.app.translator.RequestParameters.serializeParameterValues(param.getStatementParams());
        // CORS
        if (request.getHeader("Origin") != null) {
            response.setHeader("Access-Control-Allow-Origin", request.getHeader("Origin"));
        }
        response.setHeader("Access-Control-Allow-Headers", "Origin, X-Requested-With, Content-Type, Accept");
        response.setStatus(execution.getHttpStatus());
        executeStatement(statementsText, sessionOutput, resultProperties, stats, param, execution, optionalParams, statementParams);
        if (ResultDelivery.IMMEDIATE == delivery || ResultDelivery.DEFERRED == delivery) {
            ResultUtil.printStatus(sessionOutput, execution.getResultStatus());
        }
        if (!warnings.isEmpty()) {
            printWarnings(sessionOutput.out(), warnings);
        }
        errorCount = 0;
    } catch (Exception | TokenMgrError | org.apache.asterix.aqlplus.parser.TokenMgrError e) {
        handleExecuteStatementException(e, execution, param);
        response.setStatus(execution.getHttpStatus());
        printError(sessionOutput.out(), e);
        ResultUtil.printStatus(sessionOutput, execution.getResultStatus());
    } finally {
        // make sure that we stop buffering and return the result to the http response
        sessionOutput.release();
        execution.finish();
    }
    printMetrics(sessionOutput.out(), System.nanoTime() - elapsedStart, execution.duration(), stats.getCount(), stats.getSize(), stats.getProcessedObjects(), errorCount, warnings.size());
    sessionOutput.out().print("}\n");
    sessionOutput.out().flush();
    if (sessionOutput.out().checkError()) {
        LOGGER.warn("Error flushing output writer");
    }
}
#method_after
private void handleRequest(IServletRequest request, IServletResponse response) {
    long elapsedStart = System.nanoTime();
    long errorCount = 1;
    Stats stats = new Stats();
    RequestExecutionState execution = new RequestExecutionState();
    List<ExecutionWarning> warnings = Collections.emptyList();
    PrintWriter httpWriter = response.writer();
    SessionOutput sessionOutput = createSessionOutput(httpWriter);
    QueryServiceRequestParameters param = new QueryServiceRequestParameters();
    try {
        // buffer the output until we are ready to set the status of the response message correctly
        sessionOutput.hold();
        sessionOutput.out().print("{\n");
        HttpUtil.setContentType(response, HttpUtil.ContentType.APPLICATION_JSON, HttpUtil.Encoding.UTF8);
        setRequestParam(request, param);
        LOGGER.info("handleRequest: {}", param);
        ResultDelivery delivery = parseResultDelivery(param.getMode());
        setSessionConfig(sessionOutput, param, delivery);
        ResultProperties resultProperties = param.getMaxResultReads() == null ? new ResultProperties(delivery) : new ResultProperties(delivery, Long.parseLong(param.getMaxResultReads()));
        printAdditionalResultFields(sessionOutput.out());
        printRequestId(sessionOutput.out());
        printClientContextID(sessionOutput.out(), param);
        printSignature(sessionOutput.out(), param);
        printType(sessionOutput.out(), sessionOutput.config());
        if (param.getStatement() == null || param.getStatement().isEmpty()) {
            throw new RuntimeDataException(ErrorCode.NO_STATEMENT_PROVIDED);
        }
        String statementsText = param.getStatement() + ";";
        Map<String, String> optionalParams = null;
        if (optionalParamProvider != null) {
            optionalParams = optionalParamProvider.apply(request);
        }
        Map<String, byte[]> statementParams = org.apache.asterix.app.translator.RequestParameters.serializeParameterValues(param.getStatementParams());
        // CORS
        if (request.getHeader("Origin") != null) {
            response.setHeader("Access-Control-Allow-Origin", request.getHeader("Origin"));
        }
        response.setHeader("Access-Control-Allow-Headers", "Origin, X-Requested-With, Content-Type, Accept");
        response.setStatus(execution.getHttpStatus());
        executeStatement(statementsText, sessionOutput, resultProperties, stats, param, execution, optionalParams, statementParams);
        if (ResultDelivery.IMMEDIATE == delivery || ResultDelivery.DEFERRED == delivery) {
            ResultUtil.printStatus(sessionOutput, execution.getResultStatus());
        }
        if (!warnings.isEmpty()) {
            printWarnings(sessionOutput.out(), warnings);
        }
        errorCount = 0;
    } catch (Exception | TokenMgrError | org.apache.asterix.aqlplus.parser.TokenMgrError e) {
        handleExecuteStatementException(e, execution, param);
        response.setStatus(execution.getHttpStatus());
        printError(sessionOutput.out(), e);
        ResultUtil.printStatus(sessionOutput, execution.getResultStatus());
    } finally {
        // make sure that we stop buffering and return the result to the http response
        sessionOutput.release();
        execution.finish();
    }
    printMetrics(sessionOutput.out(), System.nanoTime() - elapsedStart, execution.duration(), stats.getCount(), stats.getSize(), stats.getProcessedObjects(), errorCount, warnings.size());
    sessionOutput.out().print("}\n");
    sessionOutput.out().flush();
    if (sessionOutput.out().checkError()) {
        LOGGER.warn("Error flushing output writer");
    }
}
#end_block

#method_before
public static Pair<ARecordType, ARecordType> createEnforcedType(ARecordType recordType, ARecordType metaType, List<Index> indexes) throws AlgebricksException {
    IAType enforcedRecordType = recordType;
    ARecordType enforcedMetaType = metaType;
    List<String> subFieldName;
    for (Index index : indexes) {
        if (!index.isSecondaryIndex() || !index.isOverridingKeyFieldTypes()) {
            continue;
        }
        if (index.hasMetaFields()) {
            throw new AlgebricksException("Indexing an open field is only supported on the record part");
        }
        for (int i = 0; i < index.getKeyFieldNames().size(); i++) {
            // keeps track of a record type and a field name in that record type
            Deque<Pair<IAType, String>> nestedTypeStack = new ArrayDeque<>();
            List<String> splits = index.getKeyFieldNames().get(i);
            IAType nestedFieldType = enforcedRecordType;
            boolean openRecords = false;
            String bridgeName = nestedFieldType.getTypeName();
            int j;
            // enforcedRecordType must always be/stay as ARecordType
            validateRecord(enforcedRecordType);
            // try to build up to the last record field, e.g. for a.b.c.d.e, build up to and including "d"
            for (j = 1; j < splits.size(); j++) {
                nestedTypeStack.push(new Pair<>(nestedFieldType, splits.get(j - 1)));
                bridgeName = nestedFieldType.getTypeName();
                subFieldName = splits.subList(0, j);
                nestedFieldType = ((ARecordType) enforcedRecordType).getSubFieldType(subFieldName);
                if (nestedFieldType == null) {
                    openRecords = true;
                    break;
                }
                // nestedFieldType (i.e. nested record field) must be either ARecordType or AUnion(ARecordType)
                validateNestedRecord(nestedFieldType, subFieldName);
            }
            if (openRecords) {
                // create the smallest record
                enforcedRecordType = new ARecordType(splits.get(splits.size() - 2), new String[] { splits.get(splits.size() - 1) }, new IAType[] { AUnionType.createUnknownableType(index.getKeyFieldTypes().get(i)) }, true);
                // create the open part of the nested field
                for (int k = splits.size() - 3; k > (j - 2); k--) {
                    enforcedRecordType = new ARecordType(splits.get(k), new String[] { splits.get(k + 1) }, new IAType[] { AUnionType.createUnknownableType(enforcedRecordType) }, true);
                }
                // bridge the gap. Update the parent type to include the new optional field, e.g. c.d.e
                Pair<IAType, String> gapPair = nestedTypeStack.pop();
                ARecordType parent = (ARecordType) TypeComputeUtils.getActualType(gapPair.first);
                // parent type must be "open" to allow inclusion of the non-declared field
                IAType[] parentFieldTypes = ArrayUtils.addAll(parent.getFieldTypes().clone(), new IAType[] { AUnionType.createUnknownableType(enforcedRecordType) });
                enforcedRecordType = new ARecordType(bridgeName, ArrayUtils.addAll(parent.getFieldNames(), enforcedRecordType.getTypeName()), parentFieldTypes, true);
                // make nullable/missable if the original parent was nullable/missable
                enforcedRecordType = keepUnknown(gapPair.first, (ARecordType) enforcedRecordType);
            } else {
                // schema is closed all the way to the field. Enforced fields are either null or strongly typed
                // e.g. nestedFieldType = a.b.c.d
                ARecordType lastNestedRecord = (ARecordType) TypeComputeUtils.getActualType(nestedFieldType);
                Map<String, IAType> recordNameTypesMap = TypeUtil.createRecordNameTypeMap(lastNestedRecord);
                // if a an enforced field already exists and the type is correct
                IAType enforcedFieldType = recordNameTypesMap.get(splits.get(splits.size() - 1));
                if (enforcedFieldType != null && enforcedFieldType.getTypeTag() == ATypeTag.UNION && ((AUnionType) enforcedFieldType).isUnknownableType()) {
                    enforcedFieldType = ((AUnionType) enforcedFieldType).getActualType();
                }
                if (enforcedFieldType != null && !ATypeHierarchy.canPromote(enforcedFieldType.getTypeTag(), index.getKeyFieldTypes().get(i).getTypeTag())) {
                    throw new AsterixException(ErrorCode.COMPILATION_ERROR, "Cannot enforce field \"" + String.join(".", index.getKeyFieldNames().get(i)) + "\" to have type " + index.getKeyFieldTypes().get(i));
                }
                if (enforcedFieldType == null) {
                    recordNameTypesMap.put(splits.get(splits.size() - 1), AUnionType.createUnknownableType(index.getKeyFieldTypes().get(i)));
                }
                enforcedRecordType = new ARecordType(lastNestedRecord.getTypeName(), recordNameTypesMap.keySet().toArray(new String[recordNameTypesMap.size()]), recordNameTypesMap.values().toArray(new IAType[recordNameTypesMap.size()]), lastNestedRecord.isOpen());
                // make nullable/missable if the original nestedFieldType was nullable/missable
                enforcedRecordType = keepUnknown(nestedFieldType, (ARecordType) enforcedRecordType);
            }
            // Create the enforced type for the nested fields in the schema, from the ground up
            if (!nestedTypeStack.isEmpty()) {
                while (!nestedTypeStack.isEmpty()) {
                    Pair<IAType, String> nestedType = nestedTypeStack.pop();
                    ARecordType nestedRecType = (ARecordType) TypeComputeUtils.getActualType((nestedType.first));
                    IAType[] nestedRecTypeFieldTypes = nestedRecType.getFieldTypes().clone();
                    nestedRecTypeFieldTypes[nestedRecType.getFieldIndex(nestedType.second)] = enforcedRecordType;
                    enforcedRecordType = new ARecordType(nestedRecType.getTypeName() + "_enforced", nestedRecType.getFieldNames(), nestedRecTypeFieldTypes, nestedRecType.isOpen());
                    // make nullable/missable if the original nestedRecType was nullable/missable
                    enforcedRecordType = keepUnknown(nestedType.first, (ARecordType) enforcedRecordType);
                }
            }
        }
    }
    // the final enforcedRecordType built must be ARecordType since the original dataset rec. type can't be nullable
    validateRecord(enforcedRecordType);
    return new Pair<>((ARecordType) enforcedRecordType, enforcedMetaType);
}
#method_after
public static Pair<ARecordType, ARecordType> createEnforcedType(ARecordType recordType, ARecordType metaType, List<Index> indexes) throws AlgebricksException {
    IAType enforcedRecordType = recordType;
    ARecordType enforcedMetaType = metaType;
    List<String> subFieldName;
    for (Index index : indexes) {
        if (!index.isSecondaryIndex() || !index.isOverridingKeyFieldTypes()) {
            continue;
        }
        if (index.hasMetaFields()) {
            throw new AlgebricksException("Indexing an open field is only supported on the record part");
        }
        for (int i = 0; i < index.getKeyFieldNames().size(); i++) {
            // keeps track of a record type and a field name in that record type
            Deque<Pair<IAType, String>> nestedTypeStack = new ArrayDeque<>();
            List<String> splits = index.getKeyFieldNames().get(i);
            IAType nestedFieldType = enforcedRecordType;
            boolean openRecords = false;
            String bridgeName = nestedFieldType.getTypeName();
            int j;
            // enforcedRecordType must always be/stay as ARecordType
            validateRecord(enforcedRecordType);
            // try to build up to the last record field, e.g. for a.b.c.d.e, build up to and including "d"
            for (j = 1; j < splits.size(); j++) {
                nestedTypeStack.push(new Pair<>(nestedFieldType, splits.get(j - 1)));
                bridgeName = nestedFieldType.getTypeName();
                subFieldName = splits.subList(0, j);
                nestedFieldType = ((ARecordType) enforcedRecordType).getSubFieldType(subFieldName);
                if (nestedFieldType == null) {
                    openRecords = true;
                    break;
                }
                // nestedFieldType (i.e. nested record field) must be either ARecordType or AUnion(ARecordType)
                validateNestedRecord(nestedFieldType, subFieldName);
            }
            if (openRecords) {
                // create the smallest record
                enforcedRecordType = new ARecordType(splits.get(splits.size() - 2), new String[] { splits.get(splits.size() - 1) }, new IAType[] { AUnionType.createUnknownableType(index.getKeyFieldTypes().get(i)) }, true);
                // create the open part of the nested field
                for (int k = splits.size() - 3; k > (j - 2); k--) {
                    enforcedRecordType = new ARecordType(splits.get(k), new String[] { splits.get(k + 1) }, new IAType[] { AUnionType.createUnknownableType(enforcedRecordType) }, true);
                }
                // bridge the gap. Update the parent type to include the new optional field, e.g. c.d.e
                Pair<IAType, String> gapPair = nestedTypeStack.pop();
                ARecordType parent = (ARecordType) TypeComputeUtils.getActualType(gapPair.first);
                // parent type must be "open" to allow inclusion of the non-declared field
                IAType[] parentFieldTypes = ArrayUtils.addAll(parent.getFieldTypes().clone(), new IAType[] { AUnionType.createUnknownableType(enforcedRecordType) });
                enforcedRecordType = new ARecordType(bridgeName, ArrayUtils.addAll(parent.getFieldNames(), enforcedRecordType.getTypeName()), parentFieldTypes, true);
                // make nullable/missable if the original parent was nullable/missable
                enforcedRecordType = keepUnknown(gapPair.first, (ARecordType) enforcedRecordType);
            } else {
                // schema is closed all the way to the field. Enforced fields are either null or strongly typed
                // e.g. nestedFieldType = a.b.c.d
                ARecordType lastNestedRecord = (ARecordType) TypeComputeUtils.getActualType(nestedFieldType);
                Map<String, IAType> recordNameTypesMap = TypeUtil.createRecordNameTypeMap(lastNestedRecord);
                // if a an enforced field already exists and the type is correct
                IAType enforcedFieldType = recordNameTypesMap.get(splits.get(splits.size() - 1));
                if (enforcedFieldType != null && enforcedFieldType.getTypeTag() == ATypeTag.UNION && ((AUnionType) enforcedFieldType).isUnknownableType()) {
                    enforcedFieldType = ((AUnionType) enforcedFieldType).getActualType();
                }
                if (enforcedFieldType != null && !ATypeHierarchy.canPromote(enforcedFieldType.getTypeTag(), index.getKeyFieldTypes().get(i).getTypeTag())) {
                    throw new AsterixException(ErrorCode.COMPILATION_ERROR, "Cannot enforce field \"" + String.join(".", index.getKeyFieldNames().get(i)) + "\" to have type " + index.getKeyFieldTypes().get(i));
                }
                if (enforcedFieldType == null) {
                    recordNameTypesMap.put(splits.get(splits.size() - 1), AUnionType.createUnknownableType(index.getKeyFieldTypes().get(i)));
                }
                enforcedRecordType = new ARecordType(lastNestedRecord.getTypeName(), recordNameTypesMap.keySet().toArray(new String[recordNameTypesMap.size()]), recordNameTypesMap.values().toArray(new IAType[recordNameTypesMap.size()]), lastNestedRecord.isOpen());
                // make nullable/missable if the original nestedFieldType was nullable/missable
                enforcedRecordType = keepUnknown(nestedFieldType, (ARecordType) enforcedRecordType);
            }
            // Create the enforced type for the nested fields in the schema, from the ground up
            if (!nestedTypeStack.isEmpty()) {
                while (!nestedTypeStack.isEmpty()) {
                    Pair<IAType, String> nestedType = nestedTypeStack.pop();
                    ARecordType nestedRecType = (ARecordType) TypeComputeUtils.getActualType(nestedType.first);
                    IAType[] nestedRecTypeFieldTypes = nestedRecType.getFieldTypes().clone();
                    nestedRecTypeFieldTypes[nestedRecType.getFieldIndex(nestedType.second)] = enforcedRecordType;
                    enforcedRecordType = new ARecordType(nestedRecType.getTypeName() + "_enforced", nestedRecType.getFieldNames(), nestedRecTypeFieldTypes, nestedRecType.isOpen());
                    // make nullable/missable if the original nestedRecType was nullable/missable
                    enforcedRecordType = keepUnknown(nestedType.first, (ARecordType) enforcedRecordType);
                }
            }
        }
    }
    // the final enforcedRecordType built must be ARecordType since the original dataset rec. type can't be nullable
    validateRecord(enforcedRecordType);
    return new Pair<>((ARecordType) enforcedRecordType, enforcedMetaType);
}
#end_block

#method_before
@Override
protected IAType getResultType(ILogicalExpression expr, IAType... strippedInputTypes) throws AlgebricksException {
    if (strippedInputTypes.length < minNumArgs || (maxNumArgs > 0 && strippedInputTypes.length > maxNumArgs)) {
        String functionName = ((AbstractFunctionCallExpression) expr).getFunctionIdentifier().getName();
        throw new CompilationException(ErrorCode.COMPILATION_INVALID_NUM_OF_ARGS, expr.getSourceLocation(), functionName);
    }
    // output type should be the same as as the type tag at [list index]. The output type is nullable/missable
    // since the output could be null due to other invalid arguments or the tag at [list index] itself is not list
    int listIndex = 0;
    if (listIsLast) {
        listIndex = strippedInputTypes.length - 1;
    }
    IAType listType = strippedInputTypes[listIndex];
    if (listType.getTypeTag().isListType()) {
        if (makeOpen) {
            listType = DefaultOpenFieldType.getDefaultOpenFieldType(listType.getTypeTag());
        }
        return AUnionType.createUnknownableType(listType);
    } else {
        return BuiltinType.ANY;
    }
}
#method_after
@Override
protected IAType getResultType(ILogicalExpression expr, IAType... strippedInputTypes) throws AlgebricksException {
    if (isCheckArgumentsCount && (strippedInputTypes.length < minNumArgs || (maxNumArgs > 0 && strippedInputTypes.length > maxNumArgs))) {
        String functionName = ((AbstractFunctionCallExpression) expr).getFunctionIdentifier().getName();
        throw new CompilationException(ErrorCode.COMPILATION_INVALID_NUM_OF_ARGS, expr.getSourceLocation(), functionName);
    }
    // output type should be the same as as the type tag at [list index]. The output type is nullable/missable
    // since the output could be null due to other invalid arguments or the tag at [list index] itself is not list
    int listIndex = 0;
    if (listIsLast) {
        listIndex = strippedInputTypes.length - 1;
    }
    IAType listType = strippedInputTypes[listIndex];
    if (listType.getTypeTag().isListType()) {
        if (makeOpen) {
            listType = DefaultOpenFieldType.getDefaultOpenFieldType(listType.getTypeTag());
        }
        return AUnionType.createUnknownableType(listType);
    } else {
        return BuiltinType.ANY;
    }
}
#end_block

#method_before
public static FunctionCollection createDefaultFunctionCollection() {
    FunctionCollection fc = new FunctionCollection();
    // array functions
    fc.add(ArrayRemoveDescriptor.FACTORY);
    fc.add(ArrayPutDescriptor.FACTORY);
    fc.add(ArrayPrependDescriptor.FACTORY);
    fc.add(ArrayAppendDescriptor.FACTORY);
    fc.add(ArrayInsertDescriptor.FACTORY);
    fc.addGenerated(ArrayPositionDescriptor.FACTORY);
    fc.addGenerated(ArrayRepeatDescriptor.FACTORY);
    fc.addGenerated(ArrayContainsDescriptor.FACTORY);
    fc.addGenerated(ArrayReverseDescriptor.FACTORY);
    fc.addGenerated(ArraySortDescriptor.FACTORY);
    fc.addGenerated(ArrayDistinctDescriptor.FACTORY);
    fc.addGenerated(ArrayUnionDescriptor.FACTORY);
    fc.addGenerated(ArrayIntersectDescriptor.FACTORY);
    fc.addGenerated(ArrayIfNullDescriptor.FACTORY);
    fc.addGenerated(ArrayConcatDescriptor.FACTORY);
    fc.addGenerated(ArrayRangeDescriptor.FACTORY);
    fc.addGenerated(ArrayFlattenDescriptor.FACTORY);
    fc.add(ArrayReplaceDescriptor.FACTORY);
    fc.add(ArraySliceDescriptor.FACTORY);
    fc.addGenerated(ArraySymDiffDescriptor.FACTORY);
    fc.addGenerated(ArraySymDiffnDescriptor.FACTORY);
    fc.addGenerated(ArrayStarDescriptor.FACTORY);
    // unnesting functions
    fc.add(TidRunningAggregateDescriptor.FACTORY);
    fc.add(ScanCollectionDescriptor.FACTORY);
    fc.add(RangeDescriptor.FACTORY);
    fc.add(SubsetCollectionDescriptor.FACTORY);
    // aggregate functions
    fc.add(ListifyAggregateDescriptor.FACTORY);
    fc.add(CountAggregateDescriptor.FACTORY);
    fc.add(AvgAggregateDescriptor.FACTORY);
    fc.add(LocalAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SumAggregateDescriptor.FACTORY);
    fc.add(LocalSumAggregateDescriptor.FACTORY);
    fc.add(IntermediateSumAggregateDescriptor.FACTORY);
    fc.add(GlobalSumAggregateDescriptor.FACTORY);
    fc.add(MaxAggregateDescriptor.FACTORY);
    fc.add(LocalMaxAggregateDescriptor.FACTORY);
    fc.add(MinAggregateDescriptor.FACTORY);
    fc.add(LocalMinAggregateDescriptor.FACTORY);
    fc.add(FirstElementAggregateDescriptor.FACTORY);
    fc.add(LocalFirstElementAggregateDescriptor.FACTORY);
    fc.add(StddevAggregateDescriptor.FACTORY);
    fc.add(LocalStddevAggregateDescriptor.FACTORY);
    fc.add(IntermediateStddevAggregateDescriptor.FACTORY);
    fc.add(GlobalStddevAggregateDescriptor.FACTORY);
    fc.add(LocalSamplingAggregateDescriptor.FACTORY);
    fc.add(RangeMapAggregateDescriptor.FACTORY);
    fc.add(StddevPopAggregateDescriptor.FACTORY);
    fc.add(LocalStddevPopAggregateDescriptor.FACTORY);
    fc.add(IntermediateStddevPopAggregateDescriptor.FACTORY);
    fc.add(GlobalStddevPopAggregateDescriptor.FACTORY);
    fc.add(VarAggregateDescriptor.FACTORY);
    fc.add(LocalVarAggregateDescriptor.FACTORY);
    fc.add(IntermediateVarAggregateDescriptor.FACTORY);
    fc.add(GlobalVarAggregateDescriptor.FACTORY);
    fc.add(VarPopAggregateDescriptor.FACTORY);
    fc.add(LocalVarPopAggregateDescriptor.FACTORY);
    fc.add(IntermediateVarPopAggregateDescriptor.FACTORY);
    fc.add(GlobalVarPopAggregateDescriptor.FACTORY);
    // serializable aggregates
    fc.add(SerializableCountAggregateDescriptor.FACTORY);
    fc.add(SerializableAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSumAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSumAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSumAggregateDescriptor.FACTORY);
    fc.add(SerializableStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableVarAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalVarAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateVarAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalVarAggregateDescriptor.FACTORY);
    fc.add(SerializableVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalVarPopAggregateDescriptor.FACTORY);
    // scalar aggregates
    fc.add(ScalarCountAggregateDescriptor.FACTORY);
    fc.add(ScalarAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSumAggregateDescriptor.FACTORY);
    fc.add(ScalarMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarMinAggregateDescriptor.FACTORY);
    fc.add(EmptyStreamAggregateDescriptor.FACTORY);
    fc.add(NonEmptyStreamAggregateDescriptor.FACTORY);
    fc.add(ScalarStddevAggregateDescriptor.FACTORY);
    fc.add(ScalarStddevPopAggregateDescriptor.FACTORY);
    fc.add(ScalarVarAggregateDescriptor.FACTORY);
    fc.add(ScalarVarPopAggregateDescriptor.FACTORY);
    // SQL aggregates
    fc.add(SqlCountAggregateDescriptor.FACTORY);
    fc.add(SqlAvgAggregateDescriptor.FACTORY);
    fc.add(LocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SqlSumAggregateDescriptor.FACTORY);
    fc.add(LocalSqlSumAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlSumAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SqlMaxAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMaxAggregateDescriptor.FACTORY);
    fc.add(SqlMinAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMinAggregateDescriptor.FACTORY);
    fc.add(SqlStddevAggregateDescriptor.FACTORY);
    fc.add(LocalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlStddevAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(LocalSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SqlVarAggregateDescriptor.FACTORY);
    fc.add(LocalSqlVarAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlVarAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlVarAggregateDescriptor.FACTORY);
    fc.add(SqlVarPopAggregateDescriptor.FACTORY);
    fc.add(LocalSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlVarPopAggregateDescriptor.FACTORY);
    // SQL serializable aggregates
    fc.add(SerializableSqlCountAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlVarAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlVarAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlVarAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlVarAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlVarPopAggregateDescriptor.FACTORY);
    // SQL scalar aggregates
    fc.add(ScalarSqlCountAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlSumAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMinAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlStddevAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlVarAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlVarPopAggregateDescriptor.FACTORY);
    // window functions
    fc.add(RowNumberRunningAggregateDescriptor.FACTORY);
    fc.add(RankRunningAggregateDescriptor.FACTORY);
    fc.add(DenseRankRunningAggregateDescriptor.FACTORY);
    fc.add(PercentRankRunningAggregateDescriptor.FACTORY);
    fc.add(NtileRunningAggregateDescriptor.FACTORY);
    // boolean functions
    fc.add(AndDescriptor.FACTORY);
    fc.add(OrDescriptor.FACTORY);
    // Record constructors / functions
    fc.add(ClosedRecordConstructorDescriptor.FACTORY);
    fc.add(OpenRecordConstructorDescriptor.FACTORY);
    fc.add(RecordConcatDescriptor.FACTORY);
    fc.add(RecordConcatStrictDescriptor.FACTORY);
    // List constructors
    fc.add(OrderedListConstructorDescriptor.FACTORY);
    fc.add(UnorderedListConstructorDescriptor.FACTORY);
    // Sleep function
    fc.add(SleepDescriptor.FACTORY);
    // Inject failure function
    fc.add(InjectFailureDescriptor.FACTORY);
    // Get Job Parameter function
    fc.add(GetJobParameterByNameDescriptor.FACTORY);
    // Switch case
    fc.add(SwitchCaseDescriptor.FACTORY);
    // null functions
    fc.add(IsMissingDescriptor.FACTORY);
    fc.add(IsNullDescriptor.FACTORY);
    fc.add(IsUnknownDescriptor.FACTORY);
    fc.add(IsSystemNullDescriptor.FACTORY);
    fc.add(CheckUnknownDescriptor.FACTORY);
    fc.add(IfMissingDescriptor.FACTORY);
    fc.add(IfNullDescriptor.FACTORY);
    fc.add(IfMissingOrNullDescriptor.FACTORY);
    // uuid generators (zero independent functions)
    fc.add(CreateUUIDDescriptor.FACTORY);
    fc.add(UUIDDescriptor.FACTORY);
    fc.add(CreateQueryUIDDescriptor.FACTORY);
    fc.add(RandomDescriptor.FACTORY);
    fc.add(CurrentDateDescriptor.FACTORY);
    fc.add(CurrentTimeDescriptor.FACTORY);
    fc.add(CurrentDateTimeDescriptor.FACTORY);
    // functions that need generated class for null-handling.
    // Element accessors.
    fc.addGenerated(FieldAccessByIndexDescriptor.FACTORY);
    fc.addGenerated(FieldAccessByNameDescriptor.FACTORY);
    fc.addGenerated(FieldAccessNestedDescriptor.FACTORY);
    fc.addGenerated(AnyCollectionMemberDescriptor.FACTORY);
    fc.addGenerated(GetItemDescriptor.FACTORY);
    // Numeric functions
    fc.add(IfInfDescriptor.FACTORY);
    fc.add(IfNanDescriptor.FACTORY);
    fc.add(IfNanOrInfDescriptor.FACTORY);
    fc.addGenerated(NumericUnaryMinusDescriptor.FACTORY);
    fc.addGenerated(NumericAddDescriptor.FACTORY);
    fc.addGenerated(NumericDivideDescriptor.FACTORY);
    fc.addGenerated(NumericDivDescriptor.FACTORY);
    fc.addGenerated(NumericMultiplyDescriptor.FACTORY);
    fc.addGenerated(NumericSubDescriptor.FACTORY);
    fc.addGenerated(NumericModuloDescriptor.FACTORY);
    fc.addGenerated(NumericPowerDescriptor.FACTORY);
    fc.addGenerated(NotDescriptor.FACTORY);
    fc.addGenerated(LenDescriptor.FACTORY);
    fc.addGenerated(NumericAbsDescriptor.FACTORY);
    fc.addGenerated(NumericCeilingDescriptor.FACTORY);
    fc.addGenerated(NumericFloorDescriptor.FACTORY);
    fc.addGenerated(NumericRoundDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEvenDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEven2Descriptor.FACTORY);
    fc.addGenerated(NumericACosDescriptor.FACTORY);
    fc.addGenerated(NumericASinDescriptor.FACTORY);
    fc.addGenerated(NumericATanDescriptor.FACTORY);
    fc.addGenerated(NumericDegreesDescriptor.FACTORY);
    fc.addGenerated(NumericRadiansDescriptor.FACTORY);
    fc.addGenerated(NumericCosDescriptor.FACTORY);
    fc.addGenerated(NumericSinDescriptor.FACTORY);
    fc.addGenerated(NumericTanDescriptor.FACTORY);
    fc.addGenerated(NumericExpDescriptor.FACTORY);
    fc.addGenerated(NumericLnDescriptor.FACTORY);
    fc.addGenerated(NumericLogDescriptor.FACTORY);
    fc.addGenerated(NumericSqrtDescriptor.FACTORY);
    fc.addGenerated(NumericSignDescriptor.FACTORY);
    fc.addGenerated(NumericTruncDescriptor.FACTORY);
    fc.addGenerated(NumericATan2Descriptor.FACTORY);
    // Comparisons.
    fc.addGenerated(EqualsDescriptor.FACTORY);
    fc.addGenerated(GreaterThanDescriptor.FACTORY);
    fc.addGenerated(GreaterThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(LessThanDescriptor.FACTORY);
    fc.addGenerated(LessThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(NotEqualsDescriptor.FACTORY);
    // If-Equals functions
    fc.addGenerated(MissingIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NullIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NanIfEqualsDescriptor.FACTORY);
    fc.addGenerated(PosInfIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NegInfIfEqualsDescriptor.FACTORY);
    // Binary functions
    fc.addGenerated(BinaryLengthDescriptor.FACTORY);
    fc.addGenerated(ParseBinaryDescriptor.FACTORY);
    fc.addGenerated(PrintBinaryDescriptor.FACTORY);
    fc.addGenerated(BinaryConcatDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromToDescriptor.FACTORY);
    fc.addGenerated(FindBinaryDescriptor.FACTORY);
    fc.addGenerated(FindBinaryFromDescriptor.FACTORY);
    // String functions
    fc.addGenerated(StringLikeDescriptor.FACTORY);
    fc.addGenerated(StringContainsDescriptor.FACTORY);
    fc.addGenerated(StringEndsWithDescriptor.FACTORY);
    fc.addGenerated(StringStartsWithDescriptor.FACTORY);
    fc.addGenerated(SubstringDescriptor.FACTORY);
    fc.addGenerated(StringEqualDescriptor.FACTORY);
    fc.addGenerated(StringLowerCaseDescriptor.FACTORY);
    fc.addGenerated(StringUpperCaseDescriptor.FACTORY);
    fc.addGenerated(StringLengthDescriptor.FACTORY);
    fc.addGenerated(Substring2Descriptor.FACTORY);
    fc.addGenerated(SubstringBeforeDescriptor.FACTORY);
    fc.addGenerated(SubstringAfterDescriptor.FACTORY);
    fc.addGenerated(StringToCodePointDescriptor.FACTORY);
    fc.addGenerated(CodePointToStringDescriptor.FACTORY);
    fc.addGenerated(StringConcatDescriptor.FACTORY);
    fc.addGenerated(StringJoinDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringInitCapDescriptor.FACTORY);
    fc.addGenerated(StringTrimDescriptor.FACTORY);
    fc.addGenerated(StringLTrimDescriptor.FACTORY);
    fc.addGenerated(StringRTrimDescriptor.FACTORY);
    fc.addGenerated(StringTrim2Descriptor.FACTORY);
    fc.addGenerated(StringLTrim2Descriptor.FACTORY);
    fc.addGenerated(StringRTrim2Descriptor.FACTORY);
    fc.addGenerated(StringPositionDescriptor.FACTORY);
    fc.addGenerated(StringRepeatDescriptor.FACTORY);
    fc.addGenerated(StringReplaceDescriptor.FACTORY);
    fc.addGenerated(StringReplaceWithLimitDescriptor.FACTORY);
    fc.addGenerated(StringReverseDescriptor.FACTORY);
    fc.addGenerated(StringSplitDescriptor.FACTORY);
    // Constructors
    fc.addGenerated(ABooleanConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryHexStringConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryBase64StringConstructorDescriptor.FACTORY);
    fc.addGenerated(AStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt8ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt16ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt32ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt64ConstructorDescriptor.FACTORY);
    fc.addGenerated(AFloatConstructorDescriptor.FACTORY);
    fc.addGenerated(ADoubleConstructorDescriptor.FACTORY);
    fc.addGenerated(APointConstructorDescriptor.FACTORY);
    fc.addGenerated(APoint3DConstructorDescriptor.FACTORY);
    fc.addGenerated(ALineConstructorDescriptor.FACTORY);
    fc.addGenerated(APolygonConstructorDescriptor.FACTORY);
    fc.addGenerated(ACircleConstructorDescriptor.FACTORY);
    fc.addGenerated(ARectangleConstructorDescriptor.FACTORY);
    fc.addGenerated(ATimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AYearMonthDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(ADayTimeDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AUUIDFromStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromTimeConstructorDescriptor.FACTORY);
    // Spatial
    fc.addGenerated(CreatePointDescriptor.FACTORY);
    fc.addGenerated(CreateLineDescriptor.FACTORY);
    fc.addGenerated(CreatePolygonDescriptor.FACTORY);
    fc.addGenerated(CreateCircleDescriptor.FACTORY);
    fc.addGenerated(CreateRectangleDescriptor.FACTORY);
    fc.addGenerated(SpatialAreaDescriptor.FACTORY);
    fc.addGenerated(SpatialDistanceDescriptor.FACTORY);
    fc.addGenerated(CreateMBRDescriptor.FACTORY);
    fc.addGenerated(SpatialCellDescriptor.FACTORY);
    fc.addGenerated(PointXCoordinateAccessor.FACTORY);
    fc.addGenerated(PointYCoordinateAccessor.FACTORY);
    fc.addGenerated(CircleRadiusAccessor.FACTORY);
    fc.addGenerated(CircleCenterAccessor.FACTORY);
    fc.addGenerated(LineRectanglePolygonAccessor.FACTORY);
    // full-text function
    fc.addGenerated(FullTextContainsDescriptor.FACTORY);
    fc.addGenerated(FullTextContainsWithoutOptionDescriptor.FACTORY);
    // Record functions.
    fc.addGenerated(GetRecordFieldsDescriptor.FACTORY);
    fc.addGenerated(GetRecordFieldValueDescriptor.FACTORY);
    fc.addGenerated(DeepEqualityDescriptor.FACTORY);
    fc.addGenerated(RecordMergeDescriptor.FACTORY);
    fc.addGenerated(RecordAddFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordLengthDescriptor.FACTORY);
    fc.addGenerated(RecordNamesDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveDescriptor.FACTORY);
    fc.addGenerated(RecordRenameDescriptor.FACTORY);
    fc.addGenerated(RecordUnwrapDescriptor.FACTORY);
    fc.add(RecordReplaceDescriptor.FACTORY);
    fc.add(RecordAddDescriptor.FACTORY);
    fc.add(RecordPutDescriptor.FACTORY);
    fc.addGenerated(RecordValuesDescriptor.FACTORY);
    fc.addGenerated(PairsDescriptor.FACTORY);
    // Spatial and temporal type accessors
    fc.addGenerated(TemporalYearAccessor.FACTORY);
    fc.addGenerated(TemporalMonthAccessor.FACTORY);
    fc.addGenerated(TemporalDayAccessor.FACTORY);
    fc.addGenerated(TemporalHourAccessor.FACTORY);
    fc.addGenerated(TemporalMinuteAccessor.FACTORY);
    fc.addGenerated(TemporalSecondAccessor.FACTORY);
    fc.addGenerated(TemporalMillisecondAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDatetimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDatetimeAccessor.FACTORY);
    // Temporal functions
    fc.addGenerated(UnixTimeFromDateInDaysDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromTimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DateFromUnixTimeInDaysDescriptor.FACTORY);
    fc.addGenerated(DateFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(TimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(TimeFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromDateAndTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDurationFromDateTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDuartionFromDateDescriptor.FACTORY);
    fc.addGenerated(AdjustDateTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(AdjustTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(IntervalBeforeDescriptor.FACTORY);
    fc.addGenerated(IntervalAfterDescriptor.FACTORY);
    fc.addGenerated(IntervalMeetsDescriptor.FACTORY);
    fc.addGenerated(IntervalMetByDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlapsDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlappedByDescriptor.FACTORY);
    fc.addGenerated(OverlapDescriptor.FACTORY);
    fc.addGenerated(IntervalStartsDescriptor.FACTORY);
    fc.addGenerated(IntervalStartedByDescriptor.FACTORY);
    fc.addGenerated(IntervalCoversDescriptor.FACTORY);
    fc.addGenerated(IntervalCoveredByDescriptor.FACTORY);
    fc.addGenerated(IntervalEndsDescriptor.FACTORY);
    fc.addGenerated(IntervalEndedByDescriptor.FACTORY);
    fc.addGenerated(DurationFromMillisecondsDescriptor.FACTORY);
    fc.addGenerated(DurationFromMonthsDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(MonthsFromYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(MillisecondsFromDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(DurationEqualDescriptor.FACTORY);
    fc.addGenerated(GetYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(GetDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(IntervalBinDescriptor.FACTORY);
    fc.addGenerated(OverlapBinsDescriptor.FACTORY);
    fc.addGenerated(DayOfWeekDescriptor.FACTORY);
    fc.addGenerated(ParseDateDescriptor.FACTORY);
    fc.addGenerated(ParseTimeDescriptor.FACTORY);
    fc.addGenerated(ParseDateTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateDescriptor.FACTORY);
    fc.addGenerated(PrintTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateTimeDescriptor.FACTORY);
    fc.addGenerated(GetOverlappingIntervalDescriptor.FACTORY);
    fc.addGenerated(DurationFromIntervalDescriptor.FACTORY);
    // Type functions.
    fc.addGenerated(IsArrayDescriptor.FACTORY);
    fc.addGenerated(IsAtomicDescriptor.FACTORY);
    fc.addGenerated(IsBooleanDescriptor.FACTORY);
    fc.addGenerated(IsNumberDescriptor.FACTORY);
    fc.addGenerated(IsObjectDescriptor.FACTORY);
    fc.addGenerated(IsStringDescriptor.FACTORY);
    fc.addGenerated(ToArrayDescriptor.FACTORY);
    fc.addGenerated(ToAtomicDescriptor.FACTORY);
    fc.addGenerated(ToBigIntDescriptor.FACTORY);
    fc.addGenerated(ToBooleanDescriptor.FACTORY);
    fc.addGenerated(ToDoubleDescriptor.FACTORY);
    fc.addGenerated(ToNumberDescriptor.FACTORY);
    fc.addGenerated(ToObjectDescriptor.FACTORY);
    fc.addGenerated(ToStringDescriptor.FACTORY);
    fc.addGenerated(TreatAsIntegerDescriptor.FACTORY);
    // Cast function
    fc.addGenerated(CastTypeDescriptor.FACTORY);
    fc.addGenerated(CastTypeLaxDescriptor.FACTORY);
    // Record function
    fc.addGenerated(RecordPairsDescriptor.FACTORY);
    // Other functions
    fc.addGenerated(RandomWithSeedDescriptor.FACTORY);
    ServiceLoader.load(IFunctionRegistrant.class).iterator().forEachRemaining(c -> c.register(fc));
    return fc;
}
#method_after
public static FunctionCollection createDefaultFunctionCollection() {
    FunctionCollection fc = new FunctionCollection();
    // array functions
    fc.add(ArrayRemoveDescriptor.FACTORY);
    fc.add(ArrayPutDescriptor.FACTORY);
    fc.add(ArrayPrependDescriptor.FACTORY);
    fc.add(ArrayAppendDescriptor.FACTORY);
    fc.add(ArrayInsertDescriptor.FACTORY);
    fc.addGenerated(ArrayPositionDescriptor.FACTORY);
    fc.addGenerated(ArrayRepeatDescriptor.FACTORY);
    fc.addGenerated(ArrayContainsDescriptor.FACTORY);
    fc.addGenerated(ArrayReverseDescriptor.FACTORY);
    fc.addGenerated(ArraySortDescriptor.FACTORY);
    fc.addGenerated(ArrayDistinctDescriptor.FACTORY);
    fc.addGenerated(ArrayUnionDescriptor.FACTORY);
    fc.addGenerated(ArrayIntersectDescriptor.FACTORY);
    fc.addGenerated(ArrayIfNullDescriptor.FACTORY);
    fc.addGenerated(ArrayConcatDescriptor.FACTORY);
    fc.addGenerated(ArrayRangeDescriptor.FACTORY);
    fc.addGenerated(ArrayFlattenDescriptor.FACTORY);
    fc.add(ArrayReplaceDescriptor.FACTORY);
    fc.addGenerated(ArraySliceWithEndPositionDescriptor.FACTORY);
    fc.addGenerated(ArraySliceWithoutEndPositionDescriptor.FACTORY);
    fc.addGenerated(ArraySymDiffDescriptor.FACTORY);
    fc.addGenerated(ArraySymDiffnDescriptor.FACTORY);
    fc.addGenerated(ArrayStarDescriptor.FACTORY);
    // unnesting functions
    fc.add(TidRunningAggregateDescriptor.FACTORY);
    fc.add(ScanCollectionDescriptor.FACTORY);
    fc.add(RangeDescriptor.FACTORY);
    fc.add(SubsetCollectionDescriptor.FACTORY);
    // aggregate functions
    fc.add(ListifyAggregateDescriptor.FACTORY);
    fc.add(CountAggregateDescriptor.FACTORY);
    fc.add(AvgAggregateDescriptor.FACTORY);
    fc.add(LocalAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SumAggregateDescriptor.FACTORY);
    fc.add(LocalSumAggregateDescriptor.FACTORY);
    fc.add(IntermediateSumAggregateDescriptor.FACTORY);
    fc.add(GlobalSumAggregateDescriptor.FACTORY);
    fc.add(MaxAggregateDescriptor.FACTORY);
    fc.add(LocalMaxAggregateDescriptor.FACTORY);
    fc.add(MinAggregateDescriptor.FACTORY);
    fc.add(LocalMinAggregateDescriptor.FACTORY);
    fc.add(FirstElementAggregateDescriptor.FACTORY);
    fc.add(LocalFirstElementAggregateDescriptor.FACTORY);
    fc.add(StddevAggregateDescriptor.FACTORY);
    fc.add(LocalStddevAggregateDescriptor.FACTORY);
    fc.add(IntermediateStddevAggregateDescriptor.FACTORY);
    fc.add(GlobalStddevAggregateDescriptor.FACTORY);
    fc.add(LocalSamplingAggregateDescriptor.FACTORY);
    fc.add(RangeMapAggregateDescriptor.FACTORY);
    fc.add(StddevPopAggregateDescriptor.FACTORY);
    fc.add(LocalStddevPopAggregateDescriptor.FACTORY);
    fc.add(IntermediateStddevPopAggregateDescriptor.FACTORY);
    fc.add(GlobalStddevPopAggregateDescriptor.FACTORY);
    fc.add(VarAggregateDescriptor.FACTORY);
    fc.add(LocalVarAggregateDescriptor.FACTORY);
    fc.add(IntermediateVarAggregateDescriptor.FACTORY);
    fc.add(GlobalVarAggregateDescriptor.FACTORY);
    fc.add(VarPopAggregateDescriptor.FACTORY);
    fc.add(LocalVarPopAggregateDescriptor.FACTORY);
    fc.add(IntermediateVarPopAggregateDescriptor.FACTORY);
    fc.add(GlobalVarPopAggregateDescriptor.FACTORY);
    // serializable aggregates
    fc.add(SerializableCountAggregateDescriptor.FACTORY);
    fc.add(SerializableAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSumAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSumAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSumAggregateDescriptor.FACTORY);
    fc.add(SerializableStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableVarAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalVarAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateVarAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalVarAggregateDescriptor.FACTORY);
    fc.add(SerializableVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalVarPopAggregateDescriptor.FACTORY);
    // scalar aggregates
    fc.add(ScalarCountAggregateDescriptor.FACTORY);
    fc.add(ScalarAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSumAggregateDescriptor.FACTORY);
    fc.add(ScalarMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarMinAggregateDescriptor.FACTORY);
    fc.add(EmptyStreamAggregateDescriptor.FACTORY);
    fc.add(NonEmptyStreamAggregateDescriptor.FACTORY);
    fc.add(ScalarStddevAggregateDescriptor.FACTORY);
    fc.add(ScalarStddevPopAggregateDescriptor.FACTORY);
    fc.add(ScalarVarAggregateDescriptor.FACTORY);
    fc.add(ScalarVarPopAggregateDescriptor.FACTORY);
    // SQL aggregates
    fc.add(SqlCountAggregateDescriptor.FACTORY);
    fc.add(SqlAvgAggregateDescriptor.FACTORY);
    fc.add(LocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SqlSumAggregateDescriptor.FACTORY);
    fc.add(LocalSqlSumAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlSumAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SqlMaxAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMaxAggregateDescriptor.FACTORY);
    fc.add(SqlMinAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMinAggregateDescriptor.FACTORY);
    fc.add(SqlStddevAggregateDescriptor.FACTORY);
    fc.add(LocalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlStddevAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(LocalSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SqlVarAggregateDescriptor.FACTORY);
    fc.add(LocalSqlVarAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlVarAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlVarAggregateDescriptor.FACTORY);
    fc.add(SqlVarPopAggregateDescriptor.FACTORY);
    fc.add(LocalSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlVarPopAggregateDescriptor.FACTORY);
    // SQL serializable aggregates
    fc.add(SerializableSqlCountAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlVarAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlVarAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlVarAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlVarAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlVarPopAggregateDescriptor.FACTORY);
    // SQL scalar aggregates
    fc.add(ScalarSqlCountAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlSumAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMinAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlStddevAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlVarAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlVarPopAggregateDescriptor.FACTORY);
    // window functions
    fc.add(RowNumberRunningAggregateDescriptor.FACTORY);
    fc.add(RankRunningAggregateDescriptor.FACTORY);
    fc.add(DenseRankRunningAggregateDescriptor.FACTORY);
    fc.add(PercentRankRunningAggregateDescriptor.FACTORY);
    fc.add(NtileRunningAggregateDescriptor.FACTORY);
    // boolean functions
    fc.add(AndDescriptor.FACTORY);
    fc.add(OrDescriptor.FACTORY);
    // Record constructors / functions
    fc.add(ClosedRecordConstructorDescriptor.FACTORY);
    fc.add(OpenRecordConstructorDescriptor.FACTORY);
    fc.add(RecordConcatDescriptor.FACTORY);
    fc.add(RecordConcatStrictDescriptor.FACTORY);
    // List constructors
    fc.add(OrderedListConstructorDescriptor.FACTORY);
    fc.add(UnorderedListConstructorDescriptor.FACTORY);
    // Sleep function
    fc.add(SleepDescriptor.FACTORY);
    // Inject failure function
    fc.add(InjectFailureDescriptor.FACTORY);
    // Get Job Parameter function
    fc.add(GetJobParameterByNameDescriptor.FACTORY);
    // Switch case
    fc.add(SwitchCaseDescriptor.FACTORY);
    // null functions
    fc.add(IsMissingDescriptor.FACTORY);
    fc.add(IsNullDescriptor.FACTORY);
    fc.add(IsUnknownDescriptor.FACTORY);
    fc.add(IsSystemNullDescriptor.FACTORY);
    fc.add(CheckUnknownDescriptor.FACTORY);
    fc.add(IfMissingDescriptor.FACTORY);
    fc.add(IfNullDescriptor.FACTORY);
    fc.add(IfMissingOrNullDescriptor.FACTORY);
    // uuid generators (zero independent functions)
    fc.add(CreateUUIDDescriptor.FACTORY);
    fc.add(UUIDDescriptor.FACTORY);
    fc.add(CreateQueryUIDDescriptor.FACTORY);
    fc.add(RandomDescriptor.FACTORY);
    fc.add(CurrentDateDescriptor.FACTORY);
    fc.add(CurrentTimeDescriptor.FACTORY);
    fc.add(CurrentDateTimeDescriptor.FACTORY);
    // functions that need generated class for null-handling.
    // Element accessors.
    fc.addGenerated(FieldAccessByIndexDescriptor.FACTORY);
    fc.addGenerated(FieldAccessByNameDescriptor.FACTORY);
    fc.addGenerated(FieldAccessNestedDescriptor.FACTORY);
    fc.addGenerated(AnyCollectionMemberDescriptor.FACTORY);
    fc.addGenerated(GetItemDescriptor.FACTORY);
    // Numeric functions
    fc.add(IfInfDescriptor.FACTORY);
    fc.add(IfNanDescriptor.FACTORY);
    fc.add(IfNanOrInfDescriptor.FACTORY);
    fc.addGenerated(NumericUnaryMinusDescriptor.FACTORY);
    fc.addGenerated(NumericAddDescriptor.FACTORY);
    fc.addGenerated(NumericDivideDescriptor.FACTORY);
    fc.addGenerated(NumericDivDescriptor.FACTORY);
    fc.addGenerated(NumericMultiplyDescriptor.FACTORY);
    fc.addGenerated(NumericSubDescriptor.FACTORY);
    fc.addGenerated(NumericModuloDescriptor.FACTORY);
    fc.addGenerated(NumericPowerDescriptor.FACTORY);
    fc.addGenerated(NotDescriptor.FACTORY);
    fc.addGenerated(LenDescriptor.FACTORY);
    fc.addGenerated(NumericAbsDescriptor.FACTORY);
    fc.addGenerated(NumericCeilingDescriptor.FACTORY);
    fc.addGenerated(NumericFloorDescriptor.FACTORY);
    fc.addGenerated(NumericRoundDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEvenDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEven2Descriptor.FACTORY);
    fc.addGenerated(NumericACosDescriptor.FACTORY);
    fc.addGenerated(NumericASinDescriptor.FACTORY);
    fc.addGenerated(NumericATanDescriptor.FACTORY);
    fc.addGenerated(NumericDegreesDescriptor.FACTORY);
    fc.addGenerated(NumericRadiansDescriptor.FACTORY);
    fc.addGenerated(NumericCosDescriptor.FACTORY);
    fc.addGenerated(NumericSinDescriptor.FACTORY);
    fc.addGenerated(NumericTanDescriptor.FACTORY);
    fc.addGenerated(NumericExpDescriptor.FACTORY);
    fc.addGenerated(NumericLnDescriptor.FACTORY);
    fc.addGenerated(NumericLogDescriptor.FACTORY);
    fc.addGenerated(NumericSqrtDescriptor.FACTORY);
    fc.addGenerated(NumericSignDescriptor.FACTORY);
    fc.addGenerated(NumericTruncDescriptor.FACTORY);
    fc.addGenerated(NumericATan2Descriptor.FACTORY);
    // Comparisons.
    fc.addGenerated(EqualsDescriptor.FACTORY);
    fc.addGenerated(GreaterThanDescriptor.FACTORY);
    fc.addGenerated(GreaterThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(LessThanDescriptor.FACTORY);
    fc.addGenerated(LessThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(NotEqualsDescriptor.FACTORY);
    // If-Equals functions
    fc.addGenerated(MissingIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NullIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NanIfEqualsDescriptor.FACTORY);
    fc.addGenerated(PosInfIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NegInfIfEqualsDescriptor.FACTORY);
    // Binary functions
    fc.addGenerated(BinaryLengthDescriptor.FACTORY);
    fc.addGenerated(ParseBinaryDescriptor.FACTORY);
    fc.addGenerated(PrintBinaryDescriptor.FACTORY);
    fc.addGenerated(BinaryConcatDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromToDescriptor.FACTORY);
    fc.addGenerated(FindBinaryDescriptor.FACTORY);
    fc.addGenerated(FindBinaryFromDescriptor.FACTORY);
    // String functions
    fc.addGenerated(StringLikeDescriptor.FACTORY);
    fc.addGenerated(StringContainsDescriptor.FACTORY);
    fc.addGenerated(StringEndsWithDescriptor.FACTORY);
    fc.addGenerated(StringStartsWithDescriptor.FACTORY);
    fc.addGenerated(SubstringDescriptor.FACTORY);
    fc.addGenerated(StringEqualDescriptor.FACTORY);
    fc.addGenerated(StringLowerCaseDescriptor.FACTORY);
    fc.addGenerated(StringUpperCaseDescriptor.FACTORY);
    fc.addGenerated(StringLengthDescriptor.FACTORY);
    fc.addGenerated(Substring2Descriptor.FACTORY);
    fc.addGenerated(SubstringBeforeDescriptor.FACTORY);
    fc.addGenerated(SubstringAfterDescriptor.FACTORY);
    fc.addGenerated(StringToCodePointDescriptor.FACTORY);
    fc.addGenerated(CodePointToStringDescriptor.FACTORY);
    fc.addGenerated(StringConcatDescriptor.FACTORY);
    fc.addGenerated(StringJoinDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringInitCapDescriptor.FACTORY);
    fc.addGenerated(StringTrimDescriptor.FACTORY);
    fc.addGenerated(StringLTrimDescriptor.FACTORY);
    fc.addGenerated(StringRTrimDescriptor.FACTORY);
    fc.addGenerated(StringTrim2Descriptor.FACTORY);
    fc.addGenerated(StringLTrim2Descriptor.FACTORY);
    fc.addGenerated(StringRTrim2Descriptor.FACTORY);
    fc.addGenerated(StringPositionDescriptor.FACTORY);
    fc.addGenerated(StringRepeatDescriptor.FACTORY);
    fc.addGenerated(StringReplaceDescriptor.FACTORY);
    fc.addGenerated(StringReplaceWithLimitDescriptor.FACTORY);
    fc.addGenerated(StringReverseDescriptor.FACTORY);
    fc.addGenerated(StringSplitDescriptor.FACTORY);
    // Constructors
    fc.addGenerated(ABooleanConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryHexStringConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryBase64StringConstructorDescriptor.FACTORY);
    fc.addGenerated(AStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt8ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt16ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt32ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt64ConstructorDescriptor.FACTORY);
    fc.addGenerated(AFloatConstructorDescriptor.FACTORY);
    fc.addGenerated(ADoubleConstructorDescriptor.FACTORY);
    fc.addGenerated(APointConstructorDescriptor.FACTORY);
    fc.addGenerated(APoint3DConstructorDescriptor.FACTORY);
    fc.addGenerated(ALineConstructorDescriptor.FACTORY);
    fc.addGenerated(APolygonConstructorDescriptor.FACTORY);
    fc.addGenerated(ACircleConstructorDescriptor.FACTORY);
    fc.addGenerated(ARectangleConstructorDescriptor.FACTORY);
    fc.addGenerated(ATimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AYearMonthDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(ADayTimeDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AUUIDFromStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromTimeConstructorDescriptor.FACTORY);
    // Spatial
    fc.addGenerated(CreatePointDescriptor.FACTORY);
    fc.addGenerated(CreateLineDescriptor.FACTORY);
    fc.addGenerated(CreatePolygonDescriptor.FACTORY);
    fc.addGenerated(CreateCircleDescriptor.FACTORY);
    fc.addGenerated(CreateRectangleDescriptor.FACTORY);
    fc.addGenerated(SpatialAreaDescriptor.FACTORY);
    fc.addGenerated(SpatialDistanceDescriptor.FACTORY);
    fc.addGenerated(CreateMBRDescriptor.FACTORY);
    fc.addGenerated(SpatialCellDescriptor.FACTORY);
    fc.addGenerated(PointXCoordinateAccessor.FACTORY);
    fc.addGenerated(PointYCoordinateAccessor.FACTORY);
    fc.addGenerated(CircleRadiusAccessor.FACTORY);
    fc.addGenerated(CircleCenterAccessor.FACTORY);
    fc.addGenerated(LineRectanglePolygonAccessor.FACTORY);
    // full-text function
    fc.addGenerated(FullTextContainsDescriptor.FACTORY);
    fc.addGenerated(FullTextContainsWithoutOptionDescriptor.FACTORY);
    // Record functions.
    fc.addGenerated(GetRecordFieldsDescriptor.FACTORY);
    fc.addGenerated(GetRecordFieldValueDescriptor.FACTORY);
    fc.addGenerated(DeepEqualityDescriptor.FACTORY);
    fc.addGenerated(RecordMergeDescriptor.FACTORY);
    fc.addGenerated(RecordAddFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordLengthDescriptor.FACTORY);
    fc.addGenerated(RecordNamesDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveDescriptor.FACTORY);
    fc.addGenerated(RecordRenameDescriptor.FACTORY);
    fc.addGenerated(RecordUnwrapDescriptor.FACTORY);
    fc.add(RecordReplaceDescriptor.FACTORY);
    fc.add(RecordAddDescriptor.FACTORY);
    fc.add(RecordPutDescriptor.FACTORY);
    fc.addGenerated(RecordValuesDescriptor.FACTORY);
    fc.addGenerated(PairsDescriptor.FACTORY);
    // Spatial and temporal type accessors
    fc.addGenerated(TemporalYearAccessor.FACTORY);
    fc.addGenerated(TemporalMonthAccessor.FACTORY);
    fc.addGenerated(TemporalDayAccessor.FACTORY);
    fc.addGenerated(TemporalHourAccessor.FACTORY);
    fc.addGenerated(TemporalMinuteAccessor.FACTORY);
    fc.addGenerated(TemporalSecondAccessor.FACTORY);
    fc.addGenerated(TemporalMillisecondAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDatetimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDatetimeAccessor.FACTORY);
    // Temporal functions
    fc.addGenerated(UnixTimeFromDateInDaysDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromTimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DateFromUnixTimeInDaysDescriptor.FACTORY);
    fc.addGenerated(DateFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(TimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(TimeFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromDateAndTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDurationFromDateTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDuartionFromDateDescriptor.FACTORY);
    fc.addGenerated(AdjustDateTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(AdjustTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(IntervalBeforeDescriptor.FACTORY);
    fc.addGenerated(IntervalAfterDescriptor.FACTORY);
    fc.addGenerated(IntervalMeetsDescriptor.FACTORY);
    fc.addGenerated(IntervalMetByDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlapsDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlappedByDescriptor.FACTORY);
    fc.addGenerated(OverlapDescriptor.FACTORY);
    fc.addGenerated(IntervalStartsDescriptor.FACTORY);
    fc.addGenerated(IntervalStartedByDescriptor.FACTORY);
    fc.addGenerated(IntervalCoversDescriptor.FACTORY);
    fc.addGenerated(IntervalCoveredByDescriptor.FACTORY);
    fc.addGenerated(IntervalEndsDescriptor.FACTORY);
    fc.addGenerated(IntervalEndedByDescriptor.FACTORY);
    fc.addGenerated(DurationFromMillisecondsDescriptor.FACTORY);
    fc.addGenerated(DurationFromMonthsDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(MonthsFromYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(MillisecondsFromDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(DurationEqualDescriptor.FACTORY);
    fc.addGenerated(GetYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(GetDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(IntervalBinDescriptor.FACTORY);
    fc.addGenerated(OverlapBinsDescriptor.FACTORY);
    fc.addGenerated(DayOfWeekDescriptor.FACTORY);
    fc.addGenerated(ParseDateDescriptor.FACTORY);
    fc.addGenerated(ParseTimeDescriptor.FACTORY);
    fc.addGenerated(ParseDateTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateDescriptor.FACTORY);
    fc.addGenerated(PrintTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateTimeDescriptor.FACTORY);
    fc.addGenerated(GetOverlappingIntervalDescriptor.FACTORY);
    fc.addGenerated(DurationFromIntervalDescriptor.FACTORY);
    // Type functions.
    fc.addGenerated(IsArrayDescriptor.FACTORY);
    fc.addGenerated(IsAtomicDescriptor.FACTORY);
    fc.addGenerated(IsBooleanDescriptor.FACTORY);
    fc.addGenerated(IsNumberDescriptor.FACTORY);
    fc.addGenerated(IsObjectDescriptor.FACTORY);
    fc.addGenerated(IsStringDescriptor.FACTORY);
    fc.addGenerated(ToArrayDescriptor.FACTORY);
    fc.addGenerated(ToAtomicDescriptor.FACTORY);
    fc.addGenerated(ToBigIntDescriptor.FACTORY);
    fc.addGenerated(ToBooleanDescriptor.FACTORY);
    fc.addGenerated(ToDoubleDescriptor.FACTORY);
    fc.addGenerated(ToNumberDescriptor.FACTORY);
    fc.addGenerated(ToObjectDescriptor.FACTORY);
    fc.addGenerated(ToStringDescriptor.FACTORY);
    fc.addGenerated(TreatAsIntegerDescriptor.FACTORY);
    // Cast function
    fc.addGenerated(CastTypeDescriptor.FACTORY);
    fc.addGenerated(CastTypeLaxDescriptor.FACTORY);
    // Record function
    fc.addGenerated(RecordPairsDescriptor.FACTORY);
    // Other functions
    fc.addGenerated(RandomWithSeedDescriptor.FACTORY);
    ServiceLoader.load(IFunctionRegistrant.class).iterator().forEachRemaining(c -> c.register(fc));
    return fc;
}
#end_block

#method_before
public void set(String strValue) throws IOException {
    ensureCapacity(strValue.length());
    strValue.getChars(0, strValue.length(), value, 0);
}
#method_after
public void set(String strValue) throws IOException {
    ensureCapacity(strValue.length());
    strValue.getChars(0, strValue.length(), value, 0);
    this.size = strValue.length();
}
#end_block

#method_before
@Test
public void openRecordTypeTest() throws IOException, URISyntaxException {
    String[] ids = { "720549057849114629", "668950503552864257", "668945640186101761", "263602997047730177", "668948268605403136", "741701526859567104" };
    // contruct type
    IAType geoFieldType = new ARecordType("GeoType", new String[] { "coordinates" }, new IAType[] { new AOrderedListType(AFLOAT, "point") }, true);
    List<IAType> unionTypeList = new ArrayList<>();
    unionTypeList.add(geoFieldType);
    unionTypeList.add(ANULL);
    unionTypeList.add(AMISSING);
    IAType geoUnionType = new AUnionType(unionTypeList, "GeoType?");
    ARecordType tweetRecordType = new ARecordType("TweetType", new String[] { "id", "geo" }, new IAType[] { AINT64, geoUnionType }, true);
    TweetParser parser = new TweetParser(tweetRecordType);
    List<String> lines = Files.readAllLines(Paths.get(getClass().getResource("/test_tweets.txt").toURI()));
    ByteArrayOutputStream is = new ByteArrayOutputStream();
    DataOutput output = new DataOutputStream(is);
    for (int iter1 = 0; iter1 < lines.size(); iter1++) {
        CharArrayRecord record = new CharArrayRecord(0);
        record.set(lines.get(iter1));
        try {
            parser.parse(record, output);
        } catch (HyracksDataException e) {
            e.printStackTrace();
            Assert.fail("Unexpected failure in parser.");
        }
        Assert.assertTrue((PA.getValue(parser, "aInt64")).toString().equals(ids[iter1]));
    }
}
#method_after
@Test
public void openRecordTypeTest() throws IOException, URISyntaxException {
    String[] ids = { "720549057849114629", "668950503552864257", "668945640186101761", "263602997047730177", "668948268605403136", "741701526859567104" };
    // contruct type
    IAType geoFieldType = new ARecordType("GeoType", new String[] { "coordinates" }, new IAType[] { new AOrderedListType(AFLOAT, "point") }, true);
    List<IAType> unionTypeList = new ArrayList<>();
    unionTypeList.add(geoFieldType);
    unionTypeList.add(ANULL);
    unionTypeList.add(AMISSING);
    IAType geoUnionType = new AUnionType(unionTypeList, "GeoType?");
    ARecordType tweetRecordType = new ARecordType("TweetType", new String[] { "id", "geo" }, new IAType[] { AINT64, geoUnionType }, true);
    TweetParser parser = new TweetParser(tweetRecordType);
    CharArrayRecord record = new CharArrayRecord();
    List<String> lines = Files.readAllLines(Paths.get(getClass().getResource("/test_tweets.txt").toURI()));
    ByteArrayOutputStream is = new ByteArrayOutputStream();
    DataOutput output = new DataOutputStream(is);
    for (int iter1 = 0; iter1 < lines.size(); iter1++) {
        record.set(lines.get(iter1));
        try {
            parser.parse(record, output);
        } catch (HyracksDataException e) {
            e.printStackTrace();
            Assert.fail("Unexpected failure in parser.");
        }
        Assert.assertTrue((PA.getValue(parser, "aInt64")).toString().equals(ids[iter1]));
    }
}
#end_block

#method_before
@Test
public void closedRecordTypeTest() throws IOException, URISyntaxException {
    // contruct type
    IAType geoFieldType = new ARecordType("GeoType", new String[] { "coordinates" }, new IAType[] { new AOrderedListType(AFLOAT, "point") }, true);
    ARecordType tweetRecordType = new ARecordType("TweetType", new String[] { "id", "geo" }, new IAType[] { AINT64, geoFieldType }, true);
    TweetParser parser = new TweetParser(tweetRecordType);
    List<String> lines = Files.readAllLines(Paths.get(getClass().getResource("/test_tweets.txt").toURI()));
    ByteArrayOutputStream is = new ByteArrayOutputStream();
    DataOutput output = new DataOutputStream(is);
    int regularCount = 0;
    for (int iter1 = 0; iter1 < lines.size(); iter1++) {
        CharArrayRecord record = new CharArrayRecord(0);
        record.set(lines.get(iter1));
        try {
            parser.parse(record, output);
            regularCount++;
        } catch (HyracksDataException e) {
            Assert.assertTrue(e.toString().contains("Non-null") && (iter1 == 0 || iter1 == 1));
        }
    }
    Assert.assertTrue(regularCount == 4);
}
#method_after
@Test
public void closedRecordTypeTest() throws IOException, URISyntaxException {
    // contruct type
    IAType geoFieldType = new ARecordType("GeoType", new String[] { "coordinates" }, new IAType[] { new AOrderedListType(AFLOAT, "point") }, true);
    ARecordType tweetRecordType = new ARecordType("TweetType", new String[] { "id", "geo" }, new IAType[] { AINT64, geoFieldType }, true);
    TweetParser parser = new TweetParser(tweetRecordType);
    List<String> lines = Files.readAllLines(Paths.get(getClass().getResource("/test_tweets.txt").toURI()));
    ByteArrayOutputStream is = new ByteArrayOutputStream();
    DataOutput output = new DataOutputStream(is);
    CharArrayRecord record = new CharArrayRecord();
    int regularCount = 0;
    for (int iter1 = 0; iter1 < lines.size(); iter1++) {
        record.set(lines.get(iter1));
        try {
            parser.parse(record, output);
            regularCount++;
        } catch (HyracksDataException e) {
            Assert.assertTrue(e.toString().contains("Non-null") && (iter1 == 0 || iter1 == 1));
        }
    }
    Assert.assertTrue(regularCount == 4);
}
#end_block

#method_before
private void init(TwitterStream twitterStream) {
    record = new CharArrayRecord(0);
    inputQ = new LinkedBlockingQueue<>();
    this.twitterStream = twitterStream;
}
#method_after
private void init(TwitterStream twitterStream) {
    record = new CharArrayRecord();
    inputQ = new LinkedBlockingQueue<>();
    this.twitterStream = twitterStream;
}
#end_block

#method_before
private boolean rewriteCountVar(AggregateOperator agg, IOptimizationContext context) throws AlgebricksException {
    if (agg.getExpressions().size() != 1) {
        return false;
    }
    ILogicalExpression exp = agg.getExpressions().get(0).getValue();
    if (exp.getExpressionTag() != LogicalExpressionTag.FUNCTION_CALL) {
        return false;
    }
    AbstractFunctionCallExpression fun = (AbstractFunctionCallExpression) exp;
    if (fun.getArguments().size() != 1) {
        return false;
    }
    ILogicalExpression arg = fun.getArguments().get(0).getValue();
    if (arg.getExpressionTag() != LogicalExpressionTag.VARIABLE) {
        return false;
    }
    if (fun.getFunctionIdentifier() == BuiltinFunctions.COUNT) {
        // for strict count, we can always replace count(var) with count(1)
        fun.getArguments().get(0).setValue(new ConstantExpression(new AsterixConstantValue(new AInt64(1L))));
        return true;
    } else if (fun.getFunctionIdentifier() == BuiltinFunctions.SQL_COUNT) {
        // for SQL count, we can replace count(var) with count(1) only when var is not nullable
        IVariableTypeEnvironment env = context.getOutputTypeEnvironment(agg.getInputs().get(0).getValue());
        LogicalVariable countVar = ((VariableReferenceExpression) arg).getVariableReference();
        Object varType = env.getVarType(countVar);
        boolean nullable = TypeHelper.canBeUnknown((IAType) varType) || !TypeHelper.isClosed((IAType) varType);
        if (!nullable) {
            fun.getArguments().get(0).setValue(new ConstantExpression(new AsterixConstantValue(new AInt64(1L))));
            return true;
        } else {
            return false;
        }
    } else {
        return false;
    }
}
#method_after
private boolean rewriteCountVar(AggregateOperator agg, IOptimizationContext context) throws AlgebricksException {
    if (agg.getExpressions().size() != 1) {
        return false;
    }
    ILogicalExpression exp = agg.getExpressions().get(0).getValue();
    if (exp.getExpressionTag() != LogicalExpressionTag.FUNCTION_CALL) {
        return false;
    }
    AbstractFunctionCallExpression fun = (AbstractFunctionCallExpression) exp;
    if (fun.getArguments().size() != 1) {
        return false;
    }
    ILogicalExpression arg = fun.getArguments().get(0).getValue();
    if (arg.getExpressionTag() != LogicalExpressionTag.VARIABLE) {
        return false;
    }
    if (fun.getFunctionIdentifier() == BuiltinFunctions.COUNT) {
        // for strict count, we can always replace count(var) with count(1)
        fun.getArguments().get(0).setValue(new ConstantExpression(new AsterixConstantValue(new AInt64(1L))));
        return true;
    } else if (fun.getFunctionIdentifier() == BuiltinFunctions.SQL_COUNT) {
        // for SQL count, we can replace count(var) with count(1) only when var is not nullable
        IVariableTypeEnvironment env = context.getOutputTypeEnvironment(agg.getInputs().get(0).getValue());
        LogicalVariable countVar = ((VariableReferenceExpression) arg).getVariableReference();
        Object varType = env.getVarType(countVar);
        boolean nullable = TypeHelper.canBeUnknown((IAType) varType);
        if (!nullable) {
            fun.getArguments().get(0).setValue(new ConstantExpression(new AsterixConstantValue(new AInt64(1L))));
            return true;
        } else {
            return false;
        }
    } else {
        return false;
    }
}
#end_block

#method_before
public static void enlistMetadataDataset(INCServiceContext ncServiceCtx, IMetadataIndex index) throws HyracksDataException {
    final int datasetId = index.getDatasetId().getId();
    // reserve memory for metadata dataset to ensure it can be opened when needed
    if (!appContext.getDatasetMemoryManager().reserve(index.getDatasetId().getId())) {
        throw new IllegalStateException("Failed to reserve memory for metadata dataset (" + datasetId + ")");
    }
    String metadataPartitionPath = StoragePathUtil.prepareStoragePartitionPath(MetadataNode.INSTANCE.getMetadataStoragePartition());
    String resourceName = metadataPartitionPath + File.separator + index.getFileNameRelativePath();
    FileReference file = ioManager.resolve(resourceName);
    index.setFile(file);
    ITypeTraits[] typeTraits = index.getTypeTraits();
    IBinaryComparatorFactory[] cmpFactories = index.getKeyBinaryComparatorFactory();
    int[] bloomFilterKeyFields = index.getBloomFilterKeyFields();
    // opTrackerProvider and ioOpCallbackFactory should both be acquired through
    // IStorageManager
    // We are unable to do this since IStorageManager needs a dataset to determine
    // the appropriate
    // objects
    ILSMOperationTrackerFactory opTrackerFactory = index.isPrimaryIndex() ? new PrimaryIndexOperationTrackerFactory(datasetId) : new SecondaryIndexOperationTrackerFactory(datasetId);
    ILSMComponentIdGeneratorFactory idGeneratorProvider = new DatasetLSMComponentIdGeneratorFactory(datasetId);
    DatasetInfoProvider datasetInfoProvider = new DatasetInfoProvider(datasetId);
    ILSMIOOperationCallbackFactory ioOpCallbackFactory = new LSMIndexIOOperationCallbackFactory(idGeneratorProvider, datasetInfoProvider);
    IStorageComponentProvider storageComponentProvider = appContext.getStorageComponentProvider();
    if (isNewUniverse()) {
        final double bloomFilterFalsePositiveRate = appContext.getStorageProperties().getBloomFilterFalsePositiveRate();
        LSMBTreeLocalResourceFactory lsmBtreeFactory = new LSMBTreeLocalResourceFactory(storageComponentProvider.getStorageManager(), typeTraits, cmpFactories, null, null, null, opTrackerFactory, ioOpCallbackFactory, storageComponentProvider.getMetadataPageManagerFactory(), new AsterixVirtualBufferCacheProvider(datasetId), storageComponentProvider.getIoOperationSchedulerProvider(), appContext.getMetadataMergePolicyFactory(), GlobalConfig.DEFAULT_COMPACTION_POLICY_PROPERTIES, true, bloomFilterKeyFields, bloomFilterFalsePositiveRate, true, null, null);
        DatasetLocalResourceFactory dsLocalResourceFactory = new DatasetLocalResourceFactory(datasetId, lsmBtreeFactory);
        // TODO(amoudi) Creating the index should be done through the same code path as
        // other indexes
        // This is to be done by having a metadata dataset associated with each index
        IIndexBuilder indexBuilder = new IndexBuilder(ncServiceCtx, storageComponentProvider.getStorageManager(), index::getResourceId, file, dsLocalResourceFactory, true);
        indexBuilder.build();
    } else {
        final LocalResource resource = localResourceRepository.get(file.getRelativePath());
        if (resource == null) {
            throw new HyracksDataException("Could not find required metadata indexes. Please delete " + appContext.getMetadataProperties().getTransactionLogDirs().get(appContext.getTransactionSubsystem().getId()) + " to intialize as a new instance. (WARNING: all data will be lost.)");
        }
        // similar to other resources?
        if (index.getResourceId() != resource.getId()) {
            throw new HyracksDataException("Resource Id doesn't match expected metadata index resource id");
        }
        IndexDataflowHelper indexHelper = new IndexDataflowHelper(ncServiceCtx, storageComponentProvider.getStorageManager(), file);
        // Opening the index through the helper will ensure it gets instantiated
        indexHelper.open();
        indexHelper.close();
    }
}
#method_after
public static void enlistMetadataDataset(INCServiceContext ncServiceCtx, IMetadataIndex index) throws HyracksDataException {
    final int datasetId = index.getDatasetId().getId();
    // reserve memory for metadata dataset to ensure it can be opened when needed
    if (!appContext.getDatasetMemoryManager().reserve(index.getDatasetId().getId())) {
        throw new IllegalStateException("Failed to reserve memory for metadata dataset (" + datasetId + ")");
    }
    String metadataPartitionPath = StoragePathUtil.prepareStoragePartitionPath(MetadataNode.INSTANCE.getMetadataStoragePartition());
    String resourceName = metadataPartitionPath + File.separator + index.getFileNameRelativePath();
    FileReference file = ioManager.resolve(resourceName);
    index.setFile(file);
    ITypeTraits[] typeTraits = index.getTypeTraits();
    IBinaryComparatorFactory[] cmpFactories = index.getKeyBinaryComparatorFactory();
    int[] bloomFilterKeyFields = index.getBloomFilterKeyFields();
    // opTrackerProvider and ioOpCallbackFactory should both be acquired through
    // IStorageManager
    // We are unable to do this since IStorageManager needs a dataset to determine
    // the appropriate
    // objects
    ILSMOperationTrackerFactory opTrackerFactory = index.isPrimaryIndex() ? new PrimaryIndexOperationTrackerFactory(datasetId) : new SecondaryIndexOperationTrackerFactory(datasetId);
    ILSMComponentIdGeneratorFactory idGeneratorProvider = new DatasetLSMComponentIdGeneratorFactory(datasetId);
    DatasetInfoProvider datasetInfoProvider = new DatasetInfoProvider(datasetId);
    ILSMIOOperationCallbackFactory ioOpCallbackFactory = new LSMIndexIOOperationCallbackFactory(idGeneratorProvider, datasetInfoProvider);
    IStorageComponentProvider storageComponentProvider = appContext.getStorageComponentProvider();
    if (isNewUniverse()) {
        final double bloomFilterFalsePositiveRate = appContext.getStorageProperties().getBloomFilterFalsePositiveRate();
        LSMBTreeLocalResourceFactory lsmBtreeFactory = new LSMBTreeLocalResourceFactory(storageComponentProvider.getStorageManager(), typeTraits, cmpFactories, null, null, null, opTrackerFactory, ioOpCallbackFactory, storageComponentProvider.getMetadataPageManagerFactory(), new AsterixVirtualBufferCacheProvider(datasetId), storageComponentProvider.getIoOperationSchedulerProvider(), appContext.getMetadataMergePolicyFactory(), GlobalConfig.DEFAULT_COMPACTION_POLICY_PROPERTIES, true, bloomFilterKeyFields, bloomFilterFalsePositiveRate, true, null, NoOpCompressorDecompressorFactory.INSTANCE);
        DatasetLocalResourceFactory dsLocalResourceFactory = new DatasetLocalResourceFactory(datasetId, lsmBtreeFactory);
        // TODO(amoudi) Creating the index should be done through the same code path as
        // other indexes
        // This is to be done by having a metadata dataset associated with each index
        IIndexBuilder indexBuilder = new IndexBuilder(ncServiceCtx, storageComponentProvider.getStorageManager(), index::getResourceId, file, dsLocalResourceFactory, true);
        indexBuilder.build();
    } else {
        final LocalResource resource = localResourceRepository.get(file.getRelativePath());
        if (resource == null) {
            throw new HyracksDataException("Could not find required metadata indexes. Please delete " + appContext.getMetadataProperties().getTransactionLogDirs().get(appContext.getTransactionSubsystem().getId()) + " to intialize as a new instance. (WARNING: all data will be lost.)");
        }
        // similar to other resources?
        if (index.getResourceId() != resource.getId()) {
            throw new HyracksDataException("Resource Id doesn't match expected metadata index resource id");
        }
        IndexDataflowHelper indexHelper = new IndexDataflowHelper(ncServiceCtx, storageComponentProvider.getStorageManager(), file);
        // Opening the index through the helper will ensure it gets instantiated
        indexHelper.open();
        indexHelper.close();
    }
}
#end_block

#method_before
@Parameters(name = "SqlppExecutionWithCompressionTest {index}: {0}")
public static Collection<Object[]> tests() throws Exception {
    return LangExecutionUtil.tests("only_sqlpp.xml", "compressionSqlpp.xml");
}
#method_after
@Parameters(name = "SqlppExecutionWithCompressionTest {index}: {0}")
public static Collection<Object[]> tests() throws Exception {
    return LangExecutionUtil.tests("only_sqlpp.xml", "testsuite_sqlpp.xml");
}
#end_block

#method_before
private void pinSanityCheck(long dpid) throws HyracksDataException {
    if (closed) {
        throw new HyracksDataException("pin called on a closed cache");
    }
    // check whether file has been created and opened
    int fileId = BufferedFileHandle.getFileId(dpid);
    BufferedFileHandle fInfo;
    synchronized (fileInfoMap) {
        fInfo = fileInfoMap.get(fileId);
    }
    if (fInfo == null) {
        throw new HyracksDataException("pin called on a fileId " + fileId + " that has not been created.");
    } else if (fInfo.getReferenceCount() <= 0) {
        throw new HyracksDataException("pin called on a fileId " + fileId + " that has not been opened.");
    }
}
#method_after
private void pinSanityCheck(long dpid) throws HyracksDataException {
    if (closed) {
        throw new HyracksDataException("pin called on a closed cache");
    }
    // check whether file has been created and opened
    int fileId = BufferedFileHandle.getFileId(dpid);
    BufferedFileHandle fInfo;
    synchronized (fileInfoMap) {
        fInfo = fileInfoMap.get(fileId);
    }
    if (fInfo == null || fInfo.hasBeenDeleted() || !fInfo.hasBeenOpened()) {
        throw new HyracksDataException("pin called on a fileId " + fileId + " that has not been created.");
    } else if (fInfo.getReferenceCount() <= 0) {
        throw new HyracksDataException("pin called on a fileId " + fileId + " that has not been opened.");
    }
}
#end_block

#method_before
private void read(CachedPage cPage) throws HyracksDataException {
    BufferedFileHandle fInfo = getFileInfo(cPage);
    cPage.buffer.clear();
    if (fInfo.isCompressed()) {
        readCompressed(cPage, fInfo);
    } else {
        readUncompressed(cPage, fInfo);
    }
}
#method_after
private void read(CachedPage cPage) throws HyracksDataException {
    BufferedFileHandle fInfo = getFileHandle(cPage);
    cPage.buffer.clear();
    fInfo.read(cPage);
}
#end_block

#method_before
void write(CachedPage cPage) throws HyracksDataException {
    BufferedFileHandle fInfo = getFileInfo(cPage);
    // synchronize on fInfo to prevent the file handle from being deleted until the page is written.
    synchronized (fInfo) {
        if (fInfo.fileHasBeenDeleted()) {
            return;
        }
        final int totalPages = cPage.getFrameSizeMultiplier();
        final int extraBlockPageId = cPage.getExtraBlockPageId();
        final boolean contiguousLargePages = (BufferedFileHandle.getPageId(cPage.dpid) + 1) == extraBlockPageId;
        if (fInfo.isCompressed()) {
            // Compress and write the page. This may fail to achieve the desired saving.
            // If so, it will write the page(s) without compression.
            writeCompressedFile(fInfo, cPage, totalPages, extraBlockPageId);
        } else {
            writeUncompressedFile(fInfo, cPage, totalPages, extraBlockPageId, contiguousLargePages);
        }
    }
}
#method_after
void write(CachedPage cPage) throws HyracksDataException {
    BufferedFileHandle fInfo = getFileHandle(cPage);
    // synchronize on fInfo to prevent the file handle from being deleted until the page is written.
    synchronized (fInfo) {
        if (fInfo.hasBeenDeleted()) {
            return;
        }
        fInfo.write(cPage);
    }
}
#end_block

#method_before
@Override
public void close() {
    closed = true;
    fifoWriter.destroyQueue();
    try {
        synchronized (cleanerThread.threadLock) {
            cleanerThread.shutdownStart = true;
            cleanerThread.threadLock.notifyAll();
            while (!cleanerThread.shutdownComplete) {
                cleanerThread.threadLock.wait();
            }
        }
    } catch (InterruptedException e) {
        Thread.currentThread().interrupt();
    }
    synchronized (fileInfoMap) {
        fileInfoMap.forEach((key, value) -> {
            try {
                sweepAndFlush(key, true);
                ioManager.close(value.getFileHandle());
            } catch (HyracksDataException e) {
                if (LOGGER.isWarnEnabled()) {
                    LOGGER.log(Level.WARN, "Error flushing file id: " + key, e);
                }
            }
        });
        fileInfoMap.clear();
    }
}
#method_after
@Override
public void close() {
    closed = true;
    fifoWriter.destroyQueue();
    try {
        synchronized (cleanerThread.threadLock) {
            cleanerThread.shutdownStart = true;
            cleanerThread.threadLock.notifyAll();
            while (!cleanerThread.shutdownComplete) {
                cleanerThread.threadLock.wait();
            }
        }
    } catch (InterruptedException e) {
        Thread.currentThread().interrupt();
    }
    synchronized (fileInfoMap) {
        fileInfoMap.forEach((key, value) -> {
            try {
                sweepAndFlush(value, true);
                value.close();
            } catch (HyracksDataException e) {
                if (LOGGER.isWarnEnabled()) {
                    LOGGER.log(Level.WARN, "Error flushing file id: " + key, e);
                }
            }
        });
        fileInfoMap.clear();
    }
}
#end_block

#method_before
@Override
public int createFile(FileReference fileRef) throws HyracksDataException {
    if (LOGGER.isEnabled(fileOpsLevel)) {
        LOGGER.log(fileOpsLevel, "Creating file: " + fileRef + " in cache: " + this);
    }
    IoUtil.create(fileRef);
    int fileId;
    try {
        synchronized (fileInfoMap) {
            fileId = fileMapManager.registerFile(fileRef);
        }
        if (fileRef.isCompressed()) {
            createFile(fileRef.getLAFFileReference());
        }
        return fileId;
    } catch (Exception e) {
        // If file registration failed for any reason, we need to undo the file creation
        try {
            IoUtil.delete(fileRef);
        } catch (Exception deleteException) {
            e.addSuppressed(deleteException);
        }
        throw HyracksDataException.create(e);
    }
}
#method_after
@Override
public int createFile(FileReference fileRef) throws HyracksDataException {
    if (LOGGER.isEnabled(fileOpsLevel)) {
        LOGGER.log(fileOpsLevel, "Creating file: " + fileRef + " in cache: " + this);
    }
    BufferedFileHandle.createFile(this, fileRef);
    int fileId;
    try {
        synchronized (fileInfoMap) {
            fileId = fileMapManager.registerFile(fileRef);
            getOrCreateFileHandle(fileId);
        }
        return fileId;
    } catch (Exception e) {
        // If file registration failed for any reason, we need to undo the file creation
        try {
            IoUtil.delete(fileRef);
        } catch (Exception deleteException) {
            e.addSuppressed(deleteException);
        }
        throw HyracksDataException.create(e);
    }
}
#end_block

#method_before
@Override
public void openFile(int fileId) throws HyracksDataException {
    if (LOGGER.isEnabled(fileOpsLevel)) {
        LOGGER.log(fileOpsLevel, "Opening file: " + fileId + " in cache: " + this);
    }
    try {
        final BufferedFileHandle fInfo = getOrCreateFileHandle(fileId);
        if (fInfo.getFileHandle() == null) {
            // a new file
            synchronized (fInfo) {
                // prevent concurrent opening of the same file
                if (fInfo.getFileHandle() == null) {
                    if (fileInfoMap.size() > maxOpenFiles) {
                        closeOpeningFiles(fInfo);
                    }
                    // create, open, and map new file reference
                    FileReference fileRef;
                    synchronized (fileInfoMap) {
                        fileRef = fileMapManager.lookupFileName(fileId);
                    }
                    IFileHandle fh = ioManager.open(fileRef, IIOManager.FileReadWriteMode.READ_WRITE, IIOManager.FileSyncMode.METADATA_ASYNC_DATA_ASYNC);
                    fInfo.setFileHandle(fh);
                }
            }
        }
        if (fInfo.isCompressed()) {
            openLAFFile(fInfo);
        }
        fInfo.incReferenceCount();
    } catch (Exception e) {
        removeFileInfo(fileId);
        throw HyracksDataException.create(e);
    }
}
#method_after
@Override
public void openFile(int fileId) throws HyracksDataException {
    if (LOGGER.isEnabled(fileOpsLevel)) {
        LOGGER.log(fileOpsLevel, "Opening file: " + fileId + " in cache: " + this);
    }
    try {
        final BufferedFileHandle fInfo = getOrCreateFileHandle(fileId);
        // CompressedFileReference may open another file which may sweep and close out this fInfo
        fInfo.incReferenceCount();
        if (!fInfo.hasBeenOpened()) {
            // a new file
            synchronized (fInfo) {
                // prevent concurrent opening of the same file
                if (!fInfo.hasBeenOpened()) {
                    if (fileInfoMap.size() > maxOpenFiles) {
                        closeOpeningFiles(fInfo);
                    }
                    // create, open, and map new file reference
                    FileReference fileRef;
                    synchronized (fileInfoMap) {
                        fileRef = fileMapManager.lookupFileName(fileId);
                    }
                    fInfo.open(fileRef);
                }
            }
        }
    } catch (Exception e) {
        removeFileHandle(fileId);
        throw HyracksDataException.create(e);
    }
}
#end_block

#method_before
private void closeOpeningFiles(BufferedFileHandle newFileHandle) throws HyracksDataException {
    synchronized (fileInfoMap) {
        boolean unreferencedFileFound = true;
        while (fileInfoMap.size() > maxOpenFiles && unreferencedFileFound) {
            // map is full, make room by cleaning up unreferenced files
            unreferencedFileFound = false;
            for (Map.Entry<Integer, BufferedFileHandle> entry : fileInfoMap.entrySet()) {
                BufferedFileHandle fh = entry.getValue();
                if (fh != newFileHandle && fh.getReferenceCount() <= 0) {
                    if (fh.getReferenceCount() < 0) {
                        throw new IllegalStateException("Illegal reference count " + fh.getReferenceCount() + " of file " + fh.getFileHandle().getFileReference());
                    }
                    int entryFileId = entry.getKey();
                    sweepAndFlush(entryFileId, true);
                    ioManager.close(entry.getValue().getFileHandle());
                    fileInfoMap.remove(entryFileId);
                    unreferencedFileFound = true;
                    // fileInfoMap
                    break;
                }
            }
        }
        if (fileInfoMap.size() > maxOpenFiles) {
            throw new HyracksDataException("Could not open fileId " + newFileHandle.getFileId() + ". Max number of files " + maxOpenFiles + " already opened and referenced.");
        }
    }
}
#method_after
private void closeOpeningFiles(BufferedFileHandle newFileHandle) throws HyracksDataException {
    synchronized (fileInfoMap) {
        boolean unreferencedFileFound = true;
        while (fileInfoMap.size() > maxOpenFiles && unreferencedFileFound) {
            // map is full, make room by cleaning up unreferenced files
            unreferencedFileFound = false;
            for (Map.Entry<Integer, BufferedFileHandle> entry : fileInfoMap.entrySet()) {
                BufferedFileHandle fh = entry.getValue();
                if (fh != newFileHandle && fh.getReferenceCount() <= 0) {
                    if (fh.getReferenceCount() < 0) {
                        throw new IllegalStateException("Illegal reference count " + fh.getReferenceCount() + " of file " + fh.getFileReference());
                    }
                    int entryFileId = entry.getKey();
                    sweepAndFlush(fh, true);
                    entry.getValue().close();
                    fileInfoMap.remove(entryFileId);
                    unreferencedFileFound = true;
                    // fileInfoMap
                    break;
                }
            }
        }
        if (fileInfoMap.size() > maxOpenFiles) {
            throw new HyracksDataException("Could not open fileId " + newFileHandle.getFileId() + ". Max number of files " + maxOpenFiles + " already opened and referenced.");
        }
    }
}
#end_block

#method_before
private void sweepAndFlush(int fileId, boolean flushDirtyPages) throws HyracksDataException {
    for (final CacheBucket bucket : pageMap) {
        bucket.bucketLock.lock();
        try {
            CachedPage prev = bucket.cachedPage;
            while (prev != null) {
                CachedPage cPage = prev.next;
                if (cPage == null) {
                    break;
                }
                if (invalidateIfFileIdMatch(fileId, cPage, flushDirtyPages)) {
                    prev.next = cPage.next;
                    cPage.next = null;
                } else {
                    prev = cPage;
                }
            }
            // Take care of the head of the chain.
            if (bucket.cachedPage != null && invalidateIfFileIdMatch(fileId, bucket.cachedPage, flushDirtyPages)) {
                CachedPage cPage = bucket.cachedPage;
                bucket.cachedPage = bucket.cachedPage.next;
                cPage.next = null;
            }
        } finally {
            bucket.bucketLock.unlock();
        }
    }
}
#method_after
private void sweepAndFlush(BufferedFileHandle fInfo, boolean flushDirtyPages) throws HyracksDataException {
    if (!fInfo.hasBeenOpened()) {
        // Skip flushing as the file has not been open
        return;
    }
    final int fileId = fInfo.getFileId();
    for (final CacheBucket bucket : pageMap) {
        bucket.bucketLock.lock();
        try {
            CachedPage prev = bucket.cachedPage;
            while (prev != null) {
                CachedPage cPage = prev.next;
                if (cPage == null) {
                    break;
                }
                if (invalidateIfFileIdMatch(fileId, cPage, flushDirtyPages)) {
                    prev.next = cPage.next;
                    cPage.next = null;
                } else {
                    prev = cPage;
                }
            }
            // Take care of the head of the chain.
            if (bucket.cachedPage != null && invalidateIfFileIdMatch(fileId, bucket.cachedPage, flushDirtyPages)) {
                CachedPage cPage = bucket.cachedPage;
                bucket.cachedPage = bucket.cachedPage.next;
                cPage.next = null;
            }
        } finally {
            bucket.bucketLock.unlock();
        }
    }
}
#end_block

#method_before
@Override
public void closeFile(int fileId) throws HyracksDataException {
    if (LOGGER.isEnabled(fileOpsLevel)) {
        LOGGER.log(fileOpsLevel, "Closing file: " + fileId + " in cache: " + this);
    }
    if (LOGGER.isTraceEnabled()) {
        LOGGER.trace(dumpState());
    }
    BufferedFileHandle fInfo;
    synchronized (fileInfoMap) {
        fInfo = fileInfoMap.get(fileId);
        if (fInfo == null) {
            throw new HyracksDataException("Closing unopened file");
        }
        if (fInfo.decReferenceCount() < 0) {
            throw new HyracksDataException("Closed fileId: " + fileId + " more times than it was opened.");
        }
    }
    synchronized (fInfo) {
        if (fInfo.isCompressed()) {
            final CompressedFileManager compressedManager = fInfo.getCompressedFileManager();
            compressedManager.close();
            closeFile(compressedManager.getFileId());
        }
    }
    if (LOGGER.isEnabled(fileOpsLevel)) {
        LOGGER.log(fileOpsLevel, "Closed file: " + fileId + " in cache: " + this);
    }
}
#method_after
@Override
public void closeFile(int fileId) throws HyracksDataException {
    if (LOGGER.isEnabled(fileOpsLevel)) {
        LOGGER.log(fileOpsLevel, "Closing file: " + fileId + " in cache: " + this);
    }
    if (LOGGER.isTraceEnabled()) {
        LOGGER.trace(dumpState());
    }
    synchronized (fileInfoMap) {
        BufferedFileHandle fInfo = fileInfoMap.get(fileId);
        if (fInfo == null || !fInfo.hasBeenOpened()) {
            throw new HyracksDataException("Closing unopened file");
        }
        if (fInfo.decReferenceCount() < 0) {
            throw new HyracksDataException("Closed fileId: " + fileId + " more times than it was opened.");
        }
    }
    if (LOGGER.isEnabled(fileOpsLevel)) {
        LOGGER.log(fileOpsLevel, "Closed file: " + fileId + " in cache: " + this);
    }
}
#end_block

#method_before
@Override
public void force(int fileId, boolean metadata) throws HyracksDataException {
    BufferedFileHandle fInfo;
    synchronized (fileInfoMap) {
        fInfo = fileInfoMap.get(fileId);
    }
    // We must ensure that the LAF file forced to disk first
    if (fInfo.isCompressed()) {
        ioManager.sync(fInfo.getCompressedFileManager().getFileHandle(), metadata);
    }
    ioManager.sync(fInfo.getFileHandle(), metadata);
}
#method_after
@Override
public void force(int fileId, boolean metadata) throws HyracksDataException {
    BufferedFileHandle fInfo;
    synchronized (fileInfoMap) {
        fInfo = fileInfoMap.get(fileId);
    }
    fInfo.force(metadata);
}
#end_block

#method_before
@Override
public void deleteFile(FileReference fileRef) throws HyracksDataException {
    boolean mapped = false;
    int fileId = -1;
    synchronized (fileInfoMap) {
        if (fileMapManager.isMapped(fileRef)) {
            mapped = true;
            fileId = fileMapManager.lookupFileId(fileRef);
        }
    }
    if (mapped) {
        deleteFile(fileId);
    } else {
        IoUtil.delete(fileRef);
        if (fileRef.isCompressed()) {
            IoUtil.delete(fileRef.getLAFFileReference());
        }
    }
}
#method_after
@Override
public void deleteFile(FileReference fileRef) throws HyracksDataException {
    boolean mapped = false;
    int fileId = -1;
    synchronized (fileInfoMap) {
        if (fileMapManager.isMapped(fileRef)) {
            mapped = true;
            fileId = fileMapManager.lookupFileId(fileRef);
        }
    }
    if (mapped) {
        deleteFile(fileId);
    } else {
        BufferedFileHandle.deleteFile(fileRef);
    }
}
#end_block

#method_before
@Override
public void deleteFile(int fileId) throws HyracksDataException {
    if (LOGGER.isEnabled(fileOpsLevel)) {
        LOGGER.log(fileOpsLevel, "Deleting file: " + fileId + " in cache: " + this);
    }
    BufferedFileHandle fInfo = removeFileInfo(fileId);
    if (fInfo == null) {
        return;
    }
    final boolean isCompressed = fInfo.isCompressed();
    sweepAndFlush(fileId, false);
    try {
        if (fInfo.getReferenceCount() > 0) {
            throw new HyracksDataException("Deleting open file");
        }
    } finally {
        FileReference fileRef = null;
        try {
            synchronized (fileInfoMap) {
                fileRef = fileMapManager.unregisterFile(fileId);
            }
        } finally {
            try {
                synchronized (fInfo) {
                    ioManager.close(fInfo.getFileHandle());
                    fInfo.markAsDeleted();
                }
            } finally {
                IoUtil.delete(fileRef);
            }
        }
    }
    if (isCompressed) {
        deleteFile(fInfo.getCompressedFileManager().getFileId());
        fInfo.setCompressedFileManager(null);
    }
}
#method_after
@Override
public void deleteFile(int fileId) throws HyracksDataException {
    if (LOGGER.isEnabled(fileOpsLevel)) {
        LOGGER.log(fileOpsLevel, "Deleting file: " + fileId + " in cache: " + this);
    }
    BufferedFileHandle fInfo = removeFileHandle(fileId);
    if (fInfo == null) {
        return;
    }
    sweepAndFlush(fInfo, false);
    try {
        if (fInfo.getReferenceCount() > 0) {
            throw new HyracksDataException("Deleting open file");
        }
    } finally {
        FileReference fileRef = null;
        try {
            synchronized (fileInfoMap) {
                fileRef = fileMapManager.unregisterFile(fileId);
            }
        } finally {
            try {
                synchronized (fInfo) {
                    fInfo.close();
                    fInfo.markAsDeleted();
                }
            } finally {
                BufferedFileHandle.deleteFile(fileRef);
            }
        }
    }
}
#end_block

#method_before
@Override
public int getNumPagesOfFile(int fileId) throws HyracksDataException {
    synchronized (fileInfoMap) {
        BufferedFileHandle fInfo = fileInfoMap.get(fileId);
        if (fInfo == null) {
            throw new HyracksDataException("No such file mapped for fileId:" + fileId);
        }
        if (DEBUG && !fInfo.isCompressed()) {
            assert ioManager.getSize(fInfo.getFileHandle()) % getPageSizeWithHeader() == 0;
        }
        if (fInfo.isCompressed()) {
            return fInfo.getCompressedFileManager().getNumberOfCompressedPages();
        }
        return (int) (ioManager.getSize(fInfo.getFileHandle()) / getPageSizeWithHeader());
    }
}
#method_after
@Override
public int getNumPagesOfFile(int fileId) throws HyracksDataException {
    synchronized (fileInfoMap) {
        BufferedFileHandle fInfo = fileInfoMap.get(fileId);
        if (fInfo == null) {
            throw new HyracksDataException("No such file mapped for fileId:" + fileId);
        }
        return fInfo.getNumberOfPages();
    }
}
#end_block

#method_before
private BufferedFileHandle getOrCreateFileHandle(int fileId) {
    synchronized (fileInfoMap) {
        return fileInfoMap.computeIfAbsent(fileId, id -> new BufferedFileHandle(fileId, null));
    }
}
#method_after
private BufferedFileHandle getOrCreateFileHandle(int fileId) throws HyracksDataException {
    synchronized (fileInfoMap) {
        final FileReference fileRef = fileMapManager.lookupFileName(fileId);
        return fileInfoMap.computeIfAbsent(fileId, id -> BufferedFileHandle.create(fileRef, fileId, this, ioManager, headerPageCache, pageReplacementStrategy));
    }
}
#end_block

#method_before
@Override
public void purgeHandle(int fileId) throws HyracksDataException {
    BufferedFileHandle fh = removeFileInfo(fileId);
    if (fh != null) {
        synchronized (fileInfoMap) {
            fileMapManager.unregisterFile(fileId);
        }
        ioManager.close(fh.getFileHandle());
        if (fh.isCompressed()) {
            final int compressedFileId = fh.getCompressedFileManager().getFileId();
            BufferedFileHandle compressedFh = removeFileInfo(compressedFileId);
            synchronized (fileInfoMap) {
                fileMapManager.unregisterFile(compressedFileId);
            }
            ioManager.close(compressedFh.getFileHandle());
        }
    }
}
#method_after
@Override
public void purgeHandle(int fileId) throws HyracksDataException {
    BufferedFileHandle fh = removeFileHandle(fileId);
    if (fh != null) {
        synchronized (fileInfoMap) {
            fileMapManager.unregisterFile(fileId);
            fh.purge();
        }
    }
}
#end_block

#method_before
@Override
public ICompressedPageWriter getCompressedPageWriter(int fileId) {
    final BufferedFileHandle fileHandle;
    synchronized (fileInfoMap) {
        fileHandle = fileInfoMap.get(fileId);
    }
    if (fileHandle.isCompressed()) {
        return fileHandle.getCompressedFileManager().getCompressedPageWriter();
    }
    return null;
}
#method_after
@Override
public ICompressedPageWriter getCompressedPageWriter(int fileId) {
    final BufferedFileHandle fInfo;
    synchronized (fileInfoMap) {
        fInfo = fileInfoMap.get(fileId);
    }
    return fInfo.getCompressedPageWriter();
}
#end_block

#method_before
protected void registerClasses() {
    /* WARNING: Changing a resource id will break storage format backward compatibility.*/
    REGISTERED_CLASSES.put("Checkpoint", Checkpoint.class);
    // IResource
    REGISTERED_CLASSES.put("LocalResource", LocalResource.class);
    REGISTERED_CLASSES.put("DatasetLocalResource", DatasetLocalResource.class);
    REGISTERED_CLASSES.put("LSMBTreeLocalResource", LSMBTreeLocalResource.class);
    REGISTERED_CLASSES.put("LSMRTreeLocalResource", LSMRTreeLocalResource.class);
    REGISTERED_CLASSES.put("LSMRTreeWithAntiMatterLocalResource", LSMRTreeWithAntiMatterLocalResource.class);
    REGISTERED_CLASSES.put("LSMInvertedIndexLocalResource", LSMInvertedIndexLocalResource.class);
    REGISTERED_CLASSES.put("ExternalBTreeLocalResource", ExternalBTreeLocalResource.class);
    REGISTERED_CLASSES.put("ExternalBTreeWithBuddyLocalResource", ExternalBTreeWithBuddyLocalResource.class);
    REGISTERED_CLASSES.put("ExternalRTreeLocalResource", ExternalRTreeLocalResource.class);
    // ILSMMergePolicyFactory
    REGISTERED_CLASSES.put("NoMergePolicyFactory", NoMergePolicyFactory.class);
    REGISTERED_CLASSES.put("PrefixMergePolicyFactory", PrefixMergePolicyFactory.class);
    REGISTERED_CLASSES.put("ConstantMergePolicyFactory", ConstantMergePolicyFactory.class);
    REGISTERED_CLASSES.put("CorrelatedPrefixMergePolicyFactory", CorrelatedPrefixMergePolicyFactory.class);
    // ILSMIOOperationSchedulerProvider
    REGISTERED_CLASSES.put("RuntimeComponentsProvider", RuntimeComponentsProvider.class);
    // ITypeTraits
    REGISTERED_CLASSES.put("FixedLengthTypeTrait", FixedLengthTypeTrait.class);
    REGISTERED_CLASSES.put("VarLengthTypeTrait", VarLengthTypeTrait.class);
    // ILSMOperationTrackerFactory
    REGISTERED_CLASSES.put("PrimaryIndexOperationTrackerFactory", PrimaryIndexOperationTrackerFactory.class);
    REGISTERED_CLASSES.put("SecondaryIndexOperationTrackerFactory", SecondaryIndexOperationTrackerFactory.class);
    // ILSMComponentIdGeneratorFactory
    REGISTERED_CLASSES.put("DatasetLSMComponentIdGeneratorFactory", DatasetLSMComponentIdGeneratorFactory.class);
    // IDatasetInfoProvider
    REGISTERED_CLASSES.put("DatasetInfoProvider", DatasetInfoProvider.class);
    // ILSMOperationTrackerFactory
    REGISTERED_CLASSES.put("NoOpIOOperationCallbackFactory", NoOpIOOperationCallbackFactory.class);
    REGISTERED_CLASSES.put("LSMBTreeIOOperationCallbackFactory", LSMIndexIOOperationCallbackFactory.class);
    // ILSMIOOperationSchedulerProvider
    REGISTERED_CLASSES.put("AppendOnlyLinkedMetadataPageManagerFactory", AppendOnlyLinkedMetadataPageManagerFactory.class);
    // ILSMIOOperationSchedulerProvider
    REGISTERED_CLASSES.put("AsterixVirtualBufferCacheProvider", AsterixVirtualBufferCacheProvider.class);
    // IBinaryComparatorFactory
    REGISTERED_CLASSES.put("ACirclePartialBinaryComparatorFactory", ACirclePartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("ADurationPartialBinaryComparatorFactory", ADurationPartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("AIntervalAscPartialBinaryComparatorFactory", AIntervalAscPartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("AIntervalDescPartialBinaryComparatorFactory", AIntervalDescPartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("ALinePartialBinaryComparatorFactory", ALinePartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("AObjectAscBinaryComparatorFactory", AObjectAscBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("AObjectDescBinaryComparatorFactory", AObjectDescBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("APoint3DPartialBinaryComparatorFactory", APoint3DPartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("APointPartialBinaryComparatorFactory", APointPartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("APolygonPartialBinaryComparatorFactory", APolygonPartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("ARectanglePartialBinaryComparatorFactory", ARectanglePartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("AUUIDPartialBinaryComparatorFactory", AUUIDPartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("BooleanBinaryComparatorFactory", BooleanBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("ListItemBinaryComparatorFactory", ListItemBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("LongBinaryComparatorFactory", LongBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("RawBinaryComparatorFactory", RawBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("PointableBinaryComparatorFactory", PointableBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("HilbertDoubleComparatorFactory", HilbertDoubleComparatorFactory.class);
    REGISTERED_CLASSES.put("ZCurveDoubleComparatorFactory", ZCurveDoubleComparatorFactory.class);
    REGISTERED_CLASSES.put("ZCurveIntComparatorFactory", ZCurveIntComparatorFactory.class);
    REGISTERED_CLASSES.put("ComponentPosComparatorFactory", SecondaryCorrelatedTreeIndexOperationsHelper.ComponentPosComparatorFactory.class);
    REGISTERED_CLASSES.put("AnyBinaryComparatorFactory", AnyBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("OrderedBinaryComparatorFactory", OrderedBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("OrderedLinearizeComparatorFactory", OrderedLinearizeComparatorFactory.class);
    // IPointableFactory
    REGISTERED_CLASSES.put("AIntervalPointableFactory", AIntervalPointable.AIntervalPointableFactory.class);
    REGISTERED_CLASSES.put("AListPointableFactory", AListPointable.AListPointableFactory.class);
    REGISTERED_CLASSES.put("ARecordPointableFactory", ARecordPointable.ARecordPointableFactory.class);
    REGISTERED_CLASSES.put("BooleanPointableFactory", BooleanPointable.BooleanPointableFactory.class);
    REGISTERED_CLASSES.put("ByteArrayPointableFactory", ByteArrayPointable.ByteArrayPointableFactory.class);
    REGISTERED_CLASSES.put("BytePointableFactory", BytePointable.BytePointableFactory.class);
    REGISTERED_CLASSES.put("DoublePointableFactory", DoublePointable.DoublePointableFactory.class);
    REGISTERED_CLASSES.put("FloatPointableFactory", FloatPointable.FloatPointableFactory.class);
    REGISTERED_CLASSES.put("IntegerPointableFactory", IntegerPointable.IntegerPointableFactory.class);
    REGISTERED_CLASSES.put("LongPointableFactory", LongPointable.LongPointableFactory.class);
    REGISTERED_CLASSES.put("RawUTF8StringPointableFactory", RawUTF8StringPointable.RawUTF8StringPointableFactory.class);
    REGISTERED_CLASSES.put("ShortPointableFactory", ShortPointable.ShortPointableFactory.class);
    REGISTERED_CLASSES.put("TaggedValuePointableFactory", TaggedValuePointable.TaggedValuePointableFactory.class);
    REGISTERED_CLASSES.put("UTF8StringLowercasePointableFactory", UTF8StringLowercasePointable.UTF8StringLowercasePointableFactory.class);
    REGISTERED_CLASSES.put("UTF8StringLowercaseTokenPointableFactory", UTF8StringLowercaseTokenPointable.UTF8StringLowercaseTokenPointableFactory.class);
    REGISTERED_CLASSES.put("UTF8StringPointableFactory", UTF8StringPointable.UTF8StringPointableFactory.class);
    REGISTERED_CLASSES.put("VoidPointableFactory", VoidPointable.VoidPointableFactory.class);
    // IPrimitiveValueProviderFactory
    REGISTERED_CLASSES.put("DoublePrimitiveValueProviderFactory", DoublePrimitiveValueProviderFactory.class);
    REGISTERED_CLASSES.put("FloatPrimitiveValueProviderFactory", FloatPrimitiveValueProviderFactory.class);
    REGISTERED_CLASSES.put("IntegerPrimitiveValueProviderFactory", IntegerPrimitiveValueProviderFactory.class);
    REGISTERED_CLASSES.put("PointablePrimitiveValueProviderFactory", PointablePrimitiveValueProviderFactory.class);
    REGISTERED_CLASSES.put("PrimitiveValueProviderFactory", PrimitiveValueProviderFactory.class);
    // IBinaryTokenizerFactory
    REGISTERED_CLASSES.put("AOrderedListBinaryTokenizerFactory", AOrderedListBinaryTokenizerFactory.class);
    REGISTERED_CLASSES.put("AUnorderedListBinaryTokenizerFactory", AUnorderedListBinaryTokenizerFactory.class);
    REGISTERED_CLASSES.put("NGramUTF8StringBinaryTokenizerFactory", NGramUTF8StringBinaryTokenizerFactory.class);
    REGISTERED_CLASSES.put("DelimitedUTF8StringBinaryTokenizerFactory", DelimitedUTF8StringBinaryTokenizerFactory.class);
    // ITokenFactory
    REGISTERED_CLASSES.put("AListElementTokenFactory", AListElementTokenFactory.class);
    REGISTERED_CLASSES.put("HashedUTF8NGramTokenFactory", HashedUTF8NGramTokenFactory.class);
    REGISTERED_CLASSES.put("HashedUTF8WordTokenFactory", HashedUTF8WordTokenFactory.class);
    REGISTERED_CLASSES.put("UTF8NGramTokenFactory", UTF8NGramTokenFactory.class);
    REGISTERED_CLASSES.put("UTF8WordTokenFactory", UTF8WordTokenFactory.class);
    REGISTERED_CLASSES.put("RTreePolicyType", RTreePolicyType.class);
    // IBlockCompressorDecompressorFactory
    CompressionManager.registerBlockCompressorDecompressorsFactoryClasses(REGISTERED_CLASSES);
}
#method_after
protected void registerClasses() {
    /* WARNING: Changing a resource id will break storage format backward compatibility.*/
    REGISTERED_CLASSES.put("Checkpoint", Checkpoint.class);
    // IResource
    REGISTERED_CLASSES.put("LocalResource", LocalResource.class);
    REGISTERED_CLASSES.put("DatasetLocalResource", DatasetLocalResource.class);
    REGISTERED_CLASSES.put("LSMBTreeLocalResource", LSMBTreeLocalResource.class);
    REGISTERED_CLASSES.put("LSMRTreeLocalResource", LSMRTreeLocalResource.class);
    REGISTERED_CLASSES.put("LSMRTreeWithAntiMatterLocalResource", LSMRTreeWithAntiMatterLocalResource.class);
    REGISTERED_CLASSES.put("LSMInvertedIndexLocalResource", LSMInvertedIndexLocalResource.class);
    REGISTERED_CLASSES.put("ExternalBTreeLocalResource", ExternalBTreeLocalResource.class);
    REGISTERED_CLASSES.put("ExternalBTreeWithBuddyLocalResource", ExternalBTreeWithBuddyLocalResource.class);
    REGISTERED_CLASSES.put("ExternalRTreeLocalResource", ExternalRTreeLocalResource.class);
    // ILSMMergePolicyFactory
    REGISTERED_CLASSES.put("NoMergePolicyFactory", NoMergePolicyFactory.class);
    REGISTERED_CLASSES.put("PrefixMergePolicyFactory", PrefixMergePolicyFactory.class);
    REGISTERED_CLASSES.put("ConstantMergePolicyFactory", ConstantMergePolicyFactory.class);
    REGISTERED_CLASSES.put("CorrelatedPrefixMergePolicyFactory", CorrelatedPrefixMergePolicyFactory.class);
    // ILSMIOOperationSchedulerProvider
    REGISTERED_CLASSES.put("RuntimeComponentsProvider", RuntimeComponentsProvider.class);
    // ITypeTraits
    REGISTERED_CLASSES.put("FixedLengthTypeTrait", FixedLengthTypeTrait.class);
    REGISTERED_CLASSES.put("VarLengthTypeTrait", VarLengthTypeTrait.class);
    // ILSMOperationTrackerFactory
    REGISTERED_CLASSES.put("PrimaryIndexOperationTrackerFactory", PrimaryIndexOperationTrackerFactory.class);
    REGISTERED_CLASSES.put("SecondaryIndexOperationTrackerFactory", SecondaryIndexOperationTrackerFactory.class);
    // ILSMComponentIdGeneratorFactory
    REGISTERED_CLASSES.put("DatasetLSMComponentIdGeneratorFactory", DatasetLSMComponentIdGeneratorFactory.class);
    // IDatasetInfoProvider
    REGISTERED_CLASSES.put("DatasetInfoProvider", DatasetInfoProvider.class);
    // ILSMOperationTrackerFactory
    REGISTERED_CLASSES.put("NoOpIOOperationCallbackFactory", NoOpIOOperationCallbackFactory.class);
    REGISTERED_CLASSES.put("LSMBTreeIOOperationCallbackFactory", LSMIndexIOOperationCallbackFactory.class);
    // ILSMIOOperationSchedulerProvider
    REGISTERED_CLASSES.put("AppendOnlyLinkedMetadataPageManagerFactory", AppendOnlyLinkedMetadataPageManagerFactory.class);
    // ILSMIOOperationSchedulerProvider
    REGISTERED_CLASSES.put("AsterixVirtualBufferCacheProvider", AsterixVirtualBufferCacheProvider.class);
    // IBinaryComparatorFactory
    REGISTERED_CLASSES.put("ACirclePartialBinaryComparatorFactory", ACirclePartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("ADurationPartialBinaryComparatorFactory", ADurationPartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("AIntervalAscPartialBinaryComparatorFactory", AIntervalAscPartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("AIntervalDescPartialBinaryComparatorFactory", AIntervalDescPartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("ALinePartialBinaryComparatorFactory", ALinePartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("AObjectAscBinaryComparatorFactory", AObjectAscBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("AObjectDescBinaryComparatorFactory", AObjectDescBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("APoint3DPartialBinaryComparatorFactory", APoint3DPartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("APointPartialBinaryComparatorFactory", APointPartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("APolygonPartialBinaryComparatorFactory", APolygonPartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("ARectanglePartialBinaryComparatorFactory", ARectanglePartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("AUUIDPartialBinaryComparatorFactory", AUUIDPartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("BooleanBinaryComparatorFactory", BooleanBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("ListItemBinaryComparatorFactory", ListItemBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("LongBinaryComparatorFactory", LongBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("RawBinaryComparatorFactory", RawBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("PointableBinaryComparatorFactory", PointableBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("HilbertDoubleComparatorFactory", HilbertDoubleComparatorFactory.class);
    REGISTERED_CLASSES.put("ZCurveDoubleComparatorFactory", ZCurveDoubleComparatorFactory.class);
    REGISTERED_CLASSES.put("ZCurveIntComparatorFactory", ZCurveIntComparatorFactory.class);
    REGISTERED_CLASSES.put("ComponentPosComparatorFactory", SecondaryCorrelatedTreeIndexOperationsHelper.ComponentPosComparatorFactory.class);
    REGISTERED_CLASSES.put("AnyBinaryComparatorFactory", AnyBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("OrderedBinaryComparatorFactory", OrderedBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("OrderedLinearizeComparatorFactory", OrderedLinearizeComparatorFactory.class);
    // IPointableFactory
    REGISTERED_CLASSES.put("AIntervalPointableFactory", AIntervalPointable.AIntervalPointableFactory.class);
    REGISTERED_CLASSES.put("AListPointableFactory", AListPointable.AListPointableFactory.class);
    REGISTERED_CLASSES.put("ARecordPointableFactory", ARecordPointable.ARecordPointableFactory.class);
    REGISTERED_CLASSES.put("BooleanPointableFactory", BooleanPointable.BooleanPointableFactory.class);
    REGISTERED_CLASSES.put("ByteArrayPointableFactory", ByteArrayPointable.ByteArrayPointableFactory.class);
    REGISTERED_CLASSES.put("BytePointableFactory", BytePointable.BytePointableFactory.class);
    REGISTERED_CLASSES.put("DoublePointableFactory", DoublePointable.DoublePointableFactory.class);
    REGISTERED_CLASSES.put("FloatPointableFactory", FloatPointable.FloatPointableFactory.class);
    REGISTERED_CLASSES.put("IntegerPointableFactory", IntegerPointable.IntegerPointableFactory.class);
    REGISTERED_CLASSES.put("LongPointableFactory", LongPointable.LongPointableFactory.class);
    REGISTERED_CLASSES.put("RawUTF8StringPointableFactory", RawUTF8StringPointable.RawUTF8StringPointableFactory.class);
    REGISTERED_CLASSES.put("ShortPointableFactory", ShortPointable.ShortPointableFactory.class);
    REGISTERED_CLASSES.put("TaggedValuePointableFactory", TaggedValuePointable.TaggedValuePointableFactory.class);
    REGISTERED_CLASSES.put("UTF8StringLowercasePointableFactory", UTF8StringLowercasePointable.UTF8StringLowercasePointableFactory.class);
    REGISTERED_CLASSES.put("UTF8StringLowercaseTokenPointableFactory", UTF8StringLowercaseTokenPointable.UTF8StringLowercaseTokenPointableFactory.class);
    REGISTERED_CLASSES.put("UTF8StringPointableFactory", UTF8StringPointable.UTF8StringPointableFactory.class);
    REGISTERED_CLASSES.put("VoidPointableFactory", VoidPointable.VoidPointableFactory.class);
    // IPrimitiveValueProviderFactory
    REGISTERED_CLASSES.put("DoublePrimitiveValueProviderFactory", DoublePrimitiveValueProviderFactory.class);
    REGISTERED_CLASSES.put("FloatPrimitiveValueProviderFactory", FloatPrimitiveValueProviderFactory.class);
    REGISTERED_CLASSES.put("IntegerPrimitiveValueProviderFactory", IntegerPrimitiveValueProviderFactory.class);
    REGISTERED_CLASSES.put("PointablePrimitiveValueProviderFactory", PointablePrimitiveValueProviderFactory.class);
    REGISTERED_CLASSES.put("PrimitiveValueProviderFactory", PrimitiveValueProviderFactory.class);
    // IBinaryTokenizerFactory
    REGISTERED_CLASSES.put("AOrderedListBinaryTokenizerFactory", AOrderedListBinaryTokenizerFactory.class);
    REGISTERED_CLASSES.put("AUnorderedListBinaryTokenizerFactory", AUnorderedListBinaryTokenizerFactory.class);
    REGISTERED_CLASSES.put("NGramUTF8StringBinaryTokenizerFactory", NGramUTF8StringBinaryTokenizerFactory.class);
    REGISTERED_CLASSES.put("DelimitedUTF8StringBinaryTokenizerFactory", DelimitedUTF8StringBinaryTokenizerFactory.class);
    // ITokenFactory
    REGISTERED_CLASSES.put("AListElementTokenFactory", AListElementTokenFactory.class);
    REGISTERED_CLASSES.put("HashedUTF8NGramTokenFactory", HashedUTF8NGramTokenFactory.class);
    REGISTERED_CLASSES.put("HashedUTF8WordTokenFactory", HashedUTF8WordTokenFactory.class);
    REGISTERED_CLASSES.put("UTF8NGramTokenFactory", UTF8NGramTokenFactory.class);
    REGISTERED_CLASSES.put("UTF8WordTokenFactory", UTF8WordTokenFactory.class);
    REGISTERED_CLASSES.put("RTreePolicyType", RTreePolicyType.class);
    // ICompressorDecompressorFactory
    CompressionManager.registerCompressorDecompressorsFactoryClasses(REGISTERED_CLASSES);
}
#end_block

#method_before
public IResourceFactory getLocalResourceFactory(IStorageManager storageManager, ITypeTraits[] typeTraits, IBinaryComparatorFactory[] comparatorFactories, IMetadataPageManagerFactory pageManagerFactory, int[] bloomFilterKeyFields, int[] btreefields, int[] filterfields, ITypeTraits[] filtertypetraits, IBinaryComparatorFactory[] filtercmpfactories) {
    return new LSMBTreeLocalResourceFactory(storageManager, typeTraits, comparatorFactories, filtertypetraits, filtercmpfactories, filterfields, ThreadCountingOperationTrackerFactory.INSTANCE, NoOpIOOperationCallbackFactory.INSTANCE, pageManagerFactory, getVirtualBufferCacheProvider(), SynchronousSchedulerProvider.INSTANCE, MERGE_POLICY_FACTORY, MERGE_POLICY_PROPERTIES, DURABLE, bloomFilterKeyFields, LSMTreeOperatorTestHelper.DEFAULT_BLOOM_FILTER_FALSE_POSITIVE_RATE, true, btreefields, null);
}
#method_after
public IResourceFactory getLocalResourceFactory(IStorageManager storageManager, ITypeTraits[] typeTraits, IBinaryComparatorFactory[] comparatorFactories, IMetadataPageManagerFactory pageManagerFactory, int[] bloomFilterKeyFields, int[] btreefields, int[] filterfields, ITypeTraits[] filtertypetraits, IBinaryComparatorFactory[] filtercmpfactories) {
    return new LSMBTreeLocalResourceFactory(storageManager, typeTraits, comparatorFactories, filtertypetraits, filtercmpfactories, filterfields, ThreadCountingOperationTrackerFactory.INSTANCE, NoOpIOOperationCallbackFactory.INSTANCE, pageManagerFactory, getVirtualBufferCacheProvider(), SynchronousSchedulerProvider.INSTANCE, MERGE_POLICY_FACTORY, MERGE_POLICY_PROPERTIES, DURABLE, bloomFilterKeyFields, LSMTreeOperatorTestHelper.DEFAULT_BLOOM_FILTER_FALSE_POSITIVE_RATE, true, btreefields, NoOpCompressorDecompressorFactory.INSTANCE);
}
#end_block

#method_before
@Override
public IResourceFactory getResourceFactory(MetadataProvider mdProvider, Dataset dataset, Index index, ARecordType recordType, ARecordType metaType, ILSMMergePolicyFactory mergePolicyFactory, Map<String, String> mergePolicyProperties, ITypeTraits[] filterTypeTraits, IBinaryComparatorFactory[] filterCmpFactories) throws AlgebricksException {
    int[] filterFields = IndexUtil.getFilterFields(dataset, index, filterTypeTraits);
    int[] btreeFields = IndexUtil.getBtreeFieldsIfFiltered(dataset, index);
    IStorageComponentProvider storageComponentProvider = mdProvider.getStorageComponentProvider();
    ITypeTraits[] typeTraits = getTypeTraits(mdProvider, dataset, index, recordType, metaType);
    IBinaryComparatorFactory[] cmpFactories = getCmpFactories(mdProvider, dataset, index, recordType, metaType);
    int[] bloomFilterFields = getBloomFilterFields(dataset, index);
    double bloomFilterFalsePositiveRate = mdProvider.getStorageProperties().getBloomFilterFalsePositiveRate();
    ILSMOperationTrackerFactory opTrackerFactory = dataset.getIndexOperationTrackerFactory(index);
    ILSMIOOperationCallbackFactory ioOpCallbackFactory = dataset.getIoOperationCallbackFactory(index);
    IStorageManager storageManager = storageComponentProvider.getStorageManager();
    IMetadataPageManagerFactory metadataPageManagerFactory = storageComponentProvider.getMetadataPageManagerFactory();
    ILSMIOOperationSchedulerProvider ioSchedulerProvider = storageComponentProvider.getIoOperationSchedulerProvider();
    switch(dataset.getDatasetType()) {
        case EXTERNAL:
            return index.getIndexName().equals(IndexingConstants.getFilesIndexName(dataset.getDatasetName())) ? new ExternalBTreeLocalResourceFactory(storageManager, typeTraits, cmpFactories, filterTypeTraits, filterCmpFactories, filterFields, opTrackerFactory, ioOpCallbackFactory, metadataPageManagerFactory, ioSchedulerProvider, mergePolicyFactory, mergePolicyProperties, true, bloomFilterFields, bloomFilterFalsePositiveRate, false, btreeFields) : new ExternalBTreeWithBuddyLocalResourceFactory(storageManager, typeTraits, cmpFactories, filterTypeTraits, filterCmpFactories, filterFields, opTrackerFactory, ioOpCallbackFactory, metadataPageManagerFactory, ioSchedulerProvider, mergePolicyFactory, mergePolicyProperties, true, bloomFilterFields, bloomFilterFalsePositiveRate, false, btreeFields);
        case INTERNAL:
            AsterixVirtualBufferCacheProvider vbcProvider = new AsterixVirtualBufferCacheProvider(dataset.getDatasetId());
            final String compressionScheme = dataset.getHints() != null ? dataset.getHints().get(CompressionSchemeHint.NAME) : null;
            final ICompressorDecompressorFactory compressorDecompressorFactory = mdProvider.getCompressionManager().getFactory(compressionScheme, index.isPrimaryIndex());
            return new LSMBTreeLocalResourceFactory(storageManager, typeTraits, cmpFactories, filterTypeTraits, filterCmpFactories, filterFields, opTrackerFactory, ioOpCallbackFactory, metadataPageManagerFactory, vbcProvider, ioSchedulerProvider, mergePolicyFactory, mergePolicyProperties, true, bloomFilterFields, bloomFilterFalsePositiveRate, index.isPrimaryIndex(), btreeFields, compressorDecompressorFactory);
        default:
            throw new CompilationException(ErrorCode.COMPILATION_UNKNOWN_DATASET_TYPE, dataset.getDatasetType().toString());
    }
}
#method_after
@Override
public IResourceFactory getResourceFactory(MetadataProvider mdProvider, Dataset dataset, Index index, ARecordType recordType, ARecordType metaType, ILSMMergePolicyFactory mergePolicyFactory, Map<String, String> mergePolicyProperties, ITypeTraits[] filterTypeTraits, IBinaryComparatorFactory[] filterCmpFactories) throws AlgebricksException {
    int[] filterFields = IndexUtil.getFilterFields(dataset, index, filterTypeTraits);
    int[] btreeFields = IndexUtil.getBtreeFieldsIfFiltered(dataset, index);
    IStorageComponentProvider storageComponentProvider = mdProvider.getStorageComponentProvider();
    ITypeTraits[] typeTraits = getTypeTraits(mdProvider, dataset, index, recordType, metaType);
    IBinaryComparatorFactory[] cmpFactories = getCmpFactories(mdProvider, dataset, index, recordType, metaType);
    int[] bloomFilterFields = getBloomFilterFields(dataset, index);
    double bloomFilterFalsePositiveRate = mdProvider.getStorageProperties().getBloomFilterFalsePositiveRate();
    ILSMOperationTrackerFactory opTrackerFactory = dataset.getIndexOperationTrackerFactory(index);
    ILSMIOOperationCallbackFactory ioOpCallbackFactory = dataset.getIoOperationCallbackFactory(index);
    IStorageManager storageManager = storageComponentProvider.getStorageManager();
    IMetadataPageManagerFactory metadataPageManagerFactory = storageComponentProvider.getMetadataPageManagerFactory();
    ILSMIOOperationSchedulerProvider ioSchedulerProvider = storageComponentProvider.getIoOperationSchedulerProvider();
    switch(dataset.getDatasetType()) {
        case EXTERNAL:
            return index.getIndexName().equals(IndexingConstants.getFilesIndexName(dataset.getDatasetName())) ? new ExternalBTreeLocalResourceFactory(storageManager, typeTraits, cmpFactories, filterTypeTraits, filterCmpFactories, filterFields, opTrackerFactory, ioOpCallbackFactory, metadataPageManagerFactory, ioSchedulerProvider, mergePolicyFactory, mergePolicyProperties, true, bloomFilterFields, bloomFilterFalsePositiveRate, false, btreeFields) : new ExternalBTreeWithBuddyLocalResourceFactory(storageManager, typeTraits, cmpFactories, filterTypeTraits, filterCmpFactories, filterFields, opTrackerFactory, ioOpCallbackFactory, metadataPageManagerFactory, ioSchedulerProvider, mergePolicyFactory, mergePolicyProperties, true, bloomFilterFields, bloomFilterFalsePositiveRate, false, btreeFields);
        case INTERNAL:
            AsterixVirtualBufferCacheProvider vbcProvider = new AsterixVirtualBufferCacheProvider(dataset.getDatasetId());
            final ICompressorDecompressorFactory compDecompFactory;
            if (index.isPrimaryIndex()) {
                // Compress only primary index
                compDecompFactory = mdProvider.getCompressionManager().getFactory(dataset.getCompressionScheme());
            } else {
                compDecompFactory = NoOpCompressorDecompressorFactory.INSTANCE;
            }
            return new LSMBTreeLocalResourceFactory(storageManager, typeTraits, cmpFactories, filterTypeTraits, filterCmpFactories, filterFields, opTrackerFactory, ioOpCallbackFactory, metadataPageManagerFactory, vbcProvider, ioSchedulerProvider, mergePolicyFactory, mergePolicyProperties, true, bloomFilterFields, bloomFilterFalsePositiveRate, index.isPrimaryIndex(), btreeFields, compDecompFactory);
        default:
            throw new CompilationException(ErrorCode.COMPILATION_UNKNOWN_DATASET_TYPE, dataset.getDatasetType().toString());
    }
}
#end_block

#method_before
public static IJsonSerializable fromJson(IPersistedResourceRegistry registry, JsonNode json) throws HyracksDataException {
    final int[] bloomFilterKeyFields = OBJECT_MAPPER.convertValue(json.get("bloomFilterKeyFields"), int[].class);
    final double bloomFilterFalsePositiveRate = json.get("bloomFilterFalsePositiveRate").asDouble();
    final boolean isPrimary = json.get("isPrimary").asBoolean();
    final int[] btreeFields = OBJECT_MAPPER.convertValue(json.get("btreeFields"), int[].class);
    final JsonNode compressorDecompressorNode = json.get("compressorDecompressorFactory");
    final ICompressorDecompressorFactory compressorDecompressorFactory = compressorDecompressorNode != null ? (ICompressorDecompressorFactory) registry.deserialize(compressorDecompressorNode) : null;
    return new LSMBTreeLocalResource(registry, json, bloomFilterKeyFields, bloomFilterFalsePositiveRate, isPrimary, btreeFields, compressorDecompressorFactory);
}
#method_after
public static IJsonSerializable fromJson(IPersistedResourceRegistry registry, JsonNode json) throws HyracksDataException {
    final int[] bloomFilterKeyFields = OBJECT_MAPPER.convertValue(json.get("bloomFilterKeyFields"), int[].class);
    final double bloomFilterFalsePositiveRate = json.get("bloomFilterFalsePositiveRate").asDouble();
    final boolean isPrimary = json.get("isPrimary").asBoolean();
    final int[] btreeFields = OBJECT_MAPPER.convertValue(json.get("btreeFields"), int[].class);
    final JsonNode compressorDecompressorNode = json.get("compressorDecompressorFactory");
    final ICompressorDecompressorFactory compDecompFactory = (ICompressorDecompressorFactory) registry.deserializeOrDefault(compressorDecompressorNode, NoOpCompressorDecompressorFactory.class);
    return new LSMBTreeLocalResource(registry, json, bloomFilterKeyFields, bloomFilterFalsePositiveRate, isPrimary, btreeFields, compDecompFactory);
}
#end_block

#method_before
@Override
protected void appendToJson(final ObjectNode json, IPersistedResourceRegistry registry) throws HyracksDataException {
    super.appendToJson(json, registry);
    json.putPOJO("bloomFilterKeyFields", bloomFilterKeyFields);
    json.put("bloomFilterFalsePositiveRate", bloomFilterFalsePositiveRate);
    json.put("isPrimary", isPrimary);
    json.putPOJO("btreeFields", btreeFields);
    if (compressorDecompressorFactory != null) {
        json.putPOJO("compressorDecompressorFactory", compressorDecompressorFactory.toJson(registry));
    }
}
#method_after
@Override
protected void appendToJson(final ObjectNode json, IPersistedResourceRegistry registry) throws HyracksDataException {
    super.appendToJson(json, registry);
    json.putPOJO("bloomFilterKeyFields", bloomFilterKeyFields);
    json.put("bloomFilterFalsePositiveRate", bloomFilterFalsePositiveRate);
    json.put("isPrimary", isPrimary);
    json.putPOJO("btreeFields", btreeFields);
    json.putPOJO("compressorDecompressorFactory", compressorDecompressorFactory.toJson(registry));
}
#end_block

#method_before
@Override
protected ITreeIndex createIndex(ITypeTraits[] typeTraits, IBinaryComparatorFactory[] cmpFactories, int[] bloomFilterKeyFields) throws HyracksDataException {
    return LSMBTreeUtil.createLSMTree(harness.getIOManager(), harness.getVirtualBufferCaches(), harness.getFileReference(), harness.getDiskBufferCache(), typeTraits, cmpFactories, bloomFilterKeyFields, harness.getBoomFilterFalsePositiveRate(), harness.getMergePolicy(), harness.getOperationTracker(), harness.getIOScheduler(), harness.getIOOperationCallbackFactory(), true, null, null, null, null, true, harness.getMetadataPageManagerFactory(), false, ITracer.NONE, null);
}
#method_after
@Override
protected ITreeIndex createIndex(ITypeTraits[] typeTraits, IBinaryComparatorFactory[] cmpFactories, int[] bloomFilterKeyFields) throws HyracksDataException {
    return LSMBTreeUtil.createLSMTree(harness.getIOManager(), harness.getVirtualBufferCaches(), harness.getFileReference(), harness.getDiskBufferCache(), typeTraits, cmpFactories, bloomFilterKeyFields, harness.getBoomFilterFalsePositiveRate(), harness.getMergePolicy(), harness.getOperationTracker(), harness.getIOScheduler(), harness.getIOOperationCallbackFactory(), true, null, null, null, null, true, harness.getMetadataPageManagerFactory(), false, ITracer.NONE, NoOpCompressorDecompressorFactory.INSTANCE);
}
#end_block

#method_before
public boolean delete() {
    final boolean deletedLAF = isCompressed() ? getLAFFileReference().delete() : true;
    return deletedLAF && file.delete();
}
#method_after
public boolean delete() {
    return file.delete();
}
#end_block

#method_before
public FileReference getChild(String name) {
    final FileReference childFr = new FileReference(dev, path + File.separator + name);
    if (isCompressed()) {
        childFr.setCompressorDecompressorFactory(compressorDecompressorFactory);
    }
    return childFr;
}
#method_after
public FileReference getChild(String name) {
    return new FileReference(dev, getChildPath(name));
}
#end_block

#method_before
public boolean isCompressed() {
    return compressorDecompressorFactory != null;
}
#method_after
public boolean isCompressed() {
    return false;
}
#end_block

#method_before
protected void handleException() throws HyracksDataException {
    // Unlatch and unpin pages that weren't in the queue to avoid leaking memory.
    if (compressedPageWriter != null) {
        compressedPageWriter.abort();
    }
    for (NodeFrontier nodeFrontier : nodeFrontiers) {
        ICachedPage frontierPage = nodeFrontier.page;
        if (frontierPage.confiscated()) {
            bufferCache.returnPage(frontierPage, false);
        }
    }
    for (ICachedPage pageToDiscard : pagesToWrite) {
        bufferCache.returnPage(pageToDiscard, false);
    }
    releasedLatches = true;
}
#method_after
protected void handleException() {
    // Unlatch and unpin pages that weren't in the queue to avoid leaking memory.
    compressedPageWriter.abort();
    for (NodeFrontier nodeFrontier : nodeFrontiers) {
        ICachedPage frontierPage = nodeFrontier.page;
        if (frontierPage.confiscated()) {
            bufferCache.returnPage(frontierPage, false);
        }
    }
    for (ICachedPage pageToDiscard : pagesToWrite) {
        bufferCache.returnPage(pageToDiscard, false);
    }
    releasedLatches = true;
}
#end_block

#method_before
public void putInQueue(ICachedPage cPage) throws HyracksDataException {
    if (compressedPageWriter != null) {
        compressedPageWriter.prepareWrite(cPage);
    }
    queue.put(cPage, this);
}
#method_after
public void putInQueue(ICachedPage cPage) throws HyracksDataException {
    compressedPageWriter.prepareWrite(cPage);
    queue.put(cPage, this);
}
#end_block

#method_before
protected void cleanupAndGetValidFilesInternal(FilenameFilter filter, TreeIndexFactory<? extends ITreeIndex> treeFactory, ArrayList<IndexComponentFileReference> allFiles, IBufferCache bufferCache) throws HyracksDataException {
    String[] files = listDirFiles(baseDir, filter);
    for (String fileName : files) {
        FileReference fileRef = getFileReference(fileName, isCompressable(fileName));
        if (treeFactory == null) {
            allFiles.add(IndexComponentFileReference.of(fileRef));
            continue;
        }
        TreeIndexState idxState = isValidTreeIndex(treeFactory.createIndexInstance(fileRef));
        if (idxState == TreeIndexState.VALID) {
            allFiles.add(IndexComponentFileReference.of(fileRef));
        } else if (idxState == TreeIndexState.INVALID) {
            bufferCache.deleteFile(fileRef);
        }
    }
}
#method_after
protected void cleanupAndGetValidFilesInternal(FilenameFilter filter, TreeIndexFactory<? extends ITreeIndex> treeFactory, ArrayList<IndexComponentFileReference> allFiles, IBufferCache bufferCache) throws HyracksDataException {
    String[] files = listDirFiles(baseDir, filter);
    for (String fileName : files) {
        FileReference fileRef = getFileReference(fileName);
        if (treeFactory == null) {
            allFiles.add(IndexComponentFileReference.of(fileRef));
            continue;
        }
        TreeIndexState idxState = isValidTreeIndex(treeFactory.createIndexInstance(fileRef));
        if (idxState == TreeIndexState.VALID) {
            allFiles.add(IndexComponentFileReference.of(fileRef));
        } else if (idxState == TreeIndexState.INVALID) {
            bufferCache.deleteFile(fileRef);
        }
    }
}
#end_block

#method_before
protected FileReference getFileReference(String name, boolean compressed) {
    final FileReference fileRef = baseDir.getChild(name);
    if (compressed && compressorDecompressorFactory != null) {
        fileRef.setCompressorDecompressorFactory(compressorDecompressorFactory);
    }
    return fileRef;
}
#method_after
protected FileReference getFileReference(String name) {
    final ICompressorDecompressor compDecomp = compressorDecompressorFactory.createInstance();
    // Avoid creating LAF file for NoOpCompressorDecompressor
    if (compDecomp != NoOpCompressorDecompressor.INSTANCE && isCompressible(name)) {
        final String path = baseDir.getChildPath(name);
        return new CompressedFileReference(baseDir.getDeviceHandle(), compDecomp, path, path + LAF_SUFFIX);
    }
    return baseDir.getChild(name);
}
#end_block

#method_before
@Override
public LSMComponentFileReferences getRelFlushFileReference() throws HyracksDataException {
    String baseName = getNextComponentSequence(btreeFilter);
    return new LSMComponentFileReferences(getFileReference(baseName + DELIMITER + BTREE_SUFFIX, true), null, hasBloomFilter ? getFileReference(baseName + DELIMITER + BLOOM_FILTER_SUFFIX, false) : null);
}
#method_after
@Override
public LSMComponentFileReferences getRelFlushFileReference() throws HyracksDataException {
    String baseName = getNextComponentSequence(btreeFilter);
    return new LSMComponentFileReferences(getFileReference(baseName + DELIMITER + BTREE_SUFFIX), null, hasBloomFilter ? getFileReference(baseName + DELIMITER + BLOOM_FILTER_SUFFIX) : null);
}
#end_block

#method_before
@Override
public LSMComponentFileReferences getRelMergeFileReference(String firstFileName, String lastFileName) {
    final String baseName = IndexComponentFileReference.getMergeSequence(firstFileName, lastFileName);
    return new LSMComponentFileReferences(getFileReference(baseName + DELIMITER + BTREE_SUFFIX, true), null, hasBloomFilter ? getFileReference(baseName + DELIMITER + BLOOM_FILTER_SUFFIX, false) : null);
}
#method_after
@Override
public LSMComponentFileReferences getRelMergeFileReference(String firstFileName, String lastFileName) {
    final String baseName = IndexComponentFileReference.getMergeSequence(firstFileName, lastFileName);
    return new LSMComponentFileReferences(getFileReference(baseName + DELIMITER + BTREE_SUFFIX), null, hasBloomFilter ? getFileReference(baseName + DELIMITER + BLOOM_FILTER_SUFFIX) : null);
}
#end_block

#method_before
@Override
protected void createIndexInstance() throws Exception {
    index = LSMBTreeUtil.createLSMTree(harness.getIOManager(), harness.getVirtualBufferCaches(), harness.getFileReference(), harness.getDiskBufferCache(), SerdeUtils.serdesToTypeTraits(keySerdes), SerdeUtils.serdesToComparatorFactories(keySerdes, keySerdes.length), bloomFilterKeyFields, harness.getBoomFilterFalsePositiveRate(), harness.getMergePolicy(), NoOpOperationTrackerFactory.INSTANCE.getOperationTracker(null, null), harness.getIOScheduler(), harness.getIOOperationCallbackFactory(), true, null, null, null, null, true, harness.getMetadataPageManagerFactory(), true, ITracer.NONE, null);
}
#method_after
@Override
protected void createIndexInstance() throws Exception {
    index = LSMBTreeUtil.createLSMTree(harness.getIOManager(), harness.getVirtualBufferCaches(), harness.getFileReference(), harness.getDiskBufferCache(), SerdeUtils.serdesToTypeTraits(keySerdes), SerdeUtils.serdesToComparatorFactories(keySerdes, keySerdes.length), bloomFilterKeyFields, harness.getBoomFilterFalsePositiveRate(), harness.getMergePolicy(), NoOpOperationTrackerFactory.INSTANCE.getOperationTracker(null, null), harness.getIOScheduler(), harness.getIOOperationCallbackFactory(), true, null, null, null, null, true, harness.getMetadataPageManagerFactory(), true, ITracer.NONE, NoOpCompressorDecompressorFactory.INSTANCE);
}
#end_block

#method_before
private static Set<IHint> initHints() {
    Set<IHint> hints = new HashSet<>();
    hints.add(new DatasetCardinalityHint());
    hints.add(new DatasetNodegroupCardinalityHint());
    hints.add(new CompressionSchemeHint());
    return hints;
}
#method_after
private static Set<IHint> initHints() {
    Set<IHint> hints = new HashSet<>();
    hints.add(new DatasetCardinalityHint());
    hints.add(new DatasetNodegroupCardinalityHint());
    return hints;
}
#end_block

#method_before
public static LSMBTree createTreeIndex(LSMBTreeTestHarness harness, ITypeTraits[] typeTraits, IBinaryComparatorFactory[] cmpFactories, int[] bloomFilterKeyFields, ITypeTraits[] filterTypeTraits, IBinaryComparatorFactory[] filterCmpFactories, int[] btreeFields, int[] filterFields) throws HyracksDataException {
    return LSMBTreeUtil.createLSMTree(harness.getIOManager(), harness.getVirtualBufferCaches(), harness.getFileReference(), harness.getDiskBufferCache(), typeTraits, cmpFactories, bloomFilterKeyFields, harness.getBoomFilterFalsePositiveRate(), harness.getMergePolicy(), harness.getOperationTracker(), harness.getIOScheduler(), harness.getIOOperationCallbackFactory(), true, filterTypeTraits, filterCmpFactories, btreeFields, filterFields, true, harness.getMetadataPageManagerFactory(), false, ITracer.NONE, null);
}
#method_after
public static LSMBTree createTreeIndex(LSMBTreeTestHarness harness, ITypeTraits[] typeTraits, IBinaryComparatorFactory[] cmpFactories, int[] bloomFilterKeyFields, ITypeTraits[] filterTypeTraits, IBinaryComparatorFactory[] filterCmpFactories, int[] btreeFields, int[] filterFields) throws HyracksDataException {
    return LSMBTreeUtil.createLSMTree(harness.getIOManager(), harness.getVirtualBufferCaches(), harness.getFileReference(), harness.getDiskBufferCache(), typeTraits, cmpFactories, bloomFilterKeyFields, harness.getBoomFilterFalsePositiveRate(), harness.getMergePolicy(), harness.getOperationTracker(), harness.getIOScheduler(), harness.getIOOperationCallbackFactory(), true, filterTypeTraits, filterCmpFactories, btreeFields, filterFields, true, harness.getMetadataPageManagerFactory(), false, ITracer.NONE, NoOpCompressorDecompressorFactory.INSTANCE);
}
#end_block

#method_before
@Override
protected void createIndexInstance() throws Exception {
    index = LSMBTreeUtil.createLSMTree(harness.getIOManager(), harness.getVirtualBufferCaches(), harness.getFileReference(), harness.getDiskBufferCache(), SerdeUtils.serdesToTypeTraits(keySerdes), SerdeUtils.serdesToComparatorFactories(keySerdes, keySerdes.length), bloomFilterKeyFields, harness.getBoomFilterFalsePositiveRate(), harness.getMergePolicy(), NoOpOperationTrackerFactory.INSTANCE.getOperationTracker(null, null), harness.getIOScheduler(), harness.getIOOperationCallbackFactory(), true, null, null, null, null, true, harness.getMetadataPageManagerFactory(), false, ITracer.NONE, null);
}
#method_after
@Override
protected void createIndexInstance() throws Exception {
    index = LSMBTreeUtil.createLSMTree(harness.getIOManager(), harness.getVirtualBufferCaches(), harness.getFileReference(), harness.getDiskBufferCache(), SerdeUtils.serdesToTypeTraits(keySerdes), SerdeUtils.serdesToComparatorFactories(keySerdes, keySerdes.length), bloomFilterKeyFields, harness.getBoomFilterFalsePositiveRate(), harness.getMergePolicy(), NoOpOperationTrackerFactory.INSTANCE.getOperationTracker(null, null), harness.getIOScheduler(), harness.getIOOperationCallbackFactory(), true, null, null, null, null, true, harness.getMetadataPageManagerFactory(), false, ITracer.NONE, NoOpCompressorDecompressorFactory.INSTANCE);
}
#end_block

#method_before
@Override
protected void createIndexInstance() throws Exception {
    index = LSMBTreeUtil.createLSMTree(harness.getIOManager(), harness.getVirtualBufferCaches(), harness.getFileReference(), harness.getDiskBufferCache(), SerdeUtils.serdesToTypeTraits(keySerdes), SerdeUtils.serdesToComparatorFactories(keySerdes, keySerdes.length), bloomFilterKeyFields, harness.getBoomFilterFalsePositiveRate(), harness.getMergePolicy(), NoOpOperationTrackerFactory.INSTANCE.getOperationTracker(null, null), harness.getIOScheduler(), harness.getIOOperationCallbackFactory(), true, null, null, null, null, true, harness.getMetadataPageManagerFactory(), false, ITracer.NONE, null);
}
#method_after
@Override
protected void createIndexInstance() throws Exception {
    index = LSMBTreeUtil.createLSMTree(harness.getIOManager(), harness.getVirtualBufferCaches(), harness.getFileReference(), harness.getDiskBufferCache(), SerdeUtils.serdesToTypeTraits(keySerdes), SerdeUtils.serdesToComparatorFactories(keySerdes, keySerdes.length), bloomFilterKeyFields, harness.getBoomFilterFalsePositiveRate(), harness.getMergePolicy(), NoOpOperationTrackerFactory.INSTANCE.getOperationTracker(null, null), harness.getIOScheduler(), harness.getIOOperationCallbackFactory(), true, null, null, null, null, true, harness.getMetadataPageManagerFactory(), false, ITracer.NONE, NoOpCompressorDecompressorFactory.INSTANCE);
}
#end_block

#method_before
public static LSMBTreeTestContext create(IIOManager ioManager, List<IVirtualBufferCache> virtualBufferCaches, FileReference file, IBufferCache diskBufferCache, ISerializerDeserializer[] fieldSerdes, int numKeyFields, double bloomFilterFalsePositiveRate, ILSMMergePolicy mergePolicy, ILSMOperationTracker opTracker, ILSMIOOperationScheduler ioScheduler, ILSMIOOperationCallbackFactory ioOpCallbackFactory, IMetadataPageManagerFactory metadataPageManagerFactory, boolean filtered, boolean needKeyDupCheck, boolean updateAware) throws HyracksDataException {
    ITypeTraits[] typeTraits = SerdeUtils.serdesToTypeTraits(fieldSerdes);
    IBinaryComparatorFactory[] cmpFactories = SerdeUtils.serdesToComparatorFactories(fieldSerdes, numKeyFields);
    int[] bloomFilterKeyFields = new int[numKeyFields];
    for (int i = 0; i < numKeyFields; ++i) {
        bloomFilterKeyFields[i] = i;
    }
    LSMBTree lsmTree;
    if (filtered) {
        ITypeTraits[] filterTypeTraits = new ITypeTraits[1];
        filterTypeTraits[0] = typeTraits[0];
        int[] btreefields = new int[typeTraits.length];
        for (int i = 0; i < btreefields.length; i++) {
            btreefields[i] = i;
        }
        int[] filterfields = { btreefields.length };
        IBinaryComparatorFactory[] filterCmp = { cmpFactories[0] };
        lsmTree = LSMBTreeUtil.createLSMTree(ioManager, virtualBufferCaches, file, diskBufferCache, typeTraits, cmpFactories, bloomFilterKeyFields, bloomFilterFalsePositiveRate, mergePolicy, opTracker, ioScheduler, ioOpCallbackFactory, needKeyDupCheck, filterTypeTraits, filterCmp, btreefields, filterfields, true, metadataPageManagerFactory, updateAware, ITracer.NONE, null);
    } else {
        lsmTree = LSMBTreeUtil.createLSMTree(ioManager, virtualBufferCaches, file, diskBufferCache, typeTraits, cmpFactories, bloomFilterKeyFields, bloomFilterFalsePositiveRate, mergePolicy, opTracker, ioScheduler, ioOpCallbackFactory, needKeyDupCheck, null, null, null, null, true, metadataPageManagerFactory, updateAware, new Tracer(LSMBTreeTestContext.class.getSimpleName(), ITraceCategoryRegistry.CATEGORIES_ALL, new TraceCategoryRegistry()), null);
    }
    LSMBTreeTestContext testCtx = new LSMBTreeTestContext(fieldSerdes, lsmTree, filtered);
    return testCtx;
}
#method_after
public static LSMBTreeTestContext create(IIOManager ioManager, List<IVirtualBufferCache> virtualBufferCaches, FileReference file, IBufferCache diskBufferCache, ISerializerDeserializer[] fieldSerdes, int numKeyFields, double bloomFilterFalsePositiveRate, ILSMMergePolicy mergePolicy, ILSMOperationTracker opTracker, ILSMIOOperationScheduler ioScheduler, ILSMIOOperationCallbackFactory ioOpCallbackFactory, IMetadataPageManagerFactory metadataPageManagerFactory, boolean filtered, boolean needKeyDupCheck, boolean updateAware) throws HyracksDataException {
    ITypeTraits[] typeTraits = SerdeUtils.serdesToTypeTraits(fieldSerdes);
    IBinaryComparatorFactory[] cmpFactories = SerdeUtils.serdesToComparatorFactories(fieldSerdes, numKeyFields);
    int[] bloomFilterKeyFields = new int[numKeyFields];
    for (int i = 0; i < numKeyFields; ++i) {
        bloomFilterKeyFields[i] = i;
    }
    LSMBTree lsmTree;
    if (filtered) {
        ITypeTraits[] filterTypeTraits = new ITypeTraits[1];
        filterTypeTraits[0] = typeTraits[0];
        int[] btreefields = new int[typeTraits.length];
        for (int i = 0; i < btreefields.length; i++) {
            btreefields[i] = i;
        }
        int[] filterfields = { btreefields.length };
        IBinaryComparatorFactory[] filterCmp = { cmpFactories[0] };
        lsmTree = LSMBTreeUtil.createLSMTree(ioManager, virtualBufferCaches, file, diskBufferCache, typeTraits, cmpFactories, bloomFilterKeyFields, bloomFilterFalsePositiveRate, mergePolicy, opTracker, ioScheduler, ioOpCallbackFactory, needKeyDupCheck, filterTypeTraits, filterCmp, btreefields, filterfields, true, metadataPageManagerFactory, updateAware, ITracer.NONE, NoOpCompressorDecompressorFactory.INSTANCE);
    } else {
        lsmTree = LSMBTreeUtil.createLSMTree(ioManager, virtualBufferCaches, file, diskBufferCache, typeTraits, cmpFactories, bloomFilterKeyFields, bloomFilterFalsePositiveRate, mergePolicy, opTracker, ioScheduler, ioOpCallbackFactory, needKeyDupCheck, null, null, null, null, true, metadataPageManagerFactory, updateAware, new Tracer(LSMBTreeTestContext.class.getSimpleName(), ITraceCategoryRegistry.CATEGORIES_ALL, new TraceCategoryRegistry()), NoOpCompressorDecompressorFactory.INSTANCE);
    }
    LSMBTreeTestContext testCtx = new LSMBTreeTestContext(fieldSerdes, lsmTree, filtered);
    return testCtx;
}
#end_block

#method_before
@Override
public void close(IPageWriteFailureCallback callback) throws HyracksDataException {
    if (ready) {
        IFIFOPageQueue queue = bufferCache.createFIFOQueue();
        ITreeIndexMetadataFrame metaFrame = frameFactory.createFrame();
        confiscatedPage.acquireWriteLatch();
        try {
            metaFrame.setPage(confiscatedPage);
            metaFrame.setValid(true);
        } finally {
            confiscatedPage.releaseWriteLatch(false);
        }
        int finalMetaPage = getMaxPageId(metaFrame) + 1;
        confiscatedPage.setDiskPageId(BufferedFileHandle.getDiskPageId(fileId, finalMetaPage));
        final ICompressedPageWriter compressedPageWriter = bufferCache.getCompressedPageWriter(fileId);
        if (compressedPageWriter != null) {
            // Prepare to write the compressed page
            compressedPageWriter.prepareWrite(confiscatedPage);
        }
        // WARNING: flushing the metadata page should be done after releasing the write latch; otherwise, the page
        // won't be flushed to disk because it won't be dirty until the write latch has been released.
        queue.put(confiscatedPage, callback);
        bufferCache.finishQueue();
        if (compressedPageWriter != null) {
            // Finalize the writing of the compressed pages
            compressedPageWriter.endWriting();
        }
        metadataPage = getMetadataPageId();
        ready = false;
    } else if (confiscatedPage != null) {
        bufferCache.returnPage(confiscatedPage, false);
    }
    confiscatedPage = null;
}
#method_after
@Override
public void close(IPageWriteFailureCallback callback) throws HyracksDataException {
    if (ready) {
        IFIFOPageQueue queue = bufferCache.createFIFOQueue();
        ITreeIndexMetadataFrame metaFrame = frameFactory.createFrame();
        confiscatedPage.acquireWriteLatch();
        try {
            metaFrame.setPage(confiscatedPage);
            metaFrame.setValid(true);
        } finally {
            confiscatedPage.releaseWriteLatch(false);
        }
        int finalMetaPage = getMaxPageId(metaFrame) + 1;
        confiscatedPage.setDiskPageId(BufferedFileHandle.getDiskPageId(fileId, finalMetaPage));
        final ICompressedPageWriter compressedPageWriter = bufferCache.getCompressedPageWriter(fileId);
        compressedPageWriter.prepareWrite(confiscatedPage);
        // WARNING: flushing the metadata page should be done after releasing the write latch; otherwise, the page
        // won't be flushed to disk because it won't be dirty until the write latch has been released.
        queue.put(confiscatedPage, callback);
        bufferCache.finishQueue();
        compressedPageWriter.endWriting();
        metadataPage = getMetadataPageId();
        ready = false;
    } else if (confiscatedPage != null) {
        bufferCache.returnPage(confiscatedPage, false);
    }
    confiscatedPage = null;
}
#end_block

#method_before
@Override
public int getMetadataPageId() throws HyracksDataException {
    if (metadataPage != IBufferCache.INVALID_PAGEID) {
        return metadataPage;
    }
    int pages = bufferCache.getNumPagesOfFile(fileId);
    if (pages == 0) {
        // At least there are 4 pages to consider the index is not empty
        return IBufferCache.INVALID_PAGEID;
    }
    metadataPage = pages - 1;
    return metadataPage;
}
#method_after
@Override
public int getMetadataPageId() throws HyracksDataException {
    if (metadataPage != IBufferCache.INVALID_PAGEID) {
        return metadataPage;
    }
    int pages = bufferCache.getNumPagesOfFile(fileId);
    if (pages == 0) {
        // At least there are 2 pages to consider the index is not empty
        return IBufferCache.INVALID_PAGEID;
    }
    metadataPage = pages - 1;
    return metadataPage;
}
#end_block

#method_before
public String getCompressionScheme() {
    return accessor.getString(Option.STORAGE_COMPRESSION_SCHEME);
}
#method_after
public String getCompressionScheme() {
    return accessor.getString(Option.STORAGE_COMPRESSION_BLOCK);
}
#end_block

#method_before
private ICompressorDecompressorFactory getFactory(String scheme) throws CompilationException {
    if (NONE.equals(scheme)) {
        return null;
    }
    Class<? extends ICompressorDecompressorFactory> clazz = REGISTERED_SCHEMES.get(scheme);
    try {
        return clazz.newInstance();
    } catch (IllegalAccessException | InstantiationException e) {
        throw new CompilationException(ErrorCode.FAILED_TO_INIT_COMPRESSOR_FACTORY, e, scheme);
    }
}
#method_after
@Override
public ICompressorDecompressorFactory getFactory(String schemeName) throws CompilationException {
    final String scheme = getDdlOrDefaultCompressionScheme(schemeName);
    Class<? extends ICompressorDecompressorFactory> clazz = REGISTERED_SCHEMES.get(scheme);
    try {
        return clazz.newInstance();
    } catch (IllegalAccessException | InstantiationException e) {
        throw new IllegalStateException("Failed to instantiate compressor/decompressor: " + scheme, e);
    }
}
#end_block

#method_before
private void validateCompressionConfiguration(StorageProperties storageProperties) throws AlgebricksException {
    if (!isRegisteredScheme(storageProperties.getCompressionScheme())) {
        final String option = StorageProperties.Option.STORAGE_COMPRESSION_SCHEME.ini();
        final String value = storageProperties.getCompressionScheme();
        throw new CompilationException(ErrorCode.INVALID_COMPRESSION_CONFIG, option, value, formatSupportedValues(REGISTERED_SCHEMES.keySet()));
    }
}
#method_after
private void validateCompressionConfiguration(StorageProperties storageProperties) {
    if (!isRegisteredScheme(storageProperties.getCompressionScheme())) {
        final String option = StorageProperties.Option.STORAGE_COMPRESSION_BLOCK.ini();
        final String value = storageProperties.getCompressionScheme();
        throw new IllegalStateException("Invalid compression configuration (" + option + " = " + value + "). Valid values are: " + formatSupportedValues());
    }
}
#end_block

#method_before
private String formatSupportedValues(Collection<String> supprtedValues) {
    final StringBuilder schemes = new StringBuilder();
    final Iterator<String> iterator = supprtedValues.iterator();
    schemes.append('[');
    schemes.append(iterator.next());
    while (iterator.hasNext()) {
        schemes.append(',');
        schemes.append(iterator.next());
    }
    schemes.append(']');
    return schemes.toString();
}
#method_after
private String formatSupportedValues() {
    final StringBuilder schemes = new StringBuilder();
    final Iterator<String> iterator = REGISTERED_SCHEMES.keySet().iterator();
    schemes.append('[');
    schemes.append(iterator.next());
    while (iterator.hasNext()) {
        schemes.append(',');
        schemes.append(iterator.next());
    }
    schemes.append(']');
    return schemes.toString();
}
#end_block

#method_before
private boolean pushDownFieldAccessRec(Mutable<ILogicalOperator> opRef, IOptimizationContext context, String finalAnnot) throws AlgebricksException {
    AssignOperator assignOp = (AssignOperator) opRef.getValue();
    Mutable<ILogicalOperator> opRef2 = assignOp.getInputs().get(0);
    AbstractLogicalOperator inputOp = (AbstractLogicalOperator) opRef2.getValue();
    // If it's not an indexed field, it is pushed so that scan can be rewritten into index search.
    if (inputOp.getOperatorTag() == LogicalOperatorTag.PROJECT || context.checkAndAddToAlreadyCompared(assignOp, inputOp) && !(inputOp.getOperatorTag() == LogicalOperatorTag.SELECT && isAccessToIndexedField(assignOp, context))) {
        return false;
    }
    Object annotation = inputOp.getAnnotations().get(OperatorPropertiesUtil.MOVABLE);
    if (annotation != null && !((Boolean) annotation)) {
        return false;
    }
    if (tryingToPushThroughSelectionWithSameDataSource(assignOp, inputOp)) {
        return false;
    }
    if (testAndModifyRedundantOp(assignOp, inputOp)) {
        pushDownFieldAccessRec(opRef2, context, finalAnnot);
        return true;
    }
    List<LogicalVariable> usedInAccess = new LinkedList<>();
    VariableUtilities.getUsedVariables(assignOp, usedInAccess);
    List<LogicalVariable> produced2 = new LinkedList<>();
    if (inputOp.getOperatorTag() == LogicalOperatorTag.GROUP) {
        VariableUtilities.getLiveVariables(inputOp, produced2);
    } else {
        VariableUtilities.getProducedVariables(inputOp, produced2);
    }
    boolean pushItDown = false;
    List<LogicalVariable> inter = new ArrayList<>(usedInAccess);
    if (inter.isEmpty()) {
        // ground value
        return false;
    }
    inter.retainAll(produced2);
    if (inter.isEmpty()) {
        pushItDown = true;
    } else if (inputOp.getOperatorTag() == LogicalOperatorTag.GROUP) {
        GroupByOperator g = (GroupByOperator) inputOp;
        List<Pair<LogicalVariable, LogicalVariable>> varMappings = new ArrayList<>();
        for (Pair<LogicalVariable, Mutable<ILogicalExpression>> p : g.getDecorList()) {
            ILogicalExpression e = p.second.getValue();
            if (e.getExpressionTag() == LogicalExpressionTag.VARIABLE) {
                LogicalVariable decorVar = GroupByOperator.getDecorVariable(p);
                if (inter.contains(decorVar)) {
                    inter.remove(decorVar);
                    LogicalVariable v1 = ((VariableReferenceExpression) e).getVariableReference();
                    varMappings.add(new Pair<>(decorVar, v1));
                }
            }
        }
        if (inter.isEmpty()) {
            boolean changed = false;
            for (Pair<LogicalVariable, LogicalVariable> m : varMappings) {
                LogicalVariable v2 = context.newVar();
                LogicalVariable oldVar = assignOp.getVariables().get(0);
                VariableReferenceExpression v2Ref = new VariableReferenceExpression(v2);
                v2Ref.setSourceLocation(g.getSourceLocation());
                g.getDecorList().add(new Pair<LogicalVariable, Mutable<ILogicalExpression>>(oldVar, new MutableObject<ILogicalExpression>(v2Ref)));
                changed = true;
                assignOp.getVariables().set(0, v2);
                VariableUtilities.substituteVariables(assignOp, m.first, m.second, context);
            }
            if (changed) {
                context.computeAndSetTypeEnvironmentForOperator(g);
            }
            usedInAccess.clear();
            VariableUtilities.getUsedVariables(assignOp, usedInAccess);
            pushItDown = true;
        }
    }
    if (pushItDown) {
        if (inputOp.getOperatorTag() == LogicalOperatorTag.NESTEDTUPLESOURCE) {
            Mutable<ILogicalOperator> childOfSubplan = ((NestedTupleSourceOperator) inputOp).getDataSourceReference().getValue().getInputs().get(0);
            pushAccessDown(opRef, inputOp, childOfSubplan, context, finalAnnot);
            return true;
        }
        if (inputOp.getInputs().size() == 1 && !inputOp.hasNestedPlans()) {
            pushAccessDown(opRef, inputOp, inputOp.getInputs().get(0), context, finalAnnot);
            return true;
        } else {
            for (Mutable<ILogicalOperator> inp : inputOp.getInputs()) {
                HashSet<LogicalVariable> v2 = new HashSet<>();
                VariableUtilities.getLiveVariables(inp.getValue(), v2);
                if (v2.containsAll(usedInAccess)) {
                    pushAccessDown(opRef, inputOp, inp, context, finalAnnot);
                    return true;
                }
            }
        }
        if (inputOp.hasNestedPlans()) {
            AbstractOperatorWithNestedPlans nestedOp = (AbstractOperatorWithNestedPlans) inputOp;
            for (ILogicalPlan plan : nestedOp.getNestedPlans()) {
                for (Mutable<ILogicalOperator> root : plan.getRoots()) {
                    HashSet<LogicalVariable> v2 = new HashSet<>();
                    VariableUtilities.getLiveVariables(root.getValue(), v2);
                    if (v2.containsAll(usedInAccess)) {
                        pushAccessDown(opRef, inputOp, root, context, finalAnnot);
                        return true;
                    }
                }
            }
        }
        throw new CompilationException(ErrorCode.COMPILATION_ERROR, assignOp.getSourceLocation(), "Field assignOp " + assignOp.getExpressions().get(0).getValue() + " does not correspond to any input of operator " + inputOp);
    } else {
        // check if the accessed field is one of the partitioning key fields. If yes, we can equate the 2 variables
        if (inputOp.getOperatorTag() == LogicalOperatorTag.DATASOURCESCAN) {
            DataSourceScanOperator scan = (DataSourceScanOperator) inputOp;
            IDataSource<DataSourceId> dataSource = (IDataSource<DataSourceId>) scan.getDataSource();
            byte dsType = ((DataSource) dataSource).getDatasourceType();
            if (dsType != DataSource.Type.INTERNAL_DATASET && dsType != DataSource.Type.EXTERNAL_DATASET) {
                return false;
            }
            DataSourceId asid = dataSource.getId();
            MetadataProvider mp = (MetadataProvider) context.getMetadataProvider();
            Dataset dataset = mp.findDataset(asid.getDataverseName(), asid.getDatasourceName());
            if (dataset == null) {
                throw new CompilationException(ErrorCode.UNKNOWN_DATASET_IN_DATAVERSE, scan.getSourceLocation(), asid.getDatasourceName(), asid.getDataverseName());
            }
            if (dataset.getDatasetType() != DatasetType.INTERNAL) {
                setAsFinal(assignOp, context, finalAnnot);
                return false;
            }
            List<LogicalVariable> allVars = scan.getVariables();
            LogicalVariable dataRecVarInScan = ((DataSource) dataSource).getDataRecordVariable(allVars);
            LogicalVariable metaRecVarInScan = ((DataSource) dataSource).getMetaVariable(allVars);
            // data part
            String dataTypeName = dataset.getItemTypeName();
            IAType dataType = mp.findType(dataset.getItemTypeDataverseName(), dataTypeName);
            if (dataType.getTypeTag() != ATypeTag.OBJECT) {
                return false;
            }
            ARecordType dataRecType = (ARecordType) dataType;
            Pair<ILogicalExpression, List<String>> fieldPathAndVar = getFieldExpression(assignOp, dataRecType);
            ILogicalExpression targetRecVar = fieldPathAndVar.first;
            List<String> targetFieldPath = fieldPathAndVar.second;
            boolean rewrite = false;
            boolean fieldFromMeta = false;
            if (sameRecords(targetRecVar, dataRecVarInScan)) {
                rewrite = true;
            } else {
                // check meta part
                // could be null
                IAType metaType = mp.findMetaType(dataset);
                if (metaType != null && metaType.getTypeTag() == ATypeTag.OBJECT) {
                    fieldPathAndVar = getFieldExpression(assignOp, (ARecordType) metaType);
                    targetRecVar = fieldPathAndVar.first;
                    targetFieldPath = fieldPathAndVar.second;
                    if (sameRecords(targetRecVar, metaRecVarInScan)) {
                        rewrite = true;
                        fieldFromMeta = true;
                    }
                }
            }
            if (rewrite) {
                int p = DatasetUtil.getPositionOfPartitioningKeyField(dataset, targetFieldPath, fieldFromMeta);
                if (p < 0) {
                    // not one of the partitioning fields
                    setAsFinal(assignOp, context, finalAnnot);
                    return false;
                }
                LogicalVariable keyVar = scan.getVariables().get(p);
                VariableReferenceExpression keyVarRef = new VariableReferenceExpression(keyVar);
                keyVarRef.setSourceLocation(targetRecVar.getSourceLocation());
                assignOp.getExpressions().get(0).setValue(keyVarRef);
                return true;
            }
        }
        setAsFinal(assignOp, context, finalAnnot);
        return false;
    }
}
#method_after
private boolean pushDownFieldAccessRec(Mutable<ILogicalOperator> opRef, IOptimizationContext context, String finalAnnot) throws AlgebricksException {
    AssignOperator assignOp = (AssignOperator) opRef.getValue();
    Mutable<ILogicalOperator> opRef2 = assignOp.getInputs().get(0);
    AbstractLogicalOperator inputOp = (AbstractLogicalOperator) opRef2.getValue();
    // If it's not an indexed field, it is pushed so that scan can be rewritten into index search.
    if (inputOp.getOperatorTag() == LogicalOperatorTag.PROJECT || context.checkAndAddToAlreadyCompared(assignOp, inputOp) && !(inputOp.getOperatorTag() == LogicalOperatorTag.SELECT && isAccessToIndexedField(assignOp, context))) {
        return false;
    }
    Object annotation = inputOp.getAnnotations().get(OperatorPropertiesUtil.MOVABLE);
    if (annotation != null && !((Boolean) annotation)) {
        return false;
    }
    if (tryingToPushThroughSelectionWithSameDataSource(assignOp, inputOp)) {
        return false;
    }
    if (testAndModifyRedundantOp(assignOp, inputOp)) {
        pushDownFieldAccessRec(opRef2, context, finalAnnot);
        return true;
    }
    List<LogicalVariable> usedInAccess = new LinkedList<>();
    VariableUtilities.getUsedVariables(assignOp, usedInAccess);
    List<LogicalVariable> produced2 = new LinkedList<>();
    if (inputOp.getOperatorTag() == LogicalOperatorTag.GROUP) {
        VariableUtilities.getLiveVariables(inputOp, produced2);
    } else {
        VariableUtilities.getProducedVariables(inputOp, produced2);
    }
    boolean pushItDown = false;
    List<LogicalVariable> inter = new ArrayList<>(usedInAccess);
    if (inter.isEmpty()) {
        // ground value
        return false;
    }
    inter.retainAll(produced2);
    if (inter.isEmpty()) {
        pushItDown = true;
    } else if (inputOp.getOperatorTag() == LogicalOperatorTag.GROUP) {
        GroupByOperator g = (GroupByOperator) inputOp;
        List<Pair<LogicalVariable, LogicalVariable>> varMappings = new ArrayList<>();
        for (Pair<LogicalVariable, Mutable<ILogicalExpression>> p : g.getDecorList()) {
            ILogicalExpression e = p.second.getValue();
            if (e.getExpressionTag() == LogicalExpressionTag.VARIABLE) {
                LogicalVariable decorVar = GroupByOperator.getDecorVariable(p);
                if (inter.contains(decorVar)) {
                    inter.remove(decorVar);
                    LogicalVariable v1 = ((VariableReferenceExpression) e).getVariableReference();
                    varMappings.add(new Pair<>(decorVar, v1));
                }
            }
        }
        if (inter.isEmpty()) {
            boolean changed = false;
            for (Pair<LogicalVariable, LogicalVariable> m : varMappings) {
                LogicalVariable v2 = context.newVar();
                LogicalVariable oldVar = assignOp.getVariables().get(0);
                VariableReferenceExpression v2Ref = new VariableReferenceExpression(v2);
                v2Ref.setSourceLocation(g.getSourceLocation());
                g.getDecorList().add(new Pair<LogicalVariable, Mutable<ILogicalExpression>>(oldVar, new MutableObject<ILogicalExpression>(v2Ref)));
                changed = true;
                assignOp.getVariables().set(0, v2);
                VariableUtilities.substituteVariables(assignOp, m.first, m.second, context);
            }
            if (changed) {
                context.computeAndSetTypeEnvironmentForOperator(g);
            }
            usedInAccess.clear();
            VariableUtilities.getUsedVariables(assignOp, usedInAccess);
            pushItDown = true;
        }
    }
    if (pushItDown) {
        if (inputOp.getOperatorTag() == LogicalOperatorTag.NESTEDTUPLESOURCE) {
            Mutable<ILogicalOperator> childOfSubplan = ((NestedTupleSourceOperator) inputOp).getDataSourceReference().getValue().getInputs().get(0);
            pushAccessDown(opRef, inputOp, childOfSubplan, context, finalAnnot);
            return true;
        }
        if (inputOp.getInputs().size() == 1 && !inputOp.hasNestedPlans()) {
            pushAccessDown(opRef, inputOp, inputOp.getInputs().get(0), context, finalAnnot);
            return true;
        } else {
            for (Mutable<ILogicalOperator> inp : inputOp.getInputs()) {
                HashSet<LogicalVariable> v2 = new HashSet<>();
                VariableUtilities.getLiveVariables(inp.getValue(), v2);
                if (v2.containsAll(usedInAccess)) {
                    pushAccessDown(opRef, inputOp, inp, context, finalAnnot);
                    return true;
                }
            }
        }
        if (inputOp.hasNestedPlans()) {
            AbstractOperatorWithNestedPlans nestedOp = (AbstractOperatorWithNestedPlans) inputOp;
            for (ILogicalPlan plan : nestedOp.getNestedPlans()) {
                for (Mutable<ILogicalOperator> root : plan.getRoots()) {
                    HashSet<LogicalVariable> v2 = new HashSet<>();
                    VariableUtilities.getLiveVariables(root.getValue(), v2);
                    if (v2.containsAll(usedInAccess)) {
                        pushAccessDown(opRef, inputOp, root, context, finalAnnot);
                        return true;
                    }
                }
            }
        }
        throw new CompilationException(ErrorCode.COMPILATION_ERROR, assignOp.getSourceLocation(), "Field access " + assignOp.getExpressions().get(0).getValue() + " does not correspond to any input of operator " + inputOp);
    } else {
        // check if the accessed field is one of the partitioning key fields. If yes, we can equate the 2 variables
        if (inputOp.getOperatorTag() == LogicalOperatorTag.DATASOURCESCAN) {
            DataSourceScanOperator scan = (DataSourceScanOperator) inputOp;
            IDataSource<DataSourceId> dataSource = (IDataSource<DataSourceId>) scan.getDataSource();
            byte dsType = ((DataSource) dataSource).getDatasourceType();
            if (dsType != DataSource.Type.INTERNAL_DATASET && dsType != DataSource.Type.EXTERNAL_DATASET) {
                return false;
            }
            DataSourceId asid = dataSource.getId();
            MetadataProvider mp = (MetadataProvider) context.getMetadataProvider();
            Dataset dataset = mp.findDataset(asid.getDataverseName(), asid.getDatasourceName());
            if (dataset == null) {
                throw new CompilationException(ErrorCode.UNKNOWN_DATASET_IN_DATAVERSE, scan.getSourceLocation(), asid.getDatasourceName(), asid.getDataverseName());
            }
            if (dataset.getDatasetType() != DatasetType.INTERNAL) {
                setAsFinal(assignOp, context, finalAnnot);
                return false;
            }
            List<LogicalVariable> allVars = scan.getVariables();
            LogicalVariable dataRecVarInScan = ((DataSource) dataSource).getDataRecordVariable(allVars);
            LogicalVariable metaRecVarInScan = ((DataSource) dataSource).getMetaVariable(allVars);
            // data part
            String dataTypeName = dataset.getItemTypeName();
            IAType dataType = mp.findType(dataset.getItemTypeDataverseName(), dataTypeName);
            if (dataType.getTypeTag() != ATypeTag.OBJECT) {
                return false;
            }
            ARecordType dataRecType = (ARecordType) dataType;
            Pair<ILogicalExpression, List<String>> fieldPathAndVar = getFieldExpression(assignOp, dataRecType);
            ILogicalExpression targetRecVar = fieldPathAndVar.first;
            List<String> targetFieldPath = fieldPathAndVar.second;
            boolean rewrite = false;
            boolean fieldFromMeta = false;
            if (sameRecords(targetRecVar, dataRecVarInScan)) {
                rewrite = true;
            } else {
                // check meta part
                // could be null
                IAType metaType = mp.findMetaType(dataset);
                if (metaType != null && metaType.getTypeTag() == ATypeTag.OBJECT) {
                    fieldPathAndVar = getFieldExpression(assignOp, (ARecordType) metaType);
                    targetRecVar = fieldPathAndVar.first;
                    targetFieldPath = fieldPathAndVar.second;
                    if (sameRecords(targetRecVar, metaRecVarInScan)) {
                        rewrite = true;
                        fieldFromMeta = true;
                    }
                }
            }
            if (rewrite) {
                int p = DatasetUtil.getPositionOfPartitioningKeyField(dataset, targetFieldPath, fieldFromMeta);
                if (p < 0) {
                    // not one of the partitioning fields
                    setAsFinal(assignOp, context, finalAnnot);
                    return false;
                }
                LogicalVariable keyVar = scan.getVariables().get(p);
                VariableReferenceExpression keyVarRef = new VariableReferenceExpression(keyVar);
                keyVarRef.setSourceLocation(targetRecVar.getSourceLocation());
                assignOp.getExpressions().get(0).setValue(keyVarRef);
                return true;
            }
        }
        setAsFinal(assignOp, context, finalAnnot);
        return false;
    }
}
#end_block

#method_before
public static PhysicalOptimizationConfig createPhysicalOptimizationConf(CompilerProperties compilerProperties, Map<String, Object> querySpecificConfig, SourceLocation sourceLoc) throws AlgebricksException {
    int frameSize = compilerProperties.getFrameSize();
    int sortFrameLimit = getSortNumFrames(compilerProperties, querySpecificConfig, sourceLoc);
    int groupFrameLimit = getFrameLimit(CompilerProperties.COMPILER_GROUPMEMORY_KEY, (String) querySpecificConfig.get(CompilerProperties.COMPILER_GROUPMEMORY_KEY), compilerProperties.getGroupMemorySize(), frameSize, MIN_FRAME_LIMIT_FOR_GROUP_BY, sourceLoc);
    int joinFrameLimit = getFrameLimit(CompilerProperties.COMPILER_JOINMEMORY_KEY, (String) querySpecificConfig.get(CompilerProperties.COMPILER_JOINMEMORY_KEY), compilerProperties.getJoinMemorySize(), frameSize, MIN_FRAME_LIMIT_FOR_JOIN, sourceLoc);
    int textSearchFrameLimit = getTextSearchNumFrames(compilerProperties, querySpecificConfig, sourceLoc);
    int sortNumSamples = getSortSamples(compilerProperties, querySpecificConfig);
    boolean fullParallelSort = getSortParallel(compilerProperties, querySpecificConfig);
    PhysicalOptimizationConfig physOptConf = new PhysicalOptimizationConfig();
    physOptConf.setFrameSize(frameSize);
    physOptConf.setMaxFramesExternalSort(sortFrameLimit);
    physOptConf.setMaxFramesExternalGroupBy(groupFrameLimit);
    physOptConf.setMaxFramesForJoin(joinFrameLimit);
    physOptConf.setMaxFramesForTextSearch(textSearchFrameLimit);
    physOptConf.setSortParallel(fullParallelSort);
    physOptConf.setSortSamples(sortNumSamples);
    return physOptConf;
}
#method_after
public static PhysicalOptimizationConfig createPhysicalOptimizationConf(CompilerProperties compilerProperties, Map<String, Object> querySpecificConfig, SourceLocation sourceLoc) throws AlgebricksException {
    int frameSize = compilerProperties.getFrameSize();
    int sortFrameLimit = getSortNumFrames(compilerProperties, querySpecificConfig, sourceLoc);
    int groupFrameLimit = getFrameLimit(CompilerProperties.COMPILER_GROUPMEMORY_KEY, (String) querySpecificConfig.get(CompilerProperties.COMPILER_GROUPMEMORY_KEY), compilerProperties.getGroupMemorySize(), frameSize, MIN_FRAME_LIMIT_FOR_GROUP_BY, sourceLoc);
    int joinFrameLimit = getFrameLimit(CompilerProperties.COMPILER_JOINMEMORY_KEY, (String) querySpecificConfig.get(CompilerProperties.COMPILER_JOINMEMORY_KEY), compilerProperties.getJoinMemorySize(), frameSize, MIN_FRAME_LIMIT_FOR_JOIN, sourceLoc);
    int textSearchFrameLimit = getTextSearchNumFrames(compilerProperties, querySpecificConfig, sourceLoc);
    int sortNumSamples = getSortSamples(compilerProperties, querySpecificConfig, sourceLoc);
    boolean fullParallelSort = getSortParallel(compilerProperties, querySpecificConfig);
    PhysicalOptimizationConfig physOptConf = new PhysicalOptimizationConfig();
    physOptConf.setFrameSize(frameSize);
    physOptConf.setMaxFramesExternalSort(sortFrameLimit);
    physOptConf.setMaxFramesExternalGroupBy(groupFrameLimit);
    physOptConf.setMaxFramesForJoin(joinFrameLimit);
    physOptConf.setMaxFramesForTextSearch(textSearchFrameLimit);
    physOptConf.setSortParallel(fullParallelSort);
    physOptConf.setSortSamples(sortNumSamples);
    return physOptConf;
}
#end_block

#method_before
private static int getFrameLimit(String parameterName, String parameter, long memBudgetInConfiguration, int frameSize, int minFrameLimit, SourceLocation sourceLoc) throws AlgebricksException {
    IOptionType<Long> longBytePropertyInterpreter = OptionTypes.LONG_BYTE_UNIT;
    long memBudget;
    try {
        memBudget = parameter == null ? memBudgetInConfiguration : longBytePropertyInterpreter.parse(parameter);
    } catch (IllegalArgumentException e) {
        throw AsterixException.create(ErrorCode.COMPILATION_ERROR, sourceLoc, e.getMessage());
    }
    int frameLimit = (int) (memBudget / frameSize);
    if (frameLimit < minFrameLimit) {
        throw AsterixException.create(ErrorCode.COMPILATION_BAD_QUERY_PARAMETER_VALUE, sourceLoc, parameterName, frameSize * minFrameLimit);
    }
    // sets the frame limit to the minimum frame limit if the calculated frame limit is too small.
    return Math.max(frameLimit, minFrameLimit);
}
#method_after
// Either log or rethrow this exception
@SuppressWarnings("squid:S1166")
private static int getFrameLimit(String parameterName, String parameter, long memBudgetInConfiguration, int frameSize, int minFrameLimit, SourceLocation sourceLoc) throws AlgebricksException {
    IOptionType<Long> longBytePropertyInterpreter = OptionTypes.LONG_BYTE_UNIT;
    long memBudget;
    try {
        memBudget = parameter == null ? memBudgetInConfiguration : longBytePropertyInterpreter.parse(parameter);
    } catch (IllegalArgumentException e) {
        throw AsterixException.create(ErrorCode.COMPILATION_ERROR, sourceLoc, e.getMessage());
    }
    int frameLimit = (int) (memBudget / frameSize);
    if (frameLimit < minFrameLimit) {
        throw AsterixException.create(ErrorCode.COMPILATION_BAD_QUERY_PARAMETER_VALUE, sourceLoc, parameterName, frameSize * minFrameLimit);
    }
    // sets the frame limit to the minimum frame limit if the calculated frame limit is too small.
    return Math.max(frameLimit, minFrameLimit);
}
#end_block

#method_before
private static int getSortSamples(CompilerProperties compilerProperties, Map<String, Object> querySpecificConfig) {
    String valueInQuery = (String) querySpecificConfig.get(CompilerProperties.COMPILER_SORT_SAMPLES_KEY);
    return valueInQuery == null ? compilerProperties.getSortSamples() : OptionTypes.POSITIVE_INTEGER.parse(valueInQuery);
}
#method_after
// Either log or rethrow this exception
@SuppressWarnings("squid:S1166")
private static int getSortSamples(CompilerProperties compilerProperties, Map<String, Object> querySpecificConfig, SourceLocation sourceLoc) throws AsterixException {
    String valueInQuery = (String) querySpecificConfig.get(CompilerProperties.COMPILER_SORT_SAMPLES_KEY);
    try {
        return valueInQuery == null ? compilerProperties.getSortSamples() : OptionTypes.POSITIVE_INTEGER.parse(valueInQuery);
    } catch (IllegalArgumentException e) {
        throw AsterixException.create(ErrorCode.COMPILATION_BAD_QUERY_PARAMETER_VALUE, sourceLoc, CompilerProperties.COMPILER_SORT_SAMPLES_KEY, 1);
    }
}
#end_block

#method_before
@Override
protected void finishNull() throws IOException {
    resultStorage.getDataOutput().writeByte(ATypeTag.SERIALIZED_NULL_TYPE_TAG);
}
#method_after
@Override
protected void finishNull(IPointable result) throws IOException {
    resultStorage.getDataOutput().writeByte(ATypeTag.SERIALIZED_NULL_TYPE_TAG);
    result.set(resultStorage);
}
#end_block

#method_before
@Override
protected void finishSystemNull() throws IOException {
    resultStorage.getDataOutput().writeByte(ATypeTag.SERIALIZED_NULL_TYPE_TAG);
}
#method_after
@Override
protected void finishSystemNull(IPointable result) throws IOException {
    resultStorage.getDataOutput().writeByte(ATypeTag.SERIALIZED_NULL_TYPE_TAG);
    result.set(resultStorage);
}
#end_block

#method_before
@Override
protected void processSystemNull() {
}
#method_after
@Override
protected void processSystemNull() {
// Do nothing
}
#end_block

#method_before
@Override
protected void finishNull() throws IOException {
    resultStorage.getDataOutput().writeByte(ATypeTag.SERIALIZED_NULL_TYPE_TAG);
}
#method_after
@Override
protected void finishNull(IPointable result) throws IOException {
    resultStorage.getDataOutput().writeByte(ATypeTag.SERIALIZED_NULL_TYPE_TAG);
    result.set(resultStorage);
}
#end_block

#method_before
@Override
protected void finishSystemNull() throws IOException {
    resultStorage.getDataOutput().writeByte(ATypeTag.SERIALIZED_NULL_TYPE_TAG);
}
#method_after
@Override
protected void finishSystemNull(IPointable result) throws IOException {
    resultStorage.getDataOutput().writeByte(ATypeTag.SERIALIZED_NULL_TYPE_TAG);
    result.set(resultStorage);
}
#end_block

#method_before
@Override
protected void finishNull() throws IOException {
    resultStorage.getDataOutput().writeByte(ATypeTag.SERIALIZED_NULL_TYPE_TAG);
}
#method_after
@Override
protected void finishNull(IPointable result) throws IOException {
    resultStorage.getDataOutput().writeByte(ATypeTag.SERIALIZED_NULL_TYPE_TAG);
    result.set(resultStorage);
}
#end_block

#method_before
@Override
protected void finishSystemNull() throws IOException {
    resultStorage.getDataOutput().writeByte(ATypeTag.SERIALIZED_NULL_TYPE_TAG);
}
#method_after
@Override
protected void finishSystemNull(IPointable result) throws IOException {
    resultStorage.getDataOutput().writeByte(ATypeTag.SERIALIZED_NULL_TYPE_TAG);
    result.set(resultStorage);
}
#end_block

#method_before
@Override
protected void finishNull() throws IOException {
    resultStorage.getDataOutput().writeByte(ATypeTag.SERIALIZED_NULL_TYPE_TAG);
}
#method_after
@Override
protected void finishNull(IPointable result) throws IOException {
    resultStorage.getDataOutput().writeByte(ATypeTag.SERIALIZED_NULL_TYPE_TAG);
    result.set(resultStorage);
}
#end_block

#method_before
@Override
protected void finishSystemNull() throws IOException {
    resultStorage.getDataOutput().writeByte(ATypeTag.SERIALIZED_SYSTEM_NULL_TYPE_TAG);
}
#method_after
@Override
protected void finishSystemNull(IPointable result) throws IOException {
    resultStorage.getDataOutput().writeByte(ATypeTag.SERIALIZED_SYSTEM_NULL_TYPE_TAG);
    result.set(resultStorage);
}
#end_block

#method_before
@Override
public void init() throws HyracksDataException {
    aggType = ATypeTag.SYSTEM_NULL;
    sum = 0.0;
}
#method_after
@Override
public void init() throws HyracksDataException {
    aggType = ATypeTag.SYSTEM_NULL;
    sumInt64 = 0;
    sumDouble = 0.0;
}
#end_block

#method_before
@Override
public void step(IFrameTupleReference tuple) throws HyracksDataException {
    // Skip current step
    if (isSkipStep()) {
        return;
    }
    // Evaluate/Get the data from the tuple
    eval.evaluate(tuple, inputVal);
    byte[] data = inputVal.getByteArray();
    int offset = inputVal.getStartOffset();
    // Get the data type tag
    ATypeTag typeTag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(data[offset]);
    // Handle MISSING and NULL values
    if (typeTag == ATypeTag.MISSING || typeTag == ATypeTag.NULL) {
        processNull();
        return;
    } else // Ensures type validity
    if (!isValidType(typeTag)) {
        throw new UnsupportedItemTypeException(sourceLoc, BuiltinFunctions.SUM, typeTag.serialize());
    } else // Non-missing and Non-null
    if (aggType == ATypeTag.SYSTEM_NULL) {
        aggType = typeTag;
    }
    // Calculate based on the incoming data type
    switch(typeTag) {
        case TINYINT:
            {
                byte val = AInt8SerializerDeserializer.getByte(data, offset + 1);
                sum += val;
                break;
            }
        case SMALLINT:
            {
                short val = AInt16SerializerDeserializer.getShort(data, offset + 1);
                sum += val;
                break;
            }
        case INTEGER:
            {
                int val = AInt32SerializerDeserializer.getInt(data, offset + 1);
                sum += val;
                break;
            }
        case BIGINT:
            {
                long val = AInt64SerializerDeserializer.getLong(data, offset + 1);
                sum += val;
                break;
            }
        case FLOAT:
            {
                float val = AFloatSerializerDeserializer.getFloat(data, offset + 1);
                sum += val;
                break;
            }
        case DOUBLE:
            {
                double val = ADoubleSerializerDeserializer.getDouble(data, offset + 1);
                sum += val;
                break;
            }
        case SYSTEM_NULL:
            {
                processSystemNull();
                break;
            }
        default:
            {
                throw new UnsupportedItemTypeException(sourceLoc, BuiltinFunctions.SUM, typeTag.serialize());
            }
    }
}
#method_after
@Override
public void step(IFrameTupleReference tuple) throws HyracksDataException {
    // Skip current step
    if (skipStep()) {
        return;
    }
    // Evaluate/Get the data from the tuple
    eval.evaluate(tuple, inputVal);
    byte[] data = inputVal.getByteArray();
    int offset = inputVal.getStartOffset();
    // Get the data type tag
    ATypeTag typeTag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(data[offset]);
    // Handle MISSING and NULL values
    if (typeTag == ATypeTag.MISSING || typeTag == ATypeTag.NULL) {
        processNull();
        return;
    } else // Non-missing and Non-null
    if (aggType == ATypeTag.SYSTEM_NULL) {
        aggType = typeTag;
    }
    // Calculate based on the incoming data type + handles invalid data type
    switch(typeTag) {
        case TINYINT:
            {
                byte val = AInt8SerializerDeserializer.getByte(data, offset + 1);
                processInt64Value(val);
                break;
            }
        case SMALLINT:
            {
                short val = AInt16SerializerDeserializer.getShort(data, offset + 1);
                processInt64Value(val);
                break;
            }
        case INTEGER:
            {
                int val = AInt32SerializerDeserializer.getInt(data, offset + 1);
                processInt64Value(val);
                break;
            }
        case BIGINT:
            {
                long val = AInt64SerializerDeserializer.getLong(data, offset + 1);
                processInt64Value(val);
                break;
            }
        case FLOAT:
            {
                upgradeOutputType();
                float val = AFloatSerializerDeserializer.getFloat(data, offset + 1);
                processFloatValue(val);
                break;
            }
        case DOUBLE:
            {
                upgradeOutputType();
                double val = ADoubleSerializerDeserializer.getDouble(data, offset + 1);
                processFloatValue(val);
                break;
            }
        case SYSTEM_NULL:
            {
                processSystemNull();
                break;
            }
        default:
            {
                throw new UnsupportedItemTypeException(sourceLoc, BuiltinFunctions.SUM, typeTag.serialize());
            }
    }
}
#end_block

#method_before
@SuppressWarnings("unchecked")
@Override
public void finishPartial(IPointable result) throws HyracksDataException {
    // Reset the result storage
    resultStorage.reset();
    try {
        // aggType is SYSTEM_NULL (ran over zero values)
        if (aggType == ATypeTag.SYSTEM_NULL) {
            if (GlobalConfig.DEBUG) {
                GlobalConfig.ASTERIX_LOGGER.trace("SUM aggregate ran over zero values.");
            }
            finishSystemNull();
            result.set(resultStorage);
        } else // aggType is NULL (Null value)
        if (aggType == ATypeTag.NULL) {
            finishNull();
            result.set(resultStorage);
        } else // Serialize the result to the data output
        {
            if (isUseInt64ForResult) {
                aInt64.setValue((long) sum);
                serde = SerializerDeserializerProvider.INSTANCE.getSerializerDeserializer(BuiltinType.AINT64);
                serde.serialize(aInt64, resultStorage.getDataOutput());
                result.set(resultStorage);
            } else {
                aDouble.setValue(sum);
                serde = SerializerDeserializerProvider.INSTANCE.getSerializerDeserializer(BuiltinType.ADOUBLE);
                serde.serialize(aDouble, resultStorage.getDataOutput());
                result.set(resultStorage);
            }
        }
    } catch (IOException ex) {
        throw HyracksDataException.create(ex);
    }
}
#method_after
@SuppressWarnings("unchecked")
@Override
public void finishPartial(IPointable result) throws HyracksDataException {
    // finishPartial() has identical behavior to finish()
    finishFinal(result);
}
#end_block

#method_before
@SuppressWarnings("unchecked")
@Override
public void finish(IPointable result) throws HyracksDataException {
    // Reset the result storage
    resultStorage.reset();
    try {
        // aggType is SYSTEM_NULL (ran over zero values)
        if (aggType == ATypeTag.SYSTEM_NULL) {
            if (GlobalConfig.DEBUG) {
                GlobalConfig.ASTERIX_LOGGER.trace("SUM aggregate ran over zero values.");
            }
            finishSystemNull();
            result.set(resultStorage);
        } else // aggType is NULL
        if (aggType == ATypeTag.NULL) {
            finishNull();
            result.set(resultStorage);
        } else // Pass the result
        {
            if (isUseInt64ForResult) {
                aInt64.setValue((long) sum);
                serde = SerializerDeserializerProvider.INSTANCE.getSerializerDeserializer(BuiltinType.AINT64);
                serde.serialize(aInt64, resultStorage.getDataOutput());
                result.set(resultStorage);
            } else {
                aDouble.setValue(sum);
                serde = SerializerDeserializerProvider.INSTANCE.getSerializerDeserializer(BuiltinType.ADOUBLE);
                serde.serialize(aDouble, resultStorage.getDataOutput());
                result.set(resultStorage);
            }
        }
    } catch (IOException ex) {
        throw HyracksDataException.create(ex);
    }
}
#method_after
@SuppressWarnings("unchecked")
@Override
public void finish(IPointable result) throws HyracksDataException {
    // Finish
    finishFinal(result);
}
#end_block

#method_before
@Override
public void init(DataOutput state) throws HyracksDataException {
    try {
        state.writeByte(ATypeTag.SERIALIZED_SYSTEM_NULL_TYPE_TAG);
        state.writeDouble(0.0);
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    }
}
#method_after
@Override
public void init(DataOutput state) throws HyracksDataException {
    try {
        state.writeByte(ATypeTag.SERIALIZED_SYSTEM_NULL_TYPE_TAG);
        state.writeLong(0);
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    }
}
#end_block

#method_before
@Override
public void step(IFrameTupleReference tuple, byte[] state, int start, int len) throws HyracksDataException {
    // Skip current step
    if (isSkipStep(state, start)) {
        return;
    }
    // Evaluate/Get the data from the tuple
    eval.evaluate(tuple, inputVal);
    byte[] bytes = inputVal.getByteArray();
    int offset = inputVal.getStartOffset();
    // Get the data type tag
    ATypeTag aggType = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(state[start + AGG_TYPE_OFFSET]);
    ATypeTag typeTag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(bytes[offset]);
    // Handle MISSING and NULL values
    if (typeTag == ATypeTag.MISSING || typeTag == ATypeTag.NULL) {
        processNull(state, start);
        return;
    } else // Ensures type validity
    if (!isValidType(typeTag)) {
        throw new UnsupportedItemTypeException(sourceLoc, BuiltinFunctions.SUM, bytes[offset]);
    } else // Non-missing and Non-null
    if (aggType == ATypeTag.SYSTEM_NULL) {
        aggType = typeTag;
    }
    // Current total
    double sum = BufferSerDeUtil.getDouble(state, start + SUM_OFFSET);
    // Calculate based on the incoming data type
    switch(typeTag) {
        case TINYINT:
            {
                byte val = AInt8SerializerDeserializer.getByte(bytes, offset + 1);
                sum += val;
                break;
            }
        case SMALLINT:
            {
                short val = AInt16SerializerDeserializer.getShort(bytes, offset + 1);
                sum += val;
                break;
            }
        case INTEGER:
            {
                int val = AInt32SerializerDeserializer.getInt(bytes, offset + 1);
                sum += val;
                break;
            }
        case BIGINT:
            {
                long val = AInt64SerializerDeserializer.getLong(bytes, offset + 1);
                sum += val;
                break;
            }
        case FLOAT:
            {
                float val = AFloatSerializerDeserializer.getFloat(bytes, offset + 1);
                sum += val;
                break;
            }
        case DOUBLE:
            {
                double val = ADoubleSerializerDeserializer.getDouble(bytes, offset + 1);
                sum += val;
                break;
            }
        case SYSTEM_NULL:
            processSystemNull();
            break;
        default:
            throw new UnsupportedItemTypeException(sourceLoc, BuiltinFunctions.SUM, bytes[offset]);
    }
    // Write the output
    if (aggType != ATypeTag.SYSTEM_NULL) {
        state[start + AGG_TYPE_OFFSET] = ATypeTag.SERIALIZED_DOUBLE_TYPE_TAG;
        BufferSerDeUtil.writeDouble(sum, state, start + SUM_OFFSET);
    }
}
#method_after
@Override
public void step(IFrameTupleReference tuple, byte[] state, int start, int len) throws HyracksDataException {
    // Skip current step
    if (skipStep(state, start)) {
        return;
    }
    // Evaluate/Get the data from the tuple
    eval.evaluate(tuple, inputVal);
    byte[] bytes = inputVal.getByteArray();
    int offset = inputVal.getStartOffset();
    // Get the data type tag
    ATypeTag typeTag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(bytes[offset]);
    // Handle MISSING and NULL values
    if (typeTag == ATypeTag.MISSING || typeTag == ATypeTag.NULL) {
        processNull(state, start);
        return;
    }
    // Calculate based on the incoming data type + handles invalid data type
    switch(typeTag) {
        case TINYINT:
            {
                byte val = AInt8SerializerDeserializer.getByte(bytes, offset + 1);
                processInt64Value(state, start, val);
                break;
            }
        case SMALLINT:
            {
                short val = AInt16SerializerDeserializer.getShort(bytes, offset + 1);
                processInt64Value(state, start, val);
                break;
            }
        case INTEGER:
            {
                int val = AInt32SerializerDeserializer.getInt(bytes, offset + 1);
                processInt64Value(state, start, val);
                break;
            }
        case BIGINT:
            {
                long val = AInt64SerializerDeserializer.getLong(bytes, offset + 1);
                processInt64Value(state, start, val);
                break;
            }
        case FLOAT:
            {
                upgradeOutputType();
                float val = AFloatSerializerDeserializer.getFloat(bytes, offset + 1);
                processFloatValue(state, start, val);
                break;
            }
        case DOUBLE:
            {
                upgradeOutputType();
                double val = ADoubleSerializerDeserializer.getDouble(bytes, offset + 1);
                processFloatValue(state, start, val);
                break;
            }
        case SYSTEM_NULL:
            processSystemNull();
            break;
        default:
            throw new UnsupportedItemTypeException(sourceLoc, BuiltinFunctions.SUM, bytes[offset]);
    }
}
#end_block

#method_before
@SuppressWarnings("unchecked")
@Override
public void finishPartial(byte[] state, int start, int len, DataOutput out) throws HyracksDataException {
    // Type and value
    ATypeTag aggType = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(state[start + AGG_TYPE_OFFSET]);
    double sum = BufferSerDeUtil.getDouble(state, start + SUM_OFFSET);
    try {
        // aggType is SYSTEM_NULL (ran over zero values)
        if (aggType == ATypeTag.SYSTEM_NULL) {
            if (GlobalConfig.DEBUG) {
                GlobalConfig.ASTERIX_LOGGER.trace("SUM aggregate ran over zero values.");
            }
            finishSystemNull(out);
        } else // aggType is NULL
        if (aggType == ATypeTag.NULL) {
            finishNull(out);
        } else // Pass the result
        {
            if (isUseInt64ForResult) {
                serde = SerializerDeserializerProvider.INSTANCE.getSerializerDeserializer(BuiltinType.AINT64);
                aInt64.setValue((long) sum);
                serde.serialize(aInt64, out);
            } else {
                serde = SerializerDeserializerProvider.INSTANCE.getSerializerDeserializer(BuiltinType.ADOUBLE);
                aDouble.setValue(sum);
                serde.serialize(aDouble, out);
            }
        }
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    }
}
#method_after
@SuppressWarnings("unchecked")
@Override
public void finishPartial(byte[] state, int start, int len, DataOutput out) throws HyracksDataException {
    // finishPartial() has identical behavior to finish()
    finishFinal(state, start, len, out);
}
#end_block

#method_before
@SuppressWarnings("unchecked")
@Override
public void finish(byte[] state, int start, int len, DataOutput out) throws HyracksDataException {
    // Type and value
    ATypeTag aggType = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(state[start + AGG_TYPE_OFFSET]);
    double sum = BufferSerDeUtil.getDouble(state, start + SUM_OFFSET);
    try {
        // aggType is SYSTEM_NULL (ran over zero values)
        if (aggType == ATypeTag.SYSTEM_NULL) {
            if (GlobalConfig.DEBUG) {
                GlobalConfig.ASTERIX_LOGGER.trace("SUM aggregate ran over zero values.");
            }
            finishSystemNull(out);
        } else // aggType is NULL
        if (aggType == ATypeTag.NULL) {
            finishNull(out);
        } else // Pass the result
        {
            if (isUseInt64ForResult) {
                aInt64.setValue((long) sum);
                serde = SerializerDeserializerProvider.INSTANCE.getSerializerDeserializer(BuiltinType.AINT64);
                serde.serialize(aInt64, out);
            } else {
                aDouble.setValue(sum);
                serde = SerializerDeserializerProvider.INSTANCE.getSerializerDeserializer(BuiltinType.ADOUBLE);
                serde.serialize(aDouble, out);
            }
        }
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    }
}
#method_after
@SuppressWarnings("unchecked")
@Override
public void finish(byte[] state, int start, int len, DataOutput out) throws HyracksDataException {
    // Finish
    finishFinal(state, start, len, out);
}
#end_block

#method_before
@Override
protected void finishNull() throws IOException {
    resultStorage.getDataOutput().writeByte(ATypeTag.SERIALIZED_NULL_TYPE_TAG);
}
#method_after
@Override
protected void finishNull(IPointable result) throws IOException {
    resultStorage.getDataOutput().writeByte(ATypeTag.SERIALIZED_NULL_TYPE_TAG);
    result.set(resultStorage);
}
#end_block

#method_before
@Override
protected void finishSystemNull() throws IOException {
    resultStorage.getDataOutput().writeByte(ATypeTag.SERIALIZED_NULL_TYPE_TAG);
}
#method_after
@Override
protected void finishSystemNull(IPointable result) throws IOException {
    resultStorage.getDataOutput().writeByte(ATypeTag.SERIALIZED_NULL_TYPE_TAG);
    result.set(resultStorage);
}
#end_block

#method_before
@Override
protected void finishNull() throws IOException {
    resultStorage.getDataOutput().writeByte(ATypeTag.SERIALIZED_NULL_TYPE_TAG);
}
#method_after
@Override
protected void finishNull(IPointable result) throws IOException {
    resultStorage.getDataOutput().writeByte(ATypeTag.SERIALIZED_NULL_TYPE_TAG);
    result.set(resultStorage);
}
#end_block

#method_before
@Override
protected void finishSystemNull() throws IOException {
    resultStorage.getDataOutput().writeByte(ATypeTag.SERIALIZED_SYSTEM_NULL_TYPE_TAG);
}
#method_after
@Override
protected void finishSystemNull(IPointable result) throws IOException {
    resultStorage.getDataOutput().writeByte(ATypeTag.SERIALIZED_SYSTEM_NULL_TYPE_TAG);
    result.set(resultStorage);
}
#end_block

#method_before
public static FunctionCollection createDefaultFunctionCollection() {
    FunctionCollection fc = new FunctionCollection();
    // array functions
    fc.add(ArrayRemoveDescriptor.FACTORY);
    fc.add(ArrayPutDescriptor.FACTORY);
    fc.add(ArrayPrependDescriptor.FACTORY);
    fc.add(ArrayAppendDescriptor.FACTORY);
    fc.add(ArrayInsertDescriptor.FACTORY);
    fc.addGenerated(ArrayPositionDescriptor.FACTORY);
    fc.addGenerated(ArrayRepeatDescriptor.FACTORY);
    fc.addGenerated(ArrayContainsDescriptor.FACTORY);
    fc.addGenerated(ArrayReverseDescriptor.FACTORY);
    fc.addGenerated(ArraySortDescriptor.FACTORY);
    fc.addGenerated(ArrayDistinctDescriptor.FACTORY);
    fc.addGenerated(ArrayUnionDescriptor.FACTORY);
    fc.addGenerated(ArrayIntersectDescriptor.FACTORY);
    fc.addGenerated(ArrayIfNullDescriptor.FACTORY);
    fc.addGenerated(ArrayConcatDescriptor.FACTORY);
    fc.addGenerated(ArrayRangeDescriptor.FACTORY);
    fc.addGenerated(ArrayFlattenDescriptor.FACTORY);
    fc.add(ArrayReplaceDescriptor.FACTORY);
    fc.addGenerated(ArraySymDiffDescriptor.FACTORY);
    fc.addGenerated(ArraySymDiffnDescriptor.FACTORY);
    fc.addGenerated(ArrayStarDescriptor.FACTORY);
    // unnesting functions
    fc.add(TidRunningAggregateDescriptor.FACTORY);
    fc.add(ScanCollectionDescriptor.FACTORY);
    fc.add(RangeDescriptor.FACTORY);
    fc.add(SubsetCollectionDescriptor.FACTORY);
    // aggregate functions
    fc.add(ListifyAggregateDescriptor.FACTORY);
    fc.add(CountAggregateDescriptor.FACTORY);
    fc.add(AvgAggregateDescriptor.FACTORY);
    fc.add(LocalAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SumAggregateDescriptor.FACTORY);
    fc.add(LocalSumAggregateDescriptor.FACTORY);
    fc.add(IntermediateSumAggregateDescriptor.FACTORY);
    fc.add(GlobalSumAggregateDescriptor.FACTORY);
    fc.add(MaxAggregateDescriptor.FACTORY);
    fc.add(LocalMaxAggregateDescriptor.FACTORY);
    fc.add(MinAggregateDescriptor.FACTORY);
    fc.add(LocalMinAggregateDescriptor.FACTORY);
    fc.add(FirstElementAggregateDescriptor.FACTORY);
    fc.add(LocalFirstElementAggregateDescriptor.FACTORY);
    fc.add(StddevAggregateDescriptor.FACTORY);
    fc.add(LocalStddevAggregateDescriptor.FACTORY);
    fc.add(IntermediateStddevAggregateDescriptor.FACTORY);
    fc.add(GlobalStddevAggregateDescriptor.FACTORY);
    fc.add(LocalSamplingAggregateDescriptor.FACTORY);
    fc.add(RangeMapAggregateDescriptor.FACTORY);
    fc.add(StddevPopAggregateDescriptor.FACTORY);
    fc.add(LocalStddevPopAggregateDescriptor.FACTORY);
    fc.add(IntermediateStddevPopAggregateDescriptor.FACTORY);
    fc.add(GlobalStddevPopAggregateDescriptor.FACTORY);
    fc.add(VarAggregateDescriptor.FACTORY);
    fc.add(LocalVarAggregateDescriptor.FACTORY);
    fc.add(IntermediateVarAggregateDescriptor.FACTORY);
    fc.add(GlobalVarAggregateDescriptor.FACTORY);
    fc.add(VarPopAggregateDescriptor.FACTORY);
    fc.add(LocalVarPopAggregateDescriptor.FACTORY);
    fc.add(IntermediateVarPopAggregateDescriptor.FACTORY);
    fc.add(GlobalVarPopAggregateDescriptor.FACTORY);
    // serializable aggregates
    fc.add(SerializableCountAggregateDescriptor.FACTORY);
    fc.add(SerializableAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSumAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSumAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSumAggregateDescriptor.FACTORY);
    fc.add(SerializableStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableVarAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalVarAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateVarAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalVarAggregateDescriptor.FACTORY);
    fc.add(SerializableVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalVarPopAggregateDescriptor.FACTORY);
    // scalar aggregates
    fc.add(ScalarCountAggregateDescriptor.FACTORY);
    fc.add(ScalarAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSumAggregateDescriptor.FACTORY);
    fc.add(ScalarMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarMinAggregateDescriptor.FACTORY);
    fc.add(EmptyStreamAggregateDescriptor.FACTORY);
    fc.add(NonEmptyStreamAggregateDescriptor.FACTORY);
    fc.add(ScalarStddevAggregateDescriptor.FACTORY);
    fc.add(ScalarStddevPopAggregateDescriptor.FACTORY);
    fc.add(ScalarVarAggregateDescriptor.FACTORY);
    fc.add(ScalarVarPopAggregateDescriptor.FACTORY);
    // SQL aggregates
    fc.add(SqlCountAggregateDescriptor.FACTORY);
    fc.add(SqlAvgAggregateDescriptor.FACTORY);
    fc.add(LocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SqlSumAggregateDescriptor.FACTORY);
    fc.add(LocalSqlSumAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlSumAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SqlMaxAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMaxAggregateDescriptor.FACTORY);
    fc.add(SqlMinAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMinAggregateDescriptor.FACTORY);
    fc.add(SqlStddevAggregateDescriptor.FACTORY);
    fc.add(LocalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlStddevAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(LocalSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SqlVarAggregateDescriptor.FACTORY);
    fc.add(LocalSqlVarAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlVarAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlVarAggregateDescriptor.FACTORY);
    fc.add(SqlVarPopAggregateDescriptor.FACTORY);
    fc.add(LocalSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlVarPopAggregateDescriptor.FACTORY);
    // SQL serializable aggregates
    fc.add(SerializableSqlCountAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlVarAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlVarAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlVarAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlVarAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlVarPopAggregateDescriptor.FACTORY);
    // SQL scalar aggregates
    fc.add(ScalarSqlCountAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlSumAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMinAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlStddevAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlVarAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlVarPopAggregateDescriptor.FACTORY);
    // boolean functions
    fc.add(AndDescriptor.FACTORY);
    fc.add(OrDescriptor.FACTORY);
    // Record constructors / functions
    fc.add(ClosedRecordConstructorDescriptor.FACTORY);
    fc.add(OpenRecordConstructorDescriptor.FACTORY);
    fc.add(RecordConcatDescriptor.FACTORY);
    fc.add(RecordConcatStrictDescriptor.FACTORY);
    // List constructors
    fc.add(OrderedListConstructorDescriptor.FACTORY);
    fc.add(UnorderedListConstructorDescriptor.FACTORY);
    // Sleep function
    fc.add(SleepDescriptor.FACTORY);
    // Inject failure function
    fc.add(InjectFailureDescriptor.FACTORY);
    // Get Job Parameter function
    fc.add(GetJobParameterByNameDescriptor.FACTORY);
    // Switch case
    fc.add(SwitchCaseDescriptor.FACTORY);
    // null functions
    fc.add(IsMissingDescriptor.FACTORY);
    fc.add(IsNullDescriptor.FACTORY);
    fc.add(IsUnknownDescriptor.FACTORY);
    fc.add(IsSystemNullDescriptor.FACTORY);
    fc.add(CheckUnknownDescriptor.FACTORY);
    fc.add(IfMissingDescriptor.FACTORY);
    fc.add(IfNullDescriptor.FACTORY);
    fc.add(IfMissingOrNullDescriptor.FACTORY);
    // uuid generators (zero independent functions)
    fc.add(CreateUUIDDescriptor.FACTORY);
    fc.add(UUIDDescriptor.FACTORY);
    fc.add(CreateQueryUIDDescriptor.FACTORY);
    fc.add(RandomDescriptor.FACTORY);
    fc.add(CurrentDateDescriptor.FACTORY);
    fc.add(CurrentTimeDescriptor.FACTORY);
    fc.add(CurrentDateTimeDescriptor.FACTORY);
    // functions that need generated class for null-handling.
    // Element accessors.
    fc.addGenerated(FieldAccessByIndexDescriptor.FACTORY);
    fc.addGenerated(FieldAccessByNameDescriptor.FACTORY);
    fc.addGenerated(FieldAccessNestedDescriptor.FACTORY);
    fc.addGenerated(AnyCollectionMemberDescriptor.FACTORY);
    fc.addGenerated(GetItemDescriptor.FACTORY);
    // Numeric functions
    fc.add(IfInfDescriptor.FACTORY);
    fc.add(IfNanDescriptor.FACTORY);
    fc.add(IfNanOrInfDescriptor.FACTORY);
    fc.addGenerated(NumericUnaryMinusDescriptor.FACTORY);
    fc.addGenerated(NumericAddDescriptor.FACTORY);
    fc.addGenerated(NumericDivideDescriptor.FACTORY);
    fc.addGenerated(NumericDivDescriptor.FACTORY);
    fc.addGenerated(NumericMultiplyDescriptor.FACTORY);
    fc.addGenerated(NumericSubDescriptor.FACTORY);
    fc.addGenerated(NumericModuloDescriptor.FACTORY);
    fc.addGenerated(NumericPowerDescriptor.FACTORY);
    fc.addGenerated(NotDescriptor.FACTORY);
    fc.addGenerated(LenDescriptor.FACTORY);
    fc.addGenerated(NumericAbsDescriptor.FACTORY);
    fc.addGenerated(NumericCeilingDescriptor.FACTORY);
    fc.addGenerated(NumericFloorDescriptor.FACTORY);
    fc.addGenerated(NumericRoundDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEvenDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEven2Descriptor.FACTORY);
    fc.addGenerated(NumericACosDescriptor.FACTORY);
    fc.addGenerated(NumericASinDescriptor.FACTORY);
    fc.addGenerated(NumericATanDescriptor.FACTORY);
    fc.addGenerated(NumericDegreesDescriptor.FACTORY);
    fc.addGenerated(NumericRadiansDescriptor.FACTORY);
    fc.addGenerated(NumericCosDescriptor.FACTORY);
    fc.addGenerated(NumericSinDescriptor.FACTORY);
    fc.addGenerated(NumericTanDescriptor.FACTORY);
    fc.addGenerated(NumericExpDescriptor.FACTORY);
    fc.addGenerated(NumericLnDescriptor.FACTORY);
    fc.addGenerated(NumericLogDescriptor.FACTORY);
    fc.addGenerated(NumericSqrtDescriptor.FACTORY);
    fc.addGenerated(NumericSignDescriptor.FACTORY);
    fc.addGenerated(NumericTruncDescriptor.FACTORY);
    fc.addGenerated(NumericATan2Descriptor.FACTORY);
    // Comparisons.
    fc.addGenerated(EqualsDescriptor.FACTORY);
    fc.addGenerated(GreaterThanDescriptor.FACTORY);
    fc.addGenerated(GreaterThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(LessThanDescriptor.FACTORY);
    fc.addGenerated(LessThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(NotEqualsDescriptor.FACTORY);
    // If-Equals functions
    fc.addGenerated(MissingIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NullIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NanIfEqualsDescriptor.FACTORY);
    fc.addGenerated(PosInfIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NegInfIfEqualsDescriptor.FACTORY);
    // Binary functions
    fc.addGenerated(BinaryLengthDescriptor.FACTORY);
    fc.addGenerated(ParseBinaryDescriptor.FACTORY);
    fc.addGenerated(PrintBinaryDescriptor.FACTORY);
    fc.addGenerated(BinaryConcatDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromToDescriptor.FACTORY);
    fc.addGenerated(FindBinaryDescriptor.FACTORY);
    fc.addGenerated(FindBinaryFromDescriptor.FACTORY);
    // String functions
    fc.addGenerated(StringLikeDescriptor.FACTORY);
    fc.addGenerated(StringContainsDescriptor.FACTORY);
    fc.addGenerated(StringEndsWithDescriptor.FACTORY);
    fc.addGenerated(StringStartsWithDescriptor.FACTORY);
    fc.addGenerated(SubstringDescriptor.FACTORY);
    fc.addGenerated(StringEqualDescriptor.FACTORY);
    fc.addGenerated(StringLowerCaseDescriptor.FACTORY);
    fc.addGenerated(StringUpperCaseDescriptor.FACTORY);
    fc.addGenerated(StringLengthDescriptor.FACTORY);
    fc.addGenerated(Substring2Descriptor.FACTORY);
    fc.addGenerated(SubstringBeforeDescriptor.FACTORY);
    fc.addGenerated(SubstringAfterDescriptor.FACTORY);
    fc.addGenerated(StringToCodePointDescriptor.FACTORY);
    fc.addGenerated(CodePointToStringDescriptor.FACTORY);
    fc.addGenerated(StringConcatDescriptor.FACTORY);
    fc.addGenerated(StringJoinDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringInitCapDescriptor.FACTORY);
    fc.addGenerated(StringTrimDescriptor.FACTORY);
    fc.addGenerated(StringLTrimDescriptor.FACTORY);
    fc.addGenerated(StringRTrimDescriptor.FACTORY);
    fc.addGenerated(StringTrim2Descriptor.FACTORY);
    fc.addGenerated(StringLTrim2Descriptor.FACTORY);
    fc.addGenerated(StringRTrim2Descriptor.FACTORY);
    fc.addGenerated(StringPositionDescriptor.FACTORY);
    fc.addGenerated(StringRepeatDescriptor.FACTORY);
    fc.addGenerated(StringReplaceDescriptor.FACTORY);
    fc.addGenerated(StringReplaceWithLimitDescriptor.FACTORY);
    fc.addGenerated(StringReverseDescriptor.FACTORY);
    fc.addGenerated(StringSplitDescriptor.FACTORY);
    // Constructors
    fc.addGenerated(ABooleanConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryHexStringConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryBase64StringConstructorDescriptor.FACTORY);
    fc.addGenerated(AStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt8ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt16ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt32ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt64ConstructorDescriptor.FACTORY);
    fc.addGenerated(AFloatConstructorDescriptor.FACTORY);
    fc.addGenerated(ADoubleConstructorDescriptor.FACTORY);
    fc.addGenerated(APointConstructorDescriptor.FACTORY);
    fc.addGenerated(APoint3DConstructorDescriptor.FACTORY);
    fc.addGenerated(ALineConstructorDescriptor.FACTORY);
    fc.addGenerated(APolygonConstructorDescriptor.FACTORY);
    fc.addGenerated(ACircleConstructorDescriptor.FACTORY);
    fc.addGenerated(ARectangleConstructorDescriptor.FACTORY);
    fc.addGenerated(ATimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AYearMonthDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(ADayTimeDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AUUIDFromStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromTimeConstructorDescriptor.FACTORY);
    // Spatial
    fc.addGenerated(CreatePointDescriptor.FACTORY);
    fc.addGenerated(CreateLineDescriptor.FACTORY);
    fc.addGenerated(CreatePolygonDescriptor.FACTORY);
    fc.addGenerated(CreateCircleDescriptor.FACTORY);
    fc.addGenerated(CreateRectangleDescriptor.FACTORY);
    fc.addGenerated(SpatialAreaDescriptor.FACTORY);
    fc.addGenerated(SpatialDistanceDescriptor.FACTORY);
    fc.addGenerated(CreateMBRDescriptor.FACTORY);
    fc.addGenerated(SpatialCellDescriptor.FACTORY);
    fc.addGenerated(PointXCoordinateAccessor.FACTORY);
    fc.addGenerated(PointYCoordinateAccessor.FACTORY);
    fc.addGenerated(CircleRadiusAccessor.FACTORY);
    fc.addGenerated(CircleCenterAccessor.FACTORY);
    fc.addGenerated(LineRectanglePolygonAccessor.FACTORY);
    // full-text function
    fc.addGenerated(FullTextContainsDescriptor.FACTORY);
    fc.addGenerated(FullTextContainsWithoutOptionDescriptor.FACTORY);
    // Record functions.
    fc.addGenerated(GetRecordFieldsDescriptor.FACTORY);
    fc.addGenerated(GetRecordFieldValueDescriptor.FACTORY);
    fc.addGenerated(DeepEqualityDescriptor.FACTORY);
    fc.addGenerated(RecordMergeDescriptor.FACTORY);
    fc.addGenerated(RecordAddFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordLengthDescriptor.FACTORY);
    fc.addGenerated(RecordNamesDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveDescriptor.FACTORY);
    fc.addGenerated(RecordRenameDescriptor.FACTORY);
    fc.addGenerated(RecordUnwrapDescriptor.FACTORY);
    fc.add(RecordReplaceDescriptor.FACTORY);
    fc.add(RecordAddDescriptor.FACTORY);
    fc.add(RecordPutDescriptor.FACTORY);
    fc.addGenerated(RecordValuesDescriptor.FACTORY);
    fc.addGenerated(PairsDescriptor.FACTORY);
    // Spatial and temporal type accessors
    fc.addGenerated(TemporalYearAccessor.FACTORY);
    fc.addGenerated(TemporalMonthAccessor.FACTORY);
    fc.addGenerated(TemporalDayAccessor.FACTORY);
    fc.addGenerated(TemporalHourAccessor.FACTORY);
    fc.addGenerated(TemporalMinuteAccessor.FACTORY);
    fc.addGenerated(TemporalSecondAccessor.FACTORY);
    fc.addGenerated(TemporalMillisecondAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDatetimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDatetimeAccessor.FACTORY);
    // Temporal functions
    fc.addGenerated(UnixTimeFromDateInDaysDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromTimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DateFromUnixTimeInDaysDescriptor.FACTORY);
    fc.addGenerated(DateFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(TimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(TimeFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromDateAndTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDurationFromDateTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDuartionFromDateDescriptor.FACTORY);
    fc.addGenerated(AdjustDateTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(AdjustTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(IntervalBeforeDescriptor.FACTORY);
    fc.addGenerated(IntervalAfterDescriptor.FACTORY);
    fc.addGenerated(IntervalMeetsDescriptor.FACTORY);
    fc.addGenerated(IntervalMetByDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlapsDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlappedByDescriptor.FACTORY);
    fc.addGenerated(OverlapDescriptor.FACTORY);
    fc.addGenerated(IntervalStartsDescriptor.FACTORY);
    fc.addGenerated(IntervalStartedByDescriptor.FACTORY);
    fc.addGenerated(IntervalCoversDescriptor.FACTORY);
    fc.addGenerated(IntervalCoveredByDescriptor.FACTORY);
    fc.addGenerated(IntervalEndsDescriptor.FACTORY);
    fc.addGenerated(IntervalEndedByDescriptor.FACTORY);
    fc.addGenerated(DurationFromMillisecondsDescriptor.FACTORY);
    fc.addGenerated(DurationFromMonthsDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(MonthsFromYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(MillisecondsFromDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(DurationEqualDescriptor.FACTORY);
    fc.addGenerated(GetYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(GetDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(IntervalBinDescriptor.FACTORY);
    fc.addGenerated(OverlapBinsDescriptor.FACTORY);
    fc.addGenerated(DayOfWeekDescriptor.FACTORY);
    fc.addGenerated(ParseDateDescriptor.FACTORY);
    fc.addGenerated(ParseTimeDescriptor.FACTORY);
    fc.addGenerated(ParseDateTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateDescriptor.FACTORY);
    fc.addGenerated(PrintTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateTimeDescriptor.FACTORY);
    fc.addGenerated(GetOverlappingIntervalDescriptor.FACTORY);
    fc.addGenerated(DurationFromIntervalDescriptor.FACTORY);
    // Type functions.
    fc.addGenerated(IsArrayDescriptor.FACTORY);
    fc.addGenerated(IsAtomicDescriptor.FACTORY);
    fc.addGenerated(IsBooleanDescriptor.FACTORY);
    fc.addGenerated(IsNumberDescriptor.FACTORY);
    fc.addGenerated(IsObjectDescriptor.FACTORY);
    fc.addGenerated(IsStringDescriptor.FACTORY);
    fc.addGenerated(ToArrayDescriptor.FACTORY);
    fc.addGenerated(ToAtomicDescriptor.FACTORY);
    fc.addGenerated(ToBigIntDescriptor.FACTORY);
    fc.addGenerated(ToBooleanDescriptor.FACTORY);
    fc.addGenerated(ToDoubleDescriptor.FACTORY);
    fc.addGenerated(ToNumberDescriptor.FACTORY);
    fc.addGenerated(ToObjectDescriptor.FACTORY);
    fc.addGenerated(ToStringDescriptor.FACTORY);
    fc.addGenerated(TreatAsIntegerDescriptor.FACTORY);
    // Cast function
    fc.addGenerated(CastTypeDescriptor.FACTORY);
    fc.addGenerated(CastTypeLaxDescriptor.FACTORY);
    // Record function
    fc.addGenerated(RecordPairsDescriptor.FACTORY);
    // Other functions
    fc.addGenerated(RandomWithSeedDescriptor.FACTORY);
    ServiceLoader.load(IFunctionRegistrant.class).iterator().forEachRemaining(c -> c.register(fc));
    return fc;
}
#method_after
public static FunctionCollection createDefaultFunctionCollection() {
    FunctionCollection fc = new FunctionCollection();
    // array functions
    fc.add(ArrayRemoveDescriptor.FACTORY);
    fc.add(ArrayPutDescriptor.FACTORY);
    fc.add(ArrayPrependDescriptor.FACTORY);
    fc.add(ArrayAppendDescriptor.FACTORY);
    fc.add(ArrayInsertDescriptor.FACTORY);
    fc.addGenerated(ArrayPositionDescriptor.FACTORY);
    fc.addGenerated(ArrayRepeatDescriptor.FACTORY);
    fc.addGenerated(ArrayContainsDescriptor.FACTORY);
    fc.addGenerated(ArrayReverseDescriptor.FACTORY);
    fc.addGenerated(ArraySortDescriptor.FACTORY);
    fc.addGenerated(ArrayDistinctDescriptor.FACTORY);
    fc.addGenerated(ArrayUnionDescriptor.FACTORY);
    fc.addGenerated(ArrayIntersectDescriptor.FACTORY);
    fc.addGenerated(ArrayIfNullDescriptor.FACTORY);
    fc.addGenerated(ArrayConcatDescriptor.FACTORY);
    fc.addGenerated(ArrayRangeDescriptor.FACTORY);
    fc.addGenerated(ArrayFlattenDescriptor.FACTORY);
    fc.add(ArrayReplaceDescriptor.FACTORY);
    fc.addGenerated(ArraySymDiffDescriptor.FACTORY);
    fc.addGenerated(ArraySymDiffnDescriptor.FACTORY);
    fc.addGenerated(ArrayStarDescriptor.FACTORY);
    // unnesting functions
    fc.add(TidRunningAggregateDescriptor.FACTORY);
    fc.add(ScanCollectionDescriptor.FACTORY);
    fc.add(RangeDescriptor.FACTORY);
    fc.add(SubsetCollectionDescriptor.FACTORY);
    // aggregate functions
    fc.add(ListifyAggregateDescriptor.FACTORY);
    fc.add(CountAggregateDescriptor.FACTORY);
    fc.add(AvgAggregateDescriptor.FACTORY);
    fc.add(LocalAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SumAggregateDescriptor.FACTORY);
    fc.add(LocalSumAggregateDescriptor.FACTORY);
    fc.add(IntermediateSumAggregateDescriptor.FACTORY);
    fc.add(GlobalSumAggregateDescriptor.FACTORY);
    fc.add(MaxAggregateDescriptor.FACTORY);
    fc.add(LocalMaxAggregateDescriptor.FACTORY);
    fc.add(MinAggregateDescriptor.FACTORY);
    fc.add(LocalMinAggregateDescriptor.FACTORY);
    fc.add(FirstElementAggregateDescriptor.FACTORY);
    fc.add(LocalFirstElementAggregateDescriptor.FACTORY);
    fc.add(StddevAggregateDescriptor.FACTORY);
    fc.add(LocalStddevAggregateDescriptor.FACTORY);
    fc.add(IntermediateStddevAggregateDescriptor.FACTORY);
    fc.add(GlobalStddevAggregateDescriptor.FACTORY);
    fc.add(LocalSamplingAggregateDescriptor.FACTORY);
    fc.add(RangeMapAggregateDescriptor.FACTORY);
    fc.add(StddevPopAggregateDescriptor.FACTORY);
    fc.add(LocalStddevPopAggregateDescriptor.FACTORY);
    fc.add(IntermediateStddevPopAggregateDescriptor.FACTORY);
    fc.add(GlobalStddevPopAggregateDescriptor.FACTORY);
    fc.add(VarAggregateDescriptor.FACTORY);
    fc.add(LocalVarAggregateDescriptor.FACTORY);
    fc.add(IntermediateVarAggregateDescriptor.FACTORY);
    fc.add(GlobalVarAggregateDescriptor.FACTORY);
    fc.add(VarPopAggregateDescriptor.FACTORY);
    fc.add(LocalVarPopAggregateDescriptor.FACTORY);
    fc.add(IntermediateVarPopAggregateDescriptor.FACTORY);
    fc.add(GlobalVarPopAggregateDescriptor.FACTORY);
    // serializable aggregates
    fc.add(SerializableCountAggregateDescriptor.FACTORY);
    fc.add(SerializableAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSumAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSumAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSumAggregateDescriptor.FACTORY);
    fc.add(SerializableStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableVarAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalVarAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateVarAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalVarAggregateDescriptor.FACTORY);
    fc.add(SerializableVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalVarPopAggregateDescriptor.FACTORY);
    // scalar aggregates
    fc.add(ScalarCountAggregateDescriptor.FACTORY);
    fc.add(ScalarAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSumAggregateDescriptor.FACTORY);
    fc.add(ScalarMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarMinAggregateDescriptor.FACTORY);
    fc.add(EmptyStreamAggregateDescriptor.FACTORY);
    fc.add(NonEmptyStreamAggregateDescriptor.FACTORY);
    fc.add(ScalarStddevAggregateDescriptor.FACTORY);
    fc.add(ScalarStddevPopAggregateDescriptor.FACTORY);
    fc.add(ScalarVarAggregateDescriptor.FACTORY);
    fc.add(ScalarVarPopAggregateDescriptor.FACTORY);
    // SQL aggregates
    fc.add(SqlCountAggregateDescriptor.FACTORY);
    fc.add(SqlAvgAggregateDescriptor.FACTORY);
    fc.add(LocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SqlSumAggregateDescriptor.FACTORY);
    fc.add(LocalSqlSumAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlSumAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SqlMaxAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMaxAggregateDescriptor.FACTORY);
    fc.add(SqlMinAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMinAggregateDescriptor.FACTORY);
    fc.add(SqlStddevAggregateDescriptor.FACTORY);
    fc.add(LocalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlStddevAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(LocalSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SqlVarAggregateDescriptor.FACTORY);
    fc.add(LocalSqlVarAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlVarAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlVarAggregateDescriptor.FACTORY);
    fc.add(SqlVarPopAggregateDescriptor.FACTORY);
    fc.add(LocalSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlVarPopAggregateDescriptor.FACTORY);
    // SQL serializable aggregates
    fc.add(SerializableSqlCountAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlVarAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlVarAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlVarAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlVarAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlVarPopAggregateDescriptor.FACTORY);
    // SQL scalar aggregates
    fc.add(ScalarSqlCountAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlSumAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMinAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlStddevAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlVarAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlVarPopAggregateDescriptor.FACTORY);
    // window functions
    fc.add(RowNumberRunningAggregateDescriptor.FACTORY);
    fc.add(RankRunningAggregateDescriptor.FACTORY);
    fc.add(DenseRankRunningAggregateDescriptor.FACTORY);
    fc.add(PercentRankRunningAggregateDescriptor.FACTORY);
    fc.add(NtileRunningAggregateDescriptor.FACTORY);
    // boolean functions
    fc.add(AndDescriptor.FACTORY);
    fc.add(OrDescriptor.FACTORY);
    // Record constructors / functions
    fc.add(ClosedRecordConstructorDescriptor.FACTORY);
    fc.add(OpenRecordConstructorDescriptor.FACTORY);
    fc.add(RecordConcatDescriptor.FACTORY);
    fc.add(RecordConcatStrictDescriptor.FACTORY);
    // List constructors
    fc.add(OrderedListConstructorDescriptor.FACTORY);
    fc.add(UnorderedListConstructorDescriptor.FACTORY);
    // Sleep function
    fc.add(SleepDescriptor.FACTORY);
    // Inject failure function
    fc.add(InjectFailureDescriptor.FACTORY);
    // Get Job Parameter function
    fc.add(GetJobParameterByNameDescriptor.FACTORY);
    // Switch case
    fc.add(SwitchCaseDescriptor.FACTORY);
    // null functions
    fc.add(IsMissingDescriptor.FACTORY);
    fc.add(IsNullDescriptor.FACTORY);
    fc.add(IsUnknownDescriptor.FACTORY);
    fc.add(IsSystemNullDescriptor.FACTORY);
    fc.add(CheckUnknownDescriptor.FACTORY);
    fc.add(IfMissingDescriptor.FACTORY);
    fc.add(IfNullDescriptor.FACTORY);
    fc.add(IfMissingOrNullDescriptor.FACTORY);
    // uuid generators (zero independent functions)
    fc.add(CreateUUIDDescriptor.FACTORY);
    fc.add(UUIDDescriptor.FACTORY);
    fc.add(CreateQueryUIDDescriptor.FACTORY);
    fc.add(RandomDescriptor.FACTORY);
    fc.add(CurrentDateDescriptor.FACTORY);
    fc.add(CurrentTimeDescriptor.FACTORY);
    fc.add(CurrentDateTimeDescriptor.FACTORY);
    // functions that need generated class for null-handling.
    // Element accessors.
    fc.addGenerated(FieldAccessByIndexDescriptor.FACTORY);
    fc.addGenerated(FieldAccessByNameDescriptor.FACTORY);
    fc.addGenerated(FieldAccessNestedDescriptor.FACTORY);
    fc.addGenerated(AnyCollectionMemberDescriptor.FACTORY);
    fc.addGenerated(GetItemDescriptor.FACTORY);
    // Numeric functions
    fc.add(IfInfDescriptor.FACTORY);
    fc.add(IfNanDescriptor.FACTORY);
    fc.add(IfNanOrInfDescriptor.FACTORY);
    fc.addGenerated(NumericUnaryMinusDescriptor.FACTORY);
    fc.addGenerated(NumericAddDescriptor.FACTORY);
    fc.addGenerated(NumericDivideDescriptor.FACTORY);
    fc.addGenerated(NumericDivDescriptor.FACTORY);
    fc.addGenerated(NumericMultiplyDescriptor.FACTORY);
    fc.addGenerated(NumericSubDescriptor.FACTORY);
    fc.addGenerated(NumericModuloDescriptor.FACTORY);
    fc.addGenerated(NumericPowerDescriptor.FACTORY);
    fc.addGenerated(NotDescriptor.FACTORY);
    fc.addGenerated(LenDescriptor.FACTORY);
    fc.addGenerated(NumericAbsDescriptor.FACTORY);
    fc.addGenerated(NumericCeilingDescriptor.FACTORY);
    fc.addGenerated(NumericFloorDescriptor.FACTORY);
    fc.addGenerated(NumericRoundDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEvenDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEven2Descriptor.FACTORY);
    fc.addGenerated(NumericACosDescriptor.FACTORY);
    fc.addGenerated(NumericASinDescriptor.FACTORY);
    fc.addGenerated(NumericATanDescriptor.FACTORY);
    fc.addGenerated(NumericDegreesDescriptor.FACTORY);
    fc.addGenerated(NumericRadiansDescriptor.FACTORY);
    fc.addGenerated(NumericCosDescriptor.FACTORY);
    fc.addGenerated(NumericSinDescriptor.FACTORY);
    fc.addGenerated(NumericTanDescriptor.FACTORY);
    fc.addGenerated(NumericExpDescriptor.FACTORY);
    fc.addGenerated(NumericLnDescriptor.FACTORY);
    fc.addGenerated(NumericLogDescriptor.FACTORY);
    fc.addGenerated(NumericSqrtDescriptor.FACTORY);
    fc.addGenerated(NumericSignDescriptor.FACTORY);
    fc.addGenerated(NumericTruncDescriptor.FACTORY);
    fc.addGenerated(NumericATan2Descriptor.FACTORY);
    // Comparisons.
    fc.addGenerated(EqualsDescriptor.FACTORY);
    fc.addGenerated(GreaterThanDescriptor.FACTORY);
    fc.addGenerated(GreaterThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(LessThanDescriptor.FACTORY);
    fc.addGenerated(LessThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(NotEqualsDescriptor.FACTORY);
    // If-Equals functions
    fc.addGenerated(MissingIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NullIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NanIfEqualsDescriptor.FACTORY);
    fc.addGenerated(PosInfIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NegInfIfEqualsDescriptor.FACTORY);
    // Binary functions
    fc.addGenerated(BinaryLengthDescriptor.FACTORY);
    fc.addGenerated(ParseBinaryDescriptor.FACTORY);
    fc.addGenerated(PrintBinaryDescriptor.FACTORY);
    fc.addGenerated(BinaryConcatDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromToDescriptor.FACTORY);
    fc.addGenerated(FindBinaryDescriptor.FACTORY);
    fc.addGenerated(FindBinaryFromDescriptor.FACTORY);
    // String functions
    fc.addGenerated(StringLikeDescriptor.FACTORY);
    fc.addGenerated(StringContainsDescriptor.FACTORY);
    fc.addGenerated(StringEndsWithDescriptor.FACTORY);
    fc.addGenerated(StringStartsWithDescriptor.FACTORY);
    fc.addGenerated(SubstringDescriptor.FACTORY);
    fc.addGenerated(StringEqualDescriptor.FACTORY);
    fc.addGenerated(StringLowerCaseDescriptor.FACTORY);
    fc.addGenerated(StringUpperCaseDescriptor.FACTORY);
    fc.addGenerated(StringLengthDescriptor.FACTORY);
    fc.addGenerated(Substring2Descriptor.FACTORY);
    fc.addGenerated(SubstringBeforeDescriptor.FACTORY);
    fc.addGenerated(SubstringAfterDescriptor.FACTORY);
    fc.addGenerated(StringToCodePointDescriptor.FACTORY);
    fc.addGenerated(CodePointToStringDescriptor.FACTORY);
    fc.addGenerated(StringConcatDescriptor.FACTORY);
    fc.addGenerated(StringJoinDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringInitCapDescriptor.FACTORY);
    fc.addGenerated(StringTrimDescriptor.FACTORY);
    fc.addGenerated(StringLTrimDescriptor.FACTORY);
    fc.addGenerated(StringRTrimDescriptor.FACTORY);
    fc.addGenerated(StringTrim2Descriptor.FACTORY);
    fc.addGenerated(StringLTrim2Descriptor.FACTORY);
    fc.addGenerated(StringRTrim2Descriptor.FACTORY);
    fc.addGenerated(StringPositionDescriptor.FACTORY);
    fc.addGenerated(StringRepeatDescriptor.FACTORY);
    fc.addGenerated(StringReplaceDescriptor.FACTORY);
    fc.addGenerated(StringReplaceWithLimitDescriptor.FACTORY);
    fc.addGenerated(StringReverseDescriptor.FACTORY);
    fc.addGenerated(StringSplitDescriptor.FACTORY);
    // Constructors
    fc.addGenerated(ABooleanConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryHexStringConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryBase64StringConstructorDescriptor.FACTORY);
    fc.addGenerated(AStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt8ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt16ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt32ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt64ConstructorDescriptor.FACTORY);
    fc.addGenerated(AFloatConstructorDescriptor.FACTORY);
    fc.addGenerated(ADoubleConstructorDescriptor.FACTORY);
    fc.addGenerated(APointConstructorDescriptor.FACTORY);
    fc.addGenerated(APoint3DConstructorDescriptor.FACTORY);
    fc.addGenerated(ALineConstructorDescriptor.FACTORY);
    fc.addGenerated(APolygonConstructorDescriptor.FACTORY);
    fc.addGenerated(ACircleConstructorDescriptor.FACTORY);
    fc.addGenerated(ARectangleConstructorDescriptor.FACTORY);
    fc.addGenerated(ATimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AYearMonthDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(ADayTimeDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AUUIDFromStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromTimeConstructorDescriptor.FACTORY);
    // Spatial
    fc.addGenerated(CreatePointDescriptor.FACTORY);
    fc.addGenerated(CreateLineDescriptor.FACTORY);
    fc.addGenerated(CreatePolygonDescriptor.FACTORY);
    fc.addGenerated(CreateCircleDescriptor.FACTORY);
    fc.addGenerated(CreateRectangleDescriptor.FACTORY);
    fc.addGenerated(SpatialAreaDescriptor.FACTORY);
    fc.addGenerated(SpatialDistanceDescriptor.FACTORY);
    fc.addGenerated(CreateMBRDescriptor.FACTORY);
    fc.addGenerated(SpatialCellDescriptor.FACTORY);
    fc.addGenerated(PointXCoordinateAccessor.FACTORY);
    fc.addGenerated(PointYCoordinateAccessor.FACTORY);
    fc.addGenerated(CircleRadiusAccessor.FACTORY);
    fc.addGenerated(CircleCenterAccessor.FACTORY);
    fc.addGenerated(LineRectanglePolygonAccessor.FACTORY);
    // full-text function
    fc.addGenerated(FullTextContainsDescriptor.FACTORY);
    fc.addGenerated(FullTextContainsWithoutOptionDescriptor.FACTORY);
    // Record functions.
    fc.addGenerated(GetRecordFieldsDescriptor.FACTORY);
    fc.addGenerated(GetRecordFieldValueDescriptor.FACTORY);
    fc.addGenerated(DeepEqualityDescriptor.FACTORY);
    fc.addGenerated(RecordMergeDescriptor.FACTORY);
    fc.addGenerated(RecordAddFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordLengthDescriptor.FACTORY);
    fc.addGenerated(RecordNamesDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveDescriptor.FACTORY);
    fc.addGenerated(RecordRenameDescriptor.FACTORY);
    fc.addGenerated(RecordUnwrapDescriptor.FACTORY);
    fc.add(RecordReplaceDescriptor.FACTORY);
    fc.add(RecordAddDescriptor.FACTORY);
    fc.add(RecordPutDescriptor.FACTORY);
    fc.addGenerated(RecordValuesDescriptor.FACTORY);
    fc.addGenerated(PairsDescriptor.FACTORY);
    // Spatial and temporal type accessors
    fc.addGenerated(TemporalYearAccessor.FACTORY);
    fc.addGenerated(TemporalMonthAccessor.FACTORY);
    fc.addGenerated(TemporalDayAccessor.FACTORY);
    fc.addGenerated(TemporalHourAccessor.FACTORY);
    fc.addGenerated(TemporalMinuteAccessor.FACTORY);
    fc.addGenerated(TemporalSecondAccessor.FACTORY);
    fc.addGenerated(TemporalMillisecondAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDatetimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDatetimeAccessor.FACTORY);
    // Temporal functions
    fc.addGenerated(UnixTimeFromDateInDaysDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromTimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DateFromUnixTimeInDaysDescriptor.FACTORY);
    fc.addGenerated(DateFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(TimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(TimeFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromDateAndTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDurationFromDateTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDuartionFromDateDescriptor.FACTORY);
    fc.addGenerated(AdjustDateTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(AdjustTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(IntervalBeforeDescriptor.FACTORY);
    fc.addGenerated(IntervalAfterDescriptor.FACTORY);
    fc.addGenerated(IntervalMeetsDescriptor.FACTORY);
    fc.addGenerated(IntervalMetByDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlapsDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlappedByDescriptor.FACTORY);
    fc.addGenerated(OverlapDescriptor.FACTORY);
    fc.addGenerated(IntervalStartsDescriptor.FACTORY);
    fc.addGenerated(IntervalStartedByDescriptor.FACTORY);
    fc.addGenerated(IntervalCoversDescriptor.FACTORY);
    fc.addGenerated(IntervalCoveredByDescriptor.FACTORY);
    fc.addGenerated(IntervalEndsDescriptor.FACTORY);
    fc.addGenerated(IntervalEndedByDescriptor.FACTORY);
    fc.addGenerated(DurationFromMillisecondsDescriptor.FACTORY);
    fc.addGenerated(DurationFromMonthsDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(MonthsFromYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(MillisecondsFromDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(DurationEqualDescriptor.FACTORY);
    fc.addGenerated(GetYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(GetDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(IntervalBinDescriptor.FACTORY);
    fc.addGenerated(OverlapBinsDescriptor.FACTORY);
    fc.addGenerated(DayOfWeekDescriptor.FACTORY);
    fc.addGenerated(ParseDateDescriptor.FACTORY);
    fc.addGenerated(ParseTimeDescriptor.FACTORY);
    fc.addGenerated(ParseDateTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateDescriptor.FACTORY);
    fc.addGenerated(PrintTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateTimeDescriptor.FACTORY);
    fc.addGenerated(GetOverlappingIntervalDescriptor.FACTORY);
    fc.addGenerated(DurationFromIntervalDescriptor.FACTORY);
    // Type functions.
    fc.addGenerated(IsArrayDescriptor.FACTORY);
    fc.addGenerated(IsAtomicDescriptor.FACTORY);
    fc.addGenerated(IsBooleanDescriptor.FACTORY);
    fc.addGenerated(IsNumberDescriptor.FACTORY);
    fc.addGenerated(IsObjectDescriptor.FACTORY);
    fc.addGenerated(IsStringDescriptor.FACTORY);
    fc.addGenerated(ToArrayDescriptor.FACTORY);
    fc.addGenerated(ToAtomicDescriptor.FACTORY);
    fc.addGenerated(ToBigIntDescriptor.FACTORY);
    fc.addGenerated(ToBooleanDescriptor.FACTORY);
    fc.addGenerated(ToDoubleDescriptor.FACTORY);
    fc.addGenerated(ToNumberDescriptor.FACTORY);
    fc.addGenerated(ToObjectDescriptor.FACTORY);
    fc.addGenerated(ToStringDescriptor.FACTORY);
    fc.addGenerated(TreatAsIntegerDescriptor.FACTORY);
    // Cast function
    fc.addGenerated(CastTypeDescriptor.FACTORY);
    fc.addGenerated(CastTypeLaxDescriptor.FACTORY);
    // Record function
    fc.addGenerated(RecordPairsDescriptor.FACTORY);
    // Other functions
    fc.addGenerated(RandomWithSeedDescriptor.FACTORY);
    ServiceLoader.load(IFunctionRegistrant.class).iterator().forEachRemaining(c -> c.register(fc));
    return fc;
}
#end_block

#method_before
@Override
protected void finishNull() throws IOException {
    resultStorage.getDataOutput().writeByte(ATypeTag.SERIALIZED_NULL_TYPE_TAG);
}
#method_after
@Override
protected void finishNull(IPointable result) throws IOException {
    resultStorage.getDataOutput().writeByte(ATypeTag.SERIALIZED_NULL_TYPE_TAG);
    result.set(resultStorage);
}
#end_block

#method_before
@Override
protected void finishSystemNull() throws IOException {
    resultStorage.getDataOutput().writeByte(ATypeTag.SERIALIZED_SYSTEM_NULL_TYPE_TAG);
}
#method_after
@Override
protected void finishSystemNull(IPointable result) throws IOException {
    resultStorage.getDataOutput().writeByte(ATypeTag.SERIALIZED_SYSTEM_NULL_TYPE_TAG);
    result.set(resultStorage);
}
#end_block

#method_before
@Override
protected void finishNull() throws IOException {
    resultStorage.getDataOutput().writeByte(ATypeTag.SERIALIZED_NULL_TYPE_TAG);
}
#method_after
@Override
protected void finishNull(IPointable result) throws IOException {
    resultStorage.getDataOutput().writeByte(ATypeTag.SERIALIZED_NULL_TYPE_TAG);
    result.set(resultStorage);
}
#end_block

#method_before
@Override
protected void finishSystemNull() throws IOException {
    resultStorage.getDataOutput().writeByte(ATypeTag.SERIALIZED_SYSTEM_NULL_TYPE_TAG);
}
#method_after
@Override
protected void finishSystemNull(IPointable result) throws IOException {
    resultStorage.getDataOutput().writeByte(ATypeTag.SERIALIZED_SYSTEM_NULL_TYPE_TAG);
    result.set(resultStorage);
}
#end_block

#method_before
private boolean equalStrings(String expected, String actual, boolean regexMatch) {
    String[] rowsExpected = expected.split("\n");
    String[] rowsActual = actual.split("\n");
    for (int i = 0; i < rowsExpected.length; i++) {
        String expectedRow = rowsExpected[i];
        String actualRow = rowsActual[i];
        if (regexMatch) {
            if (actualRow.matches(expectedRow)) {
                continue;
            }
        } else if (actualRow.equals(expectedRow)) {
            continue;
        }
        String[] expectedFields = expectedRow.split(" ");
        String[] actualFields = actualRow.split(" ");
        boolean bagEncountered = false;
        Set<String> expectedBagElements = new HashSet<>();
        Set<String> actualBagElements = new HashSet<>();
        for (int j = 0; j < expectedFields.length; j++) {
            if (j >= actualFields.length) {
                return false;
            } else if (expectedFields[j].equals(actualFields[j])) {
                bagEncountered = expectedFields[j].equals("{{");
                if (expectedFields[j].startsWith("}}")) {
                    if (regexMatch) {
                        if (expectedBagElements.size() != actualBagElements.size()) {
                            return false;
                        }
                        int[] expectedHits = new int[expectedBagElements.size()];
                        int[] actualHits = new int[actualBagElements.size()];
                        int k = 0;
                        for (String expectedElement : expectedBagElements) {
                            int l = 0;
                            for (String actualElement : actualBagElements) {
                                if (actualElement.matches(expectedElement)) {
                                    expectedHits[k]++;
                                    actualHits[l]++;
                                }
                                l++;
                            }
                            k++;
                        }
                        for (int m = 0; m < expectedHits.length; m++) {
                            if (expectedHits[m] == 0 || actualHits[m] == 0) {
                                return false;
                            }
                        }
                    } else if (!expectedBagElements.equals(actualBagElements)) {
                        return false;
                    }
                    bagEncountered = false;
                    expectedBagElements.clear();
                    actualBagElements.clear();
                }
            } else if (expectedFields[j].indexOf('.') < 0) {
                if (bagEncountered) {
                    expectedBagElements.add(expectedFields[j].replaceAll(",$", ""));
                    actualBagElements.add(actualFields[j].replaceAll(",$", ""));
                    continue;
                }
                return false;
            } else {
                // Ensures the values to be compared are of matching types (2 Ints or 2 Floats, but not a mix)
                BiFunction<String, String, Boolean> isCompatibleTypesComparator = (arg1, arg2) -> {
                    Function<String, Boolean> isIntegerStringComparator = (arg) -> {
                        try {
                            Integer.parseInt(arg);
                        } catch (NumberFormatException ignored) {
                            // String is not valid Int
                            return false;
                        }
                        return true;
                    };
                    // Step 1: Check that both are valid double numbers first
                    try {
                        Double.parseDouble(arg1);
                        Double.parseDouble(arg2);
                    } catch (NumberFormatException ignored) {
                        // One of the Strings isn't a valid number.
                        return false;
                    }
                    // positive, if both are Int or both are Floats, then it's a safe equality
                    return isIntegerStringComparator.apply(arg1) == isIntegerStringComparator.apply(arg2);
                };
                // Get the String values
                expectedFields[j] = expectedFields[j].split(",")[0];
                actualFields[j] = actualFields[j].split(",")[0];
                // Ensure compatibility before conversion
                if (isCompatibleTypesComparator.apply(expectedFields[j], actualFields[j])) {
                    try {
                        Double double1 = Double.parseDouble(expectedFields[j]);
                        Double double2 = Double.parseDouble(actualFields[j]);
                        float float1 = (float) double1.doubleValue();
                        float float2 = (float) double2.doubleValue();
                        if (Math.abs(float1 - float2) == 0) {
                            continue;
                        } else {
                            return false;
                        }
                    } catch (NumberFormatException ignored) {
                        // Guess they weren't numbers - must simply not be equal
                        return false;
                    }
                }
                // Not equal
                return false;
            }
        }
    }
    return true;
}
#method_after
private boolean equalStrings(String expected, String actual, boolean regexMatch) {
    String[] rowsExpected = expected.split("\n");
    String[] rowsActual = actual.split("\n");
    for (int i = 0; i < rowsExpected.length; i++) {
        String expectedRow = rowsExpected[i];
        String actualRow = rowsActual[i];
        if (regexMatch) {
            if (actualRow.matches(expectedRow)) {
                continue;
            }
        } else if (actualRow.equals(expectedRow)) {
            continue;
        }
        String[] expectedFields = expectedRow.split(" ");
        String[] actualFields = actualRow.split(" ");
        boolean bagEncountered = false;
        Set<String> expectedBagElements = new HashSet<>();
        Set<String> actualBagElements = new HashSet<>();
        for (int j = 0; j < expectedFields.length; j++) {
            if (j >= actualFields.length) {
                return false;
            } else if (expectedFields[j].equals(actualFields[j])) {
                bagEncountered = expectedFields[j].equals("{{");
                if (expectedFields[j].startsWith("}}")) {
                    if (regexMatch) {
                        if (expectedBagElements.size() != actualBagElements.size()) {
                            return false;
                        }
                        int[] expectedHits = new int[expectedBagElements.size()];
                        int[] actualHits = new int[actualBagElements.size()];
                        int k = 0;
                        for (String expectedElement : expectedBagElements) {
                            int l = 0;
                            for (String actualElement : actualBagElements) {
                                if (actualElement.matches(expectedElement)) {
                                    expectedHits[k]++;
                                    actualHits[l]++;
                                }
                                l++;
                            }
                            k++;
                        }
                        for (int m = 0; m < expectedHits.length; m++) {
                            if (expectedHits[m] == 0 || actualHits[m] == 0) {
                                return false;
                            }
                        }
                    } else if (!expectedBagElements.equals(actualBagElements)) {
                        return false;
                    }
                    bagEncountered = false;
                    expectedBagElements.clear();
                    actualBagElements.clear();
                }
            } else if (expectedFields[j].indexOf('.') < 0) {
                if (bagEncountered) {
                    expectedBagElements.add(expectedFields[j].replaceAll(",$", ""));
                    actualBagElements.add(actualFields[j].replaceAll(",$", ""));
                    continue;
                }
                return false;
            } else {
                // Get the String values
                expectedFields[j] = expectedFields[j].split(",")[0];
                actualFields[j] = actualFields[j].split(",")[0];
                // Ensure type compatibility before value comparison
                if (NumberUtils.isSameTypeNumericStrings(expectedFields[j], actualFields[j])) {
                    try {
                        Double double1 = Double.parseDouble(expectedFields[j]);
                        Double double2 = Double.parseDouble(actualFields[j]);
                        float float1 = (float) double1.doubleValue();
                        float float2 = (float) double2.doubleValue();
                        if (Math.abs(float1 - float2) == 0) {
                            continue;
                        } else {
                            return false;
                        }
                    } catch (NumberFormatException ignored) {
                        // Guess they weren't numbers - must simply not be equal
                        return false;
                    }
                }
                // Not equal
                return false;
            }
        }
    }
    return true;
}
#end_block

#method_before
@Override
public PhysicalRequirements getRequiredPropertiesForChildren(ILogicalOperator op, IPhysicalPropertiesVector reqdByParent, IOptimizationContext context) {
    return emptyUnaryRequirements();
}
#method_after
@Override
public PhysicalRequirements getRequiredPropertiesForChildren(ILogicalOperator op, IPhysicalPropertiesVector requiredByParent, IOptimizationContext context) {
    return emptyUnaryRequirements();
}
#end_block

#method_before
@Override
public void computeDeliveredProperties(ILogicalOperator op, IOptimizationContext context) {
    AbstractLogicalOperator childOp = (AbstractLogicalOperator) op.getInputs().get(0).getValue();
    List<ILocalStructuralProperty> childLocalProps = childOp.getDeliveredPhysicalProperties().getLocalProperties();
    IPartitioningProperty childGlobalProp = childOp.getDeliveredPhysicalProperties().getPartitioningProperty();
    List<ILocalStructuralProperty> outputLocalProp = new ArrayList<>(0);
    if (childLocalProps != null && childGlobalProp.getPartitioningType() == PartitioningType.ORDERED_PARTITIONED) {
        // the child could have a local order property that matches its global order property
        propagateChildProperties((OrderedPartitionedProperty) childGlobalProp, childLocalProps, outputLocalProp);
    }
    deliveredProperties = new StructuralPropertiesVector(IPartitioningProperty.UNPARTITIONED, outputLocalProp);
}
#method_after
@Override
public void computeDeliveredProperties(ILogicalOperator op, IOptimizationContext context) {
    AbstractLogicalOperator childOp = (AbstractLogicalOperator) op.getInputs().get(0).getValue();
    List<ILocalStructuralProperty> childLocalProps = childOp.getDeliveredPhysicalProperties().getLocalProperties();
    IPartitioningProperty childPartitioning = childOp.getDeliveredPhysicalProperties().getPartitioningProperty();
    List<ILocalStructuralProperty> outputLocalProp = new ArrayList<>(0);
    if (childLocalProps != null && !childLocalProps.isEmpty() && childPartitioning != null && childPartitioning.getPartitioningType() == PartitioningType.ORDERED_PARTITIONED) {
        // the child could have a local order property that matches its global order property
        propagateChildProperties((OrderedPartitionedProperty) childPartitioning, childLocalProps, outputLocalProp);
    }
    deliveredProperties = new StructuralPropertiesVector(IPartitioningProperty.UNPARTITIONED, outputLocalProp);
}
#end_block

#method_before
private void propagateChildProperties(OrderedPartitionedProperty childGlobalProp, List<ILocalStructuralProperty> childLocalProps, List<ILocalStructuralProperty> outputLocalProp) {
    List<OrderColumn> globalOrderColumns = childGlobalProp.getOrderColumns();
    List<OrderColumn> outputOrderColumns = new ArrayList<>();
    OrderColumn localOrderColumn;
    ILocalStructuralProperty childLocalProp;
    boolean done = false;
    for (int j = 0; j < childLocalProps.size() && !done; j++) {
        childLocalProp = childLocalProps.get(j);
        if (childLocalProp.getPropertyType() == ILocalStructuralProperty.PropertyType.LOCAL_ORDER_PROPERTY) {
            List<OrderColumn> localOrderColumns = ((LocalOrderProperty) childLocalProp).getOrderColumns();
            // start matching the order columns
            for (int i = 0; i < localOrderColumns.size() && i < globalOrderColumns.size(); i++) {
                localOrderColumn = localOrderColumns.get(i);
                if (localOrderColumn.equals(globalOrderColumns.get(i))) {
                    outputOrderColumns.add(localOrderColumn);
                } else {
                    // stop whenever the matching fails, end of prefix matching
                    break;
                }
            }
            done = true;
        }
    }
    if (!outputOrderColumns.isEmpty()) {
        // found a prefix
        outputLocalProp.add(new LocalOrderProperty(outputOrderColumns));
    }
}
#method_after
private void propagateChildProperties(OrderedPartitionedProperty childPartitioning, List<ILocalStructuralProperty> childLocalProps, List<ILocalStructuralProperty> outputLocalProp) {
    ILocalStructuralProperty childLocalProp = childLocalProps.get(0);
    // skip if the first property is a grouping property
    if (childLocalProp.getPropertyType() == ILocalStructuralProperty.PropertyType.LOCAL_ORDER_PROPERTY) {
        OrderColumn localOrderColumn;
        List<OrderColumn> outputOrderColumns = new ArrayList<>();
        List<OrderColumn> globalOrderColumns = childPartitioning.getOrderColumns();
        List<OrderColumn> localOrderColumns = ((LocalOrderProperty) childLocalProp).getOrderColumns();
        // start matching the order columns
        for (int i = 0; i < localOrderColumns.size() && i < globalOrderColumns.size(); i++) {
            localOrderColumn = localOrderColumns.get(i);
            if (localOrderColumn.equals(globalOrderColumns.get(i))) {
                outputOrderColumns.add(localOrderColumn);
            } else {
                // stop whenever the matching fails, end of prefix matching
                break;
            }
        }
        if (!outputOrderColumns.isEmpty()) {
            // found a prefix
            outputLocalProp.add(new LocalOrderProperty(outputOrderColumns));
        }
    }
}
#end_block

#method_before
private void addLocalEnforcers(AbstractLogicalOperator op, int i, List<ILocalStructuralProperty> localProperties, boolean nestedPlan, IOptimizationContext context) throws AlgebricksException {
    if (AlgebricksConfig.ALGEBRICKS_LOGGER.isTraceEnabled()) {
        AlgebricksConfig.ALGEBRICKS_LOGGER.trace(">>>> Adding local enforcers for local props = " + localProperties + "\n");
    }
    if (localProperties == null || localProperties.isEmpty()) {
        return;
    }
    Mutable<ILogicalOperator> topOp = new MutableObject<>();
    topOp.setValue(op.getInputs().get(i).getValue());
    LinkedList<LocalOrderProperty> oList = new LinkedList<>();
    for (ILocalStructuralProperty prop : localProperties) {
        switch(prop.getPropertyType()) {
            case LOCAL_ORDER_PROPERTY:
                {
                    oList.add((LocalOrderProperty) prop);
                    break;
                }
            case LOCAL_GROUPING_PROPERTY:
                {
                    LocalGroupingProperty g = (LocalGroupingProperty) prop;
                    Collection<LogicalVariable> vars = (g.getPreferredOrderEnforcer() != null) ? g.getPreferredOrderEnforcer() : g.getColumnSet();
                    List<OrderColumn> orderColumns = new ArrayList<>();
                    for (LogicalVariable v : vars) {
                        OrderColumn oc = new OrderColumn(v, OrderKind.ASC);
                        orderColumns.add(oc);
                    }
                    LocalOrderProperty lop = new LocalOrderProperty(orderColumns);
                    oList.add(lop);
                    break;
                }
            default:
                {
                    throw new IllegalStateException();
                }
        }
    }
    if (!oList.isEmpty()) {
        topOp = enforceOrderProperties(oList, topOp, nestedPlan, context);
    }
    op.getInputs().set(i, topOp);
    OperatorPropertiesUtil.computeSchemaAndPropertiesRecIfNull((AbstractLogicalOperator) topOp.getValue(), context);
    OperatorManipulationUtil.setOperatorMode(op);
    printOp((AbstractLogicalOperator) topOp.getValue());
}
#method_after
private void addLocalEnforcers(AbstractLogicalOperator op, int i, List<ILocalStructuralProperty> localProperties, boolean nestedPlan, IOptimizationContext context) throws AlgebricksException {
    if (AlgebricksConfig.ALGEBRICKS_LOGGER.isTraceEnabled()) {
        AlgebricksConfig.ALGEBRICKS_LOGGER.trace(">>>> Adding local enforcers for local props = " + localProperties + "\n");
    }
    if (localProperties == null || localProperties.isEmpty()) {
        return;
    }
    Mutable<ILogicalOperator> topOp = new MutableObject<>();
    topOp.setValue(op.getInputs().get(i).getValue());
    LinkedList<LocalOrderProperty> oList = new LinkedList<>();
    for (ILocalStructuralProperty prop : localProperties) {
        switch(prop.getPropertyType()) {
            case LOCAL_ORDER_PROPERTY:
                {
                    oList.add((LocalOrderProperty) prop);
                    break;
                }
            case LOCAL_GROUPING_PROPERTY:
                {
                    LocalGroupingProperty g = (LocalGroupingProperty) prop;
                    Collection<LogicalVariable> vars = !g.getPreferredOrderEnforcer().isEmpty() ? g.getPreferredOrderEnforcer() : g.getColumnSet();
                    List<OrderColumn> orderColumns = new ArrayList<>();
                    for (LogicalVariable v : vars) {
                        OrderColumn oc = new OrderColumn(v, OrderKind.ASC);
                        orderColumns.add(oc);
                    }
                    LocalOrderProperty lop = new LocalOrderProperty(orderColumns);
                    oList.add(lop);
                    break;
                }
            default:
                {
                    throw new IllegalStateException();
                }
        }
    }
    if (!oList.isEmpty()) {
        topOp = enforceOrderProperties(oList, topOp, nestedPlan, context);
    }
    op.getInputs().set(i, topOp);
    OperatorPropertiesUtil.computeSchemaAndPropertiesRecIfNull((AbstractLogicalOperator) topOp.getValue(), context);
    OperatorManipulationUtil.setOperatorMode(op);
    printOp((AbstractLogicalOperator) topOp.getValue());
}
#end_block

#method_before
protected void init() throws HyracksDataException {
    super.init();
    partitionComparators = createBinaryComparators(partitionComparatorFactories);
    frameAccessor = new FrameTupleAccessor(inputRecordDesc);
    copyFrame = new VSizeFrame(ctx);
    copyFrameAccessor = new FrameTupleAccessor(inputRecordDesc);
    copyFrameAccessor.reset(copyFrame.getBuffer());
    IBinaryComparator[] orderComparators = createBinaryComparators(orderComparatorFactories);
    for (IWindowAggregateEvaluator aggEval : aggEvals) {
        aggEval.configure(orderComparators);
    }
}
#method_after
@Override
protected void init() throws HyracksDataException {
    super.init();
    partitionComparators = createBinaryComparators(partitionComparatorFactories);
    frameAccessor = new FrameTupleAccessor(inputRecordDesc);
    copyFrame = new VSizeFrame(ctx);
    copyFrameAccessor = new FrameTupleAccessor(inputRecordDesc);
    copyFrameAccessor.reset(copyFrame.getBuffer());
    IBinaryComparator[] orderComparators = createBinaryComparators(orderComparatorFactories);
    for (IWindowAggregateEvaluator aggEval : aggEvals) {
        aggEval.configure(orderComparators);
    }
}
#end_block

#method_before
@Override
public void nextFrame(ByteBuffer buffer) throws HyracksDataException {
    frameAccessor.reset(buffer);
    int nTuple = frameAccessor.getTupleCount();
    if (nTuple == 0) {
        return;
    }
    if (frameId == 0) {
        beginPartition();
    } else {
        boolean samePartition = PreclusteredGroupWriter.sameGroup(copyFrameAccessor, copyFrameAccessor.getTupleCount() - 1, frameAccessor, 0, partitionColumnList, partitionComparators);
        if (!samePartition) {
            endPartition();
            beginPartition();
        }
    }
    if (nTuple == 1) {
        partitionChunk(frameId, buffer, 0, 0);
    } else {
        int tBeginIndex = 0;
        int tLastIndex = nTuple - 1;
        for (int tIndex = 1; tIndex <= tLastIndex; tIndex++) {
            boolean samePartition = PreclusteredGroupWriter.sameGroup(frameAccessor, tIndex - 1, frameAccessor, tIndex, partitionColumnList, partitionComparators);
            if (!samePartition) {
                partitionChunk(frameId, buffer, tBeginIndex, tIndex - 1);
                endPartition();
                beginPartition();
                tBeginIndex = tIndex;
            }
        }
        partitionChunk(frameId, buffer, tBeginIndex, tLastIndex);
    }
    copyFrame.ensureFrameSize(buffer.capacity());
    FrameUtils.copyAndFlip(buffer, copyFrame.getBuffer());
    copyFrameAccessor.reset(copyFrame.getBuffer());
    frameId++;
}
#method_after
@Override
public void nextFrame(ByteBuffer buffer) throws HyracksDataException {
    frameAccessor.reset(buffer);
    int nTuple = frameAccessor.getTupleCount();
    if (nTuple == 0) {
        return;
    }
    if (frameId == 0) {
        beginPartition();
    } else {
        boolean samePartition = PreclusteredGroupWriter.sameGroup(copyFrameAccessor, copyFrameAccessor.getTupleCount() - 1, frameAccessor, 0, partitionColumnList, partitionComparators);
        if (!samePartition) {
            endPartition();
            beginPartition();
        }
    }
    if (nTuple == 1) {
        partitionChunk(frameId, buffer, 0, 0);
    } else {
        int tBeginIndex = 0;
        int tLastIndex = nTuple - 1;
        for (int tIndex = 1; tIndex <= tLastIndex; tIndex++) {
            boolean samePartition = PreclusteredGroupWriter.sameGroup(frameAccessor, tIndex - 1, frameAccessor, tIndex, partitionColumnList, partitionComparators);
            if (!samePartition) {
                partitionChunk(frameId, buffer, tBeginIndex, tIndex - 1);
                endPartition();
                beginPartition();
                tBeginIndex = tIndex;
            }
        }
        partitionChunk(frameId, buffer, tBeginIndex, tLastIndex);
    }
    copyFrame.resize(buffer.capacity());
    FrameUtils.copyAndFlip(buffer, copyFrame.getBuffer());
    copyFrameAccessor.reset(copyFrame.getBuffer());
    frameId++;
}
#end_block

#method_before
@Override
protected void endPartitionImpl() {
}
#method_after
@Override
protected void endPartitionImpl() {
// nothing to do
}
#end_block

#method_before
@Override
public void init() {
}
#method_after
@Override
public void init() {
// nothing to do
}
#end_block

#method_before
@Override
public void initPartition(long partitionLength) {
    v = 0;
}
#method_after
@Override
public void initPartition(long partitionLength) {
    resultValue = 0;
}
#end_block

#method_before
@Override
public void step(IFrameTupleReference tuple, IPointable result) throws HyracksDataException {
    v++;
    resultStorage.reset();
    m.setValue(v);
    serde.serialize(m, resultStorage.getDataOutput());
    result.set(resultStorage);
}
#method_after
@Override
public void step(IFrameTupleReference tuple, IPointable result) throws HyracksDataException {
    resultValue++;
    resultStorage.reset();
    aInt64.setValue(resultValue);
    serde.serialize(aInt64, resultStorage.getDataOutput());
    result.set(resultStorage);
}
#end_block

#method_before
public static FunctionCollection createDefaultFunctionCollection() {
    FunctionCollection fc = new FunctionCollection();
    // array functions
    fc.add(ArrayRemoveDescriptor.FACTORY);
    fc.add(ArrayPutDescriptor.FACTORY);
    fc.add(ArrayPrependDescriptor.FACTORY);
    fc.add(ArrayAppendDescriptor.FACTORY);
    fc.add(ArrayInsertDescriptor.FACTORY);
    fc.addGenerated(ArrayPositionDescriptor.FACTORY);
    fc.addGenerated(ArrayRepeatDescriptor.FACTORY);
    fc.addGenerated(ArrayContainsDescriptor.FACTORY);
    fc.addGenerated(ArrayReverseDescriptor.FACTORY);
    fc.addGenerated(ArraySortDescriptor.FACTORY);
    fc.addGenerated(ArrayDistinctDescriptor.FACTORY);
    fc.addGenerated(ArrayUnionDescriptor.FACTORY);
    fc.addGenerated(ArrayIntersectDescriptor.FACTORY);
    fc.addGenerated(ArrayIfNullDescriptor.FACTORY);
    fc.addGenerated(ArrayConcatDescriptor.FACTORY);
    fc.addGenerated(ArrayRangeDescriptor.FACTORY);
    fc.addGenerated(ArrayFlattenDescriptor.FACTORY);
    fc.add(ArrayReplaceDescriptor.FACTORY);
    fc.addGenerated(ArraySymDiffDescriptor.FACTORY);
    fc.addGenerated(ArraySymDiffnDescriptor.FACTORY);
    fc.addGenerated(ArrayStarDescriptor.FACTORY);
    // unnesting functions
    fc.add(TidRunningAggregateDescriptor.FACTORY);
    fc.add(ScanCollectionDescriptor.FACTORY);
    fc.add(RangeDescriptor.FACTORY);
    fc.add(SubsetCollectionDescriptor.FACTORY);
    // aggregate functions
    fc.add(ListifyAggregateDescriptor.FACTORY);
    fc.add(CountAggregateDescriptor.FACTORY);
    fc.add(AvgAggregateDescriptor.FACTORY);
    fc.add(LocalAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SumAggregateDescriptor.FACTORY);
    fc.add(LocalSumAggregateDescriptor.FACTORY);
    fc.add(MaxAggregateDescriptor.FACTORY);
    fc.add(LocalMaxAggregateDescriptor.FACTORY);
    fc.add(MinAggregateDescriptor.FACTORY);
    fc.add(LocalMinAggregateDescriptor.FACTORY);
    fc.add(FirstElementAggregateDescriptor.FACTORY);
    fc.add(LocalFirstElementAggregateDescriptor.FACTORY);
    fc.add(StddevAggregateDescriptor.FACTORY);
    fc.add(LocalStddevAggregateDescriptor.FACTORY);
    fc.add(IntermediateStddevAggregateDescriptor.FACTORY);
    fc.add(GlobalStddevAggregateDescriptor.FACTORY);
    fc.add(LocalSamplingAggregateDescriptor.FACTORY);
    fc.add(RangeMapAggregateDescriptor.FACTORY);
    // serializable aggregates
    fc.add(SerializableCountAggregateDescriptor.FACTORY);
    fc.add(SerializableAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSumAggregateDescriptor.FACTORY);
    fc.add(SerializableStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalStddevAggregateDescriptor.FACTORY);
    // scalar aggregates
    fc.add(ScalarCountAggregateDescriptor.FACTORY);
    fc.add(ScalarAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSumAggregateDescriptor.FACTORY);
    fc.add(ScalarMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarMinAggregateDescriptor.FACTORY);
    fc.add(EmptyStreamAggregateDescriptor.FACTORY);
    fc.add(NonEmptyStreamAggregateDescriptor.FACTORY);
    fc.add(ScalarStddevAggregateDescriptor.FACTORY);
    // SQL aggregates
    fc.add(SqlCountAggregateDescriptor.FACTORY);
    fc.add(SqlAvgAggregateDescriptor.FACTORY);
    fc.add(LocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SqlSumAggregateDescriptor.FACTORY);
    fc.add(LocalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SqlMaxAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMaxAggregateDescriptor.FACTORY);
    fc.add(SqlMinAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMinAggregateDescriptor.FACTORY);
    fc.add(SqlStddevAggregateDescriptor.FACTORY);
    fc.add(LocalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlStddevAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlStddevAggregateDescriptor.FACTORY);
    // SQL serializable aggregates
    fc.add(SerializableSqlCountAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlStddevAggregateDescriptor.FACTORY);
    // SQL scalar aggregates
    fc.add(ScalarSqlCountAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlSumAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMinAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlStddevAggregateDescriptor.FACTORY);
    // window functions
    fc.add(RowNumberRunningAggregateDescriptor.FACTORY);
    fc.add(RankRunningAggregateDescriptor.FACTORY);
    fc.add(DenseRankRunningAggregateDescriptor.FACTORY);
    fc.add(PercentRankRunningAggregateDescriptor.FACTORY);
    fc.add(NtileRunningAggregateDescriptor.FACTORY);
    // boolean functions
    fc.add(AndDescriptor.FACTORY);
    fc.add(OrDescriptor.FACTORY);
    // Record constructors / functions
    fc.add(ClosedRecordConstructorDescriptor.FACTORY);
    fc.add(OpenRecordConstructorDescriptor.FACTORY);
    fc.add(RecordConcatDescriptor.FACTORY);
    fc.add(RecordConcatStrictDescriptor.FACTORY);
    // List constructors
    fc.add(OrderedListConstructorDescriptor.FACTORY);
    fc.add(UnorderedListConstructorDescriptor.FACTORY);
    // Sleep function
    fc.add(SleepDescriptor.FACTORY);
    // Inject failure function
    fc.add(InjectFailureDescriptor.FACTORY);
    // Get Job Parameter function
    fc.add(GetJobParameterByNameDescriptor.FACTORY);
    // Switch case
    fc.add(SwitchCaseDescriptor.FACTORY);
    // null functions
    fc.add(IsMissingDescriptor.FACTORY);
    fc.add(IsNullDescriptor.FACTORY);
    fc.add(IsUnknownDescriptor.FACTORY);
    fc.add(IsSystemNullDescriptor.FACTORY);
    fc.add(CheckUnknownDescriptor.FACTORY);
    fc.add(IfMissingDescriptor.FACTORY);
    fc.add(IfNullDescriptor.FACTORY);
    fc.add(IfMissingOrNullDescriptor.FACTORY);
    // uuid generators (zero independent functions)
    fc.add(CreateUUIDDescriptor.FACTORY);
    fc.add(UUIDDescriptor.FACTORY);
    fc.add(CreateQueryUIDDescriptor.FACTORY);
    fc.add(RandomDescriptor.FACTORY);
    fc.add(CurrentDateDescriptor.FACTORY);
    fc.add(CurrentTimeDescriptor.FACTORY);
    fc.add(CurrentDateTimeDescriptor.FACTORY);
    // functions that need generated class for null-handling.
    // Element accessors.
    fc.addGenerated(FieldAccessByIndexDescriptor.FACTORY);
    fc.addGenerated(FieldAccessByNameDescriptor.FACTORY);
    fc.addGenerated(FieldAccessNestedDescriptor.FACTORY);
    fc.addGenerated(AnyCollectionMemberDescriptor.FACTORY);
    fc.addGenerated(GetItemDescriptor.FACTORY);
    // Numeric functions
    fc.add(IfInfDescriptor.FACTORY);
    fc.add(IfNanDescriptor.FACTORY);
    fc.add(IfNanOrInfDescriptor.FACTORY);
    fc.addGenerated(NumericUnaryMinusDescriptor.FACTORY);
    fc.addGenerated(NumericAddDescriptor.FACTORY);
    fc.addGenerated(NumericDivideDescriptor.FACTORY);
    fc.addGenerated(NumericDivDescriptor.FACTORY);
    fc.addGenerated(NumericMultiplyDescriptor.FACTORY);
    fc.addGenerated(NumericSubDescriptor.FACTORY);
    fc.addGenerated(NumericModuloDescriptor.FACTORY);
    fc.addGenerated(NumericPowerDescriptor.FACTORY);
    fc.addGenerated(NotDescriptor.FACTORY);
    fc.addGenerated(LenDescriptor.FACTORY);
    fc.addGenerated(NumericAbsDescriptor.FACTORY);
    fc.addGenerated(NumericCeilingDescriptor.FACTORY);
    fc.addGenerated(NumericFloorDescriptor.FACTORY);
    fc.addGenerated(NumericRoundDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEvenDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEven2Descriptor.FACTORY);
    fc.addGenerated(NumericACosDescriptor.FACTORY);
    fc.addGenerated(NumericASinDescriptor.FACTORY);
    fc.addGenerated(NumericATanDescriptor.FACTORY);
    fc.addGenerated(NumericDegreesDescriptor.FACTORY);
    fc.addGenerated(NumericRadiansDescriptor.FACTORY);
    fc.addGenerated(NumericCosDescriptor.FACTORY);
    fc.addGenerated(NumericSinDescriptor.FACTORY);
    fc.addGenerated(NumericTanDescriptor.FACTORY);
    fc.addGenerated(NumericExpDescriptor.FACTORY);
    fc.addGenerated(NumericLnDescriptor.FACTORY);
    fc.addGenerated(NumericLogDescriptor.FACTORY);
    fc.addGenerated(NumericSqrtDescriptor.FACTORY);
    fc.addGenerated(NumericSignDescriptor.FACTORY);
    fc.addGenerated(NumericTruncDescriptor.FACTORY);
    fc.addGenerated(NumericATan2Descriptor.FACTORY);
    // Comparisons.
    fc.addGenerated(EqualsDescriptor.FACTORY);
    fc.addGenerated(GreaterThanDescriptor.FACTORY);
    fc.addGenerated(GreaterThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(LessThanDescriptor.FACTORY);
    fc.addGenerated(LessThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(NotEqualsDescriptor.FACTORY);
    // If-Equals functions
    fc.addGenerated(MissingIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NullIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NanIfEqualsDescriptor.FACTORY);
    fc.addGenerated(PosInfIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NegInfIfEqualsDescriptor.FACTORY);
    // Binary functions
    fc.addGenerated(BinaryLengthDescriptor.FACTORY);
    fc.addGenerated(ParseBinaryDescriptor.FACTORY);
    fc.addGenerated(PrintBinaryDescriptor.FACTORY);
    fc.addGenerated(BinaryConcatDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromToDescriptor.FACTORY);
    fc.addGenerated(FindBinaryDescriptor.FACTORY);
    fc.addGenerated(FindBinaryFromDescriptor.FACTORY);
    // String functions
    fc.addGenerated(StringLikeDescriptor.FACTORY);
    fc.addGenerated(StringContainsDescriptor.FACTORY);
    fc.addGenerated(StringEndsWithDescriptor.FACTORY);
    fc.addGenerated(StringStartsWithDescriptor.FACTORY);
    fc.addGenerated(SubstringDescriptor.FACTORY);
    fc.addGenerated(StringEqualDescriptor.FACTORY);
    fc.addGenerated(StringLowerCaseDescriptor.FACTORY);
    fc.addGenerated(StringUpperCaseDescriptor.FACTORY);
    fc.addGenerated(StringLengthDescriptor.FACTORY);
    fc.addGenerated(Substring2Descriptor.FACTORY);
    fc.addGenerated(SubstringBeforeDescriptor.FACTORY);
    fc.addGenerated(SubstringAfterDescriptor.FACTORY);
    fc.addGenerated(StringToCodePointDescriptor.FACTORY);
    fc.addGenerated(CodePointToStringDescriptor.FACTORY);
    fc.addGenerated(StringConcatDescriptor.FACTORY);
    fc.addGenerated(StringJoinDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringInitCapDescriptor.FACTORY);
    fc.addGenerated(StringTrimDescriptor.FACTORY);
    fc.addGenerated(StringLTrimDescriptor.FACTORY);
    fc.addGenerated(StringRTrimDescriptor.FACTORY);
    fc.addGenerated(StringTrim2Descriptor.FACTORY);
    fc.addGenerated(StringLTrim2Descriptor.FACTORY);
    fc.addGenerated(StringRTrim2Descriptor.FACTORY);
    fc.addGenerated(StringPositionDescriptor.FACTORY);
    fc.addGenerated(StringRepeatDescriptor.FACTORY);
    fc.addGenerated(StringReplaceDescriptor.FACTORY);
    fc.addGenerated(StringReplaceWithLimitDescriptor.FACTORY);
    fc.addGenerated(StringReverseDescriptor.FACTORY);
    fc.addGenerated(StringSplitDescriptor.FACTORY);
    // Constructors
    fc.addGenerated(ABooleanConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryHexStringConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryBase64StringConstructorDescriptor.FACTORY);
    fc.addGenerated(AStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt8ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt16ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt32ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt64ConstructorDescriptor.FACTORY);
    fc.addGenerated(AFloatConstructorDescriptor.FACTORY);
    fc.addGenerated(ADoubleConstructorDescriptor.FACTORY);
    fc.addGenerated(APointConstructorDescriptor.FACTORY);
    fc.addGenerated(APoint3DConstructorDescriptor.FACTORY);
    fc.addGenerated(ALineConstructorDescriptor.FACTORY);
    fc.addGenerated(APolygonConstructorDescriptor.FACTORY);
    fc.addGenerated(ACircleConstructorDescriptor.FACTORY);
    fc.addGenerated(ARectangleConstructorDescriptor.FACTORY);
    fc.addGenerated(ATimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AYearMonthDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(ADayTimeDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AUUIDFromStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromTimeConstructorDescriptor.FACTORY);
    // Spatial
    fc.addGenerated(CreatePointDescriptor.FACTORY);
    fc.addGenerated(CreateLineDescriptor.FACTORY);
    fc.addGenerated(CreatePolygonDescriptor.FACTORY);
    fc.addGenerated(CreateCircleDescriptor.FACTORY);
    fc.addGenerated(CreateRectangleDescriptor.FACTORY);
    fc.addGenerated(SpatialAreaDescriptor.FACTORY);
    fc.addGenerated(SpatialDistanceDescriptor.FACTORY);
    fc.addGenerated(CreateMBRDescriptor.FACTORY);
    fc.addGenerated(SpatialCellDescriptor.FACTORY);
    fc.addGenerated(PointXCoordinateAccessor.FACTORY);
    fc.addGenerated(PointYCoordinateAccessor.FACTORY);
    fc.addGenerated(CircleRadiusAccessor.FACTORY);
    fc.addGenerated(CircleCenterAccessor.FACTORY);
    fc.addGenerated(LineRectanglePolygonAccessor.FACTORY);
    // full-text function
    fc.addGenerated(FullTextContainsDescriptor.FACTORY);
    fc.addGenerated(FullTextContainsWithoutOptionDescriptor.FACTORY);
    // Record functions.
    fc.addGenerated(GetRecordFieldsDescriptor.FACTORY);
    fc.addGenerated(GetRecordFieldValueDescriptor.FACTORY);
    fc.addGenerated(DeepEqualityDescriptor.FACTORY);
    fc.addGenerated(RecordMergeDescriptor.FACTORY);
    fc.addGenerated(RecordAddFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordLengthDescriptor.FACTORY);
    fc.addGenerated(RecordNamesDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveDescriptor.FACTORY);
    fc.addGenerated(RecordRenameDescriptor.FACTORY);
    fc.addGenerated(RecordUnwrapDescriptor.FACTORY);
    fc.add(RecordReplaceDescriptor.FACTORY);
    fc.add(RecordAddDescriptor.FACTORY);
    fc.add(RecordPutDescriptor.FACTORY);
    fc.addGenerated(RecordValuesDescriptor.FACTORY);
    fc.addGenerated(PairsDescriptor.FACTORY);
    // Spatial and temporal type accessors
    fc.addGenerated(TemporalYearAccessor.FACTORY);
    fc.addGenerated(TemporalMonthAccessor.FACTORY);
    fc.addGenerated(TemporalDayAccessor.FACTORY);
    fc.addGenerated(TemporalHourAccessor.FACTORY);
    fc.addGenerated(TemporalMinuteAccessor.FACTORY);
    fc.addGenerated(TemporalSecondAccessor.FACTORY);
    fc.addGenerated(TemporalMillisecondAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDatetimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDatetimeAccessor.FACTORY);
    // Temporal functions
    fc.addGenerated(UnixTimeFromDateInDaysDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromTimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DateFromUnixTimeInDaysDescriptor.FACTORY);
    fc.addGenerated(DateFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(TimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(TimeFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromDateAndTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDurationFromDateTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDuartionFromDateDescriptor.FACTORY);
    fc.addGenerated(AdjustDateTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(AdjustTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(IntervalBeforeDescriptor.FACTORY);
    fc.addGenerated(IntervalAfterDescriptor.FACTORY);
    fc.addGenerated(IntervalMeetsDescriptor.FACTORY);
    fc.addGenerated(IntervalMetByDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlapsDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlappedByDescriptor.FACTORY);
    fc.addGenerated(OverlapDescriptor.FACTORY);
    fc.addGenerated(IntervalStartsDescriptor.FACTORY);
    fc.addGenerated(IntervalStartedByDescriptor.FACTORY);
    fc.addGenerated(IntervalCoversDescriptor.FACTORY);
    fc.addGenerated(IntervalCoveredByDescriptor.FACTORY);
    fc.addGenerated(IntervalEndsDescriptor.FACTORY);
    fc.addGenerated(IntervalEndedByDescriptor.FACTORY);
    fc.addGenerated(DurationFromMillisecondsDescriptor.FACTORY);
    fc.addGenerated(DurationFromMonthsDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(MonthsFromYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(MillisecondsFromDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(DurationEqualDescriptor.FACTORY);
    fc.addGenerated(GetYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(GetDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(IntervalBinDescriptor.FACTORY);
    fc.addGenerated(OverlapBinsDescriptor.FACTORY);
    fc.addGenerated(DayOfWeekDescriptor.FACTORY);
    fc.addGenerated(ParseDateDescriptor.FACTORY);
    fc.addGenerated(ParseTimeDescriptor.FACTORY);
    fc.addGenerated(ParseDateTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateDescriptor.FACTORY);
    fc.addGenerated(PrintTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateTimeDescriptor.FACTORY);
    fc.addGenerated(GetOverlappingIntervalDescriptor.FACTORY);
    fc.addGenerated(DurationFromIntervalDescriptor.FACTORY);
    // Type functions.
    fc.addGenerated(IsArrayDescriptor.FACTORY);
    fc.addGenerated(IsAtomicDescriptor.FACTORY);
    fc.addGenerated(IsBooleanDescriptor.FACTORY);
    fc.addGenerated(IsNumberDescriptor.FACTORY);
    fc.addGenerated(IsObjectDescriptor.FACTORY);
    fc.addGenerated(IsStringDescriptor.FACTORY);
    fc.addGenerated(ToArrayDescriptor.FACTORY);
    fc.addGenerated(ToAtomicDescriptor.FACTORY);
    fc.addGenerated(ToBigIntDescriptor.FACTORY);
    fc.addGenerated(ToBooleanDescriptor.FACTORY);
    fc.addGenerated(ToDoubleDescriptor.FACTORY);
    fc.addGenerated(ToNumberDescriptor.FACTORY);
    fc.addGenerated(ToObjectDescriptor.FACTORY);
    fc.addGenerated(ToStringDescriptor.FACTORY);
    fc.addGenerated(TreatAsIntegerDescriptor.FACTORY);
    // Cast function
    fc.addGenerated(CastTypeDescriptor.FACTORY);
    fc.addGenerated(CastTypeLaxDescriptor.FACTORY);
    // Record function
    fc.addGenerated(RecordPairsDescriptor.FACTORY);
    // Other functions
    fc.addGenerated(RandomWithSeedDescriptor.FACTORY);
    ServiceLoader.load(IFunctionRegistrant.class).iterator().forEachRemaining(c -> c.register(fc));
    return fc;
}
#method_after
public static FunctionCollection createDefaultFunctionCollection() {
    FunctionCollection fc = new FunctionCollection();
    // array functions
    fc.add(ArrayRemoveDescriptor.FACTORY);
    fc.add(ArrayPutDescriptor.FACTORY);
    fc.add(ArrayPrependDescriptor.FACTORY);
    fc.add(ArrayAppendDescriptor.FACTORY);
    fc.add(ArrayInsertDescriptor.FACTORY);
    fc.addGenerated(ArrayPositionDescriptor.FACTORY);
    fc.addGenerated(ArrayRepeatDescriptor.FACTORY);
    fc.addGenerated(ArrayContainsDescriptor.FACTORY);
    fc.addGenerated(ArrayReverseDescriptor.FACTORY);
    fc.addGenerated(ArraySortDescriptor.FACTORY);
    fc.addGenerated(ArrayDistinctDescriptor.FACTORY);
    fc.addGenerated(ArrayUnionDescriptor.FACTORY);
    fc.addGenerated(ArrayIntersectDescriptor.FACTORY);
    fc.addGenerated(ArrayIfNullDescriptor.FACTORY);
    fc.addGenerated(ArrayConcatDescriptor.FACTORY);
    fc.addGenerated(ArrayRangeDescriptor.FACTORY);
    fc.addGenerated(ArrayFlattenDescriptor.FACTORY);
    fc.add(ArrayReplaceDescriptor.FACTORY);
    fc.addGenerated(ArraySymDiffDescriptor.FACTORY);
    fc.addGenerated(ArraySymDiffnDescriptor.FACTORY);
    fc.addGenerated(ArrayStarDescriptor.FACTORY);
    // unnesting functions
    fc.add(TidRunningAggregateDescriptor.FACTORY);
    fc.add(ScanCollectionDescriptor.FACTORY);
    fc.add(RangeDescriptor.FACTORY);
    fc.add(SubsetCollectionDescriptor.FACTORY);
    // aggregate functions
    fc.add(ListifyAggregateDescriptor.FACTORY);
    fc.add(CountAggregateDescriptor.FACTORY);
    fc.add(AvgAggregateDescriptor.FACTORY);
    fc.add(LocalAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SumAggregateDescriptor.FACTORY);
    fc.add(LocalSumAggregateDescriptor.FACTORY);
    fc.add(MaxAggregateDescriptor.FACTORY);
    fc.add(LocalMaxAggregateDescriptor.FACTORY);
    fc.add(MinAggregateDescriptor.FACTORY);
    fc.add(LocalMinAggregateDescriptor.FACTORY);
    fc.add(FirstElementAggregateDescriptor.FACTORY);
    fc.add(LocalFirstElementAggregateDescriptor.FACTORY);
    fc.add(StddevAggregateDescriptor.FACTORY);
    fc.add(LocalStddevAggregateDescriptor.FACTORY);
    fc.add(IntermediateStddevAggregateDescriptor.FACTORY);
    fc.add(GlobalStddevAggregateDescriptor.FACTORY);
    fc.add(LocalSamplingAggregateDescriptor.FACTORY);
    fc.add(RangeMapAggregateDescriptor.FACTORY);
    fc.add(StddevPopAggregateDescriptor.FACTORY);
    fc.add(LocalStddevPopAggregateDescriptor.FACTORY);
    fc.add(IntermediateStddevPopAggregateDescriptor.FACTORY);
    fc.add(GlobalStddevPopAggregateDescriptor.FACTORY);
    fc.add(VarAggregateDescriptor.FACTORY);
    fc.add(LocalVarAggregateDescriptor.FACTORY);
    fc.add(IntermediateVarAggregateDescriptor.FACTORY);
    fc.add(GlobalVarAggregateDescriptor.FACTORY);
    fc.add(VarPopAggregateDescriptor.FACTORY);
    fc.add(LocalVarPopAggregateDescriptor.FACTORY);
    fc.add(IntermediateVarPopAggregateDescriptor.FACTORY);
    fc.add(GlobalVarPopAggregateDescriptor.FACTORY);
    // serializable aggregates
    fc.add(SerializableCountAggregateDescriptor.FACTORY);
    fc.add(SerializableAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSumAggregateDescriptor.FACTORY);
    fc.add(SerializableStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableVarAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalVarAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateVarAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalVarAggregateDescriptor.FACTORY);
    fc.add(SerializableVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalVarPopAggregateDescriptor.FACTORY);
    // scalar aggregates
    fc.add(ScalarCountAggregateDescriptor.FACTORY);
    fc.add(ScalarAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSumAggregateDescriptor.FACTORY);
    fc.add(ScalarMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarMinAggregateDescriptor.FACTORY);
    fc.add(EmptyStreamAggregateDescriptor.FACTORY);
    fc.add(NonEmptyStreamAggregateDescriptor.FACTORY);
    fc.add(ScalarStddevAggregateDescriptor.FACTORY);
    fc.add(ScalarStddevPopAggregateDescriptor.FACTORY);
    fc.add(ScalarVarAggregateDescriptor.FACTORY);
    fc.add(ScalarVarPopAggregateDescriptor.FACTORY);
    // SQL aggregates
    fc.add(SqlCountAggregateDescriptor.FACTORY);
    fc.add(SqlAvgAggregateDescriptor.FACTORY);
    fc.add(LocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SqlSumAggregateDescriptor.FACTORY);
    fc.add(LocalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SqlMaxAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMaxAggregateDescriptor.FACTORY);
    fc.add(SqlMinAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMinAggregateDescriptor.FACTORY);
    fc.add(SqlStddevAggregateDescriptor.FACTORY);
    fc.add(LocalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlStddevAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(LocalSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SqlVarAggregateDescriptor.FACTORY);
    fc.add(LocalSqlVarAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlVarAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlVarAggregateDescriptor.FACTORY);
    fc.add(SqlVarPopAggregateDescriptor.FACTORY);
    fc.add(LocalSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlVarPopAggregateDescriptor.FACTORY);
    // SQL serializable aggregates
    fc.add(SerializableSqlCountAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlVarAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlVarAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlVarAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlVarAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlVarPopAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlVarPopAggregateDescriptor.FACTORY);
    // SQL scalar aggregates
    fc.add(ScalarSqlCountAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlSumAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMinAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlStddevAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlVarAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlVarPopAggregateDescriptor.FACTORY);
    // window functions
    fc.add(RowNumberRunningAggregateDescriptor.FACTORY);
    fc.add(RankRunningAggregateDescriptor.FACTORY);
    fc.add(DenseRankRunningAggregateDescriptor.FACTORY);
    fc.add(PercentRankRunningAggregateDescriptor.FACTORY);
    fc.add(NtileRunningAggregateDescriptor.FACTORY);
    // boolean functions
    fc.add(AndDescriptor.FACTORY);
    fc.add(OrDescriptor.FACTORY);
    // Record constructors / functions
    fc.add(ClosedRecordConstructorDescriptor.FACTORY);
    fc.add(OpenRecordConstructorDescriptor.FACTORY);
    fc.add(RecordConcatDescriptor.FACTORY);
    fc.add(RecordConcatStrictDescriptor.FACTORY);
    // List constructors
    fc.add(OrderedListConstructorDescriptor.FACTORY);
    fc.add(UnorderedListConstructorDescriptor.FACTORY);
    // Sleep function
    fc.add(SleepDescriptor.FACTORY);
    // Inject failure function
    fc.add(InjectFailureDescriptor.FACTORY);
    // Get Job Parameter function
    fc.add(GetJobParameterByNameDescriptor.FACTORY);
    // Switch case
    fc.add(SwitchCaseDescriptor.FACTORY);
    // null functions
    fc.add(IsMissingDescriptor.FACTORY);
    fc.add(IsNullDescriptor.FACTORY);
    fc.add(IsUnknownDescriptor.FACTORY);
    fc.add(IsSystemNullDescriptor.FACTORY);
    fc.add(CheckUnknownDescriptor.FACTORY);
    fc.add(IfMissingDescriptor.FACTORY);
    fc.add(IfNullDescriptor.FACTORY);
    fc.add(IfMissingOrNullDescriptor.FACTORY);
    // uuid generators (zero independent functions)
    fc.add(CreateUUIDDescriptor.FACTORY);
    fc.add(UUIDDescriptor.FACTORY);
    fc.add(CreateQueryUIDDescriptor.FACTORY);
    fc.add(RandomDescriptor.FACTORY);
    fc.add(CurrentDateDescriptor.FACTORY);
    fc.add(CurrentTimeDescriptor.FACTORY);
    fc.add(CurrentDateTimeDescriptor.FACTORY);
    // functions that need generated class for null-handling.
    // Element accessors.
    fc.addGenerated(FieldAccessByIndexDescriptor.FACTORY);
    fc.addGenerated(FieldAccessByNameDescriptor.FACTORY);
    fc.addGenerated(FieldAccessNestedDescriptor.FACTORY);
    fc.addGenerated(AnyCollectionMemberDescriptor.FACTORY);
    fc.addGenerated(GetItemDescriptor.FACTORY);
    // Numeric functions
    fc.add(IfInfDescriptor.FACTORY);
    fc.add(IfNanDescriptor.FACTORY);
    fc.add(IfNanOrInfDescriptor.FACTORY);
    fc.addGenerated(NumericUnaryMinusDescriptor.FACTORY);
    fc.addGenerated(NumericAddDescriptor.FACTORY);
    fc.addGenerated(NumericDivideDescriptor.FACTORY);
    fc.addGenerated(NumericDivDescriptor.FACTORY);
    fc.addGenerated(NumericMultiplyDescriptor.FACTORY);
    fc.addGenerated(NumericSubDescriptor.FACTORY);
    fc.addGenerated(NumericModuloDescriptor.FACTORY);
    fc.addGenerated(NumericPowerDescriptor.FACTORY);
    fc.addGenerated(NotDescriptor.FACTORY);
    fc.addGenerated(LenDescriptor.FACTORY);
    fc.addGenerated(NumericAbsDescriptor.FACTORY);
    fc.addGenerated(NumericCeilingDescriptor.FACTORY);
    fc.addGenerated(NumericFloorDescriptor.FACTORY);
    fc.addGenerated(NumericRoundDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEvenDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEven2Descriptor.FACTORY);
    fc.addGenerated(NumericACosDescriptor.FACTORY);
    fc.addGenerated(NumericASinDescriptor.FACTORY);
    fc.addGenerated(NumericATanDescriptor.FACTORY);
    fc.addGenerated(NumericDegreesDescriptor.FACTORY);
    fc.addGenerated(NumericRadiansDescriptor.FACTORY);
    fc.addGenerated(NumericCosDescriptor.FACTORY);
    fc.addGenerated(NumericSinDescriptor.FACTORY);
    fc.addGenerated(NumericTanDescriptor.FACTORY);
    fc.addGenerated(NumericExpDescriptor.FACTORY);
    fc.addGenerated(NumericLnDescriptor.FACTORY);
    fc.addGenerated(NumericLogDescriptor.FACTORY);
    fc.addGenerated(NumericSqrtDescriptor.FACTORY);
    fc.addGenerated(NumericSignDescriptor.FACTORY);
    fc.addGenerated(NumericTruncDescriptor.FACTORY);
    fc.addGenerated(NumericATan2Descriptor.FACTORY);
    // Comparisons.
    fc.addGenerated(EqualsDescriptor.FACTORY);
    fc.addGenerated(GreaterThanDescriptor.FACTORY);
    fc.addGenerated(GreaterThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(LessThanDescriptor.FACTORY);
    fc.addGenerated(LessThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(NotEqualsDescriptor.FACTORY);
    // If-Equals functions
    fc.addGenerated(MissingIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NullIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NanIfEqualsDescriptor.FACTORY);
    fc.addGenerated(PosInfIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NegInfIfEqualsDescriptor.FACTORY);
    // Binary functions
    fc.addGenerated(BinaryLengthDescriptor.FACTORY);
    fc.addGenerated(ParseBinaryDescriptor.FACTORY);
    fc.addGenerated(PrintBinaryDescriptor.FACTORY);
    fc.addGenerated(BinaryConcatDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromToDescriptor.FACTORY);
    fc.addGenerated(FindBinaryDescriptor.FACTORY);
    fc.addGenerated(FindBinaryFromDescriptor.FACTORY);
    // String functions
    fc.addGenerated(StringLikeDescriptor.FACTORY);
    fc.addGenerated(StringContainsDescriptor.FACTORY);
    fc.addGenerated(StringEndsWithDescriptor.FACTORY);
    fc.addGenerated(StringStartsWithDescriptor.FACTORY);
    fc.addGenerated(SubstringDescriptor.FACTORY);
    fc.addGenerated(StringEqualDescriptor.FACTORY);
    fc.addGenerated(StringLowerCaseDescriptor.FACTORY);
    fc.addGenerated(StringUpperCaseDescriptor.FACTORY);
    fc.addGenerated(StringLengthDescriptor.FACTORY);
    fc.addGenerated(Substring2Descriptor.FACTORY);
    fc.addGenerated(SubstringBeforeDescriptor.FACTORY);
    fc.addGenerated(SubstringAfterDescriptor.FACTORY);
    fc.addGenerated(StringToCodePointDescriptor.FACTORY);
    fc.addGenerated(CodePointToStringDescriptor.FACTORY);
    fc.addGenerated(StringConcatDescriptor.FACTORY);
    fc.addGenerated(StringJoinDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringInitCapDescriptor.FACTORY);
    fc.addGenerated(StringTrimDescriptor.FACTORY);
    fc.addGenerated(StringLTrimDescriptor.FACTORY);
    fc.addGenerated(StringRTrimDescriptor.FACTORY);
    fc.addGenerated(StringTrim2Descriptor.FACTORY);
    fc.addGenerated(StringLTrim2Descriptor.FACTORY);
    fc.addGenerated(StringRTrim2Descriptor.FACTORY);
    fc.addGenerated(StringPositionDescriptor.FACTORY);
    fc.addGenerated(StringRepeatDescriptor.FACTORY);
    fc.addGenerated(StringReplaceDescriptor.FACTORY);
    fc.addGenerated(StringReplaceWithLimitDescriptor.FACTORY);
    fc.addGenerated(StringReverseDescriptor.FACTORY);
    fc.addGenerated(StringSplitDescriptor.FACTORY);
    // Constructors
    fc.addGenerated(ABooleanConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryHexStringConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryBase64StringConstructorDescriptor.FACTORY);
    fc.addGenerated(AStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt8ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt16ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt32ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt64ConstructorDescriptor.FACTORY);
    fc.addGenerated(AFloatConstructorDescriptor.FACTORY);
    fc.addGenerated(ADoubleConstructorDescriptor.FACTORY);
    fc.addGenerated(APointConstructorDescriptor.FACTORY);
    fc.addGenerated(APoint3DConstructorDescriptor.FACTORY);
    fc.addGenerated(ALineConstructorDescriptor.FACTORY);
    fc.addGenerated(APolygonConstructorDescriptor.FACTORY);
    fc.addGenerated(ACircleConstructorDescriptor.FACTORY);
    fc.addGenerated(ARectangleConstructorDescriptor.FACTORY);
    fc.addGenerated(ATimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AYearMonthDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(ADayTimeDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AUUIDFromStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromTimeConstructorDescriptor.FACTORY);
    // Spatial
    fc.addGenerated(CreatePointDescriptor.FACTORY);
    fc.addGenerated(CreateLineDescriptor.FACTORY);
    fc.addGenerated(CreatePolygonDescriptor.FACTORY);
    fc.addGenerated(CreateCircleDescriptor.FACTORY);
    fc.addGenerated(CreateRectangleDescriptor.FACTORY);
    fc.addGenerated(SpatialAreaDescriptor.FACTORY);
    fc.addGenerated(SpatialDistanceDescriptor.FACTORY);
    fc.addGenerated(CreateMBRDescriptor.FACTORY);
    fc.addGenerated(SpatialCellDescriptor.FACTORY);
    fc.addGenerated(PointXCoordinateAccessor.FACTORY);
    fc.addGenerated(PointYCoordinateAccessor.FACTORY);
    fc.addGenerated(CircleRadiusAccessor.FACTORY);
    fc.addGenerated(CircleCenterAccessor.FACTORY);
    fc.addGenerated(LineRectanglePolygonAccessor.FACTORY);
    // full-text function
    fc.addGenerated(FullTextContainsDescriptor.FACTORY);
    fc.addGenerated(FullTextContainsWithoutOptionDescriptor.FACTORY);
    // Record functions.
    fc.addGenerated(GetRecordFieldsDescriptor.FACTORY);
    fc.addGenerated(GetRecordFieldValueDescriptor.FACTORY);
    fc.addGenerated(DeepEqualityDescriptor.FACTORY);
    fc.addGenerated(RecordMergeDescriptor.FACTORY);
    fc.addGenerated(RecordAddFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordLengthDescriptor.FACTORY);
    fc.addGenerated(RecordNamesDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveDescriptor.FACTORY);
    fc.addGenerated(RecordRenameDescriptor.FACTORY);
    fc.addGenerated(RecordUnwrapDescriptor.FACTORY);
    fc.add(RecordReplaceDescriptor.FACTORY);
    fc.add(RecordAddDescriptor.FACTORY);
    fc.add(RecordPutDescriptor.FACTORY);
    fc.addGenerated(RecordValuesDescriptor.FACTORY);
    fc.addGenerated(PairsDescriptor.FACTORY);
    // Spatial and temporal type accessors
    fc.addGenerated(TemporalYearAccessor.FACTORY);
    fc.addGenerated(TemporalMonthAccessor.FACTORY);
    fc.addGenerated(TemporalDayAccessor.FACTORY);
    fc.addGenerated(TemporalHourAccessor.FACTORY);
    fc.addGenerated(TemporalMinuteAccessor.FACTORY);
    fc.addGenerated(TemporalSecondAccessor.FACTORY);
    fc.addGenerated(TemporalMillisecondAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDatetimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDatetimeAccessor.FACTORY);
    // Temporal functions
    fc.addGenerated(UnixTimeFromDateInDaysDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromTimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DateFromUnixTimeInDaysDescriptor.FACTORY);
    fc.addGenerated(DateFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(TimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(TimeFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromDateAndTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDurationFromDateTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDuartionFromDateDescriptor.FACTORY);
    fc.addGenerated(AdjustDateTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(AdjustTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(IntervalBeforeDescriptor.FACTORY);
    fc.addGenerated(IntervalAfterDescriptor.FACTORY);
    fc.addGenerated(IntervalMeetsDescriptor.FACTORY);
    fc.addGenerated(IntervalMetByDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlapsDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlappedByDescriptor.FACTORY);
    fc.addGenerated(OverlapDescriptor.FACTORY);
    fc.addGenerated(IntervalStartsDescriptor.FACTORY);
    fc.addGenerated(IntervalStartedByDescriptor.FACTORY);
    fc.addGenerated(IntervalCoversDescriptor.FACTORY);
    fc.addGenerated(IntervalCoveredByDescriptor.FACTORY);
    fc.addGenerated(IntervalEndsDescriptor.FACTORY);
    fc.addGenerated(IntervalEndedByDescriptor.FACTORY);
    fc.addGenerated(DurationFromMillisecondsDescriptor.FACTORY);
    fc.addGenerated(DurationFromMonthsDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(MonthsFromYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(MillisecondsFromDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(DurationEqualDescriptor.FACTORY);
    fc.addGenerated(GetYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(GetDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(IntervalBinDescriptor.FACTORY);
    fc.addGenerated(OverlapBinsDescriptor.FACTORY);
    fc.addGenerated(DayOfWeekDescriptor.FACTORY);
    fc.addGenerated(ParseDateDescriptor.FACTORY);
    fc.addGenerated(ParseTimeDescriptor.FACTORY);
    fc.addGenerated(ParseDateTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateDescriptor.FACTORY);
    fc.addGenerated(PrintTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateTimeDescriptor.FACTORY);
    fc.addGenerated(GetOverlappingIntervalDescriptor.FACTORY);
    fc.addGenerated(DurationFromIntervalDescriptor.FACTORY);
    // Type functions.
    fc.addGenerated(IsArrayDescriptor.FACTORY);
    fc.addGenerated(IsAtomicDescriptor.FACTORY);
    fc.addGenerated(IsBooleanDescriptor.FACTORY);
    fc.addGenerated(IsNumberDescriptor.FACTORY);
    fc.addGenerated(IsObjectDescriptor.FACTORY);
    fc.addGenerated(IsStringDescriptor.FACTORY);
    fc.addGenerated(ToArrayDescriptor.FACTORY);
    fc.addGenerated(ToAtomicDescriptor.FACTORY);
    fc.addGenerated(ToBigIntDescriptor.FACTORY);
    fc.addGenerated(ToBooleanDescriptor.FACTORY);
    fc.addGenerated(ToDoubleDescriptor.FACTORY);
    fc.addGenerated(ToNumberDescriptor.FACTORY);
    fc.addGenerated(ToObjectDescriptor.FACTORY);
    fc.addGenerated(ToStringDescriptor.FACTORY);
    fc.addGenerated(TreatAsIntegerDescriptor.FACTORY);
    // Cast function
    fc.addGenerated(CastTypeDescriptor.FACTORY);
    fc.addGenerated(CastTypeLaxDescriptor.FACTORY);
    // Record function
    fc.addGenerated(RecordPairsDescriptor.FACTORY);
    // Other functions
    fc.addGenerated(RandomWithSeedDescriptor.FACTORY);
    ServiceLoader.load(IFunctionRegistrant.class).iterator().forEachRemaining(c -> c.register(fc));
    return fc;
}
#end_block

#method_before
@Override
public void initPartition(long partitionLength) {
    this.partitionLength = partitionLength;
    v = 0;
}
#method_after
@Override
public void initPartition(long partitionLength) {
    this.partitionLength = partitionLength;
    resultValue = 0;
}
#end_block

#method_before
@Override
public void step(IFrameTupleReference tuple, IPointable result) throws HyracksDataException {
    if (v == 0) {
        evaluateGroupSize(tuple);
        v = n = 1;
    } else if (n < groupSize) {
        n++;
    } else if (n == groupSize && groupRemainder > 0) {
        groupRemainder--;
        n++;
    } else {
        v++;
        n = 1;
    }
    resultStorage.reset();
    m.setValue(v);
    serde.serialize(m, resultStorage.getDataOutput());
    result.set(resultStorage);
}
#method_after
@Override
public void step(IFrameTupleReference tuple, IPointable result) throws HyracksDataException {
    if (resultValue == 0) {
        evaluateGroupSize(tuple);
        resultValue = count = 1;
    } else if (count < groupSize) {
        count++;
    } else if (count == groupSize && groupRemainder > 0) {
        groupRemainder--;
        count++;
    } else {
        resultValue++;
        count = 1;
    }
    resultStorage.reset();
    aInt64.setValue(resultValue);
    serde.serialize(aInt64, resultStorage.getDataOutput());
    result.set(resultStorage);
}
#end_block

#method_before
@Override
public PhysicalRequirements getRequiredPropertiesForChildren(ILogicalOperator op, IPhysicalPropertiesVector reqdByParent, IOptimizationContext context) {
    IPartitioningProperty pp = op.getExecutionMode() == AbstractLogicalOperator.ExecutionMode.UNPARTITIONED ? IPartitioningProperty.UNPARTITIONED : new UnorderedPartitionedProperty(new ListSet<>(partitionColumns), context.getComputationNodeDomain());
    // TODO require local grouping property for partition columns
    List<OrderColumn> lopColumns = new ArrayList<>();
    for (LogicalVariable pColumn : partitionColumns) {
        lopColumns.add(new OrderColumn(pColumn, OrderOperator.IOrder.OrderKind.ASC));
    }
    lopColumns.addAll(orderColumns);
    List<ILocalStructuralProperty> localProps = Collections.singletonList(new LocalOrderProperty(lopColumns));
    StructuralPropertiesVector[] pv = new StructuralPropertiesVector[] { new StructuralPropertiesVector(pp, localProps) };
    return new PhysicalRequirements(pv, IPartitioningRequirementsCoordinator.NO_COORDINATION);
}
#method_after
@Override
public PhysicalRequirements getRequiredPropertiesForChildren(ILogicalOperator op, IPhysicalPropertiesVector reqdByParent, IOptimizationContext context) throws AlgebricksException {
    IPartitioningProperty pp;
    switch(op.getExecutionMode()) {
        case PARTITIONED:
            pp = new UnorderedPartitionedProperty(new ListSet<>(partitionColumns), context.getComputationNodeDomain());
            break;
        case UNPARTITIONED:
            pp = IPartitioningProperty.UNPARTITIONED;
            break;
        case LOCAL:
            pp = null;
            break;
        default:
            throw new IllegalStateException(op.getExecutionMode().name());
    }
    // require local order property [pc1, ... pcN, oc1, ... ocN]
    // accounting for cases where there's an overlap between order and partition columns
    // TODO replace with required local grouping on partition columns + local order on order columns
    List<OrderColumn> lopColumns = new ArrayList<>();
    ListSet<LogicalVariable> pcVars = new ListSet<>();
    pcVars.addAll(partitionColumns);
    for (int oIdx = 0, ln = orderColumns.size(); oIdx < ln; oIdx++) {
        OrderColumn oc = orderColumns.get(oIdx);
        LogicalVariable ocVar = oc.getColumn();
        if (!pcVars.remove(ocVar) && containsAny(orderColumns, oIdx + 1, pcVars)) {
            throw new AlgebricksException(ErrorCode.HYRACKS, ErrorCode.UNSUPPORTED_WINDOW_SPEC, op.getSourceLocation(), String.valueOf(partitionColumns), String.valueOf(orderColumns));
        }
        lopColumns.add(new OrderColumn(oc.getColumn(), oc.getOrder()));
    }
    int pIdx = 0;
    for (LogicalVariable pColumn : pcVars) {
        lopColumns.add(pIdx++, new OrderColumn(pColumn, OrderOperator.IOrder.OrderKind.ASC));
    }
    List<ILocalStructuralProperty> localProps = Collections.singletonList(new LocalOrderProperty(lopColumns));
    return new PhysicalRequirements(new StructuralPropertiesVector[] { new StructuralPropertiesVector(pp, localProps) }, IPartitioningRequirementsCoordinator.NO_COORDINATION);
}
#end_block

#method_before
@Override
public void initPartition(long partitionLength) {
    super.initPartition(partitionLength);
    divisor = partitionLength - 1;
}
#method_after
@Override
public void initPartition(long partitionLength) {
    super.initPartition(partitionLength);
    divisor = (double) partitionLength - 1;
}
#end_block

#method_before
static boolean extractComplexExpressions(ILogicalOperator op, List<Pair<IOrder, Mutable<ILogicalExpression>>> exprList, IOptimizationContext context) throws AlgebricksException {
    if (!hasComplexExpressions(exprList)) {
        return false;
    }
    boolean rewritten = false;
    Mutable<ILogicalOperator> inputOpRef = op.getInputs().get(0);
    for (Pair<IOrder, Mutable<ILogicalExpression>> orderPair : exprList) {
        ILogicalExpression expr = orderPair.second.getValue();
        if (expr.getExpressionTag() != LogicalExpressionTag.VARIABLE && !AnalysisUtil.isAccessToFieldRecord(expr)) {
            LogicalVariable v = extractExprIntoAssignOpRef(expr, inputOpRef, context);
            VariableReferenceExpression vRef = new VariableReferenceExpression(v);
            vRef.setSourceLocation(expr.getSourceLocation());
            orderPair.second.setValue(vRef);
            rewritten = true;
        }
    }
    context.computeAndSetTypeEnvironmentForOperator(op);
    return rewritten;
}
#method_after
static boolean extractComplexExpressions(ILogicalOperator op, List<Pair<IOrder, Mutable<ILogicalExpression>>> exprList, IOptimizationContext context) throws AlgebricksException {
    return extractComplexExpressions(op, exprList, Pair::getSecond, AnalysisUtil::isAccessToFieldRecord, context);
}
#end_block

#method_before
@Override
public Void visitAssignOperator(AssignOperator op, IOptimizationContext ctx) throws AlgebricksException {
    visitAssignment(op, ctx);
    return null;
}
#method_after
@Override
public Void visitAssignOperator(AssignOperator op, IOptimizationContext ctx) throws AlgebricksException {
    ILogicalOperator inp1 = op.getInputs().get(0).getValue();
    Map<LogicalVariable, EquivalenceClass> eqClasses = getOrComputeEqClasses(inp1, ctx);
    ctx.putEquivalenceClassMap(op, eqClasses);
    // Propagates equivalence classes that from expressions.
    // Note that an equivalence class can also contain expression members.
    propagateEquivalenceFromExpressionsToVariables(eqClasses, op.getExpressions(), op.getVariables());
    // Generates FDs.
    List<LogicalVariable> used = new ArrayList<LogicalVariable>();
    VariableUtilities.getUsedVariables(op, used);
    List<FunctionalDependency> fds1 = getOrComputeFDs(inp1, ctx);
    List<FunctionalDependency> eFds = new ArrayList<FunctionalDependency>(fds1.size());
    for (FunctionalDependency fd : fds1) {
        if (fd.getTail().containsAll(used)) {
            List<LogicalVariable> hd = new ArrayList<LogicalVariable>(fd.getHead());
            List<LogicalVariable> tl = new ArrayList<LogicalVariable>(fd.getTail());
            tl.addAll(op.getVariables());
            FunctionalDependency fd2 = new FunctionalDependency(hd, tl);
            eFds.add(fd2);
        } else {
            eFds.add(fd);
        }
    }
    ctx.putFDList(op, eFds);
    return null;
}
#end_block

#method_before
@Override
public Void visitWindowOperator(WindowOperator op, IOptimizationContext ctx) throws AlgebricksException {
    ctx.putEquivalenceClassMap(op, new HashMap<LogicalVariable, EquivalenceClass>());
    ctx.putFDList(op, new ArrayList<FunctionalDependency>());
    return null;
}
#method_after
@Override
public Void visitWindowOperator(WindowOperator op, IOptimizationContext ctx) throws AlgebricksException {
    propagateFDsAndEquivClasses(op, ctx);
    return null;
}
#end_block

#method_before
@Override
public boolean rewritePost(Mutable<ILogicalOperator> opRef, IOptimizationContext context) throws AlgebricksException {
    AbstractLogicalOperator op = (AbstractLogicalOperator) opRef.getValue();
    if (op.getOperatorTag() != LogicalOperatorTag.WINDOW) {
        return false;
    }
    if (context.checkIfInDontApplySet(this, op)) {
        return false;
    }
    context.addToDontApplySet(this, op);
    WindowOperator winOp = (WindowOperator) op;
    boolean rewritten = extractComplexExpressions(winOp, winOp.getPartitionExpressions(), context);
    rewritten |= ExtractOrderExpressionsRule.extractComplexExpressions(winOp, winOp.getOrderExpressions(), context);
    if (rewritten) {
        context.computeAndSetTypeEnvironmentForOperator(op);
    }
    return rewritten;
}
#method_after
@Override
public boolean rewritePost(Mutable<ILogicalOperator> opRef, IOptimizationContext context) throws AlgebricksException {
    AbstractLogicalOperator op = (AbstractLogicalOperator) opRef.getValue();
    if (op.getOperatorTag() != LogicalOperatorTag.WINDOW) {
        return false;
    }
    if (context.checkIfInDontApplySet(this, op)) {
        return false;
    }
    context.addToDontApplySet(this, op);
    WindowOperator winOp = (WindowOperator) op;
    boolean rewritten = ExtractGbyExpressionsRule.extractComplexExpressions(winOp, winOp.getPartitionExpressions(), Function.identity(), context);
    rewritten |= ExtractOrderExpressionsRule.extractComplexExpressions(winOp, winOp.getOrderExpressions(), context);
    if (rewritten) {
        context.computeAndSetTypeEnvironmentForOperator(op);
    }
    return rewritten;
}
#end_block

#method_before
@Override
protected void beginPartitionImpl() throws HyracksDataException {
    runInfo.clear();
    partitionLength = 0;
    if (run != null) {
        run.rewind();
    }
}
#method_after
@Override
protected void beginPartitionImpl() {
    runInfo.clear();
    partitionLength = 0;
    if (run != null) {
        run.rewind();
    }
}
#end_block

#method_before
@Override
protected void partitionChunkImpl(long frameId, ByteBuffer frameBuffer, int tBeginIdx, int tEndIdx) throws HyracksDataException {
    boolean firstChunk = runInfo.isEmpty();
    runInfo.add(tBeginIdx);
    runInfo.add(tEndIdx);
    // save frame. first one to memory, remaining ones to the run file
    if (firstChunk || tBeginIdx == 0) {
        int pos = frameBuffer.position();
        frameBuffer.position(0);
        int nBlocks = FrameHelper.deserializeNumOfMinFrame(frameBuffer);
        if (firstChunk) {
            if (frameId != curFrameId) {
                curFrame.resize(curFrame.getMinSize() * nBlocks);
                curFrame.getBuffer().clear();
                curFrame.getBuffer().put(frameBuffer);
                curFrameId = frameId;
            }
        } else {
            if (run == null) {
                FileReference file = ctx.getJobletContext().createManagedWorkspaceFile(getClass().getSimpleName());
                run = new RunFileWriter(file, ctx.getIoManager());
                run.open();
            }
            run.nextFrame(frameBuffer);
            runInfo.add(nBlocks);
            runLastFrameId = frameId;
        }
        frameBuffer.position(pos);
    }
    partitionLength += tEndIdx - tBeginIdx + 1;
}
#method_after
@Override
protected void partitionChunkImpl(long frameId, ByteBuffer frameBuffer, int tBeginIdx, int tEndIdx) throws HyracksDataException {
    boolean firstChunk = runInfo.isEmpty();
    runInfo.add(tBeginIdx);
    runInfo.add(tEndIdx);
    // save frame. first one to memory, remaining ones to the run file
    if (firstChunk || tBeginIdx == 0) {
        int pos = frameBuffer.position();
        frameBuffer.position(0);
        if (firstChunk) {
            if (frameId != curFrameId) {
                curFrame.resize(curFrame.getMinSize() * FrameHelper.deserializeNumOfMinFrame(frameBuffer));
                curFrame.getBuffer().clear();
                curFrame.getBuffer().put(frameBuffer);
                curFrameId = frameId;
            }
        } else {
            if (run == null) {
                FileReference file = ctx.getJobletContext().createManagedWorkspaceFile(getClass().getSimpleName());
                run = new RunFileWriter(file, ctx.getIoManager());
                run.open();
            }
            run.nextFrame(frameBuffer);
            runLastFrameId = frameId;
        }
        frameBuffer.position(pos);
    }
    partitionLength += tEndIdx - tBeginIdx + 1;
}
#end_block

#method_before
@Override
protected void endPartitionImpl() throws HyracksDataException {
    aggInitPartition(partitionLength);
    GeneratedRunFileReader reader = null;
    try {
        boolean runRead = false;
        for (int idx = 0, ln = runInfo.size(); idx < ln; ) {
            boolean firstChunk = idx == 0;
            int tBeginIdx = runInfo.get(idx++);
            int tEndIdx = runInfo.get(idx++);
            if (tBeginIdx == 0 && !firstChunk) {
                if (reader == null) {
                    reader = run.createReader();
                    reader.open();
                }
                int nBlocks = runInfo.get(idx++);
                curFrame.resize(curFrame.getMinSize() * nBlocks);
                reader.nextFrame(curFrame);
                runRead = true;
            }
            tAccess.reset(curFrame.getBuffer());
            produceTuples(tAccess, tBeginIdx, tEndIdx);
        }
        if (runRead) {
            curFrameId = runLastFrameId;
        }
    } finally {
        if (reader != null) {
            reader.close();
        }
    }
}
#method_after
@Override
protected void endPartitionImpl() throws HyracksDataException {
    aggInitPartition(partitionLength);
    GeneratedRunFileReader reader = null;
    try {
        boolean runRead = false;
        for (int idx = 0, ln = runInfo.size(); idx < ln; idx += 2) {
            int tBeginIdx = runInfo.get(idx);
            int tEndIdx = runInfo.get(idx + 1);
            if (tBeginIdx == 0 && idx > 0) {
                if (reader == null) {
                    reader = run.createReader();
                    reader.open();
                }
                reader.nextFrame(curFrame);
                runRead = true;
            }
            tAccess.reset(curFrame.getBuffer());
            produceTuples(tAccess, tBeginIdx, tEndIdx);
        }
        if (runRead) {
            curFrameId = runLastFrameId;
        }
    } finally {
        if (reader != null) {
            reader.close();
        }
    }
}
#end_block

#method_before
@Override
public void configure(IBinaryComparator[] orderComparators) {
    this.argComparators = orderComparators;
}
#method_after
@Override
public void configure(IBinaryComparator[] orderComparators) {
    argComparators = orderComparators;
}
#end_block

#method_before
private boolean extractComplexExpressions(ILogicalOperator op, List<Pair<LogicalVariable, Mutable<ILogicalExpression>>> exprList, IOptimizationContext context) throws AlgebricksException {
    if (!hasComplexExpressions(exprList)) {
        return false;
    }
    Mutable<ILogicalOperator> opRef2 = op.getInputs().get(0);
    for (Pair<LogicalVariable, Mutable<ILogicalExpression>> pair : exprList) {
        ILogicalExpression expr = pair.second.getValue();
        if (expr.getExpressionTag() != LogicalExpressionTag.VARIABLE) {
            LogicalVariable v = extractExprIntoAssignOpRef(expr, opRef2, context);
            VariableReferenceExpression vRef = new VariableReferenceExpression(v);
            vRef.setSourceLocation(expr.getSourceLocation());
            pair.second.setValue(vRef);
        }
    }
    return true;
}
#method_after
private static boolean extractComplexExpressions(ILogicalOperator op, List<Pair<LogicalVariable, Mutable<ILogicalExpression>>> exprList, IOptimizationContext context) throws AlgebricksException {
    return extractComplexExpressions(op, exprList, Pair::getSecond, context);
}
#end_block

#method_before
private boolean extractComplexExpressions(ILogicalOperator op, List<Pair<LogicalVariable, Mutable<ILogicalExpression>>> exprList, IOptimizationContext context) throws AlgebricksException {
    if (!hasComplexExpressions(exprList)) {
        return false;
    }
    Mutable<ILogicalOperator> opRef2 = op.getInputs().get(0);
    for (Pair<LogicalVariable, Mutable<ILogicalExpression>> pair : exprList) {
        ILogicalExpression expr = pair.second.getValue();
        if (expr.getExpressionTag() != LogicalExpressionTag.VARIABLE) {
            LogicalVariable v = extractExprIntoAssignOpRef(expr, opRef2, context);
            VariableReferenceExpression vRef = new VariableReferenceExpression(v);
            vRef.setSourceLocation(expr.getSourceLocation());
            pair.second.setValue(vRef);
        }
    }
    return true;
}
#method_after
public static <T> boolean extractComplexExpressions(ILogicalOperator op, List<T> exprList, Function<T, Mutable<ILogicalExpression>> exprGetter, IOptimizationContext context) throws AlgebricksException {
    return extractComplexExpressions(op, exprList, exprGetter, t -> false, context);
}
#end_block

#method_before
public void rewind() throws HyracksDataException {
    size = 0;
    maxOutputFrameSize = 0;
}
#method_after
public void rewind() {
    size = 0;
    maxOutputFrameSize = 0;
}
#end_block

#method_before
@Override
public Pair<ILangExpression, VariableSubstitutionEnvironment> visit(WindowExpression winExpr, VariableSubstitutionEnvironment env) throws CompilationException {
    Expression newExpr = (Expression) winExpr.getExpr().accept(this, env).first;
    List<Expression> newPartitionList = winExpr.hasPartitionList() ? VariableCloneAndSubstitutionUtil.visitAndCloneExprList(winExpr.getPartitionList(), env, this) : null;
    List<Expression> newOrderbyList = VariableCloneAndSubstitutionUtil.visitAndCloneExprList(winExpr.getOrderbyList(), env, this);
    List<OrderbyClause.OrderModifier> newOrderbyModifierList = new ArrayList<>(winExpr.getOrderbyModifierList());
    WindowExpression newWinExpr = new WindowExpression(newExpr, newPartitionList, newOrderbyList, newOrderbyModifierList);
    newWinExpr.setSourceLocation(winExpr.getSourceLocation());
    return new Pair<>(newWinExpr, env);
}
#method_after
@Override
public Pair<ILangExpression, VariableSubstitutionEnvironment> visit(WindowExpression winExpr, VariableSubstitutionEnvironment env) throws CompilationException {
    Expression newExpr = (Expression) winExpr.getExpr().accept(this, env).first;
    List<Expression> newPartitionList = winExpr.hasPartitionList() ? VariableCloneAndSubstitutionUtil.visitAndCloneExprList(winExpr.getPartitionList(), env, this) : null;
    List<Expression> newOrderbyList = VariableCloneAndSubstitutionUtil.visitAndCloneExprList(winExpr.getOrderbyList(), env, this);
    List<OrderbyClause.OrderModifier> newOrderbyModifierList = new ArrayList<>(winExpr.getOrderbyModifierList());
    WindowExpression newWinExpr = new WindowExpression(newExpr, newPartitionList, newOrderbyList, newOrderbyModifierList);
    newWinExpr.setSourceLocation(winExpr.getSourceLocation());
    newWinExpr.addHints(winExpr.getHints());
    return new Pair<>(newWinExpr, env);
}
#end_block

#method_before
@Override
protected void channelRead0(ChannelHandlerContext ctx, Object msg) {
    FullHttpRequest request = (FullHttpRequest) msg;
    handler = null;
    task = null;
    closeHandler = null;
    try {
        servlet = server.getServlet(request);
        if (servlet == null) {
            handleServletNotFound(ctx, request);
        } else {
            submit(ctx, servlet, request);
        }
    } catch (Exception e) {
        LOGGER.log(Level.WARN, "Failure Submitting HTTP Request", e);
        respond(ctx, request.protocolVersion(), new HttpResponseStatus(500, e.getMessage()));
    }
}
#method_after
@Override
protected void channelRead0(ChannelHandlerContext ctx, Object msg) {
    FullHttpRequest request = (FullHttpRequest) msg;
    handler = null;
    task = null;
    closeHandler = null;
    try {
        servlet = server.getServlet(request);
        if (servlet == null) {
            handleServletNotFound(ctx, request);
        } else {
            submit(ctx, servlet, request);
        }
    } catch (Exception e) {
        LOGGER.log(Level.WARN, "Failure Submitting HTTP Request", e);
        respond(ctx, request, HttpResponseStatus.INTERNAL_SERVER_ERROR);
    }
}
#end_block

#method_before
protected void respond(ChannelHandlerContext ctx, HttpVersion httpVersion, HttpResponseStatus status) {
    DefaultHttpResponse response = new DefaultHttpResponse(httpVersion, status);
    ctx.writeAndFlush(response);
}
#method_after
protected void respond(ChannelHandlerContext ctx, HttpRequest request, HttpResponseStatus status) {
    final DefaultHttpResponse response = new DefaultFullHttpResponse(request.protocolVersion(), status);
    response.headers().setInt(HttpHeaderNames.CONTENT_LENGTH, 0);
    HttpUtil.setConnectionHeader(request, response);
    final ChannelFuture clientChannel = ctx.writeAndFlush(response);
    if (!io.netty.handler.codec.http.HttpUtil.isKeepAlive(request)) {
        clientChannel.addListener(ChannelFutureListener.CLOSE);
    }
}
#end_block

#method_before
private void submit(ChannelHandlerContext ctx, IServlet servlet, FullHttpRequest request) throws IOException {
    IServletRequest servletRequest;
    try {
        servletRequest = HttpUtil.toServletRequest(request);
    } catch (IllegalArgumentException e) {
        LOGGER.log(Level.WARN, "Failure Decoding Request", e);
        respond(ctx, request.protocolVersion(), HttpResponseStatus.BAD_REQUEST);
        return;
    }
    handler = new HttpRequestHandler(ctx, servlet, servletRequest, chunkSize);
    submit(servlet);
}
#method_after
private void submit(ChannelHandlerContext ctx, IServlet servlet, FullHttpRequest request) throws IOException {
    IServletRequest servletRequest;
    try {
        servletRequest = HttpUtil.toServletRequest(request);
    } catch (IllegalArgumentException e) {
        LOGGER.log(Level.WARN, "Failure Decoding Request", e);
        respond(ctx, request, HttpResponseStatus.BAD_REQUEST);
        return;
    }
    handler = new HttpRequestHandler(ctx, servlet, servletRequest, chunkSize);
    submit(servlet);
}
#end_block

#method_before
protected void handleServletNotFound(ChannelHandlerContext ctx, FullHttpRequest request) {
    if (LOGGER.isDebugEnabled()) {
        LOGGER.debug("No servlet for " + request.uri());
    }
    respond(ctx, request.protocolVersion(), HttpResponseStatus.NOT_FOUND);
}
#method_after
protected void handleServletNotFound(ChannelHandlerContext ctx, FullHttpRequest request) {
    if (LOGGER.isDebugEnabled()) {
        LOGGER.debug("No servlet for " + request.uri());
    }
    respond(ctx, request, HttpResponseStatus.NOT_FOUND);
}
#end_block

#method_before
protected static void validateIfResourceIsActiveInFeed(ICcApplicationContext appCtx, Dataset dataset) throws CompilationException {
    ActiveNotificationHandler activeEventHandler = (ActiveNotificationHandler) appCtx.getActiveNotificationHandler();
    IActiveEntityEventsListener[] listeners = activeEventHandler.getEventListeners();
    for (IActiveEntityEventsListener listener : listeners) {
        if (listener.isEntityUsingDataset(dataset) && listener.isActive()) {
            throw new CompilationException(ErrorCode.COMPILATION_CANT_DROP_ACTIVE_DATASET, dataset.getFullyQualifiedName(), listener.getEntityId().toString());
        }
    }
}
#method_after
protected static void validateIfResourceIsActiveInFeed(ICcApplicationContext appCtx, Dataset dataset, SourceLocation sourceLoc) throws CompilationException {
    ActiveNotificationHandler activeEventHandler = (ActiveNotificationHandler) appCtx.getActiveNotificationHandler();
    IActiveEntityEventsListener[] listeners = activeEventHandler.getEventListeners();
    for (IActiveEntityEventsListener listener : listeners) {
        if (listener.isEntityUsingDataset(dataset) && listener.isActive()) {
            throw new CompilationException(ErrorCode.COMPILATION_CANT_DROP_ACTIVE_DATASET, sourceLoc, dataset.getFullyQualifiedName(), listener.getEntityId().toString());
        }
    }
}
#end_block

#method_before
protected void doCreateIndex(IHyracksClientConnection hcc, MetadataProvider metadataProvider, Dataset ds, Index index, EnumSet<JobFlag> jobFlags, SourceLocation sourceLoc) throws Exception {
    ProgressState progress = ProgressState.NO_PROGRESS;
    boolean bActiveTxn = true;
    Index filesIndex = null;
    boolean firstExternalDatasetIndex = false;
    boolean datasetLocked = false;
    List<ExternalFile> externalFilesSnapshot;
    MetadataTransactionContext mdTxnCtx = metadataProvider.getMetadataTxnContext();
    JobSpecification spec;
    boolean filesIndexReplicated = false;
    try {
        index.setPendingOp(MetadataUtil.PENDING_ADD_OP);
        if (ds.getDatasetType() == DatasetType.INTERNAL) {
            beforeDdlOnDataset(metadataProvider, ds);
        } else {
            // Check if the dataset is indexible
            if (!ExternalIndexingOperations.isIndexible((ExternalDatasetDetails) ds.getDatasetDetails())) {
                throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "dataset using " + ((ExternalDatasetDetails) ds.getDatasetDetails()).getAdapter() + " Adapter can't be indexed");
            }
            // Check if the name of the index is valid
            if (!ExternalIndexingOperations.isValidIndexName(index.getDatasetName(), index.getIndexName())) {
                throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "external dataset index name is invalid");
            }
            // Check if the files index exist
            filesIndex = MetadataManager.INSTANCE.getIndex(metadataProvider.getMetadataTxnContext(), index.getDataverseName(), index.getDatasetName(), IndexingConstants.getFilesIndexName(index.getDatasetName()));
            firstExternalDatasetIndex = filesIndex == null;
            // Lock external dataset
            ExternalDatasetsRegistry.INSTANCE.buildIndexBegin(ds, firstExternalDatasetIndex);
            datasetLocked = true;
            if (firstExternalDatasetIndex) {
                // Verify that no one has created an index before we acquire the lock
                filesIndex = MetadataManager.INSTANCE.getIndex(metadataProvider.getMetadataTxnContext(), index.getDataverseName(), index.getDatasetName(), IndexingConstants.getFilesIndexName(index.getDatasetName()));
                if (filesIndex != null) {
                    ExternalDatasetsRegistry.INSTANCE.buildIndexEnd(ds, firstExternalDatasetIndex);
                    firstExternalDatasetIndex = false;
                    ExternalDatasetsRegistry.INSTANCE.buildIndexBegin(ds, firstExternalDatasetIndex);
                }
            }
            if (firstExternalDatasetIndex) {
                // Get snapshot from External File System
                externalFilesSnapshot = ExternalIndexingOperations.getSnapshotFromExternalFileSystem(ds);
                // Add an entry for the files index
                filesIndex = new Index(index.getDataverseName(), index.getDatasetName(), IndexingConstants.getFilesIndexName(index.getDatasetName()), IndexType.BTREE, ExternalIndexingOperations.FILE_INDEX_FIELD_NAMES, null, ExternalIndexingOperations.FILE_INDEX_FIELD_TYPES, false, false, false, MetadataUtil.PENDING_ADD_OP);
                MetadataManager.INSTANCE.addIndex(metadataProvider.getMetadataTxnContext(), filesIndex);
                // Add files to the external files index
                for (ExternalFile file : externalFilesSnapshot) {
                    MetadataManager.INSTANCE.addExternalFile(mdTxnCtx, file);
                }
                // This is the first index for the external dataset, replicate the files index
                spec = ExternalIndexingOperations.buildFilesIndexCreateJobSpec(ds, externalFilesSnapshot, metadataProvider);
                if (spec == null) {
                    throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "Failed to create job spec for replicating Files Index For external dataset");
                }
                filesIndexReplicated = true;
                runJob(hcc, spec, jobFlags);
            }
        }
        // check whether there exists another enforced index on the same field
        if (index.isEnforced()) {
            List<Index> indexes = MetadataManager.INSTANCE.getDatasetIndexes(metadataProvider.getMetadataTxnContext(), index.getDataverseName(), index.getDatasetName());
            for (Index existingIndex : indexes) {
                if (existingIndex.getKeyFieldNames().equals(index.getKeyFieldNames()) && !existingIndex.getKeyFieldTypes().equals(index.getKeyFieldTypes()) && existingIndex.isEnforced()) {
                    throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "Cannot create index " + index.getIndexName() + " , enforced index " + existingIndex.getIndexName() + " on field \"" + StringUtils.join(index.getKeyFieldNames(), ',') + "\" is already defined with type \"" + existingIndex.getKeyFieldTypes() + "\"");
                }
            }
        }
        // #. add a new index with PendingAddOp
        MetadataManager.INSTANCE.addIndex(metadataProvider.getMetadataTxnContext(), index);
        // #. prepare to create the index artifact in NC.
        spec = IndexUtil.buildSecondaryIndexCreationJobSpec(ds, index, metadataProvider, sourceLoc);
        if (spec == null) {
            throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "Failed to create job spec for creating index '" + ds.getDatasetName() + "." + index.getIndexName() + "'");
        }
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
        bActiveTxn = false;
        progress = ProgressState.ADDED_PENDINGOP_RECORD_TO_METADATA;
        // #. create the index artifact in NC.
        runJob(hcc, spec, jobFlags);
        // of the primary index, which is incorrect.
        if (ds.getDatasetType() == DatasetType.INTERNAL) {
            FlushDatasetUtil.flushDataset(hcc, metadataProvider, index.getDataverseName(), index.getDatasetName());
        }
        mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
        bActiveTxn = true;
        metadataProvider.setMetadataTxnContext(mdTxnCtx);
        // #. load data into the index in NC.
        spec = IndexUtil.buildSecondaryIndexLoadingJobSpec(ds, index, metadataProvider, sourceLoc);
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
        bActiveTxn = false;
        runJob(hcc, spec, jobFlags);
        // #. begin new metadataTxn
        mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
        bActiveTxn = true;
        metadataProvider.setMetadataTxnContext(mdTxnCtx);
        // #. add another new index with PendingNoOp after deleting the index with
        // PendingAddOp
        MetadataManager.INSTANCE.dropIndex(metadataProvider.getMetadataTxnContext(), index.getDataverseName(), index.getDatasetName(), index.getIndexName());
        index.setPendingOp(MetadataUtil.PENDING_NO_OP);
        MetadataManager.INSTANCE.addIndex(metadataProvider.getMetadataTxnContext(), index);
        // PendingAddOp
        if (firstExternalDatasetIndex) {
            MetadataManager.INSTANCE.dropIndex(metadataProvider.getMetadataTxnContext(), index.getDataverseName(), index.getDatasetName(), filesIndex.getIndexName());
            filesIndex.setPendingOp(MetadataUtil.PENDING_NO_OP);
            MetadataManager.INSTANCE.addIndex(metadataProvider.getMetadataTxnContext(), filesIndex);
            // update transaction timestamp
            ((ExternalDatasetDetails) ds.getDatasetDetails()).setRefreshTimestamp(new Date());
            MetadataManager.INSTANCE.updateDataset(mdTxnCtx, ds);
        }
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
    } catch (Exception e) {
        if (bActiveTxn) {
            abort(e, e, mdTxnCtx);
        }
        // on NC side
        if (filesIndexReplicated) {
            mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
            bActiveTxn = true;
            try {
                JobSpecification jobSpec = ExternalIndexingOperations.buildDropFilesIndexJobSpec(metadataProvider, ds);
                MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
                bActiveTxn = false;
                runJob(hcc, jobSpec, jobFlags);
            } catch (Exception e2) {
                e.addSuppressed(e2);
                if (bActiveTxn) {
                    abort(e, e2, mdTxnCtx);
                }
            }
        }
        if (progress == ProgressState.ADDED_PENDINGOP_RECORD_TO_METADATA) {
            // #. execute compensation operations
            // remove the index in NC
            mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
            bActiveTxn = true;
            metadataProvider.setMetadataTxnContext(mdTxnCtx);
            try {
                JobSpecification jobSpec = IndexUtil.buildDropIndexJobSpec(index, metadataProvider, ds, sourceLoc);
                MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
                bActiveTxn = false;
                runJob(hcc, jobSpec, jobFlags);
            } catch (Exception e2) {
                e.addSuppressed(e2);
                if (bActiveTxn) {
                    abort(e, e2, mdTxnCtx);
                }
            }
            if (firstExternalDatasetIndex) {
                mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
                metadataProvider.setMetadataTxnContext(mdTxnCtx);
                try {
                    // Drop External Files from metadata
                    MetadataManager.INSTANCE.dropDatasetExternalFiles(mdTxnCtx, ds);
                    MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
                } catch (Exception e2) {
                    e.addSuppressed(e2);
                    abort(e, e2, mdTxnCtx);
                    throw new IllegalStateException("System is inconsistent state: pending files for(" + index.getDataverseName() + "." + index.getDatasetName() + ") couldn't be removed from the metadata", e);
                }
                mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
                metadataProvider.setMetadataTxnContext(mdTxnCtx);
                try {
                    // Drop the files index from metadata
                    MetadataManager.INSTANCE.dropIndex(metadataProvider.getMetadataTxnContext(), index.getDataverseName(), index.getDatasetName(), IndexingConstants.getFilesIndexName(index.getDatasetName()));
                    MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
                } catch (Exception e2) {
                    e.addSuppressed(e2);
                    abort(e, e2, mdTxnCtx);
                    throw new IllegalStateException("System is inconsistent state: pending index(" + index.getDataverseName() + "." + index.getDatasetName() + "." + IndexingConstants.getFilesIndexName(index.getDatasetName()) + ") couldn't be removed from the metadata", e);
                }
            }
            // remove the record from the metadata.
            mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
            metadataProvider.setMetadataTxnContext(mdTxnCtx);
            try {
                MetadataManager.INSTANCE.dropIndex(metadataProvider.getMetadataTxnContext(), index.getDataverseName(), index.getDatasetName(), index.getIndexName());
                MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
            } catch (Exception e2) {
                e.addSuppressed(e2);
                abort(e, e2, mdTxnCtx);
                throw new IllegalStateException("System is in inconsistent state: pending index(" + index.getDataverseName() + "." + index.getDatasetName() + "." + index.getIndexName() + ") couldn't be removed from the metadata", e);
            }
        }
        throw e;
    } finally {
        if (datasetLocked) {
            ExternalDatasetsRegistry.INSTANCE.buildIndexEnd(ds, firstExternalDatasetIndex);
        }
    }
}
#method_after
protected void doCreateIndex(IHyracksClientConnection hcc, MetadataProvider metadataProvider, Dataset ds, Index index, EnumSet<JobFlag> jobFlags, SourceLocation sourceLoc) throws Exception {
    ProgressState progress = ProgressState.NO_PROGRESS;
    boolean bActiveTxn = true;
    Index filesIndex = null;
    boolean firstExternalDatasetIndex = false;
    boolean datasetLocked = false;
    List<ExternalFile> externalFilesSnapshot;
    MetadataTransactionContext mdTxnCtx = metadataProvider.getMetadataTxnContext();
    JobSpecification spec;
    boolean filesIndexReplicated = false;
    try {
        index.setPendingOp(MetadataUtil.PENDING_ADD_OP);
        if (ds.getDatasetType() == DatasetType.INTERNAL) {
            validateDatasetState(metadataProvider, ds, sourceLoc);
        } else {
            // Check if the dataset is indexible
            if (!ExternalIndexingOperations.isIndexible((ExternalDatasetDetails) ds.getDatasetDetails())) {
                throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "dataset using " + ((ExternalDatasetDetails) ds.getDatasetDetails()).getAdapter() + " Adapter can't be indexed");
            }
            // Check if the name of the index is valid
            if (!ExternalIndexingOperations.isValidIndexName(index.getDatasetName(), index.getIndexName())) {
                throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "external dataset index name is invalid");
            }
            // Check if the files index exist
            filesIndex = MetadataManager.INSTANCE.getIndex(metadataProvider.getMetadataTxnContext(), index.getDataverseName(), index.getDatasetName(), IndexingConstants.getFilesIndexName(index.getDatasetName()));
            firstExternalDatasetIndex = filesIndex == null;
            // Lock external dataset
            ExternalDatasetsRegistry.INSTANCE.buildIndexBegin(ds, firstExternalDatasetIndex);
            datasetLocked = true;
            if (firstExternalDatasetIndex) {
                // Verify that no one has created an index before we acquire the lock
                filesIndex = MetadataManager.INSTANCE.getIndex(metadataProvider.getMetadataTxnContext(), index.getDataverseName(), index.getDatasetName(), IndexingConstants.getFilesIndexName(index.getDatasetName()));
                if (filesIndex != null) {
                    ExternalDatasetsRegistry.INSTANCE.buildIndexEnd(ds, firstExternalDatasetIndex);
                    firstExternalDatasetIndex = false;
                    ExternalDatasetsRegistry.INSTANCE.buildIndexBegin(ds, firstExternalDatasetIndex);
                }
            }
            if (firstExternalDatasetIndex) {
                // Get snapshot from External File System
                externalFilesSnapshot = ExternalIndexingOperations.getSnapshotFromExternalFileSystem(ds);
                // Add an entry for the files index
                filesIndex = new Index(index.getDataverseName(), index.getDatasetName(), IndexingConstants.getFilesIndexName(index.getDatasetName()), IndexType.BTREE, ExternalIndexingOperations.FILE_INDEX_FIELD_NAMES, null, ExternalIndexingOperations.FILE_INDEX_FIELD_TYPES, false, false, false, MetadataUtil.PENDING_ADD_OP);
                MetadataManager.INSTANCE.addIndex(metadataProvider.getMetadataTxnContext(), filesIndex);
                // Add files to the external files index
                for (ExternalFile file : externalFilesSnapshot) {
                    MetadataManager.INSTANCE.addExternalFile(mdTxnCtx, file);
                }
                // This is the first index for the external dataset, replicate the files index
                spec = ExternalIndexingOperations.buildFilesIndexCreateJobSpec(ds, externalFilesSnapshot, metadataProvider);
                if (spec == null) {
                    throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "Failed to create job spec for replicating Files Index For external dataset");
                }
                filesIndexReplicated = true;
                runJob(hcc, spec, jobFlags);
            }
        }
        // check whether there exists another enforced index on the same field
        if (index.isEnforced()) {
            List<Index> indexes = MetadataManager.INSTANCE.getDatasetIndexes(metadataProvider.getMetadataTxnContext(), index.getDataverseName(), index.getDatasetName());
            for (Index existingIndex : indexes) {
                if (existingIndex.getKeyFieldNames().equals(index.getKeyFieldNames()) && !existingIndex.getKeyFieldTypes().equals(index.getKeyFieldTypes()) && existingIndex.isEnforced()) {
                    throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "Cannot create index " + index.getIndexName() + " , enforced index " + existingIndex.getIndexName() + " on field \"" + StringUtils.join(index.getKeyFieldNames(), ',') + "\" is already defined with type \"" + existingIndex.getKeyFieldTypes() + "\"");
                }
            }
        }
        // #. add a new index with PendingAddOp
        MetadataManager.INSTANCE.addIndex(metadataProvider.getMetadataTxnContext(), index);
        // #. prepare to create the index artifact in NC.
        spec = IndexUtil.buildSecondaryIndexCreationJobSpec(ds, index, metadataProvider, sourceLoc);
        if (spec == null) {
            throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "Failed to create job spec for creating index '" + ds.getDatasetName() + "." + index.getIndexName() + "'");
        }
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
        bActiveTxn = false;
        progress = ProgressState.ADDED_PENDINGOP_RECORD_TO_METADATA;
        // #. create the index artifact in NC.
        runJob(hcc, spec, jobFlags);
        // of the primary index, which is incorrect.
        if (ds.getDatasetType() == DatasetType.INTERNAL) {
            FlushDatasetUtil.flushDataset(hcc, metadataProvider, index.getDataverseName(), index.getDatasetName());
        }
        mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
        bActiveTxn = true;
        metadataProvider.setMetadataTxnContext(mdTxnCtx);
        // #. load data into the index in NC.
        spec = IndexUtil.buildSecondaryIndexLoadingJobSpec(ds, index, metadataProvider, sourceLoc);
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
        bActiveTxn = false;
        runJob(hcc, spec, jobFlags);
        // #. begin new metadataTxn
        mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
        bActiveTxn = true;
        metadataProvider.setMetadataTxnContext(mdTxnCtx);
        // #. add another new index with PendingNoOp after deleting the index with
        // PendingAddOp
        MetadataManager.INSTANCE.dropIndex(metadataProvider.getMetadataTxnContext(), index.getDataverseName(), index.getDatasetName(), index.getIndexName());
        index.setPendingOp(MetadataUtil.PENDING_NO_OP);
        MetadataManager.INSTANCE.addIndex(metadataProvider.getMetadataTxnContext(), index);
        // PendingAddOp
        if (firstExternalDatasetIndex) {
            MetadataManager.INSTANCE.dropIndex(metadataProvider.getMetadataTxnContext(), index.getDataverseName(), index.getDatasetName(), filesIndex.getIndexName());
            filesIndex.setPendingOp(MetadataUtil.PENDING_NO_OP);
            MetadataManager.INSTANCE.addIndex(metadataProvider.getMetadataTxnContext(), filesIndex);
            // update transaction timestamp
            ((ExternalDatasetDetails) ds.getDatasetDetails()).setRefreshTimestamp(new Date());
            MetadataManager.INSTANCE.updateDataset(mdTxnCtx, ds);
        }
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
    } catch (Exception e) {
        if (bActiveTxn) {
            abort(e, e, mdTxnCtx);
        }
        // on NC side
        if (filesIndexReplicated) {
            mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
            bActiveTxn = true;
            try {
                JobSpecification jobSpec = ExternalIndexingOperations.buildDropFilesIndexJobSpec(metadataProvider, ds);
                MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
                bActiveTxn = false;
                runJob(hcc, jobSpec, jobFlags);
            } catch (Exception e2) {
                e.addSuppressed(e2);
                if (bActiveTxn) {
                    abort(e, e2, mdTxnCtx);
                }
            }
        }
        if (progress == ProgressState.ADDED_PENDINGOP_RECORD_TO_METADATA) {
            // #. execute compensation operations
            // remove the index in NC
            mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
            bActiveTxn = true;
            metadataProvider.setMetadataTxnContext(mdTxnCtx);
            try {
                JobSpecification jobSpec = IndexUtil.buildDropIndexJobSpec(index, metadataProvider, ds, sourceLoc);
                MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
                bActiveTxn = false;
                runJob(hcc, jobSpec, jobFlags);
            } catch (Exception e2) {
                e.addSuppressed(e2);
                if (bActiveTxn) {
                    abort(e, e2, mdTxnCtx);
                }
            }
            if (firstExternalDatasetIndex) {
                mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
                metadataProvider.setMetadataTxnContext(mdTxnCtx);
                try {
                    // Drop External Files from metadata
                    MetadataManager.INSTANCE.dropDatasetExternalFiles(mdTxnCtx, ds);
                    MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
                } catch (Exception e2) {
                    e.addSuppressed(e2);
                    abort(e, e2, mdTxnCtx);
                    throw new IllegalStateException("System is inconsistent state: pending files for(" + index.getDataverseName() + "." + index.getDatasetName() + ") couldn't be removed from the metadata", e);
                }
                mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
                metadataProvider.setMetadataTxnContext(mdTxnCtx);
                try {
                    // Drop the files index from metadata
                    MetadataManager.INSTANCE.dropIndex(metadataProvider.getMetadataTxnContext(), index.getDataverseName(), index.getDatasetName(), IndexingConstants.getFilesIndexName(index.getDatasetName()));
                    MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
                } catch (Exception e2) {
                    e.addSuppressed(e2);
                    abort(e, e2, mdTxnCtx);
                    throw new IllegalStateException("System is inconsistent state: pending index(" + index.getDataverseName() + "." + index.getDatasetName() + "." + IndexingConstants.getFilesIndexName(index.getDatasetName()) + ") couldn't be removed from the metadata", e);
                }
            }
            // remove the record from the metadata.
            mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
            metadataProvider.setMetadataTxnContext(mdTxnCtx);
            try {
                MetadataManager.INSTANCE.dropIndex(metadataProvider.getMetadataTxnContext(), index.getDataverseName(), index.getDatasetName(), index.getIndexName());
                MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
            } catch (Exception e2) {
                e.addSuppressed(e2);
                abort(e, e2, mdTxnCtx);
                throw new IllegalStateException("System is in inconsistent state: pending index(" + index.getDataverseName() + "." + index.getDatasetName() + "." + index.getIndexName() + ") couldn't be removed from the metadata", e);
            }
        }
        throw e;
    } finally {
        if (datasetLocked) {
            ExternalDatasetsRegistry.INSTANCE.buildIndexEnd(ds, firstExternalDatasetIndex);
        }
    }
}
#end_block

#method_before
public void doDropDataset(String dataverseName, String datasetName, MetadataProvider metadataProvider, boolean ifExists, IHyracksClientConnection hcc, boolean dropCorrespondingNodeGroup, SourceLocation sourceLoc) throws Exception {
    MutableObject<ProgressState> progress = new MutableObject<>(ProgressState.NO_PROGRESS);
    MutableObject<MetadataTransactionContext> mdTxnCtx = new MutableObject<>(MetadataManager.INSTANCE.beginTransaction());
    MutableBoolean bActiveTxn = new MutableBoolean(true);
    metadataProvider.setMetadataTxnContext(mdTxnCtx.getValue());
    List<JobSpecification> jobsToExecute = new ArrayList<>();
    try {
        Dataset ds = metadataProvider.findDataset(dataverseName, datasetName);
        if (ds == null) {
            if (ifExists) {
                MetadataManager.INSTANCE.commitTransaction(mdTxnCtx.getValue());
                return;
            } else {
                throw new CompilationException(ErrorCode.UNKNOWN_DATASET_IN_DATAVERSE, sourceLoc, datasetName, dataverseName);
            }
        }
        beforeDdlOnDataset(metadataProvider, ds);
        ds.drop(metadataProvider, mdTxnCtx, jobsToExecute, bActiveTxn, progress, hcc, dropCorrespondingNodeGroup, sourceLoc);
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx.getValue());
    } catch (Exception e) {
        if (bActiveTxn.booleanValue()) {
            abort(e, e, mdTxnCtx.getValue());
        }
        if (progress.getValue() == ProgressState.ADDED_PENDINGOP_RECORD_TO_METADATA) {
            // remove the all indexes in NC
            try {
                for (JobSpecification jobSpec : jobsToExecute) {
                    JobUtils.runJob(hcc, jobSpec, true);
                }
            } catch (Exception e2) {
                // do no throw exception since still the metadata needs to be compensated.
                e.addSuppressed(e2);
            }
            // remove the record from the metadata.
            mdTxnCtx.setValue(MetadataManager.INSTANCE.beginTransaction());
            metadataProvider.setMetadataTxnContext(mdTxnCtx.getValue());
            try {
                MetadataManager.INSTANCE.dropDataset(metadataProvider.getMetadataTxnContext(), dataverseName, datasetName);
                MetadataManager.INSTANCE.commitTransaction(mdTxnCtx.getValue());
            } catch (Exception e2) {
                e.addSuppressed(e2);
                abort(e, e2, mdTxnCtx.getValue());
                throw new IllegalStateException("System is inconsistent state: pending dataset(" + dataverseName + "." + datasetName + ") couldn't be removed from the metadata", e);
            }
        }
        throw e;
    } finally {
        ExternalDatasetsRegistry.INSTANCE.releaseAcquiredLocks(metadataProvider);
    }
}
#method_after
public void doDropDataset(String dataverseName, String datasetName, MetadataProvider metadataProvider, boolean ifExists, IHyracksClientConnection hcc, boolean dropCorrespondingNodeGroup, SourceLocation sourceLoc) throws Exception {
    MutableObject<ProgressState> progress = new MutableObject<>(ProgressState.NO_PROGRESS);
    MutableObject<MetadataTransactionContext> mdTxnCtx = new MutableObject<>(MetadataManager.INSTANCE.beginTransaction());
    MutableBoolean bActiveTxn = new MutableBoolean(true);
    metadataProvider.setMetadataTxnContext(mdTxnCtx.getValue());
    List<JobSpecification> jobsToExecute = new ArrayList<>();
    try {
        Dataset ds = metadataProvider.findDataset(dataverseName, datasetName);
        if (ds == null) {
            if (ifExists) {
                MetadataManager.INSTANCE.commitTransaction(mdTxnCtx.getValue());
                return;
            } else {
                throw new CompilationException(ErrorCode.UNKNOWN_DATASET_IN_DATAVERSE, sourceLoc, datasetName, dataverseName);
            }
        }
        validateDatasetState(metadataProvider, ds, sourceLoc);
        ds.drop(metadataProvider, mdTxnCtx, jobsToExecute, bActiveTxn, progress, hcc, dropCorrespondingNodeGroup, sourceLoc);
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx.getValue());
    } catch (Exception e) {
        if (bActiveTxn.booleanValue()) {
            abort(e, e, mdTxnCtx.getValue());
        }
        if (progress.getValue() == ProgressState.ADDED_PENDINGOP_RECORD_TO_METADATA) {
            // remove the all indexes in NC
            try {
                for (JobSpecification jobSpec : jobsToExecute) {
                    JobUtils.runJob(hcc, jobSpec, true);
                }
            } catch (Exception e2) {
                // do no throw exception since still the metadata needs to be compensated.
                e.addSuppressed(e2);
            }
            // remove the record from the metadata.
            mdTxnCtx.setValue(MetadataManager.INSTANCE.beginTransaction());
            metadataProvider.setMetadataTxnContext(mdTxnCtx.getValue());
            try {
                MetadataManager.INSTANCE.dropDataset(metadataProvider.getMetadataTxnContext(), dataverseName, datasetName);
                MetadataManager.INSTANCE.commitTransaction(mdTxnCtx.getValue());
            } catch (Exception e2) {
                e.addSuppressed(e2);
                abort(e, e2, mdTxnCtx.getValue());
                throw new IllegalStateException("System is inconsistent state: pending dataset(" + dataverseName + "." + datasetName + ") couldn't be removed from the metadata", e);
            }
        }
        throw e;
    } finally {
        ExternalDatasetsRegistry.INSTANCE.releaseAcquiredLocks(metadataProvider);
    }
}
#end_block

#method_before
protected void handleIndexDropStatement(MetadataProvider metadataProvider, Statement stmt, IHyracksClientConnection hcc, IRequestParameters requestParameters) throws Exception {
    IndexDropStatement stmtIndexDrop = (IndexDropStatement) stmt;
    SourceLocation sourceLoc = stmtIndexDrop.getSourceLocation();
    String datasetName = stmtIndexDrop.getDatasetName().getValue();
    String dataverseName = getActiveDataverse(stmtIndexDrop.getDataverseName());
    String indexName = stmtIndexDrop.getIndexName().getValue();
    ProgressState progress = ProgressState.NO_PROGRESS;
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    boolean bActiveTxn = true;
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    List<JobSpecification> jobsToExecute = new ArrayList<>();
    String dsFullyQualifiedName = dataverseName + "." + datasetName;
    MetadataLockUtil.dropIndexBegin(lockManager, metadataProvider.getLocks(), dataverseName, dsFullyQualifiedName);
    // For external index
    boolean dropFilesIndex = false;
    try {
        Dataset ds = metadataProvider.findDataset(dataverseName, datasetName);
        if (ds == null) {
            throw new CompilationException(ErrorCode.UNKNOWN_DATASET_IN_DATAVERSE, sourceLoc, datasetName, dataverseName);
        }
        if (ds.getDatasetType() == DatasetType.INTERNAL) {
            Index index = MetadataManager.INSTANCE.getIndex(mdTxnCtx, dataverseName, datasetName, indexName);
            if (index == null) {
                if (stmtIndexDrop.getIfExists()) {
                    MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
                    return;
                } else {
                    throw new CompilationException(ErrorCode.UNKNOWN_INDEX, sourceLoc, indexName);
                }
            }
            ensureNonPrimaryIndexDrop(index, sourceLoc);
            beforeDdlOnDataset(metadataProvider, ds);
            // #. prepare a job to drop the index in NC.
            jobsToExecute.add(IndexUtil.buildDropIndexJobSpec(index, metadataProvider, ds, sourceLoc));
            // #. mark PendingDropOp on the existing index
            MetadataManager.INSTANCE.dropIndex(mdTxnCtx, dataverseName, datasetName, indexName);
            MetadataManager.INSTANCE.addIndex(mdTxnCtx, new Index(dataverseName, datasetName, indexName, index.getIndexType(), index.getKeyFieldNames(), index.getKeyFieldSourceIndicators(), index.getKeyFieldTypes(), index.isOverridingKeyFieldTypes(), index.isEnforced(), index.isPrimaryIndex(), MetadataUtil.PENDING_DROP_OP));
            // #. commit the existing transaction before calling runJob.
            MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
            bActiveTxn = false;
            progress = ProgressState.ADDED_PENDINGOP_RECORD_TO_METADATA;
            for (JobSpecification jobSpec : jobsToExecute) {
                runJob(hcc, jobSpec);
            }
            // #. begin a new transaction
            mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
            bActiveTxn = true;
            metadataProvider.setMetadataTxnContext(mdTxnCtx);
            // #. finally, delete the existing index
            MetadataManager.INSTANCE.dropIndex(mdTxnCtx, dataverseName, datasetName, indexName);
        } else {
            // External dataset
            indexName = stmtIndexDrop.getIndexName().getValue();
            Index index = MetadataManager.INSTANCE.getIndex(mdTxnCtx, dataverseName, datasetName, indexName);
            if (index == null) {
                if (stmtIndexDrop.getIfExists()) {
                    MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
                    return;
                } else {
                    throw new CompilationException(ErrorCode.UNKNOWN_INDEX, sourceLoc, indexName);
                }
            } else if (ExternalIndexingOperations.isFileIndex(index)) {
                throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "Dropping a dataset's files index is not allowed.");
            }
            ensureNonPrimaryIndexDrop(index, sourceLoc);
            // #. prepare a job to drop the index in NC.
            jobsToExecute.add(IndexUtil.buildDropIndexJobSpec(index, metadataProvider, ds, sourceLoc));
            List<Index> datasetIndexes = MetadataManager.INSTANCE.getDatasetIndexes(mdTxnCtx, dataverseName, datasetName);
            if (datasetIndexes.size() == 2) {
                dropFilesIndex = true;
                // only one index + the files index, we need to delete both of the indexes
                for (Index externalIndex : datasetIndexes) {
                    if (ExternalIndexingOperations.isFileIndex(externalIndex)) {
                        jobsToExecute.add(ExternalIndexingOperations.buildDropFilesIndexJobSpec(metadataProvider, ds));
                        // #. mark PendingDropOp on the existing files index
                        MetadataManager.INSTANCE.dropIndex(mdTxnCtx, dataverseName, datasetName, externalIndex.getIndexName());
                        MetadataManager.INSTANCE.addIndex(mdTxnCtx, new Index(dataverseName, datasetName, externalIndex.getIndexName(), externalIndex.getIndexType(), externalIndex.getKeyFieldNames(), externalIndex.getKeyFieldSourceIndicators(), index.getKeyFieldTypes(), index.isOverridingKeyFieldTypes(), index.isEnforced(), externalIndex.isPrimaryIndex(), MetadataUtil.PENDING_DROP_OP));
                    }
                }
            }
            // #. mark PendingDropOp on the existing index
            MetadataManager.INSTANCE.dropIndex(mdTxnCtx, dataverseName, datasetName, indexName);
            MetadataManager.INSTANCE.addIndex(mdTxnCtx, new Index(dataverseName, datasetName, indexName, index.getIndexType(), index.getKeyFieldNames(), index.getKeyFieldSourceIndicators(), index.getKeyFieldTypes(), index.isOverridingKeyFieldTypes(), index.isEnforced(), index.isPrimaryIndex(), MetadataUtil.PENDING_DROP_OP));
            // #. commit the existing transaction before calling runJob.
            MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
            bActiveTxn = false;
            progress = ProgressState.ADDED_PENDINGOP_RECORD_TO_METADATA;
            for (JobSpecification jobSpec : jobsToExecute) {
                runJob(hcc, jobSpec);
            }
            // #. begin a new transaction
            mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
            bActiveTxn = true;
            metadataProvider.setMetadataTxnContext(mdTxnCtx);
            // #. finally, delete the existing index
            MetadataManager.INSTANCE.dropIndex(mdTxnCtx, dataverseName, datasetName, indexName);
            if (dropFilesIndex) {
                // delete the files index too
                MetadataManager.INSTANCE.dropIndex(mdTxnCtx, dataverseName, datasetName, IndexingConstants.getFilesIndexName(datasetName));
                MetadataManager.INSTANCE.dropDatasetExternalFiles(mdTxnCtx, ds);
                ExternalDatasetsRegistry.INSTANCE.removeDatasetInfo(ds);
            }
        }
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
    } catch (Exception e) {
        if (bActiveTxn) {
            abort(e, e, mdTxnCtx);
        }
        if (progress == ProgressState.ADDED_PENDINGOP_RECORD_TO_METADATA) {
            // remove the all indexes in NC
            try {
                for (JobSpecification jobSpec : jobsToExecute) {
                    runJob(hcc, jobSpec);
                }
            } catch (Exception e2) {
                // do no throw exception since still the metadata needs to be compensated.
                e.addSuppressed(e2);
            }
            // remove the record from the metadata.
            mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
            metadataProvider.setMetadataTxnContext(mdTxnCtx);
            try {
                MetadataManager.INSTANCE.dropIndex(metadataProvider.getMetadataTxnContext(), dataverseName, datasetName, indexName);
                if (dropFilesIndex) {
                    MetadataManager.INSTANCE.dropIndex(metadataProvider.getMetadataTxnContext(), dataverseName, datasetName, IndexingConstants.getFilesIndexName(datasetName));
                }
                MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
            } catch (Exception e2) {
                e.addSuppressed(e2);
                abort(e, e2, mdTxnCtx);
                throw new IllegalStateException("System is inconsistent state: pending index(" + dataverseName + "." + datasetName + "." + indexName + ") couldn't be removed from the metadata", e);
            }
        }
        throw e;
    } finally {
        metadataProvider.getLocks().unlock();
        ExternalDatasetsRegistry.INSTANCE.releaseAcquiredLocks(metadataProvider);
    }
}
#method_after
protected void handleIndexDropStatement(MetadataProvider metadataProvider, Statement stmt, IHyracksClientConnection hcc, IRequestParameters requestParameters) throws Exception {
    IndexDropStatement stmtIndexDrop = (IndexDropStatement) stmt;
    SourceLocation sourceLoc = stmtIndexDrop.getSourceLocation();
    String datasetName = stmtIndexDrop.getDatasetName().getValue();
    String dataverseName = getActiveDataverse(stmtIndexDrop.getDataverseName());
    String indexName = stmtIndexDrop.getIndexName().getValue();
    ProgressState progress = ProgressState.NO_PROGRESS;
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    boolean bActiveTxn = true;
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    List<JobSpecification> jobsToExecute = new ArrayList<>();
    String dsFullyQualifiedName = dataverseName + "." + datasetName;
    MetadataLockUtil.dropIndexBegin(lockManager, metadataProvider.getLocks(), dataverseName, dsFullyQualifiedName);
    // For external index
    boolean dropFilesIndex = false;
    try {
        Dataset ds = metadataProvider.findDataset(dataverseName, datasetName);
        if (ds == null) {
            throw new CompilationException(ErrorCode.UNKNOWN_DATASET_IN_DATAVERSE, sourceLoc, datasetName, dataverseName);
        }
        if (ds.getDatasetType() == DatasetType.INTERNAL) {
            Index index = MetadataManager.INSTANCE.getIndex(mdTxnCtx, dataverseName, datasetName, indexName);
            if (index == null) {
                if (stmtIndexDrop.getIfExists()) {
                    MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
                    return;
                } else {
                    throw new CompilationException(ErrorCode.UNKNOWN_INDEX, sourceLoc, indexName);
                }
            }
            ensureNonPrimaryIndexDrop(index, sourceLoc);
            validateDatasetState(metadataProvider, ds, sourceLoc);
            // #. prepare a job to drop the index in NC.
            jobsToExecute.add(IndexUtil.buildDropIndexJobSpec(index, metadataProvider, ds, sourceLoc));
            // #. mark PendingDropOp on the existing index
            MetadataManager.INSTANCE.dropIndex(mdTxnCtx, dataverseName, datasetName, indexName);
            MetadataManager.INSTANCE.addIndex(mdTxnCtx, new Index(dataverseName, datasetName, indexName, index.getIndexType(), index.getKeyFieldNames(), index.getKeyFieldSourceIndicators(), index.getKeyFieldTypes(), index.isOverridingKeyFieldTypes(), index.isEnforced(), index.isPrimaryIndex(), MetadataUtil.PENDING_DROP_OP));
            // #. commit the existing transaction before calling runJob.
            MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
            bActiveTxn = false;
            progress = ProgressState.ADDED_PENDINGOP_RECORD_TO_METADATA;
            for (JobSpecification jobSpec : jobsToExecute) {
                runJob(hcc, jobSpec);
            }
            // #. begin a new transaction
            mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
            bActiveTxn = true;
            metadataProvider.setMetadataTxnContext(mdTxnCtx);
            // #. finally, delete the existing index
            MetadataManager.INSTANCE.dropIndex(mdTxnCtx, dataverseName, datasetName, indexName);
        } else {
            // External dataset
            indexName = stmtIndexDrop.getIndexName().getValue();
            Index index = MetadataManager.INSTANCE.getIndex(mdTxnCtx, dataverseName, datasetName, indexName);
            if (index == null) {
                if (stmtIndexDrop.getIfExists()) {
                    MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
                    return;
                } else {
                    throw new CompilationException(ErrorCode.UNKNOWN_INDEX, sourceLoc, indexName);
                }
            } else if (ExternalIndexingOperations.isFileIndex(index)) {
                throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "Dropping a dataset's files index is not allowed.");
            }
            ensureNonPrimaryIndexDrop(index, sourceLoc);
            // #. prepare a job to drop the index in NC.
            jobsToExecute.add(IndexUtil.buildDropIndexJobSpec(index, metadataProvider, ds, sourceLoc));
            List<Index> datasetIndexes = MetadataManager.INSTANCE.getDatasetIndexes(mdTxnCtx, dataverseName, datasetName);
            if (datasetIndexes.size() == 2) {
                dropFilesIndex = true;
                // only one index + the files index, we need to delete both of the indexes
                for (Index externalIndex : datasetIndexes) {
                    if (ExternalIndexingOperations.isFileIndex(externalIndex)) {
                        jobsToExecute.add(ExternalIndexingOperations.buildDropFilesIndexJobSpec(metadataProvider, ds));
                        // #. mark PendingDropOp on the existing files index
                        MetadataManager.INSTANCE.dropIndex(mdTxnCtx, dataverseName, datasetName, externalIndex.getIndexName());
                        MetadataManager.INSTANCE.addIndex(mdTxnCtx, new Index(dataverseName, datasetName, externalIndex.getIndexName(), externalIndex.getIndexType(), externalIndex.getKeyFieldNames(), externalIndex.getKeyFieldSourceIndicators(), index.getKeyFieldTypes(), index.isOverridingKeyFieldTypes(), index.isEnforced(), externalIndex.isPrimaryIndex(), MetadataUtil.PENDING_DROP_OP));
                    }
                }
            }
            // #. mark PendingDropOp on the existing index
            MetadataManager.INSTANCE.dropIndex(mdTxnCtx, dataverseName, datasetName, indexName);
            MetadataManager.INSTANCE.addIndex(mdTxnCtx, new Index(dataverseName, datasetName, indexName, index.getIndexType(), index.getKeyFieldNames(), index.getKeyFieldSourceIndicators(), index.getKeyFieldTypes(), index.isOverridingKeyFieldTypes(), index.isEnforced(), index.isPrimaryIndex(), MetadataUtil.PENDING_DROP_OP));
            // #. commit the existing transaction before calling runJob.
            MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
            bActiveTxn = false;
            progress = ProgressState.ADDED_PENDINGOP_RECORD_TO_METADATA;
            for (JobSpecification jobSpec : jobsToExecute) {
                runJob(hcc, jobSpec);
            }
            // #. begin a new transaction
            mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
            bActiveTxn = true;
            metadataProvider.setMetadataTxnContext(mdTxnCtx);
            // #. finally, delete the existing index
            MetadataManager.INSTANCE.dropIndex(mdTxnCtx, dataverseName, datasetName, indexName);
            if (dropFilesIndex) {
                // delete the files index too
                MetadataManager.INSTANCE.dropIndex(mdTxnCtx, dataverseName, datasetName, IndexingConstants.getFilesIndexName(datasetName));
                MetadataManager.INSTANCE.dropDatasetExternalFiles(mdTxnCtx, ds);
                ExternalDatasetsRegistry.INSTANCE.removeDatasetInfo(ds);
            }
        }
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
    } catch (Exception e) {
        if (bActiveTxn) {
            abort(e, e, mdTxnCtx);
        }
        if (progress == ProgressState.ADDED_PENDINGOP_RECORD_TO_METADATA) {
            // remove the all indexes in NC
            try {
                for (JobSpecification jobSpec : jobsToExecute) {
                    runJob(hcc, jobSpec);
                }
            } catch (Exception e2) {
                // do no throw exception since still the metadata needs to be compensated.
                e.addSuppressed(e2);
            }
            // remove the record from the metadata.
            mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
            metadataProvider.setMetadataTxnContext(mdTxnCtx);
            try {
                MetadataManager.INSTANCE.dropIndex(metadataProvider.getMetadataTxnContext(), dataverseName, datasetName, indexName);
                if (dropFilesIndex) {
                    MetadataManager.INSTANCE.dropIndex(metadataProvider.getMetadataTxnContext(), dataverseName, datasetName, IndexingConstants.getFilesIndexName(datasetName));
                }
                MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
            } catch (Exception e2) {
                e.addSuppressed(e2);
                abort(e, e2, mdTxnCtx);
                throw new IllegalStateException("System is inconsistent state: pending index(" + dataverseName + "." + datasetName + "." + indexName + ") couldn't be removed from the metadata", e);
            }
        }
        throw e;
    } finally {
        metadataProvider.getLocks().unlock();
        ExternalDatasetsRegistry.INSTANCE.releaseAcquiredLocks(metadataProvider);
    }
}
#end_block

#method_before
@Override
public ISerializedAggregateEvaluatorFactory createSerializableAggregateEvaluatorFactory(final IScalarEvaluatorFactory[] args) throws AlgebricksException {
    return new ISerializedAggregateEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public ISerializedAggregateEvaluator createAggregateEvaluator(IHyracksTaskContext ctx) throws HyracksDataException {
            return new SerializableStddevPopAggregateFunction(args, ctx, sourceLoc);
        }
    };
}
#method_after
@Override
public ISerializedAggregateEvaluatorFactory createSerializableAggregateEvaluatorFactory(final IScalarEvaluatorFactory[] args) throws AlgebricksException {
    return new ISerializedAggregateEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public ISerializedAggregateEvaluator createAggregateEvaluator(IHyracksTaskContext ctx) throws HyracksDataException {
            return new SerializableStddevAggregateFunction(args, ctx, true, sourceLoc);
        }
    };
}
#end_block

#method_before
@Override
public ISerializedAggregateEvaluatorFactory createSerializableAggregateEvaluatorFactory(final IScalarEvaluatorFactory[] args) {
    return new ISerializedAggregateEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public ISerializedAggregateEvaluator createAggregateEvaluator(IHyracksTaskContext ctx) throws HyracksDataException {
            return new SerializableGlobalStddevPopAggregateFunction(args, ctx, sourceLoc);
        }
    };
}
#method_after
@Override
public ISerializedAggregateEvaluatorFactory createSerializableAggregateEvaluatorFactory(final IScalarEvaluatorFactory[] args) {
    return new ISerializedAggregateEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public ISerializedAggregateEvaluator createAggregateEvaluator(IHyracksTaskContext ctx) throws HyracksDataException {
            return new SerializableGlobalStddevAggregateFunction(args, ctx, true, sourceLoc);
        }
    };
}
#end_block

#method_before
protected void finishStddevFinalResults(byte[] state, int start, int len, DataOutput result) throws HyracksDataException {
    double m2 = BufferSerDeUtil.getDouble(state, start + M2_OFFSET);
    long count = BufferSerDeUtil.getLong(state, start + COUNT_OFFSET);
    ATypeTag aggType = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(state[start + AGG_TYPE_OFFSET]);
    try {
        if (count <= 1 || aggType == ATypeTag.NULL) {
            nullSerde.serialize(ANull.NULL, result);
        } else {
            aDouble.setValue(Math.sqrt(m2 / (count - 1)));
            doubleSerde.serialize(aDouble, result);
        }
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    }
}
#method_after
protected void finishStddevFinalResults(byte[] state, int start, int len, DataOutput result, int delta) throws HyracksDataException {
    double m2 = BufferSerDeUtil.getDouble(state, start + M2_OFFSET);
    long count = BufferSerDeUtil.getLong(state, start + COUNT_OFFSET);
    ATypeTag aggType = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(state[start + AGG_TYPE_OFFSET]);
    try {
        if (count <= 1 || aggType == ATypeTag.NULL) {
            nullSerde.serialize(ANull.NULL, result);
        } else {
            aDouble.setValue(Math.sqrt(m2 / (count - delta)));
            doubleSerde.serialize(aDouble, result);
        }
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    }
}
#end_block

#method_before
@Override
public ISerializedAggregateEvaluatorFactory createSerializableAggregateEvaluatorFactory(final IScalarEvaluatorFactory[] args) {
    return new ISerializedAggregateEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public ISerializedAggregateEvaluator createAggregateEvaluator(IHyracksTaskContext ctx) throws HyracksDataException {
            return new SerializableSqlStddevPopAggregateFunction(args, ctx, sourceLoc);
        }
    };
}
#method_after
@Override
public ISerializedAggregateEvaluatorFactory createSerializableAggregateEvaluatorFactory(final IScalarEvaluatorFactory[] args) {
    return new ISerializedAggregateEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public ISerializedAggregateEvaluator createAggregateEvaluator(IHyracksTaskContext ctx) throws HyracksDataException {
            return new SerializableSqlStddevAggregateFunction(args, ctx, true, sourceLoc);
        }
    };
}
#end_block

#method_before
protected void finishStddevFinalResults(IPointable result) throws HyracksDataException {
    resultStorage.reset();
    try {
        if (moments.getCount() <= 1 || aggType == ATypeTag.NULL) {
            nullSerde.serialize(ANull.NULL, resultStorage.getDataOutput());
        } else {
            aDouble.setValue(Math.sqrt(moments.getM2() / (moments.getCount() - 1)));
            doubleSerde.serialize(aDouble, resultStorage.getDataOutput());
        }
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    }
    result.set(resultStorage);
}
#method_after
protected void finishStddevFinalResults(IPointable result, int delta) throws HyracksDataException {
    resultStorage.reset();
    try {
        if (moments.getCount() <= 1 || aggType == ATypeTag.NULL) {
            nullSerde.serialize(ANull.NULL, resultStorage.getDataOutput());
        } else {
            aDouble.setValue(Math.sqrt(moments.getM2() / (moments.getCount() - delta)));
            doubleSerde.serialize(aDouble, resultStorage.getDataOutput());
        }
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    }
    result.set(resultStorage);
}
#end_block

#method_before
public static FunctionCollection createDefaultFunctionCollection() {
    FunctionCollection fc = new FunctionCollection();
    // array functions
    fc.add(ArrayRemoveDescriptor.FACTORY);
    fc.add(ArrayPutDescriptor.FACTORY);
    fc.add(ArrayPrependDescriptor.FACTORY);
    fc.add(ArrayAppendDescriptor.FACTORY);
    fc.add(ArrayInsertDescriptor.FACTORY);
    fc.addGenerated(ArrayPositionDescriptor.FACTORY);
    fc.addGenerated(ArrayRepeatDescriptor.FACTORY);
    fc.addGenerated(ArrayContainsDescriptor.FACTORY);
    fc.addGenerated(ArrayReverseDescriptor.FACTORY);
    fc.addGenerated(ArraySortDescriptor.FACTORY);
    fc.addGenerated(ArrayDistinctDescriptor.FACTORY);
    fc.addGenerated(ArrayUnionDescriptor.FACTORY);
    fc.addGenerated(ArrayIntersectDescriptor.FACTORY);
    fc.addGenerated(ArrayIfNullDescriptor.FACTORY);
    fc.addGenerated(ArrayConcatDescriptor.FACTORY);
    fc.addGenerated(ArrayRangeDescriptor.FACTORY);
    fc.addGenerated(ArrayFlattenDescriptor.FACTORY);
    fc.add(ArrayReplaceDescriptor.FACTORY);
    fc.addGenerated(ArraySymDiffDescriptor.FACTORY);
    fc.addGenerated(ArraySymDiffnDescriptor.FACTORY);
    fc.addGenerated(ArrayStarDescriptor.FACTORY);
    // unnesting functions
    fc.add(TidRunningAggregateDescriptor.FACTORY);
    fc.add(ScanCollectionDescriptor.FACTORY);
    fc.add(RangeDescriptor.FACTORY);
    fc.add(SubsetCollectionDescriptor.FACTORY);
    // aggregate functions
    fc.add(ListifyAggregateDescriptor.FACTORY);
    fc.add(CountAggregateDescriptor.FACTORY);
    fc.add(AvgAggregateDescriptor.FACTORY);
    fc.add(LocalAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SumAggregateDescriptor.FACTORY);
    fc.add(LocalSumAggregateDescriptor.FACTORY);
    fc.add(MaxAggregateDescriptor.FACTORY);
    fc.add(LocalMaxAggregateDescriptor.FACTORY);
    fc.add(MinAggregateDescriptor.FACTORY);
    fc.add(LocalMinAggregateDescriptor.FACTORY);
    fc.add(FirstElementAggregateDescriptor.FACTORY);
    fc.add(LocalFirstElementAggregateDescriptor.FACTORY);
    fc.add(StddevAggregateDescriptor.FACTORY);
    fc.add(LocalStddevAggregateDescriptor.FACTORY);
    fc.add(IntermediateStddevAggregateDescriptor.FACTORY);
    fc.add(GlobalStddevAggregateDescriptor.FACTORY);
    fc.add(StddevPopAggregateDescriptor.FACTORY);
    fc.add(LocalStddevPopAggregateDescriptor.FACTORY);
    fc.add(IntermediateStddevPopAggregateDescriptor.FACTORY);
    fc.add(GlobalStddevPopAggregateDescriptor.FACTORY);
    // serializable aggregates
    fc.add(SerializableCountAggregateDescriptor.FACTORY);
    fc.add(SerializableAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSumAggregateDescriptor.FACTORY);
    fc.add(SerializableStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalStddevPopAggregateDescriptor.FACTORY);
    // scalar aggregates
    fc.add(ScalarCountAggregateDescriptor.FACTORY);
    fc.add(ScalarAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSumAggregateDescriptor.FACTORY);
    fc.add(ScalarMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarMinAggregateDescriptor.FACTORY);
    fc.add(EmptyStreamAggregateDescriptor.FACTORY);
    fc.add(NonEmptyStreamAggregateDescriptor.FACTORY);
    fc.add(ScalarStddevAggregateDescriptor.FACTORY);
    fc.add(ScalarStddevPopAggregateDescriptor.FACTORY);
    // SQL aggregates
    fc.add(SqlCountAggregateDescriptor.FACTORY);
    fc.add(SqlAvgAggregateDescriptor.FACTORY);
    fc.add(LocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SqlSumAggregateDescriptor.FACTORY);
    fc.add(LocalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SqlMaxAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMaxAggregateDescriptor.FACTORY);
    fc.add(SqlMinAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMinAggregateDescriptor.FACTORY);
    fc.add(SqlStddevAggregateDescriptor.FACTORY);
    fc.add(LocalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlStddevAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(LocalSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlStddevPopAggregateDescriptor.FACTORY);
    // SQL serializable aggregates
    fc.add(SerializableSqlCountAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlStddevPopAggregateDescriptor.FACTORY);
    // SQL scalar aggregates
    fc.add(ScalarSqlCountAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlSumAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMinAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlStddevAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlStddevPopAggregateDescriptor.FACTORY);
    // boolean functions
    fc.add(AndDescriptor.FACTORY);
    fc.add(OrDescriptor.FACTORY);
    // Record constructors / functions
    fc.add(ClosedRecordConstructorDescriptor.FACTORY);
    fc.add(OpenRecordConstructorDescriptor.FACTORY);
    fc.add(RecordConcatDescriptor.FACTORY);
    fc.add(RecordConcatStrictDescriptor.FACTORY);
    // List constructors
    fc.add(OrderedListConstructorDescriptor.FACTORY);
    fc.add(UnorderedListConstructorDescriptor.FACTORY);
    // Sleep function
    fc.add(SleepDescriptor.FACTORY);
    // Inject failure function
    fc.add(InjectFailureDescriptor.FACTORY);
    // Get Job Parameter function
    fc.add(GetJobParameterByNameDescriptor.FACTORY);
    // Switch case
    fc.add(SwitchCaseDescriptor.FACTORY);
    // null functions
    fc.add(IsMissingDescriptor.FACTORY);
    fc.add(IsNullDescriptor.FACTORY);
    fc.add(IsUnknownDescriptor.FACTORY);
    fc.add(IsSystemNullDescriptor.FACTORY);
    fc.add(CheckUnknownDescriptor.FACTORY);
    fc.add(IfMissingDescriptor.FACTORY);
    fc.add(IfNullDescriptor.FACTORY);
    fc.add(IfMissingOrNullDescriptor.FACTORY);
    // uuid generators (zero independent functions)
    fc.add(CreateUUIDDescriptor.FACTORY);
    fc.add(UUIDDescriptor.FACTORY);
    fc.add(CreateQueryUIDDescriptor.FACTORY);
    fc.add(RandomDescriptor.FACTORY);
    fc.add(CurrentDateDescriptor.FACTORY);
    fc.add(CurrentTimeDescriptor.FACTORY);
    fc.add(CurrentDateTimeDescriptor.FACTORY);
    // functions that need generated class for null-handling.
    // Element accessors.
    fc.addGenerated(FieldAccessByIndexDescriptor.FACTORY);
    fc.addGenerated(FieldAccessByNameDescriptor.FACTORY);
    fc.addGenerated(FieldAccessNestedDescriptor.FACTORY);
    fc.addGenerated(AnyCollectionMemberDescriptor.FACTORY);
    fc.addGenerated(GetItemDescriptor.FACTORY);
    // Numeric functions
    fc.add(IfInfDescriptor.FACTORY);
    fc.add(IfNanDescriptor.FACTORY);
    fc.add(IfNanOrInfDescriptor.FACTORY);
    fc.addGenerated(NumericUnaryMinusDescriptor.FACTORY);
    fc.addGenerated(NumericAddDescriptor.FACTORY);
    fc.addGenerated(NumericDivideDescriptor.FACTORY);
    fc.addGenerated(NumericDivDescriptor.FACTORY);
    fc.addGenerated(NumericMultiplyDescriptor.FACTORY);
    fc.addGenerated(NumericSubDescriptor.FACTORY);
    fc.addGenerated(NumericModuloDescriptor.FACTORY);
    fc.addGenerated(NumericPowerDescriptor.FACTORY);
    fc.addGenerated(NotDescriptor.FACTORY);
    fc.addGenerated(LenDescriptor.FACTORY);
    fc.addGenerated(NumericAbsDescriptor.FACTORY);
    fc.addGenerated(NumericCeilingDescriptor.FACTORY);
    fc.addGenerated(NumericFloorDescriptor.FACTORY);
    fc.addGenerated(NumericRoundDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEvenDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEven2Descriptor.FACTORY);
    fc.addGenerated(NumericACosDescriptor.FACTORY);
    fc.addGenerated(NumericASinDescriptor.FACTORY);
    fc.addGenerated(NumericATanDescriptor.FACTORY);
    fc.addGenerated(NumericDegreesDescriptor.FACTORY);
    fc.addGenerated(NumericRadiansDescriptor.FACTORY);
    fc.addGenerated(NumericCosDescriptor.FACTORY);
    fc.addGenerated(NumericSinDescriptor.FACTORY);
    fc.addGenerated(NumericTanDescriptor.FACTORY);
    fc.addGenerated(NumericExpDescriptor.FACTORY);
    fc.addGenerated(NumericLnDescriptor.FACTORY);
    fc.addGenerated(NumericLogDescriptor.FACTORY);
    fc.addGenerated(NumericSqrtDescriptor.FACTORY);
    fc.addGenerated(NumericSignDescriptor.FACTORY);
    fc.addGenerated(NumericTruncDescriptor.FACTORY);
    fc.addGenerated(NumericATan2Descriptor.FACTORY);
    // Comparisons.
    fc.addGenerated(EqualsDescriptor.FACTORY);
    fc.addGenerated(GreaterThanDescriptor.FACTORY);
    fc.addGenerated(GreaterThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(LessThanDescriptor.FACTORY);
    fc.addGenerated(LessThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(NotEqualsDescriptor.FACTORY);
    // If-Equals functions
    fc.addGenerated(MissingIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NullIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NanIfEqualsDescriptor.FACTORY);
    fc.addGenerated(PosInfIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NegInfIfEqualsDescriptor.FACTORY);
    // Binary functions
    fc.addGenerated(BinaryLengthDescriptor.FACTORY);
    fc.addGenerated(ParseBinaryDescriptor.FACTORY);
    fc.addGenerated(PrintBinaryDescriptor.FACTORY);
    fc.addGenerated(BinaryConcatDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromToDescriptor.FACTORY);
    fc.addGenerated(FindBinaryDescriptor.FACTORY);
    fc.addGenerated(FindBinaryFromDescriptor.FACTORY);
    // String functions
    fc.addGenerated(StringLikeDescriptor.FACTORY);
    fc.addGenerated(StringContainsDescriptor.FACTORY);
    fc.addGenerated(StringEndsWithDescriptor.FACTORY);
    fc.addGenerated(StringStartsWithDescriptor.FACTORY);
    fc.addGenerated(SubstringDescriptor.FACTORY);
    fc.addGenerated(StringEqualDescriptor.FACTORY);
    fc.addGenerated(StringLowerCaseDescriptor.FACTORY);
    fc.addGenerated(StringUpperCaseDescriptor.FACTORY);
    fc.addGenerated(StringLengthDescriptor.FACTORY);
    fc.addGenerated(Substring2Descriptor.FACTORY);
    fc.addGenerated(SubstringBeforeDescriptor.FACTORY);
    fc.addGenerated(SubstringAfterDescriptor.FACTORY);
    fc.addGenerated(StringToCodePointDescriptor.FACTORY);
    fc.addGenerated(CodePointToStringDescriptor.FACTORY);
    fc.addGenerated(StringConcatDescriptor.FACTORY);
    fc.addGenerated(StringJoinDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringInitCapDescriptor.FACTORY);
    fc.addGenerated(StringTrimDescriptor.FACTORY);
    fc.addGenerated(StringLTrimDescriptor.FACTORY);
    fc.addGenerated(StringRTrimDescriptor.FACTORY);
    fc.addGenerated(StringTrim2Descriptor.FACTORY);
    fc.addGenerated(StringLTrim2Descriptor.FACTORY);
    fc.addGenerated(StringRTrim2Descriptor.FACTORY);
    fc.addGenerated(StringPositionDescriptor.FACTORY);
    fc.addGenerated(StringRepeatDescriptor.FACTORY);
    fc.addGenerated(StringReplaceDescriptor.FACTORY);
    fc.addGenerated(StringReplaceWithLimitDescriptor.FACTORY);
    fc.addGenerated(StringReverseDescriptor.FACTORY);
    fc.addGenerated(StringSplitDescriptor.FACTORY);
    // Constructors
    fc.addGenerated(ABooleanConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryHexStringConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryBase64StringConstructorDescriptor.FACTORY);
    fc.addGenerated(AStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt8ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt16ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt32ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt64ConstructorDescriptor.FACTORY);
    fc.addGenerated(AFloatConstructorDescriptor.FACTORY);
    fc.addGenerated(ADoubleConstructorDescriptor.FACTORY);
    fc.addGenerated(APointConstructorDescriptor.FACTORY);
    fc.addGenerated(APoint3DConstructorDescriptor.FACTORY);
    fc.addGenerated(ALineConstructorDescriptor.FACTORY);
    fc.addGenerated(APolygonConstructorDescriptor.FACTORY);
    fc.addGenerated(ACircleConstructorDescriptor.FACTORY);
    fc.addGenerated(ARectangleConstructorDescriptor.FACTORY);
    fc.addGenerated(ATimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AYearMonthDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(ADayTimeDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AUUIDFromStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromTimeConstructorDescriptor.FACTORY);
    // Spatial
    fc.addGenerated(CreatePointDescriptor.FACTORY);
    fc.addGenerated(CreateLineDescriptor.FACTORY);
    fc.addGenerated(CreatePolygonDescriptor.FACTORY);
    fc.addGenerated(CreateCircleDescriptor.FACTORY);
    fc.addGenerated(CreateRectangleDescriptor.FACTORY);
    fc.addGenerated(SpatialAreaDescriptor.FACTORY);
    fc.addGenerated(SpatialDistanceDescriptor.FACTORY);
    fc.addGenerated(CreateMBRDescriptor.FACTORY);
    fc.addGenerated(SpatialCellDescriptor.FACTORY);
    fc.addGenerated(PointXCoordinateAccessor.FACTORY);
    fc.addGenerated(PointYCoordinateAccessor.FACTORY);
    fc.addGenerated(CircleRadiusAccessor.FACTORY);
    fc.addGenerated(CircleCenterAccessor.FACTORY);
    fc.addGenerated(LineRectanglePolygonAccessor.FACTORY);
    // full-text function
    fc.addGenerated(FullTextContainsDescriptor.FACTORY);
    fc.addGenerated(FullTextContainsWithoutOptionDescriptor.FACTORY);
    // Record functions.
    fc.addGenerated(GetRecordFieldsDescriptor.FACTORY);
    fc.addGenerated(GetRecordFieldValueDescriptor.FACTORY);
    fc.addGenerated(DeepEqualityDescriptor.FACTORY);
    fc.addGenerated(RecordMergeDescriptor.FACTORY);
    fc.addGenerated(RecordAddFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordLengthDescriptor.FACTORY);
    fc.addGenerated(RecordNamesDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveDescriptor.FACTORY);
    fc.addGenerated(RecordRenameDescriptor.FACTORY);
    fc.addGenerated(RecordUnwrapDescriptor.FACTORY);
    fc.add(RecordReplaceDescriptor.FACTORY);
    fc.add(RecordAddDescriptor.FACTORY);
    fc.add(RecordPutDescriptor.FACTORY);
    fc.addGenerated(RecordValuesDescriptor.FACTORY);
    fc.addGenerated(PairsDescriptor.FACTORY);
    // Spatial and temporal type accessors
    fc.addGenerated(TemporalYearAccessor.FACTORY);
    fc.addGenerated(TemporalMonthAccessor.FACTORY);
    fc.addGenerated(TemporalDayAccessor.FACTORY);
    fc.addGenerated(TemporalHourAccessor.FACTORY);
    fc.addGenerated(TemporalMinuteAccessor.FACTORY);
    fc.addGenerated(TemporalSecondAccessor.FACTORY);
    fc.addGenerated(TemporalMillisecondAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDatetimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDatetimeAccessor.FACTORY);
    // Temporal functions
    fc.addGenerated(UnixTimeFromDateInDaysDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromTimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DateFromUnixTimeInDaysDescriptor.FACTORY);
    fc.addGenerated(DateFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(TimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(TimeFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromDateAndTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDurationFromDateTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDuartionFromDateDescriptor.FACTORY);
    fc.addGenerated(AdjustDateTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(AdjustTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(IntervalBeforeDescriptor.FACTORY);
    fc.addGenerated(IntervalAfterDescriptor.FACTORY);
    fc.addGenerated(IntervalMeetsDescriptor.FACTORY);
    fc.addGenerated(IntervalMetByDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlapsDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlappedByDescriptor.FACTORY);
    fc.addGenerated(OverlapDescriptor.FACTORY);
    fc.addGenerated(IntervalStartsDescriptor.FACTORY);
    fc.addGenerated(IntervalStartedByDescriptor.FACTORY);
    fc.addGenerated(IntervalCoversDescriptor.FACTORY);
    fc.addGenerated(IntervalCoveredByDescriptor.FACTORY);
    fc.addGenerated(IntervalEndsDescriptor.FACTORY);
    fc.addGenerated(IntervalEndedByDescriptor.FACTORY);
    fc.addGenerated(DurationFromMillisecondsDescriptor.FACTORY);
    fc.addGenerated(DurationFromMonthsDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(MonthsFromYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(MillisecondsFromDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(DurationEqualDescriptor.FACTORY);
    fc.addGenerated(GetYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(GetDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(IntervalBinDescriptor.FACTORY);
    fc.addGenerated(OverlapBinsDescriptor.FACTORY);
    fc.addGenerated(DayOfWeekDescriptor.FACTORY);
    fc.addGenerated(ParseDateDescriptor.FACTORY);
    fc.addGenerated(ParseTimeDescriptor.FACTORY);
    fc.addGenerated(ParseDateTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateDescriptor.FACTORY);
    fc.addGenerated(PrintTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateTimeDescriptor.FACTORY);
    fc.addGenerated(GetOverlappingIntervalDescriptor.FACTORY);
    fc.addGenerated(DurationFromIntervalDescriptor.FACTORY);
    // Type functions.
    fc.addGenerated(IsArrayDescriptor.FACTORY);
    fc.addGenerated(IsAtomicDescriptor.FACTORY);
    fc.addGenerated(IsBooleanDescriptor.FACTORY);
    fc.addGenerated(IsNumberDescriptor.FACTORY);
    fc.addGenerated(IsObjectDescriptor.FACTORY);
    fc.addGenerated(IsStringDescriptor.FACTORY);
    fc.addGenerated(ToArrayDescriptor.FACTORY);
    fc.addGenerated(ToAtomicDescriptor.FACTORY);
    fc.addGenerated(ToBigIntDescriptor.FACTORY);
    fc.addGenerated(ToBooleanDescriptor.FACTORY);
    fc.addGenerated(ToDoubleDescriptor.FACTORY);
    fc.addGenerated(ToNumberDescriptor.FACTORY);
    fc.addGenerated(ToObjectDescriptor.FACTORY);
    fc.addGenerated(ToStringDescriptor.FACTORY);
    fc.addGenerated(TreatAsIntegerDescriptor.FACTORY);
    // Cast function
    fc.addGenerated(CastTypeDescriptor.FACTORY);
    fc.addGenerated(CastTypeLaxDescriptor.FACTORY);
    // Record function
    fc.addGenerated(RecordPairsDescriptor.FACTORY);
    // Other functions
    fc.addGenerated(RandomWithSeedDescriptor.FACTORY);
    ServiceLoader.load(IFunctionRegistrant.class).iterator().forEachRemaining(c -> c.register(fc));
    return fc;
}
#method_after
public static FunctionCollection createDefaultFunctionCollection() {
    FunctionCollection fc = new FunctionCollection();
    // array functions
    fc.add(ArrayRemoveDescriptor.FACTORY);
    fc.add(ArrayPutDescriptor.FACTORY);
    fc.add(ArrayPrependDescriptor.FACTORY);
    fc.add(ArrayAppendDescriptor.FACTORY);
    fc.add(ArrayInsertDescriptor.FACTORY);
    fc.addGenerated(ArrayPositionDescriptor.FACTORY);
    fc.addGenerated(ArrayRepeatDescriptor.FACTORY);
    fc.addGenerated(ArrayContainsDescriptor.FACTORY);
    fc.addGenerated(ArrayReverseDescriptor.FACTORY);
    fc.addGenerated(ArraySortDescriptor.FACTORY);
    fc.addGenerated(ArrayDistinctDescriptor.FACTORY);
    fc.addGenerated(ArrayUnionDescriptor.FACTORY);
    fc.addGenerated(ArrayIntersectDescriptor.FACTORY);
    fc.addGenerated(ArrayIfNullDescriptor.FACTORY);
    fc.addGenerated(ArrayConcatDescriptor.FACTORY);
    fc.addGenerated(ArrayRangeDescriptor.FACTORY);
    fc.addGenerated(ArrayFlattenDescriptor.FACTORY);
    fc.add(ArrayReplaceDescriptor.FACTORY);
    fc.addGenerated(ArraySymDiffDescriptor.FACTORY);
    fc.addGenerated(ArraySymDiffnDescriptor.FACTORY);
    fc.addGenerated(ArrayStarDescriptor.FACTORY);
    // unnesting functions
    fc.add(TidRunningAggregateDescriptor.FACTORY);
    fc.add(ScanCollectionDescriptor.FACTORY);
    fc.add(RangeDescriptor.FACTORY);
    fc.add(SubsetCollectionDescriptor.FACTORY);
    // aggregate functions
    fc.add(ListifyAggregateDescriptor.FACTORY);
    fc.add(CountAggregateDescriptor.FACTORY);
    fc.add(AvgAggregateDescriptor.FACTORY);
    fc.add(LocalAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SumAggregateDescriptor.FACTORY);
    fc.add(LocalSumAggregateDescriptor.FACTORY);
    fc.add(MaxAggregateDescriptor.FACTORY);
    fc.add(LocalMaxAggregateDescriptor.FACTORY);
    fc.add(MinAggregateDescriptor.FACTORY);
    fc.add(LocalMinAggregateDescriptor.FACTORY);
    fc.add(FirstElementAggregateDescriptor.FACTORY);
    fc.add(LocalFirstElementAggregateDescriptor.FACTORY);
    fc.add(StddevAggregateDescriptor.FACTORY);
    fc.add(LocalStddevAggregateDescriptor.FACTORY);
    fc.add(IntermediateStddevAggregateDescriptor.FACTORY);
    fc.add(GlobalStddevAggregateDescriptor.FACTORY);
    fc.add(LocalSamplingAggregateDescriptor.FACTORY);
    fc.add(RangeMapAggregateDescriptor.FACTORY);
    fc.add(StddevPopAggregateDescriptor.FACTORY);
    fc.add(LocalStddevPopAggregateDescriptor.FACTORY);
    fc.add(IntermediateStddevPopAggregateDescriptor.FACTORY);
    fc.add(GlobalStddevPopAggregateDescriptor.FACTORY);
    // serializable aggregates
    fc.add(SerializableCountAggregateDescriptor.FACTORY);
    fc.add(SerializableAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSumAggregateDescriptor.FACTORY);
    fc.add(SerializableStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalStddevPopAggregateDescriptor.FACTORY);
    // scalar aggregates
    fc.add(ScalarCountAggregateDescriptor.FACTORY);
    fc.add(ScalarAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSumAggregateDescriptor.FACTORY);
    fc.add(ScalarMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarMinAggregateDescriptor.FACTORY);
    fc.add(EmptyStreamAggregateDescriptor.FACTORY);
    fc.add(NonEmptyStreamAggregateDescriptor.FACTORY);
    fc.add(ScalarStddevAggregateDescriptor.FACTORY);
    fc.add(ScalarStddevPopAggregateDescriptor.FACTORY);
    // SQL aggregates
    fc.add(SqlCountAggregateDescriptor.FACTORY);
    fc.add(SqlAvgAggregateDescriptor.FACTORY);
    fc.add(LocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SqlSumAggregateDescriptor.FACTORY);
    fc.add(LocalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SqlMaxAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMaxAggregateDescriptor.FACTORY);
    fc.add(SqlMinAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMinAggregateDescriptor.FACTORY);
    fc.add(SqlStddevAggregateDescriptor.FACTORY);
    fc.add(LocalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlStddevAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(LocalSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlStddevPopAggregateDescriptor.FACTORY);
    // SQL serializable aggregates
    fc.add(SerializableSqlCountAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlStddevPopAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlStddevPopAggregateDescriptor.FACTORY);
    // SQL scalar aggregates
    fc.add(ScalarSqlCountAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlSumAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMinAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlStddevAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlStddevPopAggregateDescriptor.FACTORY);
    // boolean functions
    fc.add(AndDescriptor.FACTORY);
    fc.add(OrDescriptor.FACTORY);
    // Record constructors / functions
    fc.add(ClosedRecordConstructorDescriptor.FACTORY);
    fc.add(OpenRecordConstructorDescriptor.FACTORY);
    fc.add(RecordConcatDescriptor.FACTORY);
    fc.add(RecordConcatStrictDescriptor.FACTORY);
    // List constructors
    fc.add(OrderedListConstructorDescriptor.FACTORY);
    fc.add(UnorderedListConstructorDescriptor.FACTORY);
    // Sleep function
    fc.add(SleepDescriptor.FACTORY);
    // Inject failure function
    fc.add(InjectFailureDescriptor.FACTORY);
    // Get Job Parameter function
    fc.add(GetJobParameterByNameDescriptor.FACTORY);
    // Switch case
    fc.add(SwitchCaseDescriptor.FACTORY);
    // null functions
    fc.add(IsMissingDescriptor.FACTORY);
    fc.add(IsNullDescriptor.FACTORY);
    fc.add(IsUnknownDescriptor.FACTORY);
    fc.add(IsSystemNullDescriptor.FACTORY);
    fc.add(CheckUnknownDescriptor.FACTORY);
    fc.add(IfMissingDescriptor.FACTORY);
    fc.add(IfNullDescriptor.FACTORY);
    fc.add(IfMissingOrNullDescriptor.FACTORY);
    // uuid generators (zero independent functions)
    fc.add(CreateUUIDDescriptor.FACTORY);
    fc.add(UUIDDescriptor.FACTORY);
    fc.add(CreateQueryUIDDescriptor.FACTORY);
    fc.add(RandomDescriptor.FACTORY);
    fc.add(CurrentDateDescriptor.FACTORY);
    fc.add(CurrentTimeDescriptor.FACTORY);
    fc.add(CurrentDateTimeDescriptor.FACTORY);
    // functions that need generated class for null-handling.
    // Element accessors.
    fc.addGenerated(FieldAccessByIndexDescriptor.FACTORY);
    fc.addGenerated(FieldAccessByNameDescriptor.FACTORY);
    fc.addGenerated(FieldAccessNestedDescriptor.FACTORY);
    fc.addGenerated(AnyCollectionMemberDescriptor.FACTORY);
    fc.addGenerated(GetItemDescriptor.FACTORY);
    // Numeric functions
    fc.add(IfInfDescriptor.FACTORY);
    fc.add(IfNanDescriptor.FACTORY);
    fc.add(IfNanOrInfDescriptor.FACTORY);
    fc.addGenerated(NumericUnaryMinusDescriptor.FACTORY);
    fc.addGenerated(NumericAddDescriptor.FACTORY);
    fc.addGenerated(NumericDivideDescriptor.FACTORY);
    fc.addGenerated(NumericDivDescriptor.FACTORY);
    fc.addGenerated(NumericMultiplyDescriptor.FACTORY);
    fc.addGenerated(NumericSubDescriptor.FACTORY);
    fc.addGenerated(NumericModuloDescriptor.FACTORY);
    fc.addGenerated(NumericPowerDescriptor.FACTORY);
    fc.addGenerated(NotDescriptor.FACTORY);
    fc.addGenerated(LenDescriptor.FACTORY);
    fc.addGenerated(NumericAbsDescriptor.FACTORY);
    fc.addGenerated(NumericCeilingDescriptor.FACTORY);
    fc.addGenerated(NumericFloorDescriptor.FACTORY);
    fc.addGenerated(NumericRoundDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEvenDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEven2Descriptor.FACTORY);
    fc.addGenerated(NumericACosDescriptor.FACTORY);
    fc.addGenerated(NumericASinDescriptor.FACTORY);
    fc.addGenerated(NumericATanDescriptor.FACTORY);
    fc.addGenerated(NumericDegreesDescriptor.FACTORY);
    fc.addGenerated(NumericRadiansDescriptor.FACTORY);
    fc.addGenerated(NumericCosDescriptor.FACTORY);
    fc.addGenerated(NumericSinDescriptor.FACTORY);
    fc.addGenerated(NumericTanDescriptor.FACTORY);
    fc.addGenerated(NumericExpDescriptor.FACTORY);
    fc.addGenerated(NumericLnDescriptor.FACTORY);
    fc.addGenerated(NumericLogDescriptor.FACTORY);
    fc.addGenerated(NumericSqrtDescriptor.FACTORY);
    fc.addGenerated(NumericSignDescriptor.FACTORY);
    fc.addGenerated(NumericTruncDescriptor.FACTORY);
    fc.addGenerated(NumericATan2Descriptor.FACTORY);
    // Comparisons.
    fc.addGenerated(EqualsDescriptor.FACTORY);
    fc.addGenerated(GreaterThanDescriptor.FACTORY);
    fc.addGenerated(GreaterThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(LessThanDescriptor.FACTORY);
    fc.addGenerated(LessThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(NotEqualsDescriptor.FACTORY);
    // If-Equals functions
    fc.addGenerated(MissingIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NullIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NanIfEqualsDescriptor.FACTORY);
    fc.addGenerated(PosInfIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NegInfIfEqualsDescriptor.FACTORY);
    // Binary functions
    fc.addGenerated(BinaryLengthDescriptor.FACTORY);
    fc.addGenerated(ParseBinaryDescriptor.FACTORY);
    fc.addGenerated(PrintBinaryDescriptor.FACTORY);
    fc.addGenerated(BinaryConcatDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromToDescriptor.FACTORY);
    fc.addGenerated(FindBinaryDescriptor.FACTORY);
    fc.addGenerated(FindBinaryFromDescriptor.FACTORY);
    // String functions
    fc.addGenerated(StringLikeDescriptor.FACTORY);
    fc.addGenerated(StringContainsDescriptor.FACTORY);
    fc.addGenerated(StringEndsWithDescriptor.FACTORY);
    fc.addGenerated(StringStartsWithDescriptor.FACTORY);
    fc.addGenerated(SubstringDescriptor.FACTORY);
    fc.addGenerated(StringEqualDescriptor.FACTORY);
    fc.addGenerated(StringLowerCaseDescriptor.FACTORY);
    fc.addGenerated(StringUpperCaseDescriptor.FACTORY);
    fc.addGenerated(StringLengthDescriptor.FACTORY);
    fc.addGenerated(Substring2Descriptor.FACTORY);
    fc.addGenerated(SubstringBeforeDescriptor.FACTORY);
    fc.addGenerated(SubstringAfterDescriptor.FACTORY);
    fc.addGenerated(StringToCodePointDescriptor.FACTORY);
    fc.addGenerated(CodePointToStringDescriptor.FACTORY);
    fc.addGenerated(StringConcatDescriptor.FACTORY);
    fc.addGenerated(StringJoinDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringInitCapDescriptor.FACTORY);
    fc.addGenerated(StringTrimDescriptor.FACTORY);
    fc.addGenerated(StringLTrimDescriptor.FACTORY);
    fc.addGenerated(StringRTrimDescriptor.FACTORY);
    fc.addGenerated(StringTrim2Descriptor.FACTORY);
    fc.addGenerated(StringLTrim2Descriptor.FACTORY);
    fc.addGenerated(StringRTrim2Descriptor.FACTORY);
    fc.addGenerated(StringPositionDescriptor.FACTORY);
    fc.addGenerated(StringRepeatDescriptor.FACTORY);
    fc.addGenerated(StringReplaceDescriptor.FACTORY);
    fc.addGenerated(StringReplaceWithLimitDescriptor.FACTORY);
    fc.addGenerated(StringReverseDescriptor.FACTORY);
    fc.addGenerated(StringSplitDescriptor.FACTORY);
    // Constructors
    fc.addGenerated(ABooleanConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryHexStringConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryBase64StringConstructorDescriptor.FACTORY);
    fc.addGenerated(AStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt8ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt16ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt32ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt64ConstructorDescriptor.FACTORY);
    fc.addGenerated(AFloatConstructorDescriptor.FACTORY);
    fc.addGenerated(ADoubleConstructorDescriptor.FACTORY);
    fc.addGenerated(APointConstructorDescriptor.FACTORY);
    fc.addGenerated(APoint3DConstructorDescriptor.FACTORY);
    fc.addGenerated(ALineConstructorDescriptor.FACTORY);
    fc.addGenerated(APolygonConstructorDescriptor.FACTORY);
    fc.addGenerated(ACircleConstructorDescriptor.FACTORY);
    fc.addGenerated(ARectangleConstructorDescriptor.FACTORY);
    fc.addGenerated(ATimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AYearMonthDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(ADayTimeDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AUUIDFromStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromTimeConstructorDescriptor.FACTORY);
    // Spatial
    fc.addGenerated(CreatePointDescriptor.FACTORY);
    fc.addGenerated(CreateLineDescriptor.FACTORY);
    fc.addGenerated(CreatePolygonDescriptor.FACTORY);
    fc.addGenerated(CreateCircleDescriptor.FACTORY);
    fc.addGenerated(CreateRectangleDescriptor.FACTORY);
    fc.addGenerated(SpatialAreaDescriptor.FACTORY);
    fc.addGenerated(SpatialDistanceDescriptor.FACTORY);
    fc.addGenerated(CreateMBRDescriptor.FACTORY);
    fc.addGenerated(SpatialCellDescriptor.FACTORY);
    fc.addGenerated(PointXCoordinateAccessor.FACTORY);
    fc.addGenerated(PointYCoordinateAccessor.FACTORY);
    fc.addGenerated(CircleRadiusAccessor.FACTORY);
    fc.addGenerated(CircleCenterAccessor.FACTORY);
    fc.addGenerated(LineRectanglePolygonAccessor.FACTORY);
    // full-text function
    fc.addGenerated(FullTextContainsDescriptor.FACTORY);
    fc.addGenerated(FullTextContainsWithoutOptionDescriptor.FACTORY);
    // Record functions.
    fc.addGenerated(GetRecordFieldsDescriptor.FACTORY);
    fc.addGenerated(GetRecordFieldValueDescriptor.FACTORY);
    fc.addGenerated(DeepEqualityDescriptor.FACTORY);
    fc.addGenerated(RecordMergeDescriptor.FACTORY);
    fc.addGenerated(RecordAddFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordLengthDescriptor.FACTORY);
    fc.addGenerated(RecordNamesDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveDescriptor.FACTORY);
    fc.addGenerated(RecordRenameDescriptor.FACTORY);
    fc.addGenerated(RecordUnwrapDescriptor.FACTORY);
    fc.add(RecordReplaceDescriptor.FACTORY);
    fc.add(RecordAddDescriptor.FACTORY);
    fc.add(RecordPutDescriptor.FACTORY);
    fc.addGenerated(RecordValuesDescriptor.FACTORY);
    fc.addGenerated(PairsDescriptor.FACTORY);
    // Spatial and temporal type accessors
    fc.addGenerated(TemporalYearAccessor.FACTORY);
    fc.addGenerated(TemporalMonthAccessor.FACTORY);
    fc.addGenerated(TemporalDayAccessor.FACTORY);
    fc.addGenerated(TemporalHourAccessor.FACTORY);
    fc.addGenerated(TemporalMinuteAccessor.FACTORY);
    fc.addGenerated(TemporalSecondAccessor.FACTORY);
    fc.addGenerated(TemporalMillisecondAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDatetimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDatetimeAccessor.FACTORY);
    // Temporal functions
    fc.addGenerated(UnixTimeFromDateInDaysDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromTimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DateFromUnixTimeInDaysDescriptor.FACTORY);
    fc.addGenerated(DateFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(TimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(TimeFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromDateAndTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDurationFromDateTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDuartionFromDateDescriptor.FACTORY);
    fc.addGenerated(AdjustDateTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(AdjustTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(IntervalBeforeDescriptor.FACTORY);
    fc.addGenerated(IntervalAfterDescriptor.FACTORY);
    fc.addGenerated(IntervalMeetsDescriptor.FACTORY);
    fc.addGenerated(IntervalMetByDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlapsDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlappedByDescriptor.FACTORY);
    fc.addGenerated(OverlapDescriptor.FACTORY);
    fc.addGenerated(IntervalStartsDescriptor.FACTORY);
    fc.addGenerated(IntervalStartedByDescriptor.FACTORY);
    fc.addGenerated(IntervalCoversDescriptor.FACTORY);
    fc.addGenerated(IntervalCoveredByDescriptor.FACTORY);
    fc.addGenerated(IntervalEndsDescriptor.FACTORY);
    fc.addGenerated(IntervalEndedByDescriptor.FACTORY);
    fc.addGenerated(DurationFromMillisecondsDescriptor.FACTORY);
    fc.addGenerated(DurationFromMonthsDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(MonthsFromYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(MillisecondsFromDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(DurationEqualDescriptor.FACTORY);
    fc.addGenerated(GetYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(GetDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(IntervalBinDescriptor.FACTORY);
    fc.addGenerated(OverlapBinsDescriptor.FACTORY);
    fc.addGenerated(DayOfWeekDescriptor.FACTORY);
    fc.addGenerated(ParseDateDescriptor.FACTORY);
    fc.addGenerated(ParseTimeDescriptor.FACTORY);
    fc.addGenerated(ParseDateTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateDescriptor.FACTORY);
    fc.addGenerated(PrintTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateTimeDescriptor.FACTORY);
    fc.addGenerated(GetOverlappingIntervalDescriptor.FACTORY);
    fc.addGenerated(DurationFromIntervalDescriptor.FACTORY);
    // Type functions.
    fc.addGenerated(IsArrayDescriptor.FACTORY);
    fc.addGenerated(IsAtomicDescriptor.FACTORY);
    fc.addGenerated(IsBooleanDescriptor.FACTORY);
    fc.addGenerated(IsNumberDescriptor.FACTORY);
    fc.addGenerated(IsObjectDescriptor.FACTORY);
    fc.addGenerated(IsStringDescriptor.FACTORY);
    fc.addGenerated(ToArrayDescriptor.FACTORY);
    fc.addGenerated(ToAtomicDescriptor.FACTORY);
    fc.addGenerated(ToBigIntDescriptor.FACTORY);
    fc.addGenerated(ToBooleanDescriptor.FACTORY);
    fc.addGenerated(ToDoubleDescriptor.FACTORY);
    fc.addGenerated(ToNumberDescriptor.FACTORY);
    fc.addGenerated(ToObjectDescriptor.FACTORY);
    fc.addGenerated(ToStringDescriptor.FACTORY);
    fc.addGenerated(TreatAsIntegerDescriptor.FACTORY);
    // Cast function
    fc.addGenerated(CastTypeDescriptor.FACTORY);
    fc.addGenerated(CastTypeLaxDescriptor.FACTORY);
    // Record function
    fc.addGenerated(RecordPairsDescriptor.FACTORY);
    // Other functions
    fc.addGenerated(RandomWithSeedDescriptor.FACTORY);
    ServiceLoader.load(IFunctionRegistrant.class).iterator().forEachRemaining(c -> c.register(fc));
    return fc;
}
#end_block

#method_before
@Override
public ISerializedAggregateEvaluatorFactory createSerializableAggregateEvaluatorFactory(final IScalarEvaluatorFactory[] args) {
    return new ISerializedAggregateEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public ISerializedAggregateEvaluator createAggregateEvaluator(IHyracksTaskContext ctx) throws HyracksDataException {
            return new SerializableIntermediateSqlStddevPopAggregateFunction(args, ctx, sourceLoc);
        }
    };
}
#method_after
@Override
public ISerializedAggregateEvaluatorFactory createSerializableAggregateEvaluatorFactory(final IScalarEvaluatorFactory[] args) {
    return new ISerializedAggregateEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public ISerializedAggregateEvaluator createAggregateEvaluator(IHyracksTaskContext ctx) throws HyracksDataException {
            return new SerializableIntermediateSqlStddevAggregateFunction(args, ctx, true, sourceLoc);
        }
    };
}
#end_block

#method_before
@Override
public IAggregateEvaluatorFactory createAggregateEvaluatorFactory(final IScalarEvaluatorFactory[] args) {
    return new IAggregateEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IAggregateEvaluator createAggregateEvaluator(final IHyracksTaskContext ctx) throws HyracksDataException {
            return new LocalStddevPopAggregateFunction(args, ctx, sourceLoc);
        }
    };
}
#method_after
@Override
public IAggregateEvaluatorFactory createAggregateEvaluatorFactory(final IScalarEvaluatorFactory[] args) {
    return new IAggregateEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IAggregateEvaluator createAggregateEvaluator(final IHyracksTaskContext ctx) throws HyracksDataException {
            return new LocalStddevAggregateFunction(args, ctx, true, sourceLoc);
        }
    };
}
#end_block

#method_before
@Override
public IAggregateEvaluatorFactory createAggregateEvaluatorFactory(final IScalarEvaluatorFactory[] args) {
    return new IAggregateEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IAggregateEvaluator createAggregateEvaluator(final IHyracksTaskContext ctx) throws HyracksDataException {
            return new StddevPopAggregateFunction(args, ctx, sourceLoc);
        }
    };
}
#method_after
@Override
public IAggregateEvaluatorFactory createAggregateEvaluatorFactory(final IScalarEvaluatorFactory[] args) {
    return new IAggregateEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IAggregateEvaluator createAggregateEvaluator(final IHyracksTaskContext ctx) throws HyracksDataException {
            return new StddevAggregateFunction(args, ctx, true, sourceLoc);
        }
    };
}
#end_block

#method_before
@Override
public IAggregateEvaluatorFactory createAggregateEvaluatorFactory(final IScalarEvaluatorFactory[] args) {
    return new IAggregateEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IAggregateEvaluator createAggregateEvaluator(final IHyracksTaskContext ctx) throws HyracksDataException {
            return new LocalSqlStddevPopAggregateFunction(args, ctx, sourceLoc);
        }
    };
}
#method_after
@Override
public IAggregateEvaluatorFactory createAggregateEvaluatorFactory(final IScalarEvaluatorFactory[] args) {
    return new IAggregateEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IAggregateEvaluator createAggregateEvaluator(final IHyracksTaskContext ctx) throws HyracksDataException {
            return new LocalSqlStddevAggregateFunction(args, ctx, true, sourceLoc);
        }
    };
}
#end_block

#method_before
@Override
public IAggregateEvaluatorFactory createAggregateEvaluatorFactory(final IScalarEvaluatorFactory[] args) {
    return new IAggregateEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IAggregateEvaluator createAggregateEvaluator(final IHyracksTaskContext ctx) throws HyracksDataException {
            return new IntermediateStddevPopAggregateFunction(args, ctx, sourceLoc);
        }
    };
}
#method_after
@Override
public IAggregateEvaluatorFactory createAggregateEvaluatorFactory(final IScalarEvaluatorFactory[] args) {
    return new IAggregateEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IAggregateEvaluator createAggregateEvaluator(final IHyracksTaskContext ctx) throws HyracksDataException {
            return new IntermediateStddevAggregateFunction(args, ctx, true, sourceLoc);
        }
    };
}
#end_block

#method_before
@Override
public IAggregateEvaluatorFactory createAggregateEvaluatorFactory(final IScalarEvaluatorFactory[] args) {
    return new IAggregateEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IAggregateEvaluator createAggregateEvaluator(final IHyracksTaskContext ctx) throws HyracksDataException {
            return new GlobalStddevPopAggregateFunction(args, ctx, sourceLoc);
        }
    };
}
#method_after
@Override
public IAggregateEvaluatorFactory createAggregateEvaluatorFactory(final IScalarEvaluatorFactory[] args) {
    return new IAggregateEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IAggregateEvaluator createAggregateEvaluator(final IHyracksTaskContext ctx) throws HyracksDataException {
            return new GlobalStddevAggregateFunction(args, ctx, true, sourceLoc);
        }
    };
}
#end_block

#method_before
@Override
public ISerializedAggregateEvaluatorFactory createSerializableAggregateEvaluatorFactory(final IScalarEvaluatorFactory[] args) {
    return new ISerializedAggregateEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public ISerializedAggregateEvaluator createAggregateEvaluator(IHyracksTaskContext ctx) throws HyracksDataException {
            return new SerializableLocalStddevPopAggregateFunction(args, ctx, sourceLoc);
        }
    };
}
#method_after
@Override
public ISerializedAggregateEvaluatorFactory createSerializableAggregateEvaluatorFactory(final IScalarEvaluatorFactory[] args) {
    return new ISerializedAggregateEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public ISerializedAggregateEvaluator createAggregateEvaluator(IHyracksTaskContext ctx) throws HyracksDataException {
            return new SerializableLocalStddevAggregateFunction(args, ctx, true, sourceLoc);
        }
    };
}
#end_block

#method_before
@Override
public ISerializedAggregateEvaluatorFactory createSerializableAggregateEvaluatorFactory(final IScalarEvaluatorFactory[] args) {
    return new ISerializedAggregateEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public ISerializedAggregateEvaluator createAggregateEvaluator(IHyracksTaskContext ctx) throws HyracksDataException {
            return new SerializableGlobalSqlStddevPopAggregateFunction(args, ctx, sourceLoc);
        }
    };
}
#method_after
@Override
public ISerializedAggregateEvaluatorFactory createSerializableAggregateEvaluatorFactory(final IScalarEvaluatorFactory[] args) {
    return new ISerializedAggregateEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public ISerializedAggregateEvaluator createAggregateEvaluator(IHyracksTaskContext ctx) throws HyracksDataException {
            return new SerializableGlobalSqlStddevAggregateFunction(args, ctx, true, sourceLoc);
        }
    };
}
#end_block

#method_before
@Override
public IAggregateEvaluatorFactory createAggregateEvaluatorFactory(final IScalarEvaluatorFactory[] args) {
    return new IAggregateEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IAggregateEvaluator createAggregateEvaluator(final IHyracksTaskContext ctx) throws HyracksDataException {
            return new GlobalSqlStddevPopAggregateFunction(args, ctx, sourceLoc);
        }
    };
}
#method_after
@Override
public IAggregateEvaluatorFactory createAggregateEvaluatorFactory(final IScalarEvaluatorFactory[] args) {
    return new IAggregateEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IAggregateEvaluator createAggregateEvaluator(final IHyracksTaskContext ctx) throws HyracksDataException {
            return new GlobalSqlStddevAggregateFunction(args, ctx, true, sourceLoc);
        }
    };
}
#end_block

#method_before
@Override
public ISerializedAggregateEvaluatorFactory createSerializableAggregateEvaluatorFactory(final IScalarEvaluatorFactory[] args) {
    return new ISerializedAggregateEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public ISerializedAggregateEvaluator createAggregateEvaluator(IHyracksTaskContext ctx) throws HyracksDataException {
            return new SerializableLocalSqlStddevPopAggregateFunction(args, ctx, sourceLoc);
        }
    };
}
#method_after
@Override
public ISerializedAggregateEvaluatorFactory createSerializableAggregateEvaluatorFactory(final IScalarEvaluatorFactory[] args) {
    return new ISerializedAggregateEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public ISerializedAggregateEvaluator createAggregateEvaluator(IHyracksTaskContext ctx) throws HyracksDataException {
            return new SerializableLocalSqlStddevAggregateFunction(args, ctx, true, sourceLoc);
        }
    };
}
#end_block

#method_before
@Override
public IAggregateEvaluatorFactory createAggregateEvaluatorFactory(final IScalarEvaluatorFactory[] args) {
    return new IAggregateEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IAggregateEvaluator createAggregateEvaluator(final IHyracksTaskContext ctx) throws HyracksDataException {
            return new IntermediateSqlStddevPopAggregateFunction(args, ctx, sourceLoc);
        }
    };
}
#method_after
@Override
public IAggregateEvaluatorFactory createAggregateEvaluatorFactory(final IScalarEvaluatorFactory[] args) {
    return new IAggregateEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IAggregateEvaluator createAggregateEvaluator(final IHyracksTaskContext ctx) throws HyracksDataException {
            return new IntermediateSqlStddevAggregateFunction(args, ctx, true, sourceLoc);
        }
    };
}
#end_block

#method_before
@Override
public ISerializedAggregateEvaluatorFactory createSerializableAggregateEvaluatorFactory(final IScalarEvaluatorFactory[] args) {
    return new ISerializedAggregateEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public ISerializedAggregateEvaluator createAggregateEvaluator(IHyracksTaskContext ctx) throws HyracksDataException {
            return new SerializableIntermediateStddevPopAggregateFunction(args, ctx, sourceLoc);
        }
    };
}
#method_after
@Override
public ISerializedAggregateEvaluatorFactory createSerializableAggregateEvaluatorFactory(final IScalarEvaluatorFactory[] args) {
    return new ISerializedAggregateEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public ISerializedAggregateEvaluator createAggregateEvaluator(IHyracksTaskContext ctx) throws HyracksDataException {
            return new SerializableIntermediateStddevAggregateFunction(args, ctx, true, sourceLoc);
        }
    };
}
#end_block

#method_before
@Override
public IAggregateEvaluatorFactory createAggregateEvaluatorFactory(final IScalarEvaluatorFactory[] args) {
    return new IAggregateEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IAggregateEvaluator createAggregateEvaluator(final IHyracksTaskContext ctx) throws HyracksDataException {
            return new SqlStddevPopAggregateFunction(args, ctx, sourceLoc);
        }
    };
}
#method_after
@Override
public IAggregateEvaluatorFactory createAggregateEvaluatorFactory(final IScalarEvaluatorFactory[] args) {
    return new IAggregateEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IAggregateEvaluator createAggregateEvaluator(final IHyracksTaskContext ctx) throws HyracksDataException {
            return new SqlStddevAggregateFunction(args, ctx, true, sourceLoc);
        }
    };
}
#end_block

#method_before
@Override
public int getSplitCount() {
    return endOffsets.length / fields;
}
#method_after
public int getSplitCount() {
    return endOffsets.length / numFields;
}
#end_block

#method_before
@Override
public byte[] getByteArray() {
    return bytes;
}
#method_after
public byte[] getByteArray() {
    return bytes;
}
#end_block

#method_before
@Override
public int getTag(int fieldNumber, int splitNumber) {
    return getSplitValueTag(getSplitValueIndex(fieldNumber, splitNumber));
}
#method_after
public int getTag(int fieldIndex, int splitIndex) {
    return getSplitValueTag(getSplitValueIndex(fieldIndex, splitIndex));
}
#end_block

#method_before
@Override
public int getStartOffset(int fieldNumber, int splitNumber) {
    return getSplitValueStart(getSplitValueIndex(fieldNumber, splitNumber));
}
#method_after
public int getStartOffset(int fieldIndex, int splitIndex) {
    return getSplitValueStart(getSplitValueIndex(fieldIndex, splitIndex));
}
#end_block

#method_before
@Override
public int getLength(int fieldNumber, int splitNumber) {
    return getSplitValueLength(getSplitValueIndex(fieldNumber, splitNumber));
}
#method_after
public int getLength(int fieldIndex, int splitIndex) {
    return getSplitValueLength(getSplitValueIndex(fieldIndex, splitIndex));
}
#end_block

#method_before
private int getSplitValueIndex(int fieldNumber, int splitNumber) {
    return splitNumber * fields + fieldNumber;
}
#method_after
private int getSplitValueIndex(int fieldIndex, int splitIndex) {
    return splitIndex * numFields + fieldIndex;
}
#end_block

#method_before
private int getSplitValueTag(int absoluteIndex) {
    return bytes[getSplitValueStart(absoluteIndex)];
}
#method_after
private int getSplitValueTag(int splitValueIndex) {
    return bytes[getSplitValueStart(splitValueIndex)];
}
#end_block

#method_before
private int getSplitValueStart(int absoluteIndex) {
    int start = 0;
    if (absoluteIndex != 0) {
        start = endOffsets[absoluteIndex - 1];
    }
    return start;
}
#method_after
private int getSplitValueStart(int splitValueIndex) {
    int start = 0;
    if (splitValueIndex != 0) {
        start = endOffsets[splitValueIndex - 1];
    }
    return start;
}
#end_block

#method_before
private int getSplitValueLength(int absoluteIndex) {
    int length = endOffsets[absoluteIndex];
    if (absoluteIndex != 0) {
        length -= endOffsets[absoluteIndex - 1];
    }
    return length;
}
#method_after
private int getSplitValueLength(int splitValueIndex) {
    int length = endOffsets[splitValueIndex];
    if (splitValueIndex != 0) {
        length -= endOffsets[splitValueIndex - 1];
    }
    return length;
}
#end_block

#method_before
@Override
public Void visitGroupByOperator(GroupByOperator op, IOptimizationContext ctx) throws AlgebricksException {
    Map<LogicalVariable, EquivalenceClass> equivalenceClasses = new HashMap<LogicalVariable, EquivalenceClass>();
    List<FunctionalDependency> functionalDependencies = new ArrayList<FunctionalDependency>();
    ctx.putEquivalenceClassMap(op, equivalenceClasses);
    ctx.putFDList(op, functionalDependencies);
    List<FunctionalDependency> inheritedFDs = new ArrayList<FunctionalDependency>();
    for (ILogicalPlan p : op.getNestedPlans()) {
        for (Mutable<ILogicalOperator> r : p.getRoots()) {
            ILogicalOperator op2 = r.getValue();
            equivalenceClasses.putAll(getOrComputeEqClasses(op2, ctx));
            inheritedFDs.addAll(getOrComputeFDs(op2, ctx));
        }
    }
    ILogicalOperator op0 = op.getInputs().get(0).getValue();
    inheritedFDs.addAll(getOrComputeFDs(op0, ctx));
    Map<LogicalVariable, EquivalenceClass> inheritedEcs = getOrComputeEqClasses(op0, ctx);
    for (FunctionalDependency inherited : inheritedFDs) {
        boolean isCoveredByGbyOrDecorVars = true;
        List<LogicalVariable> newHead = new ArrayList<LogicalVariable>(inherited.getHead().size());
        for (LogicalVariable v : inherited.getHead()) {
            LogicalVariable vnew = getNewGbyVar(op, v);
            if (vnew == null) {
                vnew = getNewDecorVar(op, v);
                if (vnew == null) {
                    isCoveredByGbyOrDecorVars = false;
                }
                break;
            }
            newHead.add(vnew);
        }
        if (isCoveredByGbyOrDecorVars) {
            List<LogicalVariable> newTail = new ArrayList<LogicalVariable>();
            for (LogicalVariable v2 : inherited.getTail()) {
                LogicalVariable v3 = getNewGbyVar(op, v2);
                if (v3 != null) {
                    newTail.add(v3);
                }
            }
            if (!newTail.isEmpty()) {
                FunctionalDependency newFd = new FunctionalDependency(newHead, newTail);
                functionalDependencies.add(newFd);
            }
        }
    }
    List<LogicalVariable> premiseGby = new LinkedList<LogicalVariable>();
    List<Pair<LogicalVariable, Mutable<ILogicalExpression>>> gByList = op.getGroupByList();
    for (Pair<LogicalVariable, Mutable<ILogicalExpression>> p : gByList) {
        premiseGby.add(p.first);
    }
    List<Pair<LogicalVariable, Mutable<ILogicalExpression>>> decorList = op.getDecorList();
    LinkedList<LogicalVariable> conclDecor = new LinkedList<LogicalVariable>();
    for (Pair<LogicalVariable, Mutable<ILogicalExpression>> p : decorList) {
        conclDecor.add(GroupByOperator.getDecorVariable(p));
    }
    if (!conclDecor.isEmpty()) {
        functionalDependencies.add(new FunctionalDependency(premiseGby, conclDecor));
    }
    Set<LogicalVariable> gbySet = new HashSet<LogicalVariable>();
    for (Pair<LogicalVariable, Mutable<ILogicalExpression>> p : gByList) {
        ILogicalExpression expr = p.second.getValue();
        if (expr.getExpressionTag() == LogicalExpressionTag.VARIABLE) {
            VariableReferenceExpression v = (VariableReferenceExpression) expr;
            gbySet.add(v.getVariableReference());
        }
    }
    LocalGroupingProperty lgp = new LocalGroupingProperty(gbySet);
    ILocalStructuralProperty normalizedLgp = lgp.normalize(inheritedEcs, inheritedFDs);
    Set<LogicalVariable> normSet = new ListSet<>();
    normalizedLgp.getColumns(normSet);
    List<Pair<LogicalVariable, Mutable<ILogicalExpression>>> newGbyList = new ArrayList<>();
    boolean changed = false;
    for (Pair<LogicalVariable, Mutable<ILogicalExpression>> p : gByList) {
        ILogicalExpression expr = p.second.getValue();
        if (expr.getExpressionTag() == LogicalExpressionTag.VARIABLE) {
            VariableReferenceExpression varRef = (VariableReferenceExpression) expr;
            LogicalVariable v2 = varRef.getVariableReference();
            EquivalenceClass ec2 = inheritedEcs.get(v2);
            LogicalVariable v3;
            if (ec2 != null && !ec2.representativeIsConst()) {
                v3 = ec2.getVariableRepresentative();
            } else {
                v3 = v2;
            }
            if (normSet.contains(v3)) {
                newGbyList.add(p);
            } else {
                changed = true;
                decorList.add(p);
            }
        } else {
            newGbyList.add(p);
        }
    }
    if (changed) {
        AlgebricksConfig.ALGEBRICKS_LOGGER.debug(">>>> Group-by list changed from " + GroupByOperator.veListToString(gByList) + " to " + GroupByOperator.veListToString(newGbyList) + ".\n");
    }
    gByList.clear();
    gByList.addAll(newGbyList);
    return null;
}
#method_after
@Override
public Void visitGroupByOperator(GroupByOperator op, IOptimizationContext ctx) throws AlgebricksException {
    Map<LogicalVariable, EquivalenceClass> equivalenceClasses = new HashMap<LogicalVariable, EquivalenceClass>();
    List<FunctionalDependency> functionalDependencies = new ArrayList<FunctionalDependency>();
    ctx.putEquivalenceClassMap(op, equivalenceClasses);
    ctx.putFDList(op, functionalDependencies);
    List<FunctionalDependency> inheritedFDs = new ArrayList<FunctionalDependency>();
    for (ILogicalPlan p : op.getNestedPlans()) {
        for (Mutable<ILogicalOperator> r : p.getRoots()) {
            ILogicalOperator op2 = r.getValue();
            equivalenceClasses.putAll(getOrComputeEqClasses(op2, ctx));
            inheritedFDs.addAll(getOrComputeFDs(op2, ctx));
        }
    }
    ILogicalOperator op0 = op.getInputs().get(0).getValue();
    inheritedFDs.addAll(getOrComputeFDs(op0, ctx));
    Map<LogicalVariable, EquivalenceClass> inheritedEcs = getOrComputeEqClasses(op0, ctx);
    for (FunctionalDependency inherited : inheritedFDs) {
        boolean isCoveredByGbyOrDecorVars = true;
        List<LogicalVariable> newHead = new ArrayList<LogicalVariable>(inherited.getHead().size());
        for (LogicalVariable v : inherited.getHead()) {
            LogicalVariable vnew = getNewGbyVar(op, v);
            if (vnew == null) {
                vnew = getNewDecorVar(op, v);
                if (vnew == null) {
                    isCoveredByGbyOrDecorVars = false;
                }
                break;
            }
            newHead.add(vnew);
        }
        if (isCoveredByGbyOrDecorVars) {
            List<LogicalVariable> newTail = new ArrayList<LogicalVariable>();
            for (LogicalVariable v2 : inherited.getTail()) {
                LogicalVariable v3 = getNewGbyVar(op, v2);
                if (v3 != null) {
                    newTail.add(v3);
                }
            }
            if (!newTail.isEmpty()) {
                FunctionalDependency newFd = new FunctionalDependency(newHead, newTail);
                functionalDependencies.add(newFd);
            }
        }
    }
    List<LogicalVariable> premiseGby = new LinkedList<LogicalVariable>();
    List<Pair<LogicalVariable, Mutable<ILogicalExpression>>> gByList = op.getGroupByList();
    for (Pair<LogicalVariable, Mutable<ILogicalExpression>> p : gByList) {
        premiseGby.add(p.first);
    }
    List<Pair<LogicalVariable, Mutable<ILogicalExpression>>> decorList = op.getDecorList();
    LinkedList<LogicalVariable> conclDecor = new LinkedList<LogicalVariable>();
    for (Pair<LogicalVariable, Mutable<ILogicalExpression>> p : decorList) {
        conclDecor.add(GroupByOperator.getDecorVariable(p));
    }
    if (!conclDecor.isEmpty()) {
        functionalDependencies.add(new FunctionalDependency(premiseGby, conclDecor));
    }
    Set<LogicalVariable> gbySet = new HashSet<LogicalVariable>();
    for (Pair<LogicalVariable, Mutable<ILogicalExpression>> p : gByList) {
        ILogicalExpression expr = p.second.getValue();
        if (expr.getExpressionTag() == LogicalExpressionTag.VARIABLE) {
            VariableReferenceExpression v = (VariableReferenceExpression) expr;
            gbySet.add(v.getVariableReference());
        }
    }
    LocalGroupingProperty lgp = new LocalGroupingProperty(gbySet);
    ILocalStructuralProperty normalizedLgp = lgp.normalize(inheritedEcs, inheritedFDs);
    Set<LogicalVariable> normSet = new ListSet<>();
    normalizedLgp.getColumns(normSet);
    List<Pair<LogicalVariable, Mutable<ILogicalExpression>>> newGbyList = new ArrayList<>();
    boolean changed = false;
    for (Pair<LogicalVariable, Mutable<ILogicalExpression>> p : gByList) {
        ILogicalExpression expr = p.second.getValue();
        if (expr.getExpressionTag() == LogicalExpressionTag.VARIABLE) {
            VariableReferenceExpression varRef = (VariableReferenceExpression) expr;
            LogicalVariable v2 = varRef.getVariableReference();
            EquivalenceClass ec2 = inheritedEcs.get(v2);
            LogicalVariable v3;
            if (ec2 != null && !ec2.representativeIsConst()) {
                v3 = ec2.getVariableRepresentative();
            } else {
                v3 = v2;
            }
            if (normSet.contains(v3)) {
                newGbyList.add(p);
            } else {
                changed = true;
                decorList.add(p);
            }
        } else {
            newGbyList.add(p);
        }
    }
    if (changed && AlgebricksConfig.ALGEBRICKS_LOGGER.isTraceEnabled()) {
        AlgebricksConfig.ALGEBRICKS_LOGGER.trace(">>>> Group-by list changed from " + GroupByOperator.veListToString(gByList) + " to " + GroupByOperator.veListToString(newGbyList) + ".\n");
    }
    gByList.clear();
    gByList.addAll(newGbyList);
    return null;
}
#end_block

#method_before
@Override
public Void visitForwardOperator(ForwardOperator op, Void arg) throws AlgebricksException {
    standardLayout(op);
    return null;
}
#method_after
@Override
public Void visitForwardOperator(ForwardOperator op, Void arg) throws AlgebricksException {
    // only consider variables from the branch of the data source
    VariableUtilities.getLiveVariables(op.getInputs().get(0).getValue(), schemaVariables);
    return null;
}
#end_block

#method_before
public static final List<IAlgebraicRewriteRule> buildNormalizationRuleCollection(ICcApplicationContext appCtx) {
    List<IAlgebraicRewriteRule> normalization = new LinkedList<>();
    normalization.add(new CheckInsertUpsertReturningRule());
    normalization.add(new IntroduceUnnestForCollectionToSequenceRule());
    normalization.add(new EliminateSubplanRule());
    normalization.add(new EnforceOrderByAfterSubplan());
    normalization.add(new BreakSelectIntoConjunctsRule());
    normalization.add(new ExtractGbyExpressionsRule());
    normalization.add(new ExtractDistinctByExpressionsRule());
    normalization.add(new ExtractOrderExpressionsRule());
    // IntroduceStaticTypeCastRule should go before
    // IntroduceDynamicTypeCastRule to
    // avoid unnecessary dynamic casting
    normalization.add(new IntroduceStaticTypeCastForInsertRule());
    normalization.add(new IntroduceDynamicTypeCastRule());
    normalization.add(new IntroduceDynamicTypeCastForExternalFunctionRule());
    normalization.add(new IntroduceEnforcedListTypeRule());
    normalization.add(new ExtractCommonExpressionsRule());
    // Let PushAggFuncIntoStandaloneAggregateRule run after ExtractCommonExpressionsRule
    // so that PushAggFunc can happen in fewer places.
    normalization.add(new PushAggFuncIntoStandaloneAggregateRule());
    normalization.add(new ListifyUnnestingFunctionRule());
    normalization.add(new ConstantFoldingRule(appCtx));
    normalization.add(new RemoveRedundantSelectRule());
    normalization.add(new UnnestToDataScanRule());
    normalization.add(new MetaFunctionToMetaVariableRule());
    normalization.add(new FuzzyEqRule());
    normalization.add(new SimilarityCheckRule());
    return normalization;
}
#method_after
public static final List<IAlgebraicRewriteRule> buildNormalizationRuleCollection(ICcApplicationContext appCtx) {
    List<IAlgebraicRewriteRule> normalization = new LinkedList<>();
    normalization.add(new CheckInsertUpsertReturningRule());
    normalization.add(new IntroduceUnnestForCollectionToSequenceRule());
    normalization.add(new EliminateSubplanRule());
    normalization.add(new EnforceOrderByAfterSubplan());
    normalization.add(new BreakSelectIntoConjunctsRule());
    normalization.add(new ExtractGbyExpressionsRule());
    normalization.add(new ExtractDistinctByExpressionsRule());
    normalization.add(new ExtractOrderExpressionsRule());
    // IntroduceStaticTypeCastRule should go before
    // IntroduceDynamicTypeCastRule to
    // avoid unnecessary dynamic casting
    normalization.add(new IntroduceStaticTypeCastForInsertRule());
    normalization.add(new IntroduceDynamicTypeCastRule());
    normalization.add(new IntroduceDynamicTypeCastForExternalFunctionRule());
    normalization.add(new IntroduceEnforcedListTypeRule());
    // Perform constant folding before common expression extraction
    normalization.add(new ConstantFoldingRule(appCtx));
    normalization.add(new ExtractCommonExpressionsRule());
    // Let PushAggFuncIntoStandaloneAggregateRule run after ExtractCommonExpressionsRule
    // so that PushAggFunc can happen in fewer places.
    normalization.add(new PushAggFuncIntoStandaloneAggregateRule());
    normalization.add(new ListifyUnnestingFunctionRule());
    normalization.add(new RemoveRedundantSelectRule());
    normalization.add(new UnnestToDataScanRule());
    normalization.add(new MetaFunctionToMetaVariableRule());
    normalization.add(new FuzzyEqRule());
    normalization.add(new SimilarityCheckRule());
    return normalization;
}
#end_block

#method_before
public static final List<IAlgebraicRewriteRule> buildFuzzyJoinRuleCollection() {
    List<IAlgebraicRewriteRule> fuzzy = new LinkedList<>();
    // fuzzy.add(new FuzzyJoinRule()); -- The non-indexed fuzzy join will be temporarily disabled. It should be enabled some time in the near future.
    fuzzy.add(new InferTypesRule());
    return fuzzy;
}
#method_after
public static final List<IAlgebraicRewriteRule> buildFuzzyJoinRuleCollection() {
    List<IAlgebraicRewriteRule> fuzzy = new LinkedList<>();
    fuzzy.add(new FuzzyJoinRule());
    fuzzy.add(new ExtractCommonExpressionsRule());
    fuzzy.add(new NestedSubplanToJoinRule());
    fuzzy.add(new PushSelectIntoJoinRule());
    fuzzy.add(new RemoveUnusedAssignAndAggregateRule());
    fuzzy.add(new InlineSubplanInputForNestedTupleSourceRule());
    fuzzy.add(new RemoveRedundantVariablesRule());
    fuzzy.add(new AsterixInlineVariablesRule());
    fuzzy.add(new RemoveUnusedAssignAndAggregateRule());
    return fuzzy;
}
#end_block

#method_before
public static final List<IAlgebraicRewriteRule> buildPlanCleanupRuleCollection() {
    List<IAlgebraicRewriteRule> planCleanupRules = new LinkedList<>();
    planCleanupRules.add(new SwitchInnerJoinBranchRule());
    planCleanupRules.add(new PushAssignBelowUnionAllRule());
    planCleanupRules.add(new ExtractCommonExpressionsRule());
    planCleanupRules.add(new RemoveRedundantVariablesRule());
    planCleanupRules.add(new PushProjectDownRule());
    planCleanupRules.add(new PushSelectDownRule());
    planCleanupRules.add(new SetClosedRecordConstructorsRule());
    planCleanupRules.add(new IntroduceDynamicTypeCastRule());
    planCleanupRules.add(new IntroduceDynamicTypeCastForExternalFunctionRule());
    planCleanupRules.add(new RemoveUnusedAssignAndAggregateRule());
    planCleanupRules.add(new RemoveCartesianProductWithEmptyBranchRule());
    planCleanupRules.add(new InjectTypeCastForSwitchCaseRule());
    planCleanupRules.add(new InjectTypeCastForUnionRule());
    // Needs to invoke ByNameToByIndexFieldAccessRule as the last logical optimization rule because
    // some rules can push a FieldAccessByName to a place where the name it tries to access is in the closed part.
    // For example, a possible scenario is that a field-access-by-name can be pushed down through UnionAllOperator.
    planCleanupRules.add(new ByNameToByIndexFieldAccessRule());
    return planCleanupRules;
}
#method_after
public static final List<IAlgebraicRewriteRule> buildPlanCleanupRuleCollection() {
    List<IAlgebraicRewriteRule> planCleanupRules = new LinkedList<>();
    planCleanupRules.add(new SwitchInnerJoinBranchRule());
    planCleanupRules.add(new PushAssignBelowUnionAllRule());
    planCleanupRules.add(new ExtractCommonExpressionsRule());
    planCleanupRules.add(new RemoveRedundantVariablesRule());
    planCleanupRules.add(new PushProjectDownRule());
    planCleanupRules.add(new PushSelectDownRule());
    planCleanupRules.add(new SetClosedRecordConstructorsRule());
    planCleanupRules.add(new IntroduceDynamicTypeCastRule());
    planCleanupRules.add(new IntroduceDynamicTypeCastForExternalFunctionRule());
    planCleanupRules.add(new RemoveUnusedAssignAndAggregateRule());
    planCleanupRules.add(new RemoveCartesianProductWithEmptyBranchRule());
    planCleanupRules.add(new InjectTypeCastForFunctionArgumentsRule());
    planCleanupRules.add(new InjectTypeCastForUnionRule());
    // Needs to invoke ByNameToByIndexFieldAccessRule as the last logical optimization rule because
    // some rules can push a FieldAccessByName to a place where the name it tries to access is in the closed part.
    // For example, a possible scenario is that a field-access-by-name can be pushed down through UnionAllOperator.
    planCleanupRules.add(new ByNameToByIndexFieldAccessRule());
    return planCleanupRules;
}
#end_block

#method_before
public static final List<IAlgebraicRewriteRule> buildPhysicalRewritesAllLevelsRuleCollection() {
    List<IAlgebraicRewriteRule> physicalRewritesAllLevels = new LinkedList<>();
    physicalRewritesAllLevels.add(new PullSelectOutOfEqJoin());
    // Turned off the following rule for now not to change OptimizerTest results.
    physicalRewritesAllLevels.add(new SetupCommitExtensionOpRule());
    physicalRewritesAllLevels.add(new SetAlgebricksPhysicalOperatorsRule());
    physicalRewritesAllLevels.add(new SetAsterixPhysicalOperatorsRule());
    physicalRewritesAllLevels.add(new AddEquivalenceClassForRecordConstructorRule());
    physicalRewritesAllLevels.add(new EnforceStructuralPropertiesRule());
    physicalRewritesAllLevels.add(new RemoveSortInFeedIngestionRule());
    physicalRewritesAllLevels.add(new RemoveUnnecessarySortMergeExchange());
    physicalRewritesAllLevels.add(new PushProjectDownRule());
    physicalRewritesAllLevels.add(new InsertProjectBeforeUnionRule());
    physicalRewritesAllLevels.add(new IntroduceMaterializationForInsertWithSelfScanRule());
    physicalRewritesAllLevels.add(new InlineSingleReferenceVariablesRule());
    physicalRewritesAllLevels.add(new RemoveUnusedAssignAndAggregateRule());
    physicalRewritesAllLevels.add(new ConsolidateAssignsRule());
    // After adding projects, we may need need to set physical operators again.
    physicalRewritesAllLevels.add(new SetAlgebricksPhysicalOperatorsRule());
    return physicalRewritesAllLevels;
}
#method_after
public static final List<IAlgebraicRewriteRule> buildPhysicalRewritesAllLevelsRuleCollection() {
    List<IAlgebraicRewriteRule> physicalRewritesAllLevels = new LinkedList<>();
    physicalRewritesAllLevels.add(new PullSelectOutOfEqJoin());
    // Turned off the following rule for now not to change OptimizerTest results.
    physicalRewritesAllLevels.add(new SetupCommitExtensionOpRule());
    physicalRewritesAllLevels.add(new SetAlgebricksPhysicalOperatorsRule());
    physicalRewritesAllLevels.add(new SetAsterixPhysicalOperatorsRule());
    physicalRewritesAllLevels.add(new AddEquivalenceClassForRecordConstructorRule());
    physicalRewritesAllLevels.add(new CheckFullParallelSortRule());
    physicalRewritesAllLevels.add(new EnforceStructuralPropertiesRule(BuiltinFunctions.RANGE_MAP, BuiltinFunctions.LOCAL_SAMPLING));
    physicalRewritesAllLevels.add(new RemoveSortInFeedIngestionRule());
    physicalRewritesAllLevels.add(new RemoveUnnecessarySortMergeExchange());
    physicalRewritesAllLevels.add(new PushProjectDownRule());
    physicalRewritesAllLevels.add(new IntroduceMaterializationForInsertWithSelfScanRule());
    physicalRewritesAllLevels.add(new InlineSingleReferenceVariablesRule());
    physicalRewritesAllLevels.add(new RemoveUnusedAssignAndAggregateRule());
    physicalRewritesAllLevels.add(new ConsolidateAssignsRule());
    // After adding projects, we may need need to set physical operators again.
    physicalRewritesAllLevels.add(new SetAlgebricksPhysicalOperatorsRule());
    return physicalRewritesAllLevels;
}
#end_block

#method_before
public static final List<IAlgebraicRewriteRule> buildPhysicalRewritesTopLevelRuleCollection(ICcApplicationContext appCtx) {
    List<IAlgebraicRewriteRule> physicalRewritesTopLevel = new LinkedList<>();
    physicalRewritesTopLevel.add(new PushNestedOrderByUnderPreSortedGroupByRule());
    physicalRewritesTopLevel.add(new CopyLimitDownRule());
    // CopyLimitDownRule may generates non-topmost limits with numeric_adds functions.
    // We are going to apply a constant folding rule again for this case.
    physicalRewritesTopLevel.add(new ConstantFoldingRule(appCtx));
    physicalRewritesTopLevel.add(new PushLimitIntoOrderByRule());
    physicalRewritesTopLevel.add(new IntroduceProjectsRule());
    physicalRewritesTopLevel.add(new SetAlgebricksPhysicalOperatorsRule());
    physicalRewritesTopLevel.add(new IntroduceRapidFrameFlushProjectAssignRule());
    physicalRewritesTopLevel.add(new SetExecutionModeRule());
    physicalRewritesTopLevel.add(new IntroduceRandomPartitioningFeedComputationRule());
    return physicalRewritesTopLevel;
}
#method_after
public static final List<IAlgebraicRewriteRule> buildPhysicalRewritesTopLevelRuleCollection(ICcApplicationContext appCtx) {
    List<IAlgebraicRewriteRule> physicalRewritesTopLevel = new LinkedList<>();
    physicalRewritesTopLevel.add(new PushNestedOrderByUnderPreSortedGroupByRule());
    physicalRewritesTopLevel.add(new CopyLimitDownRule());
    // CopyLimitDownRule may generates non-topmost limits with numeric_adds functions.
    // We are going to apply a constant folding rule again for this case.
    physicalRewritesTopLevel.add(new ConstantFoldingRule(appCtx));
    physicalRewritesTopLevel.add(new PushLimitIntoOrderByRule());
    physicalRewritesTopLevel.add(new PushLimitIntoPrimarySearchRule());
    // remove assigns that could become unused after PushLimitIntoPrimarySearchRule
    physicalRewritesTopLevel.add(new RemoveUnusedAssignAndAggregateRule());
    physicalRewritesTopLevel.add(new IntroduceProjectsRule());
    physicalRewritesTopLevel.add(new SetAlgebricksPhysicalOperatorsRule());
    physicalRewritesTopLevel.add(new IntroduceRapidFrameFlushProjectAssignRule());
    physicalRewritesTopLevel.add(new SetExecutionModeRule());
    physicalRewritesTopLevel.add(new IntroduceRandomPartitioningFeedComputationRule());
    return physicalRewritesTopLevel;
}
#end_block

#method_before
public static final List<IAlgebraicRewriteRule> prepareForJobGenRuleCollection() {
    List<IAlgebraicRewriteRule> prepareForJobGenRewrites = new LinkedList<>();
    prepareForJobGenRewrites.add(new IsolateHyracksOperatorsRule(HeuristicOptimizer.hyraxOperatorsBelowWhichJobGenIsDisabled));
    prepareForJobGenRewrites.add(new ExtractCommonOperatorsRule());
    prepareForJobGenRewrites.add(new PushGroupByIntoSortRule());
    prepareForJobGenRewrites.add(new IntroduceParallelSort());
    prepareForJobGenRewrites.add(new IsolateHyracksOperatorsRule(HeuristicOptimizer.hyraxOperatorsBelowWhichJobGenIsDisabled));
    // Re-infer all types, so that, e.g., the effect of not-is-null is
    // propagated.
    prepareForJobGenRewrites.add(new ReinferAllTypesRule());
    prepareForJobGenRewrites.add(new SetExecutionModeRule());
    prepareForJobGenRewrites.add(new RecomputeDeliveredPhysicalPropertiesRule());
    prepareForJobGenRewrites.add(new SweepIllegalNonfunctionalFunctions());
    prepareForJobGenRewrites.add(new FixReplicateOperatorOutputsRule());
    return prepareForJobGenRewrites;
}
#method_after
public static final List<IAlgebraicRewriteRule> prepareForJobGenRuleCollection() {
    List<IAlgebraicRewriteRule> prepareForJobGenRewrites = new LinkedList<>();
    prepareForJobGenRewrites.add(new InsertProjectBeforeUnionRule());
    prepareForJobGenRewrites.add(new SetAlgebricksPhysicalOperatorsRule());
    prepareForJobGenRewrites.add(new IsolateHyracksOperatorsRule(HeuristicOptimizer.hyraxOperatorsBelowWhichJobGenIsDisabled));
    prepareForJobGenRewrites.add(new FixReplicateOperatorOutputsRule());
    prepareForJobGenRewrites.add(new ExtractCommonOperatorsRule());
    // Re-infer all types, so that, e.g., the effect of not-is-null is
    // propagated.
    prepareForJobGenRewrites.add(new ReinferAllTypesRule());
    prepareForJobGenRewrites.add(new PushGroupByIntoSortRule());
    prepareForJobGenRewrites.add(new SetExecutionModeRule());
    prepareForJobGenRewrites.add(new SweepIllegalNonfunctionalFunctions());
    prepareForJobGenRewrites.add(new FixReplicateOperatorOutputsRule());
    return prepareForJobGenRewrites;
}
#end_block

#method_before
@Override
public IAggregateEvaluatorFactory createAggregateEvaluatorFactory(final IScalarEvaluatorFactory[] args) {
    return new IAggregateEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IAggregateEvaluator createAggregateEvaluator(final IHyracksTaskContext ctx) throws HyracksDataException {
            return new LocalSamplingAggregateFunction(args, ctx, numPartitions);
        }
    };
}
#method_after
@Override
public IAggregateEvaluatorFactory createAggregateEvaluatorFactory(final IScalarEvaluatorFactory[] args) {
    return new IAggregateEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IAggregateEvaluator createAggregateEvaluator(final IHyracksTaskContext ctx) throws HyracksDataException {
            return new LocalSamplingAggregateFunction(args, ctx, numSamples);
        }
    };
}
#end_block

#method_before
@Override
public void init() throws HyracksDataException {
    numberOfSplitPointsSeen = 0;
}
#method_after
@Override
public void init() throws HyracksDataException {
    numSamplesTaken = 0;
    listOfSamplesBuilder.reset(ListOfSamplesTypeComputer.TYPE);
}
#end_block

#method_before
@Override
public void step(IFrameTupleReference tuple) throws HyracksDataException {
    // if num of partitions = 1, then??
    if (numberOfSplitPointsSeen >= numberOfPartitions - 1) {
        return;
    }
    List<byte[]> splitPoint = new ArrayList<>(inputArgsEval.length);
    for (IScalarEvaluator fieldEval : inputArgsEval) {
        fieldEval.evaluate(tuple, inputFieldValue);
        byte[] fieldValue = new byte[inputFieldValue.getLength()];
        System.arraycopy(inputFieldValue.getByteArray(), inputFieldValue.getStartOffset(), fieldValue, 0, inputFieldValue.getLength());
        splitPoint.add(fieldValue);
    }
    splitPoints.add(splitPoint);
    numberOfSplitPointsSeen++;
}
#method_after
@Override
public void step(IFrameTupleReference tuple) throws HyracksDataException {
    if (numSamplesTaken >= numSamplesRequired) {
        return;
    }
    // start over for a new sample
    oneSampleBuilder.reset((AbstractCollectionType) ListOfSamplesTypeComputer.TYPE.getItemType());
    for (IScalarEvaluator fieldEval : sampledFieldsEval) {
        // add fields to make up one sample
        fieldEval.evaluate(tuple, inputFieldValue);
        oneSampleBuilder.addItem(inputFieldValue);
    }
    // prepare the sample to add it to the list of samples
    storage.reset();
    oneSampleBuilder.write(storage.getDataOutput(), true);
    listOfSamplesBuilder.addItem(storage);
    numSamplesTaken++;
}
#end_block

#method_before
@Override
public void finish(IPointable result) throws HyracksDataException {
    ArrayBackedValueStorage resultStorage = new ArrayBackedValueStorage();
    if (numberOfSplitPointsSeen == 0) {
        try {
            resultStorage.getDataOutput().writeByte(ATypeTag.SERIALIZED_SYSTEM_NULL_TYPE_TAG);
            result.set(resultStorage);
        } catch (IOException e) {
            throw new HyracksDataException(e);
        }
    } else {
        AOrderedListType listOfByteArrays = new AOrderedListType(BuiltinType.ABINARY, null);
        AOrderedListType listOfSplitValues = new AOrderedListType(listOfByteArrays, null);
        AOrderedList fieldsSplitValues = new AOrderedList(listOfSplitValues);
        for (List<byte[]> splitValuesOfField : splitPoints) {
            AOrderedList splitValues = new AOrderedList(listOfByteArrays);
            for (byte[] splitValue : splitValuesOfField) {
                splitValues.add(new ABinary(splitValue));
            }
            fieldsSplitValues.add(splitValues);
        }
        ISerializerDeserializer<AOrderedList> listSerde = SerializerDeserializerProvider.INSTANCE.getSerializerDeserializer(listOfSplitValues);
        listSerde.serialize(fieldsSplitValues, resultStorage.getDataOutput());
        result.set(resultStorage);
    }
}
#method_after
@Override
public void finish(IPointable result) throws HyracksDataException {
    storage.reset();
    if (numSamplesTaken == 0) {
        // empty partition? then send system null as an indication of empty partition.
        try {
            storage.getDataOutput().writeByte(ATypeTag.SERIALIZED_SYSTEM_NULL_TYPE_TAG);
            result.set(storage);
        } catch (IOException e) {
            throw HyracksDataException.create(e);
        }
    } else {
        listOfSamplesBuilder.write(storage.getDataOutput(), true);
        result.set(storage);
    }
}
#end_block

#method_before
@Override
public Boolean visitExchangeOperator(ExchangeOperator op, ILogicalOperator arg) throws AlgebricksException {
    AbstractLogicalOperator aop = (AbstractLogicalOperator) arg;
    if (aop.getOperatorTag() != LogicalOperatorTag.EXCHANGE) {
        return Boolean.FALSE;
    }
    // require the same partition property
    if (!(op.getPhysicalOperator().getOperatorTag() == aop.getPhysicalOperator().getOperatorTag())) {
        return Boolean.FALSE;
    }
    variableMapping.clear();
    IsomorphismUtilities.mapVariablesTopDown(op, arg, variableMapping);
    IPhysicalPropertiesVector properties = op.getPhysicalOperator().getDeliveredProperties();
    IPhysicalPropertiesVector propertiesArg = aop.getPhysicalOperator().getDeliveredProperties();
    if (properties == null && propertiesArg == null) {
        return Boolean.TRUE;
    }
    if (properties == null || propertiesArg == null) {
        return Boolean.FALSE;
    }
    IPartitioningProperty partProp = properties.getPartitioningProperty();
    IPartitioningProperty partPropArg = propertiesArg.getPartitioningProperty();
    if (!partProp.getPartitioningType().equals(partPropArg.getPartitioningType())) {
        return Boolean.FALSE;
    }
    List<LogicalVariable> columns = new ArrayList<LogicalVariable>();
    partProp.getColumns(columns);
    List<LogicalVariable> columnsArg = new ArrayList<LogicalVariable>();
    partPropArg.getColumns(columnsArg);
    if (columns.size() != columnsArg.size()) {
        return Boolean.FALSE;
    }
    if (columns.size() == 0) {
        return Boolean.TRUE;
    }
    for (int i = 0; i < columnsArg.size(); i++) {
        LogicalVariable rightVar = columnsArg.get(i);
        LogicalVariable leftVar = variableMapping.get(rightVar);
        if (leftVar != null) {
            columnsArg.set(i, leftVar);
        }
    }
    return VariableUtilities.varListEqualUnordered(columns, columnsArg);
}
#method_after
@Override
public Boolean visitExchangeOperator(ExchangeOperator op, ILogicalOperator arg) throws AlgebricksException {
    AbstractLogicalOperator aop = (AbstractLogicalOperator) arg;
    if (aop.getOperatorTag() != LogicalOperatorTag.EXCHANGE) {
        return Boolean.FALSE;
    }
    // require the same partition property
    if (!(op.getPhysicalOperator().getOperatorTag() == aop.getPhysicalOperator().getOperatorTag())) {
        return Boolean.FALSE;
    }
    variableMapping.clear();
    IsomorphismUtilities.mapVariablesTopDown(op, arg, variableMapping);
    IPhysicalPropertiesVector properties = op.getPhysicalOperator().getDeliveredProperties();
    IPhysicalPropertiesVector propertiesArg = aop.getPhysicalOperator().getDeliveredProperties();
    if (properties == null && propertiesArg == null) {
        return Boolean.TRUE;
    }
    if (properties == null || propertiesArg == null) {
        return Boolean.FALSE;
    }
    IPartitioningProperty partProp = properties.getPartitioningProperty();
    IPartitioningProperty partPropArg = propertiesArg.getPartitioningProperty();
    if (!partProp.getPartitioningType().equals(partPropArg.getPartitioningType())) {
        return Boolean.FALSE;
    }
    List<LogicalVariable> columns = new ArrayList<LogicalVariable>();
    partProp.getColumns(columns);
    List<LogicalVariable> columnsArg = new ArrayList<LogicalVariable>();
    partPropArg.getColumns(columnsArg);
    if (columns.size() != columnsArg.size()) {
        return Boolean.FALSE;
    }
    if (columns.size() == 0) {
        return Boolean.TRUE;
    }
    for (int i = 0; i < columnsArg.size(); i++) {
        LogicalVariable rightVar = columnsArg.get(i);
        LogicalVariable leftVar = variableMapping.get(rightVar);
        if (leftVar != null) {
            columnsArg.set(i, leftVar);
        }
    }
    return columns.equals(columnsArg);
}
#end_block

#method_before
@Override
public Boolean visitForwardOperator(ForwardOperator op, ILogicalOperator targetOp) throws AlgebricksException {
    AbstractLogicalOperator targetOperator = (AbstractLogicalOperator) targetOp;
    if (targetOperator.getOperatorTag() != LogicalOperatorTag.FORWARD) {
        return Boolean.FALSE;
    }
    return true;
}
#method_after
@Override
public Boolean visitForwardOperator(ForwardOperator op, ILogicalOperator arg) throws AlgebricksException {
    AbstractLogicalOperator argOperator = (AbstractLogicalOperator) arg;
    if (argOperator.getOperatorTag() != LogicalOperatorTag.FORWARD) {
        return Boolean.FALSE;
    }
    ForwardOperator otherOp = (ForwardOperator) copyAndSubstituteVar(op, arg);
    ILogicalExpression rangeMapExp = op.getRangeMapExpression().getValue();
    ILogicalExpression otherRangeMapExp = otherOp.getRangeMapExpression().getValue();
    return rangeMapExp.equals(otherRangeMapExp) && op.getRangeMapKey().equals(otherOp.getRangeMapKey());
}
#end_block

#method_before
@Override
public Void visitReplicateOperator(ReplicateOperator op, Void arg) throws AlgebricksException {
    // Makes sure that the downstream of a replicate operator is only visited once.
    if (!visitedOperators.contains(op)) {
        visitedOperators.add(op);
        visit(op);
    } else {
        merge(op);
    }
    return null;
}
#method_after
@Override
public Void visitReplicateOperator(ReplicateOperator op, Void arg) throws AlgebricksException {
    // make sure that the downstream of a replicate operator is visited only once.
    if (!visitedOperators.contains(op)) {
        visitedOperators.add(op);
        visit(op);
    } else {
        merge(op);
    }
    return null;
}
#end_block

#method_before
@Override
public Void visitSplitOperator(SplitOperator op, Void arg) throws AlgebricksException {
    // Makes sure that the downstream of a split operator is only visited once.
    if (!visitedOperators.contains(op)) {
        visitedOperators.add(op);
        visit(op);
    } else {
        merge(op);
    }
    return null;
}
#method_after
@Override
public Void visitSplitOperator(SplitOperator op, Void arg) throws AlgebricksException {
    // make sure that the downstream of a split operator is visited only once.
    if (!visitedOperators.contains(op)) {
        visitedOperators.add(op);
        visit(op);
    } else {
        merge(op);
    }
    return null;
}
#end_block

#method_before
@Override
public Void visitForwardOperator(ForwardOperator op, Void arg) throws AlgebricksException {
    // TODO(ali): should consider stages
    visit(op);
    return null;
}
#method_after
@Override
public Void visitForwardOperator(ForwardOperator op, Void arg) throws AlgebricksException {
    visit(op);
    return null;
}
#end_block

#method_before
private void visit(ILogicalOperator op) throws AlgebricksException {
    addToStage(op);
    if (!pendingBlockingOperators.isEmpty()) {
        final ILogicalOperator firstPending = pendingBlockingOperators.pop();
        visitBlocking(firstPending);
    }
}
#method_after
private void visit(ILogicalOperator op) throws AlgebricksException {
    addToStage(op);
    if (!pendingMultiStageOperators.isEmpty()) {
        final ILogicalOperator firstPending = pendingMultiStageOperators.pop();
        visitMultiStageOp(firstPending);
    }
}
#end_block

#method_before
private void addToStage(ILogicalOperator op) throws AlgebricksException {
    currentStage.getOperators().add(op);
    switch(op.getOperatorTag()) {
        case INNERJOIN:
        case LEFTOUTERJOIN:
            pendingBlockingOperators.add(op);
            // continue on the same stage
            final ILogicalOperator joinFirstInput = getJoinOperatorInput(op, JOIN_FIRST_INPUT);
            joinFirstInput.accept(this, null);
            break;
        case GROUP:
            if (isBlockingGroupBy((GroupByOperator) op)) {
                pendingBlockingOperators.add(op);
                return;
            }
            // continue on the same stage
            visitInputs(op);
            break;
        case ORDER:
            pendingBlockingOperators.add(op);
            break;
        default:
            visitInputs(op);
            break;
    }
}
#method_after
private void addToStage(ILogicalOperator op) throws AlgebricksException {
    currentStage.getOperators().add(op);
    switch(op.getOperatorTag()) {
        case INNERJOIN:
        case LEFTOUTERJOIN:
            pendingMultiStageOperators.add(op);
            // continue on the same stage
            final ILogicalOperator joinNonBlockingInput = getInputAt(op, JOIN_NON_BLOCKING_INPUT, JOIN_NUM_INPUTS);
            joinNonBlockingInput.accept(this, null);
            break;
        case GROUP:
            if (isBlockingGroupBy((GroupByOperator) op)) {
                pendingMultiStageOperators.add(op);
                return;
            }
            // continue on the same stage
            visitInputs(op);
            break;
        case ORDER:
            pendingMultiStageOperators.add(op);
            break;
        case FORWARD:
            pendingMultiStageOperators.add(op);
            // continue on the same current stage through the branch that is non-blocking
            ILogicalOperator nonBlockingInput = getInputAt(op, FORWARD_NON_BLOCKING_INPUT, FORWARD_NUM_INPUTS);
            nonBlockingInput.accept(this, null);
            break;
        default:
            visitInputs(op);
            break;
    }
}
#end_block

#method_before
@Override
public Void visitUnnestMapOperator(UnnestMapOperator op, Integer indent) throws AlgebricksException {
    return printAbstractUnnestMapOperator(op, indent, "unnest-map");
}
#method_after
@Override
public Void visitUnnestMapOperator(UnnestMapOperator op, Integer indent) throws AlgebricksException {
    AlgebricksAppendable plan = printAbstractUnnestMapOperator(op, indent, "unnest-map");
    appendSelectConditionInformation(plan, op.getSelectCondition(), indent);
    appendLimitInformation(plan, op.getOutputLimit(), indent);
    return null;
}
#end_block

#method_before
@Override
public Void visitLeftOuterUnnestMapOperator(LeftOuterUnnestMapOperator op, Integer indent) throws AlgebricksException {
    return printAbstractUnnestMapOperator(op, indent, "left-outer-unnest-map");
}
#method_after
@Override
public Void visitLeftOuterUnnestMapOperator(LeftOuterUnnestMapOperator op, Integer indent) throws AlgebricksException {
    printAbstractUnnestMapOperator(op, indent, "left-outer-unnest-map");
    return null;
}
#end_block

#method_before
private Void printAbstractUnnestMapOperator(AbstractUnnestMapOperator op, Integer indent, String opSignature) throws AlgebricksException {
    AlgebricksAppendable plan = addIndent(indent).append("\"operator\": \"" + opSignature + "\"");
    variablePrintHelper(op.getVariables(), indent);
    buffer.append(",\n");
    addIndent(indent).append("\"expressions\": \"" + op.getExpressionRef().getValue().accept(exprVisitor, indent).replace('"', ' ') + "\"");
    appendFilterInformation(plan, op.getMinFilterVars(), op.getMaxFilterVars(), indent);
    return null;
}
#method_after
private AlgebricksAppendable printAbstractUnnestMapOperator(AbstractUnnestMapOperator op, Integer indent, String opSignature) throws AlgebricksException {
    AlgebricksAppendable plan = addIndent(indent).append("\"operator\": \"" + opSignature + "\"");
    variablePrintHelper(op.getVariables(), indent);
    buffer.append(",\n");
    addIndent(indent).append("\"expressions\": \"" + op.getExpressionRef().getValue().accept(exprVisitor, indent).replace('"', ' ') + "\"");
    appendFilterInformation(plan, op.getMinFilterVars(), op.getMaxFilterVars(), indent);
    return plan;
}
#end_block

#method_before
@Override
public Void visitDataScanOperator(DataSourceScanOperator op, Integer indent) throws AlgebricksException {
    AlgebricksAppendable plan = addIndent(indent).append("\"operator\": \"data-scan\"");
    if (!op.getProjectVariables().isEmpty()) {
        addIndent(0).append(",\n");
        addIndent(indent).append("\"project-variables\": [");
        appendVars(op.getProjectVariables());
        buffer.append("]");
    }
    variablePrintHelper(op.getVariables(), indent);
    if (op.getDataSource() != null) {
        addIndent(0).append(",\n");
        addIndent(indent).append("\"data-source\": \"" + op.getDataSource() + "\"");
    }
    appendFilterInformation(plan, op.getMinFilterVars(), op.getMaxFilterVars(), indent);
    return null;
}
#method_after
@Override
public Void visitDataScanOperator(DataSourceScanOperator op, Integer indent) throws AlgebricksException {
    AlgebricksAppendable plan = addIndent(indent).append("\"operator\": \"data-scan\"");
    if (!op.getProjectVariables().isEmpty()) {
        addIndent(0).append(",\n");
        addIndent(indent).append("\"project-variables\": [");
        appendVars(op.getProjectVariables());
        buffer.append("]");
    }
    variablePrintHelper(op.getVariables(), indent);
    if (op.getDataSource() != null) {
        addIndent(0).append(",\n");
        addIndent(indent).append("\"data-source\": \"" + op.getDataSource() + "\"");
    }
    appendFilterInformation(plan, op.getMinFilterVars(), op.getMaxFilterVars(), indent);
    appendSelectConditionInformation(plan, op.getSelectCondition(), indent);
    appendLimitInformation(plan, op.getOutputLimit(), indent);
    return null;
}
#end_block

#method_before
@Override
public Void visitSplitOperator(SplitOperator op, Integer indent) throws AlgebricksException {
    Mutable<ILogicalExpression> branchingExpression = op.getBranchingExpression();
    addIndent(indent).append("\"operator\": \"split\",\n");
    addIndent(indent).append("\"" + branchingExpression.getValue().accept(exprVisitor, indent) + "\"");
    return null;
}
#method_after
@Override
public Void visitSplitOperator(SplitOperator op, Integer indent) throws AlgebricksException {
    Mutable<ILogicalExpression> branchingExpression = op.getBranchingExpression();
    addIndent(indent).append("\"operator\": \"split\",\n");
    addIndent(indent).append("\"expressions\": \"" + branchingExpression.getValue().accept(exprVisitor, indent).replace('"', ' ') + "\"");
    return null;
}
#end_block

#method_before
@Override
public Void visitInsertDeleteUpsertOperator(InsertDeleteUpsertOperator op, Integer indent) throws AlgebricksException {
    String header = "\"operator\": \"" + getIndexOpString(op.getOperation()) + "\",\n";
    addIndent(indent).append(header);
    addIndent(indent).append(str("\"data-source\": \"" + op.getDataSource() + "\",\n"));
    addIndent(indent).append("\"from-record\": \"").append(op.getPayloadExpression().getValue().accept(exprVisitor, indent) + "\"");
    if (op.getAdditionalNonFilteringExpressions() != null) {
        buffer.append(",\n\"meta\": \"");
        pprintExprList(op.getAdditionalNonFilteringExpressions(), 0);
        buffer.append("\"");
    }
    buffer.append(",\n");
    addIndent(indent).append("\"partitioned-by\": {");
    pprintExprList(op.getPrimaryKeyExpressions(), 0);
    buffer.append("}");
    if (op.getOperation() == Kind.UPSERT) {
        addIndent(indent).append(",\n\"out\": {\n");
        addIndent(indent).append("\"record-before-upsert\": \"" + op.getBeforeOpRecordVar() + "\"");
        if (op.getBeforeOpAdditionalNonFilteringVars() != null) {
            buffer.append(",\n");
            addIndent(indent).append("\"additional-before-upsert\": \"" + op.getBeforeOpAdditionalNonFilteringVars() + "\"");
        }
        addIndent(indent).append("}");
    }
    if (op.isBulkload()) {
        buffer.append(",\n");
        addIndent(indent).append("\"bulkload\": true");
    }
    return null;
}
#method_after
@Override
public Void visitInsertDeleteUpsertOperator(InsertDeleteUpsertOperator op, Integer indent) throws AlgebricksException {
    String header = "\"operator\": \"" + getIndexOpString(op.getOperation()) + "\",\n";
    addIndent(indent).append(header);
    addIndent(indent).append(str("\"data-source\": \"" + op.getDataSource() + "\",\n"));
    addIndent(indent).append("\"from-record\": \"").append(op.getPayloadExpression().getValue().accept(exprVisitor, indent) + "\"");
    if (op.getAdditionalNonFilteringExpressions() != null) {
        buffer.append(",\n\"meta\": {");
        pprintExprList(op.getAdditionalNonFilteringExpressions(), 0);
        buffer.append("}");
    }
    buffer.append(",\n");
    addIndent(indent).append("\"partitioned-by\": {");
    pprintExprList(op.getPrimaryKeyExpressions(), 0);
    buffer.append("}");
    if (op.getOperation() == Kind.UPSERT) {
        addIndent(indent).append(",\n\"out\": {\n");
        addIndent(indent).append("\"record-before-upsert\": \"" + op.getBeforeOpRecordVar() + "\"");
        if (op.getBeforeOpAdditionalNonFilteringVars() != null) {
            buffer.append(",\n");
            addIndent(indent).append("\"additional-before-upsert\": \"" + op.getBeforeOpAdditionalNonFilteringVars() + "\"");
        }
        addIndent(indent).append("}");
    }
    if (op.isBulkload()) {
        buffer.append(",\n");
        addIndent(indent).append("\"bulkload\": true");
    }
    return null;
}
#end_block

#method_before
@Override
public Void visitForwardOperator(ForwardOperator op, Integer indent) throws AlgebricksException {
    addIndent(indent).append("\"operator\": \"forward\"");
    return null;
}
#method_after
@Override
public Void visitForwardOperator(ForwardOperator op, Integer indent) throws AlgebricksException {
    addIndent(indent).append("\"operator\": \"forward\"");
    addIndent(indent).append("\"expressions\": \"" + op.getRangeMapExpression().getValue().accept(exprVisitor, indent).replace('"', ' ') + "\"");
    return null;
}
#end_block

#method_before
@Override
public ILogicalOperator visitUnnestMapOperator(UnnestMapOperator op, Void arg) throws AlgebricksException {
    ArrayList<LogicalVariable> newInputList = new ArrayList<>();
    newInputList.addAll(op.getVariables());
    return new UnnestMapOperator(newInputList, deepCopyExpressionRef(op.getExpressionRef()), new ArrayList<>(op.getVariableTypes()), op.propagatesInput());
}
#method_after
@Override
public ILogicalOperator visitUnnestMapOperator(UnnestMapOperator op, Void arg) throws AlgebricksException {
    ArrayList<LogicalVariable> newInputList = new ArrayList<>();
    newInputList.addAll(op.getVariables());
    Mutable<ILogicalExpression> newSelectCondition = op.getSelectCondition() != null ? deepCopyExpressionRef(op.getSelectCondition()) : null;
    return new UnnestMapOperator(newInputList, deepCopyExpressionRef(op.getExpressionRef()), new ArrayList<>(op.getVariableTypes()), op.propagatesInput(), newSelectCondition, op.getOutputLimit());
}
#end_block

#method_before
@Override
public ILogicalOperator visitDataScanOperator(DataSourceScanOperator op, Void arg) throws AlgebricksException {
    ArrayList<LogicalVariable> newInputList = new ArrayList<>();
    newInputList.addAll(op.getVariables());
    return new DataSourceScanOperator(newInputList, op.getDataSource());
}
#method_after
@Override
public ILogicalOperator visitDataScanOperator(DataSourceScanOperator op, Void arg) throws AlgebricksException {
    ArrayList<LogicalVariable> newInputList = new ArrayList<>();
    newInputList.addAll(op.getVariables());
    Mutable<ILogicalExpression> newSelectCondition = op.getSelectCondition() != null ? deepCopyExpressionRef(op.getSelectCondition()) : null;
    DataSourceScanOperator newOp = new DataSourceScanOperator(newInputList, op.getDataSource(), newSelectCondition, op.getOutputLimit());
    return newOp;
}
#end_block

#method_before
@Override
public ILogicalOperator visitForwardOperator(ForwardOperator op, Void arg) throws AlgebricksException {
    return new ForwardOperator();
}
#method_after
@Override
public ILogicalOperator visitForwardOperator(ForwardOperator op, Void arg) throws AlgebricksException {
    return new ForwardOperator(op.getRangeMapKey(), deepCopyExpressionRef(op.getRangeMapExpression()));
}
#end_block

#method_before
public void add(IFunctionDescriptorFactory descriptorFactory) {
    descriptorFactories.add(descriptorFactory);
}
#method_after
@Override
public void add(IFunctionDescriptorFactory descriptorFactory) {
    descriptorFactories.add(descriptorFactory);
}
#end_block

#method_before
public void addGenerated(IFunctionDescriptorFactory descriptorFactory) {
    add(getGeneratedFunctionDescriptorFactory(descriptorFactory.createFunctionDescriptor().getClass()));
}
#method_after
@Override
public void addGenerated(IFunctionDescriptorFactory descriptorFactory) {
    add(getGeneratedFunctionDescriptorFactory(descriptorFactory.createFunctionDescriptor().getClass()));
}
#end_block

#method_before
public static FunctionCollection createDefaultFunctionCollection() {
    FunctionCollection fc = new FunctionCollection();
    // unnesting function
    fc.add(TidRunningAggregateDescriptor.FACTORY);
    fc.add(ScanCollectionDescriptor.FACTORY);
    fc.add(RangeDescriptor.FACTORY);
    fc.add(SubsetCollectionDescriptor.FACTORY);
    // aggregate functions
    fc.add(ListifyAggregateDescriptor.FACTORY);
    fc.add(CountAggregateDescriptor.FACTORY);
    fc.add(AvgAggregateDescriptor.FACTORY);
    fc.add(LocalAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SumAggregateDescriptor.FACTORY);
    fc.add(LocalSumAggregateDescriptor.FACTORY);
    fc.add(MaxAggregateDescriptor.FACTORY);
    fc.add(LocalMaxAggregateDescriptor.FACTORY);
    fc.add(MinAggregateDescriptor.FACTORY);
    fc.add(LocalMinAggregateDescriptor.FACTORY);
    fc.add(FirstElementAggregateDescriptor.FACTORY);
    fc.add(LocalFirstElementAggregateDescriptor.FACTORY);
    fc.add(LocalSamplingAggregateDescriptor.FACTORY);
    fc.add(GlobalSamplingAggregateDescriptor.FACTORY);
    // serializable aggregates
    fc.add(SerializableCountAggregateDescriptor.FACTORY);
    fc.add(SerializableAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSumAggregateDescriptor.FACTORY);
    // scalar aggregates
    fc.add(ScalarCountAggregateDescriptor.FACTORY);
    fc.add(ScalarAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSumAggregateDescriptor.FACTORY);
    fc.add(ScalarMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarMinAggregateDescriptor.FACTORY);
    fc.add(EmptyStreamAggregateDescriptor.FACTORY);
    fc.add(NonEmptyStreamAggregateDescriptor.FACTORY);
    // SQL aggregates
    fc.add(SqlCountAggregateDescriptor.FACTORY);
    fc.add(SqlAvgAggregateDescriptor.FACTORY);
    fc.add(LocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SqlSumAggregateDescriptor.FACTORY);
    fc.add(LocalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SqlMaxAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMaxAggregateDescriptor.FACTORY);
    fc.add(SqlMinAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMinAggregateDescriptor.FACTORY);
    fc.add(CountMissingAggregateDescriptor.FACTORY);
    fc.add(CountNullAggregateDescriptor.FACTORY);
    // SQL serializable aggregates
    fc.add(SerializableSqlCountAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlSumAggregateDescriptor.FACTORY);
    // SQL scalar aggregates
    fc.add(ScalarSqlCountAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlSumAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMinAggregateDescriptor.FACTORY);
    // boolean functions
    fc.add(AndDescriptor.FACTORY);
    fc.add(OrDescriptor.FACTORY);
    // Record constructors
    fc.add(ClosedRecordConstructorDescriptor.FACTORY);
    fc.add(OpenRecordConstructorDescriptor.FACTORY);
    // List constructors
    fc.add(OrderedListConstructorDescriptor.FACTORY);
    fc.add(UnorderedListConstructorDescriptor.FACTORY);
    // Sleep function
    fc.add(SleepDescriptor.FACTORY);
    // Inject failure function
    fc.add(InjectFailureDescriptor.FACTORY);
    // Get Job Parameter function
    fc.add(GetJobParameterByNameDescriptor.FACTORY);
    // Switch case
    fc.add(SwitchCaseDescriptor.FACTORY);
    // null functions
    fc.add(IsMissingDescriptor.FACTORY);
    fc.add(IsNullDescriptor.FACTORY);
    fc.add(IsUnknownDescriptor.FACTORY);
    fc.add(IsSystemNullDescriptor.FACTORY);
    fc.add(CheckUnknownDescriptor.FACTORY);
    fc.add(IfMissingDescriptor.FACTORY);
    fc.add(IfNullDescriptor.FACTORY);
    fc.add(IfMissingOrNullDescriptor.FACTORY);
    // uuid generators (zero independent functions)
    fc.add(CreateUUIDDescriptor.FACTORY);
    fc.add(UUIDDescriptor.FACTORY);
    fc.add(CreateQueryUIDDescriptor.FACTORY);
    fc.add(CurrentDateDescriptor.FACTORY);
    fc.add(CurrentTimeDescriptor.FACTORY);
    fc.add(CurrentDateTimeDescriptor.FACTORY);
    // TODO: decide how should we deal these two weird functions as
    // the number of arguments of the function depend on the first few arguments.
    fc.add(SimilarityJaccardPrefixDescriptor.FACTORY);
    fc.add(SimilarityJaccardPrefixCheckDescriptor.FACTORY);
    // functions that need generated class for null-handling.
    // Element accessors.
    fc.addGenerated(FieldAccessByIndexDescriptor.FACTORY);
    fc.addGenerated(FieldAccessByNameDescriptor.FACTORY);
    fc.addGenerated(FieldAccessNestedDescriptor.FACTORY);
    fc.addGenerated(AnyCollectionMemberDescriptor.FACTORY);
    fc.addGenerated(GetItemDescriptor.FACTORY);
    // Numeric functions
    fc.addGenerated(NumericUnaryMinusDescriptor.FACTORY);
    fc.addGenerated(NumericAddDescriptor.FACTORY);
    fc.addGenerated(NumericDivideDescriptor.FACTORY);
    fc.addGenerated(NumericMultiplyDescriptor.FACTORY);
    fc.addGenerated(NumericSubDescriptor.FACTORY);
    fc.addGenerated(NumericModuloDescriptor.FACTORY);
    fc.addGenerated(NumericCaretDescriptor.FACTORY);
    fc.addGenerated(NotDescriptor.FACTORY);
    fc.addGenerated(LenDescriptor.FACTORY);
    fc.addGenerated(NumericAbsDescriptor.FACTORY);
    fc.addGenerated(NumericCeilingDescriptor.FACTORY);
    fc.addGenerated(NumericFloorDescriptor.FACTORY);
    fc.addGenerated(NumericRoundDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEvenDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEven2Descriptor.FACTORY);
    fc.addGenerated(NumericACosDescriptor.FACTORY);
    fc.addGenerated(NumericASinDescriptor.FACTORY);
    fc.addGenerated(NumericATanDescriptor.FACTORY);
    fc.addGenerated(NumericCosDescriptor.FACTORY);
    fc.addGenerated(NumericSinDescriptor.FACTORY);
    fc.addGenerated(NumericTanDescriptor.FACTORY);
    fc.addGenerated(NumericExpDescriptor.FACTORY);
    fc.addGenerated(NumericLnDescriptor.FACTORY);
    fc.addGenerated(NumericLogDescriptor.FACTORY);
    fc.addGenerated(NumericSqrtDescriptor.FACTORY);
    fc.addGenerated(NumericSignDescriptor.FACTORY);
    fc.addGenerated(NumericTruncDescriptor.FACTORY);
    fc.addGenerated(NumericATan2Descriptor.FACTORY);
    // Comparisons.
    fc.addGenerated(EqualsDescriptor.FACTORY);
    fc.addGenerated(GreaterThanDescriptor.FACTORY);
    fc.addGenerated(GreaterThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(LessThanDescriptor.FACTORY);
    fc.addGenerated(LessThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(NotEqualsDescriptor.FACTORY);
    // Binary functions
    fc.addGenerated(BinaryLengthDescriptor.FACTORY);
    fc.addGenerated(ParseBinaryDescriptor.FACTORY);
    fc.addGenerated(PrintBinaryDescriptor.FACTORY);
    fc.addGenerated(BinaryConcatDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromToDescriptor.FACTORY);
    fc.addGenerated(FindBinaryDescriptor.FACTORY);
    fc.addGenerated(FindBinaryFromDescriptor.FACTORY);
    // String functions
    fc.addGenerated(StringLikeDescriptor.FACTORY);
    fc.addGenerated(StringContainsDescriptor.FACTORY);
    fc.addGenerated(StringEndsWithDescriptor.FACTORY);
    fc.addGenerated(StringStartsWithDescriptor.FACTORY);
    fc.addGenerated(SubstringDescriptor.FACTORY);
    fc.addGenerated(StringEqualDescriptor.FACTORY);
    fc.addGenerated(StringLowerCaseDescriptor.FACTORY);
    fc.addGenerated(StringUpperCaseDescriptor.FACTORY);
    fc.addGenerated(StringLengthDescriptor.FACTORY);
    fc.addGenerated(Substring2Descriptor.FACTORY);
    fc.addGenerated(SubstringBeforeDescriptor.FACTORY);
    fc.addGenerated(SubstringAfterDescriptor.FACTORY);
    fc.addGenerated(StringToCodePointDescriptor.FACTORY);
    fc.addGenerated(CodePointToStringDescriptor.FACTORY);
    fc.addGenerated(StringConcatDescriptor.FACTORY);
    fc.addGenerated(StringJoinDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceWithFlagsDescriptor.FACTORY);
    fc.addGenerated(StringInitCapDescriptor.FACTORY);
    fc.addGenerated(StringTrimDescriptor.FACTORY);
    fc.addGenerated(StringLTrimDescriptor.FACTORY);
    fc.addGenerated(StringRTrimDescriptor.FACTORY);
    fc.addGenerated(StringTrim2Descriptor.FACTORY);
    fc.addGenerated(StringLTrim2Descriptor.FACTORY);
    fc.addGenerated(StringRTrim2Descriptor.FACTORY);
    fc.addGenerated(StringPositionDescriptor.FACTORY);
    fc.addGenerated(StringRepeatDescriptor.FACTORY);
    fc.addGenerated(StringSplitDescriptor.FACTORY);
    // Constructors
    fc.addGenerated(ABooleanConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryHexStringConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryBase64StringConstructorDescriptor.FACTORY);
    fc.addGenerated(AStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt8ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt16ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt32ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt64ConstructorDescriptor.FACTORY);
    fc.addGenerated(AFloatConstructorDescriptor.FACTORY);
    fc.addGenerated(ADoubleConstructorDescriptor.FACTORY);
    fc.addGenerated(APointConstructorDescriptor.FACTORY);
    fc.addGenerated(APoint3DConstructorDescriptor.FACTORY);
    fc.addGenerated(ALineConstructorDescriptor.FACTORY);
    fc.addGenerated(APolygonConstructorDescriptor.FACTORY);
    fc.addGenerated(ACircleConstructorDescriptor.FACTORY);
    fc.addGenerated(ARectangleConstructorDescriptor.FACTORY);
    fc.addGenerated(ATimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AYearMonthDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(ADayTimeDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AUUIDFromStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromTimeConstructorDescriptor.FACTORY);
    // Spatial
    fc.addGenerated(CreatePointDescriptor.FACTORY);
    fc.addGenerated(CreateLineDescriptor.FACTORY);
    fc.addGenerated(CreatePolygonDescriptor.FACTORY);
    fc.addGenerated(CreateCircleDescriptor.FACTORY);
    fc.addGenerated(CreateRectangleDescriptor.FACTORY);
    fc.addGenerated(SpatialAreaDescriptor.FACTORY);
    fc.addGenerated(SpatialDistanceDescriptor.FACTORY);
    fc.addGenerated(SpatialIntersectDescriptor.FACTORY);
    fc.addGenerated(CreateMBRDescriptor.FACTORY);
    fc.addGenerated(SpatialCellDescriptor.FACTORY);
    fc.addGenerated(PointXCoordinateAccessor.FACTORY);
    fc.addGenerated(PointYCoordinateAccessor.FACTORY);
    fc.addGenerated(CircleRadiusAccessor.FACTORY);
    fc.addGenerated(CircleCenterAccessor.FACTORY);
    fc.addGenerated(LineRectanglePolygonAccessor.FACTORY);
    // fuzzyjoin function
    fc.addGenerated(PrefixLenJaccardDescriptor.FACTORY);
    fc.addGenerated(WordTokensDescriptor.FACTORY);
    fc.addGenerated(HashedWordTokensDescriptor.FACTORY);
    fc.addGenerated(CountHashedWordTokensDescriptor.FACTORY);
    fc.addGenerated(GramTokensDescriptor.FACTORY);
    fc.addGenerated(HashedGramTokensDescriptor.FACTORY);
    fc.addGenerated(CountHashedGramTokensDescriptor.FACTORY);
    fc.addGenerated(EditDistanceDescriptor.FACTORY);
    fc.addGenerated(EditDistanceCheckDescriptor.FACTORY);
    fc.addGenerated(EditDistanceStringIsFilterableDescriptor.FACTORY);
    fc.addGenerated(EditDistanceListIsFilterableDescriptor.FACTORY);
    fc.addGenerated(EditDistanceContainsDescriptor.FACTORY);
    fc.addGenerated(SimilarityJaccardDescriptor.FACTORY);
    fc.addGenerated(SimilarityJaccardCheckDescriptor.FACTORY);
    fc.addGenerated(SimilarityJaccardSortedDescriptor.FACTORY);
    fc.addGenerated(SimilarityJaccardSortedCheckDescriptor.FACTORY);
    // full-text function
    fc.addGenerated(FullTextContainsDescriptor.FACTORY);
    fc.addGenerated(FullTextContainsWithoutOptionDescriptor.FACTORY);
    // Record functions.
    fc.addGenerated(GetRecordFieldsDescriptor.FACTORY);
    fc.addGenerated(GetRecordFieldValueDescriptor.FACTORY);
    fc.addGenerated(DeepEqualityDescriptor.FACTORY);
    fc.addGenerated(RecordMergeDescriptor.FACTORY);
    fc.addGenerated(RecordAddFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveFieldsDescriptor.FACTORY);
    // Spatial and temporal type accessors
    fc.addGenerated(TemporalYearAccessor.FACTORY);
    fc.addGenerated(TemporalMonthAccessor.FACTORY);
    fc.addGenerated(TemporalDayAccessor.FACTORY);
    fc.addGenerated(TemporalHourAccessor.FACTORY);
    fc.addGenerated(TemporalMinuteAccessor.FACTORY);
    fc.addGenerated(TemporalSecondAccessor.FACTORY);
    fc.addGenerated(TemporalMillisecondAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDatetimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDatetimeAccessor.FACTORY);
    // Temporal functions
    fc.addGenerated(UnixTimeFromDateInDaysDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromTimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DateFromUnixTimeInDaysDescriptor.FACTORY);
    fc.addGenerated(DateFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(TimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(TimeFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromDateAndTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDurationFromDateTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDuartionFromDateDescriptor.FACTORY);
    fc.addGenerated(AdjustDateTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(AdjustTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(IntervalBeforeDescriptor.FACTORY);
    fc.addGenerated(IntervalAfterDescriptor.FACTORY);
    fc.addGenerated(IntervalMeetsDescriptor.FACTORY);
    fc.addGenerated(IntervalMetByDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlapsDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlappedByDescriptor.FACTORY);
    fc.addGenerated(OverlapDescriptor.FACTORY);
    fc.addGenerated(IntervalStartsDescriptor.FACTORY);
    fc.addGenerated(IntervalStartedByDescriptor.FACTORY);
    fc.addGenerated(IntervalCoversDescriptor.FACTORY);
    fc.addGenerated(IntervalCoveredByDescriptor.FACTORY);
    fc.addGenerated(IntervalEndsDescriptor.FACTORY);
    fc.addGenerated(IntervalEndedByDescriptor.FACTORY);
    fc.addGenerated(DurationFromMillisecondsDescriptor.FACTORY);
    fc.addGenerated(DurationFromMonthsDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(MonthsFromYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(MillisecondsFromDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(DurationEqualDescriptor.FACTORY);
    fc.addGenerated(GetYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(GetDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(IntervalBinDescriptor.FACTORY);
    fc.addGenerated(OverlapBinsDescriptor.FACTORY);
    fc.addGenerated(DayOfWeekDescriptor.FACTORY);
    fc.addGenerated(ParseDateDescriptor.FACTORY);
    fc.addGenerated(ParseTimeDescriptor.FACTORY);
    fc.addGenerated(ParseDateTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateDescriptor.FACTORY);
    fc.addGenerated(PrintTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateTimeDescriptor.FACTORY);
    fc.addGenerated(GetOverlappingIntervalDescriptor.FACTORY);
    fc.addGenerated(DurationFromIntervalDescriptor.FACTORY);
    // Type functions.
    fc.addGenerated(IsBooleanDescriptor.FACTORY);
    fc.addGenerated(IsNumberDescriptor.FACTORY);
    fc.addGenerated(IsStringDescriptor.FACTORY);
    fc.addGenerated(IsArrayDescriptor.FACTORY);
    fc.addGenerated(IsObjectDescriptor.FACTORY);
    fc.addGenerated(ToBooleanDescriptor.FACTORY);
    fc.addGenerated(ToStringDescriptor.FACTORY);
    fc.addGenerated(ToDoubleDescriptor.FACTORY);
    fc.addGenerated(ToBigIntDescriptor.FACTORY);
    // Cast function
    fc.addGenerated(CastTypeDescriptor.FACTORY);
    fc.addGenerated(CastTypeLaxDescriptor.FACTORY);
    // Record function
    fc.addGenerated(RecordPairsDescriptor.FACTORY);
    return fc;
}
#method_after
public static FunctionCollection createDefaultFunctionCollection() {
    FunctionCollection fc = new FunctionCollection();
    // array functions
    fc.add(ArrayRemoveDescriptor.FACTORY);
    fc.add(ArrayPutDescriptor.FACTORY);
    fc.add(ArrayPrependDescriptor.FACTORY);
    fc.add(ArrayAppendDescriptor.FACTORY);
    fc.add(ArrayInsertDescriptor.FACTORY);
    fc.addGenerated(ArrayPositionDescriptor.FACTORY);
    fc.addGenerated(ArrayRepeatDescriptor.FACTORY);
    fc.addGenerated(ArrayContainsDescriptor.FACTORY);
    fc.addGenerated(ArrayReverseDescriptor.FACTORY);
    fc.addGenerated(ArraySortDescriptor.FACTORY);
    fc.addGenerated(ArrayDistinctDescriptor.FACTORY);
    fc.addGenerated(ArrayUnionDescriptor.FACTORY);
    fc.addGenerated(ArrayIntersectDescriptor.FACTORY);
    fc.addGenerated(ArrayIfNullDescriptor.FACTORY);
    fc.addGenerated(ArrayConcatDescriptor.FACTORY);
    fc.addGenerated(ArrayRangeDescriptor.FACTORY);
    fc.addGenerated(ArrayFlattenDescriptor.FACTORY);
    fc.add(ArrayReplaceDescriptor.FACTORY);
    fc.addGenerated(ArraySymDiffDescriptor.FACTORY);
    fc.addGenerated(ArraySymDiffnDescriptor.FACTORY);
    fc.addGenerated(ArrayStarDescriptor.FACTORY);
    // unnesting functions
    fc.add(TidRunningAggregateDescriptor.FACTORY);
    fc.add(ScanCollectionDescriptor.FACTORY);
    fc.add(RangeDescriptor.FACTORY);
    fc.add(SubsetCollectionDescriptor.FACTORY);
    // aggregate functions
    fc.add(ListifyAggregateDescriptor.FACTORY);
    fc.add(CountAggregateDescriptor.FACTORY);
    fc.add(AvgAggregateDescriptor.FACTORY);
    fc.add(LocalAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SumAggregateDescriptor.FACTORY);
    fc.add(LocalSumAggregateDescriptor.FACTORY);
    fc.add(MaxAggregateDescriptor.FACTORY);
    fc.add(LocalMaxAggregateDescriptor.FACTORY);
    fc.add(MinAggregateDescriptor.FACTORY);
    fc.add(LocalMinAggregateDescriptor.FACTORY);
    fc.add(FirstElementAggregateDescriptor.FACTORY);
    fc.add(LocalFirstElementAggregateDescriptor.FACTORY);
    fc.add(StddevAggregateDescriptor.FACTORY);
    fc.add(LocalStddevAggregateDescriptor.FACTORY);
    fc.add(IntermediateStddevAggregateDescriptor.FACTORY);
    fc.add(GlobalStddevAggregateDescriptor.FACTORY);
    fc.add(LocalSamplingAggregateDescriptor.FACTORY);
    fc.add(RangeMapAggregateDescriptor.FACTORY);
    // serializable aggregates
    fc.add(SerializableCountAggregateDescriptor.FACTORY);
    fc.add(SerializableAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSumAggregateDescriptor.FACTORY);
    fc.add(SerializableStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalStddevAggregateDescriptor.FACTORY);
    // scalar aggregates
    fc.add(ScalarCountAggregateDescriptor.FACTORY);
    fc.add(ScalarAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSumAggregateDescriptor.FACTORY);
    fc.add(ScalarMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarMinAggregateDescriptor.FACTORY);
    fc.add(EmptyStreamAggregateDescriptor.FACTORY);
    fc.add(NonEmptyStreamAggregateDescriptor.FACTORY);
    fc.add(ScalarStddevAggregateDescriptor.FACTORY);
    // SQL aggregates
    fc.add(SqlCountAggregateDescriptor.FACTORY);
    fc.add(SqlAvgAggregateDescriptor.FACTORY);
    fc.add(LocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SqlSumAggregateDescriptor.FACTORY);
    fc.add(LocalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SqlMaxAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMaxAggregateDescriptor.FACTORY);
    fc.add(SqlMinAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMinAggregateDescriptor.FACTORY);
    fc.add(SqlStddevAggregateDescriptor.FACTORY);
    fc.add(LocalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlStddevAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlStddevAggregateDescriptor.FACTORY);
    // SQL serializable aggregates
    fc.add(SerializableSqlCountAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlStddevAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlStddevAggregateDescriptor.FACTORY);
    // SQL scalar aggregates
    fc.add(ScalarSqlCountAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlSumAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMinAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlStddevAggregateDescriptor.FACTORY);
    // boolean functions
    fc.add(AndDescriptor.FACTORY);
    fc.add(OrDescriptor.FACTORY);
    // Record constructors / functions
    fc.add(ClosedRecordConstructorDescriptor.FACTORY);
    fc.add(OpenRecordConstructorDescriptor.FACTORY);
    fc.add(RecordConcatDescriptor.FACTORY);
    fc.add(RecordConcatStrictDescriptor.FACTORY);
    // List constructors
    fc.add(OrderedListConstructorDescriptor.FACTORY);
    fc.add(UnorderedListConstructorDescriptor.FACTORY);
    // Sleep function
    fc.add(SleepDescriptor.FACTORY);
    // Inject failure function
    fc.add(InjectFailureDescriptor.FACTORY);
    // Get Job Parameter function
    fc.add(GetJobParameterByNameDescriptor.FACTORY);
    // Switch case
    fc.add(SwitchCaseDescriptor.FACTORY);
    // null functions
    fc.add(IsMissingDescriptor.FACTORY);
    fc.add(IsNullDescriptor.FACTORY);
    fc.add(IsUnknownDescriptor.FACTORY);
    fc.add(IsSystemNullDescriptor.FACTORY);
    fc.add(CheckUnknownDescriptor.FACTORY);
    fc.add(IfMissingDescriptor.FACTORY);
    fc.add(IfNullDescriptor.FACTORY);
    fc.add(IfMissingOrNullDescriptor.FACTORY);
    // uuid generators (zero independent functions)
    fc.add(CreateUUIDDescriptor.FACTORY);
    fc.add(UUIDDescriptor.FACTORY);
    fc.add(CreateQueryUIDDescriptor.FACTORY);
    fc.add(RandomDescriptor.FACTORY);
    fc.add(CurrentDateDescriptor.FACTORY);
    fc.add(CurrentTimeDescriptor.FACTORY);
    fc.add(CurrentDateTimeDescriptor.FACTORY);
    // functions that need generated class for null-handling.
    // Element accessors.
    fc.addGenerated(FieldAccessByIndexDescriptor.FACTORY);
    fc.addGenerated(FieldAccessByNameDescriptor.FACTORY);
    fc.addGenerated(FieldAccessNestedDescriptor.FACTORY);
    fc.addGenerated(AnyCollectionMemberDescriptor.FACTORY);
    fc.addGenerated(GetItemDescriptor.FACTORY);
    // Numeric functions
    fc.add(IfInfDescriptor.FACTORY);
    fc.add(IfNanDescriptor.FACTORY);
    fc.add(IfNanOrInfDescriptor.FACTORY);
    fc.addGenerated(NumericUnaryMinusDescriptor.FACTORY);
    fc.addGenerated(NumericAddDescriptor.FACTORY);
    fc.addGenerated(NumericDivideDescriptor.FACTORY);
    fc.addGenerated(NumericDivDescriptor.FACTORY);
    fc.addGenerated(NumericMultiplyDescriptor.FACTORY);
    fc.addGenerated(NumericSubDescriptor.FACTORY);
    fc.addGenerated(NumericModuloDescriptor.FACTORY);
    fc.addGenerated(NumericPowerDescriptor.FACTORY);
    fc.addGenerated(NotDescriptor.FACTORY);
    fc.addGenerated(LenDescriptor.FACTORY);
    fc.addGenerated(NumericAbsDescriptor.FACTORY);
    fc.addGenerated(NumericCeilingDescriptor.FACTORY);
    fc.addGenerated(NumericFloorDescriptor.FACTORY);
    fc.addGenerated(NumericRoundDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEvenDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEven2Descriptor.FACTORY);
    fc.addGenerated(NumericACosDescriptor.FACTORY);
    fc.addGenerated(NumericASinDescriptor.FACTORY);
    fc.addGenerated(NumericATanDescriptor.FACTORY);
    fc.addGenerated(NumericDegreesDescriptor.FACTORY);
    fc.addGenerated(NumericRadiansDescriptor.FACTORY);
    fc.addGenerated(NumericCosDescriptor.FACTORY);
    fc.addGenerated(NumericSinDescriptor.FACTORY);
    fc.addGenerated(NumericTanDescriptor.FACTORY);
    fc.addGenerated(NumericExpDescriptor.FACTORY);
    fc.addGenerated(NumericLnDescriptor.FACTORY);
    fc.addGenerated(NumericLogDescriptor.FACTORY);
    fc.addGenerated(NumericSqrtDescriptor.FACTORY);
    fc.addGenerated(NumericSignDescriptor.FACTORY);
    fc.addGenerated(NumericTruncDescriptor.FACTORY);
    fc.addGenerated(NumericATan2Descriptor.FACTORY);
    // Comparisons.
    fc.addGenerated(EqualsDescriptor.FACTORY);
    fc.addGenerated(GreaterThanDescriptor.FACTORY);
    fc.addGenerated(GreaterThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(LessThanDescriptor.FACTORY);
    fc.addGenerated(LessThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(NotEqualsDescriptor.FACTORY);
    // If-Equals functions
    fc.addGenerated(MissingIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NullIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NanIfEqualsDescriptor.FACTORY);
    fc.addGenerated(PosInfIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NegInfIfEqualsDescriptor.FACTORY);
    // Binary functions
    fc.addGenerated(BinaryLengthDescriptor.FACTORY);
    fc.addGenerated(ParseBinaryDescriptor.FACTORY);
    fc.addGenerated(PrintBinaryDescriptor.FACTORY);
    fc.addGenerated(BinaryConcatDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromToDescriptor.FACTORY);
    fc.addGenerated(FindBinaryDescriptor.FACTORY);
    fc.addGenerated(FindBinaryFromDescriptor.FACTORY);
    // String functions
    fc.addGenerated(StringLikeDescriptor.FACTORY);
    fc.addGenerated(StringContainsDescriptor.FACTORY);
    fc.addGenerated(StringEndsWithDescriptor.FACTORY);
    fc.addGenerated(StringStartsWithDescriptor.FACTORY);
    fc.addGenerated(SubstringDescriptor.FACTORY);
    fc.addGenerated(StringEqualDescriptor.FACTORY);
    fc.addGenerated(StringLowerCaseDescriptor.FACTORY);
    fc.addGenerated(StringUpperCaseDescriptor.FACTORY);
    fc.addGenerated(StringLengthDescriptor.FACTORY);
    fc.addGenerated(Substring2Descriptor.FACTORY);
    fc.addGenerated(SubstringBeforeDescriptor.FACTORY);
    fc.addGenerated(SubstringAfterDescriptor.FACTORY);
    fc.addGenerated(StringToCodePointDescriptor.FACTORY);
    fc.addGenerated(CodePointToStringDescriptor.FACTORY);
    fc.addGenerated(StringConcatDescriptor.FACTORY);
    fc.addGenerated(StringJoinDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringInitCapDescriptor.FACTORY);
    fc.addGenerated(StringTrimDescriptor.FACTORY);
    fc.addGenerated(StringLTrimDescriptor.FACTORY);
    fc.addGenerated(StringRTrimDescriptor.FACTORY);
    fc.addGenerated(StringTrim2Descriptor.FACTORY);
    fc.addGenerated(StringLTrim2Descriptor.FACTORY);
    fc.addGenerated(StringRTrim2Descriptor.FACTORY);
    fc.addGenerated(StringPositionDescriptor.FACTORY);
    fc.addGenerated(StringRepeatDescriptor.FACTORY);
    fc.addGenerated(StringReplaceDescriptor.FACTORY);
    fc.addGenerated(StringReplaceWithLimitDescriptor.FACTORY);
    fc.addGenerated(StringReverseDescriptor.FACTORY);
    fc.addGenerated(StringSplitDescriptor.FACTORY);
    // Constructors
    fc.addGenerated(ABooleanConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryHexStringConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryBase64StringConstructorDescriptor.FACTORY);
    fc.addGenerated(AStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt8ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt16ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt32ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt64ConstructorDescriptor.FACTORY);
    fc.addGenerated(AFloatConstructorDescriptor.FACTORY);
    fc.addGenerated(ADoubleConstructorDescriptor.FACTORY);
    fc.addGenerated(APointConstructorDescriptor.FACTORY);
    fc.addGenerated(APoint3DConstructorDescriptor.FACTORY);
    fc.addGenerated(ALineConstructorDescriptor.FACTORY);
    fc.addGenerated(APolygonConstructorDescriptor.FACTORY);
    fc.addGenerated(ACircleConstructorDescriptor.FACTORY);
    fc.addGenerated(ARectangleConstructorDescriptor.FACTORY);
    fc.addGenerated(ATimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AYearMonthDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(ADayTimeDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AUUIDFromStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromTimeConstructorDescriptor.FACTORY);
    // Spatial
    fc.addGenerated(CreatePointDescriptor.FACTORY);
    fc.addGenerated(CreateLineDescriptor.FACTORY);
    fc.addGenerated(CreatePolygonDescriptor.FACTORY);
    fc.addGenerated(CreateCircleDescriptor.FACTORY);
    fc.addGenerated(CreateRectangleDescriptor.FACTORY);
    fc.addGenerated(SpatialAreaDescriptor.FACTORY);
    fc.addGenerated(SpatialDistanceDescriptor.FACTORY);
    fc.addGenerated(CreateMBRDescriptor.FACTORY);
    fc.addGenerated(SpatialCellDescriptor.FACTORY);
    fc.addGenerated(PointXCoordinateAccessor.FACTORY);
    fc.addGenerated(PointYCoordinateAccessor.FACTORY);
    fc.addGenerated(CircleRadiusAccessor.FACTORY);
    fc.addGenerated(CircleCenterAccessor.FACTORY);
    fc.addGenerated(LineRectanglePolygonAccessor.FACTORY);
    // full-text function
    fc.addGenerated(FullTextContainsDescriptor.FACTORY);
    fc.addGenerated(FullTextContainsWithoutOptionDescriptor.FACTORY);
    // Record functions.
    fc.addGenerated(GetRecordFieldsDescriptor.FACTORY);
    fc.addGenerated(GetRecordFieldValueDescriptor.FACTORY);
    fc.addGenerated(DeepEqualityDescriptor.FACTORY);
    fc.addGenerated(RecordMergeDescriptor.FACTORY);
    fc.addGenerated(RecordAddFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordLengthDescriptor.FACTORY);
    fc.addGenerated(RecordNamesDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveDescriptor.FACTORY);
    fc.addGenerated(RecordRenameDescriptor.FACTORY);
    fc.addGenerated(RecordUnwrapDescriptor.FACTORY);
    fc.add(RecordReplaceDescriptor.FACTORY);
    fc.add(RecordAddDescriptor.FACTORY);
    fc.add(RecordPutDescriptor.FACTORY);
    fc.addGenerated(RecordValuesDescriptor.FACTORY);
    fc.addGenerated(PairsDescriptor.FACTORY);
    // Spatial and temporal type accessors
    fc.addGenerated(TemporalYearAccessor.FACTORY);
    fc.addGenerated(TemporalMonthAccessor.FACTORY);
    fc.addGenerated(TemporalDayAccessor.FACTORY);
    fc.addGenerated(TemporalHourAccessor.FACTORY);
    fc.addGenerated(TemporalMinuteAccessor.FACTORY);
    fc.addGenerated(TemporalSecondAccessor.FACTORY);
    fc.addGenerated(TemporalMillisecondAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDatetimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDatetimeAccessor.FACTORY);
    // Temporal functions
    fc.addGenerated(UnixTimeFromDateInDaysDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromTimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DateFromUnixTimeInDaysDescriptor.FACTORY);
    fc.addGenerated(DateFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(TimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(TimeFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromDateAndTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDurationFromDateTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDuartionFromDateDescriptor.FACTORY);
    fc.addGenerated(AdjustDateTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(AdjustTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(IntervalBeforeDescriptor.FACTORY);
    fc.addGenerated(IntervalAfterDescriptor.FACTORY);
    fc.addGenerated(IntervalMeetsDescriptor.FACTORY);
    fc.addGenerated(IntervalMetByDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlapsDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlappedByDescriptor.FACTORY);
    fc.addGenerated(OverlapDescriptor.FACTORY);
    fc.addGenerated(IntervalStartsDescriptor.FACTORY);
    fc.addGenerated(IntervalStartedByDescriptor.FACTORY);
    fc.addGenerated(IntervalCoversDescriptor.FACTORY);
    fc.addGenerated(IntervalCoveredByDescriptor.FACTORY);
    fc.addGenerated(IntervalEndsDescriptor.FACTORY);
    fc.addGenerated(IntervalEndedByDescriptor.FACTORY);
    fc.addGenerated(DurationFromMillisecondsDescriptor.FACTORY);
    fc.addGenerated(DurationFromMonthsDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(MonthsFromYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(MillisecondsFromDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(DurationEqualDescriptor.FACTORY);
    fc.addGenerated(GetYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(GetDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(IntervalBinDescriptor.FACTORY);
    fc.addGenerated(OverlapBinsDescriptor.FACTORY);
    fc.addGenerated(DayOfWeekDescriptor.FACTORY);
    fc.addGenerated(ParseDateDescriptor.FACTORY);
    fc.addGenerated(ParseTimeDescriptor.FACTORY);
    fc.addGenerated(ParseDateTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateDescriptor.FACTORY);
    fc.addGenerated(PrintTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateTimeDescriptor.FACTORY);
    fc.addGenerated(GetOverlappingIntervalDescriptor.FACTORY);
    fc.addGenerated(DurationFromIntervalDescriptor.FACTORY);
    // Type functions.
    fc.addGenerated(IsArrayDescriptor.FACTORY);
    fc.addGenerated(IsAtomicDescriptor.FACTORY);
    fc.addGenerated(IsBooleanDescriptor.FACTORY);
    fc.addGenerated(IsNumberDescriptor.FACTORY);
    fc.addGenerated(IsObjectDescriptor.FACTORY);
    fc.addGenerated(IsStringDescriptor.FACTORY);
    fc.addGenerated(ToArrayDescriptor.FACTORY);
    fc.addGenerated(ToAtomicDescriptor.FACTORY);
    fc.addGenerated(ToBigIntDescriptor.FACTORY);
    fc.addGenerated(ToBooleanDescriptor.FACTORY);
    fc.addGenerated(ToDoubleDescriptor.FACTORY);
    fc.addGenerated(ToNumberDescriptor.FACTORY);
    fc.addGenerated(ToObjectDescriptor.FACTORY);
    fc.addGenerated(ToStringDescriptor.FACTORY);
    fc.addGenerated(TreatAsIntegerDescriptor.FACTORY);
    // Cast function
    fc.addGenerated(CastTypeDescriptor.FACTORY);
    fc.addGenerated(CastTypeLaxDescriptor.FACTORY);
    // Record function
    fc.addGenerated(RecordPairsDescriptor.FACTORY);
    // Other functions
    fc.addGenerated(RandomWithSeedDescriptor.FACTORY);
    ServiceLoader.load(IFunctionRegistrant.class).iterator().forEachRemaining(c -> c.register(fc));
    return fc;
}
#end_block

#method_before
@Override
public Void visitDataScanOperator(DataSourceScanOperator op, Void arg) {
    if (op.getAdditionalFilteringExpressions() != null) {
        for (Mutable<ILogicalExpression> e : op.getAdditionalFilteringExpressions()) {
            e.getValue().getUsedVariables(usedVariables);
        }
    }
    return null;
}
#method_after
@Override
public Void visitDataScanOperator(DataSourceScanOperator op, Void arg) {
    if (op.getAdditionalFilteringExpressions() != null) {
        for (Mutable<ILogicalExpression> e : op.getAdditionalFilteringExpressions()) {
            e.getValue().getUsedVariables(usedVariables);
        }
    }
    if (op.getSelectCondition() != null) {
        Set<LogicalVariable> usedVariablesBySelect = new HashSet<>();
        op.getSelectCondition().getValue().getUsedVariables(usedVariablesBySelect);
        usedVariablesBySelect.removeAll(op.getVariables());
        usedVariables.addAll(usedVariablesBySelect);
    }
    return null;
}
#end_block

#method_before
@Override
public Void visitExchangeOperator(ExchangeOperator op, Void arg) throws AlgebricksException {
    // Used variables depend on the physical operator.
    if (op.getPhysicalOperator() != null) {
        IPhysicalOperator physOp = op.getPhysicalOperator();
        switch(physOp.getOperatorTag()) {
            case BROADCAST_EXCHANGE:
            case ONE_TO_ONE_EXCHANGE:
            case RANDOM_MERGE_EXCHANGE:
                {
                    // No variables used.
                    break;
                }
            case HASH_PARTITION_EXCHANGE:
                {
                    HashPartitionExchangePOperator concreteOp = (HashPartitionExchangePOperator) physOp;
                    usedVariables.addAll(concreteOp.getHashFields());
                    break;
                }
            case HASH_PARTITION_MERGE_EXCHANGE:
                {
                    HashPartitionMergeExchangePOperator concreteOp = (HashPartitionMergeExchangePOperator) physOp;
                    usedVariables.addAll(concreteOp.getPartitionFields());
                    for (OrderColumn orderCol : concreteOp.getOrderColumns()) {
                        usedVariables.add(orderCol.getColumn());
                    }
                    break;
                }
            case SORT_MERGE_EXCHANGE:
                {
                    SortMergeExchangePOperator concreteOp = (SortMergeExchangePOperator) physOp;
                    for (OrderColumn orderCol : concreteOp.getSortColumns()) {
                        usedVariables.add(orderCol.getColumn());
                    }
                    break;
                }
            case RANGE_PARTITION_EXCHANGE:
                {
                    RangePartitionExchangePOperator concreteOp = (RangePartitionExchangePOperator) physOp;
                    for (OrderColumn partCol : concreteOp.getPartitioningFields()) {
                        usedVariables.add(partCol.getColumn());
                    }
                    break;
                }
            case RANGE_PARTITION_MERGE_EXCHANGE:
                {
                    RangePartitionMergeExchangePOperator concreteOp = (RangePartitionMergeExchangePOperator) physOp;
                    for (OrderColumn partCol : concreteOp.getPartitioningFields()) {
                        usedVariables.add(partCol.getColumn());
                    }
                    break;
                }
            case RANDOM_PARTITION_EXCHANGE:
                {
                    break;
                }
            default:
                {
                    throw new AlgebricksException("Unhandled physical operator tag '" + physOp.getOperatorTag() + "'.");
                }
        }
    }
    return null;
}
#method_after
@Override
public Void visitExchangeOperator(ExchangeOperator op, Void arg) throws AlgebricksException {
    // Used variables depend on the physical operator.
    if (op.getPhysicalOperator() != null) {
        IPhysicalOperator physOp = op.getPhysicalOperator();
        switch(physOp.getOperatorTag()) {
            case BROADCAST_EXCHANGE:
            case ONE_TO_ONE_EXCHANGE:
            case RANDOM_MERGE_EXCHANGE:
            case SEQUENTIAL_MERGE_EXCHANGE:
                // No variables used.
                break;
            case HASH_PARTITION_EXCHANGE:
                HashPartitionExchangePOperator hashPartitionPOp = (HashPartitionExchangePOperator) physOp;
                usedVariables.addAll(hashPartitionPOp.getHashFields());
                break;
            case HASH_PARTITION_MERGE_EXCHANGE:
                HashPartitionMergeExchangePOperator hashMergePOp = (HashPartitionMergeExchangePOperator) physOp;
                usedVariables.addAll(hashMergePOp.getPartitionFields());
                for (OrderColumn orderCol : hashMergePOp.getOrderColumns()) {
                    usedVariables.add(orderCol.getColumn());
                }
                break;
            case SORT_MERGE_EXCHANGE:
                SortMergeExchangePOperator sortMergePOp = (SortMergeExchangePOperator) physOp;
                for (OrderColumn orderCol : sortMergePOp.getSortColumns()) {
                    usedVariables.add(orderCol.getColumn());
                }
                break;
            case RANGE_PARTITION_EXCHANGE:
                RangePartitionExchangePOperator rangePartitionPOp = (RangePartitionExchangePOperator) physOp;
                for (OrderColumn partCol : rangePartitionPOp.getPartitioningFields()) {
                    usedVariables.add(partCol.getColumn());
                }
                break;
            case RANGE_PARTITION_MERGE_EXCHANGE:
                RangePartitionMergeExchangePOperator rangeMergePOp = (RangePartitionMergeExchangePOperator) physOp;
                for (OrderColumn partCol : rangeMergePOp.getPartitioningFields()) {
                    usedVariables.add(partCol.getColumn());
                }
                break;
            case RANDOM_PARTITION_EXCHANGE:
                break;
            default:
                throw new AlgebricksException("Unhandled physical operator tag '" + physOp.getOperatorTag() + "'.");
        }
    }
    return null;
}
#end_block

#method_before
@Override
public Void visitUnnestMapOperator(UnnestMapOperator op, Void arg) {
    getUsedVarsFromExprAndFilterExpr(op);
    return null;
}
#method_after
@Override
public Void visitUnnestMapOperator(UnnestMapOperator op, Void arg) {
    getUsedVarsFromExprAndFilterExpr(op);
    if (op.getSelectCondition() != null) {
        Set<LogicalVariable> usedVariablesBySelect = new HashSet<>();
        op.getSelectCondition().getValue().getUsedVariables(usedVariablesBySelect);
        usedVariablesBySelect.removeAll(op.getVariables());
        usedVariables.addAll(usedVariablesBySelect);
    }
    return null;
}
#end_block

#method_before
@Override
public Void visitIndexInsertDeleteUpsertOperator(IndexInsertDeleteUpsertOperator op, Void arg) {
    for (Mutable<ILogicalExpression> e : op.getPrimaryKeyExpressions()) {
        e.getValue().getUsedVariables(usedVariables);
    }
    for (Mutable<ILogicalExpression> e : op.getSecondaryKeyExpressions()) {
        e.getValue().getUsedVariables(usedVariables);
    }
    if (op.getFilterExpression() != null) {
        op.getFilterExpression().getValue().getUsedVariables(usedVariables);
    }
    if (op.getAdditionalFilteringExpressions() != null) {
        for (Mutable<ILogicalExpression> e : op.getAdditionalFilteringExpressions()) {
            e.getValue().getUsedVariables(usedVariables);
        }
    }
    if (op.getPrevAdditionalFilteringExpression() != null) {
        op.getPrevAdditionalFilteringExpression().getValue().getUsedVariables(usedVariables);
    }
    if (op.getPrevSecondaryKeyExprs() != null) {
        for (Mutable<ILogicalExpression> e : op.getPrevSecondaryKeyExprs()) {
            e.getValue().getUsedVariables(usedVariables);
        }
    }
    return null;
}
#method_after
@Override
public Void visitIndexInsertDeleteUpsertOperator(IndexInsertDeleteUpsertOperator op, Void arg) {
    for (Mutable<ILogicalExpression> e : op.getPrimaryKeyExpressions()) {
        e.getValue().getUsedVariables(usedVariables);
    }
    for (Mutable<ILogicalExpression> e : op.getSecondaryKeyExpressions()) {
        e.getValue().getUsedVariables(usedVariables);
    }
    if (op.getFilterExpression() != null) {
        op.getFilterExpression().getValue().getUsedVariables(usedVariables);
    }
    if (op.getAdditionalFilteringExpressions() != null) {
        for (Mutable<ILogicalExpression> e : op.getAdditionalFilteringExpressions()) {
            e.getValue().getUsedVariables(usedVariables);
        }
    }
    if (op.getPrevAdditionalFilteringExpression() != null) {
        op.getPrevAdditionalFilteringExpression().getValue().getUsedVariables(usedVariables);
    }
    if (op.getPrevSecondaryKeyExprs() != null) {
        for (Mutable<ILogicalExpression> e : op.getPrevSecondaryKeyExprs()) {
            e.getValue().getUsedVariables(usedVariables);
        }
    }
    if (op.getUpsertIndicatorExpr() != null) {
        op.getUpsertIndicatorExpr().getValue().getUsedVariables(usedVariables);
    }
    return null;
}
#end_block

#method_before
@Override
public Void visitForwardOperator(ForwardOperator op, Void arg) throws AlgebricksException {
    return null;
}
#method_after
@Override
public Void visitForwardOperator(ForwardOperator op, Void arg) throws AlgebricksException {
    op.getRangeMapExpression().getValue().getUsedVariables(usedVariables);
    return null;
}
#end_block

#method_before
public static String generate(final JobSpecification jobSpecification) {
    final DotFormatBuilder graphBuilder = new DotFormatBuilder(DotFormatBuilder.StringValue.of("JobSpecification"));
    final Map<ConnectorDescriptorId, IConnectorDescriptor> connectorMap = jobSpecification.getConnectorMap();
    final Set<Constraint> constraints = jobSpecification.getUserConstraints();
    Map<ConnectorDescriptorId, Pair<Pair<IOperatorDescriptor, Integer>, Pair<IOperatorDescriptor, Integer>>> cOp = jobSpecification.getConnectorOperatorMap();
    cOp.forEach((connectorId, sourceAndDestination) -> {
        IConnectorDescriptor connector = connectorMap.get(connectorId);
        String edgeLabel;
        edgeLabel = connector.getClass().getName().substring(connector.getClass().getName().lastIndexOf(".") + 1);
        edgeLabel += "-" + connectorId;
        IOperatorDescriptor sourceOp = sourceAndDestination.getLeft().getLeft();
        IOperatorDescriptor destinationOp = sourceAndDestination.getRight().getLeft();
        String source = sourceOp.getClass().getName().substring(sourceOp.getClass().getName().lastIndexOf(".") + 1);
        String destination = destinationOp.getClass().getName().substring(destinationOp.getClass().getName().lastIndexOf(".") + 1);
        // constraints
        for (Constraint constraint : constraints) {
            LValueConstraintExpression lvalue = constraint.getLValue();
            if (lvalue.getTag() == ConstraintExpression.ExpressionTag.PARTITION_COUNT) {
                PartitionCountExpression count = (PartitionCountExpression) lvalue;
                if (count.getOperatorDescriptorId().equals(sourceOp.getOperatorId())) {
                    source += "\n" + constraint;
                }
                if (count.getOperatorDescriptorId().equals(destinationOp.getOperatorId())) {
                    destination += "\n" + constraint;
                }
            } else if (lvalue.getTag() == ConstraintExpression.ExpressionTag.PARTITION_LOCATION) {
                PartitionLocationExpression location = (PartitionLocationExpression) lvalue;
                if (location.getOperatorDescriptorId().equals(sourceOp.getOperatorId())) {
                    source += "\n" + constraint;
                }
                if (location.getOperatorDescriptorId().equals(destinationOp.getOperatorId())) {
                    destination += "\n" + constraint;
                }
            }
        }
        DotFormatBuilder.Node sourceNode = graphBuilder.createNode(DotFormatBuilder.StringValue.of(sourceOp.getOperatorId().toString()), DotFormatBuilder.StringValue.of(sourceOp.toString() + "-" + source));
        DotFormatBuilder.Node destinationNode = graphBuilder.createNode(DotFormatBuilder.StringValue.of(destinationOp.getOperatorId().toString()), DotFormatBuilder.StringValue.of(destinationOp.toString() + "-" + destination));
        graphBuilder.createEdge(sourceNode, destinationNode).setLabel(DotFormatBuilder.StringValue.of(edgeLabel));
    });
    return graphBuilder.getDotDocument();
}
#method_after
public static String generate(final JobSpecification jobSpecification) {
    final DotFormatBuilder graphBuilder = new DotFormatBuilder(DotFormatBuilder.StringValue.of("JobSpecification"));
    final Map<ConnectorDescriptorId, IConnectorDescriptor> connectorMap = jobSpecification.getConnectorMap();
    final Set<Constraint> constraints = jobSpecification.getUserConstraints();
    Map<ConnectorDescriptorId, Pair<Pair<IOperatorDescriptor, Integer>, Pair<IOperatorDescriptor, Integer>>> cOp = jobSpecification.getConnectorOperatorMap();
    cOp.forEach((connId, srcAndDest) -> addToGraph(graphBuilder, constraints, connectorMap, connId, srcAndDest));
    return graphBuilder.getDotDocument();
}
#end_block

#method_before
public static String generate(ILogicalOperator startingOp) throws AlgebricksException {
    final DotFormatBuilder graphBuilder = new DotFormatBuilder(DotFormatBuilder.StringValue.of("Plan"));
    generateNode(graphBuilder, startingOp, dotVisitor, new HashSet<>());
    return graphBuilder.getDotDocument();
}
#method_after
public String generate(ILogicalPlan plan, boolean showDetails) throws AlgebricksException {
    ILogicalOperator root = plan.getRoots().get(0).getValue();
    return generate(root, showDetails);
}
#end_block

#method_before
private static void generateNode(DotFormatBuilder dotBuilder, ILogicalOperator op, LogicalOperatorDotVisitor dotVisitor, Set<ILogicalOperator> operatorsVisited) throws AlgebricksException {
    DotFormatBuilder.StringValue destinationNodeLabel = formatStringOf(op, dotVisitor);
    DotFormatBuilder.Node destinationNode = dotBuilder.createNode(DotFormatBuilder.StringValue.of(Integer.toString(op.hashCode())), destinationNodeLabel);
    DotFormatBuilder.StringValue sourceNodeLabel;
    DotFormatBuilder.Node sourceNode;
    for (Mutable<ILogicalOperator> child : op.getInputs()) {
        sourceNodeLabel = formatStringOf(child.getValue(), dotVisitor);
        sourceNode = dotBuilder.createNode(DotFormatBuilder.StringValue.of(Integer.toString(child.getValue().hashCode())), sourceNodeLabel);
        dotBuilder.createEdge(sourceNode, destinationNode);
        if (!operatorsVisited.contains(child.getValue())) {
            generateNode(dotBuilder, child.getValue(), dotVisitor, operatorsVisited);
        }
    }
    if (((AbstractLogicalOperator) op).hasNestedPlans()) {
        ILogicalOperator nestedOperator;
        for (ILogicalPlan nestedPlan : ((AbstractOperatorWithNestedPlans) op).getNestedPlans()) {
            nestedOperator = nestedPlan.getRoots().get(0).getValue();
            sourceNodeLabel = formatStringOf(nestedOperator, dotVisitor);
            sourceNode = dotBuilder.createNode(DotFormatBuilder.StringValue.of(Integer.toString(nestedOperator.hashCode())), sourceNodeLabel);
            dotBuilder.createEdge(sourceNode, destinationNode).setLabel(DotFormatBuilder.StringValue.of("subplan"));
            if (!operatorsVisited.contains(nestedOperator)) {
                generateNode(dotBuilder, nestedOperator, dotVisitor, operatorsVisited);
            }
        }
    }
    if (!(op instanceof ExchangeOperator)) {
        destinationNode.setFillColor(DotFormatBuilder.Color.SKYBLUE);
    }
    // replicate/split operator
    if (op.getOperatorTag() == LogicalOperatorTag.REPLICATE || op.getOperatorTag() == LogicalOperatorTag.SPLIT) {
        AbstractReplicateOperator replicateOperator = (AbstractReplicateOperator) op;
        ILogicalOperator replicateOutput;
        sourceNode = destinationNode;
        for (int i = 0; i < replicateOperator.getOutputs().size(); i++) {
            replicateOutput = replicateOperator.getOutputs().get(i).getValue();
            destinationNodeLabel = formatStringOf(replicateOutput, dotVisitor);
            destinationNode = dotBuilder.createNode(DotFormatBuilder.StringValue.of(Integer.toString(replicateOutput.hashCode())), destinationNodeLabel);
            if (replicateOperator.getOutputMaterializationFlags()[i]) {
                dotBuilder.createEdge(sourceNode, destinationNode).setColor(DotFormatBuilder.Color.RED);
            } else {
                dotBuilder.createEdge(sourceNode, destinationNode);
            }
        }
    }
    operatorsVisited.add(op);
}
#method_after
private void generateNode(DotFormatBuilder dotBuilder, ILogicalOperator op, boolean showDetails, Set<ILogicalOperator> operatorsVisited) throws AlgebricksException {
    DotFormatBuilder.StringValue destinationNodeLabel = formatStringOf(op, showDetails);
    DotFormatBuilder.Node destinationNode = dotBuilder.createNode(DotFormatBuilder.StringValue.of(Integer.toString(op.hashCode())), destinationNodeLabel);
    DotFormatBuilder.StringValue sourceNodeLabel;
    DotFormatBuilder.Node sourceNode;
    for (Mutable<ILogicalOperator> child : op.getInputs()) {
        sourceNodeLabel = formatStringOf(child.getValue(), showDetails);
        sourceNode = dotBuilder.createNode(DotFormatBuilder.StringValue.of(Integer.toString(child.getValue().hashCode())), sourceNodeLabel);
        dotBuilder.createEdge(sourceNode, destinationNode);
        if (!operatorsVisited.contains(child.getValue())) {
            generateNode(dotBuilder, child.getValue(), showDetails, operatorsVisited);
        }
    }
    if (((AbstractLogicalOperator) op).hasNestedPlans()) {
        ILogicalOperator nestedOperator;
        for (ILogicalPlan nestedPlan : ((AbstractOperatorWithNestedPlans) op).getNestedPlans()) {
            nestedOperator = nestedPlan.getRoots().get(0).getValue();
            sourceNodeLabel = formatStringOf(nestedOperator, showDetails);
            sourceNode = dotBuilder.createNode(DotFormatBuilder.StringValue.of(Integer.toString(nestedOperator.hashCode())), sourceNodeLabel);
            dotBuilder.createEdge(sourceNode, destinationNode).setLabel(DotFormatBuilder.StringValue.of("subplan"));
            if (!operatorsVisited.contains(nestedOperator)) {
                generateNode(dotBuilder, nestedOperator, showDetails, operatorsVisited);
            }
        }
    }
    if (!(op instanceof ExchangeOperator)) {
        destinationNode.setFillColor(DotFormatBuilder.Color.SKYBLUE);
    }
    // replicate/split operator
    if (op.getOperatorTag() == LogicalOperatorTag.REPLICATE || op.getOperatorTag() == LogicalOperatorTag.SPLIT) {
        AbstractReplicateOperator replicateOperator = (AbstractReplicateOperator) op;
        ILogicalOperator replicateOutput;
        sourceNode = destinationNode;
        for (int i = 0; i < replicateOperator.getOutputs().size(); i++) {
            replicateOutput = replicateOperator.getOutputs().get(i).getValue();
            destinationNodeLabel = formatStringOf(replicateOutput, showDetails);
            destinationNode = dotBuilder.createNode(DotFormatBuilder.StringValue.of(Integer.toString(replicateOutput.hashCode())), destinationNodeLabel);
            if (replicateOperator.getOutputMaterializationFlags()[i]) {
                dotBuilder.createEdge(sourceNode, destinationNode).setColor(DotFormatBuilder.Color.RED);
            } else {
                dotBuilder.createEdge(sourceNode, destinationNode);
            }
        }
    }
    operatorsVisited.add(op);
}
#end_block

#method_before
private static DotFormatBuilder.StringValue formatStringOf(ILogicalOperator operator, LogicalOperatorDotVisitor dotVisitor) throws AlgebricksException {
    String formattedString = operator.accept(dotVisitor, null).trim();
    return DotFormatBuilder.StringValue.of(formattedString);
}
#method_after
private DotFormatBuilder.StringValue formatStringOf(ILogicalOperator operator, boolean showDetails) throws AlgebricksException {
    String formattedString = operator.accept(dotVisitor, showDetails).trim();
    return DotFormatBuilder.StringValue.of(formattedString);
}
#end_block

#method_before
@Override
public void recomputeSchema() throws AlgebricksException {
    setSchema(inputs.get(0).getValue().getSchema());
// TODO(ali): ignore input at index 1?
}
#method_after
@Override
public void recomputeSchema() throws AlgebricksException {
    // schema is equal to the schema of the data source at idx 0
    setSchema(inputs.get(0).getValue().getSchema());
}
#end_block

#method_before
@Override
public boolean acceptExpressionTransform(ILogicalExpressionReferenceTransform transform) throws AlgebricksException {
    // forward operator does not have any expressions to transform
    return false;
}
#method_after
@Override
public boolean acceptExpressionTransform(ILogicalExpressionReferenceTransform visitor) throws AlgebricksException {
    return visitor.transform(rangeMapExpression);
}
#end_block

#method_before
@Override
public <R, T> R accept(ILogicalOperatorVisitor<R, T> visitor, T arg) throws AlgebricksException {
    // TODO(ali): complete this
    return visitor.visitForwardOperator(this, arg);
}
#method_after
@Override
public <R, T> R accept(ILogicalOperatorVisitor<R, T> visitor, T arg) throws AlgebricksException {
    return visitor.visitForwardOperator(this, arg);
}
#end_block

#method_before
@Override
public boolean isMap() {
    return true;
}
#method_after
@Override
public boolean isMap() {
    return false;
}
#end_block

#method_before
@Override
public VariablePropagationPolicy getVariablePropagationPolicy() {
    return new VariablePropagationPolicy() {

        @Override
        public void propagateVariables(IOperatorSchema target, IOperatorSchema... sources) throws AlgebricksException {
            if (sources.length > 0) {
                target.addAllVariables(sources[0]);
            }
        }
    };
}
#method_after
@Override
public VariablePropagationPolicy getVariablePropagationPolicy() {
    return new VariablePropagationPolicy() {

        @Override
        public void propagateVariables(IOperatorSchema target, IOperatorSchema... sources) throws AlgebricksException {
            // propagate the variables of the data source at idx 0
            if (sources.length > 0) {
                target.addAllVariables(sources[0]);
            }
        }
    };
}
#end_block

#method_before
@Override
public IVariableTypeEnvironment computeOutputTypeEnvironment(ITypingContext ctx) throws AlgebricksException {
    ITypeEnvPointer[] envPointers = new ITypeEnvPointer[] { new OpRefTypeEnvPointer(inputs.get(0), ctx) };
    return new PropagatingTypeEnvironment(ctx.getExpressionTypeComputer(), ctx.getMissableTypeComputer(), ctx.getMetadataProvider(), TypePropagationPolicy.ALL, envPointers);
}
#method_after
@Override
public IVariableTypeEnvironment computeOutputTypeEnvironment(ITypingContext ctx) throws AlgebricksException {
    // propagate the type environment of the data source at idx 0
    ITypeEnvPointer[] envPointers = new ITypeEnvPointer[] { new OpRefTypeEnvPointer(inputs.get(0), ctx) };
    return new PropagatingTypeEnvironment(ctx.getExpressionTypeComputer(), ctx.getMissableTypeComputer(), ctx.getMetadataProvider(), TypePropagationPolicy.ALL, envPointers);
}
#end_block

#method_before
@Override
public ITuplePartitionComputer createPartitioner(IHyracksTaskContext hyracksTaskContext) {
    final IBinaryComparator[] comparators = new IBinaryComparator[comparatorFactories.length];
    for (int i = 0; i < comparatorFactories.length; ++i) {
        comparators[i] = comparatorFactories[i].createBinaryComparator();
    }
    return new ITuplePartitionComputer() {

        @Override
        public void initialize() throws HyracksDataException {
            if (rangeMapIsComputedAtRunTime) {
                // get the range map from the context
                rangeMap = TaskUtil.get(rangeMapKeyInContext, hyracksTaskContext);
                if (rangeMap == null) {
                    throw new HyracksDataException("Range map was not found");
                }
            }
        }

        /**
         * Determine the range partition.
         */
        @Override
        public int partition(IFrameTupleAccessor accessor, int tIndex, int nParts) throws HyracksDataException {
            if (nParts == 1) {
                return 0;
            }
            int slotIndex = getRangePartition(accessor, tIndex);
            // Map range partition to node partitions.
            double rangesPerPart = 1;
            if (rangeMap.getSplitCount() + 1 > nParts) {
                rangesPerPart = ((double) rangeMap.getSplitCount() + 1) / nParts;
            }
            return (int) Math.floor(slotIndex / rangesPerPart);
        }

        /*
             * Determine the range partition.
             */
        public int getRangePartition(IFrameTupleAccessor accessor, int tIndex) throws HyracksDataException {
            int slotIndex = 0;
            for (int i = 0; i < rangeMap.getSplitCount(); ++i) {
                int c = compareSlotAndFields(accessor, tIndex, i);
                if (c < 0) {
                    return slotIndex;
                }
                slotIndex++;
            }
            return slotIndex;
        }

        public int compareSlotAndFields(IFrameTupleAccessor accessor, int tIndex, int fieldIndex) throws HyracksDataException {
            int c = 0;
            int startOffset = accessor.getTupleStartOffset(tIndex);
            int slotLength = accessor.getFieldSlotsLength();
            for (int f = 0; f < comparators.length; ++f) {
                int fIdx = rangeFields[f];
                int fStart = accessor.getFieldStartOffset(tIndex, fIdx);
                int fEnd = accessor.getFieldEndOffset(tIndex, fIdx);
                c = comparators[f].compare(accessor.getBuffer().array(), startOffset + slotLength + fStart, fEnd - fStart, rangeMap.getByteArray(), rangeMap.getStartOffset(fieldIndex, f), rangeMap.getLength(fieldIndex, f));
                if (c != 0) {
                    return c;
                }
            }
            return c;
        }
    };
}
#method_after
@Override
public ITuplePartitionComputer createPartitioner(IHyracksTaskContext hyracksTaskContext) {
    final IBinaryComparator[] comparators = new IBinaryComparator[comparatorFactories.length];
    for (int i = 0; i < comparatorFactories.length; ++i) {
        comparators[i] = comparatorFactories[i].createBinaryComparator();
    }
    return new ITuplePartitionComputer() {

        private RangeMap rangeMap;

        @Override
        public void initialize() throws HyracksDataException {
            rangeMap = getRangeMap(hyracksTaskContext);
        }

        @Override
        public int partition(IFrameTupleAccessor accessor, int tIndex, int nParts) throws HyracksDataException {
            if (nParts == 1) {
                return 0;
            }
            int slotIndex = getRangePartition(accessor, tIndex);
            // Map range partition to node partitions.
            double rangesPerPart = 1;
            if (rangeMap.getSplitCount() + 1 > nParts) {
                rangesPerPart = ((double) rangeMap.getSplitCount() + 1) / nParts;
            }
            return (int) Math.floor(slotIndex / rangesPerPart);
        }

        private int getRangePartition(IFrameTupleAccessor accessor, int tIndex) throws HyracksDataException {
            int slotIndex = 0;
            for (int slotNumber = 0; slotNumber < rangeMap.getSplitCount(); ++slotNumber) {
                int c = compareSlotAndFields(accessor, tIndex, slotNumber);
                if (c < 0) {
                    return slotIndex;
                }
                slotIndex++;
            }
            return slotIndex;
        }

        private int compareSlotAndFields(IFrameTupleAccessor accessor, int tIndex, int slotNumber) throws HyracksDataException {
            int c = 0;
            int startOffset = accessor.getTupleStartOffset(tIndex);
            int slotLength = accessor.getFieldSlotsLength();
            for (int fieldNum = 0; fieldNum < comparators.length; ++fieldNum) {
                int fIdx = rangeFields[fieldNum];
                int fStart = accessor.getFieldStartOffset(tIndex, fIdx);
                int fEnd = accessor.getFieldEndOffset(tIndex, fIdx);
                c = comparators[fieldNum].compare(accessor.getBuffer().array(), startOffset + slotLength + fStart, fEnd - fStart, rangeMap.getByteArray(), rangeMap.getStartOffset(fieldNum, slotNumber), rangeMap.getLength(fieldNum, slotNumber));
                if (c != 0) {
                    return c;
                }
            }
            return c;
        }
    };
}
#end_block

#method_before
@Override
public Void visitUnnestMapOperator(UnnestMapOperator op, Integer indent) throws AlgebricksException {
    return printAbstractUnnestMapOperator(op, indent, "unnest-map");
}
#method_after
@Override
public Void visitUnnestMapOperator(UnnestMapOperator op, Integer indent) throws AlgebricksException {
    AlgebricksAppendable plan = printAbstractUnnestMapOperator(op, indent, "unnest-map");
    appendSelectConditionInformation(plan, op.getSelectCondition(), indent);
    appendLimitInformation(plan, op.getOutputLimit());
    return null;
}
#end_block

#method_before
@Override
public Void visitLeftOuterUnnestMapOperator(LeftOuterUnnestMapOperator op, Integer indent) throws AlgebricksException {
    return printAbstractUnnestMapOperator(op, indent, "left-outer-unnest-map");
}
#method_after
@Override
public Void visitLeftOuterUnnestMapOperator(LeftOuterUnnestMapOperator op, Integer indent) throws AlgebricksException {
    printAbstractUnnestMapOperator(op, indent, "left-outer-unnest-map");
    return null;
}
#end_block

#method_before
private Void printAbstractUnnestMapOperator(AbstractUnnestMapOperator op, Integer indent, String opSignature) throws AlgebricksException {
    AlgebricksAppendable plan = addIndent(indent).append(opSignature + " " + op.getVariables() + " <- " + op.getExpressionRef().getValue().accept(exprVisitor, indent));
    appendFilterInformation(plan, op.getMinFilterVars(), op.getMaxFilterVars());
    return null;
}
#method_after
private AlgebricksAppendable printAbstractUnnestMapOperator(AbstractUnnestMapOperator op, Integer indent, String opSignature) throws AlgebricksException {
    AlgebricksAppendable plan = addIndent(indent).append(opSignature + " " + op.getVariables() + " <- " + op.getExpressionRef().getValue().accept(exprVisitor, indent));
    appendFilterInformation(plan, op.getMinFilterVars(), op.getMaxFilterVars());
    return plan;
}
#end_block

#method_before
@Override
public Void visitDataScanOperator(DataSourceScanOperator op, Integer indent) throws AlgebricksException {
    AlgebricksAppendable plan = addIndent(indent).append("data-scan " + op.getProjectVariables() + "<-" + op.getVariables() + " <- " + op.getDataSource());
    appendFilterInformation(plan, op.getMinFilterVars(), op.getMaxFilterVars());
    return null;
}
#method_after
@Override
public Void visitDataScanOperator(DataSourceScanOperator op, Integer indent) throws AlgebricksException {
    AlgebricksAppendable plan = addIndent(indent).append("data-scan " + op.getProjectVariables() + "<-" + op.getVariables() + " <- " + op.getDataSource());
    appendFilterInformation(plan, op.getMinFilterVars(), op.getMaxFilterVars());
    appendSelectConditionInformation(plan, op.getSelectCondition(), indent);
    appendLimitInformation(plan, op.getOutputLimit());
    return null;
}
#end_block

#method_before
@Override
public Void visitSplitOperator(SplitOperator op, Integer indent) throws AlgebricksException {
    Mutable<ILogicalExpression> branchingExpression = op.getBranchingExpression();
    addIndent(indent).append("split " + branchingExpression.getValue().accept(exprVisitor, indent));
    return null;
}
#method_after
@Override
public Void visitSplitOperator(SplitOperator op, Integer indent) throws AlgebricksException {
    Mutable<ILogicalExpression> branchingExpression = op.getBranchingExpression();
    addIndent(indent).append("split (" + branchingExpression.getValue().accept(exprVisitor, indent) + ")");
    return null;
}
#end_block

#method_before
@Override
public Void visitForwardOperator(ForwardOperator op, Integer indent) throws AlgebricksException {
    addIndent(indent).append("forward");
    return null;
}
#method_after
@Override
public Void visitForwardOperator(ForwardOperator op, Integer indent) throws AlgebricksException {
    addIndent(indent).append("forward: range-map = " + op.getRangeMapExpression().getValue().accept(exprVisitor, indent));
    return null;
}
#end_block

#method_before
private void deepCopyInputsAnnotationsAndExecutionMode(ILogicalOperator op, ILogicalOperator arg, AbstractLogicalOperator opCopy) throws AlgebricksException {
    deepCopyInputs(op, opCopy, arg);
    copyAnnotations(op, opCopy);
    opCopy.setExecutionMode(op.getExecutionMode());
}
#method_after
private void deepCopyInputsAnnotationsAndExecutionMode(ILogicalOperator op, ILogicalOperator arg, AbstractLogicalOperator opCopy) throws AlgebricksException {
    deepCopyInputs(op, opCopy, arg);
    copyAnnotations(op, opCopy);
    copySourceLocation(op, opCopy);
    opCopy.setExecutionMode(op.getExecutionMode());
}
#end_block

#method_before
@Override
public ILogicalOperator visitDataScanOperator(DataSourceScanOperator op, ILogicalOperator arg) throws AlgebricksException {
    DataSourceScanOperator opCopy = new DataSourceScanOperator(deepCopyVariableList(op.getVariables()), op.getDataSource());
    deepCopyInputsAnnotationsAndExecutionMode(op, arg, opCopy);
    return opCopy;
}
#method_after
@Override
public ILogicalOperator visitDataScanOperator(DataSourceScanOperator op, ILogicalOperator arg) throws AlgebricksException {
    Mutable<ILogicalExpression> newSelectCondition = op.getSelectCondition() != null ? exprDeepCopyVisitor.deepCopyExpressionReference(op.getSelectCondition()) : null;
    DataSourceScanOperator opCopy = new DataSourceScanOperator(deepCopyVariableList(op.getVariables()), op.getDataSource(), newSelectCondition, op.getOutputLimit());
    deepCopyInputsAnnotationsAndExecutionMode(op, arg, opCopy);
    return opCopy;
}
#end_block

#method_before
@Override
public ILogicalOperator visitEmptyTupleSourceOperator(EmptyTupleSourceOperator op, ILogicalOperator arg) {
    EmptyTupleSourceOperator opCopy = new EmptyTupleSourceOperator();
    opCopy.setExecutionMode(op.getExecutionMode());
    return opCopy;
}
#method_after
@Override
public ILogicalOperator visitEmptyTupleSourceOperator(EmptyTupleSourceOperator op, ILogicalOperator arg) {
    EmptyTupleSourceOperator opCopy = new EmptyTupleSourceOperator();
    copySourceLocation(op, opCopy);
    opCopy.setExecutionMode(op.getExecutionMode());
    return opCopy;
}
#end_block

#method_before
@Override
public ILogicalOperator visitInnerJoinOperator(InnerJoinOperator op, ILogicalOperator arg) throws AlgebricksException {
    InnerJoinOperator opCopy = new InnerJoinOperator(exprDeepCopyVisitor.deepCopyExpressionReference(op.getCondition()), deepCopyOperatorReference(op.getInputs().get(0), arg), deepCopyOperatorReference(op.getInputs().get(1), arg));
    copyAnnotations(op, opCopy);
    opCopy.setExecutionMode(op.getExecutionMode());
    return opCopy;
}
#method_after
@Override
public ILogicalOperator visitInnerJoinOperator(InnerJoinOperator op, ILogicalOperator arg) throws AlgebricksException {
    InnerJoinOperator opCopy = new InnerJoinOperator(exprDeepCopyVisitor.deepCopyExpressionReference(op.getCondition()), deepCopyOperatorReference(op.getInputs().get(0), arg), deepCopyOperatorReference(op.getInputs().get(1), arg));
    copyAnnotations(op, opCopy);
    copySourceLocation(op, opCopy);
    opCopy.setExecutionMode(op.getExecutionMode());
    return opCopy;
}
#end_block

#method_before
@Override
public ILogicalOperator visitLeftOuterJoinOperator(LeftOuterJoinOperator op, ILogicalOperator arg) throws AlgebricksException {
    LeftOuterJoinOperator opCopy = new LeftOuterJoinOperator(exprDeepCopyVisitor.deepCopyExpressionReference(op.getCondition()), deepCopyOperatorReference(op.getInputs().get(0), arg), deepCopyOperatorReference(op.getInputs().get(1), arg));
    copyAnnotations(op, opCopy);
    opCopy.setExecutionMode(op.getExecutionMode());
    return opCopy;
}
#method_after
@Override
public ILogicalOperator visitLeftOuterJoinOperator(LeftOuterJoinOperator op, ILogicalOperator arg) throws AlgebricksException {
    LeftOuterJoinOperator opCopy = new LeftOuterJoinOperator(exprDeepCopyVisitor.deepCopyExpressionReference(op.getCondition()), deepCopyOperatorReference(op.getInputs().get(0), arg), deepCopyOperatorReference(op.getInputs().get(1), arg));
    copyAnnotations(op, opCopy);
    copySourceLocation(op, opCopy);
    opCopy.setExecutionMode(op.getExecutionMode());
    return opCopy;
}
#end_block

#method_before
@Override
public ILogicalOperator visitUnnestMapOperator(UnnestMapOperator op, ILogicalOperator arg) throws AlgebricksException {
    UnnestMapOperator opCopy = new UnnestMapOperator(deepCopyVariableList(op.getVariables()), exprDeepCopyVisitor.deepCopyExpressionReference(op.getExpressionRef()), op.getVariableTypes(), op.propagatesInput());
    deepCopyInputsAnnotationsAndExecutionMode(op, arg, opCopy);
    return opCopy;
}
#method_after
@Override
public ILogicalOperator visitUnnestMapOperator(UnnestMapOperator op, ILogicalOperator arg) throws AlgebricksException {
    Mutable<ILogicalExpression> newSelectCondition = op.getSelectCondition() != null ? exprDeepCopyVisitor.deepCopyExpressionReference(op.getSelectCondition()) : null;
    UnnestMapOperator opCopy = new UnnestMapOperator(deepCopyVariableList(op.getVariables()), exprDeepCopyVisitor.deepCopyExpressionReference(op.getExpressionRef()), op.getVariableTypes(), op.propagatesInput(), newSelectCondition, op.getOutputLimit());
    deepCopyInputsAnnotationsAndExecutionMode(op, arg, opCopy);
    return opCopy;
}
#end_block

#method_before
@Override
public ILogicalOperator visitForwardOperator(ForwardOperator op, ILogicalOperator arg) throws AlgebricksException {
    ForwardOperator opCopy = new ForwardOperator();
    deepCopyInputsAnnotationsAndExecutionMode(op, arg, opCopy);
    return opCopy;
}
#method_after
@Override
public ILogicalOperator visitForwardOperator(ForwardOperator op, ILogicalOperator arg) throws AlgebricksException {
    ForwardOperator opCopy = new ForwardOperator(op.getRangeMapKey(), exprDeepCopyVisitor.deepCopyExpressionReference(op.getRangeMapExpression()));
    deepCopyInputsAnnotationsAndExecutionMode(op, arg, opCopy);
    return opCopy;
}
#end_block

#method_before
@Override
public void computeDeliveredProperties(ILogicalOperator op, IOptimizationContext context) {
    IPartitioningProperty p = new OrderedPartitionedProperty(new ArrayList<OrderColumn>(partitioningFields), domain);
    this.deliveredProperties = new StructuralPropertiesVector(p, new LinkedList<ILocalStructuralProperty>());
}
#method_after
@Override
public void computeDeliveredProperties(ILogicalOperator op, IOptimizationContext context) {
    IPartitioningProperty p = new OrderedPartitionedProperty(new ArrayList<>(partitioningFields), domain);
    this.deliveredProperties = new StructuralPropertiesVector(p, new LinkedList<ILocalStructuralProperty>());
}
#end_block

#method_before
@Override
public Pair<IConnectorDescriptor, TargetConstraint> createConnectorDescriptor(IConnectorDescriptorRegistry spec, ILogicalOperator op, IOperatorSchema opSchema, JobGenContext context) throws AlgebricksException {
    int n = partitioningFields.size();
    int[] sortFields = new int[n];
    IBinaryComparatorFactory[] comps = new IBinaryComparatorFactory[n];
    INormalizedKeyComputerFactoryProvider nkcfProvider = context.getNormalizedKeyComputerFactoryProvider();
    INormalizedKeyComputerFactory nkcf = null;
    IVariableTypeEnvironment env = context.getTypeEnvironment(op);
    int i = 0;
    for (OrderColumn oc : partitioningFields) {
        LogicalVariable var = oc.getColumn();
        sortFields[i] = opSchema.findVariable(var);
        Object type = env.getVarType(var);
        OrderKind order = oc.getOrder();
        if (i == 0 && nkcfProvider != null && type != null) {
            nkcf = nkcfProvider.getNormalizedKeyComputerFactory(type, order == OrderKind.ASC);
        }
        IBinaryComparatorFactoryProvider bcfp = context.getBinaryComparatorFactoryProvider();
        comps[i] = bcfp.getBinaryComparatorFactory(type, oc.getOrder() == OrderKind.ASC);
        i++;
    }
    FieldRangePartitionComputerFactory partitionerFactory;
    if (rangeMapIsComputedAtRunTime) {
        partitionerFactory = new FieldRangePartitionComputerFactory(sortFields, comps, rangeMapKeyInContext);
    } else {
        partitionerFactory = new FieldRangePartitionComputerFactory(sortFields, comps, rangeMap);
    }
    IConnectorDescriptor conn = new MToNPartitioningConnectorDescriptor(spec, partitionerFactory);
    return new Pair<IConnectorDescriptor, TargetConstraint>(conn, null);
}
#method_after
@Override
public Pair<IConnectorDescriptor, TargetConstraint> createConnectorDescriptor(IConnectorDescriptorRegistry spec, ILogicalOperator op, IOperatorSchema opSchema, JobGenContext context) throws AlgebricksException {
    int n = partitioningFields.size();
    int[] sortFields = new int[n];
    IBinaryComparatorFactory[] comps = new IBinaryComparatorFactory[n];
    IVariableTypeEnvironment env = context.getTypeEnvironment(op);
    int i = 0;
    for (OrderColumn oc : partitioningFields) {
        LogicalVariable var = oc.getColumn();
        sortFields[i] = opSchema.findVariable(var);
        Object type = env.getVarType(var);
        IBinaryComparatorFactoryProvider bcfp = context.getBinaryComparatorFactoryProvider();
        comps[i] = bcfp.getBinaryComparatorFactory(type, oc.getOrder() == OrderKind.ASC);
        i++;
    }
    FieldRangePartitionComputerFactory partitionerFactory;
    if (rangeMapIsComputedAtRunTime) {
        partitionerFactory = new DynamicFieldRangePartitionComputerFactory(sortFields, comps, rangeMapKeyInContext, op.getSourceLocation());
    } else {
        partitionerFactory = new StaticFieldRangePartitionComputerFactory(sortFields, comps, rangeMap);
    }
    IConnectorDescriptor conn = new MToNPartitioningConnectorDescriptor(spec, partitionerFactory);
    return new Pair<>(conn, null);
}
#end_block

#method_before
@Override
public String toString() {
    final String splitCount = rangeMap == null ? "" : Integer.toString(rangeMap.getSplitCount());
    return getOperatorTag().toString() + " " + partitioningFields + " SPLIT COUNT:" + splitCount;
}
#method_after
@Override
public String toString() {
    final String splitCount = rangeMap == null ? "" : " SPLIT COUNT:" + Integer.toString(rangeMap.getSplitCount());
    return getOperatorTag().toString() + " " + partitioningFields + splitCount;
}
#end_block

#method_before
public long getOperatorRequiredMemory(ILogicalOperator operator) {
    switch(operator.getOperatorTag()) {
        case AGGREGATE:
        case ASSIGN:
        case DATASOURCESCAN:
        case DISTINCT:
        case DISTRIBUTE_RESULT:
        case EMPTYTUPLESOURCE:
        case DELEGATE_OPERATOR:
        case EXTERNAL_LOOKUP:
        case LEFT_OUTER_UNNEST_MAP:
        case LIMIT:
        case MATERIALIZE:
        case NESTEDTUPLESOURCE:
        case PROJECT:
        case REPLICATE:
        case RUNNINGAGGREGATE:
        case SCRIPT:
        case SELECT:
        case SINK:
        case SPLIT:
        case SUBPLAN:
        case TOKENIZE:
        case UNIONALL:
        case UNNEST:
        case LEFT_OUTER_UNNEST:
        case UNNEST_MAP:
        case UPDATE:
        case WRITE:
        case WRITE_RESULT:
        case INDEX_INSERT_DELETE_UPSERT:
        case INSERT_DELETE_UPSERT:
        case INTERSECT:
        case FORWARD:
            return getOperatorRequiredMemory(operator, frameSize);
        case EXCHANGE:
            return getExchangeRequiredMemory((ExchangeOperator) operator);
        case GROUP:
            return getOperatorRequiredMemory(operator, groupByMemorySize);
        case ORDER:
            return getOperatorRequiredMemory(operator, sortMemorySize);
        case INNERJOIN:
        case LEFTOUTERJOIN:
            return getOperatorRequiredMemory(operator, joinMemorySize);
        default:
            throw new IllegalStateException("Unrecognized operator: " + operator.getOperatorTag());
    }
}
#method_after
public long getOperatorRequiredMemory(ILogicalOperator operator) {
    switch(operator.getOperatorTag()) {
        case AGGREGATE:
        case ASSIGN:
        case DATASOURCESCAN:
        case DISTINCT:
        case DISTRIBUTE_RESULT:
        case EMPTYTUPLESOURCE:
        case DELEGATE_OPERATOR:
        case EXTERNAL_LOOKUP:
        case LIMIT:
        case MATERIALIZE:
        case NESTEDTUPLESOURCE:
        case PROJECT:
        case REPLICATE:
        case RUNNINGAGGREGATE:
        case SCRIPT:
        case SELECT:
        case SINK:
        case SPLIT:
        case SUBPLAN:
        case TOKENIZE:
        case UNIONALL:
        case UNNEST:
        case LEFT_OUTER_UNNEST:
        case UPDATE:
        case WRITE:
        case WRITE_RESULT:
        case INDEX_INSERT_DELETE_UPSERT:
        case INSERT_DELETE_UPSERT:
        case INTERSECT:
        case FORWARD:
            return getOperatorRequiredMemory(operator, frameSize);
        case LEFT_OUTER_UNNEST_MAP:
        case UNNEST_MAP:
            // Since an inverted-index search requires certain amount of memory, needs to calculate
            // the memory size differently if the given index-search is an inverted-index search.
            long unnestMapMemorySize = frameSize;
            if (isInvertedIndexSearch((AbstractUnnestMapOperator) operator)) {
                unnestMapMemorySize += textSearchMemorySize;
            }
            return getOperatorRequiredMemory(operator, unnestMapMemorySize);
        case EXCHANGE:
            return getExchangeRequiredMemory((ExchangeOperator) operator);
        case GROUP:
            return getOperatorRequiredMemory(operator, groupByMemorySize);
        case ORDER:
            return getOperatorRequiredMemory(operator, sortMemorySize);
        case INNERJOIN:
        case LEFTOUTERJOIN:
            return getOperatorRequiredMemory(operator, joinMemorySize);
        default:
            throw new IllegalStateException("Unrecognized operator: " + operator.getOperatorTag());
    }
}
#end_block

#method_before
@Override
public ILogicalOperator visitInnerJoinOperator(InnerJoinOperator op, Void arg) throws AlgebricksException {
    hasJoinAncestor = true;
    boolean needToSwitch = false;
    for (int i = 0; i < op.getInputs().size(); ++i) {
        // Deals with single input operators.
        ILogicalOperator newChild = op.getInputs().get(i).getValue().accept(this, null);
        op.getInputs().get(i).setValue(newChild);
        if (i == 1) {
            needToSwitch = true;
        }
        if (rewritten) {
            break;
        }
    }
    // Checks whether there is a need to switch two join branches.
    if (rewritten && needToSwitch) {
        Mutable<ILogicalOperator> leftBranch = op.getInputs().get(0);
        Mutable<ILogicalOperator> rightBranch = op.getInputs().get(1);
        op.getInputs().set(0, rightBranch);
        op.getInputs().set(1, leftBranch);
    }
    AbstractBinaryJoinOperator returnOp = op;
    // After rewriting, the original inner join should become an left outer join.
    if (rewritten) {
        returnOp = new LeftOuterJoinOperator(op.getCondition());
        returnOp.getInputs().addAll(op.getInputs());
        injectNullCheckVars(returnOp);
    }
    return returnOp;
}
#method_after
@Override
public ILogicalOperator visitInnerJoinOperator(InnerJoinOperator op, Void arg) throws AlgebricksException {
    hasJoinAncestor = true;
    boolean needToSwitch = false;
    for (int i = 0; i < op.getInputs().size(); ++i) {
        // Deals with single input operators.
        ILogicalOperator newChild = op.getInputs().get(i).getValue().accept(this, null);
        op.getInputs().get(i).setValue(newChild);
        if (i == 1) {
            needToSwitch = true;
        }
        if (rewritten) {
            break;
        }
    }
    // Checks whether there is a need to switch two join branches.
    if (rewritten && needToSwitch) {
        Mutable<ILogicalOperator> leftBranch = op.getInputs().get(0);
        Mutable<ILogicalOperator> rightBranch = op.getInputs().get(1);
        op.getInputs().set(0, rightBranch);
        op.getInputs().set(1, leftBranch);
    }
    AbstractBinaryJoinOperator returnOp = op;
    // After rewriting, the original inner join should become an left outer join.
    if (rewritten) {
        returnOp = new LeftOuterJoinOperator(op.getCondition());
        returnOp.setSourceLocation(op.getSourceLocation());
        returnOp.getInputs().addAll(op.getInputs());
        injectNullCheckVars(returnOp);
    }
    return returnOp;
}
#end_block

#method_before
@Override
public ILogicalOperator visitOrderOperator(OrderOperator op, Void arg) throws AlgebricksException {
    boolean underJoin = hasJoinAncestor;
    visitSingleInputOperator(op);
    if (!rewritten || !underJoin) {
        return op;
    }
    // Adjust the ordering if its input operator pipeline has been rewritten.
    List<Pair<IOrder, Mutable<ILogicalExpression>>> orderExprList = new ArrayList<>();
    // Adds keyVars to the prefix of sorting columns.
    for (LogicalVariable liveVar : liveVarsFromSubplanInput) {
        orderExprList.add(new Pair<IOrder, Mutable<ILogicalExpression>>(OrderOperator.ASC_ORDER, new MutableObject<ILogicalExpression>(new VariableReferenceExpression(liveVar))));
    }
    orderExprList.addAll(op.getOrderExpressions());
    // Creates an order operator with the new expression list.
    OrderOperator orderOp = new OrderOperator(orderExprList);
    orderOp.getInputs().addAll(op.getInputs());
    context.computeAndSetTypeEnvironmentForOperator(orderOp);
    return orderOp;
}
#method_after
@Override
public ILogicalOperator visitOrderOperator(OrderOperator op, Void arg) throws AlgebricksException {
    boolean underJoin = hasJoinAncestor;
    visitSingleInputOperator(op);
    if (!rewritten || !underJoin) {
        return op;
    }
    // Adjust the ordering if its input operator pipeline has been rewritten.
    List<Pair<IOrder, Mutable<ILogicalExpression>>> orderExprList = new ArrayList<>();
    // Adds keyVars to the prefix of sorting columns.
    for (LogicalVariable liveVar : liveVarsFromSubplanInput) {
        VariableReferenceExpression liveVarRef = new VariableReferenceExpression(liveVar);
        liveVarRef.setSourceLocation(op.getSourceLocation());
        orderExprList.add(new Pair<IOrder, Mutable<ILogicalExpression>>(OrderOperator.ASC_ORDER, new MutableObject<ILogicalExpression>(liveVarRef)));
    }
    orderExprList.addAll(op.getOrderExpressions());
    // Creates an order operator with the new expression list.
    OrderOperator orderOp = new OrderOperator(orderExprList);
    orderOp.setSourceLocation(op.getSourceLocation());
    orderOp.getInputs().addAll(op.getInputs());
    context.computeAndSetTypeEnvironmentForOperator(orderOp);
    return orderOp;
}
#end_block

#method_before
@Override
public ILogicalOperator visitForwardOperator(ForwardOperator op, Void arg) throws AlgebricksException {
    // TODO(ali): check this
    ILogicalOperator newChild = op.getInputs().get(0).getValue().accept(this, null);
    op.getInputs().get(0).setValue(newChild);
    return op;
}
#method_after
@Override
public ILogicalOperator visitForwardOperator(ForwardOperator op, Void arg) throws AlgebricksException {
    throw new UnsupportedOperationException("Nested subplans with a forward operator should have been disqualified for this rewriting!");
}
#end_block

#method_before
private void injectNullCheckVars(AbstractBinaryJoinOperator joinOp) {
    LogicalVariable assignVar = context.newVar();
    ILogicalOperator assignOp = new AssignOperator(assignVar, new MutableObject<ILogicalExpression>(ConstantExpression.TRUE));
    assignOp.getInputs().add(joinOp.getInputs().get(1));
    joinOp.getInputs().set(1, new MutableObject<ILogicalOperator>(assignOp));
    nullCheckVars.add(assignVar);
}
#method_after
private void injectNullCheckVars(AbstractBinaryJoinOperator joinOp) {
    LogicalVariable assignVar = context.newVar();
    AssignOperator assignOp = new AssignOperator(assignVar, new MutableObject<ILogicalExpression>(ConstantExpression.TRUE));
    assignOp.setSourceLocation(joinOp.getSourceLocation());
    assignOp.getInputs().add(joinOp.getInputs().get(1));
    joinOp.getInputs().set(1, new MutableObject<ILogicalOperator>(assignOp));
    nullCheckVars.add(assignVar);
}
#end_block

#method_before
private static void computeLogicalPropertiesRec(ILogicalOperator op, LogicalPropertiesVisitor visitor, IOptimizationContext context) throws AlgebricksException {
    for (Mutable<ILogicalOperator> ref : op.getInputs()) {
        computeLogicalPropertiesRec(ref.getValue(), visitor, context);
    }
    op.accept(visitor, context);
    if (AlgebricksConfig.DEBUG) {
        AlgebricksConfig.ALGEBRICKS_LOGGER.trace("Logical properties visitor for " + op + ": " + context.getLogicalPropertiesVector(op) + "\n");
    }
}
#method_after
private static void computeLogicalPropertiesRec(ILogicalOperator op, LogicalPropertiesVisitor visitor, IOptimizationContext context) throws AlgebricksException {
    for (Mutable<ILogicalOperator> ref : op.getInputs()) {
        computeLogicalPropertiesRec(ref.getValue(), visitor, context);
    }
    op.accept(visitor, context);
    if (AlgebricksConfig.ALGEBRICKS_LOGGER.isTraceEnabled()) {
        AlgebricksConfig.ALGEBRICKS_LOGGER.trace("Logical properties visitor for " + op + ": " + context.getLogicalPropertiesVector(op) + "\n");
    }
}
#end_block

#method_before
@Override
public Boolean visitForwardOperator(ForwardOperator op, Void arg) throws AlgebricksException {
    return visitInputs(op);
}
#method_after
@Override
public Boolean visitForwardOperator(ForwardOperator op, Void arg) throws AlgebricksException {
    throw new CompilationException(ErrorCode.COMPILATION_ERROR, op.getSourceLocation(), "Forward operator should have been disqualified for this rewriting!");
}
#end_block

#method_before
@Override
public String visitAggregateOperator(AggregateOperator op, Void noArgs) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("aggregate ").append(str(op.getVariables())).append(" <- ");
    printExprList(op.getExpressions());
    appendSchema(op);
    appendAnnotations(op);
    appendPhysicalOperatorInfo(op);
    return stringBuilder.toString();
}
#method_after
@Override
public String visitAggregateOperator(AggregateOperator op, Boolean showDetails) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("aggregate ").append(str(op.getVariables())).append(" <- ");
    printExprList(op.getExpressions());
    appendSchema(op, showDetails);
    appendAnnotations(op, showDetails);
    appendPhysicalOperatorInfo(op, showDetails);
    return stringBuilder.toString();
}
#end_block

#method_before
@Override
public String visitRunningAggregateOperator(RunningAggregateOperator op, Void noArgs) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("running-aggregate ").append(str(op.getVariables())).append(" <- ");
    printExprList(op.getExpressions());
    appendSchema(op);
    appendAnnotations(op);
    appendPhysicalOperatorInfo(op);
    return stringBuilder.toString();
}
#method_after
@Override
public String visitRunningAggregateOperator(RunningAggregateOperator op, Boolean showDetails) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("running-aggregate ").append(str(op.getVariables())).append(" <- ");
    printExprList(op.getExpressions());
    appendSchema(op, showDetails);
    appendAnnotations(op, showDetails);
    appendPhysicalOperatorInfo(op, showDetails);
    return stringBuilder.toString();
}
#end_block

#method_before
@Override
public String visitEmptyTupleSourceOperator(EmptyTupleSourceOperator op, Void noArgs) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("empty-tuple-source");
    appendSchema(op);
    appendAnnotations(op);
    appendPhysicalOperatorInfo(op);
    return stringBuilder.toString();
}
#method_after
@Override
public String visitEmptyTupleSourceOperator(EmptyTupleSourceOperator op, Boolean showDetails) {
    stringBuilder.setLength(0);
    stringBuilder.append("empty-tuple-source");
    appendSchema(op, showDetails);
    appendAnnotations(op, showDetails);
    appendPhysicalOperatorInfo(op, showDetails);
    return stringBuilder.toString();
}
#end_block

#method_before
@Override
public String visitGroupByOperator(GroupByOperator op, Void noArgs) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("group by").append(op.isGroupAll() ? " (all)" : "").append(" (");
    printVariableAndExprList(op.getGroupByList());
    stringBuilder.append(") decor (");
    printVariableAndExprList(op.getDecorList());
    stringBuilder.append(")");
    appendSchema(op);
    appendAnnotations(op);
    appendPhysicalOperatorInfo(op);
    return stringBuilder.toString();
}
#method_after
@Override
public String visitGroupByOperator(GroupByOperator op, Boolean showDetails) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("group by").append(op.isGroupAll() ? " (all)" : "").append(" (");
    printVariableAndExprList(op.getGroupByList());
    stringBuilder.append(") decor (");
    printVariableAndExprList(op.getDecorList());
    stringBuilder.append(")");
    appendSchema(op, showDetails);
    appendAnnotations(op, showDetails);
    appendPhysicalOperatorInfo(op, showDetails);
    return stringBuilder.toString();
}
#end_block

#method_before
@Override
public String visitDistinctOperator(DistinctOperator op, Void noArgs) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("distinct (");
    printExprList(op.getExpressions());
    stringBuilder.append(")");
    appendSchema(op);
    appendAnnotations(op);
    appendPhysicalOperatorInfo(op);
    return stringBuilder.toString();
}
#method_after
@Override
public String visitDistinctOperator(DistinctOperator op, Boolean showDetails) {
    stringBuilder.setLength(0);
    stringBuilder.append("distinct (");
    printExprList(op.getExpressions());
    stringBuilder.append(")");
    appendSchema(op, showDetails);
    appendAnnotations(op, showDetails);
    appendPhysicalOperatorInfo(op, showDetails);
    return stringBuilder.toString();
}
#end_block

#method_before
@Override
public String visitInnerJoinOperator(InnerJoinOperator op, Void noArgs) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("join (").append(op.getCondition().getValue().toString()).append(")");
    appendSchema(op);
    appendAnnotations(op);
    appendPhysicalOperatorInfo(op);
    return stringBuilder.toString();
}
#method_after
@Override
public String visitInnerJoinOperator(InnerJoinOperator op, Boolean showDetails) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("join (").append(op.getCondition().getValue().toString()).append(")");
    appendSchema(op, showDetails);
    appendAnnotations(op, showDetails);
    appendPhysicalOperatorInfo(op, showDetails);
    return stringBuilder.toString();
}
#end_block

#method_before
@Override
public String visitLeftOuterJoinOperator(LeftOuterJoinOperator op, Void noArgs) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("left outer join (").append(op.getCondition().getValue().toString()).append(")");
    appendSchema(op);
    appendAnnotations(op);
    appendPhysicalOperatorInfo(op);
    return stringBuilder.toString();
}
#method_after
@Override
public String visitLeftOuterJoinOperator(LeftOuterJoinOperator op, Boolean showDetails) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("left outer join (").append(op.getCondition().getValue().toString()).append(")");
    appendSchema(op, showDetails);
    appendAnnotations(op, showDetails);
    appendPhysicalOperatorInfo(op, showDetails);
    return stringBuilder.toString();
}
#end_block

#method_before
@Override
public String visitNestedTupleSourceOperator(NestedTupleSourceOperator op, Void noArgs) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("nested tuple source");
    appendSchema(op);
    appendAnnotations(op);
    appendPhysicalOperatorInfo(op);
    return stringBuilder.toString();
}
#method_after
@Override
public String visitNestedTupleSourceOperator(NestedTupleSourceOperator op, Boolean showDetails) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("nested tuple source");
    appendSchema(op, showDetails);
    appendAnnotations(op, showDetails);
    appendPhysicalOperatorInfo(op, showDetails);
    return stringBuilder.toString();
}
#end_block

#method_before
@Override
public String visitOrderOperator(OrderOperator op, Void noArgs) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("order ");
    for (Pair<OrderOperator.IOrder, Mutable<ILogicalExpression>> p : op.getOrderExpressions()) {
        if (op.getTopK() != -1) {
            stringBuilder.append("(topK: ").append(op.getTopK()).append(") ");
        }
        stringBuilder.append("(");
        switch(p.first.getKind()) {
            case ASC:
                stringBuilder.append("ASC");
                break;
            case DESC:
                stringBuilder.append("DESC");
                break;
            default:
                final Mutable<ILogicalExpression> expressionRef = p.first.getExpressionRef();
                stringBuilder.append(expressionRef == null ? "null" : expressionRef.toString());
        }
        stringBuilder.append(", ").append(p.second.getValue().toString()).append(") ");
    }
    appendSchema(op);
    appendAnnotations(op);
    appendPhysicalOperatorInfo(op);
    return stringBuilder.toString();
}
#method_after
@Override
public String visitOrderOperator(OrderOperator op, Boolean showDetails) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("order ");
    for (Pair<OrderOperator.IOrder, Mutable<ILogicalExpression>> p : op.getOrderExpressions()) {
        if (op.getTopK() != -1) {
            stringBuilder.append("(topK: ").append(op.getTopK()).append(") ");
        }
        stringBuilder.append("(");
        switch(p.first.getKind()) {
            case ASC:
                stringBuilder.append("ASC");
                break;
            case DESC:
                stringBuilder.append("DESC");
                break;
            default:
                final Mutable<ILogicalExpression> expressionRef = p.first.getExpressionRef();
                stringBuilder.append(expressionRef == null ? "null" : expressionRef.toString());
        }
        stringBuilder.append(", ").append(p.second.getValue().toString()).append(") ");
    }
    appendSchema(op, showDetails);
    appendAnnotations(op, showDetails);
    appendPhysicalOperatorInfo(op, showDetails);
    return stringBuilder.toString();
}
#end_block

#method_before
@Override
public String visitAssignOperator(AssignOperator op, Void noArgs) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("assign ").append(str(op.getVariables())).append(" <- ");
    printExprList(op.getExpressions());
    appendSchema(op);
    appendAnnotations(op);
    appendPhysicalOperatorInfo(op);
    return stringBuilder.toString();
}
#method_after
@Override
public String visitAssignOperator(AssignOperator op, Boolean showDetails) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("assign ").append(str(op.getVariables())).append(" <- ");
    printExprList(op.getExpressions());
    appendSchema(op, showDetails);
    appendAnnotations(op, showDetails);
    appendPhysicalOperatorInfo(op, showDetails);
    return stringBuilder.toString();
}
#end_block

#method_before
@Override
public String visitWriteOperator(WriteOperator op, Void noArgs) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("write ");
    printExprList(op.getExpressions());
    appendSchema(op);
    appendAnnotations(op);
    appendPhysicalOperatorInfo(op);
    return stringBuilder.toString();
}
#method_after
@Override
public String visitWriteOperator(WriteOperator op, Boolean showDetails) {
    stringBuilder.setLength(0);
    stringBuilder.append("write ");
    printExprList(op.getExpressions());
    appendSchema(op, showDetails);
    appendAnnotations(op, showDetails);
    appendPhysicalOperatorInfo(op, showDetails);
    return stringBuilder.toString();
}
#end_block

#method_before
@Override
public String visitDistributeResultOperator(DistributeResultOperator op, Void noArgs) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("distribute result ");
    printExprList(op.getExpressions());
    appendSchema(op);
    appendAnnotations(op);
    appendPhysicalOperatorInfo(op);
    return stringBuilder.toString();
}
#method_after
@Override
public String visitDistributeResultOperator(DistributeResultOperator op, Boolean showDetails) {
    stringBuilder.setLength(0);
    stringBuilder.append("distribute result ");
    printExprList(op.getExpressions());
    appendSchema(op, showDetails);
    appendAnnotations(op, showDetails);
    appendPhysicalOperatorInfo(op, showDetails);
    return stringBuilder.toString();
}
#end_block

#method_before
@Override
public String visitWriteResultOperator(WriteResultOperator op, Void noArgs) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("load ").append(str(op.getDataSource())).append(" from ").append(op.getPayloadExpression().getValue().toString()).append(" partitioned by ");
    printExprList(op.getKeyExpressions());
    appendSchema(op);
    appendAnnotations(op);
    appendPhysicalOperatorInfo(op);
    return stringBuilder.toString();
}
#method_after
@Override
public String visitWriteResultOperator(WriteResultOperator op, Boolean showDetails) {
    stringBuilder.setLength(0);
    stringBuilder.append("load ").append(str(op.getDataSource())).append(" from ").append(op.getPayloadExpression().getValue().toString()).append(" partitioned by ");
    printExprList(op.getKeyExpressions());
    appendSchema(op, showDetails);
    appendAnnotations(op, showDetails);
    appendPhysicalOperatorInfo(op, showDetails);
    return stringBuilder.toString();
}
#end_block

#method_before
@Override
public String visitSelectOperator(SelectOperator op, Void noArgs) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("select (").append(op.getCondition().getValue().toString()).append(")");
    appendSchema(op);
    appendAnnotations(op);
    appendPhysicalOperatorInfo(op);
    return stringBuilder.toString();
}
#method_after
@Override
public String visitSelectOperator(SelectOperator op, Boolean showDetails) {
    stringBuilder.setLength(0);
    stringBuilder.append("select (").append(op.getCondition().getValue().toString()).append(")");
    appendSchema(op, showDetails);
    appendAnnotations(op, showDetails);
    appendPhysicalOperatorInfo(op, showDetails);
    return stringBuilder.toString();
}
#end_block

#method_before
@Override
public String visitProjectOperator(ProjectOperator op, Void noArgs) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("project ").append("(").append(op.getVariables()).append(")");
    appendSchema(op);
    appendAnnotations(op);
    appendPhysicalOperatorInfo(op);
    return stringBuilder.toString();
}
#method_after
@Override
public String visitProjectOperator(ProjectOperator op, Boolean showDetails) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("project ").append("(").append(op.getVariables()).append(")");
    appendSchema(op, showDetails);
    appendAnnotations(op, showDetails);
    appendPhysicalOperatorInfo(op, showDetails);
    return stringBuilder.toString();
}
#end_block

#method_before
@Override
public String visitSubplanOperator(SubplanOperator op, Void noArgs) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("subplan {}");
    appendSchema(op);
    appendAnnotations(op);
    appendPhysicalOperatorInfo(op);
    return stringBuilder.toString();
}
#method_after
@Override
public String visitSubplanOperator(SubplanOperator op, Boolean showDetails) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("subplan {}");
    appendSchema(op, showDetails);
    appendAnnotations(op, showDetails);
    appendPhysicalOperatorInfo(op, showDetails);
    return stringBuilder.toString();
}
#end_block

#method_before
@Override
public String visitUnionOperator(UnionAllOperator op, Void noArgs) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("union");
    for (Triple<LogicalVariable, LogicalVariable, LogicalVariable> v : op.getVariableMappings()) {
        stringBuilder.append(" (").append(v.first).append(", ").append(v.second).append(", ").append(v.third).append(")");
    }
    appendSchema(op);
    appendAnnotations(op);
    appendPhysicalOperatorInfo(op);
    return stringBuilder.toString();
}
#method_after
@Override
public String visitUnionOperator(UnionAllOperator op, Boolean showDetails) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("union");
    for (Triple<LogicalVariable, LogicalVariable, LogicalVariable> v : op.getVariableMappings()) {
        stringBuilder.append(" (").append(v.first).append(", ").append(v.second).append(", ").append(v.third).append(")");
    }
    appendSchema(op, showDetails);
    appendAnnotations(op, showDetails);
    appendPhysicalOperatorInfo(op, showDetails);
    return stringBuilder.toString();
}
#end_block

#method_before
@Override
public String visitIntersectOperator(IntersectOperator op, Void noArgs) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("intersect (");
    stringBuilder.append('[');
    for (int i = 0; i < op.getOutputVars().size(); i++) {
        if (i > 0) {
            stringBuilder.append(", ");
        }
        stringBuilder.append(str(op.getOutputVars().get(i)));
    }
    stringBuilder.append("] <- [");
    for (int i = 0; i < op.getNumInput(); i++) {
        if (i > 0) {
            stringBuilder.append(", ");
        }
        stringBuilder.append('[');
        for (int j = 0; j < op.getInputVariables(i).size(); j++) {
            if (j > 0) {
                stringBuilder.append(", ");
            }
            stringBuilder.append(str(op.getInputVariables(i).get(j)));
        }
        stringBuilder.append(']');
    }
    stringBuilder.append("])");
    appendSchema(op);
    appendAnnotations(op);
    appendPhysicalOperatorInfo(op);
    return stringBuilder.toString();
}
#method_after
@Override
public String visitIntersectOperator(IntersectOperator op, Boolean showDetails) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("intersect (");
    stringBuilder.append('[');
    for (int i = 0; i < op.getOutputVars().size(); i++) {
        if (i > 0) {
            stringBuilder.append(", ");
        }
        stringBuilder.append(str(op.getOutputVars().get(i)));
    }
    stringBuilder.append("] <- [");
    for (int i = 0; i < op.getNumInput(); i++) {
        if (i > 0) {
            stringBuilder.append(", ");
        }
        stringBuilder.append('[');
        for (int j = 0; j < op.getInputVariables(i).size(); j++) {
            if (j > 0) {
                stringBuilder.append(", ");
            }
            stringBuilder.append(str(op.getInputVariables(i).get(j)));
        }
        stringBuilder.append(']');
    }
    stringBuilder.append("])");
    appendSchema(op, showDetails);
    appendAnnotations(op, showDetails);
    appendPhysicalOperatorInfo(op, showDetails);
    return stringBuilder.toString();
}
#end_block

#method_before
@Override
public String visitUnnestOperator(UnnestOperator op, Void noArgs) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("unnest ").append(op.getVariable());
    if (op.getPositionalVariable() != null) {
        stringBuilder.append(" at ").append(op.getPositionalVariable());
    }
    stringBuilder.append(" <- ").append(op.getExpressionRef().getValue().toString());
    appendSchema(op);
    appendAnnotations(op);
    appendPhysicalOperatorInfo(op);
    return stringBuilder.toString();
}
#method_after
@Override
public String visitUnnestOperator(UnnestOperator op, Boolean showDetails) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("unnest ").append(op.getVariable());
    if (op.getPositionalVariable() != null) {
        stringBuilder.append(" at ").append(op.getPositionalVariable());
    }
    stringBuilder.append(" <- ").append(op.getExpressionRef().getValue().toString());
    appendSchema(op, showDetails);
    appendAnnotations(op, showDetails);
    appendPhysicalOperatorInfo(op, showDetails);
    return stringBuilder.toString();
}
#end_block

#method_before
@Override
public String visitLeftOuterUnnestOperator(LeftOuterUnnestOperator op, Void noArgs) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("outer-unnest ").append(op.getVariable());
    if (op.getPositionalVariable() != null) {
        stringBuilder.append(" at ").append(op.getPositionalVariable());
    }
    stringBuilder.append(" <- ").append(op.getExpressionRef().getValue().toString());
    appendSchema(op);
    appendAnnotations(op);
    appendPhysicalOperatorInfo(op);
    return stringBuilder.toString();
}
#method_after
@Override
public String visitLeftOuterUnnestOperator(LeftOuterUnnestOperator op, Boolean showDetails) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("outer-unnest ").append(op.getVariable());
    if (op.getPositionalVariable() != null) {
        stringBuilder.append(" at ").append(op.getPositionalVariable());
    }
    stringBuilder.append(" <- ").append(op.getExpressionRef().getValue().toString());
    appendSchema(op, showDetails);
    appendAnnotations(op, showDetails);
    appendPhysicalOperatorInfo(op, showDetails);
    return stringBuilder.toString();
}
#end_block

#method_before
@Override
public String visitUnnestMapOperator(UnnestMapOperator op, Void noArgs) throws AlgebricksException {
    stringBuilder.setLength(0);
    return printAbstractUnnestMapOperator(op, "unnest-map");
}
#method_after
@Override
public String visitUnnestMapOperator(UnnestMapOperator op, Boolean showDetails) throws AlgebricksException {
    stringBuilder.setLength(0);
    printAbstractUnnestMapOperator(op, "unnest-map", showDetails);
    appendSelectConditionInformation(op.getSelectCondition());
    appendLimitInformation(op.getOutputLimit());
    return stringBuilder.toString();
}
#end_block

#method_before
@Override
public String visitLeftOuterUnnestMapOperator(LeftOuterUnnestMapOperator op, Void noArgs) throws AlgebricksException {
    stringBuilder.setLength(0);
    return printAbstractUnnestMapOperator(op, "left-outer-unnest-map");
}
#method_after
@Override
public String visitLeftOuterUnnestMapOperator(LeftOuterUnnestMapOperator op, Boolean showDetails) throws AlgebricksException {
    stringBuilder.setLength(0);
    printAbstractUnnestMapOperator(op, "left-outer-unnest-map", showDetails);
    return stringBuilder.toString();
}
#end_block

#method_before
private String printAbstractUnnestMapOperator(AbstractUnnestMapOperator op, String opSignature) {
    stringBuilder.append(opSignature).append(" ").append(op.getVariables()).append(" <- ").append(op.getExpressionRef().getValue().toString());
    appendFilterInformation(stringBuilder, op.getMinFilterVars(), op.getMaxFilterVars());
    appendSchema(op);
    appendAnnotations(op);
    appendPhysicalOperatorInfo(op);
    return stringBuilder.toString();
}
#method_after
private void printAbstractUnnestMapOperator(AbstractUnnestMapOperator op, String opSignature, boolean show) {
    stringBuilder.append(opSignature).append(" ").append(op.getVariables()).append(" <- ").append(op.getExpressionRef().getValue().toString());
    appendFilterInformation(op.getMinFilterVars(), op.getMaxFilterVars());
    appendSchema(op, show);
    appendAnnotations(op, show);
    appendPhysicalOperatorInfo(op, show);
}
#end_block

#method_before
@Override
public String visitDataScanOperator(DataSourceScanOperator op, Void noArgs) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("data-scan ").append(op.getProjectVariables()).append("<-").append(op.getVariables()).append(" <- ").append(op.getDataSource());
    appendFilterInformation(stringBuilder, op.getMinFilterVars(), op.getMaxFilterVars());
    appendSchema(op);
    appendAnnotations(op);
    appendPhysicalOperatorInfo(op);
    return stringBuilder.toString();
}
#method_after
@Override
public String visitDataScanOperator(DataSourceScanOperator op, Boolean showDetails) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("data-scan ").append(op.getProjectVariables()).append("<-").append(op.getVariables()).append(" <- ").append(op.getDataSource());
    appendFilterInformation(op.getMinFilterVars(), op.getMaxFilterVars());
    appendSelectConditionInformation(op.getSelectCondition());
    appendLimitInformation(op.getOutputLimit());
    appendSchema(op, showDetails);
    appendAnnotations(op, showDetails);
    appendPhysicalOperatorInfo(op, showDetails);
    return stringBuilder.toString();
}
#end_block

#method_before
private String appendFilterInformation(StringBuilder plan, List<LogicalVariable> minFilterVars, List<LogicalVariable> maxFilterVars) {
    if (minFilterVars != null || maxFilterVars != null) {
        plan.append(" with filter on");
    }
    if (minFilterVars != null) {
        plan.append(" min:").append(minFilterVars);
    }
    if (maxFilterVars != null) {
        plan.append(" max:").append(maxFilterVars);
    }
    return stringBuilder.toString();
}
#method_after
private void appendFilterInformation(List<LogicalVariable> minFilterVars, List<LogicalVariable> maxFilterVars) {
    if (minFilterVars != null || maxFilterVars != null) {
        stringBuilder.append(" with filter on");
    }
    if (minFilterVars != null) {
        stringBuilder.append(" min:").append(minFilterVars);
    }
    if (maxFilterVars != null) {
        stringBuilder.append(" max:").append(maxFilterVars);
    }
}
#end_block

#method_before
@Override
public String visitLimitOperator(LimitOperator op, Void noArgs) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("limit ").append(op.getMaxObjects().getValue().toString());
    ILogicalExpression offset = op.getOffset().getValue();
    if (offset != null) {
        stringBuilder.append(", ").append(offset.toString());
    }
    appendSchema(op);
    appendAnnotations(op);
    appendPhysicalOperatorInfo(op);
    return stringBuilder.toString();
}
#method_after
@Override
public String visitLimitOperator(LimitOperator op, Boolean showDetails) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("limit ").append(op.getMaxObjects().getValue().toString());
    ILogicalExpression offset = op.getOffset().getValue();
    if (offset != null) {
        stringBuilder.append(", ").append(offset.toString());
    }
    appendSchema(op, showDetails);
    appendAnnotations(op, showDetails);
    appendPhysicalOperatorInfo(op, showDetails);
    return stringBuilder.toString();
}
#end_block

#method_before
@Override
public String visitExchangeOperator(ExchangeOperator op, Void noArgs) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("exchange");
    appendSchema(op);
    appendAnnotations(op);
    appendPhysicalOperatorInfo(op);
    return stringBuilder.toString();
}
#method_after
@Override
public String visitExchangeOperator(ExchangeOperator op, Boolean showDetails) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("exchange");
    appendSchema(op, showDetails);
    appendAnnotations(op, showDetails);
    appendPhysicalOperatorInfo(op, showDetails);
    return stringBuilder.toString();
}
#end_block

#method_before
@Override
public String visitScriptOperator(ScriptOperator op, Void noArgs) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("script (in: ").append(op.getInputVariables()).append(") (out: ").append(op.getOutputVariables()).append(")");
    appendSchema(op);
    appendAnnotations(op);
    appendPhysicalOperatorInfo(op);
    return stringBuilder.toString();
}
#method_after
@Override
public String visitScriptOperator(ScriptOperator op, Boolean showDetails) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("script (in: ").append(op.getInputVariables()).append(") (out: ").append(op.getOutputVariables()).append(")");
    appendSchema(op, showDetails);
    appendAnnotations(op, showDetails);
    appendPhysicalOperatorInfo(op, showDetails);
    return stringBuilder.toString();
}
#end_block

#method_before
@Override
public String visitReplicateOperator(ReplicateOperator op, Void noArgs) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("replicate");
    appendSchema(op);
    appendAnnotations(op);
    appendPhysicalOperatorInfo(op);
    return stringBuilder.toString();
}
#method_after
@Override
public String visitReplicateOperator(ReplicateOperator op, Boolean showDetails) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("replicate");
    appendSchema(op, showDetails);
    appendAnnotations(op, showDetails);
    appendPhysicalOperatorInfo(op, showDetails);
    return stringBuilder.toString();
}
#end_block

#method_before
@Override
public String visitSplitOperator(SplitOperator op, Void noArgs) throws AlgebricksException {
    stringBuilder.setLength(0);
    Mutable<ILogicalExpression> branchingExpression = op.getBranchingExpression();
    stringBuilder.append("split ").append(branchingExpression.getValue().toString());
    appendSchema(op);
    appendAnnotations(op);
    appendPhysicalOperatorInfo(op);
    return stringBuilder.toString();
}
#method_after
@Override
public String visitSplitOperator(SplitOperator op, Boolean showDetails) throws AlgebricksException {
    stringBuilder.setLength(0);
    Mutable<ILogicalExpression> branchingExpression = op.getBranchingExpression();
    stringBuilder.append("split ").append(branchingExpression.getValue().toString());
    appendSchema(op, showDetails);
    appendAnnotations(op, showDetails);
    appendPhysicalOperatorInfo(op, showDetails);
    return stringBuilder.toString();
}
#end_block

#method_before
@Override
public String visitMaterializeOperator(MaterializeOperator op, Void noArgs) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("materialize");
    appendSchema(op);
    appendAnnotations(op);
    appendPhysicalOperatorInfo(op);
    return stringBuilder.toString();
}
#method_after
@Override
public String visitMaterializeOperator(MaterializeOperator op, Boolean showDetails) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("materialize");
    appendSchema(op, showDetails);
    appendAnnotations(op, showDetails);
    appendPhysicalOperatorInfo(op, showDetails);
    return stringBuilder.toString();
}
#end_block

#method_before
@Override
public String visitInsertDeleteUpsertOperator(InsertDeleteUpsertOperator op, Void noArgs) throws AlgebricksException {
    stringBuilder.setLength(0);
    String header = getIndexOpString(op.getOperation());
    stringBuilder.append(header).append(str(op.getDataSource())).append(" from record: ").append(op.getPayloadExpression().getValue().toString());
    if (op.getAdditionalNonFilteringExpressions() != null) {
        stringBuilder.append(", meta: ");
        printExprList(op.getAdditionalNonFilteringExpressions());
    }
    stringBuilder.append(" partitioned by ");
    printExprList(op.getPrimaryKeyExpressions());
    if (op.getOperation() == Kind.UPSERT) {
        stringBuilder.append(" out: ([record-before-upsert:").append(op.getBeforeOpRecordVar());
        if (op.getBeforeOpAdditionalNonFilteringVars() != null) {
            stringBuilder.append(", additional-before-upsert: ").append(op.getBeforeOpAdditionalNonFilteringVars());
        }
        stringBuilder.append("]) ");
    }
    if (op.isBulkload()) {
        stringBuilder.append(" [bulkload]");
    }
    appendSchema(op);
    appendAnnotations(op);
    appendPhysicalOperatorInfo(op);
    return stringBuilder.toString();
}
#method_after
@Override
public String visitInsertDeleteUpsertOperator(InsertDeleteUpsertOperator op, Boolean showDetails) {
    stringBuilder.setLength(0);
    String header = getIndexOpString(op.getOperation());
    stringBuilder.append(header).append(str(op.getDataSource())).append(" from record: ").append(op.getPayloadExpression().getValue().toString());
    if (op.getAdditionalNonFilteringExpressions() != null) {
        stringBuilder.append(", meta: ");
        printExprList(op.getAdditionalNonFilteringExpressions());
    }
    stringBuilder.append(" partitioned by ");
    printExprList(op.getPrimaryKeyExpressions());
    if (op.getOperation() == Kind.UPSERT) {
        stringBuilder.append(" out: ([record-before-upsert:").append(op.getBeforeOpRecordVar());
        if (op.getBeforeOpAdditionalNonFilteringVars() != null) {
            stringBuilder.append(", additional-before-upsert: ").append(op.getBeforeOpAdditionalNonFilteringVars());
        }
        stringBuilder.append("]) ");
    }
    if (op.isBulkload()) {
        stringBuilder.append(" [bulkload]");
    }
    appendSchema(op, showDetails);
    appendAnnotations(op, showDetails);
    appendPhysicalOperatorInfo(op, showDetails);
    return stringBuilder.toString();
}
#end_block

#method_before
@Override
public String visitIndexInsertDeleteUpsertOperator(IndexInsertDeleteUpsertOperator op, Void noArgs) throws AlgebricksException {
    stringBuilder.setLength(0);
    String header = getIndexOpString(op.getOperation());
    stringBuilder.append(header).append(op.getIndexName()).append(" on ").append(str(op.getDataSourceIndex().getDataSource())).append(" from ");
    if (op.getOperation() == Kind.UPSERT) {
        stringBuilder.append(" replace:");
        printExprList(op.getPrevSecondaryKeyExprs());
        stringBuilder.append(" with:");
        printExprList(op.getSecondaryKeyExpressions());
    } else {
        printExprList(op.getSecondaryKeyExpressions());
    }
    if (op.isBulkload()) {
        stringBuilder.append(" [bulkload]");
    }
    appendSchema(op);
    appendAnnotations(op);
    appendPhysicalOperatorInfo(op);
    return stringBuilder.toString();
}
#method_after
@Override
public String visitIndexInsertDeleteUpsertOperator(IndexInsertDeleteUpsertOperator op, Boolean showDetails) {
    stringBuilder.setLength(0);
    String header = getIndexOpString(op.getOperation());
    stringBuilder.append(header).append(op.getIndexName()).append(" on ").append(str(op.getDataSourceIndex().getDataSource())).append(" from ");
    if (op.getOperation() == Kind.UPSERT) {
        stringBuilder.append(" replace:");
        printExprList(op.getPrevSecondaryKeyExprs());
        stringBuilder.append(" with:");
        printExprList(op.getSecondaryKeyExpressions());
    } else {
        printExprList(op.getSecondaryKeyExpressions());
    }
    if (op.isBulkload()) {
        stringBuilder.append(" [bulkload]");
    }
    appendSchema(op, showDetails);
    appendAnnotations(op, showDetails);
    appendPhysicalOperatorInfo(op, showDetails);
    return stringBuilder.toString();
}
#end_block

#method_before
@Override
public String visitTokenizeOperator(TokenizeOperator op, Void noArgs) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("tokenize ").append(str(op.getTokenizeVars())).append(" <- ");
    printExprList(op.getSecondaryKeyExpressions());
    appendSchema(op);
    appendAnnotations(op);
    appendPhysicalOperatorInfo(op);
    return stringBuilder.toString();
}
#method_after
@Override
public String visitTokenizeOperator(TokenizeOperator op, Boolean showDetails) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("tokenize ").append(str(op.getTokenizeVars())).append(" <- ");
    printExprList(op.getSecondaryKeyExpressions());
    appendSchema(op, showDetails);
    appendAnnotations(op, showDetails);
    appendPhysicalOperatorInfo(op, showDetails);
    return stringBuilder.toString();
}
#end_block

#method_before
@Override
public String visitSinkOperator(SinkOperator op, Void noArgs) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("sink");
    appendSchema(op);
    appendAnnotations(op);
    appendPhysicalOperatorInfo(op);
    return stringBuilder.toString();
}
#method_after
@Override
public String visitSinkOperator(SinkOperator op, Boolean showDetails) {
    stringBuilder.setLength(0);
    stringBuilder.append("sink");
    appendSchema(op, showDetails);
    appendAnnotations(op, showDetails);
    appendPhysicalOperatorInfo(op, showDetails);
    return stringBuilder.toString();
}
#end_block

#method_before
@Override
public String visitDelegateOperator(DelegateOperator op, Void noArgs) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append(op.toString());
    appendSchema(op);
    appendAnnotations(op);
    appendPhysicalOperatorInfo(op);
    return stringBuilder.toString();
}
#method_after
@Override
public String visitDelegateOperator(DelegateOperator op, Boolean showDetails) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append(op.toString());
    appendSchema(op, showDetails);
    appendAnnotations(op, showDetails);
    appendPhysicalOperatorInfo(op, showDetails);
    return stringBuilder.toString();
}
#end_block

#method_before
@Override
public String visitForwardOperator(ForwardOperator op, Void arg) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("forward");
    appendSchema(op);
    appendAnnotations(op);
    appendPhysicalOperatorInfo(op);
    return stringBuilder.toString();
}
#method_after
@Override
public String visitForwardOperator(ForwardOperator op, Boolean showDetails) throws AlgebricksException {
    stringBuilder.setLength(0);
    stringBuilder.append("forward(").append(op.getRangeMapExpression().getValue().toString()).append(")");
    appendSchema(op, showDetails);
    appendAnnotations(op, showDetails);
    appendPhysicalOperatorInfo(op, showDetails);
    return stringBuilder.toString();
}
#end_block

#method_before
private void appendSchema(AbstractLogicalOperator op) {
    stringBuilder.append("\\nSchema: ");
    final List<LogicalVariable> schema = op.getSchema();
    stringBuilder.append(schema == null ? "null" : schema);
}
#method_after
private void appendSchema(AbstractLogicalOperator op, boolean show) {
    if (show) {
        stringBuilder.append("\\nSchema: ");
        final List<LogicalVariable> schema = op.getSchema();
        stringBuilder.append(schema == null ? "null" : schema);
    }
}
#end_block

#method_before
private void appendAnnotations(AbstractLogicalOperator op) {
    final Map<String, Object> annotations = op.getAnnotations();
    if (!annotations.isEmpty()) {
        stringBuilder.append("\\nAnnotations: ").append(annotations);
    }
}
#method_after
private void appendAnnotations(AbstractLogicalOperator op, boolean show) {
    if (show) {
        final Map<String, Object> annotations = op.getAnnotations();
        if (!annotations.isEmpty()) {
            stringBuilder.append("\\nAnnotations: ").append(annotations);
        }
    }
}
#end_block

#method_before
private void appendPhysicalOperatorInfo(AbstractLogicalOperator op) {
    IPhysicalOperator physicalOperator = op.getPhysicalOperator();
    stringBuilder.append("\\n Phys Op: ");
    stringBuilder.append(physicalOperator == null ? "null" : physicalOperator.toString().trim());
    stringBuilder.append(", Exec. Mode: ").append(op.getExecutionMode());
    if (physicalOperator != null) {
        IPhysicalPropertiesVector deliveredProperties = physicalOperator.getDeliveredProperties();
        if (deliveredProperties != null) {
            List<ILocalStructuralProperty> localProperties = deliveredProperties.getLocalProperties();
            if (localProperties != null) {
                stringBuilder.append("\\nProperties in each partition: [");
                for (ILocalStructuralProperty property : localProperties) {
                    if (property == null) {
                        stringBuilder.append("null, ");
                    } else if (property.getPropertyType() == LOCAL_ORDER_PROPERTY) {
                        stringBuilder.append("ordered by ");
                    } else if (property.getPropertyType() == LOCAL_GROUPING_PROPERTY) {
                        stringBuilder.append("group by ");
                    }
                    stringBuilder.append(property).append(", ");
                }
                stringBuilder.append("]");
            }
            IPartitioningProperty partitioningProperty = deliveredProperties.getPartitioningProperty();
            if (partitioningProperty != null) {
                stringBuilder.append("\\n").append(partitioningProperty.getPartitioningType()).append(":");
                INodeDomain nodeDomain = partitioningProperty.getNodeDomain();
                stringBuilder.append("\\n ");
                if (nodeDomain != null && nodeDomain.cardinality() != null) {
                    stringBuilder.append(nodeDomain.cardinality()).append(" partitions. ");
                }
                switch(partitioningProperty.getPartitioningType()) {
                    case BROADCAST:
                        stringBuilder.append("Data is replicated across partitions.");
                        break;
                    case RANDOM:
                        stringBuilder.append("Data is randomly partitioned.");
                        break;
                    case ORDERED_PARTITIONED:
                        stringBuilder.append("Data is orderly partitioned via a range.");
                        break;
                    case UNORDERED_PARTITIONED:
                        stringBuilder.append("Data is hash partitioned.");
                        break;
                    case UNPARTITIONED:
                        stringBuilder.append("Data is in one place.");
                }
                if (nodeDomain instanceof DefaultNodeGroupDomain) {
                    DefaultNodeGroupDomain nd = (DefaultNodeGroupDomain) nodeDomain;
                    stringBuilder.append("\\n").append(nd);
                }
            }
        }
    }
}
#method_after
private void appendPhysicalOperatorInfo(AbstractLogicalOperator op, boolean show) {
    IPhysicalOperator physicalOp = op.getPhysicalOperator();
    stringBuilder.append("\\n").append(physicalOp == null ? "null" : physicalOp.toString().trim());
    stringBuilder.append(", Exec: ").append(op.getExecutionMode());
    if (show) {
        IPhysicalPropertiesVector properties = physicalOp == null ? null : physicalOp.getDeliveredProperties();
        List<ILocalStructuralProperty> localProp = properties == null ? null : properties.getLocalProperties();
        IPartitioningProperty partitioningProp = properties == null ? null : properties.getPartitioningProperty();
        if (localProp != null) {
            stringBuilder.append("\\nProperties in each partition: [");
            for (ILocalStructuralProperty property : localProp) {
                if (property == null) {
                    stringBuilder.append("null, ");
                } else if (property.getPropertyType() == LOCAL_ORDER_PROPERTY) {
                    stringBuilder.append("ordered by ");
                } else if (property.getPropertyType() == LOCAL_GROUPING_PROPERTY) {
                    stringBuilder.append("group by ");
                }
                stringBuilder.append(property).append(", ");
            }
            stringBuilder.append("]");
        }
        if (partitioningProp != null) {
            stringBuilder.append("\\n").append(partitioningProp.getPartitioningType()).append(":");
            INodeDomain nodeDomain = partitioningProp.getNodeDomain();
            stringBuilder.append("\\n ");
            if (nodeDomain != null && nodeDomain.cardinality() != null) {
                stringBuilder.append(nodeDomain.cardinality()).append(" partitions. ");
            }
            switch(partitioningProp.getPartitioningType()) {
                case BROADCAST:
                    stringBuilder.append("Data is broadcast to partitions.");
                    break;
                case RANDOM:
                    stringBuilder.append("Data is randomly partitioned.");
                    break;
                case ORDERED_PARTITIONED:
                    stringBuilder.append("Data is orderly partitioned via a range.");
                    break;
                case UNORDERED_PARTITIONED:
                    stringBuilder.append("Data is hash partitioned.");
                    break;
                case UNPARTITIONED:
                    stringBuilder.append("Data is in one place.");
            }
            if (nodeDomain instanceof DefaultNodeGroupDomain) {
                DefaultNodeGroupDomain nd = (DefaultNodeGroupDomain) nodeDomain;
                stringBuilder.append("\\n").append(nd);
            }
        }
    }
}
#end_block

#method_before
@Override
public ILogicalOperator visitGroupByOperator(GroupByOperator op, Void arg) throws AlgebricksException {
    visitSingleInputOperator(op);
    Set<LogicalVariable> groupKeyVars = new HashSet<>();
    // VariableReferenceExpressions.
    for (Pair<LogicalVariable, Mutable<ILogicalExpression>> keyVarExprRef : op.getGroupByList()) {
        ILogicalExpression expr = keyVarExprRef.second.getValue();
        if (expr.getExpressionTag() == LogicalExpressionTag.VARIABLE) {
            VariableReferenceExpression varExpr = (VariableReferenceExpression) expr;
            LogicalVariable sourceVar = varExpr.getVariableReference();
            updateInputToOutputVarMapping(sourceVar, keyVarExprRef.first, false);
            groupKeyVars.add(keyVarExprRef.first);
        }
    }
    // Add correlated key variables into group-by keys.
    Map<LogicalVariable, LogicalVariable> addedGroupKeyMapping = new HashMap<>();
    for (LogicalVariable keyVar : correlatedKeyVars) {
        if (!groupKeyVars.contains(keyVar)) {
            LogicalVariable newVar = context.newVar();
            op.getGroupByList().add(new Pair<>(newVar, new MutableObject<>(new VariableReferenceExpression(keyVar))));
            addedGroupKeyMapping.put(keyVar, newVar);
        }
    }
    // Updates decor list.
    Iterator<Pair<LogicalVariable, Mutable<ILogicalExpression>>> decorExprIter = op.getDecorList().iterator();
    while (decorExprIter.hasNext()) {
        ILogicalExpression expr = decorExprIter.next().second.getValue();
        if (expr.getExpressionTag() == LogicalExpressionTag.VARIABLE) {
            VariableReferenceExpression varExpr = (VariableReferenceExpression) expr;
            if (correlatedKeyVars.contains(varExpr.getVariableReference())) {
                decorExprIter.remove();
            }
        }
    }
    // Updates the var mapping for added group-by keys.
    addedGroupKeyMapping.forEach((key, value) -> updateInputToOutputVarMapping(key, value, false));
    return op;
}
#method_after
@Override
public ILogicalOperator visitGroupByOperator(GroupByOperator op, Void arg) throws AlgebricksException {
    visitSingleInputOperator(op);
    Set<LogicalVariable> groupKeyVars = new HashSet<>();
    // VariableReferenceExpressions.
    for (Pair<LogicalVariable, Mutable<ILogicalExpression>> keyVarExprRef : op.getGroupByList()) {
        ILogicalExpression expr = keyVarExprRef.second.getValue();
        if (expr.getExpressionTag() == LogicalExpressionTag.VARIABLE) {
            VariableReferenceExpression varExpr = (VariableReferenceExpression) expr;
            LogicalVariable sourceVar = varExpr.getVariableReference();
            updateInputToOutputVarMapping(sourceVar, keyVarExprRef.first, false);
            groupKeyVars.add(keyVarExprRef.first);
        }
    }
    // Add correlated key variables into group-by keys.
    Map<LogicalVariable, LogicalVariable> addedGroupKeyMapping = new HashMap<>();
    for (LogicalVariable keyVar : correlatedKeyVars) {
        if (!groupKeyVars.contains(keyVar)) {
            LogicalVariable newVar = context.newVar();
            VariableReferenceExpression keyVarRef = new VariableReferenceExpression(keyVar);
            keyVarRef.setSourceLocation(op.getSourceLocation());
            op.getGroupByList().add(new Pair<>(newVar, new MutableObject<>(keyVarRef)));
            addedGroupKeyMapping.put(keyVar, newVar);
        }
    }
    // Updates decor list.
    Iterator<Pair<LogicalVariable, Mutable<ILogicalExpression>>> decorExprIter = op.getDecorList().iterator();
    while (decorExprIter.hasNext()) {
        ILogicalExpression expr = decorExprIter.next().second.getValue();
        if (expr.getExpressionTag() == LogicalExpressionTag.VARIABLE) {
            VariableReferenceExpression varExpr = (VariableReferenceExpression) expr;
            if (correlatedKeyVars.contains(varExpr.getVariableReference())) {
                decorExprIter.remove();
            }
        }
    }
    // Updates the var mapping for added group-by keys.
    addedGroupKeyMapping.forEach((key, value) -> updateInputToOutputVarMapping(key, value, false));
    return op;
}
#end_block

#method_before
@Override
public ILogicalOperator visitLimitOperator(LimitOperator op, Void arg) throws AlgebricksException {
    // Processes its input operator.
    visitSingleInputOperator(op);
    if (correlatedKeyVars.isEmpty()) {
        return op;
    }
    // Get live variables before limit.
    Set<LogicalVariable> inputLiveVars = new HashSet<LogicalVariable>();
    VariableUtilities.getSubplanLocalLiveVariables(op.getInputs().get(0).getValue(), inputLiveVars);
    // Creates a record construction assign operator.
    Pair<ILogicalOperator, LogicalVariable> assignOpAndRecordVar = createRecordConstructorAssignOp(inputLiveVars);
    ILogicalOperator assignOp = assignOpAndRecordVar.first;
    LogicalVariable recordVar = assignOpAndRecordVar.second;
    ILogicalOperator inputOp = op.getInputs().get(0).getValue();
    assignOp.getInputs().add(new MutableObject<>(inputOp));
    // Rewrites limit to a group-by with limit as its nested operator.
    Pair<ILogicalOperator, LogicalVariable> gbyOpAndAggVar = wrapLimitInGroupBy(op, recordVar, inputLiveVars);
    ILogicalOperator gbyOp = gbyOpAndAggVar.first;
    LogicalVariable aggVar = gbyOpAndAggVar.second;
    gbyOp.getInputs().add(new MutableObject<>(assignOp));
    // Adds an unnest operators on top of the group-by operator.
    Pair<ILogicalOperator, LogicalVariable> unnestOpAndUnnestVar = createUnnestForAggregatedList(aggVar);
    ILogicalOperator unnestOp = unnestOpAndUnnestVar.first;
    LogicalVariable unnestVar = unnestOpAndUnnestVar.second;
    unnestOp.getInputs().add(new MutableObject<>(gbyOp));
    // Adds field accesses to recover input live variables.
    ILogicalOperator fieldAccessAssignOp = createFieldAccessAssignOperator(unnestVar, inputLiveVars);
    fieldAccessAssignOp.getInputs().add(new MutableObject<>(unnestOp));
    OperatorManipulationUtil.computeTypeEnvironmentBottomUp(fieldAccessAssignOp, context);
    return fieldAccessAssignOp;
}
#method_after
@Override
public ILogicalOperator visitLimitOperator(LimitOperator op, Void arg) throws AlgebricksException {
    // Processes its input operator.
    visitSingleInputOperator(op);
    if (correlatedKeyVars.isEmpty()) {
        return op;
    }
    // Get live variables before limit.
    Set<LogicalVariable> inputLiveVars = new HashSet<LogicalVariable>();
    VariableUtilities.getSubplanLocalLiveVariables(op.getInputs().get(0).getValue(), inputLiveVars);
    // Creates a record construction assign operator.
    Pair<ILogicalOperator, LogicalVariable> assignOpAndRecordVar = createRecordConstructorAssignOp(inputLiveVars, op.getSourceLocation());
    ILogicalOperator assignOp = assignOpAndRecordVar.first;
    LogicalVariable recordVar = assignOpAndRecordVar.second;
    ILogicalOperator inputOp = op.getInputs().get(0).getValue();
    assignOp.getInputs().add(new MutableObject<>(inputOp));
    // Rewrites limit to a group-by with limit as its nested operator.
    Pair<ILogicalOperator, LogicalVariable> gbyOpAndAggVar = wrapLimitInGroupBy(op, recordVar, inputLiveVars);
    ILogicalOperator gbyOp = gbyOpAndAggVar.first;
    LogicalVariable aggVar = gbyOpAndAggVar.second;
    gbyOp.getInputs().add(new MutableObject<>(assignOp));
    // Adds an unnest operators on top of the group-by operator.
    Pair<ILogicalOperator, LogicalVariable> unnestOpAndUnnestVar = createUnnestForAggregatedList(aggVar, op.getSourceLocation());
    ILogicalOperator unnestOp = unnestOpAndUnnestVar.first;
    LogicalVariable unnestVar = unnestOpAndUnnestVar.second;
    unnestOp.getInputs().add(new MutableObject<>(gbyOp));
    // Adds field accesses to recover input live variables.
    ILogicalOperator fieldAccessAssignOp = createFieldAccessAssignOperator(unnestVar, inputLiveVars, op.getSourceLocation());
    fieldAccessAssignOp.getInputs().add(new MutableObject<>(unnestOp));
    OperatorManipulationUtil.computeTypeEnvironmentBottomUp(fieldAccessAssignOp, context);
    return fieldAccessAssignOp;
}
#end_block

#method_before
private Pair<ILogicalOperator, LogicalVariable> createRecordConstructorAssignOp(Set<LogicalVariable> inputLiveVars) {
    // Creates a nested record.
    List<Mutable<ILogicalExpression>> recordConstructorArgs = new ArrayList<>();
    for (LogicalVariable inputLiveVar : inputLiveVars) {
        if (!correlatedKeyVars.contains(inputLiveVar)) {
            recordConstructorArgs.add(new MutableObject<>(new ConstantExpression(new AsterixConstantValue(new AString(Integer.toString(inputLiveVar.getId()))))));
            recordConstructorArgs.add(new MutableObject<>(new VariableReferenceExpression(inputLiveVar)));
        }
    }
    LogicalVariable recordVar = context.newVar();
    Mutable<ILogicalExpression> recordExprRef = new MutableObject<ILogicalExpression>(new ScalarFunctionCallExpression(FunctionUtil.getFunctionInfo(BuiltinFunctions.OPEN_RECORD_CONSTRUCTOR), recordConstructorArgs));
    AssignOperator assignOp = new AssignOperator(recordVar, recordExprRef);
    return new Pair<>(assignOp, recordVar);
}
#method_after
private Pair<ILogicalOperator, LogicalVariable> createRecordConstructorAssignOp(Set<LogicalVariable> inputLiveVars, SourceLocation sourceLoc) {
    // Creates a nested record.
    List<Mutable<ILogicalExpression>> recordConstructorArgs = new ArrayList<>();
    for (LogicalVariable inputLiveVar : inputLiveVars) {
        if (!correlatedKeyVars.contains(inputLiveVar)) {
            recordConstructorArgs.add(new MutableObject<>(new ConstantExpression(new AsterixConstantValue(new AString(Integer.toString(inputLiveVar.getId()))))));
            VariableReferenceExpression inputLiveVarRef = new VariableReferenceExpression(inputLiveVar);
            inputLiveVarRef.setSourceLocation(sourceLoc);
            recordConstructorArgs.add(new MutableObject<>(inputLiveVarRef));
        }
    }
    LogicalVariable recordVar = context.newVar();
    ScalarFunctionCallExpression openRecConstr = new ScalarFunctionCallExpression(FunctionUtil.getFunctionInfo(BuiltinFunctions.OPEN_RECORD_CONSTRUCTOR), recordConstructorArgs);
    openRecConstr.setSourceLocation(sourceLoc);
    Mutable<ILogicalExpression> recordExprRef = new MutableObject<ILogicalExpression>(openRecConstr);
    AssignOperator assignOp = new AssignOperator(recordVar, recordExprRef);
    assignOp.setSourceLocation(sourceLoc);
    return new Pair<>(assignOp, recordVar);
}
#end_block

#method_before
private Pair<ILogicalOperator, LogicalVariable> wrapLimitInGroupBy(ILogicalOperator op, LogicalVariable recordVar, Set<LogicalVariable> inputLiveVars) throws AlgebricksException {
    GroupByOperator gbyOp = new GroupByOperator();
    List<Pair<LogicalVariable, LogicalVariable>> keyVarNewVarPairs = new ArrayList<>();
    for (LogicalVariable keyVar : correlatedKeyVars) {
        // This limits the visitor can only be applied to a nested logical
        // plan inside a Subplan operator,
        // where the keyVarsToEnforce forms a candidate key which can
        // uniquely identify a tuple out of the nested-tuple-source.
        LogicalVariable newVar = context.newVar();
        gbyOp.getGroupByList().add(new Pair<>(newVar, new MutableObject<>(new VariableReferenceExpression(keyVar))));
        keyVarNewVarPairs.add(new Pair<>(keyVar, newVar));
    }
    // Creates an aggregate operator doing LISTIFY, as the root of the
    // nested plan of the added group-by operator.
    List<LogicalVariable> aggVarList = new ArrayList<LogicalVariable>();
    List<Mutable<ILogicalExpression>> aggExprList = new ArrayList<Mutable<ILogicalExpression>>();
    LogicalVariable aggVar = context.newVar();
    List<Mutable<ILogicalExpression>> aggArgList = new ArrayList<>();
    aggVarList.add(aggVar);
    // Creates an aggregation function expression.
    aggArgList.add(new MutableObject<>(new VariableReferenceExpression(recordVar)));
    ILogicalExpression aggExpr = new AggregateFunctionCallExpression(FunctionUtil.getFunctionInfo(BuiltinFunctions.LISTIFY), false, aggArgList);
    aggExprList.add(new MutableObject<>(aggExpr));
    AggregateOperator aggOp = new AggregateOperator(aggVarList, aggExprList);
    // Adds the original limit operator as the input operator to the added
    // aggregate operator.
    aggOp.getInputs().add(new MutableObject<>(op));
    op.getInputs().clear();
    ILogicalOperator currentOp = op;
    if (!orderingExprs.isEmpty()) {
        OrderOperator orderOp = new OrderOperator(cloneOrderingExpression(orderingExprs));
        op.getInputs().add(new MutableObject<>(orderOp));
        currentOp = orderOp;
    }
    // Adds a nested tuple source operator as the input operator to the
    // limit operator.
    NestedTupleSourceOperator nts = new NestedTupleSourceOperator(new MutableObject<>(gbyOp));
    currentOp.getInputs().add(new MutableObject<>(nts));
    // Sets the root of the added nested plan to the aggregate operator.
    ILogicalPlan nestedPlan = new ALogicalPlanImpl();
    nestedPlan.getRoots().add(new MutableObject<>(aggOp));
    // Sets the nested plan for the added group-by operator.
    gbyOp.getNestedPlans().add(nestedPlan);
    // Updates variable mapping for ancestor operators.
    for (Pair<LogicalVariable, LogicalVariable> keyVarNewVar : keyVarNewVarPairs) {
        updateInputToOutputVarMapping(keyVarNewVar.first, keyVarNewVar.second, false);
    }
    return new Pair<>(gbyOp, aggVar);
}
#method_after
private Pair<ILogicalOperator, LogicalVariable> wrapLimitInGroupBy(ILogicalOperator op, LogicalVariable recordVar, Set<LogicalVariable> inputLiveVars) throws AlgebricksException {
    SourceLocation sourceLoc = op.getSourceLocation();
    GroupByOperator gbyOp = new GroupByOperator();
    gbyOp.setSourceLocation(sourceLoc);
    List<Pair<LogicalVariable, LogicalVariable>> keyVarNewVarPairs = new ArrayList<>();
    for (LogicalVariable keyVar : correlatedKeyVars) {
        // This limits the visitor can only be applied to a nested logical
        // plan inside a Subplan operator,
        // where the keyVarsToEnforce forms a candidate key which can
        // uniquely identify a tuple out of the nested-tuple-source.
        LogicalVariable newVar = context.newVar();
        VariableReferenceExpression keyVarRef = new VariableReferenceExpression(keyVar);
        keyVarRef.setSourceLocation(sourceLoc);
        gbyOp.getGroupByList().add(new Pair<>(newVar, new MutableObject<>(keyVarRef)));
        keyVarNewVarPairs.add(new Pair<>(keyVar, newVar));
    }
    // Creates an aggregate operator doing LISTIFY, as the root of the
    // nested plan of the added group-by operator.
    List<LogicalVariable> aggVarList = new ArrayList<LogicalVariable>();
    List<Mutable<ILogicalExpression>> aggExprList = new ArrayList<Mutable<ILogicalExpression>>();
    LogicalVariable aggVar = context.newVar();
    List<Mutable<ILogicalExpression>> aggArgList = new ArrayList<>();
    aggVarList.add(aggVar);
    // Creates an aggregation function expression.
    VariableReferenceExpression recordVarRef = new VariableReferenceExpression(recordVar);
    recordVarRef.setSourceLocation(sourceLoc);
    aggArgList.add(new MutableObject<>(recordVarRef));
    AggregateFunctionCallExpression aggExpr = new AggregateFunctionCallExpression(FunctionUtil.getFunctionInfo(BuiltinFunctions.LISTIFY), false, aggArgList);
    aggExpr.setSourceLocation(sourceLoc);
    aggExprList.add(new MutableObject<>(aggExpr));
    AggregateOperator aggOp = new AggregateOperator(aggVarList, aggExprList);
    aggOp.setSourceLocation(sourceLoc);
    // Adds the original limit operator as the input operator to the added
    // aggregate operator.
    aggOp.getInputs().add(new MutableObject<>(op));
    op.getInputs().clear();
    ILogicalOperator currentOp = op;
    if (!orderingExprs.isEmpty()) {
        OrderOperator orderOp = new OrderOperator(cloneOrderingExpression(orderingExprs));
        orderOp.setSourceLocation(sourceLoc);
        op.getInputs().add(new MutableObject<>(orderOp));
        currentOp = orderOp;
    }
    // Adds a nested tuple source operator as the input operator to the
    // limit operator.
    NestedTupleSourceOperator nts = new NestedTupleSourceOperator(new MutableObject<>(gbyOp));
    nts.setSourceLocation(sourceLoc);
    currentOp.getInputs().add(new MutableObject<>(nts));
    // Sets the root of the added nested plan to the aggregate operator.
    ILogicalPlan nestedPlan = new ALogicalPlanImpl();
    nestedPlan.getRoots().add(new MutableObject<>(aggOp));
    // Sets the nested plan for the added group-by operator.
    gbyOp.getNestedPlans().add(nestedPlan);
    // Updates variable mapping for ancestor operators.
    for (Pair<LogicalVariable, LogicalVariable> keyVarNewVar : keyVarNewVarPairs) {
        updateInputToOutputVarMapping(keyVarNewVar.first, keyVarNewVar.second, false);
    }
    return new Pair<>(gbyOp, aggVar);
}
#end_block

#method_before
private Pair<ILogicalOperator, LogicalVariable> createUnnestForAggregatedList(LogicalVariable aggVar) {
    LogicalVariable unnestVar = context.newVar();
    // Creates an unnest function expression.
    Mutable<ILogicalExpression> unnestArg = new MutableObject<>(new VariableReferenceExpression(aggVar));
    List<Mutable<ILogicalExpression>> unnestArgList = new ArrayList<>();
    unnestArgList.add(unnestArg);
    Mutable<ILogicalExpression> unnestExpr = new MutableObject<>(new UnnestingFunctionCallExpression(FunctionUtil.getFunctionInfo(BuiltinFunctions.SCAN_COLLECTION), unnestArgList));
    ILogicalOperator unnestOp = new UnnestOperator(unnestVar, unnestExpr);
    return new Pair<>(unnestOp, unnestVar);
}
#method_after
private Pair<ILogicalOperator, LogicalVariable> createUnnestForAggregatedList(LogicalVariable aggVar, SourceLocation sourceLoc) {
    LogicalVariable unnestVar = context.newVar();
    // Creates an unnest function expression.
    VariableReferenceExpression aggVarRef = new VariableReferenceExpression(aggVar);
    aggVarRef.setSourceLocation(sourceLoc);
    Mutable<ILogicalExpression> unnestArg = new MutableObject<>(aggVarRef);
    List<Mutable<ILogicalExpression>> unnestArgList = new ArrayList<>();
    unnestArgList.add(unnestArg);
    UnnestingFunctionCallExpression unnestExpr = new UnnestingFunctionCallExpression(FunctionUtil.getFunctionInfo(BuiltinFunctions.SCAN_COLLECTION), unnestArgList);
    unnestExpr.setSourceLocation(sourceLoc);
    UnnestOperator unnestOp = new UnnestOperator(unnestVar, new MutableObject<>(unnestExpr));
    unnestOp.setSourceLocation(sourceLoc);
    return new Pair<>(unnestOp, unnestVar);
}
#end_block

#method_before
private ILogicalOperator createFieldAccessAssignOperator(LogicalVariable recordVar, Set<LogicalVariable> inputLiveVars) {
    List<LogicalVariable> fieldAccessVars = new ArrayList<>();
    List<Mutable<ILogicalExpression>> fieldAccessExprs = new ArrayList<>();
    // Adds field access by name.
    for (LogicalVariable inputLiveVar : inputLiveVars) {
        if (!correlatedKeyVars.contains(inputLiveVar)) {
            // field Var
            LogicalVariable newVar = context.newVar();
            fieldAccessVars.add(newVar);
            // fieldAcess expr
            List<Mutable<ILogicalExpression>> argRefs = new ArrayList<>();
            argRefs.add(new MutableObject<>(new VariableReferenceExpression(recordVar)));
            argRefs.add(new MutableObject<>(new ConstantExpression(new AsterixConstantValue(new AString(Integer.toString(inputLiveVar.getId()))))));
            fieldAccessExprs.add(new MutableObject<>(new ScalarFunctionCallExpression(FunctionUtil.getFunctionInfo(BuiltinFunctions.FIELD_ACCESS_BY_NAME), argRefs)));
            // Updates variable mapping for ancestor operators.
            updateInputToOutputVarMapping(inputLiveVar, newVar, false);
        }
    }
    return new AssignOperator(fieldAccessVars, fieldAccessExprs);
}
#method_after
private ILogicalOperator createFieldAccessAssignOperator(LogicalVariable recordVar, Set<LogicalVariable> inputLiveVars, SourceLocation sourceLoc) {
    List<LogicalVariable> fieldAccessVars = new ArrayList<>();
    List<Mutable<ILogicalExpression>> fieldAccessExprs = new ArrayList<>();
    // Adds field access by name.
    for (LogicalVariable inputLiveVar : inputLiveVars) {
        if (!correlatedKeyVars.contains(inputLiveVar)) {
            // field Var
            LogicalVariable newVar = context.newVar();
            fieldAccessVars.add(newVar);
            // fieldAcess expr
            List<Mutable<ILogicalExpression>> argRefs = new ArrayList<>();
            VariableReferenceExpression recordVarRef = new VariableReferenceExpression(recordVar);
            recordVarRef.setSourceLocation(sourceLoc);
            argRefs.add(new MutableObject<>(recordVarRef));
            argRefs.add(new MutableObject<>(new ConstantExpression(new AsterixConstantValue(new AString(Integer.toString(inputLiveVar.getId()))))));
            ScalarFunctionCallExpression faExpr = new ScalarFunctionCallExpression(FunctionUtil.getFunctionInfo(BuiltinFunctions.FIELD_ACCESS_BY_NAME), argRefs);
            faExpr.setSourceLocation(sourceLoc);
            fieldAccessExprs.add(new MutableObject<>(faExpr));
            // Updates variable mapping for ancestor operators.
            updateInputToOutputVarMapping(inputLiveVar, newVar, false);
        }
    }
    AssignOperator assignOp = new AssignOperator(fieldAccessVars, fieldAccessExprs);
    assignOp.setSourceLocation(sourceLoc);
    return assignOp;
}
#end_block

#method_before
@Override
public ILogicalOperator visitOrderOperator(OrderOperator op, Void arg) throws AlgebricksException {
    visitSingleInputOperator(op);
    if (correlatedKeyVars.isEmpty()) {
        return op;
    }
    orderingExprs.clear();
    orderingExprs.addAll(cloneOrderingExpression(op.getOrderExpressions()));
    List<Pair<IOrder, Mutable<ILogicalExpression>>> orderExprList = new ArrayList<>();
    // Adds keyVars to the prefix of sorting columns.
    for (LogicalVariable keyVar : correlatedKeyVars) {
        orderExprList.add(new Pair<>(OrderOperator.ASC_ORDER, new MutableObject<>(new VariableReferenceExpression(keyVar))));
    }
    orderExprList.addAll(op.getOrderExpressions());
    // Creates an order operator with the new expression list.
    OrderOperator orderOp = new OrderOperator(orderExprList);
    orderOp.getInputs().addAll(op.getInputs());
    context.computeAndSetTypeEnvironmentForOperator(orderOp);
    return orderOp;
}
#method_after
@Override
public ILogicalOperator visitOrderOperator(OrderOperator op, Void arg) throws AlgebricksException {
    visitSingleInputOperator(op);
    if (correlatedKeyVars.isEmpty()) {
        return op;
    }
    orderingExprs.clear();
    orderingExprs.addAll(cloneOrderingExpression(op.getOrderExpressions()));
    List<Pair<IOrder, Mutable<ILogicalExpression>>> orderExprList = new ArrayList<>();
    // Adds keyVars to the prefix of sorting columns.
    for (LogicalVariable keyVar : correlatedKeyVars) {
        VariableReferenceExpression keyVarRef = new VariableReferenceExpression(keyVar);
        keyVarRef.setSourceLocation(op.getSourceLocation());
        orderExprList.add(new Pair<>(OrderOperator.ASC_ORDER, new MutableObject<>(keyVarRef)));
    }
    orderExprList.addAll(op.getOrderExpressions());
    // Creates an order operator with the new expression list.
    OrderOperator orderOp = new OrderOperator(orderExprList);
    orderOp.setSourceLocation(op.getSourceLocation());
    orderOp.getInputs().addAll(op.getInputs());
    context.computeAndSetTypeEnvironmentForOperator(orderOp);
    return orderOp;
}
#end_block

#method_before
@Override
public ILogicalOperator visitUnionOperator(UnionAllOperator op, Void arg) throws AlgebricksException {
    visitMultiInputOperator(op);
    // Update the variable mappings
    List<Triple<LogicalVariable, LogicalVariable, LogicalVariable>> varTriples = op.getVariableMappings();
    for (Triple<LogicalVariable, LogicalVariable, LogicalVariable> triple : varTriples) {
        updateInputToOutputVarMapping(triple.third, triple.first, false);
        updateInputToOutputVarMapping(triple.second, triple.first, false);
    }
    return op;
}
#method_after
@Override
public ILogicalOperator visitUnionOperator(UnionAllOperator op, Void arg) throws AlgebricksException {
    visitMultiInputOperator(op);
    // Update the variable mappings
    List<Triple<LogicalVariable, LogicalVariable, LogicalVariable>> varTriples = op.getVariableMappings();
    for (Triple<LogicalVariable, LogicalVariable, LogicalVariable> triple : varTriples) {
        updateInputToOutputVarMapping(triple.first, triple.third, false);
        updateInputToOutputVarMapping(triple.second, triple.third, false);
    }
    return op;
}
#end_block

#method_before
@Override
public ILogicalOperator visitIntersectOperator(IntersectOperator op, Void arg) throws AlgebricksException {
    visitMultiInputOperator(op);
    List<LogicalVariable> outputVars = op.getOutputVars();
    for (int i = 0; i < op.getNumInput(); i++) {
        List<LogicalVariable> inputVars = op.getInputVariables(i);
        if (inputVars.size() != outputVars.size()) {
            throw new AlgebricksException("The cardinality of input and output are not equal for Intersection");
        }
        for (int j = 0; j < inputVars.size(); j++) {
            updateInputToOutputVarMapping(inputVars.get(j), outputVars.get(j), false);
        }
    }
    return op;
}
#method_after
@Override
public ILogicalOperator visitIntersectOperator(IntersectOperator op, Void arg) throws AlgebricksException {
    visitMultiInputOperator(op);
    List<LogicalVariable> outputVars = op.getOutputVars();
    for (int i = 0; i < op.getNumInput(); i++) {
        List<LogicalVariable> inputVars = op.getInputVariables(i);
        if (inputVars.size() != outputVars.size()) {
            throw new CompilationException(ErrorCode.COMPILATION_ERROR, op.getSourceLocation(), "The cardinality of input and output are not equal for Intersection");
        }
        for (int j = 0; j < inputVars.size(); j++) {
            updateInputToOutputVarMapping(inputVars.get(j), outputVars.get(j), false);
        }
    }
    return op;
}
#end_block

#method_before
@Override
public ILogicalOperator visitLeftOuterUnnestMapOperator(LeftOuterUnnestMapOperator op, Void arg) throws AlgebricksException {
    throw new AlgebricksException("The subquery de-correlation rule should always be applied before index-access-method related rules.");
}
#method_after
@Override
public ILogicalOperator visitLeftOuterUnnestMapOperator(LeftOuterUnnestMapOperator op, Void arg) throws AlgebricksException {
    throw new CompilationException(ErrorCode.COMPILATION_ERROR, op.getSourceLocation(), "The subquery de-correlation rule should always be applied before index-access-method related rules.");
}
#end_block

#method_before
@Override
public ILogicalOperator visitForwardOperator(ForwardOperator op, Void arg) throws AlgebricksException {
    // TODO(ali): check this
    return visitMultiInputOperator(op);
}
#method_after
@Override
public ILogicalOperator visitForwardOperator(ForwardOperator op, Void arg) throws AlgebricksException {
    throw new CompilationException(ErrorCode.COMPILATION_ERROR, op.getSourceLocation(), "Forward operator should have been disqualified for this rewriting!");
}
#end_block

#method_before
private ILogicalOperator visitAggregateOperator(ILogicalOperator op) throws AlgebricksException {
    visitSingleInputOperator(op);
    if (correlatedKeyVars.isEmpty()) {
        return op;
    }
    GroupByOperator gbyOp = new GroupByOperator();
    // Creates a copy of correlatedKeyVars, to fix the ConcurrentModificationException in ASTERIXDB-1581.
    List<LogicalVariable> copyOfCorrelatedKeyVars = new ArrayList<>(correlatedKeyVars);
    for (LogicalVariable keyVar : copyOfCorrelatedKeyVars) {
        // This limits the visitor can only be applied to a nested logical
        // plan inside a Subplan operator,
        // where the keyVarsToEnforce forms a candidate key which can
        // uniquely identify a tuple out of the nested-tuple-source.
        LogicalVariable newVar = context.newVar();
        gbyOp.getGroupByList().add(new Pair<>(newVar, new MutableObject<>(new VariableReferenceExpression(keyVar))));
        updateInputToOutputVarMapping(keyVar, newVar, false);
    }
    ILogicalOperator inputOp = op.getInputs().get(0).getValue();
    gbyOp.getInputs().add(new MutableObject<>(inputOp));
    NestedTupleSourceOperator nts = new NestedTupleSourceOperator(new MutableObject<>(gbyOp));
    op.getInputs().clear();
    op.getInputs().add(new MutableObject<>(nts));
    ILogicalPlan nestedPlan = new ALogicalPlanImpl();
    nestedPlan.getRoots().add(new MutableObject<>(op));
    gbyOp.getNestedPlans().add(nestedPlan);
    OperatorManipulationUtil.computeTypeEnvironmentBottomUp(gbyOp, context);
    return op;
}
#method_after
private ILogicalOperator visitAggregateOperator(ILogicalOperator op) throws AlgebricksException {
    visitSingleInputOperator(op);
    if (correlatedKeyVars.isEmpty()) {
        return op;
    }
    SourceLocation sourceLoc = op.getSourceLocation();
    GroupByOperator gbyOp = new GroupByOperator();
    gbyOp.setSourceLocation(sourceLoc);
    // Creates a copy of correlatedKeyVars, to fix the ConcurrentModificationException in ASTERIXDB-1581.
    List<LogicalVariable> copyOfCorrelatedKeyVars = new ArrayList<>(correlatedKeyVars);
    for (LogicalVariable keyVar : copyOfCorrelatedKeyVars) {
        // This limits the visitor can only be applied to a nested logical
        // plan inside a Subplan operator,
        // where the keyVarsToEnforce forms a candidate key which can
        // uniquely identify a tuple out of the nested-tuple-source.
        LogicalVariable newVar = context.newVar();
        VariableReferenceExpression keyVarRef = new VariableReferenceExpression(keyVar);
        keyVarRef.setSourceLocation(sourceLoc);
        gbyOp.getGroupByList().add(new Pair<>(newVar, new MutableObject<>(keyVarRef)));
        updateInputToOutputVarMapping(keyVar, newVar, false);
    }
    ILogicalOperator inputOp = op.getInputs().get(0).getValue();
    gbyOp.getInputs().add(new MutableObject<>(inputOp));
    NestedTupleSourceOperator nts = new NestedTupleSourceOperator(new MutableObject<>(gbyOp));
    nts.setSourceLocation(sourceLoc);
    op.getInputs().clear();
    op.getInputs().add(new MutableObject<>(nts));
    ILogicalPlan nestedPlan = new ALogicalPlanImpl();
    nestedPlan.getRoots().add(new MutableObject<>(op));
    gbyOp.getNestedPlans().add(nestedPlan);
    OperatorManipulationUtil.computeTypeEnvironmentBottomUp(gbyOp, context);
    return op;
}
#end_block

#method_before
private void sweepExpression(ILogicalExpression expr, ILogicalOperator op) throws AlgebricksException {
    if (expr.getExpressionTag() == LogicalExpressionTag.FUNCTION_CALL) {
        if (!expr.isFunctional()) {
            AbstractFunctionCallExpression fce = (AbstractFunctionCallExpression) expr;
            throw new AlgebricksException("Found non-functional function " + fce.getFunctionIdentifier() + " in op " + op);
        }
    }
}
#method_after
private void sweepExpression(ILogicalExpression expr, ILogicalOperator op) throws AlgebricksException {
    if (expr.getExpressionTag() == LogicalExpressionTag.FUNCTION_CALL && !expr.isFunctional()) {
        AbstractFunctionCallExpression fce = (AbstractFunctionCallExpression) expr;
        throw new CompilationException(ErrorCode.COMPILATION_ERROR, fce.getSourceLocation(), "Found non-functional function " + fce.getFunctionIdentifier() + " in op " + op);
    }
}
#end_block

#method_before
@Override
public Void visitForwardOperator(ForwardOperator op, Void arg) throws AlgebricksException {
    return null;
}
#method_after
@Override
public Void visitForwardOperator(ForwardOperator op, Void arg) throws AlgebricksException {
    sweepExpression(op.getRangeMapExpression().getValue(), op);
    return null;
}
#end_block

#method_before
@Override
public Void visitDataScanOperator(DataSourceScanOperator op, Pair<LogicalVariable, LogicalVariable> pair) throws AlgebricksException {
    List<LogicalVariable> variables = op.getVariables();
    for (int i = 0; i < variables.size(); i++) {
        if (variables.get(i) == pair.first) {
            variables.set(i, pair.second);
            return null;
        }
    }
    substVarTypes(op, pair);
    return null;
}
#method_after
@Override
public Void visitDataScanOperator(DataSourceScanOperator op, Pair<LogicalVariable, LogicalVariable> pair) throws AlgebricksException {
    List<LogicalVariable> variables = op.getVariables();
    for (int i = 0; i < variables.size(); i++) {
        if (variables.get(i) == pair.first) {
            variables.set(i, pair.second);
            return null;
        }
    }
    substVarTypes(op, pair);
    if (op.getSelectCondition() != null) {
        op.getSelectCondition().getValue().substituteVar(pair.first, pair.second);
    }
    return null;
}
#end_block

#method_before
@Override
public Void visitUnnestMapOperator(UnnestMapOperator op, Pair<LogicalVariable, LogicalVariable> pair) throws AlgebricksException {
    substituteVarsForAbstractUnnestMapOp(op, pair);
    return null;
}
#method_after
@Override
public Void visitUnnestMapOperator(UnnestMapOperator op, Pair<LogicalVariable, LogicalVariable> pair) throws AlgebricksException {
    substituteVarsForAbstractUnnestMapOp(op, pair);
    if (op.getSelectCondition() != null) {
        op.getSelectCondition().getValue().substituteVar(pair.first, pair.second);
    }
    return null;
}
#end_block

#method_before
@Override
public Void visitForwardOperator(ForwardOperator op, Pair<LogicalVariable, LogicalVariable> arg) throws AlgebricksException {
    return null;
}
#method_after
@Override
public Void visitForwardOperator(ForwardOperator op, Pair<LogicalVariable, LogicalVariable> arg) throws AlgebricksException {
    op.getRangeMapExpression().getValue().substituteVar(arg.first, arg.second);
    substVarTypes(op, arg);
    return null;
}
#end_block

#method_before
private static void addAgg(FunctionIdentifier fi) {
    builtinAggregateFunctions.add(getAsterixFunctionInfo(fi));
}
#method_after
public static void addAgg(FunctionIdentifier fi) {
    builtinAggregateFunctions.add(getAsterixFunctionInfo(fi));
}
#end_block

#method_before
private static void addLocalAgg(FunctionIdentifier fi, FunctionIdentifier localfi) {
    aggregateToLocalAggregate.put(getAsterixFunctionInfo(fi), getAsterixFunctionInfo(localfi));
}
#method_after
public static void addLocalAgg(FunctionIdentifier fi, FunctionIdentifier localfi) {
    aggregateToLocalAggregate.put(getAsterixFunctionInfo(fi), getAsterixFunctionInfo(localfi));
}
#end_block

#method_before
private static void addIntermediateAgg(FunctionIdentifier fi, FunctionIdentifier globalfi) {
    aggregateToIntermediateAggregate.put(getAsterixFunctionInfo(fi), getAsterixFunctionInfo(globalfi));
}
#method_after
public static void addIntermediateAgg(FunctionIdentifier fi, FunctionIdentifier globalfi) {
    aggregateToIntermediateAggregate.put(getAsterixFunctionInfo(fi), getAsterixFunctionInfo(globalfi));
}
#end_block

#method_before
private static void addGlobalAgg(FunctionIdentifier fi, FunctionIdentifier globalfi) {
    aggregateToGlobalAggregate.put(getAsterixFunctionInfo(fi), getAsterixFunctionInfo(globalfi));
    globalAggregateFunctions.add(getAsterixFunctionInfo(globalfi));
}
#method_after
public static void addGlobalAgg(FunctionIdentifier fi, FunctionIdentifier globalfi) {
    aggregateToGlobalAggregate.put(getAsterixFunctionInfo(fi), getAsterixFunctionInfo(globalfi));
    globalAggregateFunctions.add(getAsterixFunctionInfo(globalfi));
}
#end_block

#method_before
private static void addSerialAgg(FunctionIdentifier fi, FunctionIdentifier serialfi) {
    aggregateToSerializableAggregate.put(getAsterixFunctionInfo(fi), getAsterixFunctionInfo(serialfi));
}
#method_after
public static void addSerialAgg(FunctionIdentifier fi, FunctionIdentifier serialfi) {
    aggregateToSerializableAggregate.put(getAsterixFunctionInfo(fi), getAsterixFunctionInfo(serialfi));
}
#end_block

#method_before
private static void addScalarAgg(FunctionIdentifier fi, FunctionIdentifier scalarfi) {
    scalarToAggregateFunctionMap.put(getAsterixFunctionInfo(scalarfi), getAsterixFunctionInfo(fi));
}
#method_after
public static void addScalarAgg(FunctionIdentifier fi, FunctionIdentifier scalarfi) {
    scalarToAggregateFunctionMap.put(getAsterixFunctionInfo(scalarfi), getAsterixFunctionInfo(fi));
}
#end_block

#method_before
private static void addDistinctAgg(FunctionIdentifier distinctfi, FunctionIdentifier regularscalarfi) {
    distinctToRegularScalarAggregateFunctionMap.put(getAsterixFunctionInfo(distinctfi), getAsterixFunctionInfo(regularscalarfi));
}
#method_after
public static void addDistinctAgg(FunctionIdentifier distinctfi, FunctionIdentifier regularscalarfi) {
    distinctToRegularScalarAggregateFunctionMap.put(getAsterixFunctionInfo(distinctfi), getAsterixFunctionInfo(regularscalarfi));
}
#end_block

#method_before
@Override
public void init(DataOutput state) throws HyracksDataException {
    try {
        state.writeDouble(0.0);
        state.writeDouble(0.0);
        state.writeDouble(0.0);
        state.writeDouble(0.0);
        state.writeLong(0L);
        state.writeByte(ATypeTag.SERIALIZED_SYSTEM_NULL_TYPE_TAG);
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    }
}
#method_after
@Override
public void init(DataOutput state) throws HyracksDataException {
    try {
        state.writeDouble(0.0);
        state.writeDouble(0.0);
        state.writeLong(0L);
        state.writeByte(ATypeTag.SERIALIZED_SYSTEM_NULL_TYPE_TAG);
        moments.set(0, 0, 0);
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    }
}
#end_block

#method_before
protected void processDataValues(IFrameTupleReference tuple, byte[] state, int start, int len) throws HyracksDataException {
    if (skipStep(state, start)) {
        return;
    }
    eval.evaluate(tuple, inputVal);
    byte[] bytes = inputVal.getByteArray();
    int offset = inputVal.getStartOffset();
    double m1 = BufferSerDeUtil.getDouble(state, start + M1_OFFSET);
    double m2 = BufferSerDeUtil.getDouble(state, start + M2_OFFSET);
    double m3 = BufferSerDeUtil.getDouble(state, start + M3_OFFSET);
    double m4 = BufferSerDeUtil.getDouble(state, start + M4_OFFSET);
    long count = BufferSerDeUtil.getLong(state, start + COUNT_OFFSET);
    boolean m3_flag = getSkewFlag();
    boolean m4_flag = getKurtFlag();
    ATypeTag typeTag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(bytes[offset]);
    ATypeTag aggType = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(state[start + AGG_TYPE_OFFSET]);
    if (typeTag == ATypeTag.MISSING || typeTag == ATypeTag.NULL) {
        processNull(state, start);
        return;
    } else if (aggType == ATypeTag.SYSTEM_NULL) {
        aggType = typeTag;
    } else if (typeTag != ATypeTag.SYSTEM_NULL && !ATypeHierarchy.isCompatible(typeTag, aggType)) {
        if (typeTag.ordinal() > aggType.ordinal()) {
            throw new IncompatibleTypeException(sourceLoc, getFunctionIdentifier(), bytes[offset], aggType.serialize());
        } else {
            throw new IncompatibleTypeException(sourceLoc, getFunctionIdentifier(), aggType.serialize(), bytes[offset]);
        }
    } else if (ATypeHierarchy.canPromote(aggType, typeTag)) {
        aggType = typeTag;
    }
    long n1 = count;
    ++count;
    switch(typeTag) {
        case TINYINT:
            {
                byte val = AInt8SerializerDeserializer.getByte(bytes, offset + 1);
                double delta = val - m1;
                double delta_n = delta / count;
                double term1 = delta * delta_n * n1;
                m1 += delta / count;
                if (m4_flag) {
                    m4 += term1 * delta_n * delta_n * (count * count - 3 * count + 3);
                    m4 += 6 * delta_n * delta_n * m2 - 4 * delta_n * m3;
                }
                if (m3_flag) {
                    m3 += term1 * delta_n * (count - 2) - 3 * delta_n * m2;
                }
                m2 += term1;
                break;
            }
        case SMALLINT:
            {
                short val = AInt16SerializerDeserializer.getShort(bytes, offset + 1);
                double delta = val - m1;
                double delta_n = delta / count;
                double term1 = delta * delta_n * n1;
                m1 += delta / count;
                if (m4_flag) {
                    m4 += term1 * delta_n * delta_n * (count * count - 3 * count + 3);
                    m4 += 6 * delta_n * delta_n * m2 - 4 * delta_n * m3;
                }
                if (m3_flag) {
                    m3 += term1 * delta_n * (count - 2) - 3 * delta_n * m2;
                }
                m2 += term1;
                break;
            }
        case INTEGER:
            {
                int val = AInt32SerializerDeserializer.getInt(bytes, offset + 1);
                double delta = val - m1;
                double delta_n = delta / count;
                double term1 = delta * delta_n * n1;
                m1 += delta / count;
                if (m4_flag) {
                    m4 += term1 * delta_n * delta_n * (count * count - 3 * count + 3);
                    m4 += 6 * delta_n * delta_n * m2 - 4 * delta_n * m3;
                }
                if (m3_flag) {
                    m3 += term1 * delta_n * (count - 2) - 3 * delta_n * m2;
                }
                m2 += term1;
                break;
            }
        case BIGINT:
            {
                long val = AInt64SerializerDeserializer.getLong(bytes, offset + 1);
                double delta = val - m1;
                double delta_n = delta / count;
                double term1 = delta * delta_n * n1;
                m1 += delta / count;
                if (m4_flag) {
                    m4 += term1 * delta_n * delta_n * (count * count - 3 * count + 3);
                    m4 += 6 * delta_n * delta_n * m2 - 4 * delta_n * m3;
                }
                if (m3_flag) {
                    m3 += term1 * delta_n * (count - 2) - 3 * delta_n * m2;
                }
                m2 += term1;
                break;
            }
        case FLOAT:
            {
                float val = AFloatSerializerDeserializer.getFloat(bytes, offset + 1);
                double delta = val - m1;
                double delta_n = delta / count;
                double term1 = delta * delta_n * n1;
                m1 += delta / count;
                if (m4_flag) {
                    m4 += term1 * delta_n * delta_n * (count * count - 3 * count + 3);
                    m4 += 6 * delta_n * delta_n * m2 - 4 * delta_n * m3;
                }
                if (m3_flag) {
                    m3 += term1 * delta_n * (count - 2) - 3 * delta_n * m2;
                }
                m2 += term1;
                break;
            }
        case DOUBLE:
            {
                double val = ADoubleSerializerDeserializer.getDouble(bytes, offset + 1);
                double delta = val - m1;
                double delta_n = delta / count;
                double term1 = delta * delta_n * n1;
                m1 += delta / count;
                if (m4_flag) {
                    m4 += term1 * delta_n * delta_n * (count * count - 3 * count + 3);
                    m4 += 6 * delta_n * delta_n * m2 - 4 * delta_n * m3;
                }
                if (m3_flag) {
                    m3 += term1 * delta_n * (count - 2) - 3 * delta_n * m2;
                }
                m2 += term1;
                break;
            }
        default:
            throw new UnsupportedItemTypeException(sourceLoc, getFunctionIdentifier(), bytes[offset]);
    }
    BufferSerDeUtil.writeDouble(m1, state, start + M1_OFFSET);
    BufferSerDeUtil.writeDouble(m2, state, start + M2_OFFSET);
    BufferSerDeUtil.writeDouble(m3, state, start + M3_OFFSET);
    BufferSerDeUtil.writeDouble(m4, state, start + M4_OFFSET);
    BufferSerDeUtil.writeLong(count, state, start + COUNT_OFFSET);
    state[start + AGG_TYPE_OFFSET] = aggType.serialize();
}
#method_after
protected void processDataValues(IFrameTupleReference tuple, byte[] state, int start, int len) throws HyracksDataException {
    if (skipStep(state, start)) {
        return;
    }
    eval.evaluate(tuple, inputVal);
    byte[] bytes = inputVal.getByteArray();
    int offset = inputVal.getStartOffset();
    double m1 = BufferSerDeUtil.getDouble(state, start + M1_OFFSET);
    double m2 = BufferSerDeUtil.getDouble(state, start + M2_OFFSET);
    long count = BufferSerDeUtil.getLong(state, start + COUNT_OFFSET);
    moments.set(m1, m2, count);
    ATypeTag typeTag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(bytes[offset]);
    ATypeTag aggType = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(state[start + AGG_TYPE_OFFSET]);
    if (typeTag == ATypeTag.MISSING || typeTag == ATypeTag.NULL) {
        processNull(state, start);
        return;
    } else if (aggType == ATypeTag.SYSTEM_NULL) {
        aggType = typeTag;
    } else if (typeTag != ATypeTag.SYSTEM_NULL && !ATypeHierarchy.isCompatible(typeTag, aggType)) {
        if (typeTag.ordinal() > aggType.ordinal()) {
            throw new IncompatibleTypeException(sourceLoc, getFunctionIdentifier(), bytes[offset], aggType.serialize());
        } else {
            throw new IncompatibleTypeException(sourceLoc, getFunctionIdentifier(), aggType.serialize(), bytes[offset]);
        }
    } else if (ATypeHierarchy.canPromote(aggType, typeTag)) {
        aggType = typeTag;
    }
    double val;
    switch(typeTag) {
        case TINYINT:
            val = AInt8SerializerDeserializer.getByte(bytes, offset + 1);
            moments.push(val);
            break;
        case SMALLINT:
            val = AInt16SerializerDeserializer.getShort(bytes, offset + 1);
            moments.push(val);
            break;
        case INTEGER:
            val = AInt32SerializerDeserializer.getInt(bytes, offset + 1);
            moments.push(val);
            break;
        case BIGINT:
            val = AInt64SerializerDeserializer.getLong(bytes, offset + 1);
            moments.push(val);
            break;
        case FLOAT:
            val = AFloatSerializerDeserializer.getFloat(bytes, offset + 1);
            moments.push(val);
            break;
        case DOUBLE:
            val = ADoubleSerializerDeserializer.getDouble(bytes, offset + 1);
            moments.push(val);
            break;
        default:
            throw new UnsupportedItemTypeException(sourceLoc, getFunctionIdentifier(), bytes[offset]);
    }
    BufferSerDeUtil.writeDouble(moments.getM1(), state, start + M1_OFFSET);
    BufferSerDeUtil.writeDouble(moments.getM2(), state, start + M2_OFFSET);
    BufferSerDeUtil.writeLong(moments.getCount(), state, start + COUNT_OFFSET);
    state[start + AGG_TYPE_OFFSET] = aggType.serialize();
}
#end_block

#method_before
protected void finishPartialResults(byte[] state, int start, int len, DataOutput result) throws HyracksDataException {
    double m1 = BufferSerDeUtil.getDouble(state, start + M1_OFFSET);
    double m2 = BufferSerDeUtil.getDouble(state, start + M2_OFFSET);
    double m3 = BufferSerDeUtil.getDouble(state, start + M3_OFFSET);
    double m4 = BufferSerDeUtil.getDouble(state, start + M4_OFFSET);
    long count = BufferSerDeUtil.getLong(state, start + COUNT_OFFSET);
    boolean m3_flag = getSkewFlag();
    boolean m4_flag = getKurtFlag();
    ATypeTag aggType = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(state[start + AGG_TYPE_OFFSET]);
    if (recordEval == null) {
        ARecordType recType = new ARecordType(null, new String[] { "m1", "m2", "m3", "m4", "count" }, new IAType[] { BuiltinType.ADOUBLE, BuiltinType.ADOUBLE, BuiltinType.ADOUBLE, BuiltinType.ADOUBLE, BuiltinType.AINT64 }, false);
        recordEval = new ClosedRecordConstructorEval(recType, new IScalarEvaluator[] { evalM1, evalM2, evalM3, evalM4, evalCount });
    }
    try {
        if (aggType == ATypeTag.SYSTEM_NULL) {
            if (GlobalConfig.DEBUG) {
                GlobalConfig.ASTERIX_LOGGER.trace("Single Var statistics aggregate ran over empty input.");
            }
            result.writeByte(ATypeTag.SERIALIZED_SYSTEM_NULL_TYPE_TAG);
        } else if (aggType == ATypeTag.NULL) {
            result.writeByte(ATypeTag.SERIALIZED_NULL_TYPE_TAG);
        } else {
            m1Bytes.reset();
            aDouble.setValue(m1);
            doubleSerde.serialize(aDouble, m1BytesOutput);
            m2Bytes.reset();
            aDouble.setValue(m2);
            doubleSerde.serialize(aDouble, m2BytesOutput);
            m3Bytes.reset();
            aDouble.setValue(m3);
            doubleSerde.serialize(aDouble, m3BytesOutput);
            m4Bytes.reset();
            aDouble.setValue(m4);
            doubleSerde.serialize(aDouble, m4BytesOutput);
            countBytes.reset();
            aInt64.setValue(count);
            longSerde.serialize(aInt64, countBytesOutput);
            recordEval.evaluate(null, resultBytes);
            result.write(resultBytes.getByteArray(), resultBytes.getStartOffset(), resultBytes.getLength());
        }
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    }
}
#method_after
protected void finishPartialResults(byte[] state, int start, int len, DataOutput result) throws HyracksDataException {
    double m1 = BufferSerDeUtil.getDouble(state, start + M1_OFFSET);
    double m2 = BufferSerDeUtil.getDouble(state, start + M2_OFFSET);
    long count = BufferSerDeUtil.getLong(state, start + COUNT_OFFSET);
    ATypeTag aggType = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(state[start + AGG_TYPE_OFFSET]);
    if (recordEval == null) {
        ARecordType recType = new ARecordType(null, new String[] { "m1", "m2", "count" }, new IAType[] { BuiltinType.ADOUBLE, BuiltinType.ADOUBLE, BuiltinType.AINT64 }, false);
        recordEval = new ClosedRecordConstructorEval(recType, new IScalarEvaluator[] { evalM1, evalM2, evalCount });
    }
    try {
        if (aggType == ATypeTag.SYSTEM_NULL) {
            if (GlobalConfig.DEBUG) {
                GlobalConfig.ASTERIX_LOGGER.trace("Single Var statistics aggregate ran over empty input.");
            }
            result.writeByte(ATypeTag.SERIALIZED_SYSTEM_NULL_TYPE_TAG);
        } else if (aggType == ATypeTag.NULL) {
            result.writeByte(ATypeTag.SERIALIZED_NULL_TYPE_TAG);
        } else {
            m1Bytes.reset();
            aDouble.setValue(m1);
            doubleSerde.serialize(aDouble, m1BytesOutput);
            m2Bytes.reset();
            aDouble.setValue(m2);
            doubleSerde.serialize(aDouble, m2BytesOutput);
            countBytes.reset();
            aInt64.setValue(count);
            longSerde.serialize(aInt64, countBytesOutput);
            recordEval.evaluate(null, resultBytes);
            result.write(resultBytes.getByteArray(), resultBytes.getStartOffset(), resultBytes.getLength());
        }
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    }
}
#end_block

#method_before
protected void processPartialResults(IFrameTupleReference tuple, byte[] state, int start, int len) throws HyracksDataException {
    if (skipStep(state, start)) {
        return;
    }
    double m1 = BufferSerDeUtil.getDouble(state, start + M1_OFFSET);
    double m2 = BufferSerDeUtil.getDouble(state, start + M2_OFFSET);
    double m3 = BufferSerDeUtil.getDouble(state, start + M3_OFFSET);
    double m4 = BufferSerDeUtil.getDouble(state, start + M4_OFFSET);
    long count = BufferSerDeUtil.getLong(state, start + COUNT_OFFSET);
    boolean m3_flag = getSkewFlag();
    boolean m4_flag = getKurtFlag();
    eval.evaluate(tuple, inputVal);
    byte[] serBytes = inputVal.getByteArray();
    int offset = inputVal.getStartOffset();
    ATypeTag typeTag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(serBytes[offset]);
    switch(typeTag) {
        case NULL:
            {
                processNull(state, start);
                break;
            }
        case SYSTEM_NULL:
            {
                // Ignore and return.
                break;
            }
        case OBJECT:
            {
                // Expected.
                ATypeTag aggType = ATypeTag.DOUBLE;
                int nullBitmapSize = 0;
                int offset1 = ARecordSerializerDeserializer.getFieldOffsetById(serBytes, offset, M1_FIELD_ID, nullBitmapSize, false);
                int offset2 = ARecordSerializerDeserializer.getFieldOffsetById(serBytes, offset, M2_FIELD_ID, nullBitmapSize, false);
                int offset3 = ARecordSerializerDeserializer.getFieldOffsetById(serBytes, offset, M3_FIELD_ID, nullBitmapSize, false);
                int offset4 = ARecordSerializerDeserializer.getFieldOffsetById(serBytes, offset, M4_FIELD_ID, nullBitmapSize, false);
                int offset5 = ARecordSerializerDeserializer.getFieldOffsetById(serBytes, offset, COUNT_FIELD_ID, nullBitmapSize, false);
                double temp_m1 = ADoubleSerializerDeserializer.getDouble(serBytes, offset1);
                double temp_m2 = ADoubleSerializerDeserializer.getDouble(serBytes, offset2);
                double temp_m3 = ADoubleSerializerDeserializer.getDouble(serBytes, offset3);
                double temp_m4 = ADoubleSerializerDeserializer.getDouble(serBytes, offset4);
                long temp_count = AInt64SerializerDeserializer.getLong(serBytes, offset5);
                double delta = temp_m1 - m1;
                long combined_count = count + temp_count;
                if (m3_flag) {
                    double delta3 = delta * delta * delta;
                    if (m4_flag) {
                        m4 += temp_m4 + delta3 * delta * count * temp_count * (count * count - count * temp_count + temp_count * temp_count) / (combined_count * combined_count * combined_count);
                        m4 += 6 * delta * delta * (count * count * temp_m2 + temp_count * temp_count * m2) / (combined_count * combined_count) + 4 * delta * (count * temp_m3 - temp_count * m3) / combined_count;
                    }
                    m3 += temp_m3 + delta3 * count * temp_count * (count - temp_count) / (combined_count * combined_count);
                    m3 += 3 * delta * (count * temp_m2 - temp_count * m2) / combined_count;
                }
                m1 = (count * m1 + temp_count * temp_m1) / combined_count;
                m2 += temp_m2 + delta * delta * count * temp_count / combined_count;
                count = combined_count;
                BufferSerDeUtil.writeDouble(m1, state, start + M1_OFFSET);
                BufferSerDeUtil.writeDouble(m2, state, start + M2_OFFSET);
                BufferSerDeUtil.writeDouble(m3, state, start + M3_OFFSET);
                BufferSerDeUtil.writeDouble(m4, state, start + M4_OFFSET);
                BufferSerDeUtil.writeLong(count, state, start + COUNT_OFFSET);
                state[start + AGG_TYPE_OFFSET] = aggType.serialize();
                break;
            }
        default:
            throw new UnsupportedItemTypeException(sourceLoc, getFunctionIdentifier(), serBytes[offset]);
    }
}
#method_after
protected void processPartialResults(IFrameTupleReference tuple, byte[] state, int start, int len) throws HyracksDataException {
    if (skipStep(state, start)) {
        return;
    }
    double m1 = BufferSerDeUtil.getDouble(state, start + M1_OFFSET);
    double m2 = BufferSerDeUtil.getDouble(state, start + M2_OFFSET);
    long count = BufferSerDeUtil.getLong(state, start + COUNT_OFFSET);
    moments.set(m1, m2, count);
    eval.evaluate(tuple, inputVal);
    byte[] serBytes = inputVal.getByteArray();
    int offset = inputVal.getStartOffset();
    ATypeTag typeTag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(serBytes[offset]);
    switch(typeTag) {
        case NULL:
            processNull(state, start);
            break;
        case SYSTEM_NULL:
            // Ignore and return.
            break;
        case OBJECT:
            // Expected.
            ATypeTag aggType = ATypeTag.DOUBLE;
            int nullBitmapSize = 0;
            int offset1 = ARecordSerializerDeserializer.getFieldOffsetById(serBytes, offset, M1_FIELD_ID, nullBitmapSize, false);
            int offset2 = ARecordSerializerDeserializer.getFieldOffsetById(serBytes, offset, M2_FIELD_ID, nullBitmapSize, false);
            int offset3 = ARecordSerializerDeserializer.getFieldOffsetById(serBytes, offset, COUNT_FIELD_ID, nullBitmapSize, false);
            double temp_m1 = ADoubleSerializerDeserializer.getDouble(serBytes, offset1);
            double temp_m2 = ADoubleSerializerDeserializer.getDouble(serBytes, offset2);
            long temp_count = AInt64SerializerDeserializer.getLong(serBytes, offset3);
            moments.combine(temp_m1, temp_m2, temp_count);
            BufferSerDeUtil.writeDouble(moments.getM1(), state, start + M1_OFFSET);
            BufferSerDeUtil.writeDouble(moments.getM2(), state, start + M2_OFFSET);
            BufferSerDeUtil.writeLong(moments.getCount(), state, start + COUNT_OFFSET);
            state[start + AGG_TYPE_OFFSET] = aggType.serialize();
            break;
        default:
            throw new UnsupportedItemTypeException(sourceLoc, getFunctionIdentifier(), serBytes[offset]);
    }
}
#end_block

#method_before
@Override
public void init() throws HyracksDataException {
    aggType = ATypeTag.SYSTEM_NULL;
    m1 = 0.0;
    m2 = 0.0;
    m3 = 0.0;
    m4 = 0.0;
    count = 0;
}
#method_after
@Override
public void init() throws HyracksDataException {
    aggType = ATypeTag.SYSTEM_NULL;
    moments.set(0, 0, 0);
}
#end_block

#method_before
protected void processDataValues(IFrameTupleReference tuple) throws HyracksDataException {
    if (skipStep()) {
        return;
    }
    eval.evaluate(tuple, inputVal);
    byte[] data = inputVal.getByteArray();
    int offset = inputVal.getStartOffset();
    ATypeTag typeTag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(data[offset]);
    if (typeTag == ATypeTag.MISSING || typeTag == ATypeTag.NULL) {
        processNull();
        return;
    } else if (aggType == ATypeTag.SYSTEM_NULL) {
        aggType = typeTag;
    } else if (typeTag != ATypeTag.SYSTEM_NULL && !ATypeHierarchy.isCompatible(typeTag, aggType)) {
        if (typeTag.ordinal() > aggType.ordinal()) {
            throw new IncompatibleTypeException(sourceLoc, getFunctionIdentifier(), data[offset], aggType.serialize());
        } else {
            throw new IncompatibleTypeException(sourceLoc, getFunctionIdentifier(), aggType.serialize(), data[offset]);
        }
    } else if (ATypeHierarchy.canPromote(aggType, typeTag)) {
        aggType = typeTag;
    }
    long n1 = count;
    ++count;
    switch(typeTag) {
        case TINYINT:
            {
                byte val = AInt8SerializerDeserializer.getByte(data, offset + 1);
                double delta = val - m1;
                double delta_n = delta / count;
                double term1 = delta * delta_n * n1;
                m1 += delta / count;
                if (getKurtFlag()) {
                    m4 += term1 * delta_n * delta_n * (count * count - 3 * count + 3);
                    m4 += 6 * delta_n * delta_n * m2 - 4 * delta_n * m3;
                }
                if (getSkewFlag()) {
                    m3 += term1 * delta_n * (count - 2) - 3 * delta_n * m2;
                }
                m2 += term1;
                break;
            }
        case SMALLINT:
            {
                short val = AInt16SerializerDeserializer.getShort(data, offset + 1);
                double delta = val - m1;
                double delta_n = delta / count;
                double term1 = delta * delta_n * n1;
                m1 += delta / count;
                if (getKurtFlag()) {
                    m4 += term1 * delta_n * delta_n * (count * count - 3 * count + 3);
                    m4 += 6 * delta_n * delta_n * m2 - 4 * delta_n * m3;
                }
                if (getSkewFlag()) {
                    m3 += term1 * delta_n * (count - 2) - 3 * delta_n * m2;
                }
                m2 += term1;
                break;
            }
        case INTEGER:
            {
                int val = AInt32SerializerDeserializer.getInt(data, offset + 1);
                double delta = val - m1;
                double delta_n = delta / count;
                double term1 = delta * delta_n * n1;
                m1 += delta / count;
                if (getKurtFlag()) {
                    m4 += term1 * delta_n * delta_n * (count * count - 3 * count + 3);
                    m4 += 6 * delta_n * delta_n * m2 - 4 * delta_n * m3;
                }
                if (getSkewFlag()) {
                    m3 += term1 * delta_n * (count - 2) - 3 * delta_n * m2;
                }
                m2 += term1;
                break;
            }
        case BIGINT:
            {
                long val = AInt64SerializerDeserializer.getLong(data, offset + 1);
                double delta = val - m1;
                double delta_n = delta / count;
                double term1 = delta * delta_n * n1;
                m1 += delta / count;
                if (getKurtFlag()) {
                    m4 += term1 * delta_n * delta_n * (count * count - 3 * count + 3);
                    m4 += 6 * delta_n * delta_n * m2 - 4 * delta_n * m3;
                }
                if (getSkewFlag()) {
                    m3 += term1 * delta_n * (count - 2) - 3 * delta_n * m2;
                }
                m2 += term1;
                break;
            }
        case FLOAT:
            {
                float val = AFloatSerializerDeserializer.getFloat(data, offset + 1);
                double delta = val - m1;
                double delta_n = delta / count;
                double term1 = delta * delta_n * n1;
                m1 += delta / count;
                if (getKurtFlag()) {
                    m4 += term1 * delta_n * delta_n * (count * count - 3 * count + 3);
                    m4 += 6 * delta_n * delta_n * m2 - 4 * delta_n * m3;
                }
                if (getSkewFlag()) {
                    m3 += term1 * delta_n * (count - 2) - 3 * delta_n * m2;
                }
                m2 += term1;
                break;
            }
        case DOUBLE:
            {
                double val = ADoubleSerializerDeserializer.getDouble(data, offset + 1);
                double delta = val - m1;
                double delta_n = delta / count;
                double term1 = delta * delta_n * n1;
                m1 += delta / count;
                if (getKurtFlag()) {
                    m4 += term1 * delta_n * delta_n * (count * count - 3 * count + 3);
                    m4 += 6 * delta_n * delta_n * m2 - 4 * delta_n * m3;
                }
                if (getSkewFlag()) {
                    m3 += term1 * delta_n * (count - 2) - 3 * delta_n * m2;
                }
                m2 += term1;
                break;
            }
        default:
            {
                throw new UnsupportedItemTypeException(sourceLoc, getFunctionIdentifier(), data[offset]);
            }
    }
}
#method_after
protected void processDataValues(IFrameTupleReference tuple) throws HyracksDataException {
    if (skipStep()) {
        return;
    }
    eval.evaluate(tuple, inputVal);
    byte[] data = inputVal.getByteArray();
    int offset = inputVal.getStartOffset();
    ATypeTag typeTag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(data[offset]);
    if (typeTag == ATypeTag.MISSING || typeTag == ATypeTag.NULL) {
        processNull();
        return;
    } else if (aggType == ATypeTag.SYSTEM_NULL) {
        aggType = typeTag;
    } else if (typeTag != ATypeTag.SYSTEM_NULL && !ATypeHierarchy.isCompatible(typeTag, aggType)) {
        if (typeTag.ordinal() > aggType.ordinal()) {
            throw new IncompatibleTypeException(sourceLoc, getFunctionIdentifier(), data[offset], aggType.serialize());
        } else {
            throw new IncompatibleTypeException(sourceLoc, getFunctionIdentifier(), aggType.serialize(), data[offset]);
        }
    } else if (ATypeHierarchy.canPromote(aggType, typeTag)) {
        aggType = typeTag;
    }
    double val;
    switch(typeTag) {
        case TINYINT:
            val = AInt8SerializerDeserializer.getByte(data, offset + 1);
            moments.push(val);
            break;
        case SMALLINT:
            val = AInt16SerializerDeserializer.getShort(data, offset + 1);
            moments.push(val);
            break;
        case INTEGER:
            val = AInt32SerializerDeserializer.getInt(data, offset + 1);
            moments.push(val);
            break;
        case BIGINT:
            val = AInt64SerializerDeserializer.getLong(data, offset + 1);
            moments.push(val);
            break;
        case FLOAT:
            val = AFloatSerializerDeserializer.getFloat(data, offset + 1);
            moments.push(val);
            break;
        case DOUBLE:
            val = ADoubleSerializerDeserializer.getDouble(data, offset + 1);
            moments.push(val);
            break;
        default:
            throw new UnsupportedItemTypeException(sourceLoc, getFunctionIdentifier(), data[offset]);
    }
}
#end_block

#method_before
protected void finishPartialResults(IPointable result) throws HyracksDataException {
    resultStorage.reset();
    try {
        // Double check that count 0 is accounted
        if (aggType == ATypeTag.SYSTEM_NULL) {
            if (GlobalConfig.DEBUG) {
                GlobalConfig.ASTERIX_LOGGER.trace("Single var statistics aggregate ran over empty input.");
            }
            resultStorage.getDataOutput().writeByte(ATypeTag.SERIALIZED_SYSTEM_NULL_TYPE_TAG);
            result.set(resultStorage);
        } else if (aggType == ATypeTag.NULL) {
            resultStorage.getDataOutput().writeByte(ATypeTag.SERIALIZED_NULL_TYPE_TAG);
            result.set(resultStorage);
        } else {
            m1Bytes.reset();
            aDouble.setValue(m1);
            doubleSerde.serialize(aDouble, m1BytesOutput);
            m2Bytes.reset();
            aDouble.setValue(m2);
            doubleSerde.serialize(aDouble, m2BytesOutput);
            m3Bytes.reset();
            aDouble.setValue(m3);
            doubleSerde.serialize(aDouble, m3BytesOutput);
            m4Bytes.reset();
            aDouble.setValue(m4);
            doubleSerde.serialize(aDouble, m4BytesOutput);
            countBytes.reset();
            aInt64.setValue(count);
            longSerde.serialize(aInt64, countBytesOutput);
            recordEval.evaluate(null, resultBytes);
            result.set(resultBytes);
        }
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    }
}
#method_after
protected void finishPartialResults(IPointable result) throws HyracksDataException {
    resultStorage.reset();
    try {
        // Double check that count 0 is accounted
        if (aggType == ATypeTag.SYSTEM_NULL) {
            if (GlobalConfig.DEBUG) {
                GlobalConfig.ASTERIX_LOGGER.trace("Single var statistics aggregate ran over empty input.");
            }
            resultStorage.getDataOutput().writeByte(ATypeTag.SERIALIZED_SYSTEM_NULL_TYPE_TAG);
            result.set(resultStorage);
        } else if (aggType == ATypeTag.NULL) {
            resultStorage.getDataOutput().writeByte(ATypeTag.SERIALIZED_NULL_TYPE_TAG);
            result.set(resultStorage);
        } else {
            m1Bytes.reset();
            aDouble.setValue(moments.getM1());
            doubleSerde.serialize(aDouble, m1BytesOutput);
            m2Bytes.reset();
            aDouble.setValue(moments.getM2());
            doubleSerde.serialize(aDouble, m2BytesOutput);
            countBytes.reset();
            aInt64.setValue(moments.getCount());
            longSerde.serialize(aInt64, countBytesOutput);
            recordEval.evaluate(null, resultBytes);
            result.set(resultBytes);
        }
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    }
}
#end_block

#method_before
protected void processPartialResults(IFrameTupleReference tuple) throws HyracksDataException {
    if (skipStep()) {
        return;
    }
    eval.evaluate(tuple, inputVal);
    byte[] serBytes = inputVal.getByteArray();
    int offset = inputVal.getStartOffset();
    ATypeTag typeTag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(serBytes[offset]);
    switch(typeTag) {
        case NULL:
            {
                processNull();
                break;
            }
        case SYSTEM_NULL:
            {
                // Ignore and return.
                break;
            }
        case OBJECT:
            {
                // Expected.
                aggType = ATypeTag.DOUBLE;
                int nullBitmapSize = 0;
                int offset1 = ARecordSerializerDeserializer.getFieldOffsetById(serBytes, offset, M1_FIELD_ID, nullBitmapSize, false);
                int offset2 = ARecordSerializerDeserializer.getFieldOffsetById(serBytes, offset, M2_FIELD_ID, nullBitmapSize, false);
                int offset3 = ARecordSerializerDeserializer.getFieldOffsetById(serBytes, offset, M3_FIELD_ID, nullBitmapSize, false);
                int offset4 = ARecordSerializerDeserializer.getFieldOffsetById(serBytes, offset, M4_FIELD_ID, nullBitmapSize, false);
                int offset5 = ARecordSerializerDeserializer.getFieldOffsetById(serBytes, offset, COUNT_FIELD_ID, nullBitmapSize, false);
                double temp_m1 = ADoubleSerializerDeserializer.getDouble(serBytes, offset1);
                double temp_value = ADoubleSerializerDeserializer.getDouble(serBytes, offset2);
                double temp_m3 = ADoubleSerializerDeserializer.getDouble(serBytes, offset3);
                double temp_m4 = ADoubleSerializerDeserializer.getDouble(serBytes, offset4);
                long temp_count = AInt64SerializerDeserializer.getLong(serBytes, offset5);
                double delta = temp_m1 - m1;
                long combined_count = count + temp_count;
                if (getSkewFlag()) {
                    double delta3 = delta * delta * delta;
                    if (getKurtFlag()) {
                        m4 += temp_m4 + delta3 * delta * count * temp_count * (count * count - count * temp_count + temp_count * temp_count) / (combined_count * combined_count * combined_count);
                        m4 += 6 * delta * delta * (count * count * temp_value + temp_count * temp_count * m2) / (combined_count * combined_count) + 4 * delta * (count * temp_m3 - temp_count * m3) / combined_count;
                    }
                    m3 += temp_m3 + delta3 * count * temp_count * (count - temp_count) / (combined_count * combined_count);
                    m3 += 3 * delta * (count * temp_value - temp_count * m2) / combined_count;
                }
                m1 = (count * m1 + temp_count * temp_m1) / combined_count;
                m2 += temp_value + delta * delta * count * temp_count / combined_count;
                count = combined_count;
                break;
            }
        default:
            {
                throw new UnsupportedItemTypeException(sourceLoc, "intermediate/global-single-var-statistics", serBytes[offset]);
            }
    }
}
#method_after
protected void processPartialResults(IFrameTupleReference tuple) throws HyracksDataException {
    if (skipStep()) {
        return;
    }
    eval.evaluate(tuple, inputVal);
    byte[] serBytes = inputVal.getByteArray();
    int offset = inputVal.getStartOffset();
    ATypeTag typeTag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(serBytes[offset]);
    switch(typeTag) {
        case NULL:
            processNull();
            break;
        case SYSTEM_NULL:
            // Ignore and return.
            break;
        case OBJECT:
            // Expected.
            aggType = ATypeTag.DOUBLE;
            int nullBitmapSize = 0;
            int offset1 = ARecordSerializerDeserializer.getFieldOffsetById(serBytes, offset, M1_FIELD_ID, nullBitmapSize, false);
            int offset2 = ARecordSerializerDeserializer.getFieldOffsetById(serBytes, offset, M2_FIELD_ID, nullBitmapSize, false);
            int offset3 = ARecordSerializerDeserializer.getFieldOffsetById(serBytes, offset, COUNT_FIELD_ID, nullBitmapSize, false);
            double temp_m1 = ADoubleSerializerDeserializer.getDouble(serBytes, offset1);
            double temp_m2 = ADoubleSerializerDeserializer.getDouble(serBytes, offset2);
            long temp_count = AInt64SerializerDeserializer.getLong(serBytes, offset3);
            moments.combine(temp_m1, temp_m2, temp_count);
            break;
        default:
            throw new UnsupportedItemTypeException(sourceLoc, "intermediate/global-single-var-statistics", serBytes[offset]);
    }
}
#end_block

#method_before
protected void finishStddevFinalResults(IPointable result) throws HyracksDataException {
    resultStorage.reset();
    try {
        if (count <= 1 || aggType == ATypeTag.NULL) {
            nullSerde.serialize(ANull.NULL, resultStorage.getDataOutput());
        } else {
            aDouble.setValue((Math.sqrt(m2 / (count - 1))));
            doubleSerde.serialize(aDouble, resultStorage.getDataOutput());
        }
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    }
    result.set(resultStorage);
}
#method_after
protected void finishStddevFinalResults(IPointable result) throws HyracksDataException {
    resultStorage.reset();
    try {
        if (moments.getCount() <= 1 || aggType == ATypeTag.NULL) {
            nullSerde.serialize(ANull.NULL, resultStorage.getDataOutput());
        } else {
            aDouble.setValue(Math.sqrt(moments.getM2() / (moments.getCount() - 1)));
            doubleSerde.serialize(aDouble, resultStorage.getDataOutput());
        }
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    }
    result.set(resultStorage);
}
#end_block

#method_before
@Override
public IAType computeType(ILogicalExpression expression, IVariableTypeEnvironment env, IMetadataProvider<?, ?> metadataProvider) throws AlgebricksException {
    return new ARecordType(null, new String[] { "m1", "m2", "m3", "m4", "count" }, new IAType[] { AUnionType.createNullableType(BuiltinType.ADOUBLE, "OptionalDouble"), AUnionType.createNullableType(BuiltinType.ADOUBLE, "OptionalDouble"), AUnionType.createNullableType(BuiltinType.ADOUBLE, "OptionalDouble"), AUnionType.createNullableType(BuiltinType.ADOUBLE, "OptionalDouble"), BuiltinType.AINT32 }, false);
}
#method_after
@Override
public IAType computeType(ILogicalExpression expression, IVariableTypeEnvironment env, IMetadataProvider<?, ?> metadataProvider) throws AlgebricksException {
    return new ARecordType(null, new String[] { "m1", "m2", "count" }, new IAType[] { AUnionType.createNullableType(BuiltinType.ADOUBLE, "OptionalDouble"), AUnionType.createNullableType(BuiltinType.ADOUBLE, "OptionalDouble"), BuiltinType.AINT64 }, false);
}
#end_block

#method_before
private int splitIntoRecords(String admData) throws InterruptedException {
    int p = 0, lvlCtr = 0;
    int recordCtr = 0;
    boolean inRecord = false;
    char[] charBuff = admData.toCharArray();
    for (int iter1 = 0; iter1 < charBuff.length; iter1++) {
        if (charBuff[iter1] == '{') {
            if (inRecord == false) {
                p = iter1;
                inRecord = true;
            }
            lvlCtr++;
        } else if (charBuff[iter1] == '}') {
            lvlCtr--;
        }
        if (lvlCtr == 0) {
            if (inRecord) {
                inputQ.put(admData.substring(p, iter1 + 1) + '\n');
                recordCtr++;
                inRecord = false;
            }
            p = iter1;
        }
    }
    return recordCtr;
}
#method_after
private int splitIntoRecords(String admData) throws InterruptedException {
    int p = 0;
    int lvlCtr = 0;
    int recordCtr = 0;
    boolean inRecord = false;
    char[] charBuff = admData.toCharArray();
    for (int iter1 = 0; iter1 < charBuff.length; iter1++) {
        if (charBuff[iter1] == '{') {
            if (!inRecord) {
                p = iter1;
                inRecord = true;
            }
            lvlCtr++;
        } else if (charBuff[iter1] == '}') {
            lvlCtr--;
        }
        if (lvlCtr == 0) {
            if (inRecord) {
                inputQ.put(admData.substring(p, iter1 + 1) + '\n');
                recordCtr++;
                inRecord = false;
            }
            p = iter1;
        }
    }
    return recordCtr;
}
#end_block

#method_before
@Override
public void handle(IServletRequest request, IServletResponse response) {
    PrintWriter responseWriter = response.writer();
    if (request.getHttpRequest().method() == HttpMethod.POST) {
        try {
            responseWriter.write(String.valueOf(doPost(request)));
            response.setStatus(HttpResponseStatus.OK);
        } catch (InterruptedException e) {
            LOGGER.log(Level.INFO, "exception thrown for " + request, e);
            response.setStatus(HttpResponseStatus.INTERNAL_SERVER_ERROR);
            responseWriter.write(e.toString());
        }
    } else {
        response.setStatus(HttpResponseStatus.METHOD_NOT_ALLOWED);
    }
    responseWriter.flush();
}
#method_after
@Override
public void handle(IServletRequest request, IServletResponse response) {
    PrintWriter responseWriter = response.writer();
    if (request.getHttpRequest().method() == HttpMethod.POST) {
        try {
            responseWriter.write(String.valueOf(doPost(request)));
            response.setStatus(HttpResponseStatus.OK);
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
            LOGGER.log(Level.INFO, "exception thrown for {}", request, e);
            response.setStatus(HttpResponseStatus.INTERNAL_SERVER_ERROR);
            responseWriter.write(e.toString());
        }
    } else {
        response.setStatus(HttpResponseStatus.METHOD_NOT_ALLOWED);
    }
    responseWriter.flush();
}
#end_block

#method_before
@Override
public IRecordReader<? extends char[]> createRecordReader(IHyracksTaskContext ctx, int partition) throws HyracksDataException {
    try {
        return new HttpServerRecordReader(serverAddrs.get(partition).getRight(), entryPoint, queueSize, HttpServerConfigBuilder.createDefault());
    } catch (Exception e) {
        throw new HyracksDataException(e.getMessage());
    }
}
#method_after
@Override
public IRecordReader<? extends char[]> createRecordReader(IHyracksTaskContext ctx, int partition) throws HyracksDataException {
    try {
        return new HttpServerRecordReader(serverAddrs.get(partition).getRight(), entryPoint, queueSize, HttpServerConfigBuilder.createDefault());
    } catch (Exception e) {
        throw HyracksDataException.create(e);
    }
}
#end_block

#method_before
public static List<Pair<String, Integer>> extractHostsPorts(String modeValue, IServiceContext serviceCtx, String hostsValue) throws AlgebricksException {
    try {
        List<Pair<String, Integer>> sockets = new ArrayList<>();
        String mode = modeValue.trim().toUpperCase();
        if (hostsValue == null) {
            throw new CompilationException(ErrorCode.FEED_METADATA_SOCKET_ADAPTOR_SOCKET_NOT_PROPERLY_CONFIGURED);
        }
        Map<InetAddress, Set<String>> ncMap;
        ncMap = RuntimeUtils.getNodeControllerMap((ICcApplicationContext) serviceCtx.getApplicationContext());
        List<String> ncs = RuntimeUtils.getAllNodeControllers((ICcApplicationContext) serviceCtx.getApplicationContext());
        String[] socketsArray = hostsValue.split(",");
        Random random = new Random();
        for (String socket : socketsArray) {
            String[] socketTokens = socket.split(":");
            String host = socketTokens[0].trim();
            int port = Integer.parseInt(socketTokens[1].trim());
            Pair<String, Integer> p = null;
            if (FEED_HOST_MODE_IP.equals(mode)) {
                Set<String> ncsOnIp = ncMap.get(InetAddress.getByName(host));
                if ((ncsOnIp == null) || ncsOnIp.isEmpty()) {
                    throw new CompilationException(ErrorCode.FEED_METADATA_SOCKET_ADAPTOR_SOCKET_INVALID_HOST_NC, FEED_HOST_MODE_IP, host, StringUtils.join(ncMap.keySet(), ", "));
                }
                String[] ncArray = ncsOnIp.toArray(new String[] {});
                String nc = ncArray[random.nextInt(ncArray.length)];
                p = Pair.of(nc, port);
            } else if (FEED_HOST_MODE_NC.equals(mode)) {
                p = Pair.of(host, port);
                if (!ncs.contains(host)) {
                    throw new CompilationException(ErrorCode.FEED_METADATA_SOCKET_ADAPTOR_SOCKET_INVALID_HOST_NC, FEED_HOST_MODE_NC, host, StringUtils.join(ncs, ", "));
                }
            }
            sockets.add(p);
        }
        return sockets;
    } catch (HyracksDataException | UnknownHostException e) {
        throw new AlgebricksException(e);
    }
}
#method_after
public static List<Pair<String, Integer>> extractHostsPorts(String modeValue, IServiceContext serviceCtx, String hostsValue) throws AlgebricksException {
    try {
        List<Pair<String, Integer>> sockets = new ArrayList<>();
        String mode = modeValue.trim().toUpperCase();
        if (hostsValue == null) {
            throw new CompilationException(ErrorCode.FEED_METADATA_SOCKET_ADAPTOR_SOCKET_NOT_PROPERLY_CONFIGURED);
        }
        Map<InetAddress, Set<String>> ncMap = RuntimeUtils.getNodeControllerMap((ICcApplicationContext) serviceCtx.getApplicationContext());
        List<String> ncs = RuntimeUtils.getAllNodeControllers((ICcApplicationContext) serviceCtx.getApplicationContext());
        String[] socketsArray = hostsValue.split(",");
        Random random = new Random();
        for (String socket : socketsArray) {
            String[] socketTokens = socket.split(":");
            String host = socketTokens[0].trim();
            int port = Integer.parseInt(socketTokens[1].trim());
            Pair<String, Integer> p = null;
            if (FEED_HOST_MODE_IP.equals(mode)) {
                Set<String> ncsOnIp = ncMap.get(InetAddress.getByName(host));
                if ((ncsOnIp == null) || ncsOnIp.isEmpty()) {
                    throw new CompilationException(ErrorCode.FEED_METADATA_SOCKET_ADAPTOR_SOCKET_INVALID_HOST_NC, FEED_HOST_MODE_IP, host, StringUtils.join(ncMap.keySet(), ", "));
                }
                String[] ncArray = ncsOnIp.toArray(new String[] {});
                String nc = ncArray[random.nextInt(ncArray.length)];
                p = Pair.of(nc, port);
            } else if (FEED_HOST_MODE_NC.equals(mode)) {
                p = Pair.of(host, port);
                if (!ncs.contains(host)) {
                    throw new CompilationException(ErrorCode.FEED_METADATA_SOCKET_ADAPTOR_SOCKET_INVALID_HOST_NC, FEED_HOST_MODE_NC, host, StringUtils.join(ncs, ", "));
                }
            }
            sockets.add(p);
        }
        return sockets;
    } catch (HyracksDataException | UnknownHostException e) {
        throw new AlgebricksException(e);
    }
}
#end_block

#method_before
@Override
public boolean rewritePost(Mutable<ILogicalOperator> opRef, IOptimizationContext context) throws AlgebricksException {
    AbstractLogicalOperator op = (AbstractLogicalOperator) opRef.getValue();
    // current opperator is join
    if (op.getOperatorTag() != LogicalOperatorTag.INNERJOIN && op.getOperatorTag() != LogicalOperatorTag.LEFTOUTERJOIN) {
        return false;
    }
    // Find GET_ITEM function.
    AbstractBinaryJoinOperator joinOp = (AbstractBinaryJoinOperator) op;
    Mutable<ILogicalExpression> expRef = joinOp.getCondition();
    Mutable<ILogicalExpression> getItemExprRef = getSimilarityExpression(expRef);
    if (getItemExprRef == null) {
        return false;
    }
    // Check if the GET_ITEM function is on one of the supported similarity-check functions.
    AbstractFunctionCallExpression getItemFuncExpr = (AbstractFunctionCallExpression) getItemExprRef.getValue();
    Mutable<ILogicalExpression> argRef = getItemFuncExpr.getArguments().get(0);
    AbstractFunctionCallExpression simFuncExpr = (AbstractFunctionCallExpression) argRef.getValue();
    // Currently, we limit the prefix based fuzzy join times so as to restrict the memory assumption.
    if (!simFuncs.contains(simFuncExpr.getFunctionIdentifier())) {
        return false;
    }
    // Skip this rule based on annotations.
    if (simFuncExpr.getAnnotations().containsKey(IndexedNLJoinExpressionAnnotation.INSTANCE)) {
        return false;
    }
    // Get both input branches of fuzzy join
    List<Mutable<ILogicalOperator>> inputOps = joinOp.getInputs();
    ILogicalOperator leftInputOp = inputOps.get(0).getValue();
    ILogicalOperator rightInputOp = inputOps.get(1).getValue();
    List<Mutable<ILogicalExpression>> inputExps = simFuncExpr.getArguments();
    if (inputExps.size() != 3) {
        return false;
    }
    // Fuzzy similarity function extraction
    ILogicalExpression inputExp0 = inputExps.get(0).getValue();
    ILogicalExpression inputExp1 = inputExps.get(1).getValue();
    ILogicalExpression inputExp2 = inputExps.get(2).getValue();
    // left and right expressions are variables
    if (inputExp0.getExpressionTag() != LogicalExpressionTag.VARIABLE || inputExp1.getExpressionTag() != LogicalExpressionTag.VARIABLE || inputExp2.getExpressionTag() != LogicalExpressionTag.CONSTANT) {
        return false;
    }
    LogicalVariable inputVar0 = ((VariableReferenceExpression) inputExp0).getVariableReference();
    LogicalVariable inputVar1 = ((VariableReferenceExpression) inputExp1).getVariableReference();
    LogicalVariable leftInputVar;
    LogicalVariable rightInputVar;
    Collection<LogicalVariable> liveVars = new HashSet<>();
    VariableUtilities.getLiveVariables(leftInputOp, liveVars);
    if (liveVars.contains(inputVar0)) {
        leftInputVar = inputVar0;
        rightInputVar = inputVar1;
    } else {
        leftInputVar = inputVar1;
        rightInputVar = inputVar0;
    }
    List<LogicalVariable> leftInputPKs = findPrimaryKeysInSubplan(liveVars, context);
    liveVars.clear();
    VariableUtilities.getLiveVariables(rightInputOp, liveVars);
    List<LogicalVariable> rightInputPKs = findPrimaryKeysInSubplan(liveVars, context);
    boolean regardAsSelect = false;
    Set<LogicalVariable> currentPK = new HashSet<>();
    currentPK.addAll(leftInputPKs);
    currentPK.addAll(rightInputPKs);
    for (int i = 0; i < previousPK.size(); i++) {
        if (previousPK.get(i).containsAll(currentPK) && currentPK.containsAll(previousPK.get(i))) {
            regardAsSelect = true;
        }
    }
    if (regardAsSelect) {
        return false;
    }
    previousPK.add(currentPK);
    // Avoid the duplicated pk generation in findPrimaryKeysInSubplan, especially for multiway fuzzy join.
    IsomorphismUtilities.mergeHomogeneousPK(leftInputOp, leftInputPKs);
    // Bail if primary keys could not be inferred.
    if (leftInputPKs == null || rightInputPKs == null) {
        return false;
    }
    IAType leftType = (IAType) context.getOutputTypeEnvironment(leftInputOp).getVarType(leftInputVar);
    IAType rightType = (IAType) context.getOutputTypeEnvironment(rightInputOp).getVarType(rightInputVar);
    // left-hand side and right-hand side of "~=" has the same type
    IAType left2 = TypeComputeUtils.getActualType(leftType);
    IAType right2 = TypeComputeUtils.getActualType(rightType);
    if (!left2.deepEqual(right2)) {
        return false;
    }
    // 
    // -- - FIRE - --
    // 
    AqlMetadataProvider metadataProvider = ((AqlMetadataProvider) context.getMetadataProvider());
    FunctionIdentifier funcId = FuzzyUtils.getTokenizer(leftType.getTypeTag());
    String tokenizer;
    if (funcId == null) {
        tokenizer = "";
    } else {
        tokenizer = funcId.getName();
    }
    String simFunction = FuzzyUtils.getSimFunction(simFuncExpr.getFunctionIdentifier());
    float simThreshold;
    ConstantExpression constExpr = (ConstantExpression) inputExp2;
    AsterixConstantValue constVal = (AsterixConstantValue) constExpr.getValue();
    if (constVal.getObject() instanceof AFloat) {
        simThreshold = ((AFloat) constVal.getObject()).getFloatValue();
    } else {
        simThreshold = FuzzyUtils.getSimThreshold(metadataProvider);
    }
    // finalize AQL+ query
    String prepareJoin;
    switch(joinOp.getJoinKind()) {
        case INNER:
            {
                prepareJoin = "join" + AQLPLUS;
                break;
            }
        case LEFT_OUTER:
            {
                prepareJoin = "loj" + AQLPLUS;
                break;
            }
        default:
            {
                throw new IllegalStateException();
            }
    }
    String groupByLeft = "";
    String joinCondLeft = "";
    // at extracting those mapping from prefix tokens to tuples
    for (int i = 0; i < leftInputPKs.size(); i++) {
        if (i > 0) {
            groupByLeft += ", ";
            joinCondLeft += " and ";
        }
        groupByLeft += String.format(Locale.US, GROUPBY_LEFT, nBranches, i, nBranches, i);
        joinCondLeft += String.format(Locale.US, JOIN_COND_LEFT, nBranches, i, nBranches, i);
    }
    String groupByRight = "";
    String joinCondRight = "";
    for (int i = 0; i < rightInputPKs.size(); i++) {
        if (i > 0) {
            groupByRight += ", ";
            joinCondRight += " and ";
        }
        groupByRight += String.format(Locale.US, GROUPBY_RIGHT, nBranches, i, nBranches, i);
        joinCondRight += String.format(Locale.US, JOIN_COND_RIGHT, nBranches, i, nBranches, i);
    }
    // Step3. Translate the tokenizer, join condition and group by (shared token) as shown
    // in the above AQLPLUS template.
    String aqlPlus = String.format(Locale.US, prepareJoin, nBranches, nBranches, nBranches, tokenizer, nBranches, nBranches, nBranches, tokenizer, nBranches, simFunction, simThreshold, nBranches, tokenizer, nBranches, nBranches, nBranches, tokenizer, nBranches, simFunction, simThreshold, simFunction, simThreshold, simThreshold, groupByLeft, groupByRight, joinCondRight, joinCondLeft);
    Counter counter = new Counter(context.getVarCounter());
    int contextCounter = counter.get();
    // The translator will compile metadata internally. Run this compilation
    // under the same transaction id as the "outer" compilation.
    AqlPlusExpressionToPlanTranslator translator = new AqlPlusExpressionToPlanTranslator(metadataProvider.getJobId(), metadataProvider, counter, null, null);
    LogicalOperatorDeepCopyWithNewVariablesVisitor copyVisitor = new LogicalOperatorDeepCopyWithNewVariablesVisitor(context, context);
    // Step3.1. Substitute the variable references of the above AQLPLUS template with
    // the actually attached variables.
    translator.addOperatorToMetaScope(new VarIdentifier("#LEFT_" + nBranches + "_0"), leftInputOp);
    translator.addVariableToMetaScope(new VarIdentifier("$$LEFT_" + nBranches + "_0"), leftInputVar);
    for (int i = 0; i < leftInputPKs.size(); i++) {
        translator.addVariableToMetaScope(new VarIdentifier("$$LEFTPK_" + nBranches + "_0_" + i), leftInputPKs.get(i));
    }
    // Step3.2. right side again.
    translator.addOperatorToMetaScope(new VarIdentifier("#RIGHT_" + nBranches + "_0"), rightInputOp);
    translator.addVariableToMetaScope(new VarIdentifier("$$RIGHT_" + nBranches + "_0"), rightInputVar);
    for (int i = 0; i < rightInputPKs.size(); i++) {
        translator.addVariableToMetaScope(new VarIdentifier("$$RIGHTPK_" + nBranches + "_0_" + i), rightInputPKs.get(i));
    }
    // Step3.3. the suffix 0-3 is used for identifying the different level of variable references.
    ILogicalOperator leftInputOpCopy = copyVisitor.deepCopy(leftInputOp);
    translator.addOperatorToMetaScope(new VarIdentifier("#LEFT_" + nBranches + "_1"), leftInputOpCopy);
    LogicalVariable leftInputVarCopy = copyVisitor.varCopy(leftInputVar);
    translator.addVariableToMetaScope(new VarIdentifier("$$LEFT_" + nBranches + "_1"), leftInputVarCopy);
    for (int i = 0; i < leftInputPKs.size(); i++) {
        leftInputVarCopy = copyVisitor.varCopy(leftInputPKs.get(i));
        translator.addVariableToMetaScope(new VarIdentifier("$$LEFTPK_" + nBranches + "_1_" + i), leftInputVarCopy);
    }
    copyVisitor.updatePrimaryKeys(context);
    copyVisitor.reset();
    // TODO pick side to run Stage 1, currently always picks RIGHT side
    for (int i = 1; i < 4; i++) {
        translator.addOperatorToMetaScope(new VarIdentifier("#RIGHT_" + nBranches + "_" + i), copyVisitor.deepCopy(rightInputOp));
        LogicalVariable rightInputVarCopy = copyVisitor.varCopy(rightInputVar);
        translator.addVariableToMetaScope(new VarIdentifier("$$RIGHT_" + nBranches + "_" + i), rightInputVarCopy);
        for (int j = 0; j < rightInputPKs.size(); j++) {
            rightInputVarCopy = copyVisitor.varCopy(rightInputPKs.get(j));
            translator.addVariableToMetaScope(new VarIdentifier("$$RIGHTPK_" + nBranches + "_" + i + "_" + j), rightInputVarCopy);
        }
        copyVisitor.updatePrimaryKeys(context);
        copyVisitor.reset();
    }
    int incrementedCounter = context.getVarCounter() - contextCounter;
    counter.set(counter.get() + incrementedCounter);
    AQLPlusParser parser = new AQLPlusParser(new StringReader(aqlPlus));
    parser.initScope();
    parser.setVarCounter(counter);
    List<Clause> clauses;
    try {
        clauses = parser.Clauses();
    } catch (ParseException e) {
        throw new AlgebricksException(e);
    }
    // Step 4. The essential substitution with translator.
    ILogicalPlan plan;
    try {
        plan = translator.translate(clauses);
    } catch (AsterixException e) {
        throw new AlgebricksException(e);
    }
    context.setVarCounter(counter.get());
    // Step 5. Bind the plan to the father op referred by the below opRef.
    ILogicalOperator outputOp = plan.getRoots().get(0).getValue();
    SelectOperator extraSelect = null;
    if (getItemExprRef != expRef) {
        // more than one join condition
        getItemExprRef.setValue(ConstantExpression.TRUE);
        switch(joinOp.getJoinKind()) {
            case INNER:
                {
                    extraSelect = new SelectOperator(expRef, false, null);
                    extraSelect.getInputs().add(new MutableObject<>(outputOp));
                    outputOp = extraSelect;
                    break;
                }
            case LEFT_OUTER:
                {
                    LeftOuterJoinOperator topJoin = (LeftOuterJoinOperator) outputOp;
                    setConditionForLeftOuterJoin(topJoin, expRef);
                    break;
                }
            default:
                {
                    throw new IllegalStateException();
                }
        }
    }
    opRef.setValue(outputOp);
    OperatorPropertiesUtil.typeOpRec(opRef, context);
    nBranches++;
    return true;
}
#method_after
@Override
public boolean rewritePost(Mutable<ILogicalOperator> opRef, IOptimizationContext context) throws AlgebricksException {
    AbstractLogicalOperator op = (AbstractLogicalOperator) opRef.getValue();
    // current operator should be a join.
    if (op.getOperatorTag() != LogicalOperatorTag.INNERJOIN && op.getOperatorTag() != LogicalOperatorTag.LEFTOUTERJOIN) {
        return false;
    }
    // Finds GET_ITEM function in the join condition.
    AbstractBinaryJoinOperator joinOp = (AbstractBinaryJoinOperator) op;
    Mutable<ILogicalExpression> exprRef = joinOp.getCondition();
    Mutable<ILogicalExpression> getItemExprRef = getSimilarityExpression(exprRef);
    if (getItemExprRef == null) {
        return false;
    }
    // Checks if the GET_ITEM function is on the one of the supported similarity-check functions.
    AbstractFunctionCallExpression getItemFuncExpr = (AbstractFunctionCallExpression) getItemExprRef.getValue();
    Mutable<ILogicalExpression> argRef = getItemFuncExpr.getArguments().get(0);
    AbstractFunctionCallExpression simFuncExpr = (AbstractFunctionCallExpression) argRef.getValue();
    if (!simFuncs.contains(simFuncExpr.getFunctionIdentifier())) {
        return false;
    }
    // Skips this rule based on annotations.
    if (simFuncExpr.getAnnotations().containsKey(IndexedNLJoinExpressionAnnotation.INSTANCE)) {
        return false;
    }
    // Gets both input branches of fuzzy join.
    List<Mutable<ILogicalOperator>> inputOps = joinOp.getInputs();
    ILogicalOperator leftInputOp = inputOps.get(0).getValue();
    ILogicalOperator rightInputOp = inputOps.get(1).getValue();
    List<Mutable<ILogicalExpression>> inputExprs = simFuncExpr.getArguments();
    if (inputExprs.size() != 3) {
        return false;
    }
    // Extracts Fuzzy similarity function.
    ILogicalExpression leftOperatingExpr = inputExprs.get(0).getValue();
    ILogicalExpression rightOperatingExpr = inputExprs.get(1).getValue();
    ILogicalExpression thresholdConstantExpr = inputExprs.get(2).getValue();
    // left and right expressions should be variables.
    if (leftOperatingExpr.getExpressionTag() != LogicalExpressionTag.VARIABLE || rightOperatingExpr.getExpressionTag() != LogicalExpressionTag.VARIABLE || thresholdConstantExpr.getExpressionTag() != LogicalExpressionTag.CONSTANT) {
        return false;
    }
    LogicalVariable inputVar0 = ((VariableReferenceExpression) leftOperatingExpr).getVariableReference();
    LogicalVariable inputVar1 = ((VariableReferenceExpression) rightOperatingExpr).getVariableReference();
    LogicalVariable leftInputVar;
    LogicalVariable rightInputVar;
    Collection<LogicalVariable> liveVars = new HashSet<>();
    VariableUtilities.getLiveVariables(leftInputOp, liveVars);
    if (liveVars.contains(inputVar0)) {
        leftInputVar = inputVar0;
        rightInputVar = inputVar1;
    } else {
        leftInputVar = inputVar1;
        rightInputVar = inputVar0;
    }
    // leftInputPKs in currrentPKs keeps all PKs derived from the left branch in the current similarity fuzzyjoin.
    List<LogicalVariable> leftInputPKs = findPrimaryKeysInSubplan(liveVars, context);
    liveVars.clear();
    VariableUtilities.getLiveVariables(rightInputOp, liveVars);
    // rightInputPKs in currentPKs keeps all PKs derived from the right branch in the current similarity fuzzyjoin.
    List<LogicalVariable> rightInputPKs = findPrimaryKeysInSubplan(liveVars, context);
    IAType leftType = (IAType) context.getOutputTypeEnvironment(leftInputOp).getVarType(leftInputVar);
    if (!isPrefixFuzzyJoin(context, leftInputOp, rightInputOp, rightInputVar, leftInputPKs, rightInputPKs, leftType)) {
        return false;
    }
    // 
    // -- - FIRE - --
    // 
    MetadataProvider metadataProvider = ((MetadataProvider) context.getMetadataProvider());
    // Steps 1 and 2. Generate the prefix-based fuzzy jon template.
    String aqlPlus = generateAqlTemplate(metadataProvider, joinOp, simFuncExpr, leftInputPKs, leftType, rightInputPKs, thresholdConstantExpr);
    // Steps 3 and 4. Generate the prefix-based fuzzy join subplan.
    ILogicalOperator outputOp = generatePrefixFuzzyJoinSubplan(context, metadataProvider, aqlPlus, leftInputOp, leftInputPKs, leftInputVar, rightInputOp, rightInputPKs, rightInputVar);
    // Step 5. Bind the plan to the parent op referred by the following opRef.
    SelectOperator extraSelect;
    if (getItemExprRef != exprRef) {
        // more than one join condition
        getItemExprRef.setValue(ConstantExpression.TRUE);
        switch(joinOp.getJoinKind()) {
            case INNER:
                {
                    extraSelect = new SelectOperator(exprRef, false, null);
                    extraSelect.setSourceLocation(exprRef.getValue().getSourceLocation());
                    extraSelect.getInputs().add(new MutableObject<>(outputOp));
                    outputOp = extraSelect;
                    break;
                }
            case LEFT_OUTER:
                {
                    LeftOuterJoinOperator topJoin = (LeftOuterJoinOperator) outputOp;
                    setConditionForLeftOuterJoin(topJoin, exprRef);
                    break;
                }
            default:
                {
                    throw new IllegalStateException();
                }
        }
    }
    opRef.setValue(outputOp);
    OperatorPropertiesUtil.typeOpRec(opRef, context);
    return true;
}
#end_block

#method_before
private void setConditionForLeftOuterJoin(LeftOuterJoinOperator topJoin, Mutable<ILogicalExpression> expRef) {
    // Combine the conditions of top join of aqlplus plan and the original join
    AbstractFunctionCallExpression andFunc = new ScalarFunctionCallExpression(FunctionUtil.getFunctionInfo(AlgebricksBuiltinFunctions.AND));
    List<Mutable<ILogicalExpression>> conjs = new ArrayList<>();
    if (topJoin.getCondition().getValue().splitIntoConjuncts(conjs)) {
        andFunc.getArguments().addAll(conjs);
    } else {
        andFunc.getArguments().add(new MutableObject<>(topJoin.getCondition().getValue()));
    }
    List<Mutable<ILogicalExpression>> conjs2 = new ArrayList<>();
    if (expRef.getValue().splitIntoConjuncts(conjs2)) {
        andFunc.getArguments().addAll(conjs2);
    } else {
        andFunc.getArguments().add(expRef);
    }
    topJoin.getCondition().setValue(andFunc);
}
#method_after
// Since the generatePrefixFuzzyJoinSubplan generates the prefix-based join operators for the partial simJoin
// of expRef, we need to add the full condition expRef\getItemExprRef into the top-level operator of the plan.
// Notice: Any composite select on leftOuterJoin with fuzzyjoin condition inlined can be regarded as its example.
private void setConditionForLeftOuterJoin(LeftOuterJoinOperator topJoin, Mutable<ILogicalExpression> expRef) {
    // Combine the conditions of top join of aqlplus plan and the original join
    AbstractFunctionCallExpression andFunc = new ScalarFunctionCallExpression(FunctionUtil.getFunctionInfo(AlgebricksBuiltinFunctions.AND));
    List<Mutable<ILogicalExpression>> conjs = new ArrayList<>();
    if (topJoin.getCondition().getValue().splitIntoConjuncts(conjs)) {
        andFunc.getArguments().addAll(conjs);
    } else {
        andFunc.getArguments().add(new MutableObject<>(topJoin.getCondition().getValue()));
    }
    List<Mutable<ILogicalExpression>> conjs2 = new ArrayList<>();
    if (expRef.getValue().splitIntoConjuncts(conjs2)) {
        andFunc.getArguments().addAll(conjs2);
    } else {
        andFunc.getArguments().add(expRef);
    }
    topJoin.getCondition().setValue(andFunc);
}
#end_block

#method_before
private Mutable<ILogicalExpression> getSimilarityExpression(Mutable<ILogicalExpression> expRef) {
    ILogicalExpression exp = expRef.getValue();
    if (exp.getExpressionTag() == LogicalExpressionTag.FUNCTION_CALL) {
        AbstractFunctionCallExpression funcExpr = (AbstractFunctionCallExpression) exp;
        if (funcExpr.getFunctionIdentifier().equals(AsterixBuiltinFunctions.GET_ITEM)) {
            return expRef;
        }
        if (funcExpr.getFunctionIdentifier().equals(AlgebricksBuiltinFunctions.AND)) {
            for (Mutable<ILogicalExpression> arg : funcExpr.getArguments()) {
                Mutable<ILogicalExpression> expRefRet = getSimilarityExpression(arg);
                if (expRefRet != null) {
                    return expRefRet;
                }
            }
        }
    }
    return null;
}
#method_after
private Mutable<ILogicalExpression> getSimilarityExpression(Mutable<ILogicalExpression> exprRef) {
    ILogicalExpression exp = exprRef.getValue();
    if (exp.getExpressionTag() == LogicalExpressionTag.FUNCTION_CALL) {
        AbstractFunctionCallExpression funcExpr = (AbstractFunctionCallExpression) exp;
        if (funcExpr.getFunctionIdentifier().equals(BuiltinFunctions.GET_ITEM)) {
            return exprRef;
        }
        if (funcExpr.getFunctionIdentifier().equals(AlgebricksBuiltinFunctions.AND)) {
            for (Mutable<ILogicalExpression> arg : funcExpr.getArguments()) {
                Mutable<ILogicalExpression> expRefRet = getSimilarityExpression(arg);
                if (expRefRet != null) {
                    return expRefRet;
                }
            }
        }
    }
    return null;
}
#end_block

#method_before
public static FunctionIdentifier getTokenizer(ATypeTag inputTag) {
    switch(inputTag) {
        case STRING:
            return AsterixBuiltinFunctions.COUNTHASHED_WORD_TOKENS;
        case UNORDEREDLIST:
        case ORDEREDLIST:
        case UNION:
        case ANY:
            return null;
        default:
            throw new NotImplementedException("No tokenizer for type " + inputTag);
    }
}
#method_after
public static FunctionIdentifier getTokenizer(ATypeTag inputTag) {
    switch(inputTag) {
        case STRING:
            return BuiltinFunctions.COUNTHASHED_WORD_TOKENS;
        case MULTISET:
        case ARRAY:
        case UNION:
        case ANY:
            return null;
        default:
            throw new NotImplementedException("No tokenizer for type " + inputTag);
    }
}
#end_block

#method_before
public static float getSimThreshold(AqlMetadataProvider metadata) {
    float simThreshold = JACCARD_DEFAULT_SIM_THRESHOLD;
    String simThresholValue = metadata.getPropertyValue(SIM_THRESHOLD_PROP_NAME);
    if (simThresholValue != null) {
        simThreshold = Float.parseFloat(simThresholValue);
    }
    return simThreshold;
}
#method_after
public static IAObject getSimThreshold(MetadataProvider metadata, String simFuncName) {
    String simThresholValue = metadata.getProperty(SIM_THRESHOLD_PROP_NAME);
    IAObject ret = null;
    if (simFuncName.equals(JACCARD_FUNCTION_NAME)) {
        if (simThresholValue != null) {
            float jaccThresh = Float.parseFloat(simThresholValue);
            ret = new AFloat(jaccThresh);
        } else {
            ret = new AFloat(JACCARD_DEFAULT_SIM_THRESHOLD);
        }
    } else if (simFuncName.equals(EDIT_DISTANCE_FUNCTION_NAME)) {
        if (simThresholValue != null) {
            int edThresh = Integer.parseInt(simThresholValue);
            ret = new AInt32(edThresh);
        } else {
            ret = new AFloat(EDIT_DISTANCE_DEFAULT_SIM_THRESHOLD);
        }
    }
    return ret;
}
#end_block

#method_before
public static FunctionIdentifier getFunctionIdentifier(String simFuncName) {
    if (simFuncName.equals(JACCARD_FUNCTION_NAME)) {
        return AsterixBuiltinFunctions.SIMILARITY_JACCARD;
    } else if (simFuncName.equals(EDIT_DISTANCE_FUNCTION_NAME)) {
        return AsterixBuiltinFunctions.EDIT_DISTANCE;
    }
    return null;
}
#method_after
public static FunctionIdentifier getFunctionIdentifier(String simFuncName) {
    if (simFuncName.equals(JACCARD_FUNCTION_NAME)) {
        return BuiltinFunctions.SIMILARITY_JACCARD;
    } else if (simFuncName.equals(EDIT_DISTANCE_FUNCTION_NAME)) {
        return BuiltinFunctions.EDIT_DISTANCE;
    }
    return null;
}
#end_block

#method_before
public static String getSimFunction(FunctionIdentifier simFuncId) {
    if (simFuncId.equals(AsterixBuiltinFunctions.SIMILARITY_JACCARD) || simFuncId.equals(AsterixBuiltinFunctions.SIMILARITY_JACCARD_CHECK)) {
        return JACCARD_FUNCTION_NAME;
    } else if (simFuncId.equals(AsterixBuiltinFunctions.EDIT_DISTANCE) || simFuncId.equals(AsterixBuiltinFunctions.EDIT_DISTANCE_CHECK)) {
        return EDIT_DISTANCE_FUNCTION_NAME;
    }
    return null;
}
#method_after
public static String getSimFunction(MetadataProvider metadata) {
    String simFunction = metadata.getProperty(SIM_FUNCTION_PROP_NAME);
    if (simFunction == null) {
        simFunction = DEFAULT_SIM_FUNCTION;
    }
    simFunction = simFunction.toLowerCase();
    return simFunction;
}
#end_block

#method_before
public static String getSimFunction(FunctionIdentifier simFuncId) {
    if (simFuncId.equals(AsterixBuiltinFunctions.SIMILARITY_JACCARD) || simFuncId.equals(AsterixBuiltinFunctions.SIMILARITY_JACCARD_CHECK)) {
        return JACCARD_FUNCTION_NAME;
    } else if (simFuncId.equals(AsterixBuiltinFunctions.EDIT_DISTANCE) || simFuncId.equals(AsterixBuiltinFunctions.EDIT_DISTANCE_CHECK)) {
        return EDIT_DISTANCE_FUNCTION_NAME;
    }
    return null;
}
#method_after
public static String getSimFunction(FunctionIdentifier simFuncId) {
    if (simFuncId.equals(BuiltinFunctions.SIMILARITY_JACCARD) || simFuncId.equals(BuiltinFunctions.SIMILARITY_JACCARD_CHECK)) {
        return JACCARD_FUNCTION_NAME;
    } else if (simFuncId.equals(BuiltinFunctions.EDIT_DISTANCE) || simFuncId.equals(BuiltinFunctions.EDIT_DISTANCE_CHECK)) {
        return EDIT_DISTANCE_FUNCTION_NAME;
    }
    return null;
}
#end_block

#method_before
public static final List<IAlgebraicRewriteRule> buildNormalizationRuleCollection() {
    List<IAlgebraicRewriteRule> normalization = new LinkedList<>();
    normalization.add(new ResolveVariableRule());
    normalization.add(new IntroduceUnnestForCollectionToSequenceRule());
    normalization.add(new EliminateSubplanRule());
    normalization.add(new EnforceOrderByAfterSubplan());
    normalization.add(new PushAggFuncIntoStandaloneAggregateRule());
    normalization.add(new BreakSelectIntoConjunctsRule());
    normalization.add(new ExtractGbyExpressionsRule());
    normalization.add(new ExtractDistinctByExpressionsRule());
    normalization.add(new ExtractOrderExpressionsRule());
    // IntroduceStaticTypeCastRule should go before
    // IntroduceDynamicTypeCastRule to
    // avoid unnecessary dynamic casting
    normalization.add(new IntroduceStaticTypeCastForInsertRule());
    normalization.add(new IntroduceDynamicTypeCastRule());
    normalization.add(new IntroduceDynamicTypeCastForExternalFunctionRule());
    normalization.add(new IntroduceEnforcedListTypeRule());
    normalization.add(new ExtractCommonExpressionsRule());
    normalization.add(new ConstantFoldingRule());
    normalization.add(new RemoveRedundantSelectRule());
    normalization.add(new UnnestToDataScanRule());
    normalization.add(new MetaFunctionToMetaVariableRule());
    normalization.add(new FuzzyEqRule());
    normalization.add(new SimilarityCheckRule());
    return normalization;
}
#method_after
public static final List<IAlgebraicRewriteRule> buildNormalizationRuleCollection(ICcApplicationContext appCtx) {
    List<IAlgebraicRewriteRule> normalization = new LinkedList<>();
    normalization.add(new CheckInsertUpsertReturningRule());
    normalization.add(new IntroduceUnnestForCollectionToSequenceRule());
    normalization.add(new EliminateSubplanRule());
    normalization.add(new EnforceOrderByAfterSubplan());
    normalization.add(new BreakSelectIntoConjunctsRule());
    normalization.add(new ExtractGbyExpressionsRule());
    normalization.add(new ExtractDistinctByExpressionsRule());
    normalization.add(new ExtractOrderExpressionsRule());
    // IntroduceStaticTypeCastRule should go before
    // IntroduceDynamicTypeCastRule to
    // avoid unnecessary dynamic casting
    normalization.add(new IntroduceStaticTypeCastForInsertRule());
    normalization.add(new IntroduceDynamicTypeCastRule());
    normalization.add(new IntroduceDynamicTypeCastForExternalFunctionRule());
    normalization.add(new IntroduceEnforcedListTypeRule());
    // Perform constant folding before common expression extraction
    normalization.add(new ConstantFoldingRule(appCtx));
    normalization.add(new ExtractCommonExpressionsRule());
    // Let PushAggFuncIntoStandaloneAggregateRule run after ExtractCommonExpressionsRule
    // so that PushAggFunc can happen in fewer places.
    normalization.add(new PushAggFuncIntoStandaloneAggregateRule());
    normalization.add(new ListifyUnnestingFunctionRule());
    normalization.add(new RemoveRedundantSelectRule());
    normalization.add(new UnnestToDataScanRule());
    normalization.add(new MetaFunctionToMetaVariableRule());
    normalization.add(new FuzzyEqRule());
    normalization.add(new SimilarityCheckRule());
    return normalization;
}
#end_block

#method_before
public static final List<IAlgebraicRewriteRule> buildCondPushDownAndJoinInferenceRuleCollection() {
    List<IAlgebraicRewriteRule> condPushDownAndJoinInference = new LinkedList<>();
    condPushDownAndJoinInference.add(new PushSelectDownRule());
    condPushDownAndJoinInference.add(new PushSortDownRule());
    condPushDownAndJoinInference.add(new RemoveRedundantListifyRule());
    condPushDownAndJoinInference.add(new CancelUnnestWithNestedListifyRule());
    condPushDownAndJoinInference.add(new SimpleUnnestToProductRule());
    condPushDownAndJoinInference.add(new ComplexUnnestToProductRule());
    condPushDownAndJoinInference.add(new DisjunctivePredicateToJoinRule());
    condPushDownAndJoinInference.add(new PushSelectIntoJoinRule());
    condPushDownAndJoinInference.add(new IntroJoinInsideSubplanRule());
    condPushDownAndJoinInference.add(new PushMapOperatorDownThroughProductRule());
    condPushDownAndJoinInference.add(new PushSubplanWithAggregateDownThroughProductRule());
    condPushDownAndJoinInference.add(new SubplanOutOfGroupRule());
    condPushDownAndJoinInference.add(new AsterixExtractFunctionsFromJoinConditionRule());
    condPushDownAndJoinInference.add(new RemoveRedundantVariablesRule());
    condPushDownAndJoinInference.add(new AsterixInlineVariablesRule());
    condPushDownAndJoinInference.add(new RemoveUnusedAssignAndAggregateRule());
    condPushDownAndJoinInference.add(new FactorRedundantGroupAndDecorVarsRule());
    condPushDownAndJoinInference.add(new PushAggregateIntoGroupbyRule());
    condPushDownAndJoinInference.add(new EliminateSubplanRule());
    condPushDownAndJoinInference.add(new PushProperJoinThroughProduct());
    condPushDownAndJoinInference.add(new PushGroupByThroughProduct());
    condPushDownAndJoinInference.add(new NestGroupByRule());
    condPushDownAndJoinInference.add(new EliminateGroupByEmptyKeyRule());
    condPushDownAndJoinInference.add(new PushSubplanIntoGroupByRule());
    condPushDownAndJoinInference.add(new NestedSubplanToJoinRule());
    condPushDownAndJoinInference.add(new EliminateSubplanWithInputCardinalityOneRule());
    // The following rule should be fired after PushAggregateIntoGroupbyRule because
    // pulling invariants out of a subplan will make PushAggregateIntoGroupby harder.
    condPushDownAndJoinInference.add(new AsterixMoveFreeVariableOperatorOutOfSubplanRule());
    return condPushDownAndJoinInference;
}
#method_after
public static final List<IAlgebraicRewriteRule> buildCondPushDownAndJoinInferenceRuleCollection() {
    List<IAlgebraicRewriteRule> condPushDownAndJoinInference = new LinkedList<>();
    condPushDownAndJoinInference.add(new PushSelectDownRule());
    condPushDownAndJoinInference.add(new PushSortDownRule());
    condPushDownAndJoinInference.add(new RemoveRedundantListifyRule());
    condPushDownAndJoinInference.add(new CancelUnnestWithNestedListifyRule());
    condPushDownAndJoinInference.add(new SimpleUnnestToProductRule());
    condPushDownAndJoinInference.add(new ComplexUnnestToProductRule());
    condPushDownAndJoinInference.add(new DisjunctivePredicateToJoinRule());
    condPushDownAndJoinInference.add(new PushSelectIntoJoinRule());
    condPushDownAndJoinInference.add(new IntroJoinInsideSubplanRule());
    // Apply RemoveCartesianProductWithEmptyBranchRule before PushMapOperatorDownThroughProductRule
    // to avoid that a constant assignment gets pushed into an empty branch.
    condPushDownAndJoinInference.add(new RemoveCartesianProductWithEmptyBranchRule());
    condPushDownAndJoinInference.add(new PushMapOperatorDownThroughProductRule());
    condPushDownAndJoinInference.add(new PushSubplanWithAggregateDownThroughProductRule());
    condPushDownAndJoinInference.add(new SubplanOutOfGroupRule());
    condPushDownAndJoinInference.add(new AsterixExtractFunctionsFromJoinConditionRule());
    condPushDownAndJoinInference.add(new RemoveRedundantVariablesRule());
    condPushDownAndJoinInference.add(new AsterixInlineVariablesRule());
    condPushDownAndJoinInference.add(new RemoveUnusedAssignAndAggregateRule());
    condPushDownAndJoinInference.add(new FactorRedundantGroupAndDecorVarsRule());
    condPushDownAndJoinInference.add(new PushAggregateIntoNestedSubplanRule());
    condPushDownAndJoinInference.add(new EliminateSubplanRule());
    condPushDownAndJoinInference.add(new PushProperJoinThroughProduct());
    condPushDownAndJoinInference.add(new PushGroupByThroughProduct());
    condPushDownAndJoinInference.add(new NestGroupByRule());
    condPushDownAndJoinInference.add(new EliminateGroupByEmptyKeyRule());
    condPushDownAndJoinInference.add(new PushSubplanIntoGroupByRule());
    condPushDownAndJoinInference.add(new NestedSubplanToJoinRule());
    condPushDownAndJoinInference.add(new EliminateSubplanWithInputCardinalityOneRule());
    // The following rule should be fired after PushAggregateIntoNestedSubplanRule because
    // pulling invariants out of a subplan will make PushAggregateIntoGroupby harder.
    condPushDownAndJoinInference.add(new AsterixMoveFreeVariableOperatorOutOfSubplanRule());
    return condPushDownAndJoinInference;
}
#end_block

#method_before
public static final List<IAlgebraicRewriteRule> buildLoadFieldsRuleCollection() {
    List<IAlgebraicRewriteRule> fieldLoads = new LinkedList<>();
    fieldLoads.add(new LoadRecordFieldsRule());
    fieldLoads.add(new PushFieldAccessRule());
    // fieldLoads.add(new ByNameToByHandleFieldAccessRule()); -- disabled
    fieldLoads.add(new ByNameToByIndexFieldAccessRule());
    fieldLoads.add(new RemoveRedundantVariablesRule());
    fieldLoads.add(new AsterixInlineVariablesRule());
    fieldLoads.add(new RemoveUnusedAssignAndAggregateRule());
    fieldLoads.add(new ConstantFoldingRule());
    fieldLoads.add(new RemoveRedundantSelectRule());
    fieldLoads.add(new FeedScanCollectionToUnnest());
    fieldLoads.add(new NestedSubplanToJoinRule());
    fieldLoads.add(new InlineSubplanInputForNestedTupleSourceRule());
    fieldLoads.add(new RemoveLeftOuterUnnestForLeftOuterJoinRule());
    return fieldLoads;
}
#method_after
public static final List<IAlgebraicRewriteRule> buildLoadFieldsRuleCollection(ICcApplicationContext appCtx) {
    List<IAlgebraicRewriteRule> fieldLoads = new LinkedList<>();
    fieldLoads.add(new LoadRecordFieldsRule());
    fieldLoads.add(new PushFieldAccessRule());
    // fieldLoads.add(new ByNameToByHandleFieldAccessRule()); -- disabled
    fieldLoads.add(new ByNameToByIndexFieldAccessRule());
    fieldLoads.add(new RemoveRedundantVariablesRule());
    fieldLoads.add(new AsterixInlineVariablesRule());
    fieldLoads.add(new RemoveUnusedAssignAndAggregateRule());
    fieldLoads.add(new ConstantFoldingRule(appCtx));
    fieldLoads.add(new RemoveRedundantSelectRule());
    fieldLoads.add(new FeedScanCollectionToUnnest());
    fieldLoads.add(new NestedSubplanToJoinRule());
    fieldLoads.add(new InlineSubplanInputForNestedTupleSourceRule());
    fieldLoads.add(new RemoveLeftOuterUnnestForLeftOuterJoinRule());
    return fieldLoads;
}
#end_block

#method_before
public static final List<IAlgebraicRewriteRule> buildFuzzyJoinRuleCollection() {
    List<IAlgebraicRewriteRule> fuzzy = new LinkedList<>();
    fuzzy.add(new FuzzyJoinRule());
    // Embedding the prefix join instead of ~= cause the newly subplan derived from the AggregateOp->NTSOp
    // The ComplexJoinInferenceRule as well as the following variable/assign/select rules are successively
    // used to flatten the generated subplan corresponding to ~= clause to make FuzzyJoinRule transparent.
    fuzzy.add(new ComplexJoinInferenceRule());
    fuzzy.add(new PushSelectIntoJoinRule());
    fuzzy.add(new RemoveUnusedAssignAndAggregateRule());
    fuzzy.add(new InlineSubplanInputForNestedTupleSourceRule());
    fuzzy.add(new RemoveRedundantVariablesRule());
    return fuzzy;
}
#method_after
public static final List<IAlgebraicRewriteRule> buildFuzzyJoinRuleCollection() {
    List<IAlgebraicRewriteRule> fuzzy = new LinkedList<>();
    fuzzy.add(new FuzzyJoinRule());
    fuzzy.add(new ExtractCommonExpressionsRule());
    fuzzy.add(new NestedSubplanToJoinRule());
    fuzzy.add(new PushSelectIntoJoinRule());
    fuzzy.add(new RemoveUnusedAssignAndAggregateRule());
    fuzzy.add(new InlineSubplanInputForNestedTupleSourceRule());
    fuzzy.add(new RemoveRedundantVariablesRule());
    fuzzy.add(new AsterixInlineVariablesRule());
    fuzzy.add(new RemoveUnusedAssignAndAggregateRule());
    return fuzzy;
}
#end_block

#method_before
public static final List<IAlgebraicRewriteRule> buildConsolidationRuleCollection() {
    List<IAlgebraicRewriteRule> consolidation = new LinkedList<>();
    consolidation.add(new ConsolidateSelectsRule());
    consolidation.add(new ConsolidateAssignsRule());
    consolidation.add(new InlineAssignIntoAggregateRule());
    consolidation.add(new AsterixIntroduceGroupByCombinerRule());
    consolidation.add(new IntroduceAggregateCombinerRule());
    consolidation.add(new CountVarToCountOneRule());
    consolidation.add(new RemoveUnusedAssignAndAggregateRule());
    consolidation.add(new RemoveRedundantGroupByDecorVars());
    // PushUnnestDownUnion => RemoveRedundantListifyRule cause these rules are correlated
    consolidation.add(new PushUnnestDownThroughUnionRule());
    consolidation.add(new RemoveRedundantListifyRule());
    return consolidation;
}
#method_after
public static final List<IAlgebraicRewriteRule> buildConsolidationRuleCollection() {
    List<IAlgebraicRewriteRule> consolidation = new LinkedList<>();
    consolidation.add(new ConsolidateSelectsRule());
    consolidation.add(new ConsolidateAssignsRule());
    consolidation.add(new InlineAssignIntoAggregateRule());
    consolidation.add(new AsterixIntroduceGroupByCombinerRule());
    consolidation.add(new IntroduceAggregateCombinerRule());
    consolidation.add(new CountVarToCountOneRule());
    consolidation.add(new RemoveUnusedAssignAndAggregateRule());
    consolidation.add(new RemoveRedundantGroupByDecorVarsRule());
    // PushUnnestDownUnion => RemoveRedundantListifyRule cause these rules are correlated
    consolidation.add(new PushUnnestDownThroughUnionRule());
    consolidation.add(new RemoveRedundantListifyRule());
    return consolidation;
}
#end_block

#method_before
public static final List<IAlgebraicRewriteRule> buildAccessMethodRuleCollection() {
    List<IAlgebraicRewriteRule> accessMethod = new LinkedList<>();
    accessMethod.add(new IntroduceSelectAccessMethodRule());
    accessMethod.add(new IntroduceJoinAccessMethodRule());
    accessMethod.add(new IntroduceLSMComponentFilterRule());
    accessMethod.add(new IntroduceSecondaryIndexInsertDeleteRule());
    accessMethod.add(new RemoveUnusedOneToOneEquiJoinRule());
    accessMethod.add(new PushSimilarityFunctionsBelowJoin());
    accessMethod.add(new RemoveUnusedAssignAndAggregateRule());
    return accessMethod;
}
#method_after
public static final List<IAlgebraicRewriteRule> buildAccessMethodRuleCollection() {
    List<IAlgebraicRewriteRule> accessMethod = new LinkedList<>();
    accessMethod.add(new IntroduceSelectAccessMethodRule());
    accessMethod.add(new IntroduceJoinAccessMethodRule());
    accessMethod.add(new IntroduceLSMComponentFilterRule());
    accessMethod.add(new IntroducePrimaryIndexForAggregationRule());
    accessMethod.add(new IntroduceSecondaryIndexInsertDeleteRule());
    accessMethod.add(new RemoveUnusedOneToOneEquiJoinRule());
    accessMethod.add(new PushSimilarityFunctionsBelowJoin());
    accessMethod.add(new RemoveUnusedAssignAndAggregateRule());
    return accessMethod;
}
#end_block

#method_before
public static final List<IAlgebraicRewriteRule> buildPlanCleanupRuleCollection() {
    List<IAlgebraicRewriteRule> planCleanupRules = new LinkedList<>();
    planCleanupRules.add(new PushAssignBelowUnionAllRule());
    planCleanupRules.add(new ExtractCommonExpressionsRule());
    planCleanupRules.add(new RemoveRedundantVariablesRule());
    planCleanupRules.add(new PushProjectDownRule());
    planCleanupRules.add(new PushSelectDownRule());
    planCleanupRules.add(new SetClosedRecordConstructorsRule());
    planCleanupRules.add(new IntroduceDynamicTypeCastRule());
    planCleanupRules.add(new IntroduceDynamicTypeCastForExternalFunctionRule());
    planCleanupRules.add(new RemoveUnusedAssignAndAggregateRule());
    planCleanupRules.add(new RemoveCartesianProductWithEmptyBranchRule());
    planCleanupRules.add(new InjectTypeCastForSwitchCaseRule());
    planCleanupRules.add(new InjectTypeCastForUnionRule());
    // Needs to invoke ByNameToByIndexFieldAccessRule as the last logical optimization rule because
    // some rules can push a FieldAccessByName to a place where the name it tries to access is in the closed part.
    // For example, a possible scenario is that a field-access-by-name can be pushed down through UnionAllOperator.
    planCleanupRules.add(new ByNameToByIndexFieldAccessRule());
    return planCleanupRules;
}
#method_after
public static final List<IAlgebraicRewriteRule> buildPlanCleanupRuleCollection() {
    List<IAlgebraicRewriteRule> planCleanupRules = new LinkedList<>();
    planCleanupRules.add(new SwitchInnerJoinBranchRule());
    planCleanupRules.add(new PushAssignBelowUnionAllRule());
    planCleanupRules.add(new ExtractCommonExpressionsRule());
    planCleanupRules.add(new RemoveRedundantVariablesRule());
    planCleanupRules.add(new PushProjectDownRule());
    planCleanupRules.add(new PushSelectDownRule());
    planCleanupRules.add(new SetClosedRecordConstructorsRule());
    planCleanupRules.add(new IntroduceDynamicTypeCastRule());
    planCleanupRules.add(new IntroduceDynamicTypeCastForExternalFunctionRule());
    planCleanupRules.add(new RemoveUnusedAssignAndAggregateRule());
    planCleanupRules.add(new RemoveCartesianProductWithEmptyBranchRule());
    planCleanupRules.add(new InjectTypeCastForFunctionArgumentsRule());
    planCleanupRules.add(new InjectTypeCastForUnionRule());
    // Needs to invoke ByNameToByIndexFieldAccessRule as the last logical optimization rule because
    // some rules can push a FieldAccessByName to a place where the name it tries to access is in the closed part.
    // For example, a possible scenario is that a field-access-by-name can be pushed down through UnionAllOperator.
    planCleanupRules.add(new ByNameToByIndexFieldAccessRule());
    return planCleanupRules;
}
#end_block

#method_before
public static final List<IAlgebraicRewriteRule> buildPhysicalRewritesAllLevelsRuleCollection() {
    List<IAlgebraicRewriteRule> physicalRewritesAllLevels = new LinkedList<>();
    physicalRewritesAllLevels.add(new PullSelectOutOfEqJoin());
    // Turned off the following rule for now not to change OptimizerTest results.
    physicalRewritesAllLevels.add(new ReplaceSinkOpWithCommitOpRule());
    physicalRewritesAllLevels.add(new SetAlgebricksPhysicalOperatorsRule());
    physicalRewritesAllLevels.add(new SetAsterixPhysicalOperatorsRule());
    physicalRewritesAllLevels.add(new AddEquivalenceClassForRecordConstructorRule());
    physicalRewritesAllLevels.add(new EnforceStructuralPropertiesRule());
    physicalRewritesAllLevels.add(new RemoveSortInFeedIngestionRule());
    physicalRewritesAllLevels.add(new RemoveUnnecessarySortMergeExchange());
    physicalRewritesAllLevels.add(new PushProjectDownRule());
    physicalRewritesAllLevels.add(new InsertProjectBeforeUnionRule());
    physicalRewritesAllLevels.add(new IntroduceMaterializationForInsertWithSelfScanRule());
    physicalRewritesAllLevels.add(new InlineSingleReferenceVariablesRule());
    physicalRewritesAllLevels.add(new RemoveUnusedAssignAndAggregateRule());
    physicalRewritesAllLevels.add(new ConsolidateAssignsRule());
    // After adding projects, we may need need to set physical operators again.
    physicalRewritesAllLevels.add(new SetAlgebricksPhysicalOperatorsRule());
    return physicalRewritesAllLevels;
}
#method_after
public static final List<IAlgebraicRewriteRule> buildPhysicalRewritesAllLevelsRuleCollection() {
    List<IAlgebraicRewriteRule> physicalRewritesAllLevels = new LinkedList<>();
    physicalRewritesAllLevels.add(new PullSelectOutOfEqJoin());
    // Turned off the following rule for now not to change OptimizerTest results.
    physicalRewritesAllLevels.add(new SetupCommitExtensionOpRule());
    physicalRewritesAllLevels.add(new SetAlgebricksPhysicalOperatorsRule());
    physicalRewritesAllLevels.add(new SetAsterixPhysicalOperatorsRule());
    physicalRewritesAllLevels.add(new AddEquivalenceClassForRecordConstructorRule());
    physicalRewritesAllLevels.add(new EnforceStructuralPropertiesRule());
    physicalRewritesAllLevels.add(new RemoveSortInFeedIngestionRule());
    physicalRewritesAllLevels.add(new RemoveUnnecessarySortMergeExchange());
    physicalRewritesAllLevels.add(new PushProjectDownRule());
    physicalRewritesAllLevels.add(new IntroduceMaterializationForInsertWithSelfScanRule());
    physicalRewritesAllLevels.add(new InlineSingleReferenceVariablesRule());
    physicalRewritesAllLevels.add(new RemoveUnusedAssignAndAggregateRule());
    physicalRewritesAllLevels.add(new ConsolidateAssignsRule());
    // After adding projects, we may need need to set physical operators again.
    physicalRewritesAllLevels.add(new SetAlgebricksPhysicalOperatorsRule());
    return physicalRewritesAllLevels;
}
#end_block

#method_before
public static final List<IAlgebraicRewriteRule> buildPhysicalRewritesTopLevelRuleCollection() {
    List<IAlgebraicRewriteRule> physicalRewritesTopLevel = new LinkedList<>();
    physicalRewritesTopLevel.add(new PushNestedOrderByUnderPreSortedGroupByRule());
    physicalRewritesTopLevel.add(new CopyLimitDownRule());
    // CopyLimitDownRule may generates non-topmost limits with numeric_adds functions.
    // We are going to apply a constant folding rule again for this case.
    physicalRewritesTopLevel.add(new ConstantFoldingRule());
    physicalRewritesTopLevel.add(new PushLimitIntoOrderByRule());
    physicalRewritesTopLevel.add(new IntroduceProjectsRule());
    physicalRewritesTopLevel.add(new SetAlgebricksPhysicalOperatorsRule());
    physicalRewritesTopLevel.add(new IntroduceRapidFrameFlushProjectAssignRule());
    physicalRewritesTopLevel.add(new SetExecutionModeRule());
    physicalRewritesTopLevel.add(new IntroduceRandomPartitioningFeedComputationRule());
    return physicalRewritesTopLevel;
}
#method_after
public static final List<IAlgebraicRewriteRule> buildPhysicalRewritesTopLevelRuleCollection(ICcApplicationContext appCtx) {
    List<IAlgebraicRewriteRule> physicalRewritesTopLevel = new LinkedList<>();
    physicalRewritesTopLevel.add(new PushNestedOrderByUnderPreSortedGroupByRule());
    physicalRewritesTopLevel.add(new CopyLimitDownRule());
    // CopyLimitDownRule may generates non-topmost limits with numeric_adds functions.
    // We are going to apply a constant folding rule again for this case.
    physicalRewritesTopLevel.add(new ConstantFoldingRule(appCtx));
    physicalRewritesTopLevel.add(new PushLimitIntoOrderByRule());
    physicalRewritesTopLevel.add(new PushLimitIntoPrimarySearchRule());
    // remove assigns that could become unused after PushLimitIntoPrimarySearchRule
    physicalRewritesTopLevel.add(new RemoveUnusedAssignAndAggregateRule());
    physicalRewritesTopLevel.add(new IntroduceProjectsRule());
    physicalRewritesTopLevel.add(new SetAlgebricksPhysicalOperatorsRule());
    physicalRewritesTopLevel.add(new IntroduceRapidFrameFlushProjectAssignRule());
    physicalRewritesTopLevel.add(new SetExecutionModeRule());
    physicalRewritesTopLevel.add(new IntroduceRandomPartitioningFeedComputationRule());
    return physicalRewritesTopLevel;
}
#end_block

#method_before
public static final List<IAlgebraicRewriteRule> prepareForJobGenRuleCollection() {
    List<IAlgebraicRewriteRule> prepareForJobGenRewrites = new LinkedList<>();
    prepareForJobGenRewrites.add(new IsolateHyracksOperatorsRule(HeuristicOptimizer.hyraxOperatorsBelowWhichJobGenIsDisabled));
    prepareForJobGenRewrites.add(new ExtractCommonOperatorsRule());
    // Re-infer all types, so that, e.g., the effect of not-is-null is
    // propagated.
    prepareForJobGenRewrites.add(new ReinferAllTypesRule());
    prepareForJobGenRewrites.add(new PushGroupByIntoSortRule());
    prepareForJobGenRewrites.add(new SetExecutionModeRule());
    prepareForJobGenRewrites.add(new SweepIllegalNonfunctionalFunctions());
    return prepareForJobGenRewrites;
}
#method_after
public static final List<IAlgebraicRewriteRule> prepareForJobGenRuleCollection() {
    List<IAlgebraicRewriteRule> prepareForJobGenRewrites = new LinkedList<>();
    prepareForJobGenRewrites.add(new InsertProjectBeforeUnionRule());
    prepareForJobGenRewrites.add(new SetAlgebricksPhysicalOperatorsRule());
    prepareForJobGenRewrites.add(new IsolateHyracksOperatorsRule(HeuristicOptimizer.hyraxOperatorsBelowWhichJobGenIsDisabled));
    prepareForJobGenRewrites.add(new ExtractCommonOperatorsRule());
    // Re-infer all types, so that, e.g., the effect of not-is-null is
    // propagated.
    prepareForJobGenRewrites.add(new ReinferAllTypesRule());
    prepareForJobGenRewrites.add(new PushGroupByIntoSortRule());
    prepareForJobGenRewrites.add(new SetExecutionModeRule());
    prepareForJobGenRewrites.add(new SweepIllegalNonfunctionalFunctions());
    prepareForJobGenRewrites.add(new FixReplicateOperatorOutputsRule());
    return prepareForJobGenRewrites;
}
#end_block

#method_before
public static void mergeHomogeneousPK(ILogicalOperator op, List<LogicalVariable> pks) throws AlgebricksException {
    Map<LogicalVariable, ILogicalOperator> varOpMap = new HashMap<>();
    for (LogicalVariable pk : pks) {
        ILogicalOperator mOp = extractPKProduction(op, pk);
        if (mOp == null || !mOp.getOperatorTag().equals(LogicalOperatorTag.DATASOURCESCAN)) {
            throw new AlgebricksException("Illegal variable production.");
        }
        varOpMap.put(pk, mOp);
    }
    Map<LogicalVariable, LogicalVariable> variableMapping = new HashMap<>();
    for (int i = 0; i < pks.size() - 1; i++) {
        for (int j = i + 1; j < pks.size(); j++) {
            IDataSource<?> leftSource = ((DataSourceScanOperator) (varOpMap.get(pks.get(i)))).getDataSource();
            IDataSource<?> rightSource = ((DataSourceScanOperator) (varOpMap.get(pks.get(j)))).getDataSource();
            if (leftSource.getId().toString().equals(rightSource.getId().toString())) {
                IsomorphismUtilities.mapVariablesTopDown(varOpMap.get(pks.get(i)), varOpMap.get(pks.get(j)), variableMapping);
            }
        }
    }
    Iterator<LogicalVariable> itr = pks.iterator();
    while (itr.hasNext()) {
        LogicalVariable pk = itr.next();
        if (variableMapping.containsKey(pk)) {
            variableMapping.remove(pk);
            itr.remove();
        }
    }
}
#method_after
public static void mergeHomogeneousPK(ILogicalOperator op, List<LogicalVariable> pkVars) throws AlgebricksException {
    Map<LogicalVariable, ILogicalOperator> varOpMap = new HashMap<>();
    for (LogicalVariable pk : pkVars) {
        ILogicalOperator mOp = getOpThatProducesPK(op, pk);
        if (mOp == null || !mOp.getOperatorTag().equals(LogicalOperatorTag.DATASOURCESCAN)) {
            throw new AlgebricksException("Illegal variable production.");
        }
        varOpMap.put(pk, mOp);
    }
    // Check the isomorphic variables in pkVars by DataSource, use variableMapping to store each isomorphic pair.
    // For any isomorphic pair <$i, $j>, use $i that is close to the beginning of pkVars as key and let $j as value.
    Map<LogicalVariable, LogicalVariable> variableMapping = new HashMap<>();
    for (int i = 0; i < pkVars.size() - 1; i++) {
        for (int j = i + 1; j < pkVars.size(); j++) {
            IDataSource<?> leftSource = ((DataSourceScanOperator) (varOpMap.get(pkVars.get(i)))).getDataSource();
            IDataSource<?> rightSource = ((DataSourceScanOperator) (varOpMap.get(pkVars.get(j)))).getDataSource();
            if (leftSource.getId().toString().equals(rightSource.getId().toString())) {
                mapVariablesTopDown(varOpMap.get(pkVars.get(i)), varOpMap.get(pkVars.get(j)), variableMapping);
            }
        }
    }
    // Remove a key variable in pkVars if it has at least one isomorphic variable in variableMapping.
    Iterator<LogicalVariable> itr = pkVars.iterator();
    while (itr.hasNext()) {
        LogicalVariable pk = itr.next();
        if (variableMapping.containsKey(pk)) {
            variableMapping.remove(pk);
            itr.remove();
        }
    }
}
#end_block

#method_before
@BeforeClass
public static void setUp() throws Exception {
    File outdir = new File(PATH_ACTUAL);
    outdir.mkdirs();
    asterixInstallerPath = new File(System.getProperty("user.dir"));
    installerTargetPath = new File(new File(asterixInstallerPath.getParentFile().getParentFile(), "asterix-server"), "target");
    reportPath = new File(installerTargetPath, "failsafe-reports").getAbsolutePath();
    reportPath = new File(installerTargetPath, "failsafe-reports").getAbsolutePath();
    ncServiceSubDirName = installerTargetPath.list((dir, name) -> name.matches("asterix-server.*binary-assembly"))[0];
    ncServiceSubPath = new File(installerTargetPath, ncServiceSubDirName).getAbsolutePath();
    ncServiceHomeDirName = new File(ncServiceSubPath).list(((dir, name) -> name.matches("apache-asterixdb.*")))[0];
    ncServiceHomePath = new File(ncServiceSubPath, ncServiceHomeDirName).getAbsolutePath();
    pb = new ProcessBuilder();
    env = pb.environment();
    env.put("JAVA_HOME", System.getProperty("java.home"));
    // Create the folder to run asterix with extensions
    String asterixInstallerTarget = asterixInstallerPath + File.separator + "target";
    Process p = Runtime.getRuntime().exec("cp -R " + ncServiceHomePath + " " + asterixInstallerTarget);
    p.waitFor();
    ncServiceHomePath = asterixInstallerTarget + File.separator + ncServiceHomeDirName;
    String confDir = File.separator + "opt" + File.separator + "local" + File.separator + "conf" + File.separator;
    p = Runtime.getRuntime().exec("rm " + ncServiceHomePath + confDir + "cc.conf");
    p.waitFor();
    String BADconf = asterixInstallerPath + File.separator + "src" + File.separator + "main" + File.separator + "resources" + File.separator + "cc.conf";
    p = Runtime.getRuntime().exec("cp " + BADconf + " " + ncServiceHomePath + confDir);
    p.waitFor();
    LOGGER.info("NCSERVICE_HOME=" + ncServiceHomePath);
    env.put("NCSERVICE_HOME", ncServiceHomePath);
    env.put("JAVA_HOME", System.getProperty("java.home"));
    scriptHomePath = asterixInstallerPath + File.separator + "src" + File.separator + "test" + File.separator + "resources" + File.separator + "recoveryts" + File.separator + "scripts";
    env.put("SCRIPT_HOME", scriptHomePath);
    TestExecutor.executeScript(pb, scriptHomePath + File.separator + "setup_teardown" + File.separator + "stop_and_delete.sh");
    TestExecutor.executeScript(pb, scriptHomePath + File.separator + "setup_teardown" + File.separator + "configure_and_validate.sh");
}
#method_after
@BeforeClass
public static void setUp() throws Exception {
    File outdir = new File(PATH_ACTUAL);
    outdir.mkdirs();
    asterixInstallerPath = new File(System.getProperty("user.dir"));
    installerTargetPath = new File(new File(asterixInstallerPath.getParentFile().getParentFile(), "asterix-server"), "target");
    reportPath = new File(installerTargetPath, "failsafe-reports").getAbsolutePath();
    ncServiceSubDirName = installerTargetPath.list((dir, name) -> name.matches("asterix-server.*binary-assembly"))[0];
    ncServiceSubPath = new File(installerTargetPath, ncServiceSubDirName).getAbsolutePath();
    ncServiceHomeDirName = new File(ncServiceSubPath).list(((dir, name) -> name.matches("apache-asterixdb.*")))[0];
    ncServiceHomePath = new File(ncServiceSubPath, ncServiceHomeDirName).getAbsolutePath();
    pb = new ProcessBuilder();
    env = pb.environment();
    env.put("JAVA_HOME", System.getProperty("java.home"));
    // Create the folder to run asterix with extensions
    String asterixInstallerTarget = asterixInstallerPath + File.separator + "target";
    Process p = Runtime.getRuntime().exec("cp -R " + ncServiceHomePath + " " + asterixInstallerTarget);
    p.waitFor();
    ncServiceHomePath = asterixInstallerTarget + File.separator + ncServiceHomeDirName;
    String confDir = File.separator + "opt" + File.separator + "local" + File.separator + "conf" + File.separator;
    p = Runtime.getRuntime().exec("rm " + ncServiceHomePath + confDir + "cc.conf");
    p.waitFor();
    String BADconf = asterixInstallerPath + File.separator + "src" + File.separator + "main" + File.separator + "resources" + File.separator + "cc.conf";
    p = Runtime.getRuntime().exec("cp " + BADconf + " " + ncServiceHomePath + confDir);
    p.waitFor();
    LOGGER.info("NCSERVICE_HOME=" + ncServiceHomePath);
    env.put("NCSERVICE_HOME", ncServiceHomePath);
    env.put("JAVA_HOME", System.getProperty("java.home"));
    scriptHomePath = asterixInstallerPath + File.separator + "src" + File.separator + "test" + File.separator + "resources" + File.separator + "recoveryts" + File.separator + "scripts";
    env.put("SCRIPT_HOME", scriptHomePath);
    TestExecutor.executeScript(pb, scriptHomePath + File.separator + "setup_teardown" + File.separator + "stop_and_delete.sh");
    TestExecutor.executeScript(pb, scriptHomePath + File.separator + "setup_teardown" + File.separator + "configure_and_validate.sh");
}
#end_block

#method_before
@Override
public void deinitialize() {
    System.out.println("De-Initialized");
}
#method_after
@Override
public void deinitialize() {
// no op
}
#end_block

#method_before
private static IAType getTypeInfo(String paramType, MetadataTransactionContext txnCtx, Function function) throws AlgebricksException {
    if (paramType.equalsIgnoreCase(BuiltinType.AINT32.getDisplayName())) {
        return (BuiltinType.AINT32);
    } else if (paramType.equalsIgnoreCase(BuiltinType.AFLOAT.getDisplayName())) {
        return (BuiltinType.AFLOAT);
    } else if (paramType.equalsIgnoreCase(BuiltinType.ASTRING.getDisplayName())) {
        return (BuiltinType.ASTRING);
    } else if (paramType.equalsIgnoreCase(BuiltinType.ADOUBLE.getDisplayName())) {
        return (BuiltinType.ADOUBLE);
    } else if (paramType.equalsIgnoreCase(BuiltinType.ABOOLEAN.getDisplayName())) {
        return (BuiltinType.ABOOLEAN);
    } else if (paramType.equalsIgnoreCase(BuiltinType.APOINT.getDisplayName())) {
        return (BuiltinType.APOINT);
    } else if (paramType.equalsIgnoreCase(BuiltinType.AFLOAT.getDisplayName())) {
        return (BuiltinType.AFLOAT);
    } else if (paramType.equalsIgnoreCase(BuiltinType.ADATE.getDisplayName())) {
        return (BuiltinType.ADATE);
    } else if (paramType.equalsIgnoreCase(BuiltinType.ADATETIME.getDisplayName())) {
        return (BuiltinType.ADATETIME);
    } else if (paramType.equalsIgnoreCase(BuiltinType.APOINT3D.getDisplayName())) {
        return (BuiltinType.APOINT3D);
    } else if (paramType.equalsIgnoreCase(BuiltinType.ALINE.getDisplayName())) {
        return (BuiltinType.ALINE);
    } else if (paramType.equalsIgnoreCase(BuiltinType.ACIRCLE.getDisplayName())) {
        return (BuiltinType.ACIRCLE);
    } else if (paramType.equalsIgnoreCase(BuiltinType.ARECTANGLE.getDisplayName())) {
        return (BuiltinType.ARECTANGLE);
    } else {
        IAType collection = getCollectionType(paramType, txnCtx, function);
        if (collection != null) {
            return collection;
        } else {
            Datatype datatype;
            datatype = MetadataManager.INSTANCE.getDatatype(txnCtx, function.getDataverseName(), paramType);
            if (datatype == null) {
                throw new MetadataException(" Type " + paramType + " is not supported in UDF.");
            }
            return (datatype.getDatatype());
        }
    }
}
#method_after
private static IAType getTypeInfo(String paramType, MetadataTransactionContext txnCtx, Function function) throws AlgebricksException {
    if (paramType.equalsIgnoreCase(BuiltinType.AINT32.getDisplayName())) {
        return BuiltinType.AINT32;
    } else if (paramType.equalsIgnoreCase(BuiltinType.AFLOAT.getDisplayName())) {
        return BuiltinType.AFLOAT;
    } else if (paramType.equalsIgnoreCase(BuiltinType.ASTRING.getDisplayName())) {
        return BuiltinType.ASTRING;
    } else if (paramType.equalsIgnoreCase(BuiltinType.ADOUBLE.getDisplayName())) {
        return BuiltinType.ADOUBLE;
    } else if (paramType.equalsIgnoreCase(BuiltinType.ABOOLEAN.getDisplayName())) {
        return BuiltinType.ABOOLEAN;
    } else if (paramType.equalsIgnoreCase(BuiltinType.APOINT.getDisplayName())) {
        return BuiltinType.APOINT;
    } else if (paramType.equalsIgnoreCase(BuiltinType.ADATE.getDisplayName())) {
        return BuiltinType.ADATE;
    } else if (paramType.equalsIgnoreCase(BuiltinType.ADATETIME.getDisplayName())) {
        return BuiltinType.ADATETIME;
    } else if (paramType.equalsIgnoreCase(BuiltinType.APOINT3D.getDisplayName())) {
        return BuiltinType.APOINT3D;
    } else if (paramType.equalsIgnoreCase(BuiltinType.ALINE.getDisplayName())) {
        return BuiltinType.ALINE;
    } else if (paramType.equalsIgnoreCase(BuiltinType.ACIRCLE.getDisplayName())) {
        return BuiltinType.ACIRCLE;
    } else if (paramType.equalsIgnoreCase(BuiltinType.ARECTANGLE.getDisplayName())) {
        return BuiltinType.ARECTANGLE;
    } else {
        IAType collection = getCollectionType(paramType, txnCtx, function);
        if (collection != null) {
            return collection;
        } else {
            Datatype datatype;
            datatype = MetadataManager.INSTANCE.getDatatype(txnCtx, function.getDataverseName(), paramType);
            if (datatype == null) {
                throw new MetadataException(" Type " + paramType + " is not supported in UDF.");
            }
            return datatype.getDatatype();
        }
    }
}
#end_block

#method_before
@Override
protected IAType getResultType(ILogicalExpression expr, IAType... strippedInputTypes) throws AlgebricksException {
    if (strippedInputTypes.length == 0) {
        return BuiltinType.ANULL;
    }
    boolean any = false;
    IAType currentType = null;
    for (IAType type : strippedInputTypes) {
        if (currentType != null && !type.equals(currentType)) {
            any = true;
            break;
        }
        currentType = type;
    }
    if (any || currentType == null) {
        return BuiltinType.ANY;
    }
    switch(currentType.getTypeTag()) {
        case MISSING:
            if (skipMissing) {
                // i.e. all args have been inspected and couldn't find a candidate value, so return null
                return BuiltinType.ANULL;
            }
        case ANY:
        case BIGINT:
        case INTEGER:
        case SMALLINT:
        case TINYINT:
            return currentType;
        case DOUBLE:
        case FLOAT:
            return AUnionType.createNullableType(currentType, null);
        default:
            return BuiltinType.ANULL;
    }
}
#method_after
@Override
protected IAType getResultType(ILogicalExpression expr, IAType... strippedInputTypes) throws AlgebricksException {
    if (strippedInputTypes.length < 2 || strippedInputTypes.length > Short.MAX_VALUE) {
        String functionName = ((AbstractFunctionCallExpression) expr).getFunctionIdentifier().getName();
        throw new CompilationException(ErrorCode.COMPILATION_INVALID_NUM_OF_ARGS, expr.getSourceLocation(), functionName);
    }
    boolean any = false;
    IAType currentType = null;
    for (IAType type : strippedInputTypes) {
        if (currentType != null && !type.equals(currentType)) {
            any = true;
            break;
        }
        currentType = type;
    }
    if (any || currentType == null) {
        return BuiltinType.ANY;
    }
    switch(currentType.getTypeTag()) {
        case MISSING:
            if (skipMissing) {
                // i.e. all args have been inspected and couldn't find a candidate value, so return null
                return BuiltinType.ANULL;
            }
        case ANY:
        case BIGINT:
        case INTEGER:
        case SMALLINT:
        case TINYINT:
            return currentType;
        case DOUBLE:
        case FLOAT:
            return AUnionType.createNullableType(currentType, null);
        default:
            return BuiltinType.ANULL;
    }
}
#end_block

#method_before
private boolean scheduleMerge(final ILSMIndex index) throws HyracksDataException {
    int numFlushes = (int) ((AbstractLSMIndex) index).getNumFlushes();
    List<ILSMDiskComponent> immutableComponents = new ArrayList<>(index.getDiskComponents());
    Collections.reverse(immutableComponents);
    int size = immutableComponents.size();
    int depth = 0;
    while ((treeDepth(depth) < numFlushes)) {
        depth++;
    }
    int mergedIndex = binomialIndex(depth, Math.min(depth, numComponents) - 1, numFlushes - treeDepth(depth - 1) - 1);
    if (mergedIndex == size - 1) {
        return false;
    }
    long mergeSize = 0;
    List<ILSMDiskComponent> mergableComponents = new ArrayList<ILSMDiskComponent>();
    for (int i = mergedIndex; i < immutableComponents.size(); i++) {
        mergeSize = mergeSize + immutableComponents.get(i).getComponentSize();
        mergableComponents.add(immutableComponents.get(i));
    }
    Collections.reverse(mergableComponents);
    ILSMIndexAccessor accessor = index.createAccessor(NoOpIndexAccessParameters.INSTANCE);
    accessor.scheduleMerge(mergableComponents);
    return true;
}
#method_after
private boolean scheduleMerge(final ILSMIndex index) throws HyracksDataException {
    Optional<Long> latestSeq = ((AbstractLSMIndex) index).getLatestDiskComponentSequence();
    if (!latestSeq.isPresent()) {
        return false;
    }
    // sequence number starts from 0, and thus latestSeq + 1 gives the number of flushes
    int numFlushes = latestSeq.get().intValue() + 1;
    List<ILSMDiskComponent> immutableComponents = new ArrayList<>(index.getDiskComponents());
    Collections.reverse(immutableComponents);
    int size = immutableComponents.size();
    int depth = 0;
    while (treeDepth(depth) < numFlushes) {
        depth++;
    }
    int mergedIndex = binomialIndex(depth, Math.min(depth, numComponents) - 1, numFlushes - treeDepth(depth - 1) - 1);
    if (mergedIndex == size - 1) {
        return false;
    }
    long mergeSize = 0;
    List<ILSMDiskComponent> mergableComponents = new ArrayList<ILSMDiskComponent>();
    for (int i = mergedIndex; i < immutableComponents.size(); i++) {
        mergeSize = mergeSize + immutableComponents.get(i).getComponentSize();
        mergableComponents.add(immutableComponents.get(i));
    }
    Collections.reverse(mergableComponents);
    ILSMIndexAccessor accessor = index.createAccessor(NoOpIndexAccessParameters.INSTANCE);
    accessor.scheduleMerge(mergableComponents);
    return true;
}
#end_block

#method_before
@Override
public boolean isMergeLagging(ILSMIndex index) throws HyracksDataException {
    // TODO: for now, we simply block the ingestion when there is an ongoing merge
    List<ILSMDiskComponent> immutableComponents = index.getDiskComponents();
    boolean isMergeOngoing = isMergeOngoing(immutableComponents);
    if (isMergeOngoing) {
        return true;
    }
    return false;
}
#method_after
@Override
public boolean isMergeLagging(ILSMIndex index) throws HyracksDataException {
    // TODO: for now, we simply block the ingestion when there is an ongoing merge
    List<ILSMDiskComponent> immutableComponents = index.getDiskComponents();
    return isMergeOngoing(immutableComponents);
}
#end_block

#method_before
@Override
public void addDiskComponent(ILSMDiskComponent c) throws HyracksDataException {
    if (c != EmptyComponent.INSTANCE) {
        diskComponents.add(0, c);
    }
    assert checkComponentIds();
}
#method_after
@Override
public void addDiskComponent(ILSMDiskComponent c) throws HyracksDataException {
    if (c != EmptyComponent.INSTANCE) {
        diskComponents.add(0, c);
    }
    validateComponentIds();
}
#end_block

#method_before
@Override
public void subsumeMergedComponents(ILSMDiskComponent newComponent, List<ILSMComponent> mergedComponents) throws HyracksDataException {
    int swapIndex = diskComponents.indexOf(mergedComponents.get(0));
    diskComponents.removeAll(mergedComponents);
    if (newComponent != EmptyComponent.INSTANCE) {
        diskComponents.add(swapIndex, newComponent);
    }
    assert checkComponentIds();
}
#method_after
@Override
public void subsumeMergedComponents(ILSMDiskComponent newComponent, List<ILSMComponent> mergedComponents) throws HyracksDataException {
    int swapIndex = diskComponents.indexOf(mergedComponents.get(0));
    diskComponents.removeAll(mergedComponents);
    if (newComponent != EmptyComponent.INSTANCE) {
        diskComponents.add(swapIndex, newComponent);
    }
    validateComponentIds();
}
#end_block

#method_before
private static ILogicalOperator createFinalIndexOnlySearchPlan(List<Mutable<ILogicalOperator>> afterTopOpRefs, Mutable<ILogicalOperator> topOpRef, Mutable<ILogicalExpression> conditionRef, List<Mutable<ILogicalOperator>> assignsBeforeTopOpRef, Dataset dataset, ARecordType recordType, ARecordType metaRecordType, ILogicalOperator inputOp, IOptimizationContext context, boolean retainInput, boolean retainMissing, boolean requiresBroadcast, Index secondaryIndex, AccessMethodAnalysisContext analysisCtx, OptimizableOperatorSubTree subTree, LogicalVariable newMissingPlaceHolderForLOJ, List<LogicalVariable> pkVarsFromSIdxUnnestMapOp, List<LogicalVariable> primaryIndexUnnestVars, List<Object> primaryIndexOutputTypes) throws AlgebricksException {
    SourceLocation sourceLoc = inputOp.getSourceLocation();
    Quadruple<Boolean, Boolean, Boolean, Boolean> indexOnlyPlanInfo = analysisCtx.getIndexOnlyPlanInfo();
    // From now on, we deal with the index-only plan.
    // Initializes the information required for the index-only plan optimization.
    // Fetches SK variable(s) from the secondary-index search operator.
    List<LogicalVariable> skVarsFromSIdxUnnestMap = AccessMethodUtils.getKeyVarsFromSecondaryUnnestMap(dataset, recordType, metaRecordType, inputOp, secondaryIndex, SecondaryUnnestMapOutputVarType.SECONDARY_KEY);
    boolean skFieldUsedAfterTopOp = indexOnlyPlanInfo.getSecond();
    boolean requireVerificationAfterSIdxSearch = indexOnlyPlanInfo.getThird();
    ILogicalOperator assignBeforeTopOp;
    UnionAllOperator unionAllOp;
    SelectOperator newSelectOpInLeftPath;
    SelectOperator newSelectOpInRightPath;
    SplitOperator splitOp = null;
    // This variable map will be used as input to UNIONALL operator. The form is <left, right, output>.
    // In our case, left: instantTryLock fail path, right: instantTryLock success path
    List<Triple<LogicalVariable, LogicalVariable, LogicalVariable>> unionVarMap = new ArrayList<>();
    List<LogicalVariable> condSplitVars;
    List<LogicalVariable> liveVarsAfterTopOp = new ArrayList<>();
    // Constructs the variable mapping between newly constructed secondary
    // key search (SK, PK) and those in the original plan (datasource scan).
    LinkedHashMap<LogicalVariable, LogicalVariable> origVarToSIdxUnnestMapOpVarMap = new LinkedHashMap<>();
    List<List<String>> chosenIndexFieldNames = secondaryIndex.getKeyFieldNames();
    IndexType idxType = secondaryIndex.getIndexType();
    // variables used in SELECT or JOIN operator
    List<LogicalVariable> usedVarsInTopOp = new ArrayList<>();
    List<LogicalVariable> uniqueUsedVarsInTopOp = new ArrayList<>();
    // variables used in ASSIGN before SELECT operator
    List<LogicalVariable> producedVarsInAssignsBeforeTopOp = new ArrayList<>();
    // For the index-nested-loop join case, we need to exclude the variables from the left (outer) branch
    // when deciding which variables should be propagated via UNIONALL operator.
    // This is because these variables are already generated and is not related to the decision
    // whether the plan is an index-only plan or not. Only the right (inner) branch matters.
    List<LogicalVariable> liveVarsInSubTreeRootOp = new ArrayList<>();
    // variables used after SELECT or JOIN operator
    List<LogicalVariable> usedVarsAfterTopOp = new ArrayList<>();
    List<LogicalVariable> varsTmpList = new ArrayList<>();
    // If the secondary key field is used after SELECT or JOIN operator (e.g., returning the field value),
    // then we need to keep these secondary keys. In case of R-tree index, the result of an R-tree
    // index search is an MBR. So, we need to reconstruct original field values from the result if that index
    // is on a rectangle or point.
    AssignOperator skVarAssignOpInRightPath = null;
    List<LogicalVariable> restoredSKVarFromRTree = null;
    // Original SK field variable to restored SK field variable in the right path mapping
    LinkedHashMap<LogicalVariable, LogicalVariable> origSKFieldVarToNewSKFieldVarMap = new LinkedHashMap<>();
    // index is RECTANGLE or POINT (in this case only, removing false-positive is possible.).
    if (idxType == IndexType.RTREE && (skFieldUsedAfterTopOp || requireVerificationAfterSIdxSearch)) {
        IOptimizableFuncExpr optFuncExpr = AccessMethodUtils.chooseFirstOptFuncExpr(secondaryIndex, analysisCtx);
        int optFieldIdx = AccessMethodUtils.chooseFirstOptFuncVar(secondaryIndex, analysisCtx);
        Pair<IAType, Boolean> keyPairType = Index.getNonNullableOpenFieldType(optFuncExpr.getFieldType(optFieldIdx), optFuncExpr.getFieldName(optFieldIdx), recordType);
        if (keyPairType == null) {
            return null;
        }
        // Gets the number of dimensions corresponding to the field indexed by chosenIndex.
        IAType spatialType = keyPairType.first;
        ArrayList<Mutable<ILogicalExpression>> restoredSKFromRTreeExprs = new ArrayList<>();
        restoredSKVarFromRTree = new ArrayList<>();
        switch(spatialType.getTypeTag()) {
            case POINT:
                // Reconstructs a POINT value.
                AbstractFunctionCallExpression createPointExpr = createPointExpression(skVarsFromSIdxUnnestMap, sourceLoc);
                restoredSKVarFromRTree.add(context.newVar());
                restoredSKFromRTreeExprs.add(new MutableObject<ILogicalExpression>(createPointExpr));
                skVarAssignOpInRightPath = new AssignOperator(restoredSKVarFromRTree, restoredSKFromRTreeExprs);
                skVarAssignOpInRightPath.setSourceLocation(sourceLoc);
                break;
            case RECTANGLE:
                // Reconstructs a RECTANGLE value.
                AbstractFunctionCallExpression expr1 = createPointExpression(skVarsFromSIdxUnnestMap.subList(0, 2), sourceLoc);
                AbstractFunctionCallExpression expr2 = createPointExpression(skVarsFromSIdxUnnestMap.subList(2, 4), sourceLoc);
                AbstractFunctionCallExpression createRectangleExpr = createRectangleExpression(expr1, expr2);
                restoredSKVarFromRTree.add(context.newVar());
                restoredSKFromRTreeExprs.add(new MutableObject<ILogicalExpression>(createRectangleExpr));
                skVarAssignOpInRightPath = new AssignOperator(restoredSKVarFromRTree, restoredSKFromRTreeExprs);
                skVarAssignOpInRightPath.setSourceLocation(sourceLoc);
                break;
            default:
                break;
        }
    }
    // Gets all variables from the right (inner) branch.
    VariableUtilities.getLiveVariables(subTree.getRootRef().getValue(), liveVarsInSubTreeRootOp);
    // Gets the used variables from the SELECT or JOIN operator.
    VariableUtilities.getUsedVariables(topOpRef.getValue(), usedVarsInTopOp);
    // Excludes the variables in the condition from the outer branch - in join case.
    for (Iterator<LogicalVariable> iterator = usedVarsInTopOp.iterator(); iterator.hasNext(); ) {
        LogicalVariable v = iterator.next();
        if (!liveVarsInSubTreeRootOp.contains(v)) {
            iterator.remove();
        }
    }
    // Keeps the unique used variables in the SELECT or JOIN operator.
    copyVarsToAnotherList(usedVarsInTopOp, uniqueUsedVarsInTopOp);
    // we may need to propagate these produced variables via the UNIONALL operator if they are used afterwards.
    if (assignsBeforeTopOpRef != null && !assignsBeforeTopOpRef.isEmpty()) {
        for (int i = 0; i < assignsBeforeTopOpRef.size(); i++) {
            assignBeforeTopOp = assignsBeforeTopOpRef.get(i).getValue();
            varsTmpList.clear();
            VariableUtilities.getProducedVariables(assignBeforeTopOp, varsTmpList);
            copyVarsToAnotherList(varsTmpList, producedVarsInAssignsBeforeTopOp);
        }
    }
    // Adds an optional ASSIGN operator that sits right after the SELECT or JOIN operator.
    // This assign operator keeps any constant expression(s) extracted from the original ASSIGN operators
    // in the subtree and are used after the SELECT or JOIN operator. In usual case,
    // this constant value would be used in a group-by after a left-outer-join and will be removed by the optimizer.
    // We need to conduct this since this variable does not have to be in the both branch of an index-only plan.
    AssignOperator constAssignOp = null;
    ILogicalOperator currentOpAfterTopOp = null;
    List<LogicalVariable> constAssignVars = new ArrayList<>();
    List<Mutable<ILogicalExpression>> constAssignExprs = new ArrayList<>();
    ILogicalOperator currentOp = inputOp;
    boolean constantAssignVarUsedInTopOp = false;
    if (assignsBeforeTopOpRef != null) {
        // From the first ASSIGN (earliest in the plan) to the last ASSGIN (latest)
        for (int i = assignsBeforeTopOpRef.size() - 1; i >= 0; i--) {
            AssignOperator tmpOp = (AssignOperator) assignsBeforeTopOpRef.get(i).getValue();
            List<LogicalVariable> tmpAssignVars = tmpOp.getVariables();
            List<Mutable<ILogicalExpression>> tmpAsssignExprs = tmpOp.getExpressions();
            Iterator<LogicalVariable> varIt = tmpAssignVars.iterator();
            Iterator<Mutable<ILogicalExpression>> exprIt = tmpAsssignExprs.iterator();
            boolean changed = false;
            while (exprIt.hasNext()) {
                Mutable<ILogicalExpression> tmpExpr = exprIt.next();
                LogicalVariable tmpVar = varIt.next();
                if (tmpExpr.getValue().getExpressionTag() == LogicalExpressionTag.CONSTANT) {
                    constAssignVars.add(tmpVar);
                    constAssignExprs.add(tmpExpr);
                    varIt.remove();
                    exprIt.remove();
                    changed = true;
                }
            }
            if (changed) {
                context.computeAndSetTypeEnvironmentForOperator(tmpOp);
            }
        }
        if (!constAssignVars.isEmpty()) {
            // These constants should not be used in the SELECT or JOIN operator.
            for (LogicalVariable v : constAssignVars) {
                if (usedVarsInTopOp.contains(v)) {
                    constantAssignVarUsedInTopOp = true;
                    break;
                }
            }
            // If this assign operator is not used in the SELECT or JOIN operator,
            // we will add this operator after creating UNION operator in the last part of this method.
            constAssignOp = new AssignOperator(constAssignVars, constAssignExprs);
            constAssignOp.setSourceLocation(sourceLoc);
            if (constantAssignVarUsedInTopOp) {
                // Places this assign after the secondary index-search op.
                constAssignOp.getInputs().add(new MutableObject<ILogicalOperator>(inputOp));
                constAssignOp.setExecutionMode(ExecutionMode.PARTITIONED);
                context.computeAndSetTypeEnvironmentForOperator(constAssignOp);
                currentOp = constAssignOp;
            }
        }
    }
    // variables used after SELECT or JOIN operator
    HashSet<LogicalVariable> varsTmpSet = new HashSet<>();
    if (afterTopOpRefs != null) {
        for (Mutable<ILogicalOperator> afterTopOpRef : afterTopOpRefs) {
            varsTmpSet.clear();
            OperatorPropertiesUtil.getFreeVariablesInOp(afterTopOpRef.getValue(), varsTmpSet);
            copyVarsToAnotherList(varsTmpSet, usedVarsAfterTopOp);
        }
    }
    // Now, adds a SPLIT operator to propagate <SK, PK> pair from the secondary-index search to the two paths.
    // And constructs the path from the secondary index search to the SPLIT operator.
    // Fetches the conditional split variable from the secondary-index search
    condSplitVars = AccessMethodUtils.getKeyVarsFromSecondaryUnnestMap(dataset, recordType, metaRecordType, inputOp, secondaryIndex, SecondaryUnnestMapOutputVarType.CONDITIONAL_SPLIT_VAR);
    // Adds a SPLIT operator after the given secondary index-search unnest-map operator.
    splitOp = new SplitOperator(2, new MutableObject<ILogicalExpression>(new VariableReferenceExpression(condSplitVars.get(0))));
    splitOp.setSourceLocation(sourceLoc);
    splitOp.getInputs().add(new MutableObject<ILogicalOperator>(currentOp));
    splitOp.setExecutionMode(ExecutionMode.PARTITIONED);
    context.computeAndSetTypeEnvironmentForOperator(splitOp);
    // To maintain SSA, we assign new variables for the incoming variables in the left branch
    // since the most tuples go to the right branch (instantTryLock success path). Also, the output of
    // UNIONALL should be a new variable. (it cannot be the same to the left or right variable.)
    // Original variables (before SPLIT) to the variables in the left path mapping
    LinkedHashMap<LogicalVariable, LogicalVariable> liveVarAfterSplitToLeftPathMap = new LinkedHashMap<>();
    // output variables to the variables generated in the left branch mapping
    LinkedHashMap<LogicalVariable, LogicalVariable> origPKRecAndSKVarToleftPathMap = new LinkedHashMap<>();
    // Original variables (before SPLIT) to the output variables mapping (mainly for join case)
    LinkedHashMap<LogicalVariable, LogicalVariable> origVarToOutputVarMap = new LinkedHashMap<>();
    List<LogicalVariable> liveVarsAfterSplitOp = new ArrayList<>();
    VariableUtilities.getLiveVariables(splitOp, liveVarsAfterSplitOp);
    ArrayList<LogicalVariable> assignVars = new ArrayList<>();
    ArrayList<Mutable<ILogicalExpression>> assignExprs = new ArrayList<>();
    for (LogicalVariable v : liveVarsAfterSplitOp) {
        LogicalVariable newVar = context.newVar();
        liveVarAfterSplitToLeftPathMap.put(v, newVar);
        assignVars.add(newVar);
        VariableReferenceExpression vRef = new VariableReferenceExpression(v);
        vRef.setSourceLocation(sourceLoc);
        assignExprs.add(new MutableObject<ILogicalExpression>(vRef));
    }
    AssignOperator origVarsToLeftPathVarsAssignOp = new AssignOperator(assignVars, assignExprs);
    origVarsToLeftPathVarsAssignOp.setSourceLocation(sourceLoc);
    origVarsToLeftPathVarsAssignOp.getInputs().add(new MutableObject<ILogicalOperator>(splitOp));
    context.computeAndSetTypeEnvironmentForOperator(origVarsToLeftPathVarsAssignOp);
    origVarsToLeftPathVarsAssignOp.setExecutionMode(ExecutionMode.PARTITIONED);
    // Creates the variable mapping for the UNIONALL operator.
    // PK Variable(s) that will be fed into the primary index-search has been re-assigned in the left path.
    List<LogicalVariable> pkVarsInLeftPathFromSIdxSearchBeforeSplit = new ArrayList<>();
    for (LogicalVariable v : pkVarsFromSIdxUnnestMapOp) {
        pkVarsInLeftPathFromSIdxSearchBeforeSplit.add(liveVarAfterSplitToLeftPathMap.get(v));
    }
    // PK and Record variable(s) from the primary-index search will be reassigned in the left path
    // to make the output of the UNIONALL the original variables from the data-scan.
    List<LogicalVariable> pkVarsFromPIdxSearchInLeftPath = new ArrayList<>();
    for (int i = 0; i < primaryIndexUnnestVars.size(); i++) {
        LogicalVariable replacedVar = context.newVar();
        pkVarsFromPIdxSearchInLeftPath.add(replacedVar);
        origPKRecAndSKVarToleftPathMap.put(primaryIndexUnnestVars.get(i), replacedVar);
    }
    // Then, creates the variable mapping between two paths.
    for (LogicalVariable tVar : usedVarsAfterTopOp) {
        // It should be also a part of the primary key variables.
        if (findVarInTripleVarList(unionVarMap, tVar, false) || !primaryIndexUnnestVars.contains(tVar)) {
            continue;
        }
        int pIndexPKIdx = primaryIndexUnnestVars.indexOf(tVar);
        // from different branch (join case). These cases will be dealt with later.
        if (pIndexPKIdx == -1) {
            continue;
        }
        unionVarMap.add(new Triple<>(pkVarsFromPIdxSearchInLeftPath.get(pIndexPKIdx), pkVarsFromSIdxUnnestMapOp.get(pIndexPKIdx), tVar));
        origVarToOutputVarMap.put(pkVarsFromSIdxUnnestMapOp.get(pIndexPKIdx), tVar);
        // Constructs the mapping between the PK from the original data-scan to the PK
        // from the secondary index search since they are different logical variables.
        origVarToSIdxUnnestMapOpVarMap.put(tVar, pkVarsFromSIdxUnnestMapOp.get(pIndexPKIdx));
    }
    // Are the used variables after SELECT or JOIN operator from the given secondary index?
    for (LogicalVariable tVar : usedVarsAfterTopOp) {
        // Checks whether this variable is already added to the union variable map.
        if (findVarInTripleVarList(unionVarMap, tVar, false)) {
            continue;
        }
        // Should be either used in the condition or a composite index field that is not used in the condition.
        if (!usedVarsInTopOp.contains(tVar) && !producedVarsInAssignsBeforeTopOp.contains(tVar)) {
            continue;
        }
        int sIndexIdx = chosenIndexFieldNames.indexOf(subTree.getVarsToFieldNameMap().get(tVar));
        // In this case, we just propagate the variables later.
        if (sIndexIdx == -1) {
            continue;
        }
        if (idxType == IndexType.RTREE) {
            // In this case, we just propagate the variables later.
            if (!skFieldUsedAfterTopOp && !requireVerificationAfterSIdxSearch) {
                continue;
            }
            LogicalVariable replacedVar = context.newVar();
            origPKRecAndSKVarToleftPathMap.put(tVar, replacedVar);
            origSKFieldVarToNewSKFieldVarMap.put(tVar, restoredSKVarFromRTree.get(sIndexIdx));
            unionVarMap.add(new Triple<>(replacedVar, restoredSKVarFromRTree.get(sIndexIdx), tVar));
            continue;
        }
        // B-Tree case:
        LogicalVariable replacedVar = context.newVar();
        origPKRecAndSKVarToleftPathMap.put(tVar, replacedVar);
        origVarToOutputVarMap.put(skVarsFromSIdxUnnestMap.get(sIndexIdx), tVar);
        unionVarMap.add(new Triple<LogicalVariable, LogicalVariable, LogicalVariable>(replacedVar, skVarsFromSIdxUnnestMap.get(sIndexIdx), tVar));
        // Constructs the mapping between the SK from the original data-scan
        // and the SK from the secondary index search since they are different logical variables.
        origVarToSIdxUnnestMapOpVarMap.put(tVar, skVarsFromSIdxUnnestMap.get(sIndexIdx));
    }
    // For B-Tree case: if the given secondary key field variable is used only in the select or
    // join condition, we were not able to catch the mapping between the the SK from the original
    // data-scan and the SK from the secondary index search since they are different logical variables.
    // (E.g., we are sending a query on a composite index but returns only one field.)
    List<LogicalVariable> varsUsedInTopOpButNotAfterwards = new ArrayList<>();
    copyVarsToAnotherList(uniqueUsedVarsInTopOp, varsUsedInTopOpButNotAfterwards);
    for (LogicalVariable v : usedVarsAfterTopOp) {
        if (varsUsedInTopOpButNotAfterwards.contains(v)) {
            varsUsedInTopOpButNotAfterwards.remove(v);
        }
    }
    if (idxType == IndexType.BTREE) {
        for (LogicalVariable v : varsUsedInTopOpButNotAfterwards) {
            int sIndexIdx = chosenIndexFieldNames.indexOf(subTree.getVarsToFieldNameMap().get(v));
            // In this case, we just propagate the variables later.
            if (sIndexIdx == -1) {
                continue;
            }
            LogicalVariable replacedVar = context.newVar();
            origPKRecAndSKVarToleftPathMap.put(v, replacedVar);
            origVarToOutputVarMap.put(skVarsFromSIdxUnnestMap.get(sIndexIdx), v);
            // Constructs the mapping between the SK from the original data-scan
            // and the SK from the secondary index search since they are different logical variables.
            origVarToSIdxUnnestMapOpVarMap.put(v, skVarsFromSIdxUnnestMap.get(sIndexIdx));
        }
    }
    // secondary key field in the assign operator in the right path.
    if (idxType == IndexType.RTREE && (skFieldUsedAfterTopOp || requireVerificationAfterSIdxSearch)) {
        for (LogicalVariable v : uniqueUsedVarsInTopOp) {
            if (!primaryIndexUnnestVars.contains(v)) {
                origSKFieldVarToNewSKFieldVarMap.put(v, restoredSKVarFromRTree.get(0));
            }
        }
    }
    // For the index-nested-loop join case,
    // we propagate all variables that come from the outer relation and are used after join operator.
    // Adds the variables that are both live after JOIN and used after the JOIN operator.
    VariableUtilities.getLiveVariables(topOpRef.getValue(), liveVarsAfterTopOp);
    for (LogicalVariable v : usedVarsAfterTopOp) {
        if (!liveVarsAfterTopOp.contains(v) || findVarInTripleVarList(unionVarMap, v, false)) {
            continue;
        }
        LogicalVariable outputVar = context.newVar();
        origVarToOutputVarMap.put(v, outputVar);
        unionVarMap.add(new Triple<>(liveVarAfterSplitToLeftPathMap.get(v), v, outputVar));
    }
    // Replaces the original variables in the operators after the SELECT or JOIN operator to satisfy SSA.
    if (afterTopOpRefs != null) {
        for (Mutable<ILogicalOperator> afterTopOpRef : afterTopOpRefs) {
            VariableUtilities.substituteVariables(afterTopOpRef.getValue(), origVarToOutputVarMap, context);
        }
    }
    // Creates the primary index lookup operator.
    // The job gen parameters are transferred to the actual job gen via the UnnestMapOperator's function arguments.
    AbstractUnnestMapOperator primaryIndexUnnestMapOp = createPrimaryIndexUnnestMapOp(dataset, retainInput, retainMissing, requiresBroadcast, pkVarsInLeftPathFromSIdxSearchBeforeSplit, pkVarsFromPIdxSearchInLeftPath, primaryIndexOutputTypes, sourceLoc);
    primaryIndexUnnestMapOp.setSourceLocation(sourceLoc);
    primaryIndexUnnestMapOp.getInputs().add(new MutableObject<ILogicalOperator>(origVarsToLeftPathVarsAssignOp));
    context.computeAndSetTypeEnvironmentForOperator(primaryIndexUnnestMapOp);
    primaryIndexUnnestMapOp.setExecutionMode(ExecutionMode.PARTITIONED);
    // Now, generates the UnionAllOperator to merge the left and right paths.
    // If we are transforming a join, in the instantTryLock on PK fail path, a SELECT operator should be
    // constructed from the join condition and placed after the primary index lookup
    // to do the final verification. If this is a select plan, we just need to use the original
    // SELECT operator after the primary index lookup to do the final verification.
    LinkedHashMap<LogicalVariable, LogicalVariable> origVarToNewVarInLeftPathMap = new LinkedHashMap<>();
    origVarToNewVarInLeftPathMap.putAll(liveVarAfterSplitToLeftPathMap);
    origVarToNewVarInLeftPathMap.putAll(origPKRecAndSKVarToleftPathMap);
    ILogicalExpression conditionRefExpr = conditionRef.getValue().cloneExpression();
    // The retainMissing variable contains the information whether we are optimizing a left-outer join or not.
    LogicalVariable newMissingPlaceHolderVar = retainMissing ? newMissingPlaceHolderForLOJ : null;
    newSelectOpInLeftPath = new SelectOperator(new MutableObject<ILogicalExpression>(conditionRefExpr), retainMissing, newMissingPlaceHolderVar);
    newSelectOpInLeftPath.setSourceLocation(conditionRefExpr.getSourceLocation());
    VariableUtilities.substituteVariables(newSelectOpInLeftPath, origVarToNewVarInLeftPathMap, context);
    // we need to put these operators between the SELECT or JOIN and the primary index lookup in the left path.
    if (assignsBeforeTopOpRef != null) {
        // Makes the primary unnest-map as the child of the last ASSIGN (from top) in the path.
        assignBeforeTopOp = assignsBeforeTopOpRef.get(assignsBeforeTopOpRef.size() - 1).getValue();
        assignBeforeTopOp.getInputs().clear();
        assignBeforeTopOp.getInputs().add(new MutableObject<ILogicalOperator>(primaryIndexUnnestMapOp));
        // Makes the first ASSIGN (from top) as the child of the SELECT operator.
        for (int i = assignsBeforeTopOpRef.size() - 1; i >= 0; i--) {
            if (assignsBeforeTopOpRef.get(i) != null) {
                AbstractLogicalOperator assignTmpOp = (AbstractLogicalOperator) assignsBeforeTopOpRef.get(i).getValue();
                assignTmpOp.setExecutionMode(ExecutionMode.PARTITIONED);
                VariableUtilities.substituteVariables(assignTmpOp, origVarToNewVarInLeftPathMap, context);
                context.computeAndSetTypeEnvironmentForOperator(assignTmpOp);
            }
        }
        newSelectOpInLeftPath.getInputs().clear();
        newSelectOpInLeftPath.getInputs().add(new MutableObject<ILogicalOperator>(assignsBeforeTopOpRef.get(0).getValue()));
    } else {
        newSelectOpInLeftPath.getInputs().add(new MutableObject<ILogicalOperator>(primaryIndexUnnestMapOp));
    }
    newSelectOpInLeftPath.setExecutionMode(ExecutionMode.PARTITIONED);
    context.computeAndSetTypeEnvironmentForOperator(newSelectOpInLeftPath);
    // Now, we take care of the right path (instantTryLock on PK success path).
    ILogicalOperator currentTopOpInRightPath = splitOp;
    // This is done by adding the following assign operator that we have made in the beginning of this method.
    if (skVarAssignOpInRightPath != null) {
        skVarAssignOpInRightPath.getInputs().add(new MutableObject<ILogicalOperator>(splitOp));
        skVarAssignOpInRightPath.setExecutionMode(ExecutionMode.PARTITIONED);
        context.computeAndSetTypeEnvironmentForOperator(skVarAssignOpInRightPath);
        currentTopOpInRightPath = skVarAssignOpInRightPath;
    }
    // (e.g., where $a.authors /*+ indexnl */ = $b.authors and $a.id = $b.id   <- authors:SK, id:PK)
    if ((idxType == IndexType.RTREE || uniqueUsedVarsInTopOp.size() > 1) && requireVerificationAfterSIdxSearch) {
        // Creates a new SELECT operator by deep-copying the SELECT operator in the left path
        // since we need to change the variable reference in the SELECT operator.
        // For the index-nested-loop join case, we copy the condition of the join operator.
        ILogicalExpression conditionRefExpr2 = conditionRef.getValue().cloneExpression();
        newSelectOpInRightPath = new SelectOperator(new MutableObject<ILogicalExpression>(conditionRefExpr2), retainMissing, newMissingPlaceHolderVar);
        newSelectOpInRightPath.setSourceLocation(conditionRefExpr2.getSourceLocation());
        newSelectOpInRightPath.getInputs().add(new MutableObject<ILogicalOperator>(currentTopOpInRightPath));
        VariableUtilities.substituteVariables(newSelectOpInRightPath, origVarToSIdxUnnestMapOpVarMap, context);
        VariableUtilities.substituteVariables(newSelectOpInRightPath, origSKFieldVarToNewSKFieldVarMap, context);
        newSelectOpInRightPath.setExecutionMode(ExecutionMode.PARTITIONED);
        context.computeAndSetTypeEnvironmentForOperator(newSelectOpInRightPath);
        currentTopOpInRightPath = newSelectOpInRightPath;
    }
    // The assumption here is that this variable is the first PK variable that was set.
    if (retainMissing && newMissingPlaceHolderForLOJ == primaryIndexUnnestVars.get(0) && !findVarInTripleVarList(unionVarMap, newMissingPlaceHolderForLOJ, false)) {
        unionVarMap.add(new Triple<>(origPKRecAndSKVarToleftPathMap.get(newMissingPlaceHolderForLOJ), pkVarsFromSIdxUnnestMapOp.get(0), newMissingPlaceHolderForLOJ));
    }
    // UNIONALL operator that combines both paths.
    unionAllOp = new UnionAllOperator(unionVarMap);
    unionAllOp.setSourceLocation(sourceLoc);
    unionAllOp.getInputs().add(new MutableObject<ILogicalOperator>(newSelectOpInLeftPath));
    unionAllOp.getInputs().add(new MutableObject<ILogicalOperator>(currentTopOpInRightPath));
    unionAllOp.setExecutionMode(ExecutionMode.PARTITIONED);
    context.computeAndSetTypeEnvironmentForOperator(unionAllOp);
    // If an assign operator that keeps constant values was added, set the UNIONALL operator as its child.
    if (!constAssignVars.isEmpty() && !constantAssignVarUsedInTopOp) {
        constAssignOp.getInputs().clear();
        constAssignOp.getInputs().add(new MutableObject<ILogicalOperator>(unionAllOp));
        constAssignOp.setExecutionMode(ExecutionMode.PARTITIONED);
        context.computeAndSetTypeEnvironmentForOperator(constAssignOp);
        // This constant assign operator is the new child of the first operator after the original
        // SELECT or JOIN operator.
        currentOpAfterTopOp = afterTopOpRefs.get(afterTopOpRefs.size() - 1).getValue();
        currentOpAfterTopOp.getInputs().clear();
        currentOpAfterTopOp.getInputs().add(new MutableObject<ILogicalOperator>(constAssignOp));
        context.computeAndSetTypeEnvironmentForOperator(currentOpAfterTopOp);
        afterTopOpRefs.add(new MutableObject<ILogicalOperator>(constAssignOp));
    }
    // Index-only plan is now constructed. Return this operator to the caller.
    return unionAllOp;
}
#method_after
private static ILogicalOperator createFinalIndexOnlySearchPlan(List<Mutable<ILogicalOperator>> afterTopOpRefs, Mutable<ILogicalOperator> topOpRef, Mutable<ILogicalExpression> conditionRef, List<Mutable<ILogicalOperator>> assignsBeforeTopOpRef, Dataset dataset, ARecordType recordType, ARecordType metaRecordType, ILogicalOperator inputOp, IOptimizationContext context, boolean retainInput, boolean retainMissing, boolean requiresBroadcast, Index secondaryIndex, AccessMethodAnalysisContext analysisCtx, OptimizableOperatorSubTree subTree, LogicalVariable newMissingPlaceHolderForLOJ, List<LogicalVariable> pkVarsFromSIdxUnnestMapOp, List<LogicalVariable> primaryIndexUnnestVars, List<Object> primaryIndexOutputTypes) throws AlgebricksException {
    SourceLocation sourceLoc = inputOp.getSourceLocation();
    Quadruple<Boolean, Boolean, Boolean, Boolean> indexOnlyPlanInfo = analysisCtx.getIndexOnlyPlanInfo();
    // From now on, we deal with the index-only plan.
    // Initializes the information required for the index-only plan optimization.
    // Fetches SK variable(s) from the secondary-index search operator.
    List<LogicalVariable> skVarsFromSIdxUnnestMap = AccessMethodUtils.getKeyVarsFromSecondaryUnnestMap(dataset, recordType, metaRecordType, inputOp, secondaryIndex, SecondaryUnnestMapOutputVarType.SECONDARY_KEY);
    boolean skFieldUsedAfterTopOp = indexOnlyPlanInfo.getSecond();
    boolean requireVerificationAfterSIdxSearch = indexOnlyPlanInfo.getThird();
    ILogicalOperator assignBeforeTopOp;
    UnionAllOperator unionAllOp;
    SelectOperator newSelectOpInLeftPath;
    SelectOperator newSelectOpInRightPath;
    SplitOperator splitOp = null;
    // This variable map will be used as input to UNIONALL operator. The form is <left, right, output>.
    // In our case, left: instantTryLock fail path, right: instantTryLock success path
    List<Triple<LogicalVariable, LogicalVariable, LogicalVariable>> unionVarMap = new ArrayList<>();
    List<LogicalVariable> condSplitVars;
    List<LogicalVariable> liveVarsAfterTopOp = new ArrayList<>();
    // Constructs the variable mapping between newly constructed secondary
    // key search (SK, PK) and those in the original plan (datasource scan).
    LinkedHashMap<LogicalVariable, LogicalVariable> origVarToSIdxUnnestMapOpVarMap = new LinkedHashMap<>();
    List<List<String>> chosenIndexFieldNames = secondaryIndex.getKeyFieldNames();
    IndexType idxType = secondaryIndex.getIndexType();
    // variables used in SELECT or JOIN operator
    List<LogicalVariable> usedVarsInTopOp = new ArrayList<>();
    List<LogicalVariable> uniqueUsedVarsInTopOp = new ArrayList<>();
    // variables used in ASSIGN before SELECT operator
    List<LogicalVariable> producedVarsInAssignsBeforeTopOp = new ArrayList<>();
    // For the index-nested-loop join case, we need to exclude the variables from the left (outer) branch
    // when deciding which variables should be propagated via UNIONALL operator.
    // This is because these variables are already generated and is not related to the decision
    // whether the plan is an index-only plan or not. Only the right (inner) branch matters.
    List<LogicalVariable> liveVarsInSubTreeRootOp = new ArrayList<>();
    // variables used after SELECT or JOIN operator
    List<LogicalVariable> usedVarsAfterTopOp = new ArrayList<>();
    List<LogicalVariable> varsTmpList = new ArrayList<>();
    // If the secondary key field is used after SELECT or JOIN operator (e.g., returning the field value),
    // then we need to keep these secondary keys. In case of R-tree index, the result of an R-tree
    // index search is an MBR. So, we need to reconstruct original field values from the result if that index
    // is on a rectangle or point.
    AssignOperator skVarAssignOpInRightPath = null;
    List<LogicalVariable> restoredSKVarFromRTree = null;
    // Original SK field variable to restored SK field variable in the right path mapping
    LinkedHashMap<LogicalVariable, LogicalVariable> origSKFieldVarToNewSKFieldVarMap = new LinkedHashMap<>();
    // index is RECTANGLE or POINT (in this case only, removing false-positive is possible.).
    if (idxType == IndexType.RTREE && (skFieldUsedAfterTopOp || requireVerificationAfterSIdxSearch)) {
        IOptimizableFuncExpr optFuncExpr = AccessMethodUtils.chooseFirstOptFuncExpr(secondaryIndex, analysisCtx);
        int optFieldIdx = AccessMethodUtils.chooseFirstOptFuncVar(secondaryIndex, analysisCtx);
        Pair<IAType, Boolean> keyPairType = Index.getNonNullableOpenFieldType(optFuncExpr.getFieldType(optFieldIdx), optFuncExpr.getFieldName(optFieldIdx), recordType);
        if (keyPairType == null) {
            return null;
        }
        // Gets the number of dimensions corresponding to the field indexed by chosenIndex.
        IAType spatialType = keyPairType.first;
        ArrayList<Mutable<ILogicalExpression>> restoredSKFromRTreeExprs = new ArrayList<>();
        restoredSKVarFromRTree = new ArrayList<>();
        switch(spatialType.getTypeTag()) {
            case POINT:
                // Reconstructs a POINT value.
                AbstractFunctionCallExpression createPointExpr = createPointExpression(skVarsFromSIdxUnnestMap, sourceLoc);
                restoredSKVarFromRTree.add(context.newVar());
                restoredSKFromRTreeExprs.add(new MutableObject<ILogicalExpression>(createPointExpr));
                skVarAssignOpInRightPath = new AssignOperator(restoredSKVarFromRTree, restoredSKFromRTreeExprs);
                skVarAssignOpInRightPath.setSourceLocation(sourceLoc);
                break;
            case RECTANGLE:
                // Reconstructs a RECTANGLE value.
                AbstractFunctionCallExpression expr1 = createPointExpression(skVarsFromSIdxUnnestMap.subList(0, 2), sourceLoc);
                AbstractFunctionCallExpression expr2 = createPointExpression(skVarsFromSIdxUnnestMap.subList(2, 4), sourceLoc);
                AbstractFunctionCallExpression createRectangleExpr = createRectangleExpression(expr1, expr2);
                restoredSKVarFromRTree.add(context.newVar());
                restoredSKFromRTreeExprs.add(new MutableObject<ILogicalExpression>(createRectangleExpr));
                skVarAssignOpInRightPath = new AssignOperator(restoredSKVarFromRTree, restoredSKFromRTreeExprs);
                skVarAssignOpInRightPath.setSourceLocation(sourceLoc);
                break;
            default:
                break;
        }
    }
    // Gets all variables from the right (inner) branch.
    VariableUtilities.getLiveVariables(subTree.getRootRef().getValue(), liveVarsInSubTreeRootOp);
    // Gets the used variables from the SELECT or JOIN operator.
    VariableUtilities.getUsedVariables(topOpRef.getValue(), usedVarsInTopOp);
    // Excludes the variables in the condition from the outer branch - in join case.
    for (Iterator<LogicalVariable> iterator = usedVarsInTopOp.iterator(); iterator.hasNext(); ) {
        LogicalVariable v = iterator.next();
        if (!liveVarsInSubTreeRootOp.contains(v)) {
            iterator.remove();
        }
    }
    // Keeps the unique used variables in the SELECT or JOIN operator.
    copyVarsToAnotherList(usedVarsInTopOp, uniqueUsedVarsInTopOp);
    // we may need to propagate these produced variables via the UNIONALL operator if they are used afterwards.
    if (assignsBeforeTopOpRef != null && !assignsBeforeTopOpRef.isEmpty()) {
        for (int i = 0; i < assignsBeforeTopOpRef.size(); i++) {
            assignBeforeTopOp = assignsBeforeTopOpRef.get(i).getValue();
            varsTmpList.clear();
            VariableUtilities.getProducedVariables(assignBeforeTopOp, varsTmpList);
            copyVarsToAnotherList(varsTmpList, producedVarsInAssignsBeforeTopOp);
        }
    }
    // Adds an optional ASSIGN operator that sits right after the SELECT or JOIN operator.
    // This assign operator keeps any constant expression(s) extracted from the original ASSIGN operators
    // in the subtree and are used after the SELECT or JOIN operator. In usual case,
    // this constant value would be used in a group-by after a left-outer-join and will be removed by the optimizer.
    // We need to conduct this since this variable does not have to be in the both branch of an index-only plan.
    AssignOperator constAssignOp = null;
    ILogicalOperator currentOpAfterTopOp = null;
    List<LogicalVariable> constAssignVars = new ArrayList<>();
    List<Mutable<ILogicalExpression>> constAssignExprs = new ArrayList<>();
    ILogicalOperator currentOp = inputOp;
    boolean constantAssignVarUsedInTopOp = false;
    if (assignsBeforeTopOpRef != null) {
        // From the first ASSIGN (earliest in the plan) to the last ASSGIN (latest)
        for (int i = assignsBeforeTopOpRef.size() - 1; i >= 0; i--) {
            AssignOperator tmpOp = (AssignOperator) assignsBeforeTopOpRef.get(i).getValue();
            List<LogicalVariable> tmpAssignVars = tmpOp.getVariables();
            List<Mutable<ILogicalExpression>> tmpAsssignExprs = tmpOp.getExpressions();
            Iterator<LogicalVariable> varIt = tmpAssignVars.iterator();
            Iterator<Mutable<ILogicalExpression>> exprIt = tmpAsssignExprs.iterator();
            boolean changed = false;
            while (exprIt.hasNext()) {
                Mutable<ILogicalExpression> tmpExpr = exprIt.next();
                LogicalVariable tmpVar = varIt.next();
                if (tmpExpr.getValue().getExpressionTag() == LogicalExpressionTag.CONSTANT) {
                    constAssignVars.add(tmpVar);
                    constAssignExprs.add(tmpExpr);
                    varIt.remove();
                    exprIt.remove();
                    changed = true;
                }
            }
            if (changed) {
                context.computeAndSetTypeEnvironmentForOperator(tmpOp);
            }
        }
        if (!constAssignVars.isEmpty()) {
            // These constants should not be used in the SELECT or JOIN operator.
            for (LogicalVariable v : constAssignVars) {
                if (usedVarsInTopOp.contains(v)) {
                    constantAssignVarUsedInTopOp = true;
                    break;
                }
            }
            // If this assign operator is not used in the SELECT or JOIN operator,
            // we will add this operator after creating UNION operator in the last part of this method.
            constAssignOp = new AssignOperator(constAssignVars, constAssignExprs);
            constAssignOp.setSourceLocation(sourceLoc);
            if (constantAssignVarUsedInTopOp) {
                // Places this assign after the secondary index-search op.
                constAssignOp.getInputs().add(new MutableObject<ILogicalOperator>(inputOp));
                constAssignOp.setExecutionMode(ExecutionMode.PARTITIONED);
                context.computeAndSetTypeEnvironmentForOperator(constAssignOp);
                currentOp = constAssignOp;
            }
        }
    }
    // variables used after SELECT or JOIN operator
    HashSet<LogicalVariable> varsTmpSet = new HashSet<>();
    if (afterTopOpRefs != null) {
        for (Mutable<ILogicalOperator> afterTopOpRef : afterTopOpRefs) {
            varsTmpSet.clear();
            OperatorPropertiesUtil.getFreeVariablesInOp(afterTopOpRef.getValue(), varsTmpSet);
            copyVarsToAnotherList(varsTmpSet, usedVarsAfterTopOp);
        }
    }
    // Now, adds a SPLIT operator to propagate <SK, PK> pair from the secondary-index search to the two paths.
    // And constructs the path from the secondary index search to the SPLIT operator.
    // Fetches the conditional split variable from the secondary-index search
    condSplitVars = AccessMethodUtils.getKeyVarsFromSecondaryUnnestMap(dataset, recordType, metaRecordType, inputOp, secondaryIndex, SecondaryUnnestMapOutputVarType.CONDITIONAL_SPLIT_VAR);
    // Adds a SPLIT operator after the given secondary index-search unnest-map operator.
    splitOp = new SplitOperator(2, new MutableObject<ILogicalExpression>(new VariableReferenceExpression(condSplitVars.get(0))));
    splitOp.setSourceLocation(sourceLoc);
    splitOp.getInputs().add(new MutableObject<ILogicalOperator>(currentOp));
    splitOp.setExecutionMode(ExecutionMode.PARTITIONED);
    context.computeAndSetTypeEnvironmentForOperator(splitOp);
    // To maintain SSA, we assign new variables for the incoming variables in the left branch
    // since the most tuples go to the right branch (instantTryLock success path). Also, the output of
    // UNIONALL should be a new variable. (it cannot be the same to the left or right variable.)
    // Original variables (before SPLIT) to the variables in the left path mapping
    LinkedHashMap<LogicalVariable, LogicalVariable> liveVarAfterSplitToLeftPathMap = new LinkedHashMap<>();
    // output variables to the variables generated in the left branch mapping
    LinkedHashMap<LogicalVariable, LogicalVariable> origPKRecAndSKVarToleftPathMap = new LinkedHashMap<>();
    // Original variables (before SPLIT) to the output variables mapping (mainly for join case)
    LinkedHashMap<LogicalVariable, LogicalVariable> origVarToOutputVarMap = new LinkedHashMap<>();
    List<LogicalVariable> liveVarsAfterSplitOp = new ArrayList<>();
    VariableUtilities.getLiveVariables(splitOp, liveVarsAfterSplitOp);
    ArrayList<LogicalVariable> assignVars = new ArrayList<>();
    ArrayList<Mutable<ILogicalExpression>> assignExprs = new ArrayList<>();
    for (LogicalVariable v : liveVarsAfterSplitOp) {
        LogicalVariable newVar = context.newVar();
        liveVarAfterSplitToLeftPathMap.put(v, newVar);
        assignVars.add(newVar);
        VariableReferenceExpression vRef = new VariableReferenceExpression(v);
        vRef.setSourceLocation(sourceLoc);
        assignExprs.add(new MutableObject<ILogicalExpression>(vRef));
    }
    AssignOperator origVarsToLeftPathVarsAssignOp = new AssignOperator(assignVars, assignExprs);
    origVarsToLeftPathVarsAssignOp.setSourceLocation(sourceLoc);
    origVarsToLeftPathVarsAssignOp.getInputs().add(new MutableObject<ILogicalOperator>(splitOp));
    context.computeAndSetTypeEnvironmentForOperator(origVarsToLeftPathVarsAssignOp);
    origVarsToLeftPathVarsAssignOp.setExecutionMode(ExecutionMode.PARTITIONED);
    // Creates the variable mapping for the UNIONALL operator.
    // PK Variable(s) that will be fed into the primary index-search has been re-assigned in the left path.
    List<LogicalVariable> pkVarsInLeftPathFromSIdxSearchBeforeSplit = new ArrayList<>();
    for (LogicalVariable v : pkVarsFromSIdxUnnestMapOp) {
        pkVarsInLeftPathFromSIdxSearchBeforeSplit.add(liveVarAfterSplitToLeftPathMap.get(v));
    }
    // PK and Record variable(s) from the primary-index search will be reassigned in the left path
    // to make the output of the UNIONALL the original variables from the data-scan.
    List<LogicalVariable> pkVarsFromPIdxSearchInLeftPath = new ArrayList<>();
    for (int i = 0; i < primaryIndexUnnestVars.size(); i++) {
        LogicalVariable replacedVar = context.newVar();
        pkVarsFromPIdxSearchInLeftPath.add(replacedVar);
        origPKRecAndSKVarToleftPathMap.put(primaryIndexUnnestVars.get(i), replacedVar);
    }
    // Then, creates the variable mapping between two paths.
    for (LogicalVariable tVar : usedVarsAfterTopOp) {
        // It should be also a part of the primary key variables.
        if (findVarInTripleVarList(unionVarMap, tVar, false) || !primaryIndexUnnestVars.contains(tVar)) {
            continue;
        }
        int pIndexPKIdx = primaryIndexUnnestVars.indexOf(tVar);
        // from different branch (join case). These cases will be dealt with later.
        if (pIndexPKIdx == -1) {
            continue;
        }
        unionVarMap.add(new Triple<>(pkVarsFromPIdxSearchInLeftPath.get(pIndexPKIdx), pkVarsFromSIdxUnnestMapOp.get(pIndexPKIdx), tVar));
        origVarToOutputVarMap.put(pkVarsFromSIdxUnnestMapOp.get(pIndexPKIdx), tVar);
        // Constructs the mapping between the PK from the original data-scan to the PK
        // from the secondary index search since they are different logical variables.
        origVarToSIdxUnnestMapOpVarMap.put(tVar, pkVarsFromSIdxUnnestMapOp.get(pIndexPKIdx));
    }
    // Are the used variables after SELECT or JOIN operator from the given secondary index?
    for (LogicalVariable tVar : usedVarsAfterTopOp) {
        // Checks whether this variable is already added to the union variable map.
        if (findVarInTripleVarList(unionVarMap, tVar, false)) {
            continue;
        }
        // Should be either used in the condition or a composite index field that is not used in the condition.
        if (!usedVarsInTopOp.contains(tVar) && !producedVarsInAssignsBeforeTopOp.contains(tVar)) {
            continue;
        }
        int sIndexIdx = chosenIndexFieldNames.indexOf(subTree.getVarsToFieldNameMap().get(tVar));
        // In this case, we just propagate the variables later.
        if (sIndexIdx == -1) {
            continue;
        }
        if (idxType == IndexType.RTREE) {
            // In this case, we just propagate the variables later.
            if (!skFieldUsedAfterTopOp && !requireVerificationAfterSIdxSearch) {
                continue;
            }
            LogicalVariable replacedVar = context.newVar();
            origPKRecAndSKVarToleftPathMap.put(tVar, replacedVar);
            origSKFieldVarToNewSKFieldVarMap.put(tVar, restoredSKVarFromRTree.get(sIndexIdx));
            unionVarMap.add(new Triple<>(replacedVar, restoredSKVarFromRTree.get(sIndexIdx), tVar));
            continue;
        }
        // B-Tree case:
        LogicalVariable replacedVar = context.newVar();
        origPKRecAndSKVarToleftPathMap.put(tVar, replacedVar);
        origVarToOutputVarMap.put(skVarsFromSIdxUnnestMap.get(sIndexIdx), tVar);
        unionVarMap.add(new Triple<LogicalVariable, LogicalVariable, LogicalVariable>(replacedVar, skVarsFromSIdxUnnestMap.get(sIndexIdx), tVar));
        // Constructs the mapping between the SK from the original data-scan
        // and the SK from the secondary index search since they are different logical variables.
        origVarToSIdxUnnestMapOpVarMap.put(tVar, skVarsFromSIdxUnnestMap.get(sIndexIdx));
    }
    // For B-Tree case: if the given secondary key field variable is used only in the select or
    // join condition, we were not able to catch the mapping between the the SK from the original
    // data-scan and the SK from the secondary index search since they are different logical variables.
    // (E.g., we are sending a query on a composite index but returns only one field.)
    List<LogicalVariable> varsUsedInTopOpButNotAfterwards = new ArrayList<>();
    copyVarsToAnotherList(uniqueUsedVarsInTopOp, varsUsedInTopOpButNotAfterwards);
    varsUsedInTopOpButNotAfterwards.removeAll(usedVarsAfterTopOp);
    if (idxType == IndexType.BTREE) {
        for (LogicalVariable v : varsUsedInTopOpButNotAfterwards) {
            int sIndexIdx = chosenIndexFieldNames.indexOf(subTree.getVarsToFieldNameMap().get(v));
            // In this case, we just propagate the variables later.
            if (sIndexIdx == -1) {
                continue;
            }
            LogicalVariable replacedVar = context.newVar();
            origPKRecAndSKVarToleftPathMap.put(v, replacedVar);
            origVarToOutputVarMap.put(skVarsFromSIdxUnnestMap.get(sIndexIdx), v);
            // Constructs the mapping between the SK from the original data-scan
            // and the SK from the secondary index search since they are different logical variables.
            origVarToSIdxUnnestMapOpVarMap.put(v, skVarsFromSIdxUnnestMap.get(sIndexIdx));
        }
    }
    // secondary key field in the assign operator in the right path.
    if (idxType == IndexType.RTREE && (skFieldUsedAfterTopOp || requireVerificationAfterSIdxSearch)) {
        for (LogicalVariable v : uniqueUsedVarsInTopOp) {
            if (!primaryIndexUnnestVars.contains(v)) {
                origSKFieldVarToNewSKFieldVarMap.put(v, restoredSKVarFromRTree.get(0));
            }
        }
    }
    // For the index-nested-loop join case,
    // we propagate all variables that come from the outer relation and are used after join operator.
    // Adds the variables that are both live after JOIN and used after the JOIN operator.
    VariableUtilities.getLiveVariables(topOpRef.getValue(), liveVarsAfterTopOp);
    for (LogicalVariable v : usedVarsAfterTopOp) {
        if (!liveVarsAfterTopOp.contains(v) || findVarInTripleVarList(unionVarMap, v, false)) {
            continue;
        }
        LogicalVariable outputVar = context.newVar();
        origVarToOutputVarMap.put(v, outputVar);
        unionVarMap.add(new Triple<>(liveVarAfterSplitToLeftPathMap.get(v), v, outputVar));
    }
    // Replaces the original variables in the operators after the SELECT or JOIN operator to satisfy SSA.
    if (afterTopOpRefs != null) {
        for (Mutable<ILogicalOperator> afterTopOpRef : afterTopOpRefs) {
            VariableUtilities.substituteVariables(afterTopOpRef.getValue(), origVarToOutputVarMap, context);
        }
    }
    // Creates the primary index lookup operator.
    // The job gen parameters are transferred to the actual job gen via the UnnestMapOperator's function arguments.
    AbstractUnnestMapOperator primaryIndexUnnestMapOp = createPrimaryIndexUnnestMapOp(dataset, retainInput, retainMissing, requiresBroadcast, pkVarsInLeftPathFromSIdxSearchBeforeSplit, pkVarsFromPIdxSearchInLeftPath, primaryIndexOutputTypes, sourceLoc);
    primaryIndexUnnestMapOp.setSourceLocation(sourceLoc);
    primaryIndexUnnestMapOp.getInputs().add(new MutableObject<ILogicalOperator>(origVarsToLeftPathVarsAssignOp));
    context.computeAndSetTypeEnvironmentForOperator(primaryIndexUnnestMapOp);
    primaryIndexUnnestMapOp.setExecutionMode(ExecutionMode.PARTITIONED);
    // Now, generates the UnionAllOperator to merge the left and right paths.
    // If we are transforming a join, in the instantTryLock on PK fail path, a SELECT operator should be
    // constructed from the join condition and placed after the primary index lookup
    // to do the final verification. If this is a select plan, we just need to use the original
    // SELECT operator after the primary index lookup to do the final verification.
    LinkedHashMap<LogicalVariable, LogicalVariable> origVarToNewVarInLeftPathMap = new LinkedHashMap<>();
    origVarToNewVarInLeftPathMap.putAll(liveVarAfterSplitToLeftPathMap);
    origVarToNewVarInLeftPathMap.putAll(origPKRecAndSKVarToleftPathMap);
    ILogicalExpression conditionRefExpr = conditionRef.getValue().cloneExpression();
    // The retainMissing variable contains the information whether we are optimizing a left-outer join or not.
    LogicalVariable newMissingPlaceHolderVar = retainMissing ? newMissingPlaceHolderForLOJ : null;
    newSelectOpInLeftPath = new SelectOperator(new MutableObject<ILogicalExpression>(conditionRefExpr), retainMissing, newMissingPlaceHolderVar);
    newSelectOpInLeftPath.setSourceLocation(conditionRefExpr.getSourceLocation());
    VariableUtilities.substituteVariables(newSelectOpInLeftPath, origVarToNewVarInLeftPathMap, context);
    // we need to put these operators between the SELECT or JOIN and the primary index lookup in the left path.
    if (assignsBeforeTopOpRef != null) {
        // Makes the primary unnest-map as the child of the last ASSIGN (from top) in the path.
        assignBeforeTopOp = assignsBeforeTopOpRef.get(assignsBeforeTopOpRef.size() - 1).getValue();
        assignBeforeTopOp.getInputs().clear();
        assignBeforeTopOp.getInputs().add(new MutableObject<ILogicalOperator>(primaryIndexUnnestMapOp));
        // Makes the first ASSIGN (from top) as the child of the SELECT operator.
        for (int i = assignsBeforeTopOpRef.size() - 1; i >= 0; i--) {
            if (assignsBeforeTopOpRef.get(i) != null) {
                AbstractLogicalOperator assignTmpOp = (AbstractLogicalOperator) assignsBeforeTopOpRef.get(i).getValue();
                assignTmpOp.setExecutionMode(ExecutionMode.PARTITIONED);
                VariableUtilities.substituteVariables(assignTmpOp, origVarToNewVarInLeftPathMap, context);
                context.computeAndSetTypeEnvironmentForOperator(assignTmpOp);
            }
        }
        newSelectOpInLeftPath.getInputs().clear();
        newSelectOpInLeftPath.getInputs().add(new MutableObject<ILogicalOperator>(assignsBeforeTopOpRef.get(0).getValue()));
    } else {
        newSelectOpInLeftPath.getInputs().add(new MutableObject<ILogicalOperator>(primaryIndexUnnestMapOp));
    }
    newSelectOpInLeftPath.setExecutionMode(ExecutionMode.PARTITIONED);
    context.computeAndSetTypeEnvironmentForOperator(newSelectOpInLeftPath);
    // Now, we take care of the right path (instantTryLock on PK success path).
    ILogicalOperator currentTopOpInRightPath = splitOp;
    // This is done by adding the following assign operator that we have made in the beginning of this method.
    if (skVarAssignOpInRightPath != null) {
        skVarAssignOpInRightPath.getInputs().add(new MutableObject<ILogicalOperator>(splitOp));
        skVarAssignOpInRightPath.setExecutionMode(ExecutionMode.PARTITIONED);
        context.computeAndSetTypeEnvironmentForOperator(skVarAssignOpInRightPath);
        currentTopOpInRightPath = skVarAssignOpInRightPath;
    }
    // (e.g., where $a.authors /*+ indexnl */ = $b.authors and $a.id = $b.id   <- authors:SK, id:PK)
    if ((idxType == IndexType.RTREE || uniqueUsedVarsInTopOp.size() > 1) && requireVerificationAfterSIdxSearch) {
        // Creates a new SELECT operator by deep-copying the SELECT operator in the left path
        // since we need to change the variable reference in the SELECT operator.
        // For the index-nested-loop join case, we copy the condition of the join operator.
        ILogicalExpression conditionRefExpr2 = conditionRef.getValue().cloneExpression();
        newSelectOpInRightPath = new SelectOperator(new MutableObject<ILogicalExpression>(conditionRefExpr2), retainMissing, newMissingPlaceHolderVar);
        newSelectOpInRightPath.setSourceLocation(conditionRefExpr2.getSourceLocation());
        newSelectOpInRightPath.getInputs().add(new MutableObject<ILogicalOperator>(currentTopOpInRightPath));
        VariableUtilities.substituteVariables(newSelectOpInRightPath, origVarToSIdxUnnestMapOpVarMap, context);
        VariableUtilities.substituteVariables(newSelectOpInRightPath, origSKFieldVarToNewSKFieldVarMap, context);
        newSelectOpInRightPath.setExecutionMode(ExecutionMode.PARTITIONED);
        context.computeAndSetTypeEnvironmentForOperator(newSelectOpInRightPath);
        currentTopOpInRightPath = newSelectOpInRightPath;
    }
    // The assumption here is that this variable is the first PK variable that was set.
    if (retainMissing && newMissingPlaceHolderForLOJ == primaryIndexUnnestVars.get(0) && !findVarInTripleVarList(unionVarMap, newMissingPlaceHolderForLOJ, false)) {
        unionVarMap.add(new Triple<>(origPKRecAndSKVarToleftPathMap.get(newMissingPlaceHolderForLOJ), pkVarsFromSIdxUnnestMapOp.get(0), newMissingPlaceHolderForLOJ));
    }
    // UNIONALL operator that combines both paths.
    unionAllOp = new UnionAllOperator(unionVarMap);
    unionAllOp.setSourceLocation(sourceLoc);
    unionAllOp.getInputs().add(new MutableObject<ILogicalOperator>(newSelectOpInLeftPath));
    unionAllOp.getInputs().add(new MutableObject<ILogicalOperator>(currentTopOpInRightPath));
    unionAllOp.setExecutionMode(ExecutionMode.PARTITIONED);
    context.computeAndSetTypeEnvironmentForOperator(unionAllOp);
    // If an assign operator that keeps constant values was added, set the UNIONALL operator as its child.
    if (!constAssignVars.isEmpty() && !constantAssignVarUsedInTopOp) {
        constAssignOp.getInputs().clear();
        constAssignOp.getInputs().add(new MutableObject<ILogicalOperator>(unionAllOp));
        constAssignOp.setExecutionMode(ExecutionMode.PARTITIONED);
        context.computeAndSetTypeEnvironmentForOperator(constAssignOp);
        // This constant assign operator is the new child of the first operator after the original
        // SELECT or JOIN operator.
        currentOpAfterTopOp = afterTopOpRefs.get(afterTopOpRefs.size() - 1).getValue();
        currentOpAfterTopOp.getInputs().clear();
        currentOpAfterTopOp.getInputs().add(new MutableObject<ILogicalOperator>(constAssignOp));
        context.computeAndSetTypeEnvironmentForOperator(currentOpAfterTopOp);
        afterTopOpRefs.add(new MutableObject<ILogicalOperator>(constAssignOp));
    }
    // Index-only plan is now constructed. Return this operator to the caller.
    return unionAllOp;
}
#end_block

#method_before
@Override
public void close() throws IOException {
    writer.close();
    if (error == null && response.status() == HttpResponseStatus.OK) {
        if (!done) {
            future = ctx.writeAndFlush(LastHttpContent.EMPTY_LAST_CONTENT);
        }
    } else {
        // There was an error
        if (headerSent) {
            LOGGER.log(Level.WARN, "Error after header write of chunked response");
            if (error != null) {
                error.release();
            }
            future = ctx.channel().close();
        } else {
            // we didn't send anything to the user, we need to send an non-chunked error response
            fullResponse(response.protocolVersion(), response.status(), error == null ? ctx.alloc().buffer(0, 0) : error, response.headers());
            if (!keepAlive) {
                // since the request failed, we need to close the channel on complete
                future.addListener(ChannelFutureListener.CLOSE);
            }
        }
    }
    done = true;
}
#method_after
@Override
public void close() throws IOException {
    writer.close();
    if (error == null && response.status() == HttpResponseStatus.OK) {
        if (!done) {
            future = ctx.writeAndFlush(LastHttpContent.EMPTY_LAST_CONTENT);
        }
    } else {
        // There was an error
        if (headerSent) {
            LOGGER.log(Level.WARN, "Error after header write of chunked response");
            if (error != null) {
                error.release();
            }
            future = ctx.channel().close();
        } else {
            // we didn't send anything to the user, we need to send an non-chunked error response
            fullResponse(response.protocolVersion(), response.status(), error == null ? ctx.alloc().buffer(0, 0) : error, response.headers());
        }
    }
    done = true;
}
#end_block

#method_before
private void persist(IndexCheckpoint checkpoint) throws HyracksDataException {
    final Path checkpointPath = getCheckpointPath(checkpoint);
    for (int i = 1; i <= MAX_CHECKPOINT_WRITE_ATTEMPTS; i++) {
        try {
            // clean up from previous write failure
            if (checkpointPath.toFile().exists()) {
                Files.delete(checkpointPath);
            }
            try (BufferedWriter writer = Files.newBufferedWriter(checkpointPath)) {
                writer.write(checkpoint.asJson());
            }
            // ensure it was written correctly by reading it
            read(checkpointPath);
            return;
        } catch (ClosedByInterruptException e) {
            LOGGER.info("interrupted while writing checkponint at {}", checkpointPath);
            throw HyracksDataException.create(e);
        } catch (IOException e) {
            if (i == MAX_CHECKPOINT_WRITE_ATTEMPTS) {
                throw HyracksDataException.create(e);
            }
            LOGGER.warn(() -> "Filed to write checkpoint at: " + indexPath, e);
            int nextAttempt = i + 1;
            LOGGER.info(() -> "Checkpoint write attempt " + nextAttempt + "/" + MAX_CHECKPOINT_WRITE_ATTEMPTS);
        }
    }
}
#method_after
private void persist(IndexCheckpoint checkpoint) throws HyracksDataException {
    final Path checkpointPath = getCheckpointPath(checkpoint);
    for (int i = 1; i <= MAX_CHECKPOINT_WRITE_ATTEMPTS; i++) {
        try {
            // clean up from previous write failure
            if (checkpointPath.toFile().exists()) {
                Files.delete(checkpointPath);
            }
            try (BufferedWriter writer = Files.newBufferedWriter(checkpointPath)) {
                writer.write(checkpoint.asJson());
            }
            // ensure it was written correctly by reading it
            read(checkpointPath);
            return;
        } catch (ClosedByInterruptException e) {
            LOGGER.info("interrupted while writing checkpoint at {}", checkpointPath);
            throw HyracksDataException.create(e);
        } catch (IOException e) {
            if (i == MAX_CHECKPOINT_WRITE_ATTEMPTS) {
                throw HyracksDataException.create(e);
            }
            LOGGER.warn(() -> "Filed to write checkpoint at: " + indexPath, e);
            int nextAttempt = i + 1;
            LOGGER.info(() -> "Checkpoint write attempt " + nextAttempt + "/" + MAX_CHECKPOINT_WRITE_ATTEMPTS);
        }
    }
}
#end_block

#method_before
@Test
public void interruptedLogFileSwitch() throws Exception {
    final INcApplicationContext ncAppCtx = (INcApplicationContext) integrationUtil.ncs[0].getApplicationContext();
    final LogManager logManager = (LogManager) ncAppCtx.getTransactionSubsystem().getLogManager();
    int logFileCountBeforeInterrupt = logManager.getSortedLogFileIds().size();
    // ensure an interrupted transactor will create next log file but will fail to position the log channel
    final AtomicBoolean failed = new AtomicBoolean(false);
    Thread interruptedTransactor = new Thread(() -> {
        Thread.currentThread().interrupt();
        try {
            prepareNextLogFile(logManager);
        } catch (Exception e) {
            failed.set(true);
        }
    });
    interruptedTransactor.start();
    interruptedTransactor.join();
    // ensure a new log file was created and survived interrupt
    int logFileCountAfterInterrupt = logManager.getSortedLogFileIds().size();
    Assert.assertEquals(logFileCountBeforeInterrupt + 1, logFileCountAfterInterrupt);
    Assert.assertFalse(failed.get());
    // make sure we can still log to the new file
    interruptedLogPageSwitch();
}
#method_after
@Test
public void interruptedLogFileSwitch() throws Exception {
    final INcApplicationContext ncAppCtx = (INcApplicationContext) integrationUtil.ncs[0].getApplicationContext();
    final LogManager logManager = (LogManager) ncAppCtx.getTransactionSubsystem().getLogManager();
    int logFileCountBeforeInterrupt = logManager.getOrderedLogFileIds().size();
    // ensure an interrupted transactor will create next log file but will fail to position the log channel
    final AtomicBoolean failed = new AtomicBoolean(false);
    Thread interruptedTransactor = new Thread(() -> {
        Thread.currentThread().interrupt();
        try {
            prepareNextLogFile(logManager);
        } catch (Exception e) {
            failed.set(true);
        }
    });
    interruptedTransactor.start();
    interruptedTransactor.join();
    // ensure a new log file was created and survived interrupt
    int logFileCountAfterInterrupt = logManager.getOrderedLogFileIds().size();
    Assert.assertEquals(logFileCountBeforeInterrupt + 1, logFileCountAfterInterrupt);
    Assert.assertFalse(failed.get());
    // make sure we can still log to the new file
    interruptedLogPageSwitch();
}
#end_block

#method_before
private long initializeLogAnchor(long nextLogFileId) {
    long fileId = 0;
    long offset = 0;
    File fileLogDir = new File(logDir);
    if (fileLogDir.exists()) {
        List<Long> logFileIds = getSortedLogFileIds();
        if (logFileIds.isEmpty()) {
            fileId = nextLogFileId;
            createFileIfNotExists(getLogFilePath(fileId));
        } else {
            fileId = logFileIds.get(logFileIds.size() - 1);
            File logFile = new File(getLogFilePath(fileId));
            offset = logFile.length();
        }
    } else {
        fileId = nextLogFileId;
        createNewDirectory(logDir);
        if (LOGGER.isInfoEnabled()) {
            LOGGER.info("created the log directory: " + logManagerProperties.getLogDir());
        }
        createFileIfNotExists(getLogFilePath(fileId));
    }
    if (LOGGER.isInfoEnabled()) {
        LOGGER.info("log file Id: " + fileId + ", offset: " + offset);
    }
    return getLogFileFirstLsn(fileId) + offset;
}
#method_after
private long initializeLogAnchor(long fileId) {
    final String logFilePath = getLogFilePath(fileId);
    createFileIfNotExists(logFilePath);
    final File logFile = new File(logFilePath);
    long offset = logFile.length();
    if (LOGGER.isInfoEnabled()) {
        LOGGER.info("initializing log anchor with log file Id: {} at offset: {}", fileId, offset);
    }
    return getLogFileFirstLsn(fileId) + offset;
}
#end_block

#method_before
@Override
public void deleteOldLogFiles(long checkpointLSN) {
    Long checkpointLSNLogFileID = getLogFileId(checkpointLSN);
    List<Long> logFileIds = getSortedLogFileIds();
    if (!logFileIds.isEmpty()) {
        // sort log files from oldest to newest
        Collections.sort(logFileIds);
        // remove the last one not to delete the current log file
        logFileIds.remove(logFileIds.size() - 1);
        /**
         * At this point, any future LogReader should read from LSN >= checkpointLSN
         */
        for (Long id : logFileIds) {
            /**
             * Stop deletion if:
             * The log file which contains the checkpointLSN has been reached.
             * The oldest log file being accessed by a LogReader has been reached.
             */
            if (id >= checkpointLSNLogFileID) {
                break;
            }
            // delete old log file
            File file = new File(getLogFilePath(id));
            file.delete();
            if (LOGGER.isInfoEnabled()) {
                LOGGER.info("Deleted log file " + file.getAbsolutePath());
            }
        }
    }
}
#method_after
@Override
public void deleteOldLogFiles(long checkpointLSN) {
    Long checkpointLSNLogFileID = getLogFileId(checkpointLSN);
    List<Long> logFileIds = getOrderedLogFileIds();
    if (!logFileIds.isEmpty()) {
        // sort log files from oldest to newest
        Collections.sort(logFileIds);
        // remove the last one not to delete the current log file
        logFileIds.remove(logFileIds.size() - 1);
        /**
         * At this point, any future LogReader should read from LSN >= checkpointLSN
         */
        for (Long id : logFileIds) {
            /**
             * Stop deletion if:
             * The log file which contains the checkpointLSN has been reached.
             * The oldest log file being accessed by a LogReader has been reached.
             */
            if (id >= checkpointLSNLogFileID) {
                break;
            }
            // delete old log file
            File file = new File(getLogFilePath(id));
            file.delete();
            if (LOGGER.isInfoEnabled()) {
                LOGGER.info("Deleted log file " + file.getAbsolutePath());
            }
        }
    }
}
#end_block

#method_before
private static void createFileIfNotExists(String path) {
    try {
        File file = new File(path);
        File parentFile = file.getParentFile();
        if (parentFile != null) {
            parentFile.mkdirs();
        }
        Files.createFile(file.toPath());
        LOGGER.info("Created log file {}", path);
    } catch (IOException e) {
        throw new IllegalStateException("File to create file in " + path, e);
    }
}
#method_after
private static void createFileIfNotExists(String path) {
    try {
        File file = new File(path);
        if (file.exists()) {
            return;
        }
        File parentFile = file.getParentFile();
        if (parentFile != null) {
            parentFile.mkdirs();
        }
        Files.createFile(file.toPath());
        LOGGER.info("Created log file {}", path);
    } catch (IOException e) {
        throw new IllegalStateException("Failed to create file in " + path, e);
    }
}
#end_block

#method_before
@Override
public long getReadableSmallestLSN() {
    List<Long> logFileIds = getSortedLogFileIds();
    if (!logFileIds.isEmpty()) {
        return logFileIds.get(0) * logFileSize;
    } else {
        throw new IllegalStateException("Couldn't find any log files.");
    }
}
#method_after
@Override
public long getReadableSmallestLSN() {
    List<Long> logFileIds = getOrderedLogFileIds();
    if (!logFileIds.isEmpty()) {
        return logFileIds.get(0) * logFileSize;
    } else {
        throw new IllegalStateException("Couldn't find any log files.");
    }
}
#end_block

#method_before
private long getNextLogFileId() {
    final List<Long> logFileIds = getSortedLogFileIds();
    if (logFileIds.isEmpty()) {
        return 0;
    }
    return logFileIds.get(logFileIds.size() - 1) + 1;
}
#method_after
private long getNextLogFileId() {
    return getOnDiskMaxLogFileId() + 1;
}
#end_block

#method_before
@Test
public void testDeleteOldLogFiles() {
    try {
        TestNodeController nc = new TestNodeController(new File(TEST_CONFIG_FILE_PATH).getAbsolutePath(), false);
        StorageComponentProvider storageManager = new StorageComponentProvider();
        nc.init();
        List<List<String>> partitioningKeys = new ArrayList<>();
        partitioningKeys.add(Collections.singletonList("key"));
        try {
            nc.createPrimaryIndex(StorageTestUtils.DATASET, KEY_TYPES, RECORD_TYPE, META_TYPE, null, storageManager, KEY_INDEXES, KEY_INDICATOR_LIST, 0);
            JobId jobId = nc.newJobId();
            IHyracksTaskContext ctx = nc.createTestContext(jobId, 0, false);
            ITransactionContext txnCtx = nc.getTransactionManager().beginTransaction(nc.getTxnJobId(ctx), new TransactionOptions(ITransactionManager.AtomicityLevel.ENTITY_LEVEL));
            // Prepare insert operation
            LSMInsertDeleteOperatorNodePushable insertOp = nc.getInsertPipeline(ctx, StorageTestUtils.DATASET, KEY_TYPES, RECORD_TYPE, META_TYPE, null, KEY_INDEXES, KEY_INDICATOR_LIST, storageManager, null).getLeft();
            insertOp.open();
            RecordTupleGenerator tupleGenerator = new RecordTupleGenerator(RECORD_TYPE, META_TYPE, KEY_INDEXES, KEY_INDICATOR, RECORD_GEN_FUNCTION, UNIQUE_RECORD_FIELDS, META_GEN_FUNCTION, UNIQUE_META_FIELDS);
            VSizeFrame frame = new VSizeFrame(ctx);
            FrameTupleAppender tupleAppender = new FrameTupleAppender(frame);
            RecoveryManager recoveryManager = (RecoveryManager) nc.getTransactionSubsystem().getRecoveryManager();
            ICheckpointManager checkpointManager = nc.getTransactionSubsystem().getCheckpointManager();
            LogManager logManager = (LogManager) nc.getTransactionSubsystem().getLogManager();
            // Number of log files after node startup should be one
            int numberOfLogFiles = logManager.getSortedLogFileIds().size();
            Assert.assertEquals(1, numberOfLogFiles);
            // Low-water mark LSN
            long lowWaterMarkLSN = recoveryManager.getMinFirstLSN();
            // Low-water mark log file id
            long initialLowWaterMarkFileId = logManager.getLogFileId(lowWaterMarkLSN);
            // Initial Low-water mark should be in the only available log file
            Assert.assertEquals(initialLowWaterMarkFileId, logManager.getSortedLogFileIds().get(0).longValue());
            // Insert records until a new log file is created
            while (logManager.getSortedLogFileIds().size() == 1) {
                ITupleReference tuple = tupleGenerator.next();
                DataflowUtils.addTupleToFrame(tupleAppender, tuple, insertOp);
            }
            // Check if the new low-water mark is still in the initial low-water mark log file
            lowWaterMarkLSN = recoveryManager.getMinFirstLSN();
            long currentLowWaterMarkLogFileId = logManager.getLogFileId(lowWaterMarkLSN);
            if (currentLowWaterMarkLogFileId == initialLowWaterMarkFileId) {
                /*
                     * Make sure checkpoint will not delete the initial log file since
                     * the low-water mark is still in it (i.e. it is still required for
                     * recovery)
                     */
                int numberOfLogFilesBeforeCheckpoint = logManager.getSortedLogFileIds().size();
                checkpointManager.tryCheckpoint(logManager.getAppendLSN());
                int numberOfLogFilesAfterCheckpoint = logManager.getSortedLogFileIds().size();
                Assert.assertEquals(numberOfLogFilesBeforeCheckpoint, numberOfLogFilesAfterCheckpoint);
                /*
                     * Insert records until the low-water mark is not in the initialLowWaterMarkFileId
                     * either because of the asynchronous flush caused by the previous checkpoint or a flush
                     * due to the dataset memory budget getting full.
                     */
                while (currentLowWaterMarkLogFileId == initialLowWaterMarkFileId) {
                    ITupleReference tuple = tupleGenerator.next();
                    DataflowUtils.addTupleToFrame(tupleAppender, tuple, insertOp);
                    lowWaterMarkLSN = recoveryManager.getMinFirstLSN();
                    currentLowWaterMarkLogFileId = logManager.getLogFileId(lowWaterMarkLSN);
                }
            }
            /*
                 * At this point, the low-water mark is not in the initialLowWaterMarkFileId, so
                 * a checkpoint should delete it. We will also start a second
                  * job to ensure that the checkpointing coexists peacefully
                  * with other concurrent readers of the log that request
                  * deletions to be witheld
                 */
            JobId jobId2 = nc.newJobId();
            IHyracksTaskContext ctx2 = nc.createTestContext(jobId2, 0, false);
            nc.getTransactionManager().beginTransaction(nc.getTxnJobId(ctx2), new TransactionOptions(ITransactionManager.AtomicityLevel.ENTITY_LEVEL));
            // Prepare insert operation
            LSMInsertDeleteOperatorNodePushable insertOp2 = nc.getInsertPipeline(ctx2, StorageTestUtils.DATASET, KEY_TYPES, RECORD_TYPE, META_TYPE, null, KEY_INDEXES, KEY_INDICATOR_LIST, storageManager, null).getLeft();
            insertOp2.open();
            VSizeFrame frame2 = new VSizeFrame(ctx2);
            FrameTupleAppender tupleAppender2 = new FrameTupleAppender(frame2);
            for (int i = 0; i < 4; i++) {
                long lastCkpoint = recoveryManager.getMinFirstLSN();
                long lastFileId = logManager.getLogFileId(lastCkpoint);
                checkpointManager.tryCheckpoint(lowWaterMarkLSN);
                // Validate initialLowWaterMarkFileId was deleted
                for (Long fileId : logManager.getSortedLogFileIds()) {
                    Assert.assertNotEquals(initialLowWaterMarkFileId, fileId.longValue());
                }
                while (currentLowWaterMarkLogFileId == lastFileId) {
                    ITupleReference tuple = tupleGenerator.next();
                    DataflowUtils.addTupleToFrame(tupleAppender2, tuple, insertOp2);
                    lowWaterMarkLSN = recoveryManager.getMinFirstLSN();
                    currentLowWaterMarkLogFileId = logManager.getLogFileId(lowWaterMarkLSN);
                }
            }
            Thread.UncaughtExceptionHandler h = new Thread.UncaughtExceptionHandler() {

                @Override
                public void uncaughtException(Thread th, Throwable ex) {
                    threadException = true;
                    exception = ex;
                }
            };
            Thread t = new Thread(() -> {
                TransactionManager spyTxnMgr = spy((TransactionManager) nc.getTransactionManager());
                doAnswer(i -> {
                    stallAbortTxn(Thread.currentThread(), txnCtx, nc.getTransactionSubsystem(), (TxnId) i.getArguments()[0]);
                    return null;
                }).when(spyTxnMgr).abortTransaction(any(TxnId.class));
                spyTxnMgr.abortTransaction(txnCtx.getTxnId());
            });
            t.setUncaughtExceptionHandler(h);
            synchronized (t) {
                t.start();
                t.wait();
            }
            long lockedLSN = recoveryManager.getMinFirstLSN();
            checkpointManager.tryCheckpoint(lockedLSN);
            synchronized (t) {
                t.notifyAll();
            }
            t.join();
            if (threadException) {
                throw exception;
            }
        } finally {
            nc.deInit();
        }
    } catch (Throwable e) {
        e.printStackTrace();
        Assert.fail(e.getMessage());
    }
}
#method_after
@Test
public void testDeleteOldLogFiles() {
    try {
        TestNodeController nc = new TestNodeController(new File(TEST_CONFIG_FILE_PATH).getAbsolutePath(), false);
        StorageComponentProvider storageManager = new StorageComponentProvider();
        nc.init();
        List<List<String>> partitioningKeys = new ArrayList<>();
        partitioningKeys.add(Collections.singletonList("key"));
        try {
            nc.createPrimaryIndex(StorageTestUtils.DATASET, KEY_TYPES, RECORD_TYPE, META_TYPE, null, storageManager, KEY_INDEXES, KEY_INDICATOR_LIST, 0);
            JobId jobId = nc.newJobId();
            IHyracksTaskContext ctx = nc.createTestContext(jobId, 0, false);
            ITransactionContext txnCtx = nc.getTransactionManager().beginTransaction(nc.getTxnJobId(ctx), new TransactionOptions(ITransactionManager.AtomicityLevel.ENTITY_LEVEL));
            // Prepare insert operation
            LSMInsertDeleteOperatorNodePushable insertOp = nc.getInsertPipeline(ctx, StorageTestUtils.DATASET, KEY_TYPES, RECORD_TYPE, META_TYPE, null, KEY_INDEXES, KEY_INDICATOR_LIST, storageManager, null).getLeft();
            insertOp.open();
            RecordTupleGenerator tupleGenerator = new RecordTupleGenerator(RECORD_TYPE, META_TYPE, KEY_INDEXES, KEY_INDICATOR, RECORD_GEN_FUNCTION, UNIQUE_RECORD_FIELDS, META_GEN_FUNCTION, UNIQUE_META_FIELDS);
            VSizeFrame frame = new VSizeFrame(ctx);
            FrameTupleAppender tupleAppender = new FrameTupleAppender(frame);
            RecoveryManager recoveryManager = (RecoveryManager) nc.getTransactionSubsystem().getRecoveryManager();
            ICheckpointManager checkpointManager = nc.getTransactionSubsystem().getCheckpointManager();
            LogManager logManager = (LogManager) nc.getTransactionSubsystem().getLogManager();
            // Number of log files after node startup should be one
            int numberOfLogFiles = logManager.getOrderedLogFileIds().size();
            Assert.assertEquals(1, numberOfLogFiles);
            // Low-water mark LSN
            long lowWaterMarkLSN = recoveryManager.getMinFirstLSN();
            // Low-water mark log file id
            long initialLowWaterMarkFileId = logManager.getLogFileId(lowWaterMarkLSN);
            // Initial Low-water mark should be in the only available log file
            Assert.assertEquals(initialLowWaterMarkFileId, logManager.getOrderedLogFileIds().get(0).longValue());
            // Insert records until a new log file is created
            while (logManager.getOrderedLogFileIds().size() == 1) {
                ITupleReference tuple = tupleGenerator.next();
                DataflowUtils.addTupleToFrame(tupleAppender, tuple, insertOp);
            }
            // Check if the new low-water mark is still in the initial low-water mark log file
            lowWaterMarkLSN = recoveryManager.getMinFirstLSN();
            long currentLowWaterMarkLogFileId = logManager.getLogFileId(lowWaterMarkLSN);
            if (currentLowWaterMarkLogFileId == initialLowWaterMarkFileId) {
                /*
                     * Make sure checkpoint will not delete the initial log file since
                     * the low-water mark is still in it (i.e. it is still required for
                     * recovery)
                     */
                int numberOfLogFilesBeforeCheckpoint = logManager.getOrderedLogFileIds().size();
                checkpointManager.tryCheckpoint(logManager.getAppendLSN());
                int numberOfLogFilesAfterCheckpoint = logManager.getOrderedLogFileIds().size();
                Assert.assertEquals(numberOfLogFilesBeforeCheckpoint, numberOfLogFilesAfterCheckpoint);
                /*
                     * Insert records until the low-water mark is not in the initialLowWaterMarkFileId
                     * either because of the asynchronous flush caused by the previous checkpoint or a flush
                     * due to the dataset memory budget getting full.
                     */
                while (currentLowWaterMarkLogFileId == initialLowWaterMarkFileId) {
                    ITupleReference tuple = tupleGenerator.next();
                    DataflowUtils.addTupleToFrame(tupleAppender, tuple, insertOp);
                    lowWaterMarkLSN = recoveryManager.getMinFirstLSN();
                    currentLowWaterMarkLogFileId = logManager.getLogFileId(lowWaterMarkLSN);
                }
            }
            /*
                 * At this point, the low-water mark is not in the initialLowWaterMarkFileId, so
                 * a checkpoint should delete it. We will also start a second
                  * job to ensure that the checkpointing coexists peacefully
                  * with other concurrent readers of the log that request
                  * deletions to be witheld
                 */
            JobId jobId2 = nc.newJobId();
            IHyracksTaskContext ctx2 = nc.createTestContext(jobId2, 0, false);
            nc.getTransactionManager().beginTransaction(nc.getTxnJobId(ctx2), new TransactionOptions(ITransactionManager.AtomicityLevel.ENTITY_LEVEL));
            // Prepare insert operation
            LSMInsertDeleteOperatorNodePushable insertOp2 = nc.getInsertPipeline(ctx2, StorageTestUtils.DATASET, KEY_TYPES, RECORD_TYPE, META_TYPE, null, KEY_INDEXES, KEY_INDICATOR_LIST, storageManager, null).getLeft();
            insertOp2.open();
            VSizeFrame frame2 = new VSizeFrame(ctx2);
            FrameTupleAppender tupleAppender2 = new FrameTupleAppender(frame2);
            for (int i = 0; i < 4; i++) {
                long lastCkpoint = recoveryManager.getMinFirstLSN();
                long lastFileId = logManager.getLogFileId(lastCkpoint);
                checkpointManager.tryCheckpoint(lowWaterMarkLSN);
                // Validate initialLowWaterMarkFileId was deleted
                for (Long fileId : logManager.getOrderedLogFileIds()) {
                    Assert.assertNotEquals(initialLowWaterMarkFileId, fileId.longValue());
                }
                while (currentLowWaterMarkLogFileId == lastFileId) {
                    ITupleReference tuple = tupleGenerator.next();
                    DataflowUtils.addTupleToFrame(tupleAppender2, tuple, insertOp2);
                    lowWaterMarkLSN = recoveryManager.getMinFirstLSN();
                    currentLowWaterMarkLogFileId = logManager.getLogFileId(lowWaterMarkLSN);
                }
            }
            Thread.UncaughtExceptionHandler h = new Thread.UncaughtExceptionHandler() {

                @Override
                public void uncaughtException(Thread th, Throwable ex) {
                    threadException = true;
                    exception = ex;
                }
            };
            Thread t = new Thread(() -> {
                TransactionManager spyTxnMgr = spy((TransactionManager) nc.getTransactionManager());
                doAnswer(i -> {
                    stallAbortTxn(Thread.currentThread(), txnCtx, nc.getTransactionSubsystem(), (TxnId) i.getArguments()[0]);
                    return null;
                }).when(spyTxnMgr).abortTransaction(any(TxnId.class));
                spyTxnMgr.abortTransaction(txnCtx.getTxnId());
            });
            t.setUncaughtExceptionHandler(h);
            synchronized (t) {
                t.start();
                t.wait();
            }
            long lockedLSN = recoveryManager.getMinFirstLSN();
            checkpointManager.tryCheckpoint(lockedLSN);
            synchronized (t) {
                t.notifyAll();
            }
            t.join();
            if (threadException) {
                throw exception;
            }
        } finally {
            nc.deInit();
        }
    } catch (Throwable e) {
        e.printStackTrace();
        Assert.fail(e.getMessage());
    }
}
#end_block

#method_before
@Override
public boolean rewritePost(Mutable<ILogicalOperator> opRef, IOptimizationContext context) throws AlgebricksException {
    AbstractLogicalOperator op = (AbstractLogicalOperator) opRef.getValue();
    if (context.checkIfInDontApplySet(this, op)) {
        return false;
    }
    if (op.getOperatorTag() != LogicalOperatorTag.GROUP) {
        return false;
    }
    GroupByOperator gbyOp = (GroupByOperator) op;
    ExecutionMode executionMode = gbyOp.getExecutionMode();
    if (executionMode != ExecutionMode.PARTITIONED && !(executionMode == ExecutionMode.UNPARTITIONED && gbyOp.isGroupAll())) {
        return false;
    }
    BookkeepingInfo bi = new BookkeepingInfo();
    GroupByOperator newGbyOp = opToPush(gbyOp, bi, context);
    if (newGbyOp == null) {
        return false;
    }
    Set<LogicalVariable> newGbyLiveVars = new ListSet<LogicalVariable>();
    VariableUtilities.getLiveVariables(newGbyOp, newGbyLiveVars);
    for (Pair<LogicalVariable, Mutable<ILogicalExpression>> p : gbyOp.getDecorList()) {
        List<LogicalVariable> usedDecorVars = new ArrayList<LogicalVariable>();
        // p.second.getValue() should always return a VariableReferenceExpression, hence
        // usedDecorVars should always contain only one variable.
        p.second.getValue().getUsedVariables(usedDecorVars);
        if (!newGbyLiveVars.contains(usedDecorVars.get(0))) {
            // Let the left-hand side of gbyOp's decoration expressions populated through the combiner group-by without
            // any intermediate assignment.
            newGbyOp.addDecorExpression(null, p.second.getValue());
            newGbyLiveVars.add(usedDecorVars.get(0));
        }
    }
    newGbyOp.setExecutionMode(ExecutionMode.LOCAL);
    Object v = gbyOp.getAnnotations().get(OperatorAnnotations.USE_HASH_GROUP_BY);
    newGbyOp.getAnnotations().put(OperatorAnnotations.USE_HASH_GROUP_BY, v);
    Object v2 = gbyOp.getAnnotations().get(OperatorAnnotations.USE_EXTERNAL_GROUP_BY);
    newGbyOp.getAnnotations().put(OperatorAnnotations.USE_EXTERNAL_GROUP_BY, v2);
    List<LogicalVariable> propagatedVars = new LinkedList<LogicalVariable>();
    VariableUtilities.getProducedVariables(newGbyOp, propagatedVars);
    Set<LogicalVariable> freeVars = new HashSet<LogicalVariable>();
    OperatorPropertiesUtil.getFreeVariablesInSubplans(gbyOp, freeVars);
    for (LogicalVariable var : freeVars) {
        if (!propagatedVars.contains(var) && !newGbyLiveVars.contains(var)) {
            LogicalVariable newDecorVar = context.newVar();
            VariableReferenceExpression varRef = new VariableReferenceExpression(var);
            varRef.setSourceLocation(gbyOp.getSourceLocation());
            newGbyOp.addDecorExpression(newDecorVar, varRef);
            VariableUtilities.substituteVariables(gbyOp.getNestedPlans().get(0).getRoots().get(0).getValue(), var, newDecorVar, context);
        }
    }
    Mutable<ILogicalOperator> opRef3 = gbyOp.getInputs().get(0);
    opRef3.setValue(newGbyOp);
    typeGby(newGbyOp, context);
    typeGby(gbyOp, context);
    context.addToDontApplySet(this, op);
    return true;
}
#method_after
@Override
public boolean rewritePost(Mutable<ILogicalOperator> opRef, IOptimizationContext context) throws AlgebricksException {
    AbstractLogicalOperator op = (AbstractLogicalOperator) opRef.getValue();
    if (context.checkIfInDontApplySet(this, op)) {
        return false;
    }
    if (op.getOperatorTag() != LogicalOperatorTag.GROUP) {
        return false;
    }
    GroupByOperator gbyOp = (GroupByOperator) op;
    ExecutionMode executionMode = gbyOp.getExecutionMode();
    if (executionMode != ExecutionMode.PARTITIONED && !(executionMode == ExecutionMode.UNPARTITIONED && gbyOp.isGroupAll())) {
        return false;
    }
    BookkeepingInfo bi = new BookkeepingInfo();
    GroupByOperator newGbyOp = opToPush(gbyOp, bi, context);
    if (newGbyOp == null) {
        return false;
    }
    Set<LogicalVariable> newGbyLiveVars = new ListSet<LogicalVariable>();
    VariableUtilities.getLiveVariables(newGbyOp, newGbyLiveVars);
    for (Pair<LogicalVariable, Mutable<ILogicalExpression>> p : gbyOp.getDecorList()) {
        List<LogicalVariable> usedDecorVars = new ArrayList<LogicalVariable>();
        // p.second.getValue() should always return a VariableReferenceExpression, hence
        // usedDecorVars should always contain only one variable.
        p.second.getValue().getUsedVariables(usedDecorVars);
        LogicalVariable usedVar = usedDecorVars.get(0);
        if (!newGbyLiveVars.contains(usedVar)) {
            // Let the left-hand side of gbyOp's decoration expressions populated through the combiner group-by without
            // any intermediate assignment.
            newGbyOp.addDecorExpression(null, p.second.getValue());
            newGbyLiveVars.add(usedVar);
        }
    }
    newGbyOp.setExecutionMode(ExecutionMode.LOCAL);
    Object v = gbyOp.getAnnotations().get(OperatorAnnotations.USE_HASH_GROUP_BY);
    newGbyOp.getAnnotations().put(OperatorAnnotations.USE_HASH_GROUP_BY, v);
    Object v2 = gbyOp.getAnnotations().get(OperatorAnnotations.USE_EXTERNAL_GROUP_BY);
    newGbyOp.getAnnotations().put(OperatorAnnotations.USE_EXTERNAL_GROUP_BY, v2);
    Set<LogicalVariable> freeVars = new HashSet<LogicalVariable>();
    OperatorPropertiesUtil.getFreeVariablesInSubplans(gbyOp, freeVars);
    for (LogicalVariable var : freeVars) {
        if (!newGbyLiveVars.contains(var)) {
            LogicalVariable newDecorVar = context.newVar();
            VariableReferenceExpression varRef = new VariableReferenceExpression(var);
            varRef.setSourceLocation(gbyOp.getSourceLocation());
            newGbyOp.addDecorExpression(newDecorVar, varRef);
            VariableUtilities.substituteVariables(gbyOp.getNestedPlans().get(0).getRoots().get(0).getValue(), var, newDecorVar, context);
        }
    }
    Mutable<ILogicalOperator> opRef3 = gbyOp.getInputs().get(0);
    opRef3.setValue(newGbyOp);
    typeGby(newGbyOp, context);
    typeGby(gbyOp, context);
    context.addToDontApplySet(this, op);
    return true;
}
#end_block

#method_before
public static String getMergeSequence(String firstComponentName, String lastComponentName) {
    long mergeSequenceStart = IndexComponentFileReference.of(firstComponentName).getSequenceStart();
    long mergeSequenceEnd = IndexComponentFileReference.of(lastComponentName).getSequenceEnd();
    if (mergeSequenceEnd <= mergeSequenceStart) {
        throw new IllegalArgumentException("A merge must have end greater than start. Found end: " + mergeSequenceEnd + " and start: " + mergeSequenceStart);
    }
    return mergeSequenceStart + DELIMITER + mergeSequenceEnd;
}
#method_after
public static String getMergeSequence(String firstComponentName, String lastComponentName) {
    long mergeSequenceStart = IndexComponentFileReference.of(firstComponentName).getSequenceStart();
    long mergeSequenceEnd = IndexComponentFileReference.of(lastComponentName).getSequenceEnd();
    return mergeSequenceStart + DELIMITER + mergeSequenceEnd;
}
#end_block

#method_before
@Test
public void testNormalSequence() throws HyracksDataException {
    int numMemoryComponents = 2;
    ILSMIndex mockIndex = Mockito.mock(ILSMIndex.class);
    String indexId = "mockIndexId";
    Mockito.when(mockIndex.getNumberOfAllMemoryComponents()).thenReturn(numMemoryComponents);
    Mockito.when(mockIndex.getCurrentMemoryComponent()).thenReturn(Mockito.mock(AbstractLSMMemoryComponent.class));
    DatasetInfo dsInfo = new DatasetInfo(101, null);
    LSMComponentIdGenerator idGenerator = new LSMComponentIdGenerator(numMemoryComponents, MIN_VALID_COMPONENT_ID);
    LSMIOOperationCallback callback = new LSMIOOperationCallback(dsInfo, mockIndex, idGenerator.getId(), mockIndexCheckpointManagerProvider());
    // Flush first
    idGenerator.refresh();
    long flushLsn = 1L;
    ILSMComponentId nextComponentId = idGenerator.getId();
    Map<String, Object> flushMap = new HashMap<>();
    flushMap.put(LSMIOOperationCallback.KEY_FLUSH_LOG_LSN, flushLsn);
    flushMap.put(LSMIOOperationCallback.KEY_NEXT_COMPONENT_ID, nextComponentId);
    ILSMIndexAccessor firstAccessor = new TestLSMIndexAccessor(new TestLSMIndexOperationContext(mockIndex));
    firstAccessor.getOpContext().setParameters(flushMap);
    FileReference firstTarget = new FileReference(Mockito.mock(IODeviceHandle.class), getComponentFileName());
    LSMComponentFileReferences firstFiles = new LSMComponentFileReferences(firstTarget, firstTarget, firstTarget);
    FlushOperation firstFlush = new TestFlushOperation(firstAccessor, firstTarget, callback, indexId, firstFiles, new LSMComponentId(0, 0));
    callback.scheduled(firstFlush);
    callback.beforeOperation(firstFlush);
    // Flush second
    idGenerator.refresh();
    flushLsn = 2L;
    nextComponentId = idGenerator.getId();
    flushMap = new HashMap<>();
    flushMap.put(LSMIOOperationCallback.KEY_FLUSH_LOG_LSN, flushLsn);
    flushMap.put(LSMIOOperationCallback.KEY_NEXT_COMPONENT_ID, nextComponentId);
    ILSMIndexAccessor secondAccessor = new TestLSMIndexAccessor(new TestLSMIndexOperationContext(mockIndex));
    secondAccessor.getOpContext().setParameters(flushMap);
    FileReference secondTarget = new FileReference(Mockito.mock(IODeviceHandle.class), getComponentFileName());
    LSMComponentFileReferences secondFiles = new LSMComponentFileReferences(secondTarget, secondTarget, secondTarget);
    FlushOperation secondFlush = new TestFlushOperation(secondAccessor, secondTarget, callback, indexId, secondFiles, new LSMComponentId(1, 1));
    callback.scheduled(secondFlush);
    callback.beforeOperation(secondFlush);
    Map<String, Object> firstFlushMap = firstFlush.getAccessor().getOpContext().getParameters();
    long firstFlushLogLsn = (Long) firstFlushMap.get(LSMIOOperationCallback.KEY_FLUSH_LOG_LSN);
    Assert.assertEquals(1, firstFlushLogLsn);
    final ILSMDiskComponent diskComponent1 = mockDiskComponent();
    firstFlush.setNewComponent(diskComponent1);
    callback.afterOperation(firstFlush);
    callback.afterFinalize(firstFlush);
    callback.completed(firstFlush);
    Map<String, Object> secondFlushMap = secondFlush.getAccessor().getOpContext().getParameters();
    long secondFlushLogLsn = (Long) secondFlushMap.get(LSMIOOperationCallback.KEY_FLUSH_LOG_LSN);
    Assert.assertEquals(2, secondFlushLogLsn);
    final ILSMDiskComponent diskComponent2 = mockDiskComponent();
    secondFlush.setNewComponent(diskComponent2);
    callback.afterOperation(secondFlush);
    callback.afterFinalize(secondFlush);
    callback.completed(secondFlush);
}
#method_after
@Test
public void testNormalSequence() throws HyracksDataException {
    int numMemoryComponents = 2;
    ILSMIndex mockIndex = Mockito.mock(ILSMIndex.class);
    String indexId = "mockIndexId";
    Mockito.when(mockIndex.getNumberOfAllMemoryComponents()).thenReturn(numMemoryComponents);
    Mockito.when(mockIndex.getCurrentMemoryComponent()).thenReturn(Mockito.mock(AbstractLSMMemoryComponent.class));
    DatasetInfo dsInfo = new DatasetInfo(101, null);
    LSMComponentIdGenerator idGenerator = new LSMComponentIdGenerator(numMemoryComponents);
    idGenerator.init(MIN_VALID_COMPONENT_ID);
    LSMIOOperationCallback callback = new LSMIOOperationCallback(dsInfo, mockIndex, idGenerator, mockIndexCheckpointManagerProvider());
    // Flush first
    idGenerator.refresh();
    long flushLsn = 1L;
    ILSMComponentId nextComponentId = idGenerator.getId();
    Map<String, Object> flushMap = new HashMap<>();
    flushMap.put(LSMIOOperationCallback.KEY_FLUSH_LOG_LSN, flushLsn);
    flushMap.put(LSMIOOperationCallback.KEY_NEXT_COMPONENT_ID, nextComponentId);
    ILSMIndexAccessor firstAccessor = new TestLSMIndexAccessor(new TestLSMIndexOperationContext(mockIndex));
    firstAccessor.getOpContext().setParameters(flushMap);
    FileReference firstTarget = new FileReference(Mockito.mock(IODeviceHandle.class), getComponentFileName());
    LSMComponentFileReferences firstFiles = new LSMComponentFileReferences(firstTarget, firstTarget, firstTarget);
    FlushOperation firstFlush = new TestFlushOperation(firstAccessor, firstTarget, callback, indexId, firstFiles, new LSMComponentId(0, 0));
    callback.scheduled(firstFlush);
    callback.beforeOperation(firstFlush);
    // Flush second
    idGenerator.refresh();
    flushLsn = 2L;
    nextComponentId = idGenerator.getId();
    flushMap = new HashMap<>();
    flushMap.put(LSMIOOperationCallback.KEY_FLUSH_LOG_LSN, flushLsn);
    flushMap.put(LSMIOOperationCallback.KEY_NEXT_COMPONENT_ID, nextComponentId);
    ILSMIndexAccessor secondAccessor = new TestLSMIndexAccessor(new TestLSMIndexOperationContext(mockIndex));
    secondAccessor.getOpContext().setParameters(flushMap);
    FileReference secondTarget = new FileReference(Mockito.mock(IODeviceHandle.class), getComponentFileName());
    LSMComponentFileReferences secondFiles = new LSMComponentFileReferences(secondTarget, secondTarget, secondTarget);
    FlushOperation secondFlush = new TestFlushOperation(secondAccessor, secondTarget, callback, indexId, secondFiles, new LSMComponentId(1, 1));
    callback.scheduled(secondFlush);
    callback.beforeOperation(secondFlush);
    Map<String, Object> firstFlushMap = firstFlush.getAccessor().getOpContext().getParameters();
    long firstFlushLogLsn = (Long) firstFlushMap.get(LSMIOOperationCallback.KEY_FLUSH_LOG_LSN);
    Assert.assertEquals(1, firstFlushLogLsn);
    final ILSMDiskComponent diskComponent1 = mockDiskComponent();
    firstFlush.setNewComponent(diskComponent1);
    callback.afterOperation(firstFlush);
    callback.afterFinalize(firstFlush);
    callback.completed(firstFlush);
    Map<String, Object> secondFlushMap = secondFlush.getAccessor().getOpContext().getParameters();
    long secondFlushLogLsn = (Long) secondFlushMap.get(LSMIOOperationCallback.KEY_FLUSH_LOG_LSN);
    Assert.assertEquals(2, secondFlushLogLsn);
    final ILSMDiskComponent diskComponent2 = mockDiskComponent();
    secondFlush.setNewComponent(diskComponent2);
    callback.afterOperation(secondFlush);
    callback.afterFinalize(secondFlush);
    callback.completed(secondFlush);
}
#end_block

#method_before
@Test
public void testAllocateComponentId() throws HyracksDataException {
    int numMemoryComponents = 2;
    DatasetInfo dsInfo = new DatasetInfo(101, null);
    ILSMComponentIdGenerator idGenerator = new LSMComponentIdGenerator(numMemoryComponents, MIN_VALID_COMPONENT_ID);
    ILSMIndex mockIndex = Mockito.mock(ILSMIndex.class);
    Mockito.when(mockIndex.getNumberOfAllMemoryComponents()).thenReturn(numMemoryComponents);
    ILSMMemoryComponent mockComponent = Mockito.mock(AbstractLSMMemoryComponent.class);
    Mockito.when(mockIndex.getCurrentMemoryComponent()).thenReturn(mockComponent);
    LSMIOOperationCallback callback = new LSMIOOperationCallback(dsInfo, mockIndex, idGenerator.getId(), mockIndexCheckpointManagerProvider());
    ILSMComponentId initialId = idGenerator.getId();
    // simulate a partition is flushed before allocated
    idGenerator.refresh();
    long flushLsn = 1L;
    ILSMComponentId nextComponentId = idGenerator.getId();
    Map<String, Object> flushMap = new HashMap<>();
    flushMap.put(LSMIOOperationCallback.KEY_FLUSH_LOG_LSN, flushLsn);
    flushMap.put(LSMIOOperationCallback.KEY_NEXT_COMPONENT_ID, nextComponentId);
    callback.allocated(mockComponent);
    callback.recycled(mockComponent);
    checkMemoryComponent(initialId, mockComponent);
}
#method_after
@Test
public void testAllocateComponentId() throws HyracksDataException {
    int numMemoryComponents = 2;
    DatasetInfo dsInfo = new DatasetInfo(101, null);
    ILSMComponentIdGenerator idGenerator = new LSMComponentIdGenerator(numMemoryComponents);
    idGenerator.init(MIN_VALID_COMPONENT_ID);
    ILSMIndex mockIndex = Mockito.mock(ILSMIndex.class);
    Mockito.when(mockIndex.getNumberOfAllMemoryComponents()).thenReturn(numMemoryComponents);
    ILSMMemoryComponent mockComponent = Mockito.mock(AbstractLSMMemoryComponent.class);
    Mockito.when(mockIndex.getCurrentMemoryComponent()).thenReturn(mockComponent);
    LSMIOOperationCallback callback = new LSMIOOperationCallback(dsInfo, mockIndex, idGenerator, mockIndexCheckpointManagerProvider());
    callback.allocated(mockComponent);
    ILSMComponentId initialId = idGenerator.getId();
    idGenerator.refresh();
    long flushLsn = 1L;
    ILSMComponentId nextComponentId = idGenerator.getId();
    callback.recycled(mockComponent);
    checkMemoryComponent(initialId, mockComponent);
}
#end_block

#method_before
@Test
public void testRecycleComponentId() throws HyracksDataException {
    int numMemoryComponents = 2;
    DatasetInfo dsInfo = new DatasetInfo(101, null);
    ILSMComponentIdGenerator idGenerator = new LSMComponentIdGenerator(numMemoryComponents, MIN_VALID_COMPONENT_ID);
    ILSMIndex mockIndex = Mockito.mock(ILSMIndex.class);
    Mockito.when(mockIndex.getNumberOfAllMemoryComponents()).thenReturn(numMemoryComponents);
    ILSMMemoryComponent mockComponent = Mockito.mock(AbstractLSMMemoryComponent.class);
    Mockito.when(mockIndex.getCurrentMemoryComponent()).thenReturn(mockComponent);
    LSMIOOperationCallback callback = new LSMIOOperationCallback(dsInfo, mockIndex, idGenerator.getId(), mockIndexCheckpointManagerProvider());
    String indexId = "mockIndexId";
    ILSMComponentId id = idGenerator.getId();
    callback.recycled(mockComponent);
    checkMemoryComponent(id, mockComponent);
    Mockito.when(mockIndex.isMemoryComponentsAllocated()).thenReturn(true);
    for (int i = 0; i < 100; i++) {
        // schedule a flush
        idGenerator.refresh();
        ILSMComponentId expectedId = idGenerator.getId();
        long flushLsn = 0L;
        Map<String, Object> flushMap = new HashMap<>();
        flushMap.put(LSMIOOperationCallback.KEY_FLUSH_LOG_LSN, flushLsn);
        flushMap.put(LSMIOOperationCallback.KEY_NEXT_COMPONENT_ID, expectedId);
        ILSMIndexAccessor accessor = new TestLSMIndexAccessor(new TestLSMIndexOperationContext(mockIndex));
        accessor.getOpContext().setParameters(flushMap);
        FileReference target = new FileReference(Mockito.mock(IODeviceHandle.class), getComponentFileName());
        LSMComponentFileReferences files = new LSMComponentFileReferences(target, target, target);
        FlushOperation flush = new TestFlushOperation(accessor, target, callback, indexId, files, new LSMComponentId(0, 0));
        callback.scheduled(flush);
        callback.beforeOperation(flush);
        callback.recycled(mockComponent);
        flush.setNewComponent(mockDiskComponent());
        callback.afterOperation(flush);
        callback.afterFinalize(flush);
        callback.completed(flush);
        checkMemoryComponent(expectedId, mockComponent);
    }
}
#method_after
@Test
public void testRecycleComponentId() throws HyracksDataException {
    int numMemoryComponents = 2;
    DatasetInfo dsInfo = new DatasetInfo(101, null);
    ILSMComponentIdGenerator idGenerator = new LSMComponentIdGenerator(numMemoryComponents);
    idGenerator.init(MIN_VALID_COMPONENT_ID);
    ILSMIndex mockIndex = Mockito.mock(ILSMIndex.class);
    Mockito.when(mockIndex.getNumberOfAllMemoryComponents()).thenReturn(numMemoryComponents);
    ILSMMemoryComponent mockComponent = Mockito.mock(AbstractLSMMemoryComponent.class);
    Mockito.when(mockIndex.getCurrentMemoryComponent()).thenReturn(mockComponent);
    LSMIOOperationCallback callback = new LSMIOOperationCallback(dsInfo, mockIndex, idGenerator, mockIndexCheckpointManagerProvider());
    String indexId = "mockIndexId";
    callback.allocated(mockComponent);
    ILSMComponentId id = idGenerator.getId();
    callback.recycled(mockComponent);
    checkMemoryComponent(id, mockComponent);
    Mockito.when(mockIndex.isMemoryComponentsAllocated()).thenReturn(true);
    for (int i = 0; i < 100; i++) {
        // schedule a flush
        idGenerator.refresh();
        ILSMComponentId expectedId = idGenerator.getId();
        long flushLsn = 0L;
        Map<String, Object> flushMap = new HashMap<>();
        flushMap.put(LSMIOOperationCallback.KEY_FLUSH_LOG_LSN, flushLsn);
        flushMap.put(LSMIOOperationCallback.KEY_NEXT_COMPONENT_ID, expectedId);
        ILSMIndexAccessor accessor = new TestLSMIndexAccessor(new TestLSMIndexOperationContext(mockIndex));
        accessor.getOpContext().setParameters(flushMap);
        FileReference target = new FileReference(Mockito.mock(IODeviceHandle.class), getComponentFileName());
        LSMComponentFileReferences files = new LSMComponentFileReferences(target, target, target);
        FlushOperation flush = new TestFlushOperation(accessor, target, callback, indexId, files, new LSMComponentId(0, 0));
        callback.scheduled(flush);
        callback.beforeOperation(flush);
        callback.recycled(mockComponent);
        flush.setNewComponent(mockDiskComponent());
        callback.afterOperation(flush);
        callback.afterFinalize(flush);
        callback.completed(flush);
        checkMemoryComponent(expectedId, mockComponent);
    }
}
#end_block

#method_before
@Override
public int compare(String a, String b) {
    return -(IndexComponentFileReference.of(a).compareTo(IndexComponentFileReference.of(b)));
}
#method_after
@Override
public int compare(String a, String b) {
    return IndexComponentFileReference.of(b).compareTo(IndexComponentFileReference.of(a));
}
#end_block

#method_before
@Override
public void refresh() {
    final long nextId = ++lastUsedId;
    componentId = new LSMComponentId(nextId, nextId);
    currentComponentIndex = (currentComponentIndex + 1) % numComponents;
}
#method_after
@Override
public synchronized void refresh() {
    if (!initialized) {
        throw new IllegalStateException("Attempt to refresh component id before initialziation.");
    }
    final long nextId = ++lastUsedId;
    componentId = new LSMComponentId(nextId, nextId);
    currentComponentIndex = (currentComponentIndex + 1) % numComponents;
}
#end_block

#method_before
@Override
public ILSMComponentId getId() {
    return componentId;
}
#method_after
@Override
public synchronized ILSMComponentId getId() {
    if (!initialized) {
        throw new IllegalStateException("Attempt to get component id before initialziation.");
    }
    return componentId;
}
#end_block

#method_before
@Override
public int getCurrentComponentIndex() {
    return currentComponentIndex;
}
#method_after
@Override
public synchronized int getCurrentComponentIndex() {
    return currentComponentIndex;
}
#end_block

#method_before
@Override
public void allocated(ILSMMemoryComponent component) throws HyracksDataException {
// No Op
}
#method_after
@Override
public void allocated(ILSMMemoryComponent component) throws HyracksDataException {
    if (firstAllocation) {
        firstAllocation = false;
        componentIds.add(componentIdGenerator.getId());
    }
}
#end_block

#method_before
@Override
public synchronized void register(String resourcePath, IIndex index) throws HyracksDataException {
    validateDatasetLifecycleManagerState();
    int did = getDIDfromResourcePath(resourcePath);
    LocalResource resource = resourceRepository.get(resourcePath);
    DatasetResource datasetResource = datasets.get(did);
    if (datasetResource == null) {
        datasetResource = getDatasetLifecycle(did);
    }
    datasetResource.register(resource, (ILSMIndex) index);
}
#method_after
@Override
public synchronized void register(String resourcePath, IIndex index) throws HyracksDataException {
    validateDatasetLifecycleManagerState();
    int did = getDIDfromResourcePath(resourcePath);
    LocalResource resource = resourceRepository.get(resourcePath);
    DatasetResource datasetResource = datasets.get(did);
    if (datasetResource == null) {
        datasetResource = getDatasetLifecycle(did);
    }
    datasetResource.register(resource, (ILSMIndex) index);
    if (((ILSMIndex) index).isPrimaryIndex()) {
        initializeDatasetPartitionValidComponentId(datasetResource, resource);
    }
}
#end_block

#method_before
private void populateOpTrackerAndIdGenerator(DatasetResource dataset, int partition) {
    final long validComponentId = getDatasetPartitionValidComponentId(dataset, partition);
    ILSMComponentIdGenerator idGenerator = new LSMComponentIdGenerator(storageProperties.getMemoryComponentsNum(), validComponentId);
    PrimaryIndexOperationTracker opTracker = new PrimaryIndexOperationTracker(dataset.getDatasetID(), partition, logManager, dataset.getDatasetInfo(), idGenerator);
    dataset.setPrimaryIndexOperationTracker(partition, opTracker);
    dataset.setIdGenerator(partition, idGenerator);
}
#method_after
private void populateOpTrackerAndIdGenerator(DatasetResource dataset, int partition) {
    ILSMComponentIdGenerator idGenerator = new LSMComponentIdGenerator(storageProperties.getMemoryComponentsNum());
    PrimaryIndexOperationTracker opTracker = new PrimaryIndexOperationTracker(dataset.getDatasetID(), partition, logManager, dataset.getDatasetInfo(), idGenerator);
    dataset.setPrimaryIndexOperationTracker(partition, opTracker);
    dataset.setIdGenerator(partition, idGenerator);
}
#end_block

#method_before
@Override
public String toString() {
    return "{ \"class\" : \"" + getClass().getSimpleName() + "\", \"data\" : " + (data == null ? "null" : ("\"" + data.hashCode() + ":" + data.length + "\"")) + ", \"offset\" : " + start + ", \"length\" : " + len + " }";
}
#method_after
@Override
public String toString() {
    return "{ \"class\" : \"" + getClass().getSimpleName() + "\", \"data\" : " + (data == null ? "null" : ("\"" + System.identityHashCode(data) + ":" + data.length + "\"")) + ", \"offset\" : " + start + ", \"length\" : " + len + " }";
}
#end_block

#method_before
public static void main(String[] args) {
    try {
        final String nodeId = ConfigUtils.getOptionValue(args, NCConfig.Option.NODE_ID);
        final ConfigManager configManager = new ConfigManager(args);
        INCApplication application = getApplication(args);
        application.registerConfig(configManager);
        NCConfig ncConfig = new NCConfig(nodeId, configManager);
        LoggerContext ctx = (LoggerContext) LogManager.getContext(false);
        Configuration cfg = ctx.getConfiguration();
        NCLogConfigurationFactory logCfgFactory = new NCLogConfigurationFactory(ncConfig);
        ConfigurationFactory.setConfigurationFactory(logCfgFactory);
        cfg.removeLogger("Console");
        configManager.processConfig();
        ctx.start(logCfgFactory.getConfiguration(ctx, ConfigurationSource.NULL_SOURCE));
        final NodeControllerService ncService = new NodeControllerService(ncConfig, application);
        ncService.start();
        while (true) {
            Thread.sleep(10000);
        }
    } catch (CmdLineException e) {
        LOGGER.log(Level.DEBUG, "Exception parsing command line: " + Arrays.toString(args), e);
        System.exit(2);
    } catch (Exception e) {
        LOGGER.error("Exiting NCDriver due to exception", e);
        System.exit(1);
    }
}
#method_after
public static void main(String[] args) {
    try {
        final String nodeId = ConfigUtils.getOptionValue(args, NCConfig.Option.NODE_ID);
        final ConfigManager configManager = new ConfigManager(args);
        INCApplication application = getApplication(args);
        application.registerConfig(configManager);
        NCConfig ncConfig = new NCConfig(nodeId, configManager);
        LoggerContext ctx = (LoggerContext) LogManager.getContext(false);
        Configuration cfg = ctx.getConfiguration();
        NCLogConfigurationFactory logCfgFactory = new NCLogConfigurationFactory(ncConfig);
        ConfigurationFactory.setConfigurationFactory(logCfgFactory);
        configManager.processConfig();
        cfg.removeLogger("Console");
        ctx.start(logCfgFactory.getConfiguration(ctx, ConfigurationSource.NULL_SOURCE));
        final NodeControllerService ncService = new NodeControllerService(ncConfig, application);
        ncService.start();
        while (true) {
            Thread.sleep(10000);
        }
    } catch (CmdLineException e) {
        LOGGER.log(Level.DEBUG, "Exception parsing command line: " + Arrays.toString(args), e);
        System.exit(2);
    } catch (Exception e) {
        LOGGER.error("Exiting NCDriver due to exception", e);
        System.exit(1);
    }
}
#end_block

#method_before
public void insertDoubleTuples(IIndexTestContext ctx, int numTuples, Random rnd) throws Exception {
    insertDoubleTuples(ctx, numTuples, rnd, false);
}
#method_after
public void insertDoubleTuples(IIndexTestContext ctx, int numTuples, Random rnd) throws HyracksDataException {
    insertDoubleTuples(ctx, numTuples, rnd, false);
}
#end_block

#method_before
@SuppressWarnings("unchecked")
public void insertDoubleTuples(IIndexTestContext ctx, int numTuples, Random rnd, boolean isPoint) throws Exception {
    int fieldCount = ctx.getFieldCount();
    int numKeyFields = ctx.getKeyFieldCount();
    double[] fieldValues = new double[ctx.getFieldCount()];
    // Scale range of values according to number of keys.
    // For example, for 2 keys we want the square root of numTuples, for 3
    // keys the cube root of numTuples, etc.
    double maxValue = Math.ceil(Math.pow(numTuples, 1.0 / numKeyFields));
    for (int i = 0; i < numTuples; i++) {
        // Set keys.
        setDoubleKeyFields(fieldValues, numKeyFields, maxValue, rnd, isPoint);
        // Set values.
        setDoublePayloadFields(fieldValues, numKeyFields, fieldCount);
        TupleUtils.createDoubleTuple(ctx.getTupleBuilder(), ctx.getTuple(), fieldValues);
        if (LOGGER.isInfoEnabled()) {
            if ((i + 1) % (numTuples / Math.min(10, numTuples)) == 0) {
                LOGGER.info("Inserting Tuple " + (i + 1) + "/" + numTuples);
            }
        }
        try {
            ctx.getIndexAccessor().insert(ctx.getTuple());
            ctx.insertCheckTuple(createDoubleCheckTuple(fieldValues, ctx.getKeyFieldCount()), ctx.getCheckTuples());
        } catch (HyracksDataException e) {
            // we ignore duplicate keys.
            if (e.getErrorCode() != ErrorCode.DUPLICATE_KEY) {
                throw e;
            }
        }
    }
}
#method_after
@SuppressWarnings("unchecked")
public void insertDoubleTuples(IIndexTestContext ctx, int numTuples, Random rnd, boolean isPoint) throws HyracksDataException {
    int fieldCount = ctx.getFieldCount();
    int numKeyFields = ctx.getKeyFieldCount();
    double[] fieldValues = new double[ctx.getFieldCount()];
    // Scale range of values according to number of keys.
    // For example, for 2 keys we want the square root of numTuples, for 3
    // keys the cube root of numTuples, etc.
    double maxValue = Math.ceil(Math.pow(numTuples, 1.0 / numKeyFields));
    for (int i = 0; i < numTuples; i++) {
        // Set keys.
        setDoubleKeyFields(fieldValues, numKeyFields, maxValue, rnd, isPoint);
        // Set values.
        setDoublePayloadFields(fieldValues, numKeyFields, fieldCount);
        TupleUtils.createDoubleTuple(ctx.getTupleBuilder(), ctx.getTuple(), fieldValues);
        if (LOGGER.isInfoEnabled()) {
            if ((i + 1) % (numTuples / Math.min(10, numTuples)) == 0) {
                LOGGER.info("Inserting Tuple " + (i + 1) + "/" + numTuples);
            }
        }
        try {
            ctx.getIndexAccessor().insert(ctx.getTuple());
            ctx.insertCheckTuple(createDoubleCheckTuple(fieldValues, ctx.getKeyFieldCount()), ctx.getCheckTuples());
        } catch (HyracksDataException e) {
            // we ignore duplicate keys.
            if (e.getErrorCode() != ErrorCode.DUPLICATE_KEY) {
                throw e;
            }
        }
    }
}
#end_block

#method_before
@SuppressWarnings("unchecked")
public void bulkLoadDoubleTuples(IIndexTestContext ctx, int numTuples, Random rnd, boolean isPoint) throws Exception {
    int fieldCount = ctx.getFieldCount();
    int numKeyFields = ctx.getKeyFieldCount();
    double[] fieldValues = new double[ctx.getFieldCount()];
    double maxValue = Math.ceil(Math.pow(numTuples, 1.0 / numKeyFields));
    Collection<CheckTuple> tmpCheckTuples = createCheckTuplesCollection();
    for (int i = 0; i < numTuples; i++) {
        // Set keys.
        setDoubleKeyFields(fieldValues, numKeyFields, maxValue, rnd, isPoint);
        // Set values.
        setDoublePayloadFields(fieldValues, numKeyFields, fieldCount);
        // Set expected values.
        ctx.insertCheckTuple(createDoubleCheckTuple(fieldValues, ctx.getKeyFieldCount()), tmpCheckTuples);
    }
    bulkLoadCheckTuples(ctx, tmpCheckTuples);
    // Add tmpCheckTuples to ctx check tuples for comparing searches.
    for (CheckTuple checkTuple : tmpCheckTuples) {
        ctx.insertCheckTuple(checkTuple, ctx.getCheckTuples());
    }
}
#method_after
@SuppressWarnings("unchecked")
public void bulkLoadDoubleTuples(IIndexTestContext ctx, int numTuples, Random rnd, boolean isPoint) throws HyracksDataException {
    int fieldCount = ctx.getFieldCount();
    int numKeyFields = ctx.getKeyFieldCount();
    double[] fieldValues = new double[ctx.getFieldCount()];
    double maxValue = Math.ceil(Math.pow(numTuples, 1.0 / numKeyFields));
    Collection<CheckTuple> tmpCheckTuples = createCheckTuplesCollection();
    for (int i = 0; i < numTuples; i++) {
        // Set keys.
        setDoubleKeyFields(fieldValues, numKeyFields, maxValue, rnd, isPoint);
        // Set values.
        setDoublePayloadFields(fieldValues, numKeyFields, fieldCount);
        // Set expected values.
        ctx.insertCheckTuple(createDoubleCheckTuple(fieldValues, ctx.getKeyFieldCount()), tmpCheckTuples);
    }
    bulkLoadCheckTuples(ctx, tmpCheckTuples);
    // Add tmpCheckTuples to ctx check tuples for comparing searches.
    for (CheckTuple checkTuple : tmpCheckTuples) {
        ctx.insertCheckTuple(checkTuple, ctx.getCheckTuples());
    }
}
#end_block

#method_before
@SuppressWarnings("unchecked")
public void bulkLoadIntTuples(IIndexTestContext ctx, int numTuples, Random rnd, boolean isPoint) throws Exception {
    int fieldCount = ctx.getFieldCount();
    int numKeyFields = ctx.getKeyFieldCount();
    int[] fieldValues = new int[ctx.getFieldCount()];
    int maxValue = (int) Math.ceil(Math.pow(numTuples, 1.0 / numKeyFields));
    Collection<CheckTuple> tmpCheckTuples = createCheckTuplesCollection();
    for (int i = 0; i < numTuples; i++) {
        // Set keys.
        setIntKeyFields(fieldValues, numKeyFields, maxValue, rnd, isPoint);
        // Set values.
        setIntPayloadFields(fieldValues, numKeyFields, fieldCount);
        // Set expected values. (We also use these as the pre-sorted stream
        // for ordered indexes bulk loading).
        ctx.insertCheckTuple(createIntCheckTuple(fieldValues, ctx.getKeyFieldCount()), tmpCheckTuples);
    }
    bulkLoadCheckTuples(ctx, tmpCheckTuples, false);
    // Add tmpCheckTuples to ctx check tuples for comparing searches.
    for (CheckTuple checkTuple : tmpCheckTuples) {
        ctx.insertCheckTuple(checkTuple, ctx.getCheckTuples());
    }
}
#method_after
@SuppressWarnings("unchecked")
public void bulkLoadIntTuples(IIndexTestContext ctx, int numTuples, Random rnd, boolean isPoint) throws HyracksDataException {
    int fieldCount = ctx.getFieldCount();
    int numKeyFields = ctx.getKeyFieldCount();
    int[] fieldValues = new int[ctx.getFieldCount()];
    int maxValue = (int) Math.ceil(Math.pow(numTuples, 1.0 / numKeyFields));
    Collection<CheckTuple> tmpCheckTuples = createCheckTuplesCollection();
    for (int i = 0; i < numTuples; i++) {
        // Set keys.
        setIntKeyFields(fieldValues, numKeyFields, maxValue, rnd, isPoint);
        // Set values.
        setIntPayloadFields(fieldValues, numKeyFields, fieldCount);
        // Set expected values. (We also use these as the pre-sorted stream
        // for ordered indexes bulk loading).
        ctx.insertCheckTuple(createIntCheckTuple(fieldValues, ctx.getKeyFieldCount()), tmpCheckTuples);
    }
    bulkLoadCheckTuples(ctx, tmpCheckTuples, false);
    // Add tmpCheckTuples to ctx check tuples for comparing searches.
    for (CheckTuple checkTuple : tmpCheckTuples) {
        ctx.insertCheckTuple(checkTuple, ctx.getCheckTuples());
    }
}
#end_block

#method_before
// *** IJobLifecycleListener
@Override
public void notifyJobCreation(JobId jobId, JobSpecification jobSpecification) throws HyracksDataException {
    if (LOGGER.isEnabled(level)) {
        LOGGER.log(level, "notifyJobCreation(JobId jobId, JobSpecification jobSpecification) was called with jobId = " + jobId);
    }
    Object property = jobSpecification.getProperty(ACTIVE_ENTITY_PROPERTY_NAME);
    if (property == null || !(property instanceof EntityId)) {
        if (LOGGER.isEnabled(level)) {
            LOGGER.log(level, "Job is not of type active job. property found to be: " + property);
        }
        return;
    }
    EntityId entityId = (EntityId) property;
    monitorJob(jobId, entityId);
    boolean found = jobId2EntityId.get(jobId) != null;
    LOGGER.log(level, "Job was found to be: " + (found ? "Active" : "Inactive"));
    add(new ActiveEvent(jobId, Kind.JOB_CREATED, entityId, jobSpecification));
}
#method_after
// *** IJobLifecycleListener
@Override
public void notifyJobCreation(JobId jobId, JobSpecification jobSpecification) throws HyracksDataException {
    if (LOGGER.isEnabled(level)) {
        LOGGER.log(level, "notifyJobCreation(JobId jobId, JobSpecification jobSpecification) was called with jobId = " + jobId);
    }
    Object property = jobSpecification.getProperty(ACTIVE_ENTITY_PROPERTY_NAME);
    if (!(property instanceof EntityId)) {
        if (LOGGER.isEnabled(level)) {
            LOGGER.log(level, "Job is not of type active job. property found to be: " + property);
        }
        return;
    }
    EntityId entityId = (EntityId) property;
    monitorJob(jobId, entityId);
    boolean found = jobId2EntityId.get(jobId) != null;
    LOGGER.log(level, "Job was found to be: " + (found ? "Active" : "Inactive"));
    add(new ActiveEvent(jobId, Kind.JOB_CREATED, entityId, jobSpecification));
}
#end_block

#method_before
@Override
public AbstractOneInputOneOutputOneFramePushRuntime createOneOutputPushRuntime(final IHyracksTaskContext ctx) throws HyracksDataException {
    final IPrinter[] printers = new IPrinter[printerFactories.length];
    for (int i = 0; i < printerFactories.length; i++) {
        printers[i] = printerFactories[i].createPrinter();
    }
    return new AbstractOneInputOneOutputOneFramePushRuntime() {

        final class ForwardScriptOutput implements Runnable {

            private InputStream inStream;

            private ITupleParser parser;

            public ForwardScriptOutput(ITupleParser parser, InputStream inStream) {
                this.parser = parser;
                this.inStream = inStream;
            }

            @Override
            public void run() {
                try {
                    parser.parse(inStream, writer);
                } catch (HyracksDataException e) {
                    throw new RuntimeException(e);
                } finally {
                    try {
                        inStream.close();
                    } catch (Exception e) {
                    }
                }
            }
        }

        final class DumpInStreamToPrintStream implements Runnable {

            private BufferedReader reader;

            private PrintStream printStream;

            public DumpInStreamToPrintStream(InputStream inStream, PrintStream printStream) {
                this.reader = new BufferedReader(new InputStreamReader(inStream));
                this.printStream = printStream;
            }

            @Override
            public void run() {
                String s;
                try {
                    while ((s = reader.readLine()) != null) {
                        printStream.println(s);
                    }
                } catch (IOException e) {
                    throw new RuntimeException(e);
                } finally {
                    try {
                        reader.close();
                    } catch (IOException e) {
                        e.printStackTrace();
                    }
                    printStream.close();
                }
            }
        }

        private Process process;

        private PrintStream ps;

        private boolean first = true;

        private Thread outputPipe;

        private Thread dumpStderr;

        @Override
        public void open() throws HyracksDataException {
            if (first) {
                first = false;
                initAccessAppendRef(ctx);
            }
            try {
                ITupleParser parser = parserFactory.createTupleParser(ctx);
                process = Runtime.getRuntime().exec(command);
                ps = new PrintStream(process.getOutputStream());
                ForwardScriptOutput fso = new ForwardScriptOutput(parser, process.getInputStream());
                outputPipe = new Thread(fso);
                outputPipe.start();
                DumpInStreamToPrintStream disps = new DumpInStreamToPrintStream(process.getErrorStream(), System.err);
                dumpStderr = new Thread(disps);
                dumpStderr.start();
            } catch (IOException e) {
                throw HyracksDataException.create(e);
            }
        }

        @Override
        public void nextFrame(ByteBuffer buffer) throws HyracksDataException {
            tAccess.reset(buffer);
            int nTuple = tAccess.getTupleCount();
            for (int t = 0; t < nTuple; t++) {
                tRef.reset(tAccess, t);
                for (int i = 0; i < printers.length; i++) {
                    printers[i].print(buffer.array(), tRef.getFieldStart(i), tRef.getFieldLength(i), ps);
                    ps.print(fieldDelimiter);
                    if (i == printers.length - 1) {
                        ps.print('\n');
                    }
                }
            }
        }

        @Override
        public void close() throws HyracksDataException {
            // first close the printer printing to the process
            ps.close();
            int ret = 0;
            try {
                ret = process.waitFor();
                outputPipe.join();
                dumpStderr.join();
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
                throw HyracksDataException.create(e);
            }
            if (ret != 0) {
                throw new HyracksDataException("Process exit value: " + ret);
            }
            // close the following operator in the chain
            super.close();
        }

        @Override
        public void flush() throws HyracksDataException {
            ps.flush();
        }
    };
}
#method_after
@Override
public AbstractOneInputOneOutputOneFramePushRuntime createOneOutputPushRuntime(final IHyracksTaskContext ctx) throws HyracksDataException {
    final IPrinter[] printers = new IPrinter[printerFactories.length];
    for (int i = 0; i < printerFactories.length; i++) {
        printers[i] = printerFactories[i].createPrinter();
    }
    return new AbstractOneInputOneOutputOneFramePushRuntime() {

        final class ForwardScriptOutput implements Runnable {

            private InputStream inStream;

            private ITupleParser parser;

            public ForwardScriptOutput(ITupleParser parser, InputStream inStream) {
                this.parser = parser;
                this.inStream = inStream;
            }

            @Override
            public void run() {
                try {
                    parser.parse(inStream, writer);
                } catch (HyracksDataException e) {
                    throw new RuntimeException(e);
                } finally {
                    try {
                        inStream.close();
                    } catch (Exception e) {
                    }
                }
            }
        }

        final class DumpInStreamToPrintStream implements Runnable {

            private BufferedReader reader;

            private PrintStream printStream;

            public DumpInStreamToPrintStream(InputStream inStream, PrintStream printStream) {
                this.reader = new BufferedReader(new InputStreamReader(inStream));
                this.printStream = printStream;
            }

            @Override
            public void run() {
                String s;
                try {
                    while ((s = reader.readLine()) != null) {
                        printStream.println(s);
                    }
                } catch (IOException e) {
                    throw new RuntimeException(e);
                } finally {
                    try {
                        reader.close();
                    } catch (IOException e) {
                        e.printStackTrace();
                    }
                    printStream.close();
                }
            }
        }

        private Process process;

        private PrintStream ps;

        private boolean first = true;

        private Thread outputPipe;

        private Thread dumpStderr;

        @Override
        public void open() throws HyracksDataException {
            if (first) {
                first = false;
                initAccessAppendRef(ctx);
            }
            try {
                ITupleParser parser = parserFactory.createTupleParser(ctx);
                process = Runtime.getRuntime().exec(command);
                ps = new PrintStream(process.getOutputStream());
                ForwardScriptOutput fso = new ForwardScriptOutput(parser, process.getInputStream());
                outputPipe = new Thread(fso);
                outputPipe.start();
                DumpInStreamToPrintStream disps = new DumpInStreamToPrintStream(process.getErrorStream(), System.err);
                dumpStderr = new Thread(disps);
                dumpStderr.start();
                super.open();
            } catch (IOException e) {
                throw HyracksDataException.create(e);
            }
        }

        @Override
        public void nextFrame(ByteBuffer buffer) throws HyracksDataException {
            tAccess.reset(buffer);
            int nTuple = tAccess.getTupleCount();
            for (int t = 0; t < nTuple; t++) {
                tRef.reset(tAccess, t);
                for (int i = 0; i < printers.length; i++) {
                    printers[i].print(buffer.array(), tRef.getFieldStart(i), tRef.getFieldLength(i), ps);
                    ps.print(fieldDelimiter);
                    if (i == printers.length - 1) {
                        ps.print('\n');
                    }
                }
            }
        }

        @Override
        public void close() throws HyracksDataException {
            // first close the printer printing to the process
            ps.close();
            int ret = 0;
            try {
                ret = process.waitFor();
                outputPipe.join();
                dumpStderr.join();
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
                throw HyracksDataException.create(e);
            }
            if (ret != 0) {
                throw new HyracksDataException("Process exit value: " + ret);
            }
            // close the following operator in the chain
            super.close();
        }

        @Override
        public void flush() throws HyracksDataException {
            ps.flush();
        }
    };
}
#end_block

#method_before
public boolean proceed(List<ILSMDiskComponent> allDiskComponents) throws HyracksDataException {
    for (int i = 0; i < components.size(); i++) {
        replacedComponentIds.add(components.get(i).getId());
        // ensure that disk component exists
        boolean found = false;
        final ILSMComponentId replacedComponentId = replacedComponentIds.get(i);
        LOGGER.debug("looking for a component with the id: {}", replacedComponentId);
        for (ILSMDiskComponent dc : allDiskComponents) {
            ILSMComponentId diskComponentId = dc.getId();
            LOGGER.info("next disk component id: {}", diskComponentId);
            if (diskComponentId.equals(replacedComponentId)) {
                found = true;
                diskComponents.add(dc);
                break;
            }
        }
        if (!found) {
            // component has been merged?
            LOGGER.log(Level.WARN, "Memory Component with id = " + replacedComponentId + " was flushed and merged before search cursor replaces it");
            return false;
        }
    }
    return true;
}
#method_after
public boolean proceed(List<ILSMDiskComponent> allDiskComponents) throws HyracksDataException {
    for (int i = 0; i < components.size(); i++) {
        replacedComponentIds.add(components.get(i).getId());
        // ensure that disk component exists
        boolean found = false;
        final ILSMComponentId replacedComponentId = replacedComponentIds.get(i);
        LOGGER.trace("looking for a component with the id: {}", replacedComponentId);
        for (ILSMDiskComponent dc : allDiskComponents) {
            ILSMComponentId diskComponentId = dc.getId();
            LOGGER.trace("next disk component id: {}", diskComponentId);
            if (diskComponentId.equals(replacedComponentId)) {
                found = true;
                diskComponents.add(dc);
                break;
            }
        }
        if (!found) {
            // component has been merged?
            LOGGER.warn("memory component {} was flushed and merged before search cursor replaces it", replacedComponentId);
            return false;
        }
    }
    return true;
}
#end_block

#method_before
public void replace(ILSMIndexOperationContext ctx) {
    // Called after exit and enter has been completed
    try {
        for (int i = 0; i < count; i++) {
            ILSMComponent removed = ctx.getComponentHolder().remove(swapIndexes[i]);
            if (removed.getType() == LSMComponentType.MEMORY) {
                LOGGER.log(Level.INFO, "Removed a memory component from the search operation");
            } else {
                throw new IllegalStateException("Disk components can't be removed from the search operation");
            }
            ctx.getComponentHolder().add(swapIndexes[i], diskComponents.get(i));
        }
    } catch (Exception e) {
        LOGGER.log(Level.WARN, "Failure replacing memory components with disk components", e);
        throw e;
    }
}
#method_after
public void replace(ILSMIndexOperationContext ctx) {
    // Called after exit and enter has been completed
    try {
        for (int i = 0; i < count; i++) {
            ILSMComponent removed = ctx.getComponentHolder().remove(swapIndexes[i]);
            if (removed.getType() == LSMComponentType.MEMORY) {
                LOGGER.info("Removed a memory component from the search operation");
            } else {
                throw new IllegalStateException("Disk components can't be removed from the search operation");
            }
            ctx.getComponentHolder().add(swapIndexes[i], diskComponents.get(i));
        }
    } catch (Exception e) {
        LOGGER.warn("Failure replacing memory components with disk components", e);
        throw e;
    }
}
#end_block

#method_before
private int getFrameIndex(int ptr) {
    return (ptr >> 16);
}
#method_after
private int getFrameIndex(int ptr) {
    return ptr >> 16;
}
#end_block

#method_before
private int getFrameOffset(int ptr) {
    return (ptr & 0xffff);
}
#method_after
private int getFrameOffset(int ptr) {
    return ptr & 0xffff;
}
#end_block

#method_before
private boolean isInOperatorWithStaticList(QuantifiedExpression qe) {
    if (qe.getQuantifier() != QuantifiedExpression.Quantifier.SOME) {
        return false;
    }
    List<QuantifiedPair> qpList = qe.getQuantifiedList();
    if (qpList.size() != 1) {
        return false;
    }
    QuantifiedPair qp = qpList.get(0);
    Expression condExpr = qe.getSatisfiesExpr();
    if (condExpr.getKind() != Kind.OP_EXPRESSION) {
        return false;
    }
    OperatorExpr opExpr = (OperatorExpr) condExpr;
    if (opExpr.getOpList().get(0) != OperatorType.EQ) {
        return false;
    }
    List<Expression> operandExprs = opExpr.getExprList();
    if (operandExprs.size() != 2) {
        return false;
    }
    int varPos = operandExprs.indexOf(qp.getVarExpr());
    if (varPos < 0) {
        return false;
    }
    Expression inExpr = qp.getExpr();
    switch(inExpr.getKind()) {
        case LIST_CONSTRUCTOR_EXPRESSION:
            ListConstructor listExpr = (ListConstructor) inExpr;
            List<Expression> itemExprs = listExpr.getExprList();
            if (itemExprs.isEmpty()) {
                return false;
            }
            for (Expression itemExpr : itemExprs) {
                boolean isConst = itemExpr.getKind() == Kind.LITERAL_EXPRESSION || (itemExpr.getKind() == Kind.VARIABLE_EXPRESSION && SqlppVariableUtil.isExternalVariableReference((VariableExpr) itemExpr));
                if (!isConst) {
                    return false;
                }
            }
            return true;
        case VARIABLE_EXPRESSION:
            VarIdentifier inVarId = ((VariableExpr) inExpr).getVar();
            if (!SqlppVariableUtil.isExternalVariableIdentifier(inVarId)) {
                return false;
            }
            IAObject inValue = externalVars.get(inVarId);
            return inValue != null && inValue.getType().getTypeTag().isListType() && ((IACollection) inValue).size() > 0;
        default:
            return false;
    }
}
#method_after
// At this point "$x in list_expr" is a quantified expression:
// "some $y in list_expr satisfies $x = $y"
// Look for such quantified expression with a constant list_expr ([e1, e2, ... eN])
private boolean isInOperatorWithStaticList(QuantifiedExpression qe) {
    if (qe.getQuantifier() != QuantifiedExpression.Quantifier.SOME) {
        return false;
    }
    List<QuantifiedPair> qpList = qe.getQuantifiedList();
    if (qpList.size() != 1) {
        return false;
    }
    QuantifiedPair qp = qpList.get(0);
    Expression condExpr = qe.getSatisfiesExpr();
    if (condExpr.getKind() != Kind.OP_EXPRESSION) {
        return false;
    }
    OperatorExpr opExpr = (OperatorExpr) condExpr;
    if (opExpr.getOpList().get(0) != OperatorType.EQ) {
        return false;
    }
    List<Expression> operandExprs = opExpr.getExprList();
    if (operandExprs.size() != 2) {
        return false;
    }
    int varPos = operandExprs.indexOf(qp.getVarExpr());
    if (varPos < 0) {
        return false;
    }
    Expression inExpr = qp.getExpr();
    switch(inExpr.getKind()) {
        case LIST_CONSTRUCTOR_EXPRESSION:
            ListConstructor listExpr = (ListConstructor) inExpr;
            List<Expression> itemExprs = listExpr.getExprList();
            if (itemExprs.isEmpty()) {
                return false;
            }
            for (Expression itemExpr : itemExprs) {
                boolean isConst = itemExpr.getKind() == Kind.LITERAL_EXPRESSION || (itemExpr.getKind() == Kind.VARIABLE_EXPRESSION && SqlppVariableUtil.isExternalVariableReference((VariableExpr) itemExpr));
                if (!isConst) {
                    return false;
                }
            }
            return true;
        case VARIABLE_EXPRESSION:
            VarIdentifier inVarId = ((VariableExpr) inExpr).getVar();
            if (!SqlppVariableUtil.isExternalVariableIdentifier(inVarId)) {
                return false;
            }
            IAObject inValue = externalVars.get(inVarId);
            return inValue != null && inValue.getType().getTypeTag().isListType() && ((IACollection) inValue).size() > 0;
        default:
            return false;
    }
}
#end_block

#method_before
@Override
public void deleteFile(int fileId) throws HyracksDataException {
    synchronized (fileMapManager) {
        fileMapManager.unregisterFile(fileId);
    }
    int reclaimedPages = 0;
    for (int i = 0; i < buckets.length; i++) {
        final CacheBucket bucket = buckets[i];
        bucket.bucketLock.lock();
        try {
            VirtualPage prev = null;
            VirtualPage curr = bucket.cachedPage;
            while (curr != null) {
                if (BufferedFileHandle.getFileId(curr.dpid()) == fileId) {
                    reclaimedPages++;
                    if (curr.isLargePage()) {
                        largePages.getAndAdd(-curr.getFrameSizeMultiplier());
                        used.addAndGet(-curr.getFrameSizeMultiplier());
                    } else {
                        used.decrementAndGet();
                    }
                    if (prev == null) {
                        bucket.cachedPage = curr.next();
                        recycle(curr);
                        curr = bucket.cachedPage;
                    } else {
                        prev.next(curr.next());
                        recycle(curr);
                        curr = prev.next();
                    }
                } else {
                    prev = curr;
                    curr = curr.next();
                }
            }
        } finally {
            bucket.bucketLock.unlock();
        }
    }
    LOGGER.trace("Reclaimed pages = {}", reclaimedPages);
    logStats();
}
#method_after
@Override
public void deleteFile(int fileId) throws HyracksDataException {
    synchronized (fileMapManager) {
        fileMapManager.unregisterFile(fileId);
    }
    int reclaimedPages = 0;
    for (int i = 0; i < buckets.length; i++) {
        final CacheBucket bucket = buckets[i];
        bucket.bucketLock.lock();
        try {
            VirtualPage prev = null;
            VirtualPage curr = bucket.cachedPage;
            while (curr != null) {
                if (BufferedFileHandle.getFileId(curr.dpid()) == fileId) {
                    reclaimedPages++;
                    if (curr.isLargePage()) {
                        largePages.getAndAdd(-curr.getFrameSizeMultiplier());
                        used.addAndGet(-curr.getFrameSizeMultiplier());
                    } else {
                        used.decrementAndGet();
                    }
                    if (prev == null) {
                        bucket.cachedPage = curr.next();
                        recycle(curr);
                        curr = bucket.cachedPage;
                    } else {
                        prev.next(curr.next());
                        recycle(curr);
                        curr = prev.next();
                    }
                } else {
                    prev = curr;
                    curr = curr.next();
                }
            }
        } finally {
            bucket.bucketLock.unlock();
        }
    }
    if (LOGGER.isTraceEnabled()) {
        LOGGER.trace("Reclaimed pages = " + reclaimedPages);
    }
    logStats();
}
#end_block

#method_before
@Override
public Void visitGroupByOperator(GroupByOperator op, IOptimizationContext ctx) throws AlgebricksException {
    Map<LogicalVariable, EquivalenceClass> equivalenceClasses = new HashMap<LogicalVariable, EquivalenceClass>();
    List<FunctionalDependency> functionalDependencies = new ArrayList<FunctionalDependency>();
    ctx.putEquivalenceClassMap(op, equivalenceClasses);
    ctx.putFDList(op, functionalDependencies);
    List<FunctionalDependency> inheritedFDs = new ArrayList<FunctionalDependency>();
    for (ILogicalPlan p : op.getNestedPlans()) {
        for (Mutable<ILogicalOperator> r : p.getRoots()) {
            ILogicalOperator op2 = r.getValue();
            equivalenceClasses.putAll(getOrComputeEqClasses(op2, ctx));
            inheritedFDs.addAll(getOrComputeFDs(op2, ctx));
        }
    }
    ILogicalOperator op0 = op.getInputs().get(0).getValue();
    inheritedFDs.addAll(getOrComputeFDs(op0, ctx));
    Map<LogicalVariable, EquivalenceClass> inheritedEcs = getOrComputeEqClasses(op0, ctx);
    for (FunctionalDependency inherited : inheritedFDs) {
        boolean isCoveredByGbyOrDecorVars = true;
        List<LogicalVariable> newHead = new ArrayList<LogicalVariable>(inherited.getHead().size());
        for (LogicalVariable v : inherited.getHead()) {
            LogicalVariable vnew = getNewGbyVar(op, v);
            if (vnew == null) {
                vnew = getNewDecorVar(op, v);
                if (vnew == null) {
                    isCoveredByGbyOrDecorVars = false;
                }
                break;
            }
            newHead.add(vnew);
        }
        if (isCoveredByGbyOrDecorVars) {
            List<LogicalVariable> newTail = new ArrayList<LogicalVariable>();
            for (LogicalVariable v2 : inherited.getTail()) {
                LogicalVariable v3 = getNewGbyVar(op, v2);
                if (v3 != null) {
                    newTail.add(v3);
                }
            }
            if (!newTail.isEmpty()) {
                FunctionalDependency newFd = new FunctionalDependency(newHead, newTail);
                functionalDependencies.add(newFd);
            }
        }
    }
    List<LogicalVariable> premiseGby = new LinkedList<LogicalVariable>();
    List<Pair<LogicalVariable, Mutable<ILogicalExpression>>> gByList = op.getGroupByList();
    for (Pair<LogicalVariable, Mutable<ILogicalExpression>> p : gByList) {
        premiseGby.add(p.first);
    }
    List<Pair<LogicalVariable, Mutable<ILogicalExpression>>> decorList = op.getDecorList();
    LinkedList<LogicalVariable> conclDecor = new LinkedList<LogicalVariable>();
    for (Pair<LogicalVariable, Mutable<ILogicalExpression>> p : decorList) {
        conclDecor.add(GroupByOperator.getDecorVariable(p));
    }
    if (!conclDecor.isEmpty()) {
        functionalDependencies.add(new FunctionalDependency(premiseGby, conclDecor));
    }
    Set<LogicalVariable> gbySet = new HashSet<LogicalVariable>();
    for (Pair<LogicalVariable, Mutable<ILogicalExpression>> p : gByList) {
        ILogicalExpression expr = p.second.getValue();
        if (expr.getExpressionTag() == LogicalExpressionTag.VARIABLE) {
            VariableReferenceExpression v = (VariableReferenceExpression) expr;
            gbySet.add(v.getVariableReference());
        }
    }
    LocalGroupingProperty lgp = new LocalGroupingProperty(gbySet);
    ILocalStructuralProperty normalizedLgp = lgp.normalize(inheritedEcs, inheritedFDs);
    Set<LogicalVariable> normSet = new ListSet<>();
    normalizedLgp.getColumns(normSet);
    List<Pair<LogicalVariable, Mutable<ILogicalExpression>>> newGbyList = new ArrayList<>();
    boolean changed = false;
    for (Pair<LogicalVariable, Mutable<ILogicalExpression>> p : gByList) {
        ILogicalExpression expr = p.second.getValue();
        if (expr.getExpressionTag() == LogicalExpressionTag.VARIABLE) {
            VariableReferenceExpression varRef = (VariableReferenceExpression) expr;
            LogicalVariable v2 = varRef.getVariableReference();
            EquivalenceClass ec2 = inheritedEcs.get(v2);
            LogicalVariable v3;
            if (ec2 != null && !ec2.representativeIsConst()) {
                v3 = ec2.getVariableRepresentative();
            } else {
                v3 = v2;
            }
            if (normSet.contains(v3)) {
                newGbyList.add(p);
            } else {
                changed = true;
                decorList.add(p);
            }
        } else {
            newGbyList.add(p);
        }
    }
    if (changed) {
        if (AlgebricksConfig.ALGEBRICKS_LOGGER.isTraceEnabled()) {
            AlgebricksConfig.ALGEBRICKS_LOGGER.trace(">>>> Group-by list changed from " + GroupByOperator.veListToString(gByList) + " to " + GroupByOperator.veListToString(newGbyList) + ".\n");
        }
    }
    gByList.clear();
    gByList.addAll(newGbyList);
    return null;
}
#method_after
@Override
public Void visitGroupByOperator(GroupByOperator op, IOptimizationContext ctx) throws AlgebricksException {
    Map<LogicalVariable, EquivalenceClass> equivalenceClasses = new HashMap<LogicalVariable, EquivalenceClass>();
    List<FunctionalDependency> functionalDependencies = new ArrayList<FunctionalDependency>();
    ctx.putEquivalenceClassMap(op, equivalenceClasses);
    ctx.putFDList(op, functionalDependencies);
    List<FunctionalDependency> inheritedFDs = new ArrayList<FunctionalDependency>();
    for (ILogicalPlan p : op.getNestedPlans()) {
        for (Mutable<ILogicalOperator> r : p.getRoots()) {
            ILogicalOperator op2 = r.getValue();
            equivalenceClasses.putAll(getOrComputeEqClasses(op2, ctx));
            inheritedFDs.addAll(getOrComputeFDs(op2, ctx));
        }
    }
    ILogicalOperator op0 = op.getInputs().get(0).getValue();
    inheritedFDs.addAll(getOrComputeFDs(op0, ctx));
    Map<LogicalVariable, EquivalenceClass> inheritedEcs = getOrComputeEqClasses(op0, ctx);
    for (FunctionalDependency inherited : inheritedFDs) {
        boolean isCoveredByGbyOrDecorVars = true;
        List<LogicalVariable> newHead = new ArrayList<LogicalVariable>(inherited.getHead().size());
        for (LogicalVariable v : inherited.getHead()) {
            LogicalVariable vnew = getNewGbyVar(op, v);
            if (vnew == null) {
                vnew = getNewDecorVar(op, v);
                if (vnew == null) {
                    isCoveredByGbyOrDecorVars = false;
                }
                break;
            }
            newHead.add(vnew);
        }
        if (isCoveredByGbyOrDecorVars) {
            List<LogicalVariable> newTail = new ArrayList<LogicalVariable>();
            for (LogicalVariable v2 : inherited.getTail()) {
                LogicalVariable v3 = getNewGbyVar(op, v2);
                if (v3 != null) {
                    newTail.add(v3);
                }
            }
            if (!newTail.isEmpty()) {
                FunctionalDependency newFd = new FunctionalDependency(newHead, newTail);
                functionalDependencies.add(newFd);
            }
        }
    }
    List<LogicalVariable> premiseGby = new LinkedList<LogicalVariable>();
    List<Pair<LogicalVariable, Mutable<ILogicalExpression>>> gByList = op.getGroupByList();
    for (Pair<LogicalVariable, Mutable<ILogicalExpression>> p : gByList) {
        premiseGby.add(p.first);
    }
    List<Pair<LogicalVariable, Mutable<ILogicalExpression>>> decorList = op.getDecorList();
    LinkedList<LogicalVariable> conclDecor = new LinkedList<LogicalVariable>();
    for (Pair<LogicalVariable, Mutable<ILogicalExpression>> p : decorList) {
        conclDecor.add(GroupByOperator.getDecorVariable(p));
    }
    if (!conclDecor.isEmpty()) {
        functionalDependencies.add(new FunctionalDependency(premiseGby, conclDecor));
    }
    Set<LogicalVariable> gbySet = new HashSet<LogicalVariable>();
    for (Pair<LogicalVariable, Mutable<ILogicalExpression>> p : gByList) {
        ILogicalExpression expr = p.second.getValue();
        if (expr.getExpressionTag() == LogicalExpressionTag.VARIABLE) {
            VariableReferenceExpression v = (VariableReferenceExpression) expr;
            gbySet.add(v.getVariableReference());
        }
    }
    LocalGroupingProperty lgp = new LocalGroupingProperty(gbySet);
    ILocalStructuralProperty normalizedLgp = lgp.normalize(inheritedEcs, inheritedFDs);
    Set<LogicalVariable> normSet = new ListSet<>();
    normalizedLgp.getColumns(normSet);
    List<Pair<LogicalVariable, Mutable<ILogicalExpression>>> newGbyList = new ArrayList<>();
    boolean changed = false;
    for (Pair<LogicalVariable, Mutable<ILogicalExpression>> p : gByList) {
        ILogicalExpression expr = p.second.getValue();
        if (expr.getExpressionTag() == LogicalExpressionTag.VARIABLE) {
            VariableReferenceExpression varRef = (VariableReferenceExpression) expr;
            LogicalVariable v2 = varRef.getVariableReference();
            EquivalenceClass ec2 = inheritedEcs.get(v2);
            LogicalVariable v3;
            if (ec2 != null && !ec2.representativeIsConst()) {
                v3 = ec2.getVariableRepresentative();
            } else {
                v3 = v2;
            }
            if (normSet.contains(v3)) {
                newGbyList.add(p);
            } else {
                changed = true;
                decorList.add(p);
            }
        } else {
            newGbyList.add(p);
        }
    }
    if (changed && AlgebricksConfig.ALGEBRICKS_LOGGER.isTraceEnabled()) {
        AlgebricksConfig.ALGEBRICKS_LOGGER.trace(">>>> Group-by list changed from " + GroupByOperator.veListToString(gByList) + " to " + GroupByOperator.veListToString(newGbyList) + ".\n");
    }
    gByList.clear();
    gByList.addAll(newGbyList);
    return null;
}
#end_block

#method_before
protected void traceWaitsAndBlocks(AbstractWork r, ThreadInfo before) {
    ThreadInfo after = threadMXBean.getThreadInfo(thread.getId());
    final long waitedDelta = after.getWaitedCount() - before.getWaitedCount();
    final long blockedDelta = after.getBlockedCount() - before.getBlockedCount();
    if (waitedDelta > 0 || blockedDelta > 0) {
        LOGGER.trace("Work {} waited {} times (~{}ms), blocked {} times (~{}ms)", r, waitedDelta, (after.getWaitedTime() - before.getWaitedTime()), blockedDelta, (after.getBlockedTime() - before.getBlockedTime()));
    }
}
#method_after
protected void traceWaitsAndBlocks(AbstractWork r, ThreadInfo before) {
    ThreadInfo after = threadMXBean.getThreadInfo(thread.getId());
    final long waitedDelta = after.getWaitedCount() - before.getWaitedCount();
    final long blockedDelta = after.getBlockedCount() - before.getBlockedCount();
    if (waitedDelta > 0 || blockedDelta > 0) {
        LOGGER.trace("Work {} waited {} times (~{}ms), blocked {} times (~{}ms)", r, waitedDelta, after.getWaitedTime() - before.getWaitedTime(), blockedDelta, after.getBlockedTime() - before.getBlockedTime());
    }
}
#end_block

#method_before
@CriticalPath
protected boolean enterComponents(ILSMIndexOperationContext ctx, LSMOperationType opType) throws HyracksDataException {
    validateOperationEnterComponentsState(ctx);
    List<ILSMComponent> components = ctx.getComponentHolder();
    int numEntered = 0;
    boolean entranceSuccessful = false;
    try {
        final int componentsCount = components.size();
        for (int i = 0; i < componentsCount; i++) {
            final ILSMComponent component = components.get(i);
            boolean isMutableComponent = numEntered == 0 && component.getType() == LSMComponentType.MEMORY;
            if (!component.threadEnter(opType, isMutableComponent)) {
                break;
            }
            numEntered++;
        }
        entranceSuccessful = numEntered == components.size();
    } catch (Throwable e) {
        // NOSONAR: Log and re-throw
        if (LOGGER.isWarnEnabled()) {
            LOGGER.warn("{} failed to enter components on {}", opType.name(), lsmIndex, e);
        }
        throw e;
    } finally {
        if (!entranceSuccessful) {
            final int componentsCount = components.size();
            for (int i = 0; i < componentsCount; i++) {
                final ILSMComponent component = components.get(i);
                if (numEntered == 0) {
                    break;
                }
                boolean isMutableComponent = i == 0 && component.getType() == LSMComponentType.MEMORY;
                component.threadExit(opType, true, isMutableComponent);
                numEntered--;
            }
        }
    }
    if (!entranceSuccessful) {
        return false;
    }
    ctx.setAccessingComponents(true);
    opTracker.beforeOperation(lsmIndex, opType, ctx.getSearchOperationCallback(), ctx.getModificationCallback());
    return true;
}
#method_after
@CriticalPath
protected boolean enterComponents(ILSMIndexOperationContext ctx, LSMOperationType opType) throws HyracksDataException {
    validateOperationEnterComponentsState(ctx);
    List<ILSMComponent> components = ctx.getComponentHolder();
    int numEntered = 0;
    boolean entranceSuccessful = false;
    try {
        final int componentsCount = components.size();
        for (int i = 0; i < componentsCount; i++) {
            final ILSMComponent component = components.get(i);
            boolean isMutableComponent = numEntered == 0 && component.getType() == LSMComponentType.MEMORY;
            if (!component.threadEnter(opType, isMutableComponent)) {
                break;
            }
            numEntered++;
        }
        entranceSuccessful = numEntered == components.size();
    } catch (Throwable e) {
        // NOSONAR: Log and re-throw
        LOGGER.warn("{} failed to enter components on {}", opType.name(), lsmIndex, e);
        throw e;
    } finally {
        if (!entranceSuccessful) {
            final int componentsCount = components.size();
            for (int i = 0; i < componentsCount; i++) {
                final ILSMComponent component = components.get(i);
                if (numEntered == 0) {
                    break;
                }
                boolean isMutableComponent = i == 0 && component.getType() == LSMComponentType.MEMORY;
                component.threadExit(opType, true, isMutableComponent);
                numEntered--;
            }
        }
    }
    if (!entranceSuccessful) {
        return false;
    }
    ctx.setAccessingComponents(true);
    opTracker.beforeOperation(lsmIndex, opType, ctx.getSearchOperationCallback(), ctx.getModificationCallback());
    return true;
}
#end_block

#method_before
@CriticalPath
private void doExitComponents(ILSMIndexOperationContext ctx, LSMOperationType opType, ILSMDiskComponent newComponent, boolean failedOperation) throws HyracksDataException {
    /*
         * FLUSH and MERGE operations should always exit the components
         * to notify waiting threads.
         */
    if (!ctx.isAccessingComponents() && opType != LSMOperationType.FLUSH && opType != LSMOperationType.MERGE) {
        return;
    }
    List<ILSMDiskComponent> inactiveDiskComponents;
    List<ILSMDiskComponent> inactiveDiskComponentsToBeDeleted = null;
    try {
        synchronized (opTracker) {
            try {
                /*
                     * [flow control]
                     * If merge operations are lagged according to the merge policy,
                     * flushing in-memory components are hold until the merge operation catches up.
                     * See PrefixMergePolicy.isMergeLagging() for more details.
                     */
                if (opType == LSMOperationType.FLUSH) {
                    opTracker.notifyAll();
                    if (!failedOperation) {
                        waitForLaggingMerge();
                    }
                } else if (opType == LSMOperationType.MERGE) {
                    opTracker.notifyAll();
                }
                exitOperationalComponents(ctx, opType, failedOperation);
                ctx.setAccessingComponents(false);
                exitOperation(ctx, opType, newComponent, failedOperation);
            } catch (Throwable e) {
                // NOSONAR: Log and re-throw
                if (LOGGER.isWarnEnabled()) {
                    LOGGER.warn(e.getMessage(), e);
                }
                throw e;
            } finally {
                if (failedOperation && (opType == LSMOperationType.MODIFICATION || opType == LSMOperationType.FORCE_MODIFICATION)) {
                    // When the operation failed, completeOperation() method must be called
                    // in order to decrement active operation count which was incremented
                    // in beforeOperation() method.
                    opTracker.completeOperation(lsmIndex, opType, ctx.getSearchOperationCallback(), ctx.getModificationCallback());
                } else {
                    opTracker.afterOperation(lsmIndex, opType, ctx.getSearchOperationCallback(), ctx.getModificationCallback());
                }
                /*
                     * = Inactive disk components lazy cleanup if any =
                     * Prepare to cleanup inactive diskComponents which were old merged components
                     * and not anymore accessed.
                     * This cleanup is done outside of optracker synchronized block.
                     */
                inactiveDiskComponents = lsmIndex.getInactiveDiskComponents();
                if (!inactiveDiskComponents.isEmpty()) {
                    for (ILSMDiskComponent inactiveComp : inactiveDiskComponents) {
                        if (inactiveComp.getFileReferenceCount() == 1) {
                            inactiveDiskComponentsToBeDeleted = inactiveDiskComponentsToBeDeleted == null ? new LinkedList<>() : inactiveDiskComponentsToBeDeleted;
                            inactiveDiskComponentsToBeDeleted.add(inactiveComp);
                        }
                    }
                    if (inactiveDiskComponentsToBeDeleted != null) {
                        inactiveDiskComponents.removeAll(inactiveDiskComponentsToBeDeleted);
                    }
                }
            }
        }
    } finally {
        /*
             * cleanup inactive disk components if any
             */
        if (inactiveDiskComponentsToBeDeleted != null) {
            try {
                // schedule a replication job to delete these inactive disk components from replicas
                if (replicationEnabled) {
                    lsmIndex.scheduleReplication(null, inactiveDiskComponentsToBeDeleted, ReplicationOperation.DELETE, opType);
                }
                for (ILSMDiskComponent c : inactiveDiskComponentsToBeDeleted) {
                    c.deactivateAndDestroy();
                }
            } catch (Throwable e) {
                // NOSONAR Log and re-throw
                if (LOGGER.isWarnEnabled()) {
                    LOGGER.log(Level.WARN, "Failure scheduling replication or destroying merged component", e);
                }
                // NOSONAR: The last call in the finally clause
                throw e;
            }
        }
    }
}
#method_after
@CriticalPath
private void doExitComponents(ILSMIndexOperationContext ctx, LSMOperationType opType, ILSMDiskComponent newComponent, boolean failedOperation) throws HyracksDataException {
    /*
         * FLUSH and MERGE operations should always exit the components
         * to notify waiting threads.
         */
    if (!ctx.isAccessingComponents() && opType != LSMOperationType.FLUSH && opType != LSMOperationType.MERGE) {
        return;
    }
    List<ILSMDiskComponent> inactiveDiskComponents;
    List<ILSMDiskComponent> inactiveDiskComponentsToBeDeleted = null;
    try {
        synchronized (opTracker) {
            try {
                /*
                     * [flow control]
                     * If merge operations are lagged according to the merge policy,
                     * flushing in-memory components are hold until the merge operation catches up.
                     * See PrefixMergePolicy.isMergeLagging() for more details.
                     */
                if (opType == LSMOperationType.FLUSH) {
                    opTracker.notifyAll();
                    if (!failedOperation) {
                        waitForLaggingMerge();
                    }
                } else if (opType == LSMOperationType.MERGE) {
                    opTracker.notifyAll();
                }
                exitOperationalComponents(ctx, opType, failedOperation);
                ctx.setAccessingComponents(false);
                exitOperation(ctx, opType, newComponent, failedOperation);
            } catch (Throwable e) {
                // NOSONAR: Log and re-throw
                LOGGER.warn("Failure exiting components", e);
                throw e;
            } finally {
                if (failedOperation && (opType == LSMOperationType.MODIFICATION || opType == LSMOperationType.FORCE_MODIFICATION)) {
                    // When the operation failed, completeOperation() method must be called
                    // in order to decrement active operation count which was incremented
                    // in beforeOperation() method.
                    opTracker.completeOperation(lsmIndex, opType, ctx.getSearchOperationCallback(), ctx.getModificationCallback());
                } else {
                    opTracker.afterOperation(lsmIndex, opType, ctx.getSearchOperationCallback(), ctx.getModificationCallback());
                }
                /*
                     * = Inactive disk components lazy cleanup if any =
                     * Prepare to cleanup inactive diskComponents which were old merged components
                     * and not anymore accessed.
                     * This cleanup is done outside of optracker synchronized block.
                     */
                inactiveDiskComponents = lsmIndex.getInactiveDiskComponents();
                if (!inactiveDiskComponents.isEmpty()) {
                    for (ILSMDiskComponent inactiveComp : inactiveDiskComponents) {
                        if (inactiveComp.getFileReferenceCount() == 1) {
                            inactiveDiskComponentsToBeDeleted = inactiveDiskComponentsToBeDeleted == null ? new LinkedList<>() : inactiveDiskComponentsToBeDeleted;
                            inactiveDiskComponentsToBeDeleted.add(inactiveComp);
                        }
                    }
                    if (inactiveDiskComponentsToBeDeleted != null) {
                        inactiveDiskComponents.removeAll(inactiveDiskComponentsToBeDeleted);
                    }
                }
            }
        }
    } finally {
        /*
             * cleanup inactive disk components if any
             */
        if (inactiveDiskComponentsToBeDeleted != null) {
            try {
                // schedule a replication job to delete these inactive disk components from replicas
                if (replicationEnabled) {
                    lsmIndex.scheduleReplication(null, inactiveDiskComponentsToBeDeleted, ReplicationOperation.DELETE, opType);
                }
                for (ILSMDiskComponent c : inactiveDiskComponentsToBeDeleted) {
                    c.deactivateAndDestroy();
                }
            } catch (Throwable e) {
                // NOSONAR Log and re-throw
                if (LOGGER.isWarnEnabled()) {
                    LOGGER.log(Level.WARN, "Failure scheduling replication or destroying merged component", e);
                }
                // NOSONAR: The last call in the finally clause
                throw e;
            }
        }
    }
}
#end_block

#method_before
@Override
public void batchOperate(ILSMIndexOperationContext ctx, FrameTupleAccessor accessor, FrameTupleReference tuple, IFrameTupleProcessor processor, IFrameOperationCallback frameOpCallback) throws HyracksDataException {
    processor.start();
    enter(ctx);
    try {
        try {
            processFrame(accessor, tuple, processor);
            frameOpCallback.frameCompleted();
        } finally {
            processor.finish();
        }
    } catch (HyracksDataException e) {
        if (LOGGER.isWarnEnabled()) {
            LOGGER.warn("Failed to process frame", e);
        }
        throw e;
    } finally {
        exit(ctx);
        ctx.logPerformanceCounters(accessor.getTupleCount());
    }
}
#method_after
@Override
public void batchOperate(ILSMIndexOperationContext ctx, FrameTupleAccessor accessor, FrameTupleReference tuple, IFrameTupleProcessor processor, IFrameOperationCallback frameOpCallback) throws HyracksDataException {
    processor.start();
    enter(ctx);
    try {
        try {
            processFrame(accessor, tuple, processor);
            frameOpCallback.frameCompleted();
        } finally {
            processor.finish();
        }
    } catch (HyracksDataException e) {
        LOGGER.warn("Failed to process frame", e);
        throw e;
    } finally {
        exit(ctx);
        ctx.logPerformanceCounters(accessor.getTupleCount());
    }
}
#end_block

#method_before
@Override
public IGatekeeper getGatekeeper() {
    return configManager.getAppConfig().getNCNames()::contains;
}
#method_after
@Override
public IGatekeeper getGatekeeper() {
    return node -> true;
}
#end_block

#method_before
@Override
public synchronized void addNode(String nodeId, NodeControllerState ncState) throws HyracksException {
    LOGGER.warn("+addNode: " + nodeId);
    if (nodeId == null || ncState == null) {
        throw HyracksException.create(ErrorCode.INVALID_INPUT_PARAMETER);
    }
    if (!gatekeeper.isAuthorized(nodeId)) {
        throw HyracksException.create(ErrorCode.NO_SUCH_NODE, nodeId);
    }
    // Updates the node registry.
    if (nodeRegistry.containsKey(nodeId)) {
        LOGGER.warn("Node '" + nodeId + "' is already registered; failing the node then re-registering.");
        failNode(nodeId);
    }
    try {
        ncState.getNodeController().abortJobs(ccs.getCcId());
    } catch (IPCException e) {
        throw HyracksDataException.create(e);
    }
    LOGGER.info("adding node to registry");
    nodeRegistry.put(nodeId, ncState);
    // Updates the IP address to node names map.
    try {
        InetAddress ipAddress = getIpAddress(ncState);
        Set<String> nodes = ipAddressNodeNameMap.computeIfAbsent(ipAddress, k -> new HashSet<>());
        nodes.add(nodeId);
    } catch (HyracksException e) {
        // If anything fails, we ignore the node.
        nodeRegistry.remove(nodeId);
        throw e;
    }
    // info the cluster capacity.
    LOGGER.info("updating cluster capacity");
    resourceManager.update(nodeId, getAdjustedNodeCapacity(ncState.getCapacity()));
}
#method_after
@Override
public synchronized void addNode(String nodeId, NodeControllerState ncState) throws HyracksException {
    LOGGER.warn("+addNode: " + nodeId);
    if (nodeId == null || ncState == null) {
        throw HyracksException.create(ErrorCode.INVALID_INPUT_PARAMETER);
    }
    if (!gatekeeper.isAuthorized(nodeId)) {
        throw HyracksException.create(ErrorCode.NO_SUCH_NODE, nodeId);
    }
    // Updates the node registry.
    if (nodeRegistry.containsKey(nodeId)) {
        LOGGER.warn("Node '" + nodeId + "' is already registered; failing the node then re-registering.");
        failNode(nodeId);
    }
    try {
        ncState.getNodeController().abortJobs(ccs.getCcId());
    } catch (IPCException e) {
        throw HyracksDataException.create(e);
    }
    LOGGER.info("adding node to registry");
    nodeRegistry.put(nodeId, ncState);
    // Updates the IP address to node names map.
    try {
        InetAddress ipAddress = getIpAddress(ncState);
        Set<String> nodes = ipAddressNodeNameMap.computeIfAbsent(ipAddress, k -> new HashSet<>());
        nodes.add(nodeId);
    } catch (HyracksException e) {
        // If anything fails, we ignore the node.
        nodeRegistry.remove(nodeId);
        throw e;
    }
    LOGGER.info("updating cluster capacity");
    resourceManager.update(nodeId, getAdjustedNodeCapacity(ncState.getCapacity()));
}
#end_block

#method_before
private void runInParallel(OperatorNodePushableAction action) throws HyracksDataException {
    List<Future<Void>> tasks = new ArrayList<>(operatorNodePushablesBFSOrder.size());
    Queue<Throwable> failures = new ArrayBlockingQueue<>(operatorNodePushablesBFSOrder.size());
    final Semaphore startSemaphore = new Semaphore(1 - operatorNodePushablesBFSOrder.size());
    final Semaphore completeSemaphore = new Semaphore(1 - operatorNodePushablesBFSOrder.size());
    Throwable root = null;
    try {
        for (final IOperatorNodePushable op : operatorNodePushablesBFSOrder) {
            tasks.add(ctx.getExecutorService().submit(() -> {
                final String nameBefore = Thread.currentThread().getName();
                startSemaphore.release();
                try {
                    Thread.currentThread().setName(nameBefore + ":" + ctx.getJobletContext().getJobId() + ":" + ctx.getTaskAttemptId() + ":" + SuperActivityOperatorNodePushable.class.getSimpleName());
                    action.run(op);
                } catch (Throwable th) {
                    // NOSONAR: Must catch all causes of failure
                    failures.offer(th);
                    throw th;
                } finally {
                    completeSemaphore.release();
                    Thread.currentThread().setName(nameBefore);
                }
                return null;
            }));
        }
        for (Future<Void> task : tasks) {
            task.get();
        }
    } catch (ExecutionException e) {
        root = e.getCause();
    } catch (Throwable e) {
        // NOSONAR: Must catch all causes of failure
        root = e;
    }
    if (root != null) {
        final Throwable failure = root;
        cancelTasks(tasks, startSemaphore, completeSemaphore);
        failures.forEach(t -> ExceptionUtils.suppress(failure, t));
        throw HyracksDataException.create(failure);
    }
}
#method_after
private void runInParallel(OperatorNodePushableAction action) throws HyracksDataException {
    List<Future<Void>> tasks = new ArrayList<>(operatorNodePushablesBFSOrder.size());
    Queue<Throwable> failures = new ArrayBlockingQueue<>(operatorNodePushablesBFSOrder.size());
    final Semaphore startSemaphore = new Semaphore(1 - operatorNodePushablesBFSOrder.size());
    final Semaphore completeSemaphore = new Semaphore(1 - operatorNodePushablesBFSOrder.size());
    Throwable root = null;
    try {
        for (final IOperatorNodePushable op : operatorNodePushablesBFSOrder) {
            tasks.add(ctx.getExecutorService().submit(() -> {
                startSemaphore.release();
                try {
                    Thread.currentThread().setName(Thread.currentThread().getName() + ":" + ctx.getJobletContext().getJobId() + ":" + ctx.getTaskAttemptId() + ":" + SuperActivityOperatorNodePushable.class.getSimpleName());
                    action.run(op);
                } catch (Throwable th) {
                    // NOSONAR: Must catch all causes of failure
                    failures.offer(th);
                    throw th;
                } finally {
                    completeSemaphore.release();
                }
                return null;
            }));
        }
        for (Future<Void> task : tasks) {
            task.get();
        }
    } catch (ExecutionException e) {
        root = e.getCause();
    } catch (Throwable e) {
        // NOSONAR: Must catch all causes of failure
        root = e;
    }
    if (root != null) {
        final Throwable failure = root;
        cancelTasks(tasks, startSemaphore, completeSemaphore);
        failures.forEach(t -> ExceptionUtils.suppress(failure, t));
        throw HyracksDataException.create(failure);
    }
}
#end_block

#method_before
@Override
protected void doRun() throws Exception {
    IJobManager jobManager = ccs.getJobManager();
    final JobRun jobRun = jobManager.get(jobId);
    if (jobRun != null) {
        ccs.getExecutor().execute(new Runnable() {

            @Override
            public void run() {
                String nameBefore = Thread.currentThread().getName();
                try {
                    Thread.currentThread().setName(nameBefore + " : WaitForCompletionForJobId: " + jobId);
                    jobRun.waitForCompletion();
                    callback.setValue(null);
                } catch (Exception e) {
                    callback.setException(e);
                } finally {
                    Thread.currentThread().setName(nameBefore);
                }
            }
        });
    } else {
        // Couldn't find jobRun
        List<Exception> exceptionHistory = jobManager.getExceptionHistory(jobId);
        List<Exception> exceptions;
        if (exceptionHistory == null) {
            // couldn't be found
            exceptions = Collections.singletonList(HyracksDataException.create(ErrorCode.JOB_HAS_BEEN_CLEARED_FROM_HISTORY, jobId));
        } else {
            exceptions = exceptionHistory;
        }
        ccs.getExecutor().execute(() -> {
            if (!exceptions.isEmpty()) {
                /*
                     * only report the first exception because IResultCallback will only throw one exception
                     * anyway
                     */
                callback.setException(exceptions.get(0));
            } else {
                callback.setValue(null);
            }
        });
    }
}
#method_after
@Override
protected void doRun() throws Exception {
    IJobManager jobManager = ccs.getJobManager();
    final JobRun jobRun = jobManager.get(jobId);
    if (jobRun != null) {
        ccs.getExecutor().execute(new Runnable() {

            @Override
            public void run() {
                try {
                    Thread.currentThread().setName(Thread.currentThread().getName() + " : WaitForCompletionForJobId: " + jobId);
                    jobRun.waitForCompletion();
                    callback.setValue(null);
                } catch (Exception e) {
                    callback.setException(e);
                }
            }
        });
    } else {
        // Couldn't find jobRun
        List<Exception> exceptionHistory = jobManager.getExceptionHistory(jobId);
        List<Exception> exceptions;
        if (exceptionHistory == null) {
            // couldn't be found
            exceptions = Collections.singletonList(HyracksDataException.create(ErrorCode.JOB_HAS_BEEN_CLEARED_FROM_HISTORY, jobId));
        } else {
            exceptions = exceptionHistory;
        }
        ccs.getExecutor().execute(() -> {
            if (!exceptions.isEmpty()) {
                /*
                     * only report the first exception because IResultCallback will only throw one exception
                     * anyway
                     */
                callback.setException(exceptions.get(0));
            } else {
                callback.setValue(null);
            }
        });
    }
}
#end_block

#method_before
@Override
public void run() {
    try {
        ncs.getClusterController(ccId).notifyPingResponse(ncs.getId());
    } catch (Exception e) {
        LOGGER.debug("failed to respond to ping from cc {}", ccId, e);
    }
}
#method_after
@Override
public void run() {
    try {
        ncs.getClusterController(ccId).notifyPingResponse(ncs.getId());
    } catch (Exception e) {
        LOGGER.info("failed to respond to ping from cc {}", ccId, e);
    }
}
#end_block

#method_before
@Override
public void start() throws Exception {
    LOGGER.log(Level.INFO, "Starting NodeControllerService");
    ipc = new IPCSystem(new InetSocketAddress(ncConfig.getClusterListenAddress(), ncConfig.getClusterListenPort()), new NodeControllerIPCI(this), new CCNCFunctions.SerializerDeserializer());
    ipc.start();
    partitionManager = new PartitionManager(this);
    netManager = new NetworkManager(ncConfig.getDataListenAddress(), ncConfig.getDataListenPort(), partitionManager, ncConfig.getNetThreadCount(), ncConfig.getNetBufferCount(), ncConfig.getDataPublicAddress(), ncConfig.getDataPublicPort(), FullFrameChannelInterfaceFactory.INSTANCE);
    netManager.start();
    startApplication();
    init();
    resultNetworkManager.start();
    if (messagingNetManager != null) {
        messagingNetManager.start();
    }
    initNodeControllerState();
    workQueue.start();
    hbTask = new HeartbeatComputeTask(this);
    primaryCcId = addCc(new InetSocketAddress(ncConfig.getClusterAddress(), ncConfig.getClusterPort()));
    // Schedule heartbeat data updates
    timer.schedule(hbTask, HEARTBEAT_REFRESH_MILLIS, HEARTBEAT_REFRESH_MILLIS);
    // Schedule tracing a human-readable datetime
    timer.schedule(new TraceCurrentTimeTask(serviceCtx.getTracer()), 0, 60000);
    LOGGER.log(Level.INFO, "Started NodeControllerService");
    application.startupCompleted();
}
#method_after
@Override
public void start() throws Exception {
    LOGGER.log(Level.INFO, "Starting NodeControllerService");
    ipc = new IPCSystem(new InetSocketAddress(ncConfig.getClusterListenAddress(), ncConfig.getClusterListenPort()), new NodeControllerIPCI(this), new CCNCFunctions.SerializerDeserializer());
    ipc.start();
    partitionManager = new PartitionManager(this);
    netManager = new NetworkManager(ncConfig.getDataListenAddress(), ncConfig.getDataListenPort(), partitionManager, ncConfig.getNetThreadCount(), ncConfig.getNetBufferCount(), ncConfig.getDataPublicAddress(), ncConfig.getDataPublicPort(), FullFrameChannelInterfaceFactory.INSTANCE);
    netManager.start();
    startApplication();
    init();
    resultNetworkManager.start();
    if (messagingNetManager != null) {
        messagingNetManager.start();
    }
    initNodeControllerState();
    hbTask = new HeartbeatComputeTask(this);
    primaryCcId = addCc(new InetSocketAddress(ncConfig.getClusterAddress(), ncConfig.getClusterPort()));
    workQueue.start();
    // Schedule heartbeat data updates
    timer.schedule(hbTask, HEARTBEAT_REFRESH_MILLIS, HEARTBEAT_REFRESH_MILLIS);
    // Schedule tracing a human-readable datetime
    timer.schedule(new TraceCurrentTimeTask(serviceCtx.getTracer()), 0, 60000);
    LOGGER.log(Level.INFO, "Started NodeControllerService");
    application.startupCompleted();
}
#end_block

#method_before
public void removeCc(InetSocketAddress ccAddress) throws Exception {
    synchronized (ccLock) {
        LOGGER.info("removeCc: {}", ccAddress);
        if (ccAddress.isUnresolved()) {
            throw new IllegalArgumentException("must use resolved InetSocketAddress");
        }
        CcId ccId = ccAddressMap.get(ccAddress);
        if (ccId == null) {
            LOGGER.warn("ignoring request to remove unknown cc: {}", ccAddress);
            return;
        }
        if (primaryCcId.equals(ccId)) {
            throw new IllegalStateException("cannot remove primary cc: " + ccAddress);
        }
        try {
            final CcConnection ccc = getCcConnection(ccId);
            ccc.getClusterControllerService().unregisterNode(id);
        } catch (Exception e) {
            LOGGER.warn("ignoring exception trying to gracefully unregister cc {}: ", () -> ccId, () -> String.valueOf(e));
        }
        workQueue.scheduleAndSync(new AbortAllJobsWork(this, ccId, -1));
        Thread hbThread = heartbeatThreads.remove(ccId);
        hbThread.interrupt();
        Timer ccTimer = ccTimers.remove(ccId);
        if (ccTimer != null) {
            ccTimer.cancel();
        }
        ccMap.remove(ccId);
        ccAddressMap.remove(ccAddress);
    }
}
#method_after
public void removeCc(InetSocketAddress ccAddress) throws Exception {
    synchronized (ccLock) {
        LOGGER.info("removeCc: {}", ccAddress);
        if (ccAddress.isUnresolved()) {
            throw new IllegalArgumentException("must use resolved InetSocketAddress");
        }
        CcId ccId = ccAddressMap.get(ccAddress);
        if (ccId == null) {
            LOGGER.warn("ignoring request to remove unknown cc: {}", ccAddress);
            return;
        }
        if (primaryCcId.equals(ccId)) {
            throw new IllegalStateException("cannot remove primary cc: " + ccAddress);
        }
        try {
            final CcConnection ccc = getCcConnection(ccId);
            ccc.getClusterControllerService().unregisterNode(id);
        } catch (Exception e) {
            LOGGER.warn("ignoring exception trying to gracefully unregister cc {}: ", () -> ccId, () -> String.valueOf(e));
        }
        getWorkQueue().scheduleAndSync(new AbortAllJobsWork(this, ccId));
        Thread hbThread = heartbeatThreads.remove(ccId);
        hbThread.interrupt();
        Timer ccTimer = ccTimers.remove(ccId);
        if (ccTimer != null) {
            ccTimer.cancel();
        }
        ccMap.remove(ccId);
        ccAddressMap.remove(ccAddress);
    }
}
#end_block

#method_before
public CcId registerNode(CcConnection ccc, InetSocketAddress ccAddress) throws Exception {
    LOGGER.info("Registering with Cluster Controller {}", ccc);
    int registrationId = nextRegistrationId.incrementAndGet();
    pendingRegistrations.put(registrationId, ccc);
    CcId ccId = ccc.registerNode(nodeRegistration, registrationId);
    ccMap.put(ccId, ccc);
    ccAddressMap.put(ccAddress, ccId);
    Serializable distributedState = ccc.getNodeParameters().getDistributedState();
    if (distributedState != null) {
        getDistributedState().put(ccId, distributedState);
    }
    IClusterController ccs = ccc.getClusterControllerService();
    NodeParameters nodeParameters = ccc.getNodeParameters();
    // Start heartbeat generator.
    if (!heartbeatThreads.containsKey(ccId)) {
        Thread heartbeatThread = new Thread(new HeartbeatTask(getId(), hbTask.getHeartbeatData(), ccs, nodeParameters.getHeartbeatPeriod()), id + "-Heartbeat");
        heartbeatThread.setPriority(Thread.MAX_PRIORITY);
        heartbeatThread.setDaemon(true);
        heartbeatThread.start();
        heartbeatThreads.put(ccId, heartbeatThread);
    }
    if (!ccTimers.containsKey(ccId) && nodeParameters.getProfileDumpPeriod() > 0) {
        Timer ccTimer = new Timer("Timer-" + ccId, true);
        // Schedule profile dump generator.
        ccTimer.schedule(new ProfileDumpTask(ccs, ccId), 0, nodeParameters.getProfileDumpPeriod());
        ccTimers.put(ccId, ccTimer);
    }
    ccc.notifyRegistrationCompleted();
    application.nodeRegistered(ccId);
    LOGGER.info("Registering with Cluster Controller {} completed", ccc);
    return ccId;
}
#method_after
public CcId registerNode(CcConnection ccc, InetSocketAddress ccAddress) throws Exception {
    LOGGER.info("Registering with Cluster Controller {}", ccc);
    int registrationId = nextRegistrationId.incrementAndGet();
    pendingRegistrations.put(registrationId, ccc);
    CcId ccId = ccc.registerNode(nodeRegistration, registrationId);
    ccMap.put(ccId, ccc);
    ccAddressMap.put(ccAddress, ccId);
    Serializable distributedState = ccc.getNodeParameters().getDistributedState();
    if (distributedState != null) {
        getDistributedState().put(ccId, distributedState);
    }
    IClusterController ccs = ccc.getClusterControllerService();
    NodeParameters nodeParameters = ccc.getNodeParameters();
    // Start heartbeat generator.
    if (!heartbeatThreads.containsKey(ccId)) {
        Thread heartbeatThread = new Thread(new HeartbeatTask(getId(), hbTask.getHeartbeatData(), ccs, nodeParameters.getHeartbeatPeriod()), id + "-Heartbeat");
        heartbeatThread.setPriority(Thread.MAX_PRIORITY);
        heartbeatThread.setDaemon(true);
        heartbeatThread.start();
        heartbeatThreads.put(ccId, heartbeatThread);
    }
    if (!ccTimers.containsKey(ccId) && nodeParameters.getProfileDumpPeriod() > 0) {
        Timer ccTimer = new Timer("Timer-" + ccId, true);
        // Schedule profile dump generator.
        ccTimer.schedule(new ProfileDumpTask(ccs, ccId), 0, nodeParameters.getProfileDumpPeriod());
        ccTimers.put(ccId, ccTimer);
    }
    ccc.notifyRegistrationCompleted();
    LOGGER.info("Registering with Cluster Controller {} completed", ccc);
    return ccId;
}
#end_block

#method_before
public void notifyTasksCompleted(CcId ccId, int registrationId) {
    partitionManager.jobsCompleted(ccId);
    if (pendingRegistrations.containsKey(registrationId)) {
        final CcConnection ccConnection = pendingRegistrations.get(registrationId);
        ccConnection.notifyTasksCompleted();
    } else {
        LOGGER.warn("Ignoring tasks completed notification for CC {} with registration id", ccId, registrationId);
    }
}
#method_after
public void notifyTasksCompleted(CcId ccId) throws Exception {
    partitionManager.jobsCompleted(ccId);
    application.tasksCompleted(ccId);
}
#end_block

#method_before
private void appendUpsertIndicator(boolean isUpsert) throws IOException {
    if (!isUpsert) {
        System.out.println();
    }
    recordDesc.getFields()[0].serialize(isUpsert ? ABoolean.TRUE : ABoolean.FALSE, dos);
    tb.addFieldEndOffset();
}
#method_after
private void appendUpsertIndicator(boolean isUpsert) throws IOException {
    recordDesc.getFields()[0].serialize(isUpsert ? ABoolean.TRUE : ABoolean.FALSE, dos);
    tb.addFieldEndOffset();
}
#end_block

#method_before
@Override
public void open() throws HyracksDataException {
    super.open();
    abstractModCallback = (AbstractIndexModificationOperationCallback) modCallback;
}
#method_after
@Override
public void open() throws HyracksDataException {
    super.open();
    frameTuple = new FrameTupleReference();
    abstractModCallback = (AbstractIndexModificationOperationCallback) modCallback;
}
#end_block

#method_before
@Override
public boolean acceptExpressionTransform(ILogicalExpressionReferenceTransform visitor) throws AlgebricksException {
    boolean b = false;
    // Primary
    for (int i = 0; i < primaryKeyExprs.size(); i++) {
        if (visitor.transform(primaryKeyExprs.get(i))) {
            b = true;
        }
    }
    // Secondary
    for (int i = 0; i < secondaryKeyExprs.size(); i++) {
        if (visitor.transform(secondaryKeyExprs.get(i))) {
            b = true;
        }
    }
    // Additional Filtering <For upsert>
    if (additionalFilteringExpressions != null) {
        for (int i = 0; i < additionalFilteringExpressions.size(); i++) {
            if (visitor.transform(additionalFilteringExpressions.get(i))) {
                b = true;
            }
        }
    }
    // Old secondary <For upsert>
    if (prevSecondaryKeyExprs != null) {
        for (int i = 0; i < prevSecondaryKeyExprs.size(); i++) {
            if (visitor.transform(prevSecondaryKeyExprs.get(i))) {
                b = true;
            }
        }
    }
    // Old Filtering <For upsert>
    if (prevAdditionalFilteringExpression != null) {
        visitor.transform(prevAdditionalFilteringExpression);
    }
    return b;
}
#method_after
@Override
public boolean acceptExpressionTransform(ILogicalExpressionReferenceTransform visitor) throws AlgebricksException {
    boolean b = false;
    // Primary
    for (int i = 0; i < primaryKeyExprs.size(); i++) {
        if (visitor.transform(primaryKeyExprs.get(i))) {
            b = true;
        }
    }
    // Secondary
    for (int i = 0; i < secondaryKeyExprs.size(); i++) {
        if (visitor.transform(secondaryKeyExprs.get(i))) {
            b = true;
        }
    }
    // Additional Filtering <For upsert>
    if (additionalFilteringExpressions != null) {
        for (int i = 0; i < additionalFilteringExpressions.size(); i++) {
            if (visitor.transform(additionalFilteringExpressions.get(i))) {
                b = true;
            }
        }
    }
    // Upsert indicator var <For upsert>
    if (upsertIndicatorExpr != null && visitor.transform(upsertIndicatorExpr)) {
        b = true;
    }
    // Old secondary <For upsert>
    if (prevSecondaryKeyExprs != null) {
        for (int i = 0; i < prevSecondaryKeyExprs.size(); i++) {
            if (visitor.transform(prevSecondaryKeyExprs.get(i))) {
                b = true;
            }
        }
    }
    // Old Filtering <For upsert>
    if (prevAdditionalFilteringExpression != null) {
        visitor.transform(prevAdditionalFilteringExpression);
    }
    return b;
}
#end_block

#method_before
@SuppressWarnings({ "unchecked", "rawtypes" })
private static void computeDefaultPhysicalOp(AbstractLogicalOperator op, boolean topLevelOp, IOptimizationContext context) throws AlgebricksException {
    PhysicalOptimizationConfig physicalOptimizationConfig = context.getPhysicalOptimizationConfig();
    if (op.getPhysicalOperator() == null) {
        switch(op.getOperatorTag()) {
            case AGGREGATE:
                {
                    op.setPhysicalOperator(new AggregatePOperator());
                    break;
                }
            case ASSIGN:
                {
                    op.setPhysicalOperator(new AssignPOperator());
                    break;
                }
            case DISTINCT:
                {
                    DistinctOperator distinct = (DistinctOperator) op;
                    if (topLevelOp) {
                        distinct.setPhysicalOperator(new PreSortedDistinctByPOperator(distinct.getDistinctByVarList()));
                    } else {
                        distinct.setPhysicalOperator(new MicroPreSortedDistinctByPOperator(distinct.getDistinctByVarList()));
                    }
                    break;
                }
            case EMPTYTUPLESOURCE:
                {
                    op.setPhysicalOperator(new EmptyTupleSourcePOperator());
                    break;
                }
            case EXCHANGE:
                {
                    if (op.getPhysicalOperator() == null) {
                        throw new AlgebricksException("Implementation for EXCHANGE operator was not set.");
                    }
                    // implem. choice for exchange should be set by a parent op.
                    break;
                }
            case GROUP:
                {
                    GroupByOperator gby = (GroupByOperator) op;
                    if (gby.getNestedPlans().size() == 1) {
                        ILogicalPlan p0 = gby.getNestedPlans().get(0);
                        if (p0.getRoots().size() == 1) {
                            if ((gby.getAnnotations().get(OperatorAnnotations.USE_HASH_GROUP_BY) == Boolean.TRUE) || (gby.getAnnotations().get(OperatorAnnotations.USE_EXTERNAL_GROUP_BY) == Boolean.TRUE)) {
                                if (!topLevelOp) {
                                    throw new NotImplementedException("External hash group-by for nested grouping is not implemented.");
                                }
                                boolean hasIntermediateAgg = generateMergeAggregationExpressions(gby, context);
                                if (hasIntermediateAgg) {
                                    ExternalGroupByPOperator externalGby = new ExternalGroupByPOperator(gby.getGroupByList(), physicalOptimizationConfig.getMaxFramesForGroupBy(), (long) physicalOptimizationConfig.getMaxFramesForGroupBy() * physicalOptimizationConfig.getFrameSize());
                                    op.setPhysicalOperator(externalGby);
                                    break;
                                }
                            }
                        }
                    }
                    List<Pair<LogicalVariable, Mutable<ILogicalExpression>>> gbyList = gby.getGroupByList();
                    List<LogicalVariable> columnList = new ArrayList<LogicalVariable>(gbyList.size());
                    for (Pair<LogicalVariable, Mutable<ILogicalExpression>> p : gbyList) {
                        ILogicalExpression expr = p.second.getValue();
                        if (expr.getExpressionTag() == LogicalExpressionTag.VARIABLE) {
                            VariableReferenceExpression varRef = (VariableReferenceExpression) expr;
                            columnList.add(varRef.getVariableReference());
                        }
                    }
                    if (topLevelOp) {
                        op.setPhysicalOperator(new PreclusteredGroupByPOperator(columnList, gby.isGroupAll(), context.getPhysicalOptimizationConfig().getMaxFramesForGroupBy()));
                    } else {
                        op.setPhysicalOperator(new MicroPreclusteredGroupByPOperator(columnList));
                    }
                    break;
                }
            case INNERJOIN:
                {
                    JoinUtils.setJoinAlgorithmAndExchangeAlgo((InnerJoinOperator) op, topLevelOp, context);
                    break;
                }
            case LEFTOUTERJOIN:
                {
                    JoinUtils.setJoinAlgorithmAndExchangeAlgo((LeftOuterJoinOperator) op, topLevelOp, context);
                    break;
                }
            case LIMIT:
                {
                    op.setPhysicalOperator(new StreamLimitPOperator());
                    break;
                }
            case NESTEDTUPLESOURCE:
                {
                    op.setPhysicalOperator(new NestedTupleSourcePOperator());
                    break;
                }
            case ORDER:
                {
                    OrderOperator oo = (OrderOperator) op;
                    for (Pair<IOrder, Mutable<ILogicalExpression>> p : oo.getOrderExpressions()) {
                        ILogicalExpression e = p.second.getValue();
                        if (e.getExpressionTag() != LogicalExpressionTag.VARIABLE) {
                            throw new AlgebricksException("Order expression " + e + " has not been normalized.");
                        }
                    }
                    if (topLevelOp) {
                        op.setPhysicalOperator(new StableSortPOperator(physicalOptimizationConfig.getMaxFramesExternalSort(), oo.getTopK()));
                    } else {
                        op.setPhysicalOperator(new InMemoryStableSortPOperator());
                    }
                    break;
                }
            case PROJECT:
                {
                    op.setPhysicalOperator(new StreamProjectPOperator());
                    break;
                }
            case RUNNINGAGGREGATE:
                {
                    op.setPhysicalOperator(new RunningAggregatePOperator());
                    break;
                }
            case REPLICATE:
                {
                    op.setPhysicalOperator(new ReplicatePOperator());
                    break;
                }
            case SPLIT:
                op.setPhysicalOperator(new SplitPOperator());
                break;
            case SCRIPT:
                {
                    op.setPhysicalOperator(new StringStreamingScriptPOperator());
                    break;
                }
            case SELECT:
                {
                    op.setPhysicalOperator(new StreamSelectPOperator());
                    break;
                }
            case SUBPLAN:
                {
                    op.setPhysicalOperator(new SubplanPOperator());
                    break;
                }
            case UNIONALL:
                {
                    if (topLevelOp) {
                        op.setPhysicalOperator(new UnionAllPOperator());
                    } else {
                        op.setPhysicalOperator(new MicroUnionAllPOperator());
                    }
                    break;
                }
            case INTERSECT:
                {
                    if (topLevelOp) {
                        op.setPhysicalOperator(new IntersectPOperator());
                    } else {
                        throw new IllegalStateException("Micro operator not implemented for: " + op.getOperatorTag());
                    }
                    break;
                }
            case UNNEST:
                {
                    op.setPhysicalOperator(new UnnestPOperator());
                    break;
                }
            case LEFT_OUTER_UNNEST:
                op.setPhysicalOperator(new LeftOuterUnnestPOperator());
                break;
            case DATASOURCESCAN:
                {
                    DataSourceScanOperator scan = (DataSourceScanOperator) op;
                    IDataSource dataSource = scan.getDataSource();
                    DataSourceScanPOperator dss = new DataSourceScanPOperator(dataSource);
                    if (dataSource.isScanAccessPathALeaf()) {
                        dss.disableJobGenBelowMe();
                    }
                    op.setPhysicalOperator(dss);
                    break;
                }
            case WRITE:
                {
                    op.setPhysicalOperator(new SinkWritePOperator());
                    break;
                }
            case DISTRIBUTE_RESULT:
                {
                    op.setPhysicalOperator(new DistributeResultPOperator());
                    break;
                }
            case WRITE_RESULT:
                {
                    WriteResultOperator opLoad = (WriteResultOperator) op;
                    LogicalVariable payload;
                    List<LogicalVariable> keys = new ArrayList<LogicalVariable>();
                    List<LogicalVariable> additionalFilteringKeys = null;
                    payload = getKeysAndLoad(opLoad.getPayloadExpression(), opLoad.getKeyExpressions(), keys);
                    if (opLoad.getAdditionalFilteringExpressions() != null) {
                        additionalFilteringKeys = new ArrayList<LogicalVariable>();
                        getKeys(opLoad.getAdditionalFilteringExpressions(), additionalFilteringKeys);
                    }
                    op.setPhysicalOperator(new WriteResultPOperator(opLoad.getDataSource(), payload, keys, additionalFilteringKeys));
                    break;
                }
            case INSERT_DELETE_UPSERT:
                {
                    // Primary index
                    InsertDeleteUpsertOperator opLoad = (InsertDeleteUpsertOperator) op;
                    LogicalVariable payload;
                    List<LogicalVariable> keys = new ArrayList<LogicalVariable>();
                    List<LogicalVariable> additionalFilteringKeys = null;
                    List<LogicalVariable> additionalNonFilterVariables = null;
                    if (opLoad.getAdditionalNonFilteringExpressions() != null) {
                        additionalNonFilterVariables = new ArrayList<LogicalVariable>();
                        getKeys(opLoad.getAdditionalNonFilteringExpressions(), additionalNonFilterVariables);
                    }
                    payload = getKeysAndLoad(opLoad.getPayloadExpression(), opLoad.getPrimaryKeyExpressions(), keys);
                    if (opLoad.getAdditionalFilteringExpressions() != null) {
                        additionalFilteringKeys = new ArrayList<LogicalVariable>();
                        getKeys(opLoad.getAdditionalFilteringExpressions(), additionalFilteringKeys);
                    }
                    if (opLoad.isBulkload()) {
                        op.setPhysicalOperator(new BulkloadPOperator(payload, keys, additionalFilteringKeys, additionalNonFilterVariables, opLoad.getDataSource()));
                    } else {
                        op.setPhysicalOperator(new InsertDeleteUpsertPOperator(payload, keys, additionalFilteringKeys, opLoad.getDataSource(), opLoad.getOperation(), additionalNonFilterVariables));
                    }
                    break;
                }
            case INDEX_INSERT_DELETE_UPSERT:
                {
                    // Secondary index
                    IndexInsertDeleteUpsertOperator opInsDel = (IndexInsertDeleteUpsertOperator) op;
                    List<LogicalVariable> primaryKeys = new ArrayList<LogicalVariable>();
                    List<LogicalVariable> secondaryKeys = new ArrayList<LogicalVariable>();
                    List<LogicalVariable> additionalFilteringKeys = null;
                    getKeys(opInsDel.getPrimaryKeyExpressions(), primaryKeys);
                    getKeys(opInsDel.getSecondaryKeyExpressions(), secondaryKeys);
                    if (opInsDel.getAdditionalFilteringExpressions() != null) {
                        additionalFilteringKeys = new ArrayList<LogicalVariable>();
                        getKeys(opInsDel.getAdditionalFilteringExpressions(), additionalFilteringKeys);
                    }
                    if (opInsDel.isBulkload()) {
                        op.setPhysicalOperator(new IndexBulkloadPOperator(primaryKeys, secondaryKeys, additionalFilteringKeys, opInsDel.getFilterExpression(), opInsDel.getDataSourceIndex()));
                    } else {
                        LogicalVariable upsertIndicatorVar = null;
                        List<LogicalVariable> prevSecondaryKeys = null;
                        LogicalVariable prevAdditionalFilteringKey = null;
                        if (opInsDel.getOperation() == Kind.UPSERT) {
                            upsertIndicatorVar = ((VariableReferenceExpression) opInsDel.getUpsertIndicatorExpr().getValue()).getVariableReference();
                            prevSecondaryKeys = new ArrayList<LogicalVariable>();
                            getKeys(opInsDel.getPrevSecondaryKeyExprs(), prevSecondaryKeys);
                            if (opInsDel.getPrevAdditionalFilteringExpression() != null) {
                                prevAdditionalFilteringKey = ((VariableReferenceExpression) (opInsDel.getPrevAdditionalFilteringExpression()).getValue()).getVariableReference();
                            }
                        }
                        op.setPhysicalOperator(new IndexInsertDeleteUpsertPOperator(primaryKeys, secondaryKeys, additionalFilteringKeys, opInsDel.getFilterExpression(), opInsDel.getDataSourceIndex(), upsertIndicatorVar, prevSecondaryKeys, prevAdditionalFilteringKey, opInsDel.getNumberOfAdditionalNonFilteringFields()));
                    }
                    break;
                }
            case TOKENIZE:
                {
                    TokenizeOperator opTokenize = (TokenizeOperator) op;
                    List<LogicalVariable> primaryKeys = new ArrayList<LogicalVariable>();
                    List<LogicalVariable> secondaryKeys = new ArrayList<LogicalVariable>();
                    getKeys(opTokenize.getPrimaryKeyExpressions(), primaryKeys);
                    getKeys(opTokenize.getSecondaryKeyExpressions(), secondaryKeys);
                    // Tokenize Operator only operates with a bulk load on a data set with an index
                    if (opTokenize.isBulkload()) {
                        op.setPhysicalOperator(new TokenizePOperator(primaryKeys, secondaryKeys, opTokenize.getDataSourceIndex()));
                    }
                    break;
                }
            case SINK:
                {
                    op.setPhysicalOperator(new SinkPOperator());
                    break;
                }
        }
    }
    if (op.hasNestedPlans()) {
        AbstractOperatorWithNestedPlans nested = (AbstractOperatorWithNestedPlans) op;
        for (ILogicalPlan p : nested.getNestedPlans()) {
            setPhysicalOperators(p, false, context);
        }
    }
    for (Mutable<ILogicalOperator> opRef : op.getInputs()) {
        computeDefaultPhysicalOp((AbstractLogicalOperator) opRef.getValue(), topLevelOp, context);
    }
}
#method_after
@SuppressWarnings({ "unchecked", "rawtypes" })
private static void computeDefaultPhysicalOp(AbstractLogicalOperator op, boolean topLevelOp, IOptimizationContext context) throws AlgebricksException {
    PhysicalOptimizationConfig physicalOptimizationConfig = context.getPhysicalOptimizationConfig();
    if (op.getPhysicalOperator() == null) {
        switch(op.getOperatorTag()) {
            case AGGREGATE:
                {
                    op.setPhysicalOperator(new AggregatePOperator());
                    break;
                }
            case ASSIGN:
                {
                    op.setPhysicalOperator(new AssignPOperator());
                    break;
                }
            case DISTINCT:
                {
                    DistinctOperator distinct = (DistinctOperator) op;
                    if (topLevelOp) {
                        distinct.setPhysicalOperator(new PreSortedDistinctByPOperator(distinct.getDistinctByVarList()));
                    } else {
                        distinct.setPhysicalOperator(new MicroPreSortedDistinctByPOperator(distinct.getDistinctByVarList()));
                    }
                    break;
                }
            case EMPTYTUPLESOURCE:
                {
                    op.setPhysicalOperator(new EmptyTupleSourcePOperator());
                    break;
                }
            case EXCHANGE:
                {
                    if (op.getPhysicalOperator() == null) {
                        throw new AlgebricksException("Implementation for EXCHANGE operator was not set.");
                    }
                    // implem. choice for exchange should be set by a parent op.
                    break;
                }
            case GROUP:
                {
                    GroupByOperator gby = (GroupByOperator) op;
                    if (gby.getNestedPlans().size() == 1) {
                        ILogicalPlan p0 = gby.getNestedPlans().get(0);
                        if (p0.getRoots().size() == 1) {
                            if ((gby.getAnnotations().get(OperatorAnnotations.USE_HASH_GROUP_BY) == Boolean.TRUE) || (gby.getAnnotations().get(OperatorAnnotations.USE_EXTERNAL_GROUP_BY) == Boolean.TRUE)) {
                                if (!topLevelOp) {
                                    throw new NotImplementedException("External hash group-by for nested grouping is not implemented.");
                                }
                                boolean hasIntermediateAgg = generateMergeAggregationExpressions(gby, context);
                                if (hasIntermediateAgg) {
                                    ExternalGroupByPOperator externalGby = new ExternalGroupByPOperator(gby.getGroupByList(), physicalOptimizationConfig.getMaxFramesForGroupBy(), (long) physicalOptimizationConfig.getMaxFramesForGroupBy() * physicalOptimizationConfig.getFrameSize());
                                    op.setPhysicalOperator(externalGby);
                                    break;
                                }
                            }
                        }
                    }
                    List<Pair<LogicalVariable, Mutable<ILogicalExpression>>> gbyList = gby.getGroupByList();
                    List<LogicalVariable> columnList = new ArrayList<LogicalVariable>(gbyList.size());
                    for (Pair<LogicalVariable, Mutable<ILogicalExpression>> p : gbyList) {
                        ILogicalExpression expr = p.second.getValue();
                        if (expr.getExpressionTag() == LogicalExpressionTag.VARIABLE) {
                            VariableReferenceExpression varRef = (VariableReferenceExpression) expr;
                            columnList.add(varRef.getVariableReference());
                        }
                    }
                    if (topLevelOp) {
                        op.setPhysicalOperator(new PreclusteredGroupByPOperator(columnList, gby.isGroupAll(), context.getPhysicalOptimizationConfig().getMaxFramesForGroupBy()));
                    } else {
                        op.setPhysicalOperator(new MicroPreclusteredGroupByPOperator(columnList));
                    }
                    break;
                }
            case INNERJOIN:
                {
                    JoinUtils.setJoinAlgorithmAndExchangeAlgo((InnerJoinOperator) op, topLevelOp, context);
                    break;
                }
            case LEFTOUTERJOIN:
                {
                    JoinUtils.setJoinAlgorithmAndExchangeAlgo((LeftOuterJoinOperator) op, topLevelOp, context);
                    break;
                }
            case LIMIT:
                {
                    op.setPhysicalOperator(new StreamLimitPOperator());
                    break;
                }
            case NESTEDTUPLESOURCE:
                {
                    op.setPhysicalOperator(new NestedTupleSourcePOperator());
                    break;
                }
            case ORDER:
                {
                    OrderOperator oo = (OrderOperator) op;
                    for (Pair<IOrder, Mutable<ILogicalExpression>> p : oo.getOrderExpressions()) {
                        ILogicalExpression e = p.second.getValue();
                        if (e.getExpressionTag() != LogicalExpressionTag.VARIABLE) {
                            throw new AlgebricksException("Order expression " + e + " has not been normalized.");
                        }
                    }
                    if (topLevelOp) {
                        op.setPhysicalOperator(new StableSortPOperator(physicalOptimizationConfig.getMaxFramesExternalSort(), oo.getTopK()));
                    } else {
                        op.setPhysicalOperator(new InMemoryStableSortPOperator());
                    }
                    break;
                }
            case PROJECT:
                {
                    op.setPhysicalOperator(new StreamProjectPOperator());
                    break;
                }
            case RUNNINGAGGREGATE:
                {
                    op.setPhysicalOperator(new RunningAggregatePOperator());
                    break;
                }
            case REPLICATE:
                {
                    op.setPhysicalOperator(new ReplicatePOperator());
                    break;
                }
            case SPLIT:
                op.setPhysicalOperator(new SplitPOperator());
                break;
            case SCRIPT:
                {
                    op.setPhysicalOperator(new StringStreamingScriptPOperator());
                    break;
                }
            case SELECT:
                {
                    op.setPhysicalOperator(new StreamSelectPOperator());
                    break;
                }
            case SUBPLAN:
                {
                    op.setPhysicalOperator(new SubplanPOperator());
                    break;
                }
            case UNIONALL:
                {
                    if (topLevelOp) {
                        op.setPhysicalOperator(new UnionAllPOperator());
                    } else {
                        op.setPhysicalOperator(new MicroUnionAllPOperator());
                    }
                    break;
                }
            case INTERSECT:
                {
                    if (topLevelOp) {
                        op.setPhysicalOperator(new IntersectPOperator());
                    } else {
                        throw new IllegalStateException("Micro operator not implemented for: " + op.getOperatorTag());
                    }
                    break;
                }
            case UNNEST:
                {
                    op.setPhysicalOperator(new UnnestPOperator());
                    break;
                }
            case LEFT_OUTER_UNNEST:
                op.setPhysicalOperator(new LeftOuterUnnestPOperator());
                break;
            case DATASOURCESCAN:
                {
                    DataSourceScanOperator scan = (DataSourceScanOperator) op;
                    IDataSource dataSource = scan.getDataSource();
                    DataSourceScanPOperator dss = new DataSourceScanPOperator(dataSource);
                    if (dataSource.isScanAccessPathALeaf()) {
                        dss.disableJobGenBelowMe();
                    }
                    op.setPhysicalOperator(dss);
                    break;
                }
            case WRITE:
                {
                    op.setPhysicalOperator(new SinkWritePOperator());
                    break;
                }
            case DISTRIBUTE_RESULT:
                {
                    op.setPhysicalOperator(new DistributeResultPOperator());
                    break;
                }
            case WRITE_RESULT:
                {
                    WriteResultOperator opLoad = (WriteResultOperator) op;
                    LogicalVariable payload;
                    List<LogicalVariable> keys = new ArrayList<LogicalVariable>();
                    List<LogicalVariable> additionalFilteringKeys = null;
                    payload = getKeysAndLoad(opLoad.getPayloadExpression(), opLoad.getKeyExpressions(), keys);
                    if (opLoad.getAdditionalFilteringExpressions() != null) {
                        additionalFilteringKeys = new ArrayList<LogicalVariable>();
                        getKeys(opLoad.getAdditionalFilteringExpressions(), additionalFilteringKeys);
                    }
                    op.setPhysicalOperator(new WriteResultPOperator(opLoad.getDataSource(), payload, keys, additionalFilteringKeys));
                    break;
                }
            case INSERT_DELETE_UPSERT:
                {
                    // Primary index
                    InsertDeleteUpsertOperator opLoad = (InsertDeleteUpsertOperator) op;
                    LogicalVariable payload;
                    List<LogicalVariable> keys = new ArrayList<LogicalVariable>();
                    List<LogicalVariable> additionalFilteringKeys = null;
                    List<LogicalVariable> additionalNonFilterVariables = null;
                    if (opLoad.getAdditionalNonFilteringExpressions() != null) {
                        additionalNonFilterVariables = new ArrayList<LogicalVariable>();
                        getKeys(opLoad.getAdditionalNonFilteringExpressions(), additionalNonFilterVariables);
                    }
                    payload = getKeysAndLoad(opLoad.getPayloadExpression(), opLoad.getPrimaryKeyExpressions(), keys);
                    if (opLoad.getAdditionalFilteringExpressions() != null) {
                        additionalFilteringKeys = new ArrayList<LogicalVariable>();
                        getKeys(opLoad.getAdditionalFilteringExpressions(), additionalFilteringKeys);
                    }
                    if (opLoad.isBulkload()) {
                        op.setPhysicalOperator(new BulkloadPOperator(payload, keys, additionalFilteringKeys, additionalNonFilterVariables, opLoad.getDataSource()));
                    } else {
                        op.setPhysicalOperator(new InsertDeleteUpsertPOperator(payload, keys, additionalFilteringKeys, opLoad.getDataSource(), opLoad.getOperation(), additionalNonFilterVariables));
                    }
                    break;
                }
            case INDEX_INSERT_DELETE_UPSERT:
                {
                    // Secondary index
                    IndexInsertDeleteUpsertOperator opInsDel = (IndexInsertDeleteUpsertOperator) op;
                    List<LogicalVariable> primaryKeys = new ArrayList<LogicalVariable>();
                    List<LogicalVariable> secondaryKeys = new ArrayList<LogicalVariable>();
                    List<LogicalVariable> additionalFilteringKeys = null;
                    getKeys(opInsDel.getPrimaryKeyExpressions(), primaryKeys);
                    getKeys(opInsDel.getSecondaryKeyExpressions(), secondaryKeys);
                    if (opInsDel.getAdditionalFilteringExpressions() != null) {
                        additionalFilteringKeys = new ArrayList<LogicalVariable>();
                        getKeys(opInsDel.getAdditionalFilteringExpressions(), additionalFilteringKeys);
                    }
                    if (opInsDel.isBulkload()) {
                        op.setPhysicalOperator(new IndexBulkloadPOperator(primaryKeys, secondaryKeys, additionalFilteringKeys, opInsDel.getFilterExpression(), opInsDel.getDataSourceIndex()));
                    } else {
                        LogicalVariable upsertIndicatorVar = null;
                        List<LogicalVariable> prevSecondaryKeys = null;
                        LogicalVariable prevAdditionalFilteringKey = null;
                        if (opInsDel.getOperation() == Kind.UPSERT) {
                            upsertIndicatorVar = getKey(opInsDel.getUpsertIndicatorExpr().getValue());
                            prevSecondaryKeys = new ArrayList<LogicalVariable>();
                            getKeys(opInsDel.getPrevSecondaryKeyExprs(), prevSecondaryKeys);
                            if (opInsDel.getPrevAdditionalFilteringExpression() != null) {
                                prevAdditionalFilteringKey = ((VariableReferenceExpression) (opInsDel.getPrevAdditionalFilteringExpression()).getValue()).getVariableReference();
                            }
                        }
                        op.setPhysicalOperator(new IndexInsertDeleteUpsertPOperator(primaryKeys, secondaryKeys, additionalFilteringKeys, opInsDel.getFilterExpression(), opInsDel.getDataSourceIndex(), upsertIndicatorVar, prevSecondaryKeys, prevAdditionalFilteringKey, opInsDel.getNumberOfAdditionalNonFilteringFields()));
                    }
                    break;
                }
            case TOKENIZE:
                {
                    TokenizeOperator opTokenize = (TokenizeOperator) op;
                    List<LogicalVariable> primaryKeys = new ArrayList<LogicalVariable>();
                    List<LogicalVariable> secondaryKeys = new ArrayList<LogicalVariable>();
                    getKeys(opTokenize.getPrimaryKeyExpressions(), primaryKeys);
                    getKeys(opTokenize.getSecondaryKeyExpressions(), secondaryKeys);
                    // Tokenize Operator only operates with a bulk load on a data set with an index
                    if (opTokenize.isBulkload()) {
                        op.setPhysicalOperator(new TokenizePOperator(primaryKeys, secondaryKeys, opTokenize.getDataSourceIndex()));
                    }
                    break;
                }
            case SINK:
                {
                    op.setPhysicalOperator(new SinkPOperator());
                    break;
                }
        }
    }
    if (op.hasNestedPlans()) {
        AbstractOperatorWithNestedPlans nested = (AbstractOperatorWithNestedPlans) op;
        for (ILogicalPlan p : nested.getNestedPlans()) {
            setPhysicalOperators(p, false, context);
        }
    }
    for (Mutable<ILogicalOperator> opRef : op.getInputs()) {
        computeDefaultPhysicalOp((AbstractLogicalOperator) opRef.getValue(), topLevelOp, context);
    }
}
#end_block

#method_before
private static void getKeys(List<Mutable<ILogicalExpression>> keyExpressions, List<LogicalVariable> keys) {
    for (Mutable<ILogicalExpression> kExpr : keyExpressions) {
        ILogicalExpression e = kExpr.getValue();
        if (e.getExpressionTag() != LogicalExpressionTag.VARIABLE) {
            throw new NotImplementedException();
        }
        keys.add(((VariableReferenceExpression) e).getVariableReference());
    }
}
#method_after
private static void getKeys(List<Mutable<ILogicalExpression>> keyExpressions, List<LogicalVariable> keys) {
    for (Mutable<ILogicalExpression> kExpr : keyExpressions) {
        keys.add(getKey(kExpr.getValue()));
    }
}
#end_block

#method_before
public InputStream executeQueryService(String str, OutputFormat fmt, URI uri, List<Parameter> params, boolean jsonEncoded, Predicate<Integer> responseCodeValidator, boolean cancellable) throws Exception {
    List<Parameter> newParams = upsertParam(params, "format", ParameterTypeEnum.STRING, fmt.mimeType());
    final Optional<String> maxReadsOptional = extractMaxResultReads(str);
    if (maxReadsOptional.isPresent()) {
        newParams = upsertParam(newParams, QueryServiceServlet.Parameter.MAX_RESULT_READS.str(), ParameterTypeEnum.STRING, maxReadsOptional.get());
    }
    final List<Parameter> additionalParams = extractParameters(str);
    for (Parameter param : additionalParams) {
        newParams = upsertParam(newParams, param.getName(), param.getType(), param.getValue());
    }
    HttpUriRequest method = jsonEncoded ? constructPostMethodJson(str, uri, "statement", newParams) : constructPostMethodUrl(str, uri, "statement", newParams);
    // Set accepted output response type
    method.setHeader("Accept", OutputFormat.CLEAN_JSON.mimeType());
    HttpResponse response = executeHttpRequest(method);
    if (responseCodeValidator != null) {
        checkResponse(response, responseCodeValidator);
    }
    return response.getEntity().getContent();
}
#method_after
public InputStream executeQueryService(String str, OutputFormat fmt, URI uri, List<Parameter> params, boolean jsonEncoded, Predicate<Integer> responseCodeValidator, boolean cancellable) throws Exception {
    List<Parameter> newParams = upsertParam(params, "format", ParameterTypeEnum.STRING, fmt.mimeType());
    newParams = upsertParam(newParams, QueryServiceServlet.Parameter.PLAN_FORMAT.str(), ParameterTypeEnum.STRING, DEFAULT_PLAN_FORMAT);
    final Optional<String> maxReadsOptional = extractMaxResultReads(str);
    if (maxReadsOptional.isPresent()) {
        newParams = upsertParam(newParams, QueryServiceServlet.Parameter.MAX_RESULT_READS.str(), ParameterTypeEnum.STRING, maxReadsOptional.get());
    }
    final List<Parameter> additionalParams = extractParameters(str);
    for (Parameter param : additionalParams) {
        newParams = upsertParam(newParams, param.getName(), param.getType(), param.getValue());
    }
    HttpUriRequest method = jsonEncoded ? constructPostMethodJson(str, uri, "statement", newParams) : constructPostMethodUrl(str, uri, "statement", newParams);
    // Set accepted output response type
    method.setHeader("Accept", OutputFormat.CLEAN_JSON.mimeType());
    HttpResponse response = executeHttpRequest(method);
    if (responseCodeValidator != null) {
        checkResponse(response, responseCodeValidator);
    }
    return response.getEntity().getContent();
}
#end_block

#method_before
protected void executeHttpRequest(OutputFormat fmt, String statement, Map<String, Object> variableCtx, String reqType, File testFile, File expectedResultFile, File actualResultFile, MutableInt queryCount, int numResultFiles, String extension, ComparisonEnum compare) throws Exception {
    String handleVar = getHandleVariable(statement);
    final String trimmedPathAndQuery = stripAllComments(statement).trim();
    final String variablesReplaced = replaceVarRef(trimmedPathAndQuery, variableCtx);
    final List<Parameter> params = extractParameters(statement);
    final Optional<String> body = extractBody(statement);
    final Predicate<Integer> statusCodePredicate = extractStatusCodePredicate(statement);
    InputStream resultStream;
    if ("http".equals(extension)) {
        resultStream = executeHttp(reqType, variablesReplaced, fmt, params, statusCodePredicate, body);
    } else if ("uri".equals(extension)) {
        resultStream = executeURI(reqType, URI.create(variablesReplaced), fmt, params, statusCodePredicate, body);
    } else {
        throw new IllegalArgumentException("Unexpected format for method " + reqType + ": " + extension);
    }
    if (handleVar != null) {
        String handle = ResultExtractor.extractHandle(resultStream);
        if (handle != null) {
            variableCtx.put(handleVar, handle);
        } else {
            throw new Exception("no handle for test " + testFile.toString());
        }
    } else {
        if (expectedResultFile == null) {
            if (testFile.getName().startsWith(DIAGNOSE)) {
                LOGGER.info("Diagnostic output: {}", IOUtils.toString(resultStream, StandardCharsets.UTF_8));
            } else {
                writeOutputToFile(actualResultFile, resultStream);
                Assert.fail("no result file for " + testFile.toString() + "; queryCount: " + queryCount + ", filectxs.size: " + numResultFiles);
            }
        } else {
            writeOutputToFile(actualResultFile, resultStream);
            runScriptAndCompareWithResult(testFile, expectedResultFile, actualResultFile, compare);
        }
    }
    queryCount.increment();
}
#method_after
protected void executeHttpRequest(OutputFormat fmt, String statement, Map<String, Object> variableCtx, String reqType, File testFile, File expectedResultFile, File actualResultFile, MutableInt queryCount, int numResultFiles, String extension, ComparisonEnum compare) throws Exception {
    String handleVar = getHandleVariable(statement);
    final String trimmedPathAndQuery = stripAllComments(statement).trim();
    final String variablesReplaced = replaceVarRef(trimmedPathAndQuery, variableCtx);
    final List<Parameter> params = extractParameters(statement);
    final Optional<String> body = extractBody(statement);
    final Predicate<Integer> statusCodePredicate = extractStatusCodePredicate(statement);
    InputStream resultStream;
    if ("http".equals(extension)) {
        resultStream = executeHttp(reqType, variablesReplaced, fmt, params, statusCodePredicate, body);
    } else if ("uri".equals(extension)) {
        resultStream = executeURI(reqType, URI.create(variablesReplaced), fmt, params, statusCodePredicate, body);
    } else {
        throw new IllegalArgumentException("Unexpected format for method " + reqType + ": " + extension);
    }
    if (handleVar != null) {
        String handle = ResultExtractor.extractHandle(resultStream);
        if (handle != null) {
            variableCtx.put(handleVar, handle);
        } else {
            throw new Exception("no handle for test " + testFile.toString());
        }
    } else {
        if (expectedResultFile == null) {
            if (testFile.getName().startsWith(DIAGNOSE)) {
                LOGGER.info("Diagnostic output: {}", IOUtils.toString(resultStream, StandardCharsets.UTF_8));
            } else {
                LOGGER.info("Unexpected output: {}", IOUtils.toString(resultStream, StandardCharsets.UTF_8));
                Assert.fail("no result file for " + testFile.toString() + "; queryCount: " + queryCount + ", filectxs.size: " + numResultFiles);
            }
        } else {
            writeOutputToFile(actualResultFile, resultStream);
            runScriptAndCompareWithResult(testFile, expectedResultFile, actualResultFile, compare);
        }
    }
    queryCount.increment();
}
#end_block

#method_before
protected void cleanupAndGetValidFilesInternal(FilenameFilter filter, TreeIndexFactory<? extends ITreeIndex> treeFactory, ArrayList<ComparableFileName> allFiles) throws HyracksDataException {
    String[] files = listDirFiles(baseDir, filter);
    for (String fileName : files) {
        FileReference fileRef = baseDir.getChild(fileName);
        if (treeFactory == null) {
            allFiles.add(new ComparableFileName(fileRef));
            continue;
        }
        TreeIndexState idxState = isValidTreeIndex(treeFactory.createIndexInstance(fileRef));
        if (idxState == TreeIndexState.VALID) {
            allFiles.add(new ComparableFileName(fileRef));
        } else if (idxState == TreeIndexState.INVALID) {
            fileRef.delete();
        }
    }
}
#method_after
protected void cleanupAndGetValidFilesInternal(FilenameFilter filter, TreeIndexFactory<? extends ITreeIndex> treeFactory, ArrayList<ComparableFileName> allFiles, IBufferCache bufferCache) throws HyracksDataException {
    String[] files = listDirFiles(baseDir, filter);
    for (String fileName : files) {
        FileReference fileRef = baseDir.getChild(fileName);
        if (treeFactory == null) {
            allFiles.add(new ComparableFileName(fileRef));
            continue;
        }
        TreeIndexState idxState = isValidTreeIndex(treeFactory.createIndexInstance(fileRef));
        if (idxState == TreeIndexState.VALID) {
            allFiles.add(new ComparableFileName(fileRef));
        } else if (idxState == TreeIndexState.INVALID) {
            bufferCache.deleteFile(fileRef);
        }
    }
}
#end_block

#method_before
protected void validateFiles(HashSet<String> groundTruth, ArrayList<ComparableFileName> validFiles, FilenameFilter filter, TreeIndexFactory<? extends ITreeIndex> treeFactory) throws HyracksDataException {
    ArrayList<ComparableFileName> tmpAllInvListsFiles = new ArrayList<>();
    cleanupAndGetValidFilesInternal(filter, treeFactory, tmpAllInvListsFiles);
    for (ComparableFileName cmpFileName : tmpAllInvListsFiles) {
        int index = cmpFileName.fileName.lastIndexOf(DELIMITER);
        String file = cmpFileName.fileName.substring(0, index);
        if (groundTruth.contains(file)) {
            validFiles.add(cmpFileName);
        } else {
            File invalidFile = new File(cmpFileName.fullPath);
            IoUtil.delete(invalidFile);
        }
    }
}
#method_after
protected void validateFiles(HashSet<String> groundTruth, ArrayList<ComparableFileName> validFiles, FilenameFilter filter, TreeIndexFactory<? extends ITreeIndex> treeFactory, IBufferCache bufferCache) throws HyracksDataException {
    ArrayList<ComparableFileName> tmpAllInvListsFiles = new ArrayList<>();
    cleanupAndGetValidFilesInternal(filter, treeFactory, tmpAllInvListsFiles, bufferCache);
    for (ComparableFileName cmpFileName : tmpAllInvListsFiles) {
        int index = cmpFileName.fileName.lastIndexOf(DELIMITER);
        String file = cmpFileName.fileName.substring(0, index);
        if (groundTruth.contains(file)) {
            validFiles.add(cmpFileName);
        } else {
            delete(bufferCache, cmpFileName.fullPath);
        }
    }
}
#end_block

#method_before
@Override
public List<LSMComponentFileReferences> cleanupAndGetValidFiles() throws HyracksDataException {
    List<LSMComponentFileReferences> validFiles = new ArrayList<>();
    ArrayList<ComparableFileName> allFiles = new ArrayList<>();
    // Gather files and delete invalid files
    // There are two types of invalid files:
    // (1) The isValid flag is not set
    // (2) The file's interval is contained by some other file
    // Here, we only filter out (1).
    cleanupAndGetValidFilesInternal(COMPONENT_FILES_FILTER, treeFactory, allFiles);
    if (allFiles.isEmpty()) {
        return validFiles;
    }
    if (allFiles.size() == 1) {
        validFiles.add(new LSMComponentFileReferences(allFiles.get(0).fileRef, null, null));
        return validFiles;
    }
    // Sorts files names from earliest to latest timestamp.
    Collections.sort(allFiles);
    List<ComparableFileName> validComparableFiles = new ArrayList<>();
    ComparableFileName last = allFiles.get(0);
    validComparableFiles.add(last);
    for (int i = 1; i < allFiles.size(); i++) {
        ComparableFileName current = allFiles.get(i);
        // The current start timestamp is greater than last stop timestamp so current is valid.
        if (current.interval[0].compareTo(last.interval[1]) > 0) {
            validComparableFiles.add(current);
            last = current;
        } else if (current.interval[0].compareTo(last.interval[0]) >= 0 && current.interval[1].compareTo(last.interval[1]) <= 0) {
            // The current file is completely contained in the interval of the
            // last file. Thus the last file must contain at least as much information
            // as the current file, so delete the current file.
            current.fileRef.delete();
        } else {
            // This scenario should not be possible since timestamps are monotonically increasing.
            throw HyracksDataException.create(ErrorCode.FOUND_OVERLAPPING_LSM_FILES, baseDir);
        }
    }
    // Sort valid files in reverse lexicographical order, such that newer files come first.
    Collections.sort(validComparableFiles, recencyCmp);
    for (ComparableFileName cmpFileName : validComparableFiles) {
        validFiles.add(new LSMComponentFileReferences(cmpFileName.fileRef, null, null));
    }
    return validFiles;
}
#method_after
@Override
public List<LSMComponentFileReferences> cleanupAndGetValidFiles() throws HyracksDataException {
    List<LSMComponentFileReferences> validFiles = new ArrayList<>();
    ArrayList<ComparableFileName> allFiles = new ArrayList<>();
    // Gather files and delete invalid files
    // There are two types of invalid files:
    // (1) The isValid flag is not set
    // (2) The file's interval is contained by some other file
    // Here, we only filter out (1).
    cleanupAndGetValidFilesInternal(COMPONENT_FILES_FILTER, treeFactory, allFiles, treeFactory.getBufferCache());
    if (allFiles.isEmpty()) {
        return validFiles;
    }
    if (allFiles.size() == 1) {
        validFiles.add(new LSMComponentFileReferences(allFiles.get(0).fileRef, null, null));
        return validFiles;
    }
    // Sorts files names from earliest to latest timestamp.
    Collections.sort(allFiles);
    List<ComparableFileName> validComparableFiles = new ArrayList<>();
    ComparableFileName last = allFiles.get(0);
    validComparableFiles.add(last);
    for (int i = 1; i < allFiles.size(); i++) {
        ComparableFileName current = allFiles.get(i);
        // The current start timestamp is greater than last stop timestamp so current is valid.
        if (current.interval[0].compareTo(last.interval[1]) > 0) {
            validComparableFiles.add(current);
            last = current;
        } else if (current.interval[0].compareTo(last.interval[0]) >= 0 && current.interval[1].compareTo(last.interval[1]) <= 0) {
            // The current file is completely contained in the interval of the
            // last file. Thus the last file must contain at least as much information
            // as the current file, so delete the current file.
            delete(treeFactory.getBufferCache(), current.fullPath);
        } else {
            // This scenario should not be possible since timestamps are monotonically increasing.
            throw HyracksDataException.create(ErrorCode.FOUND_OVERLAPPING_LSM_FILES, baseDir);
        }
    }
    // Sort valid files in reverse lexicographical order, such that newer files come first.
    Collections.sort(validComparableFiles, recencyCmp);
    for (ComparableFileName cmpFileName : validComparableFiles) {
        validFiles.add(new LSMComponentFileReferences(cmpFileName.fileRef, null, null));
    }
    return validFiles;
}
#end_block

#method_before
@Override
public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException {
    startNumEval.evaluate(tuple, start);
    endNumEval.evaluate(tuple, end);
    String n = getIdentifier().getName();
    ATypeTag startTag = ATYPETAGDESERIALIZER.deserialize(start.getTag());
    ATypeTag endTag = ATYPETAGDESERIALIZER.deserialize(end.getTag());
    ATypeTag stepTag = ATypeTag.INTEGER;
    double stepNum = 1;
    if (stepNumEval != null) {
        stepNumEval.evaluate(tuple, step);
        stepTag = ATYPETAGDESERIALIZER.deserialize(step.getTag());
        if (!ATypeHierarchy.isCompatible(ATypeTag.DOUBLE, stepTag)) {
            PointableHelper.setNull(result);
            return;
        }
        stepNum = ATypeHierarchy.getDoubleValue(n, 2, step.getByteArray(), step.getStartOffset());
    }
    if (!ATypeHierarchy.isCompatible(ATypeTag.DOUBLE, startTag) || !ATypeHierarchy.isCompatible(ATypeTag.DOUBLE, endTag)) {
        PointableHelper.setNull(result);
        return;
    }
    ISerializerDeserializer serde;
    if (ATypeHierarchy.canPromote(startTag, ATypeTag.BIGINT) && ATypeHierarchy.canPromote(endTag, ATypeTag.BIGINT) && ATypeHierarchy.canPromote(stepTag, ATypeTag.BIGINT)) {
        // all 3 numbers are whole numbers
        serde = SerializerDeserializerProvider.INSTANCE.getSerializerDeserializer(BuiltinType.AINT64);
        long startNum = ATypeHierarchy.getLongValue(n, 0, start.getByteArray(), start.getStartOffset());
        long endNum = ATypeHierarchy.getLongValue(n, 1, end.getByteArray(), end.getStartOffset());
        listBuilder.reset(ArrayRangeTypeComputer.LONG_LIST);
        while ((startNum < endNum && stepNum > 0) || (startNum > endNum && stepNum < 0)) {
            aLong.setValue(startNum);
            storage.reset();
            serde.serialize(aLong, storage.getDataOutput());
            listBuilder.addItem(storage);
            startNum += stepNum;
        }
    } else {
        // one number is a floating-point number
        serde = SerializerDeserializerProvider.INSTANCE.getSerializerDeserializer(BuiltinType.ADOUBLE);
        double startNum = ATypeHierarchy.getDoubleValue(n, 0, start.getByteArray(), start.getStartOffset());
        double endNum = ATypeHierarchy.getDoubleValue(n, 1, end.getByteArray(), end.getStartOffset());
        listBuilder.reset(ArrayRangeTypeComputer.DOUBLE_LIST);
        while ((startNum < endNum && stepNum > 0) || (startNum > endNum && stepNum < 0)) {
            aDouble.setValue(startNum);
            storage.reset();
            serde.serialize(aDouble, storage.getDataOutput());
            listBuilder.addItem(storage);
            startNum += stepNum;
        }
    }
    storage.reset();
    listBuilder.write(storage.getDataOutput(), true);
    result.set(storage);
}
#method_after
@Override
public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException {
    startNumEval.evaluate(tuple, start);
    endNumEval.evaluate(tuple, end);
    String n = getIdentifier().getName();
    ATypeTag startTag = ATYPETAGDESERIALIZER.deserialize(start.getTag());
    ATypeTag endTag = ATYPETAGDESERIALIZER.deserialize(end.getTag());
    ATypeTag stepTag = ATypeTag.INTEGER;
    double stepNum = 1;
    if (stepNumEval != null) {
        stepNumEval.evaluate(tuple, step);
        stepTag = ATYPETAGDESERIALIZER.deserialize(step.getTag());
        if (!ATypeHierarchy.isCompatible(ATypeTag.DOUBLE, stepTag)) {
            PointableHelper.setNull(result);
            return;
        }
        stepNum = ATypeHierarchy.getDoubleValue(n, 2, step.getByteArray(), step.getStartOffset());
    }
    if (!ATypeHierarchy.isCompatible(ATypeTag.DOUBLE, startTag) || Double.isNaN(stepNum) || !ATypeHierarchy.isCompatible(ATypeTag.DOUBLE, endTag) || Double.isInfinite(stepNum)) {
        PointableHelper.setNull(result);
        return;
    }
    ISerializerDeserializer serde;
    if (ATypeHierarchy.canPromote(startTag, ATypeTag.BIGINT) && ATypeHierarchy.canPromote(endTag, ATypeTag.BIGINT) && ATypeHierarchy.canPromote(stepTag, ATypeTag.BIGINT)) {
        // all 3 numbers are whole numbers
        serde = SerializerDeserializerProvider.INSTANCE.getSerializerDeserializer(BuiltinType.AINT64);
        long startNum = ATypeHierarchy.getLongValue(n, 0, start.getByteArray(), start.getStartOffset());
        long endNum = ATypeHierarchy.getLongValue(n, 1, end.getByteArray(), end.getStartOffset());
        listBuilder.reset(ArrayRangeTypeComputer.LONG_LIST);
        while ((startNum < endNum && stepNum > 0) || (startNum > endNum && stepNum < 0)) {
            aLong.setValue(startNum);
            storage.reset();
            serde.serialize(aLong, storage.getDataOutput());
            listBuilder.addItem(storage);
            startNum += stepNum;
        }
    } else {
        // one number is a floating-point number
        serde = SerializerDeserializerProvider.INSTANCE.getSerializerDeserializer(BuiltinType.ADOUBLE);
        double startNum = ATypeHierarchy.getDoubleValue(n, 0, start.getByteArray(), start.getStartOffset());
        double endNum = ATypeHierarchy.getDoubleValue(n, 1, end.getByteArray(), end.getStartOffset());
        if (Double.isNaN(startNum) || Double.isInfinite(startNum) || Double.isNaN(endNum) || Double.isInfinite(endNum)) {
            PointableHelper.setNull(result);
            return;
        }
        listBuilder.reset(ArrayRangeTypeComputer.DOUBLE_LIST);
        while ((startNum < endNum && stepNum > 0) || (startNum > endNum && stepNum < 0)) {
            aDouble.setValue(startNum);
            storage.reset();
            serde.serialize(aDouble, storage.getDataOutput());
            listBuilder.addItem(storage);
            startNum += stepNum;
        }
    }
    storage.reset();
    listBuilder.write(storage.getDataOutput(), true);
    result.set(storage);
}
#end_block

#method_before
@Override
protected boolean processItem(IPointable item, int listIndex, IAsterixListBuilder listBuilder) throws HyracksDataException {
    int hash = binaryHashFunction.hash(item.getByteArray(), item.getStartOffset(), item.getLength());
    List<IPointable> sameHashes = hashes.get(hash);
    if (sameHashes == null) {
        // new item
        sameHashes = pointableListAllocator.allocate(null);
        sameHashes.clear();
        addItem(listBuilder, item, sameHashes);
        hashes.put(hash, sameHashes);
        return true;
    } else if (ArrayFunctionsUtil.findItem(item, sameHashes) == null) {
        // new item, it could happen that two hashes are the same but they are for different items
        addItem(listBuilder, item, sameHashes);
        return true;
    }
    // else ignore since the item already exists
    return false;
}
#method_after
@Override
protected boolean processItem(IPointable item, int listIndex, IAsterixListBuilder listBuilder) throws HyracksDataException {
    int hash = binaryHashFunction.hash(item.getByteArray(), item.getStartOffset(), item.getLength());
    List<IPointable> sameHashes = hashes.get(hash);
    if (sameHashes == null) {
        // new item
        sameHashes = pointableListAllocator.allocate(null);
        sameHashes.clear();
        addItem(listBuilder, item, sameHashes);
        hashes.put(hash, sameHashes);
        return true;
    } else if (ArrayFunctionsUtil.findItem(item, sameHashes, comp) == null) {
        // new item, it could happen that two hashes are the same but they are for different items
        addItem(listBuilder, item, sameHashes);
        return true;
    }
    // else ignore since the item already exists
    return false;
}
#end_block

#method_before
@Override
public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException {
    byte listArgType;
    boolean returnNull = false;
    AbstractCollectionType outList = null;
    ATypeTag listTag;
    int minListIndex = 0;
    int minSize = -1;
    int nextSize;
    IScalarEvaluator listEval;
    IPointable listArg;
    // evaluate all the lists first to make sure they're all actually lists and of the same list type
    for (int i = 0; i < listsEval.length; i++) {
        listEval = listsEval[i];
        listEval.evaluate(tuple, listsArgs[i]);
        if (!returnNull) {
            listArg = listsArgs[i];
            listArgType = listArg.getByteArray()[listArg.getStartOffset()];
            listTag = ATYPETAGDESERIALIZER.deserialize(listArgType);
            if (!listTag.isListType()) {
                returnNull = true;
            } else if (outList != null && outList.getTypeTag() != listTag) {
                throw new RuntimeDataException(ErrorCode.DIFFERENT_LIST_TYPE_ARGS, sourceLoc);
            } else {
                if (outList == null) {
                    outList = (AbstractCollectionType) DefaultOpenFieldType.getDefaultOpenFieldType(listTag);
                }
                nextSize = getNumItems(outList, listArg.getByteArray(), listArg.getStartOffset());
                if (nextSize < minSize) {
                    minSize = nextSize;
                    minListIndex = i;
                }
            }
        }
    }
    if (returnNull) {
        PointableHelper.setNull(result);
        return;
    }
    IAsterixListBuilder listBuilder;
    if (outList.getTypeTag() == ATypeTag.ARRAY) {
        if (orderedListBuilder == null) {
            orderedListBuilder = new OrderedListBuilder();
        }
        listBuilder = orderedListBuilder;
    } else {
        if (unorderedListBuilder == null) {
            unorderedListBuilder = new UnorderedListBuilder();
        }
        listBuilder = unorderedListBuilder;
    }
    hashes.clear();
    try {
        // first, get distinct items of the most restrictive (smallest) list, pass listBuilder as null since
        // we're not adding values yet. Values will be added to listBuilder after inspecting all input lists
        listArg = listsArgs[minListIndex];
        listAccessor.reset(listArg.getByteArray(), listArg.getStartOffset());
        processList(listAccessor, minListIndex, null, true);
        // now process each list one by one
        listBuilder.reset(outList);
        for (int listIndex = 0; listIndex < listsArgs.length; listIndex++) {
            if (listIndex == minListIndex) {
                incrementSmallest(listIndex, hashes.values());
            } else {
                listArg = listsArgs[listIndex];
                listAccessor.reset(listArg.getByteArray(), listArg.getStartOffset());
                processList(listAccessor, listIndex, listBuilder, false);
            }
        }
        finalResult.reset();
        listBuilder.write(finalResult.getDataOutput(), true);
        result.set(finalResult);
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    } finally {
        storageAllocator.reset();
        arrayListAllocator.reset();
        pointableAllocator.reset();
    }
}
#method_after
@Override
public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException {
    byte listArgType;
    boolean returnNull = false;
    AbstractCollectionType outList = null;
    ATypeTag listTag;
    int minListIndex = 0;
    int minSize = -1;
    int nextSize;
    IScalarEvaluator listEval;
    IPointable listArg;
    // evaluate all the lists first to make sure they're all actually lists and of the same list type
    for (int i = 0; i < listsEval.length; i++) {
        listEval = listsEval[i];
        listEval.evaluate(tuple, listsArgs[i]);
        if (!returnNull) {
            listArg = listsArgs[i];
            listArgType = listArg.getByteArray()[listArg.getStartOffset()];
            listTag = ATYPETAGDESERIALIZER.deserialize(listArgType);
            if (!listTag.isListType()) {
                returnNull = true;
            } else if (outList != null && outList.getTypeTag() != listTag) {
                throw new RuntimeDataException(ErrorCode.DIFFERENT_LIST_TYPE_ARGS, sourceLoc);
            } else {
                if (outList == null) {
                    outList = (AbstractCollectionType) DefaultOpenFieldType.getDefaultOpenFieldType(listTag);
                }
                caster.reset(outList, argTypes[i], listsEval[i]);
                caster.evaluate(tuple, listsArgs[i]);
                nextSize = getNumItems(outList, listArg.getByteArray(), listArg.getStartOffset());
                if (nextSize < minSize) {
                    minSize = nextSize;
                    minListIndex = i;
                }
            }
        }
    }
    if (returnNull) {
        PointableHelper.setNull(result);
        return;
    }
    IAsterixListBuilder listBuilder;
    if (outList.getTypeTag() == ATypeTag.ARRAY) {
        if (orderedListBuilder == null) {
            orderedListBuilder = new OrderedListBuilder();
        }
        listBuilder = orderedListBuilder;
    } else {
        if (unorderedListBuilder == null) {
            unorderedListBuilder = new UnorderedListBuilder();
        }
        listBuilder = unorderedListBuilder;
    }
    hashes.clear();
    try {
        // first, get distinct items of the most restrictive (smallest) list, pass listBuilder as null since
        // we're not adding values yet. Values will be added to listBuilder after inspecting all input lists
        listArg = listsArgs[minListIndex];
        listAccessor.reset(listArg.getByteArray(), listArg.getStartOffset());
        processList(listAccessor, minListIndex, null, true);
        // now process each list one by one
        listBuilder.reset(outList);
        for (int listIndex = 0; listIndex < listsArgs.length; listIndex++) {
            if (listIndex == minListIndex) {
                incrementSmallest(listIndex, hashes.values());
            } else {
                listArg = listsArgs[listIndex];
                listAccessor.reset(listArg.getByteArray(), listArg.getStartOffset());
                processList(listAccessor, listIndex, listBuilder, false);
            }
        }
        finalResult.reset();
        listBuilder.write(finalResult.getDataOutput(), true);
        result.set(finalResult);
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    } finally {
        storageAllocator.reset();
        arrayListAllocator.reset();
        pointableAllocator.reset();
    }
}
#end_block

#method_before
// collect the items of the most restrictive list, it initializes the list index as -1. each successive list
private boolean initIntersectList(IPointable item, int hash, List<ValueListIndex> sameHashes) throws IOException {
    // add if new item
    if (sameHashes == null) {
        List<ValueListIndex> newHashes = arrayListAllocator.allocate(null);
        newHashes.clear();
        newHashes.add(new ValueListIndex(item, -1));
        hashes.put(hash, newHashes);
        return true;
    } else if (ArrayFunctionsUtil.findItem(item, sameHashes) == null) {
        sameHashes.add(new ValueListIndex(item, -1));
        return true;
    }
    // else ignore for duplicate values in the same list
    return false;
}
#method_after
// collect the items of the most restrictive list, it initializes the list index as -1. each successive list
private boolean initIntersectList(IPointable item, int hash, List<ValueListIndex> sameHashes) throws IOException {
    // add if new item
    if (sameHashes == null) {
        List<ValueListIndex> newHashes = arrayListAllocator.allocate(null);
        newHashes.clear();
        newHashes.add(new ValueListIndex(item, -1));
        hashes.put(hash, newHashes);
        return true;
    } else if (ArrayFunctionsUtil.findItem(item, sameHashes, comp) == null) {
        sameHashes.add(new ValueListIndex(item, -1));
        return true;
    }
    // else ignore for duplicate values in the same list
    return false;
}
#end_block

#method_before
private void incrementIfExists(List<ValueListIndex> sameHashes, IPointable item, int listIndex, IAsterixListBuilder listBuilder) throws HyracksDataException {
    ValueListIndex sameValue = ArrayFunctionsUtil.findItem(item, sameHashes);
    if (sameValue != null && listIndex - sameValue.listIndex == 1) {
        // found the item, its stamp is OK (stamp saves the last list index that has seen this item)
        // increment stamp of this item
        sameValue.listIndex = listIndex;
        if (listIndex == listsArgs.length - 1) {
            // when listIndex is the last list, then it means this item was found in all previous lists
            listBuilder.addItem(item);
        }
    }
}
#method_after
private void incrementIfExists(List<ValueListIndex> sameHashes, IPointable item, int listIndex, IAsterixListBuilder listBuilder) throws HyracksDataException {
    ValueListIndex sameValue = ArrayFunctionsUtil.findItem(item, sameHashes, comp);
    if (sameValue != null && listIndex - sameValue.listIndex == 1) {
        // found the item, its stamp is OK (stamp saves the last list index that has seen this item)
        // increment stamp of this item
        sameValue.listIndex = listIndex;
        if (listIndex == listsArgs.length - 1) {
            // when listIndex is the last list, then it means this item was found in all previous lists
            listBuilder.addItem(item);
        }
    }
}
#end_block

#method_before
@Override
public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException {
    storage.reset();
    listEval.evaluate(tuple, list);
    ATypeTag listTag = ATYPETAGDESERIALIZER.deserialize(list.getByteArray()[list.getStartOffset()]);
    if (listTag != ATypeTag.ARRAY) {
        PointableHelper.setNull(result);
        return;
    }
    IAType openListType = DefaultOpenFieldType.getDefaultOpenFieldType(inputListType.getTypeTag());
    caster.reset(openListType, inputListType, listEval);
    caster.evaluate(tuple, list);
    fieldNameToValues.clear();
    listAccessor.reset(list.getByteArray(), list.getStartOffset());
    int numObjects = listAccessor.size();
    try {
        for (int objectIndex = 0; objectIndex < numObjects; objectIndex++) {
            listAccessor.getOrWriteItem(objectIndex, object, storage);
            processObject(object, objectIndex, numObjects);
        }
        if (fieldNameToValues.isEmpty()) {
            PointableHelper.setMissing(result);
            return;
        }
        recordBuilder.reset(DefaultOpenFieldType.NESTED_OPEN_RECORD_TYPE);
        recordBuilder.init();
        for (Map.Entry<IVisitablePointable, IVisitablePointable[]> e : fieldNameToValues.entrySet()) {
            listBuilder.reset(DefaultOpenFieldType.NESTED_OPEN_AORDERED_LIST_TYPE);
            for (int i = 0; i < e.getValue().length; i++) {
                if (e.getValue()[i] == null) {
                    listBuilder.addItem(PointableHelper.NULL_REF);
                } else {
                    listBuilder.addItem(e.getValue()[i]);
                }
            }
            storage.reset();
            listBuilder.write(storage.getDataOutput(), true);
            recordBuilder.addField(e.getKey(), storage);
        }
        storage.reset();
        recordBuilder.write(storage.getDataOutput(), true);
        result.set(storage);
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    } finally {
        pointableAllocator.reset();
    }
}
#method_after
@Override
public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException {
    storage.reset();
    listEval.evaluate(tuple, list);
    ATypeTag listTag = ATYPETAGDESERIALIZER.deserialize(list.getByteArray()[list.getStartOffset()]);
    if (listTag != ATypeTag.ARRAY) {
        PointableHelper.setNull(result);
        return;
    }
    caster.reset(DefaultOpenFieldType.NESTED_OPEN_AORDERED_LIST_TYPE, inputListType, listEval);
    caster.evaluate(tuple, list);
    fieldNameToValues.clear();
    listAccessor.reset(list.getByteArray(), list.getStartOffset());
    int numObjects = listAccessor.size();
    try {
        for (int objectIndex = 0; objectIndex < numObjects; objectIndex++) {
            listAccessor.getOrWriteItem(objectIndex, object, storage);
            processObject(object, objectIndex, numObjects);
        }
        if (fieldNameToValues.isEmpty()) {
            PointableHelper.setMissing(result);
            return;
        }
        recordBuilder.reset(DefaultOpenFieldType.NESTED_OPEN_RECORD_TYPE);
        recordBuilder.init();
        for (Map.Entry<IVisitablePointable, IVisitablePointable[]> e : fieldNameToValues.entrySet()) {
            listBuilder.reset(DefaultOpenFieldType.NESTED_OPEN_AORDERED_LIST_TYPE);
            for (int i = 0; i < e.getValue().length; i++) {
                if (e.getValue()[i] == null) {
                    listBuilder.addItem(PointableHelper.NULL_REF);
                } else {
                    listBuilder.addItem(e.getValue()[i]);
                }
            }
            storage.reset();
            listBuilder.write(storage.getDataOutput(), true);
            recordBuilder.addField(e.getKey(), storage);
        }
        storage.reset();
        recordBuilder.write(storage.getDataOutput(), true);
        result.set(storage);
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    } finally {
        pointableAllocator.reset();
    }
}
#end_block

#method_before
@Override
public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException {
    // 1st arg: value to repeat
    repeatedValueEval.evaluate(tuple, repeatedValueArg);
    // 2nd arg: number of repetitions
    repeatEval.evaluate(tuple, repeatArg);
    repeatArgValue.set(repeatArg);
    if (!ATypeHierarchy.isCompatible(ATypeTag.INTEGER, ATypeTag.VALUE_TYPE_MAPPING[repeatArgValue.getTag()])) {
        PointableHelper.setNull(result);
        return;
    }
    final String name = getIdentifier().getName();
    final int repetitions = ATypeHierarchy.getIntegerValue(name, 1, repeatArg.getByteArray(), repeatArg.getStartOffset());
    // create list
    listBuilder.reset(repeatedValueListType);
    for (int i = 0; i < repetitions; ++i) {
        listBuilder.addItem(repeatedValueArg);
    }
    storage.reset();
    listBuilder.write(storage.getDataOutput(), true);
    result.set(storage);
}
#method_after
@Override
public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException {
    // 1st arg: value to repeat
    repeatedValueEval.evaluate(tuple, repeatedValueArg);
    // 2nd arg: number of repetitions
    repeatEval.evaluate(tuple, repeatArg);
    repeatArgValue.set(repeatArg);
    if (!ATypeHierarchy.isCompatible(ATypeTag.DOUBLE, ATypeTag.VALUE_TYPE_MAPPING[repeatArgValue.getTag()])) {
        PointableHelper.setNull(result);
        return;
    }
    final String name = getIdentifier().getName();
    final double repetitions = ATypeHierarchy.getDoubleValue(name, 1, repeatArg.getByteArray(), repeatArg.getStartOffset());
    if (Double.isNaN(repetitions) || Double.isInfinite(repetitions) || Math.floor(repetitions) < repetitions || repetitions < 0) {
        PointableHelper.setNull(result);
        return;
    }
    // create list
    listBuilder.reset(repeatedValueListType);
    for (int i = 0; i < repetitions; ++i) {
        listBuilder.addItem(repeatedValueArg);
    }
    storage.reset();
    listBuilder.write(storage.getDataOutput(), true);
    result.set(storage);
}
#end_block

#method_before
@Override
public IScalarEvaluatorFactory createEvaluatorFactory(final IScalarEvaluatorFactory[] args) throws AlgebricksException {
    return new IScalarEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IScalarEvaluator createScalarEvaluator(final IHyracksTaskContext ctx) throws HyracksDataException {
            return new ArraySortFunction(args, ctx, sourceLoc);
        }
    };
}
#method_after
@Override
public IScalarEvaluatorFactory createEvaluatorFactory(final IScalarEvaluatorFactory[] args) throws AlgebricksException {
    return new IScalarEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IScalarEvaluator createScalarEvaluator(final IHyracksTaskContext ctx) throws HyracksDataException {
            return new ArraySortEval(args, ctx, sourceLoc);
        }
    };
}
#end_block

#method_before
@Override
protected void processList(ListAccessor listAccessor, IAsterixListBuilder listBuilder) throws IOException {
    int hash;
    boolean itemInStorage;
    boolean nullMissingWasAdded = false;
    List<IPointable> sameHashes;
    hashes.clear();
    for (int i = 0; i < listAccessor.size(); i++) {
        // get the item and compute its hash
        itemInStorage = listAccessor.getOrWriteItem(i, item, storage);
        if (ATYPETAGDESERIALIZER.deserialize(item.getByteArray()[item.getStartOffset()]).isDerivedType()) {
            throw new RuntimeDataException(ErrorCode.CANNOT_COMPARE_COMPLEX, sourceLoc);
        }
        if (isNullOrMissing(item)) {
            if (!nullMissingWasAdded) {
                listBuilder.addItem(item);
                nullMissingWasAdded = true;
            }
        } else {
            // look up if it already exists
            hash = binaryHashFunction.hash(item.getByteArray(), item.getStartOffset(), item.getLength());
            hashes.get(hash);
            sameHashes = hashes.get(hash);
            if (sameHashes == null) {
                // new item
                sameHashes = arrayListAllocator.allocate(null);
                sameHashes.clear();
                addItem(item, listBuilder, itemInStorage, sameHashes);
                hashes.put(hash, sameHashes);
                item = pointableAllocator.allocateEmpty();
            } else if (ArrayFunctionsUtil.findItem(item, sameHashes) == null) {
                // new item, it could happen that two hashes are the same but they are for different items
                addItem(item, listBuilder, itemInStorage, sameHashes);
                item = pointableAllocator.allocateEmpty();
            }
        }
    }
}
#method_after
@Override
protected void processList(ListAccessor listAccessor, IAsterixListBuilder listBuilder) throws IOException {
    int hash;
    boolean itemInStorage;
    boolean nullMissingWasAdded = false;
    List<IPointable> sameHashes;
    hashes.clear();
    for (int i = 0; i < listAccessor.size(); i++) {
        // get the item and compute its hash
        itemInStorage = listAccessor.getOrWriteItem(i, item, storage);
        if (ATYPETAGDESERIALIZER.deserialize(item.getByteArray()[item.getStartOffset()]).isDerivedType()) {
            throw new RuntimeDataException(ErrorCode.CANNOT_COMPARE_COMPLEX, sourceLoc);
        }
        if (isNullOrMissing(item)) {
            if (!nullMissingWasAdded) {
                listBuilder.addItem(item);
                nullMissingWasAdded = true;
            }
        } else {
            // look up if it already exists
            hash = binaryHashFunction.hash(item.getByteArray(), item.getStartOffset(), item.getLength());
            hashes.get(hash);
            sameHashes = hashes.get(hash);
            if (sameHashes == null) {
                // new item
                sameHashes = arrayListAllocator.allocate(null);
                sameHashes.clear();
                addItem(item, listBuilder, itemInStorage, sameHashes);
                hashes.put(hash, sameHashes);
                item = pointableAllocator.allocateEmpty();
            } else if (ArrayFunctionsUtil.findItem(item, sameHashes, comp) == null) {
                // new item, it could happen that two hashes are the same but they are for different items
                addItem(item, listBuilder, itemInStorage, sameHashes);
                item = pointableAllocator.allocateEmpty();
            }
        }
    }
}
#end_block

#method_before
@Override
public void run() {
    try {
        ccs.getDatasetDirectoryService().registerResultPartitionLocation(jobId, rsId, orderedResult, emptyResult, partition, nPartitions, networkAddress);
    } catch (HyracksDataException e) {
        LOGGER.log(Level.WARN, "Failed to register partition location", e);
        // Should fail the job if exists on cc, otherwise, do nothing
        JobRun jobRun = ccs.getJobManager().get(jobId);
        if (jobRun != null) {
            List<Exception> exceptions = new ArrayList<>();
            exceptions.add(e);
            jobRun.getExecutor().abortJob(exceptions, NoOpCallback.INSTANCE);
        }
    }
}
#method_after
@Override
public void run() {
    try {
        ccs.getResultDirectoryService().registerResultPartitionLocation(jobId, rsId, orderedResult, emptyResult, partition, nPartitions, networkAddress);
    } catch (HyracksDataException e) {
        LOGGER.log(Level.WARN, "Failed to register partition location", e);
        // Should fail the job if exists on cc, otherwise, do nothing
        JobRun jobRun = ccs.getJobManager().get(jobId);
        if (jobRun != null) {
            List<Exception> exceptions = new ArrayList<>();
            exceptions.add(e);
            jobRun.getExecutor().abortJob(exceptions, NoOpCallback.INSTANCE);
        }
    }
}
#end_block

#method_before
@Override
public IResultSetReader createReader(JobId jobId, ResultSetId resultSetId) throws HyracksDataException {
    IResultSetReader reader = null;
    try {
        reader = new ResultSetReader(resultDirectory, netManager, resultClientCtx, jobId, resultSetId);
    } catch (Exception e) {
        throw new HyracksDataException(e);
    }
    return reader;
}
#method_after
@Override
public IResultSetReader createReader(JobId jobId, ResultSetId resultSetId) throws HyracksDataException {
    IResultSetReader reader = null;
    try {
        reader = new ResultSetReader(resultDirectory, netManager, resultClientCtx, jobId, resultSetId);
    } catch (Exception e) {
        throw HyracksDataException.create(e);
    }
    return reader;
}
#end_block

#method_before
@Override
public Map<String, String> getConfig() {
    return config;
}
#method_after
@Override
public Map<String, Object> getConfig() {
    return config;
}
#end_block

#method_before
public ARecordType findOutputRecordType() throws AlgebricksException {
    return MetadataManagerUtil.findOutputRecordType(mdTxnCtx, getDefaultDataverseName(), getPropertyValue("output-record-type"));
}
#method_after
public ARecordType findOutputRecordType() throws AlgebricksException {
    return MetadataManagerUtil.findOutputRecordType(mdTxnCtx, getDefaultDataverseName(), getProperty("output-record-type"));
}
#end_block

#method_before
@Override
public Pair<IOperatorDescriptor, AlgebricksPartitionConstraint> getScannerRuntime(IDataSource<DataSourceId> dataSource, List<LogicalVariable> scanVariables, List<LogicalVariable> projectVariables, boolean projectPushed, List<LogicalVariable> minFilterVars, List<LogicalVariable> maxFilterVars, IOperatorSchema opSchema, IVariableTypeEnvironment typeEnv, JobGenContext context, JobSpecification jobSpec, Object implConfig) throws AlgebricksException {
    return ((DataSource) dataSource).buildDatasourceScanRuntime(this, dataSource, scanVariables, projectVariables, projectPushed, minFilterVars, maxFilterVars, opSchema, typeEnv, context, jobSpec, implConfig);
}
#method_after
@Override
public Pair<IOperatorDescriptor, AlgebricksPartitionConstraint> getScannerRuntime(IDataSource<DataSourceId> dataSource, List<LogicalVariable> scanVariables, List<LogicalVariable> projectVariables, boolean projectPushed, List<LogicalVariable> minFilterVars, List<LogicalVariable> maxFilterVars, ITupleFilterFactory tupleFilterFactory, long outputLimit, IOperatorSchema opSchema, IVariableTypeEnvironment typeEnv, JobGenContext context, JobSpecification jobSpec, Object implConfig) throws AlgebricksException {
    return ((DataSource) dataSource).buildDatasourceScanRuntime(this, dataSource, scanVariables, projectVariables, projectPushed, minFilterVars, maxFilterVars, tupleFilterFactory, outputLimit, opSchema, typeEnv, context, jobSpec, implConfig);
}
#end_block

#method_before
public Pair<IOperatorDescriptor, AlgebricksPartitionConstraint> buildBtreeRuntime(JobSpecification jobSpec, IOperatorSchema opSchema, IVariableTypeEnvironment typeEnv, JobGenContext context, boolean retainInput, boolean retainMissing, Dataset dataset, String indexName, int[] lowKeyFields, int[] highKeyFields, boolean lowKeyInclusive, boolean highKeyInclusive, boolean propagateFilter, int[] minFilterFieldIndexes, int[] maxFilterFieldIndexes, boolean isIndexOnlyPlan) throws AlgebricksException {
    boolean isSecondary = true;
    Index primaryIndex = MetadataManager.INSTANCE.getIndex(mdTxnCtx, dataset.getDataverseName(), dataset.getDatasetName(), dataset.getDatasetName());
    if (primaryIndex != null && (dataset.getDatasetType() != DatasetType.EXTERNAL)) {
        isSecondary = !indexName.equals(primaryIndex.getIndexName());
    }
    Index theIndex = isSecondary ? MetadataManager.INSTANCE.getIndex(mdTxnCtx, dataset.getDataverseName(), dataset.getDatasetName(), indexName) : primaryIndex;
    int numPrimaryKeys = dataset.getPrimaryKeys().size();
    RecordDescriptor outputRecDesc = JobGenHelper.mkRecordDescriptor(typeEnv, opSchema, context);
    Pair<IFileSplitProvider, AlgebricksPartitionConstraint> spPc = getSplitProviderAndConstraints(dataset, theIndex.getIndexName());
    int[] primaryKeyFields = new int[numPrimaryKeys];
    for (int i = 0; i < numPrimaryKeys; i++) {
        primaryKeyFields[i] = i;
    }
    int[] primaryKeyFieldsInSecondaryIndex = null;
    byte[] successValueForIndexOnlyPlan = null;
    byte[] failValueForIndexOnlyPlan = null;
    boolean proceedIndexOnlyPlan = isIndexOnlyPlan && isSecondary;
    if (proceedIndexOnlyPlan) {
        int numSecondaryKeys = theIndex.getKeyFieldNames().size();
        primaryKeyFieldsInSecondaryIndex = new int[numPrimaryKeys];
        for (int i = 0; i < numPrimaryKeys; i++) {
            primaryKeyFieldsInSecondaryIndex[i] = i + numSecondaryKeys;
        }
        // Defines the return value from a secondary index search if this is an index-only plan.
        failValueForIndexOnlyPlan = SerializerDeserializerUtil.computeByteArrayForIntValue(0);
        successValueForIndexOnlyPlan = SerializerDeserializerUtil.computeByteArrayForIntValue(1);
    }
    ISearchOperationCallbackFactory searchCallbackFactory = dataset.getSearchCallbackFactory(storageComponentProvider, theIndex, IndexOperation.SEARCH, primaryKeyFields, primaryKeyFieldsInSecondaryIndex, proceedIndexOnlyPlan);
    IStorageManager storageManager = getStorageComponentProvider().getStorageManager();
    IIndexDataflowHelperFactory indexHelperFactory = new IndexDataflowHelperFactory(storageManager, spPc.first);
    BTreeSearchOperatorDescriptor btreeSearchOp;
    if (dataset.getDatasetType() == DatasetType.INTERNAL) {
        btreeSearchOp = new BTreeSearchOperatorDescriptor(jobSpec, outputRecDesc, lowKeyFields, highKeyFields, lowKeyInclusive, highKeyInclusive, indexHelperFactory, retainInput, retainMissing, context.getMissingWriterFactory(), searchCallbackFactory, minFilterFieldIndexes, maxFilterFieldIndexes, propagateFilter, proceedIndexOnlyPlan, failValueForIndexOnlyPlan, successValueForIndexOnlyPlan);
    } else {
        btreeSearchOp = new ExternalBTreeSearchOperatorDescriptor(jobSpec, outputRecDesc, lowKeyFields, highKeyFields, lowKeyInclusive, highKeyInclusive, indexHelperFactory, retainInput, retainMissing, context.getMissingWriterFactory(), searchCallbackFactory, minFilterFieldIndexes, maxFilterFieldIndexes, ExternalDatasetsRegistry.INSTANCE.getAndLockDatasetVersion(dataset, this));
    }
    return new Pair<>(btreeSearchOp, spPc.second);
}
#method_after
public Pair<IOperatorDescriptor, AlgebricksPartitionConstraint> buildBtreeRuntime(JobSpecification jobSpec, IOperatorSchema opSchema, IVariableTypeEnvironment typeEnv, JobGenContext context, boolean retainInput, boolean retainMissing, Dataset dataset, String indexName, int[] lowKeyFields, int[] highKeyFields, boolean lowKeyInclusive, boolean highKeyInclusive, boolean propagateFilter, int[] minFilterFieldIndexes, int[] maxFilterFieldIndexes, ITupleFilterFactory tupleFilterFactory, long outputLimit, boolean isIndexOnlyPlan) throws AlgebricksException {
    boolean isSecondary = true;
    Index primaryIndex = MetadataManager.INSTANCE.getIndex(mdTxnCtx, dataset.getDataverseName(), dataset.getDatasetName(), dataset.getDatasetName());
    if (primaryIndex != null && (dataset.getDatasetType() != DatasetType.EXTERNAL)) {
        isSecondary = !indexName.equals(primaryIndex.getIndexName());
    }
    Index theIndex = isSecondary ? MetadataManager.INSTANCE.getIndex(mdTxnCtx, dataset.getDataverseName(), dataset.getDatasetName(), indexName) : primaryIndex;
    int numPrimaryKeys = dataset.getPrimaryKeys().size();
    RecordDescriptor outputRecDesc = JobGenHelper.mkRecordDescriptor(typeEnv, opSchema, context);
    Pair<IFileSplitProvider, AlgebricksPartitionConstraint> spPc = getSplitProviderAndConstraints(dataset, theIndex.getIndexName());
    int[] primaryKeyFields = new int[numPrimaryKeys];
    for (int i = 0; i < numPrimaryKeys; i++) {
        primaryKeyFields[i] = i;
    }
    int[] primaryKeyFieldsInSecondaryIndex = null;
    byte[] successValueForIndexOnlyPlan = null;
    byte[] failValueForIndexOnlyPlan = null;
    boolean proceedIndexOnlyPlan = isIndexOnlyPlan && isSecondary;
    if (proceedIndexOnlyPlan) {
        int numSecondaryKeys = theIndex.getKeyFieldNames().size();
        primaryKeyFieldsInSecondaryIndex = new int[numPrimaryKeys];
        for (int i = 0; i < numPrimaryKeys; i++) {
            primaryKeyFieldsInSecondaryIndex[i] = i + numSecondaryKeys;
        }
        // Defines the return value from a secondary index search if this is an index-only plan.
        failValueForIndexOnlyPlan = SerializerDeserializerUtil.computeByteArrayForIntValue(0);
        successValueForIndexOnlyPlan = SerializerDeserializerUtil.computeByteArrayForIntValue(1);
    }
    ISearchOperationCallbackFactory searchCallbackFactory = dataset.getSearchCallbackFactory(storageComponentProvider, theIndex, IndexOperation.SEARCH, primaryKeyFields, primaryKeyFieldsInSecondaryIndex, proceedIndexOnlyPlan);
    IStorageManager storageManager = getStorageComponentProvider().getStorageManager();
    IIndexDataflowHelperFactory indexHelperFactory = new IndexDataflowHelperFactory(storageManager, spPc.first);
    BTreeSearchOperatorDescriptor btreeSearchOp;
    if (dataset.getDatasetType() == DatasetType.INTERNAL) {
        btreeSearchOp = new BTreeSearchOperatorDescriptor(jobSpec, outputRecDesc, lowKeyFields, highKeyFields, lowKeyInclusive, highKeyInclusive, indexHelperFactory, retainInput, retainMissing, context.getMissingWriterFactory(), searchCallbackFactory, minFilterFieldIndexes, maxFilterFieldIndexes, propagateFilter, tupleFilterFactory, outputLimit, proceedIndexOnlyPlan, failValueForIndexOnlyPlan, successValueForIndexOnlyPlan);
    } else {
        btreeSearchOp = new ExternalBTreeSearchOperatorDescriptor(jobSpec, outputRecDesc, lowKeyFields, highKeyFields, lowKeyInclusive, highKeyInclusive, indexHelperFactory, retainInput, retainMissing, context.getMissingWriterFactory(), searchCallbackFactory, minFilterFieldIndexes, maxFilterFieldIndexes, ExternalDatasetsRegistry.INSTANCE.getAndLockDatasetVersion(dataset, this));
    }
    return new Pair<>(btreeSearchOp, spPc.second);
}
#end_block

#method_before
private AsterixTupleFilterFactory createTupleFilterFactory(IOperatorSchema[] inputSchemas, IVariableTypeEnvironment typeEnv, ILogicalExpression filterExpr, JobGenContext context) throws AlgebricksException {
    // No filtering condition.
    if (filterExpr == null) {
        return null;
    }
    IExpressionRuntimeProvider expressionRuntimeProvider = context.getExpressionRuntimeProvider();
    IScalarEvaluatorFactory filterEvalFactory = expressionRuntimeProvider.createEvaluatorFactory(filterExpr, typeEnv, inputSchemas, context);
    return new AsterixTupleFilterFactory(filterEvalFactory, context.getBinaryBooleanInspectorFactory());
}
#method_after
@Override
public AsterixTupleFilterFactory createTupleFilterFactory(IOperatorSchema[] inputSchemas, IVariableTypeEnvironment typeEnv, ILogicalExpression filterExpr, JobGenContext context) throws AlgebricksException {
    // No filtering condition.
    if (filterExpr == null) {
        return null;
    }
    IExpressionRuntimeProvider expressionRuntimeProvider = context.getExpressionRuntimeProvider();
    IScalarEvaluatorFactory filterEvalFactory = expressionRuntimeProvider.createEvaluatorFactory(filterExpr, typeEnv, inputSchemas, context);
    return new AsterixTupleFilterFactory(filterEvalFactory, context.getBinaryBooleanInspectorFactory());
}
#end_block

#method_before
@Override
public void deliverIncomingMessage(IIPCHandle handle, long mid, long rmid, Object payload, Exception exception) {
    HyracksClientInterfaceFunctions.Function fn = (HyracksClientInterfaceFunctions.Function) payload;
    switch(fn.getFunctionId()) {
        case GET_CLUSTER_CONTROLLER_INFO:
            try {
                handle.send(mid, ccs.getClusterControllerInfo(), null);
            } catch (IPCException e) {
                LOGGER.log(Level.WARN, "Error sending response to GET_CLUSTER_CONTROLLER_INFO request", e);
            }
            break;
        case GET_JOB_STATUS:
            HyracksClientInterfaceFunctions.GetJobStatusFunction gjsf = (HyracksClientInterfaceFunctions.GetJobStatusFunction) fn;
            ccs.getWorkQueue().schedule(new GetJobStatusWork(ccs.getJobManager(), gjsf.getJobId(), new IPCResponder<>(handle, mid)));
            break;
        case GET_JOB_INFO:
            HyracksClientInterfaceFunctions.GetJobInfoFunction gjif = (HyracksClientInterfaceFunctions.GetJobInfoFunction) fn;
            ccs.getWorkQueue().schedule(new GetJobInfoWork(ccs.getJobManager(), gjif.getJobId(), new IPCResponder<JobInfo>(handle, mid)));
            break;
        case DISTRIBUTE_JOB:
            HyracksClientInterfaceFunctions.DeployJobSpecFunction djf = (HyracksClientInterfaceFunctions.DeployJobSpecFunction) fn;
            ccs.getWorkQueue().schedule(new DeployJobSpecWork(ccs, djf.getACGGFBytes(), deployedJobSpecIdFactory.create(), new IPCResponder<>(handle, mid)));
            break;
        case DESTROY_JOB:
            HyracksClientInterfaceFunctions.UndeployJobSpecFunction dsjf = (HyracksClientInterfaceFunctions.UndeployJobSpecFunction) fn;
            ccs.getWorkQueue().schedule(new UndeployJobSpecWork(ccs, dsjf.getDeployedJobSpecId(), new IPCResponder<>(handle, mid)));
            break;
        case CANCEL_JOB:
            HyracksClientInterfaceFunctions.CancelJobFunction cjf = (HyracksClientInterfaceFunctions.CancelJobFunction) fn;
            ccs.getWorkQueue().schedule(new CancelJobWork(ccs.getJobManager(), cjf.getJobId(), new IPCResponder<Void>(handle, mid)));
            break;
        case START_JOB:
            HyracksClientInterfaceFunctions.StartJobFunction sjf = (HyracksClientInterfaceFunctions.StartJobFunction) fn;
            DeployedJobSpecId id = sjf.getDeployedJobSpecId();
            byte[] acggfBytes = null;
            if (id == null) {
                // The job is new
                acggfBytes = sjf.getACGGFBytes();
            }
            ccs.getWorkQueue().schedule(new JobStartWork(ccs, sjf.getDeploymentId(), acggfBytes, sjf.getJobFlags(), jobIdFactory, sjf.getJobParameters(), new IPCResponder<>(handle, mid), id));
            break;
        case GET_DATASET_DIRECTORY_SERIVICE_INFO:
            ccs.getWorkQueue().schedule(new GetDatasetDirectoryServiceInfoWork(ccs, new IPCResponder<NetworkAddress>(handle, mid)));
            break;
        case GET_DATASET_RESULT_STATUS:
            HyracksClientInterfaceFunctions.GetDatasetResultStatusFunction gdrsf = (HyracksClientInterfaceFunctions.GetDatasetResultStatusFunction) fn;
            ccs.getWorkQueue().schedule(new GetResultStatusWork(ccs, gdrsf.getJobId(), gdrsf.getResultSetId(), new IPCResponder<Status>(handle, mid)));
            break;
        case GET_DATASET_RESULT_LOCATIONS:
            HyracksClientInterfaceFunctions.GetDatasetResultLocationsFunction gdrlf = (HyracksClientInterfaceFunctions.GetDatasetResultLocationsFunction) fn;
            ccs.getWorkQueue().schedule(new GetResultPartitionLocationsWork(ccs, gdrlf.getJobId(), gdrlf.getResultSetId(), gdrlf.getKnownRecords(), new IPCResponder<>(handle, mid)));
            break;
        case WAIT_FOR_COMPLETION:
            HyracksClientInterfaceFunctions.WaitForCompletionFunction wfcf = (HyracksClientInterfaceFunctions.WaitForCompletionFunction) fn;
            ccs.getWorkQueue().schedule(new WaitForJobCompletionWork(ccs, wfcf.getJobId(), new IPCResponder<>(handle, mid)));
            break;
        case GET_NODE_CONTROLLERS_INFO:
            ccs.getWorkQueue().schedule(new GetNodeControllersInfoWork(ccs.getNodeManager(), new IPCResponder<>(handle, mid)));
            break;
        case GET_CLUSTER_TOPOLOGY:
            try {
                handle.send(mid, ccs.getCCContext().getClusterTopology(), null);
            } catch (IPCException e) {
                LOGGER.log(Level.WARN, "Error sending response to GET_CLUSTER_TOPOLOGY request", e);
            }
            break;
        case CLI_DEPLOY_BINARY:
            HyracksClientInterfaceFunctions.CliDeployBinaryFunction dbf = (HyracksClientInterfaceFunctions.CliDeployBinaryFunction) fn;
            ccs.getWorkQueue().schedule(new CliDeployBinaryWork(ccs, dbf.getBinaryURLs(), dbf.getDeploymentId(), new IPCResponder<>(handle, mid)));
            break;
        case CLI_UNDEPLOY_BINARY:
            HyracksClientInterfaceFunctions.CliUnDeployBinaryFunction udbf = (HyracksClientInterfaceFunctions.CliUnDeployBinaryFunction) fn;
            ccs.getWorkQueue().schedule(new CliUnDeployBinaryWork(ccs, udbf.getDeploymentId(), new IPCResponder<>(handle, mid)));
            break;
        case CLUSTER_SHUTDOWN:
            HyracksClientInterfaceFunctions.ClusterShutdownFunction csf = (HyracksClientInterfaceFunctions.ClusterShutdownFunction) fn;
            ccs.getWorkQueue().schedule(new ClusterShutdownWork(ccs, csf.isTerminateNCService(), new IPCResponder<>(handle, mid)));
            break;
        case GET_NODE_DETAILS_JSON:
            HyracksClientInterfaceFunctions.GetNodeDetailsJSONFunction gndjf = (HyracksClientInterfaceFunctions.GetNodeDetailsJSONFunction) fn;
            ccs.getWorkQueue().schedule(new GetNodeDetailsJSONWork(ccs.getNodeManager(), ccs.getCCConfig(), gndjf.getNodeId(), gndjf.isIncludeStats(), gndjf.isIncludeConfig(), new IPCResponder<>(handle, mid)));
            break;
        case THREAD_DUMP:
            HyracksClientInterfaceFunctions.ThreadDumpFunction tdf = (HyracksClientInterfaceFunctions.ThreadDumpFunction) fn;
            ccs.getWorkQueue().schedule(new GetThreadDumpWork(ccs, tdf.getNode(), new IPCResponder<String>(handle, mid)));
            break;
        default:
            try {
                handle.send(mid, null, new IllegalArgumentException("Unknown function " + fn.getFunctionId()));
            } catch (IPCException e) {
                LOGGER.log(Level.WARN, "Error sending Unknown function response", e);
            }
    }
}
#method_after
@Override
public void deliverIncomingMessage(IIPCHandle handle, long mid, long rmid, Object payload, Exception exception) {
    HyracksClientInterfaceFunctions.Function fn = (HyracksClientInterfaceFunctions.Function) payload;
    switch(fn.getFunctionId()) {
        case GET_CLUSTER_CONTROLLER_INFO:
            try {
                handle.send(mid, ccs.getClusterControllerInfo(), null);
            } catch (IPCException e) {
                LOGGER.log(Level.WARN, "Error sending response to GET_CLUSTER_CONTROLLER_INFO request", e);
            }
            break;
        case GET_JOB_STATUS:
            HyracksClientInterfaceFunctions.GetJobStatusFunction gjsf = (HyracksClientInterfaceFunctions.GetJobStatusFunction) fn;
            ccs.getWorkQueue().schedule(new GetJobStatusWork(ccs.getJobManager(), gjsf.getJobId(), new IPCResponder<>(handle, mid)));
            break;
        case GET_JOB_INFO:
            HyracksClientInterfaceFunctions.GetJobInfoFunction gjif = (HyracksClientInterfaceFunctions.GetJobInfoFunction) fn;
            ccs.getWorkQueue().schedule(new GetJobInfoWork(ccs.getJobManager(), gjif.getJobId(), new IPCResponder<JobInfo>(handle, mid)));
            break;
        case DEPLOY_JOB:
            HyracksClientInterfaceFunctions.DeployJobSpecFunction djf = (HyracksClientInterfaceFunctions.DeployJobSpecFunction) fn;
            ccs.getWorkQueue().schedule(new DeployJobSpecWork(ccs, djf.getACGGFBytes(), deployedJobSpecIdFactory.create(), false, new IPCResponder<>(handle, mid)));
            break;
        case REDEPLOY_JOB:
            HyracksClientInterfaceFunctions.redeployJobSpecFunction udjsf = (HyracksClientInterfaceFunctions.redeployJobSpecFunction) fn;
            ccs.getWorkQueue().schedule(new DeployJobSpecWork(ccs, udjsf.getACGGFBytes(), udjsf.getDeployedJobSpecId(), true, new IPCResponder<>(handle, mid)));
            break;
        case UNDEPLOY_JOB:
            HyracksClientInterfaceFunctions.UndeployJobSpecFunction dsjf = (HyracksClientInterfaceFunctions.UndeployJobSpecFunction) fn;
            ccs.getWorkQueue().schedule(new UndeployJobSpecWork(ccs, dsjf.getDeployedJobSpecId(), new IPCResponder<>(handle, mid)));
            break;
        case CANCEL_JOB:
            HyracksClientInterfaceFunctions.CancelJobFunction cjf = (HyracksClientInterfaceFunctions.CancelJobFunction) fn;
            ccs.getWorkQueue().schedule(new CancelJobWork(ccs.getJobManager(), cjf.getJobId(), new IPCResponder<Void>(handle, mid)));
            break;
        case START_JOB:
            HyracksClientInterfaceFunctions.StartJobFunction sjf = (HyracksClientInterfaceFunctions.StartJobFunction) fn;
            DeployedJobSpecId id = sjf.getDeployedJobSpecId();
            byte[] acggfBytes = null;
            if (id == null) {
                // The job is new
                acggfBytes = sjf.getACGGFBytes();
            }
            ccs.getWorkQueue().schedule(new JobStartWork(ccs, sjf.getDeploymentId(), acggfBytes, sjf.getJobFlags(), jobIdFactory, sjf.getJobParameters(), new IPCResponder<>(handle, mid), id));
            break;
        case GET_RESULT_DIRECTORY_ADDRESS:
            ccs.getWorkQueue().schedule(new GetResultDirectoryAddressWork(ccs, new IPCResponder<NetworkAddress>(handle, mid)));
            break;
        case GET_RESULT_STATUS:
            HyracksClientInterfaceFunctions.GetResultStatusFunction gdrsf = (HyracksClientInterfaceFunctions.GetResultStatusFunction) fn;
            ccs.getWorkQueue().schedule(new GetResultStatusWork(ccs, gdrsf.getJobId(), gdrsf.getResultSetId(), new IPCResponder<Status>(handle, mid)));
            break;
        case GET_RESULT_LOCATIONS:
            HyracksClientInterfaceFunctions.GetResultLocationsFunction gdrlf = (HyracksClientInterfaceFunctions.GetResultLocationsFunction) fn;
            ccs.getWorkQueue().schedule(new GetResultPartitionLocationsWork(ccs, gdrlf.getJobId(), gdrlf.getResultSetId(), gdrlf.getKnownRecords(), new IPCResponder<>(handle, mid)));
            break;
        case WAIT_FOR_COMPLETION:
            HyracksClientInterfaceFunctions.WaitForCompletionFunction wfcf = (HyracksClientInterfaceFunctions.WaitForCompletionFunction) fn;
            ccs.getWorkQueue().schedule(new WaitForJobCompletionWork(ccs, wfcf.getJobId(), new IPCResponder<>(handle, mid)));
            break;
        case GET_NODE_CONTROLLERS_INFO:
            ccs.getWorkQueue().schedule(new GetNodeControllersInfoWork(ccs.getNodeManager(), new IPCResponder<>(handle, mid)));
            break;
        case GET_CLUSTER_TOPOLOGY:
            try {
                handle.send(mid, ccs.getCCContext().getClusterTopology(), null);
            } catch (IPCException e) {
                LOGGER.log(Level.WARN, "Error sending response to GET_CLUSTER_TOPOLOGY request", e);
            }
            break;
        case CLI_DEPLOY_BINARY:
            HyracksClientInterfaceFunctions.CliDeployBinaryFunction dbf = (HyracksClientInterfaceFunctions.CliDeployBinaryFunction) fn;
            ccs.getWorkQueue().schedule(new CliDeployBinaryWork(ccs, dbf.getBinaryURLs(), dbf.getDeploymentId(), new IPCResponder<>(handle, mid)));
            break;
        case CLI_UNDEPLOY_BINARY:
            HyracksClientInterfaceFunctions.CliUnDeployBinaryFunction udbf = (HyracksClientInterfaceFunctions.CliUnDeployBinaryFunction) fn;
            ccs.getWorkQueue().schedule(new CliUnDeployBinaryWork(ccs, udbf.getDeploymentId(), new IPCResponder<>(handle, mid)));
            break;
        case CLUSTER_SHUTDOWN:
            HyracksClientInterfaceFunctions.ClusterShutdownFunction csf = (HyracksClientInterfaceFunctions.ClusterShutdownFunction) fn;
            ccs.getWorkQueue().schedule(new ClusterShutdownWork(ccs, csf.isTerminateNCService(), new IPCResponder<>(handle, mid)));
            break;
        case GET_NODE_DETAILS_JSON:
            HyracksClientInterfaceFunctions.GetNodeDetailsJSONFunction gndjf = (HyracksClientInterfaceFunctions.GetNodeDetailsJSONFunction) fn;
            ccs.getWorkQueue().schedule(new GetNodeDetailsJSONWork(ccs.getNodeManager(), ccs.getCCConfig(), gndjf.getNodeId(), gndjf.isIncludeStats(), gndjf.isIncludeConfig(), new IPCResponder<>(handle, mid)));
            break;
        case THREAD_DUMP:
            HyracksClientInterfaceFunctions.ThreadDumpFunction tdf = (HyracksClientInterfaceFunctions.ThreadDumpFunction) fn;
            ccs.getWorkQueue().schedule(new GetThreadDumpWork(ccs, tdf.getNode(), new IPCResponder<String>(handle, mid)));
            break;
        default:
            try {
                handle.send(mid, null, new IllegalArgumentException("Unknown function " + fn.getFunctionId()));
            } catch (IPCException e) {
                LOGGER.log(Level.WARN, "Error sending Unknown function response", e);
            }
    }
}
#end_block

#method_before
@Override
public void start() throws Exception {
    LOGGER.log(Level.INFO, "Starting ClusterControllerService: " + this);
    serverCtx = new ServerContext(ServerContext.ServerType.CLUSTER_CONTROLLER, new File(ccConfig.getRootDir()));
    IIPCI ccIPCI = new ClusterControllerIPCI(this);
    clusterIPC = new IPCSystem(new InetSocketAddress(ccConfig.getClusterListenPort()), ccIPCI, new CCNCFunctions.SerializerDeserializer());
    IIPCI ciIPCI = new ClientInterfaceIPCI(this, jobIdFactory);
    clientIPC = new IPCSystem(new InetSocketAddress(ccConfig.getClientListenAddress(), ccConfig.getClientListenPort()), ciIPCI, new JavaSerializationBasedPayloadSerializerDeserializer());
    webServer = new WebServer(this, ccConfig.getConsoleListenPort());
    clusterIPC.start();
    clientIPC.start();
    webServer.start();
    info = new ClusterControllerInfo(ccId, ccConfig.getClientListenAddress(), ccConfig.getClientListenPort(), webServer.getListeningPort());
    timer.schedule(sweeper, 0, ccConfig.getHeartbeatPeriodMillis());
    jobLog.open();
    startApplication();
    datasetDirectoryService.init(executor);
    workQueue.start();
    connectNCs();
    LOGGER.log(Level.INFO, "Started ClusterControllerService");
    notifyApplication();
}
#method_after
@Override
public void start() throws Exception {
    LOGGER.log(Level.INFO, "Starting ClusterControllerService: " + this);
    serverCtx = new ServerContext(ServerContext.ServerType.CLUSTER_CONTROLLER, new File(ccConfig.getRootDir()));
    IIPCI ccIPCI = new ClusterControllerIPCI(this);
    clusterIPC = new IPCSystem(new InetSocketAddress(ccConfig.getClusterListenPort()), ccIPCI, new CCNCFunctions.SerializerDeserializer());
    IIPCI ciIPCI = new ClientInterfaceIPCI(this, jobIdFactory);
    clientIPC = new IPCSystem(new InetSocketAddress(ccConfig.getClientListenAddress(), ccConfig.getClientListenPort()), ciIPCI, new JavaSerializationBasedPayloadSerializerDeserializer());
    webServer = new WebServer(this, ccConfig.getConsoleListenPort());
    clusterIPC.start();
    clientIPC.start();
    webServer.start();
    info = new ClusterControllerInfo(ccId, ccConfig.getClientPublicAddress(), ccConfig.getClientPublicPort(), ccConfig.getConsolePublicPort());
    timer.schedule(sweeper, 0, ccConfig.getHeartbeatPeriodMillis());
    jobLog.open();
    startApplication();
    resultDirectoryService.init(executor);
    workQueue.start();
    connectNCs();
    LOGGER.log(Level.INFO, "Started ClusterControllerService");
    notifyApplication();
}
#end_block

#method_before
private void startApplication() throws Exception {
    serviceCtx = new CCServiceContext(this, serverCtx, ccContext, ccConfig.getAppConfig());
    serviceCtx.addJobLifecycleListener(datasetDirectoryService);
    application.init(serviceCtx);
    executor = MaintainedThreadNameExecutorService.newCachedThreadPool(serviceCtx.getThreadFactory());
    application.start(ccConfig.getAppArgsArray());
    IJobCapacityController jobCapacityController = application.getJobCapacityController();
    // Job manager is in charge of job lifecycle management.
    try {
        Constructor<?> jobManagerConstructor = this.getClass().getClassLoader().loadClass(ccConfig.getJobManagerClass()).getConstructor(CCConfig.class, ClusterControllerService.class, IJobCapacityController.class);
        jobManager = (IJobManager) jobManagerConstructor.newInstance(ccConfig, this, jobCapacityController);
    } catch (ClassNotFoundException | InstantiationException | IllegalAccessException | NoSuchMethodException | InvocationTargetException e) {
        if (LOGGER.isWarnEnabled()) {
            LOGGER.log(Level.WARN, "class " + ccConfig.getJobManagerClass() + " could not be used: ", e);
        }
        // Falls back to the default implementation if the user-provided class name is not valid.
        jobManager = new JobManager(ccConfig, this, jobCapacityController);
    }
}
#method_after
private void startApplication() throws Exception {
    serviceCtx = new CCServiceContext(this, serverCtx, ccContext, ccConfig.getAppConfig());
    serviceCtx.addJobLifecycleListener(resultDirectoryService);
    application.init(serviceCtx);
    executor = MaintainedThreadNameExecutorService.newCachedThreadPool(serviceCtx.getThreadFactory());
    application.start(ccConfig.getAppArgsArray());
    IJobCapacityController jobCapacityController = application.getJobCapacityController();
    // Job manager is in charge of job lifecycle management.
    try {
        Constructor<?> jobManagerConstructor = this.getClass().getClassLoader().loadClass(ccConfig.getJobManagerClass()).getConstructor(CCConfig.class, ClusterControllerService.class, IJobCapacityController.class);
        jobManager = (IJobManager) jobManagerConstructor.newInstance(ccConfig, this, jobCapacityController);
    } catch (ClassNotFoundException | InstantiationException | IllegalAccessException | NoSuchMethodException | InvocationTargetException e) {
        if (LOGGER.isWarnEnabled()) {
            LOGGER.log(Level.WARN, "class " + ccConfig.getJobManagerClass() + " could not be used: ", e);
        }
        // Falls back to the default implementation if the user-provided class name is not valid.
        jobManager = new JobManager(ccConfig, this, jobCapacityController);
    }
}
#end_block

#method_before
@Override
public void getIPAddressNodeMap(Map<InetAddress, Set<String>> map) throws HyracksDataException {
    GetIpAddressNodeNameMapWork ginmw = new GetIpAddressNodeNameMapWork(ClusterControllerService.this.getNodeManager(), map);
    try {
        workQueue.scheduleAndSync(ginmw);
    } catch (Exception e) {
        throw new HyracksDataException(e);
    }
}
#method_after
@Override
public void getIPAddressNodeMap(Map<InetAddress, Set<String>> map) throws HyracksDataException {
    GetIpAddressNodeNameMapWork ginmw = new GetIpAddressNodeNameMapWork(ClusterControllerService.this.getNodeManager(), map);
    try {
        workQueue.scheduleAndSync(ginmw);
    } catch (Exception e) {
        throw HyracksDataException.create(e);
    }
}
#end_block

#method_before
@Override
protected void executeStatement(String statementsText, SessionOutput sessionOutput, ResultProperties resultProperties, IStatementExecutor.Stats stats, RequestParameters param, RequestExecutionState execution, Map<String, String> optionalParameters) throws Exception {
    // Running on NC -> send 'execute' message to CC
    INCServiceContext ncCtx = (INCServiceContext) serviceCtx;
    INCMessageBroker ncMb = (INCMessageBroker) ncCtx.getMessageBroker();
    final IStatementExecutor.ResultDelivery delivery = resultProperties.getDelivery();
    ExecuteStatementResponseMessage responseMsg;
    MessageFuture responseFuture = ncMb.registerMessageFuture();
    final String handleUrl = getHandleUrl(param.host, param.path, delivery);
    try {
        if (param.clientContextID == null) {
            param.clientContextID = UUID.randomUUID().toString();
        }
        long timeout = ExecuteStatementRequestMessage.DEFAULT_NC_TIMEOUT_MILLIS;
        if (param.timeout != null && !param.timeout.trim().isEmpty()) {
            timeout = TimeUnit.NANOSECONDS.toMillis(Duration.parseDurationStringToNanos(param.timeout));
        }
        ExecuteStatementRequestMessage requestMsg = new ExecuteStatementRequestMessage(ncCtx.getNodeId(), responseFuture.getFutureId(), queryLanguage, statementsText, sessionOutput.config(), resultProperties.getNcToCcResultProperties(), param.clientContextID, handleUrl, optionalParameters);
        execution.start();
        ncMb.sendMessageToPrimaryCC(requestMsg);
        try {
            responseMsg = (ExecuteStatementResponseMessage) responseFuture.get(timeout, TimeUnit.MILLISECONDS);
        } catch (InterruptedException e) {
            cancelQuery(ncMb, ncCtx.getNodeId(), param.clientContextID, e, false);
            throw e;
        } catch (TimeoutException exception) {
            RuntimeDataException hde = new RuntimeDataException(ErrorCode.QUERY_TIMEOUT);
            hde.addSuppressed(exception);
            // cancel query
            cancelQuery(ncMb, ncCtx.getNodeId(), param.clientContextID, hde, true);
            throw hde;
        }
        execution.end();
    } finally {
        ncMb.deregisterMessageFuture(responseFuture.getFutureId());
    }
    Throwable err = responseMsg.getError();
    if (err != null) {
        if (err instanceof Error) {
            throw (Error) err;
        } else if (err instanceof Exception) {
            throw (Exception) err;
        } else {
            throw new Exception(err.toString(), err);
        }
    }
    // no errors - stop buffering and allow for streaming result delivery
    sessionOutput.release();
    IStatementExecutor.ResultMetadata resultMetadata = responseMsg.getMetadata();
    if (delivery == IStatementExecutor.ResultDelivery.IMMEDIATE && !resultMetadata.getResultSets().isEmpty()) {
        stats.setProcessedObjects(responseMsg.getStats().getProcessedObjects());
        for (Triple<JobId, ResultSetId, ARecordType> rsmd : resultMetadata.getResultSets()) {
            ResultReader resultReader = new ResultReader(getHyracksDataset(), rsmd.getLeft(), rsmd.getMiddle());
            ResultUtil.printResults(appCtx, resultReader, sessionOutput, stats, rsmd.getRight());
        }
    } else {
        sessionOutput.out().append(responseMsg.getResult());
    }
}
#method_after
@Override
protected void executeStatement(String statementsText, SessionOutput sessionOutput, ResultProperties resultProperties, IStatementExecutor.Stats stats, QueryServiceRequestParameters param, RequestExecutionState execution, Map<String, String> optionalParameters, Map<String, byte[]> statementParameters) throws Exception {
    // Running on NC -> send 'execute' message to CC
    INCServiceContext ncCtx = (INCServiceContext) serviceCtx;
    INCMessageBroker ncMb = (INCMessageBroker) ncCtx.getMessageBroker();
    final IStatementExecutor.ResultDelivery delivery = resultProperties.getDelivery();
    ExecuteStatementResponseMessage responseMsg;
    MessageFuture responseFuture = ncMb.registerMessageFuture();
    final String handleUrl = getHandleUrl(param.getHost(), param.getPath(), delivery);
    try {
        if (param.getClientContextID() == null) {
            param.setClientContextID(UUID.randomUUID().toString());
        }
        long timeout = ExecuteStatementRequestMessage.DEFAULT_NC_TIMEOUT_MILLIS;
        if (param.getTimeout() != null && !param.getTimeout().trim().isEmpty()) {
            timeout = TimeUnit.NANOSECONDS.toMillis(Duration.parseDurationStringToNanos(param.getTimeout()));
        }
        ExecuteStatementRequestMessage requestMsg = new ExecuteStatementRequestMessage(ncCtx.getNodeId(), responseFuture.getFutureId(), queryLanguage, statementsText, sessionOutput.config(), resultProperties.getNcToCcResultProperties(), param.getClientContextID(), handleUrl, optionalParameters, statementParameters, param.isMultiStatement());
        execution.start();
        ncMb.sendMessageToPrimaryCC(requestMsg);
        try {
            responseMsg = (ExecuteStatementResponseMessage) responseFuture.get(timeout, TimeUnit.MILLISECONDS);
        } catch (InterruptedException e) {
            cancelQuery(ncMb, ncCtx.getNodeId(), param.getClientContextID(), e, false);
            throw e;
        } catch (TimeoutException exception) {
            RuntimeDataException hde = new RuntimeDataException(ErrorCode.REQUEST_TIMEOUT);
            hde.addSuppressed(exception);
            // cancel query
            cancelQuery(ncMb, ncCtx.getNodeId(), param.getClientContextID(), hde, true);
            throw hde;
        }
        execution.end();
    } finally {
        ncMb.deregisterMessageFuture(responseFuture.getFutureId());
    }
    Throwable err = responseMsg.getError();
    if (err != null) {
        if (err instanceof Error) {
            throw (Error) err;
        } else if (err instanceof Exception) {
            throw (Exception) err;
        } else {
            throw new Exception(err.toString(), err);
        }
    }
    // no errors - stop buffering and allow for streaming result delivery
    sessionOutput.release();
    IStatementExecutor.ResultMetadata resultMetadata = responseMsg.getMetadata();
    if (delivery == IStatementExecutor.ResultDelivery.IMMEDIATE && !resultMetadata.getResultSets().isEmpty()) {
        stats.setProcessedObjects(responseMsg.getStats().getProcessedObjects());
        for (Triple<JobId, ResultSetId, ARecordType> rsmd : resultMetadata.getResultSets()) {
            ResultReader resultReader = new ResultReader(getResultSet(), rsmd.getLeft(), rsmd.getMiddle());
            ResultUtil.printResults(appCtx, resultReader, sessionOutput, stats, rsmd.getRight());
        }
    } else {
        sessionOutput.out().append(responseMsg.getResult());
    }
    printExecutionPlans(sessionOutput, responseMsg.getExecutionPlans());
}
#end_block

#method_before
@Override
protected void handleExecuteStatementException(Throwable t, RequestExecutionState execution) {
    if (t instanceof TimeoutException || ExceptionUtils.matchingCause(t, candidate -> candidate instanceof IPCException)) {
        GlobalConfig.ASTERIX_LOGGER.log(Level.WARN, t.toString(), t);
        execution.setStatus(ResultStatus.FAILED, HttpResponseStatus.SERVICE_UNAVAILABLE);
    } else {
        super.handleExecuteStatementException(t, execution);
    }
}
#method_after
@Override
protected void handleExecuteStatementException(Throwable t, RequestExecutionState state, QueryServiceRequestParameters param) {
    if (// TODO(mblow): I don't think t can ever been an instance of TimeoutException
    t instanceof TimeoutException || ExceptionUtils.matchingCause(t, candidate -> candidate instanceof IPCException)) {
        GlobalConfig.ASTERIX_LOGGER.log(Level.WARN, t.toString(), t);
        state.setStatus(ResultStatus.FAILED, HttpResponseStatus.SERVICE_UNAVAILABLE);
    } else {
        super.handleExecuteStatementException(t, state, param);
    }
}
#end_block

#method_before
private void doHandle(IServletResponse response, String query, SessionOutput sessionOutput, ResultDelivery resultDelivery) throws JsonProcessingException {
    try {
        response.setStatus(HttpResponseStatus.OK);
        IHyracksClientConnection hcc = (IHyracksClientConnection) ctx.get(HYRACKS_CONNECTION_ATTR);
        IResultSet hds = (IResultSet) ctx.get(HYRACKS_DATASET_ATTR);
        if (hds == null) {
            synchronized (ctx) {
                hds = (IResultSet) ctx.get(HYRACKS_DATASET_ATTR);
                if (hds == null) {
                    hds = new ResultSet(hcc, appCtx.getCompilerProperties().getFrameSize(), ResultReader.NUM_READERS);
                    ctx.put(HYRACKS_DATASET_ATTR, hds);
                }
            }
        }
        IParser parser = parserFactory.createParser(query);
        List<Statement> aqlStatements = parser.parse();
        validate(aqlStatements);
        MetadataManager.INSTANCE.init();
        IStatementExecutor translator = statementExecutorFactory.create(appCtx, aqlStatements, sessionOutput, compilationProvider, componentProvider);
        final IRequestParameters requestParameters = new RequestParameters(hds, new ResultProperties(resultDelivery), new IStatementExecutor.Stats(), null, null, null);
        translator.compileAndExecute(hcc, null, requestParameters);
    } catch (AsterixException | TokenMgrError | org.apache.asterix.aqlplus.parser.TokenMgrError pe) {
        response.setStatus(HttpResponseStatus.INTERNAL_SERVER_ERROR);
        GlobalConfig.ASTERIX_LOGGER.log(Level.ERROR, pe.getMessage(), pe);
        String errorMessage = ResultUtil.buildParseExceptionMessage(pe, query);
        ObjectNode errorResp = ResultUtil.getErrorResponse(2, errorMessage, "", ResultUtil.extractFullStackTrace(pe));
        sessionOutput.out().write(OBJECT_MAPPER.writeValueAsString(errorResp));
    } catch (Exception e) {
        GlobalConfig.ASTERIX_LOGGER.log(Level.ERROR, e.getMessage(), e);
        response.setStatus(HttpResponseStatus.INTERNAL_SERVER_ERROR);
        ResultUtil.apiErrorHandler(sessionOutput.out(), e);
    }
}
#method_after
private void doHandle(IServletResponse response, String query, SessionOutput sessionOutput, ResultDelivery resultDelivery) throws JsonProcessingException {
    try {
        response.setStatus(HttpResponseStatus.OK);
        IHyracksClientConnection hcc = (IHyracksClientConnection) ctx.get(HYRACKS_CONNECTION_ATTR);
        IParser parser = parserFactory.createParser(query);
        List<Statement> aqlStatements = parser.parse();
        validate(aqlStatements);
        MetadataManager.INSTANCE.init();
        IStatementExecutor translator = statementExecutorFactory.create(appCtx, aqlStatements, sessionOutput, compilationProvider, componentProvider);
        final IResultSet resultSet = ServletUtil.getResultSet(hcc, appCtx, ctx);
        final IRequestParameters requestParameters = new RequestParameters(resultSet, new ResultProperties(resultDelivery), new IStatementExecutor.Stats(), null, null, null, null, true);
        translator.compileAndExecute(hcc, null, requestParameters);
    } catch (AsterixException | TokenMgrError | org.apache.asterix.aqlplus.parser.TokenMgrError pe) {
        response.setStatus(HttpResponseStatus.INTERNAL_SERVER_ERROR);
        GlobalConfig.ASTERIX_LOGGER.log(Level.ERROR, pe.getMessage(), pe);
        String errorMessage = ResultUtil.buildParseExceptionMessage(pe, query);
        ObjectNode errorResp = ResultUtil.getErrorResponse(2, errorMessage, "", ResultUtil.extractFullStackTrace(pe));
        sessionOutput.out().write(OBJECT_MAPPER.writeValueAsString(errorResp));
    } catch (Exception e) {
        GlobalConfig.ASTERIX_LOGGER.log(Level.ERROR, e.getMessage(), e);
        response.setStatus(HttpResponseStatus.INTERNAL_SERVER_ERROR);
        ResultUtil.apiErrorHandler(sessionOutput.out(), e);
    }
}
#end_block

#method_before
protected List<String> readResults(JobSpecification spec, JobId jobId, ResultSetId resultSetId) throws Exception {
    int nReaders = 1;
    IFrameTupleAccessor frameTupleAccessor = new ResultFrameTupleAccessor();
    IResultSet hyracksDataset = new ResultSet(hcc, spec.getFrameSize(), nReaders);
    IResultSetReader reader = hyracksDataset.createReader(jobId, resultSetId);
    List<String> resultRecords = new ArrayList<>();
    ByteBufferInputStream bbis = new ByteBufferInputStream();
    FrameManager resultDisplayFrameMgr = new FrameManager(spec.getFrameSize());
    VSizeFrame frame = new VSizeFrame(resultDisplayFrameMgr);
    int readSize = reader.read(frame);
    while (readSize > 0) {
        try {
            frameTupleAccessor.reset(frame.getBuffer());
            for (int tIndex = 0; tIndex < frameTupleAccessor.getTupleCount(); tIndex++) {
                int start = frameTupleAccessor.getTupleStartOffset(tIndex);
                int length = frameTupleAccessor.getTupleEndOffset(tIndex) - start;
                bbis.setByteBuffer(frame.getBuffer(), start);
                byte[] recordBytes = new byte[length];
                bbis.read(recordBytes, 0, length);
                resultRecords.add(new String(recordBytes, 0, length));
            }
        } finally {
            bbis.close();
        }
        readSize = reader.read(frame);
    }
    return resultRecords;
}
#method_after
protected List<String> readResults(JobSpecification spec, JobId jobId, ResultSetId resultSetId) throws Exception {
    int nReaders = 1;
    IFrameTupleAccessor frameTupleAccessor = new ResultFrameTupleAccessor();
    IResultSet resultSet = new ResultSet(hcc, spec.getFrameSize(), nReaders);
    IResultSetReader reader = resultSet.createReader(jobId, resultSetId);
    List<String> resultRecords = new ArrayList<>();
    ByteBufferInputStream bbis = new ByteBufferInputStream();
    FrameManager resultDisplayFrameMgr = new FrameManager(spec.getFrameSize());
    VSizeFrame frame = new VSizeFrame(resultDisplayFrameMgr);
    int readSize = reader.read(frame);
    while (readSize > 0) {
        try {
            frameTupleAccessor.reset(frame.getBuffer());
            for (int tIndex = 0; tIndex < frameTupleAccessor.getTupleCount(); tIndex++) {
                int start = frameTupleAccessor.getTupleStartOffset(tIndex);
                int length = frameTupleAccessor.getTupleEndOffset(tIndex) - start;
                bbis.setByteBuffer(frame.getBuffer(), start);
                byte[] recordBytes = new byte[length];
                bbis.read(recordBytes, 0, length);
                resultRecords.add(new String(recordBytes, 0, length));
            }
        } finally {
            bbis.close();
        }
        readSize = reader.read(frame);
    }
    return resultRecords;
}
#end_block

#method_before
public static void compareActualAndExpectedIndexesRangeSearch(LSMInvertedIndexTestContext testCtx) throws HyracksDataException {
    IInvertedIndex invIndex = (IInvertedIndex) testCtx.getIndex();
    int tokenFieldCount = invIndex.getTokenTypeTraits().length;
    int invListFieldCount = invIndex.getInvListTypeTraits().length;
    IInvertedIndexAccessor invIndexAccessor = (IInvertedIndexAccessor) invIndex.createAccessor(NoOpIndexAccessParameters.INSTANCE);
    IIndexCursor invIndexCursor = invIndexAccessor.createRangeSearchCursor();
    try {
        MultiComparator tokenCmp = MultiComparator.create(invIndex.getTokenCmpFactories());
        IBinaryComparatorFactory[] tupleCmpFactories = new IBinaryComparatorFactory[tokenFieldCount + invListFieldCount];
        for (int i = 0; i < tokenFieldCount; i++) {
            tupleCmpFactories[i] = invIndex.getTokenCmpFactories()[i];
        }
        for (int i = 0; i < invListFieldCount; i++) {
            tupleCmpFactories[tokenFieldCount + i] = invIndex.getInvListCmpFactories()[i];
        }
        MultiComparator tupleCmp = MultiComparator.create(tupleCmpFactories);
        RangePredicate nullPred = new RangePredicate(null, null, true, true, tokenCmp, tokenCmp);
        // Helpers for generating a serialized inverted-list element from a CheckTuple from the expected index.
        ISerializerDeserializer[] fieldSerdes = testCtx.getFieldSerdes();
        ArrayTupleBuilder expectedBuilder = new ArrayTupleBuilder(fieldSerdes.length);
        ArrayTupleReference expectedTuple = new ArrayTupleReference();
        Iterator<CheckTuple> expectedIter = testCtx.getCheckTuples().iterator();
        // Compare index elements.
        invIndexAccessor.rangeSearch(invIndexCursor, nullPred);
        try {
            while (invIndexCursor.hasNext() && expectedIter.hasNext()) {
                invIndexCursor.next();
                ITupleReference actualTuple = invIndexCursor.getTuple();
                CheckTuple expected = expectedIter.next();
                OrderedIndexTestUtils.createTupleFromCheckTuple(expected, expectedBuilder, expectedTuple, fieldSerdes);
                if (tupleCmp.compare(actualTuple, expectedTuple) != 0) {
                    fail("Index entries differ for token '" + expected.getField(0) + "'.");
                }
            }
            if (expectedIter.hasNext()) {
                fail("Indexes do not match. Actual index is missing entries.");
            }
            if (invIndexCursor.hasNext()) {
                fail("Indexes do not match. Actual index contains too many entries.");
            }
        } finally {
            invIndexCursor.close();
        }
    } finally {
        invIndexCursor.destroy();
    }
}
#method_after
public static void compareActualAndExpectedIndexesRangeSearch(LSMInvertedIndexTestContext testCtx) throws HyracksDataException {
    IInvertedIndex invIndex = (IInvertedIndex) testCtx.getIndex();
    IInvertedIndexAccessor invIndexAccessor = (IInvertedIndexAccessor) invIndex.createAccessor(NoOpIndexAccessParameters.INSTANCE);
    compareActualAndExpectedIndexesRangeSearch(testCtx, invIndexAccessor.createRangeSearchCursor());
}
#end_block

#method_before
public static void compareActualAndExpectedIndexesRangeSearch(LSMInvertedIndexTestContext testCtx) throws HyracksDataException {
    IInvertedIndex invIndex = (IInvertedIndex) testCtx.getIndex();
    int tokenFieldCount = invIndex.getTokenTypeTraits().length;
    int invListFieldCount = invIndex.getInvListTypeTraits().length;
    IInvertedIndexAccessor invIndexAccessor = (IInvertedIndexAccessor) invIndex.createAccessor(NoOpIndexAccessParameters.INSTANCE);
    IIndexCursor invIndexCursor = invIndexAccessor.createRangeSearchCursor();
    try {
        MultiComparator tokenCmp = MultiComparator.create(invIndex.getTokenCmpFactories());
        IBinaryComparatorFactory[] tupleCmpFactories = new IBinaryComparatorFactory[tokenFieldCount + invListFieldCount];
        for (int i = 0; i < tokenFieldCount; i++) {
            tupleCmpFactories[i] = invIndex.getTokenCmpFactories()[i];
        }
        for (int i = 0; i < invListFieldCount; i++) {
            tupleCmpFactories[tokenFieldCount + i] = invIndex.getInvListCmpFactories()[i];
        }
        MultiComparator tupleCmp = MultiComparator.create(tupleCmpFactories);
        RangePredicate nullPred = new RangePredicate(null, null, true, true, tokenCmp, tokenCmp);
        // Helpers for generating a serialized inverted-list element from a CheckTuple from the expected index.
        ISerializerDeserializer[] fieldSerdes = testCtx.getFieldSerdes();
        ArrayTupleBuilder expectedBuilder = new ArrayTupleBuilder(fieldSerdes.length);
        ArrayTupleReference expectedTuple = new ArrayTupleReference();
        Iterator<CheckTuple> expectedIter = testCtx.getCheckTuples().iterator();
        // Compare index elements.
        invIndexAccessor.rangeSearch(invIndexCursor, nullPred);
        try {
            while (invIndexCursor.hasNext() && expectedIter.hasNext()) {
                invIndexCursor.next();
                ITupleReference actualTuple = invIndexCursor.getTuple();
                CheckTuple expected = expectedIter.next();
                OrderedIndexTestUtils.createTupleFromCheckTuple(expected, expectedBuilder, expectedTuple, fieldSerdes);
                if (tupleCmp.compare(actualTuple, expectedTuple) != 0) {
                    fail("Index entries differ for token '" + expected.getField(0) + "'.");
                }
            }
            if (expectedIter.hasNext()) {
                fail("Indexes do not match. Actual index is missing entries.");
            }
            if (invIndexCursor.hasNext()) {
                fail("Indexes do not match. Actual index contains too many entries.");
            }
        } finally {
            invIndexCursor.close();
        }
    } finally {
        invIndexCursor.destroy();
    }
}
#method_after
public static void compareActualAndExpectedIndexesRangeSearch(LSMInvertedIndexTestContext testCtx, IIndexCursor invIndexCursor) throws HyracksDataException {
    IInvertedIndex invIndex = (IInvertedIndex) testCtx.getIndex();
    int tokenFieldCount = invIndex.getTokenTypeTraits().length;
    int invListFieldCount = invIndex.getInvListTypeTraits().length;
    IInvertedIndexAccessor invIndexAccessor = (IInvertedIndexAccessor) invIndex.createAccessor(NoOpIndexAccessParameters.INSTANCE);
    try {
        MultiComparator tokenCmp = MultiComparator.create(invIndex.getTokenCmpFactories());
        IBinaryComparatorFactory[] tupleCmpFactories = new IBinaryComparatorFactory[tokenFieldCount + invListFieldCount];
        for (int i = 0; i < tokenFieldCount; i++) {
            tupleCmpFactories[i] = invIndex.getTokenCmpFactories()[i];
        }
        for (int i = 0; i < invListFieldCount; i++) {
            tupleCmpFactories[tokenFieldCount + i] = invIndex.getInvListCmpFactories()[i];
        }
        MultiComparator tupleCmp = MultiComparator.create(tupleCmpFactories);
        RangePredicate nullPred = new RangePredicate(null, null, true, true, tokenCmp, tokenCmp);
        // Helpers for generating a serialized inverted-list element from a CheckTuple from the expected index.
        ISerializerDeserializer[] fieldSerdes = testCtx.getFieldSerdes();
        ArrayTupleBuilder expectedBuilder = new ArrayTupleBuilder(fieldSerdes.length);
        ArrayTupleReference expectedTuple = new ArrayTupleReference();
        Iterator<CheckTuple> expectedIter = testCtx.getCheckTuples().iterator();
        // Compare index elements.
        invIndexAccessor.rangeSearch(invIndexCursor, nullPred);
        try {
            while (invIndexCursor.hasNext() && expectedIter.hasNext()) {
                invIndexCursor.next();
                ITupleReference actualTuple = invIndexCursor.getTuple();
                CheckTuple expected = expectedIter.next();
                OrderedIndexTestUtils.createTupleFromCheckTuple(expected, expectedBuilder, expectedTuple, fieldSerdes);
                if (tupleCmp.compare(actualTuple, expectedTuple) != 0) {
                    fail("Index entries differ for token '" + expected.getField(0) + "'.");
                }
            }
            if (expectedIter.hasNext()) {
                fail("Indexes do not match. Actual index is missing entries.");
            }
            if (invIndexCursor.hasNext()) {
                fail("Indexes do not match. Actual index contains too many entries.");
            }
        } finally {
            invIndexCursor.close();
        }
    } finally {
        invIndexCursor.destroy();
    }
}
#end_block

#method_before
@Override
public FunctionId getFunctionId() {
    return FunctionId.DISTRIBUTE_JOB;
}
#method_after
@Override
public FunctionId getFunctionId() {
    return FunctionId.DEPLOY_JOB;
}
#end_block

#method_before
@Override
public FunctionId getFunctionId() {
    return FunctionId.DESTROY_JOB;
}
#method_after
@Override
public FunctionId getFunctionId() {
    return FunctionId.UNDEPLOY_JOB;
}
#end_block

#method_before
@Override
public void doRun() {
    try {
        Status status = ccs.getDatasetDirectoryService().getResultStatus(jobId, rsId);
        callback.setValue(status);
    } catch (HyracksDataException e) {
        callback.setException(e);
    }
}
#method_after
@Override
public void doRun() {
    try {
        Status status = ccs.getResultDirectoryService().getResultStatus(jobId, rsId);
        callback.setValue(status);
    } catch (HyracksDataException e) {
        callback.setException(e);
    }
}
#end_block

#method_before
@Override
public int read(IFrame frame) throws HyracksDataException {
    frame.reset();
    int readSize = 0;
    if (isFirstRead() && !hasNextRecord()) {
        return readSize;
    }
    // read until frame is full or all dataset records have been read
    while (readSize < frame.getFrameSize()) {
        if (currentRecordMonitor.hasMoreFrames()) {
            final ByteBuffer readBuffer = currentRecordChannel.getNextBuffer();
            if (readBuffer == null) {
                throw new IllegalStateException("Unexpected empty frame");
            }
            currentRecordMonitor.notifyFrameRead();
            if (readSize == 0) {
                final int nBlocks = FrameHelper.deserializeNumOfMinFrame(readBuffer);
                frame.ensureFrameSize(frame.getMinSize() * nBlocks);
                frame.getBuffer().clear();
            }
            frame.getBuffer().put(readBuffer);
            currentRecordChannel.recycleBuffer(readBuffer);
            readSize = frame.getBuffer().position();
        } else {
            currentRecordChannel.close();
            if (currentRecordMonitor.failed()) {
                throw HyracksDataException.create(ErrorCode.FAILED_TO_READ_RESULT, jobId);
            }
            if (isLastRecord() || !hasNextRecord()) {
                break;
            }
        }
    }
    frame.getBuffer().flip();
    return readSize;
}
#method_after
@Override
public int read(IFrame frame) throws HyracksDataException {
    frame.reset();
    int readSize = 0;
    if (isFirstRead() && !hasNextRecord()) {
        return readSize;
    }
    // read until frame is full or all result records have been read
    while (readSize < frame.getFrameSize()) {
        if (currentRecordMonitor.hasMoreFrames()) {
            final ByteBuffer readBuffer = currentRecordChannel.getNextBuffer();
            if (readBuffer == null) {
                throw new IllegalStateException("Unexpected empty frame");
            }
            currentRecordMonitor.notifyFrameRead();
            if (readSize == 0) {
                final int nBlocks = FrameHelper.deserializeNumOfMinFrame(readBuffer);
                frame.ensureFrameSize(frame.getMinSize() * nBlocks);
                frame.getBuffer().clear();
            }
            frame.getBuffer().put(readBuffer);
            currentRecordChannel.recycleBuffer(readBuffer);
            readSize = frame.getBuffer().position();
        } else {
            currentRecordChannel.close();
            if (currentRecordMonitor.failed()) {
                throw HyracksDataException.create(ErrorCode.FAILED_TO_READ_RESULT, jobId);
            }
            if (isLastRecord() || !hasNextRecord()) {
                break;
            }
        }
    }
    frame.getBuffer().flip();
    return readSize;
}
#end_block

#method_before
private void requestRecordData(ResultDirectoryRecord record) throws HyracksDataException {
    currentRecordChannel = new DatasetNetworkInputChannel(netManager, getSocketAddress(record), jobId, resultSetId, currentRecord, NUM_READ_BUFFERS);
    currentRecordMonitor = getMonitor(currentRecord);
    currentRecordChannel.registerMonitor(currentRecordMonitor);
    currentRecordChannel.open(resultClientCtx);
}
#method_after
private void requestRecordData(ResultDirectoryRecord record) throws HyracksDataException {
    currentRecordChannel = new ResultNetworkInputChannel(netManager, getSocketAddress(record), jobId, resultSetId, currentRecord, NUM_READ_BUFFERS);
    currentRecordMonitor = getMonitor(currentRecord);
    currentRecordChannel.registerMonitor(currentRecordMonitor);
    currentRecordChannel.open(resultClientCtx);
}
#end_block

#method_before
@Override
public synchronized void notifyFailure(IInputChannel channel) {
    failed = true;
    notifyAll();
}
#method_after
@Override
public synchronized void notifyFailure(IInputChannel channel, int errorCode) {
    failed = true;
    notifyAll();
}
#end_block

#method_before
private void init() {
    datasetPartitionManager = new ResultPartitionManager(this, executor, ncConfig.getResultManagerMemory(), ncConfig.getResultTTL(), ncConfig.getResultSweepThreshold());
    datasetNetworkManager = new DatasetNetworkManager(ncConfig.getResultListenAddress(), ncConfig.getResultListenPort(), datasetPartitionManager, ncConfig.getNetThreadCount(), ncConfig.getNetBufferCount(), ncConfig.getResultPublicAddress(), ncConfig.getResultPublicPort(), FullFrameChannelInterfaceFactory.INSTANCE);
    if (ncConfig.getMessagingListenAddress() != null && serviceCtx.getMessagingChannelInterfaceFactory() != null) {
        messagingNetManager = new MessagingNetworkManager(this, ncConfig.getMessagingListenAddress(), ncConfig.getMessagingListenPort(), ncConfig.getNetThreadCount(), ncConfig.getMessagingPublicAddress(), ncConfig.getMessagingPublicPort(), serviceCtx.getMessagingChannelInterfaceFactory());
    }
}
#method_after
private void init() {
    resultPartitionManager = new ResultPartitionManager(this, executor, ncConfig.getResultManagerMemory(), ncConfig.getResultTTL(), ncConfig.getResultSweepThreshold());
    resultNetworkManager = new ResultNetworkManager(ncConfig.getResultListenAddress(), ncConfig.getResultListenPort(), resultPartitionManager, ncConfig.getNetThreadCount(), ncConfig.getNetBufferCount(), ncConfig.getResultPublicAddress(), ncConfig.getResultPublicPort(), FullFrameChannelInterfaceFactory.INSTANCE);
    if (ncConfig.getMessagingListenAddress() != null && serviceCtx.getMessagingChannelInterfaceFactory() != null) {
        messagingNetManager = new MessagingNetworkManager(this, ncConfig.getMessagingListenAddress(), ncConfig.getMessagingListenPort(), ncConfig.getNetThreadCount(), ncConfig.getMessagingPublicAddress(), ncConfig.getMessagingPublicPort(), serviceCtx.getMessagingChannelInterfaceFactory());
    }
}
#end_block

#method_before
@Override
public void start() throws Exception {
    LOGGER.log(Level.INFO, "Starting NodeControllerService");
    ipc = new IPCSystem(new InetSocketAddress(ncConfig.getClusterListenAddress(), ncConfig.getClusterListenPort()), new NodeControllerIPCI(this), new CCNCFunctions.SerializerDeserializer());
    ipc.start();
    partitionManager = new PartitionManager(this);
    netManager = new NetworkManager(ncConfig.getDataListenAddress(), ncConfig.getDataListenPort(), partitionManager, ncConfig.getNetThreadCount(), ncConfig.getNetBufferCount(), ncConfig.getDataPublicAddress(), ncConfig.getDataPublicPort(), FullFrameChannelInterfaceFactory.INSTANCE);
    netManager.start();
    startApplication();
    init();
    datasetNetworkManager.start();
    if (messagingNetManager != null) {
        messagingNetManager.start();
    }
    initNodeControllerState();
    hbTask = new HeartbeatComputeTask(this);
    primaryCcId = addCc(new InetSocketAddress(ncConfig.getClusterAddress(), ncConfig.getClusterPort()));
    workQueue.start();
    // Schedule heartbeat data updates
    timer.schedule(hbTask, HEARTBEAT_REFRESH_MILLIS, HEARTBEAT_REFRESH_MILLIS);
    // Schedule tracing a human-readable datetime
    timer.schedule(new TraceCurrentTimeTask(serviceCtx.getTracer()), 0, 60000);
    LOGGER.log(Level.INFO, "Started NodeControllerService");
    application.startupCompleted();
}
#method_after
@Override
public void start() throws Exception {
    LOGGER.log(Level.INFO, "Starting NodeControllerService");
    ipc = new IPCSystem(new InetSocketAddress(ncConfig.getClusterListenAddress(), ncConfig.getClusterListenPort()), new NodeControllerIPCI(this), new CCNCFunctions.SerializerDeserializer());
    ipc.start();
    partitionManager = new PartitionManager(this);
    netManager = new NetworkManager(ncConfig.getDataListenAddress(), ncConfig.getDataListenPort(), partitionManager, ncConfig.getNetThreadCount(), ncConfig.getNetBufferCount(), ncConfig.getDataPublicAddress(), ncConfig.getDataPublicPort(), FullFrameChannelInterfaceFactory.INSTANCE);
    netManager.start();
    startApplication();
    init();
    resultNetworkManager.start();
    if (messagingNetManager != null) {
        messagingNetManager.start();
    }
    initNodeControllerState();
    hbTask = new HeartbeatComputeTask(this);
    primaryCcId = addCc(new InetSocketAddress(ncConfig.getClusterAddress(), ncConfig.getClusterPort()));
    workQueue.start();
    // Schedule heartbeat data updates
    timer.schedule(hbTask, HEARTBEAT_REFRESH_MILLIS, HEARTBEAT_REFRESH_MILLIS);
    // Schedule tracing a human-readable datetime
    timer.schedule(new TraceCurrentTimeTask(serviceCtx.getTracer()), 0, 60000);
    LOGGER.log(Level.INFO, "Started NodeControllerService");
    application.startupCompleted();
}
#end_block

#method_before
private void initNodeControllerState() {
    // Use "public" versions of network addresses and ports, if defined
    InetSocketAddress ncAddress;
    if (ncConfig.getClusterPublicPort() == 0) {
        ncAddress = ipc.getSocketAddress();
    } else {
        ncAddress = new InetSocketAddress(ncConfig.getClusterPublicAddress(), ncConfig.getClusterPublicPort());
    }
    HeartbeatSchema.GarbageCollectorInfo[] gcInfos = new HeartbeatSchema.GarbageCollectorInfo[gcMXBeans.size()];
    for (int i = 0; i < gcInfos.length; ++i) {
        gcInfos[i] = new HeartbeatSchema.GarbageCollectorInfo(gcMXBeans.get(i).getName());
    }
    HeartbeatSchema hbSchema = new HeartbeatSchema(gcInfos);
    NetworkAddress datasetAddress = datasetNetworkManager.getPublicNetworkAddress();
    NetworkAddress netAddress = netManager.getPublicNetworkAddress();
    NetworkAddress messagingAddress = messagingNetManager != null ? messagingNetManager.getPublicNetworkAddress() : null;
    nodeRegistration = new NodeRegistration(ncAddress, id, ncConfig, netAddress, datasetAddress, osMXBean.getName(), osMXBean.getArch(), osMXBean.getVersion(), osMXBean.getAvailableProcessors(), runtimeMXBean.getVmName(), runtimeMXBean.getVmVersion(), runtimeMXBean.getVmVendor(), runtimeMXBean.getClassPath(), runtimeMXBean.getLibraryPath(), runtimeMXBean.getBootClassPath(), runtimeMXBean.getInputArguments(), runtimeMXBean.getSystemProperties(), hbSchema, messagingAddress, application.getCapacity(), PidHelper.getPid());
    ncData = new NodeControllerData(nodeRegistration);
}
#method_after
private void initNodeControllerState() {
    // Use "public" versions of network addresses and ports, if defined
    InetSocketAddress ncAddress;
    if (ncConfig.getClusterPublicPort() == 0) {
        ncAddress = ipc.getSocketAddress();
    } else {
        ncAddress = new InetSocketAddress(ncConfig.getClusterPublicAddress(), ncConfig.getClusterPublicPort());
    }
    HeartbeatSchema.GarbageCollectorInfo[] gcInfos = new HeartbeatSchema.GarbageCollectorInfo[gcMXBeans.size()];
    for (int i = 0; i < gcInfos.length; ++i) {
        gcInfos[i] = new HeartbeatSchema.GarbageCollectorInfo(gcMXBeans.get(i).getName());
    }
    HeartbeatSchema hbSchema = new HeartbeatSchema(gcInfos);
    NetworkAddress resultAddress = resultNetworkManager.getPublicNetworkAddress();
    NetworkAddress netAddress = netManager.getPublicNetworkAddress();
    NetworkAddress messagingAddress = messagingNetManager != null ? messagingNetManager.getPublicNetworkAddress() : null;
    nodeRegistration = new NodeRegistration(ncAddress, id, ncConfig, netAddress, resultAddress, hbSchema, messagingAddress, application.getCapacity());
    ncData = new NodeControllerData(nodeRegistration);
}
#end_block

#method_before
public CcId addCc(InetSocketAddress ccAddress) throws Exception {
    synchronized (ccLock) {
        LOGGER.info("addCc: {}", ccAddress);
        if (ccAddress.isUnresolved()) {
            throw new IllegalArgumentException("must use resolved InetSocketAddress");
        }
        if (ccAddressMap.containsKey(ccAddress)) {
            throw new IllegalStateException("cc already registered: " + ccAddress);
        }
        final IIPCEventListener ipcEventListener = new IIPCEventListener() {

            @Override
            public void ipcHandleRestored(IIPCHandle handle) throws IPCException {
                // we need to re-register in case of NC -> CC connection reset
                try {
                    registerNode(getCcConnection(ccAddressMap.get(ccAddress)), ccAddress);
                } catch (Exception e) {
                    LOGGER.log(Level.WARN, "Failed Registering with cc", e);
                    throw new IPCException(e);
                }
            }
        };
        ClusterControllerRemoteProxy ccProxy = new ClusterControllerRemoteProxy(ipc.getHandle(ccAddress, ncConfig.getClusterConnectRetries(), 1, ipcEventListener));
        CcConnection ccc = new CcConnection(ccProxy);
        return registerNode(ccc, ccAddress);
    }
}
#method_after
public CcId addCc(InetSocketAddress ccAddress) throws Exception {
    synchronized (ccLock) {
        LOGGER.info("addCc: {}", ccAddress);
        if (ccAddress.isUnresolved()) {
            throw new IllegalArgumentException("must use resolved InetSocketAddress");
        }
        if (ccAddressMap.containsKey(ccAddress)) {
            throw new IllegalStateException("cc already registered: " + ccAddress);
        }
        final IIPCEventListener ipcEventListener = new IIPCEventListener() {

            @Override
            public void ipcHandleRestored(IIPCHandle handle) throws IPCException {
                // we need to re-register in case of NC -> CC connection reset
                final CcConnection ccConnection = getCcConnection(ccAddressMap.get(ccAddress));
                try {
                    ccConnection.notifyConnectionRestored(NodeControllerService.this, ccAddress);
                } catch (InterruptedException e) {
                    Thread.currentThread().interrupt();
                    throw new IPCException(e);
                }
            }
        };
        ClusterControllerRemoteProxy ccProxy = new ClusterControllerRemoteProxy(ipc.getHandle(ccAddress, ncConfig.getClusterConnectRetries(), 1, ipcEventListener));
        return registerNode(new CcConnection(ccProxy), ccAddress);
    }
}
#end_block

#method_before
private CcId registerNode(CcConnection ccc, InetSocketAddress ccAddress) throws Exception {
    LOGGER.info("Registering with Cluster Controller {}", ccc);
    int registrationId = nextRegistrationId.incrementAndGet();
    pendingRegistrations.put(registrationId, ccc);
    CcId ccId = ccc.registerNode(nodeRegistration, registrationId);
    ccMap.put(ccId, ccc);
    ccAddressMap.put(ccAddress, ccId);
    Serializable distributedState = ccc.getNodeParameters().getDistributedState();
    if (distributedState != null) {
        getDistributedState().put(ccId, distributedState);
    }
    application.onRegisterNode(ccId);
    IClusterController ccs = ccc.getClusterControllerService();
    NodeParameters nodeParameters = ccc.getNodeParameters();
    // Start heartbeat generator.
    if (!heartbeatThreads.containsKey(ccId)) {
        Thread heartbeatThread = new Thread(new HeartbeatTask(getId(), hbTask.getHeartbeatData(), ccs, nodeParameters.getHeartbeatPeriod()), id + "-Heartbeat");
        heartbeatThread.setPriority(Thread.MAX_PRIORITY);
        heartbeatThread.setDaemon(true);
        heartbeatThread.start();
        heartbeatThreads.put(ccId, heartbeatThread);
    }
    if (!ccTimers.containsKey(ccId) && nodeParameters.getProfileDumpPeriod() > 0) {
        Timer ccTimer = new Timer("Timer-" + ccId, true);
        // Schedule profile dump generator.
        ccTimer.schedule(new ProfileDumpTask(ccs, ccId), 0, nodeParameters.getProfileDumpPeriod());
        ccTimers.put(ccId, ccTimer);
    }
    LOGGER.info("Registering with Cluster Controller {} complete", ccc);
    return ccId;
}
#method_after
public CcId registerNode(CcConnection ccc, InetSocketAddress ccAddress) throws Exception {
    LOGGER.info("Registering with Cluster Controller {}", ccc);
    int registrationId = nextRegistrationId.incrementAndGet();
    pendingRegistrations.put(registrationId, ccc);
    CcId ccId = ccc.registerNode(nodeRegistration, registrationId);
    ccMap.put(ccId, ccc);
    ccAddressMap.put(ccAddress, ccId);
    Serializable distributedState = ccc.getNodeParameters().getDistributedState();
    if (distributedState != null) {
        getDistributedState().put(ccId, distributedState);
    }
    IClusterController ccs = ccc.getClusterControllerService();
    NodeParameters nodeParameters = ccc.getNodeParameters();
    // Start heartbeat generator.
    if (!heartbeatThreads.containsKey(ccId)) {
        Thread heartbeatThread = new Thread(new HeartbeatTask(getId(), hbTask.getHeartbeatData(), ccs, nodeParameters.getHeartbeatPeriod()), id + "-Heartbeat");
        heartbeatThread.setPriority(Thread.MAX_PRIORITY);
        heartbeatThread.setDaemon(true);
        heartbeatThread.start();
        heartbeatThreads.put(ccId, heartbeatThread);
    }
    if (!ccTimers.containsKey(ccId) && nodeParameters.getProfileDumpPeriod() > 0) {
        Timer ccTimer = new Timer("Timer-" + ccId, true);
        // Schedule profile dump generator.
        ccTimer.schedule(new ProfileDumpTask(ccs, ccId), 0, nodeParameters.getProfileDumpPeriod());
        ccTimers.put(ccId, ccTimer);
    }
    ccc.notifyRegistrationCompleted();
    LOGGER.info("Registering with Cluster Controller {} completed", ccc);
    return ccId;
}
#end_block

#method_before
private ConcurrentHashMap<CcId, Serializable> getDistributedState() {
    // noinspection unchecked
    return (ConcurrentHashMap<CcId, Serializable>) serviceCtx.getDistributedState();
}
#method_after
private ConcurrentHashMap<CcId, Serializable> getDistributedState() {
    return (ConcurrentHashMap<CcId, Serializable>) serviceCtx.getDistributedState();
}
#end_block

#method_before
@Override
public synchronized void stop() throws Exception {
    if (shutdownCallStack == null) {
        shutdownCallStack = new Throwable().getStackTrace();
        LOGGER.log(Level.INFO, "Stopping NodeControllerService");
        application.preStop();
        executor.shutdownNow();
        if (!executor.awaitTermination(10, TimeUnit.SECONDS)) {
            LOGGER.log(Level.ERROR, "Some jobs failed to exit, continuing with abnormal shutdown");
        }
        partitionManager.close();
        datasetPartitionManager.close();
        netManager.stop();
        datasetNetworkManager.stop();
        if (messagingNetManager != null) {
            messagingNetManager.stop();
        }
        workQueue.stop();
        application.stop();
        /*
             * Stop heartbeats only after NC has stopped to avoid false node failure detection
             * on CC if an NC takes a long time to stop.
             */
        heartbeatThreads.values().parallelStream().forEach(t -> {
            t.interrupt();
            InvokeUtil.doUninterruptibly(() -> t.join(1000));
        });
        synchronized (ccLock) {
            ccMap.values().parallelStream().forEach(cc -> {
                try {
                    cc.getClusterControllerService().notifyShutdown(id);
                } catch (Exception e) {
                    LOGGER.log(Level.WARN, "Exception notifying CC of shutdown", e);
                }
            });
        }
        ipc.stop();
        ioManager.close();
        LOGGER.log(Level.INFO, "Stopped NodeControllerService");
    } else {
        LOGGER.log(Level.ERROR, "Duplicate shutdown call; original: " + Arrays.toString(shutdownCallStack), new Exception("Duplicate shutdown call"));
    }
    if (ncShutdownHook != null) {
        try {
            Runtime.getRuntime().removeShutdownHook(ncShutdownHook);
            LOGGER.info("removed shutdown hook for {}", id);
        } catch (IllegalStateException e) {
            LOGGER.log(Level.DEBUG, "ignoring exception while attempting to remove shutdown hook", e);
        }
    }
}
#method_after
@Override
public synchronized void stop() throws Exception {
    if (shutdownCallStack == null) {
        shutdownCallStack = new Throwable().getStackTrace();
        LOGGER.log(Level.INFO, "Stopping NodeControllerService");
        application.preStop();
        executor.shutdownNow();
        if (!executor.awaitTermination(10, TimeUnit.SECONDS)) {
            LOGGER.log(Level.ERROR, "Some jobs failed to exit, continuing with abnormal shutdown");
        }
        partitionManager.close();
        resultPartitionManager.close();
        netManager.stop();
        resultNetworkManager.stop();
        if (messagingNetManager != null) {
            messagingNetManager.stop();
        }
        workQueue.stop();
        application.stop();
        /*
             * Stop heartbeats only after NC has stopped to avoid false node failure detection
             * on CC if an NC takes a long time to stop.
             */
        heartbeatThreads.values().parallelStream().forEach(t -> {
            t.interrupt();
            InvokeUtil.doUninterruptibly(() -> t.join(1000));
        });
        synchronized (ccLock) {
            ccMap.values().parallelStream().forEach(cc -> {
                try {
                    cc.getClusterControllerService().notifyShutdown(id);
                } catch (Exception e) {
                    LOGGER.log(Level.WARN, "Exception notifying CC of shutdown", e);
                }
            });
        }
        ipc.stop();
        ioManager.close();
        LOGGER.log(Level.INFO, "Stopped NodeControllerService");
    } else {
        LOGGER.log(Level.ERROR, "Duplicate shutdown call; original: " + Arrays.toString(shutdownCallStack), new Exception("Duplicate shutdown call"));
    }
    if (ncShutdownHook != null) {
        try {
            Runtime.getRuntime().removeShutdownHook(ncShutdownHook);
            LOGGER.info("removed shutdown hook for {}", id);
        } catch (IllegalStateException e) {
            LOGGER.log(Level.DEBUG, "ignoring exception while attempting to remove shutdown hook", e);
        }
    }
}
#end_block

#method_before
public void storeActivityClusterGraph(DeployedJobSpecId deployedJobSpecId, ActivityClusterGraph acg) throws HyracksException {
    if (deployedJobSpecActivityClusterGraphMap.get(deployedJobSpecId.getId()) != null) {
        throw HyracksException.create(ErrorCode.DUPLICATE_DEPLOYED_JOB, deployedJobSpecId);
    }
    deployedJobSpecActivityClusterGraphMap.put(deployedJobSpecId.getId(), acg);
}
#method_after
public void storeActivityClusterGraph(DeployedJobSpecId deployedJobSpecId, ActivityClusterGraph acg) throws HyracksException {
    deployedJobSpecActivityClusterGraphMap.put(deployedJobSpecId.getId(), acg);
}
#end_block

#method_before
private static INCApplication getApplication(NCConfig config) throws ClassNotFoundException, IllegalAccessException, InstantiationException {
    if (config.getAppClass() != null) {
        Class<?> c = Class.forName(config.getAppClass());
        return (INCApplication) c.newInstance();
    } else {
        return BaseNCApplication.INSTANCE;
    }
}
#method_after
public INCApplication getApplication() {
    return application;
}
#end_block

#method_before
@Test
public void optimizedSortMergeTest01() throws Exception {
    JobSpecification spec = new JobSpecification();
    FileSplit[] ordersSplits = new FileSplit[] { new ManagedFileSplit(NC1_ID, "data" + File.separator + "tpch0.001" + File.separator + "orders-part1.tbl"), new ManagedFileSplit(NC2_ID, "data" + File.separator + "tpch0.001" + File.separator + "orders-part2.tbl") };
    IFileSplitProvider ordersSplitProvider = new ConstantFileSplitProvider(ordersSplits);
    RecordDescriptor ordersDesc = new RecordDescriptor(new ISerializerDeserializer[] { new UTF8StringSerializerDeserializer(), new UTF8StringSerializerDeserializer(), new UTF8StringSerializerDeserializer(), new UTF8StringSerializerDeserializer(), new UTF8StringSerializerDeserializer(), new UTF8StringSerializerDeserializer(), new UTF8StringSerializerDeserializer(), new UTF8StringSerializerDeserializer(), new UTF8StringSerializerDeserializer() });
    FileScanOperatorDescriptor ordScanner = new FileScanOperatorDescriptor(spec, ordersSplitProvider, new DelimitedDataTupleParserFactory(new IValueParserFactory[] { UTF8StringParserFactory.INSTANCE, UTF8StringParserFactory.INSTANCE, UTF8StringParserFactory.INSTANCE, UTF8StringParserFactory.INSTANCE, UTF8StringParserFactory.INSTANCE, UTF8StringParserFactory.INSTANCE, UTF8StringParserFactory.INSTANCE, UTF8StringParserFactory.INSTANCE, UTF8StringParserFactory.INSTANCE }, '|'), ordersDesc);
    PartitionConstraintHelper.addAbsoluteLocationConstraint(spec, ordScanner, NC1_ID, NC2_ID);
    // larger than the total record numbers.
    int outputLimit = 5;
    TopKSorterOperatorDescriptor sorter = new TopKSorterOperatorDescriptor(spec, 4, outputLimit, new int[] { 1, 0 }, (INormalizedKeyComputerFactory) null, new IBinaryComparatorFactory[] { PointableBinaryComparatorFactory.of(UTF8StringPointable.FACTORY), PointableBinaryComparatorFactory.of(UTF8StringPointable.FACTORY) }, ordersDesc);
    PartitionConstraintHelper.addAbsoluteLocationConstraint(spec, sorter, NC1_ID, NC2_ID);
    ResultSetId rsId = new ResultSetId(1);
    spec.addResultSetId(rsId);
    FileSplit fs = createFile(nc1);
    IFileSplitProvider outputSplitProvider = new ConstantFileSplitProvider(new FileSplit[] { fs });
    IOperatorDescriptor printer = new PlainFileWriterOperatorDescriptor(spec, outputSplitProvider, "|");
    PartitionConstraintHelper.addAbsoluteLocationConstraint(spec, printer, NC1_ID);
    spec.connect(new OneToOneConnectorDescriptor(spec), ordScanner, 0, sorter, 0);
    spec.connect(new MToNPartitioningMergingConnectorDescriptor(spec, new FieldHashPartitionComputerFactory(new int[] { 1, 0 }, new IBinaryHashFunctionFactory[] { PointableBinaryHashFunctionFactory.of(UTF8StringPointable.FACTORY), PointableBinaryHashFunctionFactory.of(UTF8StringPointable.FACTORY) }), new int[] { 1, 0 }, new IBinaryComparatorFactory[] { PointableBinaryComparatorFactory.of(UTF8StringPointable.FACTORY), PointableBinaryComparatorFactory.of(UTF8StringPointable.FACTORY) }, new UTF8StringNormalizedKeyComputerFactory()), sorter, 0, printer, 0);
    runTest(spec);
    System.out.println("ResultSet write into :" + fs.getPath() + " in node: " + fs.getNodeName());
}
#method_after
@Test
public void optimizedSortMergeTest01() throws Exception {
    JobSpecification spec = new JobSpecification();
    FileSplit[] ordersSplits = new FileSplit[] { new ManagedFileSplit(NC1_ID, "data" + File.separator + "tpch0.001" + File.separator + "orders-part1.tbl"), new ManagedFileSplit(NC2_ID, "data" + File.separator + "tpch0.001" + File.separator + "orders-part2.tbl") };
    IFileSplitProvider ordersSplitProvider = new ConstantFileSplitProvider(ordersSplits);
    RecordDescriptor ordersDesc = new RecordDescriptor(new ISerializerDeserializer[] { new UTF8StringSerializerDeserializer(), new UTF8StringSerializerDeserializer(), new UTF8StringSerializerDeserializer(), new UTF8StringSerializerDeserializer(), new UTF8StringSerializerDeserializer(), new UTF8StringSerializerDeserializer(), new UTF8StringSerializerDeserializer(), new UTF8StringSerializerDeserializer(), new UTF8StringSerializerDeserializer() });
    FileScanOperatorDescriptor ordScanner = new FileScanOperatorDescriptor(spec, ordersSplitProvider, new DelimitedDataTupleParserFactory(new IValueParserFactory[] { UTF8StringParserFactory.INSTANCE, UTF8StringParserFactory.INSTANCE, UTF8StringParserFactory.INSTANCE, UTF8StringParserFactory.INSTANCE, UTF8StringParserFactory.INSTANCE, UTF8StringParserFactory.INSTANCE, UTF8StringParserFactory.INSTANCE, UTF8StringParserFactory.INSTANCE, UTF8StringParserFactory.INSTANCE }, '|'), ordersDesc);
    PartitionConstraintHelper.addAbsoluteLocationConstraint(spec, ordScanner, NC1_ID, NC2_ID);
    // larger than the total record numbers.
    int outputLimit = 5;
    TopKSorterOperatorDescriptor sorter = new TopKSorterOperatorDescriptor(spec, 4, outputLimit, new int[] { 1, 0 }, (INormalizedKeyComputerFactory) null, new IBinaryComparatorFactory[] { PointableBinaryComparatorFactory.of(UTF8StringPointable.FACTORY), PointableBinaryComparatorFactory.of(UTF8StringPointable.FACTORY) }, ordersDesc);
    PartitionConstraintHelper.addAbsoluteLocationConstraint(spec, sorter, NC1_ID, NC2_ID);
    ResultSetId rsId = new ResultSetId(1);
    spec.addResultSetId(rsId);
    FileSplit fs = createFile(nc1);
    IFileSplitProvider outputSplitProvider = new ConstantFileSplitProvider(new FileSplit[] { fs });
    IOperatorDescriptor printer = new PlainFileWriterOperatorDescriptor(spec, outputSplitProvider, "|");
    PartitionConstraintHelper.addAbsoluteLocationConstraint(spec, printer, NC1_ID);
    spec.connect(new OneToOneConnectorDescriptor(spec), ordScanner, 0, sorter, 0);
    spec.connect(new MToNPartitioningMergingConnectorDescriptor(spec, new FieldHashPartitionComputerFactory(new int[] { 1, 0 }, new IBinaryHashFunctionFactory[] { PointableBinaryHashFunctionFactory.of(UTF8StringPointable.FACTORY), PointableBinaryHashFunctionFactory.of(UTF8StringPointable.FACTORY) }), new int[] { 1, 0 }, new IBinaryComparatorFactory[] { PointableBinaryComparatorFactory.of(UTF8StringPointable.FACTORY), PointableBinaryComparatorFactory.of(UTF8StringPointable.FACTORY) }, new UTF8StringNormalizedKeyComputerFactory()), sorter, 0, printer, 0);
    runTest(spec);
    System.out.println("Result write into :" + fs.getPath() + " in node: " + fs.getNodeName());
}
#end_block

#method_before
@Override
public IOperatorNodePushable createPushRuntime(final IHyracksTaskContext ctx, IRecordDescriptorProvider recordDescProvider, final int partition, final int nPartitions) throws HyracksDataException {
    final IResultPartitionManager dpm = ctx.getDatasetPartitionManager();
    final IFrame frame = new VSizeFrame(ctx);
    final FrameOutputStream frameOutputStream = new FrameOutputStream(ctx.getInitialFrameSize());
    frameOutputStream.reset(frame, true);
    PrintStream printStream = new PrintStream(frameOutputStream);
    final RecordDescriptor outRecordDesc = recordDescProvider.getInputRecordDescriptor(getActivityId(), 0);
    final IResultSerializer resultSerializer = resultSerializerFactory.createResultSerializer(outRecordDesc, printStream);
    final FrameTupleAccessor frameTupleAccessor = new FrameTupleAccessor(outRecordDesc);
    return new AbstractUnaryInputSinkOperatorNodePushable() {

        private IFrameWriter datasetPartitionWriter;

        private boolean failed = false;

        @Override
        public void open() throws HyracksDataException {
            try {
                datasetPartitionWriter = dpm.createDatasetPartitionWriter(ctx, rsId, ordered, asyncMode, partition, nPartitions, maxReads);
                datasetPartitionWriter.open();
                resultSerializer.init();
            } catch (HyracksException e) {
                throw HyracksDataException.create(e);
            }
        }

        @Override
        public void nextFrame(ByteBuffer buffer) throws HyracksDataException {
            frameTupleAccessor.reset(buffer);
            for (int tIndex = 0; tIndex < frameTupleAccessor.getTupleCount(); tIndex++) {
                resultSerializer.appendTuple(frameTupleAccessor, tIndex);
                if (!frameOutputStream.appendTuple()) {
                    frameOutputStream.flush(datasetPartitionWriter);
                    resultSerializer.appendTuple(frameTupleAccessor, tIndex);
                    frameOutputStream.appendTuple();
                }
            }
        }

        @Override
        public void fail() throws HyracksDataException {
            failed = true;
            if (datasetPartitionWriter != null) {
                datasetPartitionWriter.fail();
            }
        }

        @Override
        public void close() throws HyracksDataException {
            if (datasetPartitionWriter != null) {
                try {
                    if (!failed && frameOutputStream.getTupleCount() > 0) {
                        frameOutputStream.flush(datasetPartitionWriter);
                    }
                } catch (Exception e) {
                    datasetPartitionWriter.fail();
                    throw e;
                } finally {
                    datasetPartitionWriter.close();
                }
            }
        }

        @Override
        public String toString() {
            StringBuilder sb = new StringBuilder();
            sb.append("{ ");
            sb.append("\"rsId\": \"").append(rsId).append("\", ");
            sb.append("\"ordered\": ").append(ordered).append(", ");
            sb.append("\"asyncMode\": ").append(asyncMode).append(", ");
            sb.append("\"maxReads\": ").append(maxReads).append(" }");
            return sb.toString();
        }
    };
}
#method_after
@Override
public IOperatorNodePushable createPushRuntime(final IHyracksTaskContext ctx, IRecordDescriptorProvider recordDescProvider, final int partition, final int nPartitions) throws HyracksDataException {
    final IResultPartitionManager resultPartitionManager = ctx.getResultPartitionManager();
    final IFrame frame = new VSizeFrame(ctx);
    final FrameOutputStream frameOutputStream = new FrameOutputStream(ctx.getInitialFrameSize());
    frameOutputStream.reset(frame, true);
    PrintStream printStream = new PrintStream(frameOutputStream);
    final RecordDescriptor outRecordDesc = recordDescProvider.getInputRecordDescriptor(getActivityId(), 0);
    final IResultSerializer resultSerializer = resultSerializerFactory.createResultSerializer(outRecordDesc, printStream);
    final FrameTupleAccessor frameTupleAccessor = new FrameTupleAccessor(outRecordDesc);
    return new AbstractUnaryInputSinkOperatorNodePushable() {

        private IFrameWriter resultPartitionWriter;

        private boolean failed = false;

        @Override
        public void open() throws HyracksDataException {
            try {
                resultPartitionWriter = resultPartitionManager.createResultPartitionWriter(ctx, rsId, ordered, asyncMode, partition, nPartitions, maxReads);
                resultPartitionWriter.open();
                resultSerializer.init();
            } catch (HyracksException e) {
                throw HyracksDataException.create(e);
            }
        }

        @Override
        public void nextFrame(ByteBuffer buffer) throws HyracksDataException {
            frameTupleAccessor.reset(buffer);
            for (int tIndex = 0; tIndex < frameTupleAccessor.getTupleCount(); tIndex++) {
                resultSerializer.appendTuple(frameTupleAccessor, tIndex);
                if (!frameOutputStream.appendTuple()) {
                    frameOutputStream.flush(resultPartitionWriter);
                    resultSerializer.appendTuple(frameTupleAccessor, tIndex);
                    frameOutputStream.appendTuple();
                }
            }
        }

        @Override
        public void fail() throws HyracksDataException {
            failed = true;
            if (resultPartitionWriter != null) {
                resultPartitionWriter.fail();
            }
        }

        @Override
        public void close() throws HyracksDataException {
            if (resultPartitionWriter != null) {
                try {
                    if (!failed && frameOutputStream.getTupleCount() > 0) {
                        frameOutputStream.flush(resultPartitionWriter);
                    }
                } catch (Exception e) {
                    resultPartitionWriter.fail();
                    throw e;
                } finally {
                    resultPartitionWriter.close();
                }
            }
        }

        @Override
        public String toString() {
            StringBuilder sb = new StringBuilder();
            sb.append("{ ");
            sb.append("\"rsId\": \"").append(rsId).append("\", ");
            sb.append("\"ordered\": ").append(ordered).append(", ");
            sb.append("\"asyncMode\": ").append(asyncMode).append(", ");
            sb.append("\"maxReads\": ").append(maxReads).append(" }");
            return sb.toString();
        }
    };
}
#end_block

#method_before
protected JobId runTest(JobSpecification spec, String expectedErrorMessage) throws Exception {
    if (LOGGER.isInfoEnabled()) {
        LOGGER.info(spec.toJSON().asText());
    }
    JobId jobId = hcc.startJob(spec, EnumSet.of(JobFlag.PROFILE_RUNTIME));
    if (LOGGER.isInfoEnabled()) {
        LOGGER.info(jobId.toString());
    }
    int nReaders = 1;
    FrameManager resultDisplayFrameMgr = new FrameManager(spec.getFrameSize());
    VSizeFrame resultFrame = new VSizeFrame(resultDisplayFrameMgr);
    IFrameTupleAccessor frameTupleAccessor = new ResultFrameTupleAccessor();
    if (!spec.getResultSetIds().isEmpty()) {
        IResultSet hyracksDataset = new ResultSet(hcc, spec.getFrameSize(), nReaders);
        IResultSetReader reader = hyracksDataset.createReader(jobId, spec.getResultSetIds().get(0));
        ObjectMapper om = new ObjectMapper();
        ArrayNode resultRecords = om.createArrayNode();
        ByteBufferInputStream bbis = new ByteBufferInputStream();
        int readSize = reader.read(resultFrame);
        while (readSize > 0) {
            try {
                frameTupleAccessor.reset(resultFrame.getBuffer());
                for (int tIndex = 0; tIndex < frameTupleAccessor.getTupleCount(); tIndex++) {
                    int start = frameTupleAccessor.getTupleStartOffset(tIndex);
                    int length = frameTupleAccessor.getTupleEndOffset(tIndex) - start;
                    bbis.setByteBuffer(resultFrame.getBuffer(), start);
                    byte[] recordBytes = new byte[length];
                    bbis.read(recordBytes, 0, length);
                    resultRecords.add(new String(recordBytes, 0, length));
                }
            } finally {
                try {
                    bbis.close();
                } catch (IOException e) {
                    throw HyracksDataException.create(e);
                }
            }
            readSize = reader.read(resultFrame);
        }
    }
    waitForCompletion(jobId, expectedErrorMessage);
    // Waiting a second time should lead to the same behavior
    waitForCompletion(jobId, expectedErrorMessage);
    dumpOutputFiles();
    return jobId;
}
#method_after
protected JobId runTest(JobSpecification spec, String expectedErrorMessage) throws Exception {
    if (LOGGER.isInfoEnabled()) {
        LOGGER.info(spec.toJSON().asText());
    }
    JobId jobId = hcc.startJob(spec, EnumSet.of(JobFlag.PROFILE_RUNTIME));
    if (LOGGER.isInfoEnabled()) {
        LOGGER.info(jobId.toString());
    }
    int nReaders = 1;
    FrameManager resultDisplayFrameMgr = new FrameManager(spec.getFrameSize());
    VSizeFrame resultFrame = new VSizeFrame(resultDisplayFrameMgr);
    IFrameTupleAccessor frameTupleAccessor = new ResultFrameTupleAccessor();
    if (!spec.getResultSetIds().isEmpty()) {
        IResultSet resultSet = new ResultSet(hcc, spec.getFrameSize(), nReaders);
        IResultSetReader reader = resultSet.createReader(jobId, spec.getResultSetIds().get(0));
        ObjectMapper om = new ObjectMapper();
        ArrayNode resultRecords = om.createArrayNode();
        ByteBufferInputStream bbis = new ByteBufferInputStream();
        int readSize = reader.read(resultFrame);
        while (readSize > 0) {
            try {
                frameTupleAccessor.reset(resultFrame.getBuffer());
                for (int tIndex = 0; tIndex < frameTupleAccessor.getTupleCount(); tIndex++) {
                    int start = frameTupleAccessor.getTupleStartOffset(tIndex);
                    int length = frameTupleAccessor.getTupleEndOffset(tIndex) - start;
                    bbis.setByteBuffer(resultFrame.getBuffer(), start);
                    byte[] recordBytes = new byte[length];
                    bbis.read(recordBytes, 0, length);
                    resultRecords.add(new String(recordBytes, 0, length));
                }
            } finally {
                try {
                    bbis.close();
                } catch (IOException e) {
                    throw HyracksDataException.create(e);
                }
            }
            readSize = reader.read(resultFrame);
        }
    }
    waitForCompletion(jobId, expectedErrorMessage);
    // Waiting a second time should lead to the same behavior
    waitForCompletion(jobId, expectedErrorMessage);
    dumpOutputFiles();
    return jobId;
}
#end_block

#method_before
@Override
public void cancelJob(JobId jobId) throws Exception {
    hci.cancelJob(jobId);
}
#method_after
@Override
public void cancelJob(JobId jobId) throws Exception {
    CancelJobRequest request = new CancelJobRequest(jobId);
    uninterruptiblySubmitAndExecute(request);
}
#end_block

#method_before
@Override
public DeployedJobSpecId undeployJobSpec(DeployedJobSpecId deployedJobSpecId) throws Exception {
    return hci.undeployJobSpec(deployedJobSpecId);
}
#method_after
@Override
public void undeployJobSpec(DeployedJobSpecId deployedJobSpecId) throws Exception {
    hci.undeployJobSpec(deployedJobSpecId);
}
#end_block

#method_before
@Override
public JobId startJob(DeployedJobSpecId deployedJobSpecId, Map<byte[], byte[]> jobParameters) throws Exception {
    return hci.startJob(deployedJobSpecId, jobParameters);
}
#method_after
@Override
public JobId startJob(DeployedJobSpecId deployedJobSpecId, Map<byte[], byte[]> jobParameters) throws Exception {
    StartDeployedJobRequest request = new StartDeployedJobRequest(deployedJobSpecId, jobParameters);
    return interruptiblySubmitAndExecute(request);
}
#end_block

#method_before
@Override
public JobId startJob(IActivityClusterGraphGeneratorFactory acggf, EnumSet<JobFlag> jobFlags) throws Exception {
    return hci.startJob(JavaSerializationUtils.serialize(acggf), jobFlags);
}
#method_after
@Override
public JobId startJob(IActivityClusterGraphGeneratorFactory acggf, EnumSet<JobFlag> jobFlags) throws Exception {
    return startJob(null, acggf, jobFlags);
}
#end_block

#method_before
@Override
public NetworkAddress getResultDirectoryAddress() throws Exception {
    return hci.getDatasetDirectoryServiceInfo();
}
#method_after
@Override
public NetworkAddress getResultDirectoryAddress() throws Exception {
    return hci.getResultDirectoryAddress();
}
#end_block

#method_before
@Override
public void waitForCompletion(JobId jobId) throws Exception {
    try {
        hci.waitForCompletion(jobId);
    } catch (InterruptedException e) {
        // Cancels an on-going job if the current thread gets interrupted.
        hci.cancelJob(jobId);
        throw e;
    }
}
#method_after
@Override
public void waitForCompletion(JobId jobId) throws Exception {
    try {
        hci.waitForCompletion(jobId);
    } catch (InterruptedException e) {
        // Cancels an on-going job if the current thread gets interrupted.
        cancelJob(jobId);
        throw e;
    }
}
#end_block

#method_before
@Override
public Map<String, NodeControllerInfo> getNodeControllerInfos() throws HyracksException {
    try {
        return hci.getNodeControllersInfo();
    } catch (Exception e) {
        throw new HyracksException(e);
    }
}
#method_after
@Override
public Map<String, NodeControllerInfo> getNodeControllerInfos() throws HyracksException {
    try {
        return hci.getNodeControllersInfo();
    } catch (Exception e) {
        throw HyracksException.create(e);
    }
}
#end_block

#method_before
@Override
public ClusterTopology getClusterTopology() throws HyracksException {
    try {
        return hci.getClusterTopology();
    } catch (Exception e) {
        throw new HyracksException(e);
    }
}
#method_after
@Override
public ClusterTopology getClusterTopology() throws HyracksException {
    try {
        return hci.getClusterTopology();
    } catch (Exception e) {
        throw HyracksException.create(e);
    }
}
#end_block

#method_before
@Override
public JobId startJob(DeploymentId deploymentId, IActivityClusterGraphGeneratorFactory acggf, EnumSet<JobFlag> jobFlags) throws Exception {
    return hci.startJob(deploymentId, JavaSerializationUtils.serialize(acggf), jobFlags);
}
#method_after
@Override
public JobId startJob(DeploymentId deploymentId, IActivityClusterGraphGeneratorFactory acggf, EnumSet<JobFlag> jobFlags) throws Exception {
    StartJobRequest request = new StartJobRequest(deploymentId, acggf, jobFlags);
    return interruptiblySubmitAndExecute(request);
}
#end_block

#method_before
@Override
public Status getResultStatus(JobId jobId, ResultSetId rsId) throws Exception {
    HyracksClientInterfaceFunctions.GetDatasetResultStatusFunction gdrlf = new HyracksClientInterfaceFunctions.GetDatasetResultStatusFunction(jobId, rsId);
    return (Status) rpci.call(ipcHandle, gdrlf);
}
#method_after
@Override
public Status getResultStatus(JobId jobId, ResultSetId rsId) throws Exception {
    HyracksClientInterfaceFunctions.GetResultStatusFunction gdrlf = new HyracksClientInterfaceFunctions.GetResultStatusFunction(jobId, rsId);
    return (Status) rpci.call(ipcHandle, gdrlf);
}
#end_block

#method_before
@Override
public ResultDirectoryRecord[] getResultLocations(JobId jobId, ResultSetId rsId, ResultDirectoryRecord[] knownRecords) throws Exception {
    HyracksClientInterfaceFunctions.GetDatasetResultLocationsFunction gdrlf = new HyracksClientInterfaceFunctions.GetDatasetResultLocationsFunction(jobId, rsId, knownRecords);
    return (ResultDirectoryRecord[]) rpci.call(ipcHandle, gdrlf);
}
#method_after
@Override
public ResultDirectoryRecord[] getResultLocations(JobId jobId, ResultSetId rsId, ResultDirectoryRecord[] knownRecords) throws Exception {
    HyracksClientInterfaceFunctions.GetResultLocationsFunction gdrlf = new HyracksClientInterfaceFunctions.GetResultLocationsFunction(jobId, rsId, knownRecords);
    return (ResultDirectoryRecord[]) rpci.call(ipcHandle, gdrlf);
}
#end_block

#method_before
@Override
public void doRun() {
    final IResultDirectoryService dds = ccs.getDatasetDirectoryService();
    ccs.getExecutor().execute(new Runnable() {

        @Override
        public void run() {
            try {
                dds.getResultPartitionLocations(jobId, rsId, knownRecords, callback);
            } catch (HyracksDataException e) {
                callback.setException(e);
            }
        }
    });
}
#method_after
@Override
public void doRun() {
    final IResultDirectoryService dds = ccs.getResultDirectoryService();
    ccs.getExecutor().execute(new Runnable() {

        @Override
        public void run() {
            try {
                dds.getResultPartitionLocations(jobId, rsId, knownRecords, callback);
            } catch (HyracksDataException e) {
                callback.setException(e);
            }
        }
    });
}
#end_block

#method_before
@Override
protected void doRun() throws Exception {
    LOGGER.info("Aborting all tasks for controller {}", ccId);
    IResultPartitionManager dpm = ncs.getDatasetPartitionManager();
    if (dpm == null) {
        LOGGER.log(Level.WARN, "ResultPartitionManager is null on " + ncs.getId());
    }
    Collection<Joblet> joblets = ncs.getJobletMap().values();
    // TODO(mblow): should we have one jobletmap per cc?
    joblets.stream().filter(joblet -> joblet.getJobId().getCcId().equals(ccId)).forEach(joblet -> {
        Collection<Task> tasks = joblet.getTaskMap().values();
        for (Task task : tasks) {
            task.abort();
        }
        final JobId jobId = joblet.getJobId();
        if (dpm != null) {
            dpm.abortReader(jobId);
            dpm.sweep(jobId);
        }
        ncs.getWorkQueue().schedule(new CleanupJobletWork(ncs, jobId, JobStatus.FAILURE));
    });
}
#method_after
@Override
protected void doRun() throws Exception {
    LOGGER.info("Aborting all tasks for controller {}", ccId);
    IResultPartitionManager resultPartitionManager = ncs.getResultPartitionManager();
    if (resultPartitionManager == null) {
        LOGGER.log(Level.WARN, "ResultPartitionManager is null on " + ncs.getId());
    }
    Deque<Task> abortedTasks = new ArrayDeque<>();
    Collection<Joblet> joblets = ncs.getJobletMap().values();
    // TODO(mblow): should we have one jobletmap per cc?
    joblets.stream().filter(joblet -> joblet.getJobId().getCcId().equals(ccId)).forEach(joblet -> {
        joblet.getTaskMap().values().forEach(task -> {
            task.abort();
            abortedTasks.add(task);
        });
        final JobId jobId = joblet.getJobId();
        if (resultPartitionManager != null) {
            resultPartitionManager.abortReader(jobId);
            resultPartitionManager.sweep(jobId);
        }
        ncs.getWorkQueue().schedule(new CleanupJobletWork(ncs, jobId, JobStatus.FAILURE));
    });
    ncs.getExecutor().submit(new EnsureAllCcTasksCompleted(ncs, ccId, abortedTasks));
}
#end_block

#method_before
@Override
protected void get(IServletRequest request, IServletResponse response) throws Exception {
    final String strHandle = localPath(request);
    final ResultHandle handle = ResultHandle.parse(strHandle);
    if (handle == null) {
        response.setStatus(HttpResponseStatus.BAD_REQUEST);
        return;
    }
    IResultSet hds = getHyracksDataset();
    ResultReader resultReader = new ResultReader(hds, handle.getJobId(), handle.getResultSetId());
    final ResultJobRecord.Status resultReaderStatus = resultReader.getStatus();
    if (resultReaderStatus == null) {
        LOGGER.log(Level.INFO, "No results for: \"" + strHandle + "\"");
        response.setStatus(HttpResponseStatus.NOT_FOUND);
        return;
    }
    ResultStatus resultStatus = resultStatus(resultReaderStatus);
    Exception ex = extractException(resultReaderStatus);
    final StringWriter stringWriter = new StringWriter();
    final PrintWriter resultWriter = new PrintWriter(stringWriter);
    HttpUtil.setContentType(response, HttpUtil.ContentType.APPLICATION_JSON, HttpUtil.Encoding.UTF8);
    HttpResponseStatus httpStatus = HttpResponseStatus.OK;
    resultWriter.print("{\n");
    ResultUtil.printStatus(resultWriter, resultStatus, (ex != null) || ResultStatus.SUCCESS == resultStatus);
    if (ResultStatus.SUCCESS == resultStatus) {
        String servletPath = servletPath(request).replace("status", "result");
        String resHandle = "http://" + host(request) + servletPath + strHandle;
        printHandle(resultWriter, resHandle, false);
    } else if (ex != null) {
        ResultUtil.printError(resultWriter, ex, false);
    }
    resultWriter.print("}\n");
    resultWriter.flush();
    String result = stringWriter.toString();
    response.setStatus(httpStatus);
    response.writer().print(result);
    if (response.writer().checkError()) {
        LOGGER.warn("Error flushing output writer");
    }
}
#method_after
@Override
protected void get(IServletRequest request, IServletResponse response) throws Exception {
    final String strHandle = localPath(request);
    final ResultHandle handle = ResultHandle.parse(strHandle);
    if (handle == null) {
        response.setStatus(HttpResponseStatus.BAD_REQUEST);
        return;
    }
    ResultReader resultReader = new ResultReader(getResultSet(), handle.getJobId(), handle.getResultSetId());
    final ResultJobRecord.Status resultReaderStatus = resultReader.getStatus();
    if (resultReaderStatus == null) {
        LOGGER.log(Level.INFO, "No results for: \"" + strHandle + "\"");
        response.setStatus(HttpResponseStatus.NOT_FOUND);
        return;
    }
    ResultStatus resultStatus = resultStatus(resultReaderStatus);
    Exception ex = extractException(resultReaderStatus);
    final StringWriter stringWriter = new StringWriter();
    final PrintWriter resultWriter = new PrintWriter(stringWriter);
    HttpUtil.setContentType(response, HttpUtil.ContentType.APPLICATION_JSON, HttpUtil.Encoding.UTF8);
    HttpResponseStatus httpStatus = HttpResponseStatus.OK;
    resultWriter.print("{\n");
    ResultUtil.printStatus(resultWriter, resultStatus, (ex != null) || ResultStatus.SUCCESS == resultStatus);
    if (ResultStatus.SUCCESS == resultStatus) {
        String servletPath = servletPath(request).replace("status", "result");
        String resHandle = "http://" + host(request) + servletPath + strHandle;
        printHandle(resultWriter, resHandle, false);
    } else if (ex != null) {
        ResultUtil.printError(resultWriter, ex, false);
    }
    resultWriter.print("}\n");
    resultWriter.flush();
    String result = stringWriter.toString();
    response.setStatus(httpStatus);
    response.writer().print(result);
    if (response.writer().checkError()) {
        LOGGER.warn("Error flushing output writer");
    }
}
#end_block

#method_before
@Override
protected void post(IServletRequest request, IServletResponse response) {
    // Query language
    ILangCompilationProvider compilationProvider = "AQL".equals(request.getParameter("query-language")) ? aqlCompilationProvider : sqlppCompilationProvider;
    IParserFactory parserFactory = compilationProvider.getParserFactory();
    // Output format.
    PrintWriter out = response.writer();
    OutputFormat format;
    boolean csvAndHeader = false;
    String output = request.getParameter("output-format");
    if ("CSV-Header".equals(output)) {
        output = "CSV";
        csvAndHeader = true;
    }
    try {
        format = OutputFormat.valueOf(output);
    } catch (IllegalArgumentException e) {
        LOGGER.log(Level.INFO, output + ": unsupported output-format, using " + OutputFormat.CLEAN_JSON + " instead", e);
        // Default output format
        format = OutputFormat.CLEAN_JSON;
    }
    PlanFormat planFormat = PlanFormat.get(request.getParameter("plan-format"), "plan format", PlanFormat.STRING, LOGGER);
    String query = request.getParameter("query");
    String wrapperArray = request.getParameter("wrapper-array");
    String printExprParam = request.getParameter("print-expr-tree");
    String printRewrittenExprParam = request.getParameter("print-rewritten-expr-tree");
    String printLogicalPlanParam = request.getParameter("print-logical-plan");
    String printOptimizedLogicalPlanParam = request.getParameter("print-optimized-logical-plan");
    String printJob = request.getParameter("print-job");
    String executeQuery = request.getParameter("execute-query");
    try {
        response.setStatus(HttpResponseStatus.OK);
        HttpUtil.setContentType(response, ContentType.TEXT_HTML, Encoding.UTF8);
    } catch (IOException e) {
        LOGGER.log(Level.WARN, "Failure setting content type", e);
        response.setStatus(HttpResponseStatus.INTERNAL_SERVER_ERROR);
        return;
    }
    try {
        IHyracksClientConnection hcc = (IHyracksClientConnection) ctx.get(HYRACKS_CONNECTION_ATTR);
        IResultSet hds = (IResultSet) ctx.get(HYRACKS_DATASET_ATTR);
        if (hds == null) {
            synchronized (ctx) {
                hds = (IResultSet) ctx.get(HYRACKS_DATASET_ATTR);
                if (hds == null) {
                    hds = new ResultSet(hcc, appCtx.getCompilerProperties().getFrameSize(), ResultReader.NUM_READERS);
                    ctx.put(HYRACKS_DATASET_ATTR, hds);
                }
            }
        }
        IParser parser = parserFactory.createParser(query);
        List<Statement> aqlStatements = parser.parse();
        SessionConfig sessionConfig = new SessionConfig(format, true, isSet(executeQuery), true, planFormat);
        sessionConfig.set(SessionConfig.FORMAT_HTML, true);
        sessionConfig.set(SessionConfig.FORMAT_CSV_HEADER, csvAndHeader);
        sessionConfig.set(SessionConfig.FORMAT_WRAPPER_ARRAY, isSet(wrapperArray));
        sessionConfig.setOOBData(isSet(printExprParam), isSet(printRewrittenExprParam), isSet(printLogicalPlanParam), isSet(printOptimizedLogicalPlanParam), isSet(printJob));
        SessionOutput sessionOutput = new SessionOutput(sessionConfig, out);
        MetadataManager.INSTANCE.init();
        IStatementExecutor translator = statementExectorFactory.create(appCtx, aqlStatements, sessionOutput, compilationProvider, componentProvider);
        double duration;
        long startTime = System.currentTimeMillis();
        final IRequestParameters requestParameters = new RequestParameters(hds, new ResultProperties(IStatementExecutor.ResultDelivery.IMMEDIATE), new IStatementExecutor.Stats(), null, null, null);
        translator.compileAndExecute(hcc, null, requestParameters);
        long endTime = System.currentTimeMillis();
        duration = (endTime - startTime) / 1000.00;
        out.println(HTML_STATEMENT_SEPARATOR);
        out.println("<PRE>Duration of all jobs: " + duration + " sec</PRE>");
    } catch (AsterixException | TokenMgrError | org.apache.asterix.aqlplus.parser.TokenMgrError pe) {
        GlobalConfig.ASTERIX_LOGGER.log(Level.INFO, pe.toString(), pe);
        ResultUtil.webUIParseExceptionHandler(out, pe, query);
    } catch (Exception e) {
        GlobalConfig.ASTERIX_LOGGER.log(Level.ERROR, e.getMessage(), e);
        ResultUtil.webUIErrorHandler(out, e);
    }
}
#method_after
@Override
protected void post(IServletRequest request, IServletResponse response) {
    // Query language
    ILangCompilationProvider compilationProvider = "AQL".equals(request.getParameter("query-language")) ? aqlCompilationProvider : sqlppCompilationProvider;
    IParserFactory parserFactory = compilationProvider.getParserFactory();
    // Output format.
    PrintWriter out = response.writer();
    OutputFormat format;
    boolean csvAndHeader = false;
    String output = request.getParameter("output-format");
    if ("CSV-Header".equals(output)) {
        output = "CSV";
        csvAndHeader = true;
    }
    try {
        format = OutputFormat.valueOf(output);
    } catch (IllegalArgumentException e) {
        LOGGER.log(Level.INFO, output + ": unsupported output-format, using " + OutputFormat.CLEAN_JSON + " instead", e);
        // Default output format
        format = OutputFormat.CLEAN_JSON;
    }
    PlanFormat planFormat = PlanFormat.get(request.getParameter("plan-format"), "plan format", PlanFormat.STRING, LOGGER);
    String query = request.getParameter("query");
    String wrapperArray = request.getParameter("wrapper-array");
    String printExprParam = request.getParameter("print-expr-tree");
    String printRewrittenExprParam = request.getParameter("print-rewritten-expr-tree");
    String printLogicalPlanParam = request.getParameter("print-logical-plan");
    String printOptimizedLogicalPlanParam = request.getParameter("print-optimized-logical-plan");
    String printJob = request.getParameter("print-job");
    String executeQuery = request.getParameter("execute-query");
    try {
        response.setStatus(HttpResponseStatus.OK);
        HttpUtil.setContentType(response, ContentType.TEXT_HTML, Encoding.UTF8);
    } catch (IOException e) {
        LOGGER.log(Level.WARN, "Failure setting content type", e);
        response.setStatus(HttpResponseStatus.INTERNAL_SERVER_ERROR);
        return;
    }
    try {
        IHyracksClientConnection hcc = (IHyracksClientConnection) ctx.get(HYRACKS_CONNECTION_ATTR);
        IResultSet resultSet = ServletUtil.getResultSet(hcc, appCtx, ctx);
        IParser parser = parserFactory.createParser(query);
        List<Statement> aqlStatements = parser.parse();
        SessionConfig sessionConfig = new SessionConfig(format, true, isSet(executeQuery), true, planFormat);
        sessionConfig.set(SessionConfig.FORMAT_HTML, true);
        sessionConfig.set(SessionConfig.FORMAT_CSV_HEADER, csvAndHeader);
        sessionConfig.set(SessionConfig.FORMAT_WRAPPER_ARRAY, isSet(wrapperArray));
        sessionConfig.setOOBData(isSet(printExprParam), isSet(printRewrittenExprParam), isSet(printLogicalPlanParam), isSet(printOptimizedLogicalPlanParam), isSet(printJob));
        SessionOutput sessionOutput = new SessionOutput(sessionConfig, out);
        MetadataManager.INSTANCE.init();
        IStatementExecutor translator = statementExectorFactory.create(appCtx, aqlStatements, sessionOutput, compilationProvider, componentProvider);
        double duration;
        long startTime = System.currentTimeMillis();
        final IRequestParameters requestParameters = new RequestParameters(resultSet, new ResultProperties(IStatementExecutor.ResultDelivery.IMMEDIATE), new IStatementExecutor.Stats(), null, null, null, null, true);
        translator.compileAndExecute(hcc, null, requestParameters);
        long endTime = System.currentTimeMillis();
        duration = (endTime - startTime) / 1000.00;
        out.println(HTML_STATEMENT_SEPARATOR);
        out.println("<PRE>Duration of all jobs: " + duration + " sec</PRE>");
    } catch (AsterixException | TokenMgrError | org.apache.asterix.aqlplus.parser.TokenMgrError pe) {
        GlobalConfig.ASTERIX_LOGGER.log(Level.INFO, pe.toString(), pe);
        ResultUtil.webUIParseExceptionHandler(out, pe, query);
    } catch (Exception e) {
        GlobalConfig.ASTERIX_LOGGER.log(Level.ERROR, e.getMessage(), e);
        ResultUtil.webUIErrorHandler(out, e);
    }
}
#end_block

#method_before
@Override
public FunctionId getFunctionId() {
    return FunctionId.DISTRIBUTE_JOB;
}
#method_after
@Override
public FunctionId getFunctionId() {
    return FunctionId.DEPLOY_JOB;
}
#end_block

#method_before
@Override
public FunctionId getFunctionId() {
    return FunctionId.DESTROY_JOB;
}
#method_after
@Override
public FunctionId getFunctionId() {
    return FunctionId.UNDEPLOY_JOB;
}
#end_block

#method_before
public static Object deserialize(ByteBuffer buffer, int length) throws Exception {
    ByteArrayInputStream bais = new ByteArrayInputStream(buffer.array(), buffer.position(), length);
    DataInputStream dis = new DataInputStream(bais);
    // read jobId and taskId
    JobId jobId = JobId.create(dis);
    DeploymentId deploymentId = null;
    boolean hasDeployed = dis.readBoolean();
    if (hasDeployed) {
        deploymentId = DeploymentId.create(dis);
    }
    // read plan bytes
    int planBytesSize = dis.readInt();
    byte[] planBytes = null;
    if (planBytesSize >= 0) {
        planBytes = new byte[planBytesSize];
        dis.read(planBytes, 0, planBytesSize);
    }
    // read task attempt descriptors
    int tadSize = dis.readInt();
    List<TaskAttemptDescriptor> taskDescriptors = new ArrayList<>();
    for (int i = 0; i < tadSize; i++) {
        TaskAttemptDescriptor tad = TaskAttemptDescriptor.create(dis);
        taskDescriptors.add(tad);
    }
    // read connector policies
    int cpSize = dis.readInt();
    Map<ConnectorDescriptorId, IConnectorPolicy> connectorPolicies = new HashMap<>();
    for (int i = 0; i < cpSize; i++) {
        ConnectorDescriptorId cid = ConnectorDescriptorId.create(dis);
        IConnectorPolicy policy = ConnectorPolicyFactory.INSTANCE.getConnectorPolicy(dis);
        connectorPolicies.put(cid, policy);
    }
    // read flags
    int flagSize = dis.readInt();
    EnumSet<JobFlag> flags = EnumSet.noneOf(JobFlag.class);
    for (int i = 0; i < flagSize; i++) {
        flags.add(JobFlag.values()[(dis.readInt())]);
    }
    // read job parameters
    int paramListSize = dis.readInt();
    Map<byte[], byte[]> jobParameters = new HashMap<>();
    for (int i = 0; i < paramListSize; i++) {
        int nameLength = dis.readInt();
        byte[] nameBytes = null;
        if (nameLength >= 0) {
            nameBytes = new byte[nameLength];
            dis.read(nameBytes, 0, nameLength);
        }
        int valueLength = dis.readInt();
        byte[] valueBytes = null;
        if (valueLength >= 0) {
            valueBytes = new byte[valueLength];
            dis.read(valueBytes, 0, valueLength);
        }
        jobParameters.put(nameBytes, valueBytes);
    }
    // read DeployedJobSpecId
    DeployedJobSpecId deployedJobSpecId = null;
    if (dis.readBoolean()) {
        deployedJobSpecId = DeployedJobSpecId.create(dis);
    }
    return new StartTasksFunction(deploymentId, jobId, planBytes, taskDescriptors, connectorPolicies, flags, jobParameters, deployedJobSpecId);
}
#method_after
public static Object deserialize(ByteBuffer buffer, int length) throws Exception {
    ByteArrayInputStream bais = new ByteArrayInputStream(buffer.array(), buffer.position(), length);
    DataInputStream dis = new DataInputStream(bais);
    // read jobId and taskId
    JobId jobId = JobId.create(dis);
    DeploymentId deploymentId = null;
    boolean hasDeployed = dis.readBoolean();
    if (hasDeployed) {
        deploymentId = DeploymentId.create(dis);
    }
    // read plan bytes
    int planBytesSize = dis.readInt();
    byte[] planBytes = null;
    if (planBytesSize >= 0) {
        planBytes = new byte[planBytesSize];
        dis.read(planBytes, 0, planBytesSize);
    }
    // read task attempt descriptors
    int tadSize = dis.readInt();
    List<TaskAttemptDescriptor> taskDescriptors = new ArrayList<>();
    for (int i = 0; i < tadSize; i++) {
        TaskAttemptDescriptor tad = TaskAttemptDescriptor.create(dis);
        taskDescriptors.add(tad);
    }
    // read connector policies
    int cpSize = dis.readInt();
    Map<ConnectorDescriptorId, IConnectorPolicy> connectorPolicies = new HashMap<>();
    for (int i = 0; i < cpSize; i++) {
        ConnectorDescriptorId cid = ConnectorDescriptorId.create(dis);
        IConnectorPolicy policy = ConnectorPolicyFactory.INSTANCE.getConnectorPolicy(dis);
        connectorPolicies.put(cid, policy);
    }
    // read flags
    int flagSize = dis.readInt();
    EnumSet<JobFlag> flags = EnumSet.noneOf(JobFlag.class);
    for (int i = 0; i < flagSize; i++) {
        flags.add(JobFlag.values()[(dis.readInt())]);
    }
    // read job parameters
    int paramListSize = dis.readInt();
    Map<byte[], byte[]> jobParameters = new HashMap<>();
    for (int i = 0; i < paramListSize; i++) {
        int nameLength = dis.readInt();
        byte[] nameBytes = null;
        if (nameLength >= 0) {
            nameBytes = new byte[nameLength];
            dis.read(nameBytes, 0, nameLength);
        }
        int valueLength = dis.readInt();
        byte[] valueBytes = null;
        if (valueLength >= 0) {
            valueBytes = new byte[valueLength];
            dis.read(valueBytes, 0, valueLength);
        }
        jobParameters.put(nameBytes, valueBytes);
    }
    // read DeployedJobSpecId
    DeployedJobSpecId deployedJobSpecId = null;
    if (dis.readBoolean()) {
        deployedJobSpecId = DeployedJobSpecId.create(dis);
    }
    long jobStartTime = dis.readLong();
    return new StartTasksFunction(deploymentId, jobId, planBytes, taskDescriptors, connectorPolicies, flags, jobParameters, deployedJobSpecId, jobStartTime);
}
#end_block

#method_before
public static void serialize(OutputStream out, Object object) throws Exception {
    StartTasksFunction fn = (StartTasksFunction) object;
    DataOutputStream dos = new DataOutputStream(out);
    // write jobId and deploymentId
    fn.jobId.writeFields(dos);
    dos.writeBoolean(fn.deploymentId == null ? false : true);
    if (fn.deploymentId != null) {
        fn.deploymentId.writeFields(dos);
    }
    // write plan bytes
    dos.writeInt(fn.planBytes == null ? -1 : fn.planBytes.length);
    if (fn.planBytes != null) {
        dos.write(fn.planBytes, 0, fn.planBytes.length);
    }
    // write task descriptors
    dos.writeInt(fn.taskDescriptors.size());
    for (int i = 0; i < fn.taskDescriptors.size(); i++) {
        fn.taskDescriptors.get(i).writeFields(dos);
    }
    // write connector policies
    dos.writeInt(fn.connectorPolicies.size());
    for (Entry<ConnectorDescriptorId, IConnectorPolicy> entry : fn.connectorPolicies.entrySet()) {
        entry.getKey().writeFields(dos);
        ConnectorPolicyFactory.INSTANCE.writeConnectorPolicy(entry.getValue(), dos);
    }
    // write flags
    dos.writeInt(fn.flags.size());
    for (JobFlag flag : fn.flags) {
        dos.writeInt(flag.ordinal());
    }
    // write job parameters
    dos.writeInt(fn.jobParameters.size());
    for (Entry<byte[], byte[]> entry : fn.jobParameters.entrySet()) {
        dos.writeInt(entry.getKey().length);
        dos.write(entry.getKey(), 0, entry.getKey().length);
        dos.writeInt(entry.getValue().length);
        dos.write(entry.getValue(), 0, entry.getValue().length);
    }
    // write deployed job spec id
    dos.writeBoolean(fn.getDeployedJobSpecId() == null ? false : true);
    if (fn.getDeployedJobSpecId() != null) {
        fn.getDeployedJobSpecId().writeFields(dos);
    }
}
#method_after
public static void serialize(OutputStream out, Object object) throws Exception {
    StartTasksFunction fn = (StartTasksFunction) object;
    DataOutputStream dos = new DataOutputStream(out);
    // write jobId and deploymentId
    fn.jobId.writeFields(dos);
    dos.writeBoolean(fn.deploymentId == null ? false : true);
    if (fn.deploymentId != null) {
        fn.deploymentId.writeFields(dos);
    }
    // write plan bytes
    dos.writeInt(fn.planBytes == null ? -1 : fn.planBytes.length);
    if (fn.planBytes != null) {
        dos.write(fn.planBytes, 0, fn.planBytes.length);
    }
    // write task descriptors
    dos.writeInt(fn.taskDescriptors.size());
    for (int i = 0; i < fn.taskDescriptors.size(); i++) {
        fn.taskDescriptors.get(i).writeFields(dos);
    }
    // write connector policies
    dos.writeInt(fn.connectorPolicies.size());
    for (Entry<ConnectorDescriptorId, IConnectorPolicy> entry : fn.connectorPolicies.entrySet()) {
        entry.getKey().writeFields(dos);
        ConnectorPolicyFactory.INSTANCE.writeConnectorPolicy(entry.getValue(), dos);
    }
    // write flags
    dos.writeInt(fn.flags.size());
    for (JobFlag flag : fn.flags) {
        dos.writeInt(flag.ordinal());
    }
    // write job parameters
    dos.writeInt(fn.jobParameters.size());
    for (Entry<byte[], byte[]> entry : fn.jobParameters.entrySet()) {
        dos.writeInt(entry.getKey().length);
        dos.write(entry.getKey(), 0, entry.getKey().length);
        dos.writeInt(entry.getValue().length);
        dos.write(entry.getValue(), 0, entry.getValue().length);
    }
    // write deployed job spec id
    dos.writeBoolean(fn.getDeployedJobSpecId() != null);
    if (fn.getDeployedJobSpecId() != null) {
        fn.getDeployedJobSpecId().writeFields(dos);
    }
    // write job start time
    dos.writeLong(fn.jobStartTime);
}
#end_block

#method_before
@Override
public void run() {
    if (LOGGER.isInfoEnabled()) {
        LOGGER.info("Aborting Tasks: " + jobId + ":" + tasks);
    }
    IResultPartitionManager dpm = ncs.getDatasetPartitionManager();
    if (dpm != null) {
        ncs.getDatasetPartitionManager().abortReader(jobId);
    }
    Joblet ji = ncs.getJobletMap().get(jobId);
    if (ji != null) {
        Map<TaskAttemptId, Task> taskMap = ji.getTaskMap();
        for (TaskAttemptId taId : tasks) {
            Task task = taskMap.get(taId);
            if (task != null) {
                task.abort();
            }
        }
    } else {
        LOGGER.log(Level.WARN, "Joblet couldn't be found. Tasks of job " + jobId + " have all either completed or failed");
    }
}
#method_after
@Override
public void run() {
    if (LOGGER.isInfoEnabled()) {
        LOGGER.info("Aborting Tasks: " + jobId + ":" + tasks);
    }
    IResultPartitionManager resultPartitionManager = ncs.getResultPartitionManager();
    if (resultPartitionManager != null) {
        ncs.getResultPartitionManager().abortReader(jobId);
    }
    Joblet ji = ncs.getJobletMap().get(jobId);
    if (ji != null) {
        Map<TaskAttemptId, Task> taskMap = ji.getTaskMap();
        for (TaskAttemptId taId : tasks) {
            Task task = taskMap.get(taId);
            if (task != null) {
                task.abort();
            }
        }
    } else {
        LOGGER.log(Level.WARN, "Joblet couldn't be found. Tasks of job " + jobId + " have all either completed or failed");
    }
}
#end_block

#method_before
private synchronized boolean addPendingThread(Thread t) {
    if (aborted) {
        return false;
    }
    pendingThreads.add(t);
    return true;
}
#method_after
private synchronized boolean addPendingThread(Thread t) {
    if (aborted) {
        return false;
    }
    return pendingThreads.add(t);
}
#end_block

#method_before
@Override
public void run() {
    Thread ct = Thread.currentThread();
    // the thread is not escaped from interruption.
    if (!addPendingThread(ct)) {
        exceptions.add(HyracksDataException.create(TASK_ABORTED, getTaskAttemptId()));
        ExceptionUtils.setNodeIds(exceptions, ncs.getId());
        ncs.getWorkQueue().schedule(new NotifyTaskFailureWork(ncs, this, exceptions, joblet.getJobId(), taskAttemptId));
        return;
    }
    ct.setName(displayName + ":" + taskAttemptId + ":" + 0);
    try {
        Exception operatorException = null;
        try {
            operator.initialize();
            if (collectors.length > 0) {
                final Semaphore sem = new Semaphore(collectors.length - 1);
                for (int i = 1; i < collectors.length; ++i) {
                    final IPartitionCollector collector = collectors[i];
                    final IFrameWriter writer = operator.getInputFrameWriter(i);
                    sem.acquire();
                    final int cIdx = i;
                    executorService.execute(() -> {
                        Thread thread = Thread.currentThread();
                        // the thread is not escaped from interruption.
                        if (!addPendingThread(thread)) {
                            return;
                        }
                        thread.setName(displayName + ":" + taskAttemptId + ":" + cIdx);
                        thread.setPriority(Thread.MIN_PRIORITY);
                        try {
                            pushFrames(collector, inputChannelsFromConnectors.get(cIdx), writer);
                        } catch (HyracksDataException e) {
                            synchronized (Task.this) {
                                exceptions.add(e);
                            }
                        } finally {
                            sem.release();
                            removePendingThread(thread);
                        }
                    });
                }
                try {
                    pushFrames(collectors[0], inputChannelsFromConnectors.get(0), operator.getInputFrameWriter(0));
                } finally {
                    sem.acquire(collectors.length - 1);
                }
            }
        } catch (Exception e) {
            // Store the operator exception
            operatorException = e;
            throw e;
        } finally {
            try {
                operator.deinitialize();
            } catch (Exception e) {
                if (operatorException != null) {
                    // Add deinitialize exception to the operator exception to keep track of both
                    operatorException.addSuppressed(e);
                } else {
                    operatorException = e;
                }
                throw operatorException;
            }
        }
        NodeControllerService ncs = joblet.getNodeController();
        ncs.getWorkQueue().schedule(new NotifyTaskCompleteWork(ncs, this));
    } catch (InterruptedException e) {
        exceptions.add(e);
        Thread.currentThread().interrupt();
    } catch (Exception e) {
        exceptions.add(e);
    } finally {
        close();
        removePendingThread(ct);
    }
    if (!exceptions.isEmpty()) {
        if (LOGGER.isWarnEnabled()) {
            for (int i = 0; i < exceptions.size(); i++) {
                LOGGER.log(Level.WARN, "Task " + taskAttemptId + " failed with exception" + (exceptions.size() > 1 ? "s (" + (i + 1) + "/" + exceptions.size() + ")" : ""), exceptions.get(i));
            }
        }
        NodeControllerService ncs = joblet.getNodeController();
        ExceptionUtils.setNodeIds(exceptions, ncs.getId());
        ncs.getWorkQueue().schedule(new NotifyTaskFailureWork(ncs, this, exceptions, joblet.getJobId(), taskAttemptId));
    }
}
#method_after
@Override
public void run() {
    Thread ct = Thread.currentThread();
    // the thread is not escaped from interruption.
    if (!addPendingThread(ct)) {
        exceptions.add(HyracksDataException.create(TASK_ABORTED, getTaskAttemptId()));
        ExceptionUtils.setNodeIds(exceptions, ncs.getId());
        ncs.getWorkQueue().schedule(new NotifyTaskFailureWork(ncs, this, exceptions, joblet.getJobId(), taskAttemptId));
        return;
    }
    ct.setName(displayName + ":" + joblet.getJobId() + ":" + taskAttemptId + ":" + 0);
    try {
        Throwable operatorException = null;
        try {
            operator.initialize();
            if (collectors.length > 0) {
                final Semaphore sem = new Semaphore(collectors.length - 1);
                for (int i = 1; i < collectors.length; ++i) {
                    // Q. Do we ever have a task that has more than one collector?
                    final IPartitionCollector collector = collectors[i];
                    final IFrameWriter writer = operator.getInputFrameWriter(i);
                    sem.acquireUninterruptibly();
                    final int cIdx = i;
                    executorService.execute(() -> {
                        try {
                            Thread thread = Thread.currentThread();
                            if (!addPendingThread(thread)) {
                                return;
                            }
                            thread.setName(displayName + ":" + joblet.getJobId() + ":" + taskAttemptId + ":" + cIdx);
                            thread.setPriority(Thread.MIN_PRIORITY);
                            try {
                                pushFrames(collector, inputChannelsFromConnectors.get(cIdx), writer);
                            } catch (HyracksDataException e) {
                                synchronized (Task.this) {
                                    exceptions.add(e);
                                }
                            } finally {
                                removePendingThread(thread);
                            }
                        } finally {
                            sem.release();
                        }
                    });
                }
                try {
                    pushFrames(collectors[0], inputChannelsFromConnectors.get(0), operator.getInputFrameWriter(0));
                } finally {
                    sem.acquireUninterruptibly(collectors.length - 1);
                }
            }
        } catch (Throwable e) {
            // NOSONAR: Must catch all failures
            operatorException = e;
        } finally {
            try {
                operator.deinitialize();
            } catch (Throwable e) {
                // NOSONAR: Must catch all failures
                operatorException = ExceptionUtils.suppress(operatorException, e);
            }
        }
        if (operatorException != null) {
            throw operatorException;
        }
        ncs.getWorkQueue().schedule(new NotifyTaskCompleteWork(ncs, this));
    } catch (Throwable e) {
        // NOSONAR: Catch all failures
        exceptions.add(HyracksDataException.create(e));
    } finally {
        close();
        removePendingThread(ct);
        completed = true;
    }
    if (!exceptions.isEmpty()) {
        if (LOGGER.isWarnEnabled()) {
            for (int i = 0; i < exceptions.size(); i++) {
                LOGGER.log(Level.WARN, "Task " + taskAttemptId + " failed with exception" + (exceptions.size() > 1 ? "s (" + (i + 1) + "/" + exceptions.size() + ")" : ""), exceptions.get(i));
            }
        }
        ExceptionUtils.setNodeIds(exceptions, ncs.getId());
        ncs.getWorkQueue().schedule(new NotifyTaskFailureWork(ncs, this, exceptions, joblet.getJobId(), taskAttemptId));
    }
}
#end_block

#method_before
public Set<JobFlag> getJobFlags() {
    return jobFlags;
}
#method_after
@Override
public Set<JobFlag> getJobFlags() {
    return jobFlags;
}
#end_block

#method_before
@Override
public void run() {
    try {
        ccs.getDatasetDirectoryService().reportResultPartitionWriteCompletion(jobId, rsId, partition);
    } catch (HyracksDataException e) {
        throw new RuntimeException(e);
    }
}
#method_after
@Override
public void run() {
    try {
        ccs.getResultDirectoryService().reportResultPartitionWriteCompletion(jobId, rsId, partition);
    } catch (HyracksDataException e) {
        throw new RuntimeException(e);
    }
}
#end_block

#method_before
@Override
public void run() {
    LOGGER.log(Level.WARN, ncs.getId() + " is sending a notification to cc that task " + taskId + " has failed", exceptions.get(0));
    try {
        IResultPartitionManager dpm = ncs.getDatasetPartitionManager();
        if (dpm != null) {
            dpm.abortReader(jobId);
        }
        ncs.getClusterController(jobId.getCcId()).notifyTaskFailure(jobId, taskId, ncs.getId(), exceptions);
    } catch (Exception e) {
        LOGGER.log(Level.ERROR, "Failure reporting task failure to cluster controller", e);
    }
    if (task != null) {
        task.getJoblet().removeTask(task);
    }
}
#method_after
@Override
public void run() {
    LOGGER.log(Level.WARN, ncs.getId() + " is sending a notification to cc that task " + taskId + " has failed", exceptions.get(0));
    try {
        IResultPartitionManager resultPartitionManager = ncs.getResultPartitionManager();
        if (resultPartitionManager != null) {
            resultPartitionManager.abortReader(jobId);
        }
        ncs.getClusterController(jobId.getCcId()).notifyTaskFailure(jobId, taskId, ncs.getId(), exceptions);
    } catch (Exception e) {
        LOGGER.log(Level.ERROR, "Failure reporting task failure to cluster controller", e);
    }
    if (task != null) {
        task.getJoblet().removeTask(task);
    }
}
#end_block

#method_before
@Override
public void compileAndExecute(IHyracksClientConnection hcc, IStatementExecutorContext ctx, IRequestParameters requestParameters) throws Exception {
    int resultSetIdCounter = 0;
    FileSplit outputFile = null;
    IAWriterFactory writerFactory = PrinterBasedWriterFactory.INSTANCE;
    IResultSerializerFactoryProvider resultSerializerFactoryProvider = ResultSerializerFactoryProvider.INSTANCE;
    /*
         * Since the system runs a large number of threads, when HTTP requests don't
         * return, it becomes difficult to find the thread running the request to
         * determine where it has stopped. Setting the thread name helps make that
         * easier
         */
    String threadName = Thread.currentThread().getName();
    Thread.currentThread().setName(QueryTranslator.class.getSimpleName());
    Map<String, String> config = new HashMap<>();
    final IResultSet hdc = requestParameters.getResultset();
    final ResultDelivery resultDelivery = requestParameters.getResultProperties().getDelivery();
    final long maxResultReads = requestParameters.getResultProperties().getMaxReads();
    final Stats stats = requestParameters.getStats();
    final ResultMetadata outMetadata = requestParameters.getOutMetadata();
    final String clientContextId = requestParameters.getClientContextId();
    try {
        for (Statement stmt : statements) {
            if (sessionConfig.is(SessionConfig.FORMAT_HTML)) {
                sessionOutput.out().println(ApiServlet.HTML_STATEMENT_SEPARATOR);
            }
            validateOperation(appCtx, activeDataverse, stmt);
            // Rewrite the statement's AST.
            rewriteStatement(stmt);
            MetadataProvider metadataProvider = new MetadataProvider(appCtx, activeDataverse);
            metadataProvider.getConfig().putAll(config);
            metadataProvider.setWriterFactory(writerFactory);
            metadataProvider.setResultSerializerFactoryProvider(resultSerializerFactoryProvider);
            metadataProvider.setOutputFile(outputFile);
            switch(stmt.getKind()) {
                case SET:
                    handleSetStatement(stmt, config);
                    break;
                case DATAVERSE_DECL:
                    activeDataverse = handleUseDataverseStatement(metadataProvider, stmt);
                    break;
                case CREATE_DATAVERSE:
                    handleCreateDataverseStatement(metadataProvider, stmt);
                    break;
                case DATASET_DECL:
                    handleCreateDatasetStatement(metadataProvider, stmt, hcc, requestParameters);
                    break;
                case CREATE_INDEX:
                    handleCreateIndexStatement(metadataProvider, stmt, hcc, requestParameters);
                    break;
                case TYPE_DECL:
                    handleCreateTypeStatement(metadataProvider, stmt);
                    break;
                case NODEGROUP_DECL:
                    handleCreateNodeGroupStatement(metadataProvider, stmt);
                    break;
                case DATAVERSE_DROP:
                    handleDataverseDropStatement(metadataProvider, stmt, hcc);
                    break;
                case DATASET_DROP:
                    handleDatasetDropStatement(metadataProvider, stmt, hcc, requestParameters);
                    break;
                case INDEX_DROP:
                    handleIndexDropStatement(metadataProvider, stmt, hcc, requestParameters);
                    break;
                case TYPE_DROP:
                    handleTypeDropStatement(metadataProvider, stmt);
                    break;
                case NODEGROUP_DROP:
                    handleNodegroupDropStatement(metadataProvider, stmt);
                    break;
                case CREATE_FUNCTION:
                    handleCreateFunctionStatement(metadataProvider, stmt);
                    break;
                case FUNCTION_DROP:
                    handleFunctionDropStatement(metadataProvider, stmt);
                    break;
                case LOAD:
                    handleLoadStatement(metadataProvider, stmt, hcc);
                    break;
                case INSERT:
                case UPSERT:
                    if (((InsertStatement) stmt).getReturnExpression() != null) {
                        metadataProvider.setResultSetId(new ResultSetId(resultSetIdCounter++));
                        metadataProvider.setResultAsyncMode(resultDelivery == ResultDelivery.ASYNC || resultDelivery == ResultDelivery.DEFERRED);
                        metadataProvider.setMaxResultReads(maxResultReads);
                    }
                    handleInsertUpsertStatement(metadataProvider, stmt, hcc, hdc, resultDelivery, outMetadata, stats, false, clientContextId);
                    break;
                case DELETE:
                    handleDeleteStatement(metadataProvider, stmt, hcc, false);
                    break;
                case CREATE_FEED:
                    handleCreateFeedStatement(metadataProvider, stmt);
                    break;
                case DROP_FEED:
                    handleDropFeedStatement(metadataProvider, stmt, hcc);
                    break;
                case DROP_FEED_POLICY:
                    handleDropFeedPolicyStatement(metadataProvider, stmt);
                    break;
                case CONNECT_FEED:
                    handleConnectFeedStatement(metadataProvider, stmt);
                    break;
                case DISCONNECT_FEED:
                    handleDisconnectFeedStatement(metadataProvider, stmt);
                    break;
                case START_FEED:
                    handleStartFeedStatement(metadataProvider, stmt, hcc);
                    break;
                case STOP_FEED:
                    handleStopFeedStatement(metadataProvider, stmt);
                    break;
                case CREATE_FEED_POLICY:
                    handleCreateFeedPolicyStatement(metadataProvider, stmt);
                    break;
                case QUERY:
                    metadataProvider.setResultSetId(new ResultSetId(resultSetIdCounter++));
                    metadataProvider.setResultAsyncMode(resultDelivery == ResultDelivery.ASYNC || resultDelivery == ResultDelivery.DEFERRED);
                    metadataProvider.setMaxResultReads(maxResultReads);
                    handleQuery(metadataProvider, (Query) stmt, hcc, hdc, resultDelivery, outMetadata, stats, clientContextId, ctx);
                    break;
                case COMPACT:
                    handleCompactStatement(metadataProvider, stmt, hcc);
                    break;
                case EXTERNAL_DATASET_REFRESH:
                    handleExternalDatasetRefreshStatement(metadataProvider, stmt, hcc);
                    break;
                case WRITE:
                    Pair<IAWriterFactory, FileSplit> result = handleWriteStatement(stmt);
                    writerFactory = (result.first != null) ? result.first : writerFactory;
                    outputFile = result.second;
                    break;
                case FUNCTION_DECL:
                    // No op
                    break;
                case EXTENSION:
                    ((ExtensionStatement) stmt).handle(hcc, this, requestParameters, metadataProvider, resultSetIdCounter);
                    break;
                default:
                    throw new CompilationException("Unknown function");
            }
        }
    } finally {
        Thread.currentThread().setName(threadName);
    }
}
#method_after
@Override
public void compileAndExecute(IHyracksClientConnection hcc, IStatementExecutorContext ctx, IRequestParameters requestParameters) throws Exception {
    if (!requestParameters.isMultiStatement()) {
        validateStatements(statements);
    }
    int resultSetIdCounter = 0;
    FileSplit outputFile = null;
    IAWriterFactory writerFactory = PrinterBasedWriterFactory.INSTANCE;
    IResultSerializerFactoryProvider resultSerializerFactoryProvider = ResultSerializerFactoryProvider.INSTANCE;
    /*
         * Since the system runs a large number of threads, when HTTP requests don't
         * return, it becomes difficult to find the thread running the request to
         * determine where it has stopped. Setting the thread name helps make that
         * easier
         */
    String threadName = Thread.currentThread().getName();
    Thread.currentThread().setName(QueryTranslator.class.getSimpleName());
    Map<String, String> config = new HashMap<>();
    final IResultSet resultSet = requestParameters.getResultSet();
    final ResultDelivery resultDelivery = requestParameters.getResultProperties().getDelivery();
    final long maxResultReads = requestParameters.getResultProperties().getMaxReads();
    final Stats stats = requestParameters.getStats();
    final ResultMetadata outMetadata = requestParameters.getOutMetadata();
    final String clientContextId = requestParameters.getClientContextId();
    final Map<String, IAObject> stmtParams = requestParameters.getStatementParameters();
    try {
        for (Statement stmt : statements) {
            if (sessionConfig.is(SessionConfig.FORMAT_HTML)) {
                sessionOutput.out().println(ApiServlet.HTML_STATEMENT_SEPARATOR);
            }
            validateOperation(appCtx, activeDataverse, stmt);
            IStatementRewriter stmtRewriter = rewriterFactory.createStatementRewriter();
            // Rewrite the statement's AST.
            rewriteStatement(stmt, stmtRewriter);
            MetadataProvider metadataProvider = new MetadataProvider(appCtx, activeDataverse);
            metadataProvider.getConfig().putAll(config);
            metadataProvider.setWriterFactory(writerFactory);
            metadataProvider.setResultSerializerFactoryProvider(resultSerializerFactoryProvider);
            metadataProvider.setOutputFile(outputFile);
            switch(stmt.getKind()) {
                case SET:
                    handleSetStatement(stmt, config);
                    break;
                case DATAVERSE_DECL:
                    activeDataverse = handleUseDataverseStatement(metadataProvider, stmt);
                    break;
                case CREATE_DATAVERSE:
                    handleCreateDataverseStatement(metadataProvider, stmt);
                    break;
                case DATASET_DECL:
                    handleCreateDatasetStatement(metadataProvider, stmt, hcc, requestParameters);
                    break;
                case CREATE_INDEX:
                    handleCreateIndexStatement(metadataProvider, stmt, hcc, requestParameters);
                    break;
                case TYPE_DECL:
                    handleCreateTypeStatement(metadataProvider, stmt);
                    break;
                case NODEGROUP_DECL:
                    handleCreateNodeGroupStatement(metadataProvider, stmt);
                    break;
                case DATAVERSE_DROP:
                    handleDataverseDropStatement(metadataProvider, stmt, hcc);
                    break;
                case DATASET_DROP:
                    handleDatasetDropStatement(metadataProvider, stmt, hcc, requestParameters);
                    break;
                case INDEX_DROP:
                    handleIndexDropStatement(metadataProvider, stmt, hcc, requestParameters);
                    break;
                case TYPE_DROP:
                    handleTypeDropStatement(metadataProvider, stmt);
                    break;
                case NODEGROUP_DROP:
                    handleNodegroupDropStatement(metadataProvider, stmt);
                    break;
                case CREATE_FUNCTION:
                    handleCreateFunctionStatement(metadataProvider, stmt);
                    break;
                case FUNCTION_DROP:
                    handleFunctionDropStatement(metadataProvider, stmt);
                    break;
                case LOAD:
                    handleLoadStatement(metadataProvider, stmt, hcc);
                    break;
                case INSERT:
                case UPSERT:
                    if (((InsertStatement) stmt).getReturnExpression() != null) {
                        metadataProvider.setResultSetId(new ResultSetId(resultSetIdCounter++));
                        metadataProvider.setResultAsyncMode(resultDelivery == ResultDelivery.ASYNC || resultDelivery == ResultDelivery.DEFERRED);
                        metadataProvider.setMaxResultReads(maxResultReads);
                    }
                    handleInsertUpsertStatement(metadataProvider, stmt, hcc, resultSet, resultDelivery, outMetadata, stats, false, clientContextId, stmtParams, stmtRewriter);
                    break;
                case DELETE:
                    handleDeleteStatement(metadataProvider, stmt, hcc, false, stmtParams, stmtRewriter);
                    break;
                case CREATE_FEED:
                    handleCreateFeedStatement(metadataProvider, stmt);
                    break;
                case DROP_FEED:
                    handleDropFeedStatement(metadataProvider, stmt, hcc);
                    break;
                case DROP_FEED_POLICY:
                    handleDropFeedPolicyStatement(metadataProvider, stmt);
                    break;
                case CONNECT_FEED:
                    handleConnectFeedStatement(metadataProvider, stmt);
                    break;
                case DISCONNECT_FEED:
                    handleDisconnectFeedStatement(metadataProvider, stmt);
                    break;
                case START_FEED:
                    handleStartFeedStatement(metadataProvider, stmt, hcc);
                    break;
                case STOP_FEED:
                    handleStopFeedStatement(metadataProvider, stmt);
                    break;
                case CREATE_FEED_POLICY:
                    handleCreateFeedPolicyStatement(metadataProvider, stmt);
                    break;
                case QUERY:
                    metadataProvider.setResultSetId(new ResultSetId(resultSetIdCounter++));
                    metadataProvider.setResultAsyncMode(resultDelivery == ResultDelivery.ASYNC || resultDelivery == ResultDelivery.DEFERRED);
                    metadataProvider.setMaxResultReads(maxResultReads);
                    handleQuery(metadataProvider, (Query) stmt, hcc, resultSet, resultDelivery, outMetadata, stats, clientContextId, ctx, stmtParams, stmtRewriter);
                    break;
                case COMPACT:
                    handleCompactStatement(metadataProvider, stmt, hcc);
                    break;
                case EXTERNAL_DATASET_REFRESH:
                    handleExternalDatasetRefreshStatement(metadataProvider, stmt, hcc);
                    break;
                case WRITE:
                    Pair<IAWriterFactory, FileSplit> result = handleWriteStatement(stmt);
                    writerFactory = (result.first != null) ? result.first : writerFactory;
                    outputFile = result.second;
                    break;
                case FUNCTION_DECL:
                    // No op
                    break;
                case EXTENSION:
                    ((ExtensionStatement) stmt).handle(hcc, this, requestParameters, metadataProvider, resultSetIdCounter, ctx);
                    break;
                default:
                    throw new CompilationException(ErrorCode.COMPILATION_ILLEGAL_STATE, stmt.getSourceLocation(), "Unexpected statement: " + stmt.getKind());
            }
        }
    } finally {
        Thread.currentThread().setName(threadName);
    }
}
#end_block

#method_before
protected void handleSetStatement(Statement stmt, Map<String, String> config) {
    SetStatement ss = (SetStatement) stmt;
    String pname = ss.getPropName();
    String pvalue = ss.getPropValue();
    config.put(pname, pvalue);
}
#method_after
protected void handleSetStatement(Statement stmt, Map<String, String> config) throws CompilationException {
    SetStatement ss = (SetStatement) stmt;
    String pname = ss.getPropName();
    String pvalue = ss.getPropValue();
    if (pname.startsWith(APIFramework.PREFIX_INTERNAL_PARAMETERS)) {
        throw new CompilationException(ErrorCode.ILLEGAL_SET_PARAMETER, pname);
    }
    config.put(pname, pvalue);
}
#end_block

#method_before
protected Dataverse handleUseDataverseStatement(MetadataProvider metadataProvider, Statement stmt) throws Exception {
    DataverseDecl dvd = (DataverseDecl) stmt;
    String dvName = dvd.getDataverseName().getValue();
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    lockManager.acquireDataverseReadLock(metadataProvider.getLocks(), dvName);
    try {
        Dataverse dv = MetadataManager.INSTANCE.getDataverse(metadataProvider.getMetadataTxnContext(), dvName);
        if (dv == null) {
            throw new MetadataException("Unknown dataverse " + dvName);
        }
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
        return dv;
    } catch (Exception e) {
        abort(e, e, mdTxnCtx);
        throw new MetadataException(e);
    } finally {
        metadataProvider.getLocks().unlock();
    }
}
#method_after
protected Dataverse handleUseDataverseStatement(MetadataProvider metadataProvider, Statement stmt) throws Exception {
    DataverseDecl dvd = (DataverseDecl) stmt;
    SourceLocation sourceLoc = dvd.getSourceLocation();
    String dvName = dvd.getDataverseName().getValue();
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    lockManager.acquireDataverseReadLock(metadataProvider.getLocks(), dvName);
    try {
        Dataverse dv = MetadataManager.INSTANCE.getDataverse(metadataProvider.getMetadataTxnContext(), dvName);
        if (dv == null) {
            throw new MetadataException(ErrorCode.UNKNOWN_DATAVERSE, sourceLoc, dvName);
        }
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
        return dv;
    } catch (Exception e) {
        abort(e, e, mdTxnCtx);
        throw new MetadataException(ErrorCode.METADATA_ERROR, e, sourceLoc, e.toString());
    } finally {
        metadataProvider.getLocks().unlock();
    }
}
#end_block

#method_before
protected void handleCreateDataverseStatement(MetadataProvider metadataProvider, Statement stmt) throws Exception {
    CreateDataverseStatement stmtCreateDataverse = (CreateDataverseStatement) stmt;
    String dvName = stmtCreateDataverse.getDataverseName().getValue();
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    lockManager.acquireDataverseReadLock(metadataProvider.getLocks(), dvName);
    try {
        Dataverse dv = MetadataManager.INSTANCE.getDataverse(metadataProvider.getMetadataTxnContext(), dvName);
        if (dv != null) {
            if (stmtCreateDataverse.getIfNotExists()) {
                MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
                return;
            } else {
                throw new AlgebricksException("A dataverse with this name " + dvName + " already exists.");
            }
        }
        MetadataManager.INSTANCE.addDataverse(metadataProvider.getMetadataTxnContext(), new Dataverse(dvName, stmtCreateDataverse.getFormat(), MetadataUtil.PENDING_NO_OP));
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
    } catch (Exception e) {
        abort(e, e, mdTxnCtx);
        throw e;
    } finally {
        metadataProvider.getLocks().unlock();
    }
}
#method_after
protected void handleCreateDataverseStatement(MetadataProvider metadataProvider, Statement stmt) throws Exception {
    CreateDataverseStatement stmtCreateDataverse = (CreateDataverseStatement) stmt;
    String dvName = stmtCreateDataverse.getDataverseName().getValue();
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    lockManager.acquireDataverseReadLock(metadataProvider.getLocks(), dvName);
    try {
        doCreateDataverseStatement(mdTxnCtx, metadataProvider, stmtCreateDataverse);
    } catch (Exception e) {
        abort(e, e, mdTxnCtx);
        throw e;
    } finally {
        metadataProvider.getLocks().unlock();
    }
}
#end_block

#method_before
protected static void validateCompactionPolicy(String compactionPolicy, Map<String, String> compactionPolicyProperties, MetadataTransactionContext mdTxnCtx, boolean isExternalDataset) throws CompilationException, Exception {
    CompactionPolicy compactionPolicyEntity = MetadataManager.INSTANCE.getCompactionPolicy(mdTxnCtx, MetadataConstants.METADATA_DATAVERSE_NAME, compactionPolicy);
    if (compactionPolicyEntity == null) {
        throw new CompilationException("Unknown compaction policy: " + compactionPolicy);
    }
    String compactionPolicyFactoryClassName = compactionPolicyEntity.getClassName();
    ILSMMergePolicyFactory mergePolicyFactory = (ILSMMergePolicyFactory) Class.forName(compactionPolicyFactoryClassName).newInstance();
    if (isExternalDataset && mergePolicyFactory.getName().compareTo("correlated-prefix") == 0) {
        throw new CompilationException("The correlated-prefix merge policy cannot be used with external dataset.");
    }
    if (compactionPolicyProperties == null) {
        if (mergePolicyFactory.getName().compareTo("no-merge") != 0) {
            throw new CompilationException("Compaction policy properties are missing.");
        }
    } else {
        for (Map.Entry<String, String> entry : compactionPolicyProperties.entrySet()) {
            if (!mergePolicyFactory.getPropertiesNames().contains(entry.getKey())) {
                throw new CompilationException("Invalid compaction policy property: " + entry.getKey());
            }
        }
        for (String p : mergePolicyFactory.getPropertiesNames()) {
            if (!compactionPolicyProperties.containsKey(p)) {
                throw new CompilationException("Missing compaction policy property: " + p);
            }
        }
    }
}
#method_after
protected static void validateCompactionPolicy(String compactionPolicy, Map<String, String> compactionPolicyProperties, MetadataTransactionContext mdTxnCtx, boolean isExternalDataset, SourceLocation sourceLoc) throws CompilationException, Exception {
    CompactionPolicy compactionPolicyEntity = MetadataManager.INSTANCE.getCompactionPolicy(mdTxnCtx, MetadataConstants.METADATA_DATAVERSE_NAME, compactionPolicy);
    if (compactionPolicyEntity == null) {
        throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "Unknown compaction policy: " + compactionPolicy);
    }
    String compactionPolicyFactoryClassName = compactionPolicyEntity.getClassName();
    ILSMMergePolicyFactory mergePolicyFactory = (ILSMMergePolicyFactory) Class.forName(compactionPolicyFactoryClassName).newInstance();
    if (isExternalDataset && mergePolicyFactory.getName().compareTo("correlated-prefix") == 0) {
        throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "The correlated-prefix merge policy cannot be used with external dataset.");
    }
    if (compactionPolicyProperties == null) {
        if (mergePolicyFactory.getName().compareTo("no-merge") != 0) {
            throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "Compaction policy properties are missing.");
        }
    } else {
        for (Map.Entry<String, String> entry : compactionPolicyProperties.entrySet()) {
            if (!mergePolicyFactory.getPropertiesNames().contains(entry.getKey())) {
                throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "Invalid compaction policy property: " + entry.getKey());
            }
        }
        for (String p : mergePolicyFactory.getPropertiesNames()) {
            if (!compactionPolicyProperties.containsKey(p)) {
                throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "Missing compaction policy property: " + p);
            }
        }
    }
}
#end_block

#method_before
public void handleCreateDatasetStatement(MetadataProvider metadataProvider, Statement stmt, IHyracksClientConnection hcc, IRequestParameters requestParameters) throws CompilationException, Exception {
    MutableObject<ProgressState> progress = new MutableObject<>(ProgressState.NO_PROGRESS);
    DatasetDecl dd = (DatasetDecl) stmt;
    String dataverseName = getActiveDataverse(dd.getDataverse());
    String datasetName = dd.getName().getValue();
    DatasetType dsType = dd.getDatasetType();
    String itemTypeDataverseName = getActiveDataverse(dd.getItemTypeDataverse());
    String itemTypeName = dd.getItemTypeName().getValue();
    String metaItemTypeDataverseName = getActiveDataverse(dd.getMetaItemTypeDataverse());
    String metaItemTypeName = dd.getMetaItemTypeName().getValue();
    Identifier ngNameId = dd.getNodegroupName();
    String nodegroupName = ngNameId == null ? null : ngNameId.getValue();
    String compactionPolicy = dd.getCompactionPolicy();
    Map<String, String> compactionPolicyProperties = dd.getCompactionPolicyProperties();
    boolean defaultCompactionPolicy = compactionPolicy == null;
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    boolean bActiveTxn = true;
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    MetadataLockUtil.createDatasetBegin(lockManager, metadataProvider.getLocks(), dataverseName, itemTypeDataverseName, itemTypeDataverseName + "." + itemTypeName, metaItemTypeDataverseName, metaItemTypeDataverseName + "." + metaItemTypeName, nodegroupName, compactionPolicy, dataverseName + "." + datasetName, defaultCompactionPolicy);
    Dataset dataset = null;
    try {
        IDatasetDetails datasetDetails = null;
        Dataset ds = metadataProvider.findDataset(dataverseName, datasetName);
        if (ds != null) {
            if (dd.getIfNotExists()) {
                MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
                return;
            } else {
                throw new AlgebricksException("A dataset with this name " + datasetName + " already exists.");
            }
        }
        Datatype dt = MetadataManager.INSTANCE.getDatatype(metadataProvider.getMetadataTxnContext(), itemTypeDataverseName, itemTypeName);
        if (dt == null) {
            throw new AlgebricksException(": type " + itemTypeName + " could not be found.");
        }
        String ngName = ngNameId != null ? ngNameId.getValue() : configureNodegroupForDataset(appCtx, dd.getHints(), dataverseName, datasetName, metadataProvider);
        if (compactionPolicy == null) {
            compactionPolicy = GlobalConfig.DEFAULT_COMPACTION_POLICY_NAME;
            compactionPolicyProperties = GlobalConfig.DEFAULT_COMPACTION_POLICY_PROPERTIES;
        } else {
            validateCompactionPolicy(compactionPolicy, compactionPolicyProperties, mdTxnCtx, false);
        }
        switch(dd.getDatasetType()) {
            case INTERNAL:
                IAType itemType = dt.getDatatype();
                if (itemType.getTypeTag() != ATypeTag.OBJECT) {
                    throw new AlgebricksException("Dataset type has to be a record type.");
                }
                IAType metaItemType = null;
                if (metaItemTypeDataverseName != null && metaItemTypeName != null) {
                    metaItemType = metadataProvider.findType(metaItemTypeDataverseName, metaItemTypeName);
                }
                if (metaItemType != null && metaItemType.getTypeTag() != ATypeTag.OBJECT) {
                    throw new AlgebricksException("Dataset meta type has to be a record type.");
                }
                ARecordType metaRecType = (ARecordType) metaItemType;
                List<List<String>> partitioningExprs = ((InternalDetailsDecl) dd.getDatasetDetailsDecl()).getPartitioningExprs();
                List<Integer> keySourceIndicators = ((InternalDetailsDecl) dd.getDatasetDetailsDecl()).getKeySourceIndicators();
                boolean autogenerated = ((InternalDetailsDecl) dd.getDatasetDetailsDecl()).isAutogenerated();
                ARecordType aRecordType = (ARecordType) itemType;
                List<IAType> partitioningTypes = ValidateUtil.validatePartitioningExpressions(aRecordType, metaRecType, partitioningExprs, keySourceIndicators, autogenerated);
                List<String> filterField = ((InternalDetailsDecl) dd.getDatasetDetailsDecl()).getFilterField();
                if (filterField != null) {
                    ValidateUtil.validateFilterField(aRecordType, filterField);
                }
                if (compactionPolicy == null && filterField != null) {
                    // If the dataset has a filter and the user didn't specify a merge
                    // policy, then we will pick the
                    // correlated-prefix as the default merge policy.
                    compactionPolicy = GlobalConfig.DEFAULT_FILTERED_DATASET_COMPACTION_POLICY_NAME;
                    compactionPolicyProperties = GlobalConfig.DEFAULT_COMPACTION_POLICY_PROPERTIES;
                }
                datasetDetails = new InternalDatasetDetails(InternalDatasetDetails.FileStructure.BTREE, InternalDatasetDetails.PartitioningStrategy.HASH, partitioningExprs, partitioningExprs, keySourceIndicators, partitioningTypes, autogenerated, filterField);
                break;
            case EXTERNAL:
                String adapter = ((ExternalDetailsDecl) dd.getDatasetDetailsDecl()).getAdapter();
                Map<String, String> properties = ((ExternalDetailsDecl) dd.getDatasetDetailsDecl()).getProperties();
                datasetDetails = new ExternalDatasetDetails(adapter, properties, new Date(), TransactionState.COMMIT);
                break;
            default:
                throw new CompilationException("Unknown datatype " + dd.getDatasetType());
        }
        // #. initialize DatasetIdFactory if it is not initialized.
        if (!DatasetIdFactory.isInitialized()) {
            DatasetIdFactory.initialize(MetadataManager.INSTANCE.getMostRecentDatasetId());
        }
        // #. add a new dataset with PendingAddOp
        dataset = new Dataset(dataverseName, datasetName, itemTypeDataverseName, itemTypeName, metaItemTypeDataverseName, metaItemTypeName, ngName, compactionPolicy, compactionPolicyProperties, datasetDetails, dd.getHints(), dsType, DatasetIdFactory.generateDatasetId(), MetadataUtil.PENDING_ADD_OP);
        MetadataManager.INSTANCE.addDataset(metadataProvider.getMetadataTxnContext(), dataset);
        if (dd.getDatasetType() == DatasetType.INTERNAL) {
            JobSpecification jobSpec = DatasetUtil.createDatasetJobSpec(dataset, metadataProvider);
            // #. make metadataTxn commit before calling runJob.
            MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
            bActiveTxn = false;
            progress.setValue(ProgressState.ADDED_PENDINGOP_RECORD_TO_METADATA);
            // #. runJob
            runJob(hcc, jobSpec);
            // #. begin new metadataTxn
            mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
            bActiveTxn = true;
            metadataProvider.setMetadataTxnContext(mdTxnCtx);
        }
        // #. add a new dataset with PendingNoOp after deleting the dataset with
        // PendingAddOp
        MetadataManager.INSTANCE.dropDataset(metadataProvider.getMetadataTxnContext(), dataverseName, datasetName);
        dataset.setPendingOp(MetadataUtil.PENDING_NO_OP);
        MetadataManager.INSTANCE.addDataset(metadataProvider.getMetadataTxnContext(), dataset);
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
    } catch (Exception e) {
        if (bActiveTxn) {
            abort(e, e, mdTxnCtx);
        }
        if (progress.getValue() == ProgressState.ADDED_PENDINGOP_RECORD_TO_METADATA) {
            // #. execute compensation operations
            // remove the index in NC
            // [Notice]
            // As long as we updated(and committed) metadata, we should remove any effect of
            // the job
            // because an exception occurs during runJob.
            mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
            bActiveTxn = true;
            metadataProvider.setMetadataTxnContext(mdTxnCtx);
            try {
                JobSpecification jobSpec = DatasetUtil.dropDatasetJobSpec(dataset, metadataProvider);
                MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
                bActiveTxn = false;
                runJob(hcc, jobSpec);
            } catch (Exception e2) {
                e.addSuppressed(e2);
                if (bActiveTxn) {
                    abort(e, e2, mdTxnCtx);
                }
            }
            // remove the record from the metadata.
            mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
            metadataProvider.setMetadataTxnContext(mdTxnCtx);
            try {
                MetadataManager.INSTANCE.dropDataset(metadataProvider.getMetadataTxnContext(), dataverseName, datasetName);
                MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
            } catch (Exception e2) {
                e.addSuppressed(e2);
                abort(e, e2, mdTxnCtx);
                throw new IllegalStateException("System is inconsistent state: pending dataset(" + dataverseName + "." + datasetName + ") couldn't be removed from the metadata", e);
            }
        }
        throw e;
    } finally {
        metadataProvider.getLocks().unlock();
    }
}
#method_after
public void handleCreateDatasetStatement(MetadataProvider metadataProvider, Statement stmt, IHyracksClientConnection hcc, IRequestParameters requestParameters) throws CompilationException, Exception {
    MutableObject<ProgressState> progress = new MutableObject<>(ProgressState.NO_PROGRESS);
    DatasetDecl dd = (DatasetDecl) stmt;
    SourceLocation sourceLoc = dd.getSourceLocation();
    String dataverseName = getActiveDataverse(dd.getDataverse());
    String datasetName = dd.getName().getValue();
    DatasetType dsType = dd.getDatasetType();
    String itemTypeDataverseName = getActiveDataverse(dd.getItemTypeDataverse());
    String itemTypeName = dd.getItemTypeName().getValue();
    String metaItemTypeDataverseName = getActiveDataverse(dd.getMetaItemTypeDataverse());
    String metaItemTypeName = dd.getMetaItemTypeName().getValue();
    Identifier ngNameId = dd.getNodegroupName();
    String nodegroupName = ngNameId == null ? null : ngNameId.getValue();
    String compactionPolicy = dd.getCompactionPolicy();
    Map<String, String> compactionPolicyProperties = dd.getCompactionPolicyProperties();
    boolean defaultCompactionPolicy = compactionPolicy == null;
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    boolean bActiveTxn = true;
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    MetadataLockUtil.createDatasetBegin(lockManager, metadataProvider.getLocks(), dataverseName, itemTypeDataverseName, itemTypeDataverseName + "." + itemTypeName, metaItemTypeDataverseName, metaItemTypeDataverseName + "." + metaItemTypeName, nodegroupName, compactionPolicy, dataverseName + "." + datasetName, defaultCompactionPolicy);
    Dataset dataset = null;
    try {
        IDatasetDetails datasetDetails = null;
        Dataset ds = metadataProvider.findDataset(dataverseName, datasetName);
        if (ds != null) {
            if (dd.getIfNotExists()) {
                MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
                return;
            } else {
                throw new CompilationException(ErrorCode.DATASET_EXISTS, sourceLoc, datasetName);
            }
        }
        Datatype dt = MetadataManager.INSTANCE.getDatatype(metadataProvider.getMetadataTxnContext(), itemTypeDataverseName, itemTypeName);
        if (dt == null) {
            throw new CompilationException(ErrorCode.UNKNOWN_TYPE, sourceLoc, itemTypeName);
        }
        String ngName = ngNameId != null ? ngNameId.getValue() : configureNodegroupForDataset(appCtx, dd.getHints(), dataverseName, datasetName, metadataProvider, sourceLoc);
        if (compactionPolicy == null) {
            compactionPolicy = GlobalConfig.DEFAULT_COMPACTION_POLICY_NAME;
            compactionPolicyProperties = GlobalConfig.DEFAULT_COMPACTION_POLICY_PROPERTIES;
        } else {
            validateCompactionPolicy(compactionPolicy, compactionPolicyProperties, mdTxnCtx, false, sourceLoc);
        }
        switch(dd.getDatasetType()) {
            case INTERNAL:
                IAType itemType = dt.getDatatype();
                if (itemType.getTypeTag() != ATypeTag.OBJECT) {
                    throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "Dataset type has to be a record type.");
                }
                IAType metaItemType = null;
                if (metaItemTypeDataverseName != null && metaItemTypeName != null) {
                    metaItemType = metadataProvider.findType(metaItemTypeDataverseName, metaItemTypeName);
                }
                if (metaItemType != null && metaItemType.getTypeTag() != ATypeTag.OBJECT) {
                    throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "Dataset meta type has to be a record type.");
                }
                ARecordType metaRecType = (ARecordType) metaItemType;
                List<List<String>> partitioningExprs = ((InternalDetailsDecl) dd.getDatasetDetailsDecl()).getPartitioningExprs();
                List<Integer> keySourceIndicators = ((InternalDetailsDecl) dd.getDatasetDetailsDecl()).getKeySourceIndicators();
                boolean autogenerated = ((InternalDetailsDecl) dd.getDatasetDetailsDecl()).isAutogenerated();
                ARecordType aRecordType = (ARecordType) itemType;
                List<IAType> partitioningTypes = ValidateUtil.validatePartitioningExpressions(aRecordType, metaRecType, partitioningExprs, keySourceIndicators, autogenerated, sourceLoc);
                List<String> filterField = ((InternalDetailsDecl) dd.getDatasetDetailsDecl()).getFilterField();
                if (filterField != null) {
                    ValidateUtil.validateFilterField(aRecordType, filterField, sourceLoc);
                }
                if (compactionPolicy == null && filterField != null) {
                    // If the dataset has a filter and the user didn't specify a merge
                    // policy, then we will pick the
                    // correlated-prefix as the default merge policy.
                    compactionPolicy = GlobalConfig.DEFAULT_FILTERED_DATASET_COMPACTION_POLICY_NAME;
                    compactionPolicyProperties = GlobalConfig.DEFAULT_COMPACTION_POLICY_PROPERTIES;
                }
                datasetDetails = new InternalDatasetDetails(InternalDatasetDetails.FileStructure.BTREE, InternalDatasetDetails.PartitioningStrategy.HASH, partitioningExprs, partitioningExprs, keySourceIndicators, partitioningTypes, autogenerated, filterField);
                break;
            case EXTERNAL:
                String adapter = ((ExternalDetailsDecl) dd.getDatasetDetailsDecl()).getAdapter();
                Map<String, String> properties = ((ExternalDetailsDecl) dd.getDatasetDetailsDecl()).getProperties();
                datasetDetails = new ExternalDatasetDetails(adapter, properties, new Date(), TransactionState.COMMIT);
                break;
            default:
                throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "Unknown dataset type " + dd.getDatasetType());
        }
        // #. initialize DatasetIdFactory if it is not initialized.
        if (!DatasetIdFactory.isInitialized()) {
            DatasetIdFactory.initialize(MetadataManager.INSTANCE.getMostRecentDatasetId());
        }
        // #. add a new dataset with PendingAddOp
        dataset = new Dataset(dataverseName, datasetName, itemTypeDataverseName, itemTypeName, metaItemTypeDataverseName, metaItemTypeName, ngName, compactionPolicy, compactionPolicyProperties, datasetDetails, dd.getHints(), dsType, DatasetIdFactory.generateDatasetId(), MetadataUtil.PENDING_ADD_OP);
        MetadataManager.INSTANCE.addDataset(metadataProvider.getMetadataTxnContext(), dataset);
        if (dd.getDatasetType() == DatasetType.INTERNAL) {
            JobSpecification jobSpec = DatasetUtil.createDatasetJobSpec(dataset, metadataProvider);
            // #. make metadataTxn commit before calling runJob.
            MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
            bActiveTxn = false;
            progress.setValue(ProgressState.ADDED_PENDINGOP_RECORD_TO_METADATA);
            // #. runJob
            runJob(hcc, jobSpec);
            // #. begin new metadataTxn
            mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
            bActiveTxn = true;
            metadataProvider.setMetadataTxnContext(mdTxnCtx);
        }
        // #. add a new dataset with PendingNoOp after deleting the dataset with
        // PendingAddOp
        MetadataManager.INSTANCE.dropDataset(metadataProvider.getMetadataTxnContext(), dataverseName, datasetName);
        dataset.setPendingOp(MetadataUtil.PENDING_NO_OP);
        MetadataManager.INSTANCE.addDataset(metadataProvider.getMetadataTxnContext(), dataset);
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
    } catch (Exception e) {
        if (bActiveTxn) {
            abort(e, e, mdTxnCtx);
        }
        if (progress.getValue() == ProgressState.ADDED_PENDINGOP_RECORD_TO_METADATA) {
            // #. execute compensation operations
            // remove the index in NC
            // [Notice]
            // As long as we updated(and committed) metadata, we should remove any effect of
            // the job
            // because an exception occurs during runJob.
            mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
            bActiveTxn = true;
            metadataProvider.setMetadataTxnContext(mdTxnCtx);
            try {
                JobSpecification jobSpec = DatasetUtil.dropDatasetJobSpec(dataset, metadataProvider);
                MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
                bActiveTxn = false;
                runJob(hcc, jobSpec);
            } catch (Exception e2) {
                e.addSuppressed(e2);
                if (bActiveTxn) {
                    abort(e, e2, mdTxnCtx);
                }
            }
            // remove the record from the metadata.
            mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
            metadataProvider.setMetadataTxnContext(mdTxnCtx);
            try {
                MetadataManager.INSTANCE.dropDataset(metadataProvider.getMetadataTxnContext(), dataverseName, datasetName);
                MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
            } catch (Exception e2) {
                e.addSuppressed(e2);
                abort(e, e2, mdTxnCtx);
                throw new IllegalStateException("System is inconsistent state: pending dataset(" + dataverseName + "." + datasetName + ") couldn't be removed from the metadata", e);
            }
        }
        throw e;
    } finally {
        metadataProvider.getLocks().unlock();
    }
}
#end_block

#method_before
protected static void validateIfResourceIsActiveInFeed(ICcApplicationContext appCtx, Dataset dataset) throws CompilationException {
    StringBuilder builder = null;
    ActiveNotificationHandler activeEventHandler = (ActiveNotificationHandler) appCtx.getActiveNotificationHandler();
    IActiveEntityEventsListener[] listeners = activeEventHandler.getEventListeners();
    for (IActiveEntityEventsListener listener : listeners) {
        if (listener.isEntityUsingDataset(dataset) && listener.isActive()) {
            if (builder == null) {
                builder = new StringBuilder();
            }
            builder.append(listener.getEntityId() + "\n");
        }
    }
    if (builder != null) {
        throw new CompilationException("Dataset " + dataset.getDataverseName() + "." + dataset.getDatasetName() + " is currently being " + "fed into by the following active entities.\n" + builder.toString());
    }
}
#method_after
protected static void validateIfResourceIsActiveInFeed(ICcApplicationContext appCtx, Dataset dataset, SourceLocation sourceLoc) throws CompilationException {
    StringBuilder builder = null;
    ActiveNotificationHandler activeEventHandler = (ActiveNotificationHandler) appCtx.getActiveNotificationHandler();
    IActiveEntityEventsListener[] listeners = activeEventHandler.getEventListeners();
    for (IActiveEntityEventsListener listener : listeners) {
        if (listener.isEntityUsingDataset(dataset) && listener.isActive()) {
            if (builder == null) {
                builder = new StringBuilder();
            }
            builder.append(listener.getEntityId() + "\n");
        }
    }
    if (builder != null) {
        throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "Dataset " + dataset.getDataverseName() + "." + dataset.getDatasetName() + " is currently being " + "fed into by the following active entities.\n" + builder.toString());
    }
}
#end_block

#method_before
protected static String configureNodegroupForDataset(ICcApplicationContext appCtx, Map<String, String> hints, String dataverseName, String datasetName, MetadataProvider metadataProvider) throws Exception {
    IClusterStateManager csm = appCtx.getClusterStateManager();
    Set<String> allNodes = csm.getParticipantNodes(true);
    Set<String> selectedNodes = new LinkedHashSet<>();
    String hintValue = hints.get(DatasetNodegroupCardinalityHint.NAME);
    if (hintValue == null) {
        selectedNodes.addAll(allNodes);
    } else {
        int nodegroupCardinality;
        final Pair<Boolean, String> validation = DatasetHints.validate(appCtx, DatasetNodegroupCardinalityHint.NAME, hints.get(DatasetNodegroupCardinalityHint.NAME));
        boolean valid = validation.first;
        if (!valid) {
            throw new CompilationException("Incorrect use of hint '" + DatasetNodegroupCardinalityHint.NAME + "': " + validation.second);
        } else {
            nodegroupCardinality = Integer.parseInt(hints.get(DatasetNodegroupCardinalityHint.NAME));
        }
        List<String> allNodeList = new ArrayList<>(allNodes);
        Collections.shuffle(allNodeList);
        selectedNodes.addAll(allNodeList.subList(0, nodegroupCardinality));
    }
    // Creates the associated node group for the dataset.
    return DatasetUtil.createNodeGroupForNewDataset(dataverseName, datasetName, selectedNodes, metadataProvider);
}
#method_after
protected static String configureNodegroupForDataset(ICcApplicationContext appCtx, Map<String, String> hints, String dataverseName, String datasetName, MetadataProvider metadataProvider, SourceLocation sourceLoc) throws Exception {
    IClusterStateManager csm = appCtx.getClusterStateManager();
    Set<String> allNodes = csm.getParticipantNodes(true);
    Set<String> selectedNodes = new LinkedHashSet<>();
    String hintValue = hints.get(DatasetNodegroupCardinalityHint.NAME);
    if (hintValue == null) {
        selectedNodes.addAll(allNodes);
    } else {
        int nodegroupCardinality;
        final Pair<Boolean, String> validation = DatasetHints.validate(appCtx, DatasetNodegroupCardinalityHint.NAME, hints.get(DatasetNodegroupCardinalityHint.NAME));
        boolean valid = validation.first;
        if (!valid) {
            throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "Incorrect use of hint '" + DatasetNodegroupCardinalityHint.NAME + "': " + validation.second);
        } else {
            nodegroupCardinality = Integer.parseInt(hints.get(DatasetNodegroupCardinalityHint.NAME));
        }
        List<String> allNodeList = new ArrayList<>(allNodes);
        Collections.shuffle(allNodeList);
        selectedNodes.addAll(allNodeList.subList(0, nodegroupCardinality));
    }
    // Creates the associated node group for the dataset.
    return DatasetUtil.createNodeGroupForNewDataset(dataverseName, datasetName, selectedNodes, metadataProvider);
}
#end_block

#method_before
public void handleCreateIndexStatement(MetadataProvider metadataProvider, Statement stmt, IHyracksClientConnection hcc, IRequestParameters requestParameters) throws Exception {
    CreateIndexStatement stmtCreateIndex = (CreateIndexStatement) stmt;
    String dataverseName = getActiveDataverse(stmtCreateIndex.getDataverseName());
    String datasetName = stmtCreateIndex.getDatasetName().getValue();
    String indexName = stmtCreateIndex.getIndexName().getValue();
    List<Integer> keySourceIndicators = stmtCreateIndex.getFieldSourceIndicators();
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    String datasetFullyQualifiedName = dataverseName + "." + datasetName;
    Dataset ds = null;
    Index index = null;
    MetadataLockUtil.createIndexBegin(lockManager, metadataProvider.getLocks(), dataverseName, datasetFullyQualifiedName);
    try {
        ds = metadataProvider.findDataset(dataverseName, datasetName);
        if (ds == null) {
            throw new AlgebricksException("There is no dataset with this name " + datasetName + " in dataverse " + dataverseName);
        }
        index = MetadataManager.INSTANCE.getIndex(metadataProvider.getMetadataTxnContext(), dataverseName, datasetName, indexName);
        if (index != null) {
            if (stmtCreateIndex.getIfNotExists()) {
                MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
                return;
            } else {
                throw new AlgebricksException("An index with this name " + indexName + " already exists.");
            }
        }
        // can't create secondary primary index on an external dataset
        if (ds.getDatasetType() == DatasetType.EXTERNAL && stmtCreateIndex.getFieldExprs().isEmpty()) {
            throw new AsterixException(ErrorCode.CANNOT_CREATE_SEC_PRIMARY_IDX_ON_EXT_DATASET);
        }
        Datatype dt = MetadataManager.INSTANCE.getDatatype(metadataProvider.getMetadataTxnContext(), ds.getItemTypeDataverseName(), ds.getItemTypeName());
        ARecordType aRecordType = (ARecordType) dt.getDatatype();
        ARecordType metaRecordType = null;
        if (ds.hasMetaPart()) {
            Datatype metaDt = MetadataManager.INSTANCE.getDatatype(metadataProvider.getMetadataTxnContext(), ds.getMetaItemTypeDataverseName(), ds.getMetaItemTypeName());
            metaRecordType = (ARecordType) metaDt.getDatatype();
        }
        List<List<String>> indexFields = new ArrayList<>();
        List<IAType> indexFieldTypes = new ArrayList<>();
        int keyIndex = 0;
        boolean overridesFieldTypes = false;
        // this set is used to detect duplicates in the specified keys in the create
        // index statement
        // e.g. CREATE INDEX someIdx on dataset(id,id).
        // checking only the names is not enough. Need also to check the source
        // indicators for cases like:
        // CREATE INDEX someIdx on dataset(meta().id, id)
        Set<Pair<List<String>, Integer>> indexKeysSet = new HashSet<>();
        for (Pair<List<String>, IndexedTypeExpression> fieldExpr : stmtCreateIndex.getFieldExprs()) {
            IAType fieldType = null;
            ARecordType subType = KeyFieldTypeUtil.chooseSource(keySourceIndicators, keyIndex, aRecordType, metaRecordType);
            boolean isOpen = subType.isOpen();
            int i = 0;
            if (fieldExpr.first.size() > 1 && !isOpen) {
                while (i < fieldExpr.first.size() - 1 && !isOpen) {
                    subType = (ARecordType) subType.getFieldType(fieldExpr.first.get(i));
                    i++;
                    isOpen = subType.isOpen();
                }
            }
            if (fieldExpr.second == null) {
                fieldType = subType.getSubFieldType(fieldExpr.first.subList(i, fieldExpr.first.size()));
            } else {
                if (!stmtCreateIndex.isEnforced() && stmtCreateIndex.getIndexType() != IndexType.BTREE) {
                    throw new AsterixException(ErrorCode.INDEX_ILLEGAL_NON_ENFORCED_TYPED, stmtCreateIndex.getIndexType());
                }
                if (stmtCreateIndex.isEnforced() && !fieldExpr.second.isUnknownable()) {
                    throw new AsterixException(ErrorCode.INDEX_ILLEGAL_ENFORCED_NON_OPTIONAL, String.valueOf(fieldExpr.first));
                }
                // get the field type, if it's not null, then the field is closed-type
                if (stmtCreateIndex.isEnforced() && subType.getSubFieldType(fieldExpr.first.subList(i, fieldExpr.first.size())) != null) {
                    throw new AsterixException(ErrorCode.INDEX_ILLEGAL_ENFORCED_ON_CLOSED_FIELD, String.valueOf(fieldExpr.first));
                }
                if (!isOpen) {
                    throw new AlgebricksException("Typed index on \"" + fieldExpr.first + "\" field could be created only for open datatype");
                }
                if (stmtCreateIndex.hasMetaField()) {
                    throw new AlgebricksException("Typed open index can only be created on the record part");
                }
                Map<TypeSignature, IAType> typeMap = TypeTranslator.computeTypes(mdTxnCtx, fieldExpr.second.getType(), indexName, dataverseName);
                TypeSignature typeSignature = new TypeSignature(dataverseName, indexName);
                fieldType = typeMap.get(typeSignature);
                overridesFieldTypes = true;
            }
            if (fieldType == null) {
                throw new AlgebricksException("Unknown type " + (fieldExpr.second == null ? fieldExpr.first : fieldExpr.second));
            }
            // there is a duplicate
            if (!indexKeysSet.add(new Pair<>(fieldExpr.first, stmtCreateIndex.getFieldSourceIndicators().get(keyIndex)))) {
                throw new AsterixException(ErrorCode.INDEX_ILLEGAL_REPETITIVE_FIELD, String.valueOf(fieldExpr.first));
            }
            indexFields.add(fieldExpr.first);
            indexFieldTypes.add(fieldType);
            ++keyIndex;
        }
        validateIndexKeyFields(stmtCreateIndex, keySourceIndicators, aRecordType, metaRecordType, indexFields, indexFieldTypes);
        // error message and stop.
        if (stmtCreateIndex.getIndexType() == IndexType.SINGLE_PARTITION_WORD_INVIX || stmtCreateIndex.getIndexType() == IndexType.SINGLE_PARTITION_NGRAM_INVIX || stmtCreateIndex.getIndexType() == IndexType.LENGTH_PARTITIONED_WORD_INVIX || stmtCreateIndex.getIndexType() == IndexType.LENGTH_PARTITIONED_NGRAM_INVIX) {
            List<List<String>> partitioningKeys = ds.getPrimaryKeys();
            for (List<String> partitioningKey : partitioningKeys) {
                IAType keyType = aRecordType.getSubFieldType(partitioningKey);
                ITypeTraits typeTrait = TypeTraitProvider.INSTANCE.getTypeTrait(keyType);
                // If it is not a fixed length
                if (typeTrait.getFixedLength() < 0) {
                    throw new AlgebricksException("The keyword or ngram index -" + indexName + " cannot be created on the dataset -" + datasetName + " due to its variable-length primary key field - " + partitioningKey);
                }
            }
        }
        Index newIndex = new Index(dataverseName, datasetName, indexName, stmtCreateIndex.getIndexType(), indexFields, keySourceIndicators, indexFieldTypes, stmtCreateIndex.getGramLength(), overridesFieldTypes, stmtCreateIndex.isEnforced(), false, MetadataUtil.PENDING_ADD_OP);
        doCreateIndex(hcc, metadataProvider, ds, newIndex, jobFlags);
    } finally {
        metadataProvider.getLocks().unlock();
    }
}
#method_after
public void handleCreateIndexStatement(MetadataProvider metadataProvider, Statement stmt, IHyracksClientConnection hcc, IRequestParameters requestParameters) throws Exception {
    CreateIndexStatement stmtCreateIndex = (CreateIndexStatement) stmt;
    SourceLocation sourceLoc = stmtCreateIndex.getSourceLocation();
    String dataverseName = getActiveDataverse(stmtCreateIndex.getDataverseName());
    String datasetName = stmtCreateIndex.getDatasetName().getValue();
    String indexName = stmtCreateIndex.getIndexName().getValue();
    List<Integer> keySourceIndicators = stmtCreateIndex.getFieldSourceIndicators();
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    String datasetFullyQualifiedName = dataverseName + "." + datasetName;
    Dataset ds = null;
    Index index = null;
    MetadataLockUtil.createIndexBegin(lockManager, metadataProvider.getLocks(), dataverseName, datasetFullyQualifiedName);
    try {
        ds = metadataProvider.findDataset(dataverseName, datasetName);
        if (ds == null) {
            throw new CompilationException(ErrorCode.UNKNOWN_DATASET_IN_DATAVERSE, sourceLoc, datasetName, dataverseName);
        }
        index = MetadataManager.INSTANCE.getIndex(metadataProvider.getMetadataTxnContext(), dataverseName, datasetName, indexName);
        if (index != null) {
            if (stmtCreateIndex.getIfNotExists()) {
                MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
                return;
            } else {
                throw new CompilationException(ErrorCode.INDEX_EXISTS, sourceLoc, indexName);
            }
        }
        // can't create secondary primary index on an external dataset
        if (ds.getDatasetType() == DatasetType.EXTERNAL && stmtCreateIndex.getFieldExprs().isEmpty()) {
            throw new AsterixException(ErrorCode.CANNOT_CREATE_SEC_PRIMARY_IDX_ON_EXT_DATASET);
        }
        Datatype dt = MetadataManager.INSTANCE.getDatatype(metadataProvider.getMetadataTxnContext(), ds.getItemTypeDataverseName(), ds.getItemTypeName());
        ARecordType aRecordType = (ARecordType) dt.getDatatype();
        ARecordType metaRecordType = null;
        if (ds.hasMetaPart()) {
            Datatype metaDt = MetadataManager.INSTANCE.getDatatype(metadataProvider.getMetadataTxnContext(), ds.getMetaItemTypeDataverseName(), ds.getMetaItemTypeName());
            metaRecordType = (ARecordType) metaDt.getDatatype();
        }
        List<List<String>> indexFields = new ArrayList<>();
        List<IAType> indexFieldTypes = new ArrayList<>();
        int keyIndex = 0;
        boolean overridesFieldTypes = false;
        // this set is used to detect duplicates in the specified keys in the create
        // index statement
        // e.g. CREATE INDEX someIdx on dataset(id,id).
        // checking only the names is not enough. Need also to check the source
        // indicators for cases like:
        // CREATE INDEX someIdx on dataset(meta().id, id)
        Set<Pair<List<String>, Integer>> indexKeysSet = new HashSet<>();
        for (Pair<List<String>, IndexedTypeExpression> fieldExpr : stmtCreateIndex.getFieldExprs()) {
            IAType fieldType = null;
            ARecordType subType = KeyFieldTypeUtil.chooseSource(keySourceIndicators, keyIndex, aRecordType, metaRecordType);
            boolean isOpen = subType.isOpen();
            int i = 0;
            if (fieldExpr.first.size() > 1 && !isOpen) {
                while (i < fieldExpr.first.size() - 1 && !isOpen) {
                    subType = (ARecordType) subType.getFieldType(fieldExpr.first.get(i));
                    i++;
                    isOpen = subType.isOpen();
                }
            }
            if (fieldExpr.second == null) {
                fieldType = subType.getSubFieldType(fieldExpr.first.subList(i, fieldExpr.first.size()));
            } else {
                if (!stmtCreateIndex.isEnforced() && stmtCreateIndex.getIndexType() != IndexType.BTREE) {
                    throw new AsterixException(ErrorCode.INDEX_ILLEGAL_NON_ENFORCED_TYPED, sourceLoc, stmtCreateIndex.getIndexType());
                }
                if (stmtCreateIndex.isEnforced() && !fieldExpr.second.isUnknownable()) {
                    throw new AsterixException(ErrorCode.INDEX_ILLEGAL_ENFORCED_NON_OPTIONAL, sourceLoc, String.valueOf(fieldExpr.first));
                }
                // get the field type, if it's not null, then the field is closed-type
                if (stmtCreateIndex.isEnforced() && subType.getSubFieldType(fieldExpr.first.subList(i, fieldExpr.first.size())) != null) {
                    throw new AsterixException(ErrorCode.INDEX_ILLEGAL_ENFORCED_ON_CLOSED_FIELD, sourceLoc, String.valueOf(fieldExpr.first));
                }
                if (!isOpen) {
                    throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "Typed index on \"" + fieldExpr.first + "\" field could be created only for open datatype");
                }
                if (stmtCreateIndex.hasMetaField()) {
                    throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "Typed open index can only be created on the record part");
                }
                Map<TypeSignature, IAType> typeMap = TypeTranslator.computeTypes(mdTxnCtx, fieldExpr.second.getType(), indexName, dataverseName);
                TypeSignature typeSignature = new TypeSignature(dataverseName, indexName);
                fieldType = typeMap.get(typeSignature);
                overridesFieldTypes = true;
            }
            if (fieldType == null) {
                throw new CompilationException(ErrorCode.UNKNOWN_TYPE, sourceLoc, fieldExpr.second == null ? String.valueOf(fieldExpr.first) : String.valueOf(fieldExpr.second));
            }
            // there is a duplicate
            if (!indexKeysSet.add(new Pair<>(fieldExpr.first, stmtCreateIndex.getFieldSourceIndicators().get(keyIndex)))) {
                throw new AsterixException(ErrorCode.INDEX_ILLEGAL_REPETITIVE_FIELD, sourceLoc, String.valueOf(fieldExpr.first));
            }
            indexFields.add(fieldExpr.first);
            indexFieldTypes.add(fieldType);
            ++keyIndex;
        }
        validateIndexKeyFields(stmtCreateIndex, keySourceIndicators, aRecordType, metaRecordType, indexFields, indexFieldTypes);
        // error message and stop.
        if (stmtCreateIndex.getIndexType() == IndexType.SINGLE_PARTITION_WORD_INVIX || stmtCreateIndex.getIndexType() == IndexType.SINGLE_PARTITION_NGRAM_INVIX || stmtCreateIndex.getIndexType() == IndexType.LENGTH_PARTITIONED_WORD_INVIX || stmtCreateIndex.getIndexType() == IndexType.LENGTH_PARTITIONED_NGRAM_INVIX) {
            List<List<String>> partitioningKeys = ds.getPrimaryKeys();
            for (List<String> partitioningKey : partitioningKeys) {
                IAType keyType = aRecordType.getSubFieldType(partitioningKey);
                ITypeTraits typeTrait = TypeTraitProvider.INSTANCE.getTypeTrait(keyType);
                // If it is not a fixed length
                if (typeTrait.getFixedLength() < 0) {
                    throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "The keyword or ngram index -" + indexName + " cannot be created on the dataset -" + datasetName + " due to its variable-length primary key field - " + partitioningKey);
                }
            }
        }
        Index newIndex = new Index(dataverseName, datasetName, indexName, stmtCreateIndex.getIndexType(), indexFields, keySourceIndicators, indexFieldTypes, stmtCreateIndex.getGramLength(), overridesFieldTypes, stmtCreateIndex.isEnforced(), false, MetadataUtil.PENDING_ADD_OP);
        doCreateIndex(hcc, metadataProvider, ds, newIndex, jobFlags, sourceLoc);
    } finally {
        metadataProvider.getLocks().unlock();
    }
}
#end_block

#method_before
public static void doCreateIndex(IHyracksClientConnection hcc, MetadataProvider metadataProvider, Dataset ds, Index index, EnumSet<JobFlag> jobFlags) throws Exception {
    ProgressState progress = ProgressState.NO_PROGRESS;
    boolean bActiveTxn = true;
    Index filesIndex = null;
    boolean firstExternalDatasetIndex = false;
    boolean datasetLocked = false;
    List<ExternalFile> externalFilesSnapshot;
    MetadataTransactionContext mdTxnCtx = metadataProvider.getMetadataTxnContext();
    JobSpecification spec;
    boolean filesIndexReplicated = false;
    try {
        index.setPendingOp(MetadataUtil.PENDING_ADD_OP);
        if (ds.getDatasetType() == DatasetType.INTERNAL) {
            validateIfResourceIsActiveInFeed(metadataProvider.getApplicationContext(), ds);
        } else {
            // Check if the dataset is indexible
            if (!ExternalIndexingOperations.isIndexible((ExternalDatasetDetails) ds.getDatasetDetails())) {
                throw new AlgebricksException("dataset using " + ((ExternalDatasetDetails) ds.getDatasetDetails()).getAdapter() + " Adapter can't be indexed");
            }
            // Check if the name of the index is valid
            if (!ExternalIndexingOperations.isValidIndexName(index.getDatasetName(), index.getIndexName())) {
                throw new AlgebricksException("external dataset index name is invalid");
            }
            // Check if the files index exist
            filesIndex = MetadataManager.INSTANCE.getIndex(metadataProvider.getMetadataTxnContext(), index.getDataverseName(), index.getDatasetName(), IndexingConstants.getFilesIndexName(index.getDatasetName()));
            firstExternalDatasetIndex = filesIndex == null;
            // Lock external dataset
            ExternalDatasetsRegistry.INSTANCE.buildIndexBegin(ds, firstExternalDatasetIndex);
            datasetLocked = true;
            if (firstExternalDatasetIndex) {
                // Verify that no one has created an index before we acquire the lock
                filesIndex = MetadataManager.INSTANCE.getIndex(metadataProvider.getMetadataTxnContext(), index.getDataverseName(), index.getDatasetName(), IndexingConstants.getFilesIndexName(index.getDatasetName()));
                if (filesIndex != null) {
                    ExternalDatasetsRegistry.INSTANCE.buildIndexEnd(ds, firstExternalDatasetIndex);
                    firstExternalDatasetIndex = false;
                    ExternalDatasetsRegistry.INSTANCE.buildIndexBegin(ds, firstExternalDatasetIndex);
                }
            }
            if (firstExternalDatasetIndex) {
                // Get snapshot from External File System
                externalFilesSnapshot = ExternalIndexingOperations.getSnapshotFromExternalFileSystem(ds);
                // Add an entry for the files index
                filesIndex = new Index(index.getDataverseName(), index.getDatasetName(), IndexingConstants.getFilesIndexName(index.getDatasetName()), IndexType.BTREE, ExternalIndexingOperations.FILE_INDEX_FIELD_NAMES, null, ExternalIndexingOperations.FILE_INDEX_FIELD_TYPES, false, false, false, MetadataUtil.PENDING_ADD_OP);
                MetadataManager.INSTANCE.addIndex(metadataProvider.getMetadataTxnContext(), filesIndex);
                // Add files to the external files index
                for (ExternalFile file : externalFilesSnapshot) {
                    MetadataManager.INSTANCE.addExternalFile(mdTxnCtx, file);
                }
                // This is the first index for the external dataset, replicate the files index
                spec = ExternalIndexingOperations.buildFilesIndexCreateJobSpec(ds, externalFilesSnapshot, metadataProvider);
                if (spec == null) {
                    throw new CompilationException("Failed to create job spec for replicating Files Index For external dataset");
                }
                filesIndexReplicated = true;
                runJob(hcc, spec, jobFlags);
            }
        }
        // check whether there exists another enforced index on the same field
        if (index.isEnforced()) {
            List<Index> indexes = MetadataManager.INSTANCE.getDatasetIndexes(metadataProvider.getMetadataTxnContext(), index.getDataverseName(), index.getDatasetName());
            for (Index existingIndex : indexes) {
                if (existingIndex.getKeyFieldNames().equals(index.getKeyFieldNames()) && !existingIndex.getKeyFieldTypes().equals(index.getKeyFieldTypes()) && existingIndex.isEnforced()) {
                    throw new CompilationException("Cannot create index " + index.getIndexName() + " , enforced index " + existingIndex.getIndexName() + " on field \"" + StringUtils.join(index.getKeyFieldNames(), ',') + "\" is already defined with type \"" + existingIndex.getKeyFieldTypes() + "\"");
                }
            }
        }
        // #. add a new index with PendingAddOp
        MetadataManager.INSTANCE.addIndex(metadataProvider.getMetadataTxnContext(), index);
        // #. prepare to create the index artifact in NC.
        spec = IndexUtil.buildSecondaryIndexCreationJobSpec(ds, index, metadataProvider);
        if (spec == null) {
            throw new CompilationException("Failed to create job spec for creating index '" + ds.getDatasetName() + "." + index.getIndexName() + "'");
        }
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
        bActiveTxn = false;
        progress = ProgressState.ADDED_PENDINGOP_RECORD_TO_METADATA;
        // #. create the index artifact in NC.
        runJob(hcc, spec, jobFlags);
        // of the primary index, which is incorrect.
        if (ds.getDatasetType() == DatasetType.INTERNAL) {
            FlushDatasetUtil.flushDataset(hcc, metadataProvider, index.getDataverseName(), index.getDatasetName());
        }
        mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
        bActiveTxn = true;
        metadataProvider.setMetadataTxnContext(mdTxnCtx);
        // #. load data into the index in NC.
        spec = IndexUtil.buildSecondaryIndexLoadingJobSpec(ds, index, metadataProvider);
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
        bActiveTxn = false;
        runJob(hcc, spec, jobFlags);
        // #. begin new metadataTxn
        mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
        bActiveTxn = true;
        metadataProvider.setMetadataTxnContext(mdTxnCtx);
        // #. add another new index with PendingNoOp after deleting the index with
        // PendingAddOp
        MetadataManager.INSTANCE.dropIndex(metadataProvider.getMetadataTxnContext(), index.getDataverseName(), index.getDatasetName(), index.getIndexName());
        index.setPendingOp(MetadataUtil.PENDING_NO_OP);
        MetadataManager.INSTANCE.addIndex(metadataProvider.getMetadataTxnContext(), index);
        // PendingAddOp
        if (firstExternalDatasetIndex) {
            MetadataManager.INSTANCE.dropIndex(metadataProvider.getMetadataTxnContext(), index.getDataverseName(), index.getDatasetName(), filesIndex.getIndexName());
            filesIndex.setPendingOp(MetadataUtil.PENDING_NO_OP);
            MetadataManager.INSTANCE.addIndex(metadataProvider.getMetadataTxnContext(), filesIndex);
            // update transaction timestamp
            ((ExternalDatasetDetails) ds.getDatasetDetails()).setRefreshTimestamp(new Date());
            MetadataManager.INSTANCE.updateDataset(mdTxnCtx, ds);
        }
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
    } catch (Exception e) {
        if (bActiveTxn) {
            abort(e, e, mdTxnCtx);
        }
        // on NC side
        if (filesIndexReplicated) {
            mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
            bActiveTxn = true;
            try {
                JobSpecification jobSpec = ExternalIndexingOperations.buildDropFilesIndexJobSpec(metadataProvider, ds);
                MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
                bActiveTxn = false;
                runJob(hcc, jobSpec, jobFlags);
            } catch (Exception e2) {
                e.addSuppressed(e2);
                if (bActiveTxn) {
                    abort(e, e2, mdTxnCtx);
                }
            }
        }
        if (progress == ProgressState.ADDED_PENDINGOP_RECORD_TO_METADATA) {
            // #. execute compensation operations
            // remove the index in NC
            mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
            bActiveTxn = true;
            metadataProvider.setMetadataTxnContext(mdTxnCtx);
            try {
                JobSpecification jobSpec = IndexUtil.buildDropIndexJobSpec(index, metadataProvider, ds);
                MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
                bActiveTxn = false;
                runJob(hcc, jobSpec, jobFlags);
            } catch (Exception e2) {
                e.addSuppressed(e2);
                if (bActiveTxn) {
                    abort(e, e2, mdTxnCtx);
                }
            }
            if (firstExternalDatasetIndex) {
                mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
                metadataProvider.setMetadataTxnContext(mdTxnCtx);
                try {
                    // Drop External Files from metadata
                    MetadataManager.INSTANCE.dropDatasetExternalFiles(mdTxnCtx, ds);
                    MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
                } catch (Exception e2) {
                    e.addSuppressed(e2);
                    abort(e, e2, mdTxnCtx);
                    throw new IllegalStateException("System is inconsistent state: pending files for(" + index.getDataverseName() + "." + index.getDatasetName() + ") couldn't be removed from the metadata", e);
                }
                mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
                metadataProvider.setMetadataTxnContext(mdTxnCtx);
                try {
                    // Drop the files index from metadata
                    MetadataManager.INSTANCE.dropIndex(metadataProvider.getMetadataTxnContext(), index.getDataverseName(), index.getDatasetName(), IndexingConstants.getFilesIndexName(index.getDatasetName()));
                    MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
                } catch (Exception e2) {
                    e.addSuppressed(e2);
                    abort(e, e2, mdTxnCtx);
                    throw new IllegalStateException("System is inconsistent state: pending index(" + index.getDataverseName() + "." + index.getDatasetName() + "." + IndexingConstants.getFilesIndexName(index.getDatasetName()) + ") couldn't be removed from the metadata", e);
                }
            }
            // remove the record from the metadata.
            mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
            metadataProvider.setMetadataTxnContext(mdTxnCtx);
            try {
                MetadataManager.INSTANCE.dropIndex(metadataProvider.getMetadataTxnContext(), index.getDataverseName(), index.getDatasetName(), index.getIndexName());
                MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
            } catch (Exception e2) {
                e.addSuppressed(e2);
                abort(e, e2, mdTxnCtx);
                throw new IllegalStateException("System is in inconsistent state: pending index(" + index.getDataverseName() + "." + index.getDatasetName() + "." + index.getIndexName() + ") couldn't be removed from the metadata", e);
            }
        }
        throw e;
    } finally {
        if (datasetLocked) {
            ExternalDatasetsRegistry.INSTANCE.buildIndexEnd(ds, firstExternalDatasetIndex);
        }
    }
}
#method_after
public static void doCreateIndex(IHyracksClientConnection hcc, MetadataProvider metadataProvider, Dataset ds, Index index, EnumSet<JobFlag> jobFlags, SourceLocation sourceLoc) throws Exception {
    ProgressState progress = ProgressState.NO_PROGRESS;
    boolean bActiveTxn = true;
    Index filesIndex = null;
    boolean firstExternalDatasetIndex = false;
    boolean datasetLocked = false;
    List<ExternalFile> externalFilesSnapshot;
    MetadataTransactionContext mdTxnCtx = metadataProvider.getMetadataTxnContext();
    JobSpecification spec;
    boolean filesIndexReplicated = false;
    try {
        index.setPendingOp(MetadataUtil.PENDING_ADD_OP);
        if (ds.getDatasetType() == DatasetType.INTERNAL) {
            validateIfResourceIsActiveInFeed(metadataProvider.getApplicationContext(), ds, sourceLoc);
        } else {
            // Check if the dataset is indexible
            if (!ExternalIndexingOperations.isIndexible((ExternalDatasetDetails) ds.getDatasetDetails())) {
                throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "dataset using " + ((ExternalDatasetDetails) ds.getDatasetDetails()).getAdapter() + " Adapter can't be indexed");
            }
            // Check if the name of the index is valid
            if (!ExternalIndexingOperations.isValidIndexName(index.getDatasetName(), index.getIndexName())) {
                throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "external dataset index name is invalid");
            }
            // Check if the files index exist
            filesIndex = MetadataManager.INSTANCE.getIndex(metadataProvider.getMetadataTxnContext(), index.getDataverseName(), index.getDatasetName(), IndexingConstants.getFilesIndexName(index.getDatasetName()));
            firstExternalDatasetIndex = filesIndex == null;
            // Lock external dataset
            ExternalDatasetsRegistry.INSTANCE.buildIndexBegin(ds, firstExternalDatasetIndex);
            datasetLocked = true;
            if (firstExternalDatasetIndex) {
                // Verify that no one has created an index before we acquire the lock
                filesIndex = MetadataManager.INSTANCE.getIndex(metadataProvider.getMetadataTxnContext(), index.getDataverseName(), index.getDatasetName(), IndexingConstants.getFilesIndexName(index.getDatasetName()));
                if (filesIndex != null) {
                    ExternalDatasetsRegistry.INSTANCE.buildIndexEnd(ds, firstExternalDatasetIndex);
                    firstExternalDatasetIndex = false;
                    ExternalDatasetsRegistry.INSTANCE.buildIndexBegin(ds, firstExternalDatasetIndex);
                }
            }
            if (firstExternalDatasetIndex) {
                // Get snapshot from External File System
                externalFilesSnapshot = ExternalIndexingOperations.getSnapshotFromExternalFileSystem(ds);
                // Add an entry for the files index
                filesIndex = new Index(index.getDataverseName(), index.getDatasetName(), IndexingConstants.getFilesIndexName(index.getDatasetName()), IndexType.BTREE, ExternalIndexingOperations.FILE_INDEX_FIELD_NAMES, null, ExternalIndexingOperations.FILE_INDEX_FIELD_TYPES, false, false, false, MetadataUtil.PENDING_ADD_OP);
                MetadataManager.INSTANCE.addIndex(metadataProvider.getMetadataTxnContext(), filesIndex);
                // Add files to the external files index
                for (ExternalFile file : externalFilesSnapshot) {
                    MetadataManager.INSTANCE.addExternalFile(mdTxnCtx, file);
                }
                // This is the first index for the external dataset, replicate the files index
                spec = ExternalIndexingOperations.buildFilesIndexCreateJobSpec(ds, externalFilesSnapshot, metadataProvider);
                if (spec == null) {
                    throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "Failed to create job spec for replicating Files Index For external dataset");
                }
                filesIndexReplicated = true;
                runJob(hcc, spec, jobFlags);
            }
        }
        // check whether there exists another enforced index on the same field
        if (index.isEnforced()) {
            List<Index> indexes = MetadataManager.INSTANCE.getDatasetIndexes(metadataProvider.getMetadataTxnContext(), index.getDataverseName(), index.getDatasetName());
            for (Index existingIndex : indexes) {
                if (existingIndex.getKeyFieldNames().equals(index.getKeyFieldNames()) && !existingIndex.getKeyFieldTypes().equals(index.getKeyFieldTypes()) && existingIndex.isEnforced()) {
                    throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "Cannot create index " + index.getIndexName() + " , enforced index " + existingIndex.getIndexName() + " on field \"" + StringUtils.join(index.getKeyFieldNames(), ',') + "\" is already defined with type \"" + existingIndex.getKeyFieldTypes() + "\"");
                }
            }
        }
        // #. add a new index with PendingAddOp
        MetadataManager.INSTANCE.addIndex(metadataProvider.getMetadataTxnContext(), index);
        // #. prepare to create the index artifact in NC.
        spec = IndexUtil.buildSecondaryIndexCreationJobSpec(ds, index, metadataProvider, sourceLoc);
        if (spec == null) {
            throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "Failed to create job spec for creating index '" + ds.getDatasetName() + "." + index.getIndexName() + "'");
        }
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
        bActiveTxn = false;
        progress = ProgressState.ADDED_PENDINGOP_RECORD_TO_METADATA;
        // #. create the index artifact in NC.
        runJob(hcc, spec, jobFlags);
        // of the primary index, which is incorrect.
        if (ds.getDatasetType() == DatasetType.INTERNAL) {
            FlushDatasetUtil.flushDataset(hcc, metadataProvider, index.getDataverseName(), index.getDatasetName());
        }
        mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
        bActiveTxn = true;
        metadataProvider.setMetadataTxnContext(mdTxnCtx);
        // #. load data into the index in NC.
        spec = IndexUtil.buildSecondaryIndexLoadingJobSpec(ds, index, metadataProvider, sourceLoc);
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
        bActiveTxn = false;
        runJob(hcc, spec, jobFlags);
        // #. begin new metadataTxn
        mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
        bActiveTxn = true;
        metadataProvider.setMetadataTxnContext(mdTxnCtx);
        // #. add another new index with PendingNoOp after deleting the index with
        // PendingAddOp
        MetadataManager.INSTANCE.dropIndex(metadataProvider.getMetadataTxnContext(), index.getDataverseName(), index.getDatasetName(), index.getIndexName());
        index.setPendingOp(MetadataUtil.PENDING_NO_OP);
        MetadataManager.INSTANCE.addIndex(metadataProvider.getMetadataTxnContext(), index);
        // PendingAddOp
        if (firstExternalDatasetIndex) {
            MetadataManager.INSTANCE.dropIndex(metadataProvider.getMetadataTxnContext(), index.getDataverseName(), index.getDatasetName(), filesIndex.getIndexName());
            filesIndex.setPendingOp(MetadataUtil.PENDING_NO_OP);
            MetadataManager.INSTANCE.addIndex(metadataProvider.getMetadataTxnContext(), filesIndex);
            // update transaction timestamp
            ((ExternalDatasetDetails) ds.getDatasetDetails()).setRefreshTimestamp(new Date());
            MetadataManager.INSTANCE.updateDataset(mdTxnCtx, ds);
        }
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
    } catch (Exception e) {
        if (bActiveTxn) {
            abort(e, e, mdTxnCtx);
        }
        // on NC side
        if (filesIndexReplicated) {
            mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
            bActiveTxn = true;
            try {
                JobSpecification jobSpec = ExternalIndexingOperations.buildDropFilesIndexJobSpec(metadataProvider, ds);
                MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
                bActiveTxn = false;
                runJob(hcc, jobSpec, jobFlags);
            } catch (Exception e2) {
                e.addSuppressed(e2);
                if (bActiveTxn) {
                    abort(e, e2, mdTxnCtx);
                }
            }
        }
        if (progress == ProgressState.ADDED_PENDINGOP_RECORD_TO_METADATA) {
            // #. execute compensation operations
            // remove the index in NC
            mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
            bActiveTxn = true;
            metadataProvider.setMetadataTxnContext(mdTxnCtx);
            try {
                JobSpecification jobSpec = IndexUtil.buildDropIndexJobSpec(index, metadataProvider, ds, sourceLoc);
                MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
                bActiveTxn = false;
                runJob(hcc, jobSpec, jobFlags);
            } catch (Exception e2) {
                e.addSuppressed(e2);
                if (bActiveTxn) {
                    abort(e, e2, mdTxnCtx);
                }
            }
            if (firstExternalDatasetIndex) {
                mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
                metadataProvider.setMetadataTxnContext(mdTxnCtx);
                try {
                    // Drop External Files from metadata
                    MetadataManager.INSTANCE.dropDatasetExternalFiles(mdTxnCtx, ds);
                    MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
                } catch (Exception e2) {
                    e.addSuppressed(e2);
                    abort(e, e2, mdTxnCtx);
                    throw new IllegalStateException("System is inconsistent state: pending files for(" + index.getDataverseName() + "." + index.getDatasetName() + ") couldn't be removed from the metadata", e);
                }
                mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
                metadataProvider.setMetadataTxnContext(mdTxnCtx);
                try {
                    // Drop the files index from metadata
                    MetadataManager.INSTANCE.dropIndex(metadataProvider.getMetadataTxnContext(), index.getDataverseName(), index.getDatasetName(), IndexingConstants.getFilesIndexName(index.getDatasetName()));
                    MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
                } catch (Exception e2) {
                    e.addSuppressed(e2);
                    abort(e, e2, mdTxnCtx);
                    throw new IllegalStateException("System is inconsistent state: pending index(" + index.getDataverseName() + "." + index.getDatasetName() + "." + IndexingConstants.getFilesIndexName(index.getDatasetName()) + ") couldn't be removed from the metadata", e);
                }
            }
            // remove the record from the metadata.
            mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
            metadataProvider.setMetadataTxnContext(mdTxnCtx);
            try {
                MetadataManager.INSTANCE.dropIndex(metadataProvider.getMetadataTxnContext(), index.getDataverseName(), index.getDatasetName(), index.getIndexName());
                MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
            } catch (Exception e2) {
                e.addSuppressed(e2);
                abort(e, e2, mdTxnCtx);
                throw new IllegalStateException("System is in inconsistent state: pending index(" + index.getDataverseName() + "." + index.getDatasetName() + "." + index.getIndexName() + ") couldn't be removed from the metadata", e);
            }
        }
        throw e;
    } finally {
        if (datasetLocked) {
            ExternalDatasetsRegistry.INSTANCE.buildIndexEnd(ds, firstExternalDatasetIndex);
        }
    }
}
#end_block

#method_before
protected void handleCreateTypeStatement(MetadataProvider metadataProvider, Statement stmt) throws Exception {
    TypeDecl stmtCreateType = (TypeDecl) stmt;
    String dataverseName = getActiveDataverse(stmtCreateType.getDataverseName());
    String typeName = stmtCreateType.getIdent().getValue();
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    MetadataLockUtil.createTypeBegin(lockManager, metadataProvider.getLocks(), dataverseName, dataverseName + "." + typeName);
    try {
        Dataverse dv = MetadataManager.INSTANCE.getDataverse(mdTxnCtx, dataverseName);
        if (dv == null) {
            throw new AlgebricksException("Unknown dataverse " + dataverseName);
        }
        Datatype dt = MetadataManager.INSTANCE.getDatatype(mdTxnCtx, dataverseName, typeName);
        if (dt != null) {
            if (!stmtCreateType.getIfNotExists()) {
                throw new AlgebricksException("A datatype with this name " + typeName + " already exists.");
            }
        } else {
            if (BuiltinTypeMap.getBuiltinType(typeName) != null) {
                throw new AlgebricksException("Cannot redefine builtin type " + typeName + ".");
            } else {
                Map<TypeSignature, IAType> typeMap = TypeTranslator.computeTypes(mdTxnCtx, stmtCreateType.getTypeDef(), stmtCreateType.getIdent().getValue(), dataverseName);
                TypeSignature typeSignature = new TypeSignature(dataverseName, typeName);
                IAType type = typeMap.get(typeSignature);
                MetadataManager.INSTANCE.addDatatype(mdTxnCtx, new Datatype(dataverseName, typeName, type, false));
            }
        }
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
    } catch (Exception e) {
        abort(e, e, mdTxnCtx);
        throw e;
    } finally {
        metadataProvider.getLocks().unlock();
    }
}
#method_after
protected void handleCreateTypeStatement(MetadataProvider metadataProvider, Statement stmt) throws Exception {
    TypeDecl stmtCreateType = (TypeDecl) stmt;
    SourceLocation sourceLoc = stmtCreateType.getSourceLocation();
    String dataverseName = getActiveDataverse(stmtCreateType.getDataverseName());
    String typeName = stmtCreateType.getIdent().getValue();
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    MetadataLockUtil.createTypeBegin(lockManager, metadataProvider.getLocks(), dataverseName, dataverseName + "." + typeName);
    try {
        Dataverse dv = MetadataManager.INSTANCE.getDataverse(mdTxnCtx, dataverseName);
        if (dv == null) {
            throw new CompilationException(ErrorCode.UNKNOWN_DATAVERSE, sourceLoc, dataverseName);
        }
        Datatype dt = MetadataManager.INSTANCE.getDatatype(mdTxnCtx, dataverseName, typeName);
        if (dt != null) {
            if (!stmtCreateType.getIfNotExists()) {
                throw new CompilationException(ErrorCode.TYPE_EXISTS, sourceLoc, typeName);
            }
        } else {
            if (BuiltinTypeMap.getBuiltinType(typeName) != null) {
                throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "Cannot redefine builtin type " + typeName + ".");
            } else {
                Map<TypeSignature, IAType> typeMap = TypeTranslator.computeTypes(mdTxnCtx, stmtCreateType.getTypeDef(), stmtCreateType.getIdent().getValue(), dataverseName);
                TypeSignature typeSignature = new TypeSignature(dataverseName, typeName);
                IAType type = typeMap.get(typeSignature);
                MetadataManager.INSTANCE.addDatatype(mdTxnCtx, new Datatype(dataverseName, typeName, type, false));
            }
        }
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
    } catch (Exception e) {
        abort(e, e, mdTxnCtx);
        throw e;
    } finally {
        metadataProvider.getLocks().unlock();
    }
}
#end_block

#method_before
protected void handleDataverseDropStatement(MetadataProvider metadataProvider, Statement stmt, IHyracksClientConnection hcc) throws Exception {
    DataverseDropStatement stmtDelete = (DataverseDropStatement) stmt;
    String dataverseName = stmtDelete.getDataverseName().getValue();
    if (dataverseName.equals(MetadataBuiltinEntities.DEFAULT_DATAVERSE_NAME)) {
        throw new HyracksDataException(MetadataBuiltinEntities.DEFAULT_DATAVERSE_NAME + " dataverse can't be dropped");
    }
    ProgressState progress = ProgressState.NO_PROGRESS;
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    boolean bActiveTxn = true;
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    List<JobSpecification> jobsToExecute = new ArrayList<>();
    lockManager.acquireDataverseWriteLock(metadataProvider.getLocks(), dataverseName);
    try {
        Dataverse dv = MetadataManager.INSTANCE.getDataverse(mdTxnCtx, dataverseName);
        if (dv == null) {
            if (stmtDelete.getIfExists()) {
                MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
                return;
            } else {
                throw new AlgebricksException("There is no dataverse with this name " + dataverseName + ".");
            }
        }
        // # check whether any function in current dataverse is being used by others
        List<Function> functionsInDataverse = MetadataManager.INSTANCE.getDataverseFunctions(mdTxnCtx, dataverseName);
        for (Function function : functionsInDataverse) {
            if (isFunctionUsed(mdTxnCtx, function.getSignature(), dataverseName)) {
                throw new MetadataException(ErrorCode.METADATA_DROP_FUCTION_IN_USE, function.getDataverseName() + "." + function.getName() + "@" + function.getArity());
            }
        }
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
        bActiveTxn = false;
        // # disconnect all feeds from any datasets in the dataverse.
        ActiveNotificationHandler activeEventHandler = (ActiveNotificationHandler) appCtx.getActiveNotificationHandler();
        IActiveEntityEventsListener[] activeListeners = activeEventHandler.getEventListeners();
        for (IActiveEntityEventsListener listener : activeListeners) {
            EntityId activeEntityId = listener.getEntityId();
            if (activeEntityId.getExtensionName().equals(Feed.EXTENSION_NAME) && activeEntityId.getDataverse().equals(dataverseName)) {
                if (listener.getState() != ActivityState.STOPPED) {
                    ((ActiveEntityEventsListener) listener).stop(metadataProvider);
                }
                FeedEventsListener feedListener = (FeedEventsListener) listener;
                mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
                bActiveTxn = true;
                metadataProvider.setMetadataTxnContext(mdTxnCtx);
                doDropFeed(hcc, metadataProvider, feedListener.getFeed());
                MetadataManager.INSTANCE.commitTransaction(metadataProvider.getMetadataTxnContext());
                bActiveTxn = false;
            }
        }
        mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
        bActiveTxn = true;
        metadataProvider.setMetadataTxnContext(mdTxnCtx);
        // #. prepare jobs which will drop corresponding datasets with indexes.
        List<Dataset> datasets = MetadataManager.INSTANCE.getDataverseDatasets(mdTxnCtx, dataverseName);
        for (Dataset dataset : datasets) {
            String datasetName = dataset.getDatasetName();
            DatasetType dsType = dataset.getDatasetType();
            if (dsType == DatasetType.INTERNAL) {
                List<Index> indexes = MetadataManager.INSTANCE.getDatasetIndexes(mdTxnCtx, dataverseName, datasetName);
                for (Index index : indexes) {
                    jobsToExecute.add(IndexUtil.buildDropIndexJobSpec(index, metadataProvider, dataset));
                }
            } else {
                // External dataset
                List<Index> indexes = MetadataManager.INSTANCE.getDatasetIndexes(mdTxnCtx, dataverseName, datasetName);
                for (int k = 0; k < indexes.size(); k++) {
                    if (ExternalIndexingOperations.isFileIndex(indexes.get(k))) {
                        jobsToExecute.add(ExternalIndexingOperations.buildDropFilesIndexJobSpec(metadataProvider, dataset));
                    } else {
                        jobsToExecute.add(IndexUtil.buildDropIndexJobSpec(indexes.get(k), metadataProvider, dataset));
                    }
                }
                ExternalDatasetsRegistry.INSTANCE.removeDatasetInfo(dataset);
            }
        }
        jobsToExecute.add(DataverseUtil.dropDataverseJobSpec(dv, metadataProvider));
        // #. mark PendingDropOp on the dataverse record by
        // first, deleting the dataverse record from the DATAVERSE_DATASET
        // second, inserting the dataverse record with the PendingDropOp value into the
        // DATAVERSE_DATASET
        MetadataManager.INSTANCE.dropDataverse(mdTxnCtx, dataverseName);
        MetadataManager.INSTANCE.addDataverse(mdTxnCtx, new Dataverse(dataverseName, dv.getDataFormat(), MetadataUtil.PENDING_DROP_OP));
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
        bActiveTxn = false;
        progress = ProgressState.ADDED_PENDINGOP_RECORD_TO_METADATA;
        for (JobSpecification jobSpec : jobsToExecute) {
            runJob(hcc, jobSpec);
        }
        mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
        bActiveTxn = true;
        metadataProvider.setMetadataTxnContext(mdTxnCtx);
        // #. finally, delete the dataverse.
        MetadataManager.INSTANCE.dropDataverse(mdTxnCtx, dataverseName);
        // Drops all node groups that no longer needed
        for (Dataset dataset : datasets) {
            String nodeGroup = dataset.getNodeGroupName();
            lockManager.acquireNodeGroupWriteLock(metadataProvider.getLocks(), nodeGroup);
            if (MetadataManager.INSTANCE.getNodegroup(mdTxnCtx, nodeGroup) != null) {
                MetadataManager.INSTANCE.dropNodegroup(mdTxnCtx, nodeGroup, true);
            }
        }
        if (activeDataverse != null && activeDataverse.getDataverseName() == dataverseName) {
            activeDataverse = null;
        }
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
    } catch (Exception e) {
        if (bActiveTxn) {
            abort(e, e, mdTxnCtx);
        }
        if (progress == ProgressState.ADDED_PENDINGOP_RECORD_TO_METADATA) {
            if (activeDataverse != null && activeDataverse.getDataverseName() == dataverseName) {
                activeDataverse = null;
            }
            // remove the all indexes in NC
            try {
                for (JobSpecification jobSpec : jobsToExecute) {
                    runJob(hcc, jobSpec);
                }
            } catch (Exception e2) {
                // do no throw exception since still the metadata needs to be compensated.
                e.addSuppressed(e2);
            }
            // remove the record from the metadata.
            mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
            try {
                MetadataManager.INSTANCE.dropDataverse(mdTxnCtx, dataverseName);
                MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
            } catch (Exception e2) {
                e.addSuppressed(e2);
                abort(e, e2, mdTxnCtx);
                throw new IllegalStateException("System is inconsistent state: pending dataverse(" + dataverseName + ") couldn't be removed from the metadata", e);
            }
        }
        throw e;
    } finally {
        metadataProvider.getLocks().unlock();
        ExternalDatasetsRegistry.INSTANCE.releaseAcquiredLocks(metadataProvider);
    }
}
#method_after
protected void handleDataverseDropStatement(MetadataProvider metadataProvider, Statement stmt, IHyracksClientConnection hcc) throws Exception {
    DataverseDropStatement stmtDelete = (DataverseDropStatement) stmt;
    SourceLocation sourceLoc = stmtDelete.getSourceLocation();
    String dataverseName = stmtDelete.getDataverseName().getValue();
    if (dataverseName.equals(MetadataBuiltinEntities.DEFAULT_DATAVERSE_NAME)) {
        throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, MetadataBuiltinEntities.DEFAULT_DATAVERSE_NAME + " dataverse can't be dropped");
    }
    lockManager.acquireDataverseWriteLock(metadataProvider.getLocks(), dataverseName);
    try {
        doDropDataverse(stmtDelete, sourceLoc, metadataProvider, hcc);
    } finally {
        metadataProvider.getLocks().unlock();
        ExternalDatasetsRegistry.INSTANCE.releaseAcquiredLocks(metadataProvider);
    }
}
#end_block

#method_before
public void handleDatasetDropStatement(MetadataProvider metadataProvider, Statement stmt, IHyracksClientConnection hcc, IRequestParameters requestParameters) throws Exception {
    DropDatasetStatement stmtDelete = (DropDatasetStatement) stmt;
    String dataverseName = getActiveDataverse(stmtDelete.getDataverseName());
    String datasetName = stmtDelete.getDatasetName().getValue();
    MetadataLockUtil.dropDatasetBegin(lockManager, metadataProvider.getLocks(), dataverseName, dataverseName + "." + datasetName);
    try {
        doDropDataset(dataverseName, datasetName, metadataProvider, stmtDelete.getIfExists(), hcc, true);
    } finally {
        metadataProvider.getLocks().unlock();
    }
}
#method_after
public void handleDatasetDropStatement(MetadataProvider metadataProvider, Statement stmt, IHyracksClientConnection hcc, IRequestParameters requestParameters) throws Exception {
    DropDatasetStatement stmtDelete = (DropDatasetStatement) stmt;
    SourceLocation sourceLoc = stmtDelete.getSourceLocation();
    String dataverseName = getActiveDataverse(stmtDelete.getDataverseName());
    String datasetName = stmtDelete.getDatasetName().getValue();
    MetadataLockUtil.dropDatasetBegin(lockManager, metadataProvider.getLocks(), dataverseName, dataverseName + "." + datasetName);
    try {
        doDropDataset(dataverseName, datasetName, metadataProvider, stmtDelete.getIfExists(), hcc, true, sourceLoc);
    } finally {
        metadataProvider.getLocks().unlock();
    }
}
#end_block

#method_before
public static void doDropDataset(String dataverseName, String datasetName, MetadataProvider metadataProvider, boolean ifExists, IHyracksClientConnection hcc, boolean dropCorrespondingNodeGroup) throws Exception {
    MutableObject<ProgressState> progress = new MutableObject<>(ProgressState.NO_PROGRESS);
    MutableObject<MetadataTransactionContext> mdTxnCtx = new MutableObject<>(MetadataManager.INSTANCE.beginTransaction());
    MutableBoolean bActiveTxn = new MutableBoolean(true);
    metadataProvider.setMetadataTxnContext(mdTxnCtx.getValue());
    List<JobSpecification> jobsToExecute = new ArrayList<>();
    try {
        Dataset ds = metadataProvider.findDataset(dataverseName, datasetName);
        if (ds == null) {
            if (ifExists) {
                MetadataManager.INSTANCE.commitTransaction(mdTxnCtx.getValue());
                return;
            } else {
                throw new AsterixException(ErrorCode.NO_DATASET_WITH_NAME, dataverseName, datasetName);
            }
        }
        ds.drop(metadataProvider, mdTxnCtx, jobsToExecute, bActiveTxn, progress, hcc, dropCorrespondingNodeGroup);
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx.getValue());
    } catch (Exception e) {
        if (bActiveTxn.booleanValue()) {
            abort(e, e, mdTxnCtx.getValue());
        }
        if (progress.getValue() == ProgressState.ADDED_PENDINGOP_RECORD_TO_METADATA) {
            // remove the all indexes in NC
            try {
                for (JobSpecification jobSpec : jobsToExecute) {
                    JobUtils.runJob(hcc, jobSpec, true);
                }
            } catch (Exception e2) {
                // do no throw exception since still the metadata needs to be compensated.
                e.addSuppressed(e2);
            }
            // remove the record from the metadata.
            mdTxnCtx.setValue(MetadataManager.INSTANCE.beginTransaction());
            metadataProvider.setMetadataTxnContext(mdTxnCtx.getValue());
            try {
                MetadataManager.INSTANCE.dropDataset(metadataProvider.getMetadataTxnContext(), dataverseName, datasetName);
                MetadataManager.INSTANCE.commitTransaction(mdTxnCtx.getValue());
            } catch (Exception e2) {
                e.addSuppressed(e2);
                abort(e, e2, mdTxnCtx.getValue());
                throw new IllegalStateException("System is inconsistent state: pending dataset(" + dataverseName + "." + datasetName + ") couldn't be removed from the metadata", e);
            }
        }
        throw e;
    } finally {
        ExternalDatasetsRegistry.INSTANCE.releaseAcquiredLocks(metadataProvider);
    }
}
#method_after
public static void doDropDataset(String dataverseName, String datasetName, MetadataProvider metadataProvider, boolean ifExists, IHyracksClientConnection hcc, boolean dropCorrespondingNodeGroup, SourceLocation sourceLoc) throws Exception {
    MutableObject<ProgressState> progress = new MutableObject<>(ProgressState.NO_PROGRESS);
    MutableObject<MetadataTransactionContext> mdTxnCtx = new MutableObject<>(MetadataManager.INSTANCE.beginTransaction());
    MutableBoolean bActiveTxn = new MutableBoolean(true);
    metadataProvider.setMetadataTxnContext(mdTxnCtx.getValue());
    List<JobSpecification> jobsToExecute = new ArrayList<>();
    try {
        Dataset ds = metadataProvider.findDataset(dataverseName, datasetName);
        if (ds == null) {
            if (ifExists) {
                MetadataManager.INSTANCE.commitTransaction(mdTxnCtx.getValue());
                return;
            } else {
                throw new CompilationException(ErrorCode.UNKNOWN_DATASET_IN_DATAVERSE, sourceLoc, datasetName, dataverseName);
            }
        }
        ds.drop(metadataProvider, mdTxnCtx, jobsToExecute, bActiveTxn, progress, hcc, dropCorrespondingNodeGroup, sourceLoc);
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx.getValue());
    } catch (Exception e) {
        if (bActiveTxn.booleanValue()) {
            abort(e, e, mdTxnCtx.getValue());
        }
        if (progress.getValue() == ProgressState.ADDED_PENDINGOP_RECORD_TO_METADATA) {
            // remove the all indexes in NC
            try {
                for (JobSpecification jobSpec : jobsToExecute) {
                    JobUtils.runJob(hcc, jobSpec, true);
                }
            } catch (Exception e2) {
                // do no throw exception since still the metadata needs to be compensated.
                e.addSuppressed(e2);
            }
            // remove the record from the metadata.
            mdTxnCtx.setValue(MetadataManager.INSTANCE.beginTransaction());
            metadataProvider.setMetadataTxnContext(mdTxnCtx.getValue());
            try {
                MetadataManager.INSTANCE.dropDataset(metadataProvider.getMetadataTxnContext(), dataverseName, datasetName);
                MetadataManager.INSTANCE.commitTransaction(mdTxnCtx.getValue());
            } catch (Exception e2) {
                e.addSuppressed(e2);
                abort(e, e2, mdTxnCtx.getValue());
                throw new IllegalStateException("System is inconsistent state: pending dataset(" + dataverseName + "." + datasetName + ") couldn't be removed from the metadata", e);
            }
        }
        throw e;
    } finally {
        ExternalDatasetsRegistry.INSTANCE.releaseAcquiredLocks(metadataProvider);
    }
}
#end_block

#method_before
protected void handleIndexDropStatement(MetadataProvider metadataProvider, Statement stmt, IHyracksClientConnection hcc, IRequestParameters requestParameters) throws Exception {
    IndexDropStatement stmtIndexDrop = (IndexDropStatement) stmt;
    String datasetName = stmtIndexDrop.getDatasetName().getValue();
    String dataverseName = getActiveDataverse(stmtIndexDrop.getDataverseName());
    String indexName = stmtIndexDrop.getIndexName().getValue();
    ProgressState progress = ProgressState.NO_PROGRESS;
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    boolean bActiveTxn = true;
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    List<JobSpecification> jobsToExecute = new ArrayList<>();
    String dsFullyQualifiedName = dataverseName + "." + datasetName;
    MetadataLockUtil.dropIndexBegin(lockManager, metadataProvider.getLocks(), dataverseName, dsFullyQualifiedName);
    // For external index
    boolean dropFilesIndex = false;
    try {
        Dataset ds = metadataProvider.findDataset(dataverseName, datasetName);
        if (ds == null) {
            throw new AlgebricksException("There is no dataset with this name " + datasetName + " in dataverse " + dataverseName);
        }
        ActiveNotificationHandler activeEventHandler = (ActiveNotificationHandler) appCtx.getActiveNotificationHandler();
        IActiveEntityEventsListener[] listeners = activeEventHandler.getEventListeners();
        StringBuilder builder = null;
        for (IActiveEntityEventsListener listener : listeners) {
            if (listener.isEntityUsingDataset(ds)) {
                if (builder == null) {
                    builder = new StringBuilder();
                }
                builder.append(new FeedConnectionId(listener.getEntityId(), datasetName) + "\n");
            }
        }
        if (builder != null) {
            throw new CompilationException("Dataset" + datasetName + " is currently being fed into by the following active entities: " + builder.toString());
        }
        if (ds.getDatasetType() == DatasetType.INTERNAL) {
            Index index = MetadataManager.INSTANCE.getIndex(mdTxnCtx, dataverseName, datasetName, indexName);
            if (index == null) {
                if (stmtIndexDrop.getIfExists()) {
                    MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
                    return;
                } else {
                    throw new AlgebricksException("There is no index with this name " + indexName + ".");
                }
            }
            // #. prepare a job to drop the index in NC.
            jobsToExecute.add(IndexUtil.buildDropIndexJobSpec(index, metadataProvider, ds));
            // #. mark PendingDropOp on the existing index
            MetadataManager.INSTANCE.dropIndex(mdTxnCtx, dataverseName, datasetName, indexName);
            MetadataManager.INSTANCE.addIndex(mdTxnCtx, new Index(dataverseName, datasetName, indexName, index.getIndexType(), index.getKeyFieldNames(), index.getKeyFieldSourceIndicators(), index.getKeyFieldTypes(), index.isOverridingKeyFieldTypes(), index.isEnforced(), index.isPrimaryIndex(), MetadataUtil.PENDING_DROP_OP));
            // #. commit the existing transaction before calling runJob.
            MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
            bActiveTxn = false;
            progress = ProgressState.ADDED_PENDINGOP_RECORD_TO_METADATA;
            for (JobSpecification jobSpec : jobsToExecute) {
                runJob(hcc, jobSpec);
            }
            // #. begin a new transaction
            mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
            bActiveTxn = true;
            metadataProvider.setMetadataTxnContext(mdTxnCtx);
            // #. finally, delete the existing index
            MetadataManager.INSTANCE.dropIndex(mdTxnCtx, dataverseName, datasetName, indexName);
        } else {
            // External dataset
            indexName = stmtIndexDrop.getIndexName().getValue();
            Index index = MetadataManager.INSTANCE.getIndex(mdTxnCtx, dataverseName, datasetName, indexName);
            if (index == null) {
                if (stmtIndexDrop.getIfExists()) {
                    MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
                    return;
                } else {
                    throw new AlgebricksException("There is no index with this name " + indexName + ".");
                }
            } else if (ExternalIndexingOperations.isFileIndex(index)) {
                throw new AlgebricksException("Dropping a dataset's files index is not allowed.");
            }
            // #. prepare a job to drop the index in NC.
            jobsToExecute.add(IndexUtil.buildDropIndexJobSpec(index, metadataProvider, ds));
            List<Index> datasetIndexes = MetadataManager.INSTANCE.getDatasetIndexes(mdTxnCtx, dataverseName, datasetName);
            if (datasetIndexes.size() == 2) {
                dropFilesIndex = true;
                // only one index + the files index, we need to delete both of the indexes
                for (Index externalIndex : datasetIndexes) {
                    if (ExternalIndexingOperations.isFileIndex(externalIndex)) {
                        jobsToExecute.add(ExternalIndexingOperations.buildDropFilesIndexJobSpec(metadataProvider, ds));
                        // #. mark PendingDropOp on the existing files index
                        MetadataManager.INSTANCE.dropIndex(mdTxnCtx, dataverseName, datasetName, externalIndex.getIndexName());
                        MetadataManager.INSTANCE.addIndex(mdTxnCtx, new Index(dataverseName, datasetName, externalIndex.getIndexName(), externalIndex.getIndexType(), externalIndex.getKeyFieldNames(), externalIndex.getKeyFieldSourceIndicators(), index.getKeyFieldTypes(), index.isOverridingKeyFieldTypes(), index.isEnforced(), externalIndex.isPrimaryIndex(), MetadataUtil.PENDING_DROP_OP));
                    }
                }
            }
            // #. mark PendingDropOp on the existing index
            MetadataManager.INSTANCE.dropIndex(mdTxnCtx, dataverseName, datasetName, indexName);
            MetadataManager.INSTANCE.addIndex(mdTxnCtx, new Index(dataverseName, datasetName, indexName, index.getIndexType(), index.getKeyFieldNames(), index.getKeyFieldSourceIndicators(), index.getKeyFieldTypes(), index.isOverridingKeyFieldTypes(), index.isEnforced(), index.isPrimaryIndex(), MetadataUtil.PENDING_DROP_OP));
            // #. commit the existing transaction before calling runJob.
            MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
            bActiveTxn = false;
            progress = ProgressState.ADDED_PENDINGOP_RECORD_TO_METADATA;
            for (JobSpecification jobSpec : jobsToExecute) {
                runJob(hcc, jobSpec);
            }
            // #. begin a new transaction
            mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
            bActiveTxn = true;
            metadataProvider.setMetadataTxnContext(mdTxnCtx);
            // #. finally, delete the existing index
            MetadataManager.INSTANCE.dropIndex(mdTxnCtx, dataverseName, datasetName, indexName);
            if (dropFilesIndex) {
                // delete the files index too
                MetadataManager.INSTANCE.dropIndex(mdTxnCtx, dataverseName, datasetName, IndexingConstants.getFilesIndexName(datasetName));
                MetadataManager.INSTANCE.dropDatasetExternalFiles(mdTxnCtx, ds);
                ExternalDatasetsRegistry.INSTANCE.removeDatasetInfo(ds);
            }
        }
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
    } catch (Exception e) {
        if (bActiveTxn) {
            abort(e, e, mdTxnCtx);
        }
        if (progress == ProgressState.ADDED_PENDINGOP_RECORD_TO_METADATA) {
            // remove the all indexes in NC
            try {
                for (JobSpecification jobSpec : jobsToExecute) {
                    runJob(hcc, jobSpec);
                }
            } catch (Exception e2) {
                // do no throw exception since still the metadata needs to be compensated.
                e.addSuppressed(e2);
            }
            // remove the record from the metadata.
            mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
            metadataProvider.setMetadataTxnContext(mdTxnCtx);
            try {
                MetadataManager.INSTANCE.dropIndex(metadataProvider.getMetadataTxnContext(), dataverseName, datasetName, indexName);
                if (dropFilesIndex) {
                    MetadataManager.INSTANCE.dropIndex(metadataProvider.getMetadataTxnContext(), dataverseName, datasetName, IndexingConstants.getFilesIndexName(datasetName));
                }
                MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
            } catch (Exception e2) {
                e.addSuppressed(e2);
                abort(e, e2, mdTxnCtx);
                throw new IllegalStateException("System is inconsistent state: pending index(" + dataverseName + "." + datasetName + "." + indexName + ") couldn't be removed from the metadata", e);
            }
        }
        throw e;
    } finally {
        metadataProvider.getLocks().unlock();
        ExternalDatasetsRegistry.INSTANCE.releaseAcquiredLocks(metadataProvider);
    }
}
#method_after
protected void handleIndexDropStatement(MetadataProvider metadataProvider, Statement stmt, IHyracksClientConnection hcc, IRequestParameters requestParameters) throws Exception {
    IndexDropStatement stmtIndexDrop = (IndexDropStatement) stmt;
    SourceLocation sourceLoc = stmtIndexDrop.getSourceLocation();
    String datasetName = stmtIndexDrop.getDatasetName().getValue();
    String dataverseName = getActiveDataverse(stmtIndexDrop.getDataverseName());
    String indexName = stmtIndexDrop.getIndexName().getValue();
    ProgressState progress = ProgressState.NO_PROGRESS;
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    boolean bActiveTxn = true;
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    List<JobSpecification> jobsToExecute = new ArrayList<>();
    String dsFullyQualifiedName = dataverseName + "." + datasetName;
    MetadataLockUtil.dropIndexBegin(lockManager, metadataProvider.getLocks(), dataverseName, dsFullyQualifiedName);
    // For external index
    boolean dropFilesIndex = false;
    try {
        Dataset ds = metadataProvider.findDataset(dataverseName, datasetName);
        if (ds == null) {
            throw new CompilationException(ErrorCode.UNKNOWN_DATASET_IN_DATAVERSE, sourceLoc, datasetName, dataverseName);
        }
        ActiveNotificationHandler activeEventHandler = (ActiveNotificationHandler) appCtx.getActiveNotificationHandler();
        IActiveEntityEventsListener[] listeners = activeEventHandler.getEventListeners();
        StringBuilder builder = null;
        for (IActiveEntityEventsListener listener : listeners) {
            if (listener.isEntityUsingDataset(ds)) {
                if (builder == null) {
                    builder = new StringBuilder();
                }
                builder.append(new FeedConnectionId(listener.getEntityId(), datasetName) + "\n");
            }
        }
        if (builder != null) {
            throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "Dataset" + datasetName + " is currently being fed into by the following active entities: " + builder.toString());
        }
        if (ds.getDatasetType() == DatasetType.INTERNAL) {
            Index index = MetadataManager.INSTANCE.getIndex(mdTxnCtx, dataverseName, datasetName, indexName);
            if (index == null) {
                if (stmtIndexDrop.getIfExists()) {
                    MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
                    return;
                } else {
                    throw new CompilationException(ErrorCode.UNKNOWN_INDEX, sourceLoc, indexName);
                }
            }
            ensureNonPrimaryIndexDrop(index, sourceLoc);
            // #. prepare a job to drop the index in NC.
            jobsToExecute.add(IndexUtil.buildDropIndexJobSpec(index, metadataProvider, ds, sourceLoc));
            // #. mark PendingDropOp on the existing index
            MetadataManager.INSTANCE.dropIndex(mdTxnCtx, dataverseName, datasetName, indexName);
            MetadataManager.INSTANCE.addIndex(mdTxnCtx, new Index(dataverseName, datasetName, indexName, index.getIndexType(), index.getKeyFieldNames(), index.getKeyFieldSourceIndicators(), index.getKeyFieldTypes(), index.isOverridingKeyFieldTypes(), index.isEnforced(), index.isPrimaryIndex(), MetadataUtil.PENDING_DROP_OP));
            // #. commit the existing transaction before calling runJob.
            MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
            bActiveTxn = false;
            progress = ProgressState.ADDED_PENDINGOP_RECORD_TO_METADATA;
            for (JobSpecification jobSpec : jobsToExecute) {
                runJob(hcc, jobSpec);
            }
            // #. begin a new transaction
            mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
            bActiveTxn = true;
            metadataProvider.setMetadataTxnContext(mdTxnCtx);
            // #. finally, delete the existing index
            MetadataManager.INSTANCE.dropIndex(mdTxnCtx, dataverseName, datasetName, indexName);
        } else {
            // External dataset
            indexName = stmtIndexDrop.getIndexName().getValue();
            Index index = MetadataManager.INSTANCE.getIndex(mdTxnCtx, dataverseName, datasetName, indexName);
            if (index == null) {
                if (stmtIndexDrop.getIfExists()) {
                    MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
                    return;
                } else {
                    throw new CompilationException(ErrorCode.UNKNOWN_INDEX, sourceLoc, indexName);
                }
            } else if (ExternalIndexingOperations.isFileIndex(index)) {
                throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "Dropping a dataset's files index is not allowed.");
            }
            ensureNonPrimaryIndexDrop(index, sourceLoc);
            // #. prepare a job to drop the index in NC.
            jobsToExecute.add(IndexUtil.buildDropIndexJobSpec(index, metadataProvider, ds, sourceLoc));
            List<Index> datasetIndexes = MetadataManager.INSTANCE.getDatasetIndexes(mdTxnCtx, dataverseName, datasetName);
            if (datasetIndexes.size() == 2) {
                dropFilesIndex = true;
                // only one index + the files index, we need to delete both of the indexes
                for (Index externalIndex : datasetIndexes) {
                    if (ExternalIndexingOperations.isFileIndex(externalIndex)) {
                        jobsToExecute.add(ExternalIndexingOperations.buildDropFilesIndexJobSpec(metadataProvider, ds));
                        // #. mark PendingDropOp on the existing files index
                        MetadataManager.INSTANCE.dropIndex(mdTxnCtx, dataverseName, datasetName, externalIndex.getIndexName());
                        MetadataManager.INSTANCE.addIndex(mdTxnCtx, new Index(dataverseName, datasetName, externalIndex.getIndexName(), externalIndex.getIndexType(), externalIndex.getKeyFieldNames(), externalIndex.getKeyFieldSourceIndicators(), index.getKeyFieldTypes(), index.isOverridingKeyFieldTypes(), index.isEnforced(), externalIndex.isPrimaryIndex(), MetadataUtil.PENDING_DROP_OP));
                    }
                }
            }
            // #. mark PendingDropOp on the existing index
            MetadataManager.INSTANCE.dropIndex(mdTxnCtx, dataverseName, datasetName, indexName);
            MetadataManager.INSTANCE.addIndex(mdTxnCtx, new Index(dataverseName, datasetName, indexName, index.getIndexType(), index.getKeyFieldNames(), index.getKeyFieldSourceIndicators(), index.getKeyFieldTypes(), index.isOverridingKeyFieldTypes(), index.isEnforced(), index.isPrimaryIndex(), MetadataUtil.PENDING_DROP_OP));
            // #. commit the existing transaction before calling runJob.
            MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
            bActiveTxn = false;
            progress = ProgressState.ADDED_PENDINGOP_RECORD_TO_METADATA;
            for (JobSpecification jobSpec : jobsToExecute) {
                runJob(hcc, jobSpec);
            }
            // #. begin a new transaction
            mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
            bActiveTxn = true;
            metadataProvider.setMetadataTxnContext(mdTxnCtx);
            // #. finally, delete the existing index
            MetadataManager.INSTANCE.dropIndex(mdTxnCtx, dataverseName, datasetName, indexName);
            if (dropFilesIndex) {
                // delete the files index too
                MetadataManager.INSTANCE.dropIndex(mdTxnCtx, dataverseName, datasetName, IndexingConstants.getFilesIndexName(datasetName));
                MetadataManager.INSTANCE.dropDatasetExternalFiles(mdTxnCtx, ds);
                ExternalDatasetsRegistry.INSTANCE.removeDatasetInfo(ds);
            }
        }
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
    } catch (Exception e) {
        if (bActiveTxn) {
            abort(e, e, mdTxnCtx);
        }
        if (progress == ProgressState.ADDED_PENDINGOP_RECORD_TO_METADATA) {
            // remove the all indexes in NC
            try {
                for (JobSpecification jobSpec : jobsToExecute) {
                    runJob(hcc, jobSpec);
                }
            } catch (Exception e2) {
                // do no throw exception since still the metadata needs to be compensated.
                e.addSuppressed(e2);
            }
            // remove the record from the metadata.
            mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
            metadataProvider.setMetadataTxnContext(mdTxnCtx);
            try {
                MetadataManager.INSTANCE.dropIndex(metadataProvider.getMetadataTxnContext(), dataverseName, datasetName, indexName);
                if (dropFilesIndex) {
                    MetadataManager.INSTANCE.dropIndex(metadataProvider.getMetadataTxnContext(), dataverseName, datasetName, IndexingConstants.getFilesIndexName(datasetName));
                }
                MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
            } catch (Exception e2) {
                e.addSuppressed(e2);
                abort(e, e2, mdTxnCtx);
                throw new IllegalStateException("System is inconsistent state: pending index(" + dataverseName + "." + datasetName + "." + indexName + ") couldn't be removed from the metadata", e);
            }
        }
        throw e;
    } finally {
        metadataProvider.getLocks().unlock();
        ExternalDatasetsRegistry.INSTANCE.releaseAcquiredLocks(metadataProvider);
    }
}
#end_block

#method_before
protected void handleTypeDropStatement(MetadataProvider metadataProvider, Statement stmt) throws Exception {
    TypeDropStatement stmtTypeDrop = (TypeDropStatement) stmt;
    String dataverseName = getActiveDataverse(stmtTypeDrop.getDataverseName());
    String typeName = stmtTypeDrop.getTypeName().getValue();
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    MetadataLockUtil.dropTypeBegin(lockManager, metadataProvider.getLocks(), dataverseName, dataverseName + "." + typeName);
    try {
        Datatype dt = MetadataManager.INSTANCE.getDatatype(mdTxnCtx, dataverseName, typeName);
        if (dt == null) {
            if (!stmtTypeDrop.getIfExists()) {
                throw new AlgebricksException("There is no datatype with this name " + typeName + ".");
            }
        } else {
            MetadataManager.INSTANCE.dropDatatype(mdTxnCtx, dataverseName, typeName);
        }
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
    } catch (Exception e) {
        abort(e, e, mdTxnCtx);
        throw e;
    } finally {
        metadataProvider.getLocks().unlock();
    }
}
#method_after
protected void handleTypeDropStatement(MetadataProvider metadataProvider, Statement stmt) throws Exception {
    TypeDropStatement stmtTypeDrop = (TypeDropStatement) stmt;
    SourceLocation sourceLoc = stmtTypeDrop.getSourceLocation();
    String dataverseName = getActiveDataverse(stmtTypeDrop.getDataverseName());
    String typeName = stmtTypeDrop.getTypeName().getValue();
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    MetadataLockUtil.dropTypeBegin(lockManager, metadataProvider.getLocks(), dataverseName, dataverseName + "." + typeName);
    try {
        Datatype dt = MetadataManager.INSTANCE.getDatatype(mdTxnCtx, dataverseName, typeName);
        if (dt == null) {
            if (!stmtTypeDrop.getIfExists()) {
                throw new CompilationException(ErrorCode.UNKNOWN_TYPE, sourceLoc, typeName);
            }
        } else {
            MetadataManager.INSTANCE.dropDatatype(mdTxnCtx, dataverseName, typeName);
        }
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
    } catch (Exception e) {
        abort(e, e, mdTxnCtx);
        throw e;
    } finally {
        metadataProvider.getLocks().unlock();
    }
}
#end_block

#method_before
protected void handleNodegroupDropStatement(MetadataProvider metadataProvider, Statement stmt) throws Exception {
    NodeGroupDropStatement stmtDelete = (NodeGroupDropStatement) stmt;
    String nodegroupName = stmtDelete.getNodeGroupName().getValue();
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    lockManager.acquireNodeGroupWriteLock(metadataProvider.getLocks(), nodegroupName);
    try {
        NodeGroup ng = MetadataManager.INSTANCE.getNodegroup(mdTxnCtx, nodegroupName);
        if (ng == null) {
            if (!stmtDelete.getIfExists()) {
                throw new AlgebricksException("There is no nodegroup with this name " + nodegroupName + ".");
            }
        } else {
            MetadataManager.INSTANCE.dropNodegroup(mdTxnCtx, nodegroupName, false);
        }
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
    } catch (Exception e) {
        abort(e, e, mdTxnCtx);
        throw e;
    } finally {
        metadataProvider.getLocks().unlock();
    }
}
#method_after
protected void handleNodegroupDropStatement(MetadataProvider metadataProvider, Statement stmt) throws Exception {
    NodeGroupDropStatement stmtDelete = (NodeGroupDropStatement) stmt;
    SourceLocation sourceLoc = stmtDelete.getSourceLocation();
    String nodegroupName = stmtDelete.getNodeGroupName().getValue();
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    lockManager.acquireNodeGroupWriteLock(metadataProvider.getLocks(), nodegroupName);
    try {
        NodeGroup ng = MetadataManager.INSTANCE.getNodegroup(mdTxnCtx, nodegroupName);
        if (ng == null) {
            if (!stmtDelete.getIfExists()) {
                throw new CompilationException(ErrorCode.UNKNOWN_NODEGROUP, sourceLoc, nodegroupName);
            }
        } else {
            MetadataManager.INSTANCE.dropNodegroup(mdTxnCtx, nodegroupName, false);
        }
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
    } catch (Exception e) {
        abort(e, e, mdTxnCtx);
        throw e;
    } finally {
        metadataProvider.getLocks().unlock();
    }
}
#end_block

#method_before
protected void handleCreateFunctionStatement(MetadataProvider metadataProvider, Statement stmt) throws Exception {
    CreateFunctionStatement cfs = (CreateFunctionStatement) stmt;
    FunctionSignature signature = cfs.getFunctionSignature();
    String dataverse = getActiveDataverseName(signature.getNamespace());
    signature.setNamespace(dataverse);
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    MetadataLockUtil.functionStatementBegin(lockManager, metadataProvider.getLocks(), dataverse, dataverse + "." + signature.getName());
    try {
        Dataverse dv = MetadataManager.INSTANCE.getDataverse(mdTxnCtx, dataverse);
        if (dv == null) {
            throw new AlgebricksException("There is no dataverse with this name " + dataverse + ".");
        }
        // Check whether the function is use-able
        metadataProvider.setDefaultDataverse(dv);
        Query wrappedQuery = new Query(false);
        wrappedQuery.setBody(cfs.getFunctionBodyExpression());
        wrappedQuery.setTopLevel(false);
        List<VarIdentifier> varIds = new ArrayList<>();
        for (String v : cfs.getParamList()) {
            varIds.add(new VarIdentifier(v));
        }
        wrappedQuery.setExternalVars(varIds);
        apiFramework.reWriteQuery(declaredFunctions, metadataProvider, wrappedQuery, sessionOutput, false);
        List<List<List<String>>> dependencies = FunctionUtil.getFunctionDependencies(rewriterFactory.createQueryRewriter(), cfs.getFunctionBodyExpression(), metadataProvider);
        final String language = rewriterFactory instanceof SqlppRewriterFactory ? Function.LANGUAGE_SQLPP : Function.LANGUAGE_AQL;
        Function function = new Function(signature, cfs.getParamList(), Function.RETURNTYPE_VOID, cfs.getFunctionBody(), language, FunctionKind.SCALAR.toString(), dependencies);
        MetadataManager.INSTANCE.addFunction(mdTxnCtx, function);
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
    } catch (Exception e) {
        abort(e, e, mdTxnCtx);
        throw e;
    } finally {
        metadataProvider.getLocks().unlock();
        metadataProvider.setDefaultDataverse(activeDataverse);
    }
}
#method_after
protected void handleCreateFunctionStatement(MetadataProvider metadataProvider, Statement stmt) throws Exception {
    CreateFunctionStatement cfs = (CreateFunctionStatement) stmt;
    SourceLocation sourceLoc = cfs.getSourceLocation();
    FunctionSignature signature = cfs.getFunctionSignature();
    String dataverse = getActiveDataverseName(signature.getNamespace());
    signature.setNamespace(dataverse);
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    MetadataLockUtil.functionStatementBegin(lockManager, metadataProvider.getLocks(), dataverse, dataverse + "." + signature.getName());
    try {
        Dataverse dv = MetadataManager.INSTANCE.getDataverse(mdTxnCtx, dataverse);
        if (dv == null) {
            throw new CompilationException(ErrorCode.UNKNOWN_DATAVERSE, sourceLoc, dataverse);
        }
        // Check whether the function is use-able
        metadataProvider.setDefaultDataverse(dv);
        Query wrappedQuery = new Query(false);
        wrappedQuery.setSourceLocation(sourceLoc);
        wrappedQuery.setBody(cfs.getFunctionBodyExpression());
        wrappedQuery.setTopLevel(false);
        List<VarIdentifier> paramVars = new ArrayList<>();
        for (String v : cfs.getParamList()) {
            paramVars.add(new VarIdentifier(v));
        }
        apiFramework.reWriteQuery(declaredFunctions, metadataProvider, wrappedQuery, sessionOutput, false, paramVars);
        List<List<List<String>>> dependencies = FunctionUtil.getFunctionDependencies(rewriterFactory.createQueryRewriter(), cfs.getFunctionBodyExpression(), metadataProvider);
        Function function = new Function(signature, cfs.getParamList(), Function.RETURNTYPE_VOID, cfs.getFunctionBody(), getFunctionLanguage(), FunctionKind.SCALAR.toString(), dependencies);
        MetadataManager.INSTANCE.addFunction(mdTxnCtx, function);
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
    } catch (Exception e) {
        abort(e, e, mdTxnCtx);
        throw e;
    } finally {
        metadataProvider.getLocks().unlock();
        metadataProvider.setDefaultDataverse(activeDataverse);
    }
}
#end_block

#method_before
protected void handleFunctionDropStatement(MetadataProvider metadataProvider, Statement stmt) throws Exception {
    FunctionDropStatement stmtDropFunction = (FunctionDropStatement) stmt;
    FunctionSignature signature = stmtDropFunction.getFunctionSignature();
    signature.setNamespace(getActiveDataverseName(signature.getNamespace()));
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    MetadataLockUtil.functionStatementBegin(lockManager, metadataProvider.getLocks(), signature.getNamespace(), signature.getNamespace() + "." + signature.getName());
    try {
        Function function = MetadataManager.INSTANCE.getFunction(mdTxnCtx, signature);
        if (function == null && !stmtDropFunction.getIfExists()) {
            throw new AlgebricksException("Unknonw function " + signature);
        } else if (isFunctionUsed(mdTxnCtx, signature, null)) {
            throw new MetadataException(ErrorCode.METADATA_DROP_FUCTION_IN_USE, signature);
        } else {
            MetadataManager.INSTANCE.dropFunction(mdTxnCtx, signature);
        }
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
    } catch (Exception e) {
        abort(e, e, mdTxnCtx);
        throw e;
    } finally {
        metadataProvider.getLocks().unlock();
    }
}
#method_after
protected void handleFunctionDropStatement(MetadataProvider metadataProvider, Statement stmt) throws Exception {
    FunctionDropStatement stmtDropFunction = (FunctionDropStatement) stmt;
    SourceLocation sourceLoc = stmtDropFunction.getSourceLocation();
    FunctionSignature signature = stmtDropFunction.getFunctionSignature();
    signature.setNamespace(getActiveDataverseName(signature.getNamespace()));
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    MetadataLockUtil.functionStatementBegin(lockManager, metadataProvider.getLocks(), signature.getNamespace(), signature.getNamespace() + "." + signature.getName());
    try {
        Function function = MetadataManager.INSTANCE.getFunction(mdTxnCtx, signature);
        // If function == null && stmtDropFunction.getIfExists() == true, commit txn directly.
        if (function == null && !stmtDropFunction.getIfExists()) {
            throw new CompilationException(ErrorCode.UNKNOWN_FUNCTION, sourceLoc, signature);
        } else if (function != null) {
            if (isFunctionUsed(mdTxnCtx, signature, null)) {
                throw new MetadataException(ErrorCode.METADATA_DROP_FUCTION_IN_USE, sourceLoc, signature);
            } else {
                MetadataManager.INSTANCE.dropFunction(mdTxnCtx, signature);
            }
        }
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
    } catch (Exception e) {
        abort(e, e, mdTxnCtx);
        throw e;
    } finally {
        metadataProvider.getLocks().unlock();
    }
}
#end_block

#method_before
protected void handleLoadStatement(MetadataProvider metadataProvider, Statement stmt, IHyracksClientConnection hcc) throws Exception {
    LoadStatement loadStmt = (LoadStatement) stmt;
    String dataverseName = getActiveDataverse(loadStmt.getDataverseName());
    String datasetName = loadStmt.getDatasetName().getValue();
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    boolean bActiveTxn = true;
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    MetadataLockUtil.modifyDatasetBegin(lockManager, metadataProvider.getLocks(), dataverseName, dataverseName + "." + datasetName);
    try {
        CompiledLoadFromFileStatement cls = new CompiledLoadFromFileStatement(dataverseName, loadStmt.getDatasetName().getValue(), loadStmt.getAdapter(), loadStmt.getProperties(), loadStmt.dataIsAlreadySorted());
        JobSpecification spec = apiFramework.compileQuery(hcc, metadataProvider, null, 0, null, sessionOutput, cls);
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
        bActiveTxn = false;
        if (spec != null) {
            runJob(hcc, spec);
        }
    } catch (Exception e) {
        if (bActiveTxn) {
            abort(e, e, mdTxnCtx);
        }
        throw e;
    } finally {
        metadataProvider.getLocks().unlock();
    }
}
#method_after
protected void handleLoadStatement(MetadataProvider metadataProvider, Statement stmt, IHyracksClientConnection hcc) throws Exception {
    LoadStatement loadStmt = (LoadStatement) stmt;
    String dataverseName = getActiveDataverse(loadStmt.getDataverseName());
    String datasetName = loadStmt.getDatasetName().getValue();
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    boolean bActiveTxn = true;
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    MetadataLockUtil.modifyDatasetBegin(lockManager, metadataProvider.getLocks(), dataverseName, dataverseName + "." + datasetName);
    try {
        CompiledLoadFromFileStatement cls = new CompiledLoadFromFileStatement(dataverseName, loadStmt.getDatasetName().getValue(), loadStmt.getAdapter(), loadStmt.getProperties(), loadStmt.dataIsAlreadySorted());
        cls.setSourceLocation(stmt.getSourceLocation());
        JobSpecification spec = apiFramework.compileQuery(hcc, metadataProvider, null, 0, null, sessionOutput, cls, null);
        afterCompile();
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
        bActiveTxn = false;
        if (spec != null) {
            runJob(hcc, spec);
        }
    } catch (Exception e) {
        if (bActiveTxn) {
            abort(e, e, mdTxnCtx);
        }
        throw e;
    } finally {
        metadataProvider.getLocks().unlock();
    }
}
#end_block

#method_before
public JobSpecification handleInsertUpsertStatement(MetadataProvider metadataProvider, Statement stmt, IHyracksClientConnection hcc, IResultSet hdc, ResultDelivery resultDelivery, ResultMetadata outMetadata, Stats stats, boolean compileOnly, String clientContextId) throws Exception {
    InsertStatement stmtInsertUpsert = (InsertStatement) stmt;
    String dataverseName = getActiveDataverse(stmtInsertUpsert.getDataverseName());
    final IMetadataLocker locker = new IMetadataLocker() {

        @Override
        public void lock() throws AlgebricksException {
            MetadataLockUtil.insertDeleteUpsertBegin(lockManager, metadataProvider.getLocks(), dataverseName + "." + stmtInsertUpsert.getDatasetName());
        }

        @Override
        public void unlock() {
            metadataProvider.getLocks().unlock();
        }
    };
    final IStatementCompiler compiler = () -> {
        MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
        boolean bActiveTxn = true;
        metadataProvider.setMetadataTxnContext(mdTxnCtx);
        try {
            metadataProvider.setWriteTransaction(true);
            final JobSpecification jobSpec = rewriteCompileInsertUpsert(hcc, metadataProvider, stmtInsertUpsert);
            MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
            bActiveTxn = false;
            return jobSpec;
        } catch (Exception e) {
            if (bActiveTxn) {
                abort(e, e, mdTxnCtx);
            }
            throw e;
        }
    };
    if (compileOnly) {
        locker.lock();
        try {
            return compiler.compile();
        } finally {
            locker.unlock();
        }
    }
    if (stmtInsertUpsert.getReturnExpression() != null) {
        deliverResult(hcc, hdc, compiler, metadataProvider, locker, resultDelivery, outMetadata, stats, clientContextId, NoOpStatementExecutorContext.INSTANCE);
    } else {
        locker.lock();
        try {
            final JobSpecification jobSpec = compiler.compile();
            if (jobSpec == null) {
                return jobSpec;
            }
            runJob(hcc, jobSpec);
        } finally {
            locker.unlock();
        }
    }
    return null;
}
#method_after
public JobSpecification handleInsertUpsertStatement(MetadataProvider metadataProvider, Statement stmt, IHyracksClientConnection hcc, IResultSet resultSet, ResultDelivery resultDelivery, ResultMetadata outMetadata, Stats stats, boolean compileOnly, String clientContextId, Map<String, IAObject> stmtParams, IStatementRewriter stmtRewriter) throws Exception {
    InsertStatement stmtInsertUpsert = (InsertStatement) stmt;
    String dataverseName = getActiveDataverse(stmtInsertUpsert.getDataverseName());
    final IMetadataLocker locker = new IMetadataLocker() {

        @Override
        public void lock() throws AlgebricksException {
            MetadataLockUtil.insertDeleteUpsertBegin(lockManager, metadataProvider.getLocks(), dataverseName + "." + stmtInsertUpsert.getDatasetName());
        }

        @Override
        public void unlock() {
            metadataProvider.getLocks().unlock();
        }
    };
    final IStatementCompiler compiler = () -> {
        MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
        boolean bActiveTxn = true;
        metadataProvider.setMetadataTxnContext(mdTxnCtx);
        try {
            metadataProvider.setWriteTransaction(true);
            final JobSpecification jobSpec = rewriteCompileInsertUpsert(hcc, metadataProvider, stmtInsertUpsert, stmtParams, stmtRewriter);
            MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
            bActiveTxn = false;
            return jobSpec;
        } catch (Exception e) {
            if (bActiveTxn) {
                abort(e, e, mdTxnCtx);
            }
            throw e;
        }
    };
    if (compileOnly) {
        locker.lock();
        try {
            return compiler.compile();
        } finally {
            locker.unlock();
        }
    }
    if (stmtInsertUpsert.getReturnExpression() != null) {
        deliverResult(hcc, resultSet, compiler, metadataProvider, locker, resultDelivery, outMetadata, stats, clientContextId, NoOpStatementExecutorContext.INSTANCE);
    } else {
        locker.lock();
        try {
            final JobSpecification jobSpec = compiler.compile();
            if (jobSpec == null) {
                return jobSpec;
            }
            runJob(hcc, jobSpec);
        } finally {
            locker.unlock();
        }
    }
    return null;
}
#end_block

#method_before
public JobSpecification handleDeleteStatement(MetadataProvider metadataProvider, Statement stmt, IHyracksClientConnection hcc, boolean compileOnly) throws Exception {
    DeleteStatement stmtDelete = (DeleteStatement) stmt;
    String dataverseName = getActiveDataverse(stmtDelete.getDataverseName());
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    boolean bActiveTxn = true;
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    MetadataLockUtil.insertDeleteUpsertBegin(lockManager, metadataProvider.getLocks(), dataverseName + "." + stmtDelete.getDatasetName());
    try {
        metadataProvider.setWriteTransaction(true);
        CompiledDeleteStatement clfrqs = new CompiledDeleteStatement(stmtDelete.getVariableExpr(), dataverseName, stmtDelete.getDatasetName().getValue(), stmtDelete.getCondition(), stmtDelete.getVarCounter(), stmtDelete.getQuery());
        JobSpecification jobSpec = rewriteCompileQuery(hcc, metadataProvider, clfrqs.getQuery(), clfrqs);
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
        bActiveTxn = false;
        if (jobSpec != null && !compileOnly) {
            runJob(hcc, jobSpec);
        }
        return jobSpec;
    } catch (Exception e) {
        if (bActiveTxn) {
            abort(e, e, mdTxnCtx);
        }
        throw e;
    } finally {
        metadataProvider.getLocks().unlock();
    }
}
#method_after
public JobSpecification handleDeleteStatement(MetadataProvider metadataProvider, Statement stmt, IHyracksClientConnection hcc, boolean compileOnly, Map<String, IAObject> stmtParams, IStatementRewriter stmtRewriter) throws Exception {
    DeleteStatement stmtDelete = (DeleteStatement) stmt;
    String dataverseName = getActiveDataverse(stmtDelete.getDataverseName());
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    boolean bActiveTxn = true;
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    MetadataLockUtil.insertDeleteUpsertBegin(lockManager, metadataProvider.getLocks(), dataverseName + "." + stmtDelete.getDatasetName());
    try {
        metadataProvider.setWriteTransaction(true);
        CompiledDeleteStatement clfrqs = new CompiledDeleteStatement(stmtDelete.getVariableExpr(), dataverseName, stmtDelete.getDatasetName().getValue(), stmtDelete.getCondition(), stmtDelete.getVarCounter(), stmtDelete.getQuery());
        clfrqs.setSourceLocation(stmt.getSourceLocation());
        JobSpecification jobSpec = rewriteCompileQuery(hcc, metadataProvider, clfrqs.getQuery(), clfrqs, stmtParams, stmtRewriter);
        afterCompile();
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
        bActiveTxn = false;
        if (jobSpec != null && !compileOnly) {
            runJob(hcc, jobSpec);
        }
        return jobSpec;
    } catch (Exception e) {
        if (bActiveTxn) {
            abort(e, e, mdTxnCtx);
        }
        throw e;
    } finally {
        metadataProvider.getLocks().unlock();
    }
}
#end_block

#method_before
@Override
public JobSpecification rewriteCompileQuery(IClusterInfoCollector clusterInfoCollector, MetadataProvider metadataProvider, Query query, ICompiledDmlStatement stmt) throws RemoteException, AlgebricksException, ACIDException {
    // Query Rewriting (happens under the same ongoing metadata transaction)
    Pair<IReturningStatement, Integer> rewrittenResult = apiFramework.reWriteQuery(declaredFunctions, metadataProvider, query, sessionOutput, true);
    // Query Compilation (happens under the same ongoing metadata transaction)
    return apiFramework.compileQuery(clusterInfoCollector, metadataProvider, (Query) rewrittenResult.first, rewrittenResult.second, stmt == null ? null : stmt.getDatasetName(), sessionOutput, stmt);
}
#method_after
@Override
public JobSpecification rewriteCompileQuery(IClusterInfoCollector clusterInfoCollector, MetadataProvider metadataProvider, Query query, ICompiledDmlStatement stmt, Map<String, IAObject> stmtParams, IStatementRewriter stmtRewriter) throws AlgebricksException, ACIDException {
    Map<VarIdentifier, IAObject> externalVars = createExternalVariables(stmtParams, stmtRewriter);
    // Query Rewriting (happens under the same ongoing metadata transaction)
    Pair<IReturningStatement, Integer> rewrittenResult = apiFramework.reWriteQuery(declaredFunctions, metadataProvider, query, sessionOutput, true, externalVars.keySet());
    // Query Compilation (happens under the same ongoing metadata transaction)
    return apiFramework.compileQuery(clusterInfoCollector, metadataProvider, (Query) rewrittenResult.first, rewrittenResult.second, stmt == null ? null : stmt.getDatasetName(), sessionOutput, stmt, externalVars);
}
#end_block

#method_before
private JobSpecification rewriteCompileInsertUpsert(IClusterInfoCollector clusterInfoCollector, MetadataProvider metadataProvider, InsertStatement insertUpsert) throws RemoteException, AlgebricksException, ACIDException {
    // Insert/upsert statement rewriting (happens under the same ongoing metadata
    // transaction)
    Pair<IReturningStatement, Integer> rewrittenResult = apiFramework.reWriteQuery(declaredFunctions, metadataProvider, insertUpsert, sessionOutput, true);
    InsertStatement rewrittenInsertUpsert = (InsertStatement) rewrittenResult.first;
    String dataverseName = getActiveDataverse(rewrittenInsertUpsert.getDataverseName());
    String datasetName = rewrittenInsertUpsert.getDatasetName().getValue();
    CompiledInsertStatement clfrqs;
    switch(insertUpsert.getKind()) {
        case INSERT:
            clfrqs = new CompiledInsertStatement(dataverseName, datasetName, rewrittenInsertUpsert.getQuery(), rewrittenInsertUpsert.getVarCounter(), rewrittenInsertUpsert.getVar(), rewrittenInsertUpsert.getReturnExpression());
            break;
        case UPSERT:
            clfrqs = new CompiledUpsertStatement(dataverseName, datasetName, rewrittenInsertUpsert.getQuery(), rewrittenInsertUpsert.getVarCounter(), rewrittenInsertUpsert.getVar(), rewrittenInsertUpsert.getReturnExpression());
            break;
        default:
            throw new AlgebricksException("Unsupported statement type " + rewrittenInsertUpsert.getKind());
    }
    // transaction)
    return apiFramework.compileQuery(clusterInfoCollector, metadataProvider, rewrittenInsertUpsert.getQuery(), rewrittenResult.second, datasetName, sessionOutput, clfrqs);
}
#method_after
private JobSpecification rewriteCompileInsertUpsert(IClusterInfoCollector clusterInfoCollector, MetadataProvider metadataProvider, InsertStatement insertUpsert, Map<String, IAObject> stmtParams, IStatementRewriter stmtRewriter) throws AlgebricksException, ACIDException {
    SourceLocation sourceLoc = insertUpsert.getSourceLocation();
    Map<VarIdentifier, IAObject> externalVars = createExternalVariables(stmtParams, stmtRewriter);
    // Insert/upsert statement rewriting (happens under the same ongoing metadata transaction)
    Pair<IReturningStatement, Integer> rewrittenResult = apiFramework.reWriteQuery(declaredFunctions, metadataProvider, insertUpsert, sessionOutput, true, externalVars.keySet());
    InsertStatement rewrittenInsertUpsert = (InsertStatement) rewrittenResult.first;
    String dataverseName = getActiveDataverse(rewrittenInsertUpsert.getDataverseName());
    String datasetName = rewrittenInsertUpsert.getDatasetName().getValue();
    CompiledInsertStatement clfrqs;
    switch(insertUpsert.getKind()) {
        case INSERT:
            clfrqs = new CompiledInsertStatement(dataverseName, datasetName, rewrittenInsertUpsert.getQuery(), rewrittenInsertUpsert.getVarCounter(), rewrittenInsertUpsert.getVar(), rewrittenInsertUpsert.getReturnExpression());
            clfrqs.setSourceLocation(insertUpsert.getSourceLocation());
            break;
        case UPSERT:
            clfrqs = new CompiledUpsertStatement(dataverseName, datasetName, rewrittenInsertUpsert.getQuery(), rewrittenInsertUpsert.getVarCounter(), rewrittenInsertUpsert.getVar(), rewrittenInsertUpsert.getReturnExpression());
            clfrqs.setSourceLocation(insertUpsert.getSourceLocation());
            break;
        default:
            throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "Unsupported statement type " + rewrittenInsertUpsert.getKind());
    }
    // transaction)
    return apiFramework.compileQuery(clusterInfoCollector, metadataProvider, rewrittenInsertUpsert.getQuery(), rewrittenResult.second, datasetName, sessionOutput, clfrqs, externalVars);
}
#end_block

#method_before
protected void handleCreateFeedStatement(MetadataProvider metadataProvider, Statement stmt) throws Exception {
    CreateFeedStatement cfs = (CreateFeedStatement) stmt;
    String dataverseName = getActiveDataverse(cfs.getDataverseName());
    String feedName = cfs.getFeedName().getValue();
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    MetadataLockUtil.createFeedBegin(lockManager, metadataProvider.getLocks(), dataverseName, dataverseName + "." + feedName);
    try {
        Feed feed = MetadataManager.INSTANCE.getFeed(metadataProvider.getMetadataTxnContext(), dataverseName, feedName);
        if (feed != null) {
            if (cfs.getIfNotExists()) {
                MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
                return;
            } else {
                throw new AlgebricksException("A feed with this name " + feedName + " already exists.");
            }
        }
        feed = new Feed(dataverseName, feedName, cfs.getConfiguration());
        FeedMetadataUtil.validateFeed(feed, mdTxnCtx, appCtx);
        MetadataManager.INSTANCE.addFeed(metadataProvider.getMetadataTxnContext(), feed);
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
    } catch (Exception e) {
        abort(e, e, mdTxnCtx);
        throw e;
    } finally {
        metadataProvider.getLocks().unlock();
    }
}
#method_after
protected void handleCreateFeedStatement(MetadataProvider metadataProvider, Statement stmt) throws Exception {
    CreateFeedStatement cfs = (CreateFeedStatement) stmt;
    SourceLocation sourceLoc = cfs.getSourceLocation();
    String dataverseName = getActiveDataverse(cfs.getDataverseName());
    String feedName = cfs.getFeedName().getValue();
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    MetadataLockUtil.createFeedBegin(lockManager, metadataProvider.getLocks(), dataverseName, dataverseName + "." + feedName);
    try {
        Feed feed = MetadataManager.INSTANCE.getFeed(metadataProvider.getMetadataTxnContext(), dataverseName, feedName);
        if (feed != null) {
            if (cfs.getIfNotExists()) {
                MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
                return;
            } else {
                throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "A feed with this name " + feedName + " already exists.");
            }
        }
        feed = new Feed(dataverseName, feedName, cfs.getConfiguration());
        FeedMetadataUtil.validateFeed(feed, mdTxnCtx, appCtx);
        MetadataManager.INSTANCE.addFeed(metadataProvider.getMetadataTxnContext(), feed);
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
    } catch (Exception e) {
        abort(e, e, mdTxnCtx);
        throw e;
    } finally {
        metadataProvider.getLocks().unlock();
    }
}
#end_block

#method_before
protected void handleCreateFeedPolicyStatement(MetadataProvider metadataProvider, Statement stmt) throws AlgebricksException, HyracksDataException {
    String dataverse;
    String policy;
    FeedPolicyEntity newPolicy = null;
    MetadataTransactionContext mdTxnCtx = null;
    CreateFeedPolicyStatement cfps = (CreateFeedPolicyStatement) stmt;
    dataverse = getActiveDataverse(null);
    policy = cfps.getPolicyName();
    MetadataLockUtil.createFeedPolicyBegin(lockManager, metadataProvider.getLocks(), dataverse, dataverse + "." + policy);
    try {
        mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
        metadataProvider.setMetadataTxnContext(mdTxnCtx);
        FeedPolicyEntity feedPolicy = MetadataManager.INSTANCE.getFeedPolicy(metadataProvider.getMetadataTxnContext(), dataverse, policy);
        if (feedPolicy != null) {
            if (cfps.getIfNotExists()) {
                MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
                return;
            } else {
                throw new AlgebricksException("A policy with this name " + policy + " already exists.");
            }
        }
        boolean extendingExisting = cfps.getSourcePolicyName() != null;
        String description = cfps.getDescription() == null ? "" : cfps.getDescription();
        if (extendingExisting) {
            FeedPolicyEntity sourceFeedPolicy = MetadataManager.INSTANCE.getFeedPolicy(metadataProvider.getMetadataTxnContext(), dataverse, cfps.getSourcePolicyName());
            if (sourceFeedPolicy == null) {
                sourceFeedPolicy = MetadataManager.INSTANCE.getFeedPolicy(metadataProvider.getMetadataTxnContext(), MetadataConstants.METADATA_DATAVERSE_NAME, cfps.getSourcePolicyName());
                if (sourceFeedPolicy == null) {
                    throw new AlgebricksException("Unknown policy " + cfps.getSourcePolicyName());
                }
            }
            Map<String, String> policyProperties = sourceFeedPolicy.getProperties();
            policyProperties.putAll(cfps.getProperties());
            newPolicy = new FeedPolicyEntity(dataverse, policy, description, policyProperties);
        } else {
            Properties prop = new Properties();
            try {
                InputStream stream = new FileInputStream(cfps.getSourcePolicyFile());
                prop.load(stream);
            } catch (Exception e) {
                throw new AlgebricksException("Unable to read policy file" + cfps.getSourcePolicyFile(), e);
            }
            Map<String, String> policyProperties = new HashMap<>();
            prop.forEach((key, value) -> policyProperties.put((String) key, (String) value));
            newPolicy = new FeedPolicyEntity(dataverse, policy, description, policyProperties);
        }
        MetadataManager.INSTANCE.addFeedPolicy(mdTxnCtx, newPolicy);
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
    } catch (RemoteException | ACIDException e) {
        abort(e, e, mdTxnCtx);
        throw new HyracksDataException(e);
    } finally {
        metadataProvider.getLocks().unlock();
    }
}
#method_after
protected void handleCreateFeedPolicyStatement(MetadataProvider metadataProvider, Statement stmt) throws AlgebricksException, HyracksDataException {
    String dataverse;
    String policy;
    FeedPolicyEntity newPolicy = null;
    MetadataTransactionContext mdTxnCtx = null;
    CreateFeedPolicyStatement cfps = (CreateFeedPolicyStatement) stmt;
    SourceLocation sourceLoc = cfps.getSourceLocation();
    dataverse = getActiveDataverse(null);
    policy = cfps.getPolicyName();
    MetadataLockUtil.createFeedPolicyBegin(lockManager, metadataProvider.getLocks(), dataverse, dataverse + "." + policy);
    try {
        mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
        metadataProvider.setMetadataTxnContext(mdTxnCtx);
        FeedPolicyEntity feedPolicy = MetadataManager.INSTANCE.getFeedPolicy(metadataProvider.getMetadataTxnContext(), dataverse, policy);
        if (feedPolicy != null) {
            if (cfps.getIfNotExists()) {
                MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
                return;
            } else {
                throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "A policy with this name " + policy + " already exists.");
            }
        }
        boolean extendingExisting = cfps.getSourcePolicyName() != null;
        String description = cfps.getDescription() == null ? "" : cfps.getDescription();
        if (extendingExisting) {
            FeedPolicyEntity sourceFeedPolicy = MetadataManager.INSTANCE.getFeedPolicy(metadataProvider.getMetadataTxnContext(), dataverse, cfps.getSourcePolicyName());
            if (sourceFeedPolicy == null) {
                sourceFeedPolicy = MetadataManager.INSTANCE.getFeedPolicy(metadataProvider.getMetadataTxnContext(), MetadataConstants.METADATA_DATAVERSE_NAME, cfps.getSourcePolicyName());
                if (sourceFeedPolicy == null) {
                    throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "Unknown policy " + cfps.getSourcePolicyName());
                }
            }
            Map<String, String> policyProperties = sourceFeedPolicy.getProperties();
            policyProperties.putAll(cfps.getProperties());
            newPolicy = new FeedPolicyEntity(dataverse, policy, description, policyProperties);
        } else {
            Properties prop = new Properties();
            try {
                InputStream stream = new FileInputStream(cfps.getSourcePolicyFile());
                prop.load(stream);
            } catch (Exception e) {
                throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "Unable to read policy file" + cfps.getSourcePolicyFile(), e);
            }
            Map<String, String> policyProperties = new HashMap<>();
            prop.forEach((key, value) -> policyProperties.put((String) key, (String) value));
            newPolicy = new FeedPolicyEntity(dataverse, policy, description, policyProperties);
        }
        MetadataManager.INSTANCE.addFeedPolicy(mdTxnCtx, newPolicy);
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
    } catch (RemoteException | ACIDException e) {
        abort(e, e, mdTxnCtx);
        throw HyracksDataException.create(e);
    } finally {
        metadataProvider.getLocks().unlock();
    }
}
#end_block

#method_before
protected void handleDropFeedStatement(MetadataProvider metadataProvider, Statement stmt, IHyracksClientConnection hcc) throws Exception {
    FeedDropStatement stmtFeedDrop = (FeedDropStatement) stmt;
    String dataverseName = getActiveDataverse(stmtFeedDrop.getDataverseName());
    String feedName = stmtFeedDrop.getFeedName().getValue();
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    MetadataLockUtil.dropFeedBegin(lockManager, metadataProvider.getLocks(), dataverseName, dataverseName + "." + feedName);
    try {
        Feed feed = MetadataManager.INSTANCE.getFeed(mdTxnCtx, dataverseName, feedName);
        if (feed == null) {
            if (!stmtFeedDrop.getIfExists()) {
                throw new AlgebricksException("There is no feed with this name " + feedName + ".");
            }
            MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
            return;
        }
        doDropFeed(hcc, metadataProvider, feed);
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
    } catch (Exception e) {
        abort(e, e, mdTxnCtx);
        throw e;
    } finally {
        metadataProvider.getLocks().unlock();
    }
}
#method_after
protected void handleDropFeedStatement(MetadataProvider metadataProvider, Statement stmt, IHyracksClientConnection hcc) throws Exception {
    FeedDropStatement stmtFeedDrop = (FeedDropStatement) stmt;
    SourceLocation sourceLoc = stmtFeedDrop.getSourceLocation();
    String dataverseName = getActiveDataverse(stmtFeedDrop.getDataverseName());
    String feedName = stmtFeedDrop.getFeedName().getValue();
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    MetadataLockUtil.dropFeedBegin(lockManager, metadataProvider.getLocks(), dataverseName, dataverseName + "." + feedName);
    try {
        Feed feed = MetadataManager.INSTANCE.getFeed(mdTxnCtx, dataverseName, feedName);
        if (feed == null) {
            if (!stmtFeedDrop.getIfExists()) {
                throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "There is no feed with this name " + feedName + ".");
            }
            MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
            return;
        }
        doDropFeed(hcc, metadataProvider, feed, sourceLoc);
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
    } catch (Exception e) {
        abort(e, e, mdTxnCtx);
        throw e;
    } finally {
        metadataProvider.getLocks().unlock();
    }
}
#end_block

#method_before
protected void doDropFeed(IHyracksClientConnection hcc, MetadataProvider metadataProvider, Feed feed) throws Exception {
    MetadataTransactionContext mdTxnCtx = metadataProvider.getMetadataTxnContext();
    EntityId feedId = feed.getFeedId();
    ActiveNotificationHandler activeNotificationHandler = (ActiveNotificationHandler) appCtx.getActiveNotificationHandler();
    ActiveEntityEventsListener listener = (ActiveEntityEventsListener) activeNotificationHandler.getListener(feedId);
    if (listener != null && listener.getState() != ActivityState.STOPPED) {
        throw new AlgebricksException("Feed " + feedId + " is currently active and connected to the following dataset(s) \n" + listener.toString());
    } else if (listener != null) {
        listener.unregister();
    }
    JobSpecification spec = FeedOperations.buildRemoveFeedStorageJob(metadataProvider, MetadataManager.INSTANCE.getFeed(mdTxnCtx, feedId.getDataverse(), feedId.getEntityName()));
    runJob(hcc, spec);
    MetadataManager.INSTANCE.dropFeed(mdTxnCtx, feed.getDataverseName(), feed.getFeedName());
    if (LOGGER.isInfoEnabled()) {
        LOGGER.info("Removed feed " + feedId);
    }
}
#method_after
protected void doDropFeed(IHyracksClientConnection hcc, MetadataProvider metadataProvider, Feed feed, SourceLocation sourceLoc) throws Exception {
    MetadataTransactionContext mdTxnCtx = metadataProvider.getMetadataTxnContext();
    EntityId feedId = feed.getFeedId();
    ActiveNotificationHandler activeNotificationHandler = (ActiveNotificationHandler) appCtx.getActiveNotificationHandler();
    ActiveEntityEventsListener listener = (ActiveEntityEventsListener) activeNotificationHandler.getListener(feedId);
    if (listener != null && listener.getState() != ActivityState.STOPPED) {
        throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "Feed " + feedId + " is currently active and connected to the following dataset(s) \n" + listener.toString());
    } else if (listener != null) {
        listener.unregister();
    }
    JobSpecification spec = FeedOperations.buildRemoveFeedStorageJob(metadataProvider, MetadataManager.INSTANCE.getFeed(mdTxnCtx, feedId.getDataverse(), feedId.getEntityName()));
    runJob(hcc, spec);
    MetadataManager.INSTANCE.dropFeed(mdTxnCtx, feed.getDataverseName(), feed.getFeedName());
    if (LOGGER.isInfoEnabled()) {
        LOGGER.info("Removed feed " + feedId);
    }
}
#end_block

#method_before
protected void handleDropFeedPolicyStatement(MetadataProvider metadataProvider, Statement stmt) throws Exception {
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    FeedPolicyDropStatement stmtFeedPolicyDrop = (FeedPolicyDropStatement) stmt;
    String dataverseName = getActiveDataverse(stmtFeedPolicyDrop.getDataverseName());
    String policyName = stmtFeedPolicyDrop.getPolicyName().getValue();
    MetadataLockUtil.dropFeedPolicyBegin(lockManager, metadataProvider.getLocks(), dataverseName, dataverseName + "." + policyName);
    try {
        FeedPolicyEntity feedPolicy = MetadataManager.INSTANCE.getFeedPolicy(mdTxnCtx, dataverseName, policyName);
        if (feedPolicy == null) {
            if (!stmtFeedPolicyDrop.getIfExists()) {
                throw new AlgebricksException("Unknown policy " + policyName + " in dataverse " + dataverseName);
            }
            MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
            return;
        }
        MetadataManager.INSTANCE.dropFeedPolicy(mdTxnCtx, dataverseName, policyName);
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
    } catch (Exception e) {
        abort(e, e, mdTxnCtx);
        throw e;
    } finally {
        metadataProvider.getLocks().unlock();
    }
}
#method_after
protected void handleDropFeedPolicyStatement(MetadataProvider metadataProvider, Statement stmt) throws Exception {
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    FeedPolicyDropStatement stmtFeedPolicyDrop = (FeedPolicyDropStatement) stmt;
    SourceLocation sourceLoc = stmtFeedPolicyDrop.getSourceLocation();
    String dataverseName = getActiveDataverse(stmtFeedPolicyDrop.getDataverseName());
    String policyName = stmtFeedPolicyDrop.getPolicyName().getValue();
    MetadataLockUtil.dropFeedPolicyBegin(lockManager, metadataProvider.getLocks(), dataverseName, dataverseName + "." + policyName);
    try {
        FeedPolicyEntity feedPolicy = MetadataManager.INSTANCE.getFeedPolicy(mdTxnCtx, dataverseName, policyName);
        if (feedPolicy == null) {
            if (!stmtFeedPolicyDrop.getIfExists()) {
                throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "Unknown policy " + policyName + " in dataverse " + dataverseName);
            }
            MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
            return;
        }
        MetadataManager.INSTANCE.dropFeedPolicy(mdTxnCtx, dataverseName, policyName);
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
    } catch (Exception e) {
        abort(e, e, mdTxnCtx);
        throw e;
    } finally {
        metadataProvider.getLocks().unlock();
    }
}
#end_block

#method_before
private void handleStartFeedStatement(MetadataProvider metadataProvider, Statement stmt, IHyracksClientConnection hcc) throws Exception {
    StartFeedStatement sfs = (StartFeedStatement) stmt;
    String dataverseName = getActiveDataverse(sfs.getDataverseName());
    String feedName = sfs.getFeedName().getValue();
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    boolean committed = false;
    MetadataLockUtil.startFeedBegin(lockManager, metadataProvider.getLocks(), dataverseName, dataverseName + "." + feedName);
    try {
        metadataProvider.setMetadataTxnContext(mdTxnCtx);
        // Runtime handler
        EntityId entityId = new EntityId(Feed.EXTENSION_NAME, dataverseName, feedName);
        // Feed & Feed Connections
        Feed feed = FeedMetadataUtil.validateIfFeedExists(dataverseName, feedName, metadataProvider.getMetadataTxnContext());
        List<FeedConnection> feedConnections = MetadataManager.INSTANCE.getFeedConections(metadataProvider.getMetadataTxnContext(), dataverseName, feedName);
        if (feedConnections.isEmpty()) {
            throw new CompilationException(ErrorCode.FEED_START_FEED_WITHOUT_CONNECTION, feedName);
        }
        for (FeedConnection feedConnection : feedConnections) {
            // what if the dataset is in a different dataverse
            String fqName = feedConnection.getDataverseName() + "." + feedConnection.getDatasetName();
            lockManager.acquireDatasetReadLock(metadataProvider.getLocks(), fqName);
        }
        ActiveNotificationHandler activeEventHandler = (ActiveNotificationHandler) appCtx.getActiveNotificationHandler();
        ActiveEntityEventsListener listener = (ActiveEntityEventsListener) activeEventHandler.getListener(entityId);
        if (listener == null) {
            // Prepare policy
            List<Dataset> datasets = new ArrayList<>();
            for (FeedConnection connection : feedConnections) {
                Dataset ds = metadataProvider.findDataset(connection.getDataverseName(), connection.getDatasetName());
                datasets.add(ds);
            }
            listener = new FeedEventsListener(this, metadataProvider.getApplicationContext(), hcc, entityId, datasets, null, FeedIntakeOperatorNodePushable.class.getSimpleName(), NoRetryPolicyFactory.INSTANCE, feed, feedConnections);
        }
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
        committed = true;
        listener.start(metadataProvider);
    } catch (Exception e) {
        if (!committed) {
            abort(e, e, mdTxnCtx);
        }
        throw e;
    } finally {
        metadataProvider.getLocks().unlock();
    }
}
#method_after
private void handleStartFeedStatement(MetadataProvider metadataProvider, Statement stmt, IHyracksClientConnection hcc) throws Exception {
    StartFeedStatement sfs = (StartFeedStatement) stmt;
    SourceLocation sourceLoc = sfs.getSourceLocation();
    String dataverseName = getActiveDataverse(sfs.getDataverseName());
    String feedName = sfs.getFeedName().getValue();
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    boolean committed = false;
    MetadataLockUtil.startFeedBegin(lockManager, metadataProvider.getLocks(), dataverseName, dataverseName + "." + feedName);
    try {
        metadataProvider.setMetadataTxnContext(mdTxnCtx);
        // Runtime handler
        EntityId entityId = new EntityId(Feed.EXTENSION_NAME, dataverseName, feedName);
        // Feed & Feed Connections
        Feed feed = FeedMetadataUtil.validateIfFeedExists(dataverseName, feedName, metadataProvider.getMetadataTxnContext());
        List<FeedConnection> feedConnections = MetadataManager.INSTANCE.getFeedConections(metadataProvider.getMetadataTxnContext(), dataverseName, feedName);
        if (feedConnections.isEmpty()) {
            throw new CompilationException(ErrorCode.FEED_START_FEED_WITHOUT_CONNECTION, sourceLoc, feedName);
        }
        for (FeedConnection feedConnection : feedConnections) {
            // what if the dataset is in a different dataverse
            String fqName = feedConnection.getDataverseName() + "." + feedConnection.getDatasetName();
            lockManager.acquireDatasetReadLock(metadataProvider.getLocks(), fqName);
        }
        ActiveNotificationHandler activeEventHandler = (ActiveNotificationHandler) appCtx.getActiveNotificationHandler();
        ActiveEntityEventsListener listener = (ActiveEntityEventsListener) activeEventHandler.getListener(entityId);
        if (listener == null) {
            // Prepare policy
            List<Dataset> datasets = new ArrayList<>();
            for (FeedConnection connection : feedConnections) {
                Dataset ds = metadataProvider.findDataset(connection.getDataverseName(), connection.getDatasetName());
                datasets.add(ds);
            }
            listener = new FeedEventsListener(this, metadataProvider.getApplicationContext(), hcc, entityId, datasets, null, FeedIntakeOperatorNodePushable.class.getSimpleName(), NoRetryPolicyFactory.INSTANCE, feed, feedConnections);
        }
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
        committed = true;
        listener.start(metadataProvider);
    } catch (Exception e) {
        if (!committed) {
            abort(e, e, mdTxnCtx);
        }
        throw e;
    } finally {
        metadataProvider.getLocks().unlock();
    }
}
#end_block

#method_before
private void handleStopFeedStatement(MetadataProvider metadataProvider, Statement stmt) throws Exception {
    StopFeedStatement sfst = (StopFeedStatement) stmt;
    String dataverseName = getActiveDataverse(sfst.getDataverseName());
    String feedName = sfst.getFeedName().getValue();
    EntityId entityId = new EntityId(Feed.EXTENSION_NAME, dataverseName, feedName);
    ActiveNotificationHandler activeEventHandler = (ActiveNotificationHandler) appCtx.getActiveNotificationHandler();
    // Obtain runtime info from ActiveListener
    ActiveEntityEventsListener listener = (ActiveEntityEventsListener) activeEventHandler.getListener(entityId);
    if (listener == null) {
        throw new AlgebricksException("Feed " + feedName + " is not started.");
    }
    MetadataLockUtil.stopFeedBegin(lockManager, metadataProvider.getLocks(), entityId.getDataverse(), entityId.getEntityName());
    try {
        listener.stop(metadataProvider);
    } finally {
        metadataProvider.getLocks().unlock();
    }
}
#method_after
private void handleStopFeedStatement(MetadataProvider metadataProvider, Statement stmt) throws Exception {
    StopFeedStatement sfst = (StopFeedStatement) stmt;
    SourceLocation sourceLoc = sfst.getSourceLocation();
    String dataverseName = getActiveDataverse(sfst.getDataverseName());
    String feedName = sfst.getFeedName().getValue();
    EntityId entityId = new EntityId(Feed.EXTENSION_NAME, dataverseName, feedName);
    ActiveNotificationHandler activeEventHandler = (ActiveNotificationHandler) appCtx.getActiveNotificationHandler();
    // Obtain runtime info from ActiveListener
    ActiveEntityEventsListener listener = (ActiveEntityEventsListener) activeEventHandler.getListener(entityId);
    if (listener == null) {
        throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "Feed " + feedName + " is not started.");
    }
    MetadataLockUtil.stopFeedBegin(lockManager, metadataProvider.getLocks(), entityId.getDataverse(), entityId.getEntityName());
    try {
        listener.stop(metadataProvider);
    } finally {
        metadataProvider.getLocks().unlock();
    }
}
#end_block

#method_before
private void handleConnectFeedStatement(MetadataProvider metadataProvider, Statement stmt) throws Exception {
    FeedConnection fc;
    ConnectFeedStatement cfs = (ConnectFeedStatement) stmt;
    String dataverseName = getActiveDataverse(cfs.getDataverseName());
    String feedName = cfs.getFeedName();
    String datasetName = cfs.getDatasetName().getValue();
    String policyName = cfs.getPolicy();
    String whereClauseBody = cfs.getWhereClauseBody();
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    // TODO: Check whether we are connecting a change feed to a non-meta dataset
    // Check whether feed is alive
    ActiveNotificationHandler activeEventHandler = (ActiveNotificationHandler) appCtx.getActiveNotificationHandler();
    // Transaction handling
    MetadataLockUtil.connectFeedBegin(lockManager, metadataProvider.getLocks(), dataverseName, dataverseName + "." + datasetName, dataverseName + "." + feedName);
    try {
        // validation
        Dataset dataset = FeedMetadataUtil.validateIfDatasetExists(metadataProvider, dataverseName, datasetName);
        Feed feed = FeedMetadataUtil.validateIfFeedExists(dataverseName, feedName, metadataProvider.getMetadataTxnContext());
        FeedEventsListener listener = (FeedEventsListener) activeEventHandler.getListener(feed.getFeedId());
        if (listener != null && listener.isActive()) {
            throw new CompilationException(ErrorCode.FEED_CHANGE_FEED_CONNECTIVITY_ON_ALIVE_FEED, feedName);
        }
        ARecordType outputType = FeedMetadataUtil.getOutputType(feed, feed.getConfiguration().get(ExternalDataConstants.KEY_TYPE_NAME));
        List<FunctionSignature> appliedFunctions = cfs.getAppliedFunctions();
        for (FunctionSignature func : appliedFunctions) {
            if (MetadataManager.INSTANCE.getFunction(mdTxnCtx, func) == null) {
                throw new CompilationException(ErrorCode.FEED_CONNECT_FEED_APPLIED_INVALID_FUNCTION, func.getName());
            }
        }
        fc = MetadataManager.INSTANCE.getFeedConnection(metadataProvider.getMetadataTxnContext(), dataverseName, feedName, datasetName);
        if (fc != null) {
            throw new AlgebricksException("Feed" + feedName + " is already connected dataset " + datasetName);
        }
        fc = new FeedConnection(dataverseName, feedName, datasetName, appliedFunctions, policyName, whereClauseBody, outputType.getTypeName());
        MetadataManager.INSTANCE.addFeedConnection(metadataProvider.getMetadataTxnContext(), fc);
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
        if (listener != null) {
            listener.add(dataset);
            listener.addFeedConnection(fc);
        }
    } catch (Exception e) {
        abort(e, e, mdTxnCtx);
        throw e;
    } finally {
        metadataProvider.getLocks().unlock();
    }
}
#method_after
private void handleConnectFeedStatement(MetadataProvider metadataProvider, Statement stmt) throws Exception {
    FeedConnection fc;
    ConnectFeedStatement cfs = (ConnectFeedStatement) stmt;
    SourceLocation sourceLoc = cfs.getSourceLocation();
    String dataverseName = getActiveDataverse(cfs.getDataverseName());
    String feedName = cfs.getFeedName();
    String datasetName = cfs.getDatasetName().getValue();
    String policyName = cfs.getPolicy();
    String whereClauseBody = cfs.getWhereClauseBody();
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    // TODO: Check whether we are connecting a change feed to a non-meta dataset
    // Check whether feed is alive
    ActiveNotificationHandler activeEventHandler = (ActiveNotificationHandler) appCtx.getActiveNotificationHandler();
    // Transaction handling
    MetadataLockUtil.connectFeedBegin(lockManager, metadataProvider.getLocks(), dataverseName, dataverseName + "." + datasetName, dataverseName + "." + feedName);
    try {
        // validation
        Dataset dataset = FeedMetadataUtil.validateIfDatasetExists(metadataProvider, dataverseName, datasetName);
        Feed feed = FeedMetadataUtil.validateIfFeedExists(dataverseName, feedName, metadataProvider.getMetadataTxnContext());
        FeedEventsListener listener = (FeedEventsListener) activeEventHandler.getListener(feed.getFeedId());
        if (listener != null && listener.isActive()) {
            throw new CompilationException(ErrorCode.FEED_CHANGE_FEED_CONNECTIVITY_ON_ALIVE_FEED, sourceLoc, feedName);
        }
        ARecordType outputType = FeedMetadataUtil.getOutputType(feed, feed.getConfiguration().get(ExternalDataConstants.KEY_TYPE_NAME));
        List<FunctionSignature> appliedFunctions = cfs.getAppliedFunctions();
        for (FunctionSignature func : appliedFunctions) {
            if (MetadataManager.INSTANCE.getFunction(mdTxnCtx, func) == null) {
                throw new CompilationException(ErrorCode.FEED_CONNECT_FEED_APPLIED_INVALID_FUNCTION, sourceLoc, func.getName());
            }
        }
        fc = MetadataManager.INSTANCE.getFeedConnection(metadataProvider.getMetadataTxnContext(), dataverseName, feedName, datasetName);
        if (fc != null) {
            throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "Feed" + feedName + " is already connected dataset " + datasetName);
        }
        fc = new FeedConnection(dataverseName, feedName, datasetName, appliedFunctions, policyName, whereClauseBody, outputType.getTypeName());
        MetadataManager.INSTANCE.addFeedConnection(metadataProvider.getMetadataTxnContext(), fc);
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
        if (listener != null) {
            listener.add(dataset);
            listener.addFeedConnection(fc);
        }
    } catch (Exception e) {
        abort(e, e, mdTxnCtx);
        throw e;
    } finally {
        metadataProvider.getLocks().unlock();
    }
}
#end_block

#method_before
protected void handleDisconnectFeedStatement(MetadataProvider metadataProvider, Statement stmt) throws Exception {
    DisconnectFeedStatement cfs = (DisconnectFeedStatement) stmt;
    String dataverseName = getActiveDataverse(cfs.getDataverseName());
    String datasetName = cfs.getDatasetName().getValue();
    String feedName = cfs.getFeedName().getValue();
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    MetadataLockUtil.disconnectFeedBegin(lockManager, metadataProvider.getLocks(), dataverseName, dataverseName + "." + datasetName, dataverseName + "." + cfs.getFeedName());
    try {
        ActiveNotificationHandler activeEventHandler = (ActiveNotificationHandler) appCtx.getActiveNotificationHandler();
        // Check whether feed is alive
        ActiveEntityEventsListener listener = (ActiveEntityEventsListener) activeEventHandler.getListener(new EntityId(Feed.EXTENSION_NAME, dataverseName, feedName));
        if (listener != null && listener.isActive()) {
            throw new CompilationException(ErrorCode.FEED_CHANGE_FEED_CONNECTIVITY_ON_ALIVE_FEED, feedName);
        }
        FeedMetadataUtil.validateIfDatasetExists(metadataProvider, dataverseName, cfs.getDatasetName().getValue());
        FeedMetadataUtil.validateIfFeedExists(dataverseName, cfs.getFeedName().getValue(), mdTxnCtx);
        FeedConnection fc = MetadataManager.INSTANCE.getFeedConnection(metadataProvider.getMetadataTxnContext(), dataverseName, feedName, datasetName);
        Dataset ds = metadataProvider.findDataset(dataverseName, datasetName);
        if (ds == null) {
            throw new CompilationException("Dataset " + dataverseName + "." + datasetName + " doesn't exist");
        }
        if (fc == null) {
            throw new CompilationException("Feed " + feedName + " is currently not connected to " + cfs.getDatasetName().getValue() + ". Invalid operation!");
        }
        MetadataManager.INSTANCE.dropFeedConnection(mdTxnCtx, dataverseName, feedName, datasetName);
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
        if (listener != null) {
            listener.remove(ds);
        }
    } catch (Exception e) {
        abort(e, e, mdTxnCtx);
        throw e;
    } finally {
        metadataProvider.getLocks().unlock();
    }
}
#method_after
protected void handleDisconnectFeedStatement(MetadataProvider metadataProvider, Statement stmt) throws Exception {
    DisconnectFeedStatement cfs = (DisconnectFeedStatement) stmt;
    SourceLocation sourceLoc = cfs.getSourceLocation();
    String dataverseName = getActiveDataverse(cfs.getDataverseName());
    String datasetName = cfs.getDatasetName().getValue();
    String feedName = cfs.getFeedName().getValue();
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    MetadataLockUtil.disconnectFeedBegin(lockManager, metadataProvider.getLocks(), dataverseName, dataverseName + "." + datasetName, dataverseName + "." + cfs.getFeedName());
    try {
        ActiveNotificationHandler activeEventHandler = (ActiveNotificationHandler) appCtx.getActiveNotificationHandler();
        // Check whether feed is alive
        ActiveEntityEventsListener listener = (ActiveEntityEventsListener) activeEventHandler.getListener(new EntityId(Feed.EXTENSION_NAME, dataverseName, feedName));
        if (listener != null && listener.isActive()) {
            throw new CompilationException(ErrorCode.FEED_CHANGE_FEED_CONNECTIVITY_ON_ALIVE_FEED, sourceLoc, feedName);
        }
        FeedMetadataUtil.validateIfDatasetExists(metadataProvider, dataverseName, cfs.getDatasetName().getValue());
        FeedMetadataUtil.validateIfFeedExists(dataverseName, cfs.getFeedName().getValue(), mdTxnCtx);
        FeedConnection fc = MetadataManager.INSTANCE.getFeedConnection(metadataProvider.getMetadataTxnContext(), dataverseName, feedName, datasetName);
        Dataset ds = metadataProvider.findDataset(dataverseName, datasetName);
        if (ds == null) {
            throw new CompilationException(ErrorCode.UNKNOWN_DATASET_IN_DATAVERSE, sourceLoc, datasetName, dataverseName);
        }
        if (fc == null) {
            throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "Feed " + feedName + " is currently not connected to " + cfs.getDatasetName().getValue() + ". Invalid operation!");
        }
        MetadataManager.INSTANCE.dropFeedConnection(mdTxnCtx, dataverseName, feedName, datasetName);
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
        if (listener != null) {
            listener.remove(ds);
        }
    } catch (Exception e) {
        abort(e, e, mdTxnCtx);
        throw e;
    } finally {
        metadataProvider.getLocks().unlock();
    }
}
#end_block

#method_before
protected void handleCompactStatement(MetadataProvider metadataProvider, Statement stmt, IHyracksClientConnection hcc) throws Exception {
    CompactStatement compactStatement = (CompactStatement) stmt;
    String dataverseName = getActiveDataverse(compactStatement.getDataverseName());
    String datasetName = compactStatement.getDatasetName().getValue();
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    boolean bActiveTxn = true;
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    List<JobSpecification> jobsToExecute = new ArrayList<>();
    MetadataLockUtil.compactBegin(lockManager, metadataProvider.getLocks(), dataverseName, dataverseName + "." + datasetName);
    try {
        Dataset ds = metadataProvider.findDataset(dataverseName, datasetName);
        if (ds == null) {
            throw new AlgebricksException("There is no dataset with this name " + datasetName + " in dataverse " + dataverseName + ".");
        }
        // Prepare jobs to compact the datatset and its indexes
        List<Index> indexes = MetadataManager.INSTANCE.getDatasetIndexes(mdTxnCtx, dataverseName, datasetName);
        if (indexes.isEmpty()) {
            throw new AlgebricksException("Cannot compact the extrenal dataset " + datasetName + " because it has no indexes");
        }
        Dataverse dataverse = MetadataManager.INSTANCE.getDataverse(metadataProvider.getMetadataTxnContext(), dataverseName);
        jobsToExecute.add(DatasetUtil.compactDatasetJobSpec(dataverse, datasetName, metadataProvider));
        if (ds.getDatasetType() == DatasetType.INTERNAL) {
            for (Index index : indexes) {
                if (index.isSecondaryIndex()) {
                    jobsToExecute.add(IndexUtil.buildSecondaryIndexCompactJobSpec(ds, index, metadataProvider));
                }
            }
        } else {
            prepareCompactJobsForExternalDataset(indexes, ds, jobsToExecute, metadataProvider);
        }
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
        bActiveTxn = false;
        // #. run the jobs
        for (JobSpecification jobSpec : jobsToExecute) {
            runJob(hcc, jobSpec);
        }
    } catch (Exception e) {
        if (bActiveTxn) {
            abort(e, e, mdTxnCtx);
        }
        throw e;
    } finally {
        metadataProvider.getLocks().unlock();
        ExternalDatasetsRegistry.INSTANCE.releaseAcquiredLocks(metadataProvider);
    }
}
#method_after
protected void handleCompactStatement(MetadataProvider metadataProvider, Statement stmt, IHyracksClientConnection hcc) throws Exception {
    CompactStatement compactStatement = (CompactStatement) stmt;
    SourceLocation sourceLoc = compactStatement.getSourceLocation();
    String dataverseName = getActiveDataverse(compactStatement.getDataverseName());
    String datasetName = compactStatement.getDatasetName().getValue();
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    boolean bActiveTxn = true;
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    List<JobSpecification> jobsToExecute = new ArrayList<>();
    MetadataLockUtil.compactBegin(lockManager, metadataProvider.getLocks(), dataverseName, dataverseName + "." + datasetName);
    try {
        Dataset ds = metadataProvider.findDataset(dataverseName, datasetName);
        if (ds == null) {
            throw new CompilationException(ErrorCode.UNKNOWN_DATASET_IN_DATAVERSE, sourceLoc, datasetName, dataverseName);
        }
        // Prepare jobs to compact the datatset and its indexes
        List<Index> indexes = MetadataManager.INSTANCE.getDatasetIndexes(mdTxnCtx, dataverseName, datasetName);
        if (indexes.isEmpty()) {
            throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "Cannot compact the extrenal dataset " + datasetName + " because it has no indexes");
        }
        Dataverse dataverse = MetadataManager.INSTANCE.getDataverse(metadataProvider.getMetadataTxnContext(), dataverseName);
        jobsToExecute.add(DatasetUtil.compactDatasetJobSpec(dataverse, datasetName, metadataProvider));
        if (ds.getDatasetType() == DatasetType.INTERNAL) {
            for (Index index : indexes) {
                if (index.isSecondaryIndex()) {
                    jobsToExecute.add(IndexUtil.buildSecondaryIndexCompactJobSpec(ds, index, metadataProvider, sourceLoc));
                }
            }
        } else {
            prepareCompactJobsForExternalDataset(indexes, ds, jobsToExecute, metadataProvider, sourceLoc);
        }
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
        bActiveTxn = false;
        // #. run the jobs
        for (JobSpecification jobSpec : jobsToExecute) {
            runJob(hcc, jobSpec);
        }
    } catch (Exception e) {
        if (bActiveTxn) {
            abort(e, e, mdTxnCtx);
        }
        throw e;
    } finally {
        metadataProvider.getLocks().unlock();
        ExternalDatasetsRegistry.INSTANCE.releaseAcquiredLocks(metadataProvider);
    }
}
#end_block

#method_before
protected void prepareCompactJobsForExternalDataset(List<Index> indexes, Dataset ds, List<JobSpecification> jobsToExecute, MetadataProvider metadataProvider) throws AlgebricksException {
    for (int j = 0; j < indexes.size(); j++) {
        jobsToExecute.add(IndexUtil.buildSecondaryIndexCompactJobSpec(ds, indexes.get(j), metadataProvider));
    }
}
#method_after
protected void prepareCompactJobsForExternalDataset(List<Index> indexes, Dataset ds, List<JobSpecification> jobsToExecute, MetadataProvider metadataProvider, SourceLocation sourceLoc) throws AlgebricksException {
    for (int j = 0; j < indexes.size(); j++) {
        jobsToExecute.add(IndexUtil.buildSecondaryIndexCompactJobSpec(ds, indexes.get(j), metadataProvider, sourceLoc));
    }
}
#end_block

#method_before
protected void handleQuery(MetadataProvider metadataProvider, Query query, IHyracksClientConnection hcc, IResultSet hdc, ResultDelivery resultDelivery, ResultMetadata outMetadata, Stats stats, String clientContextId, IStatementExecutorContext ctx) throws Exception {
    final IMetadataLocker locker = new IMetadataLocker() {

        @Override
        public void lock() {
        }

        @Override
        public void unlock() {
            metadataProvider.getLocks().unlock();
            // release external datasets' locks acquired during compilation of the query
            ExternalDatasetsRegistry.INSTANCE.releaseAcquiredLocks(metadataProvider);
        }
    };
    final IStatementCompiler compiler = () -> {
        MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
        boolean bActiveTxn = true;
        metadataProvider.setMetadataTxnContext(mdTxnCtx);
        try {
            final JobSpecification jobSpec = rewriteCompileQuery(hcc, metadataProvider, query, null);
            MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
            bActiveTxn = false;
            return query.isExplain() || !sessionConfig.isExecuteQuery() ? null : jobSpec;
        } catch (Exception e) {
            LOGGER.log(Level.INFO, e.getMessage(), e);
            if (bActiveTxn) {
                abort(e, e, mdTxnCtx);
            }
            throw e;
        }
    };
    deliverResult(hcc, hdc, compiler, metadataProvider, locker, resultDelivery, outMetadata, stats, clientContextId, ctx);
}
#method_after
protected void handleQuery(MetadataProvider metadataProvider, Query query, IHyracksClientConnection hcc, IResultSet resultSet, ResultDelivery resultDelivery, ResultMetadata outMetadata, Stats stats, String clientContextId, IStatementExecutorContext ctx, Map<String, IAObject> stmtParams, IStatementRewriter stmtRewriter) throws Exception {
    final IMetadataLocker locker = new IMetadataLocker() {

        @Override
        public void lock() {
        }

        @Override
        public void unlock() {
            metadataProvider.getLocks().unlock();
            // release external datasets' locks acquired during compilation of the query
            ExternalDatasetsRegistry.INSTANCE.releaseAcquiredLocks(metadataProvider);
        }
    };
    final IStatementCompiler compiler = () -> {
        MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
        boolean bActiveTxn = true;
        metadataProvider.setMetadataTxnContext(mdTxnCtx);
        try {
            final JobSpecification jobSpec = rewriteCompileQuery(hcc, metadataProvider, query, null, stmtParams, stmtRewriter);
            afterCompile();
            MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
            bActiveTxn = false;
            return query.isExplain() || !sessionConfig.isExecuteQuery() ? null : jobSpec;
        } catch (Exception e) {
            LOGGER.log(Level.INFO, e.getMessage(), e);
            if (bActiveTxn) {
                abort(e, e, mdTxnCtx);
            }
            throw e;
        }
    };
    deliverResult(hcc, resultSet, compiler, metadataProvider, locker, resultDelivery, outMetadata, stats, clientContextId, ctx);
}
#end_block

#method_before
private void deliverResult(IHyracksClientConnection hcc, IResultSet hdc, IStatementCompiler compiler, MetadataProvider metadataProvider, IMetadataLocker locker, ResultDelivery resultDelivery, ResultMetadata outMetadata, Stats stats, String clientContextId, IStatementExecutorContext ctx) throws Exception {
    final ResultSetId resultSetId = metadataProvider.getResultSetId();
    switch(resultDelivery) {
        case ASYNC:
            MutableBoolean printed = new MutableBoolean(false);
            executorService.submit(() -> asyncCreateAndRunJob(hcc, compiler, locker, resultDelivery, clientContextId, ctx, resultSetId, printed));
            synchronized (printed) {
                while (!printed.booleanValue()) {
                    printed.wait();
                }
            }
            break;
        case IMMEDIATE:
            createAndRunJob(hcc, jobFlags, null, compiler, locker, resultDelivery, id -> {
                final ResultReader resultReader = new ResultReader(hdc, id, resultSetId);
                updateJobStats(id, stats);
                // stop buffering and allow for streaming result delivery
                sessionOutput.release();
                ResultUtil.printResults(appCtx, resultReader, sessionOutput, stats, metadataProvider.findOutputRecordType());
            }, clientContextId, ctx);
            break;
        case DEFERRED:
            createAndRunJob(hcc, jobFlags, null, compiler, locker, resultDelivery, id -> {
                updateJobStats(id, stats);
                ResultUtil.printResultHandle(sessionOutput, new ResultHandle(id, resultSetId));
                if (outMetadata != null) {
                    outMetadata.getResultSets().add(Triple.of(id, resultSetId, metadataProvider.findOutputRecordType()));
                }
            }, clientContextId, ctx);
            break;
        default:
            break;
    }
}
#method_after
private void deliverResult(IHyracksClientConnection hcc, IResultSet resultSet, IStatementCompiler compiler, MetadataProvider metadataProvider, IMetadataLocker locker, ResultDelivery resultDelivery, ResultMetadata outMetadata, Stats stats, String clientContextId, IStatementExecutorContext ctx) throws Exception {
    final ResultSetId resultSetId = metadataProvider.getResultSetId();
    switch(resultDelivery) {
        case ASYNC:
            MutableBoolean printed = new MutableBoolean(false);
            executorService.submit(() -> asyncCreateAndRunJob(hcc, compiler, locker, resultDelivery, clientContextId, ctx, resultSetId, printed));
            synchronized (printed) {
                while (!printed.booleanValue()) {
                    printed.wait();
                }
            }
            break;
        case IMMEDIATE:
            createAndRunJob(hcc, jobFlags, null, compiler, locker, resultDelivery, id -> {
                final ResultReader resultReader = new ResultReader(resultSet, id, resultSetId);
                updateJobStats(id, stats);
                // stop buffering and allow for streaming result delivery
                sessionOutput.release();
                ResultUtil.printResults(appCtx, resultReader, sessionOutput, stats, metadataProvider.findOutputRecordType());
            }, clientContextId, ctx);
            break;
        case DEFERRED:
            createAndRunJob(hcc, jobFlags, null, compiler, locker, resultDelivery, id -> {
                updateJobStats(id, stats);
                ResultUtil.printResultHandle(sessionOutput, new ResultHandle(id, resultSetId));
                if (outMetadata != null) {
                    outMetadata.getResultSets().add(Triple.of(id, resultSetId, metadataProvider.findOutputRecordType()));
                }
            }, clientContextId, ctx);
            break;
        default:
            break;
    }
}
#end_block

#method_before
private static void createAndRunJob(IHyracksClientConnection hcc, EnumSet<JobFlag> jobFlags, Mutable<JobId> jId, IStatementCompiler compiler, IMetadataLocker locker, ResultDelivery resultDelivery, IResultPrinter printer, String clientContextId, IStatementExecutorContext ctx) throws Exception {
    locker.lock();
    try {
        final JobSpecification jobSpec = compiler.compile();
        if (jobSpec == null) {
            return;
        }
        final JobId jobId = JobUtils.runJob(hcc, jobSpec, jobFlags, false);
        if (ctx != null && clientContextId != null) {
            // Adds the running job into the context.
            ctx.put(clientContextId, jobId);
        }
        if (jId != null) {
            jId.setValue(jobId);
        }
        if (ResultDelivery.ASYNC == resultDelivery) {
            printer.print(jobId);
            hcc.waitForCompletion(jobId);
        } else {
            hcc.waitForCompletion(jobId);
            printer.print(jobId);
        }
    } finally {
        locker.unlock();
        // No matter the job succeeds or fails, removes it into the context.
        if (ctx != null && clientContextId != null) {
            ctx.removeJobIdFromClientContextId(clientContextId);
        }
    }
}
#method_after
private static void createAndRunJob(IHyracksClientConnection hcc, EnumSet<JobFlag> jobFlags, Mutable<JobId> jId, IStatementCompiler compiler, IMetadataLocker locker, ResultDelivery resultDelivery, IResultPrinter printer, String clientContextId, IStatementExecutorContext ctx) throws Exception {
    ClientJobRequest req = null;
    locker.lock();
    try {
        final JobSpecification jobSpec = compiler.compile();
        if (jobSpec == null) {
            return;
        }
        final JobId jobId = JobUtils.runJob(hcc, jobSpec, jobFlags, false);
        if (ctx != null && clientContextId != null) {
            req = new ClientJobRequest(ctx, clientContextId, jobId);
            // Adds the running job into the context.
            ctx.put(clientContextId, req);
        }
        if (jId != null) {
            jId.setValue(jobId);
        }
        if (ResultDelivery.ASYNC == resultDelivery) {
            printer.print(jobId);
            hcc.waitForCompletion(jobId);
        } else {
            hcc.waitForCompletion(jobId);
            printer.print(jobId);
        }
    } finally {
        locker.unlock();
        // No matter the job succeeds or fails, removes it into the context.
        if (req != null) {
            req.complete();
        }
    }
}
#end_block

#method_before
protected void handleCreateNodeGroupStatement(MetadataProvider metadataProvider, Statement stmt) throws Exception {
    NodegroupDecl stmtCreateNodegroup = (NodegroupDecl) stmt;
    String ngName = stmtCreateNodegroup.getNodegroupName().getValue();
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    lockManager.acquireNodeGroupWriteLock(metadataProvider.getLocks(), ngName);
    try {
        NodeGroup ng = MetadataManager.INSTANCE.getNodegroup(mdTxnCtx, ngName);
        if (ng != null) {
            if (!stmtCreateNodegroup.getIfNotExists()) {
                throw new AlgebricksException("A nodegroup with this name " + ngName + " already exists.");
            }
        } else {
            List<Identifier> ncIdentifiers = stmtCreateNodegroup.getNodeControllerNames();
            List<String> ncNames = new ArrayList<>(ncIdentifiers.size());
            for (Identifier id : ncIdentifiers) {
                ncNames.add(id.getValue());
            }
            MetadataManager.INSTANCE.addNodegroup(mdTxnCtx, new NodeGroup(ngName, ncNames));
        }
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
    } catch (Exception e) {
        abort(e, e, mdTxnCtx);
        throw e;
    } finally {
        metadataProvider.getLocks().unlock();
    }
}
#method_after
protected void handleCreateNodeGroupStatement(MetadataProvider metadataProvider, Statement stmt) throws Exception {
    NodegroupDecl stmtCreateNodegroup = (NodegroupDecl) stmt;
    SourceLocation sourceLoc = stmtCreateNodegroup.getSourceLocation();
    String ngName = stmtCreateNodegroup.getNodegroupName().getValue();
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    lockManager.acquireNodeGroupWriteLock(metadataProvider.getLocks(), ngName);
    try {
        NodeGroup ng = MetadataManager.INSTANCE.getNodegroup(mdTxnCtx, ngName);
        if (ng != null) {
            if (!stmtCreateNodegroup.getIfNotExists()) {
                throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "A nodegroup with this name " + ngName + " already exists.");
            }
        } else {
            List<Identifier> ncIdentifiers = stmtCreateNodegroup.getNodeControllerNames();
            List<String> ncNames = new ArrayList<>(ncIdentifiers.size());
            for (Identifier id : ncIdentifiers) {
                ncNames.add(id.getValue());
            }
            MetadataManager.INSTANCE.addNodegroup(mdTxnCtx, new NodeGroup(ngName, ncNames));
        }
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
    } catch (Exception e) {
        abort(e, e, mdTxnCtx);
        throw e;
    } finally {
        metadataProvider.getLocks().unlock();
    }
}
#end_block

#method_before
protected void handleExternalDatasetRefreshStatement(MetadataProvider metadataProvider, Statement stmt, IHyracksClientConnection hcc) throws Exception {
    RefreshExternalDatasetStatement stmtRefresh = (RefreshExternalDatasetStatement) stmt;
    String dataverseName = getActiveDataverse(stmtRefresh.getDataverseName());
    String datasetName = stmtRefresh.getDatasetName().getValue();
    TransactionState transactionState = TransactionState.COMMIT;
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    boolean bActiveTxn = true;
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    JobSpecification spec = null;
    Dataset ds = null;
    List<ExternalFile> metadataFiles = null;
    List<ExternalFile> deletedFiles = null;
    List<ExternalFile> addedFiles = null;
    List<ExternalFile> appendedFiles = null;
    List<Index> indexes = null;
    Dataset transactionDataset = null;
    boolean lockAquired = false;
    boolean success = false;
    MetadataLockUtil.refreshDatasetBegin(lockManager, metadataProvider.getLocks(), dataverseName, dataverseName + "." + datasetName);
    try {
        ds = metadataProvider.findDataset(dataverseName, datasetName);
        // Dataset exists ?
        if (ds == null) {
            throw new AlgebricksException("There is no dataset with this name " + datasetName + " in dataverse " + dataverseName);
        }
        // Dataset external ?
        if (ds.getDatasetType() != DatasetType.EXTERNAL) {
            throw new AlgebricksException("dataset " + datasetName + " in dataverse " + dataverseName + " is not an external dataset");
        }
        // Dataset has indexes ?
        indexes = MetadataManager.INSTANCE.getDatasetIndexes(mdTxnCtx, dataverseName, datasetName);
        if (indexes.isEmpty()) {
            throw new AlgebricksException("External dataset " + datasetName + " in dataverse " + dataverseName + " doesn't have any index");
        }
        // Record transaction time
        Date txnTime = new Date();
        // refresh lock here
        ExternalDatasetsRegistry.INSTANCE.refreshBegin(ds);
        lockAquired = true;
        // Get internal files
        metadataFiles = MetadataManager.INSTANCE.getDatasetExternalFiles(mdTxnCtx, ds);
        deletedFiles = new ArrayList<>();
        addedFiles = new ArrayList<>();
        appendedFiles = new ArrayList<>();
        // Now we compare snapshot with external file system
        if (ExternalIndexingOperations.isDatasetUptodate(ds, metadataFiles, addedFiles, deletedFiles, appendedFiles)) {
            ((ExternalDatasetDetails) ds.getDatasetDetails()).setRefreshTimestamp(txnTime);
            MetadataManager.INSTANCE.updateDataset(mdTxnCtx, ds);
            MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
            // latch will be released in the finally clause
            return;
        }
        // At this point, we know data has changed in the external file system, record
        // transaction in metadata and start
        transactionDataset = ExternalIndexingOperations.createTransactionDataset(ds);
        /*
             * Remove old dataset record and replace it with a new one
             */
        MetadataManager.INSTANCE.updateDataset(mdTxnCtx, transactionDataset);
        // Add delta files to the metadata
        for (ExternalFile file : addedFiles) {
            MetadataManager.INSTANCE.addExternalFile(mdTxnCtx, file);
        }
        for (ExternalFile file : appendedFiles) {
            MetadataManager.INSTANCE.addExternalFile(mdTxnCtx, file);
        }
        for (ExternalFile file : deletedFiles) {
            MetadataManager.INSTANCE.addExternalFile(mdTxnCtx, file);
        }
        // Create the files index update job
        spec = ExternalIndexingOperations.buildFilesIndexUpdateOp(ds, metadataFiles, addedFiles, appendedFiles, metadataProvider);
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
        bActiveTxn = false;
        transactionState = TransactionState.BEGIN;
        // run the files update job
        runJob(hcc, spec);
        for (Index index : indexes) {
            if (!ExternalIndexingOperations.isFileIndex(index)) {
                spec = ExternalIndexingOperations.buildIndexUpdateOp(ds, index, metadataFiles, addedFiles, appendedFiles, metadataProvider);
                // run the files update job
                runJob(hcc, spec);
            }
        }
        // all index updates has completed successfully, record transaction state
        spec = ExternalIndexingOperations.buildCommitJob(ds, indexes, metadataProvider);
        // Aquire write latch again -> start a transaction and record the decision to
        // commit
        mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
        metadataProvider.setMetadataTxnContext(mdTxnCtx);
        bActiveTxn = true;
        ((ExternalDatasetDetails) transactionDataset.getDatasetDetails()).setState(TransactionState.READY_TO_COMMIT);
        ((ExternalDatasetDetails) transactionDataset.getDatasetDetails()).setRefreshTimestamp(txnTime);
        MetadataManager.INSTANCE.updateDataset(mdTxnCtx, transactionDataset);
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
        bActiveTxn = false;
        transactionState = TransactionState.READY_TO_COMMIT;
        // We don't release the latch since this job is expected to be quick
        runJob(hcc, spec);
        // Start a new metadata transaction to record the final state of the transaction
        mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
        metadataProvider.setMetadataTxnContext(mdTxnCtx);
        bActiveTxn = true;
        for (ExternalFile file : metadataFiles) {
            if (file.getPendingOp() == ExternalFilePendingOp.DROP_OP) {
                MetadataManager.INSTANCE.dropExternalFile(mdTxnCtx, file);
            } else if (file.getPendingOp() == ExternalFilePendingOp.NO_OP) {
                Iterator<ExternalFile> iterator = appendedFiles.iterator();
                while (iterator.hasNext()) {
                    ExternalFile appendedFile = iterator.next();
                    if (file.getFileName().equals(appendedFile.getFileName())) {
                        // delete existing file
                        MetadataManager.INSTANCE.dropExternalFile(mdTxnCtx, file);
                        // delete existing appended file
                        MetadataManager.INSTANCE.dropExternalFile(mdTxnCtx, appendedFile);
                        // add the original file with appended information
                        appendedFile.setFileNumber(file.getFileNumber());
                        appendedFile.setPendingOp(ExternalFilePendingOp.NO_OP);
                        MetadataManager.INSTANCE.addExternalFile(mdTxnCtx, appendedFile);
                        iterator.remove();
                    }
                }
            }
        }
        // remove the deleted files delta
        for (ExternalFile file : deletedFiles) {
            MetadataManager.INSTANCE.dropExternalFile(mdTxnCtx, file);
        }
        // insert new files
        for (ExternalFile file : addedFiles) {
            MetadataManager.INSTANCE.dropExternalFile(mdTxnCtx, file);
            file.setPendingOp(ExternalFilePendingOp.NO_OP);
            MetadataManager.INSTANCE.addExternalFile(mdTxnCtx, file);
        }
        // mark the transaction as complete
        ((ExternalDatasetDetails) transactionDataset.getDatasetDetails()).setState(TransactionState.COMMIT);
        MetadataManager.INSTANCE.updateDataset(mdTxnCtx, transactionDataset);
        // commit metadata transaction
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
        success = true;
    } catch (Exception e) {
        if (bActiveTxn) {
            abort(e, e, mdTxnCtx);
        }
        if (transactionState == TransactionState.READY_TO_COMMIT) {
            throw new IllegalStateException("System is inconsistent state: commit of (" + dataverseName + "." + datasetName + ") refresh couldn't carry out the commit phase", e);
        }
        if (transactionState == TransactionState.COMMIT) {
            // Nothing to do , everything should be clean
            throw e;
        }
        if (transactionState == TransactionState.BEGIN) {
            // transaction failed, need to do the following
            // clean NCs removing transaction components
            mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
            bActiveTxn = true;
            metadataProvider.setMetadataTxnContext(mdTxnCtx);
            spec = ExternalIndexingOperations.buildAbortOp(ds, indexes, metadataProvider);
            MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
            bActiveTxn = false;
            try {
                runJob(hcc, spec);
            } catch (Exception e2) {
                // This should never happen -- fix throw illegal
                e.addSuppressed(e2);
                throw new IllegalStateException("System is in inconsistent state. Failed to abort refresh", e);
            }
            // return the state of the dataset to committed
            try {
                mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
                for (ExternalFile file : deletedFiles) {
                    MetadataManager.INSTANCE.dropExternalFile(mdTxnCtx, file);
                }
                for (ExternalFile file : addedFiles) {
                    MetadataManager.INSTANCE.dropExternalFile(mdTxnCtx, file);
                }
                for (ExternalFile file : appendedFiles) {
                    MetadataManager.INSTANCE.dropExternalFile(mdTxnCtx, file);
                }
                MetadataManager.INSTANCE.updateDataset(mdTxnCtx, ds);
                // commit metadata transaction
                MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
            } catch (Exception e2) {
                abort(e, e2, mdTxnCtx);
                e.addSuppressed(e2);
                throw new IllegalStateException("System is in inconsistent state. Failed to drop delta files", e);
            }
        }
    } finally {
        if (lockAquired) {
            ExternalDatasetsRegistry.INSTANCE.refreshEnd(ds, success);
        }
        metadataProvider.getLocks().unlock();
    }
}
#method_after
protected void handleExternalDatasetRefreshStatement(MetadataProvider metadataProvider, Statement stmt, IHyracksClientConnection hcc) throws Exception {
    RefreshExternalDatasetStatement stmtRefresh = (RefreshExternalDatasetStatement) stmt;
    SourceLocation sourceLoc = stmtRefresh.getSourceLocation();
    String dataverseName = getActiveDataverse(stmtRefresh.getDataverseName());
    String datasetName = stmtRefresh.getDatasetName().getValue();
    TransactionState transactionState = TransactionState.COMMIT;
    MetadataTransactionContext mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
    boolean bActiveTxn = true;
    metadataProvider.setMetadataTxnContext(mdTxnCtx);
    JobSpecification spec = null;
    Dataset ds = null;
    List<ExternalFile> metadataFiles = null;
    List<ExternalFile> deletedFiles = null;
    List<ExternalFile> addedFiles = null;
    List<ExternalFile> appendedFiles = null;
    List<Index> indexes = null;
    Dataset transactionDataset = null;
    boolean lockAquired = false;
    boolean success = false;
    MetadataLockUtil.refreshDatasetBegin(lockManager, metadataProvider.getLocks(), dataverseName, dataverseName + "." + datasetName);
    try {
        ds = metadataProvider.findDataset(dataverseName, datasetName);
        // Dataset exists ?
        if (ds == null) {
            throw new CompilationException(ErrorCode.UNKNOWN_DATASET_IN_DATAVERSE, sourceLoc, datasetName, dataverseName);
        }
        // Dataset external ?
        if (ds.getDatasetType() != DatasetType.EXTERNAL) {
            throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "dataset " + datasetName + " in dataverse " + dataverseName + " is not an external dataset");
        }
        // Dataset has indexes ?
        indexes = MetadataManager.INSTANCE.getDatasetIndexes(mdTxnCtx, dataverseName, datasetName);
        if (indexes.isEmpty()) {
            throw new CompilationException(ErrorCode.COMPILATION_ERROR, sourceLoc, "External dataset " + datasetName + " in dataverse " + dataverseName + " doesn't have any index");
        }
        // Record transaction time
        Date txnTime = new Date();
        // refresh lock here
        ExternalDatasetsRegistry.INSTANCE.refreshBegin(ds);
        lockAquired = true;
        // Get internal files
        metadataFiles = MetadataManager.INSTANCE.getDatasetExternalFiles(mdTxnCtx, ds);
        deletedFiles = new ArrayList<>();
        addedFiles = new ArrayList<>();
        appendedFiles = new ArrayList<>();
        // Now we compare snapshot with external file system
        if (ExternalIndexingOperations.isDatasetUptodate(ds, metadataFiles, addedFiles, deletedFiles, appendedFiles)) {
            ((ExternalDatasetDetails) ds.getDatasetDetails()).setRefreshTimestamp(txnTime);
            MetadataManager.INSTANCE.updateDataset(mdTxnCtx, ds);
            MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
            // latch will be released in the finally clause
            return;
        }
        // At this point, we know data has changed in the external file system, record
        // transaction in metadata and start
        transactionDataset = ExternalIndexingOperations.createTransactionDataset(ds);
        /*
             * Remove old dataset record and replace it with a new one
             */
        MetadataManager.INSTANCE.updateDataset(mdTxnCtx, transactionDataset);
        // Add delta files to the metadata
        for (ExternalFile file : addedFiles) {
            MetadataManager.INSTANCE.addExternalFile(mdTxnCtx, file);
        }
        for (ExternalFile file : appendedFiles) {
            MetadataManager.INSTANCE.addExternalFile(mdTxnCtx, file);
        }
        for (ExternalFile file : deletedFiles) {
            MetadataManager.INSTANCE.addExternalFile(mdTxnCtx, file);
        }
        // Create the files index update job
        spec = ExternalIndexingOperations.buildFilesIndexUpdateOp(ds, metadataFiles, addedFiles, appendedFiles, metadataProvider);
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
        bActiveTxn = false;
        transactionState = TransactionState.BEGIN;
        // run the files update job
        runJob(hcc, spec);
        for (Index index : indexes) {
            if (!ExternalIndexingOperations.isFileIndex(index)) {
                spec = ExternalIndexingOperations.buildIndexUpdateOp(ds, index, metadataFiles, addedFiles, appendedFiles, metadataProvider, sourceLoc);
                // run the files update job
                runJob(hcc, spec);
            }
        }
        // all index updates has completed successfully, record transaction state
        spec = ExternalIndexingOperations.buildCommitJob(ds, indexes, metadataProvider);
        // Aquire write latch again -> start a transaction and record the decision to
        // commit
        mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
        metadataProvider.setMetadataTxnContext(mdTxnCtx);
        bActiveTxn = true;
        ((ExternalDatasetDetails) transactionDataset.getDatasetDetails()).setState(TransactionState.READY_TO_COMMIT);
        ((ExternalDatasetDetails) transactionDataset.getDatasetDetails()).setRefreshTimestamp(txnTime);
        MetadataManager.INSTANCE.updateDataset(mdTxnCtx, transactionDataset);
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
        bActiveTxn = false;
        transactionState = TransactionState.READY_TO_COMMIT;
        // We don't release the latch since this job is expected to be quick
        runJob(hcc, spec);
        // Start a new metadata transaction to record the final state of the transaction
        mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
        metadataProvider.setMetadataTxnContext(mdTxnCtx);
        bActiveTxn = true;
        for (ExternalFile file : metadataFiles) {
            if (file.getPendingOp() == ExternalFilePendingOp.DROP_OP) {
                MetadataManager.INSTANCE.dropExternalFile(mdTxnCtx, file);
            } else if (file.getPendingOp() == ExternalFilePendingOp.NO_OP) {
                Iterator<ExternalFile> iterator = appendedFiles.iterator();
                while (iterator.hasNext()) {
                    ExternalFile appendedFile = iterator.next();
                    if (file.getFileName().equals(appendedFile.getFileName())) {
                        // delete existing file
                        MetadataManager.INSTANCE.dropExternalFile(mdTxnCtx, file);
                        // delete existing appended file
                        MetadataManager.INSTANCE.dropExternalFile(mdTxnCtx, appendedFile);
                        // add the original file with appended information
                        appendedFile.setFileNumber(file.getFileNumber());
                        appendedFile.setPendingOp(ExternalFilePendingOp.NO_OP);
                        MetadataManager.INSTANCE.addExternalFile(mdTxnCtx, appendedFile);
                        iterator.remove();
                    }
                }
            }
        }
        // remove the deleted files delta
        for (ExternalFile file : deletedFiles) {
            MetadataManager.INSTANCE.dropExternalFile(mdTxnCtx, file);
        }
        // insert new files
        for (ExternalFile file : addedFiles) {
            MetadataManager.INSTANCE.dropExternalFile(mdTxnCtx, file);
            file.setPendingOp(ExternalFilePendingOp.NO_OP);
            MetadataManager.INSTANCE.addExternalFile(mdTxnCtx, file);
        }
        // mark the transaction as complete
        ((ExternalDatasetDetails) transactionDataset.getDatasetDetails()).setState(TransactionState.COMMIT);
        MetadataManager.INSTANCE.updateDataset(mdTxnCtx, transactionDataset);
        // commit metadata transaction
        MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
        success = true;
    } catch (Exception e) {
        if (bActiveTxn) {
            abort(e, e, mdTxnCtx);
        }
        if (transactionState == TransactionState.READY_TO_COMMIT) {
            throw new IllegalStateException("System is inconsistent state: commit of (" + dataverseName + "." + datasetName + ") refresh couldn't carry out the commit phase", e);
        }
        if (transactionState == TransactionState.COMMIT) {
            // Nothing to do , everything should be clean
            throw e;
        }
        if (transactionState == TransactionState.BEGIN) {
            // transaction failed, need to do the following
            // clean NCs removing transaction components
            mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
            bActiveTxn = true;
            metadataProvider.setMetadataTxnContext(mdTxnCtx);
            spec = ExternalIndexingOperations.buildAbortOp(ds, indexes, metadataProvider);
            MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
            bActiveTxn = false;
            try {
                runJob(hcc, spec);
            } catch (Exception e2) {
                // This should never happen -- fix throw illegal
                e.addSuppressed(e2);
                throw new IllegalStateException("System is in inconsistent state. Failed to abort refresh", e);
            }
            // return the state of the dataset to committed
            try {
                mdTxnCtx = MetadataManager.INSTANCE.beginTransaction();
                for (ExternalFile file : deletedFiles) {
                    MetadataManager.INSTANCE.dropExternalFile(mdTxnCtx, file);
                }
                for (ExternalFile file : addedFiles) {
                    MetadataManager.INSTANCE.dropExternalFile(mdTxnCtx, file);
                }
                for (ExternalFile file : appendedFiles) {
                    MetadataManager.INSTANCE.dropExternalFile(mdTxnCtx, file);
                }
                MetadataManager.INSTANCE.updateDataset(mdTxnCtx, ds);
                // commit metadata transaction
                MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
            } catch (Exception e2) {
                abort(e, e2, mdTxnCtx);
                e.addSuppressed(e2);
                throw new IllegalStateException("System is in inconsistent state. Failed to drop delta files", e);
            }
        }
    } finally {
        if (lockAquired) {
            ExternalDatasetsRegistry.INSTANCE.refreshEnd(ds, success);
        }
        metadataProvider.getLocks().unlock();
    }
}
#end_block

#method_before
@Override
public String getActiveDataverseName(String dataverse) {
    return (dataverse != null) ? dataverse : activeDataverse.getDataverseName();
}
#method_after
@Override
public String getActiveDataverseName(String dataverse) {
    return (dataverse != null && !dataverse.isEmpty()) ? dataverse : activeDataverse.getDataverseName();
}
#end_block

#method_before
protected void rewriteStatement(Statement stmt) throws CompilationException {
    IStatementRewriter rewriter = rewriterFactory.createStatementRewriter();
    rewriter.rewrite(stmt);
}
#method_after
protected void rewriteStatement(Statement stmt, IStatementRewriter rewriter) throws CompilationException {
    rewriter.rewrite(stmt);
}
#end_block

#method_before
@Override
protected void get(IServletRequest request, IServletResponse response) throws Exception {
    // TODO this seems wrong ...
    HttpUtil.setContentType(response, HttpUtil.ContentType.TEXT_HTML, HttpUtil.Encoding.UTF8);
    PrintWriter out = response.writer();
    final String strHandle = localPath(request);
    final ResultHandle handle = ResultHandle.parse(strHandle);
    if (handle == null) {
        response.setStatus(HttpResponseStatus.BAD_REQUEST);
        return;
    }
    IResultSet hds = getHyracksDataset();
    ResultReader resultReader = new ResultReader(hds, handle.getJobId(), handle.getResultSetId());
    try {
        ResultJobRecord.Status status = resultReader.getStatus();
        final HttpResponseStatus httpStatus;
        if (status == null) {
            httpStatus = HttpResponseStatus.NOT_FOUND;
        } else {
            switch(status.getState()) {
                case SUCCESS:
                    httpStatus = HttpResponseStatus.OK;
                    break;
                case RUNNING:
                case IDLE:
                case FAILED:
                    httpStatus = HttpResponseStatus.NOT_FOUND;
                    break;
                default:
                    httpStatus = HttpResponseStatus.INTERNAL_SERVER_ERROR;
                    break;
            }
        }
        response.setStatus(httpStatus);
        if (httpStatus != HttpResponseStatus.OK) {
            return;
        }
        // QQQ The output format is determined by the initial
        // query and cannot be modified here, so calling back to
        // initResponse() is really an error. We need to find a
        // way to send the same OutputFormat value here as was
        // originally determined there. Need to save this value on
        // some object that we can obtain here.
        SessionOutput sessionOutput = RestApiServlet.initResponse(request, response);
        ResultUtil.printResults(appCtx, resultReader, sessionOutput, new Stats(), null);
    } catch (HyracksDataException e) {
        final int errorCode = e.getErrorCode();
        if (ErrorCode.NO_RESULT_SET == errorCode) {
            LOGGER.log(Level.INFO, "No results for: \"" + strHandle + "\"");
            response.setStatus(HttpResponseStatus.NOT_FOUND);
            return;
        }
        response.setStatus(HttpResponseStatus.BAD_REQUEST);
        out.println(e.getMessage());
        LOGGER.log(Level.WARN, "Error retrieving result for \"" + strHandle + "\"", e);
    } catch (Exception e) {
        response.setStatus(HttpResponseStatus.BAD_REQUEST);
        LOGGER.log(Level.WARN, "Error retrieving result for \"" + strHandle + "\"", e);
    }
    if (out.checkError()) {
        LOGGER.warn("Error flushing output writer for \"" + strHandle + "\"");
    }
}
#method_after
@Override
protected void get(IServletRequest request, IServletResponse response) throws Exception {
    // TODO this seems wrong ...
    HttpUtil.setContentType(response, HttpUtil.ContentType.TEXT_HTML, HttpUtil.Encoding.UTF8);
    PrintWriter out = response.writer();
    final String strHandle = localPath(request);
    final ResultHandle handle = ResultHandle.parse(strHandle);
    if (handle == null) {
        response.setStatus(HttpResponseStatus.BAD_REQUEST);
        return;
    }
    IResultSet resultSet = getResultSet();
    ResultReader resultReader = new ResultReader(resultSet, handle.getJobId(), handle.getResultSetId());
    try {
        ResultJobRecord.Status status = resultReader.getStatus();
        final HttpResponseStatus httpStatus;
        if (status == null) {
            httpStatus = HttpResponseStatus.NOT_FOUND;
        } else {
            switch(status.getState()) {
                case SUCCESS:
                    httpStatus = HttpResponseStatus.OK;
                    break;
                case RUNNING:
                case IDLE:
                case FAILED:
                    httpStatus = HttpResponseStatus.NOT_FOUND;
                    break;
                default:
                    httpStatus = HttpResponseStatus.INTERNAL_SERVER_ERROR;
                    break;
            }
        }
        response.setStatus(httpStatus);
        if (httpStatus != HttpResponseStatus.OK) {
            return;
        }
        // QQQ The output format is determined by the initial
        // query and cannot be modified here, so calling back to
        // initResponse() is really an error. We need to find a
        // way to send the same OutputFormat value here as was
        // originally determined there. Need to save this value on
        // some object that we can obtain here.
        SessionOutput sessionOutput = RestApiServlet.initResponse(request, response);
        ResultUtil.printResults(appCtx, resultReader, sessionOutput, new Stats(), null);
    } catch (HyracksDataException e) {
        final int errorCode = e.getErrorCode();
        if (ErrorCode.NO_RESULT_SET == errorCode) {
            LOGGER.log(Level.INFO, "No results for: \"" + strHandle + "\"");
            response.setStatus(HttpResponseStatus.NOT_FOUND);
            return;
        }
        response.setStatus(HttpResponseStatus.BAD_REQUEST);
        out.println(e.getMessage());
        LOGGER.log(Level.WARN, "Error retrieving result for \"" + strHandle + "\"", e);
    } catch (Exception e) {
        response.setStatus(HttpResponseStatus.BAD_REQUEST);
        LOGGER.log(Level.WARN, "Error retrieving result for \"" + strHandle + "\"", e);
    }
    if (out.checkError()) {
        LOGGER.warn("Error flushing output writer for \"" + strHandle + "\"");
    }
}
#end_block

#method_before
@Override
public IScalarEvaluatorFactory createEvaluatorFactory(final IScalarEvaluatorFactory[] args) {
    return new IScalarEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IScalarEvaluator createScalarEvaluator(IHyracksTaskContext ctx) throws HyracksDataException {
            return new IScalarEvaluator() {

                private final ArrayBackedValueStorage resultStorage = new ArrayBackedValueStorage();

                private final DataOutput out = resultStorage.getDataOutput();

                private final IPointable argPtr0 = new VoidPointable();

                private final IPointable argPtr1 = new VoidPointable();

                private final IScalarEvaluator evalLeft = args[0].createScalarEvaluator(ctx);

                private final IScalarEvaluator evalRight = args[1].createScalarEvaluator(ctx);

                private final double[] operandsFloating = new double[args.length];

                private final long[] operandsInteger = new long[args.length];

                private final AMutableFloat aFloat = new AMutableFloat(0);

                private final AMutableDouble aDouble = new AMutableDouble(0);

                private final AMutableInt64 aInt64 = new AMutableInt64(0);

                private final AMutableInt32 aInt32 = new AMutableInt32(0);

                private final AMutableInt16 aInt16 = new AMutableInt16((short) 0);

                private final AMutableInt8 aInt8 = new AMutableInt8((byte) 0);

                private final AMutableDuration aDuration = new AMutableDuration(0, 0);

                private final AMutableDate aDate = new AMutableDate(0);

                private final AMutableTime aTime = new AMutableTime(0);

                private final AMutableDateTime aDatetime = new AMutableDateTime(0);

                @SuppressWarnings("rawtypes")
                private final ISerializerDeserializer int8Serde = SerializerDeserializerProvider.INSTANCE.getSerializerDeserializer(BuiltinType.AINT8);

                @SuppressWarnings("rawtypes")
                private final ISerializerDeserializer int16Serde = SerializerDeserializerProvider.INSTANCE.getSerializerDeserializer(BuiltinType.AINT16);

                @SuppressWarnings("rawtypes")
                private final ISerializerDeserializer int32Serde = SerializerDeserializerProvider.INSTANCE.getSerializerDeserializer(BuiltinType.AINT32);

                @SuppressWarnings("rawtypes")
                private final ISerializerDeserializer int64Serde = SerializerDeserializerProvider.INSTANCE.getSerializerDeserializer(BuiltinType.AINT64);

                @SuppressWarnings("rawtypes")
                private final ISerializerDeserializer floatSerde = SerializerDeserializerProvider.INSTANCE.getSerializerDeserializer(BuiltinType.AFLOAT);

                @SuppressWarnings("rawtypes")
                private final ISerializerDeserializer doubleSerde = SerializerDeserializerProvider.INSTANCE.getSerializerDeserializer(BuiltinType.ADOUBLE);

                @SuppressWarnings("rawtypes")
                private final ISerializerDeserializer dateSerde = SerializerDeserializerProvider.INSTANCE.getSerializerDeserializer(BuiltinType.ADATE);

                @SuppressWarnings("rawtypes")
                private final ISerializerDeserializer timeSerde = SerializerDeserializerProvider.INSTANCE.getSerializerDeserializer(BuiltinType.ATIME);

                @SuppressWarnings("rawtypes")
                private final ISerializerDeserializer dateTimeSerde = SerializerDeserializerProvider.INSTANCE.getSerializerDeserializer(BuiltinType.ADATETIME);

                @SuppressWarnings("rawtypes")
                private final ISerializerDeserializer durationSerde = SerializerDeserializerProvider.INSTANCE.getSerializerDeserializer(BuiltinType.ADURATION);

                @SuppressWarnings("rawtypes")
                private final ISerializerDeserializer nullSerde = SerializerDeserializerProvider.INSTANCE.getSerializerDeserializer(BuiltinType.ANULL);

                @Override
                @SuppressWarnings("unchecked")
                public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException {
                    evalLeft.evaluate(tuple, argPtr0);
                    evalRight.evaluate(tuple, argPtr1);
                    resultStorage.reset();
                    ATypeTag argTypeMax = null;
                    for (int i = 0; i < 2; i++) {
                        IPointable argPtr = i == 0 ? argPtr0 : argPtr1;
                        byte[] bytes = argPtr.getByteArray();
                        int offset = argPtr.getStartOffset();
                        ATypeTag currentType;
                        ATypeTag typeTag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(bytes[offset]);
                        switch(typeTag) {
                            case TINYINT:
                                currentType = ATypeTag.TINYINT;
                                operandsInteger[i] = AInt8SerializerDeserializer.getByte(bytes, offset + 1);
                                operandsFloating[i] = operandsInteger[i];
                                break;
                            case SMALLINT:
                                currentType = ATypeTag.SMALLINT;
                                operandsInteger[i] = AInt16SerializerDeserializer.getShort(bytes, offset + 1);
                                operandsFloating[i] = operandsInteger[i];
                                break;
                            case INTEGER:
                                currentType = ATypeTag.INTEGER;
                                operandsInteger[i] = AInt32SerializerDeserializer.getInt(bytes, offset + 1);
                                operandsFloating[i] = operandsInteger[i];
                                break;
                            case BIGINT:
                                currentType = ATypeTag.BIGINT;
                                operandsInteger[i] = AInt64SerializerDeserializer.getLong(bytes, offset + 1);
                                operandsFloating[i] = operandsInteger[i];
                                break;
                            case FLOAT:
                                currentType = ATypeTag.FLOAT;
                                operandsFloating[i] = AFloatSerializerDeserializer.getFloat(bytes, offset + 1);
                                break;
                            case DOUBLE:
                                currentType = ATypeTag.DOUBLE;
                                operandsFloating[i] = ADoubleSerializerDeserializer.getDouble(bytes, offset + 1);
                                break;
                            case DATE:
                            case TIME:
                            case DATETIME:
                            case DURATION:
                            case YEARMONTHDURATION:
                            case DAYTIMEDURATION:
                                evaluateTemporalArithmeticOperation(typeTag);
                                result.set(resultStorage);
                                return;
                            default:
                                throw new TypeMismatchException(sourceLoc, getIdentifier(), i, bytes[offset], ATypeTag.SERIALIZED_INT8_TYPE_TAG, ATypeTag.SERIALIZED_INT16_TYPE_TAG, ATypeTag.SERIALIZED_INT32_TYPE_TAG, ATypeTag.SERIALIZED_INT64_TYPE_TAG, ATypeTag.SERIALIZED_FLOAT_TYPE_TAG, ATypeTag.SERIALIZED_DOUBLE_TYPE_TAG, ATypeTag.SERIALIZED_DATE_TYPE_TAG, ATypeTag.SERIALIZED_TIME_TYPE_TAG, ATypeTag.SERIALIZED_DATETIME_TYPE_TAG, ATypeTag.SERIALIZED_DURATION_TYPE_TAG, ATypeTag.SERIALIZED_YEAR_MONTH_DURATION_TYPE_TAG, ATypeTag.SERIALIZED_DAY_TIME_DURATION_TYPE_TAG);
                        }
                        if (i == 0 || currentType.ordinal() > argTypeMax.ordinal()) {
                            argTypeMax = currentType;
                        }
                    }
                    ATypeTag resultType = getNumericResultType(argTypeMax);
                    long lres;
                    double dres;
                    switch(resultType) {
                        case TINYINT:
                            if (evaluateInteger(operandsInteger[0], operandsInteger[1], aInt64)) {
                                lres = aInt64.getLongValue();
                                if (lres > Byte.MAX_VALUE) {
                                    throw new OverflowException(sourceLoc, getIdentifier());
                                }
                                if (lres < Byte.MIN_VALUE) {
                                    throw new UnderflowException(sourceLoc, getIdentifier());
                                }
                                aInt8.setValue((byte) lres);
                                int8Serde.serialize(aInt8, out);
                            } else {
                                nullSerde.serialize(ANull.NULL, out);
                            }
                            break;
                        case SMALLINT:
                            if (evaluateInteger(operandsInteger[0], operandsInteger[1], aInt64)) {
                                lres = aInt64.getLongValue();
                                if (lres > Short.MAX_VALUE) {
                                    throw new OverflowException(sourceLoc, getIdentifier());
                                }
                                if (lres < Short.MIN_VALUE) {
                                    throw new UnderflowException(sourceLoc, getIdentifier());
                                }
                                aInt16.setValue((short) lres);
                                int16Serde.serialize(aInt16, out);
                            } else {
                                nullSerde.serialize(ANull.NULL, out);
                            }
                            break;
                        case INTEGER:
                            if (evaluateInteger(operandsInteger[0], operandsInteger[1], aInt64)) {
                                lres = aInt64.getLongValue();
                                if (lres > Integer.MAX_VALUE) {
                                    throw new OverflowException(sourceLoc, getIdentifier());
                                }
                                if (lres < Integer.MIN_VALUE) {
                                    throw new UnderflowException(sourceLoc, getIdentifier());
                                }
                                aInt32.setValue((int) lres);
                                int32Serde.serialize(aInt32, out);
                            } else {
                                nullSerde.serialize(ANull.NULL, out);
                            }
                            break;
                        case BIGINT:
                            if (evaluateInteger(operandsInteger[0], operandsInteger[1], aInt64)) {
                                int64Serde.serialize(aInt64, out);
                            } else {
                                nullSerde.serialize(ANull.NULL, out);
                            }
                            break;
                        case FLOAT:
                            if (evaluateDouble(operandsFloating[0], operandsFloating[1], aDouble)) {
                                dres = aDouble.getDoubleValue();
                                if (dres > Float.MAX_VALUE) {
                                    throw new OverflowException(sourceLoc, getIdentifier());
                                }
                                if (dres < -Float.MAX_VALUE) {
                                    throw new UnderflowException(sourceLoc, getIdentifier());
                                }
                                aFloat.setValue((float) dres);
                                floatSerde.serialize(aFloat, out);
                            } else {
                                nullSerde.serialize(ANull.NULL, out);
                            }
                            break;
                        case DOUBLE:
                            if (evaluateDouble(operandsFloating[0], operandsFloating[1], aDouble)) {
                                doubleSerde.serialize(aDouble, out);
                            } else {
                                nullSerde.serialize(ANull.NULL, out);
                            }
                            break;
                    }
                    result.set(resultStorage);
                }

                @SuppressWarnings("unchecked")
                private void evaluateTemporalArithmeticOperation(ATypeTag leftType) throws HyracksDataException {
                    byte[] bytes1 = argPtr1.getByteArray();
                    int offset1 = argPtr1.getStartOffset();
                    ATypeTag rightType = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(bytes1[offset1]);
                    byte[] bytes0 = argPtr0.getByteArray();
                    int offset0 = argPtr0.getStartOffset();
                    if (rightType == leftType) {
                        long leftChronon = 0, rightChronon = 0, dayTime = 0;
                        int yearMonth = 0;
                        boolean yearMonthIsNull = false, dayTimeIsNull = false;
                        switch(leftType) {
                            case DATE:
                                leftChronon = ADateSerializerDeserializer.getChronon(bytes0, offset0 + 1) * GregorianCalendarSystem.CHRONON_OF_DAY;
                                rightChronon = ADateSerializerDeserializer.getChronon(bytes1, offset1 + 1) * GregorianCalendarSystem.CHRONON_OF_DAY;
                                break;
                            case TIME:
                                leftChronon = ATimeSerializerDeserializer.getChronon(bytes0, offset0 + 1);
                                rightChronon = ATimeSerializerDeserializer.getChronon(bytes1, offset1 + 1);
                                break;
                            case DATETIME:
                                leftChronon = ADateTimeSerializerDeserializer.getChronon(bytes0, offset0 + 1);
                                rightChronon = ADateTimeSerializerDeserializer.getChronon(bytes1, offset1 + 1);
                                break;
                            case YEARMONTHDURATION:
                                if (evaluateTimeInstanceArithmetic(AYearMonthDurationSerializerDeserializer.getYearMonth(bytes0, offset0 + 1), AYearMonthDurationSerializerDeserializer.getYearMonth(bytes1, offset1 + 1), aInt64)) {
                                    yearMonth = (int) aInt64.getLongValue();
                                } else {
                                    yearMonthIsNull = true;
                                }
                                break;
                            case DAYTIMEDURATION:
                                leftChronon = ADayTimeDurationSerializerDeserializer.getDayTime(bytes0, offset0 + 1);
                                rightChronon = ADayTimeDurationSerializerDeserializer.getDayTime(bytes1, offset1 + 1);
                                break;
                            default:
                                throw new UnsupportedTypeException(sourceLoc, getIdentifier(), bytes1[offset1]);
                        }
                        if (evaluateTimeInstanceArithmetic(leftChronon, rightChronon, aInt64)) {
                            dayTime = aInt64.getLongValue();
                        } else {
                            dayTimeIsNull = true;
                        }
                        if (yearMonthIsNull || dayTimeIsNull) {
                            nullSerde.serialize(ANull.NULL, out);
                        } else {
                            aDuration.setValue(yearMonth, dayTime);
                            durationSerde.serialize(aDuration, out);
                        }
                    } else {
                        long chronon = 0, dayTime = 0;
                        int yearMonth = 0;
                        ATypeTag resultType = null;
                        ISerializerDeserializer serde = null;
                        boolean isTimeOnly = false;
                        switch(leftType) {
                            case TIME:
                                serde = timeSerde;
                                chronon = ATimeSerializerDeserializer.getChronon(bytes0, offset0 + 1);
                                isTimeOnly = true;
                                resultType = ATypeTag.TIME;
                                switch(rightType) {
                                    case DAYTIMEDURATION:
                                        dayTime = ADayTimeDurationSerializerDeserializer.getDayTime(bytes1, offset1 + 1);
                                        break;
                                    case DURATION:
                                        dayTime = ADurationSerializerDeserializer.getDayTime(bytes1, offset1 + 1);
                                        yearMonth = ADurationSerializerDeserializer.getYearMonth(bytes1, offset1 + 1);
                                        break;
                                    default:
                                        throw new IncompatibleTypeException(sourceLoc, getIdentifier(), bytes0[offset0], bytes1[offset1]);
                                }
                                break;
                            case DATE:
                                serde = dateSerde;
                                resultType = ATypeTag.DATE;
                                chronon = ADateSerializerDeserializer.getChronon(bytes0, offset0 + 1) * GregorianCalendarSystem.CHRONON_OF_DAY;
                            case DATETIME:
                                if (leftType == ATypeTag.DATETIME) {
                                    serde = dateTimeSerde;
                                    resultType = ATypeTag.DATETIME;
                                    chronon = ADateTimeSerializerDeserializer.getChronon(bytes0, offset0 + 1);
                                }
                                switch(rightType) {
                                    case DURATION:
                                        yearMonth = ADurationSerializerDeserializer.getYearMonth(bytes1, offset1 + 1);
                                        dayTime = ADurationSerializerDeserializer.getDayTime(bytes1, offset1 + 1);
                                        break;
                                    case YEARMONTHDURATION:
                                        yearMonth = AYearMonthDurationSerializerDeserializer.getYearMonth(bytes1, offset1 + 1);
                                        break;
                                    case DAYTIMEDURATION:
                                        dayTime = ADayTimeDurationSerializerDeserializer.getDayTime(bytes1, offset1 + 1);
                                        break;
                                    default:
                                        throw new IncompatibleTypeException(sourceLoc, getIdentifier(), bytes0[offset0], bytes1[offset1]);
                                }
                                break;
                            case YEARMONTHDURATION:
                                yearMonth = AYearMonthDurationSerializerDeserializer.getYearMonth(bytes0, offset0 + 1);
                                switch(rightType) {
                                    case DATETIME:
                                        serde = dateTimeSerde;
                                        resultType = ATypeTag.DATETIME;
                                        chronon = ADateTimeSerializerDeserializer.getChronon(bytes1, offset1 + 1);
                                        break;
                                    case DATE:
                                        serde = dateSerde;
                                        resultType = ATypeTag.DATE;
                                        chronon = ADateSerializerDeserializer.getChronon(bytes1, offset1 + 1) * GregorianCalendarSystem.CHRONON_OF_DAY;
                                        break;
                                    default:
                                        throw new IncompatibleTypeException(sourceLoc, getIdentifier(), bytes0[offset0], bytes1[offset1]);
                                }
                                break;
                            case DURATION:
                                yearMonth = ADurationSerializerDeserializer.getYearMonth(bytes0, offset0 + 1);
                                dayTime = ADurationSerializerDeserializer.getDayTime(bytes0, offset0 + 1);
                            case DAYTIMEDURATION:
                                if (leftType == ATypeTag.DAYTIMEDURATION) {
                                    dayTime = ADayTimeDurationSerializerDeserializer.getDayTime(bytes0, offset0 + 1);
                                }
                                switch(rightType) {
                                    case DATETIME:
                                        serde = dateTimeSerde;
                                        resultType = ATypeTag.DATETIME;
                                        chronon = ADateTimeSerializerDeserializer.getChronon(bytes1, offset1 + 1);
                                        break;
                                    case DATE:
                                        serde = dateSerde;
                                        resultType = ATypeTag.DATE;
                                        chronon = ADateSerializerDeserializer.getChronon(bytes1, offset1 + 1) * GregorianCalendarSystem.CHRONON_OF_DAY;
                                        break;
                                    case TIME:
                                        if (yearMonth == 0) {
                                            serde = timeSerde;
                                            resultType = ATypeTag.TIME;
                                            chronon = ATimeSerializerDeserializer.getChronon(bytes1, offset1 + 1);
                                            isTimeOnly = true;
                                            break;
                                        }
                                    default:
                                        throw new IncompatibleTypeException(sourceLoc, getIdentifier(), bytes0[offset0], bytes1[offset1]);
                                }
                                break;
                            default:
                                throw new IncompatibleTypeException(sourceLoc, getIdentifier(), bytes0[offset0], bytes1[offset1]);
                        }
                        boolean eres = evaluateTimeDurationArithmetic(chronon, yearMonth, dayTime, isTimeOnly, aInt64);
                        if (eres) {
                            chronon = aInt64.getLongValue();
                            switch(resultType) {
                                case DATE:
                                    if (chronon < 0 && chronon % GregorianCalendarSystem.CHRONON_OF_DAY != 0) {
                                        chronon = chronon / GregorianCalendarSystem.CHRONON_OF_DAY - 1;
                                    } else {
                                        chronon = chronon / GregorianCalendarSystem.CHRONON_OF_DAY;
                                    }
                                    aDate.setValue((int) chronon);
                                    serde.serialize(aDate, out);
                                    break;
                                case TIME:
                                    aTime.setValue((int) chronon);
                                    serde.serialize(aTime, out);
                                    break;
                                case DATETIME:
                                    aDatetime.setValue(chronon);
                                    serde.serialize(aDatetime, out);
                                    break;
                                default:
                                    throw new IncompatibleTypeException(sourceLoc, getIdentifier(), bytes0[offset0], bytes1[offset1]);
                            }
                        } else {
                            nullSerde.serialize(ANull.NULL, out);
                        }
                    }
                }
            };
        }
    };
}
#method_after
@Override
public IScalarEvaluatorFactory createEvaluatorFactory(final IScalarEvaluatorFactory[] args) {
    return new IScalarEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IScalarEvaluator createScalarEvaluator(IHyracksTaskContext ctx) throws HyracksDataException {
            return new IScalarEvaluator() {

                private final ArrayBackedValueStorage resultStorage = new ArrayBackedValueStorage();

                private final DataOutput out = resultStorage.getDataOutput();

                private final IPointable argPtr0 = new VoidPointable();

                private final IPointable argPtr1 = new VoidPointable();

                private final IScalarEvaluator evalLeft = args[0].createScalarEvaluator(ctx);

                private final IScalarEvaluator evalRight = args[1].createScalarEvaluator(ctx);

                private final double[] operandsFloating = new double[args.length];

                private final long[] operandsInteger = new long[args.length];

                private final AMutableFloat aFloat = new AMutableFloat(0);

                private final AMutableDouble aDouble = new AMutableDouble(0);

                private final AMutableInt64 aInt64 = new AMutableInt64(0);

                private final AMutableInt32 aInt32 = new AMutableInt32(0);

                private final AMutableInt16 aInt16 = new AMutableInt16((short) 0);

                private final AMutableInt8 aInt8 = new AMutableInt8((byte) 0);

                private final AMutableDuration aDuration = new AMutableDuration(0, 0);

                private final AMutableDate aDate = new AMutableDate(0);

                private final AMutableTime aTime = new AMutableTime(0);

                private final AMutableDateTime aDatetime = new AMutableDateTime(0);

                @SuppressWarnings("rawtypes")
                private final ISerializerDeserializer int8Serde = SerializerDeserializerProvider.INSTANCE.getSerializerDeserializer(BuiltinType.AINT8);

                @SuppressWarnings("rawtypes")
                private final ISerializerDeserializer int16Serde = SerializerDeserializerProvider.INSTANCE.getSerializerDeserializer(BuiltinType.AINT16);

                @SuppressWarnings("rawtypes")
                private final ISerializerDeserializer int32Serde = SerializerDeserializerProvider.INSTANCE.getSerializerDeserializer(BuiltinType.AINT32);

                @SuppressWarnings("rawtypes")
                private final ISerializerDeserializer int64Serde = SerializerDeserializerProvider.INSTANCE.getSerializerDeserializer(BuiltinType.AINT64);

                @SuppressWarnings("rawtypes")
                private final ISerializerDeserializer floatSerde = SerializerDeserializerProvider.INSTANCE.getSerializerDeserializer(BuiltinType.AFLOAT);

                @SuppressWarnings("rawtypes")
                private final ISerializerDeserializer doubleSerde = SerializerDeserializerProvider.INSTANCE.getSerializerDeserializer(BuiltinType.ADOUBLE);

                @SuppressWarnings("rawtypes")
                private final ISerializerDeserializer dateSerde = SerializerDeserializerProvider.INSTANCE.getSerializerDeserializer(BuiltinType.ADATE);

                @SuppressWarnings("rawtypes")
                private final ISerializerDeserializer timeSerde = SerializerDeserializerProvider.INSTANCE.getSerializerDeserializer(BuiltinType.ATIME);

                @SuppressWarnings("rawtypes")
                private final ISerializerDeserializer dateTimeSerde = SerializerDeserializerProvider.INSTANCE.getSerializerDeserializer(BuiltinType.ADATETIME);

                @SuppressWarnings("rawtypes")
                private final ISerializerDeserializer durationSerde = SerializerDeserializerProvider.INSTANCE.getSerializerDeserializer(BuiltinType.ADURATION);

                @SuppressWarnings("rawtypes")
                private final ISerializerDeserializer nullSerde = SerializerDeserializerProvider.INSTANCE.getSerializerDeserializer(BuiltinType.ANULL);

                @Override
                @SuppressWarnings("unchecked")
                public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException {
                    evalLeft.evaluate(tuple, argPtr0);
                    evalRight.evaluate(tuple, argPtr1);
                    resultStorage.reset();
                    ATypeTag argTypeMax = null;
                    for (int i = 0; i < 2; i++) {
                        IPointable argPtr = i == 0 ? argPtr0 : argPtr1;
                        byte[] bytes = argPtr.getByteArray();
                        int offset = argPtr.getStartOffset();
                        ATypeTag currentType;
                        ATypeTag typeTag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(bytes[offset]);
                        switch(typeTag) {
                            case TINYINT:
                                currentType = ATypeTag.TINYINT;
                                operandsInteger[i] = AInt8SerializerDeserializer.getByte(bytes, offset + 1);
                                operandsFloating[i] = operandsInteger[i];
                                break;
                            case SMALLINT:
                                currentType = ATypeTag.SMALLINT;
                                operandsInteger[i] = AInt16SerializerDeserializer.getShort(bytes, offset + 1);
                                operandsFloating[i] = operandsInteger[i];
                                break;
                            case INTEGER:
                                currentType = ATypeTag.INTEGER;
                                operandsInteger[i] = AInt32SerializerDeserializer.getInt(bytes, offset + 1);
                                operandsFloating[i] = operandsInteger[i];
                                break;
                            case BIGINT:
                                currentType = ATypeTag.BIGINT;
                                operandsInteger[i] = AInt64SerializerDeserializer.getLong(bytes, offset + 1);
                                operandsFloating[i] = operandsInteger[i];
                                break;
                            case FLOAT:
                                currentType = ATypeTag.FLOAT;
                                operandsFloating[i] = AFloatSerializerDeserializer.getFloat(bytes, offset + 1);
                                break;
                            case DOUBLE:
                                currentType = ATypeTag.DOUBLE;
                                operandsFloating[i] = ADoubleSerializerDeserializer.getDouble(bytes, offset + 1);
                                break;
                            case DATE:
                            case TIME:
                            case DATETIME:
                            case DURATION:
                            case YEARMONTHDURATION:
                            case DAYTIMEDURATION:
                                evaluateTemporalArithmeticOperation(typeTag);
                                result.set(resultStorage);
                                return;
                            default:
                                throw new TypeMismatchException(sourceLoc, getIdentifier(), i, bytes[offset], ATypeTag.SERIALIZED_INT8_TYPE_TAG, ATypeTag.SERIALIZED_INT16_TYPE_TAG, ATypeTag.SERIALIZED_INT32_TYPE_TAG, ATypeTag.SERIALIZED_INT64_TYPE_TAG, ATypeTag.SERIALIZED_FLOAT_TYPE_TAG, ATypeTag.SERIALIZED_DOUBLE_TYPE_TAG, ATypeTag.SERIALIZED_DATE_TYPE_TAG, ATypeTag.SERIALIZED_TIME_TYPE_TAG, ATypeTag.SERIALIZED_DATETIME_TYPE_TAG, ATypeTag.SERIALIZED_DURATION_TYPE_TAG, ATypeTag.SERIALIZED_YEAR_MONTH_DURATION_TYPE_TAG, ATypeTag.SERIALIZED_DAY_TIME_DURATION_TYPE_TAG);
                        }
                        if (i == 0 || currentType.ordinal() > argTypeMax.ordinal()) {
                            argTypeMax = currentType;
                        }
                    }
                    ATypeTag resultType = getNumericResultType(argTypeMax);
                    long lres;
                    double dres;
                    switch(resultType) {
                        case TINYINT:
                            if (evaluateInteger(operandsInteger[0], operandsInteger[1], aInt64)) {
                                lres = aInt64.getLongValue();
                                if (lres > Byte.MAX_VALUE) {
                                    throw new OverflowException(sourceLoc, getIdentifier());
                                }
                                if (lres < Byte.MIN_VALUE) {
                                    throw new UnderflowException(sourceLoc, getIdentifier());
                                }
                                aInt8.setValue((byte) lres);
                                int8Serde.serialize(aInt8, out);
                            } else {
                                nullSerde.serialize(ANull.NULL, out);
                            }
                            break;
                        case SMALLINT:
                            if (evaluateInteger(operandsInteger[0], operandsInteger[1], aInt64)) {
                                lres = aInt64.getLongValue();
                                if (lres > Short.MAX_VALUE) {
                                    throw new OverflowException(sourceLoc, getIdentifier());
                                }
                                if (lres < Short.MIN_VALUE) {
                                    throw new UnderflowException(sourceLoc, getIdentifier());
                                }
                                aInt16.setValue((short) lres);
                                int16Serde.serialize(aInt16, out);
                            } else {
                                nullSerde.serialize(ANull.NULL, out);
                            }
                            break;
                        case INTEGER:
                            if (evaluateInteger(operandsInteger[0], operandsInteger[1], aInt64)) {
                                lres = aInt64.getLongValue();
                                if (lres > Integer.MAX_VALUE) {
                                    throw new OverflowException(sourceLoc, getIdentifier());
                                }
                                if (lres < Integer.MIN_VALUE) {
                                    throw new UnderflowException(sourceLoc, getIdentifier());
                                }
                                aInt32.setValue((int) lres);
                                int32Serde.serialize(aInt32, out);
                            } else {
                                nullSerde.serialize(ANull.NULL, out);
                            }
                            break;
                        case BIGINT:
                            if (evaluateInteger(operandsInteger[0], operandsInteger[1], aInt64)) {
                                int64Serde.serialize(aInt64, out);
                            } else {
                                nullSerde.serialize(ANull.NULL, out);
                            }
                            break;
                        case FLOAT:
                            if (evaluateDouble(operandsFloating[0], operandsFloating[1], aDouble)) {
                                dres = aDouble.getDoubleValue();
                                if (dres > Float.MAX_VALUE) {
                                    throw new OverflowException(sourceLoc, getIdentifier());
                                }
                                if (dres < -Float.MAX_VALUE) {
                                    throw new UnderflowException(sourceLoc, getIdentifier());
                                }
                                aFloat.setValue((float) dres);
                                floatSerde.serialize(aFloat, out);
                            } else {
                                nullSerde.serialize(ANull.NULL, out);
                            }
                            break;
                        case DOUBLE:
                            if (evaluateDouble(operandsFloating[0], operandsFloating[1], aDouble)) {
                                doubleSerde.serialize(aDouble, out);
                            } else {
                                nullSerde.serialize(ANull.NULL, out);
                            }
                            break;
                    }
                    result.set(resultStorage);
                }

                @SuppressWarnings("unchecked")
                private void evaluateTemporalArithmeticOperation(ATypeTag leftType) throws HyracksDataException {
                    byte[] bytes1 = argPtr1.getByteArray();
                    int offset1 = argPtr1.getStartOffset();
                    ATypeTag rightType = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(bytes1[offset1]);
                    byte[] bytes0 = argPtr0.getByteArray();
                    int offset0 = argPtr0.getStartOffset();
                    if (rightType == leftType) {
                        long leftChronon = 0, rightChronon = 0, dayTime = 0;
                        int yearMonth = 0;
                        boolean yearMonthIsNull = false, dayTimeIsNull = false;
                        switch(leftType) {
                            case DATE:
                                leftChronon = ADateSerializerDeserializer.getChronon(bytes0, offset0 + 1) * GregorianCalendarSystem.CHRONON_OF_DAY;
                                rightChronon = ADateSerializerDeserializer.getChronon(bytes1, offset1 + 1) * GregorianCalendarSystem.CHRONON_OF_DAY;
                                break;
                            case TIME:
                                leftChronon = ATimeSerializerDeserializer.getChronon(bytes0, offset0 + 1);
                                rightChronon = ATimeSerializerDeserializer.getChronon(bytes1, offset1 + 1);
                                break;
                            case DATETIME:
                                leftChronon = ADateTimeSerializerDeserializer.getChronon(bytes0, offset0 + 1);
                                rightChronon = ADateTimeSerializerDeserializer.getChronon(bytes1, offset1 + 1);
                                break;
                            case YEARMONTHDURATION:
                                if (evaluateTimeInstanceArithmetic(AYearMonthDurationSerializerDeserializer.getYearMonth(bytes0, offset0 + 1), AYearMonthDurationSerializerDeserializer.getYearMonth(bytes1, offset1 + 1), aInt64)) {
                                    yearMonth = (int) aInt64.getLongValue();
                                } else {
                                    yearMonthIsNull = true;
                                }
                                break;
                            case DAYTIMEDURATION:
                                leftChronon = ADayTimeDurationSerializerDeserializer.getDayTime(bytes0, offset0 + 1);
                                rightChronon = ADayTimeDurationSerializerDeserializer.getDayTime(bytes1, offset1 + 1);
                                break;
                            default:
                                throw new UnsupportedTypeException(sourceLoc, getIdentifier(), bytes1[offset1]);
                        }
                        if (evaluateTimeInstanceArithmetic(leftChronon, rightChronon, aInt64)) {
                            dayTime = aInt64.getLongValue();
                        } else {
                            dayTimeIsNull = true;
                        }
                        if (yearMonthIsNull || dayTimeIsNull) {
                            nullSerde.serialize(ANull.NULL, out);
                        } else {
                            aDuration.setValue(yearMonth, dayTime);
                            durationSerde.serialize(aDuration, out);
                        }
                    } else {
                        long chronon = 0, dayTime = 0;
                        int yearMonth = 0;
                        ATypeTag resultType = null;
                        ISerializerDeserializer serde = null;
                        boolean isTimeOnly = false;
                        switch(leftType) {
                            case TIME:
                                serde = timeSerde;
                                chronon = ATimeSerializerDeserializer.getChronon(bytes0, offset0 + 1);
                                isTimeOnly = true;
                                resultType = ATypeTag.TIME;
                                switch(rightType) {
                                    case DAYTIMEDURATION:
                                        dayTime = ADayTimeDurationSerializerDeserializer.getDayTime(bytes1, offset1 + 1);
                                        break;
                                    case DURATION:
                                        dayTime = ADurationSerializerDeserializer.getDayTime(bytes1, offset1 + 1);
                                        yearMonth = ADurationSerializerDeserializer.getYearMonth(bytes1, offset1 + 1);
                                        break;
                                    default:
                                        throw new IncompatibleTypeException(sourceLoc, getIdentifier(), bytes0[offset0], bytes1[offset1]);
                                }
                                break;
                            case DATE:
                                serde = dateSerde;
                                resultType = ATypeTag.DATE;
                                chronon = ADateSerializerDeserializer.getChronon(bytes0, offset0 + 1) * GregorianCalendarSystem.CHRONON_OF_DAY;
                            case DATETIME:
                                if (leftType == ATypeTag.DATETIME) {
                                    serde = dateTimeSerde;
                                    resultType = ATypeTag.DATETIME;
                                    chronon = ADateTimeSerializerDeserializer.getChronon(bytes0, offset0 + 1);
                                }
                                switch(rightType) {
                                    case DURATION:
                                        yearMonth = ADurationSerializerDeserializer.getYearMonth(bytes1, offset1 + 1);
                                        dayTime = ADurationSerializerDeserializer.getDayTime(bytes1, offset1 + 1);
                                        break;
                                    case YEARMONTHDURATION:
                                        yearMonth = AYearMonthDurationSerializerDeserializer.getYearMonth(bytes1, offset1 + 1);
                                        break;
                                    case DAYTIMEDURATION:
                                        dayTime = ADayTimeDurationSerializerDeserializer.getDayTime(bytes1, offset1 + 1);
                                        break;
                                    default:
                                        throw new IncompatibleTypeException(sourceLoc, getIdentifier(), bytes0[offset0], bytes1[offset1]);
                                }
                                break;
                            case YEARMONTHDURATION:
                                yearMonth = AYearMonthDurationSerializerDeserializer.getYearMonth(bytes0, offset0 + 1);
                                switch(rightType) {
                                    case DATETIME:
                                        serde = dateTimeSerde;
                                        resultType = ATypeTag.DATETIME;
                                        chronon = ADateTimeSerializerDeserializer.getChronon(bytes1, offset1 + 1);
                                        break;
                                    case DATE:
                                        serde = dateSerde;
                                        resultType = ATypeTag.DATE;
                                        chronon = ADateSerializerDeserializer.getChronon(bytes1, offset1 + 1) * GregorianCalendarSystem.CHRONON_OF_DAY;
                                        break;
                                    default:
                                        throw new IncompatibleTypeException(sourceLoc, getIdentifier(), bytes0[offset0], bytes1[offset1]);
                                }
                                break;
                            case DURATION:
                                yearMonth = ADurationSerializerDeserializer.getYearMonth(bytes0, offset0 + 1);
                                dayTime = ADurationSerializerDeserializer.getDayTime(bytes0, offset0 + 1);
                            case DAYTIMEDURATION:
                                if (leftType == ATypeTag.DAYTIMEDURATION) {
                                    dayTime = ADayTimeDurationSerializerDeserializer.getDayTime(bytes0, offset0 + 1);
                                }
                                switch(rightType) {
                                    case DATETIME:
                                        serde = dateTimeSerde;
                                        resultType = ATypeTag.DATETIME;
                                        chronon = ADateTimeSerializerDeserializer.getChronon(bytes1, offset1 + 1);
                                        break;
                                    case DATE:
                                        serde = dateSerde;
                                        resultType = ATypeTag.DATE;
                                        chronon = ADateSerializerDeserializer.getChronon(bytes1, offset1 + 1) * GregorianCalendarSystem.CHRONON_OF_DAY;
                                        break;
                                    case TIME:
                                        if (yearMonth == 0) {
                                            serde = timeSerde;
                                            resultType = ATypeTag.TIME;
                                            chronon = ATimeSerializerDeserializer.getChronon(bytes1, offset1 + 1);
                                            isTimeOnly = true;
                                            break;
                                        }
                                    default:
                                        throw new IncompatibleTypeException(sourceLoc, getIdentifier(), bytes0[offset0], bytes1[offset1]);
                                }
                                break;
                            default:
                                throw new IncompatibleTypeException(sourceLoc, getIdentifier(), bytes0[offset0], bytes1[offset1]);
                        }
                        if (evaluateTimeDurationArithmetic(chronon, yearMonth, dayTime, isTimeOnly, aInt64)) {
                            chronon = aInt64.getLongValue();
                            switch(resultType) {
                                case DATE:
                                    if (chronon < 0 && chronon % GregorianCalendarSystem.CHRONON_OF_DAY != 0) {
                                        chronon = chronon / GregorianCalendarSystem.CHRONON_OF_DAY - 1;
                                    } else {
                                        chronon = chronon / GregorianCalendarSystem.CHRONON_OF_DAY;
                                    }
                                    aDate.setValue((int) chronon);
                                    serde.serialize(aDate, out);
                                    break;
                                case TIME:
                                    aTime.setValue((int) chronon);
                                    serde.serialize(aTime, out);
                                    break;
                                case DATETIME:
                                    aDatetime.setValue(chronon);
                                    serde.serialize(aDatetime, out);
                                    break;
                                default:
                                    throw new IncompatibleTypeException(sourceLoc, getIdentifier(), bytes0[offset0], bytes1[offset1]);
                            }
                        } else {
                            nullSerde.serialize(ANull.NULL, out);
                        }
                    }
                }
            };
        }
    };
}
#end_block

#method_before
private static Map<String, Object> validateConfig(Map<String, Object> config, SourceLocation sourceLoc) throws AlgebricksException {
    for (String parameterName : config.keySet()) {
        if (!CONFIGURABLE_PARAMETER_NAMES.contains(parameterName)) {
            throw AsterixException.create(ErrorCode.COMPILATION_UNSUPPORTED_QUERY_PARAMETER, sourceLoc, parameterName);
        }
    }
    return config;
}
#method_after
private static Map<String, Object> validateConfig(Map<String, Object> config, SourceLocation sourceLoc) throws AlgebricksException {
    for (String parameterName : config.keySet()) {
        if (!CONFIGURABLE_PARAMETER_NAMES.contains(parameterName) && !parameterName.startsWith(PREFIX_INTERNAL_PARAMETERS)) {
            throw AsterixException.create(ErrorCode.COMPILATION_UNSUPPORTED_QUERY_PARAMETER, sourceLoc, parameterName);
        }
    }
    return config;
}
#end_block

#method_before
@Override
public void add(ITupleReference tuple) throws HyracksDataException {
    if (hasFailed()) {
        throw HyracksDataException.create(failure);
    }
    try {
        int leafFrameTupleSize = leafFrame.getBytesRequiredToWriteTuple(tuple);
        int interiorFrameTupleSize = interiorFrame.getBytesRequiredToWriteTuple(tuple);
        int tupleSize = Math.max(leafFrameTupleSize, interiorFrameTupleSize);
        if (tupleSize > maxTupleSize) {
            throw HyracksDataException.create(ErrorCode.RECORD_IS_TOO_LARGE, tupleSize, maxTupleSize);
        }
        NodeFrontier leafFrontier = nodeFrontiers.get(0);
        int spaceNeeded = leafFrameTupleSize;
        int spaceUsed = leafFrame.getBuffer().capacity() - leafFrame.getTotalFreeSpace();
        // try to free space by compression
        if (spaceUsed + spaceNeeded > leafMaxBytes) {
            leafFrame.compress();
            spaceUsed = leafFrame.getBuffer().capacity() - leafFrame.getTotalFreeSpace();
        }
        if (spaceUsed + spaceNeeded > leafMaxBytes) {
            if (prevNodeFrontierPages.size() == 0) {
                prevNodeFrontierPages.add(leafFrontier.pageId);
            } else {
                prevNodeFrontierPages.set(0, leafFrontier.pageId);
            }
            propagateBulk(1, false, pagesToWrite);
            leafFrontier.pageId = freePageManager.takePage(metaFrame);
            queue.put(leafFrontier.page, this);
            for (ICachedPage c : pagesToWrite) {
                queue.put(c, this);
            }
            pagesToWrite.clear();
            leafFrontier.page = bufferCache.confiscatePage(BufferedFileHandle.getDiskPageId(getFileId(), leafFrontier.pageId));
            leafFrame.setPage(leafFrontier.page);
            leafFrame.initBuffer((byte) 0);
        }
        leafFrame.setPage(leafFrontier.page);
        leafFrame.insert(tuple, AbstractSlotManager.GREATEST_KEY_INDICATOR);
    } catch (HyracksDataException e) {
        handleException();
        throw e;
    } catch (RuntimeException e) {
        handleException();
        throw e;
    }
}
#method_after
@Override
public void add(ITupleReference tuple) throws HyracksDataException {
    try {
        int leafFrameTupleSize = leafFrame.getBytesRequiredToWriteTuple(tuple);
        int interiorFrameTupleSize = interiorFrame.getBytesRequiredToWriteTuple(tuple);
        int tupleSize = Math.max(leafFrameTupleSize, interiorFrameTupleSize);
        if (tupleSize > maxTupleSize) {
            throw HyracksDataException.create(ErrorCode.RECORD_IS_TOO_LARGE, tupleSize, maxTupleSize);
        }
        NodeFrontier leafFrontier = nodeFrontiers.get(0);
        int spaceNeeded = leafFrameTupleSize;
        int spaceUsed = leafFrame.getBuffer().capacity() - leafFrame.getTotalFreeSpace();
        // try to free space by compression
        if (spaceUsed + spaceNeeded > leafMaxBytes) {
            leafFrame.compress();
            spaceUsed = leafFrame.getBuffer().capacity() - leafFrame.getTotalFreeSpace();
        }
        if (spaceUsed + spaceNeeded > leafMaxBytes) {
            if (prevNodeFrontierPages.size() == 0) {
                prevNodeFrontierPages.add(leafFrontier.pageId);
            } else {
                prevNodeFrontierPages.set(0, leafFrontier.pageId);
            }
            propagateBulk(1, false, pagesToWrite);
            leafFrontier.pageId = freePageManager.takePage(metaFrame);
            queue.put(leafFrontier.page, this);
            for (ICachedPage c : pagesToWrite) {
                queue.put(c, this);
            }
            pagesToWrite.clear();
            leafFrontier.page = bufferCache.confiscatePage(BufferedFileHandle.getDiskPageId(getFileId(), leafFrontier.pageId));
            leafFrame.setPage(leafFrontier.page);
            leafFrame.initBuffer((byte) 0);
        }
        leafFrame.setPage(leafFrontier.page);
        leafFrame.insert(tuple, AbstractSlotManager.GREATEST_KEY_INDICATOR);
    } catch (HyracksDataException e) {
        handleException();
        throw e;
    } catch (RuntimeException e) {
        handleException();
        throw e;
    }
}
#end_block

#method_before
protected void propagateBulk(int level, boolean toRoot, List<ICachedPage> pagesToWrite) throws HyracksDataException {
    boolean propagated = false;
    if (level == 1) {
        lowerFrame = leafFrame;
    }
    if (lowerFrame.getTupleCount() == 0) {
        return;
    }
    if (level >= nodeFrontiers.size()) {
        addLevel();
    }
    // adjust the tuple pointers of the lower frame to allow us to calculate our MBR
    // if this is a leaf, then there is only one tuple, so this is trivial
    ((RTreeNSMFrame) lowerFrame).adjustMBR();
    if (mbr == null) {
        int bytesRequired = interiorFrameTupleWriter.bytesRequired(((RTreeNSMFrame) lowerFrame).getMBRTuples()[0], 0, cmp.getKeyFieldCount()) + ((RTreeNSMInteriorFrame) interiorFrame).getChildPointerSize();
        mbr = ByteBuffer.allocate(bytesRequired);
    }
    interiorFrameTupleWriter.writeTupleFields(((RTreeNSMFrame) lowerFrame).getMBRTuples(), 0, mbr, 0);
    mbrTuple.resetByTupleOffset(mbr.array(), 0);
    NodeFrontier frontier = nodeFrontiers.get(level);
    interiorFrame.setPage(frontier.page);
    // see if we have space for two tuples. this works around a  tricky boundary condition with sequential bulk
    // load where finalization can possibly lead to a split
    // TODO: accomplish this without wasting 1 tuple
    int sizeOfTwoTuples = 2 * (mbrTuple.getTupleSize() + RTreeNSMInteriorFrame.childPtrSize);
    FrameOpSpaceStatus spaceForTwoTuples = (((RTreeNSMInteriorFrame) interiorFrame).hasSpaceInsert(sizeOfTwoTuples));
    if (spaceForTwoTuples != FrameOpSpaceStatus.SUFFICIENT_CONTIGUOUS_SPACE && !toRoot) {
        int finalPageId = freePageManager.takePage(metaFrame);
        if (prevNodeFrontierPages.size() <= level) {
            prevNodeFrontierPages.add(finalPageId);
        } else {
            prevNodeFrontierPages.set(level, finalPageId);
        }
        frontier.page.setDiskPageId(BufferedFileHandle.getDiskPageId(getFileId(), finalPageId));
        pagesToWrite.add(frontier.page);
        lowerFrame = prevInteriorFrame;
        lowerFrame.setPage(frontier.page);
        frontier.page = bufferCache.confiscatePage(BufferCache.INVALID_DPID);
        interiorFrame.setPage(frontier.page);
        interiorFrame.initBuffer((byte) level);
        interiorFrame.insert(mbrTuple, AbstractSlotManager.GREATEST_KEY_INDICATOR);
        interiorFrame.getBuffer().putInt(interiorFrame.getTupleOffset(interiorFrame.getTupleCount() - 1) + mbrTuple.getTupleSize(), prevNodeFrontierPages.get(level - 1));
        propagateBulk(level + 1, toRoot, pagesToWrite);
    } else if (interiorFrame.hasSpaceInsert(mbrTuple) == FrameOpSpaceStatus.SUFFICIENT_CONTIGUOUS_SPACE && !toRoot) {
        interiorFrame.insert(mbrTuple, -1);
        interiorFrame.getBuffer().putInt(interiorFrame.getTupleOffset(interiorFrame.getTupleCount() - 1) + mbrTuple.getTupleSize(), prevNodeFrontierPages.get(level - 1));
    }
    if (toRoot && level < nodeFrontiers.size() - 1) {
        lowerFrame = prevInteriorFrame;
        lowerFrame.setPage(frontier.page);
        propagateBulk(level + 1, true, pagesToWrite);
    }
    leafFrame.setPage(nodeFrontiers.get(0).page);
}
#method_after
protected void propagateBulk(int level, boolean toRoot, List<ICachedPage> pagesToWrite) throws HyracksDataException {
    if (level == 1) {
        lowerFrame = leafFrame;
    }
    if (lowerFrame.getTupleCount() == 0) {
        return;
    }
    if (level >= nodeFrontiers.size()) {
        addLevel();
    }
    // adjust the tuple pointers of the lower frame to allow us to calculate our MBR
    // if this is a leaf, then there is only one tuple, so this is trivial
    ((RTreeNSMFrame) lowerFrame).adjustMBR();
    if (mbr == null) {
        int bytesRequired = interiorFrameTupleWriter.bytesRequired(((RTreeNSMFrame) lowerFrame).getMBRTuples()[0], 0, cmp.getKeyFieldCount()) + ((RTreeNSMInteriorFrame) interiorFrame).getChildPointerSize();
        mbr = ByteBuffer.allocate(bytesRequired);
    }
    interiorFrameTupleWriter.writeTupleFields(((RTreeNSMFrame) lowerFrame).getMBRTuples(), 0, mbr, 0);
    mbrTuple.resetByTupleOffset(mbr.array(), 0);
    NodeFrontier frontier = nodeFrontiers.get(level);
    interiorFrame.setPage(frontier.page);
    // see if we have space for two tuples. this works around a  tricky boundary condition with sequential bulk
    // load where finalization can possibly lead to a split
    // TODO: accomplish this without wasting 1 tuple
    int sizeOfTwoTuples = 2 * (mbrTuple.getTupleSize() + RTreeNSMInteriorFrame.childPtrSize);
    FrameOpSpaceStatus spaceForTwoTuples = (((RTreeNSMInteriorFrame) interiorFrame).hasSpaceInsert(sizeOfTwoTuples));
    if (spaceForTwoTuples != FrameOpSpaceStatus.SUFFICIENT_CONTIGUOUS_SPACE && !toRoot) {
        int finalPageId = freePageManager.takePage(metaFrame);
        if (prevNodeFrontierPages.size() <= level) {
            prevNodeFrontierPages.add(finalPageId);
        } else {
            prevNodeFrontierPages.set(level, finalPageId);
        }
        frontier.page.setDiskPageId(BufferedFileHandle.getDiskPageId(getFileId(), finalPageId));
        pagesToWrite.add(frontier.page);
        lowerFrame = prevInteriorFrame;
        lowerFrame.setPage(frontier.page);
        frontier.page = bufferCache.confiscatePage(BufferCache.INVALID_DPID);
        interiorFrame.setPage(frontier.page);
        interiorFrame.initBuffer((byte) level);
        interiorFrame.insert(mbrTuple, AbstractSlotManager.GREATEST_KEY_INDICATOR);
        interiorFrame.getBuffer().putInt(interiorFrame.getTupleOffset(interiorFrame.getTupleCount() - 1) + mbrTuple.getTupleSize(), prevNodeFrontierPages.get(level - 1));
        propagateBulk(level + 1, toRoot, pagesToWrite);
    } else if (interiorFrame.hasSpaceInsert(mbrTuple) == FrameOpSpaceStatus.SUFFICIENT_CONTIGUOUS_SPACE && !toRoot) {
        interiorFrame.insert(mbrTuple, -1);
        interiorFrame.getBuffer().putInt(interiorFrame.getTupleOffset(interiorFrame.getTupleCount() - 1) + mbrTuple.getTupleSize(), prevNodeFrontierPages.get(level - 1));
    }
    if (toRoot && level < nodeFrontiers.size() - 1) {
        lowerFrame = prevInteriorFrame;
        lowerFrame.setPage(frontier.page);
        propagateBulk(level + 1, true, pagesToWrite);
    }
    leafFrame.setPage(nodeFrontiers.get(0).page);
}
#end_block

#method_before
@Override
public void add(ITupleReference tuple) throws HyracksDataException {
    if (hasFailed()) {
        throw HyracksDataException.create(getFailure());
    }
    TokenKeyPairTuple pairTuple = (TokenKeyPairTuple) tuple;
    ITupleReference tokenTuple = pairTuple.getTokenTuple();
    ITupleReference keyTuple = pairTuple.getKeyTuple();
    boolean startNewList = pairTuple.isNewToken();
    if (startNewList) {
        if (btreeTupleBuilder.getSize() > 0) {
            insertBTreeTuple();
        }
        startNewList(tokenTuple);
        copyTokenToBTreeTuple(tokenTuple);
    }
    appendInvertedList(keyTuple, 0);
    if (verifyInput) {
        verifyTuple(tuple);
        saveLastTuple(tuple);
    }
}
#method_after
@Override
public void add(ITupleReference tuple) throws HyracksDataException {
    TokenKeyPairTuple pairTuple = (TokenKeyPairTuple) tuple;
    ITupleReference tokenTuple = pairTuple.getTokenTuple();
    ITupleReference keyTuple = pairTuple.getKeyTuple();
    boolean startNewList = pairTuple.isNewToken();
    if (startNewList) {
        if (btreeTupleBuilder.getSize() > 0) {
            insertBTreeTuple();
        }
        startNewList(tokenTuple);
        copyTokenToBTreeTuple(tokenTuple);
    }
    appendInvertedList(keyTuple, 0);
    if (verifyInput) {
        verifyTuple(tuple);
        saveLastTuple(tuple);
    }
}
#end_block

#method_before
@Override
public void add(ITupleReference tuple) throws HyracksDataException {
    if (hasFailed()) {
        throw HyracksDataException.create(getFailure());
    }
    boolean firstElement = btreeTupleBuilder.getSize() == 0;
    boolean startNewList = firstElement;
    if (!firstElement) {
        // If the current and the last token don't match, we start a new list.
        startNewList = !TupleUtils.equalTuples(tuple, lastTuple, numTokenFields);
    }
    if (startNewList) {
        if (!firstElement) {
            // Create entry in btree for last inverted list.
            insertBTreeTuple();
        }
        startNewList(tuple);
        copyTokenToBTreeTuple(tuple);
    } else {
        if (invListCmp.compare(tuple, lastTuple, numTokenFields) == 0) {
            // Duplicate inverted-list element.
            return;
        }
    }
    appendInvertedList(tuple, numTokenFields);
    if (verifyInput) {
        verifyTuple(tuple);
    }
    saveLastTuple(tuple);
}
#method_after
@Override
public void add(ITupleReference tuple) throws HyracksDataException {
    boolean firstElement = btreeTupleBuilder.getSize() == 0;
    boolean startNewList = firstElement;
    if (!firstElement) {
        // If the current and the last token don't match, we start a new list.
        startNewList = !TupleUtils.equalTuples(tuple, lastTuple, numTokenFields);
    }
    if (startNewList) {
        if (!firstElement) {
            // Create entry in btree for last inverted list.
            insertBTreeTuple();
        }
        startNewList(tuple);
        copyTokenToBTreeTuple(tuple);
    } else {
        if (invListCmp.compare(tuple, lastTuple, numTokenFields) == 0) {
            // Duplicate inverted-list element.
            return;
        }
    }
    appendInvertedList(tuple, numTokenFields);
    if (verifyInput) {
        verifyTuple(tuple);
    }
    saveLastTuple(tuple);
}
#end_block

#method_before
@Override
public void writeFailed(Exception e) {
    if (failureCallback != null) {
        failureCallback.writeFailed(this, e);
    }
}
#method_after
@Override
public void writeFailed(Exception e) {
    if (failureCallback != null) {
        failureCallback.writeFailed(this, e);
    } else {
        LOGGER.error("An IO Failure took place but the failure callback is not set", e);
    }
}
#end_block

#method_before
@Override
public void write(ICachedPage page, BufferCache bufferCache) {
    CachedPage cPage = (CachedPage) page;
    try {
        bufferCache.write(cPage);
    } catch (Exception e) {
        page.writeFailed(e);
        LOGGER.warn("Failed to write page {}", cPage, e);
    } catch (Throwable th) {
        // Halt
        LOGGER.error("FIFOLocalWriter has encountered a fatal error", th);
        ExitUtil.halt(ExitUtil.EC_ABNORMAL_TERMINATION);
    } finally {
        bufferCache.returnPage(cPage);
        if (DEBUG) {
            LOGGER.error("[FIFO] Return page: {}, {}", cPage.cpid, cPage.dpid);
        }
    }
}
#method_after
// System must halt on all IO errors
@SuppressWarnings("squid:S1181")
@Override
public void write(ICachedPage page, BufferCache bufferCache) {
    CachedPage cPage = (CachedPage) page;
    try {
        bufferCache.write(cPage);
    } catch (Exception e) {
        page.writeFailed(e);
        LOGGER.warn("Failed to write page {}", cPage, e);
    } catch (Throwable th) {
        // Halt
        LOGGER.error("FIFOLocalWriter has encountered a fatal error", th);
        ExitUtil.halt(ExitUtil.EC_ABNORMAL_TERMINATION);
    } finally {
        bufferCache.returnPage(cPage);
        if (DEBUG) {
            LOGGER.error("[FIFO] Return page: {}, {}", cPage.cpid, cPage.dpid);
        }
    }
}
#end_block

#method_before
@Override
public void add(ITupleReference tuple) throws HyracksDataException {
    if (failure != null) {
        throw HyracksDataException.create(failure);
    }
    try {
        int tupleSize = Math.max(leafFrame.getBytesRequiredToWriteTuple(tuple), interiorFrame.getBytesRequiredToWriteTuple(tuple));
        NodeFrontier leafFrontier = nodeFrontiers.get(0);
        int spaceNeeded = tupleWriter.bytesRequired(tuple) + slotSize;
        int spaceUsed = leafFrame.getBuffer().capacity() - leafFrame.getTotalFreeSpace();
        // try to free space by compression
        if (spaceUsed + spaceNeeded > leafMaxBytes) {
            leafFrame.compress();
            spaceUsed = leafFrame.getBuffer().capacity() - leafFrame.getTotalFreeSpace();
        }
        // full, allocate new page
        if (spaceUsed + spaceNeeded > leafMaxBytes) {
            if (leafFrame.getTupleCount() == 0) {
                bufferCache.returnPage(leafFrontier.page, false);
            } else {
                leafFrontier.lastTuple.resetByTupleIndex(leafFrame, leafFrame.getTupleCount() - 1);
                if (verifyInput) {
                    verifyInputTuple(tuple, leafFrontier.lastTuple);
                }
                int splitKeySize = tupleWriter.bytesRequired(leafFrontier.lastTuple, 0, cmp.getKeyFieldCount());
                splitKey.initData(splitKeySize);
                tupleWriter.writeTupleFields(leafFrontier.lastTuple, 0, cmp.getKeyFieldCount(), splitKey.getBuffer().array(), 0);
                splitKey.getTuple().resetByTupleOffset(splitKey.getBuffer().array(), 0);
                splitKey.setLeftPage(leafFrontier.pageId);
                propagateBulk(1, pagesToWrite);
                leafFrontier.pageId = freePageManager.takePage(metaFrame);
                ((IBTreeLeafFrame) leafFrame).setNextLeaf(leafFrontier.pageId);
                queue.put(leafFrontier.page, this);
                for (ICachedPage c : pagesToWrite) {
                    queue.put(c, this);
                }
                pagesToWrite.clear();
                splitKey.setRightPage(leafFrontier.pageId);
            }
            if (tupleSize > maxTupleSize) {
                final long dpid = BufferedFileHandle.getDiskPageId(getFileId(), leafFrontier.pageId);
                // calculate required number of pages.
                int headerSize = Math.max(leafFrame.getPageHeaderSize(), interiorFrame.getPageHeaderSize());
                final int multiplier = (int) Math.ceil((double) tupleSize / (bufferCache.getPageSize() - headerSize));
                if (multiplier > 1) {
                    leafFrontier.page = bufferCache.confiscateLargePage(dpid, multiplier, freePageManager.takeBlock(metaFrame, multiplier - 1));
                } else {
                    leafFrontier.page = bufferCache.confiscatePage(dpid);
                }
                leafFrame.setPage(leafFrontier.page);
                leafFrame.initBuffer((byte) 0);
                ((IBTreeLeafFrame) leafFrame).setLargeFlag(true);
            } else {
                final long dpid = BufferedFileHandle.getDiskPageId(getFileId(), leafFrontier.pageId);
                leafFrontier.page = bufferCache.confiscatePage(dpid);
                leafFrame.setPage(leafFrontier.page);
                leafFrame.initBuffer((byte) 0);
            }
        } else {
            if (verifyInput && leafFrame.getTupleCount() > 0) {
                leafFrontier.lastTuple.resetByTupleIndex(leafFrame, leafFrame.getTupleCount() - 1);
                verifyInputTuple(tuple, leafFrontier.lastTuple);
            }
        }
        ((IBTreeLeafFrame) leafFrame).insertSorted(tuple);
    } catch (HyracksDataException | RuntimeException e) {
        handleException();
        throw e;
    }
}
#method_after
@Override
public void add(ITupleReference tuple) throws HyracksDataException {
    try {
        int tupleSize = Math.max(leafFrame.getBytesRequiredToWriteTuple(tuple), interiorFrame.getBytesRequiredToWriteTuple(tuple));
        NodeFrontier leafFrontier = nodeFrontiers.get(0);
        int spaceNeeded = tupleWriter.bytesRequired(tuple) + slotSize;
        int spaceUsed = leafFrame.getBuffer().capacity() - leafFrame.getTotalFreeSpace();
        // try to free space by compression
        if (spaceUsed + spaceNeeded > leafMaxBytes) {
            leafFrame.compress();
            spaceUsed = leafFrame.getBuffer().capacity() - leafFrame.getTotalFreeSpace();
        }
        // full, allocate new page
        if (spaceUsed + spaceNeeded > leafMaxBytes) {
            if (leafFrame.getTupleCount() == 0) {
                bufferCache.returnPage(leafFrontier.page, false);
            } else {
                leafFrontier.lastTuple.resetByTupleIndex(leafFrame, leafFrame.getTupleCount() - 1);
                if (verifyInput) {
                    verifyInputTuple(tuple, leafFrontier.lastTuple);
                }
                int splitKeySize = tupleWriter.bytesRequired(leafFrontier.lastTuple, 0, cmp.getKeyFieldCount());
                splitKey.initData(splitKeySize);
                tupleWriter.writeTupleFields(leafFrontier.lastTuple, 0, cmp.getKeyFieldCount(), splitKey.getBuffer().array(), 0);
                splitKey.getTuple().resetByTupleOffset(splitKey.getBuffer().array(), 0);
                splitKey.setLeftPage(leafFrontier.pageId);
                propagateBulk(1, pagesToWrite);
                leafFrontier.pageId = freePageManager.takePage(metaFrame);
                ((IBTreeLeafFrame) leafFrame).setNextLeaf(leafFrontier.pageId);
                queue.put(leafFrontier.page, this);
                for (ICachedPage c : pagesToWrite) {
                    queue.put(c, this);
                }
                pagesToWrite.clear();
                splitKey.setRightPage(leafFrontier.pageId);
            }
            if (tupleSize > maxTupleSize) {
                final long dpid = BufferedFileHandle.getDiskPageId(getFileId(), leafFrontier.pageId);
                // calculate required number of pages.
                int headerSize = Math.max(leafFrame.getPageHeaderSize(), interiorFrame.getPageHeaderSize());
                final int multiplier = (int) Math.ceil((double) tupleSize / (bufferCache.getPageSize() - headerSize));
                if (multiplier > 1) {
                    leafFrontier.page = bufferCache.confiscateLargePage(dpid, multiplier, freePageManager.takeBlock(metaFrame, multiplier - 1));
                } else {
                    leafFrontier.page = bufferCache.confiscatePage(dpid);
                }
                leafFrame.setPage(leafFrontier.page);
                leafFrame.initBuffer((byte) 0);
                ((IBTreeLeafFrame) leafFrame).setLargeFlag(true);
            } else {
                final long dpid = BufferedFileHandle.getDiskPageId(getFileId(), leafFrontier.pageId);
                leafFrontier.page = bufferCache.confiscatePage(dpid);
                leafFrame.setPage(leafFrontier.page);
                leafFrame.initBuffer((byte) 0);
            }
        } else {
            if (verifyInput && leafFrame.getTupleCount() > 0) {
                leafFrontier.lastTuple.resetByTupleIndex(leafFrame, leafFrame.getTupleCount() - 1);
                verifyInputTuple(tuple, leafFrontier.lastTuple);
            }
        }
        ((IBTreeLeafFrame) leafFrame).insertSorted(tuple);
    } catch (HyracksDataException | RuntimeException e) {
        handleException();
        throw e;
    }
}
#end_block

#method_before
@Override
public void end() throws HyracksDataException {
    try {
        ioOpCallback.afterOperation(loadOp);
        componentBulkLoader.end();
        if (componentBulkLoader.hasFailed()) {
            loadOp.setFailure(componentBulkLoader.getFailure());
        }
        if (component.getComponentSize() > 0) {
            if (isTransaction) {
                // deactivate. it could later be added or deleted
                try {
                    if (!loadOp.hasFailed()) {
                        component.markAsValid(durable, loadOp);
                    }
                } finally {
                    ioOpCallback.afterFinalize(loadOp);
                }
                component.deactivate();
            } else {
                ioOpCallback.afterFinalize(loadOp);
                getHarness().addBulkLoadedComponent(loadOp);
            }
        }
    } finally {
        ioOpCallback.completed(loadOp);
    }
}
#method_after
@Override
public void end() throws HyracksDataException {
    try {
        ioOpCallback.afterOperation(loadOp);
        componentBulkLoader.end();
        if (component.getComponentSize() > 0) {
            if (isTransaction) {
                // deactivate. it could later be added or deleted
                try {
                    component.markAsValid(durable, loadOp);
                } finally {
                    ioOpCallback.afterFinalize(loadOp);
                }
                component.deactivate();
            } else {
                ioOpCallback.afterFinalize(loadOp);
                getHarness().addBulkLoadedComponent(loadOp);
            }
        }
    } finally {
        ioOpCallback.completed(loadOp);
    }
}
#end_block

#method_before
@SuppressWarnings("squid:S2142")
@Override
public void put(ICachedPage page, IPageWriteFailureCallback callback) {
    page.setFailureCallback(callback);
    try {
        if (!poisoned.get()) {
            queue.put(page);
        } else {
            LOGGER.error("An attempt to write a page found buffer cache closed");
            ExitUtil.halt(ExitUtil.EC_ABNORMAL_TERMINATION);
        }
    } catch (InterruptedException e) {
        LOGGER.error("IO Operation interrupted", e);
        ExitUtil.halt(ExitUtil.EC_ABNORMAL_TERMINATION);
    }
}
#method_after
@SuppressWarnings("squid:S2142")
@Override
public void put(ICachedPage page, IPageWriteFailureCallback callback) throws HyracksDataException {
    failIfPreviousPageFailed(callback);
    page.setFailureCallback(callback);
    try {
        if (!poisoned.get()) {
            queue.put(page);
        } else {
            LOGGER.error("An attempt to write a page found buffer cache closed");
            ExitUtil.halt(ExitUtil.EC_ABNORMAL_TERMINATION);
        }
    } catch (InterruptedException e) {
        LOGGER.error("IO Operation interrupted", e);
        ExitUtil.halt(ExitUtil.EC_ABNORMAL_TERMINATION);
    }
}
#end_block

#method_before
@Override
public void end() throws HyracksDataException {
    bufferCache.finishQueue();
    freePageManager.setRootPageId(rootPage);
}
#method_after
@Override
public void end() throws HyracksDataException {
    bufferCache.finishQueue();
    if (hasFailed()) {
        throw HyracksDataException.create(getFailure());
    }
    freePageManager.setRootPageId(rootPage);
}
#end_block

#method_before
@Override
public void end() throws HyracksDataException {
    try {
        ioOpCallback.afterOperation(loadOp);
        componentBulkLoader.end();
        if (componentBulkLoader.hasFailed()) {
            loadOp.setFailure(componentBulkLoader.getFailure());
        }
        if (component.getComponentSize() > 0) {
            if (isTransaction) {
                // deactivate. it could later be added or deleted
                try {
                    if (!loadOp.hasFailed()) {
                        component.markAsValid(durable, loadOp);
                    }
                } finally {
                    ioOpCallback.afterFinalize(loadOp);
                }
                component.deactivate();
            } else {
                ioOpCallback.afterFinalize(loadOp);
                getHarness().addBulkLoadedComponent(loadOp);
            }
        }
    } finally {
        ioOpCallback.completed(loadOp);
    }
}
#method_after
@Override
public void end() throws HyracksDataException {
    try {
        ioOpCallback.afterOperation(loadOp);
        componentBulkLoader.end();
        if (component.getComponentSize() > 0) {
            if (isTransaction) {
                // deactivate. it could later be added or deleted
                try {
                    component.markAsValid(durable, loadOp);
                } finally {
                    ioOpCallback.afterFinalize(loadOp);
                }
                component.deactivate();
            } else {
                ioOpCallback.afterFinalize(loadOp);
                getHarness().addBulkLoadedComponent(loadOp);
            }
        }
    } finally {
        ioOpCallback.completed(loadOp);
    }
}
#end_block

#method_before
@Override
public void add(ITupleReference tuple) throws HyracksDataException {
    if (failure != null) {
        throw HyracksDataException.create(failure);
    }
    if (numPages == 0) {
        throw HyracksDataException.create(ErrorCode.CANNOT_ADD_TUPLES_TO_DUMMY_BLOOM_FILTER);
    }
    actualNumElements++;
    MurmurHash128Bit.hash3_x64_128(tuple, keyFields, SEED, hashes);
    long hash = Math.abs(hashes[0] % numBits);
    long groupId = hash / NUM_BITS_PER_BLOCK;
    int pageId = (int) (groupId / numBlocksPerPage);
    long groupStartIndex = (groupId % numBlocksPerPage) * NUM_BITS_PER_BLOCK;
    ICachedPage page = pages[pageId];
    ByteBuffer buffer = page.getBuffer();
    for (int i = 1; i < numHashes; ++i) {
        hash = Math.abs((hashes[0] + i * hashes[1]) % NUM_BITS_PER_BLOCK);
        // divide 8
        int byteIndex = (int) ((hash + groupStartIndex) >> 3);
        byte b = buffer.get(byteIndex);
        // mod 8
        int bitIndex = (int) (hash & 0x07);
        b = (byte) (b | (1 << bitIndex));
        buffer.put(byteIndex, b);
    }
}
#method_after
@Override
public void add(ITupleReference tuple) throws HyracksDataException {
    if (numPages == 0) {
        throw HyracksDataException.create(ErrorCode.CANNOT_ADD_TUPLES_TO_DUMMY_BLOOM_FILTER);
    }
    actualNumElements++;
    MurmurHash128Bit.hash3_x64_128(tuple, keyFields, SEED, hashes);
    long hash = Math.abs(hashes[0] % numBits);
    long groupId = hash / NUM_BITS_PER_BLOCK;
    int pageId = (int) (groupId / numBlocksPerPage);
    long groupStartIndex = (groupId % numBlocksPerPage) * NUM_BITS_PER_BLOCK;
    ICachedPage page = pages[pageId];
    ByteBuffer buffer = page.getBuffer();
    for (int i = 1; i < numHashes; ++i) {
        hash = Math.abs((hashes[0] + i * hashes[1]) % NUM_BITS_PER_BLOCK);
        // divide 8
        int byteIndex = (int) ((hash + groupStartIndex) >> 3);
        byte b = buffer.get(byteIndex);
        // mod 8
        int bitIndex = (int) (hash & 0x07);
        b = (byte) (b | (1 << bitIndex));
        buffer.put(byteIndex, b);
    }
}
#end_block

#method_before
@Override
public void end() throws HyracksDataException {
    allocateAndInitMetaDataPage();
    queue.put(metaDataPage, this);
    for (ICachedPage p : pages) {
        queue.put(p, this);
    }
    bufferCache.finishQueue();
    BloomFilter.this.numBits = numBits;
    BloomFilter.this.numHashes = numHashes;
    BloomFilter.this.numElements = actualNumElements;
    BloomFilter.this.numPages = numPages;
    BloomFilter.this.version = BLOCKED_BLOOM_FILTER_VERSION;
}
#method_after
@Override
public void end() throws HyracksDataException {
    allocateAndInitMetaDataPage();
    queue.put(metaDataPage, this);
    for (ICachedPage p : pages) {
        queue.put(p, this);
    }
    bufferCache.finishQueue();
    if (hasFailed()) {
        throw HyracksDataException.create(getFailure());
    }
    BloomFilter.this.numBits = numBits;
    BloomFilter.this.numHashes = numHashes;
    BloomFilter.this.numElements = actualNumElements;
    BloomFilter.this.numPages = numPages;
    BloomFilter.this.version = BLOCKED_BLOOM_FILTER_VERSION;
}
#end_block

#method_before
public static void markAsValid(ITreeIndex treeIndex, boolean forceToDisk, IPageWriteFailureCallback callback) throws HyracksDataException {
    int fileId = treeIndex.getFileId();
    IBufferCache bufferCache = treeIndex.getBufferCache();
    treeIndex.getPageManager().close(callback);
    // If the index is not durable, then the flush is not necessary.
    if (forceToDisk) {
        bufferCache.force(fileId, true);
    }
}
#method_after
public static void markAsValid(ITreeIndex treeIndex, boolean forceToDisk, IPageWriteFailureCallback callback) throws HyracksDataException {
    int fileId = treeIndex.getFileId();
    IBufferCache bufferCache = treeIndex.getBufferCache();
    treeIndex.getPageManager().close(callback);
    if (callback.hasFailed()) {
        throw HyracksDataException.create(callback.getFailure());
    }
    // If the index is not durable, then the flush is not necessary.
    if (forceToDisk) {
        bufferCache.force(fileId, true);
    }
}
#end_block

#method_before
@Override
public String toString() {
    return getClass().getSimpleName() + ":" + task.getJoblet().getJobId() + ":" + task.getTaskAttemptId();
}
#method_after
@Override
public String toString() {
    return getName() + ": [" + ncs.getId() + "[" + task.getJoblet().getJobId() + ":" + task.getTaskAttemptId() + "]";
}
#end_block

#method_before
@Override
public void prepareComplete(JobRun run, JobStatus status, List<Exception> exceptions) throws HyracksException {
    ccs.removeJobParameterByteStore(run.getJobId());
    checkJob(run);
    if (status == JobStatus.FAILURE_BEFORE_EXECUTION) {
        run.setPendingStatus(JobStatus.FAILURE, exceptions);
        finalComplete(run);
        return;
    }
    if (run.getPendingStatus() != null && run.getCleanupPendingNodeIds().isEmpty()) {
        finalComplete(run);
        return;
    }
    if (run.getPendingStatus() != null) {
        LOGGER.warn("Ignoring duplicate cleanup for JobRun with id: {}", run::getJobId);
        return;
    }
    Set<String> targetNodes = run.getParticipatingNodeIds();
    run.getCleanupPendingNodeIds().addAll(targetNodes);
    if (run.getPendingStatus() != JobStatus.FAILURE && run.getPendingStatus() != JobStatus.TERMINATED) {
        run.setPendingStatus(status, exceptions);
    }
    if (!targetNodes.isEmpty()) {
        cleanupJobOnNodes(run, status, targetNodes);
    } else {
        finalComplete(run);
    }
}
#method_after
@Override
public void prepareComplete(JobRun run, JobStatus status, List<Exception> exceptions) throws HyracksException {
    checkJob(run);
    ccs.removeJobParameterByteStore(run.getJobId());
    if (status == JobStatus.FAILURE_BEFORE_EXECUTION) {
        run.setPendingStatus(JobStatus.FAILURE, exceptions);
        finalComplete(run);
        return;
    }
    if (run.getPendingStatus() != null && run.getCleanupPendingNodeIds().isEmpty()) {
        finalComplete(run);
        return;
    }
    if (run.getPendingStatus() != null) {
        LOGGER.warn("Ignoring duplicate cleanup for JobRun with id: {}", run::getJobId);
        return;
    }
    Set<String> targetNodes = run.getParticipatingNodeIds();
    run.getCleanupPendingNodeIds().addAll(targetNodes);
    if (run.getPendingStatus() != JobStatus.FAILURE && run.getPendingStatus() != JobStatus.TERMINATED) {
        run.setPendingStatus(status, exceptions);
    }
    if (!targetNodes.isEmpty()) {
        cleanupJobOnNodes(run, status, targetNodes);
    } else {
        finalComplete(run);
    }
}
#end_block

#method_before
@Override
public void finalComplete(JobRun run) throws HyracksException {
    checkJob(run);
    JobId jobId = run.getJobId();
    Throwable caughtException = null;
    CCServiceContext serviceCtx = ccs.getContext();
    try {
        serviceCtx.notifyJobFinish(jobId, run.getPendingStatus(), run.getPendingExceptions());
    } catch (Exception e) {
        LOGGER.error("Exception notifying job finish {}", jobId, e);
        caughtException = e;
    }
    run.setStatus(run.getPendingStatus(), run.getPendingExceptions());
    run.setEndTime(System.currentTimeMillis());
    if (activeRunMap.remove(jobId) == null) {
        LOGGER.warn("Job {} was not found inf activeRunMap but is being put into archive and released from capacity controller", jobId);
    }
    runMapArchive.put(jobId, run);
    runMapHistory.put(jobId, run.getExceptions());
    if (run.getActivityClusterGraph().isReportTaskDetails()) {
        /*
             * log job details when profiling is enabled
             */
        try {
            ccs.getJobLogFile().log(createJobLogObject(run));
        } catch (Exception e) {
            LOGGER.error("Exception reporting task details for job {}", jobId, e);
            caughtException = ExceptionUtils.suppress(caughtException, e);
        }
    }
    // Releases cluster capacitys occupied by the job.
    JobSpecification job = run.getJobSpecification();
    jobCapacityController.release(job);
    // Picks the next job to execute.
    pickJobsToRun();
    // throws caught exceptions if any
    if (caughtException != null) {
        throw HyracksException.wrapOrThrowUnchecked(caughtException);
    }
}
#method_after
@Override
public void finalComplete(JobRun run) throws HyracksException {
    checkJob(run);
    JobId jobId = run.getJobId();
    Throwable caughtException = null;
    CCServiceContext serviceCtx = ccs.getContext();
    try {
        serviceCtx.notifyJobFinish(jobId, run.getPendingStatus(), run.getPendingExceptions());
    } catch (Exception e) {
        LOGGER.error("Exception notifying job finish {}", jobId, e);
        caughtException = e;
    }
    run.setStatus(run.getPendingStatus(), run.getPendingExceptions());
    run.setEndTime(System.currentTimeMillis());
    if (activeRunMap.remove(jobId) == null) {
        LOGGER.warn("Job {} was not found running but is getting archived and capacity released", jobId);
    }
    runMapArchive.put(jobId, run);
    runMapHistory.put(jobId, run.getExceptions());
    if (run.getActivityClusterGraph().isReportTaskDetails()) {
        /*
             * log job details when profiling is enabled
             */
        try {
            ccs.getJobLogFile().log(createJobLogObject(run));
        } catch (Exception e) {
            LOGGER.error("Exception reporting task details for job {}", jobId, e);
            caughtException = ExceptionUtils.suppress(caughtException, e);
        }
    }
    // Releases cluster capacitys occupied by the job.
    JobSpecification job = run.getJobSpecification();
    jobCapacityController.release(job);
    // Picks the next job to execute.
    pickJobsToRun();
    // throws caught exceptions if any
    if (caughtException != null) {
        throw HyracksException.wrapOrThrowUnchecked(caughtException);
    }
}
#end_block

#method_before
@Override
public String toString() {
    return getName() + ":" + jobId + ":" + taskId.getTaskId();
}
#method_after
@Override
public String toString() {
    return getName() + ": [" + ncs.getId() + "[" + jobId + ":" + taskId + "]";
}
#end_block

#method_before
@Override
public synchronized IndexCheckpoint getLatest() throws HyracksDataException {
    List<IndexCheckpoint> checkpoints;
    try {
        checkpoints = getCheckpoints();
    } catch (ClosedByInterruptException e) {
        throw HyracksDataException.create(e);
    }
    if (checkpoints.isEmpty()) {
        throw new IllegalStateException("Couldn't find any checkpoints for resource: " + indexPath);
    }
    checkpoints.sort(Comparator.comparingLong(IndexCheckpoint::getId).reversed());
    return checkpoints.get(0);
}
#method_after
@Override
public synchronized IndexCheckpoint getLatest() throws HyracksDataException {
    List<IndexCheckpoint> checkpoints;
    try {
        checkpoints = getCheckpoints();
    } catch (ClosedByInterruptException e) {
        throw HyracksDataException.create(e);
    }
    if (checkpoints.isEmpty()) {
        LOGGER.warn("Couldn't find any checkpoint file for index {}. Content of dir are {}.", indexPath, Arrays.toString(indexPath.toFile().listFiles()));
        throw new IllegalStateException("Couldn't find any checkpoints for resource: " + indexPath);
    }
    checkpoints.sort(Comparator.comparingLong(IndexCheckpoint::getId).reversed());
    return checkpoints.get(0);
}
#end_block

#method_before
private List<IndexCheckpoint> getCheckpoints() throws ClosedByInterruptException {
    List<IndexCheckpoint> checkpoints = new ArrayList<>();
    final File[] checkpointFiles = indexPath.toFile().listFiles(CHECKPOINT_FILE_FILTER);
    if (checkpointFiles != null) {
        for (File checkpointFile : checkpointFiles) {
            try {
                checkpoints.add(read(checkpointFile.toPath()));
            } catch (ClosedByInterruptException e) {
                throw e;
            } catch (IOException e) {
                LOGGER.warn(() -> "Couldn't read index checkpoint file: " + checkpointFile, e);
            }
        }
    }
    if (checkpoints.isEmpty()) {
        LOGGER.warn("Couldn't find any checkpoint file for index {}. Content of dir are {}.", indexPath, Arrays.toString(indexPath.toFile().listFiles()));
    }
    return checkpoints;
}
#method_after
private List<IndexCheckpoint> getCheckpoints() throws ClosedByInterruptException {
    List<IndexCheckpoint> checkpoints = new ArrayList<>();
    final File[] checkpointFiles = indexPath.toFile().listFiles(CHECKPOINT_FILE_FILTER);
    if (checkpointFiles != null) {
        for (File checkpointFile : checkpointFiles) {
            try {
                checkpoints.add(read(checkpointFile.toPath()));
            } catch (ClosedByInterruptException e) {
                throw e;
            } catch (IOException e) {
                LOGGER.warn(() -> "Couldn't read index checkpoint file: " + checkpointFile, e);
            }
        }
    }
    return checkpoints;
}
#end_block

#method_before
public IScalarEvaluatorFactory createEvaluatorFactory(final IScalarEvaluatorFactory[] args) {
    return new IScalarEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IScalarEvaluator createScalarEvaluator(final IHyracksTaskContext ctx) throws HyracksDataException {
            final IScalarEvaluator inputEval = args[0].createScalarEvaluator(ctx);
            final IPointable inputArg = new VoidPointable();
            final ArrayBackedValueStorage resultStorage = new ArrayBackedValueStorage();
            final DataOutput out = resultStorage.getDataOutput();
            final AMutableInt32 aInt32 = new AMutableInt32(0);
            @SuppressWarnings("unchecked")
            final ISerializerDeserializer<AInt32> int32Ser = SerializerDeserializerProvider.INSTANCE.getSerializerDeserializer(BuiltinType.AINT32);
            return new IScalarEvaluator() {

                @Override
                public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException {
                    inputEval.evaluate(tuple, inputArg);
                    int intValue;
                    byte[] bytes = inputArg.getByteArray();
                    int startOffset = inputArg.getStartOffset();
                    ATypeTag tt = ATypeTag.VALUE_TYPE_MAPPING[bytes[startOffset]];
                    switch(tt) {
                        case TINYINT:
                        case SMALLINT:
                        case INTEGER:
                        case BIGINT:
                            intValue = ATypeHierarchy.getIntegerValue(getIdentifier().getName(), 0, bytes, startOffset, true);
                            break;
                        case FLOAT:
                        case DOUBLE:
                            double doubleValue = ATypeHierarchy.getDoubleValue(getIdentifier().getName(), 0, bytes, startOffset);
                            intValue = asInt(doubleValue);
                            break;
                        default:
                            throw new TypeMismatchException(sourceLoc, bytes[startOffset], ATypeTag.SERIALIZED_INT8_TYPE_TAG, ATypeTag.SERIALIZED_INT16_TYPE_TAG, ATypeTag.SERIALIZED_INT32_TYPE_TAG, ATypeTag.SERIALIZED_INT64_TYPE_TAG, ATypeTag.SERIALIZED_FLOAT_TYPE_TAG, ATypeTag.SERIALIZED_DOUBLE_TYPE_TAG);
                    }
                    resultStorage.reset();
                    aInt32.setValue(intValue);
                    int32Ser.serialize(aInt32, out);
                    result.set(resultStorage);
                }

                private int asInt(double d) throws HyracksDataException {
                    if (Double.isFinite(d)) {
                        long v = (long) d;
                        if (v == d && Integer.MIN_VALUE <= v && v <= Integer.MAX_VALUE) {
                            return (int) v;
                        }
                    }
                    throw new RuntimeDataException(ErrorCode.INTEGER_VALUE_EXPECTED, sourceLoc, d);
                }
            };
        }
    };
}
#method_after
@Override
public IScalarEvaluatorFactory createEvaluatorFactory(final IScalarEvaluatorFactory[] args) {
    return new IScalarEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IScalarEvaluator createScalarEvaluator(final IHyracksTaskContext ctx) throws HyracksDataException {
            final IScalarEvaluator inputEval = args[0].createScalarEvaluator(ctx);
            final IPointable inputArg = new VoidPointable();
            final ArrayBackedValueStorage resultStorage = new ArrayBackedValueStorage();
            final DataOutput out = resultStorage.getDataOutput();
            final AMutableInt32 aInt32 = new AMutableInt32(0);
            @SuppressWarnings("unchecked")
            final ISerializerDeserializer<AInt32> int32Ser = SerializerDeserializerProvider.INSTANCE.getSerializerDeserializer(BuiltinType.AINT32);
            return new IScalarEvaluator() {

                @Override
                public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException {
                    inputEval.evaluate(tuple, inputArg);
                    int intValue;
                    byte[] bytes = inputArg.getByteArray();
                    int startOffset = inputArg.getStartOffset();
                    ATypeTag tt = ATypeTag.VALUE_TYPE_MAPPING[bytes[startOffset]];
                    switch(tt) {
                        case TINYINT:
                        case SMALLINT:
                        case INTEGER:
                        case BIGINT:
                            intValue = ATypeHierarchy.getIntegerValue(getIdentifier().getName(), 0, bytes, startOffset, true);
                            break;
                        case FLOAT:
                        case DOUBLE:
                            double doubleValue = ATypeHierarchy.getDoubleValue(getIdentifier().getName(), 0, bytes, startOffset);
                            intValue = asInt(doubleValue);
                            break;
                        default:
                            throw new TypeMismatchException(sourceLoc, bytes[startOffset], ATypeTag.SERIALIZED_INT8_TYPE_TAG, ATypeTag.SERIALIZED_INT16_TYPE_TAG, ATypeTag.SERIALIZED_INT32_TYPE_TAG, ATypeTag.SERIALIZED_INT64_TYPE_TAG, ATypeTag.SERIALIZED_FLOAT_TYPE_TAG, ATypeTag.SERIALIZED_DOUBLE_TYPE_TAG);
                    }
                    resultStorage.reset();
                    aInt32.setValue(intValue);
                    int32Ser.serialize(aInt32, out);
                    result.set(resultStorage);
                }

                private int asInt(double d) throws HyracksDataException {
                    if (Double.isFinite(d)) {
                        long v = (long) d;
                        if (v == d && Integer.MIN_VALUE <= v && v <= Integer.MAX_VALUE) {
                            return (int) v;
                        }
                    }
                    throw new RuntimeDataException(ErrorCode.INTEGER_VALUE_EXPECTED, sourceLoc, d);
                }
            };
        }
    };
}
#end_block

#method_before
public static FunctionCollection createDefaultFunctionCollection() {
    FunctionCollection fc = new FunctionCollection();
    // array functions
    fc.add(ArrayRemoveDescriptor.FACTORY);
    fc.add(ArrayPutDescriptor.FACTORY);
    fc.add(ArrayPrependDescriptor.FACTORY);
    fc.add(ArrayAppendDescriptor.FACTORY);
    fc.add(ArrayInsertDescriptor.FACTORY);
    fc.addGenerated(ArrayPositionDescriptor.FACTORY);
    fc.addGenerated(ArrayRepeatDescriptor.FACTORY);
    fc.addGenerated(ArrayContainsDescriptor.FACTORY);
    fc.addGenerated(ArrayReverseDescriptor.FACTORY);
    fc.addGenerated(ArraySortDescriptor.FACTORY);
    fc.addGenerated(ArrayDistinctDescriptor.FACTORY);
    // unnesting functions
    fc.add(TidRunningAggregateDescriptor.FACTORY);
    fc.add(ScanCollectionDescriptor.FACTORY);
    fc.add(RangeDescriptor.FACTORY);
    fc.add(SubsetCollectionDescriptor.FACTORY);
    // aggregate functions
    fc.add(ListifyAggregateDescriptor.FACTORY);
    fc.add(CountAggregateDescriptor.FACTORY);
    fc.add(AvgAggregateDescriptor.FACTORY);
    fc.add(LocalAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SumAggregateDescriptor.FACTORY);
    fc.add(LocalSumAggregateDescriptor.FACTORY);
    fc.add(MaxAggregateDescriptor.FACTORY);
    fc.add(LocalMaxAggregateDescriptor.FACTORY);
    fc.add(MinAggregateDescriptor.FACTORY);
    fc.add(LocalMinAggregateDescriptor.FACTORY);
    fc.add(FirstElementAggregateDescriptor.FACTORY);
    fc.add(LocalFirstElementAggregateDescriptor.FACTORY);
    // serializable aggregates
    fc.add(SerializableCountAggregateDescriptor.FACTORY);
    fc.add(SerializableAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSumAggregateDescriptor.FACTORY);
    // scalar aggregates
    fc.add(ScalarCountAggregateDescriptor.FACTORY);
    fc.add(ScalarAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSumAggregateDescriptor.FACTORY);
    fc.add(ScalarMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarMinAggregateDescriptor.FACTORY);
    fc.add(EmptyStreamAggregateDescriptor.FACTORY);
    fc.add(NonEmptyStreamAggregateDescriptor.FACTORY);
    // SQL aggregates
    fc.add(SqlCountAggregateDescriptor.FACTORY);
    fc.add(SqlAvgAggregateDescriptor.FACTORY);
    fc.add(LocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SqlSumAggregateDescriptor.FACTORY);
    fc.add(LocalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SqlMaxAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMaxAggregateDescriptor.FACTORY);
    fc.add(SqlMinAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMinAggregateDescriptor.FACTORY);
    // SQL serializable aggregates
    fc.add(SerializableSqlCountAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlSumAggregateDescriptor.FACTORY);
    // SQL scalar aggregates
    fc.add(ScalarSqlCountAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlSumAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMinAggregateDescriptor.FACTORY);
    // boolean functions
    fc.add(AndDescriptor.FACTORY);
    fc.add(OrDescriptor.FACTORY);
    // Record constructors / functions
    fc.add(ClosedRecordConstructorDescriptor.FACTORY);
    fc.add(OpenRecordConstructorDescriptor.FACTORY);
    fc.add(RecordConcatDescriptor.FACTORY);
    fc.add(RecordConcatStrictDescriptor.FACTORY);
    // List constructors
    fc.add(OrderedListConstructorDescriptor.FACTORY);
    fc.add(UnorderedListConstructorDescriptor.FACTORY);
    // Sleep function
    fc.add(SleepDescriptor.FACTORY);
    // Inject failure function
    fc.add(InjectFailureDescriptor.FACTORY);
    // Get Job Parameter function
    fc.add(GetJobParameterByNameDescriptor.FACTORY);
    // Switch case
    fc.add(SwitchCaseDescriptor.FACTORY);
    // null functions
    fc.add(IsMissingDescriptor.FACTORY);
    fc.add(IsNullDescriptor.FACTORY);
    fc.add(IsUnknownDescriptor.FACTORY);
    fc.add(IsSystemNullDescriptor.FACTORY);
    fc.add(CheckUnknownDescriptor.FACTORY);
    fc.add(IfMissingDescriptor.FACTORY);
    fc.add(IfNullDescriptor.FACTORY);
    fc.add(IfMissingOrNullDescriptor.FACTORY);
    // uuid generators (zero independent functions)
    fc.add(CreateUUIDDescriptor.FACTORY);
    fc.add(UUIDDescriptor.FACTORY);
    fc.add(CreateQueryUIDDescriptor.FACTORY);
    fc.add(RandomDescriptor.FACTORY);
    fc.add(CurrentDateDescriptor.FACTORY);
    fc.add(CurrentTimeDescriptor.FACTORY);
    fc.add(CurrentDateTimeDescriptor.FACTORY);
    // functions that need generated class for null-handling.
    // Element accessors.
    fc.addGenerated(FieldAccessByIndexDescriptor.FACTORY);
    fc.addGenerated(FieldAccessByNameDescriptor.FACTORY);
    fc.addGenerated(FieldAccessNestedDescriptor.FACTORY);
    fc.addGenerated(AnyCollectionMemberDescriptor.FACTORY);
    fc.addGenerated(GetItemDescriptor.FACTORY);
    // Numeric functions
    fc.add(IfInfDescriptor.FACTORY);
    fc.add(IfNanDescriptor.FACTORY);
    fc.add(IfNanOrInfDescriptor.FACTORY);
    fc.addGenerated(NumericUnaryMinusDescriptor.FACTORY);
    fc.addGenerated(NumericAddDescriptor.FACTORY);
    fc.addGenerated(NumericDivideDescriptor.FACTORY);
    fc.addGenerated(NumericDivDescriptor.FACTORY);
    fc.addGenerated(NumericMultiplyDescriptor.FACTORY);
    fc.addGenerated(NumericSubDescriptor.FACTORY);
    fc.addGenerated(NumericModuloDescriptor.FACTORY);
    fc.addGenerated(NumericPowerDescriptor.FACTORY);
    fc.addGenerated(NotDescriptor.FACTORY);
    fc.addGenerated(LenDescriptor.FACTORY);
    fc.addGenerated(NumericAbsDescriptor.FACTORY);
    fc.addGenerated(NumericCeilingDescriptor.FACTORY);
    fc.addGenerated(NumericFloorDescriptor.FACTORY);
    fc.addGenerated(NumericRoundDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEvenDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEven2Descriptor.FACTORY);
    fc.addGenerated(NumericACosDescriptor.FACTORY);
    fc.addGenerated(NumericASinDescriptor.FACTORY);
    fc.addGenerated(NumericATanDescriptor.FACTORY);
    fc.addGenerated(NumericDegreesDescriptor.FACTORY);
    fc.addGenerated(NumericRadiansDescriptor.FACTORY);
    fc.addGenerated(NumericCosDescriptor.FACTORY);
    fc.addGenerated(NumericSinDescriptor.FACTORY);
    fc.addGenerated(NumericTanDescriptor.FACTORY);
    fc.addGenerated(NumericExpDescriptor.FACTORY);
    fc.addGenerated(NumericLnDescriptor.FACTORY);
    fc.addGenerated(NumericLogDescriptor.FACTORY);
    fc.addGenerated(NumericSqrtDescriptor.FACTORY);
    fc.addGenerated(NumericSignDescriptor.FACTORY);
    fc.addGenerated(NumericTruncDescriptor.FACTORY);
    fc.addGenerated(NumericATan2Descriptor.FACTORY);
    // Comparisons.
    fc.addGenerated(EqualsDescriptor.FACTORY);
    fc.addGenerated(GreaterThanDescriptor.FACTORY);
    fc.addGenerated(GreaterThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(LessThanDescriptor.FACTORY);
    fc.addGenerated(LessThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(NotEqualsDescriptor.FACTORY);
    // If-Equals functions
    fc.addGenerated(MissingIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NullIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NanIfEqualsDescriptor.FACTORY);
    fc.addGenerated(PosInfIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NegInfIfEqualsDescriptor.FACTORY);
    // Binary functions
    fc.addGenerated(BinaryLengthDescriptor.FACTORY);
    fc.addGenerated(ParseBinaryDescriptor.FACTORY);
    fc.addGenerated(PrintBinaryDescriptor.FACTORY);
    fc.addGenerated(BinaryConcatDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromToDescriptor.FACTORY);
    fc.addGenerated(FindBinaryDescriptor.FACTORY);
    fc.addGenerated(FindBinaryFromDescriptor.FACTORY);
    // String functions
    fc.addGenerated(StringLikeDescriptor.FACTORY);
    fc.addGenerated(StringContainsDescriptor.FACTORY);
    fc.addGenerated(StringEndsWithDescriptor.FACTORY);
    fc.addGenerated(StringStartsWithDescriptor.FACTORY);
    fc.addGenerated(SubstringDescriptor.FACTORY);
    fc.addGenerated(StringEqualDescriptor.FACTORY);
    fc.addGenerated(StringLowerCaseDescriptor.FACTORY);
    fc.addGenerated(StringUpperCaseDescriptor.FACTORY);
    fc.addGenerated(StringLengthDescriptor.FACTORY);
    fc.addGenerated(Substring2Descriptor.FACTORY);
    fc.addGenerated(SubstringBeforeDescriptor.FACTORY);
    fc.addGenerated(SubstringAfterDescriptor.FACTORY);
    fc.addGenerated(StringToCodePointDescriptor.FACTORY);
    fc.addGenerated(CodePointToStringDescriptor.FACTORY);
    fc.addGenerated(StringConcatDescriptor.FACTORY);
    fc.addGenerated(StringJoinDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceWithFlagsDescriptor.FACTORY);
    fc.addGenerated(StringInitCapDescriptor.FACTORY);
    fc.addGenerated(StringTrimDescriptor.FACTORY);
    fc.addGenerated(StringLTrimDescriptor.FACTORY);
    fc.addGenerated(StringRTrimDescriptor.FACTORY);
    fc.addGenerated(StringTrim2Descriptor.FACTORY);
    fc.addGenerated(StringLTrim2Descriptor.FACTORY);
    fc.addGenerated(StringRTrim2Descriptor.FACTORY);
    fc.addGenerated(StringPositionDescriptor.FACTORY);
    fc.addGenerated(StringRepeatDescriptor.FACTORY);
    fc.addGenerated(StringReplaceDescriptor.FACTORY);
    fc.addGenerated(StringReplaceWithLimitDescriptor.FACTORY);
    fc.addGenerated(StringReverseDescriptor.FACTORY);
    fc.addGenerated(StringSplitDescriptor.FACTORY);
    // Constructors
    fc.addGenerated(ABooleanConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryHexStringConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryBase64StringConstructorDescriptor.FACTORY);
    fc.addGenerated(AStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt8ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt16ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt32ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt64ConstructorDescriptor.FACTORY);
    fc.addGenerated(AFloatConstructorDescriptor.FACTORY);
    fc.addGenerated(ADoubleConstructorDescriptor.FACTORY);
    fc.addGenerated(APointConstructorDescriptor.FACTORY);
    fc.addGenerated(APoint3DConstructorDescriptor.FACTORY);
    fc.addGenerated(ALineConstructorDescriptor.FACTORY);
    fc.addGenerated(APolygonConstructorDescriptor.FACTORY);
    fc.addGenerated(ACircleConstructorDescriptor.FACTORY);
    fc.addGenerated(ARectangleConstructorDescriptor.FACTORY);
    fc.addGenerated(ATimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AYearMonthDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(ADayTimeDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AUUIDFromStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromTimeConstructorDescriptor.FACTORY);
    // Spatial
    fc.addGenerated(CreatePointDescriptor.FACTORY);
    fc.addGenerated(CreateLineDescriptor.FACTORY);
    fc.addGenerated(CreatePolygonDescriptor.FACTORY);
    fc.addGenerated(CreateCircleDescriptor.FACTORY);
    fc.addGenerated(CreateRectangleDescriptor.FACTORY);
    fc.addGenerated(SpatialAreaDescriptor.FACTORY);
    fc.addGenerated(SpatialDistanceDescriptor.FACTORY);
    fc.addGenerated(CreateMBRDescriptor.FACTORY);
    fc.addGenerated(SpatialCellDescriptor.FACTORY);
    fc.addGenerated(PointXCoordinateAccessor.FACTORY);
    fc.addGenerated(PointYCoordinateAccessor.FACTORY);
    fc.addGenerated(CircleRadiusAccessor.FACTORY);
    fc.addGenerated(CircleCenterAccessor.FACTORY);
    fc.addGenerated(LineRectanglePolygonAccessor.FACTORY);
    // full-text function
    fc.addGenerated(FullTextContainsDescriptor.FACTORY);
    fc.addGenerated(FullTextContainsWithoutOptionDescriptor.FACTORY);
    // Record functions.
    fc.addGenerated(GetRecordFieldsDescriptor.FACTORY);
    fc.addGenerated(GetRecordFieldValueDescriptor.FACTORY);
    fc.addGenerated(DeepEqualityDescriptor.FACTORY);
    fc.addGenerated(RecordMergeDescriptor.FACTORY);
    fc.addGenerated(RecordAddFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordLengthDescriptor.FACTORY);
    fc.addGenerated(RecordNamesDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveDescriptor.FACTORY);
    fc.addGenerated(RecordRenameDescriptor.FACTORY);
    fc.addGenerated(RecordUnwrapDescriptor.FACTORY);
    fc.add(RecordReplaceDescriptor.FACTORY);
    fc.add(RecordAddDescriptor.FACTORY);
    fc.add(RecordPutDescriptor.FACTORY);
    fc.addGenerated(RecordValuesDescriptor.FACTORY);
    fc.addGenerated(PairsDescriptor.FACTORY);
    // Spatial and temporal type accessors
    fc.addGenerated(TemporalYearAccessor.FACTORY);
    fc.addGenerated(TemporalMonthAccessor.FACTORY);
    fc.addGenerated(TemporalDayAccessor.FACTORY);
    fc.addGenerated(TemporalHourAccessor.FACTORY);
    fc.addGenerated(TemporalMinuteAccessor.FACTORY);
    fc.addGenerated(TemporalSecondAccessor.FACTORY);
    fc.addGenerated(TemporalMillisecondAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDatetimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDatetimeAccessor.FACTORY);
    // Temporal functions
    fc.addGenerated(UnixTimeFromDateInDaysDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromTimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DateFromUnixTimeInDaysDescriptor.FACTORY);
    fc.addGenerated(DateFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(TimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(TimeFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromDateAndTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDurationFromDateTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDuartionFromDateDescriptor.FACTORY);
    fc.addGenerated(AdjustDateTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(AdjustTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(IntervalBeforeDescriptor.FACTORY);
    fc.addGenerated(IntervalAfterDescriptor.FACTORY);
    fc.addGenerated(IntervalMeetsDescriptor.FACTORY);
    fc.addGenerated(IntervalMetByDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlapsDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlappedByDescriptor.FACTORY);
    fc.addGenerated(OverlapDescriptor.FACTORY);
    fc.addGenerated(IntervalStartsDescriptor.FACTORY);
    fc.addGenerated(IntervalStartedByDescriptor.FACTORY);
    fc.addGenerated(IntervalCoversDescriptor.FACTORY);
    fc.addGenerated(IntervalCoveredByDescriptor.FACTORY);
    fc.addGenerated(IntervalEndsDescriptor.FACTORY);
    fc.addGenerated(IntervalEndedByDescriptor.FACTORY);
    fc.addGenerated(DurationFromMillisecondsDescriptor.FACTORY);
    fc.addGenerated(DurationFromMonthsDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(MonthsFromYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(MillisecondsFromDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(DurationEqualDescriptor.FACTORY);
    fc.addGenerated(GetYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(GetDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(IntervalBinDescriptor.FACTORY);
    fc.addGenerated(OverlapBinsDescriptor.FACTORY);
    fc.addGenerated(DayOfWeekDescriptor.FACTORY);
    fc.addGenerated(ParseDateDescriptor.FACTORY);
    fc.addGenerated(ParseTimeDescriptor.FACTORY);
    fc.addGenerated(ParseDateTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateDescriptor.FACTORY);
    fc.addGenerated(PrintTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateTimeDescriptor.FACTORY);
    fc.addGenerated(GetOverlappingIntervalDescriptor.FACTORY);
    fc.addGenerated(DurationFromIntervalDescriptor.FACTORY);
    // Type functions.
    fc.addGenerated(IsArrayDescriptor.FACTORY);
    fc.addGenerated(IsAtomicDescriptor.FACTORY);
    fc.addGenerated(IsBooleanDescriptor.FACTORY);
    fc.addGenerated(IsNumberDescriptor.FACTORY);
    fc.addGenerated(IsObjectDescriptor.FACTORY);
    fc.addGenerated(IsStringDescriptor.FACTORY);
    fc.addGenerated(ToArrayDescriptor.FACTORY);
    fc.addGenerated(ToAtomicDescriptor.FACTORY);
    fc.addGenerated(ToBigIntDescriptor.FACTORY);
    fc.addGenerated(ToBooleanDescriptor.FACTORY);
    fc.addGenerated(ToDoubleDescriptor.FACTORY);
    fc.addGenerated(ToNumberDescriptor.FACTORY);
    fc.addGenerated(ToObjectDescriptor.FACTORY);
    fc.addGenerated(ToStringDescriptor.FACTORY);
    fc.addGenerated(TreatAsIntegerDescriptor.FACTORY);
    // Cast function
    fc.addGenerated(CastTypeDescriptor.FACTORY);
    fc.addGenerated(CastTypeLaxDescriptor.FACTORY);
    // Record function
    fc.addGenerated(RecordPairsDescriptor.FACTORY);
    // Other functions
    fc.addGenerated(RandomWithSeedDescriptor.FACTORY);
    ServiceLoader.load(IFunctionRegistrant.class).iterator().forEachRemaining(c -> c.register(fc));
    return fc;
}
#method_after
public static FunctionCollection createDefaultFunctionCollection() {
    FunctionCollection fc = new FunctionCollection();
    // array functions
    fc.add(ArrayRemoveDescriptor.FACTORY);
    fc.add(ArrayPutDescriptor.FACTORY);
    fc.add(ArrayPrependDescriptor.FACTORY);
    fc.add(ArrayAppendDescriptor.FACTORY);
    fc.add(ArrayInsertDescriptor.FACTORY);
    fc.addGenerated(ArrayPositionDescriptor.FACTORY);
    fc.addGenerated(ArrayRepeatDescriptor.FACTORY);
    fc.addGenerated(ArrayContainsDescriptor.FACTORY);
    fc.addGenerated(ArrayReverseDescriptor.FACTORY);
    fc.addGenerated(ArraySortDescriptor.FACTORY);
    fc.addGenerated(ArrayDistinctDescriptor.FACTORY);
    fc.addGenerated(ArrayUnionDescriptor.FACTORY);
    fc.addGenerated(ArrayIntersectDescriptor.FACTORY);
    fc.addGenerated(ArrayIfNullDescriptor.FACTORY);
    fc.addGenerated(ArrayConcatDescriptor.FACTORY);
    fc.addGenerated(ArrayRangeDescriptor.FACTORY);
    fc.addGenerated(ArrayFlattenDescriptor.FACTORY);
    fc.add(ArrayReplaceDescriptor.FACTORY);
    fc.addGenerated(ArraySymDiffDescriptor.FACTORY);
    fc.addGenerated(ArraySymDiffnDescriptor.FACTORY);
    fc.addGenerated(ArrayStarDescriptor.FACTORY);
    // unnesting functions
    fc.add(TidRunningAggregateDescriptor.FACTORY);
    fc.add(ScanCollectionDescriptor.FACTORY);
    fc.add(RangeDescriptor.FACTORY);
    fc.add(SubsetCollectionDescriptor.FACTORY);
    // aggregate functions
    fc.add(ListifyAggregateDescriptor.FACTORY);
    fc.add(CountAggregateDescriptor.FACTORY);
    fc.add(AvgAggregateDescriptor.FACTORY);
    fc.add(LocalAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SumAggregateDescriptor.FACTORY);
    fc.add(LocalSumAggregateDescriptor.FACTORY);
    fc.add(MaxAggregateDescriptor.FACTORY);
    fc.add(LocalMaxAggregateDescriptor.FACTORY);
    fc.add(MinAggregateDescriptor.FACTORY);
    fc.add(LocalMinAggregateDescriptor.FACTORY);
    fc.add(FirstElementAggregateDescriptor.FACTORY);
    fc.add(LocalFirstElementAggregateDescriptor.FACTORY);
    // serializable aggregates
    fc.add(SerializableCountAggregateDescriptor.FACTORY);
    fc.add(SerializableAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSumAggregateDescriptor.FACTORY);
    // scalar aggregates
    fc.add(ScalarCountAggregateDescriptor.FACTORY);
    fc.add(ScalarAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSumAggregateDescriptor.FACTORY);
    fc.add(ScalarMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarMinAggregateDescriptor.FACTORY);
    fc.add(EmptyStreamAggregateDescriptor.FACTORY);
    fc.add(NonEmptyStreamAggregateDescriptor.FACTORY);
    // SQL aggregates
    fc.add(SqlCountAggregateDescriptor.FACTORY);
    fc.add(SqlAvgAggregateDescriptor.FACTORY);
    fc.add(LocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SqlSumAggregateDescriptor.FACTORY);
    fc.add(LocalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SqlMaxAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMaxAggregateDescriptor.FACTORY);
    fc.add(SqlMinAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMinAggregateDescriptor.FACTORY);
    // SQL serializable aggregates
    fc.add(SerializableSqlCountAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlSumAggregateDescriptor.FACTORY);
    // SQL scalar aggregates
    fc.add(ScalarSqlCountAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlSumAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMinAggregateDescriptor.FACTORY);
    // boolean functions
    fc.add(AndDescriptor.FACTORY);
    fc.add(OrDescriptor.FACTORY);
    // Record constructors / functions
    fc.add(ClosedRecordConstructorDescriptor.FACTORY);
    fc.add(OpenRecordConstructorDescriptor.FACTORY);
    fc.add(RecordConcatDescriptor.FACTORY);
    fc.add(RecordConcatStrictDescriptor.FACTORY);
    // List constructors
    fc.add(OrderedListConstructorDescriptor.FACTORY);
    fc.add(UnorderedListConstructorDescriptor.FACTORY);
    // Sleep function
    fc.add(SleepDescriptor.FACTORY);
    // Inject failure function
    fc.add(InjectFailureDescriptor.FACTORY);
    // Get Job Parameter function
    fc.add(GetJobParameterByNameDescriptor.FACTORY);
    // Switch case
    fc.add(SwitchCaseDescriptor.FACTORY);
    // null functions
    fc.add(IsMissingDescriptor.FACTORY);
    fc.add(IsNullDescriptor.FACTORY);
    fc.add(IsUnknownDescriptor.FACTORY);
    fc.add(IsSystemNullDescriptor.FACTORY);
    fc.add(CheckUnknownDescriptor.FACTORY);
    fc.add(IfMissingDescriptor.FACTORY);
    fc.add(IfNullDescriptor.FACTORY);
    fc.add(IfMissingOrNullDescriptor.FACTORY);
    // uuid generators (zero independent functions)
    fc.add(CreateUUIDDescriptor.FACTORY);
    fc.add(UUIDDescriptor.FACTORY);
    fc.add(CreateQueryUIDDescriptor.FACTORY);
    fc.add(RandomDescriptor.FACTORY);
    fc.add(CurrentDateDescriptor.FACTORY);
    fc.add(CurrentTimeDescriptor.FACTORY);
    fc.add(CurrentDateTimeDescriptor.FACTORY);
    // functions that need generated class for null-handling.
    // Element accessors.
    fc.addGenerated(FieldAccessByIndexDescriptor.FACTORY);
    fc.addGenerated(FieldAccessByNameDescriptor.FACTORY);
    fc.addGenerated(FieldAccessNestedDescriptor.FACTORY);
    fc.addGenerated(AnyCollectionMemberDescriptor.FACTORY);
    fc.addGenerated(GetItemDescriptor.FACTORY);
    // Numeric functions
    fc.add(IfInfDescriptor.FACTORY);
    fc.add(IfNanDescriptor.FACTORY);
    fc.add(IfNanOrInfDescriptor.FACTORY);
    fc.addGenerated(NumericUnaryMinusDescriptor.FACTORY);
    fc.addGenerated(NumericAddDescriptor.FACTORY);
    fc.addGenerated(NumericDivideDescriptor.FACTORY);
    fc.addGenerated(NumericDivDescriptor.FACTORY);
    fc.addGenerated(NumericMultiplyDescriptor.FACTORY);
    fc.addGenerated(NumericSubDescriptor.FACTORY);
    fc.addGenerated(NumericModuloDescriptor.FACTORY);
    fc.addGenerated(NumericPowerDescriptor.FACTORY);
    fc.addGenerated(NotDescriptor.FACTORY);
    fc.addGenerated(LenDescriptor.FACTORY);
    fc.addGenerated(NumericAbsDescriptor.FACTORY);
    fc.addGenerated(NumericCeilingDescriptor.FACTORY);
    fc.addGenerated(NumericFloorDescriptor.FACTORY);
    fc.addGenerated(NumericRoundDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEvenDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEven2Descriptor.FACTORY);
    fc.addGenerated(NumericACosDescriptor.FACTORY);
    fc.addGenerated(NumericASinDescriptor.FACTORY);
    fc.addGenerated(NumericATanDescriptor.FACTORY);
    fc.addGenerated(NumericDegreesDescriptor.FACTORY);
    fc.addGenerated(NumericRadiansDescriptor.FACTORY);
    fc.addGenerated(NumericCosDescriptor.FACTORY);
    fc.addGenerated(NumericSinDescriptor.FACTORY);
    fc.addGenerated(NumericTanDescriptor.FACTORY);
    fc.addGenerated(NumericExpDescriptor.FACTORY);
    fc.addGenerated(NumericLnDescriptor.FACTORY);
    fc.addGenerated(NumericLogDescriptor.FACTORY);
    fc.addGenerated(NumericSqrtDescriptor.FACTORY);
    fc.addGenerated(NumericSignDescriptor.FACTORY);
    fc.addGenerated(NumericTruncDescriptor.FACTORY);
    fc.addGenerated(NumericATan2Descriptor.FACTORY);
    // Comparisons.
    fc.addGenerated(EqualsDescriptor.FACTORY);
    fc.addGenerated(GreaterThanDescriptor.FACTORY);
    fc.addGenerated(GreaterThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(LessThanDescriptor.FACTORY);
    fc.addGenerated(LessThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(NotEqualsDescriptor.FACTORY);
    // If-Equals functions
    fc.addGenerated(MissingIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NullIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NanIfEqualsDescriptor.FACTORY);
    fc.addGenerated(PosInfIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NegInfIfEqualsDescriptor.FACTORY);
    // Binary functions
    fc.addGenerated(BinaryLengthDescriptor.FACTORY);
    fc.addGenerated(ParseBinaryDescriptor.FACTORY);
    fc.addGenerated(PrintBinaryDescriptor.FACTORY);
    fc.addGenerated(BinaryConcatDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromToDescriptor.FACTORY);
    fc.addGenerated(FindBinaryDescriptor.FACTORY);
    fc.addGenerated(FindBinaryFromDescriptor.FACTORY);
    // String functions
    fc.addGenerated(StringLikeDescriptor.FACTORY);
    fc.addGenerated(StringContainsDescriptor.FACTORY);
    fc.addGenerated(StringEndsWithDescriptor.FACTORY);
    fc.addGenerated(StringStartsWithDescriptor.FACTORY);
    fc.addGenerated(SubstringDescriptor.FACTORY);
    fc.addGenerated(StringEqualDescriptor.FACTORY);
    fc.addGenerated(StringLowerCaseDescriptor.FACTORY);
    fc.addGenerated(StringUpperCaseDescriptor.FACTORY);
    fc.addGenerated(StringLengthDescriptor.FACTORY);
    fc.addGenerated(Substring2Descriptor.FACTORY);
    fc.addGenerated(SubstringBeforeDescriptor.FACTORY);
    fc.addGenerated(SubstringAfterDescriptor.FACTORY);
    fc.addGenerated(StringToCodePointDescriptor.FACTORY);
    fc.addGenerated(CodePointToStringDescriptor.FACTORY);
    fc.addGenerated(StringConcatDescriptor.FACTORY);
    fc.addGenerated(StringJoinDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceWithFlagsDescriptor.FACTORY);
    fc.addGenerated(StringInitCapDescriptor.FACTORY);
    fc.addGenerated(StringTrimDescriptor.FACTORY);
    fc.addGenerated(StringLTrimDescriptor.FACTORY);
    fc.addGenerated(StringRTrimDescriptor.FACTORY);
    fc.addGenerated(StringTrim2Descriptor.FACTORY);
    fc.addGenerated(StringLTrim2Descriptor.FACTORY);
    fc.addGenerated(StringRTrim2Descriptor.FACTORY);
    fc.addGenerated(StringPositionDescriptor.FACTORY);
    fc.addGenerated(StringRepeatDescriptor.FACTORY);
    fc.addGenerated(StringReplaceDescriptor.FACTORY);
    fc.addGenerated(StringReplaceWithLimitDescriptor.FACTORY);
    fc.addGenerated(StringReverseDescriptor.FACTORY);
    fc.addGenerated(StringSplitDescriptor.FACTORY);
    // Constructors
    fc.addGenerated(ABooleanConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryHexStringConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryBase64StringConstructorDescriptor.FACTORY);
    fc.addGenerated(AStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt8ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt16ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt32ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt64ConstructorDescriptor.FACTORY);
    fc.addGenerated(AFloatConstructorDescriptor.FACTORY);
    fc.addGenerated(ADoubleConstructorDescriptor.FACTORY);
    fc.addGenerated(APointConstructorDescriptor.FACTORY);
    fc.addGenerated(APoint3DConstructorDescriptor.FACTORY);
    fc.addGenerated(ALineConstructorDescriptor.FACTORY);
    fc.addGenerated(APolygonConstructorDescriptor.FACTORY);
    fc.addGenerated(ACircleConstructorDescriptor.FACTORY);
    fc.addGenerated(ARectangleConstructorDescriptor.FACTORY);
    fc.addGenerated(ATimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AYearMonthDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(ADayTimeDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AUUIDFromStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromTimeConstructorDescriptor.FACTORY);
    // Spatial
    fc.addGenerated(CreatePointDescriptor.FACTORY);
    fc.addGenerated(CreateLineDescriptor.FACTORY);
    fc.addGenerated(CreatePolygonDescriptor.FACTORY);
    fc.addGenerated(CreateCircleDescriptor.FACTORY);
    fc.addGenerated(CreateRectangleDescriptor.FACTORY);
    fc.addGenerated(SpatialAreaDescriptor.FACTORY);
    fc.addGenerated(SpatialDistanceDescriptor.FACTORY);
    fc.addGenerated(CreateMBRDescriptor.FACTORY);
    fc.addGenerated(SpatialCellDescriptor.FACTORY);
    fc.addGenerated(PointXCoordinateAccessor.FACTORY);
    fc.addGenerated(PointYCoordinateAccessor.FACTORY);
    fc.addGenerated(CircleRadiusAccessor.FACTORY);
    fc.addGenerated(CircleCenterAccessor.FACTORY);
    fc.addGenerated(LineRectanglePolygonAccessor.FACTORY);
    // full-text function
    fc.addGenerated(FullTextContainsDescriptor.FACTORY);
    fc.addGenerated(FullTextContainsWithoutOptionDescriptor.FACTORY);
    // Record functions.
    fc.addGenerated(GetRecordFieldsDescriptor.FACTORY);
    fc.addGenerated(GetRecordFieldValueDescriptor.FACTORY);
    fc.addGenerated(DeepEqualityDescriptor.FACTORY);
    fc.addGenerated(RecordMergeDescriptor.FACTORY);
    fc.addGenerated(RecordAddFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordLengthDescriptor.FACTORY);
    fc.addGenerated(RecordNamesDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveDescriptor.FACTORY);
    fc.addGenerated(RecordRenameDescriptor.FACTORY);
    fc.addGenerated(RecordUnwrapDescriptor.FACTORY);
    fc.add(RecordReplaceDescriptor.FACTORY);
    fc.add(RecordAddDescriptor.FACTORY);
    fc.add(RecordPutDescriptor.FACTORY);
    fc.addGenerated(RecordValuesDescriptor.FACTORY);
    fc.addGenerated(PairsDescriptor.FACTORY);
    // Spatial and temporal type accessors
    fc.addGenerated(TemporalYearAccessor.FACTORY);
    fc.addGenerated(TemporalMonthAccessor.FACTORY);
    fc.addGenerated(TemporalDayAccessor.FACTORY);
    fc.addGenerated(TemporalHourAccessor.FACTORY);
    fc.addGenerated(TemporalMinuteAccessor.FACTORY);
    fc.addGenerated(TemporalSecondAccessor.FACTORY);
    fc.addGenerated(TemporalMillisecondAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDatetimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDatetimeAccessor.FACTORY);
    // Temporal functions
    fc.addGenerated(UnixTimeFromDateInDaysDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromTimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DateFromUnixTimeInDaysDescriptor.FACTORY);
    fc.addGenerated(DateFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(TimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(TimeFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromDateAndTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDurationFromDateTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDuartionFromDateDescriptor.FACTORY);
    fc.addGenerated(AdjustDateTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(AdjustTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(IntervalBeforeDescriptor.FACTORY);
    fc.addGenerated(IntervalAfterDescriptor.FACTORY);
    fc.addGenerated(IntervalMeetsDescriptor.FACTORY);
    fc.addGenerated(IntervalMetByDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlapsDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlappedByDescriptor.FACTORY);
    fc.addGenerated(OverlapDescriptor.FACTORY);
    fc.addGenerated(IntervalStartsDescriptor.FACTORY);
    fc.addGenerated(IntervalStartedByDescriptor.FACTORY);
    fc.addGenerated(IntervalCoversDescriptor.FACTORY);
    fc.addGenerated(IntervalCoveredByDescriptor.FACTORY);
    fc.addGenerated(IntervalEndsDescriptor.FACTORY);
    fc.addGenerated(IntervalEndedByDescriptor.FACTORY);
    fc.addGenerated(DurationFromMillisecondsDescriptor.FACTORY);
    fc.addGenerated(DurationFromMonthsDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(MonthsFromYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(MillisecondsFromDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(DurationEqualDescriptor.FACTORY);
    fc.addGenerated(GetYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(GetDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(IntervalBinDescriptor.FACTORY);
    fc.addGenerated(OverlapBinsDescriptor.FACTORY);
    fc.addGenerated(DayOfWeekDescriptor.FACTORY);
    fc.addGenerated(ParseDateDescriptor.FACTORY);
    fc.addGenerated(ParseTimeDescriptor.FACTORY);
    fc.addGenerated(ParseDateTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateDescriptor.FACTORY);
    fc.addGenerated(PrintTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateTimeDescriptor.FACTORY);
    fc.addGenerated(GetOverlappingIntervalDescriptor.FACTORY);
    fc.addGenerated(DurationFromIntervalDescriptor.FACTORY);
    // Type functions.
    fc.addGenerated(IsArrayDescriptor.FACTORY);
    fc.addGenerated(IsAtomicDescriptor.FACTORY);
    fc.addGenerated(IsBooleanDescriptor.FACTORY);
    fc.addGenerated(IsNumberDescriptor.FACTORY);
    fc.addGenerated(IsObjectDescriptor.FACTORY);
    fc.addGenerated(IsStringDescriptor.FACTORY);
    fc.addGenerated(ToArrayDescriptor.FACTORY);
    fc.addGenerated(ToAtomicDescriptor.FACTORY);
    fc.addGenerated(ToBigIntDescriptor.FACTORY);
    fc.addGenerated(ToBooleanDescriptor.FACTORY);
    fc.addGenerated(ToDoubleDescriptor.FACTORY);
    fc.addGenerated(ToNumberDescriptor.FACTORY);
    fc.addGenerated(ToObjectDescriptor.FACTORY);
    fc.addGenerated(ToStringDescriptor.FACTORY);
    fc.addGenerated(TreatAsIntegerDescriptor.FACTORY);
    // Cast function
    fc.addGenerated(CastTypeDescriptor.FACTORY);
    fc.addGenerated(CastTypeLaxDescriptor.FACTORY);
    // Record function
    fc.addGenerated(RecordPairsDescriptor.FACTORY);
    // Other functions
    fc.addGenerated(RandomWithSeedDescriptor.FACTORY);
    ServiceLoader.load(IFunctionRegistrant.class).iterator().forEachRemaining(c -> c.register(fc));
    return fc;
}
#end_block

#method_before
@Override
public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException {
    storage.reset();
    listEval.evaluate(tuple, list);
    ATypeTag listTag = ATYPETAGDESERIALIZER.deserialize(list.getByteArray()[list.getStartOffset()]);
    if (listTag != ATypeTag.ARRAY) {
        PointableHelper.setNull(result);
        return;
    }
    IAType openListType = DefaultOpenFieldType.getDefaultOpenFieldType(inputListType.getTypeTag());
    caster.reset(openListType, inputListType, listEval);
    caster.evaluate(tuple, list);
    fieldNameToValues.clear();
    listAccessor.reset(list.getByteArray(), list.getStartOffset());
    int numObjects = listAccessor.size();
    ARecordVisitablePointable record;
    try {
        for (int objectIndex = 0; objectIndex < numObjects; objectIndex++) {
            listAccessor.getOrWriteItem(objectIndex, object, storage);
            // process only objects (records)
            if (object.getByteArray()[object.getStartOffset()] == ATypeTag.SERIALIZED_RECORD_TYPE_TAG) {
                record = pointableAllocator.allocateRecordValue(DefaultOpenFieldType.NESTED_OPEN_RECORD_TYPE);
                record.set(object.getByteArray(), object.getStartOffset(), object.getLength());
                List<IVisitablePointable> fieldNames = record.getFieldNames();
                List<IVisitablePointable> fieldValues = record.getFieldValues();
                IVisitablePointable[] values;
                for (int j = 0; j < fieldNames.size(); j++) {
                    values = fieldNameToValues.get(fieldNames.get(j));
                    if (values == null) {
                        values = new IVisitablePointable[numObjects];
                        fieldNameToValues.put(fieldNames.get(j), values);
                    }
                    values[objectIndex] = fieldValues.get(j);
                }
            }
        }
        if (fieldNameToValues.isEmpty()) {
            PointableHelper.setMissing(result);
            return;
        }
        recordBuilder.reset(DefaultOpenFieldType.NESTED_OPEN_RECORD_TYPE);
        recordBuilder.init();
        for (Map.Entry<IVisitablePointable, IVisitablePointable[]> e : fieldNameToValues.entrySet()) {
            listBuilder.reset(DefaultOpenFieldType.NESTED_OPEN_AORDERED_LIST_TYPE);
            for (int i = 0; i < e.getValue().length; i++) {
                if (e.getValue()[i] == null) {
                    listBuilder.addItem(PointableHelper.NULL_REF);
                } else {
                    listBuilder.addItem(e.getValue()[i]);
                }
            }
            storage.reset();
            listBuilder.write(storage.getDataOutput(), true);
            recordBuilder.addField(e.getKey(), storage);
        }
        storage.reset();
        recordBuilder.write(storage.getDataOutput(), true);
        result.set(storage);
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    } finally {
        pointableAllocator.reset();
    }
}
#method_after
@Override
public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException {
    storage.reset();
    listEval.evaluate(tuple, list);
    ATypeTag listTag = ATYPETAGDESERIALIZER.deserialize(list.getByteArray()[list.getStartOffset()]);
    if (listTag != ATypeTag.ARRAY) {
        PointableHelper.setNull(result);
        return;
    }
    IAType openListType = DefaultOpenFieldType.getDefaultOpenFieldType(inputListType.getTypeTag());
    caster.reset(openListType, inputListType, listEval);
    caster.evaluate(tuple, list);
    fieldNameToValues.clear();
    listAccessor.reset(list.getByteArray(), list.getStartOffset());
    int numObjects = listAccessor.size();
    try {
        for (int objectIndex = 0; objectIndex < numObjects; objectIndex++) {
            listAccessor.getOrWriteItem(objectIndex, object, storage);
            processObject(object, objectIndex, numObjects);
        }
        if (fieldNameToValues.isEmpty()) {
            PointableHelper.setMissing(result);
            return;
        }
        recordBuilder.reset(DefaultOpenFieldType.NESTED_OPEN_RECORD_TYPE);
        recordBuilder.init();
        for (Map.Entry<IVisitablePointable, IVisitablePointable[]> e : fieldNameToValues.entrySet()) {
            listBuilder.reset(DefaultOpenFieldType.NESTED_OPEN_AORDERED_LIST_TYPE);
            for (int i = 0; i < e.getValue().length; i++) {
                if (e.getValue()[i] == null) {
                    listBuilder.addItem(PointableHelper.NULL_REF);
                } else {
                    listBuilder.addItem(e.getValue()[i]);
                }
            }
            storage.reset();
            listBuilder.write(storage.getDataOutput(), true);
            recordBuilder.addField(e.getKey(), storage);
        }
        storage.reset();
        recordBuilder.write(storage.getDataOutput(), true);
        result.set(storage);
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    } finally {
        pointableAllocator.reset();
    }
}
#end_block

#method_before
@Override
public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException {
    byte listArgType;
    boolean returnNull = false;
    AbstractCollectionType outList = null;
    ATypeTag listTag;
    int minListIndex = 0;
    int minSize = -1;
    int nextSize;
    // evaluate all the lists first to make sure they're all actually lists and of the same list type
    for (int i = 0; i < listsEval.length; i++) {
        listsEval[i].evaluate(tuple, listsArgs[i]);
        if (!returnNull) {
            listArgType = listsArgs[i].getByteArray()[listsArgs[i].getStartOffset()];
            listTag = ATYPETAGDESERIALIZER.deserialize(listArgType);
            if (!listTag.isListType()) {
                returnNull = true;
            } else if (outList != null && outList.getTypeTag() != listTag) {
                throw new RuntimeDataException(ErrorCode.DIFFERENT_LIST_TYPE_ARGS, sourceLoc);
            } else {
                if (outList == null) {
                    outList = (AbstractCollectionType) DefaultOpenFieldType.getDefaultOpenFieldType(listTag);
                }
                nextSize = getNumItems(outList, listsArgs[i].getByteArray(), listsArgs[i].getStartOffset());
                if (nextSize < minSize) {
                    minSize = nextSize;
                    minListIndex = i;
                }
            }
        }
    }
    if (returnNull) {
        PointableHelper.setNull(result);
        return;
    }
    IAsterixListBuilder listBuilder;
    if (outList.getTypeTag() == ATypeTag.ARRAY) {
        if (orderedListBuilder == null) {
            orderedListBuilder = new OrderedListBuilder();
        }
        listBuilder = orderedListBuilder;
    } else {
        if (unorderedListBuilder == null) {
            unorderedListBuilder = new UnorderedListBuilder();
        }
        listBuilder = unorderedListBuilder;
    }
    hashes.clear();
    try {
        // first, get distinct items of the most restrictive (smallest) list, pass listBuilder as null since
        // we're not adding values yet. Values will be added to listBuilder after inspecting all input lists
        listAccessor.reset(listsArgs[minListIndex].getByteArray(), listsArgs[minListIndex].getStartOffset());
        processList(listAccessor, minListIndex, null, true);
        // now process each list one by one
        listBuilder.reset(outList);
        for (int listIndex = 0; listIndex < listsArgs.length; listIndex++) {
            if (listIndex == minListIndex) {
                incrementSmallest(listIndex, hashes.values());
            } else {
                listAccessor.reset(listsArgs[listIndex].getByteArray(), listsArgs[listIndex].getStartOffset());
                processList(listAccessor, listIndex, listBuilder, false);
            }
        }
        finalResult.reset();
        listBuilder.write(finalResult.getDataOutput(), true);
        result.set(finalResult);
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    } finally {
        storageAllocator.reset();
        arrayListAllocator.reset();
        pointableAllocator.reset();
    }
}
#method_after
@Override
public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException {
    byte listArgType;
    boolean returnNull = false;
    AbstractCollectionType outList = null;
    ATypeTag listTag;
    int minListIndex = 0;
    int minSize = -1;
    int nextSize;
    IScalarEvaluator listEval;
    IPointable listArg;
    // evaluate all the lists first to make sure they're all actually lists and of the same list type
    for (int i = 0; i < listsEval.length; i++) {
        listEval = listsEval[i];
        listEval.evaluate(tuple, listsArgs[i]);
        if (!returnNull) {
            listArg = listsArgs[i];
            listArgType = listArg.getByteArray()[listArg.getStartOffset()];
            listTag = ATYPETAGDESERIALIZER.deserialize(listArgType);
            if (!listTag.isListType()) {
                returnNull = true;
            } else if (outList != null && outList.getTypeTag() != listTag) {
                throw new RuntimeDataException(ErrorCode.DIFFERENT_LIST_TYPE_ARGS, sourceLoc);
            } else {
                if (outList == null) {
                    outList = (AbstractCollectionType) DefaultOpenFieldType.getDefaultOpenFieldType(listTag);
                }
                nextSize = getNumItems(outList, listArg.getByteArray(), listArg.getStartOffset());
                if (nextSize < minSize) {
                    minSize = nextSize;
                    minListIndex = i;
                }
            }
        }
    }
    if (returnNull) {
        PointableHelper.setNull(result);
        return;
    }
    IAsterixListBuilder listBuilder;
    if (outList.getTypeTag() == ATypeTag.ARRAY) {
        if (orderedListBuilder == null) {
            orderedListBuilder = new OrderedListBuilder();
        }
        listBuilder = orderedListBuilder;
    } else {
        if (unorderedListBuilder == null) {
            unorderedListBuilder = new UnorderedListBuilder();
        }
        listBuilder = unorderedListBuilder;
    }
    hashes.clear();
    try {
        // first, get distinct items of the most restrictive (smallest) list, pass listBuilder as null since
        // we're not adding values yet. Values will be added to listBuilder after inspecting all input lists
        listArg = listsArgs[minListIndex];
        listAccessor.reset(listArg.getByteArray(), listArg.getStartOffset());
        processList(listAccessor, minListIndex, null, true);
        // now process each list one by one
        listBuilder.reset(outList);
        for (int listIndex = 0; listIndex < listsArgs.length; listIndex++) {
            if (listIndex == minListIndex) {
                incrementSmallest(listIndex, hashes.values());
            } else {
                listArg = listsArgs[listIndex];
                listAccessor.reset(listArg.getByteArray(), listArg.getStartOffset());
                processList(listAccessor, listIndex, listBuilder, false);
            }
        }
        finalResult.reset();
        listBuilder.write(finalResult.getDataOutput(), true);
        result.set(finalResult);
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    } finally {
        storageAllocator.reset();
        arrayListAllocator.reset();
        pointableAllocator.reset();
    }
}
#end_block

#method_before
// collect the items of the most restrictive list, it initializes the list index as -1. each successive list
private boolean initIntersectList(IPointable item, int hash, List<ValueListIndex> sameHashes) throws IOException {
    // add if new item
    if (sameHashes == null) {
        List<ValueListIndex> newHashes = arrayListAllocator.allocate(null);
        newHashes.clear();
        newHashes.add(new ValueListIndex(item, -1));
        hashes.put(hash, newHashes);
        return true;
    } else if (isNewItem(item, sameHashes)) {
        sameHashes.add(new ValueListIndex(item, -1));
        return true;
    }
    // else ignore for duplicate values in the same list
    return false;
}
#method_after
// collect the items of the most restrictive list, it initializes the list index as -1. each successive list
private boolean initIntersectList(IPointable item, int hash, List<ValueListIndex> sameHashes) throws IOException {
    // add if new item
    if (sameHashes == null) {
        List<ValueListIndex> newHashes = arrayListAllocator.allocate(null);
        newHashes.clear();
        newHashes.add(new ValueListIndex(item, -1));
        hashes.put(hash, newHashes);
        return true;
    } else if (ArrayFunctionsUtil.findItem(item, sameHashes) == null) {
        sameHashes.add(new ValueListIndex(item, -1));
        return true;
    }
    // else ignore for duplicate values in the same list
    return false;
}
#end_block

#method_before
private void incrementIfExists(List<ValueListIndex> sameHashes, IPointable item, int listIndex, IAsterixListBuilder listBuilder) throws HyracksDataException {
    ValueListIndex sameValue;
    for (int k = 0; k < sameHashes.size(); k++) {
        sameValue = sameHashes.get(k);
        if (comp.compare(item.getByteArray(), item.getStartOffset(), item.getLength(), sameValue.value.getByteArray(), sameValue.value.getStartOffset(), sameValue.value.getLength()) == 0) {
            // found the item, check its stamp (stamp saves the last list index that has seen this item)
            if (listIndex - sameValue.listIndex == 1) {
                // increment stamp of this item (only when the original stamp == previous listIndex)
                sameValue.listIndex = listIndex;
                if (listIndex == listsArgs.length - 1) {
                    // when listIndex is the last list, then it means this item was found in all previous lists
                    listBuilder.addItem(item);
                }
            }
            return;
        }
    }
}
#method_after
private void incrementIfExists(List<ValueListIndex> sameHashes, IPointable item, int listIndex, IAsterixListBuilder listBuilder) throws HyracksDataException {
    ValueListIndex sameValue = ArrayFunctionsUtil.findItem(item, sameHashes);
    if (sameValue != null && listIndex - sameValue.listIndex == 1) {
        // found the item, its stamp is OK (stamp saves the last list index that has seen this item)
        // increment stamp of this item
        sameValue.listIndex = listIndex;
        if (listIndex == listsArgs.length - 1) {
            // when listIndex is the last list, then it means this item was found in all previous lists
            listBuilder.addItem(item);
        }
    }
}
#end_block

#method_before
@Override
public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException {
    byte listArgType;
    boolean returnNull = false;
    AbstractCollectionType outList = null;
    ATypeTag listTag;
    for (int i = 0; i < listsEval.length; i++) {
        listsEval[i].evaluate(tuple, listsArgs[i]);
        if (!returnNull) {
            listArgType = listsArgs[i].getByteArray()[listsArgs[i].getStartOffset()];
            listTag = ATYPETAGDESERIALIZER.deserialize(listArgType);
            if (!listTag.isListType()) {
                returnNull = true;
            } else if (outList != null && outList.getTypeTag() != listTag) {
                throw new RuntimeDataException(ErrorCode.DIFFERENT_LIST_TYPE_ARGS, sourceLocation);
            } else if (outList == null) {
                outList = (AbstractCollectionType) DefaultOpenFieldType.getDefaultOpenFieldType(listTag);
            }
        }
    }
    if (returnNull) {
        PointableHelper.setNull(result);
        return;
    }
    IAsterixListBuilder listBuilder;
    if (outList.getTypeTag() == ATypeTag.ARRAY) {
        if (orderedListBuilder == null) {
            orderedListBuilder = new OrderedListBuilder();
        }
        listBuilder = orderedListBuilder;
    } else {
        if (unorderedListBuilder == null) {
            unorderedListBuilder = new UnorderedListBuilder();
        }
        listBuilder = unorderedListBuilder;
    }
    listBuilder.reset(outList);
    try {
        init();
        processLists(listsArgs, listBuilder);
        finish(listBuilder);
        finalResult.reset();
        listBuilder.write(finalResult.getDataOutput(), true);
        result.set(finalResult);
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    } finally {
        storageAllocator.reset();
        pointableAllocator.reset();
        arrayListAllocator.reset();
        pointableListAllocator.reset();
    }
}
#method_after
@Override
public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException {
    byte listArgType;
    boolean returnNull = false;
    AbstractCollectionType outList = null;
    ATypeTag listTag;
    IAType defaultOpenType;
    for (int i = 0; i < listsEval.length; i++) {
        listsEval[i].evaluate(tuple, listsArgs[i]);
        if (!returnNull) {
            listArgType = listsArgs[i].getByteArray()[listsArgs[i].getStartOffset()];
            listTag = ATYPETAGDESERIALIZER.deserialize(listArgType);
            if (!listTag.isListType()) {
                returnNull = true;
            } else if (outList != null && outList.getTypeTag() != listTag) {
                throw new RuntimeDataException(ErrorCode.DIFFERENT_LIST_TYPE_ARGS, sourceLocation);
            } else {
                if (outList == null) {
                    outList = (AbstractCollectionType) DefaultOpenFieldType.getDefaultOpenFieldType(listTag);
                }
                defaultOpenType = DefaultOpenFieldType.getDefaultOpenFieldType(argTypes[i].getTypeTag());
                caster.reset(defaultOpenType, argTypes[i], listsEval[i]);
                caster.evaluate(tuple, listsArgs[i]);
            }
        }
    }
    if (returnNull) {
        PointableHelper.setNull(result);
        return;
    }
    IAsterixListBuilder listBuilder;
    if (outList.getTypeTag() == ATypeTag.ARRAY) {
        if (orderedListBuilder == null) {
            orderedListBuilder = new OrderedListBuilder();
        }
        listBuilder = orderedListBuilder;
    } else {
        if (unorderedListBuilder == null) {
            unorderedListBuilder = new UnorderedListBuilder();
        }
        listBuilder = unorderedListBuilder;
    }
    listBuilder.reset(outList);
    try {
        init();
        processLists(listsArgs, listBuilder);
        finish(listBuilder);
        finalResult.reset();
        listBuilder.write(finalResult.getDataOutput(), true);
        result.set(finalResult);
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    } finally {
        release();
        storageAllocator.reset();
        pointableAllocator.reset();
    }
}
#end_block

#method_before
@Override
protected IAType getResultType(ILogicalExpression expr, IAType... strippedInputTypes) throws AlgebricksException {
    IAType type = strippedInputTypes[0];
    if (type.getTypeTag().isListType()) {
        return ((AbstractCollectionType) type).getItemType();
    }
    return BuiltinType.ANY;
}
#method_after
@Override
protected IAType getResultType(ILogicalExpression expr, IAType... strippedInputTypes) throws AlgebricksException {
    IAType type = strippedInputTypes[0];
    if (type.getTypeTag().isListType()) {
        return AUnionType.createNullableType(((AbstractCollectionType) type).getItemType());
    }
    return BuiltinType.ANY;
}
#end_block

#method_before
@Override
protected IAType getResultType(ILogicalExpression expr, IAType... strippedInputTypes) throws AlgebricksException {
    if (strippedInputTypes.length != 2 && strippedInputTypes.length != 3) {
        String functionName = ((AbstractFunctionCallExpression) expr).getFunctionIdentifier().getName();
        throw new CompilationException(ErrorCode.COMPILATION_INVALID_NUM_OF_ARGS, expr.getSourceLocation(), "2 or 3", functionName);
    }
    IAType startNum = strippedInputTypes[0];
    IAType endNum = strippedInputTypes[1];
    IAType step = strippedInputTypes.length == 3 ? strippedInputTypes[2] : null;
    if (ATypeHierarchy.canPromote(startNum.getTypeTag(), ATypeTag.BIGINT) && ATypeHierarchy.canPromote(endNum.getTypeTag(), ATypeTag.BIGINT) && (step == null || ATypeHierarchy.canPromote(step.getTypeTag(), ATypeTag.BIGINT))) {
        return LONG_LIST;
    } else if (ATypeHierarchy.canPromote(startNum.getTypeTag(), ATypeTag.DOUBLE) && ATypeHierarchy.canPromote(endNum.getTypeTag(), ATypeTag.DOUBLE) && (step == null || ATypeHierarchy.canPromote(step.getTypeTag(), ATypeTag.DOUBLE))) {
        return DOUBLE_LIST;
    } else {
        return BuiltinType.ANY;
    }
}
#method_after
@Override
protected IAType getResultType(ILogicalExpression expr, IAType... strippedInputTypes) throws AlgebricksException {
    if (strippedInputTypes.length != 2 && strippedInputTypes.length != 3) {
        String functionName = ((AbstractFunctionCallExpression) expr).getFunctionIdentifier().getName();
        throw new CompilationException(ErrorCode.COMPILATION_INVALID_NUM_OF_ARGS, expr.getSourceLocation(), functionName);
    }
    IAType startNum = strippedInputTypes[0];
    IAType endNum = strippedInputTypes[1];
    IAType step = strippedInputTypes.length == 3 ? strippedInputTypes[2] : null;
    if (ATypeHierarchy.canPromote(startNum.getTypeTag(), ATypeTag.BIGINT) && ATypeHierarchy.canPromote(endNum.getTypeTag(), ATypeTag.BIGINT) && (step == null || ATypeHierarchy.canPromote(step.getTypeTag(), ATypeTag.BIGINT))) {
        return LONG_LIST;
    } else if (ATypeHierarchy.canPromote(startNum.getTypeTag(), ATypeTag.DOUBLE) && ATypeHierarchy.canPromote(endNum.getTypeTag(), ATypeTag.DOUBLE) && (step == null || ATypeHierarchy.canPromote(step.getTypeTag(), ATypeTag.DOUBLE))) {
        return DOUBLE_LIST;
    } else {
        return BuiltinType.ANY;
    }
}
#end_block

#method_before
@Override
protected IAType getResultType(ILogicalExpression expr, IAType... strippedInputTypes) throws AlgebricksException {
    if (strippedInputTypes.length < minNumArgs || (maxNumArgs > 0 && strippedInputTypes.length > maxNumArgs)) {
        String functionName = ((AbstractFunctionCallExpression) expr).getFunctionIdentifier().getName();
        String numArgs = "min args: " + minNumArgs;
        if (maxNumArgs > 0) {
            numArgs += ", max args: " + maxNumArgs;
        }
        throw new CompilationException(ErrorCode.COMPILATION_INVALID_NUM_OF_ARGS, expr.getSourceLocation(), numArgs, functionName);
    }
    // output type should be the same as as the type tag at [list index]. The output type is nullable/missable
    // since the output could be null due to other invalid arguments or the tag at [list index] itself is not list
    int listIndex = 0;
    if (listIsLast) {
        listIndex = strippedInputTypes.length - 1;
    }
    IAType listType = strippedInputTypes[listIndex];
    if (listType.getTypeTag().isListType()) {
        if (makeOpen) {
            listType = DefaultOpenFieldType.getDefaultOpenFieldType(listType.getTypeTag());
        }
        return AUnionType.createUnknownableType(listType);
    } else {
        return BuiltinType.ANY;
    }
}
#method_after
@Override
protected IAType getResultType(ILogicalExpression expr, IAType... strippedInputTypes) throws AlgebricksException {
    if (strippedInputTypes.length < minNumArgs || (maxNumArgs > 0 && strippedInputTypes.length > maxNumArgs)) {
        String functionName = ((AbstractFunctionCallExpression) expr).getFunctionIdentifier().getName();
        throw new CompilationException(ErrorCode.COMPILATION_INVALID_NUM_OF_ARGS, expr.getSourceLocation(), functionName);
    }
    // output type should be the same as as the type tag at [list index]. The output type is nullable/missable
    // since the output could be null due to other invalid arguments or the tag at [list index] itself is not list
    int listIndex = 0;
    if (listIsLast) {
        listIndex = strippedInputTypes.length - 1;
    }
    IAType listType = strippedInputTypes[listIndex];
    if (listType.getTypeTag().isListType()) {
        if (makeOpen) {
            listType = DefaultOpenFieldType.getDefaultOpenFieldType(listType.getTypeTag());
        }
        return AUnionType.createUnknownableType(listType);
    } else {
        return BuiltinType.ANY;
    }
}
#end_block

#method_before
@Override
public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException {
    storage.reset();
    listEval.evaluate(tuple, list);
    targetValEval.evaluate(tuple, target);
    newValEval.evaluate(tuple, newVal);
    ATypeTag listType = ATYPETAGDESERIALIZER.deserialize(list.getByteArray()[list.getStartOffset()]);
    ATypeTag targetTag = ATYPETAGDESERIALIZER.deserialize(target.getByteArray()[target.getStartOffset()]);
    ATypeTag newValTag = ATYPETAGDESERIALIZER.deserialize(newVal.getByteArray()[newVal.getStartOffset()]);
    if (listType == ATypeTag.MISSING || targetTag == ATypeTag.MISSING || newValTag == ATypeTag.MISSING) {
        PointableHelper.setMissing(result);
        return;
    }
    double maxDouble = -1;
    String name = getIdentifier().getName();
    if (maxEval != null) {
        maxEval.evaluate(tuple, maxArg);
        ATypeTag maxTag = ATYPETAGDESERIALIZER.deserialize(maxArg.getTag());
        if (maxTag == ATypeTag.MISSING) {
            PointableHelper.setMissing(result);
            return;
        } else if (!ATypeHierarchy.isCompatible(maxTag, ATypeTag.DOUBLE)) {
            PointableHelper.setNull(result);
            return;
        }
        maxDouble = ATypeHierarchy.getDoubleValue(name, 3, maxArg.getByteArray(), maxArg.getStartOffset());
    }
    if (!listType.isListType() || Math.floor(maxDouble) < maxDouble || targetTag == ATypeTag.NULL) {
        PointableHelper.setNull(result);
        return;
    }
    if (targetTag.isDerivedType()) {
        throw new RuntimeDataException(ErrorCode.CANNOT_COMPARE_COMPLEX, sourceLoc);
    }
    int max = (int) maxDouble;
    // create list
    IAsterixListBuilder listBuilder;
    if (listType == ATypeTag.ARRAY) {
        if (orderedListBuilder == null) {
            orderedListBuilder = new OrderedListBuilder();
        }
        listBuilder = orderedListBuilder;
    } else {
        if (unorderedListBuilder == null) {
            unorderedListBuilder = new UnorderedListBuilder();
        }
        listBuilder = unorderedListBuilder;
    }
    listBuilder.reset((AbstractCollectionType) DefaultOpenFieldType.getDefaultOpenFieldType(listType));
    listAccessor.reset(list.getByteArray(), list.getStartOffset());
    try {
        int counter = 0;
        byte[] targetBytes = target.getByteArray();
        int offset = target.getStartOffset();
        int length = target.getLength();
        for (int i = 0; i < listAccessor.size(); i++) {
            listAccessor.getOrWriteItem(i, item, storage);
            if (counter != max && comp.compare(item.getByteArray(), item.getStartOffset(), item.getLength(), targetBytes, offset, length) == 0) {
                listBuilder.addItem(newVal);
                counter++;
            } else {
                listBuilder.addItem(item);
            }
        }
        storage.reset();
        listBuilder.write(storage.getDataOutput(), true);
        result.set(storage);
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    }
}
#method_after
@Override
public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException {
    storage.reset();
    listEval.evaluate(tuple, list);
    targetValEval.evaluate(tuple, target);
    newValEval.evaluate(tuple, newVal);
    ATypeTag listType = ATYPETAGDESERIALIZER.deserialize(list.getByteArray()[list.getStartOffset()]);
    ATypeTag targetTag = ATYPETAGDESERIALIZER.deserialize(target.getByteArray()[target.getStartOffset()]);
    ATypeTag newValTag = ATYPETAGDESERIALIZER.deserialize(newVal.getByteArray()[newVal.getStartOffset()]);
    if (listType == ATypeTag.MISSING || targetTag == ATypeTag.MISSING || newValTag == ATypeTag.MISSING) {
        PointableHelper.setMissing(result);
        return;
    }
    double maxDouble = -1;
    String name = getIdentifier().getName();
    if (maxEval != null) {
        maxEval.evaluate(tuple, maxArg);
        ATypeTag maxTag = ATYPETAGDESERIALIZER.deserialize(maxArg.getTag());
        if (maxTag == ATypeTag.MISSING) {
            PointableHelper.setMissing(result);
            return;
        } else if (!ATypeHierarchy.isCompatible(maxTag, ATypeTag.DOUBLE)) {
            PointableHelper.setNull(result);
            return;
        }
        maxDouble = ATypeHierarchy.getDoubleValue(name, 3, maxArg.getByteArray(), maxArg.getStartOffset());
    }
    if (!listType.isListType() || Math.floor(maxDouble) < maxDouble || targetTag == ATypeTag.NULL || Double.isInfinite(maxDouble) || Double.isNaN(maxDouble)) {
        PointableHelper.setNull(result);
        return;
    }
    if (targetTag.isDerivedType()) {
        throw new RuntimeDataException(ErrorCode.CANNOT_COMPARE_COMPLEX, sourceLoc);
    }
    IAType defaultOpenType = DefaultOpenFieldType.getDefaultOpenFieldType(listType);
    caster.reset(defaultOpenType, inputListType, listEval);
    caster.evaluate(tuple, list);
    defaultOpenType = DefaultOpenFieldType.getDefaultOpenFieldType(newValTag);
    if (defaultOpenType != null) {
        caster.reset(defaultOpenType, newValueType, newValEval);
        caster.evaluate(tuple, newVal);
    }
    int max = (int) maxDouble;
    // create list
    IAsterixListBuilder listBuilder;
    if (listType == ATypeTag.ARRAY) {
        if (orderedListBuilder == null) {
            orderedListBuilder = new OrderedListBuilder();
        }
        listBuilder = orderedListBuilder;
    } else {
        if (unorderedListBuilder == null) {
            unorderedListBuilder = new UnorderedListBuilder();
        }
        listBuilder = unorderedListBuilder;
    }
    listBuilder.reset((AbstractCollectionType) DefaultOpenFieldType.getDefaultOpenFieldType(listType));
    listAccessor.reset(list.getByteArray(), list.getStartOffset());
    try {
        int counter = 0;
        byte[] targetBytes = target.getByteArray();
        int offset = target.getStartOffset();
        int length = target.getLength();
        for (int i = 0; i < listAccessor.size(); i++) {
            listAccessor.getOrWriteItem(i, item, storage);
            if (counter != max && comp.compare(item.getByteArray(), item.getStartOffset(), item.getLength(), targetBytes, offset, length) == 0) {
                listBuilder.addItem(newVal);
                counter++;
            } else {
                listBuilder.addItem(item);
            }
        }
        storage.reset();
        listBuilder.write(storage.getDataOutput(), true);
        result.set(storage);
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    }
}
#end_block

#method_before
@Override
protected boolean processItem(IPointable item, int listIndex, IAsterixListBuilder listBuilder) throws HyracksDataException {
    int hash = binaryHashFunction.hash(item.getByteArray(), item.getStartOffset(), item.getLength());
    List<IPointable> sameHashes = hashes.get(hash);
    if (sameHashes == null) {
        // new item
        sameHashes = pointableListAllocator.allocate(null);
        sameHashes.clear();
        addItem(listBuilder, item, sameHashes);
        hashes.put(hash, sameHashes);
        return true;
    } else if (isNewItem(item, sameHashes)) {
        // check if it happens that two hashes are the same but they are for different items
        addItem(listBuilder, item, sameHashes);
        return true;
    }
    // else ignore since the item already exists
    return false;
}
#method_after
@Override
protected boolean processItem(IPointable item, int listIndex, IAsterixListBuilder listBuilder) throws HyracksDataException {
    int hash = binaryHashFunction.hash(item.getByteArray(), item.getStartOffset(), item.getLength());
    List<IPointable> sameHashes = hashes.get(hash);
    if (sameHashes == null) {
        // new item
        sameHashes = pointableListAllocator.allocate(null);
        sameHashes.clear();
        addItem(listBuilder, item, sameHashes);
        hashes.put(hash, sameHashes);
        return true;
    } else if (ArrayFunctionsUtil.findItem(item, sameHashes) == null) {
        // new item, it could happen that two hashes are the same but they are for different items
        addItem(listBuilder, item, sameHashes);
        return true;
    }
    // else ignore since the item already exists
    return false;
}
#end_block

#method_before
@Override
public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException {
    // 1st arg: list to flatten
    listEval.evaluate(tuple, list);
    // 2nd arg: depthArg
    depthEval.evaluate(tuple, depthArg);
    ATypeTag listType = ATYPETAGDESERIALIZER.deserialize(list.getByteArray()[list.getStartOffset()]);
    if (!ATypeHierarchy.isCompatible(ATYPETAGDESERIALIZER.deserialize(depthArg.getTag()), ATypeTag.DOUBLE) || !listType.isListType()) {
        PointableHelper.setNull(result);
        return;
    }
    String name = getIdentifier().getName();
    double depth = ATypeHierarchy.getDoubleValue(name, 1, depthArg.getByteArray(), depthArg.getStartOffset());
    if (Math.floor(depth) < depth) {
        PointableHelper.setNull(result);
        return;
    }
    int depthInt = (int) depth;
    // create list
    IAsterixListBuilder listBuilder;
    if (listType == ATypeTag.ARRAY) {
        if (orderedListBuilder == null) {
            orderedListBuilder = new OrderedListBuilder();
        }
        listBuilder = orderedListBuilder;
    } else {
        if (unorderedListBuilder == null) {
            unorderedListBuilder = new UnorderedListBuilder();
        }
        listBuilder = unorderedListBuilder;
    }
    listBuilder.reset((AbstractCollectionType) DefaultOpenFieldType.getDefaultOpenFieldType(listType));
    mainListAccessor.reset(list.getByteArray(), list.getStartOffset());
    try {
        process(mainListAccessor, listBuilder, 0, depthInt);
        storage.reset();
        listBuilder.write(storage.getDataOutput(), true);
        result.set(storage);
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    } finally {
        storageAllocator.reset();
    }
}
#method_after
@Override
public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException {
    // 1st arg: list to flatten
    listEval.evaluate(tuple, list);
    // 2nd arg: depthArg
    depthEval.evaluate(tuple, depthArg);
    ATypeTag listType = ATYPETAGDESERIALIZER.deserialize(list.getByteArray()[list.getStartOffset()]);
    if (!ATypeHierarchy.isCompatible(ATYPETAGDESERIALIZER.deserialize(depthArg.getTag()), ATypeTag.DOUBLE) || !listType.isListType()) {
        PointableHelper.setNull(result);
        return;
    }
    String name = getIdentifier().getName();
    double depth = ATypeHierarchy.getDoubleValue(name, 1, depthArg.getByteArray(), depthArg.getStartOffset());
    if (Double.isNaN(depth) || Double.isInfinite(depth) || Math.floor(depth) < depth) {
        PointableHelper.setNull(result);
        return;
    }
    caster.reset(DefaultOpenFieldType.getDefaultOpenFieldType(listType), inputListType, listEval);
    caster.evaluate(tuple, list);
    int depthInt = (int) depth;
    // create list
    IAsterixListBuilder listBuilder;
    if (listType == ATypeTag.ARRAY) {
        if (orderedListBuilder == null) {
            orderedListBuilder = new OrderedListBuilder();
        }
        listBuilder = orderedListBuilder;
    } else {
        if (unorderedListBuilder == null) {
            unorderedListBuilder = new UnorderedListBuilder();
        }
        listBuilder = unorderedListBuilder;
    }
    ListAccessor mainListAccessor = listAccessorAllocator.allocate(null);
    listBuilder.reset((AbstractCollectionType) DefaultOpenFieldType.getDefaultOpenFieldType(listType));
    mainListAccessor.reset(list.getByteArray(), list.getStartOffset());
    try {
        process(mainListAccessor, listBuilder, 0, depthInt);
        storage.reset();
        listBuilder.write(storage.getDataOutput(), true);
        result.set(storage);
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    } finally {
        storageAllocator.reset();
        listAccessorAllocator.reset();
    }
}
#end_block

#method_before
private void process(ListAccessor listAccessor, IAsterixListBuilder listBuilder, int currentDepth, int depth) throws IOException {
    boolean itemInStorage;
    for (int i = 0; i < listAccessor.size(); i++) {
        itemInStorage = listAccessor.getOrWriteItem(i, item, storage);
        // if item is not a list or depth is reached, write it
        if (!ATYPETAGDESERIALIZER.deserialize(item.getByteArray()[item.getStartOffset()]).isListType() || currentDepth == depth) {
            listBuilder.addItem(item);
        } else {
            // recurse on the sublist
            ListAccessor newListAccessor = new ListAccessor();
            newListAccessor.reset(item.getByteArray(), item.getStartOffset());
            if (itemInStorage) {
                // create a new storage since the item is using it
                storage = (ArrayBackedValueStorage) storageAllocator.allocate(null);
            }
            process(newListAccessor, listBuilder, currentDepth + 1, depth);
        }
    }
}
#method_after
private void process(ListAccessor listAccessor, IAsterixListBuilder listBuilder, int currentDepth, int depth) throws IOException {
    boolean itemInStorage;
    for (int i = 0; i < listAccessor.size(); i++) {
        itemInStorage = listAccessor.getOrWriteItem(i, item, storage);
        // if item is not a list or depth is reached, write it
        if (!ATYPETAGDESERIALIZER.deserialize(item.getByteArray()[item.getStartOffset()]).isListType() || currentDepth == depth) {
            listBuilder.addItem(item);
        } else {
            // recurse on the sublist
            ListAccessor newListAccessor = listAccessorAllocator.allocate(null);
            newListAccessor.reset(item.getByteArray(), item.getStartOffset());
            if (itemInStorage) {
                // create a new storage since the item is using it
                storage = (ArrayBackedValueStorage) storageAllocator.allocate(null);
                storage.reset();
            }
            process(newListAccessor, listBuilder, currentDepth + 1, depth);
        }
    }
}
#end_block

#method_before
@Override
public IScalarEvaluatorFactory createEvaluatorFactory(final IScalarEvaluatorFactory[] args) throws AlgebricksException {
    return new IScalarEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IScalarEvaluator createScalarEvaluator(final IHyracksTaskContext ctx) throws HyracksDataException {
            return new ArraySymDiffEval(args, ctx, sourceLoc);
        }
    };
}
#method_after
@Override
public IScalarEvaluatorFactory createEvaluatorFactory(final IScalarEvaluatorFactory[] args) throws AlgebricksException {
    return new IScalarEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IScalarEvaluator createScalarEvaluator(final IHyracksTaskContext ctx) throws HyracksDataException {
            return new ArraySymDiffEval(args, ctx, sourceLoc, argTypes);
        }
    };
}
#end_block

#method_before
@Override
protected boolean processItem(IPointable item, int listIndex, IAsterixListBuilder listBuilder) throws HyracksDataException {
    // lookup the item
    int hash = binaryHashFunction.hash(item.getByteArray(), item.getStartOffset(), item.getLength());
    List<ValueCounter> sameHashes = hashes.get(hash);
    if (sameHashes == null) {
        // new item
        sameHashes = arrayListAllocator.allocate(null);
        sameHashes.clear();
        addItem(item, listIndex, sameHashes);
        hashes.put(hash, sameHashes);
        return true;
    } else {
        // potentially, item already exists
        ValueCounter itemListIdxCounter = findItem(item, sameHashes);
        if (itemListIdxCounter == null) {
            // new item
            addItem(item, listIndex, sameHashes);
            return true;
        }
        // the item already exists, increment the counter (don't increment the counter for the same listIndex)
        if (itemListIdxCounter.listIndex != listIndex) {
            itemListIdxCounter.listIndex = listIndex;
            itemListIdxCounter.counter++;
        }
        // false, since we didn't add (use) the item
        return false;
    }
}
#method_after
@Override
protected boolean processItem(IPointable item, int listIndex, IAsterixListBuilder listBuilder) throws HyracksDataException {
    // lookup the item
    int hash = binaryHashFunction.hash(item.getByteArray(), item.getStartOffset(), item.getLength());
    List<ValueCounter> sameHashes = hashes.get(hash);
    if (sameHashes == null) {
        // new item
        sameHashes = arrayListAllocator.allocate(null);
        sameHashes.clear();
        addItem(item, listIndex, sameHashes);
        hashes.put(hash, sameHashes);
        return true;
    } else {
        // potentially, item already exists
        ValueCounter itemListIdxCounter = ArrayFunctionsUtil.findItem(item, sameHashes);
        if (itemListIdxCounter == null) {
            // new item
            addItem(item, listIndex, sameHashes);
            return true;
        }
        // the item already exists, increment the counter (don't increment the counter for the same listIndex)
        if (itemListIdxCounter.listIndex != listIndex) {
            itemListIdxCounter.listIndex = listIndex;
            itemListIdxCounter.counter++;
        }
        // false, since we didn't add (use) the item
        return false;
    }
}
#end_block

#method_before
private void addItem(IPointable item, int listIndex, List<ValueCounter> sameHashes) {
    sameHashes.add(new ValueCounter(item, listIndex, 1));
}
#method_after
private void addItem(IPointable item, int listIndex, List<ValueCounter> sameHashes) {
    ValueCounter valueCounter = valueCounterAllocator.allocate(null);
    valueCounter.reset(item, listIndex, 1);
    sameHashes.add(valueCounter);
}
#end_block

#method_before
@Override
protected void checkArgType(String funcName, int argIndex, IAType type, SourceLocation sourceLoc) throws AlgebricksException {
    ATypeTag actualTypeTag = type.getTypeTag();
    if (argIndex == 0 && actualTypeTag != ATypeTag.OBJECT) {
        throw new TypeMismatchException(sourceLoc, actualTypeTag, ATypeTag.OBJECT);
    }
    if (argIndex == 1) {
        switch(actualTypeTag) {
            case STRING:
                break;
            case ARRAY:
                checkOrderedList(funcName, type, sourceLoc);
                break;
            default:
                throw new TypeMismatchException(sourceLoc, actualTypeTag, ATypeTag.STRING, ATypeTag.ARRAY);
        }
    }
}
#method_after
@Override
protected void checkArgType(String funcName, int argIndex, IAType type, SourceLocation sourceLoc) throws AlgebricksException {
    ATypeTag actualTypeTag = type.getTypeTag();
    if (argIndex == 0 && actualTypeTag != ATypeTag.OBJECT) {
        throw new TypeMismatchException(sourceLoc, actualTypeTag, ATypeTag.OBJECT);
    }
    if (argIndex == 1) {
        switch(actualTypeTag) {
            case STRING:
                break;
            case ARRAY:
                checkOrderedList(type, sourceLoc);
                break;
            default:
                throw new TypeMismatchException(sourceLoc, actualTypeTag, ATypeTag.STRING, ATypeTag.ARRAY);
        }
    }
}
#end_block

#method_before
private void checkOrderedList(String funcName, IAType type, SourceLocation sourceLoc) throws AlgebricksException {
    AOrderedListType listType = (AOrderedListType) type;
    ATypeTag itemTypeTag = listType.getItemType().getTypeTag();
    if (itemTypeTag != ATypeTag.STRING && itemTypeTag != ATypeTag.ANY) {
        throw new TypeMismatchException(sourceLoc, itemTypeTag, ATypeTag.STRING, ATypeTag.ANY);
    }
}
#method_after
private void checkOrderedList(IAType type, SourceLocation sourceLoc) throws AlgebricksException {
    AOrderedListType listType = (AOrderedListType) type;
    ATypeTag itemTypeTag = listType.getItemType().getTypeTag();
    if (itemTypeTag != ATypeTag.STRING && itemTypeTag != ATypeTag.ANY) {
        throw new TypeMismatchException(sourceLoc, itemTypeTag, ATypeTag.STRING, ATypeTag.ANY);
    }
}
#end_block

#method_before
@Override
protected IAType getResultType(ILogicalExpression expr, IAType... strippedInputTypes) throws AlgebricksException {
    IAType argType = strippedInputTypes[0];
    switch(argType.getTypeTag()) {
        case ARRAY:
        case MULTISET:
            return AUnionType.createNullableType(argType);
        default:
            return BuiltinType.ANY;
    }
}
#method_after
@Override
protected IAType getResultType(ILogicalExpression expr, IAType... strippedInputTypes) throws AlgebricksException {
    if (strippedInputTypes.length < minNumArgs) {
        String functionName = ((AbstractFunctionCallExpression) expr).getFunctionIdentifier().getName();
        throw new CompilationException(ErrorCode.COMPILATION_INVALID_NUM_OF_ARGS, expr.getSourceLocation(), minNumArgs, functionName);
    }
    // output type should be the same as as the type tag at [list index]. The output type is nullable/missable
    // since the output could be null due to other invalid arguments or the tag at [list index] itself is not list
    int listIndex = 0;
    if (listIsLast) {
        listIndex = strippedInputTypes.length - 1;
    }
    IAType listType = strippedInputTypes[listIndex];
    if (listType.getTypeTag() == ATypeTag.ARRAY) {
        return makeOpen ? AUnionType.createUnknownableType(DefaultOpenFieldType.NESTED_OPEN_AORDERED_LIST_TYPE) : AUnionType.createUnknownableType(listType);
    } else if (listType.getTypeTag() == ATypeTag.MULTISET) {
        return makeOpen ? AUnionType.createUnknownableType(DefaultOpenFieldType.NESTED_OPEN_AUNORDERED_LIST_TYPE) : AUnionType.createUnknownableType(listType);
    } else {
        return BuiltinType.ANY;
    }
}
#end_block

#method_before
@Override
protected void processList(ListAccessor listAccessor, IAsterixListBuilder listBuilder) throws IOException {
    boolean addItem;
    ArrayBackedValueStorage item;
    List<ArrayBackedValueStorage> distinct = new ArrayList<>();
    for (int i = 0; i < listAccessor.size(); i++) {
        item = new ArrayBackedValueStorage();
        listAccessor.writeItem(i, item.getDataOutput());
        if (ATYPETAGDESERIALIZER.deserialize(item.getByteArray()[item.getStartOffset()]).isDerivedType()) {
            throw HyracksDataException.create(ErrorCode.CANNOT_COMPARE_COMPLEX, sourceLoc);
        }
        addItem = true;
        for (ArrayBackedValueStorage addedItem : distinct) {
            if (comp.compare(item.getByteArray(), item.getStartOffset(), item.getLength(), addedItem.getByteArray(), addedItem.getStartOffset(), addedItem.getLength()) == 0 || isNullAndMissing(item, addedItem)) {
                addItem = false;
                break;
            }
        }
        if (addItem) {
            listBuilder.addItem(item);
            distinct.add(item);
        }
    }
}
#method_after
@Override
protected void processList(ListAccessor listAccessor, IAsterixListBuilder listBuilder) throws IOException {
    int hash;
    boolean itemInStorage;
    boolean nullMissingWasAdded = false;
    List<IPointable> sameHashes;
    hashes.clear();
    for (int i = 0; i < listAccessor.size(); i++) {
        // get the item and compute its hash
        itemInStorage = listAccessor.getOrWriteItem(i, item, storage);
        if (ATYPETAGDESERIALIZER.deserialize(item.getByteArray()[item.getStartOffset()]).isDerivedType()) {
            throw new RuntimeDataException(ErrorCode.CANNOT_COMPARE_COMPLEX, sourceLoc);
        }
        if (isNullOrMissing(item)) {
            if (!nullMissingWasAdded) {
                listBuilder.addItem(item);
                nullMissingWasAdded = true;
            }
        } else {
            // look up if it already exists
            hash = binaryHashFunction.hash(item.getByteArray(), item.getStartOffset(), item.getLength());
            hashes.get(hash);
            sameHashes = hashes.get(hash);
            if (sameHashes == null) {
                // new item
                sameHashes = arrayListAllocator.allocate(null);
                sameHashes.clear();
                addItem(item, listBuilder, itemInStorage, sameHashes);
                hashes.put(hash, sameHashes);
                item = pointableAllocator.allocateEmpty();
            } else {
                // check if it happens that two hashes are the same but they are for different items
                if (isNewItem(item, sameHashes)) {
                    addItem(item, listBuilder, itemInStorage, sameHashes);
                    item = pointableAllocator.allocateEmpty();
                }
            }
        }
    }
}
#end_block

#method_before
@Override
public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException {
    // get the list argument and make sure it's a list
    listArgEval.evaluate(tuple, listArg);
    byte listArgType = listArg.getByteArray()[listArg.getStartOffset()];
    if (listArgType == ATypeTag.SERIALIZED_MISSING_TYPE_TAG) {
        PointableHelper.setMissing(result);
        return;
    }
    // create the new list with the same type as the input list
    IAsterixListBuilder listBuilder;
    if (listArgType == ATypeTag.SERIALIZED_ORDEREDLIST_TYPE_TAG) {
        listBuilder = new OrderedListBuilder();
    } else if (listArgType == ATypeTag.SERIALIZED_UNORDEREDLIST_TYPE_TAG) {
        listBuilder = new UnorderedListBuilder();
    } else {
        PointableHelper.setNull(result);
        return;
    }
    listBuilder.reset((AbstractCollectionType) inputListType);
    listAccessor.reset(listArg.getByteArray(), listArg.getStartOffset());
    try {
        processList(listAccessor, listBuilder);
        storage.reset();
        listBuilder.write(storage.getDataOutput(), true);
        result.set(storage);
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    }
}
#method_after
@Override
public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException {
    // get the list argument and make sure it's a list
    listArgEval.evaluate(tuple, listArg);
    byte listArgType = listArg.getByteArray()[listArg.getStartOffset()];
    // create the new list with the same type as the input list
    IAsterixListBuilder listBuilder;
    if (listArgType == ATypeTag.SERIALIZED_ORDEREDLIST_TYPE_TAG) {
        if (orderedListBuilder == null) {
            orderedListBuilder = new OrderedListBuilder();
        }
        listBuilder = orderedListBuilder;
    } else if (listArgType == ATypeTag.SERIALIZED_UNORDEREDLIST_TYPE_TAG) {
        if (unorderedListBuilder == null) {
            unorderedListBuilder = new UnorderedListBuilder();
        }
        listBuilder = unorderedListBuilder;
    } else {
        PointableHelper.setNull(result);
        return;
    }
    listAccessor.reset(listArg.getByteArray(), listArg.getStartOffset());
    AbstractCollectionType outputListType;
    if (!inputListType.getTypeTag().isListType()) {
        ATypeTag itemType = listAccessor.getItemType();
        if (listAccessor.getListType() == ATypeTag.ARRAY) {
            outputListType = new AOrderedListType(TypeTagUtil.getBuiltinTypeByTag(itemType), null);
        } else {
            outputListType = new AUnorderedListType(TypeTagUtil.getBuiltinTypeByTag(itemType), null);
        }
    } else {
        outputListType = (AbstractCollectionType) inputListType;
    }
    listBuilder.reset(outputListType);
    try {
        processList(listAccessor, listBuilder);
        storage.reset();
        listBuilder.write(storage.getDataOutput(), true);
        result.set(storage);
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    } finally {
        pointableAllocator.reset();
        storageAllocator.reset();
        arrayListAllocator.reset();
    }
}
#end_block

#method_before
public static FunctionCollection createDefaultFunctionCollection() {
    FunctionCollection fc = new FunctionCollection();
    // array functions
    fc.addGenerated(ArrayAppendDescriptor.FACTORY);
    fc.addGenerated(ArrayPositionDescriptor.FACTORY);
    fc.addGenerated(ArrayRepeatDescriptor.FACTORY);
    fc.addGenerated(ArrayContainsDescriptor.FACTORY);
    fc.add(ArrayReverseDescriptor.FACTORY);
    fc.add(ArraySortDescriptor.FACTORY);
    fc.add(ArrayDistinctDescriptor.FACTORY);
    // unnesting functions
    fc.add(TidRunningAggregateDescriptor.FACTORY);
    fc.add(ScanCollectionDescriptor.FACTORY);
    fc.add(RangeDescriptor.FACTORY);
    fc.add(SubsetCollectionDescriptor.FACTORY);
    // aggregate functions
    fc.add(ListifyAggregateDescriptor.FACTORY);
    fc.add(CountAggregateDescriptor.FACTORY);
    fc.add(AvgAggregateDescriptor.FACTORY);
    fc.add(LocalAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SumAggregateDescriptor.FACTORY);
    fc.add(LocalSumAggregateDescriptor.FACTORY);
    fc.add(MaxAggregateDescriptor.FACTORY);
    fc.add(LocalMaxAggregateDescriptor.FACTORY);
    fc.add(MinAggregateDescriptor.FACTORY);
    fc.add(LocalMinAggregateDescriptor.FACTORY);
    fc.add(FirstElementAggregateDescriptor.FACTORY);
    fc.add(LocalFirstElementAggregateDescriptor.FACTORY);
    // serializable aggregates
    fc.add(SerializableCountAggregateDescriptor.FACTORY);
    fc.add(SerializableAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSumAggregateDescriptor.FACTORY);
    // scalar aggregates
    fc.add(ScalarCountAggregateDescriptor.FACTORY);
    fc.add(ScalarAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSumAggregateDescriptor.FACTORY);
    fc.add(ScalarMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarMinAggregateDescriptor.FACTORY);
    fc.add(EmptyStreamAggregateDescriptor.FACTORY);
    fc.add(NonEmptyStreamAggregateDescriptor.FACTORY);
    // SQL aggregates
    fc.add(SqlCountAggregateDescriptor.FACTORY);
    fc.add(SqlAvgAggregateDescriptor.FACTORY);
    fc.add(LocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SqlSumAggregateDescriptor.FACTORY);
    fc.add(LocalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SqlMaxAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMaxAggregateDescriptor.FACTORY);
    fc.add(SqlMinAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMinAggregateDescriptor.FACTORY);
    // SQL serializable aggregates
    fc.add(SerializableSqlCountAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlSumAggregateDescriptor.FACTORY);
    // SQL scalar aggregates
    fc.add(ScalarSqlCountAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlSumAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMinAggregateDescriptor.FACTORY);
    // boolean functions
    fc.add(AndDescriptor.FACTORY);
    fc.add(OrDescriptor.FACTORY);
    // Record constructors / functions
    fc.add(ClosedRecordConstructorDescriptor.FACTORY);
    fc.add(OpenRecordConstructorDescriptor.FACTORY);
    fc.add(RecordConcatDescriptor.FACTORY);
    fc.add(RecordConcatStrictDescriptor.FACTORY);
    // List constructors
    fc.add(OrderedListConstructorDescriptor.FACTORY);
    fc.add(UnorderedListConstructorDescriptor.FACTORY);
    // Sleep function
    fc.add(SleepDescriptor.FACTORY);
    // Inject failure function
    fc.add(InjectFailureDescriptor.FACTORY);
    // Get Job Parameter function
    fc.add(GetJobParameterByNameDescriptor.FACTORY);
    // Switch case
    fc.add(SwitchCaseDescriptor.FACTORY);
    // null functions
    fc.add(IsMissingDescriptor.FACTORY);
    fc.add(IsNullDescriptor.FACTORY);
    fc.add(IsUnknownDescriptor.FACTORY);
    fc.add(IsSystemNullDescriptor.FACTORY);
    fc.add(CheckUnknownDescriptor.FACTORY);
    fc.add(IfMissingDescriptor.FACTORY);
    fc.add(IfNullDescriptor.FACTORY);
    fc.add(IfMissingOrNullDescriptor.FACTORY);
    // uuid generators (zero independent functions)
    fc.add(CreateUUIDDescriptor.FACTORY);
    fc.add(UUIDDescriptor.FACTORY);
    fc.add(CreateQueryUIDDescriptor.FACTORY);
    fc.add(RandomDescriptor.FACTORY);
    fc.add(CurrentDateDescriptor.FACTORY);
    fc.add(CurrentTimeDescriptor.FACTORY);
    fc.add(CurrentDateTimeDescriptor.FACTORY);
    // functions that need generated class for null-handling.
    // Element accessors.
    fc.addGenerated(FieldAccessByIndexDescriptor.FACTORY);
    fc.addGenerated(FieldAccessByNameDescriptor.FACTORY);
    fc.addGenerated(FieldAccessNestedDescriptor.FACTORY);
    fc.addGenerated(AnyCollectionMemberDescriptor.FACTORY);
    fc.addGenerated(GetItemDescriptor.FACTORY);
    // Numeric functions
    fc.add(IfInfDescriptor.FACTORY);
    fc.add(IfNanDescriptor.FACTORY);
    fc.add(IfNanOrInfDescriptor.FACTORY);
    fc.addGenerated(NumericUnaryMinusDescriptor.FACTORY);
    fc.addGenerated(NumericAddDescriptor.FACTORY);
    fc.addGenerated(NumericDivideDescriptor.FACTORY);
    fc.addGenerated(NumericDivDescriptor.FACTORY);
    fc.addGenerated(NumericMultiplyDescriptor.FACTORY);
    fc.addGenerated(NumericSubDescriptor.FACTORY);
    fc.addGenerated(NumericModuloDescriptor.FACTORY);
    fc.addGenerated(NumericPowerDescriptor.FACTORY);
    fc.addGenerated(NotDescriptor.FACTORY);
    fc.addGenerated(LenDescriptor.FACTORY);
    fc.addGenerated(NumericAbsDescriptor.FACTORY);
    fc.addGenerated(NumericCeilingDescriptor.FACTORY);
    fc.addGenerated(NumericFloorDescriptor.FACTORY);
    fc.addGenerated(NumericRoundDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEvenDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEven2Descriptor.FACTORY);
    fc.addGenerated(NumericACosDescriptor.FACTORY);
    fc.addGenerated(NumericASinDescriptor.FACTORY);
    fc.addGenerated(NumericATanDescriptor.FACTORY);
    fc.addGenerated(NumericDegreesDescriptor.FACTORY);
    fc.addGenerated(NumericRadiansDescriptor.FACTORY);
    fc.addGenerated(NumericCosDescriptor.FACTORY);
    fc.addGenerated(NumericSinDescriptor.FACTORY);
    fc.addGenerated(NumericTanDescriptor.FACTORY);
    fc.addGenerated(NumericExpDescriptor.FACTORY);
    fc.addGenerated(NumericLnDescriptor.FACTORY);
    fc.addGenerated(NumericLogDescriptor.FACTORY);
    fc.addGenerated(NumericSqrtDescriptor.FACTORY);
    fc.addGenerated(NumericSignDescriptor.FACTORY);
    fc.addGenerated(NumericTruncDescriptor.FACTORY);
    fc.addGenerated(NumericATan2Descriptor.FACTORY);
    // Comparisons.
    fc.addGenerated(EqualsDescriptor.FACTORY);
    fc.addGenerated(GreaterThanDescriptor.FACTORY);
    fc.addGenerated(GreaterThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(LessThanDescriptor.FACTORY);
    fc.addGenerated(LessThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(NotEqualsDescriptor.FACTORY);
    // If-Equals functions
    fc.addGenerated(MissingIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NullIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NanIfEqualsDescriptor.FACTORY);
    fc.addGenerated(PosInfIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NegInfIfEqualsDescriptor.FACTORY);
    // Binary functions
    fc.addGenerated(BinaryLengthDescriptor.FACTORY);
    fc.addGenerated(ParseBinaryDescriptor.FACTORY);
    fc.addGenerated(PrintBinaryDescriptor.FACTORY);
    fc.addGenerated(BinaryConcatDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromToDescriptor.FACTORY);
    fc.addGenerated(FindBinaryDescriptor.FACTORY);
    fc.addGenerated(FindBinaryFromDescriptor.FACTORY);
    // String functions
    fc.addGenerated(StringLikeDescriptor.FACTORY);
    fc.addGenerated(StringContainsDescriptor.FACTORY);
    fc.addGenerated(StringEndsWithDescriptor.FACTORY);
    fc.addGenerated(StringStartsWithDescriptor.FACTORY);
    fc.addGenerated(SubstringDescriptor.FACTORY);
    fc.addGenerated(StringEqualDescriptor.FACTORY);
    fc.addGenerated(StringLowerCaseDescriptor.FACTORY);
    fc.addGenerated(StringUpperCaseDescriptor.FACTORY);
    fc.addGenerated(StringLengthDescriptor.FACTORY);
    fc.addGenerated(Substring2Descriptor.FACTORY);
    fc.addGenerated(SubstringBeforeDescriptor.FACTORY);
    fc.addGenerated(SubstringAfterDescriptor.FACTORY);
    fc.addGenerated(StringToCodePointDescriptor.FACTORY);
    fc.addGenerated(CodePointToStringDescriptor.FACTORY);
    fc.addGenerated(StringConcatDescriptor.FACTORY);
    fc.addGenerated(StringJoinDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceWithFlagsDescriptor.FACTORY);
    fc.addGenerated(StringInitCapDescriptor.FACTORY);
    fc.addGenerated(StringTrimDescriptor.FACTORY);
    fc.addGenerated(StringLTrimDescriptor.FACTORY);
    fc.addGenerated(StringRTrimDescriptor.FACTORY);
    fc.addGenerated(StringTrim2Descriptor.FACTORY);
    fc.addGenerated(StringLTrim2Descriptor.FACTORY);
    fc.addGenerated(StringRTrim2Descriptor.FACTORY);
    fc.addGenerated(StringPositionDescriptor.FACTORY);
    fc.addGenerated(StringRepeatDescriptor.FACTORY);
    fc.addGenerated(StringReplaceDescriptor.FACTORY);
    fc.addGenerated(StringReplaceWithLimitDescriptor.FACTORY);
    fc.addGenerated(StringReverseDescriptor.FACTORY);
    fc.addGenerated(StringSplitDescriptor.FACTORY);
    // Constructors
    fc.addGenerated(ABooleanConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryHexStringConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryBase64StringConstructorDescriptor.FACTORY);
    fc.addGenerated(AStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt8ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt16ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt32ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt64ConstructorDescriptor.FACTORY);
    fc.addGenerated(AFloatConstructorDescriptor.FACTORY);
    fc.addGenerated(ADoubleConstructorDescriptor.FACTORY);
    fc.addGenerated(APointConstructorDescriptor.FACTORY);
    fc.addGenerated(APoint3DConstructorDescriptor.FACTORY);
    fc.addGenerated(ALineConstructorDescriptor.FACTORY);
    fc.addGenerated(APolygonConstructorDescriptor.FACTORY);
    fc.addGenerated(ACircleConstructorDescriptor.FACTORY);
    fc.addGenerated(ARectangleConstructorDescriptor.FACTORY);
    fc.addGenerated(ATimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AYearMonthDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(ADayTimeDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AUUIDFromStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromTimeConstructorDescriptor.FACTORY);
    // Spatial
    fc.addGenerated(CreatePointDescriptor.FACTORY);
    fc.addGenerated(CreateLineDescriptor.FACTORY);
    fc.addGenerated(CreatePolygonDescriptor.FACTORY);
    fc.addGenerated(CreateCircleDescriptor.FACTORY);
    fc.addGenerated(CreateRectangleDescriptor.FACTORY);
    fc.addGenerated(SpatialAreaDescriptor.FACTORY);
    fc.addGenerated(SpatialDistanceDescriptor.FACTORY);
    fc.addGenerated(CreateMBRDescriptor.FACTORY);
    fc.addGenerated(SpatialCellDescriptor.FACTORY);
    fc.addGenerated(PointXCoordinateAccessor.FACTORY);
    fc.addGenerated(PointYCoordinateAccessor.FACTORY);
    fc.addGenerated(CircleRadiusAccessor.FACTORY);
    fc.addGenerated(CircleCenterAccessor.FACTORY);
    fc.addGenerated(LineRectanglePolygonAccessor.FACTORY);
    // full-text function
    fc.addGenerated(FullTextContainsDescriptor.FACTORY);
    fc.addGenerated(FullTextContainsWithoutOptionDescriptor.FACTORY);
    // Record functions.
    fc.addGenerated(GetRecordFieldsDescriptor.FACTORY);
    fc.addGenerated(GetRecordFieldValueDescriptor.FACTORY);
    fc.addGenerated(DeepEqualityDescriptor.FACTORY);
    fc.addGenerated(RecordMergeDescriptor.FACTORY);
    fc.addGenerated(RecordAddFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordLengthDescriptor.FACTORY);
    fc.addGenerated(RecordNamesDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveDescriptor.FACTORY);
    fc.addGenerated(RecordRenameDescriptor.FACTORY);
    fc.addGenerated(RecordUnwrapDescriptor.FACTORY);
    fc.add(RecordReplaceDescriptor.FACTORY);
    fc.add(RecordAddDescriptor.FACTORY);
    fc.add(RecordPutDescriptor.FACTORY);
    fc.addGenerated(RecordValuesDescriptor.FACTORY);
    fc.addGenerated(PairsDescriptor.FACTORY);
    // Spatial and temporal type accessors
    fc.addGenerated(TemporalYearAccessor.FACTORY);
    fc.addGenerated(TemporalMonthAccessor.FACTORY);
    fc.addGenerated(TemporalDayAccessor.FACTORY);
    fc.addGenerated(TemporalHourAccessor.FACTORY);
    fc.addGenerated(TemporalMinuteAccessor.FACTORY);
    fc.addGenerated(TemporalSecondAccessor.FACTORY);
    fc.addGenerated(TemporalMillisecondAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDatetimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDatetimeAccessor.FACTORY);
    // Temporal functions
    fc.addGenerated(UnixTimeFromDateInDaysDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromTimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DateFromUnixTimeInDaysDescriptor.FACTORY);
    fc.addGenerated(DateFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(TimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(TimeFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromDateAndTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDurationFromDateTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDuartionFromDateDescriptor.FACTORY);
    fc.addGenerated(AdjustDateTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(AdjustTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(IntervalBeforeDescriptor.FACTORY);
    fc.addGenerated(IntervalAfterDescriptor.FACTORY);
    fc.addGenerated(IntervalMeetsDescriptor.FACTORY);
    fc.addGenerated(IntervalMetByDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlapsDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlappedByDescriptor.FACTORY);
    fc.addGenerated(OverlapDescriptor.FACTORY);
    fc.addGenerated(IntervalStartsDescriptor.FACTORY);
    fc.addGenerated(IntervalStartedByDescriptor.FACTORY);
    fc.addGenerated(IntervalCoversDescriptor.FACTORY);
    fc.addGenerated(IntervalCoveredByDescriptor.FACTORY);
    fc.addGenerated(IntervalEndsDescriptor.FACTORY);
    fc.addGenerated(IntervalEndedByDescriptor.FACTORY);
    fc.addGenerated(DurationFromMillisecondsDescriptor.FACTORY);
    fc.addGenerated(DurationFromMonthsDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(MonthsFromYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(MillisecondsFromDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(DurationEqualDescriptor.FACTORY);
    fc.addGenerated(GetYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(GetDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(IntervalBinDescriptor.FACTORY);
    fc.addGenerated(OverlapBinsDescriptor.FACTORY);
    fc.addGenerated(DayOfWeekDescriptor.FACTORY);
    fc.addGenerated(ParseDateDescriptor.FACTORY);
    fc.addGenerated(ParseTimeDescriptor.FACTORY);
    fc.addGenerated(ParseDateTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateDescriptor.FACTORY);
    fc.addGenerated(PrintTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateTimeDescriptor.FACTORY);
    fc.addGenerated(GetOverlappingIntervalDescriptor.FACTORY);
    fc.addGenerated(DurationFromIntervalDescriptor.FACTORY);
    // Type functions.
    fc.addGenerated(IsArrayDescriptor.FACTORY);
    fc.addGenerated(IsAtomicDescriptor.FACTORY);
    fc.addGenerated(IsBooleanDescriptor.FACTORY);
    fc.addGenerated(IsNumberDescriptor.FACTORY);
    fc.addGenerated(IsObjectDescriptor.FACTORY);
    fc.addGenerated(IsStringDescriptor.FACTORY);
    fc.addGenerated(ToArrayDescriptor.FACTORY);
    fc.addGenerated(ToAtomicDescriptor.FACTORY);
    fc.addGenerated(ToBigIntDescriptor.FACTORY);
    fc.addGenerated(ToBooleanDescriptor.FACTORY);
    fc.addGenerated(ToDoubleDescriptor.FACTORY);
    fc.addGenerated(ToNumberDescriptor.FACTORY);
    fc.addGenerated(ToObjectDescriptor.FACTORY);
    fc.addGenerated(ToStringDescriptor.FACTORY);
    // Cast function
    fc.addGenerated(CastTypeDescriptor.FACTORY);
    fc.addGenerated(CastTypeLaxDescriptor.FACTORY);
    // Record function
    fc.addGenerated(RecordPairsDescriptor.FACTORY);
    // Other functions
    fc.addGenerated(RandomWithSeedDescriptor.FACTORY);
    ServiceLoader.load(IFunctionRegistrant.class).iterator().forEachRemaining(c -> c.register(fc));
    return fc;
}
#method_after
public static FunctionCollection createDefaultFunctionCollection() {
    FunctionCollection fc = new FunctionCollection();
    // array functions
    fc.add(ArrayRemoveDescriptor.FACTORY);
    fc.add(ArrayPutDescriptor.FACTORY);
    fc.add(ArrayPrependDescriptor.FACTORY);
    fc.add(ArrayAppendDescriptor.FACTORY);
    fc.add(ArrayInsertDescriptor.FACTORY);
    fc.addGenerated(ArrayPositionDescriptor.FACTORY);
    fc.addGenerated(ArrayRepeatDescriptor.FACTORY);
    fc.addGenerated(ArrayContainsDescriptor.FACTORY);
    fc.addGenerated(ArrayReverseDescriptor.FACTORY);
    fc.addGenerated(ArraySortDescriptor.FACTORY);
    fc.addGenerated(ArrayDistinctDescriptor.FACTORY);
    // unnesting functions
    fc.add(TidRunningAggregateDescriptor.FACTORY);
    fc.add(ScanCollectionDescriptor.FACTORY);
    fc.add(RangeDescriptor.FACTORY);
    fc.add(SubsetCollectionDescriptor.FACTORY);
    // aggregate functions
    fc.add(ListifyAggregateDescriptor.FACTORY);
    fc.add(CountAggregateDescriptor.FACTORY);
    fc.add(AvgAggregateDescriptor.FACTORY);
    fc.add(LocalAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SumAggregateDescriptor.FACTORY);
    fc.add(LocalSumAggregateDescriptor.FACTORY);
    fc.add(MaxAggregateDescriptor.FACTORY);
    fc.add(LocalMaxAggregateDescriptor.FACTORY);
    fc.add(MinAggregateDescriptor.FACTORY);
    fc.add(LocalMinAggregateDescriptor.FACTORY);
    fc.add(FirstElementAggregateDescriptor.FACTORY);
    fc.add(LocalFirstElementAggregateDescriptor.FACTORY);
    // serializable aggregates
    fc.add(SerializableCountAggregateDescriptor.FACTORY);
    fc.add(SerializableAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSumAggregateDescriptor.FACTORY);
    // scalar aggregates
    fc.add(ScalarCountAggregateDescriptor.FACTORY);
    fc.add(ScalarAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSumAggregateDescriptor.FACTORY);
    fc.add(ScalarMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarMinAggregateDescriptor.FACTORY);
    fc.add(EmptyStreamAggregateDescriptor.FACTORY);
    fc.add(NonEmptyStreamAggregateDescriptor.FACTORY);
    // SQL aggregates
    fc.add(SqlCountAggregateDescriptor.FACTORY);
    fc.add(SqlAvgAggregateDescriptor.FACTORY);
    fc.add(LocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SqlSumAggregateDescriptor.FACTORY);
    fc.add(LocalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SqlMaxAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMaxAggregateDescriptor.FACTORY);
    fc.add(SqlMinAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMinAggregateDescriptor.FACTORY);
    // SQL serializable aggregates
    fc.add(SerializableSqlCountAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlSumAggregateDescriptor.FACTORY);
    // SQL scalar aggregates
    fc.add(ScalarSqlCountAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlSumAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMinAggregateDescriptor.FACTORY);
    // boolean functions
    fc.add(AndDescriptor.FACTORY);
    fc.add(OrDescriptor.FACTORY);
    // Record constructors / functions
    fc.add(ClosedRecordConstructorDescriptor.FACTORY);
    fc.add(OpenRecordConstructorDescriptor.FACTORY);
    fc.add(RecordConcatDescriptor.FACTORY);
    fc.add(RecordConcatStrictDescriptor.FACTORY);
    // List constructors
    fc.add(OrderedListConstructorDescriptor.FACTORY);
    fc.add(UnorderedListConstructorDescriptor.FACTORY);
    // Sleep function
    fc.add(SleepDescriptor.FACTORY);
    // Inject failure function
    fc.add(InjectFailureDescriptor.FACTORY);
    // Get Job Parameter function
    fc.add(GetJobParameterByNameDescriptor.FACTORY);
    // Switch case
    fc.add(SwitchCaseDescriptor.FACTORY);
    // null functions
    fc.add(IsMissingDescriptor.FACTORY);
    fc.add(IsNullDescriptor.FACTORY);
    fc.add(IsUnknownDescriptor.FACTORY);
    fc.add(IsSystemNullDescriptor.FACTORY);
    fc.add(CheckUnknownDescriptor.FACTORY);
    fc.add(IfMissingDescriptor.FACTORY);
    fc.add(IfNullDescriptor.FACTORY);
    fc.add(IfMissingOrNullDescriptor.FACTORY);
    // uuid generators (zero independent functions)
    fc.add(CreateUUIDDescriptor.FACTORY);
    fc.add(UUIDDescriptor.FACTORY);
    fc.add(CreateQueryUIDDescriptor.FACTORY);
    fc.add(RandomDescriptor.FACTORY);
    fc.add(CurrentDateDescriptor.FACTORY);
    fc.add(CurrentTimeDescriptor.FACTORY);
    fc.add(CurrentDateTimeDescriptor.FACTORY);
    // functions that need generated class for null-handling.
    // Element accessors.
    fc.addGenerated(FieldAccessByIndexDescriptor.FACTORY);
    fc.addGenerated(FieldAccessByNameDescriptor.FACTORY);
    fc.addGenerated(FieldAccessNestedDescriptor.FACTORY);
    fc.addGenerated(AnyCollectionMemberDescriptor.FACTORY);
    fc.addGenerated(GetItemDescriptor.FACTORY);
    // Numeric functions
    fc.add(IfInfDescriptor.FACTORY);
    fc.add(IfNanDescriptor.FACTORY);
    fc.add(IfNanOrInfDescriptor.FACTORY);
    fc.addGenerated(NumericUnaryMinusDescriptor.FACTORY);
    fc.addGenerated(NumericAddDescriptor.FACTORY);
    fc.addGenerated(NumericDivideDescriptor.FACTORY);
    fc.addGenerated(NumericDivDescriptor.FACTORY);
    fc.addGenerated(NumericMultiplyDescriptor.FACTORY);
    fc.addGenerated(NumericSubDescriptor.FACTORY);
    fc.addGenerated(NumericModuloDescriptor.FACTORY);
    fc.addGenerated(NumericPowerDescriptor.FACTORY);
    fc.addGenerated(NotDescriptor.FACTORY);
    fc.addGenerated(LenDescriptor.FACTORY);
    fc.addGenerated(NumericAbsDescriptor.FACTORY);
    fc.addGenerated(NumericCeilingDescriptor.FACTORY);
    fc.addGenerated(NumericFloorDescriptor.FACTORY);
    fc.addGenerated(NumericRoundDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEvenDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEven2Descriptor.FACTORY);
    fc.addGenerated(NumericACosDescriptor.FACTORY);
    fc.addGenerated(NumericASinDescriptor.FACTORY);
    fc.addGenerated(NumericATanDescriptor.FACTORY);
    fc.addGenerated(NumericDegreesDescriptor.FACTORY);
    fc.addGenerated(NumericRadiansDescriptor.FACTORY);
    fc.addGenerated(NumericCosDescriptor.FACTORY);
    fc.addGenerated(NumericSinDescriptor.FACTORY);
    fc.addGenerated(NumericTanDescriptor.FACTORY);
    fc.addGenerated(NumericExpDescriptor.FACTORY);
    fc.addGenerated(NumericLnDescriptor.FACTORY);
    fc.addGenerated(NumericLogDescriptor.FACTORY);
    fc.addGenerated(NumericSqrtDescriptor.FACTORY);
    fc.addGenerated(NumericSignDescriptor.FACTORY);
    fc.addGenerated(NumericTruncDescriptor.FACTORY);
    fc.addGenerated(NumericATan2Descriptor.FACTORY);
    // Comparisons.
    fc.addGenerated(EqualsDescriptor.FACTORY);
    fc.addGenerated(GreaterThanDescriptor.FACTORY);
    fc.addGenerated(GreaterThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(LessThanDescriptor.FACTORY);
    fc.addGenerated(LessThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(NotEqualsDescriptor.FACTORY);
    // If-Equals functions
    fc.addGenerated(MissingIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NullIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NanIfEqualsDescriptor.FACTORY);
    fc.addGenerated(PosInfIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NegInfIfEqualsDescriptor.FACTORY);
    // Binary functions
    fc.addGenerated(BinaryLengthDescriptor.FACTORY);
    fc.addGenerated(ParseBinaryDescriptor.FACTORY);
    fc.addGenerated(PrintBinaryDescriptor.FACTORY);
    fc.addGenerated(BinaryConcatDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromToDescriptor.FACTORY);
    fc.addGenerated(FindBinaryDescriptor.FACTORY);
    fc.addGenerated(FindBinaryFromDescriptor.FACTORY);
    // String functions
    fc.addGenerated(StringLikeDescriptor.FACTORY);
    fc.addGenerated(StringContainsDescriptor.FACTORY);
    fc.addGenerated(StringEndsWithDescriptor.FACTORY);
    fc.addGenerated(StringStartsWithDescriptor.FACTORY);
    fc.addGenerated(SubstringDescriptor.FACTORY);
    fc.addGenerated(StringEqualDescriptor.FACTORY);
    fc.addGenerated(StringLowerCaseDescriptor.FACTORY);
    fc.addGenerated(StringUpperCaseDescriptor.FACTORY);
    fc.addGenerated(StringLengthDescriptor.FACTORY);
    fc.addGenerated(Substring2Descriptor.FACTORY);
    fc.addGenerated(SubstringBeforeDescriptor.FACTORY);
    fc.addGenerated(SubstringAfterDescriptor.FACTORY);
    fc.addGenerated(StringToCodePointDescriptor.FACTORY);
    fc.addGenerated(CodePointToStringDescriptor.FACTORY);
    fc.addGenerated(StringConcatDescriptor.FACTORY);
    fc.addGenerated(StringJoinDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceWithFlagsDescriptor.FACTORY);
    fc.addGenerated(StringInitCapDescriptor.FACTORY);
    fc.addGenerated(StringTrimDescriptor.FACTORY);
    fc.addGenerated(StringLTrimDescriptor.FACTORY);
    fc.addGenerated(StringRTrimDescriptor.FACTORY);
    fc.addGenerated(StringTrim2Descriptor.FACTORY);
    fc.addGenerated(StringLTrim2Descriptor.FACTORY);
    fc.addGenerated(StringRTrim2Descriptor.FACTORY);
    fc.addGenerated(StringPositionDescriptor.FACTORY);
    fc.addGenerated(StringRepeatDescriptor.FACTORY);
    fc.addGenerated(StringReplaceDescriptor.FACTORY);
    fc.addGenerated(StringReplaceWithLimitDescriptor.FACTORY);
    fc.addGenerated(StringReverseDescriptor.FACTORY);
    fc.addGenerated(StringSplitDescriptor.FACTORY);
    // Constructors
    fc.addGenerated(ABooleanConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryHexStringConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryBase64StringConstructorDescriptor.FACTORY);
    fc.addGenerated(AStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt8ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt16ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt32ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt64ConstructorDescriptor.FACTORY);
    fc.addGenerated(AFloatConstructorDescriptor.FACTORY);
    fc.addGenerated(ADoubleConstructorDescriptor.FACTORY);
    fc.addGenerated(APointConstructorDescriptor.FACTORY);
    fc.addGenerated(APoint3DConstructorDescriptor.FACTORY);
    fc.addGenerated(ALineConstructorDescriptor.FACTORY);
    fc.addGenerated(APolygonConstructorDescriptor.FACTORY);
    fc.addGenerated(ACircleConstructorDescriptor.FACTORY);
    fc.addGenerated(ARectangleConstructorDescriptor.FACTORY);
    fc.addGenerated(ATimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AYearMonthDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(ADayTimeDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AUUIDFromStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromTimeConstructorDescriptor.FACTORY);
    // Spatial
    fc.addGenerated(CreatePointDescriptor.FACTORY);
    fc.addGenerated(CreateLineDescriptor.FACTORY);
    fc.addGenerated(CreatePolygonDescriptor.FACTORY);
    fc.addGenerated(CreateCircleDescriptor.FACTORY);
    fc.addGenerated(CreateRectangleDescriptor.FACTORY);
    fc.addGenerated(SpatialAreaDescriptor.FACTORY);
    fc.addGenerated(SpatialDistanceDescriptor.FACTORY);
    fc.addGenerated(CreateMBRDescriptor.FACTORY);
    fc.addGenerated(SpatialCellDescriptor.FACTORY);
    fc.addGenerated(PointXCoordinateAccessor.FACTORY);
    fc.addGenerated(PointYCoordinateAccessor.FACTORY);
    fc.addGenerated(CircleRadiusAccessor.FACTORY);
    fc.addGenerated(CircleCenterAccessor.FACTORY);
    fc.addGenerated(LineRectanglePolygonAccessor.FACTORY);
    // full-text function
    fc.addGenerated(FullTextContainsDescriptor.FACTORY);
    fc.addGenerated(FullTextContainsWithoutOptionDescriptor.FACTORY);
    // Record functions.
    fc.addGenerated(GetRecordFieldsDescriptor.FACTORY);
    fc.addGenerated(GetRecordFieldValueDescriptor.FACTORY);
    fc.addGenerated(DeepEqualityDescriptor.FACTORY);
    fc.addGenerated(RecordMergeDescriptor.FACTORY);
    fc.addGenerated(RecordAddFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordLengthDescriptor.FACTORY);
    fc.addGenerated(RecordNamesDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveDescriptor.FACTORY);
    fc.addGenerated(RecordRenameDescriptor.FACTORY);
    fc.addGenerated(RecordUnwrapDescriptor.FACTORY);
    fc.add(RecordReplaceDescriptor.FACTORY);
    fc.add(RecordAddDescriptor.FACTORY);
    fc.add(RecordPutDescriptor.FACTORY);
    fc.addGenerated(RecordValuesDescriptor.FACTORY);
    fc.addGenerated(PairsDescriptor.FACTORY);
    // Spatial and temporal type accessors
    fc.addGenerated(TemporalYearAccessor.FACTORY);
    fc.addGenerated(TemporalMonthAccessor.FACTORY);
    fc.addGenerated(TemporalDayAccessor.FACTORY);
    fc.addGenerated(TemporalHourAccessor.FACTORY);
    fc.addGenerated(TemporalMinuteAccessor.FACTORY);
    fc.addGenerated(TemporalSecondAccessor.FACTORY);
    fc.addGenerated(TemporalMillisecondAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDatetimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDatetimeAccessor.FACTORY);
    // Temporal functions
    fc.addGenerated(UnixTimeFromDateInDaysDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromTimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DateFromUnixTimeInDaysDescriptor.FACTORY);
    fc.addGenerated(DateFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(TimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(TimeFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromDateAndTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDurationFromDateTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDuartionFromDateDescriptor.FACTORY);
    fc.addGenerated(AdjustDateTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(AdjustTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(IntervalBeforeDescriptor.FACTORY);
    fc.addGenerated(IntervalAfterDescriptor.FACTORY);
    fc.addGenerated(IntervalMeetsDescriptor.FACTORY);
    fc.addGenerated(IntervalMetByDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlapsDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlappedByDescriptor.FACTORY);
    fc.addGenerated(OverlapDescriptor.FACTORY);
    fc.addGenerated(IntervalStartsDescriptor.FACTORY);
    fc.addGenerated(IntervalStartedByDescriptor.FACTORY);
    fc.addGenerated(IntervalCoversDescriptor.FACTORY);
    fc.addGenerated(IntervalCoveredByDescriptor.FACTORY);
    fc.addGenerated(IntervalEndsDescriptor.FACTORY);
    fc.addGenerated(IntervalEndedByDescriptor.FACTORY);
    fc.addGenerated(DurationFromMillisecondsDescriptor.FACTORY);
    fc.addGenerated(DurationFromMonthsDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(MonthsFromYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(MillisecondsFromDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(DurationEqualDescriptor.FACTORY);
    fc.addGenerated(GetYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(GetDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(IntervalBinDescriptor.FACTORY);
    fc.addGenerated(OverlapBinsDescriptor.FACTORY);
    fc.addGenerated(DayOfWeekDescriptor.FACTORY);
    fc.addGenerated(ParseDateDescriptor.FACTORY);
    fc.addGenerated(ParseTimeDescriptor.FACTORY);
    fc.addGenerated(ParseDateTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateDescriptor.FACTORY);
    fc.addGenerated(PrintTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateTimeDescriptor.FACTORY);
    fc.addGenerated(GetOverlappingIntervalDescriptor.FACTORY);
    fc.addGenerated(DurationFromIntervalDescriptor.FACTORY);
    // Type functions.
    fc.addGenerated(IsArrayDescriptor.FACTORY);
    fc.addGenerated(IsAtomicDescriptor.FACTORY);
    fc.addGenerated(IsBooleanDescriptor.FACTORY);
    fc.addGenerated(IsNumberDescriptor.FACTORY);
    fc.addGenerated(IsObjectDescriptor.FACTORY);
    fc.addGenerated(IsStringDescriptor.FACTORY);
    fc.addGenerated(ToArrayDescriptor.FACTORY);
    fc.addGenerated(ToAtomicDescriptor.FACTORY);
    fc.addGenerated(ToBigIntDescriptor.FACTORY);
    fc.addGenerated(ToBooleanDescriptor.FACTORY);
    fc.addGenerated(ToDoubleDescriptor.FACTORY);
    fc.addGenerated(ToNumberDescriptor.FACTORY);
    fc.addGenerated(ToObjectDescriptor.FACTORY);
    fc.addGenerated(ToStringDescriptor.FACTORY);
    // Cast function
    fc.addGenerated(CastTypeDescriptor.FACTORY);
    fc.addGenerated(CastTypeLaxDescriptor.FACTORY);
    // Record function
    fc.addGenerated(RecordPairsDescriptor.FACTORY);
    // Other functions
    fc.addGenerated(RandomWithSeedDescriptor.FACTORY);
    ServiceLoader.load(IFunctionRegistrant.class).iterator().forEachRemaining(c -> c.register(fc));
    return fc;
}
#end_block

#method_before
@Override
protected void processList(ListAccessor listAccessor, IAsterixListBuilder listBuilder) throws IOException {
    // get the list items in reverse and append to the new list
    for (int i = listAccessor.size() - 1; i >= 0; i--) {
        storage.reset();
        listAccessor.writeItem(i, storage.getDataOutput());
        listBuilder.addItem(storage);
    }
}
#method_after
@Override
protected void processList(ListAccessor listAccessor, IAsterixListBuilder listBuilder) throws IOException {
    // get the list items in reverse and append to the new list
    for (int i = listAccessor.size() - 1; i >= 0; i--) {
        listAccessor.getOrWriteItem(i, item, storage);
        listBuilder.addItem(item);
    }
}
#end_block

#method_before
@Override
protected void processList(ListAccessor listAccessor, IAsterixListBuilder listBuilder) throws IOException {
    ArrayBackedValueStorage item;
    for (int i = 0; i < listAccessor.size(); i++) {
        item = new ArrayBackedValueStorage();
        listAccessor.writeItem(i, item.getDataOutput());
        if (ATYPETAGDESERIALIZER.deserialize(item.getByteArray()[item.getStartOffset()]).isDerivedType()) {
            throw HyracksDataException.create(ErrorCode.CANNOT_COMPARE_COMPLEX, sourceLoc);
        }
        sortedList.add(item);
    }
    while (!sortedList.isEmpty()) {
        listBuilder.addItem(sortedList.poll());
    }
}
#method_after
@Override
protected void processList(ListAccessor listAccessor, IAsterixListBuilder listBuilder) throws IOException {
    sortedList.clear();
    boolean itemInStorage;
    for (int i = 0; i < listAccessor.size(); i++) {
        itemInStorage = listAccessor.getOrWriteItem(i, item, storage);
        if (ATYPETAGDESERIALIZER.deserialize(item.getByteArray()[item.getStartOffset()]).isDerivedType()) {
            throw new RuntimeDataException(ErrorCode.CANNOT_COMPARE_COMPLEX, sourceLoc);
        }
        sortedList.add(item);
        if (itemInStorage) {
            storage = (ArrayBackedValueStorage) storageAllocator.allocate(null);
        }
        item = pointableAllocator.allocateEmpty();
    }
    while (!sortedList.isEmpty()) {
        listBuilder.addItem(sortedList.poll());
    }
}
#end_block

#method_before
public static Throwable close(IFrameWriter writer, Throwable root) {
    if (writer != null) {
        try {
            writer.close();
        } catch (Throwable th) {
            // NOSONAR Will be suppressed
            try {
                LOGGER.log(Level.WARN, "Failure closing a closeable resource of class {}", writer.getClass().getName(), th);
            } catch (Throwable loggingFailure) {
            // NOSONAR: Ignore catching Throwable
            // NOSONAR: Ignore logging failure
            }
            // NOSONAR
            root = ExceptionUtils.suppress(root, th);
        }
    }
    return root;
}
#method_after
public static Throwable close(IFrameWriter writer, Throwable root) {
    if (writer != null) {
        try {
            writer.close();
        } catch (Throwable th) {
            // NOSONAR Will be suppressed
            try {
                LOGGER.log(Level.WARN, "Failure closing a closeable resource of class {}", writer.getClass().getSimpleName(), th);
            } catch (Throwable loggingFailure) {
            // NOSONAR: Ignore catching Throwable
            // NOSONAR: Ignore logging failure
            }
            // NOSONAR
            root = ExceptionUtils.suppress(root, th);
        }
    }
    return root;
}
#end_block

#method_before
protected void sendStopMessages(MetadataProvider metadataProvider, long timeout, TimeUnit unit) throws Exception {
    ICcApplicationContext applicationCtx = metadataProvider.getApplicationContext();
    ICCMessageBroker messageBroker = (ICCMessageBroker) applicationCtx.getServiceContext().getMessageBroker();
    AlgebricksAbsolutePartitionConstraint runtimeLocations = getLocations();
    int partition = 0;
    LOGGER.log(Level.INFO, "Sending stop messages to " + runtimeLocations);
    for (String location : runtimeLocations.getLocations()) {
        LOGGER.log(Level.INFO, "Sending to " + location);
        ActiveRuntimeId runtimeId = getActiveRuntimeId(partition++);
        messageBroker.sendApplicationMessageToNC(new ActiveManagerMessage(ActiveManagerMessage.Kind.STOP_ACTIVITY, new StopRuntimeContent(runtimeId, timeout, unit)), location);
    }
}
#method_after
protected void sendStopMessages(MetadataProvider metadataProvider, long timeout, TimeUnit unit) throws Exception {
    ICcApplicationContext applicationCtx = metadataProvider.getApplicationContext();
    ICCMessageBroker messageBroker = (ICCMessageBroker) applicationCtx.getServiceContext().getMessageBroker();
    AlgebricksAbsolutePartitionConstraint runtimeLocations = getLocations();
    int partition = 0;
    LOGGER.log(Level.INFO, "Sending stop messages to " + runtimeLocations);
    for (String location : runtimeLocations.getLocations()) {
        LOGGER.log(Level.INFO, "Sending to " + location);
        ActiveRuntimeId runtimeId = getActiveRuntimeId(partition++);
        messageBroker.sendApplicationMessageToNC(new ActiveManagerMessage(ActiveManagerMessage.Kind.STOP_ACTIVITY, new StopRuntimeParameters(runtimeId, timeout, unit)), location);
    }
}
#end_block

#method_before
private void stopRuntime(ActiveManagerMessage message) {
    StopRuntimeContent content = (StopRuntimeContent) message.getPayload();
    ActiveRuntimeId runtimeId = content.getRuntimeId();
    IActiveRuntime runtime = runtimes.get(runtimeId);
    if (runtime == null) {
        LOGGER.warn("Request to stop runtime: " + runtimeId + " that is not registered. Could be that the runtime completed execution on" + " this node before the cluster controller sent the stop request");
    } else {
        executor.execute(() -> {
            try {
                stopIfRunning(runtime, content.getTimeout(), content.getUnit());
            } catch (Throwable e) {
                // TODO(till) Figure out a better way to handle failure to stop a runtime
                LOGGER.warn("Failed to stop runtime: {}", runtimeId, e);
            }
        });
    }
}
#method_after
// Catch Error
@SuppressWarnings("squid:S1181")
private void stopRuntime(ActiveManagerMessage message) {
    StopRuntimeParameters content = (StopRuntimeParameters) message.getPayload();
    ActiveRuntimeId runtimeId = content.getRuntimeId();
    IActiveRuntime runtime = runtimes.get(runtimeId);
    if (runtime == null) {
        LOGGER.warn("Request to stop runtime: " + runtimeId + " that is not registered. Could be that the runtime completed execution on" + " this node before the cluster controller sent the stop request");
    } else {
        executor.execute(() -> {
            try {
                stopIfRunning(runtime, content.getTimeout(), content.getUnit());
            } catch (Exception e) {
                LOGGER.warn("Failed to stop runtime: {}", runtimeId, e);
            } catch (Throwable th) {
                LOGGER.warn("Failed to stop runtime: {}", runtimeId, th);
                ExitUtil.halt(ExitUtil.EC_UNCAUGHT_THROWABLE);
            }
        });
    }
}
#end_block

#method_before
public JsonNode toJson(IPersistedResourceRegistry registry) throws HyracksDataException {
    final ObjectNode json = registry.getClassIdentifier(getClass(), serialVersionUID);
    json.put("tokenTypeTag", tokenTypeTag);
    json.put("countTypeTag", countTypeTag);
    return json;
}
#method_after
@Override
public JsonNode toJson(IPersistedResourceRegistry registry) throws HyracksDataException {
    final ObjectNode json = registry.getClassIdentifier(getClass(), serialVersionUID);
    json.put("tokenTypeTag", tokenTypeTag);
    json.put("countTypeTag", countTypeTag);
    return json;
}
#end_block

#method_before
@Override
public ITypeTraits getTypeTraits() {
    return VarLengthTypeTrait.INSTANCE;
}
#method_after
@Override
public ITypeTraits getTypeTraits() {
    return TYPE_TRAITS;
}
#end_block

#method_before
@Override
public ITypeTraits getTypeTraits() {
    return VoidPointable.FACTORY.getTypeTraits();
}
#method_after
@Override
public ITypeTraits getTypeTraits() {
    return VoidPointable.TYPE_TRAITS;
}
#end_block

#method_before
protected void registerClasses() {
    /* WARNING: Changing a resource id will break storage format backward compatibility.*/
    REGISTERED_CLASSES.put("Checkpoint", Checkpoint.class);
    // IResource
    REGISTERED_CLASSES.put("LocalResource", LocalResource.class);
    REGISTERED_CLASSES.put("DatasetLocalResource", DatasetLocalResource.class);
    REGISTERED_CLASSES.put("LSMBTreeLocalResource", LSMBTreeLocalResource.class);
    REGISTERED_CLASSES.put("LSMRTreeLocalResource", LSMRTreeLocalResource.class);
    REGISTERED_CLASSES.put("LSMRTreeWithAntiMatterLocalResource", LSMRTreeWithAntiMatterLocalResource.class);
    REGISTERED_CLASSES.put("LSMInvertedIndexLocalResource", LSMInvertedIndexLocalResource.class);
    REGISTERED_CLASSES.put("ExternalBTreeLocalResource", ExternalBTreeLocalResource.class);
    REGISTERED_CLASSES.put("ExternalBTreeWithBuddyLocalResource", ExternalBTreeWithBuddyLocalResource.class);
    REGISTERED_CLASSES.put("ExternalRTreeLocalResource", ExternalRTreeLocalResource.class);
    // ILSMMergePolicyFactory
    REGISTERED_CLASSES.put("NoMergePolicyFactory", NoMergePolicyFactory.class);
    REGISTERED_CLASSES.put("PrefixMergePolicyFactory", PrefixMergePolicyFactory.class);
    REGISTERED_CLASSES.put("ConstantMergePolicyFactory", ConstantMergePolicyFactory.class);
    REGISTERED_CLASSES.put("CorrelatedPrefixMergePolicyFactory", CorrelatedPrefixMergePolicyFactory.class);
    // ILSMIOOperationSchedulerProvider
    REGISTERED_CLASSES.put("RuntimeComponentsProvider", RuntimeComponentsProvider.class);
    // ITypeTraits
    REGISTERED_CLASSES.put("FixedLengthTypeTrait", FixedLengthTypeTrait.class);
    REGISTERED_CLASSES.put("VarLengthTypeTrait", VarLengthTypeTrait.class);
    // ILSMOperationTrackerFactory
    REGISTERED_CLASSES.put("PrimaryIndexOperationTrackerFactory", PrimaryIndexOperationTrackerFactory.class);
    REGISTERED_CLASSES.put("SecondaryIndexOperationTrackerFactory", SecondaryIndexOperationTrackerFactory.class);
    // ILSMComponentIdGeneratorFactory
    REGISTERED_CLASSES.put("DatasetLSMComponentIdGeneratorFactory", DatasetLSMComponentIdGeneratorFactory.class);
    // IDatasetInfoProvider
    REGISTERED_CLASSES.put("DatasetInfoProvider", DatasetInfoProvider.class);
    // ILSMOperationTrackerFactory
    REGISTERED_CLASSES.put("NoOpIOOperationCallbackFactory", NoOpIOOperationCallbackFactory.class);
    REGISTERED_CLASSES.put("LSMBTreeIOOperationCallbackFactory", LSMIndexIOOperationCallbackFactory.class);
    // ILSMIOOperationSchedulerProvider
    REGISTERED_CLASSES.put("AppendOnlyLinkedMetadataPageManagerFactory", AppendOnlyLinkedMetadataPageManagerFactory.class);
    // ILSMIOOperationSchedulerProvider
    REGISTERED_CLASSES.put("AsterixVirtualBufferCacheProvider", AsterixVirtualBufferCacheProvider.class);
    // IBinaryComparatorFactory
    REGISTERED_CLASSES.put("ACirclePartialBinaryComparatorFactory", ACirclePartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("ADurationPartialBinaryComparatorFactory", ADurationPartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("AIntervalAscPartialBinaryComparatorFactory", AIntervalAscPartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("AIntervalDescPartialBinaryComparatorFactory", AIntervalDescPartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("ALinePartialBinaryComparatorFactory", ALinePartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("AObjectAscBinaryComparatorFactory", AObjectAscBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("AObjectDescBinaryComparatorFactory", AObjectDescBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("APoint3DPartialBinaryComparatorFactory", APoint3DPartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("APointPartialBinaryComparatorFactory", APointPartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("APolygonPartialBinaryComparatorFactory", APolygonPartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("ARectanglePartialBinaryComparatorFactory", ARectanglePartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("AUUIDPartialBinaryComparatorFactory", AUUIDPartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("BooleanBinaryComparatorFactory", BooleanBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("ListItemBinaryComparatorFactory", ListItemBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("LongBinaryComparatorFactory", LongBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("RawBinaryComparatorFactory", RawBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("PointableBinaryComparatorFactory", PointableBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("HilbertDoubleComparatorFactory", HilbertDoubleComparatorFactory.class);
    REGISTERED_CLASSES.put("ZCurveDoubleComparatorFactory", ZCurveDoubleComparatorFactory.class);
    REGISTERED_CLASSES.put("ZCurveIntComparatorFactory", ZCurveIntComparatorFactory.class);
    REGISTERED_CLASSES.put("ComponentPosComparatorFactory", SecondaryCorrelatedTreeIndexOperationsHelper.ComponentPosComparatorFactory.class);
    REGISTERED_CLASSES.put("HdfsRawBinaryComparatorFactory", org.apache.hyracks.hdfs.lib.RawBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("AnyBinaryComparatorFactory", AnyBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("OrderedBinaryComparatorFactory", OrderedBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("OrderedLinearizeComparatorFactory", OrderedLinearizeComparatorFactory.class);
    // IPointableFactory
    REGISTERED_CLASSES.put("AIntervalPointableFactory", AIntervalPointable.AIntervalPointableFactory.class);
    REGISTERED_CLASSES.put("AListPointableFactory", AListPointable.AListPointableFactory.class);
    REGISTERED_CLASSES.put("ARecordPointableFactory", ARecordPointable.ARecordPointableFactory.class);
    REGISTERED_CLASSES.put("BooleanPointableFactory", BooleanPointable.BooleanPointableFactory.class);
    REGISTERED_CLASSES.put("ByteArrayPointableFactory", ByteArrayPointable.ByteArrayPointableFactory.class);
    REGISTERED_CLASSES.put("BytePointableFactory", BytePointable.BytePointableFactory.class);
    REGISTERED_CLASSES.put("DoublePointableFactory", DoublePointable.DoublePointableFactory.class);
    REGISTERED_CLASSES.put("FloatPointableFactory", FloatPointable.FloatPointableFactory.class);
    REGISTERED_CLASSES.put("IntegerPointableFactory", IntegerPointable.IntegerPointableFactory.class);
    REGISTERED_CLASSES.put("LongPointableFactory", LongPointable.LongPointableFactory.class);
    REGISTERED_CLASSES.put("RawUTF8StringPointableFactory", RawUTF8StringPointable.RawUTF8StringPointableFactory.class);
    REGISTERED_CLASSES.put("ShortPointableFactory", ShortPointable.ShortPointableFactory.class);
    REGISTERED_CLASSES.put("TaggedValuePointableFactory", TaggedValuePointable.TaggedValuePointableFactory.class);
    REGISTERED_CLASSES.put("UTF8StringLowercasePointableFactory", UTF8StringLowercasePointable.UTF8StringLowercasePointableFactory.class);
    REGISTERED_CLASSES.put("UTF8StringLowercaseTokenPointableFactory", UTF8StringLowercaseTokenPointable.UTF8StringLowercaseTokenPointableFactory.class);
    REGISTERED_CLASSES.put("UTF8StringPointableFactory", UTF8StringPointable.UTF8StringPointableFactory.class);
    REGISTERED_CLASSES.put("VoidPointableFactory", VoidPointable.VoidPointableFactory.class);
    // IPrimitiveValueProviderFactory
    REGISTERED_CLASSES.put("DoublePrimitiveValueProviderFactory", DoublePrimitiveValueProviderFactory.class);
    REGISTERED_CLASSES.put("FloatPrimitiveValueProviderFactory", FloatPrimitiveValueProviderFactory.class);
    REGISTERED_CLASSES.put("IntegerPrimitiveValueProviderFactory", IntegerPrimitiveValueProviderFactory.class);
    REGISTERED_CLASSES.put("PointablePrimitiveValueProviderFactory", PointablePrimitiveValueProviderFactory.class);
    REGISTERED_CLASSES.put("PrimitiveValueProviderFactory", PrimitiveValueProviderFactory.class);
    // IBinaryTokenizerFactory
    REGISTERED_CLASSES.put("AOrderedListBinaryTokenizerFactory", AOrderedListBinaryTokenizerFactory.class);
    REGISTERED_CLASSES.put("AUnorderedListBinaryTokenizerFactory", AUnorderedListBinaryTokenizerFactory.class);
    REGISTERED_CLASSES.put("NGramUTF8StringBinaryTokenizerFactory", NGramUTF8StringBinaryTokenizerFactory.class);
    REGISTERED_CLASSES.put("DelimitedUTF8StringBinaryTokenizerFactory", DelimitedUTF8StringBinaryTokenizerFactory.class);
    // ITokenFactory
    REGISTERED_CLASSES.put("AListElementTokenFactory", AListElementTokenFactory.class);
    REGISTERED_CLASSES.put("HashedUTF8NGramTokenFactory", HashedUTF8NGramTokenFactory.class);
    REGISTERED_CLASSES.put("HashedUTF8WordTokenFactory", HashedUTF8WordTokenFactory.class);
    REGISTERED_CLASSES.put("UTF8NGramTokenFactory", UTF8NGramTokenFactory.class);
    REGISTERED_CLASSES.put("UTF8WordTokenFactory", UTF8WordTokenFactory.class);
    REGISTERED_CLASSES.put("RTreePolicyType", RTreePolicyType.class);
}
#method_after
protected void registerClasses() {
    /* WARNING: Changing a resource id will break storage format backward compatibility.*/
    REGISTERED_CLASSES.put("Checkpoint", Checkpoint.class);
    // IResource
    REGISTERED_CLASSES.put("LocalResource", LocalResource.class);
    REGISTERED_CLASSES.put("DatasetLocalResource", DatasetLocalResource.class);
    REGISTERED_CLASSES.put("LSMBTreeLocalResource", LSMBTreeLocalResource.class);
    REGISTERED_CLASSES.put("LSMRTreeLocalResource", LSMRTreeLocalResource.class);
    REGISTERED_CLASSES.put("LSMRTreeWithAntiMatterLocalResource", LSMRTreeWithAntiMatterLocalResource.class);
    REGISTERED_CLASSES.put("LSMInvertedIndexLocalResource", LSMInvertedIndexLocalResource.class);
    REGISTERED_CLASSES.put("ExternalBTreeLocalResource", ExternalBTreeLocalResource.class);
    REGISTERED_CLASSES.put("ExternalBTreeWithBuddyLocalResource", ExternalBTreeWithBuddyLocalResource.class);
    REGISTERED_CLASSES.put("ExternalRTreeLocalResource", ExternalRTreeLocalResource.class);
    // ILSMMergePolicyFactory
    REGISTERED_CLASSES.put("NoMergePolicyFactory", NoMergePolicyFactory.class);
    REGISTERED_CLASSES.put("PrefixMergePolicyFactory", PrefixMergePolicyFactory.class);
    REGISTERED_CLASSES.put("ConstantMergePolicyFactory", ConstantMergePolicyFactory.class);
    REGISTERED_CLASSES.put("CorrelatedPrefixMergePolicyFactory", CorrelatedPrefixMergePolicyFactory.class);
    // ILSMIOOperationSchedulerProvider
    REGISTERED_CLASSES.put("RuntimeComponentsProvider", RuntimeComponentsProvider.class);
    // ITypeTraits
    REGISTERED_CLASSES.put("FixedLengthTypeTrait", FixedLengthTypeTrait.class);
    REGISTERED_CLASSES.put("VarLengthTypeTrait", VarLengthTypeTrait.class);
    // ILSMOperationTrackerFactory
    REGISTERED_CLASSES.put("PrimaryIndexOperationTrackerFactory", PrimaryIndexOperationTrackerFactory.class);
    REGISTERED_CLASSES.put("SecondaryIndexOperationTrackerFactory", SecondaryIndexOperationTrackerFactory.class);
    // ILSMComponentIdGeneratorFactory
    REGISTERED_CLASSES.put("DatasetLSMComponentIdGeneratorFactory", DatasetLSMComponentIdGeneratorFactory.class);
    // IDatasetInfoProvider
    REGISTERED_CLASSES.put("DatasetInfoProvider", DatasetInfoProvider.class);
    // ILSMOperationTrackerFactory
    REGISTERED_CLASSES.put("NoOpIOOperationCallbackFactory", NoOpIOOperationCallbackFactory.class);
    REGISTERED_CLASSES.put("LSMBTreeIOOperationCallbackFactory", LSMIndexIOOperationCallbackFactory.class);
    // ILSMIOOperationSchedulerProvider
    REGISTERED_CLASSES.put("AppendOnlyLinkedMetadataPageManagerFactory", AppendOnlyLinkedMetadataPageManagerFactory.class);
    // ILSMIOOperationSchedulerProvider
    REGISTERED_CLASSES.put("AsterixVirtualBufferCacheProvider", AsterixVirtualBufferCacheProvider.class);
    // IBinaryComparatorFactory
    REGISTERED_CLASSES.put("ACirclePartialBinaryComparatorFactory", ACirclePartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("ADurationPartialBinaryComparatorFactory", ADurationPartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("AIntervalAscPartialBinaryComparatorFactory", AIntervalAscPartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("AIntervalDescPartialBinaryComparatorFactory", AIntervalDescPartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("ALinePartialBinaryComparatorFactory", ALinePartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("AObjectAscBinaryComparatorFactory", AObjectAscBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("AObjectDescBinaryComparatorFactory", AObjectDescBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("APoint3DPartialBinaryComparatorFactory", APoint3DPartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("APointPartialBinaryComparatorFactory", APointPartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("APolygonPartialBinaryComparatorFactory", APolygonPartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("ARectanglePartialBinaryComparatorFactory", ARectanglePartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("AUUIDPartialBinaryComparatorFactory", AUUIDPartialBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("BooleanBinaryComparatorFactory", BooleanBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("ListItemBinaryComparatorFactory", ListItemBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("LongBinaryComparatorFactory", LongBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("RawBinaryComparatorFactory", RawBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("PointableBinaryComparatorFactory", PointableBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("HilbertDoubleComparatorFactory", HilbertDoubleComparatorFactory.class);
    REGISTERED_CLASSES.put("ZCurveDoubleComparatorFactory", ZCurveDoubleComparatorFactory.class);
    REGISTERED_CLASSES.put("ZCurveIntComparatorFactory", ZCurveIntComparatorFactory.class);
    REGISTERED_CLASSES.put("ComponentPosComparatorFactory", SecondaryCorrelatedTreeIndexOperationsHelper.ComponentPosComparatorFactory.class);
    REGISTERED_CLASSES.put("AnyBinaryComparatorFactory", AnyBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("OrderedBinaryComparatorFactory", OrderedBinaryComparatorFactory.class);
    REGISTERED_CLASSES.put("OrderedLinearizeComparatorFactory", OrderedLinearizeComparatorFactory.class);
    // IPointableFactory
    REGISTERED_CLASSES.put("AIntervalPointableFactory", AIntervalPointable.AIntervalPointableFactory.class);
    REGISTERED_CLASSES.put("AListPointableFactory", AListPointable.AListPointableFactory.class);
    REGISTERED_CLASSES.put("ARecordPointableFactory", ARecordPointable.ARecordPointableFactory.class);
    REGISTERED_CLASSES.put("BooleanPointableFactory", BooleanPointable.BooleanPointableFactory.class);
    REGISTERED_CLASSES.put("ByteArrayPointableFactory", ByteArrayPointable.ByteArrayPointableFactory.class);
    REGISTERED_CLASSES.put("BytePointableFactory", BytePointable.BytePointableFactory.class);
    REGISTERED_CLASSES.put("DoublePointableFactory", DoublePointable.DoublePointableFactory.class);
    REGISTERED_CLASSES.put("FloatPointableFactory", FloatPointable.FloatPointableFactory.class);
    REGISTERED_CLASSES.put("IntegerPointableFactory", IntegerPointable.IntegerPointableFactory.class);
    REGISTERED_CLASSES.put("LongPointableFactory", LongPointable.LongPointableFactory.class);
    REGISTERED_CLASSES.put("RawUTF8StringPointableFactory", RawUTF8StringPointable.RawUTF8StringPointableFactory.class);
    REGISTERED_CLASSES.put("ShortPointableFactory", ShortPointable.ShortPointableFactory.class);
    REGISTERED_CLASSES.put("TaggedValuePointableFactory", TaggedValuePointable.TaggedValuePointableFactory.class);
    REGISTERED_CLASSES.put("UTF8StringLowercasePointableFactory", UTF8StringLowercasePointable.UTF8StringLowercasePointableFactory.class);
    REGISTERED_CLASSES.put("UTF8StringLowercaseTokenPointableFactory", UTF8StringLowercaseTokenPointable.UTF8StringLowercaseTokenPointableFactory.class);
    REGISTERED_CLASSES.put("UTF8StringPointableFactory", UTF8StringPointable.UTF8StringPointableFactory.class);
    REGISTERED_CLASSES.put("VoidPointableFactory", VoidPointable.VoidPointableFactory.class);
    // IPrimitiveValueProviderFactory
    REGISTERED_CLASSES.put("DoublePrimitiveValueProviderFactory", DoublePrimitiveValueProviderFactory.class);
    REGISTERED_CLASSES.put("FloatPrimitiveValueProviderFactory", FloatPrimitiveValueProviderFactory.class);
    REGISTERED_CLASSES.put("IntegerPrimitiveValueProviderFactory", IntegerPrimitiveValueProviderFactory.class);
    REGISTERED_CLASSES.put("PointablePrimitiveValueProviderFactory", PointablePrimitiveValueProviderFactory.class);
    REGISTERED_CLASSES.put("PrimitiveValueProviderFactory", PrimitiveValueProviderFactory.class);
    // IBinaryTokenizerFactory
    REGISTERED_CLASSES.put("AOrderedListBinaryTokenizerFactory", AOrderedListBinaryTokenizerFactory.class);
    REGISTERED_CLASSES.put("AUnorderedListBinaryTokenizerFactory", AUnorderedListBinaryTokenizerFactory.class);
    REGISTERED_CLASSES.put("NGramUTF8StringBinaryTokenizerFactory", NGramUTF8StringBinaryTokenizerFactory.class);
    REGISTERED_CLASSES.put("DelimitedUTF8StringBinaryTokenizerFactory", DelimitedUTF8StringBinaryTokenizerFactory.class);
    // ITokenFactory
    REGISTERED_CLASSES.put("AListElementTokenFactory", AListElementTokenFactory.class);
    REGISTERED_CLASSES.put("HashedUTF8NGramTokenFactory", HashedUTF8NGramTokenFactory.class);
    REGISTERED_CLASSES.put("HashedUTF8WordTokenFactory", HashedUTF8WordTokenFactory.class);
    REGISTERED_CLASSES.put("UTF8NGramTokenFactory", UTF8NGramTokenFactory.class);
    REGISTERED_CLASSES.put("UTF8WordTokenFactory", UTF8WordTokenFactory.class);
    REGISTERED_CLASSES.put("RTreePolicyType", RTreePolicyType.class);
}
#end_block

#method_before
private Class<? extends IJsonSerializable> getResourceClass(String id) {
    REGISTERED_CLASSES.computeIfAbsent(id, key -> {
        throw new IllegalStateException(String.format("No class with id %s was registered.", key));
    });
    return REGISTERED_CLASSES.get(id);
}
#method_after
private Class<? extends IJsonSerializable> getResourceClass(String id) {
    return REGISTERED_CLASSES.computeIfAbsent(id, key -> {
        throw new IllegalStateException(String.format("No class with id %s was registered.", key));
    });
}
#end_block

#method_before
public static ITypeTraits[] serdesToTypeTraits(ISerializerDeserializer[] serdes, int payloadSize) {
    ITypeTraits[] typeTraits = new ITypeTraits[serdes.length + 1];
    for (int i = 0; i < serdes.length; i++) {
        typeTraits[i] = serdeToTypeTrait(serdes[i]);
    }
    typeTraits[serdes.length] = new PayloadTypeTraits(payloadSize);
    return typeTraits;
}
#method_after
public static ITypeTraits[] serdesToTypeTraits(ISerializerDeserializer[] serdes, int payloadSize) {
    ITypeTraits[] typeTraits = new ITypeTraits[serdes.length + 1];
    for (int i = 0; i < serdes.length; i++) {
        typeTraits[i] = serdeToTypeTrait(serdes[i]);
    }
    typeTraits[serdes.length] = new FixedLengthTypeTrait(payloadSize);
    return typeTraits;
}
#end_block

#method_before
protected void appendToJson(final ObjectNode json, IPersistedResourceRegistry registry) throws HyracksDataException {
    json.put("path", path);
    json.set("storageManager", storageManager.toJson(registry));
    ArrayNode ttArray = OBJECT_MAPPER.createArrayNode();
    for (ITypeTraits tt : typeTraits) {
        ttArray.add(tt.toJson(registry));
    }
    json.set("typeTraits", ttArray);
    ArrayNode cmpArray = OBJECT_MAPPER.createArrayNode();
    for (IBinaryComparatorFactory factory : cmpFactories) {
        cmpArray.add(factory.toJson(registry));
    }
    json.set("cmpFactories", cmpArray);
    if (filterTypeTraits != null) {
        ArrayNode fttArray = OBJECT_MAPPER.createArrayNode();
        for (ITypeTraits tt : filterTypeTraits) {
            fttArray.add(tt.toJson(registry));
        }
        json.set("filterTypeTraits", ttArray);
    } else {
        json.set("filterTypeTraits", null);
    }
    if (filterCmpFactories != null) {
        ArrayNode filterCmpArray = OBJECT_MAPPER.createArrayNode();
        for (IBinaryComparatorFactory factory : cmpFactories) {
            filterCmpArray.add(factory.toJson(registry));
        }
        json.set("filterCmpFactories", filterCmpArray);
    } else {
        json.set("filterCmpFactories", null);
    }
    json.putPOJO("filterFields", filterFields);
    json.set("opTrackerProvider", opTrackerProvider.toJson(registry));
    json.set("ioOpCallbackFactory", ioOpCallbackFactory.toJson(registry));
    json.set("metadataPageManagerFactory", metadataPageManagerFactory.toJson(registry));
    if (vbcProvider != null) {
        json.set("vbcProvider", vbcProvider.toJson(registry));
    }
    json.set("ioSchedulerProvider", ioSchedulerProvider.toJson(registry));
    json.set("mergePolicyFactory", mergePolicyFactory.toJson(registry));
    json.putPOJO("mergePolicyProperties", mergePolicyProperties);
    json.put("durable", durable);
}
#method_after
protected void appendToJson(final ObjectNode json, IPersistedResourceRegistry registry) throws HyracksDataException {
    json.put("path", path);
    json.set("storageManager", storageManager.toJson(registry));
    ArrayNode ttArray = OBJECT_MAPPER.createArrayNode();
    for (ITypeTraits tt : typeTraits) {
        ttArray.add(tt.toJson(registry));
    }
    json.set("typeTraits", ttArray);
    ArrayNode cmpArray = OBJECT_MAPPER.createArrayNode();
    for (IBinaryComparatorFactory factory : cmpFactories) {
        cmpArray.add(factory.toJson(registry));
    }
    json.set("cmpFactories", cmpArray);
    if (filterTypeTraits != null) {
        ArrayNode fttArray = OBJECT_MAPPER.createArrayNode();
        for (ITypeTraits tt : filterTypeTraits) {
            fttArray.add(tt.toJson(registry));
        }
        json.set("filterTypeTraits", fttArray);
    } else {
        json.set("filterTypeTraits", null);
    }
    if (filterCmpFactories != null) {
        ArrayNode filterCmpArray = OBJECT_MAPPER.createArrayNode();
        for (IBinaryComparatorFactory factory : filterCmpFactories) {
            filterCmpArray.add(factory.toJson(registry));
        }
        json.set("filterCmpFactories", filterCmpArray);
    } else {
        json.set("filterCmpFactories", null);
    }
    json.putPOJO("filterFields", filterFields);
    json.set("opTrackerProvider", opTrackerProvider.toJson(registry));
    json.set("ioOpCallbackFactory", ioOpCallbackFactory.toJson(registry));
    json.set("metadataPageManagerFactory", metadataPageManagerFactory.toJson(registry));
    if (vbcProvider != null) {
        json.set("vbcProvider", vbcProvider.toJson(registry));
    }
    json.set("ioSchedulerProvider", ioSchedulerProvider.toJson(registry));
    json.set("mergePolicyFactory", mergePolicyFactory.toJson(registry));
    json.putPOJO("mergePolicyProperties", mergePolicyProperties);
    json.put("durable", durable);
}
#end_block

#method_before
private static ScalarFunctionCallExpression getNestedIsMissingCall(AbstractFunctionCallExpression call) {
    ScalarFunctionCallExpression isMissingFuncExpr = null;
    if (call.getFunctionIdentifier().equals(AlgebricksBuiltinFunctions.NOT)) {
        if (call.getArguments().get(0).getValue().getExpressionTag() == LogicalExpressionTag.FUNCTION_CALL) {
            if (((AbstractFunctionCallExpression) call.getArguments().get(0).getValue()).getFunctionIdentifier().equals(AlgebricksBuiltinFunctions.IS_MISSING)) {
                isMissingFuncExpr = (ScalarFunctionCallExpression) call.getArguments().get(0).getValue();
                if (isMissingFuncExpr.getArguments().get(0).getValue().getExpressionTag() == LogicalExpressionTag.VARIABLE) {
                    return isMissingFuncExpr;
                }
            }
        }
    }
    return null;
}
#method_after
private static ScalarFunctionCallExpression getNestedIsMissingCall(AbstractFunctionCallExpression call, OptimizableOperatorSubTree rightSubTree) throws AlgebricksException {
    ScalarFunctionCallExpression isMissingFuncExpr;
    if (call.getFunctionIdentifier().equals(AlgebricksBuiltinFunctions.NOT)) {
        if (call.getArguments().get(0).getValue().getExpressionTag() == LogicalExpressionTag.FUNCTION_CALL) {
            if (((AbstractFunctionCallExpression) call.getArguments().get(0).getValue()).getFunctionIdentifier().equals(AlgebricksBuiltinFunctions.IS_MISSING)) {
                isMissingFuncExpr = (ScalarFunctionCallExpression) call.getArguments().get(0).getValue();
                if (isMissingFuncExpr.getArguments().get(0).getValue().getExpressionTag() == LogicalExpressionTag.VARIABLE) {
                    LogicalVariable var = ((VariableReferenceExpression) isMissingFuncExpr.getArguments().get(0).getValue()).getVariableReference();
                    List<LogicalVariable> liveSubplanVars = new ArrayList<>();
                    VariableUtilities.getSubplanLocalLiveVariables(rightSubTree.getRoot(), liveSubplanVars);
                    if (liveSubplanVars.contains(var)) {
                        return isMissingFuncExpr;
                    }
                }
            }
        }
    }
    return null;
}
#end_block

#method_before
public static ScalarFunctionCallExpression findLOJIsMissingFuncInGroupBy(GroupByOperator lojGroupbyOp) throws AlgebricksException {
    // find IS_MISSING function of which argument has the nullPlaceholder variable in the nested plan of groupby.
    ALogicalPlanImpl subPlan = (ALogicalPlanImpl) lojGroupbyOp.getNestedPlans().get(0);
    Mutable<ILogicalOperator> subPlanRootOpRef = subPlan.getRoots().get(0);
    AbstractLogicalOperator subPlanRootOp = (AbstractLogicalOperator) subPlanRootOpRef.getValue();
    boolean foundSelectNonMissing = false;
    ScalarFunctionCallExpression isMissingFuncExpr = null;
    AbstractLogicalOperator inputOp = subPlanRootOp;
    while (inputOp != null) {
        if (inputOp.getOperatorTag() == LogicalOperatorTag.SELECT) {
            SelectOperator selectOp = (SelectOperator) inputOp;
            if (selectOp.getCondition().getValue().getExpressionTag() == LogicalExpressionTag.FUNCTION_CALL) {
                AbstractFunctionCallExpression call = (AbstractFunctionCallExpression) (selectOp).getCondition().getValue();
                if (call.getFunctionIdentifier().equals(AlgebricksBuiltinFunctions.AND)) {
                    for (Mutable<ILogicalExpression> mexpr : call.getArguments()) {
                        if (mexpr.getValue().getExpressionTag() == LogicalExpressionTag.FUNCTION_CALL) {
                            isMissingFuncExpr = getNestedIsMissingCall((AbstractFunctionCallExpression) mexpr.getValue());
                            if (isMissingFuncExpr != null) {
                                foundSelectNonMissing = true;
                                break;
                            }
                        }
                    }
                }
                if (foundSelectNonMissing) {
                    break;
                }
                isMissingFuncExpr = getNestedIsMissingCall(call);
                if (isMissingFuncExpr != null) {
                    foundSelectNonMissing = true;
                    break;
                }
            }
        }
        inputOp = inputOp.getInputs().size() > 0 ? (AbstractLogicalOperator) inputOp.getInputs().get(0).getValue() : null;
    }
    if (!foundSelectNonMissing) {
        throw CompilationException.create(ErrorCode.CANNOT_FIND_NON_MISSING_SELECT_OPERATOR, lojGroupbyOp.getSourceLocation());
    }
    return isMissingFuncExpr;
}
#method_after
public static ScalarFunctionCallExpression findLOJIsMissingFuncInGroupBy(GroupByOperator lojGroupbyOp, OptimizableOperatorSubTree rightSubTree) throws AlgebricksException {
    // find IS_MISSING function of which argument has the nullPlaceholder variable in the nested plan of groupby.
    ALogicalPlanImpl subPlan = (ALogicalPlanImpl) lojGroupbyOp.getNestedPlans().get(0);
    Mutable<ILogicalOperator> subPlanRootOpRef = subPlan.getRoots().get(0);
    AbstractLogicalOperator subPlanRootOp = (AbstractLogicalOperator) subPlanRootOpRef.getValue();
    ScalarFunctionCallExpression isMissingFuncExpr = findIsMissingInSubplan(subPlanRootOp, rightSubTree);
    if (isMissingFuncExpr == null) {
        throw CompilationException.create(ErrorCode.CANNOT_FIND_NON_MISSING_SELECT_OPERATOR, lojGroupbyOp.getSourceLocation());
    }
    return isMissingFuncExpr;
}
#end_block

#method_before
@Override
protected int getPosition(IFrameTupleReference tuple, AListPointable listArg) throws HyracksDataException {
    return 0;
}
#method_after
@Override
protected int getPosition(IFrameTupleReference tuple, IPointable listArg, ATypeTag listTag) throws HyracksDataException {
    return 0;
}
#end_block

#method_before
@Test
public void test() throws Exception {
    List<IFunctionDescriptorFactory> functions = FunctionCollection.createDefaultFunctionCollection().getFunctionDescriptorFactories();
    int testedFunctions = 0;
    for (IFunctionDescriptorFactory func : functions) {
        String className = func.getClass().getName();
        // We test all generated functions except
        // record and cast functions, which requires type settings.
        String[] splits = className.split("\\.");
        if (className.contains("Gen") && !className.contains("record") && !className.contains("Cast") && !splits[splits.length - 1].startsWith("Array") && !splits[splits.length - 1].startsWith("AbstractArray")) {
            testFunction(func);
            ++testedFunctions;
        }
    }
    // 208 is the current number of functions with generated code.
    Assert.assertTrue(testedFunctions >= 208);
}
#method_after
@Test
public void test() throws Exception {
    List<IFunctionDescriptorFactory> functions = FunctionCollection.createDefaultFunctionCollection().getFunctionDescriptorFactories();
    int testedFunctions = 0;
    for (IFunctionDescriptorFactory func : functions) {
        String className = func.getClass().getName();
        // record and cast functions, which requires type settings.
        if (className.contains("Gen") && !className.contains("record") && !className.contains("Cast")) {
            System.out.println("Testing " + className);
            testFunction(func);
            ++testedFunctions;
        }
    }
    // 208 is the current number of functions with generated code.
    Assert.assertTrue(testedFunctions >= 208);
}
#end_block

#method_before
private void testFunction(IFunctionDescriptorFactory funcFactory) throws Exception {
    AbstractScalarFunctionDynamicDescriptor funcDesc = (AbstractScalarFunctionDynamicDescriptor) funcFactory.createFunctionDescriptor();
    int inputArity = funcDesc.getIdentifier().getArity();
    Iterator<IScalarEvaluatorFactory[]> argEvalFactoryIterator = getArgCombinations(inputArity);
    while (argEvalFactoryIterator.hasNext()) {
        IScalarEvaluatorFactory evalFactory = funcDesc.createEvaluatorFactory(argEvalFactoryIterator.next());
        IHyracksTaskContext ctx = mock(IHyracksTaskContext.class);
        try {
            IScalarEvaluator evaluator = evalFactory.createScalarEvaluator(ctx);
            IPointable resultPointable = new VoidPointable();
            evaluator.evaluate(null, resultPointable);
        } catch (Throwable e) {
            String msg = e.getMessage();
            if (msg == null) {
                continue;
            }
            if (msg.startsWith("ASX")) {
                // Verifies the error code.
                int errorCode = Integer.parseInt(msg.substring(3, 7));
                Assert.assertTrue(errorCode >= 0 && errorCode < 1000);
                continue;
            } else {
                // Any root-level data exceptions thrown from runtime functions should have an error code.
                Assert.assertTrue(!(e instanceof HyracksDataException) || (e.getCause() != null));
            }
        }
    }
}
#method_after
private void testFunction(IFunctionDescriptorFactory funcFactory) throws Exception {
    AbstractScalarFunctionDynamicDescriptor funcDesc = (AbstractScalarFunctionDynamicDescriptor) funcFactory.createFunctionDescriptor();
    int inputArity = funcDesc.getIdentifier().getArity();
    Iterator<IScalarEvaluatorFactory[]> argEvalFactoryIterator = getArgCombinations(inputArity);
    while (argEvalFactoryIterator.hasNext()) {
        IScalarEvaluatorFactory evalFactory = funcDesc.createEvaluatorFactory(argEvalFactoryIterator.next());
        IHyracksTaskContext ctx = mock(IHyracksTaskContext.class);
        try {
            IScalarEvaluator evaluator = evalFactory.createScalarEvaluator(ctx);
            IPointable resultPointable = new VoidPointable();
            evaluator.evaluate(null, resultPointable);
        } catch (Throwable e) {
            String msg = e.getMessage();
            if (msg == null) {
                continue;
            }
            if (msg.startsWith("ASX")) {
                // Verifies the error code.
                int errorCode = Integer.parseInt(msg.substring(3, 7));
                Assert.assertTrue(errorCode >= 0 && errorCode < 1000);
                continue;
            } else if (msg.startsWith("HYR")) {
                // Verifies the error code.
                int errorCode = Integer.parseInt(msg.substring(3, 7));
                Assert.assertTrue(errorCode >= 0 && errorCode < 1000);
            } else {
                // Any root-level data exceptions thrown from runtime functions should have an error code.
                Assert.assertTrue(!(e instanceof HyracksDataException) || (e.getCause() != null));
            }
        }
    }
}
#end_block

#method_before
@Override
protected int getPosition(IFrameTupleReference tuple, AListPointable listArg) throws HyracksDataException {
    positionArgEval.evaluate(tuple, positionArg);
    if (positionArg.getTag() == ATypeTag.SERIALIZED_MISSING_TYPE_TAG) {
        return -1;
    }
    ATypeTag listTag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(listArg.getByteArray()[listArg.getStartOffset()]);
    int position;
    if (!ATypeHierarchy.isCompatible(ATypeTag.INTEGER, ATYPETAGDESERIALIZER.deserialize(positionArg.getTag())) || !listTag.isListType()) {
        return -2;
    } else {
        String name = getIdentifier().getName();
        position = ATypeHierarchy.getIntegerValue(name, 1, positionArg.getByteArray(), positionArg.getStartOffset());
        int listSize = listArg.getItemCount();
        // adjust position for negative positions
        if (position < 0) {
            position = listSize + position;
        }
        // position should always be positive now and should be within [0-list_size]
        if (position < 0 || position > listSize) {
            return -2;
        }
        return position;
    }
}
#method_after
@Override
protected int getPosition(IFrameTupleReference tuple, IPointable l, ATypeTag listTag) throws HyracksDataException {
    positionArgEval.evaluate(tuple, positionArg);
    if (positionArg.getTag() == ATypeTag.SERIALIZED_MISSING_TYPE_TAG) {
        return RETURN_MISSING;
    }
    int position;
    if (!ATypeHierarchy.isCompatible(ATypeTag.INTEGER, ATYPETAGDESERIALIZER.deserialize(positionArg.getTag())) || !listTag.isListType()) {
        return RETURN_NULL;
    } else {
        String name = getIdentifier().getName();
        position = ATypeHierarchy.getIntegerValue(name, 1, positionArg.getByteArray(), positionArg.getStartOffset());
        // list size
        int size;
        if (listTag == ATypeTag.ARRAY) {
            size = AOrderedListSerializerDeserializer.getNumberOfItems(l.getByteArray(), l.getStartOffset());
        } else {
            size = AUnorderedListSerializerDeserializer.getNumberOfItems(l.getByteArray(), l.getStartOffset());
        }
        // adjust position for negative positions
        if (position < 0) {
            position = size + position;
        }
        // position should always be positive now and should be within [0-list_size]
        if (position < 0 || position > size) {
            return RETURN_NULL;
        }
        return position;
    }
}
#end_block

#method_before
@Override
protected int getPosition(IFrameTupleReference tuple, AListPointable listArg) throws HyracksDataException {
    ATypeTag listTag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(listArg.getByteArray()[listArg.getStartOffset()]);
    if (listTag.isListType()) {
        return listArg.getItemCount();
    }
    return -2;
}
#method_after
@Override
protected int getPosition(IFrameTupleReference tuple, IPointable l, ATypeTag listTag) throws HyracksDataException {
    // l = list
    if (listTag == ATypeTag.ARRAY) {
        return AOrderedListSerializerDeserializer.getNumberOfItems(l.getByteArray(), l.getStartOffset());
    } else if (listTag == ATypeTag.MULTISET) {
        return AUnorderedListSerializerDeserializer.getNumberOfItems(l.getByteArray(), l.getStartOffset());
    } else {
        return RETURN_NULL;
    }
}
#end_block

#method_before
@Test
public void test() throws Exception {
    List<IFunctionDescriptorFactory> functions = FunctionCollection.createDefaultFunctionCollection().getFunctionDescriptorFactories();
    int testedFunctions = 0;
    String[] splits;
    for (IFunctionDescriptorFactory func : functions) {
        String className = func.getClass().getName();
        // We test all generated functions except
        // record and cast functions, which requires type settings (we test them in runtime tests).
        splits = className.split("\\.");
        if (className.contains("Gen") && !className.contains("record") && !className.contains("Cast") && !splits[splits.length - 1].startsWith(arrayName) && !splits[splits.length - 1].startsWith(abstractArray)) {
            testFunction(func);
            ++testedFunctions;
        }
    }
    // 217 is the current number of functions with generated code.
    Assert.assertTrue("expected >= 217 generated functions to be tested, but was " + testedFunctions, testedFunctions >= 217);
}
#method_after
@Test
public void test() throws Exception {
    List<IFunctionDescriptorFactory> functions = FunctionCollection.createDefaultFunctionCollection().getFunctionDescriptorFactories();
    int testedFunctions = 0;
    for (IFunctionDescriptorFactory func : functions) {
        String className = func.getClass().getName();
        // record and cast functions, which requires type settings (we test them in runtime tests).
        if (className.contains("Gen") && !className.contains("record") && !className.contains("Cast")) {
            System.out.println("Testing " + className);
            testFunction(func);
            ++testedFunctions;
        }
    }
    // 217 is the current number of functions with generated code.
    Assert.assertTrue("expected >= 217 generated functions to be tested, but was " + testedFunctions, testedFunctions >= 217);
}
#end_block

#method_before
@Override
protected int getPosition(IFrameTupleReference tuple, AListPointable listArg) throws HyracksDataException {
    ATypeTag listTag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(listArg.getByteArray()[listArg.getStartOffset()]);
    if (listTag.isListType()) {
        return listArg.getItemCount();
    }
    return -2;
}
#method_after
@Override
protected int getPosition(IFrameTupleReference tuple, IPointable l, ATypeTag listTag) throws HyracksDataException {
    // l = list
    if (listTag == ATypeTag.ARRAY) {
        return AOrderedListSerializerDeserializer.getNumberOfItems(l.getByteArray(), l.getStartOffset());
    } else if (listTag == ATypeTag.MULTISET) {
        return AUnorderedListSerializerDeserializer.getNumberOfItems(l.getByteArray(), l.getStartOffset());
    } else {
        return RETURN_NULL;
    }
}
#end_block

#method_before
@Override
public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException {
    // get the list argument, 1st or last argument, make sure it's a list
    listArgEval.evaluate(tuple, listArg);
    ATypeTag listArgTag = ATYPETAGDESERIALIZER.deserialize(listArg.getByteArray()[listArg.getStartOffset()]);
    // evaluate the position argument if provided by some functions
    int adjustedPosition = getPosition(tuple, listArg);
    if (listArgTag == ATypeTag.MISSING || adjustedPosition == -1) {
        PointableHelper.setMissing(result);
        return;
    }
    boolean returnNull = false;
    if (!listArgTag.isListType() || adjustedPosition < -1) {
        returnNull = true;
    }
    // evaluate values to be added/removed
    ATypeTag valueTag;
    IAType defaultOpenType;
    boolean encounteredNonPrimitive = false;
    CastTypeEvaluator caster = new CastTypeEvaluator();
    for (int i = 0; i < valuesEval.length; i++) {
        // cast val to open if needed. don't cast if function will return null anyway, e.g. list arg was not list
        defaultOpenType = DefaultOpenFieldType.getDefaultOpenFieldType(argTypes[i + valuesOffset].getTypeTag());
        if (defaultOpenType != null && !returnNull) {
            caster.reset(defaultOpenType, argTypes[i + valuesOffset], valuesEval[i]);
            caster.evaluate(tuple, valuesArgs[i]);
        } else {
            valuesEval[i].evaluate(tuple, valuesArgs[i]);
        }
        valueTag = ATYPETAGDESERIALIZER.deserialize(valuesArgs[i].getByteArray()[valuesArgs[i].getStartOffset()]);
        // for now, we don't support deep equality of object/lists. Throw an error if the value is of these types
        if (comparesValues && valueTag.isDerivedType()) {
            encounteredNonPrimitive = true;
        }
        if (valueTag == ATypeTag.MISSING) {
            PointableHelper.setMissing(result);
            return;
        }
        if (!acceptNullValues && valueTag == ATypeTag.NULL) {
            returnNull = true;
        }
    }
    if (returnNull) {
        PointableHelper.setNull(result);
        return;
    }
    if (encounteredNonPrimitive) {
        throw HyracksDataException.create(ErrorCode.CANNOT_COMPARE_COMPLEX, sourceLocation);
    }
    // all arguments are valid
    AbstractCollectionType listType = (AbstractCollectionType) argTypes[listOffset];
    IAsterixListBuilder listBuilder;
    // create the new list to be returned. cast the input list and make it open if required
    if (listArgTag == ATypeTag.ARRAY) {
        listBuilder = new OrderedListBuilder();
        if (makeOpen) {
            listType = DefaultOpenFieldType.NESTED_OPEN_AORDERED_LIST_TYPE;
            caster.reset(listType, argTypes[listOffset], listArgEval);
            caster.evaluate(tuple, listArg);
        }
    } else {
        listBuilder = new UnorderedListBuilder();
        if (makeOpen) {
            listType = DefaultOpenFieldType.NESTED_OPEN_AUNORDERED_LIST_TYPE;
            caster.reset(listType, argTypes[listOffset], listArgEval);
            caster.evaluate(tuple, listArg);
        }
    }
    listBuilder.reset(listType);
    ListAccessor listAccessor = new ListAccessor();
    listAccessor.reset(listArg.getByteArray(), listArg.getStartOffset());
    try {
        processList(listAccessor, listBuilder, valuesArgs, adjustedPosition);
        storage.reset();
        listBuilder.write(storage.getDataOutput(), true);
        result.set(storage);
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    }
}
#method_after
@Override
public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException {
    // get the list argument, 1st or last argument, make sure it's a list
    listArgEval.evaluate(tuple, listArg);
    ATypeTag listArgTag = ATYPETAGDESERIALIZER.deserialize(listArg.getByteArray()[listArg.getStartOffset()]);
    // evaluate the position argument if provided by some functions
    int adjustedPosition = getPosition(tuple, listArg, listArgTag);
    if (listArgTag == ATypeTag.MISSING || adjustedPosition == RETURN_MISSING) {
        PointableHelper.setMissing(result);
        return;
    }
    boolean returnNull = false;
    if (!listArgTag.isListType() || adjustedPosition == RETURN_NULL) {
        returnNull = true;
    }
    // evaluate values to be added/removed
    ATypeTag valueTag;
    IAType defaultOpenType;
    boolean encounteredNonPrimitive = false;
    for (int i = 0; i < valuesEval.length; i++) {
        // cast val to open if needed. don't cast if function will return null anyway, e.g. list arg was not list
        defaultOpenType = DefaultOpenFieldType.getDefaultOpenFieldType(argTypes[i + valuesOffset].getTypeTag());
        if (defaultOpenType != null && !returnNull) {
            caster.reset(defaultOpenType, argTypes[i + valuesOffset], valuesEval[i]);
            caster.evaluate(tuple, valuesArgs[i]);
        } else {
            valuesEval[i].evaluate(tuple, valuesArgs[i]);
        }
        valueTag = ATYPETAGDESERIALIZER.deserialize(valuesArgs[i].getByteArray()[valuesArgs[i].getStartOffset()]);
        // for now, we don't support deep equality of object/lists. Throw an error if the value is of these types
        if (comparesValues && valueTag.isDerivedType()) {
            encounteredNonPrimitive = true;
        }
        if (valueTag == ATypeTag.MISSING) {
            PointableHelper.setMissing(result);
            return;
        }
        if (!acceptNullValues && valueTag == ATypeTag.NULL) {
            returnNull = true;
        }
    }
    if (returnNull) {
        PointableHelper.setNull(result);
        return;
    }
    if (encounteredNonPrimitive) {
        throw HyracksDataException.create(ErrorCode.CANNOT_COMPARE_COMPLEX, sourceLocation);
    }
    // all arguments are valid
    AbstractCollectionType listType = (AbstractCollectionType) argTypes[listOffset];
    IAsterixListBuilder listBuilder;
    // create the new list to be returned. cast the input list and make it open if required
    if (listArgTag == ATypeTag.ARRAY) {
        if (orderedListBuilder == null) {
            orderedListBuilder = new OrderedListBuilder();
        }
        listBuilder = orderedListBuilder;
        if (makeOpen) {
            listType = DefaultOpenFieldType.NESTED_OPEN_AORDERED_LIST_TYPE;
            caster.reset(listType, argTypes[listOffset], listArgEval);
            caster.evaluate(tuple, listArg);
        }
    } else {
        if (unorderedListBuilder == null) {
            unorderedListBuilder = new UnorderedListBuilder();
        }
        listBuilder = unorderedListBuilder;
        if (makeOpen) {
            listType = DefaultOpenFieldType.NESTED_OPEN_AUNORDERED_LIST_TYPE;
            caster.reset(listType, argTypes[listOffset], listArgEval);
            caster.evaluate(tuple, listArg);
        }
    }
    listBuilder.reset(listType);
    listAccessor.reset(listArg.getByteArray(), listArg.getStartOffset());
    try {
        processList(listAccessor, listBuilder, valuesArgs, adjustedPosition);
        storage.reset();
        listBuilder.write(storage.getDataOutput(), true);
        result.set(storage);
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    }
}
#end_block

#method_before
protected void processList(ListAccessor listAccessor, IAsterixListBuilder listBuilder, IPointable[] values, int position) throws IOException {
    int i;
    for (i = 0; i < position; i++) {
        storage.reset();
        listAccessor.writeItem(i, storage.getDataOutput());
        listBuilder.addItem(storage);
    }
    // insert the values arguments
    for (IPointable addedValues : values) {
        listBuilder.addItem(addedValues);
    }
    for (; i < listAccessor.size(); i++) {
        storage.reset();
        listAccessor.writeItem(i, storage.getDataOutput());
        listBuilder.addItem(storage);
    }
}
#method_after
protected void processList(ListAccessor listAccessor, IAsterixListBuilder listBuilder, IPointable[] values, int position) throws IOException {
    int i;
    for (i = 0; i < position; i++) {
        storage.reset();
        listAccessor.writeItem(i, storage.getDataOutput());
        listBuilder.addItem(storage);
    }
    // insert the values arguments
    for (int j = 0; j < values.length; j++) {
        listBuilder.addItem(values[j]);
    }
    for (; i < listAccessor.size(); i++) {
        storage.reset();
        listAccessor.writeItem(i, storage.getDataOutput());
        listBuilder.addItem(storage);
    }
}
#end_block

#method_before
@Override
protected int getPosition(IFrameTupleReference tuple, AListPointable listArg) throws HyracksDataException {
    return 0;
}
#method_after
@Override
protected int getPosition(IFrameTupleReference tuple, IPointable listArg, ATypeTag listTag) throws HyracksDataException {
    return 0;
}
#end_block

#method_before
@Override
protected void processList(ListAccessor listAccessor, IAsterixListBuilder listBuilder, IPointable[] removedVals, int position) throws IOException {
    // get the list items one by one and append to the new list only if the list item is not in removed list
    boolean addItem;
    for (int i = 0; i < listAccessor.size(); i++) {
        storage.reset();
        listAccessor.writeItem(i, storage.getDataOutput());
        addItem = true;
        for (IPointable removedVal : removedVals) {
            if (comp.compare(storage.getByteArray(), storage.getStartOffset(), storage.getLength(), removedVal.getByteArray(), removedVal.getStartOffset(), removedVal.getLength()) == 0) {
                addItem = false;
                break;
            }
        }
        if (addItem) {
            listBuilder.addItem(storage);
        }
    }
}
#method_after
@Override
protected void processList(ListAccessor listAccessor, IAsterixListBuilder listBuilder, IPointable[] removed, int position) throws IOException {
    // get the list items one by one and append to the new list only if the list item is not in removed list
    boolean addItem;
    for (int i = 0; i < listAccessor.size(); i++) {
        storage.reset();
        listAccessor.writeItem(i, storage.getDataOutput());
        addItem = true;
        for (int j = 0; j < removed.length; j++) {
            if (comp.compare(storage.getByteArray(), storage.getStartOffset(), storage.getLength(), removed[j].getByteArray(), removed[j].getStartOffset(), removed[j].getLength()) == 0) {
                addItem = false;
                break;
            }
        }
        if (addItem) {
            listBuilder.addItem(storage);
        }
    }
}
#end_block

#method_before
private static JobSpecification getConnectionJob(MetadataProvider metadataProvider, FeedConnection feedConn, IStatementExecutor statementExecutor, IHyracksClientConnection hcc, Boolean insertFeed) throws AlgebricksException, RemoteException, ACIDException {
    metadataProvider.getConfig().put(FeedActivityDetails.FEED_POLICY_NAME, feedConn.getPolicyName());
    Query feedConnQuery = makeConnectionQuery(feedConn);
    CompiledStatements.ICompiledDmlStatement clfrqs;
    if (insertFeed) {
        InsertStatement stmtUpsert = new InsertStatement(new Identifier(feedConn.getDataverseName()), new Identifier(feedConn.getDatasetName()), feedConnQuery, -1, null, null);
        clfrqs = new CompiledStatements.CompiledInsertStatement(feedConn.getDataverseName(), feedConn.getDatasetName(), feedConnQuery, stmtUpsert.getVarCounter(), null, null);
    } else {
        UpsertStatement stmtUpsert = new UpsertStatement(new Identifier(feedConn.getDataverseName()), new Identifier(feedConn.getDatasetName()), feedConnQuery, -1, null, null);
        clfrqs = new CompiledStatements.CompiledUpsertStatement(feedConn.getDataverseName(), feedConn.getDatasetName(), feedConnQuery, stmtUpsert.getVarCounter(), null, null);
    }
    return statementExecutor.rewriteCompileQuery(hcc, metadataProvider, feedConnQuery, clfrqs);
}
#method_after
private static JobSpecification getConnectionJob(MetadataProvider metadataProvider, FeedConnection feedConn, IStatementExecutor statementExecutor, IHyracksClientConnection hcc, Boolean insertFeed) throws AlgebricksException, RemoteException, ACIDException {
    metadataProvider.getConfig().put(FeedActivityDetails.FEED_POLICY_NAME, feedConn.getPolicyName());
    Query feedConnQuery = makeConnectionQuery(feedConn);
    CompiledStatements.ICompiledDmlStatement clfrqs;
    if (insertFeed) {
        InsertStatement stmtUpsert = new InsertStatement(new Identifier(feedConn.getDataverseName()), new Identifier(feedConn.getDatasetName()), feedConnQuery, -1, null, null);
        clfrqs = new CompiledStatements.CompiledInsertStatement(feedConn.getDataverseName(), feedConn.getDatasetName(), feedConnQuery, stmtUpsert.getVarCounter(), null, null);
    } else {
        UpsertStatement stmtUpsert = new UpsertStatement(new Identifier(feedConn.getDataverseName()), new Identifier(feedConn.getDatasetName()), feedConnQuery, -1, null, null);
        clfrqs = new CompiledStatements.CompiledUpsertStatement(feedConn.getDataverseName(), feedConn.getDatasetName(), feedConnQuery, stmtUpsert.getVarCounter(), null, null);
    }
    return statementExecutor.rewriteCompileQuery(hcc, metadataProvider, feedConnQuery, clfrqs, null, null);
}
#end_block

#method_before
protected synchronized void handle(ActivePartitionMessage message) {
    if (message.getEvent() == Event.RUNTIME_REGISTERED) {
        numRegistered++;
        if (numRegistered == locations.getLocations().length && state != ActivityState.CANCELLING) {
            setState(ActivityState.RUNNING);
        }
    } else if (message.getEvent() == Event.RUNTIME_DEREGISTERED) {
        numDeRegistered++;
    }
}
#method_after
protected synchronized void handle(ActivePartitionMessage message) {
    if (message.getEvent() == Event.RUNTIME_REGISTERED) {
        numRegistered++;
        if (allPartitionsRegisteredAndNotCancelling()) {
            setState(ActivityState.RUNNING);
        }
    } else if (message.getEvent() == Event.RUNTIME_DEREGISTERED) {
        numDeRegistered++;
    }
}
#end_block

#method_before
@SuppressWarnings("unchecked")
protected void finish(ActiveEvent event) throws HyracksDataException {
    LOGGER.log(level, "the job " + jobId + " finished");
    if (numRegistered != numDeRegistered) {
        LOGGER.log(Level.WARN, "the job {} finished with reported runtime registrations = {} and deregistrations = {}", jobId, numRegistered, numDeRegistered);
    }
    jobId = null;
    Pair<JobStatus, List<Exception>> status = (Pair<JobStatus, List<Exception>>) event.getEventObject();
    JobStatus jobStatus = status.getLeft();
    List<Exception> exceptions = status.getRight();
    LOGGER.log(level, "The job finished with status: " + jobStatus);
    if (!jobStatus.equals(JobStatus.TERMINATED)) {
        jobFailure = exceptions.isEmpty() ? new RuntimeDataException(ErrorCode.UNREPORTED_TASK_FAILURE_EXCEPTION) : exceptions.get(0);
        setState((state == ActivityState.STOPPING || state == ActivityState.CANCELLING) ? ActivityState.STOPPED : ActivityState.TEMPORARILY_FAILED);
        if (prevState == ActivityState.RUNNING) {
            recover();
        }
    } else {
        setState(state == ActivityState.SUSPENDING ? ActivityState.SUSPENDED : ActivityState.STOPPED);
    }
}
#method_after
@SuppressWarnings("unchecked")
protected void finish(ActiveEvent event) throws HyracksDataException {
    LOGGER.log(level, "the job " + jobId + " finished");
    if (numRegistered != numDeRegistered) {
        LOGGER.log(Level.WARN, "the job {} finished with reported runtime registrations = {} and deregistrations = {}", jobId, numRegistered, numDeRegistered);
    }
    jobId = null;
    Pair<JobStatus, List<Exception>> status = (Pair<JobStatus, List<Exception>>) event.getEventObject();
    JobStatus jobStatus = status.getLeft();
    List<Exception> exceptions = status.getRight();
    LOGGER.log(level, "The job finished with status: " + jobStatus);
    if (!jobSuccessfullyTerminated(jobStatus)) {
        jobFailure = exceptions.isEmpty() ? new RuntimeDataException(ErrorCode.UNREPORTED_TASK_FAILURE_EXCEPTION) : exceptions.get(0);
        setState((state == ActivityState.STOPPING || state == ActivityState.CANCELLING) ? ActivityState.STOPPED : ActivityState.TEMPORARILY_FAILED);
        if (prevState == ActivityState.RUNNING) {
            recover();
        }
    } else {
        setState(state == ActivityState.SUSPENDING ? ActivityState.SUSPENDED : ActivityState.STOPPED);
    }
}
#end_block

#method_before
@Override
public synchronized void subscribe(IActiveEntityEventSubscriber subscriber) throws HyracksDataException {
    subscriber.subscribed(this);
    if (!subscriber.isDone()) {
        subscribers.add(subscriber);
    }
}
#method_after
@Override
public synchronized void subscribe(IActiveEntityEventSubscriber subscriber) {
    subscriber.subscribed(this);
    if (!subscriber.isDone()) {
        subscribers.add(subscriber);
    }
}
#end_block

#method_before
protected synchronized void notifySubscribers(ActiveEvent event) {
    notifyAll();
    Iterator<IActiveEntityEventSubscriber> it = subscribers.iterator();
    while (it.hasNext()) {
        IActiveEntityEventSubscriber subscriber = it.next();
        if (subscriber.isDone()) {
            it.remove();
        } else {
            try {
                subscriber.notify(event);
            } catch (HyracksDataException e) {
                LOGGER.log(Level.WARN, "Failed to notify subscriber", e);
            }
            if (subscriber.isDone()) {
                it.remove();
            }
        }
    }
}
#method_after
protected synchronized void notifySubscribers(ActiveEvent event) {
    notifyAll();
    Iterator<IActiveEntityEventSubscriber> it = subscribers.iterator();
    while (it.hasNext()) {
        IActiveEntityEventSubscriber subscriber = it.next();
        if (subscriber.isDone()) {
            it.remove();
        } else {
            subscriber.notify(event);
            if (subscriber.isDone()) {
                it.remove();
            }
        }
    }
}
#end_block

#method_before
@SuppressWarnings("squid:S1181")
protected synchronized void doStart(MetadataProvider metadataProvider) throws HyracksDataException {
    WaitForStateSubscriber subscriber = new WaitForStateSubscriber(this, EnumSet.of(ActivityState.RUNNING, ActivityState.TEMPORARILY_FAILED, ActivityState.STOPPED));
    jobId = compileAndStartJob(metadataProvider);
    numRegistered = 0;
    numDeRegistered = 0;
    try {
        subscriber.sync();
        if (subscriber.getFailure() != null) {
            throw subscriber.getFailure();
        }
    } catch (InterruptedException ie) {
        // interrupted.. check if the subscriber is done
        if (subscriber.isDone()) {
            if (subscriber.getFailure() != null) {
                throw HyracksDataException.create(subscriber.getFailure());
            }
            Thread.currentThread().interrupt();
        } else {
            // Subscriber is not done yet. so, we need to cancel, we have the jobId
            setState(ActivityState.CANCELLING);
            try {
                cancelJobSafely(metadataProvider, ie);
            } catch (Throwable th) {
                ExitUtil.halt(ExitUtil.EC_FAILED_TO_CANCEL_ACTIVE_START_STOP);
            }
            final WaitForStateSubscriber cancelSubscriber = new WaitForStateSubscriber(this, EnumSet.of(ActivityState.STOPPED));
            final Span span = Span.start(2, TimeUnit.MINUTES);
            InvokeUtil.doUninterruptibly(() -> {
                if (!cancelSubscriber.sync(span)) {
                    ExitUtil.halt(ExitUtil.EC_FAILED_TO_CANCEL_ACTIVE_START_STOP);
                }
            });
            throw HyracksDataException.create(ie);
        }
    } catch (Throwable e) {
        throw HyracksDataException.create(e);
    }
}
#method_after
@SuppressWarnings("squid:S1181")
protected synchronized void doStart(MetadataProvider metadataProvider) throws HyracksDataException {
    WaitForStateSubscriber subscriber = new WaitForStateSubscriber(this, EnumSet.of(ActivityState.RUNNING, ActivityState.TEMPORARILY_FAILED, ActivityState.STOPPED));
    jobId = compileAndStartJob(metadataProvider);
    numRegistered = 0;
    numDeRegistered = 0;
    try {
        subscriber.sync();
        if (subscriber.getFailure() != null) {
            throw subscriber.getFailure();
        }
    } catch (InterruptedException ie) {
        // interrupted.. check if the subscriber is done
        if (subscriber.isDone()) {
            if (subscriber.getFailure() != null) {
                throw HyracksDataException.create(subscriber.getFailure());
            }
            Thread.currentThread().interrupt();
        } else {
            // Subscriber is not done yet. so, we need to cancel, we have the jobId
            setState(ActivityState.CANCELLING);
            cancelJob(ie);
            throw HyracksDataException.create(ie);
        }
    } catch (Throwable e) {
        throw HyracksDataException.create(e);
    }
}
#end_block

#method_before
protected void cancelJobSafely(MetadataProvider metadataProvider, Throwable e) {
    try {
        metadataProvider.getApplicationContext().getHcc().cancelJob(jobId);
    } catch (Throwable th) {
        LOGGER.warn("Failed to cancel active job", th);
        e.addSuppressed(th);
    }
}
#method_after
@SuppressWarnings("squid:S1181")
protected void cancelJobSafely(MetadataProvider metadataProvider, Throwable e) {
    try {
        metadataProvider.getApplicationContext().getHcc().cancelJob(jobId);
    } catch (Throwable th) {
        LOGGER.warn("Failed to cancel active job", th);
        e.addSuppressed(th);
    }
}
#end_block

#method_before
protected synchronized void doStop(MetadataProvider metadataProvider) throws HyracksDataException {
    ActivityState intention = state;
    Set<ActivityState> waitFor;
    if (intention == ActivityState.STOPPING) {
        waitFor = EnumSet.of(ActivityState.STOPPED);
    } else if (intention == ActivityState.SUSPENDING) {
        waitFor = EnumSet.of(ActivityState.SUSPENDED, ActivityState.TEMPORARILY_FAILED);
    } else {
        throw new IllegalStateException("stop with what intention?? Current state is " + intention);
    }
    WaitForStateSubscriber subscriber = new WaitForStateSubscriber(this, waitFor);
    // Note: once we start sending stop messages, we can't go back until the entity is stopped
    try {
        sendStopMessages(metadataProvider);
        LOGGER.log(Level.DEBUG, "Waiting for its state to become " + waitFor);
        subscriber.sync();
        LOGGER.log(Level.DEBUG, "Disconnect has been completed " + waitFor);
    } catch (Throwable e) {
        if (!subscriber.isDone()) {
            cancelJobSafely(metadataProvider, e);
            final Span span = Span.start(2, TimeUnit.MINUTES);
            InvokeUtil.doUninterruptibly(() -> {
                if (!subscriber.sync(span)) {
                    ExitUtil.halt(ExitUtil.EC_FAILED_TO_CANCEL_ACTIVE_START_STOP);
                }
            });
        }
        // Stop should not through an exception if the entity was stopped..
        // Simply log
        LOGGER.warn("Failure encountered while stopping {}", this, e);
    }
}
#method_after
@SuppressWarnings("squid:S1181")
protected synchronized void doStop(MetadataProvider metadataProvider) throws HyracksDataException {
    ActivityState intention = state;
    Set<ActivityState> waitFor;
    if (intention == ActivityState.STOPPING) {
        waitFor = EnumSet.of(ActivityState.STOPPED);
    } else if (intention == ActivityState.SUSPENDING) {
        waitFor = EnumSet.of(ActivityState.SUSPENDED, ActivityState.TEMPORARILY_FAILED);
    } else {
        throw new IllegalStateException("stop with what intention?? Current state is " + intention);
    }
    WaitForStateSubscriber subscriber = new WaitForStateSubscriber(this, waitFor);
    // Note: once we start sending stop messages, we can't go back until the entity is stopped
    try {
        sendStopMessages(metadataProvider);
        LOGGER.log(Level.DEBUG, "Waiting for its state to become " + waitFor);
        subscriber.sync();
        LOGGER.log(Level.DEBUG, "Disconnect has been completed " + waitFor);
    } catch (InterruptedException ie) {
        forceStop(subscriber, ie);
        Thread.currentThread().interrupt();
    } catch (Throwable e) {
        forceStop(subscriber, e);
    }
}
#end_block

#method_before
protected void sendStopMessages(MetadataProvider metadataProvider) throws Exception {
    ICcApplicationContext appCtx = metadataProvider.getApplicationContext();
    ICCMessageBroker messageBroker = (ICCMessageBroker) appCtx.getServiceContext().getMessageBroker();
    AlgebricksAbsolutePartitionConstraint locations = getLocations();
    int partition = 0;
    LOGGER.log(Level.INFO, "Sending stop messages to " + locations);
    for (String location : locations.getLocations()) {
        LOGGER.log(Level.INFO, "Sending to " + location);
        messageBroker.sendApplicationMessageToNC(new ActiveManagerMessage(ActiveManagerMessage.Kind.STOP_ACTIVITY, getActiveRuntimeId(partition++)), location);
    }
}
#method_after
protected void sendStopMessages(MetadataProvider metadataProvider) throws Exception {
    ICcApplicationContext applicationCtx = metadataProvider.getApplicationContext();
    ICCMessageBroker messageBroker = (ICCMessageBroker) applicationCtx.getServiceContext().getMessageBroker();
    AlgebricksAbsolutePartitionConstraint runtimeLocations = getLocations();
    int partition = 0;
    LOGGER.log(Level.INFO, "Sending stop messages to " + runtimeLocations);
    for (String location : runtimeLocations.getLocations()) {
        LOGGER.log(Level.INFO, "Sending to " + location);
        messageBroker.sendApplicationMessageToNC(new ActiveManagerMessage(ActiveManagerMessage.Kind.STOP_ACTIVITY, getActiveRuntimeId(partition++)), location);
    }
}
#end_block

#method_before
@Override
public void notify(ActiveEvent event) throws HyracksDataException {
    if (targetStates.contains(listener.getState())) {
        complete(listener.getJobFailure());
    } else if (event != null && event.getEventKind() == ActiveEvent.Kind.FAILURE) {
        try {
            complete((Exception) event.getEventObject());
        } catch (Exception e) {
            throw HyracksDataException.create(e);
        }
    }
}
#method_after
@Override
public void notify(ActiveEvent event) {
    if (targetStates.contains(listener.getState())) {
        complete(listener.getJobFailure());
    } else if (event != null && event.getEventKind() == ActiveEvent.Kind.FAILURE) {
        complete((Exception) event.getEventObject());
    }
}
#end_block

#method_before
@Override
public void subscribed(IActiveEntityEventsListener eventsListener) throws HyracksDataException {
    if (targetStates.contains(listener.getState())) {
        complete(null);
    }
}
#method_after
@Override
public void subscribed(IActiveEntityEventsListener eventsListener) {
    if (targetStates.contains(listener.getState())) {
        complete(null);
    }
}
#end_block

#method_before
private static boolean noNullOrMissingInKeys(IFrameTupleAccessor fta, int tupId, int[] keys) {
    int tStart = fta.getTupleStartOffset(tupId);
    int fStartOffset = fta.getFieldSlotsLength() + tStart;
    for (int key : keys) {
        int fieldStartIx = fta.getFieldStartOffset(tupId, key);
        ATypeTag typeTag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(fta.getBuffer().array()[fieldStartIx + fStartOffset]);
        if (typeTag == ATypeTag.MISSING || typeTag == ATypeTag.NULL) {
            return false;
        }
    }
    return true;
}
#method_after
private static boolean noNullOrMissingInKeys(IFrameTupleAccessor fta, int tupId, int[] keys) {
    int tStart = fta.getTupleStartOffset(tupId);
    int fStartOffset = fta.getFieldSlotsLength() + tStart;
    for (int i = 0; i < keys.length; ++i) {
        int key = keys[i];
        int fieldStartIx = fta.getFieldStartOffset(tupId, key);
        ATypeTag typeTag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(fta.getBuffer().array()[fieldStartIx + fStartOffset]);
        if (typeTag == ATypeTag.MISSING || typeTag == ATypeTag.NULL) {
            return false;
        }
    }
    return true;
}
#end_block

#method_before
public static FunctionCollection createDefaultFunctionCollection() {
    FunctionCollection fc = new FunctionCollection();
    // array functions
    fc.addGenerated(ArrayAppendDescriptor.FACTORY);
    fc.addGenerated(ArrayPositionDescriptor.FACTORY);
    fc.addGenerated(ArrayReverseDescriptor.FACTORY);
    fc.addGenerated(ArrayContainsDescriptor.FACTORY);
    // unnesting functions
    fc.add(TidRunningAggregateDescriptor.FACTORY);
    fc.add(ScanCollectionDescriptor.FACTORY);
    fc.add(RangeDescriptor.FACTORY);
    fc.add(SubsetCollectionDescriptor.FACTORY);
    // aggregate functions
    fc.add(ListifyAggregateDescriptor.FACTORY);
    fc.add(CountAggregateDescriptor.FACTORY);
    fc.add(AvgAggregateDescriptor.FACTORY);
    fc.add(LocalAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SumAggregateDescriptor.FACTORY);
    fc.add(LocalSumAggregateDescriptor.FACTORY);
    fc.add(MaxAggregateDescriptor.FACTORY);
    fc.add(LocalMaxAggregateDescriptor.FACTORY);
    fc.add(MinAggregateDescriptor.FACTORY);
    fc.add(LocalMinAggregateDescriptor.FACTORY);
    fc.add(FirstElementAggregateDescriptor.FACTORY);
    fc.add(LocalFirstElementAggregateDescriptor.FACTORY);
    // serializable aggregates
    fc.add(SerializableCountAggregateDescriptor.FACTORY);
    fc.add(SerializableAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSumAggregateDescriptor.FACTORY);
    // scalar aggregates
    fc.add(ScalarCountAggregateDescriptor.FACTORY);
    fc.add(ScalarAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSumAggregateDescriptor.FACTORY);
    fc.add(ScalarMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarMinAggregateDescriptor.FACTORY);
    fc.add(EmptyStreamAggregateDescriptor.FACTORY);
    fc.add(NonEmptyStreamAggregateDescriptor.FACTORY);
    // SQL aggregates
    fc.add(SqlCountAggregateDescriptor.FACTORY);
    fc.add(SqlAvgAggregateDescriptor.FACTORY);
    fc.add(LocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SqlSumAggregateDescriptor.FACTORY);
    fc.add(LocalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SqlMaxAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMaxAggregateDescriptor.FACTORY);
    fc.add(SqlMinAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMinAggregateDescriptor.FACTORY);
    // SQL serializable aggregates
    fc.add(SerializableSqlCountAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlSumAggregateDescriptor.FACTORY);
    // SQL scalar aggregates
    fc.add(ScalarSqlCountAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlSumAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMinAggregateDescriptor.FACTORY);
    // boolean functions
    fc.add(AndDescriptor.FACTORY);
    fc.add(OrDescriptor.FACTORY);
    // Record constructors / functions
    fc.add(ClosedRecordConstructorDescriptor.FACTORY);
    fc.add(OpenRecordConstructorDescriptor.FACTORY);
    fc.add(RecordConcatDescriptor.FACTORY);
    fc.add(RecordConcatStrictDescriptor.FACTORY);
    // List constructors
    fc.add(OrderedListConstructorDescriptor.FACTORY);
    fc.add(UnorderedListConstructorDescriptor.FACTORY);
    // Sleep function
    fc.add(SleepDescriptor.FACTORY);
    // Inject failure function
    fc.add(InjectFailureDescriptor.FACTORY);
    // Get Job Parameter function
    fc.add(GetJobParameterByNameDescriptor.FACTORY);
    // Switch case
    fc.add(SwitchCaseDescriptor.FACTORY);
    // null functions
    fc.add(IsMissingDescriptor.FACTORY);
    fc.add(IsNullDescriptor.FACTORY);
    fc.add(IsUnknownDescriptor.FACTORY);
    fc.add(IsSystemNullDescriptor.FACTORY);
    fc.add(CheckUnknownDescriptor.FACTORY);
    fc.add(IfMissingDescriptor.FACTORY);
    fc.add(IfNullDescriptor.FACTORY);
    fc.add(IfMissingOrNullDescriptor.FACTORY);
    // uuid generators (zero independent functions)
    fc.add(CreateUUIDDescriptor.FACTORY);
    fc.add(UUIDDescriptor.FACTORY);
    fc.add(CreateQueryUIDDescriptor.FACTORY);
    fc.add(RandomDescriptor.FACTORY);
    fc.add(CurrentDateDescriptor.FACTORY);
    fc.add(CurrentTimeDescriptor.FACTORY);
    fc.add(CurrentDateTimeDescriptor.FACTORY);
    // functions that need generated class for null-handling.
    // Element accessors.
    fc.addGenerated(FieldAccessByIndexDescriptor.FACTORY);
    fc.addGenerated(FieldAccessByNameDescriptor.FACTORY);
    fc.addGenerated(FieldAccessNestedDescriptor.FACTORY);
    fc.addGenerated(AnyCollectionMemberDescriptor.FACTORY);
    fc.addGenerated(GetItemDescriptor.FACTORY);
    // Numeric functions
    fc.add(IfInfDescriptor.FACTORY);
    fc.add(IfNanDescriptor.FACTORY);
    fc.add(IfNanOrInfDescriptor.FACTORY);
    fc.addGenerated(NumericUnaryMinusDescriptor.FACTORY);
    fc.addGenerated(NumericAddDescriptor.FACTORY);
    fc.addGenerated(NumericDivideDescriptor.FACTORY);
    fc.addGenerated(NumericDivDescriptor.FACTORY);
    fc.addGenerated(NumericMultiplyDescriptor.FACTORY);
    fc.addGenerated(NumericSubDescriptor.FACTORY);
    fc.addGenerated(NumericModuloDescriptor.FACTORY);
    fc.addGenerated(NumericPowerDescriptor.FACTORY);
    fc.addGenerated(NotDescriptor.FACTORY);
    fc.addGenerated(LenDescriptor.FACTORY);
    fc.addGenerated(NumericAbsDescriptor.FACTORY);
    fc.addGenerated(NumericCeilingDescriptor.FACTORY);
    fc.addGenerated(NumericFloorDescriptor.FACTORY);
    fc.addGenerated(NumericRoundDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEvenDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEven2Descriptor.FACTORY);
    fc.addGenerated(NumericACosDescriptor.FACTORY);
    fc.addGenerated(NumericASinDescriptor.FACTORY);
    fc.addGenerated(NumericATanDescriptor.FACTORY);
    fc.addGenerated(NumericDegreesDescriptor.FACTORY);
    fc.addGenerated(NumericRadiansDescriptor.FACTORY);
    fc.addGenerated(NumericCosDescriptor.FACTORY);
    fc.addGenerated(NumericSinDescriptor.FACTORY);
    fc.addGenerated(NumericTanDescriptor.FACTORY);
    fc.addGenerated(NumericExpDescriptor.FACTORY);
    fc.addGenerated(NumericLnDescriptor.FACTORY);
    fc.addGenerated(NumericLogDescriptor.FACTORY);
    fc.addGenerated(NumericSqrtDescriptor.FACTORY);
    fc.addGenerated(NumericSignDescriptor.FACTORY);
    fc.addGenerated(NumericTruncDescriptor.FACTORY);
    fc.addGenerated(NumericATan2Descriptor.FACTORY);
    // Comparisons.
    fc.addGenerated(EqualsDescriptor.FACTORY);
    fc.addGenerated(GreaterThanDescriptor.FACTORY);
    fc.addGenerated(GreaterThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(LessThanDescriptor.FACTORY);
    fc.addGenerated(LessThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(NotEqualsDescriptor.FACTORY);
    // If-Equals functions
    fc.addGenerated(MissingIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NullIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NanIfEqualsDescriptor.FACTORY);
    fc.addGenerated(PosInfIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NegInfIfEqualsDescriptor.FACTORY);
    // Binary functions
    fc.addGenerated(BinaryLengthDescriptor.FACTORY);
    fc.addGenerated(ParseBinaryDescriptor.FACTORY);
    fc.addGenerated(PrintBinaryDescriptor.FACTORY);
    fc.addGenerated(BinaryConcatDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromToDescriptor.FACTORY);
    fc.addGenerated(FindBinaryDescriptor.FACTORY);
    fc.addGenerated(FindBinaryFromDescriptor.FACTORY);
    // String functions
    fc.addGenerated(StringLikeDescriptor.FACTORY);
    fc.addGenerated(StringContainsDescriptor.FACTORY);
    fc.addGenerated(StringEndsWithDescriptor.FACTORY);
    fc.addGenerated(StringStartsWithDescriptor.FACTORY);
    fc.addGenerated(SubstringDescriptor.FACTORY);
    fc.addGenerated(StringEqualDescriptor.FACTORY);
    fc.addGenerated(StringLowerCaseDescriptor.FACTORY);
    fc.addGenerated(StringUpperCaseDescriptor.FACTORY);
    fc.addGenerated(StringLengthDescriptor.FACTORY);
    fc.addGenerated(Substring2Descriptor.FACTORY);
    fc.addGenerated(SubstringBeforeDescriptor.FACTORY);
    fc.addGenerated(SubstringAfterDescriptor.FACTORY);
    fc.addGenerated(StringToCodePointDescriptor.FACTORY);
    fc.addGenerated(CodePointToStringDescriptor.FACTORY);
    fc.addGenerated(StringConcatDescriptor.FACTORY);
    fc.addGenerated(StringJoinDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceWithFlagsDescriptor.FACTORY);
    fc.addGenerated(StringInitCapDescriptor.FACTORY);
    fc.addGenerated(StringTrimDescriptor.FACTORY);
    fc.addGenerated(StringLTrimDescriptor.FACTORY);
    fc.addGenerated(StringRTrimDescriptor.FACTORY);
    fc.addGenerated(StringTrim2Descriptor.FACTORY);
    fc.addGenerated(StringLTrim2Descriptor.FACTORY);
    fc.addGenerated(StringRTrim2Descriptor.FACTORY);
    fc.addGenerated(StringPositionDescriptor.FACTORY);
    fc.addGenerated(StringRepeatDescriptor.FACTORY);
    fc.addGenerated(StringReplaceDescriptor.FACTORY);
    fc.addGenerated(StringReplaceWithLimitDescriptor.FACTORY);
    fc.addGenerated(StringReverseDescriptor.FACTORY);
    fc.addGenerated(StringSplitDescriptor.FACTORY);
    // Constructors
    fc.addGenerated(ABooleanConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryHexStringConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryBase64StringConstructorDescriptor.FACTORY);
    fc.addGenerated(AStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt8ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt16ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt32ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt64ConstructorDescriptor.FACTORY);
    fc.addGenerated(AFloatConstructorDescriptor.FACTORY);
    fc.addGenerated(ADoubleConstructorDescriptor.FACTORY);
    fc.addGenerated(APointConstructorDescriptor.FACTORY);
    fc.addGenerated(APoint3DConstructorDescriptor.FACTORY);
    fc.addGenerated(ALineConstructorDescriptor.FACTORY);
    fc.addGenerated(APolygonConstructorDescriptor.FACTORY);
    fc.addGenerated(ACircleConstructorDescriptor.FACTORY);
    fc.addGenerated(ARectangleConstructorDescriptor.FACTORY);
    fc.addGenerated(ATimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AYearMonthDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(ADayTimeDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AUUIDFromStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromTimeConstructorDescriptor.FACTORY);
    // Spatial
    fc.addGenerated(CreatePointDescriptor.FACTORY);
    fc.addGenerated(CreateLineDescriptor.FACTORY);
    fc.addGenerated(CreatePolygonDescriptor.FACTORY);
    fc.addGenerated(CreateCircleDescriptor.FACTORY);
    fc.addGenerated(CreateRectangleDescriptor.FACTORY);
    fc.addGenerated(SpatialAreaDescriptor.FACTORY);
    fc.addGenerated(SpatialDistanceDescriptor.FACTORY);
    fc.addGenerated(CreateMBRDescriptor.FACTORY);
    fc.addGenerated(SpatialCellDescriptor.FACTORY);
    fc.addGenerated(PointXCoordinateAccessor.FACTORY);
    fc.addGenerated(PointYCoordinateAccessor.FACTORY);
    fc.addGenerated(CircleRadiusAccessor.FACTORY);
    fc.addGenerated(CircleCenterAccessor.FACTORY);
    fc.addGenerated(LineRectanglePolygonAccessor.FACTORY);
    // full-text function
    fc.addGenerated(FullTextContainsDescriptor.FACTORY);
    fc.addGenerated(FullTextContainsWithoutOptionDescriptor.FACTORY);
    // Record functions.
    fc.addGenerated(GetRecordFieldsDescriptor.FACTORY);
    fc.addGenerated(GetRecordFieldValueDescriptor.FACTORY);
    fc.addGenerated(DeepEqualityDescriptor.FACTORY);
    fc.addGenerated(RecordMergeDescriptor.FACTORY);
    fc.addGenerated(RecordAddFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordLengthDescriptor.FACTORY);
    fc.addGenerated(RecordNamesDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveDescriptor.FACTORY);
    fc.addGenerated(RecordRenameDescriptor.FACTORY);
    fc.addGenerated(RecordUnwrapDescriptor.FACTORY);
    fc.add(RecordReplaceDescriptor.FACTORY);
    fc.add(RecordAddDescriptor.FACTORY);
    fc.add(RecordPutDescriptor.FACTORY);
    fc.addGenerated(RecordValuesDescriptor.FACTORY);
    fc.addGenerated(PairsDescriptor.FACTORY);
    // Spatial and temporal type accessors
    fc.addGenerated(TemporalYearAccessor.FACTORY);
    fc.addGenerated(TemporalMonthAccessor.FACTORY);
    fc.addGenerated(TemporalDayAccessor.FACTORY);
    fc.addGenerated(TemporalHourAccessor.FACTORY);
    fc.addGenerated(TemporalMinuteAccessor.FACTORY);
    fc.addGenerated(TemporalSecondAccessor.FACTORY);
    fc.addGenerated(TemporalMillisecondAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDatetimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDatetimeAccessor.FACTORY);
    // Temporal functions
    fc.addGenerated(UnixTimeFromDateInDaysDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromTimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DateFromUnixTimeInDaysDescriptor.FACTORY);
    fc.addGenerated(DateFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(TimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(TimeFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromDateAndTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDurationFromDateTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDuartionFromDateDescriptor.FACTORY);
    fc.addGenerated(AdjustDateTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(AdjustTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(IntervalBeforeDescriptor.FACTORY);
    fc.addGenerated(IntervalAfterDescriptor.FACTORY);
    fc.addGenerated(IntervalMeetsDescriptor.FACTORY);
    fc.addGenerated(IntervalMetByDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlapsDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlappedByDescriptor.FACTORY);
    fc.addGenerated(OverlapDescriptor.FACTORY);
    fc.addGenerated(IntervalStartsDescriptor.FACTORY);
    fc.addGenerated(IntervalStartedByDescriptor.FACTORY);
    fc.addGenerated(IntervalCoversDescriptor.FACTORY);
    fc.addGenerated(IntervalCoveredByDescriptor.FACTORY);
    fc.addGenerated(IntervalEndsDescriptor.FACTORY);
    fc.addGenerated(IntervalEndedByDescriptor.FACTORY);
    fc.addGenerated(DurationFromMillisecondsDescriptor.FACTORY);
    fc.addGenerated(DurationFromMonthsDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(MonthsFromYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(MillisecondsFromDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(DurationEqualDescriptor.FACTORY);
    fc.addGenerated(GetYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(GetDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(IntervalBinDescriptor.FACTORY);
    fc.addGenerated(OverlapBinsDescriptor.FACTORY);
    fc.addGenerated(DayOfWeekDescriptor.FACTORY);
    fc.addGenerated(ParseDateDescriptor.FACTORY);
    fc.addGenerated(ParseTimeDescriptor.FACTORY);
    fc.addGenerated(ParseDateTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateDescriptor.FACTORY);
    fc.addGenerated(PrintTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateTimeDescriptor.FACTORY);
    fc.addGenerated(GetOverlappingIntervalDescriptor.FACTORY);
    fc.addGenerated(DurationFromIntervalDescriptor.FACTORY);
    // Type functions.
    fc.addGenerated(IsArrayDescriptor.FACTORY);
    fc.addGenerated(IsAtomicDescriptor.FACTORY);
    fc.addGenerated(IsBooleanDescriptor.FACTORY);
    fc.addGenerated(IsNumberDescriptor.FACTORY);
    fc.addGenerated(IsObjectDescriptor.FACTORY);
    fc.addGenerated(IsStringDescriptor.FACTORY);
    fc.addGenerated(ToArrayDescriptor.FACTORY);
    fc.addGenerated(ToAtomicDescriptor.FACTORY);
    fc.addGenerated(ToBigIntDescriptor.FACTORY);
    fc.addGenerated(ToBooleanDescriptor.FACTORY);
    fc.addGenerated(ToDoubleDescriptor.FACTORY);
    fc.addGenerated(ToNumberDescriptor.FACTORY);
    fc.addGenerated(ToObjectDescriptor.FACTORY);
    fc.addGenerated(ToStringDescriptor.FACTORY);
    // Cast function
    fc.addGenerated(CastTypeDescriptor.FACTORY);
    fc.addGenerated(CastTypeLaxDescriptor.FACTORY);
    // Record function
    fc.addGenerated(RecordPairsDescriptor.FACTORY);
    // Other functions
    fc.addGenerated(RandomWithSeedDescriptor.FACTORY);
    ServiceLoader.load(IFunctionRegistrant.class).iterator().forEachRemaining(c -> c.register(fc));
    return fc;
}
#method_after
public static FunctionCollection createDefaultFunctionCollection() {
    FunctionCollection fc = new FunctionCollection();
    // array functions
    fc.addGenerated(ArrayAppendDescriptor.FACTORY);
    fc.addGenerated(ArrayPositionDescriptor.FACTORY);
    fc.addGenerated(ArrayRepeatDescriptor.FACTORY);
    fc.addGenerated(ArrayReverseDescriptor.FACTORY);
    fc.addGenerated(ArrayContainsDescriptor.FACTORY);
    // unnesting functions
    fc.add(TidRunningAggregateDescriptor.FACTORY);
    fc.add(ScanCollectionDescriptor.FACTORY);
    fc.add(RangeDescriptor.FACTORY);
    fc.add(SubsetCollectionDescriptor.FACTORY);
    // aggregate functions
    fc.add(ListifyAggregateDescriptor.FACTORY);
    fc.add(CountAggregateDescriptor.FACTORY);
    fc.add(AvgAggregateDescriptor.FACTORY);
    fc.add(LocalAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SumAggregateDescriptor.FACTORY);
    fc.add(LocalSumAggregateDescriptor.FACTORY);
    fc.add(MaxAggregateDescriptor.FACTORY);
    fc.add(LocalMaxAggregateDescriptor.FACTORY);
    fc.add(MinAggregateDescriptor.FACTORY);
    fc.add(LocalMinAggregateDescriptor.FACTORY);
    fc.add(FirstElementAggregateDescriptor.FACTORY);
    fc.add(LocalFirstElementAggregateDescriptor.FACTORY);
    // serializable aggregates
    fc.add(SerializableCountAggregateDescriptor.FACTORY);
    fc.add(SerializableAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSumAggregateDescriptor.FACTORY);
    // scalar aggregates
    fc.add(ScalarCountAggregateDescriptor.FACTORY);
    fc.add(ScalarAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSumAggregateDescriptor.FACTORY);
    fc.add(ScalarMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarMinAggregateDescriptor.FACTORY);
    fc.add(EmptyStreamAggregateDescriptor.FACTORY);
    fc.add(NonEmptyStreamAggregateDescriptor.FACTORY);
    // SQL aggregates
    fc.add(SqlCountAggregateDescriptor.FACTORY);
    fc.add(SqlAvgAggregateDescriptor.FACTORY);
    fc.add(LocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SqlSumAggregateDescriptor.FACTORY);
    fc.add(LocalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SqlMaxAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMaxAggregateDescriptor.FACTORY);
    fc.add(SqlMinAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMinAggregateDescriptor.FACTORY);
    // SQL serializable aggregates
    fc.add(SerializableSqlCountAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlSumAggregateDescriptor.FACTORY);
    // SQL scalar aggregates
    fc.add(ScalarSqlCountAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlSumAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMinAggregateDescriptor.FACTORY);
    // boolean functions
    fc.add(AndDescriptor.FACTORY);
    fc.add(OrDescriptor.FACTORY);
    // Record constructors / functions
    fc.add(ClosedRecordConstructorDescriptor.FACTORY);
    fc.add(OpenRecordConstructorDescriptor.FACTORY);
    fc.add(RecordConcatDescriptor.FACTORY);
    fc.add(RecordConcatStrictDescriptor.FACTORY);
    // List constructors
    fc.add(OrderedListConstructorDescriptor.FACTORY);
    fc.add(UnorderedListConstructorDescriptor.FACTORY);
    // Sleep function
    fc.add(SleepDescriptor.FACTORY);
    // Inject failure function
    fc.add(InjectFailureDescriptor.FACTORY);
    // Get Job Parameter function
    fc.add(GetJobParameterByNameDescriptor.FACTORY);
    // Switch case
    fc.add(SwitchCaseDescriptor.FACTORY);
    // null functions
    fc.add(IsMissingDescriptor.FACTORY);
    fc.add(IsNullDescriptor.FACTORY);
    fc.add(IsUnknownDescriptor.FACTORY);
    fc.add(IsSystemNullDescriptor.FACTORY);
    fc.add(CheckUnknownDescriptor.FACTORY);
    fc.add(IfMissingDescriptor.FACTORY);
    fc.add(IfNullDescriptor.FACTORY);
    fc.add(IfMissingOrNullDescriptor.FACTORY);
    // uuid generators (zero independent functions)
    fc.add(CreateUUIDDescriptor.FACTORY);
    fc.add(UUIDDescriptor.FACTORY);
    fc.add(CreateQueryUIDDescriptor.FACTORY);
    fc.add(RandomDescriptor.FACTORY);
    fc.add(CurrentDateDescriptor.FACTORY);
    fc.add(CurrentTimeDescriptor.FACTORY);
    fc.add(CurrentDateTimeDescriptor.FACTORY);
    // functions that need generated class for null-handling.
    // Element accessors.
    fc.addGenerated(FieldAccessByIndexDescriptor.FACTORY);
    fc.addGenerated(FieldAccessByNameDescriptor.FACTORY);
    fc.addGenerated(FieldAccessNestedDescriptor.FACTORY);
    fc.addGenerated(AnyCollectionMemberDescriptor.FACTORY);
    fc.addGenerated(GetItemDescriptor.FACTORY);
    // Numeric functions
    fc.add(IfInfDescriptor.FACTORY);
    fc.add(IfNanDescriptor.FACTORY);
    fc.add(IfNanOrInfDescriptor.FACTORY);
    fc.addGenerated(NumericUnaryMinusDescriptor.FACTORY);
    fc.addGenerated(NumericAddDescriptor.FACTORY);
    fc.addGenerated(NumericDivideDescriptor.FACTORY);
    fc.addGenerated(NumericDivDescriptor.FACTORY);
    fc.addGenerated(NumericMultiplyDescriptor.FACTORY);
    fc.addGenerated(NumericSubDescriptor.FACTORY);
    fc.addGenerated(NumericModuloDescriptor.FACTORY);
    fc.addGenerated(NumericPowerDescriptor.FACTORY);
    fc.addGenerated(NotDescriptor.FACTORY);
    fc.addGenerated(LenDescriptor.FACTORY);
    fc.addGenerated(NumericAbsDescriptor.FACTORY);
    fc.addGenerated(NumericCeilingDescriptor.FACTORY);
    fc.addGenerated(NumericFloorDescriptor.FACTORY);
    fc.addGenerated(NumericRoundDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEvenDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEven2Descriptor.FACTORY);
    fc.addGenerated(NumericACosDescriptor.FACTORY);
    fc.addGenerated(NumericASinDescriptor.FACTORY);
    fc.addGenerated(NumericATanDescriptor.FACTORY);
    fc.addGenerated(NumericDegreesDescriptor.FACTORY);
    fc.addGenerated(NumericRadiansDescriptor.FACTORY);
    fc.addGenerated(NumericCosDescriptor.FACTORY);
    fc.addGenerated(NumericSinDescriptor.FACTORY);
    fc.addGenerated(NumericTanDescriptor.FACTORY);
    fc.addGenerated(NumericExpDescriptor.FACTORY);
    fc.addGenerated(NumericLnDescriptor.FACTORY);
    fc.addGenerated(NumericLogDescriptor.FACTORY);
    fc.addGenerated(NumericSqrtDescriptor.FACTORY);
    fc.addGenerated(NumericSignDescriptor.FACTORY);
    fc.addGenerated(NumericTruncDescriptor.FACTORY);
    fc.addGenerated(NumericATan2Descriptor.FACTORY);
    // Comparisons.
    fc.addGenerated(EqualsDescriptor.FACTORY);
    fc.addGenerated(GreaterThanDescriptor.FACTORY);
    fc.addGenerated(GreaterThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(LessThanDescriptor.FACTORY);
    fc.addGenerated(LessThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(NotEqualsDescriptor.FACTORY);
    // If-Equals functions
    fc.addGenerated(MissingIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NullIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NanIfEqualsDescriptor.FACTORY);
    fc.addGenerated(PosInfIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NegInfIfEqualsDescriptor.FACTORY);
    // Binary functions
    fc.addGenerated(BinaryLengthDescriptor.FACTORY);
    fc.addGenerated(ParseBinaryDescriptor.FACTORY);
    fc.addGenerated(PrintBinaryDescriptor.FACTORY);
    fc.addGenerated(BinaryConcatDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromToDescriptor.FACTORY);
    fc.addGenerated(FindBinaryDescriptor.FACTORY);
    fc.addGenerated(FindBinaryFromDescriptor.FACTORY);
    // String functions
    fc.addGenerated(StringLikeDescriptor.FACTORY);
    fc.addGenerated(StringContainsDescriptor.FACTORY);
    fc.addGenerated(StringEndsWithDescriptor.FACTORY);
    fc.addGenerated(StringStartsWithDescriptor.FACTORY);
    fc.addGenerated(SubstringDescriptor.FACTORY);
    fc.addGenerated(StringEqualDescriptor.FACTORY);
    fc.addGenerated(StringLowerCaseDescriptor.FACTORY);
    fc.addGenerated(StringUpperCaseDescriptor.FACTORY);
    fc.addGenerated(StringLengthDescriptor.FACTORY);
    fc.addGenerated(Substring2Descriptor.FACTORY);
    fc.addGenerated(SubstringBeforeDescriptor.FACTORY);
    fc.addGenerated(SubstringAfterDescriptor.FACTORY);
    fc.addGenerated(StringToCodePointDescriptor.FACTORY);
    fc.addGenerated(CodePointToStringDescriptor.FACTORY);
    fc.addGenerated(StringConcatDescriptor.FACTORY);
    fc.addGenerated(StringJoinDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceWithFlagsDescriptor.FACTORY);
    fc.addGenerated(StringInitCapDescriptor.FACTORY);
    fc.addGenerated(StringTrimDescriptor.FACTORY);
    fc.addGenerated(StringLTrimDescriptor.FACTORY);
    fc.addGenerated(StringRTrimDescriptor.FACTORY);
    fc.addGenerated(StringTrim2Descriptor.FACTORY);
    fc.addGenerated(StringLTrim2Descriptor.FACTORY);
    fc.addGenerated(StringRTrim2Descriptor.FACTORY);
    fc.addGenerated(StringPositionDescriptor.FACTORY);
    fc.addGenerated(StringRepeatDescriptor.FACTORY);
    fc.addGenerated(StringReplaceDescriptor.FACTORY);
    fc.addGenerated(StringReplaceWithLimitDescriptor.FACTORY);
    fc.addGenerated(StringReverseDescriptor.FACTORY);
    fc.addGenerated(StringSplitDescriptor.FACTORY);
    // Constructors
    fc.addGenerated(ABooleanConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryHexStringConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryBase64StringConstructorDescriptor.FACTORY);
    fc.addGenerated(AStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt8ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt16ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt32ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt64ConstructorDescriptor.FACTORY);
    fc.addGenerated(AFloatConstructorDescriptor.FACTORY);
    fc.addGenerated(ADoubleConstructorDescriptor.FACTORY);
    fc.addGenerated(APointConstructorDescriptor.FACTORY);
    fc.addGenerated(APoint3DConstructorDescriptor.FACTORY);
    fc.addGenerated(ALineConstructorDescriptor.FACTORY);
    fc.addGenerated(APolygonConstructorDescriptor.FACTORY);
    fc.addGenerated(ACircleConstructorDescriptor.FACTORY);
    fc.addGenerated(ARectangleConstructorDescriptor.FACTORY);
    fc.addGenerated(ATimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AYearMonthDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(ADayTimeDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AUUIDFromStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromTimeConstructorDescriptor.FACTORY);
    // Spatial
    fc.addGenerated(CreatePointDescriptor.FACTORY);
    fc.addGenerated(CreateLineDescriptor.FACTORY);
    fc.addGenerated(CreatePolygonDescriptor.FACTORY);
    fc.addGenerated(CreateCircleDescriptor.FACTORY);
    fc.addGenerated(CreateRectangleDescriptor.FACTORY);
    fc.addGenerated(SpatialAreaDescriptor.FACTORY);
    fc.addGenerated(SpatialDistanceDescriptor.FACTORY);
    fc.addGenerated(CreateMBRDescriptor.FACTORY);
    fc.addGenerated(SpatialCellDescriptor.FACTORY);
    fc.addGenerated(PointXCoordinateAccessor.FACTORY);
    fc.addGenerated(PointYCoordinateAccessor.FACTORY);
    fc.addGenerated(CircleRadiusAccessor.FACTORY);
    fc.addGenerated(CircleCenterAccessor.FACTORY);
    fc.addGenerated(LineRectanglePolygonAccessor.FACTORY);
    // full-text function
    fc.addGenerated(FullTextContainsDescriptor.FACTORY);
    fc.addGenerated(FullTextContainsWithoutOptionDescriptor.FACTORY);
    // Record functions.
    fc.addGenerated(GetRecordFieldsDescriptor.FACTORY);
    fc.addGenerated(GetRecordFieldValueDescriptor.FACTORY);
    fc.addGenerated(DeepEqualityDescriptor.FACTORY);
    fc.addGenerated(RecordMergeDescriptor.FACTORY);
    fc.addGenerated(RecordAddFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordLengthDescriptor.FACTORY);
    fc.addGenerated(RecordNamesDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveDescriptor.FACTORY);
    fc.addGenerated(RecordRenameDescriptor.FACTORY);
    fc.addGenerated(RecordUnwrapDescriptor.FACTORY);
    fc.add(RecordReplaceDescriptor.FACTORY);
    fc.add(RecordAddDescriptor.FACTORY);
    fc.add(RecordPutDescriptor.FACTORY);
    fc.addGenerated(RecordValuesDescriptor.FACTORY);
    fc.addGenerated(PairsDescriptor.FACTORY);
    // Spatial and temporal type accessors
    fc.addGenerated(TemporalYearAccessor.FACTORY);
    fc.addGenerated(TemporalMonthAccessor.FACTORY);
    fc.addGenerated(TemporalDayAccessor.FACTORY);
    fc.addGenerated(TemporalHourAccessor.FACTORY);
    fc.addGenerated(TemporalMinuteAccessor.FACTORY);
    fc.addGenerated(TemporalSecondAccessor.FACTORY);
    fc.addGenerated(TemporalMillisecondAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDatetimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDatetimeAccessor.FACTORY);
    // Temporal functions
    fc.addGenerated(UnixTimeFromDateInDaysDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromTimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DateFromUnixTimeInDaysDescriptor.FACTORY);
    fc.addGenerated(DateFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(TimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(TimeFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromDateAndTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDurationFromDateTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDuartionFromDateDescriptor.FACTORY);
    fc.addGenerated(AdjustDateTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(AdjustTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(IntervalBeforeDescriptor.FACTORY);
    fc.addGenerated(IntervalAfterDescriptor.FACTORY);
    fc.addGenerated(IntervalMeetsDescriptor.FACTORY);
    fc.addGenerated(IntervalMetByDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlapsDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlappedByDescriptor.FACTORY);
    fc.addGenerated(OverlapDescriptor.FACTORY);
    fc.addGenerated(IntervalStartsDescriptor.FACTORY);
    fc.addGenerated(IntervalStartedByDescriptor.FACTORY);
    fc.addGenerated(IntervalCoversDescriptor.FACTORY);
    fc.addGenerated(IntervalCoveredByDescriptor.FACTORY);
    fc.addGenerated(IntervalEndsDescriptor.FACTORY);
    fc.addGenerated(IntervalEndedByDescriptor.FACTORY);
    fc.addGenerated(DurationFromMillisecondsDescriptor.FACTORY);
    fc.addGenerated(DurationFromMonthsDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(MonthsFromYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(MillisecondsFromDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(DurationEqualDescriptor.FACTORY);
    fc.addGenerated(GetYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(GetDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(IntervalBinDescriptor.FACTORY);
    fc.addGenerated(OverlapBinsDescriptor.FACTORY);
    fc.addGenerated(DayOfWeekDescriptor.FACTORY);
    fc.addGenerated(ParseDateDescriptor.FACTORY);
    fc.addGenerated(ParseTimeDescriptor.FACTORY);
    fc.addGenerated(ParseDateTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateDescriptor.FACTORY);
    fc.addGenerated(PrintTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateTimeDescriptor.FACTORY);
    fc.addGenerated(GetOverlappingIntervalDescriptor.FACTORY);
    fc.addGenerated(DurationFromIntervalDescriptor.FACTORY);
    // Type functions.
    fc.addGenerated(IsArrayDescriptor.FACTORY);
    fc.addGenerated(IsAtomicDescriptor.FACTORY);
    fc.addGenerated(IsBooleanDescriptor.FACTORY);
    fc.addGenerated(IsNumberDescriptor.FACTORY);
    fc.addGenerated(IsObjectDescriptor.FACTORY);
    fc.addGenerated(IsStringDescriptor.FACTORY);
    fc.addGenerated(ToArrayDescriptor.FACTORY);
    fc.addGenerated(ToAtomicDescriptor.FACTORY);
    fc.addGenerated(ToBigIntDescriptor.FACTORY);
    fc.addGenerated(ToBooleanDescriptor.FACTORY);
    fc.addGenerated(ToDoubleDescriptor.FACTORY);
    fc.addGenerated(ToNumberDescriptor.FACTORY);
    fc.addGenerated(ToObjectDescriptor.FACTORY);
    fc.addGenerated(ToStringDescriptor.FACTORY);
    // Cast function
    fc.addGenerated(CastTypeDescriptor.FACTORY);
    fc.addGenerated(CastTypeLaxDescriptor.FACTORY);
    // Record function
    fc.addGenerated(RecordPairsDescriptor.FACTORY);
    // Other functions
    fc.addGenerated(RandomWithSeedDescriptor.FACTORY);
    ServiceLoader.load(IFunctionRegistrant.class).iterator().forEachRemaining(c -> c.register(fc));
    return fc;
}
#end_block

#method_before
// ----------------------
// Item accessors
// ----------------------
public int getItemOffset(AbstractCollectionType inputType, int index) throws HyracksDataException {
    LOGGER.info("Getting item offset at index {}", index);
    if (isFixedType(inputType)) {
        LOGGER.info("List is of fixed type");
        return getItemCountOffset() + getItemCountSize() + index * getFixedLength(inputType);
    } else {
        LOGGER.info("List is of not fixed type");
        int offset = getItemCountOffset() + getItemCountSize() + index * ITEM_OFFSET_SIZE;
        LOGGER.info("The offset location for index {} is {}", index, offset);
        return start + IntegerPointable.getInteger(bytes, offset);
    }
}
#method_after
// ----------------------
// Item accessors
// ----------------------
public int getItemOffset(AbstractCollectionType inputType, int index) throws HyracksDataException {
    if (isFixedType(inputType)) {
        return getItemCountOffset() + getItemCountSize() + index * getFixedLength(inputType);
    } else {
        int offset = getItemCountOffset() + getItemCountSize() + index * ITEM_OFFSET_SIZE;
        return start + IntegerPointable.getInteger(bytes, offset);
    }
}
#end_block

#method_before
@Override
public void commitTransaction(MetadataTransactionContext ctx) {
    try {
        metadataNode.commitTransaction(ctx.getTxnId());
        cache.commit(ctx);
    } catch (Throwable th) {
        // Metadata node should abort all transactions on re-joining the new CC
        LOGGER.fatal("Failure committing a metadata transaction", th);
        ExitUtil.halt(ExitUtil.EC_FAILED_TO_COMMIT_METADATA_TXN);
    }
}
#method_after
@SuppressWarnings("squid:S1181")
@Override
public void commitTransaction(MetadataTransactionContext ctx) {
    try {
        metadataNode.commitTransaction(ctx.getTxnId());
        cache.commit(ctx);
    } catch (Throwable th) {
        // Metadata node should abort all transactions on re-joining the new CC
        LOGGER.fatal("Failure committing a metadata transaction", th);
        ExitUtil.halt(ExitUtil.EC_FAILED_TO_COMMIT_METADATA_TXN);
    }
}
#end_block

#method_before
@Override
public void abortTransaction(MetadataTransactionContext ctx) {
    try {
        metadataNode.abortTransaction(ctx.getTxnId());
    } catch (Throwable th) {
        // Metadata node should abort all transactions on re-joining the new CC
        LOGGER.fatal("Failure aborting a metadata transaction", th);
        ExitUtil.halt(ExitUtil.EC_FAILED_TO_ABORT_METADATA_TXN);
    }
}
#method_after
@SuppressWarnings("squid:S1181")
@Override
public void abortTransaction(MetadataTransactionContext ctx) {
    try {
        metadataNode.abortTransaction(ctx.getTxnId());
    } catch (Throwable th) {
        // Metadata node should abort all transactions on re-joining the new CC
        LOGGER.fatal("Failure aborting a metadata transaction", th);
        ExitUtil.halt(ExitUtil.EC_FAILED_TO_ABORT_METADATA_TXN);
    }
}
#end_block

#method_before
protected boolean doCreateDataverseStatement(MetadataTransactionContext mdTxnCtx, MetadataProvider metadataProvider, CreateDataverseStatement stmtCreateDataverse) throws Exception {
    String dvName = stmtCreateDataverse.getDataverseName().getValue();
    Dataverse dv = MetadataManager.INSTANCE.getDataverse(metadataProvider.getMetadataTxnContext(), dvName);
    if (dv != null) {
        if (stmtCreateDataverse.getIfNotExists()) {
            MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
            return false;
        } else {
            throw new CompilationException(ErrorCode.DATAVERSE_EXISTS, stmtCreateDataverse.getSourceLocation(), dvName);
        }
    }
    MetadataManager.INSTANCE.addDataverse(metadataProvider.getMetadataTxnContext(), new Dataverse(dvName, stmtCreateDataverse.getFormat(), MetadataUtil.PENDING_NO_OP));
    MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
    return true;
}
#method_after
@SuppressWarnings("squid:S00112")
protected boolean doCreateDataverseStatement(MetadataTransactionContext mdTxnCtx, MetadataProvider metadataProvider, CreateDataverseStatement stmtCreateDataverse) throws Exception {
    String dvName = stmtCreateDataverse.getDataverseName().getValue();
    Dataverse dv = MetadataManager.INSTANCE.getDataverse(metadataProvider.getMetadataTxnContext(), dvName);
    if (dv != null) {
        if (stmtCreateDataverse.getIfNotExists()) {
            MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
            return false;
        } else {
            throw new CompilationException(ErrorCode.DATAVERSE_EXISTS, stmtCreateDataverse.getSourceLocation(), dvName);
        }
    }
    MetadataManager.INSTANCE.addDataverse(metadataProvider.getMetadataTxnContext(), new Dataverse(dvName, stmtCreateDataverse.getFormat(), MetadataUtil.PENDING_NO_OP));
    MetadataManager.INSTANCE.commitTransaction(mdTxnCtx);
    return true;
}
#end_block

#method_before
public String getOpenFieldName(ARecordType recordType, int fieldId) throws IOException {
    StringBuilder str = new StringBuilder();
    int offset = getOpenFieldNameOffset(recordType, fieldId);
    UTF8StringUtil.toString(str, bytes, offset);
    String fieldName = str.toString();
    LOGGER.info("Open field name {}", fieldName);
    return fieldName;
}
#method_after
public String getOpenFieldName(ARecordType recordType, int fieldId) throws IOException {
    StringBuilder str = new StringBuilder();
    int offset = getOpenFieldNameOffset(recordType, fieldId);
    UTF8StringUtil.toString(str, bytes, offset);
    String fieldName = str.toString();
    return fieldName;
}
#end_block

#method_before
public void addHint(IExpressionAnnotation hint) {
    if (hints == null) {
        hints = new ArrayList<>();
    }
    hints.add(hint);
}
#method_after
public void addHint(IExpressionAnnotation hint) {
    if (hint == null) {
        return;
    }
    if (hints == null) {
        hints = new ArrayList<>();
    }
    hints.add(hint);
}
#end_block

#method_before
public void addHints(List<IExpressionAnnotation> hint) {
    if (hints == null) {
        hints = new ArrayList<>();
    }
    hints.addAll(hint);
}
#method_after
public void addHints(List<IExpressionAnnotation> newHints) {
    if (newHints == null) {
        return;
    }
    if (hints == null) {
        hints = new ArrayList<>();
    }
    hints.addAll(newHints);
}
#end_block

#method_before
@Override
public SelectExpression visit(SelectExpression selectExpression, Void arg) throws CompilationException {
    List<LetClause> lets = new ArrayList<>();
    SelectSetOperation select;
    OrderbyClause orderby = null;
    LimitClause limit = null;
    // visit let list
    if (selectExpression.hasLetClauses()) {
        for (LetClause letClause : selectExpression.getLetList()) {
            lets.add((LetClause) letClause.accept(this, arg));
        }
    }
    // visit the main select.
    select = (SelectSetOperation) selectExpression.getSelectSetOperation().accept(this, arg);
    // visit order by
    if (selectExpression.hasOrderby()) {
        orderby = (OrderbyClause) selectExpression.getOrderbyClause().accept(this, arg);
    }
    // visit limit
    if (selectExpression.hasLimit()) {
        limit = (LimitClause) selectExpression.getLimitClause().accept(this, arg);
    }
    return new SelectExpression(lets, select, orderby, limit, selectExpression.isSubquery());
}
#method_after
@Override
public SelectExpression visit(SelectExpression selectExpression, Void arg) throws CompilationException {
    List<LetClause> lets = new ArrayList<>();
    SelectSetOperation select;
    OrderbyClause orderby = null;
    LimitClause limit = null;
    // visit let list
    if (selectExpression.hasLetClauses()) {
        for (LetClause letClause : selectExpression.getLetList()) {
            lets.add((LetClause) letClause.accept(this, arg));
        }
    }
    // visit the main select.
    select = (SelectSetOperation) selectExpression.getSelectSetOperation().accept(this, arg);
    // visit order by
    if (selectExpression.hasOrderby()) {
        orderby = (OrderbyClause) selectExpression.getOrderbyClause().accept(this, arg);
    }
    // visit limit
    if (selectExpression.hasLimit()) {
        limit = (LimitClause) selectExpression.getLimitClause().accept(this, arg);
    }
    SelectExpression copy = new SelectExpression(lets, select, orderby, limit, selectExpression.isSubquery());
    copy.addHints(selectExpression.getHints());
    return copy;
}
#end_block

#method_before
@Override
public ListConstructor visit(ListConstructor lc, Void arg) throws CompilationException {
    ListConstructor copy = new ListConstructor(lc.getType(), copyExprList(lc.getExprList(), arg));
    copy.setSourceLocation(lc.getSourceLocation());
    return copy;
}
#method_after
@Override
public ListConstructor visit(ListConstructor lc, Void arg) throws CompilationException {
    ListConstructor copy = new ListConstructor(lc.getType(), copyExprList(lc.getExprList(), arg));
    copy.setSourceLocation(lc.getSourceLocation());
    copy.addHints(lc.getHints());
    return copy;
}
#end_block

#method_before
@Override
public RecordConstructor visit(RecordConstructor rc, Void arg) throws CompilationException {
    List<FieldBinding> bindings = new ArrayList<>();
    for (FieldBinding binding : rc.getFbList()) {
        FieldBinding fb = new FieldBinding((Expression) binding.getLeftExpr().accept(this, arg), (Expression) binding.getRightExpr().accept(this, arg));
        bindings.add(fb);
    }
    RecordConstructor copy = new RecordConstructor(bindings);
    copy.setSourceLocation(rc.getSourceLocation());
    return copy;
}
#method_after
@Override
public RecordConstructor visit(RecordConstructor rc, Void arg) throws CompilationException {
    List<FieldBinding> bindings = new ArrayList<>();
    for (FieldBinding binding : rc.getFbList()) {
        FieldBinding fb = new FieldBinding((Expression) binding.getLeftExpr().accept(this, arg), (Expression) binding.getRightExpr().accept(this, arg));
        bindings.add(fb);
    }
    RecordConstructor copy = new RecordConstructor(bindings);
    copy.setSourceLocation(rc.getSourceLocation());
    copy.addHints(rc.getHints());
    return copy;
}
#end_block

#method_before
@Override
public OperatorExpr visit(OperatorExpr operatorExpr, Void arg) throws CompilationException {
    OperatorExpr copy = new OperatorExpr(copyExprList(operatorExpr.getExprList(), arg), operatorExpr.getExprBroadcastIdx(), operatorExpr.getOpList(), operatorExpr.isCurrentop(), operatorExpr.getHints());
    copy.setSourceLocation(operatorExpr.getSourceLocation());
    return copy;
}
#method_after
@Override
public OperatorExpr visit(OperatorExpr operatorExpr, Void arg) throws CompilationException {
    OperatorExpr copy = new OperatorExpr(copyExprList(operatorExpr.getExprList(), arg), operatorExpr.getExprBroadcastIdx(), operatorExpr.getOpList(), operatorExpr.isCurrentop());
    copy.setSourceLocation(operatorExpr.getSourceLocation());
    copy.addHints(operatorExpr.getHints());
    return copy;
}
#end_block

#method_before
@Override
public IfExpr visit(IfExpr ifExpr, Void arg) throws CompilationException {
    Expression conditionExpr = (Expression) ifExpr.getCondExpr().accept(this, arg);
    Expression thenExpr = (Expression) ifExpr.getThenExpr().accept(this, arg);
    Expression elseExpr = (Expression) ifExpr.getElseExpr().accept(this, arg);
    IfExpr copy = new IfExpr(conditionExpr, thenExpr, elseExpr);
    copy.setSourceLocation(ifExpr.getSourceLocation());
    return copy;
}
#method_after
@Override
public IfExpr visit(IfExpr ifExpr, Void arg) throws CompilationException {
    Expression conditionExpr = (Expression) ifExpr.getCondExpr().accept(this, arg);
    Expression thenExpr = (Expression) ifExpr.getThenExpr().accept(this, arg);
    Expression elseExpr = (Expression) ifExpr.getElseExpr().accept(this, arg);
    IfExpr copy = new IfExpr(conditionExpr, thenExpr, elseExpr);
    copy.setSourceLocation(ifExpr.getSourceLocation());
    copy.addHints(ifExpr.getHints());
    return copy;
}
#end_block

#method_before
@Override
public QuantifiedExpression visit(QuantifiedExpression qe, Void arg) throws CompilationException {
    List<QuantifiedPair> quantifiedPairs = new ArrayList<>();
    for (QuantifiedPair pair : qe.getQuantifiedList()) {
        Expression expr = (Expression) pair.getExpr().accept(this, arg);
        VariableExpr var = (VariableExpr) pair.getVarExpr().accept(this, arg);
        quantifiedPairs.add(new QuantifiedPair(var, expr));
    }
    Expression condition = (Expression) qe.getSatisfiesExpr().accept(this, arg);
    QuantifiedExpression copy = new QuantifiedExpression(qe.getQuantifier(), quantifiedPairs, condition);
    copy.setSourceLocation(qe.getSourceLocation());
    return copy;
}
#method_after
@Override
public QuantifiedExpression visit(QuantifiedExpression qe, Void arg) throws CompilationException {
    List<QuantifiedPair> quantifiedPairs = new ArrayList<>();
    for (QuantifiedPair pair : qe.getQuantifiedList()) {
        Expression expr = (Expression) pair.getExpr().accept(this, arg);
        VariableExpr var = (VariableExpr) pair.getVarExpr().accept(this, arg);
        quantifiedPairs.add(new QuantifiedPair(var, expr));
    }
    Expression condition = (Expression) qe.getSatisfiesExpr().accept(this, arg);
    QuantifiedExpression copy = new QuantifiedExpression(qe.getQuantifier(), quantifiedPairs, condition);
    copy.setSourceLocation(qe.getSourceLocation());
    copy.addHints(qe.getHints());
    return copy;
}
#end_block

#method_before
@Override
public CallExpr visit(CallExpr callExpr, Void arg) throws CompilationException {
    List<Expression> newExprList = new ArrayList<>();
    for (Expression expr : callExpr.getExprList()) {
        newExprList.add((Expression) expr.accept(this, arg));
    }
    CallExpr copy = new CallExpr(callExpr.getFunctionSignature(), newExprList);
    copy.setSourceLocation(callExpr.getSourceLocation());
    return copy;
}
#method_after
@Override
public CallExpr visit(CallExpr callExpr, Void arg) throws CompilationException {
    List<Expression> newExprList = new ArrayList<>();
    for (Expression expr : callExpr.getExprList()) {
        newExprList.add((Expression) expr.accept(this, arg));
    }
    CallExpr copy = new CallExpr(callExpr.getFunctionSignature(), newExprList);
    copy.setSourceLocation(callExpr.getSourceLocation());
    copy.addHints(callExpr.getHints());
    return copy;
}
#end_block

#method_before
@Override
public VariableExpr visit(VariableExpr varExpr, Void arg) throws CompilationException {
    VariableExpr clonedVar = new VariableExpr(new VarIdentifier(varExpr.getVar()));
    clonedVar.setSourceLocation(varExpr.getSourceLocation());
    clonedVar.setIsNewVar(varExpr.getIsNewVar());
    return clonedVar;
}
#method_after
@Override
public VariableExpr visit(VariableExpr varExpr, Void arg) throws CompilationException {
    VariableExpr clonedVar = new VariableExpr(new VarIdentifier(varExpr.getVar()));
    clonedVar.setSourceLocation(varExpr.getSourceLocation());
    clonedVar.setIsNewVar(varExpr.getIsNewVar());
    clonedVar.addHints(varExpr.getHints());
    return clonedVar;
}
#end_block

#method_before
@Override
public UnaryExpr visit(UnaryExpr u, Void arg) throws CompilationException {
    UnaryExpr copy = new UnaryExpr(u.getExprType(), (Expression) u.getExpr().accept(this, arg));
    copy.setSourceLocation(u.getSourceLocation());
    return copy;
}
#method_after
@Override
public UnaryExpr visit(UnaryExpr u, Void arg) throws CompilationException {
    UnaryExpr copy = new UnaryExpr(u.getExprType(), (Expression) u.getExpr().accept(this, arg));
    copy.setSourceLocation(u.getSourceLocation());
    copy.addHints(u.getHints());
    return copy;
}
#end_block

#method_before
@Override
public FieldAccessor visit(FieldAccessor fa, Void arg) throws CompilationException {
    FieldAccessor copy = new FieldAccessor((Expression) fa.getExpr().accept(this, arg), fa.getIdent());
    copy.setSourceLocation(fa.getSourceLocation());
    return copy;
}
#method_after
@Override
public FieldAccessor visit(FieldAccessor fa, Void arg) throws CompilationException {
    FieldAccessor copy = new FieldAccessor((Expression) fa.getExpr().accept(this, arg), fa.getIdent());
    copy.setSourceLocation(fa.getSourceLocation());
    copy.addHints(fa.getHints());
    return copy;
}
#end_block

#method_before
@Override
public Expression visit(IndexAccessor ia, Void arg) throws CompilationException {
    Expression expr = (Expression) ia.getExpr().accept(this, arg);
    Expression indexExpr = null;
    if (ia.getIndexExpr() != null) {
        indexExpr = (Expression) ia.getIndexExpr().accept(this, arg);
    }
    IndexAccessor copy = new IndexAccessor(expr, indexExpr);
    copy.setSourceLocation(ia.getSourceLocation());
    return copy;
}
#method_after
@Override
public Expression visit(IndexAccessor ia, Void arg) throws CompilationException {
    Expression expr = (Expression) ia.getExpr().accept(this, arg);
    Expression indexExpr = null;
    if (ia.getIndexExpr() != null) {
        indexExpr = (Expression) ia.getIndexExpr().accept(this, arg);
    }
    IndexAccessor copy = new IndexAccessor(expr, indexExpr);
    copy.setSourceLocation(ia.getSourceLocation());
    copy.addHints(ia.getHints());
    return copy;
}
#end_block

#method_before
@Override
public ILangExpression visit(CaseExpression caseExpr, Void arg) throws CompilationException {
    Expression conditionExpr = (Expression) caseExpr.getConditionExpr().accept(this, arg);
    List<Expression> whenExprList = copyExprList(caseExpr.getWhenExprs(), arg);
    List<Expression> thenExprList = copyExprList(caseExpr.getThenExprs(), arg);
    Expression elseExpr = (Expression) caseExpr.getElseExpr().accept(this, arg);
    CaseExpression copy = new CaseExpression(conditionExpr, whenExprList, thenExprList, elseExpr);
    copy.setSourceLocation(caseExpr.getSourceLocation());
    return copy;
}
#method_after
@Override
public ILangExpression visit(CaseExpression caseExpr, Void arg) throws CompilationException {
    Expression conditionExpr = (Expression) caseExpr.getConditionExpr().accept(this, arg);
    List<Expression> whenExprList = copyExprList(caseExpr.getWhenExprs(), arg);
    List<Expression> thenExprList = copyExprList(caseExpr.getThenExprs(), arg);
    Expression elseExpr = (Expression) caseExpr.getElseExpr().accept(this, arg);
    CaseExpression copy = new CaseExpression(conditionExpr, whenExprList, thenExprList, elseExpr);
    copy.setSourceLocation(caseExpr.getSourceLocation());
    copy.addHints(caseExpr.getHints());
    return copy;
}
#end_block

#method_before
@Override
public Pair<ILangExpression, VariableSubstitutionEnvironment> visit(QuantifiedExpression qe, VariableSubstitutionEnvironment env) throws CompilationException {
    List<QuantifiedPair> oldPairs = qe.getQuantifiedList();
    List<QuantifiedPair> newPairs = new ArrayList<>(oldPairs.size());
    VariableSubstitutionEnvironment newSubs = env;
    for (QuantifiedPair t : oldPairs) {
        VariableExpr newVar = generateNewVariable(context, t.getVarExpr());
        newSubs = VariableCloneAndSubstitutionUtil.eliminateSubstFromList(newVar, newSubs);
        Pair<ILangExpression, VariableSubstitutionEnvironment> p1 = visitUnnesBindingExpression(t.getExpr(), newSubs);
        QuantifiedPair t2 = new QuantifiedPair(newVar, (Expression) p1.first);
        newPairs.add(t2);
    }
    Pair<ILangExpression, VariableSubstitutionEnvironment> p2 = qe.getSatisfiesExpr().accept(this, newSubs);
    QuantifiedExpression qe2 = new QuantifiedExpression(qe.getQuantifier(), newPairs, (Expression) p2.first);
    qe2.setSourceLocation(qe.getSourceLocation());
    return new Pair<>(qe2, newSubs);
}
#method_after
@Override
public Pair<ILangExpression, VariableSubstitutionEnvironment> visit(QuantifiedExpression qe, VariableSubstitutionEnvironment env) throws CompilationException {
    List<QuantifiedPair> oldPairs = qe.getQuantifiedList();
    List<QuantifiedPair> newPairs = new ArrayList<>(oldPairs.size());
    VariableSubstitutionEnvironment newSubs = env;
    for (QuantifiedPair t : oldPairs) {
        VariableExpr newVar = generateNewVariable(context, t.getVarExpr());
        newSubs = VariableCloneAndSubstitutionUtil.eliminateSubstFromList(newVar, newSubs);
        Pair<ILangExpression, VariableSubstitutionEnvironment> p1 = visitUnnesBindingExpression(t.getExpr(), newSubs);
        QuantifiedPair t2 = new QuantifiedPair(newVar, (Expression) p1.first);
        newPairs.add(t2);
    }
    Pair<ILangExpression, VariableSubstitutionEnvironment> p2 = qe.getSatisfiesExpr().accept(this, newSubs);
    QuantifiedExpression qe2 = new QuantifiedExpression(qe.getQuantifier(), newPairs, (Expression) p2.first);
    qe2.setSourceLocation(qe.getSourceLocation());
    qe2.addHints(qe.getHints());
    return new Pair<>(qe2, newSubs);
}
#end_block

#method_before
@Override
public Pair<ILangExpression, VariableSubstitutionEnvironment> visit(CallExpr pf, VariableSubstitutionEnvironment env) throws CompilationException {
    List<Expression> exprList = VariableCloneAndSubstitutionUtil.visitAndCloneExprList(pf.getExprList(), env, this);
    CallExpr f = new CallExpr(pf.getFunctionSignature(), exprList);
    f.setSourceLocation(pf.getSourceLocation());
    return new Pair<>(f, env);
}
#method_after
@Override
public Pair<ILangExpression, VariableSubstitutionEnvironment> visit(CallExpr pf, VariableSubstitutionEnvironment env) throws CompilationException {
    List<Expression> exprList = VariableCloneAndSubstitutionUtil.visitAndCloneExprList(pf.getExprList(), env, this);
    CallExpr f = new CallExpr(pf.getFunctionSignature(), exprList);
    f.setSourceLocation(pf.getSourceLocation());
    f.addHints(pf.getHints());
    return new Pair<>(f, env);
}
#end_block

#method_before
@Override
public Pair<ILangExpression, VariableSubstitutionEnvironment> visit(IfExpr ifexpr, VariableSubstitutionEnvironment env) throws CompilationException {
    Pair<ILangExpression, VariableSubstitutionEnvironment> p1 = ifexpr.getCondExpr().accept(this, env);
    Pair<ILangExpression, VariableSubstitutionEnvironment> p2 = ifexpr.getThenExpr().accept(this, env);
    Pair<ILangExpression, VariableSubstitutionEnvironment> p3 = ifexpr.getElseExpr().accept(this, env);
    IfExpr i = new IfExpr((Expression) p1.first, (Expression) p2.first, (Expression) p3.first);
    i.setSourceLocation(ifexpr.getSourceLocation());
    return new Pair<>(i, env);
}
#method_after
@Override
public Pair<ILangExpression, VariableSubstitutionEnvironment> visit(IfExpr ifexpr, VariableSubstitutionEnvironment env) throws CompilationException {
    Pair<ILangExpression, VariableSubstitutionEnvironment> p1 = ifexpr.getCondExpr().accept(this, env);
    Pair<ILangExpression, VariableSubstitutionEnvironment> p2 = ifexpr.getThenExpr().accept(this, env);
    Pair<ILangExpression, VariableSubstitutionEnvironment> p3 = ifexpr.getElseExpr().accept(this, env);
    IfExpr i = new IfExpr((Expression) p1.first, (Expression) p2.first, (Expression) p3.first);
    i.setSourceLocation(ifexpr.getSourceLocation());
    i.addHints(ifexpr.getHints());
    return new Pair<>(i, env);
}
#end_block

#method_before
@Override
public Pair<ILangExpression, VariableSubstitutionEnvironment> visit(ListConstructor lc, VariableSubstitutionEnvironment env) throws CompilationException {
    List<Expression> oldExprList = lc.getExprList();
    List<Expression> exprs = VariableCloneAndSubstitutionUtil.visitAndCloneExprList(oldExprList, env, this);
    ListConstructor c = new ListConstructor(lc.getType(), exprs);
    c.setSourceLocation(lc.getSourceLocation());
    return new Pair<>(c, env);
}
#method_after
@Override
public Pair<ILangExpression, VariableSubstitutionEnvironment> visit(ListConstructor lc, VariableSubstitutionEnvironment env) throws CompilationException {
    List<Expression> oldExprList = lc.getExprList();
    List<Expression> exprs = VariableCloneAndSubstitutionUtil.visitAndCloneExprList(oldExprList, env, this);
    ListConstructor c = new ListConstructor(lc.getType(), exprs);
    c.setSourceLocation(lc.getSourceLocation());
    c.addHints(lc.getHints());
    return new Pair<>(c, env);
}
#end_block

#method_before
@Override
public Pair<ILangExpression, VariableSubstitutionEnvironment> visit(OperatorExpr op, VariableSubstitutionEnvironment env) throws CompilationException {
    List<Expression> oldExprList = op.getExprList();
    List<Expression> exprs = new ArrayList<>(oldExprList.size());
    for (Expression e : oldExprList) {
        Pair<ILangExpression, VariableSubstitutionEnvironment> p1 = e.accept(this, env);
        exprs.add((Expression) p1.first);
    }
    OperatorExpr oe = new OperatorExpr(exprs, op.getExprBroadcastIdx(), op.getOpList(), op.isCurrentop(), op.getHints());
    oe.setSourceLocation(op.getSourceLocation());
    return new Pair<>(oe, env);
}
#method_after
@Override
public Pair<ILangExpression, VariableSubstitutionEnvironment> visit(OperatorExpr op, VariableSubstitutionEnvironment env) throws CompilationException {
    List<Expression> oldExprList = op.getExprList();
    List<Expression> exprs = new ArrayList<>(oldExprList.size());
    for (Expression e : oldExprList) {
        Pair<ILangExpression, VariableSubstitutionEnvironment> p1 = e.accept(this, env);
        exprs.add((Expression) p1.first);
    }
    OperatorExpr oe = new OperatorExpr(exprs, op.getExprBroadcastIdx(), op.getOpList(), op.isCurrentop());
    oe.setSourceLocation(op.getSourceLocation());
    oe.addHints(op.getHints());
    return new Pair<>(oe, env);
}
#end_block

#method_before
@Override
public Pair<ILangExpression, VariableSubstitutionEnvironment> visit(RecordConstructor rc, VariableSubstitutionEnvironment env) throws CompilationException {
    List<FieldBinding> oldFbs = rc.getFbList();
    ArrayList<FieldBinding> newFbs = new ArrayList<>(oldFbs.size());
    for (FieldBinding fb : oldFbs) {
        Pair<ILangExpression, VariableSubstitutionEnvironment> p1 = fb.getLeftExpr().accept(this, env);
        Pair<ILangExpression, VariableSubstitutionEnvironment> p2 = fb.getRightExpr().accept(this, env);
        FieldBinding fb2 = new FieldBinding((Expression) p1.first, (Expression) p2.first);
        newFbs.add(fb2);
    }
    RecordConstructor newRc = new RecordConstructor(newFbs);
    newRc.setSourceLocation(rc.getSourceLocation());
    return new Pair<>(newRc, env);
}
#method_after
@Override
public Pair<ILangExpression, VariableSubstitutionEnvironment> visit(RecordConstructor rc, VariableSubstitutionEnvironment env) throws CompilationException {
    List<FieldBinding> oldFbs = rc.getFbList();
    ArrayList<FieldBinding> newFbs = new ArrayList<>(oldFbs.size());
    for (FieldBinding fb : oldFbs) {
        Pair<ILangExpression, VariableSubstitutionEnvironment> p1 = fb.getLeftExpr().accept(this, env);
        Pair<ILangExpression, VariableSubstitutionEnvironment> p2 = fb.getRightExpr().accept(this, env);
        FieldBinding fb2 = new FieldBinding((Expression) p1.first, (Expression) p2.first);
        newFbs.add(fb2);
    }
    RecordConstructor newRc = new RecordConstructor(newFbs);
    newRc.setSourceLocation(rc.getSourceLocation());
    newRc.addHints(rc.getHints());
    return new Pair<>(newRc, env);
}
#end_block

#method_before
@Override
public Pair<ILangExpression, VariableSubstitutionEnvironment> visit(UnaryExpr u, VariableSubstitutionEnvironment env) throws CompilationException {
    Pair<ILangExpression, VariableSubstitutionEnvironment> p1 = u.getExpr().accept(this, env);
    UnaryExpr newU = new UnaryExpr(u.getExprType(), (Expression) p1.first);
    newU.setSourceLocation(u.getSourceLocation());
    return new Pair<>(newU, env);
}
#method_after
@Override
public Pair<ILangExpression, VariableSubstitutionEnvironment> visit(UnaryExpr u, VariableSubstitutionEnvironment env) throws CompilationException {
    Pair<ILangExpression, VariableSubstitutionEnvironment> p1 = u.getExpr().accept(this, env);
    UnaryExpr newU = new UnaryExpr(u.getExprType(), (Expression) p1.first);
    newU.setSourceLocation(u.getSourceLocation());
    newU.addHints(u.getHints());
    return new Pair<>(newU, env);
}
#end_block

#method_before
@Override
public Pair<ILangExpression, VariableSubstitutionEnvironment> visit(IndexAccessor ia, VariableSubstitutionEnvironment env) throws CompilationException {
    Pair<ILangExpression, VariableSubstitutionEnvironment> p1 = ia.getExpr().accept(this, env);
    Expression indexExpr = null;
    if (!ia.isAny()) {
        Pair<ILangExpression, VariableSubstitutionEnvironment> p2 = ia.getIndexExpr().accept(this, env);
        indexExpr = (Expression) p2.first;
    }
    IndexAccessor i = new IndexAccessor((Expression) p1.first, indexExpr);
    i.setAny(ia.isAny());
    i.setSourceLocation(ia.getSourceLocation());
    return new Pair<>(i, env);
}
#method_after
@Override
public Pair<ILangExpression, VariableSubstitutionEnvironment> visit(IndexAccessor ia, VariableSubstitutionEnvironment env) throws CompilationException {
    Pair<ILangExpression, VariableSubstitutionEnvironment> p1 = ia.getExpr().accept(this, env);
    Expression indexExpr = null;
    if (!ia.isAny()) {
        Pair<ILangExpression, VariableSubstitutionEnvironment> p2 = ia.getIndexExpr().accept(this, env);
        indexExpr = (Expression) p2.first;
    }
    IndexAccessor i = new IndexAccessor((Expression) p1.first, indexExpr);
    i.setAny(ia.isAny());
    i.setSourceLocation(ia.getSourceLocation());
    i.addHints(ia.getHints());
    return new Pair<>(i, env);
}
#end_block

#method_before
@Override
public Pair<ILangExpression, VariableSubstitutionEnvironment> visit(FieldAccessor fa, VariableSubstitutionEnvironment env) throws CompilationException {
    Pair<ILangExpression, VariableSubstitutionEnvironment> p = fa.getExpr().accept(this, env);
    FieldAccessor newF = new FieldAccessor((Expression) p.first, fa.getIdent());
    newF.setSourceLocation(fa.getSourceLocation());
    return new Pair<>(newF, p.second);
}
#method_after
@Override
public Pair<ILangExpression, VariableSubstitutionEnvironment> visit(FieldAccessor fa, VariableSubstitutionEnvironment env) throws CompilationException {
    Pair<ILangExpression, VariableSubstitutionEnvironment> p = fa.getExpr().accept(this, env);
    FieldAccessor newF = new FieldAccessor((Expression) p.first, fa.getIdent());
    newF.setSourceLocation(fa.getSourceLocation());
    newF.addHints(fa.getHints());
    return new Pair<>(newF, p.second);
}
#end_block

#method_before
protected Expression rewriteVariableExpr(VariableExpr expr, VariableSubstitutionEnvironment env) throws CompilationException {
    if (env.constainsOldVar(expr)) {
        return env.findSubstitution(expr);
    } else {
        // it is a variable from the context
        VarIdentifier var = context.getRewrittenVar(expr.getVar().getId());
        if (var != null) {
            VariableExpr newVarExpr = new VariableExpr(var);
            newVarExpr.setSourceLocation(expr.getSourceLocation());
            return newVarExpr;
        }
    }
    return expr;
}
#method_after
protected Expression rewriteVariableExpr(VariableExpr expr, VariableSubstitutionEnvironment env) throws CompilationException {
    if (env.constainsOldVar(expr)) {
        return env.findSubstitution(expr);
    } else {
        // it is a variable from the context
        VarIdentifier var = context.getRewrittenVar(expr.getVar().getId());
        if (var != null) {
            VariableExpr newVarExpr = new VariableExpr(var);
            newVarExpr.setSourceLocation(expr.getSourceLocation());
            newVarExpr.addHints(expr.getHints());
            return newVarExpr;
        }
    }
    return expr;
}
#end_block

#method_before
@Override
public void processResult(AMutableInt32 intValue, IPointable result) throws HyracksDataException {
    storage.reset();
    if (intValue.getIntegerValue() == -1) {
        booleanSerde.serialize(ABoolean.FALSE, storage.getDataOutput());
    } else {
        booleanSerde.serialize(ABoolean.TRUE, storage.getDataOutput());
    }
    result.set(storage);
}
#method_after
@Override
public void processResult(AMutableInt32 intValue, IPointable result) throws HyracksDataException {
    storage.reset();
    booleanSerde.serialize(ABoolean.valueOf(intValue.getIntegerValue() != -1), storage.getDataOutput());
    result.set(storage);
}
#end_block

#method_before
public static void setJoinAlgorithmAndExchangeAlgo(AbstractBinaryJoinOperator op, boolean topLevelOp, IOptimizationContext context) throws AlgebricksException {
    if (!topLevelOp) {
        throw new IllegalStateException("Micro operator not implemented for: " + op.getOperatorTag());
    }
    List<LogicalVariable> sideLeft = new LinkedList<>();
    List<LogicalVariable> sideRight = new LinkedList<>();
    List<LogicalVariable> varsLeft = op.getInputs().get(0).getValue().getSchema();
    List<LogicalVariable> varsRight = op.getInputs().get(1).getValue().getSchema();
    if (isHashJoinCondition(op.getCondition().getValue(), varsLeft, varsRight, sideLeft, sideRight)) {
        BroadcastSide side = getBroadcastJoinSide(op.getCondition().getValue(), varsLeft, varsRight);
        if (side == null) {
            setHashJoinOp(op, JoinPartitioningType.PAIRWISE, sideLeft, sideRight, context);
        } else {
            if (side == BroadcastSide.RIGHT) {
                setHashJoinOp(op, JoinPartitioningType.BROADCAST, sideLeft, sideRight, context);
            } else if ((side == BroadcastSide.LEFT && !(op instanceof LeftOuterJoinOperator))) {
                Mutable<ILogicalOperator> opRef0 = op.getInputs().get(0);
                Mutable<ILogicalOperator> opRef1 = op.getInputs().get(1);
                ILogicalOperator tmp = opRef0.getValue();
                opRef0.setValue(opRef1.getValue());
                opRef1.setValue(tmp);
                setHashJoinOp(op, JoinPartitioningType.BROADCAST, sideRight, sideLeft, context);
            } else {
                setHashJoinOp(op, JoinPartitioningType.PAIRWISE, sideLeft, sideRight, context);
            }
        }
    } else {
        setNestedLoopJoinOp(op, context);
    }
}
#method_after
public static void setJoinAlgorithmAndExchangeAlgo(AbstractBinaryJoinOperator op, boolean topLevelOp, IOptimizationContext context) throws AlgebricksException {
    if (!topLevelOp) {
        throw new IllegalStateException("Micro operator not implemented for: " + op.getOperatorTag());
    }
    List<LogicalVariable> sideLeft = new LinkedList<>();
    List<LogicalVariable> sideRight = new LinkedList<>();
    List<LogicalVariable> varsLeft = op.getInputs().get(0).getValue().getSchema();
    List<LogicalVariable> varsRight = op.getInputs().get(1).getValue().getSchema();
    if (isHashJoinCondition(op.getCondition().getValue(), varsLeft, varsRight, sideLeft, sideRight)) {
        BroadcastSide side = getBroadcastJoinSide(op.getCondition().getValue(), varsLeft, varsRight);
        if (side == null) {
            setHashJoinOp(op, JoinPartitioningType.PAIRWISE, sideLeft, sideRight, context);
        } else {
            switch(side) {
                case RIGHT:
                    setHashJoinOp(op, JoinPartitioningType.BROADCAST, sideLeft, sideRight, context);
                    break;
                case LEFT:
                    if (op.getJoinKind() == AbstractBinaryJoinOperator.JoinKind.INNER) {
                        Mutable<ILogicalOperator> opRef0 = op.getInputs().get(0);
                        Mutable<ILogicalOperator> opRef1 = op.getInputs().get(1);
                        ILogicalOperator tmp = opRef0.getValue();
                        opRef0.setValue(opRef1.getValue());
                        opRef1.setValue(tmp);
                        setHashJoinOp(op, JoinPartitioningType.BROADCAST, sideRight, sideLeft, context);
                    } else {
                        setHashJoinOp(op, JoinPartitioningType.PAIRWISE, sideLeft, sideRight, context);
                    }
                    break;
                default:
                    // This should never happen
                    throw new IllegalStateException(side.toString());
            }
        }
    } else {
        setNestedLoopJoinOp(op, context);
    }
}
#end_block

#method_before
@Override
public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException {
    // 1st arg: list
    listEval.evaluate(tuple, listArg);
    byte[] listBytes = listArg.getByteArray();
    int listOffset = listArg.getStartOffset();
    // 2nd arg: value to search for
    searchedValueEval.evaluate(tuple, searchedValueArg);
    byte[] valueBytes = searchedValueArg.getByteArray();
    int valueOffset = searchedValueArg.getStartOffset();
    int valueLength = searchedValueArg.getLength();
    // for now, we don't support deep equality of object/lists. Throw an error if the value is of these types
    if (ATYPETAGDESERIALIZER.deserialize(valueBytes[valueOffset]).isComplexType()) {
        throw HyracksDataException.create(ErrorCode.CANNOT_COMPARE_COMPLEX, sourceLoc);
    }
    if (!ATYPETAGDESERIALIZER.deserialize(listBytes[listOffset]).isListType()) {
        PointableHelper.setNull(result);
        return;
    }
    IBinaryComparator comp = AObjectAscBinaryComparatorFactory.INSTANCE.createBinaryComparator();
    ListAccessor listAccessor = new ListAccessor();
    listAccessor.reset(listBytes, listOffset);
    int numItems = listAccessor.size();
    AMutableInt32 intValue = new AMutableInt32(-1);
    try {
        for (int i = 0; i < numItems; i++) {
            storage.reset();
            listAccessor.writeItem(i, storage.getDataOutput());
            if (comp.compare(storage.getByteArray(), storage.getStartOffset(), storage.getLength(), valueBytes, valueOffset, valueLength) == 0) {
                intValue.setValue(i);
                break;
            }
        }
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    }
    storage.reset();
    ISerializerDeserializer intSerde = SerializerDeserializerProvider.INSTANCE.getSerializerDeserializer(BuiltinType.AINT32);
    intSerde.serialize(intValue, storage.getDataOutput());
    result.set(storage);
}
#method_after
@Override
public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException {
    // 1st arg: list
    listEval.evaluate(tuple, listArg);
    byte[] listBytes = listArg.getByteArray();
    int listOffset = listArg.getStartOffset();
    // 2nd arg: value to search for
    searchedValueEval.evaluate(tuple, searchedValueArg);
    byte[] valueBytes = searchedValueArg.getByteArray();
    int valueOffset = searchedValueArg.getStartOffset();
    int valueLength = searchedValueArg.getLength();
    // for now, we don't support deep equality of object/lists. Throw an error if the value is of these types
    if (ATYPETAGDESERIALIZER.deserialize(valueBytes[valueOffset]).isDerivedType()) {
        throw HyracksDataException.create(ErrorCode.CANNOT_COMPARE_COMPLEX, sourceLoc);
    }
    if (!ATYPETAGDESERIALIZER.deserialize(listBytes[listOffset]).isListType()) {
        PointableHelper.setNull(result);
        return;
    }
    listAccessor.reset(listBytes, listOffset);
    int numItems = listAccessor.size();
    intValue.setValue(-1);
    try {
        for (int i = 0; i < numItems; i++) {
            storage.reset();
            listAccessor.writeItem(i, storage.getDataOutput());
            if (comp.compare(storage.getByteArray(), storage.getStartOffset(), storage.getLength(), valueBytes, valueOffset, valueLength) == 0) {
                intValue.setValue(i);
                break;
            }
        }
    } catch (IOException e) {
        throw HyracksDataException.create(e);
    }
    storage.reset();
    intSerde.serialize(intValue, storage.getDataOutput());
    result.set(storage);
}
#end_block

#method_before
@Test
public void test() throws Exception {
    List<IFunctionDescriptorFactory> functions = FunctionCollection.createDefaultFunctionCollection().getFunctionDescriptorFactories();
    int testedFunctions = 0;
    for (IFunctionDescriptorFactory func : functions) {
        String className = func.getClass().getName();
        // We test all generated functions except
        // record and cast functions, which requires type settings (we test them in runtime tests).
        // TODO(ali): do something better
        String[] splits = className.split("\\.");
        if (className.contains("Gen") && !className.contains("record") && !className.contains("Cast") && !splits[splits.length - 1].startsWith("Array")) {
            testFunction(func);
            ++testedFunctions;
        }
    }
    // 217 is the current number of functions with generated code.
    Assert.assertTrue("expected >= 217 generated functions to be tested, but was " + testedFunctions, testedFunctions >= 217);
}
#method_after
@Test
public void test() throws Exception {
    List<IFunctionDescriptorFactory> functions = FunctionCollection.createDefaultFunctionCollection().getFunctionDescriptorFactories();
    int testedFunctions = 0;
    String[] splits;
    for (IFunctionDescriptorFactory func : functions) {
        String className = func.getClass().getName();
        // We test all generated functions except
        // record and cast functions, which requires type settings (we test them in runtime tests).
        splits = className.split("\\.");
        if (className.contains("Gen") && !className.contains("record") && !className.contains("Cast") && !splits[splits.length - 1].startsWith(arrayAppend)) {
            testFunction(func);
            ++testedFunctions;
        }
    }
    // 217 is the current number of functions with generated code.
    Assert.assertTrue("expected >= 217 generated functions to be tested, but was " + testedFunctions, testedFunctions >= 217);
}
#end_block

#method_before
public static FunctionCollection createDefaultFunctionCollection() {
    FunctionCollection fc = new FunctionCollection();
    // array functions
    fc.addGenerated(ArrayAppendDescriptor.FACTORY);
    fc.addGenerated(ArrayPositionDescriptor.FACTORY);
    // unnesting functions
    fc.add(TidRunningAggregateDescriptor.FACTORY);
    fc.add(ScanCollectionDescriptor.FACTORY);
    fc.add(RangeDescriptor.FACTORY);
    fc.add(SubsetCollectionDescriptor.FACTORY);
    // aggregate functions
    fc.add(ListifyAggregateDescriptor.FACTORY);
    fc.add(CountAggregateDescriptor.FACTORY);
    fc.add(AvgAggregateDescriptor.FACTORY);
    fc.add(LocalAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SumAggregateDescriptor.FACTORY);
    fc.add(LocalSumAggregateDescriptor.FACTORY);
    fc.add(MaxAggregateDescriptor.FACTORY);
    fc.add(LocalMaxAggregateDescriptor.FACTORY);
    fc.add(MinAggregateDescriptor.FACTORY);
    fc.add(LocalMinAggregateDescriptor.FACTORY);
    fc.add(FirstElementAggregateDescriptor.FACTORY);
    fc.add(LocalFirstElementAggregateDescriptor.FACTORY);
    // serializable aggregates
    fc.add(SerializableCountAggregateDescriptor.FACTORY);
    fc.add(SerializableAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSumAggregateDescriptor.FACTORY);
    // scalar aggregates
    fc.add(ScalarCountAggregateDescriptor.FACTORY);
    fc.add(ScalarAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSumAggregateDescriptor.FACTORY);
    fc.add(ScalarMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarMinAggregateDescriptor.FACTORY);
    fc.add(EmptyStreamAggregateDescriptor.FACTORY);
    fc.add(NonEmptyStreamAggregateDescriptor.FACTORY);
    // SQL aggregates
    fc.add(SqlCountAggregateDescriptor.FACTORY);
    fc.add(SqlAvgAggregateDescriptor.FACTORY);
    fc.add(LocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SqlSumAggregateDescriptor.FACTORY);
    fc.add(LocalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SqlMaxAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMaxAggregateDescriptor.FACTORY);
    fc.add(SqlMinAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMinAggregateDescriptor.FACTORY);
    // SQL serializable aggregates
    fc.add(SerializableSqlCountAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlSumAggregateDescriptor.FACTORY);
    // SQL scalar aggregates
    fc.add(ScalarSqlCountAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlSumAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMinAggregateDescriptor.FACTORY);
    // boolean functions
    fc.add(AndDescriptor.FACTORY);
    fc.add(OrDescriptor.FACTORY);
    // Record constructors / functions
    fc.add(ClosedRecordConstructorDescriptor.FACTORY);
    fc.add(OpenRecordConstructorDescriptor.FACTORY);
    fc.add(RecordConcatDescriptor.FACTORY);
    fc.add(RecordConcatStrictDescriptor.FACTORY);
    // List constructors
    fc.add(OrderedListConstructorDescriptor.FACTORY);
    fc.add(UnorderedListConstructorDescriptor.FACTORY);
    // Sleep function
    fc.add(SleepDescriptor.FACTORY);
    // Inject failure function
    fc.add(InjectFailureDescriptor.FACTORY);
    // Get Job Parameter function
    fc.add(GetJobParameterByNameDescriptor.FACTORY);
    // Switch case
    fc.add(SwitchCaseDescriptor.FACTORY);
    // null functions
    fc.add(IsMissingDescriptor.FACTORY);
    fc.add(IsNullDescriptor.FACTORY);
    fc.add(IsUnknownDescriptor.FACTORY);
    fc.add(IsSystemNullDescriptor.FACTORY);
    fc.add(CheckUnknownDescriptor.FACTORY);
    fc.add(IfMissingDescriptor.FACTORY);
    fc.add(IfNullDescriptor.FACTORY);
    fc.add(IfMissingOrNullDescriptor.FACTORY);
    // uuid generators (zero independent functions)
    fc.add(CreateUUIDDescriptor.FACTORY);
    fc.add(UUIDDescriptor.FACTORY);
    fc.add(CreateQueryUIDDescriptor.FACTORY);
    fc.add(RandomDescriptor.FACTORY);
    fc.add(CurrentDateDescriptor.FACTORY);
    fc.add(CurrentTimeDescriptor.FACTORY);
    fc.add(CurrentDateTimeDescriptor.FACTORY);
    // functions that need generated class for null-handling.
    // Element accessors.
    fc.addGenerated(FieldAccessByIndexDescriptor.FACTORY);
    fc.addGenerated(FieldAccessByNameDescriptor.FACTORY);
    fc.addGenerated(FieldAccessNestedDescriptor.FACTORY);
    fc.addGenerated(AnyCollectionMemberDescriptor.FACTORY);
    fc.addGenerated(GetItemDescriptor.FACTORY);
    // Numeric functions
    fc.add(IfInfDescriptor.FACTORY);
    fc.add(IfNanDescriptor.FACTORY);
    fc.add(IfNanOrInfDescriptor.FACTORY);
    fc.addGenerated(NumericUnaryMinusDescriptor.FACTORY);
    fc.addGenerated(NumericAddDescriptor.FACTORY);
    fc.addGenerated(NumericDivideDescriptor.FACTORY);
    fc.addGenerated(NumericDivDescriptor.FACTORY);
    fc.addGenerated(NumericMultiplyDescriptor.FACTORY);
    fc.addGenerated(NumericSubDescriptor.FACTORY);
    fc.addGenerated(NumericModuloDescriptor.FACTORY);
    fc.addGenerated(NumericPowerDescriptor.FACTORY);
    fc.addGenerated(NotDescriptor.FACTORY);
    fc.addGenerated(LenDescriptor.FACTORY);
    fc.addGenerated(NumericAbsDescriptor.FACTORY);
    fc.addGenerated(NumericCeilingDescriptor.FACTORY);
    fc.addGenerated(NumericFloorDescriptor.FACTORY);
    fc.addGenerated(NumericRoundDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEvenDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEven2Descriptor.FACTORY);
    fc.addGenerated(NumericACosDescriptor.FACTORY);
    fc.addGenerated(NumericASinDescriptor.FACTORY);
    fc.addGenerated(NumericATanDescriptor.FACTORY);
    fc.addGenerated(NumericDegreesDescriptor.FACTORY);
    fc.addGenerated(NumericRadiansDescriptor.FACTORY);
    fc.addGenerated(NumericCosDescriptor.FACTORY);
    fc.addGenerated(NumericSinDescriptor.FACTORY);
    fc.addGenerated(NumericTanDescriptor.FACTORY);
    fc.addGenerated(NumericExpDescriptor.FACTORY);
    fc.addGenerated(NumericLnDescriptor.FACTORY);
    fc.addGenerated(NumericLogDescriptor.FACTORY);
    fc.addGenerated(NumericSqrtDescriptor.FACTORY);
    fc.addGenerated(NumericSignDescriptor.FACTORY);
    fc.addGenerated(NumericTruncDescriptor.FACTORY);
    fc.addGenerated(NumericATan2Descriptor.FACTORY);
    // Comparisons.
    fc.addGenerated(EqualsDescriptor.FACTORY);
    fc.addGenerated(GreaterThanDescriptor.FACTORY);
    fc.addGenerated(GreaterThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(LessThanDescriptor.FACTORY);
    fc.addGenerated(LessThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(NotEqualsDescriptor.FACTORY);
    // If-Equals functions
    fc.addGenerated(MissingIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NullIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NanIfEqualsDescriptor.FACTORY);
    fc.addGenerated(PosInfIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NegInfIfEqualsDescriptor.FACTORY);
    // Binary functions
    fc.addGenerated(BinaryLengthDescriptor.FACTORY);
    fc.addGenerated(ParseBinaryDescriptor.FACTORY);
    fc.addGenerated(PrintBinaryDescriptor.FACTORY);
    fc.addGenerated(BinaryConcatDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromToDescriptor.FACTORY);
    fc.addGenerated(FindBinaryDescriptor.FACTORY);
    fc.addGenerated(FindBinaryFromDescriptor.FACTORY);
    // String functions
    fc.addGenerated(StringLikeDescriptor.FACTORY);
    fc.addGenerated(StringContainsDescriptor.FACTORY);
    fc.addGenerated(StringEndsWithDescriptor.FACTORY);
    fc.addGenerated(StringStartsWithDescriptor.FACTORY);
    fc.addGenerated(SubstringDescriptor.FACTORY);
    fc.addGenerated(StringEqualDescriptor.FACTORY);
    fc.addGenerated(StringLowerCaseDescriptor.FACTORY);
    fc.addGenerated(StringUpperCaseDescriptor.FACTORY);
    fc.addGenerated(StringLengthDescriptor.FACTORY);
    fc.addGenerated(Substring2Descriptor.FACTORY);
    fc.addGenerated(SubstringBeforeDescriptor.FACTORY);
    fc.addGenerated(SubstringAfterDescriptor.FACTORY);
    fc.addGenerated(StringToCodePointDescriptor.FACTORY);
    fc.addGenerated(CodePointToStringDescriptor.FACTORY);
    fc.addGenerated(StringConcatDescriptor.FACTORY);
    fc.addGenerated(StringJoinDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceWithFlagsDescriptor.FACTORY);
    fc.addGenerated(StringInitCapDescriptor.FACTORY);
    fc.addGenerated(StringTrimDescriptor.FACTORY);
    fc.addGenerated(StringLTrimDescriptor.FACTORY);
    fc.addGenerated(StringRTrimDescriptor.FACTORY);
    fc.addGenerated(StringTrim2Descriptor.FACTORY);
    fc.addGenerated(StringLTrim2Descriptor.FACTORY);
    fc.addGenerated(StringRTrim2Descriptor.FACTORY);
    fc.addGenerated(StringPositionDescriptor.FACTORY);
    fc.addGenerated(StringRepeatDescriptor.FACTORY);
    fc.addGenerated(StringReplaceDescriptor.FACTORY);
    fc.addGenerated(StringReplaceWithLimitDescriptor.FACTORY);
    fc.addGenerated(StringReverseDescriptor.FACTORY);
    fc.addGenerated(StringSplitDescriptor.FACTORY);
    // Constructors
    fc.addGenerated(ABooleanConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryHexStringConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryBase64StringConstructorDescriptor.FACTORY);
    fc.addGenerated(AStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt8ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt16ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt32ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt64ConstructorDescriptor.FACTORY);
    fc.addGenerated(AFloatConstructorDescriptor.FACTORY);
    fc.addGenerated(ADoubleConstructorDescriptor.FACTORY);
    fc.addGenerated(APointConstructorDescriptor.FACTORY);
    fc.addGenerated(APoint3DConstructorDescriptor.FACTORY);
    fc.addGenerated(ALineConstructorDescriptor.FACTORY);
    fc.addGenerated(APolygonConstructorDescriptor.FACTORY);
    fc.addGenerated(ACircleConstructorDescriptor.FACTORY);
    fc.addGenerated(ARectangleConstructorDescriptor.FACTORY);
    fc.addGenerated(ATimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AYearMonthDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(ADayTimeDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AUUIDFromStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromTimeConstructorDescriptor.FACTORY);
    // Spatial
    fc.addGenerated(CreatePointDescriptor.FACTORY);
    fc.addGenerated(CreateLineDescriptor.FACTORY);
    fc.addGenerated(CreatePolygonDescriptor.FACTORY);
    fc.addGenerated(CreateCircleDescriptor.FACTORY);
    fc.addGenerated(CreateRectangleDescriptor.FACTORY);
    fc.addGenerated(SpatialAreaDescriptor.FACTORY);
    fc.addGenerated(SpatialDistanceDescriptor.FACTORY);
    fc.addGenerated(CreateMBRDescriptor.FACTORY);
    fc.addGenerated(SpatialCellDescriptor.FACTORY);
    fc.addGenerated(PointXCoordinateAccessor.FACTORY);
    fc.addGenerated(PointYCoordinateAccessor.FACTORY);
    fc.addGenerated(CircleRadiusAccessor.FACTORY);
    fc.addGenerated(CircleCenterAccessor.FACTORY);
    fc.addGenerated(LineRectanglePolygonAccessor.FACTORY);
    // full-text function
    fc.addGenerated(FullTextContainsDescriptor.FACTORY);
    fc.addGenerated(FullTextContainsWithoutOptionDescriptor.FACTORY);
    // Record functions.
    fc.addGenerated(GetRecordFieldsDescriptor.FACTORY);
    fc.addGenerated(GetRecordFieldValueDescriptor.FACTORY);
    fc.addGenerated(DeepEqualityDescriptor.FACTORY);
    fc.addGenerated(RecordMergeDescriptor.FACTORY);
    fc.addGenerated(RecordAddFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordLengthDescriptor.FACTORY);
    fc.addGenerated(RecordNamesDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveDescriptor.FACTORY);
    fc.addGenerated(RecordRenameDescriptor.FACTORY);
    fc.addGenerated(RecordUnwrapDescriptor.FACTORY);
    fc.add(RecordReplaceDescriptor.FACTORY);
    // Spatial and temporal type accessors
    fc.addGenerated(TemporalYearAccessor.FACTORY);
    fc.addGenerated(TemporalMonthAccessor.FACTORY);
    fc.addGenerated(TemporalDayAccessor.FACTORY);
    fc.addGenerated(TemporalHourAccessor.FACTORY);
    fc.addGenerated(TemporalMinuteAccessor.FACTORY);
    fc.addGenerated(TemporalSecondAccessor.FACTORY);
    fc.addGenerated(TemporalMillisecondAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDatetimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDatetimeAccessor.FACTORY);
    // Temporal functions
    fc.addGenerated(UnixTimeFromDateInDaysDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromTimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DateFromUnixTimeInDaysDescriptor.FACTORY);
    fc.addGenerated(DateFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(TimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(TimeFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromDateAndTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDurationFromDateTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDuartionFromDateDescriptor.FACTORY);
    fc.addGenerated(AdjustDateTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(AdjustTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(IntervalBeforeDescriptor.FACTORY);
    fc.addGenerated(IntervalAfterDescriptor.FACTORY);
    fc.addGenerated(IntervalMeetsDescriptor.FACTORY);
    fc.addGenerated(IntervalMetByDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlapsDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlappedByDescriptor.FACTORY);
    fc.addGenerated(OverlapDescriptor.FACTORY);
    fc.addGenerated(IntervalStartsDescriptor.FACTORY);
    fc.addGenerated(IntervalStartedByDescriptor.FACTORY);
    fc.addGenerated(IntervalCoversDescriptor.FACTORY);
    fc.addGenerated(IntervalCoveredByDescriptor.FACTORY);
    fc.addGenerated(IntervalEndsDescriptor.FACTORY);
    fc.addGenerated(IntervalEndedByDescriptor.FACTORY);
    fc.addGenerated(DurationFromMillisecondsDescriptor.FACTORY);
    fc.addGenerated(DurationFromMonthsDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(MonthsFromYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(MillisecondsFromDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(DurationEqualDescriptor.FACTORY);
    fc.addGenerated(GetYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(GetDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(IntervalBinDescriptor.FACTORY);
    fc.addGenerated(OverlapBinsDescriptor.FACTORY);
    fc.addGenerated(DayOfWeekDescriptor.FACTORY);
    fc.addGenerated(ParseDateDescriptor.FACTORY);
    fc.addGenerated(ParseTimeDescriptor.FACTORY);
    fc.addGenerated(ParseDateTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateDescriptor.FACTORY);
    fc.addGenerated(PrintTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateTimeDescriptor.FACTORY);
    fc.addGenerated(GetOverlappingIntervalDescriptor.FACTORY);
    fc.addGenerated(DurationFromIntervalDescriptor.FACTORY);
    // Type functions.
    fc.addGenerated(IsArrayDescriptor.FACTORY);
    fc.addGenerated(IsAtomicDescriptor.FACTORY);
    fc.addGenerated(IsBooleanDescriptor.FACTORY);
    fc.addGenerated(IsNumberDescriptor.FACTORY);
    fc.addGenerated(IsObjectDescriptor.FACTORY);
    fc.addGenerated(IsStringDescriptor.FACTORY);
    fc.addGenerated(ToArrayDescriptor.FACTORY);
    fc.addGenerated(ToAtomicDescriptor.FACTORY);
    fc.addGenerated(ToBigIntDescriptor.FACTORY);
    fc.addGenerated(ToBooleanDescriptor.FACTORY);
    fc.addGenerated(ToDoubleDescriptor.FACTORY);
    fc.addGenerated(ToNumberDescriptor.FACTORY);
    fc.addGenerated(ToObjectDescriptor.FACTORY);
    fc.addGenerated(ToStringDescriptor.FACTORY);
    // Cast function
    fc.addGenerated(CastTypeDescriptor.FACTORY);
    fc.addGenerated(CastTypeLaxDescriptor.FACTORY);
    // Record function
    fc.addGenerated(RecordPairsDescriptor.FACTORY);
    // Other functions
    fc.addGenerated(RandomWithSeedDescriptor.FACTORY);
    ServiceLoader.load(IFunctionRegistrant.class).iterator().forEachRemaining(c -> c.register(fc));
    return fc;
}
#method_after
public static FunctionCollection createDefaultFunctionCollection() {
    FunctionCollection fc = new FunctionCollection();
    // array functions
    fc.addGenerated(ArrayAppendDescriptor.FACTORY);
    fc.addGenerated(ArrayPositionDescriptor.FACTORY);
    // unnesting functions
    fc.add(TidRunningAggregateDescriptor.FACTORY);
    fc.add(ScanCollectionDescriptor.FACTORY);
    fc.add(RangeDescriptor.FACTORY);
    fc.add(SubsetCollectionDescriptor.FACTORY);
    // aggregate functions
    fc.add(ListifyAggregateDescriptor.FACTORY);
    fc.add(CountAggregateDescriptor.FACTORY);
    fc.add(AvgAggregateDescriptor.FACTORY);
    fc.add(LocalAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SumAggregateDescriptor.FACTORY);
    fc.add(LocalSumAggregateDescriptor.FACTORY);
    fc.add(MaxAggregateDescriptor.FACTORY);
    fc.add(LocalMaxAggregateDescriptor.FACTORY);
    fc.add(MinAggregateDescriptor.FACTORY);
    fc.add(LocalMinAggregateDescriptor.FACTORY);
    fc.add(FirstElementAggregateDescriptor.FACTORY);
    fc.add(LocalFirstElementAggregateDescriptor.FACTORY);
    // serializable aggregates
    fc.add(SerializableCountAggregateDescriptor.FACTORY);
    fc.add(SerializableAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSumAggregateDescriptor.FACTORY);
    // scalar aggregates
    fc.add(ScalarCountAggregateDescriptor.FACTORY);
    fc.add(ScalarAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSumAggregateDescriptor.FACTORY);
    fc.add(ScalarMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarMinAggregateDescriptor.FACTORY);
    fc.add(EmptyStreamAggregateDescriptor.FACTORY);
    fc.add(NonEmptyStreamAggregateDescriptor.FACTORY);
    // SQL aggregates
    fc.add(SqlCountAggregateDescriptor.FACTORY);
    fc.add(SqlAvgAggregateDescriptor.FACTORY);
    fc.add(LocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SqlSumAggregateDescriptor.FACTORY);
    fc.add(LocalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SqlMaxAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMaxAggregateDescriptor.FACTORY);
    fc.add(SqlMinAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMinAggregateDescriptor.FACTORY);
    // SQL serializable aggregates
    fc.add(SerializableSqlCountAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlSumAggregateDescriptor.FACTORY);
    // SQL scalar aggregates
    fc.add(ScalarSqlCountAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlSumAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMinAggregateDescriptor.FACTORY);
    // boolean functions
    fc.add(AndDescriptor.FACTORY);
    fc.add(OrDescriptor.FACTORY);
    // Record constructors / functions
    fc.add(ClosedRecordConstructorDescriptor.FACTORY);
    fc.add(OpenRecordConstructorDescriptor.FACTORY);
    fc.add(RecordConcatDescriptor.FACTORY);
    fc.add(RecordConcatStrictDescriptor.FACTORY);
    // List constructors
    fc.add(OrderedListConstructorDescriptor.FACTORY);
    fc.add(UnorderedListConstructorDescriptor.FACTORY);
    // Sleep function
    fc.add(SleepDescriptor.FACTORY);
    // Inject failure function
    fc.add(InjectFailureDescriptor.FACTORY);
    // Get Job Parameter function
    fc.add(GetJobParameterByNameDescriptor.FACTORY);
    // Switch case
    fc.add(SwitchCaseDescriptor.FACTORY);
    // null functions
    fc.add(IsMissingDescriptor.FACTORY);
    fc.add(IsNullDescriptor.FACTORY);
    fc.add(IsUnknownDescriptor.FACTORY);
    fc.add(IsSystemNullDescriptor.FACTORY);
    fc.add(CheckUnknownDescriptor.FACTORY);
    fc.add(IfMissingDescriptor.FACTORY);
    fc.add(IfNullDescriptor.FACTORY);
    fc.add(IfMissingOrNullDescriptor.FACTORY);
    // uuid generators (zero independent functions)
    fc.add(CreateUUIDDescriptor.FACTORY);
    fc.add(UUIDDescriptor.FACTORY);
    fc.add(CreateQueryUIDDescriptor.FACTORY);
    fc.add(RandomDescriptor.FACTORY);
    fc.add(CurrentDateDescriptor.FACTORY);
    fc.add(CurrentTimeDescriptor.FACTORY);
    fc.add(CurrentDateTimeDescriptor.FACTORY);
    // functions that need generated class for null-handling.
    // Element accessors.
    fc.addGenerated(FieldAccessByIndexDescriptor.FACTORY);
    fc.addGenerated(FieldAccessByNameDescriptor.FACTORY);
    fc.addGenerated(FieldAccessNestedDescriptor.FACTORY);
    fc.addGenerated(AnyCollectionMemberDescriptor.FACTORY);
    fc.addGenerated(GetItemDescriptor.FACTORY);
    // Numeric functions
    fc.add(IfInfDescriptor.FACTORY);
    fc.add(IfNanDescriptor.FACTORY);
    fc.add(IfNanOrInfDescriptor.FACTORY);
    fc.addGenerated(NumericUnaryMinusDescriptor.FACTORY);
    fc.addGenerated(NumericAddDescriptor.FACTORY);
    fc.addGenerated(NumericDivideDescriptor.FACTORY);
    fc.addGenerated(NumericDivDescriptor.FACTORY);
    fc.addGenerated(NumericMultiplyDescriptor.FACTORY);
    fc.addGenerated(NumericSubDescriptor.FACTORY);
    fc.addGenerated(NumericModuloDescriptor.FACTORY);
    fc.addGenerated(NumericPowerDescriptor.FACTORY);
    fc.addGenerated(NotDescriptor.FACTORY);
    fc.addGenerated(LenDescriptor.FACTORY);
    fc.addGenerated(NumericAbsDescriptor.FACTORY);
    fc.addGenerated(NumericCeilingDescriptor.FACTORY);
    fc.addGenerated(NumericFloorDescriptor.FACTORY);
    fc.addGenerated(NumericRoundDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEvenDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEven2Descriptor.FACTORY);
    fc.addGenerated(NumericACosDescriptor.FACTORY);
    fc.addGenerated(NumericASinDescriptor.FACTORY);
    fc.addGenerated(NumericATanDescriptor.FACTORY);
    fc.addGenerated(NumericDegreesDescriptor.FACTORY);
    fc.addGenerated(NumericRadiansDescriptor.FACTORY);
    fc.addGenerated(NumericCosDescriptor.FACTORY);
    fc.addGenerated(NumericSinDescriptor.FACTORY);
    fc.addGenerated(NumericTanDescriptor.FACTORY);
    fc.addGenerated(NumericExpDescriptor.FACTORY);
    fc.addGenerated(NumericLnDescriptor.FACTORY);
    fc.addGenerated(NumericLogDescriptor.FACTORY);
    fc.addGenerated(NumericSqrtDescriptor.FACTORY);
    fc.addGenerated(NumericSignDescriptor.FACTORY);
    fc.addGenerated(NumericTruncDescriptor.FACTORY);
    fc.addGenerated(NumericATan2Descriptor.FACTORY);
    // Comparisons.
    fc.addGenerated(EqualsDescriptor.FACTORY);
    fc.addGenerated(GreaterThanDescriptor.FACTORY);
    fc.addGenerated(GreaterThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(LessThanDescriptor.FACTORY);
    fc.addGenerated(LessThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(NotEqualsDescriptor.FACTORY);
    // If-Equals functions
    fc.addGenerated(MissingIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NullIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NanIfEqualsDescriptor.FACTORY);
    fc.addGenerated(PosInfIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NegInfIfEqualsDescriptor.FACTORY);
    // Binary functions
    fc.addGenerated(BinaryLengthDescriptor.FACTORY);
    fc.addGenerated(ParseBinaryDescriptor.FACTORY);
    fc.addGenerated(PrintBinaryDescriptor.FACTORY);
    fc.addGenerated(BinaryConcatDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromToDescriptor.FACTORY);
    fc.addGenerated(FindBinaryDescriptor.FACTORY);
    fc.addGenerated(FindBinaryFromDescriptor.FACTORY);
    // String functions
    fc.addGenerated(StringLikeDescriptor.FACTORY);
    fc.addGenerated(StringContainsDescriptor.FACTORY);
    fc.addGenerated(StringEndsWithDescriptor.FACTORY);
    fc.addGenerated(StringStartsWithDescriptor.FACTORY);
    fc.addGenerated(SubstringDescriptor.FACTORY);
    fc.addGenerated(StringEqualDescriptor.FACTORY);
    fc.addGenerated(StringLowerCaseDescriptor.FACTORY);
    fc.addGenerated(StringUpperCaseDescriptor.FACTORY);
    fc.addGenerated(StringLengthDescriptor.FACTORY);
    fc.addGenerated(Substring2Descriptor.FACTORY);
    fc.addGenerated(SubstringBeforeDescriptor.FACTORY);
    fc.addGenerated(SubstringAfterDescriptor.FACTORY);
    fc.addGenerated(StringToCodePointDescriptor.FACTORY);
    fc.addGenerated(CodePointToStringDescriptor.FACTORY);
    fc.addGenerated(StringConcatDescriptor.FACTORY);
    fc.addGenerated(StringJoinDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceWithFlagsDescriptor.FACTORY);
    fc.addGenerated(StringInitCapDescriptor.FACTORY);
    fc.addGenerated(StringTrimDescriptor.FACTORY);
    fc.addGenerated(StringLTrimDescriptor.FACTORY);
    fc.addGenerated(StringRTrimDescriptor.FACTORY);
    fc.addGenerated(StringTrim2Descriptor.FACTORY);
    fc.addGenerated(StringLTrim2Descriptor.FACTORY);
    fc.addGenerated(StringRTrim2Descriptor.FACTORY);
    fc.addGenerated(StringPositionDescriptor.FACTORY);
    fc.addGenerated(StringRepeatDescriptor.FACTORY);
    fc.addGenerated(StringReplaceDescriptor.FACTORY);
    fc.addGenerated(StringReplaceWithLimitDescriptor.FACTORY);
    fc.addGenerated(StringReverseDescriptor.FACTORY);
    fc.addGenerated(StringSplitDescriptor.FACTORY);
    // Constructors
    fc.addGenerated(ABooleanConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryHexStringConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryBase64StringConstructorDescriptor.FACTORY);
    fc.addGenerated(AStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt8ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt16ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt32ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt64ConstructorDescriptor.FACTORY);
    fc.addGenerated(AFloatConstructorDescriptor.FACTORY);
    fc.addGenerated(ADoubleConstructorDescriptor.FACTORY);
    fc.addGenerated(APointConstructorDescriptor.FACTORY);
    fc.addGenerated(APoint3DConstructorDescriptor.FACTORY);
    fc.addGenerated(ALineConstructorDescriptor.FACTORY);
    fc.addGenerated(APolygonConstructorDescriptor.FACTORY);
    fc.addGenerated(ACircleConstructorDescriptor.FACTORY);
    fc.addGenerated(ARectangleConstructorDescriptor.FACTORY);
    fc.addGenerated(ATimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AYearMonthDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(ADayTimeDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AUUIDFromStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromTimeConstructorDescriptor.FACTORY);
    // Spatial
    fc.addGenerated(CreatePointDescriptor.FACTORY);
    fc.addGenerated(CreateLineDescriptor.FACTORY);
    fc.addGenerated(CreatePolygonDescriptor.FACTORY);
    fc.addGenerated(CreateCircleDescriptor.FACTORY);
    fc.addGenerated(CreateRectangleDescriptor.FACTORY);
    fc.addGenerated(SpatialAreaDescriptor.FACTORY);
    fc.addGenerated(SpatialDistanceDescriptor.FACTORY);
    fc.addGenerated(CreateMBRDescriptor.FACTORY);
    fc.addGenerated(SpatialCellDescriptor.FACTORY);
    fc.addGenerated(PointXCoordinateAccessor.FACTORY);
    fc.addGenerated(PointYCoordinateAccessor.FACTORY);
    fc.addGenerated(CircleRadiusAccessor.FACTORY);
    fc.addGenerated(CircleCenterAccessor.FACTORY);
    fc.addGenerated(LineRectanglePolygonAccessor.FACTORY);
    // full-text function
    fc.addGenerated(FullTextContainsDescriptor.FACTORY);
    fc.addGenerated(FullTextContainsWithoutOptionDescriptor.FACTORY);
    // Record functions.
    fc.addGenerated(GetRecordFieldsDescriptor.FACTORY);
    fc.addGenerated(GetRecordFieldValueDescriptor.FACTORY);
    fc.addGenerated(DeepEqualityDescriptor.FACTORY);
    fc.addGenerated(RecordMergeDescriptor.FACTORY);
    fc.addGenerated(RecordAddFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordLengthDescriptor.FACTORY);
    fc.addGenerated(RecordNamesDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveDescriptor.FACTORY);
    fc.addGenerated(RecordRenameDescriptor.FACTORY);
    fc.addGenerated(RecordUnwrapDescriptor.FACTORY);
    fc.add(RecordReplaceDescriptor.FACTORY);
    fc.add(RecordAddDescriptor.FACTORY);
    fc.add(RecordPutDescriptor.FACTORY);
    fc.addGenerated(RecordValuesDescriptor.FACTORY);
    // Spatial and temporal type accessors
    fc.addGenerated(TemporalYearAccessor.FACTORY);
    fc.addGenerated(TemporalMonthAccessor.FACTORY);
    fc.addGenerated(TemporalDayAccessor.FACTORY);
    fc.addGenerated(TemporalHourAccessor.FACTORY);
    fc.addGenerated(TemporalMinuteAccessor.FACTORY);
    fc.addGenerated(TemporalSecondAccessor.FACTORY);
    fc.addGenerated(TemporalMillisecondAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDatetimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDatetimeAccessor.FACTORY);
    // Temporal functions
    fc.addGenerated(UnixTimeFromDateInDaysDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromTimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DateFromUnixTimeInDaysDescriptor.FACTORY);
    fc.addGenerated(DateFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(TimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(TimeFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromDateAndTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDurationFromDateTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDuartionFromDateDescriptor.FACTORY);
    fc.addGenerated(AdjustDateTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(AdjustTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(IntervalBeforeDescriptor.FACTORY);
    fc.addGenerated(IntervalAfterDescriptor.FACTORY);
    fc.addGenerated(IntervalMeetsDescriptor.FACTORY);
    fc.addGenerated(IntervalMetByDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlapsDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlappedByDescriptor.FACTORY);
    fc.addGenerated(OverlapDescriptor.FACTORY);
    fc.addGenerated(IntervalStartsDescriptor.FACTORY);
    fc.addGenerated(IntervalStartedByDescriptor.FACTORY);
    fc.addGenerated(IntervalCoversDescriptor.FACTORY);
    fc.addGenerated(IntervalCoveredByDescriptor.FACTORY);
    fc.addGenerated(IntervalEndsDescriptor.FACTORY);
    fc.addGenerated(IntervalEndedByDescriptor.FACTORY);
    fc.addGenerated(DurationFromMillisecondsDescriptor.FACTORY);
    fc.addGenerated(DurationFromMonthsDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(MonthsFromYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(MillisecondsFromDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(DurationEqualDescriptor.FACTORY);
    fc.addGenerated(GetYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(GetDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(IntervalBinDescriptor.FACTORY);
    fc.addGenerated(OverlapBinsDescriptor.FACTORY);
    fc.addGenerated(DayOfWeekDescriptor.FACTORY);
    fc.addGenerated(ParseDateDescriptor.FACTORY);
    fc.addGenerated(ParseTimeDescriptor.FACTORY);
    fc.addGenerated(ParseDateTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateDescriptor.FACTORY);
    fc.addGenerated(PrintTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateTimeDescriptor.FACTORY);
    fc.addGenerated(GetOverlappingIntervalDescriptor.FACTORY);
    fc.addGenerated(DurationFromIntervalDescriptor.FACTORY);
    // Type functions.
    fc.addGenerated(IsArrayDescriptor.FACTORY);
    fc.addGenerated(IsAtomicDescriptor.FACTORY);
    fc.addGenerated(IsBooleanDescriptor.FACTORY);
    fc.addGenerated(IsNumberDescriptor.FACTORY);
    fc.addGenerated(IsObjectDescriptor.FACTORY);
    fc.addGenerated(IsStringDescriptor.FACTORY);
    fc.addGenerated(ToArrayDescriptor.FACTORY);
    fc.addGenerated(ToAtomicDescriptor.FACTORY);
    fc.addGenerated(ToBigIntDescriptor.FACTORY);
    fc.addGenerated(ToBooleanDescriptor.FACTORY);
    fc.addGenerated(ToDoubleDescriptor.FACTORY);
    fc.addGenerated(ToNumberDescriptor.FACTORY);
    fc.addGenerated(ToObjectDescriptor.FACTORY);
    fc.addGenerated(ToStringDescriptor.FACTORY);
    // Cast function
    fc.addGenerated(CastTypeDescriptor.FACTORY);
    fc.addGenerated(CastTypeLaxDescriptor.FACTORY);
    // Record function
    fc.addGenerated(RecordPairsDescriptor.FACTORY);
    // Other functions
    fc.addGenerated(RandomWithSeedDescriptor.FACTORY);
    ServiceLoader.load(IFunctionRegistrant.class).iterator().forEachRemaining(c -> c.register(fc));
    return fc;
}
#end_block

#method_before
public static FunctionCollection createDefaultFunctionCollection() {
    FunctionCollection fc = new FunctionCollection();
    // array functions
    fc.addGenerated(ArrayAppendDescriptor.FACTORY);
    // unnesting functions
    fc.add(TidRunningAggregateDescriptor.FACTORY);
    fc.add(ScanCollectionDescriptor.FACTORY);
    fc.add(RangeDescriptor.FACTORY);
    fc.add(SubsetCollectionDescriptor.FACTORY);
    // aggregate functions
    fc.add(ListifyAggregateDescriptor.FACTORY);
    fc.add(CountAggregateDescriptor.FACTORY);
    fc.add(AvgAggregateDescriptor.FACTORY);
    fc.add(LocalAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SumAggregateDescriptor.FACTORY);
    fc.add(LocalSumAggregateDescriptor.FACTORY);
    fc.add(MaxAggregateDescriptor.FACTORY);
    fc.add(LocalMaxAggregateDescriptor.FACTORY);
    fc.add(MinAggregateDescriptor.FACTORY);
    fc.add(LocalMinAggregateDescriptor.FACTORY);
    fc.add(FirstElementAggregateDescriptor.FACTORY);
    fc.add(LocalFirstElementAggregateDescriptor.FACTORY);
    // serializable aggregates
    fc.add(SerializableCountAggregateDescriptor.FACTORY);
    fc.add(SerializableAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSumAggregateDescriptor.FACTORY);
    // scalar aggregates
    fc.add(ScalarCountAggregateDescriptor.FACTORY);
    fc.add(ScalarAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSumAggregateDescriptor.FACTORY);
    fc.add(ScalarMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarMinAggregateDescriptor.FACTORY);
    fc.add(EmptyStreamAggregateDescriptor.FACTORY);
    fc.add(NonEmptyStreamAggregateDescriptor.FACTORY);
    // SQL aggregates
    fc.add(SqlCountAggregateDescriptor.FACTORY);
    fc.add(SqlAvgAggregateDescriptor.FACTORY);
    fc.add(LocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SqlSumAggregateDescriptor.FACTORY);
    fc.add(LocalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SqlMaxAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMaxAggregateDescriptor.FACTORY);
    fc.add(SqlMinAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMinAggregateDescriptor.FACTORY);
    // SQL serializable aggregates
    fc.add(SerializableSqlCountAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlSumAggregateDescriptor.FACTORY);
    // SQL scalar aggregates
    fc.add(ScalarSqlCountAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlSumAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMinAggregateDescriptor.FACTORY);
    // boolean functions
    fc.add(AndDescriptor.FACTORY);
    fc.add(OrDescriptor.FACTORY);
    // Record constructors / functions
    fc.add(ClosedRecordConstructorDescriptor.FACTORY);
    fc.add(OpenRecordConstructorDescriptor.FACTORY);
    fc.add(RecordConcatDescriptor.FACTORY);
    fc.add(RecordConcatStrictDescriptor.FACTORY);
    // List constructors
    fc.add(OrderedListConstructorDescriptor.FACTORY);
    fc.add(UnorderedListConstructorDescriptor.FACTORY);
    // Sleep function
    fc.add(SleepDescriptor.FACTORY);
    // Inject failure function
    fc.add(InjectFailureDescriptor.FACTORY);
    // Get Job Parameter function
    fc.add(GetJobParameterByNameDescriptor.FACTORY);
    // Switch case
    fc.add(SwitchCaseDescriptor.FACTORY);
    // null functions
    fc.add(IsMissingDescriptor.FACTORY);
    fc.add(IsNullDescriptor.FACTORY);
    fc.add(IsUnknownDescriptor.FACTORY);
    fc.add(IsSystemNullDescriptor.FACTORY);
    fc.add(CheckUnknownDescriptor.FACTORY);
    fc.add(IfMissingDescriptor.FACTORY);
    fc.add(IfNullDescriptor.FACTORY);
    fc.add(IfMissingOrNullDescriptor.FACTORY);
    // uuid generators (zero independent functions)
    fc.add(CreateUUIDDescriptor.FACTORY);
    fc.add(UUIDDescriptor.FACTORY);
    fc.add(CreateQueryUIDDescriptor.FACTORY);
    fc.add(RandomDescriptor.FACTORY);
    fc.add(CurrentDateDescriptor.FACTORY);
    fc.add(CurrentTimeDescriptor.FACTORY);
    fc.add(CurrentDateTimeDescriptor.FACTORY);
    // functions that need generated class for null-handling.
    // Element accessors.
    fc.addGenerated(FieldAccessByIndexDescriptor.FACTORY);
    fc.addGenerated(FieldAccessByNameDescriptor.FACTORY);
    fc.addGenerated(FieldAccessNestedDescriptor.FACTORY);
    fc.addGenerated(AnyCollectionMemberDescriptor.FACTORY);
    fc.addGenerated(GetItemDescriptor.FACTORY);
    // Numeric functions
    fc.add(IfInfDescriptor.FACTORY);
    fc.add(IfNanDescriptor.FACTORY);
    fc.add(IfNanOrInfDescriptor.FACTORY);
    fc.addGenerated(NumericUnaryMinusDescriptor.FACTORY);
    fc.addGenerated(NumericAddDescriptor.FACTORY);
    fc.addGenerated(NumericDivideDescriptor.FACTORY);
    fc.addGenerated(NumericDivDescriptor.FACTORY);
    fc.addGenerated(NumericMultiplyDescriptor.FACTORY);
    fc.addGenerated(NumericSubDescriptor.FACTORY);
    fc.addGenerated(NumericModuloDescriptor.FACTORY);
    fc.addGenerated(NumericPowerDescriptor.FACTORY);
    fc.addGenerated(NotDescriptor.FACTORY);
    fc.addGenerated(LenDescriptor.FACTORY);
    fc.addGenerated(NumericAbsDescriptor.FACTORY);
    fc.addGenerated(NumericCeilingDescriptor.FACTORY);
    fc.addGenerated(NumericFloorDescriptor.FACTORY);
    fc.addGenerated(NumericRoundDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEvenDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEven2Descriptor.FACTORY);
    fc.addGenerated(NumericACosDescriptor.FACTORY);
    fc.addGenerated(NumericASinDescriptor.FACTORY);
    fc.addGenerated(NumericATanDescriptor.FACTORY);
    fc.addGenerated(NumericDegreesDescriptor.FACTORY);
    fc.addGenerated(NumericRadiansDescriptor.FACTORY);
    fc.addGenerated(NumericCosDescriptor.FACTORY);
    fc.addGenerated(NumericSinDescriptor.FACTORY);
    fc.addGenerated(NumericTanDescriptor.FACTORY);
    fc.addGenerated(NumericExpDescriptor.FACTORY);
    fc.addGenerated(NumericLnDescriptor.FACTORY);
    fc.addGenerated(NumericLogDescriptor.FACTORY);
    fc.addGenerated(NumericSqrtDescriptor.FACTORY);
    fc.addGenerated(NumericSignDescriptor.FACTORY);
    fc.addGenerated(NumericTruncDescriptor.FACTORY);
    fc.addGenerated(NumericATan2Descriptor.FACTORY);
    // Comparisons.
    fc.addGenerated(EqualsDescriptor.FACTORY);
    fc.addGenerated(GreaterThanDescriptor.FACTORY);
    fc.addGenerated(GreaterThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(LessThanDescriptor.FACTORY);
    fc.addGenerated(LessThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(NotEqualsDescriptor.FACTORY);
    // If-Equals functions
    fc.addGenerated(MissingIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NullIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NanIfEqualsDescriptor.FACTORY);
    fc.addGenerated(PosInfIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NegInfIfEqualsDescriptor.FACTORY);
    // Binary functions
    fc.addGenerated(BinaryLengthDescriptor.FACTORY);
    fc.addGenerated(ParseBinaryDescriptor.FACTORY);
    fc.addGenerated(PrintBinaryDescriptor.FACTORY);
    fc.addGenerated(BinaryConcatDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromToDescriptor.FACTORY);
    fc.addGenerated(FindBinaryDescriptor.FACTORY);
    fc.addGenerated(FindBinaryFromDescriptor.FACTORY);
    // String functions
    fc.addGenerated(StringLikeDescriptor.FACTORY);
    fc.addGenerated(StringContainsDescriptor.FACTORY);
    fc.addGenerated(StringEndsWithDescriptor.FACTORY);
    fc.addGenerated(StringStartsWithDescriptor.FACTORY);
    fc.addGenerated(SubstringDescriptor.FACTORY);
    fc.addGenerated(StringEqualDescriptor.FACTORY);
    fc.addGenerated(StringLowerCaseDescriptor.FACTORY);
    fc.addGenerated(StringUpperCaseDescriptor.FACTORY);
    fc.addGenerated(StringLengthDescriptor.FACTORY);
    fc.addGenerated(Substring2Descriptor.FACTORY);
    fc.addGenerated(SubstringBeforeDescriptor.FACTORY);
    fc.addGenerated(SubstringAfterDescriptor.FACTORY);
    fc.addGenerated(StringToCodePointDescriptor.FACTORY);
    fc.addGenerated(CodePointToStringDescriptor.FACTORY);
    fc.addGenerated(StringConcatDescriptor.FACTORY);
    fc.addGenerated(StringJoinDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceWithFlagsDescriptor.FACTORY);
    fc.addGenerated(StringInitCapDescriptor.FACTORY);
    fc.addGenerated(StringTrimDescriptor.FACTORY);
    fc.addGenerated(StringLTrimDescriptor.FACTORY);
    fc.addGenerated(StringRTrimDescriptor.FACTORY);
    fc.addGenerated(StringTrim2Descriptor.FACTORY);
    fc.addGenerated(StringLTrim2Descriptor.FACTORY);
    fc.addGenerated(StringRTrim2Descriptor.FACTORY);
    fc.addGenerated(StringPositionDescriptor.FACTORY);
    fc.addGenerated(StringRepeatDescriptor.FACTORY);
    fc.addGenerated(StringReplaceDescriptor.FACTORY);
    fc.addGenerated(StringReplaceWithLimitDescriptor.FACTORY);
    fc.addGenerated(StringReverseDescriptor.FACTORY);
    fc.addGenerated(StringSplitDescriptor.FACTORY);
    // Constructors
    fc.addGenerated(ABooleanConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryHexStringConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryBase64StringConstructorDescriptor.FACTORY);
    fc.addGenerated(AStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt8ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt16ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt32ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt64ConstructorDescriptor.FACTORY);
    fc.addGenerated(AFloatConstructorDescriptor.FACTORY);
    fc.addGenerated(ADoubleConstructorDescriptor.FACTORY);
    fc.addGenerated(APointConstructorDescriptor.FACTORY);
    fc.addGenerated(APoint3DConstructorDescriptor.FACTORY);
    fc.addGenerated(ALineConstructorDescriptor.FACTORY);
    fc.addGenerated(APolygonConstructorDescriptor.FACTORY);
    fc.addGenerated(ACircleConstructorDescriptor.FACTORY);
    fc.addGenerated(ARectangleConstructorDescriptor.FACTORY);
    fc.addGenerated(ATimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AYearMonthDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(ADayTimeDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AUUIDFromStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromTimeConstructorDescriptor.FACTORY);
    // Spatial
    fc.addGenerated(CreatePointDescriptor.FACTORY);
    fc.addGenerated(CreateLineDescriptor.FACTORY);
    fc.addGenerated(CreatePolygonDescriptor.FACTORY);
    fc.addGenerated(CreateCircleDescriptor.FACTORY);
    fc.addGenerated(CreateRectangleDescriptor.FACTORY);
    fc.addGenerated(SpatialAreaDescriptor.FACTORY);
    fc.addGenerated(SpatialDistanceDescriptor.FACTORY);
    fc.addGenerated(CreateMBRDescriptor.FACTORY);
    fc.addGenerated(SpatialCellDescriptor.FACTORY);
    fc.addGenerated(PointXCoordinateAccessor.FACTORY);
    fc.addGenerated(PointYCoordinateAccessor.FACTORY);
    fc.addGenerated(CircleRadiusAccessor.FACTORY);
    fc.addGenerated(CircleCenterAccessor.FACTORY);
    fc.addGenerated(LineRectanglePolygonAccessor.FACTORY);
    // full-text function
    fc.addGenerated(FullTextContainsDescriptor.FACTORY);
    fc.addGenerated(FullTextContainsWithoutOptionDescriptor.FACTORY);
    // Record functions.
    fc.addGenerated(GetRecordFieldsDescriptor.FACTORY);
    fc.addGenerated(GetRecordFieldValueDescriptor.FACTORY);
    fc.addGenerated(DeepEqualityDescriptor.FACTORY);
    fc.addGenerated(RecordMergeDescriptor.FACTORY);
    fc.addGenerated(RecordAddFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordLengthDescriptor.FACTORY);
    fc.addGenerated(RecordNamesDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveDescriptor.FACTORY);
    fc.addGenerated(RecordRenameDescriptor.FACTORY);
    fc.addGenerated(RecordUnwrapDescriptor.FACTORY);
    fc.add(RecordReplaceDescriptor.FACTORY);
    fc.addGenerated(RecordValuesDescriptor.FACTORY);
    // Spatial and temporal type accessors
    fc.addGenerated(TemporalYearAccessor.FACTORY);
    fc.addGenerated(TemporalMonthAccessor.FACTORY);
    fc.addGenerated(TemporalDayAccessor.FACTORY);
    fc.addGenerated(TemporalHourAccessor.FACTORY);
    fc.addGenerated(TemporalMinuteAccessor.FACTORY);
    fc.addGenerated(TemporalSecondAccessor.FACTORY);
    fc.addGenerated(TemporalMillisecondAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDatetimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDatetimeAccessor.FACTORY);
    // Temporal functions
    fc.addGenerated(UnixTimeFromDateInDaysDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromTimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DateFromUnixTimeInDaysDescriptor.FACTORY);
    fc.addGenerated(DateFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(TimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(TimeFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromDateAndTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDurationFromDateTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDuartionFromDateDescriptor.FACTORY);
    fc.addGenerated(AdjustDateTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(AdjustTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(IntervalBeforeDescriptor.FACTORY);
    fc.addGenerated(IntervalAfterDescriptor.FACTORY);
    fc.addGenerated(IntervalMeetsDescriptor.FACTORY);
    fc.addGenerated(IntervalMetByDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlapsDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlappedByDescriptor.FACTORY);
    fc.addGenerated(OverlapDescriptor.FACTORY);
    fc.addGenerated(IntervalStartsDescriptor.FACTORY);
    fc.addGenerated(IntervalStartedByDescriptor.FACTORY);
    fc.addGenerated(IntervalCoversDescriptor.FACTORY);
    fc.addGenerated(IntervalCoveredByDescriptor.FACTORY);
    fc.addGenerated(IntervalEndsDescriptor.FACTORY);
    fc.addGenerated(IntervalEndedByDescriptor.FACTORY);
    fc.addGenerated(DurationFromMillisecondsDescriptor.FACTORY);
    fc.addGenerated(DurationFromMonthsDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(MonthsFromYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(MillisecondsFromDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(DurationEqualDescriptor.FACTORY);
    fc.addGenerated(GetYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(GetDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(IntervalBinDescriptor.FACTORY);
    fc.addGenerated(OverlapBinsDescriptor.FACTORY);
    fc.addGenerated(DayOfWeekDescriptor.FACTORY);
    fc.addGenerated(ParseDateDescriptor.FACTORY);
    fc.addGenerated(ParseTimeDescriptor.FACTORY);
    fc.addGenerated(ParseDateTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateDescriptor.FACTORY);
    fc.addGenerated(PrintTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateTimeDescriptor.FACTORY);
    fc.addGenerated(GetOverlappingIntervalDescriptor.FACTORY);
    fc.addGenerated(DurationFromIntervalDescriptor.FACTORY);
    // Type functions.
    fc.addGenerated(IsArrayDescriptor.FACTORY);
    fc.addGenerated(IsAtomicDescriptor.FACTORY);
    fc.addGenerated(IsBooleanDescriptor.FACTORY);
    fc.addGenerated(IsNumberDescriptor.FACTORY);
    fc.addGenerated(IsObjectDescriptor.FACTORY);
    fc.addGenerated(IsStringDescriptor.FACTORY);
    fc.addGenerated(ToArrayDescriptor.FACTORY);
    fc.addGenerated(ToAtomicDescriptor.FACTORY);
    fc.addGenerated(ToBigIntDescriptor.FACTORY);
    fc.addGenerated(ToBooleanDescriptor.FACTORY);
    fc.addGenerated(ToDoubleDescriptor.FACTORY);
    fc.addGenerated(ToNumberDescriptor.FACTORY);
    fc.addGenerated(ToObjectDescriptor.FACTORY);
    fc.addGenerated(ToStringDescriptor.FACTORY);
    // Cast function
    fc.addGenerated(CastTypeDescriptor.FACTORY);
    fc.addGenerated(CastTypeLaxDescriptor.FACTORY);
    // Record function
    fc.addGenerated(RecordPairsDescriptor.FACTORY);
    // Other functions
    fc.addGenerated(RandomWithSeedDescriptor.FACTORY);
    ServiceLoader.load(IFunctionRegistrant.class).iterator().forEachRemaining(c -> c.register(fc));
    return fc;
}
#method_after
public static FunctionCollection createDefaultFunctionCollection() {
    FunctionCollection fc = new FunctionCollection();
    // array functions
    fc.addGenerated(ArrayAppendDescriptor.FACTORY);
    // unnesting functions
    fc.add(TidRunningAggregateDescriptor.FACTORY);
    fc.add(ScanCollectionDescriptor.FACTORY);
    fc.add(RangeDescriptor.FACTORY);
    fc.add(SubsetCollectionDescriptor.FACTORY);
    // aggregate functions
    fc.add(ListifyAggregateDescriptor.FACTORY);
    fc.add(CountAggregateDescriptor.FACTORY);
    fc.add(AvgAggregateDescriptor.FACTORY);
    fc.add(LocalAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SumAggregateDescriptor.FACTORY);
    fc.add(LocalSumAggregateDescriptor.FACTORY);
    fc.add(MaxAggregateDescriptor.FACTORY);
    fc.add(LocalMaxAggregateDescriptor.FACTORY);
    fc.add(MinAggregateDescriptor.FACTORY);
    fc.add(LocalMinAggregateDescriptor.FACTORY);
    fc.add(FirstElementAggregateDescriptor.FACTORY);
    fc.add(LocalFirstElementAggregateDescriptor.FACTORY);
    // serializable aggregates
    fc.add(SerializableCountAggregateDescriptor.FACTORY);
    fc.add(SerializableAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSumAggregateDescriptor.FACTORY);
    // scalar aggregates
    fc.add(ScalarCountAggregateDescriptor.FACTORY);
    fc.add(ScalarAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSumAggregateDescriptor.FACTORY);
    fc.add(ScalarMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarMinAggregateDescriptor.FACTORY);
    fc.add(EmptyStreamAggregateDescriptor.FACTORY);
    fc.add(NonEmptyStreamAggregateDescriptor.FACTORY);
    // SQL aggregates
    fc.add(SqlCountAggregateDescriptor.FACTORY);
    fc.add(SqlAvgAggregateDescriptor.FACTORY);
    fc.add(LocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SqlSumAggregateDescriptor.FACTORY);
    fc.add(LocalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SqlMaxAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMaxAggregateDescriptor.FACTORY);
    fc.add(SqlMinAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMinAggregateDescriptor.FACTORY);
    // SQL serializable aggregates
    fc.add(SerializableSqlCountAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlSumAggregateDescriptor.FACTORY);
    // SQL scalar aggregates
    fc.add(ScalarSqlCountAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlSumAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMinAggregateDescriptor.FACTORY);
    // boolean functions
    fc.add(AndDescriptor.FACTORY);
    fc.add(OrDescriptor.FACTORY);
    // Record constructors / functions
    fc.add(ClosedRecordConstructorDescriptor.FACTORY);
    fc.add(OpenRecordConstructorDescriptor.FACTORY);
    fc.add(RecordConcatDescriptor.FACTORY);
    fc.add(RecordConcatStrictDescriptor.FACTORY);
    // List constructors
    fc.add(OrderedListConstructorDescriptor.FACTORY);
    fc.add(UnorderedListConstructorDescriptor.FACTORY);
    // Sleep function
    fc.add(SleepDescriptor.FACTORY);
    // Inject failure function
    fc.add(InjectFailureDescriptor.FACTORY);
    // Get Job Parameter function
    fc.add(GetJobParameterByNameDescriptor.FACTORY);
    // Switch case
    fc.add(SwitchCaseDescriptor.FACTORY);
    // null functions
    fc.add(IsMissingDescriptor.FACTORY);
    fc.add(IsNullDescriptor.FACTORY);
    fc.add(IsUnknownDescriptor.FACTORY);
    fc.add(IsSystemNullDescriptor.FACTORY);
    fc.add(CheckUnknownDescriptor.FACTORY);
    fc.add(IfMissingDescriptor.FACTORY);
    fc.add(IfNullDescriptor.FACTORY);
    fc.add(IfMissingOrNullDescriptor.FACTORY);
    // uuid generators (zero independent functions)
    fc.add(CreateUUIDDescriptor.FACTORY);
    fc.add(UUIDDescriptor.FACTORY);
    fc.add(CreateQueryUIDDescriptor.FACTORY);
    fc.add(RandomDescriptor.FACTORY);
    fc.add(CurrentDateDescriptor.FACTORY);
    fc.add(CurrentTimeDescriptor.FACTORY);
    fc.add(CurrentDateTimeDescriptor.FACTORY);
    // functions that need generated class for null-handling.
    // Element accessors.
    fc.addGenerated(FieldAccessByIndexDescriptor.FACTORY);
    fc.addGenerated(FieldAccessByNameDescriptor.FACTORY);
    fc.addGenerated(FieldAccessNestedDescriptor.FACTORY);
    fc.addGenerated(AnyCollectionMemberDescriptor.FACTORY);
    fc.addGenerated(GetItemDescriptor.FACTORY);
    // Numeric functions
    fc.add(IfInfDescriptor.FACTORY);
    fc.add(IfNanDescriptor.FACTORY);
    fc.add(IfNanOrInfDescriptor.FACTORY);
    fc.addGenerated(NumericUnaryMinusDescriptor.FACTORY);
    fc.addGenerated(NumericAddDescriptor.FACTORY);
    fc.addGenerated(NumericDivideDescriptor.FACTORY);
    fc.addGenerated(NumericDivDescriptor.FACTORY);
    fc.addGenerated(NumericMultiplyDescriptor.FACTORY);
    fc.addGenerated(NumericSubDescriptor.FACTORY);
    fc.addGenerated(NumericModuloDescriptor.FACTORY);
    fc.addGenerated(NumericPowerDescriptor.FACTORY);
    fc.addGenerated(NotDescriptor.FACTORY);
    fc.addGenerated(LenDescriptor.FACTORY);
    fc.addGenerated(NumericAbsDescriptor.FACTORY);
    fc.addGenerated(NumericCeilingDescriptor.FACTORY);
    fc.addGenerated(NumericFloorDescriptor.FACTORY);
    fc.addGenerated(NumericRoundDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEvenDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEven2Descriptor.FACTORY);
    fc.addGenerated(NumericACosDescriptor.FACTORY);
    fc.addGenerated(NumericASinDescriptor.FACTORY);
    fc.addGenerated(NumericATanDescriptor.FACTORY);
    fc.addGenerated(NumericDegreesDescriptor.FACTORY);
    fc.addGenerated(NumericRadiansDescriptor.FACTORY);
    fc.addGenerated(NumericCosDescriptor.FACTORY);
    fc.addGenerated(NumericSinDescriptor.FACTORY);
    fc.addGenerated(NumericTanDescriptor.FACTORY);
    fc.addGenerated(NumericExpDescriptor.FACTORY);
    fc.addGenerated(NumericLnDescriptor.FACTORY);
    fc.addGenerated(NumericLogDescriptor.FACTORY);
    fc.addGenerated(NumericSqrtDescriptor.FACTORY);
    fc.addGenerated(NumericSignDescriptor.FACTORY);
    fc.addGenerated(NumericTruncDescriptor.FACTORY);
    fc.addGenerated(NumericATan2Descriptor.FACTORY);
    // Comparisons.
    fc.addGenerated(EqualsDescriptor.FACTORY);
    fc.addGenerated(GreaterThanDescriptor.FACTORY);
    fc.addGenerated(GreaterThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(LessThanDescriptor.FACTORY);
    fc.addGenerated(LessThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(NotEqualsDescriptor.FACTORY);
    // If-Equals functions
    fc.addGenerated(MissingIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NullIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NanIfEqualsDescriptor.FACTORY);
    fc.addGenerated(PosInfIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NegInfIfEqualsDescriptor.FACTORY);
    // Binary functions
    fc.addGenerated(BinaryLengthDescriptor.FACTORY);
    fc.addGenerated(ParseBinaryDescriptor.FACTORY);
    fc.addGenerated(PrintBinaryDescriptor.FACTORY);
    fc.addGenerated(BinaryConcatDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromToDescriptor.FACTORY);
    fc.addGenerated(FindBinaryDescriptor.FACTORY);
    fc.addGenerated(FindBinaryFromDescriptor.FACTORY);
    // String functions
    fc.addGenerated(StringLikeDescriptor.FACTORY);
    fc.addGenerated(StringContainsDescriptor.FACTORY);
    fc.addGenerated(StringEndsWithDescriptor.FACTORY);
    fc.addGenerated(StringStartsWithDescriptor.FACTORY);
    fc.addGenerated(SubstringDescriptor.FACTORY);
    fc.addGenerated(StringEqualDescriptor.FACTORY);
    fc.addGenerated(StringLowerCaseDescriptor.FACTORY);
    fc.addGenerated(StringUpperCaseDescriptor.FACTORY);
    fc.addGenerated(StringLengthDescriptor.FACTORY);
    fc.addGenerated(Substring2Descriptor.FACTORY);
    fc.addGenerated(SubstringBeforeDescriptor.FACTORY);
    fc.addGenerated(SubstringAfterDescriptor.FACTORY);
    fc.addGenerated(StringToCodePointDescriptor.FACTORY);
    fc.addGenerated(CodePointToStringDescriptor.FACTORY);
    fc.addGenerated(StringConcatDescriptor.FACTORY);
    fc.addGenerated(StringJoinDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceWithFlagsDescriptor.FACTORY);
    fc.addGenerated(StringInitCapDescriptor.FACTORY);
    fc.addGenerated(StringTrimDescriptor.FACTORY);
    fc.addGenerated(StringLTrimDescriptor.FACTORY);
    fc.addGenerated(StringRTrimDescriptor.FACTORY);
    fc.addGenerated(StringTrim2Descriptor.FACTORY);
    fc.addGenerated(StringLTrim2Descriptor.FACTORY);
    fc.addGenerated(StringRTrim2Descriptor.FACTORY);
    fc.addGenerated(StringPositionDescriptor.FACTORY);
    fc.addGenerated(StringRepeatDescriptor.FACTORY);
    fc.addGenerated(StringReplaceDescriptor.FACTORY);
    fc.addGenerated(StringReplaceWithLimitDescriptor.FACTORY);
    fc.addGenerated(StringReverseDescriptor.FACTORY);
    fc.addGenerated(StringSplitDescriptor.FACTORY);
    // Constructors
    fc.addGenerated(ABooleanConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryHexStringConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryBase64StringConstructorDescriptor.FACTORY);
    fc.addGenerated(AStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt8ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt16ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt32ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt64ConstructorDescriptor.FACTORY);
    fc.addGenerated(AFloatConstructorDescriptor.FACTORY);
    fc.addGenerated(ADoubleConstructorDescriptor.FACTORY);
    fc.addGenerated(APointConstructorDescriptor.FACTORY);
    fc.addGenerated(APoint3DConstructorDescriptor.FACTORY);
    fc.addGenerated(ALineConstructorDescriptor.FACTORY);
    fc.addGenerated(APolygonConstructorDescriptor.FACTORY);
    fc.addGenerated(ACircleConstructorDescriptor.FACTORY);
    fc.addGenerated(ARectangleConstructorDescriptor.FACTORY);
    fc.addGenerated(ATimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AYearMonthDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(ADayTimeDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AUUIDFromStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromTimeConstructorDescriptor.FACTORY);
    // Spatial
    fc.addGenerated(CreatePointDescriptor.FACTORY);
    fc.addGenerated(CreateLineDescriptor.FACTORY);
    fc.addGenerated(CreatePolygonDescriptor.FACTORY);
    fc.addGenerated(CreateCircleDescriptor.FACTORY);
    fc.addGenerated(CreateRectangleDescriptor.FACTORY);
    fc.addGenerated(SpatialAreaDescriptor.FACTORY);
    fc.addGenerated(SpatialDistanceDescriptor.FACTORY);
    fc.addGenerated(CreateMBRDescriptor.FACTORY);
    fc.addGenerated(SpatialCellDescriptor.FACTORY);
    fc.addGenerated(PointXCoordinateAccessor.FACTORY);
    fc.addGenerated(PointYCoordinateAccessor.FACTORY);
    fc.addGenerated(CircleRadiusAccessor.FACTORY);
    fc.addGenerated(CircleCenterAccessor.FACTORY);
    fc.addGenerated(LineRectanglePolygonAccessor.FACTORY);
    // full-text function
    fc.addGenerated(FullTextContainsDescriptor.FACTORY);
    fc.addGenerated(FullTextContainsWithoutOptionDescriptor.FACTORY);
    // Record functions.
    fc.addGenerated(GetRecordFieldsDescriptor.FACTORY);
    fc.addGenerated(GetRecordFieldValueDescriptor.FACTORY);
    fc.addGenerated(DeepEqualityDescriptor.FACTORY);
    fc.addGenerated(RecordMergeDescriptor.FACTORY);
    fc.addGenerated(RecordAddFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordLengthDescriptor.FACTORY);
    fc.addGenerated(RecordNamesDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveDescriptor.FACTORY);
    fc.addGenerated(RecordRenameDescriptor.FACTORY);
    fc.addGenerated(RecordUnwrapDescriptor.FACTORY);
    fc.add(RecordReplaceDescriptor.FACTORY);
    fc.add(RecordAddDescriptor.FACTORY);
    fc.add(RecordPutDescriptor.FACTORY);
    fc.addGenerated(RecordValuesDescriptor.FACTORY);
    // Spatial and temporal type accessors
    fc.addGenerated(TemporalYearAccessor.FACTORY);
    fc.addGenerated(TemporalMonthAccessor.FACTORY);
    fc.addGenerated(TemporalDayAccessor.FACTORY);
    fc.addGenerated(TemporalHourAccessor.FACTORY);
    fc.addGenerated(TemporalMinuteAccessor.FACTORY);
    fc.addGenerated(TemporalSecondAccessor.FACTORY);
    fc.addGenerated(TemporalMillisecondAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDatetimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDatetimeAccessor.FACTORY);
    // Temporal functions
    fc.addGenerated(UnixTimeFromDateInDaysDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromTimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DateFromUnixTimeInDaysDescriptor.FACTORY);
    fc.addGenerated(DateFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(TimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(TimeFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromDateAndTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDurationFromDateTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDuartionFromDateDescriptor.FACTORY);
    fc.addGenerated(AdjustDateTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(AdjustTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(IntervalBeforeDescriptor.FACTORY);
    fc.addGenerated(IntervalAfterDescriptor.FACTORY);
    fc.addGenerated(IntervalMeetsDescriptor.FACTORY);
    fc.addGenerated(IntervalMetByDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlapsDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlappedByDescriptor.FACTORY);
    fc.addGenerated(OverlapDescriptor.FACTORY);
    fc.addGenerated(IntervalStartsDescriptor.FACTORY);
    fc.addGenerated(IntervalStartedByDescriptor.FACTORY);
    fc.addGenerated(IntervalCoversDescriptor.FACTORY);
    fc.addGenerated(IntervalCoveredByDescriptor.FACTORY);
    fc.addGenerated(IntervalEndsDescriptor.FACTORY);
    fc.addGenerated(IntervalEndedByDescriptor.FACTORY);
    fc.addGenerated(DurationFromMillisecondsDescriptor.FACTORY);
    fc.addGenerated(DurationFromMonthsDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(MonthsFromYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(MillisecondsFromDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(DurationEqualDescriptor.FACTORY);
    fc.addGenerated(GetYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(GetDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(IntervalBinDescriptor.FACTORY);
    fc.addGenerated(OverlapBinsDescriptor.FACTORY);
    fc.addGenerated(DayOfWeekDescriptor.FACTORY);
    fc.addGenerated(ParseDateDescriptor.FACTORY);
    fc.addGenerated(ParseTimeDescriptor.FACTORY);
    fc.addGenerated(ParseDateTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateDescriptor.FACTORY);
    fc.addGenerated(PrintTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateTimeDescriptor.FACTORY);
    fc.addGenerated(GetOverlappingIntervalDescriptor.FACTORY);
    fc.addGenerated(DurationFromIntervalDescriptor.FACTORY);
    // Type functions.
    fc.addGenerated(IsArrayDescriptor.FACTORY);
    fc.addGenerated(IsAtomicDescriptor.FACTORY);
    fc.addGenerated(IsBooleanDescriptor.FACTORY);
    fc.addGenerated(IsNumberDescriptor.FACTORY);
    fc.addGenerated(IsObjectDescriptor.FACTORY);
    fc.addGenerated(IsStringDescriptor.FACTORY);
    fc.addGenerated(ToArrayDescriptor.FACTORY);
    fc.addGenerated(ToAtomicDescriptor.FACTORY);
    fc.addGenerated(ToBigIntDescriptor.FACTORY);
    fc.addGenerated(ToBooleanDescriptor.FACTORY);
    fc.addGenerated(ToDoubleDescriptor.FACTORY);
    fc.addGenerated(ToNumberDescriptor.FACTORY);
    fc.addGenerated(ToObjectDescriptor.FACTORY);
    fc.addGenerated(ToStringDescriptor.FACTORY);
    // Cast function
    fc.addGenerated(CastTypeDescriptor.FACTORY);
    fc.addGenerated(CastTypeLaxDescriptor.FACTORY);
    // Record function
    fc.addGenerated(RecordPairsDescriptor.FACTORY);
    // Other functions
    fc.addGenerated(RandomWithSeedDescriptor.FACTORY);
    ServiceLoader.load(IFunctionRegistrant.class).iterator().forEachRemaining(c -> c.register(fc));
    return fc;
}
#end_block

#method_before
private void buildOutputRecord() throws HyracksDataException {
    resultStorage.reset();
    outRecordBuilder.reset(DefaultOpenFieldType.NESTED_OPEN_RECORD_TYPE);
    outRecordBuilder.init();
    inputOpenRecordPointable.set(inputRecordPointable);
    final List<IVisitablePointable> fieldNames = inputOpenRecordPointable.getFieldNames();
    final List<IVisitablePointable> fieldValues = inputOpenRecordPointable.getFieldValues();
    boolean newFieldFound = false;
    for (int i = 0, fieldCount = fieldNames.size(); i < fieldCount; i++) {
        final IVisitablePointable fieldName = fieldNames.get(i);
        if (PointableHelper.isEqual(fieldName, newFieldNamePointable, stringBinaryComparator)) {
            newFieldFound = true;
        }
        outRecordBuilder.addField(fieldName, fieldValues.get(i));
    }
    if (!addMissingValue && !newFieldFound) {
        outRecordBuilder.addField(newFieldNamePointable, newFieldValuePointable);
    }
    outRecordBuilder.write(resultOutput, true);
}
#method_after
@Override
protected void buildOutputRecord() throws HyracksDataException {
    resultStorage.reset();
    outRecordBuilder.reset(DefaultOpenFieldType.NESTED_OPEN_RECORD_TYPE);
    outRecordBuilder.init();
    inputOpenRecordPointable.set(inputRecordPointable);
    final List<IVisitablePointable> fieldNames = inputOpenRecordPointable.getFieldNames();
    final List<IVisitablePointable> fieldValues = inputOpenRecordPointable.getFieldValues();
    boolean newFieldFound = false;
    for (int i = 0, fieldCount = fieldNames.size(); i < fieldCount; i++) {
        final IVisitablePointable fieldName = fieldNames.get(i);
        if (PointableHelper.isEqual(fieldName, newFieldNamePointable, stringBinaryComparator)) {
            newFieldFound = true;
        }
        outRecordBuilder.addField(fieldName, fieldValues.get(i));
    }
    if (!newFieldValueIsMissing && !newFieldFound) {
        outRecordBuilder.addField(newFieldNamePointable, newFieldValuePointable);
    }
    outRecordBuilder.write(resultOutput, true);
}
#end_block

#method_before
private void buildOutputRecord() throws HyracksDataException {
    resultStorage.reset();
    outRecordBuilder.reset(DefaultOpenFieldType.NESTED_OPEN_RECORD_TYPE);
    outRecordBuilder.init();
    inputOpenRecordPointable.set(inputRecordPointable);
    final List<IVisitablePointable> fieldNames = inputOpenRecordPointable.getFieldNames();
    final List<IVisitablePointable> fieldValues = inputOpenRecordPointable.getFieldValues();
    boolean newFieldFound = false;
    for (int i = 0, fieldCount = fieldNames.size(); i < fieldCount; i++) {
        final IVisitablePointable fieldName = fieldNames.get(i);
        if (!PointableHelper.isEqual(fieldName, newFieldNamePointable, stringBinaryComparator)) {
            outRecordBuilder.addField(fieldName, fieldValues.get(i));
        } else {
            newFieldFound = true;
            if (!removeField) {
                putNewField();
            }
        }
    }
    if (!newFieldFound) {
        putNewField();
    }
    outRecordBuilder.write(resultOutput, true);
}
#method_after
@Override
protected void buildOutputRecord() throws HyracksDataException {
    resultStorage.reset();
    outRecordBuilder.reset(DefaultOpenFieldType.NESTED_OPEN_RECORD_TYPE);
    outRecordBuilder.init();
    inputOpenRecordPointable.set(inputRecordPointable);
    final List<IVisitablePointable> fieldNames = inputOpenRecordPointable.getFieldNames();
    final List<IVisitablePointable> fieldValues = inputOpenRecordPointable.getFieldValues();
    boolean newFieldFound = false;
    for (int i = 0, fieldCount = fieldNames.size(); i < fieldCount; i++) {
        final IVisitablePointable fieldName = fieldNames.get(i);
        if (!PointableHelper.isEqual(fieldName, newFieldNamePointable, stringBinaryComparator)) {
            outRecordBuilder.addField(fieldName, fieldValues.get(i));
        } else {
            newFieldFound = true;
            if (!newFieldValueIsMissing) {
                putNewField();
            }
        }
    }
    if (!newFieldFound) {
        putNewField();
    }
    outRecordBuilder.write(resultOutput, true);
}
#end_block

#method_before
public String createData(String endpoint) {
    String resultTitle = "\"subscriptionIds";
    if (push) {
        resultTitle = "\"results\"";
    }
    String JSON = "{ \"dataverseName\":\"" + entityId.getDataverse() + "\", \"channelName\":\"" + entityId.getEntityName() + "\", \"" + BADConstants.ChannelExecutionTime + "\":\"" + executionTimeString + "\", " + resultTitle + ":[";
    JSON += sendData.get(endpoint);
    JSON = JSON.substring(0, JSON.length());
    JSON += "]}";
    return JSON;
}
#method_after
public String createData(String endpoint) {
    String resultTitle = "\"subscriptionIds";
    if (push) {
        resultTitle = "\"results\"";
    }
    String jsonStr = "{ \"dataverseName\":\"" + entityId.getDataverse() + "\", \"channelName\":\"" + entityId.getEntityName() + "\", \"" + BADConstants.ChannelExecutionTime + "\":\"" + executionTimeString + "\", " + resultTitle + ":[";
    jsonStr += sendData.get(endpoint);
    jsonStr = jsonStr.substring(0, jsonStr.length());
    jsonStr += "]}";
    return jsonStr;
}
#end_block

#method_before
@Override
public void nextFrame(ByteBuffer buffer) throws HyracksDataException {
    tAccess.reset(buffer);
    int nTuple = tAccess.getTupleCount();
    for (int t = 0; t < nTuple; t++) {
        tRef.reset(tAccess, t);
        eval0.evaluate(tRef, inputArg0);
        eval1.evaluate(tRef, inputArg1);
        eval2.evaluate(tRef, inputArg2);
        if (executionTimeString == null) {
            int resultSetOffset = inputArg2.getStartOffset();
            bbis.setByteBuffer(tRef.getFrameTupleAccessor().getBuffer(), resultSetOffset + 1);
            ADateTime executionTime = ADateTimeSerializerDeserializer.INSTANCE.deserialize(di);
            try {
                executionTimeString = executionTime.toSimpleString();
            } catch (IOException e) {
                throw HyracksDataException.create(e);
            }
        }
        int serBrokerOffset = inputArg0.getStartOffset();
        bbis.setByteBuffer(tRef.getFrameTupleAccessor().getBuffer(), serBrokerOffset + 1);
        endpoint = stringSerDes.deserialize(di).getStringValue();
        sendbaos.putIfAbsent(endpoint, new ByteArrayOutputStream());
        try {
            sendStreams.putIfAbsent(endpoint, new PrintStream(sendbaos.get(endpoint), true, "UTF-8"));
        } catch (UnsupportedEncodingException e) {
            throw new HyracksDataException(e.getMessage());
        }
        if (push) {
            int pushOffset = inputArg1.getStartOffset();
            bbis.setByteBuffer(tRef.getFrameTupleAccessor().getBuffer(), pushOffset + 1);
            if (!firstResult) {
                sendStreams.get(endpoint).append(',');
            }
            recordPrinterFactory.print(inputArg1.getByteArray(), inputArg1.getStartOffset(), inputArg1.getLength(), sendStreams.get(endpoint));
        } else {
            if (!firstResult) {
                sendStreams.get(endpoint).append(',');
            }
            listPrinterFactory.print(inputArg1.getByteArray(), inputArg1.getStartOffset(), inputArg1.getLength(), sendStreams.get(endpoint));
        }
        firstResult = false;
    }
}
#method_after
@Override
public void nextFrame(ByteBuffer buffer) throws HyracksDataException {
    tAccess.reset(buffer);
    int nTuple = tAccess.getTupleCount();
    for (int t = 0; t < nTuple; t++) {
        tRef.reset(tAccess, t);
        eval0.evaluate(tRef, inputArg0);
        eval1.evaluate(tRef, inputArg1);
        eval2.evaluate(tRef, inputArg2);
        /*The incoming tuples have three fields:
             1. eval0 will get the serialized broker endpoint string
             2. eval1 will get the payload (either the subscriptionIds or entire results)
             3. eval2 will get the channel execution time stamp (the same for all tuples)
            */
        if (executionTimeString == null) {
            int resultSetOffset = inputArg2.getStartOffset();
            bbis.setByteBuffer(tRef.getFrameTupleAccessor().getBuffer(), resultSetOffset + 1);
            ADateTime executionTime = ADateTimeSerializerDeserializer.INSTANCE.deserialize(di);
            try {
                executionTimeString = executionTime.toSimpleString();
            } catch (IOException e) {
                throw HyracksDataException.create(e);
            }
        }
        int serBrokerOffset = inputArg0.getStartOffset();
        bbis.setByteBuffer(tRef.getFrameTupleAccessor().getBuffer(), serBrokerOffset + 1);
        endpoint = stringSerDes.deserialize(di).getStringValue();
        sendbaos.putIfAbsent(endpoint, new ByteArrayOutputStream());
        try {
            sendStreams.putIfAbsent(endpoint, new PrintStream(sendbaos.get(endpoint), true, StandardCharsets.UTF_8.name()));
        } catch (UnsupportedEncodingException e) {
            throw new HyracksDataException(e.getMessage());
        }
        if (push) {
            int pushOffset = inputArg1.getStartOffset();
            bbis.setByteBuffer(tRef.getFrameTupleAccessor().getBuffer(), pushOffset + 1);
            if (!firstResult) {
                sendStreams.get(endpoint).append(',');
            }
            recordPrinterFactory.print(inputArg1.getByteArray(), inputArg1.getStartOffset(), inputArg1.getLength(), sendStreams.get(endpoint));
        } else {
            if (!firstResult) {
                sendStreams.get(endpoint).append(',');
            }
            subscriptionIdListPrinterFactory.print(inputArg1.getByteArray(), inputArg1.getStartOffset(), inputArg1.getLength(), sendStreams.get(endpoint));
        }
        firstResult = false;
    }
}
#end_block

#method_before
@Override
public void setImmutableStates(Object... states) {
    argTypes = new IAType[states.length];
    for (int i = 0; i < states.length; i++) {
        argTypes[i] = (IAType) states[i];
    }
}
#method_after
@Override
public void setImmutableStates(Object... states) {
    argTypes = Arrays.copyOf(states, states.length, IAType[].class);
}
#end_block

#method_before
@Override
protected IAType getResultType(ILogicalExpression expr, IAType... strippedInputTypes) throws AlgebricksException {
    if (strippedInputTypes.length < 2) {
        String functionName = ((AbstractFunctionCallExpression) expr).getFunctionIdentifier().getName();
        throw new CompilationException(ErrorCode.COMPILATION_INVALID_NUM_OF_ARGS, 2, functionName);
    }
    // type tag at [0] should be array or multiset.
    ATypeTag typeTag = strippedInputTypes[0].getTypeTag();
    IAType resultType;
    if (typeTag == ATypeTag.ARRAY) {
        resultType = new AOrderedListType(BuiltinType.ANY, null);
    } else {
        resultType = new AUnorderedListType(BuiltinType.ANY, null);
    }
    return resultType;
}
#method_after
@Override
protected IAType getResultType(ILogicalExpression expr, IAType... strippedInputTypes) throws AlgebricksException {
    if (strippedInputTypes.length < 2) {
        String functionName = ((AbstractFunctionCallExpression) expr).getFunctionIdentifier().getName();
        throw new CompilationException(ErrorCode.COMPILATION_INVALID_NUM_OF_ARGS, expr.getSourceLocation(), 2, functionName);
    }
    // type tag at [0] should be array or multiset.
    ATypeTag typeTag = strippedInputTypes[0].getTypeTag();
    if (typeTag == ATypeTag.ARRAY) {
        return DefaultOpenFieldType.NESTED_OPEN_AORDERED_LIST_TYPE;
    } else if (typeTag == ATypeTag.MULTISET) {
        return DefaultOpenFieldType.NESTED_OPEN_AUNORDERED_LIST_TYPE;
    } else {
        return BuiltinType.ANY;
    }
}
#end_block

#method_before
public static FunctionCollection createDefaultFunctionCollection() {
    FunctionCollection fc = new FunctionCollection();
    // array functions
    fc.addGenerated(ArrayAppendDescriptor.FACTORY);
    // unnesting functions
    fc.add(TidRunningAggregateDescriptor.FACTORY);
    fc.add(ScanCollectionDescriptor.FACTORY);
    fc.add(RangeDescriptor.FACTORY);
    fc.add(SubsetCollectionDescriptor.FACTORY);
    // aggregate functions
    fc.add(ListifyAggregateDescriptor.FACTORY);
    fc.add(CountAggregateDescriptor.FACTORY);
    fc.add(AvgAggregateDescriptor.FACTORY);
    fc.add(LocalAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SumAggregateDescriptor.FACTORY);
    fc.add(LocalSumAggregateDescriptor.FACTORY);
    fc.add(MaxAggregateDescriptor.FACTORY);
    fc.add(LocalMaxAggregateDescriptor.FACTORY);
    fc.add(MinAggregateDescriptor.FACTORY);
    fc.add(LocalMinAggregateDescriptor.FACTORY);
    fc.add(FirstElementAggregateDescriptor.FACTORY);
    fc.add(LocalFirstElementAggregateDescriptor.FACTORY);
    // serializable aggregates
    fc.add(SerializableCountAggregateDescriptor.FACTORY);
    fc.add(SerializableAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSumAggregateDescriptor.FACTORY);
    // scalar aggregates
    fc.add(ScalarCountAggregateDescriptor.FACTORY);
    fc.add(ScalarAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSumAggregateDescriptor.FACTORY);
    fc.add(ScalarMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarMinAggregateDescriptor.FACTORY);
    fc.add(EmptyStreamAggregateDescriptor.FACTORY);
    fc.add(NonEmptyStreamAggregateDescriptor.FACTORY);
    // SQL aggregates
    fc.add(SqlCountAggregateDescriptor.FACTORY);
    fc.add(SqlAvgAggregateDescriptor.FACTORY);
    fc.add(LocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SqlSumAggregateDescriptor.FACTORY);
    fc.add(LocalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SqlMaxAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMaxAggregateDescriptor.FACTORY);
    fc.add(SqlMinAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMinAggregateDescriptor.FACTORY);
    // SQL serializable aggregates
    fc.add(SerializableSqlCountAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlSumAggregateDescriptor.FACTORY);
    // SQL scalar aggregates
    fc.add(ScalarSqlCountAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlSumAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMinAggregateDescriptor.FACTORY);
    // boolean functions
    fc.add(AndDescriptor.FACTORY);
    fc.add(OrDescriptor.FACTORY);
    // Record constructors / functions
    fc.add(ClosedRecordConstructorDescriptor.FACTORY);
    fc.add(OpenRecordConstructorDescriptor.FACTORY);
    fc.add(RecordConcatDescriptor.FACTORY);
    fc.add(RecordConcatStrictDescriptor.FACTORY);
    // List constructors
    fc.add(OrderedListConstructorDescriptor.FACTORY);
    fc.add(UnorderedListConstructorDescriptor.FACTORY);
    // Sleep function
    fc.add(SleepDescriptor.FACTORY);
    // Inject failure function
    fc.add(InjectFailureDescriptor.FACTORY);
    // Get Job Parameter function
    fc.add(GetJobParameterByNameDescriptor.FACTORY);
    // Switch case
    fc.add(SwitchCaseDescriptor.FACTORY);
    // null functions
    fc.add(IsMissingDescriptor.FACTORY);
    fc.add(IsNullDescriptor.FACTORY);
    fc.add(IsUnknownDescriptor.FACTORY);
    fc.add(IsSystemNullDescriptor.FACTORY);
    fc.add(CheckUnknownDescriptor.FACTORY);
    fc.add(IfMissingDescriptor.FACTORY);
    fc.add(IfNullDescriptor.FACTORY);
    fc.add(IfMissingOrNullDescriptor.FACTORY);
    // uuid generators (zero independent functions)
    fc.add(CreateUUIDDescriptor.FACTORY);
    fc.add(UUIDDescriptor.FACTORY);
    fc.add(CreateQueryUIDDescriptor.FACTORY);
    fc.add(RandomDescriptor.FACTORY);
    fc.add(CurrentDateDescriptor.FACTORY);
    fc.add(CurrentTimeDescriptor.FACTORY);
    fc.add(CurrentDateTimeDescriptor.FACTORY);
    // functions that need generated class for null-handling.
    // Element accessors.
    fc.addGenerated(FieldAccessByIndexDescriptor.FACTORY);
    fc.addGenerated(FieldAccessByNameDescriptor.FACTORY);
    fc.addGenerated(FieldAccessNestedDescriptor.FACTORY);
    fc.addGenerated(AnyCollectionMemberDescriptor.FACTORY);
    fc.addGenerated(GetItemDescriptor.FACTORY);
    // Numeric functions
    fc.add(IfInfDescriptor.FACTORY);
    fc.add(IfNanDescriptor.FACTORY);
    fc.add(IfNanOrInfDescriptor.FACTORY);
    fc.addGenerated(NumericUnaryMinusDescriptor.FACTORY);
    fc.addGenerated(NumericAddDescriptor.FACTORY);
    fc.addGenerated(NumericDivideDescriptor.FACTORY);
    fc.addGenerated(NumericDivDescriptor.FACTORY);
    fc.addGenerated(NumericMultiplyDescriptor.FACTORY);
    fc.addGenerated(NumericSubDescriptor.FACTORY);
    fc.addGenerated(NumericModuloDescriptor.FACTORY);
    fc.addGenerated(NumericPowerDescriptor.FACTORY);
    fc.addGenerated(NotDescriptor.FACTORY);
    fc.addGenerated(LenDescriptor.FACTORY);
    fc.addGenerated(NumericAbsDescriptor.FACTORY);
    fc.addGenerated(NumericCeilingDescriptor.FACTORY);
    fc.addGenerated(NumericFloorDescriptor.FACTORY);
    fc.addGenerated(NumericRoundDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEvenDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEven2Descriptor.FACTORY);
    fc.addGenerated(NumericACosDescriptor.FACTORY);
    fc.addGenerated(NumericASinDescriptor.FACTORY);
    fc.addGenerated(NumericATanDescriptor.FACTORY);
    fc.addGenerated(NumericDegreesDescriptor.FACTORY);
    fc.addGenerated(NumericRadiansDescriptor.FACTORY);
    fc.addGenerated(NumericCosDescriptor.FACTORY);
    fc.addGenerated(NumericSinDescriptor.FACTORY);
    fc.addGenerated(NumericTanDescriptor.FACTORY);
    fc.addGenerated(NumericExpDescriptor.FACTORY);
    fc.addGenerated(NumericLnDescriptor.FACTORY);
    fc.addGenerated(NumericLogDescriptor.FACTORY);
    fc.addGenerated(NumericSqrtDescriptor.FACTORY);
    fc.addGenerated(NumericSignDescriptor.FACTORY);
    fc.addGenerated(NumericTruncDescriptor.FACTORY);
    fc.addGenerated(NumericATan2Descriptor.FACTORY);
    // Comparisons.
    fc.addGenerated(EqualsDescriptor.FACTORY);
    fc.addGenerated(GreaterThanDescriptor.FACTORY);
    fc.addGenerated(GreaterThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(LessThanDescriptor.FACTORY);
    fc.addGenerated(LessThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(NotEqualsDescriptor.FACTORY);
    // If-Equals functions
    fc.addGenerated(MissingIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NullIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NanIfEqualsDescriptor.FACTORY);
    fc.addGenerated(PosInfIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NegInfIfEqualsDescriptor.FACTORY);
    // Binary functions
    fc.addGenerated(BinaryLengthDescriptor.FACTORY);
    fc.addGenerated(ParseBinaryDescriptor.FACTORY);
    fc.addGenerated(PrintBinaryDescriptor.FACTORY);
    fc.addGenerated(BinaryConcatDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromToDescriptor.FACTORY);
    fc.addGenerated(FindBinaryDescriptor.FACTORY);
    fc.addGenerated(FindBinaryFromDescriptor.FACTORY);
    // String functions
    fc.addGenerated(StringLikeDescriptor.FACTORY);
    fc.addGenerated(StringContainsDescriptor.FACTORY);
    fc.addGenerated(StringEndsWithDescriptor.FACTORY);
    fc.addGenerated(StringStartsWithDescriptor.FACTORY);
    fc.addGenerated(SubstringDescriptor.FACTORY);
    fc.addGenerated(StringEqualDescriptor.FACTORY);
    fc.addGenerated(StringLowerCaseDescriptor.FACTORY);
    fc.addGenerated(StringUpperCaseDescriptor.FACTORY);
    fc.addGenerated(StringLengthDescriptor.FACTORY);
    fc.addGenerated(Substring2Descriptor.FACTORY);
    fc.addGenerated(SubstringBeforeDescriptor.FACTORY);
    fc.addGenerated(SubstringAfterDescriptor.FACTORY);
    fc.addGenerated(StringToCodePointDescriptor.FACTORY);
    fc.addGenerated(CodePointToStringDescriptor.FACTORY);
    fc.addGenerated(StringConcatDescriptor.FACTORY);
    fc.addGenerated(StringJoinDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceWithFlagsDescriptor.FACTORY);
    fc.addGenerated(StringInitCapDescriptor.FACTORY);
    fc.addGenerated(StringTrimDescriptor.FACTORY);
    fc.addGenerated(StringLTrimDescriptor.FACTORY);
    fc.addGenerated(StringRTrimDescriptor.FACTORY);
    fc.addGenerated(StringTrim2Descriptor.FACTORY);
    fc.addGenerated(StringLTrim2Descriptor.FACTORY);
    fc.addGenerated(StringRTrim2Descriptor.FACTORY);
    fc.addGenerated(StringPositionDescriptor.FACTORY);
    fc.addGenerated(StringRepeatDescriptor.FACTORY);
    fc.addGenerated(StringReplaceDescriptor.FACTORY);
    fc.addGenerated(StringReplaceWithLimitDescriptor.FACTORY);
    fc.addGenerated(StringReverseDescriptor.FACTORY);
    fc.addGenerated(StringSplitDescriptor.FACTORY);
    // Constructors
    fc.addGenerated(ABooleanConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryHexStringConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryBase64StringConstructorDescriptor.FACTORY);
    fc.addGenerated(AStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt8ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt16ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt32ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt64ConstructorDescriptor.FACTORY);
    fc.addGenerated(AFloatConstructorDescriptor.FACTORY);
    fc.addGenerated(ADoubleConstructorDescriptor.FACTORY);
    fc.addGenerated(APointConstructorDescriptor.FACTORY);
    fc.addGenerated(APoint3DConstructorDescriptor.FACTORY);
    fc.addGenerated(ALineConstructorDescriptor.FACTORY);
    fc.addGenerated(APolygonConstructorDescriptor.FACTORY);
    fc.addGenerated(ACircleConstructorDescriptor.FACTORY);
    fc.addGenerated(ARectangleConstructorDescriptor.FACTORY);
    fc.addGenerated(ATimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AYearMonthDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(ADayTimeDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AUUIDFromStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromTimeConstructorDescriptor.FACTORY);
    // Spatial
    fc.addGenerated(CreatePointDescriptor.FACTORY);
    fc.addGenerated(CreateLineDescriptor.FACTORY);
    fc.addGenerated(CreatePolygonDescriptor.FACTORY);
    fc.addGenerated(CreateCircleDescriptor.FACTORY);
    fc.addGenerated(CreateRectangleDescriptor.FACTORY);
    fc.addGenerated(SpatialAreaDescriptor.FACTORY);
    fc.addGenerated(SpatialDistanceDescriptor.FACTORY);
    fc.addGenerated(CreateMBRDescriptor.FACTORY);
    fc.addGenerated(SpatialCellDescriptor.FACTORY);
    fc.addGenerated(PointXCoordinateAccessor.FACTORY);
    fc.addGenerated(PointYCoordinateAccessor.FACTORY);
    fc.addGenerated(CircleRadiusAccessor.FACTORY);
    fc.addGenerated(CircleCenterAccessor.FACTORY);
    fc.addGenerated(LineRectanglePolygonAccessor.FACTORY);
    // full-text function
    fc.addGenerated(FullTextContainsDescriptor.FACTORY);
    fc.addGenerated(FullTextContainsWithoutOptionDescriptor.FACTORY);
    // Record functions.
    fc.addGenerated(GetRecordFieldsDescriptor.FACTORY);
    fc.addGenerated(GetRecordFieldValueDescriptor.FACTORY);
    fc.addGenerated(DeepEqualityDescriptor.FACTORY);
    fc.addGenerated(RecordMergeDescriptor.FACTORY);
    fc.addGenerated(RecordAddFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordLengthDescriptor.FACTORY);
    fc.addGenerated(RecordNamesDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveDescriptor.FACTORY);
    fc.addGenerated(RecordRenameDescriptor.FACTORY);
    fc.addGenerated(RecordUnwrapDescriptor.FACTORY);
    // Spatial and temporal type accessors
    fc.addGenerated(TemporalYearAccessor.FACTORY);
    fc.addGenerated(TemporalMonthAccessor.FACTORY);
    fc.addGenerated(TemporalDayAccessor.FACTORY);
    fc.addGenerated(TemporalHourAccessor.FACTORY);
    fc.addGenerated(TemporalMinuteAccessor.FACTORY);
    fc.addGenerated(TemporalSecondAccessor.FACTORY);
    fc.addGenerated(TemporalMillisecondAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDatetimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDatetimeAccessor.FACTORY);
    // Temporal functions
    fc.addGenerated(UnixTimeFromDateInDaysDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromTimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DateFromUnixTimeInDaysDescriptor.FACTORY);
    fc.addGenerated(DateFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(TimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(TimeFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromDateAndTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDurationFromDateTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDuartionFromDateDescriptor.FACTORY);
    fc.addGenerated(AdjustDateTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(AdjustTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(IntervalBeforeDescriptor.FACTORY);
    fc.addGenerated(IntervalAfterDescriptor.FACTORY);
    fc.addGenerated(IntervalMeetsDescriptor.FACTORY);
    fc.addGenerated(IntervalMetByDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlapsDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlappedByDescriptor.FACTORY);
    fc.addGenerated(OverlapDescriptor.FACTORY);
    fc.addGenerated(IntervalStartsDescriptor.FACTORY);
    fc.addGenerated(IntervalStartedByDescriptor.FACTORY);
    fc.addGenerated(IntervalCoversDescriptor.FACTORY);
    fc.addGenerated(IntervalCoveredByDescriptor.FACTORY);
    fc.addGenerated(IntervalEndsDescriptor.FACTORY);
    fc.addGenerated(IntervalEndedByDescriptor.FACTORY);
    fc.addGenerated(DurationFromMillisecondsDescriptor.FACTORY);
    fc.addGenerated(DurationFromMonthsDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(MonthsFromYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(MillisecondsFromDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(DurationEqualDescriptor.FACTORY);
    fc.addGenerated(GetYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(GetDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(IntervalBinDescriptor.FACTORY);
    fc.addGenerated(OverlapBinsDescriptor.FACTORY);
    fc.addGenerated(DayOfWeekDescriptor.FACTORY);
    fc.addGenerated(ParseDateDescriptor.FACTORY);
    fc.addGenerated(ParseTimeDescriptor.FACTORY);
    fc.addGenerated(ParseDateTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateDescriptor.FACTORY);
    fc.addGenerated(PrintTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateTimeDescriptor.FACTORY);
    fc.addGenerated(GetOverlappingIntervalDescriptor.FACTORY);
    fc.addGenerated(DurationFromIntervalDescriptor.FACTORY);
    // Type functions.
    fc.addGenerated(IsArrayDescriptor.FACTORY);
    fc.addGenerated(IsAtomicDescriptor.FACTORY);
    fc.addGenerated(IsBooleanDescriptor.FACTORY);
    fc.addGenerated(IsNumberDescriptor.FACTORY);
    fc.addGenerated(IsObjectDescriptor.FACTORY);
    fc.addGenerated(IsStringDescriptor.FACTORY);
    fc.addGenerated(ToArrayDescriptor.FACTORY);
    fc.addGenerated(ToAtomicDescriptor.FACTORY);
    fc.addGenerated(ToBigIntDescriptor.FACTORY);
    fc.addGenerated(ToBooleanDescriptor.FACTORY);
    fc.addGenerated(ToDoubleDescriptor.FACTORY);
    fc.addGenerated(ToNumberDescriptor.FACTORY);
    fc.addGenerated(ToObjectDescriptor.FACTORY);
    fc.addGenerated(ToStringDescriptor.FACTORY);
    // Cast function
    fc.addGenerated(CastTypeDescriptor.FACTORY);
    fc.addGenerated(CastTypeLaxDescriptor.FACTORY);
    // Record function
    fc.addGenerated(RecordPairsDescriptor.FACTORY);
    // Other functions
    fc.addGenerated(RandomWithSeedDescriptor.FACTORY);
    ServiceLoader.load(IFunctionRegistrant.class).iterator().forEachRemaining(c -> c.register(fc));
    return fc;
}
#method_after
public static FunctionCollection createDefaultFunctionCollection() {
    FunctionCollection fc = new FunctionCollection();
    // array functions
    fc.addGenerated(ArrayAppendDescriptor.FACTORY);
    // unnesting functions
    fc.add(TidRunningAggregateDescriptor.FACTORY);
    fc.add(ScanCollectionDescriptor.FACTORY);
    fc.add(RangeDescriptor.FACTORY);
    fc.add(SubsetCollectionDescriptor.FACTORY);
    // aggregate functions
    fc.add(ListifyAggregateDescriptor.FACTORY);
    fc.add(CountAggregateDescriptor.FACTORY);
    fc.add(AvgAggregateDescriptor.FACTORY);
    fc.add(LocalAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SumAggregateDescriptor.FACTORY);
    fc.add(LocalSumAggregateDescriptor.FACTORY);
    fc.add(MaxAggregateDescriptor.FACTORY);
    fc.add(LocalMaxAggregateDescriptor.FACTORY);
    fc.add(MinAggregateDescriptor.FACTORY);
    fc.add(LocalMinAggregateDescriptor.FACTORY);
    fc.add(FirstElementAggregateDescriptor.FACTORY);
    fc.add(LocalFirstElementAggregateDescriptor.FACTORY);
    // serializable aggregates
    fc.add(SerializableCountAggregateDescriptor.FACTORY);
    fc.add(SerializableAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSumAggregateDescriptor.FACTORY);
    // scalar aggregates
    fc.add(ScalarCountAggregateDescriptor.FACTORY);
    fc.add(ScalarAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSumAggregateDescriptor.FACTORY);
    fc.add(ScalarMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarMinAggregateDescriptor.FACTORY);
    fc.add(EmptyStreamAggregateDescriptor.FACTORY);
    fc.add(NonEmptyStreamAggregateDescriptor.FACTORY);
    // SQL aggregates
    fc.add(SqlCountAggregateDescriptor.FACTORY);
    fc.add(SqlAvgAggregateDescriptor.FACTORY);
    fc.add(LocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SqlSumAggregateDescriptor.FACTORY);
    fc.add(LocalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SqlMaxAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMaxAggregateDescriptor.FACTORY);
    fc.add(SqlMinAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMinAggregateDescriptor.FACTORY);
    // SQL serializable aggregates
    fc.add(SerializableSqlCountAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlSumAggregateDescriptor.FACTORY);
    // SQL scalar aggregates
    fc.add(ScalarSqlCountAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlSumAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMinAggregateDescriptor.FACTORY);
    // boolean functions
    fc.add(AndDescriptor.FACTORY);
    fc.add(OrDescriptor.FACTORY);
    // Record constructors / functions
    fc.add(ClosedRecordConstructorDescriptor.FACTORY);
    fc.add(OpenRecordConstructorDescriptor.FACTORY);
    fc.add(RecordConcatDescriptor.FACTORY);
    fc.add(RecordConcatStrictDescriptor.FACTORY);
    // List constructors
    fc.add(OrderedListConstructorDescriptor.FACTORY);
    fc.add(UnorderedListConstructorDescriptor.FACTORY);
    // Sleep function
    fc.add(SleepDescriptor.FACTORY);
    // Inject failure function
    fc.add(InjectFailureDescriptor.FACTORY);
    // Get Job Parameter function
    fc.add(GetJobParameterByNameDescriptor.FACTORY);
    // Switch case
    fc.add(SwitchCaseDescriptor.FACTORY);
    // null functions
    fc.add(IsMissingDescriptor.FACTORY);
    fc.add(IsNullDescriptor.FACTORY);
    fc.add(IsUnknownDescriptor.FACTORY);
    fc.add(IsSystemNullDescriptor.FACTORY);
    fc.add(CheckUnknownDescriptor.FACTORY);
    fc.add(IfMissingDescriptor.FACTORY);
    fc.add(IfNullDescriptor.FACTORY);
    fc.add(IfMissingOrNullDescriptor.FACTORY);
    // uuid generators (zero independent functions)
    fc.add(CreateUUIDDescriptor.FACTORY);
    fc.add(UUIDDescriptor.FACTORY);
    fc.add(CreateQueryUIDDescriptor.FACTORY);
    fc.add(RandomDescriptor.FACTORY);
    fc.add(CurrentDateDescriptor.FACTORY);
    fc.add(CurrentTimeDescriptor.FACTORY);
    fc.add(CurrentDateTimeDescriptor.FACTORY);
    // functions that need generated class for null-handling.
    // Element accessors.
    fc.addGenerated(FieldAccessByIndexDescriptor.FACTORY);
    fc.addGenerated(FieldAccessByNameDescriptor.FACTORY);
    fc.addGenerated(FieldAccessNestedDescriptor.FACTORY);
    fc.addGenerated(AnyCollectionMemberDescriptor.FACTORY);
    fc.addGenerated(GetItemDescriptor.FACTORY);
    // Numeric functions
    fc.add(IfInfDescriptor.FACTORY);
    fc.add(IfNanDescriptor.FACTORY);
    fc.add(IfNanOrInfDescriptor.FACTORY);
    fc.addGenerated(NumericUnaryMinusDescriptor.FACTORY);
    fc.addGenerated(NumericAddDescriptor.FACTORY);
    fc.addGenerated(NumericDivideDescriptor.FACTORY);
    fc.addGenerated(NumericDivDescriptor.FACTORY);
    fc.addGenerated(NumericMultiplyDescriptor.FACTORY);
    fc.addGenerated(NumericSubDescriptor.FACTORY);
    fc.addGenerated(NumericModuloDescriptor.FACTORY);
    fc.addGenerated(NumericPowerDescriptor.FACTORY);
    fc.addGenerated(NotDescriptor.FACTORY);
    fc.addGenerated(LenDescriptor.FACTORY);
    fc.addGenerated(NumericAbsDescriptor.FACTORY);
    fc.addGenerated(NumericCeilingDescriptor.FACTORY);
    fc.addGenerated(NumericFloorDescriptor.FACTORY);
    fc.addGenerated(NumericRoundDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEvenDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEven2Descriptor.FACTORY);
    fc.addGenerated(NumericACosDescriptor.FACTORY);
    fc.addGenerated(NumericASinDescriptor.FACTORY);
    fc.addGenerated(NumericATanDescriptor.FACTORY);
    fc.addGenerated(NumericDegreesDescriptor.FACTORY);
    fc.addGenerated(NumericRadiansDescriptor.FACTORY);
    fc.addGenerated(NumericCosDescriptor.FACTORY);
    fc.addGenerated(NumericSinDescriptor.FACTORY);
    fc.addGenerated(NumericTanDescriptor.FACTORY);
    fc.addGenerated(NumericExpDescriptor.FACTORY);
    fc.addGenerated(NumericLnDescriptor.FACTORY);
    fc.addGenerated(NumericLogDescriptor.FACTORY);
    fc.addGenerated(NumericSqrtDescriptor.FACTORY);
    fc.addGenerated(NumericSignDescriptor.FACTORY);
    fc.addGenerated(NumericTruncDescriptor.FACTORY);
    fc.addGenerated(NumericATan2Descriptor.FACTORY);
    // Comparisons.
    fc.addGenerated(EqualsDescriptor.FACTORY);
    fc.addGenerated(GreaterThanDescriptor.FACTORY);
    fc.addGenerated(GreaterThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(LessThanDescriptor.FACTORY);
    fc.addGenerated(LessThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(NotEqualsDescriptor.FACTORY);
    // If-Equals functions
    fc.addGenerated(MissingIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NullIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NanIfEqualsDescriptor.FACTORY);
    fc.addGenerated(PosInfIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NegInfIfEqualsDescriptor.FACTORY);
    // Binary functions
    fc.addGenerated(BinaryLengthDescriptor.FACTORY);
    fc.addGenerated(ParseBinaryDescriptor.FACTORY);
    fc.addGenerated(PrintBinaryDescriptor.FACTORY);
    fc.addGenerated(BinaryConcatDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromToDescriptor.FACTORY);
    fc.addGenerated(FindBinaryDescriptor.FACTORY);
    fc.addGenerated(FindBinaryFromDescriptor.FACTORY);
    // String functions
    fc.addGenerated(StringLikeDescriptor.FACTORY);
    fc.addGenerated(StringContainsDescriptor.FACTORY);
    fc.addGenerated(StringEndsWithDescriptor.FACTORY);
    fc.addGenerated(StringStartsWithDescriptor.FACTORY);
    fc.addGenerated(SubstringDescriptor.FACTORY);
    fc.addGenerated(StringEqualDescriptor.FACTORY);
    fc.addGenerated(StringLowerCaseDescriptor.FACTORY);
    fc.addGenerated(StringUpperCaseDescriptor.FACTORY);
    fc.addGenerated(StringLengthDescriptor.FACTORY);
    fc.addGenerated(Substring2Descriptor.FACTORY);
    fc.addGenerated(SubstringBeforeDescriptor.FACTORY);
    fc.addGenerated(SubstringAfterDescriptor.FACTORY);
    fc.addGenerated(StringToCodePointDescriptor.FACTORY);
    fc.addGenerated(CodePointToStringDescriptor.FACTORY);
    fc.addGenerated(StringConcatDescriptor.FACTORY);
    fc.addGenerated(StringJoinDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceWithFlagsDescriptor.FACTORY);
    fc.addGenerated(StringInitCapDescriptor.FACTORY);
    fc.addGenerated(StringTrimDescriptor.FACTORY);
    fc.addGenerated(StringLTrimDescriptor.FACTORY);
    fc.addGenerated(StringRTrimDescriptor.FACTORY);
    fc.addGenerated(StringTrim2Descriptor.FACTORY);
    fc.addGenerated(StringLTrim2Descriptor.FACTORY);
    fc.addGenerated(StringRTrim2Descriptor.FACTORY);
    fc.addGenerated(StringPositionDescriptor.FACTORY);
    fc.addGenerated(StringRepeatDescriptor.FACTORY);
    fc.addGenerated(StringReplaceDescriptor.FACTORY);
    fc.addGenerated(StringReplaceWithLimitDescriptor.FACTORY);
    fc.addGenerated(StringReverseDescriptor.FACTORY);
    fc.addGenerated(StringSplitDescriptor.FACTORY);
    // Constructors
    fc.addGenerated(ABooleanConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryHexStringConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryBase64StringConstructorDescriptor.FACTORY);
    fc.addGenerated(AStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt8ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt16ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt32ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt64ConstructorDescriptor.FACTORY);
    fc.addGenerated(AFloatConstructorDescriptor.FACTORY);
    fc.addGenerated(ADoubleConstructorDescriptor.FACTORY);
    fc.addGenerated(APointConstructorDescriptor.FACTORY);
    fc.addGenerated(APoint3DConstructorDescriptor.FACTORY);
    fc.addGenerated(ALineConstructorDescriptor.FACTORY);
    fc.addGenerated(APolygonConstructorDescriptor.FACTORY);
    fc.addGenerated(ACircleConstructorDescriptor.FACTORY);
    fc.addGenerated(ARectangleConstructorDescriptor.FACTORY);
    fc.addGenerated(ATimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AYearMonthDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(ADayTimeDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AUUIDFromStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromTimeConstructorDescriptor.FACTORY);
    // Spatial
    fc.addGenerated(CreatePointDescriptor.FACTORY);
    fc.addGenerated(CreateLineDescriptor.FACTORY);
    fc.addGenerated(CreatePolygonDescriptor.FACTORY);
    fc.addGenerated(CreateCircleDescriptor.FACTORY);
    fc.addGenerated(CreateRectangleDescriptor.FACTORY);
    fc.addGenerated(SpatialAreaDescriptor.FACTORY);
    fc.addGenerated(SpatialDistanceDescriptor.FACTORY);
    fc.addGenerated(CreateMBRDescriptor.FACTORY);
    fc.addGenerated(SpatialCellDescriptor.FACTORY);
    fc.addGenerated(PointXCoordinateAccessor.FACTORY);
    fc.addGenerated(PointYCoordinateAccessor.FACTORY);
    fc.addGenerated(CircleRadiusAccessor.FACTORY);
    fc.addGenerated(CircleCenterAccessor.FACTORY);
    fc.addGenerated(LineRectanglePolygonAccessor.FACTORY);
    // full-text function
    fc.addGenerated(FullTextContainsDescriptor.FACTORY);
    fc.addGenerated(FullTextContainsWithoutOptionDescriptor.FACTORY);
    // Record functions.
    fc.addGenerated(GetRecordFieldsDescriptor.FACTORY);
    fc.addGenerated(GetRecordFieldValueDescriptor.FACTORY);
    fc.addGenerated(DeepEqualityDescriptor.FACTORY);
    fc.addGenerated(RecordMergeDescriptor.FACTORY);
    fc.addGenerated(RecordAddFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordLengthDescriptor.FACTORY);
    fc.addGenerated(RecordNamesDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveDescriptor.FACTORY);
    fc.addGenerated(RecordRenameDescriptor.FACTORY);
    fc.addGenerated(RecordUnwrapDescriptor.FACTORY);
    fc.add(RecordReplaceDescriptor.FACTORY);
    // Spatial and temporal type accessors
    fc.addGenerated(TemporalYearAccessor.FACTORY);
    fc.addGenerated(TemporalMonthAccessor.FACTORY);
    fc.addGenerated(TemporalDayAccessor.FACTORY);
    fc.addGenerated(TemporalHourAccessor.FACTORY);
    fc.addGenerated(TemporalMinuteAccessor.FACTORY);
    fc.addGenerated(TemporalSecondAccessor.FACTORY);
    fc.addGenerated(TemporalMillisecondAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDatetimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDatetimeAccessor.FACTORY);
    // Temporal functions
    fc.addGenerated(UnixTimeFromDateInDaysDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromTimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DateFromUnixTimeInDaysDescriptor.FACTORY);
    fc.addGenerated(DateFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(TimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(TimeFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromDateAndTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDurationFromDateTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDuartionFromDateDescriptor.FACTORY);
    fc.addGenerated(AdjustDateTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(AdjustTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(IntervalBeforeDescriptor.FACTORY);
    fc.addGenerated(IntervalAfterDescriptor.FACTORY);
    fc.addGenerated(IntervalMeetsDescriptor.FACTORY);
    fc.addGenerated(IntervalMetByDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlapsDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlappedByDescriptor.FACTORY);
    fc.addGenerated(OverlapDescriptor.FACTORY);
    fc.addGenerated(IntervalStartsDescriptor.FACTORY);
    fc.addGenerated(IntervalStartedByDescriptor.FACTORY);
    fc.addGenerated(IntervalCoversDescriptor.FACTORY);
    fc.addGenerated(IntervalCoveredByDescriptor.FACTORY);
    fc.addGenerated(IntervalEndsDescriptor.FACTORY);
    fc.addGenerated(IntervalEndedByDescriptor.FACTORY);
    fc.addGenerated(DurationFromMillisecondsDescriptor.FACTORY);
    fc.addGenerated(DurationFromMonthsDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(MonthsFromYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(MillisecondsFromDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(DurationEqualDescriptor.FACTORY);
    fc.addGenerated(GetYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(GetDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(IntervalBinDescriptor.FACTORY);
    fc.addGenerated(OverlapBinsDescriptor.FACTORY);
    fc.addGenerated(DayOfWeekDescriptor.FACTORY);
    fc.addGenerated(ParseDateDescriptor.FACTORY);
    fc.addGenerated(ParseTimeDescriptor.FACTORY);
    fc.addGenerated(ParseDateTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateDescriptor.FACTORY);
    fc.addGenerated(PrintTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateTimeDescriptor.FACTORY);
    fc.addGenerated(GetOverlappingIntervalDescriptor.FACTORY);
    fc.addGenerated(DurationFromIntervalDescriptor.FACTORY);
    // Type functions.
    fc.addGenerated(IsArrayDescriptor.FACTORY);
    fc.addGenerated(IsAtomicDescriptor.FACTORY);
    fc.addGenerated(IsBooleanDescriptor.FACTORY);
    fc.addGenerated(IsNumberDescriptor.FACTORY);
    fc.addGenerated(IsObjectDescriptor.FACTORY);
    fc.addGenerated(IsStringDescriptor.FACTORY);
    fc.addGenerated(ToArrayDescriptor.FACTORY);
    fc.addGenerated(ToAtomicDescriptor.FACTORY);
    fc.addGenerated(ToBigIntDescriptor.FACTORY);
    fc.addGenerated(ToBooleanDescriptor.FACTORY);
    fc.addGenerated(ToDoubleDescriptor.FACTORY);
    fc.addGenerated(ToNumberDescriptor.FACTORY);
    fc.addGenerated(ToObjectDescriptor.FACTORY);
    fc.addGenerated(ToStringDescriptor.FACTORY);
    // Cast function
    fc.addGenerated(CastTypeDescriptor.FACTORY);
    fc.addGenerated(CastTypeLaxDescriptor.FACTORY);
    // Record function
    fc.addGenerated(RecordPairsDescriptor.FACTORY);
    // Other functions
    fc.addGenerated(RandomWithSeedDescriptor.FACTORY);
    ServiceLoader.load(IFunctionRegistrant.class).iterator().forEachRemaining(c -> c.register(fc));
    return fc;
}
#end_block

#method_before
@Override
public void setImmutableStates(Object... states) {
    recordType = (ARecordType) states[0];
}
#method_after
@Override
public void setImmutableStates(Object... states) {
    argTypes = new IAType[states.length];
    for (int i = 0; i < states.length; i++) {
        argTypes[i] = (IAType) states[i];
    }
}
#end_block

#method_before
@Override
public IScalarEvaluatorFactory createEvaluatorFactory(final IScalarEvaluatorFactory[] args) {
    return new IScalarEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IScalarEvaluator createScalarEvaluator(IHyracksTaskContext ctx) throws HyracksDataException {
            final IScalarEvaluator[] argEvals = new IScalarEvaluator[args.length];
            for (int i = 0; i < args.length; i++) {
                argEvals[i] = args[i].createScalarEvaluator(ctx);
            }
            return new RecordReplaceEvaluator(argEvals[0], argEvals[1], argEvals[2], recordType);
        }
    };
}
#method_after
@Override
public IScalarEvaluatorFactory createEvaluatorFactory(final IScalarEvaluatorFactory[] args) {
    return new IScalarEvaluatorFactory() {

        private static final long serialVersionUID = 1L;

        @Override
        public IScalarEvaluator createScalarEvaluator(IHyracksTaskContext ctx) throws HyracksDataException {
            final IScalarEvaluator[] argEvals = new IScalarEvaluator[args.length];
            for (int i = 0; i < args.length; i++) {
                argEvals[i] = args[i].createScalarEvaluator(ctx);
            }
            return new RecordReplaceEvaluator(sourceLoc, argEvals[0], argEvals[1], argEvals[2], argTypes);
        }
    };
}
#end_block

#method_before
public static FunctionCollection createDefaultFunctionCollection() {
    FunctionCollection fc = new FunctionCollection();
    // unnesting function
    fc.add(TidRunningAggregateDescriptor.FACTORY);
    fc.add(ScanCollectionDescriptor.FACTORY);
    fc.add(RangeDescriptor.FACTORY);
    fc.add(SubsetCollectionDescriptor.FACTORY);
    // aggregate functions
    fc.add(ListifyAggregateDescriptor.FACTORY);
    fc.add(CountAggregateDescriptor.FACTORY);
    fc.add(AvgAggregateDescriptor.FACTORY);
    fc.add(LocalAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SumAggregateDescriptor.FACTORY);
    fc.add(LocalSumAggregateDescriptor.FACTORY);
    fc.add(MaxAggregateDescriptor.FACTORY);
    fc.add(LocalMaxAggregateDescriptor.FACTORY);
    fc.add(MinAggregateDescriptor.FACTORY);
    fc.add(LocalMinAggregateDescriptor.FACTORY);
    fc.add(FirstElementAggregateDescriptor.FACTORY);
    fc.add(LocalFirstElementAggregateDescriptor.FACTORY);
    // serializable aggregates
    fc.add(SerializableCountAggregateDescriptor.FACTORY);
    fc.add(SerializableAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSumAggregateDescriptor.FACTORY);
    // scalar aggregates
    fc.add(ScalarCountAggregateDescriptor.FACTORY);
    fc.add(ScalarAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSumAggregateDescriptor.FACTORY);
    fc.add(ScalarMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarMinAggregateDescriptor.FACTORY);
    fc.add(EmptyStreamAggregateDescriptor.FACTORY);
    fc.add(NonEmptyStreamAggregateDescriptor.FACTORY);
    // SQL aggregates
    fc.add(SqlCountAggregateDescriptor.FACTORY);
    fc.add(SqlAvgAggregateDescriptor.FACTORY);
    fc.add(LocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SqlSumAggregateDescriptor.FACTORY);
    fc.add(LocalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SqlMaxAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMaxAggregateDescriptor.FACTORY);
    fc.add(SqlMinAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMinAggregateDescriptor.FACTORY);
    // SQL serializable aggregates
    fc.add(SerializableSqlCountAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlSumAggregateDescriptor.FACTORY);
    // SQL scalar aggregates
    fc.add(ScalarSqlCountAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlSumAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMinAggregateDescriptor.FACTORY);
    // boolean functions
    fc.add(AndDescriptor.FACTORY);
    fc.add(OrDescriptor.FACTORY);
    // Record constructors / functions
    fc.add(ClosedRecordConstructorDescriptor.FACTORY);
    fc.add(OpenRecordConstructorDescriptor.FACTORY);
    fc.add(RecordConcatDescriptor.FACTORY);
    fc.add(RecordConcatStrictDescriptor.FACTORY);
    // List constructors
    fc.add(OrderedListConstructorDescriptor.FACTORY);
    fc.add(UnorderedListConstructorDescriptor.FACTORY);
    // Sleep function
    fc.add(SleepDescriptor.FACTORY);
    // Inject failure function
    fc.add(InjectFailureDescriptor.FACTORY);
    // Get Job Parameter function
    fc.add(GetJobParameterByNameDescriptor.FACTORY);
    // Switch case
    fc.add(SwitchCaseDescriptor.FACTORY);
    // null functions
    fc.add(IsMissingDescriptor.FACTORY);
    fc.add(IsNullDescriptor.FACTORY);
    fc.add(IsUnknownDescriptor.FACTORY);
    fc.add(IsSystemNullDescriptor.FACTORY);
    fc.add(CheckUnknownDescriptor.FACTORY);
    fc.add(IfMissingDescriptor.FACTORY);
    fc.add(IfNullDescriptor.FACTORY);
    fc.add(IfMissingOrNullDescriptor.FACTORY);
    // uuid generators (zero independent functions)
    fc.add(CreateUUIDDescriptor.FACTORY);
    fc.add(UUIDDescriptor.FACTORY);
    fc.add(CreateQueryUIDDescriptor.FACTORY);
    fc.add(RandomDescriptor.FACTORY);
    fc.add(CurrentDateDescriptor.FACTORY);
    fc.add(CurrentTimeDescriptor.FACTORY);
    fc.add(CurrentDateTimeDescriptor.FACTORY);
    // functions that need generated class for null-handling.
    // Element accessors.
    fc.addGenerated(FieldAccessByIndexDescriptor.FACTORY);
    fc.addGenerated(FieldAccessByNameDescriptor.FACTORY);
    fc.addGenerated(FieldAccessNestedDescriptor.FACTORY);
    fc.addGenerated(AnyCollectionMemberDescriptor.FACTORY);
    fc.addGenerated(GetItemDescriptor.FACTORY);
    // Numeric functions
    fc.add(IfInfDescriptor.FACTORY);
    fc.add(IfNanDescriptor.FACTORY);
    fc.add(IfNanOrInfDescriptor.FACTORY);
    fc.addGenerated(NumericUnaryMinusDescriptor.FACTORY);
    fc.addGenerated(NumericAddDescriptor.FACTORY);
    fc.addGenerated(NumericDivideDescriptor.FACTORY);
    fc.addGenerated(NumericDivDescriptor.FACTORY);
    fc.addGenerated(NumericMultiplyDescriptor.FACTORY);
    fc.addGenerated(NumericSubDescriptor.FACTORY);
    fc.addGenerated(NumericModuloDescriptor.FACTORY);
    fc.addGenerated(NumericPowerDescriptor.FACTORY);
    fc.addGenerated(NotDescriptor.FACTORY);
    fc.addGenerated(LenDescriptor.FACTORY);
    fc.addGenerated(NumericAbsDescriptor.FACTORY);
    fc.addGenerated(NumericCeilingDescriptor.FACTORY);
    fc.addGenerated(NumericFloorDescriptor.FACTORY);
    fc.addGenerated(NumericRoundDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEvenDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEven2Descriptor.FACTORY);
    fc.addGenerated(NumericACosDescriptor.FACTORY);
    fc.addGenerated(NumericASinDescriptor.FACTORY);
    fc.addGenerated(NumericATanDescriptor.FACTORY);
    fc.addGenerated(NumericDegreesDescriptor.FACTORY);
    fc.addGenerated(NumericRadiansDescriptor.FACTORY);
    fc.addGenerated(NumericCosDescriptor.FACTORY);
    fc.addGenerated(NumericSinDescriptor.FACTORY);
    fc.addGenerated(NumericTanDescriptor.FACTORY);
    fc.addGenerated(NumericExpDescriptor.FACTORY);
    fc.addGenerated(NumericLnDescriptor.FACTORY);
    fc.addGenerated(NumericLogDescriptor.FACTORY);
    fc.addGenerated(NumericSqrtDescriptor.FACTORY);
    fc.addGenerated(NumericSignDescriptor.FACTORY);
    fc.addGenerated(NumericTruncDescriptor.FACTORY);
    fc.addGenerated(NumericATan2Descriptor.FACTORY);
    // Comparisons.
    fc.addGenerated(EqualsDescriptor.FACTORY);
    fc.addGenerated(GreaterThanDescriptor.FACTORY);
    fc.addGenerated(GreaterThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(LessThanDescriptor.FACTORY);
    fc.addGenerated(LessThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(NotEqualsDescriptor.FACTORY);
    // If-Equals functions
    fc.addGenerated(MissingIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NullIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NanIfEqualsDescriptor.FACTORY);
    fc.addGenerated(PosInfIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NegInfIfEqualsDescriptor.FACTORY);
    // Binary functions
    fc.addGenerated(BinaryLengthDescriptor.FACTORY);
    fc.addGenerated(ParseBinaryDescriptor.FACTORY);
    fc.addGenerated(PrintBinaryDescriptor.FACTORY);
    fc.addGenerated(BinaryConcatDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromToDescriptor.FACTORY);
    fc.addGenerated(FindBinaryDescriptor.FACTORY);
    fc.addGenerated(FindBinaryFromDescriptor.FACTORY);
    // String functions
    fc.addGenerated(StringLikeDescriptor.FACTORY);
    fc.addGenerated(StringContainsDescriptor.FACTORY);
    fc.addGenerated(StringEndsWithDescriptor.FACTORY);
    fc.addGenerated(StringStartsWithDescriptor.FACTORY);
    fc.addGenerated(SubstringDescriptor.FACTORY);
    fc.addGenerated(StringEqualDescriptor.FACTORY);
    fc.addGenerated(StringLowerCaseDescriptor.FACTORY);
    fc.addGenerated(StringUpperCaseDescriptor.FACTORY);
    fc.addGenerated(StringLengthDescriptor.FACTORY);
    fc.addGenerated(Substring2Descriptor.FACTORY);
    fc.addGenerated(SubstringBeforeDescriptor.FACTORY);
    fc.addGenerated(SubstringAfterDescriptor.FACTORY);
    fc.addGenerated(StringToCodePointDescriptor.FACTORY);
    fc.addGenerated(CodePointToStringDescriptor.FACTORY);
    fc.addGenerated(StringConcatDescriptor.FACTORY);
    fc.addGenerated(StringJoinDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceWithFlagsDescriptor.FACTORY);
    fc.addGenerated(StringInitCapDescriptor.FACTORY);
    fc.addGenerated(StringTrimDescriptor.FACTORY);
    fc.addGenerated(StringLTrimDescriptor.FACTORY);
    fc.addGenerated(StringRTrimDescriptor.FACTORY);
    fc.addGenerated(StringTrim2Descriptor.FACTORY);
    fc.addGenerated(StringLTrim2Descriptor.FACTORY);
    fc.addGenerated(StringRTrim2Descriptor.FACTORY);
    fc.addGenerated(StringPositionDescriptor.FACTORY);
    fc.addGenerated(StringRepeatDescriptor.FACTORY);
    fc.addGenerated(StringReplaceDescriptor.FACTORY);
    fc.addGenerated(StringReplaceWithLimitDescriptor.FACTORY);
    fc.addGenerated(StringReverseDescriptor.FACTORY);
    fc.addGenerated(StringSplitDescriptor.FACTORY);
    // Constructors
    fc.addGenerated(ABooleanConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryHexStringConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryBase64StringConstructorDescriptor.FACTORY);
    fc.addGenerated(AStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt8ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt16ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt32ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt64ConstructorDescriptor.FACTORY);
    fc.addGenerated(AFloatConstructorDescriptor.FACTORY);
    fc.addGenerated(ADoubleConstructorDescriptor.FACTORY);
    fc.addGenerated(APointConstructorDescriptor.FACTORY);
    fc.addGenerated(APoint3DConstructorDescriptor.FACTORY);
    fc.addGenerated(ALineConstructorDescriptor.FACTORY);
    fc.addGenerated(APolygonConstructorDescriptor.FACTORY);
    fc.addGenerated(ACircleConstructorDescriptor.FACTORY);
    fc.addGenerated(ARectangleConstructorDescriptor.FACTORY);
    fc.addGenerated(ATimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AYearMonthDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(ADayTimeDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AUUIDFromStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromTimeConstructorDescriptor.FACTORY);
    // Spatial
    fc.addGenerated(CreatePointDescriptor.FACTORY);
    fc.addGenerated(CreateLineDescriptor.FACTORY);
    fc.addGenerated(CreatePolygonDescriptor.FACTORY);
    fc.addGenerated(CreateCircleDescriptor.FACTORY);
    fc.addGenerated(CreateRectangleDescriptor.FACTORY);
    fc.addGenerated(SpatialAreaDescriptor.FACTORY);
    fc.addGenerated(SpatialDistanceDescriptor.FACTORY);
    fc.addGenerated(CreateMBRDescriptor.FACTORY);
    fc.addGenerated(SpatialCellDescriptor.FACTORY);
    fc.addGenerated(PointXCoordinateAccessor.FACTORY);
    fc.addGenerated(PointYCoordinateAccessor.FACTORY);
    fc.addGenerated(CircleRadiusAccessor.FACTORY);
    fc.addGenerated(CircleCenterAccessor.FACTORY);
    fc.addGenerated(LineRectanglePolygonAccessor.FACTORY);
    // full-text function
    fc.addGenerated(FullTextContainsDescriptor.FACTORY);
    fc.addGenerated(FullTextContainsWithoutOptionDescriptor.FACTORY);
    // Record functions.
    fc.addGenerated(GetRecordFieldsDescriptor.FACTORY);
    fc.addGenerated(GetRecordFieldValueDescriptor.FACTORY);
    fc.addGenerated(DeepEqualityDescriptor.FACTORY);
    fc.addGenerated(RecordMergeDescriptor.FACTORY);
    fc.addGenerated(RecordAddFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordLengthDescriptor.FACTORY);
    fc.addGenerated(RecordNamesDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveDescriptor.FACTORY);
    fc.addGenerated(RecordRenameDescriptor.FACTORY);
    fc.addGenerated(RecordReplaceDescriptor.FACTORY);
    // Spatial and temporal type accessors
    fc.addGenerated(TemporalYearAccessor.FACTORY);
    fc.addGenerated(TemporalMonthAccessor.FACTORY);
    fc.addGenerated(TemporalDayAccessor.FACTORY);
    fc.addGenerated(TemporalHourAccessor.FACTORY);
    fc.addGenerated(TemporalMinuteAccessor.FACTORY);
    fc.addGenerated(TemporalSecondAccessor.FACTORY);
    fc.addGenerated(TemporalMillisecondAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDatetimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDatetimeAccessor.FACTORY);
    // Temporal functions
    fc.addGenerated(UnixTimeFromDateInDaysDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromTimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DateFromUnixTimeInDaysDescriptor.FACTORY);
    fc.addGenerated(DateFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(TimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(TimeFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromDateAndTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDurationFromDateTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDuartionFromDateDescriptor.FACTORY);
    fc.addGenerated(AdjustDateTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(AdjustTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(IntervalBeforeDescriptor.FACTORY);
    fc.addGenerated(IntervalAfterDescriptor.FACTORY);
    fc.addGenerated(IntervalMeetsDescriptor.FACTORY);
    fc.addGenerated(IntervalMetByDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlapsDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlappedByDescriptor.FACTORY);
    fc.addGenerated(OverlapDescriptor.FACTORY);
    fc.addGenerated(IntervalStartsDescriptor.FACTORY);
    fc.addGenerated(IntervalStartedByDescriptor.FACTORY);
    fc.addGenerated(IntervalCoversDescriptor.FACTORY);
    fc.addGenerated(IntervalCoveredByDescriptor.FACTORY);
    fc.addGenerated(IntervalEndsDescriptor.FACTORY);
    fc.addGenerated(IntervalEndedByDescriptor.FACTORY);
    fc.addGenerated(DurationFromMillisecondsDescriptor.FACTORY);
    fc.addGenerated(DurationFromMonthsDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(MonthsFromYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(MillisecondsFromDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(DurationEqualDescriptor.FACTORY);
    fc.addGenerated(GetYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(GetDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(IntervalBinDescriptor.FACTORY);
    fc.addGenerated(OverlapBinsDescriptor.FACTORY);
    fc.addGenerated(DayOfWeekDescriptor.FACTORY);
    fc.addGenerated(ParseDateDescriptor.FACTORY);
    fc.addGenerated(ParseTimeDescriptor.FACTORY);
    fc.addGenerated(ParseDateTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateDescriptor.FACTORY);
    fc.addGenerated(PrintTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateTimeDescriptor.FACTORY);
    fc.addGenerated(GetOverlappingIntervalDescriptor.FACTORY);
    fc.addGenerated(DurationFromIntervalDescriptor.FACTORY);
    // Type functions.
    fc.addGenerated(IsArrayDescriptor.FACTORY);
    fc.addGenerated(IsAtomicDescriptor.FACTORY);
    fc.addGenerated(IsBooleanDescriptor.FACTORY);
    fc.addGenerated(IsNumberDescriptor.FACTORY);
    fc.addGenerated(IsObjectDescriptor.FACTORY);
    fc.addGenerated(IsStringDescriptor.FACTORY);
    fc.addGenerated(ToArrayDescriptor.FACTORY);
    fc.addGenerated(ToAtomicDescriptor.FACTORY);
    fc.addGenerated(ToBigIntDescriptor.FACTORY);
    fc.addGenerated(ToBooleanDescriptor.FACTORY);
    fc.addGenerated(ToDoubleDescriptor.FACTORY);
    fc.addGenerated(ToNumberDescriptor.FACTORY);
    fc.addGenerated(ToObjectDescriptor.FACTORY);
    fc.addGenerated(ToStringDescriptor.FACTORY);
    // Cast function
    fc.addGenerated(CastTypeDescriptor.FACTORY);
    fc.addGenerated(CastTypeLaxDescriptor.FACTORY);
    // Record function
    fc.addGenerated(RecordPairsDescriptor.FACTORY);
    // Other functions
    fc.addGenerated(RandomWithSeedDescriptor.FACTORY);
    ServiceLoader.load(IFunctionRegistrant.class).iterator().forEachRemaining(c -> c.register(fc));
    return fc;
}
#method_after
public static FunctionCollection createDefaultFunctionCollection() {
    FunctionCollection fc = new FunctionCollection();
    // unnesting function
    fc.add(TidRunningAggregateDescriptor.FACTORY);
    fc.add(ScanCollectionDescriptor.FACTORY);
    fc.add(RangeDescriptor.FACTORY);
    fc.add(SubsetCollectionDescriptor.FACTORY);
    // aggregate functions
    fc.add(ListifyAggregateDescriptor.FACTORY);
    fc.add(CountAggregateDescriptor.FACTORY);
    fc.add(AvgAggregateDescriptor.FACTORY);
    fc.add(LocalAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SumAggregateDescriptor.FACTORY);
    fc.add(LocalSumAggregateDescriptor.FACTORY);
    fc.add(MaxAggregateDescriptor.FACTORY);
    fc.add(LocalMaxAggregateDescriptor.FACTORY);
    fc.add(MinAggregateDescriptor.FACTORY);
    fc.add(LocalMinAggregateDescriptor.FACTORY);
    fc.add(FirstElementAggregateDescriptor.FACTORY);
    fc.add(LocalFirstElementAggregateDescriptor.FACTORY);
    // serializable aggregates
    fc.add(SerializableCountAggregateDescriptor.FACTORY);
    fc.add(SerializableAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSumAggregateDescriptor.FACTORY);
    // scalar aggregates
    fc.add(ScalarCountAggregateDescriptor.FACTORY);
    fc.add(ScalarAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSumAggregateDescriptor.FACTORY);
    fc.add(ScalarMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarMinAggregateDescriptor.FACTORY);
    fc.add(EmptyStreamAggregateDescriptor.FACTORY);
    fc.add(NonEmptyStreamAggregateDescriptor.FACTORY);
    // SQL aggregates
    fc.add(SqlCountAggregateDescriptor.FACTORY);
    fc.add(SqlAvgAggregateDescriptor.FACTORY);
    fc.add(LocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(IntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(GlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SqlSumAggregateDescriptor.FACTORY);
    fc.add(LocalSqlSumAggregateDescriptor.FACTORY);
    fc.add(SqlMaxAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMaxAggregateDescriptor.FACTORY);
    fc.add(SqlMinAggregateDescriptor.FACTORY);
    fc.add(LocalSqlMinAggregateDescriptor.FACTORY);
    // SQL serializable aggregates
    fc.add(SerializableSqlCountAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableIntermediateSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableGlobalSqlAvgAggregateDescriptor.FACTORY);
    fc.add(SerializableSqlSumAggregateDescriptor.FACTORY);
    fc.add(SerializableLocalSqlSumAggregateDescriptor.FACTORY);
    // SQL scalar aggregates
    fc.add(ScalarSqlCountAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlAvgAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlSumAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMaxAggregateDescriptor.FACTORY);
    fc.add(ScalarSqlMinAggregateDescriptor.FACTORY);
    // boolean functions
    fc.add(AndDescriptor.FACTORY);
    fc.add(OrDescriptor.FACTORY);
    // Record constructors / functions
    fc.add(ClosedRecordConstructorDescriptor.FACTORY);
    fc.add(OpenRecordConstructorDescriptor.FACTORY);
    fc.add(RecordConcatDescriptor.FACTORY);
    fc.add(RecordConcatStrictDescriptor.FACTORY);
    // List constructors
    fc.add(OrderedListConstructorDescriptor.FACTORY);
    fc.add(UnorderedListConstructorDescriptor.FACTORY);
    // Sleep function
    fc.add(SleepDescriptor.FACTORY);
    // Inject failure function
    fc.add(InjectFailureDescriptor.FACTORY);
    // Get Job Parameter function
    fc.add(GetJobParameterByNameDescriptor.FACTORY);
    // Switch case
    fc.add(SwitchCaseDescriptor.FACTORY);
    // null functions
    fc.add(IsMissingDescriptor.FACTORY);
    fc.add(IsNullDescriptor.FACTORY);
    fc.add(IsUnknownDescriptor.FACTORY);
    fc.add(IsSystemNullDescriptor.FACTORY);
    fc.add(CheckUnknownDescriptor.FACTORY);
    fc.add(IfMissingDescriptor.FACTORY);
    fc.add(IfNullDescriptor.FACTORY);
    fc.add(IfMissingOrNullDescriptor.FACTORY);
    // uuid generators (zero independent functions)
    fc.add(CreateUUIDDescriptor.FACTORY);
    fc.add(UUIDDescriptor.FACTORY);
    fc.add(CreateQueryUIDDescriptor.FACTORY);
    fc.add(RandomDescriptor.FACTORY);
    fc.add(CurrentDateDescriptor.FACTORY);
    fc.add(CurrentTimeDescriptor.FACTORY);
    fc.add(CurrentDateTimeDescriptor.FACTORY);
    // functions that need generated class for null-handling.
    // Element accessors.
    fc.addGenerated(FieldAccessByIndexDescriptor.FACTORY);
    fc.addGenerated(FieldAccessByNameDescriptor.FACTORY);
    fc.addGenerated(FieldAccessNestedDescriptor.FACTORY);
    fc.addGenerated(AnyCollectionMemberDescriptor.FACTORY);
    fc.addGenerated(GetItemDescriptor.FACTORY);
    // Numeric functions
    fc.add(IfInfDescriptor.FACTORY);
    fc.add(IfNanDescriptor.FACTORY);
    fc.add(IfNanOrInfDescriptor.FACTORY);
    fc.addGenerated(NumericUnaryMinusDescriptor.FACTORY);
    fc.addGenerated(NumericAddDescriptor.FACTORY);
    fc.addGenerated(NumericDivideDescriptor.FACTORY);
    fc.addGenerated(NumericDivDescriptor.FACTORY);
    fc.addGenerated(NumericMultiplyDescriptor.FACTORY);
    fc.addGenerated(NumericSubDescriptor.FACTORY);
    fc.addGenerated(NumericModuloDescriptor.FACTORY);
    fc.addGenerated(NumericPowerDescriptor.FACTORY);
    fc.addGenerated(NotDescriptor.FACTORY);
    fc.addGenerated(LenDescriptor.FACTORY);
    fc.addGenerated(NumericAbsDescriptor.FACTORY);
    fc.addGenerated(NumericCeilingDescriptor.FACTORY);
    fc.addGenerated(NumericFloorDescriptor.FACTORY);
    fc.addGenerated(NumericRoundDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEvenDescriptor.FACTORY);
    fc.addGenerated(NumericRoundHalfToEven2Descriptor.FACTORY);
    fc.addGenerated(NumericACosDescriptor.FACTORY);
    fc.addGenerated(NumericASinDescriptor.FACTORY);
    fc.addGenerated(NumericATanDescriptor.FACTORY);
    fc.addGenerated(NumericDegreesDescriptor.FACTORY);
    fc.addGenerated(NumericRadiansDescriptor.FACTORY);
    fc.addGenerated(NumericCosDescriptor.FACTORY);
    fc.addGenerated(NumericSinDescriptor.FACTORY);
    fc.addGenerated(NumericTanDescriptor.FACTORY);
    fc.addGenerated(NumericExpDescriptor.FACTORY);
    fc.addGenerated(NumericLnDescriptor.FACTORY);
    fc.addGenerated(NumericLogDescriptor.FACTORY);
    fc.addGenerated(NumericSqrtDescriptor.FACTORY);
    fc.addGenerated(NumericSignDescriptor.FACTORY);
    fc.addGenerated(NumericTruncDescriptor.FACTORY);
    fc.addGenerated(NumericATan2Descriptor.FACTORY);
    // Comparisons.
    fc.addGenerated(EqualsDescriptor.FACTORY);
    fc.addGenerated(GreaterThanDescriptor.FACTORY);
    fc.addGenerated(GreaterThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(LessThanDescriptor.FACTORY);
    fc.addGenerated(LessThanOrEqualsDescriptor.FACTORY);
    fc.addGenerated(NotEqualsDescriptor.FACTORY);
    // If-Equals functions
    fc.addGenerated(MissingIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NullIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NanIfEqualsDescriptor.FACTORY);
    fc.addGenerated(PosInfIfEqualsDescriptor.FACTORY);
    fc.addGenerated(NegInfIfEqualsDescriptor.FACTORY);
    // Binary functions
    fc.addGenerated(BinaryLengthDescriptor.FACTORY);
    fc.addGenerated(ParseBinaryDescriptor.FACTORY);
    fc.addGenerated(PrintBinaryDescriptor.FACTORY);
    fc.addGenerated(BinaryConcatDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromDescriptor.FACTORY);
    fc.addGenerated(SubBinaryFromToDescriptor.FACTORY);
    fc.addGenerated(FindBinaryDescriptor.FACTORY);
    fc.addGenerated(FindBinaryFromDescriptor.FACTORY);
    // String functions
    fc.addGenerated(StringLikeDescriptor.FACTORY);
    fc.addGenerated(StringContainsDescriptor.FACTORY);
    fc.addGenerated(StringEndsWithDescriptor.FACTORY);
    fc.addGenerated(StringStartsWithDescriptor.FACTORY);
    fc.addGenerated(SubstringDescriptor.FACTORY);
    fc.addGenerated(StringEqualDescriptor.FACTORY);
    fc.addGenerated(StringLowerCaseDescriptor.FACTORY);
    fc.addGenerated(StringUpperCaseDescriptor.FACTORY);
    fc.addGenerated(StringLengthDescriptor.FACTORY);
    fc.addGenerated(Substring2Descriptor.FACTORY);
    fc.addGenerated(SubstringBeforeDescriptor.FACTORY);
    fc.addGenerated(SubstringAfterDescriptor.FACTORY);
    fc.addGenerated(StringToCodePointDescriptor.FACTORY);
    fc.addGenerated(CodePointToStringDescriptor.FACTORY);
    fc.addGenerated(StringConcatDescriptor.FACTORY);
    fc.addGenerated(StringJoinDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsDescriptor.FACTORY);
    fc.addGenerated(StringRegExpContainsWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeDescriptor.FACTORY);
    fc.addGenerated(StringRegExpLikeWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionDescriptor.FACTORY);
    fc.addGenerated(StringRegExpPositionWithFlagDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceDescriptor.FACTORY);
    fc.addGenerated(StringRegExpReplaceWithFlagsDescriptor.FACTORY);
    fc.addGenerated(StringInitCapDescriptor.FACTORY);
    fc.addGenerated(StringTrimDescriptor.FACTORY);
    fc.addGenerated(StringLTrimDescriptor.FACTORY);
    fc.addGenerated(StringRTrimDescriptor.FACTORY);
    fc.addGenerated(StringTrim2Descriptor.FACTORY);
    fc.addGenerated(StringLTrim2Descriptor.FACTORY);
    fc.addGenerated(StringRTrim2Descriptor.FACTORY);
    fc.addGenerated(StringPositionDescriptor.FACTORY);
    fc.addGenerated(StringRepeatDescriptor.FACTORY);
    fc.addGenerated(StringReplaceDescriptor.FACTORY);
    fc.addGenerated(StringReplaceWithLimitDescriptor.FACTORY);
    fc.addGenerated(StringReverseDescriptor.FACTORY);
    fc.addGenerated(StringSplitDescriptor.FACTORY);
    // Constructors
    fc.addGenerated(ABooleanConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryHexStringConstructorDescriptor.FACTORY);
    fc.addGenerated(ABinaryBase64StringConstructorDescriptor.FACTORY);
    fc.addGenerated(AStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt8ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt16ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt32ConstructorDescriptor.FACTORY);
    fc.addGenerated(AInt64ConstructorDescriptor.FACTORY);
    fc.addGenerated(AFloatConstructorDescriptor.FACTORY);
    fc.addGenerated(ADoubleConstructorDescriptor.FACTORY);
    fc.addGenerated(APointConstructorDescriptor.FACTORY);
    fc.addGenerated(APoint3DConstructorDescriptor.FACTORY);
    fc.addGenerated(ALineConstructorDescriptor.FACTORY);
    fc.addGenerated(APolygonConstructorDescriptor.FACTORY);
    fc.addGenerated(ACircleConstructorDescriptor.FACTORY);
    fc.addGenerated(ARectangleConstructorDescriptor.FACTORY);
    fc.addGenerated(ATimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateConstructorDescriptor.FACTORY);
    fc.addGenerated(ADateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(ADurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AYearMonthDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(ADayTimeDurationConstructorDescriptor.FACTORY);
    fc.addGenerated(AUUIDFromStringConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromDateTimeConstructorDescriptor.FACTORY);
    fc.addGenerated(AIntervalStartFromTimeConstructorDescriptor.FACTORY);
    // Spatial
    fc.addGenerated(CreatePointDescriptor.FACTORY);
    fc.addGenerated(CreateLineDescriptor.FACTORY);
    fc.addGenerated(CreatePolygonDescriptor.FACTORY);
    fc.addGenerated(CreateCircleDescriptor.FACTORY);
    fc.addGenerated(CreateRectangleDescriptor.FACTORY);
    fc.addGenerated(SpatialAreaDescriptor.FACTORY);
    fc.addGenerated(SpatialDistanceDescriptor.FACTORY);
    fc.addGenerated(CreateMBRDescriptor.FACTORY);
    fc.addGenerated(SpatialCellDescriptor.FACTORY);
    fc.addGenerated(PointXCoordinateAccessor.FACTORY);
    fc.addGenerated(PointYCoordinateAccessor.FACTORY);
    fc.addGenerated(CircleRadiusAccessor.FACTORY);
    fc.addGenerated(CircleCenterAccessor.FACTORY);
    fc.addGenerated(LineRectanglePolygonAccessor.FACTORY);
    // full-text function
    fc.addGenerated(FullTextContainsDescriptor.FACTORY);
    fc.addGenerated(FullTextContainsWithoutOptionDescriptor.FACTORY);
    // Record functions.
    fc.addGenerated(GetRecordFieldsDescriptor.FACTORY);
    fc.addGenerated(GetRecordFieldValueDescriptor.FACTORY);
    fc.addGenerated(DeepEqualityDescriptor.FACTORY);
    fc.addGenerated(RecordMergeDescriptor.FACTORY);
    fc.addGenerated(RecordAddFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveFieldsDescriptor.FACTORY);
    fc.addGenerated(RecordLengthDescriptor.FACTORY);
    fc.addGenerated(RecordNamesDescriptor.FACTORY);
    fc.addGenerated(RecordRemoveDescriptor.FACTORY);
    fc.addGenerated(RecordRenameDescriptor.FACTORY);
    fc.addGenerated(RecordUnwrapDescriptor.FACTORY);
    fc.add(RecordReplaceDescriptor.FACTORY);
    // Spatial and temporal type accessors
    fc.addGenerated(TemporalYearAccessor.FACTORY);
    fc.addGenerated(TemporalMonthAccessor.FACTORY);
    fc.addGenerated(TemporalDayAccessor.FACTORY);
    fc.addGenerated(TemporalHourAccessor.FACTORY);
    fc.addGenerated(TemporalMinuteAccessor.FACTORY);
    fc.addGenerated(TemporalSecondAccessor.FACTORY);
    fc.addGenerated(TemporalMillisecondAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDateAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndTimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalStartDatetimeAccessor.FACTORY);
    fc.addGenerated(TemporalIntervalEndDatetimeAccessor.FACTORY);
    // Temporal functions
    fc.addGenerated(UnixTimeFromDateInDaysDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromTimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInMsDescriptor.FACTORY);
    fc.addGenerated(UnixTimeFromDatetimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DateFromUnixTimeInDaysDescriptor.FACTORY);
    fc.addGenerated(DateFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(TimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(TimeFromDatetimeDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInMsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromUnixTimeInSecsDescriptor.FACTORY);
    fc.addGenerated(DatetimeFromDateAndTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDurationFromDateTimeDescriptor.FACTORY);
    fc.addGenerated(CalendarDuartionFromDateDescriptor.FACTORY);
    fc.addGenerated(AdjustDateTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(AdjustTimeForTimeZoneDescriptor.FACTORY);
    fc.addGenerated(IntervalBeforeDescriptor.FACTORY);
    fc.addGenerated(IntervalAfterDescriptor.FACTORY);
    fc.addGenerated(IntervalMeetsDescriptor.FACTORY);
    fc.addGenerated(IntervalMetByDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlapsDescriptor.FACTORY);
    fc.addGenerated(IntervalOverlappedByDescriptor.FACTORY);
    fc.addGenerated(OverlapDescriptor.FACTORY);
    fc.addGenerated(IntervalStartsDescriptor.FACTORY);
    fc.addGenerated(IntervalStartedByDescriptor.FACTORY);
    fc.addGenerated(IntervalCoversDescriptor.FACTORY);
    fc.addGenerated(IntervalCoveredByDescriptor.FACTORY);
    fc.addGenerated(IntervalEndsDescriptor.FACTORY);
    fc.addGenerated(IntervalEndedByDescriptor.FACTORY);
    fc.addGenerated(DurationFromMillisecondsDescriptor.FACTORY);
    fc.addGenerated(DurationFromMonthsDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(YearMonthDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationGreaterThanComparatorDescriptor.FACTORY);
    fc.addGenerated(DayTimeDurationLessThanComparatorDescriptor.FACTORY);
    fc.addGenerated(MonthsFromYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(MillisecondsFromDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(DurationEqualDescriptor.FACTORY);
    fc.addGenerated(GetYearMonthDurationDescriptor.FACTORY);
    fc.addGenerated(GetDayTimeDurationDescriptor.FACTORY);
    fc.addGenerated(IntervalBinDescriptor.FACTORY);
    fc.addGenerated(OverlapBinsDescriptor.FACTORY);
    fc.addGenerated(DayOfWeekDescriptor.FACTORY);
    fc.addGenerated(ParseDateDescriptor.FACTORY);
    fc.addGenerated(ParseTimeDescriptor.FACTORY);
    fc.addGenerated(ParseDateTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateDescriptor.FACTORY);
    fc.addGenerated(PrintTimeDescriptor.FACTORY);
    fc.addGenerated(PrintDateTimeDescriptor.FACTORY);
    fc.addGenerated(GetOverlappingIntervalDescriptor.FACTORY);
    fc.addGenerated(DurationFromIntervalDescriptor.FACTORY);
    // Type functions.
    fc.addGenerated(IsArrayDescriptor.FACTORY);
    fc.addGenerated(IsAtomicDescriptor.FACTORY);
    fc.addGenerated(IsBooleanDescriptor.FACTORY);
    fc.addGenerated(IsNumberDescriptor.FACTORY);
    fc.addGenerated(IsObjectDescriptor.FACTORY);
    fc.addGenerated(IsStringDescriptor.FACTORY);
    fc.addGenerated(ToArrayDescriptor.FACTORY);
    fc.addGenerated(ToAtomicDescriptor.FACTORY);
    fc.addGenerated(ToBigIntDescriptor.FACTORY);
    fc.addGenerated(ToBooleanDescriptor.FACTORY);
    fc.addGenerated(ToDoubleDescriptor.FACTORY);
    fc.addGenerated(ToNumberDescriptor.FACTORY);
    fc.addGenerated(ToObjectDescriptor.FACTORY);
    fc.addGenerated(ToStringDescriptor.FACTORY);
    // Cast function
    fc.addGenerated(CastTypeDescriptor.FACTORY);
    fc.addGenerated(CastTypeLaxDescriptor.FACTORY);
    // Record function
    fc.addGenerated(RecordPairsDescriptor.FACTORY);
    // Other functions
    fc.addGenerated(RandomWithSeedDescriptor.FACTORY);
    ServiceLoader.load(IFunctionRegistrant.class).iterator().forEachRemaining(c -> c.register(fc));
    return fc;
}
#end_block

#method_before
@Override
public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException {
    resultStorage.reset();
    eval0.evaluate(tuple, inputRecordPointable);
    eval1.evaluate(tuple, oldValuePointable);
    eval2.evaluate(tuple, newValuePointable);
    byte[] data = inputRecordPointable.getByteArray();
    int offset = inputRecordPointable.getStartOffset();
    byte typeTag = data[offset];
    if (typeTag != ATypeTag.SERIALIZED_RECORD_TYPE_TAG) {
        PointableHelper.setNull(result);
        return;
    }
    data = oldValuePointable.getByteArray();
    offset = oldValuePointable.getStartOffset();
    typeTag = data[offset];
    ATypeTag aTypeTag = ATypeTag.VALUE_TYPE_MAPPING[typeTag];
    if (aTypeTag == ATypeTag.OBJECT || aTypeTag == ATypeTag.ARRAY || aTypeTag == ATypeTag.MULTISET) {
        PointableHelper.setNull(result);
        return;
    }
    data = newValuePointable.getByteArray();
    offset = newValuePointable.getStartOffset();
    typeTag = data[offset];
    aTypeTag = ATypeTag.VALUE_TYPE_MAPPING[typeTag];
    if (aTypeTag == ATypeTag.OBJECT || aTypeTag == ATypeTag.ARRAY || aTypeTag == ATypeTag.MULTISET) {
        PointableHelper.setNull(result);
        return;
    }
    evaluate();
    result.set(resultStorage);
}
#method_after
@Override
public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException {
    resultStorage.reset();
    eval0.evaluate(tuple, inputRecordPointable);
    eval1.evaluate(tuple, oldValuePointable);
    eval2.evaluate(tuple, newValuePointable);
    if (containsMissing(inputRecordPointable, oldValuePointable, newValuePointable)) {
        writeTypeTag(ATypeTag.SERIALIZED_MISSING_TYPE_TAG);
        result.set(resultStorage);
        return;
    }
    final ATypeTag inputObjectType = PointableHelper.getTypeTag(inputRecordPointable);
    final ATypeTag oldValueType = PointableHelper.getTypeTag(oldValuePointable);
    if (inputObjectType != ATypeTag.OBJECT || oldValueType == ATypeTag.NULL) {
        writeTypeTag(ATypeTag.SERIALIZED_NULL_TYPE_TAG);
        result.set(resultStorage);
        return;
    }
    if (oldValueType.isDerivedType()) {
        throw new TypeMismatchException(sourceLoc, BuiltinFunctions.RECORD_REPLACE, 1, oldValueType.serialize(), "primitive");
    }
    inputRecordCaster.evaluate(tuple, inputRecordPointable);
    final ATypeTag newValueType = PointableHelper.getTypeTag(newValuePointable);
    if (newValueType.isDerivedType()) {
        newValueRecordCaster.evaluate(tuple, newValuePointable);
    }
    resultStorage.reset();
    buildOutputRecord(oldValueType);
    result.set(resultStorage);
}
#end_block

#method_before
private void buildOutputRecord(ARecordVisitablePointable inputRecord) throws HyracksDataException {
    outRecordBuilder.reset(DefaultOpenFieldType.NESTED_OPEN_RECORD_TYPE);
    outRecordBuilder.init();
    final List<IVisitablePointable> fieldNames = inputRecord.getFieldNames();
    final List<IVisitablePointable> fieldValues = inputRecord.getFieldValues();
    for (int i = 0, fieldCount = fieldNames.size(); i < fieldCount; i++) {
        final IVisitablePointable fieldName = fieldNames.get(i);
        final IVisitablePointable fieldValue = fieldValues.get(i);
        if (binaryComparator.compare(fieldValue.getByteArray(), fieldValue.getStartOffset(), fieldValue.getLength(), oldValuePointable.getByteArray(), oldValuePointable.getStartOffset(), oldValuePointable.getLength()) != 0) {
            outRecordBuilder.addField(fieldName, fieldValue);
        } else {
            outRecordBuilder.addField(fieldName, newValuePointable);
        }
    }
    outRecordBuilder.write(resultOutput, true);
}
#method_after
private void buildOutputRecord(ATypeTag oldValueTypeTag) throws HyracksDataException {
    openRecordPointable.set(inputRecordPointable);
    outRecordBuilder.reset(DefaultOpenFieldType.NESTED_OPEN_RECORD_TYPE);
    outRecordBuilder.init();
    final List<IVisitablePointable> fieldNames = openRecordPointable.getFieldNames();
    final List<IVisitablePointable> fieldValues = openRecordPointable.getFieldValues();
    for (int i = 0, fieldCount = fieldNames.size(); i < fieldCount; i++) {
        final IVisitablePointable fieldName = fieldNames.get(i);
        final IVisitablePointable fieldValue = fieldValues.get(i);
        final ATypeTag existingValueTypeTag = PointableHelper.getTypeTag(fieldValue);
        if (isEqual(existingValueTypeTag, fieldValue, oldValueTypeTag, oldValuePointable)) {
            outRecordBuilder.addField(fieldName, newValuePointable);
        } else {
            outRecordBuilder.addField(fieldName, fieldValue);
        }
    }
    outRecordBuilder.write(resultOutput, true);
}
#end_block

#method_before
public static String extractStatementParameterName(String name) {
    int ln = name.length();
    return ln > 1 && name.charAt(0) == '$' && Character.isLetter(name.charAt(1)) && (ln == 2 || isStatementParameterNameRest(name, 2)) ? name.substring(1) : null;
}
#method_after
public static String extractStatementParameterName(String name) {
    int ln = name.length();
    if (ln > 1 && name.charAt(0) == '$' && Character.isLetter(name.charAt(1))) {
        if (ln == 2 || isStatementParameterNameRest(name, 2)) {
            return name.substring(1);
        }
    }
    return null;
}
#end_block

#method_before
@Override
public IScalarEvaluator createScalarEvaluator(final IHyracksTaskContext ctx) throws HyracksDataException {
    return new IScalarEvaluator() {

        private final ArrayBackedValueStorage resultStorage = new ArrayBackedValueStorage();

        private final DataOutput output = resultStorage.getDataOutput();

        private IPointable inputArgList = new VoidPointable();

        private IPointable inputArgIdx = new VoidPointable();

        private IScalarEvaluator evalList = listEvalFactory.createScalarEvaluator(ctx);

        private IScalarEvaluator evalIdx = indexEvalFactory.createScalarEvaluator(ctx);

        private byte[] missingBytes = new byte[] { ATypeTag.SERIALIZED_MISSING_TYPE_TAG };

        private int itemIndex;

        private int itemOffset;

        private int itemLength;

        @Override
        public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException {
            try {
                evalList.evaluate(tuple, inputArgList);
                evalIdx.evaluate(tuple, inputArgIdx);
                byte[] serList = inputArgList.getByteArray();
                int offset = inputArgList.getStartOffset();
                byte[] indexBytes = inputArgIdx.getByteArray();
                int indexOffset = inputArgIdx.getStartOffset();
                int itemCount;
                if (serList[offset] == ATypeTag.SERIALIZED_ORDEREDLIST_TYPE_TAG) {
                    itemCount = AOrderedListSerializerDeserializer.getNumberOfItems(serList, offset);
                } else if (serList[offset] == ATypeTag.SERIALIZED_UNORDEREDLIST_TYPE_TAG) {
                    itemCount = AUnorderedListSerializerDeserializer.getNumberOfItems(serList, offset);
                } else {
                    throw new TypeMismatchException(sourceLoc, BuiltinFunctions.GET_ITEM, 0, serList[offset], ATypeTag.SERIALIZED_ORDEREDLIST_TYPE_TAG, ATypeTag.SERIALIZED_UNORDEREDLIST_TYPE_TAG);
                }
                itemIndex = ATypeHierarchy.getIntegerValue(BuiltinFunctions.GET_ITEM.getName(), 0, indexBytes, indexOffset);
                if (itemIndex < 0 || itemIndex >= itemCount) {
                    // Out-of-bound index access should return MISSING.
                    result.set(missingBytes, 0, 1);
                    return;
                }
                itemTag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(serList[offset + 1]);
                if (itemTag == ATypeTag.ANY) {
                    selfDescList = true;
                } else {
                    serItemTypeTag = serList[offset + 1];
                }
                if (serList[offset] == ATypeTag.SERIALIZED_ORDEREDLIST_TYPE_TAG) {
                    itemOffset = AOrderedListSerializerDeserializer.getItemOffset(serList, offset, itemIndex);
                } else {
                    itemOffset = AUnorderedListSerializerDeserializer.getItemOffset(serList, offset, 0);
                }
                if (selfDescList) {
                    itemTag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(serList[itemOffset]);
                    itemLength = NonTaggedFormatUtil.getFieldValueLength(serList, itemOffset, itemTag, true) + 1;
                    result.set(serList, itemOffset, itemLength);
                } else {
                    itemLength = NonTaggedFormatUtil.getFieldValueLength(serList, itemOffset, itemTag, false);
                    resultStorage.reset();
                    output.writeByte(serItemTypeTag);
                    output.write(serList, itemOffset, itemLength);
                    result.set(resultStorage);
                }
            } catch (IOException e) {
                throw HyracksDataException.create(e);
            }
        }
    };
}
#method_after
@Override
public IScalarEvaluator createScalarEvaluator(final IHyracksTaskContext ctx) throws HyracksDataException {
    return new IScalarEvaluator() {

        private final ArrayBackedValueStorage resultStorage = new ArrayBackedValueStorage();

        private final DataOutput output = resultStorage.getDataOutput();

        private IPointable inputArgList = new VoidPointable();

        private IPointable inputArgIdx = new VoidPointable();

        private IScalarEvaluator evalList = listEvalFactory.createScalarEvaluator(ctx);

        private IScalarEvaluator evalIdx = indexEvalFactory.createScalarEvaluator(ctx);

        private byte[] missingBytes = new byte[] { ATypeTag.SERIALIZED_MISSING_TYPE_TAG };

        @Override
        public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException {
            try {
                evalList.evaluate(tuple, inputArgList);
                evalIdx.evaluate(tuple, inputArgIdx);
                byte[] serList = inputArgList.getByteArray();
                int offset = inputArgList.getStartOffset();
                byte[] indexBytes = inputArgIdx.getByteArray();
                int indexOffset = inputArgIdx.getStartOffset();
                int itemCount;
                byte serListTypeTag = serList[offset];
                if (serListTypeTag == ATypeTag.SERIALIZED_ORDEREDLIST_TYPE_TAG) {
                    itemCount = AOrderedListSerializerDeserializer.getNumberOfItems(serList, offset);
                } else if (serListTypeTag == ATypeTag.SERIALIZED_UNORDEREDLIST_TYPE_TAG) {
                    itemCount = AUnorderedListSerializerDeserializer.getNumberOfItems(serList, offset);
                } else {
                    throw new TypeMismatchException(sourceLoc, BuiltinFunctions.GET_ITEM, 0, serListTypeTag, ATypeTag.SERIALIZED_ORDEREDLIST_TYPE_TAG, ATypeTag.SERIALIZED_UNORDEREDLIST_TYPE_TAG);
                }
                int itemIndex = ATypeHierarchy.getIntegerValue(BuiltinFunctions.GET_ITEM.getName(), 0, indexBytes, indexOffset);
                if (itemIndex < 0 || itemIndex >= itemCount) {
                    // Out-of-bound index access should return MISSING.
                    result.set(missingBytes, 0, 1);
                    return;
                }
                byte serItemTypeTag = serList[offset + 1];
                ATypeTag itemTag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(serItemTypeTag);
                boolean selfDescList = itemTag == ATypeTag.ANY;
                int itemOffset = serListTypeTag == ATypeTag.SERIALIZED_ORDEREDLIST_TYPE_TAG ? AOrderedListSerializerDeserializer.getItemOffset(serList, offset, itemIndex) : AUnorderedListSerializerDeserializer.getItemOffset(serList, offset, 0);
                if (selfDescList) {
                    itemTag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(serList[itemOffset]);
                    int itemLength = NonTaggedFormatUtil.getFieldValueLength(serList, itemOffset, itemTag, true) + 1;
                    result.set(serList, itemOffset, itemLength);
                } else {
                    int itemLength = NonTaggedFormatUtil.getFieldValueLength(serList, itemOffset, itemTag, false);
                    resultStorage.reset();
                    output.writeByte(serItemTypeTag);
                    output.write(serList, itemOffset, itemLength);
                    result.set(resultStorage);
                }
            } catch (IOException e) {
                throw HyracksDataException.create(e);
            }
        }
    };
}
#end_block

#method_before
@Test
public void test() throws Exception {
    try {
        String queryFileShort = queryFile.getPath().substring(PATH_QUERIES.length()).replace(SEPARATOR.charAt(0), '/');
        if (!only.isEmpty()) {
            boolean toRun = TestHelper.isInPrefixList(only, queryFileShort);
            if (!toRun) {
                LOGGER.info("SKIP TEST: \"" + queryFile.getPath() + "\" \"only.txt\" not empty and not in \"only.txt\".");
            }
            Assume.assumeTrue(toRun);
        }
        boolean skipped = TestHelper.isInPrefixList(ignore, queryFileShort);
        if (skipped) {
            LOGGER.info("SKIP TEST: \"" + queryFile.getPath() + "\" in \"ignore.txt\".");
        }
        Assume.assumeTrue(!skipped);
        LOGGER.info("RUN TEST: \"" + queryFile.getPath() + "\"");
        byte[] queryContents = Files.readAllBytes(queryFile.toPath());
        String query = new String(queryContents, StandardCharsets.UTF_8);
        Map<String, IAObject> queryParams = TestHelper.readStatementParameters(query);
        LOGGER.info("ACTUAL RESULT FILE: " + actualFile.getAbsolutePath());
        // Forces the creation of actualFile.
        actualFile.getParentFile().mkdirs();
        ILangCompilationProvider provider = queryFile.getName().endsWith("aql") ? aqlCompilationProvider : sqlppCompilationProvider;
        if (extensionLangCompilationProvider != null) {
            provider = extensionLangCompilationProvider;
        }
        IHyracksClientConnection hcc = integrationUtil.getHyracksClientConnection();
        try (PrintWriter plan = new PrintWriter(actualFile)) {
            AsterixJavaClient asterix = new AsterixJavaClient((ICcApplicationContext) integrationUtil.cc.getApplicationContext(), hcc, new StringReader(query), plan, provider, statementExecutorFactory, storageComponentProvider);
            asterix.setStatementParameters(queryParams);
            asterix.compile(true, false, false, true, true, false, false);
        } catch (AlgebricksException e) {
            throw new Exception("Compile ERROR for " + queryFile + ": " + e.getMessage(), e);
        }
        BufferedReader readerExpected = new BufferedReader(new InputStreamReader(new FileInputStream(expectedFile), "UTF-8"));
        BufferedReader readerActual = new BufferedReader(new InputStreamReader(new FileInputStream(actualFile), "UTF-8"));
        String lineExpected, lineActual;
        int num = 1;
        try {
            while ((lineExpected = readerExpected.readLine()) != null) {
                lineActual = readerActual.readLine();
                if (lineActual == null) {
                    throw new Exception("Result for " + queryFile + " changed at line " + num + ":\n< " + lineExpected + "\n> ");
                }
                if (!lineExpected.equals(lineActual)) {
                    throw new Exception("Result for " + queryFile + " changed at line " + num + ":\n< " + lineExpected + "\n> " + lineActual);
                }
                ++num;
            }
            lineActual = readerActual.readLine();
            if (lineActual != null) {
                throw new Exception("Result for " + queryFile + " changed at line " + num + ":\n< \n> " + lineActual);
            }
            LOGGER.info("Test \"" + queryFile.getPath() + "\" PASSED!");
            actualFile.delete();
        } finally {
            readerExpected.close();
            readerActual.close();
        }
    } catch (Exception e) {
        if (!(e instanceof AssumptionViolatedException)) {
            LOGGER.error("Test \"" + queryFile.getPath() + "\" FAILED!");
            throw new Exception("Test \"" + queryFile.getPath() + "\" FAILED!", e);
        } else {
            throw e;
        }
    }
}
#method_after
@Test
public void test() throws Exception {
    try {
        String queryFileShort = queryFile.getPath().substring(PATH_QUERIES.length()).replace(SEPARATOR.charAt(0), '/');
        if (!only.isEmpty()) {
            boolean toRun = TestHelper.isInPrefixList(only, queryFileShort);
            if (!toRun) {
                LOGGER.info("SKIP TEST: \"" + queryFile.getPath() + "\" \"only.txt\" not empty and not in \"only.txt\".");
            }
            Assume.assumeTrue(toRun);
        }
        boolean skipped = TestHelper.isInPrefixList(ignore, queryFileShort);
        if (skipped) {
            LOGGER.info("SKIP TEST: \"" + queryFile.getPath() + "\" in \"ignore.txt\".");
        }
        Assume.assumeTrue(!skipped);
        LOGGER.info("RUN TEST: \"" + queryFile.getPath() + "\"");
        String query = FileUtils.readFileToString(queryFile, StandardCharsets.UTF_8);
        Map<String, IAObject> queryParams = TestHelper.readStatementParameters(query);
        LOGGER.info("ACTUAL RESULT FILE: " + actualFile.getAbsolutePath());
        // Forces the creation of actualFile.
        actualFile.getParentFile().mkdirs();
        ILangCompilationProvider provider = queryFile.getName().endsWith("aql") ? aqlCompilationProvider : sqlppCompilationProvider;
        if (extensionLangCompilationProvider != null) {
            provider = extensionLangCompilationProvider;
        }
        IHyracksClientConnection hcc = integrationUtil.getHyracksClientConnection();
        try (PrintWriter plan = new PrintWriter(actualFile)) {
            AsterixJavaClient asterix = new AsterixJavaClient((ICcApplicationContext) integrationUtil.cc.getApplicationContext(), hcc, new StringReader(query), plan, provider, statementExecutorFactory, storageComponentProvider);
            asterix.setStatementParameters(queryParams);
            asterix.compile(true, false, false, true, true, false, false);
        } catch (AlgebricksException e) {
            throw new Exception("Compile ERROR for " + queryFile + ": " + e.getMessage(), e);
        }
        BufferedReader readerExpected = new BufferedReader(new InputStreamReader(new FileInputStream(expectedFile), "UTF-8"));
        BufferedReader readerActual = new BufferedReader(new InputStreamReader(new FileInputStream(actualFile), "UTF-8"));
        String lineExpected, lineActual;
        int num = 1;
        try {
            while ((lineExpected = readerExpected.readLine()) != null) {
                lineActual = readerActual.readLine();
                if (lineActual == null) {
                    throw new Exception("Result for " + queryFile + " changed at line " + num + ":\n< " + lineExpected + "\n> ");
                }
                if (!lineExpected.equals(lineActual)) {
                    throw new Exception("Result for " + queryFile + " changed at line " + num + ":\n< " + lineExpected + "\n> " + lineActual);
                }
                ++num;
            }
            lineActual = readerActual.readLine();
            if (lineActual != null) {
                throw new Exception("Result for " + queryFile + " changed at line " + num + ":\n< \n> " + lineActual);
            }
            LOGGER.info("Test \"" + queryFile.getPath() + "\" PASSED!");
            actualFile.delete();
        } finally {
            readerExpected.close();
            readerActual.close();
        }
    } catch (Exception e) {
        if (!(e instanceof AssumptionViolatedException)) {
            LOGGER.error("Test \"" + queryFile.getPath() + "\" FAILED!");
            throw new Exception("Test \"" + queryFile.getPath() + "\" FAILED!", e);
        } else {
            throw e;
        }
    }
}
#end_block

#method_before
@Override
public IRetryPolicy create(IActiveEntityEventsListener listener) {
    return policy;
}
#method_after
@Override
public IRetryPolicy create(IActiveEntityEventsListener listener) {
    return NoRetryPolicy.INSTANCE;
}
#end_block

